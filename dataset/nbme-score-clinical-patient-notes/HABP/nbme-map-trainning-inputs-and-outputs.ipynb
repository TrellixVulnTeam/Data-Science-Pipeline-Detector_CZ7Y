{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow import keras\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-16T17:25:58.82276Z","iopub.execute_input":"2022-04-16T17:25:58.823129Z","iopub.status.idle":"2022-04-16T17:26:04.307919Z","shell.execute_reply.started":"2022-04-16T17:25:58.823037Z","shell.execute_reply":"2022-04-16T17:26:04.307042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Vocabulary","metadata":{}},{"cell_type":"code","source":"total_vocabulary_df = pd.read_csv('/kaggle/input/nbme-creating-vocabulary/total_vocabulary.csv')\n\ntotal_annotation_vocabulary_df = pd.read_csv('/kaggle/input/nbme-creating-vocabulary/total_annotation_vocabulary.csv')","metadata":{"execution":{"iopub.status.busy":"2022-04-16T17:26:04.311482Z","iopub.execute_input":"2022-04-16T17:26:04.311885Z","iopub.status.idle":"2022-04-16T17:26:04.418239Z","shell.execute_reply.started":"2022-04-16T17:26:04.311836Z","shell.execute_reply":"2022-04-16T17:26:04.417381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Input Data","metadata":{}},{"cell_type":"code","source":"patient_notes_df = pd.read_csv('/kaggle/input/nbme-score-clinical-patient-notes/patient_notes.csv')\n\nfeatures_df = pd.read_csv('/kaggle/input/nbme-score-clinical-patient-notes/features.csv')\n\ntrain_df = pd.read_csv('/kaggle/input/nbme-score-clinical-patient-notes/train.csv')","metadata":{"execution":{"iopub.status.busy":"2022-04-16T17:26:04.419633Z","iopub.execute_input":"2022-04-16T17:26:04.419912Z","iopub.status.idle":"2022-04-16T17:26:05.273097Z","shell.execute_reply.started":"2022-04-16T17:26:04.419874Z","shell.execute_reply":"2022-04-16T17:26:05.272242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Functions","metadata":{}},{"cell_type":"code","source":"import ast\n\ndef take_pacient_note(pacient_note_num: int) -> dict:\n    pacient_note = patient_notes_df[patient_notes_df['pn_num'] == pacient_note_num].reset_index()['pn_history'][0]\n    return pacient_note\n\ndef get_training_patient_note_numbers(case_number):\n    return train_df[train_df['case_num'] == case_number]['pn_num'].to_numpy()\n\ndef get_all_feature_numbers(case_number):\n    return features_df[features_df['case_num'] == case_number]['feature_num'].to_numpy()\n\ndef get_all_patient_note_numbers(case_number):\n    return patient_notes_df[patient_notes_df['case_num'] == case_number]['pn_num'].to_numpy()\n\ndef get_feature_annotations(patient_note_num, feature_number):\n    aux_df = train_df[train_df['pn_num'] == patient_note_num]\n    return ast.literal_eval(aux_df[aux_df['feature_num'] == feature_number].reset_index()['annotation'][0])\n\ndef get_all_training_annotations(case_number):\n    return [ast.literal_eval(x) for x in train_df[train_df['case_num'] == case_number]['annotation'].to_numpy()]","metadata":{"execution":{"iopub.status.busy":"2022-04-16T17:26:05.275136Z","iopub.execute_input":"2022-04-16T17:26:05.275426Z","iopub.status.idle":"2022-04-16T17:26:05.283157Z","shell.execute_reply.started":"2022-04-16T17:26:05.275395Z","shell.execute_reply":"2022-04-16T17:26:05.282372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing Entry Data","metadata":{}},{"cell_type":"code","source":"def preprocessing(X_batch):\n    X_out_batch = tf.strings.lower(X_batch)\n    X_out_batch = tf.strings.regex_replace(X_out_batch, b\"\\n\\r\", b\" \")\n    X_out_batch = tf.strings.regex_replace(X_out_batch, b\"\\r\\n\", b\" \")\n    X_out_batch = tf.strings.regex_replace(X_out_batch, b\"[^a-zA-Z0-9-']\", b\" \")\n    X_out_batch = tf.strings.regex_replace(X_out_batch, b\"-\", b\" - \")\n    X_out_batch = tf.strings.split(X_out_batch)\n    return X_out_batch","metadata":{"execution":{"iopub.status.busy":"2022-04-16T17:26:05.284307Z","iopub.execute_input":"2022-04-16T17:26:05.284496Z","iopub.status.idle":"2022-04-16T17:26:05.296795Z","shell.execute_reply.started":"2022-04-16T17:26:05.284471Z","shell.execute_reply":"2022-04-16T17:26:05.296256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Defining Truncated Vocabulary","metadata":{}},{"cell_type":"code","source":"import pickle\n\nwith open('/kaggle/input/nbme-truncated-vocabulary/truncated.vocabulary', 'rb') as truncated_vocabulary_file:\n    truncated_vocabulary = pickle.load(truncated_vocabulary_file)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T17:26:05.298018Z","iopub.execute_input":"2022-04-16T17:26:05.298401Z","iopub.status.idle":"2022-04-16T17:26:05.313028Z","shell.execute_reply.started":"2022-04-16T17:26:05.29836Z","shell.execute_reply":"2022-04-16T17:26:05.312105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generate Lookup Table","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\ndef create_lookup_table(truncated_vocabulary):\n    words = tf.constant(truncated_vocabulary)\n    word_ids = tf.range(len(truncated_vocabulary), dtype=tf.int64)\n    vocab_init = tf.lookup.KeyValueTensorInitializer(words, word_ids)\n    num_oov_buckets = 1000\n    \n    return tf.lookup.StaticVocabularyTable(vocab_init, num_oov_buckets)\n\nlookup_table = create_lookup_table(truncated_vocabulary)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T17:26:05.314448Z","iopub.execute_input":"2022-04-16T17:26:05.314797Z","iopub.status.idle":"2022-04-16T17:26:05.36991Z","shell.execute_reply.started":"2022-04-16T17:26:05.314762Z","shell.execute_reply":"2022-04-16T17:26:05.369009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lookup_table","metadata":{"execution":{"iopub.status.busy":"2022-04-16T17:26:05.371075Z","iopub.execute_input":"2022-04-16T17:26:05.371326Z","iopub.status.idle":"2022-04-16T17:26:05.378963Z","shell.execute_reply.started":"2022-04-16T17:26:05.371295Z","shell.execute_reply":"2022-04-16T17:26:05.378073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Input Map Functions","metadata":{}},{"cell_type":"code","source":"def add_padding(input_string, padding_size):\n    padding = \" <pad> \"* padding_size\n    string_with_padding = padding + input_string + padding\n    \n    return string_with_padding","metadata":{"execution":{"iopub.status.busy":"2022-04-16T17:26:05.380339Z","iopub.execute_input":"2022-04-16T17:26:05.380612Z","iopub.status.idle":"2022-04-16T17:26:05.389817Z","shell.execute_reply.started":"2022-04-16T17:26:05.380582Z","shell.execute_reply":"2022-04-16T17:26:05.388935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def input_map_generation(input_string, padding_size):\n    processed_string = add_padding(input_string, padding_size)\n    tensor_words = preprocessing(processed_string)\n    coded_tensor = lookup_table.lookup(tensor_words)\n    return coded_tensor","metadata":{"execution":{"iopub.status.busy":"2022-04-16T17:26:05.392331Z","iopub.execute_input":"2022-04-16T17:26:05.392556Z","iopub.status.idle":"2022-04-16T17:26:05.399292Z","shell.execute_reply.started":"2022-04-16T17:26:05.392529Z","shell.execute_reply":"2022-04-16T17:26:05.398628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def map_input_pacient_note(patient_note_num, padding_size):\n    pacient_note = take_pacient_note(patient_note_num)\n    coded_tensor = input_map_generation(pacient_note, padding_size)\n    return coded_tensor","metadata":{"execution":{"iopub.status.busy":"2022-04-16T17:26:05.400294Z","iopub.execute_input":"2022-04-16T17:26:05.40087Z","iopub.status.idle":"2022-04-16T17:26:05.410797Z","shell.execute_reply.started":"2022-04-16T17:26:05.400828Z","shell.execute_reply":"2022-04-16T17:26:05.410169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def map_all_training_inputs(case_number, padding_size):\n    patient_note_numbers = list(set(get_training_patient_note_numbers(case_number)))\n    patient_note_numbers.sort()\n    \n    mapped_inputs = {}\n    for patient_note_num in patient_note_numbers:\n        mapped_inputs[patient_note_num] = map_input_pacient_note(patient_note_num, padding_size)\n        \n    return mapped_inputs","metadata":{"execution":{"iopub.status.busy":"2022-04-16T17:26:05.41404Z","iopub.execute_input":"2022-04-16T17:26:05.414901Z","iopub.status.idle":"2022-04-16T17:26:05.421817Z","shell.execute_reply.started":"2022-04-16T17:26:05.414857Z","shell.execute_reply":"2022-04-16T17:26:05.421017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dicionario = map_all_training_inputs(0, 5)\n\n# dicionario","metadata":{"execution":{"iopub.status.busy":"2022-04-16T17:26:05.423312Z","iopub.execute_input":"2022-04-16T17:26:05.423786Z","iopub.status.idle":"2022-04-16T17:26:05.432772Z","shell.execute_reply.started":"2022-04-16T17:26:05.423754Z","shell.execute_reply":"2022-04-16T17:26:05.432116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Output Map Functions","metadata":{}},{"cell_type":"code","source":"def find_annotation_position(input_tensor, annotation_tensor):\n    len_input_tensor = len(input_tensor)\n    len_annotation_tensor = len(annotation_tensor)\n    \n    if len_annotation_tensor == 0:\n        return []\n    \n    is_in = [all(annotation_tensor == input_tensor[i:len_annotation_tensor+i]) for i in range(len_input_tensor - len_annotation_tensor+1)]\n    return [i for i, val in enumerate(is_in) if val == True]","metadata":{"execution":{"iopub.status.busy":"2022-04-16T17:26:05.434068Z","iopub.execute_input":"2022-04-16T17:26:05.434567Z","iopub.status.idle":"2022-04-16T17:26:05.443929Z","shell.execute_reply.started":"2022-04-16T17:26:05.434535Z","shell.execute_reply":"2022-04-16T17:26:05.443283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def output_map_generation(input_string, annotations_list):\n    tensor_input = preprocessing(input_string)\n    coded_input_tensor = lookup_table.lookup(tensor_input)\n    \n    output_array = np.zeros(coded_input_tensor.shape, dtype=np.int32)\n    \n    for annotation_string in annotations_list:\n        tensor_annotation = preprocessing(annotation_string)\n        coded_annotation_tensor = lookup_table.lookup(tensor_annotation)\n        \n        annotation_positions = find_annotation_position(coded_input_tensor, coded_annotation_tensor)\n        len_coded_annotation_tensor = len(coded_annotation_tensor)\n        \n        for position in annotation_positions:\n            for i in range(len_coded_annotation_tensor):\n                output_array[position + i] = 1\n    \n    output_tensor = tf.convert_to_tensor(output_array)\n    return output_tensor\n        ","metadata":{"execution":{"iopub.status.busy":"2022-04-16T17:26:05.445398Z","iopub.execute_input":"2022-04-16T17:26:05.445895Z","iopub.status.idle":"2022-04-16T17:26:05.455573Z","shell.execute_reply.started":"2022-04-16T17:26:05.445853Z","shell.execute_reply":"2022-04-16T17:26:05.454819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def map_all_training_outputs(case_number):\n    patient_note_numbers = list(set(get_training_patient_note_numbers(case_number)))\n    patient_note_numbers.sort()\n    \n    feature_numbers = get_all_feature_numbers(case_number)\n    feature_numbers.sort()\n    \n    mapped_outputs = {}\n    for patient_note_num in patient_note_numbers:\n        for feature_number in feature_numbers:\n            input_string = take_pacient_note(patient_note_num)\n            annotations_list = get_feature_annotations(patient_note_num, feature_number)\n            mapped_outputs[(patient_note_num, feature_number)] = output_map_generation(input_string, annotations_list)\n        \n    return mapped_outputs","metadata":{"execution":{"iopub.status.busy":"2022-04-16T17:26:05.456785Z","iopub.execute_input":"2022-04-16T17:26:05.457494Z","iopub.status.idle":"2022-04-16T17:26:05.470584Z","shell.execute_reply.started":"2022-04-16T17:26:05.45746Z","shell.execute_reply":"2022-04-16T17:26:05.469666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dicionario2 = map_all_training_outputs(0)\n\n# dicionario2","metadata":{"execution":{"iopub.status.busy":"2022-04-16T17:26:05.471669Z","iopub.execute_input":"2022-04-16T17:26:05.471918Z","iopub.status.idle":"2022-04-16T17:26:05.480852Z","shell.execute_reply.started":"2022-04-16T17:26:05.47189Z","shell.execute_reply":"2022-04-16T17:26:05.480037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generating and Saving Output Maps","metadata":{}},{"cell_type":"code","source":"import pickle\n\ndef save_input_map(input_map, case):\n    with open(f'/kaggle/working/input.map.case.{case}', 'wb') as input_case_file:\n        pickle.dump(input_map, input_case_file)\n    \ndef save_output_map(output_map, case):\n    with open(f'/kaggle/working/output.map.case.{case}', 'wb') as output_case_file:\n        pickle.dump(output_map, output_case_file)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T17:26:05.482002Z","iopub.execute_input":"2022-04-16T17:26:05.482278Z","iopub.status.idle":"2022-04-16T17:26:05.493845Z","shell.execute_reply.started":"2022-04-16T17:26:05.482208Z","shell.execute_reply":"2022-04-16T17:26:05.493025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"defined_padding = 5\nnumber_of_cases = 10\n\nfor case_num in range(number_of_cases):\n    print(f\"Creating input map for case {case_num}\")\n    input_map = map_all_training_inputs(case_num, defined_padding)\n    \n    print(f\"Creating output map for case {case_num}\")\n    output_map = map_all_training_outputs(case_num)\n    \n    print(f\"Saving maps for case {case_num}\")\n    save_input_map(input_map, case_num)\n    save_output_map(output_map, case_num)\n    print(f\"Saved maps for case {case_num}\")","metadata":{"execution":{"iopub.status.busy":"2022-04-16T17:29:31.110167Z","iopub.execute_input":"2022-04-16T17:29:31.11048Z","iopub.status.idle":"2022-04-16T17:29:32.55007Z","shell.execute_reply.started":"2022-04-16T17:29:31.110447Z","shell.execute_reply":"2022-04-16T17:29:32.548947Z"},"trusted":true},"execution_count":null,"outputs":[]}]}