{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow import keras\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-17T02:35:17.898017Z","iopub.execute_input":"2022-04-17T02:35:17.898391Z","iopub.status.idle":"2022-04-17T02:35:23.438666Z","shell.execute_reply.started":"2022-04-17T02:35:17.898296Z","shell.execute_reply":"2022-04-17T02:35:23.437589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Vocabulary","metadata":{}},{"cell_type":"code","source":"total_vocabulary_df = pd.read_csv('/kaggle/input/nbme-creating-vocabulary/total_vocabulary.csv')\n\ntotal_annotation_vocabulary_df = pd.read_csv('/kaggle/input/nbme-creating-vocabulary/total_annotation_vocabulary.csv')","metadata":{"execution":{"iopub.status.busy":"2022-04-17T02:35:23.440858Z","iopub.execute_input":"2022-04-17T02:35:23.441202Z","iopub.status.idle":"2022-04-17T02:35:23.507971Z","shell.execute_reply.started":"2022-04-17T02:35:23.441158Z","shell.execute_reply":"2022-04-17T02:35:23.507219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Input Data","metadata":{}},{"cell_type":"code","source":"patient_notes_df = pd.read_csv('/kaggle/input/nbme-score-clinical-patient-notes/patient_notes.csv')\n\nfeatures_df = pd.read_csv('/kaggle/input/nbme-score-clinical-patient-notes/features.csv')\n\ntrain_df = pd.read_csv('/kaggle/input/nbme-score-clinical-patient-notes/train.csv')","metadata":{"execution":{"iopub.status.busy":"2022-04-17T02:35:23.508919Z","iopub.execute_input":"2022-04-17T02:35:23.509688Z","iopub.status.idle":"2022-04-17T02:35:24.219817Z","shell.execute_reply.started":"2022-04-17T02:35:23.50965Z","shell.execute_reply":"2022-04-17T02:35:24.219041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Functions","metadata":{}},{"cell_type":"code","source":"import ast\n\ndef take_pacient_note(pacient_note_num: int) -> dict:\n    pacient_note = patient_notes_df[patient_notes_df['pn_num'] == pacient_note_num].reset_index()['pn_history'][0]\n    return pacient_note\n\ndef get_training_patient_note_numbers(case_number):\n    return train_df[train_df['case_num'] == case_number]['pn_num'].to_numpy()\n\ndef get_all_feature_numbers(case_number):\n    return features_df[features_df['case_num'] == case_number]['feature_num'].to_numpy()\n\ndef get_all_patient_note_numbers(case_number):\n    return patient_notes_df[patient_notes_df['case_num'] == case_number]['pn_num'].to_numpy()\n\ndef get_feature_annotations(patient_note_num, feature_number):\n    aux_df = train_df[train_df['pn_num'] == patient_note_num]\n    return ast.literal_eval(aux_df[aux_df['feature_num'] == feature_number].reset_index()['annotation'][0])\n\ndef get_all_training_annotations(case_number):\n    return [ast.literal_eval(x) for x in train_df[train_df['case_num'] == case_number]['annotation'].to_numpy()]","metadata":{"execution":{"iopub.status.busy":"2022-04-17T02:35:24.222214Z","iopub.execute_input":"2022-04-17T02:35:24.222526Z","iopub.status.idle":"2022-04-17T02:35:24.232006Z","shell.execute_reply.started":"2022-04-17T02:35:24.222484Z","shell.execute_reply":"2022-04-17T02:35:24.231369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing Entry Data","metadata":{}},{"cell_type":"code","source":"def preprocessing(X_batch):\n    X_out_batch = tf.strings.lower(X_batch)\n    X_out_batch = tf.strings.regex_replace(X_out_batch, b\"\\n\\r\", b\" \")\n    X_out_batch = tf.strings.regex_replace(X_out_batch, b\"\\r\\n\", b\" \")\n    X_out_batch = tf.strings.regex_replace(X_out_batch, b\"[^a-zA-Z0-9-']\", b\" \")\n    X_out_batch = tf.strings.regex_replace(X_out_batch, b\"-\", b\" - \")\n    X_out_batch = tf.strings.split(X_out_batch)\n    return X_out_batch","metadata":{"execution":{"iopub.status.busy":"2022-04-17T02:35:24.232971Z","iopub.execute_input":"2022-04-17T02:35:24.233683Z","iopub.status.idle":"2022-04-17T02:35:24.248996Z","shell.execute_reply.started":"2022-04-17T02:35:24.233643Z","shell.execute_reply":"2022-04-17T02:35:24.248359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Defining Truncated Vocabulary","metadata":{}},{"cell_type":"code","source":"import pickle\n\nwith open('/kaggle/input/nbme-truncated-vocabulary/truncated.vocabulary', 'rb') as truncated_vocabulary_file:\n    truncated_vocabulary = pickle.load(truncated_vocabulary_file)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T02:35:24.250349Z","iopub.execute_input":"2022-04-17T02:35:24.250725Z","iopub.status.idle":"2022-04-17T02:35:24.267863Z","shell.execute_reply.started":"2022-04-17T02:35:24.250682Z","shell.execute_reply":"2022-04-17T02:35:24.267197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generate Lookup Table","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\ndef create_lookup_table(truncated_vocabulary):\n    words = tf.constant(truncated_vocabulary)\n    word_ids = tf.range(len(truncated_vocabulary), dtype=tf.int64)\n    vocab_init = tf.lookup.KeyValueTensorInitializer(words, word_ids)\n    num_oov_buckets = 1000\n    \n    return tf.lookup.StaticVocabularyTable(vocab_init, num_oov_buckets)\n\nlookup_table = create_lookup_table(truncated_vocabulary)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T02:35:24.269068Z","iopub.execute_input":"2022-04-17T02:35:24.269919Z","iopub.status.idle":"2022-04-17T02:35:24.325468Z","shell.execute_reply.started":"2022-04-17T02:35:24.269881Z","shell.execute_reply":"2022-04-17T02:35:24.324764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lookup_table","metadata":{"execution":{"iopub.status.busy":"2022-04-17T02:35:24.326608Z","iopub.execute_input":"2022-04-17T02:35:24.326955Z","iopub.status.idle":"2022-04-17T02:35:24.334273Z","shell.execute_reply.started":"2022-04-17T02:35:24.326914Z","shell.execute_reply":"2022-04-17T02:35:24.333624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Input Map Functions","metadata":{}},{"cell_type":"code","source":"def add_padding(input_string, padding_size):\n    padding = \" <pad> \"* padding_size\n    string_with_padding = padding + input_string + padding\n    \n    return string_with_padding","metadata":{"execution":{"iopub.status.busy":"2022-04-17T02:35:24.335181Z","iopub.execute_input":"2022-04-17T02:35:24.335977Z","iopub.status.idle":"2022-04-17T02:35:24.345979Z","shell.execute_reply.started":"2022-04-17T02:35:24.335943Z","shell.execute_reply":"2022-04-17T02:35:24.34531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def input_map_generation(input_string, padding_size):\n    processed_string = add_padding(input_string, padding_size)\n    tensor_words = preprocessing(processed_string)\n    coded_tensor = lookup_table.lookup(tensor_words)\n    return coded_tensor","metadata":{"execution":{"iopub.status.busy":"2022-04-17T02:35:24.34798Z","iopub.execute_input":"2022-04-17T02:35:24.34839Z","iopub.status.idle":"2022-04-17T02:35:24.358286Z","shell.execute_reply.started":"2022-04-17T02:35:24.348356Z","shell.execute_reply":"2022-04-17T02:35:24.357607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def map_input_pacient_note(patient_note_num, padding_size):\n    pacient_note = take_pacient_note(patient_note_num)\n    coded_tensor = input_map_generation(pacient_note, padding_size)\n    return coded_tensor","metadata":{"execution":{"iopub.status.busy":"2022-04-17T02:35:24.35929Z","iopub.execute_input":"2022-04-17T02:35:24.359664Z","iopub.status.idle":"2022-04-17T02:35:24.37212Z","shell.execute_reply.started":"2022-04-17T02:35:24.359634Z","shell.execute_reply":"2022-04-17T02:35:24.371143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def map_all_no_training_inputs(case_number, padding_size):\n    patient_note_numbers = list(set(get_all_patient_note_numbers(case_number))-set(get_training_patient_note_numbers(case_number)))\n    patient_note_numbers.sort()\n    \n    mapped_inputs = {}\n    for patient_note_num in patient_note_numbers:\n        mapped_inputs[patient_note_num] = map_input_pacient_note(patient_note_num, padding_size)\n        \n    return mapped_inputs","metadata":{"execution":{"iopub.status.busy":"2022-04-17T02:35:24.373841Z","iopub.execute_input":"2022-04-17T02:35:24.374192Z","iopub.status.idle":"2022-04-17T02:35:24.384169Z","shell.execute_reply.started":"2022-04-17T02:35:24.374148Z","shell.execute_reply":"2022-04-17T02:35:24.383305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dicionario = map_all_no_training_inputs(2, 5)\n\n# dicionario","metadata":{"execution":{"iopub.status.busy":"2022-04-17T02:35:24.385355Z","iopub.execute_input":"2022-04-17T02:35:24.385583Z","iopub.status.idle":"2022-04-17T02:35:24.396708Z","shell.execute_reply.started":"2022-04-17T02:35:24.385556Z","shell.execute_reply":"2022-04-17T02:35:24.395989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generating and Saving Output Maps","metadata":{}},{"cell_type":"code","source":"import pickle\n\ndef save_input_map(input_map, case):\n    with open(f'/kaggle/working/input.map.case.{case}', 'wb') as input_case_file:\n        pickle.dump(input_map, input_case_file)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T02:35:24.39814Z","iopub.execute_input":"2022-04-17T02:35:24.398695Z","iopub.status.idle":"2022-04-17T02:35:24.410189Z","shell.execute_reply.started":"2022-04-17T02:35:24.398655Z","shell.execute_reply":"2022-04-17T02:35:24.409231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"defined_padding = 5\nnumber_of_cases = 10\n\nfor case_num in range(number_of_cases):\n    print(f\"Creating input map for case {case_num}\")\n    input_map = map_all_no_training_inputs(case_num, defined_padding)\n    \n    print(f\"Saving maps for case {case_num}\")\n    save_input_map(input_map, case_num)\n    print(f\"Saved maps for case {case_num}\")","metadata":{"execution":{"iopub.status.busy":"2022-04-17T02:35:24.412056Z","iopub.execute_input":"2022-04-17T02:35:24.412501Z","iopub.status.idle":"2022-04-17T02:36:21.711167Z","shell.execute_reply.started":"2022-04-17T02:35:24.412459Z","shell.execute_reply":"2022-04-17T02:36:21.709563Z"},"trusted":true},"execution_count":null,"outputs":[]}]}