{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow import keras\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-15T18:49:39.470537Z","iopub.execute_input":"2022-04-15T18:49:39.471503Z","iopub.status.idle":"2022-04-15T18:49:44.854585Z","shell.execute_reply.started":"2022-04-15T18:49:39.471381Z","shell.execute_reply":"2022-04-15T18:49:44.85243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Input Data","metadata":{}},{"cell_type":"code","source":"patient_notes_df = pd.read_csv('/kaggle/input/nbme-score-clinical-patient-notes/patient_notes.csv')\n\nfeatures_df = pd.read_csv('/kaggle/input/nbme-score-clinical-patient-notes/features.csv')\n\ntrain_df = pd.read_csv('/kaggle/input/nbme-score-clinical-patient-notes/train.csv')","metadata":{"execution":{"iopub.status.busy":"2022-04-15T18:49:44.856164Z","iopub.execute_input":"2022-04-15T18:49:44.856407Z","iopub.status.idle":"2022-04-15T18:49:45.565533Z","shell.execute_reply.started":"2022-04-15T18:49:44.856377Z","shell.execute_reply":"2022-04-15T18:49:45.564482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Functions","metadata":{}},{"cell_type":"code","source":"import ast\n\ndef take_pacient_note(pacient_note_num: int) -> dict:\n    pacient_note = patient_notes_df[patient_notes_df['pn_num'] == pacient_note_num].reset_index()['pn_history'][0]\n    return pacient_note\n\ndef get_training_patient_note_numbers(case_number):\n    return train_df[train_df['case_num'] == case_number]['pn_num'].to_numpy()\n\ndef get_all_patient_note_numbers(case_number):\n    return patient_notes_df[patient_notes_df['case_num'] == case_number]['pn_num'].to_numpy()\n\ndef get_all_training_annotations(case_number):\n    return [ast.literal_eval(x) for x in train_df[train_df['case_num'] == case_number]['annotation'].to_numpy()]","metadata":{"execution":{"iopub.status.busy":"2022-04-15T18:49:45.566816Z","iopub.execute_input":"2022-04-15T18:49:45.5671Z","iopub.status.idle":"2022-04-15T18:49:45.574589Z","shell.execute_reply.started":"2022-04-15T18:49:45.567055Z","shell.execute_reply":"2022-04-15T18:49:45.573413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Looking Data","metadata":{}},{"cell_type":"code","source":"print(\"patient_notes_df\")\nprint(repr(patient_notes_df.head(5)))\nprint(\"features_df\")\nprint(repr(features_df.head(5)))\nprint(\"train_df\")\nprint(repr(train_df.head(5)))","metadata":{"execution":{"iopub.status.busy":"2022-04-15T18:49:45.610333Z","iopub.execute_input":"2022-04-15T18:49:45.610811Z","iopub.status.idle":"2022-04-15T18:49:45.640486Z","shell.execute_reply.started":"2022-04-15T18:49:45.610764Z","shell.execute_reply":"2022-04-15T18:49:45.63962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using range 10 because they have 10 different cases\nfor i in range(10):\n    print(f\"Case {i} trainning: {len(set(get_training_patient_note_numbers(i)))}\")\n    print(f\"Case {i} total    : {len(set(get_all_patient_note_numbers(i)))}\")\n    print(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-04-15T18:49:45.641699Z","iopub.execute_input":"2022-04-15T18:49:45.641916Z","iopub.status.idle":"2022-04-15T18:49:45.69031Z","shell.execute_reply.started":"2022-04-15T18:49:45.64189Z","shell.execute_reply":"2022-04-15T18:49:45.688638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing Entry Data","metadata":{}},{"cell_type":"code","source":"def preprocessing(X_batch):\n    X_out_batch = tf.strings.lower(X_batch)\n#     X_out_batch = tf.strings.regex_replace(X_out_batch, r'\\b(' + r'|'.join(stopwords.words('english')) + r')\\b\\s*',\"\")\n    X_out_batch = tf.strings.regex_replace(X_out_batch, b\"\\n\\r\", b\" \")\n    X_out_batch = tf.strings.regex_replace(X_out_batch, b\"\\r\\n\", b\" \")\n    X_out_batch = tf.strings.regex_replace(X_out_batch, b\"[^a-zA-Z0-9-']\", b\" \")\n    X_out_batch = tf.strings.regex_replace(X_out_batch, b\"-\", b\" - \")\n    X_out_batch = tf.strings.split(X_out_batch)\n    return X_out_batch","metadata":{"execution":{"iopub.status.busy":"2022-04-15T19:00:52.846895Z","iopub.execute_input":"2022-04-15T19:00:52.84775Z","iopub.status.idle":"2022-04-15T19:00:52.858331Z","shell.execute_reply.started":"2022-04-15T19:00:52.84768Z","shell.execute_reply":"2022-04-15T19:00:52.857493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating Our Vocabularies\n \nIn order to create a bag of words, we will use all the entry dataset. ","metadata":{}},{"cell_type":"markdown","source":"## From patient_note_df","metadata":{}},{"cell_type":"code","source":"from collections import Counter\nfrom IPython.display import clear_output\n\npatient_note_number_fail = []\n\ntotal_vocabulary = Counter()\nfor case_number in range(10):\n    case_vocabulary = Counter()\n    case_patient_note_numbers = get_all_patient_note_numbers(case_number)\n    case_patient_note_numbers_len = len(case_patient_note_numbers)\n    \n    for pn_count, pacient_note_number in enumerate(case_patient_note_numbers):\n        try:\n            X = take_pacient_note(pacient_note_number)\n            case_vocabulary.update(preprocessing(X).numpy())\n            total_vocabulary.update(preprocessing(X).numpy())\n        except:\n            patient_note_number_fail.append(pacient_note_number)\n            continue\n        finally:\n            clear_output(wait=True)\n            print(f\"Case {case_number}: {pn_count} of {case_patient_note_numbers_len} patient note numbers\")\n        \n    case_vocabulary_df = pd.DataFrame.from_dict(case_vocabulary, orient='index').reset_index()\n    case_vocabulary_df = case_vocabulary_df.rename(columns={'index':'word',0:'count'})\n    case_vocabulary_df.to_csv(f\"/kaggle/working/case_vocabulary_{case_number}.csv\")\n\ntotal_vocabulary_df = pd.DataFrame.from_dict(total_vocabulary, orient='index').reset_index()\ntotal_vocabulary_df = total_vocabulary_df.rename(columns={'index':'word',0:'count'})\ntotal_vocabulary_df.to_csv(f\"/kaggle/working/total_vocabulary.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-04-15T18:28:25.938242Z","iopub.execute_input":"2022-04-15T18:28:25.939104Z","iopub.status.idle":"2022-04-15T18:29:06.794703Z","shell.execute_reply.started":"2022-04-15T18:28:25.939064Z","shell.execute_reply":"2022-04-15T18:29:06.793514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Failed note numbers: {patient_note_number_fail}\")","metadata":{"execution":{"iopub.status.busy":"2022-04-15T18:27:30.823146Z","iopub.status.idle":"2022-04-15T18:27:30.823518Z","shell.execute_reply.started":"2022-04-15T18:27:30.823316Z","shell.execute_reply":"2022-04-15T18:27:30.82334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## From train_df","metadata":{}},{"cell_type":"code","source":"from collections import Counter\nfrom IPython.display import clear_output\n\ntotal_annotation_vocabulary = Counter()\nfor case_number in range(10):\n    case_annotation_vocabulary = Counter()\n    case_annotations = get_all_training_annotations(case_number)\n    case_annotations_len = len(case_annotations)\n    \n    for ca_count, case_annotation in enumerate(case_annotations):\n        for annotation in case_annotation:\n            try:\n                case_annotation_vocabulary.update(preprocessing(annotation).numpy())\n                total_annotation_vocabulary.update(preprocessing(annotation).numpy())\n            except:\n                continue\n            finally:\n                clear_output(wait=True)\n                print(f\"Case {case_number}: {ca_count} of {case_annotations_len} case annotation numbers\")\n        \n    case_annotation_vocabulary_df = pd.DataFrame.from_dict(case_annotation_vocabulary, orient='index').reset_index()\n    case_annotation_vocabulary_df = case_annotation_vocabulary_df.rename(columns={'index':'word',0:'count'})\n    case_annotation_vocabulary_df.to_csv(f\"/kaggle/working/case_annotation_vocabulary_{case_number}.csv\")\n\ntotal_annotation_vocabulary_df = pd.DataFrame.from_dict(total_annotation_vocabulary, orient='index').reset_index()\ntotal_annotation_vocabulary_df = total_annotation_vocabulary_df.rename(columns={'index':'word',0:'count'})\ntotal_annotation_vocabulary_df.to_csv(f\"/kaggle/working/total_annotation_vocabulary.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-04-15T18:29:35.447738Z","iopub.execute_input":"2022-04-15T18:29:35.448053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Looking Our Vocabulary","metadata":{}},{"cell_type":"code","source":"len(total_vocabulary)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T18:27:30.827013Z","iopub.status.idle":"2022-04-15T18:27:30.827333Z","shell.execute_reply.started":"2022-04-15T18:27:30.827167Z","shell.execute_reply":"2022-04-15T18:27:30.827184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_vocabulary.most_common()[:50]","metadata":{"execution":{"iopub.status.busy":"2022-04-15T18:27:30.828048Z","iopub.status.idle":"2022-04-15T18:27:30.828389Z","shell.execute_reply.started":"2022-04-15T18:27:30.828215Z","shell.execute_reply":"2022-04-15T18:27:30.828239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(total_annotation_vocabulary)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T18:27:30.829387Z","iopub.status.idle":"2022-04-15T18:27:30.829725Z","shell.execute_reply.started":"2022-04-15T18:27:30.829554Z","shell.execute_reply":"2022-04-15T18:27:30.829572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_annotation_vocabulary.most_common()[:50]","metadata":{"execution":{"iopub.status.busy":"2022-04-15T18:27:30.831404Z","iopub.status.idle":"2022-04-15T18:27:30.831746Z","shell.execute_reply.started":"2022-04-15T18:27:30.831556Z","shell.execute_reply":"2022-04-15T18:27:30.831574Z"},"trusted":true},"execution_count":null,"outputs":[]}]}