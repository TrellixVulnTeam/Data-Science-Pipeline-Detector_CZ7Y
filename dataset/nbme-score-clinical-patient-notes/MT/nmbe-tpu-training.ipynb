{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"I hope this notebook would be helpful.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"- By default, transformers ver is 4.5.1 when we turn TPU acceralation on.\n- This notebook itself successfully works even if using the old version.\n- But upgrating it to 4.16.2 is very important regarding how to treat the whitespace, which is mentioned in [disscussion](https://www.kaggle.com/c/nbme-score-clinical-patient-notes/discussion/310897)","metadata":{}},{"cell_type":"code","source":"!pip install transformers==4.16.2","metadata":{"execution":{"iopub.status.busy":"2022-03-21T02:33:46.30878Z","iopub.execute_input":"2022-03-21T02:33:46.309353Z","iopub.status.idle":"2022-03-21T02:34:01.0192Z","shell.execute_reply.started":"2022-03-21T02:33:46.309237Z","shell.execute_reply":"2022-03-21T02:34:01.018368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install tokenizers==0.11.0","metadata":{"execution":{"iopub.status.busy":"2022-03-21T02:34:01.021156Z","iopub.execute_input":"2022-03-21T02:34:01.021445Z","iopub.status.idle":"2022-03-21T02:34:10.544307Z","shell.execute_reply.started":"2022-03-21T02:34:01.021412Z","shell.execute_reply":"2022-03-21T02:34:10.543346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import os\nimport gc\nimport re\nimport ast\nimport sys\nimport copy\nimport json\nimport time\nimport math\nimport string\nimport pickle\nimport random\nimport joblib\nimport itertools\nimport typing\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n\nimport tensorflow as tf\nimport tensorflow_addons as tfa\n\nimport transformers\nfrom transformers import *\n\nprint('TF version,', tf.__version__)\nprint('transformers version,', transformers.__version__)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T02:34:10.546429Z","iopub.execute_input":"2022-03-21T02:34:10.546754Z","iopub.status.idle":"2022-03-21T02:34:21.43262Z","shell.execute_reply.started":"2022-03-21T02:34:10.546711Z","shell.execute_reply":"2022-03-21T02:34:21.431846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Configuration","metadata":{}},{"cell_type":"code","source":"MODEL_NAME = ['roberta-large', 'microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract', 'dmis-lab/biobert-large-cased-v1.1']\nMAX_LEN = 512\n\nfolds = 5\nepochs = 7\nseed = 660\nlr = 2e-5\nmin_lr = 1e-6\nbatch_size_single = 4\nnum_warmup_steps = 0\nnum_cycles = 0.5","metadata":{"execution":{"iopub.status.busy":"2022-03-21T02:34:21.435405Z","iopub.execute_input":"2022-03-21T02:34:21.436108Z","iopub.status.idle":"2022-03-21T02:34:21.441867Z","shell.execute_reply.started":"2022-03-21T02:34:21.436059Z","shell.execute_reply":"2022-03-21T02:34:21.440893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def hardware_config() -> tuple:\n    \"\"\"Return strategy and batch size according to hardware state\"\"\"\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        tf.config.experimental_connect_to_cluster(tpu)\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n        batch_size = batch_size_single * strategy.num_replicas_in_sync\n    except Exception:\n        tpu = None\n        strategy = tf.distribute.get_strategy()\n        batch_size = 4\n\n    return strategy, tpu, batch_size\n\nstrategy, TPU, batch_size = hardware_config()\nprint('batch size, ', batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T02:34:21.443584Z","iopub.execute_input":"2022-03-21T02:34:21.443903Z","iopub.status.idle":"2022-03-21T02:34:27.145972Z","shell.execute_reply.started":"2022-03-21T02:34:21.443863Z","shell.execute_reply":"2022-03-21T02:34:27.145008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed=42):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    tf.random.set_seed(seed)\nseed_everything(seed)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T02:34:27.147197Z","iopub.execute_input":"2022-03-21T02:34:27.147559Z","iopub.status.idle":"2022-03-21T02:34:27.153406Z","shell.execute_reply.started":"2022-03-21T02:34:27.147524Z","shell.execute_reply":"2022-03-21T02:34:27.15252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Train","metadata":{}},{"cell_type":"code","source":"def process_feature_text(text):\n    text = re.sub('I-year', '1-year', text)\n    text = re.sub('-OR-', \" or \", text)\n    text = re.sub('-', ' ', text)\n    return text\n\ndef clean_spaces(txt):\n    txt = re.sub('\\n', ' ', txt)\n    txt = re.sub('\\t', ' ', txt)\n    txt = re.sub('\\r', ' ', txt)\n#     txt = re.sub(r'\\s+', ' ', txt)\n    return txt","metadata":{"execution":{"iopub.status.busy":"2022-03-21T02:34:27.154876Z","iopub.execute_input":"2022-03-21T02:34:27.155156Z","iopub.status.idle":"2022-03-21T02:34:27.195414Z","shell.execute_reply.started":"2022-03-21T02:34:27.155128Z","shell.execute_reply":"2022-03-21T02:34:27.194537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://www.kaggle.com/yasufuminakama/nbme-deberta-base-baseline-train\ntrain = pd.read_csv('../input/nbme-score-clinical-patient-notes/train.csv')\ntrain['annotation'] = train['annotation'].apply(ast.literal_eval)\ntrain['location'] = train['location'].apply(ast.literal_eval)\nfeatures = pd.read_csv('../input/nbme-score-clinical-patient-notes/features.csv')\nfeatures.loc[27, 'feature_text'] = \"Last-Pap-smear-1-year-ago\"\npatient_notes = pd.read_csv('../input/nbme-score-clinical-patient-notes/patient_notes.csv')\n\nprint(f\"train.shape: {train.shape}\")\ndisplay(train.head(10))\nprint(f\"features.shape: {features.shape}\")\ndisplay(features.head(10))\nprint(f\"patient_notes.shape: {patient_notes.shape}\")\ndisplay(patient_notes.head(10))","metadata":{"execution":{"iopub.status.busy":"2022-03-21T02:34:27.196558Z","iopub.execute_input":"2022-03-21T02:34:27.197275Z","iopub.status.idle":"2022-03-21T02:34:28.245211Z","shell.execute_reply.started":"2022-03-21T02:34:27.197237Z","shell.execute_reply":"2022-03-21T02:34:28.244373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.merge(features, on=['feature_num', 'case_num'], how='left')\ntrain = train.merge(patient_notes, on=['pn_num', 'case_num'], how='left')\ndisplay(train.head())","metadata":{"execution":{"iopub.status.busy":"2022-03-21T02:34:28.246785Z","iopub.execute_input":"2022-03-21T02:34:28.24707Z","iopub.status.idle":"2022-03-21T02:34:28.301982Z","shell.execute_reply.started":"2022-03-21T02:34:28.24704Z","shell.execute_reply":"2022-03-21T02:34:28.300828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://www.kaggle.com/code/yasufuminakama/nbme-deberta-base-baseline-train/notebook\n# incorrect annotation\ntrain.loc[338, 'annotation'] = ast.literal_eval('[[\"father heart attack\"]]')\ntrain.loc[338, 'location'] = ast.literal_eval('[[\"764 783\"]]')\n\ntrain.loc[621, 'annotation'] = ast.literal_eval('[[\"for the last 2-3 months\"]]')\ntrain.loc[621, 'location'] = ast.literal_eval('[[\"77 100\"]]')\n\ntrain.loc[655, 'annotation'] = ast.literal_eval('[[\"no heat intolerance\"], [\"no cold intolerance\"]]')\ntrain.loc[655, 'location'] = ast.literal_eval('[[\"285 292;301 312\"], [\"285 287;296 312\"]]')\n\ntrain.loc[1262, 'annotation'] = ast.literal_eval('[[\"mother thyroid problem\"]]')\ntrain.loc[1262, 'location'] = ast.literal_eval('[[\"551 557;565 580\"]]')\n\ntrain.loc[1265, 'annotation'] = ast.literal_eval('[[\\'felt like he was going to \"pass out\"\\']]')\ntrain.loc[1265, 'location'] = ast.literal_eval('[[\"131 135;181 212\"]]')\n\ntrain.loc[1396, 'annotation'] = ast.literal_eval('[[\"stool , with no blood\"]]')\ntrain.loc[1396, 'location'] = ast.literal_eval('[[\"259 280\"]]')\n\ntrain.loc[1591, 'annotation'] = ast.literal_eval('[[\"diarrhoe non blooody\"]]')\ntrain.loc[1591, 'location'] = ast.literal_eval('[[\"176 184;201 212\"]]')\n\ntrain.loc[1615, 'annotation'] = ast.literal_eval('[[\"diarrhea for last 2-3 days\"]]')\ntrain.loc[1615, 'location'] = ast.literal_eval('[[\"249 257;271 288\"]]')\n\ntrain.loc[1664, 'annotation'] = ast.literal_eval('[[\"no vaginal discharge\"]]')\ntrain.loc[1664, 'location'] = ast.literal_eval('[[\"822 824;907 924\"]]')\n\ntrain.loc[1714, 'annotation'] = ast.literal_eval('[[\"started about 8-10 hours ago\"]]')\ntrain.loc[1714, 'location'] = ast.literal_eval('[[\"101 129\"]]')\n\ntrain.loc[1929, 'annotation'] = ast.literal_eval('[[\"no blood in the stool\"]]')\ntrain.loc[1929, 'location'] = ast.literal_eval('[[\"531 539;549 561\"]]')\n\ntrain.loc[2134, 'annotation'] = ast.literal_eval('[[\"last sexually active 9 months ago\"]]')\ntrain.loc[2134, 'location'] = ast.literal_eval('[[\"540 560;581 593\"]]')\n\ntrain.loc[2191, 'annotation'] = ast.literal_eval('[[\"right lower quadrant pain\"]]')\ntrain.loc[2191, 'location'] = ast.literal_eval('[[\"32 57\"]]')\n\ntrain.loc[2553, 'annotation'] = ast.literal_eval('[[\"diarrhoea no blood\"]]')\ntrain.loc[2553, 'location'] = ast.literal_eval('[[\"308 317;376 384\"]]')\n\ntrain.loc[3124, 'annotation'] = ast.literal_eval('[[\"sweating\"]]')\ntrain.loc[3124, 'location'] = ast.literal_eval('[[\"549 557\"]]')\n\ntrain.loc[3858, 'annotation'] = ast.literal_eval('[[\"previously as regular\"], [\"previously eveyr 28-29 days\"], [\"previously lasting 5 days\"], [\"previously regular flow\"]]')\ntrain.loc[3858, 'location'] = ast.literal_eval('[[\"102 123\"], [\"102 112;125 141\"], [\"102 112;143 157\"], [\"102 112;159 171\"]]')\n\ntrain.loc[4373, 'annotation'] = ast.literal_eval('[[\"for 2 months\"]]')\ntrain.loc[4373, 'location'] = ast.literal_eval('[[\"33 45\"]]')\n\ntrain.loc[4763, 'annotation'] = ast.literal_eval('[[\"35 year old\"]]')\ntrain.loc[4763, 'location'] = ast.literal_eval('[[\"5 16\"]]')\n\ntrain.loc[4782, 'annotation'] = ast.literal_eval('[[\"darker brown stools\"]]')\ntrain.loc[4782, 'location'] = ast.literal_eval('[[\"175 194\"]]')\n\ntrain.loc[4908, 'annotation'] = ast.literal_eval('[[\"uncle with peptic ulcer\"]]')\ntrain.loc[4908, 'location'] = ast.literal_eval('[[\"700 723\"]]')\n\ntrain.loc[6016, 'annotation'] = ast.literal_eval('[[\"difficulty falling asleep\"]]')\ntrain.loc[6016, 'location'] = ast.literal_eval('[[\"225 250\"]]')\n\ntrain.loc[6192, 'annotation'] = ast.literal_eval('[[\"helps to take care of aging mother and in-laws\"]]')\ntrain.loc[6192, 'location'] = ast.literal_eval('[[\"197 218;236 260\"]]')\n\ntrain.loc[6380, 'annotation'] = ast.literal_eval('[[\"No hair changes\"], [\"No skin changes\"], [\"No GI changes\"], [\"No palpitations\"], [\"No excessive sweating\"]]')\ntrain.loc[6380, 'location'] = ast.literal_eval('[[\"480 482;507 519\"], [\"480 482;499 503;512 519\"], [\"480 482;521 531\"], [\"480 482;533 545\"], [\"480 482;564 582\"]]')\n\ntrain.loc[6562, 'annotation'] = ast.literal_eval('[[\"stressed due to taking care of her mother\"], [\"stressed due to taking care of husbands parents\"]]')\ntrain.loc[6562, 'location'] = ast.literal_eval('[[\"290 320;327 337\"], [\"290 320;342 358\"]]')\n\ntrain.loc[6862, 'annotation'] = ast.literal_eval('[[\"stressor taking care of many sick family members\"]]')\ntrain.loc[6862, 'location'] = ast.literal_eval('[[\"288 296;324 363\"]]')\n\ntrain.loc[7022, 'annotation'] = ast.literal_eval('[[\"heart started racing and felt numbness for the 1st time in her finger tips\"]]')\ntrain.loc[7022, 'location'] = ast.literal_eval('[[\"108 182\"]]')\n\ntrain.loc[7422, 'annotation'] = ast.literal_eval('[[\"first started 5 yrs\"]]')\ntrain.loc[7422, 'location'] = ast.literal_eval('[[\"102 121\"]]')\n\ntrain.loc[8876, 'annotation'] = ast.literal_eval('[[\"No shortness of breath\"]]')\ntrain.loc[8876, 'location'] = ast.literal_eval('[[\"481 483;533 552\"]]')\n\ntrain.loc[9027, 'annotation'] = ast.literal_eval('[[\"recent URI\"], [\"nasal stuffines, rhinorrhea, for 3-4 days\"]]')\ntrain.loc[9027, 'location'] = ast.literal_eval('[[\"92 102\"], [\"123 164\"]]')\n\ntrain.loc[9938, 'annotation'] = ast.literal_eval('[[\"irregularity with her cycles\"], [\"heavier bleeding\"], [\"changes her pad every couple hours\"]]')\ntrain.loc[9938, 'location'] = ast.literal_eval('[[\"89 117\"], [\"122 138\"], [\"368 402\"]]')\n\ntrain.loc[9973, 'annotation'] = ast.literal_eval('[[\"gaining 10-15 lbs\"]]')\ntrain.loc[9973, 'location'] = ast.literal_eval('[[\"344 361\"]]')\n\ntrain.loc[10513, 'annotation'] = ast.literal_eval('[[\"weight gain\"], [\"gain of 10-16lbs\"]]')\ntrain.loc[10513, 'location'] = ast.literal_eval('[[\"600 611\"], [\"607 623\"]]')\n\ntrain.loc[11551, 'annotation'] = ast.literal_eval('[[\"seeing her son knows are not real\"]]')\ntrain.loc[11551, 'location'] = ast.literal_eval('[[\"386 400;443 461\"]]')\n\ntrain.loc[11677, 'annotation'] = ast.literal_eval('[[\"saw him once in the kitchen after he died\"]]')\ntrain.loc[11677, 'location'] = ast.literal_eval('[[\"160 201\"]]')\n\ntrain.loc[12124, 'annotation'] = ast.literal_eval('[[\"tried Ambien but it didnt work\"]]')\ntrain.loc[12124, 'location'] = ast.literal_eval('[[\"325 337;349 366\"]]')\n\ntrain.loc[12279, 'annotation'] = ast.literal_eval('[[\"heard what she described as a party later than evening these things did not actually happen\"]]')\ntrain.loc[12279, 'location'] = ast.literal_eval('[[\"405 459;488 524\"]]')\n\ntrain.loc[12289, 'annotation'] = ast.literal_eval('[[\"experienced seeing her son at the kitchen table these things did not actually happen\"]]')\ntrain.loc[12289, 'location'] = ast.literal_eval('[[\"353 400;488 524\"]]')\n\ntrain.loc[13238, 'annotation'] = ast.literal_eval('[[\"SCRACHY THROAT\"], [\"RUNNY NOSE\"]]')\ntrain.loc[13238, 'location'] = ast.literal_eval('[[\"293 307\"], [\"321 331\"]]')\n\ntrain.loc[13297, 'annotation'] = ast.literal_eval('[[\"without improvement when taking tylenol\"], [\"without improvement when taking ibuprofen\"]]')\ntrain.loc[13297, 'location'] = ast.literal_eval('[[\"182 221\"], [\"182 213;225 234\"]]')\n\ntrain.loc[13299, 'annotation'] = ast.literal_eval('[[\"yesterday\"], [\"yesterday\"]]')\ntrain.loc[13299, 'location'] = ast.literal_eval('[[\"79 88\"], [\"409 418\"]]')\n\ntrain.loc[13845, 'annotation'] = ast.literal_eval('[[\"headache global\"], [\"headache throughout her head\"]]')\ntrain.loc[13845, 'location'] = ast.literal_eval('[[\"86 94;230 236\"], [\"86 94;237 256\"]]')\n\ntrain.loc[14083, 'annotation'] = ast.literal_eval('[[\"headache generalized in her head\"]]')\ntrain.loc[14083, 'location'] = ast.literal_eval('[[\"56 64;156 179\"]]')","metadata":{"execution":{"iopub.status.busy":"2022-03-21T02:34:28.306448Z","iopub.execute_input":"2022-03-21T02:34:28.306708Z","iopub.status.idle":"2022-03-21T02:34:28.416007Z","shell.execute_reply.started":"2022-03-21T02:34:28.30668Z","shell.execute_reply":"2022-03-21T02:34:28.41527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://www.kaggle.com/code/theoviel/roberta-strikes-back/notebook\ntrain['feature_text'] = train['feature_text'].apply(process_feature_text)\ntrain['feature_text'] = train['feature_text'].apply(clean_spaces)\ntrain['clean_text'] = train['pn_history'].apply(clean_spaces)\ntrain['pn_history'] = train['pn_history'].apply(lambda x: x.strip())","metadata":{"execution":{"iopub.status.busy":"2022-03-21T02:34:28.416987Z","iopub.execute_input":"2022-03-21T02:34:28.417526Z","iopub.status.idle":"2022-03-21T02:34:28.661118Z","shell.execute_reply.started":"2022-03-21T02:34:28.417494Z","shell.execute_reply":"2022-03-21T02:34:28.660226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['annotation_length'] = train['annotation'].apply(len)\ndisplay(train['annotation_length'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-03-21T02:34:28.662595Z","iopub.execute_input":"2022-03-21T02:34:28.663062Z","iopub.status.idle":"2022-03-21T02:34:28.680473Z","shell.execute_reply.started":"2022-03-21T02:34:28.66303Z","shell.execute_reply":"2022-03-21T02:34:28.679449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CV split","metadata":{}},{"cell_type":"code","source":"Fold = GroupKFold(n_splits=folds)\ngroups = train['pn_num'].values\nfor n, (train_index, val_index) in enumerate(Fold.split(train, train['location'], groups)):\n    train.loc[val_index, 'fold'] = int(n)\ntrain['fold'] = train['fold'].astype(int)\ndisplay(train.groupby('fold').size())","metadata":{"execution":{"iopub.status.busy":"2022-03-21T02:34:28.681656Z","iopub.execute_input":"2022-03-21T02:34:28.681909Z","iopub.status.idle":"2022-03-21T02:34:28.707275Z","shell.execute_reply.started":"2022-03-21T02:34:28.681881Z","shell.execute_reply":"2022-03-21T02:34:28.706339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Helper Functions","metadata":{}},{"cell_type":"code","source":"# From https://www.kaggle.com/theoviel/evaluation-metric-folds-baseline\n\ndef micro_f1(preds, truths):\n    \"\"\"\n    Micro f1 on binary arrays.\n\n    Args:\n        preds (list of lists of ints): Predictions.\n        truths (list of lists of ints): Ground truths.\n\n    Returns:\n        float: f1 score.\n    \"\"\"\n    # Micro : aggregating over all instances\n    preds = np.concatenate(preds)\n    truths = np.concatenate(truths)\n    return f1_score(truths, preds)\n\n\ndef spans_to_binary(spans, length=None):\n    \"\"\"\n    Converts spans to a binary array indicating whether each character is in the span.\n\n    Args:\n        spans (list of lists of two ints): Spans.\n\n    Returns:\n        np array [length]: Binarized spans.\n    \"\"\"\n    length = np.max(spans) if length is None else length\n    binary = np.zeros(length)\n    for start, end in spans:\n        binary[start:end] = 1\n    return binary\n\n\ndef span_micro_f1(preds, truths):\n    \"\"\"\n    Micro f1 on spans.\n\n    Args:\n        preds (list of lists of two ints): Prediction spans.\n        truths (list of lists of two ints): Ground truth spans.\n\n    Returns:\n        float: f1 score.\n    \"\"\"\n    bin_preds = []\n    bin_truths = []\n    for pred, truth in zip(preds, truths):\n        if not len(pred) and not len(truth):\n            continue\n        length = max(np.max(pred) if len(pred) else 0, np.max(truth) if len(truth) else 0)\n        bin_preds.append(spans_to_binary(pred, length))\n        bin_truths.append(spans_to_binary(truth, length))\n    return micro_f1(bin_preds, bin_truths)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-03-21T02:34:28.708486Z","iopub.execute_input":"2022-03-21T02:34:28.708869Z","iopub.status.idle":"2022-03-21T02:34:28.720208Z","shell.execute_reply.started":"2022-03-21T02:34:28.708835Z","shell.execute_reply":"2022-03-21T02:34:28.718887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_char_probs(texts, predictions, tokenizer):\n    results = [np.zeros(len(t)) for t in texts]\n    for i, (text, prediction) in enumerate(zip(texts, predictions)):\n        encoded = tokenizer(text, \n                            add_special_tokens=True,\n                            return_offsets_mapping=True)\n        for idx, (offset_mapping, pred) in enumerate(zip(encoded['offset_mapping'][1:], prediction[1:])):\n            start = offset_mapping[0]\n            end = offset_mapping[1]\n            results[i][start:end] = pred\n            if len(text) == end: break\n    return results\n\ndef get_results(char_probs, th=0.5):\n    results = []\n    for char_prob in char_probs:\n        result = np.where(char_prob >= th)[0] + 1\n        result = [list(g) for _, g in itertools.groupby(result, key=lambda n, c=itertools.count(): n - next(c))]\n        result = [f\"{min(r)} {max(r)}\" for r in result]\n        result = \";\".join(result)\n        results.append(result)\n    return results\n\ndef get_predictions(results):\n    predictions = []\n    for result in results:\n        prediction = []\n        if result != \"\":\n            for loc in [s.split() for s in result.split(';')]:\n                start, end = int(loc[0]), int(loc[1])\n                prediction.append([start, end])\n        predictions.append(prediction)\n    return predictions","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-03-21T02:34:28.722169Z","iopub.execute_input":"2022-03-21T02:34:28.722903Z","iopub.status.idle":"2022-03-21T02:34:28.735689Z","shell.execute_reply.started":"2022-03-21T02:34:28.722867Z","shell.execute_reply":"2022-03-21T02:34:28.734899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_score(y_true, y_pred):\n    score = span_micro_f1(y_true, y_pred)\n    return score","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-03-21T02:34:28.736986Z","iopub.execute_input":"2022-03-21T02:34:28.737222Z","iopub.status.idle":"2022-03-21T02:34:28.748794Z","shell.execute_reply.started":"2022-03-21T02:34:28.737197Z","shell.execute_reply":"2022-03-21T02:34:28.748068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_labels_for_scoring(df):\n    # example: ['0 1', '3 4'] -> ['0 1; 3 4']\n    df['location_for_create_labels'] = [ast.literal_eval(f'[]')] * len(df)\n    for i in range(len(df)):\n        lst = df.loc[i, 'location']\n        if lst:\n            new_lst = ';'.join(lst)\n            df.loc[i, 'location_for_create_labels'] = ast.literal_eval(f'[[\"{new_lst}\"]]')\n    # create labels\n    truths = []\n    for location_list in df['location_for_create_labels'].values:\n        truth = []\n        if len(location_list) > 0:\n            location = location_list[0]\n            for loc in [s.split() for s in location.split(';')]:\n                start, end = int(loc[0]), int(loc[1])\n                truth.append([start, end])\n        truths.append(truth)\n    return truths","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-03-21T02:34:28.750079Z","iopub.execute_input":"2022-03-21T02:34:28.750367Z","iopub.status.idle":"2022-03-21T02:34:28.760848Z","shell.execute_reply.started":"2022-03-21T02:34:28.750328Z","shell.execute_reply":"2022-03-21T02:34:28.760072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_dataset(\n    input_ids: np.array,\n    attention_mask: np.array,\n    labels: typing.Optional[np.array] = None,\n    ordered: bool = False,\n    repeated: bool = False,\n    drop_remainder = True\n) -> tf.data.Dataset:\n    \"\"\"Return batched and prefetched dataset\"\"\"\n    if labels is not None:\n        dataset = tf.data.Dataset.from_tensor_slices(\n            ({\"input_ids\": input_ids, \"attention_mask\": attention_mask}, labels)\n        )\n    else:\n        dataset = tf.data.Dataset.from_tensor_slices(\n            {\"input_ids\": input_ids, \"attention_mask\": attention_mask}\n        )\n\n    if repeated:\n        dataset = dataset.repeat()\n    if not ordered:\n        dataset = dataset.shuffle(1024)\n    if drop_remainder:\n        dataset = dataset.batch(batch_size, drop_remainder=True)\n    else:\n        dataset = dataset.batch(batch_size)\n    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n\n    return dataset","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-03-21T02:34:28.762317Z","iopub.execute_input":"2022-03-21T02:34:28.762562Z","iopub.status.idle":"2022-03-21T02:34:28.774819Z","shell.execute_reply.started":"2022-03-21T02:34:28.762529Z","shell.execute_reply":"2022-03-21T02:34:28.774148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomNonPaddingTokenLoss(tf.keras.losses.Loss):\n    def __init__(self, name=\"custom_ner_loss\"):\n        super().__init__(name=name)\n\n    def call(self, y_true, y_pred):\n        loss_fn = tf.keras.losses.BinaryCrossentropy(\n            from_logits=False, reduction=tf.keras.losses.Reduction.NONE\n        )\n        active_loss = tf.reshape(y_true, (-1,)) != -1\n        reduced_pred = tf.boolean_mask(tf.reshape(y_pred, (-1,)), active_loss)\n        labels = tf.boolean_mask(tf.reshape(y_true, (-1,)), active_loss)\n#         loss = loss_fn(y_true, y_pred)\n#         mask = tf.cast((y_true >= 0), dtype=tf.float32)\n#         loss = loss * mask\n        return loss_fn(labels, reduced_pred)#tf.reduce_sum(loss) / tf.reduce_sum(mask)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-03-21T02:34:28.776267Z","iopub.execute_input":"2022-03-21T02:34:28.7766Z","iopub.status.idle":"2022-03-21T02:34:28.787184Z","shell.execute_reply.started":"2022-03-21T02:34:28.776559Z","shell.execute_reply":"2022-03-21T02:34:28.786391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class F1Callback(tf.keras.callbacks.Callback):\n    def __init__(self, model, val_dataset, val_texts, val_labels, tokenizer, file_name):\n        self.model = model\n        self.val_dataset = val_dataset\n        self.valid_texts = val_texts\n        self.valid_labels = val_labels\n        self.tokenizer = tokenizer\n        self.best_f1 = 0\n        self.file_name = file_name\n\n    def on_epoch_end(self, epoch, logs):\n        pred = self.model.predict(self.val_dataset)\n        pred = np.squeeze(pred)\n        # scoring\n        char_probs = get_char_probs(self.valid_texts, pred, self.tokenizer)\n        results = get_results(char_probs, th=0.5)\n        preds = get_predictions(results)\n        score = get_score(self.valid_labels, preds)\n        \n        print(\"f1_val =\", score)\n        \n        if self.best_f1 < score:\n            self.best_f1 = score\n            self.model.save_weights(self.file_name, save_format='h5')","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-03-21T02:34:28.788377Z","iopub.execute_input":"2022-03-21T02:34:28.788694Z","iopub.status.idle":"2022-03-21T02:34:28.804815Z","shell.execute_reply.started":"2022-03-21T02:34:28.788657Z","shell.execute_reply":"2022-03-21T02:34:28.803679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_lr(epoch, lr, num_warmup_steps=num_warmup_steps, num_training_steps=epochs):\n    if epoch < num_warmup_steps:\n        return float(epoch) / float(max(1, num_warmup_steps)) * lr\n    progress = float(epoch - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n    return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))) * lr","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-03-21T02:34:28.806278Z","iopub.execute_input":"2022-03-21T02:34:28.806714Z","iopub.status.idle":"2022-03-21T02:34:28.814807Z","shell.execute_reply.started":"2022-03-21T02:34:28.806667Z","shell.execute_reply":"2022-03-21T02:34:28.813737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# RoBerta","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME[0], trim_offsets=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T02:34:28.816013Z","iopub.execute_input":"2022-03-21T02:34:28.816252Z","iopub.status.idle":"2022-03-21T02:34:31.989876Z","shell.execute_reply.started":"2022-03-21T02:34:28.816225Z","shell.execute_reply":"2022-03-21T02:34:31.988884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_inp_ids = []\ntrain_attn_mask = []\ntrain_labels = []\nfor n, row in tqdm(train.iterrows(), total=len(train)):\n    encoded = tokenizer(row['pn_history'], row['feature_text'],\n                       add_special_tokens=True,\n                           max_length=MAX_LEN,\n                           padding=\"max_length\",\n                           return_offsets_mapping=False)\n    train_inp_ids.append(encoded['input_ids'])\n    train_attn_mask.append(encoded['attention_mask'])\n    encoded = tokenizer(row['pn_history'],\n                       add_special_tokens=True,\n                           max_length=MAX_LEN,\n                           padding=\"max_length\",\n                           return_offsets_mapping=True)\n    offset_mapping = encoded['offset_mapping']\n    ignore_idxes = np.where(np.array(encoded.sequence_ids()) != 0)[0]\n    label = np.zeros(len(offset_mapping))\n    label[ignore_idxes] = -1\n    if row['annotation_length'] != 0:\n        for location in row['location']:\n            for loc in [s.split() for s in location.split(';')]:\n                start_idx = -1\n                end_idx = -1\n                start, end = int(loc[0]), int(loc[1])\n                for idx in range(len(offset_mapping)):\n                    if (start_idx == -1) & (start < offset_mapping[idx][0]):\n                        start_idx = idx - 1\n                    if (end_idx == -1) & (end <= offset_mapping[idx][1]):\n                        end_idx = idx + 1\n                if start_idx == -1:\n                    start_idx = end_idx\n                if (start_idx != -1) & (end_idx != -1):\n                    label[start_idx:end_idx] = 1\n    train_labels.append(label)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T02:34:31.991198Z","iopub.execute_input":"2022-03-21T02:34:31.991447Z","iopub.status.idle":"2022-03-21T02:35:05.646644Z","shell.execute_reply.started":"2022-03-21T02:34:31.991419Z","shell.execute_reply":"2022-03-21T02:35:05.645749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_inp_ids = np.stack(train_inp_ids)\ntrain_attn_mask = np.stack(train_attn_mask)\ntrain_labels = np.stack(train_labels)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T02:35:05.648239Z","iopub.execute_input":"2022-03-21T02:35:05.648552Z","iopub.status.idle":"2022-03-21T02:35:09.122998Z","shell.execute_reply.started":"2022-03-21T02:35:05.648513Z","shell.execute_reply":"2022-03-21T02:35:09.121959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model():\n    config = RobertaConfig.from_pretrained(MODEL_NAME[0])\n    backbone = TFRobertaModel.from_pretrained(MODEL_NAME[0], config=config)\n    \n    input_ids = tf.keras.layers.Input(\n        shape=(MAX_LEN,),\n        dtype=tf.int32,\n        name=\"input_ids\",\n    )\n    attention_mask = tf.keras.layers.Input(\n        shape=(MAX_LEN,),\n        dtype=tf.int32,\n        name=\"attention_mask\",\n    )\n    \n    x = backbone({\n            \"input_ids\": input_ids,\n            \"attention_mask\": attention_mask,\n        })[0]\n    out = tf.keras.layers.Dense(1, activation='sigmoid')(tf.keras.layers.Dropout(0.2)(x))\n    \n    model = tf.keras.Model(inputs=[input_ids,attention_mask], outputs=out)\n    model.compile(optimizer = tfa.optimizers.AdamW(weight_decay=1e-5, learning_rate = lr),\n                  loss = [CustomNonPaddingTokenLoss()])\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-03-21T02:35:09.127392Z","iopub.execute_input":"2022-03-21T02:35:09.127692Z","iopub.status.idle":"2022-03-21T02:35:09.136822Z","shell.execute_reply.started":"2022-03-21T02:35:09.127659Z","shell.execute_reply":"2022-03-21T02:35:09.135714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-03-21T02:35:09.138806Z","iopub.execute_input":"2022-03-21T02:35:09.139527Z","iopub.status.idle":"2022-03-21T02:35:09.44554Z","shell.execute_reply.started":"2022-03-21T02:35:09.139474Z","shell.execute_reply":"2022-03-21T02:35:09.444357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr_callback = tf.keras.callbacks.LearningRateScheduler(get_lr, verbose=1)\nfor fold in range(folds):\n    if fold not in [0,1]:\n        continue\n    print(f'=============== Training fold {fold} =================')\n    train_dataset = get_dataset(\n            input_ids=train_inp_ids[train['fold'].values!=fold],\n            attention_mask=train_attn_mask[train['fold'].values!=fold],\n            labels=train_labels[train['fold'].values!=fold],\n            repeated=True,\n            drop_remainder=True\n        )\n    val_dataset = get_dataset(\n            input_ids=train_inp_ids[train['fold'].values==fold],\n            attention_mask=train_attn_mask[train['fold'].values==fold],\n            labels=train_labels[train['fold']==fold],\n            ordered=True,\n            drop_remainder=True\n        )\n    train_total_steps = sum(train['fold'].values!=fold) // batch_size\n    val_total_steps = sum(train['fold'].values==fold) // batch_size# + int(sum(train['fold'].values==fold) % batch_size > 0)\n    val_labels = create_labels_for_scoring(train[train['fold']==fold].copy().reset_index())\n    val_texts = train[train['fold']==fold]['pn_history'].values\n    resi = len(val_texts) - val_total_steps * batch_size\n    with strategy.scope():\n        model = build_model()\n    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n        f'./best_roberta_large_fold{fold}.h5', save_best_only=True, monitor='val_loss', mode='min', save_weights_only=True)\n    history = model.fit(train_dataset,\n                    validation_data = val_dataset,\n                    callbacks =[checkpoint, F1Callback(model, val_dataset, val_texts[:-resi], val_labels[:-resi], tokenizer,\n                                                      f'./best_f1_roberta_large_fold{fold}.h5'), lr_callback], #[checkpoint, lr_reducer], #[checkpoint, lr_callback],\n                    epochs = epochs,\n                    steps_per_epoch=train_total_steps,\n                    verbose = 1)\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-03-21T02:52:00.990437Z","iopub.execute_input":"2022-03-21T02:52:00.990908Z","iopub.status.idle":"2022-03-21T02:59:26.892142Z","shell.execute_reply.started":"2022-03-21T02:52:00.990867Z","shell.execute_reply":"2022-03-21T02:59:26.890455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PubMedBert","metadata":{}},{"cell_type":"markdown","source":"- change some functions in order to properly handle whitespace","metadata":{}},{"cell_type":"code","source":"def get_char_probs(texts, predictions, tokenizer):\n    results = [np.zeros(len(t)) for t in texts]\n    for i, (text, prediction) in enumerate(zip(texts, predictions)):\n        text = text.replace('\\r\\n', '__')\n        encoded = tokenizer(text, \n                            add_special_tokens=True,\n                            return_offsets_mapping=True)\n        offsets = encoded['offset_mapping']\n        tmp = offsets\n        for n, (start, end) in enumerate(tmp):\n            if n == 0: continue\n            if tmp[n-1][1] == start - 1:\n                offsets[n] = (start - 1, end)\n        for idx, (offset_mapping, pred) in enumerate(zip(offsets[1:], prediction[1:])):\n            start = offset_mapping[0]\n            end = offset_mapping[1]\n            results[i][start:end] = pred\n            if len(text) == end: break\n    return results","metadata":{"execution":{"iopub.status.busy":"2022-03-21T01:44:33.232253Z","iopub.execute_input":"2022-03-21T01:44:33.232574Z","iopub.status.idle":"2022-03-21T01:44:33.243844Z","shell.execute_reply.started":"2022-03-21T01:44:33.232545Z","shell.execute_reply":"2022-03-21T01:44:33.243143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME[1])","metadata":{"execution":{"iopub.status.busy":"2022-03-21T01:45:31.691405Z","iopub.execute_input":"2022-03-21T01:45:31.692356Z","iopub.status.idle":"2022-03-21T01:45:34.257641Z","shell.execute_reply.started":"2022-03-21T01:45:31.692304Z","shell.execute_reply":"2022-03-21T01:45:34.256322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_inp_ids = []\ntrain_attn_mask = []\ntrain_labels = []\nfor n, row in tqdm(train.iterrows(), total=len(train)):\n    text = row['pn_history']\n    text = text.replace('\\r\\n', '__')\n    encoded = tokenizer(text, row['feature_text'],\n                       add_special_tokens=True,\n                           max_length=MAX_LEN,\n                           padding=\"max_length\",\n                           return_offsets_mapping=False)\n    train_inp_ids.append(encoded['input_ids'])\n    train_attn_mask.append(encoded['attention_mask'])\n    encoded = tokenizer(text,\n                       add_special_tokens=True,\n                           max_length=MAX_LEN,\n                           padding=\"max_length\",\n                           return_offsets_mapping=True)\n    offset_mapping = encoded['offset_mapping']\n    tmp = offset_mapping\n    for n, (start, end) in enumerate(tmp):\n        if n == 0: continue\n        if tmp[n-1][1] == start - 1:\n            offset_mapping[n] = (start - 1, end)\n    ignore_idxes = np.where(np.array(encoded.sequence_ids()) != 0)[0]\n    label = np.zeros(len(offset_mapping))\n    label[ignore_idxes] = -1\n    if row['annotation_length'] != 0:\n        for location in row['location']:\n            for loc in [s.split() for s in location.split(';')]:\n                start_idx = -1\n                end_idx = -1\n                start, end = int(loc[0]), int(loc[1])\n                for idx in range(len(offset_mapping)):\n                    if (start_idx == -1) & (start < offset_mapping[idx][0]):\n                        start_idx = idx - 1\n                    if (end_idx == -1) & (end <= offset_mapping[idx][1]):\n                        end_idx = idx + 1\n                if start_idx == -1:\n                    start_idx = end_idx\n                if (start_idx != -1) & (end_idx != -1):\n                    label[start_idx:end_idx] = 1\n    train_labels.append(label)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T01:50:31.557182Z","iopub.execute_input":"2022-03-21T01:50:31.558063Z","iopub.status.idle":"2022-03-21T01:51:11.610677Z","shell.execute_reply.started":"2022-03-21T01:50:31.558014Z","shell.execute_reply":"2022-03-21T01:51:11.608783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_inp_ids = np.stack(train_inp_ids)\ntrain_attn_mask = np.stack(train_attn_mask)\ntrain_labels = np.stack(train_labels)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T01:51:12.447741Z","iopub.execute_input":"2022-03-21T01:51:12.448083Z","iopub.status.idle":"2022-03-21T01:51:15.935637Z","shell.execute_reply.started":"2022-03-21T01:51:12.448048Z","shell.execute_reply":"2022-03-21T01:51:15.934432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model():\n    config = AutoConfig.from_pretrained(MODEL_NAME[1])\n    backbone = TFBertModel.from_pretrained(MODEL_NAME[1], config=config, from_pt=True)\n    \n    input_ids = tf.keras.layers.Input(\n        shape=(MAX_LEN,),\n        dtype=tf.int32,\n        name=\"input_ids\",\n    )\n    attention_mask = tf.keras.layers.Input(\n        shape=(MAX_LEN,),\n        dtype=tf.int32,\n        name=\"attention_mask\",\n    )\n    \n    x = backbone({\n            \"input_ids\": input_ids,\n            \"attention_mask\": attention_mask,\n        })[0]\n    out = tf.keras.layers.Dense(1, activation='sigmoid')(tf.keras.layers.Dropout(0.2)(x))\n    \n    model = tf.keras.Model(inputs=[input_ids,attention_mask], outputs=out)\n    model.compile(optimizer = tfa.optimizers.AdamW(weight_decay=1e-5, learning_rate = lr),\n                  loss = [CustomNonPaddingTokenLoss()])\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-03-21T01:51:17.755755Z","iopub.execute_input":"2022-03-21T01:51:17.757164Z","iopub.status.idle":"2022-03-21T01:51:17.767853Z","shell.execute_reply.started":"2022-03-21T01:51:17.757108Z","shell.execute_reply":"2022-03-21T01:51:17.766773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-03-21T01:51:18.639672Z","iopub.execute_input":"2022-03-21T01:51:18.639991Z","iopub.status.idle":"2022-03-21T01:51:19.14829Z","shell.execute_reply.started":"2022-03-21T01:51:18.639954Z","shell.execute_reply":"2022-03-21T01:51:19.147433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr_callback = tf.keras.callbacks.LearningRateScheduler(get_lr, verbose=1)\nfor fold in range(folds):\n    if fold not in [0,1]:\n        continue\n    print(f'=============== Training fold {fold} =================')\n    train_dataset = get_dataset(\n            input_ids=train_inp_ids[train['fold'].values!=fold],\n            attention_mask=train_attn_mask[train['fold'].values!=fold],\n            labels=train_labels[train['fold'].values!=fold],\n            repeated=True,\n            drop_remainder=True\n        )\n    val_dataset = get_dataset(\n            input_ids=train_inp_ids[train['fold'].values==fold],\n            attention_mask=train_attn_mask[train['fold'].values==fold],\n            labels=train_labels[train['fold']==fold],\n            ordered=True,\n            drop_remainder=True\n        )\n    train_total_steps = sum(train['fold'].values!=fold) // batch_size\n    val_total_steps = sum(train['fold'].values==fold) // batch_size# + int(sum(train['fold'].values==fold) % batch_size > 0)\n    val_labels = create_labels_for_scoring(train[train['fold']==fold].copy().reset_index())\n    val_texts = train[train['fold']==fold]['pn_history'].values\n    resi = len(val_texts) - val_total_steps * batch_size\n    with strategy.scope():\n        model = build_model()\n    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n        f'./best_pubmedbert_fold{fold}.h5', save_best_only=True, monitor='val_loss', mode='min', save_weights_only=True)\n    history = model.fit(train_dataset,\n                    validation_data = val_dataset,\n                    callbacks =[checkpoint, F1Callback(model, val_dataset, val_texts[:-resi], val_labels[:-resi], tokenizer,\n                                                      f'./best_f1_pubmedbert_fold{fold}.h5'), lr_callback], #[checkpoint, lr_reducer], #[checkpoint, lr_callback],\n                    epochs = epochs,\n                    steps_per_epoch=train_total_steps,\n                    verbose = 1)\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-03-21T01:51:19.420552Z","iopub.execute_input":"2022-03-21T01:51:19.420856Z","iopub.status.idle":"2022-03-21T01:58:16.29136Z","shell.execute_reply.started":"2022-03-21T01:51:19.420825Z","shell.execute_reply":"2022-03-21T01:58:16.289943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# bioBert","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME[2], trim_offsets=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T02:03:11.899957Z","iopub.execute_input":"2022-03-21T02:03:11.901202Z","iopub.status.idle":"2022-03-21T02:03:14.411347Z","shell.execute_reply.started":"2022-03-21T02:03:11.901157Z","shell.execute_reply":"2022-03-21T02:03:14.410232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_inp_ids = []\ntrain_attn_mask = []\ntrain_labels = []\nfor n, row in tqdm(train.iterrows(), total=len(train)):\n    text = row['pn_history']\n    text = text.replace('\\r\\n', '__')\n    encoded = tokenizer(text, row['feature_text'],\n                       add_special_tokens=True,\n                           max_length=MAX_LEN,\n                           padding=\"max_length\",\n                           return_offsets_mapping=False)\n    train_inp_ids.append(encoded['input_ids'])\n    train_attn_mask.append(encoded['attention_mask'])\n    encoded = tokenizer(text,\n                       add_special_tokens=True,\n                           max_length=MAX_LEN,\n                           padding=\"max_length\",\n                           return_offsets_mapping=True)\n    offset_mapping = encoded['offset_mapping']\n    tmp = offset_mapping\n    for n, (start, end) in enumerate(tmp):\n        if n == 0: continue\n        if tmp[n-1][1] == start - 1:\n            offset_mapping[n] = (start - 1, end)\n    ignore_idxes = np.where(np.array(encoded.sequence_ids()) != 0)[0]\n    label = np.zeros(len(offset_mapping))\n    label[ignore_idxes] = -1\n    if row['annotation_length'] != 0:\n        for location in row['location']:\n            for loc in [s.split() for s in location.split(';')]:\n                start_idx = -1\n                end_idx = -1\n                start, end = int(loc[0]), int(loc[1])\n                for idx in range(len(offset_mapping)):\n                    if (start_idx == -1) & (start < offset_mapping[idx][0]):\n                        start_idx = idx - 1\n                    if (end_idx == -1) & (end <= offset_mapping[idx][1]):\n                        end_idx = idx + 1\n                if start_idx == -1:\n                    start_idx = end_idx\n                if (start_idx != -1) & (end_idx != -1):\n                    label[start_idx:end_idx] = 1\n    train_labels.append(label)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T02:03:26.269863Z","iopub.execute_input":"2022-03-21T02:03:26.270194Z","iopub.status.idle":"2022-03-21T02:04:06.386834Z","shell.execute_reply.started":"2022-03-21T02:03:26.270162Z","shell.execute_reply":"2022-03-21T02:04:06.385852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_inp_ids = np.stack(train_inp_ids)\ntrain_attn_mask = np.stack(train_attn_mask)\ntrain_labels = np.stack(train_labels)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T02:04:08.397535Z","iopub.execute_input":"2022-03-21T02:04:08.397831Z","iopub.status.idle":"2022-03-21T02:04:11.871922Z","shell.execute_reply.started":"2022-03-21T02:04:08.397802Z","shell.execute_reply":"2022-03-21T02:04:11.871053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model():\n    config = AutoConfig.from_pretrained(MODEL_NAME[2])\n    backbone = TFBertModel.from_pretrained(MODEL_NAME[2], config=config, from_pt=True)\n    \n    input_ids = tf.keras.layers.Input(\n        shape=(MAX_LEN,),\n        dtype=tf.int32,\n        name=\"input_ids\",\n    )\n    attention_mask = tf.keras.layers.Input(\n        shape=(MAX_LEN,),\n        dtype=tf.int32,\n        name=\"attention_mask\",\n    )\n    \n    x = backbone({\n            \"input_ids\": input_ids,\n            \"attention_mask\": attention_mask,\n        })[0]\n    out = tf.keras.layers.Dense(1, activation='sigmoid')(tf.keras.layers.Dropout(0.2)(x))\n    \n    model = tf.keras.Model(inputs=[input_ids,attention_mask], outputs=out)\n    model.compile(optimizer = tfa.optimizers.AdamW(weight_decay=1e-5, learning_rate = lr),\n                  loss = [CustomNonPaddingTokenLoss()])\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-03-21T02:04:11.874751Z","iopub.execute_input":"2022-03-21T02:04:11.875117Z","iopub.status.idle":"2022-03-21T02:04:11.885498Z","shell.execute_reply.started":"2022-03-21T02:04:11.875071Z","shell.execute_reply":"2022-03-21T02:04:11.884455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-03-21T02:04:11.887013Z","iopub.execute_input":"2022-03-21T02:04:11.8876Z","iopub.status.idle":"2022-03-21T02:04:12.550698Z","shell.execute_reply.started":"2022-03-21T02:04:11.887557Z","shell.execute_reply":"2022-03-21T02:04:12.54964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr_callback = tf.keras.callbacks.LearningRateScheduler(get_lr, verbose=1)\nfor fold in range(folds):\n    if fold not in [0,1]:\n        continue\n    print(f'=============== Training fold {fold} =================')\n    train_dataset = get_dataset(\n            input_ids=train_inp_ids[train['fold'].values!=fold],\n            attention_mask=train_attn_mask[train['fold'].values!=fold],\n            labels=train_labels[train['fold'].values!=fold],\n            repeated=True,\n            drop_remainder=True\n        )\n    val_dataset = get_dataset(\n            input_ids=train_inp_ids[train['fold'].values==fold],\n            attention_mask=train_attn_mask[train['fold'].values==fold],\n            labels=train_labels[train['fold']==fold],\n            ordered=True,\n            drop_remainder=True\n        )\n    train_total_steps = sum(train['fold'].values!=fold) // batch_size\n    val_total_steps = sum(train['fold'].values==fold) // batch_size# + int(sum(train['fold'].values==fold) % batch_size > 0)\n    val_labels = create_labels_for_scoring(train[train['fold']==fold].copy().reset_index())\n    val_texts = train[train['fold']==fold]['pn_history'].values\n    resi = len(val_texts) - val_total_steps * batch_size\n    with strategy.scope():\n        model = build_model()\n    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n        f'./best_biobert_fold{fold}.h5', save_best_only=True, monitor='val_loss', mode='min', save_weights_only=True)\n    history = model.fit(train_dataset,\n                    validation_data = val_dataset,\n                    callbacks =[checkpoint, F1Callback(model, val_dataset, val_texts[:-resi], val_labels[:-resi], tokenizer,\n                                                      f'./best_f1_biobert_fold{fold}.h5'), lr_callback], #[checkpoint, lr_reducer], #[checkpoint, lr_callback],\n                    epochs = epochs,\n                    steps_per_epoch=train_total_steps,\n                    verbose = 1)\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-03-21T02:04:13.216346Z","iopub.execute_input":"2022-03-21T02:04:13.216657Z","iopub.status.idle":"2022-03-21T02:17:22.826896Z","shell.execute_reply.started":"2022-03-21T02:04:13.216626Z","shell.execute_reply":"2022-03-21T02:17:22.825596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}