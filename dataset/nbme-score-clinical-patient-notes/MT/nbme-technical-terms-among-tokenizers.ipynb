{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"- **OBJECTIVES**\n    - Probably NBME texts have much technical terms for biomedicine.\n    - Recently microsoft researchers showed even domain-specific pretraining can benefit by starting from general-domain language models. [PubMedBert](https://huggingface.co/microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract)\n    - The aim of this notebook is to roughly explore how much techical terms in NBME features cannot be detected by various tokenizers, especially Roberta, DeBerta_V2 and PubMedBert","metadata":{}},{"cell_type":"markdown","source":"**VER3**\n- added DeBerta.\n- explored how many tokens 'location' truth are devided into regarding various tokenizers.","metadata":{}},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"!pip install transformers==4.16.2","metadata":{"execution":{"iopub.status.busy":"2022-03-18T01:51:04.404828Z","iopub.execute_input":"2022-03-18T01:51:04.405195Z","iopub.status.idle":"2022-03-18T01:51:21.321903Z","shell.execute_reply.started":"2022-03-18T01:51:04.405101Z","shell.execute_reply":"2022-03-18T01:51:21.320942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install tokenizers==0.11.0","metadata":{"execution":{"iopub.status.busy":"2022-03-18T01:51:21.324387Z","iopub.execute_input":"2022-03-18T01:51:21.324767Z","iopub.status.idle":"2022-03-18T01:51:31.348016Z","shell.execute_reply.started":"2022-03-18T01:51:21.324721Z","shell.execute_reply":"2022-03-18T01:51:31.346936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://www.kaggle.com/nbroad/deberta-v2-3-fast-tokenizer\nimport shutil\nfrom pathlib import Path\n\ntransformers_path = Path('/opt/conda/lib/python3.7/site-packages/transformers') \ninput_dir = Path('../input/deberta-v2-3-fast-tokenizer')\n\nconvert_file = input_dir / 'convert_slow_tokenizer.py'\nconversion_path = transformers_path/convert_file.name \nif conversion_path.exists():\n    print('previous convert file exists. will be unlinked.')\n    conversion_path.unlink() \nshutil.copy(convert_file, transformers_path)\n\ndeberta_v2_path = transformers_path / 'models' / 'deberta_v2' \nfor filename in ['tokenization_deberta_v2.py', 'tokenization_deberta_v2_fast.py']:\n    filepath = deberta_v2_path/filename\n    if filepath.exists():\n        print(f'previous {filename} exists. will be unlinked.')\n        filepath.unlink() \n    shutil.copy(input_dir/filename, filepath)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T01:51:31.350087Z","iopub.execute_input":"2022-03-18T01:51:31.350478Z","iopub.status.idle":"2022-03-18T01:51:31.381151Z","shell.execute_reply.started":"2022-03-18T01:51:31.350413Z","shell.execute_reply":"2022-03-18T01:51:31.380414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport sys\nimport glob\nimport random\nfrom tqdm.notebook import tqdm\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nimport ast\n\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\nfrom sklearn.model_selection import train_test_split\n\nimport transformers\nfrom transformers.models.deberta_v2.tokenization_deberta_v2_fast import DebertaV2TokenizerFast\nfrom transformers import AutoConfig, AutoModel, AutoTokenizer\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom matplotlib_venn import venn3, venn2\nimport seaborn as sns\nsns.set()\n\nprint('TF version,', tf.__version__)\nprint('transformers version,', transformers.__version__)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-18T01:57:42.951844Z","iopub.execute_input":"2022-03-18T01:57:42.952127Z","iopub.status.idle":"2022-03-18T01:57:42.966365Z","shell.execute_reply.started":"2022-03-18T01:57:42.952097Z","shell.execute_reply":"2022-03-18T01:57:42.96529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Configuration","metadata":{}},{"cell_type":"code","source":"seed = 42\nMAX_LEN = 512","metadata":{"execution":{"iopub.status.busy":"2022-03-18T01:53:05.340371Z","iopub.execute_input":"2022-03-18T01:53:05.340963Z","iopub.status.idle":"2022-03-18T01:53:05.344776Z","shell.execute_reply.started":"2022-03-18T01:53:05.340924Z","shell.execute_reply":"2022-03-18T01:53:05.343954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed=42):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    tf.random.set_seed(seed)\nseed_everything(seed)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T01:53:05.454139Z","iopub.execute_input":"2022-03-18T01:53:05.45513Z","iopub.status.idle":"2022-03-18T01:53:05.460322Z","shell.execute_reply.started":"2022-03-18T01:53:05.455086Z","shell.execute_reply":"2022-03-18T01:53:05.459619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Train","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/nbme-score-clinical-patient-notes/train.csv')\ntrain['annotation'] = train['annotation'].apply(ast.literal_eval) # Construct an object from a string\ntrain['location'] = train['location'].apply(ast.literal_eval) # Construct an object from a string\ntrain","metadata":{"execution":{"iopub.status.busy":"2022-03-18T01:53:05.878232Z","iopub.execute_input":"2022-03-18T01:53:05.878546Z","iopub.status.idle":"2022-03-18T01:53:06.401658Z","shell.execute_reply.started":"2022-03-18T01:53:05.878513Z","shell.execute_reply":"2022-03-18T01:53:06.400782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = pd.read_csv('../input/nbme-score-clinical-patient-notes/features.csv')\nfeatures","metadata":{"execution":{"iopub.status.busy":"2022-03-18T01:53:06.956627Z","iopub.execute_input":"2022-03-18T01:53:06.957Z","iopub.status.idle":"2022-03-18T01:53:06.975301Z","shell.execute_reply.started":"2022-03-18T01:53:06.956961Z","shell.execute_reply":"2022-03-18T01:53:06.974506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"patient_notes = pd.read_csv('../input/nbme-score-clinical-patient-notes/patient_notes.csv')\npatient_notes","metadata":{"execution":{"iopub.status.busy":"2022-03-18T01:53:07.391417Z","iopub.execute_input":"2022-03-18T01:53:07.391744Z","iopub.status.idle":"2022-03-18T01:53:08.14345Z","shell.execute_reply.started":"2022-03-18T01:53:07.391703Z","shell.execute_reply":"2022-03-18T01:53:08.142598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Merge","metadata":{}},{"cell_type":"code","source":"train = train.merge(features, on=['feature_num', 'case_num'], how='left')\ntrain = train.merge(patient_notes, on=['pn_num', 'case_num'], how='left')\ntrain['annotation_length'] = train['annotation'].apply(len)\ntrain","metadata":{"execution":{"iopub.status.busy":"2022-03-18T01:53:08.456415Z","iopub.execute_input":"2022-03-18T01:53:08.45676Z","iopub.status.idle":"2022-03-18T01:53:08.530215Z","shell.execute_reply.started":"2022-03-18T01:53:08.456727Z","shell.execute_reply":"2022-03-18T01:53:08.529289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Words","metadata":{}},{"cell_type":"code","source":"feature_set = set()\nfor n, row in features.iterrows():\n    tmp_set = set(row['feature_text'].split('-'))\n    feature_set = feature_set | tmp_set\nfeature_set = {item.lower() for item in feature_set}","metadata":{"execution":{"iopub.status.busy":"2022-03-18T01:53:09.443395Z","iopub.execute_input":"2022-03-18T01:53:09.444292Z","iopub.status.idle":"2022-03-18T01:53:09.459517Z","shell.execute_reply.started":"2022-03-18T01:53:09.444243Z","shell.execute_reply":"2022-03-18T01:53:09.458326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for n, item in enumerate(feature_set):\n    print(item.ljust(15), end='')","metadata":{"execution":{"iopub.status.busy":"2022-03-18T01:53:10.149815Z","iopub.execute_input":"2022-03-18T01:53:10.150197Z","iopub.status.idle":"2022-03-18T01:53:10.189559Z","shell.execute_reply.started":"2022-03-18T01:53:10.150153Z","shell.execute_reply":"2022-03-18T01:53:10.18863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(feature_set)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T01:53:10.795136Z","iopub.execute_input":"2022-03-18T01:53:10.795502Z","iopub.status.idle":"2022-03-18T01:53:10.80179Z","shell.execute_reply.started":"2022-03-18T01:53:10.79547Z","shell.execute_reply":"2022-03-18T01:53:10.800976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_words = []\nfor n, row in train.iterrows():\n    if len(row['annotation']) > 0:\n        for anno in row['annotation']:\n            num_words.append(len(anno.split()))\nnum_words = np.array(num_words)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T01:53:11.425836Z","iopub.execute_input":"2022-03-18T01:53:11.426105Z","iopub.status.idle":"2022-03-18T01:53:12.216923Z","shell.execute_reply.started":"2022-03-18T01:53:11.426077Z","shell.execute_reply":"2022-03-18T01:53:12.215926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tokenizer","metadata":{"execution":{"iopub.status.busy":"2022-03-16T01:11:44.431902Z","iopub.execute_input":"2022-03-16T01:11:44.432204Z","iopub.status.idle":"2022-03-16T01:11:44.439139Z","shell.execute_reply.started":"2022-03-16T01:11:44.432163Z","shell.execute_reply":"2022-03-16T01:11:44.438434Z"}}},{"cell_type":"markdown","source":"- Deberta_v2","metadata":{}},{"cell_type":"code","source":"deberta_v2_tokenizer = DebertaV2TokenizerFast.from_pretrained('kamalkraj/deberta-v2-xlarge')","metadata":{"execution":{"iopub.status.busy":"2022-03-18T01:53:14.483137Z","iopub.execute_input":"2022-03-18T01:53:14.483465Z","iopub.status.idle":"2022-03-18T01:53:17.436841Z","shell.execute_reply.started":"2022-03-18T01:53:14.483418Z","shell.execute_reply":"2022-03-18T01:53:17.435857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"voc_size_deberta_v2 = deberta_v2_tokenizer.vocab_size\nprint(voc_size_deberta_v2)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T01:53:24.355415Z","iopub.execute_input":"2022-03-18T01:53:24.35587Z","iopub.status.idle":"2022-03-18T01:53:24.362008Z","shell.execute_reply.started":"2022-03-18T01:53:24.355837Z","shell.execute_reply":"2022-03-18T01:53:24.361029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"voc_deberta_v2 = np.array(list(deberta_v2_tokenizer.get_vocab().keys()))\nvoc_deberta_v2 = set(voc_deberta_v2)\nvoc_deberta_v2 = {item.lower() for item in voc_deberta_v2}","metadata":{"execution":{"iopub.status.busy":"2022-03-18T01:53:25.824952Z","iopub.execute_input":"2022-03-18T01:53:25.825425Z","iopub.status.idle":"2022-03-18T01:53:26.150608Z","shell.execute_reply.started":"2022-03-18T01:53:25.825374Z","shell.execute_reply":"2022-03-18T01:53:26.149737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"diff_deberta_v2 = feature_set - voc_deberta_v2\nfor n, item in enumerate(diff_deberta_v2):\n    print(item.ljust(15), end='')","metadata":{"execution":{"iopub.status.busy":"2022-03-18T01:53:27.789964Z","iopub.execute_input":"2022-03-18T01:53:27.790266Z","iopub.status.idle":"2022-03-18T01:53:27.814373Z","shell.execute_reply.started":"2022-03-18T01:53:27.790231Z","shell.execute_reply":"2022-03-18T01:53:27.807686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(diff_deberta_v2)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T01:53:27.98424Z","iopub.execute_input":"2022-03-18T01:53:27.984539Z","iopub.status.idle":"2022-03-18T01:53:27.990683Z","shell.execute_reply.started":"2022-03-18T01:53:27.984505Z","shell.execute_reply":"2022-03-18T01:53:27.989695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_tokens_deberta_v2 = []\nfor n, row in train.iterrows():\n    if len(row['annotation'])>0:\n        for anno in row['annotation']:\n            tmp = deberta_v2_tokenizer(anno, add_special_tokens=False)\n            num_tokens_deberta_v2.append(len(tmp['input_ids']))","metadata":{"execution":{"iopub.status.busy":"2022-03-18T01:53:28.569672Z","iopub.execute_input":"2022-03-18T01:53:28.569998Z","iopub.status.idle":"2022-03-18T01:53:30.61226Z","shell.execute_reply.started":"2022-03-18T01:53:28.569965Z","shell.execute_reply":"2022-03-18T01:53:30.611348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_tokens_deberta_v2 = np.array(num_tokens_deberta_v2)\ndevided_fold_deberta_v2 = num_tokens_deberta_v2 / num_words","metadata":{"execution":{"iopub.status.busy":"2022-03-18T01:53:30.613789Z","iopub.execute_input":"2022-03-18T01:53:30.614015Z","iopub.status.idle":"2022-03-18T01:53:30.6237Z","shell.execute_reply.started":"2022-03-18T01:53:30.613988Z","shell.execute_reply":"2022-03-18T01:53:30.622399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- deberta","metadata":{}},{"cell_type":"code","source":"deberta_tokenizer = AutoTokenizer.from_pretrained('kamalkraj/deberta-base')","metadata":{"execution":{"iopub.status.busy":"2022-03-18T01:53:44.536693Z","iopub.execute_input":"2022-03-18T01:53:44.537008Z","iopub.status.idle":"2022-03-18T01:53:46.984169Z","shell.execute_reply.started":"2022-03-18T01:53:44.536977Z","shell.execute_reply":"2022-03-18T01:53:46.983394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"deberta_tokenizer(train.iloc[0]['annotation'][0], add_special_tokens=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T02:13:45.760187Z","iopub.execute_input":"2022-03-18T02:13:45.760488Z","iopub.status.idle":"2022-03-18T02:13:45.768811Z","shell.execute_reply.started":"2022-03-18T02:13:45.760435Z","shell.execute_reply":"2022-03-18T02:13:45.767655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"voc_size_deberta = deberta_tokenizer.vocab_size\nprint(voc_size_deberta)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T01:54:06.591221Z","iopub.execute_input":"2022-03-18T01:54:06.591557Z","iopub.status.idle":"2022-03-18T01:54:06.597487Z","shell.execute_reply.started":"2022-03-18T01:54:06.59152Z","shell.execute_reply":"2022-03-18T01:54:06.59638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"voc_deberta = np.array(list(deberta_tokenizer.get_vocab().keys()))\nvoc_deberta = set(voc_deberta)\nvoc_deberta = {item.lower() for item in voc_deberta}","metadata":{"execution":{"iopub.status.busy":"2022-03-18T01:54:33.759363Z","iopub.execute_input":"2022-03-18T01:54:33.759975Z","iopub.status.idle":"2022-03-18T01:54:33.907261Z","shell.execute_reply.started":"2022-03-18T01:54:33.759924Z","shell.execute_reply":"2022-03-18T01:54:33.906391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"diff_deberta = feature_set - voc_deberta\nfor n, item in enumerate(diff_deberta):\n    print(item.ljust(15), end='')","metadata":{"execution":{"iopub.status.busy":"2022-03-18T01:54:59.653713Z","iopub.execute_input":"2022-03-18T01:54:59.654136Z","iopub.status.idle":"2022-03-18T01:54:59.678096Z","shell.execute_reply.started":"2022-03-18T01:54:59.654105Z","shell.execute_reply":"2022-03-18T01:54:59.677145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(diff_deberta)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T01:55:13.916913Z","iopub.execute_input":"2022-03-18T01:55:13.917212Z","iopub.status.idle":"2022-03-18T01:55:13.923569Z","shell.execute_reply.started":"2022-03-18T01:55:13.91718Z","shell.execute_reply":"2022-03-18T01:55:13.922698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_tokens_deberta = []\nfor n, row in train.iterrows():\n    if len(row['annotation'])>0:\n        for anno in row['annotation']:\n            tmp = deberta_tokenizer(anno, add_special_tokens=False)\n            num_tokens_deberta.append(len(tmp['input_ids']))","metadata":{"execution":{"iopub.status.busy":"2022-03-18T01:55:36.608341Z","iopub.execute_input":"2022-03-18T01:55:36.608682Z","iopub.status.idle":"2022-03-18T01:55:38.733513Z","shell.execute_reply.started":"2022-03-18T01:55:36.608646Z","shell.execute_reply":"2022-03-18T01:55:38.732827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_tokens_deberta = np.array(num_tokens_deberta)\ndevided_fold_deberta = num_tokens_deberta / num_words","metadata":{"execution":{"iopub.status.busy":"2022-03-18T01:56:17.615658Z","iopub.execute_input":"2022-03-18T01:56:17.61596Z","iopub.status.idle":"2022-03-18T01:56:17.621733Z","shell.execute_reply.started":"2022-03-18T01:56:17.61593Z","shell.execute_reply":"2022-03-18T01:56:17.620873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Roberta","metadata":{}},{"cell_type":"code","source":"roberta_tokenizer = AutoTokenizer.from_pretrained('roberta-large')","metadata":{"execution":{"iopub.status.busy":"2022-03-18T01:56:19.535538Z","iopub.execute_input":"2022-03-18T01:56:19.53611Z","iopub.status.idle":"2022-03-18T01:56:21.771148Z","shell.execute_reply.started":"2022-03-18T01:56:19.536049Z","shell.execute_reply":"2022-03-18T01:56:21.769747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"voc_size_roberta = roberta_tokenizer.vocab_size\nprint(voc_size_roberta)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T01:56:22.415417Z","iopub.execute_input":"2022-03-18T01:56:22.415733Z","iopub.status.idle":"2022-03-18T01:56:22.421531Z","shell.execute_reply.started":"2022-03-18T01:56:22.415703Z","shell.execute_reply":"2022-03-18T01:56:22.420582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"voc_roberta = np.array(list(roberta_tokenizer.get_vocab().keys()))\nvoc_roberta = set(voc_roberta)\nvoc_roberta = {item.lower() for item in voc_roberta}","metadata":{"execution":{"iopub.status.busy":"2022-03-18T01:56:23.254902Z","iopub.execute_input":"2022-03-18T01:56:23.255183Z","iopub.status.idle":"2022-03-18T01:56:23.40424Z","shell.execute_reply.started":"2022-03-18T01:56:23.255154Z","shell.execute_reply":"2022-03-18T01:56:23.403412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"diff_roberta = feature_set - voc_roberta\nfor n, item in enumerate(diff_roberta):\n    print(item.ljust(15), end='')","metadata":{"execution":{"iopub.status.busy":"2022-03-18T01:56:30.410518Z","iopub.execute_input":"2022-03-18T01:56:30.411169Z","iopub.status.idle":"2022-03-18T01:56:30.449644Z","shell.execute_reply.started":"2022-03-18T01:56:30.411123Z","shell.execute_reply":"2022-03-18T01:56:30.448714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(diff_roberta)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T01:56:31.684945Z","iopub.execute_input":"2022-03-18T01:56:31.685221Z","iopub.status.idle":"2022-03-18T01:56:31.690271Z","shell.execute_reply.started":"2022-03-18T01:56:31.685193Z","shell.execute_reply":"2022-03-18T01:56:31.689556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_tokens_roberta = []\nfor n, row in train.iterrows():\n    if len(row['annotation'])>0:\n        for anno in row['annotation']:\n            tmp = roberta_tokenizer(anno, add_special_tokens=False)\n            num_tokens_roberta.append(len(tmp['input_ids']))","metadata":{"execution":{"iopub.status.busy":"2022-03-18T02:00:09.716609Z","iopub.execute_input":"2022-03-18T02:00:09.716946Z","iopub.status.idle":"2022-03-18T02:00:11.892321Z","shell.execute_reply.started":"2022-03-18T02:00:09.71691Z","shell.execute_reply":"2022-03-18T02:00:11.8915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_tokens_roberta = np.array(num_tokens_roberta)\ndevided_fold_roberta = num_tokens_roberta / num_words","metadata":{"execution":{"iopub.status.busy":"2022-03-18T02:00:40.843618Z","iopub.execute_input":"2022-03-18T02:00:40.843918Z","iopub.status.idle":"2022-03-18T02:00:40.850117Z","shell.execute_reply.started":"2022-03-18T02:00:40.843884Z","shell.execute_reply":"2022-03-18T02:00:40.849436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- PubMedBert","metadata":{}},{"cell_type":"code","source":"pubmedbert_tokenizer = AutoTokenizer.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\")","metadata":{"execution":{"iopub.status.busy":"2022-03-18T02:00:43.802169Z","iopub.execute_input":"2022-03-18T02:00:43.802793Z","iopub.status.idle":"2022-03-18T02:00:45.559364Z","shell.execute_reply.started":"2022-03-18T02:00:43.802734Z","shell.execute_reply":"2022-03-18T02:00:45.5586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"voc_size_pubmedbert = pubmedbert_tokenizer.vocab_size\nprint(voc_size_pubmedbert)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T02:00:55.020754Z","iopub.execute_input":"2022-03-18T02:00:55.021259Z","iopub.status.idle":"2022-03-18T02:00:55.026722Z","shell.execute_reply.started":"2022-03-18T02:00:55.021224Z","shell.execute_reply":"2022-03-18T02:00:55.025693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"voc_pubmedbert = np.array(list(pubmedbert_tokenizer.get_vocab().keys()))\nvoc_pubmedbert = set(voc_pubmedbert)\nvoc_pubmedbert = {item.lower() for item in voc_pubmedbert}","metadata":{"execution":{"iopub.status.busy":"2022-03-18T02:00:55.149551Z","iopub.execute_input":"2022-03-18T02:00:55.150114Z","iopub.status.idle":"2022-03-18T02:00:55.209611Z","shell.execute_reply.started":"2022-03-18T02:00:55.150077Z","shell.execute_reply":"2022-03-18T02:00:55.208945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"diff_pubmedbert = feature_set - voc_pubmedbert\nfor n, item in enumerate(diff_pubmedbert):\n    print(item.ljust(15), end='')","metadata":{"execution":{"iopub.status.busy":"2022-03-18T02:00:56.065545Z","iopub.execute_input":"2022-03-18T02:00:56.066082Z","iopub.status.idle":"2022-03-18T02:00:56.076976Z","shell.execute_reply.started":"2022-03-18T02:00:56.066047Z","shell.execute_reply":"2022-03-18T02:00:56.076135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(diff_pubmedbert)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T02:00:56.559581Z","iopub.execute_input":"2022-03-18T02:00:56.560306Z","iopub.status.idle":"2022-03-18T02:00:56.565702Z","shell.execute_reply.started":"2022-03-18T02:00:56.560269Z","shell.execute_reply":"2022-03-18T02:00:56.564726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_tokens_pubmedbert = []\nfor n, row in train.iterrows():\n    if len(row['annotation'])>0:\n        for anno in row['annotation']:\n            tmp = pubmedbert_tokenizer(anno, add_special_tokens=False)\n            num_tokens_pubmedbert.append(len(tmp['input_ids']))","metadata":{"execution":{"iopub.status.busy":"2022-03-18T02:01:22.947223Z","iopub.execute_input":"2022-03-18T02:01:22.948083Z","iopub.status.idle":"2022-03-18T02:01:25.006633Z","shell.execute_reply.started":"2022-03-18T02:01:22.948025Z","shell.execute_reply":"2022-03-18T02:01:25.005843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_tokens_pubmedbert = np.array(num_tokens_pubmedbert)\ndevided_fold_pubmedbert = num_tokens_pubmedbert / num_words","metadata":{"execution":{"iopub.status.busy":"2022-03-18T02:02:02.728141Z","iopub.execute_input":"2022-03-18T02:02:02.728656Z","iopub.status.idle":"2022-03-18T02:02:02.734057Z","shell.execute_reply.started":"2022-03-18T02:02:02.728591Z","shell.execute_reply":"2022-03-18T02:02:02.733397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Comparison","metadata":{}},{"cell_type":"code","source":"undetected = np.array([len(diff_deberta_v2), len(diff_deberta), len(diff_roberta), len(diff_pubmedbert)])\nundetected = undetected / len(feature_set) * 100","metadata":{"execution":{"iopub.status.busy":"2022-03-18T02:02:24.931949Z","iopub.execute_input":"2022-03-18T02:02:24.932717Z","iopub.status.idle":"2022-03-18T02:02:24.937185Z","shell.execute_reply.started":"2022-03-18T02:02:24.932677Z","shell.execute_reply":"2022-03-18T02:02:24.936532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(ncols=2, figsize=(12, 6))\nlabels = ['DeBerta_V2', 'DeBerta', 'RoBerta', 'PubMedBert']\naxes[0].bar([1,2,3, 4], [voc_size_deberta_v2, voc_size_deberta, voc_size_roberta, voc_size_pubmedbert],\n           tick_label=labels, color=['#E7B8B9', '#BBDCC2', '#BBDCC2', '#B7C6DF'])\naxes[0].set_ylabel('vocabulary size', fontsize=15)\naxes[0].set_title('Vocabulary size among 4 tokenizers', fontsize=15, fontweight='bold')\naxes[0].tick_params(axis='x', labelsize=15)\naxes[1].bar([1,2,3, 4], 100-undetected, tick_label=labels, color=['#E7B8B9', '#BBDCC2', '#BBDCC2', '#B7C6DF'])\naxes[1].set_ylabel('detected feature words (%)', fontsize=15)\naxes[1].set_title('Detected feature words among 4 tokenizers', fontsize=15, fontweight='bold')\naxes[1].tick_params(axis='x', labelsize=15)\nfig.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-18T02:23:54.599512Z","iopub.execute_input":"2022-03-18T02:23:54.599856Z","iopub.status.idle":"2022-03-18T02:23:55.037696Z","shell.execute_reply.started":"2022-03-18T02:23:54.59982Z","shell.execute_reply":"2022-03-18T02:23:55.035949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Deberta V2 has the most vocabularies, but misses very important technical terms like asthma, bowel, hallucination, infarction, insomnia, nervous, stool, urinary etc.\n- PubMedBert has the least vocabularies, but detects the most technical terms.","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(ncols=2, figsize=(12, 6))\nlabels = ['DeBerta_V2', 'DeBerta', 'RoBerta', 'PubMedBert']\naxes[0].bar([1,2,3, 4], [num_tokens_deberta_v2.mean(), num_tokens_deberta.mean(), num_tokens_roberta.mean(), num_tokens_pubmedbert.mean()],\n           tick_label=labels, color=['#E7B8B9', '#BBDCC2', '#BBDCC2', '#B7C6DF'])\naxes[0].set_ylabel('length of ground truth tokens', fontsize=15)\naxes[0].set_title('Length of Annotation tokens among 4 tokenizers', fontsize=15, fontweight='bold')\naxes[0].tick_params(axis='x', labelsize=15)\naxes[1].bar([1,2,3, 4], [devided_fold_deberta_v2.mean(), devided_fold_deberta.mean(), devided_fold_roberta.mean(), devided_fold_pubmedbert.mean()],\n            tick_label=labels, color=['#E7B8B9', '#BBDCC2', '#BBDCC2', '#B7C6DF'])\naxes[1].set_ylabel('devided rate (tokens/words)', fontsize=15)\naxes[1].set_title('Tokens/Words rate among 4 tokenizers', fontsize=15, fontweight='bold')\naxes[1].tick_params(axis='x', labelsize=15)\nfig.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-18T02:24:04.272663Z","iopub.execute_input":"2022-03-18T02:24:04.272948Z","iopub.status.idle":"2022-03-18T02:24:04.709755Z","shell.execute_reply.started":"2022-03-18T02:24:04.272918Z","shell.execute_reply":"2022-03-18T02:24:04.708806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The annotaion length is about 4 tokens. \n- If we set MAX_LEN=512 and tackle this competition as NER task, only 0.78% (4/MAX_LEN) is positive label in each patient note.\n- Tokens/Words rate of PubMedBert was higher than I expected.","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(6,6))\nax = fig.add_subplot()\nvenn3([voc_deberta, voc_roberta, voc_pubmedbert], set_labels=labels, ax=ax)\nfig.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-16T05:19:28.960985Z","iopub.execute_input":"2022-03-16T05:19:28.9614Z","iopub.status.idle":"2022-03-16T05:19:29.205727Z","shell.execute_reply.started":"2022-03-16T05:19:28.961368Z","shell.execute_reply":"2022-03-16T05:19:29.20421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- PubMedBert can be much effective to biomedical notes because of having much technical terms.\n- But since PubMedBert has less vocabularies, it can be poor at catching the whole text meanings.\n- We should include PubMedBert when ensembling?","metadata":{}},{"cell_type":"markdown","source":"- thanks","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}