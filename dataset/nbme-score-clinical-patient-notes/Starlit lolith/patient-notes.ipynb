{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"- Training notebook: https://www.kaggle.com/hengzheng/training-qa-roberta-base-5-folds\n- Base on: https://www.kaggle.com/tomohiroh/nbme-bert-for-beginners","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.simplefilter('ignore')\n\nimport os\nimport gc\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm, trange\n\nimport torch\nfrom transformers import AutoModel, AutoTokenizer, AutoConfig","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-28T12:33:39.731629Z","iopub.execute_input":"2022-03-28T12:33:39.731875Z","iopub.status.idle":"2022-03-28T12:33:47.057354Z","shell.execute_reply.started":"2022-03-28T12:33:39.731802Z","shell.execute_reply":"2022-03-28T12:33:47.056604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# config","metadata":{}},{"cell_type":"code","source":"ROOT = '../input/nbme-score-clinical-patient-notes'\nMODEL_NAME = '../input/roberta-base'\nBATCH_SIZE = 16\nN_FOLDS = 5\nMODELS_PATH = '../input/training-qa-roberta-base-5-folds'","metadata":{"execution":{"iopub.status.busy":"2022-03-28T12:33:47.059101Z","iopub.execute_input":"2022-03-28T12:33:47.059356Z","iopub.status.idle":"2022-03-28T12:33:47.065909Z","shell.execute_reply.started":"2022-03-28T12:33:47.059323Z","shell.execute_reply":"2022-03-28T12:33:47.064908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nDEVICE","metadata":{"execution":{"iopub.status.busy":"2022-03-28T12:33:47.066802Z","iopub.execute_input":"2022-03-28T12:33:47.067022Z","iopub.status.idle":"2022-03-28T12:33:47.131283Z","shell.execute_reply.started":"2022-03-28T12:33:47.06699Z","shell.execute_reply":"2022-03-28T12:33:47.130584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# helper functions","metadata":{}},{"cell_type":"code","source":"def create_test_df():\n    feats = pd.read_csv(f\"{ROOT}/features.csv\")\n    feats.loc[27, 'feature_text'] = \"Last-Pap-smear-1-year-ago\"\n    \n    notes = pd.read_csv(f\"{ROOT}/patient_notes.csv\")\n    test = pd.read_csv(f\"{ROOT}/test.csv\")\n\n    merged = test.merge(notes, how = \"left\")\n    merged = merged.merge(feats, how = \"left\")\n\n    def process_feature_text(text):\n        return text.replace(\"-OR-\", \";-\").replace(\"-\", \" \")\n    merged[\"feature_text\"] = [process_feature_text(x) for x in merged[\"feature_text\"]]\n    \n    return merged","metadata":{"execution":{"iopub.status.busy":"2022-03-28T12:33:47.133515Z","iopub.execute_input":"2022-03-28T12:33:47.134058Z","iopub.status.idle":"2022-03-28T12:33:47.141124Z","shell.execute_reply.started":"2022-03-28T12:33:47.133996Z","shell.execute_reply":"2022-03-28T12:33:47.140435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class NBMETestData(torch.utils.data.Dataset):\n    def __init__(self, data, tokenizer):\n        self.data = data\n        self.tokenizer = tokenizer\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        example = self.data.loc[idx]\n        tokenized = self.tokenizer(\n            example[\"feature_text\"],\n            example[\"pn_history\"],\n            truncation = \"only_second\",\n            max_length = 416,\n            padding = \"max_length\",\n            return_offsets_mapping = True\n        )\n        tokenized[\"sequence_ids\"] = tokenized.sequence_ids()\n\n        input_ids = np.array(tokenized[\"input_ids\"])\n        attention_mask = np.array(tokenized[\"attention_mask\"])\n        offset_mapping = np.array(tokenized[\"offset_mapping\"])\n        sequence_ids = np.array(tokenized[\"sequence_ids\"]).astype(\"float16\")\n\n        return input_ids, attention_mask, offset_mapping, sequence_ids","metadata":{"execution":{"iopub.status.busy":"2022-03-28T12:33:47.143261Z","iopub.execute_input":"2022-03-28T12:33:47.143897Z","iopub.status.idle":"2022-03-28T12:33:47.152826Z","shell.execute_reply.started":"2022-03-28T12:33:47.143858Z","shell.execute_reply":"2022-03-28T12:33:47.152108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class NBMEModel(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.backbone = AutoModel.from_pretrained(MODEL_NAME)\n        self.config = AutoConfig.from_pretrained(MODEL_NAME)\n        self.dropout = torch.nn.Dropout(p=0.2)\n        self.classifier = torch.nn.Linear(self.config.hidden_size, 1)\n        \n    def forward(self, input_ids, attention_mask):\n        pooler_outputs = self.backbone(input_ids=input_ids, \n                                       attention_mask=attention_mask)[0]\n        logits = self.classifier(self.dropout(pooler_outputs)).squeeze(-1)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2022-03-28T12:33:47.15425Z","iopub.execute_input":"2022-03-28T12:33:47.154881Z","iopub.status.idle":"2022-03-28T12:33:47.162771Z","shell.execute_reply.started":"2022-03-28T12:33:47.154766Z","shell.execute_reply":"2022-03-28T12:33:47.162121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sigmoid(z):\n    return 1/(1 + np.exp(-z))\n\n\ndef get_location_predictions(preds, offset_mapping, sequence_ids, test=False):\n    all_predictions = []\n    for pred, offsets, seq_ids in zip(preds, offset_mapping, sequence_ids):\n        pred = sigmoid(pred)\n        start_idx = None\n        current_preds = []\n        for p, o, s_id in zip(pred, offsets, seq_ids):\n            if s_id is None or s_id == 0:\n                continue\n            if p > 0.5:\n                if start_idx is None:\n                    start_idx = o[0]\n                end_idx = o[1]\n            elif start_idx is not None:\n                if test:\n                    current_preds.append(f\"{start_idx} {end_idx}\")\n                else:\n                    current_preds.append((start_idx, end_idx))\n                start_idx = None\n        if test:\n            all_predictions.append(\"; \".join(current_preds))\n        else:\n            all_predictions.append(current_preds)\n    return all_predictions","metadata":{"execution":{"iopub.status.busy":"2022-03-28T12:33:47.164367Z","iopub.execute_input":"2022-03-28T12:33:47.164639Z","iopub.status.idle":"2022-03-28T12:33:47.175935Z","shell.execute_reply.started":"2022-03-28T12:33:47.164603Z","shell.execute_reply":"2022-03-28T12:33:47.175072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# loading test and tokenizer","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n\ntest = create_test_df()\ntest_ds = NBMETestData(test, tokenizer)\ntest_dl = torch.utils.data.DataLoader(test_ds, batch_size=BATCH_SIZE, pin_memory=True, \n                                      shuffle=False, drop_last=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T12:33:47.177674Z","iopub.execute_input":"2022-03-28T12:33:47.177943Z","iopub.status.idle":"2022-03-28T12:33:47.930102Z","shell.execute_reply.started":"2022-03-28T12:33:47.177907Z","shell.execute_reply":"2022-03-28T12:33:47.929389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# infer","metadata":{}},{"cell_type":"code","source":"all_preds = None\noffsets = []\nseq_ids = []\n\nfor fold in range(N_FOLDS):\n    model = NBMEModel().to(DEVICE)\n    model.load_state_dict(torch.load(f'{MODELS_PATH}/nbme_{fold}.pth', map_location=DEVICE))\n    model.eval()\n    preds = []\n    with torch.no_grad():\n        for batch in tqdm(test_dl):\n            input_ids = batch[0].to(DEVICE)\n            attention_mask = batch[1].to(DEVICE)\n            logits = model(input_ids, attention_mask)\n            preds.append(logits.cpu().numpy())\n            if fold == 0:                  # only in the first fold\n                offset_mapping = batch[2]\n                sequence_ids = batch[3]\n                offsets.append(offset_mapping.numpy())\n                seq_ids.append(sequence_ids.numpy())\n    preds = np.concatenate(preds, axis=0)\n    if all_preds is None:\n        all_preds = np.array(preds).astype(np.float32)\n    else:\n        all_preds += np.array(preds).astype(np.float32)\n    torch.cuda.empty_cache()\n    \n    \nall_preds /= N_FOLDS\nall_preds = all_preds.squeeze()\n\noffsets = np.concatenate(offsets, axis=0)\nseq_ids = np.concatenate(seq_ids, axis=0)\n\nprint(all_preds.shape, offsets.shape, seq_ids.shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T12:33:47.931942Z","iopub.execute_input":"2022-03-28T12:33:47.93234Z","iopub.status.idle":"2022-03-28T12:34:26.851211Z","shell.execute_reply.started":"2022-03-28T12:33:47.932305Z","shell.execute_reply":"2022-03-28T12:34:26.850421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"location_preds = get_location_predictions(all_preds, offsets, seq_ids, test=True)\n\ntest[\"location\"] = location_preds\ntest[[\"id\", \"location\"]].to_csv(\"submission.csv\", index = False)\npd.read_csv(\"submission.csv\").head()","metadata":{"execution":{"iopub.status.busy":"2022-03-28T12:34:26.853817Z","iopub.execute_input":"2022-03-28T12:34:26.854627Z","iopub.status.idle":"2022-03-28T12:34:26.897287Z","shell.execute_reply.started":"2022-03-28T12:34:26.854576Z","shell.execute_reply":"2022-03-28T12:34:26.896394Z"},"trusted":true},"execution_count":null,"outputs":[]}]}