{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-21T09:54:25.3146Z","iopub.execute_input":"2022-03-21T09:54:25.314916Z","iopub.status.idle":"2022-03-21T09:54:25.327753Z","shell.execute_reply.started":"2022-03-21T09:54:25.314884Z","shell.execute_reply":"2022-03-21T09:54:25.326704Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This code is heavily borrowed from https://www.kaggle.com/code/yasufuminakama/nbme-deberta-base-baseline-train/notebook. Please upvote his workbook if you find this useful\n\nI have given a very beginner level explanation of how the code works to find incorrect annotations, which is an important part of cleaning the data. ","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Basic Idea**\n\nWe loop through the offset values to find whether the annotation location is matching with any one of the offset values in the offset value list, if not it means there is some sort of error in the annotation","metadata":{}},{"cell_type":"markdown","source":"**Offset value** : Starting and ending value of each token","metadata":{}},{"cell_type":"code","source":"import os\nimport gc\nimport re\nimport ast\nimport sys\nimport copy\nimport json\nimport time\nimport math\nimport string\nimport pickle\nimport random\nimport joblib\nimport itertools\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\nfrom tqdm.auto import tqdm\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n\nimport torch\n# import torch.nn as nn\n# from torch.nn import Parameter\n# import torch.nn.functional as F\n# from torch.optim import Adam, SGD, AdamW\n# from torch.utils.data import DataLoader, Dataset\n\nos.system('pip install transformers')\n#os.system('python -m pip install --no-index --find-links=../input/nbme-pip-wheels transformers')\nimport tokenizers\nimport transformers\nprint(f\"tokenizers.__version__: {tokenizers.__version__}\")\nprint(f\"transformers.__version__: {transformers.__version__}\")\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig\nfrom transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n%env TOKENIZERS_PARALLELISM=true\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2022-03-21T09:54:33.272275Z","iopub.execute_input":"2022-03-21T09:54:33.273042Z","iopub.status.idle":"2022-03-21T09:54:51.133146Z","shell.execute_reply.started":"2022-03-21T09:54:33.272999Z","shell.execute_reply":"2022-03-21T09:54:51.132506Z"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# Data Loading\n# ====================================================\ntrain = pd.read_csv('../input/nbme-score-clinical-patient-notes/train.csv')\ntrain['annotation'] = train['annotation'].apply(ast.literal_eval)\ntrain['location'] = train['location'].apply(ast.literal_eval)\nfeatures = pd.read_csv('../input/nbme-score-clinical-patient-notes/features.csv')\npatient_notes = pd.read_csv('../input/nbme-score-clinical-patient-notes/patient_notes.csv')\n\n","metadata":{"execution":{"iopub.status.busy":"2022-03-21T09:54:51.134768Z","iopub.execute_input":"2022-03-21T09:54:51.135123Z","iopub.status.idle":"2022-03-21T09:54:52.235639Z","shell.execute_reply.started":"2022-03-21T09:54:51.135093Z","shell.execute_reply":"2022-03-21T09:54:52.234405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.merge(features, on=['feature_num', 'case_num'], how='left')\ntrain = train.merge(patient_notes, on=['pn_num', 'case_num'], how='left')\ndisplay(train.head())\n\ntrain['annotation_length'] = train['annotation'].apply(len)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T09:54:52.237033Z","iopub.execute_input":"2022-03-21T09:54:52.237286Z","iopub.status.idle":"2022-03-21T09:54:52.326075Z","shell.execute_reply.started":"2022-03-21T09:54:52.237254Z","shell.execute_reply":"2022-03-21T09:54:52.323935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-03-21T09:54:52.328593Z","iopub.execute_input":"2022-03-21T09:54:52.328967Z","iopub.status.idle":"2022-03-21T09:54:52.347724Z","shell.execute_reply.started":"2022-03-21T09:54:52.328925Z","shell.execute_reply":"2022-03-21T09:54:52.346532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Undestanding Offset mapping","metadata":{}},{"cell_type":"code","source":"model = \"microsoft/deberta-base\" \ntokenizer = AutoTokenizer.from_pretrained(model)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T09:54:52.349544Z","iopub.execute_input":"2022-03-21T09:54:52.350141Z","iopub.status.idle":"2022-03-21T09:54:58.571558Z","shell.execute_reply.started":"2022-03-21T09:54:52.350093Z","shell.execute_reply":"2022-03-21T09:54:58.570659Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer(\"Hello how are you\", return_offsets_mapping=True)['offset_mapping']","metadata":{"execution":{"iopub.status.busy":"2022-03-21T10:10:29.300466Z","iopub.execute_input":"2022-03-21T10:10:29.301257Z","iopub.status.idle":"2022-03-21T10:10:29.307294Z","shell.execute_reply.started":"2022-03-21T10:10:29.301221Z","shell.execute_reply":"2022-03-21T10:10:29.306697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see offset mapping gives us indices of each token\n\n(0,5) - Hello\n\n(5,9) - how\n\n(9,13) - are\n\n(13,17) - you\n","metadata":{}},{"cell_type":"markdown","source":"If the annotation is a single word, it should exactly match one of the tuples in the offset mapping list\n\nOn the other hand, if annotation is a group of words, the starting index should match first element of one of the tuples and ending index should match second element of another tuple in the offset mapping list. This logic is implemented in the code below","metadata":{}},{"cell_type":"markdown","source":"## Finding Incorrect Annotations","metadata":{}},{"cell_type":"code","source":"#https://huggingface.co/docs/transformers/preprocessing\n#https://huggingface.co/course/chapter2/6?fw=pt\nincorrect_annotation_ids = []\ntk0 = tqdm(range(len(train)), total=len(train))\nfor i in tk0:\n    \n    text = train.loc[i, 'pn_history']\n    feature_text = train.loc[i, 'feature_text']\n    annotation_length = train.loc[i, 'annotation_length']\n    annotation_list = train.loc[i, 'annotation']\n    location_list = train.loc[i, 'location']\n\n    encoded_text = tokenizer(text,\n                             add_special_tokens=True,\n                             max_length=512,\n                             padding=\"max_length\",\n                             return_offsets_mapping=True)\n    \n   \n    if annotation_length != 0:\n       \n        for location, annotation in zip(location_list, annotation_list):\n            \n            results = []\n            #print(annotation)\n            for loc in [s.split() for s in location.split(';')]:\n                \n                start_idx = -1\n                end_idx = -1\n                start, end = int(loc[0]), int(loc[1])\n                #print(start, end)\n                for idx in range(len(encoded_text['offset_mapping'])):\n                    #if start value of annotation \n                    if (start_idx == -1) & (start < encoded_text['offset_mapping'][idx][0]):\n                        start_idx = idx - 1\n                    if (end_idx == -1) & (end <= encoded_text['offset_mapping'][idx][1]):\n                        end_idx = idx\n                    #print(start_idx,\" \", end_idx)\n                if start_idx == -1:\n                    start_idx = end_idx\n                #print(start_idx, \"--\", end_idx)\n                res = f\"{encoded_text['offset_mapping'][start_idx][0] + 1} {encoded_text['offset_mapping'][end_idx][1]}\"\n                results.append(res)\n            result = \";\".join(results)\n#             if (int(location.split()[0]) >= int(result.split()[0]) + 2 ) or (location == result and location[0] != '0'):\n#                 print(i)\n#                 print(location, result)\n            if location != result:\n                incorrect_annotation_ids.append(i)\n               \n    \n            \n            \n            \n","metadata":{"execution":{"iopub.status.busy":"2022-03-21T10:34:42.192078Z","iopub.execute_input":"2022-03-21T10:34:42.192391Z","iopub.status.idle":"2022-03-21T10:35:09.897945Z","shell.execute_reply.started":"2022-03-21T10:34:42.192362Z","shell.execute_reply":"2022-03-21T10:35:09.897044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(incorrect_annotation_ids)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T10:35:10.761213Z","iopub.execute_input":"2022-03-21T10:35:10.761545Z","iopub.status.idle":"2022-03-21T10:35:10.769058Z","shell.execute_reply.started":"2022-03-21T10:35:10.761509Z","shell.execute_reply":"2022-03-21T10:35:10.767947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#incorrect_annotation_ids # Scope for improvement by removing punctuations","metadata":{"execution":{"iopub.status.busy":"2022-03-21T10:41:59.500691Z","iopub.execute_input":"2022-03-21T10:41:59.501355Z","iopub.status.idle":"2022-03-21T10:41:59.506244Z","shell.execute_reply.started":"2022-03-21T10:41:59.501306Z","shell.execute_reply":"2022-03-21T10:41:59.505035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num = 338\n\ntrain.loc[num,]['pn_history']","metadata":{"execution":{"iopub.status.busy":"2022-03-21T10:25:23.356364Z","iopub.execute_input":"2022-03-21T10:25:23.356683Z","iopub.status.idle":"2022-03-21T10:25:23.363817Z","shell.execute_reply.started":"2022-03-21T10:25:23.356651Z","shell.execute_reply":"2022-03-21T10:25:23.362856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.loc[num,]","metadata":{"execution":{"iopub.status.busy":"2022-03-21T10:25:24.568544Z","iopub.execute_input":"2022-03-21T10:25:24.568818Z","iopub.status.idle":"2022-03-21T10:25:24.57632Z","shell.execute_reply.started":"2022-03-21T10:25:24.568788Z","shell.execute_reply":"2022-03-21T10:25:24.57577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}