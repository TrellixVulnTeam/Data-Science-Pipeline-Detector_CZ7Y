{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"lunana  \nlast update 2022 04 27  \nゆっくりしてってね！","metadata":{}},{"cell_type":"markdown","source":"Thanh氏のnotebookをpseudo labelに改造しました。","metadata":{}},{"cell_type":"markdown","source":"# Trends  \n## EDA  \nhttps://www.kaggle.com/code/lunapandachan/nbme-eda-english  \n\n## Add test  \n* NBME RoBERTa-base pseudo label train  \nhttps://www.kaggle.com/code/lunapandachan/nbme-roberta-base-train-add-test  \n* NBME Theo's add test LB=0.882  \n\n  \n* NBME RoBERTa-base pseudo label infer LB=0.86   \nhttps://www.kaggle.com/code/lunapandachan/nbme-roberta-base-pseudo-label-infer  \n\n## Datasets  \n* [Training] QA RoBERTa-base 5 Folds ( Heng )  \nhttps://www.kaggle.com/code/hengzheng/training-qa-roberta-base-5-folds  \n* name roberta_base seed41 ( Lunana )  \nhttps://www.kaggle.com/datasets/lunapandachan/nbme-roberta-base-seed41  \n* nbme pseudo labeling  \nhttps://www.kaggle.com/datasets/lunapandachan/nbme-pseudo-labeling","metadata":{}},{"cell_type":"markdown","source":"**霊夢:今日はThanhさんの推測使用して最初のpseudo-labelを作ります。**  \n\n**Reimu: Today I'm going to make a first pseudo-label by Thanh's infer.**  \n\nhttps://www.kaggle.com/code/thanhns/deberta-v3-large-0-883-lb  \n\n**魔理沙:最初なので、モデルは5fold使って、２０％だけラベル創るよ。**  \n\n**Reimu: At first we make 20% labels with only fold0 model.**  \n\n**Deberta-v3-large LB =0.883の精度のものです。時間が、10時間くらいかかりました。**","metadata":{}},{"cell_type":"markdown","source":"# CFG","metadata":{}},{"cell_type":"code","source":"GCS_PATH='../input/nbme-score-clinical-patient-notes/'","metadata":{"execution":{"iopub.status.busy":"2022-04-27T13:51:04.446281Z","iopub.execute_input":"2022-04-27T13:51:04.446856Z","iopub.status.idle":"2022-04-27T13:51:04.48138Z","shell.execute_reply.started":"2022-04-27T13:51:04.446766Z","shell.execute_reply":"2022-04-27T13:51:04.480658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    num_workers=4\n    path=\"../input/deberta-v3-large-5-folds-public/\"\n    config_path=path+'config.pth'\n    model=\"microsoft/deberta-v3-large\"\n#    batch_size=128\n    batch_size=32\n    fc_dropout=0.2\n    max_len=354\n    seed=42\n    n_fold=5\n    trn_fold=[0, 1, 2, 3, 4]\n#    trn_fold=[0]\n    pl_folds=5\n    pl_n_fold=1\n    \n    NO_ZERO=False","metadata":{"execution":{"iopub.status.busy":"2022-04-27T13:51:04.484783Z","iopub.execute_input":"2022-04-27T13:51:04.484977Z","iopub.status.idle":"2022-04-27T13:51:04.490568Z","shell.execute_reply.started":"2022-04-27T13:51:04.484954Z","shell.execute_reply":"2022-04-27T13:51:04.48938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The following is necessary if you want to use the fast tokenizer for deberta v2 or v3\n# This must be done before importing transformers\nimport shutil\nfrom pathlib import Path\n\ntransformers_path = Path(\"/opt/conda/lib/python3.7/site-packages/transformers\")\n\ninput_dir = Path(\"../input/deberta-v2-3-fast-tokenizer\")\n\nconvert_file = input_dir / \"convert_slow_tokenizer.py\"\nconversion_path = transformers_path/convert_file.name\n\nif conversion_path.exists():\n    conversion_path.unlink()\n\nshutil.copy(convert_file, transformers_path)\ndeberta_v2_path = transformers_path / \"models\" / \"deberta_v2\"\n\nfor filename in ['tokenization_deberta_v2.py', 'tokenization_deberta_v2_fast.py']:\n    filepath = deberta_v2_path/filename\n    \n    if filepath.exists():\n        filepath.unlink()\n\n    shutil.copy(input_dir/filename, filepath)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T13:51:04.523745Z","iopub.execute_input":"2022-04-27T13:51:04.524152Z","iopub.status.idle":"2022-04-27T13:51:04.548794Z","shell.execute_reply.started":"2022-04-27T13:51:04.524105Z","shell.execute_reply":"2022-04-27T13:51:04.548173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!cp ../input/nbme-pseudo-label-0/pl_train0.csv ./pl_train0.csv\n#!cp ../input/nbme-pseudo-label-0/pl_train1.csv ./pl_train1.csv","metadata":{"execution":{"iopub.status.busy":"2022-04-27T13:51:04.552525Z","iopub.execute_input":"2022-04-27T13:51:04.552725Z","iopub.status.idle":"2022-04-27T13:51:04.556517Z","shell.execute_reply.started":"2022-04-27T13:51:04.552701Z","shell.execute_reply":"2022-04-27T13:51:04.555841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# import","metadata":{}},{"cell_type":"code","source":"import os\nimport gc\nimport ast\nimport sys\nimport copy\nimport json\nimport math\nimport string\nimport pickle\nimport random\nimport itertools\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\nfrom tqdm.auto import tqdm\nfrom sklearn.metrics import f1_score\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import AdamW\nfrom torch.utils.data import DataLoader, Dataset\n\nimport tokenizers\nimport transformers\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig\n%env TOKENIZERS_PARALLELISM=true\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)\n\ndebug=False","metadata":{"execution":{"iopub.status.busy":"2022-04-27T13:51:04.593479Z","iopub.execute_input":"2022-04-27T13:51:04.593772Z","iopub.status.idle":"2022-04-27T13:51:07.362224Z","shell.execute_reply.started":"2022-04-27T13:51:04.593744Z","shell.execute_reply":"2022-04-27T13:51:07.361401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utils","metadata":{}},{"cell_type":"code","source":"def seed_everything(seed=42):\n    '''\n    Sets the seed of the entire notebook so results are the same every time we run.\n    This is for REPRODUCIBILITY.\n    '''\n    random.seed(seed)\n    # Set a fixed value for the hash seed\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    \n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n        # When running on the CuDNN backend, two further options must be set\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\n\nseed_everything(seed=CFG.seed)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T13:51:07.367403Z","iopub.execute_input":"2022-04-27T13:51:07.367836Z","iopub.status.idle":"2022-04-27T13:51:07.383924Z","shell.execute_reply.started":"2022-04-27T13:51:07.367794Z","shell.execute_reply":"2022-04-27T13:51:07.383181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**魔理沙:ここではseedを設定するよ。random.seedはランダムに数値を決めるが、実行結果は毎回同じになるよ。**  \n\n**Marisa: I'll set the seed here. random.seed randomly decides the number, but the execution result will be the same every time.**","metadata":{}},{"cell_type":"markdown","source":"# Tokenizer","metadata":{}},{"cell_type":"code","source":"from transformers.models.deberta_v2.tokenization_deberta_v2_fast import DebertaV2TokenizerFast\n\ntokenizer = DebertaV2TokenizerFast.from_pretrained('../input/deberta-tokenizer')\nCFG.tokenizer = tokenizer","metadata":{"execution":{"iopub.status.busy":"2022-04-27T13:51:07.384952Z","iopub.execute_input":"2022-04-27T13:51:07.385335Z","iopub.status.idle":"2022-04-27T13:51:08.483532Z","shell.execute_reply.started":"2022-04-27T13:51:07.385297Z","shell.execute_reply":"2022-04-27T13:51:08.482788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**霊夢:ここではテキストをトークン化してるよ。**  \n\n**Reimu: I'm tokenizing the text here.**","metadata":{}},{"cell_type":"markdown","source":"# Helper functions for scoring","metadata":{}},{"cell_type":"code","source":"def micro_f1(preds, truths):\n    \"\"\"\n    Micro f1 on binary arrays.\n\n    Args:\n        preds (list of lists of ints): Predictions.\n        truths (list of lists of ints): Ground truths.\n\n    Returns:\n        float: f1 score.\n    \"\"\"\n    # Micro : aggregating over all instances\n    preds = np.concatenate(preds)\n    truths = np.concatenate(truths)\n    \n    return f1_score(truths, preds)\n\n\ndef spans_to_binary(spans, length=None):\n    \"\"\"\n    Converts spans to a binary array indicating whether each character is in the span.\n\n    Args:\n        spans (list of lists of two ints): Spans.\n\n    Returns:\n        np array [length]: Binarized spans.\n    \"\"\"\n    length = np.max(spans) if length is None else length\n    binary = np.zeros(length)\n    for start, end in spans:\n        binary[start:end] = 1\n        \n    return binary\n\n\ndef span_micro_f1(preds, truths):\n    \"\"\"\n    Micro f1 on spans.\n\n    Args:\n        preds (list of lists of two ints): Prediction spans.\n        truths (list of lists of two ints): Ground truth spans.\n\n    Returns:\n        float: f1 score.\n    \"\"\"\n    bin_preds = []\n    bin_truths = []\n    for pred, truth in zip(preds, truths):\n        if not len(pred) and not len(truth):\n            continue\n        length = max(np.max(pred) if len(pred) else 0, np.max(truth) if len(truth) else 0)\n        bin_preds.append(spans_to_binary(pred, length))\n        bin_truths.append(spans_to_binary(truth, length))\n        \n    return micro_f1(bin_preds, bin_truths)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T13:51:08.485452Z","iopub.execute_input":"2022-04-27T13:51:08.485718Z","iopub.status.idle":"2022-04-27T13:51:08.497514Z","shell.execute_reply.started":"2022-04-27T13:51:08.485681Z","shell.execute_reply":"2022-04-27T13:51:08.496707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_labels_for_scoring(df):\n    # example: ['0 1', '3 4'] -> ['0 1; 3 4']\n    df['location_for_create_labels'] = [ast.literal_eval(f'[]')] * len(df)\n    for i in range(len(df)):\n        lst = df.loc[i, 'location']\n        if lst:\n            new_lst = ';'.join(lst)\n            df.loc[i, 'location_for_create_labels'] = ast.literal_eval(f'[[\"{new_lst}\"]]')\n    # create labels\n    truths = []\n    for location_list in df['location_for_create_labels'].values:\n        truth = []\n        if len(location_list) > 0:\n            location = location_list[0]\n            for loc in [s.split() for s in location.split(';')]:\n                start, end = int(loc[0]), int(loc[1])\n                truth.append([start, end])\n        truths.append(truth)\n        \n    return truths\n\n\ndef get_char_probs(texts, predictions, tokenizer):\n    results = [np.zeros(len(t)) for t in texts]\n    for i, (text, prediction) in enumerate(zip(texts, predictions)):\n        encoded = tokenizer(text, \n                            add_special_tokens=True,\n                            return_offsets_mapping=True)\n        for idx, (offset_mapping, pred) in enumerate(zip(encoded['offset_mapping'], prediction)):\n            start = offset_mapping[0]\n            end = offset_mapping[1]\n            results[i][start:end] = pred\n            \n    return results\n\n\ndef get_results(char_probs, th=0.5):\n    results = []\n    for char_prob in char_probs:\n        result = np.where(char_prob >= th)[0] + 1\n        result = [list(g) for _, g in itertools.groupby(result, key=lambda n, c=itertools.count(): n - next(c))]\n        result = [f\"{min(r)} {max(r)}\" for r in result]\n        result = \";\".join(result)\n        results.append(result)\n        \n    return results\n\n\ndef get_predictions(results):\n    predictions = []\n    for result in results:\n        prediction = []\n        if result != \"\":\n            for loc in [s.split() for s in result.split(';')]:\n                start, end = int(loc[0]), int(loc[1])\n                prediction.append([start, end])\n        predictions.append(prediction)\n        \n    return predictions\n\n\ndef get_score(y_true, y_pred):\n    return span_micro_f1(y_true, y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T13:51:08.49991Z","iopub.execute_input":"2022-04-27T13:51:08.500108Z","iopub.status.idle":"2022-04-27T13:51:08.516793Z","shell.execute_reply.started":"2022-04-27T13:51:08.500082Z","shell.execute_reply":"2022-04-27T13:51:08.515861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# OOF","metadata":{}},{"cell_type":"code","source":"oof = pd.read_pickle(CFG.path+'oof_df.pkl')\ntruths = create_labels_for_scoring(oof)\nchar_probs = get_char_probs(oof['pn_history'].values,\n                            oof[[i for i in range(CFG.max_len)]].values, \n                            CFG.tokenizer)\n\nbest_th = 0.5\nbest_score = 0.\nfor th in np.arange(0.45, 0.55, 0.01):\n    th = np.round(th, 2)\n    results = get_results(char_probs, th=th)\n    preds = get_predictions(results)\n    score = get_score(preds, truths)\n    \n    if best_score < score:\n        best_th = th\n        best_score = score\n    print(f\"th: {th}  score: {score:.5f}\")\nprint(f\"best_th: {best_th}  score: {best_score:.5f}\")","metadata":{"execution":{"iopub.status.busy":"2022-04-27T13:51:08.518473Z","iopub.execute_input":"2022-04-27T13:51:08.51867Z","iopub.status.idle":"2022-04-27T13:51:48.681931Z","shell.execute_reply.started":"2022-04-27T13:51:08.518647Z","shell.execute_reply":"2022-04-27T13:51:48.681182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**霊夢:oofは「out of fold」を表すよ。  \n魔理沙:つまり、学習に使われなかったデータのことだ。**  \n\n**Reimu: oof stands for \"out of fold\".  \nMarisa: In other words, the data that wasn't used for learning.**","metadata":{}},{"cell_type":"markdown","source":"# Data Loading","metadata":{}},{"cell_type":"code","source":"def preprocess_features(features):\n    features.loc[27, 'feature_text'] = \"Last-Pap-smear-1-year-ago\"\n    return features","metadata":{"execution":{"iopub.status.busy":"2022-04-27T13:51:48.683064Z","iopub.execute_input":"2022-04-27T13:51:48.683324Z","iopub.status.idle":"2022-04-27T13:51:48.688013Z","shell.execute_reply.started":"2022-04-27T13:51:48.683288Z","shell.execute_reply":"2022-04-27T13:51:48.687346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## make pseudo-label df","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv(GCS_PATH+'test.csv')\nsubmission = pd.read_csv(GCS_PATH+'sample_submission.csv')\nfeatures = pd.read_csv(GCS_PATH+'features.csv')\npatient_notes = pd.read_csv(GCS_PATH+'patient_notes.csv')\ntrain_df = pd.read_csv(GCS_PATH+'train.csv')\nfeatures = preprocess_features(features)\n\nprint(f\"test.shape: {test.shape}\")\ndisplay(test.head())\nprint(f\"features.shape: {features.shape}\")\ndisplay(features.head())\nprint(f\"patient_notes.shape: {patient_notes.shape}\")\ndisplay(patient_notes.head())","metadata":{"execution":{"iopub.status.busy":"2022-04-27T13:51:48.689157Z","iopub.execute_input":"2022-04-27T13:51:48.689879Z","iopub.status.idle":"2022-04-27T13:51:49.376725Z","shell.execute_reply.started":"2022-04-27T13:51:48.689843Z","shell.execute_reply":"2022-04-27T13:51:49.376043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test.merge(features, on=['feature_num', 'case_num'], how='left')\ntest = test.merge(patient_notes, on=['pn_num', 'case_num'], how='left')\ndisplay(test.head())","metadata":{"execution":{"iopub.status.busy":"2022-04-27T13:51:49.377968Z","iopub.execute_input":"2022-04-27T13:51:49.378382Z","iopub.status.idle":"2022-04-27T13:51:49.407474Z","shell.execute_reply.started":"2022-04-27T13:51:49.378346Z","shell.execute_reply":"2022-04-27T13:51:49.406723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_pn_num_list=train_df['pn_num'].unique()\ns=[]\nif debug:\n    patient_notes=patient_notes[:10]\nfor i,row in patient_notes.iterrows():\n    if row['pn_num'] not in train_pn_num_list:\n        t_features=features[features['case_num']==row['case_num']]\n        for j,row_f in t_features.iterrows():\n            id=str(row['pn_num']).zfill(5)+'_'+str(row_f['feature_num']).zfill(3)\n            s.append([id,row_f['case_num'] , row['pn_num'],row_f['feature_num']])\npl_test=pd.DataFrame(s,columns=test.columns)\npl_test.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T13:51:49.410088Z","iopub.execute_input":"2022-04-27T13:51:49.410359Z","iopub.status.idle":"2022-04-27T13:52:52.2571Z","shell.execute_reply.started":"2022-04-27T13:51:49.410329Z","shell.execute_reply":"2022-04-27T13:52:52.255974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\n\nskf = StratifiedKFold(n_splits=5,shuffle=True,random_state=CFG.seed)\npl_test[\"fold\"] = -1\nfor fold, (_, valid_idx) in enumerate(skf.split(pl_test[\"id\"], y=pl_test[\"case_num\"])):\n    pl_test.loc[valid_idx, \"fold\"] = fold\npl_test.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T13:52:52.258321Z","iopub.status.idle":"2022-04-27T13:52:52.258926Z","shell.execute_reply.started":"2022-04-27T13:52:52.258695Z","shell.execute_reply":"2022-04-27T13:52:52.258719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pl_test=pl_test[pl_test['fold'] == CFG.pl_n_fold]\ndisplay(pl_test['case_num'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-04-27T13:52:52.260171Z","iopub.status.idle":"2022-04-27T13:52:52.260816Z","shell.execute_reply.started":"2022-04-27T13:52:52.260576Z","shell.execute_reply":"2022-04-27T13:52:52.260601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pl_test = pl_test.merge(features, on=['feature_num', 'case_num'], how='left')\npl_test = pl_test.merge(patient_notes, on=['pn_num', 'case_num'], how='left')\ndisplay(pl_test.head())","metadata":{"execution":{"iopub.status.busy":"2022-04-27T13:52:52.261986Z","iopub.status.idle":"2022-04-27T13:52:52.262597Z","shell.execute_reply.started":"2022-04-27T13:52:52.262373Z","shell.execute_reply":"2022-04-27T13:52:52.262397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"def prepare_input(cfg, text, feature_text):\n    inputs = cfg.tokenizer(text, feature_text, \n                           add_special_tokens=True,\n                           max_length=CFG.max_len,\n                           padding=\"max_length\",\n                           return_offsets_mapping=False)\n    for k, v in inputs.items():\n        inputs[k] = torch.tensor(v, dtype=torch.long)\n        \n    return inputs\n\n\nclass TestDataset(Dataset):\n    def __init__(self, cfg, df):\n        self.cfg = cfg\n        self.feature_texts = df['feature_text'].values\n        self.pn_historys = df['pn_history'].values\n\n    def __len__(self):\n        return len(self.feature_texts)\n\n    def __getitem__(self, item):\n        inputs = prepare_input(self.cfg, \n                               self.pn_historys[item], \n                               self.feature_texts[item])\n        \n        return inputs","metadata":{"execution":{"iopub.status.busy":"2022-04-27T13:52:52.26372Z","iopub.status.idle":"2022-04-27T13:52:52.264333Z","shell.execute_reply.started":"2022-04-27T13:52:52.264087Z","shell.execute_reply":"2022-04-27T13:52:52.26411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class ScoringModel(nn.Module):\n    def __init__(self, cfg, config_path=None, pretrained=False):\n        super().__init__()\n        self.cfg = cfg\n        \n        if config_path is None:\n            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n        else:\n            self.config = torch.load(config_path)\n        if pretrained:\n            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n        else:\n            self.model = AutoModel.from_config(self.config)\n        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n        self.fc = nn.Linear(self.config.hidden_size, 1)\n        self._init_weights(self.fc)\n        \n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, nn.Embedding):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.padding_idx is not None:\n                module.weight.data[module.padding_idx].zero_()\n        elif isinstance(module, nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n        \n    def feature(self, inputs):\n        outputs = self.model(**inputs)\n        last_hidden_states = outputs[0]\n        \n        return last_hidden_states\n\n    def forward(self, inputs):\n        feature = self.feature(inputs)\n        output = self.fc(self.fc_dropout(feature))\n        \n        return output","metadata":{"execution":{"iopub.status.busy":"2022-04-27T13:52:52.265486Z","iopub.status.idle":"2022-04-27T13:52:52.266066Z","shell.execute_reply.started":"2022-04-27T13:52:52.265843Z","shell.execute_reply":"2022-04-27T13:52:52.265867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"def inference_fn(test_loader, model, device):\n    preds = []\n    model.eval()\n    model.to(device)\n    \n    tk0 = tqdm(test_loader, total=len(test_loader))\n    for inputs in tk0:\n        for k, v in inputs.items():\n            inputs[k] = v.to(device)\n        with torch.no_grad():\n            y_preds = model(inputs)\n        preds.append(y_preds.sigmoid().to('cpu').numpy())\n    predictions = np.concatenate(preds)\n    \n    return predictions","metadata":{"execution":{"iopub.status.busy":"2022-04-27T13:52:52.267205Z","iopub.status.idle":"2022-04-27T13:52:52.267807Z","shell.execute_reply.started":"2022-04-27T13:52:52.267584Z","shell.execute_reply":"2022-04-27T13:52:52.267607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = TestDataset(CFG, pl_test)\ntest_loader = DataLoader(test_dataset,\n                         batch_size=CFG.batch_size,\n                         shuffle=False,\n                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\npredictions = []\nfor fold in CFG.trn_fold:\n    model = ScoringModel(CFG, config_path=CFG.config_path, pretrained=False)\n    \n    state = torch.load(CFG.path+f\"{CFG.model.split('/')[1]}_fold{fold}_best.pth\",\n                           map_location=torch.device('cpu'))\n       \n    model.load_state_dict(state['model'])\n    prediction = inference_fn(test_loader, model, device)\n    prediction = prediction.reshape((len(pl_test), CFG.max_len))\n    char_probs = get_char_probs(pl_test['pn_history'].values, prediction, CFG.tokenizer)\n    predictions.append(char_probs)\n    del model, state, prediction, char_probs\n    gc.collect()\n    torch.cuda.empty_cache()\n    \npredictions = np.mean(predictions, axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T13:52:52.268929Z","iopub.status.idle":"2022-04-27T13:52:52.269555Z","shell.execute_reply.started":"2022-04-27T13:52:52.26933Z","shell.execute_reply":"2022-04-27T13:52:52.269354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"results = get_results(predictions, th=0.48)\npl_train=pl_test.copy()\npl_train=pl_train.drop(['feature_text','pn_history'],axis=1)\npl_train['location'] = results\nif CFG.NO_ZERO:\n    pl_train['location2']=pl_train['location'].str.split(';')\n    pl_train=pl_train.fillna({'location2':''})\n    pl_train['annotation_length'] = pl_train['location2'].apply(len)\n    pl_train=pl_train[pl_train['annotation_length']>0]\n    pl_train=pl_train.drop(['annotation_length','location2'],axis=1)\ndisplay(pl_train.head())\npl_train.to_csv('pl_train1.csv', index=False)\n#submission['location'] = results\n#display(submission.head())\n#submission[['id', 'location']].to_csv('pl_train.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T13:52:52.270682Z","iopub.status.idle":"2022-04-27T13:52:52.271307Z","shell.execute_reply.started":"2022-04-27T13:52:52.271058Z","shell.execute_reply":"2022-04-27T13:52:52.271082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**霊夢:submissionファイルができた。提出してみよう。**  \n\n**Reimu: The submission file is ready. Let's submit it.**","metadata":{}}]}