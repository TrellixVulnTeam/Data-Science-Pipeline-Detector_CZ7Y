{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/kuangliu/pytorch-cifar.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-05T07:38:20.719989Z","iopub.execute_input":"2022-04-05T07:38:20.720599Z","iopub.status.idle":"2022-04-05T07:38:22.229701Z","shell.execute_reply.started":"2022-04-05T07:38:20.720496Z","shell.execute_reply":"2022-04-05T07:38:22.228863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd pytorch-cifar","metadata":{"execution":{"iopub.status.busy":"2022-04-05T07:38:22.231557Z","iopub.execute_input":"2022-04-05T07:38:22.231909Z","iopub.status.idle":"2022-04-05T07:38:22.238256Z","shell.execute_reply.started":"2022-04-05T07:38:22.231872Z","shell.execute_reply":"2022-04-05T07:38:22.237581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile models/resnet.py\n\n'''ResNet in PyTorch.\n\nFor Pre-activation ResNet, see 'preact_resnet.py'.\n\nReference:\n[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n'''\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom torch.nn.parameter import Parameter\nfrom torch.nn.modules import Module\n\nclass mySequential(nn.Sequential):\n    def forward(self, *inputs):\n        for module in self._modules.values():\n            if type(inputs) == tuple:\n#                 print(len(inputs[0]))\n                inputs = module(*inputs)\n            else:\n                inputs = module(inputs)\n        return inputs\n    \nclass BatchNorm2d(Module):\n    \"\"\"\n    Module for Virtual Batch Normalization.\n\n    Implementation borrowed and modified from Rafael_Valle's code + help of SimonW from this discussion thread:\n    https://discuss.pytorch.org/t/parameter-grad-of-conv-weight-is-none-after-virtual-batch-normalization/9036\n    \"\"\"\n    def __init__(self, num_features: int, eps: float=1e-5):\n        super().__init__()\n        # batch statistics\n        self.num_features = num_features\n        self.eps = eps  # epsilon\n        self.ref_mean = self.register_parameter('ref_mean', None)\n        self.ref_mean_sq = self.register_parameter('ref_mean_sq', None)\n\n        # define gamma and beta parameters\n        gamma = torch.normal(mean=torch.ones(1, num_features, 1, 1), std=0.02)\n        self.gamma = Parameter(gamma.float().cuda(non_blocking=False))\n        self.beta = Parameter(torch.cuda.FloatTensor(1, num_features, 1, 1).fill_(0))\n\n    def get_stats(self, x):\n        \"\"\"\n        Calculates mean and mean square for given batch x.\n        Args:\n            x: tensor containing batch of activations\n        Returns:\n            mean: mean tensor over features\n            mean_sq: squared mean tensor over features\n        \"\"\"\n        mean = x.mean(2, keepdim=True).mean(0, keepdim=True)\n        mean_sq = (x ** 2).mean(2, keepdim=True).mean(0, keepdim=True)\n        return mean, mean_sq\n\n    def forward(self, x, ref_mean= None, ref_mean_sq= None):\n        \"\"\"\n        Forward pass of virtual batch normalization.\n        Virtual batch normalization require two forward passes\n        for reference batch and train batch, respectively.\n        The input parameter is_reference should indicate whether it is a forward pass\n        for reference batch or not.\n\n        Args:\n            x: input tensor\n            is_reference(bool): True if forwarding for reference batch\n        Result:\n            x: normalized batch tensor\n        \"\"\"\n        mean, mean_sq = self.get_stats(x)\n        if ref_mean is None or ref_mean_sq is None:\n            # reference mode - works just like batch norm\n            mean = mean.clone().detach()\n            mean_sq = mean_sq.clone().detach()\n            out = self._normalize(x, mean, mean_sq)\n        else:\n            # calculate new mean and mean_sq\n            batch_size = x.size(0)\n            new_coeff = 1. / (batch_size + 1.)\n            old_coeff = 1. - new_coeff\n            mean = new_coeff * mean + old_coeff * ref_mean\n            mean_sq = new_coeff * mean_sq + old_coeff * ref_mean_sq\n            out = self._normalize(x, mean, mean_sq)\n        return out, mean, mean_sq\n\n    def _normalize(self, x, mean, mean_sq):\n        \"\"\"\n        Normalize tensor x given the statistics.\n\n        Args:\n            x: input tensor\n            mean: mean over features. it has size [1:num_features:]\n            mean_sq: squared means over features.\n\n        Result:\n            x: normalized batch tensor\n        \"\"\"\n        assert mean_sq is not None\n        assert mean is not None\n        assert len(x.size()) == 4  # specific for 1d VBN\n        if mean.size(1) != self.num_features:\n            raise Exception(\n                    'Mean size not equal to number of featuers : given {}, expected {}'\n                    .format(mean.size(1), self.num_features))\n        if mean_sq.size(1) != self.num_features:\n            raise Exception(\n                    'Squared mean tensor size not equal to number of features : given {}, expected {}'\n                    .format(mean_sq.size(1), self.num_features))\n\n        std = torch.sqrt(self.eps + mean_sq - mean**2)\n        x = x - mean\n        x = x / std\n        x = x * self.gamma\n        x = x + self.beta\n        return x\n\n    def __repr__(self):\n        return ('{name}(num_features={num_features}, eps={eps}'\n                .format(name=self.__class__.__name__, **self.__dict__))\n    \n\n\n\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1, ex=1):\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(\n            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n                               stride=1, padding=1, bias=False)\n        self.bn2 = BatchNorm2d(planes)\n\n        self.shortcut = False\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = True\n            self.downsample = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes,\n                          kernel_size=1, stride=stride, bias=False)\n            )\n            self.vt2 = BatchNorm2d(planes * ex)\n            \n    def forward(self, x, ref_x):\n        identity = x\n        identity2 = ref_x\n        ref_x, mean1, mq1 = self.bn1(self.conv1(ref_x))\n        ref_x = F.relu(ref_x)\n        ref_x, mean2, mq2 = self.bn2(self.conv2(ref_x))\n        ref_x = F.relu(ref_x)\n        if self.shortcut:\n            identity2 = self.downsample(identity2)\n            identity2, mean3, mq3  = self.vt2(identity2)\n        ref_x += identity2\n        ref_x = F.relu(ref_x)\n        \n        x, _, _ = self.bn1(self.conv1(x), mean1, mq1)\n        x = F.relu(x)\n        x, _, _ = self.bn2(self.conv2(x), mean2, mq2)\n        x = F.relu(x)\n        if self.shortcut:\n            identity = self.downsample(identity)\n            identity, _, _  = self.vt2(identity, mean3, mq3)\n        x += identity\n        x = F.relu(x)\n        \n        return x, ref_x\n\n\nclass Bottleneck(nn.Module):\n    expansion = 4\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n        self.bn1 = BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n                               stride=stride, padding=1, bias=False)\n        self.bn2 = BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, self.expansion *\n                               planes, kernel_size=1, bias=False)\n        self.bn3 = BatchNorm2d(self.expansion*planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(self.expansion*planes)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = F.relu(self.bn2(self.conv2(out)))\n        out = self.bn3(self.conv3(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\n\nclass ResNet(nn.Module):\n    def __init__(self, block, num_blocks, num_classes=10):\n        super(ResNet, self).__init__()\n        self.in_planes = 64\n\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n                               stride=1, padding=1, bias=False)\n        self.bn1 = BatchNorm2d(64)\n        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n        self.linear = nn.Linear(512*block.expansion, num_classes)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride, ex= block.expansion))\n            self.in_planes = planes * block.expansion\n        return mySequential(*layers)\n\n    def forward(self, x, ref_x):\n        \n        ref_x, mean1, mq1 = self.bn1(self.conv1(ref_x))\n        ref_x = F.relu(ref_x)\n        x, _, _ = self.bn1(self.conv1(x), mean1, mq1)\n        x = F.relu(x)\n        x, ref_x = self.layer1(x, ref_x)\n        x, ref_x = self.layer2(x, ref_x)\n        x, ref_x = self.layer3(x, ref_x)\n        x, ref_x = self.layer4(x, ref_x)\n        x = F.avg_pool2d(x, 4)\n        x = x.view(x.size(0), -1)\n        x = self.linear(x)\n        return x\n\n\ndef ResNet18():\n    return ResNet(BasicBlock, [2, 2, 2, 2])\n\n\ndef ResNet34():\n    return ResNet(BasicBlock, [3, 4, 6, 3])\n\n\ndef ResNet50():\n    return ResNet(Bottleneck, [3, 4, 6, 3])\n\n\ndef ResNet101():\n    return ResNet(Bottleneck, [3, 4, 23, 3])\n\n\ndef ResNet152():\n    return ResNet(Bottleneck, [3, 8, 36, 3])\n\n\ndef test():\n    net = ResNet18()\n    y = net(torch.randn(1, 3, 32, 32))\n    print(y.size())\n\n# test()","metadata":{"execution":{"iopub.status.busy":"2022-04-05T07:38:22.240119Z","iopub.execute_input":"2022-04-05T07:38:22.240679Z","iopub.status.idle":"2022-04-05T07:38:22.254493Z","shell.execute_reply.started":"2022-04-05T07:38:22.240643Z","shell.execute_reply":"2022-04-05T07:38:22.253724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile cifar10.py\n\n\nimport os.path\nimport pickle\nfrom typing import Any, Callable, Optional, Tuple\n\nimport numpy as np\nfrom PIL import Image\n\nfrom torchvision.datasets.utils import check_integrity, download_and_extract_archive\nfrom torchvision.datasets.vision import VisionDataset\n\n\n\nclass CIFAR10(VisionDataset):\n    \"\"\"`CIFAR10 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ Dataset.\n\n    Args:\n        root (string): Root directory of dataset where directory\n            ``cifar-10-batches-py`` exists or will be saved to if download is set to True.\n        train (bool, optional): If True, creates dataset from training set, otherwise\n            creates from test set.\n        transform (callable, optional): A function/transform that takes in an PIL image\n            and returns a transformed version. E.g, ``transforms.RandomCrop``\n        target_transform (callable, optional): A function/transform that takes in the\n            target and transforms it.\n        download (bool, optional): If true, downloads the dataset from the internet and\n            puts it in root directory. If dataset is already downloaded, it is not\n            downloaded again.\n\n    \"\"\"\n\n    base_folder = \"cifar-10-batches-py\"\n    url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n    filename = \"cifar-10-python.tar.gz\"\n    tgz_md5 = \"c58f30108f718f92721af3b95e74349a\"\n    train_list = [\n        [\"data_batch_1\", \"c99cafc152244af753f735de768cd75f\"],\n        [\"data_batch_2\", \"d4bba439e000b95fd0a9bffe97cbabec\"],\n        [\"data_batch_3\", \"54ebc095f3ab1f0389bbae665268c751\"],\n        [\"data_batch_4\", \"634d18415352ddfa80567beed471001a\"],\n        [\"data_batch_5\", \"482c414d41f54cd18b22e5b47cb7c3cb\"],\n    ]\n\n    test_list = [\n        [\"test_batch\", \"40351d587109b95175f43aff81a1287e\"],\n    ]\n    meta = {\n        \"filename\": \"batches.meta\",\n        \"key\": \"label_names\",\n        \"md5\": \"5ff9c542aee3614f3951f8cda6e48888\",\n    }\n\n    def __init__(\n        self,\n        root: str,\n        train: bool = True,\n        transform: Optional[Callable] = None,\n        transform2: Optional[Callable] = None,\n        target_transform: Optional[Callable] = None,\n        download: bool = False,\n    ) -> None:\n\n        super().__init__(root, transform=transform, target_transform=target_transform)\n\n        self.train = train  # training set or test set\n\n        if download:\n            self.download()\n        self.transform2 = transform2\n\n        if not self._check_integrity():\n            raise RuntimeError(\"Dataset not found or corrupted. You can use download=True to download it\")\n\n        if self.train:\n            downloaded_list = self.train_list\n        else:\n            downloaded_list = self.test_list\n\n        self.data: Any = []\n        self.targets = []\n\n        # now load the picked numpy arrays\n        for file_name, checksum in downloaded_list:\n            file_path = os.path.join(self.root, self.base_folder, file_name)\n            with open(file_path, \"rb\") as f:\n                entry = pickle.load(f, encoding=\"latin1\")\n                self.data.append(entry[\"data\"])\n                if \"labels\" in entry:\n                    self.targets.extend(entry[\"labels\"])\n                else:\n                    self.targets.extend(entry[\"fine_labels\"])\n\n        self.data = np.vstack(self.data).reshape(-1, 3, 32, 32)\n        self.data = self.data.transpose((0, 2, 3, 1))  # convert to HWC\n\n        self._load_meta()\n\n    def _load_meta(self) -> None:\n        path = os.path.join(self.root, self.base_folder, self.meta[\"filename\"])\n        if not check_integrity(path, self.meta[\"md5\"]):\n            raise RuntimeError(\"Dataset metadata file not found or corrupted. You can use download=True to download it\")\n        with open(path, \"rb\") as infile:\n            data = pickle.load(infile, encoding=\"latin1\")\n            self.classes = data[self.meta[\"key\"]]\n        self.class_to_idx = {_class: i for i, _class in enumerate(self.classes)}\n\n\n    def __getitem__(self, index: int) -> Tuple[Any, Any]:\n        \"\"\"\n        Args:\n            index (int): Index\n\n        Returns:\n            tuple: (image, target) where target is index of the target class.\n        \"\"\"\n        img, target = self.data[index], self.targets[index]\n\n        # doing this so that it is consistent with all other datasets\n        # to return a PIL Image\n        img = Image.fromarray(img)\n        ref_img = img\n        if self.transform is not None:\n            img = self.transform(img)\n        \n        if self.transform2 is not None:\n            ref_img = self.transform2(ref_img)\n\n        if self.target_transform is not None:\n            target = self.target_transform(target)\n\n        return img, ref_img, target\n\n\n    def __len__(self) -> int:\n        return len(self.data)\n\n    def _check_integrity(self) -> bool:\n        root = self.root\n        for fentry in self.train_list + self.test_list:\n            filename, md5 = fentry[0], fentry[1]\n            fpath = os.path.join(root, self.base_folder, filename)\n            if not check_integrity(fpath, md5):\n                return False\n        return True\n\n    def download(self) -> None:\n        if self._check_integrity():\n            print(\"Files already downloaded and verified\")\n            return\n        download_and_extract_archive(self.url, self.root, filename=self.filename, md5=self.tgz_md5)\n\n    def extra_repr(self) -> str:\n        split = \"Train\" if self.train is True else \"Test\"\n        return f\"Split: {split}\"\n\n\n\n\nclass CIFAR100(CIFAR10):\n    \"\"\"`CIFAR100 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ Dataset.\n\n    This is a subclass of the `CIFAR10` Dataset.\n    \"\"\"\n\n    base_folder = \"cifar-100-python\"\n    url = \"https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\"\n    filename = \"cifar-100-python.tar.gz\"\n    tgz_md5 = \"eb9058c3a382ffc7106e4002c42a8d85\"\n    train_list = [\n        [\"train\", \"16019d7e3df5f24257cddd939b257f8d\"],\n    ]\n\n    test_list = [\n        [\"test\", \"f0ef6b0ae62326f3e7ffdfab6717acfc\"],\n    ]\n    meta = {\n        \"filename\": \"meta\",\n        \"key\": \"fine_label_names\",\n        \"md5\": \"7973b15100ade9c7d40fb424638fde48\",\n    }\n","metadata":{"execution":{"iopub.status.busy":"2022-04-05T07:38:22.257121Z","iopub.execute_input":"2022-04-05T07:38:22.257639Z","iopub.status.idle":"2022-04-05T07:38:22.269509Z","shell.execute_reply.started":"2022-04-05T07:38:22.257594Z","shell.execute_reply":"2022-04-05T07:38:22.26881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile main.py\n\n\nfrom cifar10 import CIFAR10\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torch.backends.cudnn as cudnn\n\nimport torchvision\nimport torchvision.transforms as transforms\n\nimport os\nimport argparse\n\nfrom models import *\nfrom utils import progress_bar\n\n\nparser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\nparser.add_argument('--lr', default=0.1, type=float, help='learning rate')\nparser.add_argument('--resume', '-r', action='store_true',\n                    help='resume from checkpoint')\nargs = parser.parse_args()\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nbest_acc = 0  # best test accuracy\nstart_epoch = 0  # start from epoch 0 or last checkpoint epoch\n\n# Data\nprint('==> Preparing data..')\ntransform_train = transforms.Compose([\n    transforms.RandomCrop(32, padding=4),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n\ntransform_test = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n\ntrainset = CIFAR10(\n    root='./data', train=True, download=True, transform=transform_train, transform2 = transform_test)\ntrainloader = torch.utils.data.DataLoader(\n    trainset, batch_size=128, shuffle=True, num_workers=2)\n\ntestset = CIFAR10(\n    root='./data', train=False, download=True, transform=transform_test, transform2 = transform_test)\ntestloader = torch.utils.data.DataLoader(\n    testset, batch_size=100, shuffle=False, num_workers=2)\n\nclasses = ('plane', 'car', 'bird', 'cat', 'deer',\n           'dog', 'frog', 'horse', 'ship', 'truck')\n\n# Model\nprint('==> Building model..')\nnet = ResNet18()\nnet = net.to(device)\nif device == 'cuda':\n    net = torch.nn.DataParallel(net)\n    cudnn.benchmark = True\n\nif args.resume:\n    # Load checkpoint.\n    print('==> Resuming from checkpoint..')\n    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n    checkpoint = torch.load('./checkpoint/ckpt.pth')\n    net.load_state_dict(checkpoint['net'])\n    best_acc = checkpoint['acc']\n    start_epoch = checkpoint['epoch']\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=args.lr,\n                      momentum=0.9, weight_decay=5e-4)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n\n\n# Training\ndef train(epoch):\n    print('\\nEpoch: %d' % epoch)\n    net.train()\n    train_loss = 0\n    correct = 0\n    total = 0\n#     ref_x = next(iter(trainloader))[0].to(device)\n    for batch_idx, (inputs, ref_x, targets) in enumerate(trainloader):\n        inputs, ref_x, targets = inputs.to(device), ref_x.to(device), targets.to(device)\n        optimizer.zero_grad()\n        outputs = net(inputs, ref_x)\n        loss = criterion(outputs, targets)\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += targets.size(0)\n        correct += predicted.eq(targets).sum().item()\n\n        progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n                     % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n\n\ndef test(epoch):\n    global best_acc\n    net.eval()\n    test_loss = 0\n    correct = 0\n    total = 0\n#     ref_x = next(iter(trainloader))[0].to(device)\n    with torch.no_grad():\n        for batch_idx, (inputs, ref_x, targets) in enumerate(trainloader):\n            inputs, ref_x, targets = inputs.to(device), ref_x.to(device), targets.to(device)\n            outputs = net(inputs, ref_x)\n            loss = criterion(outputs, targets)\n\n            test_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += targets.size(0)\n            correct += predicted.eq(targets).sum().item()\n\n            progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n                         % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n\n    # Save checkpoint.\n    acc = 100.*correct/total\n    if acc > best_acc:\n        print('Saving..')\n        state = {\n            'net': net.state_dict(),\n            'acc': acc,\n            'epoch': epoch,\n        }\n        if not os.path.isdir('checkpoint'):\n            os.mkdir('checkpoint')\n        torch.save(state, './checkpoint/ckpt.pth')\n        best_acc = acc\n\n\nfor epoch in range(start_epoch, start_epoch+200):\n    train(epoch)\n    test(epoch)\n    scheduler.step()\n    ","metadata":{"execution":{"iopub.status.busy":"2022-04-05T07:38:22.271018Z","iopub.execute_input":"2022-04-05T07:38:22.271381Z","iopub.status.idle":"2022-04-05T07:38:22.282307Z","shell.execute_reply.started":"2022-04-05T07:38:22.271344Z","shell.execute_reply":"2022-04-05T07:38:22.281461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python main.py","metadata":{"execution":{"iopub.status.busy":"2022-04-05T07:38:22.284836Z","iopub.execute_input":"2022-04-05T07:38:22.285573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/MadryLab/robustness.git","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd robustness","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile robustness/attacker.py\n\"\"\"\n**For most use cases, this can just be considered an internal class and\nignored.**\n\nThis module houses the :class:`robustness.attacker.Attacker` and\n:class:`robustness.attacker.AttackerModel` classes. \n\n:class:`~robustness.attacker.Attacker` is an internal class that should not be\nimported/called from outside the library.\n:class:`~robustness.attacker.AttackerModel` is a \"wrapper\" class which is fed a\nmodel and adds to it adversarial attack functionalities as well as other useful\noptions. See :meth:`robustness.attacker.AttackerModel.forward` for documentation\non which arguments AttackerModel supports, and see\n:meth:`robustness.attacker.Attacker.forward` for the arguments pertaining to\nadversarial examples specifically.\n\nFor a demonstration of this module in action, see the walkthrough\n\":doc:`../example_usage/input_space_manipulation`\"\n\n**Note 1**: :samp:`.forward()` should never be called directly but instead the\nAttackerModel object itself should be called, just like with any\n:samp:`nn.Module` subclass.\n\n**Note 2**: Even though the adversarial example arguments are documented in\n:meth:`robustness.attacker.Attacker.forward`, this function should never be\ncalled directly---instead, these arguments are passed along from\n:meth:`robustness.attacker.AttackerModel.forward`.\n\"\"\"\n\n\nimport torch as ch\nimport dill\nimport os\nif int(os.environ.get(\"NOTEBOOK_MODE\", 0)) == 1:\n    from tqdm import tqdm_notebook as tqdm\nelse:\n    from tqdm import tqdm\n\nfrom .tools import helpers\nfrom . import attack_steps\n\nSTEPS = {\n    'inf': attack_steps.LinfStep,\n    '2': attack_steps.L2Step,\n    'unconstrained': attack_steps.UnconstrainedStep,\n    'fourier': attack_steps.FourierStep,\n    'random_smooth': attack_steps.RandomStep\n}\n\nclass Attacker(ch.nn.Module):\n    \"\"\"\n    Attacker class, used to make adversarial examples.\n\n    This is primarily an internal class, you probably want to be looking at\n    :class:`robustness.attacker.AttackerModel`, which is how models are actually\n    served (AttackerModel uses this Attacker class).\n\n    However, the :meth:`robustness.Attacker.forward` function below\n    documents the arguments supported for adversarial attacks specifically.\n    \"\"\"\n    def __init__(self, model, dataset):\n        \"\"\"\n        Initialize the Attacker\n\n        Args:\n            nn.Module model : the PyTorch model to attack\n            Dataset dataset : dataset the model is trained on, only used to get mean and std for normalization\n        \"\"\"\n        super(Attacker, self).__init__()\n        self.normalize = helpers.InputNormalize(dataset.mean, dataset.std)\n        self.model = model\n\n    def forward(self, x,ref_x, target, *_, constraint, eps, step_size, iterations, with_latent=False,\n                random_start=False, random_restarts=False, do_tqdm=False,\n                targeted=False, custom_loss=None, should_normalize=True,\n                orig_input=None, use_best=True, return_image=True,\n                est_grad=None, mixed_precision=False):\n        \"\"\"\n        Implementation of forward (finds adversarial examples). Note that\n        this does **not** perform inference and should not be called\n        directly; refer to :meth:`robustness.attacker.AttackerModel.forward`\n        for the function you should actually be calling.\n\n        Args:\n            x, target (ch.tensor) : see :meth:`robustness.attacker.AttackerModel.forward`\n            constraint\n                (\"2\"|\"inf\"|\"unconstrained\"|\"fourier\"|:class:`~robustness.attack_steps.AttackerStep`)\n                : threat model for adversarial attacks (:math:`\\ell_2` ball,\n                :math:`\\ell_\\infty` ball, :math:`[0, 1]^n`, Fourier basis, or\n                custom AttackerStep subclass).\n            eps (float) : radius for threat model.\n            step_size (float) : step size for adversarial attacks.\n            iterations (int): number of steps for adversarial attacks.\n            random_start (bool) : if True, start the attack with a random step.\n            random_restarts (bool) : if True, do many random restarts and\n                take the worst attack (in terms of loss) per input.\n            do_tqdm (bool) : if True, show a tqdm progress bar for the attack.\n            targeted (bool) : if True (False), minimize (maximize) the loss.\n            custom_loss (function|None) : if provided, used instead of the\n                criterion as the loss to maximize/minimize during\n                adversarial attack. The function should take in\n                :samp:`model, x, target` and return a tuple of the form\n                :samp:`loss, None`, where loss is a tensor of size N\n                (per-element loss).\n            should_normalize (bool) : If False, don't normalize the input\n                (not recommended unless normalization is done in the\n                custom_loss instead).\n            orig_input (ch.tensor|None) : If not None, use this as the\n                center of the perturbation set, rather than :samp:`x`.\n            use_best (bool) : If True, use the best (in terms of loss)\n                iterate of the attack process instead of just the last one.\n            return_image (bool) : If True (default), then return the adversarial\n                example as an image, otherwise return it in its parameterization\n                (for example, the Fourier coefficients if 'constraint' is\n                'fourier')\n            est_grad (tuple|None) : If not None (default), then these are\n                :samp:`(query_radius [R], num_queries [N])` to use for estimating the\n                gradient instead of autograd. We use the spherical gradient\n                estimator, shown below, along with antithetic sampling [#f1]_\n                to reduce variance:\n                :math:`\\\\nabla_x f(x) \\\\approx \\\\sum_{i=0}^N f(x + R\\\\cdot\n                \\\\vec{\\\\delta_i})\\\\cdot \\\\vec{\\\\delta_i}`, where\n                :math:`\\delta_i` are randomly sampled from the unit ball.\n            mixed_precision (bool) : if True, use mixed-precision calculations\n                to compute the adversarial examples / do the inference.\n        Returns:\n            An adversarial example for x (i.e. within a feasible set\n            determined by `eps` and `constraint`, but classified as:\n\n            * `target` (if `targeted == True`)\n            *  not `target` (if `targeted == False`)\n\n        .. [#f1] This means that we actually draw :math:`N/2` random vectors\n            from the unit ball, and then use :math:`\\delta_{N/2+i} =\n            -\\delta_{i}`.\n        \"\"\"\n        # Can provide a different input to make the feasible set around\n        # instead of the initial point\n        if orig_input is None: orig_input = x.detach()\n        orig_input = orig_input.cuda()\n\n        # Multiplier for gradient ascent [untargeted] or descent [targeted]\n        m = -1 if targeted else 1\n\n        # Initialize step class and attacker criterion\n        criterion = ch.nn.CrossEntropyLoss(reduction='none')\n        step_class = STEPS[constraint] if isinstance(constraint, str) else constraint\n        step = step_class(eps=eps, orig_input=orig_input, step_size=step_size) \n\n        def calc_loss(inp, ref_inp,  target):\n            '''\n            Calculates the loss of an input with respect to target labels\n            Uses custom loss (if provided) otherwise the criterion\n            '''\n            if should_normalize:\n                inp = self.normalize(inp)\n                \n            if should_normalize:\n                ref_inp = self.normalize(ref_inp)\n            output = self.model(inp, ref_inp)\n            if custom_loss:\n                return custom_loss(self.model, inp, target)\n\n            return criterion(output, target), output\n\n        # Main function for making adversarial examples\n        def get_adv_examples(x):\n            # Random start (to escape certain types of gradient masking)\n            if random_start:\n                x = step.random_perturb(x)\n            \n            \n            iterator = range(iterations)\n            if do_tqdm: iterator = tqdm(iterator)\n\n            # Keep track of the \"best\" (worst-case) loss and its\n            # corresponding input\n            best_loss = None\n            best_x = None\n\n            # A function that updates the best loss and best input\n            def replace_best(loss, bloss, x, bx):\n                if bloss is None:\n                    bx = x.clone().detach()\n                    bloss = loss.clone().detach()\n                else:\n                    replace = m * bloss < m * loss\n                    bx[replace] = x[replace].clone().detach()\n                    bloss[replace] = loss[replace]\n\n                return bloss, bx\n\n            # PGD iterates\n            for _ in iterator:\n                x = x.clone().detach().requires_grad_(True)\n                rè_x = ref_x.clone().detach().requires_grad_(True)\n                losses, out = calc_loss(step.to_image(x), step.to_image(ref_x) , target)\n                assert losses.shape[0] == x.shape[0], \\\n                        'Shape of losses must match input!'\n\n                loss = ch.mean(losses)\n\n                if step.use_grad:\n                    if (est_grad is None) and mixed_precision:\n                        with amp.scale_loss(loss, []) as sl:\n                            sl.backward()\n                        grad = x.grad.detach()\n                        x.grad.zero_()\n                    elif (est_grad is None):\n                        grad, = ch.autograd.grad(m * loss, [x])\n                    else:\n                        f = lambda _x, _y: m * calc_loss(step.to_image(_x), _y)[0]\n                        grad = helpers.calc_est_grad(f, x, target, *est_grad)\n                else:\n                    grad = None\n\n                with ch.no_grad():\n                    args = [losses, best_loss, x, best_x]\n                    best_loss, best_x = replace_best(*args) if use_best else (losses, x)\n\n                    x = step.step(x, grad)\n                    x = step.project(x)\n                    if do_tqdm: iterator.set_description(\"Current loss: {l}\".format(l=loss))\n\n            # Save computation (don't compute last loss) if not use_best\n            if not use_best: \n                ret = x.clone().detach()\n                return step.to_image(ret) if return_image else ret\n\n            losses, _ = calc_loss(step.to_image(x),step.to_image(ref_x), target)\n            args = [losses, best_loss, x, best_x]\n            best_loss, best_x = replace_best(*args)\n            return step.to_image(best_x) if return_image else best_x\n\n        # Random restarts: repeat the attack and find the worst-case\n        # example for each input in the batch\n        if random_restarts:\n            to_ret = None\n\n            orig_cpy = x.clone().detach()\n            ref_orig_cpy = ref_x.clone().detach()\n            for _ in range(random_restarts):\n                adv = get_adv_examples(orig_cpy)\n                ref_adv = get_adv_examples(ref_orig_cpy)\n\n                if to_ret is None:\n                    to_ret = adv.detach()\n\n                _, output = calc_loss(adv,ref_adv, target)\n                corr, = helpers.accuracy(output, target, topk=(1,), exact=True)\n                corr = corr.byte()\n                misclass = ~corr\n                to_ret[misclass] = adv[misclass]\n\n            adv_ret = to_ret\n        else:\n            adv_ret = get_adv_examples(x)\n            red_adv_ret = get_adv_examples(ref_x)\n\n        return adv_ret, red_adv_ret\n\nclass AttackerModel(ch.nn.Module):\n    \"\"\"\n    Wrapper class for adversarial attacks on models. Given any normal\n    model (a ``ch.nn.Module`` instance), wrapping it in AttackerModel allows\n    for convenient access to adversarial attacks and other applications.::\n\n        model = ResNet50()\n        model = AttackerModel(model)\n        x = ch.rand(10, 3, 32, 32) # random images\n        y = ch.zeros(10) # label 0\n        out, new_im = model(x, y, make_adv=True) # adversarial attack\n        out, new_im = model(x, y, make_adv=True, targeted=True) # targeted attack\n        out = model(x) # normal inference (no label needed)\n\n    More code examples available in the documentation for `forward`.\n    For a more comprehensive overview of this class, see \n    :doc:`our detailed walkthrough <../example_usage/input_space_manipulation>`.\n    \"\"\"\n    def __init__(self, model, dataset):\n        super(AttackerModel, self).__init__()\n        self.normalizer = helpers.InputNormalize(dataset.mean, dataset.std)\n        self.model = model\n        self.attacker = Attacker(model, dataset)\n\n    def forward(self, inp, ref_inp,  target=None, make_adv=False,\n                fake_relu=False, no_relu=False, with_image=True, **attacker_kwargs):\n        \"\"\"\n        Main function for running inference and generating adversarial\n        examples for a model.\n\n        Parameters:\n            inp (ch.tensor) : input to do inference on [N x input_shape] (e.g. NCHW)\n            target (ch.tensor) : ignored if `make_adv == False`. Otherwise,\n                labels for adversarial attack.\n            make_adv (bool) : whether to make an adversarial example for\n                the model. If true, returns a tuple of the form\n                :samp:`(model_prediction, adv_input)` where\n                :samp:`model_prediction` is a tensor with the *logits* from\n                the network.\n            with_latent (bool) : also return the second-last layer along\n                with the logits. Output becomes of the form\n                :samp:`((model_logits, model_layer), adv_input)` if\n                :samp:`make_adv==True`, otherwise :samp:`(model_logits, model_layer)`.\n            fake_relu (bool) : useful for activation maximization. If\n                :samp:`True`, replace the ReLUs in the last layer with\n                \"fake ReLUs,\" which are ReLUs in the forwards pass but\n                identity in the backwards pass (otherwise, maximizing a\n                ReLU which is dead is impossible as there is no gradient).\n            no_relu (bool) : If :samp:`True`, return the latent output with\n                the (pre-ReLU) output of the second-last layer, instead of the\n                post-ReLU output. Requires :samp:`fake_relu=False`, and has no\n                visible effect without :samp:`with_latent=True`.\n            with_image (bool) : if :samp:`False`, only return the model output\n                (even if :samp:`make_adv == True`).\n\n        \"\"\"\n        if make_adv:\n            assert target is not None\n            prev_training = bool(self.training)\n            self.eval()\n            adv, ref_adv = self.attacker(inp, ref_inp, target, **attacker_kwargs)\n            if prev_training:\n                self.train()\n\n            inp = adv\n            ref_inp = ref_adv\n\n        normalized_inp = self.normalizer(inp)\n        ref_normalized_inp = self.normalizer(ref_inp)\n        \n        if no_relu and (not with_latent):\n            print(\"WARNING: 'no_relu' has no visible effect if 'with_latent is False.\")\n        if no_relu and fake_relu:\n            raise ValueError(\"Options 'no_relu' and 'fake_relu' are exclusive\")\n\n        output = self.model(normalized_inp,  ref_normalized_inp)\n        if with_image:\n            return (output, ref_inp, inp)\n        return output\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install cox","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working/pytorch-cifar","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working/pytorch-cifar/robustness/\n# %cd ..","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile score.py\n\nfrom robustness.datasets import CIFAR\nfrom robustness.model_utils import make_and_restore_model\nimport sys \nsys.path.append('..')\nfrom models import *\nimport torch\nfrom tqdm import tqdm\n\nimport gc\ngc.collect()\ndevice = \"cuda:0\"\nnet = ResNet18().to(device)\nnet = torch.nn.DataParallel(net)\n\nfor seed in [2019, 2020, 2021]:\n#     net = ResNet18().to(device)\n    checkpoint = torch.load('../checkpoint/ckpt.pth')\n    net.load_state_dict(checkpoint['net'])\n#     net.load_state_dict(torch.load(\"../checkpoint/ckpt.pth\")['net'])\n    ds = CIFAR('../data')\n    net.eval()\n    m, _ = make_and_restore_model(arch=net, dataset=ds, add_custom_forward=False)\n    m.eval()\n    _, test_loader = ds.make_loaders(workers=4, batch_size=28)\n    _, (im, label) = next(enumerate(test_loader))\n\n    def test_model_adv_accuracy(m, model, dataloader, kwargs):\n        correct = 0\n        total = 0\n#         ref_x = next(iter(dataloader))[0].cuda()\n        bar = tqdm(enumerate(dataloader), total=len(dataloader))\n        for _, (x, y) in bar:\n            ref_x = x.clone().cuda()\n            _, ref_adv, x_adv_pgd_hard = m(x.cuda(), ref_x, y.cuda(), make_adv=True, **kwargs)\n\n            outputs = net(x_adv_pgd_hard, ref_adv)\n            _, predicted = torch.max(outputs.data, 1)\n            total += y.size(0)\n            correct += (predicted == y.cuda()).sum().item()\n            bar.set_postfix(\n            correct=correct/total\n        )\n\n        print(\"adv accuracy: \", correct / total)\n\n        return correct / total\n\n    for adv_epsilon in [0.1, 0.5, 1, 2, 4]:\n        kwargs = {\n        'constraint':'2', # use L2-PGD\n        'eps': adv_epsilon, # L2 radius around original image\n        'step_size': 1,\n        'iterations': 100,\n        'do_tqdm': False,\n    }\n        temp_adv_acc = test_model_adv_accuracy(m, net, test_loader, kwargs)\n        print(\"adv_epsilon\", adv_epsilon, \"seed\", seed)\n#             robustness_dict[adv_epsilon] = robustness_dict.setdefault(adv_epsilon, default=[]).append(adv_epsilon)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python score.py","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}