{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Intro\nCompetition home page: https://www.kaggle.com/competitions/nbme-score-clinical-patient-notes\n\nThis notebook is a starter kit for a transfer learning by Transformers pre-trainded models. \n\nWe employ the code from the following references.\n\n* Hugging Face - Fine tune NER models: https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/token_classification.ipynb\n\n* Hugging Face - Create a dataset loading script: https://huggingface.co/docs/datasets/dataset_script\n \n* Hugging Face - dataset loading script template: https://github.com/huggingface/datasets/blob/master/datasets/wnut_17/wnut_17.py\n\nFor training, we use the conll data converted by https://www.kaggle.com/code/crischir/nbme2-conll-via-spacy. This data will be imported by the utility script under usr/lib from Github.\n\nFor prediction, we use Transformers pipeline to load the fine tuned model.\nhttps://huggingface.co/docs/transformers/pipeline_tutorial\n\nUse displacy to visualize the results.","metadata":{}},{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip install seqeval","metadata":{"execution":{"iopub.status.busy":"2022-04-08T15:49:16.564933Z","iopub.execute_input":"2022-04-08T15:49:16.565435Z","iopub.status.idle":"2022-04-08T15:49:29.709272Z","shell.execute_reply.started":"2022-04-08T15:49:16.565342Z","shell.execute_reply":"2022-04-08T15:49:29.708378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nimport pandas as pd\nimport transformers\nfrom transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer, DataCollatorForTokenClassification, pipeline\nfrom datasets import load_dataset, load_metric\nfrom spacy import displacy\n\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"execution":{"iopub.status.busy":"2022-04-08T15:49:29.713089Z","iopub.execute_input":"2022-04-08T15:49:29.713348Z","iopub.status.idle":"2022-04-08T15:49:44.35423Z","shell.execute_reply.started":"2022-04-08T15:49:29.713315Z","shell.execute_reply":"2022-04-08T15:49:44.353376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utilities","metadata":{}},{"cell_type":"code","source":"def tokenize_and_align_labels(task,examples,tokenizer,label_all_tokens = True):\n    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n    labels = []\n    for i, label in enumerate(examples[f\"{task}_tags\"]):\n        word_ids = tokenized_inputs.word_ids(batch_index=i)\n        previous_word_idx = None\n        label_ids = []\n        for word_idx in word_ids:\n            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n            # ignored in the loss function.\n            if word_idx is None:\n                label_ids.append(-100)\n            # We set the label for the first token of each word.\n            elif word_idx != previous_word_idx:\n                label_ids.append(label[word_idx])\n            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n            # the label_all_tokens flag.\n            else:\n                label_ids.append(label[word_idx] if label_all_tokens else -100)\n            previous_word_idx = word_idx\n\n        labels.append(label_ids)\n\n    tokenized_inputs[\"labels\"] = labels\n    return tokenized_inputs\n\n\ndef compute_metrics(p,label_list):\n    predictions, labels = p\n    predictions = np.argmax(predictions, axis=2)\n\n    # Remove ignored index (special tokens)\n    true_predictions = [\n        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n    true_labels = [\n        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n    metric = load_metric(\"seqeval\")\n    results = metric.compute(predictions=true_predictions, references=true_labels)\n    return {\n        \"precision\": results[\"overall_precision\"],\n        \"recall\": results[\"overall_recall\"],\n        \"f1\": results[\"overall_f1\"],\n        \"accuracy\": results[\"overall_accuracy\"],\n    }\n\n\ndef getDatasets(datasetScript,task,tokenizer,split=False,debug=False):       \n    datasets = load_dataset(datasetScript)\n    labelList = datasets[\"train\"].features[f\"{task}_tags\"].feature.names\n    tokenizedDatasets = datasets.map(lambda x: tokenize_and_align_labels(task=task,\n                                                                         examples=x,\n                                                                         tokenizer=tokenizer,\n                                                                         label_all_tokens = True), \n                                    batched=True)\n    if split:\n        tokenizedDatasets = tokenizedDatasets[\"train\"].train_test_split(test_size=0.2)\n        eval_dataset=tokenizedDatasets[\"test\"] \n    else:\n        eval_dataset=tokenizedDatasets[\"validation\"]\n    train_dataset=tokenizedDatasets[\"train\"]\n    \n    if debug:\n        train_dataset = train_dataset.shuffle(seed=42).select(range(100))\n        eval_dataset = eval_dataset.shuffle(seed=42).select(range(100))\n    \n    return train_dataset,eval_dataset,labelList\n\n\ndef runTrainer(cfg):\n    # Set datasets\n    tokenizer = AutoTokenizer.from_pretrained(cfg.modelCheckpoint)\n    assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)    \n    train_dataset,eval_dataset,label_list = getDatasets(datasetScript=cfg.datasetScript,\n                                                       task=cfg.task,\n                                                       tokenizer=tokenizer,\n                                                       split=cfg.split,\n                                                       debug=cfg.debug)\n                                          \n    # Set trainer   \n    model = AutoModelForTokenClassification.from_pretrained(cfg.modelCheckpoint, num_labels=len(label_list))\n    model_name = cfg.modelCheckpoint.split(\"/\")[-1]\n    args = TrainingArguments(\n                                output_dir=os.path.join(cfg.outdir,f\"{model_name}-finetuned-{cfg.task}\"),\n                                evaluation_strategy=\"epoch\",\n                                learning_rate=2e-5,\n                                per_device_train_batch_size=cfg.batchSize,\n                                per_device_eval_batch_size=cfg.batchSize,\n                                num_train_epochs=3,\n                                weight_decay=0.01,\n                            )\n    data_collator = DataCollatorForTokenClassification(tokenizer)\n    trainer = Trainer(\n                        model,\n                        args,\n                        train_dataset=train_dataset,\n                        eval_dataset=eval_dataset,\n                        data_collator=data_collator,\n                        tokenizer=tokenizer,\n                        compute_metrics=lambda x:compute_metrics(x,label_list)\n                      )\n    \n    # Train\n    trainOutput = trainer.train()\n    print(\"Training completed.\")\n    trainer.save_metrics(split=\"train\",metrics=trainOutput.metrics)\n    trainer.save_metrics(split=\"eval\",metrics=trainer.evaluate())\n    print(\"Evaluation completed.\")\n    #predOutput = trainer.predict(tokenized_datasets[\"test\"])\n    #trainer.save_metrics(split=\"test\",metrics=predOutput.metrics)\n    #print(\"Testing completed.\") \n    trainer.save_model(output_dir=os.path.join(cfg.outdir,cfg.saveModelName))\n    print(\"Model saved.\")\n\n    \nclass CFG:\n    task = \"ner\"\n    modelCheckpoint = \"distilbert-base-uncased\"\n    batchSize = 16\n    datasetScript = \"../usr/lib/nbmedatasetloadingscript/nbmedatasetloadingscript.py\"\n    split = False # split dataset to train/validation\n    outdir = \"./\"\n    saveModelName = \"mytrfmodel\"\n    debug = True # Disable this may cause CUDA OOM!!!!\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-08T15:49:44.356106Z","iopub.execute_input":"2022-04-08T15:49:44.356472Z","iopub.status.idle":"2022-04-08T15:49:44.380302Z","shell.execute_reply.started":"2022-04-08T15:49:44.356431Z","shell.execute_reply":"2022-04-08T15:49:44.379096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"cfg = CFG\ncfg.split = True\ncfg.debug = True\nrunTrainer(cfg)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T15:51:36.031884Z","iopub.execute_input":"2022-04-08T15:51:36.032632Z","iopub.status.idle":"2022-04-08T15:51:48.587784Z","shell.execute_reply.started":"2022-04-08T15:51:36.032597Z","shell.execute_reply":"2022-04-08T15:51:48.586805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict","metadata":{}},{"cell_type":"code","source":"task = \"token-classification\"\nmodelName = f\"./{cfg.saveModelName}\"\ntokenizer = AutoTokenizer.from_pretrained(modelName)\nmodel = AutoModelForTokenClassification.from_pretrained(modelName) \n    \nnlp = pipeline(task=task,\n               model=model,\n               tokenizer=tokenizer,\n               aggregation_strategy=\"simple\")","metadata":{"execution":{"iopub.status.busy":"2022-04-08T15:51:52.12019Z","iopub.execute_input":"2022-04-08T15:51:52.120987Z","iopub.status.idle":"2022-04-08T15:51:52.939775Z","shell.execute_reply.started":"2022-04-08T15:51:52.120928Z","shell.execute_reply":"2022-04-08T15:51:52.93908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note that LABEL_i maps to label_list[i]","metadata":{}},{"cell_type":"code","source":"notes = pd.read_csv(\"../input/nbme-score-clinical-patient-notes/patient_notes.csv\")\nsample = notes.sample(1)\ntext = sample[\"pn_history\"].values[0]\ndoc = nlp(text)\ndf = pd.DataFrame(doc,columns=[\"start\",\"end\",\"entity_group\"])\ndf.columns = [\"start\",\"end\",\"label\"]\nex = [{\"text\": text,\n       \"ents\": df.to_dict(\"records\"),\n       \"title\": None}]\ndisplacy.render(ex, style=\"ent\", manual=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T15:51:59.134241Z","iopub.execute_input":"2022-04-08T15:51:59.1345Z","iopub.status.idle":"2022-04-08T15:51:59.959512Z","shell.execute_reply.started":"2022-04-08T15:51:59.134472Z","shell.execute_reply":"2022-04-08T15:51:59.958732Z"},"trusted":true},"execution_count":null,"outputs":[]}]}