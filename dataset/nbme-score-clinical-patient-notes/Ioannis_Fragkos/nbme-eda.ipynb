{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-19T18:10:09.538578Z","iopub.execute_input":"2022-03-19T18:10:09.538917Z","iopub.status.idle":"2022-03-19T18:10:09.569578Z","shell.execute_reply.started":"2022-03-19T18:10:09.538831Z","shell.execute_reply":"2022-03-19T18:10:09.568501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install stylecloud","metadata":{"execution":{"iopub.status.busy":"2022-03-19T18:10:09.571864Z","iopub.execute_input":"2022-03-19T18:10:09.572179Z","iopub.status.idle":"2022-03-19T18:10:27.218237Z","shell.execute_reply.started":"2022-03-19T18:10:09.572138Z","shell.execute_reply":"2022-03-19T18:10:27.217477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" <h1 align='center'>Dataset Info\n\n\n\n## Training data\n**patient_notes.csv - A collection of about 40,000 Patient Note history portions.**\n\n* ```pn_num``` - A unique identifier for each patient note.\n* ```case_num``` - A unique identifier for the clinical case a patient note represents.\n* ```pn_history``` - The text of the encounter as recorded by the test taker.\n\n**features.csv - The rubric of features (or key concepts) for each clinical case.**\n\n* ```feature_num``` - A unique identifier for each feature.\n* ```case_num``` - A unique identifier for each case.\n* ```feature_text``` - A description of the feature.\n\n**train.csv - Feature annotations for 1000 of the patient notes, 100 for each of ten cases.**\n\n* ```id``` - Unique identifier for each patient note / feature pair.\n* ```pn_num``` - The patient note annotated in this row.\n* ```feature_num``` - The feature annotated in this row.\n* ```case_num``` - The case to which this patient note belongs.\n* ```annotation``` - The text(s) within a patient note indicating a feature. A feature may be indicated multiple times within a single note.\n* ```location``` - Character spans indicating the location of each annotation within the note. Multiple spans may be needed to represent an annotation, in which case the spans are delimited by a semicolon ;.\n","metadata":{}},{"cell_type":"markdown","source":"<h1 align='center'>TABLE OF COTENTENTS</h1>\n\n* Import libraries\n* Reading the data\n* Explore\n    * Train data\n    * Feutures data\n    * Patients Note data","metadata":{}},{"cell_type":"markdown","source":"## IMPORT LIBRARIES","metadata":{}},{"cell_type":"code","source":"from matplotlib import pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set_style(\"darkgrid\")\nimport plotly.express as px\nimport plotly.figure_factory as ff\nfrom IPython.display import Image\nimport sklearn\nimport stylecloud\nimport ast\nfrom collections import Counter, defaultdict\nimport nltk\nimport spacy\nfrom spacy import displacy\n\nimport warnings\nwarnings.simplefilter('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-03-19T18:10:27.21966Z","iopub.execute_input":"2022-03-19T18:10:27.219975Z","iopub.status.idle":"2022-03-19T18:10:39.900167Z","shell.execute_reply.started":"2022-03-19T18:10:27.219936Z","shell.execute_reply":"2022-03-19T18:10:39.899363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>READING THE DATA</h2>","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/nbme-score-clinical-patient-notes/train.csv')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-19T18:10:39.902144Z","iopub.execute_input":"2022-03-19T18:10:39.902397Z","iopub.status.idle":"2022-03-19T18:10:39.962552Z","shell.execute_reply.started":"2022-03-19T18:10:39.902366Z","shell.execute_reply":"2022-03-19T18:10:39.961751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2022-03-19T18:10:39.965217Z","iopub.execute_input":"2022-03-19T18:10:39.965537Z","iopub.status.idle":"2022-03-19T18:10:39.991636Z","shell.execute_reply.started":"2022-03-19T18:10:39.965505Z","shell.execute_reply":"2022-03-19T18:10:39.990812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature = pd.read_csv('/kaggle/input/nbme-score-clinical-patient-notes/features.csv')\nfeature.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-19T18:10:39.992814Z","iopub.execute_input":"2022-03-19T18:10:39.993039Z","iopub.status.idle":"2022-03-19T18:10:40.007394Z","shell.execute_reply.started":"2022-03-19T18:10:39.993011Z","shell.execute_reply":"2022-03-19T18:10:40.006622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature.info()","metadata":{"execution":{"iopub.status.busy":"2022-03-19T18:10:40.008622Z","iopub.execute_input":"2022-03-19T18:10:40.008836Z","iopub.status.idle":"2022-03-19T18:10:40.023126Z","shell.execute_reply.started":"2022-03-19T18:10:40.008812Z","shell.execute_reply":"2022-03-19T18:10:40.02249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"patient_note = pd.read_csv('/kaggle/input/nbme-score-clinical-patient-notes/patient_notes.csv')\npatient_note.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-19T18:10:40.024094Z","iopub.execute_input":"2022-03-19T18:10:40.024606Z","iopub.status.idle":"2022-03-19T18:10:40.68432Z","shell.execute_reply.started":"2022-03-19T18:10:40.02457Z","shell.execute_reply":"2022-03-19T18:10:40.683742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"patient_note.info()","metadata":{"execution":{"iopub.status.busy":"2022-03-19T18:10:40.685223Z","iopub.execute_input":"2022-03-19T18:10:40.685967Z","iopub.status.idle":"2022-03-19T18:10:40.704748Z","shell.execute_reply.started":"2022-03-19T18:10:40.685919Z","shell.execute_reply":"2022-03-19T18:10:40.703809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 align='center'>EXPLORE</h1>\n\n<h2>Train Data</h2>\n\n<h4>We will start by looking the distribution of case_num.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 8))\n\nsns.countplot(x='case_num', data=train, palette='flare')\nplt.title('Distribution of Case_Num in Training Data', fontsize=15)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-19T18:10:40.706871Z","iopub.execute_input":"2022-03-19T18:10:40.707444Z","iopub.status.idle":"2022-03-19T18:10:40.990485Z","shell.execute_reply.started":"2022-03-19T18:10:40.707403Z","shell.execute_reply":"2022-03-19T18:10:40.989645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h4>Next step is to analyse the annotations. First, we will focus at the number of features in annotations and then we will consider the most important words in the annotations.</h4> ","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 2, figsize=(12, 8))\nfig.suptitle('Distribution of Number of Annotations', size=15)\ntrain['annot_features'] = train['annotation'].apply(lambda x : len(ast.literal_eval(x))) \nsns.countplot(x=train['annot_features'], palette='crest', ax=ax[0])\n\nsizes = []\nno_annotations = len(train[train['annot_features']==0])\nsizes.append(no_annotations)\nannotated = len(train) - len(train[train['annot_features']==0])\nsizes.append(annotated)\n\nprint('Number of Rows with no Annotations -', no_annotations)\nprint('Number of Rows with Annotations -', annotated)\n\nlabels = ['No Annotation', 'Annotation']\ncolors = ['#72CC50', '#54C2CC']\nax[1].pie(sizes, colors=colors, startangle=90, labels=labels,\n        autopct='%1.0f%%', pctdistance=0.7,textprops={'fontsize':12}, counterclock=False)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-19T18:10:40.992106Z","iopub.execute_input":"2022-03-19T18:10:40.992685Z","iopub.status.idle":"2022-03-19T18:10:41.436699Z","shell.execute_reply.started":"2022-03-19T18:10:40.992639Z","shell.execute_reply":"2022-03-19T18:10:41.435838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def annot_list(annotation):\n    text = [word for words in ast.literal_eval(annotation) for word in words.split()]\n    return text\n\n\ntrain['text'] = train['annotation'].apply(lambda x : annot_list(x))\ntop = Counter([word for words in train['text'] for word in words])\n\n\ndf_temp = pd.DataFrame(top.most_common(25))\ndf_temp.columns = ['Common_words','count']\n\nfig = px.bar(df_temp, x='count', y='Common_words', title='Most Common Words(including stopwords) in Annotations', orientation='h', width=800,height=600, color='Common_words')\nfig.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-03-19T18:10:41.438399Z","iopub.execute_input":"2022-03-19T18:10:41.438957Z","iopub.status.idle":"2022-03-19T18:10:42.508202Z","shell.execute_reply.started":"2022-03-19T18:10:41.438914Z","shell.execute_reply":"2022-03-19T18:10:42.50732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def stopwords_remove(annotation):\n    text = [word for words in ast.literal_eval(annotation) for word in words.split() if word not in set(nltk.corpus.stopwords.words('english'))]\n    return text\n\ntrain['text'] = train['annotation'].apply(lambda x : stopwords_remove(x))\n\ntop = Counter([word for words in train['text'] for word in words])\ndf_temp = pd.DataFrame(top.most_common(25))\ndf_temp.columns = ['Common_words','count']\n\nfig = px.bar(df_temp, x='count', y='Common_words', title='Most Common Words(including stopwords) in Annotations', orientation='h', width=800,height=600, color='Common_words')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-19T18:10:42.509833Z","iopub.execute_input":"2022-03-19T18:10:42.510339Z","iopub.status.idle":"2022-03-19T18:10:47.256946Z","shell.execute_reply.started":"2022-03-19T18:10:42.510291Z","shell.execute_reply":"2022-03-19T18:10:47.256111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feuture Data","metadata":{}},{"cell_type":"markdown","source":"#### Now we will analyse the features data. We will start by looking the distribution of case_num.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 8))\n\nsns.countplot(x='case_num', data=feature, palette = 'Purples_r')\nplt.title('Distribution of Case_Num in Features Data', fontsize=15)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-19T18:10:47.258326Z","iopub.execute_input":"2022-03-19T18:10:47.258545Z","iopub.status.idle":"2022-03-19T18:10:47.50885Z","shell.execute_reply.started":"2022-03-19T18:10:47.258518Z","shell.execute_reply":"2022-03-19T18:10:47.508301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Then we will inspect some feature_text properties like number of words in it and the average word length distributions.","metadata":{}},{"cell_type":"code","source":"text_len = feature['feature_text'].str.split('-').map(lambda x : len(x))\n#text_len = [len(i) for i in text_len]\nfig = ff.create_distplot([text_len], ['feature'], colors=['#2ca02c'])\nfig.update_layout(title_text='Word Count Distribution')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-19T18:10:47.509724Z","iopub.execute_input":"2022-03-19T18:10:47.510019Z","iopub.status.idle":"2022-03-19T18:10:47.55904Z","shell.execute_reply.started":"2022-03-19T18:10:47.509992Z","shell.execute_reply":"2022-03-19T18:10:47.558195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"avg_word_len = feature['feature_text'].str.split('-').apply(lambda x : [len(i) for i in x]).map(lambda x : np.mean(x))\nfig = ff.create_distplot([avg_word_len], ['feature'], colors=['#ffa408'])\nfig.update_layout(title_text='Average Word Length Distribution')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-19T18:10:47.560464Z","iopub.execute_input":"2022-03-19T18:10:47.561006Z","iopub.status.idle":"2022-03-19T18:10:47.58201Z","shell.execute_reply.started":"2022-03-19T18:10:47.560974Z","shell.execute_reply":"2022-03-19T18:10:47.581152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Patient Notes Data","metadata":{}},{"cell_type":"markdown","source":"#### Lastly, we will analyse the patient_notes data. We will start by looking the distribution of case_num.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15, 9))\n\nsns.countplot(x='case_num', data=patient_note, palette = 'winter')\nplt.title('Distribution of Case_Num in Patient Notes Data', fontsize=15)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-19T18:10:47.583919Z","iopub.execute_input":"2022-03-19T18:10:47.584557Z","iopub.status.idle":"2022-03-19T18:10:47.85994Z","shell.execute_reply.started":"2022-03-19T18:10:47.584512Z","shell.execute_reply":"2022-03-19T18:10:47.859257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Then similarly we will inspect some patient history notes properties like number of words in it and the average word length distributions.","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(2, 1, figsize=(20, 12))\n\ntext_len = patient_note['pn_history'].str.split().map(lambda x : len(x))\nsns.histplot(text_len, element=\"step\", kde=True, color='#2ca02c', ax=ax[0])\nax[0].set_title('Word Count Distribution', size=20)\n\navg_word_len = patient_note['pn_history'].str.split().apply(lambda x : [len(i) for i in x]).map(lambda x : np.mean(x))\nsns.histplot(avg_word_len, element=\"step\", kde=True, color='#ffa408', ax=ax[1])\nax[1].set_title('Average Word Length Distribution', size=20)\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-19T18:10:47.860848Z","iopub.execute_input":"2022-03-19T18:10:47.861169Z","iopub.status.idle":"2022-03-19T18:10:52.436433Z","shell.execute_reply.started":"2022-03-19T18:10:47.861142Z","shell.execute_reply":"2022-03-19T18:10:52.435512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Anotations Visualization","metadata":{}},{"cell_type":"code","source":"# Reference - https://www.kaggle.com/vanguarde/nbme-eda\nnlp = spacy.blank('en')\nloc = list(train.loc[(train.pn_num==224) & (train.location!='[]'), 'location'].str.replace(\"['\", \"\", regex=False).str.replace(\"']\", \"\", regex=False))\ntext = patient_note[patient_note.pn_num==224].pn_history.values[0]\ndoc = nlp.make_doc(text)\nents = []\nfor l in loc:\n    start, end = l.split(' ')\n    ent = doc.char_span(int(start), int(end), label='annotation')\n    ents.append(ent)\ndoc.ents = ents\ncolor = {\"Annotation\": '#A32EFF'}\ndisplacy.render(doc, style=\"ent\", jupyter=True, options={'colors': color})","metadata":{"execution":{"iopub.status.busy":"2022-03-19T18:10:52.438111Z","iopub.execute_input":"2022-03-19T18:10:52.43844Z","iopub.status.idle":"2022-03-19T18:10:52.668345Z","shell.execute_reply.started":"2022-03-19T18:10:52.438385Z","shell.execute_reply":"2022-03-19T18:10:52.667552Z"},"trusted":true},"execution_count":null,"outputs":[]}]}