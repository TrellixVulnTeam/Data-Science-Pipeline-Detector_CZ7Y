{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# DeBERTa + RoBERTa\nThis is an ensemble of deberta-base and roberta-base, emphasizing the difference in the range\nof offset mappings.\n\nDeBERTa tokenizer includes preceding space ' ' in offset_mapping, while many other tokenizers do not, including RoBERTa.\n\n### tokenize('Hello world!')\n\nbegin, end, text[begin:end]\n\n\nDeBERTa\n```\n  0   5 'Hello'\n  5  11 ' world'\n 11  12 '!'\n```\n\nRoBERTa\n```\n  0   5  'Hello'\n  6  11  'world'\n 11  12  '!'\n```\n\nIf you do not handle this difference appropriately, you might:\n\n* Mark first white space as positive, or,\n* mark white spaces between positive words as negative,\n\ngetting unnecessarily worse scores.\n\nThis notebook:\n1. *Always* assign token probabilities to preceding ' ' in character-wise probabilities (deberta style).\n2. Remove first ' ' in location.\n\nYou can do more sophisticated location extractions, but always\nimportant to notice the difference in the offset mappings when you map to character-wise probabilities.\n\n## Scores\n\n```\n1-fold deberta-base: 0.856 (Version 2)\n1-fold roberta-base: 0.846 (Version 3)\nMean of 1-fold each: 0.859 (Version 4)\nMean of 5-fold each: 0.868 (Version 5)\nWeighted mean:       This version\n```\n\nThe ensemble is 0.6-0.4 weighted mean of deberta and roberta, 5 fold each.\n\n## Reference\n\nThe model is Nakama's great baseline:\n\nhttps://www.kaggle.com/code/yasufuminakama/nbme-deberta-base-baseline-train/notebook\n\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport sys\nimport time\nimport pickle\n\nimport torch\nimport torch.nn as nn\n\nfrom torch.utils.data import DataLoader\nfrom transformers import AutoConfig, AutoModel, AutoTokenizer\n\n%env TOKENIZERS_PARALLELISM=false\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2022-03-26T02:38:04.994724Z","iopub.execute_input":"2022-03-26T02:38:04.995006Z","iopub.status.idle":"2022-03-26T02:38:05.629419Z","shell.execute_reply.started":"2022-03-26T02:38:04.994957Z","shell.execute_reply":"2022-03-26T02:38:05.627844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data","metadata":{}},{"cell_type":"code","source":"di = '/kaggle/input/nbme-score-clinical-patient-notes/'\n\n# id, case_num, pn_num, feature_num\ntest = pd.read_csv(di + 'test.csv')\n\n# Features: feature_num -> case_num\nfeatures = pd.read_csv(di + 'features.csv')\nfeatures.loc[27, 'feature_text'] = 'Last-Pap-smear-1-year-ago'  # Fix typo I-year -> 1-year\n\n# Patient notes: Main texts\npatient_notes = pd.read_csv(di + 'patient_notes.csv')\n\n# Attach text `pn_history` to train annotations\ntest = test.merge(features, on=['feature_num', 'case_num'], how='left')\ntest = test.merge(patient_notes, on=['pn_num', 'case_num'], how='left')\n\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-26T02:38:05.634783Z","iopub.execute_input":"2022-03-26T02:38:05.635277Z","iopub.status.idle":"2022-03-26T02:38:05.983379Z","shell.execute_reply.started":"2022-03-26T02:38:05.635239Z","shell.execute_reply":"2022-03-26T02:38:05.982667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Dataset(torch.utils.data.Dataset):\n    \"\"\"\n    Dataset(data)\n      data (np.array or list-like): input_ids and y\n    \"\"\"\n    def __init__(self, data, *, max_length=512):\n        self.data = data\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, i):\n        # Padding to max_length\n        d = self.data[i]\n        n = min(d['n'], self.max_length)\n\n        input_ids = np.zeros(self.max_length, dtype=int)\n        input_ids[:n] = d['input_ids']\n\n        attention_mask = np.zeros(self.max_length, dtype=int)\n        attention_mask[:n] = 1\n\n        return {'input_ids': input_ids,\n                'attention_mask': attention_mask,\n                'n': n}","metadata":{"execution":{"iopub.status.busy":"2022-03-26T02:38:05.984791Z","iopub.execute_input":"2022-03-26T02:38:05.985026Z","iopub.status.idle":"2022-03-26T02:38:05.993647Z","shell.execute_reply.started":"2022-03-26T02:38:05.984993Z","shell.execute_reply":"2022-03-26T02:38:05.992806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Tokenize","metadata":{}},{"cell_type":"code","source":"def create_data(train, tokenizer, *, max_length=1024):\n    \"\"\"\n    Create input_ids and label array y\n\n    Args:\n      train (pd.DataFrame)\n\n    Returns: list[dict]\n      input_ids (np.array[int])\n      n (int): seq length or number of tokens\n    \"\"\"\n    sep = tokenizer.sep_token_id\n    if tokenizer.__class__.__name__ == 'RobertaTokenizerFast':\n        nsep = 3\n    else:\n        nsep = 2\n        \n    data = []\n    for i, r in train.iterrows():\n        text = r.pn_history\n        feature_text = r.feature_text\n\n        o = tokenizer(text, feature_text,\n                      add_special_tokens=True, max_length=max_length,\n                      truncation=True,\n                      return_offsets_mapping=True)\n\n        # Input ids\n        input_ids = o['input_ids']\n        n = len(input_ids)\n\n        input_ids = np.array(o['input_ids'], dtype=int)\n        assert np.sum(input_ids == sep) == nsep  # text and feature_text seperated by [SEP]; sep sep for roberta\n\n        # Attention mask\n        attention_mask = np.array(o['attention_mask'])\n        assert np.all(attention_mask == 1)\n\n        d = {'row_id': r['id'],\n             'input_ids': input_ids,\n             'text': text,\n             'n': n,\n             'offset_mapping': o['offset_mapping']}\n        data.append(d)\n\n    return np.array(data)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-03-26T02:38:05.996591Z","iopub.execute_input":"2022-03-26T02:38:05.997054Z","iopub.status.idle":"2022-03-26T02:38:06.008085Z","shell.execute_reply.started":"2022-03-26T02:38:05.996953Z","shell.execute_reply":"2022-03-26T02:38:06.007305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self, model_dir, *, dropout=0.2, pretrained=True):\n        super().__init__()\n\n        config = AutoConfig.from_pretrained(model_dir, add_pooling_layer=False)\n        if pretrained:\n            self.transformer = AutoModel.from_pretrained(model_dir, config=config)\n        else:\n            self.transformer = AutoModel.from_config(config)\n\n        self.fc_dropout = nn.Dropout(dropout)\n        self.fc = nn.Linear(config.hidden_size, 1)\n\n        self._init_weights(self.fc, config)\n\n    def _init_weights(self, module, config):\n        module.weight.data.normal_(mean=0.0, std=config.initializer_range)\n        if module.bias is not None:\n            module.bias.data.zero_()\n\n    def forward(self, input_ids, attention_mask):\n        out = self.transformer(input_ids, attention_mask)\n        x = out['last_hidden_state']  # batch_size x max_length (512) x 768\n\n        x = self.fc_dropout(x)\n        x = self.fc(x)\n\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-03-26T02:38:06.009903Z","iopub.execute_input":"2022-03-26T02:38:06.010316Z","iopub.status.idle":"2022-03-26T02:38:06.020798Z","shell.execute_reply.started":"2022-03-26T02:38:06.010172Z","shell.execute_reply":"2022-03-26T02:38:06.020008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predict","metadata":{}},{"cell_type":"code","source":"def character_prob(pred):\n    \"\"\"\n    Map token-level probabilites to character-level probabilites\n    \n    Args:\n      pred (dict): pred['y_pred'] and pred['d']\n\n    Returns:\n      y_prob (np.array[float]): character-level probabilities\n    \"\"\"\n    y_pred = pred['y_pred']\n    d = pred['d']\n    text = d['text']\n    offset_mapping = d['offset_mapping']\n\n    # Map token-level prob to character-level prob\n    y_prob = np.zeros(len(text))  # character-wise probabilities\n    end_prev = 0\n    for p, (begin, end) in zip(y_pred, offset_mapping):\n        if end_prev > 0 and begin == 0 and end == 0:\n            break  # This is end of patient note (ToDo think better way)\n\n        y_prob[end_prev:end] = p  # assign p to ' ' in end_prev:begin, too\n        end_prev = end\n\n    return y_prob\n\n\ndef predict(data, model_info, *, batch_size=12):\n    \"\"\"\n    data => pred\n    \n    Args:\n      data (list[dict]): input_ids\n    \n    Result: preds, probs\n      preds (list[dict]): token-level model prediction\n      probs (list[dict]): character-level probability\n    \"\"\"\n    print(model_info)\n\n    transformer_name = model_info[0]  # deberta-base\n    model_name = model_info[1]        # nbaseline\n    run_name = model_info[2]          # deberta_base\n    ifold = model_info[3]\n    best = model_info[4]              # True = with early stopping\n    \n    best = '_best' if best else ''\n    \n    transformer_dir = '/kaggle/input/clinical-public/transformers/%s' % transformer_name\n    weight_dir = '/kaggle/input/clinical-public/%s_%s' % (model_name, run_name)  # nbaseline_deberta_base\n    \n    # Data\n    loader = DataLoader(Dataset(data), batch_size=batch_size)\n\n    # Model\n    model = Model(transformer_dir, pretrained=False)\n\n    weight_filename = '%s/model%d%s.pytorch' % (weight_dir, ifold, best)\n    model.load_state_dict(torch.load(weight_filename, map_location=device))\n    model.eval()\n    model.to(device)\n\n    i = 0\n    preds = []\n    probs = []\n    for d in loader:\n        input_ids = d['input_ids'].to(device)\n        attention_mask = d['attention_mask'].to(device)\n\n        with torch.no_grad():\n            y_pred = model(input_ids, attention_mask)\n\n        y_pred = y_pred.sigmoid().cpu().numpy()\n\n        for k, m in enumerate(d['n']):\n            pred = {'d': data[i],\n                    'y_pred': y_pred[k, :m].copy()}\n            \n            prob = {'row_id': pred['d']['row_id'],\n                    'text':   pred['d']['text'],\n                    'y_prob': character_prob(pred)}\n\n            preds.append(pred)\n            probs.append(prob)\n            i += 1\n\n    del model\n\n    return preds, probs\n\n\ndef add_probs(probs, probs2, w):\n    \"\"\"\n    probs += w * prob2\n    First probs2 will become probs and get modified\n    \"\"\"\n    if probs is None:\n        for prob in probs2:\n            prob['y_prob'] *= w\n        return probs2\n    \n    assert len(probs) == len(probs2)\n    \n    for prob, prob2 in zip(probs, probs2):\n        assert prob['row_id'] == prob2['row_id']\n        prob['y_prob'] += w * prob2['y_prob']\n    \n    return probs","metadata":{"execution":{"iopub.status.busy":"2022-03-26T02:38:06.022111Z","iopub.execute_input":"2022-03-26T02:38:06.022368Z","iopub.status.idle":"2022-03-26T02:38:06.041464Z","shell.execute_reply.started":"2022-03-26T02:38:06.022334Z","shell.execute_reply":"2022-03-26T02:38:06.040363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Weighted mean of 0.6 deberta - 0.4 roberta\nmodels = [('deberta-base', 'nbaseline', 'deberta_base', ifold, True, 0.6 / 5)\n          for ifold in range(5)] + \\\n         [('roberta-base', 'nbaseline', 'roberta_base', ifold, True, 0.4 / 5)\n          for ifold in range(5)]\n\nn = 0\nw_sum = 0\nprobs = None\n\nfor model in models:\n    transformer_name = model[0]  # deberta-base\n    transformer_dir = '/kaggle/input/clinical-public/transformers/%s/tokenizer' % transformer_name\n    tokenizer = AutoTokenizer.from_pretrained(transformer_dir)\n    data = create_data(test, tokenizer)\n    w = model[5]\n\n    _, probs1 = predict(data, model)\n    probs = add_probs(probs, probs1, w)\n    n += 1\n    w_sum += w\n\n\nprint('Weighted average of %d models. Weight sum %.3f' % (n, w_sum))\nassert 0.999 < w_sum < 1.001","metadata":{"execution":{"iopub.status.busy":"2022-03-26T02:40:16.23728Z","iopub.execute_input":"2022-03-26T02:40:16.238024Z","iopub.status.idle":"2022-03-26T02:40:45.056581Z","shell.execute_reply.started":"2022-03-26T02:40:16.237986Z","shell.execute_reply":"2022-03-26T02:40:45.055795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def format_spans(indices):\n    segs = []\n    left = last = None\n    for i in indices:\n        if left is None:\n            left = last = i\n        elif last + 1 == i:\n            last = i\n        else:\n            # New segment\n            segs.append('%d %d' % (left, last + 1))\n            left = last = i\n\n    if last is not None:\n        segs.append('%d %d' % (left, last + 1))\n    \n    return ';'.join(segs)\n\n\ndef create_submission(probs, *, th=0.5):\n    \"\"\"\n    Create character-level prediction\n\n    Args:\n      probs: chacter-level predictions\n    \"\"\"\n    assert len(probs) == len(test)\n    \n    locs = []\n    \n    ids = []\n    locs = []\n        \n    for prob in probs:\n        ids.append(prob['row_id'])\n        text = prob['text']\n        y_prob = prob['y_prob']\n        \n        li = []\n        i_begin = i_last = None\n        for i, (x, p) in enumerate(zip(text, y_prob)):\n            if p >= th:\n                if i_begin is None and x != ' ':  # Do not include first space in span\n                    i_begin = i_last = i\n                    li.append(i)\n                elif i_begin is not None:         # Positive character is continuing\n                    assert i_last + 1 == i\n                    i_last = i\n                    li.append(i)\n            else:\n                i_begin = i_last = None           # Negative; reset span\n\n        locs.append(format_spans(li))\n\n    return pd.DataFrame({'id': ids, 'location': locs})\n\n\nsubmit = create_submission(probs)\nsubmit.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-26T02:39:15.422772Z","iopub.execute_input":"2022-03-26T02:39:15.424288Z","iopub.status.idle":"2022-03-26T02:39:15.445312Z","shell.execute_reply.started":"2022-03-26T02:39:15.424247Z","shell.execute_reply":"2022-03-26T02:39:15.444373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Example:\n\n```\n\tid\tlocation\n0\t00016_000\t696 724\n1\t00016_001\t668 693\n2\t00016_002\t203 217\n3\t00016_003\t70 91\n4\t00016_004\t222 258\n```","metadata":{}},{"cell_type":"code","source":"submit.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-26T02:39:15.446922Z","iopub.execute_input":"2022-03-26T02:39:15.447223Z","iopub.status.idle":"2022-03-26T02:39:15.45879Z","shell.execute_reply.started":"2022-03-26T02:39:15.447187Z","shell.execute_reply":"2022-03-26T02:39:15.458075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Additional info\n\n### KFold\n\n```\nnfold = 5\nkfold = StratifiedGroupKFold(nfold, shuffle=True, random_state=42)\ngroups = train['pn_num'].values\ncases = train['case_num'].values\n\nfor ifold, (idx_train, idx_val) in enumerate(kfold.split(data, cases, groups=groups)):\n    pass\n```\n\n### Training\n\nRoBERTa\n\n```\nget_cosine_schedule_with_warmup\n\nlearning rate: 1e-4 with 0.1 epochs of warmup\n5 epochs\n```\n\nDeBERTa\n\nSame as the original baseline.\n\n","metadata":{}}]}