{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-02T07:08:28.938674Z","iopub.execute_input":"2022-05-02T07:08:28.939023Z","iopub.status.idle":"2022-05-02T07:08:31.807346Z","shell.execute_reply.started":"2022-05-02T07:08:28.938927Z","shell.execute_reply":"2022-05-02T07:08:31.806628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training of base model:\nThis is my version of training baseline model using hugginface trainer, compute_loss function and datasets only. It would help people to get familar with hugginface eco system without worrying about internal details.\n\nHuge thanks to @nboard notebook https://www.kaggle.com/code/nbroad/qa-ner-hybrid-train-nbme, most of the snippets inspired from his work, checkout his work if you haven't already.\n\nCheckout inference notebook [0.867] https://www.kaggle.com/code/raghavendrakotala/inference-deberta-trainer-compute-loss-datasets\n\n### **I Hope this helps in enhancing more NLP skills in your DS journey. Don't forget to upvote if you find it useful :), Thanks!**","metadata":{}},{"cell_type":"code","source":"\nfrom torch.utils.data import Dataset, DataLoader\nimport pdb\nimport torch\nfrom torch import cuda\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom tqdm.auto import tqdm\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import precision_recall_fscore_support\nimport datasets\nfrom functools import partial\nfrom ast import literal_eval\nfrom datetime import datetime\nimport gc\n\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-05-02T07:08:31.808698Z","iopub.execute_input":"2022-05-02T07:08:31.808959Z","iopub.status.idle":"2022-05-02T07:08:34.721775Z","shell.execute_reply.started":"2022-05-02T07:08:31.808927Z","shell.execute_reply":"2022-05-02T07:08:34.721066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load data and set the config : we will run for 5 folds, 5 epochs","metadata":{}},{"cell_type":"code","source":"config = {'model_name': '../input/deberta-v3-base/deberta-v3-base/',\n         'max_length': 512,\n         'train_batch_size':8,\n         'valid_batch_size':16,\n         'epochs':5,\n         'learning_rate':2e-05,\n         'max_grad_norm':10,\n          'warmup':0.1,\n          \"grad_acc\":8,\n          \"model_save_path\":\"deberta-trained\",\n          \"folds\":5,\n          \"seed\":42,\n          'num_proc' : 2,\n         'device': 'cuda' if cuda.is_available() else 'cpu'}","metadata":{"execution":{"iopub.status.busy":"2022-05-02T07:08:34.724941Z","iopub.execute_input":"2022-05-02T07:08:34.725142Z","iopub.status.idle":"2022-05-02T07:08:34.790597Z","shell.execute_reply.started":"2022-05-02T07:08:34.725117Z","shell.execute_reply":"2022-05-02T07:08:34.789609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_features = pd.read_csv(\"/kaggle/input/nbme-score-clinical-patient-notes/features.csv\")\ndf_patients = pd.read_csv(\"/kaggle/input/nbme-score-clinical-patient-notes/patient_notes.csv\")\ndf_train = pd.read_csv(\"/kaggle/input/nbme-score-clinical-patient-notes/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-05-02T07:08:34.792686Z","iopub.execute_input":"2022-05-02T07:08:34.793523Z","iopub.status.idle":"2022-05-02T07:08:35.433448Z","shell.execute_reply.started":"2022-05-02T07:08:34.793482Z","shell.execute_reply":"2022-05-02T07:08:35.432663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_patients.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-02T07:08:37.220479Z","iopub.execute_input":"2022-05-02T07:08:37.221092Z","iopub.status.idle":"2022-05-02T07:08:37.240317Z","shell.execute_reply.started":"2022-05-02T07:08:37.221043Z","shell.execute_reply":"2022-05-02T07:08:37.23955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_patients['pn_num'].nunique(), df_patients['case_num'].nunique()","metadata":{"execution":{"iopub.status.busy":"2022-05-02T07:08:37.654216Z","iopub.execute_input":"2022-05-02T07:08:37.654462Z","iopub.status.idle":"2022-05-02T07:08:37.668324Z","shell.execute_reply.started":"2022-05-02T07:08:37.654433Z","shell.execute_reply":"2022-05-02T07:08:37.667396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-02T07:08:38.152393Z","iopub.execute_input":"2022-05-02T07:08:38.15265Z","iopub.status.idle":"2022-05-02T07:08:38.165394Z","shell.execute_reply.started":"2022-05-02T07:08:38.15262Z","shell.execute_reply":"2022-05-02T07:08:38.164607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_patients.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-02T07:08:38.528589Z","iopub.execute_input":"2022-05-02T07:08:38.528872Z","iopub.status.idle":"2022-05-02T07:08:38.537878Z","shell.execute_reply.started":"2022-05-02T07:08:38.528837Z","shell.execute_reply":"2022-05-02T07:08:38.53716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load tokenizer and clean the data\n\nWhile cleaning we don't remove empty annotations as it leads to removing true positive cases and we see CV and LB results not in sync [ref](http://kaggle.com/competitions/nbme-score-clinical-patient-notes/discussion/318224)","metadata":{}},{"cell_type":"code","source":"!pip uninstall -q -y transformers","metadata":{"execution":{"iopub.status.busy":"2022-05-02T07:08:40.248467Z","iopub.execute_input":"2022-05-02T07:08:40.249247Z","iopub.status.idle":"2022-05-02T07:08:44.079084Z","shell.execute_reply.started":"2022-05-02T07:08:40.249203Z","shell.execute_reply":"2022-05-02T07:08:44.078141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install git+https://github.com/huggingface/transformers.git -qq","metadata":{"execution":{"iopub.status.busy":"2022-05-02T07:10:20.790332Z","iopub.execute_input":"2022-05-02T07:10:20.790604Z","iopub.status.idle":"2022-05-02T07:10:59.427909Z","shell.execute_reply.started":"2022-05-02T07:10:20.790576Z","shell.execute_reply":"2022-05-02T07:10:59.426949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers.models.deberta_v2.tokenization_deberta_v2_fast import DebertaV2TokenizerFast\nfrom transformers import Trainer, TrainingArguments\nfrom transformers import AutoTokenizer, AutoModelForTokenClassification\n\n\ntokenizer = AutoTokenizer.from_pretrained(config['model_name'])","metadata":{"execution":{"iopub.status.busy":"2022-05-02T07:11:06.303866Z","iopub.execute_input":"2022-05-02T07:11:06.304191Z","iopub.status.idle":"2022-05-02T07:11:11.557739Z","shell.execute_reply.started":"2022-05-02T07:11:06.304151Z","shell.execute_reply":"2022-05-02T07:11:11.556844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pre_process_data(df_train):\n    print(f\"before converting annotations of type :{type(df_train.annotation[0])}, {df_train.annotation[0]}, location of type: {type(df_train.location[0])}, {df_train.location[0]}\")\n    df_train['anno_list'] = [literal_eval(x) for x in df_train.annotation]\n    df_train['loc_list'] = [literal_eval(x) for x in df_train.location]\n    print(f\"after converting annotations of type :{type(df_train.annotation[0])}, {df_train.annotation[0]}, location of type: {type(df_train.location[0])}, {df_train.location[0]}\")\n    print(f\"column names of df_train : {df_train.columns}\")\n    merged = df_train.merge(df_patients, how='left')\n    print(f\"column names of df_train after merging with patietns: {merged.columns}\")\n    merged = merged.merge(df_features, how='left')\n    print(f\"column names of df_train after merging with features: {merged.columns}\")\n    return merged","metadata":{"execution":{"iopub.status.busy":"2022-05-02T07:11:13.828256Z","iopub.execute_input":"2022-05-02T07:11:13.829113Z","iopub.status.idle":"2022-05-02T07:11:13.835941Z","shell.execute_reply.started":"2022-05-02T07:11:13.829068Z","shell.execute_reply":"2022-05-02T07:11:13.83524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged = pre_process_data(df_train)\nmerged.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-02T07:11:14.14252Z","iopub.execute_input":"2022-05-02T07:11:14.142799Z","iopub.status.idle":"2022-05-02T07:11:14.606429Z","shell.execute_reply.started":"2022-05-02T07:11:14.142765Z","shell.execute_reply":"2022-05-02T07:11:14.605719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# incorrect annotations\nmerged.loc[338, \"anno_list\"] =  '[\"father heart attack\"]'\nmerged.loc[338, \"loc_list\"] =  '[\"764 783\"]'\n\nmerged.loc[621, \"anno_list\"] =  '[\"for the last 2-3 months\", \"over the last 2 months\"]'\nmerged.loc[621, \"loc_list\"] =  '[\"77 100\", \"398 420\"]'\n\nmerged.loc[655, \"anno_list\"] =  '[\"no heat intolerance\", \"no cold intolerance\"]'\nmerged.loc[655, \"loc_list\"] =  '[\"285 292;301 312\", \"285 287;296 312\"]'\n\nmerged.loc[1262, \"anno_list\"] =  '[\"mother thyroid problem\"]'\nmerged.loc[1262, \"loc_list\"] =  '[\"551 557;565 580\"]'\n\nmerged.loc[1265, \"anno_list\"] =  '[\\'felt like he was going to \"pass out\"\\']'\nmerged.loc[1265, \"loc_list\"] =  '[\"131 135;181 212\"]'\n\nmerged.loc[1396, \"anno_list\"] =  '[\"stool , with no blood\"]'\nmerged.loc[1396, \"loc_list\"] =  '[\"259 280\"]'\n\nmerged.loc[1591, \"anno_list\"] =  '[\"diarrhoe non blooody\"]'\nmerged.loc[1591, \"loc_list\"] =  '[\"176 184;201 212\"]'\n\nmerged.loc[1615, \"anno_list\"] =  '[\"diarrhea for last 2-3 days\"]'\nmerged.loc[1615, \"loc_list\"] =  '[\"249 257;271 288\"]'\n\nmerged.loc[1664, \"anno_list\"] =  '[\"no vaginal discharge\"]'\nmerged.loc[1664, \"loc_list\"] =  '[\"822 824;907 924\"]'\n\nmerged.loc[1714, \"anno_list\"] =  '[\"started about 8-10 hours ago\"]'\nmerged.loc[1714, \"loc_list\"] =  '[\"101 129\"]'\n\nmerged.loc[1929, \"anno_list\"] =  '[\"no blood in the stool\"]'\nmerged.loc[1929, \"loc_list\"] =  '[\"531 539;549 561\"]'\n\nmerged.loc[2134, \"anno_list\"] =  '[\"last sexually active 9 months ago\"]'\nmerged.loc[2134, \"loc_list\"] =  '[\"540 560;581 593\"]'\n\nmerged.loc[2191, \"anno_list\"] =  '[\"right lower quadrant pain\"]'\nmerged.loc[2191, \"loc_list\"] =  '[\"32 57\"]'\n\nmerged.loc[2553, \"anno_list\"] =  '[\"diarrhoea no blood\"]'\nmerged.loc[2553, \"loc_list\"] =  '[\"308 317;376 384\"]'\n\nmerged.loc[3124, \"anno_list\"] =  '[\"sweating\"]'\nmerged.loc[3124, \"loc_list\"] =  '[\"549 557\"]'\n\nmerged.loc[3858, \"anno_list\"] =  '[\"previously as regular\", \"previously eveyr 28-29 days\", \"previously lasting 5 days\", \"previously regular flow\"]'\nmerged.loc[3858, \"loc_list\"] =  '[\"102 123\", \"102 112;125 141\", \"102 112;143 157\", \"102 112;159 171\"]'\n\nmerged.loc[4373, \"anno_list\"] =  '[\"for 2 months\"]'\nmerged.loc[4373, \"loc_list\"] =  '[\"33 45\"]'\n\nmerged.loc[4763, \"anno_list\"] =  '[\"35 year old\"]'\nmerged.loc[4763, \"loc_list\"] =  '[\"5 16\"]'\n\nmerged.loc[4782, \"anno_list\"] =  '[\"darker brown stools\"]'\nmerged.loc[4782, \"loc_list\"] =  '[\"175 194\"]'\n\nmerged.loc[4908, \"anno_list\"] =  '[\"uncle with peptic ulcer\"]'\nmerged.loc[4908, \"loc_list\"] =  '[\"700 723\"]'\n\nmerged.loc[6016, \"anno_list\"] =  '[\"difficulty falling asleep\"]'\nmerged.loc[6016, \"loc_list\"] =  '[\"225 250\"]'\n\nmerged.loc[6192, \"anno_list\"] =  '[\"helps to take care of aging mother and in-laws\"]'\nmerged.loc[6192, \"loc_list\"] =  '[\"197 218;236 260\"]'\n\nmerged.loc[6380, \"anno_list\"] =  '[\"No hair changes\", \"No skin changes\", \"No GI changes\", \"No palpitations\", \"No excessive sweating\"]'\nmerged.loc[6380, \"loc_list\"] =  '[\"480 482;507 519\", \"480 482;499 503;512 519\", \"480 482;521 531\", \"480 482;533 545\", \"480 482;564 582\"]'\n\nmerged.loc[6562, \"anno_list\"] =  '[\"stressed due to taking care of her mother\", \"stressed due to taking care of husbands parents\"]'\nmerged.loc[6562, \"loc_list\"] =  '[\"290 320;327 337\", \"290 320;342 358\"]'\n\nmerged.loc[6862, \"anno_list\"] =  '[\"stressor taking care of many sick family members\"]'\nmerged.loc[6862, \"loc_list\"] =  '[\"288 296;324 363\"]'\n\nmerged.loc[7022, \"anno_list\"] =  '[\"heart started racing and felt numbness for the 1st time in her finger tips\"]'\nmerged.loc[7022, \"loc_list\"] =  '[\"108 182\"]'\n\nmerged.loc[7422, \"anno_list\"] =  '[\"first started 5 yrs\"]'\nmerged.loc[7422, \"loc_list\"] =  '[\"102 121\"]'\n\nmerged.loc[8876, \"anno_list\"] =  '[\"No shortness of breath\"]'\nmerged.loc[8876, \"loc_list\"] =  '[\"481 483;533 552\"]'\n\nmerged.loc[9027, \"anno_list\"] =  '[\"recent URI\", \"nasal stuffines, rhinorrhea, for 3-4 days\"]'\nmerged.loc[9027, \"loc_list\"] =  '[\"92 102\", \"123 164\"]'\n\nmerged.loc[9938, \"anno_list\"] =  '[\"irregularity with her cycles\", \"heavier bleeding\", \"changes her pad every couple hours\"]'\nmerged.loc[9938, \"loc_list\"] =  '[\"89 117\", \"122 138\", \"368 402\"]'\n\nmerged.loc[9973, \"anno_list\"] =  '[\"gaining 10-15 lbs\"]'\nmerged.loc[9973, \"loc_list\"] =  '[\"344 361\"]'\n\nmerged.loc[10513, \"anno_list\"] =  '[\"weight gain\", \"gain of 10-16lbs\"]'\nmerged.loc[10513, \"loc_list\"] =  '[\"600 611\", \"607 623\"]'\n\nmerged.loc[11551, \"anno_list\"] =  '[\"seeing her son knows are not real\"]'\nmerged.loc[11551, \"loc_list\"] =  '[\"386 400;443 461\"]'\n\nmerged.loc[11677, \"anno_list\"] =  '[\"saw him once in the kitchen after he died\"]'\nmerged.loc[11677, \"loc_list\"] =  '[\"160 201\"]'\n\nmerged.loc[12124, \"anno_list\"] =  '[\"tried Ambien but it didnt work\"]'\nmerged.loc[12124, \"loc_list\"] =  '[\"325 337;349 366\"]'\n\nmerged.loc[12279, \"anno_list\"] =  '[\"heard what she described as a party later than evening these things did not actually happen\"]'\nmerged.loc[12279, \"loc_list\"] =  '[\"405 459;488 524\"]'\n\nmerged.loc[12289, \"anno_list\"] =  '[\"experienced seeing her son at the kitchen table these things did not actually happen\"]'\nmerged.loc[12289, \"loc_list\"] =  '[\"353 400;488 524\"]'\n\nmerged.loc[13238, \"anno_list\"] =  '[\"SCRACHY THROAT\", \"RUNNY NOSE\"]'\nmerged.loc[13238, \"loc_list\"] =  '[\"293 307\", \"321 331\"]'\n\nmerged.loc[13297, \"anno_list\"] =  '[\"without improvement when taking tylenol\", \"without improvement when taking ibuprofen\"]'\nmerged.loc[13297, \"loc_list\"] =  '[\"182 221\", \"182 213;225 234\"]'\n\nmerged.loc[13299, \"anno_list\"] =  '[\"yesterday\", \"yesterday\"]'\nmerged.loc[13299, \"loc_list\"] =  '[\"79 88\", \"409 418\"]'\n\nmerged.loc[13845, \"anno_list\"] =  '[\"headache global\", \"headache throughout her head\"]'\nmerged.loc[13845, \"loc_list\"] =  '[\"86 94;230 236\", \"86 94;237 256\"]'\n\nmerged.loc[14083, \"anno_list\"] =  '[\"headache generalized in her head\"]'\nmerged.loc[14083, \"loc_list\"] =  '[\"56 64;156 179\"]'\n\nmerged[\"anno_list\"] = [\n    literal_eval(x) if isinstance(x, str) else x for x in merged[\"anno_list\"]\n]\nmerged[\"loc_list\"] = [\n    literal_eval(x) if isinstance(x, str) else x for x in merged[\"loc_list\"]\n]","metadata":{"execution":{"iopub.status.busy":"2022-05-02T07:11:14.608268Z","iopub.execute_input":"2022-05-02T07:11:14.608538Z","iopub.status.idle":"2022-05-02T07:11:14.717417Z","shell.execute_reply.started":"2022-05-02T07:11:14.6085Z","shell.execute_reply":"2022-05-02T07:11:14.716691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-02T07:11:14.754728Z","iopub.execute_input":"2022-05-02T07:11:14.755348Z","iopub.status.idle":"2022-05-02T07:11:14.760861Z","shell.execute_reply.started":"2022-05-02T07:11:14.755304Z","shell.execute_reply":"2022-05-02T07:11:14.760073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged = merged[~merged['pn_history'].isnull()]\nmerged.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-02T07:11:15.210153Z","iopub.execute_input":"2022-05-02T07:11:15.210648Z","iopub.status.idle":"2022-05-02T07:11:15.224797Z","shell.execute_reply.started":"2022-05-02T07:11:15.210604Z","shell.execute_reply":"2022-05-02T07:11:15.22406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_data(merged):\n    # Not removing empty annotations as mentioned in some discussions it would lead to removing true positives.\n    \n#     print(f\"before clearning: count of empty annotations :{merged.loc[merged['annotation'] == '[]'].shape} and its shape {merged.shape}\")\n#     merged = merged.loc[merged['annotation'] != \"[]\"].copy().reset_index(drop=False)\n#     print(f\"after clearning: count of empty annotations :{merged.loc[merged['annotation'] == '[]'].shape} and its shape {merged.shape}\")\n    print(f\"before clearning: count of '-OR-' in feature text: {merged[merged['feature_text'].str.contains('-OR-')].shape} and its shape {merged.shape}\")\n    merged['feature_text'] = merged['feature_text'].apply(lambda x:x.replace(\"-OR-\", ';-').replace(\"-\", \" \").lower())\n    print(f\"after clearning: count of '-OR-' in feature text: {merged[merged['feature_text'].str.contains('-OR-')].shape} and its shape {merged.shape}\")\n    print(f\"before clearning: lower pn_history {merged['pn_history'].values[1]} and its shape {merged.shape}\")\n    merged['pn_history'] = merged['pn_history'].apply(lambda x:x.lower())\n    print(f\"before clearning: lower pn_history {merged['pn_history'].values[1]} and its shape {merged.shape}\")\n    return merged","metadata":{"execution":{"iopub.status.busy":"2022-05-02T07:11:15.62179Z","iopub.execute_input":"2022-05-02T07:11:15.622383Z","iopub.status.idle":"2022-05-02T07:11:15.629599Z","shell.execute_reply.started":"2022-05-02T07:11:15.62234Z","shell.execute_reply":"2022-05-02T07:11:15.628404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged = clean_data(merged)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T07:11:15.971343Z","iopub.execute_input":"2022-05-02T07:11:15.973078Z","iopub.status.idle":"2022-05-02T07:11:16.066481Z","shell.execute_reply.started":"2022-05-02T07:11:15.973023Z","shell.execute_reply":"2022-05-02T07:11:16.065595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-02T07:11:16.131974Z","iopub.execute_input":"2022-05-02T07:11:16.132598Z","iopub.status.idle":"2022-05-02T07:11:16.161861Z","shell.execute_reply.started":"2022-05-02T07:11:16.132552Z","shell.execute_reply":"2022-05-02T07:11:16.161067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-02T07:11:16.34765Z","iopub.execute_input":"2022-05-02T07:11:16.348528Z","iopub.status.idle":"2022-05-02T07:11:16.357773Z","shell.execute_reply.started":"2022-05-02T07:11:16.348477Z","shell.execute_reply":"2022-05-02T07:11:16.356922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Do the KFold validation and load the data into data loaders.\n\n[ref](http://kaggle.com/competitions/nbme-score-clinical-patient-notes/discussion/305599kaggle.com/competitions/nbme-score-clinical-patient-notes/discussion/305599) followed this strategy to avoid leakage of data.\n","metadata":{}},{"cell_type":"code","source":"skf = StratifiedKFold(n_splits=config['folds'], random_state=config['seed'], shuffle=True)\n\nmerged[\"fold\"] = -1\n\nfor fold, (_, val_idx) in enumerate(skf.split(merged, y=merged[\"case_num\"])):\n    merged.loc[val_idx, \"fold\"] = fold\n    \ncounts = merged.groupby([\"fold\", \"pn_num\"], as_index=False).count()\n\n# If the number of rows is the same as the number of \n# unique pn_num, then each pn_num is only in one fold.\n# Also if all the counts=1\nprint(counts.shape, counts.pn_num.nunique(), counts.case_num.unique(), merged['pn_num'].nunique())\nmerged['fold'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-05-02T07:11:16.82233Z","iopub.execute_input":"2022-05-02T07:11:16.822589Z","iopub.status.idle":"2022-05-02T07:11:16.864843Z","shell.execute_reply.started":"2022-05-02T07:11:16.822561Z","shell.execute_reply":"2022-05-02T07:11:16.864081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"first = merged.loc[35]\n\nexample = {\"feature_text\": first.feature_text,\n          \"pn_history\": first.pn_history,\n          \"loc_list\": first.loc_list,\n          \"annotation_list\": first.anno_list}\n\nfor key in example.keys():\n    print(key)\n    print(example[key])\n    print('='*10)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T07:11:17.041904Z","iopub.execute_input":"2022-05-02T07:11:17.042481Z","iopub.status.idle":"2022-05-02T07:11:17.051021Z","shell.execute_reply.started":"2022-05-02T07:11:17.042441Z","shell.execute_reply":"2022-05-02T07:11:17.050064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def loc_list_to_tuples(loc_list):\n    to_return = []\n    for loc_str in loc_list:\n        loc_strs = loc_str.split(\";\")\n        for loc in loc_strs:\n            start, end = loc.split()\n            to_return.append((int(start), int(end)))\n    return to_return\n\nprint(example['loc_list'])\nexample_loc_ints = loc_list_to_tuples(example['loc_list'])\nprint(example_loc_ints)\nfor loc in example_loc_ints:\n    print(example['pn_history'][loc[0] : loc[1]])","metadata":{"execution":{"iopub.status.busy":"2022-05-02T07:11:17.779973Z","iopub.execute_input":"2022-05-02T07:11:17.780573Z","iopub.status.idle":"2022-05-02T07:11:17.794445Z","shell.execute_reply.started":"2022-05-02T07:11:17.780531Z","shell.execute_reply":"2022-05-02T07:11:17.793562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tokenize_and_label(example):\n    tokenized_inputs = tokenizer(example['feature_text'],\n                                example['pn_history'],\n                                truncation='only_second',\n                                max_length = config['max_length'],\n                                padding='max_length',\n                                return_offsets_mapping=True,)\n#                                 return_tensors='pt')\n    labels = [0.0] * len(tokenized_inputs['input_ids'])\n    tokenized_inputs['location'] = loc_list_to_tuples(example['loc_list'])\n    tokenized_inputs['sequence_ids'] = tokenized_inputs.sequence_ids()\n    \n    if len(tokenized_inputs[\"location\"]) > 0:\n        for idx, (seq_id, offsets) in enumerate(\n            zip(tokenized_inputs[\"sequence_ids\"], tokenized_inputs[\"offset_mapping\"])\n        ):\n            if seq_id is None or seq_id == 0:\n                # don't calculate loss on question part or special tokens\n                labels[idx] = -100.0\n                continue\n\n            token_start, token_end = offsets\n            for label_start, label_end in tokenized_inputs[\"location\"]:\n                if (\n                    token_start <= label_start < token_end\n                    or token_start < label_end <= token_end\n                    or label_start <= token_start < label_end\n                ):\n                    labels[idx] = 1.0  # labels should be float\n\n    tokenized_inputs[\"labels\"] = labels\n    \n    return tokenized_inputs","metadata":{"execution":{"iopub.status.busy":"2022-05-02T07:11:18.067418Z","iopub.execute_input":"2022-05-02T07:11:18.067905Z","iopub.status.idle":"2022-05-02T07:11:18.076048Z","shell.execute_reply.started":"2022-05-02T07:11:18.067852Z","shell.execute_reply":"2022-05-02T07:11:18.075319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_inputs = tokenize_and_label(example)\ntokenized_inputs.keys()","metadata":{"execution":{"iopub.status.busy":"2022-05-02T07:11:18.474167Z","iopub.execute_input":"2022-05-02T07:11:18.47471Z","iopub.status.idle":"2022-05-02T07:11:18.483813Z","shell.execute_reply.started":"2022-05-02T07:11:18.47467Z","shell.execute_reply":"2022-05-02T07:11:18.482979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged = merged[[\"pn_history\", \"feature_text\", \"loc_list\", \"fold\"]]\nmerged.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-02T07:11:18.956666Z","iopub.execute_input":"2022-05-02T07:11:18.956952Z","iopub.status.idle":"2022-05-02T07:11:18.973585Z","shell.execute_reply.started":"2022-05-02T07:11:18.956919Z","shell.execute_reply":"2022-05-02T07:11:18.972931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convert_to_dataset(merged):\n    dataset = datasets.Dataset.from_pandas(merged)\n    print(f\"keys before applying tokenization: {dataset[0].keys()}\")\n    dataset_mapped = dataset.map(tokenize_and_label, num_proc=config['num_proc'])\n    dataset_mapped.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'], output_all_columns=True)\n    # dataset_mapped = dataset_mapped.remove_columns(['pn_history',\"feature_text\",\"loc_list\", \"token_type_ids\",\"offset_mapping\", \"location_int\", \"sequence_ids\"])\n    print(f\"keys after applying tokenization: {dataset_mapped[0].keys()}\")\n    return dataset_mapped","metadata":{"execution":{"iopub.status.busy":"2022-05-02T07:11:19.217926Z","iopub.execute_input":"2022-05-02T07:11:19.218166Z","iopub.status.idle":"2022-05-02T07:11:19.226166Z","shell.execute_reply.started":"2022-05-02T07:11:19.218138Z","shell.execute_reply":"2022-05-02T07:11:19.225437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_mapped = convert_to_dataset(merged)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T07:11:19.483583Z","iopub.execute_input":"2022-05-02T07:11:19.484352Z","iopub.status.idle":"2022-05-02T07:13:37.066212Z","shell.execute_reply.started":"2022-05-02T07:11:19.484304Z","shell.execute_reply":"2022-05-02T07:13:37.065336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_mapped.save_to_disk('./processed_data/')","metadata":{"execution":{"iopub.status.busy":"2022-05-02T07:21:31.297755Z","iopub.execute_input":"2022-05-02T07:21:31.29828Z","iopub.status.idle":"2022-05-02T07:21:31.545393Z","shell.execute_reply.started":"2022-05-02T07:21:31.298241Z","shell.execute_reply":"2022-05-02T07:21:31.544625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_mapped","metadata":{"execution":{"iopub.status.busy":"2022-05-02T07:13:37.07143Z","iopub.execute_input":"2022-05-02T07:13:37.073586Z","iopub.status.idle":"2022-05-02T07:13:37.083641Z","shell.execute_reply.started":"2022-05-02T07:13:37.073536Z","shell.execute_reply":"2022-05-02T07:13:37.082871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_mapped[0]['offset_mapping']","metadata":{"execution":{"iopub.status.busy":"2022-05-02T07:13:37.085324Z","iopub.execute_input":"2022-05-02T07:13:37.085957Z","iopub.status.idle":"2022-05-02T07:13:37.144189Z","shell.execute_reply.started":"2022-05-02T07:13:37.085919Z","shell.execute_reply":"2022-05-02T07:13:37.142755Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load the model set the training arguments, wandb logging and metrics.\n","metadata":{}},{"cell_type":"code","source":"model = AutoModelForTokenClassification.from_pretrained(config['model_name'], num_labels=1)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T12:59:00.640094Z","iopub.execute_input":"2022-04-17T12:59:00.64051Z","iopub.status.idle":"2022-04-17T13:00:08.970277Z","shell.execute_reply.started":"2022-04-17T12:59:00.640457Z","shell.execute_reply":"2022-04-17T13:00:08.968897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"args = TrainingArguments('test_trainer',\n                        do_train=True,\n                        do_eval=True,\n                        do_predict=True,\n                        num_train_epochs=config['epochs'],\n                        evaluation_strategy ='epoch',\n                        per_device_train_batch_size=config['train_batch_size'],\n                        per_device_eval_batch_size=config['valid_batch_size'],\n                        #                 fp16=True,\n                        learning_rate=config['learning_rate'],\n                        weight_decay=0.01,\n                        save_strategy = \"no\",\n                        warmup_ratio= config['warmup'],\n                        gradient_accumulation_steps=config['grad_acc'],\n                        logging_strategy=\"epoch\",\n                        save_total_limit=1,\n                        seed=18,\n                        group_by_length=True,\n                        report_to='wandb'\n                        )","metadata":{"execution":{"iopub.status.busy":"2022-04-17T13:00:08.978835Z","iopub.execute_input":"2022-04-17T13:00:08.982093Z","iopub.status.idle":"2022-04-17T13:00:08.997669Z","shell.execute_reply.started":"2022-04-17T13:00:08.98205Z","shell.execute_reply":"2022-04-17T13:00:08.996499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if \"wandb\" in args.report_to:\n    !pip install -U wandb -qq\n    import wandb\n    from kaggle_secrets import UserSecretsClient\n\n    user_secrets = UserSecretsClient()\n    wandb_key = user_secrets.get_secret(\"wandb\")\n    \n    os.environ[\"WANDB_PROJECT\"] = \"NBME\"\n    os.environ[\"WANDB_RUN_GROUP\"] = \"DEBERTA_MLM_fine-tune\" + datetime.now().strftime(\n        \"%Y-%m-%d %H:%M\"\n    )\n    wandb.login(key=wandb_key)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T13:00:08.999568Z","iopub.execute_input":"2022-04-17T13:00:09.000305Z","iopub.status.idle":"2022-04-17T13:00:29.686871Z","shell.execute_reply.started":"2022-04-17T13:00:09.000255Z","shell.execute_reply":"2022-04-17T13:00:29.685789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def kaggle_metrics(eval_prediction, dataset):\n    \"\"\"\n    For `compute_metrics`\n\n    Use partial for the args and kwargs to pass other data\n    into the `compute_metrics` function.\n    \"\"\"\n\n    pred_idxs = get_location_predictions(eval_prediction.predictions, dataset)\n\n    all_labels = []\n    all_preds = []\n    for preds, locations, text in zip(\n        pred_idxs,\n        dataset[\"location\"],\n        dataset[\"pn_history\"],\n    ):\n\n        num_chars = len(text)\n        char_labels = np.zeros((num_chars), dtype=bool)\n\n        for start, end in locations:\n            char_labels[start:end] = 1\n\n        char_preds = np.zeros((num_chars))\n\n        for start_idx, end_idx in preds:\n            char_preds[start_idx:end_idx] = 1\n            if (\n                text[start_idx].isspace()\n                and start_idx > 0\n                and not char_preds[start_idx - 1]\n            ):\n                char_preds[start_idx] = 0\n\n        all_labels.extend(char_labels)\n        all_preds.extend(char_preds)\n\n    results = precision_recall_fscore_support(all_labels, all_preds, average=\"binary\")\n\n    return {\"precision\": results[0], \"recall\": results[1], \"f1\": results[2]}\n\nimport pdb\ndef get_location_predictions(preds, dataset):\n    \"\"\"\n    Finds the prediction indexes at the character level.\n    \"\"\"\n#     pdb.set_trace()\n    preds = torch.sigmoid(torch.tensor(preds))\n    all_predictions = []\n    for pred, offsets, seq_ids in zip(\n        preds, dataset[\"offset_mapping\"], dataset[\"sequence_ids\"]\n    ):\n        start_idx = None\n        current_preds = []\n        for p, o, s_id in zip(pred, offsets, seq_ids):\n            if s_id is None or s_id == 0:\n                continue\n            if p > 0.5:\n                if start_idx is None:\n                    start_idx = o[0]\n                end_idx = o[1]\n            elif start_idx is not None:\n                current_preds.append((start_idx, end_idx))\n                start_idx = None\n\n        if start_idx is not None:\n            current_preds.append((start_idx, end_idx))\n\n        all_predictions.append(current_preds)\n\n    return all_predictions\n\n# compute_metrics = partial(kaggle_metrics, dataset=dataset_mapped['test'])","metadata":{"execution":{"iopub.status.busy":"2022-04-17T13:00:29.690001Z","iopub.execute_input":"2022-04-17T13:00:29.690542Z","iopub.status.idle":"2022-04-17T13:00:29.708267Z","shell.execute_reply.started":"2022-04-17T13:00:29.690472Z","shell.execute_reply":"2022-04-17T13:00:29.706716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Override the compute_loss function of trainer class\n\nsince its a binary classification and trainer class not allowing 1 as a target variable for tokenclassification, I had to override the compute_loss to make it adaptable to this use case.","metadata":{}},{"cell_type":"code","source":"class BinaryClassificationTrainer(Trainer):\n    def compute_loss(self, model, inputs, return_outputs=False):\n        labels = inputs.pop(\"labels\")\n        outputs = model(**inputs)\n        logits = outputs.logits\n        loss_fct = torch.nn.BCEWithLogitsLoss(reduction=\"none\")\n        loss = loss_fct(logits.view(-1, self.model.config.num_labels), \n                        labels.float().view(-1, self.model.config.num_labels))\n        loss = torch.masked_select(loss, labels.view(-1, 1) > -1).mean()\n        return (loss, outputs) if return_outputs else loss","metadata":{"execution":{"iopub.status.busy":"2022-04-17T13:00:29.711552Z","iopub.execute_input":"2022-04-17T13:00:29.712202Z","iopub.status.idle":"2022-04-17T13:00:29.727964Z","shell.execute_reply.started":"2022-04-17T13:00:29.712153Z","shell.execute_reply":"2022-04-17T13:00:29.726762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_mapped.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-17T13:00:29.729699Z","iopub.execute_input":"2022-04-17T13:00:29.730247Z","iopub.status.idle":"2022-04-17T13:00:29.744013Z","shell.execute_reply.started":"2022-04-17T13:00:29.730191Z","shell.execute_reply":"2022-04-17T13:00:29.742721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Run on all folds and log the metrics to wandb","metadata":{}},{"cell_type":"code","source":"for fold in range(config['folds']):\n    print(f\"current training fold: {fold}\")\n    train_dataset = dataset_mapped.filter(lambda x:x['fold'] != fold, num_proc=config['num_proc'])\n    eval_dataset = dataset_mapped.filter(lambda x:x['fold'] == fold, num_proc=config['num_proc'])\n    print(f\"train_dataset shape {train_dataset.shape}, eval dataset shape{eval_dataset.shape}\")\n    compute_metrics = partial(kaggle_metrics, dataset=eval_dataset)\n    if \"wandb\" in args.report_to:\n        wandb_config = {\n            **args.__dict__,\n        }\n        wandb_config[\"fold\"] = fold\n        wandb.init(config=wandb_config, group=os.environ[\"WANDB_RUN_GROUP\"])\n    trainer = BinaryClassificationTrainer(model=model,\n                 args=args,\n                 train_dataset=train_dataset,\n                 eval_dataset=eval_dataset,\n                 tokenizer=tokenizer,\n                compute_metrics=compute_metrics)\n    trainer.train()\n    trainer.save_model(f\"fold_{fold}\")\n    if \"wandb\" in args.report_to:\n        wandb.finish()\n    torch.cuda.empty_cache()\n    gc.collect()\n#     break","metadata":{"execution":{"iopub.status.busy":"2022-04-17T13:00:29.746505Z","iopub.execute_input":"2022-04-17T13:00:29.747526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### I hope you leant a new way of using trainer class from hugginface, Upvote if you find it usefull. Happy learning!","metadata":{}}]}