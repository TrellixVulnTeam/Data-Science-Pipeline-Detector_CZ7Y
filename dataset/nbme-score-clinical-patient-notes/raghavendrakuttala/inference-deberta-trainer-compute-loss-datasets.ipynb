{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-29T04:49:44.140875Z","iopub.execute_input":"2022-04-29T04:49:44.141342Z","iopub.status.idle":"2022-04-29T04:49:44.203798Z","shell.execute_reply.started":"2022-04-29T04:49:44.14126Z","shell.execute_reply":"2022-04-29T04:49:44.20311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### This is Inference notebook of using only 🤗 trainer, compute_loss, datasets.\n\nCheckout my Training [notebook](http://https://www.kaggle.com/code/raghavendrakotala/training-baseline-deberta-trainer-compute-loss) , if you want detailed training instructions.","metadata":{}},{"cell_type":"markdown","source":"### Load tokenizer and data","metadata":{}},{"cell_type":"code","source":"import shutil\nfrom pathlib import Path\n\ntransformers_path = Path(\"/opt/conda/lib/python3.7/site-packages/transformers\")\n\ninput_dir = Path(\"../input/deberta-v2-3-fast-tokenizer\")\n\nconvert_file = input_dir / \"convert_slow_tokenizer.py\"\nconversion_path = transformers_path / convert_file.name\n\nif conversion_path.exists():\n    conversion_path.unlink()\n\nshutil.copy(convert_file, transformers_path)\ndeberta_v2_path = transformers_path / \"models\" / \"deberta_v2\"\n\nfor filename in [\n    \"tokenization_deberta_v2.py\",\n    \"tokenization_deberta_v2_fast.py\",\n    \"deberta__init__.py\",\n]:\n    if str(filename).startswith(\"deberta\"):\n        filepath = deberta_v2_path / str(filename).replace(\"deberta\", \"\")\n    else:\n        filepath = deberta_v2_path / filename\n    if filepath.exists():\n        filepath.unlink()\n\n    shutil.copy(input_dir / filename, filepath)\n    \nfrom transformers.models.deberta_v2.tokenization_deberta_v2_fast import DebertaV2TokenizerFast\nfrom transformers import Trainer, TrainingArguments\nfrom transformers import AutoTokenizer, AutoModelForTokenClassification\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-29T04:50:25.847447Z","iopub.execute_input":"2022-04-29T04:50:25.847701Z","iopub.status.idle":"2022-04-29T04:50:32.826602Z","shell.execute_reply.started":"2022-04-29T04:50:25.847674Z","shell.execute_reply":"2022-04-29T04:50:32.82576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import datasets\nfrom torch import cuda\nfrom transformers import AutoTokenizer, AutoModelForTokenClassification, Trainer, TrainingArguments\nimport torch","metadata":{"execution":{"iopub.status.busy":"2022-04-29T04:50:35.160205Z","iopub.execute_input":"2022-04-29T04:50:35.160922Z","iopub.status.idle":"2022-04-29T04:50:35.165273Z","shell.execute_reply.started":"2022-04-29T04:50:35.160878Z","shell.execute_reply":"2022-04-29T04:50:35.164526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_patients = pd.read_csv(\"../input/nbme-score-clinical-patient-notes/patient_notes.csv\")\ndf_features = pd.read_csv(\"../input/nbme-score-clinical-patient-notes/features.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-04-29T04:50:36.59386Z","iopub.execute_input":"2022-04-29T04:50:36.594504Z","iopub.status.idle":"2022-04-29T04:50:37.205148Z","shell.execute_reply.started":"2022-04-29T04:50:36.594467Z","shell.execute_reply":"2022-04-29T04:50:37.204342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = {\n         'max_length': 512,\n         'valid_batch_size':16,\n          \"folds\":5,\n         'device': 'cuda' if cuda.is_available() else 'cpu'\n}","metadata":{"execution":{"iopub.status.busy":"2022-04-29T04:50:37.206602Z","iopub.execute_input":"2022-04-29T04:50:37.206866Z","iopub.status.idle":"2022-04-29T04:50:37.276652Z","shell.execute_reply.started":"2022-04-29T04:50:37.206829Z","shell.execute_reply":"2022-04-29T04:50:37.275889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Preprocess data tokenize it","metadata":{}},{"cell_type":"code","source":"test_df = pd.read_csv(\"../input/nbme-score-clinical-patient-notes/test.csv\")\nresults = []\nfor row in test_df.iterrows():\n    hist, feat = df_patients[df_patients[\"pn_num\"] ==row[1]['pn_num']]['pn_history'].values[0].lower(), df_features[(df_features[\"feature_num\"] ==row[1]['feature_num']) & (df_features[\"case_num\"] ==row[1]['case_num'])]['feature_text'].values[0]\n    results.append([hist, feat])\ntest_df_ = pd.DataFrame.from_records(results, columns=['pn_history', 'feature_text'])\ndef process_feature_text(text):\n    return text.replace(\"-OR-\", \" or \").replace(\"-\", \" \").lower()\ntest_df_[\"feature_text\"] = test_df_['feature_text'].apply(process_feature_text)\n\ntest_dataset = datasets.Dataset.from_pandas(test_df_)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T04:50:39.363155Z","iopub.execute_input":"2022-04-29T04:50:39.36362Z","iopub.status.idle":"2022-04-29T04:50:39.407335Z","shell.execute_reply.started":"2022-04-29T04:50:39.363583Z","shell.execute_reply":"2022-04-29T04:50:39.406588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df_.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-29T04:50:40.686093Z","iopub.execute_input":"2022-04-29T04:50:40.686546Z","iopub.status.idle":"2022-04-29T04:50:40.702796Z","shell.execute_reply.started":"2022-04-29T04:50:40.686511Z","shell.execute_reply":"2022-04-29T04:50:40.702158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"example = test_df_.iloc[0]","metadata":{"execution":{"iopub.status.busy":"2022-04-29T04:50:41.214195Z","iopub.execute_input":"2022-04-29T04:50:41.214434Z","iopub.status.idle":"2022-04-29T04:50:41.218168Z","shell.execute_reply.started":"2022-04-29T04:50:41.214401Z","shell.execute_reply":"2022-04-29T04:50:41.217457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"example['pn_history'][:20], example['pn_history'][4:7]","metadata":{"execution":{"iopub.status.busy":"2022-04-29T04:50:42.150595Z","iopub.execute_input":"2022-04-29T04:50:42.15087Z","iopub.status.idle":"2022-04-29T04:50:42.160018Z","shell.execute_reply.started":"2022-04-29T04:50:42.150842Z","shell.execute_reply":"2022-04-29T04:50:42.159266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_tokenize(example, tokenizer):\n    tokens = tokenizer(example['feature_text'],\n                                example['pn_history'],\n                                truncation='only_second',\n                                max_length = config['max_length'],\n                                padding='max_length',\n                                return_offsets_mapping=True)\n    tokens['seq_ids'] = tokens.sequence_ids()\n    tokens['ids_to_tokens'] = tokenizer.convert_ids_to_tokens(tokens['input_ids'])\n    tokens['word_ids'] = tokens.word_ids()\n    return tokens","metadata":{"execution":{"iopub.status.busy":"2022-04-29T04:50:43.084934Z","iopub.execute_input":"2022-04-29T04:50:43.085778Z","iopub.status.idle":"2022-04-29T04:50:43.09268Z","shell.execute_reply.started":"2022-04-29T04:50:43.085737Z","shell.execute_reply":"2022-04-29T04:50:43.091883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Override trainer class with compute_loss function.","metadata":{}},{"cell_type":"code","source":"class BinaryClassificationTrainer(Trainer):\n    def compute_loss(self, model, inputs, return_outputs=False):\n        labels = inputs.pop(\"labels\")\n        outputs = model(**inputs)\n        logits = outputs.logits\n        loss_fct = torch.nn.BCEWithLogitsLoss(reduction=\"none\")\n        loss = loss_fct(logits.view(-1, self.model.config.num_labels), \n                        labels.float().view(-1, self.model.config.num_labels))\n        loss = torch.masked_select(loss, labels.view(-1, 1) > -1).mean()\n        return (loss, outputs) if return_outputs else loss","metadata":{"execution":{"iopub.status.busy":"2022-04-29T04:50:44.44652Z","iopub.execute_input":"2022-04-29T04:50:44.44705Z","iopub.status.idle":"2022-04-29T04:50:44.454135Z","shell.execute_reply.started":"2022-04-29T04:50:44.44701Z","shell.execute_reply":"2022-04-29T04:50:44.453251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"args = TrainingArguments('test_trainer',\n                         per_device_eval_batch_size=config['valid_batch_size']\n                        )","metadata":{"execution":{"iopub.status.busy":"2022-04-29T04:50:45.43759Z","iopub.execute_input":"2022-04-29T04:50:45.438171Z","iopub.status.idle":"2022-04-29T04:50:45.448659Z","shell.execute_reply.started":"2022-04-29T04:50:45.438128Z","shell.execute_reply":"2022-04-29T04:50:45.447554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Do the prediction and write support functions for results submission.\n\nMake sure to take care of white-space, as its encoded into offset-mapping in deberta","metadata":{}},{"cell_type":"code","source":"fold_results = []\nfor fold in range(config['folds']):\n    model_path = f\"../input/dberta-5fold-on-mlm-colab/fold_{fold}\"\n    print(model_path)\n    tokenizer = DebertaV2TokenizerFast.from_pretrained(model_path)\n    model = AutoModelForTokenClassification.from_pretrained(model_path)\n    trainer = BinaryClassificationTrainer(\n        model=model,\n        args=args,\n        tokenizer=tokenizer)\n    tokenized = test_dataset.map(predict_tokenize, fn_kwargs={\"tokenizer\":tokenizer})\n    tokenized.set_format(type='torch', columns=['input_ids', 'attention_mask'], output_all_columns=True)\n    results = trainer.predict(tokenized)\n    fold_results.append([tokenized, torch.sigmoid(torch.tensor(results.predictions))])","metadata":{"execution":{"iopub.status.busy":"2022-04-29T04:51:57.728225Z","iopub.execute_input":"2022-04-29T04:51:57.72869Z","iopub.status.idle":"2022-04-29T04:52:46.113109Z","shell.execute_reply.started":"2022-04-29T04:51:57.728653Z","shell.execute_reply":"2022-04-29T04:52:46.112302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def combine_offsets(output_idx_m):\n    \"\"\"\n    Take the offset mapping and combines them if they are adjacent into single span.\n    \"\"\"\n    final_out = []\n#     print(output_idx_m)\n    if output_idx_m:\n        for a in output_idx_m:\n#             print(a)\n            if final_out and (a[0]-1 == final_out[-1][-1] or a[0] == final_out[-1][-1]):\n                final_out[-1].extend([a[0], a[1]])\n            else:\n                final_out.append([a[0], a[1]])\n    return final_out","metadata":{"execution":{"iopub.status.busy":"2022-04-29T04:55:15.238494Z","iopub.execute_input":"2022-04-29T04:55:15.238786Z","iopub.status.idle":"2022-04-29T04:55:15.245715Z","shell.execute_reply.started":"2022-04-29T04:55:15.238753Z","shell.execute_reply":"2022-04-29T04:55:15.244759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\ndef return_output(tokens, preds):\n    offset_mapping = tokens['offset_mapping']\n    output_idx = []\n    ids_to_tokens = tokens['ids_to_tokens']\n    seq_ids = tokens[\"seq_ids\"]\n    word_ids = tokens['word_ids']\n    set_word_ids = []\n    for idx, (ids_, pred, (start, end), word_id) in enumerate(zip(seq_ids, preds, offset_mapping, word_ids)):\n        if ids_ is not None and ids_ != 0:\n            if pred > 0.5:\n                # here we are removing 1 from start index due to deberta codes space also into its offset-mapping\n                if re.match(r'^▁', ids_to_tokens[idx]):\n                    output_idx.append((start+1, end))\n                else:\n                    output_idx.append((start, end))\n    final_out = combine_offsets(output_idx)\n    results_out = []\n    for a in final_out:\n        results_out.append(f\"{a[0]} {a[-1]}\")\n    return \";\".join(results_out)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T04:55:15.612623Z","iopub.execute_input":"2022-04-29T04:55:15.61284Z","iopub.status.idle":"2022-04-29T04:55:15.620326Z","shell.execute_reply.started":"2022-04-29T04:55:15.612814Z","shell.execute_reply":"2022-04-29T04:55:15.619494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Do the mean of prediction across folds and submit the results.","metadata":{}},{"cell_type":"code","source":"pred_mean = torch.mean(torch.stack([i[1] for i in fold_results]), axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T04:55:16.401007Z","iopub.execute_input":"2022-04-29T04:55:16.401536Z","iopub.status.idle":"2022-04-29T04:55:16.414943Z","shell.execute_reply.started":"2022-04-29T04:55:16.4015Z","shell.execute_reply":"2022-04-29T04:55:16.414281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_mean.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-29T04:55:16.917291Z","iopub.execute_input":"2022-04-29T04:55:16.917612Z","iopub.status.idle":"2022-04-29T04:55:16.923421Z","shell.execute_reply.started":"2022-04-29T04:55:16.917577Z","shell.execute_reply":"2022-04-29T04:55:16.922627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = []\nfor i in range(len(pred_mean)):\n    tok, pred = fold_results[0][0][i], pred_mean[i]\n#     print(tok, pred.shape)\n    out = return_output(tok, pred)\n    results.append(out)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T04:55:17.320181Z","iopub.execute_input":"2022-04-29T04:55:17.320705Z","iopub.status.idle":"2022-04-29T04:55:17.358297Z","shell.execute_reply.started":"2022-04-29T04:55:17.320668Z","shell.execute_reply":"2022-04-29T04:55:17.357636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df = test_df[[\"id\"]]\nsub_df['location'] = results\nsub_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-29T04:55:18.194844Z","iopub.execute_input":"2022-04-29T04:55:18.195368Z","iopub.status.idle":"2022-04-29T04:55:18.211397Z","shell.execute_reply.started":"2022-04-29T04:55:18.195329Z","shell.execute_reply":"2022-04-29T04:55:18.210663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T04:55:18.524692Z","iopub.execute_input":"2022-04-29T04:55:18.525319Z","iopub.status.idle":"2022-04-29T04:55:18.533083Z","shell.execute_reply.started":"2022-04-29T04:55:18.525282Z","shell.execute_reply":"2022-04-29T04:55:18.532161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### I hope you leant a new way of using trainer class from hugginface, Upvote if you find it usefull. Happy learning!","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}