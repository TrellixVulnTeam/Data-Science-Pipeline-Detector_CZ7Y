{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# NBME / DeBERTa Inference | TensorFlow","metadata":{}},{"cell_type":"markdown","source":"## Imports","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport numpy as np \nimport pandas as pd \nimport os\nimport gc\nimport ast\nimport spacy\nimport random\nimport itertools\nimport matplotlib.pyplot as plt\nfrom typing import List, Tuple\n\nimport tensorflow as tf\nimport tensorflow_addons as tfa\n\n\n\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\nfrom sklearn.model_selection import train_test_split\n\nfrom transformers import AutoTokenizer, AutoConfig, TFAutoModel,AutoModel","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:17:22.45551Z","iopub.execute_input":"2022-04-11T06:17:22.4558Z","iopub.status.idle":"2022-04-11T06:17:22.465225Z","shell.execute_reply.started":"2022-04-11T06:17:22.455768Z","shell.execute_reply":"2022-04-11T06:17:22.464214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Config","metadata":{}},{"cell_type":"code","source":"# ---------- Model ---------- \nMODEL_NAME = 'microsoft/deberta-base'\nTOKENIZER_PATH = \"microsoft/deberta-base_tokenizer\"\nMAX_LEN = 512\n\n# ---------- Training ----------\nBATCH_SIZE = 8\nEPOCHS = 12\nLEARNING_RATE = 2e-5\nCLIP_NORM = 1000\n\n# ---------- Dataset ----------\nseed=42\nn_fold=5\ntrn_fold=[0, 1, 2, 3, 4]\n\ndebug=False\n\nif debug:\n    EPOCHS = 5\n    trn_fold = [0]","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:17:22.562356Z","iopub.execute_input":"2022-04-11T06:17:22.562632Z","iopub.status.idle":"2022-04-11T06:17:22.571458Z","shell.execute_reply.started":"2022-04-11T06:17:22.562603Z","shell.execute_reply":"2022-04-11T06:17:22.57046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Tokenizer","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained('../input/nbme-deberta/microsoft/deberta-base_tokenizer')","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:17:22.721778Z","iopub.execute_input":"2022-04-11T06:17:22.722043Z","iopub.status.idle":"2022-04-11T06:17:22.879872Z","shell.execute_reply.started":"2022-04-11T06:17:22.722016Z","shell.execute_reply":"2022-04-11T06:17:22.87903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef micro_f1(preds, truths):\n    \"\"\"\n    Micro f1 on binary arrays.\n\n    Args:\n        preds (list of lists of ints): Predictions.\n        truths (list of lists of ints): Ground truths.\n\n    Returns:\n        float: f1 score.\n    \"\"\"\n    # Micro : aggregating over all instances\n    preds = np.concatenate(preds)\n    truths = np.concatenate(truths)\n    return f1_score(truths, preds)\n\n\ndef spans_to_binary(spans, length=None):\n    \"\"\"\n    Converts spans to a binary array indicating whether each character is in the span.\n\n    Args:\n        spans (list of lists of two ints): Spans.\n\n    Returns:\n        np array [length]: Binarized spans.\n    \"\"\"\n    length = np.max(spans) if length is None else length\n    binary = np.zeros(length)\n    for start, end in spans:\n        binary[start:end] = 1\n    return binary\n\n\ndef span_micro_f1(preds, truths):\n    \"\"\"\n    Micro f1 on spans.\n\n    Args:\n        preds (list of lists of two ints): Prediction spans.\n        truths (list of lists of two ints): Ground truth spans.\n\n    Returns:\n        float: f1 score.\n    \"\"\"\n    bin_preds = []\n    bin_truths = []\n    for pred, truth in zip(preds, truths):\n        if not len(pred) and not len(truth):\n            continue\n        length = max(np.max(pred) if len(pred) else 0, np.max(truth) if len(truth) else 0)\n        bin_preds.append(spans_to_binary(pred, length))\n        bin_truths.append(spans_to_binary(truth, length))\n    return micro_f1(bin_preds, bin_truths)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:17:22.882364Z","iopub.execute_input":"2022-04-11T06:17:22.8826Z","iopub.status.idle":"2022-04-11T06:17:22.893213Z","shell.execute_reply.started":"2022-04-11T06:17:22.882558Z","shell.execute_reply":"2022-04-11T06:17:22.892383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_score(y_true, y_pred):\n    score = span_micro_f1(y_true, y_pred)\n    return score\n\ndef create_labels_for_scoring(df):\n    # example: ['0 1', '3 4'] -> ['0 1; 3 4']\n    df['location_for_create_labels'] = [ast.literal_eval(f'[]')] * len(df)\n    for i in range(len(df)):\n        lst = df.loc[i, 'location']\n        if lst:\n            new_lst = ';'.join(lst)\n            df.loc[i, 'location_for_create_labels'] = ast.literal_eval(f'[[\"{new_lst}\"]]')\n    # create labels\n    truths = []\n    for location_list in df['location_for_create_labels'].values:\n        truth = []\n        if len(location_list) > 0:\n            location = location_list[0]\n            for loc in [s.split() for s in location.split(';')]:\n                start, end = int(loc[0]), int(loc[1])\n                truth.append([start, end])\n        truths.append(truth)\n    return truths\n\n\ndef get_char_probs(texts, predictions, tokenizer):\n    results = [np.zeros(len(t)) for t in texts]\n    for i, (text, prediction) in enumerate(zip(texts, predictions)):\n        encoded = tokenizer(text, \n                            add_special_tokens=True,\n                            return_offsets_mapping=True)\n        for idx, (offset_mapping, pred) in enumerate(zip(encoded['offset_mapping'], prediction)):\n            start = offset_mapping[0]\n            end = offset_mapping[1]\n            results[i][start:end] = pred\n    return results\n\n\ndef get_results(char_probs, th=0.5):\n    results = []\n    for char_prob in char_probs:\n        result = np.where(char_prob >= th)[0] + 1\n        result = [list(g) for _, g in itertools.groupby(result, key=lambda n, c=itertools.count(): n - next(c))]\n        result = [f\"{min(r)} {max(r)}\" for r in result]\n        result = \";\".join(result)\n        results.append(result)\n    return results\n\n\ndef get_predictions(results):\n    predictions = []\n    for result in results:\n        prediction = []\n        if result != \"\":\n            for loc in [s.split() for s in result.split(';')]:\n                start, end = int(loc[0]), int(loc[1])\n                prediction.append([start, end])\n        predictions.append(prediction)\n    return predictions","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:17:22.89466Z","iopub.execute_input":"2022-04-11T06:17:22.89489Z","iopub.status.idle":"2022-04-11T06:17:22.914012Z","shell.execute_reply.started":"2022-04-11T06:17:22.894862Z","shell.execute_reply":"2022-04-11T06:17:22.913079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# OOF","metadata":{}},{"cell_type":"code","source":"\noof0 = pd.read_pickle('../input/nbme-debertabase/oof_fold0.pkl')\noof1 = pd.read_pickle('../input/nbme-debertabase/oof_fold1.pkl')\noof2 = pd.read_pickle('../input/nbme-debertabase/oof_fold2.pkl')\noof3 = pd.read_pickle('../input/nbme-debertabase/oof_fold3.pkl')\noof4 = pd.read_pickle('../input/nbme-debertabase/oof_fold4.pkl')\n\noof_df = pd.DataFrame()  \noof_df = pd.concat([oof0, oof1,oof2,oof3,oof4])\n\n\ntruths = create_labels_for_scoring(oof_df)\nchar_probs = get_char_probs(oof_df['pn_history'].values,\n                            oof_df[[i for i in range(MAX_LEN)]].values, \n                            tokenizer)\nbest_th = 0.5\nbest_score = 0.\nfor th in np.arange(0.45, 0.55, 0.01):\n    th = np.round(th, 2)\n    results = get_results(char_probs, th=th)\n    preds = get_predictions(results)\n    score = get_score(preds, truths)\n    if best_score < score:\n        best_th = th\n        best_score = score\n    print(f\"th: {th}  score: {score:.5f}\")\nprint(f\"best_th: {best_th}  score: {best_score:.5f}\")","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:17:22.929958Z","iopub.execute_input":"2022-04-11T06:17:22.930232Z","iopub.status.idle":"2022-04-11T06:18:12.6572Z","shell.execute_reply.started":"2022-04-11T06:17:22.9302Z","shell.execute_reply":"2022-04-11T06:18:12.656181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Loading","metadata":{}},{"cell_type":"markdown","source":"### train.csv","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/nbme-score-clinical-patient-notes/train.csv')\ntrain['annotation'] = train['annotation'].apply(ast.literal_eval) # Construct an object from a string\ntrain['location'] = train['location'].apply(ast.literal_eval) # Construct an object from a string\nprint(f\"train.shape: {train.shape}\")\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:18:12.659939Z","iopub.execute_input":"2022-04-11T06:18:12.660197Z","iopub.status.idle":"2022-04-11T06:18:12.94243Z","shell.execute_reply.started":"2022-04-11T06:18:12.660167Z","shell.execute_reply":"2022-04-11T06:18:12.941498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### features.csv","metadata":{}},{"cell_type":"code","source":"features = pd.read_csv('../input/nbme-score-clinical-patient-notes/features.csv')\nprint(f\"features.shape: {features.shape}\")\nfeatures.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:18:12.943773Z","iopub.execute_input":"2022-04-11T06:18:12.943994Z","iopub.status.idle":"2022-04-11T06:18:12.957157Z","shell.execute_reply.started":"2022-04-11T06:18:12.943966Z","shell.execute_reply":"2022-04-11T06:18:12.95649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### patient_notes.csv","metadata":{}},{"cell_type":"code","source":"patient_notes = pd.read_csv('../input/nbme-score-clinical-patient-notes/patient_notes.csv')\nprint(f\"patient_notes.shape: {patient_notes.shape}\")\npatient_notes.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:18:12.95914Z","iopub.execute_input":"2022-04-11T06:18:12.959351Z","iopub.status.idle":"2022-04-11T06:18:13.302916Z","shell.execute_reply.started":"2022-04-11T06:18:12.959326Z","shell.execute_reply":"2022-04-11T06:18:13.302034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Merging","metadata":{}},{"cell_type":"code","source":"train = train.merge(features, on=['feature_num', 'case_num'], how='left')\ntrain = train.merge(patient_notes, on=['pn_num', 'case_num'], how='left')\ntrain['annotation_length'] = train['annotation'].apply(len)\nprint(f\"train.shape: {train.shape}\")\ntrain.head()\n\n\nif debug:\n    train = train.sample(n=50, random_state=0).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:18:13.304295Z","iopub.execute_input":"2022-04-11T06:18:13.304518Z","iopub.status.idle":"2022-04-11T06:18:13.347304Z","shell.execute_reply.started":"2022-04-11T06:18:13.30449Z","shell.execute_reply":"2022-04-11T06:18:13.346404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Annotations Visualization","metadata":{}},{"cell_type":"code","source":"idx=5910\n\nlocations = train.loc[idx,'location']\npn_history= train.loc[idx,'pn_history']\n\nstart_pos = []\nend_pos = []\n\nfor location in locations:\n    for loc in [s.split() for s in location.split(';')]:\n        start_pos.append(int(loc[0]))\n        end_pos.append(int(loc[1]))\n\n\nents = []\nfor i in range(len(start_pos)):\n    ents.append({\n        'start': int(start_pos[i]), \n        'end' : int(end_pos[i]),\n        \"label\" : \"Annotation\"\n    })\ndoc = {\n    'text' : pn_history,\n    \"ents\" : ents\n}\n\ncolors = {\"Annotation\": \"linear-gradient(0deg, #888, #eeaaaa)\"} \noptions = {\"colors\": colors}\nspacy.displacy.render(doc, style=\"ent\", options=options , manual=True, jupyter=True);","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:18:13.349067Z","iopub.execute_input":"2022-04-11T06:18:13.349379Z","iopub.status.idle":"2022-04-11T06:18:13.364943Z","shell.execute_reply.started":"2022-04-11T06:18:13.349337Z","shell.execute_reply":"2022-04-11T06:18:13.364047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocess the data","metadata":{}},{"cell_type":"code","source":"# ------------------------- prepare_location ------------------------------\ndef prepare_location(locations: str) -> List[Tuple[int]]:\n    \"\"\"\n    This function returns list of tuples of locations\n    \"\"\"\n    location_tuple_list = []\n    for location in locations:\n        for loc in [s.split() for s in location.split(';')]:\n            start, end = int(loc[0]), int(loc[1])\n            location_tuple_list.append((start, end))\n    \n    return location_tuple_list\n# ------------------------- prepare_input ------------------------------\ndef prepare_input(pn_history: str, feature_text: str) -> Tuple[np.array]:\n    \"\"\"\n    This function tokenizes pn_history and feature text and\n    returns numpy array of input_ids and attention_masks\n    \"\"\"\n    tokens = tokenizer(\n        pn_history,\n        feature_text,\n        max_length=MAX_LEN,\n        padding=\"max_length\",\n        add_special_tokens=True,\n    )\n    \n    input_ids = tokens['input_ids']\n    attention_mask = tokens[\"attention_mask\"]\n    return (np.array(input_ids), np.array(attention_mask))\n# ------------------------- prepare_labels ------------------------------\n# Thanks yasufuminakama \n# https://www.kaggle.com/yasufuminakama/nbme-deberta-base-baseline-train\ndef prepare_labels(pn_history, annotation_length, location_list):\n    \"\"\"\n    This function creates labels with are vectors of zeros (no entity)\n    and ones (entity)\n    \"\"\"\n    tokenized = tokenizer(\n        pn_history,\n        add_special_tokens=True,\n        max_length=MAX_LEN,\n        padding=\"max_length\",\n        return_offsets_mapping=True\n    )\n    offset_mapping = tokenized[\"offset_mapping\"]\n    label = np.zeros(len(offset_mapping))\n    if annotation_length != 0:\n        locations = prepare_location(location_list)\n        for location in locations:\n            start_idx, end_idx = -1, -1\n            start, end = location\n            for idx in range(len(offset_mapping)):\n                if (start_idx == -1) & (start < offset_mapping[idx][0]):\n                    start_idx = idx - 1\n                if (end_idx == -1) & (end <= offset_mapping[idx][1]):\n                    end_idx = idx + 1\n            if start_idx == -1:\n                start_idx = end_idx\n            if (start_idx != -1) & (end_idx != -1):\n                label[start_idx:end_idx] = 1\n            \n    return np.array(label)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:18:13.366617Z","iopub.execute_input":"2022-04-11T06:18:13.367209Z","iopub.status.idle":"2022-04-11T06:18:13.382801Z","shell.execute_reply.started":"2022-04-11T06:18:13.367166Z","shell.execute_reply":"2022-04-11T06:18:13.382108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# metrics\nclass F1Score(tf.keras.metrics.Metric):\n    def __init__(self, name='f1', **kwargs):\n        super(F1Score, self).__init__(name=name, **kwargs)\n        self.f1 = tfa.metrics.F1Score(num_classes=2, average='micro', threshold=0.50)\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        y_true = tf.reshape(y_true, (-1,MAX_LEN))\n        y_pred = tf.reshape(y_pred, (-1,MAX_LEN))\n        self.f1.update_state(y_true, y_pred)\n        \n    def reset_state(self):\n        self.f1.reset_state()\n    \n    def result(self):\n        return self.f1.result()\n    \nmetrics = [\n    F1Score(), \n    tf.keras.metrics.Recall(thresholds=[0.5]), \n    tf.keras.metrics.Precision(thresholds=[0.5])\n]","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:18:13.384495Z","iopub.execute_input":"2022-04-11T06:18:13.385011Z","iopub.status.idle":"2022-04-11T06:18:13.409202Z","shell.execute_reply.started":"2022-04-11T06:18:13.384966Z","shell.execute_reply":"2022-04-11T06:18:13.408422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create_model\ndef create_model() -> tf.keras.Model:\n    input_tokens = tf.keras.layers.Input(shape=(MAX_LEN,), name = 'input_tokens', dtype=tf.int32)\n    attention_mask = tf.keras.layers.Input(shape=(MAX_LEN,), name = 'attention_mask', dtype=tf.int32)\n    \n    backbone = TFAutoModel.from_pretrained('../input/nbme-deberta/microsoft/deberta-base/model')\n\n    out = backbone(input_tokens, attention_mask=attention_mask)[0]\n    out = tf.keras.layers.Dropout(0.2)(out)\n    out = tf.keras.layers.Dense(1, activation='sigmoid')(out)\n    \n    model = tf.keras.Model(inputs=[input_tokens, attention_mask], outputs=out)\n\n    return model\n\nmodel = create_model()\nmodel.summary()\n\noptimizer = tf.keras.optimizers.Adam(LEARNING_RATE, clipnorm=CLIP_NORM)\nloss = tf.keras.losses.BinaryCrossentropy(reduction=\"none\")\nmodel.compile(optimizer=optimizer,loss=loss,metrics=metrics)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:18:13.410902Z","iopub.execute_input":"2022-04-11T06:18:13.411453Z","iopub.status.idle":"2022-04-11T06:18:24.49632Z","shell.execute_reply.started":"2022-04-11T06:18:13.411409Z","shell.execute_reply":"2022-04-11T06:18:24.495446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inference","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv('../input/nbme-score-clinical-patient-notes/test.csv')\ntest = test.merge(features, on=['feature_num', 'case_num'], how='left')\ntest = test.merge(patient_notes, on=['pn_num', 'case_num'], how='left')\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:18:24.499365Z","iopub.execute_input":"2022-04-11T06:18:24.499884Z","iopub.status.idle":"2022-04-11T06:18:24.530255Z","shell.execute_reply.started":"2022-04-11T06:18:24.49984Z","shell.execute_reply":"2022-04-11T06:18:24.529393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test Dataset","metadata":{}},{"cell_type":"code","source":"def create_data(dataframe: pd.DataFrame,train=True):\n    pn_history = dataframe[\"pn_history\"].values\n    feature_text = dataframe[\"feature_text\"].values\n    if train:\n        annotation_length = dataframe['annotation_length'].values\n        location = dataframe['location'].values\n    input_ids = []\n    attention_mask = []\n    labels = []\n\n    for i in range(len(dataframe)):\n        inputs, masks = prepare_input(pn_history[i], feature_text[i])\n        input_ids.append(inputs)\n        attention_mask.append(masks)\n        if train:\n            lbls = prepare_labels(pn_history[i], annotation_length[i], location[i])\n            labels.append(lbls)\n    return {\"input_ids\":input_ids,\"attention_mask\":attention_mask}, labels\n    ","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:18:24.531749Z","iopub.execute_input":"2022-04-11T06:18:24.53222Z","iopub.status.idle":"2022-04-11T06:18:24.541511Z","shell.execute_reply.started":"2022-04-11T06:18:24.532179Z","shell.execute_reply":"2022-04-11T06:18:24.540647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data, test_labels = create_data(test,train=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:18:24.543071Z","iopub.execute_input":"2022-04-11T06:18:24.543439Z","iopub.status.idle":"2022-04-11T06:18:24.564315Z","shell.execute_reply.started":"2022-04-11T06:18:24.543398Z","shell.execute_reply":"2022-04-11T06:18:24.563361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Functions","metadata":{}},{"cell_type":"code","source":"# Thanks yasufuminakama \n# https://www.kaggle.com/yasufuminakama/nbme-deberta-base-baseline-train\n\ndef get_char_probs(texts, predictions, tokenizer):\n    results = [np.zeros(len(t)) for t in texts]\n    for i, (text, prediction) in enumerate(zip(texts, predictions)):\n        encoded = tokenizer(text, \n                            add_special_tokens=True,\n                            return_offsets_mapping=True)\n        for idx, (offset_mapping, pred) in enumerate(zip(encoded['offset_mapping'], prediction)):\n            start = offset_mapping[0]\n            end = offset_mapping[1]\n            results[i][start:end] = pred\n    return results\n\n\ndef get_results(char_probs, th=0.5):\n    results = []\n    for char_prob in char_probs:\n        result = np.where(char_prob >= th)[0] + 1\n        result = [list(g) for _, g in itertools.groupby(result, key=lambda n, c=itertools.count(): n - next(c))]\n        result = [f\"{min(r)} {max(r)}\" for r in result]\n        result = \";\".join(result)\n        results.append(result)\n    return results","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:18:24.565792Z","iopub.execute_input":"2022-04-11T06:18:24.566518Z","iopub.status.idle":"2022-04-11T06:18:24.577324Z","shell.execute_reply.started":"2022-04-11T06:18:24.566474Z","shell.execute_reply":"2022-04-11T06:18:24.576771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = []\nfor fold in trn_fold:\n    model.load_weights(f'../input/nbme-debertabase/model_deberta_fold{fold}.h5')\n    pred = model.predict((np.asarray(test_data['input_ids']),np.asarray(test_data['attention_mask']),))\n    pred = pred.reshape(len(test), MAX_LEN)\n    char_probs = get_char_probs(test['pn_history'].values, pred, tokenizer)\n\n    preds.append(char_probs)\n    del pred, char_probs; gc.collect()\npreds = np.mean(preds, axis=0)\n\nresults = get_results(preds, th=best_th)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:18:24.578864Z","iopub.execute_input":"2022-04-11T06:18:24.579449Z","iopub.status.idle":"2022-04-11T06:19:35.874063Z","shell.execute_reply.started":"2022-04-11T06:18:24.579408Z","shell.execute_reply":"2022-04-11T06:19:35.872763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"submission = pd.read_csv('../input/nbme-score-clinical-patient-notes/sample_submission.csv')\nsubmission['location'] = results\ndisplay(submission.head())\nsubmission[['id', 'location']].to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T06:19:35.876239Z","iopub.execute_input":"2022-04-11T06:19:35.876877Z","iopub.status.idle":"2022-04-11T06:19:35.90505Z","shell.execute_reply.started":"2022-04-11T06:19:35.876842Z","shell.execute_reply":"2022-04-11T06:19:35.904271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## References","metadata":{}},{"cell_type":"markdown","source":"1. https://huggingface.co/course/chapter1/4?fw=tf\n1. https://www.microsoft.com/en-us/research/publication/deberta-decoding-enhanced-bert-with-disentangled-attention-2/\n1. https://github.com/microsoft/DeBERTa\n1. https://huggingface.co/course/chapter1/1\n1. https://www.kaggle.com/yasufuminakama/nbme-deberta-base-baseline-train\n1. https://www.kaggle.com/huchlatymon/nbme-eda-deberta-train-cv-0-85\n1. https://colab.research.google.com/drive/1pH9NKhAHT40ygOOf4bwld8j221r9SRq_?usp=sharing#scrollTo=SzCwE_mHkPxj\n1. https://tensorexamples.com/2020/07/27/Using-the-tf.data.Dataset.html","metadata":{}}]}