{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-05T18:27:26.826305Z","iopub.execute_input":"2022-02-05T18:27:26.827087Z","iopub.status.idle":"2022-02-05T18:27:26.839006Z","shell.execute_reply.started":"2022-02-05T18:27:26.827035Z","shell.execute_reply":"2022-02-05T18:27:26.8382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install textstat\n\nimport numpy as np\nimport pandas as pd \nimport os\nimport re\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport nltk\nimport textstat\nimport spacy\nnlp = spacy.load('en_core_web_sm')\n\nfrom termcolor import colored\nfrom wordcloud import WordCloud,STOPWORDS\nfrom spacy import displacy\nfrom nltk.tokenize import sent_tokenize, word_tokenize \n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2022-02-05T18:27:26.842374Z","iopub.execute_input":"2022-02-05T18:27:26.843063Z","iopub.status.idle":"2022-02-05T18:27:34.907953Z","shell.execute_reply.started":"2022-02-05T18:27:26.842954Z","shell.execute_reply":"2022-02-05T18:27:34.90717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/nbme-score-clinical-patient-notes/train.csv')\ntest = pd.read_csv('../input/nbme-score-clinical-patient-notes/test.csv')\nss = pd.read_csv('../input/nbme-score-clinical-patient-notes/sample_submission.csv')\npn = pd.read_csv('../input/nbme-score-clinical-patient-notes/patient_notes.csv')\nfeatures = pd.read_csv('../input/nbme-score-clinical-patient-notes/features.csv')\ntrain = train.merge(features, on=['case_num','feature_num'], validate='m:1')\ntrain = train.merge(pn, validate='m:1')","metadata":{"execution":{"iopub.status.busy":"2022-02-05T18:27:34.910542Z","iopub.execute_input":"2022-02-05T18:27:34.911655Z","iopub.status.idle":"2022-02-05T18:27:35.274112Z","shell.execute_reply.started":"2022-02-05T18:27:34.911602Z","shell.execute_reply":"2022-02-05T18:27:35.273414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-05T18:27:35.275988Z","iopub.execute_input":"2022-02-05T18:27:35.276249Z","iopub.status.idle":"2022-02-05T18:27:35.286274Z","shell.execute_reply.started":"2022-02-05T18:27:35.276213Z","shell.execute_reply":"2022-02-05T18:27:35.285526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pn.nunique()","metadata":{"execution":{"iopub.status.busy":"2022-02-05T18:27:35.28756Z","iopub.execute_input":"2022-02-05T18:27:35.288022Z","iopub.status.idle":"2022-02-05T18:27:35.379711Z","shell.execute_reply.started":"2022-02-05T18:27:35.287974Z","shell.execute_reply":"2022-02-05T18:27:35.378981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def patient_data(pn_num):\n    subset = train[train['pn_num'] == pn_num]\n    \n    features_lst = subset['feature_num'].tolist()\n    annotations_lst = subset['annotation'].tolist()\n    \n    subset_c = subset.copy()\n    subset_c['location'] = subset_c['location'].apply(eval)\n    subset_c['annotation'] = subset_c['annotation'].apply(eval)\n    locations  = subset_c[\"location\"]\n    annotations = subset_c[\"annotation\"]\n    \n    print(\"*\"*80)\n    print(colored(\"Patient Number: \" + str(pn_num), 'green'))\n    patient_history = pn[pn['pn_num']==pn_num]['pn_history'].item()\n    \n    print(colored(\"\\nAnnotated Patient History\", 'green'))\n    \n    ents = []\n    for location in locations:\n        for i in range(len(location)):\n            for loc in location:\n                val = loc.split()\n                ents.append({\n                'start': int(val[0]), \n                'end' :  int(val[1]),\n                'label' : \"Annotation\"\n                })\n    ents = sorted(ents, key = lambda i: i['start'])\n\n    doc = {\n        'text' : patient_history,\n        'ents' : ents\n    }\n    colors = {\"Annotation\" :\"linear-gradient(to right, #2980b9, #6dd5fa, #ffffff);\" } \n    options = {\"colors\": colors}\n    spacy.displacy.render(doc, style='ent', options = options , manual=True, jupyter=True);\n    \n    print(colored(\"\\nVisualizing NER\", 'green'))\n    doc = nlp(patient_history)\n    displacy.render(doc, style='ent', jupyter = True)\n    \n    print(colored(\"\\nVisualizing POS tagging\", 'green'))\n    sentences = sent_tokenize(patient_history)\n    word_count = lambda sentence: len(word_tokenize(sentence))\n    pos_text = max(sentences, key=word_count)  \n    doc = nlp(pos_text)\n    displacy.render(doc, style=\"dep\")\n\n    print(colored(\"\\nFeatures\", 'green'))\n    for feature_num in features_lst:\n        feature = features[features['feature_num'] == feature_num]['feature_text'][feature_num]\n        print(colored(feature, 'blue'))\n        \npatient_data(16)\npatient_data(46)\npatient_data(100)","metadata":{"execution":{"iopub.status.busy":"2022-02-05T18:27:35.381126Z","iopub.execute_input":"2022-02-05T18:27:35.381387Z","iopub.status.idle":"2022-02-05T18:27:35.638577Z","shell.execute_reply.started":"2022-02-05T18:27:35.381352Z","shell.execute_reply":"2022-02-05T18:27:35.637774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def avg_word_len(df):\n    df = df.str.split().apply(lambda x : [len(i) for i in x]).map(lambda x: np.mean(x))\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-02-05T18:27:35.639907Z","iopub.execute_input":"2022-02-05T18:27:35.640226Z","iopub.status.idle":"2022-02-05T18:27:35.645405Z","shell.execute_reply.started":"2022-02-05T18:27:35.640188Z","shell.execute_reply":"2022-02-05T18:27:35.644734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_distribution(text_props, num_sub):\n    fig, ax = plt.subplots(1,num_sub,figsize=(20,10))\n    sns.kdeplot(data=text_props, x=\"text_len\",color=\"#7209B7\",ax=ax[0])\n    ax[0].set_title(\"Character count distribution\",font=\"Serif\")\n    \n    sns.kdeplot(data=text_props, x=\"avg_text\",color=\"#FFBA08\",ax=ax[1])\n    ax[1].set_title(\"Average word length distribution\",font=\"Serif\")\n    \n    if num_sub != 2:\n        sns.kdeplot(data=text_props, x=\"lexicon_count\",color=\"#F72585\",ax=ax[2])\n        ax[2].set_title(\"Word count distribution\",font=\"Serif\")\n        \n    plt.tight_layout()\n    fig.subplots_adjust(wspace=0.2, hspace=0.2, top=0.93)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-05T18:27:35.64666Z","iopub.execute_input":"2022-02-05T18:27:35.647276Z","iopub.status.idle":"2022-02-05T18:27:35.659566Z","shell.execute_reply.started":"2022-02-05T18:27:35.647238Z","shell.execute_reply":"2022-02-05T18:27:35.658646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def text_properties(df, col, num_sub):\n    text_props = df.copy()\n    text_len = df[col].str.len()\n    avg_text = avg_word_len(df[col])\n    lexicon_count = []\n    sentence_count = []\n    for i in range(len(df)):\n        lc = textstat.lexicon_count(df[col][i])\n        lexicon_count.append(lc)\n\n    text_props['text_len'] = text_len\n    text_props['lexicon_count'] = lexicon_count\n    text_props['avg_text'] = avg_text\n    \n    print(colored(col, 'green'))\n    plot_distribution(text_props, num_sub)\n    \ntext_properties(train, 'annotation',3)\ntext_properties(features, 'feature_text',2)\ntext_properties(pn, 'pn_history',3)","metadata":{"execution":{"iopub.status.busy":"2022-02-05T18:27:35.66337Z","iopub.execute_input":"2022-02-05T18:27:35.663792Z","iopub.status.idle":"2022-02-05T18:27:43.413967Z","shell.execute_reply.started":"2022-02-05T18:27:35.663756Z","shell.execute_reply":"2022-02-05T18:27:43.413299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add label if the test taker correctly identified the feature\ntrain['correct'] = ~(train['annotation'] == \"[]\")\ntrain.groupby('pn_num')['correct'].mean().sort_values() \\\n    .plot(kind='hist', bins=25, figsize=(12, 5),\n          title='% of Features Correctly Noted by Doctor')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-05T18:27:43.415259Z","iopub.execute_input":"2022-02-05T18:27:43.415882Z","iopub.status.idle":"2022-02-05T18:27:43.647995Z","shell.execute_reply.started":"2022-02-05T18:27:43.41584Z","shell.execute_reply":"2022-02-05T18:27:43.647304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_taker_results = train.groupby(['pn_num','case_num'])['correct'] \\\n    .mean().reset_index()\nfig, ax = plt.subplots(figsize=(12, 5))\nsns.boxplot(data=test_taker_results, x='case_num', y='correct')\nax.set_title('% of Features Captured by Case Number')\nax.set_xlabel('Case Number')\nax.set_ylabel('% of Features Captured')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-05T18:27:43.649368Z","iopub.execute_input":"2022-02-05T18:27:43.649618Z","iopub.status.idle":"2022-02-05T18:27:43.958321Z","shell.execute_reply.started":"2022-02-05T18:27:43.649583Z","shell.execute_reply":"2022-02-05T18:27:43.957629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.groupby('feature_num')['correct'].mean() \\\n    .plot(kind='hist', bins=50, color='#00BFC4', figsize=(12, 5),\n          title='% of Correct Annotation for Features', edgecolor='black')\nax.set_xlabel('% of Correct Annotations')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-05T18:27:43.959743Z","iopub.execute_input":"2022-02-05T18:27:43.960005Z","iopub.status.idle":"2022-02-05T18:27:44.211113Z","shell.execute_reply.started":"2022-02-05T18:27:43.95997Z","shell.execute_reply":"2022-02-05T18:27:44.210322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.groupby('feature_num')['correct'].mean().sort_values()\ntrain.query('feature_num == 807').head()","metadata":{"execution":{"iopub.status.busy":"2022-02-05T18:27:44.212343Z","iopub.execute_input":"2022-02-05T18:27:44.212602Z","iopub.status.idle":"2022-02-05T18:27:44.231981Z","shell.execute_reply.started":"2022-02-05T18:27:44.212567Z","shell.execute_reply":"2022-02-05T18:27:44.231345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.query('feature_num == 807').loc[\n    train.query('feature_num == 807')['pn_history'].str.lower().str.contains('hallucinations')\n]","metadata":{"execution":{"iopub.status.busy":"2022-02-05T18:27:44.23326Z","iopub.execute_input":"2022-02-05T18:27:44.233531Z","iopub.status.idle":"2022-02-05T18:27:44.258352Z","shell.execute_reply.started":"2022-02-05T18:27:44.233494Z","shell.execute_reply":"2022-02-05T18:27:44.257623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\n    train.query('feature_num == 807').loc[\n    train.query('feature_num == 807')['pn_history'].str.lower().str.contains('hallucinations') &\n    train.query('feature_num == 807')['pn_history'].str.lower().str.contains('ambien')\n]['pn_history'].values[0]\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-05T18:27:44.259712Z","iopub.execute_input":"2022-02-05T18:27:44.259953Z","iopub.status.idle":"2022-02-05T18:27:44.27587Z","shell.execute_reply.started":"2022-02-05T18:27:44.259919Z","shell.execute_reply":"2022-02-05T18:27:44.275137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train.query('feature_num == 209').loc[\n    train.query('feature_num == 209')['pn_history'].str.lower().str.contains('stress')\n]['pn_history']\n     )","metadata":{"execution":{"iopub.status.busy":"2022-02-05T18:27:44.276935Z","iopub.execute_input":"2022-02-05T18:27:44.277778Z","iopub.status.idle":"2022-02-05T18:27:44.289816Z","shell.execute_reply.started":"2022-02-05T18:27:44.277739Z","shell.execute_reply":"2022-02-05T18:27:44.289155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train.query('feature_num == 209').sort_values('correct') \\\n    .query('pn_num == 21054')['pn_history'].values[0])","metadata":{"execution":{"iopub.status.busy":"2022-02-05T18:27:44.291023Z","iopub.execute_input":"2022-02-05T18:27:44.291462Z","iopub.status.idle":"2022-02-05T18:27:44.302382Z","shell.execute_reply.started":"2022-02-05T18:27:44.291427Z","shell.execute_reply":"2022-02-05T18:27:44.301726Z"},"trusted":true},"execution_count":null,"outputs":[]}]}