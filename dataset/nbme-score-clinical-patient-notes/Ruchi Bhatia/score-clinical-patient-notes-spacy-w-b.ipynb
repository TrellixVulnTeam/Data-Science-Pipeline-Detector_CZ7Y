{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"![](https://i.imgur.com/o0xPvMY.png)","metadata":{}},{"cell_type":"code","source":"!pip install textstat\n\nimport numpy as np\nimport pandas as pd \nimport os\nimport re\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport nltk\nimport textstat\nimport wandb\nimport spacy\nnlp = spacy.load('en_core_web_sm')\n\nfrom termcolor import colored\nfrom wordcloud import WordCloud,STOPWORDS\nfrom spacy import displacy\nfrom nltk.tokenize import sent_tokenize, word_tokenize \n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-02-17T12:59:22.635849Z","iopub.execute_input":"2022-02-17T12:59:22.636989Z","iopub.status.idle":"2022-02-17T12:59:49.015876Z","shell.execute_reply.started":"2022-02-17T12:59:22.636849Z","shell.execute_reply":"2022-02-17T12:59:49.014584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<img src=\"https://camo.githubusercontent.com/dd842f7b0be57140e68b2ab9cb007992acd131c48284eaf6b1aca758bfea358b/68747470733a2f2f692e696d6775722e636f6d2f52557469567a482e706e67\">\n\nI will be integrating W&B for visualizations and logging artifacts!\n\n> [NBME - Score Clinical Patient Notes](https://wandb.ai/ruchi798/nbme?workspace=user-ruchi798)üèãÔ∏è‚Äç‚ôÄÔ∏è\n> \n> - To get the API key, an account is to be created on the [website](https://wandb.ai/home) first.\n> - Next, use secrets to use API Keys more securely ü§´","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\napi_key = user_secrets.get_secret(\"api_key\")\n\nCONFIG = {'competition': 'nbme', '_wandb_kernel': 'ruch'}\n\nos.environ[\"WANDB_SILENT\"] = \"true\"","metadata":{"execution":{"iopub.status.busy":"2022-02-17T12:59:49.01776Z","iopub.execute_input":"2022-02-17T12:59:49.017997Z","iopub.status.idle":"2022-02-17T12:59:49.26433Z","shell.execute_reply.started":"2022-02-17T12:59:49.017968Z","shell.execute_reply":"2022-02-17T12:59:49.263165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! wandb login $api_key","metadata":{"execution":{"iopub.status.busy":"2022-02-17T12:59:49.265804Z","iopub.execute_input":"2022-02-17T12:59:49.266174Z","iopub.status.idle":"2022-02-17T12:59:52.371498Z","shell.execute_reply.started":"2022-02-17T12:59:49.266127Z","shell.execute_reply":"2022-02-17T12:59:52.369929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})","metadata":{"execution":{"iopub.status.busy":"2022-02-17T13:00:19.285823Z","iopub.execute_input":"2022-02-17T13:00:19.286221Z","iopub.status.idle":"2022-02-17T13:00:19.292451Z","shell.execute_reply.started":"2022-02-17T13:00:19.286183Z","shell.execute_reply":"2022-02-17T13:00:19.291347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BASE_PATH = \"../input/nbme-score-clinical-patient-notes/\"\nfeatures_df = pd.read_csv(BASE_PATH + \"features.csv\")\npatient_notes_df = pd.read_csv(BASE_PATH + \"patient_notes.csv\")\ntrain_df = pd.read_csv(BASE_PATH + \"train.csv\")\ntest_df = pd.read_csv(BASE_PATH + \"test.csv\")\nsubmission_df = pd.read_csv(BASE_PATH + \"sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-02-17T13:00:21.18863Z","iopub.execute_input":"2022-02-17T13:00:21.188997Z","iopub.status.idle":"2022-02-17T13:00:21.985527Z","shell.execute_reply.started":"2022-02-17T13:00:21.188958Z","shell.execute_reply":"2022-02-17T13:00:21.984421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"```features.csv```\n\nA rubric describes the key concepts relevant to each case.\n\n* feature_num - A unique identifier for each feature.\n* case_num - A unique identifier for each case.\n* feature_text - A description of the feature.","metadata":{}},{"cell_type":"code","source":"features_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-17T13:00:24.007939Z","iopub.execute_input":"2022-02-17T13:00:24.00833Z","iopub.status.idle":"2022-02-17T13:00:24.031211Z","shell.execute_reply.started":"2022-02-17T13:00:24.008292Z","shell.execute_reply":"2022-02-17T13:00:24.030116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features_df.nunique()","metadata":{"execution":{"iopub.status.busy":"2022-02-17T13:00:24.41692Z","iopub.execute_input":"2022-02-17T13:00:24.417463Z","iopub.status.idle":"2022-02-17T13:00:24.431665Z","shell.execute_reply.started":"2022-02-17T13:00:24.417422Z","shell.execute_reply":"2022-02-17T13:00:24.430605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"```patient_notes.csv``` \n\nText detailing important information related by the patient during the encounter (physical exam and interview)\n\n* pn_num - A unique identifier for each patient note.\n* case_num - A unique identifier for the clinical case a patient note represents.\n* pn_history - The text of the encounter as recorded by the test taker.","metadata":{}},{"cell_type":"code","source":"patient_notes_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-17T13:00:26.048528Z","iopub.execute_input":"2022-02-17T13:00:26.048879Z","iopub.status.idle":"2022-02-17T13:00:26.061062Z","shell.execute_reply.started":"2022-02-17T13:00:26.048844Z","shell.execute_reply":"2022-02-17T13:00:26.0597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"patient_notes_df.nunique()","metadata":{"execution":{"iopub.status.busy":"2022-02-17T13:00:27.015512Z","iopub.execute_input":"2022-02-17T13:00:27.015841Z","iopub.status.idle":"2022-02-17T13:00:27.139936Z","shell.execute_reply.started":"2022-02-17T13:00:27.015809Z","shell.execute_reply":"2022-02-17T13:00:27.139345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"```train.csv```\n* id - Unique identifier for each patient note / feature pair.\n* pn_num - The patient note annotated in this row.\n* feature_num - The feature annotated in this row.\n* case_num - The case to which this patient note belongs.\n* annotation - The text(s) within a patient note indicating a feature. A feature may be indicated multiple times within a single note.\n* location - Character spans indicating the location of each annotation within the note. Multiple spans may be needed to represent an annotation, in which case the spans are delimited by a semicolon ;.","metadata":{}},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-17T13:00:30.212321Z","iopub.execute_input":"2022-02-17T13:00:30.212607Z","iopub.status.idle":"2022-02-17T13:00:30.226658Z","shell.execute_reply.started":"2022-02-17T13:00:30.212577Z","shell.execute_reply":"2022-02-17T13:00:30.225521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.nunique()","metadata":{"execution":{"iopub.status.busy":"2022-02-17T13:00:30.599002Z","iopub.execute_input":"2022-02-17T13:00:30.599404Z","iopub.status.idle":"2022-02-17T13:00:30.622802Z","shell.execute_reply.started":"2022-02-17T13:00:30.599364Z","shell.execute_reply":"2022-02-17T13:00:30.621735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<center><img src=\"https://raw.githubusercontent.com/github/explore/8cf1837393d83900e767cc895dcc814d053e2ffe/topics/spacy/spacy.png\"></center>\n\n#### üìù Using spaCy for visualizing annotations, NER and POS tagging! ","metadata":{}},{"cell_type":"markdown","source":"# üëÄ Annotations, NER & POS","metadata":{}},{"cell_type":"code","source":"def patient_data(pn_num):\n    subset = train_df[train_df['pn_num'] == pn_num]\n    \n    features_lst = subset['feature_num'].tolist()\n    annotations_lst = subset['annotation'].tolist()\n    \n    subset_c = subset.copy()\n    subset_c['location'] = subset_c['location'].apply(eval)\n    subset_c['annotation'] = subset_c['annotation'].apply(eval)\n    locations  = subset_c[\"location\"]\n    annotations = subset_c[\"annotation\"]\n    \n    print(\"*\"*80)\n    print(colored(\"Patient Number: \" + str(pn_num), 'green'))\n    patient_history = patient_notes_df[patient_notes_df['pn_num']==pn_num]['pn_history'].item()\n    \n    print(colored(\"\\nAnnotated Patient History\", 'green'))\n    \n    ents = []\n    for location in locations:\n        for i in range(len(location)):\n            for loc in location:\n                val = loc.split()\n                ents.append({\n                'start': int(val[0]), \n                'end' :  int(val[1]),\n                'label' : \"Annotation\"\n                })\n    ents = sorted(ents, key = lambda i: i['start'])\n\n    doc = {\n        'text' : patient_history,\n        'ents' : ents\n    }\n    colors = {\"Annotation\" :\"linear-gradient(to right, #2980b9, #6dd5fa, #ffffff);\" } \n    options = {\"colors\": colors}\n    spacy.displacy.render(doc, style='ent', options = options , manual=True, jupyter=True);\n    \n    print(colored(\"\\nVisualizing NER\", 'green'))\n    doc = nlp(patient_history)\n    displacy.render(doc, style='ent', jupyter = True)\n    \n    print(colored(\"\\nVisualizing POS tagging\", 'green'))\n    sentences = sent_tokenize(patient_history)\n    word_count = lambda sentence: len(word_tokenize(sentence))\n    pos_text = max(sentences, key=word_count)  \n    doc = nlp(pos_text)\n    displacy.render(doc, style=\"dep\")\n\n    print(colored(\"\\nFeatures\", 'green'))\n    for feature_num in features_lst:\n        feature = features_df[features_df['feature_num'] == feature_num]['feature_text'][feature_num]\n        print(colored(feature, 'blue'))\n        \npatient_data(16)\npatient_data(46)\npatient_data(100)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-17T13:00:35.901687Z","iopub.execute_input":"2022-02-17T13:00:35.902009Z","iopub.status.idle":"2022-02-17T13:00:36.261321Z","shell.execute_reply.started":"2022-02-17T13:00:35.901978Z","shell.execute_reply":"2022-02-17T13:00:36.260605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ‚òÅÔ∏è WordClouds","metadata":{}},{"cell_type":"code","source":"# color function for the wordcloud\ndef color_wc(word=None,font_size=None,position=None, orientation=None,font_path=None, random_state=None):\n    h = int(360.0 * 150.0 / 255.0)\n    s = int(100.0 * 255.0 / 255.0)\n    l = int(100.0 * float(random_state.randint(80, 120)) / 255.0)\n    return \"hsl({}, {}%, {}%)\".format(h, s, l)\n\ndef create_wordcloud(df, col):\n    print(colored(col, 'green'))\n    \n    run = wandb.init(project='nbme', job_type='image-visualization',name='wordCloud')\n    \n    fig = plt.gcf()\n    fig.set_size_inches(16, 8)\n    wc = WordCloud(stopwords=STOPWORDS,background_color=\"white\", contour_width=2, contour_color='blue',width=1500, height=750,color_func=color_wc,max_words=150, max_font_size=256,random_state=42)\n    wc.generate(' '.join(df[col]))\n    fig = plt.imshow(wc, interpolation=\"bilinear\")\n    fig = plt.axis('off')\n    \n    wc_name =  \"wordcloud_\" + col\n    wandb.log({wc_name: [wandb.Image(plt, caption=\"Wordcloud\")]})\n    run.finish()\n\ncreate_wordcloud(train_df, 'annotation')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-17T13:48:19.953918Z","iopub.execute_input":"2022-02-17T13:48:19.955024Z","iopub.status.idle":"2022-02-17T13:48:34.672803Z","shell.execute_reply.started":"2022-02-17T13:48:19.954971Z","shell.execute_reply":"2022-02-17T13:48:34.671835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"create_wordcloud(features_df, 'feature_text')","metadata":{"execution":{"iopub.status.busy":"2022-02-17T13:48:39.36495Z","iopub.execute_input":"2022-02-17T13:48:39.365607Z","iopub.status.idle":"2022-02-17T13:48:53.321706Z","shell.execute_reply.started":"2022-02-17T13:48:39.365566Z","shell.execute_reply":"2022-02-17T13:48:53.320397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"create_wordcloud(patient_notes_df, 'pn_history')","metadata":{"execution":{"iopub.status.busy":"2022-02-17T13:48:53.324069Z","iopub.execute_input":"2022-02-17T13:48:53.32503Z","iopub.status.idle":"2022-02-17T13:49:28.910004Z","shell.execute_reply.started":"2022-02-17T13:48:53.324965Z","shell.execute_reply":"2022-02-17T13:49:28.908955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üìä Text properties ","metadata":{}},{"cell_type":"code","source":"#====== Function to plot wandb histogram ======\ndef plot_wb_hist(df,name,title):\n    run = wandb.init(project='nbme', job_type='image-visualization',name=name)\n\n    dt = [[x] for x in df[name]]\n    table = wandb.Table(data=dt, columns=[name])\n    wandb.log({title : wandb.plot.histogram(table, name, title=title)})\n\n    run.finish()\n    \ndef avg_word_len(df):\n    df = df.str.split().apply(lambda x : [len(i) for i in x]).map(lambda x: np.mean(x))\n    return df\n\ndef plot_distribution(text_props, num_sub):\n    fig, ax = plt.subplots(1,num_sub,figsize=(20,10))\n    sns.kdeplot(data=text_props, x=\"text_len\",color=\"#7209B7\",ax=ax[0])\n    ax[0].set_title(\"Character count distribution\",font=\"Serif\")\n    \n    sns.kdeplot(data=text_props, x=\"avg_text\",color=\"#FFBA08\",ax=ax[1])\n    ax[1].set_title(\"Average word length distribution\",font=\"Serif\")\n    \n    if num_sub != 2:\n        sns.kdeplot(data=text_props, x=\"lexicon_count\",color=\"#F72585\",ax=ax[2])\n        ax[2].set_title(\"Word count distribution\",font=\"Serif\")\n        \n    plt.tight_layout()\n    fig.subplots_adjust(wspace=0.2, hspace=0.2, top=0.93)\n    plt.show()\n    \ndef text_properties(df, col, num_sub):\n    text_props = df.copy()\n    text_len = df[col].str.len()\n    avg_text = avg_word_len(df[col])\n    lexicon_count = []\n    sentence_count = []\n    for i in range(len(df)):\n        lc = textstat.lexicon_count(df[col][i])\n        lexicon_count.append(lc)\n\n    text_props['text_len'] = text_len\n    text_props['lexicon_count'] = lexicon_count\n    text_props['avg_text'] = avg_text\n    \n    print(colored(col, 'green'))\n    plot_distribution(text_props, num_sub)\n    return text_props\n    \ntext_props = text_properties(train_df, 'annotation',3)\nplot_wb_hist(text_props,\"text_len\",\"annotation: Character Count Distribution\")\nplot_wb_hist(text_props,\"lexicon_count\",\"annotation : Word Count Distribution\")\nplot_wb_hist(text_props,\"avg_text\",\"annotation : Average Word Length Distribution\")\n\ntext_props = text_properties(features_df, 'feature_text',2)\nplot_wb_hist(text_props,\"text_len\",\"feature_text : Character Count Distribution\")\nplot_wb_hist(text_props,\"avg_text\",\"feature_text : Average Word Length Distribution\")\n\ntext_props = text_properties(patient_notes_df, 'pn_history',3)\nplot_wb_hist(text_props,\"text_len\",\"pn_history : Character Count Distribution\")\nplot_wb_hist(text_props,\"lexicon_count\",\"pn_history : Word Count Distribution\")\nplot_wb_hist(text_props,\"avg_text\",\"pn_history : Average Word Length Distribution\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-17T13:27:01.790631Z","iopub.execute_input":"2022-02-17T13:27:01.79103Z","iopub.status.idle":"2022-02-17T13:29:07.087593Z","shell.execute_reply.started":"2022-02-17T13:27:01.790993Z","shell.execute_reply":"2022-02-17T13:29:07.08654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üî§ Abbreviations used ","metadata":{}},{"cell_type":"code","source":"pl = patient_notes_df['pn_history'].tolist()\npl1 = [i.split('\\n', 1)[0] for i in pl]\n\npattern = re.compile('(.*?)\\:')\nvals = []\nfor item in range(len(pl1)):\n    val = pattern.findall(pl1[item])\n    if val:\n        if(len(val[0]) < 10):\n            vals.append(val[0])\n\nprint(set(vals))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-17T13:01:14.510182Z","iopub.execute_input":"2022-02-17T13:01:14.510464Z","iopub.status.idle":"2022-02-17T13:02:21.411289Z","shell.execute_reply.started":"2022-02-17T13:01:14.51043Z","shell.execute_reply":"2022-02-17T13:02:21.409607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here's a snapshot of my [project](https://wandb.ai/ruchi798/nbme?workspace=user-ruchi798) ‚¨áÔ∏è\n\n![](https://i.imgur.com/5we1jz6.png)\n","metadata":{}}]}