{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>NBME</center></h2>","metadata":{}},{"cell_type":"markdown","source":"<center><img src = \"https://media.istockphoto.com/vectors/people-wait-in-hospital-hall-interior-vector-illustration-cartoon-vector-id1256189055?k=20&m=1256189055&s=170667a&w=0&h=H4XhK870bkOst0_YcAooxxZvga_Jq_dG7y-xXEQDU_s=\" width = \"577\" height = \"299\"/></center> ","metadata":{}},{"cell_type":"markdown","source":"Hi,\nI am writing this notebook for noobs like me who know nothing. ","metadata":{}},{"cell_type":"markdown","source":"I am going to explain you how to tackle this problem using bert and you can use whatever you like by just changing Model and tokenizer and 2-3 other parameters. Even if you Know nothing about key phrase extraction don't worry  read till end and you can tackle this problem. I know its hard in start you may dont have teammate dont know what to do with data not understand evaluation metrics, it happens to everyone in start but you should never give up. one more thing forking others notebook and submitting that notebook will not going to help you. Yes there is nothing wrong in reading others kernels.But you must read it from start to end understand what approach they used appreciate their work by upvoting kernel take inspiration from others and start writing your own code.","metadata":{}},{"cell_type":"markdown","source":"<font color='red'>If you find my kernel useful and my efforts appreciable, Please Upvote it , it motivates me to write more Quality content</font>","metadata":{}},{"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Contents</center></h2>","metadata":{}},{"cell_type":"markdown","source":"1. [About Competition](#about-competition) \n2. [Introduction](#introduction)  \n3. [Evaluation Metric](#evaluation-metric)  \n4. [Data Cleaning](#data-cleaning)  \n5. [Preprocessing](#preprocessing) \n6. [Config](#config)   \n7. [Utils](#utils)  \n8. [Dataset](#dataset)   \n9. [Model](#model)  \n10. [Engine](#engine)  \n11. [Train](#train)","metadata":{}},{"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>About Competition</center></h2>","metadata":{}},{"cell_type":"markdown","source":"When we visit a doctor,how they interpret our symptoms can determine whether our diagnosis is accurate. But before they are licensed, physician have had a lot of practice writing patient notes, patients history, physical exam findings, and their complaints. Learning and assessing the skill of writing patient notes requires feedback from other doctors a time-intensive process that could be improved with the addition of machine learning.","metadata":{}},{"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Introduction</center></h2>","metadata":{}},{"cell_type":"markdown","source":"I used bert-base-uncased pretrained model with pytorch.\n\n\nWhat we have?\n\nWe have 5 .csv files.\n1. ```features.csv```\n2. ```patients_notes.csv```\n3. ```sample_submission.csv```\n4. ```test.csv```\n5. ```train.csv```\n\nLets take a look at them one by one.","metadata":{}},{"cell_type":"code","source":"import os\nimport re\nimport gc\nimport copy\nimport pickle\nimport random\nfrom tqdm import tqdm\n\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom sklearn import model_selection\n\nimport torch \nimport torch.nn as nn\nfrom torch.optim import AdamW\nfrom torch.nn import Sigmoid\nfrom torch.utils.data import DataLoader\n\nimport tokenizers\nimport transformers\nfrom transformers import get_linear_schedule_with_warmup","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T12:27:16.684432Z","iopub.execute_input":"2022-02-23T12:27:16.68477Z","iopub.status.idle":"2022-02-23T12:27:28.349676Z","shell.execute_reply.started":"2022-02-23T12:27:16.68468Z","shell.execute_reply":"2022-02-23T12:27:28.348586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"../input/nbme-score-clinical-patient-notes/train.csv\")\npn_notes_df = pd.read_csv(\"../input/nbme-score-clinical-patient-notes/patient_notes.csv\")\nfeat_df = pd.read_csv(\"../input/nbme-score-clinical-patient-notes/features.csv\")\n\nprint(train_df.shape)\ndisplay(train_df.head())","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T12:27:28.352194Z","iopub.execute_input":"2022-02-23T12:27:28.352511Z","iopub.status.idle":"2022-02-23T12:27:29.032273Z","shell.execute_reply.started":"2022-02-23T12:27:28.35247Z","shell.execute_reply":"2022-02-23T12:27:29.03128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(feat_df.shape)\ndisplay(feat_df.head())","metadata":{"execution":{"iopub.status.busy":"2022-02-23T12:27:29.033987Z","iopub.execute_input":"2022-02-23T12:27:29.034308Z","iopub.status.idle":"2022-02-23T12:27:29.046257Z","shell.execute_reply.started":"2022-02-23T12:27:29.034264Z","shell.execute_reply":"2022-02-23T12:27:29.044991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(pn_notes_df.shape)\ndisplay(pn_notes_df.head())","metadata":{"execution":{"iopub.status.busy":"2022-02-23T12:27:29.049874Z","iopub.execute_input":"2022-02-23T12:27:29.050416Z","iopub.status.idle":"2022-02-23T12:27:29.065298Z","shell.execute_reply.started":"2022-02-23T12:27:29.050351Z","shell.execute_reply":"2022-02-23T12:27:29.064367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"we have 6 columns in ```train.csv``` ,  3 columns in ```features.csv``` and  3 columns in ```patient_notes.csv```.\nYou can take look at data description of competition to understand about attributes/columns of dataframes.","metadata":{}},{"cell_type":"code","source":"feat_df.feature_num.nunique(),feat_df.case_num.nunique()","metadata":{"execution":{"iopub.status.busy":"2022-02-23T12:27:29.06697Z","iopub.execute_input":"2022-02-23T12:27:29.067571Z","iopub.status.idle":"2022-02-23T12:27:29.081813Z","shell.execute_reply.started":"2022-02-23T12:27:29.067529Z","shell.execute_reply":"2022-02-23T12:27:29.080634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 143 unique features and 10 unique cases","metadata":{}},{"cell_type":"code","source":"cases = [f\"case {i}\" for i in feat_df.case_num.unique()]\nfeature_count = [feat_df[feat_df.case_num == i][\"feature_num\"].nunique() for i in range(10)]\ndata = pd.DataFrame({\"case\":cases,\"unique_feature_count\":feature_count})\nfig = px.bar(data,x=\"case\",y=\"unique_feature_count\",width=500,height=400)\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-23T12:27:29.084111Z","iopub.execute_input":"2022-02-23T12:27:29.084594Z","iopub.status.idle":"2022-02-23T12:27:29.867292Z","shell.execute_reply.started":"2022-02-23T12:27:29.084552Z","shell.execute_reply":"2022-02-23T12:27:29.86626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You can see in above bar graph how each cases has their unique features.You can take look at EDA kernels in code section there are so many nice kernels for example this one\n* [https://www.kaggle.com/odins0n/nbme-detailed-eda](https://www.kaggle.com/odins0n/nbme-detailed-eda)\n\nIf you visited above notebook please dont forgot to upvote if it helped you.\n\n\nLet's go back to our dataset.\nYou can see that there is ```case_num```  , ```feature_num``` columns are in ```train_df``` and ```feat_df``` we will merge them on ```[\"case_num\",\"feature_num\"]``` ","metadata":{}},{"cell_type":"code","source":"train_df = train_df.merge(feat_df,how=\"left\",on=[\"case_num\",\"feature_num\"])\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-23T12:27:29.869244Z","iopub.execute_input":"2022-02-23T12:27:29.869593Z","iopub.status.idle":"2022-02-23T12:27:29.896971Z","shell.execute_reply.started":"2022-02-23T12:27:29.869549Z","shell.execute_reply":"2022-02-23T12:27:29.895897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now merge this ```train_df``` with ```pn_notes_df``` on ```[\"case_num\",\"pn_num\"]```","metadata":{}},{"cell_type":"code","source":"train_df = train_df.merge(pn_notes_df,how=\"left\",on=[\"case_num\",\"pn_num\"])\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-23T12:27:29.898758Z","iopub.execute_input":"2022-02-23T12:27:29.899245Z","iopub.status.idle":"2022-02-23T12:27:29.931456Z","shell.execute_reply.started":"2022-02-23T12:27:29.899193Z","shell.execute_reply":"2022-02-23T12:27:29.930435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Evaluation Metric</center></h2>","metadata":{}},{"cell_type":"markdown","source":"Evaluation metric is micro_average_F1 score\nand it's like we have two targets one is predicted and another one is original Then in our case targets is location span \nexample if we have \n\n              predicted location [\"333 342\"]\n              orig location      [\"332 340\"]\nThen our ground truth is span of orignal location and prediction is span of predicted location\nlike this \n\n              ground truth = [333, 334, 335, 336, 337, 338, 339, 340, 341]\n              prediction =   [333, 334, 335, 336, 337, 338, 339]\n             TP = len([333, 334, 335, 336, 337, 338, 339]) = 7\n             FP = len([]) = 0\n             FN = len([340, 341]) = 2\n             \n             NOW SUM  TP FP FN individualy and calculate final F1 score \n    ","metadata":{}},{"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Data Cleaning</center></h2>","metadata":{}},{"cell_type":"markdown","source":"There are some problems in dataset :\n1. In location column there are some samples are like this ```\"682 688;695 697\"``` , which should be like ```\"682 697\"```\n2. In which samples location is like above In that sample annotation is not proper example: ```\"Father MI\"``` and in text it is actually like this ```\"Father had a MI\"```\n3. In some sample annotations are merging in each other examples:\n    * 1st annotation's location is ```\"331 368\"``` and 2nd annotation's location ```\"337 371\"```\n    * 1st annotation's location is ```\"331 435\"``` and 2nd annotation's location ```\"337 371\"```\n4. In some sample annotations are unrelated to feature_text\n5. In some sample annotaions are too big like a sentence which making them unrelated to feature_text and annotations len must be from 1 to about 5-6 words ","metadata":{}},{"cell_type":"code","source":"def preprocess_location(text,as_type):\n    \"\"\"\n    text: a string contain location eg. \"333 378\", \"333 342;353 378\", \"5 9;15 35\"\n    as_type: int or str\n    return: a string contain location eg. \"333 378\", \"333 378\", \"5 35\" as str or int \n    \"\"\"\n    text = re.findall(r\"\\d+\",text)\n    if as_type==\"int\":\n        return int(text[0]), int(text[-1])\n    elif as_type==\"str\":\n        \n        return text[0] + \" \" + text[-1]\n\ndef problem_process(df,location,annotation):\n    \"\"\"\n    This function takes datafarame as input and solves avove problem 1 and 2 and return new dataset\n    \"\"\"\n    \n    \n    pn_history = df.pn_history.values\n    \n    for i in range(len(annotation)):\n        annotation[i] = eval(annotation[i]) # to convert [\"[]\",\"[]\"] to [[],[]]\n        location[i] = eval(location[i])\n    \n    new_location = copy.deepcopy(location)\n    new_annotation = copy.deepcopy(annotation)\n    \n    \"\"\"\n    errors = []\n    for i in range(len(location)):\n        if location[i] != []:\n            for j in range(len(location[i])):\n                if len(location[i][j])>7:\n                    errors.append([i,j])\n    \"\"\"\n    \n    trouble = [] # to collect sample who has problem no.3 \n    \n    for i in range(len(location)):\n        if location[i]!=[]:\n            sample = []\n            for j in range(len(location[i])):\n                text = location[i][j]\n                new_location[i][j] = preprocess_location(text=text, as_type=\"str\") # solving problem 1\n                \n                start, end = preprocess_location(text=text,as_type=\"int\")\n                new_annotation[i][j] = pn_history[i][start:end]                   # solving problem 2\n                \n                sample.append(start)\n                sample.append(end)\n            for m,n in enumerate(sample[1:]):\n                if sample[m]>n:\n                    trouble.append(i)\n                    break\n\n    df[\"annotation\"] = np.array(new_annotation)\n    df[\"location\"] = np.array(new_location)\n    \n    \n    return df, trouble","metadata":{"execution":{"iopub.status.busy":"2022-02-23T12:27:29.933486Z","iopub.execute_input":"2022-02-23T12:27:29.933847Z","iopub.status.idle":"2022-02-23T12:27:29.949368Z","shell.execute_reply.started":"2022-02-23T12:27:29.933803Z","shell.execute_reply":"2022-02-23T12:27:29.947869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df,trouble = problem_process(train_df,train_df.location.values,train_df.annotation.values)\nincorrect = [0] * len(train_df.location.values)\nfor i in trouble:\n    incorrect[i] = 1\ntrain_df[\"trouble\"] = np.array(incorrect)\n#df,trouble = problem_process(df)\nprint(train_df.shape)\ntrain_df = train_df[train_df[\"trouble\"] == 0].reset_index(drop=True) # for now i dont want to solve problem 3 so i will just drop those rows","metadata":{"execution":{"iopub.status.busy":"2022-02-23T12:27:29.953948Z","iopub.execute_input":"2022-02-23T12:27:29.954599Z","iopub.status.idle":"2022-02-23T12:27:30.612747Z","shell.execute_reply.started":"2022-02-23T12:27:29.954554Z","shell.execute_reply":"2022-02-23T12:27:30.61175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Preprocessing</center></h2>","metadata":{}},{"cell_type":"markdown","source":"After applying preprocessing on pn_history location of annotations changes so using ```apply_preprocess_and_find_location```  we are applying preprocesing and calculating new location.\nYou can play with ```process_pn_history```, ```process_annotation```, ```process_feature_text``` function and apply different preprocessing whatever you like","metadata":{}},{"cell_type":"code","source":"def process_pn_history(text):\n    text = re.sub(r\"\\r\\n\",\" \",text)\n    return text\n\n\ndef process_annotation(text):\n    text = re.sub(r\"\\r\\n\",\" \",text)\n    text = re.sub(r\"\\r\",\"\",text)\n    return text\n\ndef process_feature_text(text):\n    text = re.sub(r\"-\",\" \",text)\n    return text\n\n\ndef apply_preprocess_and_find_location(df):\n    df[\"pn_history\"] = df.pn_history.apply(process_pn_history)\n    df[\"feature_text\"] = df.feature_text.apply(process_feature_text)\n\n    location = df.location.values\n    annotation = df.annotation.values\n    \n    new_location = []\n    pn_history = df.pn_history.values\n    \n    for i in range(len(df.annotation.values)):\n        if annotation[i]==[]:\n            new_location.append([])\n        else:\n            sample = []\n            start = 0\n            for j in range(len(annotation[i])):\n                text = process_annotation(annotation[i][j]) # applied preprocess for annotation too\n                start = pn_history[i].index(text, start, len(pn_history[i]))\n                end = start + len(text)\n                ii = str(start) + \" \" + str(end)\n                sample.append(ii)\n                start = end\n            new_location.append(sample)\n    \n    \n    df[\"location\"] = np.array(new_location)\n    return df\n\ntrain_df = apply_preprocess_and_find_location(train_df)\ntrain_df = train_df.drop([0,98,197,295,394],axis=0).reset_index(drop=True) # 0,98,197,295,394 are contain ids which mentioned in test_df","metadata":{"execution":{"iopub.status.busy":"2022-02-23T12:27:30.614178Z","iopub.execute_input":"2022-02-23T12:27:30.615006Z","iopub.status.idle":"2022-02-23T12:27:30.784052Z","shell.execute_reply.started":"2022-02-23T12:27:30.61495Z","shell.execute_reply":"2022-02-23T12:27:30.781663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"If you dont know about what is attention, transformers, tokenizer, bert. Then go take look at Hugging face's course. It is super easy and so much helpfull.","metadata":{}},{"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Config</center></h2>","metadata":{}},{"cell_type":"code","source":"class args:\n    MAX_LEN = 300\n    MODEL_PATH = \"../input/bertbaseuncased/\"\n    MODEL_SAVE_PATH = \"model.bin\"\n    n_splits = 10\n    tokenizer = tokenizers.BertWordPieceTokenizer(\"../input/bertbaseuncased/vocab.txt\",lowercase=True)\n    seed = 42\n    patiens = 5\n    epochs = 2\n    threshold=0.5\n    learning_rate = 1e-4\n    device=\"cuda\"\n    TRAIN_BATCH_SIZE = 16\n    VALID_BATCH_SIZE = 16\n    TEST_BATCH_SIZE = 5\n","metadata":{"execution":{"iopub.status.busy":"2022-02-23T12:27:30.785656Z","iopub.execute_input":"2022-02-23T12:27:30.786067Z","iopub.status.idle":"2022-02-23T12:27:30.841005Z","shell.execute_reply.started":"2022-02-23T12:27:30.786022Z","shell.execute_reply":"2022-02-23T12:27:30.840037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Utils</center></h2>","metadata":{}},{"cell_type":"code","source":"class AverageMeter:\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n        \n\n# setting seed so i can reproduce same results every time \ndef set_seed(seed=args.seed):\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    \n\ndef confusion_metrics(ground_truth, prediction):\n    ground_truth_elements = set(ground_truth)\n    prediction_elements = set(prediction)\n    \n    TP = len(ground_truth_elements & prediction_elements)\n    FN = len(ground_truth_elements - prediction_elements)\n    FP = len(prediction_elements - ground_truth_elements)\n    \n    return TP, FN, FP\n\ndef micro_average_f1(TP, FN, FP):\n    tp = sum(TP)\n    fn = sum(FN)\n    fp = sum(FP)\n    f1 = tp / (tp + 0.5*(fp + fn))\n    return f1","metadata":{"execution":{"iopub.status.busy":"2022-02-23T12:27:30.844523Z","iopub.execute_input":"2022-02-23T12:27:30.844763Z","iopub.status.idle":"2022-02-23T12:27:30.856694Z","shell.execute_reply.started":"2022-02-23T12:27:30.844733Z","shell.execute_reply":"2022-02-23T12:27:30.855359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Dataset</center></h2>","metadata":{}},{"cell_type":"code","source":"class NBMEDataset:\n    def __init__(self,df,tokenizer):\n        self.df = df\n        self.pn_history = df.pn_history.values\n        self.feature_text = df.feature_text.values\n        self.annotation = df.annotation.values\n        self.location = df.location.values\n        self.max_len = args.MAX_LEN\n        self.tokenizer = tokenizer\n    \n    def __len__(self):\n        return self.df.shape[0]\n    \n    def __getitem__(self,item):\n        text = self.pn_history[item]\n        feature_text = self.feature_text[item]\n        annotation = self.annotation[item]\n        location = self.location[item]\n        \n        \n        len_featutre_text = len(feature_text)\n        len_text = len(text)\n        \"\"\"\n        lets say we have text(pn_history) like this:-  'This is first sentence' and annotaion is 'first sentence'\n        then we will assign 0 to all and 1 to that index which contain our annotation except \" \" \n        example:\n        \"This is first sentence\"\n         0000000011111011111111   >> This will be in list format like [0,0,0,0,0,0,0,0,1,1,1,1,1,0,1,1,1,1,1,1,1,1]\n        \"\"\"\n        char_targets = [0] * len_text\n        if annotation!=[]:\n            \n            for idx0, idx1 in [(int(j) for j in i.split()) for i in location]:\n                for j in range(idx0, idx1):\n                    if text[j] != \" \":\n                        char_targets[j] = 1\n        \"\"\"\n        Then we will give our text and feature_text to tokenizer and tokens will be like\n        example : text >>> \"I completed huggingface's course\"\n                tokens >>> [\"i\",\"completed\",\"hugging\",\"##face\",\"'\",\"s\",\"course\"]\n        \"\"\"\n        \n        tok_text = self.tokenizer.encode(text,feature_text)\n        tok_text_tokens = tok_text.tokens\n        tok_text_ids = tok_text.ids\n        tok_text_type_ids = tok_text.type_ids\n        tok_text_offsets = tok_text.offsets[1:-1]\n        \n        \"\"\"\n        Then we will create our targats \n        offsets are just starting and ending index of tokens like this [(0,0),(1,5),(6,9),(10,15),(15,19)]\n        we will take offsets of each token and if that offsets sum(char_targets[start:end])>0 then that token is our target\n        For example \n         annotation >>> \"first sentence\"\n               text >>> \"This is first sentence\"\n             tokens >>> [\"this\",\"is\",\"first\",\"sentence\"]                    # I know there is [CLS] and [SEP] token at start and \n             offset >>> [(0,4),(5,7),(8,13),(14,22)]                        # end but i removed first and last offset\n        char_target >>> [0,0,0,0,0,0,0,0,1,1,1,1,1,0,1,1,1,1,1,1,1,1]       # and also did -2 in len of tokens while creating target\n             target >>> [0,0,1,1]\n        \n        \"\"\"\n        targets = [0] * (len(tok_text_tokens) - 2)\n        for j, (offset1, offset2) in enumerate(tok_text_offsets):\n            if sum(char_targets[offset1:offset2]) > 0:\n                targets[j] = 1\n        \n        \n        targets = [0] + targets + [0]                   # for cls and sep token\n        \n        \n        mask = [1] * len(tok_text_ids)\n        token_type_ids = tok_text_type_ids\n        padding_len = self.max_len - len(tok_text_ids)\n        \n        ids = tok_text_ids + [0] * padding_len\n        mask = mask + [0] * padding_len\n        token_type_ids = token_type_ids + [0] * padding_len\n        targets = targets + [0] * padding_len\n        offsets = tok_text.offsets + [(0,0)] * padding_len\n        \n    \n        \n        return {\n            \"ids\":torch.tensor(ids,dtype=torch.long),\n            \"mask\":torch.tensor(mask,dtype=torch.long),\n            \"token_type_ids\":torch.tensor(token_type_ids,dtype=torch.long),\n            \"targets\":torch.tensor(targets,dtype=torch.float),\n            \"offsets\":str(offsets),\n            \"location\":str(location)\n            \n        }","metadata":{"execution":{"iopub.status.busy":"2022-02-23T12:27:30.858671Z","iopub.execute_input":"2022-02-23T12:27:30.859258Z","iopub.status.idle":"2022-02-23T12:27:30.8807Z","shell.execute_reply.started":"2022-02-23T12:27:30.859213Z","shell.execute_reply":"2022-02-23T12:27:30.879563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Model</center></h2>","metadata":{}},{"cell_type":"code","source":"class BERTBaseUncased(nn.Module):\n    def __init__(self):\n        super(BERTBaseUncased, self).__init__()\n        self.bert = transformers.BertModel.from_pretrained(args.MODEL_PATH)\n        self.bert_drop = nn.Dropout(0.3)\n        self.l0 = nn.Linear(768,1)\n        \n    def forward(self, ids, mask, token_type_ids):\n        output = self.bert(\n            ids,\n            attention_mask=mask,\n            token_type_ids=token_type_ids,\n        )\n        \n        \n        logits = self.l0(output[0])\n        logits = logits.squeeze(-1)\n        \n        return logits","metadata":{"execution":{"iopub.status.busy":"2022-02-23T12:27:30.882106Z","iopub.execute_input":"2022-02-23T12:27:30.882669Z","iopub.status.idle":"2022-02-23T12:27:30.895785Z","shell.execute_reply.started":"2022-02-23T12:27:30.882575Z","shell.execute_reply":"2022-02-23T12:27:30.8947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Engine</center></h2>","metadata":{}},{"cell_type":"code","source":"def loss_fn(o1,t1):\n    l1 = nn.BCEWithLogitsLoss()(o1, t1)\n    return l1 \n\ndef train_fn(dataloader, model, optimizer, device, scheduler):\n    model.train()\n    losses = AverageMeter()\n    tk0 = tqdm(dataloader, total=len(dataloader))\n    for bi, d in enumerate(tk0):\n        ids = d[\"ids\"]\n        token_type_ids = d[\"token_type_ids\"]\n        mask = d[\"mask\"]\n        targets = d[\"targets\"]\n        \n        ids = ids.to(device)\n        token_type_ids = token_type_ids.to(device)\n        mask = mask.to(device)\n        targets = targets.to(device)\n        \n        optimizer.zero_grad()\n        o1 = model(\n            ids=ids,\n            token_type_ids=token_type_ids,\n            mask=mask\n        )\n        \n        loss = loss_fn(o1,  targets)\n        \n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n        \n        losses.update(loss.item(), ids.size(0))\n        tk0.set_postfix(loss=losses.avg)\n        \n        ids = ids.cpu().detach().numpy()\n        token_type_ids = token_type_ids.cpu().detach().numpy()\n        mask = mask.cpu().detach().numpy()\n        targets = targets.cpu().detach().numpy()\n        del ids\n        del token_type_ids\n        del mask\n        del targets\n        del o1\n    return losses.avg\n          \n\ndef eval_fn(dataloader, model, device):\n    model.eval()\n    losses = AverageMeter()\n    tk0 = tqdm(dataloader, total=len(dataloader))\n    fin_output = []\n    fin_targets = []\n    fin_offsets = []\n    orig_targets_location = []\n    fin_targets_location = []\n    fin_output_location = []\n    TP = []\n    FN = []\n    FP = []\n    \n    for bi, d in enumerate(tk0):\n        ids = d[\"ids\"]\n        token_type_ids = d[\"token_type_ids\"]\n        mask = d[\"mask\"]\n        targets = d[\"targets\"]\n        offsets = d[\"offsets\"]\n        location = d[\"location\"]\n        \n        \n        for i in range(len(location)):\n            location[i] = eval(location[i])\n            offsets[i] = eval(offsets[i])\n        fin_offsets.extend(offsets)\n        orig_targets_location.extend(location)\n        \n        \n        ids = ids.to(device)\n        token_type_ids = token_type_ids.to(device)\n        mask = mask.to(device)\n        targets = targets.to(device)\n        \n        \n        o1 = model(\n            ids=ids,\n            token_type_ids=token_type_ids,\n            mask=mask\n        )\n        \n        loss = loss_fn(o1, targets)\n        \n        \n        losses.update(loss.item(), ids.size(0))\n        tk0.set_postfix(loss=losses.avg)\n        \n        ids = ids.cpu().detach().numpy()\n        token_type_ids = token_type_ids.cpu().detach().numpy()\n        mask = mask.cpu().detach().numpy()\n        del ids\n        del token_type_ids\n        del mask\n        \n        threshold = args.threshold\n        \n        fin_output.append(torch.sigmoid(o1).cpu().detach().numpy())\n        fin_targets.append(targets.cpu().detach().numpy())\n        del o1\n        del targets\n        \n        \n    fin_offsets = np.array(fin_offsets)\n    orig_targets_location = np.array(orig_targets_location)\n    \n    fin_output = np.vstack(fin_output)\n    fin_targets = np.vstack(fin_targets)\n    \n    \n    for i in range(len(fin_output)):\n        output = [1 if i>=threshold else 0 for i in fin_output[i]]\n        target = fin_targets[i]\n        offset = fin_offsets[i]\n        output_location = []\n        start = -1\n        for j in range(len(output)):\n            if output[j]==1 and start==-1:\n                start = offset[j][0]\n            if output[j]==0 and start!=-1:\n                end = offset[j-1][-1]\n                output_location.extend([ii for ii in range(start,end)])\n                start=-1\n            \n        fin_output_location.append(output_location)\n    \n    \n    for i in orig_targets_location:\n        orig_location = []\n        for j in  i:\n            m = j.split()\n            start = int(m[0])\n            end = int(m[-1])\n            orig_location.extend([ii for ii in range(start,end)])\n        fin_targets_location.append(orig_location)\n\n    for i in range(len(orig_targets_location)):\n        ground_truth = fin_targets_location[i]\n        prediction = fin_output_location[i]\n        \n        tp, fn, fp = confusion_metrics(ground_truth,prediction)\n        TP.append(tp)\n        FN.append(fn)\n        FP.append(fp)\n    \n    micro_average_f1_score = micro_average_f1(TP, FN, FP)\n        \n    return losses.avg, micro_average_f1_score","metadata":{"execution":{"iopub.status.busy":"2022-02-23T12:27:30.897384Z","iopub.execute_input":"2022-02-23T12:27:30.897616Z","iopub.status.idle":"2022-02-23T12:27:30.93579Z","shell.execute_reply.started":"2022-02-23T12:27:30.89758Z","shell.execute_reply":"2022-02-23T12:27:30.934642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Train</center></h2>","metadata":{}},{"cell_type":"code","source":"train_df[\"kfold\"] = -1\nset_seed(args.seed)\nskf = model_selection.StratifiedKFold(n_splits=args.n_splits,shuffle=True,random_state=args.seed)\ny=train_df.case_num.values\nfor fold_, (_,v_) in enumerate(skf.split(X=train_df,y=y)):\n    train_df.loc[v_,\"kfold\"] = fold_","metadata":{"execution":{"iopub.status.busy":"2022-02-23T12:27:30.937534Z","iopub.execute_input":"2022-02-23T12:27:30.93794Z","iopub.status.idle":"2022-02-23T12:27:30.964046Z","shell.execute_reply.started":"2022-02-23T12:27:30.937893Z","shell.execute_reply":"2022-02-23T12:27:30.963154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_score = []\nfold_no = []\nfor fold in range(args.n_splits):\n    set_seed(args.seed + fold)\n    train_data = train_df[train_df.kfold!=fold].reset_index(drop=True)\n    valid_data = train_df[train_df.kfold==fold].reset_index(drop=True)\n    \n    train_dataset = NBMEDataset(df=train_data,tokenizer=args.tokenizer)\n    valid_dataset = NBMEDataset(df=valid_data,tokenizer=args.tokenizer)\n\n    set_seed(args.seed+fold)\n    \n    train_dataloader = DataLoader(\n        train_dataset,\n        batch_size=args.TRAIN_BATCH_SIZE,\n        num_workers=2\n    )\n    \n    set_seed(args.seed+fold)\n    \n    valid_dataloader = DataLoader(\n        valid_dataset,\n        batch_size=args.VALID_BATCH_SIZE,\n        num_workers=2\n    )\n    \n    set_seed(args.seed+fold)\n    \n    model = BERTBaseUncased()\n    model.to(args.device)\n    \n    param_optimizer = list(model.named_parameters())\n    no_decay = [\"bias\",\"LayerNorm.bias\",\"LayerNorm.weight\"]\n    optimizer_parameters = [\n        {\"params\":[p for n,p in param_optimizer if not any(nd in n for nd in no_decay)],\"weight_decay\":0.001}\n    ]\n    \n    num_train_steps = int(len(train_df) / args.TRAIN_BATCH_SIZE * args.epochs)\n    optimizer = AdamW(optimizer_parameters, lr=args.learning_rate)\n    scheduler = get_linear_schedule_with_warmup(\n        optimizer,\n        num_warmup_steps=0,\n        num_training_steps=num_train_steps\n    )\n    \n    \n    \n    best_micro_averaged_F1 = 0\n    patiens = 0\n    for epoch in range(args.epochs):\n        print(f\"fold/epoch  {fold}/{epoch}\")\n        \n        tr_loss = train_fn(train_dataloader, model, optimizer, args.device, scheduler)\n        gc.collect()\n        torch.cuda.empty_cache()\n        \n        val_loss, micro_average_f1_score = eval_fn(valid_dataloader, model, args.device)\n        gc.collect()\n        torch.cuda.empty_cache()\n        \n        \n        patiens+=1\n        print(f\"valid_score = {micro_average_f1_score}\")\n        \n        if micro_average_f1_score>=best_micro_averaged_F1:\n            best_micro_averaged_F1 = micro_average_f1_score\n            torch.save(model.state_dict(),args.MODEL_SAVE_PATH)\n            patiens=0\n        \n        if patiens==args.patiens:\n            break\n        \n    valid_score.append(best_micro_averaged_F1)\n    fold_no.append(fold)\n    print(\"*\"*30)\n    break # remove break to train on all folds","metadata":{"execution":{"iopub.status.busy":"2022-02-23T12:27:30.965536Z","iopub.execute_input":"2022-02-23T12:27:30.966067Z","iopub.status.idle":"2022-02-23T12:27:57.097662Z","shell.execute_reply.started":"2022-02-23T12:27:30.966021Z","shell.execute_reply":"2022-02-23T12:27:57.096254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I used only 2 epochs here to just show you that its works, you should used 20-25 epoch. Yes I know i not explained  about how to get pred location from predicted target i will leave that to you\n     \n     hint >>> used offset to get location  >> its inside eval_fn","metadata":{}},{"cell_type":"markdown","source":"<font color='red'>If you find my kernel useful and my efforts appreciable, Please Upvote it , it motivates me to write more Quality content</font>","metadata":{}},{"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>End</center></h2>","metadata":{}}]}