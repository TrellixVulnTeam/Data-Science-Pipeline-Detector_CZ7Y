{"cells":[{"metadata":{"toc":true},"cell_type":"markdown","source":"<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Import\" data-toc-modified-id=\"Import-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Import</a></span><ul class=\"toc-item\"><li><span><a href=\"#Python-Libraries\" data-toc-modified-id=\"Python-Libraries-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Python Libraries</a></span></li><li><span><a href=\"#Study-Settings\" data-toc-modified-id=\"Study-Settings-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Study Settings</a></span></li><li><span><a href=\"#Data\" data-toc-modified-id=\"Data-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Data</a></span></li></ul></li><li><span><a href=\"#Explore\" data-toc-modified-id=\"Explore-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Explore</a></span></li><li><span><a href=\"#Social-diffusion-Model\" data-toc-modified-id=\"Social-diffusion-Model-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Social diffusion Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Confirmed-Cases\" data-toc-modified-id=\"Confirmed-Cases-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Confirmed Cases</a></span></li><li><span><a href=\"#Deaths\" data-toc-modified-id=\"Deaths-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Deaths</a></span></li></ul></li><li><span><a href=\"#Competition\" data-toc-modified-id=\"Competition-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Competition</a></span><ul class=\"toc-item\"><li><span><a href=\"#ConfirmedCases\" data-toc-modified-id=\"ConfirmedCases-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>ConfirmedCases</a></span></li><li><span><a href=\"#Fatalities\" data-toc-modified-id=\"Fatalities-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Fatalities</a></span></li><li><span><a href=\"#Submission-File\" data-toc-modified-id=\"Submission-File-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Submission File</a></span></li></ul></li><li><span><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Conclusion</a></span></li></ul></div>"},{"metadata":{},"cell_type":"markdown","source":"# Introduction"},{"metadata":{},"cell_type":"markdown","source":"This study uses the work from the following source: https://www.kaggle.com/alixmartin/covid-19-predictions. The previous study applied a model at a country level to predict the growth of confirmed cases. \n\nThe previous approach could not adequately explain the odd behaviours of growth for countries like China. In the China data, the curve seems to grow exponentially, then tapers off, then picks up exponentially again, and then tapers off.  \n\nThis author reckons that this behaviour exists, because the growth is cluster-based. Each cluster should be treated as a newly infected 'country' and therefore modelled seperately with  their results rolled up to predict the growth at a country or global level.\n\nThe data does not identify the clusters per country explicitly (which is probably at a town or suburb level). Therefore the study will examine it by province/state to see whether a significant improvement in accuracy can be obtained.\n\nIn future work, the study could estimate the number of clusters, and provide parameters in the model that could assist in identifying clusters that are managing the COVID-19 contagion well or poorly.  "},{"metadata":{},"cell_type":"markdown","source":"# Import"},{"metadata":{},"cell_type":"markdown","source":"## Python Libraries"},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T05:11:55.39134Z","start_time":"2020-03-22T05:11:54.060342Z"},"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom IPython.core.display import display, HTML\nimport plotly.graph_objects as go\nimport warnings\nimport datetime\nimport math\nfrom scipy.optimize import minimize\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Configure the notebook (see https://jupyter-notebook.readthedocs.io/en/stable/config.html)"},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T05:11:55.40834Z","start_time":"2020-03-22T05:11:55.39234Z"},"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Configure Jupyter Notebook\npd.set_option('display.max_columns', None) \npd.set_option('display.max_rows', 500) \npd.set_option('display.expand_frame_repr', False)\n# pd.set_option('max_colwidth', -1)\ndisplay(HTML(\"<style>div.output_scroll { height: 35em; }</style>\"))\n\n%matplotlib inline\n%config InlineBackend.figure_format ='retina'\n\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Study Settings"},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T05:11:55.413377Z","start_time":"2020-03-22T05:11:55.409341Z"},"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# the number of days into the future for the forecast\ndays_forecast = 30","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data"},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T05:11:56.03734Z","start_time":"2020-03-22T05:11:55.416342Z"},"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# download the latest data sets\nconf_df = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv')\ndeaths_df = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Deaths.csv')\nrecv_df = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Recovered.csv')","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T05:11:56.06734Z","start_time":"2020-03-22T05:11:56.03834Z"},"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# create full table\ndates = conf_df.columns[4:]\n\nconf_df_long = conf_df.melt(id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'], \n                            value_vars=dates, var_name='Date', value_name='Confirmed')\n\ndeaths_df_long = deaths_df.melt(id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'], \n                            value_vars=dates, var_name='Date', value_name='Deaths')\n\nrecv_df_long = recv_df.melt(id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'], \n                            value_vars=dates, var_name='Date', value_name='Recovered')\n\nfull_table = pd.concat([conf_df_long, deaths_df_long['Deaths'], recv_df_long['Recovered']], \n                       axis=1, sort=False)\n","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T05:11:56.08737Z","start_time":"2020-03-22T05:11:56.068338Z"},"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# avoid double counting\nfull_table = full_table[full_table['Province/State'].str.contains(',')!=True]","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T05:11:56.108372Z","start_time":"2020-03-22T05:11:56.088336Z"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# cases \ncases = ['Confirmed', 'Deaths', 'Recovered', 'Active']\n\n# Active Case = confirmed - deaths - recovered\nfull_table['Active'] = full_table['Confirmed'] - full_table['Deaths'] - full_table['Recovered']\n\n# replacing Mainland china with just China\nfull_table['Country/Region'] = full_table['Country/Region'].replace('Mainland China', 'China')\n\n# filling missing values \nfull_table[['Province/State']] = full_table[['Province/State']].fillna('')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"markdown","source":"# Explore"},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"markdown","source":"This section does a brief exploration of the latest data set.\n\nThe first table shows a global summary with the latest data. "},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T05:11:56.13137Z","start_time":"2020-03-22T05:11:56.110336Z"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# Display the number cases globally\ndf = full_table.groupby(['Country/Region', 'Province/State'])['Confirmed', 'Deaths', 'Recovered', 'Active'].max()\ndf = full_table.groupby('Date')['Confirmed', 'Deaths', 'Recovered', 'Active'].sum().reset_index()\ndf =  df[df['Date']==max(df['Date'])].reset_index(drop=True)\ndf","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"markdown","source":"The table below shows the lastest values by country"},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T05:11:56.663338Z","start_time":"2020-03-22T05:11:56.132338Z"},"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# count the number cases per country\ndf = full_table[full_table['Date'] == max(full_table['Date'])].reset_index()\ndf = df.groupby('Country/Region')['Confirmed', 'Deaths', 'Recovered', 'Active'].sum().reset_index()\ndf = df.sort_values(by='Confirmed', ascending=False)\ndf = df.reset_index(drop=True)\ndf.style.background_gradient(cmap='coolwarm')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"markdown","source":"The table below counts the number of provinces/states for each country. These numbers will be the clusters used in Chapter 4.2. "},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Social diffusion Model"},{"metadata":{},"cell_type":"markdown","source":"The model is the same one as before (except with an 'offset'). The model is from a marketing paper by Emmanuelle Le Nagard and Alexandre Steyer, that attempts to reflect the social structure of a diffusion process. The paper is available (in French) [here](https://www.jstor.org/stable/40588987)\n\nThe model is also sensitive to when we define the origin of time for the epidemic process. The model has an offset parameter included and better starting conditions for the optimization algorithm. The shape of the difusion can then be expressed in the following equation:\n\n$$N(1 - e^{-a(t-t_0)})^{\\alpha}$$\n"},{"metadata":{},"cell_type":"markdown","source":"## Confirmed Cases"},{"metadata":{},"cell_type":"markdown","source":"In this section we start by building and displaying a model for a country (ignoring the clusters). The model is simple to compare with the previous day's results. In the cases where the COVID-19 spread is recent and the number of confirmed cases are few the model is not accurate. In these low-number cases the predictions from yesterday to today may fluctate significantly. With the countries that have cases in the 100s or 1000s however, the model is fairly stable.  "},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T05:11:58.11434Z","start_time":"2020-03-22T05:11:56.664339Z"},"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"country = 'US'\ncluster = 'California'\n\ndf = full_table[(full_table['Country/Region'] == country)&(full_table['Province/State'] == cluster)]\ndf = df.groupby(['Date','Country/Region']).sum().reset_index()\ndf['Date'] = pd.to_datetime(df['Date'])\ndf = df.sort_values(by=['Date'])\ndf = df.set_index('Date')[['Confirmed']]\ndf_result = df.copy()\n# df_result = df_result[['Date','Confirmed']]\n\n# ensure that the model starts from when the first case is detected\n# NOTE: its better not to truncate the dataset like this \n# df = df[df[df.columns[0]]>0]\n\n# define the models to forecast the growth of cases\ndef model(N, a, alpha, t0, t):\n    return N * (1 - math.e ** (-a * (t-t0))) ** alpha\n\ndef model_loss(params):\n    N, a, alpha, t0 = params\n    global df\n    r = 0\n    for t in range(len(df)):\n        r += (model(N, a, alpha, t0, t) - df.iloc[t, 0]) ** 2\n    return r \ntry:\n    N = df['Confirmed'][-1]\n    T = -df['Confirmed'][0]\nexcept:\n    N = 10000\n    T = 0\n\nopt = minimize(model_loss, x0=np.array([N, 0.1, 5, T]), method='Nelder-Mead', tol=1e-6).x\nprint(opt)\n\n# create series to be plotted \nx_actual = pd.to_datetime(df.reset_index().iloc[:,0])\nx_actual =list(x_actual)\ny_actual = list(df.reset_index().iloc[:,1])\n\nstart_date = pd.to_datetime(df.index[0])\n\nx_model = []\ny_model = []\n\n# get the model values for the same time series as the actuals\nfor t in range(len(df) + days_forecast):\n    x_model.append(start_date + datetime.timedelta(days=t))\n    y_model.append(round(model(*opt,t)))\n\n# instantiate the figure and add the two series - actual vs modelled    \nfig = go.Figure()\nfig.update_layout(title=country + ' - ' + cluster,\n                  xaxis_title='Date',\n                  yaxis_title=\"nr People\",\n                  autosize=False,\n                  width=700,\n                  height=500,\n                 )\n\nfig.add_trace(go.Line(x=x_actual,\n                      y=y_actual,\n                      mode='markers',\n                      name='Actual',\n                      marker=dict(symbol='circle-open-dot', \n                                  size=9, \n                                  color='black', \n                                  line_width=1.5,\n                                 )\n                     ) \n             )    \n\nfig.add_trace(go.Line(x=x_model,\n                      y=y_model,\n                      mode='lines',\n                      name=\"Prediction with offset\",\n                      line=dict(color='blue', \n                                width=2.5\n                               )\n                     ) \n             ) \n\n# now add the results of the model to the dataframe\ndf2 = pd.DataFrame(y_model,index=x_model,columns=['Offset'])\ndf2.index.name = 'Date'\ndf_result = pd.merge(df_result,\n                     df2,\n                     how='outer',\n                     left_on=['Date'],\n                     right_on=['Date'])\n\n# define the models to forecast the growth of cases\ndef model(N, a, alpha, t):\n    return N * (1 - math.e ** (-a * (t))) ** alpha\n\ndef model_loss(params):\n    N, a, alpha = params\n    global df\n    r = 0\n    for t in range(len(df)):\n        r += (model(N, a, alpha, t) - df.iloc[t, 0]) ** 2\n    return r \n\ntry:\n    N = df['Confirmed'][-1]\nexcept:\n    N = 10000\n\nopt = minimize(model_loss, x0=np.array([N, 0.1, 5]), method='Nelder-Mead', tol=1e-6).x\nprint(opt)\n\ntry:\n    start_date = pd.to_datetime(df.index[0])\n\n    x_model = []\n    y_model = []\n\n    # get the model values for the same time series as the actuals\n    for t in range(len(df) + days_forecast):\n        x_model.append(start_date + datetime.timedelta(days=t))\n        y_model.append(round(model(*opt,t)))\n\n\n    # now plot the new series\n    fig.add_trace(go.Line(x=x_model,\n                          y=y_model,\n                          mode='lines',\n                          name=\"Prediction without offset\",\n                          line=dict(color='Red', \n                                    width=1.5,\n                                    dash='dot'\n                                   )\n                         ) \n                 )\n    \n    # now add the results of the model to the dataframe\n    df2 = pd.DataFrame(y_model,index=x_model,columns=['No Offset'])\n    df2.index.name = 'Date'\n    df_result = pd.merge(df_result,\n                         df2,\n                         how='outer',\n                         left_on=['Date'],\n                         right_on=['Date'])\n    \nexcept:\n    pass\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T05:11:58.24234Z","start_time":"2020-03-22T05:11:58.115341Z"},"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df_result['Offset error'] = (df_result['Confirmed']-df_result['Offset'])/df_result['Confirmed']*100\ndf_result['Offset error'][df_result['Confirmed']==0]=0\n\ndf_result['No Offset error'] = (df_result['Confirmed']-df_result['No Offset'])/df_result['Confirmed']*100\ndf_result['No Offset error'][df_result['Confirmed']==0]=0\n\ndef highlight_max(s):\n    '''\n    highlight the absolute maximum value in a Series with red font.\n    '''\n    is_min = abs(s) == abs(s).max()\n    return ['color: red' if v else '' for v in is_min]\n\ndf_result.style.apply(highlight_max,axis=1,subset=['Offset error', 'No Offset error'])","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false},"cell_type":"markdown","source":"The model with an offset is able to marginally outperform the model without an offset. The table above highlights the largest error in red font. "},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T05:11:58.404369Z","start_time":"2020-03-22T05:11:58.244341Z"},"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# now plot the prediction for the country\n# x_actual = pd.to_datetime(df_result['Date'].reset_index())\nx_actual = list(df_result.reset_index()['Date'])\n\nx_model = x_actual\ny_model_clus = list(df_result['Offset error'])\ny_model_glob = list(df_result['No Offset error'])\n\n# instantiate the figure and add the two series - actual vs modelled    \nfig = go.Figure()\n\nfig.update_layout(title=country,\n                  xaxis_title='Date',\n                  yaxis_title=\"% error\",\n                  autosize=False,\n                  width=700,\n                  height=500,\n                  #yaxis_type='log'\n                 )\n\nfig.add_trace(go.Line(x=x_model,\n                      y=y_model_clus,\n                      mode='lines',\n                      name='Offset error',\n                      line=dict(color='blue', \n                                width=1\n                               )\n                     ) \n             )\n\nfig.add_trace(go.Line(x=x_model,\n                      y=y_model_glob,\n                      mode='lines',\n                      name='No Offset error',\n                      line=dict(color='red', \n                                width=1.0,\n                                dash='dot'\n                               )\n                     ) \n             )\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false},"cell_type":"markdown","source":"The figure above compares the errors of the offset model vs the no-offset model. Where the error is zero, the actuals did not have a value>0 yet."},{"metadata":{},"cell_type":"markdown","source":"## Deaths"},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T05:11:59.331371Z","start_time":"2020-03-22T05:11:58.405336Z"},"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"country = 'US'\ncluster = 'California'\n\ndf = full_table[(full_table['Country/Region'] == country)&(full_table['Province/State'] == cluster)]\ndf = df.groupby(['Date','Country/Region']).sum().reset_index()\ndf['Date'] = pd.to_datetime(df['Date'])\ndf = df.sort_values(by=['Date'])\ndf = df.set_index('Date')[['Deaths']]\ndf_result = df.copy()\n# df_result = df_result[['Date','Deaths']]\n\n# ensure that the model starts from when the first case is detected\n# NOTE: its better not to truncate the dataset like this \n# df = df[df[df.columns[0]]>0]\n\n# define the models to forecast the growth of cases\ndef model(N, a, alpha, t0, t):\n    return N * (1 - math.e ** (-a * (t-t0))) ** alpha\n\ndef model_loss(params):\n    N, a, alpha, t0 = params\n    global df\n    r = 0\n    for t in range(len(df)):\n        r += (model(N, a, alpha, t0, t) - df.iloc[t, 0]) ** 2\n    return r \ntry:\n    N = df['Deaths'][-1]\n    T = -df['Deaths'][0]\nexcept:\n    N = 10000\n    T = 0\n\nopt = minimize(model_loss, x0=np.array([N, 0.1, 5, T]), method='Nelder-Mead', tol=1e-6).x\nprint(opt)\n\n# create series to be plotted \nx_actual = pd.to_datetime(df.reset_index().iloc[:,0])\nx_actual =list(x_actual)\ny_actual = list(df.reset_index().iloc[:,1])\n\nstart_date = pd.to_datetime(df.index[0])\n\nx_model = []\ny_model = []\n\n# get the model values for the same time series as the actuals\nfor t in range(len(df) + days_forecast):\n    x_model.append(start_date + datetime.timedelta(days=t))\n    y_model.append(round(model(*opt,t)))\n\n# instantiate the figure and add the two series - actual vs modelled    \nfig = go.Figure()\nfig.update_layout(title=country + ' - ' + cluster,\n                  xaxis_title='Date',\n                  yaxis_title=\"nr People\",\n                  autosize=False,\n                  width=700,\n                  height=500,\n                 )\n\nfig.add_trace(go.Line(x=x_actual,\n                      y=y_actual,\n                      mode='markers',\n                      name='Actual',\n                      marker=dict(symbol='circle-open-dot', \n                                  size=9, \n                                  color='black', \n                                  line_width=1.5,\n                                 )\n                     ) \n             )    \n\nfig.add_trace(go.Line(x=x_model,\n                      y=y_model,\n                      mode='lines',\n                      name=\"Prediction with offset\",\n                      line=dict(color='blue', \n                                width=2.5\n                               )\n                     ) \n             ) \n\n# now add the results of the model to the dataframe\ndf2 = pd.DataFrame(y_model,index=x_model,columns=['Offset'])\ndf2.index.name = 'Date'\ndf_result = pd.merge(df_result,\n                     df2,\n                     how='outer',\n                     left_on=['Date'],\n                     right_on=['Date'])\n\n# define the models to forecast the growth of cases\ndef model(N, a, alpha, t):\n    return N * (1 - math.e ** (-a * (t))) ** alpha\n\ndef model_loss(params):\n    N, a, alpha = params\n    global df\n    r = 0\n    for t in range(len(df)):\n        r += (model(N, a, alpha, t) - df.iloc[t, 0]) ** 2\n    return r \n\ntry:\n    N = df['Deaths'][-1]\nexcept:\n    N = 10000\n\nopt = minimize(model_loss, x0=np.array([N, 0.1, 5]), method='Nelder-Mead', tol=1e-6).x\nprint(opt)\n\ntry:\n    start_date = pd.to_datetime(df.index[0])\n\n    x_model = []\n    y_model = []\n\n    # get the model values for the same time series as the actuals\n    for t in range(len(df) + days_forecast):\n        x_model.append(start_date + datetime.timedelta(days=t))\n        y_model.append(round(model(*opt,t)))\n\n\n    # now plot the new series\n    fig.add_trace(go.Line(x=x_model,\n                          y=y_model,\n                          mode='lines',\n                          name=\"Prediction without offset\",\n                          line=dict(color='Red', \n                                    width=1.5,\n                                    dash='dot'\n                                   )\n                         ) \n                 )\n    \n    # now add the results of the model to the dataframe\n    df2 = pd.DataFrame(y_model,index=x_model,columns=['No Offset'])\n    df2.index.name = 'Date'\n    df_result = pd.merge(df_result,\n                         df2,\n                         how='outer',\n                         left_on=['Date'],\n                         right_on=['Date'])\n    \nexcept:\n    pass\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T05:11:59.452337Z","start_time":"2020-03-22T05:11:59.332335Z"},"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df_result['Offset error'] = (df_result['Deaths']-df_result['Offset'])/df_result['Deaths']*100\ndf_result['Offset error'][df_result['Deaths']==0]=0\n\ndf_result['No Offset error'] = (df_result['Deaths']-df_result['No Offset'])/df_result['Deaths']*100\ndf_result['No Offset error'][df_result['Deaths']==0]=0\n\ndef highlight_max(s):\n    '''\n    highlight the absolute maximum value in a Series with red font.\n    '''\n    is_min = abs(s) == abs(s).max()\n    return ['color: red' if v else '' for v in is_min]\n\ndf_result.style.apply(highlight_max,axis=1,subset=['Offset error', 'No Offset error'])","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T05:11:59.575338Z","start_time":"2020-03-22T05:11:59.453343Z"},"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# now plot the prediction for the country\n# x_actual = pd.to_datetime(df_result['Date'].reset_index())\nx_actual = list(df_result.reset_index()['Date'])\n\nx_model = x_actual\ny_model_clus = list(df_result['Offset error'])\ny_model_glob = list(df_result['No Offset error'])\n\n# instantiate the figure and add the two series - actual vs modelled    \nfig = go.Figure()\n\nfig.update_layout(title=country,\n                  xaxis_title='Date',\n                  yaxis_title=\"% error\",\n                  autosize=False,\n                  width=700,\n                  height=500,\n                  #yaxis_type='log'\n                 )\n\nfig.add_trace(go.Line(x=x_model,\n                      y=y_model_clus,\n                      mode='lines',\n                      name='Offset error',\n                      line=dict(color='blue', \n                                width=1\n                               )\n                     ) \n             )\n\nfig.add_trace(go.Line(x=x_model,\n                      y=y_model_glob,\n                      mode='lines',\n                      name='No Offset error',\n                      line=dict(color='red', \n                                width=1.0,\n                                dash='dot'\n                               )\n                     ) \n             )\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Competition"},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T05:16:12.942648Z","start_time":"2020-03-22T05:16:12.931649Z"},"trusted":true},"cell_type":"code","source":"df_ca_train = pd.read_csv('../input/covid19-local-us-ca-forecasting-week-1/ca_train.csv')\ndf_ca_test = pd.read_csv('../input/covid19-local-us-ca-forecasting-week-1/ca_test.csv')\ndf_ca_submission = pd.read_csv('../input/covid19-local-us-ca-forecasting-week-1/ca_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T05:16:13.765645Z","start_time":"2020-03-22T05:16:13.754647Z"},"trusted":true},"cell_type":"code","source":"df_ca_train.tail(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Well now, this is the same dataset that we've used in the previous chapter. Just up to 18 March. So the model can be used with just the last couple of days dropped. "},{"metadata":{},"cell_type":"markdown","source":"## ConfirmedCases"},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T05:16:15.190647Z","start_time":"2020-03-22T05:16:14.250659Z"},"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"country = 'US'\ncluster = 'California'\n\ndf = full_table[(full_table['Country/Region'] == country)&(full_table['Province/State'] == cluster)]\ndf = df.groupby(['Date','Country/Region']).sum().reset_index()\ndf['Date'] = pd.to_datetime(df['Date'])\ndf = df.sort_values(by=['Date'])\ndf = df.set_index('Date')[['Confirmed']]\ndf_result = df.copy()\n# drop the last three row of dataframe to model competitions results\ndf.drop(df.tail(3).index,inplace=True)\n\n# ensure that the model starts from when the first case is detected\n# NOTE: its better not to truncate the dataset like this \n# df = df[df[df.columns[0]]>0]\n\n# define the models to forecast the growth of cases\ndef model(N, a, alpha, t0, t):\n    return N * (1 - math.e ** (-a * (t-t0))) ** alpha\n\ndef model_loss(params):\n    N, a, alpha, t0 = params\n    global df\n    r = 0\n    for t in range(len(df)):\n        r += (model(N, a, alpha, t0, t) - df.iloc[t, 0]) ** 2\n    return r \ntry:\n    N = df['Confirmed'][-1]\n    T = -df['Confirmed'][0]\nexcept:\n    N = 10000\n    T = 0\n\nopt = minimize(model_loss, x0=np.array([N, 0.1, 5, T]), method='Nelder-Mead', tol=1e-6).x\nprint(opt)\n\n# create series to be plotted \nx_actual = pd.to_datetime(df.reset_index().iloc[:,0])\nx_actual =list(x_actual)\ny_actual = list(df.reset_index().iloc[:,1])\n\nstart_date = pd.to_datetime(df.index[0])\n\nx_model = []\ny_model = []\n\n# get the model values for the same time series as the actuals\nfor t in range(len(df) + days_forecast):\n    x_model.append(start_date + datetime.timedelta(days=t))\n    y_model.append(round(model(*opt,t)))\n\n# instantiate the figure and add the two series - actual vs modelled    \nfig = go.Figure()\nfig.update_layout(title=country + ' - ' + cluster,\n                  xaxis_title='Date',\n                  yaxis_title=\"nr People\",\n                  autosize=False,\n                  width=700,\n                  height=500,\n                 )\n\nfig.add_trace(go.Line(x=x_actual,\n                      y=y_actual,\n                      mode='markers',\n                      name='Actual',\n                      marker=dict(symbol='circle-open-dot', \n                                  size=9, \n                                  color='black', \n                                  line_width=1.5,\n                                 )\n                     ) \n             )    \n\nfig.add_trace(go.Line(x=x_model,\n                      y=y_model,\n                      mode='lines',\n                      name=\"Prediction with offset\",\n                      line=dict(color='blue', \n                                width=2.5\n                               )\n                     ) \n             ) \n\n# now add the results of the model to the dataframe\ndf2 = pd.DataFrame(y_model,index=x_model,columns=['Offset'])\ndf2.index.name = 'Date'\ndf_result = pd.merge(df_result,\n                     df2,\n                     how='outer',\n                     left_on=['Date'],\n                     right_on=['Date'])\n\n# define the models to forecast the growth of cases\ndef model(N, a, alpha, t):\n    return N * (1 - math.e ** (-a * (t))) ** alpha\n\ndef model_loss(params):\n    N, a, alpha = params\n    global df\n    r = 0\n    for t in range(len(df)):\n        r += (model(N, a, alpha, t) - df.iloc[t, 0]) ** 2\n    return r \n\ntry:\n    N = df['Confirmed'][-1]\nexcept:\n    N = 10000\n\nopt = minimize(model_loss, x0=np.array([N, 0.1, 5]), method='Nelder-Mead', tol=1e-6).x\nprint(opt)\n\ntry:\n    start_date = pd.to_datetime(df.index[0])\n\n    x_model = []\n    y_model = []\n\n    # get the model values for the same time series as the actuals\n    for t in range(len(df) + days_forecast):\n        x_model.append(start_date + datetime.timedelta(days=t))\n        y_model.append(round(model(*opt,t)))\n\n\n    # now plot the new series\n    fig.add_trace(go.Line(x=x_model,\n                          y=y_model,\n                          mode='lines',\n                          name=\"Prediction without offset\",\n                          line=dict(color='Red', \n                                    width=1.5,\n                                    dash='dot'\n                                   )\n                         ) \n                 )\n    \n    # now add the results of the model to the dataframe\n    df2 = pd.DataFrame(y_model,index=x_model,columns=['No Offset'])\n    df2.index.name = 'Date'\n    df_result = pd.merge(df_result,\n                         df2,\n                         how='outer',\n                         left_on=['Date'],\n                         right_on=['Date'])\n    \nexcept:\n    pass\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This might be a bit disingenious though, so let's use the training data set. Although the competition rules said that any supporting data set could be used, it would probably be unfair to use actuals from the future to train the model. "},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T05:16:16.188652Z","start_time":"2020-03-22T05:16:15.192645Z"},"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df = df_ca_train\ndf = df.groupby(['Date','Country/Region']).sum().reset_index()\ndf['Date'] = pd.to_datetime(df['Date'])\ndf = df.sort_values(by=['Date'])\ndf = df.set_index('Date')[['ConfirmedCases']]\ndf_comp = df.copy()\n\n# define the models to forecast the growth of cases\ndef model(N, a, alpha, t0, t):\n    return N * (1 - math.e ** (-a * (t-t0))) ** alpha\n\ndef model_loss(params):\n    N, a, alpha, t0 = params\n    global df\n    r = 0\n    for t in range(len(df)):\n        r += (model(N, a, alpha, t0, t) - df.iloc[t, 0]) ** 2\n    return r \ntry:\n    N = df['ConfirmedCases'][-1]\n    T = -df['ConfirmedCases'][0]\nexcept:\n    N = 10000\n    T = 0\n\nopt = minimize(model_loss, x0=np.array([N, 0.1, 5, T]), method='Nelder-Mead', tol=1e-6).x\nprint(opt)\n\n# create series to be plotted \nx_actual = pd.to_datetime(df.reset_index().iloc[:,0])\nx_actual =list(x_actual)\ny_actual = list(df.reset_index().iloc[:,1])\n\nstart_date = pd.to_datetime(df.index[0])\ndays_forecast = len(df)+len(df_ca_test)-7\nx_model = []\ny_model = []\n\n# get the model values for the same time series as the actuals\nfor t in range(days_forecast):\n    x_model.append(start_date + datetime.timedelta(days=t))\n    y_model.append(round(model(*opt,t)))\n\n# instantiate the figure and add the two series - actual vs modelled    \nfig = go.Figure()\nfig.update_layout(title=country + ' - ' + cluster,\n                  xaxis_title='Date',\n                  yaxis_title=\"nr People\",\n                  autosize=False,\n                  width=700,\n                  height=500,\n                 )\n\nfig.add_trace(go.Line(x=x_actual,\n                      y=y_actual,\n                      mode='markers',\n                      name='Actual',\n                      marker=dict(symbol='circle-open-dot', \n                                  size=9, \n                                  color='black', \n                                  line_width=1.5,\n                                 )\n                     ) \n             )    \n\nfig.add_trace(go.Line(x=x_model,\n                      y=y_model,\n                      mode='lines',\n                      name=\"Prediction with offset\",\n                      line=dict(color='blue', \n                                width=2.5\n                               )\n                     ) \n             ) \n\n# now add the results of the model to the dataframe\n\ndf2 = pd.DataFrame(y_model,index=pd.to_datetime(x_model),columns=['ConfirmedCases'])\ndf2.index.name = 'Date'\ndf_comp = df.rename(columns={'ConfirmedCases': 'Actuals'})\ndf_comp = pd.merge(df_comp,\n                     df2,\n                     how='outer',\n                     left_on=['Date'],\n                     right_on=['Date'])\ndf_comp = df_comp[['ConfirmedCases']]\n\n\n# define the models to forecast the growth of cases\ndef model(N, a, alpha, t):\n    return N * (1 - math.e ** (-a * (t))) ** alpha\n\ndef model_loss(params):\n    N, a, alpha = params\n    global df\n    r = 0\n    for t in range(len(df)):\n        r += (model(N, a, alpha, t) - df.iloc[t, 0]) ** 2\n    return r \n\ntry:\n    N = df['ConfirmedCases'][-1]\nexcept:\n    N = 10000\n\nopt = minimize(model_loss, x0=np.array([N, 0.1, 5]), method='Nelder-Mead', tol=1e-6).x\nprint(opt)\n\ntry:\n    start_date = pd.to_datetime(df.index[0])\n\n    x_model = []\n    y_model = []\n\n    # get the model values for the same time series as the actuals\n    for t in range(days_forecast):\n        x_model.append(start_date + datetime.timedelta(days=t))\n        y_model.append(round(model(*opt,t)))\n\n\n    # now plot the new series\n    fig.add_trace(go.Line(x=x_model,\n                          y=y_model,\n                          mode='lines',\n                          name=\"Prediction without offset\",\n                          line=dict(color='Red', \n                                    width=1.5,\n                                    dash='dot'\n                                   )\n                         ) \n                 )\n    \nexcept:\n    pass\n\nfig.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fatalities"},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T05:16:17.048644Z","start_time":"2020-03-22T05:16:16.190646Z"},"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df = df_ca_train\ndf = df.groupby(['Date','Country/Region']).sum().reset_index()\ndf['Date'] = pd.to_datetime(df['Date'])\ndf = df.sort_values(by=['Date'])\ndf = df.set_index('Date')[['Fatalities']]\n\n\n# # define the models to forecast the growth of cases\n# def model(N, a, alpha, t0, t):\n#     return N * (1 - math.e ** (-a * (t-t0))) ** alpha\n\n# def model_loss(params):\n#     N, a, alpha, t0 = params\n#     global df\n#     r = 0\n#     for t in range(len(df)):\n#         r += (model(N, a, alpha, t0, t) - df.iloc[t, 0]) ** 2\n#     return r \n# try:\n#     N = df['Fatalities'][-1]\n#     T = -df['Fatalities'][0]\n# except:\n#     N = 10000\n#     T = 0\n\n# opt = minimize(model_loss, x0=np.array([N, 0.1, 5, T]), method='Nelder-Mead', tol=1e-6).x\n\n# define the models to forecast the growth of cases\ndef model(N, a, alpha, t):\n    return N * (1 - math.e ** (-a * (t))) ** alpha\n\ndef model_loss(params):\n    N, a, alpha = params\n    global df\n    r = 0\n    for t in range(len(df)):\n        r += (model(N, a, alpha, t) - df.iloc[t, 0]) ** 2\n    return r \n\ntry:\n    N = df['ConfirmedCases'][-1]\nexcept:\n    N = 10000\n\nopt = minimize(model_loss, x0=np.array([N, 0.1, 5]), method='Nelder-Mead', tol=1e-6).x\nprint(opt)\n\n# create series to be plotted \nx_actual = pd.to_datetime(df.reset_index().iloc[:,0])\nx_actual =list(x_actual)\ny_actual = list(df.reset_index().iloc[:,1])\n\nstart_date = pd.to_datetime(df.index[0])\ndays_forecast = len(df)+len(df_ca_test)-7\nx_model = []\ny_model = []\n\n# get the model values for the same time series as the actuals\nfor t in range(days_forecast):\n    x_model.append(start_date + datetime.timedelta(days=t))\n    y_model.append(round(model(*opt,t)))\n\n# instantiate the figure and add the two series - actual vs modelled    \nfig = go.Figure()\nfig.update_layout(title=country + ' - ' + cluster,\n                  xaxis_title='Date',\n                  yaxis_title=\"nr People\",\n                  autosize=False,\n                  width=700,\n                  height=500,\n                 )\n\nfig.add_trace(go.Line(x=x_actual,\n                      y=y_actual,\n                      mode='markers',\n                      name='Actual',\n                      marker=dict(symbol='circle-open-dot', \n                                  size=9, \n                                  color='black', \n                                  line_width=1.5,\n                                 )\n                     ) \n             )    \n\nfig.add_trace(go.Line(x=x_model,\n                      y=y_model,\n                      mode='lines',\n                      name=\"Prediction with offset\",\n                      line=dict(color='blue', \n                                width=2.5\n                               )\n                     ) \n             ) \n\n# now add the results of the model to the dataframe\n\ndf2 = pd.DataFrame(y_model,index=pd.to_datetime(x_model),columns=['Fatalities'])\ndf2.index.name = 'Date'\ndf_comp = pd.merge(df_comp,\n                     df2,\n                     how='outer',\n                     left_on=['Date'],\n                     right_on=['Date'])\n\n# define the models to forecast the growth of cases\ndef model(N, a, alpha, t):\n    return N * (1 - math.e ** (-a * (t))) ** alpha\n\ndef model_loss(params):\n    N, a, alpha = params\n    global df\n    r = 0\n    for t in range(len(df)):\n        r += (model(N, a, alpha, t) - df.iloc[t, 0]) ** 2\n    return r \n\ntry:\n    N = df['ConfirmedCases'][-1]\nexcept:\n    N = 10000\n\nopt = minimize(model_loss, x0=np.array([N, 0.1, 5]), method='Nelder-Mead', tol=1e-6).x\nprint(opt)\n\ntry:\n    start_date = pd.to_datetime(df.index[0])\n\n    x_model = []\n    y_model = []\n\n    # get the model values for the same time series as the actuals\n    for t in range(days_forecast):\n        x_model.append(start_date + datetime.timedelta(days=t))\n        y_model.append(round(model(*opt,t)))\n\n\n    # now plot the new series\n    fig.add_trace(go.Line(x=x_model,\n                          y=y_model,\n                          mode='lines',\n                          name=\"Prediction without offset\",\n                          line=dict(color='Red', \n                                    width=1.5,\n                                    dash='dot'\n                                   )\n                         ) \n                 )\n    \nexcept:\n    pass\n\nfig.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submission File"},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T05:16:17.069676Z","start_time":"2020-03-22T05:16:17.050645Z"},"trusted":true},"cell_type":"code","source":"df_comp = df_comp.reset_index()\ndf_comp.tail()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T05:17:15.649351Z","start_time":"2020-03-22T05:17:15.639319Z"},"trusted":true},"cell_type":"code","source":"df_ca_test.head()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T05:21:56.960262Z","start_time":"2020-03-22T05:21:56.955263Z"},"trusted":true},"cell_type":"code","source":"df_ca_test['Date'] = pd.to_datetime(df_ca_test['Date'])","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T05:21:58.09507Z","start_time":"2020-03-22T05:21:58.087071Z"},"trusted":true},"cell_type":"code","source":"df_ca_test.info()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T05:22:02.247186Z","start_time":"2020-03-22T05:22:02.238166Z"},"trusted":true},"cell_type":"code","source":"df_sub = pd.merge(df_ca_test,\n                  df_comp,\n                  how='left',\n                  on=['Date']\n                 )","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T05:22:29.472403Z","start_time":"2020-03-22T05:22:29.464365Z"},"trusted":true},"cell_type":"code","source":"df_sub.tail()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T05:25:03.558197Z","start_time":"2020-03-22T05:25:03.549171Z"},"trusted":true},"cell_type":"code","source":"df_sub = df_sub[['ForecastId','ConfirmedCases','Fatalities']]\ndf_sub.tail()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T05:25:00.932171Z","start_time":"2020-03-22T05:25:00.925209Z"},"trusted":true},"cell_type":"code","source":"df_ca_submission.tail()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-03-22T05:26:36.292826Z","start_time":"2020-03-22T05:26:36.281826Z"},"trusted":true},"cell_type":"code","source":"df_sub.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion"},{"metadata":{},"cell_type":"markdown","source":"> Sorry for the rush on this job and not explaining everything well. I have kids at home, trying to give cereal while submitting the results. The fatality prediction using the offset model does not look great in this case. When there is more data, the model does much better. "},{"metadata":{},"cell_type":"markdown","source":" "}],"metadata":{"hide_input":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":true,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"261.438px"},"toc_section_display":true,"toc_window_display":true}},"nbformat":4,"nbformat_minor":4}