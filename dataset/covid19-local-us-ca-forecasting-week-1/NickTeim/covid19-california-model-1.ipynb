{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Importing data"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nsample_submission = pd.read_csv(\"/kaggle/input/covid19-local-us-ca-forecasting-week-1/ca_submission.csv\")\ntest = pd.read_csv(\"/kaggle/input/covid19-local-us-ca-forecasting-week-1/ca_test.csv\")\ntrain = pd.read_csv(\"/kaggle/input/covid19-local-us-ca-forecasting-week-1/ca_train.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Check data"},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Heatmap over California which will give a better picture as following weeks progress "},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#make a heatmap\n\nimport folium\nfrom folium import Choropleth, Marker\nfrom folium.plugins import HeatMap, MarkerCluster\nm = folium.Map(location=[37, -115], zoom_start=6) \ndef embed_map(m, file_name):\n    from IPython.display import IFrame\n    m.save(file_name)\n    return IFrame(file_name, width='100%', height='750px')\n\n#merge test and training data\nFull_data = pd.merge(test, train, on=['Lat','Long','Date'])\n\n# Add a heatmap to the base map\nHeatMap(data=Full_data[['Lat', 'Long']], radius=11).add_to(m)\n\n# Show the map\nembed_map(m, \"q_1.html\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"#rename therefor the data columns\ntrain.rename(columns={'Province/State':'Province'}, inplace=True)\ntrain.rename(columns={'Country/Region':'Country'}, inplace=True)\ntrain.rename(columns={'ConfirmedCases':'Confirmed'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#and we do the same for test set\ntest.rename(columns={'Province/State':'Province'}, inplace=True)\ntest.rename(columns={'Country/Region':'Country'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Label encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n# creating initial dataframe\nbridge_types = ('Lat', 'Date', 'Province', 'Country', 'Long', 'Confirmed',\n       'ForecastId', 'Id')\ncountries = pd.DataFrame(train, columns=['Country'])\n# creating instance of labelencoder\nlabelencoder = LabelEncoder()\n# Assigning numerical values and storing in another column\ntrain['Countries'] = labelencoder.fit_transform(train['Country'])\n\n#do the same for test set\ntest['Countries'] = labelencoder.fit_transform(test['Country'])\n\n#check label encoding \ntrain['Countries'].head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Handling dates"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Date']= pd.to_datetime(train['Date']) \ntest['Date']= pd.to_datetime(test['Date']) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.set_index(['Date'])\ntest = test.set_index(['Date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_time_features(df):\n    \"\"\"\n    Creates time series features from datetime index\n    \"\"\"\n    df['date'] = df.index\n    df['hour'] = df['date'].dt.hour\n    df['dayofweek'] = df['date'].dt.dayofweek\n    df['quarter'] = df['date'].dt.quarter\n    df['month'] = df['date'].dt.month\n    df['year'] = df['date'].dt.year\n    df['dayofyear'] = df['date'].dt.dayofyear\n    df['dayofmonth'] = df['date'].dt.day\n    df['weekofyear'] = df['date'].dt.weekofyear\n    \n    X = df[['hour','dayofweek','quarter','month','year',\n           'dayofyear','dayofmonth','weekofyear']]\n    return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"create_time_features(train).head()\ncreate_time_features(test).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dropping useless features"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop(\"date\", axis=1, inplace=True)\ntest.drop(\"date\", axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop useless columns for train and test set\ntrain.drop(['Country'], axis=1, inplace=True)\ntrain.drop(['Province'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.drop(['Country'], axis=1, inplace=True)\ntest.drop(['Province'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor  \nregressor = DecisionTreeRegressor(random_state = 0) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import xgboost as xgb\n# from xgboost import plot_importance, plot_tree\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\n\n# reg= xgb.XGBRegressor(n_estimators=1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# features that will be used in the model\nx = train[['Lat', 'Long','Countries','dayofweek','month','dayofyear','weekofyear']]\ny1 = train[['Confirmed']]\ny2 = train[['Fatalities']]\nx_test = test[['Lat', 'Long','Countries','dayofweek','month','dayofyear','weekofyear']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#use model on data \nregressor.fit(x,y1)\npredict_1 = regressor.predict(x_test)\npredict_1 = pd.DataFrame(predict_1)\npredict_1.columns = [\"Confirmed_predict\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#use model on data \nregressor.fit(x,y2)\npredict_2 = regressor.predict(x_test)\npredict_2 = pd.DataFrame(predict_2)\npredict_2.columns = [\"Death_prediction\"]\npredict_2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot = plot_importance(regressor, height=0.9, max_num_features=20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"Samle_submission = pd.read_csv(\"/kaggle/input/covid19-local-us-ca-forecasting-week-1/ca_submission.csv\")\nSamle_submission.columns\nsubmission = Samle_submission[[\"ForecastId\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Final_submission = pd.concat([predict_1,predict_2,submission],axis=1)\nFinal_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Final_submission.columns = ['ConfirmedCases', 'Fatalities', 'ForecastId']\nFinal_submission = Final_submission[['ForecastId','ConfirmedCases', 'Fatalities']]\n\nFinal_submission[\"ConfirmedCases\"] = Final_submission[\"ConfirmedCases\"].astype(int)\nFinal_submission[\"Fatalities\"] = Final_submission[\"Fatalities\"].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Final_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Final_submission.to_csv(\"submission.csv\",index=False)\nprint('Model ready for submission!')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}