{"cells":[{"metadata":{},"cell_type":"markdown","source":"We live in a world that is so intertwined and connected. This reminds us the poet from the great Persian poet Saa'di Shirazi:\n> \"Human beings are members of one another,\nsince in their creation they are of one essence.\nWhen the conditions of the time brings a member (limb) to pain,\nthe other members (limbs) will suffer from discomfort.\nYou, who are indifferent to the misery of others,\nit is not fitting that they should call you a human being.\"\n\nThis is a Quantum world and we need the rules of Quantum Physics to address the events b/c it cannot be described anymore with the cause-effect relationship. This is infact a difference between our view and how Ray Dalio (Bridgewater CEO, the world wealthiest hedgefund) interprets the world. We start with simple Newtonian AI approach here. We hope in the future we can publish some Quantum solutions."},{"metadata":{},"cell_type":"markdown","source":"# Part 1: Simple LSTM with PyTorch"},{"metadata":{},"cell_type":"markdown","source":"The novel coronavirus (COVID-19) has impacted a lot of life style especially in the southern California where we live. In this part we try to address this using a the most simple possible timeseries model using LSTM in PyTorch framework. We are also thankful to Venelin Valkov for taking initiative and published the first LSTM attempt in this regard for global patterns. Cf. https://github.com/curiousily/Getting-Things-Done-with-Pytorch/blob/master/05.time-series-forecasting-covid-19.ipynb for more information."},{"metadata":{},"cell_type":"markdown","source":"## Novel Coronavirus (COVID-19)"},{"metadata":{},"cell_type":"markdown","source":"The novel Coronavirus (Covid-19) has spread around the world in a fast way. Currenly, [Worldometers.info](https://www.worldometers.info/coronavirus/) provides data for more than *335,403* confirmed cases in more than *192* countries.\n\nThe top 6 worst-affected (by far) are China (the source of the virus), Italy, USA, Spain, Germany, and Iran. However, many cases are currently not reported due to:\n\n- A person can get infected without even knowing (asymptomatic)\n- Incorrect data reporting\n- Not enough test kits\n- The symptoms look a lot like the common flu\n"},{"metadata":{},"cell_type":"markdown","source":"### How dangerous is this virus?\n\n> Except for the common statistics you might see cited on the news, there are some good and some bad news:\n> \n> - More than 80% of the confirmed cases recover without any need of medical attention\n> - [3.4% Mortality Rate estimate by the World Health Organization (WHO) as of March 3](https://www.worldometers.info/coronavirus/coronavirus-death-rate/#who-03-03-20)\n> - The reproductive number which represents the average number of people to which a single infected person will transmit the virus is between 1.4 and 2.5 [(WHO's estimated on Jan. 23)](https://www.worldometers.info/coronavirus/#repro)\n> \n> The last one is really scary. It sounds like we can witness some crazy exponential growth if appropriate measures are not put in place.\n\nThere would be other factors and we will elaborate later in the data challenges. Let's now focus on the most simple model.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import libraries\nimport torch\n\nimport os\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport seaborn as sns\nfrom pylab import rcParams\nimport matplotlib.pyplot as plt\nfrom matplotlib import rc\nfrom sklearn.preprocessing import MinMaxScaler\nfrom pandas.plotting import register_matplotlib_converters\nfrom torch import nn, optim\nfrom sklearn.model_selection import train_test_split\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n\nsns.set(style='whitegrid', palette='muted', font_scale=1.2)\n\nHAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#93D30C\", \"#8F00FF\"]\n\nsns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n\nrcParams['figure.figsize'] = 14, 10\nregister_matplotlib_converters()\n\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)\ntorch.manual_seed(RANDOM_SEED)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Daily Cases Dataset"},{"metadata":{},"cell_type":"markdown","source":"The data is provided by the Johns Hopkins University Center for Systems Science and Engineering (JHU CSSE) and contains the number of reported daily cases by country. [The dataset is available on GitHub](https://github.com/CSSEGISandData/COVID-19) and is updated regularly.\n\nWe're going to take the Time Series data only for confirmed cases (number of deaths and recovered cases are also available):\nNote that, we are told by Kaggle to use the data upto March 18, 2020 to predict the future."},{"metadata":{},"cell_type":"markdown","source":"## Data Exploration and EDA"},{"metadata":{},"cell_type":"markdown","source":"![](http://)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv(\"../input/covid19-local-us-ca-forecasting-week-1/ca_train.csv\")\ndf_test = pd.read_csv(\"../input/covid19-local-us-ca-forecasting-week-1/ca_test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Two things to note here:\n\n- The data contains a province, country, latitude, and longitude. For simplicity these are ignored in this notebook and for the future we will explore them further.\n- The number of cases is cumulative. We'll undo the accumulation.\n\nLet's start by getting rid of the first four columns:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_drop_cols = df_train.columns[:-3]\ntest_drop_cols = df_test.columns[1:-1]\n\ntrain = df_train.copy().drop(train_drop_cols, axis=1)\ntest = df_test.copy().drop(test_drop_cols, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = train\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Check for missing values:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Reindexing the data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.index = pd.to_datetime(train['Date'])\ntrain.drop(['Date'], axis=1, inplace=True)\n\ntest.index = pd.to_datetime(test['Date'])\ntest.drop(['Date'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note that we only have data for 63 days which is not enough for a deep learning strategy but we will try to overcome this by improving the model parameters."},{"metadata":{"trusted":true},"cell_type":"code","source":"daily_cases = train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(daily_cases['ConfirmedCases'])\nplt.title(\"Cumulative confirmed daily cases\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(daily_cases['Fatalities'])\nplt.title(\"Cumulative fatalities daily cases\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We'll undo the accumulation by subtracting the current value from the previous. We'll preserve the first value of the sequence:\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"daily_cases_infected = daily_cases['ConfirmedCases'].diff().fillna(daily_cases['ConfirmedCases'][0]).astype(np.int64)\ndaily_cases_infected.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"daily_cases_fatality = daily_cases['Fatalities'].diff().fillna(daily_cases['Fatalities'][0]).astype(np.int64)\ndaily_cases_fatality.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(daily_cases_infected)\nplt.title(\"Daily infected cases\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(daily_cases_fatality)\nplt.title(\"Daily fatality cases\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"daily_cases_infected.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"daily_cases_fatality.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Extract rows with confirmed cases greater than**** 0\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# train = train[train['ConfirmedCases'] > 0]\n# train_data, test_data = train_test_split(train, test_size=0.33, random_state=42)\n# infection_train = train_data['ConfirmedCases']\n# infection_test = test_data['ConfirmedCases']\n# fatality_train = train_data['Fatalities']\n# fatality_test = test_data['Fatalities']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_infected, test_data_infected = train_test_split(daily_cases_infected, test_size=0.33, random_state=42)\ntrain_data_fatality, test_data_fatality = train_test_split(daily_cases_fatality, test_size=0.33, random_state=42)\ninfection_train = train_data_infected\nfatality_train = train_data_fatality\ninfection_test = test_data_infected\nfatality_test = test_data_fatality","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_infected.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_fatality.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The data is scaled b/w 0 and 1 to increase the training speed and performance of the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler_infection = MinMaxScaler()\n\nscaler_infection = scaler_infection.fit(np.expand_dims(infection_train, axis=1))\n\ninfection_train = scaler_infection.transform(np.expand_dims(infection_train, axis=1))\n\ninfection_test = scaler_infection.transform(np.expand_dims(infection_test, axis=1))\n\nscaler_fatality = MinMaxScaler()\n\nscaler_fatality = scaler_fatality.fit(np.expand_dims(fatality_train, axis=1))\n\nfatality_train = scaler_fatality.transform(np.expand_dims(fatality_train, axis=1))\n\nfatality_test = scaler_fatality.transform(np.expand_dims(fatality_test, axis=1))\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fatality_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Break the large sequence into chunks of smaller sequences"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_sequences(data, seq_length):\n    xs = []\n    ys = []\n\n    for i in range(len(data)-seq_length-1):\n        x = data[i:(i+seq_length)]\n        y = data[i+seq_length]\n        xs.append(x)\n        ys.append(y)\n\n    return np.array(xs), np.array(ys)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seq_length = 2\n\n# confirmed cases\nX_train_infection, y_train_infection = create_sequences(infection_train, seq_length)\nX_test_infection, y_test_infection = create_sequences(infection_test, seq_length)\n\nX_train_infection = torch.from_numpy(X_train_infection).float()\ny_train_infection = torch.from_numpy(y_train_infection).float()\n\nX_test_infection = torch.from_numpy(X_test_infection).float()\ny_test_infection = torch.from_numpy(y_test_infection).float()\n\n# fatalities\nX_train_fatality, y_train_fatality = create_sequences(fatality_train, seq_length)\nX_test_fatality, y_test_fatality = create_sequences(fatality_test, seq_length)\n\nX_train_fatality = torch.from_numpy(X_train_fatality).float()\ny_train_fatality = torch.from_numpy(y_train_fatality).float()\n\nX_test_fatality = torch.from_numpy(X_test_fatality).float()\ny_test_fatality = torch.from_numpy(y_test_fatality).float()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_infection","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Each training example contains a sequence of 5 data points of history and a label for the real value that our model needs to predict."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_infection.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_fatality.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_infection[:2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_fatality[:2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_infection.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_fatality.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_infection[:2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_fatality[:2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_infection.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"infection_train[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fatality_train[:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Constructing LSTM RNN model"},{"metadata":{"trusted":true},"cell_type":"code","source":"class CoronaVirusForecast(nn.Module):\n\n  def __init__(self, n_features, n_hidden, seq_len, n_layers=2):\n    super(CoronaVirusForecast, self).__init__()\n\n    self.n_hidden = n_hidden\n    self.seq_len = seq_len\n    self.n_layers = n_layers\n\n    self.lstm = nn.LSTM(\n      input_size=n_features,\n      hidden_size=n_hidden,\n      num_layers=n_layers,\n      dropout=0.5\n    )\n\n    self.linear = nn.Linear(in_features=n_hidden, out_features=1)\n\n  def reset_hidden_state(self):\n    self.hidden = (\n        torch.zeros(self.n_layers, self.seq_len, self.n_hidden),\n        torch.zeros(self.n_layers, self.seq_len, self.n_hidden)\n    )\n\n  def forward(self, sequences):\n    lstm_out, self.hidden = self.lstm(\n      sequences.view(len(sequences), self.seq_len, -1),\n      self.hidden\n    )\n    last_time_step = \\\n      lstm_out.view(self.seq_len, len(sequences), self.n_hidden)[-1]\n    y_pred = self.linear(last_time_step)\n    return y_pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The CoronaVirusForecast contains 3 methods:\nconstructor - initialize all helper data and create the layers\nreset_hidden_state - implements a stateless LSTM, so the state after each sample is reseted. \nforward - get the sequences, pass all of them through the LSTM layer, at once. The output of the last time step is taken and is passed through the linear layer to get the prediction."},{"metadata":{},"cell_type":"markdown","source":"### Training the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model_infection(\n  model, \n  infection_train, \n  train_labels, \n  infection_test=None, \n  test_labels=None\n):\n  loss_fn = torch.nn.MSELoss(reduction='sum')\n\n  optimiser = torch.optim.Adam(model.parameters(), lr=1e-3)\n  num_epochs = 400\n\n  infection_train_hist = np.zeros(num_epochs)\n  infection_test_hist = np.zeros(num_epochs)\n\n  for t in range(num_epochs):\n    model.reset_hidden_state()\n\n    y_pred_infection = model(X_train_infection)\n\n    loss = loss_fn(y_pred_infection.float(), y_train_infection)\n\n    if infection_test is not None:\n      with torch.no_grad():\n        y_test_pred_infection = model(X_test_infection)\n        test_loss = loss_fn(y_test_pred_infection.float(), y_test_infection)\n      infection_test_hist[t] = test_loss.item()\n\n      if t % 10 == 0:  \n        print(f'Epoch {t} train loss: {loss.item()} test loss: {test_loss.item()}')\n    elif t % 10 == 0:\n      print(f'Epoch {t} train loss: {loss.item()}')\n\n    infection_train_hist[t] = loss.item()\n    \n    optimiser.zero_grad()\n\n    loss.backward()\n\n    optimiser.step()\n  \n  return model.eval(), infection_train_hist, infection_test_hist","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model_fatality(\n  model, \n  fatality_train, \n  train_labels, \n  fatality_test=None, \n  test_labels=None\n):\n  loss_fn = torch.nn.MSELoss(reduction='sum')\n\n  optimiser = torch.optim.Adam(model.parameters(), lr=1e-3)\n  num_epochs = 400\n\n  fatality_train_hist = np.zeros(num_epochs)\n  fatality_test_hist = np.zeros(num_epochs)\n\n  for t in range(num_epochs):\n    model.reset_hidden_state()\n\n    y_pred_fatality = model(X_train_fatality)\n\n    loss = loss_fn(y_pred_fatality.float(), y_train_fatality)\n\n    if fatality_test is not None:\n      with torch.no_grad():\n        y_test_pred_fatality = model(X_test_fatality)\n        test_loss = loss_fn(y_test_pred_fatality.float(), y_test_fatality)\n      fatality_test_hist[t] = test_loss.item()\n\n      if t % 10 == 0:  \n        print(f'Epoch {t} train loss: {loss.item()} test loss: {test_loss.item()}')\n    elif t % 10 == 0:\n      print(f'Epoch {t} train loss: {loss.item()}')\n\n    fatality_train_hist[t] = loss.item()\n    \n    optimiser.zero_grad()\n\n    loss.backward()\n\n    optimiser.step()\n  \n  return model.eval(), fatality_train_hist, fatality_test_hist","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note that the hidden state is reset at the start of each epoch. We don't use batches of data our model sees every example at once. We'll use mean squared error to measure our training and test error. We'll record both.\nLet's create an instance of our model and train it:"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = CoronaVirusForecast(\n  n_features=1, \n  n_hidden=512, \n  seq_len=seq_length, \n  n_layers=2\n)\nmodel, infection_train_hist, infection_test_hist = train_model_infection(\n  model, \n  X_train_infection, \n  y_train_infection, \n  X_test_infection, \n  y_test_infection\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(infection_train_hist, label=\"Training loss\")\nplt.plot(infection_test_hist, label=\"Test loss\")\nplt.ylim((0, 5))\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = CoronaVirusForecast(\n  n_features=1, \n  n_hidden=512, \n  seq_len=seq_length, \n  n_layers=2\n)\nmodel, fatality_train_hist, fatality_test_hist = train_model_fatality(\n  model, \n  X_train_fatality, \n  y_train_fatality, \n  X_test_fatality, \n  y_test_fatality\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(fatality_train_hist, label=\"Training loss\")\nplt.plot(fatality_test_hist, label=\"Test loss\")\nplt.ylim((0, 5))\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Daily Cases Prediction"},{"metadata":{},"cell_type":"markdown","source":"The model can (due to the way we've trained it) predict only a single day in the future. We'll employ a simple strategy to overcome this limitation. Use predicted values as input for predicting the next days:"},{"metadata":{"trusted":true},"cell_type":"code","source":"with torch.no_grad():\n  test_seq_infection = X_test_infection[:1]\n  preds_infection = []\n  for _ in range(len(X_test_infection)):\n    y_test_pred_infection = model(test_seq_infection)\n    pred_infection = torch.flatten(y_test_pred_infection).item()\n    preds_infection.append(pred_infection)\n    new_seq_infection = test_seq_infection.numpy().flatten()\n    new_seq_infection = np.append(new_seq_infection, [pred_infection])\n    new_seq_infection = new_seq_infection[1:]\n    test_seq_infection = torch.as_tensor(new_seq_infection).view(1, seq_length, 1).float()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with torch.no_grad():\n  test_seq_fatality = X_test_fatality[:1]\n  preds_fatality = []\n  for _ in range(len(X_test_fatality)):\n    y_test_pred_fatality = model(test_seq_fatality)\n    pred_fatality = torch.flatten(y_test_pred_fatality).item()\n    preds_fatality.append(pred_fatality)\n    new_seq_fatality = test_seq_fatality.numpy().flatten()\n    new_seq_fatality = np.append(new_seq_fatality, [pred_fatality])\n    new_seq_fatality = new_seq_fatality[1:]\n    test_seq_fatality = torch.as_tensor(new_seq_fatality).view(1, seq_length, 1).float()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have to reverse the scaling of the test data and the model predictions:\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"true_cases_infection = scaler_infection.inverse_transform(\n    np.expand_dims(y_test_infection.flatten().numpy(), axis=0)\n).flatten()\n\npredicted_cases_infection = scaler_infection.inverse_transform(\n  np.expand_dims(preds_infection, axis=0)\n).flatten()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"true_cases_fatality = scaler_fatality.inverse_transform(\n    np.expand_dims(y_test_fatality.flatten().numpy(), axis=0)\n).flatten()\n\npredicted_cases_fatality = scaler_fatality.inverse_transform(\n  np.expand_dims(preds_fatality, axis=0)\n).flatten()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(\n  daily_cases_infected.index[:len(infection_train)], \n  scaler_infection.inverse_transform(infection_train).flatten(),\n  label='Historical Infected Daily Cases'\n)\n\nplt.plot(\n  daily_cases_infected.index[len(infection_train):len(infection_train) + len(true_cases_infection)], \n  true_cases_infection,\n  label='Real Infected Daily Cases'\n)\n\nplt.plot(\n  daily_cases_infected.index[len(infection_train):len(infection_train) + len(true_cases_infection)], \n  predicted_cases_infection, \n  label='Predicted Infected Daily Cases'\n)\n\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# All data for Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler_infection = MinMaxScaler()\n\nscaler_infection = scaler_infection.fit(np.expand_dims(daily_cases_infected, axis=1))\n\nall_data_infection = scaler_infection.transform(np.expand_dims(daily_cases_infected, axis=1))\n\nall_data_infection.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler_fatality = MinMaxScaler()\n\nscaler_fatality = scaler_fatality.fit(np.expand_dims(daily_cases_fatality, axis=1))\n\nall_data_fatality = scaler_fatality.transform(np.expand_dims(daily_cases_fatality, axis=1))\n\nall_data_fatality.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_all_infection, y_all_infection = create_sequences(all_data_infection, seq_length)\n\nX_all_infection = torch.from_numpy(X_all_infection).float()\ny_all_infection = torch.from_numpy(y_all_infection).float()\n\nmodel = CoronaVirusForecast(\n  n_features=1, \n  n_hidden=512, \n  seq_len=seq_length, \n  n_layers=2\n)\nmodel, train_hist_infection, _ = train_model_infection(model, X_all_infection, y_all_infection)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_all_fatality, y_all_fatality = create_sequences(all_data_fatality, seq_length)\n\nX_all_fatality = torch.from_numpy(X_all_fatality).float()\ny_all_fatality = torch.from_numpy(y_all_fatality).float()\n\nmodel = CoronaVirusForecast(\n  n_features=1, \n  n_hidden=512, \n  seq_len=seq_length, \n  n_layers=2\n)\nmodel, train_hist_fatality, _ = train_model_fatality(model, X_all_fatality, y_all_fatality)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DAYS_TO_PREDICT_INFECTION = 43\n\nwith torch.no_grad():\n  test_seq = X_all_infection[:1]\n  preds_infection = []\n  for _ in range(DAYS_TO_PREDICT_INFECTION):\n    y_test_pred_infection = model(test_seq_infection)\n    pred_infection = torch.flatten(y_test_pred_infection).item()\n    preds_infection.append(pred_infection)\n    new_seq_infection = test_seq_infection.numpy().flatten()\n    new_seq_infection = np.append(new_seq_infection, [pred_infection])\n    new_seq_infection = new_seq_infection[1:]\n    test_seq_infection = torch.as_tensor(new_seq_infection).view(1, seq_length, 1).float()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DAYS_TO_PREDICT_FATALITY = 43\n\nwith torch.no_grad():\n  test_seq = X_all_fatality[:1]\n  preds_fatality = []\n  for _ in range(DAYS_TO_PREDICT_FATALITY):\n    y_test_pred_fatality = model(test_seq_fatality)\n    pred_fatality = torch.flatten(y_test_pred_fatality).item()\n    preds_fatality.append(pred_fatality)\n    new_seq_fatality = test_seq_fatality.numpy().flatten()\n    new_seq_fatality = np.append(new_seq_fatality, [pred_fatality])\n    new_seq_fatality = new_seq_fatality[1:]\n    test_seq_fatality = torch.as_tensor(new_seq_fatality).view(1, seq_length, 1).float()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_cases_infection = scaler_infection.inverse_transform(\n  np.expand_dims(preds_infection, axis=0)\n).flatten()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_cases_fatality = scaler_fatality.inverse_transform(\n  np.expand_dims(preds_fatality, axis=0)\n).flatten()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To create a cool chart with the historical and predicted cases, we need to extend the date index of our data frame:"},{"metadata":{"trusted":true},"cell_type":"code","source":"daily_cases_infected.index[-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"daily_cases_fatality.index[-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_index_infection = pd.date_range(\n  start=daily_cases_infected.index[-14],\n  periods=DAYS_TO_PREDICT_INFECTION + 1,\n  closed='right'\n)\n\npredicted_cases_infection = pd.Series(\n  data=predicted_cases_infection,\n  index=predicted_index_infection\n)\n\nplt.plot(predicted_cases_infection, label='Predicted Infected Daily Cases')\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_index_fatality = pd.date_range(\n  start=daily_cases_fatality.index[-14],\n  periods=DAYS_TO_PREDICT_FATALITY + 1,\n  closed='right'\n)\n\npredicted_cases_fatality = pd.Series(\n  data=predicted_cases_fatality,\n  index=predicted_index_fatality\n)\n\nplt.plot(predicted_cases_fatality, label='Predicted Fatality Daily Cases')\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_index_infection","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(daily_cases_infected, label='Historical Infected Daily Cases')\nplt.plot(predicted_cases_infection, label='Predicted Infected Daily Cases')\nplt.legend();\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(daily_cases_fatality, label='Historical Fatality Daily Cases')\nplt.plot(predicted_cases_fatality, label='Predicted Fatality Daily Cases')\nplt.legend();\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion"},{"metadata":{},"cell_type":"markdown","source":"To make the model better it is good to focus on more data, the number of drop_out, the number of hidden layer, and maybe bidirectional LSTM."},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission = pd.read_csv(\"../input/covid19-local-us-ca-forecasting-week-1/ca_submission.csv\")\nsample_submission\nsubmission = pd.DataFrame({\n                           'ConfirmedCases': predicted_cases_infection,\n                           'Fatalities': predicted_cases_fatality})\nsubmission.index = sample_submission.index\nsubmission['ForecastId'] = sample_submission['ForecastId']\nsubmission = submission[['ForecastId','ConfirmedCases','Fatalities']]\nsubmission.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}