{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# COVID19 Local US-CA Forecasting (Week 1)\n\n# Forecast daily COVID-19 spread in California, USA\n\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib import style\nfrom sklearn.preprocessing import MinMaxScaler\n\nimport torch\nimport torch.nn as nn\n\nstyle.use('ggplot')\n\nfor dirname, _, filename in os.walk(os.getcwd()):\n    for file in filename:\n        path = os.path.join(dirname, file)\n        if 'csv' in path:\n            print(path)\n\ntrain_raw = pd.read_csv('../input/covid19-local-us-ca-forecasting-week-1/ca_train.csv')\ntest_raw = pd.read_csv('../input/covid19-local-us-ca-forecasting-week-1/ca_test.csv')\nsample_submission = pd.read_csv(\n    '../input/covid19-local-us-ca-forecasting-week-1/ca_submission.csv')\n\n#### Data Cleaning\n\n## 1. Drop Redundant Columns\ntrain_drop_cols = train_raw.columns[:-3]\ntest_drop_cols = test_raw.columns[1:-1]\n\ntrain = train_raw.copy().drop(train_drop_cols, axis=1)\ntest = test_raw.copy().drop(test_drop_cols, axis=1)\n\n## 2. Reindex\ntrain.index = pd.to_datetime(train['Date'])\ntrain.drop(['Date'], axis=1, inplace=True)\n\ntest.index = pd.to_datetime(test['Date'])\ntest.drop(['Date'], axis=1, inplace=True)\n\n## 3. Extract rows with confirmed cases greater 0\ntrain = train[train['ConfirmedCases'] > 0]\n\n## 4. Scale the data to values between 0 and 1\ninfections = train[['ConfirmedCases']]\nfatality = train[['Fatalities']]\n\nscaler_infections = MinMaxScaler()\n\nscaler_infections = scaler_infections.fit(infections)\n\ntrain_data_infections = scaler_infections.transform(infections)\n\nscaler_fatalities = MinMaxScaler()\n\nscaler_fatalities = scaler_fatalities.fit(fatality)\n\ntrain_data_fatalities = scaler_fatalities.transform(fatality)\n\n\n## 6. Break the large sequence into chunks of smaller sequences\n\ndef chunk_of_sequences(seq, chunk_length):\n    \"\"\"\n    Slice the input sequence into chunks of smaller sequences of equal length\n    \"\"\"\n    length_of_seq = len(seq)\n    x_chunks = []\n    y_chunks = []\n\n    for i in range(length_of_seq - chunk_length + 1):\n        x_chunks.append(seq[i:i + chunk_length])\n        y_chunks.append(seq[i + chunk_length - 1])\n\n    return np.array(x_chunks), np.array(y_chunks)\n\n\nseq_length = 5\n\n# confirmed cases\nX_train, y_train = chunk_of_sequences(train_data_infections, seq_length)\n\nX_train_confirmed = torch.from_numpy(X_train).float()\ny_train_confirmed = torch.from_numpy(y_train).float()\n\n# fatalities\nX_train, y_train = chunk_of_sequences(train_data_fatalities, seq_length)\n\nX_train_fatalities = torch.from_numpy(X_train).float()\ny_train_fatalities = torch.from_numpy(y_train).float()\n\n\n## LSTM Construction\nclass COVID19Estimator(nn.Module):\n    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim,\n                 learning_rate=1e-3, epochs=5, dropout=None, optimizer='Adam',\n                 loss_criterion='MSELoss'):\n\n        super(COVID19Estimator, self).__init__()\n\n        # hidden dimensions\n        self.hidden_dim = hidden_dim\n        # number of hidden layers\n        self.layer_dim = layer_dim\n\n        if dropout is not None:\n            self.lstm = nn.LSTM(input_dim,\n                                hidden_dim,\n                                layer_dim,\n                                batch_first=True,\n                                dropout=dropout)\n        else:\n            self.lstm = nn.LSTM(input_dim,\n                                hidden_dim,\n                                layer_dim,\n                                batch_first=True)\n\n        self.linear = nn.Linear(hidden_dim, output_dim)\n\n        self.learning_rate = learning_rate\n        self.epochs = epochs\n        self.optimizer = eval('torch.optim.' + optimizer)\n        self.criterion = eval('nn.' + loss_criterion)\n\n    def forward(self, x):\n        # initialize hidden state with zeros\n        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n\n        # initialize cell state\n        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n\n        out, (hn, cn) = self.lstm(x, (h0, c0))\n\n        return self.linear(out[:, -1, :])\n\n    def fit(self, x, y):\n        criterion = self.criterion(reduction='sum')\n        optimizer = self.optimizer(self.parameters(),\n                                   lr=self.learning_rate)\n\n        loss_hist = np.zeros(self.epochs)\n\n        for epoch in range(self.epochs):\n            optimizer.zero_grad()\n\n            outputs = self.forward(x)\n\n            loss = criterion(outputs, y)\n\n            loss.backward()\n\n            optimizer.step()\n\n            loss_hist[epoch] = loss.detach()\n\n            if epoch % 10 == 0:\n                print('Epoch {} || Train MSE Loss: {:0.4f}'.format(epoch + 1,\n                                                                   loss.detach()))\n\n        self.loss_hist = loss_hist\n\n    def predict(self, x):\n        return self.forward(x)\n\n    def loss_plot(self):\n        plt.figure(figsize=(10, 6))\n        plt.plot(self.loss_hist)\n        plt.title('MSE Loss', fontsize=25)\n        plt.xlabel('Epochs', fontsize=15)\n        plt.ylabel('Loss', fontsize=15)\n        plt.show()\n\n## Training the model\n\n### Confirmed cases\ninput_dim = 1\nhidden_dim = 256\nlayer_dim = 2\noutput_dim = 1\n\nCovidConfirmedCases = COVID19Estimator(input_dim=input_dim,\n                                       hidden_dim=hidden_dim,\n                                       layer_dim=layer_dim,\n                                       output_dim=output_dim,\n                                       epochs=400,\n                                       dropout=0.7)\n\nCovidConfirmedCases.fit(X_train_confirmed, y_train_confirmed)\nCovidConfirmedCases.loss_plot()\n\n### Fatalities\nCovidFatalities = COVID19Estimator(input_dim=input_dim,\n                                   hidden_dim=hidden_dim,\n                                   layer_dim=layer_dim,\n                                   output_dim=output_dim,\n                                   epochs=400,\n                                   dropout=0.7)\n\nCovidFatalities.fit(X_train_fatalities, y_train_fatalities)\nCovidFatalities.loss_plot()\n\n\n## Predict confirmed cases\ndate_length = len(test)\nseq_length = 2\n\ninitialize = train[['ConfirmedCases']].loc[:test.index[0]][-3:-1].values\ninitialize = scaler_infections.transform(initialize).reshape(1, -1, 1)\ninitialize = torch.from_numpy(initialize).float()\n\npredictions = []\n\nfor i in range(date_length):\n    if i == 0:\n        pred = CovidConfirmedCases.predict(initialize).view(1, -1, 1)\n        initialize[0, 0], initialize[0, 1] = initialize[0, 1], pred.detach()\n        predictions.append(pred.detach().numpy()[0, 0, 0])\n\n    else:\n        pred = CovidFatalities.predict(initialize).view(1, -1, 1)\n        initialize[0, 0], initialize[0, 1] = initialize[0, 1], pred.detach()\n        predictions.append(pred.detach().numpy()[0, 0, 0])\n\npredicted_confirmed_cases = scaler_infections.inverse_transform(\n    np.expand_dims(np.array(predictions), axis=0)).flatten().astype(np.int64)\n\n\n## Predict Fatalities\ndate_length = len(test)\nseq_length = 2\n\ninitialize = train[['Fatalities']].loc[:test.index[0]][-3:-1].values\ninitialize = scaler_fatalities.transform(initialize).reshape(1, -1, 1)\ninitialize = torch.from_numpy(initialize).float()\n\npredictions = []\n\nfor i in range(date_length):\n    if i == 0:\n        pred = CovidFatalities.predict(initialize).view(1, -1, 1)\n        initialize[0, 0], initialize[0, 1] = initialize[0, 1], pred.detach()\n        predictions.append(pred.detach().numpy()[0, 0, 0])\n\n    else:\n        pred = CovidFatalities.predict(initialize).view(1, -1, 1)\n        initialize[0, 0], initialize[0, 1] = initialize[0, 1], pred.detach()\n        predictions.append(pred.detach().numpy()[0, 0, 0])\n\npredicted_fatalities = scaler_fatalities.inverse_transform(\n    np.expand_dims(np.array(predictions), axis=0)).flatten().astype(np.int64)\n\n\n## Submission\nsubmission = pd.DataFrame({'ForecastId': test['ForecastId'],\n                           'ConfirmedCases': predicted_confirmed_cases,\n                           'Fatalities': predicted_fatalities})\n\nsubmission.index = sample_submission.index\nsubmission.head()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}