{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\nsns.set()\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Load the Data**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/covid19-local-us-ca-forecasting-week-1/ca_train.csv',parse_dates = ['Date'])\ntest = pd.read_csv('/kaggle/input/covid19-local-us-ca-forecasting-week-1/ca_test.csv')\nsubmission = pd.read_csv('/kaggle/input/covid19-local-us-ca-forecasting-week-1/ca_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **EDA FOR THE DATASET**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First Convert the Date in Train dataset for the further analysis and you can do this by using the .to_datetime function or you can use parse_date at the time of reading the csv file.as I used at the reading of the file"},{"metadata":{"trusted":true},"cell_type":"code","source":"date_data = train['Date']\nconfirmed_cases = train['ConfirmedCases']\nplt.figure(figsize=(10,8))\nplt.plot(date_data,confirmed_cases)\nplt.xticks(rotation=90)\nplt.title('Time Series Analysis for the confirmed Cases')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"date_data = train['Date']\nFatalities = train['Fatalities']\nplt.figure(figsize=(10,8))\nplt.plot(date_data,Fatalities)\nplt.xticks(rotation=90)\nplt.title('Time Series Analysis for Fatalities')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, as we can see as we incresed the confrimed_cases gov also incerased the Falaliets"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Province/State'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,5))\nsns.countplot(y = train['ConfirmedCases'])\nplt.title('Count for confirmed cases')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title('Count for confirmed cases')\nsns.distplot(train['ConfirmedCases'],kde = False,bins=20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will concentrate only those columns which having confirmed cases as greater than zero"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_new = train[train['ConfirmedCases'] > 0]\ntrain_new","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,8))\nsns.barplot(x='Date',y='ConfirmedCases',data=train_new)\nplt.xticks(rotation=45)\nplt.title('Confirmed cases as per Date')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,8))\nsns.barplot(x='Date',y='Fatalities',data=train_new)\nplt.xticks(rotation=45)\nplt.title('Confirmed Death as per Date')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Feature Engineering**"},{"metadata":{},"cell_type":"markdown","source":"**Now let's do some Feature Engineering**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_new.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_new['Week'] = train_new['Date'].dt.week\ntrain_new['Day'] = train_new['Date'].dt.day\ntrain_new['DayOfWeek'] = train_new['Date'].dt.dayofweek\ntrain_new['DayOfYear'] = train_new['Date'].dt.dayofyear\ntrain_new.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, drop the all other columns as they having the similer data and not going to hamper on our model"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = train_new[['Date','Week','Day','DayOfWeek','DayOfYear','ConfirmedCases','Fatalities']]\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It's time for using models and fitting our dataset for obtaining the results. We will use few models for the same."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression,Lasso\nfrom sklearn.linear_model import BayesianRidge\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import r2_score,roc_auc_score\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.drop(['Date','ConfirmedCases','Fatalities'],axis=1)\ny = df[['ConfirmedCases','Fatalities']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Split the train and test dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Size of X_train : {X_train.shape}')\nprint(f'Size of X_test : {X_test.shape}')\nprint(f'Size of y_train : {y_train.shape}')\nprint(f'Size of y_test : {y_test.shape}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_confirmed_cases(regression_algo):\n    r = regression_algo()\n    r.fit(X_train,y_train['ConfirmedCases'])\n    y_pred = r.predict(X_test)\n    rSquare = r2_score(y_test['ConfirmedCases'],y_pred)\n    confirmed_cases.append(rSquare)\n\ndef predict_confirmed_deths(algos):\n    r = algos()\n    r.fit(X_train,y_train['Fatalities'])\n    y_pred = r.predict(X_test)\n    rSquare = r2_score(y_test['Fatalities'],y_pred)\n    confirmed_death.append(rSquare)\n    \nmodels = [KNeighborsRegressor,LinearRegression,RandomForestRegressor,DecisionTreeRegressor,BayesianRidge,\n          GradientBoostingRegressor,Lasso]\n\nconfirmed_cases = []\nconfirmed_death = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in models:\n    predict_confirmed_cases(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for j in models:\n    predict_confirmed_deths(j)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confirmed_cases","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confirmed_death","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = pd.DataFrame({\n    'Model': [\"KNeighborsRegressor\",\"LinearRegression\",\"RandomForestRegressor\",\"DecisionTreeRegressor\",\"BayesianRidge\",\n          \"GradientBoostingRegressor\",\"Lasso\"],\n    'ConfirmedCase_r2': confirmed_cases,\n    'Fatalities_r2' : confirmed_death\n})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see in the above result by using **KNeighborsRegressor** and **GradientBoostingRegressor** we are getting best result"},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = test[['ForecastId','Date']]\ntest_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data['Date'] = pd.to_datetime(test_data['Date'])\ntest_data['Week'] = test_data['Date'].dt.week\ntest_data['Day'] = test_data['Date'].dt.day\ntest_data['DayOfWeek'] = test_data['Date'].dt.dayofweek\ntest_data['DayOfYear'] = test_data['Date'].dt.dayofyear\ntest_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create the model to fit on test dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"Kneighbour = KNeighborsRegressor()\nKneighbour.fit(X_train,y_train['ConfirmedCases'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decisiontree = GradientBoostingRegressor()\ndecisiontree.fit(X_train,y_train['Fatalities'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data['ConfirmedCases'] = Kneighbour.predict(test_data.drop(['Date','ForecastId'],axis=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data['Fatalities'] = decisiontree.predict(test_data.drop(['Date','ForecastId','ConfirmedCases'],axis=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = test_data[['ForecastId','ConfirmedCases','Fatalities']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}