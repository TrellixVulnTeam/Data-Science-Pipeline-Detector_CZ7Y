{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Week 3 Assignment - Plant Seedlings Dataset - Bimalendu Mishra","metadata":{}},{"cell_type":"markdown","source":"## Import Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport gc\n\nfrom sklearn.model_selection import train_test_split\n\nfrom tqdm import tqdm_notebook\n\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nplt.rcParams['figure.figsize'] = [16, 10]\nplt.style.use('fivethirtyeight')\n\n#Tensorflow Dependencies\n\nimport tensorflow as tf\n\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom tensorflow.keras.losses import categorical_crossentropy\nfrom tensorflow.keras.optimizers import Adam\n\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.layers import Input, Dense, Flatten, Activation, Dropout\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, GlobalAvgPool2D, BatchNormalization\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n\nfrom tensorflow.keras.applications.vgg16 import VGG16, preprocess_input as vgg_preprocess_input\nfrom tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input as resnet_preprocess_input\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input as inception_preprocess_input\n\nimport warnings\nwarnings.simplefilter('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:54:24.234355Z","iopub.execute_input":"2022-02-06T14:54:24.23471Z","iopub.status.idle":"2022-02-06T14:54:29.064415Z","shell.execute_reply.started":"2022-02-06T14:54:24.234676Z","shell.execute_reply":"2022-02-06T14:54:29.063532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading Data","metadata":{}},{"cell_type":"code","source":"def ImageReader(location, size=(224, 224)):\n    img = image.load_img(location, target_size=size)\n    img = image.img_to_array(img)\n    \n    return img\n\nclass LoadData(object):\n    \n    def __init__(self, image_size=(224, 224)):\n        \n        self.SetSeed()\n        self.image_size=image_size\n        \n        self.CATEGORIES = os.listdir(\"../input/plant-seedlings-classification/train/\")\n        self.N_CLASSES = len(self.CATEGORIES)\n        print(f\"Length of Categories : {self.N_CLASSES}\")\n        self.data_dir = \"../input/plant-seedlings-classification/\"\n        self.train_dir = os.path.join(self.data_dir, \"train\")\n        self.test_dir = os.path.join(self.data_dir, \"test\")\n        self.sub = pd.read_csv(\"../input/plant-seedlings-classification/sample_submission.csv\")\n\n        print(f\"Sub Shape : {self.sub.shape}\")\n    \n    def SetSeed(self, seed=13):\n        \n        self.seed = seed\n        np.random.seed(self.seed)\n    \n    def PlotDistribution(self, print_cat_wise=False):\n        \n        distribution = {}\n\n        for category in self.CATEGORIES:\n            num_samples = len(os.listdir(os.path.join(self.train_dir, category)))\n            distribution[category] = num_samples\n            if print_cat_wise:\n                print(f\"{category} has {num_samples} samples.\")\n\n        plt.figure(figsize=(24, 12))\n        plt.xlabel(\"Category\")\n        plt.ylabel(\"Count\")\n        plt.title(\"Target Distribution\")\n        sns.barplot(list(distribution.keys()), list(distribution.values()))\n        plt.show()\n    \n    def RetrieveData(self):\n        \n        \n        \n        self.train = []\n        self.test = []\n        self.class_names = {}\n        \n        for category_id, category in tqdm_notebook(enumerate(self.CATEGORIES)):\n            category_path = os.path.join(self.train_dir, category)\n            cur_cat_files = os.listdir(category_path)\n            cur_cat_files = [[os.path.join(category_path, i), category, category_id] for i in cur_cat_files]\n            \n            if not self.class_names.get(category):\n                self.class_names[category] = category_id\n            \n            self.train.extend(cur_cat_files)\n\n        print(f\"Total Train Samples : {len(self.train)}\")\n        self.train = pd.DataFrame(self.train, columns=['location', 'target', 'target_id'])\n        \n        for file in tqdm_notebook(os.listdir(self.test_dir)):\n            cur_item = os.path.join(self.test_dir, file)\n            self.test.append(cur_item)\n\n        print(f\"Total Test Samples : {len(self.test)}\")\n        self.test = pd.DataFrame(self.test, columns=['location'])\n        \n        self.SplitData()\n    \n    def SplitData(self):\n\n        self.train, self.valid, self.y_train, self.y_valid = train_test_split(self.train, self.train['target_id'], test_size=0.2, random_state=self.seed)\n        print(f\"Train Shape : {self.train.shape}\\nValid Shape : {self.valid.shape}\\n\")\n        \n    \n    def MakeDatagen(self, batch_size=32):\n\n        self.batch_size = batch_size\n        \n        self.train_gen = self.data_gen.flow_from_dataframe(\n            dataframe=self.train, \n            x_col='location',\n            y_col='target',\n            batch_size=self.batch_size,\n            seed=LoadData.seed,\n            shuffle=False, \n            class_mode='categorical',\n            target_size=self.image_size,\n        )\n\n        self.valid_gen = self.data_gen.flow_from_dataframe(\n            dataframe=self.valid, \n            x_col='location',\n            y_col='target',\n            batch_size=self.batch_size,\n            seed=LoadData.seed,\n            shuffle=False, \n            class_mode='categorical',\n            target_size=self.image_size,\n        )\n\n        self.test_gen = self.data_gen.flow_from_dataframe(\n            dataframe=self.test, \n            x_col='location',\n            y_col=None,\n            batch_size=1,  \n            seed=LoadData.seed,\n            shuffle=False,\n            class_mode=None,\n            target_size=self.image_size,\n        )\n\n        self.train_stepsize = self.train_gen.n // self.train_gen.batch_size\n        self.valid_stepsize = self.valid_gen.n // self.valid_gen.batch_size\n        \n        return (self.train_gen, self.train_stepsize), (self.valid_gen, self.valid_stepsize), self.test_gen\n    \n\n    \n    \n    \n    def SetDatagen(self, data_gen=ImageDataGenerator(rescale=1./255)):\n        self.data_gen = data_gen\n        \n    \n    def SetImageSize(self, image_size=(224, 224)):\n        \n        self.image_size = image_size\n        ","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:54:29.068671Z","iopub.execute_input":"2022-02-06T14:54:29.068968Z","iopub.status.idle":"2022-02-06T14:54:29.102449Z","shell.execute_reply.started":"2022-02-06T14:54:29.068938Z","shell.execute_reply":"2022-02-06T14:54:29.101312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LoadData = LoadData(image_size=(224, 224))\nLoadData.RetrieveData()\nLoadData.PlotDistribution()","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:54:29.103902Z","iopub.execute_input":"2022-02-06T14:54:29.104304Z","iopub.status.idle":"2022-02-06T14:54:29.864886Z","shell.execute_reply.started":"2022-02-06T14:54:29.104266Z","shell.execute_reply":"2022-02-06T14:54:29.863968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Modelling","metadata":{}},{"cell_type":"code","source":"class pre_trained_models(object):\n    \n    def __init__(self):\n        \n        self.model_utils = {\n            'resnet_50': {\n                'model': ResNet50,\n                'preprocessor': resnet_preprocess_input,\n            },\n            'vgg_16': {\n                'model': VGG16,\n                'preprocessor':vgg_preprocess_input,\n            },\n            'inception_v3': {\n                'model': InceptionV3,\n                'preprocessor': inception_preprocess_input,\n            },\n        }\n        \n        self.loss_history = {\n            'resnet_50': {},\n            'vgg_16': {},\n            'inception_v3': {},\n        }\n    \n    \n    def ModelTuning(self, LoadData, choice, params):\n        \n        self.params = params\n        \n        self.pre_trained_model = self.model_utils[choice]['model']\n        self.pre_trained_model_preprocessor = self.model_utils[choice]['preprocessor']\n        \n        self.datagen = ImageDataGenerator(preprocessing_function=self.pre_trained_model_preprocessor)\n        LoadData.SetDatagen(self.datagen)\n        \n        (self.train_gen, self.train_stepsize), (self.valid_gen, self.valid_stepsize), self.test_gen = LoadData.MakeDatagen(self.params['batch_size'])\n        \n       \n        \n        early_stopping = EarlyStopping(monitor='val_accuracy', mode='max', patience=3)\n        reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience=3, min_lr=0.00001)\n        \n        print(\"\\nDownloading & Compiling the model ... \")\n        self.model_name = choice\n        input_shape = (LoadData.image_size[0], LoadData.image_size[1], 3)\n        if choice == 'vgg_16':\n\n            file_path = \"best_vgg16.hdf5\"\n            checkpoint = ModelCheckpoint(file_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='auto', period=1)\n            \n           \n            VggModel16 = self.pre_trained_model(include_top=False, input_shape=input_shape)\n\n            \n            for layer in VggModel16.layers:\n                layer.trainable = False\n                \n            x = Flatten()(VggModel16.output)\n            x = Dense(512)(x)\n            x = BatchNormalization()(x)\n            x = Activation('relu')(x)\n            x = Dropout(0.8)(x)\n            x = BatchNormalization()(x)\n            x = Dense(LoadData.N_CLASSES, activation='softmax')(x)\n\n            self.model = Model(inputs=VggModel16.input, outputs=x)\n            \n        elif choice == 'resnet_50':\n\n            file_path = \"best_resnet50.hdf5\"\n            checkpoint = ModelCheckpoint(file_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='auto', period=1)\n\n            \n            ResnetModel50 = self.pre_trained_model(include_top=False, input_shape=input_shape)\n\n            for layer in ResnetModel50.layers:\n                layer.trainable = False\n\n            x = Flatten()(ResnetModel50.output)\n            x = Dense(512)(x)\n            x = BatchNormalization()(x)\n            x = Activation('relu')(x)\n            x = Dropout(0.8)(x)\n            x = BatchNormalization()(x)\n            x = Dense(LoadData.N_CLASSES, activation='softmax')(x)\n\n            self.model = Model(inputs=ResnetModel50.input, outputs=x)\n            \n        elif choice == 'inception_v3':\n            \n            file_path = \"best_inceptionv3.hdf5\" \n            checkpoint = ModelCheckpoint(file_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='auto', period=1)\n            \n        \n            ModelInception = self.pre_trained_model(include_top=False, input_shape=input_shape)\n\n            for layer in ModelInception.layers:\n                layer.trainable = False\n\n            x = Flatten()(ModelInception.output)\n            x = Dense(512)(x)\n            x = BatchNormalization()(x)\n            x = Activation('relu')(x)\n            x = Dropout(0.8)(x)\n            x = BatchNormalization()(x)\n            x = Dense(LoadData.N_CLASSES, activation='softmax')(x)\n\n            self.model = Model(inputs=ModelInception.input, outputs=x)\n            \n        else:\n            return \"Choose correct model.\"\n        \n        \n        optimizer = Adam() \n        self.model.compile(loss=categorical_crossentropy, optimizer=optimizer, metrics=['accuracy'])\n\n        print(\"Compiled.\")\n        print(f\"Fitting Model : {self.model_name} .. \", end='\\n\\n')\n        \n        hist = self.model.fit_generator(\n            generator = self.train_gen,\n            validation_data = self.valid_gen,\n            steps_per_epoch = self.train_stepsize,\n            validation_steps = self.valid_stepsize,\n            epochs = self.params['epochs'],\n            verbose = 1,\n            callbacks=[checkpoint, early_stopping, reduce_lr],\n        )\n        \n        self.loss_history[choice] = hist.history\n        \n        return self.model\n    \n    def PlotSingleMetric(self, choice):\n        \n        history = self.loss_history[choice]\n\n        epoch_range = [i+1 for i, loss in enumerate(history['loss'])]\n        xticks = range(0, max(epoch_range), 2)\n\n        max_loss = max([max(history['loss']), max(history['val_loss'])])\n        min_loss = min([min(history['loss']), min(history['val_loss'])])\n        max_acc = max([max(history['accuracy']), max(history['val_accuracy'])])\n        min_acc = min([min(history['accuracy']), min(history['val_accuracy'])])\n\n        plt.figure(figsize=(18, 7))\n\n        plt.subplot(1, 2, 1)\n        plt.plot(epoch_range, history['loss'], color='red', label='Train')\n        plt.plot(epoch_range, history['val_loss'], color='green', label='Valid')\n        plt.xticks(xticks)\n        plt.yticks(np.linspace(min_loss, max_loss, 10))\n        plt.grid(False)\n        plt.legend(loc='best')\n        plt.xlabel('Epochs')\n        plt.ylabel('Loss')\n        plt.title(f\"{self.model_name} | Loss Curve\")\n\n        plt.subplot(1, 2, 2)\n        plt.plot(epoch_range, history['accuracy'], color='red', label='Train')\n        plt.plot(epoch_range, history['val_accuracy'], color='green', label='Valid')\n        plt.xticks(xticks)\n        plt.yticks(np.linspace(min_acc, max_acc, 10))\n        plt.grid(False)\n        plt.legend(loc='best')\n        plt.xlabel('Epochs')\n        plt.ylabel('Accuracy')\n        plt.title(f\"{self.model_name} | Accuracy Curve\")\n\n        plt.tight_layout()\n        plt.show()\n        \n    def plot_multiple_metric(self):\n        \n        history_1 = self.loss_history['vgg_16']\n        history_2 = self.loss_history['resnet_50']\n        history_3 = self.loss_history['inception_v3']\n\n        epoch_range = [i+1 for i, loss in enumerate(history_1['loss'])]\n        xticks = range(0, max(epoch_range), 2)\n\n        plt.figure(figsize=(18, 18))\n\n        \n        plt.subplot(2, 1, 1)\n        plt.plot(epoch_range, history_1['val_loss'], color='red', label='VGG-16')\n        plt.plot(epoch_range, history_2['val_loss'], color='green', label='Resnet-50')\n        plt.plot(epoch_range, history_3['val_loss'], color='purple', label='Inception-v3')\n        plt.xticks(xticks)\n        plt.grid(False)\n        plt.legend(loc='best')\n        plt.xlabel('Epochs')\n        plt.ylabel('Loss')\n        plt.title(f\"Validation Loss Comparision\")\n\n        \n        plt.subplot(2, 1, 2)\n        plt.plot(epoch_range, history_1['val_accuracy'], color='red', label='VGG-16')\n        plt.plot(epoch_range, history_2['val_accuracy'], color='green', label='Resnet-50')\n        plt.plot(epoch_range, history_3['val_accuracy'], color='purple', label='Inception-v3')\n        plt.xticks(xticks)\n        plt.grid(False)\n        plt.legend(loc='best')\n        plt.xlabel('Epochs')\n        plt.ylabel('Accuracy')\n        plt.title(f\"Validation Accuracy Comparision\")\n\n        plt.tight_layout()\n        plt.show()\n        \n    def plot_confusion_matrix(self, LoadData, model, model_name):\n        \n        y_pred = model.predict_generator(LoadData.valid_gen)\n        y_pred = np.argmax(y_pred, axis=1)\n\n        con_mat = tf.math.confusion_matrix(labels=LoadData.valid_gen.classes, predictions=y_pred).numpy()\n        con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n        con_mat_df = pd.DataFrame(con_mat_norm,\n                             index = list(LoadData.class_names.keys()), \n                             columns = list(LoadData.class_names.keys()))\n\n        fig = plt.figure(figsize=(16, 16))\n        sns.heatmap(con_mat_df, annot=True, cmap=plt.cm.Blues)\n        plt.tight_layout()\n        plt.ylabel('True label')\n        plt.xlabel('Predicted label')\n        plt.title(f'{model_name} Confusion Matrix')\n\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:54:29.866564Z","iopub.execute_input":"2022-02-06T14:54:29.86717Z","iopub.status.idle":"2022-02-06T14:54:29.924416Z","shell.execute_reply.started":"2022-02-06T14:54:29.86713Z","shell.execute_reply":"2022-02-06T14:54:29.923694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {\n    'batch_size': 128,\n    'epochs': 10,\n}","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:54:29.927717Z","iopub.execute_input":"2022-02-06T14:54:29.928078Z","iopub.status.idle":"2022-02-06T14:54:29.937001Z","shell.execute_reply.started":"2022-02-06T14:54:29.928023Z","shell.execute_reply":"2022-02-06T14:54:29.936008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TransModels = pre_trained_models()","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:54:29.938698Z","iopub.execute_input":"2022-02-06T14:54:29.939159Z","iopub.status.idle":"2022-02-06T14:54:29.944587Z","shell.execute_reply.started":"2022-02-06T14:54:29.939122Z","shell.execute_reply":"2022-02-06T14:54:29.943611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inception Model","metadata":{}},{"cell_type":"code","source":"ModelInception = TransModels.ModelTuning(LoadData=LoadData, choice='inception_v3', params=params)\nTransModels.PlotSingleMetric(choice='inception_v3')\nTransModels.plot_confusion_matrix(LoadData=LoadData, model=ModelInception, model_name='inception_v3')","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:54:29.945974Z","iopub.execute_input":"2022-02-06T14:54:29.947006Z","iopub.status.idle":"2022-02-06T15:06:59.949167Z","shell.execute_reply.started":"2022-02-06T14:54:29.946977Z","shell.execute_reply":"2022-02-06T15:06:59.948149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ModelInception.save(\"inception_v3.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-02-06T15:06:59.950701Z","iopub.execute_input":"2022-02-06T15:06:59.951228Z","iopub.status.idle":"2022-02-06T15:07:01.275832Z","shell.execute_reply.started":"2022-02-06T15:06:59.951186Z","shell.execute_reply":"2022-02-06T15:07:01.274988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## VGG Model","metadata":{}},{"cell_type":"code","source":"VggModel = TransModels.ModelTuning(LoadData=LoadData, choice='vgg_16', params=params)\nTransModels.PlotSingleMetric(choice='vgg_16')\nTransModels.plot_confusion_matrix(LoadData=LoadData, model=VggModel, model_name='vgg_16')","metadata":{"execution":{"iopub.status.busy":"2022-02-06T15:07:01.277274Z","iopub.execute_input":"2022-02-06T15:07:01.277704Z","iopub.status.idle":"2022-02-06T15:18:45.605047Z","shell.execute_reply.started":"2022-02-06T15:07:01.277661Z","shell.execute_reply":"2022-02-06T15:18:45.604125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"VggModel.save(\"vgg_16.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-02-06T15:18:45.606493Z","iopub.execute_input":"2022-02-06T15:18:45.607055Z","iopub.status.idle":"2022-02-06T15:18:46.008536Z","shell.execute_reply.started":"2022-02-06T15:18:45.607012Z","shell.execute_reply":"2022-02-06T15:18:46.007687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ResNet Model","metadata":{}},{"cell_type":"code","source":"ResnetModel = TransModels.ModelTuning(LoadData=LoadData, choice='resnet_50', params=params)\nTransModels.PlotSingleMetric(choice='resnet_50')\nTransModels.plot_confusion_matrix(LoadData=LoadData, model=ResnetModel, model_name='resnet_50')","metadata":{"execution":{"iopub.status.busy":"2022-02-06T15:18:46.009784Z","iopub.execute_input":"2022-02-06T15:18:46.01011Z","iopub.status.idle":"2022-02-06T15:30:43.571955Z","shell.execute_reply.started":"2022-02-06T15:18:46.010075Z","shell.execute_reply":"2022-02-06T15:30:43.571067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ResnetModel.save(\"resnet_50.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-02-06T15:30:43.573302Z","iopub.execute_input":"2022-02-06T15:30:43.573923Z","iopub.status.idle":"2022-02-06T15:30:45.236246Z","shell.execute_reply.started":"2022-02-06T15:30:43.573873Z","shell.execute_reply":"2022-02-06T15:30:45.235434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Multiple Plots","metadata":{}},{"cell_type":"code","source":"TransModels.plot_multiple_metric()","metadata":{"execution":{"iopub.status.busy":"2022-02-06T15:30:45.23765Z","iopub.execute_input":"2022-02-06T15:30:45.237976Z","iopub.status.idle":"2022-02-06T15:30:45.627285Z","shell.execute_reply.started":"2022-02-06T15:30:45.237941Z","shell.execute_reply":"2022-02-06T15:30:45.626427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### It can be clearly seen that ResNet turns out to be the best model, followed by VGG and then followed by Inception","metadata":{"execution":{"iopub.status.busy":"2022-02-06T14:17:45.45393Z","iopub.execute_input":"2022-02-06T14:17:45.454334Z","iopub.status.idle":"2022-02-06T14:17:45.459585Z","shell.execute_reply.started":"2022-02-06T14:17:45.454298Z","shell.execute_reply":"2022-02-06T14:17:45.458475Z"}}},{"cell_type":"markdown","source":"# Thank You","metadata":{}}]}