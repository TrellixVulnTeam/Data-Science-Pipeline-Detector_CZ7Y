{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Transfer Learning On Plant Seedlings Dataset**\n\n\n\n---\n\nThis notebook is laid out as follows:\n\n\n\n1.   **Part 1:** Loading,Transforming and One Hot Encoding \n2.   **Part 2:** Data Augmentation\n3.  **Part 3:** Using Pre Trained models(Includes Saving and Loading)\n\n\n","metadata":{"id":"JCJeXYHH32z9"}},{"cell_type":"markdown","source":"## **Part 1: Loading,Transforming and One Hot Encoding**\n","metadata":{"id":"zedj0tKj38Rn"}},{"cell_type":"code","source":"import os\nimport fnmatch\nimport os\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.applications.inception_v3 import preprocess_input\nfrom keras.applications.resnet50 import preprocess_input\nfrom keras.preprocessing import image\nnp.random.seed(21)\n\n\n\nimport tensorflow as tf\nfrom keras.layers import Conv2D,MaxPooling2D,Flatten,Dense,BatchNormalization,Activation,Dropout,GlobalAveragePooling2D\nfrom keras.models import Sequential,Model\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.optimizers import Adam\n\n\na = '/kaggle/input/plant-seedlings-classification'\n\nprint(os.listdir(os.path.join(a,'train')))","metadata":{"id":"3nX4FkHzur5W","outputId":"6f52d6a1-0f6d-4659-a24a-97ef646a9a41","execution":{"iopub.status.busy":"2021-09-26T14:44:08.798297Z","iopub.execute_input":"2021-09-26T14:44:08.798596Z","iopub.status.idle":"2021-09-26T14:44:13.663109Z","shell.execute_reply.started":"2021-09-26T14:44:08.798566Z","shell.execute_reply":"2021-09-26T14:44:13.661595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"    from sklearn.metrics import accuracy_score\n","metadata":{"execution":{"iopub.status.busy":"2021-09-26T14:44:16.086222Z","iopub.execute_input":"2021-09-26T14:44:16.086556Z","iopub.status.idle":"2021-09-26T14:44:16.169053Z","shell.execute_reply.started":"2021-09-26T14:44:16.086524Z","shell.execute_reply":"2021-09-26T14:44:16.168225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_train_data(root):\n    \n    \"\"\"Performs required pre processing on the input images and fetches data\n\n    Args:\n      root: Directory in which we are working\n\n    Returns: \n      train_img: A numpy array consisting of train images\n      train_y : A OHE numpy array of train labels\n    \"\"\"\n    train_dir = (os.path.join(root,'train'))\n    train_label = []\n    train_img = []\n    label2num = {'Loose Silky-bent':0, 'Charlock':1, 'Sugar beet':2, 'Small-flowered Cranesbill':3,\n                 'Common Chickweed':4, 'Common wheat':5, 'Maize':6, 'Cleavers':7, 'Scentless Mayweed':8,\n                 'Fat Hen':9, 'Black-grass':10, 'Shepherds Purse':11}\n    for i in os.listdir(train_dir):\n        label_number = label2num[i]\n        new_path = os.path.join(train_dir,i)\n        for j in fnmatch.filter(os.listdir(new_path), '*.png'):\n            temp_img = image.load_img(os.path.join(new_path,j), target_size=(128,128))\n            train_label.append(label_number)\n            temp_img = image.img_to_array(temp_img)\n            train_img.append(temp_img)\n        print(i)\n    train_img = np.array(train_img)\n\n    train_y=pd.get_dummies(train_label)\n    train_y = np.array(train_y)\n    train_img=preprocess_input(train_img)\n    \n    return train_img,train_y\n\n","metadata":{"id":"Ec4CE8p7ur5e","outputId":"093d9058-bcf1-4143-d596-92424819f3e8","execution":{"iopub.status.busy":"2021-09-26T14:44:17.40258Z","iopub.execute_input":"2021-09-26T14:44:17.402935Z","iopub.status.idle":"2021-09-26T14:44:17.415013Z","shell.execute_reply.started":"2021-09-26T14:44:17.402902Z","shell.execute_reply":"2021-09-26T14:44:17.413945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_img,train_y = get_train_data(a)\nprint('Training data shape: ', train_img.shape)\nprint('Training labels shape: ', train_y.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-26T14:44:21.051227Z","iopub.execute_input":"2021-09-26T14:44:21.051597Z","iopub.status.idle":"2021-09-26T14:46:12.172447Z","shell.execute_reply.started":"2021-09-26T14:44:21.051566Z","shell.execute_reply":"2021-09-26T14:46:12.170936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_valid, Y_train, Y_valid=train_test_split(train_img,train_y,test_size=0.1, random_state=42)","metadata":{"id":"ES-0H8qO6Gez","execution":{"iopub.status.busy":"2021-09-26T14:47:10.187614Z","iopub.execute_input":"2021-09-26T14:47:10.187979Z","iopub.status.idle":"2021-09-26T14:47:10.850819Z","shell.execute_reply.started":"2021-09-26T14:47:10.187946Z","shell.execute_reply":"2021-09-26T14:47:10.849836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Part 2: Data Augmentation**\n","metadata":{"id":"WoGyR5vZ4WPY"}},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(\n        rotation_range=30,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=True)  # randomly flip images\n\ndatagen.fit(X_train)\n","metadata":{"id":"qOEtFGPGur5n","execution":{"iopub.status.busy":"2021-09-26T14:47:14.127426Z","iopub.execute_input":"2021-09-26T14:47:14.127807Z","iopub.status.idle":"2021-09-26T14:47:14.44297Z","shell.execute_reply.started":"2021-09-26T14:47:14.127773Z","shell.execute_reply":"2021-09-26T14:47:14.442151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Part 3- Transfer Learing**","metadata":{"id":"mdbs0dS-5UdZ"}},{"cell_type":"markdown","source":"### **1) VGG-16**","metadata":{"id":"yzqgD_qR5Z1O"}},{"cell_type":"markdown","source":"#### **Customizing VGG-16 for our problem statement**","metadata":{"id":"HZYZHXsKxWMZ"}},{"cell_type":"code","source":"def vgg16_model(num_classes=None):\n    \n    \"\"\" Adding custom model to the VGG-16\n\n    Args:\n      num_classes: Number of layers in the final layer(Number of classes)\n\n    Returns:\n      model: Returns the custom model added to VGG\n    \"\"\"\n\n    model = VGG16(weights='imagenet', include_top=False,input_shape=(128,128,3))\n    model.layers.pop()\n    model.layers.pop()\n    model.layers.pop()\n\n    model.outputs = [model.layers[-1].output]\n\n    #model.layers[-2].outbound_node= []\n    x=Conv2D(256, kernel_size=(2,2),strides=2)(model.output)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)    \n    x=Conv2D(128, kernel_size=(2,2),strides=1)(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x=Flatten()(x)\n    x=Dense(num_classes, activation='softmax')(x)\n\n    model=Model(model.input,x)\n\n    for layer in model.layers[:15]:\n\n        layer.trainable = False\n\n\n    return model","metadata":{"id":"Mlm_XoCaMPad","execution":{"iopub.status.busy":"2021-09-26T14:48:41.488124Z","iopub.execute_input":"2021-09-26T14:48:41.488525Z","iopub.status.idle":"2021-09-26T14:48:41.499128Z","shell.execute_reply.started":"2021-09-26T14:48:41.488494Z","shell.execute_reply":"2021-09-26T14:48:41.498027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.applications.vgg16 import VGG16\nfrom keras import backend as K\nnum_classes=12\nmodel = vgg16_model(num_classes)\nmodel.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()","metadata":{"id":"02gjBdA9i9H7","outputId":"eb6835f8-b807-4080-9635-d4adf9d5b400","execution":{"iopub.status.busy":"2021-09-26T14:48:44.920454Z","iopub.execute_input":"2021-09-26T14:48:44.920772Z","iopub.status.idle":"2021-09-26T14:48:47.872165Z","shell.execute_reply.started":"2021-09-26T14:48:44.92074Z","shell.execute_reply":"2021-09-26T14:48:47.871401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Training VGG-16**","metadata":{"id":"azFmM8N0xOZ3"}},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint\nepochs = 10\nbatch_size = 32\nmodel_checkpoint = ModelCheckpoint('vgg_weights.h5', monitor='val_accuracy', save_best_only=True,mode='max',verbose=1)\nreduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=7, min_lr=0.000001)\n#early_stop = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=7, verbose=0, mode='min', restore_best_weights=True)\n\nmodel.fit(datagen.flow(X_train,Y_train),\n          batch_size=128,\n          epochs=20,\n          verbose=1, shuffle=True, validation_data=(X_valid,Y_valid), callbacks=[model_checkpoint,reduce_lr])","metadata":{"id":"gnqrJ7vejYq4","outputId":"716a5d98-3ca1-4842-c48b-22319c19c2a1","execution":{"iopub.status.busy":"2021-09-26T14:51:49.974072Z","iopub.execute_input":"2021-09-26T14:51:49.97441Z","iopub.status.idle":"2021-09-26T14:57:41.38199Z","shell.execute_reply.started":"2021-09-26T14:51:49.974379Z","shell.execute_reply":"2021-09-26T14:57:41.381247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.style.use('seaborn')\n\n# Accuracy History\ndef accuracy_curves(m):\n    \"\"\" Plots the Train and validation Accuracy Curves\n\n    Args:\n      m: Model for which the curves are plotted\n\n    Returns:\n      \n    \"\"\"\n    \n    plt.figure(1, figsize=(16, 10))\n    plt.plot(m.history.history['accuracy'])\n    plt.plot(m.history.history['val_accuracy'])\n    plt.title('Train and Validation Accuracy', fontsize = 16)\n    plt.ylabel('Accuracy', fontsize = 14)\n    plt.xlabel('Epoch', fontsize = 14)\n    plt.legend(['Train', 'Test'], fontsize = 14)\n    plt.show()\n    \n# Loss History\n\ndef loss_curves(m):\n    \"\"\" Plots the Train and validation Loss Curves\n\n    Args:\n      m: Model for which the curves are plotted\n\n    Returns:\n      \n    \"\"\"\n    plt.figure(2, figsize=(16, 10))\n    plt.plot(m.history.history['loss'])\n    plt.plot(m.history.history['val_loss'])\n    plt.title('Train and Validation Loss', fontsize = 16)\n    plt.ylabel('Loss', fontsize = 14)\n    plt.xlabel('Epoch', fontsize = 14)\n    plt.legend(['Train', 'Test'], fontsize = 14)\n    plt.show()\n\n    \nfrom sklearn.metrics import classification_report\n\ndef class_report(m):\n    \"\"\" Creates  Classification Report \n\n    Args:\n      m: Model for which the report is generated\n\n    Returns:\n      \n    \"\"\"\n    target_names = os.listdir(os.path.join(a,'train'))\n    print(classification_report(Y_valid.argmax(axis=1), m.predict(X_valid).argmax(axis=1), target_names=target_names))\n    \n    \nfrom sklearn.metrics import confusion_matrix\n\ndef conf_matrix(m):\n    \"\"\" Creates  Confusion Matrix \n\n    Args:\n      m: Model for which the confusion matrix is generated\n\n    Returns:\n      \n    \"\"\"\n    target_names = os.listdir(os.path.join(a,'train'))\n    cf_matrix = confusion_matrix(Y_valid.argmax(axis=1), np.round(m.predict(X_valid).argmax(axis=1),0))\n    plt.figure(figsize=(20,20))\n    sns.heatmap(cf_matrix/100, annot=True, xticklabels=target_names, yticklabels=target_names, cmap='Blues')","metadata":{"execution":{"iopub.status.busy":"2021-09-26T14:58:12.316088Z","iopub.execute_input":"2021-09-26T14:58:12.316437Z","iopub.status.idle":"2021-09-26T14:58:12.332884Z","shell.execute_reply.started":"2021-09-26T14:58:12.316402Z","shell.execute_reply":"2021-09-26T14:58:12.331866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Visualizing Loss and Accuracy(VGG-16)**","metadata":{"id":"EmPZDpNfw4Kf"}},{"cell_type":"code","source":"accuracy_curves(model)","metadata":{"id":"g4iiQWm9wCwS","outputId":"19698726-010c-4a16-ce02-fb57f422c06a","execution":{"iopub.status.busy":"2021-09-26T14:58:15.057445Z","iopub.execute_input":"2021-09-26T14:58:15.057765Z","iopub.status.idle":"2021-09-26T14:58:15.269294Z","shell.execute_reply.started":"2021-09-26T14:58:15.057733Z","shell.execute_reply":"2021-09-26T14:58:15.268589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_curves(model)","metadata":{"id":"4IlLjr-lwnl2","outputId":"23555b1f-62b8-48ca-80d4-48327b0175f1","execution":{"iopub.status.busy":"2021-09-26T14:58:17.129759Z","iopub.execute_input":"2021-09-26T14:58:17.130131Z","iopub.status.idle":"2021-09-26T14:58:17.315591Z","shell.execute_reply.started":"2021-09-26T14:58:17.1301Z","shell.execute_reply":"2021-09-26T14:58:17.314687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Classification Report**","metadata":{"id":"rauWFtlExj4g"}},{"cell_type":"code","source":"class_report(model)","metadata":{"id":"ZDJhC0-kwxjh","outputId":"09a0175c-e862-4e13-f9ec-552feee3742e","execution":{"iopub.status.busy":"2021-09-26T14:58:22.493938Z","iopub.execute_input":"2021-09-26T14:58:22.494303Z","iopub.status.idle":"2021-09-26T14:58:23.408883Z","shell.execute_reply.started":"2021-09-26T14:58:22.494273Z","shell.execute_reply":"2021-09-26T14:58:23.407955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Confusion matrix**","metadata":{"id":"CR3HwtSGy5uO"}},{"cell_type":"code","source":"conf_matrix(model)","metadata":{"id":"jLxAYeDQyNhA","outputId":"10f31fb0-b8fe-401f-8490-94cfb6849c8e","execution":{"iopub.status.busy":"2021-09-26T14:58:26.051791Z","iopub.execute_input":"2021-09-26T14:58:26.052169Z","iopub.status.idle":"2021-09-26T14:58:27.056669Z","shell.execute_reply.started":"2021-09-26T14:58:26.052139Z","shell.execute_reply":"2021-09-26T14:58:27.055757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Model Optimization Using TF-Lite(Post Training Dynamic range quantization) ","metadata":{}},{"cell_type":"code","source":"import pathlib","metadata":{"execution":{"iopub.status.busy":"2021-09-26T14:58:30.842337Z","iopub.execute_input":"2021-09-26T14:58:30.842671Z","iopub.status.idle":"2021-09-26T14:58:30.84696Z","shell.execute_reply.started":"2021-09-26T14:58:30.84264Z","shell.execute_reply":"2021-09-26T14:58:30.845935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tflite_models_dir = pathlib.Path(os.path.join(os.getcwd(),'tflite_models'))\ntflite_models_dir.mkdir(exist_ok=True, parents=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-26T14:58:35.739811Z","iopub.execute_input":"2021-09-26T14:58:35.74019Z","iopub.status.idle":"2021-09-26T14:58:35.745429Z","shell.execute_reply.started":"2021-09-26T14:58:35.740159Z","shell.execute_reply":"2021-09-26T14:58:35.744244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"converter_vgg = tf.lite.TFLiteConverter.from_keras_model(model)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-26T14:58:43.24379Z","iopub.execute_input":"2021-09-26T14:58:43.244136Z","iopub.status.idle":"2021-09-26T14:58:43.32938Z","shell.execute_reply.started":"2021-09-26T14:58:43.244104Z","shell.execute_reply":"2021-09-26T14:58:43.32834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert to TF Lite without quantization\nvgg16_tflite_file = tflite_models_dir/\"vgg16.tflite\"\nvgg16_tflite_file.write_bytes(converter_vgg.convert())","metadata":{"execution":{"iopub.status.busy":"2021-09-26T14:58:45.295625Z","iopub.execute_input":"2021-09-26T14:58:45.295967Z","iopub.status.idle":"2021-09-26T14:58:51.049436Z","shell.execute_reply.started":"2021-09-26T14:58:45.295935Z","shell.execute_reply":"2021-09-26T14:58:51.048652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"interpreter = tf.lite.Interpreter(model_path='./tflite_models/vgg16.tflite')\ninput_type = interpreter.get_input_details()[0]['dtype']\nprint('input: ', input_type)\noutput_type = interpreter.get_output_details()[0]['dtype']\nprint('output: ', output_type)","metadata":{"execution":{"iopub.status.busy":"2021-09-26T14:58:51.051588Z","iopub.execute_input":"2021-09-26T14:58:51.051991Z","iopub.status.idle":"2021-09-26T14:58:51.093796Z","shell.execute_reply.started":"2021-09-26T14:58:51.051946Z","shell.execute_reply":"2021-09-26T14:58:51.092818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_tflite_model(tflite_file, test_image_indices):\n    global X_valid\n\n  # Initialize the interpreter\n    interpreter = tf.lite.Interpreter(model_path=str(tflite_file))\n    interpreter.allocate_tensors()\n\n    input_details = interpreter.get_input_details()[0]\n    output_details = interpreter.get_output_details()[0]\n\n    predictions = np.zeros((len(test_image_indices),), dtype=int)\n    for i, test_image_index in enumerate(test_image_indices):\n        test_image = X_valid[test_image_index]\n        test_label = Y_valid[test_image_index]\n\n        test_image = np.expand_dims(test_image, axis=0).astype(input_details[\"dtype\"])\n        interpreter.set_tensor(input_details[\"index\"], test_image)\n        interpreter.invoke()\n        output = interpreter.get_tensor(output_details[\"index\"])[0]\n\n        predictions[i] = output.argmax()\n\n    return predictions","metadata":{"execution":{"iopub.status.busy":"2021-09-26T14:58:55.655489Z","iopub.execute_input":"2021-09-26T14:58:55.655814Z","iopub.status.idle":"2021-09-26T14:58:55.664966Z","shell.execute_reply.started":"2021-09-26T14:58:55.655784Z","shell.execute_reply":"2021-09-26T14:58:55.6638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate_model(tflite_file, model_type):\n    global X_valid\n    global Y_valid\n\n    test_image_indices = range(X_valid.shape[0])\n    predictions = run_tflite_model(tflite_file, test_image_indices)\n    \n    predictions=pd.get_dummies(predictions)\n    predictions = np.array(predictions)\n    #print(predictions)\n    \n    accuracy = accuracy_score(y_true=Y_valid, y_pred=predictions) \n\n    #accuracy = (np.sum(Y_valid== predictions) * 100) / len(X_valid)\n\n    return accuracy","metadata":{"execution":{"iopub.status.busy":"2021-09-26T14:58:56.675159Z","iopub.execute_input":"2021-09-26T14:58:56.675483Z","iopub.status.idle":"2021-09-26T14:58:56.681504Z","shell.execute_reply.started":"2021-09-26T14:58:56.675453Z","shell.execute_reply":"2021-09-26T14:58:56.680646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"op = evaluate_model(vgg16_tflite_file, model_type=\"Float\")\nprint(\"Accuracy of TFLite - VGG : {}\".format(op))","metadata":{"execution":{"iopub.status.busy":"2021-09-26T14:58:57.300049Z","iopub.execute_input":"2021-09-26T14:58:57.300489Z","iopub.status.idle":"2021-09-26T15:00:06.520064Z","shell.execute_reply.started":"2021-09-26T14:58:57.300448Z","shell.execute_reply":"2021-09-26T15:00:06.518541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Optimization of VGG Model with TensorRT","metadata":{}},{"cell_type":"code","source":"from tensorflow.python.compiler.tensorrt import trt_convert as trt\n","metadata":{"execution":{"iopub.status.busy":"2021-09-26T15:00:11.122086Z","iopub.execute_input":"2021-09-26T15:00:11.122413Z","iopub.status.idle":"2021-09-26T15:00:11.128127Z","shell.execute_reply.started":"2021-09-26T15:00:11.122382Z","shell.execute_reply":"2021-09-26T15:00:11.126916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('vgg_saved_model')","metadata":{"execution":{"iopub.status.busy":"2021-09-26T15:00:11.70311Z","iopub.execute_input":"2021-09-26T15:00:11.703462Z","iopub.status.idle":"2021-09-26T15:00:14.340107Z","shell.execute_reply.started":"2021-09-26T15:00:11.70343Z","shell.execute_reply":"2021-09-26T15:00:14.339078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Converting to TF-TRT FP32...')\nconversion_params = trt.DEFAULT_TRT_CONVERSION_PARAMS._replace(precision_mode=trt.TrtPrecisionMode.FP32,\n                                                               max_workspace_size_bytes=8000000000)\n\nconverter = trt.TrtGraphConverterV2(input_saved_model_dir='vgg_saved_model',\n                                    conversion_params=conversion_params)\nconverter.convert()\nconverter.save(output_saved_model_dir='vgg_saved_model_TFTRT_FP32')\nprint('Done Converting to TF-TRT FP32')","metadata":{"execution":{"iopub.status.busy":"2021-09-26T15:00:14.347421Z","iopub.execute_input":"2021-09-26T15:00:14.352761Z","iopub.status.idle":"2021-09-26T15:00:22.289874Z","shell.execute_reply.started":"2021-09-26T15:00:14.352717Z","shell.execute_reply":"2021-09-26T15:00:22.288175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!saved_model_cli show --all --dir vgg_saved_model_TFTRT_FP32","metadata":{"execution":{"iopub.status.busy":"2021-09-26T15:00:22.291307Z","iopub.execute_input":"2021-09-26T15:00:22.291675Z","iopub.status.idle":"2021-09-26T15:00:31.287905Z","shell.execute_reply.started":"2021-09-26T15:00:22.291633Z","shell.execute_reply":"2021-09-26T15:00:31.287028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 8\nbatched_input = np.zeros((batch_size, 128, 128, 3), dtype=np.float32)\n\nfor i in range(batch_size):\n    img_path = '../input/plant-seedlings-classification/train/Common Chickweed'\n    for j in os.listdir(img_path):\n        img = image.load_img(os.path.join(img_path,j), target_size=(128, 128))\n        x = image.img_to_array(img)\n        x = np.expand_dims(x, axis=0)\n        x = preprocess_input(x)\n        batched_input[i, :] = x\nbatched_input = tf.constant(batched_input)\nprint('batched_input shape: ', batched_input.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-26T15:00:31.291919Z","iopub.execute_input":"2021-09-26T15:00:31.292213Z","iopub.status.idle":"2021-09-26T15:00:55.641121Z","shell.execute_reply.started":"2021-09-26T15:00:31.292182Z","shell.execute_reply":"2021-09-26T15:00:55.640169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time","metadata":{"execution":{"iopub.status.busy":"2021-09-26T15:00:55.642704Z","iopub.execute_input":"2021-09-26T15:00:55.643274Z","iopub.status.idle":"2021-09-26T15:00:55.6476Z","shell.execute_reply.started":"2021-09-26T15:00:55.643229Z","shell.execute_reply":"2021-09-26T15:00:55.646765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def benchmark_tftrt(input_saved_model):\n    saved_model_loaded = tf.saved_model.load(input_saved_model, tags=[tag_constants.SERVING])\n    infer = saved_model_loaded.signatures['serving_default']\n\n    N_warmup_run = 50\n    N_run = 500\n    elapsed_time = []\n\n    for i in range(N_warmup_run):\n        labeling = infer(batched_input)\n\n    for i in range(N_run):\n        start_time = time.time()\n        labeling = infer(batched_input)\n        #prob = labeling['probs'].numpy()\n        end_time = time.time()\n        elapsed_time = np.append(elapsed_time, end_time - start_time)\n        if i % 50 == 0:\n            print('Step {}: {:4.1f}ms'.format(i, (elapsed_time[-50:].mean()) * 1000))\n\n    print('Throughput: {:.0f} images/s'.format(N_run * batch_size / elapsed_time.sum()))","metadata":{"execution":{"iopub.status.busy":"2021-09-26T15:01:07.450534Z","iopub.execute_input":"2021-09-26T15:01:07.450869Z","iopub.status.idle":"2021-09-26T15:01:07.459727Z","shell.execute_reply.started":"2021-09-26T15:01:07.450816Z","shell.execute_reply":"2021-09-26T15:01:07.45886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **2) ResNet50**","metadata":{"id":"gj-z1rfE04OS"}},{"cell_type":"markdown","source":"#### **Customizing ResNet50 for our problem statement**","metadata":{"id":"eRu8qanN0-uG"}},{"cell_type":"code","source":"def resnet_model(num_classes=None):\n    \n    \"\"\" Adding custom model to the ResNet50\n\n    Args:\n      num_classes: Number of layers in the final layer(Number of classes)\n\n    Returns:\n      model: Returns the custom model added to ResNet\n    \"\"\"\n\n    model = ResNet50(weights='imagenet', include_top=False,input_shape=(128,128,3))\n    model.layers.pop()\n    #model.layers.pop()\n    #model.layers.pop()\n\n    model.outputs = [model.layers[-1].output]\n\n    #model.layers[-2].outbound_node= []\n    x=Conv2D(256, kernel_size=(2,2),strides=2)(model.output)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)    \n    x=Conv2D(128, kernel_size=(2,2),strides=1)(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x=Flatten()(x)\n    x=Dense(num_classes, activation='softmax')(x)\n\n    model=Model(model.input,x)\n\n    for layer in model.layers[:15]:\n\n        layer.trainable = False\n\n\n    return model","metadata":{"id":"ZCCs5p1g1hQk","execution":{"iopub.status.busy":"2021-09-26T15:01:35.000447Z","iopub.execute_input":"2021-09-26T15:01:35.000853Z","iopub.status.idle":"2021-09-26T15:01:35.011502Z","shell.execute_reply.started":"2021-09-26T15:01:35.000803Z","shell.execute_reply":"2021-09-26T15:01:35.010225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.applications.resnet50 import ResNet50\nfrom keras import backend as K\nnum_classes=12\nmodel_res = resnet_model(num_classes)\nmodel_res.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\nmodel_res.summary()","metadata":{"id":"tHLHJob04XwU","outputId":"753789b0-d4ec-4766-ef84-d585d939a4a1","execution":{"iopub.status.busy":"2021-09-26T15:01:35.538532Z","iopub.execute_input":"2021-09-26T15:01:35.538883Z","iopub.status.idle":"2021-09-26T15:01:38.930491Z","shell.execute_reply.started":"2021-09-26T15:01:35.538849Z","shell.execute_reply":"2021-09-26T15:01:38.929406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Training ResNet50**","metadata":{"id":"XDRnWf1w4tJn"}},{"cell_type":"code","source":"epochs = 10\nbatch_size = 32\nmodel_checkpoint = ModelCheckpoint('resnet_weights.h5', monitor='val_accuracy', save_best_only=True,mode='max',verbose=1)\nreduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=7, min_lr=0.000001)\n#early_stop = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=7, verbose=0, mode='min', restore_best_weights=True)\n\nmodel_res.fit(datagen.flow(X_train,Y_train),\n          batch_size=128,\n          epochs=20,\n          verbose=1, shuffle=True, validation_data=(X_valid,Y_valid), callbacks=[model_checkpoint,reduce_lr])","metadata":{"id":"ZR4N1zH63wpd","outputId":"672d1bcd-19a6-4877-e7b9-15960d18c181","execution":{"iopub.status.busy":"2021-09-26T15:01:46.939083Z","iopub.execute_input":"2021-09-26T15:01:46.939412Z","iopub.status.idle":"2021-09-26T15:08:45.158639Z","shell.execute_reply.started":"2021-09-26T15:01:46.939381Z","shell.execute_reply":"2021-09-26T15:08:45.157769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Visualizing Loss and Accuracy(ResNet50)**","metadata":{"id":"sUz9LGG465lC"}},{"cell_type":"code","source":"accuracy_curves(model_res)","metadata":{"id":"nQenbceb4_vu","outputId":"cd6b2fb7-80e1-4d83-da53-531e2ebbcbe6","execution":{"iopub.status.busy":"2021-09-26T15:08:49.522653Z","iopub.execute_input":"2021-09-26T15:08:49.523027Z","iopub.status.idle":"2021-09-26T15:08:49.733861Z","shell.execute_reply.started":"2021-09-26T15:08:49.522994Z","shell.execute_reply":"2021-09-26T15:08:49.732954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_curves(model_res)","metadata":{"id":"6aM-Raym7E3-","outputId":"c3eae56a-8517-490c-c98d-ec40dfc718e6","execution":{"iopub.status.busy":"2021-09-26T15:08:53.754733Z","iopub.execute_input":"2021-09-26T15:08:53.755102Z","iopub.status.idle":"2021-09-26T15:08:53.927013Z","shell.execute_reply.started":"2021-09-26T15:08:53.75507Z","shell.execute_reply":"2021-09-26T15:08:53.926093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Classification Report**","metadata":{"id":"FKXfGMqh7Z4h"}},{"cell_type":"code","source":"class_report(model_res)","metadata":{"id":"Q366Rs9S7OJh","outputId":"c1eb6d14-b1d8-4fc3-d5de-a8514ad33b00","execution":{"iopub.status.busy":"2021-09-26T15:08:56.254755Z","iopub.execute_input":"2021-09-26T15:08:56.255104Z","iopub.status.idle":"2021-09-26T15:08:57.604431Z","shell.execute_reply.started":"2021-09-26T15:08:56.255073Z","shell.execute_reply":"2021-09-26T15:08:57.603509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Confusion matrix**","metadata":{"id":"k7FiCfKz7fA7"}},{"cell_type":"code","source":"conf_matrix(model_res)","metadata":{"id":"PfZeL_sb7XOB","outputId":"38f392f1-6df3-4f75-ba54-359f447034ab","execution":{"iopub.status.busy":"2021-09-26T15:09:00.738909Z","iopub.execute_input":"2021-09-26T15:09:00.739249Z","iopub.status.idle":"2021-09-26T15:09:01.97465Z","shell.execute_reply.started":"2021-09-26T15:09:00.739221Z","shell.execute_reply":"2021-09-26T15:09:01.973799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Model Optimization Using TF-Lite(Post Training Dynamic range quantization) ","metadata":{}},{"cell_type":"code","source":"converter_resnet = tf.lite.TFLiteConverter.from_keras_model(model_res)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-26T15:09:02.287387Z","iopub.execute_input":"2021-09-26T15:09:02.287842Z","iopub.status.idle":"2021-09-26T15:09:02.822048Z","shell.execute_reply.started":"2021-09-26T15:09:02.287784Z","shell.execute_reply":"2021-09-26T15:09:02.821085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert to TF Lite without quantization\nresnet_tflite_file = tflite_models_dir/\"resnet.tflite\"\nresnet_tflite_file.write_bytes(converter_resnet.convert())","metadata":{"execution":{"iopub.status.busy":"2021-09-26T15:09:03.577032Z","iopub.execute_input":"2021-09-26T15:09:03.577378Z","iopub.status.idle":"2021-09-26T15:09:11.683705Z","shell.execute_reply.started":"2021-09-26T15:09:03.577346Z","shell.execute_reply":"2021-09-26T15:09:11.682716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"interpreter = tf.lite.Interpreter(model_path='./tflite_models/resnet.tflite')\ninput_type = interpreter.get_input_details()[0]['dtype']\nprint('input: ', input_type)\noutput_type = interpreter.get_output_details()[0]['dtype']\nprint('output: ', output_type)","metadata":{"execution":{"iopub.status.busy":"2021-09-26T15:09:11.685911Z","iopub.execute_input":"2021-09-26T15:09:11.686292Z","iopub.status.idle":"2021-09-26T15:09:11.695393Z","shell.execute_reply.started":"2021-09-26T15:09:11.686239Z","shell.execute_reply":"2021-09-26T15:09:11.694521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"op = evaluate_model(resnet_tflite_file, model_type=\"Float\")\nprint(\"Accuracy of TFLite - Resnet50 : {}\".format(op))","metadata":{"execution":{"iopub.status.busy":"2021-09-26T15:09:11.696971Z","iopub.execute_input":"2021-09-26T15:09:11.697368Z","iopub.status.idle":"2021-09-26T15:09:40.068783Z","shell.execute_reply.started":"2021-09-26T15:09:11.697332Z","shell.execute_reply":"2021-09-26T15:09:40.067501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Optimization of Resnet Model with TensorRT","metadata":{}},{"cell_type":"code","source":"model_res.save('res_saved_model')","metadata":{"execution":{"iopub.status.busy":"2021-09-26T15:10:00.671418Z","iopub.execute_input":"2021-09-26T15:10:00.67176Z","iopub.status.idle":"2021-09-26T15:10:26.016542Z","shell.execute_reply.started":"2021-09-26T15:10:00.67173Z","shell.execute_reply":"2021-09-26T15:10:26.015573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Converting to TF-TRT FP16...')\nconversion_params = trt.DEFAULT_TRT_CONVERSION_PARAMS._replace(\n    precision_mode=trt.TrtPrecisionMode.FP16,\n    max_workspace_size_bytes=8000000000)\nconverter = trt.TrtGraphConverterV2(\n   input_saved_model_dir='res_saved_model', conversion_params=conversion_params)\nconverter.convert()\nconverter.save(output_saved_model_dir='res_saved_model_TFTRT_FP16')\nprint('Done Converting to TF-TRT FP16')","metadata":{"execution":{"iopub.status.busy":"2021-09-26T15:10:26.027641Z","iopub.execute_input":"2021-09-26T15:10:26.027933Z","iopub.status.idle":"2021-09-26T15:10:53.700789Z","shell.execute_reply.started":"2021-09-26T15:10:26.027904Z","shell.execute_reply":"2021-09-26T15:10:53.700051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"benchmark_tftrt('res_saved_model_TFTRT_FP16')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **3) InceptionV3**","metadata":{"id":"WIlv7ZEt7ukH"}},{"cell_type":"markdown","source":"#### **Customizing InceptionV3 for our problem statement**","metadata":{"id":"HZieesu370fd"}},{"cell_type":"code","source":"def incep_model(num_classes=None):\n    \n    \"\"\" Adding custom model to the InceptionV3\n\n    Args:\n      num_classes: Number of layers in the final layer(Number of classes)\n\n    Returns:\n      model: Returns the custom model added to Inception\n    \"\"\"\n\n    model = InceptionV3(weights='imagenet', include_top=False,input_shape=(128,128,3))\n    #model.layers.pop()\n    #model.layers.pop()\n    #model.layers.pop()\n\n#    for layer in model.layers:\n #     layer.trainable = False\n    '''\n    model.outputs = model.output\n    \n    x = GlobalAveragePooling2D()(model.outputs)\n    #x=Conv2D(256, kernel_size=(2,2),strides=2)(model.output)\n    #x = BatchNormalization()(x)    \n    #x=Conv2D(128, kernel_size=(2,2),strides=1)(x)\n    #x = Activation('relu')(x)\n    x = Dense(512, activation='relu')(x)\n    x = Dense(128,activation='relu')(x)\n    x = Dense(num_classes, activation='softmax')(x)\n    #x=Flatten()(x)\n    x=Dense(num_classes, activation='softmax')(x)\n\n    model=Model(model.input,x)'''\n\n    \n    x = model.output\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(1024)(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    x = Dropout(0.3)(x)\n    x = Dense(512)(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    x = Dropout(0.3)(x)\n\n    predictions = Dense(12, activation='softmax')(x)\n\n    model = Model(model.input, predictions)\n\n\n\n\n    return model","metadata":{"id":"wPpu8lxL7nRl","execution":{"iopub.status.busy":"2021-09-26T15:11:05.341221Z","iopub.execute_input":"2021-09-26T15:11:05.341585Z","iopub.status.idle":"2021-09-26T15:11:05.352473Z","shell.execute_reply.started":"2021-09-26T15:11:05.341553Z","shell.execute_reply":"2021-09-26T15:11:05.351432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.applications.inception_v3 import InceptionV3\nfrom keras import backend as K\nnum_classes=12\nmodel_incep = incep_model(num_classes)\nmodel_incep.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\nmodel_incep.summary()","metadata":{"id":"aRTxpla28LQa","outputId":"b1bf866d-ff48-4b70-fdf9-ce962e809178","execution":{"iopub.status.busy":"2021-09-26T15:11:05.977387Z","iopub.execute_input":"2021-09-26T15:11:05.977713Z","iopub.status.idle":"2021-09-26T15:11:10.959618Z","shell.execute_reply.started":"2021-09-26T15:11:05.977683Z","shell.execute_reply":"2021-09-26T15:11:10.958907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Training InceptionV3**","metadata":{"id":"tI03DIzED5MJ"}},{"cell_type":"code","source":"epochs = 10\nbatch_size = 32\nmodel_checkpoint = ModelCheckpoint('incep_weights.h5', monitor='val_accuracy', save_best_only=True,mode='max',verbose=1)\nreduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=7, min_lr=0.000001)\n#early_stop = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=7, verbose=0, mode='min', restore_best_weights=True)\n\nmodel_incep.fit(datagen.flow(X_train,Y_train),\n          batch_size=128,\n          epochs=20,\n          verbose=1, shuffle=True, validation_data=(X_valid,Y_valid), callbacks=[model_checkpoint])","metadata":{"id":"e0Bgv-KH9JUA","outputId":"fd7b2ab2-ea6d-4aac-af5f-a7fe2d5328d4","execution":{"iopub.status.busy":"2021-09-26T15:11:10.964933Z","iopub.execute_input":"2021-09-26T15:11:10.965182Z","iopub.status.idle":"2021-09-26T15:18:11.867982Z","shell.execute_reply.started":"2021-09-26T15:11:10.965157Z","shell.execute_reply":"2021-09-26T15:18:11.866996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Visualizing Loss and Accuracy(InceptionV3)**","metadata":{"id":"5jQDgQ1eLm7h"}},{"cell_type":"code","source":"accuracy_curves(model_incep)","metadata":{"id":"Rw_cJjX8EB_q","outputId":"ade7fbb9-bbea-497c-93a4-29f95468ce07","execution":{"iopub.status.busy":"2021-09-26T15:18:14.998369Z","iopub.execute_input":"2021-09-26T15:18:14.99869Z","iopub.status.idle":"2021-09-26T15:18:15.200742Z","shell.execute_reply.started":"2021-09-26T15:18:14.99866Z","shell.execute_reply":"2021-09-26T15:18:15.199734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_curves(model_incep)","metadata":{"id":"pzdRBKswL6wF","outputId":"1be24c86-d6db-4423-8467-ee4c27463cee","execution":{"iopub.status.busy":"2021-09-26T15:18:16.962705Z","iopub.execute_input":"2021-09-26T15:18:16.963102Z","iopub.status.idle":"2021-09-26T15:18:17.159766Z","shell.execute_reply.started":"2021-09-26T15:18:16.963068Z","shell.execute_reply":"2021-09-26T15:18:17.158881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Classification Report**","metadata":{"id":"18jRfHJrMNL3"}},{"cell_type":"code","source":"class_report(model_incep)","metadata":{"id":"fLodkT-QMCrL","outputId":"bf031ef8-abc8-46a8-f394-2eae8856e6d6","execution":{"iopub.status.busy":"2021-09-26T15:18:19.0124Z","iopub.execute_input":"2021-09-26T15:18:19.012716Z","iopub.status.idle":"2021-09-26T15:18:20.851848Z","shell.execute_reply.started":"2021-09-26T15:18:19.012685Z","shell.execute_reply":"2021-09-26T15:18:20.849578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Confusion Matrix**","metadata":{"id":"5ZmupezwMeH4"}},{"cell_type":"code","source":"conf_matrix(model_incep)","metadata":{"id":"wX3NHbW_MRpW","outputId":"27ca016f-e758-423f-f4bb-5608d04077de","execution":{"iopub.status.busy":"2021-09-26T15:18:20.853688Z","iopub.execute_input":"2021-09-26T15:18:20.854205Z","iopub.status.idle":"2021-09-26T15:18:21.882214Z","shell.execute_reply.started":"2021-09-26T15:18:20.854162Z","shell.execute_reply":"2021-09-26T15:18:21.881494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Model Optimization Using TF-Lite(Post Training Dynamic range quantization) ","metadata":{}},{"cell_type":"code","source":"converter_incep = tf.lite.TFLiteConverter.from_keras_model(model_incep)","metadata":{"execution":{"iopub.status.busy":"2021-09-26T15:18:28.28315Z","iopub.execute_input":"2021-09-26T15:18:28.283494Z","iopub.status.idle":"2021-09-26T15:18:28.965227Z","shell.execute_reply.started":"2021-09-26T15:18:28.283463Z","shell.execute_reply":"2021-09-26T15:18:28.964239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert to TF Lite without quantization\nincep_tflite_file = tflite_models_dir/\"incep.tflite\"\nincep_tflite_file.write_bytes(converter_incep.convert())","metadata":{"execution":{"iopub.status.busy":"2021-09-26T15:18:30.506235Z","iopub.execute_input":"2021-09-26T15:18:30.506578Z","iopub.status.idle":"2021-09-26T15:18:38.665807Z","shell.execute_reply.started":"2021-09-26T15:18:30.50655Z","shell.execute_reply":"2021-09-26T15:18:38.664686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"interpreter = tf.lite.Interpreter(model_path='./tflite_models/incep.tflite')\ninput_type = interpreter.get_input_details()[0]['dtype']\nprint('input: ', input_type)\noutput_type = interpreter.get_output_details()[0]['dtype']\nprint('output: ', output_type)","metadata":{"execution":{"iopub.status.busy":"2021-09-26T15:18:38.669996Z","iopub.execute_input":"2021-09-26T15:18:38.670321Z","iopub.status.idle":"2021-09-26T15:18:38.683642Z","shell.execute_reply.started":"2021-09-26T15:18:38.670287Z","shell.execute_reply":"2021-09-26T15:18:38.682702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"op = evaluate_model(incep_tflite_file, model_type=\"Float\")\nprint(\"Accuracy of TFLite - InceptionV3 : {}\".format(op))","metadata":{"execution":{"iopub.status.busy":"2021-09-26T15:18:38.686711Z","iopub.execute_input":"2021-09-26T15:18:38.687159Z","iopub.status.idle":"2021-09-26T15:18:57.580206Z","shell.execute_reply.started":"2021-09-26T15:18:38.687121Z","shell.execute_reply":"2021-09-26T15:18:57.579304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Optimization of InceptionV3 Model with TensorRT","metadata":{}},{"cell_type":"code","source":"model_incep.save('incep_saved_model')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"benchmark_tftrt('incep_saved_model_TFTRT_FP16')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Saving,Loading and Predicting on test set**","metadata":{}},{"cell_type":"markdown","source":"### The validation accuracies obtained for each model are as follows:\n\n**1. VGG-16 - 91.789**\n\n**2. ResNet50 - 95.368**\n\n**3. InceptionV3 - 89.895** \n\nAs per the question, we choose the model with the highest validation accuracy for predictions on test set i.e ResNet50.","metadata":{}},{"cell_type":"code","source":"!mkdir -p saved_models\n","metadata":{"id":"E9wG2DLAMiaw","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('m_vgg.h5')\nmodel_res.save('m_res.h5')\nmodel_incep.save('m_incep.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Saved Models**\n\n[![Screenshot-2020-08-11-at-11-33-23-AM.png](https://i.postimg.cc/Ls9kkXD0/Screenshot-2020-08-11-at-11-33-23-AM.png)](https://postimg.cc/0z4JP9Lp)","metadata":{}},{"cell_type":"code","source":"new_model = tf.keras.models.load_model('m_res.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_on_test(model):\n    \"\"\" Using the Model with the highest Validation accuracy to predict on test set\n\n    Args:\n      model: Model with highest validation accuracy(ResNet50)\n\n    Returns:\n      df: A Dataframe in a format required by Kaggle \n    \"\"\"\n    prob=[]\n    num=[]\n    test_img=[]\n    test_path = os.path.join('/kaggle/input/plant-seedlings-classification','test')\n    test_all = fnmatch.filter(os.listdir(test_path), '*.png')\n\n    test_img=[]\n    for i in range(len(test_all)):\n        path=test_path+'/'+test_all[i]\n        temp_img=image.load_img(path,target_size=(128,128))\n        temp_img=image.img_to_array(temp_img)\n        test_img.append(temp_img) \n    test_img=np.array(test_img)    \n    test_img= tf.keras.applications.vgg16.preprocess_input(test_img)\n\n\n    test_labels=[]\n    pred=model.predict(test_img)\n    num2label =  {0:'Loose Silky-bent', 1:'Charlock',2: 'Sugar beet',3: 'Small-flowered Cranesbill',\n                  4:'Common Chickweed',5: 'Common wheat',6: 'Maize', 7:'Cleavers', 8:'Scentless Mayweed',\n                 9: 'Fat Hen', 10:'Black-grass', 11:'Shepherds Purse'}\n    for i in range(len(test_all)):\n        max_score =0\n        lab=-1\n        for j in range(12):\n            if pred[i][j]>max_score:\n                max_score=pred[i][j]\n                lab=j\n        test_labels.append(num2label[lab])\n\n\n    d = {'file': test_all, 'species': test_labels}\n    df = pd.DataFrame(data=d)\n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = predict_on_test(new_model)\nprint(df.head(5))\ndf.to_csv(\"/kaggle/working/submit.csv\",index=False) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Score on test Set\n\nReceived a score of 0.94 on the ResNet50 model\n\n\n[![Res-Net-Score.png](https://i.postimg.cc/j5Tb3Hph/Res-Net-Score.png)](https://postimg.cc/jWMmL7dW)","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}