{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport os        \nimport numpy as np # linear algebra\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport PIL\nimport PIL.Image\nfrom tensorflow import keras\nimport tensorflow_datasets as tfds\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":" #Preparing the training data using preprocessing of the images\n\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen =ImageDataGenerator(rescale=1./255, validation_split=0.26)\n    \ntrain_seedlings = train_datagen.flow_from_directory(\n        '../input/plant-seedlings-classification/train',  \n            target_size=(224, 224),  # Resizes images\n            batch_size=80,\n            class_mode='categorical',subset = 'training', seed=50)\n\nx_train, y_train = next(train_seedlings)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Setting up validation Data (train/test split)\n\nvalidation_seedlings = train_datagen.flow_from_directory(\n    '../input/plant-seedlings-classification/train',\n    target_size=(224, 224),\n    batch_size=82,\n    class_mode='categorical',\n    subset='validation')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's see what some examples of seedlings in our training set look like\n\nimport matplotlib.pyplot as plt\nimages = x_train[:9]\nlabels = y_train[:9]\n\n# to visualize some images from our data set\nfig, axes = plt.subplots(3, 3, figsize=(2*3,2*3))\nfor i in range(9):\n    ax = axes[i//3, i%3]\n    ax.imshow(images[i], cmap='gray')\nplt.show()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Setting up our model\n\nmodel = tf.keras.models.Sequential([\n    \n    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=train_seedlings.image_shape),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    keras.layers.Dropout(rate=0.15), \n    \n    # The second convolution\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    keras.layers.Dropout(rate=0.10),\n    \n    # The third convolution\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    keras.layers.Dropout(rate=0.15),\n    \n    # Flatten the results to feed into a DNN\n    tf.keras.layers.Flatten(),\n    \n    # hidden layer\n    \n    tf.keras.layers.Dense(512, activation='relu'),\n    keras.layers.BatchNormalization(),    #adding batch normalization\n    keras.layers.Dropout(rate=0.10),\n  \n    \n    # 12 output neurons for the 12 classes of Seedling Images\n    tf.keras.layers.Dense(12, activation='softmax')\n    \n    \n    ])\n\nfrom tensorflow.keras.optimizers import RMSprop\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=\"adam\",\n              metrics=['acc'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Running our model for 12 epochs\n\n\n#Model fitting for a number of epochs\nhistory = model.fit_generator(\n      train_seedlings,\n      steps_per_epoch=44,\n      epochs=12,\n      validation_data = validation_seedlings,\n      validation_steps = 15,\n      verbose=1)\n\nacc = history.history['acc']\nval_acc = history.history['val_acc']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n    \n\n# returns accuracy of training\nprint(\"Training Accuracy:\"), print(history.history['acc'][-1])\nprint(\"Testing Accuracy:\"), print (history.history['val_acc'][-1])\n\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(1, 2, figsize=(10, 3))\nax = ax.ravel()\nfor i, met in enumerate(['acc', 'loss']):\n    ax[i].plot(history.history[met])\n    ax[i].plot(history.history['val_' + met])\n    ax[i].set_title('Model {}'.format(met))\n    ax[i].set_xlabel('epochs')\n    ax[i].set_ylabel(met)\n    ax[i].legend(['train', 'val'])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}