{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# #dataDir = \"../input/plant-seedlings-classification\"\n# dataDir = \"/kaggle/input/plant-seedlings-classification\"\n\nspecies = ['Black-grass', 'Charlock', 'Cleavers', 'Common Chickweed', 'Common wheat', 'Fat Hen',\n          'Loose Silky-bent', 'Maize','Scentless Mayweed', 'Shepherds Purse',\n          'Small-flowered Cranesbill', 'Sugar beet']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport pandas as pd\n\ndataRootDir = '/kaggle/input/plant-seedlings-classification/'\ntrainDir = dataRootDir + 'train'\ntestDir = dataRootDir + 'test'\n\n# Organize training files into DataFrame\ntrainData = []\nfor speciesId, sp in enumerate(species):\n    for file in os.listdir(os.path.join(trainDir, sp)):\n        trainData.append(['train/{}/{}'.format(sp, file), speciesId, sp])\n\ntrain = pd.DataFrame(trainData, columns=['File', 'SpeciesId', 'Species'])\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\n# Plot a bar chart\nclasses= []\nsampleCounts= []\n\nfor f in os.listdir(trainDir):\n    trainClassPath = os.path.join(trainDir, f)\n    if os.path.isdir(trainClassPath):\n        classes.append(f)\n        sampleCounts.append(len(os.listdir(trainClassPath)))\n\nplt.rcdefaults()\nfig, ax = plt.subplots()\nyPos = np.arange(len(classes))\nax.barh(yPos, sampleCounts, align='center')\nax.set_yticks(yPos)\nax.set_yticklabels(classes)\nax.invert_yaxis()\nax.set_xlabel('Sample Counts')\nax.set_title('Sample Counts Per Class')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\nfrom keras.preprocessing import image\n\nScaleTo = 100  # px to scale\nfig = plt.figure(figsize= (10, 15))\nfig.suptitle('Random Samples From Each Class', fontsize=14, y=.92, horizontalalignment='center', weight='bold')\n\ncolumns = 5\nrows = 12\nfor i in range(12):\n    sampleClass= os.path.join(trainDir,classes[i])\n    for j in range(1,6):\n        fig.add_subplot(rows, columns, i*5+j)\n        plt.axis('off')\n        if j==1:\n            plt.text(0.0, 0.5,str(classes[i]).replace(' ','\\n'), fontsize=13, wrap=True)\n            continue\n        randomImage= os.path.join(sampleClass, random.choice(os.listdir(sampleClass)))\n        img = image.load_img(randomImage, target_size=(ScaleTo, ScaleTo))\n        img= image.img_to_array(img)\n        img /= 255.\n        plt.imshow(img)\n        \nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import shutil\n\n# # Before doing this, we must address the fact that there is no validation dataset yet. We will construct a validation set using 30% of \n# # the training set. In order to maintain the same distribution, we will randomly select 30% from each class.\n# # create validation set\n\n# validationDir = './validation'\n\n# def createValidation(validationSplit=0.3):\n#     if os.path.isdir(validationDir):\n#         print('Validation directory already created!')\n#         print('Process Terminated')\n#         return\n#     os.mkdir(validationDir)\n#     for f in os.listdir(trainDir):\n#         trainClassPath= os.path.join(trainDir, f)\n#         if os.path.isdir(trainClassPath):\n#             validationClassPath= os.path.join(validationDir, f)\n#             os.mkdir(validationClassPath)\n#             filesToMove= int(0.3*len(os.listdir(trainClassPath)))\n            \n#             for i in range(filesToMove):\n#                 randomImage= os.path.join(trainClassPath, random.choice(os.listdir(trainClassPath)))\n#                 shutil.move(randomImage, validationClassPath)\n#     print('Validation set created successfully using {:.2%} of training data'.format(validationSplit))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# createValidation()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sampleCounts= {}\n\nfor i, d in enumerate([trainDir]):\n\n    classes= []\n    sampleCounts[d]= []\n\n    for f in os.listdir(d):\n        trainClassPath= os.path.join(d, f)\n        if os.path.isdir(trainClassPath):\n            classes.append(f)\n            sampleCounts[d].append(len(os.listdir(trainClassPath)))\n\n    #fig, ax= plt.subplot(221+i)\n    fig, ax = plt.subplots()\n\n    # Example data\n    y_pos = np.arange(len(classes))\n\n    ax.barh(y_pos, sampleCounts[d], align='center')\n    ax.set_yticks(y_pos)\n    ax.set_yticklabels(classes)\n    ax.invert_yaxis()  # labels read top-to-bottom\n    ax.set_xlabel('Sample Counts')\n    ax.set_title('{} Sample Counts Per Class'.format(d.capitalize()))\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now we will attempt to remove the background from the images to see if can find a method \n# which generalizes well across all images, then this can be used to accelerate training by \n# isolating the important part of our data. The strategy will be to find upper and lower bounds \n# within a color space which will only contain the green part of the plants. We will then turn the \n# rest of the background black. In order to find the best values for these upper and lower bounds, \n# we grab random pixels from random training images from each of our 12 classes. We will then take this \n# random collection of pixels and plot it in color space i hopes that we can find upper and lower \n# bounds which cleanly seperate the green part of the plants.\n\nimport cv2\nfrom math import sqrt, floor\n\ndef pullRandomPixels(samplesPerClass, pixelsPerSample):\n    totalPixels = 12*samplesPerClass*pixelsPerSample\n    randomPixels = np.zeros((totalPixels, 3), dtype=np.uint8)\n    for i in range(12):\n        sampleClass = os.path.join(trainDir,classes[i])\n        for j in range(samplesPerClass):\n            randomImage = os.path.join(sampleClass, random.choice(os.listdir(sampleClass)))\n            img = cv2.imread(randomImage)\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            img = np.reshape(img, (img.shape[0]*img.shape[1], 3))\n            newPixels= img[np.random.randint(0, img.shape[0], pixelsPerSample)]\n            \n            startIndex = pixelsPerSample*(i*samplesPerClass+j)\n            randomPixels[startIndex:startIndex+pixelsPerSample,:]= newPixels\n\n    h = floor(sqrt(totalPixels))\n    w = totalPixels//h\n    \n    randomPixels = randomPixels[np.random.choice(totalPixels, h*w, replace=False)]\n    randomPixels = np.reshape(randomPixels, (h, w, 3))\n    return randomPixels\n    \nrandomPixels = pullRandomPixels(10, 50)\n\nplt.figure()\nplt.suptitle('Random Samples From Each Class', fontsize=14, horizontalalignment='center')\nplt.imshow(randomPixels)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot these pixels in color space (RGB).\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom matplotlib import cm\nfrom matplotlib import colors\n\nr, g, b = cv2.split(randomPixels)\nfig = plt.figure(figsize=(8, 8))\naxis = fig.add_subplot(1, 1, 1, projection=\"3d\")\naxis.view_init(20, 120)\n\npixelColors = randomPixels.reshape((np.shape(randomPixels)[0]*np.shape(randomPixels)[1], 3))\nnorm = colors.Normalize(vmin=-1.,vmax=1.)\nnorm.autoscale(pixelColors)\npixelColors = norm(pixelColors).tolist()\n\naxis.scatter(r.flatten(), g.flatten(), b.flatten(), facecolors=pixelColors, marker=\".\")\naxis.set_xlabel(\"Red\")\naxis.set_ylabel(\"Green\")\naxis.set_zlabel(\"Blue\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  Choosing bounds of RGB values will not work due to the shape of the distribution. \n# Before resorting to more sophisticated methods to isolate these pixels, lets try a differe color space basis (HSV).\n\nhsv_img = cv2.cvtColor(np.uint8(randomPixels), cv2.COLOR_RGB2HSV)\n\nh, s, v = cv2.split(hsv_img)\nfig = plt.figure(figsize=(8,8))\naxis = fig.add_subplot(1, 1, 1, projection=\"3d\")\naxis.view_init(50, 240)\n\naxis.scatter(h.flatten(), s.flatten(), v.flatten(), facecolors = pixelColors, marker=\".\")\naxis.set_xlabel(\"Hue\")\naxis.set_ylabel(\"Saturation\")\naxis.set_zlabel(\"Value\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# In HSV space, it looks like our clusters are more neatly seperable by choosing upper and lower bounds of HSV values\n\nhsv_img = cv2.cvtColor(np.uint8(randomPixels), cv2.COLOR_RGB2HSV)\n\nh, s, v = cv2.split(hsv_img)\nfig = plt.figure(figsize=(6,6))\naxis = fig.add_subplot(1, 1, 1)\n\naxis.scatter(h.flatten(), s.flatten(), facecolors=pixelColors, marker=\".\")\naxis.set_xlabel(\"Hue\")\naxis.set_ylabel(\"Saturation\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Isolate pixels with Hue values ranging from 24 to 58 and Saturation values ranging from 48 to 255.\n\nlower_bound = (24, 58, 0)\nupper_bound = (48, 255, 255)\n\nfig= plt.figure(figsize=(10, 10))\nfig.suptitle('Random Pre-Processed Image From Each Class', fontsize=14, y=.92, horizontalalignment='center', weight='bold')\n\nfor i in range(12):\n    sampleClass = os.path.join(trainDir,classes[i])\n    randomImage = os.path.join(sampleClass, random.choice(os.listdir(sampleClass)))\n    img= cv2.imread(randomImage)\n    img= cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img= cv2.resize(img, (150, 150))\n    \n    hsvImg= cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n    mask = cv2.inRange(hsvImg, lower_bound, upper_bound)\n    result = cv2.bitwise_and(img, img, mask=mask)\n\n    fig.add_subplot(6, 4, i*2+1)\n    plt.imshow(img)\n    plt.axis('off')    \n\n    fig.add_subplot(6, 4, i*2+2)\n    plt.imshow(result)\n    plt.axis('off')\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will create a function to make the transformation compatible with the ImageDataGenerator object from Keras, \n# which will be using in our model.\n\ndef colorSegmentation(imgArray):\n    imgArray = np.rint(imgArray)\n    imgArray = imgArray.astype('uint8')\n    hsvImg = cv2.cvtColor(imgArray, cv2.COLOR_RGB2HSV)\n    mask = cv2.inRange(hsvImg, (24, 58, 0), (48, 255, 255))\n    result = cv2.bitwise_and(imgArray, imgArray, mask=mask)\n    result = result.astype('float64')\n    return result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Image pre-processing\n\ntestDatagen = image.ImageDataGenerator(\n      rescale = 1./255,\n      rotation_range = 180,\n      width_shift_range = 0.0,\n      height_shift_range = 0.0,\n      shear_range = 0.1,\n      zoom_range = 0.1,\n      horizontal_flip = True,\n      vertical_flip = True,\n      preprocessing_function = colorSegmentation,\n      fill_mode='nearest')\n\ntestDatagen = image.ImageDataGenerator(rescale=1./255, preprocessing_function = colorSegmentation)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imgResize = 100\n\ntrainGenerator = testDatagen.flow_from_directory(\n  trainDir,\n  target_size=(imgResize, imgResize),\n  batch_size=20,\n  class_mode='categorical')\n\n# validationGenerator = testDatagen.flow_from_directory(\n#         'plant-seedlings-classification/validation',\n#         target_size=(imgResize, imgResize),\n#         batch_size=20,\n#         class_mode='categorical')\n\ntestGenerator = testDatagen.flow_from_directory(\n        testDir,\n        target_size=(imgResize, imgResize),\n        batch_size=20,\n        class_mode='categorical',\n        shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from prettytable import PrettyTable\nnumClases = 0\n\n#get class indices and labels. calculate class weight\nlabel_map = {}\nfor k, v in trainGenerator.class_indices.items():\n    label_map[v] = k\n\nclassCounts = pd.Series(trainGenerator.classes).value_counts()\nclassWeight = {}\n\nfor i, c in classCounts.items():\n    classWeight[i]= 1.0/c\n    \nnormFactor = np.mean(list(classWeight.values()))\n\nfor k in classCounts.keys():\n    classWeight[k] = classWeight[k]/normFactor\n\nt = PrettyTable(['class_index', 'class_label', 'class_weight'])\nfor i in sorted(classWeight.keys()):\n    t.add_row([i, label_map[i], '{:.2f}'.format(classWeight[i])])\n    numClases += i\nprint(t)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import Flatten\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers import BatchNormalization\n\nnum_clases = 12\nseed = 7\nnumpy.random.seed(seed)  # Fix seed\n\nmodel = Sequential()\n\nmodel.add(Conv2D(filters=64, kernel_size=(5, 5), input_shape=(ScaleTo, ScaleTo, 3), activation='relu'))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Conv2D(filters=64, kernel_size=(5, 5), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Dropout(0.1))\n\nmodel.add(Conv2D(filters=128, kernel_size=(5, 5), activation='relu'))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Conv2D(filters=128, kernel_size=(5, 5), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Dropout(0.1))\n\nmodel.add(Conv2D(filters=256, kernel_size=(5, 5), activation='relu'))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Conv2D(filters=256, kernel_size=(5, 5), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Dropout(0.1))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(256, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(256, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(num_clases, activation='softmax'))\n\nmodel.summary()\n\n# compile model\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras import models, layers, callbacks\n\nbest_cb = callbacks.ModelCheckpoint('/kaggle/working/model_best.h5', \n                                         monitor='val_loss', \n                                         verbose=1, \n                                         save_best_only=True, \n                                         save_weights_only=False, \n                                         mode='auto', \n                                         period=1)\n\nopt = keras.optimizers.Adam(lr=0.0005, amsgrad=True)\n\nmodel.compile(optimizer=opt,\n                loss='categorical_crossentropy',\n                metrics=['accuracy'])\n\nhistory = model.fit_generator(\n                    trainGenerator,\n                    class_weight= classWeight,\n                    steps_per_epoch= 190,\n                    epochs=50,\n                    validation_steps= 48,\n                    verbose=1,\n                    use_multiprocessing=True,\n                    callbacks=[best_cb])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#load best model from training\nmodel= models.load_model('/kaggle/working/model_best.h5')\n\n#save history\nwith open('model_history.pkl', 'wb') as f:\n    pickle.dump(history, f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\nplt.figure()\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict_generator(test_generator, steps= test_generator.n, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_class_indices=np.argmax(pred,axis=1)\nprediction_labels = [label_map[k] for k in predicted_class_indices]\nfilenames= test_generator.filenames","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import csv\ncsvfile= open('/kaggle/working/submission.csv', 'w', newline='')\nwriter= csv.writer(csvfile)\n\nheaders= ['file', 'species']\n\nwriter.writerow(headers)\nt = PrettyTable(headers)\nfor i, f, p in zip(range(len(filenames)), filenames, prediction_labels):\n    writer.writerow([os.path.basename(f),p])\n    if i <10:\n        t.add_row([os.path.basename(f), p])\n    elif i<13:\n        t.add_row(['.', '.'])\ncsvfile.close()\nprint(t)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}