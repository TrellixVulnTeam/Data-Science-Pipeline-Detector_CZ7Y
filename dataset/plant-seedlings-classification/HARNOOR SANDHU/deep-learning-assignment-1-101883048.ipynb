{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\nimport numpy as np # this library is for the mathematical operations\nimport pandas as pd # this library is used for data processing\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# the below are some of the necessary libraries required for the kaggle challenge\nimport pandas as pd\nimport numpy as np\nimport os\nimport imageio\n\nfrom keras.utils import plot_model\nfrom keras.models import Model\nfrom keras.layers import Input\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom keras.layers import Activation\nfrom keras.layers import Dropout\nfrom keras.layers import Maximum\nfrom keras.layers import ZeroPadding2D\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras import regularizers\nfrom keras.layers import BatchNormalization\nfrom keras.optimizers import Adam, SGD\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom skimage.transform import resize as imresize\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 16\nEPOCHS = 30\nRANDOM_STATE = 11\n\nCLASS = {\n    'Black-grass': 0,\n    'Charlock': 1,\n    'Cleavers': 2,\n    'Common Chickweed': 3,\n    'Common wheat': 4,\n    'Fat Hen': 5,\n    'Loose Silky-bent': 6,\n    'Maize': 7,\n    'Scentless Mayweed': 8,\n    'Shepherds Purse': 9,\n    'Small-flowered Cranesbill': 10,\n    'Sugar beet': 11\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"INV_CLASS = {\n    0: 'Black-grass',\n    1: 'Charlock',\n    2: 'Cleavers',\n    3: 'Common Chickweed',\n    4: 'Common wheat',\n    5: 'Fat Hen',\n    6: 'Loose Silky-bent',\n    7: 'Maize',\n    8: 'Scentless Mayweed',\n    9: 'Shepherds Purse',\n    10: 'Small-flowered Cranesbill',\n    11: 'Sugar beet'\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dense_set(inp_layer, n, activation, drop_rate=0.):\n    dp = Dropout(drop_rate)(inp_layer)\n    dns = Dense(n)(dp)\n    bn = BatchNormalization(axis=-1)(dns)\n    act = Activation(activation=activation)(bn)\n    return act","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def conv_layer(feature_batch, feature_map, kernel_size=(3, 3),strides=(1,1), zp_flag=False):\n    if zp_flag:\n        zp = ZeroPadding2D((1,1))(feature_batch)\n    else:\n        zp = feature_batch\n    conv = Conv2D(filters=feature_map, kernel_size=kernel_size, strides=strides)(zp)\n    bn = BatchNormalization(axis=3)(conv)\n    act = LeakyReLU(1/10)(bn)\n    return act","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model():\n    inp_img = Input(shape=(51, 51, 3))\n\n    \n    conv1 = conv_layer(inp_img, 64, zp_flag=False)\n    conv2 = conv_layer(conv1, 64, zp_flag=False)\n    mp1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(conv2)\n    \n    conv3 = conv_layer(mp1, 128, zp_flag=False)\n    conv4 = conv_layer(conv3, 128, zp_flag=False)\n    mp2 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(conv4)\n    \n    conv7 = conv_layer(mp2, 256, zp_flag=False)\n    conv8 = conv_layer(conv7, 256, zp_flag=False)\n    conv9 = conv_layer(conv8, 256, zp_flag=False)\n    mp3 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(conv9)\n    \n    \n    flt = Flatten()(mp3)\n    ds1 = dense_set(flt, 128, activation='tanh')\n    out = dense_set(ds1, 12, activation='softmax')\n\n    model = Model(inputs=inp_img, outputs=out)\n    \n    # The adam optimizer here uses the first 50 epochs\n    # The next 30 epochs are then used by the SGD optimizer.\n    \n    \n    mypotim = SGD(lr=1 * 1e-1, momentum=0.9, nesterov=True)\n    model.compile(loss='categorical_crossentropy',\n                   optimizer=mypotim,\n                   metrics=['accuracy'])\n    model.summary()\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_callbacks(filepath, patience=5):\n    lr_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.1, epsilon=1e-5, patience=patience, \n                                  verbose=1)\n    msave = ModelCheckpoint(filepath, save_best_only=True)\n    return [lr_reduce, msave]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(img, target):\n    callbacks = get_callbacks(filepath='model_weight_SGD.hdf5', patience=6)\n    gmodel = get_model()\n    gmodel.load_weights(filepath='model_weight_Adam.hdf5')\n    x_train, x_valid, y_train, y_valid = train_test_split(\n                                                        img,\n                                                        target,\n                                                        shuffle=True,\n                                                        train_size=0.8,\n                                                        random_state=RANDOM_STATE\n                                                        )\n    gen = ImageDataGenerator(\n            rotation_range=360.,\n            width_shift_range=0.3,\n            height_shift_range=0.3,\n            zoom_range=0.3,\n            horizontal_flip=True,\n            vertical_flip=True\n    )\n    gmodel.fit_generator(gen.flow(x_train, y_train,batch_size=BATCH_SIZE),\n               steps_per_epoch=10*len(x_train)/BATCH_SIZE,\n               epochs=EPOCHS,\n               verbose=1,\n               shuffle=True,\n               validation_data=(x_valid, y_valid),\n               callbacks=callbacks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_model(img, label):\n    gmodel = get_model()\n    gmodel.load_weights(filepath='../input/plantpretrainedfile/model_weight_SGD.hdf5')\n    prob = gmodel.predict(img, verbose=1)\n    pred = prob.argmax(axis=-1)\n    sub = pd.DataFrame({\"file\": label,\n                         \"species\": [INV_CLASS[p] for p in pred]})\n    sub.to_csv(\"sub.csv\", index=False, header=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def img_reshape(img):\n    img = imresize(img, (51, 51, 3))\n    return img\n\ndef img_label(path):\n    return str(str(path.split('/')[-1]))\n\ndef img_class(path):\n    return str(path.split('/')[-2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fill_dict(paths, some_dict):\n    text = ''\n    if 'train' in paths[0]:\n        text = 'Start fill train_dict'\n    elif 'test' in paths[0]:\n        text = 'Start fill test_dict'\n\n    for p in tqdm(paths, ascii=True, ncols=85, desc=text):\n        img = imageio.imread(p)\n        img = img_reshape(img)\n        some_dict['image'].append(img)\n        some_dict['label'].append(img_label(p))\n        if 'train' in paths[0]:\n            some_dict['class'].append(img_class(p))\n\n    return some_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def reader():\n    file_ext = []\n    train_path = []\n    test_path = []\n\n    for root, dirs, files in os.walk('../input'):\n        if dirs != []:\n            print('Root:\\n'+str(root))\n            print('Dirs:\\n'+str(dirs))\n        else:\n            for f in files:\n                ext = os.path.splitext(str(f))[1][1:]\n\n                if ext not in file_ext:\n                    file_ext.append(ext)\n\n                if 'train' in root:\n                    path = os.path.join(root, f)\n                    train_path.append(path)\n                elif 'test' in root:\n                    path = os.path.join(root, f)\n                    test_path.append(path)\n    train_dict = {\n        'image': [],\n        'label': [],\n        'class': []\n    }\n    test_dict = {\n        'image': [],\n        'label': []\n    }\n\n    #train_dict = fill_dict(train_path, train_dict)\n    test_dict = fill_dict(test_path, test_dict)\n    return train_dict, test_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dict, test_dict = reader()\n#X_train = np.array(train_dict['image'])\n#y_train = to_categorical(np.array([CLASS[l] for l in train_dict['class']]))\n\nX_test = np.array(test_dict['image'])\nlabel = test_dict['label']\n    \n#train_model(X_train, y_train)\ntest_model(X_test, label)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}