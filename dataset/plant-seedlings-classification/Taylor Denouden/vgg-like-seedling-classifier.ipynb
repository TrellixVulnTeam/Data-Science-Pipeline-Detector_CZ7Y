{"nbformat":4,"cells":[{"execution_count":null,"source":"import tensorflow as tf\nimport numpy as np\nimport matplotlib.pylab as plt\nimport keras\nimport os\nfrom PIL import Image, ImageOps\n\n%matplotlib inline","outputs":[],"metadata":{},"cell_type":"code"},{"execution_count":null,"source":"SPECIES = [\n    \"Black-grass\",\n    \"Charlock\",\n    \"Cleavers\",\n    \"Common Chickweed\",\n    \"Common wheat\",\n    \"Fat Hen\",\n    \"Loose Silky-bent\",\n    \"Maize\",\n    \"Scentless Mayweed\",\n    \"Shepherds Purse\",\n    \"Small-flowered Cranesbill\",\n    \"Sugar beet\"\n]\nTRAIN_PATH = './train'\nTEST_PATH = './test'\nRANDOM_SEED=42\nIMG_DIMS = (100, 100)\nIMG_BANDS = 3","outputs":[],"metadata":{"collapsed":true},"cell_type":"code"},{"execution_count":null,"source":"# Load the data\ntrain_X = []\ntrain_y = []\nfor sp_id, sp in enumerate(SPECIES):\n    for img in os.listdir(os.path.join(TRAIN_PATH, sp)):\n        path = os.path.join(TRAIN_PATH, sp, img)\n        img = Image.open(path)\n        train_X.append(ImageOps.fit(img, IMG_DIMS, Image.ANTIALIAS).convert('RGB'))\n        train_y.append(sp_id)\n        \ntest_X = []\nfor img in os.listdir(TEST_PATH):\n    path = os.path.join(TEST_PATH, img)\n    img = Image.open(path)\n    test_X.append(ImageOps.fit(img, IMG_DIMS, Image.ANTIALIAS).convert('RGB'))","outputs":[],"metadata":{"collapsed":true},"cell_type":"code"},{"execution_count":null,"source":"from sklearn.model_selection import train_test_split\n\n# Create the validation set\ntrain_X, val_X, train_y, val_y = train_test_split(train_X, train_y, test_size=0.2, random_state=RANDOM_SEED)","outputs":[],"metadata":{"collapsed":true},"cell_type":"code"},{"execution_count":null,"source":"# Convert all images to ndarray\ntrain_X = np.array([np.array(im) for im in train_X])\ntrain_X = train_X.reshape(train_X.shape[0], IMG_DIMS[0], IMG_DIMS[1], IMG_BANDS) / 255\n\nval_X = np.array([np.array(im) for im in val_X])\nval_X = val_X.reshape(val_X.shape[0], IMG_DIMS[0], IMG_DIMS[1], IMG_BANDS) / 255\n\ntest_X = np.array([np.array(im) for im in test_X])\ntest_X = test_X.reshape(test_X.shape[0], IMG_DIMS[0], IMG_DIMS[1], IMG_BANDS) / 255\n\n# Convert to one-hot labels\ntrain_y = np.asarray(keras.utils.to_categorical(train_y, num_classes=len(SPECIES)))\nval_y = np.asarray(keras.utils.to_categorical(val_y, num_classes=len(SPECIES)))","outputs":[],"metadata":{"collapsed":true},"cell_type":"code"},{"execution_count":null,"source":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint\n\nmodel = Sequential()\n\nmodel.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(IMG_DIMS[0], IMG_DIMS[1], IMG_BANDS)))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\nmodel.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\nmodel.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(len(SPECIES), activation='softmax'))\n\nadam = Adam()\nmodel.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n\ncheckpoint = ModelCheckpoint('./model.hd5', monitor='val_acc', save_best_only=True, mode='auto', period=1)\nhistory = model.fit(train_X, train_y, batch_size=32, epochs=100, \n                    validation_data=(val_X, val_y),\n                    callbacks=[checkpoint])","outputs":[],"metadata":{"scrolled":true},"cell_type":"code"},{"execution_count":null,"source":"from keras.models import load_model\n\nmodel = load_model('./model.hd5')\n\nscore = model.evaluate(val_X, val_y, batch_size=128)\nprint(\"Validation score: %f\" % score[1])","outputs":[],"metadata":{},"cell_type":"code"},{"execution_count":null,"source":"# Generate a submission\npredictions = model.predict(test_X, batch_size=128, verbose=0)\npredictions = np.argmax(predictions, axis=1)","outputs":[],"metadata":{"collapsed":true},"cell_type":"code"},{"execution_count":null,"source":"import csv\n\noutput = [[path, SPECIES[predictions[i]]] for i, path in enumerate(os.listdir(TEST_PATH))]\n\nwith open('submission.csv', 'w') as csvfile:\n    writer = csv.writer(csvfile, delimiter=',')\n    writer.writerow(['file', 'species'])\n    for r in output:\n        writer.writerow(r)    ","outputs":[],"metadata":{"collapsed":true},"cell_type":"code"},{"execution_count":null,"source":"","outputs":[],"metadata":{"collapsed":true},"cell_type":"code"}],"nbformat_minor":1,"metadata":{"language_info":{"mimetype":"text/x-python","pygments_lexer":"ipython3","name":"python","nbconvert_exporter":"python","version":"3.5.2","file_extension":".py","codemirror_mode":{"name":"ipython","version":3}},"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"}}}