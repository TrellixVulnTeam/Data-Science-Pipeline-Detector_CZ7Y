{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os, cv2, re, random\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":32,"outputs":[{"output_type":"stream","text":"['test', 'train', 'sample_submission.csv']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nfrom keras import backend as K\n\n\nimg_width, img_height = 224, 224\n\ntrain_data_dir = '../input/train'\nvalidation_data_dir = '../input/test'\nnb_train_samples = 500\nnb_validation_samples = 100\nepochs = 10\nbatch_size = 32\n\nif K.image_data_format() == 'channels_first':\n    input_shape = (3, img_width, img_height)\nelse:\n    input_shape = (img_width, img_height, 3)\n\ninput_shape","execution_count":33,"outputs":[{"output_type":"execute_result","execution_count":33,"data":{"text/plain":"(224, 224, 3)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(32, (2, 2), input_shape = input_shape))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size =(2, 2)))\n\nmodel.add(Conv2D(32, (2, 2)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size =(2, 2)))\n\nmodel.add(Conv2D(64, (2, 2)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size =(2, 2)))\nmodel.add(Dropout(0.4))\n\nmodel.add(Conv2D(128, (2, 2)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size =(2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(64))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(12))\nmodel.add(Activation('sigmoid'))\n\nmodel.compile(loss ='binary_crossentropy',optimizer ='adadelta', metrics =['accuracy'])\n\ntrain_datagen = ImageDataGenerator(rescale = 1. / 255,shear_range = 0.2,zoom_range = 0.2,horizontal_flip = True)\n\ntest_datagen = ImageDataGenerator(rescale = 1. / 255)\n\ntrain_generator = train_datagen.flow_from_directory(train_data_dir,target_size =(img_width, img_height),\n                                                    batch_size = batch_size, class_mode ='categorical')\n","execution_count":38,"outputs":[{"output_type":"stream","text":"Found 4750 images belonging to 12 classes.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nvalidation_generator = test_datagen.flow_from_directory(validation_data_dir,target_size =(img_width, img_height),\n                                                        batch_size = batch_size, class_mode ='categorical')\n","execution_count":35,"outputs":[{"output_type":"stream","text":"Found 0 images belonging to 0 classes.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmodel.fit_generator(train_generator, steps_per_epoch = nb_train_samples // batch_size,\n                    epochs = epochs, validation_data = validation_generator,\n                    validation_steps = nb_validation_samples // batch_size)\n\n","execution_count":39,"outputs":[{"output_type":"stream","text":"Epoch 1/10\n15/15 [==============================] - 28s 2s/step - loss: 0.3976 - acc: 0.8630\nEpoch 2/10\n15/15 [==============================] - 26s 2s/step - loss: 0.3434 - acc: 0.9000\nEpoch 3/10\n15/15 [==============================] - 26s 2s/step - loss: 0.3297 - acc: 0.9071\nEpoch 4/10\n15/15 [==============================] - 26s 2s/step - loss: 0.3375 - acc: 0.9101\nEpoch 5/10\n15/15 [==============================] - 25s 2s/step - loss: 0.3298 - acc: 0.9099\nEpoch 6/10\n15/15 [==============================] - 26s 2s/step - loss: 0.3236 - acc: 0.9120\nEpoch 7/10\n15/15 [==============================] - 26s 2s/step - loss: 0.3134 - acc: 0.9137\nEpoch 8/10\n15/15 [==============================] - 25s 2s/step - loss: 0.3160 - acc: 0.9158\nEpoch 9/10\n15/15 [==============================] - 26s 2s/step - loss: 0.3126 - acc: 0.9146\nEpoch 10/10\n15/15 [==============================] - 24s 2s/step - loss: 0.3086 - acc: 0.9158\n","name":"stdout"},{"output_type":"execute_result","execution_count":39,"data":{"text/plain":"<keras.callbacks.History at 0x7f054008c358>"},"metadata":{}}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}