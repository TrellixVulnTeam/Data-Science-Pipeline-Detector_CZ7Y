{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport datetime as dt\nimport matplotlib.pyplot as plt\nplt.rcParams['figure.figsize'] = [16, 10]\nplt.rcParams['font.size'] = 16\nimport numpy as np\nimport os\nimport pandas as pd\nimport seaborn as sns\nfrom keras.applications import xception\nfrom keras.preprocessing import image\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dda5ce3aac8df0f948dd0c5095a130ede8b667e9"},"cell_type":"code","source":"CATEGORIES = ['Black-grass', 'Charlock', 'Cleavers', 'Common Chickweed', 'Common wheat', 'Fat Hen', 'Loose Silky-bent',\n              'Maize', 'Scentless Mayweed', 'Shepherds Purse', 'Small-flowered Cranesbill', 'Sugar beet']\nNUM_CATEGORIES = len(CATEGORIES)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e3cd10de95b494376de42a3cdc05fec069432990"},"cell_type":"code","source":"SAMPLE_PER_CATEGORY = 200\nSEED = 1987\ndata_dir = '../input/'\ntrain_dir = os.path.join(data_dir, 'train')\ntest_dir = os.path.join(data_dir, 'test')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cb1bea5067277f90a6178c9f02284779830a9199"},"cell_type":"code","source":"for category in CATEGORIES:\n    print('{} {} images'.format(category, len(os.listdir(os.path.join(train_dir, category)))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dfff1aa1a004e1f42c94ac37694ce9c35db4410d"},"cell_type":"code","source":"train = []\nfor category_id, category in enumerate(CATEGORIES):\n    for file in os.listdir(os.path.join(train_dir, category)):\n        train.append(['train/{}/{}'.format(category, file), category_id, category])\ntrain = pd.DataFrame(train, columns=['file', 'category_id', 'category'])\ntrain.head(2)\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0dd77d5ed158f090fc0e0ed0cff0c3115aed8a2a"},"cell_type":"code","source":"train = pd.concat([train[train['category'] == c][:SAMPLE_PER_CATEGORY] for c in CATEGORIES])\ntrain = train.sample(frac=1)\ntrain.index = np.arange(len(train))\ntrain.head(2)\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d970016182ad8657896a7d721887f8829d675659"},"cell_type":"code","source":"test = []\nfor file in os.listdir(test_dir):\n    test.append(['test/{}'.format(file), file])\ntest = pd.DataFrame(test, columns=['filepath', 'file'])\ntest.head(2)\ntest.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"21c05a3aa87bc4edefe27f609a4e43d91d86c663"},"cell_type":"code","source":"def read_img(filepath, size):\n    img = image.load_img(os.path.join(data_dir, filepath), target_size=size)\n    img = image.img_to_array(img)\n    return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f8f75649c5c205f41d15563563844a964b85a294"},"cell_type":"code","source":"fig = plt.figure(1, figsize=(NUM_CATEGORIES, NUM_CATEGORIES))\ngrid = ImageGrid(fig, 111, nrows_ncols=(NUM_CATEGORIES, NUM_CATEGORIES), axes_pad=0.05)\ni = 0\nfor category_id, category in enumerate(CATEGORIES):\n    for filepath in train[train['category'] == category]['file'].values[:NUM_CATEGORIES]:\n        ax = grid[i]\n        img = read_img(filepath, (224, 224))\n        ax.imshow(img / 255.)\n        ax.axis('off')\n        if i % NUM_CATEGORIES == NUM_CATEGORIES - 1:\n            ax.text(250, 112, filepath.split('/')[1], verticalalignment='center')\n        i += 1\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"efbfef3e2fc63b8a6d0f5a30baa05f32289b1b24"},"cell_type":"code","source":"np.random.seed(seed=SEED)\nrnd = np.random.random(len(train))\ntrain_idx = rnd < 0.8\nvalid_idx = rnd >= 0.8\nytr = train.loc[train_idx, 'category_id'].values\nyv = train.loc[valid_idx, 'category_id'].values\nlen(ytr), len(yv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a3be948075faf31b788c25d1b7c93c1c5c9c2fa3"},"cell_type":"code","source":"from keras.applications.resnet50 import ResNet50,preprocess_input, decode_predictions\nINPUT_SIZE=224\nPOOLING='avg'\nx_train=np.zeros((len(train),INPUT_SIZE,INPUT_SIZE,3),dtype=np.float32)\nfor i,file in tqdm(enumerate(train['file'])):\n    img = read_img(os.path.join(data_dir,file),(INPUT_SIZE,INPUT_SIZE))\n    x=preprocess_input(np.expand_dims(img.copy(),axis=0)) #need to be changed for every model\n    x_train[i]=x\nprint('Train image shape: {} size: {:,}'.format(x_train.shape,x_train.size))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"df7b3ed176b83b31ac6e28b37b8d9e7fd3214ef4"},"cell_type":"code","source":"xtrain=x_train[train_idx]\nxvalid=x_train[valid_idx]\nprint((xtrain.shape,xvalid.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"39785de8171138458434fed1996b5b4de75816ca"},"cell_type":"code","source":"from keras.preprocessing import image\nvgg_bottleneck = ResNet50(weights='imagenet', include_top=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"12a0f64b218873e8d5560af88c9d9eae33db9512"},"cell_type":"code","source":"train_vgg_bf = vgg_bottleneck.predict(xtrain, batch_size=32, verbose=1)\nvalid_vgg_bf = vgg_bottleneck.predict(xvalid, batch_size=32, verbose=1)\nprint('VGG train bottleneck features shape: {} size: {:,}'.format(train_vgg_bf.shape, train_vgg_bf.size))\nprint('VGG valid bottleneck features shape: {} size: {:,}'.format(valid_vgg_bf.shape, valid_vgg_bf.size))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2399ce9778b5cabd309764c6d2fb496d0939489a"},"cell_type":"code","source":"train_vgg_bf=train_vgg_bf.reshape(1899,100352)\nvalid_vgg_bf=valid_vgg_bf.reshape(501,100352)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"918cda602fa1aa83cdb90ae3061a07d30c37458b"},"cell_type":"code","source":"import keras\none_hot_labels = keras.utils.to_categorical(ytr, num_classes=12)\nvalid_labels = keras.utils.to_categorical(yv, num_classes=12)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"96130c8916c41d1840f670e5c10b2fb702039285"},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Activation\nmodel=Sequential()\n\nmodel.add(Dense(1000, input_dim=100352, activation='relu',kernel_initializer='uniform'))\nkeras.layers.core.Dropout(0.3, noise_shape=None, seed=None)\n\nmodel.add(Dense(500,input_dim=1000,activation='sigmoid'))\nkeras.layers.core.Dropout(0.4, noise_shape=None, seed=None)\n\nmodel.add(Dense(150,input_dim=500,activation='sigmoid'))\nkeras.layers.core.Dropout(0.2, noise_shape=None, seed=None)\n\nmodel.add(Dense(units=12))\nmodel.add(Activation('softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"638c35bd74feca4628f89c9477d69c679449e28f"},"cell_type":"code","source":"history= model.fit(train_vgg_bf,one_hot_labels, epochs=10, batch_size=128,validation_data=(valid_vgg_bf, valid_labels))\nprint(history.history.keys())\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('batch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\nmodel.save_weights('fc_model.h5')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a443a6a2035111b227b839d63a93f3161d71a234"},"cell_type":"markdown","source":"Extra Work"},{"metadata":{"trusted":true,"_uuid":"c89c362c0f1d92690196bbbe18eda7c4796c9107"},"cell_type":"code","source":"test = []\nfor file in os.listdir(test_dir):\n    test.append(['test/{}'.format(file),file])\ntest=pd.DataFrame(test,columns=['file_path','file'])\ntest.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7c64658f82bf8cabdc82921e7658a6622b69098c"},"cell_type":"code","source":"x_test = np.zeros((len(test), INPUT_SIZE, INPUT_SIZE, 3), dtype='float32')\nfor i, file in tqdm(enumerate(test['file_path'])):\n    img = read_img(os.path.join(data_dir,file), (INPUT_SIZE, INPUT_SIZE))\n    x = preprocess_input(np.expand_dims(img.copy(), axis=0))\n    x_test[i] = x\nprint('test Images shape: {} size: {:,}'.format(x_test.shape, x_test.size))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"da69a8b583e8a014d4d59fe25c4e9b282bc644ae"},"cell_type":"code","source":"test_x_bf = vgg_bottleneck.predict(x_test, batch_size=32, verbose=1)\nprint('Test bottleneck features shape: {} size: {:,}'.format(test_x_bf.shape, test_x_bf.size))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"88e15f6785c3dcad6792ff357058536c41c01e98"},"cell_type":"code","source":"test_x_bf=test_x_bf.reshape(794,100352)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"06f79f8597a6cab95a4d94e49fe0669d8c9e3cdf"},"cell_type":"code","source":"test_preds = model.predict(test_x_bf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bf17380fb56d87adb84ee4d590b4284a13d5b269"},"cell_type":"code","source":"np.argmax(test_preds,axis=1).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"83ab1feaf64cf5e0e4fa39eaae8f431a3b5ebb86"},"cell_type":"code","source":"test_pred_one = np.argmax(test_preds,axis=1)\ntest['category_id'] = test_pred_one\ntest['species'] = [CATEGORIES[c] for c in test_pred_one]\ntest[['file', 'species']].to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"473068b1e4cf3ceb4feabc224f32e7a8ea4c1cf4"},"cell_type":"code","source":"!ls","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}