{"cells":[{"metadata":{},"cell_type":"markdown","source":"> # **Assignment-6** "},{"metadata":{},"cell_type":"markdown","source":"> > # Import Libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import datetime as dt\nimport matplotlib.pyplot as plt\nimport matplotlib.image as img\nimport numpy as np\nimport os\nimport pandas as pd\nimport seaborn as sns\nfrom tensorflow.keras.applications import InceptionV3\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.applications import resnet50\nfrom tensorflow.keras.applications import vgg16\nfrom tensorflow.keras.applications import inception_v3\nfrom keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization, ReLU\nfrom tensorflow.keras.activations import swish\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nimport random\nimport imgaug as ia\nimport imgaug.augmenters as iaa\nfrom keras.utils import layer_utils\nfrom tensorflow.keras.utils import to_categorical\nfrom statistics import mean\nimport math\nimport cv2\nfrom tensorflow import keras\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" > > # **Create a local directory of pre trained models**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!mkdir ~/.keras\n!mkdir ~/.keras/models\n!cp ../input/keras-pretrained-models/*notop* ~/.keras/models/\n!cp ../input/keras-pretrained-models/imagenet_class_index.json ~/.keras/models/\n!cp ../input/keras-pretrained-models/resnet50* ~/.keras/models/\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir -p /kaggle/working/plant-seedlings-classification/train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" > > # Saving path to Directories "},{"metadata":{"trusted":true},"cell_type":"code","source":"base_directory='../input/plant-seedlings-classification/'\ntrain_dir=os.path.join(base_directory,'train')\ntest_dir=os.path.join(base_directory,'test')\nsave_dir = \"/kaggle/working/plant-seedlings-classification/train\"\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" > > # Making a list of sample classes "},{"metadata":{"trusted":true},"cell_type":"code","source":"Classes = ['Black-grass', 'Charlock', 'Cleavers', 'Common Chickweed', 'Common wheat', 'Fat Hen', 'Loose Silky-bent',\n              'Maize', 'Scentless Mayweed', 'Shepherds Purse', 'Small-flowered Cranesbill', 'Sugar beet']\n\nn_classes = len(Classes)\n\nClasses","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" > > # Defining necessary functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def augmentation_classes(Classes,train_dir):\n    size_dict={}\n    for i,classes in enumerate(Classes):\n         size_dict[Classes[i]]=len(os.listdir(os.path.join(train_dir, classes)))\n    print('Sample sizes of different classes are\\n\\n',size_dict)\n    values_list=list(size_dict.values())\n    ideal_samples=math.ceil(mean(values_list)*1.1)\n    required_aug=[]\n    for i,j in enumerate(size_dict):\n        if size_dict[j]<ideal_samples:\n            required_aug.append(j)\n    print('\\n\\nMinority classes requiring augmentations are\\n',required_aug)\n    return required_aug,ideal_samples,size_dict\n            \n\n\n   \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def image_augmentation(raw_images):\n    \n    \n    seq=iaa.Sequential([iaa.Fliplr(0.5),\n                        iaa.Flipud(0.3),\n                        iaa.LinearContrast((0.75, 1.5)),\n                        iaa.Crop(percent=(0, 0.2)),\n                        iaa.Affine(rotate=(-45, 45)),\n                        iaa.GaussianBlur(sigma=(0.0, 3.0))\n                        ])\n    image_aug=seq(images=raw_images)\n    return image_aug\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocessing(img_path):\n    image = cv2.resize(cv2.imread(img_path), (224,224), interpolation = cv2.INTER_NEAREST)\n    return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_training_data( model):\n        \n    if model == \"resnet50\":\n        datagen = ImageDataGenerator(preprocessing_function = resnet50.preprocess_input, validation_split=0.15)\n    elif model == \"inceptionV3\":\n        datagen = ImageDataGenerator(preprocessing_function = inception_v3.preprocess_input, validation_split=0.15)\n    elif model == 'vgg16':\n        datagen = ImageDataGenerator(preprocessing_function = vgg16.preprocess_input, validation_split=0.15)\n\n    train_data_den = datagen.flow_from_directory(\n            directory= os.path.join(save_dir),\n            class_mode = \"categorical\",\n            batch_size=32,\n            shuffle=True,\n            subset='training'\n        )\n        \n    val_data_gen = datagen.flow_from_directory(\n            directory= os.path.join(save_dir),\n            class_mode = 'categorical',\n            batch_size=32,\n            shuffle=False,\n            subset='validation'\n        )\n\n    return train_data_den, val_data_gen","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def augment_and_store_data(Classes,train_dir,save_dir,required_aug,ideal_samples,size_dict):\n    for i,sample_class in enumerate(Classes):\n        try:\n            os.mkdir(os.path.join(save_dir,sample_class))\n        except FileExistsError:\n            pass\n        img_list=[]\n        for img_loc in os.listdir(os.path.join(train_dir,sample_class)):\n            image = preprocessing(os.path.join(train_dir, sample_class, img_loc))\n            img_list.append(image)\n        if sample_class in required_aug:\n            aug_img= image_augmentation(img_list)\n            req_img=random.sample(aug_img,(ideal_samples-size_dict[sample_class]))\n            img_list.extend(req_img)\n        for image_number, image in enumerate(img_list):\n            cv2.imwrite(os.path.join(save_dir, sample_class, \"{}.png\".format(image_number + 1)), image)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_prep(model_arch,monitor,lr_patience,early_stop_patience,min_lr):\n    checkpoint = ModelCheckpoint(filepath=os.path.join('/kaggle/working/',model_arch,'.h5'), monitor=monitor, mode='min', save_best_only=True)\n    reduce_lr = ReduceLROnPlateau(monitor=monitor, factor=0.2, patience=1, min_lr=min_lr)\n    early_stop = EarlyStopping(monitor=monitor, min_delta=0, patience=5, verbose=1, mode='min', restore_best_weights=True)\n    callbacks=[checkpoint,reduce_lr,early_stop]\n    train_gen, val_gen = get_training_data(model = model_arch)\n    \n    return callbacks,train_gen,val_gen\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" > > #  **Visualizing distribution of data across classes**"},{"metadata":{},"cell_type":"markdown","source":">  > > # Before Augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"a={}\nfor i,classes in enumerate(Classes):\n     a[i]=len(os.listdir(os.path.join(train_dir, classes)))\na=pd.DataFrame(a.items(),columns=['index','no.of samples'],index=a.keys())\na['no.of samples'].plot(kind='bar')\nsample_size=a['no.of samples']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":">  > > # Finding the classes needing augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"required_aug,ideal_samples,size_dict = augmentation_classes(Classes,train_dir)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":">  > > # Augmenting and storing data"},{"metadata":{"trusted":true},"cell_type":"code","source":"augment_and_store_data(Classes,train_dir,save_dir,required_aug,ideal_samples,size_dict)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":">  > > # After augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"c={}\nfor i,classes in enumerate(Classes):\n     c[i]=len(os.listdir(os.path.join(save_dir, classes)))\nc=pd.DataFrame(c.items(),columns=['index','no.of samples'],index=c.keys())\nc['no.of samples'].plot(kind='bar')\nsample_size=a['no.of samples']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"  > > # Training Models"},{"metadata":{},"cell_type":"markdown","source":" >  > > # 1. Resnet50"},{"metadata":{"trusted":true},"cell_type":"code","source":"callbacks,train_gen,val_gen=model_prep('resnet50','val_loss',2,5,0.000001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resnet50_model = ResNet50(weights='imagenet', include_top=False, pooling='avg', input_shape=(224, 224, 3))\nx = resnet50_model.output\nx = Dropout(0.6)(x)\nx = Dense(256)(x)\nx = BatchNormalization()(x)\nx = swish(x)\npred = Dense(12, activation='softmax')(x)\nfinal_model = Model(inputs = resnet50_model.input, outputs = pred)\n\nfor layer in resnet50_model.layers[0:-9]:\n    layer.trainable = False\n    \nfinal_model.compile(Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resnet50_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist_resnet50 = final_model.fit_generator(train_gen,\n                      steps_per_epoch = 155,\n                      validation_data = val_gen,\n                      epochs = 50,\n                      verbose = 1,\n                      callbacks = callbacks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(1, figsize=(10,13 ))\nfor i in range(len(hist_resnet50.history['val_loss'])):\n  plt.subplot(2,1,1)\n  plt.title('Cross Entropy Loss')\n  plt.plot(hist_resnet50.history['loss'], color='blue', label='Train')\n  plt.plot(hist_resnet50.history['val_loss'], color='orange', label='validation')\n  plt.legend(['Train', 'validation'], fontsize = 14)\n\n  plt.subplot(2,1,2)\n  plt.title('Classification Accuracy')\n  plt.plot(hist_resnet50.history['accuracy'], color='blue', label='Train')\n  plt.plot(hist_resnet50.history['val_accuracy'], color='orange', label='validation')\n  plt.legend(['Train', 'validation'], fontsize = 14)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_model.save('/kaggle/working/resnet50_saved_model')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" >  > > # 2. VGG"},{"metadata":{"trusted":true},"cell_type":"code","source":"callbacks,train_gen,val_gen=model_prep('vgg16','val_loss',2,5,0.000001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vgg_model = VGG16(weights='imagenet', include_top=False, pooling='max', input_shape=(224, 224, 3))\nx = vgg_model.output\nx = Dropout(0.6)(x)\nx = Dense(256)(x)\nx = BatchNormalization()(x)\nx = swish(x)\npred = Dense(12, activation='softmax')(x)\nfinal_vgg_model = Model(inputs = vgg_model.input, outputs = pred)\n\nfor layer in vgg_model.layers[0:-4]:\n    layer.trainable = False\n    \nfinal_vgg_model.compile(Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vgg_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_vgg16 = final_vgg_model.fit_generator(train_gen,\n                      steps_per_epoch = 155,\n                      validation_data = val_gen,\n                      epochs = 50,\n                      verbose = 1,\n                      callbacks = callbacks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(1, figsize=(14,8 ))\nfor i in range(len(history_vgg16.history['val_loss'])):\n  plt.subplot(2,1,1)\n  plt.title('Cross Entropy Loss')\n  plt.plot(history_vgg16.history['loss'], color='blue', label='Train')\n  plt.plot(history_vgg16.history['val_loss'], color='orange', label='validation')\n  plt.legend(['Train', 'validation'], fontsize = 14)\n\n  plt.subplot(2,1,2)\n  plt.title('Classification Accuracy')\n  plt.plot(history_vgg16.history['accuracy'], color='blue', label='Train')\n  plt.plot(history_vgg16.history['val_accuracy'], color='orange', label='validation')\n  plt.legend(['Train', 'validation'], fontsize = 14)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_vgg_model.save('/kaggle/working/vgg_saved_model')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" >  > > # 3. InceptionV3"},{"metadata":{"trusted":true},"cell_type":"code","source":"callbacks,train_gen,val_gen=model_prep('inceptionV3','val_loss',2,5,0.000001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inception_model = InceptionV3(weights='imagenet', include_top=False, pooling='avg', input_shape=(299, 299, 3))\nx = inception_model.output\nx = Dropout(0.5)(x)\nx = Dense(512)(x)\nx = BatchNormalization()(x)\nx = swish(x)\nx = Dropout(0.5)(x)\npred = Dense(12, activation='softmax')(x)\nfinal_inception_model = Model(inputs = inception_model.input, outputs = pred)\n\nfor layer in inception_model.layers[0:-22]:\n    layer.trainable = False\n    \nfinal_inception_model.compile(Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inception_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_inception_v3 = final_inception_model.fit_generator(train_gen,\n                      steps_per_epoch = 155,\n                      validation_data = val_gen,\n                      epochs = 50,\n                      verbose = 1,\n                      callbacks = callbacks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(1, figsize=(14,8 ))\nfor i in range(len(history_inception_v3.history['val_loss'])):\n  plt.subplot(2,1,1)\n  plt.title('Cross Entropy Loss')\n  plt.plot(history_inception_v3.history['loss'], color='blue', label='Train')\n  plt.plot(history_inception_v3.history['val_loss'], color='orange', label='validation')\n  plt.legend(['Train', 'validation'], fontsize = 14)\n\n  plt.subplot(2,1,2)\n  plt.title('Classification Accuracy')\n  plt.plot(history_inception_v3.history['accuracy'], color='blue', label='Train')\n  plt.plot(history_inception_v3.history['val_accuracy'], color='orange', label='validation')\n  plt.legend(['Train', 'validation'], fontsize = 14)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_inception_model.save('/kaggle/working/inceptionV3_saved_model')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"   > > # Model Inference"},{"metadata":{},"cell_type":"markdown","source":" >  > > # 1. InceptionV3"},{"metadata":{"trusted":true},"cell_type":"code","source":"incep_model = keras.models.load_model('/kaggle/working/inceptionV3_saved_model')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"callbacks,train_gen,val_gen=model_prep('inceptionV3','val_loss',2,5,0.000001)\nincep_model.evaluate_generator(generator=val_gen)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = incep_model.predict_generator(val_gen,28)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = np.argmax(predictions, axis=1)\ncf_matrix = confusion_matrix(val_gen.classes, y_pred)\nprint('Classification Report')\nprint(classification_report(val_gen.classes, y_pred, target_names=Classes))\nplt.figure(figsize=(20,20))\nsns.heatmap(cf_matrix, annot=True, xticklabels=Classes, yticklabels=Classes, cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" >  > > # 2. Resnet50"},{"metadata":{"trusted":true},"cell_type":"code","source":"resnet_model = keras.models.load_model('/kaggle/working/resnet50_saved_model')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"callbacks,train_gen,val_gen=model_prep('resnet50','val_loss',2,5,0.000001)\nresnet_model.evaluate_generator(generator=val_gen)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = resnet_model.predict_generator(val_gen,28)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = np.argmax(predictions, axis=1)\ncf_matrix = confusion_matrix(val_gen.classes, y_pred)\nprint('Classification Report')\nprint(classification_report(val_gen.classes, y_pred, target_names=Classes))\nplt.figure(figsize=(20,20))\nsns.heatmap(cf_matrix, annot=True, xticklabels=Classes, yticklabels=Classes, cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" >  > > # 3.Vgg16"},{"metadata":{"trusted":true},"cell_type":"code","source":"callbacks,train_gen,val_gen=model_prep('vgg16','val_loss',2,5,0.000001)\nvgg_model = keras.models.load_model('/kaggle/working/vgg_saved_model')\nvgg_model.evaluate_generator(generator=val_gen)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = vgg_model.predict_generator(val_gen,28)\ny_pred = np.argmax(predictions, axis=1)\ncf_matrix = confusion_matrix(val_gen.classes, y_pred)\nprint('Classification Report')\nprint(classification_report(val_gen.classes, y_pred, target_names=Classes))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,20))\nsns.heatmap(cf_matrix, annot=True, xticklabels=Classes, yticklabels=Classes, cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> > # **Conclusion**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n!zip-folder --auto-root --outfile /kaggle/working.zip /kaggle/working ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. Vgg16 gives us the highest validation accuray closely followed by Resnet50 and InceptionV3\n2. After going through the confusion matrices we realize that a major classification confusion was between two classes namely: \n   Black-Grass and Loose_Silky Bent\n3. Vgg16 managed to get 95 plus precision score on 8 out of 12 Classes with 4 classes getting a perfect score of 100. Comparitively \n   Resnet50 managed a 95 plus precision score in 6 classes with perfect scores in 3 classes. InceptionV3 managed 95 plus precision score \n   only in 3 classes while attaining perfect score in none.\n4. Some minor confusions were also noticed between the three classes:\n   Shepherds Purse, Scentless Mayweed and Common Chickweed"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}