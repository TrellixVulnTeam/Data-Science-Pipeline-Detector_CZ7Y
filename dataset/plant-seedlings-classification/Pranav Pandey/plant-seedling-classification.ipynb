{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport cv2 # IMAGE PROCESSING - OPENCV\nfrom glob import glob # FILE OPERATIONS\nimport itertools\n\n# KERAS AND SKLEARN MODULES\nfrom keras.utils import np_utils\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\nfrom keras.layers import BatchNormalization\nfrom keras.utils import to_categorical\n\nfrom sklearn import preprocessing\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Resize the images in the dataset"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"image_dir = '../input/train/*/*.png'\nimages = glob(image_dir)\ntraining_images = []\ntraining_labels = []\nnum = len(images)\ncount = 1\n\n#READING IMAGES AND RESIZING THEM\nfor i in images:\n    print(str(count)+'/'+str(num),end='\\r')\n    training_images.append(cv2.resize(cv2.imread(i),(128,128)))\n    training_labels.append(i.split('/')[-2])\n    count=count+1\ntraining_images = np.asarray(training_images)\ntraining_labels = pd.DataFrame(training_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_labels.rename(columns={0: 'sappling'}, inplace=True)\ntraining_labels.sappling.value_counts()\nplt.figure(figsize=(20,10))\nsns.barplot(x=training_labels.sappling.unique(), y=training_labels.sappling.value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Display some of the images in the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfig, ((ax1, ax2), (ax3, ax4), (ax5, ax6)) = plt.subplots(3, 2)\nfig.suptitle('Sharing x per column, y per row')\nax1.imshow(training_images[3])\nax2.imshow(training_images[4])\nax3.imshow(training_images[5])\nax4.imshow(training_images[6])\nax5.imshow(training_images[7])\nax6.imshow(training_images[8])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train = []\nsets = []; getEx = True\nfor i in training_images:\n    blurr = cv2.GaussianBlur(i,(5,5),0)\n    hsv = cv2.cvtColor(blurr,cv2.COLOR_BGR2HSV)\n    #GREEN PARAMETERS\n    lower = (25,40,50)\n    upper = (75,255,255)\n    mask = cv2.inRange(hsv,lower,upper)\n    struc = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(11,11))\n    mask = cv2.morphologyEx(mask,cv2.MORPH_CLOSE,struc)\n    boolean = mask>0\n    new = np.zeros_like(i,np.uint8)\n    new[boolean] = i[boolean]\n    new_train.append(new)\n    \n    if getEx:\n        plt.subplot(2,3,1);plt.imshow(i) # ORIGINAL\n        plt.subplot(2,3,2);plt.imshow(blurr) # BLURRED\n        plt.subplot(2,3,3);plt.imshow(hsv) # HSV CONVERTED\n        plt.subplot(2,3,4);plt.imshow(mask) # MASKED\n        plt.subplot(2,3,5);plt.imshow(boolean) # BOOLEAN MASKED\n        plt.subplot(2,3,6);plt.imshow(new) # NEW PROCESSED IMAGE\n        plt.show()\n        getEx = False\nnew_train = np.asarray(new_train)\n\n# CLEANED IMAGES\nfor i in range(8):\n    plt.subplot(2,4,i+1)\n    plt.imshow(new_train[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Convolutional Neural Network Model\n\nThe CNN model that we define here using keras is based on the VGG16 architecture."},{"metadata":{"trusted":true},"cell_type":"code","source":"def createModel():\n    model = Sequential()\n    \n    model.add(Conv2D(filters=64, kernel_size=(3, 3), input_shape=(128, 128, 3), activation='relu'))\n    model.add(BatchNormalization(axis=3))\n    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n    model.add(MaxPooling2D((2, 2)))\n    model.add(BatchNormalization(axis=3))\n    model.add(Dropout(0.1))\n\n    model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n    model.add(BatchNormalization(axis=3))\n    model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n    model.add(MaxPooling2D((2, 2)))\n    model.add(BatchNormalization(axis=3))\n    model.add(Dropout(0.1))\n\n    model.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu'))\n    model.add(BatchNormalization(axis=3))\n    model.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu'))\n    model.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu'))\n    model.add(MaxPooling2D((2, 2)))\n    model.add(BatchNormalization(axis=3))\n    model.add(Dropout(0.1))\n\n    model.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu'))\n    model.add(BatchNormalization(axis=3))\n    model.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu'))\n    model.add(MaxPooling2D((2, 2)))\n    model.add(BatchNormalization(axis=3))\n    model.add(Dropout(0.1))\n    \n\n    model.add(Flatten())\n\n    model.add(Dense(4096, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n\n    model.add(Dense(4096, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n\n    model.add(Dense(12, activation='softmax'))\n\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n    model.summary()\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle = preprocessing.LabelEncoder()\n\n\n# 2/3. FIT AND TRANSFORM\n# use df.apply() to apply le.fit_transform to all columns\ntraining_labels = training_labels.apply(le.fit_transform)\nprint(training_labels.head(20))\nprint(type(training_labels))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_labels = np.array(training_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_labels = to_categorical(training_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sappling_model = createModel()\nhistory = sappling_model.fit(training_images, training_labels, batch_size=32, epochs=20, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def save_model(model):\n    sappling_model_json = model.to_json()\n    with open(\"sappling_model.json\", \"w\") as json_file:\n        json_file.write(sappling_model_json)\n    # serialize weights to HDF5\n    model.save_weights(\"sappling_model.h5\")\n    print(\"Saved model to disk\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"save_model(sappling_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}