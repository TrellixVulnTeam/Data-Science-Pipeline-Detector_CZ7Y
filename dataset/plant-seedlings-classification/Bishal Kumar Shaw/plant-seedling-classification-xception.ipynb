{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Reading images from the directories","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import cv2\nimport pandas as pd\nfrom glob import glob\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport gc\n\ndim = 160  # px to scale\n\npath = '../input/plant-seedlings-classification/train/*/*.png' \nfiles = glob(path)\n\ntrainImg = []\ntrainLabel = []\n\nj = 1\nnum = len(files)\n\n# Obtain images and resizing, obtain labels\nfor img in files:\n    print(str(j) + \"/\" + str(num), end=\"\\r\")\n    trainImg.append(cv2.resize(cv2.imread(img), (dim, dim)))  # Get image (with resizing)\n    trainLabel.append(img.split('/')[-2])  # Get image label (folder name)\n    j += 1\n\ntrainImg = np.asarray(trainImg)  # Train images set\ntrainLabel = pd.DataFrame(trainLabel)  # Train labels set","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plotting some images from the Training Set ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show some of the train images\nfig=plt.figure(figsize=(10, 10))\nfor i in range(8):\n    img = fig.add_subplot(2, 4, i + 1)\n    index = np.random.randint(num)\n    plt.xticks([]),plt.yticks([])\n    img.title.set_text(trainLabel[0][index])\n    plt.imshow(trainImg[index])\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Pre-processing (Creating a mask for the Green colour)","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def preProcessImage(Img_arr, getEx=True):\n    clearImg = []\n    for img in Img_arr:\n        # Use gaussian blur\n        blurImg = cv2.GaussianBlur(img, (5, 5), 0)   \n\n        # Convert to HSV image\n        hsvImg = cv2.cvtColor(blurImg, cv2.COLOR_BGR2HSV)  \n\n        # Create mask (parameters - green color range)\n        lower_green = (25, 40, 50)\n        upper_green = (75, 255, 255)\n\n        mask = cv2.inRange(hsvImg, lower_green, upper_green)  \n        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11, 11))\n        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n\n        # Create bool mask\n        bMask = mask > 0  \n\n        # Apply the mask\n        clear = np.zeros_like(img, np.uint8)  # Create empty image\n        clear[bMask] = img[bMask]  # Apply boolean mask to the origin image\n\n        clearImg.append(clear)  # Append image without backgroung\n\n        # Show examples\n        if getEx:\n            fig = plt.figure(figsize=(10, 10))\n            imagels = [img,blurImg,hsvImg,mask,bMask,clear]\n            titlels = ['Original Image','Blur Image','HSV Image','Mask','Boolean Mask', 'Clear Image']\n            for i in range(6):\n                plot = fig.add_subplot(2, 3, i + 1)\n                plt.xticks([]),plt.yticks([])\n                plot.title.set_text(titlels[i])\n                plt.imshow(imagels[i])\n            plt.tight_layout()\n            plt.show()\n            getEx = False\n\n    return(np.asarray(clearImg))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clearTrainImg = preProcessImage(trainImg)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plotting some of the Pre-Processed train Image","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig=plt.figure(figsize=(10, 10))\nfor i in range(8):\n    img = fig.add_subplot(2, 4, i + 1)\n    index = np.random.randint(num)\n    plt.xticks([]),plt.yticks([])\n    img.title.set_text(trainLabel[0][index])\n    plt.imshow(clearTrainImg[index])\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalizing the train Images\nx_train = clearTrainImg / 255.0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## OneHotEncoding and Train-Validation Split","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\n# Encode labels and create classes\nenc = OneHotEncoder(categories='auto')\ny_train = enc.fit_transform(trainLabel).toarray()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedShuffleSplit\n\nsss = StratifiedShuffleSplit(n_splits=1, test_size=0.16, random_state=42) # Want a balanced split for all the classes\nfor train_index, test_index in sss.split(x_train, y_train):\n    print(\"Using {} for training and {} for validation\".format(len(train_index), len(test_index)))\n    x_train, x_valid = x_train[train_index], x_train[test_index]\n    y_train, y_valid = y_train[train_index], y_train[test_index]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Image Augmentation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(rotation_range=20,\n                            zoom_range=0.15,\n                            width_shift_range=0.2,\n                            height_shift_range=0.2,\n                            shear_range=0.15,\n                            horizontal_flip=True,\n                            vertical_flip=True,\n                            brightness_range=[0.4,1],\n                            rescale=1.0/255.0)\ndatagen.fit(x_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating a custom-Xception Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import optimizers\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import BatchNormalization, GlobalAveragePooling2D\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras.applications import Xception\n\n\nnum_classes = 12\nlearning_rate = 0.001\nbatch_size = 32\n\nbase_model = Xception(input_shape=(dim, dim, 3), include_top=False,weights='imagenet')\n\nbase_model.trainable = False\n\nmodel = Sequential([\n    base_model,\n    GlobalAveragePooling2D(),\n    Dense(100, activation=\"relu\"),\n    BatchNormalization(trainable = True,axis=1),\n    \n    Dropout(0.5),\n    \n    Dense(50, activation=\"relu\"),\n    BatchNormalization(trainable = True,axis=1),\n    \n    Dense(num_classes,activation='softmax')\n])\n\n\nmodel.compile(optimizer = optimizers.Nadam(learning_rate=learning_rate),\n              loss = 'categorical_crossentropy',\n              metrics=['accuracy'])\n\n# callbacks = [ EarlyStopping(monitor='val_loss', patience=5, verbose=0), \n#               ModelCheckpoint(weights, monitor='val_loss', save_best_only=True, verbose=0),\n#               ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=0, mode='auto', epsilon=0.0001, cooldown=0, min_lr=0)]\n\nresult = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size), verbose = 1,\n                   batch_size=batch_size, epochs=25, validation_data=(x_valid, y_valid))\n\n(loss, accuracy) = model.evaluate(x_valid, y_valid)\n\nprint(\"[INFO] loss={:.4f}, accuracy: {:.4f}%\".format(loss,accuracy * 100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(result.history['accuracy'], label='train')\nplt.plot(result.history['val_accuracy'], label='valid')\nplt.legend(loc='upper left')\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.show()\n\nplt.plot(result.history['loss'], label='train')\nplt.plot(result.history['val_loss'], label='valid')\nplt.legend(loc='upper right')\nplt.title('Model Cost')\nplt.ylabel('Cost')\nplt.xlabel('Epoch')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fine-tuning our model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model.trainable = True\nmodel.get_layer('xception').trainable","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer=optimizers.Nadam(learning_rate=0.0006), loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size), epochs=50, \n                   initial_epoch=25, validation_data=(x_valid, y_valid),verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(result.history['accuracy'], label='train')\nplt.plot(result.history['val_accuracy'], label='valid')\nplt.legend(loc='upper left')\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.show()\n\nplt.plot(result.history['loss'], label='train')\nplt.plot(result.history['val_loss'], label='valid')\nplt.legend(loc='upper right')\nplt.title('Model Cost')\nplt.ylabel('Cost')\nplt.xlabel('Epoch')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer=optimizers.Nadam(learning_rate=0.00006), loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size), epochs=75, \n                   initial_epoch=50, validation_data=(x_valid, y_valid),verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(result.history['accuracy'], label='train')\nplt.plot(result.history['val_accuracy'], label='valid')\nplt.legend(loc='upper left')\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.show()\n\nplt.plot(result.history['loss'], label='train')\nplt.plot(result.history['val_loss'], label='valid')\nplt.legend(loc='upper right')\nplt.title('Model Cost')\nplt.ylabel('Cost')\nplt.xlabel('Epoch')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Testing our Model ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '../input/plant-seedlings-classification/test/*.png'\nfiles = glob(path)\n\ntestImg = []\ntestId = []\nj = 1\nnum = len(files)\n\n# Obtain images and resizing, obtain labels\nfor img in files:\n    print(\"Obtain images: \" + str(j) + \"/\" + str(num), end='\\r')\n    testId.append(img.split('/')[-1])  # Images id's\n    testImg.append(cv2.resize(cv2.imread(img), (dim, dim)))\n    j += 1\n\ntestImg = np.asarray(testImg)  # Train images set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show some of the test images\nfig=plt.figure(figsize=(10, 10))\nfor i in range(8):\n    img = fig.add_subplot(2, 4, i + 1)\n    index = np.random.randint(num)\n    plt.xticks([]),plt.yticks([])\n    plt.imshow(testImg[index])\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Pre-processing the test images","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"clearTestImg = preProcessImage(testImg,getEx=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalisation of the test images\nclearTestImg = clearTestImg / 255","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Testing our trained Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict(clearTestImg)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating the submission file","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"predNum = np.argmax(pred, axis=1)\npredStr = []\nfor i in range(len(predNum)):\n    predStr.append(enc.categories_[0][predNum[i]])\n    \nres = {'file': testId, 'species': predStr}\nres = pd.DataFrame(res)\nres.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save(\"saved_model\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}