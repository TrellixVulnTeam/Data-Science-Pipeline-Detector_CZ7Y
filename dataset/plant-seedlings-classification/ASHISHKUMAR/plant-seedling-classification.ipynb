{"nbformat_minor":1,"nbformat":4,"cells":[{"cell_type":"code","outputs":[],"metadata":{"_uuid":"b64951258e2f5a5e5f3f17671cc0f8d76aae73e6","_cell_guid":"fa2d471e-bf4d-4ebe-8474-7973d9a51e1e","collapsed":true},"execution_count":null,"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","outputs":[],"metadata":{"collapsed":true},"execution_count":null,"source":"%matplotlib inline\nimport os\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport cv2\nimport numpy as np\nfrom glob import glob\nimport seaborn as sns"},{"cell_type":"code","outputs":[],"metadata":{"collapsed":true},"execution_count":null,"source":"BASE_DATA_FOLDER = \"../input\"\nTRAin_DATA_FOLDER = os.path.join(BASE_DATA_FOLDER, \"train\")"},{"cell_type":"markdown","metadata":{},"source":"Reading images\n\nReading  images and converting it from RGB to BGR (because OpenCV uses BGR)"},{"cell_type":"code","outputs":[],"metadata":{"collapsed":true},"execution_count":null,"source":"images_per_class = {}\nfor class_folder_name in os.listdir(TRAin_DATA_FOLDER):\n    class_folder_path = os.path.join(TRAin_DATA_FOLDER, class_folder_name)\n    class_label = class_folder_name\n    images_per_class[class_label] = []\n    for image_path in glob(os.path.join(class_folder_path, \"*.png\")):\n        image_rgb = cv2.imread(image_path, cv2.IMREAD_COLOR)\n        image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)\n        images_per_class[class_label].append(image_bgr)"},{"cell_type":"markdown","metadata":{},"source":"To know the Number of images per class"},{"cell_type":"code","outputs":[],"metadata":{"collapsed":true},"execution_count":null,"source":"for key,value in images_per_class.items():\n    print(\"{0} -> {1}\".format(key, len(value)))"},{"cell_type":"markdown","metadata":{},"source":"Ploting images\n\nPlotted images so that I can see what the input looks like"},{"cell_type":"code","outputs":[],"metadata":{"collapsed":true},"execution_count":null,"source":"def plot_for_class(label):\n    nb_rows = 3\n    nb_cols = 3\n    fig, axs = plt.subplots(nb_rows, nb_cols, figsize=(6, 6))\n\n    n = 0\n    for i in range(0, nb_rows):\n        for j in range(0, nb_cols):\n            axs[i, j].xaxis.set_ticklabels([])\n            axs[i, j].yaxis.set_ticklabels([])\n            axs[i, j].imshow(images_per_class[label][n])\n            n += 1        "},{"cell_type":"code","outputs":[],"metadata":{"collapsed":true},"execution_count":null,"source":"plot_for_class(\"Small-flowered Cranesbill\")"},{"cell_type":"code","outputs":[],"metadata":{"collapsed":true},"execution_count":null,"source":"plot_for_class(\"Maize\")"},{"cell_type":"markdown","metadata":{},"source":"Preprocessing for the images:"},{"cell_type":"code","outputs":[],"metadata":{"collapsed":true},"execution_count":null,"source":"def create_mask_for_plant(image):\n    image_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n\n    sensitivity = 35\n    lower_hsv = np.array([60 - sensitivity, 100, 50])\n    upper_hsv = np.array([60 + sensitivity, 255, 255])\n\n    mask = cv2.inRange(image_hsv, lower_hsv, upper_hsv)\n    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11,11))\n    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n    \n    return mask\n\ndef segment_plant(image):\n    mask = create_mask_for_plant(image)\n    output = cv2.bitwise_and(image, image, mask = mask)\n    return output\n\ndef sharpen_image(image):\n    image_blurred = cv2.GaussianBlur(image, (0, 0), 3)\n    image_sharp = cv2.addWeighted(image, 1.5, image_blurred, -0.5, 0)\n    return image_sharp"},{"cell_type":"code","outputs":[],"metadata":{"collapsed":true},"execution_count":null,"source":"# Test image to see the changes\nimage = images_per_class[\"Small-flowered Cranesbill\"][97]\n\nimage_mask = create_mask_for_plant(image)\nimage_segmented = segment_plant(image)\nimage_sharpen = sharpen_image(image)\n\nfig, axs = plt.subplots(1, 4, figsize=(20, 20))\naxs[0].imshow(image)\naxs[1].imshow(image_mask)\naxs[2].imshow(image_segmented)\naxs[3].imshow(image_sharpen)"},{"cell_type":"markdown","metadata":{},"source":"we can see that the image on the right is more recognizable than the original image on the left."},{"cell_type":"markdown","metadata":{},"source":"From the mask image what we created above(because we need that for the segmentation), we can extract some features. For example we can see how the area of the plant changes based on their classes.\n\n"},{"cell_type":"markdown","metadata":{},"source":"Of course from the contours we can extract much more information than the area of the contour and the number of components, but this is the one I would like to show you."},{"cell_type":"code","outputs":[],"metadata":{"collapsed":true},"execution_count":null,"source":"def find_contours(mask_image):\n    return cv2.findContours(mask_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]\n\ndef calculate_largest_contour_area(contours):\n    if len(contours) == 0:\n        return 0\n    c = max(contours, key=cv2.contourArea)\n    return cv2.contourArea(c)\n\ndef calculate_contours_area(contours, min_contour_area = 250):\n    area = 0\n    for c in contours:\n        c_area = cv2.contourArea(c)\n        if c_area >= min_contour_area:\n            area += c_area\n    return area"},{"cell_type":"code","outputs":[],"metadata":{"collapsed":true},"execution_count":null,"source":"areas = []\nlarges_contour_areas = []\nlabels = []\nnb_of_contours = []\n\nfor class_label in images_per_class.keys():\n    for image in images_per_class[class_label]:\n        mask = create_mask_for_plant(image)\n        contours = find_contours(mask)\n        \n        area = calculate_contours_area(contours)\n        largest_area = calculate_largest_contour_area(contours)\n        \n        areas.append(area)\n        nb_of_contours.append(len(contours))\n        larges_contour_areas.append(largest_area)\n        labels.append(class_label)"},{"cell_type":"code","outputs":[],"metadata":{"collapsed":true},"execution_count":null,"source":"features_df = pd.DataFrame()\nfeatures_df[\"label\"] = labels\nfeatures_df[\"area\"] = areas\nfeatures_df[\"largest_area\"] = larges_contour_areas\nfeatures_df[\"number_of_components\"] = nb_of_contours"},{"cell_type":"code","outputs":[],"metadata":{"collapsed":true},"execution_count":null,"source":"features_df.groupby(\"label\").describe()"}],"metadata":{"language_info":{"mimetype":"text/x-python","pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py","codemirror_mode":{"version":3,"name":"ipython"},"name":"python","version":"3.6.3"},"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"}}}