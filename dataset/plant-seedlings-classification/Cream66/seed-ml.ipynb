{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-17T07:07:28.719421Z","iopub.execute_input":"2021-11-17T07:07:28.720199Z","iopub.status.idle":"2021-11-17T07:07:30.003697Z","shell.execute_reply.started":"2021-11-17T07:07:28.720131Z","shell.execute_reply":"2021-11-17T07:07:30.002807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport keras\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport cv2","metadata":{"execution":{"iopub.status.busy":"2021-11-17T07:08:04.888648Z","iopub.execute_input":"2021-11-17T07:08:04.888947Z","iopub.status.idle":"2021-11-17T07:08:04.893656Z","shell.execute_reply.started":"2021-11-17T07:08:04.888914Z","shell.execute_reply":"2021-11-17T07:08:04.89287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Dense, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalMaxPool2D\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation, Dropout, BatchNormalization\nfrom tensorflow.keras.optimizers import SGD\nfrom keras.activations import relu\nfrom tensorflow.keras.optimizers import SGD,Adam,RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils.np_utils import to_categorical\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom keras.applications.vgg16 import VGG16\nfrom sklearn import svm\nfrom keras.preprocessing import image\nimport xgboost\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nimport os\nimport cv2\nfrom sklearn.model_selection import train_test_split\nimport sklearn.preprocessing as pr\nfrom sklearn.preprocessing import LabelEncoder \nfrom sklearn import preprocessing\nfrom glob import glob ","metadata":{"execution":{"iopub.status.busy":"2021-11-17T07:08:09.649205Z","iopub.execute_input":"2021-11-17T07:08:09.649733Z","iopub.status.idle":"2021-11-17T07:08:10.634209Z","shell.execute_reply.started":"2021-11-17T07:08:09.649683Z","shell.execute_reply":"2021-11-17T07:08:10.633447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = '/kaggle/input/plant-seedlings-classification/train/*/*.png'\ntest = '/kaggle/input/plant-seedlings-classification/test/*.png'","metadata":{"execution":{"iopub.status.busy":"2021-11-17T07:08:15.728686Z","iopub.execute_input":"2021-11-17T07:08:15.729479Z","iopub.status.idle":"2021-11-17T07:08:15.735681Z","shell.execute_reply.started":"2021-11-17T07:08:15.729428Z","shell.execute_reply":"2021-11-17T07:08:15.734864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = glob(train)\n\nx=[]\ny=[]\n\ndata_count= len(data)\n\nprint(\"Reading Data\")\nfor d in data:\n    x.append(cv2.resize(cv2.imread(d),(244,244)))\n    y.append(d.split('/')[5])\nprint(\"Data Read Complete\")\nx = np.asarray(x)\ny = pd.DataFrame(y)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T07:08:17.920678Z","iopub.execute_input":"2021-11-17T07:08:17.921467Z","iopub.status.idle":"2021-11-17T07:09:38.943991Z","shell.execute_reply.started":"2021-11-17T07:08:17.921423Z","shell.execute_reply":"2021-11-17T07:09:38.943185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(x.shape)\nprint(y.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T07:09:50.208456Z","iopub.execute_input":"2021-11-17T07:09:50.208998Z","iopub.status.idle":"2021-11-17T07:09:50.215201Z","shell.execute_reply.started":"2021-11-17T07:09:50.208954Z","shell.execute_reply":"2021-11-17T07:09:50.214231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(x[0])","metadata":{"execution":{"iopub.status.busy":"2021-11-17T07:09:53.462966Z","iopub.execute_input":"2021-11-17T07:09:53.463266Z","iopub.status.idle":"2021-11-17T07:09:53.720662Z","shell.execute_reply.started":"2021-11-17T07:09:53.463233Z","shell.execute_reply":"2021-11-17T07:09:53.719985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num = 18\nnum_row = 3\nnum_col = 6                              # plot images\nfig, axes = plt.subplots(num_row, num_col, figsize=(1.5*num_col,2*num_row))\nfor i in range(num):\n    ax = axes[i//num_col, i%num_col]\n    ax.imshow(x[i], cmap='gray')\n    #ax.set_title('{}'.format(y_train[i]))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-17T07:09:59.264038Z","iopub.execute_input":"2021-11-17T07:09:59.264767Z","iopub.status.idle":"2021-11-17T07:10:01.445596Z","shell.execute_reply.started":"2021-11-17T07:09:59.264728Z","shell.execute_reply":"2021-11-17T07:10:01.441515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(y.shape)\ny[0].unique()\n#print(x[1][1])","metadata":{"execution":{"iopub.status.busy":"2021-11-17T07:10:07.752534Z","iopub.execute_input":"2021-11-17T07:10:07.753153Z","iopub.status.idle":"2021-11-17T07:10:07.763717Z","shell.execute_reply.started":"2021-11-17T07:10:07.753114Z","shell.execute_reply":"2021-11-17T07:10:07.762885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convert_images(x):\n    X = np.array(x)          \n    # X = X.reshape(X.shape[0],100*100*3)            ## reshape 3D to 1D vector \n    return X\n\ndef convert_labels(y):\n    enc = LabelEncoder()                        \n    P = enc.fit_transform(y)                ## convert string labels to numbers \n    Y = to_categorical(P)                        ## convert number to one-hot-encode form \n    return Y\nX = np.array(x)/255.0 \nY = convert_labels(y)\n\n#print(X)\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2)\nX_train = X_train.astype('float32')    #chang integer -> float\nX_test = X_test.astype('float32')\nX_train /= 255\nX_test /= 255\n\nprint(\"Shape of training data:\")\nprint(X_train.shape)    #50,000 ภาพ ขนาด 32*32  3npg\nprint(Y_train.shape)\nprint(\"Shape of test data:\")\nprint(X_test.shape)\nprint(Y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T07:10:10.606049Z","iopub.execute_input":"2021-11-17T07:10:10.606527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn = Sequential()\n\ncnn.add(Conv2D(32, (3, 3), activation='relu', input_shape=(190, 190, 3)))\ncnn.add(MaxPooling2D(pool_size=(2, 2)))\ncnn.add(Dropout(0.25))\n\ncnn.add(Conv2D(64, (3, 3), activation='relu'))\ncnn.add(MaxPooling2D(pool_size=(2, 2)))\ncnn.add(Dropout(0.25))\n\ncnn.add(Conv2D(128, (3, 3), activation='relu'))\ncnn.add(MaxPooling2D(pool_size=(2, 2)))\ncnn.add(Dropout(0.25))\n\ncnn.add(Conv2D(256, (3, 3), activation='relu'))\ncnn.add(MaxPooling2D(pool_size=(2, 2)))\ncnn.add(Dropout(0.25))\n\ncnn.add(Flatten())        \n\ncnn.add(Dense(256, activation='relu'))\ncnn.add(Dropout(0.5))\ncnn.add(Dense(144, activation='relu'))\ncnn.add(Dense(12, activation='softmax'))\n\nsgd = (learning_rate=0.01)\n\ncnn.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=sgd)\nprint(cnn.summary())\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nhistory = cnn.fit(X_train, Y_train, validation_split=0.1,  epochs=5)\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('CNN model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = cnn.evaluate(X_test, Y_test, verbose=0)     #วัดความแม่นยำ\n# y= cnn.predict(img)\nprint(cnn.metrics_names)\nprint(score)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_path = test\ninfo = glob(test_path)\n#creating two list for isnseritng testing and testing labels\ntest_img = []\ntest_y = []\nnum = len(info)\n#print(num)\nprint(info)\nfor i in info:\n    test_y.append(i.split('/')[-1])\n    test_img.append(cv2.resize(cv2.imread(i),(190,190)))\ntest_img= np.asarray(test_img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Normalization of the Image Data\ntest_img = test_img.astype('float32')\ntest_img /= 255","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #using the model to predict the values on the testing data\nprediction = cnn.predict(test_img)\nprint(prediction.shape)\n# TEST = []\n# for i in range(len(prediction)):\n#     pred = np.argmax(prediction[i])\n#     TEST.append(list(label_map.keys())[list(label_map.values()).index(pos)])\n\n# #print(prediction[0])\n#p_test = cnn.predict(X_test, verbose=1)\n\npred = np.argmax(prediction,axis=1)\nprint(pred)\n\n# # out_df = pd.DataFrame({'file':filenames , \n# #                        'species': labelEncoder(pred)})\n# # out_df.to_csv('submission.csv', index=False)\n# predStr = LabelEncoder.classes_[pred]\n# submission = {'file':test_y,'species':predStr}\n# submission = pd.DataFrame(submission)\n# submission.to_csv(\"Prediction.csv\",index=False)\n\n# # submission['target'] = cnn.predict_proba(test)[:,1]\n# # submission.to_csv('submission.csv', index=False)\n\n# sample = pd.read_csv('../input/plant-seedlings-classification/sample_submission.csv')\n# sample['species'] = TEST\n# sample","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def category (label):\n    if label == 0: return  'Black-grass'\n    elif label == 1: return 'Charlock'\n    elif label == 2: return 'Cleavers'\n    elif label == 3: return 'Common Chickweed'\n    elif label == 4: return 'Common wheat'\n    elif label == 5: return 'Fat Hen'\n    elif label == 6: return 'Loose Silky-bent'\n    elif label == 7: return 'Maize'\n    elif label == 8: return 'Scentless Mayweed'\n    elif label == 9: return 'Shepherds Purse'\n    elif label == 10: return 'Small-flowered Cranesbill'\n    elif label == 11: return 'Sugar beet'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_cate=[]\nfor label in pred :\n    pred_category= category(label)\n    pred_cate.append(pred_category)\npred_cate","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample = pd.read_csv('../input/plant-seedlings-classification/sample_submission.csv')\nsample['species'] = pred_cate\nsample.to_csv(\"submission.csv\", index=False)\nsample.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}