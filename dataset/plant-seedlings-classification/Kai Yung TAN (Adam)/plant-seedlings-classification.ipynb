{"cells":[{"metadata":{"id":"SFwtmdoe13Xd"},"cell_type":"markdown","source":"# Plant Seedlings Classification "},{"metadata":{"id":"kDPNKIZoCS9v"},"cell_type":"markdown","source":"\n\nData Description:\nYou are provided with a training set and a test set of images of plant seedlings at various stages of grown.\nEach image has a filename that is its unique id.\nThe dataset comprises 12 plant species.\n\nThe goal of the competition is to create a classifier capable of determining a plant's species from a photo.\n"},{"metadata":{"id":"zi4PAswG1x2V"},"cell_type":"markdown","source":"# Steps and tasks:"},{"metadata":{"id":"t40QOfjAGYgU"},"cell_type":"markdown","source":"\n1. Import the libraries, load dataset, print shape of data, visualize the images in dataset.  \n2. Data Pre-processing:  \na. Normalization.\nb. Gaussian Blurring.\nc. Masking\nd. Visualize data after pre-processing.\n3. Make data compatible:  \na. Split the dataset into training, testing, and validation set.\nb. Reshape data into shapes compatible with Keras models.\nc. Convert labels from digits to one hot vectors.\nd. Print the label for y_train[0].\n4. Building CNN:  \na. Define layers.\nb. Set optimizer and loss function. (Use Adam optimizer and categorical crossentropy.)\n5. Fit and evaluate model and print confusion matrix.  \n6. Submit predictions on the test image on Kaggle. \n\n"},{"metadata":{"id":"ZLErWKM51WSW"},"cell_type":"markdown","source":"# Code\nImport libraries, load dataset,data pre-processing, make data compatible"},{"metadata":{"id":"XDptpE9HBwe2","outputId":"3807434d-317c-4f00-a202-7f4ddd9e4d82","trusted":false},"cell_type":"code","source":"from google.colab import drive\ndrive.mount('/content/drive')","execution_count":null,"outputs":[]},{"metadata":{"id":"C7bP2ouSCe-L","trusted":false},"cell_type":"code","source":"import cv2\nfrom google.colab.patches import cv2_imshow\nimport numpy as np\nimport pandas as pd\nfrom glob import glob\nfrom matplotlib import pyplot as plt\nimport itertools\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D,Activation,GlobalMaxPool2D,GlobalAveragePooling2D\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.optimizers import Adam,RMSprop\nfrom keras.utils.np_utils import to_categorical  \nfrom keras.utils import np_utils\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix,classification_report,accuracy_score ","execution_count":null,"outputs":[]},{"metadata":{"id":"ntEp_U6H11LW","outputId":"13d467c9-1b00-4790-ff4d-b6089be7c45b","trusted":false},"cell_type":"code","source":" !wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/7880/862031/bundle/archive.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1610181297&Signature=p0zAvDLq8TOzzlt8IbXGsVqY7PbTzyWcn6CgRU571bqMeuYIn3OYkVrj0udTXuetlfCJPkkmwom%2B%2FMyO0hi3rUSEQzVaeQ537DULzChhPScD5PoEhtPC0fK40DkGmIxc9D8N8FFpXVtCd5uNYxgHg35y2cwbZId%2FSdbj0rHpaBbKCDy5o%2BBNkIAXZsUsvERLUPv8xg2tXbqfozp%2FjCoa4hszkNTVSRA6%2FlVSbBHOhIGGtBdTvZUAqZwdCY5m86NZOElQOwCNFJy3XJXZKhfXHx3oN1loI8JBhXEMMc6BhKhJymCEEI%2BlkYPU5%2F%2FLZ3DftPHyvtehkerOexzT6f6dhg%3D%3D&response-content-disposition=attachment%3B+filename%3Dplant-seedlings-classification.zip\" -c -O 'plant-seedlings-classification.zip'","execution_count":null,"outputs":[]},{"metadata":{"id":"cg7VUi8R3TO-","outputId":"e1af429d-e7a6-4b1c-909b-6a91ee6d8d7f","trusted":false},"cell_type":"code","source":"!ls","execution_count":null,"outputs":[]},{"metadata":{"id":"j97pW__I3Vm_","trusted":false},"cell_type":"code","source":"# move the downloaded zip to my drive - Data Folder\n!mv plant-seedlings-classification.zip \"/content/drive/My Drive/Colab Notebooks/Data/plant-seedlings-classification.zip\"","execution_count":null,"outputs":[]},{"metadata":{"id":"vHWmbCJIC3s3","trusted":false},"cell_type":"code","source":"# Set the path to the dataset folder. (The dataset contains image folder: \"train\")\ntrain_path = \"/content/drive/My Drive/Colab Notebooks/Data/plant-seedlings-classification.zip\"\n\n# Set the path to plant-seedlings-classification.zip after download it using wget\n#train_path = \"/content/plant-seedlings-classification.zip\"","execution_count":null,"outputs":[]},{"metadata":{"id":"X_Oxv2E_DyMo","trusted":false},"cell_type":"code","source":"!mkdir temp_train","execution_count":null,"outputs":[]},{"metadata":{"id":"9rlgWSfsD8JO","trusted":false},"cell_type":"code","source":"# Extract the files from dataset to temp_train and temp_test folders (as the dataset is a zip file.)\nfrom zipfile import ZipFile\nwith ZipFile(train_path, 'r') as zip:\n  zip.extractall('./temp_train')","execution_count":null,"outputs":[]},{"metadata":{"id":"_R4y67RWEzoL","outputId":"cd549a0d-a3cf-4ca5-d3b6-e3047aed84b9","trusted":false},"cell_type":"code","source":"path = \"./temp_train/train/*/*.png\"  # The path to all images in training set. (* means include all folders and files.)\nfiles = glob(path)\n\ntrainImg = [] # Initialize empty list to store the image data as numbers.\ntrainLabel = [] # Initialize empty list to store the labels of images\nj = 1\nnum = len(files)\n\n# Obtain images and resizing, obtain labels\nfor img in files:\n    '''\n    Append the image data to trainImg list.\n    Append the labels to trainLabel list.\n    '''\n    print(str(j) + \"/\" + str(num), end=\"\\r\")\n    trainImg.append(cv2.resize(cv2.imread(img), (128, 128)))  # Get image (with resizing to 128x128)\n    trainLabel.append(img.split('/')[-2])  # Get image label (folder name contains the class to which the image belong)\n    j += 1\n\ntrainImg = np.asarray(trainImg)  # Train images set\ntrainLabel = pd.DataFrame(trainLabel)  # Train labels set","execution_count":null,"outputs":[]},{"metadata":{"id":"JhQqeeSkFbQi","outputId":"aefcc51a-6a48-43fb-ed44-ac46ffeb30ee","trusted":false},"cell_type":"code","source":"print(trainImg.shape)\nprint(trainLabel.shape)","execution_count":null,"outputs":[]},{"metadata":{"id":"Ul5wJsAzKuZK","outputId":"1a8b7bdc-a754-45c9-c89a-85f2bf5a1360","trusted":false},"cell_type":"code","source":"trainLabel[0].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"id":"1AIBWykNHAy8","outputId":"881ce28e-4420-4644-f0ac-bc3cd73d3096","trusted":false},"cell_type":"code","source":"f = plt.figure(figsize=(20, 20))\n\nf.add_subplot(2, 6, 1)\nplt.imshow(trainImg[0])\nplt.title(trainLabel[0][0])\n\nf.add_subplot(2, 6, 2)\nplt.imshow(trainImg[496])\nplt.title(trainLabel[0][496])\n\nf.add_subplot(2, 6, 3)\nplt.imshow(trainImg[759])\nplt.title(trainLabel[0][759])\n \nf.add_subplot(2, 6, 4)\nplt.imshow(trainImg[1370])\nplt.title(trainLabel[0][1370])\n\nf.add_subplot(2, 6, 5)\nplt.imshow(trainImg[1755])\nplt.title(trainLabel[0][1755])\n\nf.add_subplot(2, 6, 6)\nplt.imshow(trainImg[1685])\nplt.title(trainLabel[0][1685])\n\nf.add_subplot(1, 6, 1)\nplt.imshow(trainImg[2409])\nplt.title(trainLabel[0][2409])\n\nf.add_subplot(1, 6, 2)\nplt.imshow(trainImg[2630])\nplt.title(trainLabel[0][2630])\n\nf.add_subplot(1, 6, 3)\nplt.imshow(trainImg[3020])\nplt.title(trainLabel[0][3020])\n \nf.add_subplot(1, 6, 4)\nplt.imshow(trainImg[3251])\nplt.title(trainLabel[0][3251])\n\nf.add_subplot(1, 6, 5)\nplt.imshow(trainImg[3538])\nplt.title(trainLabel[0][3538])\n\nf.add_subplot(1, 6, 6)\nplt.imshow(trainImg[4749])\nplt.title(trainLabel[0][4749])","execution_count":null,"outputs":[]},{"metadata":{"id":"q66KSY5nXLTL","outputId":"4023eae3-469e-4314-9b0c-25472d3ab346","trusted":false},"cell_type":"code","source":"trainImg_new = []\nsets = []; getEx = True\n\nfor i in trainImg:\n    # Blurred image\n    blurr = cv2.GaussianBlur(i,(5,5),0)\n    # HSV image\n    hsv = cv2.cvtColor(blurr,cv2.COLOR_BGR2HSV)\n\n    #Green Parameters\n    sensitivity = 35\n    lower  = np.array([60 - sensitivity, 100, 50])\n    upper = np.array([60 + sensitivity, 255, 255])\n    \n    #Masked image\n    mask = cv2.inRange(hsv,lower,upper)\n    struc = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5))\n    mask = cv2.morphologyEx(mask,cv2.MORPH_CLOSE,struc)\n    \n    #Boolean image\n    boolean = mask>0\n    new = np.zeros_like(i,np.uint8)\n    new[boolean] = i[boolean]\n    trainImg_new.append(new)\n    \n    if getEx:\n        f = plt.figure(figsize=(20, 20))\n        f.add_subplot(1,6,1);plt.imshow(i);plt.title('Original image') # Original image\n        f.add_subplot(1,6,2);plt.imshow(blurr);plt.title('Blurred image') # Blurred image\n        f.add_subplot(1,6,3);plt.imshow(hsv);plt.title('HSV image') # HSV image\n        f.add_subplot(1,6,4);plt.imshow(mask);plt.title('Masked image') # Masked image\n        f.add_subplot(1,6,5);plt.imshow(boolean);plt.title('BOOLEAN Masked image') # BOOLEAN Masked image\n        f.add_subplot(1,6,6);plt.imshow(new);plt.title('New Processed image') # New Processed image\n        getEx = False\n        \ntrainImg_new = np.asarray(trainImg_new)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"sXKO_uIaZseV","outputId":"20944998-3fdb-4643-de02-9fe4c0a1f52a","trusted":false},"cell_type":"code","source":"trainImg_new.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"0rsWwmdRM_EI","outputId":"bd30a96a-0017-4ea6-cadc-18b96635c532","trusted":false},"cell_type":"code","source":"labels = preprocessing.LabelEncoder()\nlabels.fit(trainLabel[0])\nprint('Classes'+str(labels.classes_))","execution_count":null,"outputs":[]},{"metadata":{"id":"3c-zhbkHZptU","outputId":"d06231d6-7af4-4875-e6f1-b73528e05f65","trusted":false},"cell_type":"code","source":"encodedlabel = labels.transform(trainLabel[0])\nconvertedlabels = np_utils.to_categorical(encodedlabel)\nclasses = convertedlabels.shape[1]\nprint(str(classes))","execution_count":null,"outputs":[]},{"metadata":{"id":"uR0OHaKZZp0E","trusted":false},"cell_type":"code","source":"# normalization of images\ntrainImg_new = trainImg_new.astype('float32') / 255.0","execution_count":null,"outputs":[]},{"metadata":{"id":"Xb2yOW6RZp4H","trusted":false},"cell_type":"code","source":"X_train,X_test,y_train,y_test = train_test_split(trainImg_new,convertedlabels,test_size=0.3,random_state=38,stratify=convertedlabels)","execution_count":null,"outputs":[]},{"metadata":{"id":"fYjg_dROZp-N","outputId":"47006841-184d-46b0-c2a3-288b0da2e20d","trusted":false},"cell_type":"code","source":"print(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"id":"3WVZsrvTc1Hl","trusted":false},"cell_type":"code","source":"X_val,X_test_new,y_val,y_test_new = train_test_split(X_test,y_test,test_size=0.5,random_state=38,stratify=y_test)","execution_count":null,"outputs":[]},{"metadata":{"id":"IbJ39f1rdYvm","outputId":"e9434a76-fb88-4e2b-9359-b7f035f1109e","trusted":false},"cell_type":"code","source":"print(X_val.shape)\nprint(y_val.shape)\nprint(X_test_new.shape)\nprint(y_test_new.shape)","execution_count":null,"outputs":[]},{"metadata":{"id":"bWCSKBggbL7T","outputId":"467190f9-86b9-41af-af10-b04200fd116b","trusted":false},"cell_type":"code","source":"y_train[0]","execution_count":null,"outputs":[]},{"metadata":{"id":"zuHujda9PubM","outputId":"e303f284-cf56-4d67-bc76-e2594177dd18","trusted":false},"cell_type":"code","source":"labels.classes_[10]","execution_count":null,"outputs":[]},{"metadata":{"id":"NpsEejCZ1PjX"},"cell_type":"markdown","source":"# CNN Model 1\n\n\n*   2 convolution layers ( filters=64 / 128 , kernel_size=(3, 3) activation='relu')\n*   MaxPool2D((2, 2)\n*   Dropout(0.25)\n*   Flatten\n*   2 dense layers (128 / 64, activation='relu')\n*   Dropout(0.25)\n*   loss='categorical_crossentropy', optimizer='adam'\n*   model compile with ImageDataGenerator to minimize overfitting.\n*   shuffle = True \n\n\n\n\n\n\n"},{"metadata":{"id":"sqOSx_-op0XE","trusted":false},"cell_type":"code","source":"generator = ImageDataGenerator(rotation_range = 180,\n                               zoom_range = 0.2,\n                               width_shift_range = 0.2,\n                               height_shift_range = 0.2,\n                               horizontal_flip = True,\n                               vertical_flip = True)\ngenerator.fit(X_train)","execution_count":null,"outputs":[]},{"metadata":{"id":"2qO6EPMwbXSP","outputId":"60792652-2619-4ebc-e9e0-ccd69bf8a066","trusted":false},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), input_shape=(128, 128, 3), activation='relu'))\nmodel.add(MaxPool2D((2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPool2D((2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(classes, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"id":"7ZYQ_5ynbXVt","outputId":"b1ac069e-8aaa-4fef-eef1-9c23842b9be4","trusted":false},"cell_type":"code","source":"history = model.fit(generator.flow(X_train,y_train,batch_size=64),epochs=200, verbose=2,shuffle=True,validation_data=(X_val,y_val))\npd.DataFrame(history.history)","execution_count":null,"outputs":[]},{"metadata":{"id":"IlvwsGp8bXaK","outputId":"78023e61-b4bc-45a0-9e47-f6c050ad22b5","trusted":false},"cell_type":"code","source":"plt.plot(np.array(history.history['accuracy']) * 100)\nplt.plot(np.array(history.history['val_accuracy']) * 100)\nplt.ylabel('accuracy')\nplt.xlabel('epochs')\nplt.legend(['train', 'validation'])\nplt.title('Accuracy over epochs')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"Sn2XNMuil1zX","outputId":"18c0c4cd-6292-486b-f858-ed1408249644","trusted":false},"cell_type":"code","source":"scores = model.evaluate(X_test_new, y_test_new)\nprint('Test loss:', scores[0])\nprint('Test accuracy:', scores[1])\n","execution_count":null,"outputs":[]},{"metadata":{"id":"IdVBPhLVmY6A","trusted":false},"cell_type":"code","source":"# confusion matrix function\n\ndef plot_confusion_matrix(cm, classes, normalize=False,title='Confusion matrix',cmap=plt.cm.Greens):\n    \n    fig = plt.figure(figsize=(10,10))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('Actual label')\n    plt.xlabel('Predicted label')","execution_count":null,"outputs":[]},{"metadata":{"id":"mmo4ODRHaENu","outputId":"8d706735-d416-432b-f2b4-aee4ca83ea9e","trusted":false},"cell_type":"code","source":"# Predict the values from the test data\ny_pred = model.predict(X_test_new)\ny_pred_Classes = np.argmax(y_pred, axis = 1) \ntrueY = np.argmax(y_test_new, axis = 1) \n\n# confusion matrix\nconfusionMTX = confusion_matrix(trueY, y_pred_Classes) \n\n# plot the confusion matrix\nplot_confusion_matrix(confusionMTX, classes = labels.classes_) ","execution_count":null,"outputs":[]},{"metadata":{"id":"Hoav5fSjfMzW","outputId":"67302593-fd4c-42dc-82fd-2c09d2b203c7","trusted":false},"cell_type":"code","source":"#Final score and accuracy of the model\n\nscore, acc = model.evaluate(X_test_new,y_test_new)\nscore1, acc1 = model.evaluate(X_train,y_train)\nprint('Test score:', score,'   Test accuracy:', acc)\nprint('Train score:', score1,'   Train accuracy:',acc1)","execution_count":null,"outputs":[]},{"metadata":{"id":"5S7hQ2cHvFfO"},"cell_type":"markdown","source":"Model with training accuracy of 86% while testing accuracy 84%. \n"},{"metadata":{"id":"UjwG6PRjfx3c","trusted":false},"cell_type":"code","source":"test_images_path = \"./temp_train/test/*.png\"\n\n\ntest_images = glob(test_images_path)\ntest_images_arr = []\ntest_files = []\n\nfor img in test_images:\n    test_images_arr.append(cv2.resize(cv2.imread(img), (128, 128)))\n    test_files.append(img.split('/')[-1])\n\ntest_X = np.asarray(test_images_arr)\n\n# Normalization of the Image Data\ntest_X = test_X.astype('float32') / 255","execution_count":null,"outputs":[]},{"metadata":{"id":"PXPDy5pSoZe6","outputId":"67b6a3c3-5c97-4476-9cca-64e1ae3525ef","trusted":false},"cell_type":"code","source":" test_X","execution_count":null,"outputs":[]},{"metadata":{"id":"HX2JsGCzgcxM","trusted":false},"cell_type":"code","source":"predictions = model.predict(test_X)\npreds = np.argmax(predictions, axis=1)\npred_str = labels.classes_[preds]","execution_count":null,"outputs":[]},{"metadata":{"id":"uPaJ2QYJgjMb","trusted":false},"cell_type":"code","source":"final_predictions = {'file':test_files, 'species':pred_str}\nfinal_predictions = pd.DataFrame(final_predictions)\nfinal_predictions.to_csv(\"./temp_train/submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"id":"oxcDo45qyHKv"},"cell_type":"markdown","source":"# CNN Model 2 \n\n*   3 convolution layers (filters=64/128/128 , kernel_size=(3, 3) activation='relu')\n*   MaxPool2D((2, 2),\n*   Dropout(0.25)\n*   Flatten\n*   1 dense layer (256, activation='relu')\n*   Dropout(0.5)\n*   loss='categorical_crossentropy', optimizer='adam'\n*   model compile with ImageDataGenerator to minimize overfitting.\n*   shuffle = True \n"},{"metadata":{"id":"0qUsMYUd36AN","trusted":false},"cell_type":"code","source":"generator = ImageDataGenerator(rotation_range = 180,\n                               zoom_range = 0.2,\n                               width_shift_range = 0.2,\n                               height_shift_range = 0.2,\n                               horizontal_flip = True,\n                               vertical_flip = True)\ngenerator.fit(X_train)","execution_count":null,"outputs":[]},{"metadata":{"id":"B-vnFwAowK8-","outputId":"ac7ef2a5-a3f9-4746-c46c-40c9aa4fe3bc","trusted":false},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), input_shape=(128, 128, 3), activation='relu'))\nmodel.add(MaxPool2D((2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPool2D((2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPool2D((2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(classes, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"id":"eje0oKX-wLAN","outputId":"dc89f763-dd42-4394-f29f-e9f719c6a6d2","trusted":false},"cell_type":"code","source":"history = model.fit(generator.flow(X_train,y_train,batch_size=64),epochs=100, verbose=2,shuffle=True,validation_data=(X_val,y_val))\npd.DataFrame(history.history)","execution_count":null,"outputs":[]},{"metadata":{"id":"xSJfhYvOwLGP","outputId":"b771e627-c555-4d0d-ff39-044020aa5746","trusted":false},"cell_type":"code","source":"plt.plot(np.array(history.history['accuracy']) * 100)\nplt.plot(np.array(history.history['val_accuracy']) * 100)\nplt.ylabel('accuracy')\nplt.xlabel('epochs')\nplt.legend(['train', 'validation'])\nplt.title('Accuracy over epochs')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"uGzAQGFmwLKL","outputId":"a669d8c4-dbc6-4fd2-c826-ceb5eaa3c051","trusted":false},"cell_type":"code","source":"scores = model.evaluate(X_test_new, y_test_new)\nprint('Test loss:', scores[0])\nprint('Test accuracy:', scores[1])\n","execution_count":null,"outputs":[]},{"metadata":{"id":"iCeCBYsaGEFb","trusted":false},"cell_type":"code","source":"# confusion matrix function\n\ndef plot_confusion_matrix(cm, classes, normalize=False,title='Confusion matrix',cmap=plt.cm.Greens):\n    \n    fig = plt.figure(figsize=(10,10))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('Actual label')\n    plt.xlabel('Predicted label')","execution_count":null,"outputs":[]},{"metadata":{"id":"-B-iNN6vyqpz","outputId":"c10ccd1f-0fd0-421a-ff5a-2230145299c2","trusted":false},"cell_type":"code","source":"# Predict the values from the test data\ny_pred = model.predict(X_test_new)\ny_pred_Classes = np.argmax(y_pred, axis = 1) \ntrueY = np.argmax(y_test_new, axis = 1) \n\n# confusion matrix\nconfusionMTX = confusion_matrix(trueY, y_pred_Classes) \n\n# plot the confusion matrix\nplot_confusion_matrix(confusionMTX, classes = labels.classes_) ","execution_count":null,"outputs":[]},{"metadata":{"id":"dAF3ajjH4LYo","outputId":"538065a7-d708-400a-ba5a-007f52ee7d04","trusted":false},"cell_type":"code","source":"#Final score and accuracy of the model\n\nscore, acc = model.evaluate(X_test_new,y_test_new)\nscore1, acc1 = model.evaluate(X_train,y_train)\nprint('Test score:', score,'   Test accuracy:', acc)\nprint('Train score:', score1,'   Train accuracy:',acc1)","execution_count":null,"outputs":[]},{"metadata":{"id":"ZUhAnVts4QA9","trusted":false},"cell_type":"code","source":"test_images_path = \"./temp_train/test/*.png\"\n\ntest_images = glob(test_images_path)\ntest_images_arr = []\ntest_files = []\n\nfor img in test_images:\n\n    i = cv2.resize(cv2.imread(img), (128, 128))\n    test_files.append(img.split('/')[-1])\n\n    # Blurred image\n    blurr = cv2.GaussianBlur(i,(5,5),0)\n\n    # HSV image\n    hsv = cv2.cvtColor(blurr,cv2.COLOR_BGR2HSV)\n\n    #Green Parameters\n    sensitivity = 35\n    lower  = np.array([60 - sensitivity, 100, 50])\n    upper = np.array([60 + sensitivity, 255, 255])\n    \n    #Masked image\n    mask = cv2.inRange(hsv,lower,upper)\n    struc = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5))\n    mask = cv2.morphologyEx(mask,cv2.MORPH_CLOSE,struc)\n    \n    #Boolean image\n    boolean = mask>0\n    new = np.zeros_like(i,np.uint8)\n    new[boolean] = i[boolean]\n    test_images_arr.append(new)\n\ntest_X = np.asarray(test_images_arr)\n\n# Normalization of the Image Data\ntest_X = test_X.astype('float32') / 255","execution_count":null,"outputs":[]},{"metadata":{"id":"clMVsuCG5R2z","trusted":false},"cell_type":"code","source":"predictions = model.predict(test_X)\npreds = np.argmax(predictions, axis=1)\npred_str = labels.classes_[preds]","execution_count":null,"outputs":[]},{"metadata":{"id":"dWoJwzs55ZH_","trusted":false},"cell_type":"code","source":"final_predictions = {'file':test_files, 'species':pred_str}\nfinal_predictions = pd.DataFrame(final_predictions)\nfinal_predictions.to_csv(\"./temp_train/submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"id":"z7W90IAYeeby"},"cell_type":"markdown","source":"Model 2 has 90% on training accuracy and 87 %  on testing accuracy.  \n\n\n"},{"metadata":{"id":"lnSMlhEHTW2_"},"cell_type":"markdown","source":"# CNN Model 3 - VGG16\n*   Flatten\n*   2 dense layers (256, activation='relu')\n*   Dropout(0.5)\n*   loss='categorical_crossentropy', optimizer='adam'\n*   model compile with ImageDataGenerator to minimize overfitting.\n*   shuffle = True \n"},{"metadata":{"id":"G1O45nriecHr","trusted":false},"cell_type":"code","source":"generator = ImageDataGenerator(rotation_range = 180,\n                               zoom_range = 0.2,\n                               width_shift_range = 0.2,\n                               height_shift_range = 0.2,\n                               horizontal_flip = True,\n                               vertical_flip = True)\ngenerator.fit(X_train)","execution_count":null,"outputs":[]},{"metadata":{"id":"sc4jSJOQeVUz","outputId":"6fd7c147-508d-46c8-ce92-f5b871143c31","trusted":false},"cell_type":"code","source":"from keras.applications.vgg16 import VGG16\n\n# initialize the VGG-16 model\n# remove the final layer of the model and add 12 classess of plant seedlings\n# input images: 128px by 128px.\n\nprior_model = VGG16(weights='imagenet',include_top=False, input_shape=(128,128,3))\n\n# lets create our model\n\nmodel = Sequential()\n\n# and here we add a all the VGG16 as a layer\n\nmodel.add(prior_model)\n\n","execution_count":null,"outputs":[]},{"metadata":{"id":"_42OW1aXeuy0","outputId":"181f7a3a-353d-42df-d1cf-9694aad6b2c1","trusted":false},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"id":"pGV9kLiieyyV","outputId":"62a3b7ff-d655-47ee-c756-fa79146c8c16","trusted":false},"cell_type":"code","source":"model.layers[0].summary()","execution_count":null,"outputs":[]},{"metadata":{"id":"6QcY0MsXe4eV","trusted":false},"cell_type":"code","source":"model.add(Flatten())\nmodel.add(Dense(256,activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(12, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"id":"qvciChTEe-71","outputId":"914b7ec5-c592-4993-f549-ce41cd6d35ab","trusted":false},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"id":"TBpSTSrjfIet","trusted":false},"cell_type":"code","source":"for layers in model.layers[0].layers: # looping over each layers in layer 0 to freeze them\n  layers.trainable = False\n\nmodel.layers[0].trainable = False # freezing layer 0 as well for good measure","execution_count":null,"outputs":[]},{"metadata":{"id":"8j1BS_F5fU4y","trusted":false},"cell_type":"code","source":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"id":"3eXpnh7GhVmR","outputId":"1f35e027-f80c-4120-aa3a-65c5bbd4c840","trusted":false},"cell_type":"code","source":"history = model.fit(generator.flow(X_train,y_train,batch_size=64),epochs=200, verbose=2,shuffle=True,validation_data=(X_val,y_val))\npd.DataFrame(history.history)","execution_count":null,"outputs":[]},{"metadata":{"id":"bbGT9eNKhWg2","outputId":"2480e2f1-d8d1-45b9-c787-376f0018aeb8","trusted":false},"cell_type":"code","source":"plt.plot(np.array(history.history['accuracy']) * 100)\nplt.plot(np.array(history.history['val_accuracy']) * 100)\nplt.ylabel('accuracy')\nplt.xlabel('epochs')\nplt.legend(['train', 'validation'])\nplt.title('Accuracy over epochs')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"DtXMi3_ihWp6","outputId":"d5b9a5cc-f6f6-4604-82a3-60ec75f23f56","trusted":false},"cell_type":"code","source":"scores = model.evaluate(X_test_new, y_test_new)\nprint('Test loss:', scores[0])\nprint('Test accuracy:', scores[1])","execution_count":null,"outputs":[]},{"metadata":{"id":"TujlxR0jfei7","trusted":false},"cell_type":"code","source":"# confusion matrix function\n\ndef plot_confusion_matrix(cm, classes, normalize=False,title='Confusion matrix',cmap=plt.cm.Greens):\n    \n    fig = plt.figure(figsize=(10,10))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('Actual label')\n    plt.xlabel('Predicted label')","execution_count":null,"outputs":[]},{"metadata":{"id":"RQqcaCPchWtE","outputId":"94d2e14e-9221-42d2-a717-aa946d951ba9","trusted":false},"cell_type":"code","source":"# Predict the values from the test data\ny_pred = model.predict(X_test_new)\ny_pred_Classes = np.argmax(y_pred, axis = 1) \ntrueY = np.argmax(y_test_new, axis = 1) \n\n# confusion matrix\nconfusionMTX = confusion_matrix(trueY, y_pred_Classes) \n\n# plot the confusion matrix\nplot_confusion_matrix(confusionMTX, classes = labels.classes_) ","execution_count":null,"outputs":[]},{"metadata":{"id":"Z0nTyoebfrlz","outputId":"bdcddf88-5107-4d57-cbd3-58fc8320fb28","trusted":false},"cell_type":"code","source":"#Final score and accuracy of the model\n\nscore, acc = model.evaluate(X_test_new,y_test_new)\nscore1, acc1 = model.evaluate(X_train,y_train)\nprint('Test score:', score,'   Test accuracy:', acc)\nprint('Train score:', score1,'   Train accuracy:',acc1)","execution_count":null,"outputs":[]},{"metadata":{"id":"M2GovkF7fsJP","trusted":false},"cell_type":"code","source":"test_images_path = \"./temp_train/test/*.png\"\n\ntest_images = glob(test_images_path)\ntest_images_arr = []\ntest_files = []\n\nfor img in test_images:\n\n    i = cv2.resize(cv2.imread(img), (128, 128))\n    test_files.append(img.split('/')[-1])\n\n    # Blurred image\n    blurr = cv2.GaussianBlur(i,(5,5),0)\n\n    # HSV image\n    hsv = cv2.cvtColor(blurr,cv2.COLOR_BGR2HSV)\n\n    #Green Parameters\n    sensitivity = 35\n    lower  = np.array([60 - sensitivity, 100, 50])\n    upper = np.array([60 + sensitivity, 255, 255])\n    \n    #Masked image\n    mask = cv2.inRange(hsv,lower,upper)\n    struc = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5))\n    mask = cv2.morphologyEx(mask,cv2.MORPH_CLOSE,struc)\n    \n    #Boolean image\n    boolean = mask>0\n    new = np.zeros_like(i,np.uint8)\n    new[boolean] = i[boolean]\n    test_images_arr.append(new)\n\ntest_X = np.asarray(test_images_arr)\n\n# Normalization of the Image Data\ntest_X = test_X.astype('float32') / 255","execution_count":null,"outputs":[]},{"metadata":{"id":"X6tJIICNf_Yp","trusted":false},"cell_type":"code","source":"predictions = model.predict(test_X)\npreds = np.argmax(predictions, axis=1)\npred_str = labels.classes_[preds]","execution_count":null,"outputs":[]},{"metadata":{"id":"vMN_2gJPgBQs","trusted":false},"cell_type":"code","source":"final_predictions = {'file':test_files, 'species':pred_str}\nfinal_predictions = pd.DataFrame(final_predictions)\nfinal_predictions.to_csv(\"./temp_train/submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"id":"6zMgStKNlVpJ"},"cell_type":"markdown","source":"Model 3 has 88.7% on training accuracy and 85.5% on testing accuracy."},{"metadata":{"id":"TAbbCXjqme5Z"},"cell_type":"markdown","source":"# CNN Model 4 - InceptionV3\n\n*   Flatten\n*   2 dense layers (1024, activation='relu')\n*   Dropout(0.5)\n*   loss='categorical_crossentropy', optimizer='adam'\n*   model compile with ImageDataGenerator to minimize overfitting.\n*   shuffle = True \n"},{"metadata":{"id":"FC4TU2s_qYnC","trusted":false},"cell_type":"code","source":"from keras.applications.inception_v3 import InceptionV3\n\n# initialize the InceptionV3 model\n# remove the final layer of the model and add 12 classess of plant seedlings\n# input images: 128px by 128px.\n\nprior_model = InceptionV3(weights='imagenet',include_top=False, input_shape=(128,128,3))\n\n# lets create our model\n\nmodel = Sequential()\n\n# and here we add a all the InceptionV3 as a layer\n\nmodel.add(prior_model)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"AW4PCk1sq0rJ","outputId":"127e8bd5-3969-4988-ae09-77053985872d","trusted":false},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"id":"Hbl3_Jmdq3Ey","outputId":"df2543b0-9a35-4cbf-a1a6-cf2533f894d5","trusted":false},"cell_type":"code","source":"model.layers[0].summary()","execution_count":null,"outputs":[]},{"metadata":{"id":"bS2yDpGHmeTc","outputId":"99c49218-9450-4e3d-87c4-05a94e18330a","trusted":false},"cell_type":"code","source":"model.add(Flatten())\n\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(classes, activation='softmax'))\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"id":"dNV7T1-KrFHg","trusted":false},"cell_type":"code","source":"for layers in model.layers[0].layers: # looping over each layers in layer 0 to freeze them\n  layers.trainable = False\n\nmodel.layers[0].trainable = False # freezing layer 0 as well for good measure","execution_count":null,"outputs":[]},{"metadata":{"id":"57WDoum_rS4f","trusted":false},"cell_type":"code","source":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"id":"UKa4wKpLmeWf","outputId":"d3347e10-a174-4e9e-a0dd-57b03d94c564","trusted":false},"cell_type":"code","source":"history = model.fit(generator.flow(X_train,y_train,batch_size=64),epochs=200, verbose=2,shuffle=True,validation_data=(X_val,y_val))\npd.DataFrame(history.history)","execution_count":null,"outputs":[]},{"metadata":{"id":"66o7V0kSmeav","outputId":"6053a7a7-29ab-474b-97f0-99f057c843d6","trusted":false},"cell_type":"code","source":"plt.plot(np.array(history.history['accuracy']) * 100)\nplt.plot(np.array(history.history['val_accuracy']) * 100)\nplt.ylabel('accuracy')\nplt.xlabel('epochs')\nplt.legend(['train', 'validation'])\nplt.title('Accuracy over epochs')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"B0bdQc3wnTlO","outputId":"fd70bd0e-1afb-4e7f-d2dc-36cfc1c5e976","trusted":false},"cell_type":"code","source":"scores = model.evaluate(X_test_new, y_test_new)\nprint('Test loss:', scores[0])\nprint('Test accuracy:', scores[1])","execution_count":null,"outputs":[]},{"metadata":{"id":"SCgjvWdPnToh","outputId":"2c3a46ac-8ddd-4f1a-934c-4c7a637a423d","trusted":false},"cell_type":"code","source":"# Predict the values from the test data\ny_pred = model.predict(X_test_new)\ny_pred_Classes = np.argmax(y_pred, axis = 1) \ntrueY = np.argmax(y_test_new, axis = 1) \n\n# confusion matrix\nconfusionMTX = confusion_matrix(trueY, y_pred_Classes) \n\n# plot the confusion matrix\nplot_confusion_matrix(confusionMTX, classes = labels.classes_) ","execution_count":null,"outputs":[]},{"metadata":{"id":"AZ0PBU2csIjC","outputId":"edb832a7-6108-4ccd-eb13-d2cb83020be9","trusted":false},"cell_type":"code","source":"#Final score and accuracy of the model\n\nscore, acc = model.evaluate(X_test_new,y_test_new)\nscore1, acc1 = model.evaluate(X_train,y_train)\nprint('Test score:', score,'   Test accuracy:', acc)\nprint('Train score:', score1,'   Train accuracy:',acc1)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"ILqJ_ZoAsZxS","trusted":false},"cell_type":"code","source":"test_images_path = \"./temp_train/test/*.png\"\n\ntest_images = glob(test_images_path)\ntest_images_arr = []\ntest_files = []\n\nfor img in test_images:\n\n    i = cv2.resize(cv2.imread(img), (128, 128))\n    test_files.append(img.split('/')[-1])\n\n    # Blurred image\n    blurr = cv2.GaussianBlur(i,(5,5),0)\n\n    # HSV image\n    hsv = cv2.cvtColor(blurr,cv2.COLOR_BGR2HSV)\n\n    #Green Parameters\n    sensitivity = 35\n    lower  = np.array([60 - sensitivity, 100, 50])\n    upper = np.array([60 + sensitivity, 255, 255])\n    \n    #Masked image\n    mask = cv2.inRange(hsv,lower,upper)\n    struc = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5))\n    mask = cv2.morphologyEx(mask,cv2.MORPH_CLOSE,struc)\n    \n    #Boolean image\n    boolean = mask>0\n    new = np.zeros_like(i,np.uint8)\n    new[boolean] = i[boolean]\n    test_images_arr.append(new)\n\ntest_X = np.asarray(test_images_arr)\n\n# Normalization of the Image Data\ntest_X = test_X.astype('float32') / 255\n","execution_count":null,"outputs":[]},{"metadata":{"id":"R19O2gRIscwQ","trusted":false},"cell_type":"code","source":"predictions = model.predict(test_X)\npreds = np.argmax(predictions, axis=1)\npred_str = labels.classes_[preds]\n\nfinal_predictions = {'file':test_files, 'species':pred_str}\nfinal_predictions = pd.DataFrame(final_predictions)\nfinal_predictions.to_csv(\"./temp_train/submission.csv\", index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"IMbRwgLkna1C"},"cell_type":"markdown","source":"Model 4 has 90% on training accuracy and 84% on testing accuracy.\n "},{"metadata":{"id":"Z5mnMqYfrEdQ"},"cell_type":"markdown","source":"# CNN Model 5\n\n*   4 convolution layers (filters=64/64/128/256, kernel_size=(3, 3) activation='relu')\n*   MaxPool2D((2, 2) \n*   Dropout(0.25)\n*   GlobalMaxPool2D\n*   Flatten\n*   2 dense layers (256 / 256, activation='relu')\n*   Dropout(0.25)\n*   loss='categorical_crossentropy', optimizer='adam'\n*   model compile with ImageDataGenerator to minimize overfitting.\n*   shuffle = True \n"},{"metadata":{"id":"86JmCy6inTrh","outputId":"1fca6511-a891-4b8a-a7a2-95cd1dac40a7","trusted":false},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), input_shape=(128, 128, 3), activation='relu'))\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPool2D((2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPool2D((2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPool2D((2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(GlobalMaxPool2D())\n\nmodel.add(Flatten())\n\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(classes, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"id":"1RhfMIZinTuo","outputId":"c247f284-7b21-4503-ce92-8fb711dfc0bf","trusted":false},"cell_type":"code","source":"history = model.fit(generator.flow(X_train,y_train,batch_size=64),epochs=200, verbose=2,shuffle=True,validation_data=(X_val,y_val))\npd.DataFrame(history.history)","execution_count":null,"outputs":[]},{"metadata":{"id":"XwHwyWJOnTxE","outputId":"3a74e504-7675-407c-c213-2c9c8ae662c1","trusted":false},"cell_type":"code","source":"plt.plot(np.array(history.history['accuracy']) * 100)\nplt.plot(np.array(history.history['val_accuracy']) * 100)\nplt.ylabel('accuracy')\nplt.xlabel('epochs')\nplt.legend(['train', 'validation'])\nplt.title('Accuracy over epochs')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"lv4o9botnTzr","outputId":"6d42df4a-1a73-4124-afaa-d3ccadc29e66","trusted":false},"cell_type":"code","source":"scores = model.evaluate(X_test_new, y_test_new)\nprint('Test loss:', scores[0])\nprint('Test accuracy:', scores[1])","execution_count":null,"outputs":[]},{"metadata":{"id":"el5A1FfirjRp","outputId":"4153e1dc-927f-400a-ca65-e1176f4851c0","trusted":false},"cell_type":"code","source":"# Predict the values from the test data\ny_pred = model.predict(X_test_new)\ny_pred_Classes = np.argmax(y_pred, axis = 1) \ntrueY = np.argmax(y_test_new, axis = 1) \n\n# confusion matrix\nconfusionMTX = confusion_matrix(trueY, y_pred_Classes) \n\n# plot the confusion matrix\nplot_confusion_matrix(confusionMTX, classes = labels.classes_) \n","execution_count":null,"outputs":[]},{"metadata":{"id":"Y0CT3Y_G5VB-","outputId":"e6d1094e-1519-4a18-d35c-f6f67b7085bc","trusted":false},"cell_type":"code","source":"#Final score and accuracy of the model\n\nscore, acc = model.evaluate(X_test_new,y_test_new)\nscore1, acc1 = model.evaluate(X_train,y_train)\nprint('Test score:', score,'   Test accuracy:', acc)\nprint('Train score:', score1,'   Train accuracy:',acc1)\n\n","execution_count":null,"outputs":[]},{"metadata":{"id":"xfPXTAxb5YLZ","trusted":false},"cell_type":"code","source":"test_images_path = \"./temp_train/test/*.png\"\n\ntest_images = glob(test_images_path)\ntest_images_arr = []\ntest_files = []\n\nfor img in test_images:\n\n    i = cv2.resize(cv2.imread(img), (128, 128))\n    test_files.append(img.split('/')[-1])\n\n    # Blurred image\n    blurr = cv2.GaussianBlur(i,(5,5),0)\n\n    # HSV image\n    hsv = cv2.cvtColor(blurr,cv2.COLOR_BGR2HSV)\n\n    #Green Parameters\n    sensitivity = 35\n    lower  = np.array([60 - sensitivity, 100, 50])\n    upper = np.array([60 + sensitivity, 255, 255])\n    \n    #Masked image\n    mask = cv2.inRange(hsv,lower,upper)\n    struc = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5))\n    mask = cv2.morphologyEx(mask,cv2.MORPH_CLOSE,struc)\n    \n    #Boolean image\n    boolean = mask>0\n    new = np.zeros_like(i,np.uint8)\n    new[boolean] = i[boolean]\n    test_images_arr.append(new)\n\ntest_X = np.asarray(test_images_arr)\n\n# Normalization of the Image Data\ntest_X = test_X.astype('float32') / 255\n","execution_count":null,"outputs":[]},{"metadata":{"id":"pJ58OCyG5beS","trusted":false},"cell_type":"code","source":"predictions = model.predict(test_X)\npreds = np.argmax(predictions, axis=1)\npred_str = labels.classes_[preds]\n\n\nfinal_predictions = {'file':test_files, 'species':pred_str}\nfinal_predictions = pd.DataFrame(final_predictions)\nfinal_predictions.to_csv(\"./temp_train/submission.csv\", index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"r3ymAcNbu1CF"},"cell_type":"markdown","source":"Model 5 has 95% on training accuracy and 93% on testing accuracy. \n\n "},{"metadata":{"id":"257sWnQMbX91"},"cell_type":"markdown","source":"# CNN Model 6 \n\n*   6 convolution layers (filters=64/64/128/128/256/256, kernel_size=(3, 3) activation='relu')\n*   MaxPool2D((2, 2) \n*   Dropout(0.25)\n*   GlobalMaxPool2D\n*   Flatten\n*   3 dense layers (256/256/256, activation='relu')\n*   Dropout(0.25)\n*   loss='categorical_crossentropy', optimizer='adam'\n*   model compile with ImageDataGenerator to minimize overfitting.\n*   shuffle = True \n\n"},{"metadata":{"id":"mzkKOu8M0bi8","outputId":"b9adf23b-218e-48b4-8be9-6b9fa7b9c4fe","trusted":false},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), input_shape=(128, 128, 3), activation='relu'))\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPool2D((2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\nmodel.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPool2D((2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu'))\nmodel.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPool2D((2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(GlobalMaxPool2D())\n\nmodel.add(Flatten())\n\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(classes, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"id":"a6rZ_e5jxkWD","trusted":false},"cell_type":"code","source":"generator = ImageDataGenerator(rotation_range = 180,\n                               zoom_range = 0.2,\n                               width_shift_range = 0.2,\n                               height_shift_range = 0.2,\n                               horizontal_flip = True,\n                               vertical_flip = True)\ngenerator.fit(X_train)","execution_count":null,"outputs":[]},{"metadata":{"id":"CToqxPhbxbVH","outputId":"71c05f9d-a847-4567-f5cf-da1a5fba30ff","trusted":false},"cell_type":"code","source":"history = model.fit(generator.flow(X_train,y_train,batch_size=64),epochs=200, verbose=2,shuffle=True,validation_data=(X_val,y_val))\npd.DataFrame(history.history)","execution_count":null,"outputs":[]},{"metadata":{"id":"498LuDiOxxU1","outputId":"3b0c257b-5c28-4b36-e6cb-6a42d802e4dd","trusted":false},"cell_type":"code","source":"plt.plot(np.array(history.history['accuracy']) * 100)\nplt.plot(np.array(history.history['val_accuracy']) * 100)\nplt.ylabel('accuracy')\nplt.xlabel('epochs')\nplt.legend(['train', 'validation'])\nplt.title('Accuracy over epochs')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"-C92X2K4x1ml","outputId":"d7c966ad-5c18-4a48-aef1-bc01a83e10b9","trusted":false},"cell_type":"code","source":"scores = model.evaluate(X_test_new, y_test_new)\nprint('Test loss:', scores[0])\nprint('Test accuracy:', scores[1])","execution_count":null,"outputs":[]},{"metadata":{"id":"MnnmgUq3x-xD","trusted":false},"cell_type":"code","source":"# confusion matrix function\n\ndef plot_confusion_matrix(cm, classes, normalize=False,title='Confusion matrix',cmap=plt.cm.Greens):\n    \n    fig = plt.figure(figsize=(10,10))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('Actual label')\n    plt.xlabel('Predicted label')","execution_count":null,"outputs":[]},{"metadata":{"id":"lCcS9QEwx5q7","outputId":"928b4ae7-ee10-4cd6-fce4-14e1993bd419","trusted":false},"cell_type":"code","source":"# Predict the values from the test data\ny_pred = model.predict(X_test_new)\ny_pred_Classes = np.argmax(y_pred, axis = 1) \ntrueY = np.argmax(y_test_new, axis = 1) \n\n# confusion matrix\nconfusionMTX = confusion_matrix(trueY, y_pred_Classes) \n\n# plot the confusion matrix\nplot_confusion_matrix(confusionMTX, classes = labels.classes_) ","execution_count":null,"outputs":[]},{"metadata":{"id":"zVe-JnmcyKPs","outputId":"e3b8b189-f407-4220-e2e4-df09a3e566d5","trusted":false},"cell_type":"code","source":"#Final score and accuracy of the model\n\nscore, acc = model.evaluate(X_test_new,y_test_new)\nscore1, acc1 = model.evaluate(X_train,y_train)\nprint('Test score:', score,'   Test accuracy:', acc)\nprint('Train score:', score1,'   Train accuracy:',acc1)","execution_count":null,"outputs":[]},{"metadata":{"id":"b7YSP4i2yOgs","trusted":false},"cell_type":"code","source":"test_images_path = \"./temp_train/test/*.png\"\n\ntest_images = glob(test_images_path)\ntest_images_arr = []\ntest_files = []\n\nfor img in test_images:\n\n    i = cv2.resize(cv2.imread(img), (128, 128))\n    test_files.append(img.split('/')[-1])\n\n    # Blurred image\n    blurr = cv2.GaussianBlur(i,(5,5),0)\n\n    # HSV image\n    hsv = cv2.cvtColor(blurr,cv2.COLOR_BGR2HSV)\n\n    #Green Parameters\n    sensitivity = 35\n    lower  = np.array([60 - sensitivity, 100, 50])\n    upper = np.array([60 + sensitivity, 255, 255])\n    \n    #Masked image\n    mask = cv2.inRange(hsv,lower,upper)\n    struc = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5))\n    mask = cv2.morphologyEx(mask,cv2.MORPH_CLOSE,struc)\n    \n    #Boolean image\n    boolean = mask>0\n    new = np.zeros_like(i,np.uint8)\n    new[boolean] = i[boolean]\n    test_images_arr.append(new)\n\ntest_X = np.asarray(test_images_arr)\n\n# Normalization of the Image Data\ntest_X = test_X.astype('float32') / 255","execution_count":null,"outputs":[]},{"metadata":{"id":"EAzsyON3yN-8","trusted":false},"cell_type":"code","source":"predictions = model.predict(test_X)\npreds = np.argmax(predictions, axis=1)\npred_str = labels.classes_[preds]\n\n\nfinal_predictions = {'file':test_files, 'species':pred_str}\nfinal_predictions = pd.DataFrame(final_predictions)\nfinal_predictions.to_csv(\"./temp_train/submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}