{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom glob import glob\nfrom keras.utils import np_utils\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import ImageDataGenerator\n\nimport cv2\n%matplotlib inline\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-19T16:02:21.31229Z","iopub.execute_input":"2021-06-19T16:02:21.314598Z","iopub.status.idle":"2021-06-19T16:02:26.314959Z","shell.execute_reply.started":"2021-06-19T16:02:21.314554Z","shell.execute_reply":"2021-06-19T16:02:26.312719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir('/kaggle/input/plant-seedlings-classification')\n","metadata":{"execution":{"iopub.status.busy":"2021-06-19T15:37:05.340625Z","iopub.execute_input":"2021-06-19T15:37:05.340898Z","iopub.status.idle":"2021-06-19T15:37:05.348245Z","shell.execute_reply.started":"2021-06-19T15:37:05.34087Z","shell.execute_reply":"2021-06-19T15:37:05.347434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mainDir = \"/kaggle/input/plant-seedlings-classification/\"\nos.listdir(mainDir + \"train/\")","metadata":{"execution":{"iopub.status.busy":"2021-06-19T16:02:26.320311Z","iopub.execute_input":"2021-06-19T16:02:26.320708Z","iopub.status.idle":"2021-06-19T16:02:26.334201Z","shell.execute_reply.started":"2021-06-19T16:02:26.320681Z","shell.execute_reply":"2021-06-19T16:02:26.333469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T15:38:56.016418Z","iopub.execute_input":"2021-06-19T15:38:56.01684Z","iopub.status.idle":"2021-06-19T15:38:56.252134Z","shell.execute_reply.started":"2021-06-19T15:38:56.016799Z","shell.execute_reply":"2021-06-19T15:38:56.250928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = cv2.imread(mainDir + \"train/Scentless Mayweed/\" + \n                 os.listdir(mainDir + \"train/Scentless Mayweed/\")[0])\n\nim_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nplt.imshow(im_rgb)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T16:19:04.666833Z","iopub.execute_input":"2021-06-19T16:19:04.66716Z","iopub.status.idle":"2021-06-19T16:19:04.836711Z","shell.execute_reply.started":"2021-06-19T16:19:04.667126Z","shell.execute_reply":"2021-06-19T16:19:04.835897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"im_rgb.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-19T16:19:15.062534Z","iopub.execute_input":"2021-06-19T16:19:15.062887Z","iopub.status.idle":"2021-06-19T16:19:15.06861Z","shell.execute_reply.started":"2021-06-19T16:19:15.062852Z","shell.execute_reply":"2021-06-19T16:19:15.067585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Think \n\n## Directory Structure \n--- mainDir\n------ SeedlingType\n--------- Imagename\n\n------ EDA\n\nProcess 1 : Read all images and save and npy file \nProcess 2 : Use Batchgenerator \n\n---- Batch Generator \n\n1) It takes a batch of images\n2) It can apply augmentations \n\n---- CNN Model","metadata":{}},{"cell_type":"markdown","source":"### Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"Imgscale = 80\nrandomSeed = 2021","metadata":{"execution":{"iopub.status.busy":"2021-06-19T16:02:30.881849Z","iopub.execute_input":"2021-06-19T16:02:30.88218Z","iopub.status.idle":"2021-06-19T16:02:30.88691Z","shell.execute_reply.started":"2021-06-19T16:02:30.882148Z","shell.execute_reply":"2021-06-19T16:02:30.88593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Reading images \n\n\npath2images = mainDir + \"train/\" + \"*/*.png\"\n\nallImages = glob(path2images)\n\nimgArray = []\nimgLabel = []\n\ntotalImg = len(allImages)\nfor i,eachImage in enumerate(allImages):\n    print(f\"{i} / {totalImg} \",end = \"\\r\")\n    imgArray.append(cv2.resize(cv2.imread(eachImage),(Imgscale,Imgscale)))\n    imgLabel.append(eachImage.split(\"/\")[-2])\n    \n","metadata":{"execution":{"iopub.status.busy":"2021-06-19T16:02:32.816232Z","iopub.execute_input":"2021-06-19T16:02:32.816559Z","iopub.status.idle":"2021-06-19T16:03:48.478046Z","shell.execute_reply.started":"2021-06-19T16:02:32.816526Z","shell.execute_reply":"2021-06-19T16:03:48.476983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# j = 0\n# for eachImage in allImages:\n#     print(eachImage.split(\"/\")[-2])\n    \n#     j += 1\n    \n#     if j > 2:\n#         break","metadata":{"execution":{"iopub.status.busy":"2021-06-05T04:38:04.735251Z","iopub.execute_input":"2021-06-05T04:38:04.735535Z","iopub.status.idle":"2021-06-05T04:38:04.741574Z","shell.execute_reply.started":"2021-06-05T04:38:04.735507Z","shell.execute_reply":"2021-06-05T04:38:04.740467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(imgArray)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T15:42:54.914684Z","iopub.execute_input":"2021-06-19T15:42:54.915426Z","iopub.status.idle":"2021-06-19T15:42:54.922204Z","shell.execute_reply.started":"2021-06-19T15:42:54.915377Z","shell.execute_reply":"2021-06-19T15:42:54.9211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imgArray = np.asarray(imgArray)\nimgLabel = pd.DataFrame(imgLabel)\n\ntype(imgArray)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T16:03:48.479583Z","iopub.execute_input":"2021-06-19T16:03:48.47994Z","iopub.status.idle":"2021-06-19T16:03:48.522319Z","shell.execute_reply.started":"2021-06-19T16:03:48.479902Z","shell.execute_reply":"2021-06-19T16:03:48.521229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imgLabel.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-19T16:03:48.524128Z","iopub.execute_input":"2021-06-19T16:03:48.524494Z","iopub.status.idle":"2021-06-19T16:03:48.680679Z","shell.execute_reply.started":"2021-06-19T16:03:48.524455Z","shell.execute_reply":"2021-06-19T16:03:48.6796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(imgArray[:3])","metadata":{"execution":{"iopub.status.busy":"2021-06-19T15:43:11.902103Z","iopub.execute_input":"2021-06-19T15:43:11.902468Z","iopub.status.idle":"2021-06-19T15:43:11.908609Z","shell.execute_reply.started":"2021-06-19T15:43:11.902439Z","shell.execute_reply":"2021-06-19T15:43:11.907297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Let's see some examples \nplt.figure(figsize=(10, 10))\n\nfor j,img in enumerate(imgArray[:8]):\n    plt.subplot(4, 2, j+1)\n    im_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    plt.imshow(im_rgb)\n    plt.axis(\"off\")\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-19T15:43:15.194101Z","iopub.execute_input":"2021-06-19T15:43:15.194631Z","iopub.status.idle":"2021-06-19T15:43:15.743533Z","shell.execute_reply.started":"2021-06-19T15:43:15.194576Z","shell.execute_reply":"2021-06-19T15:43:15.742144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Let's see some examples \nplt.figure(figsize=(10, 10))\n\nfor j,img in enumerate(imgArray[:1]):\n    plt.subplot(4, 2, j+1)\n    ### Gaussian Blur \n    imgBlur = cv2.GaussianBlur(img,(5,5),0)\n    img_rgb = cv2.cvtColor(imgBlur, cv2.COLOR_BGR2RGB)\n    img_hsv = cv2.cvtColor(imgBlur, cv2.COLOR_BGR2HSV)\n    \n    ### mask creation -- green color \n    \n    greenLow = (25,40,50)\n    greenUp = (75,255,255)\n    mask = cv2.inRange(img_hsv,greenLow,greenUp)\n    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(11,11))\n    mask = cv2.morphologyEx(mask,cv2.MORPH_CLOSE,kernel)\n    \n    \n    bMask = mask > 0 \n    \n    clear = np.zeros_like(img,np.uint8)\n    clear[bMask] = img[bMask]\n    \n    plt.subplot(2, 3, 1); plt.imshow(img)  # Show the original image\n    plt.subplot(2, 3, 2); plt.imshow(imgBlur)  # Blur image\n    plt.subplot(2, 3, 3); plt.imshow(img_hsv)  # HSV image\n    plt.subplot(2, 3, 4); plt.imshow(mask)  # Mask\n    plt.subplot(2, 3, 5); plt.imshow(bMask)  # Boolean mask\n    plt.subplot(2, 3, 6); plt.imshow(clear)  # Image without background\n    \n    \n    \n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-19T15:47:01.578577Z","iopub.execute_input":"2021-06-19T15:47:01.578968Z","iopub.status.idle":"2021-06-19T15:47:02.472606Z","shell.execute_reply.started":"2021-06-19T15:47:01.57893Z","shell.execute_reply":"2021-06-19T15:47:02.471222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def imgCleaner(img):\n    imgBlur = cv2.GaussianBlur(img,(5,5),0)\n    img_rgb = cv2.cvtColor(imgBlur, cv2.COLOR_BGR2RGB)\n    img_hsv = cv2.cvtColor(imgBlur, cv2.COLOR_BGR2HSV)\n    ### mask creation -- green color \n    greenLow = (25,40,50)\n    greenUp = (75,255,255)\n    mask = cv2.inRange(img_hsv,greenLow,greenUp)\n    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(11,11))\n    mask = cv2.morphologyEx(mask,cv2.MORPH_CLOSE,kernel)\n    bMask = mask > 0 \n    clear = np.zeros_like(img,np.uint8)\n    clear[bMask] = img[bMask]\n    return clear","metadata":{"execution":{"iopub.status.busy":"2021-06-19T16:03:48.682712Z","iopub.execute_input":"2021-06-19T16:03:48.683103Z","iopub.status.idle":"2021-06-19T16:03:48.691547Z","shell.execute_reply.started":"2021-06-19T16:03:48.683065Z","shell.execute_reply":"2021-06-19T16:03:48.690693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Let's see some examples \nplt.figure(figsize=(10, 10))\n\nfor j,img in enumerate(imgArray[:8]):\n    plt.subplot(4, 2, j+1)\n    im_cleaned = imgCleaner(img)\n    plt.imshow(im_cleaned)\n    plt.axis(\"off\")\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-19T15:48:41.186974Z","iopub.execute_input":"2021-06-19T15:48:41.187933Z","iopub.status.idle":"2021-06-19T15:48:41.68547Z","shell.execute_reply.started":"2021-06-19T15:48:41.187873Z","shell.execute_reply":"2021-06-19T15:48:41.684169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imgArrayCleaned = []\nfor j,img in enumerate(imgArray):\n    im_cleaned = imgCleaner(img)\n    imgArrayCleaned.append(im_cleaned)\n    \n    \nimgArrayCleaned = np.asarray(imgArrayCleaned)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T16:03:48.692808Z","iopub.execute_input":"2021-06-19T16:03:48.693314Z","iopub.status.idle":"2021-06-19T16:03:50.272829Z","shell.execute_reply.started":"2021-06-19T16:03:48.693278Z","shell.execute_reply":"2021-06-19T16:03:50.271926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imgArrayCleaned.shape,imgArray.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-19T16:03:50.274268Z","iopub.execute_input":"2021-06-19T16:03:50.274606Z","iopub.status.idle":"2021-06-19T16:03:50.281743Z","shell.execute_reply.started":"2021-06-19T16:03:50.274571Z","shell.execute_reply":"2021-06-19T16:03:50.280653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imgArrayCleaned = imgArrayCleaned / 255\n","metadata":{"execution":{"iopub.status.busy":"2021-06-19T16:03:50.282985Z","iopub.execute_input":"2021-06-19T16:03:50.283427Z","iopub.status.idle":"2021-06-19T16:03:50.519101Z","shell.execute_reply.started":"2021-06-19T16:03:50.283386Z","shell.execute_reply":"2021-06-19T16:03:50.518179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Labels","metadata":{}},{"cell_type":"code","source":"imgLabel[0].value_counts().plot(kind = 'bar')","metadata":{"execution":{"iopub.status.busy":"2021-06-19T16:03:50.521186Z","iopub.execute_input":"2021-06-19T16:03:50.521561Z","iopub.status.idle":"2021-06-19T16:03:50.704095Z","shell.execute_reply.started":"2021-06-19T16:03:50.521522Z","shell.execute_reply":"2021-06-19T16:03:50.70337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Steps to encode labels from text to one hot encoding\n## Step 1 -- Label encoding \n\nlabEnc = preprocessing.LabelEncoder()\nimgLabelEncode = labEnc.fit_transform(imgLabel[0])\nprint(\"Classes: \" + str(labEnc.classes_))\nnum_clases = len(labEnc.classes_)\nprint(f\"Number of classes are {num_clases}\")\n\n### Step 2 -- One Hot encoding using keras np_utils\n\nimgLabelOhe = np_utils.to_categorical(imgLabelEncode)\nimgLabelOhe[1]","metadata":{"execution":{"iopub.status.busy":"2021-06-19T16:03:54.081641Z","iopub.execute_input":"2021-06-19T16:03:54.081973Z","iopub.status.idle":"2021-06-19T16:03:54.091639Z","shell.execute_reply.started":"2021-06-19T16:03:54.081942Z","shell.execute_reply":"2021-06-19T16:03:54.090804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### CNN Model","metadata":{}},{"cell_type":"code","source":"### Data Split \ntrainImgX, testImgX,trainImgY,testImgY = train_test_split(imgArrayCleaned,imgLabelOhe,test_size = .15,\n                                                         random_state = randomSeed,stratify = imgLabelOhe)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-19T16:03:57.180376Z","iopub.execute_input":"2021-06-19T16:03:57.180691Z","iopub.status.idle":"2021-06-19T16:03:57.488588Z","shell.execute_reply.started":"2021-06-19T16:03:57.180663Z","shell.execute_reply":"2021-06-19T16:03:57.487596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Datagenerator","metadata":{}},{"cell_type":"code","source":"dataGen = ImageDataGenerator(rotation_range=180,zoom_range=.1,width_shift_range=.1,height_shift_range = .1,\n                             horizontal_flip=True,vertical_flip=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T16:04:00.206927Z","iopub.execute_input":"2021-06-19T16:04:00.207266Z","iopub.status.idle":"2021-06-19T16:04:00.211588Z","shell.execute_reply.started":"2021-06-19T16:04:00.207232Z","shell.execute_reply":"2021-06-19T16:04:00.210563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataGen.fit(trainImgX)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T16:04:00.543865Z","iopub.execute_input":"2021-06-19T16:04:00.544311Z","iopub.status.idle":"2021-06-19T16:04:00.800262Z","shell.execute_reply.started":"2021-06-19T16:04:00.544268Z","shell.execute_reply":"2021-06-19T16:04:00.7992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Flatten,GlobalMaxPooling2D\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import RMSprop, Adam\n","metadata":{"execution":{"iopub.status.busy":"2021-06-19T16:04:03.816552Z","iopub.execute_input":"2021-06-19T16:04:03.816873Z","iopub.status.idle":"2021-06-19T16:04:03.821696Z","shell.execute_reply.started":"2021-06-19T16:04:03.816842Z","shell.execute_reply":"2021-06-19T16:04:03.820856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(randomSeed)  # Fix seed\n","metadata":{"execution":{"iopub.status.busy":"2021-06-19T16:04:04.042903Z","iopub.execute_input":"2021-06-19T16:04:04.043225Z","iopub.status.idle":"2021-06-19T16:04:04.04885Z","shell.execute_reply.started":"2021-06-19T16:04:04.043168Z","shell.execute_reply":"2021-06-19T16:04:04.048045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ModelCNN_Small(num_clases):\n\n    model = Sequential()\n    model.add(Conv2D(32, (5,5), padding='same', activation=\"relu\", input_shape=(128, 128, 3)))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D((2, 2)))\n    # model.add(layers.Dropout(0.2))\n    model.add(Conv2D(64, (3,3), padding='same', activation=\"relu\"))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D((2, 2)))\n    # model.add(layers.Dropout(0.3))\n    model.add(Conv2D(64, (3, 3), padding='same', activation=\"relu\"))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D((2, 2)))\n    # model.add(layers.Dropout(0.4))\n    model.add(Conv2D(128, (3, 3), padding='same', activation=\"relu\"))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D((2, 2)))\n  \n    model.add(GlobalMaxPooling2D())\n    ## ANN \n    model.add(Dense(64, activation=\"relu\"))\n    \n\n    model.add(Dense(num_clases, activation=\"softmax\"))\n\n    optimizer = Adam(learning_rate=0.001,beta_1=0.9,epsilon=1e-07,amsgrad=False,name='Adam')\n    model.compile(optimizer = optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-06-19T16:04:05.497923Z","iopub.execute_input":"2021-06-19T16:04:05.498266Z","iopub.status.idle":"2021-06-19T16:04:05.508016Z","shell.execute_reply.started":"2021-06-19T16:04:05.498234Z","shell.execute_reply":"2021-06-19T16:04:05.506948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def CNNModel(num_clases):\n    model = Sequential()\n\n    model.add(Conv2D(filters=64, kernel_size=(5, 5), input_shape=(Imgscale, Imgscale, 3), activation='relu'))\n    model.add(BatchNormalization(axis=3))\n    model.add(Conv2D(filters=64, kernel_size=(5, 5), activation='relu'))\n    model.add(MaxPooling2D((2, 2)))\n    model.add(BatchNormalization(axis=3))\n    model.add(Dropout(0.1))\n\n    model.add(Conv2D(filters=128, kernel_size=(5, 5), activation='relu'))\n    model.add(BatchNormalization(axis=3))\n    model.add(Conv2D(filters=128, kernel_size=(5, 5), activation='relu'))\n    model.add(MaxPooling2D((2, 2)))\n    model.add(BatchNormalization(axis=3))\n    model.add(Dropout(0.1))\n\n    model.add(Conv2D(filters=256, kernel_size=(5, 5), activation='relu'))\n    model.add(BatchNormalization(axis=3))\n    model.add(Conv2D(filters=256, kernel_size=(5, 5), activation='relu'))\n    model.add(MaxPooling2D((2, 2)))\n    model.add(BatchNormalization(axis=3))\n    model.add(Dropout(0.1))\n\n    model.add(Flatten())\n\n    model.add(Dense(256, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n\n    model.add(Dense(256, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n\n    model.add(Dense(num_clases, activation='softmax'))\n\n    model.summary()\n\n    # compile model\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-06-05T08:55:18.051821Z","iopub.execute_input":"2021-06-05T08:55:18.052198Z","iopub.status.idle":"2021-06-05T08:55:18.066891Z","shell.execute_reply.started":"2021-06-05T08:55:18.052166Z","shell.execute_reply":"2021-06-05T08:55:18.065797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger,EarlyStopping\n# learning rate reduction\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.4, \n                                            min_lr=0.00001)\n\n\nearly_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.001, patience=10)\n\n# checkpoints\nfilepath=\"./weights.best_{epoch:02d}-{val_loss:.2f}.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_loss', \n                             verbose=1, save_best_only=True, mode='auto')\nfilepath=\"./weights.last_auto4.hdf5\"\ncheckpoint_all = ModelCheckpoint(filepath, monitor='val_loss', \n                                 verbose=1, save_best_only=False, mode='auto')\n\n\n# all callbacks\ncallbacks_list = [checkpoint, learning_rate_reduction,early_stopping]","metadata":{"execution":{"iopub.status.busy":"2021-06-19T16:04:09.405608Z","iopub.execute_input":"2021-06-19T16:04:09.405946Z","iopub.status.idle":"2021-06-19T16:04:09.413903Z","shell.execute_reply.started":"2021-06-19T16:04:09.405915Z","shell.execute_reply":"2021-06-19T16:04:09.412781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainGen = dataGen.flow(trainImgX, trainImgY, batch_size=64)\nvalidGen = dataGen.flow(testImgX, testImgY, batch_size=64)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T16:04:10.578035Z","iopub.execute_input":"2021-06-19T16:04:10.578381Z","iopub.status.idle":"2021-06-19T16:04:10.723507Z","shell.execute_reply.started":"2021-06-19T16:04:10.57835Z","shell.execute_reply":"2021-06-19T16:04:10.722629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = ModelCNN_Small(num_clases)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T16:04:10.873635Z","iopub.execute_input":"2021-06-19T16:04:10.874012Z","iopub.status.idle":"2021-06-19T16:04:12.925313Z","shell.execute_reply.started":"2021-06-19T16:04:10.873972Z","shell.execute_reply":"2021-06-19T16:04:12.924493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist = model.fit_generator(trainGen, \n                           epochs=40, validation_data=validGen, \n                           steps_per_epoch=trainImgX.shape[0]//64,callbacks=callbacks_list )","metadata":{"execution":{"iopub.status.busy":"2021-06-19T16:04:15.024624Z","iopub.execute_input":"2021-06-19T16:04:15.024958Z","iopub.status.idle":"2021-06-19T16:09:24.989109Z","shell.execute_reply.started":"2021-06-19T16:04:15.024928Z","shell.execute_reply":"2021-06-19T16:09:24.988219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Training Graphs","metadata":{}},{"cell_type":"code","source":"plt.plot(hist.history['loss'], label='loss')\nplt.plot(hist.history['val_loss'], label = 'val_loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\n# plt.ylim([0.5, 1])\nplt.legend(loc='lower right');","metadata":{"execution":{"iopub.status.busy":"2021-06-19T16:10:48.048608Z","iopub.execute_input":"2021-06-19T16:10:48.048944Z","iopub.status.idle":"2021-06-19T16:10:48.197419Z","shell.execute_reply.started":"2021-06-19T16:10:48.048912Z","shell.execute_reply":"2021-06-19T16:10:48.196453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(hist.history['accuracy'], label='accuracy')\nplt.plot(hist.history['val_accuracy'], label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\n# plt.ylim([0.5, 1])\nplt.legend(loc='lower right');","metadata":{"execution":{"iopub.status.busy":"2021-06-19T16:10:59.204844Z","iopub.execute_input":"2021-06-19T16:10:59.205175Z","iopub.status.idle":"2021-06-19T16:10:59.361031Z","shell.execute_reply.started":"2021-06-19T16:10:59.205144Z","shell.execute_reply":"2021-06-19T16:10:59.360081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Evaluation","metadata":{}},{"cell_type":"code","source":"print(model.evaluate(testImgX, testImgY))  # Evaluate on test set\n","metadata":{"execution":{"iopub.status.busy":"2021-06-19T16:11:27.514758Z","iopub.execute_input":"2021-06-19T16:11:27.515079Z","iopub.status.idle":"2021-06-19T16:11:28.339822Z","shell.execute_reply.started":"2021-06-19T16:11:27.51505Z","shell.execute_reply":"2021-06-19T16:11:28.339004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Confusion Matrix","metadata":{}},{"cell_type":"code","source":"# Predict the values from the validation dataset\nY_pred = model.predict(testImgX)\n# Convert predictions classes to one hot vectors \nresult = np.argmax(Y_pred, axis=1)\n# Convert validation observations to one hot vectors\nY_true = np.argmax(testImgY, axis=1)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\n\nconf_mat = confusion_matrix(Y_true, result)\n\ndf_cm = pd.DataFrame(conf_mat, index = [i for i in range(0, 12)],\n                  columns = [i for i in range(0, 12)])\nplt.figure(figsize = (10,7))\nsns.heatmap(df_cm, annot=True, fmt='g');","metadata":{"execution":{"iopub.status.busy":"2021-06-19T16:11:31.632201Z","iopub.execute_input":"2021-06-19T16:11:31.632537Z","iopub.status.idle":"2021-06-19T16:11:32.961513Z","shell.execute_reply.started":"2021-06-19T16:11:31.632506Z","shell.execute_reply":"2021-06-19T16:11:32.960702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Some Examples","metadata":{}},{"cell_type":"code","source":"X_test  = testImgX\ny_test = testImgY\nplt.figure(figsize=(2,2))\nplt.imshow(X_test[3],cmap=\"gray\")\nplt.show()\nprint('Predicted Label', np.argmax(model.predict(X_test[3].reshape(1,Imgscale,Imgscale,3))))\nprint('True Label', np.argmax(y_test[3]))\n\nplt.figure(figsize=(2,2))\nplt.imshow(X_test[2],cmap=\"gray\")\nplt.show()\nprint('Predicted Label', np.argmax(model.predict(X_test[2].reshape(1,Imgscale,Imgscale,3))))\nprint('True Label', np.argmax(y_test[2]))\n\nplt.figure(figsize=(2,2))\nplt.imshow(X_test[33],cmap=\"gray\")\nplt.show()\nprint('Predicted Label', np.argmax(model.predict(X_test[33].reshape(1,Imgscale,Imgscale,3))))\nprint('True Label', np.argmax(y_test[33]))\n\nplt.figure(figsize=(2,2))\nplt.imshow(X_test[59],cmap=\"gray\")\nplt.show()\nprint('Predicted Label', np.argmax(model.predict(X_test[59].reshape(1,Imgscale,Imgscale,3))))\nprint('True Label', np.argmax(y_test[59]))\n\nplt.figure(figsize=(2,2))\nplt.imshow(X_test[36],cmap=\"gray\")\nplt.show()\nprint('Predicted Label', np.argmax(model.predict(X_test[36].reshape(1,Imgscale,Imgscale,3))))\nprint('True Label', np.argmax(y_test[36]))","metadata":{"execution":{"iopub.status.busy":"2021-06-19T16:12:02.234159Z","iopub.execute_input":"2021-06-19T16:12:02.234529Z","iopub.status.idle":"2021-06-19T16:12:02.858903Z","shell.execute_reply.started":"2021-06-19T16:12:02.234495Z","shell.execute_reply":"2021-06-19T16:12:02.858103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Visualisation of Feature Maps ( Activation Maps)","metadata":{}},{"cell_type":"markdown","source":"Load the trained model ( We need to create model and then just load the weights)","metadata":{}},{"cell_type":"code","source":"modelTrained = ModelCNN_Small(num_clases=num_clases)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T16:14:37.875201Z","iopub.execute_input":"2021-06-19T16:14:37.875547Z","iopub.status.idle":"2021-06-19T16:14:37.981706Z","shell.execute_reply.started":"2021-06-19T16:14:37.875513Z","shell.execute_reply":"2021-06-19T16:14:37.980784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modelTrained.load_weights(\"./weights.best_36-0.36.hdf5\")\n","metadata":{"execution":{"iopub.status.busy":"2021-06-19T16:15:13.711497Z","iopub.execute_input":"2021-06-19T16:15:13.711835Z","iopub.status.idle":"2021-06-19T16:15:13.740274Z","shell.execute_reply.started":"2021-06-19T16:15:13.711802Z","shell.execute_reply":"2021-06-19T16:15:13.739419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# modelTrained.load_weights(\"../input/trainedmodelplantseed/weights.best_01-25.64.hdf5\")\n","metadata":{"execution":{"iopub.status.busy":"2021-06-05T08:49:17.606236Z","iopub.execute_input":"2021-06-05T08:49:17.606588Z","iopub.status.idle":"2021-06-05T08:49:18.184139Z","shell.execute_reply.started":"2021-06-05T08:49:17.606561Z","shell.execute_reply":"2021-06-05T08:49:18.183125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(cv2.resize(im_rgb,(128,128)))","metadata":{"execution":{"iopub.status.busy":"2021-06-19T16:21:06.417042Z","iopub.execute_input":"2021-06-19T16:21:06.417423Z","iopub.status.idle":"2021-06-19T16:21:06.577918Z","shell.execute_reply.started":"2021-06-19T16:21:06.417382Z","shell.execute_reply":"2021-06-19T16:21:06.57694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"layer_outputs = [layer.output for layer in modelTrained.layers[1:7]]\nactivation_model = Model(inputs=modelTrained.input,outputs=layer_outputs)\nactivations = activation_model.predict(cv2.resize(im_rgb,(128,128)).reshape(1,128,128,3))\nlayer_names = []\nfor layer in modelTrained.layers[1:7]:\n    layer_names.append(layer.name) # Names of the layers, so you can have them as part of your plot\n    \n\nimages_per_row = 16\nfor layer_name, layer_activation in zip(layer_names, activations): # Displays the feature maps\n    n_features = layer_activation.shape[-1] # Number of features in the feature map\n    size = layer_activation.shape[1] #The feature map has shape (1, size, size, n_features).\n    n_cols = n_features // images_per_row # Tiles the activation channels in this matrix\n    display_grid = np.zeros((size * n_cols, images_per_row * size))\n    for col in range(n_cols): # Tiles each filter into a big horizontal grid\n        for row in range(images_per_row):\n            channel_image = layer_activation[0,\n                                             :, :,\n                                             col * images_per_row + row]\n            channel_image -= channel_image.mean() # Post-processes the feature to make it visually palatable\n            channel_image /= channel_image.std()\n            channel_image *= 64\n            channel_image += 128\n            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n            display_grid[col * size : (col + 1) * size, # Displays the grid\n                         row * size : (row + 1) * size] = channel_image\n    scale = 1. / size\n    plt.figure(figsize=(scale * display_grid.shape[1],\n                        scale * display_grid.shape[0]))\n    plt.title(layer_name)\n    plt.grid(False)\n    plt.imshow(display_grid, aspect='auto', cmap='viridis')\n","metadata":{"execution":{"iopub.status.busy":"2021-06-19T16:20:45.843581Z","iopub.execute_input":"2021-06-19T16:20:45.843901Z","iopub.status.idle":"2021-06-19T16:20:47.367924Z","shell.execute_reply.started":"2021-06-19T16:20:45.84387Z","shell.execute_reply":"2021-06-19T16:20:47.366949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# layer_outputs = [layer.output for layer in model.layers[1:7]]\n# activation_model = Model(inputs=model.input,outputs=layer_outputs)\n# activations = activation_model.predict(testImgX[3].reshape(1,scale,scale,3))\n","metadata":{"execution":{"iopub.status.busy":"2021-06-19T16:22:00.368924Z","iopub.execute_input":"2021-06-19T16:22:00.369253Z","iopub.status.idle":"2021-06-19T16:22:00.372728Z","shell.execute_reply.started":"2021-06-19T16:22:00.36922Z","shell.execute_reply":"2021-06-19T16:22:00.371684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# layer_names = []\n# for layer in model.layers[1:7]:\n#     layer_names.append(layer.name) # Names of the layers, so you can have them as part of your plot\n    \n\n# images_per_row = 16\n# for layer_name, layer_activation in zip(layer_names, activations): # Displays the feature maps\n#     n_features = layer_activation.shape[-1] # Number of features in the feature map\n#     size = layer_activation.shape[1] #The feature map has shape (1, size, size, n_features).\n#     n_cols = n_features // images_per_row # Tiles the activation channels in this matrix\n#     display_grid = np.zeros((size * n_cols, images_per_row * size))\n#     for col in range(n_cols): # Tiles each filter into a big horizontal grid\n#         for row in range(images_per_row):\n#             channel_image = layer_activation[0,\n#                                              :, :,\n#                                              col * images_per_row + row]\n#             channel_image -= channel_image.mean() # Post-processes the feature to make it visually palatable\n#             channel_image /= channel_image.std()\n#             channel_image *= 64\n#             channel_image += 128\n#             channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n#             display_grid[col * size : (col + 1) * size, # Displays the grid\n#                          row * size : (row + 1) * size] = channel_image\n#     scale = 1. / size\n#     plt.figure(figsize=(scale * display_grid.shape[1],\n#                         scale * display_grid.shape[0]))\n#     plt.title(layer_name)\n#     plt.grid(False)\n#     plt.imshow(display_grid, aspect='auto', cmap='viridis')","metadata":{"execution":{"iopub.status.busy":"2021-06-19T16:22:03.86963Z","iopub.execute_input":"2021-06-19T16:22:03.869942Z","iopub.status.idle":"2021-06-19T16:22:03.874021Z","shell.execute_reply.started":"2021-06-19T16:22:03.869913Z","shell.execute_reply":"2021-06-19T16:22:03.873144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idg = ImageDataGenerator(\n    rescale=1./255,\n    #rotation_range=20, # You can uncomment these parameters to make you generator rotate & flip the images to put the train model in stricter conditions.\n    #width_shift_range=0.2,\n    #height_shift_range=0.2,\n    horizontal_flip=True,\n    vertical_flip=True,\n    validation_split=0.2\n)","metadata":{"execution":{"iopub.status.busy":"2021-06-05T08:51:11.912093Z","iopub.execute_input":"2021-06-05T08:51:11.912512Z","iopub.status.idle":"2021-06-05T08:51:11.916698Z","shell.execute_reply.started":"2021-06-05T08:51:11.912476Z","shell.execute_reply":"2021-06-05T08:51:11.916094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mainDir","metadata":{"execution":{"iopub.status.busy":"2021-06-05T08:51:24.582651Z","iopub.execute_input":"2021-06-05T08:51:24.582998Z","iopub.status.idle":"2021-06-05T08:51:24.588884Z","shell.execute_reply.started":"2021-06-05T08:51:24.582968Z","shell.execute_reply":"2021-06-05T08:51:24.588189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_gen = idg.flow_from_directory(mainDir + 'train/',\n                                                    target_size=(Imgscale, Imgscale),\n                                                    subset='training',\n                                                    class_mode='categorical',\n                                                    batch_size=64,\n                                                    shuffle=True,\n                                                    seed=1\n                                                )","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:00:47.150144Z","iopub.execute_input":"2021-06-05T09:00:47.150904Z","iopub.status.idle":"2021-06-05T09:00:47.389883Z","shell.execute_reply.started":"2021-06-05T09:00:47.150854Z","shell.execute_reply":"2021-06-05T09:00:47.38865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_gen = idg.flow_from_directory(mainDir + 'train/',\n                                                   target_size=(Imgscale, Imgscale),                                                   \n                                                   subset='validation',\n                                                   class_mode='categorical',\n                                                   batch_size=64,\n                                                   shuffle=True,\n                                                   seed=1\n                                                )","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:00:47.517707Z","iopub.execute_input":"2021-06-05T09:00:47.518095Z","iopub.status.idle":"2021-06-05T09:00:47.630073Z","shell.execute_reply.started":"2021-06-05T09:00:47.518059Z","shell.execute_reply":"2021-06-05T09:00:47.629106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2train = CNNModel(num_clases=num_clases)","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:00:48.400558Z","iopub.execute_input":"2021-06-05T09:00:48.400991Z","iopub.status.idle":"2021-06-05T09:00:48.677855Z","shell.execute_reply.started":"2021-06-05T09:00:48.40093Z","shell.execute_reply":"2021-06-05T09:00:48.676771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"historyNew = model2train.fit_generator(train_gen,\n          epochs=2,\n        steps_per_epoch= 500,validation_steps = 100,\n        validation_data=val_gen,verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:00:54.236842Z","iopub.execute_input":"2021-06-05T09:00:54.237454Z","iopub.status.idle":"2021-06-05T09:07:49.029284Z","shell.execute_reply.started":"2021-06-05T09:00:54.237413Z","shell.execute_reply":"2021-06-05T09:07:49.028233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}