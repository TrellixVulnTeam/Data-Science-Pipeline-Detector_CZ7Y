{"cells":[{"metadata":{"_uuid":"fb081ca8bc61f4bb87b826ba199f1ca02f34d225"},"cell_type":"markdown","source":"<h1 id=\"Use-Keras-Pretrained-Models-dataset\">1. Use Keras Pretrained Models dataset<a class=\"anchor-link\" href=\"#Use-Keras-Pretrained-Models-dataset\" target=\"_self\">Â¶</a></h1><p>Kernels can't use network connection to download pretrained keras model weights.\nThis dataset helps you to apply your favorite pretrained model in the Kaggle Kernel environment. \nYou can find more details <a href=\"https://www.kaggle.com/gaborfodor/keras-pretrained-models\" target=\"_top\">here</a>.</p>\n<p>We have to copy the pretrained models to the cache directory (~/.keras/models) where keras is looking for them.</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"import fnmatch\nimport os\nimport numpy as np\nimport pandas as pd\nfrom tensorflow.keras.applications.vgg19 import preprocess_input\nfrom tensorflow.keras.preprocessing import image\nfrom tqdm.notebook import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom kaggle_datasets import KaggleDatasets\nimport gc\nfrom IPython.display import SVG\nimport cv2\nnp.random.seed(21)\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nprint(os.listdir('../input/plant-seedlings-classification/train/'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dbc0a7f8f1a4546ee0c1fde0913df1a50ea24628"},"cell_type":"code","source":"path = '../input/plant-seedlings-classification/train/'\ntrain_label = []\ntrain_img = []\nlabel2num = {'Loose Silky-bent':0, 'Charlock':1, 'Sugar beet':2, 'Small-flowered Cranesbill':3,\n             'Common Chickweed':4, 'Common wheat':5, 'Maize':6, 'Cleavers':7, 'Scentless Mayweed':8,\n             'Fat Hen':9, 'Black-grass':10, 'Shepherds Purse':11}\nfor i in tqdm(os.listdir(path)):\n    label_number = label2num[i]\n    new_path = path+i+'/'\n    for j in fnmatch.filter(os.listdir(new_path), '*.png'):\n        temp_img = image.load_img(new_path+j, target_size=(200,200))\n        train_label.append(label_number)\n        temp_img = image.img_to_array(temp_img)\n        train_img.append(temp_img)\n\ntrain_img = np.array(train_img)\n\ntrain_y=pd.get_dummies(train_label)\ntrain_y = np.array(train_y)\ntrain_img=preprocess_input(train_img)\n\nprint('Training data shape: ', train_img.shape)\nprint('Training labels shape: ', train_y.shape)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\ntf.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Detect hardware, return appropriate distribution strategy\ntry:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n    # set: this is always the case on Kaggle.\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"AUTO = tf.data.experimental.AUTOTUNE\nBATCH_SIZE = 32 * strategy.num_replicas_in_sync\nEPOCHS = 20","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(train_img,train_y, test_size=0.2, random_state = 42)\n\nX_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\nX_train /= 255\nX_test /= 255\ny_train = np.array(y_train, dtype=\"float32\")\ny_test = np.array(y_test, dtype=\"float32\")\n\nprint('x_train shape:', X_train.shape)\nprint(X_train.shape[0], 'train samples')\nprint(X_test.shape[0], 'test samples')\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def convert(image, label):\n#     image = tf.image.convert_image_dtype(image, tf.float32) # Cast and normalize the image to [0,1]\n#     return image, label\n\n# def flip_aug(image,label):\n#     image,label = convert(image, label)\n#     image = tf.image.convert_image_dtype(image, tf.float32) # Cast and normalize the image to [0,1]\n#     image = tf.image.flip_left_right(image)\n#     return image,label\n\n# def rotate_aug(image,label):\n#     image,label = convert(image, label)\n#     image = tf.image.convert_image_dtype(image, tf.float32) # Cast and normalize the image to [0,1]\n#     image = tf.image.rot90(image)\n#     return image,label\n\n# def crop_aug(image,label):\n#     image,label = convert(image, label)\n#     image = tf.image.convert_image_dtype(image, tf.float32) # Cast and normalize the image to [0,1]\n#     image = tf.image.central_crop(image, central_fraction=0.8)\n#     return image,label\n\n\n# def pad_light_aug(image,label):\n#     image,label = convert(image, label)\n#     image = tf.image.convert_image_dtype(image, tf.float32) # Cast and normalize the image to [0,1]\n#     image = tf.image.resize_with_crop_or_pad(image, 220, 220) # Add 6 pixels of padding\n#     image = tf.image.random_crop(image, size=[220, 220, 3]) # Random crop back to 224x224x3\n#     image = tf.image.random_brightness(image, max_delta=0.5) # Random brightness\n#     return image,label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_dataset = (\n#     tf.data.Dataset\n#     .from_tensor_slices((X_train, y_train))\n#     .repeat()\n#     .map(flip_aug, num_parallel_calls=AUTO)\n#     .map(rotate_aug, num_parallel_calls=AUTO)\n#     .map(crop_aug, num_parallel_calls=AUTO)\n#     .map(pad_light_aug, num_parallel_calls=AUTO)\n#     .batch(BATCH_SIZE)\n#     .prefetch(AUTO)\n# )\n\n# valid_dataset = (\n#     tf.data.Dataset\n#     .from_tensor_slices((X_test, y_test))\n#     .batch(BATCH_SIZE)\n#     .cache()\n#     .prefetch(AUTO)\n# )\n# gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"34b8442bd17bd8e0c1fc0869a80ffffec14d2b68"},"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras.models import Sequential,Model\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Activation\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ndef vgg16_model(num_classes=None):\n\n    model = VGG16(weights='imagenet', include_top=False,input_shape=(200,200,3))\n    model.trainable = False\n    \n    x=Conv2D(256, kernel_size=(2,2),strides=2)(model.output)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)    \n    x=Conv2D(128, kernel_size=(2,2),strides=1)(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x=Flatten()(x)\n    x=Dense(num_classes, activation='softmax')(x)\n\n    model=Model(model.input,x)\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8ee3a2a961051c2c6be00148756123253184a69f"},"cell_type":"code","source":"def precision(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives + K.epsilon())\n    return precision\n\n\ndef recall(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    recall = true_positives / (possible_positives + K.epsilon())\n    return recall\n\n\ndef fscore(y_true, y_pred):\n    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n        return 0\n\n    p = precision(y_true, y_pred)\n    r = recall(y_true, y_pred)\n    f_score = 2 * (p * r) / (p + r + K.epsilon())\n    return f_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b75c616941d39ffb3884172f9ee5e889e9293698"},"cell_type":"code","source":"from keras import backend as K\nwith strategy.scope():\n    num_classes=12\n    model = vgg16_model(num_classes)\n    optimizer = tf.optimizers.Adam(lr=3e-5 * strategy.num_replicas_in_sync)\n    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy',fscore])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_input_fn(batch_size=1024):\n    # Convert the inputs to a Dataset.\n    dataset = tf.data.Dataset.from_tensor_slices((x_train,y_train))\n\n    # Shuffle, repeat, and batch the examples.\n    dataset = dataset.cache() # Loads the data into memory since its such a small dataset\n    dataset = dataset.shuffle(1000, reshuffle_each_iteration=True)\n    dataset = dataset.repeat() \n    dataset = dataset.batch(batch_size, drop_remainder=True)\n\n\n    # Return the dataset.\n    return dataset\n\ndef test_input_fn(batch_size=1024):\n    # Convert the inputs to a Dataset.\n    dataset = tf.data.Dataset.from_tensor_slices((x_test,y_test))\n\n    # Shuffle, repeat, and batch the examples.\n    dataset = dataset.cache()\n    dataset = dataset.shuffle(1000, reshuffle_each_iteration=True)\n    dataset = dataset.repeat()\n    dataset = dataset.batch(batch_size, drop_remainder=True)\n\n\n    # Return the dataset.\n    return dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint\n\nmodel_checkpoint = ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True)\n\nmodel.fit(train_input_fn,\n          batch_size=128,epochs=20, \n          verbose=1, shuffle=True, \n          validation_data=(test_input_fn), callbacks=[model_checkpoint])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8c84c400c60f0eaca879c56ddc61060277712115"},"cell_type":"code","source":"# #Split training data into rain set and validation set\n# from sklearn.model_selection import train_test_split\n# X_train, X_valid, Y_train, Y_valid=train_test_split(train_img,train_y,test_size=0.1, random_state=42)\n\n# #Data augmentation\n# '''from keras.preprocessing.image import ImageDataGenerator\n# gen_train = ImageDataGenerator( \n#     rotation_range=30,\n#     width_shift_range=0.2,\n#    height_shift_range=0.2,\n#     horizontal_flip=True,\n#     vertical_flip=True\n\n# )\n# gen_train.fit(X_train)\n\n# #Train model\n# from keras.callbacks import ModelCheckpoint\n# epochs = 10\n# batch_size = 32\n# model_checkpoint = ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True)\n\n# model.fit_generator(gen_train.flow(X_train, Y_train, batch_size=batch_size, shuffle=True), \n#                     steps_per_epoch=(X_train.shape[0]//(4*batch_size)), \n#                     epochs=epochs, \n#                     validation_data=(X_valid,Y_valid),\n#                     callbacks=[model_checkpoint],verbose=1)\n# '''\n# from keras.callbacks import ModelCheckpoint\n# epochs = 10\n# batch_size = 32\n# model_checkpoint = ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True)\n\n# model.fit(X_train,Y_train,\n#           batch_size=128,\n#           epochs=20,\n#           verbose=1, shuffle=True, validation_data=(X_valid,Y_valid), callbacks=[model_checkpoint])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"35092f5cb638cf5a5c447906d7039e38c6a52753"},"cell_type":"code","source":"import matplotlib.pyplot as plt\ndef plot_model(model):\n    plots = [i for i in model.history.history.keys() if i.find('val_') == -1]\n    plt.figure(figsize=(10,10))\n\n    for i, p in enumerate(plots):\n        plt.subplot(len(plots), 2, i + 1)\n        plt.title(p)\n        plt.plot(model.history.history[p], label=p)\n        plt.plot(model.history.history['val_'+p], label='val_'+p)\n        plt.legend()\n\n    plt.show()\n    \nplot_model(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"462eeb5aa05127e083f24733b1fd559665ed5871"},"cell_type":"code","source":"model.load_weights('weights.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"67c0f4b294c57a1cc67c85c1ec9700b91813d96a"},"cell_type":"code","source":"prob=[]\nnum=[]\ntest_img=[]\ntest_path = '../input/plant-seedlings-classification/test/'\ntest_all = fnmatch.filter(os.listdir(test_path), '*.png')\n\ntest_img=[]\nfor i in range(len(test_all)):\n    path=test_path+'/'+test_all[i]\n    temp_img=image.load_img(path,target_size=(200,200))\n    temp_img=image.img_to_array(temp_img)\n    test_img.append(temp_img) \ntest_img=np.array(test_img)    \ntest_img=preprocess_input(test_img)\n\n\ntest_labels=[]\npred=model.predict(test_img)\nnum2label =  {0:'Loose Silky-bent', 1:'Charlock',2: 'Sugar beet',3: 'Small-flowered Cranesbill',\n              4:'Common Chickweed',5: 'Common wheat',6: 'Maize', 7:'Cleavers', 8:'Scentless Mayweed',\n             9: 'Fat Hen', 10:'Black-grass', 11:'Shepherds Purse'}\nfor i in range(len(test_all)):\n    max_score =0\n    lab=-1\n    for j in range(12):\n        if pred[i][j]>max_score:\n            max_score=pred[i][j]\n            lab=j\n    test_labels.append(num2label[lab])\n\n\nd = {'file': test_all, 'species': test_labels}\ndf = pd.DataFrame(data=d)\nprint(df.head(50))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c7014974c71c9c40841c6d4bb5ef4e5bea1e9c39","collapsed":true},"cell_type":"code","source":"#Convert dataframe to csv\n# df.to_csv(\"submit.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b181fe2abd8c3fe7888bfc34793a34df6a444b88"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}