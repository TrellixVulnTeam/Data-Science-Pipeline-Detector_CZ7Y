{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Plant Seddlings Classification\n\n### 설명\n* 목적: 잡초와 농작물 모종을 구별하기 --> 더 나은 농작물 생산량 & 환경 관리\n* 12개 종에 속하는 약 960개의 고유 식물의 이미지를 포함하는 데이터 셋\n\n### 필사\n* https://www.kaggle.com/code/nikkonst/plant-seedlings-with-cnn-and-image-processing","metadata":{}},{"cell_type":"markdown","source":"## 목차\n### 1. 데이터 얻기\n### 2. 데이터 정리하기\n### 3. 모델링\n### 4. 모델 평가하기","metadata":{}},{"cell_type":"markdown","source":"## **1. 데이터 얻기 - 이미지와 레이블 읽기**","metadata":{}},{"cell_type":"code","source":"import cv2 # 영상을 처리하기 위한 라이브러리\nfrom glob import glob # 파일들의 리스트를 뽑을 때 사용, 파일의 경로명을 이용해서 다양한 활용 가능\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport math\nimport pandas as pd\n\nScaleTo = 70  # px to scale\nseed = 7  # fixing random\n\npath = '../input/plant-seedlings-classification/train/*/*.png' # 위 디렉토리의 png 파일 주소\nfiles = glob(path) # glob로 files라는 변수에 저장\n\ntrainImg = []\ntrainLabel = []\ncnt = 1\nnum = len(files)\n\n# Obtain images and resizing, obtain labels\nfor img in files:\n    print(str(cnt) + \"/\" + str(num), end=\"\\r\")\n    trainImg.append(cv2.resize(cv2.imread(img), (ScaleTo, ScaleTo)))  # Get image (with resizing)\n    trainLabel.append(img.split('/')[-2])  # Get image label (folder name)\n    cnt += 1\n\ntrainImg = np.asarray(trainImg)  # Train images set\ntrainLabel = pd.DataFrame(trainLabel)  # Train labels set","metadata":{"execution":{"iopub.status.busy":"2022-05-17T11:20:45.446985Z","iopub.execute_input":"2022-05-17T11:20:45.447409Z","iopub.status.idle":"2022-05-17T11:22:13.808268Z","shell.execute_reply.started":"2022-05-17T11:20:45.447307Z","shell.execute_reply":"2022-05-17T11:22:13.807112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Show some example images\nfor i in range(12):\n    plt.subplot(3, 4, i + 1) # subplot(row, column, index) : 여러 개의 그래프를 그리기\n    plt.imshow(trainImg[i])","metadata":{"execution":{"iopub.status.busy":"2022-05-17T11:22:13.810624Z","iopub.execute_input":"2022-05-17T11:22:13.811207Z","iopub.status.idle":"2022-05-17T11:22:15.002813Z","shell.execute_reply.started":"2022-05-17T11:22:13.811159Z","shell.execute_reply":"2022-05-17T11:22:15.001883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* 위 그림을 통해 배경이 있는 것을 확인 -> 정확도를 위해선 배경을 없애는 것이 좋음.","metadata":{}},{"cell_type":"markdown","source":"## **2.데이터 정리하기**\n\n배경을 지우기 위해선 식물이 초록색인 점을 활용하면 된다.\n<br>\nmask를 만들고, 초록색 이외에 부분을 날리면 된다.","metadata":{}},{"cell_type":"markdown","source":"### 2.1 초록 식물 마스킹하기\n마스크를 만들기 위해선 배경을 지워야하는데, 이를 위해선 우린 RGB 이미지를 HSV로 변환해야한다.\n<br>\nHSV는 RGB 컬러 모델의 대안으로 RGB 컬러 공간보다 색 범위 표현이 쉽다.\n<br>\n이외에도 노이즈 제거를 위해 이미지를 블러처리한다.\n<br>\n#### 할 것\n1. 노이즈 제거를 위한 블러 생성 with Gaussian\n2. HSV 이미지로 변환\n3. 녹색의 선택된 범위를 기반하여 마스크 생성.\n4. 부울 마스크로 변환하여 본래 이미지에 적용","metadata":{}},{"cell_type":"code","source":"clearTrainImg = [] # 정리한 이미지를 넣을 배열\nexamples = []; getEx = True\nfor img in trainImg:\n    # Use gaussian blur\n    # cv2.GaussianBlur(src, ksize(커널 크기), sigmaX, sigmaY, 기타 파라미터들...)\n    blurImg = cv2.GaussianBlur(img, (5, 5), 0)\n    \n    # Convert to HSV image\n    hsvImg = cv2.cvtColor(blurImg, cv2.COLOR_BGR2HSV)  \n    \n    # Create mask (parameters - green color range)    \n    lower_green = (25, 40, 50)\n    upper_green = (75, 255, 255)\n   \n    ## 특정 범위 안에 있는 행렬 원소 검출 - cv2.inRange(src, lowerb, upperb, dst)\n    mask = cv2.inRange(hsvImg, lower_green, upper_green)\n    \n    ## getStructuringElement(shape, ksize, anchor): 이미지를 형태학적 관점에서 접근하는 기법\n    ### shape: 구조화 요소 커널의 모양 \n    ###     ==> cv2.MORPH_CROSS / cv2.MORPH_ELLIPSE / cv2.MORPH_RECT \n    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11, 11))\n    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n    \n    # Create bool mask\n    bMask = mask > 0  \n    \n    # Apply the mask\n    clear = np.zeros_like(img, np.uint8)  # Create empty image\n    clear[bMask] = img[bMask]  # Apply boolean mask to the origin image\n    \n    clearTrainImg.append(clear)  # Append image without backgroung\n    \n    # Show examples\n    if getEx:\n        plt.subplot(2, 3, 1); plt.imshow(img)  # Show the original image\n        plt.subplot(2, 3, 2); plt.imshow(blurImg)  # Blur image\n        plt.subplot(2, 3, 3); plt.imshow(hsvImg)  # HSV image\n        plt.subplot(2, 3, 4); plt.imshow(mask)  # Mask\n        plt.subplot(2, 3, 5); plt.imshow(bMask)  # Boolean mask\n        plt.subplot(2, 3, 6); plt.imshow(clear)  # Image without background\n        getEx = False\n        \nclearTrainImg = np.asarray(clearTrainImg)","metadata":{"execution":{"iopub.status.busy":"2022-05-17T11:22:15.004085Z","iopub.execute_input":"2022-05-17T11:22:15.004332Z","iopub.status.idle":"2022-05-17T11:22:18.682694Z","shell.execute_reply.started":"2022-05-17T11:22:15.004296Z","shell.execute_reply":"2022-05-17T11:22:18.681729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Show sample result\nfor i in range(12):\n    plt.subplot(3, 4, i + 1)\n    plt.imshow(clearTrainImg[i])","metadata":{"execution":{"iopub.status.busy":"2022-05-17T11:22:18.68552Z","iopub.execute_input":"2022-05-17T11:22:18.685993Z","iopub.status.idle":"2022-05-17T11:22:19.710318Z","shell.execute_reply.started":"2022-05-17T11:22:18.685949Z","shell.execute_reply":"2022-05-17T11:22:19.709343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"이렇게 배경을 제외한 사진들을 얻을 수 있었다.","metadata":{}},{"cell_type":"markdown","source":"### 2.2 Normalize input\nRGB 컬러 공간은 [0...255] 까지다. CNN이 더 빠르기 위해선 [0...1] 로 변환해야한다.","metadata":{}},{"cell_type":"code","source":"clearTrainImg = clearTrainImg / 255","metadata":{"execution":{"iopub.status.busy":"2022-05-17T11:22:19.711737Z","iopub.execute_input":"2022-05-17T11:22:19.713802Z","iopub.status.idle":"2022-05-17T11:22:19.97663Z","shell.execute_reply.started":"2022-05-17T11:22:19.713726Z","shell.execute_reply":"2022-05-17T11:22:19.975635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.3 Categories labels\n12가지의 종류을 가진 라벨을 0 또는 1로만 이루어진 벡터로 값을 수정해야합니다.\n<br>\nFor example 'Charlock' -> [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0].","metadata":{}},{"cell_type":"code","source":"from keras.utils import np_utils\nfrom sklearn import preprocessing\nimport matplotlib.pyplot as plt\n\n# Encode labels and create classes\nle = preprocessing.LabelEncoder()\nle.fit(trainLabel[0])\nprint(\"Classes: \" + str(le.classes_))\nencodeTrainLabels = le.transform(trainLabel[0])\n\n# Make labels categorical\nclearTrainLabel = np_utils.to_categorical(encodeTrainLabels)\nnum_clases = clearTrainLabel.shape[1]\nprint(\"Number of classes: \" + str(num_clases))\n\n# Plot of label types numbers\ntrainLabel[0].value_counts().plot(kind='bar')","metadata":{"execution":{"iopub.status.busy":"2022-05-17T11:22:19.978343Z","iopub.execute_input":"2022-05-17T11:22:19.978729Z","iopub.status.idle":"2022-05-17T11:22:26.707641Z","shell.execute_reply.started":"2022-05-17T11:22:19.978655Z","shell.execute_reply":"2022-05-17T11:22:26.706498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **3. 모델링**","metadata":{}},{"cell_type":"markdown","source":"## 3.1 데이터셋 분리하기\ntrain 데이터와 validation 데이터셋으로 나눈다. 10% 데이터가 validation 셋이 된다. \n<br>\n현재 데이터 셋은 불균형하다. 부정확한 모델셋을 피하기 위해 stratify = clearTrainLabel를 쓴다.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrainX, testX, trainY, testY = train_test_split(clearTrainImg, clearTrainLabel, \n                                                test_size=0.1, random_state=seed, \n                                                stratify = clearTrainLabel)","metadata":{"execution":{"iopub.status.busy":"2022-05-17T11:22:26.709098Z","iopub.execute_input":"2022-05-17T11:22:26.709563Z","iopub.status.idle":"2022-05-17T11:22:27.055426Z","shell.execute_reply.started":"2022-05-17T11:22:26.709507Z","shell.execute_reply":"2022-05-17T11:22:27.054442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.2 데이터 생성기\n과적합을 방지하기 위해 모델이 fitting하는 동안 이미지를 임의로 회전, 확대/축소, 이동 및 뒤집는 **이미지 생성기**를 만들어야 합니다.\n\n* 임의 회전을 0도에서 180도로 설정합니다.\n* 임의 줌을 0.1로 설정\n* 임의 이동을 0.1로 설정합니다.\n* 수평 및 수직 플립 설정","metadata":{}},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\ndatagen = ImageDataGenerator(\n        rotation_range=180,  # randomly rotate images in the range\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally\n        height_shift_range=0.1,  # randomly shift images vertically \n        horizontal_flip=True,  # randomly flip images horizontally\n        vertical_flip=True  # randomly flip images vertically\n    )  \ndatagen.fit(trainX)","metadata":{"execution":{"iopub.status.busy":"2022-05-17T11:22:27.057265Z","iopub.execute_input":"2022-05-17T11:22:27.057611Z","iopub.status.idle":"2022-05-17T11:22:27.2865Z","shell.execute_reply.started":"2022-05-17T11:22:27.057551Z","shell.execute_reply":"2022-05-17T11:22:27.285452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.3 모델 생성하기\n생성 모델을 위해선 Keras Sequential을 사용.\n<br>\n6개 컨볼루션 층\n3개 fully-conncected 층\n<br>\n나는 여섯 개의 컨볼루션 레이어와 세 개의 완전히 연결된 레이어를 가진 모델을 만들었다. 처음 두 개의 컨볼루션 레이어는 64개의 필터를 가지고 있고, 다음 128개의 필터와 마지막 두 개의 레이어는 256개의 필터를 가지고 있다. 각 컨볼루션 레이어 쌍 이후 모델에는 최대 풀링 레이어가 있습니다. 또한 각 컨볼루션 레이어 쌍 이후 과적합을 줄이기 위해 드롭아웃 레이어(컨볼루션 레이어 간 10%, 완전히 연결된 레이어 간 50%)를 사용하고 각 레이어 간에는 배치 정규화 레이어를 사용한다.\n\n결국 나는 분류를 위해 완전히 연결된 세 개의 레이어를 사용했다. 마지막 레이어에서 신경망은 12개 클래스 각각에 대한 확률 분포를 출력한다.","metadata":{}},{"cell_type":"code","source":"import numpy\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import Flatten\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers import BatchNormalization\n\nnumpy.random.seed(seed)  # Fix seed\n\nmodel = Sequential()\n\nmodel.add(Conv2D(filters=64, kernel_size=(5, 5), input_shape=(ScaleTo, ScaleTo, 3), activation='relu'))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Conv2D(filters=64, kernel_size=(5, 5), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Dropout(0.1))\n\nmodel.add(Conv2D(filters=128, kernel_size=(5, 5), activation='relu'))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Conv2D(filters=128, kernel_size=(5, 5), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Dropout(0.1))\n\nmodel.add(Conv2D(filters=256, kernel_size=(5, 5), activation='relu'))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Conv2D(filters=256, kernel_size=(5, 5), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Dropout(0.1))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(256, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(256, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(num_clases, activation='softmax'))\n\nmodel.summary()\n\n# compile model\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-05-17T11:22:27.288389Z","iopub.execute_input":"2022-05-17T11:22:27.288879Z","iopub.status.idle":"2022-05-17T11:22:30.842201Z","shell.execute_reply.started":"2022-05-17T11:22:27.28883Z","shell.execute_reply":"2022-05-17T11:22:30.841201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.4 Fit 모델\n여기서 모델을 교육하겠습니다. 먼저, 몇 가지 콜백을 설정했습니다. 첫 번째 콜백은 모델 학습률을 감소시킨다. 높은 학습률 모델에서는 모델이 더 빨리 수렴되지만, 높은 학습률에서는 모델이 로컬 최소값으로 떨어질 수 있다. 그래서, 우리는 피팅하는 과정에서 학습률을 낮출 것입니다. 3세기 동안 정확도가 향상되지 않으면 학습률을 낮출 것입니다. 다른 두 가지 콜백은 모델의 최고 및 마지막 가중치를 절약합니다.\n\n우리는 kaggle 커널에서 모델을 훈련시키지 않을 것이다. 왜냐하면 그것은 너무 긴 과정이기 때문이다. 그래서 나는 fitting으로 코드 라인을 코멘트한다.","metadata":{}},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n\n# learning rate reduction\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.4, \n                                            min_lr=0.00001)\n\n# checkpoints\nfilepath=\"drive/DataScience/PlantReco/weights.best_{epoch:02d}-{val_accuracy:.2f}.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_accuracy', \n                             verbose=1, save_best_only=True, mode='max')\nfilepath=\"drive/DataScience/PlantReco/weights.last_auto4.hdf5\"\ncheckpoint_all = ModelCheckpoint(filepath, monitor='val_accuracy', \n                                 verbose=1, save_best_only=False, mode='max')\n\n# all callbacks\ncallbacks_list = [checkpoint, learning_rate_reduction, checkpoint_all]\n\n# fit model\nhist = model.fit_generator(datagen.flow(trainX, trainY, batch_size=75), \n                            epochs=35, validation_data=(testX, testY), \n                            steps_per_epoch=trainX.shape[0], callbacks=callbacks_list)","metadata":{"execution":{"iopub.status.busy":"2022-05-17T11:22:30.8468Z","iopub.execute_input":"2022-05-17T11:22:30.847678Z","iopub.status.idle":"2022-05-17T11:22:49.415993Z","shell.execute_reply.started":"2022-05-17T11:22:30.847628Z","shell.execute_reply":"2022-05-17T11:22:49.414949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **4. 모델 평가하기**\n\n### 4.1. 파일에서 모델 불러오기\n여기서는 파일에서 최적의 모델의 가중치를 로드한다(앞서 훈련한 모델의 가중치가 있는 카글 데이터 세트를 사용했다). 또한 모델 정확도 평가에 적합한 모델을 Data.npz 교육 및 검증 데이터 세트에서 로드합니다","metadata":{}},{"cell_type":"markdown","source":"### 4.3 결과 얻기","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport itertools\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \n    fig = plt.figure(figsize=(10,10))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Predict the values from the validation dataset\npredY = model.predict(testX)\npredYClasses = np.argmax(predY, axis = 1) \ntrueY = np.argmax(testY, axis = 1) \n\n# confusion matrix\nconfusionMTX = confusion_matrix(trueY, predYClasses) \n\n# plot the confusion matrix\nplot_confusion_matrix(confusionMTX, classes = le.classes_) ","metadata":{"execution":{"iopub.status.busy":"2022-05-17T11:23:46.521317Z","iopub.execute_input":"2022-05-17T11:23:46.521655Z","iopub.status.idle":"2022-05-17T11:23:47.746739Z","shell.execute_reply.started":"2022-05-17T11:23:46.521614Z","shell.execute_reply":"2022-05-17T11:23:47.745743Z"},"trusted":true},"execution_count":null,"outputs":[]}]}