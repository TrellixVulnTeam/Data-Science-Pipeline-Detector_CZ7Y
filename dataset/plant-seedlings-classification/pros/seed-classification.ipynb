{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport os\nimport cv2\nimport random\nimport numpy as np\nimport pandas as pd\n\nfrom tqdm import trange\nfrom tqdm import tqdm\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.layers import multiply,Reshape,DepthwiseConv2D,Concatenate,Dense, Flatten, Conv2D,Input,GlobalAveragePooling2D,add,Add,MaxPooling2D,Dropout,ZeroPadding2D\nfrom keras.layers.core import Activation,Flatten\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.utils import to_categorical\nfrom keras.metrics import CategoricalAccuracy\nfrom keras import backend as K\nfrom time import sleep\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dir = \"../input/plant-seedlings-classification/train\"\ntest_dir = \"../input/plant-seedlings-classification/test\"\n\nclass_list = os.listdir(train_dir)\n\nimage_shape = (224,224,3)\n\nbatch_size = 4\nepoch = 20","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Dataset Utils**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_dataset(data_dir,class_list=None):\n    data = []\n    if class_list == None:\n        for img in os.listdir(os.path.join(data_dir)):\n            data.append(os.path.join(data_dir,img))\n    else:\n        for i,class_name in enumerate(class_list):\n            for img in os.listdir(os.path.join(data_dir,class_name)):\n                data.append([os.path.join(data_dir,class_name,img),i])\n\n    return data\n\ndef validation_split(data,ratio = 0.2):\n    random.shuffle(data)\n    train_data = data[int(ratio*len(data))+1:]\n    val_data = data[:int(ratio*len(data))]\n\n    \n    return train_data,val_data\n\ndef load_img(img_path,resize=(224,224),rescale=1.0):\n    img = cv2.imread(img_path)\n    img = cv2.resize(img,(resize))\n    img = img*rescale\n    return img\n\ndef load_batch(data,batch_size = 1,shuffle=False):\n    result = []\n\n    if shuffle:\n        random.shuffle(data)\n\n    for i in range(len(data)//batch_size):\n        batch_data = []\n        for j in range(batch_size):\n            batch_data.append(data[int((i*batch_size + j)%len(data))])\n        result.append(batch_data)\n\n    return result\n\ndef load_batch_data(data,img_resize=(224,224),rescale=1.0):\n    x = []\n    y = []\n\n    for img_data in data:\n        x.append(load_img(img_data[0],resize=img_resize,rescale=1/255))\n        y.append(img_data[-1])\n\n    return np.array(x),np.array(y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Model Generator**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def swish_activation(x):\n    return x*K.sigmoid(x)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Training**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def basic_block(model, kernal_size, filters, output_filters, strides,expand_ratio = 1,squeeze_ratio=0.25):\n    prev_model = model\n    \n    model = Conv2D(filters = filters*expand_ratio, kernel_size = 1, strides = strides, padding = \"same\")(prev_model)\n    model = BatchNormalization(momentum = 0.5)(model)\n    model = Activation(swish_activation)(model)\n    \n    model = DepthwiseConv2D(kernel_size = 3, strides = strides, padding = \"same\")(model)\n    model = BatchNormalization(momentum = 0.5)(model)\n    model = Activation(swish_activation)(model)\n    \n    se = GlobalAveragePooling2D()(model)\n    se = Reshape((1,1,filters*expand_ratio))(se)\n    \n    squeezed_filters = max(1, int(filters * squeeze_ratio))\n    se = Conv2D(filters = squeezed_filters, kernel_size = 1, strides = strides, padding = \"same\")(se)\n    se = Activation(swish_activation)(se)\n    \n    se = Conv2D(filters = filters*expand_ratio, kernel_size = 1, strides = strides, padding = \"same\")(se)\n    se = Activation('sigmoid')(se)\n    \n    model = multiply([model,se])\n    \n    model = Conv2D(filters = output_filters, kernel_size = 1, strides = strides, padding = \"same\")(model)\n    model = BatchNormalization(momentum = 0.5)(model)\n\n    return model\n\nclass Model_Generator(object):\n    def __init__(self, input_shape):\n        self.input_shape = input_shape\n\n    def get_model(self):\n\n        model_input = Input(shape = self.input_shape)\n#         224\n        model = Conv2D(filters = 32, kernel_size = 3, strides = 2, padding = \"same\")(model_input)\n    \n#         112\n        model = Conv2D(filters = 32, kernel_size = 1, strides = 1,padding='valid')(model)    \n        model = basic_block(model,(3,3),filters = 32,output_filters=16,strides=1,expand_ratio=1)\n        model = basic_block(model,(3,3),filters = 16,output_filters=24,strides=1,expand_ratio=6)\n        model = basic_block(model,(3,3),filters = 16,output_filters=24,strides=1,expand_ratio=6)\n        \n#         56\n        model = Conv2D(filters = 24, kernel_size = 1, strides = 1,padding='valid')(model)\n        model = basic_block(model,(5,5),filters = 24,output_filters=40,strides=1,expand_ratio=6)\n        model = basic_block(model,(5,5),filters = 24,output_filters=40,strides=1,expand_ratio=6)\n        \n#         28\n        model = Conv2D(filters = 40, kernel_size = 1, strides = 1,padding='valid')(model)\n        model = basic_block(model,(3,3),filters = 40,output_filters=80,strides=1,expand_ratio=6)\n        model = basic_block(model,(3,3),filters = 40,output_filters=80,strides=1,expand_ratio=6)\n        model = basic_block(model,(3,3),filters = 40,output_filters=80,strides=1,expand_ratio=6)\n        \n#         14\n        model = Conv2D(filters = 80, kernel_size = 1, strides = 1,padding='valid')(model)\n        model = basic_block(model,(5,5),filters = 80,output_filters=112,strides=1,expand_ratio=6)\n        model = basic_block(model,(5,5),filters = 80,output_filters=112,strides=1,expand_ratio=6)\n        model = basic_block(model,(5,5),filters = 80,output_filters=112,strides=1,expand_ratio=6)\n        model = basic_block(model,(5,5),filters = 80,output_filters=192,strides=1,expand_ratio=6)\n        model = basic_block(model,(5,5),filters = 80,output_filters=192,strides=1,expand_ratio=6)\n        model = basic_block(model,(5,5),filters = 80,output_filters=192,strides=1,expand_ratio=6)\n        model = basic_block(model,(5,5),filters = 80,output_filters=192,strides=1,expand_ratio=6)\n        \n#         7\n        model = Conv2D(filters = 192, kernel_size = 1, strides = 1,padding='valid')(model)\n        model = basic_block(model,(3,3),filters = 192,output_filters=320,strides=1,expand_ratio=6)\n        \n        model = Conv2D(filters = 1280, kernel_size = 1, strides = 1,padding='same')(model)\n        model = GlobalAveragePooling2D()(model)\n#         model = Dense(1024)(model)\n        model = Dense(len(class_list))(model)\n        \n        model_output = Activation('softmax')(model)\n\n        model = Model(inputs = model_input, outputs = model_output)\n\n        return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = load_dataset(train_dir,class_list)\ntrain_data,val_data = validation_split(data)\n\ntrain_data = load_batch(train_data,batch_size,True)\nval_data = load_batch(val_data,batch_size,True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Model_Generator(image_shape).get_model()\nmodel.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam')\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for e in range(epoch*8):\n    step_per_e = trange(len(train_data)//8)\n    for j in step_per_e:\n        step_per_e.set_description(\"Epoch {}\".format(e))\n        x,y = load_batch_data(train_data[int(np.random.uniform(low=0, high=len(train_data)))])\n        train_losses = model.train_on_batch(x, y)\n    \n#   Validation Process\n    accuracy_acc = CategoricalAccuracy()\n    for val in val_data:\n        x,y = load_batch_data(val)\n        \n        y_pred = model.predict(x)\n        y_gt = to_categorical(y, num_classes=len(class_list), dtype=\"float32\")\n        \n        accuracy_acc.update_state(y_pred,y_gt)\n    val_losses = model.train_on_batch(x, y)\n    print(\"Train loss : {}, Validation loss : {}, Accuracy : {}\".format(train_losses,val_losses,accuracy_acc.result().numpy()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save(\"trained_model.h5\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Testing**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = val_data\n\nfor i in trange(len(test_data)):\n    x,y = load_batch_data(val)\n\n    y_pred = model.predict(x)\n    y_gt = to_categorical(y, num_classes=len(class_list), dtype=\"float32\")\n\n    accuracy_acc.update_state(y_pred,y_gt)\nprint(\"Model Accuracy : {}\".format(accuracy_acc.result().numpy()))\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Submission**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = load_dataset(test_dir)\ntest_data = load_batch(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res = []\nfor test in tqdm(test_data):\n    img = load_img(test[0],(224,224),1/255)\n    y_pred = model.predict(np.expand_dims(img,axis=0))\n    class_pred = class_list[int(np.argmax(y_pred))]\n    res.append([os.path.basename(test[0]),class_pred])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame(res, columns = ['file', 'species'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_csv(\"submission_4.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!kaggle competitions submit -c plant-seedlings-classification -f submission.csv -m \"Message\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}