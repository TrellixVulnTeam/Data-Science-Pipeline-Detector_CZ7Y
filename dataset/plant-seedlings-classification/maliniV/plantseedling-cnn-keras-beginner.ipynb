{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np\n\nimport os\nimport sys\nimport cv2\nfrom keras.utils import to_categorical\nimport matplotlib\nfrom keras import backend as k\nk.clear_session()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"485249685d45f48212d2d3cd6a2c8098d592bf82"},"cell_type":"code","source":"import random\nrandom.seed(10)\nallLabels =  os.listdir(\"../input/plant-seedlings-classification/train/\")  # list of subdirectories and files\ntrainDir='/kaggle/working/../input/plant-seedlings-classification/train/'\n\nfrom keras.preprocessing.image import  img_to_array, load_img\nWIDTH = 128\nHEIGHT = 128\nDEPTH = 3\n\ndata = []\nlabels = []\n\n# loop over the input images\ndirs = os.listdir(trainDir) \nfor dir in dirs:\n    absDirPath = os.path.join(os.path.sep,trainDir, dir)\n    images = os.listdir(absDirPath)\n    for imageFileName in images:\n        \n        # load the image, pre-process it, and store it in the data list\n        imageFullPath = os.path.join(trainDir, dir, imageFileName)\n        #print(imageFullPath)\n        img = load_img(imageFullPath)\n        arr = img_to_array(img)  # Numpy array with shape (233,233,3)\n        arr = cv2.resize(arr, (HEIGHT,WIDTH)) #Numpy array with shape (HEIGHT, WIDTH,3)\n        #print(arr.shape)\n        data.append(arr)\n        #label = classes_to_int(dir)\n        label=str(imageFullPath.split('/')[-2])\n        #print(label)\n        labels.append(label)\n\n  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c61ded4fb601e422604ffc8f21d9971d6096cb87"},"cell_type":"code","source":"len(images)\nprint('Number of images :-',len(data))\nprint('Numbe of Labels',len(labels))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"017eaa586c86c86d0ddd8bd87147edb723a7e10a"},"cell_type":"code","source":"data[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"776d7fc1c95aa530797d61a376ad1660dbacad9f"},"cell_type":"code","source":"%matplotlib inline\nimport os\nimport matplotlib\nimport matplotlib.pyplot as plt\n#to view the images\n\nfor i in range(1,10):\n    #print(i)\n    new_image = tf.keras.preprocessing.image.array_to_img(data[i])\n    #Show image\n    #fig, axs = plt.subplots(1, j, figsize=(20, 20))\n    plt.imshow(new_image)\n    plt.show()\n    \n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"93d8febfe3ebc45a320597c8551d6c9bf512e1db"},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n# scale the raw pixel intensities to the range [0, 1]\nTrainX = np.array(data, dtype=\"float\") / 255.0\nY_labels = np.array(labels)\n# convert the labels from integers to vectors\n#Y =  to_categorical(Y, num_classes=12)\nlabelEncoder = LabelEncoder()\nlabelEncoder.fit(Y_labels)\ntrain_labels_encoded = labelEncoder.transform(Y_labels)\ntrainY = tf.keras.utils.to_categorical(train_labels_encoded, num_classes=12)\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6b1a71152fd48ebadf49b28b0bead309551a0e8b"},"cell_type":"code","source":"print(TrainX.shape)\nprint(trainY.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49cebd8279ba280a0e1ea4ec85625f2cda1cf46a"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nprint(\"Train Validation Split into 80:20...\")\nsys.stdout.flush()\n# partition the data into training and validation splits \n(x_train, valX, y_train, valY) = train_test_split(TrainX,trainY,test_size=0.20, random_state=10)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e1ca75b547dfd0cc760f0e52357327d943ff0700"},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\naug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1, \n    height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n   horizontal_flip=True, fill_mode=\"nearest\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1959660a2ad3356945b986e1b7837b8e9724d39d"},"cell_type":"markdown","source":"# Create a MixIterator object\n# This class is a simple method to create batches from several other batch generators\nclass MixIterator(object):\n    def __init__(self, iters,N):\n        self.iters = iters\n        self.N=N\n        self.multi = type(iters) is list\n        if self.multi:\n            self.N = sum([it[0].N for it in self.iters])\n        else:\n            self.N = sum([it.N for it in self.iters])\n\n    def reset(self):\n        for it in self.iters: it.reset()\n\n    def __iter__(self):\n        return self\n\n    def next(self, *args, **kwargs):\n        if self.multi:\n            nexts = [[next(it) for it in o] for o in self.iters]\n            n0 = np.concatenate([n[0] for n in nexts])\n            n1 = np.concatenate([n[1] for n in nexts])\n            return (n0, n1)\n        else:\n            nexts = [next(it) for it in self.iters]\n            n0 = np.concatenate([n[0] for n in nexts])\n            n1 = np.concatenate([n[1] for n in nexts])\n        return (n0, n1)"},{"metadata":{"trusted":true,"_uuid":"9c3469d41676f3a8a08f05d4c1537e83c706a31a"},"cell_type":"code","source":"from keras import backend as k\nfrom keras.models import Sequential\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\nfrom keras.layers.core import Activation, Flatten, Dense\nfrom keras.optimizers import Adam\n# initialize the model\n\nsys.stdout.flush()\nk.clear_session()\n\ninputShape = (WIDTH, HEIGHT, DEPTH)\nEPOCHS = 40\nINIT_LR = 1e-3\nBS = 32\n\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=inputShape)) \nmodel.add(Activation(\"relu\"))\n#model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, (5, 5), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\n# model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\nmodel.add(Activation(\"relu\"))\n#  model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(units=500))\nmodel.add(Activation(\"relu\"))\n\n# softmax classifier\nmodel.add(Dense(units=12))\nmodel.add(Activation(\"softmax\"))\n   \nopt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\nmodel.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"46cae0152575779ca8fb6e542b464c855e1a9eff","scrolled":true},"cell_type":"code","source":"# train the network\n\nsys.stdout.flush()\n\nH = model.fit_generator(aug.flow(x_train, y_train, batch_size=BS), \n                        validation_data=(valX, valY), \n                        steps_per_epoch=len(x_train) // BS, \n                        epochs=EPOCHS, verbose=1)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"23735c66e71c216275b3b89006e3806b4c94b66f"},"cell_type":"markdown","source":"train_batches = aug.flow(x_train, y_train, batch_size=44)\nval_batches = aug.flow(valX, valX, batch_size=4)\n#test_batches = gen.flow(x_test, predictions, batch_size=16)\nN= steps_per_epoch=len(x_train) // BS\nmi = MixIterator([train_batches, val_batches],N)\n#model.fit_generator(mi, mi.N, nb_epoch=8, validation_data=(x_val, y_val))\n\nH = model.fit_generator(mi,\n                  validation_data=(valX, valY), \n                  steps_per_epoch=len(x_train) // BS, \n                  epochs=EPOCHS, \n                  verbose=1)\n\n"},{"metadata":{"trusted":true,"_uuid":"3d18528b63180d05cc4e340cbb7ad161d889e60f"},"cell_type":"code","source":"\nfrom matplotlib import pyplot\nsys.stdout.flush()\n\npyplot.style.use(\"ggplot\")\npyplot.figure()\nN = EPOCHS\n\npyplot.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\npyplot.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\npyplot.title(\"Training /Validation and Accuracy on  crop classification\")\npyplot.xlabel(\"Epoch #\")\npyplot.ylabel(\"Accuracy\")\npyplot.legend(loc=\"lower left\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"30225406beff4a019b7c8752a1f33019f9d26660"},"cell_type":"code","source":"\nfrom matplotlib import pyplot\nsys.stdout.flush()\n\npyplot.style.use(\"ggplot\")\npyplot.figure()\nN = EPOCHS\npyplot.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\npyplot.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n\npyplot.title(\"Training /Validation Loss on  crop classification\")\npyplot.xlabel(\"Epoch #\")\npyplot.ylabel(\"Loss\")\npyplot.legend(loc=\"lower left\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cba4ec3d06a937f61b8c1b19fdf96aae5c51a93a"},"cell_type":"code","source":"#allLabels =  os.listdir(\"../input/test/\")  # list of subdirectories and files\ntestDir='/kaggle/working/../input/plant-seedlings-classification/test/'\n\nfrom keras.preprocessing.image import  img_to_array, load_img\nWIDTH = 128\nHEIGHT = 128\nDEPTH = 3\nTestdata = []\nfilenames = []\n    # loop over the input images\nimages = os.listdir(testDir)\nfor imageFileName in images:\n # load the image, pre-process it, and store it in the data list\n    imageFullPath = os.path.join(testDir, imageFileName)\n    #print(imageFullPath)\n    img = load_img(imageFullPath)\n    arr = img_to_array(img)  # Numpy array with shape (...,..,3)\n    arr = cv2.resize(arr, (HEIGHT,WIDTH)) \n    Testdata.append(arr)\n    filenames.append(imageFileName)\n   \n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fc993d48f9a77efc182c65cf2ded0bbe1668b6cd"},"cell_type":"code","source":"# scale the raw pixel intensities to the range [0, 1]\ntestX = np.array(Testdata, dtype=\"float\") / 255.0\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"79876d83de4e43c29e2b768760bfcfed382fdfdc"},"cell_type":"code","source":"testX.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"83e6653e1b4b85d13f3abab1088aa51f2fed3575"},"cell_type":"code","source":"len(filenames)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c54a7ae418bd1e0665264b2cd5b856bee8df331d"},"cell_type":"code","source":"print(filenames[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"25e5ea1530dab68134c0ee1e458ad22e7b71dbb3"},"cell_type":"code","source":"predicted_probs = model.predict(testX, batch_size=10, verbose=1)\n\n#predicted_probs = model.predict_generator(test_generator(test_files), steps=len(test_files))\n#[f.split('/')[3] for f in test_files]\npredicted_classes = np.argmax(predicted_probs, axis=1)\nout_df = pd.DataFrame({'file':filenames , \n                       'species': labelEncoder.inverse_transform(predicted_classes)})\nout_df.to_csv('submission_conv.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c637b420a80d6d84314a306fefce0dfaa6e2248b"},"cell_type":"markdown","source":"Trying Transfer Learning with Resnet"},{"metadata":{"_uuid":"8ac834a4e3fef759899694dfe5597658a01cada3"},"cell_type":"markdown","source":"model2 = tf.keras.applications.resnet50.ResNet50(include_top=False, #Do not include FC layer at the end\n                                          input_shape= inputShape,\n                                          weights='imagenet')\n\n#Set pre-trained model layers to not trainable\nfor layer in model.layers:\n    layer.trainable = False"},{"metadata":{"trusted":true,"_uuid":"cac4565b0c3a195d4eda44b2db7b209729b4eab8"},"cell_type":"code","source":"#tf.keras.applications\nfrom tensorflow.python.keras.applications import ResNet50\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n\n\n#RESNET_WEIGHTS_PATH = '../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n#RESNET_WEIGHTS_PATH = '../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\nresnet_weights_path = '../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\nmodel2 = Sequential()\n#model2 = Sequential()\nmodel2.add(ResNet50(include_top=False, pooling='avg', weights=resnet_weights_path))\n\n#model.add(ResNet50(include_top = False, pooling = RESNET50_POOLING_AVERAGE, weights = resnet_weights_path))\n\n\n#model2.add(ResNet50(include_top=False, pooling='max', weights= 'imagenet'))\n#model2.layers[0].trainable = True\n\n# Say not to train first layer (ResNet) model as it is already trained\nmodel2.layers[0].trainable = False\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"84d10c5d0518bd908ac1a29430299d02a05f84b5"},"cell_type":"code","source":"from tensorflow.keras.layers import Dropout\n#get Output layer of Pre0trained model\nx = model2.output\n\n#Flatten the output to feed to Dense layer\nx = tf.keras.layers.Flatten()(x)\n\nx = Dense(1024, activation=\"relu\")(x)\nx = Dropout(0.5)(x)\n\n#Add one Dense layer\nx = tf.keras.layers.Dense(1024, activation='relu')(x)\n\n#Add output layer\nprediction = tf.keras.layers.Dense(12,activation='softmax')(x)\n\n#Using Keras Model class\nfinal_model = tf.keras.models.Model(inputs=model2.input, #Pre-trained model input as input layer\n                                    outputs=prediction) #Output layer added\n\n#optimizer = optimizers.SGD(lr=0.0001, momentum=0.9)\nfinal_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ff968d59faadf9872d128866f66126a6e8700b41"},"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, EarlyStopping\nearly = EarlyStopping(monitor='loss', min_delta=0, patience=10, verbose=1, mode='auto')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"54a2997a4281e072d9529c1b82694948d049fc65"},"cell_type":"code","source":"H = final_model.fit_generator(aug.flow(x_train, y_train, batch_size=BS), \n                                validation_data=(valX, valY), \n                                steps_per_epoch=len(x_train) // BS, \n                                epochs=EPOCHS, verbose=1,\n                                callbacks = [early])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d7d5046626bc5f54ad985d0c43e47d927e8bd07d"},"cell_type":"code","source":"predicted_probs2 = final_model.predict(testX, batch_size=10, verbose=1)\n\n#predicted_probs = model.predict_generator(test_generator(test_files), steps=len(test_files))\n#[f.split('/')[3] for f in test_files]\npredicted_classes2 = np.argmax(predicted_probs2, axis=1)\nout_df = pd.DataFrame({'file':filenames , \n                       'species': labelEncoder.inverse_transform(predicted_classes2)})\nout_df.to_csv('submissionTL.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b19c1dca6c94fd12a4c7869c2c1b8ff1b8125fbd"},"cell_type":"code","source":"from matplotlib import pyplot\nsys.stdout.flush()\n\npyplot.style.use(\"ggplot\")\npyplot.figure()\nN = EPOCHS\n\npyplot.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\npyplot.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\npyplot.title(\"Training /Validation and Accuracy on  crop classification with Transfer Learning\")\npyplot.xlabel(\"Epoch #\")\npyplot.ylabel(\"Accuracy\")\npyplot.legend(loc=\"lower left\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b14fda47dd29b39d278a40067269bab9468ecd74"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}