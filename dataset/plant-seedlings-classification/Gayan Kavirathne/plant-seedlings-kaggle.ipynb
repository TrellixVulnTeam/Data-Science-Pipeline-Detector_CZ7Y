{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if torch.cuda.is_available():\n    device = torch.device('cuda')\nelse:\n    device = torch.device('cpu')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Loading Data\ndata_path = '../input/plant-seedlings-classification/train/'\nbatch_size=128\nresized_width=224\nresized_height=224\nclasses = ('Black-grass','Charlock','Cleavers','Common Chickweed','Common wheat','Fat Hen','Loose Silky-bent',\n'Maize','Scentless Mayweed','Shepherds Purse','Small-flowered Cranesbill','Sugar beet')\n\ndef load_split_train_test(datadir, valid_size = .2):\n    train_transforms = transforms.Compose([\n        transforms.Resize((resized_width,resized_height)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))               \n        ])\n    test_transforms = transforms.Compose([\n        transforms.Resize((resized_width,resized_height)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))               \n        ])\n    train_data = torchvision.datasets.ImageFolder(\n        root=datadir,  \n        transform=train_transforms\n    )\n    test_data = torchvision.datasets.ImageFolder(\n        root=datadir,\n        transform=test_transforms\n    )\n    num_train = len(train_data)\n    indices = list(range(num_train))\n    split = int(np.floor(valid_size * num_train))\n    np.random.shuffle(indices)\n    from torch.utils.data.sampler import SubsetRandomSampler\n    train_idx, test_idx = indices[split:], indices[:split]\n    train_sampler = SubsetRandomSampler(train_idx)\n    test_sampler = SubsetRandomSampler(test_idx)\n    trainloader = torch.utils.data.DataLoader(\n            train_data,\n            batch_size=batch_size,\n            num_workers=4,\n#             shuffle=True,                                # Mutually exclusive with sampler\n            sampler=train_sampler\n    )\n    testloader = torch.utils.data.DataLoader(\n            test_data,\n            batch_size=batch_size,\n            num_workers=4,\n#             shuffle=True,                               # Mutually exclusive with sampler\n            sampler=test_sampler\n    )\n    return trainloader, testloader\n\ntrainloader, testloader = load_split_train_test(datadir=data_path, valid_size = .2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualize images\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\nimport matplotlib.pyplot as plt\n\nimport numpy as np\nplt.rcParams['figure.dpi'] = 100\n\n# functions to show an image\ndef imshow(img):\n    img = img / 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n    print(img.size())\n\n# get some random training images\ndataiter = iter(trainloader)\nimages, labels = dataiter.next()\n\n# show images\nimshow(torchvision.utils.make_grid(images))\n# print labels\nprint(' '.join('%5s' % classes[labels[j]] for j in range(batch_size)))\n\n# get some random validation images\ntestdataiter = iter(testloader)\ntestimages, testlabels = testdataiter.next()\n\n# show images\nimshow(torchvision.utils.make_grid(testimages))\n# print labels\nprint(' '.join('%5s' % classes[testlabels[j]] for j in range(batch_size)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define the NN\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6,kernel_size=5, stride=1,padding=(2,2))\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16,kernel_size=5, stride=1,padding=(2,2))\n        self.conv3 = nn.Conv2d(in_channels=16, out_channels=32,kernel_size=5, stride=1,padding=(2,2))\n        self.fc1 = nn.Linear(32 * 28 * 28, 240)\n        self.fc2 = nn.Linear(240, 120)\n        self.fc3 = nn.Linear(120, 84)\n        self.fc4 = nn.Linear(84, 12)\n    def forward(self, x):\n#         print(x.shape)\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = self.pool(F.relu(self.conv3(x)))\n        x = x.view(-1, self.num_flat_features(x))\n#         print(x.view(-1, self.num_flat_features(x)).shape)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = F.relu(self.fc3(x))\n        X = self.fc4(x)\n        return x\n\n\n    def num_flat_features(self, x):\n        size = x.size()[1:]  # all dimensions except the batch dimension\n#         print(x.size())\n#         imshow(torchvision.utils.make_grid(x))\n        num_features = 1\n        for s in size:\n            num_features *= s\n        return num_features\n    \nnet = Net().to(device=device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install torchsummary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torchsummary import summary\nsummary(net,(3,224,224))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def save_models(epoch):\n    torch.save(net.state_dict(), \"seedlings_{}.model\".format(epoch))\n    print(\"Chekcpoint saved\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define the loss function\nimport torch.optim as optim\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training the NN\nepochs = 50\nbest_accuracy = 0.0\naccuracy_epoch = []\nloss_epoch = []\ntest_accuracy_epoch = []\ntest_loss_epoch = []\nfor epoch in range(epochs):  # loop over the dataset multiple times\n    \n    if(epoch % 10 == 0):      # cross val every 15 iteration\n        trainloader, testloader = load_split_train_test(datadir=data_path, valid_size = .2)\n    # Training the model\n    net.train()\n    running_loss = 0.0\n    correct = 0.0\n    for i, data in enumerate(trainloader, 0):\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        inputs = inputs.to(device=device)\n        labels = labels.to(device=device)\n        outputs = net(inputs)\n#         print(outputs.shape)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.item()\n        _, prediction = torch.max(outputs.data, 1)\n        correct += torch.sum(prediction == labels.data)\n#         print(correct)\n        if i % 2000 == 1999:    # print every 2000 mini-batches\n            print('[%d, %f\\%5d] loss: %.3f' %\n                  (epoch + 1,correct, i + 1, running_loss / 2000))\n            running_loss = 0.0\n    accuracy = 100 * correct / (len(trainloader)* batch_size)\n    accuracy_epoch.append(accuracy)\n    loss_epoch.append(loss)\n    if(accuracy > best_accuracy):\n        save_models(epoch)\n        best_accuracy = accuracy\n    \n    # Validating the model\n    net.eval()\n    running_test_loss = 0.0\n    test_correct = 0.0\n    with torch.no_grad():\n        for j , testdata in enumerate(testloader,0):\n            test_inputs,test_labels = testdata\n            # zero the parameter gradients\n            optimizer.zero_grad()\n            \n            test_inputs = test_inputs.to(device = device)\n            test_labels = test_labels.to(device = device)\n            \n            test_outputs = net(test_inputs)\n            test_loss = criterion(test_outputs,test_labels)\n            running_test_loss += test_loss.item()\n            _, test_prediction = torch.max(test_outputs.data, 1)\n            test_correct += torch.sum(test_prediction == test_labels.data)\n        \n        test_accuracy = 100 * test_correct / (len(testloader)*batch_size)\n        test_accuracy_epoch.append(test_accuracy)\n        test_loss_epoch.append(test_loss)\n                       \n            \n    print(\"Epoch {:d}/{:d}, Train Loss: {:.3f}, Train Accuracy: {:.3f} Validation Loss: {:.3f}, Validation Accuracy : {:.3f}\".format(epoch+1,epochs, loss.data, accuracy, test_loss.data,test_accuracy))\nprint('Finished Training')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(accuracy_epoch, label='Training Accuracy')\nplt.plot(loss_epoch, label='Training loss')\nplt.plot(test_accuracy_epoch, label='Validation Accuracy')\nplt.plot(test_loss_epoch, label='Validation loss')\nplt.legend(frameon=False)\nplt.rcParams['figure.dpi'] = 200\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_path = '../input/plantseedlingsmodels/seedlings_60.model'\ndef load_saved_model(model_path):\n    # Loading the saved models parameters to the model Class\n    model = Net()\n    state_dict = torch.load(model_path,map_location=torch.device('cpu') )\n    model.load_state_dict(state_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image\nfrom torch.autograd import Variable\n\ndef predict_image(image_path):\n#     print(\"Prediction in progress\")\n    image = Image.open(image_path)\n\n    # Define transformations for the image, should (note that imagenet models are trained with image size 224)\n    transformation = transforms.Compose([\n        transforms.CenterCrop((resized_width,resized_width)),\n        transforms.ToTensor(),\n        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n    ])\n\n    # Preprocess the image\n    image_tensor = transformation(image).float()\n\n    # Add an extra batch dimension since pytorch treats all images as batches\n    image_tensor = image_tensor.unsqueeze_(0)\n\n    if torch.cuda.is_available():\n        image_tensor.cuda()\n\n    # Turn the input into a Variable\n    input = Variable(image_tensor)\n\n    # Predict the class of the image\n    output = model(input)\n\n    index = output.data.numpy().argmax()\n\n    return index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport pandas as pd\npredict_img_dir = '../input/plant-seedlings-classification/test/'\ndef run_predictions():\n    directory = os.fsencode(predict_img_dir)\n\n    predictions = []\n    for file in os.listdir(directory):\n        filename = os.fsdecode(file)\n        print(filename)\n        prediction = predict_image(predict_img_dir+filename)\n        pred = {'file':filename, 'species':classes[prediction]}\n        predictions.append(pred)\n    df = pd.DataFrame(predictions)\n    df.to_csv('predictions.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}