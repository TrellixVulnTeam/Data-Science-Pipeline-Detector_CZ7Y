{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import glob\nimport os\nfrom PIL import Image, ImageOps\nimport numpy as np\nimport pandas as pd\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelBinarizer\n\nfrom keras.layers import Dropout, Input, Dense, Activation,GlobalMaxPooling2D, BatchNormalization, Flatten, Conv2D, MaxPooling2D\nfrom keras.models import Model, load_model\nfrom keras.optimizers import Adam\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.applications.mobilenet import MobileNet\nfrom tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\nfrom keras.callbacks import LearningRateScheduler, EarlyStopping\nfrom keras.callbacks import ModelCheckpoint\nimport matplotlib.pyplot as plt","metadata":{"_cell_guid":"e542f02f-2ba9-4eda-a521-55e12bf28178","_uuid":"03e7f1631f5f3adbbd04b3dfbbfc7bb9c9b90b8d","execution":{"iopub.status.busy":"2021-06-12T10:29:30.767478Z","iopub.execute_input":"2021-06-12T10:29:30.767841Z","iopub.status.idle":"2021-06-12T10:29:30.777039Z","shell.execute_reply.started":"2021-06-12T10:29:30.767811Z","shell.execute_reply":"2021-06-12T10:29:30.77621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"z = glob.glob('../input/train/*/*.png')\nori_label = []\nori_imgs = []\nfor fn in z:\n    if fn[-3:] != 'png':\n        continue\n    ori_label.append(fn.split('/')[-2])\n    new_img = Image.open(fn)\n    ori_imgs.append(ImageOps.fit(new_img, (64, 64), Image.ANTIALIAS).convert('RGB'))\n    \n    ","metadata":{"_cell_guid":"a5dd64e1-3e32-42dc-a3ac-c03ca0e9e31c","_uuid":"4f0efe6ef8f57aa45e217f55bd379bbcb79846d2","execution":{"iopub.status.busy":"2021-06-12T10:06:46.265042Z","iopub.execute_input":"2021-06-12T10:06:46.265361Z","iopub.status.idle":"2021-06-12T10:07:51.880464Z","shell.execute_reply.started":"2021-06-12T10:06:46.265331Z","shell.execute_reply":"2021-06-12T10:07:51.879587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ori_imgs[2]","metadata":{"_cell_guid":"545b72a2-edd6-4b1c-acb6-93e407169ab2","_uuid":"3a3cda504c889472a7e5c16c95478b22a317a9ac","execution":{"iopub.status.busy":"2021-06-12T10:07:51.881995Z","iopub.execute_input":"2021-06-12T10:07:51.882333Z","iopub.status.idle":"2021-06-12T10:07:51.894583Z","shell.execute_reply.started":"2021-06-12T10:07:51.882299Z","shell.execute_reply":"2021-06-12T10:07:51.893619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imgs = np.array([np.array(im) for im in ori_imgs])\nimgs = imgs.reshape(imgs.shape[0], 64,64, 3) / 255\nlb = LabelBinarizer().fit(ori_label)\nlabel = lb.transform(ori_label) ","metadata":{"_cell_guid":"ca1dd2ef-f1aa-4670-92de-c39c481b8463","_uuid":"7d10dfdba4b460ad1e8b20407ea27ac454a7906c","execution":{"iopub.status.busy":"2021-06-12T10:07:51.901299Z","iopub.execute_input":"2021-06-12T10:07:51.901995Z","iopub.status.idle":"2021-06-12T10:07:52.290001Z","shell.execute_reply.started":"2021-06-12T10:07:51.901956Z","shell.execute_reply":"2021-06-12T10:07:52.288979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainX, validX, trainY, validY = train_test_split(imgs, label, test_size=0.05, random_state=42)","metadata":{"_cell_guid":"1de7b866-7102-41e8-a92b-86471c5f5706","_uuid":"557c146f2f9c6631acc2f2a907b9b49282a649ee","execution":{"iopub.status.busy":"2021-06-12T10:07:52.294205Z","iopub.execute_input":"2021-06-12T10:07:52.294488Z","iopub.status.idle":"2021-06-12T10:07:52.440169Z","shell.execute_reply.started":"2021-06-12T10:07:52.294454Z","shell.execute_reply":"2021-06-12T10:07:52.439309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainX.shape , validX.shape ,trainY.shape , validY.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-12T10:07:52.441492Z","iopub.execute_input":"2021-06-12T10:07:52.441846Z","iopub.status.idle":"2021-06-12T10:07:52.448026Z","shell.execute_reply.started":"2021-06-12T10:07:52.441811Z","shell.execute_reply":"2021-06-12T10:07:52.446846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_input=Input(shape=(64,64,3))\n# create the base pre-trained model\n#base_model = ResNet50(input_tensor=image_input,weights='imagenet', include_top=False)\n\nbase_model = MobileNet(input_tensor=image_input,weights='imagenet', include_top=False)\n\nx = base_model.output\nx = Flatten()(x)\npredictions = Dense(12, activation='softmax')(x)\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n\n# compile the model (should be done *after* setting layers to non-trainable)\nmodel.compile(optimizer=Adam(lr=1e-4), loss='categorical_crossentropy',metrics=['accuracy'])\n\n# train the model on the new data for a few epochs\nbatch_size = 32\nannealer = LearningRateScheduler(lambda x: 1e-3 * 0.8 ** x)\nearlystop = EarlyStopping(patience=5)\nmodelsave = ModelCheckpoint(\n    filepath='model.h5', save_best_only=True, verbose=1)\nhistory = model.fit(\n    trainX, trainY, batch_size=batch_size,\n    epochs=200, \n    validation_data=(validX, validY),\n    callbacks=[annealer, earlystop, modelsave]\n)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-12T10:20:08.580469Z","iopub.execute_input":"2021-06-12T10:20:08.580855Z","iopub.status.idle":"2021-06-12T10:20:51.08654Z","shell.execute_reply.started":"2021-06-12T10:20:08.580822Z","shell.execute_reply":"2021-06-12T10:20:51.085731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def printHistory(history,):\n    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n    f.subplots_adjust(top=0.85, wspace=0.3)\n\n    ax1.plot( history.history['accuracy'], label='Train Accuracy')\n    ax1.plot( history.history['val_accuracy'], label='Validation Accuracy')\n    ax1.set_ylabel('Accuracy Value')\n    ax1.set_xlabel('Epoch')\n    ax1.set_title('Accuracy')\n    l1 = ax1.legend(loc=\"best\")\n\n    ax2.plot( history.history['loss'], label='Train Loss')\n    ax2.plot( history.history['val_loss'], label='Validation Loss')\n    ax2.set_ylabel('Loss Value')\n    ax2.set_xlabel('Epoch')\n    ax2.set_title('Loss')\n    l2 = ax2.legend(loc=\"best\")\n    \nprintHistory(history)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T10:28:22.842245Z","iopub.execute_input":"2021-06-12T10:28:22.842591Z","iopub.status.idle":"2021-06-12T10:28:23.136861Z","shell.execute_reply.started":"2021-06-12T10:28:22.842558Z","shell.execute_reply":"2021-06-12T10:28:23.135864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"z = glob.glob('../input/test/*.png')\ntest_imgs = []\nnames = []\nfor fn in z:\n    if fn[-3:] != 'png':\n        continue\n    names.append(fn.split('/')[-1])\n    new_img = Image.open(fn)\n    test_img = ImageOps.fit(new_img, (64, 64), Image.ANTIALIAS).convert('RGB')\n    test_imgs.append(test_img)\nmodel = load_model('model.h5')","metadata":{"_cell_guid":"1f953f1c-39b3-4160-89aa-e546719f2fef","_uuid":"20834884a92a67eb750e7d70350ca86585abfef3","execution":{"iopub.status.busy":"2021-06-12T10:29:00.784712Z","iopub.execute_input":"2021-06-12T10:29:00.785039Z","iopub.status.idle":"2021-06-12T10:29:09.887483Z","shell.execute_reply.started":"2021-06-12T10:29:00.785011Z","shell.execute_reply":"2021-06-12T10:29:09.886615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"timgs = np.array([np.array(im) for im in test_imgs])\ntestX = timgs.reshape(timgs.shape[0], 64, 64, 3) / 255","metadata":{"_cell_guid":"42ee9ca8-ae2f-469e-b881-3962281f6967","_uuid":"b6bff74f20c089f41c3b4a68ccd10df6a48afd2b","execution":{"iopub.status.busy":"2021-06-12T10:29:14.282394Z","iopub.execute_input":"2021-06-12T10:29:14.282769Z","iopub.status.idle":"2021-06-12T10:29:14.332163Z","shell.execute_reply.started":"2021-06-12T10:29:14.282737Z","shell.execute_reply":"2021-06-12T10:29:14.331298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yhat = model.predict(testX)\ntest_y = lb.inverse_transform(yhat)","metadata":{"_cell_guid":"4036ca95-2dd7-4bc2-83cc-49a61b5516cb","_uuid":"fb2e7a394c6de6daff7963689cec3783a7160846","execution":{"iopub.status.busy":"2021-06-12T10:29:20.327562Z","iopub.execute_input":"2021-06-12T10:29:20.327927Z","iopub.status.idle":"2021-06-12T10:29:20.993256Z","shell.execute_reply.started":"2021-06-12T10:29:20.327897Z","shell.execute_reply":"2021-06-12T10:29:20.992401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(data={'file': names, 'species': test_y})\ndf_sort = df.sort_values(by=['file'])\ndf_sort.to_csv('results.csv', index=False)","metadata":{"_cell_guid":"ba5e4b1e-5e87-4648-9c3e-c6a68064c4fb","_uuid":"0058bfe0909c8d0fc881602a7edd9c7e16a597f0","execution":{"iopub.status.busy":"2021-06-12T10:29:38.250397Z","iopub.execute_input":"2021-06-12T10:29:38.250763Z","iopub.status.idle":"2021-06-12T10:29:38.508533Z","shell.execute_reply.started":"2021-06-12T10:29:38.25073Z","shell.execute_reply":"2021-06-12T10:29:38.507683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}