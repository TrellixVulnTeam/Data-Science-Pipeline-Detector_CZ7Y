{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Setting up","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport PIL\nimport os\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport pathlib\nimport cv2\n\nfrom mpl_toolkits.axes_grid1 import ImageGrid","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(tf.__version__)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data","metadata":{}},{"cell_type":"code","source":"path_train = '../input/plant-seedlings-classification/train'\ndata_dir = pathlib.Path(path_train)\nfolder = list(data_dir.glob('*'))\nimages = list(data_dir.glob('*/*.png')) #list of all images (full path)\nprint('Folder Structure:')\nfor f in folder:\n    print(f)\nprint('\\nNumber of images: ', len(images))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Explore","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(10, 10))\nfor i in range(9):\n    plt.subplot(3, 3, i + 1)\n    plt.title(str(images[i]).split('/')[-1], fontsize=10) #get the file name and disply as title\n    plt.imshow(PIL.Image.open(images[i]))\n    ax = plt.axis(\"off\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Preparing Data for Modeling","metadata":{}},{"cell_type":"code","source":"image_size = 256\nbatch_size = 32","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idg = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1./255,\n    horizontal_flip=True,\n    vertical_flip=True,\n    validation_split=0.2\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_gen = idg.flow_from_directory(path_train,\n                                    target_size=(image_size, image_size),\n                                    subset='training',\n                                    class_mode='categorical',\n                                    batch_size=batch_size,\n                                    shuffle=True,\n                                    seed=1\n                                    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_gen = idg.flow_from_directory(path_train,\n                                  target_size=(image_size, image_size),                                                   \n                                  subset='validation',\n                                  class_mode='categorical',\n                                  batch_size=batch_size,\n                                  shuffle=True,\n                                  seed=1\n                                  )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Classify Train Data","metadata":{}},{"cell_type":"code","source":"classes = train_gen.class_indices\nprint(classes)\nclass_names = []\nfor c in classes:\n    class_names.append(c)\nprint('The name of the classes are: ', class_names)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Explore Classification","metadata":{}},{"cell_type":"code","source":"unique, counts = np.unique(train_gen.classes, return_counts=True)\ndict1 = dict(zip(train_gen.class_indices, counts))\n\nkeys = dict1.keys()\nvalues = dict1.values()\n\nplt.xticks(rotation='vertical')\nbar = plt.bar(keys, values)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x,y = next(train_gen)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(None, (10,10),frameon=False)\ngrid = ImageGrid(fig, 111, \n                 nrows_ncols=(2, 4),  \n                 axes_pad=0.2, \n                 share_all=True,\n                 )\nfor i in range(2*4):\n    ax = grid[i]\n    ax.imshow(x[i],cmap='Greys_r')\n    ax.axis('off')        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Modeling","metadata":{}},{"cell_type":"code","source":"model = tf.keras.models.Sequential()\nmodel.add(tf.keras.layers.InputLayer(input_shape=(image_size,image_size,3,))) # Input layer\nmodel.add(tf.keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu')) # 2D Convolution layer\nmodel.add(tf.keras.layers.MaxPool2D(pool_size = (2,2))) # Max Pool layer \nmodel.add(tf.keras.layers.BatchNormalization()) # Normalization layer\nmodel.add(tf.keras.layers.Conv2D(64, kernel_size=(3,3), strides = (1,1), activation='relu')) # 2D Convolution layer\nmodel.add(tf.keras.layers.MaxPool2D(pool_size = (2,2))) # Max Pool layer \nmodel.add(tf.keras.layers.BatchNormalization()) # Normalization layer\nmodel.add(tf.keras.layers.Conv2D(128, kernel_size=(3,3), strides = (1,1), activation='relu')) # 2D Convolution layer\nmodel.add(tf.keras.layers.MaxPool2D(pool_size = (2,2))) # Max Pool layer \nmodel.add(tf.keras.layers.BatchNormalization()) # Normalization layer\nmodel.add(tf.keras.layers.Conv2D(128, kernel_size=(3,3), strides = (1,1), activation='relu')) # 2D Convolution layer\nmodel.add(tf.keras.layers.MaxPool2D(pool_size = (2,2))) # Max Pool layer \nmodel.add(tf.keras.layers.GlobalMaxPool2D()) # Global Max Pool layer\nmodel.add(tf.keras.layers.Flatten()) # Dense Layers after flattening the data\nmodel.add(tf.keras.layers.Dense(128, activation='relu'))\nmodel.add(tf.keras.layers.Dropout(0.2)) # Dropout\nmodel.add(tf.keras.layers.Dense(64, activation='relu'))\nmodel.add(tf.keras.layers.BatchNormalization()) # Normalization layer\nmodel.add(tf.keras.layers.Dense(12, activation='softmax')) # Add Output Layer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint = tf.keras.callbacks.ModelCheckpoint('plant_classifier.h5', #where to save the model\n                                                save_best_only=True, \n                                                monitor='val_accuracy', \n                                                mode='max', \n                                                verbose = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training","metadata":{}},{"cell_type":"code","source":"activity = model.fit(train_gen,\n          epochs=20, # Increase number of epochs if you have sufficient hardware\n          steps_per_epoch= 3803//batch_size,  # Number of train images // batch_size\n          validation_data=val_gen,\n          validation_steps = 947//batch_size, # Number of val images // batch_size\n          callbacks = [checkpoint],\n          verbose = 1\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(activity.history['accuracy'], label='accuracy')\nplt.plot(activity.history['val_accuracy'], label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.xticks(list(range(1,21)))\nplt.ylim([0, 1])\nplt.legend(loc='lower right')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prediction","metadata":{}},{"cell_type":"code","source":"maize = cv2.imread(path_train+'/Maize/6e9ff31e7.png')\nax = plt.imshow(maize)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"maize = cv2.resize(maize, (256,256))\nmaize_batch = np.expand_dims(maize, axis=0)\nconv_maize = model.predict(maize_batch)\nconv_maize.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = tf.nn.softmax(conv_maize[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"simple_model = tf.keras.models.Sequential()\nsimple_model.add(tf.keras.layers.Conv2D(1,3,3,input_shape=maize.shape)) # 3x3 kernel\n\nmaize_batch = np.expand_dims(maize, axis=0)\nconv_maize2 = simple_model.predict(maize_batch)\nconv_maize2 = np.squeeze(conv_maize2, axis=0)\n    \nprint(conv_maize2.shape)\nconv_maize2 = conv_maize2.reshape(conv_maize2.shape[:2])\nprint(conv_maize2.shape)\n\nax = plt.imshow(conv_maize2)\nax = plt.title(\"This is a image of {} ({:.2f}% confidence).\".format(class_names[np.argmax(score)], 100 * np.max(score)), fontsize=12)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}