{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Setting it up","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport PIL\nimport tensorflow as tf\nimport pathlib\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\n\nprint(tf.__version__)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data","metadata":{}},{"cell_type":"code","source":"data_dir_train_path = '/kaggle/input/plant-seedlings-classification/train'\ndata_dir_train = pathlib.Path(data_dir_train_path)\n\nfolder_train = list(data_dir_train.glob('*'))\nimages_train = list(data_dir_train.glob('*/*.png')) #list of all images (full path)\nprint('Folder Structure:')\nfor f in folder_train:\n    print(f)\nprint('\\nNumber of images: ', len(images_train))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir_test_path = '/kaggle/input/plant-seedlings-classification/test'\ndata_dir_test = pathlib.Path(data_dir_test_path)\n\nimages_test = list(data_dir_test.glob('*.png')) #list of all images (full path)\nprint('\\nNumber of images: ', len(images_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Exploreing the data","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(10, 10))\nfor i in range(9):\n    plt.subplot(3, 3, i + 1)\n    plt.title(str(images_train[i]).split('/')[-1], fontsize=10) #get the file name and disply as title\n    plt.imshow(PIL.Image.open(images_train[i]))\n    ax = plt.axis(\"off\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\nimg_height = 256\nimg_width = 256","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Building Training Data Set from images","metadata":{}},{"cell_type":"code","source":"train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    data_dir_train,\n    validation_split=0.8, #80% training\n    subset=\"training\",\n    seed=123,\n    image_size=(img_height, img_width),\n    batch_size=batch_size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    data_dir_train,\n    validation_split=0.2, #20% validation\n    subset=\"validation\",\n    seed=123,\n    image_size=(img_height, img_width),\n    batch_size=batch_size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Classification of data","metadata":{}},{"cell_type":"code","source":"class_names = train_ds.class_names\nprint('The name of the classes are: ')\nfor c in class_names:\n    print('\\t*',c)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Exploreing Images after Classification","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(10, 10))\nfor images, labels in train_ds.take(1):\n    for i in range(9):\n        plt.subplot(3, 3, i + 1)\n        plt.title(class_names[labels[i]], fontsize=10)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        ax = plt.axis(\"off\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Building Model","metadata":{}},{"cell_type":"code","source":"AUTOTUNE = tf.data.AUTOTUNE\n\ntrain_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\nval_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n\nnormalization_layer = layers.experimental.preprocessing.Rescaling(1./255)\n\nnormalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y)) #lambda\nimage_batch, labels_batch = next(iter(normalized_ds))\n\nfirst_image = image_batch[0]\n\nprint(np.min(first_image), np.max(first_image)) #pixels values are now in [0,1].","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_augmentation = keras.Sequential(\n    [\n        layers.experimental.preprocessing.RandomFlip(\"horizontal\", \n                                                 input_shape=(img_height, \n                                                              img_width,\n                                                              3)),\n        layers.experimental.preprocessing.RandomRotation(0.1),\n        layers.experimental.preprocessing.RandomZoom(0.1),\n    ]\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 10))\nfor images, _ in train_ds.take(1):\n    for i in range(9):\n        augmented_images = data_augmentation(images)\n        plt.subplot(3, 3, i + 1)\n        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n        ax = plt.axis(\"off\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Compiling Model","metadata":{}},{"cell_type":"code","source":"model = tf.keras.models.Sequential()\nmodel.add(tf.keras.layers.InputLayer(input_shape=(img_width,img_height,3,))) # Input layer\nmodel.add(tf.keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu')) # 2D Convolution layer\nmodel.add(tf.keras.layers.MaxPool2D(pool_size = (2,2))) # Max Pool layer \nmodel.add(tf.keras.layers.BatchNormalization()) # Normalization layer\nmodel.add(tf.keras.layers.Conv2D(64, kernel_size=(3,3), strides = (1,1), activation='relu')) # 2D Convolution layer\nmodel.add(tf.keras.layers.MaxPool2D(pool_size = (2,2))) # Max Pool layer \nmodel.add(tf.keras.layers.BatchNormalization()) # Normalization layer\nmodel.add(tf.keras.layers.Conv2D(128, kernel_size=(3,3), strides = (1,1), activation='relu')) # 2D Convolution layer\nmodel.add(tf.keras.layers.MaxPool2D(pool_size = (2,2))) # Max Pool layer \nmodel.add(tf.keras.layers.BatchNormalization()) # Normalization layer\nmodel.add(tf.keras.layers.Conv2D(128, kernel_size=(3,3), strides = (1,1), activation='relu')) # 2D Convolution layer\nmodel.add(tf.keras.layers.MaxPool2D(pool_size = (2,2))) # Max Pool layer \nmodel.add(tf.keras.layers.GlobalMaxPool2D()) # Global Max Pool layer\nmodel.add(tf.keras.layers.Flatten()) # Dense Layers after flattening the data\nmodel.add(tf.keras.layers.Dense(128, activation='relu'))\nmodel.add(tf.keras.layers.Dropout(0.2)) # Dropout\nmodel.add(tf.keras.layers.Dense(64, activation='relu'))\nmodel.add(tf.keras.layers.BatchNormalization()) # Normalization layer\nmodel.add(tf.keras.layers.Dense(12, activation='softmax')) # Add Output Layer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training","metadata":{}},{"cell_type":"code","source":"epochs = 15 #the cycle\nactivity = model.fit(train_ds, validation_data=val_ds, epochs=epochs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = activity.history['accuracy']\nval_acc = activity.history['val_accuracy']\n\nloss = activity.history['loss']\nval_loss = activity.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(16, 8))\n\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\nplt.grid()\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.grid()\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prediction","metadata":{}},{"cell_type":"code","source":"data_dir_test_path = '../input/plant-seedlings-classification/test/007b3da8b.png'\n\nimg = keras.preprocessing.image.load_img(data_dir_test_path, target_size=(img_height, img_width))\nimg_array = keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0) #in the format it should be to perform prediction\n\npredictions = model.predict(img_array)\nscore = tf.nn.softmax(predictions[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 10))\nplt.title(\"This is a image of {} ({:.2f}% confidence).\".format(class_names[np.argmax(score)], 100 * np.max(score)), fontsize=12)\nplt.imshow(PIL.Image.open(data_dir_test_path))\nax = plt.axis(\"off\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}