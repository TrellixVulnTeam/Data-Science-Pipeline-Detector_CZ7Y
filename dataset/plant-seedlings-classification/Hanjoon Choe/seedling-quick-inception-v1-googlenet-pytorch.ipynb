{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"## This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n'''\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n'''\n\n# Any results you write to the current directory are saved as output.\nimport cv2\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset,DataLoader\nfrom tqdm import tqdm_notebook as tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class InceptionBranch(nn.Module):\n    \n    def __init__(self,in_channels,out_1x1,out_3x3_1,out_3x3_2,out_5x5_1,out_5x5_2,out_pool):\n        super().__init__()\n        self.branch1 = nn.Sequential(\n            nn.Conv2d(in_channels,out_1x1, kernel_size=1,stride=1,padding=0),\n            nn.BatchNorm2d(out_1x1),\n            nn.ReLU(True)\n        )\n        self.branch2 = nn.Sequential(\n            nn.Conv2d(in_channels,out_3x3_1, kernel_size=1,stride=1,padding=0),\n            nn.BatchNorm2d(out_3x3_1),\n            nn.ReLU(True),\n            nn.Conv2d(out_3x3_1,out_3x3_2, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(out_3x3_2),\n            nn.ReLU(True)\n        )\n        self.branch3 = nn.Sequential(\n            nn.Conv2d(in_channels,out_5x5_1,kernel_size=1,stride=1,padding=0),\n            nn.BatchNorm2d(out_5x5_1),\n            nn.ReLU(True),\n            nn.Conv2d(out_5x5_1,out_5x5_2,kernel_size=5,stride=1,padding=2),\n            nn.BatchNorm2d(out_5x5_2),\n            nn.ReLU(True)\n        )\n        self.branch4 = nn.Sequential(\n            nn.MaxPool2d(kernel_size=3,stride=1,padding=1),\n            nn.Conv2d(in_channels,out_pool,kernel_size=1, stride=1,padding=0),\n            nn.BatchNorm2d(out_pool),\n            nn.ReLU(True)\n        )\n        \n    def forward(self,x):\n        return torch.cat([self.branch1(x),self.branch2(x),self.branch3(x),self.branch4(x)],1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Googlenet(nn.Module):\n    def __init__(self,n_classes):\n        super().__init__()\n        self.pre_layer = nn.Sequential(\n            nn.Conv2d(in_channels=3,out_channels=64,kernel_size=7,stride=2,padding=3),\n            nn.ReLU(True),\n            nn.MaxPool2d(kernel_size=3,stride=2,ceil_mode=True),\n            nn.CrossMapLRN2d(5,1e-3,0.75,1),\n            nn.Conv2d(in_channels=64,out_channels=64,kernel_size=1,stride=1,padding=0),\n            nn.ReLU(True),\n            nn.Conv2d(in_channels=64,out_channels=192,kernel_size=3,stride=1,padding=1),\n            nn.ReLU(True),\n            nn.CrossMapLRN2d(5,1e-3,0.75,1),\n            nn.MaxPool2d(kernel_size=3,stride=2,ceil_mode=True)\n        )\n            \n        self.block1 = InceptionBranch(192,64,96,128,16,32,32)\n        self.block2 = InceptionBranch(256,128,128,192,32,96,64)\n        self.block3 = InceptionBranch(480,192,96,208,16,48,64)\n        self.block4 = InceptionBranch(512,160,112,224,24,64,64)\n        self.block5 = InceptionBranch(512,128,128,256,24,64,64)\n        self.block6 = InceptionBranch(512,112,144,288,32,64,64)\n        self.block7 = InceptionBranch(528,256,160,320,32,128,128)\n        self.block8 = InceptionBranch(832,256,160,320,32,128,128)\n        self.block9 = InceptionBranch(832,384,192,384,48,128,128)\n        self.fc = nn.Linear(1024,n_classes)\n            \n    def forward(self,x):\n        x = self.pre_layer(x)\n        x = self.block1(x)\n        x = self.block2(x)\n        x = F.max_pool2d(x,kernel_size=2,stride=2,ceil_mode=True)\n        x = self.block3(x)\n        x = self.block4(x)\n        x = self.block5(x)\n        x = self.block6(x)\n        x = self.block7(x)\n        x = F.max_pool2d(x,kernel_size=2,stride=2,ceil_mode=True)\n        x = self.block8(x)\n        x = self.block9(x)\n        x = F.avg_pool2d(x,kernel_size=2,stride=1,ceil_mode=True)\n        x = x.view(x.size(0),-1)\n        x = self.fc(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"!pip install torchsummary\nmodel = Googlenet(2)\nfrom torchsummary import summary\nsummary(model,(3, 56, 56))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"class Resize(object):\n    \n    def __call__(self,resize):\n        records = {}\n        root = '/kaggle/input/plant-seedlings-classification/'\n        for _type in ['train','test']:\n            path = os.path.join(root,_type)\n            if _type == 'train':\n                !rm -r resized_train\n                !mkdir resized_train\n                classes = os.listdir(path)\n                for _class in classes:\n                    print(f'resized {_class}')\n                    path1 = os.path.join(path,_class)\n                    os.mkdir(f'resized_train/{_class}')\n                    for root,_,fnames in sorted(os.walk(path1,followlinks=True)):\n                        for fname in fnames:\n                            if '.png' in fname:\n                                image = cv2.imread(os.path.join(root,fname))\n                                try:\n                                    image = cv2.resize(image,(resize,resize))\n                                    result = cv2.imwrite(f'resized_train/{_class}/{fname}',image)\n                                    print(f'train successfully saved at resized_train/{_class}/{fname}')\n                                    records[f'resized_train/{_class}/{fname}'] = f'{_class}'\n                                except:\n                                    raise print('got {} which is invalid'.format(resize))\n                records = pd.DataFrame.from_dict(records,orient='index').reset_index().rename(columns={'index':'fname',0:'label'})\n                return records\n            else:\n                !rm -r resized_test\n                !mkdir resized_test\n                print('resize test')\n                for root,_,fnames in sorted(os.walk(path,followlinks=True)):\n                    for fname in fnames:\n                        if '.png' in fname:\n                            image = cv2.imread(os.path.join(root,fname))\n                            try:\n                                image = cv2.resize(image,(resize,resize))\n                                result = cv2.imwrite(f'resized_test/{fname}', image)\n                                print(f'test :{fname} successfully saved {result}')\n                            except:\n                                print('got {} which is invalid'.format(resize))\n                            \n                                \n                        ","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"resize = Resize()\ntrain = resize(56)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seedling_num_dict = {idx:i for idx,i in enumerate(train.label.unique())}\nseedling_dict = {i:idx for idx,i in enumerate(train.label.unique())}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['num_label'] = train.label.map(seedling_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seedling_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SeedlingDataset(Dataset):\n    def __init__(self,df,_type='train'):\n        if _type=='train':\n            self.df = df\n            self.root = 'resized_train'\n        elif _type=='test':\n            self.root = 'resized_test'\n        else:\n            raise print(f'shoud be either train or test but got {_type}')\n    def __len__(self):\n        return len(self.df)\n    def __getitem__(self,idx):\n        fname = self.df.fname.values[idx]\n        Image = cv2.imread(fname)\n        label = self.df.num_label[idx]\n        return Image, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = SeedlingDataset(train,_type='train')\ntrain_dataloader = torch.utils.data.DataLoader(train_data,shuffle=True,batch_size=6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\na = next(iter(train_dataloader))\nfig,ax = plt.subplots(2,3,figsize=(25,25))\n\nfor i in range(6):\n    j = i//3\n    k = i%3\n    ax[j,k].imshow(a[0][i])\n    ax[j,k].set_title(seedling_num_dict[int(a[1][i])],fontsize=20)\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel = Googlenet(12).to(device)\noptimizer = torch.optim.Adam(model.parameters(),lr=1e-3)\ncriterion = nn.CrossEntropyLoss()\nepochs = 2\nbatch_size = 32","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"losses = []\naccs = []\ntrain_data = SeedlingDataset(train,_type='train')\ntrain_loader = torch.utils.data.DataLoader(train_data,shuffle=True,batch_size=batch_size)\nfor epoch in range(epochs):\n    running_loss = 0.0\n    running_acc = 0.0\n    for idx,(inputs,labels) in tqdm(enumerate(train_loader),total=len(train_loader)):\n        \n        inputs = inputs.to(device)\n        labels = labels.to(device)\n        \n        outputs = model(inputs.permute(0,3,2,1).float())\n        \n        loss = criterion(outputs,labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss\n        running_acc += (torch.argmax(outputs,1).unsqueeze(0)==labels).float().mean()\n        running_loss += loss\n    print('{}/{} : loss : {:.4f} || acc: {:.2f}%'.format(epoch+1,epochs,running_loss/len(train_loader),running_acc/len(train_loader)))\n    losses.append(running_loss/len(train_loader))\n    accs.append(running_acc/len(train_loader))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm -r resized_train\n!rm -r resized_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(1,2,figsize=(15,5))\nax[0].plot(losses)\nax[0].set_title('loss')\nax[1].plot(accs)\nax[1].set_title('acc')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}