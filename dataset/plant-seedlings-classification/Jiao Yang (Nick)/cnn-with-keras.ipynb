{"cells":[{"metadata":{"_cell_guid":"e542f02f-2ba9-4eda-a521-55e12bf28178","_uuid":"03e7f1631f5f3adbbd04b3dfbbfc7bb9c9b90b8d","trusted":true},"cell_type":"code","source":"import glob\nimport os\nfrom PIL import Image, ImageOps\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelBinarizer\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport time","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a5dd64e1-3e32-42dc-a3ac-c03ca0e9e31c","_uuid":"4f0efe6ef8f57aa45e217f55bd379bbcb79846d2","trusted":true},"cell_type":"code","source":"'''\nI data engineering \n'''\nimgs_size = 128\n# imgs_size = 75\n# imgs_size = 48\n# imgs_size = 100\nz = glob.glob('../input/plant-seedlings-classification/train/*/*.png')\nori_label = [] # create empty list to store labels\nori_imgs = []  # create empty list to store images\nfor fn in z:\n    if fn[-3:] != 'png':\n        continue\n    ori_label.append(fn.split('/')[-2])\n    new_img = Image.open(fn)\n    ori_imgs.append(ImageOps.fit(new_img, (imgs_size, imgs_size), Image.ANTIALIAS).convert('RGB'))   \n    # reshape the image to 128 X 128 size, use antialias and convert it to RGB\n\nimgs = np.array([np.array(im) for im in ori_imgs])\nimgs = imgs.reshape(imgs.shape[0], imgs_size, imgs_size, 3) / 255  # nomalization\n# imgs = imgs.reshape(imgs.shape[0], 128,128, 3)\nlb = LabelBinarizer().fit(ori_label) \nlabel = lb.transform(ori_label) # transform the label to a matrix\ntrainX, validX, trainY, validY = train_test_split(imgs, label, test_size=0.15, random_state=20) # split the data set","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3aa8b322-1011-468b-b730-b8cd584576bf","_uuid":"664da8ae62cbeb72bb7b696c8351a62167248206","trusted":true},"cell_type":"code","source":"'''\nII creating model\n'''\nrunning_time = time.time()\nfrom keras.layers import Dropout, Input, Dense, Activation,GlobalMaxPooling2D, BatchNormalization, Flatten, Conv2D, MaxPooling2D\nfrom keras.models import Model, load_model\nfrom keras.optimizers import Adam\nimport keras\nmodel = keras.Sequential()\nIM_input = Input((imgs_size, imgs_size, 3))\nIM = Conv2D(64, (5,5))(IM_input) # convolution layer: 64 2X2 filter with stride 1\nIM = BatchNormalization(axis = 3)(IM) # Batch Normalization to mitigate the Internal Covariate Shift \nIM = Activation('relu')(IM)  # Relu function \n# IM = MaxPooling2D((3, 3), strides=(2, 2), padding = 'same')(IM)\nIM = Conv2D(64, (5,5))(IM) \nIM = BatchNormalization(axis = 3)(IM)\nIM = Activation('relu')(IM)\nIM = MaxPooling2D((2, 2), strides=(2, 2), padding = 'same')(IM)  # maxpooling layer: 3X3 filter with stride 2. NO Padding\n\nIM = Conv2D(128, (5,5))(IM) \nIM = BatchNormalization(axis = 3)(IM)\nIM = Activation('relu')(IM)\n# IM = MaxPooling2D((3, 3), strides=(2, 2), padding = 'same')(IM)\nIM = Conv2D(128, (5,5))(IM)\nIM = BatchNormalization(axis = 3)(IM)\nIM = Activation('relu')(IM)\nIM = MaxPooling2D((2, 2), strides=(2, 2), padding = 'same')(IM)\n\nIM = Conv2D(256, (5,5))(IM)\nIM = BatchNormalization(axis = 3)(IM)\nIM = Activation('relu')(IM)\n# IM = MaxPooling2D((3, 3), strides=(2, 2), padding = 'same')(IM)\nIM = Conv2D(256, (5,5))(IM)\nIM = BatchNormalization(axis = 3)(IM)\nIM = Activation('relu')(IM)\nIM = MaxPooling2D((3, 3), strides=(2, 2), padding = 'same')(IM)\n\nIM = Conv2D(512, (2, 2))(IM)\nIM = BatchNormalization(axis = 3)(IM)\nIM = Activation('relu')(IM)\n# IM = MaxPooling2D((3, 3), strides=(2, 2), padding = 'same')(IM)\nIM = Conv2D(512, (2, 2))(IM)\nIM = BatchNormalization(axis = 3)(IM)\nIM = Activation('relu')(IM)\n# IM = MaxPooling2D((3, 3), strides=(2, 2))(IM)\n\nIM = GlobalMaxPooling2D()(IM)\n# IM = keras.layers.Flatten()(IM)\n\n# IM = Dense(512, activation='relu')(IM)  #  fully-connected layer with 512 nodes \n# IM = Dropout(0.3)(IM)\n# IM = Dense(256, activation='relu')(IM)\n# IM = Dropout(0.2)(IM)\nIM = Dense(128, activation='relu')(IM)\nIM = Dropout(0.1)(IM)\nIM = Dense(64, activation='relu')(IM)\nIM = Dense(12, activation='softmax')(IM) # softmax layer with 12 classes\nmodel = Model(inputs=IM_input, outputs=IM)\nmodel.summary()\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=Adam(lr=1e-3), metrics=['acc'])\n# model.compile(loss='categorical_crossentropy',metrics=['acc'])","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"_uuid":"3776b4ad6a904fa3c204d31e19402d9a2d76dee1","_cell_guid":"6f72071b-14cf-4e3f-845f-992be6f7f52c","trusted":true},"cell_type":"code","source":"'''\nIII traing model\n'''\nfrom keras.callbacks import LearningRateScheduler, EarlyStopping\nfrom keras.callbacks import ModelCheckpoint\n\nbatch_size = 30  # batch size is 20\nepochs = 200\nlearning_rate = LearningRateScheduler(lambda x: 1e-3 * 0.9 ** x,verbose = 1)\n\n\nearlystop = EarlyStopping(patience=30) # stop training when the validation loss does not change for 50 iterations\n\nmodelsave = ModelCheckpoint(filepath='model.h5', save_best_only=True, verbose=1)\n\nmodel_value = model.fit(trainX, trainY, batch_size=batch_size,\n                        epochs= epochs, # maximum 200 iterations\n                        validation_data=(validX, validY),\n                        callbacks=[learning_rate, earlystop, modelsave])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nIV augmentation\n'''\n# construct the training image generator for data augmentation\naug = keras.preprocessing.image.ImageDataGenerator(rotation_range=20, zoom_range=0.15,\n                                                   width_shift_range=0.2, height_shift_range=0.2, \n                                                   shear_range=0.15, horizontal_flip=True, fill_mode=\"nearest\")\n# train the network\nmodel_value_aug = model.fit_generator(aug.flow(trainX, trainY, batch_size=batch_size),\n                                  validation_data=(validX, validY), \n                                  steps_per_epoch=len(trainX) // batch_size,\n                                  epochs=epochs,\n                                  callbacks=[learning_rate, earlystop, modelsave])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1f953f1c-39b3-4160-89aa-e546719f2fef","_uuid":"20834884a92a67eb750e7d70350ca86585abfef3","trusted":true},"cell_type":"code","source":"'''\nV testing\n'''\nz = glob.glob('../input/plant-seedlings-classification/test/*.png')\ntest_imgs = []\nnames = []\nfor fn in z:\n    if fn[-3:] != 'png':\n        continue\n    names.append(fn.split('/')[-1])\n    new_img = Image.open(fn)\n    test_img = ImageOps.fit(new_img, (imgs_size, imgs_size), Image.ANTIALIAS).convert('RGB')\n    test_imgs.append(test_img)\nmodel = load_model('model.h5')\ntimgs = np.array([np.array(im) for im in test_imgs])\ntestX = timgs.reshape(timgs.shape[0], imgs_size, imgs_size, 3) / 255\n# testX = timgs.reshape(timgs.shape[0], 128,128, 3) \n\nprediction = model.predict(testX) # make prediction\ntest_y = lb.inverse_transform(prediction) # transform the prediction to an array","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"running_time = time.time()-running_time\nprint(running_time)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ba5e4b1e-5e87-4648-9c3e-c6a68064c4fb","_uuid":"0058bfe0909c8d0fc881602a7edd9c7e16a597f0","trusted":true},"cell_type":"code","source":"'''\nVI output result\n'''\ndf = pd.DataFrame(data={'file': names, 'species': test_y})\ndf_sort = df.sort_values(by=['file'])\ndf_sort.to_csv('results.csv', index=False) # output the results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nVII plotting picture for traing\n'''\nimport matplotlib.pyplot as plt\nepoch_num = []\nfor i in range(200):\n    epoch_num.append(i+1)\nepoch_num = pd.DataFrame(epoch_num)\nacc = pd.DataFrame(model_value.history['acc'])\nloss = pd.DataFrame(model_value.history['loss'])\nval_acc = pd.DataFrame(model_value.history['val_acc'])\nval_loss = pd.DataFrame(model_value.history['val_loss'])\n\ntrain_model = pd.concat((acc, loss, val_acc, val_loss, epoch_num),axis=1, \n                                  ignore_index=True) # create a list\ntrain_model.columns = ['acc', 'loss', 'val_acc', 'val_loss', 'Epochs'] # change the column index\n\ntrain_model.acc.plot(x = 'epoch_num',label = 'Train accuracy',legend = True)\ntrain_model.loss.plot(x = 'epoch_num',label = 'Train loss',legend = True)\ntrain_model.val_acc.plot(x = 'epoch_num',label = 'Validation accuracy',legend = True)\ntrain_model.val_loss.plot(x = 'epoch_num',label = 'Validation loss',legend = True,\n                          figsize = (16,10),grid=True, fontsize=15)\n\nplt.xlabel('Epochs',fontsize = 15) # x axis\nplt.ylabel('Rate',fontsize = 15) # y axis\nplt.title('Training model',fontsize = 20) # figure title\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nVIII plotting picture for augmentation\n'''\nimport matplotlib.pyplot as plt\nepoch_num = []\nfor i in range(200):\n    epoch_num.append(i+1)\nepoch_num = pd.DataFrame(epoch_num)\nacc = pd.DataFrame(model_value_aug.history['acc'])\nloss = pd.DataFrame(model_value_aug.history['loss'])\nval_acc = pd.DataFrame(model_value_aug.history['val_acc'])\nval_loss = pd.DataFrame(model_value_aug.history['val_loss'])\n\ntrain_model = pd.concat((acc, loss, val_acc, val_loss, epoch_num),axis=1, \n                                  ignore_index=True) # create a list\ntrain_model.columns = ['acc', 'loss', 'val_acc', 'val_loss', 'Epochs'] # change the column index\n\ntrain_model.acc.plot(x = 'epoch_num',label = 'Train accuracy',legend = True)\ntrain_model.loss.plot(x = 'epoch_num',label = 'Train loss',legend = True)\ntrain_model.val_acc.plot(x = 'epoch_num',label = 'Validation accuracy',legend = True)\ntrain_model.val_loss.plot(x = 'epoch_num',label = 'Validation loss',legend = True,\n                          figsize = (16,10),grid=True, fontsize=15)\n\nplt.xlabel('Epochs',fontsize = 15) # x axis\nplt.ylabel('Rate',fontsize = 15) # y axis\nplt.title('Augmentation Training model',fontsize = 20) # figure title\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}