{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport pandas_profiling\nimport os\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nimport random\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision\nimport torchvision.transforms as transforms\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_img = Image.open('/kaggle/input/plant-seedlings-classification/train/Maize/92c06eaca.png')\ntest_img = test_img.resize((200, 200))\ntest_img = np.array(test_img)\nplt.imshow(test_img)\nplt.show()\nprint(test_img.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_dir = '/kaggle/input/plant-seedlings-classification/train'\ntest_data_dir = '/kaggle/input/plant-seedlings-classification/test'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_bad_images(train_path, test_path):\n    bad_images = []\n    images = []\n    \n    classes = [dI for dI in os.listdir(train_path) if os.path.isdir(os.path.join(train_path, dI))]\n    for cl in classes:\n        class_dir = os.path.join(train_path, cl)\n        for img in os.listdir(class_dir):\n            images.append(os.path.join(class_dir, img))\n\n    for test_img in os.listdir(test_path):\n        images.append(os.path.join(test_path, test_img))\n            \n    all_images = len(images)\n    \n    for img in images:\n        try:\n            _ = Image.open(img)\n        except:\n            bad_images.append(img)\n    \n    return set(bad_images)\n    \nbad_images = get_bad_images(train_data_dir, test_data_dir)\nbad_images","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"folders = [dI for dI in os.listdir(train_data_dir) if os.path.isdir(os.path.join(train_data_dir,dI))]\n\nclass_id = {}\nid_class = {}\nfor cl in range(len(folders)):\n    class_id[folders[cl]] = cl\n    id_class[cl] = [folders[cl]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(class_id)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_id","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"id_class","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = []\nval_data = []\nfor c in range(len(class_id.keys())):\n    cl = list(class_id.keys())[c]\n    class_path = os.path.join(train_data_dir, cl)\n    class_images = [os.path.join(class_path, dI) for dI in os.listdir(class_path)]\n    train, validation = train_test_split(class_images, shuffle=True, test_size=0.3)\n    \n    for t in train:\n        train_data.append([t, c])\n        \n    for v in validation:\n        val_data.append([v, c])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train_data)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SeedlingsTrainDataset(Dataset):\n    def __init__(self, data, transform=None):\n        self.data = data\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, index):\n        try:\n            img_path, c = self.data[index]\n            img = Image.open(img_path)\n\n            if self.transform is not None:\n                img = self.transform(img)\n        \n            return img, c     \n        except:\n            print('Bad image')\n            while True:\n                try:\n                    index = random.randint(0, len(self.data) - 2)\n                    img_path, c = self.data[index]\n                    img = Image.open(img_path)\n\n                    if self.transform is not None:\n                        img = self.transform(img)\n        \n                    return img, c\n                except:\n                    print('One more bad image')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SeedlingsValidationDataset(Dataset):\n    def __init__(self, data, transform=None):\n        self.data = data\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, index):\n        img_path, c = self.data[index]\n        img = Image.open(img_path)\n        \n        if self.transform is not None:\n            img = self.transform(img)\n        \n        return img, c       ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SeedlingsTestDataset(Dataset):\n    def __init__(self, data_path, transform=None):\n        self.data_path = data_path\n        self.transform = transform\n        \n        self.images = [dI for dI in os.listdir(self.data_path)]\n    \n    def __len__(self):\n        return len(self.images)\n    \n    def __getitem__(self, index):\n        img_path = os.path.join(self.data_path, self.images[index])\n        img = Image.open(img_path)\n        \n        if self.transform is not None:\n            img = self.transform(img)\n        \n        return img, self.images[index]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transforms = transforms.Compose([\n        transforms.Resize((200, 200)),\n        transforms.RandomHorizontalFlip(),\n        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1, hue=0.1),\n        transforms.RandomAffine(degrees=180, translate=None, scale=(1, 2), shear=15, resample=False, fillcolor=0),\n        transforms.ToTensor(),\n        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_transforms = transforms.Compose([\n        transforms.Resize((200, 200)),\n        transforms.ToTensor(),\n        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = SeedlingsTrainDataset(\n    train_data, \n    transform=train_transforms)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img, cl = train_dataset.__getitem__(150)\nplt.figure(figsize=(8, 8))\ntransforms.ToPILImage()(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_dataset = SeedlingsValidationDataset(\n    train_data, \n    transform=validation_transforms)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataset = SeedlingsTestDataset(\n    test_data_dir, \n    transform=validation_transforms)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = test_dataset.__getitem__(150)[0]\nprint(img.size())\nplt.figure(figsize=(8, 8))\ntransforms.ToPILImage()(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=8)\nvalidation_loader = DataLoader(validation_dataset, batch_size=1, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        \n        self.cnn_layers = nn.Sequential(\n            nn.Conv2d(3, 8, 3),\n            \n            nn.Conv2d(8, 8, 3),\n            nn.ReLU(),\n            nn.BatchNorm2d(8),\n            nn.Dropout(0.3),\n            \n            nn.Conv2d(8, 16, 3),\n            \n            nn.Conv2d(16, 16, 3),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n            nn.BatchNorm2d(16),\n            nn.Dropout(0.3),\n            \n            nn.Conv2d(16, 32, 3),\n            \n            nn.Conv2d(32, 32, 3),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n            nn.BatchNorm2d(32),\n            nn.Dropout(0.3),\n            \n            nn.Conv2d(32, 64, 3),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n            nn.BatchNorm2d(64),\n            nn.Dropout(0.3),\n            \n            nn.Conv2d(64, 128, 3),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n            nn.BatchNorm2d(128),\n            nn.Dropout(0.3),\n            \n            nn.Conv2d(128, 256, 3),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n            nn.BatchNorm2d(256),\n            nn.Dropout(0.3),\n            \n            nn.Conv2d(256, 512, 3)\n        )\n        \n        self.linear_layers = nn.Sequential(\n            nn.Linear(512 * 2 * 2, 512),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(512, 64),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(64, len(class_id))\n        )             \n\n    def forward(self, x):\n        x = self.cnn_layers(x)\n        x = x.view(x.size(0), -1)\n        x = self.linear_layers(x)\n        return x\n\nnet = Net()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# I used 10 epochs\nfor epoch in range(1):\n\n    running_loss = 0.0\n    for i, data in enumerate(iter(train_loader), 0):\n        inputs, labels = data\n\n        optimizer.zero_grad()\n\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        if i % 50 == 49:\n            print('[%d, %5d] loss: %.3f' %\n                  (epoch + 1, i + 1, running_loss / 50))\n            running_loss = 0.0\n    \n    scheduler.step()\n\nprint('Finished Training')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(net.state_dict(), '/kaggle/working/simple_cnn_10l.pth')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net = Net()\nnet.load_state_dict(torch.load('/kaggle/working/simple_cnn_10l.pth'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Validation accuracy in 32%\n# correct = 0\n# top3 = 0\n# total = 0\n# with torch.no_grad():\n#     #batch_size = 1\n#     for i in range(len(validation_dataset)):\n#         try:\n#             images, label = validation_dataset.__getitem__(i)\n#             images = images[None, :, :]\n            \n#             predictions = net(images).numpy()[0].argsort()[::-1]\n            \n#             if label == predictions[0]:\n#                 correct += 1\n            \n#             if label in predictions[:3]:\n#                 top3 += 1\n            \n#             total += 1\n#         except:\n#             print('exception')\n\n# print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))\n# print('Accuracy of the network on the test images (top 3): %d %%' % (100 * top3 / total))\n# print('Total: ', total)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"files = []\npredictions = []\nwith torch.no_grad():\n    for img, file in test_loader:\n        prediction = net(img).numpy()[0].argsort()[-1]\n        files.append(file[0])\n        predictions.append(id_class[prediction][0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame({\n    'file': files,\n    'species': predictions\n})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}