{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n#visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#keras import\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, Dense, Flatten, Dropout, MaxPool2D, BatchNormalization, AveragePooling2D\nfrom keras.layers import GlobalAveragePooling2D\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Model\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing import image\nfrom keras.optimizers import Adam, RMSprop, SGD\nfrom keras.applications.resnet50 import ResNet50\nfrom sklearn.utils import shuffle\n\nfrom tqdm import tqdm\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prepare the dataset"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"base_dir = '../input'\ntrain_dir = os.path.join(base_dir, 'train')\ntest_dir = os.path.join(base_dir, 'test')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.listdir(train_dir))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false},"cell_type":"markdown","source":"**Here each directory inside train_dir represents a category and contains images for that category**. To prepare the dataset for training we can loop through each of those directories get the images inside it and the corresponding labels"},{"metadata":{},"cell_type":"markdown","source":"### Preparing training set"},{"metadata":{"trusted":true},"cell_type":"code","source":"categories = ['Fat Hen', 'Black-grass', 'Cleavers', 'Small-flowered Cranesbill', 'Sugar beet',\n              'Common Chickweed', 'Maize', 'Loose Silky-bent', 'Common wheat', 'Scentless Mayweed', 'Shepherds Purse', 'Charlock']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for category in categories:\n    print('{} {} images'.format(category, len(os.listdir(os.path.join(train_dir, category)))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = []\nfor category_id, category in enumerate(categories):\n    for imagefile in os.listdir(os.path.join(train_dir, category)):\n        train.append(['train/{}/{}'.format(category, imagefile), category, category_id])\n\ntrain = pd.DataFrame(train, columns=['filepath', 'category', 'category_id'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape)\nprint(train.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**As images of each category are grouped together in 'train' dataframe, it will be better for learning if we jumble the dataframe** "},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.sample(frac=1).reset_index(drop=True) #Here frac=1 gives the entire dataframe jumbled up","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets check the present state of the dataframe train"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preparing test set"},{"metadata":{},"cell_type":"markdown","source":"**Simmilar to the way we prepared 'train', we eill prepare test**"},{"metadata":{"trusted":true},"cell_type":"code","source":"test = []\nfor imagefile in os.listdir(test_dir):\n    test.append(['test/{}'.format(imagefile), imagefile])\ntest = pd.DataFrame(test, columns=['filepath', 'file'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Defining a method to load images in each of the category directory to numpy array as an array**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_image(filepath, size):\n    img = image.load_img(os.path.join(base_dir, filepath), target_size=size)\n    img = image.img_to_array(img)\n    return img\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_size = 100\n#Taking X_train as numpy array and each element of the array is an array image\nX_train = np.zeros((train.shape[0], image_size, image_size, 3), dtype='float32')\n#Taking y_train to store the labels\ny_train = np.zeros((train.shape[0], 1), dtype='float32')\n\nfor i, imagepath in tqdm(enumerate(train['filepath'])):\n    #Reading the image\n    img = read_image(imagepath, (image_size, image_size))\n    #storing it \n    X_train[i] = img\n    #storing the labels\n    y_train[i] = train['category_id'][i]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here I've taken images of size 100x100, For bigger size we will need pretrained model. "},{"metadata":{},"cell_type":"markdown","source":"Checking the shape of training set for assurance"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Lets visualize few images**"},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"#Here we are seeing 1st/0th image of X_train  \nplt.imshow(X_train[0][:,:,1])\nprint(y_train[0])","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false},"cell_type":"markdown","source":"From cell 8-9 we can see that the 1st seedling is of category '1' and 2nd seedling is of category '5'"},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"\nplt.imshow(X_train[1][:,:,1])\nprint(y_train[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**And here we can confirm it too**"},{"metadata":{},"cell_type":"markdown","source":"Everything is going well till now"},{"metadata":{},"cell_type":"markdown","source":"**Prepare X_test similar to X_train**"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = np.zeros((test.shape[0], image_size, image_size, 3), dtype='float32')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, imagefile in tqdm(enumerate(test['filepath'])):\n    img = read_image(imagefile, (image_size, image_size))\n    X_test[i] = img","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"X_test is numpy array containing test images"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"plt.imshow(X_test[0][:,:,0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**One Hot Encoding**"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = to_categorical(y_train, num_classes=12)\nprint(y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_train[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**From above cell we can confirm that**"},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_train / 255.0\nX_test = X_test / 255.0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train and validation split"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(y_train.shape)\nprint('<===============================================================>')\nprint(X_val.shape)\nprint(y_val.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(filters=64, kernel_size=(5,5), padding='Same', activation='relu', input_shape=(image_size, image_size, 3)))\nmodel.add(Conv2D(filters=64, kernel_size=(5,5), padding='Same', activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(filters=128, kernel_size=(5,5), padding='Same', activation='relu'))\nmodel.add(Conv2D(filters=128, kernel_size=(5,5), padding='Same', activation='relu'))\nmodel.add(Conv2D(filters=128, kernel_size=(5,5), padding='Same', activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(filters=256, kernel_size=(3,3), padding='Same', activation='relu'))\nmodel.add(Conv2D(filters=256, kernel_size=(3,3), padding='Same', activation='relu'))\nmodel.add(Conv2D(filters=256, kernel_size=(3,3), padding='Same', activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding='Same', activation='relu'))\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding='Same', activation='relu'))\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding='Same', activation='relu'))\n\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Dropout(0.2))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(512, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(12, activation='softmax'))\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Defining optimizer"},{"metadata":{},"cell_type":"markdown","source":"**Here I am using Adam optimizer with default parameters**"},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Compiling the model"},{"metadata":{},"cell_type":"markdown","source":"**The problem is of type multiclass classification, that's why loss is categorical cross entropy, and I'm setting accuracy as metrics**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Augmenting data"},{"metadata":{"trusted":true},"cell_type":"code","source":"image_gen = ImageDataGenerator(rotation_range = 180, zoom_range = 0.1, width_shift_range = 0.1, height_shift_range = 0.1,\n                              horizontal_flip = True, vertical_flip = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fitting augmentation to X_train"},{"metadata":{"trusted":true},"cell_type":"code","source":"image_gen.fit(X_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Reducing learning rate"},{"metadata":{"trusted":true},"cell_type":"code","source":"learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=5, factor=0.5, verbose=1, min_lr=0.00001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 70\nbatch_size = 100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fitting the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit_generator(image_gen.flow(X_train, y_train, batch_size=batch_size),\n                                            epochs=epochs, verbose=2, callbacks=[learning_rate_reduction], validation_data=(X_val, y_val), \n                                            steps_per_epoch = X_train.shape[0] // batch_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Model returns a history that containg training accuracy, training loss, validation accuracy and validation loss**"},{"metadata":{},"cell_type":"markdown","source":"Lets visualize Training accuracy vs crossvalidation accuracy and Training loss and crossvalidation loss"},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = history.history['acc']\nloss = history.history['loss']\n\nval_accuracy = history.history['val_acc']\nval_loss = history.history['val_loss']\n\nepoch = range(len(accuracy))\n\nplt.plot(epoch, accuracy, color='red', label='Training accuracy')\nplt.plot(epoch, val_accuracy, label='Crossvalidation accuracy')\nplt.title('Trainin accuracy vs Crossvalidation accuracy')\nplt.legend()\n\nplt.figure()\nplt.plot(epoch, loss, color='red', label='Training loss')\nplt.plot(epoch, val_loss, label='Crossvalidation loss')\nplt.title('Trainin loss vs Crossvalidation loss')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Really bumpy ride for cross validation dataset**"},{"metadata":{},"cell_type":"markdown","source":"## Making prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"result = model.predict(X_test)\n\nresult = np.argmax(result, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(result)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"test['species'] = [categories[i] for i in result] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[['file', 'species']].to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}