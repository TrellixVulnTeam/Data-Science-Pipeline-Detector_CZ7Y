{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input/train/\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nprint(os.listdir('../input/train'))\nencoder = LabelEncoder()\nencoder.fit(os.listdir('../input/train'))\nprint(encoder.transform(os.listdir('../input/train')))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from PIL import Image\nimport torch\nimport torch.nn as nn\nimport torchvision.models as models\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torchvision import transforms\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nTRAIN = '../input/train'\nTEST = '../input/test'\n\nimage = Image.open(TRAIN + '/' + 'Fat Hen' + '/0a1480ed8.png')\nimage = np.array(image)\nprint(image.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_manifest():\n    log = []\n    for label, plant in tqdm(zip(encoder.transform(os.listdir(TRAIN)), os.listdir(TRAIN))):\n        plant_dir = os.path.join(TRAIN, plant)\n        for img in os.listdir(plant_dir):\n            img_path = os.path.join(plant_dir, img)\n            log.append((label, plant, img_path))\n    return log\n\nlog = create_manifest()\ntrain_transform = transforms.Compose([transforms.Resize((144,144)), \n                                      transforms.RandomHorizontalFlip(0.5), \n                                      transforms.RandomVerticalFlip(0.5), \n                                      transforms.RandomRotation(90),\n                                      transforms.ToTensor(), \n                                      transforms.Normalize((0.5,),(0.5,))])\n\ntransform = transforms.Compose([transforms.Resize((144,144)),\n                                transforms.ToTensor(),\n                                transforms.Normalize((0.5,),(0.5,))])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain, val = train_test_split(log, test_size = 0.1, random_state = 29)\n\nclass Trainset(Dataset):\n    def __init__(self, transform = train_transform):\n        self.log = train\n    \n    def __len__(self):\n        return len(self.log) * 4\n    \n    def __getitem__(self, idx):\n        idx = idx % len(self.log)\n        label, _, img_path = self.log[idx]\n        img = Image.open(img_path).convert(\"RGB\")\n        if transforms:\n            img = transform(img)\n        return img, label\n        \nclass Validset(Dataset):\n    def __init__(self, transform = transform):\n        self.log = val\n    \n    def __len__(self):\n        return len(self.log)\n    \n    def __getitem__(self, idx):\n        label, _, img_path = self.log[idx]\n        img = Image.open(img_path).convert(\"RGB\")\n        if transforms:\n            img = transform(img)\n        return img, label    \n\nclass Testset(Dataset):\n    def __init__(self, transform = transform):\n        self.test = os.listdir(TEST)\n    \n    def __len__(self):\n        return len(self.test)\n    \n    def __getitem__(self, idx):\n        img = Image.open(os.path.join(TEST, self.test[idx])).convert(\"RGB\")\n        if transform:\n            img = transform(img)\n        return img\n    \ntrainset = Trainset(train_transform)\ntrainset[0][0].dtype\nvalset = Validset(transform)\nprint(valset[0][0].shape)\ntestset = Testset(transform)\ntestset[0].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device('cuda')\n!pip install torchsummary\nfrom torchsummary import summary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\npattern = re.compile('layer4.*')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = nn.Linear(512,10)\noptimizer = torch.optim.SGD(a.parameters(), lr = 0.001)\ntype(optimizer.param_groups[0]['params'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(model, trainloader, optimizer, loss_fn, epoch):\n    sum_loss = 0\n    correct = 0\n    total = 0\n    model.train()\n    #progress_bar = tqdm(enumerate(trainloader))\n    for idx, (feature, label) in enumerate(trainloader):\n        feature = feature.to(device)\n        label = label.to(device)\n        \n        optimizer.zero_grad()\n        out = model(feature)\n        _, pred = torch.max(out, dim = 1)\n        correct += (label == pred).sum().item()\n        total += len(feature)\n        loss = loss_fn(out, label)\n        sum_loss += loss.item()\n        loss.backward()\n        optimizer.step()\n        \n        print('\\rTrain {:3d} [{:2d}/{:2d} ({:.4%})] Loss: {:.4f} Acc: {:.4%}'.format(epoch, idx + 1, \n                                                                                     len(trainloader), \n                                                                                     (idx + 1) / len(trainloader), \n                                                                                     sum_loss / (idx + 1),\n                                                                                     correct / total), end = '')\n    \ndef val(model, valloader, loss_fn, epoch):\n    correct = 0\n    total = 0\n    sum_loss = 0\n    model.eval()\n    with torch.no_grad():\n        for idx, (feature, label) in enumerate(valloader):\n            feature = feature.to(device)\n            label = label.to(device)\n\n            out = model(feature)\n            _, pred = torch.max(out, dim = 1)\n            correct += (label == pred).sum().item()\n            total += len(feature)\n            loss = loss_fn(out, label)\n            sum_loss += loss.item()\n        print('Val {:3d} Loss: {:.4f} Acc: {:.4%}'.format(epoch, sum_loss / len(valloader), correct / total))\n    return correct / total\n\ndef test(model, testloader):\n    results = []\n    model.eval()\n    with torch.no_grad():\n        for feature in testloader:\n            feature = feature.to(device)\n            out = model(feature)\n            _, pred = torch.max(out, dim = 1)\n            results.extend(pred.cpu().detach().numpy().tolist())\n    return results\n        \nclass Net(nn.Module):\n    def __init__(self, num_classes):\n        super(Net, self).__init__()\n        self.model = models.resnet34(pretrained = True)\n        for name, parameter in self.model.named_parameters():\n            if not (re.match(pattern, name) or name == 'fc'):\n                parameter.requires_grad = False\n        self.model.fc = nn.Linear(512, 512)\n        self.fc_bn = nn.BatchNorm1d(512)\n        self.dropout = nn.Dropout(0.3)\n        self.classifier = nn.Linear(512, 12)\n    \n    def forward(self, x):\n        x = self.model.conv1(x)\n        x = self.model.bn1(x)\n        x = self.model.relu(x)\n        x = self.model.maxpool(x)\n        x = self.model.layer1(x)\n        x = self.model.layer2(x)\n        x = self.model.layer3(x)\n        x = self.model.layer4(x)\n        x = self.model.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.model.fc(x)\n        x = self.fc_bn(x)\n        x = self.dropout(x)\n        x = F.relu(x)\n        x = self.classifier(x)\n        return x\n        \ndef main():\n    #model = models.resnet.ResNet(models.resnet.BasicBlock, [1,1,1,1])\n    #model = models.resnet18(pretrained=True)\n    model = Net(12)\n    model.to(device)\n    summary(model, (3,144,144))\n    \n    trainloader = DataLoader(trainset, batch_size = 128, shuffle = True, num_workers = 4)\n    valloader = DataLoader(valset, batch_size = 64, shuffle = False, num_workers = 4)\n    testloader = DataLoader(testset, batch_size = 64, shuffle = False, num_workers = 4)\n    \n    loss_fn = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr = 0.01, betas = (0.9,0.999), weight_decay = 0.00001)\n    print(len(optimizer.param_groups[0]['params']))\n    #optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr = 0.01, momentum = 0.9, weight_decay = 0.00001)\n    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.3, last_epoch = -1)\n    \n    import copy\n    \n    best_acc = 0\n    model_duplicated = None\n    for epoch in range(50):\n        results = test(model, testloader)\n        train(model, trainloader, optimizer, loss_fn, epoch + 1)\n        val_acc = val(model, valloader, loss_fn, epoch + 1)\n        if val_acc >= best_acc:\n            print('save model')\n            best_acc = val_acc\n            model_duplicated = copy.deepcopy(model)\n    model = model_duplicated\n    results = test(model, testloader)\n    return model, results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model, results = main()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = encoder.inverse_transform(results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imgs = np.array(testset.test)\nsubmission = pd.DataFrame({'file':testset.test, 'species':predictions})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv', index = None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!less submission.csv","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}