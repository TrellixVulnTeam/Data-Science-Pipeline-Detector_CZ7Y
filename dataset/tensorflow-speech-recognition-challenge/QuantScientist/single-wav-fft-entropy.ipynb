{"metadata":{"language_info":{"pygments_lexer":"ipython3","file_extension":".py","mimetype":"text/x-python","version":"3.6.3","nbconvert_exporter":"python","name":"python","codemirror_mode":{"version":3,"name":"ipython"}},"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"}},"nbformat":4,"nbformat_minor":1,"cells":[{"cell_type":"markdown","source":"# Single WAV + FFT + Entropy : TensorFlow Speech Recognition Challenge\n\n- Reading data is from this Kernel: https://www.kaggle.com/jamesrequa/convert-wav-to-spectogram (all credits to the respective writer) \n","metadata":{"_cell_guid":"0f6270bd-86eb-4fb4-a51d-c333030b1267","_uuid":"a2a634cac985e965d92d987aba035b7aa8d2fcc5"}},{"cell_type":"code","execution_count":null,"source":"%reset -f\n__author__ = 'Solomonk: https://www.kaggle.com/solomonk/'\n\nimport scipy.io\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport numpy\nimport pandas as pd\nfrom sklearn.metrics import roc_auc_score, mean_squared_error, roc_curve\n\nimport numpy\nimport pandas\nfrom itertools import combinations\n\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.linear_model import LogisticRegression, Ridge\nfrom sklearn.datasets import dump_svmlight_file\nimport numpy as np, h5py \n\nimport os\nfrom pathlib import Path\nimport IPython.display as ipd\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom scipy import signal\nfrom scipy.io import wavfile\n%matplotlib inline\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))","outputs":[],"metadata":{"_cell_guid":"93e1a992-9e00-43a9-ad90-88d9f58f011c","_uuid":"46a550f6614d4f36b3e217220195037044f94c79"}},{"cell_type":"code","execution_count":null,"source":"# print(check_output([\"ls\", \"../input/train\"]).decode(\"utf8\"))\nfolders = os.listdir(\"../input/train/audio\")","outputs":[],"metadata":{"_cell_guid":"08c47377-b5ae-4449-9925-17e172b68103","_uuid":"33ddba4d8969d3f1a3738aac9b19fda7679cdba5","collapsed":true}},{"cell_type":"code","execution_count":null,"source":"train_audio_path = '../input/train/audio'\n\ntrain_labels = os.listdir(train_audio_path)\ntrain_labels.remove('_background_noise_')\nprint(f'Number of labels: {len(train_labels)}')\n\nlabels_to_keep = ['yes', 'no', 'up', 'down', 'left',\n                  'right', 'on', 'off', 'stop', 'go', 'silence']\n\ntrain_file_labels = dict()\nfor label in train_labels:\n    files = os.listdir(train_audio_path + '/' + label)\n    for f in files:\n        train_file_labels[label + '/' + f] = label\n\ntrain = pd.DataFrame.from_dict(train_file_labels, orient='index')\ntrain = train.reset_index(drop=False)\ntrain = train.rename(columns={'index': 'file', 0: 'folder'})\ntrain = train[['folder', 'file']]\ntrain = train.sort_values('file')\ntrain = train.reset_index(drop=True)\nprint(train.shape)\n\ndef remove_label_from_file(label, fname):\n    return fname[len(label)+1:]\n\ntrain['file'] = train.apply(lambda x: remove_label_from_file(*x), axis=1)\ntrain['label'] = train['folder'].apply(lambda x: x if x in labels_to_keep else 'unknown')","outputs":[],"metadata":{"_cell_guid":"b11f1eba-20e6-452b-a7a2-a126e6d2b792","_uuid":"ed2837d2cb4706932d1a9d0f47b7acc2b3830c83"}},{"cell_type":"code","execution_count":null,"source":"from PIL import Image\nimport numpy as np\n\n#---------------------------------------------------------------#\ndef entropy(signal):\n    '''\n    function returns entropy of a signal\n    signal must be a 1-D numpy array\n    '''\n    lensig=signal.size\n    symset=list(set(signal))\n    numsym=len(symset)\n    propab=[np.size(signal[signal==i])/(1.0*lensig) for i in symset]\n    ent=np.sum([p*np.log2(1.0/p) for p in propab])\n    return ent\n#---------------------------------------------------------------#    ","outputs":[],"metadata":{"_cell_guid":"d0af6bef-20d6-4069-b98a-985ed3b1d072","_uuid":"c0bb6eb1d52dadcbb0ac5ac020d1f88eea538be5","collapsed":true}},{"cell_type":"markdown","source":"# Plot Signal","metadata":{"_cell_guid":"ee17484f-c32b-4976-ae66-fc5d56addf67","_uuid":"05f8bd447c01c9742cab63ba2cbc8e44d57ae272"}},{"cell_type":"code","execution_count":null,"source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport wave\nimport sys\n\nspf = wave.open(str(train_audio_path) + '/house/61e50f62_nohash_1.wav','r')\n\n#Extract Raw Audio from Wav File\nsignal = spf.readframes(-1)\nsignal = np.fromstring(signal, 'Int16')\n\nplt.figure(1)\nplt.title('Signal Wave...')\nplt.plot(signal)\nplt.show()","outputs":[],"metadata":{"_cell_guid":"b41583fb-6856-415b-b724-d22d3198fda7","_uuid":"b8c5c26c4a827b85139b7d3bcbe062c322f62aa0"}},{"cell_type":"markdown","source":"# Plot FFT","metadata":{"_cell_guid":"6c1377b7-d302-4fb3-8d91-4e2c840686aa","_uuid":"c309e7397448e994a08e4ddc925162797caf9893"}},{"cell_type":"code","execution_count":null,"source":"import numpy as np\nimport scipy.io.wavfile\nimport scipy.fftpack\n\nt = scipy.linspace(0,120,4000)\nx = scipy.io.wavfile.read(str(train_audio_path) + '/house/61e50f62_nohash_1.wav')[1]\nFFT = abs(scipy.fft(x))\nfreqs = scipy.fftpack.fftfreq(signal.size, t[1]-t[0])\nprint (np.array(freqs))\n\n%matplotlib inline\nplt.figure(1)\nplt.title('Signal FFT...')\nplt.plot(FFT)\nplt.show()","outputs":[],"metadata":{"_cell_guid":"16c047f8-d86d-4c79-8638-13bd088c5b0b","_uuid":"eebc40b3bc0ac69a7dca91db591eb3450f6688d2"}},{"cell_type":"markdown","source":"# Entropy","metadata":{"_cell_guid":"02f91708-9cff-49b7-a92f-01338bf3a3b7","_uuid":"f009ba66c06c1072367482332049057ac4eabee1"}},{"cell_type":"code","execution_count":null,"source":"x_ent=x.ravel()\nentropy(x_ent)","outputs":[],"metadata":{"_cell_guid":"0ea1b360-096f-4712-a280-7e155590824b","_uuid":"60d34567b0608112eb722cc012cb0eb566afb5bc"}},{"cell_type":"code","execution_count":null,"source":"def nextpow2(i):\n    n = 1\n    while n < i:\n        n *= 2\n    return n\n    \ndef featurePSD(eegdata, Fs):\n    # 1. Compute the PSD\n    winSampleLength, nbCh = len(eegdata), 1\n\n    # Apply Hamming window\n    w = np.hamming(winSampleLength)\n    dataWinCentered = eegdata - np.mean(eegdata, axis=0) # Remove offset\n    dataWinCenteredHam = (dataWinCentered.T*w).T\n\n    NFFT = nextpow2(winSampleLength)\n    Y = np.fft.fft(dataWinCenteredHam, n=NFFT, axis=0)/winSampleLength\n    PSD = 2*np.abs(Y[0:NFFT/2,:])\n    f = Fs/2*np.linspace(0,1,NFFT/2)\n\n    # SPECTRAL FEATURES\n    # Average of band powers\n    # Delta <4\n    ind_delta, = np.where(f<4)\n    meanDelta = np.mean(PSD[ind_delta,:],axis=0)\n    # Theta 4-8\n    ind_theta, = np.where((f>=4) & (f<=8))\n    meanTheta = np.mean(PSD[ind_theta,:],axis=0)\n    # Alpha 8-12\n    ind_alpha, = np.where((f>=8) & (f<=12))\n    meanAlpha = np.mean(PSD[ind_alpha,:],axis=0)\n    # Beta 12-30\n    ind_beta, = np.where((f>=12) & (f<30))\n    meanBeta = np.mean(PSD[ind_beta,:],axis=0)\n    feature_vector = np.concatenate((meanDelta, meanTheta, meanAlpha, meanBeta),axis=0)\n    feature_vector = np.log10(feature_vector)\n    return feature_vector","outputs":[],"metadata":{"_cell_guid":"278e4613-da8d-48d0-9152-29c206f6e07a","_uuid":"32cfeed14edeb6cee26fa9b1315413983b1c3717","collapsed":true}},{"cell_type":"code","execution_count":null,"source":"x = scipy.io.wavfile.read(str(train_audio_path) + '/house/61e50f62_nohash_1.wav')\npsd=featurePSD (x[1], 16000)\n","outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":"","outputs":[],"metadata":{"collapsed":true}}]}