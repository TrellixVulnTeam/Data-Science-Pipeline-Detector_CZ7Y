{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n\nimport pathlib\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nimport tensorflow as tf\n!pip install py7zr\nimport py7zr\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import models\nfrom IPython import display\n\n# for random forest\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Set the seed value for experiment reproducibility.\nseed = 42\ntf.random.set_seed(seed)\nnp.random.seed(seed)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-08T17:53:55.186913Z","iopub.execute_input":"2022-06-08T17:53:55.187273Z","iopub.status.idle":"2022-06-08T17:54:30.956408Z","shell.execute_reply.started":"2022-06-08T17:53:55.187184Z","shell.execute_reply":"2022-06-08T17:54:30.955165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2022-06-08T17:54:30.958491Z","iopub.execute_input":"2022-06-08T17:54:30.959122Z","iopub.status.idle":"2022-06-08T17:54:30.966575Z","shell.execute_reply.started":"2022-06-08T17:54:30.959076Z","shell.execute_reply":"2022-06-08T17:54:30.965897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"archive = py7zr.SevenZipFile('/kaggle/input/tensorflow-speech-recognition-challenge/train.7z', mode='r')\narchive.extractall(path=\"/train\")\narchive.close()","metadata":{"execution":{"iopub.status.busy":"2022-06-06T21:19:27.022561Z","iopub.execute_input":"2022-06-06T21:19:27.0228Z","iopub.status.idle":"2022-06-06T21:28:34.431826Z","shell.execute_reply.started":"2022-06-06T21:19:27.022764Z","shell.execute_reply":"2022-06-06T21:28:34.431071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = pathlib.Path(\"/train/train/audio\")\ncommands = np.array(tf.io.gfile.listdir(str(data_dir)))\ncommands = commands[commands != 'README.md']\nprint('Commands:', commands)","metadata":{"execution":{"iopub.status.busy":"2022-06-06T21:28:34.433117Z","iopub.execute_input":"2022-06-06T21:28:34.433386Z","iopub.status.idle":"2022-06-06T21:28:34.472179Z","shell.execute_reply.started":"2022-06-06T21:28:34.433353Z","shell.execute_reply":"2022-06-06T21:28:34.471379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filenames = tf.io.gfile.glob(str(data_dir) + '/*/*')\nfilenames = tf.random.shuffle(filenames)\nnum_samples = len(filenames)\nprint('Number of total examples:', num_samples)\nprint('Number of examples per label:',\n      len(tf.io.gfile.listdir(str(data_dir/commands[0]))))\nprint('Example file tensor:', filenames[0])","metadata":{"execution":{"iopub.status.busy":"2022-06-06T21:28:34.475268Z","iopub.execute_input":"2022-06-06T21:28:34.477175Z","iopub.status.idle":"2022-06-06T21:28:38.006227Z","shell.execute_reply.started":"2022-06-06T21:28:34.477026Z","shell.execute_reply":"2022-06-06T21:28:38.005548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(type(filenames))\nf2=tf.concat(\n    [filenames[:8000],filenames[10000:30000]], 0, name='concat'\n)\nprint(f2.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-06T21:28:38.007731Z","iopub.execute_input":"2022-06-06T21:28:38.00821Z","iopub.status.idle":"2022-06-06T21:28:38.026431Z","shell.execute_reply.started":"2022-06-06T21:28:38.008169Z","shell.execute_reply":"2022-06-06T21:28:38.025018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#somewhere between 15000 and 25000 there is invalid file which messes up this whole code\ntrain_files = f2\nval_files = filenames[50001: 50000 + 7000]\ntest_files = filenames[57001:]\n\nprint('Training set size', len(train_files))\nprint('Validation set size', len(val_files))\nprint('Test set size', len(test_files))","metadata":{"execution":{"iopub.status.busy":"2022-06-06T21:28:38.027538Z","iopub.execute_input":"2022-06-06T21:28:38.02786Z","iopub.status.idle":"2022-06-06T21:28:38.449673Z","shell.execute_reply.started":"2022-06-06T21:28:38.027824Z","shell.execute_reply":"2022-06-06T21:28:38.448586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#data is of shape [16000,1] so i change it to a onedimenstional tensor\ndef decode_audio(audio_binary):\n  # Decode WAV-encoded audio files to `float32` tensors, normalized\n  # to the [-1.0, 1.0] range. Return `float32` audio and a sample rate.\n  audio, _ = tf.audio.decode_wav(contents=audio_binary)\n  # Since all the data is single channel (mono), drop the `channels`\n  # axis from the array.\n  return tf.squeeze(audio, axis=-1)\ndef get_label(file_path):\n  parts = tf.strings.split(\n      input=file_path,\n      sep=os.path.sep)\n  # Note: You'll use indexing here instead of tuple unpacking to enable this\n  # to work in a TensorFlow graph.\n  return parts[-2]\ndef get_waveform_and_label(file_path):\n  label = get_label(file_path)\n  audio_binary = tf.io.read_file(file_path)\n  waveform = decode_audio(audio_binary)\n  return waveform, label","metadata":{"execution":{"iopub.status.busy":"2022-06-06T21:28:38.451138Z","iopub.execute_input":"2022-06-06T21:28:38.451479Z","iopub.status.idle":"2022-06-06T21:28:38.458613Z","shell.execute_reply.started":"2022-06-06T21:28:38.451442Z","shell.execute_reply":"2022-06-06T21:28:38.457677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AUTOTUNE = tf.data.AUTOTUNE\n\nfiles_ds = tf.data.Dataset.from_tensor_slices(train_files)\n\nwaveform_ds = files_ds.map(\n    map_func=get_waveform_and_label,\n    num_parallel_calls=AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2022-06-06T21:28:38.460113Z","iopub.execute_input":"2022-06-06T21:28:38.460938Z","iopub.status.idle":"2022-06-06T21:28:38.646787Z","shell.execute_reply.started":"2022-06-06T21:28:38.460906Z","shell.execute_reply":"2022-06-06T21:28:38.64601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rows = 3\ncols = 3\nn = rows * cols\nfig, axes = plt.subplots(rows, cols, figsize=(10, 12))\n\nfor i, (audio, label) in enumerate(waveform_ds.take(n)):\n  r = i // cols\n  c = i % cols\n  ax = axes[r][c]\n  ax.plot(audio.numpy())\n  ax.set_yticks(np.arange(-1.2, 1.2, 0.2))\n  label = label.numpy().decode('utf-8')\n  ax.set_title(label)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-06T21:28:38.648716Z","iopub.execute_input":"2022-06-06T21:28:38.648939Z","iopub.status.idle":"2022-06-06T21:28:39.666779Z","shell.execute_reply.started":"2022-06-06T21:28:38.648913Z","shell.execute_reply":"2022-06-06T21:28:39.666123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_spectrogram(waveform):\n  # Zero-padding for an audio waveform with less than 16,000 samples.\n  input_len = 16000\n  waveform = waveform[:input_len]\n  zero_padding = tf.zeros(\n      [16000] - tf.shape(waveform),\n      dtype=tf.float32)\n  # Cast the waveform tensors' dtype to float32.\n  waveform = tf.cast(waveform, dtype=tf.float32)\n  # Concatenate the waveform with `zero_padding`, which ensures all audio\n  # clips are of the same length.\n  equal_length = tf.concat([waveform, zero_padding], 0)\n  # Convert the waveform to a spectrogram via a short-time fourier transform.\n  spectrogram = tf.signal.stft(\n      equal_length, frame_length=255, frame_step=128)#play around with it TODO::\n#rozne rozmiary/typy okien (humminga, hunning [van hann])\n  # Obtain the magnitude of the short-time fourier transform.\n  spectrogram = tf.abs(spectrogram)\n  # Add a `channels` dimension, so that the spectrogram can be used\n  # as image-like input data with convolution layers (which expect\n  # shape (`batch_size`, `height`, `width`, `channels`).\n  spectrogram = spectrogram[..., tf.newaxis]\n  return spectrogram","metadata":{"execution":{"iopub.status.busy":"2022-06-06T21:28:39.670141Z","iopub.execute_input":"2022-06-06T21:28:39.670391Z","iopub.status.idle":"2022-06-06T21:28:39.677398Z","shell.execute_reply.started":"2022-06-06T21:28:39.670365Z","shell.execute_reply":"2022-06-06T21:28:39.675909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for waveform, label in waveform_ds.take(1):\n  label = label.numpy().decode('utf-8')\n  spectrogram = get_spectrogram(waveform)\n\nprint('Label:', label)\nprint('Waveform shape:', waveform.shape)\nprint('Spectrogram shape:', spectrogram.shape)\nprint('Audio playback')\ndisplay.display(display.Audio(waveform, rate=16000))","metadata":{"execution":{"iopub.status.busy":"2022-06-06T21:28:39.679103Z","iopub.execute_input":"2022-06-06T21:28:39.679383Z","iopub.status.idle":"2022-06-06T21:28:40.189262Z","shell.execute_reply.started":"2022-06-06T21:28:39.679349Z","shell.execute_reply":"2022-06-06T21:28:40.188554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_spectrogram(spectrogram, ax):\n  if len(spectrogram.shape) > 2:\n    assert len(spectrogram.shape) == 3\n    spectrogram = np.squeeze(spectrogram, axis=-1)\n  # Convert the frequencies to log scale and transpose, so that the time is\n  # represented on the x-axis (columns).\n  # Add an epsilon to avoid taking a log of zero.\n  log_spec = np.log(spectrogram.T + np.finfo(float).eps)\n  height = log_spec.shape[0]\n  width = log_spec.shape[1]\n  X = np.linspace(0, np.size(spectrogram), num=width, dtype=int)\n  Y = range(height)\n  ax.pcolormesh(X, Y, log_spec)\n\n\nfig, axes = plt.subplots(2, figsize=(12, 8))\ntimescale = np.arange(waveform.shape[0])\naxes[0].plot(timescale, waveform.numpy())\naxes[0].set_title('Waveform')\naxes[0].set_xlim([0, 16000])\n\nplot_spectrogram(spectrogram.numpy(), axes[1])\naxes[1].set_title('Spectrogram')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-06T21:28:40.190694Z","iopub.execute_input":"2022-06-06T21:28:40.191167Z","iopub.status.idle":"2022-06-06T21:28:40.513607Z","shell.execute_reply.started":"2022-06-06T21:28:40.191128Z","shell.execute_reply":"2022-06-06T21:28:40.512913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_spectrogram_and_label_id(audio, label):\n  spectrogram = get_spectrogram(audio)\n  type(spectrogram)\n  label_id = tf.argmax(label == commands)\n  return spectrogram, label_id","metadata":{"execution":{"iopub.status.busy":"2022-06-06T21:28:40.514622Z","iopub.execute_input":"2022-06-06T21:28:40.514834Z","iopub.status.idle":"2022-06-06T21:28:40.519622Z","shell.execute_reply.started":"2022-06-06T21:28:40.514805Z","shell.execute_reply":"2022-06-06T21:28:40.518953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spectrogram_ds = waveform_ds.map(\n  map_func=get_spectrogram_and_label_id,\n  num_parallel_calls=AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2022-06-06T21:28:40.521108Z","iopub.execute_input":"2022-06-06T21:28:40.521626Z","iopub.status.idle":"2022-06-06T21:28:40.705319Z","shell.execute_reply.started":"2022-06-06T21:28:40.521587Z","shell.execute_reply":"2022-06-06T21:28:40.704615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rows = 3\ncols = 3\nn = rows*cols\nfig, axes = plt.subplots(rows, cols, figsize=(10, 10))\n\nfor i, (spectrogram, label_id) in enumerate(spectrogram_ds.take(n)):\n  r = i // cols\n  c = i % cols\n  ax = axes[r][c]\n  plot_spectrogram(spectrogram.numpy(), ax)\n  ax.set_title(commands[label_id.numpy()])\n  ax.axis('off')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-06T21:28:40.706502Z","iopub.execute_input":"2022-06-06T21:28:40.706726Z","iopub.status.idle":"2022-06-06T21:28:41.565971Z","shell.execute_reply.started":"2022-06-06T21:28:40.706693Z","shell.execute_reply":"2022-06-06T21:28:41.564922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_dataset(files):\n  files_ds = tf.data.Dataset.from_tensor_slices(files)\n  output_ds = files_ds.map(\n      map_func=get_waveform_and_label,\n      num_parallel_calls=AUTOTUNE)\n  output_ds = output_ds.map(\n      map_func=get_spectrogram_and_label_id,\n      num_parallel_calls=AUTOTUNE)\n  return output_ds","metadata":{"execution":{"iopub.status.busy":"2022-06-06T21:28:41.569834Z","iopub.execute_input":"2022-06-06T21:28:41.570238Z","iopub.status.idle":"2022-06-06T21:28:41.585724Z","shell.execute_reply.started":"2022-06-06T21:28:41.570202Z","shell.execute_reply":"2022-06-06T21:28:41.585122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = spectrogram_ds\nval_ds = preprocess_dataset(val_files)\ntest_ds = preprocess_dataset(test_files)","metadata":{"execution":{"iopub.status.busy":"2022-06-06T21:28:41.586928Z","iopub.execute_input":"2022-06-06T21:28:41.587723Z","iopub.status.idle":"2022-06-06T21:28:42.021639Z","shell.execute_reply.started":"2022-06-06T21:28:41.587685Z","shell.execute_reply":"2022-06-06T21:28:42.020423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 64\ntrain_ds = train_ds.batch(batch_size)\nval_ds = val_ds.batch(batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-06-06T21:28:42.023214Z","iopub.execute_input":"2022-06-06T21:28:42.023658Z","iopub.status.idle":"2022-06-06T21:28:42.032592Z","shell.execute_reply.started":"2022-06-06T21:28:42.023621Z","shell.execute_reply":"2022-06-06T21:28:42.032003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = train_ds.cache().prefetch(AUTOTUNE)\nval_ds = val_ds.cache().prefetch(AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2022-06-06T21:28:42.040216Z","iopub.execute_input":"2022-06-06T21:28:42.040707Z","iopub.status.idle":"2022-06-06T21:28:42.125357Z","shell.execute_reply.started":"2022-06-06T21:28:42.040673Z","shell.execute_reply":"2022-06-06T21:28:42.124763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for spectrogram, _ in spectrogram_ds.take(1):\n  input_shape = spectrogram.shape\n  type(spectrogram)\n\nprint('Input shape:', input_shape)\nnum_labels = len(commands)\n\n# Instantiate the `tf.keras.layers.Normalization` layer.\nnorm_layer = layers.Normalization()\n# Fit the state of the layer to the spectrograms\n# with `Normalization.adapt`.\ndata=spectrogram_ds.map(map_func=lambda x, label:x)\ntry:\n    norm_layer.adapt(data)\n    \nexcept:\n    print(\"Oops!  Invalid header again1\")\n\n        \n\n# model = tf.keras.Sequential([\n#     layers.Input(shape=input_shape),\n#     norm_layer,\n#     tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu'), \n#     tf.keras.layers.MaxPooling2D(2,2),\n#     tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu'),\n#     tf.keras.layers.MaxPooling2D(2,2),\n#     tf.keras.layers.Flatten(),\n#     tf.keras.layers.Dense(128, activation=tf.nn.relu),\n#     tf.keras.layers.Dropout(0.2),\n#     tf.keras.layers.Dense(6, activation=tf.nn.softmax)\n# ])\nmodel = models.Sequential([\n    layers.Input(shape=input_shape),\n    layers.GaussianNoise(0.1),\n    layers.Resizing(32, 32),\n    # Normalize.\n    norm_layer,\n    layers.Conv2D(16, (3,3), activation='relu'),\n    layers.Conv2D(16, (3,3), activation='relu'),\n#     layers.MaxPooling2D(),\n    layers.Conv2D(32, (3,3), activation='relu'),\n#     layers.Conv2D(32, (3,3), activation='relu'),\n    layers.Dropout(0.25),\n    layers.MaxPooling2D(),\n    layers.Conv2D(64, (3,3), activation='relu'),\n#     layers.Conv2D(64, (3,3), activation='relu'),\n\n    layers.Flatten(),\n    layers.Dense(1024, activation='relu'),\n    layers.Dropout(0.4),\n    layers.Dense(1024, activation='relu'),\n#     layers.MaxPooling2D(),\n#     layers.Dropout(0.25),\n#     layers.Flatten(),\n#     layers.Dense(1024, activation='relu'),\n    layers.Dropout(0.45),\n    layers.Dense(num_labels),\n])\n\n# model = models.Sequential([\n#     layers.Input(shape=input_shape),\n#     layers.Resizing(32, 32),\n#     # Normalize.\n#     norm_layer,\n#     layers.Conv2D(32, 3, activation='relu'),\n#     layers.Conv2D(64, 3, activation='relu'),\n#     layers.MaxPooling2D(),\n#     layers.Dropout(0.25),\n#     layers.Flatten(),\n#     layers.Dense(128, activation='relu'),\n#     layers.Dropout(0.5),\n#     layers.Dense(num_labels),\n# ])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-06-06T22:23:38.331129Z","iopub.execute_input":"2022-06-06T22:23:38.331411Z","iopub.status.idle":"2022-06-06T22:24:53.260957Z","shell.execute_reply.started":"2022-06-06T22:23:38.331381Z","shell.execute_reply":"2022-06-06T22:24:53.260219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(\n    optimizer=tf.keras.optimizers.Adam(),\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics=['accuracy'],\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-06T22:24:53.263961Z","iopub.execute_input":"2022-06-06T22:24:53.264152Z","iopub.status.idle":"2022-06-06T22:24:53.273088Z","shell.execute_reply.started":"2022-06-06T22:24:53.264129Z","shell.execute_reply":"2022-06-06T22:24:53.272423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 100\nhistory = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=EPOCHS,\n    callbacks=tf.keras.callbacks.EarlyStopping(verbose=1, patience=4),\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-06T22:24:53.274358Z","iopub.execute_input":"2022-06-06T22:24:53.274595Z","iopub.status.idle":"2022-06-06T22:25:59.955405Z","shell.execute_reply.started":"2022-06-06T22:24:53.274566Z","shell.execute_reply":"2022-06-06T22:25:59.954671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics = history.history\nplt.plot(history.epoch, metrics['loss'], metrics['val_loss'])\nplt.legend(['loss', 'val_loss'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-06T22:25:59.95796Z","iopub.execute_input":"2022-06-06T22:25:59.958672Z","iopub.status.idle":"2022-06-06T22:26:00.169605Z","shell.execute_reply.started":"2022-06-06T22:25:59.958641Z","shell.execute_reply":"2022-06-06T22:26:00.168887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_audio = []\ntest_labels = []\ni=0\nfor audio, label in test_ds:\n    i=i+1\n#     print(i)\n    if(i==1271):\n        break\n    try:\n        test_audio.append(audio.numpy())\n        test_labels.append(label.numpy())\n    except:\n        print(i)\n\ntest_audio = np.array(test_audio)\ntest_labels = np.array(test_labels)","metadata":{"execution":{"iopub.status.busy":"2022-06-06T22:26:00.170717Z","iopub.execute_input":"2022-06-06T22:26:00.171589Z","iopub.status.idle":"2022-06-06T22:26:02.8958Z","shell.execute_reply.started":"2022-06-06T22:26:00.171545Z","shell.execute_reply":"2022-06-06T22:26:02.895055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = np.argmax(model.predict(test_audio), axis=1)\ny_true = test_labels\n\ntest_acc = sum(y_pred == y_true) / len(y_true)\nprint(f'Test set accuracy: {test_acc:.0%}')","metadata":{"execution":{"iopub.status.busy":"2022-06-06T22:26:02.897244Z","iopub.execute_input":"2022-06-06T22:26:02.897543Z","iopub.status.idle":"2022-06-06T22:26:03.24179Z","shell.execute_reply.started":"2022-06-06T22:26:02.897508Z","shell.execute_reply":"2022-06-06T22:26:03.240951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_mtx = tf.math.confusion_matrix(y_true, y_pred)\nplt.figure(figsize=(10, 8))\nsns.heatmap(confusion_mtx,\n            xticklabels=commands,\n            yticklabels=commands,\n            annot=True, fmt='g')\nplt.xlabel('Prediction')\nplt.ylabel('Label')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-06T21:29:58.50049Z","iopub.status.idle":"2022-06-06T21:29:58.500968Z","shell.execute_reply.started":"2022-06-06T21:29:58.500707Z","shell.execute_reply":"2022-06-06T21:29:58.500732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for spectrogram, _ in spectrogram_ds.take(1):\n  input_shape = spectrogram.shape\n  type(spectrogram)\n\nprint('Input shape:', input_shape)\nnum_labels = len(commands)\n\n# Instantiate the `tf.keras.layers.Normalization` layer.\nnorm_layer = layers.Normalization()\n# Fit the state of the layer to the spectrograms\n# with `Normalization.adapt`.\ndata=spectrogram_ds.map(map_func=lambda x, label:x)\ntry:\n    norm_layer.adapt(data)\n    \nexcept:\n    print(\"Oops!  Invalid header again1\")\n\n        \n\nmodel2 = tf.keras.Sequential([\n    layers.Input(shape=input_shape),\n    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu'), \n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dense(6, activation=tf.nn.softmax)\n])\nmodel2.summary()","metadata":{"execution":{"iopub.status.busy":"2022-06-06T21:29:58.502846Z","iopub.status.idle":"2022-06-06T21:29:58.504357Z","shell.execute_reply.started":"2022-06-06T21:29:58.504067Z","shell.execute_reply":"2022-06-06T21:29:58.504094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-06-06T21:29:58.509975Z","iopub.status.idle":"2022-06-06T21:29:58.510464Z","shell.execute_reply.started":"2022-06-06T21:29:58.510219Z","shell.execute_reply":"2022-06-06T21:29:58.510243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model2.fit(train_ds, validation_data=val_ds, batch_size=128, epochs=20)\n\n\n# EPOCHS = 100\n# history = model2.fit(\n#     train_ds,\n#     validation_data=val_ds,\n#     epochs=EPOCHS,\n# )\n\nmetrics = history.history\nplt.plot(history.epoch, metrics['loss'], metrics['val_loss'])\nplt.legend(['loss', 'val_loss'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-06T21:29:58.511843Z","iopub.status.idle":"2022-06-06T21:29:58.512279Z","shell.execute_reply.started":"2022-06-06T21:29:58.512045Z","shell.execute_reply":"2022-06-06T21:29:58.512068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_audio = []\ntest_labels = []\ni=0\nfor audio, label in test_ds:\n    i=i+1\n#     print(i)\n    if(i==1271):\n        break\n    try:\n        test_audio.append(audio.numpy())\n        test_labels.append(label.numpy())\n    except:\n        print(i)\n\ntest_audio = np.array(test_audio)\ntest_labels = np.array(test_labels)\n\ny_pred = np.argmax(model2.predict(test_audio), axis=1)\ny_true = test_labels\n\ntest_acc = sum(y_pred == y_true) / len(y_true)\nprint(f'Test set accuracy: {test_acc:.0%}')","metadata":{"execution":{"iopub.status.busy":"2022-06-06T21:29:58.513568Z","iopub.status.idle":"2022-06-06T21:29:58.514083Z","shell.execute_reply.started":"2022-06-06T21:29:58.513848Z","shell.execute_reply":"2022-06-06T21:29:58.513872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_mtx = tf.math.confusion_matrix(y_true, y_pred)\nplt.figure(figsize=(10, 8))\nsns.heatmap(confusion_mtx,\n            xticklabels=commands,\n            yticklabels=commands,\n            annot=True, fmt='g')\nplt.xlabel('Prediction')\nplt.ylabel('Label')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-06T21:29:58.515995Z","iopub.status.idle":"2022-06-06T21:29:58.516559Z","shell.execute_reply.started":"2022-06-06T21:29:58.516238Z","shell.execute_reply":"2022-06-06T21:29:58.516276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#longer training\nEPOCHS = 70\nhistory = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=EPOCHS\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-06T21:29:58.51948Z","iopub.status.idle":"2022-06-06T21:29:58.520113Z","shell.execute_reply.started":"2022-06-06T21:29:58.519799Z","shell.execute_reply":"2022-06-06T21:29:58.519828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = np.argmax(model.predict(test_audio), axis=1)\ny_true = test_labels\n\ntest_acc = sum(y_pred == y_true) / len(y_true)\nprint(f'Test set accuracy: {test_acc:.0%}')","metadata":{"execution":{"iopub.status.busy":"2022-06-06T21:29:58.521806Z","iopub.status.idle":"2022-06-06T21:29:58.522219Z","shell.execute_reply.started":"2022-06-06T21:29:58.521994Z","shell.execute_reply":"2022-06-06T21:29:58.522017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics = history.history\nplt.plot(history.epoch, metrics['loss'], metrics['val_loss'])\nplt.legend(['loss', 'val_loss'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-06T21:29:58.529048Z","iopub.status.idle":"2022-06-06T21:29:58.529682Z","shell.execute_reply.started":"2022-06-06T21:29:58.529344Z","shell.execute_reply":"2022-06-06T21:29:58.529372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"wspolczynniki cepstralne \ndtw\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}