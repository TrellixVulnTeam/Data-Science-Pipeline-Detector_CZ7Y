{"metadata":{"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"},"language_info":{"nbconvert_exporter":"python","codemirror_mode":{"name":"ipython","version":3},"name":"python","version":"3.6.3","file_extension":".py","pygments_lexer":"ipython3","mimetype":"text/x-python"}},"nbformat_minor":1,"nbformat":4,"cells":[{"metadata":{},"execution_count":null,"cell_type":"code","source":"# input, output and command line tools\nimport os\nfrom os.path import isdir, join\nimport pandas as pd\n\n# math and data handler\nimport numpy as np\nimport pandas as pd\nfrom sklearn.decomposition import PCA\n\n# audio file i/o\nfrom scipy.fftpack import fft\nfrom scipy import signal\nfrom scipy.io import wavfile\n\n# Visualization\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom IPython.display import display\n\n\nmpl.rc('font', family = 'serif', size = 17)\nmpl.rcParams['xtick.major.size'] = 5\nmpl.rcParams['xtick.minor.size'] = 2\nmpl.rcParams['ytick.major.size'] = 5\nmpl.rcParams['ytick.minor.size'] = 2\n\n# Shuffle data\nfrom sklearn.utils import shuffle\n\n# Keras\nfrom keras import backend as K\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation\nfrom keras.layers import Flatten, Conv2D, MaxPooling2D, GRU\nfrom keras.optimizers import SGD, Adam, RMSprop, Adadelta\nfrom keras.utils import np_utils, plot_model\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.advanced_activations import LeakyReLU, PReLU\nfrom keras.callbacks import LearningRateScheduler\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers.recurrent import SimpleRNN, LSTM #Actually in this test, SimpleRNN works much better\nfrom keras.layers.embeddings import Embedding","outputs":[]},{"metadata":{"collapsed":true},"execution_count":null,"cell_type":"code","source":"hyper_pwr = 0.5\nhyper_train_ratio = 0.9\nhyper_n = 25\nhyper_m = 15\nhyper_NR = 208\nhyper_NC = 112\nhyper_delta = 0.3\nhyper_dropout0 = 0.2\nhyper_dropout1 = 0.4\nhyper_dropout2 = 0.6\nhyper_dropout3 = 0.6\nhyper_dropout4 = 0.4\nhyper_dropout5 = 0.7\n\nTAGET_LABELS = ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'silence', 'unknown']","outputs":[]},{"metadata":{"collapsed":true},"execution_count":null,"cell_type":"code","source":"## Function for loading the audio data, return a dataFrame\nMAX_SIZE = 16000\ndef load_audio_data(path, ltoi):\n    '''\n    path: audio file path\n    return: pd.DataFrame\n    '''\n    x = []\n    y = []\n    for i, folder in enumerate(os.listdir(path)):\n        for filename in os.listdir(path + '/' + folder):\n            if filename == 'README.md':\n                continue\n            rate, sample = wavfile.read(data_dir + '/' + folder + '/' + filename)\n            assert(rate == MAX_SIZE)\n            if folder == '_background_noise_':\n                length = len(sample)\n                for j in range(int(length/rate)):\n                    x.append(np.array(sample[j*rate: (j+1)*rate]))\n                    y.append(ltoi['silence'])\n            else:\n                x.append(np.array(sample))\n                label = folder\n                if folder not in TAGET_LABELS:\n                    label = 'unknown'\n                y.append(ltoi[label])\n    x = np.array(pad_sequences(x, maxlen=MAX_SIZE))\n    y = np.array(y)\n    df = pd.DataFrame()\n    df['x'] = list(x)\n    df['y'] = list(y)\n    return df","outputs":[]},{"metadata":{},"execution_count":null,"cell_type":"code","source":"data_dir = '../input/train/audio'\nos.listdir('{0}/_background_noise_'.format(data_dir))","outputs":[]},{"metadata":{},"execution_count":null,"cell_type":"code","source":"## Loading raw data Frame\nprint(\"LOADING RAW DATA!\")\nlabel2idx = {}\nidmap = {}\nfor i,lab in enumerate(TAGET_LABELS):\n    label2idx[lab] = i\n    idmap[i] = lab\nraw_df = load_audio_data(data_dir, label2idx)\nprint(label2idx)\nprint(idmap)\nprint(raw_df.x.as_matrix().shape)\nprint(raw_df.y.as_matrix().shape)","outputs":[]},{"metadata":{"collapsed":true},"execution_count":null,"cell_type":"code","source":"# Split train, test sets, and also return label_map\ndef train_test_split(df, train_ratio = 0.2, test_ratio = 0.1):\n    '''\n    return train_sets + test_sets + label_map, which maps from y to label name\n    '''\n    test_x = []\n    test_y = []\n    train_x = []\n    train_y = []\n    for i in set(df.y.tolist()):\n        tmp_df = df[df.y == i]\n        tmp_df = shuffle(tmp_df)\n        tmp_n = int(len(tmp_df)*train_ratio)\n        tmp_m = int(len(tmp_df)*test_ratio)\n        train_x += tmp_df.x.tolist()[: tmp_n]\n        test_x += tmp_df.x.tolist()[tmp_n: tmp_n + tmp_m]\n        train_y += tmp_df.y.tolist()[: tmp_n]\n        test_y += tmp_df.y.tolist()[tmp_n: tmp_n + tmp_m]\n    return np.array(train_x), np.array(train_y), np.array(test_x), np.array(test_y)","outputs":[]},{"metadata":{},"execution_count":null,"cell_type":"code","source":"## Parsing the data Frame into train and test sets\nprint(\"SPLITTING DATA INTO TRAIN AND TEST SETS!\")\ntr_x, tr_y, ts_x, ts_y = train_test_split(raw_df, 0.3, 0.1)\nprint(tr_x.shape)\nprint(tr_y.shape)\nprint(ts_x.shape)\nprint(ts_y.shape)\ndel raw_df","outputs":[]},{"metadata":{},"execution_count":null,"cell_type":"code","source":"BASE_LVL = min(tr_x.min(), ts_x.min())\nprint(BASE_LVL)\ntr_x = tr_x - BASE_LVL\nts_x = ts_x - BASE_LVL\nUPPER_X = max(tr_x.max(), ts_x.max()) + 1\nprint(UPPER_X)\nprint(tr_x[0])","outputs":[]},{"metadata":{},"execution_count":null,"cell_type":"code","source":"print(tr_x[0])\nprint(tr_x.max())\nprint(ts_x.max())\nprint(tr_x.min())\nprint(ts_x.min())","outputs":[]},{"metadata":{},"execution_count":null,"cell_type":"code","source":"# Function to compute class weights\ndef comp_cls_wts(y, pwr = 0.5):\n    '''\n    Used to compute class weights\n    '''\n    dic = {}\n    for x in set(y):\n        dic[x] = len(y)**pwr/list(y).count(x)**pwr\n    return dic","outputs":[]},{"metadata":{},"execution_count":null,"cell_type":"code","source":"cls_wts = comp_cls_wts(tr_y)\nprint(cls_wts)","outputs":[]},{"metadata":{"collapsed":true},"execution_count":null,"cell_type":"code","source":"NUM_CLS = len(TAGET_LABELS)\ntr_y = np_utils.to_categorical(tr_y, num_classes=NUM_CLS)\nts_y = np_utils.to_categorical(ts_y, num_classes=NUM_CLS)","outputs":[]},{"metadata":{},"execution_count":null,"cell_type":"code","source":"model = Sequential()\nmodel.add(Embedding(UPPER_X, 128, input_length=MAX_SIZE))\nmodel.add(SimpleRNN(512))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(NUM_CLS, activation='softmax'))\nmodel.summary()","outputs":[]},{"metadata":{"collapsed":true},"execution_count":null,"cell_type":"code","source":"### Compile the model\noptimizer = SGD()\nmetrics = ['accuracy']\nloss = 'categorical_crossentropy'\nmodel.compile(optimizer = optimizer, loss = loss, metrics = metrics)","outputs":[]},{"metadata":{},"execution_count":null,"cell_type":"code","source":"res = model.fit(tr_x, tr_y, batch_size = 64,epochs = 15, validation_data = (ts_x, ts_y),\n                class_weight = cls_wts)","outputs":[]},{"metadata":{"collapsed":true},"execution_count":null,"cell_type":"code","source":"","outputs":[]}]}