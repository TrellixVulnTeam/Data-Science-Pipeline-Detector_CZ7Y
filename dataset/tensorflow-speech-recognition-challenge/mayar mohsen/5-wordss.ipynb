{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import the libraries\n","metadata":{"execution":{"iopub.status.busy":"2022-02-11T15:15:42.09471Z","iopub.execute_input":"2022-02-11T15:15:42.095103Z","iopub.status.idle":"2022-02-11T15:15:42.099724Z","shell.execute_reply.started":"2022-02-11T15:15:42.095016Z","shell.execute_reply":"2022-02-11T15:15:42.098645Z"}}},{"cell_type":"code","source":"!pip install pyunpack\n!pip install patool\n!pip install py7zr\n!pip install sounddevice\n!pip install noisereduce\n!pip install librosa\n! pip install python_speech_features\n! pip install tensorflow==2.4\n! pip install malaya_speech\n! pip install webrtcvad","metadata":{"execution":{"iopub.status.busy":"2022-03-18T15:48:13.336788Z","iopub.execute_input":"2022-03-18T15:48:13.337224Z","iopub.status.idle":"2022-03-18T15:49:43.394733Z","shell.execute_reply.started":"2022-03-18T15:48:13.337125Z","shell.execute_reply":"2022-03-18T15:49:43.393732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom py7zr import unpack_7zarchive\nimport shutil\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimport librosa\nimport IPython.display as ipd\nfrom scipy.io import wavfile\n\nimport noisereduce as nr\nimport tensorflow \nfrom malaya_speech import Pipeline\n\nimport malaya_speech\nimport os\n\nfrom python_speech_features import mfcc\n\nfrom sklearn.preprocessing import LabelEncoder\nimport seaborn as sn","metadata":{"execution":{"iopub.status.busy":"2022-03-18T15:49:43.398054Z","iopub.execute_input":"2022-03-18T15:49:43.398427Z","iopub.status.idle":"2022-03-18T15:49:47.881749Z","shell.execute_reply.started":"2022-03-18T15:49:43.398387Z","shell.execute_reply":"2022-03-18T15:49:47.880605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shutil.register_unpack_format('7zip', ['.7z'], unpack_7zarchive)\nshutil.unpack_archive('/kaggle/input/tensorflow-speech-recognition-challenge/train.7z', '/kaggle/working/tensorflow-speech-recognition-challenge/train/')","metadata":{"execution":{"iopub.status.busy":"2022-03-18T15:49:47.884177Z","iopub.execute_input":"2022-03-18T15:49:47.884778Z","iopub.status.idle":"2022-03-18T15:52:29.945579Z","shell.execute_reply.started":"2022-03-18T15:49:47.884727Z","shell.execute_reply":"2022-03-18T15:52:29.944679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from pyunpack import Archive\n# import shutil\n# if not os.path.exists('/kaggle/working/tensorflow-speech-recognition-challenge/train/'):\n#     os.makedirs('/kaggle/working/tensorflow-speech-recognition-challenge/train/')\n# Archive('/kaggle/input/tensorflow-speech-recognition-challenge/train.7z').extractall('/kaggle/working/tensorflow-speech-recognition-challenge/train/')\n\n#for dirname, _, filenames in os.walk('/kaggle/working/tensorflow-speech-recognition-challenge/train/train/audio'):\n #   for filename in filename[:5]:\n  #      print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2022-03-18T15:52:29.947306Z","iopub.execute_input":"2022-03-18T15:52:29.947664Z","iopub.status.idle":"2022-03-18T15:52:29.951869Z","shell.execute_reply.started":"2022-03-18T15:52:29.947612Z","shell.execute_reply":"2022-03-18T15:52:29.950972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <center> Implementing the Speech Recognition Model in Python\n**Dataset used for our Speech Recognition Project**\n\n__You can download the dataset from__ [here](https://www.kaggle.com/c/tensorflow-speech-recognition-challenge).\n    \nTensorFlow recently released the Speech Commands Datasets. It includes 65,000 one-second long utterances of 30 short words, by thousands of different people. We’ll build a speech recognition system that understands simple spoken commands. <br>    ","metadata":{}},{"cell_type":"markdown","source":"**Data Exploration and Visualization**\n\nData Exploration and Visualization helps us to understand the data as well as pre-processing steps in a better way. \n\n**Visualization of Audio signal in time series domain**\n\nNow, we’ll visualize the audio signal in the time series domain:","metadata":{}},{"cell_type":"code","source":"train_audio_path = '/kaggle/working/tensorflow-speech-recognition-challenge/train/train/audio/'","metadata":{"execution":{"iopub.status.busy":"2022-03-18T15:52:29.953329Z","iopub.execute_input":"2022-03-18T15:52:29.954014Z","iopub.status.idle":"2022-03-18T15:52:29.962574Z","shell.execute_reply.started":"2022-03-18T15:52:29.953976Z","shell.execute_reply":"2022-03-18T15:52:29.961733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Accessing each file in data**","metadata":{}},{"cell_type":"code","source":"#!apt-get install -y p7zip-full\n#!7z x ../input/tensorflow-speech-recognition-challenge/train.7z","metadata":{"execution":{"iopub.status.busy":"2022-03-18T15:52:29.964169Z","iopub.execute_input":"2022-03-18T15:52:29.964806Z","iopub.status.idle":"2022-03-18T15:52:29.972352Z","shell.execute_reply.started":"2022-03-18T15:52:29.964714Z","shell.execute_reply":"2022-03-18T15:52:29.971503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"samples, sample_rate = librosa.load(train_audio_path+'on/5a3712c9_nohash_1.wav', sr = 16000)\nfig = plt.figure(figsize=(14, 8))\nax1 = fig.add_subplot(211)\nax1.set_title('Raw wave of ' + '../input/train/audio/on/0a7c2a8d_nohash_0.wav')\nax1.set_xlabel('time')\nax1.set_ylabel('Amplitude')\nax1.plot(np.linspace(0, sample_rate/len(samples), sample_rate), samples)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T15:52:29.973711Z","iopub.execute_input":"2022-03-18T15:52:29.974141Z","iopub.status.idle":"2022-03-18T15:52:30.154121Z","shell.execute_reply.started":"2022-03-18T15:52:29.974104Z","shell.execute_reply":"2022-03-18T15:52:30.15324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Sampling rate **\n\nLet us now look at the sampling rate of the audio signals","metadata":{}},{"cell_type":"code","source":"ipd.Audio(samples, rate=sample_rate)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T15:52:30.156737Z","iopub.execute_input":"2022-03-18T15:52:30.157256Z","iopub.status.idle":"2022-03-18T15:52:30.166376Z","shell.execute_reply.started":"2022-03-18T15:52:30.157215Z","shell.execute_reply":"2022-03-18T15:52:30.165352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(sample_rate)\nsig1=samples\nfs=sample_rate\nsr=fs","metadata":{"execution":{"iopub.status.busy":"2022-03-18T15:52:30.169503Z","iopub.execute_input":"2022-03-18T15:52:30.169907Z","iopub.status.idle":"2022-03-18T15:52:30.175883Z","shell.execute_reply.started":"2022-03-18T15:52:30.169869Z","shell.execute_reply":"2022-03-18T15:52:30.174771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time = np.linspace(0, len(sig1 - 1) / fs, len(sig1 - 1))\nreduced_noise1 = nr.reduce_noise(y=sig1, sr=fs,stationary=True)\nplt.plot(time, reduced_noise1)  # plot in seconds\n#reduced_noise2 = nr.reduce_noise(y=sig2, sr=fs,stationary=True)\n#plt.plot(time, reduced_noise2)  # plot in seconds\n#plt.title(\"Voice Signal\")\nplt.xlabel(\"Time [seconds]\")\nplt.ylabel(\"Voice amplitude\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-18T15:52:30.177333Z","iopub.execute_input":"2022-03-18T15:52:30.177756Z","iopub.status.idle":"2022-03-18T15:52:30.457307Z","shell.execute_reply.started":"2022-03-18T15:52:30.177719Z","shell.execute_reply":"2022-03-18T15:52:30.456213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ipd.Audio(reduced_noise1, rate=sample_rate)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T15:52:30.458965Z","iopub.execute_input":"2022-03-18T15:52:30.459347Z","iopub.status.idle":"2022-03-18T15:52:30.467576Z","shell.execute_reply.started":"2022-03-18T15:52:30.459308Z","shell.execute_reply":"2022-03-18T15:52:30.46656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Silence Removal\nvad = malaya_speech.vad.webrtc()\ny=reduced_noise1\ny_= malaya_speech.resample(y, sr, 16000)\ny_ = malaya_speech.astype.float_to_int(y_)\nframes = malaya_speech.generator.frames(y, 30, sr)\nframes_ = list(malaya_speech.generator.frames(y_, 30, 16000, append_ending_trail = False))\nframes_webrtc = [(frames[no], vad(frame)) for no, frame in enumerate(frames_)]\ny_ = malaya_speech.combine.without_silent(frames_webrtc)\ny_","metadata":{"execution":{"iopub.status.busy":"2022-03-18T15:52:30.468953Z","iopub.execute_input":"2022-03-18T15:52:30.469484Z","iopub.status.idle":"2022-03-18T15:52:30.494519Z","shell.execute_reply.started":"2022-03-18T15:52:30.469444Z","shell.execute_reply":"2022-03-18T15:52:30.493595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ipd.Audio(y_, rate = sr )","metadata":{"execution":{"iopub.status.busy":"2022-03-18T15:52:30.498287Z","iopub.execute_input":"2022-03-18T15:52:30.498613Z","iopub.status.idle":"2022-03-18T15:52:30.50873Z","shell.execute_reply.started":"2022-03-18T15:52:30.498585Z","shell.execute_reply":"2022-03-18T15:52:30.507565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"zero = np.zeros((1*sr-y_.shape[0]))\nsignal = np.concatenate((y_,zero))\nsignal.shape\ntime = np.linspace(0, len(signal - 1) / fs, len(signal - 1))","metadata":{"execution":{"iopub.status.busy":"2022-03-18T15:52:30.510174Z","iopub.execute_input":"2022-03-18T15:52:30.510813Z","iopub.status.idle":"2022-03-18T15:52:30.517206Z","shell.execute_reply.started":"2022-03-18T15:52:30.510775Z","shell.execute_reply":"2022-03-18T15:52:30.516158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(time,signal)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T15:52:30.51901Z","iopub.execute_input":"2022-03-18T15:52:30.519891Z","iopub.status.idle":"2022-03-18T15:52:30.672335Z","shell.execute_reply.started":"2022-03-18T15:52:30.519849Z","shell.execute_reply":"2022-03-18T15:52:30.671461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels=os.listdir(train_audio_path)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T15:52:30.67361Z","iopub.execute_input":"2022-03-18T15:52:30.674142Z","iopub.status.idle":"2022-03-18T15:52:30.679457Z","shell.execute_reply.started":"2022-03-18T15:52:30.674098Z","shell.execute_reply":"2022-03-18T15:52:30.67832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#find count of each label and plot bar graph\nno_of_recordings=[]\nfor label in labels:\n    waves = [f for f in os.listdir(train_audio_path + '/'+ label) if f.endswith('.wav')]\n    no_of_recordings.append(len(waves))\n    \n#plot\nplt.figure(figsize=(30,5))\nindex = np.arange(len(labels))\nplt.bar(index, no_of_recordings)\nplt.xlabel('Commands', fontsize=12)\nplt.ylabel('No of recordings', fontsize=12)\nplt.xticks(index, labels, fontsize=15, rotation=60)\nplt.title('No. of recordings for each command')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-18T15:52:30.681164Z","iopub.execute_input":"2022-03-18T15:52:30.681602Z","iopub.status.idle":"2022-03-18T15:52:31.034002Z","shell.execute_reply.started":"2022-03-18T15:52:30.681563Z","shell.execute_reply":"2022-03-18T15:52:31.033117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Words used","metadata":{}},{"cell_type":"code","source":"labels=[\"left\",\"right\",\"up\", \"down\",\"stop\"]","metadata":{"execution":{"iopub.status.busy":"2022-03-18T15:52:31.03526Z","iopub.execute_input":"2022-03-18T15:52:31.03576Z","iopub.status.idle":"2022-03-18T15:52:31.040476Z","shell.execute_reply.started":"2022-03-18T15:52:31.035714Z","shell.execute_reply":"2022-03-18T15:52:31.039683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Preprocessing the audio waves**\n\nlet us read the audio waves and use the below-preprocessing steps :\n\n* Noise Reduction\n* Silence Removal\n* Extracting MFCCs\n\nLet us define these preprocessing steps in the below code snippet:","metadata":{}},{"cell_type":"code","source":"sr=16000\nvad = malaya_speech.vad.webrtc()\nall_wave = []\nall_label = []\nfor label in labels:\n    print(label)\n    waves = [f for f in os.listdir(train_audio_path + '/'+ label) if f.endswith('.wav')]\n    for wav in waves:\n        samples, sample_rate = librosa.load(train_audio_path + '/' + label + '/' + wav, sr = 16000)\n        samples = nr.reduce_noise(y=samples, sr=sr,stationary=True)\n        y_= malaya_speech.resample(samples, sr, 16000)\n        y_ = malaya_speech.astype.float_to_int(y_)\n        frames = malaya_speech.generator.frames(samples, 30, sr)\n        frames_ = list(malaya_speech.generator.frames(y_, 30, 16000, append_ending_trail = False))\n        frames_webrtc = [(frames[no], vad(frame)) for no, frame in enumerate(frames_)]\n        y_ = malaya_speech.combine.without_silent(frames_webrtc)\n        zero = np.zeros(((1*sr+4000)-y_.shape[0]))\n        signal = np.concatenate((y_,zero))\n        all_wave.append(signal)\n        all_label.append(label)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T15:52:31.04213Z","iopub.execute_input":"2022-03-18T15:52:31.042903Z","iopub.status.idle":"2022-03-18T15:57:59.104324Z","shell.execute_reply.started":"2022-03-18T15:52:31.042861Z","shell.execute_reply":"2022-03-18T15:57:59.103366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.array(all_wave).shape)\nprint(np.array(all_label).shape)\ntime = np.linspace(0, len(signal - 1) / fs, len(signal - 1))\nplt.plot(time,np.array(all_wave)[2000,:])\nprint(np.array(all_label)[2000])\nipd.Audio(np.array(all_wave)[2000,:], rate = sr )","metadata":{"execution":{"iopub.status.busy":"2022-03-18T15:57:59.105705Z","iopub.execute_input":"2022-03-18T15:57:59.106059Z","iopub.status.idle":"2022-03-18T15:58:04.983476Z","shell.execute_reply.started":"2022-03-18T15:57:59.106022Z","shell.execute_reply":"2022-03-18T15:58:04.982586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_mfcc=[]\nfor wave in all_wave:\n    i=0\n    mfcc_feat = mfcc(wave , fs, winlen=256/fs, winstep=256/(2*fs), numcep=13, nfilt=26, nfft=256,\n                 lowfreq=0, highfreq=fs/2, preemph=0.97, ceplifter=22, appendEnergy=True, winfunc=np.hamming)\n    mfcc_feat= np.transpose(mfcc_feat)\n    all_mfcc.append(mfcc_feat)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-18T15:58:04.984856Z","iopub.execute_input":"2022-03-18T15:58:04.985373Z","iopub.status.idle":"2022-03-18T15:58:38.172335Z","shell.execute_reply.started":"2022-03-18T15:58:04.985334Z","shell.execute_reply":"2022-03-18T15:58:38.17125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.array(all_mfcc).shape)\nprint(np.array(all_label).shape)\nd1=np.array(all_mfcc).shape[1]\nd2=np.array(all_mfcc).shape[2]\nd=d1*d2\nprint(d)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T15:58:38.173615Z","iopub.execute_input":"2022-03-18T15:58:38.174261Z","iopub.status.idle":"2022-03-18T15:58:38.455817Z","shell.execute_reply.started":"2022-03-18T15:58:38.174212Z","shell.execute_reply":"2022-03-18T15:58:38.454846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"op_mfcc=np.array(all_mfcc)\nop_mfcc=op_mfcc.reshape(np.array(all_mfcc).shape[0],-1)\nop_mfcc.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-18T15:58:38.460142Z","iopub.execute_input":"2022-03-18T15:58:38.460421Z","iopub.status.idle":"2022-03-18T15:58:38.67746Z","shell.execute_reply.started":"2022-03-18T15:58:38.460393Z","shell.execute_reply":"2022-03-18T15:58:38.67655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#all_label = all_label.tolist()\n\nle = LabelEncoder()\ny=le.fit_transform(all_label)\nclasses= list(le.classes_)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T15:58:38.679463Z","iopub.execute_input":"2022-03-18T15:58:38.679984Z","iopub.status.idle":"2022-03-18T15:58:38.690078Z","shell.execute_reply.started":"2022-03-18T15:58:38.679946Z","shell.execute_reply":"2022-03-18T15:58:38.689192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Model based on ANN** ","metadata":{}},{"cell_type":"code","source":"! pip install --upgrade tensorflow\n! pip install --upgrade tensorflow-gpu\n! pip install keras==2.3.1","metadata":{"execution":{"iopub.status.busy":"2022-03-18T15:58:38.691629Z","iopub.execute_input":"2022-03-18T15:58:38.692032Z","iopub.status.idle":"2022-03-18T15:59:31.681237Z","shell.execute_reply.started":"2022-03-18T15:58:38.691995Z","shell.execute_reply":"2022-03-18T15:59:31.680209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.optimizers import SGD\nfrom keras.constraints import maxnorm\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Conv2D, Flatten, Dense,Dropout\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint","metadata":{"execution":{"iopub.status.busy":"2022-03-18T15:59:31.683846Z","iopub.execute_input":"2022-03-18T15:59:31.684228Z","iopub.status.idle":"2022-03-18T15:59:31.746442Z","shell.execute_reply.started":"2022-03-18T15:59:31.684183Z","shell.execute_reply":"2022-03-18T15:59:31.745529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y=tensorflow.keras.utils.to_categorical(y, num_classes=len(labels), dtype='float32')\ny.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-18T15:59:31.747938Z","iopub.execute_input":"2022-03-18T15:59:31.748587Z","iopub.status.idle":"2022-03-18T15:59:31.75714Z","shell.execute_reply.started":"2022-03-18T15:59:31.748547Z","shell.execute_reply":"2022-03-18T15:59:31.756051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_tr, x_val, y_tr, y_val= train_test_split(op_mfcc,np.array(y),stratify=y,test_size = 0.2,random_state=777,shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T15:59:31.758881Z","iopub.execute_input":"2022-03-18T15:59:31.759987Z","iopub.status.idle":"2022-03-18T15:59:32.075694Z","shell.execute_reply.started":"2022-03-18T15:59:31.759946Z","shell.execute_reply":"2022-03-18T15:59:32.074583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(x_tr.shape)\nprint(y_tr.shape)\nprint(x_val.shape)\nprint(y_val.shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T15:59:32.07706Z","iopub.execute_input":"2022-03-18T15:59:32.077444Z","iopub.status.idle":"2022-03-18T15:59:32.084786Z","shell.execute_reply.started":"2022-03-18T15:59:32.077404Z","shell.execute_reply":"2022-03-18T15:59:32.083714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Model Architecture**","metadata":{}},{"cell_type":"code","source":"#Model Architecture\nmodel = Sequential()\nmodel.add(Dense(100, activation='relu', input_shape=(d,), kernel_constraint=maxnorm(3)))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(80, activation='relu', kernel_constraint=maxnorm(3)))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(len(classes), activation='softmax' , kernel_constraint=maxnorm(3)))","metadata":{"execution":{"iopub.status.busy":"2022-03-18T15:59:32.086518Z","iopub.execute_input":"2022-03-18T15:59:32.087205Z","iopub.status.idle":"2022-03-18T15:59:34.19Z","shell.execute_reply.started":"2022-03-18T15:59:32.087166Z","shell.execute_reply":"2022-03-18T15:59:34.18899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tensorflow.keras.utils.plot_model(model, 'model.png',show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T15:59:34.192739Z","iopub.execute_input":"2022-03-18T15:59:34.193394Z","iopub.status.idle":"2022-03-18T15:59:34.687291Z","shell.execute_reply.started":"2022-03-18T15:59:34.193354Z","shell.execute_reply":"2022-03-18T15:59:34.686255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='categorical_crossentropy',optimizer='adamax',metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2022-03-18T15:59:34.68904Z","iopub.execute_input":"2022-03-18T15:59:34.689443Z","iopub.status.idle":"2022-03-18T15:59:34.710953Z","shell.execute_reply.started":"2022-03-18T15:59:34.6894Z","shell.execute_reply":"2022-03-18T15:59:34.70975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, min_delta=0.0001) \nmc = ModelCheckpoint('best_model.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')","metadata":{"execution":{"iopub.status.busy":"2022-03-18T15:59:34.712559Z","iopub.execute_input":"2022-03-18T15:59:34.713142Z","iopub.status.idle":"2022-03-18T15:59:34.719536Z","shell.execute_reply.started":"2022-03-18T15:59:34.713103Z","shell.execute_reply":"2022-03-18T15:59:34.718284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#3776\n300*32","metadata":{"execution":{"iopub.status.busy":"2022-03-18T15:59:34.721373Z","iopub.execute_input":"2022-03-18T15:59:34.721982Z","iopub.status.idle":"2022-03-18T15:59:34.735232Z","shell.execute_reply.started":"2022-03-18T15:59:34.721946Z","shell.execute_reply":"2022-03-18T15:59:34.734375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history=model.fit(x_tr, y_tr,validation_data=(x_val,y_val), epochs=300, batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T15:59:34.736942Z","iopub.execute_input":"2022-03-18T15:59:34.737322Z","iopub.status.idle":"2022-03-18T16:04:25.335924Z","shell.execute_reply.started":"2022-03-18T15:59:34.737283Z","shell.execute_reply":"2022-03-18T16:04:25.335024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_score = model.evaluate(x_tr, y_tr, batch_size=12)\nprint(train_score)\n\nprint('----------------Training Complete-----------------')\n\ntest_score = model.evaluate(x_val, y_val, batch_size = 12)\nprint(test_score)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T16:04:25.337368Z","iopub.execute_input":"2022-03-18T16:04:25.337684Z","iopub.status.idle":"2022-03-18T16:04:27.491277Z","shell.execute_reply.started":"2022-03-18T16:04:25.337648Z","shell.execute_reply":"2022-03-18T16:04:27.490439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history.history.keys()","metadata":{"execution":{"iopub.status.busy":"2022-03-18T16:04:27.496117Z","iopub.execute_input":"2022-03-18T16:04:27.498581Z","iopub.status.idle":"2022-03-18T16:04:27.508083Z","shell.execute_reply.started":"2022-03-18T16:04:27.498374Z","shell.execute_reply":"2022-03-18T16:04:27.507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot\npyplot.plot(history.history['loss'], label='train')\npyplot.plot(history.history['val_loss'], label='test')\npyplot.legend()\npyplot.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-18T16:04:27.516662Z","iopub.execute_input":"2022-03-18T16:04:27.517026Z","iopub.status.idle":"2022-03-18T16:04:27.667237Z","shell.execute_reply.started":"2022-03-18T16:04:27.516989Z","shell.execute_reply":"2022-03-18T16:04:27.666397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-18T16:04:27.668724Z","iopub.execute_input":"2022-03-18T16:04:27.669102Z","iopub.status.idle":"2022-03-18T16:04:27.807327Z","shell.execute_reply.started":"2022-03-18T16:04:27.669063Z","shell.execute_reply":"2022-03-18T16:04:27.806378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_predict=model.predict(x_val)\nconf_mat=tensorflow.math.confusion_matrix(np.argmax(y_val,axis=1) , np.argmax(y_predict,axis=1))","metadata":{"execution":{"iopub.status.busy":"2022-03-18T16:04:27.808798Z","iopub.execute_input":"2022-03-18T16:04:27.809178Z","iopub.status.idle":"2022-03-18T16:04:28.399519Z","shell.execute_reply.started":"2022-03-18T16:04:27.809136Z","shell.execute_reply":"2022-03-18T16:04:28.39853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_cm = pd.DataFrame(np.array(conf_mat), index = [i for i in classes],\n                  columns = [i for i in classes])\nplt.figure(figsize = (13,7))\nax = sn.heatmap(df_cm, annot=True)\nplt.title(\"Confusion Matrix\", fontsize=20)\nplt.ylabel(\"True Class\"     , fontsize=20)\nplt.xlabel(\"Predicted Class\", fontsize=20)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-18T16:04:28.400919Z","iopub.execute_input":"2022-03-18T16:04:28.401289Z","iopub.status.idle":"2022-03-18T16:04:28.729825Z","shell.execute_reply.started":"2022-03-18T16:04:28.40124Z","shell.execute_reply":"2022-03-18T16:04:28.728854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_val[1].shape\nmodel.predict(x_val[1].reshape((1,d)))","metadata":{"execution":{"iopub.status.busy":"2022-03-18T16:04:28.731116Z","iopub.execute_input":"2022-03-18T16:04:28.731618Z","iopub.status.idle":"2022-03-18T16:04:28.782409Z","shell.execute_reply.started":"2022-03-18T16:04:28.73158Z","shell.execute_reply":"2022-03-18T16:04:28.781527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Define the function that predicts text for the given audio:","metadata":{}},{"cell_type":"code","source":"def predict(audio):\n    print(samples.shape)\n    prob=model.predict(audio)\n    index=np.argmax(prob[0])\n    return classes[index]","metadata":{"execution":{"iopub.status.busy":"2022-03-18T16:04:28.783724Z","iopub.execute_input":"2022-03-18T16:04:28.78413Z","iopub.status.idle":"2022-03-18T16:04:28.790689Z","shell.execute_reply.started":"2022-03-18T16:04:28.784098Z","shell.execute_reply":"2022-03-18T16:04:28.789526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Prediction time! Make predictions on the validation data:","metadata":{}},{"cell_type":"code","source":"import random\nindex=random.randint(0,len(x_val)-1)\nprint(index)\nsamples=x_val[index]\nprint(\"Audio:\",classes[np.argmax(y_val[index])])\n#ipd.Audio(np.array(all_wave)[index,:], rate=16000)","metadata":{"execution":{"iopub.status.busy":"2022-03-18T16:04:28.792364Z","iopub.execute_input":"2022-03-18T16:04:28.792947Z","iopub.status.idle":"2022-03-18T16:04:28.801439Z","shell.execute_reply.started":"2022-03-18T16:04:28.792902Z","shell.execute_reply":"2022-03-18T16:04:28.800181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Text:\",predict(samples.reshape(1,d)))","metadata":{"execution":{"iopub.status.busy":"2022-03-18T16:04:28.803448Z","iopub.execute_input":"2022-03-18T16:04:28.803917Z","iopub.status.idle":"2022-03-18T16:04:28.851162Z","shell.execute_reply.started":"2022-03-18T16:04:28.803876Z","shell.execute_reply":"2022-03-18T16:04:28.84908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import load_model\nmodel.save(\"5_words.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-03-18T16:04:28.852372Z","iopub.execute_input":"2022-03-18T16:04:28.852655Z","iopub.status.idle":"2022-03-18T16:04:28.886939Z","shell.execute_reply.started":"2022-03-18T16:04:28.85261Z","shell.execute_reply":"2022-03-18T16:04:28.885902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}