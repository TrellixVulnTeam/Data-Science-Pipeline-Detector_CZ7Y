{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import the libraries\n","metadata":{"execution":{"iopub.status.busy":"2022-02-11T15:15:42.09471Z","iopub.execute_input":"2022-02-11T15:15:42.095103Z","iopub.status.idle":"2022-02-11T15:15:42.099724Z","shell.execute_reply.started":"2022-02-11T15:15:42.095016Z","shell.execute_reply":"2022-02-11T15:15:42.098645Z"}}},{"cell_type":"code","source":"!pip install pyunpack\n!pip install patool\n!pip install py7zr\n!pip install sounddevice\n!pip install noisereduce\n!pip install librosa\n! pip install python_speech_features\n! pip install tensorflow==2.4\n! pip install malaya_speech\n! pip install webrtcvad","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:12:04.203637Z","iopub.execute_input":"2022-05-14T16:12:04.204332Z","iopub.status.idle":"2022-05-14T16:13:25.941937Z","shell.execute_reply.started":"2022-05-14T16:12:04.204186Z","shell.execute_reply":"2022-05-14T16:13:25.940659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom py7zr import unpack_7zarchive\nimport shutil\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimport librosa\nimport IPython.display as ipd\nfrom scipy.io import wavfile\n\nimport noisereduce as nr\nimport tensorflow \nfrom malaya_speech import Pipeline\n\nimport malaya_speech\nimport os\n\nfrom python_speech_features import mfcc\n\nfrom sklearn.preprocessing import LabelEncoder\nimport seaborn as sn","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:13:25.951604Z","iopub.execute_input":"2022-05-14T16:13:25.95212Z","iopub.status.idle":"2022-05-14T16:13:29.563212Z","shell.execute_reply.started":"2022-05-14T16:13:25.952055Z","shell.execute_reply":"2022-05-14T16:13:29.562082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shutil.register_unpack_format('7zip', ['.7z'], unpack_7zarchive)\nshutil.unpack_archive('/kaggle/input/tensorflow-speech-recognition-challenge/train.7z', '/kaggle/working/tensorflow-speech-recognition-challenge/train/')","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:13:29.56575Z","iopub.execute_input":"2022-05-14T16:13:29.566244Z","iopub.status.idle":"2022-05-14T16:26:47.951103Z","shell.execute_reply.started":"2022-05-14T16:13:29.566197Z","shell.execute_reply":"2022-05-14T16:26:47.94991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from pyunpack import Archive\n# import shutil\n# if not os.path.exists('/kaggle/working/tensorflow-speech-recognition-challenge/train/'):\n#     os.makedirs('/kaggle/working/tensorflow-speech-recognition-challenge/train/')\n# Archive('/kaggle/input/tensorflow-speech-recognition-challenge/train.7z').extractall('/kaggle/working/tensorflow-speech-recognition-challenge/train/')\n\n#for dirname, _, filenames in os.walk('/kaggle/working/tensorflow-speech-recognition-challenge/train/train/audio'):\n #   for filename in filename[:5]:\n  #      print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:26:47.952589Z","iopub.execute_input":"2022-05-14T16:26:47.952979Z","iopub.status.idle":"2022-05-14T16:26:47.958688Z","shell.execute_reply.started":"2022-05-14T16:26:47.95294Z","shell.execute_reply":"2022-05-14T16:26:47.957387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <center> Implementing the Speech Recognition Model in Python\n**Dataset used for our Speech Recognition Project**\n\n__You can download the dataset from__ [here](https://www.kaggle.com/c/tensorflow-speech-recognition-challenge).\n    \nTensorFlow recently released the Speech Commands Datasets. It includes 65,000 one-second long utterances of 30 short words, by thousands of different people. We’ll build a speech recognition system that understands simple spoken commands. <br>    ","metadata":{}},{"cell_type":"markdown","source":"**Data Exploration and Visualization**\n\nData Exploration and Visualization helps us to understand the data as well as pre-processing steps in a better way. \n\n**Visualization of Audio signal in time series domain**\n\nNow, we’ll visualize the audio signal in the time series domain:","metadata":{}},{"cell_type":"code","source":"train_audio_path = '/kaggle/working/tensorflow-speech-recognition-challenge/train/train/audio/'","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:26:47.960637Z","iopub.execute_input":"2022-05-14T16:26:47.961444Z","iopub.status.idle":"2022-05-14T16:26:47.972491Z","shell.execute_reply.started":"2022-05-14T16:26:47.961389Z","shell.execute_reply":"2022-05-14T16:26:47.97113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Accessing each file in data**","metadata":{}},{"cell_type":"code","source":"#!apt-get install -y p7zip-full\n#!7z x ../input/tensorflow-speech-recognition-challenge/train.7z","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:26:47.97411Z","iopub.execute_input":"2022-05-14T16:26:47.974772Z","iopub.status.idle":"2022-05-14T16:26:47.987267Z","shell.execute_reply.started":"2022-05-14T16:26:47.974727Z","shell.execute_reply":"2022-05-14T16:26:47.986165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"samples, sample_rate = librosa.load(train_audio_path+'on/5a3712c9_nohash_1.wav', sr = 16000)\nfig = plt.figure(figsize=(14, 8))\nax1 = fig.add_subplot(211)\nax1.set_title('Raw wave of ' + '../input/train/audio/on/0a7c2a8d_nohash_0.wav')\nax1.set_xlabel('time')\nax1.set_ylabel('Amplitude')\nax1.plot(np.linspace(0, sample_rate/len(samples), sample_rate), samples)","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:26:47.98893Z","iopub.execute_input":"2022-05-14T16:26:47.989564Z","iopub.status.idle":"2022-05-14T16:26:48.239489Z","shell.execute_reply.started":"2022-05-14T16:26:47.98952Z","shell.execute_reply":"2022-05-14T16:26:48.237868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Sampling rate **\n\nLet us now look at the sampling rate of the audio signals","metadata":{}},{"cell_type":"code","source":"ipd.Audio(samples, rate=sample_rate)","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:26:48.244222Z","iopub.execute_input":"2022-05-14T16:26:48.245033Z","iopub.status.idle":"2022-05-14T16:26:48.261778Z","shell.execute_reply.started":"2022-05-14T16:26:48.244973Z","shell.execute_reply":"2022-05-14T16:26:48.260504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(sample_rate)\nsig1=samples\nfs=sample_rate\nsr=fs","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:26:48.264994Z","iopub.execute_input":"2022-05-14T16:26:48.266102Z","iopub.status.idle":"2022-05-14T16:26:48.27567Z","shell.execute_reply.started":"2022-05-14T16:26:48.266033Z","shell.execute_reply":"2022-05-14T16:26:48.274343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time = np.linspace(0, len(sig1 - 1) / fs, len(sig1 - 1))\nreduced_noise1 = nr.reduce_noise(y=sig1, sr=fs,stationary=True)\nplt.plot(time, reduced_noise1)  # plot in seconds\n#reduced_noise2 = nr.reduce_noise(y=sig2, sr=fs,stationary=True)\n#plt.plot(time, reduced_noise2)  # plot in seconds\n#plt.title(\"Voice Signal\")\nplt.xlabel(\"Time [seconds]\")\nplt.ylabel(\"Voice amplitude\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:26:48.283437Z","iopub.execute_input":"2022-05-14T16:26:48.284454Z","iopub.status.idle":"2022-05-14T16:26:49.518355Z","shell.execute_reply.started":"2022-05-14T16:26:48.284405Z","shell.execute_reply":"2022-05-14T16:26:49.517245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ipd.Audio(reduced_noise1, rate=sample_rate)","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:26:49.520019Z","iopub.execute_input":"2022-05-14T16:26:49.520557Z","iopub.status.idle":"2022-05-14T16:26:49.535239Z","shell.execute_reply.started":"2022-05-14T16:26:49.5205Z","shell.execute_reply":"2022-05-14T16:26:49.533927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Silence Removal\nvad = malaya_speech.vad.webrtc()\ny=reduced_noise1\ny_= malaya_speech.resample(y, sr, 16000)\ny_ = malaya_speech.astype.float_to_int(y_)\nframes = malaya_speech.generator.frames(y, 30, sr)\nframes_ = list(malaya_speech.generator.frames(y_, 30, 16000, append_ending_trail = False))\nframes_webrtc = [(frames[no], vad(frame)) for no, frame in enumerate(frames_)]\ny_ = malaya_speech.combine.without_silent(frames_webrtc)\ny_","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:26:49.536916Z","iopub.execute_input":"2022-05-14T16:26:49.538049Z","iopub.status.idle":"2022-05-14T16:26:49.566059Z","shell.execute_reply.started":"2022-05-14T16:26:49.538004Z","shell.execute_reply":"2022-05-14T16:26:49.564719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ipd.Audio(y_, rate = sr )","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:26:49.568057Z","iopub.execute_input":"2022-05-14T16:26:49.568571Z","iopub.status.idle":"2022-05-14T16:26:49.57844Z","shell.execute_reply.started":"2022-05-14T16:26:49.568529Z","shell.execute_reply":"2022-05-14T16:26:49.57684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"zero = np.zeros((1*sr-y_.shape[0]))\nsignal = np.concatenate((y_,zero))\nsignal.shape\ntime = np.linspace(0, len(signal - 1) / fs, len(signal - 1))","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:26:49.580629Z","iopub.execute_input":"2022-05-14T16:26:49.581146Z","iopub.status.idle":"2022-05-14T16:26:49.590175Z","shell.execute_reply.started":"2022-05-14T16:26:49.581066Z","shell.execute_reply":"2022-05-14T16:26:49.588644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(time,signal)","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:26:49.592194Z","iopub.execute_input":"2022-05-14T16:26:49.592758Z","iopub.status.idle":"2022-05-14T16:26:49.7773Z","shell.execute_reply.started":"2022-05-14T16:26:49.592696Z","shell.execute_reply":"2022-05-14T16:26:49.775897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels=os.listdir(train_audio_path)","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:26:49.779124Z","iopub.execute_input":"2022-05-14T16:26:49.779574Z","iopub.status.idle":"2022-05-14T16:26:49.785291Z","shell.execute_reply.started":"2022-05-14T16:26:49.779531Z","shell.execute_reply":"2022-05-14T16:26:49.783946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#find count of each label and plot bar graph\nno_of_recordings=[]\nfor label in labels:\n    waves = [f for f in os.listdir(train_audio_path + '/'+ label) if f.endswith('.wav')]\n    no_of_recordings.append(len(waves))\n    \n#plot\nplt.figure(figsize=(30,5))\nindex = np.arange(len(labels))\nplt.bar(index, no_of_recordings)\nplt.xlabel('Commands', fontsize=12)\nplt.ylabel('No of recordings', fontsize=12)\nplt.xticks(index, labels, fontsize=15, rotation=60)\nplt.title('No. of recordings for each command')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:26:49.787202Z","iopub.execute_input":"2022-05-14T16:26:49.788053Z","iopub.status.idle":"2022-05-14T16:26:50.220118Z","shell.execute_reply.started":"2022-05-14T16:26:49.788008Z","shell.execute_reply":"2022-05-14T16:26:50.218966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Words used","metadata":{}},{"cell_type":"code","source":"labels=[\"down\",\"left\",\"right\",\"stop\",\"up\"]","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:26:50.222035Z","iopub.execute_input":"2022-05-14T16:26:50.222802Z","iopub.status.idle":"2022-05-14T16:26:50.228409Z","shell.execute_reply.started":"2022-05-14T16:26:50.222754Z","shell.execute_reply":"2022-05-14T16:26:50.227018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Preprocessing the audio waves**\n\nlet us read the audio waves and use the below-preprocessing steps :\n\n* Noise Reduction\n* Silence Removal\n* Extracting MFCCs\n\nLet us define these preprocessing steps in the below code snippet:","metadata":{}},{"cell_type":"code","source":"sr=16000\nvad = malaya_speech.vad.webrtc()\nall_wave = []\nall_label = []\nfor label in labels:\n    print(label)\n    waves = [f for f in os.listdir(train_audio_path + '/'+ label) if f.endswith('.wav')]\n    for wav in waves:\n        samples, sample_rate = librosa.load(train_audio_path + '/' + label + '/' + wav, sr = 16000)\n        samples = nr.reduce_noise(y=samples, sr=sr,stationary=True)\n        y_= malaya_speech.resample(samples, sr, 16000)\n        y_ = malaya_speech.astype.float_to_int(y_)\n        frames = malaya_speech.generator.frames(samples, 30, sr)\n        frames_ = list(malaya_speech.generator.frames(y_, 30, 16000, append_ending_trail = False))\n        frames_webrtc = [(frames[no], vad(frame)) for no, frame in enumerate(frames_)]\n        y_ = malaya_speech.combine.without_silent(frames_webrtc)\n        zero = np.zeros(((1*sr+4000)-y_.shape[0]))\n        signal = np.concatenate((y_,zero))\n        all_wave.append(signal)\n        all_label.append(label)","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:26:50.23063Z","iopub.execute_input":"2022-05-14T16:26:50.231138Z","iopub.status.idle":"2022-05-14T16:33:55.667428Z","shell.execute_reply.started":"2022-05-14T16:26:50.231081Z","shell.execute_reply":"2022-05-14T16:33:55.666238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.array(all_wave).shape)\nprint(np.array(all_label).shape)\ntime = np.linspace(0, len(signal - 1) / fs, len(signal - 1))\nplt.plot(time,np.array(all_wave)[2000,:])\nprint(np.array(all_label)[2000])\nipd.Audio(np.array(all_wave)[2000,:], rate = sr )","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:33:55.668957Z","iopub.execute_input":"2022-05-14T16:33:55.67055Z","iopub.status.idle":"2022-05-14T16:34:02.219533Z","shell.execute_reply.started":"2022-05-14T16:33:55.670497Z","shell.execute_reply":"2022-05-14T16:34:02.218271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_mfcc=[]\nfor wave in all_wave:\n    i=0\n    mfcc_feat = mfcc(wave , fs, winlen=256/fs, winstep=256/(2*fs), numcep=13, nfilt=26, nfft=256,\n                 lowfreq=0, highfreq=fs/2, preemph=0.97, ceplifter=22, appendEnergy=True, winfunc=np.hamming)\n    mfcc_feat= np.transpose(mfcc_feat)\n    all_mfcc.append(mfcc_feat)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:34:02.221374Z","iopub.execute_input":"2022-05-14T16:34:02.221875Z","iopub.status.idle":"2022-05-14T16:34:53.059666Z","shell.execute_reply.started":"2022-05-14T16:34:02.221832Z","shell.execute_reply":"2022-05-14T16:34:53.058109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.array(all_mfcc).shape)\nprint(np.array(all_label).shape)\nd1=np.array(all_mfcc).shape[1]\nd2=np.array(all_mfcc).shape[2]\nd=d1*d2\nprint(d)","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:34:53.06195Z","iopub.execute_input":"2022-05-14T16:34:53.064075Z","iopub.status.idle":"2022-05-14T16:34:53.419217Z","shell.execute_reply.started":"2022-05-14T16:34:53.064027Z","shell.execute_reply":"2022-05-14T16:34:53.417916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"op_mfcc=np.array(all_mfcc)\n#op_mfcc=op_mfcc.reshape(np.array(all_mfcc).shape[0],-1)\nop_mfcc.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:34:53.420938Z","iopub.execute_input":"2022-05-14T16:34:53.421472Z","iopub.status.idle":"2022-05-14T16:34:53.524417Z","shell.execute_reply.started":"2022-05-14T16:34:53.421431Z","shell.execute_reply":"2022-05-14T16:34:53.523283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"op_mfcc=np.array(all_mfcc)\nop_mfcc.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:34:53.526349Z","iopub.execute_input":"2022-05-14T16:34:53.527015Z","iopub.status.idle":"2022-05-14T16:34:53.631639Z","shell.execute_reply.started":"2022-05-14T16:34:53.526959Z","shell.execute_reply":"2022-05-14T16:34:53.630362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"op_mfcc=op_mfcc.reshape(11834,13,156,-1)\nop_mfcc.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:37:08.511238Z","iopub.execute_input":"2022-05-14T16:37:08.511668Z","iopub.status.idle":"2022-05-14T16:37:08.519664Z","shell.execute_reply.started":"2022-05-14T16:37:08.511639Z","shell.execute_reply":"2022-05-14T16:37:08.518228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#all_label = all_label.tolist()\n\nle = LabelEncoder()\ny=le.fit_transform(all_label)\nclasses= list(le.classes_)","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:37:12.51229Z","iopub.execute_input":"2022-05-14T16:37:12.512861Z","iopub.status.idle":"2022-05-14T16:37:12.522544Z","shell.execute_reply.started":"2022-05-14T16:37:12.512826Z","shell.execute_reply":"2022-05-14T16:37:12.520994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:37:15.07709Z","iopub.execute_input":"2022-05-14T16:37:15.077576Z","iopub.status.idle":"2022-05-14T16:37:15.085673Z","shell.execute_reply.started":"2022-05-14T16:37:15.077547Z","shell.execute_reply":"2022-05-14T16:37:15.084523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Model based on ANN** ","metadata":{}},{"cell_type":"code","source":"! pip install --upgrade tensorflow\n! pip install --upgrade tensorflow-gpu\n! pip install keras==2.3.1","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:37:18.774656Z","iopub.execute_input":"2022-05-14T16:37:18.775135Z","iopub.status.idle":"2022-05-14T16:39:48.221815Z","shell.execute_reply.started":"2022-05-14T16:37:18.775073Z","shell.execute_reply":"2022-05-14T16:39:48.220552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.optimizers import SGD\nfrom keras.constraints import maxnorm\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Conv2D, Flatten, Dense,Dropout\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:39:48.224715Z","iopub.execute_input":"2022-05-14T16:39:48.225222Z","iopub.status.idle":"2022-05-14T16:39:48.288366Z","shell.execute_reply.started":"2022-05-14T16:39:48.225174Z","shell.execute_reply":"2022-05-14T16:39:48.28712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y=tensorflow.keras.utils.to_categorical(y, num_classes=len(labels), dtype='float32')\ny.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:39:48.290993Z","iopub.execute_input":"2022-05-14T16:39:48.291814Z","iopub.status.idle":"2022-05-14T16:39:48.303131Z","shell.execute_reply.started":"2022-05-14T16:39:48.291766Z","shell.execute_reply":"2022-05-14T16:39:48.301892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_tr, x_val, y_tr, y_val= train_test_split(op_mfcc,np.array(y),stratify=y,test_size = 0.2,random_state=777,shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:39:48.307421Z","iopub.execute_input":"2022-05-14T16:39:48.30821Z","iopub.status.idle":"2022-05-14T16:39:48.543239Z","shell.execute_reply.started":"2022-05-14T16:39:48.308166Z","shell.execute_reply":"2022-05-14T16:39:48.541927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(x_tr.shape)\nprint(y_tr.shape)\nprint(x_val.shape)\nprint(y_val.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:39:48.544986Z","iopub.execute_input":"2022-05-14T16:39:48.545621Z","iopub.status.idle":"2022-05-14T16:39:48.554752Z","shell.execute_reply.started":"2022-05-14T16:39:48.545565Z","shell.execute_reply":"2022-05-14T16:39:48.55218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Model Architecture**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, Input, MaxPooling2D\nfrom tensorflow.keras.layers import BatchNormalization\n#Model Architecture\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(4, 4), activation='relu', input_shape=(d1,d2,1)))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(48, kernel_size=(3, 3), activation='relu'))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(120, kernel_size=(3, 3), activation='relu'))\nmodel.add(BatchNormalization())\n\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(128, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(len(classes), activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:40:43.868903Z","iopub.execute_input":"2022-05-14T16:40:43.869389Z","iopub.status.idle":"2022-05-14T16:40:50.934625Z","shell.execute_reply.started":"2022-05-14T16:40:43.869355Z","shell.execute_reply":"2022-05-14T16:40:50.933569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tensorflow.keras.utils.plot_model(model, 'model.png',show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:40:50.936542Z","iopub.execute_input":"2022-05-14T16:40:50.936938Z","iopub.status.idle":"2022-05-14T16:40:51.90381Z","shell.execute_reply.started":"2022-05-14T16:40:50.936898Z","shell.execute_reply":"2022-05-14T16:40:51.902409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='categorical_crossentropy',optimizer='adamax',metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:40:51.90625Z","iopub.execute_input":"2022-05-14T16:40:51.907489Z","iopub.status.idle":"2022-05-14T16:40:51.930453Z","shell.execute_reply.started":"2022-05-14T16:40:51.907419Z","shell.execute_reply":"2022-05-14T16:40:51.929216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, min_delta=0.0001) \nmc = ModelCheckpoint('best_model.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:40:51.933693Z","iopub.execute_input":"2022-05-14T16:40:51.934522Z","iopub.status.idle":"2022-05-14T16:40:51.941745Z","shell.execute_reply.started":"2022-05-14T16:40:51.934471Z","shell.execute_reply":"2022-05-14T16:40:51.940352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#18932\n320*32","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:41:47.666221Z","iopub.execute_input":"2022-05-14T16:41:47.666655Z","iopub.status.idle":"2022-05-14T16:41:47.674503Z","shell.execute_reply.started":"2022-05-14T16:41:47.666624Z","shell.execute_reply":"2022-05-14T16:41:47.67295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history=model.fit(x_tr, y_tr,validation_data=(x_val,y_val), epochs=320, batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:41:57.701306Z","iopub.execute_input":"2022-05-14T16:41:57.701747Z","iopub.status.idle":"2022-05-14T16:57:45.397984Z","shell.execute_reply.started":"2022-05-14T16:41:57.701716Z","shell.execute_reply":"2022-05-14T16:57:45.396768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_score = model.evaluate(x_tr, y_tr, batch_size=12)\nprint(train_score)\n\nprint('----------------Training Complete-----------------')\n\ntest_score = model.evaluate(x_val, y_val, batch_size = 12)\nprint(test_score)","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:57:45.400211Z","iopub.execute_input":"2022-05-14T16:57:45.400565Z","iopub.status.idle":"2022-05-14T16:57:50.177269Z","shell.execute_reply.started":"2022-05-14T16:57:45.400532Z","shell.execute_reply":"2022-05-14T16:57:50.176058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history.history.keys()","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:57:50.180207Z","iopub.execute_input":"2022-05-14T16:57:50.18099Z","iopub.status.idle":"2022-05-14T16:57:50.189779Z","shell.execute_reply.started":"2022-05-14T16:57:50.180944Z","shell.execute_reply":"2022-05-14T16:57:50.188084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot\npyplot.plot(history.history['loss'], label='train')\npyplot.plot(history.history['val_loss'], label='test')\npyplot.legend()\npyplot.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:57:50.19184Z","iopub.execute_input":"2022-05-14T16:57:50.192375Z","iopub.status.idle":"2022-05-14T16:57:50.389385Z","shell.execute_reply.started":"2022-05-14T16:57:50.192311Z","shell.execute_reply":"2022-05-14T16:57:50.388266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:57:50.390928Z","iopub.execute_input":"2022-05-14T16:57:50.391485Z","iopub.status.idle":"2022-05-14T16:57:50.577626Z","shell.execute_reply.started":"2022-05-14T16:57:50.391454Z","shell.execute_reply":"2022-05-14T16:57:50.576369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_predict=model.predict(x_val)\nconf_mat=tensorflow.math.confusion_matrix(np.argmax(y_val,axis=1) , np.argmax(y_predict,axis=1))","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:57:50.579162Z","iopub.execute_input":"2022-05-14T16:57:50.579578Z","iopub.status.idle":"2022-05-14T16:57:51.384664Z","shell.execute_reply.started":"2022-05-14T16:57:50.579537Z","shell.execute_reply":"2022-05-14T16:57:51.383424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_cm = pd.DataFrame(np.array(conf_mat), index = [i for i in classes],\n                  columns = [i for i in classes])\nplt.figure(figsize = (13,7))\nax = sn.heatmap(df_cm, annot=True)\nplt.title(\"Confusion Matrix\", fontsize=20)\nplt.ylabel(\"True Class\"     , fontsize=20)\nplt.xlabel(\"Predicted Class\", fontsize=20)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:57:51.388758Z","iopub.execute_input":"2022-05-14T16:57:51.389166Z","iopub.status.idle":"2022-05-14T16:57:51.778153Z","shell.execute_reply.started":"2022-05-14T16:57:51.389129Z","shell.execute_reply":"2022-05-14T16:57:51.776935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_val[1].shape\nmodel.predict(x_val[1].reshape((1,d)))","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:34:54.18291Z","iopub.status.idle":"2022-05-14T16:34:54.183723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Define the function that predicts text for the given audio:","metadata":{}},{"cell_type":"code","source":"def predict(audio):\n    print(samples.shape)\n    prob=model.predict(audio)\n    index=np.argmax(prob[0])\n    return classes[index]","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:34:54.185033Z","iopub.status.idle":"2022-05-14T16:34:54.185931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Prediction time! Make predictions on the validation data:","metadata":{}},{"cell_type":"code","source":"import random\nindex=random.randint(0,len(x_val)-1)\nprint(index)\nsamples=x_val[index]\nprint(\"Audio:\",classes[np.argmax(y_val[index])])\n#ipd.Audio(np.array(all_wave)[index,:], rate=16000)","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:34:54.187524Z","iopub.status.idle":"2022-05-14T16:34:54.188335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Text:\",predict(samples.reshape(1,d)))","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:34:54.189732Z","iopub.status.idle":"2022-05-14T16:34:54.190669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import load_model\nmodel.save(\"commands_CNN.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-05-14T16:58:48.984991Z","iopub.execute_input":"2022-05-14T16:58:48.985487Z","iopub.status.idle":"2022-05-14T16:58:49.160084Z","shell.execute_reply.started":"2022-05-14T16:58:48.985453Z","shell.execute_reply":"2022-05-14T16:58:49.158657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}