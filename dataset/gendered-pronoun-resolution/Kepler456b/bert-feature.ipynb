{"cells":[{"metadata":{"_uuid":"f4caacffb0f4175a4b93c64356d815027e171741"},"cell_type":"markdown","source":"ALL BELOW BERT-RELATED FROM MATEI I. \n\nIn this kernel, I'm trying to obtain a baseline for the following model:\n1. Use a pre-trained version for the BERT transformer model to obtain contextual word embeddings for the 3 target words in each passage: A, B and Pronoun.\n2. Feed this into a multi-layer perceptron (MLP), which learns to solve the coreference resolution problem as a supervised classification task.\n\nI'm using the [GitHub repo for the BERT project ](https://github.com/google-research/bert) to obtain the pre-trained model. See also the [BERT paper](https://arxiv.org/abs/1810.04805) by Devlin et al. The idea for the architecture (1-2 above) comes from the [paper](https://openreview.net/forum?id=SJzSgnRcKX) \"What do you learn from context? Probing for sentence structure in contextualized word representations\" by Tenney et al. For coreference resolution, they use the OntoNotes and Definite Pronoun Resolution datasets, but not GAP. As such, the MLP hyperparameters they use may not be the best for our current task. The hyperparameters I use below are quite different from theirs.\n\nThe data I'm using comes from the 3 GAP files available [here](https://github.com/google-research-datasets/gap-coreference). The gap-development file contains the same data as the test_stage_1 file that we're trying to make predictions on. Of course, gap-development also contains the true labels, but I'm not using these when making predictions. I only use the true labels to evaluate the predictions made by my model. The other two files, gap-test and gap-validation, are used for training the model.\n\n**Updates V7**:\nIn the previous version, I was a little worried by the large variance of the model. The current version uses a much smaller MLP for the supervised classification problem, with more regularization. This achieves the same mean CV score, with lower variance. Specifically, the current MLP has:\n- only one hidden layer of size 37, down from two hidden layers of sizes [59,31]\n- dropout rate of 0.6 in the hidden layer, up from 0.5\n- L2 regularization in the output layer of 0.1, up from 0.05\n\nCeshine Lee independently published a kernel with a very neat PyTorch implementation of the same idea. You can check it out [here](https://www.kaggle.com/ceshine/pytorch-bert-baseline-public-score-0-54)."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\nimport zipfile\nimport sys\nimport time\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"26e811daa96d51bacaab58df081330063db24a2e"},"cell_type":"markdown","source":"Downloading the pre-trained BERT -Base, Uncased model. The kernel needs an Internet connection to do this, so make sure it's enabled."},{"metadata":{"trusted":true,"_uuid":"15d1a479dc9bd6e33c6acf30bfd8534ea64488e7"},"cell_type":"code","source":"from keras import backend as K\nfrom keras import initializers, regularizers, constraints, optimizers, layers\nfrom keras.engine.topology import Layer","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#downloading weights and cofiguration file for the model\n!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\nwith zipfile.ZipFile(\"uncased_L-12_H-768_A-12.zip\",\"r\") as zip_ref:\n    zip_ref.extractall()\n!ls 'uncased_L-12_H-768_A-12'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"632a8531b58804cd28272c2ef8dd5b5102334bd7"},"cell_type":"markdown","source":"Next, in order to feed our data to the model, we'll use some scripts from the bert repo on GitHub."},{"metadata":{"trusted":true,"_uuid":"3e0ac6bb63d1487866640ebe8e73f78b3a96c25a"},"cell_type":"code","source":"#!wget https://raw.githubusercontent.com/google-research/bert/master/modeling.py \n!wget https://raw.githubusercontent.com/isikkuntay/AIND/master/modeling.py\n!wget https://raw.githubusercontent.com/isikkuntay/AIND/master/run_classifier.py\n!wget https://raw.githubusercontent.com/google-research/bert/master/extract_features.py \n!wget https://raw.githubusercontent.com/google-research/bert/master/tokenization.py","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cfccbec6c87185a0db428e3ce8ecb93aa9c4547e"},"cell_type":"code","source":"import modeling\nimport extract_features\nimport tokenization\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fedd913810abd7c059385959634f220fb8fbad47"},"cell_type":"markdown","source":"Finally, let's download all the data from the GAP repo. The gap-development.tsv data contains the same 2000 rows as test_stage_1.tsv data. So we'll make predictions on it. The other two files, gap-validation.tsv with 454 rows, and gap-test.tsv with 2000 rows, will be used for training."},{"metadata":{"trusted":true,"_uuid":"64c3f40f620c50434a4645a76fe5ad1c9d34ec74"},"cell_type":"code","source":"!wget https://raw.githubusercontent.com/google-research-datasets/gap-coreference/master/gap-development.tsv\n!wget https://raw.githubusercontent.com/google-research-datasets/gap-coreference/master/gap-validation.tsv\n!wget https://raw.githubusercontent.com/google-research-datasets/gap-coreference/master/gap-test.tsv\n!ls","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f525be88f8fa80c8a8b680c0946e111cd7f653fa"},"cell_type":"markdown","source":"Next, we feed BERT the data from these three files. For each line, we want to obtain contextual embeddings for the 3 target words (A, B, Pronoun). Here are some helper functions to keep track of the offsets of the target words."},{"metadata":{"trusted":true,"_uuid":"1a655a90d41802605da6f27c605313eac4af4cc2"},"cell_type":"code","source":"def compute_offset_no_spaces(text, offset):\n\tcount = 0\n\tfor pos in range(offset):\n\t\tif text[pos] != \" \": count +=1\n\treturn count\n\ndef count_chars_no_special(text):\n\tcount = 0\n\tspecial_char_list = [\"#\"]\n\tfor pos in range(len(text)):\n\t\tif text[pos] not in special_char_list: count +=1\n\treturn count\n\ndef count_length_no_special(text):\n\tcount = 0\n\tspecial_char_list = [\"#\", \" \"]\n\tfor pos in range(len(text)):\n\t\tif text[pos] not in special_char_list: count +=1\n\treturn count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Copying Simple NLP notebook over here:\n\nimport os\nimport csv\nimport json\nimport string\nimport keras\nfrom pandas.io.json import json_normalize\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ncolor = sns.color_palette()\nfrom math import floor\nimport spacy\n\n%matplotlib inline\n\nfrom plotly import tools\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n\nfrom sklearn import model_selection, preprocessing, metrics, ensemble, naive_bayes, linear_model\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.ensemble import RandomForestClassifier\nimport lightgbm as lgb\n\nimport time\nfrom tqdm import tqdm\nimport math\nfrom sklearn.model_selection import train_test_split\nimport regex as re\n\nimport nltk \nfrom nltk.corpus import stopwords, wordnet\nfrom nltk.tokenize import word_tokenize, sent_tokenize \n\nnlp = spacy.load('en_core_web_sm')\n\ndef word_locate(sentence, location): \n    count_words = 0\n    count_chars = 2 #2 is to count for the two spaces in the beginning\n    for word in sentence.split():\n        count_words += 1\n        if location == count_chars:\n            return word, count_words\n        count_chars += len(word)\n        count_chars += 1 #for space\n        \ndef name_btwn_paran(sentence):\n    capture = \"\"\n    trigger_on = 0\n    for char in sentence:\n        if char == \")\":\n            trigger_on = 0\n        if trigger_on == 1:\n            capture += char\n        if char == \"(\":\n            trigger_on = 1\n    return capture\n\ndef which_name_first(sentence, name1, name2): #If name1 is first, return True\n    name1_check = 0\n    for word_punct in sentence.split():\n        for word_comma in word_punct.split(\";\"):\n            for word in word_comma.split(\",\"):\n                if word == name2 and name1_check == 0:\n                    return False\n                if word == name1:\n                    name1_check = 1\n    return True\n\ndef curr_prev_sentence(sentence, loc):\n    current_sentence = \"\"\n    prev_sentence = \"\"\n    trunc_curr_sentence = \"\"\n    remainder_curr = \"\"\n    detect = 0\n    count = 0\n    for char in sentence:\n        count += 1\n        current_sentence += char\n        remainder_curr += char\n        if ((char == \".\" or char == \";\") and detect == 0 and sentence[count] != \",\"): #the last arguement to prevent ., as in sent #4\n            prev_sentence = current_sentence \n            current_sentence = \"\"\n        if char == \".\" and detect == 1:\n            return current_sentence, prev_sentence, trunc_curr_sentence, remainder_curr\n        if count == loc:\n            detect = 1\n            trunc_curr_sentence = current_sentence\n            remainder_curr = \"\"\n    return current_sentence, prev_sentence, trunc_curr_sentence, remainder_curr\n\ndef remove_last_word(sentence):\n    new_sent = sentence.split()\n    new_sent = new_sent[:-1]\n    return \" \".join(new_sent)\n\ndef check_if_capital(word):\n    if word[0] in [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\",\"K\",\"L\",\"M\",\"O\",\"P\",\"Q\",\"R\",\"S\",\"T\",\"U\",\"V\",\"W\",\"X\",\"Y\",\"Z\"]:\n        return True\n    else:\n        return False\n    \ndef list_of_name_words(tokenized):\n    names_list = []\n    for word_tuple in nltk.pos_tag(tokenized):\n        if word_tuple[1] == \"NNP\":\n            names_list.append(word_tuple[0])\n    return names_list\n\ndef check_if_name(tokenized,word):\n    text = tokenized\n    for word_tuple in nltk.pos_tag(text):\n        if word_tuple[0] == word:\n            if word_tuple[1] == \"NNP\":\n                return True\n            else:\n                return False\n            \ndef find_name_words(sentence):\n    name = \"none\"\n    for word in sentence.split():\n        if check_if_capital(word):\n            return word\n    return name\n\ndef remove_first_word(sentence):\n    new_sent = sentence.split()\n    new_sent = new_sent[1:]\n    return \" \".join(new_sent)\n\ndef find_nth_subj(doc, n): #finds subject number n\n    subject = \"none\"\n    count = 0\n    for token in doc:\n        if (token.dep_ == \"nsubj\" or token.dep_ == \"nsubjpass\"):\n            count += 1\n            if count == n:\n                subject = token.text\n    return subject\n\ndef find_nth_dobj(doc, n): #finds direct object number n\n    dobj = \"none\"\n    count = 0\n    for token in doc:\n        if (token.dep_ == \"dobj\"):\n            count += 1\n            if count == n:\n                dobj = token.text\n    return dobj\n\ndef find_nth_poss(doc, n): #finds possessing noun number n\n    poss = \"none\"\n    count = 0\n    for token in doc:\n        if (token.dep_ == \"poss\"):\n            count += 1\n            if count == n:\n                poss = token.text\n    return poss\n\ndef find_nth_appos(doc, n): #finds appos number n; sometimes Spacy mislabels nsubj as appos\n    appos = \"none\"\n    count = 0\n    for token in doc:\n        if (token.dep_ == \"appos\"):\n            count += 1\n            if count == n:\n                appos = token.text\n    return appos\n\ndef check_if_poss_her(doc, pronoun): #tells whether it is her as in his or her as in him\n    #assumes only one her in the whole sentence (inaccurate?)\n    for token in doc:\n        if token.text == pronoun:\n            if token.dep_ == \"poss\":\n                return True\n            else:\n                return False\n            \nif 1 == 1:    \n    def get_feature_vector(pronoun, text, A, B, proffset, inquiry_part = \"A\"):\n        row = {}\n        row['A'] = A\n        row['B'] = B\n        curr, prev, trunc_curr, remainder = curr_prev_sentence(text, proffset)\n        curr_doc = nlp(curr)\n        prev_doc = nlp(prev) \n        curr_tok = word_tokenize(curr)\n        prev_tok = word_tokenize(prev)\n        trunc_curr_tok = word_tokenize(trunc_curr)\n        train_vector = []\n        #get first subj in prev @@@@@@@@@@@@@@@@@@@@@@@@@@@\n        get_p_f_s = \"none\"\n        for n in [1,2,3,4,5]: #number of n is from common sense\n            dummy_p_f_s = find_nth_subj(prev_doc,n)\n            if check_if_name(prev_tok,dummy_p_f_s) and get_p_f_s == \"none\":\n                get_p_f_s = dummy_p_f_s\n        \n        ####For sentence no. 5, spacy and nltk both failed to identify Collins as a propn.\n        ### therefore, we will add a new line here making sure we have a name.\n        \n        if get_p_f_s == \"none\":\n            if check_if_capital(find_nth_subj(prev_doc,1)):\n                get_p_f_s = find_nth_subj(prev_doc,1)\n        \n        ### We are changing the feature conditions in this kernel (1st of fork of simple nlp):\n        if get_p_f_s in row[inquiry_part] or row[inquiry_part] in get_p_f_s:\n            train_vector.append(1)\n        else:\n            train_vector.append(0)\n        \n        #get last  subj in prev @@@@@@@@@@@@@@@@@@@@@@@@@@@\n        get_p_l_s = \"none\"\n        for n in [1,2,3,4,5]:\n            dummy_p_l_s = find_nth_subj(prev_doc,n)\n            if check_if_name(prev_tok,dummy_p_l_s):\n                get_p_l_s = dummy_p_l_s\n               \n        ### pls Random forest classifier label special line:\n        if get_p_l_s in row[inquiry_part] or row[inquiry_part] in get_p_l_s:\n            train_vector.append(1)\n        else:\n            train_vector.append(0)\n        \n        #get first  obj in prev @@@@@@@@@@@@@@@@@@@@@@@@@@@\n        get_p_f_o = \"none\"\n        for n in [1,2,3,4,5]: \n            dummy_p_f_o = find_nth_dobj(prev_doc,n)\n            if check_if_name(prev_tok,dummy_p_f_o) and get_p_f_o == \"none\":\n                get_p_f_o = dummy_p_f_o\n          \n        ### pfo Random forest classifier label special line:\n        if get_p_f_o in row[inquiry_part] or row[inquiry_part] in get_p_f_o:\n            train_vector.append(1)\n        else:\n            train_vector.append(0)\n            \n        #get last  dobj in prev @@@@@@@@@@@@@@@@@@@@@@@@@@@\n        get_p_l_o = \"none\"\n        for n in [1,2,3,4,5]: \n            dummy_p_l_o = find_nth_dobj(prev_doc,n)\n            if check_if_name(prev_tok,dummy_p_l_o):\n                get_p_l_o = dummy_p_l_o\n          \n        ### plo Random forest classifier label special line:\n        if get_p_l_o in row[inquiry_part] or row[inquiry_part] in get_p_l_o: \n            train_vector.append(1)\n        else:\n            train_vector.append(0)\n        \n        #get last  subj in trunc curr @@@@@@@@@@@@@@@@@@@@@@@@@@@\n        get_tc_l_s = \"none\"\n        for n in [1,2,3,4]:\n            dummy_tc_l_s = find_nth_subj(curr_doc,n)\n            if check_if_name(curr_tok,dummy_tc_l_s)\\\n                    and (dummy_tc_l_s in trunc_curr): #this is slightly inaccurate but oh well\n                get_tc_l_s = dummy_tc_l_s \n        \n        ### tcls Random forest classifier label special line:\n        if get_tc_l_s in row[inquiry_part] or row[inquiry_part] in get_tc_l_s: \n            train_vector.append(1)\n        else:\n            train_vector.append(0)\n            \n        #get last  dobj in trunc curr @@@@@@@@@@@@@@@@@@@@@@@@@@@\n        get_tc_l_o = \"none\"\n        for n in [1,2,3,4]:\n            dummy_tc_l_o = find_nth_dobj(curr_doc,n)\n            if (dummy_tc_l_o in trunc_curr)\\\n                                        and check_if_name(curr_tok,dummy_tc_l_o): \n                get_tc_l_o = dummy_tc_l_o \n         \n        ### tclo Random forest classifier label special line:\n        if get_tc_l_o in row[inquiry_part] or row[inquiry_part] in get_tc_l_o: \n            train_vector.append(1)\n        else:\n            train_vector.append(0)\n        \n        #get last  poss in trunc curr @@@@@@@@@@@@@@@@@@@@@@@@@@@\n        get_tc_l_p = \"none\"\n        for n in [1,2,3,4]:\n            dummy_tc_l_p = find_nth_poss(curr_doc,n)\n            if (dummy_tc_l_p in trunc_curr)\\\n                                        and check_if_name(curr_tok,dummy_tc_l_p): \n                get_tc_l_p = dummy_tc_l_p \n        \n        ### tclp Random forest classifier label special line:\n        if get_tc_l_p in row[inquiry_part] or row[inquiry_part] in get_tc_l_p:\n            train_vector.append(1)\n        else:\n            train_vector.append(0)\n        \n        #get first subj in trunc curr @@@@@@@@@@@@@@@@@@@@@@@@@@@\n        get_tc_f_s = \"none\"\n        for n in [1,2,3,4]:\n            dummy_tc_f_s = find_nth_subj(curr_doc,n)\n            if check_if_name(curr_tok,dummy_tc_f_s) and get_tc_f_s == \"none\":\n                get_tc_f_s = dummy_tc_f_s \n           \n        ### tcfs Random forest classifier label special line:\n        if get_tc_f_s in row[inquiry_part] or row[inquiry_part] in get_tc_f_s:\n            train_vector.append(1)\n        else:\n            train_vector.append(0)\n            \n        #get first dobj in trunc curr @@@@@@@@@@@@@@@@@@@@@@@@@@@\n        get_tc_f_o = \"none\"\n        for n in [1,2,3,4]:\n            dummy_tc_f_o = find_nth_dobj(curr_doc,n)\n            if check_if_name(curr_tok,dummy_tc_f_o) and get_tc_f_o == \"none\": \n                get_tc_f_o = dummy_tc_f_o \n          \n        ### tcfo Random forest classifier label special line:\n        if get_tc_f_o in row[inquiry_part] or row[inquiry_part] in get_tc_f_o:  \n            train_vector.append(1)\n        else:\n            train_vector.append(0)\n    \n        #get last  non-subj name word  in trunc curr @@@@@@@@@@@@@@@@@@@@@@@@@@@\n        get_tc_l_nw = \"none\"\n        candidate = \"none\"\n        tc_name_words = list_of_name_words(trunc_curr_tok) \n        if len(tc_name_words) > 0:\n            candidate = tc_name_words[-1]\n        if candidate in get_tc_f_s or candidate in get_tc_l_s:\n            if len(tc_name_words) > 1:\n                candidate = tc_name_words[-1]\n        if check_if_name(curr_tok,candidate):\n            get_tc_l_nw = candidate\n        \n        ### tclnw Random forest classifier label special line:\n        if get_tc_l_nw in row[inquiry_part] or row[inquiry_part] in get_tc_l_nw: \n            train_vector.append(1)\n        else:\n            train_vector.append(0)\n        \n        #get first aposs in trunc curr @@@@@@@@@@@@@@@@@@@@@@@@@@@\n        get_tc_f_a = \"none\"\n        for n in [1,2,3,4]:\n            dummy_tc_f_a = find_nth_appos(curr_doc,n)\n            if check_if_name(curr_tok,dummy_tc_f_a) and get_tc_f_a == \"none\": \n                get_tc_f_a = dummy_tc_f_a \n         \n        ### tcfa Random forest classifier label special line:\n        if get_tc_f_a in row[inquiry_part] or row[inquiry_part] in get_tc_f_a: \n            train_vector.append(1)\n        else:\n            train_vector.append(0)\n    \n        #get word btwn paranthesis in prev @@@@@@@@@@@@@@@@@@@@@@@@@@@\n        get_p_f_wp = find_name_words(name_btwn_paran(prev))\n          \n        ### pfwp Random forest classifier label special line:\n        if get_p_f_wp in row[inquiry_part] or row[inquiry_part] in get_p_f_wp:\n            train_vector.append(1)\n        else:\n            train_vector.append(0)\n            \n        #get word btwn paranthesis in trunc curr @@@@@@@@@@@@@@@@@@@@@@@@@@@\n        get_tc_l_wp = find_name_words(name_btwn_paran(curr))  \n              \n        ### tclwp Random forest classifier label special line:\n        if get_tc_l_wp in row[inquiry_part] or row[inquiry_part] in get_tc_l_wp: \n            train_vector.append(1)\n        else:\n            train_vector.append(0)\n            \n        #get last subj in remainder @@@@@@@@@@@@@@@@@@@@@@@@@@@\n        get_r_f_s = \"none\"\n        for n in [1,2,3,4,5,6,7,8]: #in the final version, each of the name subjects will be accunted for\n            dummy_r_f_s = find_nth_subj(curr_doc,n)\n            if dummy_r_f_s in remainder and check_if_name(curr_tok,dummy_r_f_s):\n                get_r_f_s = dummy_r_f_s \n           \n        ### rfs Random forest classifier label special line:\n        if get_r_f_s in row[inquiry_part] or row[inquiry_part] in get_r_f_s:\n            train_vector.append(1)\n        else:\n            train_vector.append(0)\n            \n        #get last dobj in remainder @@@@@@@@@@@@@@@@@@@@@@@@@@@\n        get_r_f_o = \"none\"\n        for n in [1,2,3,4,5,6,7,8]: #in the final version, each of the name objects will be accunted for\n            dummy_r_f_o = find_nth_dobj(curr_doc,n)\n            if dummy_r_f_o in remainder and check_if_name(curr_tok,dummy_r_f_o):\n                get_r_f_o = dummy_r_f_o \n              \n        ### rfo Random forest classifier label special line:\n        if get_r_f_o in row[inquiry_part] or row[inquiry_part] in get_r_f_o:\n            train_vector.append(1)\n        else:\n            train_vector.append(0)\n            \n        #get last appos in remainder @@@@@@@@@@@@@@@@@@@@@@@@@@@\n        get_r_f_a = \"none\"\n        for n in [1,2,3,4]:\n            dummy_r_f_a = find_nth_appos(curr_doc,n)\n            if dummy_r_f_a in remainder and check_if_name(curr_tok,dummy_r_f_a): \n                get_r_f_a = dummy_r_f_a \n          \n        ### rfa Random forest classifier label special line:\n        if get_r_f_a in row[inquiry_part] or row[inquiry_part] in get_r_f_a:\n            train_vector.append(1)\n        else:\n            train_vector.append(0)\n        \n        #get first appos in current @@@@@@@@@@@@@@@@@@@@@@@@@@@\n        get_c_f_a = \"none\"\n        for n in [1,2,3,4]:\n            dummy_c_f_a = find_nth_appos(curr_doc,n)\n            if check_if_name(curr_tok,dummy_c_f_a) and get_c_f_a == \"none\": \n                get_c_f_a = dummy_c_f_a \n               \n        ### cfa Random forest classifier label special line:\n        if get_c_f_a in row[inquiry_part] or row[inquiry_part] in get_c_f_a: \n            train_vector.append(1)\n        else:\n            train_vector.append(0)\n        \n        #get first appos in prev @@@@@@@@@@@@@@@@@@@@@@@@@@@\n        get_p_f_a = \"none\"\n        for n in [1,2,3,4]:\n            dummy_p_f_a = find_nth_appos(prev_doc,n)\n            if check_if_name(prev_tok,dummy_p_f_a) and get_p_f_a == \"none\": \n                get_p_f_a = dummy_p_f_a \n              \n        ### pfa Random forest classifier label special line:\n        if get_p_f_a in row[inquiry_part] or row[inquiry_part] in get_p_f_a:\n            train_vector.append(1)\n        else:\n            train_vector.append(0)\n    \n        #check_if_poss_her\n        get_poss_her = check_if_poss_her(curr_doc, pronoun)\n        \n        #rand_forest classifier for pronoun type:\n        if pronoun == \"he\" or pronoun == \"she\": \n            train_vector.append(1)\n        elif pronoun == \"He\" or pronoun == \"She\": \n            train_vector.append(2)\n        elif pronoun == \"his\" or (pronoun == \"her\" and get_poss_her): \n            train_vector.append(3)\n        elif pronoun == \"him\" or (pronoun == \"her\" and not get_poss_her): \n            train_vector.append(4)\n        elif pronoun == \"His\" or (pronoun == \"Her\" and get_poss_her): \n            train_vector.append(5)\n        else:\n            train_vector.append(6)\n    \n        return train_vector","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6552a7a9786187610be695fcf25766594ca41685"},"cell_type":"markdown","source":"The following method takes the data from a file, passes it through BERT to obtain contextual embeddings for the target words, then returns these embeddings in the emb DataFrame. Below, we will use it 3 times, once for each of the files gap-test, gap-development, gap-validation."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9d8437cb4f7c1737e0c915d7d16cc3d004612416"},"cell_type":"code","source":"def run_bert(data):\n\t'''\n\tRuns a forward propagation of BERT on input text, extracting contextual word embeddings\n\tInput: data, a pandas DataFrame containing the information in one of the GAP files\n\n\tOutput: emb, a pandas DataFrame containing contextual embeddings for the words A, B and Pronoun. Each embedding is a numpy array of shape (768)\n\tcolumns: \"emb_A\": the embedding for word A\n\t         \"emb_B\": the embedding for word B\n\t         \"emb_P\": the embedding for the pronoun\n\t         \"label\": the answer to the coreference problem: \"A\", \"B\" or \"NEITHER\"\n\t'''\n    # From the current file, take the text only, and write it in a file which will be passed to BERT\n\ttext = data[\"Text\"]\n\ttext.to_csv(\"input.txt\", index = False, header = False)\n\n\ttask_name = \"kepler\"\n\n#\tprocessors = {\"kepler\": run_classifier.KeplerProcessor}\n#\tprocessors = {\"kepler\": run_classifier.MrpcProcessor}\n#processor = processors[\"kepler\"]\n\n    # The script extract_features.py runs forward propagation through BERT, and writes the output in the file output.jsonl\n    # I'm lazy, so I'm only saving the output of the last layer. Feel free to change --layers = -1 to save the output of other layers.\n\tos.system(\"python3 extract_features.py \\\n\t  --input_file=input.txt \\\n\t  --output_file=output.jsonl \\\n\t  --vocab_file=uncased_L-12_H-768_A-12/vocab.txt \\\n\t  --bert_config_file=uncased_L-12_H-768_A-12/bert_config.json \\\n\t  --init_checkpoint=uncased_L-12_H-768_A-12/bert_model.ckpt \\\n\t  --layers=-2 \\\n\t  --max_seq_length=256 \\\n\t  --batch_size=8\")\n\n\tbert_output = pd.read_json(\"output.jsonl\", lines = True)\n\n\tos.system(\"rm output.jsonl\")\n\tos.system(\"rm input.txt\")\n\n\tindex = data.index\n\tcolumns = [\"emb_A\", \"emb_B\", \"emb_P\", \"feat_A\", \"feat_B\", \"label\"]\n\temb = pd.DataFrame(index = index, columns = columns)\n\temb.index.name = \"ID\"\n\n\tfor i in range(len(data)): # For each line in the data file\n\t\t# get the words A, B, Pronoun. Convert them to lower case, since we're using the uncased version of BERT\n\t\tP = data.loc[i,\"Pronoun\"]\n\t\tA = data.loc[i,\"A\"]\n\t\tB = data.loc[i,\"B\"]\n\n\t\t# For each word, find the offset not counting spaces. This is necessary for comparison with the output of BERT\n\t\tP_offset = compute_offset_no_spaces(data.loc[i,\"Text\"], data.loc[i,\"Pronoun-offset\"])\n\t\tA_offset = compute_offset_no_spaces(data.loc[i,\"Text\"], data.loc[i,\"A-offset\"])\n\t\tB_offset = compute_offset_no_spaces(data.loc[i,\"Text\"], data.loc[i,\"B-offset\"])\n\t\t# Figure out the length of A, B, not counting spaces or special characters\n\t\tA_length = count_length_no_special(A)\n\t\tB_length = count_length_no_special(B)\n\n\t\t# Initialize embeddings with zeros\n\t\temb_A = np.zeros(768)\n\t\temb_B = np.zeros(768)\n\t\temb_P = np.zeros(768)\n\n\t\t# Initialize counts\n\t\tcount_chars = 0\n\t\tcnt_A, cnt_B, cnt_P = 0, 0, 0\n\n\t\tfeatures = pd.DataFrame(bert_output.loc[i,\"features\"]) # Get the BERT embeddings for the current line in the data file\n\t\tfor j in range(2,len(features)):  # Iterate over the BERT tokens for the current line; we skip over the first 2 tokens, which don't correspond to words\n\t\t\ttoken = features.loc[j,\"token\"]\n\n\t\t\t# See if the character count until the current token matches the offset of any of the 3 target words\n\t\t\tif count_chars  == P_offset: \n\t\t\t\t# print(token)\n\t\t\t\temb_P += np.array(features.loc[j,\"layers\"][0]['values'])\n\t\t\t\tcnt_P += 1\n\t\t\tif count_chars in range(A_offset, A_offset + A_length): \n\t\t\t\t# print(token)\n\t\t\t\temb_A += np.array(features.loc[j,\"layers\"][0]['values'])\n\t\t\t\tcnt_A += 1\n\t\t\tif count_chars in range(B_offset, B_offset + B_length): \n\t\t\t\t# print(token)\n\t\t\t\temb_B += np.array(features.loc[j,\"layers\"][0]['values'])\n\t\t\t\tcnt_B += 1\n# Update the character count\n\t\t\tcount_chars += count_length_no_special(token)\n\t\t# Taking the average between tokens in the span of A or B, so divide the current value by the count\t\n\t\temb_A /= cnt_A\n\t\temb_B /= cnt_B\n\n\t\t# Work out the label of the current piece of text\n\t\tlabel = \"Neither\"\n\t\tif (data.loc[i,\"A-coref\"] == True):\n\t\t\tlabel = \"A\"\n\t\tif (data.loc[i,\"B-coref\"] == True):\n\t\t\tlabel = \"B\"\n\n\t\tpro_offset = data.loc[i,\"Pronoun-offset\"]\n\t\tthis_text = data.loc[i,\"Text\"]\n\n\t\tfeat_A = get_feature_vector(P, this_text, A, B, pro_offset, inquiry_part = \"A\")\n\t\tfeat_B = get_feature_vector(P, this_text, A, B, pro_offset, inquiry_part = \"B\")\n            \n\t\t# Put everything together in emb\n\t\temb.iloc[i] = [emb_A, emb_B, emb_P, np.asarray(feat_A), np.asarray(feat_B), label]\n\n\treturn emb","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"98ca59d6fc859477aff649ea2ca8a35f65201e9d"},"cell_type":"markdown","source":"Read the three GAP files, pass them through BERT, and write the contextual embeddings in json files. Unfortunately, I wasn't able to silence TensorFlow, so it's giving a lot of information and warnings when I run this cell."},{"metadata":{"trusted":true,"_uuid":"8298947fa33285e722bdaae2df41bca5dd795732"},"cell_type":"code","source":"print(\"Started at \", time.ctime())\ntest_data = pd.read_csv(\"gap-test.tsv\", sep = '\\t')\ntest_emb = run_bert(test_data)\ntest_emb.to_json(\"contextual_embeddings_gap_test.json\", orient = 'columns')\n\nvalidation_data = pd.read_csv(\"gap-validation.tsv\", sep = '\\t')\nvalidation_emb = run_bert(validation_data)\nvalidation_emb.to_json(\"contextual_embeddings_gap_validation.json\", orient = 'columns')\n\nwith open('../input/test_stage_2.tsv') as tsvfile:\n    development_data = pd.read_csv(tsvfile, sep = '\\t')\ndevelopment_emb = run_bert(development_data)\ndevelopment_emb.to_json(\"contextual_embeddings_gap_development.json\", orient = 'columns')\nprint(\"Finished at \", time.ctime())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0bb6a706145f87f5b40755aa209183f5f5e82a7b"},"cell_type":"markdown","source":"Now that we have the embeddings, we pass them to a multi-layer perceptron (i.e. vanilla neural network), which learns to classify the triples of embeddings (emb_A, emb_B,emb_P) as \"A\", \"B\" or \"NEITHER\"."},{"metadata":{"trusted":true,"_uuid":"29ba41d2570238ec22735909c76cd86c2742517c"},"cell_type":"code","source":"from keras import backend, models, layers, initializers, regularizers, constraints, optimizers\nfrom keras import callbacks as kc\nfrom keras import optimizers as ko\n\nfrom sklearn.model_selection import cross_val_score, KFold, train_test_split\nfrom sklearn.metrics import log_loss\nimport time\n\n\ndense_layer_sizes = [37]\ndropout_rate = 0.6\nlearning_rate = 0.001\nn_fold = 5\nbatch_size = 32\nepochs = 1000\npatience = 100\n# n_test = 100\nlambd = 0.1 # L2 regularization","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"351a99cfb2b3616216fe17f78c4c70484704c2da"},"cell_type":"markdown","source":"We define a model with two hidden layers and one output layer in Keras."},{"metadata":{"trusted":true,"_uuid":"5ae69f747d3adb8f4635675ee77031304637faa0"},"cell_type":"code","source":"class IsLayer(Layer):\n    #Layer to be used after a dense one. It will multiply all the elements with each other.\n    #In a sense, it allows the neurons to have a say on  each others' outputs. This layer, hopefully,\n    #compares the relative importance of neurons.The compound prob is regulated with weights.\n    #The idea follows from attention layer, but is more basic than that. As it is multiplicative, it is \n    #an alternative to the vanilla additive layer where outputs are added at the next layer.\n    \n    def __init__(self, **kwargs):\n        super(IsLayer, self).__init__(**kwargs)\n    \n    def build(self, input_shape):\n        #Create a trainable weight variable for this layer.\n        self.W = self.add_weight(name='W', \n                                 shape=(input_shape[1], 1), \n                                 initializer='uniform',\n                                 trainable=True)\n        super(IsLayer, self).build(input_shape)\n        \n    def call(self, x):\n        x_W = K.dot(x, self.W)\n        x_new = x*x_W \n        return x_new\n    \n    def compute_output_shape(self, input_shape):\n        return (input_shape[0], input_shape[-1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"763ec8591474c45d6b065cad0c7efc2bbe9ad514"},"cell_type":"code","source":"def build_mlp_model(input_shape, num_output):\n\tX_input = layers.Input(input_shape)\n\n\t# First dense layer\n\tX = layers.Dense(dense_layer_sizes[0], name = 'dense0')(X_input)\n\tX = layers.BatchNormalization(name = 'bn0')(X)\n\tX = layers.Activation('relu')(X)\n\tX = layers.Dropout(dropout_rate, seed = 7)(X)\n#\tX = IsLayer()(X)\n\n\t# Second dense layer\n# \tX = layers.Dense(dense_layer_sizes[0], name = 'dense1')(X)\n# \tX = layers.BatchNormalization(name = 'bn1')(X)\n# \tX = layers.Activation('relu')(X)\n# \tX = layers.Dropout(dropout_rate, seed = 9)(X)\n\n\t# Output layer\n\tX = layers.Dense(num_output, name = 'output', kernel_regularizer = regularizers.l2(lambd))(X)\n\tX = layers.Activation('sigmoid')(X)\n\n\t# Create model\n\tmodel = models.Model(input = X_input, output = X, name = \"classif_model\")\n\treturn model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0ea0ac2603b0a4bbdaa2776c8e37ad7894a99f5a"},"cell_type":"code","source":"def parse_json(embeddings):\n\t'''\n\tParses the embeddigns given by BERT, and suitably formats them to be passed to the MLP model\n\n\tInput: embeddings, a DataFrame containing contextual embeddings from BERT, as well as the labels for the classification problem\n\tcolumns: \"emb_A\": contextual embedding for the word A\n\t         \"emb_B\": contextual embedding for the word B\n\t         \"emb_P\": contextual embedding for the pronoun\n\t         \"label\": the answer to the coreference problem: \"A\", \"B\" or \"NEITHER\"\n\n\tOutput: X, a numpy array containing, for each line in the GAP file, the concatenation of the embeddings of the target words\n\t        Y, a numpy array containing, for each line in the GAP file, the one-hot encoded answer to the coreference problem\n\t'''\n\tembeddings.sort_index(inplace = True) # Sorting the DataFrame, because reading from the json file messed with the order\n\tX = np.zeros((len(embeddings)*2,2*768+19)) #19 is the length of special feature vector\n\tY = np.zeros((len(embeddings)*2, 1))\n\n\t# Concatenate features (A first batch)\n\tfor i in range(len(embeddings)):\n\t\tA = np.array(embeddings.loc[i,\"emb_A\"])\n\t\tP = np.array(embeddings.loc[i,\"emb_P\"])\n\t\tF = np.array(embeddings.loc[i,\"feat_A\"])        \n\t\tX[i] = np.concatenate((A, P, F))\n\n\t# One-hot encoding for labels\n\tfor i in range(len(embeddings)):\n\t\tlabel = embeddings.loc[i,\"label\"]\n\t\tif label == \"A\":\n\t\t\tY[i] = 1\n\t\telse:\n\t\t\tY[i] = 0\n\n\t# Concatenate features (B second batch)\n\tfor i in range(len(embeddings)):\n\t\tB = np.array(embeddings.loc[i,\"emb_B\"])\n\t\tP = np.array(embeddings.loc[i,\"emb_P\"])\n\t\tF = np.array(embeddings.loc[i,\"feat_B\"])                \n\t\tX[i+len(embeddings)] = np.concatenate((B, P, F)) \n\n\t# One-hot encoding for labels ; A's and B's concatenated like same since they are symmetrical\n\tfor i in range(len(embeddings)):\n\t\tlabel = embeddings.loc[i,\"label\"]\n\t\tif label == \"B\":\n\t\t\tY[i+len(embeddings)] = 1\n\t\telse:\n\t\t\tY[i+len(embeddings)] = 0\n        \n\treturn X, Y","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eb7ea0c73fe3479ae464df563c90965b0d179db6"},"cell_type":"markdown","source":"We use the method defined above to parse the contextual embeddings, for each of the 3 GAP data files. The variable names here may be a bit counter-intuitive. Keep in mind that we will use X_test and X_validation for training, and then make predictions on X_development."},{"metadata":{"trusted":true,"_uuid":"870abe398fa7a8cd20aa42953bcf592b0db5469b"},"cell_type":"code","source":"# Read development embeddigns from json file - this is the output of Bert\ndevelopment = pd.read_json(\"contextual_embeddings_gap_development.json\")\nX_development, Y_development = parse_json(development)\n\nvalidation = pd.read_json(\"contextual_embeddings_gap_validation.json\")\nX_validation, Y_validation = parse_json(validation)\n\ntest = pd.read_json(\"contextual_embeddings_gap_test.json\")\nX_test, Y_test = parse_json(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3b942d4712312b1c03b657b83aafd6d6595179c4"},"cell_type":"code","source":"# There may be a few NaN values, where the offset of a target word is greater than the max_seq_length of BERT.\n# They are very few, so I'm just dropping the rows.\nremove_test = [row for row in range(len(X_test)) if np.sum(np.isnan(X_test[row]))]\nX_train = np.delete(X_test, remove_test, 0)\nY_train = np.delete(Y_test, remove_test, 0)\n\n# We want predictions for all validation rows. So instead of removing rows, make them 0\nremove_validation = [row for row in range(len(X_validation)) if np.sum(np.isnan(X_validation[row]))]\nX_validation[remove_validation] = np.zeros(2*768+19)\n\n# We want predictions for all development rows. So instead of removing rows, make them 0\nremove_development = [row for row in range(len(X_development)) if np.sum(np.isnan(X_development[row]))]\nX_development[remove_development] = np.zeros(2*768+19)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"25de1c995bf67e68ffd342063eb5a363c43fe459"},"cell_type":"code","source":"# Will train on data from the gap-test and gap-validation files, in total 2454 rows\n#X_train = np.concatenate((X_test, X_validation), axis = 0)\n#Y_train = np.concatenate((Y_test, Y_validation), axis = 0)\n\n# Will predict probabilities for data from the gap-development file; initializing the predictions\n#prediction = np.zeros((len(X_development),1)) # testing predictions\n\nval_prediction = np.zeros((len(X_validation),1)) # valid predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2538dcc94af4b17eb2c34112f62cf5244d2329ca"},"cell_type":"code","source":"# Training and cross-validation\nfolds = KFold(n_splits=n_fold, shuffle=True, random_state=3)\nscores = []\nfor fold_n, (train_index, valid_index) in enumerate(folds.split(X_train)):\n\t# split training and validation data\n\tprint('Fold', fold_n, 'started at', time.ctime())\n\tX_tr, X_val = X_train[train_index], X_train[valid_index]\n\tY_tr, Y_val = Y_train[train_index], Y_train[valid_index]\n\n\t# Define the model, re-initializing for each fold\n\tclassif_model = build_mlp_model([X_train.shape[1]],1)\n\tclassif_model.compile(optimizer = optimizers.Adam(lr = learning_rate), loss = \"binary_crossentropy\")\n\tcallbacks = [kc.EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights = True)]\n\n\t# train the model\n\tclassif_model.fit(x = X_tr, y = Y_tr, epochs = epochs, batch_size = batch_size, callbacks = callbacks, validation_data = (X_val, Y_val), verbose = 0)\n\n\t# make predictions on validation and test data\n\tpred_valid = classif_model.predict(x = X_val, verbose = 0)\n\n\t# oof[valid_index] = pred_valid.reshape(-1,)\n\tscores.append(log_loss(Y_val, pred_valid))\n    \nval_prediction = classif_model.predict(x = X_validation, verbose = 0)\n\n# Print CV scores, as well as score on the test data\nprint('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\nprint(scores)\nprint(\"Test score:\", log_loss(Y_validation,val_prediction))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_neither_mlp(input_shape, num_output):\n\tX_input = layers.Input(input_shape)\n\n\t# First dense layer\n\tX = layers.Dense(dense_layer_sizes[0], name = 'dense0')(X_input)\n\tX = layers.BatchNormalization(name = 'bn0')(X)\n\tX = layers.Activation('relu')(X)\n\tX = layers.Dropout(dropout_rate, seed = 7)(X)\n\n    # Output layer\n\tX = layers.Dense(num_output, name = 'output', kernel_regularizer = regularizers.l2(lambd))(X)\n\tX = layers.Activation('sigmoid')(X)\n\n\t# Create model\n\tmodel = models.Model(input = X_input, output = X, name = \"neither_model\")\n\treturn model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_val_A = val_prediction[: int(len(val_prediction)/2)]\nX_val_B = val_prediction[int(len(val_prediction)/2) :]\nX_train_neither = np.concatenate((X_val_A, X_val_B), axis=1)\n\nY_val_A = Y_validation[: int(len(Y_validation)/2)]\nY_val_B = Y_validation[int(len(Y_validation)/2) :]\nY_train_neither = 1 - Y_val_A - Y_val_B","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_val_A.shape)\nprint(X_val_B.shape)\nprint(X_train_neither.shape)\nprint(Y_val_A.shape)\nprint(Y_val_B.shape)\nprint(Y_train_neither.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"neither_model = build_neither_mlp([X_train_neither.shape[1]],1)\nneither_model.compile(optimizer = optimizers.Adam(lr = learning_rate), loss = \"binary_crossentropy\")\nneither_model.fit(X_train_neither, y = Y_train_neither, epochs = epochs, batch_size = batch_size, validation_data = (X_train_neither, Y_train_neither), verbose = 0)\n\ndev_prediction = classif_model.predict(x = X_development, verbose = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_dev_A = dev_prediction[: int(len(dev_prediction)/2)]\nX_dev_B = dev_prediction[int(len(dev_prediction)/2) :]\nX_dev_neither = np.concatenate((X_dev_A, X_dev_B), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dev_neither = neither_model.predict(x = X_dev_neither, verbose = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"198c1b2df108afcf2292538c1b12b10c05d9c12b"},"cell_type":"code","source":"# Write the prediction to file for submission\nsubmission = pd.read_csv(\"../input/sample_submission_stage_1.csv\", index_col = \"ID\")\n\nsubmission[\"A\"] = X_dev_A\nsubmission[\"B\"] = X_dev_B\nsubmission[\"NEITHER\"] = dev_neither\nsubmission.to_csv(\"submission_bert.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cd59f99e4b2061de33cf975d41071f5bad38014f"},"cell_type":"markdown","source":"The best LB score I got with this method is 0.52. There are many things to try that could improve this, and I may attempt some of these in the future:\n1. Fine-tune the BERT model, instead of using the pre-trained weights.\n2. Use a mix of the BERT layers, instead of just the output of the last layer.\n3. Tune some of the hyperparameters of the MLP model; I haven't played with them at all.\n4. Look at all occurences of the target words A and B in the text, instead of just the one specified by the offset."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}