{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this kernel I will explain what caused error during preprocessing *test_stage_2.tsv* and a fixed code doesn't affect training."},{"metadata":{"trusted":false},"cell_type":"code","source":"!wget https://github.com/google-research-datasets/gap-coreference/raw/master/gap-development.tsv -q\n!wget https://github.com/google-research-datasets/gap-coreference/raw/master/gap-test.tsv -q\n!wget https://github.com/google-research-datasets/gap-coreference/raw/master/gap-validation.tsv -q","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import pandas as pd\nimport re\nimport spacy\nfrom IPython.core.display import display, HTML","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_df = pd.concat([pd.read_csv(\"gap-test.tsv\", index_col=0, delimiter=\"\\t\"),\n                      pd.read_csv(\"gap-validation.tsv\", index_col=0, delimiter=\"\\t\"),\n                      pd.read_csv(\"gap-development.tsv\", index_col=0, delimiter=\"\\t\")])\ntest_df = pd.read_csv(\"../input/test_stage_2.tsv\", index_col=0, delimiter=\"\\t\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is the original code."},{"metadata":{"trusted":false},"cell_type":"code","source":"nlp = spacy.load('en')\ndef get_sentence(text, offset, token_after=\"[PRONOUN]\"):\n    \"\"\"\n    Extract a sentence containing a word at position offset by character and\n    replace the word with token_after.\n    output: Transformed sentence\n            token_before\n            a pos tag of the word.\n    \"\"\"\n    doc = nlp(text)\n    # idx: Character offset\n    idx_begin = 0\n    for token in doc:\n        if token.sent_start:\n            idx_begin = token.idx\n        if token.idx == offset:\n            sent = token.sent.string\n            pos_tag = token.pos_\n            idx_token = offset - idx_begin\n            break\n    # word_s = sent[idx_token:].split()\n    # n = len(sent)\n    token_before = token.string.strip()\n    subtxt_transformed = re.sub(\"^\" + token_before, token_after, sent[idx_token:])\n    sent_transformed = sent[:idx_token] + subtxt_transformed\n    # n_diff = len(sent_transformed) - n - len(token_after) + len(token_before)\n    return sent_transformed, token_before, pos_tag","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time\ntrain_preprocessed_before = []\nfor obj in train_df.iterrows():\n    train_preprocessed_before.append(get_sentence(obj[1][\"Text\"], obj[1][\"Pronoun-offset\"]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No errors."},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"%%time\ntest_preprocessed = []\nfor e, obj in enumerate(test_df.iterrows()):\n    test_preprocessed.append(get_sentence(obj[1][\"Text\"], obj[1][\"Pronoun-offset\"]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The function assumes that **token.idx == offset** somewhere in doc, which is wrong."},{"metadata":{"trusted":false},"cell_type":"code","source":"ID = obj[0]\ntext = obj[1][\"Text\"]\noffset = obj[1][\"Pronoun-offset\"]\nhtml_text = \"<BLOCKQUOTE>\" + text[:offset] + \"<font color='red'>\" + text[offset:offset + 2] + \"</font>\" + text[offset + 2:] + \"</BLOCKQUOTE>\" \ndisplay(HTML(\"An error occured during preprocessing ID: \" +  \"<I>\" + ID + \"</I>.\" + html_text))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"doc = nlp(text)\n\nprint(\"Pronoun-offset:\", offset)\nfor token in doc:\n    if token.idx > offset - 10 and token.idx < offset + 10:\n        print(token.idx, token.pos_, \":\", token)\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The reason for the error is that spacy'tokenizer couldn't extract \"**he**\" at position 313 and *get_sentence* doesn't properly handle that case.\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time\nfor obj in test_df.iloc[e + 1:].iterrows():\n    test_preprocessed.append(get_sentence(obj[1][\"Text\"], obj[1][\"Pronoun-offset\"]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No error after that. Only one case caused error.\n\nHere is a fixed code."},{"metadata":{"trusted":false},"cell_type":"code","source":"def get_sentence(text, offset, token_after=\"[PRONOUN]\"):\n    \"\"\"\n    Extract a sentence containing a word at position offset by character and\n    replace the word with token_after.\n    output: Transformed sentence\n            A word starting at offset\n            A pos tag of the word.\n            If the word cannot be extracted it returns default values.\n    \"\"\"\n    doc = nlp(text)\n    # idx: Character offset\n    idx_begin = 0\n    sent = None\n    for token in doc:\n        if token.sent_start:\n            idx_begin = token.idx\n        if token.idx == offset:\n            sent = token.sent.string\n            pos_tag = token.pos_\n            idx_token = offset - idx_begin\n            break\n    # word_s = sent[idx_token:].split()\n    # n = len(sent)\n    if sent is None:\n        # Default values\n        sent_transformed = token_after\n        token_before = \"it\"\n        pos_tag = \"PRON\"\n    else:\n        token_before = token.string.strip()\n        subtxt_transformed = re.sub(\"^\" + token_before, token_after, sent[idx_token:])\n        sent_transformed = sent[:idx_token] + subtxt_transformed\n    # n_diff = len(sent_transformed) - n - len(token_after) + len(token_before)\n    return sent_transformed, token_before, pos_tag","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time\ntrain_preprocessed_after = []\nfor obj in train_df.iterrows():\n    train_preprocessed_after.append(get_sentence(obj[1][\"Text\"], obj[1][\"Pronoun-offset\"]))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"%%time\ntest_preprocessed = []\nfor obj in test_df.iterrows():\n    test_preprocessed.append(get_sentence(obj[1][\"Text\"], obj[1][\"Pronoun-offset\"]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No errors."},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"all([before == after for before, after in zip(train_preprocessed_before, train_preprocessed_after)])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The change doesn't affect training."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"}},"nbformat":4,"nbformat_minor":1}