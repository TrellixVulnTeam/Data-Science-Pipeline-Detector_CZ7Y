{"cells":[{"metadata":{},"cell_type":"markdown","source":"The following is my initial EDA for the Gendered Pronoun Resolution dataset from the similarly named competition. I'm presently working with a group to make a late attempt to see if we can find a better solution to the ones which were submitted. This kernal is meant as a starting point for my group and is far from a finished end product.\n\nVersion 2: removed pronouns from the stopwords list as they are relevent to this challenge. added the side effect of the word 'Hi' showing up and being counted frequently, which is not present in the prior version, you can see the impact side by side"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\npd.options.display.max_columns = 100\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom nltk import sent_tokenize, word_tokenize\nimport nltk.data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\nfrom keras.preprocessing.sequence import pad_sequences\nfrom sklearn.model_selection import train_test_split\nfrom pytorch_pretrained_bert import BertTokenizer, BertConfig\nfrom pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\nfrom tqdm import tqdm, trange\nimport pandas as pd\nimport io\nimport numpy as np\nimport matplotlib.pyplot as plt\n% matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"stage_one = pd.read_csv('../input/gendered-pronoun-resolution/test_stage_1.tsv', sep='\\t')\nstage_two = pd.read_csv('../input/gendered-pronoun-resolution/test_stage_2.tsv', sep='\\t')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(stage_one.head())\ndisplay(stage_two.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(stage_one.Text.iloc[0])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stng = stage_one.Text.iloc[0]\nprint(stng[191:204]) # The A-offset or where the Subject is\nprint(stng[207:211]) # The B-offset or where the object is\nprint(stng[274:278]) # The location of the pronoun","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(stage_two.Text.iloc[3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stage_one.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stage_one['length'] = pd.Series([len(x) for x in stage_one.Text], index=stage_one.index)\nstage_two['length'] = pd.Series([len(x) for x in stage_two.Text], index=stage_two.index)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Stage one data: ')\n\n\n\ndisplay(stage_one.describe())\ndisplay(stage_one.shape)\npronoun = stage_one.groupby(\"Pronoun\")\nprint('\\n\\npronoun data: ')\ndisplay(pronoun.describe())\n#display(pronoun.length)\n\nplt.figure(figsize=(20,7))\nsns.distplot(stage_one.length)\nplt.xlabel(\"Frequency\")\nplt.ylabel(\"length of of text\")\n\n\nplt.figure(figsize=(12,7))\npronoun.size().sort_values().plot.bar()\nplt.xticks(rotation=50)\nplt.xlabel(\"Pronoun\")\nplt.ylabel(\"Frequency of pronoun\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Stage two data: ')\ndisplay(stage_two.describe())\ndisplay(stage_two.shape)\npronoun = stage_two.groupby(\"Pronoun\")\nprint('pronoun data: ')\ndisplay(pronoun.describe())\n\nplt.figure(figsize=(20,7))\nsns.distplot(stage_two.length, color='g')\nplt.xlabel(\"Frequency\")\nplt.ylabel(\"length of text\")\n\nplt.figure(figsize=(12,7))\npronoun.size().sort_values().plot.bar(color='g')\nplt.xticks(rotation=50)\nplt.xlabel(\"Pronoun\")\nplt.ylabel(\"Frequency of pronoun\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Let's make some MF word clouds!\nFull discloser I have never made a word cloud before, this project seemed like a good time to give it a try.\nThe link below is what I used for reference material and also some copying of a few lines of code.\n\nhttps://www.datacamp.com/community/tutorials/wordcloud-python\n\nI highly recommend that tutorial there are some gorgeos wordplots there which exceed the scope of this perticular notebook"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom os import path\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Credit to DJ here, she had mentioned that pronouns can show as stop words (words that NLP tools will ignore as inconsequential)\n# This cell collects the recognized pronouns and adds them to a list\nnon_stop = set(pronoun.Pronoun.unique().index)\nprint(non_stop)\n\nnon_stop = STOPWORDS - non_stop","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#?WordCloud\n#uncomment to see documentation for wordcloud, I had to reference this one alot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text = \" \".join(sample for sample in stage_one.Text)\nprint(\"There are \", len(text),\" words in the combination of all strings from 'Text' column.\")\n\n\nwordcloud = WordCloud(stopwords=STOPWORDS,width=1200,\n    height=600).generate(text)\n\nplt.figure(figsize=(20,15))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.title('WordCloud without pronouns', fontsize=26)\nplt.axis(\"off\")\nplt.show()\n\n\n\nwordcloud = WordCloud(stopwords=non_stop,width=1200,\n    height=600).generate(text)\n\nplt.figure(figsize=(20,15))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.title('WordCloud with pronouns', fontsize=26)\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text = \" \".join(sample for sample in stage_two.Text)\nprint(\"There are \", len(text),\" words in the combination of all strings from 'Text' column.\")\nprint(\"this is 5x the number of words in the stage one dataset\")\nwordcloud = WordCloud(stopwords=STOPWORDS,width=1200,\n    height=600).generate(text)\n\nplt.figure(figsize=(20,15))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.title('WordCloud without pronouns', fontsize=26)\nplt.axis(\"off\")\nplt.show()\n\n\nwordcloud = WordCloud(stopwords=non_stop,width=1200,\n    height=600).generate(text)\n\nplt.figure(figsize=(20,15))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.title('WordCloud with pronouns', fontsize=26)\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Further consideration: It might be interesting to break down the text samples differently, for instance spliting the strings into two to four word chunks and looking for common chunks (words occuring frequently in the same sequence)."},{"metadata":{"trusted":true},"cell_type":"code","source":"q = stage_one.Text[0]\n#q = q.split()\n#sentences = [\"[CLS] \" + val + \" [SEP]\" for val in q.split('.')]\nprint(cleaned string)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}