{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn import *\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gap_development = pd.read_csv('../input/gapdataset/gap-development.tsv', delimiter='\\t')\ngap_test = pd.read_csv('../input/gapdataset/gap-test.tsv', delimiter='\\t')\ngap_validation = pd.read_csv('../input/gapdataset/gap-validation.tsv', delimiter='\\t')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gap_development.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gap_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gap_validation.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.concat((gap_test, gap_validation)).reset_index(drop=True)\ntest = gap_development\n\ntrain['A-coref'] = train['A-coref'].astype(int)\ntrain['B-coref'] = train['B-coref'].astype(int)\ntrain['NEITHER'] = 1.0 - (train['A-coref'] + train['B-coref'])\n\ntest['A-coref'] = test['A-coref'].astype(int)\ntest['B-coref'] = test['B-coref'].astype(int)\ntest['NEITHER'] = 1.0 - (test['A-coref'] + test['B-coref'])\n\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Use Bert embeding to acquire correct similarity between A and pronoun, B and pronoun."},{"metadata":{"trusted":true},"cell_type":"code","source":"!wget https://raw.githubusercontent.com/google-research/bert/master/modeling.py \n!wget https://raw.githubusercontent.com/google-research/bert/master/extract_features.py \n!wget https://raw.githubusercontent.com/google-research/bert/master/tokenization.py","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n! 7z x uncased_L-12_H-768_A-12.zip","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import modeling\nimport extract_features\nimport tokenization","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def compute_offset_no_spaces(text, offset):\n    count = 0\n    for pos in range(offset):\n        if text[pos] != \" \": count +=1\n    return count\n\ndef count_chars_no_special(text):\n    count = 0\n    special_char_list = [\"#\"]\n    for pos in range(len(text)):\n        if text[pos] not in special_char_list: count +=1\n    return count\n\ndef count_length_no_special(text):\n    count = 0\n    special_char_list = [\"#\", \" \"]\n    for pos in range(len(text)):\n        if text[pos] not in special_char_list: count +=1\n    return count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def bert_embeddings(df):\n    text = df[\"Text\"]\n    text.to_csv(\"input.txt\", index = False, header = False)\n    \n    # run BERT model\n    os.system(\"python3 extract_features.py \\\n      --input_file=input.txt \\\n      --output_file=output.jsonl \\\n      --vocab_file=uncased_L-12_H-768_A-12/vocab.txt \\\n      --bert_config_file=uncased_L-12_H-768_A-12/bert_config.json \\\n      --init_checkpoint=uncased_L-12_H-768_A-12/bert_model.ckpt \\\n      --layers=-1 \\\n      --max_seq_length=256 \\\n      --batch_size=8\")\n    \n    bert_output = pd.read_json(\"output.jsonl\", lines = True)\n\n    os.system(\"rm output.jsonl\")\n    os.system(\"rm input.txt\")\n\n    index = df.index\n    columns = [\"emb_A\", \"emb_B\", \"emb_P\", \"label\"]\n    emb = pd.DataFrame(index = index, columns = columns)\n    emb.index.name = \"ID\"\n    \n    for i in range(len(df)): # For each line in the data file\n        # get the words A, B, Pronoun. Convert them to lower case, since we're using the uncased version of BERT\n        P = df.loc[i,\"Pronoun\"].lower()\n        A = df.loc[i,\"A\"].lower()\n        B = df.loc[i,\"B\"].lower()\n\n        # For each word, find the offset not counting spaces. This is necessary for comparison with the output of BERT\n        P_offset = compute_offset_no_spaces(df.loc[i,\"Text\"], df.loc[i,\"Pronoun-offset\"])\n        A_offset = compute_offset_no_spaces(df.loc[i,\"Text\"], df.loc[i,\"A-offset\"])\n        B_offset = compute_offset_no_spaces(df.loc[i,\"Text\"], df.loc[i,\"B-offset\"])\n        # Figure out the length of A, B, not counting spaces or special characters\n        A_length = count_length_no_special(A)\n        B_length = count_length_no_special(B)\n\n        # Initialize embeddings with zeros\n        emb_A = np.zeros(768)\n        emb_B = np.zeros(768)\n        emb_P = np.zeros(768)\n\n        # Initialize counts\n        count_chars = 0\n        cnt_A, cnt_B, cnt_P = 0, 0, 0\n\n        features = pd.DataFrame(bert_output.loc[i,\"features\"])\n        \n        for j in range(2,len(features)):  # Iterate over the BERT tokens for the current line; we skip over the first 2 tokens, which don't correspond to words\n            token = features.loc[j,\"token\"]\n\n            # See if the character count until the current token matches the offset of any of the 3 target words\n            if count_chars  == P_offset: \n                # print(token)\n                emb_P += np.array(features.loc[j,\"layers\"][0]['values'])\n                cnt_P += 1\n            if count_chars in range(A_offset, A_offset + A_length): \n                # print(token)\n                emb_A += np.array(features.loc[j,\"layers\"][0]['values'])\n                cnt_A +=1\n            if count_chars in range(B_offset, B_offset + B_length): \n                # print(token)\n                emb_B += np.array(features.loc[j,\"layers\"][0]['values'])\n                cnt_B +=1\n            # Update the character count\n            count_chars += count_length_no_special(token)\n        # Taking the average between tokens in the span of A or B, so divide the current value by the count\t\n        emb_A /= cnt_A\n        emb_B /= cnt_B\n        \n        label = \"Neither\"\n        if (df.loc[i,\"A-coref\"] == 1):\n            label = \"A\"\n        if (df.loc[i,\"B-coref\"] == 1):\n            label = \"B\"\n\n        # Put everything together in emb\n        emb.iloc[i] = [emb_A, emb_B, emb_P, label]\n        \n    return emb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_emb = bert_embeddings(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_emb =  bert_embeddings(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy import spatial \ndef add_similarity_columns(df, df_emb):\n    df['sim_A_P'] = 0\n    df['sim_B_P'] = 0\n\n    for i in range(0, len(df)):\n        sim_A_P = 1 - spatial.distance.cosine(df_emb.loc[i, 'emb_A'], df_emb.loc[i, 'emb_P'])\n        if not np.isnan(sim_A_P):\n            df.loc[i, 'sim_A_P'] = sim_A_P\n        \n        sim_B_P = 1 - spatial.distance.cosine(df_emb.loc[i, 'emb_B'], df_emb.loc[i, 'emb_P'])\n        if not np.isnan(sim_B_P):\n            df.loc[i, 'sim_B_P'] = sim_B_P","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"add_similarity_columns(train, train_emb)\nadd_similarity_columns(test, test_emb)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Extend feature matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_additional_features(df):\n    df['Pronoun-offset2'] = df['Pronoun-offset'] + df['Pronoun'].map(len)\n    df['A-offset2'] = df['A-offset'] + df['A'].map(len)\n    df['B-offset2'] = df['B-offset'] + df['B'].map(len)\n    df['A-dist'] = (df['Pronoun-offset'] - df['A-offset']).abs()\n    df['B-dist'] = (df['Pronoun-offset'] - df['B-offset']).abs()\n    df['section_min'] = df[['Pronoun-offset', 'A-offset', 'B-offset']].min(axis=1)\n    df['section_max'] = df[['Pronoun-offset2', 'A-offset2', 'B-offset2']].max(axis=1)\n    \nadd_additional_features(train)\nadd_additional_features(test)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def name_replace(s, r1, r2):\n    s = str(s).replace(r1,r2)\n    for r3 in r1.split(' '):\n        s = str(s).replace(r3,r2)\n    return s\n\ntrain['Text'] = train.apply(lambda r: name_replace(r['Text'], r['A'], 'subjectone'), axis=1)\ntrain['Text'] = train.apply(lambda r: name_replace(r['Text'], r['B'], 'subjecttwo'), axis=1)\n\ntest['Text'] = test.apply(lambda r: name_replace(r['Text'], r['A'], 'subjectone'), axis=1)\ntest['Text'] = test.apply(lambda r: name_replace(r['Text'], r['B'], 'subjecttwo'), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import spacy \nnlp = spacy.load('en_core_web_sm')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tags = {}\nfor text in train['Text']:\n    doc = nlp(str(text))\n    for token in doc:\n        if token.text == 'subjectone' or token.text == 'subjecttwo':\n            if token.dep_ in tags:\n                tags[token.dep_] += 1\n            else:\n                tags[token.dep_] = 1\n                \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Find top 5 the most often occurency tags"},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted_tags = sorted(tags.items(), key=lambda kv: kv[1])\nsorted_tags[-5:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fill_nlp_tag_empty_cols(df, tag):\n    df[f\"A-{tag}\"] = None\n    df[f\"B-{tag}\"] = None\n    \ndef fill_nlp_empty_cols(df, tags):\n    for tag in tags:\n        fill_nlp_tag_empty_cols(df, tag)\n\ndef fill_word_offset_empty_cols(df):\n    df['Pronoun-word-offset'] = None\n    df['A-word-offset'] = None\n    df['B-word-offset'] = None\n    df['A-word-dist'] = None\n    df['B-word-dist'] = None\n    \ndef fill_similarity(df):\n    df['sim_A_P'] = 0.0\n    df['sim_B_P'] = 0.0\n\n    \ndef get_nlp_tag_feature(doc, tag):\n    tokens = pd.DataFrame([[token.text, token.dep_] for token in doc], columns=['text', 'dep'])\n    A_tag = len(tokens[((tokens['text']=='subjectone') & (tokens['dep']==tag))])\n    B_tag = len(tokens[((tokens['text']=='subjecttwo') & (tokens['dep']==tag))])\n    \n    return A_tag, B_tag\n\ndef word_offset(doc, w):\n    count = 0\n    for token in doc:\n        if token.text == w:\n            break\n        if not token.is_punct and token.text != '`':\n            count += 1\n    return count\n\n\ndef add_nlp_features(df, tags):\n    size = len(df)\n    fill_nlp_empty_cols(df, tags)\n    fill_word_offset_empty_cols(df)\n    \n    for i in range(0, size):\n        text = df.loc[i, 'Text']\n        doc = nlp(str(text))\n        \n        #add tag features\n        for tag in tags:\n            df.loc[i, f\"A-{tag}\"], df.loc[i, f\"B-{tag}\"] = get_nlp_tag_feature(doc, tag)\n            \n        \n        #add word offset features\n        df.loc[i, 'Pronoun-word-offset'] = word_offset(doc, df.loc[i, 'Pronoun'])\n        df.loc[i, 'A-word-offset'] = word_offset(doc, 'subjectone')\n        df.loc[i, 'B-word-offset'] = word_offset(doc, 'subjecttwo')\n        \n        df.loc[i, 'A-word-dist'] = np.abs(df.loc[i, 'Pronoun-word-offset'] - df.loc[i, 'A-word-offset'])\n        df.loc[i, 'B-word-dist'] = np.abs(df.loc[i, 'Pronoun-word-offset'] - df.loc[i, 'B-word-offset'])\n        \n        #add similarity \n#         df.loc[i, 'sim_A_P'], df.loc[i, 'sim_B_P'] = get_similarity(doc, df.loc[i, 'Pronoun'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"add_nlp_features(train, ['poss', 'nsubj', 'pobj', 'dobj', 'conj'])\nadd_nlp_features(test, ['poss', 'nsubj', 'pobj', 'dobj', 'conj'])\ntrain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_col = [\n               'Pronoun-offset', \n               'Pronoun-offset2', \n               'A-offset', \n               'A-offset2', \n               'A-dist', \n               'B-offset', \n               'B-offset2',\n               'B-dist', \n               'section_min',  \n               'section_max',\n               'A-poss', \n               'B-poss', \n               'A-nsubj',\n               'B-nsubj',\n               'A-pobj',\n               'B-pobj',\n               'A-dobj',\n               'B-dobj',\n               'A-conj',\n               'B-conj',\n               'sim_A_P',\n               'sim_B_P',\n               'A-word-offset',\n               'B-word-offset',\n               'Pronoun-word-offset',\n               'A-word-dist',\n               'B-word-dist'\n              ]\npred_col = ['A-coref', 'B-coref', 'NEITHER']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train[feature_col].values\nY_train = train[pred_col].values\n\nX_test = test[feature_col].values\nY_test = test[pred_col].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# x_train, x_test, y_train, y_test = model_selection.train_test_split(train[feature_col].fillna(-1), train[pred_col], test_size=0.2, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = multiclass.OneVsRestClassifier(ensemble.RandomForestClassifier(max_depth = 7, n_estimators=2000, random_state=33))\nmodel.fit(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.predict_proba(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('log_loss: ', metrics.log_loss(Y_test, model.predict_proba(X_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# gap_development['A-coref'] = train['A-coref'].astype(int)\n# gap_development['B-coref'] = train['B-coref'].astype(int)\n# gap_development['NEITHER'] = 1.0 - (train['A-coref'] + train['B-coref'])\n# gap_development.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# add_additional_features(gap_development)\n# gap_development_x = gap_development[feature_col]\n# gap_development_y = gap_development[pred_col]\n# gap_development_pred = model.predict_proba(gap_development_x)\n# print('log_loss: ', metrics.log_loss(gap_development_y, gap_development_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# gap_development_y.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# gap_development_pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Submission test"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_sub1 = pd.read_csv('../input/gendered-pronoun-resolution/test_stage_1.tsv', delimiter='\\t')\ntest_sub1_bert = bert_embeddings(test_sub1)\nadd_similarity_columns(test_sub1, test_sub1_bert)\n\n#add necessary  features\nadd_additional_features(test_sub1)\n\ntest_sub1['Text'] = test_sub1.apply(lambda r: name_replace(r['Text'], r['A'], 'subjectone'), axis=1)\ntest_sub1['Text'] = test_sub1.apply(lambda r: name_replace(r['Text'], r['B'], 'subjecttwo'), axis=1)\n\nadd_nlp_features(test_sub2, ['poss', 'nsubj', 'pobj', 'dobj', 'conj'])\n\nresults = model.predict_proba(test_sub1[feature_col])\ntest_sub1.rename(columns={'A': 'A_Noun', 'B': 'B_Noun'})\ntest_sub1['A'] = results[:,0].astype(np.float)\ntest_sub1['B'] = results[:,1].astype(np.float)\ntest_sub1['NEITHER'] = results[:,2].astype(np.float)\ntest_sub1[['ID', 'A', 'B', 'NEITHER']].to_csv('submission1.csv', index=False)\ntest_sub1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_sub2 = pd.read_csv('../input/gendered-pronoun-resolution/test_stage_2.tsv', delimiter='\\t')\n# test_sub2_bert = bert_embeddings(test_sub2)\n# add_similarity_columns(test_sub2, test_sub2_bert)\n\n# #add necessary  features\n# add_additional_features(test_sub2)\n\n# test_sub2['Text'] = test_sub2.apply(lambda r: name_replace(r['Text'], r['A'], 'subjectone'), axis=1)\n# test_sub2['Text'] = test_sub2.apply(lambda r: name_replace(r['Text'], r['B'], 'subjecttwo'), axis=1)\n\n# add_nlp_features(test_sub2, ['poss', 'nsubj', 'pobj', 'dobj', 'conj'])\n\n# results = model.predict_proba(test_sub2[feature_col])\n# test_sub2.rename(columns={'A': 'A_Noun', 'B': 'B_Noun'})\n# test_sub2['A'] = results[:,0].astype(np.float)\n# test_sub2['B'] = results[:,1].astype(np.float)\n# test_sub2['NEITHER'] = results[:,2].astype(np.float)\n# test_sub2[['ID', 'A', 'B', 'NEITHER']].to_csv('submission2.csv', index=False)\n# test_sub2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_sub2","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}