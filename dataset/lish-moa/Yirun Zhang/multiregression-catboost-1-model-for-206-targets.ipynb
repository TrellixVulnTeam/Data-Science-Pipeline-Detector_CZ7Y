{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Multi-Regression CatBoost Test\n\nCatBoost has its own MultiRMSE loss that supports multi-regression tasks. In this notebook, I test its performance.\n\n**Update:** By changing the learning rate to 0.03 and iteration to 1000, CV becomes 0.0168, LB is 0.02016."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"id":"kw1VW6DCvgSq","outputId":"030d81e0-579d-463d-b2ed-6c714151a063"},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport sys\nsys.path.append('../input/iterative-stratification/iterative-stratification-master')\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n\nimport os\nimport gc\nimport datetime\nimport numpy as np\nimport pandas as pd\nfrom catboost import CatBoost, CatBoostClassifier, CatBoostRegressor, Pool\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import log_loss\nfrom tqdm.notebook import tqdm\nfrom time import time","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_folds(num_starts, num_splits):\n    \n    folds = []\n    \n    # LOAD FILES\n    train_feats = pd.read_csv('../input/lish-moa/train_features.csv')\n    scored = pd.read_csv('/kaggle/input/lish-moa/train_targets_scored.csv')\n    drug = pd.read_csv('/kaggle/input/lish-moa/train_drug.csv')\n    scored = scored.loc[train_feats['cp_type'] == 'trt_cp', :]\n    drug = drug.loc[train_feats['cp_type'] == 'trt_cp', :]\n    targets = scored.columns[1:]\n    scored = scored.merge(drug, on = 'sig_id', how = 'left') \n\n    # LOCATE DRUGS\n    vc = scored.drug_id.value_counts()\n    vc1 = vc.loc[vc <= 18].index.sort_values()\n    vc2 = vc.loc[vc > 18].index.sort_values()\n    \n    for seed in range(num_starts):\n\n        # STRATIFY DRUGS 18X OR LESS\n        dct1 = {}; dct2 = {}\n        skf = MultilabelStratifiedKFold(n_splits = num_splits, shuffle = True, random_state = seed)\n        tmp = scored.groupby('drug_id')[targets].mean().loc[vc1]\n        for fold,(idxT,idxV) in enumerate(skf.split(tmp,tmp[targets])):\n            dd = {k:fold for k in tmp.index[idxV].values}\n            dct1.update(dd)\n\n        # STRATIFY DRUGS MORE THAN 18X\n        skf = MultilabelStratifiedKFold(n_splits = num_splits, shuffle = True, random_state = seed)\n        tmp = scored.loc[scored.drug_id.isin(vc2)].reset_index(drop = True)\n        for fold,(idxT,idxV) in enumerate(skf.split(tmp,tmp[targets])):\n            dd = {k:fold for k in tmp.sig_id[idxV].values}\n            dct2.update(dd)\n\n        # ASSIGN FOLDS\n        scored['fold'] = scored.drug_id.map(dct1)\n        scored.loc[scored.fold.isna(),'fold'] =\\\n            scored.loc[scored.fold.isna(),'sig_id'].map(dct2)\n        scored.fold = scored.fold.astype('int8')\n        folds.append(scored.fold.values)\n        \n        del scored['fold']\n        \n    return np.stack(folds)","execution_count":null,"outputs":[]},{"metadata":{"id":"dSVuPpi2vgSv"},"cell_type":"markdown","source":"# Data Preparation"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"id":"UvG3N1HHvgSv"},"cell_type":"code","source":"train_features = pd.read_csv('../input/lish-moa/train_features.csv')\ntrain_targets = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\ntrain_targets_nonscored = pd.read_csv('../input/lish-moa/train_targets_nonscored.csv')\ntest_features = pd.read_csv('../input/lish-moa/test_features.csv')\n\nss = pd.read_csv('../input/lish-moa/sample_submission.csv')\nss_lr = ss.copy()\n\ncols = [c for c in ss.columns.values if c != 'sig_id']\nGENES = [col for col in train_features.columns if col.startswith('g-')]\nCELLS = [col for col in train_features.columns if col.startswith('c-')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"JItYfC6jvgSy"},"cell_type":"code","source":"def preprocess(df):\n    df.loc[:, 'cp_type'] = df.loc[:, 'cp_type'].map({'trt_cp': 0, 'ctl_vehicle': 1})\n#     df.loc[:, 'cp_time'] = df.loc[:, 'cp_time'].map({24: 0, 48: 0.5, 72: 1})\n    df.loc[:, 'cp_dose'] = df.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n    del df['sig_id']\n    return df\n\n# def log_loss_metric(y_true, y_pred):\n#     metrics = []\n#     for _target in train_targets.columns:\n#         metrics.append(log_loss(y_true.loc[:, _target], y_pred.loc[:, _target].astype(float), labels = [0,1]))\n#     return np.mean(metrics)\n\ndef log_loss_metric(y_true, y_pred):\n    loss = 0\n    y_pred_clip = np.clip(y_pred, 1e-15, 1 - 1e-15)\n    for i in range(y_true.shape[1]):\n        loss += - np.mean(y_true[:, i] * np.log(y_pred_clip[:, i]) + (1 - y_true[:, i]) * np.log(1 - y_pred_clip[:, i]))\n    return loss / y_true.shape[1]\n\ntrain = preprocess(train_features)\ntest = preprocess(test_features)\n\ndel train_targets['sig_id']\ndel train_targets_nonscored['sig_id']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"id":"Cg0gF9u5vgS1","outputId":"2dcd7162-6e0e-427c-cfc0-9e36329cd8a2"},"cell_type":"code","source":"from sklearn.preprocessing import QuantileTransformer\n\nqt = QuantileTransformer(output_distribution = 'normal', random_state = 42)\nqt.fit(pd.concat([pd.DataFrame(train[GENES+CELLS]), pd.DataFrame(test[GENES+CELLS])]))\ntrain[GENES+CELLS] = qt.transform(train[GENES+CELLS])\ntest[GENES+CELLS] = qt.transform(test[GENES+CELLS])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_targets = train_targets.loc[train['cp_type'] == 0].reset_index(drop = True)\ntrain_targets_nonscored = train_targets_nonscored.loc[train['cp_type'] == 0].reset_index(drop = True)\ntrain = train.loc[train['cp_type'] == 0].reset_index(drop = True)\n\nprint(train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_feats = np.arange(1, train.shape[1])\nprint(top_feats)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"N_STARTS = 1\nN_SPLITS = 5\nLBS = 0.0008\nfolds = create_folds(N_STARTS, N_SPLITS)\nprint(folds)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Multi-Regression CatBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {'learning_rate': 0.3, \n          'depth': 6, \n          'l2_leaf_reg': 3, \n          'loss_function': 'MultiRMSE', \n          'eval_metric': 'MultiRMSE', \n          'task_type': 'CPU', \n          'iterations': 150,\n          'od_type': 'Iter', \n          'boosting_type': 'Plain', \n          'bootstrap_type': 'Bernoulli', \n          'allow_const_label': True, \n         }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"qiCub3F5vgTA","outputId":"a409642d-80cd-4fdb-d21b-586422655f38"},"cell_type":"code","source":"res = train_targets.copy()\nss.loc[:, train_targets.columns] = 0\nres.loc[:, train_targets.columns] = 0\n\nfor nums, seed in enumerate(range(N_STARTS)):\n    \n#     for n, (tr, te) in enumerate(MultilabelStratifiedKFold(n_splits = N_SPILTS, random_state = 42, shuffle = True).split(train_targets, train_targets)):\n    for n, foldno in enumerate(set(folds[nums])):\n        start_time = time()\n        tr = folds[nums] != foldno\n        te = folds[nums] == foldno\n        \n        x_tr, x_val = train.values[tr][:, top_feats], train.values[te][:, top_feats]\n        y_tr, y_val = train_targets.astype(float).values[tr], train_targets.astype(float).values[te]\n        x_tt = test.values[:, top_feats]\n        \n        # Label Smoothing\n        y_tr = y_tr * (1 - LBS) + 0.5 * LBS\n        \n        cat_tr = Pool(x_tr, label = y_tr)\n        cat_val = Pool(x_val, label = y_val)\n        \n        params['random_state'] = seed\n        model = CatBoostRegressor(**params)\n        fit_model = model.fit(cat_tr, eval_set = cat_val, early_stopping_rounds = 5, \n                              use_best_model = True, verbose = 0)\n        \n        ss.loc[:, train_targets.columns] += fit_model.predict(x_tt) / (N_SPLITS * N_STARTS)\n        fold_pred = fit_model.predict(x_val)\n        res.loc[te, train_targets.columns] += fold_pred / N_STARTS\n        fold_score = log_loss_metric(train_targets.loc[te].values, fold_pred)\n        print(f'[{str(datetime.timedelta(seconds = time() - start_time))[0:7]}] CatBoost: Seed {seed}, Fold {n}:', fold_score)\n        \n        del model, fit_model\n        x = gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"dgIrzdQZvgTC","outputId":"a2ab66fb-1783-45aa-b1ef-6a6f719dce6a"},"cell_type":"code","source":"print(f'CatBoost OOF Metric: {log_loss_metric(train_targets.values, res.values)}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logistic Regression Stacked on Regressor\n\nhttps://www.kaggle.com/gogo827jz/rapids-svm-on-gpu-6000-models-in-1-hour"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_new = res[cols].values\nx_tt_new = ss[cols].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nres_lr = train_targets.copy()\nss_lr.loc[:, train_targets.columns] = 0\nres_lr.loc[:, train_targets.columns] = 0\n\nfor tar in tqdm(range(train_targets.shape[1])):\n    \n    start_time = time()\n    targets = train_targets.values[:, tar]\n    \n    if targets.sum() >= N_SPLITS:\n        \n        for seed in range(N_STARTS):\n\n            skf = StratifiedKFold(n_splits = N_SPLITS, random_state = 42, shuffle = True)\n\n            for n, (tr, te) in enumerate(skf.split(targets, targets)):\n\n                x_tr, x_val = X_new[tr, tar].reshape(-1, 1), X_new[te, tar].reshape(-1, 1)\n                y_tr, y_val = targets[tr], targets[te]\n                \n                model = LogisticRegression(random_state = seed)\n                model.fit(x_tr, y_tr)\n                ss_lr.loc[:, train_targets.columns[tar]] += model.predict_proba(x_tt_new[:, tar].reshape(-1, 1))[:, 1] / (N_SPLITS * N_STARTS)\n                res_lr.loc[te, train_targets.columns[tar]] += model.predict_proba(x_val)[:, 1] / N_STARTS\n    \n    score = log_loss(train_targets.loc[:, train_targets.columns[tar]].values, res_lr.loc[:, train_targets.columns[tar]].values)\n#     print(f'[{str(datetime.timedelta(seconds = time() - start_time))[2:7]}] LR Target {tar}:', score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'LR OOF Metric: {log_loss_metric(train_targets.values, res_lr.values)}')","execution_count":null,"outputs":[]},{"metadata":{"id":"4i2yuxNCvgTV"},"cell_type":"markdown","source":"# Submit"},{"metadata":{"trusted":true,"id":"fZG5AjqOvgTY"},"cell_type":"code","source":"ss.loc[test['cp_type'] == 1, train_targets.columns] = 0\nss.to_csv('submission_cat.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss_lr.loc[test['cp_type'] == 1, train_targets.columns] = 0\nss_lr.to_csv('submission.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}