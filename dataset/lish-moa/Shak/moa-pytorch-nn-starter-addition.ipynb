{"cells":[{"metadata":{"papermill":{"duration":0.009336,"end_time":"2020-09-08T12:57:04.72463","exception":false,"start_time":"2020-09-08T12:57:04.715294","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# About this notebook\n\nCredits to Y. Nakama [link](https://www.kaggle.com/yasufuminakama/moa-pytorch-nn-starter) for introducing pytorch method of tackling this project\n\nI've edited the codes by proposing a Maxout Layer to help with network performance. Maxout Layers performs well with dropouts."},{"metadata":{"papermill":{"duration":0.009429,"end_time":"2020-09-08T12:57:04.742529","exception":false,"start_time":"2020-09-08T12:57:04.7331","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Library"},{"metadata":{"execution":{"iopub.execute_input":"2020-09-08T12:57:04.763621Z","iopub.status.busy":"2020-09-08T12:57:04.762899Z","iopub.status.idle":"2020-09-08T12:57:05.839192Z","shell.execute_reply":"2020-09-08T12:57:05.838502Z"},"papermill":{"duration":1.089116,"end_time":"2020-09-08T12:57:05.839337","exception":false,"start_time":"2020-09-08T12:57:04.750221","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import sys\nsys.path.append('../input/iterative-stratification/iterative-stratification-master')\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2020-09-08T12:57:05.866212Z","iopub.status.busy":"2020-09-08T12:57:05.865356Z","iopub.status.idle":"2020-09-08T12:57:07.907745Z","shell.execute_reply":"2020-09-08T12:57:07.906648Z"},"papermill":{"duration":2.05941,"end_time":"2020-09-08T12:57:07.907888","exception":false,"start_time":"2020-09-08T12:57:05.848478","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import os\nimport gc\nimport random\nimport math\nimport time\n\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\nfrom sklearn.metrics import log_loss\n\nimport category_encoders as ce\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.optim as optim\nimport torch.nn.functional as F\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.007898,"end_time":"2020-09-08T12:57:07.924243","exception":false,"start_time":"2020-09-08T12:57:07.916345","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Utils"},{"metadata":{"execution":{"iopub.execute_input":"2020-09-08T12:57:07.950635Z","iopub.status.busy":"2020-09-08T12:57:07.949869Z","iopub.status.idle":"2020-09-08T12:57:07.956578Z","shell.execute_reply":"2020-09-08T12:57:07.956044Z"},"papermill":{"duration":0.024386,"end_time":"2020-09-08T12:57:07.95667","exception":false,"start_time":"2020-09-08T12:57:07.932284","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def get_logger(filename='log'):\n    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=f\"{filename}.log\")\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nlogger = get_logger()\n\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_everything(seed=42)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.007543,"end_time":"2020-09-08T12:57:07.97211","exception":false,"start_time":"2020-09-08T12:57:07.964567","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Data Loading"},{"metadata":{"execution":{"iopub.execute_input":"2020-09-08T12:57:07.991958Z","iopub.status.busy":"2020-09-08T12:57:07.991313Z","iopub.status.idle":"2020-09-08T12:57:07.998727Z","shell.execute_reply":"2020-09-08T12:57:07.999322Z"},"papermill":{"duration":0.019604,"end_time":"2020-09-08T12:57:07.999443","exception":false,"start_time":"2020-09-08T12:57:07.979839","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"os.listdir('../input/lish-moa')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.execute_input":"2020-09-08T12:57:08.02321Z","iopub.status.busy":"2020-09-08T12:57:08.022449Z","iopub.status.idle":"2020-09-08T12:57:14.470045Z","shell.execute_reply":"2020-09-08T12:57:14.468674Z"},"papermill":{"duration":6.462996,"end_time":"2020-09-08T12:57:14.470217","exception":false,"start_time":"2020-09-08T12:57:08.007221","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"train_features = pd.read_csv('../input/lish-moa/train_features.csv')\ntrain_targets_scored = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\ntrain_targets_nonscored = pd.read_csv('../input/lish-moa/train_targets_nonscored.csv')\ntest_features = pd.read_csv('../input/lish-moa/test_features.csv')\nsubmission = pd.read_csv('../input/lish-moa/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-09-08T12:57:14.498406Z","iopub.status.busy":"2020-09-08T12:57:14.496945Z","iopub.status.idle":"2020-09-08T12:57:14.738336Z","shell.execute_reply":"2020-09-08T12:57:14.738895Z"},"papermill":{"duration":0.25979,"end_time":"2020-09-08T12:57:14.739067","exception":false,"start_time":"2020-09-08T12:57:14.479277","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# ref: https://www.kaggle.com/c/lish-moa/discussion/180165\n# check if labels for 'ctl_vehicle' are all 0.\ntrain = train_features.merge(train_targets_scored, on='sig_id')\ntarget_cols = [c for c in train_targets_scored.columns if c not in ['sig_id']]\ncols = target_cols + ['cp_type']\ntrain[cols].groupby('cp_type').sum().sum(1)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.008869,"end_time":"2020-09-08T12:57:14.757104","exception":false,"start_time":"2020-09-08T12:57:14.748235","status":"completed"},"tags":[]},"cell_type":"markdown","source":"- labels for 'ctl_vehicle' are all 0."},{"metadata":{"execution":{"iopub.execute_input":"2020-09-08T12:57:14.787727Z","iopub.status.busy":"2020-09-08T12:57:14.786631Z","iopub.status.idle":"2020-09-08T12:57:14.952049Z","shell.execute_reply":"2020-09-08T12:57:14.952622Z"},"papermill":{"duration":0.186465,"end_time":"2020-09-08T12:57:14.952772","exception":false,"start_time":"2020-09-08T12:57:14.766307","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# constrcut train&test except 'cp_type'=='ctl_vehicle' data\nprint(train_features.shape, test_features.shape)\ntrain = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\ntest = test_features[test_features['cp_type']!='ctl_vehicle'].reset_index(drop=True)\nprint(train.shape, test.shape)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.008189,"end_time":"2020-09-08T12:57:14.969528","exception":false,"start_time":"2020-09-08T12:57:14.961339","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# CV split"},{"metadata":{"execution":{"iopub.execute_input":"2020-09-08T12:57:14.994644Z","iopub.status.busy":"2020-09-08T12:57:14.993335Z","iopub.status.idle":"2020-09-08T12:57:16.80217Z","shell.execute_reply":"2020-09-08T12:57:16.802679Z"},"papermill":{"duration":1.825036,"end_time":"2020-09-08T12:57:16.802829","exception":false,"start_time":"2020-09-08T12:57:14.977793","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"folds = train.copy()\nFold = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=42)\nfor n, (train_index, val_index) in enumerate(Fold.split(folds, folds[target_cols])):\n    folds.loc[val_index, 'fold'] = int(n)\nfolds['fold'] = folds['fold'].astype(int)\nprint(folds.shape)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.00827,"end_time":"2020-09-08T12:57:16.820283","exception":false,"start_time":"2020-09-08T12:57:16.812013","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Dataset"},{"metadata":{"execution":{"iopub.execute_input":"2020-09-08T12:57:16.852738Z","iopub.status.busy":"2020-09-08T12:57:16.850687Z","iopub.status.idle":"2020-09-08T12:57:16.853521Z","shell.execute_reply":"2020-09-08T12:57:16.854141Z"},"papermill":{"duration":0.025508,"end_time":"2020-09-08T12:57:16.854279","exception":false,"start_time":"2020-09-08T12:57:16.828771","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"class TrainDataset(Dataset):\n    def __init__(self, df, num_features, cat_features, labels):\n        self.cont_values = df[num_features].values\n        self.cate_values = df[cat_features].values\n        self.labels = labels\n        \n    def __len__(self):\n        return len(self.cont_values)\n\n    def __getitem__(self, idx):\n        cont_x = torch.FloatTensor(self.cont_values[idx])\n        cate_x = torch.LongTensor(self.cate_values[idx])\n        label = torch.tensor(self.labels[idx]).float()\n        \n        return cont_x, cate_x, label\n    \n\nclass TestDataset(Dataset):\n    def __init__(self, df, num_features, cat_features):\n        self.cont_values = df[num_features].values\n        self.cate_values = df[cat_features].values\n        \n    def __len__(self):\n        return len(self.cont_values)\n\n    def __getitem__(self, idx):\n        cont_x = torch.FloatTensor(self.cont_values[idx])\n        cate_x = torch.LongTensor(self.cate_values[idx])\n        \n        return cont_x, cate_x","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-09-08T12:57:17.086655Z","iopub.status.busy":"2020-09-08T12:57:17.085858Z","iopub.status.idle":"2020-09-08T12:57:17.099471Z","shell.execute_reply":"2020-09-08T12:57:17.098599Z"},"papermill":{"duration":0.236966,"end_time":"2020-09-08T12:57:17.099593","exception":false,"start_time":"2020-09-08T12:57:16.862627","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"cat_features = ['cp_time', 'cp_dose']\nnum_features = [c for c in train.columns if train.dtypes[c] != 'object']\nnum_features = [c for c in num_features if c not in cat_features]\nnum_features = [c for c in num_features if c not in target_cols]\ntarget = train[target_cols].values\n\ndef cate2num(df):\n    df['cp_time'] = df['cp_time'].map({24: 0, 48: 1, 72: 2})\n    df['cp_dose'] = df['cp_dose'].map({'D1': 3, 'D2': 4})\n    return df\n\ntrain = cate2num(train)\ntest = cate2num(test)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.008606,"end_time":"2020-09-08T12:57:17.117223","exception":false,"start_time":"2020-09-08T12:57:17.108617","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# MODEL"},{"metadata":{"execution":{"iopub.execute_input":"2020-09-08T12:57:17.139432Z","iopub.status.busy":"2020-09-08T12:57:17.138673Z","iopub.status.idle":"2020-09-08T12:57:17.142857Z","shell.execute_reply":"2020-09-08T12:57:17.14216Z"},"papermill":{"duration":0.017703,"end_time":"2020-09-08T12:57:17.142974","exception":false,"start_time":"2020-09-08T12:57:17.125271","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"class CFG:\n    max_grad_norm=1000\n    gradient_accumulation_steps=1\n    hidden_size=512\n    dropout=0.5\n    lr=1e-2\n    weight_decay=1e-6\n    batch_size=32\n    epochs=20\n    #total_cate_size=5\n    #emb_size=4\n    num_features=num_features\n    cat_features=cat_features\n    target_cols=target_cols","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-09-08T12:57:17.168578Z","iopub.status.busy":"2020-09-08T12:57:17.1668Z","iopub.status.idle":"2020-09-08T12:57:17.172465Z","shell.execute_reply":"2020-09-08T12:57:17.17199Z"},"papermill":{"duration":0.021233,"end_time":"2020-09-08T12:57:17.172556","exception":false,"start_time":"2020-09-08T12:57:17.151323","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"class TabularNN(nn.Module):\n    def __init__(self, cfg, num_units = 5):\n        super().__init__()\n        '''self.mlp = nn.Sequential(\n                          nn.Linear(len(cfg.num_features), cfg.hidden_size),\n                          nn.BatchNorm1d(cfg.hidden_size),\n                          nn.Dropout(cfg.dropout),\n                          nn.PReLU(),\n                          nn.Linear(cfg.hidden_size, cfg.hidden_size),\n                          nn.BatchNorm1d(cfg.hidden_size),\n                          nn.Dropout(cfg.dropout),\n                          nn.PReLU(),\n                          nn.Linear(cfg.hidden_size, len(cfg.target_cols)),\n                          )'''\n        self.mlp = nn.Sequential(\n                          nn.Linear(len(cfg.num_features), cfg.hidden_size),\n                          nn.BatchNorm1d(cfg.hidden_size),\n                          nn.Dropout(cfg.dropout),\n                          nn.PReLU(),\n                          nn.Linear(cfg.hidden_size, cfg.hidden_size),\n                          nn.BatchNorm1d(cfg.hidden_size),\n                          nn.Dropout(cfg.dropout),\n                          nn.PReLU())\n        self.fc1 = nn.ModuleList([nn.Linear(cfg.hidden_size,len(cfg.target_cols)) for i in range (num_units)])\n        \n    def maxout(self, x, layer_list):\n        max_output = layer_list[0](x)\n        for _, layer in enumerate(layer_list, start=1):\n            max_output = torch.max(max_output, layer(x))\n        return max_output\n    \n    def forward(self, cont_x, cate_x):\n        # no use of cate_x yet\n        x = self.mlp(cont_x)\n        x = self.maxout(x, self.fc1)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-09-08T12:57:17.216494Z","iopub.status.busy":"2020-09-08T12:57:17.202409Z","iopub.status.idle":"2020-09-08T12:57:17.218873Z","shell.execute_reply":"2020-09-08T12:57:17.218378Z"},"papermill":{"duration":0.038438,"end_time":"2020-09-08T12:57:17.218987","exception":false,"start_time":"2020-09-08T12:57:17.180549","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def train_fn(train_loader, model, optimizer, epoch, scheduler, device):\n    \n    losses = AverageMeter()\n\n    model.train()\n\n    for step, (cont_x, cate_x, y) in enumerate(train_loader):\n        \n        cont_x, cate_x, y = cont_x.to(device), cate_x.to(device), y.to(device)\n        batch_size = cont_x.size(0)\n\n        pred = model(cont_x, cate_x)\n        \n        loss = nn.BCEWithLogitsLoss()(pred, y)\n        losses.update(loss.item(), batch_size)\n\n        if CFG.gradient_accumulation_steps > 1:\n            loss = loss / CFG.gradient_accumulation_steps\n\n        loss.backward()\n        \n        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n\n        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n            scheduler.step()\n            optimizer.step()\n            optimizer.zero_grad()\n        \n    return losses.avg\n\n\ndef validate_fn(valid_loader, model, device):\n    \n    losses = AverageMeter()\n\n    model.eval()\n    val_preds = []\n\n    for step, (cont_x, cate_x, y) in enumerate(valid_loader):\n        \n        cont_x, cate_x, y = cont_x.to(device), cate_x.to(device), y.to(device)\n        batch_size = cont_x.size(0)\n\n        with torch.no_grad():\n            pred = model(cont_x, cate_x)\n            \n        loss = nn.BCEWithLogitsLoss()(pred, y)\n        losses.update(loss.item(), batch_size)\n\n        val_preds.append(pred.sigmoid().detach().cpu().numpy())\n\n        if CFG.gradient_accumulation_steps > 1:\n            loss = loss / CFG.gradient_accumulation_steps\n\n    val_preds = np.concatenate(val_preds)\n        \n    return losses.avg, val_preds\n\n\ndef inference_fn(test_loader, model, device):\n\n    model.eval()\n    preds = []\n\n    for step, (cont_x, cate_x) in enumerate(test_loader):\n\n        cont_x,  cate_x = cont_x.to(device), cate_x.to(device)\n\n        with torch.no_grad():\n            pred = model(cont_x, cate_x)\n\n        preds.append(pred.sigmoid().detach().cpu().numpy())\n\n    preds = np.concatenate(preds)\n\n    return preds\n\n\nclass AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-09-08T12:57:17.254161Z","iopub.status.busy":"2020-09-08T12:57:17.24384Z","iopub.status.idle":"2020-09-08T12:57:17.269689Z","shell.execute_reply":"2020-09-08T12:57:17.269148Z"},"papermill":{"duration":0.042442,"end_time":"2020-09-08T12:57:17.269792","exception":false,"start_time":"2020-09-08T12:57:17.22735","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def run_single_nn(cfg, train, test, folds, num_features, cat_features, target, device, fold_num=0, seed=42):\n    \n    # Set seed\n    logger.info(f'Set seed {seed}')\n    seed_everything(seed=seed)\n\n    # loader\n    trn_idx = folds[folds['fold'] != fold_num].index\n    val_idx = folds[folds['fold'] == fold_num].index\n    train_folds = train.loc[trn_idx].reset_index(drop=True)\n    valid_folds = train.loc[val_idx].reset_index(drop=True)\n    train_target = target[trn_idx]\n    valid_target = target[val_idx]\n    train_dataset = TrainDataset(train_folds, num_features, cat_features, train_target)\n    valid_dataset = TrainDataset(valid_folds, num_features, cat_features, valid_target)\n    train_loader = DataLoader(train_dataset, batch_size=cfg.batch_size, shuffle=True, \n                              num_workers=4, pin_memory=True, drop_last=True)\n    valid_loader = DataLoader(valid_dataset, batch_size=cfg.batch_size, shuffle=False, \n                              num_workers=4, pin_memory=True, drop_last=False)\n\n    # model\n    model = TabularNN(cfg)\n    model.to(device)\n    optimizer = optim.Adam(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n    scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n                                              max_lr=1e-2, epochs=cfg.epochs, steps_per_epoch=len(train_loader))\n\n    # log\n    log_df = pd.DataFrame(columns=(['EPOCH']+['TRAIN_LOSS']+['VALID_LOSS']) )\n\n    # train & validate\n    best_loss = np.inf\n    for epoch in range(cfg.epochs):\n        train_loss = train_fn(train_loader, model, optimizer, epoch, scheduler, device)\n        valid_loss, val_preds = validate_fn(valid_loader, model, device)\n        log_row = {'EPOCH': epoch, \n                   'TRAIN_LOSS': train_loss,\n                   'VALID_LOSS': valid_loss,\n                  }\n        log_df = log_df.append(pd.DataFrame(log_row, index=[0]), sort=False)\n        #logger.info(log_df.tail(1))\n        if valid_loss < best_loss:\n            logger.info(f'epoch{epoch} save best model... {valid_loss}')\n            best_loss = valid_loss\n            oof = np.zeros((len(train), len(cfg.target_cols)))\n            oof[val_idx] = val_preds\n            torch.save(model.state_dict(), f\"fold{fold_num}_seed{seed}.pth\")\n\n    # predictions\n    test_dataset = TestDataset(test, num_features, cat_features)\n    test_loader = DataLoader(test_dataset, batch_size=cfg.batch_size, shuffle=False, \n                             num_workers=4, pin_memory=True)\n    model = TabularNN(cfg)\n    model.load_state_dict(torch.load(f\"fold{fold_num}_seed{seed}.pth\"))\n    model.to(device)\n    predictions = inference_fn(test_loader, model, device)\n    \n    # del\n    torch.cuda.empty_cache()\n\n    return oof, predictions\n\n\ndef run_kfold_nn(cfg, train, test, folds, num_features, cat_features, target, device, n_fold=5, seed=42):\n\n    oof = np.zeros((len(train), len(cfg.target_cols)))\n    predictions = np.zeros((len(test), len(cfg.target_cols)))\n\n    for _fold in range(n_fold):\n        logger.info(\"Fold {}\".format(_fold))\n        _oof, _predictions = run_single_nn(cfg,\n                                           train,\n                                           test,\n                                           folds,\n                                           num_features, \n                                           cat_features,\n                                           target, \n                                           device,\n                                           fold_num=_fold,\n                                           seed=seed)\n        oof += _oof\n        predictions += _predictions / n_fold\n\n    score = 0\n    for i in range(target.shape[1]):\n        _score = log_loss(target[:,i], oof[:,i])\n        score += _score / target.shape[1]\n    logger.info(f\"CV score: {score}\")\n    \n    return oof, predictions","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-09-08T12:57:17.29669Z","iopub.status.busy":"2020-09-08T12:57:17.294235Z","iopub.status.idle":"2020-09-08T13:24:02.26513Z","shell.execute_reply":"2020-09-08T13:24:02.265708Z"},"papermill":{"duration":1604.987499,"end_time":"2020-09-08T13:24:02.26588","exception":false,"start_time":"2020-09-08T12:57:17.278381","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Seed Averaging for solid result\noof = np.zeros((len(train), len(CFG.target_cols)))\npredictions = np.zeros((len(test), len(CFG.target_cols)))\n\nSEED = [0, 1, 2]\nfor seed in SEED:\n    _oof, _predictions = run_kfold_nn(CFG, \n                                      train, test, folds, \n                                      num_features, cat_features, target,\n                                      device,\n                                      n_fold=5, seed=seed)\n    oof += _oof / len(SEED)\n    predictions += _predictions / len(SEED)\n\nscore = 0\nfor i in range(target.shape[1]):\n    _score = log_loss(target[:,i], oof[:,i])\n    score += _score / target.shape[1]\nlogger.info(f\"Seed Averaged CV score: {score}\")","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-09-08T13:24:02.542845Z","iopub.status.busy":"2020-09-08T13:24:02.541378Z","iopub.status.idle":"2020-09-08T13:24:18.417982Z","shell.execute_reply":"2020-09-08T13:24:18.416822Z"},"papermill":{"duration":16.1285,"end_time":"2020-09-08T13:24:18.418159","exception":false,"start_time":"2020-09-08T13:24:02.289659","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"train[target_cols] = oof\ntrain[['sig_id']+target_cols].to_csv('oof.csv', index=False)\n\ntest[target_cols] = predictions\ntest[['sig_id']+target_cols].to_csv('pred.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-09-08T13:24:18.481088Z","iopub.status.busy":"2020-09-08T13:24:18.479685Z","iopub.status.idle":"2020-09-08T13:24:19.451698Z","shell.execute_reply":"2020-09-08T13:24:19.451031Z"},"papermill":{"duration":1.011637,"end_time":"2020-09-08T13:24:19.451836","exception":false,"start_time":"2020-09-08T13:24:18.440199","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Final result with 'cp_type'=='ctl_vehicle' data\nresult = train_targets_scored.drop(columns=target_cols)\\\n            .merge(train[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\ny_true = train_targets_scored[target_cols].values\ny_pred = result[target_cols].values\nscore = 0\nfor i in range(y_true.shape[1]):\n    _score = log_loss(y_true[:,i], y_pred[:,i])\n    score += _score / y_true.shape[1]\nlogger.info(f\"Final result: {score}\")","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.022164,"end_time":"2020-09-08T13:24:19.495744","exception":false,"start_time":"2020-09-08T13:24:19.47358","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Submit"},{"metadata":{"execution":{"iopub.execute_input":"2020-09-08T13:24:19.549646Z","iopub.status.busy":"2020-09-08T13:24:19.548254Z","iopub.status.idle":"2020-09-08T13:24:21.363279Z","shell.execute_reply":"2020-09-08T13:24:21.363848Z"},"papermill":{"duration":1.845969,"end_time":"2020-09-08T13:24:21.364013","exception":false,"start_time":"2020-09-08T13:24:19.518044","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"sub = submission.drop(columns=target_cols).merge(test[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\nsub.to_csv('submission.csv', index=False)\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}