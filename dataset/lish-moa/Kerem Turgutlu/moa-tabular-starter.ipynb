{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\n# INSTALL RAPIDS\n!cp ../input/rapids/rapids.0.16.0 /opt/conda/envs/rapids.tar.gz\n!cd /opt/conda/envs/ && tar -xzvf rapids.tar.gz > /dev/null\nsys.path = [\"/opt/conda/envs/rapids/lib/python3.7/site-packages\"] + sys.path\nsys.path = [\"/opt/conda/envs/rapids/lib/python3.7\"] + sys.path\nsys.path = [\"/opt/conda/envs/rapids/lib\"] + sys.path \n!cp /opt/conda/envs/rapids/lib/libxgboost.so /opt/conda/lib/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install -q /kaggle/input/iterative-stratification/iterative-stratification-master/","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from fastai.basics import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datapath = Path(\"/kaggle/input/lish-moa\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datapath.ls().map(lambda o: o.name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_df = pd.read_csv(datapath/'train_features.csv')\ntest_features_df = pd.read_csv(datapath/'test_features.csv')\ntrain_targets_scored_df = pd.read_csv(datapath/'train_targets_scored.csv')\ntrain_targets_nonscored_df = pd.read_csv(datapath/'train_targets_nonscored.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_df.shape, test_features_df.shape, train_targets_scored_df.shape, train_targets_nonscored_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nonscored_cols = list(train_targets_nonscored_df.columns[1:])\nscored_cols = list(train_targets_scored_df.columns[1:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(nonscored_cols), len(scored_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert set(nonscored_cols).intersection(scored_cols) == set()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_features_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_targets_scored_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_targets_scored_df.iloc[1:].mean().hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_target_distrib = dict(train_targets_scored_df.iloc[:,1:].sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_target_distrib;","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"[(k,train_target_distrib[k]) for k in train_target_distrib if train_target_distrib[k] == 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_train, n_test = train_features_df.shape[0], test_features_df.shape[0]\ntrain_test_features_df = pd.concat([train_features_df, test_features_df]).reset_index(drop=True)\ng_cols = list(o for o in train_test_features_df.columns if o.startswith(\"g-\"))\nc_cols = list(o for o in train_test_features_df.columns if o.startswith(\"c-\"))\ngc_cols = g_cols + c_cols\n\nlen(g_cols), len(c_cols), len(gc_cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Distributions"},{"metadata":{"trusted":true},"cell_type":"code","source":"from seaborn import distplot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_dist():\n    fig, axes = plt.subplots(2, 5, figsize=(15,6))\n    axes = axes.flatten()\n    for c, ax in zip(list(np.random.choice(c_cols, 5))+list(np.random.choice(g_cols,5)), axes): distplot(train_test_features_df[c], ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_dist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Config\n\nUseful for hyperparameter search"},{"metadata":{"trusted":true},"cell_type":"code","source":"ParamConfig = SimpleNamespace(\n    do_rank_gauss = True,\n    \n    do_quantile_tfms = False,\n    n_quantiles = 100,\n    \n    do_pca = False,\n    pca_reduction_factor = 3,\n\n    do_umap = False,\n    umap_reduction_factor = 3,\n    umap_n_neighbors = 150,\n    \n    do_knn_encoding = True,\n    knn_k = 100,\n    \n    do_transfer_learning = False,\n    tl_n_epochs = 30,\n    tl_smoothing = 0.001,\n    tl_lr = 0.001,\n    \n    ft_n_epochs = 30,\n    ft_smoothing = 0.001,\n    ft_lr = 0.001,\n    \n    model_n_layers = 2,\n    model_layer_width = 512,\n    model_ps = 0.25\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### RankGauss"},{"metadata":{"trusted":true},"cell_type":"code","source":"import cupy as cp\nfrom cupyx.scipy.special import erfinv\nimport cudf as gd\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom scipy.special import erfinv as sp_erfinv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def to_rankgauss(x):\n    \"https://medium.com/rapids-ai/gauss-rank-transformation-is-100x-faster-with-rapids-and-cupy-7c947e3397da\"\n    x_cpu = x\n    r_cpu = x_cpu.argsort().argsort() \n    epsilon = 1e-6\n    r_cpu = (r_cpu/r_cpu.max()-0.5)*2 # scale to (-1,1)\n    r_cpu = cp.clip(r_cpu,-1+epsilon,1-epsilon)\n    r_cpu = sp_erfinv(r_cpu) # map to gaussian\n    return r_cpu","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if ParamConfig.do_rank_gauss: \n    for col in gc_cols: \n        train_test_features_df[col] = to_rankgauss(train_test_features_df[col])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### QuantileTransform"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import QuantileTransformer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if ParamConfig.do_quantile_tfms:\n    transformer = QuantileTransformer(n_quantiles=ParamConfig.n_quantiles, random_state=0, output_distribution=\"normal\")\n    train_test_features_df[gc_cols] = transformer.fit_transform(train_test_features_df[gc_cols])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plot Dist"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_dist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(g_cols), len(c_cols), len(gc_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_test_features_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_test_features_df.groupby(['cp_type', 'cp_time', 'cp_dose'])[['sig_id']].count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train_test_features_df['sig_id'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ctl_vehicle have no MoA hence all 0 target labels\nall(train_test_features_df.merge(train_targets_scored_df, on='sig_id').query(\"cp_type == 'ctl_vehicle'\")[scored_cols].sum()==0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ctl_vehicle have no MoA hence all 0 target labels\nall(train_test_features_df.merge(train_targets_nonscored_df, on='sig_id').query(\"cp_type == 'ctl_vehicle'\")[nonscored_cols].sum()==0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_features_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### PCA"},{"metadata":{"trusted":true},"cell_type":"code","source":"from cuml.decomposition import PCA as cumlPCA","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nif ParamConfig.do_pca:\n    # add pca features\n    pca_feats = []\n    colnames = []\n    for name, cols in [(\"gene\", g_cols), (\"cell\", c_cols)]:\n        n_comp = int(len(cols)/ParamConfig.pca_reduction_factor)\n        pca = cumlPCA(n_components=n_comp, iterated_power=500)\n        pca_feat = pca.fit_transform(train_test_features_df[cols])\n        pca_feats += [pca_feat]\n        colnames += [f\"pca_{name}_{i}\" for i in range(n_comp)]\n        \n    pca_feats = np.hstack(pca_feats)\n    train_test_features_df[colnames] = pca_feats","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_test_features_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### UMAP"},{"metadata":{"trusted":true},"cell_type":"code","source":"from cuml.manifold import UMAP as cumlUMAP","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# add umap features\nif ParamConfig.do_umap:\n    umap_feats = []\n    colnames = []\n    for name, cols in [(\"gene\", g_cols), (\"cell\", c_cols)]:\n        n_comp = int(len(cols)/ParamConfig.umap_reduction_factor)\n        umap = cumlUMAP(n_components=n_comp, n_neighbors=ParamConfig.umap_n_neighbors)\n        umap_feat = umap.fit_transform(train_test_features_df[cols])\n        umap_feats += [umap_feat]\n        colnames += [f\"umap_{name}_{i}\" for i in range(n_comp)]\n\n    umap_feats = np.hstack(umap_feats)\n    train_test_features_df[colnames] = umap_feats","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_test_features_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### One-hot Encode"},{"metadata":{"trusted":true},"cell_type":"code","source":"for ohe_col in ['cp_type', 'cp_time', 'cp_dose']:\n    vals = train_test_features_df[ohe_col].unique()\n    if len(vals) == 2:\n        col = ohe_col+\"s\"\n        cat2code = {v:k for k,v in enumerate(vals)}\n        train_test_features_df[col] = train_test_features_df[ohe_col].map(cat2code)\n\n    else:\n        cat2code = {v:k for k,v in enumerate(vals)}\n        encoded = train_test_features_df[ohe_col].map(cat2code)\n        ohe_arr = np.zeros((len(vals), len(vals)))\n        ohe_arr[np.diag_indices_from(ohe_arr)] = 1\n        col = [f\"{ohe_col}s_{o}\" for o in vals]   \n        train_test_features_df[col] = ohe_arr[encoded]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_test_features_df = train_test_features_df.drop(\"cp_types\", 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_test_features_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### KNN Non-Scored Target Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"from cuml.neighbors import KNeighborsRegressor as cumlKNN","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if ParamConfig.do_knn_encoding:\n    knn = cumlKNN(n_neighbors=ParamConfig.knn_k)\n    merged_nonscored_train_test_df = train_test_features_df.merge(train_targets_nonscored_df, on='sig_id', how='left')\n    unique_cp_time, unique_cp_dose = merged_nonscored_train_test_df['cp_time'].unique(), merged_nonscored_train_test_df['cp_dose'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if ParamConfig.do_knn_encoding:\n    # create pairwise groups\n    knn_groups = []\n    for i in unique_cp_time:\n        for j in unique_cp_dose: knn_groups.append((i,j))\n\n    # initialize knn feature cols\n    knn_cols = [f\"knn{ParamConfig.knn_k}_{i}\" for i in range(len(nonscored_cols))]\n    for c in knn_cols: train_test_features_df[c] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if ParamConfig.do_knn_encoding:\n    \n    for time, dose in knn_groups:\n\n        # filter data by time and dose group\n        X = merged_nonscored_train_test_df.query(f\"cp_time == '{time}' & cp_dose == '{dose}'\")[gc_cols]\n        y = merged_nonscored_train_test_df.query(f\"cp_time == '{time}' & cp_dose == '{dose}'\")[nonscored_cols]\n\n        # find corresponding indexes from dataframe\n        idxs = array(list(X.index))\n        train_idxs = idxs[np.where((y.isna().sum(1) == 0))[0]]\n        test_idxs = idxs[np.where((y.isna().sum(1) != 0))[0]]\n\n        # fit KNN\n        X_train, y_train, X_test, y_test = X.loc[train_idxs], y.loc[train_idxs], X.loc[test_idxs], y.loc[test_idxs]\n        knn.fit(X_train, y_train)\n\n        # predict and put encoded features\n        train_preds, test_preds = knn.predict(X_train), knn.predict(X_test)\n        train_test_features_df.loc[train_idxs, knn_cols] = train_preds\n        train_test_features_df.loc[test_idxs, knn_cols] = test_preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_test_features_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### New train, test "},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_df = train_test_features_df[:n_train].reset_index(drop=True)\ntest_features_df = train_test_features_df[n_train:].reset_index(drop=True)\nassert np.sum(train_features_df.isna()).sum() == 0\nassert np.sum(test_features_df.isna()).sum() == 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_df.shape, test_features_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_features_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loss/Metric/Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai.tabular.all import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loss\n@log_args\nclass LabelSmoothingBCEWithLogits(Module):\n    y_int = True\n    def __init__(self, eps:float=0.1): store_attr('eps')\n\n    def forward(self, output, target):\n        target = target + self.eps*(1-2*target)\n        return F.binary_cross_entropy_with_logits(output, target)\n\n    def decodes(self, x):    return x>self.thresh\n    def activation(self, x): return torch.sigmoid(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Metric\ndef clipped_bce(inp, targ): return F.binary_cross_entropy(torch.clamp(inp.sigmoid(),1e-15, 1-1e-15), targ.float())\nmetric = AvgMetric(clipped_bce)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Pretrained Model (Non-Scored)"},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_names = []\ncont_names = L(list(train_features_df.columns[4:]))\ny_names = nonscored_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged_nonscored_train_df = train_features_df.merge(train_targets_nonscored_df, on='sig_id', how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logspath = Path(\"logs\")\nif not logspath.exists(): logspath.mkdir()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop control perturbation\nctl_sig_ids = merged_nonscored_train_df.query(\"cp_type=='ctl_vehicle'\")['sig_id'].values\ntrn_df = merged_nonscored_train_df[~merged_nonscored_train_df['sig_id'].isin(ctl_sig_ids)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trn_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trn_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"procs = []\ndls = TabularDataLoaders.from_df(merged_nonscored_train_df,\n                                 procs=procs,\n                                 cat_names=cat_names, \n                                 cont_names=cont_names, \n                                 y_names=y_names,\n                                 valid_idx=[], # use all data\n                                 bs=128)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tl_learner = tabular_learner(dls,\n                             layers=ParamConfig.model_n_layers*[ParamConfig.model_layer_width],\n                             config = {\"ps\": ParamConfig.model_n_layers*[ParamConfig.model_ps]},\n                             n_out=len(nonscored_cols), \n                             loss_func=LabelSmoothingBCEWithLogits(ParamConfig.tl_smoothing),\n                             metrics=[metric])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tl_learner.model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if ParamConfig.do_transfer_learning: tl_learner.fit_flat_cos(ParamConfig.tl_n_epochs, lr=ParamConfig.tl_lr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if ParamConfig.do_transfer_learning:  tl_learner.save(\"pretrained_tabular\", with_opt=False);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Scored Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from iterstrat.ml_stratifiers import MultilabelStratifiedKFold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged_scored_train_df = train_features_df.merge(train_targets_scored_df, on='sig_id', how='left')\n# drop control perturbation\nctl_sig_ids = merged_scored_train_df.query(\"cp_type=='ctl_vehicle'\")['sig_id'].values\ntrn_df = merged_scored_train_df[~merged_scored_train_df['sig_id'].isin(ctl_sig_ids)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_names = scored_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"N_FOLDS = 10\nmskf = MultilabelStratifiedKFold(n_splits=N_FOLDS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sig_ids = trn_df['sig_id'].values\ncv_idxs = list(mskf.split(sig_ids, y=trn_df[y_names]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cvpath = Path(\"cv_sig_ids\")\nif not cvpath.exists(): cvpath.mkdir()\nfor i, idxs in enumerate(cv_idxs): pd.to_pickle(sig_ids[idxs[1]], cvpath/f'sig_ids_fold{i}.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged_scored_train_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Scored Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"if ParamConfig.do_transfer_learning: pretrained_statedict = torch.load(\"models/pretrained_tabular.pth\", map_location=default_device())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_top_layers(learner, pretrained_statedict):\n    i = 0\n    for n, p in learner.model.named_parameters():\n        try:\n            p.data.copy_(pretrained_statedict[n])\n            print(f\"Loaded {n}\")\n            i += 1\n        except:\n            continue\n    \n    if i == 0: \n        print(\"No parameter is loaded\")\n        if ParamConfig.do_transfer_learning: raise Exception(\"Transfer learning is set True but no parameter loaded!\")\n    else: \n        print(f\"Total of loaded params: {i}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for FOLD in range(N_FOLDS):\n    valid_sig_ids = pd.read_pickle(cvpath/f'sig_ids_fold{FOLD}.pkl')\n    valid_idxs = np.where(trn_df.sig_id.isin(valid_sig_ids))[0]\n    procs = []\n    dls = TabularDataLoaders.from_df(trn_df,\n                                     procs=procs,\n                                     cat_names=cat_names, \n                                     cont_names=cont_names,\n                                     y_names=y_names,\n                                     valid_idx=valid_idxs,\n                                     bs=128)\n    learner = tabular_learner(dls,\n                              layers=ParamConfig.model_n_layers*[ParamConfig.model_layer_width],\n                              config = {\"ps\": ParamConfig.model_n_layers*[ParamConfig.model_ps]},\n                              n_out=len(scored_cols), \n                              loss_func=LabelSmoothingBCEWithLogits(ParamConfig.ft_smoothing),\n                              metrics=[metric])\n    \n    if ParamConfig.do_transfer_learning: load_top_layers(learner, pretrained_statedict)\n    \n    learner.fit_flat_cos(ParamConfig.ft_n_epochs,\n                         lr=ParamConfig.ft_lr,\n                         cbs=[SaveModelCallback(monitor='clipped_bce', \n                                                fname=f'tabular_fold{FOLD}',\n                                                comp=np.less),\n                              EarlyStoppingCallback(monitor='clipped_bce', \n                                                    patience=5,\n                                                    comp=np.less),\n                              CSVLogger(fname=f\"logs/tabular_logs_fold{FOLD}.csv\")])\n    \n    learner.export(f'models/tabular_fold{FOLD}_export.pkl')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"fold_metrics = [pd.read_csv(logspath/f'tabular_logs_fold{FOLD}.csv')['clipped_bce'].min() for FOLD in range(10)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.mean(fold_metrics), np.std(fold_metrics)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Inference"},{"metadata":{"trusted":true},"cell_type":"code","source":"modelspath = Path(\"models\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fold_preds = []\nfor i in range(10):\n    learner = load_learner(modelspath/f'tabular_fold{i}_export.pkl')\n    test_dl = learner.dls.test_dl(test_features_df)\n    preds, _ = learner.get_preds(dl=test_dl)\n    fold_preds += [preds]\npreds = torch.stack(fold_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_preds = preds.mean(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df = pd.DataFrame(mean_preds, columns=test_dl.y_names)\nsub_df['sig_id'] = test_dl.items['sig_id']\nsub_df = sub_df[['sig_id']+test_dl.y_names]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ctl_sig_ids = test_features_df.query(\"cp_type == 'ctl_vehicle'\")['sig_id'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df.loc[sub_df.sig_id.isin(ctl_sig_ids), test_dl.y_names] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}