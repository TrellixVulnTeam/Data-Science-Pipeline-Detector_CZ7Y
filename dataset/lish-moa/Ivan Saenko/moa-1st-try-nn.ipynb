{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import StratifiedKFold, KFold\nfrom sklearn.metrics import log_loss\nfrom tqdm.notebook import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nimport sys\nsys.path.append('../input/iterative-stratification/iterative-stratification-master')\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n#used net arch from kaggle.com/nicohrubec/pytorch-multilabel-neural-network/","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"X_train = pd.read_csv('../input/lish-moa/train_features.csv')\ny_train = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\nX_test = pd.read_csv('../input/lish-moa/test_features.csv')\n\nsubmit = pd.read_csv('../input/lish-moa/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(df):\n    df = df.copy()\n    df.loc[:, 'cp_type'] = df.loc[:, 'cp_type'].map({'trt_cp': 0, 'ctl_vehicle': 1})\n    df.loc[:, 'cp_dose'] = df.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n    del df['sig_id']\n    return df\n\ntrain = preprocess(X_train)\ntest = preprocess(X_test)\n\ndel y_train['sig_id']\n\ny_train = y_train.loc[train['cp_type']==0].reset_index(drop=True)\ntrain = train.loc[train['cp_type']==0].reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nfolds = 7\nnstarts = 1\nnepochs = 50\nbatch_size = 128\nval_batch_size = batch_size * 4\nntargets = y_train.shape[1]\ntargets = [col for col in y_train.columns]\ncriterion = nn.BCELoss()\nkfold = MultilabelStratifiedKFold(n_splits=nfolds, random_state=517, shuffle=True)\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ntrain = train.values\ntest = test.values\ny_train = y_train.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self, num_columns):\n        super(Model, self).__init__()\n        self.batch_norm1 = nn.BatchNorm1d(num_columns)\n        self.dropout1 = nn.Dropout(0.2)\n        self.dense1 = nn.utils.weight_norm(nn.Linear(num_columns, 2048))\n        \n        self.batch_norm2 = nn.BatchNorm1d(2048)\n        self.dropout2 = nn.Dropout(0.5)\n        self.dense2 = nn.utils.weight_norm(nn.Linear(2048, 1024))\n        \n        self.batch_norm3 = nn.BatchNorm1d(1024)\n        self.dropout3 = nn.Dropout(0.5)\n        self.dense3 = nn.utils.weight_norm(nn.Linear(1024, 206))\n    \n    def forward(self, x):\n        x = self.batch_norm1(x)\n        x = self.dropout1(x)\n        x = F.relu(self.dense1(x))\n        \n        x = self.batch_norm2(x)\n        x = self.dropout2(x)\n        x = F.relu(self.dense2(x))\n        \n        x = self.batch_norm3(x)\n        x = self.dropout3(x)\n        x = F.sigmoid(self.dense3(x))\n        \n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Dataset(Dataset):\n    def __init__(self, df, targets, mode='train'):\n        self.mode = mode\n        #self.feats = feats_idx\n        #self.data = df[:, feats_idx]\n        self.data = df\n        if mode=='train':\n            self.targets = targets\n    \n    def __getitem__(self, idx):\n        if self.mode == 'train':\n            return torch.FloatTensor(self.data[idx]), torch.FloatTensor(self.targets[idx])\n        elif self.mode == 'test':\n            return torch.FloatTensor(self.data[idx]), 0\n        \n    def __len__(self):\n        return len(self.data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for n, (tr, te) in enumerate(kfold.split(y_train, y_train)):\n    print(f'Train fold {n+1}')\n    xtrain, xval = train[tr], train[te]\n    ytrain, yval = y_train[tr], y_train[te]\n\n    train_set = Dataset(xtrain, ytrain)\n    val_set = Dataset(xval, yval)\n\n    dataloaders = {\n        'train': DataLoader(train_set, batch_size=batch_size, shuffle=True),\n        'val': DataLoader(val_set, batch_size=val_batch_size, shuffle=False)\n    }\n\n    model = Model(X_train.shape[1]-1).to(device)\n    checkpoint_path = f'repeat:{1}_Fold:{n+1}.pt'\n    optimizer = optim.Adam(model.parameters(), weight_decay=1e-5)\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, eps=1e-4, verbose=True)\n    best_loss = {'train': np.inf, 'val': np.inf}\n\n    for epoch in range(nepochs):\n        epoch_loss = {'train': 0.0, 'val': 0.0}\n\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()\n            else:\n                model.eval()\n\n            running_loss = 0.0\n\n            for i, (x, y) in enumerate(dataloaders[phase]):\n                x, y = x.to(device), y.to(device)\n\n                optimizer.zero_grad()\n\n                with torch.set_grad_enabled(phase=='train'):\n                    preds = model(x)\n                    loss = criterion(preds, y)\n\n                    if phase=='train':\n                        loss.backward()\n                        optimizer.step()\n\n                running_loss += loss.item() / len(dataloaders[phase])\n\n            epoch_loss[phase] = running_loss\n\n        print(\"Epoch {}/{}   -   loss: {:5.5f}   -   val_loss: {:5.5f}\".format(epoch+1, nepochs, epoch_loss['train'], epoch_loss['val']))\n\n        scheduler.step(epoch_loss['val'])\n\n        if epoch_loss['val'] < best_loss['val']:\n            best_loss = epoch_loss\n            torch.save(model.state_dict(), checkpoint_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oof = np.zeros((len(train), nstarts, ntargets))\noof_targets = np.zeros((len(train), ntargets))\npreds = np.zeros((len(test), ntargets))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mean_log_loss(y_true, y_pred):\n    metrics = []\n    for i, target in enumerate(targets):\n        metrics.append(log_loss(y_true[:, i], y_pred[:, i].astype(float), labels=[0,1]))\n    return np.mean(metrics)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seed_targets = []\nseed_oof = []\nseed_preds = np.zeros((len(test), ntargets, nfolds))\n\nfor n, (tr, te) in enumerate(kfold.split(y_train, y_train)):\n    xval, yval = train[te], y_train[te]\n    fold_preds = []\n\n    val_set = Dataset(xval, yval)\n    test_set = Dataset(test, None, mode='test')\n\n    dataloaders = {\n        'val': DataLoader(val_set, batch_size=val_batch_size, shuffle=False),\n        'test': DataLoader(test_set, batch_size=val_batch_size, shuffle=False)\n    }\n\n    checkpoint_path = f'repeat:{1}_Fold:{n+1}.pt'\n    model = Model(X_train.shape[1]-1).to(device)\n    model.load_state_dict(torch.load(checkpoint_path))\n    model.eval()\n\n    for phase in ['val', 'test']:\n        for i, (x, y) in enumerate(dataloaders[phase]):\n            if phase == 'val':\n                x, y = x.to(device), y.to(device)\n            elif phase == 'test':\n                x = x.to(device)\n\n            with torch.no_grad():\n                batch_preds = model(x)\n\n                if phase == 'val':\n                    seed_targets.append(y)\n                    seed_oof.append(batch_preds)\n                elif phase == 'test':\n                    fold_preds.append(batch_preds)\n\n    fold_preds = torch.cat(fold_preds, dim=0).cpu().numpy()\n    seed_preds[:, :, n] = fold_preds\n\nseed_targets = torch.cat(seed_targets, dim=0).cpu().numpy()\nseed_oof = torch.cat(seed_oof, dim=0).cpu().numpy()\nseed_preds = np.mean(seed_preds, axis=2)\n\noof_targets = seed_targets\noof[:, 0, :] = seed_oof\npreds += seed_preds / nstarts\n\noof = np.mean(oof, axis=1)\nprint(\"Overall score is {:5.5f}\".format(mean_log_loss(oof_targets, oof)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit[targets] = preds\nsubmit.loc[X_test['cp_type']=='ctl_vehicle', targets] = 0\nsubmit.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}