{"cells":[{"metadata":{"_uuid":"22fd04ed-deed-4319-8649-a646846ae8cd","_cell_guid":"b74550ae-6af4-412b-bc1b-2983d34df654","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nX_train = pd.read_csv('/kaggle/input/moa-1111a-enrich-source/moa_1111A_X_train.zip')\nX_test = pd.read_csv('/kaggle/input/moa-1111a-enrich-source/moa_1111A_X_test.zip')\nY_train = pd.read_csv('/kaggle/input/lish-moa/train_targets_scored.csv')\nX_train.shape, X_test.shape, X_train.shape\n\n# splitting the data\nfrom sklearn.model_selection import train_test_split\nX_train_tr, X_train_te, Y_train_tr, Y_train_te = train_test_split(X_train,Y_train,test_size=0.3,random_state=101)\n\n# Using Keras \n# -- Model\nfrom tensorflow.keras.layers import Input, Dense, Activation, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras import layers\n\n\ncols_output = Y_train_tr.columns[1:] # first column is sig_id\nX_tr = X_train_tr.drop('sig_id',axis=1)\nY_tr = Y_train_tr[cols_output]\nX_te = X_train_te.drop('sig_id',axis=1)\nY_te = Y_train_te[cols_output]\n\ninputs = Input(shape=(X_tr.shape[1],))\nbn = BatchNormalization()(inputs)\ndp=Dropout(0.2, name='dp1')(bn)\nhidden = Dense(2048, activation='relu', name='ly1')(dp)\n#wn = WeightNormalization()(hidden) # not present in keras\nbn = BatchNormalization()(hidden)\ndp = Dropout(0.5, name='dp2')(bn)\n\nhidden = Dense(1048, activation='relu', name='ly2')(dp)\n#wn = WeightNormalization()(hidden)\nbn = BatchNormalization()(hidden)\ndp = Dropout(0.5, name='dp3')(bn)\n\nout = Dense(206, activation='sigmoid', name='ly3')(dp)\n\n#model = Model(inputs=inputs, outputs=[out1,out2,out3,out4,out5,out6,out7,out8,out9,out10])\nmodel = Model(inputs=inputs, outputs=out)\n\nprint(model.summary())\n\n#--- Run Keras Model\nlosses = 'binary_crossentropy'\n#model.compile(optimizer = \"sgd\", loss = 'mse')\nmodel.compile(loss=losses, optimizer=\"adam\", metrics=['accuracy'])\nhistory = model.fit(X_tr, Y_tr, epochs=100, batch_size=128, validation_data=(X_te, Y_te.values))  # batch_size=128 was critical to get the high accuracy\n# add the patters\n#df_submission[X_test.cp_type == 1][df_submission.columns[1:]] = 0\n\n# preparing for submission\nY_test_pred = model.predict(X_test[X_test.columns[1:]])\n# df_submission = pd.DataFrame(X_test.sig_id)\n# df_submission = pd.concat([df_submission,pd.DataFrame(Y_test_pred)], axis=1)\n# df_submission.columns = Y_train.columns\n# # implement a pattern\n# df_submission.loc[X_test['cp_type'] == 1, Y_train.columns[1:]] = 0\n# #\n# df_submission.to_csv('submission.csv', index=False)\n# df_submission.shape\n\n# # Validation checks of submission with sample submission\n# sample_submission = pd.read_csv('/kaggle/input/lish-moa/sample_submission.csv')\n# print(set(df_submission.dtypes == sample_submission.dtypes)) # check if ID column type is identical\n# print(set(df_submission['sig_id'] == sample_submission['sig_id'])) # check if ID rows are identical\n# print(df_submission.shape, sample_submission.shape) # check if shapes are identical\n# print(set(df_submission.columns == sample_submission.columns)) # check if columns are identical\n\n# print(df_submission.dtypes)\n# print(sample_submission.dtypes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sam = pd.read_csv('../input/lish-moa/sample_submission.csv')\nsam.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_submission.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = model.predict(X_test[X_test.columns[1:]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sam.iloc[:,1:]=sub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sam.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}