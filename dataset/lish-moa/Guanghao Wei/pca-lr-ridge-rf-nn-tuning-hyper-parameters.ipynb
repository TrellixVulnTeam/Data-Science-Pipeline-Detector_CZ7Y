{"cells":[{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"from IPython.display import display\n\nimport pandas as pd\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":false},"cell_type":"code","source":"# Configuration\n\nimport logging\nimport sys\nfrom multiprocessing import cpu_count\n\n# Configure logging level\nlogging.basicConfig(stream=sys.stderr, level=logging.DEBUG)\n\n# Number of cpu cores used\nn_jobs = cpu_count()","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":false},"cell_type":"code","source":"# Load Data\n\nx_train = pd.read_csv('../input/lish-moa/train_features.csv', index_col=0)\nx_test = pd.read_csv('../input/lish-moa/test_features.csv', index_col=0)\ny_train = pd.read_csv('../input/lish-moa/train_targets_scored.csv', index_col=0)\nsubmission = pd.read_csv('../input/lish-moa/sample_submission.csv', index_col=0)\n\ndisplay(x_train.head())\ndisplay(x_test.head())\ndisplay(y_train.head())\ndisplay(submission.head())","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":false},"cell_type":"code","source":"# Preprocess Data\n\ndef preprocess(df):\n    df['cp_type'] = df['cp_type'].map({'trt_cp': 0, 'ctl_vehicle': 1})\n    df['cp_time'] = df['cp_time'].map({24: 1, 48: 2, 72: 3})\n    df['cp_dose'] = df['cp_dose'].map({'D1': 0, 'D2': 1})\n    return df\n\nx_train = preprocess(x_train)\nx_test = preprocess(x_test)\n\ndisplay(x_train.head())\ndisplay(x_test.head())","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":false},"cell_type":"code","source":"# Define the scorer function\n\nfrom sklearn.metrics import roc_auc_score, log_loss, f1_score\n\ndef scorer(y_true, y_pred):\n    log_loss_, auc, f1 = 0,0,0\n\n    # Add a dummy prediction to y_true and y_pred in case some label has all 0's\n    y_true = np.vstack((y_true, np.ones((1, y_true.shape[1]))))\n    y_pred = np.vstack((y_pred, np.ones((1, y_pred.shape[1]))))\n\n    v = y_true.shape[1]\n    for i in range(v):\n        log_loss_ += log_loss(y_true[:, i], y_pred[:, i])\n        auc += roc_auc_score(y_true[:, i], y_pred[:, i])\n        f1 += f1_score(y_true[:, i], y_pred[:, i] > 0.5)\n    return log_loss_ / v, auc / v, f1 / v","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":false},"cell_type":"code","source":"# Define the method to evaluate a model\n\nfrom skmultilearn.model_selection import IterativeStratification\n\nimport pickle\nfrom time import time\nfrom pathlib import Path\nfrom os import path\n\ndef eval_model(model, _x_train, _y_train, n_splits=3, id_=None):\n    start_time = time()\n    logging.info('*' * 20)\n    logging.info(\"Evaluating model {}\".format(id_ if id_ else model))\n\n    output = None\n\n    # Try to load saved result from disk if exists\n    if id_:\n        output = Path('output') / id_\n        output.mkdir(parents=True, exist_ok=True)\n        if path.exists(output / 'score.pkl'):\n            logging.debug(\"Loading result from disk\")\n            log_loss_, auc, f1 = pickle.load(open(output / 'score.pkl', 'rb'))\n            logging.info(\"The Average Log Loss is {}\".format(log_loss_))\n            logging.info(\"The Average AUC is {}\".format(auc))\n            logging.info(\"The Average f1 is {}\".format(f1))\n            return log_loss_, auc, f1\n\n    # Convert data into numpy\n    _x_train = np.array(_x_train)\n    _y_train = np.array(_y_train)\n\n    # Deprecated sklearn k-forld\n    # kf = StratifiedKFold(n_splits=n_splits)\n    # kf.get_n_splits(X_train)\n\n    # Use Iterative stratification for multi-label data to handle imbalance\n    kf = IterativeStratification(n_splits=n_splits, order=1)\n\n    log_loss_, auc, f1 = 0.0, 0.0, 0.0\n    for i, (train_index, test_index) in enumerate(kf.split(_x_train, _y_train)):\n        x_train_, x_val_ = _x_train[train_index], _x_train[test_index]\n        y_train_, y_val_ = _y_train[train_index], _y_train[test_index]\n\n        # Add dummy sample to make sure every column has 2 labels\n        x_train_ = np.vstack((x_train_, np.zeros((1, x_train_.shape[1]))))\n        y_train_ = np.vstack((y_train_, np.ones((1, y_train_.shape[1]))))\n\n        y_pred_ = model.fit(x_train_, y_train_).predict(x_val_)\n\n        log_loss_val, auc_val, f1_val = scorer(y_val_, y_pred_)\n\n        # Pickle y_val_ and y_pred_\n        if id_:\n            pickle.dump((y_val_, y_pred_), open(output / \"cv_{}.pkl\".format(i), 'wb'))\n\n        # Update the scores\n        log_loss_ += log_loss_val\n        auc += auc_val\n        f1 += f1_val\n\n    log_loss_ /= n_splits\n    auc /= n_splits\n    f1 /= n_splits\n    if id_:\n        pickle.dump((log_loss_, auc, f1), open(output / 'score.pkl', 'wb'))\n    logging.info(\"The Average Log Loss is {}\".format(log_loss_))\n    logging.info(\"The Average AUC is {}\".format(auc))\n    logging.info(\"The Average f1 is {}\".format(f1))\n    logging.debug(\"Used {:.2f}s\".format(time() - start_time))\n    return log_loss_, auc, f1","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":false},"cell_type":"code","source":"# Run a Linear Regression for demo\n\nfrom sklearn.linear_model import LogisticRegression, LinearRegression, Ridge\nfrom sklearn.ensemble import RandomForestClassifier, StackingClassifier, RandomForestRegressor, StackingRegressor\nfrom sklearn.multioutput import MultiOutputClassifier, MultiOutputRegressor\nfrom sklearn.neural_network import MLPClassifier, MLPRegressor\n\n# eval_model(LinearRegression(n_jobs=n_jobs), x_train, y_train, id_='lr')","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":false},"cell_type":"code","source":"# Define PCA Function\n\nfrom sklearn.decomposition import PCA\n\ndef pca(_x_train, _x_test, n_gene=200, n_cell=50):\n    genes = [col for col in _x_train.columns if col.startswith('g-')]\n    cells = [col for col in _x_train.columns if col.startswith('c-')]\n\n    # PCA genes\n    data_genes = pd.concat([pd.DataFrame(_x_train[genes]), pd.DataFrame(_x_test[genes])])\n    data_genes_pca = PCA(n_components=n_gene, random_state=42).fit_transform(data_genes)\n\n    train_gene_pca = data_genes_pca[:_x_train.shape[0]]\n    test_gene_pca = data_genes_pca[-_x_test.shape[0]:]\n\n    train_gene_pca = pd.DataFrame(train_gene_pca, columns=[f'pca_G-{i}' for i in range(n_gene)])\n    test_gene_pca = pd.DataFrame(test_gene_pca, columns=[f'pca_G-{i}' for i in range(n_gene)])\n\n    # PCA cells\n    data_cells = pd.concat([pd.DataFrame(_x_train[cells]), pd.DataFrame(_x_test[cells])])\n    data_cells_pca = PCA(n_components=n_cell, random_state=42).fit_transform(data_cells)\n\n    train_cells_pca = data_cells_pca[:_x_train.shape[0]]\n    test_cells_pca = data_cells_pca[-_x_test.shape[0]:]\n\n    train_cells_pca = pd.DataFrame(train_cells_pca, columns=[f'pca_C-{i}' for i in range(n_cell)])\n    test_cells_pca = pd.DataFrame(test_cells_pca, columns=[f'pca_C-{i}' for i in range(n_cell)])\n\n    # Generate new training and test data\n    _train_features = pd.concat((train_gene_pca, train_cells_pca), axis=1)\n    _test_features = pd.concat((test_gene_pca, test_cells_pca), axis=1)\n    return _train_features, _test_features","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":false},"cell_type":"code","source":"# # Tuning PCA with linear regression\n#\n# cols = ['log_loss', 'roc_auc', 'f1']\n# df = pd.DataFrame(columns=cols)\n# for n_genes in [10, 20, 50, 100, 200, 400, 500]:\n#     for n_cells in [10, 25, 50, 75]:\n#         train_features, test_features = pca(x_train, x_test, n_genes, n_cells)\n#         ll, auc, f1 = eval_model(LinearRegression(n_jobs=n_jobs),train_features, y_train, id_='lr_{}_{}'.format(n_genes, n_cells))\n#         df = df.append(pd.Series([ll, auc, f1], name='lr_{}_{}'.format(n_genes, n_cells), index=cols))\n#\n# display(df.sort_values(by=['log_loss']).head())","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":false},"cell_type":"code","source":"# Make hist plot\nimport matplotlib.pyplot as plt\n\nmpl_logger = logging.getLogger('matplotlib')\nmpl_logger.setLevel(logging.WARNING)\n\ndef make_hist_plot(df, title, id_):\n    def __plot(score):\n        logging.debug(df[score])\n        x = list(df.index)\n        y = df[score].values\n        plt.figure(figsize=(16, 9))\n        plt.bar(x, y)\n        plt.xticks(x, x, rotation='vertical')\n        plt.ylabel(score)\n        plt.title(\"{} {}\".format(title, score))\n        plt.subplots_adjust(bottom=0.4)\n\n        plt.savefig(\"fig/{}_{}.png\".format(id_, score))\n        plt.show()\n\n    for col in df:\n        __plot(col)\n\ndef make_plot(df, title, id_, x_label=None, log_x=False):\n    def __plot(score):\n        logging.debug(df[score])\n        x = list(df.index)\n        y = df[score].values\n        # plt.figure(figsize=(16, 9))\n        plt.plot(x, y)\n        if x_label:\n            plt.xlabel(x_label)\n        plt.ylabel(score)\n        if log_x:\n            plt.xscale('log')\n        plt.title(\"{} {}\".format(title, score))\n\n        plt.savefig(\"fig/{}_{}.png\".format(id_, score))\n        plt.show()\n\n    for col in df:\n        __plot(col)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":false},"cell_type":"code","source":"# # Make plot of tuning PCA\n#\n# make_hist_plot(df, 'Tuning PCA', 'tuning_pca')","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":false},"cell_type":"code","source":"# Use 20 genes and 10 cells as best PCA\ntrain_features, test_features = pca(x_train, x_test, 20, 10)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":false},"cell_type":"code","source":"# # Tuning over sampling per label, tested with lr\n# df = pd.DataFrame(columns=cols)\n# ll, auc, f1 = eval_model(MultiOutputClassifier(LogisticRegression(max_iter=1e4, C=0.01), n_jobs=n_jobs),\n#                          train_features, y_train, id_='lr_100_25_c_0.01')\n# df = df.append(pd.Series([ll, auc, f1], name='lr_100_25_c_0.01', index=cols))\n#\n# # MultiOutputWithSampling is a class I implemented to treat each label as separate training task and train the model.\n# from MultiOutputWithSampling import MultiOutputWithSampling\n#\n# # 0.01, 0.02, and 0.03 result in errors\n# for ss in [0.04, 0.1, 0.2, 0.25, 0.5]:\n#     ll, auc, f1 = eval_model(\n#         MultiOutputWithSampling(LogisticRegression(max_iter=1e4, C=0.01), sampling_strategy=ss, n_jobs=n_jobs),\n#         train_features, y_train, id_='lr_100_25_c_0.01_ss_{}_separate_sampling'.format(ss))\n#     df = df.append(pd.Series([ll, auc, f1], name='lr_100_25_c_0.01_ss_{}_separate_sampling'.format(ss), index=cols))\n# make_hist_plot(df, \"Tuning sampling strategy per label on LR, C=0.01\", 'sampling')\n# # No separate sampling performs better","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":false},"cell_type":"code","source":"# # Ridge, Tuning a\n# tuning_a = np.logspace(-2, 3, 6)\n# df = pd.DataFrame(columns=cols)\n# for a in tuning_a:\n#     ll, auc, f1 = eval_model(MultiOutputRegressor(Ridge(alpha=a), n_jobs=n_jobs), train_features, y_train,\n#                              id_='ridge_100_25_a_{:.2f}'.format(a))\n#     df = df.append(pd.Series([ll, auc, f1], name=a, index=cols))\n# make_plot(df, \"Ridge, Tuning a\", \"ridge_tuning_a\", x_label='a', log_x=True)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":false},"cell_type":"code","source":"# The best ridge is a=1000\nbest_ridge = Ridge(alpha=1000)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":false},"cell_type":"code","source":"# # Logistic Regression, Tuning C\n# tuning_c = np.logspace(-2, 3, 6)\n# df = pd.DataFrame(columns=cols)\n# for c in tuning_c:\n#     ll, auc, f1 = eval_model(MultiOutputClassifier(LogisticRegression(max_iter=1e4, C=c), n_jobs=n_jobs),\n#                              train_features, y_train, id_='lr_100_25_c_{:.2f}'.format(c))\n#     df = df.append(pd.Series([ll, auc, f1], name=c, index=cols))\n# make_plot(df, \"LR, Tuning C\", \"lr_tuning_c\", x_label='C', log_x=True)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":false},"cell_type":"code","source":"# The best LR is C=0.01\nbest_lr = LogisticRegression(max_iter=1e4, C=0.01)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":false},"cell_type":"code","source":"# # Random Forest, tuning max_depth\n# df = pd.DataFrame(columns=cols)\n# for n_estimators in [50, 200, 500]:\n#     for max_depth in [1, 3, 6, 10]:\n#         ll, auc, f1 = eval_model(MultiOutputRegressor(\n#             RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, random_state=43,\n#                                   min_samples_split=10), n_jobs=n_jobs), train_features, y_train,\n#             id_='rfr_{}_{}_43_10'.format(n_estimators, max_depth))\n#         df = df.append(pd.Series([ll, auc, f1], name=max_depth, index=cols))\n# display(df.sort_values(by='log_loss').head())\n# make_hist_plot(df, \"Random Forest, Tuning n_estimators and max_depth\", \"rfr_tuning_n_d\")","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":false},"cell_type":"code","source":"# The best Random Forest is max_depth=3\n\nbest_rf = MultiOutputRegressor(\n    RandomForestRegressor(n_estimators=50, max_depth=3, random_state=43, min_samples_split=10), n_jobs=n_jobs)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":false},"cell_type":"code","source":"# # NN model, Tuning hidden_layer\n# df = pd.DataFrame(columns=cols)\n# best_loss = np.inf\n# best_h = None\n# for i in [50, 100, 200]:\n#     for j in [50, 100, 200]:\n#         for k in [50, 100, 200]:\n#             ll, auc, f1 = eval_model(\n#                 MLPRegressor(hidden_layer_sizes=(i, j, k), random_state=1, max_iter=1500, learning_rate='adaptive',\n#                              warm_start=True), train_features, y_train, id_='nn_100_25_h_{}_{}_{}'.format(i, j, k))\n#             if best_loss > ll:\n#                 best_loss = ll\n#                 best_h = (i, j, k)\n#             df = df.append(pd.Series([ll, auc, f1], name='nn_100_25_h_{}_{}_{}'.format(i, j, k), index=cols))\n# make_hist_plot(df, \"Neural Network\", \"nn_tuning_hidden\")\n# logging.info(\"The best hidden layer configuration is {}\".format(best_h))\n# logging.info(\"The best log loss is {}\".format(best_loss))","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":false},"cell_type":"code","source":"# The best nn is hidden_layer=(200,100,100)\nbest_nn = MLPRegressor(hidden_layer_sizes=(200, 100, 100), random_state=1, max_iter=1500, warm_start=True)","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":false},"cell_type":"code","source":"# Predict with the best model\nbest_model = best_rf\nbest_model.fit(train_features, y_train)\ny_pred = best_model.predict(test_features)\n# pickle.dump((best_model, y_pred), open(\"best_model.pkl\", 'wb'))\n# best_model, y_pred = pickle.load(open(\"best_model.pkl\", 'rb'))\nsubmission = pd.DataFrame(y_pred, index=submission.index, columns=submission.columns)\n\ndisplay(submission.head())","execution_count":null,"outputs":[]},{"metadata":{"pycharm":{"name":"#%%\n"},"trusted":false},"cell_type":"code","source":"submission.to_csv('submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Remove pickle files\n\n# import shutil\n\n# shutil.rmtree(\"/kaggle/working/output\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}