{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os,time,random,tqdm\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nimport sklearn\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.utils import shuffle\n\n# from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n\nimport tensorflow as tf\nimport tensorflow_addons as tfa\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_features = pd.read_csv('/kaggle/input/lish-moa/train_features.csv')\ntrain_targets = pd.read_csv('/kaggle/input/lish-moa/train_targets_scored.csv')\n# train_targets_nonscored = pd.read_csv('/kaggle/input/lish-moa/train_targets_nonscored.csv')\ntest_features = pd.read_csv('/kaggle/input/lish-moa/test_features.csv')\nsample_submission = pd.read_csv('/kaggle/input/lish-moa/sample_submission.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cells with cp_type = ctl_vehicle have targets = 0 everywhere\n\nindices = test_features[test_features['cp_type'] == 'ctl_vehicle'].index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oh = OneHotEncoder()\n\noh.fit(train_features[['cp_time','cp_dose']])\noh.get_feature_names()\n\ntrain_features[oh.get_feature_names()] = oh.transform(train_features[['cp_time','cp_dose']]).todense()\ntest_features[oh.get_feature_names()] = oh.transform(test_features[['cp_time','cp_dose']]).todense()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_targets.drop(['sig_id'],axis=1,inplace=True)\ntrain_features.drop(['sig_id','cp_type','cp_time','cp_dose'],axis=1,inplace=True)\ntest_features.drop(['sig_id','cp_type','cp_time','cp_dose'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_model(inp_shape=877,out_shape=206,bias_init=None):\n    \n    model = tf.keras.models.Sequential([\n        tf.keras.layers.BatchNormalization(input_shape=(inp_shape,)),\n        tf.keras.layers.Dropout(0.2),\n        tfa.layers.WeightNormalization(tf.keras.layers.Dense(2048)),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Activation('relu'),\n        tf.keras.layers.Dropout(0.5),\n        tfa.layers.WeightNormalization(tf.keras.layers.Dense(2048)),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Activation('relu'),\n        tf.keras.layers.Dropout(0.5),\n        tfa.layers.WeightNormalization(tf.keras.layers.Dense(1024)),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Activation('relu'),\n        tf.keras.layers.Dropout(0.5),\n        tfa.layers.WeightNormalization(tf.keras.layers.Dense(512)),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Activation('relu'),\n        tf.keras.layers.Dropout(0.5),\n        tfa.layers.WeightNormalization(tf.keras.layers.Dense(512)),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Activation('relu'),\n        tf.keras.layers.Dropout(0.5),\n        tf.keras.layers.Dense(out_shape,'sigmoid',bias_initializer=tf.keras.initializers.Constant(bias_init))\n    ])\n    \n    opt = tfa.optimizers.Lookahead(\n        tf.keras.optimizers.Adam(lr=1e-4)\n    )\n    \n    \n    model.compile(\n        optimizer=opt,\n        loss='binary_crossentropy',\n        metrics=['accuracy']\n    )\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# temp_learning_rate_schedule=CustomSchedule()\n# plt.plot(temp_learning_rate_schedule(tf.range(4500, dtype=tf.float32)))\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_folds = 7\ncv = KFold(n_folds,random_state=33,shuffle=True)\npreds = np.zeros((len(test_features),206))\n\n\nscores = []\n\nfor index,(train_index, test_index) in enumerate(cv.split(train_features)):\n    X_train,X_test,y_train,y_test = train_features.loc[train_index],train_features.loc[test_index],train_targets.loc[train_index],train_targets.loc[test_index]\n\n    bias_init = np.log((np.sum(y_train.values,axis=0)+0.000001)/(len(y_train) - np.sum(y_train.values,axis=0)))\n    pipeline = make_pipeline(StandardScaler())\n    X_train = pipeline.fit_transform(X_train)\n    X_test = pipeline.transform(X_test)\n\n\n    tf.keras.backend.clear_session()\n        \n    model = make_model(bias_init=bias_init)\n        \n    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(patience=3,verbose=1)\n    m_ckpt = tf.keras.callbacks.ModelCheckpoint(\n            '/checkpoint', monitor='val_loss', verbose=1, save_best_only=True,\n            save_weights_only=True\n            )\n    es = tf.keras.callbacks.EarlyStopping(patience=5)\n    \n\n        \n    model.fit(X_train,y_train,batch_size=128,epochs=45,validation_data=(X_test,y_test),verbose=-1,callbacks=[es,m_ckpt,reduce_lr])\n    \n        \n    scores.append(m_ckpt.best)\n    print(f\"Best fold {index} score : {scores[-1]}\")\n        \n    model.load_weights('/checkpoint')\n    p = model.predict(pipeline.transform(test_features))\n    preds += p","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Prediction on 10 the same models with different seeds\n\n# preds = np.zeros((len(test_features),206))\n# X_train,y_train = train_features,train_targets\n# bias_init = np.log(np.sum(y_train.values,axis=0)/(len(y_train) - np.sum(y_train.values,axis=0)))\n\n# pipeline = make_pipeline(StandardScaler())\n# X_train = pipeline.fit_transform(X_train)\n\n# for i in range(10):\n#     tf.keras.backend.clear_session()\n        \n#     model = make_model(bias_init=bias_init)\n    \n#     model.fit(X_train,y_train,batch_size=128,epochs=20,verbose=1)\n\n#     p = model.predict(pipeline.transform(test_features))\n    \n#     preds+=p","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds/=n_folds\n# preds/=10.0\npreds[indices][:,:] = 0\nsample_submission[sample_submission.columns.tolist()[1:]] = preds\nsample_submission.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}