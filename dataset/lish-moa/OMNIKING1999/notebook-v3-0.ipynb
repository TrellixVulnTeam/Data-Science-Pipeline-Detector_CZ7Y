{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers import RMSprop,Adam\nimport tensorflow_addons as tfa\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import KFold\nfrom sklearn import preprocessing\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.feature_selection import VarianceThreshold\nfrom tensorflow.keras import layers,regularizers,Sequential,Model,backend,callbacks,optimizers,metrics,losses\nimport tensorflow as tf\nimport sys\nsys.path.append('../input/iterativestratification/iterative_stratification-0.1.6-py3-none-any.whl')\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf = pd.read_csv('/kaggle/input/lish-moa/train_features.csv')\nnon_ctl_idx = df.loc[df['cp_type']!='ctl_vehicle'].index.to_list()\ndf = df.drop(['sig_id','cp_type','cp_dose','cp_time'],axis=1)\ndata_X_test = pd.read_csv('/kaggle/input/lish-moa/test_features.csv')\ndata_X_test = data_X_test.drop(['sig_id','cp_dose','cp_time'],axis=1)\n\ndada = pd.read_csv('/kaggle/input/lish-moa/train_targets_scored.csv')\ndada = dada.drop('sig_id',axis=1)\ndf_label = dada.values\ndf = df.iloc[non_ctl_idx]\ndf_label = df_label[non_ctl_idx]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ncs = df.columns.str.contains('c-')\ngs = df.columns.str.contains('g-')\n\ndef preprocessor(train,test):\n    \n    \n    n_gs = 2 \n    n_cs = 100 \n    \n    pca_cs = PCA(n_components = n_cs)\n    pca_gs = PCA(n_components = n_gs)\n\n    train_pca_gs = pca_gs.fit_transform(train[:,gs])\n    train_pca_cs = pca_cs.fit_transform(train[:,cs])\n    test_pca_gs = pca_gs.transform(test[:,gs])\n    test_pca_cs = pca_cs.transform(test[:,cs])\n\n    \n    train_c_mean = train[:,cs].mean(axis=1)\n    test_c_mean = test[:,cs].mean(axis=1)\n    train_g_mean = train[:,gs].mean(axis=1)\n    test_g_mean = test[:,gs].mean(axis=1)\n    \n    \n    train = np.concatenate((train,train_pca_gs,train_pca_cs,train_c_mean[:,np.newaxis]\n                            ,train_g_mean[:,np.newaxis]),axis=1)\n    test = np.concatenate((test,test_pca_gs,test_pca_cs,test_c_mean[:,np.newaxis],\n                           test_g_mean[:,np.newaxis]),axis=1)\n    \n    scaler = preprocessing.StandardScaler()\n\n    train = scaler.fit_transform(train)\n\n    test = scaler.transform(test)\n    \n    return train, test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\np_min = 0.0005\np_max = 0.9995\n\ndef logloss(y_true, y_pred):\n    y_pred = tf.clip_by_value(y_pred,p_min,p_max)\n    return -backend.mean(y_true*backend.log(y_pred) + (1-y_true)*backend.log(1-y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_logloss', factor=0.1, verbose=0,mode='min',\n                              patience=3, min_lr=1E-7)\nearly_st = tf.keras.callbacks.EarlyStopping(monitor='val_logloss', min_delta=1E-5, patience=7, verbose=0, mode='min',\n    baseline=None, restore_best_weights=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model1(num_columns):\n    model = tf.keras.Sequential([\n    tf.keras.layers.Input(num_columns),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.3),\n    tfa.layers.WeightNormalization(tf.keras.layers.Dense(512, activation=\"elu\")),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.3),\n    tfa.layers.WeightNormalization(tf.keras.layers.Dense(1024, activation=\"elu\")),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.3),\n    tfa.layers.WeightNormalization(tf.keras.layers.Dense(512, activation=\"elu\")),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.4),\n    tfa.layers.WeightNormalization(tf.keras.layers.Dense(2048, activation=\"elu\")),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.3),   \n    tfa.layers.WeightNormalization(tf.keras.layers.Dense(206, activation=\"sigmoid\"))\n    ])\n    model.compile(optimizer=tfa.optimizers.Lookahead(tf.optimizers.Adam(), sync_period=10),\n                  loss=losses.BinaryCrossentropy(label_smoothing=0.0015),metrics=logloss\n                  )\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model(num_columns):\n    model = tf.keras.Sequential([\n    tf.keras.layers.Input(num_columns),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.2),\n    tfa.layers.WeightNormalization(tf.keras.layers.Dense(2048, activation=\"relu\")),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.2),\n    tfa.layers.WeightNormalization(tf.keras.layers.Dense(1048, activation=\"relu\")),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.5), \n    tfa.layers.WeightNormalization(tf.keras.layers.Dense(512, activation=\"relu\")),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.2),        \n    tfa.layers.WeightNormalization(tf.keras.layers.Dense(206, activation=\"sigmoid\"))\n    ])\n    model.compile(optimizer=tfa.optimizers.Lookahead(tf.optimizers.Adam(), sync_period=10),\n                  loss=losses.BinaryCrossentropy(label_smoothing=0.001),metrics=logloss\n                  )\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = 976\n\nfrom keras import backend \nn_seeds = 6\nnp.random.seed(1)\nseeds = np.random.randint(0,100,size=n_seeds)\n\nn_labels = df_label.shape[1]\nn_train = df.shape[0]\nn_test = data_X_test.shape[0]\nn_folds = 5\ny_pred = np.zeros((n_test,n_labels))\noof = tf.constant(0.0)\nhists = []\n\n\nfor seed in seeds:\n    fold = 0\n    print(fold)\n    mlkf = MultilabelStratifiedKFold(n_splits=n_folds,shuffle=True,random_state=seed)\n    for n,(train, test) in enumerate(mlkf.split(df,df_label)):\n        tf.print('OOF score is ',oof)\n        print(f'Fold {n}')\n        \n        \n        train_x, validation_x = preprocessor(df.iloc[train].values,\n                                       df.iloc[test].values)\n        _,data_test = preprocessor(df.iloc[train].values,\n                                   data_X_test.drop('cp_type',axis=1).values)\n\n        train_y = df_label[train]\n        validation_y = df_label[test]\n        \n        if seed%2 == 0:\n            model = create_model1(X)\n        else:    \n            model = create_model(X)\n\n        model.compile(optimizer='adam',loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=0.001), metrics=logloss )\n        \n\n        hist = model.fit(train_x,train_y, batch_size=128, epochs=200,verbose=0,validation_data = (validation_x,validation_y),callbacks =[reduce_lr, early_st])\n        hists.append(hist)\n        \n        # Save Model\n        model.save('_seed_'+str(seed)+'_fold_'+str(fold))\n\n        # OOF Score\n        y_val = model.predict(validation_x)\n        oof += logloss(tf.constant(validation_y,dtype=tf.float32),tf.constant(y_val,dtype=tf.float32))/(n_folds*n_seeds)\n\n        # Run prediction\n        y_pred += model.predict(data_test)/(n_folds*n_seeds)\n        \n        fold += 1\n        \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.print('OOF score is ',oof)\n\nplt.figure(figsize=(12,8))\n\nhist_trains = []\nhist_lens = []\nfor i in range(n_folds*n_seeds):\n    hist_train = (hists[i]).history['logloss']\n    hist_trains.append(hist_train)\n    hist_lens.append(len(hist_train))\nhist_train = []\nfor i in range(min(hist_lens)):\n    hist_train.append(np.mean([hist_trains[j][i] for j in range(n_folds*n_seeds)]))\n\nplt.plot(hist_train)\n\nhist_vals = []\nhist_lens = []\nfor i in range(n_folds*n_seeds):\n    hist_val = (hists[i]).history['val_logloss']\n    hist_vals.append(hist_val)\n    hist_lens.append(len(hist_val))\nhist_val = []\nfor i in range(min(hist_lens)):\n    hist_val.append(np.mean([hist_vals[j][i] for j in range(n_folds*n_seeds)]))\n\nplt.plot(hist_val)\n\nplt.yscale('log')\nplt.yticks(ticks=[1,1E-1,1E-2])\nplt.xlabel('Epochs')\nplt.ylabel('Average Logloss')\nplt.legend(['Training','Validation'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfinal = pd.read_csv('/kaggle/input/lish-moa/sample_submission.csv')\nfinal.iloc[:,1:] = np.clip(y_pred,p_min,p_max)\nfinal.iloc[data_X_test['cp_type'] == 'ctl_vehicle',1:] = 0\n\nfinal.to_csv('submission.csv', index=False)\nfinal.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}