{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing libraries\nimport pandas as pd\nimport numpy as np\nimport random\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm.notebook import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Reading datasets\ndf = pd.read_csv('/kaggle/input/lish-moa/train_features.csv')\ntts = pd.read_csv('/kaggle/input/lish-moa/train_targets_scored.csv')\nttns = pd.read_csv('/kaggle/input/lish-moa/train_targets_nonscored.csv')\ntd = pd.read_csv('/kaggle/input/lish-moa/train_drug.csv')\nte_df = pd.read_csv('/kaggle/input/lish-moa/test_features.csv')\nsub = pd.read_csv('/kaggle/input/lish-moa/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#embedding cp_type, cp_time and cp_dose categorical columns of train dataset\ndf['cp_type'] = df['cp_type'].map({'trt_cp':0, 'ctl_vehicle':1})\ndf['cp_time'] = df['cp_time'].map({24:0, 48:1, 72:2})\ndf['cp_dose'] = df['cp_dose'].map({'D1':0, 'D2':1})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#embedding cp_type, cp_time and cp_dose categorical columns of test dataset\nte_df['cp_type'] = te_df['cp_type'].map({'trt_cp':0, 'ctl_vehicle':1})\nte_df['cp_time'] = te_df['cp_time'].map({24:0, 48:1, 72:2})\nte_df['cp_dose'] = te_df['cp_dose'].map({'D1':0, 'D2':1})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Seperating gene and cell columns\ngene_cols = [c for c in df.columns if c.startswith('g-')]\ncell_cols = [c for c in df.columns if c.startswith('c-')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#making copy of train_features dataset\ndf_cp = df.copy()\nte_df_cp = te_df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#using QunatileTransformer to transform oue gene and cell columns\n#QunatileTransformer method transforms the features to follow a uniform or a normal distribution.\nfrom sklearn.preprocessing import QuantileTransformer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"qt = QuantileTransformer(n_quantiles=100, random_state=0)\nqt.fit(df_cp[gene_cols + cell_cols])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cp[gene_cols+cell_cols] = qt.transform(df_cp[gene_cols + cell_cols])\nte_df_cp[gene_cols+cell_cols] = qt.transform(te_df[gene_cols + cell_cols])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cp.drop('sig_id', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"te_df_cp.drop('sig_id', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers import LeakyReLU\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.models import load_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# AutoEncoder Model Preparation\nn_inputs = df_cp.shape[1]\n# define encoder\ninput_data_shape= Input(shape=(n_inputs,))\n# encoder level\nencoder= Dense(512, activation='relu')(input_data_shape)\nencoder= Dense(128, activation='relu')(encoder)\nencoder= Dense(64, activation='relu')(encoder)\nencoder= Dense(32, activation='relu')(encoder)\n# bottleneck\nn_bottleneck = 50\nbottleneck = Dense(n_bottleneck)(encoder)\n# define decoder\ndecoder = Dense(32, activation='relu')(bottleneck)\ndecoder = Dense(64, activation='relu')(decoder)\ndecoder = Dense(128, activation='relu')(decoder)\ndecoder = Dense(512, activation='relu')(decoder)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# output layer\noutput = Dense(n_inputs, activation='linear')(decoder)\n# define autoencoder model\nmodel = Model(inputs=input_data_shape, outputs=output)\n# compile autoencoder model\nmodel.compile(optimizer='adam', loss='mse')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fit the autoencoder model to reconstruct input\nhistory = model.fit(df_cp, df_cp, epochs=50, batch_size=16, verbose=2, validation_data=(te_df_cp,te_df_cp))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define an encoder model (without the decoder)\nencoder = Model(inputs=input_data_shape, outputs=bottleneck)\n# save the encoder to file\nencoder.save('encoder.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# loading the encoder model\nencoder = load_model('encoder.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# encode the train data\nX_train_encode = encoder.predict(df_cp)\n# encode the test data\nX_test_encode = encoder.predict(te_df_cp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import log_loss\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import GridSearchCV\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.pipeline import Pipeline\nfrom sklearn.multiclass import OneVsRestClassifier\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Step 1**"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_moa_each_sample = np.sum(tts.drop('sig_id', axis=1), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_1 = pd.concat([df_cp, pd.DataFrame(X_train_encode)], axis=1)    #concatenating original train data with data left after autoencoding\ny_1 = num_moa_each_sample.map({1:1,2:1,3:1,4:1,5:1,7:1,0:0})    #if MoA is present then map it to 1 elso 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#final model for Step 1\nmodel_1 = SGDClassifier(loss='log')\nmodel_1.fit(X_1, y_1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Step 2**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#removing first column i.e sig_id column from all datasets and storing in different variables\nX = pd.concat([df_cp, pd.DataFrame(X_train_encode)], axis=1)\ny = tts.iloc[:,1:]\ntest = pd.concat([te_df_cp, pd.DataFrame(X_test_encode)], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X = df_cp\n# y = tts.iloc[:,1:]\n# test = te_df_cp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X.shape, y.shape, test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kf = KFold(n_splits=2, shuffle=True, random_state=22)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nbest_model = None      #initializing best_model variable for storing best_model\nbest_loss = 99999999   #initializing best_loss variable to store least log-loss\ncv = 1                 #initializing cv variable to store number of cross validation iterating\n\nfor train_idx, test_idx in tqdm(kf.split(X, y)):     #iterating for each cv\n  X_train , X_val = X.iloc[train_idx], X.iloc[test_idx]\n  y_train, y_val = y.iloc[train_idx], y.iloc[test_idx]\n\n  #training the model\n  print('FIT')\n  #model = OneVsRestClassifier(SGDClassifier(loss='log', alpha=0.001, penalty='l2', max_iter=10000,tol=0.00001, eta0=0.002), n_jobs=-1)\n  #model = OneVsRestClassifier(GaussianNB(), n_jobs=-1)\n  model = OneVsRestClassifier(RandomForestClassifier(max_depth=2, n_estimators = 100))\n  model.fit(X_train, y_train)\n\n  #predicting target values for validation set and computing log-loss for each target features\n  print('PREDICT')\n  pred = model.predict_proba(X_val)\n  pred = np.array(pred)\n  \n  loss = log_loss(np.ravel(np.array(y_val)), np.ravel(pred))\n  print('Log loss for ',cv,' cv = ',loss)\n  \n  #saving best model and least log-loss\n  if loss < best_loss:\n      best_model = model\n      best_loss = loss\n  \n  cv += 1    #updating cv variable\n''' ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #best_model = OneVsRestClassifier(RandomForestClassifier(max_depth=2, n_estimators = 100))\nbest_model = OneVsRestClassifier(SGDClassifier(loss='log', alpha=0.001, penalty='l2', max_iter=10000,tol=0.00001, eta0=0.002), n_jobs=-1)\nbest_model.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Combining step 1 and step 2**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#predicting target value for test dataset using first model (step 1 model) to find whether MoA is present or not\nmodel_1_pred = model_1.predict(test)#[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#np.sum(model_1_pred<0.4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predicting target values for test dataset\ntest_pred = best_model.predict_proba(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred[2].max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.iloc[:,1:] = test_pred\nsub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}