{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\nsys.path.append('../input/iterativestratificationkfold/iterative-stratification-master/iterative-stratification-master')\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\ntest_features = pd.read_csv('/kaggle/input/lish-moa/test_features.csv')\ntrain_targets = pd.read_csv('/kaggle/input/lish-moa/train_targets_scored.csv')\ntrain_features = pd.read_csv(\"/kaggle/input/lish-moa/train_features.csv\")\nsubmission = pd.read_csv('/kaggle/input/lish-moa/sample_submission.csv')\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nimport io\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import figure","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pip install iterative-stratification","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#preprocessing steps\ndef preprocess(df):\n    df.loc[:, 'cp_type'] = df.loc[:, 'cp_type'].map({'trt_cp': 0, 'ctl_vehicle': 1})\n    df.loc[:, 'cp_dose'] = df.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n    df.loc[:, 'cp_time'] = df.loc[:, 'cp_time'].map({24: 0, 48: 1, 72: 2})\n    del df['sig_id']\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = preprocess(train_features)\ntest = preprocess(test_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train_targets['sig_id']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape)\nprint(train_targets.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.astype('float32')\ntest = test.astype('float32')\ntrain_targets = train_targets.astype('float32')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def metric(y_true, y_pred):\n    metrics = []\n    for _target in train_targets.columns:\n        metrics.append(log_loss(y_true.loc[:, _target], y_pred.loc[:, _target].astype(float),labels=[0,1]))\n    return np.mean(metrics)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nimport tensorflow\nfrom keras.layers import Input, concatenate, Activation, Add\nfrom keras.models import Model, load_model\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.optimizers import Adam\nfrom keras.utils import to_categorical\nfrom numpy.random import seed\nfrom keras.layers import Conv1D\nfrom keras.layers import MaxPooling1D, GlobalAveragePooling1D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\nfrom keras.layers import BatchNormalization\nfrom keras.layers import Dropout\nfrom tensorflow.keras import regularizers\nfrom keras.models import Sequential\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nimport tensorflow.keras.layers as L\nimport tensorflow.keras.models as M\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\nfrom tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import log_loss\nimport math\nfrom keras.callbacks import LearningRateScheduler\nfrom keras.layers import LeakyReLU\n\nseed(1)\ntf.random.set_seed(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras import regularizers\ndef evaluate_model(train): \n        input_shape = train.shape[1]\n        input = Input(shape=(input_shape,1))\n        input_shortcut = input\n        convolved = Conv1D(64, 2, padding=\"same\",kernel_regularizer=keras.regularizers.l2(l=0.1))(input)\n        convolved= LeakyReLU(alpha=0.1)(convolved)\n        x_1= MaxPooling1D()(convolved)\n        convolved_4= Conv1D(64, 8, padding=\"same\",kernel_regularizer=keras.regularizers.l2(l=0.1))(input)\n        convolved_4= LeakyReLU(alpha=0.1)(convolved_4)\n        x_15= MaxPooling1D()(convolved_4)\n        convolved1 = Conv1D(64, 16, padding=\"same\",kernel_regularizer=keras.regularizers.l2(l=0.1))(input)\n        convolved1= LeakyReLU(alpha=0.1)(convolved1)\n        x_2= MaxPooling1D()(convolved1)\n        c = concatenate([x_1, x_2,x_15])\n        convolved4 = Conv1D(64, 3, padding=\"same\",kernel_regularizer=keras.regularizers.l2(l=0.1))(c)\n        convolved4= LeakyReLU(alpha=0.1)(convolved4)\n        x_4= MaxPooling1D()(convolved4)    \n        convolved5 = Conv1D(64, 3, padding=\"same\",kernel_regularizer=keras.regularizers.l2(l=0.1))(x_4)\n        convolved5= LeakyReLU(alpha=0.1)(convolved5)\n        x_5= MaxPooling1D()(convolved5)\n        x_5 = Dropout(0.50)(x_5)\n        x_6 = Flatten()(x_5)\n        x_6 = Dropout(0.50)(x_6)\n        x_7 = Dense(256)(x_6)\n        x_10 = Flatten()(input_shortcut)\n        x_10 = Dense(256)(x_10)\n        x_9 = Add()([x_10,x_7])\n        x_9 = Activation('linear')(x_9)\n        x_9 = Dropout(0.50)(x_9)\n        output = Dense(units=206, activation='sigmoid')(x_9)\n        model3 = Model(input,output)\n        opt = keras.optimizers.Adam(learning_rate=0.001)\n        model3.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n        return model3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"N_STARTS = 7\nres = train_targets.copy()\nres.loc[:, train_targets.columns] = 0\nsubmission.loc[:, train_targets.columns] = 0\nhistorys = dict()\ntf.random.set_seed(43)\nfor seed in range(N_STARTS):\n    for n, (tr, te) in enumerate(MultilabelStratifiedKFold(n_splits=7, random_state=seed, shuffle=True).split(train, train_targets)):\n        print(f\"======{train.iloc[tr].shape}========{train_targets.iloc[tr].shape}=====\")\n        print(f'Seed: {seed} => Fold: {n}')\n        model = evaluate_model(train)\n        checkpoint_path = f'repeat:{seed}_Fold:{n}.hdf5'\n        reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, min_lr=1e-5, patience=3, verbose=1, mode='min')\n        cb_checkpt = ModelCheckpoint(checkpoint_path, monitor = 'val_loss', verbose = 1, save_best_only = True,\n                                     save_weights_only = True, mode = 'min')\n        early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", restore_best_weights=True, patience= 5, verbose = 1)\n        history = model.fit(train.iloc[tr], train_targets.iloc[tr],\n                  validation_data=(train.values[te], train_targets.iloc[te]),\n                  epochs=50, batch_size=128,\n                  callbacks=[reduce_lr_loss, cb_checkpt, early], verbose=2\n                 )\n        historys[f'history_{seed+1}'] = history\n        print(\"Model History Saved.\")\n        model.load_weights(checkpoint_path)\n        #test_predict = model.predict(test.values[:, top_feats])\n        test_predict = model.predict(test)\n        val_predict = model.predict(train.iloc[te])\n        res.loc[te, train_targets.columns] += val_predict\n        submission.loc[:, train_targets.columns] += test_predict\n\n        print(f'OOF Metric For FOLD {n} : {metric(train_targets.loc[te, train_targets.columns], pd.DataFrame(val_predict, columns=train_targets.columns))}')\n        print('+-' * 10)\nres.loc[:, train_targets.columns] /= N_STARTS\n    \nsubmission.loc[:, train_targets.columns] /= ((n+1) * N_STARTS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nprint(f'OOF Metric: {metric(train_targets, res)}')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}