{"cells":[{"metadata":{"papermill":{"duration":0.025335,"end_time":"2020-09-12T10:35:51.904032","exception":false,"start_time":"2020-09-12T10:35:51.878697","status":"completed"},"tags":[]},"cell_type":"markdown","source":"\nReferences :\n1. @abhishek and @artgor 's Parallel Programming video https://www.youtube.com/watch?v=VRVit0-0AXE\n2. @yasufuminakama 's Amazying Notebook https://www.kaggle.com/yasufuminakama/moa-pytorch-nn-starter \n3. @namanj27 mostly  from here https://www.kaggle.com/namanj27/new-baseline-pytorch-moa\n\ntorch BCE smoothing as implemented here https://gist.github.com/MrRobot2211\n\n"},{"metadata":{"papermill":{"duration":0.024247,"end_time":"2020-09-12T10:35:51.951844","exception":false,"start_time":"2020-09-12T10:35:51.927597","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## Update:\n1. Model updated\n2. Changed to reduce LR in plateau\n3. Increased Seeds"},{"metadata":{"papermill":{"duration":0.023141,"end_time":"2020-09-12T10:35:52.044656","exception":false,"start_time":"2020-09-12T10:35:52.021515","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# If you like it, Do Upvote :)"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2020-09-12T10:35:52.096375Z","iopub.status.busy":"2020-09-12T10:35:52.095606Z","iopub.status.idle":"2020-09-12T10:35:52.885827Z","shell.execute_reply":"2020-09-12T10:35:52.885289Z"},"papermill":{"duration":0.817757,"end_time":"2020-09-12T10:35:52.885954","exception":false,"start_time":"2020-09-12T10:35:52.068197","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import sys \nsys.path.append('../input/iterative-stratification/iterative-stratification-master')\n#sys.path.append('..')\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.execute_input":"2020-09-12T10:35:52.94117Z","iopub.status.busy":"2020-09-12T10:35:52.940456Z","iopub.status.idle":"2020-09-12T10:35:54.286013Z","shell.execute_reply":"2020-09-12T10:35:54.285455Z"},"papermill":{"duration":1.375673,"end_time":"2020-09-12T10:35:54.286123","exception":false,"start_time":"2020-09-12T10:35:52.91045","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import numpy as np\nimport random\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport copy\nimport seaborn as sn\n#import mlflow\n\nfrom sklearn import preprocessing\nfrom sklearn.metrics import log_loss\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\n#import mlflow\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from tools.loaders import train_short_form_loader, test_short_form_loader","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"exp_name=\"torch_moa_arch_multilabelv5_smoothed_lrplateau_5_folds_continued\"\n#mlflow.set_experiment(exp_name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def reduce_mem_usage(props):\n    start_mem_usg = props.memory_usage().sum() / 1024**2 \n    print(\"Memory usage of properties dataframe is :\",start_mem_usg,\" MB\")\n    NAlist = [] # Keeps track of columns that have missing values filled in. \n    for col in props.columns:\n        if props[col].dtype != object:  # Exclude strings\n            \n            # Print current column type\n            #print(\"******************************\")\n            #print(\"Column: \",col)\n            #print(\"dtype before: \",props[col].dtype)\n            \n            # make variables for Int, max and min\n            IsInt = False\n            mx = props[col].max()\n            mn = props[col].min()\n            \n            # Integer does not support NA, therefore, NA needs to be filled\n            if not np.isfinite(props[col]).all(): \n                NAlist.append(col)\n                props[col].fillna(mn-1,inplace=True)  \n                   \n            # test if column can be converted to an integer\n            asint = props[col].fillna(0).astype(np.int64)\n            result = (props[col] - asint)\n            result = result.sum()\n            if result > -0.01 and result < 0.01:\n                IsInt = True\n\n            \n            # Make Integer/unsigned Integer datatypes\n            if IsInt:\n                if mn >= 0:\n                    if mx < 255:\n                        props[col] = props[col].astype(np.uint8)\n                    elif mx < 65535:\n                        props[col] = props[col].astype(np.uint16)\n                    elif mx < 4294967295:\n                        props[col] = props[col].astype(np.uint32)\n                    else:\n                        props[col] = props[col].astype(np.uint64)\n                else:\n                    if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n                        props[col] = props[col].astype(np.int8)\n                    elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n                        props[col] = props[col].astype(np.int16)\n                    elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n                        props[col] = props[col].astype(np.int32)\n                    elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n                        props[col] = props[col].astype(np.int64)    \n            \n            # Make float datatypes 32 bit\n            else:\n                props[col] = props[col].astype(np.float32)\n            \n            # Print new column type\n           # print(\"dtype after: \",props[col].dtype)\n           # print(\"******************************\")\n    \n    # Print final result\n    print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n    mem_usg = props.memory_usage().sum() / 1024**2 \n    print(\"Memory usage is: \",mem_usg,\" MB\")\n    print(\"This is \",100*mem_usg/start_mem_usg,\"% of the initial size\")\n    return props, NAlist\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ndef train_short_form_loader(feature_file,target_file,extra_target_file=None):\n    '''takes the original target and features and creates a train dataset \n    in col long format'''\n\n\n    train_features = pd.read_csv(feature_file)\n\n    train_targets = pd.read_csv(target_file)\n    train_features,_= reduce_mem_usage(train_features)\n    train_targets,_ = reduce_mem_usage(train_targets)\n\n\n    if extra_target_file is not None:\n        extra_targets = pd.read_csv(extra_target_file)\n        extra_targets,_ = reduce_mem_usage(extra_targets)\n        train_targets = pd.concat([train_targets,extra_targets])\n        del extra_targets\n\n    targets = train_targets.columns[1:]\n\n    train_melt=train_targets.merge(train_features,how=\"left\",on=\"sig_id\")\n\n\n    del train_features,train_targets\n\n\n    train_melt.set_index(\"sig_id\",inplace=True)\n\n    #train_melt[\"variable\"]= train_melt[\"variable\"].astype('category')\n    train_melt[\"cp_type\"]= train_melt[\"cp_type\"].astype('category')\n    train_melt[\"cp_dose\"]= train_melt[\"cp_dose\"].astype('category')\n\n    return train_melt , targets\n\n\n\ndef test_short_form_loader(feature_file):\n    '''takes the original target and features and creates a train dataset \n    in col long format'''\n\n\n    train_features = pd.read_csv(feature_file)\n\n    #train_targets = pd.read_csv(target_file)\n    train_features,_= reduce_mem_usage(train_features)\n    #train_targets,_ = reduce_mem_usage(train_targets)\n\n    train_melt =  train_features.copy()\n    del train_features\n\n\n    train_melt.set_index(\"sig_id\",inplace=True)\n\n    #train_melt[\"variable\"]= train_melt[\"variable\"].astype('category')\n    train_melt[\"cp_type\"]= train_melt[\"cp_type\"].astype('category')\n    train_melt[\"cp_dose\"]= train_melt[\"cp_dose\"].astype('category')\n\n    return train_melt \n","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-09-12T10:35:54.33849Z","iopub.status.busy":"2020-09-12T10:35:54.337942Z","iopub.status.idle":"2020-09-12T10:35:54.345442Z","shell.execute_reply":"2020-09-12T10:35:54.344993Z"},"papermill":{"duration":0.035524,"end_time":"2020-09-12T10:35:54.34553","exception":false,"start_time":"2020-09-12T10:35:54.310006","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"#os.listdir('../input/lish-moa') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train,target=train_short_form_loader('../input/lish-moa/train_features.csv','../input/lish-moa/train_targets_scored.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-09-12T10:36:00.082793Z","iopub.status.busy":"2020-09-12T10:36:00.082133Z","iopub.status.idle":"2020-09-12T10:36:00.087736Z","shell.execute_reply":"2020-09-12T10:36:00.087244Z"},"papermill":{"duration":0.035085,"end_time":"2020-09-12T10:36:00.087837","exception":false,"start_time":"2020-09-12T10:36:00.052752","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def seed_everything(seed=42):\n    random.seed(seed)\n    #os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_everything(seed=42)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.02481,"end_time":"2020-09-12T10:36:00.405939","exception":false,"start_time":"2020-09-12T10:36:00.381129","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# feature Selection using Variance Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"def supress_controls(df):\n    \n    df = df[train['cp_type']!='ctl_vehicle']\n    df = df.drop('cp_type', axis=1)\n\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def map_controls(df):\n    \n    df['cp_type']=df['cp_type'].map({'ctl_vehicle': 0, 'trt_cp': 1})\n    df['cp_type']=df['cp_type'].astype(int)\n    return df\n\ndef map_dose(df):\n    \n    df['cp_dose']=df['cp_dose'].map({'D1': 1, 'D2': 0})\n    df['cp_dose']=df['cp_dose'].astype(int)\n    return df\n\ndef map_time(df):\n    \n    df['cp_time']=df['cp_time'].map({24: 0, 48: 1, 72: 2})\n    df['cp_time']=df['cp_time'].astype(int)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_preprocess(preprocesses=[map_time,map_dose,map_controls]):\n    \n    def preprocesser(df):\n        for proc in preprocesses:\n            df = proc(df)\n        return df\n    \n    return preprocesser\n    \n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocess_data=build_preprocess()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.027852,"end_time":"2020-09-12T10:36:02.17222","exception":false,"start_time":"2020-09-12T10:36:02.144368","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# CV folds"},{"metadata":{"execution":{"iopub.execute_input":"2020-09-12T10:36:02.23479Z","iopub.status.busy":"2020-09-12T10:36:02.233591Z","iopub.status.idle":"2020-09-12T10:36:04.852035Z","shell.execute_reply":"2020-09-12T10:36:04.850755Z"},"papermill":{"duration":2.652257,"end_time":"2020-09-12T10:36:04.852139","exception":false,"start_time":"2020-09-12T10:36:02.199882","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def multifold_indexer(train,target_columns,n_splits=10,random_state=12347,**kwargs):\n    folds = train.copy()\n\n    mskf = MultilabelStratifiedKFold(n_splits=n_splits,random_state=random_state,**kwargs)\n    folds[ 'kfold']=0\n    for f, (t_idx, v_idx) in enumerate(mskf.split(X=train, y=train[target_columns])):\n        folds.iloc[v_idx,-1] = int(f)\n\n    folds['kfold'] = folds['kfold'].astype(int)\n    return folds\n","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.028651,"end_time":"2020-09-12T10:36:04.977763","exception":false,"start_time":"2020-09-12T10:36:04.949112","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Dataset Classes"},{"metadata":{"execution":{"iopub.execute_input":"2020-09-12T10:36:05.047595Z","iopub.status.busy":"2020-09-12T10:36:05.046831Z","iopub.status.idle":"2020-09-12T10:36:05.049694Z","shell.execute_reply":"2020-09-12T10:36:05.049265Z"},"papermill":{"duration":0.042195,"end_time":"2020-09-12T10:36:05.049792","exception":false,"start_time":"2020-09-12T10:36:05.007597","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"class MoADataset:\n    def __init__(self, features, targets):\n        self.features = features\n        self.targets = targets\n        \n    def __len__(self):\n        return (self.features.shape[0])\n    \n    def __getitem__(self, idx):\n        dct = {\n            'x' : torch.tensor(self.features[idx, :], dtype=torch.float),\n            'y' : torch.tensor(self.targets[idx, :], dtype=torch.float)            \n        }\n        return dct\n    \nclass TestDataset:\n    def __init__(self, features):\n        self.features = features\n        \n    def __len__(self):\n        return (self.features.shape[0])\n    \n    def __getitem__(self, idx):\n        dct = {\n            'x' : torch.tensor(self.features[idx, :], dtype=torch.float)\n        }\n        return dct\n    ","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-09-12T10:36:05.121448Z","iopub.status.busy":"2020-09-12T10:36:05.120667Z","iopub.status.idle":"2020-09-12T10:36:05.123455Z","shell.execute_reply":"2020-09-12T10:36:05.123057Z"},"papermill":{"duration":0.044641,"end_time":"2020-09-12T10:36:05.123539","exception":false,"start_time":"2020-09-12T10:36:05.078898","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def train_fn(model, optimizer, scheduler, loss_fn, dataloader, device):\n    model.train()\n    final_loss = 0\n    \n    for data in dataloader:\n        optimizer.zero_grad()\n        inputs, targets = data['x'].to(device), data['y'].to(device)\n#         print(inputs.shape)\n        outputs = model(inputs)\n        loss = loss_fn(outputs, targets)\n        loss.backward()\n        optimizer.step()\n        \n        if not  scheduler.__class__ ==  torch.optim.lr_scheduler.ReduceLROnPlateau:\n            scheduler.step()\n        \n        final_loss += loss.item()\n        \n    final_loss /= len(dataloader)\n    \n    return final_loss\n\n\ndef valid_fn(model, scheduler, loss_fn, dataloader, device):\n    model.eval()\n    final_loss = 0\n    valid_preds = []\n    \n    for data in dataloader:\n        inputs, targets = data['x'].to(device), data['y'].to(device)\n        outputs = model(inputs)\n        loss = loss_fn(outputs, targets)\n        \n        final_loss += loss.item()\n        valid_preds.append(outputs.sigmoid().detach().cpu().numpy())\n        \n    final_loss /= len(dataloader)\n    valid_preds = np.concatenate(valid_preds)\n    \n    if scheduler.__class__ ==  torch.optim.lr_scheduler.ReduceLROnPlateau:\n        scheduler.step(final_loss)\n    \n    return final_loss, valid_preds\n\ndef inference_fn(model, dataloader, device):\n    model.eval()\n    preds = []\n    \n    for data in dataloader:\n        inputs = data['x'].to(device)\n\n        with torch.no_grad():\n            outputs = model(inputs)\n        \n        preds.append(outputs.sigmoid().detach().cpu().numpy())\n        \n    preds = np.concatenate(preds)\n    \n    return preds\n   \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nfrom torch.nn.modules.loss import _WeightedLoss\nimport torch.nn.functional as F\n\nclass SmoothBCEwLogits(_WeightedLoss):\n    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n        super().__init__(weight=weight, reduction=reduction)\n        self.smoothing = torch.from_numpy(np.array(smoothing)).float().to(DEVICE)\n        self.weight = weight\n        self.reduction = reduction\n\n    @staticmethod\n    def _smooth(targets:torch.Tensor, n_labels:int, smoothing=0.0):\n      #  assert np.all(0 <= smoothing) and  np.all(smoothing < 1)\n        with torch.no_grad():\n            targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n        return targets\n\n    def forward(self, inputs, targets):\n        targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1),\n            self.smoothing)\n        loss = F.binary_cross_entropy_with_logits(inputs, targets,self.weight)\n\n        if  self.reduction == 'sum':\n            loss = loss.sum()\n        elif  self.reduction == 'mean':\n            loss = loss.mean()\n\n        return loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SMOOTHING =[5.01187234e-03, 5.01187234e-03, 3.98107171e-03, 1.00000000e-05,\n       1.58489319e-03, 5.01187234e-04, 1.58489319e-03, 2.51188643e-02,\n       6.30957344e-03, 3.16227766e-04, 1.00000000e-06, 7.94328235e-02,\n       7.94328235e-03, 1.99526231e-03, 6.30957344e-03, 6.30957344e-03,\n       1.58489319e-03, 3.16227766e-04, 5.01187234e-02, 2.51188643e-03,\n       2.51188643e-03, 6.30957344e-04, 7.94328235e-03, 1.58489319e-03,\n       6.30957344e-03, 5.01187234e-03, 6.30957344e-03, 5.01187234e-03,\n       7.94328235e-04, 2.51188643e-03, 5.01187234e-03, 1.58489319e-03,\n       1.58489319e-03, 7.94328235e-03, 7.94328235e-03, 6.30957344e-03,\n       2.51188643e-04, 5.01187234e-03, 2.51188643e-04, 7.94328235e-03,\n       1.00000000e-03, 6.30957344e-04, 2.51188643e-03, 1.00000000e-05,\n       3.16227766e-04, 1.58489319e-04, 6.30957344e-03, 2.51188643e-03,\n       2.51188643e-03, 6.30957344e-04, 3.98107171e-03, 5.01187234e-02,\n       3.16227766e-03, 7.94328235e-03, 2.51188643e-04, 1.99526231e-03,\n       1.25892541e-03, 2.51188643e-03, 2.51188643e-03, 6.30957344e-03,\n       6.30957344e-03, 1.99526231e-04, 5.01187234e-03, 3.98107171e-05,\n       1.25892541e-08, 3.98107171e-03, 1.99526231e-03, 1.58489319e-03,\n       1.25892541e-03, 7.94328235e-03, 3.16227766e-03, 3.98107171e-05,\n       3.16227766e-04, 2.51188643e-03, 3.98107171e-03, 7.94328235e-03,\n       1.58489319e-03, 1.00000000e-08, 6.30957344e-03, 1.58489319e-04,\n       3.16227766e-03, 7.94328235e-03, 7.94328235e-03, 3.98107171e-04,\n       2.51188643e-03, 2.51188643e-03, 5.01187234e-03, 3.98107171e-03,\n       1.00000000e-03, 1.99526231e-02, 5.01187234e-03, 5.01187234e-03,\n       3.98107171e-03, 1.99526231e-02, 2.51188643e-03, 1.00000000e-03,\n       2.51188643e-01, 6.30957344e-03, 6.30957344e-04, 5.01187234e-09,\n       5.01187234e-03, 1.00000000e-03, 6.30957344e-04, 1.58489319e-04,\n       1.00000000e-03, 1.00000000e-06, 3.98107171e-03, 2.51188643e-03,\n       7.94328235e-04, 1.99526231e-03, 3.98107171e-04, 1.99526231e-03,\n       3.16227766e-03, 3.16227766e-03, 7.94328235e-04, 3.16227766e-03,\n       1.58489319e-03, 1.99526231e-03, 3.16227766e-04, 1.99526231e-04,\n       7.94328235e-03, 7.94328235e-03, 1.25892541e-03, 6.30957344e-03,\n       7.94328235e-04, 7.94328235e-03, 3.16227766e-03, 7.94328235e-04,\n       7.94328235e-04, 3.98107171e-03, 6.30957344e-03, 3.16227766e-04,\n       5.01187234e-03, 6.30957344e-05, 1.58489319e-03, 2.51188643e-03,\n       1.25892541e-01, 7.94328235e-03, 3.98107171e-03, 6.30957344e-03,\n       3.16227766e-03, 6.30957344e-03, 5.01187234e-03, 1.00000000e-03,\n       3.98107171e-04, 2.51188643e-03, 7.94328235e-04, 3.98107171e-03,\n       1.00000000e-03, 7.94328235e-05, 5.01187234e-03, 2.51188643e-04,\n       3.98107171e-03, 3.16227766e-05, 3.16227766e-03, 1.00000000e-03,\n       1.99526231e-04, 1.00000000e-04, 3.16227766e-03, 1.58489319e-03,\n       5.01187234e-03, 2.51188643e-03, 3.16227766e-03, 3.98107171e-03,\n       1.58489319e-03, 7.94328235e-03, 1.58489319e-03, 3.98107171e-03,\n       1.58489319e-03, 1.25892541e-03, 6.30957344e-03, 7.94328235e-04,\n       7.94328235e-03, 2.51188643e-03, 1.99526231e-03, 3.16227766e-03,\n       1.00000000e-06, 1.25892541e-04, 1.58489319e-03, 2.51188643e-03,\n       2.51188643e-03, 3.16227766e-03, 3.16227766e-07, 3.16227766e-03,\n       6.30957344e-04, 7.94328235e-03, 5.01187234e-03, 1.00000000e-03,\n       3.16227766e-03, 5.01187234e-03, 3.98107171e-03, 3.16227766e-03,\n       6.30957344e-03, 2.51188643e-03, 1.58489319e-04, 5.01187234e-03,\n       7.94328235e-03, 3.98107171e-03, 1.58489319e-03, 6.30957344e-03,\n       5.01187234e-01, 7.94328235e-03, 7.94328235e-06, 3.98107171e-07,\n       1.58489319e-07, 3.16227766e-07]","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.028912,"end_time":"2020-09-12T10:36:05.183929","exception":false,"start_time":"2020-09-12T10:36:05.155017","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Model_multilabel(nn.Module):\n    def __init__(self, num_features, num_targets, hidden_size1=388,hidden_size2=512,drop_rate1=0.8,drop_rate2=0.8,drop_rate3=0.8):\n        super(Model_multilabel, self).__init__()\n        self.batch_norm1 = nn.BatchNorm1d(num_features)\n        self.dense1 = nn.utils.weight_norm(nn.Linear(num_features, hidden_size1))\n\n        self.batch_norm2 = nn.BatchNorm1d(hidden_size1)\n        self.dropout2 = nn.Dropout(drop_rate2)\n        self.dense2 = nn.utils.weight_norm(nn.Linear(hidden_size1, hidden_size2))\n\n        self.batch_norm3 = nn.BatchNorm1d(hidden_size2)\n        #self.dropout3 = nn.Dropout(drop_rate3)\n        self.dense3 = nn.utils.weight_norm(nn.Linear(hidden_size2, num_targets))\n\n\n    def forward(self, x):\n        \n        x = self.batch_norm1(x)\n        x = F.relu(self.dense1(x))\n        \n        x = self.batch_norm2(x)\n        x = self.dropout2(x)\n        x = F.relu(self.dense2(x))\n        \n        x = self.batch_norm3(x)\n        x = self.dense3(x)\n        \n        return x\n    ","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-09-12T10:36:05.997257Z","iopub.status.busy":"2020-09-12T10:36:05.996385Z","iopub.status.idle":"2020-09-12T10:36:05.999493Z","shell.execute_reply":"2020-09-12T10:36:05.999927Z"},"papermill":{"duration":0.36398,"end_time":"2020-09-12T10:36:06.000056","exception":false,"start_time":"2020-09-12T10:36:05.636076","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# HyperParameters\n\nDEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\nEPOCHS = 100\nBATCH_SIZE = 512\nLEARNING_RATE = 2e-4\nWEIGHT_DECAY = 2e-7\nNFOLDS = 5\nEARLY_STOPPING_STEPS = 10\nEARLY_STOP = False\n\n#num_features=len(feature_cols)\n#num_targets=len(target_cols)\nhidden_size=512\n\n","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.030067,"end_time":"2020-09-12T10:36:06.060856","exception":false,"start_time":"2020-09-12T10:36:06.030789","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Single fold training"},{"metadata":{"trusted":true},"cell_type":"code","source":"def initialize_from_past_model(model,past_model_file):\n\n   # pretrained_dict = torch.load('FOLD0_.pth')\n    pretrained_dict = torch.load(past_model_file)\n    model_dict = model.state_dict()\n\n    pretrained_dict['dense3.bias']=pretrained_dict['dense3.bias'][:206]\n\n    pretrained_dict['dense3.weight_g']=pretrained_dict['dense3.weight_g'][:206]\n\n    pretrained_dict['dense3.weight_v']=pretrained_dict['dense3.weight_v'][:206]\n\n    # 1. filter out unnecessary keys\n    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n    # 2. overwrite entries in the existing state dict\n    model_dict.update(pretrained_dict) \n    # 3. load the new state dict\n    model.load_state_dict(pretrained_dict)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#exp_name =  \"test_flow\"","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-09-12T10:36:06.141206Z","iopub.status.busy":"2020-09-12T10:36:06.134309Z","iopub.status.idle":"2020-09-12T10:36:06.143431Z","shell.execute_reply":"2020-09-12T10:36:06.143903Z"},"papermill":{"duration":0.053144,"end_time":"2020-09-12T10:36:06.14402","exception":false,"start_time":"2020-09-12T10:36:06.090876","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def run_training(X_train,y_train,X_valid,y_valid,X_test,fold, seed,verbose=False,**kwargs):\n    \n    seed_everything(seed)\n    \n   \n    \n    train_dataset = MoADataset(X_train, y_train)\n    valid_dataset = MoADataset(X_valid, y_valid)\n    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n    validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n    \n    model = Model_multilabel(\n        num_features= X_train.shape[1] ,\n        num_targets=  y_train.shape[1],\n        **kwargs\n    )\n    \n    model.to(DEVICE)\n    \n    initialize_from_past_model(model,f\"../results/torch_moa_arch_multilabelv5_smoothed_lrplateau_5_folds_AUX_SEED{seed}_FOLD{fold}.pth\")#,freeze_first_layer=True)\n    \n    \n    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n    #scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e2, \n                                          #max_lr=5e-4, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n    \n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer,patience=3)\n    \n    loss_val = nn.BCEWithLogitsLoss()\n    \n    loss_tr = SmoothBCEwLogits(smoothing =SMOOTHING)\n    \n    early_stopping_steps = EARLY_STOPPING_STEPS\n    early_step = 0\n    \n    #todo el guardado de los resultados se puede mover a kfold que si tiene info de los indices\n    #oof = np.zeros((len(train), target.iloc[:, 1:].shape[1]))\n    best_loss = np.inf\n    \n    \n    \n    \n    for epoch in range(EPOCHS):\n        \n        train_loss = train_fn(model, optimizer,scheduler, loss_tr, trainloader, DEVICE)\n        if verbose:\n            print(f\"FOLD: {fold}, EPOCH: {epoch}, train_loss: {train_loss}\")\n        valid_loss, valid_preds = valid_fn(model,scheduler, loss_val, validloader, DEVICE)\n        if verbose:\n            print(f\"FOLD: {fold}, EPOCH: {epoch}, valid_loss: {valid_loss}\")\n        \n        if valid_loss < best_loss:\n            \n            best_loss = valid_loss\n            oof = valid_preds\n        \n        \n        \n            torch.save(model.state_dict(), f\"../results/{exp_name}_SEED{seed}_FOLD{fold}.pth\")\n        \n        elif(EARLY_STOP == True):\n            \n            early_step += 1\n            if (early_step >= early_stopping_steps):\n                break\n            \n    \n    #--------------------- PREDICTION---------------------\n   \n    testdataset = TestDataset(X_test)\n    testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n    \n#     model = Model(\n#          num_features= X_train.shape[1] ,\n#         num_targets=  y_train.shape[1],\n#         hidden_size=hidden_size,**kwargs\n#     )\n    \n#     model.load_state_dict(torch.load(f\"../results/FOLD{fold}_{exp_name}.pth\"))\n    model.to(DEVICE)\n    \n    #predictions = np.zeros((len(test_), target.iloc[:, 1:].shape[1]))\n    predictions = inference_fn(model, testloader, DEVICE)\n    \n    return oof, predictions\n","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-09-12T10:36:06.210418Z","iopub.status.busy":"2020-09-12T10:36:06.20964Z","iopub.status.idle":"2020-09-12T10:36:06.212328Z","shell.execute_reply":"2020-09-12T10:36:06.21191Z"},"papermill":{"duration":0.038373,"end_time":"2020-09-12T10:36:06.212414","exception":false,"start_time":"2020-09-12T10:36:06.174041","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def run_k_fold(folds,target_cols,test,NFOLDS, seed,verbose=False,**kwargs):\n    \n    \n    train = folds\n    test_ = test\n    \n    \n    #oof = np.zeros((len(folds), len(target_cols)))\n    oof = train[target_cols].copy()\n    predictions = np.zeros((len(test), len(target_cols)))\n    \n    #print(test_.head())\n    for fold in range(NFOLDS):\n        \n        #trn_idx = train[train['kfold'] != fold].reset_index().index\n        #val_idx = train[train['kfold'] == fold].reset_index().index\n    \n        train_df = train[train['kfold'] != fold]#.reset_index(drop=True)\n        valid_df = train[train['kfold'] == fold]#.reset_index(drop=True)\n        \n       # print(len(train_df))\n        #print(len(valid_df))\n        \n        feature_cols = [col  for col in train_df.columns if not (col in target_cols.to_list()+['kfold'])]\n        \n        #print(feature_cols)\n        \n        X_train, y_train  = train_df[feature_cols].values, train_df[target_cols].values\n        X_valid, y_valid =  valid_df[feature_cols].values, valid_df[target_cols].values\n        X_test = test_[feature_cols].values\n            \n        oof_, pred_ = run_training(X_train,y_train,X_valid,y_valid,X_test,fold, seed,verbose,**kwargs)\n        \n        oof[train['kfold'] == fold] = oof_\n        \n        \n        \n        predictions += pred_ / NFOLDS\n        \n        \n    return oof, predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params ={'drop_rate1':0.5,'drop_rate2':0.2,'drop_rate3':0.2}","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-09-12T10:36:06.285683Z","iopub.status.busy":"2020-09-12T10:36:06.28093Z","iopub.status.idle":"2020-09-12T10:39:02.065157Z","shell.execute_reply":"2020-09-12T10:39:02.064159Z"},"papermill":{"duration":175.822637,"end_time":"2020-09-12T10:39:02.065292","exception":false,"start_time":"2020-09-12T10:36:06.242655","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Averaging on multiple SEEDS\n\nSEED = [0,12347,565657,123123,78591]\n#SEED = [0]\ntrain,target_cols = train_short_form_loader('../input/lish-moa/train_features.csv','../input/lish-moa/train_targets_scored.csv')\ntest = test_short_form_loader(\"../input/lish-moa/test_features.csv\")\n\n\n\ntrain = preprocess_data(train)\ntest = preprocess_data(test)\n    \n\noof = np.zeros((len(train), len(target_cols)))\npredictions = np.zeros((len(test), len(target_cols)))\n\nfor seed in SEED:\n   \n    folds = multifold_indexer(train,target_cols,n_splits=NFOLDS)\n    \n    \n    oof_, predictions_ = run_k_fold(folds,target_cols,test,NFOLDS, seed,verbose=True,**params)\n    oof += oof_ / len(SEED)\n    predictions += predictions_ / len(SEED)\n\n#train[target_cols] = oof\ntest[target_cols] = predictions\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" folds['kfold'].unique()","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-09-12T10:39:02.665055Z","iopub.status.busy":"2020-09-12T10:39:02.6644Z","iopub.status.idle":"2020-09-12T10:39:03.734984Z","shell.execute_reply":"2020-09-12T10:39:03.7343Z"},"papermill":{"duration":1.148997,"end_time":"2020-09-12T10:39:03.735124","exception":false,"start_time":"2020-09-12T10:39:02.586127","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"#valid_results = train.drop(columns=target_cols).merge(train[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n#valid_results\n\ny_true = train[target_cols].values\ny_pred = oof\n\nscore = 0\nfor i in range(len(target_cols)):\n   # print(log_loss(y_true[:, i], y_pred[:, i])/ len(target_cols))\n    score_ = log_loss(y_true[:, i], y_pred.iloc[:, i],labels=[0,1])\n    #if score_ > 0.02:\n     #   print(score_)\n    score +=( score_ / len(target_cols))\n    \nprint(\"CV log_loss: \", score)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission = pd.read_csv('../input/lish-moa/sample_submission.csv')\ntest_features = pd.read_csv('../input/lish-moa/test_features.csv')\nsample_submission.set_index('sig_id',inplace=True)\ntest_features.set_index('sig_id',inplace=True)\ntest_features = test_features.loc[sample_submission.index]\n\nsub = sample_submission.drop(columns=target_cols).merge(test[target_cols], on='sig_id', how='left').fillna(0)\n#sub.set_index('sig_id',inplace=True)\nsub.loc[test_features['cp_type']=='ctl_vehicle', target_cols] =0\nsub.to_csv('./submission.csv', index=True)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}