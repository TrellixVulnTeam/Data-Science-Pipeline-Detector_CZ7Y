{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"PATH = '/kaggle/input/lish-moa/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(PATH + 'train_features.csv')\ntest_df = pd.read_csv(PATH + 'test_features.csv')\n\ntarget_df = pd.read_csv(PATH + 'train_targets_scored.csv')\nsub_df = pd.read_csv(PATH + 'sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Признаки**\n- `sig_id` - уникальный идентификатор образца\n- признаки с префиксом `g`- являются признаками экспрессии генов, и их 772 (от `g-0` до `g-771`).\n- признаки с префиксом `c` - являются характеристиками жизнеспособности клеток, их 100 (от `c-0` до `c-99`).\n- `cp_type` - категориальный признак с двумя категориями, который указывает, что образцы обрабатываются составом или управляющим возмущением (trt_cp или ctl_vehicle)\n- `cp_time` - это категориальный признак, который указывает продолжительность лечения (24, 48 или 72 часа)\n- `cp_dose` - категориальный признак с двумя катеuориями, который указывает, что доза низкая или высокая (`D1` или `D2`)"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.drop(['sig_id'], axis=1, inplace=True)\ntest_df.drop(['sig_id'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_df.drop(['sig_id'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_df.sum(axis=1).sample(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Предобработка**"},{"metadata":{"trusted":true},"cell_type":"code","source":"idx = len(train_df)\ndata_df = pd.concat([train_df, test_df], axis = 0)\ndel train_df, test_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nenc = LabelEncoder()\n\ncategory_cols = ['cp_dose', 'cp_type']\n\nfor cols in category_cols:\n    data_df[cols] = enc.fit_transform(data_df[cols])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = data_df.iloc[:idx,:]\nX_test = data_df.iloc[idx:,:]\ny_train = target_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Построение модели**"},{"metadata":{"trusted":true},"cell_type":"code","source":" def create_model():\n    model = tf.keras.Sequential([\n        tf.keras.layers.Input(875),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dense(4096, activation=\"relu\"),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(0.2),\n        tf.keras.layers.Dense(4096, activation=\"relu\"),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(0.2),\n        tf.keras.layers.Dense(206, activation=\"sigmoid\")\n        ])\n    model.compile(optimizer=tf.keras.optimizers.Adam(lr=2.75e-5), loss='binary_crossentropy', metrics=[\"accuracy\"])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\n\ncolumns = target_df.columns\n\ntest_preds = sub_df.copy()\ntest_preds.loc[:,columns] = 0\n\nval_preds = target_df.copy()\nval_preds.loc[:,columns] = 0\n\nkf = KFold(n_splits=5, random_state=42, shuffle=True)  \n\nfor ix, (train_idx, val_idx) in enumerate(kf.split(X_train)):\n    \n    print(f'Fold {ix}')\n\n    model = create_model()\n    reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, epsilon=1e-4, mode='min')\n     \n    X_train_cv, X_val_cv = X_train.iloc[train_idx], X_train.iloc[val_idx]\n    y_train_cv, y_val_cv = y_train.iloc[train_idx], y_train.iloc[val_idx]\n    \n    model.fit(X_train_cv, y_train_cv, \n            validation_data=(X_val_cv, y_val_cv), \n            epochs=30, batch_size=128,\n            callbacks=[reduce_lr_loss], verbose=2)\n    \n    #print(\"Train loss\", model.evaluate(X_train_cv, y_train_cv))\n    #print(\"Val loss\", model.evaluate(X_val_cv, y_val_cv))\n    \n    print(\"Val predict\")    \n    val_preds.loc[val_idx, columns] = model.predict(X_val_cv) \n    \n    print(\"Test predict\")\n    test_preds.loc[:,columns] += model.predict(X_test)\n    \n    print('-'*20)\n    \nval_preds.loc[:,columns] /= 5 \ntest_preds.loc[:,columns] /= 5 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import log_loss\ndef metric(y_true, y_pred):\n    metrics = []\n    for col in columns:\n        metrics.append(log_loss(y_true.loc[:, col], y_pred.loc[:, col].astype(float), labels=[0,1]))\n    return np.mean(metrics)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"OOF Metric: {metric(target_df, val_preds)}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask = X_test['cp_type']=='ctl_vehicle'\ntest_preds[mask] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}