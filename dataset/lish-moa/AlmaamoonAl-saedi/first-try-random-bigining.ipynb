{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport  matplotlib.pyplot as plt\nimport random\n\nfrom sklearn.preprocessing import LabelEncoder\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def seed_everything(seed=999):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    \nseed_everything(49)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drug_featuers = pd.read_csv(\"/kaggle/input/lish-moa/train_features.csv\")\ndrug_featuers.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fet_g = list(drug_featuers)[4:776]\nfet_c = list(drug_featuers)[776:876]\ndrug_featuers['gsum'] = drug_featuers[fet_g].sum(axis=1)\ndrug_featuers['gstd'] = drug_featuers[fet_g].std(axis=1)\ndrug_featuers['gmean'] = drug_featuers[fet_g].mean(axis=1)\ndrug_featuers['gkurtosis'] = drug_featuers[fet_g].kurtosis(axis=1)\ndrug_featuers['gskew'] = drug_featuers[fet_g].skew(axis=1)\n\ndrug_featuers['csum'] = drug_featuers[fet_c].sum(axis=1)\ndrug_featuers['cstd'] = drug_featuers[fet_c].std(axis=1)\ndrug_featuers['cmean'] = drug_featuers[fet_c].mean(axis=1)\ndrug_featuers['ckurtosis'] = drug_featuers[fet_c].kurtosis(axis=1)\ndrug_featuers['cskew'] = drug_featuers[fet_c].skew(axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drug_featuers.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drug_featuers.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drug_y = pd.read_csv(\"/kaggle/input/lish-moa/train_targets_scored.csv\")\ndrug_y.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drug_y2 = pd.read_csv(\"/kaggle/input/lish-moa/train_targets_nonscored.csv\")\ndrug_y2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#merge 2 dataframes based on one column\ndrugs_all = pd.merge(drug_featuers, drug_y, on='sig_id')\n\ndrugs_all.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drugs_all2 = pd.merge(drug_featuers, drug_y2, on='sig_id')\n\ndrugs_all2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = drugs_all.iloc[:, 1:drug_featuers.shape[1]].values\n\nx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = drugs_all.iloc[:, drug_featuers.shape[1]:].values\n\ny","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y2 = drugs_all2.iloc[:, drug_featuers.shape[1]:].values\n\ny2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x[:,1] = x[:,1] / 72\nlabelencoder_x2 = LabelEncoder()\nx[:,2] = labelencoder_x2.fit_transform(x[:,2])\nlabelencoder_x0 = LabelEncoder()\nx[:,0] = labelencoder_x0.fit_transform(x[:,0])\nx[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder \nfrom sklearn.compose import ColumnTransformer \n   \n# creating one hot encoder object with categorical feature 0 \n# indicating the first column \ncolumnTransformer = ColumnTransformer([('encoder', \n                                        OneHotEncoder(), \n                                        [0])], \n                                      remainder='passthrough') \n  \nx = np.array(columnTransformer.fit_transform(x), dtype = np.float32) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from __future__ import absolute_import\nfrom __future__  import division\nfrom __future__ import print_function\nimport tensorflow as tf\nimport numpy as np\nfrom skimage.io import imread\nfrom skimage.transform import resize\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"layers = tf.keras.layers\nmodels = tf.keras.models\nlosses = tf.keras.losses\noptimizers = tf.keras.optimizers \nmetrics = tf.keras.metrics\nutils = tf.keras.utils\ncallbacks = tf.keras.callbacks","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras import regularizers\nimport tensorflow.keras.backend as K\n\np_min = 0.001\np_max = 0.999\ndef logloss(y_true, y_pred):\n    y_pred = tf.clip_by_value(y_pred,p_min,p_max)\n    return -K.mean(y_true*K.log(y_pred) + (1-y_true)*K.log(1-y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras.losses\nkeras.losses.custom_loss = logloss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_classes = 402\n\nmodel = models.Sequential()\n\nmodel.add(tf.keras.Input(shape=(x.shape[1],)))\nmodel.add(layers.BatchNormalization())\n\nmodel.add(layers.Dense(12340))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Dropout(0.4))\n\n\nmodel.add(layers.Dense(4500))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.ReLU())\nmodel.add(layers.Dropout(0.4))\n\n\nmodel.add(layers.Dense(1024))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.ReLU())\nmodel.add(layers.Dropout(0.3))\n\n\nmodel.add(layers.Dense(512))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.ReLU())\nmodel.add(layers.Dropout(0.3))\n\n\n\n\nmodel.add(layers.Dense(256))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.ReLU())\n\n\nmodel.add(layers.Dense(num_classes, activation=\"sigmoid\"))\n\nadam = optimizers.Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\nmodel.compile(loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=0.001), optimizer= adam, metrics=logloss)\n\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def log_loss_metric(y_true, y_pred):\n    metrics = []\n    for _target in y.columns:\n        metrics.append(log_loss(y_true.loc[:, _target], y_pred.loc[:, _target].astype(float), labels = [0,1]))\n    return np.mean(metrics)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class AccuracyHistory(callbacks.Callback):\n    def on_train_begin(self, logs={}):\n        self.acc = []\n        self.val_acc = []\n        self.loss = []\n        self.val_loss = []\n\n    def on_epoch_end(self, batch, logs={}):\n        self.acc.append(logs.get('acc'))\n        self.val_acc.append(logs.get('val_acc'))\n        self.loss.append(logs.get('loss'))\n        self.val_loss.append(logs.get('val_loss'))\n\nhistory = AccuracyHistory()\nearlyStopping = callbacks.EarlyStopping(monitor='val_logloss', patience=4 ,restore_best_weights = True\n                                        ,min_delta=1e-5, verbose=0, mode='min')\nmcp_save = callbacks.ModelCheckpoint('mamon-drugtryrnonescoredpre.hdf5', save_best_only=True, monitor='val_logloss', mode='min')\nreduce_lr_loss = callbacks.ReduceLROnPlateau(monitor='val_logloss',patience=2, verbose=2,factor=0.25,min_lr=0.0000001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size =32\n\nepochs = 5\ny2 = y2.astype('float64') \n\nprint(y2.dtype)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train2, x_val2, y_train2, y_val2 = train_test_split(x, y2, test_size = 0.3, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nmillis = int(round(time.time() * 1000))\nprint(\"started at \" , millis)\n \nmodel.fit(x_train2, y_train2, \n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_val2,y_val2),callbacks=[earlyStopping, mcp_save, reduce_lr_loss,history]\n         )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights('mamon-drugtryrnonescoredpre.hdf5')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.weights","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_classes = 206\n\nmodelscored = models.Sequential()\nmodelscored.add(tf.keras.Input(shape=(x.shape[1],)))\nfor layer in model.layers[:-1]: # go through until last layer\n    modelscored.add(layer)\n\nmodelscored.add(layers.Dense(num_classes, activation=\"sigmoid\"))\nadam = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\nmodelscored.compile(loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=0.001), optimizer= adam, metrics=logloss)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelscored.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelscored.weights","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class AccuracyHistory(callbacks.Callback):\n    def on_train_begin(self, logs={}):\n        self.acc = []\n        self.val_acc = []\n        self.loss = []\n        self.val_loss = []\n\n    def on_epoch_end(self, batch, logs={}):\n        self.acc.append(logs.get('acc'))\n        self.val_acc.append(logs.get('val_acc'))\n        self.loss.append(logs.get('loss'))\n        self.val_loss.append(logs.get('val_loss'))\n\nhistory = AccuracyHistory()\nearlyStopping = callbacks.EarlyStopping(monitor='val_logloss', patience=6 ,restore_best_weights = True\n                                        ,min_delta=1e-5, verbose=0, mode='min')\nmcp_save = callbacks.ModelCheckpoint('mamon-drugtryr3.hdf5', save_best_only=True, monitor='val_logloss', mode='min')\nreduce_lr_loss = callbacks.ReduceLROnPlateau(monitor='val_logloss',patience=3, verbose=2,factor=0.25,min_lr=0.0000001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size =32\n\nepochs = 100\ny = y.astype('float64') \n\nprint(y.dtype)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_val, y_train, y_val = train_test_split(x, y, test_size = 0.3, random_state = 0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nmillis = int(round(time.time() * 1000))\nprint(\"started at \" , millis)\n \nmodelscored.fit(x_train, y_train, \n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_val,y_val),callbacks=[earlyStopping, mcp_save, reduce_lr_loss,history]\n         )\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history.acc\nval_acc = history.val_acc\nloss = history.loss\nval_loss = history.val_loss\nepochs = range(len(acc))\n \nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n \nplt.figure()\n \nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loads the weights\nmodelscored.load_weights('mamon-drugtryr3.hdf5')\n\n# Re-evaluate the model\nloss, acc = modelscored.evaluate(x_val,y_val, verbose=2)\nprint(\"Restored model, accuracy: {:5.5f}%\".format(  acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testdrug_featuers = pd.read_csv(\"/kaggle/input/lish-moa/test_features.csv\")\ntestdrug_featuers.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fet_g = list(testdrug_featuers)[4:776]\nfet_c = list(testdrug_featuers)[776:876]\nprint(testdrug_featuers.shape)\ntestdrug_featuers['gsum'] = testdrug_featuers[fet_g].sum(axis=1)\nprint(testdrug_featuers.shape)\ntestdrug_featuers['gstd'] = testdrug_featuers[fet_g].std(axis=1)\nprint(testdrug_featuers.shape)\ntestdrug_featuers['gmean'] = testdrug_featuers[fet_g].mean(axis=1)\nprint(testdrug_featuers.shape)\ntestdrug_featuers['gkurtosis'] = testdrug_featuers[fet_g].kurtosis(axis=1)\nprint(testdrug_featuers.shape)\ntestdrug_featuers['gskew'] = testdrug_featuers[fet_g].skew(axis=1)\nprint(testdrug_featuers.shape)\ntestdrug_featuers['csum'] = testdrug_featuers[fet_c].sum(axis=1)\nprint(testdrug_featuers.shape)\ntestdrug_featuers['cstd'] = testdrug_featuers[fet_c].std(axis=1)\nprint(testdrug_featuers.shape)\ntestdrug_featuers['cmean'] = testdrug_featuers[fet_c].mean(axis=1)\nprint(testdrug_featuers.shape)\ntestdrug_featuers['ckurtosis'] = testdrug_featuers[fet_c].kurtosis(axis=1)\nprint(testdrug_featuers.shape)\ntestdrug_featuers['cskew'] = testdrug_featuers[fet_c].skew(axis=1)\nprint(testdrug_featuers.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ind_te = testdrug_featuers[testdrug_featuers['cp_type']=='ctl_vehicle'].index\nind_te","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testdrug_featuers.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(testdrug_featuers.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sigid = testdrug_featuers.iloc[:, :1].values\n\nsigid","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtest = testdrug_featuers.iloc[:, 1:].values\n\nxtest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtest.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtest[:,1] = xtest[:,1] / 72\nlabelencoder_xtest = LabelEncoder()\nxtest[:,2] = labelencoder_xtest.fit_transform(xtest[:,2])\nlabelencoder_xtest0 = LabelEncoder()\nxtest[:,0] = labelencoder_xtest0.fit_transform(xtest[:,0])\nxtest[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columnTransformer = ColumnTransformer([('encoder', \n                                        OneHotEncoder(), \n                                        [0])], \n                                      remainder='passthrough') \n  \nxtest = np.array(columnTransformer.fit_transform(xtest), dtype = np.float32) \nxtest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = modelscored.predict(xtest)\ny_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert to submission format\ny_trai4n = pd.read_csv('/kaggle/input/lish-moa/train_targets_scored.csv').drop(columns=['sig_id'])\ncol = y_trai4n.columns\ny_pred_df = pd.DataFrame(y_pred, columns = col)\nsig_id = pd.read_csv('/kaggle/input/lish-moa/test_features.csv')[['sig_id']]\ny_pred_df = sig_id.join(y_pred_df)\n\ny_pred_df.head(200)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_df.loc[ind_te, col] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_df.head(200)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#write to output\ny_pred_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}