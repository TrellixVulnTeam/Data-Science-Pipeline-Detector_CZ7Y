{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":" \nimport numpy as np \nimport pandas as pd \n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        #print(os.path.join(dirname, filename))\n        #print(os.path.join(dirname, filename))\n        if(filename=='train_features.csv'):\n            train_features = pd.read_csv(os.path.join(dirname, filename))\n            print('train_features')\n        if(filename=='test_features.csv'):\n            test_features = pd.read_csv(os.path.join(dirname, filename))\n            print('test_features')    \n        if(filename=='train_targets_scored.csv'):\n            train_targets = pd.read_csv(os.path.join(dirname, filename))\n            print('train_targets')   \n        if(filename=='sample_submission.csv'):\n            sample_submissions = pd.read_csv(os.path.join(dirname, filename))\n            print('sample submissions')       \n            ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_targets.info() #159+37=196 MB","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_targets.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#print(sample_submissions.head())\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(100,100))\n#print(train_targets)\ntrain_targets. acat_inhibitor.hist(bins=30,alpha=0.5)\ntrain_targets. acetylcholine_receptor_agonist.hist(bins=30,alpha=0.5)\ntrain_targets. adenylyl_cyclase_activator.hist(bins=30,alpha=0.5)\ntrain_targets. trpv_agonist .hist(bins=30,alpha=0.5)\ntrain_targets. trpv_antagonist.hist(bins=30,alpha=0.5)\ntrain_targets. tubulin_inhibitor.hist(bins=30,alpha=0.5)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.style.use('ggplot')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col=train_features.columns\nreq_train_col = col[1:]\ncol=train_targets.columns\nreq_train_targets_col = col[1:]\nreq_train_num_cols = train_features._get_numeric_data().columns\nreq_train_cat_cols =  (list(set(req_train_col) - set(req_train_num_cols)))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"All_dataset = train_features[req_train_col]\nAll_dataset[req_train_targets_col]  = train_targets[req_train_targets_col] \nAll_dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#training set\ntrain_features[req_train_col]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#numeric features in the training set\ntrain_features[req_train_num_cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport statsmodels.api as sm\n#Using Pearson Correlation\ntraining_features = train_features[req_train_num_cols[:20]]\ntarget_col = train_targets[req_train_targets_col]\n\n#plt.figure(figsize=(12,10))\n#cor = training_features.corr()\n#sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\n#plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_targets[req_train_targets_col]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Categorical features in the trainig set\ntrain_features[req_train_cat_cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nohe = OneHotEncoder()\nohe.fit(train_features[req_train_cat_cols])\ncat_features = ohe.transform(train_features[req_train_cat_cols])\ncat_features = cat_features.toarray()\ncat_features.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_features_test = ohe.transform(test_features[req_train_cat_cols])\ncat_features_test = cat_features_test.toarray()\ncat_features_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_features = np.array(train_features[req_train_num_cols])\nnum_features.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_features_test = np.array(test_features[req_train_num_cols])\nnum_features_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prepro_training_set =np.hstack((num_features,cat_features))\nX_train = prepro_training_set \nX_train = np.array(prepro_training_set,dtype = 'float')\nX_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prepro_testing_set =np.hstack((num_features_test,cat_features_test))\nX_test = prepro_testing_set \nX_test = np.array(prepro_testing_set,dtype = 'float')\nX_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_train = train_targets[req_train_targets_col].to_numpy()\nY_train = np.array(Y_train,dtype = 'float')\nY_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from skmultilearn.model_selection import iterative_train_test_split\nX_train_part1,Y_train_part1, X_test_part2,Y_test_part2 =  iterative_train_test_split(X_train,Y_train, test_size=0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_part1.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from skmultilearn.problem_transform import BinaryRelevance\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neural_network import MLPClassifier\n\nfrom sklearn.svm import SVC\n\n\nclassifier1 = BinaryRelevance(RandomForestClassifier(random_state=0,n_estimators=30,class_weight=\"balanced_subsample\",n_jobs=-1),require_dense=[False, True])\nclassifier2 = BinaryRelevance(RandomForestClassifier(random_state=0,n_estimators=200,class_weight=\"balanced_subsample\",n_jobs=-1),require_dense=[False, True])\nclassifier3 = BinaryRelevance(BaggingClassifier(LogisticRegression(random_state = 1,n_jobs=-1),n_estimators=5,bootstrap = True,n_jobs=-1),require_dense=[False, True])\nclassifier4 = BinaryRelevance(MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(600,500,400,206), random_state=1),require_dense=[False, True])\n\n#classifier = GridSearchCV(BinaryRelevance(), parameters, scoring='accuracy')\n# train\n#classifier.fit(X_train, Y_train)\n\n# predict\n#predictions = classifier.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\n\nX_NN_scaled_without_Binary_features = preprocessing.scale(X_train_part1[:,:-4])\nX_NN_scaled_with_Binary_features = np.concatenate((X_NN_scaled_without_Binary_features,X_train_part1[:,-4:]),axis=1)\n\nX_NN_Val_scaled_without_Binary_features = preprocessing.scale(X_test_part2[:,:-4])\nX_NN_Val_with_Binary_features = np.concatenate((X_NN_Val_scaled_without_Binary_features,X_test_part2[:,-4:]),axis=1)\n\nX_NN_test_scaled_without_Binary_features = preprocessing.scale(X_test[:,:-4])\nX_NN_test_with_Binary_features = np.concatenate((X_NN_test_scaled_without_Binary_features,X_test[:,-4:]),axis=1)\n\n\n\n   \n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred4_on_test = np.zeros((3982,),float)\npred4_on_train_Part1 = np.zeros((16669,),float)\npred4_on_test_Part2 = np.zeros((7145,),float)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nimport numpy as np\nfrom keras.models import Sequential\nfrom sklearn.utils import class_weight\nimport random as python_random\nimport tensorflow as tf\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom tensorflow.keras import regularizers\nmodels = []\nfor i in range(0,206,1):\n    np.random.seed(1337)\n    model = Sequential()\n    model.add(Dense(600,input_shape=(877,),activation=\"relu\"))\n    model.add(Dense(500,activation=\"relu\"))\n    model.add(Dense(400,activation=\"relu\"))\n    model.add(Dense(350,activation=\"relu\"))\n    model.add(Dense(300,activation=\"relu\"))\n    model.add(Dense(250,activation=\"relu\"))\n    model.add(Dense(200,activation=\"relu\"))\n    model.add(Dense(150,activation=\"relu\"))\n    model.add(Dense(100,activation=\"relu\"))\n    model.add(Dropout(0.25,seed=0))\n    model.add(Dense(2,activation=\"softmax\"))\n    my_callbacks = [\n    keras.callbacks.EarlyStopping(patience=5)\n    ]\n    class_weights = class_weight.compute_class_weight('balanced',np.unique(Y_train_part1[:,i]),Y_train_part1[:,i])\n    SGD = keras.optimizers.SGD(learning_rate=0.1,decay=0.1/40,momentum=0.9,nesterov=True)\n    model.compile(loss=\"binary_crossentropy\",optimizer=SGD,metrics=[\"accuracy\"])\n    print(\"trainig model \",format(i))\n    \n    model.fit(X_NN_scaled_with_Binary_features ,Y_train_part1[:,i],callbacks=my_callbacks,class_weight={0:2,1:1},validation_split=0.3,epochs=100,batch_size=64,verbose=True)\n    \n    pred4_on_test_star = model.predict(X_NN_test_with_Binary_features,batch_size=64)\n    pred4_on_train_Part1_star = model.predict(X_NN_scaled_with_Binary_features,batch_size=64)\n    pred4_on_test_Part2_star = model.predict(X_NN_Val_with_Binary_features,batch_size=64)\n    \n    pred4_on_test_yet= np.where(pred4_on_test_star[:,1] >= 0.5, 1, 0)\n    pred4_on_train_Part1_yet= np.where(pred4_on_train_Part1_star[:,1] >= 0.5, 1, 0)\n    pred4_on_test_Part2_yet= np.where(pred4_on_test_Part2_star[:,1] >= 0.5, 1, 0)\n    \n    pred4_on_test = np.c_[pred4_on_test, pred4_on_test_yet]\n    pred4_on_test_Part2 = np.c_[pred4_on_test_Part2, pred4_on_test_Part2_yet]\n    pred4_on_train_Part1 = np.c_[pred4_on_train_Part1, pred4_on_train_Part1_yet]\n    \n    if(i==0):\n        pred4_on_test = np.delete(pred4_on_test, 0, 1)\n        pred4_on_test_Part2 = np.delete(pred4_on_test_Part2, 0, 1)\n        pred4_on_train_Part1 = np.delete(pred4_on_train_Part1, 0, 1)\n    \n\n    \n  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier1.fit(X_train_part1, Y_train_part1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_scaled_for_Logis_without_Binary_features = preprocessing.scale(X_train_part1[:,:-4])\nX_scaled_for_Logis_with_Binary_features = np.concatenate((X_scaled_for_Logis_without_Binary_features,X_train_part1[:,-4:]),axis=1)\n\nX_Val_scaled_for_Logis_without_Binary_features = preprocessing.scale(X_test_part2[:,:-4])\nX_Val_scaled_for_Logis_with_Binary_features = np.concatenate((X_Val_scaled_for_Logis_without_Binary_features,X_test_part2[:,-4:]),axis=1)\n\nX_test_scaled_for_Logis_without_Binary_features = preprocessing.scale(X_test[:,:-4])\nX_test_scaled_for_Logis_with_Binary_features = np.concatenate((X_test_scaled_for_Logis_without_Binary_features,X_test[:,-4:]),axis=1)\n\n\n\nclassifier3.fit(X_scaled_for_Logis_with_Binary_features, Y_train_part1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_scaled_for_SVC_with_Binary_features=X_scaled_for_Logis_with_Binary_features\n#classifier4.fit(X_scaled_for_SVC_with_Binary_features, Y_train_part1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred1_on_test = classifier1.predict(X_test)\npred1_on_test = pred1_on_test.toarray()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred1_on_train_Part1 = classifier1.predict(X_train_part1)#تقييم النموذج الثاني\npred1_on_train_Part1 = pred1_on_train_Part1.toarray()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred1_on_test_Part2 = classifier1.predict(X_test_part2)#تقيمم النموذج  الاول\npred1_on_test_Part2 = pred1_on_test_Part2.toarray()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"                                              \npred2_on_test = classifier3.predict(X_test_scaled_for_Logis_with_Binary_features)\npred2_on_test = pred2_on_test.toarray()#للشركه","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred2_on_train_Part1 = classifier3.predict(X_scaled_for_Logis_with_Binary_features)\npred2_on_train_Part1 = pred2_on_train_Part1.toarray() #تقييم النموذج الثاني\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\npred2_on_test_Part2 = classifier3.predict(X_Val_scaled_for_Logis_with_Binary_features)#تقيمم النموذج  الاول\npred2_on_test_Part2 = pred2_on_test_Part2.toarray()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pred3_on_test = classifier4.predict(X_test)\n#pred3_on_test = pred2_on_test.toarray()#","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pred3_on_train_Part1 = classifier4.predict(X_train_part1)#\n#pred3_on_train_Part1 = pred2_on_train_Part1.toarray() #","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pred3_on_test_Part2 = classifier4.predict(X_test_part2)\n#pred3_on_test_Part2 = pred2_on_test_Part2.toarray()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_DT_on_70 = np.concatenate((pred1_on_train_Part1,pred2_on_train_Part1),axis=1)\nX_train_DT_on_70 = np.concatenate((X_train_DT_on_70,pred4_on_train_Part1),axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier2.fit(X_train_DT_on_70, Y_train_part1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_input_to_DT  = np.concatenate((pred1_on_test,pred2_on_test),axis=1)\ntest_input_to_DT  = np.concatenate((test_input_to_DT,pred4_on_test),axis=1)\nVal_Input_to_DT   = np.concatenate((pred1_on_test_Part2,pred2_on_test_Part2),axis=1)\nVal_Input_to_DT   = np.concatenate((Val_Input_to_DT,pred4_on_test_Part2),axis=1)\ntrain_Input_to_DT = np.concatenate((pred1_on_train_Part1,pred2_on_train_Part1),axis=1)\ntrain_Input_to_DT = np.concatenate((train_Input_to_DT,pred4_on_train_Part1),axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Val_pred_DT = classifier2.predict(Val_Input_to_DT)\ntrain_pred_DT = classifier2.predict(train_Input_to_DT)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Val_pred_DT = Val_pred_DT.toarray()\ntrain_pred_DT = train_pred_DT.toarray()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred4_on_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_test_part2[:,0].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred4_on_train_Part1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import log_loss\nmetric = log_loss(y_pred=Val_pred_DT,y_true=Y_test_part2)\nmetric","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" parameters = [{\n              \"classifier\" : [DecisionTreeClassifier()],\n              \"classifier__max_depth\": [6,8]\n              }]\n\n#classifier3 = GridSearchCV(BinaryRelevance(), parameters, scoring='accuracy', cv = 5,n_jobs=-1)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#classifier2.get_params().keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#classifier3.fit(X_train_part1, Y_train_part1)\n#print (classifier3.best_params_, classifier3.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Final_pred_on_test = classifier2.predict(test_input_to_DT)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from sklearn.model_selection import KFold\n#from sklearn.metrics import log_loss\n#kf = KFold(n_splits=5, random_state=42, shuffle=True)\n#fold_metrics = []\n#for train_index , Val_index in  kf.split(X_train):\n#    X_train, X_Val = X_train[train_index], X_train[Val_index]\n#    Y_train, Y_Val = Y_train[train_index], Y_train[Val_index]\n#    classifier.fit(X_train, Y_train)\n#    predictions = classifier.predict(X_Val)\n#    predictions = predictions.toarray()\n#    metric = log_loss(y_pred=predictions,y_true=Y_Val)\n#    fold_metrics.append(metric)\n#mean_score = np.mean(fold_metrics)    \n#overall_score_minimizing = np.mean(fold_metrics) + np.std(fold_metrics)\n#overall_score_maximizing = np.mean(fold_metrics) - np.std(fold_metrics)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Testing"},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = Final_pred_on_test.toarray()\npred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# submission"},{"metadata":{"trusted":true},"cell_type":"code","source":" sample_submissions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = train_features.columns\ntargets  = train_targets.columns[1:]\npred = np.array(pred,dtype='float')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = pd.DataFrame(pred,columns = targets)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred['sig_id'] = test_features['sig_id']\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pred[train_targets.columns]\nsubmission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv(\"/kaggle/working/submission.csv\",index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}