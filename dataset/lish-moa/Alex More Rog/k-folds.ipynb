{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/lish-moa/train_features.csv')\ntarget = pd.read_csv('/kaggle/input/lish-moa/train_targets_scored.csv')\ndel data['sig_id']\n\ncategorical_cols = ['cp_type', 'cp_dose']\ncategorical_features = data[categorical_cols]\ndata.drop(categorical_cols, axis=1, inplace=True)\ncategorical_features = OneHotEncoder(sparse=False).fit_transform(categorical_features)\ndata = StandardScaler().fit_transform(data)\n\nX = np.concatenate((categorical_features, data), axis=1)\ny = target.to_numpy()[:,1:].astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def k_folds_gen(*arrs, test_size=0.1):\n    indeces = np.random.permutation(arrs[0].shape[0])\n    \n    batch_size = int(arrs[0].shape[0] * 0.1)\n    for start in range(0, len(indeces), batch_size):\n        indx_val = indeces[start: start+batch_size]\n        indx_train = np.concatenate((indeces[:start], indeces[start+batch_size:]), axis=0)\n        \n        to_return = []\n        for arr in arrs:\n            to_return.append(arr[indx_train])\n            to_return.append(arr[indx_val])\n        yield tuple(to_return)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def batch_iterator(*arrs, batch_size):\n    indeces = np.random.permutation(arrs[0].shape[0])\n    \n    \n    for start in range(0, len(indeces), batch_size):\n        indx = indeces[start: start+batch_size]\n        to_return = []\n        for arr in arrs:\n            to_return.append(arr[indx])\n        yield tuple(to_return)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def create_N_models(N, device):\n    models = [None] * N\n    for i in range(len(models)):\n        models[i] = nn.Sequential(\n            nn.Linear(877, 256),\n            nn.BatchNorm1d(256),\n            nn.Dropout(p=0.8),\n            nn.LeakyReLU(),\n            nn.Linear(256, 206),\n            nn.Sigmoid(),\n        )\n        models[i].to(device)\n    return models","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodels = create_N_models(10, device)\nfor i in range(len(models)):\n    models[i].load_state_dict(torch.load(f\"/kaggle/input/k-folds-weights/model_{i}.pth\", map_location=device))\nbatch_size=128","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# n = 3\n# prob = 10 / 206\n# criterion = nn.BCELoss()\n# k_fold_generator = iter(k_folds_gen(X, y, test_size=0.1))\n\n# for model in models:\n#     opt = torch.optim.Adam(model.parameters())\n    \n#     final_loss = []\n#     final_val_loss = []\n#     final_true_loss = []\n    \n#     X_train, X_val, y_train, y_val = next(k_fold_generator)\n    \n#     for i in range(250):\n#         model.train()\n#         losses = []\n#         true_losses = []\n\n#         for X_batch, y_batch in batch_iterator(X_train, y_train, batch_size=batch_size):\n\n#             X_batch = torch.tensor(X_batch, dtype=torch.float32).to(device)\n\n#             true_y_batch = torch.tensor(y_batch, dtype=torch.float32).to(device)\n#             ind = np.random.randint(0, y_batch.shape[0], size=n)\n#             y_batch[ind] = np.ones_like(y_batch[ind]) * (np.random.rand(n, 206) < prob)\n#             y_batch = torch.tensor(y_batch, dtype=torch.float32).to(device)\n\n#             p = model(X_batch)\n#             true_loss = criterion(p, true_y_batch)\n#             loss = criterion(p, y_batch)\n#             total_loss = loss + 0.0001*sum(map(lambda x: torch.sum(x**2), list(model.parameters())[-1:]))\n#             total_loss.backward()\n#             opt.step()\n#             opt.zero_grad()\n#             losses.append(loss.cpu().detach().numpy())\n#             true_losses.append(true_loss.cpu().detach().numpy())\n\n#         for g in opt.param_groups:\n#             g['lr'] = g['lr']*0.99\n\n#         loss = np.mean(losses)\n#         final_loss.append(loss)\n#         final_true_loss.append(np.mean(true_losses))\n#         losses = []\n#         model.eval()\n#         with torch.no_grad():\n#             for X_batch, y_batch in batch_iterator(X_val, y_val, batch_size=batch_size):\n\n#                 X_batch = torch.tensor(X_batch, dtype=torch.float32).to(device)\n#                 y_batch = torch.tensor(y_batch, dtype=torch.float32).to(device)\n\n#                 p = model(X_batch)           \n#                 loss = criterion(p, y_batch)\n#                 losses.append(loss.cpu().detach().numpy())\n#         val_loss = np.mean(losses)\n#         final_val_loss.append(val_loss)\n        \n#         if (i+1) % 10 == 0:\n#             print('Iteration {}'.format(i+1))\n#             print('  {:.5f} loss'.format(final_loss[-1]))\n#             print('  {:.5f} true loss'.format(final_true_loss[-1]))\n#             print('  {:.5f} val loss'.format(val_loss))\n#         if final_true_loss[-1] < 0.015 and val_loss < 0.015:\n#             break\n\n#     plt.plot(final_loss, label='train_loss')\n#     plt.plot(final_val_loss, label='val_loss')\n#     plt.plot(final_true_loss, label='true_train_loss')\n#     plt.legend()\n#     plt.ylim(0, 0.020)\n#     plt.grid()\n#     plt.xticks(range(0, epoch+1, 10))\n#     plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = pd.read_csv('/kaggle/input/lish-moa/test_features.csv')\nsig_id = test_data['sig_id']\ndel test_data['sig_id']\n\ncategorical_features = test_data[categorical_cols]\ntest_data.drop(categorical_cols, axis=1, inplace=True)\ncategorical_features = OneHotEncoder(sparse=False).fit_transform(categorical_features)\ntest_data = StandardScaler().fit_transform(test_data)\nX_test = np.concatenate((categorical_features, test_data), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(models)):\n    models[i].eval()\n    \nwith torch.no_grad():\n    predictions = (sum(map(lambda x: x(torch.tensor(X_test, dtype=torch.float32).to(device)), models)) /\n                   len(models)).to('cpu').detach().numpy()\npredictions.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame(predictions)\nsubmission.columns = target.columns[1:]\nsubmission['sig_id'] = sig_id\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}