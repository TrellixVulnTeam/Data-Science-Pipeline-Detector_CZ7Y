{"cells":[{"metadata":{},"cell_type":"markdown","source":"# PCA + Logistic Regression\n\nI here present my notebook with a simple treatment of the data. I will make use of PCA and logistic regression only. Let's import the necessary packets."},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport sys\nimport time\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import log_loss\n\nsys.path.append('../input/iterative-stratification/iterative-stratification-master')\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\n\nimport pdb","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"now the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"dir_data = '/kaggle/input/lish-moa/'\ndf_train_orig = pd.read_csv(dir_data + 'train_features.csv', index_col=0)\ndf_target_orig = pd.read_csv(dir_data + 'train_targets_scored.csv', index_col=0)\ndf_target_nonscored_orig = pd.read_csv(dir_data + 'train_targets_nonscored.csv', index_col=0)\ndf_submiss = pd.read_csv(dir_data + 'sample_submission.csv', index_col=0)\ndf_test_orig = pd.read_csv(dir_data + 'test_features.csv', index_col=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_orig.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Two columns ('cp_type' and 'cp_dose') are categorical. The 'cp_type' column has just two values: one ('trt_cp') indicates samples treated with a compound, the other one ('ctl_vehicle') it's a control sample and has no MoAs. Let's check it. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_orig['cp_type'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idx_vehicle = df_train_orig[df_train_orig['cp_type'] == 'ctl_vehicle'].index\ndf_target_orig.loc[idx_vehicle].sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_target_orig.loc[idx_vehicle].sum().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"this will be useful later, since we know that any sample with 'cp_type' == 'ctl_vehicle' has target zero for any MoA.\nMoAs represent the particular actions of the drugs under analysis. Let's see how many examples there are for each MoA=1"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_target_orig.sum(axis=0).sort_values()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For 'nfkb_inhibitor' there are 832 examples, while for 'atp-sensitive_potassium_channel_antagonist' and 'erbb2_inhibitor' there is just one. This can make troubles later, so we add one dummy value for each one. Besides, the training set is unbalanced."},{"metadata":{"trusted":true},"cell_type":"code","source":"ds_to_plot = df_target_orig.sum(axis=0).sort_values()\n\nplt.figure(figsize=(16,8))\nplt.bar(height=ds_to_plot, x=range(len(ds_to_plot)), tick_label=ds_to_plot.index.tolist())\nplt.xticks(ticks=range(len(ds_to_plot)),labels=ds_to_plot.index.tolist(), rotation=90, fontsize=3)\nplt.xlabel('MoA')\nplt.ylabel('number of samples')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's duplicate the rows having just one example for MoAs 'atp_sensitive_potassium_channel_antagonist' and 'erbb2_inhibitor' (otherwise MultilabelStratifiedShuffleSplit will complain with just one example)."},{"metadata":{"trusted":true},"cell_type":"code","source":"#consider non-categorical values only\ncols_no_cp = df_train_orig.columns[3:]\n#cols targets that has only one example\ncols_oneEx =df_target_orig.columns[df_target_orig.sum(axis=0) == 1].tolist()\n#boolean to select the ids\nboole = (df_target_orig[cols_oneEx[0]] == 1) | (df_target_orig[cols_oneEx[1]] == 1)\nids_oneEx = df_target_orig.loc[boole].index.tolist()\nids_oneEx_dummy = [i + '_dum' for i in ids_oneEx]\n#create dummy values for ids_oneEx\ndf_train_orig.loc[ids_oneEx_dummy[0]] = df_train_orig.loc[ids_oneEx[0]] \ndf_train_orig.loc[ids_oneEx_dummy[1]] = df_train_orig.loc[ids_oneEx[1]] \ndf_target_orig.loc[ids_oneEx_dummy[0]] = df_target_orig.loc[ids_oneEx[0]]\ndf_target_orig.loc[ids_oneEx_dummy[1]] = df_target_orig.loc[ids_oneEx[1]]\n#add dummy features\ndf_train_orig.loc[ids_oneEx_dummy[0],cols_no_cp] = df_train_orig.loc[ids_oneEx[0],cols_no_cp] + 0.1\ndf_train_orig.loc[ids_oneEx_dummy[1],cols_no_cp] = df_train_orig.loc[ids_oneEx[1],cols_no_cp] + 0.1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"apply one-hot-encoding for categorical values to both training and test sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"#put together the two sets in order to apply the same one-hot-encoding\n#first identify the train from the test set\nidx_train = df_train_orig.index\nidx_test = df_test_orig.index\n#put them together\ndf_all = pd.concat([df_train_orig,df_test_orig])\n#get dummies for categorical variables\ndf_all = pd.get_dummies(df_all)\n#separate the two sets\ndf_train = df_all.loc[idx_train]\ndf_test = df_all.loc[idx_test]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Short discussion on the number of MoAs for each example\nLet's check if every sample has one or more MoAs"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_target_orig.sum(axis=1).sort_values().unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"so, there can be up to 7 MoAs for one sample. Let's see how many"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_target_orig.sum(axis=1).value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we see that only 6 examples have 7 MoAs while 9367 samples have 0 MoAs. Are the latter all 'ctl_vehicle'?"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('numer of ctl_vehicles= ', len(idx_vehicle))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"therefore, there are 9367-1866 examples that have no MoAs but are not control sample. How can it be? \nActually, we found that these samples have MoAs in the file 'train_targets_nonscored.csv'. Let's put the two together and drop the 'idx_vehicle' rows"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_target_whole = df_target_orig.join(df_target_nonscored_orig, how='left')\ndf_target_whole.drop(idx_vehicle, inplace=True)\ndf_target_whole.sum(axis=1).value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we actually see that the number of samples with 'ctl_vehicle'=trt_cp having no MoAs are 3664. This suggest that the data are not complete, i.e. these are examples which MoA are not reported in the data. \n\nHowever, we are not using the non-scored data in our analysis."},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"## Preparation of the model"},{"metadata":{},"cell_type":"markdown","source":"Let's apply PCA (keeping 90% of the information), standard scaler and logistic regression, putting everything together in a pipeline. We use MultiOutput classifier."},{"metadata":{"trusted":true},"cell_type":"code","source":"pca=PCA(n_components=0.9)\nscaler = StandardScaler()\nlogistic = LogisticRegression(max_iter=10000, tol=0.1, C = 0.008)# C=0.008 appears to be the best after some tests\npipe = Pipeline(steps=[('scaler', scaler),('pca', pca),('moc',MultiOutputClassifier(logistic,n_jobs=-1))])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we split the sample using stratification to keep the ratio of the samples."},{"metadata":{"trusted":true},"cell_type":"code","source":"sss = MultilabelStratifiedShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\nX = df_train\ny = df_target_orig","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now some useful function to compute the log loss and predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def log_loss_metric(y_true, y_pred):\n    metrics = []\n    for i in np.arange(y_true.shape[1]):\n        metrics.append(log_loss(y_true[:, i].astype(float), y_pred[:, i].astype(float), labels = [0,1]))\n    return np.mean(metrics)\n\n###############################################\ndef compute_logloss_0(clf, X, y, string):\n\n    proba = clf.predict_proba(X)\n    y_pred=np.zeros(y.shape)\n\n    for i,val in enumerate(proba):\n        y_pred[:,i] = val[:,1]\n\n    logloss_value = log_loss_metric(y.values,y_pred)\n    print(string + ' log loss ', logloss_value)\n\n    return y_pred\n###############################################\ndef predict_test(clf, X, y):\n\n\n    proba = clf.predict_proba(X)\n\n    y_pred=np.zeros(y.shape)\n    for i,val in enumerate(proba):\n        y_pred[:,i] = val[:,1]\n\n    return y_pred\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_list = []\nfor i, (train_index, test_index) in enumerate(sss.split(X, y)):\n    X_train_sss, X_test_sss = X.iloc[train_index], X.iloc[test_index]\n    y_train_sss, y_test_sss = y.iloc[train_index], y.iloc[test_index]\n\n    pipe.fit(X_train_sss,y_train_sss)\n    print('*** split n =', i, ' ***')\n    y_pred_train_sss = compute_logloss_0(pipe, X_train_sss, y_train_sss, 'X_train_sss ')\n    y_pred_test_sss = compute_logloss_0(pipe, X_test_sss, y_test_sss, 'X_test_sss ')\n    y_pred = predict_test(pipe, df_test, df_submiss)\n    y_pred_list.append(y_pred)\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"#compute the mean\ny_pred_mean = np.array(y_pred_list).mean(axis=0)\n#prepare the submission dataframe\ndf_sub = pd.DataFrame(y_pred_mean, columns=df_submiss.columns, index=idx_test)\n#set the 'ctl_vehicle' to zero\nidx_test_vehicle = df_test_orig[df_test_orig['cp_type'] == 'ctl_vehicle'].index\ndf_sub.loc[idx_test_vehicle] = 0.0\n#reset index\ndf_sub.reset_index(inplace=True)\n#write\ndf_sub.to_csv('submission.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}