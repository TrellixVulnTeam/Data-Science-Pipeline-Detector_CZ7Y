{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nimport tensorflow.keras.layers as L\nimport tensorflow.keras.models as M\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\nimport tensorflow_addons as tfa\nfrom sklearn.model_selection import KFold, train_test_split\nfrom sklearn.metrics import log_loss\nfrom tqdm.notebook import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model(num_columns):\n    model = tf.keras.Sequential([\n    tf.keras.layers.Input(num_columns),\n#     tf.keras.layers.BatchNormalization(),\n    tfa.layers.WeightNormalization(tf.keras.layers.Dense(1048, activation=\"relu\")),\n    tf.keras.layers.BatchNormalization(),\n    #tf.keras.layers.Dropout(0.2),\n    tfa.layers.WeightNormalization(tf.keras.layers.Dense(548, activation=\"relu\")),\n    tf.keras.layers.BatchNormalization(),\n    #tf.keras.layers.Dropout(0.8),\n    tfa.layers.WeightNormalization(tf.keras.layers.Dense(248, activation=\"relu\")),\n    tf.keras.layers.BatchNormalization(),\n    tfa.layers.WeightNormalization(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n    ])\n    model.compile(optimizer=tfa.optimizers.Lookahead(tf.optimizers.Adam(), sync_period=10),\n                  loss='binary_crossentropy', \n                  )\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def custom_log_loss(y_true, y_pred):\n    s = 0.0\n    for i in range(y_true.shape[0]):\n        s+=y_true[i]*np.log(y_pred[i])+(1-y_true[i])*np.log(1-y_pred[i])\n    \n    return s/(-y_true.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"eps, weight_tg, weight_x3, weight_x5 = 10**(-5), 0.0, 0.0, 0.0 # last couple =0.0\nweight = 1.0 - weight_tg - weight_x3 - weight_x5\n\n\ndef cube(x):\n    x /= 10.0\n    return 10.0 * x*x*x\ndef tgfunc(x):\n    return  np.tan(np.pi *x/ 4.0) \ndef application_transform(x):\n    \"\"\"    x = 2*x-1.0\n    x1 = weight_tg*tgfunc(x) + (weight_x3 + weight_x5*x**2)*x**3 + weight*x\n    x1 = x1/2 + 0.5\"\"\"\n    x1 = x\n    if x1 < eps:\n        x1 = eps\n    elif x1 >= 1 - eps:\n        x1 = 1 - eps\n    return x1\n\ndef transform(x):\n    x = x[x['cp_type']=='trt_cp']\n    x.pop('cp_type')\n    x['cp_dose'] = x['cp_dose'].replace({'D1':-1, 'D2':1})\n    x['cp_time'] = x['cp_time'] // 24\n    x.join(pd.get_dummies(x['cp_time']))\n    x.pop('cp_time')\n    return x\n\nX_all = pd.read_csv('/kaggle/input/lish-moa/train_features.csv')\ny_all = pd.read_csv('/kaggle/input/lish-moa/train_targets_scored.csv')\nX = transform(X_all[X_all.columns[1:]])\nY = y_all[X_all['cp_type']=='trt_cp']\nY = Y[Y.columns[1:]]\ndef metric(y_true, y_pred):\n    metrics = []\n    for _target in train_targets.columns:\n        metrics.append(log_loss(y_true.loc[:, _target], y_pred.loc[:, _target].astype(float), labels=[0,1]))\n    return np.mean(metrics)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y.transpose().iloc[1].transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def write_results(drug_no, val_loss, time_to_train):\n    return {\n        'drug_no': drug_no,\n        #'random_state': random_state,\n        'val_loss': val_loss,\n        'time_to_train' : time_to_train\n    }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_results = []\nimport time","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfor drug_i in range(206):\n#for random_state in range(2020,2070,10):\n    Y_new = Y.transpose().iloc[drug_i].transpose()\n    checkpoint_path = f'drug_no{drug_i+1}_rs.hdf5'\n    early_stopping = tf.keras.callbacks.EarlyStopping(patience=8)\n    reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=8, verbose=1, epsilon=1e-4, mode='min')\n    cb_checkpt = ModelCheckpoint(checkpoint_path, monitor = 'val_loss', verbose = 0, save_best_only = True,\n                                 save_weights_only = True, mode = 'min')\n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y_new, test_size=0.2 \n                                                            #,random_state=random_state\n                                                       )\n\n    print(f'beginning training on drug no.{drug_i+1} ')\n    model = create_model(X.shape[1])\n    t0 = time.clock()\n    model.fit(X_train, Y_train,\n              validation_data=(X_test, Y_test), \n              epochs=50, batch_size=128,verbose=2,\n              callbacks=[reduce_lr_loss, cb_checkpt, early_stopping])\n    model.load_weights(checkpoint_path)\n    t1 = time.clock()\n    test_predict = np.array(list(map(application_transform, model.predict(X_test))))\n    \n\n    \"\"\"df = pd.DataFrame(subm)\n    df = df.applymap(application_transform)\n    df = np.array(df).reshape(dim)\n    \"\"\"\n\n    cur_loss = custom_log_loss(np.array(Y_test),test_predict)\n    train_results.append(write_results(drug_i, cur_loss, t1-t0))\n    print('==================================================')\n    print(f'loss on validation: {cur_loss}')\n    print(f'time for training: {t1-t0} sec')\n    print('==================================================')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(train_results).to_csv('train_res.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"custom_log_loss(np.zeros(100), np.array(list(map(application_transform, np.zeros(100)))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}