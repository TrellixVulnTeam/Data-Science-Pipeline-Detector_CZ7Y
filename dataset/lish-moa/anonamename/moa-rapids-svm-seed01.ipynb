{"cells":[{"metadata":{},"cell_type":"markdown","source":"https://www.kaggle.com/gogo827jz/rapids-svm-on-gpu-6000-models-in-1-hour"},{"metadata":{"trusted":true},"cell_type":"code","source":"# OSError: [Errno 28] No space left on device: 対策\n# https://www.kaggle.com/getting-started/45288\n%env JOBLIB_TEMP_FOLDER=/tmp\n\n# これ入れてもだめ。出力ファイルは20GBまでしか保存できないため5seedは失敗する。1seedで8GBぐらい出力\n# https://www.kaggle.com/product-feedback/155538\n# https://www.kaggle.com/docs/notebooks#technical-specifications","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings, sys\nwarnings.filterwarnings(\"ignore\")\n\n# Thanks to Chris's RAPIDS dataset, it only takes around 1 min to install offline\n!cp ../input/rapids/rapids.0.15.0 /opt/conda/envs/rapids.tar.gz\n!cd /opt/conda/envs/ && tar -xzvf rapids.tar.gz > /dev/null\nsys.path = [\"/opt/conda/envs/rapids/lib/python3.7/site-packages\"] + sys.path\nsys.path = [\"/opt/conda/envs/rapids/lib/python3.7\"] + sys.path\nsys.path = [\"/opt/conda/envs/rapids/lib\"] + sys.path \n!cp /opt/conda/envs/rapids/lib/libxgboost.so /opt/conda/lib/\n\nimport cuml\nprint('RAPIDS',cuml.__version__)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"id":"kw1VW6DCvgSq","outputId":"030d81e0-579d-463d-b2ed-6c714151a063"},"cell_type":"code","source":"import os\nimport gc\nimport pickle\nimport joblib\nimport datetime\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import log_loss\nfrom tqdm.notebook import tqdm\nfrom time import time","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport random as rn\nimport numpy as np\n\n\ndef set_seed(seed=0):\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n\n    rn.seed(seed)\n    np.random.seed(seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import log_loss\n\n\ndef score(Y, Y_pred):\n    _, n_classes = Y.shape\n\n    losses = []\n\n    for j in range(n_classes):\n        loss = log_loss(Y.iloc[:, j], Y_pred.iloc[:, j], labels=[0, 1])\n\n        losses.append(loss)\n\n    return np.mean(losses)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\nsys.path.append('../input/iterativestratification')\n\nimport numpy as np\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\nfrom sklearn.model_selection._split import _BaseKFold\n\n\nclass MultilabelGroupStratifiedKFold(_BaseKFold):\n    def __init__(self, n_splits=5, random_state=None, shuffle=False):\n        super().__init__(n_splits=n_splits, random_state=random_state, shuffle=shuffle)\n\n    def _iter_test_indices(self, X=None, Y=None, groups=None):\n        cv = MultilabelStratifiedKFold(\n            n_splits=self.n_splits,\n            random_state=self.random_state,\n            shuffle=self.shuffle,\n        )\n\n        value_counts = groups.value_counts()\n        regular_index = value_counts.loc[\n            (value_counts == 6) | (value_counts == 12) | (value_counts == 18)\n        ].index.sort_values()\n        irregular_index = value_counts.loc[\n            (value_counts != 6) & (value_counts != 12) & (value_counts != 18)\n        ].index.sort_values()\n\n        group_to_fold = {}\n        tmp = Y.groupby(groups).mean().loc[regular_index]\n\n        for fold, (_, test) in enumerate(cv.split(tmp, tmp)):\n            group_to_fold.update({group: fold for group in tmp.index[test]})\n\n        sample_to_fold = {}\n        tmp = Y.loc[groups.isin(irregular_index)]\n\n        for fold, (_, test) in enumerate(cv.split(tmp, tmp)):\n            sample_to_fold.update({sample: fold for sample in tmp.index[test]})\n\n        folds = groups.map(group_to_fold)\n        is_na = folds.isna()\n        folds[is_na] = folds[is_na].index.map(sample_to_fold).values\n\n        for i in range(self.n_splits):\n            yield np.where(folds == i)[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.base import BaseEstimator\nfrom sklearn.base import TransformerMixin\n\n\nclass ClippedFeatures(BaseEstimator, TransformerMixin):\n    def __init__(self, copy=True, high=0.99, low=0.01):\n        self.copy = copy\n        self.high = high\n        self.low = low\n\n    def fit(self, X, y=None):\n        self.data_max_ = X.quantile(q=self.high)\n        self.data_min_ = X.quantile(q=self.low)\n\n        return self\n\n    def transform(self, X):\n        if self.copy:\n            X = X.copy()\n\n        X.clip(self.data_min_, self.data_max_, axis=1, inplace=True)\n\n        return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import pandas as pd\n#\n#\n#def compute_row_statistics(X, prefix=\"\"):\n#    Xt = pd.DataFrame()\n#\n#    for agg_func in [\n#        # \"min\",\n#        # \"max\",\n#        \"mean\",\n#        \"std\",\n#        \"kurtosis\",\n#        \"skew\",\n#    ]:\n#        Xt[f\"{prefix}{agg_func}\"] = X.agg(agg_func, axis=1)\n#\n#    return Xt","execution_count":null,"outputs":[]},{"metadata":{"id":"dSVuPpi2vgSv"},"cell_type":"markdown","source":"# Data Preparation"},{"metadata":{"trusted":true},"cell_type":"code","source":"dtype = {\"cp_type\": \"category\", \"cp_dose\": \"category\"}\nindex_col = \"sig_id\"\n\ntrain_features = pd.read_csv(\n   \"../input/lish-moa/train_features.csv\", dtype=dtype, index_col=index_col\n)\nX = train_features.select_dtypes(\"number\")\nY_nonscored = pd.read_csv(\n   \"../input/lish-moa/train_targets_nonscored.csv\", index_col=index_col\n)\nY = pd.read_csv(\"../input/lish-moa/train_targets_scored.csv\", index_col=index_col)\ngroups = pd.read_csv(\n   \"../input/lish-moa/train_drug.csv\", index_col=index_col, squeeze=True\n)\n\ncolumns = Y.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clipped_features = ClippedFeatures()\nX = clipped_features.fit_transform(X)\n\nwith open(\"clipped_features.pkl\", \"wb\") as f:\n    pickle.dump(clipped_features, f)\n# アンサンブルのために統計値, nonscoredは入れない \n#c_prefix = \"c-\"\n#g_prefix = \"g-\"\n#c_columns = X.columns.str.startswith(c_prefix)\n#g_columns = X.columns.str.startswith(g_prefix)\n#X_c = compute_row_statistics(X.loc[:, c_columns], prefix=c_prefix)\n#X_g = compute_row_statistics(X.loc[:, g_columns], prefix=g_prefix)\n#X = pd.concat([X, X_c, X_g], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seeds = [0, 1]\n#seeds = [2, 3]\n#seeds = [4]\nn_splits = 5\n\n#DEBUG = True\nDEBUG = False\nif DEBUG:\n    columns = [\n        \"atp-sensitive_potassium_channel_antagonist\",  # 陽性ラベル1個だけ\n        \"erbb2_inhibitor\",  # 陽性ラベル1個だけ\n        \"antiarrhythmic\",  # 陽性ラベル6個だけ\n        \"aldehyde_dehydrogenase_inhibitor\",  # 陽性ラベル7個だけ\n#        \"lipase_inhibitor\",  # 陽性ラベル12個だけ\n#        \"sphingosine_receptor_agonist\",  # 陽性ラベル25個だけ\n#        \"igf-1_inhibitor\",  # 陽性ラベル37個だけ\n#        \"potassium_channel_activator\",  # 陽性ラベル55個だけ\n#        \"potassium_channel_antagonist\",  # 陽性ラベル98個だけ\n#        \"dopamine_receptor_agonist\",  # 陽性ラベル121個だけ\n#        \"nfkb_inhibitor\",  # 陽性ラベル832個\n#        \"cyclooxygenase_inhibitor\",  # 陽性ラベル435個\n#        \"dna_inhibitor\",  # 陽性ラベル402個\n#        \"glutamate_receptor_antagonist\",  # 陽性ラベル367個\n#        \"tubulin_inhibitor\",  # 陽性ラベル316個\n#        \"pdgfr_inhibitor\",  # 陽性ラベル297個\n#        \"calcium_channel_blocker\",  # 陽性ラベル281個\n        \"flt3_inhibitor\",  # 陽性ラベル279個\n        \"progesterone_receptor_agonist\",  # 陽性ラベル119個\n        \"hdac_inhibitor\",  # 陽性ラベル106個\n    ]\n    Y = Y[columns]\n    \n    seeds = [0]\n    n_splits = 5\n    print(f\"DEBUG: {DEBUG}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_size, n_features = X.shape\n_, n_classes_nonscored = Y_nonscored.shape\n_, n_classes = Y.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"0eDJ68r-vgTA"},"cell_type":"markdown","source":"# CuML SVM Models"},{"metadata":{"trusted":true,"id":"qiCub3F5vgTA","outputId":"a409642d-80cd-4fdb-d21b-586422655f38"},"cell_type":"code","source":"# from sklearn.svm import SVC, SVR\nfrom cuml.svm import SVC, SVR\n\n\nY_pred = Y.copy()\nY_pred.loc[:, Y.columns] = 0\n\ncounts = []\nfor i in tqdm(seeds):\n    print(f\"------------ seed:{i} ------------\")\n    set_seed(seed=i)\n\n    cv = MultilabelGroupStratifiedKFold(n_splits=n_splits, random_state=i, shuffle=True)\n    cv_split = cv.split(X, Y, groups)\n        \n    for j, (trn_idx, val_idx) in enumerate(cv_split):\n\n        X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n        Y_train_targets, Y_val_targets = Y.iloc[trn_idx], Y.iloc[val_idx]\n    \n        targets_counts = []\n    \n        for tar, tar_col in enumerate(Y.columns):\n            \n            Y_train, Y_val = Y_train_targets.values[:, tar], Y_val_targets.values[:, tar]  \n\n            if Y_train.sum() >= 5:\n            \n                model = SVC(C=10, cache_size=2000, probability=True)\n                model.fit(X_train, Y_train)\n                Y_pred[Y.columns[tar]][val_idx] += model.predict_proba(X_val)[:,1] / len(seeds)\n                \n                joblib.dump(model, f\"model_seed_{i}_fold_{j}_{Y.columns[tar]}.jlb\", compress=True)\n                \n            else:\n                Y_pred[Y.columns[tar]][val_idx] += Y_train.mean() / len(seeds)\n                \n            targets_counts.append(Y_train.sum())\n                \n        counts.append(targets_counts)\n\ncounts = np.array(counts)\nassert (\n    counts.shape == np.empty((len(seeds) * n_splits, n_classes)).shape\n), f\"countsのshapeおかしい. {counts.shape}\"\n\nY_pred[train_features[\"cp_type\"] == \"ctl_vehicle\"] = 0.0\n\nwith open(\"counts.pkl\", \"wb\") as f:\n    pickle.dump(counts, f)\n\nwith open(\"Y_pred.pkl\", \"wb\") as f:\n    pickle.dump(Y_pred[columns], f)\n\nscore(Y[columns], Y_pred[columns])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# pkl check"},{"metadata":{"trusted":true},"cell_type":"code","source":"path = r\"counts.pkl\"\nwith open(path, 'rb') as f:\n    counts = pickle.load(f)\ncounts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = r\"Y_pred.pkl\"\nwith open(path, 'rb') as f:\n    Y_pred = pickle.load(f)\nY_pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# predict test"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_features = pd.read_csv(\n    \"../input/lish-moa/test_features.csv\", dtype=dtype, index_col=index_col\n    #f\"{DATADIR}/test_features.csv\", dtype=dtype, index_col=index_col,\n)\nX_test = test_features.select_dtypes(\"number\")\n\nwith open(\"./clipped_features.pkl\", \"rb\") as f:\n    clipped_features = pickle.load(f)\nX_test = clipped_features.transform(X_test)\n\nY_test_pred = np.zeros((X_test.shape[0], len(columns)))\nY_test_pred = pd.DataFrame(Y_test_pred, columns=columns, index=test_features.index)\n\nfor i in seeds:\n    for j in range(n_splits):\n        for tar in range(Y.shape[1]):\n            \n            m_path = f\"model_seed_{i}_fold_{j}_{Y.columns[tar]}.jlb\"\n            if os.path.exists(m_path):\n                model = joblib.load(m_path)\n                Y_test_pred.iloc[:,tar] += model.predict_proba(X_test)[:,1] / (len(seeds) * n_splits)\n            else:\n                Y_test_pred.iloc[:,tar] += np.array([Y_pred.iloc[:,tar].mean()] * X_test.shape[0]) / (len(seeds) * n_splits)\n\nY_test_pred[test_features[\"cp_type\"] == \"ctl_vehicle\"] = 0.0\n                \nprint(Y_test_pred.shape) \ndisplay(Y_test_pred)\n\nY_test_pred.to_csv(\"submission.csv\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}