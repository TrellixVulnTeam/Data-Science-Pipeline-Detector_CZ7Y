{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import gc\nimport re\nimport math\nimport pickle\nimport joblib\nimport warnings\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.multioutput import MultiOutputClassifier, ClassifierChain\nfrom sklearn.linear_model import LogisticRegression\n\nfrom xgboost import XGBClassifier\n\nwarnings.simplefilter('ignore')\npd.set_option('display.max_columns', None)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport random as rn\nimport numpy as np\n\n\ndef set_seed(seed=0):\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n\n    rn.seed(seed)\n    np.random.seed(seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import log_loss\n\n\ndef score(Y, Y_pred):\n    _, n_classes = Y.shape\n\n    losses = []\n\n    for j in range(n_classes):\n        loss = log_loss(Y.iloc[:, j], Y_pred.iloc[:, j], labels=[0, 1])\n\n        losses.append(loss)\n\n    return np.mean(losses)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\n\n\ndef auc_score(Y, Y_pred):\n    _, n_classes = Y.shape\n\n    aucs = []\n\n    for j in range(n_classes):\n        auc = roc_auc_score(Y.iloc[:, j], Y_pred.iloc[:, j])\n\n        aucs.append(auc)\n\n    return np.mean(aucs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def compute_row_statistics(X, prefix=\"\"):\n    Xt = pd.DataFrame()\n\n    for agg_func in [\n        # \"min\",\n        # \"max\",\n        \"mean\",\n        \"std\",\n        \"kurtosis\",\n        \"skew\",\n    ]:\n        Xt[f\"{prefix}{agg_func}\"] = X.agg(agg_func, axis=1)\n\n    return Xt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.base import BaseEstimator\nfrom sklearn.base import TransformerMixin\n\n\nclass ClippedFeatures(BaseEstimator, TransformerMixin):\n    def __init__(self, copy=True, high=0.99, low=0.01):\n        self.copy = copy\n        self.high = high\n        self.low = low\n\n    def fit(self, X, y=None):\n        self.data_max_ = X.quantile(q=self.high)\n        self.data_min_ = X.quantile(q=self.low)\n\n        return self\n\n    def transform(self, X):\n        if self.copy:\n            X = X.copy()\n\n        X.clip(self.data_min_, self.data_max_, axis=1, inplace=True)\n\n        return X","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CV"},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\nsys.path.append('../input/iterative-stratification/iterative-stratification-master')\n\nimport numpy as np\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\nfrom sklearn.model_selection._split import _BaseKFold\n\n\nclass MultilabelStratifiedGroupKFold(_BaseKFold):\n    def __init__(self, n_splits=5, random_state=None, shuffle=False):\n        super().__init__(n_splits=n_splits, random_state=random_state, shuffle=shuffle)\n\n    def _iter_test_indices(self, X=None, y=None, groups=None):\n        cv = MultilabelStratifiedKFold(\n            n_splits=self.n_splits,\n            random_state=self.random_state,\n            shuffle=self.shuffle,\n        )\n\n        value_counts = groups.value_counts()\n        regluar_indices = value_counts.loc[\n            (value_counts == 6) | (value_counts == 12) | (value_counts == 18)\n        ].index.sort_values()\n        irregluar_indices = value_counts.loc[\n            (value_counts != 6) & (value_counts != 12) & (value_counts != 18)\n        ].index.sort_values()\n\n        group_to_fold = {}\n        tmp = y.groupby(groups).mean().loc[regluar_indices]\n\n        for fold, (_, test) in enumerate(cv.split(tmp, tmp)):\n            group_to_fold.update({group: fold for group in tmp.index[test]})\n\n        sample_to_fold = {}\n        tmp = y.loc[groups.isin(irregluar_indices)]\n\n        for fold, (_, test) in enumerate(cv.split(tmp, tmp)):\n            sample_to_fold.update({sample: fold for sample in tmp.index[test]})\n\n        folds = groups.map(group_to_fold)\n        is_na = folds.isna()\n        folds[is_na] = folds[is_na].index.map(sample_to_fold).values\n\n        for i in range(self.n_splits):\n            yield np.where(folds == i)[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preparation"},{"metadata":{"trusted":true},"cell_type":"code","source":"dtype = {\"cp_type\": \"category\", \"cp_dose\": \"category\"}\nindex_col = \"sig_id\"\n\ntrain_features = pd.read_csv(\n    \"../input/lish-moa/train_features.csv\", dtype=dtype, index_col=index_col\n)\nX = train_features.select_dtypes(\"number\")\nY_nonscored = pd.read_csv(\n    \"../input/lish-moa/train_targets_nonscored.csv\", index_col=index_col\n)\nY = pd.read_csv(\"../input/lish-moa/train_targets_scored.csv\", index_col=index_col)\ngroups = pd.read_csv(\n    \"../input/lish-moa/train_drug.csv\", index_col=index_col, squeeze=True\n)\n\ncolumns = Y.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c_prefix = \"c-\"\ng_prefix = \"g-\"\nc_columns = X.columns.str.startswith(c_prefix)\ng_columns = X.columns.str.startswith(g_prefix)\nX_c = compute_row_statistics(X.loc[:, c_columns], prefix=c_prefix)\nX_g = compute_row_statistics(X.loc[:, g_columns], prefix=g_prefix)\n\nclipped_features = ClippedFeatures()\nX = clipped_features.fit_transform(X)\nwith open(\"clipped_features.pkl\", \"wb\") as f:\n    pickle.dump(clipped_features, f)\n\nX = pd.concat([X, X_c, X_g], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_seeds = 5\nn_splits = 5\nLBS = 0.0008\n\nparams = {\n    'n_estimators': 1000,\n    'objective': 'binary:logistic', \n    'tree_method': 'gpu_hist', \n    'verbosity': 0, \n    'colsample_bytree': 0.1818593017814899, \n    'learning_rate': 0.012887963193108452, \n    'gamma': 6.576022976359221, \n    'max_depth': 8, \n    'min_child_weight': 8.876744371188476, \n    'subsample': 0.7813380253086911, \n}\n\n#DEBUG = True\nDEBUG = False\nif DEBUG:\n    columns = [\n        \"atp-sensitive_potassium_channel_antagonist\",  # 陽性ラベル1個だけ\n        \"erbb2_inhibitor\",  # 陽性ラベル1個だけ\n        \"antiarrhythmic\",  # 陽性ラベル6個だけ\n        \"aldehyde_dehydrogenase_inhibitor\",  # 陽性ラベル7個だけ\n        \"lipase_inhibitor\",  # 陽性ラベル12個だけ\n        \"sphingosine_receptor_agonist\",  # 陽性ラベル25個だけ\n        \"igf-1_inhibitor\",  # 陽性ラベル37個だけ\n        \"potassium_channel_activator\",  # 陽性ラベル55個だけ\n        \"potassium_channel_antagonist\",  # 陽性ラベル98個だけ\n        \"dopamine_receptor_agonist\",  # 陽性ラベル121個だけ\n        \"nfkb_inhibitor\",  # 陽性ラベル832個\n        \"cyclooxygenase_inhibitor\",  # 陽性ラベル435個\n        \"dna_inhibitor\",  # 陽性ラベル402個\n        \"glutamate_receptor_antagonist\",  # 陽性ラベル367個\n        \"tubulin_inhibitor\",  # 陽性ラベル316個\n        \"pdgfr_inhibitor\",  # 陽性ラベル297個\n        \"calcium_channel_blocker\",  # 陽性ラベル281個\n        \"flt3_inhibitor\",  # 陽性ラベル279個\n        \"progesterone_receptor_agonist\",  # 陽性ラベル119個\n        \"hdac_inhibitor\",  # 陽性ラベル106個\n    ]\n    Y = Y[columns]\n    \n    params[\"n_estimators\"] = 2\n    n_seeds = 2\n    n_splits = 2\n    print(f\"DEBUG: {DEBUG}\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_size, n_features = X.shape\n_, n_classes = Y.shape\nprint(\"n_classes:\", n_classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\ncounts = np.empty((n_seeds * n_splits, n_classes))\n\nY_pred = np.zeros((train_size, n_classes))\nY_pred = pd.DataFrame(Y_pred, columns=Y.columns, index=Y.index)\n\nfor i in range(n_seeds):\n    set_seed(seed=i)\n    \n    cv = MultilabelStratifiedGroupKFold(n_splits=n_splits, random_state=i, shuffle=True)\n    cv_split = cv.split(X, Y, groups)\n        \n    for j, (trn_idx, val_idx) in tqdm(enumerate(cv_split)):\n        counts[i * n_splits + j] = Y.iloc[trn_idx].sum()\n        \n        X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n        Y_train, Y_val = Y.iloc[trn_idx], Y.iloc[val_idx]\n        \n        # Label Smoothing\n        Y_train = Y_train * (1 - LBS) + 0.5 * LBS\n        \n        clf = ClassifierChain(XGBClassifier(**params), order=\"random\", random_state=i)\n        clf.fit(X_train, Y_train)\n        val_preds = clf.predict_proba(X_val) # list of preds per class\n        \n        Y_pred.iloc[val_idx] += val_preds / n_seeds\n        \n        joblib.dump(clf, f\"model_seed_{i}_fold_{j}.jlb\", compress=True)\n\nY_pred[train_features[\"cp_type\"] == \"ctl_vehicle\"] = 0.0\n\nwith open(\"counts.pkl\", \"wb\") as f:\n    pickle.dump(counts, f)\n\nwith open(\"Y_pred.pkl\", \"wb\") as f:\n    pickle.dump(Y_pred[columns], f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oof_logloss = score(Y[columns], Y_pred[columns])\noof_auc = auc_score(Y[columns], Y_pred[columns])\nprint(f\"oof_logloss:\", oof_logloss)\nprint(f\"oof_auc:\", oof_auc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Platt Scaling\nTrain a Logistic Regression model to calibrate the results\n- https://www.kaggle.com/gogo827jz/kernel-logistic-regression-one-for-206-targets"},{"metadata":{"trusted":true},"cell_type":"code","source":"## predict_probaでだしたY_predをロジスティク回帰で確率に補正する\n#\n#X = Y_pred.copy()\n#Y_cali = np.zeros((train_size, n_classes))\n#Y_cali = pd.DataFrame(Y_cali, columns=Y.columns, index=Y.index)\n#\n#for i in tqdm(range(n_seeds)):\n#    set_seed(seed=i)\n#\n#    cv = MultilabelStratifiedGroupKFold(n_splits=n_splits, random_state=i, shuffle=True)\n#    cv_split = cv.split(X, Y, groups)\n#        \n#    for j, (trn_idx, val_idx) in enumerate(cv_split):\n#\n#        print(f\"\\n------------ fold:{j} ------------\")\n#\n#        X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n#        Y_train_targets, Y_val_targets = Y.iloc[trn_idx], Y.iloc[val_idx]\n#        \n#        # Label Smoothing. https://www.kaggle.com/gogo827jz/self-stacking-groupcv-xgboost\n#        #Y_train_targets = Y_train_targets * (1 - LBS) + 0.5 * LBS\n#    \n#        for tar, tar_col in enumerate(Y.columns):\n#            Y_train, Y_val = Y_train_targets.values[:, tar], Y_val_targets.values[:, tar]  \n#            \n#            if Y_train.sum() >= 1:\n#                \n#                model = LogisticRegression(penalty=\"none\", max_iter=1000)\n#                model.fit(X_train, Y_train)\n#                \n#                Y_cali[tar_col][val_idx] += model.predict_proba(X_val)[:, 1] / n_seeds\n#            \n#                joblib.dump(model, \n#                            f\"calibrate_model_seed_{i}_fold_{j}_{tar_col}.jlb\", \n#                            compress=True)\n#            else:\n#                Y_cali[tar_col][val_idx] = Y_pred[tar_col][val_idx]\n#                \n#with open(\"Y_pred_calibrate.pkl\", \"wb\") as f:\n#    pickle.dump(Y_cali[columns], f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#oof_logloss = score(Y[columns], Y_pred[columns])\n#oof_auc = auc_score(Y[columns], Y_pred[columns])\n#print(f\"oof_logloss:\", oof_logloss)\n#print(f\"oof_auc:\", oof_auc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# pkl check"},{"metadata":{"trusted":true},"cell_type":"code","source":"path = r\"counts.pkl\"\nwith open(path, 'rb') as f:\n    counts = pickle.load(f)\ncounts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = r\"Y_pred.pkl\"\nwith open(path, 'rb') as f:\n    Y_pred = pickle.load(f)\nY_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#path = r\"Y_pred_calibrate.pkl\"\n#with open(path, 'rb') as f:\n#    Y_pred = pickle.load(f)\n#Y_pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# predict test"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_features = pd.read_csv(\n    \"../input/lish-moa/test_features.csv\", dtype=dtype, index_col=index_col\n)\nX_test = test_features.select_dtypes(\"number\")\nX_c = compute_row_statistics(X_test.loc[:, c_columns], prefix=c_prefix)\nX_g = compute_row_statistics(X_test.loc[:, g_columns], prefix=g_prefix)\n\nwith open(\"./clipped_features.pkl\", \"rb\") as f:\n    clipped_features = pickle.load(f)\nX_test = clipped_features.transform(X_test)\n\nX_test = pd.concat([X_test, X_c, X_g], axis=1)\nprint(f\"X_test.shape: {X_test.shape}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# xgbで予測\nY_test_pred = np.zeros((X_test.shape[0], len(columns)))\nY_test_pred = pd.DataFrame(Y_test_pred, columns=columns, index=test_features.index)\nfor i in range(n_seeds):\n    for j in range(n_splits):\n        clf = joblib.load(f\"model_seed_{i}_fold_{j}.jlb\")\n        Y_test_pred += clf.predict_proba(X_test)[:, : len(columns)] / (n_seeds * n_splits)\n        \nprint(Y_test_pred.shape)\ndisplay(Y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## calibrate\n#print(\"\\n---------- calibrate ----------\")\n#X_test = Y_test_pred.copy()\n#Y_test_cali = np.zeros((X_test.shape[0], len(columns)))\n#Y_test_cali = pd.DataFrame(Y_test_pred, columns=columns, index=test_features.index)\n#for i in range(n_seeds):\n#    for j in range(n_splits):\n#        for tar in range(Y.shape[1]):\n#            \n#            m_path = f\"calibrate_model_seed_{i}_fold_{j}_{Y.columns[tar]}.jlb\"\n#            if os.path.exists(m_path):\n#                print(m_path)\n#                model = joblib.load(m_path)\n#                Y_test_cali.iloc[:,tar] += model.predict_proba(X_test)[:, 1] / (n_seeds * n_splits)\n#            else:\n#                Y_test_cali.iloc[:,tar] = Y_test_pred.iloc[:,tar]\n#                \n#print(Y_test_cali.shape)\n#display(Y_test_cali)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}