{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import gc\nimport re\nimport math\nimport pickle\nimport joblib\nimport warnings\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.multioutput import MultiOutputClassifier, ClassifierChain\nfrom sklearn.linear_model import LogisticRegression\n\nimport lightgbm as lgb\n\nwarnings.simplefilter('ignore')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport random as rn\nimport numpy as np\n\n\ndef set_seed(seed=0):\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n\n    rn.seed(seed)\n    np.random.seed(seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import log_loss\n\n\ndef score(Y, Y_pred):\n    _, n_classes = Y.shape\n\n    losses = []\n\n    for j in range(n_classes):\n        loss = log_loss(Y.iloc[:, j], Y_pred.iloc[:, j], labels=[0, 1])\n\n        losses.append(loss)\n\n    return np.mean(losses)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import sys\nsys.path.append('../input/iterativestratification')\n\nimport numpy as np\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\nfrom sklearn.model_selection._split import _BaseKFold\n\n\nclass MultilabelGroupStratifiedKFold(_BaseKFold):\n    def __init__(self, n_splits=5, random_state=None, shuffle=False):\n        super().__init__(n_splits=n_splits, random_state=random_state, shuffle=shuffle)\n\n    def _iter_test_indices(self, X=None, Y=None, groups=None):\n        cv = MultilabelStratifiedKFold(\n            n_splits=self.n_splits,\n            random_state=self.random_state,\n            shuffle=self.shuffle,\n        )\n\n        value_counts = groups.value_counts()\n        regular_index = value_counts.loc[\n            (value_counts == 6) | (value_counts == 12) | (value_counts == 18)\n        ].index.sort_values()\n        irregular_index = value_counts.loc[\n            (value_counts != 6) & (value_counts != 12) & (value_counts != 18)\n        ].index.sort_values()\n\n        group_to_fold = {}\n        tmp = Y.groupby(groups).mean().loc[regular_index]\n\n        for fold, (_, test) in enumerate(cv.split(tmp, tmp)):\n            group_to_fold.update({group: fold for group in tmp.index[test]})\n\n        sample_to_fold = {}\n        tmp = Y.loc[groups.isin(irregular_index)]\n\n        for fold, (_, test) in enumerate(cv.split(tmp, tmp)):\n            sample_to_fold.update({sample: fold for sample in tmp.index[test]})\n\n        folds = groups.map(group_to_fold)\n        is_na = folds.isna()\n        folds[is_na] = folds[is_na].index.map(sample_to_fold).values\n\n        for i in range(self.n_splits):\n            yield np.where(folds == i)[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.base import BaseEstimator\nfrom sklearn.base import TransformerMixin\n\n\nclass ClippedFeatures(BaseEstimator, TransformerMixin):\n    def __init__(self, copy=True, high=0.99, low=0.01):\n        self.copy = copy\n        self.high = high\n        self.low = low\n\n    def fit(self, X, y=None):\n        self.data_max_ = X.quantile(q=self.high)\n        self.data_min_ = X.quantile(q=self.low)\n\n        return self\n\n    def transform(self, X):\n        if self.copy:\n            X = X.copy()\n\n        X.clip(self.data_min_, self.data_max_, axis=1, inplace=True)\n\n        return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\n\n\ndef compute_row_statistics(X, prefix=\"\"):\n    Xt = pd.DataFrame()\n\n    for agg_func in [\n        # \"min\",\n        # \"max\",\n        \"mean\",\n        \"std\",\n        \"kurtosis\",\n        \"skew\",\n    ]:\n        Xt[f\"{prefix}{agg_func}\"] = X.agg(agg_func, axis=1)\n\n    return Xt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n\ndef display_importances(\n    importance_df, png_path=f\"feature_importance.png\",\n):\n    \"\"\"feature_importance plot\"\"\"\n    importance_df.sort_values(by=\"importance\", ascending=False).to_csv(f\"feature_importance.csv\")\n    cols = (\n        importance_df[[\"feature\", \"importance\"]]\n        .groupby(\"feature\")\n        .mean()\n        .sort_values(by=\"importance\", ascending=False)[:100]\n        .index\n    )\n    best_features = importance_df.loc[importance_df.feature.isin(cols)]\n    plt.figure(figsize=(8, 15))\n    sns.barplot(\n        x=\"importance\",\n        y=\"feature\",\n        data=best_features.sort_values(by=\"importance\", ascending=False),\n    )\n    plt.title(\"LightGBM (avg over folds)\")\n    plt.tight_layout()\n    plt.savefig(png_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtype = {\"cp_type\": \"category\", \"cp_dose\": \"category\"}\nindex_col = \"sig_id\"\n\ntrain_features = pd.read_csv(\n   \"../input/lish-moa/train_features.csv\", dtype=dtype, index_col=index_col\n)\nX = train_features.select_dtypes(\"number\")\nY_nonscored = pd.read_csv(\n   \"../input/lish-moa/train_targets_nonscored.csv\", index_col=index_col\n)\nY = pd.read_csv(\"../input/lish-moa/train_targets_scored.csv\", index_col=index_col)\ngroups = pd.read_csv(\n   \"../input/lish-moa/train_drug.csv\", index_col=index_col, squeeze=True\n)\n\ncolumns = Y.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clipped_features = ClippedFeatures()\nX = clipped_features.fit_transform(X)\n\nwith open(\"clipped_features.pkl\", \"wb\") as f:\n    pickle.dump(clipped_features, f)\n# アンサンブルのために統計値, nonscoredは入れない \n#c_prefix = \"c-\"\n#g_prefix = \"g-\"\n#c_columns = X.columns.str.startswith(c_prefix)\n#g_columns = X.columns.str.startswith(g_prefix)\n#X_c = compute_row_statistics(X.loc[:, c_columns], prefix=c_prefix)\n#X_g = compute_row_statistics(X.loc[:, g_columns], prefix=g_prefix)\n#X = pd.concat([X, X_c, X_g], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"is_drug_cv = True\nn_splits = 5\nn_seeds = 5\n# LBS = 0.0008  # ラベルスムージングは全然効かないからやめる\nLBS = 0.0\n\nparams = {\n    \"objective\": \"binary\",\n    \"learning_rate\": 0.1,\n    \"num_leaves\": 4,\n    \"max_depth\": 2,\n    \"min_data_in_leaf\": 1951,\n    \"feature_fraction\": 0.25,\n    \"lambda_l1\": 3.34060389323178e-07,\n    \"lambda_l2\": 0.00012255072592595102,\n}\n\nnum_boost_round = 2000\nverbose_eval = 100\n#num_boost_round = 1000\n#verbose_eval = 50\nearly_stopping_rounds = verbose_eval\n\n#DEBUG = True\nDEBUG = False\nif DEBUG:\n    columns = [\n        \"atp-sensitive_potassium_channel_antagonist\",  # 陽性ラベル1個だけ\n        \"erbb2_inhibitor\",  # 陽性ラベル1個だけ\n        \"antiarrhythmic\",  # 陽性ラベル6個だけ\n        \"aldehyde_dehydrogenase_inhibitor\",  # 陽性ラベル7個だけ\n#        \"lipase_inhibitor\",  # 陽性ラベル12個だけ\n#        \"sphingosine_receptor_agonist\",  # 陽性ラベル25個だけ\n#        \"igf-1_inhibitor\",  # 陽性ラベル37個だけ\n#        \"potassium_channel_activator\",  # 陽性ラベル55個だけ\n#        \"potassium_channel_antagonist\",  # 陽性ラベル98個だけ\n#        \"dopamine_receptor_agonist\",  # 陽性ラベル121個だけ\n#        \"nfkb_inhibitor\",  # 陽性ラベル832個\n#        \"cyclooxygenase_inhibitor\",  # 陽性ラベル435個\n#        \"dna_inhibitor\",  # 陽性ラベル402個\n#        \"glutamate_receptor_antagonist\",  # 陽性ラベル367個\n#        \"tubulin_inhibitor\",  # 陽性ラベル316個\n#        \"pdgfr_inhibitor\",  # 陽性ラベル297個\n#        \"calcium_channel_blocker\",  # 陽性ラベル281個\n#        \"flt3_inhibitor\",  # 陽性ラベル279個\n#        \"progesterone_receptor_agonist\",  # 陽性ラベル119個\n        \"hdac_inhibitor\",  # 陽性ラベル106個\n    ]\n    Y = Y[columns]\n    n_seeds = 2\n    params[\"n_estimators\"] = 2\n    n_splits = 4\n    num_boost_round = 50\n    verbose_eval = 5\n    early_stopping_rounds = verbose_eval\n    print(f\"DEBUG: {DEBUG}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_size, n_features = X.shape\n_, n_classes_nonscored = Y_nonscored.shape\n_, n_classes = Y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"%%time\n\nf_importance = np.zeros((n_features,))\nY_pred = np.zeros((train_size, n_classes))\nY_pred = pd.DataFrame(Y_pred, columns=Y.columns, index=Y.index)\n\ncounts = []\nfor i in tqdm(range(n_seeds)):\n    set_seed(seed=i)\n\n    cv = MultilabelGroupStratifiedKFold(n_splits=n_splits, random_state=i, shuffle=True)\n    cv_split = cv.split(X, Y, groups)\n        \n    for j, (trn_idx, val_idx) in enumerate(cv_split):\n\n        print(f\"\\n------------ fold:{j} ------------\")\n\n        X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n        Y_train_targets, Y_val_targets = Y.iloc[trn_idx], Y.iloc[val_idx]\n    \n        targets_counts = []\n\n        # Label Smoothing. https://www.kaggle.com/gogo827jz/self-stacking-groupcv-xgboost\n        Y_train_targets = Y_train_targets * (1 - LBS) + 0.5 * LBS\n    \n        for tar, tar_col in enumerate(Y.columns):\n            Y_train, Y_val = Y_train_targets.values[:, tar], Y_val_targets.values[:, tar]           \n\n            lgb_train = lgb.Dataset(X_train, Y_train)\n            lgb_eval = lgb.Dataset(X_val, Y_val, reference=lgb_train)\n\n            model = lgb.train(\n                params,\n                lgb_train,\n                valid_sets=[lgb_train, lgb_eval],\n                verbose_eval=verbose_eval,\n                num_boost_round=num_boost_round,\n                early_stopping_rounds=early_stopping_rounds,\n            )\n            Y_pred[tar_col][val_idx] += (\n                model.predict(X_val, num_iteration=model.best_iteration) / n_seeds\n            )\n\n            f_importance += np.array(\n                model.feature_importance(importance_type=\"gain\")\n            ) / (n_seeds * n_splits)\n\n            joblib.dump(\n                model, f\"model_seed_{i}_fold_{j}_{Y.columns[tar]}.jlb\", compress=True\n            )\n\n            targets_counts.append(Y_train.sum())\n\n        counts.append(targets_counts)\n\ncounts = np.array(counts)\nassert (\n    counts.shape == np.empty((n_seeds * n_splits, n_classes)).shape\n), f\"countsのshapeおかしい. {counts.shape}\"\n\nimportance_df = pd.DataFrame(\n    {\"feature\": model.feature_name(), \"importance\": f_importance}\n)\n\nY_pred[train_features[\"cp_type\"] == \"ctl_vehicle\"] = 0.0\n\nwith open(\"counts.pkl\", \"wb\") as f:\n    pickle.dump(counts, f)\n\nwith open(\"Y_pred.pkl\", \"wb\") as f:\n    pickle.dump(Y_pred[columns], f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score(Y[columns], Y_pred[columns])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_importances(importance_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Platt Scaling\nTrain a Logistic Regression model to calibrate the results\n\nhttps://www.kaggle.com/gogo827jz/kernel-logistic-regression-one-for-206-targets"},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"## predict_probaでだしたY_predをロジスティク回帰で確率に補正する\n#\n#X = Y_pred.copy()\n#Y_cali = np.zeros((train_size, n_classes))\n#Y_cali = pd.DataFrame(Y_cali, columns=Y.columns, index=Y.index)\n#\n#for i in tqdm(range(n_seeds)):\n#    set_seed(seed=i)\n#\n#    cv = MultilabelGroupStratifiedKFold(n_splits=n_splits, random_state=i, shuffle=True)\n#    cv_split = cv.split(X, Y, groups)\n#        \n#    for j, (trn_idx, val_idx) in enumerate(cv_split):\n#\n#        print(f\"\\n------------ fold:{j} ------------\")\n#\n#        X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n#        Y_train_targets, Y_val_targets = Y.iloc[trn_idx], Y.iloc[val_idx]\n#        \n#        # Label Smoothing. https://www.kaggle.com/gogo827jz/self-stacking-groupcv-xgboost\n#        #Y_train_targets = Y_train_targets * (1 - LBS) + 0.5 * LBS\n#    \n#        for tar, tar_col in enumerate(Y.columns):\n#            Y_train, Y_val = Y_train_targets.values[:, tar], Y_val_targets.values[:, tar]  \n#            \n#            if Y_train.sum() >= 1:\n#                \n#                model = LogisticRegression(penalty=\"none\", max_iter=1000)\n#                model.fit(X_train, Y_train)\n#                \n#                Y_cali[tar_col][val_idx] += model.predict_proba(X_val)[:, 1] / n_seeds\n#            \n#                joblib.dump(model, \n#                            f\"calibrate_model_seed_{i}_fold_{j}_{tar_col}.jlb\", \n#                            compress=True)\n#            else:\n#                Y_cali[tar_col][val_idx] = Y_pred[tar_col][val_idx]\n#                \n#with open(\"Y_pred_calibrate.pkl\", \"wb\") as f:\n#    pickle.dump(Y_cali[columns], f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#score(Y[columns], Y_cali[columns])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# pkl check"},{"metadata":{"trusted":true},"cell_type":"code","source":"path = r\"counts.pkl\"\nwith open(path, 'rb') as f:\n    counts = pickle.load(f)\nprint(counts.shape)\ncounts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = r\"Y_pred.pkl\"\nwith open(path, 'rb') as f:\n    Y_pred = pickle.load(f)\nY_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#path = r\"Y_pred_calibrate.pkl\"\n#with open(path, 'rb') as f:\n#    Y_pred_calibrate = pickle.load(f)\n#Y_pred_calibrate","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# predict test"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_features = pd.read_csv(\n    \"../input/lish-moa/test_features.csv\", dtype=dtype, index_col=index_col\n)\nX_test = test_features.select_dtypes(\"number\")\n\n\nwith open(\"./clipped_features.pkl\", \"rb\") as f:\n    clipped_features = pickle.load(f)\nX_test = clipped_features.transform(X_test)\n# アンサンブルのため統計値, nonscoredは入れない \n#X_c = compute_row_statistics(X_test.loc[:, c_columns], prefix=c_prefix)\n#X_g = compute_row_statistics(X_test.loc[:, g_columns], prefix=g_prefix)\n#X_test = pd.concat([X_test, X_c, X_g], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import glob\n\n# lgbで予測\nY_test_pred = np.zeros((X_test.shape[0], len(columns)))\nY_test_pred = pd.DataFrame(Y_test_pred, columns=columns, index=test_features.index)\nfor target in columns:\n    model_paths = glob.glob(f\"./model_seed_*_{target}.jlb\")\n    for model_path in model_paths:\n        model = joblib.load(model_path)\n        Y_test_pred[target] += model.predict(X_test) / len(model_paths)\nprint(Y_test_pred.shape)\ndisplay(Y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## calibrate\n#print(\"\\n---------- calibrate ----------\")\n#X_test = Y_test_pred.copy()\n#Y_test_cali = np.zeros((X_test.shape[0], len(columns)))\n#Y_test_cali = pd.DataFrame(Y_test_pred, columns=columns, index=test_features.index)\n#for i in range(n_seeds):\n#    for j in range(n_splits):\n#        for tar in range(Y.shape[1]):\n#            \n#            m_path = f\"calibrate_model_seed_{i}_fold_{j}_{Y.columns[tar]}.jlb\"\n#            if os.path.exists(m_path):\n#                print(m_path)\n#                model = joblib.load(m_path)\n#                Y_test_cali.iloc[:,tar] += model.predict_proba(X_test)[:, 1] / (n_seeds * n_splits)\n#            else:\n#                Y_test_cali.iloc[:,tar] = Y_test_pred.iloc[:,tar]\n#                \n#print(Y_test_cali.shape)\n#display(Y_test_cali)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}