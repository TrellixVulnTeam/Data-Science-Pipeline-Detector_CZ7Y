{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\n\nsys.path.append(\"../input/iterative-stratification/iterative-stratification-master\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pickle\n\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MIXED_PRECISION = False\nXLA_ACCELERATE = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if MIXED_PRECISION:\n    policy = tf.keras.mixed_precision.experimental.Policy(\"mixed_float16\")\n\n    tf.keras.mixed_precision.experimental.set_policy(policy)\n\ntf.config.optimizer.set_jit(XLA_ACCELERATE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow\n\n\ndef build_callbacks(\n    checkpoint_path,\n    factor=0.1,\n    mode=\"auto\",\n    monitor=\"val_loss\",\n    patience_for_es=0,\n    patience_for_rlop=10,\n    save_best_only=False,\n    verbose=0,\n):\n    callbacks = []\n\n    if checkpoint_path is not None:\n        model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n            checkpoint_path,\n            mode=mode,\n            monitor=monitor,\n            save_best_only=save_best_only,\n            verbose=verbose,\n        )\n\n        callbacks.append(model_checkpoint)\n\n    if patience_for_es is not None:\n        early_stopping = tf.keras.callbacks.EarlyStopping(\n            mode=mode, monitor=monitor, patience=patience_for_es, verbose=verbose\n        )\n\n        callbacks.append(early_stopping)\n\n    if patience_for_rlop is not None:\n        reduce_lr_on_plateau = tf.keras.callbacks.ReduceLROnPlateau(\n            factor=factor,\n            monitor=monitor,\n            mode=mode,\n            patience=patience_for_rlop,\n            verbose=verbose,\n        )\n\n        callbacks.append(reduce_lr_on_plateau)\n\n    return callbacks","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\n\n\ndef build_model(\n    input_dim,\n    output_dim,\n    activation=\"relu\",\n    kernel_initializer=\"glorot_uniform\",\n    label_smoothing=0.0,\n    momentum=0.99,\n    n_layers=3,\n    n_units=\"auto\",\n    optimizer_params=None,\n    rate=0.0,\n):\n    if n_units == \"auto\":\n        n_units = 0.5 * (input_dim + output_dim)\n\n    inputs = tf.keras.layers.Input(shape=input_dim)\n\n    x = inputs\n\n    for i in range(n_layers - 2):\n        x = tf.keras.layers.Dense(n_units, kernel_initializer=kernel_initializer)(x)\n        x = tf.keras.layers.BatchNormalization(momentum=momentum)(x)\n        x = tf.keras.layers.Activation(activation)(x)\n        x = tf.keras.layers.Dropout(rate)(x)\n\n    x = tf.keras.layers.Dense(output_dim)(x)\n\n    outputs = tf.keras.layers.Activation(\"sigmoid\")(x)\n\n    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n\n    if optimizer_params is None:\n        optimizer_params = {}\n\n    loss = tf.keras.losses.BinaryCrossentropy(label_smoothing=label_smoothing)\n    optimizer = tf.keras.optimizers.Adam(**optimizer_params)\n\n    model.compile(loss=loss, optimizer=optimizer)\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n\n\ndef score(Y, Y_pred, eps=1e-15, label_smoothing=0.0):\n    Y = np.asarray(Y)\n    Y = np.ravel(Y)\n\n    if label_smoothing > 0.0:\n        Y = Y * (1.0 - label_smoothing) + 0.5 * label_smoothing\n\n    Y_pred = np.asarray(Y_pred)\n    Y_pred = np.ravel(Y_pred)\n    Y_pred = np.clip(Y_pred, eps, 1.0 - eps)\n\n    return -np.mean(Y * np.log(Y_pred) + (1.0 - Y) * np.log(1.0 - Y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport random as rn\n\nimport tensorflow as tf\nimport numpy as np\n\n\ndef set_seed(seed=0):\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n\n    rn.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n\n    graph = tf.compat.v1.get_default_graph()\n    session_conf = tf.compat.v1.ConfigProto(\n        inter_op_parallelism_threads=1, intra_op_parallelism_threads=1\n    )\n    sess = tf.compat.v1.Session(graph=graph, config=session_conf)\n\n    tf.compat.v1.keras.backend.set_session(sess)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://www.kaggle.com/c/lish-moa/discussion/195195\n\nimport numpy as np\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\nfrom sklearn.model_selection._split import _BaseKFold\n\n\nclass MultilabelStratifiedGroupKFold(_BaseKFold):\n    def __init__(self, n_splits=5, random_state=None, shuffle=False):\n        super().__init__(n_splits=n_splits, random_state=random_state, shuffle=shuffle)\n\n    def _iter_test_indices(self, X=None, y=None, groups=None):\n        cv = MultilabelStratifiedKFold(\n            n_splits=self.n_splits,\n            random_state=self.random_state,\n            shuffle=self.shuffle,\n        )\n\n        value_counts = groups.value_counts()\n        regluar_indices = value_counts.loc[value_counts <= 18].index.sort_values()\n        irregluar_indices = value_counts.loc[value_counts > 18].index.sort_values()\n\n        group_to_fold = {}\n        tmp = y.groupby(groups).mean().loc[regluar_indices]\n\n        for fold, (_, test) in enumerate(cv.split(tmp, tmp)):\n            group_to_fold.update({group: fold for group in tmp.index[test]})\n\n        sample_to_fold = {}\n        tmp = y.loc[groups.isin(irregluar_indices)]\n\n        for fold, (_, test) in enumerate(cv.split(tmp, tmp)):\n            sample_to_fold.update({sample: fold for sample in tmp.index[test]})\n\n        folds = groups.map(group_to_fold)\n        is_na = folds.isna()\n        folds[is_na] = folds[is_na].index.map(sample_to_fold).values\n\n        for i in range(self.n_splits):\n            yield np.where(folds == i)[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtype = {\"cp_type\": \"category\", \"cp_dose\": \"category\"}\nindex_col = \"sig_id\"\n\ntrain_features = pd.read_csv(\n    \"../input/lish-moa/train_features.csv\", dtype=dtype, index_col=index_col\n)\ntest_features = pd.read_csv(\n    \"../input/lish-moa/test_features.csv\", dtype=dtype, index_col=index_col\n)\nX = train_features.select_dtypes(\"number\")\nX_test = test_features.select_dtypes(\"number\")\nY = pd.read_csv(\"../input/lish-moa/train_targets_scored.csv\", index_col=index_col)\ngroups = pd.read_csv(\n    \"../input/lish-moa/train_drug.csv\", index_col=index_col, squeeze=True\n)\n\ntrain_size, n_features = X.shape\ntest_size, _ = X_test.shape\n_, n_classes = Y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# hyperparameters\nn_seeds = 5\nn_splits = 5\nshuffle = True\nparams = {\"n_layers\": 4, \"rate\": 0.25}\ncallbacks_params = {\"patience_for_es\": 20, \"save_best_only\": True}\nfit_params = {\"epochs\": 1_000}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nY_pred = np.zeros((train_size, n_classes))\nY_pred = pd.DataFrame(Y_pred, columns=Y.columns, index=Y.index)\n\nfor i in range(n_seeds):\n    set_seed(seed=i)\n\n    cv = MultilabelStratifiedGroupKFold(\n        n_splits=n_splits, random_state=i, shuffle=shuffle\n    )\n\n    for j, (train, valid) in enumerate(cv.split(X, Y, groups)):\n        model_path = f\"model_seed_{i}_fold_{j}.h5\"\n\n        model = build_model(n_features, n_classes, **params)\n        callbacks = build_callbacks(model_path, **callbacks_params)\n\n        model.fit(\n            X.iloc[train],\n            Y.iloc[train],\n            callbacks=callbacks,\n            validation_data=(X.iloc[valid], Y.iloc[valid]),\n            **fit_params,\n        )\n\n        model.load_weights(model_path)\n\n        Y_pred.iloc[valid] += model.predict(X.iloc[valid]) / n_seeds\n\nY_pred[train_features[\"cp_type\"] == \"ctl_vehicle\"] = 0.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score(Y, Y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nY_pred = np.zeros((test_size, n_classes))\nY_pred = pd.DataFrame(Y_pred, columns=Y.columns, index=X_test.index)\n\nfor i in range(n_seeds):\n    for j in range(n_splits):\n        model = tf.keras.models.load_model(f\"model_seed_{i}_fold_{j}.h5\", compile=False)\n\n        Y_pred += model.predict(X_test) / n_seeds / n_splits\n\nY_pred[test_features[\"cp_type\"] == \"ctl_vehicle\"] = 0.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_pred.to_csv(\"submission.csv\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}