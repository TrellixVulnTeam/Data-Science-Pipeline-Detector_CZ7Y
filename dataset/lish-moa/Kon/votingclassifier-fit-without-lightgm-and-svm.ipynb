{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\n\nsys.path.append(\"../input/iterative-stratification/iterative-stratification-master\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pickle\n\nimport numpy as np\nimport pandas as pd\nfrom scipy.optimize import minimize\nfrom scipy.optimize import minimize_scalar\nfrom sklearn.metrics import roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import numpy as np\n\n\n# def objective_for_high(exponent, Y_true, Y_pred, label_smoothing=0.0):\n#     high = 1.0 - 10.0 ** exponent\n#     Y_pred = Y_pred.copy()\n#     Y_pred = np.clip(Y_pred, 0.0, high)\n\n#     return score(Y_true, Y_pred, label_smoothing=label_smoothing)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import numpy as np\n\n\n# def objective_for_low(exponent, Y_true, Y_pred, label_smoothing=0.0):\n#     low = 10.0 ** exponent\n#     Y_pred = Y_pred.copy()\n#     Y_pred = np.clip(Y_pred, low, 1.0)\n\n#     return score(Y_true, Y_pred, label_smoothing=label_smoothing)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def objective_for_threshold(exponent, Y_true, Y_pred, label_smoothing=0.0):\n    threshold = 10.0 ** exponent\n    Y_pred = Y_pred.copy()\n    Y_pred[Y_pred < threshold] = 0.0\n    Y_pred[Y_pred > 1.0 - threshold] = 1.0\n\n    return score(Y_true, Y_pred, label_smoothing=label_smoothing)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n\n\ndef objective_for_weights(weights, Y_true, Y_preds, label_smoothing=0.0):\n    Y_pred = np.tensordot(weights, Y_preds, axes=(0, 0))\n\n    return score(Y_true, Y_pred, label_smoothing=label_smoothing)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n\n\ndef score(Y, Y_pred, eps=1e-15, label_smoothing=0.0):\n    Y = np.asarray(Y)\n    Y = np.ravel(Y)\n\n    if label_smoothing > 0.0:\n        Y = Y * (1.0 - label_smoothing) + 0.5 * label_smoothing\n\n    Y_pred = np.asarray(Y_pred)\n    Y_pred = np.ravel(Y_pred)\n    Y_pred = np.clip(Y_pred, eps, 1.0 - eps)\n\n    return -np.mean(Y * np.log(Y_pred) + (1.0 - Y) * np.log(1.0 - Y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\nfrom sklearn.model_selection._split import _BaseKFold\n\n\nclass MultilabelStratifiedGroupKFold(_BaseKFold):\n    def __init__(self, n_splits=5, random_state=None, shuffle=False):\n        super().__init__(n_splits=n_splits, random_state=random_state, shuffle=shuffle)\n\n    def _iter_test_indices(self, X=None, y=None, groups=None):\n        cv = MultilabelStratifiedKFold(\n            n_splits=self.n_splits,\n            random_state=self.random_state,\n            shuffle=self.shuffle,\n        )\n\n        value_counts = groups.value_counts()\n        regluar_indices = value_counts.loc[\n            (value_counts == 6) | (value_counts == 12) | (value_counts == 18)\n        ].index.sort_values()\n        irregluar_indices = value_counts.loc[\n            (value_counts != 6) & (value_counts != 12) & (value_counts != 18)\n        ].index.sort_values()\n\n        group_to_fold = {}\n        tmp = y.groupby(groups).mean().loc[regluar_indices]\n\n        for fold, (_, test) in enumerate(cv.split(tmp, tmp)):\n            group_to_fold.update({group: fold for group in tmp.index[test]})\n\n        sample_to_fold = {}\n        tmp = y.loc[groups.isin(irregluar_indices)]\n\n        for fold, (_, test) in enumerate(cv.split(tmp, tmp)):\n            sample_to_fold.update({sample: fold for sample in tmp.index[test]})\n\n        folds = groups.map(group_to_fold)\n        is_na = folds.isna()\n        folds[is_na] = folds[is_na].index.map(sample_to_fold).values\n\n        for i in range(self.n_splits):\n            yield np.where(folds == i)[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n\n\nclass ObjectiveWithEarlyStopping(object):\n    def __init__(\n        self, y_true, y_preds, y_true_valid, y_preds_valid, label_smoothing=0.0, patience=30\n    ):\n        self.y_true = np.asarray(y_true)\n        self.y_preds = np.asarray(y_preds)\n        self.y_true_valid = np.asarray(y_true_valid)\n        self.y_preds_valid = np.asarray(y_preds_valid)\n        self.label_smoothing = label_smoothing\n        self.patience = patience\n\n        self._nit = 0\n        self._wait = 0\n        self._best_score = np.inf\n        self._best_weights = None\n\n    def __call__(self, params):\n        train_score = self._objective(\n            params,\n            self.y_true,\n            self.y_preds,\n            label_smoothing=self.label_smoothing,\n        )\n        valid_score = self._objective(\n            params,\n            self.y_true_valid,\n            self.y_preds_valid,\n            label_smoothing=self.label_smoothing,\n        )\n\n        self._nit += 1\n\n        if valid_score < self._best_score:\n            self._wait = 0\n            self._best_score = valid_score\n            self._best_params = params\n        else:\n            self._wait += 1\n\n        if self._wait >= self.patience:\n            raise RuntimeError(f\"Epoch {self._nit}: early stopping\")\n\n        return train_score\n\n\n# class ObjectiveForHighWithEarlyStopping(ObjectiveWithEarlyStopping):\n#     @property\n#     def _objective(self):\n#          return objective_for_high\n\n\n# class ObjectiveForLowWithEarlyStopping(ObjectiveWithEarlyStopping):\n#     @property\n#     def _objective(self):\n#          return objective_for_low\n\n\nclass ObjectiveForThresholdWithEarlyStopping(ObjectiveWithEarlyStopping):\n    @property\n    def _objective(self):\n         return objective_for_threshold\n\n\nclass ObjectiveForWeightsWithEarlyStopping(ObjectiveWithEarlyStopping):\n    @property\n    def _objective(self):\n         return objective_for_weights","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"index_col = \"sig_id\"\n\nY = pd.read_csv(\"../input/lish-moa/train_targets_scored.csv\", index_col=index_col)\ngroups = pd.read_csv(\n    \"../input/lish-moa/train_drug.csv\", index_col=index_col, squeeze=True\n)\n\ncolumns = Y.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_size, n_classes = Y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_preds = []\n\npaths = [\n    # anonamename\n    # \"../input/mlp-for-ensemble/kaggle_upload/Y_pred_2l.pkl\",\n    # \"../input/mlp-for-ensemble/kaggle_upload/Y_pred_3l_v2.pkl\",\n    # \"../input/mlp-for-ensemble/kaggle_upload/Y_pred_4l.pkl\",\n    # \"../input/mlp-for-ensemble/kaggle_upload/Y_pred_5l.pkl\",\n    \"../input/mlp-for-ensemble/kaggle_upload/Y_pred_rs.pkl\",\n    \"../input/mlp-for-ensemble/kaggle_upload/Y_pred_StackedTabNet.pkl\",\n    # \"../input/moa-grownet/Y_pred.pkl\",\n    # \"../input/moa-lgbmclassifier-classifierchain/Y_pred.pkl\",\n    # \"../input/moa-lightgbm/Y_pred.pkl\",\n    # \"../input/moa-rapids-svm-seed-y-pred/Y_pred.pkl\",\n    # ari hiro\n    \"../input/transformer-fit/Y_pred.pkl\",\n    # hirune924\n    \"../input/pytorch-mlp-tabnet-many-fe-predict/mlp_oof_avg.pkl\",\n    \"../input/pytorch-mlp-tabnet-many-fe-predict/tabnet_oof_avg.pkl\",\n    \"../input/pytorch-tabnet-pretraining-step3-many-fe-predict/tabnet_oof_avg.pkl\",\n    # Kon\n    # \"../input/lstmclassifier-fit/Y_pred.pkl\",\n    # \"../input/mlpclassifier-fit/Y_pred.pkl\",\n    \"../input/resnetclassifier-fit/Y_pred.pkl\",\n    # \"../input/tabnetclassifier-fit/Y_pred.pkl\",\n    # \"../input/transformerclassifier-fit/Y_pred.pkl\",\n    # ynishi\n    # \"../input/21-tabnet-fit/Y_pred.pkl\",\n]\nn_models = len(paths)\n\nresult = pd.DataFrame(index=paths)\n\nfor i, path in enumerate(paths):\n    with open(path, \"rb\") as f:\n        Y_pred = pickle.load(f)\n\n    Y_pred = np.asarray(Y_pred)\n\n    Y_preds.append(Y_pred)\n\n    result.loc[path, \"oof_logloss\"] = score(Y, Y_pred)\n    result.loc[path, \"oof_roc_auc_score\"] = roc_auc_score(Y, Y_pred, average=\"micro\")\n\nY_preds = np.asarray(Y_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = np.empty((n_models, n_models))\ncorr = pd.DataFrame(corr, columns=paths, index=paths)\n\nfor i, row in enumerate(paths):\n    for j, column in enumerate(paths):\n        if i <= j:\n            corr.loc[row, column] = 0\n        else:\n            df = pd.DataFrame(Y_preds[i])\n            other = pd.DataFrame(Y_preds[j])\n\n            corr.loc[row, column] = df.corrwith(other).mean()\n\ncorr.style.background_gradient(cmap=\"Blues\", subset=paths, vmax=1.0, vmin=0.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# hyperparameters\nn_seeds = 1\nn_splits = 5\nshuffle = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"%%time\nY_pred = np.zeros((train_size, n_classes))\nY_pred = pd.DataFrame(Y_pred, columns=Y.columns, dtype=\"float\", index=Y.index)\n\nweights = np.zeros((n_classes, n_models))\nn_iters = np.zeros(n_classes)\n\nx0 = np.ones(n_models) / n_models\nbounds = [(0.0, 1.0) for _ in range(n_models)]\nconstraints = {\n    \"type\": \"eq\",\n    \"fun\": lambda x: np.sum(x) - 1.0,\n    \"jac\": lambda x: np.ones_like(x),\n}\noptions = {\"ftol\": 0.0, \"maxiter\": 1_000_000}\n\nfor i in range(n_seeds):\n    cv = MultilabelStratifiedGroupKFold(\n        n_splits=n_splits, random_state=i, shuffle=shuffle\n    )\n\n    for j, (train, valid) in enumerate(cv.split(Y, Y, groups)):\n        for k, column in enumerate(columns):\n            objective = ObjectiveForWeightsWithEarlyStopping(\n                Y.iloc[train, [k]],\n                Y_preds[:, train, [k]],\n                Y.iloc[valid, [k]],\n                Y_preds[:, valid, [k]],\n                label_smoothing=1e-06,\n                patience=30,\n            )\n\n            try:\n                res = minimize(\n                    objective,\n                    x0,\n                    bounds=bounds,\n                    constraints=constraints,\n                    method=\"SLSQP\",\n                    options=options,\n                )\n            except RuntimeError:\n                pass\n\n            weights[k] += objective._best_params / n_seeds / n_splits\n            n_iters[k] += objective._nit / n_seeds / n_splits\n\n            Y_pred.iloc[valid, k] += np.tensordot(\n                objective._best_params, Y_preds[:, valid, [k]], axes=(0, 0)\n            ) / n_seeds\n\nwith open(\"weights.pkl\", \"wb\") as f:\n    pickle.dump(weights, f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result[\"weights_mean\"] = np.mean(weights, axis=0)\n\nresult.sort_values(\"oof_logloss\").style.background_gradient(cmap=\"Blues\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = pd.DataFrame(weights, columns=paths, index=Y.columns)\nresult[\"n_pos\"] = Y.sum()\nresult[\"n_iter\"] = n_iters\n\nresult.style.background_gradient(cmap=\"Blues\", subset=paths, vmax=1.0, vmin=0.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score(Y[columns], Y_pred[columns])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"roc_auc_score(Y[columns], Y_pred[columns], average=\"micro\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# %%time\n# Y_pred_postprocessed = np.zeros((train_size, n_classes))\n# Y_pred_postprocessed = pd.DataFrame(\n#     Y_pred_postprocessed, columns=Y.columns, dtype=\"float\", index=Y.index\n# )\n\n# thresholds = np.empty(n_classes)\n# n_iters = np.zeros(n_classes)\n\n# for i in range(n_seeds):\n#     cv = MultilabelStratifiedGroupKFold(\n#         n_splits=n_splits, random_state=i, shuffle=shuffle\n#     )\n\n#     for j, (train, valid) in enumerate(cv.split(Y, Y, groups)):\n#         for k, column in enumerate(columns):\n#             objective = ObjectiveForThresholdWithEarlyStopping(\n#                 Y.iloc[train, [k]],\n#                 Y_pred.iloc[train, [k]],\n#                 Y.iloc[valid, [k]],\n#                 Y_pred.iloc[valid, [k]],\n#                 # label_smoothing=1e-06,\n#                 patience=30,\n#             )\n\n#             try:\n#                 res = minimize_scalar(\n#                     objective,\n#                     bounds=[-6.0, -4.0],\n#                     method=\"bounded\",\n#                     options={\"maxiter\": 1_000_000, \"xatol\": 0.0},\n#                 )\n#             except RuntimeError:\n#                 pass\n\n#             thresholds[k] += objective._best_params / n_seeds / n_splits\n#             n_iters[k] += objective._nit / n_seeds / n_splits\n\n#             tmp = Y_pred.iloc[:, k].copy()\n#             tmp[tmp < 10 ** objective._best_params] = 0.0\n#             tmp[tmp > 1.0 - 10 ** objective._best_params] = 1.0\n\n#             Y_pred_postprocessed.iloc[valid, k] += tmp.iloc[valid] / n_splits\n\n# thresholds = 10 ** thresholds\n\n# with open(\"thresholds.pkl\", \"wb\") as f:\n#     pickle.dump(thresholds, f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# score(Y[columns], Y_pred_postprocessed[columns])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# roc_auc_score(Y[columns], Y_pred_postprocessed[columns], average=\"micro\")","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# b 0.015139477616298346: 5 models\n# + 0.015155485177579045: remove anonamename's resnet\n# + 0.015175202091833243: remove hirune924's mlp\n# + 0.015164515328761272: remove hirune924's tabnet\n# + 0.015267901074102700: remove Kon's resnet\n# + 0.015182427500416380: remove hirune924's custom tabnet\n# - 0.015137371244008616: add Kon's tabnet\n# - 0.015125755262557580: add anonamename's tabnet\n# - 0.015123081606109805: add ari hiro's transformer\n# + 0.015126446377100101: add anonamename's 2l-mlp\n# + 0.015127751381848550: add anonamename's lightgbm\n# + 0.015127386890777982: add Kon's transformer\n# + 0.015144190451307262: add anonamename's grownet\n# + 0.015129582758532654: add anonamename's 3l-mlp\n# + 0.015128664309679032: add Kon's lstm\n# + 0.015125454798629432: add anonamename's 4l-mlp\n# + 0.015125978015766315: add anonamename's 5l-mlp\n# + 0.015127642264192595: add Kon's mlp","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}