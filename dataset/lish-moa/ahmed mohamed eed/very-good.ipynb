{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\nsys.path.append('../input/iterative/iterative-stratification-master/')\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.metrics import log_loss\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import regularizers\nimport tensorflow_addons as tfa\n\nimport random","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = pd.read_csv('/kaggle/input/lish-moa/train_features.csv')\nX_test = pd.read_csv('/kaggle/input/lish-moa/test_features.csv')\ny_train = pd.read_csv('/kaggle/input/lish-moa/train_targets_scored.csv')\nsubmission = pd.read_csv('/kaggle/input/lish-moa/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.set_index('sig_id', inplace=True)\nX_test.set_index('sig_id', inplace=True)\ny_train.set_index('sig_id', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.cp_time = X_train.cp_time // 24\nX_train.cp_dose = X_train.cp_dose.map({'D1': 0, 'D2': 1})\nX_test.cp_time = X_test.cp_time // 24\nX_test.cp_dose = X_test.cp_dose.map({'D1': 0, 'D2': 1})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_moa = X_train[X_train.cp_type != 'ctl_vehicle'].drop(columns=['cp_type'])\nX_test_moa = X_test[X_test.cp_type != 'ctl_vehicle'].drop(columns=['cp_type'])\n\n# Don't forget to keep only proper rows in y_train\ny_train_moa = y_train.loc[X_train_moa.index]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_moa.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mean_predictions(models_dense, X):\n    y_pred_dense = [model.predict(X) for model in models_dense]\n    return np.mean(y_pred_dense, axis=0)\n\ndef macro_log_loss(y_true, y_pred):\n    if len(y_true.shape) == 1:\n        return log_loss(y_true, y_pred, labels=[0, 1]), [log_loss(y_true, y_pred, labels=[0, 1])] \n    y_pred = np.maximum(np.minimum(y_pred, [[1 - 1e-15] * y_pred.shape[1]] * y_pred.shape[0]), [[1e-15] * y_pred.shape[1]] * y_pred.shape[0])\n    losses = [log_loss(y_true[:, i], y_pred[:, i], labels=[0, 1]) for i in range(y_true.shape[1])]\n    return np.mean(losses), losses","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model():\n    model = tf.keras.Sequential([\n    tf.keras.layers.Input(N_FEATURES),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.3),\n    tfa.layers.WeightNormalization(tf.keras.layers.Dense(1024, activation=\"relu\")),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.4),\n\n    tfa.layers.WeightNormalization(tf.keras.layers.Dense(1024, activation=\"relu\")),  \n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.3),\n    tfa.layers.WeightNormalization(tf.keras.layers.Dense(N_TARGETS, activation=\"sigmoid\"))\n    ])\n    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = LR), loss='binary_crossentropy', metrics=[\"accuracy\"])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_dense_model(input_shape, output_shape):\n    inputs = keras.Input(shape=(input_shape,), name='drug')\n    x = layers.BatchNormalization()(inputs)\n    x = layers.Dropout(0.3)(x)\n    x = tfa.layers.WeightNormalization(layers.Dense(units=1024, activation='relu', name='dense_1'))(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Dropout(0.4)(x)\n    x = tfa.layers.WeightNormalization(layers.Dense(units=1024, activation='relu', name='dense_2'))(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Dropout(0.3)(x)\n    output = tfa.layers.WeightNormalization(layers.Dense(output_shape, activation='sigmoid', kernel_regularizer=keras.regularizers.l2(l2=1e-5), \n                                                         name='predictions'))(x)\n    model = keras.Model(inputs=inputs, outputs=output)\n    opt = tfa.optimizers.AdamW(weight_decay=1e-5, learning_rate=1e-2)\n    model.compile(optimizer=opt, loss='binary_crossentropy')\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"callbacks = [\n    keras.callbacks.EarlyStopping(\n        monitor='val_loss',\n        min_delta=1e-5,\n        patience=3,\n        verbose=0),\n    keras.callbacks.ReduceLROnPlateau(\n        monitor=\"val_loss\",\n        factor=0.1,\n        patience=2)\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_dense = X_train_moa.to_numpy()\ny_train_dense = y_train_moa.to_numpy()\n\nkf = MultilabelStratifiedKFold(n_splits=5, shuffle=True)\nmlls = []\nmodels = []\ni = 1\nfor train, test in kf.split(x_train_dense, y_train_dense):\n    print(f'FOLD {i}.', end=' ')\n    i = i + 1\n    \n    from numpy.random import seed\n    seed(train[0])\n    tf.random.set_seed(train[0])\n\n    dense = create_dense_model(x_train_dense.shape[1], y_train_dense.shape[1])\n    history_dense = dense.fit(x_train_dense[train], y_train_dense[train],\n                     batch_size=64,\n                     epochs=100,\n                     callbacks=callbacks,\n                     validation_data=(x_train_dense[test], y_train_dense[test]),\n                     shuffle=True, verbose=0)\n    mll, _ = macro_log_loss(y_train_dense[test], dense.predict(x_train_dense[test]))\n    models.append(dense)\n    mlls.append(mll)\n    print('Dense macro log loss:', mll)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(np.mean(mlls))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = mean_predictions(models, X_test_moa)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"indexes = dict(zip(X_test_moa.index, range(X_test_moa.shape[0])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for idx, row in submission.iterrows():\n    sig_id = row.sig_id\n    if sig_id in indexes.keys():\n        submission.loc[idx] = [sig_id] + [np.maximum(np.minimum(pred, 1 - 1e-3), 1e-3) for pred in preds[indexes[sig_id]]]\n    else:\n        submission.loc[idx] = [sig_id] + [0] * preds.shape[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}