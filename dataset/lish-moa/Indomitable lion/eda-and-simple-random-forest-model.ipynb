{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"**The goal of this notebook is to carry out and EDA on train and test data and build a simple random Forest model.**","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import sys\nimport pandas as pd\nimport numpy as np\n\nimport seaborn as sns\n\n#from scipy.stats import entropy\nfrom matplotlib import pyplot as plt\n%matplotlib inline\n\nfrom scipy.stats import skew\nfrom sklearn.model_selection import  KFold , GridSearchCV, train_test_split\nfrom sklearn.ensemble import  RandomForestClassifier\nimport json\nfrom sklearn.feature_selection import SelectKBest, chi2, f_classif\nfrom sklearn.metrics import confusion_matrix, log_loss, make_scorer, accuracy_score, f1_score\n\nfrom sklearn.preprocessing import scale\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.feature_selection import VarianceThreshold\n\nfrom sklearn.preprocessing import LabelEncoder","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"####  Data analysis functions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def missing_perc(df):\n     \"\"\"\n     Return a dataframe with percentage of missing values\n     in each column in a sorted order\n     Args:\n     df: dataframe\n     Returns:\n     dataframe with percentage of missing values in each column\n     \"\"\"\n\n     missing = df.isnull().sum()\n     missing = missing[missing > 0] * 100 / df.shape[0]\n     missing.sort_values(inplace=True)\n     return pd.DataFrame(missing, columns=['missing_perc'])\n\n\ndef unique_val(df, outputcol='n_unique_vals'):\n     \"\"\"\n     Count the number of distinct values in each column in a sorted order\n     Args:\n     df: dataframe\n     col: string, column name of the output dataframe\n     Returns:\n     dataframe with the number of distinct values in each column\n     \"\"\"\n\n     columns = df.columns\n     undict = {}\n     for col in columns:\n         undict[col] = df[col].astype(str).nunique()\n     undf = pd.DataFrame.from_dict(undict,\n         'index',\n         columns=[outputcol])\n     undf.sort_values(by=[outputcol], inplace=True)\n     return undf\n\n\ndef getCategoricalVariablesRanking(df, target, limit=50):\n    \"\"\"\n    Return sorted chi square statistics for categorical features\n    Source: https://scikit-learn.org/stable/modules/generated/sklearn.\n    feature_selection.chi2.html#sklearn.feature_selection.chi2\n    Args:\n         df: pandas dataframe\n         target: string corresponding to the categorical target column\n    Returns:\n         list object with sorted chi square statistics\n    \"\"\"\n    categorical_variables = [i for i in list(df.dtypes[df.dtypes == 'object'].index) if i != target]\n    chi2_selector = SelectKBest(chi2, k='all')\n    df_chi_final = pd.DataFrame(columns=[\"scaled_importance\", \"value\", \"column\"])\n    for col in categorical_variables:\n        dummy = pd.get_dummies(df[col])\n        chi2_selector.fit_transform(dummy, df[target])\n        df_chi = pd.DataFrame(chi2_selector.scores_,\n                              columns=['scaled_importance'])\n        df_chi[\"value\"] = dummy.columns\n        df_chi[\"column\"] = col\n        df_chi_final = pd.concat([df_chi_final, df_chi], axis=0)\n\n    df_chi_final[\"scaled_importance\"] -= df_chi_final[\"scaled_importance\"].min()\n    df_chi_final[\"scaled_importance\"] /= df_chi_final[\"scaled_importance\"].max()\n    df_chi_final = df_chi_final.sort_values(by='scaled_importance', ascending=False).head(limit)\n\n    return df_chi_final\n\ndef getContinuousVariablesRanking(df, target):\n    \"\"\"\n    Return sorted F value statistics for continuous features\n    Source: https://scikit-learn.org/stable/modules/generated/sklearn.\n    feature_selection.SelectKBest.html#sklearn.feature_selection.SelectKBest\n    Args:\n         df: pandas dataframe\n         target: string corresponding to the categorical target column\n    Returns:\n         dataframe with sorted F value statistics\n    \"\"\"\n    cont_vars = [i for i in list(df.dtypes[df.dtypes != 'object'].index) if i != target]\n\n    Fvalue_selector = SelectKBest(f_classif, k=len(cont_vars))\n    Fvalue_selector.fit_transform(df[cont_vars].fillna(-1), df[target])\n    df_Fvalue = pd.DataFrame(Fvalue_selector.scores_,\n                             columns=['scaled_importance'])\n    # scaling the statistics\n    df_Fvalue -= df_Fvalue.min()\n    df_Fvalue /= df_Fvalue.max()\n    df_Fvalue['columns'] = cont_vars\n    df_Fvalue.sort_values(by='scaled_importance', ascending=False, inplace=True)\n    \n    return df_Fvalue","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Reading input data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pwd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nsub = pd.read_csv('/kaggle/input/lish-moa/sample_submission.csv')\ntrain_features = pd.read_csv('/kaggle/input/lish-moa/train_features.csv')\ntest_features = pd.read_csv('/kaggle/input/lish-moa/test_features.csv')\ntrain_targets_nonscored = pd.read_csv('/kaggle/input/lish-moa/train_targets_nonscored.csv')\ntrain_targets_scored = pd.read_csv('/kaggle/input/lish-moa/train_targets_scored.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\n## EDA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ntrain_features.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_targets_scored.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(train_targets_scored.mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have a high imbalance: the max target rate is 0.03, the min is very low. We would need to be careful.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_features.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_targets_scored.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Analysing missing values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#missing values\nmissing_perc(train_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#missing values\nmissing_perc(test_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#missing values\nmissing_perc(train_targets_scored)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are no missing values","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Counting unique values**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"unique_val(train_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unique_val(test_features)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Based on the description columns cp_type and cp_dose can be set as categorical.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"catList = ['cp_type', 'cp_dose']\n\ncountList =  list (set(train_features.columns) - set(catList))\n\ncountList.remove('sig_id')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Checking for duplicated rows in the training set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_features.shape,  train_features.drop_duplicates().shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is no duplicate in the training set.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Categorical variables distribution","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(2, 1, figsize=(6, 4))\n\nfor i, ax in enumerate(fig.axes):\n    if i < len(catList):\n        ax.set_xticklabels(ax.xaxis.get_majorticklabels(), rotation=90)\n        sns.countplot(x=catList[i], alpha=0.7, data=train_features, ax=ax)\n\nfig.tight_layout()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1, 1, figsize=(6, 4))\n\nfor i, ax in enumerate(fig.axes):\n\n    ax.set_xticklabels(ax.xaxis.get_majorticklabels(), rotation=90)\n\n    sns.countplot(x='cp_time', alpha=0.7, data=train_features, ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(2, 1, figsize=(6, 4))\n\nfor i, ax in enumerate(fig.axes):\n    if i < len(catList):\n        ax.set_xticklabels(ax.xaxis.get_majorticklabels(), rotation=90)\n        sns.countplot(x=catList[i], alpha=0.7, data=test_features, ax=ax)\n\nfig.tight_layout()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1, 1, figsize=(6, 4))\n\nfor i, ax in enumerate(fig.axes):\n\n    ax.set_xticklabels(ax.xaxis.get_majorticklabels(), rotation=90)\n\n    sns.countplot(x='cp_time', alpha=0.7, data=test_features, ax=ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Feature importance analysis based on the most represented target value: wnt_inhibitor ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_targets_scored.mean()[train_targets_scored.mean() == train_targets_scored.mean().max()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain_features_toptarget_count = pd.concat([train_features[countList], train_targets_scored['nfkb_inhibitor'].astype('str')], axis = 1)\n\ndf_Fvalue_s = getContinuousVariablesRanking(train_features_toptarget_count, 'nfkb_inhibitor')\n\ndf_Fvalue_s","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n = 10\nplt.figure(figsize=(10,5))\nplt.title(\"F-value scaled importance for continuous features (top 10, target = nfkb_inhibitor)\",fontsize=15)\nplt.xlabel(\"Continuous Features\",fontsize=15)\nplt.xticks(fontsize=15)\nplt.yticks(fontsize=15)\nplt.bar(range(10),df_Fvalue_s.head(10)['scaled_importance'],align='edge',color='rgbkymc')\nplt.xticks(range(10),df_Fvalue_s.head(10)['columns'],rotation=90,color='g')\nplt.show()\nplt.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n = 10\nplt.figure(figsize=(10,5))\nplt.title(\"F-value scaled importance for continuous features (bottom 10, target = nfkb_inhibitor)\",fontsize=15)\nplt.xlabel(\"Continuous Features\",fontsize=15)\nplt.xticks(fontsize=15)\nplt.yticks(fontsize=15)\nplt.bar(range(10),df_Fvalue_s.tail(10)['scaled_importance'],align='edge',color='rgbkymc')\nplt.xticks(range(10),df_Fvalue_s.tail(10)['columns'],rotation=90,color='g')\nplt.show()\nplt.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colist = df_Fvalue_s.head(10)['columns']\nlabel = 'nfkb_inhibitor'\n\nfor col in colist: \n    \n    g = sns.FacetGrid(train_features_toptarget_count[[col, label]],  hue =label, height = 4, aspect = 1.5) \n    g.map(sns.distplot, col, hist = False, kde_kws = {'shade': True, 'linewidth': 3}).set_axis_labels(col,\"density\").add_legend()\n\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain_features_toptarget_cat = pd.concat([train_features[catList], train_targets_scored['nfkb_inhibitor'].astype('str')], axis = 1)\n\n\ngetCategoricalVariablesRanking(train_features_toptarget_cat, 'nfkb_inhibitor')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_toptarget_cat[train_features_toptarget_cat.cp_type == 'ctl_vehicle'][label].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As stated in the description control perturbation (ctrl_vehicle) has no MOA. Predictions will be set to zero for these samples.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_features[test_features.cp_type == 'ctl_vehicle'].shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Even though not depicted here the feature importance is found to vary with the target as one would expect.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Label encoding the categorical variables","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"lb=LabelEncoder()\n\nfor f in catList: \n\n    train_features[f]=lb.fit_transform(train_features[f])\n    test_features[f]=lb.transform(test_features[f])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colList = list(train_targets_scored.columns[1:])\ntrain_features2 = train_features[countList+ catList]\n#mask = test_features.cp_type == test_features.cp_type.value_counts().index[-1]\n\nfor label in colList: \n    \n    y_train = train_targets_scored[label]\n    rf = RandomForestClassifier(class_weight='balanced', max_depth=15,\n                            n_estimators=500, #500\n                            n_jobs=-1, \n                            random_state=1234)\n    rf.fit(train_features2, y_train)\n    test_features[label] =  rf.predict_proba(test_features[countList + catList])[:,1] \n    #test_features.loc[mask][label] = 0\n    #print('label:', label)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Saving predictions.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_features[\n['sig_id'] + colList].head()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_features[\n['sig_id'] + colList ].to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}