{"cells":[{"metadata":{},"cell_type":"markdown","source":"Первая версия - 6 эпох lb = 0.01918\n\nВторая версия - 20 эпох + GPU сделал lb = 0.02666 (плохо!)\n\nТретья версия - DropOut + Sigmoid"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"dir0 = '../input/lish-moa/'\n# dir0 = \"\"\ntrain_features = pd.read_csv(dir0 + 'train_features.csv')\ntrain_targets_scored = pd.read_csv(dir0 + 'train_targets_scored.csv')\ntrain_targets_nonscored = pd.read_csv(dir0 + 'train_targets_nonscored.csv')\nsample_submission = pd.read_csv(dir0 + 'sample_submission.csv')\ntest_features = pd.read_csv(dir0 + 'test_features.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_features(train_features):\n    train_features['cp_type'] = (train_features['cp_type'] == 'ctl_vehicle').astype(int)\n    train_features['cp_time'] = (train_features['cp_time'] - 48) / 24\n    train_features['cp_dose'] = (train_features['cp_dose'] == 'D1').astype(int)\n    train_features_ids = train_features.pop('sig_id')\n    return (train_features, train_features_ids)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features, train_features_ids = make_features(train_features)\ntest_features, test_features_ids = make_features(test_features)\n\ntrain_targets_scored_sig_id = train_targets_scored.pop('sig_id')\n\nprint (train_features.shape, test_features.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ii = train_features.cp_type.values==0\ntrain_features = train_features.loc[ii]\ntrain_targets_scored = train_targets_scored.loc[ii]\nprint (train_features.shape, test_features.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_targets_scored.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = TensorDataset(torch.tensor(train_features.values, dtype=torch.float32).to(device),\n                              torch.tensor(train_targets_scored.values, dtype=torch.float32).to(device))\ntrain_dataloader = DataLoader(train_dataset, batch_size=256, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features.shape, train_targets_scored.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MyModel(nn.Module):\n    def __init__(self, in_features, out_features):\n        super().__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n\n        self.model = nn.Sequential(\n            nn.BatchNorm1d(in_features),\n            nn.Dropout(0.3),\n            nn.Linear(in_features, 800),\n            nn.Sigmoid(),\n\n            nn.BatchNorm1d(800),            # nn.Dropout(0.1),\n            nn.Dropout(0.3),\n            nn.Linear(800, 600),\n            nn.Sigmoid(),\n\n            nn.BatchNorm1d(600),            # nn.Dropout(0.1),\n            nn.Dropout(0.3),\n            nn.Linear(600, 400),\n            nn.Sigmoid(),\n\n            nn.BatchNorm1d(400),\n            nn.Linear(400, out_features),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        return self.model(x)\n    \n# class MyModel(nn.Module):\n#     def __init__(self, in_features, out_features):\n#         super().__init__()\n#         self.in_features = in_features\n#         self.out_features = out_features\n\n#         self.model = nn.Sequential(\n#             nn.BatchNorm1d(in_features),\n#             nn.Linear(in_features, 800),\n#             nn.ReLU(),\n\n#             nn.BatchNorm1d(800),            # nn.Dropout(0.1),\n#             nn.Linear(800, 600),\n#             nn.ReLU(),\n\n#             nn.BatchNorm1d(600),            # nn.Dropout(0.1),\n#             nn.Linear(600, 400),\n#             nn.ReLU(),\n\n#             nn.BatchNorm1d(400),\n#             nn.Linear(400, out_features),\n#             nn.Sigmoid()\n#         )\n\n#     def forward(self, x):\n#         return self.model(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nmodel = MyModel(train_features.shape[1], train_targets_scored.shape[1]).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3) #SGD(model.parameters(), lr=1e-3)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, 0.05, 10)\ncriterion = nn.BCELoss()\nmax_epoch = 20\n\nfor epoch in range(max_epoch):\n    model.train()\n    for i, (x_batch, y_batch) in enumerate(train_dataloader):\n        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n        preds = model(x_batch)\n\n        optimizer.zero_grad()\n        loss = criterion(preds, y_batch)\n        loss.backward()\n        optimizer.step()\n\n        if i % 20 == 0:\n            print(f'Epoch: {epoch}, train loss: {loss.item():12.5f}')\n\n    model.eval()\n    with torch.no_grad():\n        train, y_train = train_dataset.tensors\n        train, y_train = train.to(device), y_train.to(device)\n        train_preds = model(train)\n        train_loss = criterion(train_preds, y_train).item()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model = MyModel(train_features.shape[1], train_targets_scored.shape[1])\n# optimizer = torch.optim.Adam(model.parameters()) #SGD(model.parameters(), lr=1e-3)\n# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 0.05, 10)\n# criterion = nn.BCELoss()\n# max_epoch = 6\n\n# for epoch in range(max_epoch):\n#     model.train()\n#     for i, (x_batch, y_batch) in enumerate(train_dataloader):\n#         preds = model(x_batch)\n\n#         optimizer.zero_grad()\n#         loss = criterion(preds, y_batch)\n#         loss.backward()\n#         optimizer.step()\n\n#         if i % 20 == 0:\n#             print(f'Epoch: {epoch}, train loss: {loss.item():12.5f}')\n\n#     model.eval()\n#     with torch.no_grad():\n#         train, y_train = train_dataset.tensors\n#         train_preds = model(train)\n#         train_loss = criterion(train_preds, y_train).item()\n        \n# #         test, y_test = test_dataset.tensors\n# #         test_preds = model(test)\n# #         test_loss = criterion(test_preds, y_test).item()\n#         print(f'Epoch {epoch} final: train loss: {train_loss}')#, f'test loss: {test_loss}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.eval()\nwith torch.no_grad():\n    probs = model(torch.tensor(test_features.values, dtype=torch.float32).to(device))\n    \nprobs = probs.to(\"cpu\").numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ii2 = test_features.cp_type.values==1 # 1 !!!!\nprobs[ii2,:] = 0.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame(probs, index=test_features_ids, columns=train_targets_scored.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_csv('submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}