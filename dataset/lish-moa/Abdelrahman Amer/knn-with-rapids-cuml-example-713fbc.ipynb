{"cells":[{"metadata":{},"cell_type":"markdown","source":"# RAPIDS CuML\nThe RAPIDS library is now available in all Kaggle notebooks. Hooray! Simply type `import cuml` or `import cudf` to load the two most popular packages.\n\nRAPIDS is described [here][1]. RAPIDS `cuDF` accelerates dataframe operations using GPU and has a similar api as Pandas. RAPIDS `cuML` accelerates machine learning algorithms using GPU and has a similar api as Scikit-Learn. Since RAPIDS ML algorithms are so fast, we can do things that were never possible like applying genetic algorithms to ML hyperparameter searchs!\n\n[1]: https://rapids.ai/"},{"metadata":{},"cell_type":"markdown","source":"# Load Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys, warnings\nwarnings.filterwarnings(\"ignore\")\nsys.path.append('../input/iterativestratification')\n\nimport pandas as pd, numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import KFold\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n\nfrom sklearn.metrics import log_loss\n\nimport cuml\nprint('RAPIDS',cuml.__version__)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load Data"},{"metadata":{},"cell_type":"markdown","source":"## First 30% test 70% trainig"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/otto-group-product-classification-challenge/train.csv')\nprint('train shape',train.shape)\ntest = pd.read_csv('../input/otto-group-product-classification-challenge/test.csv')\nprint('test shape',test.shape)\n\ntrain['target'].nunique()\n#targets = pd.read_csv('../input/lish-moa/train_targets_scored.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y= le.fit_transform(train['target'])\ny","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.iloc[:,1:-1] #to remove the 1st coloumn which is ID and target.\ntrain.shape\n#train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(train,y, test_size=0.3, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nclassifier = KNeighborsClassifier(n_neighbors=3)\nclassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cudf, cuml\nfrom cuml.neighbors import KNeighborsClassifier as cuKNeighbors\nmodel = cuKNeighbors(n_neighbors=3)\nmodel.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(x_test)\ny_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\naccuracy = accuracy_score(y_test, y_pred)\naccuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nroc_acc = cross_val_score(classifier, x_train, y_train, cv=5, scoring='roc_auc_ovr').mean()\nroc_acc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NGL = cross_val_score(model, x_train, y_train, scoring='neg_log_loss').mean()\nNGL","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"   \n  ## Now for 20% test and 80% train"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(train,y, test_size=0.2, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nclassifier = KNeighborsClassifier(n_neighbors=3)\nclassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from cuml.neighbors import KNeighborsClassifier as cuKNeighbors\nmodel = cuKNeighbors(n_neighbors=3)\nmodel.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(x_test)\ny_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\naccuracy = accuracy_score(y_test, y_pred)\naccuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nroc_acc = cross_val_score(classifier, x_train, y_train, cv=5, scoring='roc_auc_ovr').mean()\nroc_acc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NGL = cross_val_score(model, x_train, y_train, scoring='neg_log_loss').mean()\nNGL","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## For the last one 10% test and 90% train"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(train,y, test_size=0.1, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nclassifier = KNeighborsClassifier(n_neighbors=3)\nclassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from cuml.neighbors import KNeighborsClassifier as cuKNeighbors\nmodel = cuKNeighbors(n_neighbors=3)\nmodel.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(x_test)\ny_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\naccuracy = accuracy_score(y_test, y_pred)\naccuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nroc_acc = cross_val_score(classifier, x_train, y_train, cv=5, scoring='roc_auc_ovr').mean()\nroc_acc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NGL = cross_val_score(model, x_train, y_train, scoring='neg_log_loss').mean()\nNGL","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### As we can see... the increasing in accurecy is small. but its increasing when we but more data in training and less in testing.\n\n### for the ROC_ACC its also increasing but very small increase. Same for the Neg_log_loss.\n\n### So, the 10% test and 90% training is the best."},{"metadata":{},"cell_type":"markdown","source":"# K-fold validation:"},{"metadata":{"trusted":true},"cell_type":"code","source":"kmodel = cuKNeighbors(n_neighbors=3)\nkmodel.fit(train, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\ncross_val_score(model, train, y, cv=5, scoring='accuracy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"avrg = cross_val_score(model, train, y, cv=5, scoring='accuracy').mean()\navrg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"roc_acc = cross_val_score(model, train, y, cv=5, scoring='roc_auc_ovr').mean()\nroc_acc","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### From this output it is safe to say that this methond \"k-fold\" gave us the same results as the previous ones. But, we can notice that this method has a very small increase more than the previous methods. Not big diffrence though."},{"metadata":{},"cell_type":"markdown","source":"## For the optimal K number:"},{"metadata":{"trusted":true},"cell_type":"code","source":"k_list = list(range(2, 200))\nk_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_scores = []\n\nfor k in k_list:\n    knn = cuKNeighbors(n_neighbors=k)\n    scores = cross_val_score(knn, train, y, cv=5, scoring='accuracy').mean()\n    cv_scores.append(scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_scores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\n\nplt.figure()\nplt.title(\"The optimal number of neighbors\")\nplt.xlabel(\"Number of Neighbors K\")\nplt.ylabel(\"Accuracy\")\nsns.set_style(\"whitegrid\")\nplt.plot(k_list, cv_scores)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_k = k_list[cv_scores.index(max(cv_scores))]\nbest_k\n\n#optimal number of neighbors","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}