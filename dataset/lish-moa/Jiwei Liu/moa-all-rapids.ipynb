{"cells":[{"metadata":{},"cell_type":"markdown","source":"This notebook is inspired by [Yirun Zhang's great rapids svm kernel](https://www.kaggle.com/gogo827jz/rapids-svm-on-gpu-6000-models-in-1-hour).\n\nWe go a step further to use rapids libraries exclusively for the entire pipeline including data preprocessing, training and scoring. To make a point, we don't even import `numpy`, `pandas` and `sklearn`. We use simple `LogisticRegression` models and **in less than 10 mins** it gets a better score than previous best rapids demo. "},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings, sys\nwarnings.filterwarnings(\"ignore\")\n\n# Thanks to Chris's RAPIDS dataset, it only takes around 1 min to install offline\n!cp ../input/rapids/rapids.0.15.0 /opt/conda/envs/rapids.tar.gz\n!cd /opt/conda/envs/ && tar -xzvf rapids.tar.gz > /dev/null\nsys.path = [\"/opt/conda/envs/rapids/lib/python3.7/site-packages\"] + sys.path\nsys.path = [\"/opt/conda/envs/rapids/lib/python3.7\"] + sys.path\nsys.path = [\"/opt/conda/envs/rapids/lib\"] + sys.path \n!cp /opt/conda/envs/rapids/lib/libxgboost.so /opt/conda/lib/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cudf as gd\nimport cupy as cp\nfrom cuml.svm import SVC\nfrom cuml.preprocessing import LabelEncoder\nfrom cuml.linear_model import LogisticRegression\nfrom numba import cuda\nfrom cuml.metrics import log_loss, roc_auc_score\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '../input/lish-moa'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain = gd.read_csv(f'{path}/train_features.csv')\ntest = gd.read_csv(f'{path}/test_features.csv')\nfea_cols = train.columns.values[1:]\nprint(train.shape, test.shape)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nlbl = LabelEncoder()\ntrain['cp_type'] = lbl.fit_transform(train['cp_type'])\ntest['cp_type'] = lbl.transform(test['cp_type'])\ntrain['cp_type'].value_counts()\nprint('0 means control group')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nprint(train['cp_time'].value_counts())\nprint(test['cp_time'].value_counts())\ntrain['cp_time'] = train['cp_time']/24 - 2\ntest['cp_time'] = test['cp_time']/24 - 2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nlbl = LabelEncoder()\ntrain['cp_dose'] = lbl.fit_transform(train['cp_dose'])\ntest['cp_dose'] = lbl.transform(test['cp_dose'])\ntrain['cp_dose'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\n# confirm there is no missing values\n\nfor col in train.columns:\n    nasum = train[col].isnull().sum() + test[col].isnull().sum()\n    if nasum: print(col, nasum)       ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\n# normalize \n\nfor col in train.columns[4:]:\n    mean, std = train[col].mean(), train[col].std()\n    train[col] = (train[col] - mean)/std\n    test[col] = (test[col] - mean)/std\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\ntrain_targets = gd.read_csv(f'{path}/train_targets_scored.csv')\nprint(train_targets.shape)\ntrain_targets.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\ntrain = train.merge(train_targets, on='sig_id', how='left')\nprint(train.shape)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\n# confirm control group has all 0 targets\n\nmask = train.cp_type == 0\ntcols = train_targets.columns[1:].values\nycontrol = train.loc[mask, tcols].values\nycontrol.max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nprint(train.shape)\ntrain = train.loc[train.cp_type>0]\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nX = train[fea_cols].values\nXt = test[fea_cols].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class StratifiedKFold_gpu:\n    \n    def __init__(self,n_splits=3,shuffle=True,random_state=42,tpb=32,mode='relax'):\n        self.n_splits = n_splits\n        self.shuffle = shuffle\n        self.seed = random_state\n        self.tpb = tpb # threads per thread block\n        self.mode = mode\n        \n    def get_n_splits(self, X=None, y=None):\n        return self.n_splits\n              \n    def split(self,x,y):\n        \n        assert x.shape[0] == y.shape[0]\n        df = gd.DataFrame()\n        ids = cp.arange(x.shape[0])\n        \n        if self.shuffle:\n            cp.random.seed(self.seed)\n            cp.random.shuffle(ids)\n            x = x[ids]\n            y = y[ids]\n        \n        cols = []\n        df['y'] = y\n        df['ids'] = ids\n    \n        grpby = df.groupby(['y'])\n        if self.mode == 'sklearn':\n            dg = grpby.agg({'y':'count'})\n            #print(dg.columns)\n            col = dg.columns[0]\n            msg = 'n_splits=%d cannot be greater than the number of members in each class.'%self.n_splits\n            assert dg[col].min()>=self.n_splits,msg\n\n        def get_order_in_group(y,ids,order):\n            for i in range(cuda.threadIdx.x, len(y), cuda.blockDim.x):\n                order[i] = i\n\n        got = grpby.apply_grouped(get_order_in_group,incols=['y','ids'],\n                                  outcols={'order': 'int32'},\n                                  tpb=self.tpb)\n\n        got = got.sort_values('ids')\n        \n        for i in range(self.n_splits):\n            mask = got['order']%self.n_splits==i\n            train = got.loc[~mask,'ids'].values\n            test = got.loc[mask,'ids'].values\n            if len(test)==0:\n                break\n            yield train,test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\ndef calibrate(y, mean, eps = 1e-4):\n    ymean = y.mean()\n    eps = min(eps, ymean)\n    y = y - ymean + mean\n    return cp.clip(y, eps, 1-eps)\n    \ndef cv(X, y, Xt, folds = 4):\n    skf = StratifiedKFold_gpu(n_splits=folds)#, random_state=None, shuffle=False)\n\n    scores = 0\n    ysub = 0\n    for train_index, test_index in skf.split(X, y):\n        X_train, X_test = X[train_index], X[test_index]\n        y_train, y_test = y[train_index], y[test_index]\n        \n        model = LogisticRegression(C=0.01)\n        model.fit(X_train, y_train)\n        yp = model.predict_proba(X_test)[:,1]\n        yp = cp.asarray(yp, order='C')\n        yp = calibrate(yp, y_train.mean())\n        \n        yps = model.predict_proba(Xt)[:,1]\n        yps = cp.asarray(yps, order='C')\n        yps = calibrate(yps, y_train.mean())\n        ysub += yps\n        \n        score = log_loss(y_test, yp)\n\n        scores += score\n    return scores/folds, ysub/folds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nscores = []\nmean_scores = []\ntargets = train_targets.columns.values[1:]\n\nsub = test[['sig_id', 'cp_type']]\n\nfor ycol in tqdm(targets, total=len(targets)):\n    y = train[ycol].values\n    try:\n        score, ysub = cv(X, y, Xt, folds=8)\n    except:\n        ysub = cp.ones(Xt.shape[0])*y.mean()\n        score = log_loss(y, cp.ones_like(y)*y.mean())\n    mean_score = log_loss(y, cp.ones_like(y)*y.mean())\n    sub[ycol] = ysub #if score < mean_score else y.mean()\n\n    scores.append(score)\n    mean_scores.append(mean_score)\n\nscores = gd.DataFrame({'model_score': scores, 'target': targets, 'mean_score':mean_scores})\nscores['best'] = cp.minimum(scores['model_score'].values, scores['mean_score'].values)\n\nscores = scores.sort_values(by='model_score', ascending=False)\nprint(f\"best:{scores['best'].mean():.5f}, mean:{scores['mean_score'].mean():.5f}, model:{scores['model_score'].mean():.5f}\")\nscores.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nmask = sub['cp_type'] == 0\ncontrol_sum = mask.sum()\nprint(sub.shape[0], control_sum)\n\nfor col in targets:\n    ys = sub[col].values.copy()\n    sub.loc[mask, col] = 0\n    assert (ys != sub[col].values).sum() == control_sum","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = sub.drop('cp_type', axis=1)\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}