{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\nimport os\n\nimport seaborn as sns\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport matplotlib\n%config InlineBackend.figure_format = 'svg'\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import TensorDataset, DataLoader\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom xgboost import XGBClassifier\n\n# matplotlib.style.use('seaborn') \n\nif torch.cuda.is_available():\n    device = 'cuda'\nelse:\n    device = 'cpu'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_features = pd.read_csv('/kaggle/input/lish-moa/train_features.csv')\ntrain_targets_scored = pd.read_csv('/kaggle/input/lish-moa/train_targets_scored.csv')\ntrain_targets_nonscored = pd.read_csv('/kaggle/input/lish-moa/train_targets_nonscored.csv')\ntest_features = pd.read_csv('/kaggle/input/lish-moa/test_features.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_targets_scored.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features.shape, train_targets_scored.shape, train_targets_scored.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features.isnull().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Проверим, все ли id уникальны и совпадают ли id для признаков и таргетов"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features.sig_id.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(train_features.sig_id != train_targets_scored.sig_id).sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features.set_index('sig_id', inplace=True)\ntest_features.set_index('sig_id', inplace=True)\ntrain_targets_scored.set_index('sig_id', inplace=True)\ntrain_targets_nonscored.set_index('sig_id', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Исследуем таргеты"},{"metadata":{},"cell_type":"markdown","source":"Проверим, может ли таргет принимать несколько целевых значений"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_targets_scored.sum(axis=1).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_targets_scored.sum(axis=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Посмотрим на кол-во объектов с положительным значением для каждого таргета."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots()\nfig.set_figwidth(10)\nfig.set_figheight(5)\n\nplt.scatter(np.arange(train_targets_scored.shape[1]), train_targets_scored.sum(axis=0)) \nplt.grid(True)\nplt.ylabel('Положительные исходы')\nplt.xlabel('Номер целевой переменной')\nplt.xticks(np.arange(train_targets_scored.shape[1])[::10])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Выделяются три группы таргетов - редкие (чсило объектов от 0 до 200), частые (чиcло объектов от 200 до 600), популярные (чиcло объектов > 600). Может, пригодится в дальнейшем."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_targets_scored.loc[:, train_targets_scored.sum(axis=0) > 600]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\nmoa_types = Counter([name.split('_')[-1] for name in train_targets_scored.columns])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"moa_types","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Исследуем признаки"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features.cp_type.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Проверим, что признаки с ctrl_vehicle не имеют MoAs."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_targets_scored.loc[train_features[train_features.cp_type == 'ctl_vehicle'].index].sum(axis=0).sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"В дальнейшем для обучения удалим признаки с cp_type == 'ctl_vehicle' и будем выдавать для них нулевые веротяности для всех MoAs."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features.cp_time.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features.cp_dose.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Подготовка данных"},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_statistics(df):\n\n    features_g = [col for col in df.columns if col.startswith('g-')]\n    features_c = [col for col in df.columns if col.startswith('c-')]\n    \n    df['g_sum'] = df[features_g].sum(axis=1)\n    df['g_mean'] = df[features_g].mean(axis=1)\n    df['g_std'] = df[features_g].std(axis=1)\n    df['g_kurt'] = df[features_g].kurtosis(axis=1)\n    df['g_skew'] = df[features_g].skew(axis=1)\n    df['c_sum'] = df[features_c].sum(axis=1)\n    df['c_mean'] = df[features_c].mean(axis=1)\n    df['c_std'] = df[features_c].std(axis=1)\n    df['c_kurt'] = df[features_c].kurtosis(axis=1)\n    df['c_skew'] = df[features_c].skew(axis=1)\n    df['gc_sum'] = df[features_g + features_c].sum(axis=1)\n    df['gc_mean'] = df[features_g + features_c].mean(axis=1)\n    df['gc_std'] = df[features_g + features_c].std(axis=1)\n    df['gc_kurt'] = df[features_g + features_c].kurtosis(axis=1)\n    df['gc_skew'] = df[features_g + features_c].skew(axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_index = train_features[train_features.cp_type == 'ctl_vehicle'].index\n\ntrain_features_df = train_features.drop(drop_index, axis=0)\ntrain_features_df = train_features_df.drop('cp_type', axis=1)\n\ntrain_target_df = train_targets_scored.drop(drop_index, axis=0)\n\n\ndrop_index = test_features[test_features.cp_type == 'ctl_vehicle'].index\ntest_features_df = test_features.drop(drop_index, axis=0)\ntest_features_df = test_features_df.drop('cp_type', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_df = pd.get_dummies(train_features_df, columns=['cp_time', 'cp_dose'], drop_first=True)\ntest_features_df = pd.get_dummies(test_features_df , columns=['cp_time', 'cp_dose'], drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# add_statistics(train_features_df)\nadd_statistics(test_features_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_all = train_features_df.values\ny_train_all = train_target_df.values\nX_test = test_features_df.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\nX_train_all = scaler.fit_transform(X_train_all)\nX_test = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X_train_all, y_train_all, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_all_dataset = TensorDataset(torch.tensor(X_train_all).float(), torch.tensor(y_train_all).float())\ntrain_all_loader = DataLoader(train_all_dataset, batch_size=512)\n\ntrain_dataset = TensorDataset(torch.tensor(X_train).float(), torch.tensor(y_train).float())\nval_dataset = TensorDataset(torch.tensor(X_val).float(), torch.tensor(y_val).float())\n\ntrain_loader = DataLoader(train_dataset, batch_size=512)\nval_loader = DataLoader(val_dataset, batch_size=512)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x, y = next(iter(train_loader))\nx.shape, y.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### FFNN model"},{"metadata":{"trusted":true},"cell_type":"code","source":"class FFNN(nn.Module):\n    def __init__(self, input_size, output_size, dropout_rate=0.1):\n        super().__init__()\n        \n        hidden_size = input_size // 2\n        \n        self.l1 =  nn.utils.weight_norm(nn.Linear(input_size, hidden_size))\n        self.bn1 = nn.BatchNorm1d(hidden_size)\n        self.dropout1 = nn.Dropout(dropout_rate)\n        \n        self.l2 =  nn.utils.weight_norm(nn.Linear(hidden_size, output_size))\n        self.bn2 = nn.BatchNorm1d(output_size)\n        self.dropout2 = nn.Dropout(dropout_rate)\n        \n        self.l3 =  nn.utils.weight_norm(nn.Linear(output_size, output_size))\n        \n    \n    def forward(self, x):\n        x = self.l1(x)\n        x = self.bn1(x)\n        x = self.dropout1(x)\n        x = F.elu(x)\n        \n        x = self.l2(x)\n        x = self.bn2(x)\n        x = self.dropout2(x)\n        x = F.elu(x)\n        \n        x = self.l3(x)\n        \n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = FFNN(input_size=890, output_size=206)\nmodel(x).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(model, optimizer, loss_function, train_loader, \n                val_loader=None, scheduler=None, epochs=1):\n\n    for epoch in range(epochs):\n        running_loss = 0.0\n        for n_iter, (x, y) in enumerate(train_loader):\n            model.train()\n            x = x.to(device)\n            y = y.to(device) \n            optimizer.zero_grad()\n            y_pred = model(x)\n            loss = loss_function(y_pred, y)\n            loss.backward()\n            optimizer.step()      \n            running_loss += loss.item()\n        running_loss /= len(train_loader)   \n        \n        if val_loader is not None:\n            model.eval()  \n            loss = 0.0\n            with torch.no_grad():\n                for (x, y) in val_loader:\n                    x = x.to(device)\n                    y = y.to(device) \n                    y_pred = model(x)\n                    loss += loss_function(y_pred, y).item()\n                loss /= len(val_loader)\n\n            print(\"Epoch: [{}/{}] \".format(epoch + 1, epochs),\n                  \"Train loss: {:.6f}\".format(running_loss),\n                  \"Val loss: {:.6f} \".format(loss))\n        else:\n            print(\"Epoch: [{}/{}] \".format(epoch + 1, epochs),\n                  \"Train loss: {:.6f}\".format(running_loss))\n        if scheduler is not None:\n            scheduler.step()     ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(model, X):\n    model.eval()  \n            \n    with torch.no_grad():\n        X = X.to(device)\n        preds = model(X)\n        y_pred = torch.sigmoid(preds)\n    return y_pred.cpu().numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss_function = nn.BCEWithLogitsLoss()\nmodel = FFNN(input_size=890, output_size=206).to(device)\noptimizer = optim.Adam(lr=0.001, params=model.parameters(), weight_decay=1e-5)\nscheduler = optim.lr_scheduler.StepLR(optimizer,10, gamma=0.8, last_epoch=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pca = PCA()\n# pca.fit_transform(X_train).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_model(model, optimizer, loss_function, train_loader, val_loader, epochs=150, scheduler=scheduler)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train on all objects"},{"metadata":{"trusted":true},"cell_type":"code","source":"loss_function = nn.BCEWithLogitsLoss()\nmodel = FFNN(input_size=875, output_size=206).to(device)\noptimizer = optim.Adam(lr=0.001, params=model.parameters(), weight_decay=1e-5)\nscheduler = optim.lr_scheduler.StepLR(optimizer,10, gamma=0.8, last_epoch=-1)\n\ntrain_model(model, optimizer, loss_function, train_all_loader, epochs=100, scheduler=scheduler)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = predict(model, torch.tensor(X_test).float())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###  Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame(np.zeros((test_features.shape[0], train_targets_scored.shape[1])),\n                         index=test_features.index, columns=train_targets_scored.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission = pd.read_csv('/kaggle/input/lish-moa/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_index = test_features[test_features.cp_type != 'ctl_vehicle'].index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(pred_index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.loc[pred_index, :] = y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.reset_index(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('/kaggle/working/submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}