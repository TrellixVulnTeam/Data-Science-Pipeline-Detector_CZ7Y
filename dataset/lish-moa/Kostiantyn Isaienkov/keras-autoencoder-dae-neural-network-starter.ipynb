{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.layers import Input, Dense\nimport tensorflow_addons as tfa\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import log_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(666)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Current best version - 29."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_features = pd.read_csv('/kaggle/input/lish-moa/train_features.csv')\ntrain_targets = pd.read_csv('/kaggle/input/lish-moa/train_targets_scored.csv')\ntest_features = pd.read_csv('/kaggle/input/lish-moa/test_features.csv')\nsubmission = pd.read_csv('/kaggle/input/lish-moa/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(df):\n    df.loc[:, 'cp_dose'] = df.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n    df.loc[:, 'cp_time'] = df.loc[:, 'cp_time'].map({24: 0, 48: 1, 72:2})\n    del df['sig_id']\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = preprocess(train_features)\ntest = preprocess(test_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train_targets['sig_id']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_targets['cp_type'] = train['cp_type']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train[train['cp_type'] != 'ctl_vehicle']\ntrain_targets = train_targets[train_targets['cp_type'] != 'ctl_vehicle']\n\ntrain = train.drop(['cp_type'], axis=1)\ntrain_targets = train_targets.drop(['cp_type'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.reset_index().drop(['index'], axis=1)\ntrain_targets = train_targets.reset_index().drop(['index'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_categories = train[['cp_dose', 'cp_time']]\ntest_categories = test[['cp_dose', 'cp_time']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_cp_type = test['cp_type']\ntest = test.drop(['cp_type'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_autoencoder():\n    input_vector = Input(shape=(874,))\n    encoded = Dense(2000, activation='elu')(input_vector)\n    encoded = Dense(1000, activation='elu')(encoded)\n    decoded = Dense(2000, activation='elu')(encoded)\n    decoded = Dense(874, activation='elu')(decoded)\n    \n    autoencoder = tf.keras.Model(\n        input_vector, \n        decoded\n    )\n    \n    autoencoder.compile(\n        optimizer='adadelta', \n        loss='mse'\n    )\n    \n    return autoencoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"autoencoder = create_autoencoder()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"autoencoder.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mu, sigma = 0, 0.05\n\nnoise = np.random.normal(\n    mu, \n    sigma, \n    [21948, 874]\n) \nnoised_train = train + noise","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"autoencoder.fit(\n    noised_train, \n    train, \n    epochs=1000,\n    batch_size=128,\n    shuffle=True,\n    validation_split=0.2\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder = tf.keras.Model(\n    autoencoder.input, \n    autoencoder.layers[2].output\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features = pd.DataFrame(encoder.predict(train))\ntest_features = pd.DataFrame(encoder.predict(test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model():\n    model = tf.keras.Sequential([\n        tf.keras.layers.Input(1000),\n        tf.keras.layers.BatchNormalization(),\n\n        tfa.layers.WeightNormalization(tf.keras.layers.Dense(500)),\n        tf.keras.layers.LeakyReLU(),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(0.3),\n        \n        tfa.layers.WeightNormalization(tf.keras.layers.Dense(500)),\n        tf.keras.layers.LeakyReLU(),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(0.3),\n        \n        tfa.layers.WeightNormalization(tf.keras.layers.Dense(350)),\n        tf.keras.layers.LeakyReLU(),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(0.3),\n        \n        tfa.layers.WeightNormalization(\n            tf.keras.layers.Dense(\n                206, \n                activation=\"sigmoid\"\n            )\n        )\n    ])\n    model.compile(\n        optimizer=tfa.optimizers.AdamW(\n            lr=1e-3, \n            weight_decay=1e-5, \n            clipvalue=700\n        ), \n        loss='binary_crossentropy'\n    )\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.loc[:, train_targets.columns] = 0\nres = train_targets.copy()\nfor n, (tr, te) in enumerate(KFold(n_splits=7, random_state=666, shuffle=True).split(train_targets)):\n    print(f'Fold {n}')\n    \n    model = create_model()\n    \n    model.fit(\n        train_features.values[tr],\n        train_targets.values[tr],\n        epochs=50, \n        batch_size=128\n    )\n    \n    submission.loc[:, train_targets.columns] += model.predict(test_features)\n    res.loc[te, train_targets.columns] = model.predict(train_features.values[te])\n    \nsubmission.loc[:, train_targets.columns] /= (n+1)\n\nmetrics = []\nfor _target in train_targets.columns:\n    metrics.append(log_loss(train_targets.loc[:, _target], res.loc[:, _target]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'OOF Metric: {np.mean(metrics)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['cp_type'] = test_cp_type\nfor col in submission.columns:\n    if col in ['sig_id', 'cp_type', 'cp_dose', 'cp_time']:\n        continue\n    submission.loc[submission['cp_type'] == 'ctl_vehicle', col] = 0\n\nsubmission = submission.drop(['cp_type'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}