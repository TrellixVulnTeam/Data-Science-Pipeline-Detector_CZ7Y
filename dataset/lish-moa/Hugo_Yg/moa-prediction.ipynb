{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 预测药物MoA\n一个样本可以有为一个或多个MoA标记，属于多标签分类任务(MultiLabel Classification)\n\nkaggle: https://www.kaggle.com/competitions/lish-moa/overview","metadata":{}},{"cell_type":"markdown","source":"## Import","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.append('../input/iterativestratification')\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold","metadata":{"execution":{"iopub.status.busy":"2022-05-20T15:41:39.455653Z","iopub.execute_input":"2022-05-20T15:41:39.45597Z","iopub.status.idle":"2022-05-20T15:41:39.461059Z","shell.execute_reply.started":"2022-05-20T15:41:39.455938Z","shell.execute_reply":"2022-05-20T15:41:39.460139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import log_loss\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"execution":{"iopub.status.busy":"2022-05-20T15:40:02.391026Z","iopub.execute_input":"2022-05-20T15:40:02.391412Z","iopub.status.idle":"2022-05-20T15:40:05.896118Z","shell.execute_reply.started":"2022-05-20T15:40:02.391372Z","shell.execute_reply":"2022-05-20T15:40:05.895161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data","metadata":{}},{"cell_type":"markdown","source":"EDA refences: https://www.kaggle.com/code/amiiiney/drugs-moa-classification-eda/notebook#1-Overview:-Features\n\nIn train_features: \n- Features **g-** signify gene expression data.\n\n- Features **c-** signify cell viability data.\n \n- **cp_type** indicates samples treated with a compound, **trt_cp** samples treated with the compounds.**ctl_vehicle**; control perturbations have no MoAs.\n\n- **cp_time** and **cp_dose** indicate treatment duration (24, 48, 72 hours) and dose (high or low).","metadata":{}},{"cell_type":"code","source":"train_features = pd.read_csv('../input/lish-moa/train_features.csv')\ntrain_targets_scored = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\ntrain_targets_noscored = pd.read_csv('../input/lish-moa/train_targets_nonscored.csv')\n\ntest_features = pd.read_csv('../input/lish-moa/test_features.csv')\n\ntrain_features.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-20T15:40:05.901177Z","iopub.execute_input":"2022-05-20T15:40:05.903697Z","iopub.status.idle":"2022-05-20T15:40:14.473513Z","shell.execute_reply.started":"2022-05-20T15:40:05.903652Z","shell.execute_reply":"2022-05-20T15:40:14.472549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_features.shape, train_targets_scored.shape, train_targets_noscored.shape, test_features.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-20T15:40:14.476363Z","iopub.execute_input":"2022-05-20T15:40:14.476928Z","iopub.status.idle":"2022-05-20T15:40:14.486361Z","shell.execute_reply.started":"2022-05-20T15:40:14.476884Z","shell.execute_reply":"2022-05-20T15:40:14.48527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"GENES = [col for col in train_features.columns if col.startswith('g-')]\nCELLS = [col for col in train_features.columns if col.startswith('c-')]\n\nlen(GENES), len(CELLS)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T15:40:14.490919Z","iopub.execute_input":"2022-05-20T15:40:14.491356Z","iopub.status.idle":"2022-05-20T15:40:14.503966Z","shell.execute_reply.started":"2022-05-20T15:40:14.491324Z","shell.execute_reply":"2022-05-20T15:40:14.502912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_features['cp_type'].unique()","metadata":{"execution":{"iopub.status.busy":"2022-05-20T15:40:14.505772Z","iopub.execute_input":"2022-05-20T15:40:14.506141Z","iopub.status.idle":"2022-05-20T15:40:14.521761Z","shell.execute_reply.started":"2022-05-20T15:40:14.5061Z","shell.execute_reply":"2022-05-20T15:40:14.52007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_count = train_targets_scored.sum()[1:].sort_values()\nsns.set_style('whitegrid')\nsns.histplot(target_count)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T15:40:14.523561Z","iopub.execute_input":"2022-05-20T15:40:14.523923Z","iopub.status.idle":"2022-05-20T15:40:15.140654Z","shell.execute_reply.started":"2022-05-20T15:40:14.523877Z","shell.execute_reply":"2022-05-20T15:40:15.139699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocess","metadata":{}},{"cell_type":"code","source":"def map(df):\n    df.loc[:, 'cp_type'] = df.loc[:, 'cp_type'].map({'trt_cp': 1, 'ctl_vehicle': 0})\n    df.loc[:, 'cp_dose'] = df.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n    return df\n\ntrain_features = map(train_features)\ntest_features = map(test_features)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T15:40:15.143472Z","iopub.execute_input":"2022-05-20T15:40:15.144094Z","iopub.status.idle":"2022-05-20T15:40:15.164486Z","shell.execute_reply.started":"2022-05-20T15:40:15.144019Z","shell.execute_reply":"2022-05-20T15:40:15.163414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### PCA features + Existing features","metadata":{}},{"cell_type":"code","source":"# GENE\nn_comp = 50\n\ndata = pd.concat([train_features[GENES], test_features[GENES]])\ndata2 = PCA(n_components=n_comp, random_state=42).fit_transform(data)\n\ntrain2 = data2[:len(train_features)]\ntest2 = data2[len(train_features):]\n\ntrain2 = pd.DataFrame(train2, columns=[f'g-{i}' for i in range(n_comp)])\ntest2 = pd.DataFrame(test2, columns=[f'g-{i}' for i in range(n_comp)])\n\ntrain_features = pd.concat([train_features, train2], axis=1)\ntest_features = pd.concat([test_features, test2], axis=1)\n\ntrain_features.shape, test_features.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-20T15:40:15.16846Z","iopub.execute_input":"2022-05-20T15:40:15.168708Z","iopub.status.idle":"2022-05-20T15:40:20.027927Z","shell.execute_reply.started":"2022-05-20T15:40:15.16866Z","shell.execute_reply":"2022-05-20T15:40:20.026707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CELL\nn_comp = 15\n\ndata = pd.concat([train_features[CELLS], test_features[CELLS]])\n# PCA 返回的是numpy array\ndata2 = PCA(n_components=n_comp, random_state=42).fit_transform(data)\n\ntrain2 = data2[:len(train_features)]\ntest2 = data2[len(train_features):]\n\ntrain2 = pd.DataFrame(train2, columns=[f'c-{i}' for i in range(n_comp)])\ntest2 = pd.DataFrame(test2, columns=[f'c-{i}' for i in range(n_comp)])\n\ntrain_features = pd.concat([train_features, train2], axis=1)\ntest_features = pd.concat([test_features, test2], axis=1)\n\ntrain_features.shape, test_features.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-20T15:40:20.029637Z","iopub.execute_input":"2022-05-20T15:40:20.030044Z","iopub.status.idle":"2022-05-20T15:40:20.740178Z","shell.execute_reply.started":"2022-05-20T15:40:20.029992Z","shell.execute_reply":"2022-05-20T15:40:20.739222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### feature selection by VarianceThreshold","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import VarianceThreshold\n\nvar_thresh = VarianceThreshold(threshold=0.5)\ndata = pd.concat([train_features, test_features])\n# transform 返回的是numpy array\ndata_transformed = var_thresh.fit_transform(data.iloc[:, 4:])\n\ntrain_transformed = data_transformed[:len(train_features)]\ntest_transformed = data_transformed[len(train_features):]\n\ntrain_features = pd.concat([train_features.iloc[:, :4], pd.DataFrame(train_transformed)], axis=1)\ntest_features = pd.concat([test_features.iloc[:, :4], pd.DataFrame(test_transformed)], axis=1)\n\ntrain_features.shape, test_features.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-20T15:40:20.741873Z","iopub.execute_input":"2022-05-20T15:40:20.742152Z","iopub.status.idle":"2022-05-20T15:40:21.576436Z","shell.execute_reply.started":"2022-05-20T15:40:20.742113Z","shell.execute_reply":"2022-05-20T15:40:21.575389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train_features.merge(train_targets_scored, on='sig_id')\n\ntrain = train[train_features['cp_type'] == 1].reset_index(drop=True)\ntest = test_features[test_features['cp_type'] == 1].reset_index(drop=True)\ntarget = train[train_targets_scored.columns]\n\ntrain.drop('cp_type', axis=1, inplace=True)\ntest.drop('cp_type', axis=1, inplace=True)\n\ntrain.shape, test.shape, target.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-20T15:40:21.577873Z","iopub.execute_input":"2022-05-20T15:40:21.578772Z","iopub.status.idle":"2022-05-20T15:40:22.066905Z","shell.execute_reply.started":"2022-05-20T15:40:21.578725Z","shell.execute_reply":"2022-05-20T15:40:22.065717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Distribution plots","metadata":{}},{"cell_type":"code","source":"# plt.figure(figsize=(16, 16))\n# gene_choice = np.random.choice(len(GENES), 16)\n\n# for i, col in enumerate(gene_choice):\n#     plt.subplot(4, 4, i + 1)\n#     plt.hist(train_features.loc[:, col], bins=100, color='orange')\n#     plt.title(GENES[col])","metadata":{"execution":{"iopub.status.busy":"2022-05-20T15:40:22.068384Z","iopub.execute_input":"2022-05-20T15:40:22.068806Z","iopub.status.idle":"2022-05-20T15:40:22.073849Z","shell.execute_reply.started":"2022-05-20T15:40:22.06876Z","shell.execute_reply":"2022-05-20T15:40:22.072631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Cross Validation","metadata":{}},{"cell_type":"markdown","source":"由于样本的类别数存在不平衡，普通`Kfold`随机分类可能会导致训练集标签全为某个单一类别，而`StratifiedKFold`会按比例进行划分。\n但是scikit-learn的StratifiedKFold不能用于多标签分类","metadata":{}},{"cell_type":"code","source":"folds = train.copy()\n\nmskf = MultilabelStratifiedKFold(n_splits=5)\n    \nfor f, (train_idx, valid_idx) in enumerate(mskf.split(X=train, y=target)):\n    folds.loc[valid_idx, 'kfold'] = int(f)\n\nfolds['kfold'] = folds['kfold'].astype(int)\nfolds","metadata":{"execution":{"iopub.status.busy":"2022-05-20T15:41:55.598859Z","iopub.execute_input":"2022-05-20T15:41:55.601443Z","iopub.status.idle":"2022-05-20T15:41:59.727122Z","shell.execute_reply.started":"2022-05-20T15:41:55.60141Z","shell.execute_reply":"2022-05-20T15:41:59.726267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_col = target.drop('sig_id', axis=1).columns.values.tolist()\nfeature_col = [col for col in train.columns if col not in target_col]\nfeature_col = [col for col in feature_col if col not in ['sig_id']]\n\nprint(train.shape, test.shape, target.shape, folds.shape)\nprint(len(feature_col), len(target_col))","metadata":{"execution":{"iopub.status.busy":"2022-05-20T15:41:59.732174Z","iopub.execute_input":"2022-05-20T15:41:59.73469Z","iopub.status.idle":"2022-05-20T15:41:59.773504Z","shell.execute_reply.started":"2022-05-20T15:41:59.734643Z","shell.execute_reply":"2022-05-20T15:41:59.772631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset","metadata":{}},{"cell_type":"code","source":"class MoADataset(Dataset):\n    def __init__(self, features, targets):\n        self.features = features\n        self.targets = targets\n    \n    def __getitem__(self, idx):\n        return {\n            'x': torch.tensor(self.features[idx, :], dtype=torch.float32),\n            'y': torch.tensor(self.targets[idx, :], dtype=torch.float32)\n        }\n\n    def __len__(self):\n        return len(self.features)\n\nclass TestDataset(Dataset):\n    def __init__(self, features):\n        self.features = features\n    \n    def __getitem__(self, idx):\n        return {\n            'x': torch.tensor(self.features[idx, :], dtype=torch.float32)\n        }\n\n    def __len__(self):\n        return len(self.features)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T15:41:59.778166Z","iopub.execute_input":"2022-05-20T15:41:59.780642Z","iopub.status.idle":"2022-05-20T15:41:59.793679Z","shell.execute_reply.started":"2022-05-20T15:41:59.780598Z","shell.execute_reply":"2022-05-20T15:41:59.792466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training functions","metadata":{}},{"cell_type":"code","source":"def train_fn(model, optimizer, scheduler, criterion, dataloader, device):\n    model.train()\n    final_loss = 0\n\n    for data in dataloader:\n        optimizer.zero_grad()\n        input, target = data['x'].to(device), data['y'].to(device)\n        output = model(input)\n        loss = criterion(output, target)\n        loss.backward()\n        optimizer.step()\n        scheduler.step(loss)\n\n        final_loss += loss.item()\n\n    return final_loss / len(dataloader)\n\ndef valid_fn(model, dataloader, criterion, device):\n    model.eval()\n    final_loss = 0\n    valid_preds = []\n\n    for data in dataloader:\n        input, target = data['x'].to(device), data['y'].to(device)\n        output = model(input)\n        loss = criterion(output, target)\n\n        final_loss += loss.item()\n        valid_preds.append(output.sigmoid().detach().cpu().numpy())\n\n    final_loss = final_loss / len(dataloader)\n    valid_preds = np.concatenate(valid_preds)   # list -> numpy array(matrix)\n    return final_loss , valid_preds\n\ndef inference_fn(model, dataloader, device):\n    model.eval()\n    final_preds = []\n\n    with torch.no_grad():\n        for data in dataloader:\n            input = data['x'].to(device)\n            output = model(input)\n            final_preds.append(output.sigmoid().detach().cpu().numpy())\n\n    final_preds = np.concatenate(final_preds)\n    return final_preds","metadata":{"execution":{"iopub.status.busy":"2022-05-20T15:41:59.800125Z","iopub.execute_input":"2022-05-20T15:41:59.80327Z","iopub.status.idle":"2022-05-20T15:41:59.823206Z","shell.execute_reply.started":"2022-05-20T15:41:59.803195Z","shell.execute_reply":"2022-05-20T15:41:59.822283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self, num_features, hidden_size, num_targets):\n        super().__init__()\n        self.model = nn.Sequential(\n            nn.BatchNorm1d(num_features),\n            nn.Dropout(0.2),\n            nn.Linear(num_features, hidden_size),\n            nn.LeakyReLU(),\n\n            # nn.BatchNorm1d(hidden_size),\n            nn.Dropout(0.3),\n            nn.Linear(hidden_size, hidden_size),\n            nn.LeakyReLU(),\n            \n            # nn.BatchNorm1d(hidden_size),\n            nn.Dropout(0.3),\n            nn.Linear(hidden_size, hidden_size),\n            nn.LeakyReLU(),\n\n            # nn.BatchNorm1d(hidden_size),\n            nn.Dropout(0.3),\n            nn.Linear(hidden_size, hidden_size),\n            nn.LeakyReLU(),\n\n            # nn.BatchNorm1d(hidden_size),\n            nn.Dropout(0.3),\n            nn.Linear(hidden_size, hidden_size),\n            nn.LeakyReLU(),\n\n            nn.BatchNorm1d(hidden_size),\n            nn.Dropout(0.3),\n            nn.Linear(hidden_size, num_targets),\n        )\n\n    def forward(self, x):\n        return self.model(x)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T15:41:59.828679Z","iopub.execute_input":"2022-05-20T15:41:59.831645Z","iopub.status.idle":"2022-05-20T15:41:59.845835Z","shell.execute_reply.started":"2022-05-20T15:41:59.831601Z","shell.execute_reply":"2022-05-20T15:41:59.844881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Single Fold Training","metadata":{}},{"cell_type":"code","source":"# Hyperparameters\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nepochs = 30\nbatch_size = 1024\nlearning_rate = 1e-3\nweight_decay = 1e-5\nnfolds = 5\nearly_stop_step = 10\nearly_stop = False\n\nnum_features = len(feature_col)\nhidden_size = 2048\nnum_targets = len(target_col)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T15:41:59.848585Z","iopub.execute_input":"2022-05-20T15:41:59.85075Z","iopub.status.idle":"2022-05-20T15:41:59.950837Z","shell.execute_reply.started":"2022-05-20T15:41:59.850706Z","shell.execute_reply":"2022-05-20T15:41:59.949414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_training(fold):\n    train_idx = train[folds['kfold'] != fold].index\n    valid_idx = train[folds['kfold'] == fold].index\n\n\n    train_df = train[folds['kfold'] != fold].reset_index(drop=True)\n    valid_df = train[folds['kfold'] == fold].reset_index(drop=True)\n\n    x_train, y_train = train_df[feature_col].values, train_df[target_col].values\n    x_valid, y_valid = valid_df[feature_col].values, valid_df[target_col].values\n\n    train_dataset = MoADataset(x_train, y_train)\n    valid_dataset = MoADataset(x_valid, y_valid)\n    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n\n    model = Model(num_features, hidden_size, num_targets).to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True)\n    criterion = nn.BCEWithLogitsLoss()\n\n    best_loss = np.inf\n    oof = np.zeros((len(train), target.iloc[:, 1:].shape[1]))\n\n    for epoch in range(epochs):\n        train_loss = train_fn(model, optimizer, scheduler, criterion, train_dataloader, device)\n        valid_loss, valid_preds = valid_fn(model, valid_dataloader, criterion, device)\n\n        if valid_loss < best_loss:\n            best_loss = valid_loss\n            early_stop = 0\n            torch.save(model.state_dict(), f'FOLD{fold}_.pth')\n        else:\n            early_stop += 1\n\n        if early_stop >= early_stop_step:\n            print(f'Early stop at epoch {epoch + 1}')\n            break\n\n        print(f'Fold {fold} | Epoch {epoch + 1} | train loss: {train_loss:.4f} | valid loss: {valid_loss:.4f}')\n\n    # <-------------- inference ---------------->/\n    x_test = test[feature_col].values\n    test_dataset = TestDataset(x_test)\n    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n    model = Model(num_features, hidden_size, num_targets)\n    model.load_state_dict(torch.load(f'FOLD{fold}_.pth'))\n    model.to(device)\n\n    predictions = inference_fn(model, test_dataloader, device)\n\n    return oof, predictions","metadata":{"execution":{"iopub.status.busy":"2022-05-20T15:41:59.957843Z","iopub.execute_input":"2022-05-20T15:41:59.958652Z","iopub.status.idle":"2022-05-20T15:41:59.974193Z","shell.execute_reply.started":"2022-05-20T15:41:59.958605Z","shell.execute_reply":"2022-05-20T15:41:59.973246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_k_fold(nfolds):\n    oof = np.zeros((len(train), len(target_col)))\n    predictions = np.zeros((len(test), len(target_col)))\n\n    for fold in range(nfolds):\n        oof_, pred_ = run_training(fold)\n        oof += oof_\n        predictions += pred_ / nfolds\n\n    return oof, predictions","metadata":{"execution":{"iopub.status.busy":"2022-05-20T15:41:59.975925Z","iopub.execute_input":"2022-05-20T15:41:59.9765Z","iopub.status.idle":"2022-05-20T15:41:59.99001Z","shell.execute_reply.started":"2022-05-20T15:41:59.976452Z","shell.execute_reply":"2022-05-20T15:41:59.988821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof, predictions = run_k_fold(nfolds)\n# 将输出存入原dataframe的target列\ntrain[target_col] = oof\ntest[target_col] = predictions","metadata":{"execution":{"iopub.status.busy":"2022-05-20T15:41:59.991824Z","iopub.execute_input":"2022-05-20T15:41:59.992329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submit","metadata":{}},{"cell_type":"code","source":"train_targets_scored.shape, len(target_col)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_results = train_targets_scored.drop(columns=target_col).merge(train[['sig_id']+target_col], on='sig_id', how='left').fillna(0)\n\ny_true = train_targets_scored[target_col].values\ny_pred = valid_results[target_col].values\n\nscore = 0\nfor i in range(len(target_col)):\n    score_ = log_loss(y_true[:, i], y_pred[:, i])\n    score += score_ / target.shape[1]\n    \nprint(\"CV log_loss: \", score)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission = pd.read_csv('../input/lish-moa/sample_submission.csv')\nsub = sample_submission.drop(columns=target_col).merge(test[['sig_id']+target_col], on='sig_id', how='left').fillna(0)\nsub.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}