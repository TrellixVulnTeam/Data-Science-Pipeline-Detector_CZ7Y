{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom scipy.stats import ttest_ind\n\nimport os \nimport pandas as pds\nimport numpy as np\n\nfrom matplotlib import pyplot as plt\nimport seaborn as sbn\n\nimport tensorflow as tf\nimport gc\n\nimport sys \n\ndef printProgress (iteration, total, prefix = '', suffix = '', decimals = 1, barLength = 100): \n    formatStr = \"{0:.\" + str(decimals) + \"f}\" \n    percent = formatStr.format(100 * (iteration / float(total))) \n    filledLength = int(round(barLength * iteration / float(total))) \n    bar = '#' * filledLength + '-' * (barLength - filledLength) \n    sys.stdout.write('\\r%s |%s| %s%s %s' % (prefix, bar, percent, '%', suffix)), \n    if iteration == total: \n        sys.stdout.write('\\n') \n    sys.stdout.flush() \n    \ntf.config.experimental.set_memory_growth(tf.config.experimental.list_physical_devices('GPU')[0],True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set=pds.read_csv(os.path.join('/kaggle/input/lish-moa','train_features.csv'))\ntest_set=pds.read_csv(os.path.join('/kaggle/input/lish-moa','test_features.csv'))\ntarget_nons=pds.read_csv(os.path.join('/kaggle/input/lish-moa','train_targets_nonscored.csv')).iloc[:,1:]\ntarget_s=pds.read_csv(os.path.join('/kaggle/input/lish-moa','train_targets_scored.csv')).iloc[:,1:]\nsubs=pds.read_csv(os.path.join('/kaggle/input/lish-moa','sample_submission.csv'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cp_time=train_set.cp_time\ncp_dose=train_set.cp_dose","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set_squares=(train_set.iloc[:,4:]**2).rename({i:i+'^2' for i in train_set.columns},axis=1)\ntest_set_squares=(test_set.iloc[:,4:]**2).rename({i:i+'^2' for i in test_set.columns},axis=1)\n\ntrain_set=pds.concat([train_set,train_set_squares],1)\ntest_set=pds.concat([test_set,test_set_squares],1)\n\ntrs=train_set.iloc[:,4:]\ntts=test_set.iloc[:,4:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def gen_model(input_shape,output_shape):\n    inputs=tf.keras.Input((input_shape))\n    \n    dense=tf.keras.layers.Dense(500)(inputs)\n    batch=tf.keras.layers.BatchNormalization()(dense)\n    drop=tf.keras.layers.Dropout(0.5)(batch)\n    activ=tf.keras.activations.relu(drop,0.3)\n    \n    dense=tf.keras.layers.Dense(500)(activ)\n    batch=tf.keras.layers.BatchNormalization()(dense)\n    drop=tf.keras.layers.Dropout(0.5)(batch)\n    activ=tf.keras.activations.relu(drop,0.3)\n    \n    dense=tf.keras.layers.Dense(500)(activ)\n    batch=tf.keras.layers.BatchNormalization()(dense)\n    drop=tf.keras.layers.Dropout(0.5)(batch)\n    activ=tf.keras.activations.relu(drop,0.3)\n    \n    dense=tf.keras.layers.Dense(500)(activ)\n    batch=tf.keras.layers.BatchNormalization()(dense)\n    drop=tf.keras.layers.Dropout(0.5)(batch)\n    activ=tf.keras.activations.relu(drop,0.3)\n    \n    dense=tf.keras.layers.Dense(500)(activ)\n    batch=tf.keras.layers.BatchNormalization()(dense)\n    drop=tf.keras.layers.Dropout(0.5)(batch)\n    activ=tf.keras.activations.relu(drop,0.3)\n    \n    output=tf.keras.layers.Dense(output_shape,activation='sigmoid')(activ)\n    \n    model=tf.keras.models.Model(inputs,output)\n    model.compile(loss=loss_fn,metrics='AUC')\n    return model\n\ndef loss_fn(y_true,y_pred):\n    return tf.reduce_mean(tf.keras.losses.binary_crossentropy(tf.transpose(y_true,[1,0]),\n                                                              tf.transpose(y_pred,[1,0])),)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"smooth_target_s=target_s.applymap(lambda x : 0.05 if x == 0 else 0.95)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kf=KFold(5,shuffle=True)\n\nif not os.path.exists('model'):\n    os.mkdir('model')\n\nclass_dict=dict()\n    \nfor cpt,cpd in [[x,y] for x in cp_time.unique() for y in cp_dose.unique()]:\n    \n    \n    idx=(cpt==cp_time) & (cpd==cp_dose)\n    for n,(tr_idx,vl_idx) in enumerate(kf.split(train_set.loc[idx],smooth_target_s.loc[idx])):\n        print(f'Start time : {cpt} / dose : {cpd} / fold : {n}')\n        x_train,x_val=trs.loc[idx].values[tr_idx],trs.loc[idx].values[vl_idx]\n        y_train,y_val=smooth_target_s.loc[idx].values[tr_idx],smooth_target_s.loc[idx].values[vl_idx]\n        \n        ys=y_train.sum(0)\n        ys[ys==0]=y_train.shape[0]\n        class_weights={n:i for n,i in enumerate((y_train.shape[0]-ys)/ys)}\n        class_dict[f'{cpt}-{cpd}-{n}']=class_weights\n        \n        mod=gen_model(trs.shape[1],smooth_target_s.shape[1])\n        hitory=mod.fit(x_train,y_train,\n                batch_size=100,epochs=10000,verbose=0,\n                class_weight=class_weights,\n                callbacks=[tf.keras.callbacks.EarlyStopping(patience=50,\n                                                            restore_best_weights=True),\n                           tf.keras.callbacks.ModelCheckpoint(os.path.join('model',f'{cpt}-{cpd}-{n}.h5')),\n                           tf.keras.callbacks.ReduceLROnPlateau()\n                          ],\n                validation_data=(x_val,y_val))\n        print(f'End time : {cpt} / dose : {cpd} / fold : {n}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for cpt,cpd in [[x,y] for x in cp_time.unique() for y in cp_dose.unique()]:\n    for n in range(5):\n        name=f'{cpt}-{cpd}-{n}'\n        \n        if n == 0 :\n            cw = np.expand_dims(np.array([i for i in class_dict[name].values()]),-1)\n        else:\n            cw = np.concatenate([cw,\n                                 np.expand_dims(np.array([i for i in class_dict[name].values()]),-1)\n                                ],1)\n        cw[cw.sum(1)!=0]=(cw[cw.sum(1)!=0]/cw.sum(1,keepdims=True)[cw.sum(1)!=0])\n    \n    for n in range(5):\n        mod=gen_model(tts.shape[1],target_s.shape[1])\n        mod.load_weights(os.path.join('model',name+'.h5'))\n        pred=np.expand_dims(\n            mod.predict(tts.loc[(cpt==test_set.cp_time) & (cpd==test_set.cp_dose)]),-1)\n        if n == 0:\n            preds=pred\n        else:\n            preds=np.concatenate([preds,pred],-1)\n            \n    subs.loc[(cpt==test_set.cp_time) & (cpd==test_set.cp_dose),\n             subs.columns[1:]]=(preds*cw).sum(-1)\n    \n    del mod\n    gc.collect()\n    tf.keras.backend.clear_session()\n\nsubs.loc[test_set.cp_type=='ctl_vehicle',subs.columns[1:]]=0\nsubs.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}