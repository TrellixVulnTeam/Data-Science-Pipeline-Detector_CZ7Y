{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this short kernel, I am going to show you how to choose the `number of principal components` when using principal component analysis for dimensionality reduction as in MoA Competition "},{"metadata":{},"cell_type":"markdown","source":"Full Post for detailed Explanation :- https://www.mikulskibartosz.name/pca-how-to-choose-the-number-of-components/"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# If you like it, Do Upvote :)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\n\nfrom sklearn import preprocessing\nfrom sklearn.decomposition import PCA","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('../input/lish-moa')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features = pd.read_csv('../input/lish-moa/train_features.csv')\ntrain_targets_scored = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\ntrain_targets_nonscored = pd.read_csv('../input/lish-moa/train_targets_nonscored.csv')\ntest_features = pd.read_csv('../input/lish-moa/test_features.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GENES = [col for col in train_features.columns if col.startswith('g-')]\nCELLS = [col for col in train_features.columns if col.startswith('c-')]\nlen(GENES+CELLS)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Choosing PCA on Genes columns "},{"metadata":{},"cell_type":"markdown","source":"Don’t do it. Don’t choose the number of components manually.Instead of that, use the option that allows you to set the variance of the input that is supposed to be explained by the generated components."},{"metadata":{},"cell_type":"markdown","source":"### Remember to scale the data to the range between 0 and 1 before using PCA!\nTypically, we want the explained variance to be between 95–99%. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import QuantileTransformer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in (GENES + CELLS):\n    transformer = QuantileTransformer(random_state=0, output_distribution=\"normal\")\n    vec_len = len(train_features[col].values)\n    vec_len_test = len(test_features[col].values)\n    raw_vec = train_features[col].values.reshape(vec_len, 1)\n    transformer.fit(raw_vec)\n\n    train_features[col] = transformer.transform(raw_vec).reshape(1, vec_len)[0]\n    test_features[col] = transformer.transform(test_features[col].values.reshape(vec_len_test, 1)).reshape(1, vec_len_test)[0]\n    \ndata = pd.concat([pd.DataFrame(train_features[GENES]), pd.DataFrame(test_features[GENES])])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Now we have standardized our Data"},{"metadata":{},"cell_type":"markdown","source":"From the Scikit-learn implementation, we can get the information about the explained variance and plot the cumulative variance."},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA().fit(data)\n\nimport matplotlib.pyplot as plt\nplt.rcParams[\"figure.figsize\"] = (12,6)\n\nfig, ax = plt.subplots()\nxi = np.arange(1, 773, step=1)\ny = np.cumsum(pca.explained_variance_ratio_)\n\nplt.ylim(0.0,1.1)\nplt.plot(xi, y, marker='o', linestyle='--', color='b')\n\nplt.xlabel('Number of Components')\nplt.xticks(np.arange(0, 750, step=50)) #change from 0-based array index to 1-based human-readable label\nplt.ylabel('Cumulative variance (%)')\nplt.title('The number of components needed to explain variance')\n\nplt.axhline(y=0.95, color='r', linestyle='-')\nplt.text(0.5, 0.85, '95% cut-off threshold', color = 'red', fontsize=16)\n\nax.grid(axis='x')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On the plotted chart, we see what number of principal components we need."},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## In this case, to get 95% of variance explained I need 600 principal components."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}