{"cells":[{"metadata":{},"cell_type":"markdown","source":"# MoA Prediction using deep neural network"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport random","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def set_random_seed():\n    random.seed(2021)\n    tf.random.set_seed(2020)\n    np.random.seed(2019)\nset_random_seed()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CONFIG\nmodel_version = 'v0'\nBATCH_SIZE = 128\nEPOCHS = 15\nSPLITS = 10","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"TRAIN_FEATURES = pd.read_csv('../input/lish-moa/train_features.csv')\nTRAIN_FEATURES.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TEST_FEATURES = pd.read_csv('../input/lish-moa/test_features.csv')\nTEST_FEATURES.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Features description\n* g- signify gene expression data, and c- signify cell viability data\n* cp_type indicates samples treated with a compound (cp_vehicle) or with a control perturbation (ctrl_vehicle)\n* cp_time and cp_dose indicate treatment duration (24, 48, 72 hours) and dose (high or low)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# cp_type indicates samples treated with a compound (cp_vehicle) or with a control perturbation (ctrl_vehicle)\ntrain_cp_type = np.unique(TRAIN_FEATURES['cp_type'])\nprint(\"Train cp types:\", train_cp_type)\n\n# cp_time and cp_dose indicate treatment duration (24, 48, 72 hours) and dose (high or low)\ntrain_cp_dose = np.unique(TRAIN_FEATURES['cp_dose'])\nprint(\"Train cp_dose:\", train_cp_dose)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for column correlation\n# TRAIN_FEATURES.corr(method='pearson')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data preprocessing\n* One hot encode categorical data\n* Standardize continuous features"},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN_FEATURES = pd.get_dummies(TRAIN_FEATURES, columns=['cp_type', 'cp_dose'])\nTRAIN_FEATURES.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TEST_FEATURES = pd.get_dummies(TEST_FEATURES, columns=['cp_type', 'cp_dose'])\nTEST_FEATURES.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MEAN_STD = {}\ntraining_features = TRAIN_FEATURES.columns.tolist()\ntraining_features.remove('sig_id')\nfor column in training_features:\n    # Skip categorical column\n    if len(np.unique(TRAIN_FEATURES[column])) == 2 or column == 'sig_id':\n        print(\"Skip categorical column: \", column)\n        continue\n    # Standardize continous column\n    (mu, sigma) = TRAIN_FEATURES[column].mean(), TRAIN_FEATURES[column].std()\n    TRAIN_FEATURES[column] = (TRAIN_FEATURES[column] - mu) / sigma\n    TEST_FEATURES[column] = (TEST_FEATURES[column] - mu) / sigma\n    MEAN_STD[column] = (mu, sigma)\nprint(TRAIN_FEATURES.describe())\nprint(TEST_FEATURES.describe())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN_TARGETS = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\nTRAIN_TARGETS.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"targets = TRAIN_TARGETS.columns.tolist()\ntargets.remove('sig_id')\nprint(\"Num of classes: \", len(targets))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Deep Neural Network Modelling (Simple modelling for now)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers import Input, Dense, BatchNormalization, Activation\nfrom tensorflow.keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\n\ndef dense_layer(x, num_of_nodes=1024, activation='tanh'):\n    d = Dense(num_of_nodes)(x)\n    b = BatchNormalization()(d)\n    a = Activation(activation)(b)\n    return a\n\ndef build_model():\n    inp = Input(shape=(len(training_features),))\n    d = dense_layer(inp, 1024, 'tanh')\n    d = dense_layer(d, 1024, 'tanh')\n    out = Dense(len(targets), activation='sigmoid')(d)\n    \n    model = Model(inputs = inp, outputs = out)\n    model.compile(optimizer=Adam(), loss=BinaryCrossentropy())\n    \n    return model \n\nmodel = build_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training 5-Fold CV"},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN_DF = pd.merge(TRAIN_FEATURES, TRAIN_TARGETS, on=['sig_id'])\n# TRAIN_DF.d\nTRAIN_DF.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X, y = TRAIN_DF[training_features].values, TRAIN_DF[targets].values\nX = np.asarray(X, dtype='float32')\ny = np.asarray(y, dtype='float32')\nprint(\"Shape of X training: \", X.shape)\nprint(\"Shape of y training: \", y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.callbacks import *\ndef get_callback(fold):\n    return [\n#         ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=20, min_lr=1e-5),\n        ModelCheckpoint(f'model_{model_version}_{fold}.h5', monitor='val_loss', save_best_only=True, save_weights_only=True, verbose=1)\n    ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nimport tensorflow.keras.backend as K\nimport gc\nkfold = KFold(n_splits=SPLITS)\nfold = 0\nhistory = []\nfor train_idx, test_idx in kfold.split(X, y):\n    K.clear_session()\n    gc.collect()\n    print(\"FOLD \", fold)\n    X_train, y_train = X[train_idx], y[train_idx]\n    X_test, y_test = X[test_idx], y[test_idx]\n    \n    callbacks = get_callback(fold)\n    \n    model = build_model()\n    hist = model.fit(X_train, y_train, \n                     batch_size = BATCH_SIZE,\n                     epochs = EPOCHS,\n                     validation_data=(X_test, y_test), \n                     callbacks = callbacks)\n    \n    \n    history.append(hist)\n    fold += 1\n    K.clear_session()\n    gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_val_loss = [np.min(hist.history['val_loss']) for hist in history]\nprint(\"Best val loss for each fold: \", best_val_loss)\nprint(\"OOF val loss: \", np.mean(best_val_loss))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot learning curve for each fold\nfor fold in range(SPLITS):\n    fig, ax = plt.subplots()\n    ax.plot(history[fold].history['loss'])\n    ax.plot(history[fold].history['val_loss'])\n    ax.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Inference on test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"models = []\npredictions = []\nfor i in range(SPLITS):\n    model = build_model()\n    model.load_weights(f'model_{model_version}_{i}.h5')\n    models.append(model)\n    \nX_test = np.asarray(TEST_FEATURES[training_features].values, dtype='float32')\nfor model in models:\n    predictions.append(model.predict(X_test, verbose=1))\n    \nfinal_prediction = predictions[0]\nfor i in range(1, SPLITS):\n    final_prediction += predictions[i]\nfinal_prediction /= len(models)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(final_prediction.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_data = {}\nsubmission_data['sig_id'] = TEST_FEATURES.sig_id.values\nfor i, target in enumerate(targets):\n    submission_data[target] = final_prediction[:, i]\nsubmission_csv = pd.DataFrame(data=submission_data)\nsubmission_csv.to_csv('submission.csv', index=False)\nsubmission_csv.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Done!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}