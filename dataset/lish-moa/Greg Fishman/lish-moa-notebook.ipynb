{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"},"outputs":[],"source":"# %% [code]\nimport sys\nimport logging\n\nfrom tqdm.auto import tqdm as tqdm\n\nsys.path.append('../input/omegaconf')\nfrom omegaconf.omegaconf import DictConfig, OmegaConf\n\nlog = logging.getLogger(__name__)\n\n\nimport warnings\n\nwarnings.filterwarnings('ignore')\n\n##########################\nimport os\nimport sys\nimport torch\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.metrics import log_loss\n\nsys.path.append('../input/iterativestratification')\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\nsys.path.append('../input/src-code0')\nsys.path.append('../input/models0')\n\nfrom src.torch_model_loop import run_k_fold\nfrom src.data.process_data import set_seed, preprocess_data, from_yml,\\\n    quantile_transformer, get_pca_transform, split_with_variancethreshold\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nos.listdir('../input/lish-moa')\n\npd.set_option('max_columns', 2000)\n\n# @hydra.main(config_path=\"config\", config_name=\"config.yaml\", strict=False)\ndef run():\n    cfg = OmegaConf.load('../input/src-code0/src/test.yaml')\n    # os.chdir(utils.get_original_cwd())\n#     log.info(OmegaConf.to_yaml(cfg))\n    cfg['device'] = ('cuda' if torch.cuda.is_available() else 'cpu')\n    cfg['list_seed'] = [i for i in range(cfg.model.nseed)]\n    verbose = 0\n    local_path = '../'\n    path = f'{local_path}input/lish-moa'\n    path_model = f'../input/models0'\n    cfg['path_model'] = path_model\n    # print(os.listdir(f'{local_path}../'))\n    print(cfg['device'])\n    # data_load\n    train_features = pd.read_csv(f'{path}/train_features.csv')\n    test_features = pd.read_csv(f'{path}/test_features.csv')\n    train_targets_scored = pd.read_csv(f'{path}/train_targets_scored.csv')\n    train_targets_nonscored = pd.read_csv(f'{path}/train_targets_nonscored.csv')\n    sample_submission = pd.read_csv(f'{path}/sample_submission.csv')\n#     sub = pd.read_csv(f'{path}/sample_submission.csv')\n\n    log.info(f\"n_comp_genes: {cfg.model.n_comp_genes}, n_comp_cells: {cfg.model.n_comp_cells}, total: \"\n          f\"{cfg.model.n_comp_genes + cfg.model.n_comp_cells}.\")\n\n    GENES = [col for col in train_features.columns if col.startswith('g-')]\n    CELLS = [col for col in train_features.columns if col.startswith('c-')]\n\n    train_features_norm, test_features_norm = \\\n        quantile_transformer(train_features, test_features, features=GENES+CELLS,\n                             n_quantiles=cfg.quantile_transformer.n_quantiles,\n                             output_distribution=cfg.quantile_transformer.output_distribution)\n    train_features = train_features_norm\n    test_features = test_features_norm\n    log.info(f\"End prearation data transform.\\n\"\n             f\"train_features.shape: {train_features.shape}\\n\"\n             f\"test_features.shape: {test_features.shape}\\n\"\n             f\"{'_' * 80}\\n\")\n\n    ##################################################\n    # PCA\n    ##################################################\n\n    train2, test2 = get_pca_transform(train_features, test_features, features=GENES,\n                                      n_components=cfg.model.n_comp_genes, flag='GENES')\n    train_features = pd.concat((train_features, train2), axis=1)\n    test_features = pd.concat((test_features, test2), axis=1)\n\n    train2, test2 = get_pca_transform(train_features, test_features, features=CELLS,\n                                      n_components=cfg.model.n_comp_cells, flag='CELLS')\n    train_features = pd.concat((train_features, train2), axis=1)\n    test_features = pd.concat((test_features, test2), axis=1)\n\n    ##################################################\n    # Start: Feature selection\n    ##################################################\n    train_features_return, test_features_return = \\\n        split_with_variancethreshold(train_features, test_features,\n                                     variance_threshold_for_fs=cfg.model.variance_threshold_for_fs,\n                                     categorical=['sig_id', 'cp_type', 'cp_time', 'cp_dose'],\n                                     test_append=False)\n    train_features = train_features_return\n    test_features = test_features_return\n\n    ##################################################\n    # Start: Zero hack target & prepare train test\n    ##################################################\n    if verbose:\n        print(f\"Preparation of train & test:\")\n\n    train = train_features.merge(train_targets_scored, on='sig_id')\n    train = train[train['cp_type'] != 'ctl_vehicle'].reset_index(drop=True)\n    test = test_features[test_features['cp_type'] != 'ctl_vehicle'].reset_index(drop=True)\n\n    target = train[train_targets_scored.columns]\n    train = train.drop('cp_type', axis=1)\n    test = test.drop('cp_type', axis=1)\n\n    target_cols = target.drop('sig_id', axis=1).columns.values.tolist()\n\n    log.debug(f\"Preparation of train & test.\\n\"\n              f\"train.shape: {train.shape}\\n\"\n              f\"test.shape: {test.shape}\\n\"\n              f\"{'_' * 80}\\n\"\n              )\n\n    ##################################################\n    # CV folds\n    ##################################################\n    folds = train.copy()\n    mskf = MultilabelStratifiedKFold(n_splits=cfg.model.nfolds, random_state=cfg['list_seed'][0])\n\n    for f, (t_idx, v_idx) in enumerate(mskf.split(X=train, y=target)):\n        folds.loc[v_idx, 'kfold'] = int(f)\n\n    folds['kfold'] = folds['kfold'].astype(int)\n\n    log.debug(f\"train.shape: {train.shape}\"\n              f\"folds.shape: {folds.shape}\"\n              f\"test.shape: {test.shape}\"\n              f\"target.shape: {target.shape}\"\n              f\"sample_submission.shape: {sample_submission.shape}\"\n              )\n\n    ##################################################\n    # Preprocessing feature_cols\n    ##################################################\n    feature_cols = [c for c in preprocess_data(folds, cfg.model.patch1).columns if c not in target_cols]\n    feature_cols = [c for c in feature_cols if c not in ['kfold', 'sig_id']]\n\n    if verbose:\n        print(f\"Preprocessing\")\n    if verbose:\n        print(f\"len(feature_cols): {len(feature_cols)}\")\n\n    num_features = len(feature_cols)\n    num_targets = len(target_cols)\n\n    # Averaging on multiple SEEDS\n\n    #     print(f\"target.columns: {target.columns}\")\n\n    ##################################################\n    # Train\n    ##################################################\n    SEED = cfg['list_seed']\n    oof = np.zeros((len(train), len(target_cols)))\n    predictions = np.zeros((len(test), len(target_cols)))\n\n    for seed in tqdm(SEED, leave=verbose):\n        return_run_k_fold = run_k_fold(cfg.model.nfolds, seed, cfg, folds, train, test, feature_cols, target_cols,\n                                       num_features, num_targets, target, verbose)\n        if cfg.model.train_models:\n            oof_, predictions_ = return_run_k_fold\n            oof += oof_ / len(SEED)\n        else:\n            predictions_ = return_run_k_fold\n        predictions += predictions_ / len(SEED)\n\n    if cfg.model.train_models:\n        train[target_cols] = oof\n    test[target_cols] = predictions\n\n    ##################################################\n    # valodation and save\n    ##################################################\n\n    if cfg.model.train_models:\n        valid_results = train_targets_scored.drop(columns=target_cols).merge(train[['sig_id'] + target_cols],\n                                                                         on='sig_id', how='left').fillna(0)\n\n    y_true = train_targets_scored[target_cols].values\n\n    if cfg.model.train_models:\n        y_pred = valid_results[target_cols].values\n\n        score = 0\n        for i in range(len(target_cols)):\n            score_ = log_loss(y_true[:, i], y_pred[:, i])\n            score += score_ / num_targets\n\n        print(\"CV log_loss: \", score)\n\n    \n    test[['sig_id'] + target_cols].to_csv('submission.csv', index=False)\n#     sub = sub.drop(columns=target_cols).merge(test[['sig_id'] + target_cols], on='sig_id',\n#                                                             how='left').fillna(0)\n#     sub.to_csv('submission.csv', index=False)\n#     log.info(f\"sub.shape: {sub.shape}\")\n\n    print(test[['sig_id'] + target_cols].shape)\n    if cfg.model.train_models:\n        return score\n    else:\n        return 0\n\n\nif __name__ == '__main__':\n    run()\n"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"nbformat":4,"nbformat_minor":4}