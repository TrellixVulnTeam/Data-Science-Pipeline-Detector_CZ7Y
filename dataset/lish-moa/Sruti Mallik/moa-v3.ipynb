{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Read train and test datasets"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_features = pd.read_csv('/kaggle/input/lish-moa/train_features.csv')\ntrain_targets = pd.read_csv('/kaggle/input/lish-moa/train_targets_scored.csv')\n\ntest_features = pd.read_csv('/kaggle/input/lish-moa/test_features.csv')\nsample_sub = pd.read_csv('/kaggle/input/lish-moa/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of training samples: {}'.format(train_features.shape[0]))\nprint('Number of features: {}'.format(train_features.shape[1]))\n\nprint('Number of test samples: {}'.format(test_features.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Let us look at the types of features in the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"def feature_distribution_visualize(data):\n    g_feats = []\n    c_feats = []\n    others = []\n    for feature in data.columns:\n        if feature.find('c-')!=-1:\n            c_feats.append(feature)\n        elif feature.find('g-')!=-1:\n            g_feats.append(feature)\n        else:\n            others.append(feature)\n    return c_feats, g_feats, others\n\nc_feats, g_feats, others = feature_distribution_visualize(train_features)\n\n#Plot distribution of the type of features\nplt.figure(figsize=(8,4))\nplt.bar(['cell viability', 'gene expression', 'others'], [len(c_feats), len(g_feats), len(others)], \n            color = ['gray','pink','magenta'])\nplt.xticks(['cell viability', 'gene expression', 'others'], rotation = 0)\nplt.title('Distribution of type of features')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" **Plot the distribution for the features that are related to treatment plan**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16,4))\no_count = len(others)\nfor i in range(1,o_count):\n    plt.subplot(1,o_count-1, i)\n    sns.countplot(train_features[others[i]], palette = 'pink')\nplt.suptitle('Distribution of features related to treatment')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Investigate the statistics of cell viability features**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nsummary_stat_c = train_features[c_feats].describe()\nplt.figure(figsize = (8,8))\n#Plot the distribution of mean of cell viability\nplt.subplot(2,2,1)\nsns.distplot(summary_stat_c.values[1], color = 'gray')\nplt.title('Mean Cell Viability')\n\n#Plot the distribution of std of cell viability\nplt.subplot(2,2,2)\nsns.distplot(summary_stat_c.values[2], color = 'gray')\nplt.title('Standard Deviation of Cell Viability')\n\n#Plot the distribution of minimum values of cell viability\nplt.subplot(2,2,3)\nsns.distplot(summary_stat_c.values[3], color = 'gray',kde_kws={'bw': 0.1})\nplt.title('Minimum Cell Viability')\n\n#Plot the distribution of maximum values of cell viability\nplt.subplot(2,2,4)\nsns.distplot(summary_stat_c.values[7], color = 'gray')\nplt.title('Maximum Cell Viability')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Investigate the statistics of gene expression features**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Investigate the statistics of cell viability features\nsummary_stat_g = train_features[g_feats].describe()\nplt.figure(figsize = (8,8))\n#Plot the distribution of mean of cell viability\nplt.subplot(2,2,1)\nsns.distplot(summary_stat_g.values[1], color = 'pink')\nplt.title('Mean Gene Expression')\n\n#Plot the distribution of std of cell viability\nplt.subplot(2,2,2)\nsns.distplot(summary_stat_g.values[2], color = 'pink')\nplt.title('Standard Deviation of Gene Expression')\n\n#Plot the distribution of minimum values of cell viability\nplt.subplot(2,2,3)\nsns.distplot(summary_stat_g.values[3], color = 'pink',kde_kws={'bw': 0.1})\nplt.title('Minimum Gene Expression Viability')\n\n#Plot the distribution of maximum values of cell viability\nplt.subplot(2,2,4)\nsns.distplot(summary_stat_g.values[7], color = 'pink')\nplt.title('Maximum Gene Expression Viability')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Look at Correlations across Cell Viability and Gene Expressions**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# corr_Matrix_cell = train_features[c_feats].corr()\n# plt.figure(figsize= (10,10))\n# sns.heatmap(corr_Matrix_cell, cmap = 'bwr')\n# plt.title('Correlation across c-type features')\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# corr_Matrix_gene = train_features[g_feats].corr()\n# plt.figure(figsize= (10,10))\n# sns.heatmap(corr_Matrix_gene, cmap = 'bwr')\n# plt.title('Correlation across g-type features')\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Let us consider the target variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_targets.head()\n\n#Look at the range of values of the targets\n# plt.figure(figsize=(8,8))\n# plt.pcolor(train_targets.iloc[1:100,1:100])\n# plt.title('Heatmap of values of the target')\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA on target variables"},{"metadata":{},"cell_type":"markdown","source":"# Prepare dataset for model generation"},{"metadata":{"trusted":true},"cell_type":"code","source":"#check if all ids match in training features and training targets\ndef check_ids(features, targets):\n    for i in range(train_features.shape[0]):\n        if train_features['sig_id'][i]!= train_targets['sig_id'][i]:\n            print('Mismatch detected!')\n    print('Done!')\n    \ndef preprocess_categorical(data):\n    data.loc[:,'cp_type'] = data.loc[:, 'cp_type'].map({'trt_cp': 0, 'ctl_vehicle': 1})\n    data.loc[:,'cp_dose'] = data.loc[:, 'cp_dose'].map({'D1':0, 'D2':1})\n    return data\n\ncheck_ids(train_features, train_targets)\naug_data_g = pd.concat([pd.DataFrame(train_features[g_feats]), \n                      pd.DataFrame(test_features[g_feats])])\naug_data_c = pd.concat([pd.DataFrame(train_features[c_feats]), \n                      pd.DataFrame(test_features[c_feats])])\n\nX = train_features.drop(labels ='sig_id', axis = 1)\nX = preprocess_categorical(X)\ny = train_targets.drop(labels = 'sig_id', axis = 1)\n\nX_test = test_features.drop(labels = 'sig_id', axis = 1)\nX_test = preprocess_categorical(X_test)\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.feature_selection import VarianceThreshold\n\ndef feature_augment(aug_data, feature_set, n_comp):\n    data_pca = (PCA(n_components=n_comp, random_state=42).fit_transform(aug_data[feature_set]))\n    train2 = data_pca[:train_features.shape[0]]; test2 = data_pca[-test_features.shape[0]:]    \n    return train2, test2\n\ntrain_g_add, test_g_add = feature_augment(aug_data_g, g_feats, 600)\ntrain_c_add, test_c_add = feature_augment(aug_data_c, c_feats, 40)\n\ntrain_g_add = pd.DataFrame(train_g_add, columns=[f'pca_G-{i}' for i in range(600)])\ntest_g_add = pd.DataFrame(test_g_add, columns=[f'pca_G-{i}' for i in range(600)])\n\ntrain_c_add = pd.DataFrame(train_c_add, columns=[f'pca_C-{i}' for i in range(40)])\ntest_c_add = pd.DataFrame(test_c_add, columns=[f'pca_C-{i}' for i in range(40)])\n\nX = pd.concat((X, train_g_add, train_c_add), axis=1)\nX_test = pd.concat((X_test, test_g_add, test_c_add), axis=1)\n\nvar_thresh = VarianceThreshold(0.8)\ndata = X.append(X_test)\ndata_transformed = var_thresh.fit_transform(data.iloc[:, 3:])\n\ntrain_transform = data_transformed[ : train_features.shape[0]]\ntest_transform = data_transformed[-test_features.shape[0] : ]\n\nX_train_features = pd.DataFrame(X[['cp_type','cp_time','cp_dose']].values.reshape(-1, 3),\\\n                              columns=['cp_type','cp_time','cp_dose'])\nX = pd.concat([X_train_features, pd.DataFrame(train_transform)], axis=1)\n\n\nX_test_features = pd.DataFrame(X_test[['cp_type','cp_time','cp_dose']].values.reshape(-1, 3),\\\n                             columns=['cp_type','cp_time','cp_dose'])\nX_test = pd.concat([X_test_features, pd.DataFrame(test_transform)], axis=1)\n\nprint(X.head())\nprint('Number of features in modified training set: ', X.shape[1])\nprint('Number of features in modified test set: ', X_test.shape[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Begin building ML Model to make predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, KFold\nfrom sklearn.metrics import log_loss\n\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras import layers, models, optimizers\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS = 30\nLR = 1e-3\nBATCH_SIZE = 32\nINPUT_DIM = X.shape[1]\nOUTPUT_DIM = y.shape[1]\nHIDDEN = [1024, 1024, 512, 512, 512, 512]\nNUM_FOLD = 5\n\ndef create_model(input_dim = INPUT_DIM, hidden_layers = HIDDEN, output_dim = OUTPUT_DIM):\n    inp = layers.Input(shape = (input_dim, ))\n    x = inp\n    \n    x = layers.BatchNormalization()(x)\n    \n    for units in hidden_layers:\n        x = layers.Dense(units, activation = 'relu', \n                         kernel_regularizer = tf.keras.regularizers.l2(1e-4),\n                         bias_regularizer = tf.keras.regularizers.l2(1e-4))(x)\n        x = layers.BatchNormalization()(x)\n        \n    outp = layers.Dense(output_dim, activation = 'sigmoid', \n                        kernel_regularizer = tf.keras.regularizers.l2(1e-4), \n                        bias_regularizer = tf.keras.regularizers.l2(1e-4))(x)\n    model = models.Model(inputs = inp, outputs = outp, name = 'multioutput_model')\n    \n#     model.summary()\n    return model\n\ndef train_model(X, y, K_Fold =False, epochs = EPOCHS, \n                learning_rate = LR, batch_size = BATCH_SIZE):\n    \n    opt = optimizers.Adam(learning_rate=LR)\n    reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, patience = 3)\n    \n    if not K_Fold:\n        print('-----------------------------------------------------------')\n        print('Performing hold-out validation')\n        print('-----------------------------------------------------------')\n        X_train, X_val, y_train, y_val = train_test_split(X,y, test_size = 0.25, \n                                                  random_state = True, shuffle = True)\n        model = create_model()\n        model.compile(loss = 'binary_crossentropy', optimizer = opt, metrics = ['binary_crossentropy'])\n        history = model.fit(X_train, y_train, validation_data = (X_val, y_val), epochs = epochs, \n                       batch_size = batch_size, callbacks = [reduce_lr])\n        plot_train_result(history)\n    else:\n        print('-----------------------------------------------------------')\n        print('Performing k-fold cross validation')\n        print('-----------------------------------------------------------')\n        kfold = KFold(n_splits=NUM_FOLD, shuffle=True)\n        loss_per_fold = []\n        \n        fold_num = 1\n        for train, val in kfold.split(X, y):\n            \n            model = create_model()\n            model.compile(loss = 'binary_crossentropy', optimizer = opt)\n            \n            print('-----------------------------------------------------------')\n            print('Training on Fold: {}'.format(fold_num))\n            print('-----------------------------------------------------------')\n            \n            X_train, X_val = X.values[train], X.values[val]\n            y_train, y_val = y.values[train], y.values[val]\n            history = model.fit(X_train, y_train, validation_data = (X_val, y_val), \n                                epochs = epochs, batch_size = batch_size, \n                                callbacks = [reduce_lr])\n            fold_num += 1   \n            loss_per_fold.append(history.history['val_loss'][-1])\n        print('Best Validation Loss:', min(loss_per_fold))\n        \n    return model\n\ndef plot_train_result(history):\n    plt.figure()\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.legend(['Training Loss', 'Validation Loss'])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = train_model(X, y, K_Fold = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_predict = sample_sub.copy()\nsubmission_predict.loc[:, y.columns] = 0\nsubmission_predict.loc[:, y.columns] += model.predict(X_test.values[:])\n\ntraining_predict = y.copy()\ntraining_predict.loc[:, y.columns] = 0\ntraining_predict.loc[:, y.columns] += model.predict(X.values[:])\n\nmetrics = []\nfor _target in y.columns:\n    metrics.append(log_loss(train_targets.loc[:, _target], training_predict.loc[:, _target]))\n    \nprint(f'OOF Metric: {np.mean(metrics)}')\n\nsubmission_predict.loc[X_test['cp_type'] == 1, y.columns] = 0\n\nsubmission_predict.to_csv('submission.csv', index = False)\n\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}