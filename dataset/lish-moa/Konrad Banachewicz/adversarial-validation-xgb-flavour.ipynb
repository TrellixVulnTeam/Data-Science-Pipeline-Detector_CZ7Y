{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import KFold, StratifiedKFold\n\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.metrics import log_loss, roc_auc_score\n\nfrom datetime import date\n\nfrom sklearn.pipeline import Pipeline\n\nfrom xgboost import XGBClassifier, plot_importance\n\nfrom category_encoders import CountEncoder\n\nfrom matplotlib import pyplot","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# settings\n\nnfolds = 5\ndata_folder = '../input/lish-moa/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load the data\nxtrain = pd.read_csv(data_folder + 'train_features.csv')\nxtest = pd.read_csv(data_folder + 'test_features.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# prepare split\nkf = StratifiedKFold(n_splits = nfolds)\n\n# separation\nid_train = xtrain['sig_id']; id_test = xtest['sig_id']\nxtrain.drop('sig_id', axis = 1, inplace = True)\nxtest.drop('sig_id', axis = 1, inplace = True)\n\n# add the differentiating column\nxtrain['is_test'] = 0\nxtest['is_test'] = 1\n\n# combine the two datasets\nxdat = pd.concat([xtrain, xtest], axis = 0)\ndel xtrain, xtest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# little bit of FE\n\nenc = LabelEncoder()\nenc_cnt = CountEncoder()\ncategory_cols = ['cp_dose', 'cp_type']\nprint(category_cols)\n\nfor cols in category_cols:\n    xdat[cols] = enc.fit_transform(xdat[cols])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model\n\nclassifier = XGBClassifier(tree_method='gpu_hist')\n\nparams = {'colsample_bytree': 0.6522,\n          'gamma': 3.6975,\n          'learning_rate': 0.0503,\n          'max_delta_step': 2.0706,\n          'max_depth': 10,\n          'min_child_weight': 31.5800,\n          'n_estimators': 200,\n          'subsample': 0.8639,\n          'alpha': 0.05\n         }\n\nclassifier.set_params(**params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# separate the target\nydat = xdat['is_test']; xdat.drop('is_test', axis =1, inplace = True)\n\n# storage structure for the predicted probabilities\nprmat = np.zeros((xdat.shape[0],1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for (ff, (id0, id1)) in enumerate(kf.split(xdat,ydat)):\n     \n    x0, x1 = xdat.iloc[id0], xdat.iloc[id1]\n    y0, y1 = ydat.iloc[id0], ydat.iloc[id1]\n    \n    print(sum(y0))\n    \n    # fit model\n    classifier.fit(x0, y0)\n    \n    # generate predictions\n    vpreds = classifier.predict_proba(x1)\n    prmat[id1,0] = vpreds[:,1]\n\n    print(ff)\n    \n    print('--')\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluate the performance \nprint(roc_auc_score(ydat, prmat))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot the features relevant for distinction\n\nplot_importance(classifier, max_num_features = 25)\npyplot.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}