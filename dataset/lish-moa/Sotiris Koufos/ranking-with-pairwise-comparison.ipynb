{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Import libraries\nimport numpy as np\nimport pandas as pd\n\n# Load the competition data (train features and train labels)\nx_train = pd.read_csv('/kaggle/input/lish-moa/train_features.csv')\ny_train = pd.read_csv('/kaggle/input/lish-moa/train_targets_scored.csv')\n\nprint(f'Train features shape: {x_train.shape}')\nprint(f'Train target shape: {y_train.shape}')\n\n# The competition authors mentioned that only treatment typed samples have\n# labels. We can quickly verify that\n\ntrt_ids = x_train[x_train.cp_type != 'trt_cp'].sig_id\nnon_trt_label_count = y_train[y_train.sig_id.isin(trt_ids)].values[:, 1:].sum()\nprint(f'Control type samples label count: {non_trt_label_count}')\n\n# Keep only treatment typed samples from both train features\n# and train labels\nfiltered_idxs = x_train[x_train.cp_type == 'trt_cp'].index\nx_train = x_train.loc[filtered_idxs, :]\ny_train = y_train.loc[filtered_idxs, :]\n\n# One-encode the two categorical features: dose and time\ndose_cat = pd.get_dummies(x_train.cp_dose)\ntime_cat = pd.get_dummies(x_train.cp_time)\nx_train = pd.concat([x_train, dose_cat, time_cat], axis=1)\n\n# Select the columns of the train dataset.\n# The train dataset will consist of the numeric features plus the one-hot encoded\n# representations of dose and time.\nfeature_columns = [i for i in x_train.columns if i not in ['sig_id', 'cp_type', 'cp_time', 'cp_dose']]\ntarget_classes = [i for i in y_train.columns if i not in ['sig_id']]\n\n# Filter the data based on the selected columns\nX = x_train[feature_columns].values\ny = y_train[target_classes].values\nprint(f'Train dataset shape: {X.shape}')\nprint(f'Train labels shape: {y.shape}')\n\n# Calculate the sparcity of labels\ntotal_positive_labels = np.sum(y)\ntotal_labels = y.flatten().shape[0]\nprint(f'Positive labels: {total_positive_labels}')\nprint(f'Total labels: {total_labels}')\nprint(f'Sparsity ratio: {total_positive_labels / total_labels:.4f}')\n\n# Perform analysis on the representation of classes between samples\n# We select the unique combination of feature classes in a 2D array\n# and the frequency if each unique combination in a 1D array\nunique_rows, unique_counts = np.unique(y, return_counts=True, axis=0)\n\n# Construct a dataframe from the above extraction for easier manipulation\n# Dataframe inndex will be the integer label for each unique combination,\n# Row is each unique representation and class count its frequency count\nclass_df = pd.DataFrame({\n    'row': [i for i in unique_rows],\n    'class_count': list(unique_counts)\n})\n\n# Sort the dataframe in descending popularity. The impact of the sorting\n# to end performance should be investigated, but this way when we filter out\n# unpopular classes we do not have gaps in class numbers, can be problematic\n# for certain sklearn methods\nclass_df.sort_values(by='class_count', ascending=False, inplace=True)\nclass_df.reset_index(drop=True, inplace=True)\n\n# Construct dictionaries to map from a unique representation to a class number\n# and vice versa\nrow_to_class = {}\nclass_to_row = {}\nfor i, df_row in class_df.iterrows():\n    row_to_class[tuple(df_row.row)] = i\n    class_to_row[i] = df_row.row\n\n# Map the train labels to their respective class number. This way we can filter out\n# train samples that belong to unpopular classes but also perform StratifedKFold.\n# We can also use this new representation of classes to transform our multi-label\n# problem to a multi-class problem which are generally easier to slove.\n\n# But there are issues with that:\n# If there are too many unique representations we end up with too many labels.\n# Usually heavy class imbalance\n# We cannot predict class combinations whose representation does not exist during\n# training\ny_classes = np.array([row_to_class[tuple(i)] for i in y])\nprint(f'Target class shape: {y_classes.shape}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find which classes are the least popular.\noutlier_classes = class_df[class_df.class_count < 6].index\n\n# Find the index of the train labels where there are no unpopular classes\nfiltered_idx = [i for i,x in enumerate(y_classes) if x not in outlier_classes]\n\n# Filter the train set without having unpopular classes\nX = X[filtered_idx]\ny = y[filtered_idx]\ny_classes = y_classes[filtered_idx]\nprint(f'Outlier classes: {outlier_classes}')\nprint(f'Shape of filtered features: {X.shape}')\nprint(f'Shape of filtered classes: {y_classes.shape}')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# create label pairs\nlabel_idxs = np.arange(y.shape[1])\nlabel_pairs = [(i, j) for i,_ in enumerate(label_idxs) for j,_ in enumerate(label_idxs) if i>j]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm.notebook import tqdm\nfrom sklearn.linear_model import LogisticRegressionCV, SGDClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import make_scorer, log_loss, roc_auc_score\nimport warnings\n\nscorer = make_scorer(log_loss,\n                     greater_is_better=False,\n                     needs_proba=True)\n\n\ndef assign_class(class_names, pred):\n    return class_names[0] if pred == 0 else class_names[1]\n\n\nwith warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\")\n    pairwise_models = []\n    pairwise_scores = []\n\n    for pair in tqdm(label_pairs):\n        partial_ds = y[:, pair]\n        # filter samples that have at least one label but not both\n        filtered_idxs = np.logical_xor(partial_ds[:, 0], partial_ds[:, 1])\n        partial_X = X[filtered_idxs]\n        partial_y = partial_ds[filtered_idxs, 1]\n        ds_size = partial_y.shape[0]\n        \n        v, c = np.unique(partial_y, return_counts=True)\n        if (v.shape[0] < 2) or any(i < 6 for i in c):\n            continue\n        \n        model = LogisticRegressionCV(cv=5, n_jobs=5)\n        model.fit(partial_X, partial_y)\n        \n        # calculate score\n#         partial_preds = model.predict_proba(partial_X)\n#         partial_score = roc_auc_score(partial_y, partial_preds[:, 1])\n#         pairwise_scores.append(partial_score)\n        \n        # gather models\n        pairwise_models.append((model, pair, ds_size))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_features = pd.read_csv('/kaggle/input/lish-moa/test_features.csv')\n\ntest_time = pd.get_dummies(test_features.cp_time)\ntest_dose = pd.get_dummies(test_features.cp_dose)\n\ntest_features = pd.concat([test_features, test_dose, test_time], axis=1)\nX_test = test_features[feature_columns].values\n\n# Cast votes for each classifier\nvotes = np.zeros((X_test.shape[0], y.shape[1]))\nnormalization = 206\nvote_normalization = max([i[2] for i in pairwise_models])\n\nfor i, (model, class_i, w) in tqdm(enumerate(pairwise_models), total=len(pairwise_models)):\n#     vote = model.predict_proba(X)\n#     current_class_votes = votes[:, class_i[1]]\n#     current_class_votes += vote[:, 1] * (w/vote_normalization)\n#     votes[:, class_i[1]] = current_class_votes\n\n#     for j, class_idx in enumerate(class_i):\n#         current_class_votes = votes[:, class_idx]\n#         current_class_votes += vote[:, j] * (w/vote_normalization)\n#         votes[:, class_idx] = current_class_votes\n\n    vote = model.predict(X_test)\n    vote = np.array(list(map(lambda x: assign_class(class_i, x), vote)))\n    for class_name in class_i:\n        vote = np.where(vote == class_name, 1, 0) * (w/vote_normalization)\n        current_class_votes = votes[:, class_name]\n        current_class_votes += vote\n        votes[:, class_name] = current_class_votes\n\nvotes /= normalization\n\nprint(f'Votes shape: {votes.shape}')   \n\nsubmission = pd.read_csv('/kaggle/input/lish-moa/sample_submission.csv')\nsubmission.iloc[:, 1:] = votes\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}