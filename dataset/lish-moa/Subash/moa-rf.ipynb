{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"scored=pd.read_csv('/kaggle/input/lish-moa/train_targets_scored.csv')\nnoscored=pd.read_csv('/kaggle/input/lish-moa/train_targets_nonscored.csv')\ntrain=pd.read_csv('/kaggle/input/lish-moa/train_features.csv')\nsubmit=pd.read_csv('/kaggle/input/lish-moa/sample_submission.csv')\ntest=pd.read_csv('/kaggle/input/lish-moa/test_features.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=train.drop('sig_id',axis=1)\nY=scored.drop('sig_id',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import log_loss\nfrom category_encoders.target_encoder import TargetEncoder\nfrom sklearn.decomposition import PCA","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X1=pd.concat([X,Y],axis=1)\ncorr1=X1.corr()\na=pd.DataFrame(corr1[Y.columns].T.abs().max()>0.4)\naa=train[a[a[0]==False].index.tolist()].drop('cp_time',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.1, random_state=42)\npca = PCA(n_components=100)\nX_train_pca=pd.DataFrame(pca.fit_transform(X_train[aa.columns]),index=X_train.index)\nX_train=pd.concat([X_train.drop(aa.columns,axis=1),X_train_pca],axis=1)\nX_test=pd.concat([X_test.drop(aa.columns,axis=1),pd.DataFrame(pca.transform(X_test[aa.columns]),index=X_test.index)],axis=1)\ntest2=pd.concat([test.drop(aa.columns,axis=1),pd.DataFrame(pca.transform(test[aa.columns]),index=test.index)],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params1 = {'bootstrap': True,\n 'max_depth': 3,\n 'n_estimators': 25}\nparams2 = {'bootstrap': True,\n 'max_depth': 80,\n 'n_estimators': 50}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def pred_output(X_train, X_test, Y_train, Y_test, test):\n    try :\n        test=test.drop('sig_id',axis=1)\n        cet=TargetEncoder(cols=['cp_type','cp_time','cp_dose'])\n        X_train=cet.fit_transform(X_train,Y_train).drop(['cp_type','cp_time','cp_dose'],axis=1)\n        X_test=cet.transform(X_test).drop(['cp_type','cp_time','cp_dose'],axis=1)\n        test=cet.transform(test).drop(['cp_type','cp_time','cp_dose'],axis=1)\n        if Y_train.sum()>300:\n            params=params2\n        else : \n            params=params1\n        clf = RandomForestClassifier(n_estimators=params['n_estimators'], max_depth=params['max_depth'], bootstrap = params['bootstrap'])\n        clf.fit(X_train, Y_train)\n        Y_submit = clf.predict_proba(test)[:,1]\n        return(Y_submit,log_loss(Y_test,clf.predict_proba(X_test)[:,1]))\n    except (ValueError, IndexError):\n        return(np.zeros(test.shape[0]),np.nan)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score=[]\nj=0\nfor i in scored.drop('sig_id',axis=1).columns:\n    print(i)\n    j=j+1\n    print(j)\n    output, m= pred_output(X_train, X_test, Y_train[i], Y_test[i], test2)\n    score.append(m)\n    submit[i]=output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train.sig_id=='id_000644bb2']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sum(scored.sum()==0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sum(scored.sum()==0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params1['bootstrap']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}