{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Загрузим и посмотрим датасеты"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/lish-moa/train_features.csv')\ntrain_df_scored = pd.read_csv('/kaggle/input/lish-moa/train_targets_scored.csv')\ntrain_df_noscored = pd.read_csv(\"/kaggle/input/lish-moa/train_targets_nonscored.csv\")\n\ntest_df = pd.read_csv(\"/kaggle/input/lish-moa/test_features.csv\")\nsample_sub = pd.read_csv(\"/kaggle/input/lish-moa/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df_scored.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df_scored.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Сделаем небольшой EDA"},{"metadata":{},"cell_type":"markdown","source":"Посмотрим сначала на фичи, которые выделяются от остальных (категориальные):"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['cp_type'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['cp_dose'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['cp_time'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Теперь посмотрим на таргет. Сначала - сумму по столбцам, потом - по строкам"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df_scored.iloc[:, 1:].sum(axis = 0).sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df_scored.iloc[:, 1:].sum(axis = 1).value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Видим, что у большинства объектов только одна 1, но есть и много тех, у которых 1 нет вообще. Посмотрим на них"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[train_df_scored.iloc[:, 1:].sum(axis = 1) == 0][['cp_type']].value_counts()/len(train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[['cp_type']].value_counts()/len(train_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Видим, что если cp_type = 'ctl_vehicle', то нули во всех столбцах. От этой фичи можно избавиться."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[train_df_scored.iloc[:, 1:].sum(axis = 1) == 0][['cp_dose']].value_counts()/len(train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[['cp_dose']].value_counts()/len(train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[train_df_scored.iloc[:, 1:].sum(axis = 1) == 0][['cp_time']].value_counts()/len(train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[['cp_time']].value_counts()/len(train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(12, 60))\n\nsns.barplot(x=train_df_scored.drop('sig_id', axis = 1).sum(axis = 0).sort_values().values,\n            y=train_df_scored.drop('sig_id', axis = 1).sum(axis = 0).sort_values().index)\n\nplt.tick_params(axis='x', labelsize=15)\nplt.tick_params(axis='y', labelsize=15)\nplt.xlabel('')\nplt.ylabel('')\nplt.title('Число 1 в различных таргетах', size=18, pad=18)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = train_df_scored.iloc[:, 1:].corr()\ncorr[corr>=.5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ncorr = train_df_scored.iloc[:, 1:].corr()\n\nf = plt.figure(figsize=(50, 50))\n\nax = sns.heatmap(\n    corr, \n    vmin=-1, vmax=1, center=0,\n    cmap=sns.diverging_palette(20, 220, n=200),\n    square=True\n)\nax.set_xticklabels(\n    ax.get_xticklabels(),\n    rotation=45,\n    horizontalalignment='right'\n);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df_scored.iloc[:, 1:].corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set()\n\nsns.set_style('whitegrid')\nsns.set_context('talk')\nparams = {'legend.fontsize': 'x-large',\n          'figure.figsize': (30, 10),\n          'axes.labelsize': 'x-large',\n          'axes.titlesize':'x-large',\n          'xtick.labelsize':'x-large',\n          'ytick.labelsize':'x-large'}\n\nplt.rcParams.update(params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df_scored.sum(axis = 1).value_counts().plot(kind='bar', title = \"Число ненулевых значений таргета\", xlabel = \"количество 1 в таргете\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['is_all_targets_null'] = (train_df_scored.sum(axis = 1) == 0).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[['cp_type', 'is_all_targets_null']].groupby('cp_type').sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train_df[train_df['cp_type'] == 'ctl_vehicle'])/len(train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use('default')\nsns.pairplot(train_df[['is_all_targets_null', 'cp_time', 'g-1']].sample(n = 1000), height=2.5, hue=\"is_all_targets_null\") ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"targets = pd.DataFrame(train_df_scored.iloc[:, 1:].columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_targ = pd.DataFrame(train_df_scored.iloc[:, 1:].sum(axis = 0)).reset_index()\n\ndef make_groups(x):\n    if 'inhibitor' in x: \n        return 'is_inhibitor'\n    elif 'agonist' in x:\n        return 'is_agonist'\n    elif 'antagonist' in x:\n        return 'is_antagonist'\n    elif 'activator' in x:\n        return 'is_activator'\n    elif 'blocker' in x:\n        return 'is_blocker'\n    else:\n        return 'else'\n            \n            \ndf_targ.columns = ['name', 'number']\ndf_targ['group'] = df_targ['name'].apply(lambda x: make_groups(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"make_groups('acetylcholine_receptor_agonist')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_targ['group'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use('default')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_targ.groupby('group').sum().plot(kind = 'bar', title = 'число 1 по типам')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['group'] = df_targ['group']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in ['is_inhibitor', 'is_agonist', 'is_antagonist', 'is_activator', 'is_blocker', 'else_col']:\n    train_df_scored[i] = 0\n\n\n    \n\nfor i in train_df_scored.iloc[:, 1:].columns:\n    if 'inhibitor' in i: \n        train_df_scored['is_inhibitor'] += train_df_scored[i]\n    if 'agonist' in i:\n        train_df_scored['is_agonist'] += train_df_scored[i]\n    if 'antagonist' in i:\n        train_df_scored['is_antagonist'] += train_df_scored[i]\n    if 'activator' in i:\n        train_df_scored['is_activator'] += train_df_scored[i]\n    if 'blocker' in i:\n        train_df_scored['is_blocker'] += train_df_scored[i]\n    else:\n        train_df_scored['else_col'] = train_df_scored['else_col'] + train_df_scored[i]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in ['is_inhibitor', 'is_agonist', 'is_antagonist', 'is_activator', 'is_blocker', 'else_col']:\n    train_df_scored[i] = train_df_scored[i].apply(lambda x: 1 if x >= 1 else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in ['is_inhibitor', 'is_agonist', 'is_antagonist', 'is_activator', 'is_blocker', 'else_col']:\n    train_df[i] = train_df_scored[i]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(train_df[['is_inhibitor', 'g-0', 'g-1']].sample(n = 4000), height=2.5, hue=\"is_inhibitor\") ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['is_inhibitor']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import umap","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df_sample = train_df.sample(n = 5000)\nembedding = umap.UMAP(n_neighbors=5).fit_transform(train_df_sample.iloc[:, 4:104])\n\nfor i in ['is_inhibitor', 'is_agonist', 'is_antagonist', 'is_activator', 'is_blocker', 'else_col']:\n    plt.figure()\n    plt.scatter(embedding[:, 0],embedding[:, 1], s= 5, c=train_df_sample[i], cmap='Spectral',label=i)\n    plt.title('Embedding of the g-XX features on training set by UMAP', fontsize=13);\n    plt.legend();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df_sample = train_df.sample(n = 5000)\nembedding = umap.UMAP(n_neighbors=5).fit_transform(train_df_sample.iloc[:, 4:104])\n\nfor i in ['is_inhibitor', 'is_agonist', 'is_antagonist', 'is_activator', 'is_blocker', 'else_col']:\n    plt.figure()\n    plt.scatter(embedding[:, 0],embedding[:, 1], s= 5, c=train_df_sample[i], cmap='Spectral',label=i)\n    plt.title('Embedding of the g-XX features on training set by UMAP', fontsize=13);\n    plt.legend();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df_sample = train_df.sample(n = 5000)\nembedding = umap.UMAP(n_neighbors=5).fit_transform(train_df_sample.iloc[:, 776:876])\n\nfor i in ['is_inhibitor', 'is_agonist', 'is_antagonist', 'is_activator', 'is_blocker', 'else_col']:\n    plt.figure()\n    plt.scatter(embedding[:, 0],embedding[:, 1], s= 5, c=train_df_sample[i], cmap='Spectral',label=i)\n    plt.title('Embedding of the c-XX features on training set by UMAP', fontsize=13);\n    plt.legend();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Сделаем простенькую модель"},{"metadata":{"trusted":true},"cell_type":"code","source":"from catboost import CatBoostClassifier\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.multioutput import MultiOutputClassifier\n\nfrom xgboost import XGBClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import log_loss\nfrom category_encoders import CountEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train_df.drop(['sig_id'] , axis = 1)\nX_test_big = test_df.drop(['sig_id'], axis = 1)\n\ny = train_df_scored.drop('sig_id', axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX = CountEncoder(cols=['cp_type', 'cp_dose']).fit_transform(X)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train['5-alpha_reductase_inhibitor'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = CatBoostClassifier(n_estimators = 50).fit(X_train, y_train['5-alpha_reductase_inhibitor'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.Series(model.predict(X_test)).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = MultiOutputClassifier(CatBoostClassifier(n_estimators = 10, max_depth = 10))\n\nclf = Pipeline([('encode', CountEncoder(cols=[0, 2])),\n                ('classify', classifier)\n               ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time \nclf.fit(X.values, y.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.predict_proba(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_train(resume_models = None, repeat_number = 0, folds = 5, skip_folds = 0):\n    \n    models = []\n    oof_preds = y_train.copy()\n    \n\n    kfold = KFold(folds, shuffle = True)\n    \n    for fold, (train_ind, val_ind) in enumerate(kfold.split(x_train)):\n        print('\\n')\n        print('---------------------------------------------------------')\n        print(f'Fold number {fold + 1}')\n        \n        cb_lr_schedule = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'binary_crossentropy', factor = 0.4, patience = 2, verbose = 1, min_delta = 0.0001, mode = 'auto')\n        checkpoint_path = f'repeat:{repeat_number}_Fold:{fold}.hdf5'\n        cb_checkpt = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, monitor = 'val_loss', verbose = 0, save_best_only = True, save_weights_only = True, mode = 'min')\n\n        model = create_model()\n        model.fit(x_train.values[train_ind],\n              y_train.values[train_ind],\n              validation_data=(x_train.values[val_ind], y_train.values[val_ind]),\n              callbacks = [cb_lr_schedule, cb_checkpt],\n              epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=2\n             )\n        model.load_weights(checkpoint_path)\n        oof_preds.loc[val_ind, :] = model.predict(x_train.values[val_ind])\n        models.append(model)\n\n    return models, oof_preds","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}