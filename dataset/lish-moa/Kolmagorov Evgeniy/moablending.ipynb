{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#!pip3 install iterative-stratification\nimport sys\nsys.path.append('../input/iterset/iterstrat')\nfrom ml_stratifiers import MultilabelStratifiedKFold\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import GroupKFold, StratifiedKFold, KFold, train_test_split,  cross_val_score\nfrom sklearn.metrics import log_loss, make_scorer\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import QuantileTransformer\n\nimport torch \nimport matplotlib.pyplot as plt\nimport random","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def seed_everything(seed_value):\n    random.seed(seed_value)\n    np.random.seed(seed_value)\n    torch.manual_seed(seed_value)\n    os.environ['PYTHONHASHSEED'] = str(seed_value)\n    \n    if torch.cuda.is_available(): \n        torch.cuda.manual_seed(seed_value)\n        torch.cuda.manual_seed_all(seed_value)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\n        \nseed_everything(42)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_features = pd.read_csv(\"/kaggle/input/lish-moa/test_features.csv\")\ntrain_drug = pd.read_csv(\"/kaggle/input/lish-moa/train_drug.csv\")\ntrain_features = pd.read_csv(\"/kaggle/input/lish-moa/train_features.csv\")\ntrain_targets_scored = pd.read_csv(\"/kaggle/input/lish-moa/train_targets_scored.csv\")\ntrain_targets_nonscored = pd.read_csv(\"/kaggle/input/lish-moa/train_targets_nonscored.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_features.shape, train_targets_scored.shape, train_targets_nonscored.shape,  test_features.shape)\ntrain_features.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"common_names = [name for name in train_targets_nonscored.columns \n                if name in train_targets_scored.columns]\ncommon_names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cp_indexes_train = train_features[train_features[\"cp_type\"] == \"ctl_vehicle\"].index\ncp_indexes_test = test_features[test_features[\"cp_type\"] == \"ctl_vehicle\"].index\nprint(len(cp_indexes_train), len(cp_indexes_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#train_features = train_features.drop(cp_indexes_train).reset_index(drop=True)\n#test_dropped_rows = test_features.iloc[cp_indexes_test]\n\n#test_features = test_features.drop(cp_indexes_test).reset_index(drop=True)\n#train_targets_scored = train_targets_scored.drop(cp_indexes_train).reset_index(drop=True)\n#train_targets_nonscored = train_targets_nonscored.drop(cp_indexes_train).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_features = train_features.drop(\"cp_type\", axis=1)\n#test_features = test_features.drop(\"cp_type\",  axis=1)\n#print(train_features.shape, test_features.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Добавим drug_id в train_features"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_drug.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Preprocession_block"},{"metadata":{"trusted":true},"cell_type":"code","source":"GENES = [colname for colname in train_features.columns \n         if colname.startswith(\"g-\")]\n\nCELLS = [colname for colname in train_features.columns\n        if colname.startswith(\"c-\")]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#map categorical values\ndef map_dataset(df):\n    df['cp_type'] = df['cp_type'].map({'ctl_vehicle': 0, 'trt_cp':1})\n    df['cp_dose'] = df['cp_dose'].map({\"D1\":0, \"D2\":1})\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features = map_dataset(train_features)\ntest_features = map_dataset(test_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_PCA(train, test):\n    n_gs = 200 # No of PCA comps to include\n    n_cs = 20 # No of PCA comps to include\n    \n    pca_cs = PCA(n_components = n_cs)\n    pca_gs = PCA(n_components = n_gs)\n\n    united = pd.concat([train[GENES + CELLS], test[GENES+CELLS]], axis=0)\n    \n    united_pca_gs = pca_gs.fit_transform(united[GENES])\n    united_pca_cs = pca_cs.fit_transform(united[CELLS])\n    \n    \n    united_c_mean = np.expand_dims(united[CELLS].mean(axis=1), axis=1)\n    united_g_mean = np.expand_dims(united[GENES].mean(axis=1), axis=1)\n    \n    generated_features = pd.DataFrame(np.concatenate([united_pca_gs, united_pca_cs,\n                                         united_g_mean, united_c_mean], axis=1))\n    \n    train_generated = generated_features.iloc[:train.shape[0]].reset_index(drop=True)\n    test_generated = generated_features.iloc[train.shape[0]:].reset_index(drop=True)\n\n    train = pd.concat([train, train_generated], axis=1)\n    print(\"before:\", test.shape)\n    print(test_generated.shape, test.shape)\n    test = pd.concat([test, test_generated], axis=1)\n    print(\"After:\", test.shape)\n    return train, test\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_features.shape, test_features.shape)\ntrain_features, test_features = add_PCA(train_features, test_features)\nprint(train_features.shape, test_features.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_features.tail(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def QuantileTransform(train, test, transform_type):\n    transformer = QuantileTransformer(n_quantiles=100,random_state=0, output_distribution=transform_type)\n    united = pd.concat([train[GENES+CELLS], test[GENES+CELLS]], axis=0)\n    united = transformer.fit_transform(united)\n    train[GENES+CELLS] = united[:train.shape[0]]\n    test[GENES+CELLS] = united[train.shape[0]:]\n    \n    return train, test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30, 30))\ntrain_features[GENES[::25] + CELLS[::25]].hist(figsize=(20, 20))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features, test_features = QuantileTransform(train_features, test_features, 'normal')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features[GENES[::25] + CELLS[::25]].hist(figsize=(20, 20))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features = train_features.merge(train_drug, on='sig_id')\ntrain_features['drug_id'] = LabelEncoder().fit_transform(train_features['drug_id'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch \nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam\nfrom torch import optim\nfrom torch.utils.data import Dataset, DataLoader","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#!pip3 install pytorch-tabnet\nsys.path.append('../input/tabnet')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pytorch_tabnet.tab_model import TabNetRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MoADataset(Dataset):\n    def __init__(self, X, y=None):\n        if y is not None:\n            assert X.shape[0] == y.shape[0]\n        \n        self.X = torch.tensor(X, dtype=torch.float)\n        self.y = None\n        if y is not None:\n            self.y = torch.tensor(y, dtype=torch.float)\n        \n    def __getitem__(self, idx):\n\n        tensor_X = self.X[idx]\n        if self.y is not None:\n            tensor_y = self.y[idx]\n            return tensor_X, tensor_y\n        else:\n            return tensor_X\n    \n    def __len__(self):\n        return len(self.X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ModelMLP(nn.Module):\n    def __init__(self, num_features, num_targets, hidden_size):\n        super(ModelMLP, self).__init__()\n        self.hidden_size = hidden_size\n        \n        self.batch_norm1 = nn.BatchNorm1d(num_features)\n        self.dropout1 = nn.Dropout(0.3)\n        self.dense1 = nn.utils.weight_norm(nn.Linear(num_features, 2* hidden_size))\n        \n        self.batch_norm2 = nn.BatchNorm1d(2*hidden_size)\n        self.dropout2 = nn.Dropout(0.2)\n        self.dense2 = nn.utils.weight_norm(nn.Linear(2*hidden_size,  hidden_size))\n        \n        self.batch_norm3 = nn.BatchNorm1d(hidden_size)\n        self.dropout3 = nn.Dropout(0.1)\n        self.dense3 = nn.utils.weight_norm(nn.Linear(hidden_size, hidden_size))\n        \n        self.batch_norm4 = nn.BatchNorm1d(hidden_size)\n        self.dropout4 = nn.Dropout(0.1)\n        self.dense4 = nn.utils.weight_norm(nn.Linear(hidden_size, num_targets))\n        \n    def get_freeze(self, target_size, freeze_all=True):\n\n        if freeze_all:\n            for param in self.parameters():\n                param.requires_grad = False\n\n        self.dense3 = nn.Linear(self.hidden_size, self.hidden_size)\n        self.dense4 = nn.Linear(self.hidden_size, target_size)\n        \n    def forward(self, x):\n        #x = self.dropout1(x)\n        #x = self.batch_norm1(x)\n        x = F.leaky_relu(self.dense1(x), 1e-2)\n        \n        x = self.batch_norm2(x)\n        x = self.dropout2(x)\n        x_1 = F.relu(self.dense2(x))\n        \n        x=self.batch_norm3(x_1)\n        x = self.dropout3(x)\n        \n        \n        x = self.dense4(x + x_1)\n        #x = self.batch_norm3(x)\n        #x = self.dropout3(x)\n        \n\n        \n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ResidualNet(nn.Module):\n    \n    def __init__(self, num_features, num_targets, n_hidden):\n        super(ResidualNet, self).__init__()\n        self.block1 = nn.Sequential(\n            nn.Linear(num_features, n_hidden),\n            nn.ELU(),\n            nn.BatchNorm1d(n_hidden),\n            nn.Dropout(0.3),\n            nn.Linear(n_hidden, n_hidden),\n            nn.ELU(),\n            nn.BatchNorm1d(n_hidden),\n            nn.Dropout(0.3),\n            \n        )\n\n        self.block2 = nn.Sequential(\n            nn.Linear(num_features + n_hidden, n_hidden),\n            nn.ELU(),\n            nn.BatchNorm1d(n_hidden),\n            nn.Dropout(0.2),\n            \n            nn.Linear(n_hidden, n_hidden),\n            nn.ELU(),\n            nn.BatchNorm1d(n_hidden),\n            nn.Dropout(0.2),\n            \n            nn.Linear(n_hidden, n_hidden),\n            nn.ELU(),\n            nn.Dropout(0.2),\n            nn.BatchNorm1d(n_hidden),\n            \n            )\n\n        self.block3 = nn.Sequential(\n            nn.Linear(n_hidden + n_hidden, n_hidden),\n            nn.ELU(),\n            nn.BatchNorm1d(n_hidden),\n            nn.Dropout(0.1),\n            nn.Linear(n_hidden, n_hidden),\n            nn.ELU(),\n            nn.BatchNorm1d(n_hidden),\n            nn.Dropout(0.1),\n            nn.Linear(n_hidden, num_targets)\n        )\n\n\n    def get_freeze(self, target_size, freeze_all=True):\n        \n        if freeze_all:\n            for param in self.parameters():\n                param.requires_grad = False\n            \n        self.block3 = nn.Sequential(\n            nn.Linear(512 + 256, 512),\n            nn.BatchNorm1d(512),\n            nn.Dropout(0.1),\n            nn.ELU(),\n            nn.Linear(512, 256),\n            nn.BatchNorm1d(256),\n            nn.Dropout(0.1),\n            nn.ELU(),\n            nn.Linear(256, target_size)\n        )\n\n    def forward(self, x):\n\n        x_1 = self.block1(x)\n        x_1_cat = torch.cat([x, x_1], axis=-1)\n        x_2 = self.block2(x_1_cat)\n        x_2_cat = torch.cat([x_1, x_2], axis=-1)\n        output = self.block3(x_2_cat)\n\n        return output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self, num_features, num_targets, hidden_size):\n        super(Model, self).__init__()\n        self.batch_norm1 = nn.BatchNorm1d(num_features)\n        self.dropout1 = nn.Dropout(0.2)\n        self.dense1 = nn.utils.weight_norm(nn.Linear(num_features, hidden_size))\n        \n        self.batch_norm2 = nn.BatchNorm1d(hidden_size)\n        self.dropout2 = nn.Dropout(0.2)\n        self.dense2 = nn.utils.weight_norm(nn.Linear(hidden_size + num_features, hidden_size))\n        \n        self.batch_norm3 = nn.BatchNorm1d(hidden_size)\n        self.dropout3 = nn.Dropout(0.2)\n        self.dense3 = nn.utils.weight_norm(nn.Linear(hidden_size, num_targets))\n    \n    def forward(self, inputs):\n        x = self.batch_norm1(inputs)\n        #x = self.dropout1(x)\n        x_1 = F.leaky_relu(self.dense1(x), 1e-2)\n        \n        x = self.batch_norm2(x_1)\n        x_1 = self.dropout2(x)\n        x = torch.cat([x_1, inputs], axis=-1)\n        \n        x_2 = F.leaky_relu(self.dense2(x), 1e-2)\n        \n        x = self.batch_norm3(x_2)\n        x_2 = self.dropout3(x)\n        x = self.dense3(x_2)\n        \n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SimpleNet(nn.Module):\n    def __init__(self, num_features, num_targets, n_hidden):\n        super(SimpleNet, self).__init__()\n        self.layer1 = nn.Linear(num_features, n_hidden)\n        self.layer2 = nn.Linear(n_hidden, num_targets)\n    def forward(self, inputs):\n        \n        x = self.layer1(inputs)\n        x = F.relu(x)\n        x = self.layer2(x)\n        \n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PARAMS = {\n    \"BATCH_SIZE\": 1024,\n    \"EPOCHS\": 100,\n    \"DEVICE\": torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n    \"PATIENCE\": 10,\n    \"NUM_FOLDS\": 10,\n    \"TARGETS_OUTPUT\": 206,\n    \"LEARNING_RATE\": 1e-2,\n    \"WEIGHT_DECAY\" : 1e-5\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MAX_EPOCH=200\ntabnet_params = dict(n_d=24, n_a=24, n_steps=1, gamma=1.3,\n                     lambda_sparse=0, optimizer_fn=torch.optim.Adam,\n                     optimizer_params=dict(lr=3e-2, weight_decay=PARAMS[\"WEIGHT_DECAY\"]),\n                     mask_type='entmax',\n                     scheduler_params=dict(mode=\"min\",\n                                           patience=5,\n                                           min_lr=1e-5,\n                                           factor=0.8,),\n                     scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n                     verbose=5,\n                     )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pytorch_tabnet.metrics import Metric","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class LogitsLogLoss(Metric):\n    \"\"\"\n    LogLoss with sigmoid applied\n    \"\"\"\n\n    def __init__(self):\n        self._name = \"logits_ll\"\n        self._maximize = False\n\n    def __call__(self, y_true, y_pred):\n        \"\"\"\n        Compute LogLoss of predictions.\n\n        Parameters\n        ----------\n        y_true: np.ndarray\n            Target matrix or vector\n        y_score: np.ndarray\n            Score matrix or vector\n\n        Returns\n        -------\n            float\n            LogLoss of predictions vs targets.\n        \"\"\"\n       # self.smooth = 0.0002\n       # y_pred = y_pred * (1.0 - self.smooth) + 0.5 * self.smooth\n        \n        logits = 1 / (1 + np.exp(-y_pred))\n        aux = (1-y_true)*np.log(1-logits+1e-15) + y_true*np.log(logits+1e-10)\n        return np.mean(-aux)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SmoothBCEwLogits(nn.Module):\n    def __init__(self, weight=None, reduction='mean', smoothing=0.0005):\n        super(SmoothBCEwLogits, self).__init__()\n        self.smoothing = smoothing\n        self.weight = weight\n        self.reduction = reduction\n \n    @staticmethod\n    def _smooth(targets:torch.Tensor, n_labels:int, smoothing=0.0005):\n        assert 0 <= smoothing < 1\n        with torch.no_grad():\n            targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n        return targets\n \n    def forward(self, inputs, targets):\n        targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1),\n            self.smoothing)\n        loss = F.binary_cross_entropy_with_logits(inputs, targets,self.weight)\n \n        if  self.reduction == 'sum':\n            loss = loss.sum()\n        elif  self.reduction == 'mean':\n            loss = loss.mean()\n \n        return loss\n\n\n\n\ndef validation_fn(model, val_dataloader, criterion=F.binary_cross_entropy_with_logits):\n    net = model['model']\n    total_val_loss = 0\n    outputs = []\n    with torch.no_grad():\n        for  idx, (X, y) in enumerate(val_dataloader):\n            X, y = X.to(PARAMS[\"DEVICE\"]), y.to(PARAMS[\"DEVICE\"])\n            preds = net(X)\n            total_val_loss += criterion(preds[:, :206], y[:, :206]).item()\n            outputs.append(preds.sigmoid().detach().cpu().numpy())\n        \n        \n        outputs = np.concatenate(outputs)\n        \n        return outputs, total_val_loss / len(val_dataloader)\n    \ndef predict_fn(model, test_X, model_name=None):\n    model.eval()\n    test_dataset = MoADataset(test_X)\n    test_loader = DataLoader(test_dataset, batch_size=PARAMS[\"BATCH_SIZE\"], shuffle=False)\n    outputs = []\n    if model_name != 'TabNet':\n        with torch.no_grad():\n            for idx, X in enumerate(test_loader):\n                X = X.to(PARAMS[\"DEVICE\"])\n                preds = model(X)\n                outputs.append(preds.sigmoid().detach().cpu().numpy())\n\n            return np.concatenate(outputs)\n    else:\n        preds = model['model'].predict(test_X)\n        preds = 1/ (1 + np.exp(-model.predict(X_val)))\n        \n        return preds\n   \n    \ndef train_fn(model, optimizer, loss, train_loader, val_loader, scheduler, fold):\n    \n    net, name = model['model'].to(PARAMS[\"DEVICE\"]), model['name']\n    no_improvement_steps = 0\n    min_loss_val = 1\n    for epoch in range(PARAMS[\"EPOCHS\"]):\n        if no_improvement_steps == PARAMS[\"PATIENCE\"]:\n            print(\"Early stopping!\")\n            break\n            \n        total_loss_train = 0\n\n        for idx, (X, y) in enumerate(train_loader):\n            optimizer.zero_grad()\n            X, y = X.to(PARAMS[\"DEVICE\"]), y.to(PARAMS[\"DEVICE\"])\n            preds = net(X)\n\n            loss_val = loss(preds, y)\n            loss_val.backward()\n            optimizer.step()\n            scheduler.step()\n            total_loss_train += loss_val.item()\n\n        total_loss_train /= len(train_loader)\n        outputs, total_loss_val = validation_fn(model, val_loader)\n        if total_loss_val < min_loss_val:\n            min_loss_val = total_loss_val\n            torch.save(net.state_dict(), \"{}_{}.pth\".format(name, fold))\n            no_improvement_steps = 0\n        else:\n            no_improvement_steps += 1\n            \n            \n        print(\"Fold: %d Epoch: %d, train loss:%.6f | validation loss: %.6f\"%(fold, epoch, total_loss_train, total_loss_val))\n    model['model'].load_state_dict(torch.load(\"{}_{}.pth\".format(name, fold)))\n    return model['model'], outputs \n\n#------------------------------------------------------\ndef return_model(model_name, input_size, target_size, hidden_size):\n    print(model_name)\n    if model_name == 'ResNet':\n        return {\"name\":model_name, \n                \"model\":ResidualNet(input_size, target_size, 512)}\n    \n    elif model_name == 'ModelMLP':\n        return {\"name\": model_name,\n                \"model\": ModelMLP(input_size, target_size, hidden_size)\n               }\n    elif model_name == 'Model':\n        return {'name': model_name,\n                'model': Model(input_size, target_size, hidden_size)}\n    \n    elif model_name == 'simple':\n        return {\"name\":'simple',\n                'model': SimpleNet(input_size, target_size, hidden_size)}\n    else:\n        raise RuntimeError(\"Such network  doesn't exists\")\n\n#--------------------------------------------------------------------------------\n\n\ndef train(model_names, train_X, train_y, groups, n_seeds, transfer_learning=None):\n    print(\"Train shape:\", train_X.shape, \" train_y shape:\", train_y.shape)\n    models_predictions = []\n    trained_models = []\n    \n    for model_name in model_names:\n        val = np.random.randint(8, 30)\n        n_hidden = np.random.randint(512, 1524)\n        group_kfold = MultilabelStratifiedKFold(n_splits=PARAMS[\"NUM_FOLDS\"], shuffle=True)\n        preds = np.zeros((train_y.shape[0], train_y.shape[1]), dtype=float)\n        loss = SmoothBCEwLogits()\n        folds_models = []\n        \n        for idx, (train_index, test_index) in enumerate(group_kfold.split(train_X, train_y)):\n            \n            X_train, y_train = train_X[train_index], train_y[train_index]\n            X_val, y_val = train_X[test_index], train_y[test_index]\n            \n            if model_name != \"TabNet\":\n                if transfer_learning is not None:\n                    model = return_model(model_name, transfer_learning['in_size'], transfer_learning['out_size'])\n                    model[\"model\"].load_state_dict(torch.load(\"{}_{}.pth\".format(model[\"name\"], idx)))\n                    model[\"model\"].get_freeze(train_y.shape[-1], True)\n\n                else:\n                    model = return_model(model_name, X_train.shape[-1], y_train.shape[-1], n_hidden)\n                    \n                print(\"Train - Test:\", len(train_index), len(test_index))\n                train_dataset = MoADataset(X_train, y_train)\n                val_dataset = MoADataset(X_val, y_val)\n\n                train_loader = DataLoader(train_dataset, batch_size=PARAMS[\"BATCH_SIZE\"], shuffle=True)\n                val_loader = DataLoader(val_dataset, batch_size=PARAMS[\"BATCH_SIZE\"], shuffle=False)\n\n                optimizer = Adam(model[\"model\"].parameters(), lr=PARAMS[\"LEARNING_RATE\"], weight_decay=PARAMS[\"WEIGHT_DECAY\"])\n                scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, \n                                                          pct_start=0.1, div_factor=1e3, \n                                                          max_lr=1e-2, epochs=PARAMS[\"EPOCHS\"], \n                                                          steps_per_epoch=len(train_loader))\n\n                model, outputs = train_fn(model, optimizer, loss, train_loader, val_loader, scheduler, idx)\n\n                preds[test_index] = outputs\n                \n            else:\n\n                \n                tabnet_params[\"n_a\"] = val\n                tabnet_params['n_d'] = val\n                model = TabNetRegressor(**tabnet_params)\n                \n                model.fit(X_train=X_train,\n                          y_train=y_train[:, :206],\n                          eval_set=[(X_val, y_val[:, :206])],\n                          eval_name = [\"validation loss\"],\n                          eval_metric = [\"logits_ll\"],\n                          max_epochs=MAX_EPOCH,\n                          patience=PARAMS['PATIENCE'], batch_size=PARAMS[\"BATCH_SIZE\"],\n                          virtual_batch_size=128,\n                          num_workers=1, drop_last=False,\n                          loss_fn=SmoothBCEwLogits())\n                \n                preds[test_index] = 1/ (1 + np.exp(-model.predict(X_val)))\n                \n            folds_models.append(model)\n            \n        trained_models.append({'name': model_name, 'fold_models':folds_models})                   \n        models_predictions.append(preds)\n        \n    return trained_models, models_predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"preds dimensions:\",  train_targets_scored.shape,train_targets_nonscored.shape)\naux_train_y = train_targets_nonscored.iloc[:, 1:].to_numpy()\nmerged_train = train_targets_scored.merge(train_targets_nonscored, on='sig_id').iloc[:, 1:].to_numpy()\n\ntrain_X = train_features.iloc[:, 1:-1].to_numpy()\ntrain_y = train_targets_scored.iloc[:, 1:].to_numpy()\ntest_X = test_features.iloc[:, 1:].to_numpy()\ngroups = train_features['drug_id']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X.shape, train_y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_size, target_size = train_X.shape[-1], train_y.shape[-1]\n\nMLP = ModelMLP(input_size, target_size, 1024)\nResNet = ResidualNet(input_size, target_size, 512)\n#TabNet = TabNetMultiTaskClassifier()\n\nmodel_names = [ 'simple','TabNet', \"Model\", \"TabNet\", 'simple', 'Model', 'TabNet', 'simple', \"Model\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_X.shape, aux_train_y.shape)\nprint(aux_train_y.shape)\n#models, predictions = train(model_names, train_X, aux_train_y, groups, 30, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transfer_learning = {'in_size':train_X.shape[-1],\n                     'out_size': aux_train_y.shape[-1]}\n\nmodels, predictions = train(model_names, train_X, train_y, groups, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#######    Try to Stack ########\ndef make_folds_predictions(models, test_X):\n    all_predictions = []\n    for model in models:\n        name = model['name']\n        folds_models = model['fold_models']\n        predictions = []\n        for fold_model in folds_models:\n            predictions.append(predict_fn(fold_model, test_X, name))\n        all_predictions.append(sum(predictions) / len(predictions))\n        \n    return all_predictions\n\n\ndef stack_predict(meta_models, weak_models, test_X, meta_with_source=False):\n    \n    weak_preds = []\n    weak_preds = make_folds_predictions(weak_models, test_X)\n    \n    if meta_with_source:\n        stacked_input = np.concatenate(test_X + weak_preds, axis=-1)\n    else:\n        stacked_input = np.concatenate(weak_preds, axis=-1)\n    \n    meta_predictions = make_folds_predictions(meta_models, stacked_input)\n    \n    final_predictions = sum(meta_predictions) / len(meta_predictions)\n    \n    return final_predictions\n\ndef blend_stack_models(all_models, test_X):\n    predictions = []\n    for models in all_models:\n        predictions.append(stack_predict(models['meta_models'],\n                                         models['weak_models'],test_X))\n        \n    return sum(predictions) / len(predictions)\n\n\ndef train_stack_models(weak_learners, meta_learners, train_X, train_y, meta_params, weak_params):\n        control_fold = KFold(n_splits=3, shuffle=True, random_state=0)\n        predictions = np.zeros(train_y.shape)\n        all_models = []\n        for fold_num, (train_index_ctl, test_index_ctl) in enumerate(control_fold.split(train_X, train_y)):\n            weak_folds = MultilabelStratifiedKFold(n_splits=3, shuffle=True, random_state=1)\n            train_X_ctl, train_y_ctl = train_X[train_index_ctl], train_y[train_index_ctl]\n            test_X_ctl, test_y_ctl = train_X[test_index_ctl], train_y[test_index_ctl]\n            weak_meta_models = []\n            for train_index, test_index in weak_folds.split(train_X_ctl, train_y_ctl):\n                weak_train_X, weak_train_y = train_X_ctl[train_index], train_y_ctl[train_index]\n                meta_train_X, meta_train_y = train_X_ctl[test_index], train_y_ctl[test_index]\n\n                PARAMS['NUM_FOLDS'] = 3\n                PARAMS['EPOCHS'] = 30\n                print(\"-------------TRAIN WEAK MODELS-------------\")\n                weak_models, _ = train(weak_learners, weak_train_X, weak_train_y, None, 1)\n                weak_predictions = make_folds_predictions(weak_models, meta_train_X)\n                #weak_predictions.append(meta_train_X)\n                weak_predictions = np.concatenate(weak_predictions, axis=-1)\n\n                print(\"------------TRAIN META MODELS--------------\")\n                PARAMS['EPOCHS'] = 100\n                meta_models, _ = train(meta_learners, weak_predictions, meta_train_y, None, 1)\n                weak_meta_models.append({ 'weak_models': weak_models,\n                                            'meta_models': meta_models})\n                \n            all_models.append(weak_meta_models)\n            preds = blend_stack_models(weak_meta_models, test_X_ctl)\n            print(\"Preds shape\", preds.shape, predictions[test_index_ctl].shape)\n            predictions[test_index_ctl] = preds\n            \n        return [predictions], all_models\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predictions, all_models = train_stack_models(['Model'], ['simple'], train_X, train_y, None, None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(models)\n\n#simple_prediction = sum([pred[:, :206] for  pred in predictions]) / len(predictions)\n\ndef compute_score(y_pred, y_true):\n    assert y_pred.shape == y_true.shape\n    score = 0\n    scores = []\n    for i in range(PARAMS[\"TARGETS_OUTPUT\"]):\n        \n        score_ = log_loss(y_true[:, i], y_pred[:, i])\n        #print(\"target {}:{}\".format(i, score_))\n        score += score_\n        scores.append(score_)\n        \n    return score / PARAMS[\"TARGETS_OUTPUT\"], scores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_best(scores):\n    num_targets = len(scores[0])\n    target_model = {}\n    for i in range(num_targets):\n        neurals_target_scores = list([scores[j][i] for j in range(len(scores))])\n        #print(neurals_target_scores)\n        min_score = min(neurals_target_scores)\n        index = neurals_target_scores.index(min_score)\n        target_model[i] = index\n    return target_model\n\ndef create_final_prediction(models_predictions, target_model):\n    final_prediction = np.zeros(models_predictions[0].shape)\n    \n    for i in range(final_prediction.shape[-1]):\n        final_prediction[:, i] = models_predictions[target_model[i]][:, i]\n        \n    return final_prediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(len(predictions))\nensemble_prediction = sum([pred[:, :206] for  pred in predictions]) / len(predictions)\ntotal_predictions = predictions + [ensemble_prediction]\nprint(len(total_predictions), len(predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = [compute_score(preds, train_y)[0] for preds in total_predictions]\nscores = [compute_score(preds, train_y)[-1] for preds in total_predictions]\nprint(len(scores))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_model = find_best(scores)\nfinal_prediction = create_final_prediction(total_predictions, target_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(simple_prediction.shape, aux_train_y.shape)\ncompute_score(final_prediction, train_y)[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(models)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def final_preds(all_models, test_X, weights=None):\n    if weights is None:\n        weights = [1/len(model_names) \n                   for  i in range(len(model_names))]\n\n    models_preds = []\n    for models in all_models:\n        model_name = models['name']\n        fold_preds = []\n        for fold_model in models['fold_models']:\n            if model_name == 'TabNet':\n                preds = fold_model.predict(test_X)\n                preds = 1/(1 + np.exp(-preds))\n            else:\n                preds = predict_fn(fold_model, test_X)\n                \n            fold_preds.append(preds[:, :206])\n        print(len(fold_preds))\n        models_preds.append(sum(fold_preds)/len(fold_preds))\n    return models_preds\n    #return sum([w*p for w, p in zip(weights, models_preds)])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test_X.shape, test_features.shape)\nprint(train_X.shape)\ntest_preds = final_preds(models, test_X)\nensemble_preds = sum(test_preds) / len(test_preds)\ntotal_test_preds = test_preds + [ensemble_preds]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds = create_final_prediction(total_test_preds, target_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test_preds.shape)\npredictions = pd.concat([test_features['sig_id'],\n                         pd.DataFrame(test_preds, columns=train_targets_scored.columns[1:])], \n                        axis=1)\n\n#predictions = predictions.merge(test_dropped_rows['sig_id'], how='outer', on='sig_id').fillna(0)\nprint(predictions.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"####### bosting ensemle ########","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nimport lightgbm as lgb\nfrom catboost import CatBoostRegressor\n\nfrom hyperopt import Trials, STATUS_OK, tpe, hp, fmin","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ObjectiveFunction():\n    def __init__(self, clf, X, y, cv=5, scoring=None):\n        self.X = X\n        self.y = y\n        self.cv = cv\n        self.scoring = scoring\n        self.clf = clf\n        \n        \n    def change_model(self, clf):\n        self.clf = clf\n    \n        return self\n    \n    def __call__(self, space):\n        clf  = self.clf(**space)\n        scores = cross_val_score(clf, self.X, self.y, cv=self.cv, scoring=self.scoring)\n        return  sum(scores) / len(scores)\n\ndef train_classifiers(clf, X_train, y_train, space, clf_params):\n    \n    predictions = []\n    predictors = []\n    X_train,X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, shuffle=True)\n    num_targets = y_train.shape[-1]\n    for target in range(num_targets):\n        print(\"target :{}\".format(target))\n        fit_labels = y_train[:, target]\n\n        predictor = clf(**clf_params)\n        predictor.fit(X_train, y=fit_labels, eval_set = (X_val, y_val[:, target]))\n        predictors.append(predictor)\n\n        preds = predictor.predict(X_val)\n        loss =  LoglossMetric().evaluate([preds], y_val[:, target])[0] / len(preds)\n        print(\"loss:\", loss)\n        predictions.append(loss)\n    return predictors, predictions\n        \n\n            \n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"space_gbm = {\n\n    'max_depth' : hp.choice('max_depth', range(5, 30, 1)),\n    'learning_rate' : hp.uniform('learning_rate', 0.01, 1),\n    'n_estimators' : hp.choice('n_estimators', range(20, 200, 1)),\n    'gamma' : hp.uniform('gamma', 0, 1),\n    'min_child_weight' : hp.uniform('min_child_weight', 1, 10),\n    'subsample' : hp.uniform('subsample', 0.1, 1),\n    'colsample_bytree' : hp.quniform('colsample_bytree', 0.1, 1.0, 0.01),\n    'reg_alpha' : hp.uniform('aplha', 0, 1),\n    'reg_lambda' : hp.uniform('lambda', 0, 1)}\n\nspace_xgb = {\n    'max_depth' : hp.choice('max_depth', range(2, 30, 1)),\n    'learning_rate' : hp.uniform('learning_rate', 0.01, 1),\n    'n_estimators' : hp.choice('n_estimators', range(20, 200, 1)),\n    'gamma' : hp.uniform('gamma', 0, 1),\n    'min_child_weight' : hp.uniform('min_child_weight', 0, 10),\n    'subsample' : hp.uniform('subsample', 0.01, 1),\n    'lambda': hp.uniform('lambda', 0.00, 10) }\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class LoglossObjective(object):\n    def calc_ders_range(self, approxes, targets, weights=None):\n        #print(\"APP:\", approxes, \"targets:\", targets)\n        assert len(approxes) == len(targets)\n        if weights is not None:\n            assert len(weights) == len(approxes)\n        \n        result = []\n        for index in range(len(targets)):\n            e = np.exp(approxes[index])\n            p = e / (1 + e)\n            der1 = targets[index] - p\n            der2 = -p * (1 - p)\n\n            if weights is not None:\n                der1 *= weights[index]\n                der2 *= weights[index]\n\n            result.append((der1, der2))\n        return result\n    \nclass LoglossMetric(object):\n    def get_final_error(self, error, weight):\n        return error / (weight + 1e-38)\n\n    def is_max_optimal(self):\n        return False\n\n    def evaluate(self, approxes, target, weight=None):\n        assert len(approxes) == 1\n        assert len(target) == len(approxes[0])\n\n        approx = approxes[0]\n\n        error_sum = 0.0\n        weight_sum = 0.0\n        \n        for i in range(len(approx)):\n            e = np.exp(approx[i])\n            p = e / (1 + e)\n            w = 1.0 if weight is None else weight[i]\n            weight_sum += w\n            error_sum += -w * (target[i] * np.log(p) + (1 - target[i]) * np.log(1 - p))\n\n        return error_sum, weight_sum","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#clf =  xgb.XGBClassifier\n#clf = lgb.LGBMRegressor\nclf = CatBoostRegressor\nclf_params = {'iterations':5, 'learning_rate':2, 'loss_function': LoglossObjective(), 'eval_metric':LoglossMetric()}\n#predictors, predictions_cat = train_classifiers(clf, train_X, train_y, space_xgb, clf_params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#predictions_cat = np.asarray(predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(predictions_cat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_predictors(predictors, test_X):\n\n    for target_predictor in predictor:\n        preds = target_predictor.predict(test_X)\n        predictions.append(preds)\n       \n    \n    return np.asarray(predictions)\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef compute_score(y_pred, y_true):\n    assert y_pred.shape == y_true.shape\n    score = 0\n    scores = []\n    for i in range(PARAMS[\"TARGETS_OUTPUT\"]):\n        \n        score_ = log_loss(y_true[:, i], y_pred[:, i])\n        print(\"target {}:{}\".format(i, score_))\n        score += score_\n        scores.append(score_)\n    return score / PARAMS[\"TARGETS_OUTPUT\"], scores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def choose_model(neural_nets_scores, catboost_predictors_scores):\n        \n    target_model = {}\n    for  target in range(206):\n        neural_scores = [neural_nets_scores[i][target] for i in range(len(neural_nets_scores))]\n        neural_min = min(neural_scores)\n        argmin_neural = neural_scors.index(neural_min)\n        if neural_min < cat_boost_predictors[target]:\n            target_model[target] = argmin_neural\n        else:\n            target_model[target] = -1\n    \n    return target_model\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}