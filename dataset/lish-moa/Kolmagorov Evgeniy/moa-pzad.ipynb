{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport sklearn\nimport seaborn as sns\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.linear_model import LinearRegression, Perceptron, RidgeCV, Lasso\nfrom sklearn.decomposition import PCA\n\nfrom sklearn.metrics import log_loss\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.feature_selection import VarianceThreshold\n#from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n\nimport torch\nfrom torch import optim\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X = pd.read_csv(\"/kaggle/input/lish-moa/train_features.csv\")\ntrain_y = pd.read_csv(\"/kaggle/input/lish-moa/train_targets_scored.csv\")\ntrain_y_ns = pd.read_csv(\"/kaggle/input/lish-moa/train_targets_nonscored.csv\")\n#train_X, val_X, train_y, val_y = train_test_split(train_X, train_y, test_size=0.3)\n\ntest_X = pd.read_csv(\"/kaggle/input/lish-moa/test_features.csv\")\nprint(test_X.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ctl_vehicle_idx = train_X[train_X['cp_type']=='ctl_vehicle'].index\ntest_ctl_vehicle_idx = test_X[test_X['cp_type'] == 'ctl_vehicle'].index\n\ntrain_X = train_X.drop(train_ctl_vehicle_idx).reset_index(drop=True)\ntrain_y = train_y.drop(train_ctl_vehicle_idx).reset_index(drop=True)\ntest_X = test_X.drop(test_ctl_vehicle_idx).reset_index(drop=True)\n\ntrain_X, test_X = train_X.drop('cp_type', axis=1), test_X.drop('cp_type', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_columns, y_columns = train_X.columns, train_y.columns\nX_columns\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_columns', 200)\ntrain_y.head(2)\nprint(train_y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train features shape:\", train_X.shape, \"Train Scored Targets:\", train_y.shape)\n#print(\"Validation features shape:{}\", val_X.shape, \"Validation Scored Targers:\", val_y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1,2, figsize=(14,4))\n#sns.countplot(train_X['cp_type'], ax=axes[0])\nsns.countplot(train_X['cp_dose'], ax=axes[0])\nsns.countplot(train_X['cp_time'], ax=axes[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"g_features = [col for col in train_X.columns if col.startswith('g-')]\nc_features = [col for col in train_X.columns if col.startswith('c-')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of gene features:{}, number of cell features:{}\".format(len(g_features), len(c_features)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_c_features = len(c_features)\nstep = n_c_features // 9\n\nfig, axes = plt.subplots(nrows=3,ncols=3, figsize=(10, 10))\n\nfor  i in range(0, 9, 1):\n    row, col = i // 3, i % 3\n    features = train_X.loc[:, 'c-{}'.format(i * step)]\n    sns.kdeplot(features, ax=axes[row, col])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_g_features = len(g_features)\nstep = n_g_features // 9\n\nfig, axes = plt.subplots(nrows=3,ncols=3, figsize=(10, 10))\n\nfor  i in range(0, 9, 1):\n    row, col = i // 3, i % 3\n    features = train_X.loc[:, 'g-{}'.format(i * step)]\n    sns.kdeplot(features, ax=axes[row, col])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_std(train_X, columns):\n    df = train_X[columns]\n    stds = df.std(axis=0)\n    sns.distplot(stds)\n    plt,show()\n\n\ndef plot_correlation(df, columns):\n\n    corr = df[columns].corr()\n    print(corr)\n    mask = np.triu(np.ones_like(corr, dtype=bool))\n    f, ax = plt.subplots(figsize=(11, 9))\n    sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n    plt.show()\n    \n\ndef number_of_activations(train_y):\n    \n    df = train_y.drop(['sig_id'], axis=1).astype(bool).sum(axis=1).reset_index()\n\n    df.columns = ['row', 'count']\n    df = data.groupby(['count'])['row'].count().reset_index()\n\n    fig = sns.barplot(data, y=data['row'],  x=\"count\", \n        title='Number of activations in targets for every sample')\n\n    fig.show()\n\ndef find_top_correlation(train_x, train_y, x_columns, target):\n    \n    target_features = train_y[target]\n    correlations = []\n    for x_column in x_columns:\n        features = train_x[x_column]\n        corr_coef = np.corrcoef(features, target_features)\n        correlations.append((x_column, corr_coef))\n    \n    top5 = sorted(target_features, key=lambda x:x[1], inverse=True)\n    return top5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def drop_cp(df):\n    return df[df['cp_type'] == 'trt_cp'].reset_index(drop=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ind_tr = train_X[train_X['cp_type'] == 'ctl_vehicle'].index\n#ind_te = test_X[test_X['cp_type'] == 'ctl_vehicle'].index\n\ntest_ids = test_X.sig_id","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(val_X)\n#train_y.iloc[list(ind_tr)].sum(axis=1)#.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#most_popular_occurancies\n#print(train_y.iloc[0])\nscored = train_y.sum(axis=0)[1:].sort_values(ascending=False) #[1:] so as sort without id colums\n#print(scored)\n#print(scored)\nscored[:20].plot(kind='barh', fontsize=14, figsize=(5,20))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_X.shape)\nfor  i in range(0, len(g_features), len(g_features)//10):\n    sns.kdeplot(train_X.loc[:, g_features[i]])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c_features = [col for col in train_X.columns if col.startswith('c-')]\nprint(train_X.shape)\nfor  i in range(0, len(c_features), len(c_features)//10):\n    sns.kdeplot(train_X.loc[:, c_features[i]])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def normal_split(train_X, train_y):\n    X_n_columns = len(train_X.columns)\n    y_n_columns = len(train_y.columns)\n    #print(train_X.shape, train_y.shape)\n    \n    train_X_y = pd.merge(train_X, train_y ,on='sig_id')\n    #print(\"After merge:\", train_X_y.shape)\n    #train_X_y = train_X_y.drop(['sig_id', 'cp_type'], axis=1)\n    \n    #print(\"After drop:\", train_X_y.shape)\n    \n    train_X = train_X_y.iloc[:, :X_n_columns]\n    train_y = train_X_y.iloc[:, X_n_columns:]\n    return train_X, train_y\n\ntrain_X, train_y = normal_split(train_X, train_y)\n#val_X, val_y = normal_split(val_X, val_y)\ntrain_y.shape\n#train_X.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#-----------------------------Preprocession block-------------------------------\ndef cat_dfs(dataFrames):\n    sizes = [len(df) for df in dataFrames]\n    \n    concatenated_df = pd.concat(dataFrames, axis=0).reset_index(drop=True)\n    \n    return concatenated_df, sizes\n\ndef drop_high_correlated(dataFrames, threshold=0.9):\n    df, sizes = cat_dfs(dataFrames)\n    cols = df.columns\n    above_90 = []\n\n    for i in range(0, len(cols)):\n        for j in range(i+1, len(cols)):\n            #print(i,j)\n            if abs(df[cols[i]].corr(df[cols[j]])) > threshold:\n                above_90.append(cols[i])\n                \n    print(\"number high correlated:{}\".format(len(above_90))) \n    \n    df = df.drop(above_90, axis=1)\n    return __split_data_frame(df, sizes)\n\n\ndef __split_data_frame(df, sizes):\n    \n    last_size = 0\n    splitted_dfs = []\n    \n    for size in sizes:\n        tmp_df = df[last_size:size + last_size]\n        splitted_dfs.append(tmp_df)\n        last_size = size + last_size\n    \n    return splitted_dfs\n\n\ndef map_categorical(dataFrames):\n    concatenated_df, sizes = cat_dfs(dataFrames)\n    #concatenated_df['cp_type'] = concatenated_df['cp_type'].map({'trt_cp':0, 'ctl_vehicle':1})\n    concatenated_df['cp_time'] = concatenated_df['cp_time'].map({24:0, 48:1, 72:2})\n    concatenated_df['cp_dose'] = concatenated_df['cp_dose'].map({'D1':0, 'D2':1})\n    \n    return __split_data_frame(concatenated_df, sizes)\n    \n\ndef filter_variance(dataFrames, threshold=0.5):\n    concatenated_df, sizes = cat_dfs(dataFrames)\n    print(sizes)\n    VT = VarianceThreshold(threshold)\n    \n    \n    variances = VT.fit(concatenated_df).variances_\n    \n    columns_names = concatenated_df.columns[variances < threshold]\n    print(columns_names)\n    concatenated_df = concatenated_df.drop(columns_names, axis=1)\n    \n    return __split_data_frame(concatenated_df, sizes)\n\n\n    \ndef add_PCA(dataFrames, g_n_components, c_n_components):\n    sizes = [len(df) for df in dataFrames]\n    \n    concatenated_df, sizes = cat_dfs(dataFrames)\n    \n    g_features = [col for col in concatenated_df.columns if col.startswith('g-')]\n    c_features = [col for col in concatenated_df.columns if col.startswith('c-')]\n    \n\n    pca_transformer_g = PCA(n_components=g_n_components)\n    pca_transformer_c = PCA(n_components=c_n_components)\n\n    pca_features_g = pd.DataFrame(pca_transformer_g.fit_transform(concatenated_df[g_features]),\n                                  columns=[\"PCA_g_{}\".format(i) for i in range(g_n_components)])\n    pca_features_c = pd.DataFrame(pca_transformer_c.fit_transform(concatenated_df[c_features]),\n                                 columns=[\"PCA_c_{}\".format(i) for i in range(c_n_components)])\n        \n    \n    \n\n    new_df = pd.concat([concatenated_df[g_features], pca_features_g,\n                        concatenated_df[c_features], pca_features_c], axis=1)\n\n        \n    return __split_data_frame(new_df, sizes)\n\n\ndef add_features(dataFrames):\n    \n    df, sizes = cat_dfs(dataFrames)\n    g_features = [col for col in df.columns if col.startswith('g-')]\n    c_features = [col for col in df.columns if col.startswith('c-')]\n    \n    df['g_mean'] = df[g_features].mean(axis=1)\n    df['g_std'] = df[g_features].std(axis=1)\n    df['g_sum'] = df[g_features].sum(axis=1)\n    \n    df['c_mean'] = df[c_features].mean(axis=1)\n    df['c_std'] = df[c_features].std(axis=1)\n    df['c_sum'] = df[c_features].sum(axis=1)\n    df = pd.concat([df, g_mean, g_std, g_sum, c_mean, c_std, c_sum], axis=1)\n    \n    return __split_data_frame(df, sizes)\n\n\ndef add_new(dataFrames):\n    df, sizes = cat_dfs(dataFrames)\n    \n    #df['time_dose'] = df['cp_time'].astype(str)+df['cp_dose']\n    features_g = [col for col in df.columns if col.startswith('g-')]\n    features_c = [col for col in df.columns if col.startswith('c-')]\n    \n    df['g_sum'] = df[features_g].sum(axis = 1)\n    df['g_mean'] = df[features_g].mean(axis = 1)\n    df['g_std'] = df[features_g].std(axis = 1)\n    df['g_kurt'] = df[features_g].kurtosis(axis = 1)\n    df['g_skew'] = df[features_g].skew(axis = 1)\n    df['c_sum'] = df[features_c].sum(axis = 1)\n    df['c_mean'] = df[features_c].mean(axis = 1)\n    df['c_std'] = df[features_c].std(axis = 1)\n    df['c_kurt'] = df[features_c].kurtosis(axis = 1)\n    df['c_skew'] = df[features_c].skew(axis = 1)\n    df['gc_sum'] = df[features_g + features_c].sum(axis = 1)\n    df['gc_mean'] = df[features_g + features_c].mean(axis = 1)\n    df['gc_std'] = df[features_g + features_c].std(axis = 1)\n    df['gc_kurt'] = df[features_g + features_c].kurtosis(axis = 1)\n    df['gc_skew'] = df[features_g + features_c].skew(axis = 1)\n    \n    \n    for feature in features_c:\n        df[f'{feature}_squared'] = df[feature] ** 2\n    \n    return __split_data_frame(df, sizes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(dataFrames, cat_features, con_features):\n    \n    new_dfs = []\n    dataFrames_cat = [ df[cat_features] for df in dataFrames]\n    dataFrames_con = [ df[con_features] for df in dataFrames]\n    \n    dataFrames_con = filter_variance(dataFrames_con)\n    print(\"Variance filtered\")\n    #dataFrames_con = drop_high_correlated(dataFrames_con)\n    print(\"High correlated features dropped\")\n    dataFrames_con = add_PCA(dataFrames_con, 30, 10)\n    print(\"PCA added\")\n    dataFrames_con = add_new(dataFrames_con)\n    print(\"Additional featires added\")\n    dataFrames_cat = map_categorical(dataFrames_cat)\n    print(\"Categorical features transformed\")\n    for df_cat, df_con in zip(dataFrames_cat, dataFrames_con):\n        new_dfs.append(pd.concat((df_cat, df_con), axis=1))\n    \n    return new_dfs\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ntrain_X = train_X.drop('sig_id', axis=1, errors='ignore')\ntest_X = test_X.drop('sig_id', axis=1, errors='ignore')\n\ncat_features = ['cp_time', 'cp_dose']\ncon_features = [colname for colname in train_X.columns \n                if colname not in cat_features]\n\n\ntrain_X, test_X = preprocess([train_X, test_X], cat_features, con_features)\n\nprint(\"train_X shape:{}, test_X:{}\".format(train_X.shape, test_X.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nfolds_train_X = train_X.copy()\nfolds_train_y = train_y.copy()\n\nFold = KFold(n_splits=6, shuffle=True, random_state=42)\nfor n, (train_index, val_index) in enumerate(Fold.split(folds_train_X, folds_train_y)):\n    folds_train_X.loc[val_index, 'fold'] = int(n)\n    folds_train_y.loc[val_index, 'fold'] = int(n)\n#folds['fold'] = folds['fold'].astype(int)\nfolds_train_X['fold'] = folds_train_X['fold'].astype(int)\nfolds_train_y['fold'] = folds_train_y['fold'].astype(int)\nprint(folds_train_X.shape, folds_train_y.shape)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nclass MoADataset(Dataset):\n    def __init__(self, X, y=None):\n        if y is not None:\n            assert X.shape[0] == y.shape[0]\n        \n        self.X = torch.tensor(X.to_numpy(), dtype=torch.float)\n        self.y = None\n        if y is not None:\n            self.y = torch.tensor(y.to_numpy(), dtype=torch.float)\n        \n    def __getitem__(self, idx):\n\n        tensor_X = self.X[idx]\n        if self.y is not None:\n            tensor_y = self.y[idx]\n            return tensor_X, tensor_y\n        else:\n            return tensor_X\n    \n    def __len__(self):\n        return len(self.X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = MoADataset(train_X, train_y)\ntrain_dataloader = DataLoader(dataset, batch_size=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MoANet(nn.Module):\n    \n    def __init__(self, input_size, output_size):\n        super().__init__()\n        \n        self.input_size = input_size\n        self.output_size = output_size\n        self.hidden_size = 256\n\n        self.wn = nn.utils.weight_norm\n        self.mlp = nn.Sequential(\n                          self.wn(nn.Linear(input_size, self.hidden_size)),\n                            \n                          #nn.BatchNorm1d(self.hidden_size),\n                          nn.Dropout(0.3),\n                          nn.ELU(),\n                          self.wn(nn.Linear(self.hidden_size, self.hidden_size)),\n                          #nn.BatchNorm1d(self.hidden_size),\n                          nn.Dropout(0.3),\n                          nn.ELU(),\n                          self.wn(nn.Linear(self.hidden_size, self.output_size)))\n        \n        \n    def forward(self, x):\n        x = self.mlp(x)\n        return x\n\nnet = MoANet(train_X.shape[1], train_y.shape[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self, num_features, num_targets, hidden_size):\n        super(Model, self).__init__()\n        self.batch_norm1 = nn.BatchNorm1d(num_features)\n        self.dropout1 = nn.Dropout(0.2)\n        self.dense1 = nn.utils.weight_norm(nn.Linear(num_features, hidden_size))\n        \n        self.batch_norm2 = nn.BatchNorm1d(hidden_size)\n        self.dropout2 = nn.Dropout(0.2)\n        self.dense2 = nn.utils.weight_norm(nn.Linear(hidden_size, hidden_size))\n        \n        self.batch_norm3 = nn.BatchNorm1d(hidden_size)\n        self.dropout3 = nn.Dropout(0.2)\n        self.dense3 = nn.utils.weight_norm(nn.Linear(hidden_size, num_targets))\n    \n    def forward(self, x):\n        #x = self.batch_norm1(x)\n        #x = self.dropout1(x)\n        x = F.leaky_relu(self.dense1(x), 1e-3)\n        \n        x = self.batch_norm2(x)\n        x = self.dropout2(x)\n        x =F.leaky_relu(self.dense2(x), 1e-3)\n        \n        x = self.batch_norm3(x)\n        x = self.dropout3(x)\n        x = self.dense3(x)\n        \n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_X, test_X = process_data([train_X, test_X])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train, validate and test on train data and test data\ndef train_fn(model, optimizer, scheduler, loss_fn, dataloader, device):\n    model.train()\n    final_loss = 0\n    \n    for X, y in dataloader:\n        optimizer.zero_grad()\n        X, y = X.to(device), y.to(device)\n        #print(inputs.shape)\n        outputs = model(X)\n        loss = loss_fn(outputs, y)\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n        \n        final_loss += loss.item()\n        \n    final_loss /= len(dataloader)\n    \n    return final_loss\n\n\ndef valid_fn(model, loss_fn, dataloader, device):\n    model.eval()\n    final_loss = 0\n    valid_preds = []\n    \n    for X, y in dataloader:\n        X, y = X.to(device), y.to(device)\n        outputs = model(X)\n        loss = loss_fn(outputs, y)\n        \n        final_loss += loss.item()\n        valid_preds.append(outputs.sigmoid().detach().cpu().numpy())\n        \n    final_loss /= len(dataloader)\n    valid_preds = np.concatenate(valid_preds)\n    \n    return final_loss, valid_preds\n\ndef inference_fn(model, dataloader, device):\n    model.eval()\n    preds = []\n    \n    for X in dataloader:\n        X = X.to(device)\n\n        with torch.no_grad():\n            outputs = model(X)\n        \n        preds.append(outputs.sigmoid().detach().cpu().numpy())\n        \n    preds = np.concatenate(preds)\n    \n    return preds\n   \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\nEPOCHS = 26\nBATCH_SIZE = 256\nLEARNING_RATE = 6e-4\nWEIGHT_DECAY = 1e-5\nNFOLDS = 7\nEARLY_STOPPING_STEPS = 10\nEARLY_STOP = True\nHIDDEN_SIZE=2048","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def run_training(fold_number, train_X, train_y, test_X, train_indexes, val_indexes, seed):\n    #seed_everything(seed)\n    \n    x_train = train_X.iloc[train_indexes].reset_index(drop=True)\n    y_train = train_y.iloc[train_indexes].reset_index(drop=True)\n    \n    x_val = train_X.iloc[val_indexes].reset_index(drop=True)\n    y_val = train_y.iloc[val_indexes].reset_index(drop=True)\n    \n    train_dataset = MoADataset(x_train, y_train)\n    valid_dataset = MoADataset(x_val, y_val)\n    \n    trainloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n    validloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n    model = Model(\n        num_features=train_X.shape[-1],\n        num_targets=train_y.shape[-1],\n        hidden_size=HIDDEN_SIZE,\n    )\n    \n    model.to(DEVICE)\n    \n    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n    scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e1, \n                                              max_lr=1e-2, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n    \n    loss_fn = nn.BCEWithLogitsLoss()\n    \n    early_stopping_steps = EARLY_STOPPING_STEPS\n    early_step = 0\n    \n    oof = np.zeros((train_X.shape[0], train_y.shape[-1]))\n    best_loss = np.inf\n    \n    print(f\"FOLD: {fold_number}\")\n    \n    for epoch in range(EPOCHS):\n        \n        train_loss = train_fn(model, optimizer,scheduler, loss_fn, trainloader, DEVICE)\n        valid_loss, valid_preds = valid_fn(model, loss_fn, validloader, DEVICE)\n        print(f\"EPOCH: {epoch}, train_loss: {train_loss}, valid_loss: {valid_loss}\")\n        \n        if valid_loss < best_loss:\n            early_step =0\n            best_loss = valid_loss\n            oof[val_indexes] = valid_preds\n            torch.save(model.state_dict(), f\"FOLD{fold_number}_.pth\")\n        \n        elif(EARLY_STOP == True):\n            \n            early_step += 1\n            if (early_step >= early_stopping_steps):\n                break\n            \n    \n    #--------------------- PREDICTION---------------------\n    testdataset = MoADataset(test_X)\n    testloader = DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n    \n    model = Model(\n        num_features=train_X.shape[-1],\n        num_targets=train_y.shape[-1],\n        hidden_size=HIDDEN_SIZE,\n    )\n    \n    model.load_state_dict(torch.load(f\"FOLD{fold_number}_.pth\"))\n    model.to(DEVICE)\n    \n    predictions = np.zeros((len(test_X), train_y.shape[-1]))\n    predictions = inference_fn(model, testloader, DEVICE)\n    \n    return oof, predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def run_k_fold(NFOLDS, train_X, train_y, test_X, seed):\n    oof = np.zeros((train_y.shape))\n    predictions = np.zeros((test_X.shape[0], train_y.shape[-1]))\n    kf = KFold(n_splits=NFOLDS, shuffle=True, random_state=seed)\n    \n    for fold, (train_indexes, val_indexes)  in enumerate(kf.split(train_X)):\n        oof_, pred_ = run_training(fold, train_X, train_y, test_X, train_indexes, val_indexes, seed)\n        \n        predictions += pred_ / NFOLDS\n        oof += oof_ \n        \n    return oof, predictions","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"SEED = [1973, 1998]\noof = np.zeros((train_X.shape[0], train_y.shape[-1]))\npredictions = np.zeros((test_X.shape[0], train_y.shape[-1]))\n\nfor seed in SEED:\n    print(f\"SEED: {seed}\")\n    \n    oof_, predictions_ = run_k_fold(NFOLDS, train_X, train_y, test_X, seed)\n    oof += oof_ / len(SEED)\n    predictions += predictions_ / len(SEED)\n\n#train[target_cols] = oof\n#test[target_cols] = predictions\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_prediction_df= pd.DataFrame(data=oof, columns=train_y.columns)\ntest_prediction_df = pd.DataFrame(data=predictions, columns=train_y.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ctl_vehicle_idx\ntest_ctl_vehicle_idx\n\ntts = pd.read_csv(\"/kaggle/input/lish-moa/train_targets_scored.csv\")\ntrain = pd.read_csv(\"/kaggle/input/lish-moa/train_features.csv\")\ntstf = pd.read_csv(\"/kaggle/input/lish-moa/test_features.csv\")\nprint(tts.shape)\n#print(len(train_ctl_vehicle_idx))\ndropped_sig_id_train = pd.DataFrame(tts.iloc[:,0].drop(train_ctl_vehicle_idx, axis=0).reset_index(drop=True), columns=['sig_id']) \n#print(dropped_sig_id_train.shape, train_prediction_df.shape)\n\ntrain_prediction_df = pd.concat([dropped_sig_id_train, train_prediction_df], axis=1)\nvalid_results = tts.drop(columns=train_y.columns).merge(train_prediction_df, on='sig_id', how='left').fillna(0)\n\n\ny_true = tts[train_y.columns].values\ny_pred = valid_results[train_y.columns].values\n\n\nscore = 0\nfor i in range(y_true.shape[1]):\n    score_ = log_loss(y_true[:, i], y_pred[:, i])\n    score += score_ \nscore /= train_y.shape[1]\n    \nprint(\"CV log_loss: \", score)\n#print(*(zip(valid_results.sig_id, tts.sig_id)))\n#dropped_sig_id_test = tstf.iloc[test_ctl_vehicle_idx]['sig_id']\n#test_prediction_df = pd.concat([dropped_sig_id_test, test_prediction_df])\n#test_results = tstf.drop(columns=train.iloc[:, 1:].columns).merge(test_prediction_df, on='sig_id', how='left').fillna(0)\n\n#print(\"CV log_loss:{}\".format(log_loss(tts.iloc[:,1:], valid_results.iloc[:, 1:])))\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dropped_sig_id_test = pd.DataFrame(tstf.iloc[:,0].drop(test_ctl_vehicle_idx, axis=0).reset_index(drop=True), columns=['sig_id']) \n#print(dropped_sig_id_train.shape, train_prediction_df.shape)\n\ntest_prediction_df = pd.concat([dropped_sig_id_test, test_prediction_df], axis=1)\ntest_results = tstf.drop(columns=tstf.columns[1:]).merge(test_prediction_df, on='sig_id', how='left').fillna(0)\ntest_results.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_results.to_csv(\"submission.csv\", index=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#preds = predict(net, val_dataloader)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(val_X)\n#val_log_loss = evaluate(preds, val_y.to_numpy())\n#print(\"You get such quality of log_loss:{}\".format(val_log_loss))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#preds = predict(net, test_dataloader)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\npreds = pd.DataFrame(preds, columns=train_y.columns)\npreds['sig_id'] = test_ids\ncols = preds.columns.tolist()\ncols = cols[-1:] + cols[:-1]\npreds = preds[cols]\npreds.set_index(keys='sig_id', drop=False)\npreds.to_csv(\"submission.csv\", index=None)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#readed = pd.read_csv(\"submission.csv\")\n#readed.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#readed.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\n\ndef one_to_all_reg(reg_model, train_X, train_y):\n    models = {}\n    #print(train_y)\n    for idx, target_name in enumerate(train_y.columns):\n        print(\"Train #:{}. {}\".format(idx, target_name))\n        targets = train_y[target_name]\n        #print(targets)\n        reg_model.fit(train_X, targets)\n        models[target_name] = reg_model\n        \n    return models\n\ndef predict_ensemble(test_X, models, targets_names):\n    df_prediction = pd.DataFrame()\n    for target_name in targets_names:\n        df_prediction[target_name] = models[target_name].predict(test_X)\n        \n    return df_prediction\n\ndef create_equal_ordering(pred_df, true_df):\n    assert pred_df.shape == true_df.shape\n    \n    numpy_pred = np.zeros(pred_df.shape)\n    numpy_true = np.zeros(true_df.shape)\n    \n    for idx, target_name in enumerate(true_df.columns):\n        numpy_pred[:, idx] = pred_df[target_name].to_numpy()\n        numpy_true[:, idx] = true_df[target_name].to_numpy()\n        \n    return numpy_pred, numpy_true","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from  sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier as KNN\nfrom sklearn.svm import SVC\n'''\nparams = {'num_leaves': 490,\n          'min_child_weight': 0.03,\n          'feature_fraction': 0.55,\n          'bagging_fraction': 0.9,\n          'min_data_in_leaf': 150,\n          'objective': 'binary',\n          'max_depth': -1,\n          'learning_rate': 0.01,\n          \"boosting_type\": \"gbdt\",\n          \"bagging_seed\": 11,\n          \"metric\": 'binary_logloss',\n          \"verbosity\": 0,\n          'reg_alpha': 0.4,\n          'reg_lambda': 0.6,\n          'random_state': 47\n         }\n\nreg_model = lgb.LGBMClassifier(params)\n\nmodels = one_to_all_reg(reg_model, train_X, train_y)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#models","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#preds = predict_ensemble(val_X, models, val_y.columns)#\\\n#numpy_pred, numpy_true = create_equal_ordering(preds, val_y)\n#loss = evaluate(numpy_pred, numpy_true)\n#print(\"Your ensemble have log score:{}\".format(loss))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}