{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install iterative-stratification","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom pathlib import Path\nPath.ls = lambda x: list(x.iterdir())\n\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n\nimport torch\nfrom torch import nn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nclass Processor():\n    def __init__(self):\n        self.encoder_dict = {}\n\n    def process_df(self, df_, cols):\n        # Categorical Columns\n        df = df_.copy()\n        for col in cols:\n            ohe = pd.get_dummies(df[col])\n            ohe_cols = [f'{col}_{x}'for x in ohe.columns]\n            df[ohe_cols] = ohe\n            df.drop(col, axis=1,inplace=True)\n        \n        return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FOLDS = 5\nDEVICE= 'cuda'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = Path('/kaggle/input/lish-moa/')\npath.ls()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features = pd.read_csv(path/'train_features.csv')\ntrain_targets_scored = pd.read_csv(path/'train_targets_scored.csv')\ntrain_targets_nonscored = pd.read_csv(path/'train_targets_nonscored.csv')\ntest_features = pd.read_csv(path/'test_features.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_targets_scored['folds'] = -1\n\ncv = MultilabelStratifiedKFold(n_splits=5)\nfor i, (trn_, val_) in enumerate(cv.split(train_features, train_targets_scored.iloc[:,1:])):\n    train_targets_scored.loc[val_,'folds'] = i","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_proc = Processor()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feat_df = cat_proc.process_df(train_features, ['cp_type', 'cp_time', 'cp_dose'])\ntrain_df = pd.merge(feat_df, train_targets_scored, how='left', on='sig_id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feat_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Dataset:\n    def __init__(self,df,features, targets):\n        self.features = df.loc[:, features]\n        self.targets = df.loc[:, targets]\n        \n    def __len__(self):\n        return len(self.features)\n    \n    def __getitem__(self, idx):\n        data = self.features.iloc[idx]\n        target= self.targets.iloc[idx]\n        return {\n            'x': torch.tensor(data, dtype=torch.float),\n            'y': torch.tensor(target, dtype=torch.float)\n        }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feat_cols = feat_df.drop('sig_id',axis=1).columns\ntarget_cols = train_targets_scored.drop(['sig_id','folds'], axis=1).columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cont_cols = []\nfor c in train_df.columns:\n    if ('c-' in c) or ('g-' in c):\n        cont_cols.append(c)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds = Dataset(train_df, feat_cols, target_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self, f_in, f_out, dropout=0, hidden_size=256):\n        super().__init__()\n        self.model = nn.Sequential(\n            nn.Linear(f_in, hidden_size),\n            nn.BatchNorm1d(hidden_size),\n            nn.ReLU(),\n            nn.Dropout(p=dropout),\n            nn.Linear(hidden_size, hidden_size),\n            nn.BatchNorm1d(hidden_size),\n            nn.ReLU(),\n            nn.Dropout(p=dropout),\n            nn.Linear(hidden_size, hidden_size),\n            nn.BatchNorm1d(hidden_size),\n            nn.ReLU(),\n            nn.Dropout(p=dropout),\n            nn.Linear(hidden_size, hidden_size),\n            nn.BatchNorm1d(hidden_size),\n            nn.ReLU(),\n            nn.Dropout(p=dropout),\n            nn.Linear(hidden_size, f_out),\n            nn.BatchNorm1d(f_out),\n        )\n        \n    def forward(self, x):\n        return self.model(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm.notebook import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Engine:\n    def __init__(self, model, optimizer,scheduler, criterion, device):\n        self.model = model\n        self.optimizer = optimizer\n        self.criterion = criterion\n        self.scheduler = scheduler\n        self.device = device\n        \n    def step(self, batch):\n        x = batch['x'].to(self.device)\n        y = batch['y'].to(self.device)\n        outs = self.model(x)\n        loss = self.criterion(outs, y)\n        \n        return loss\n            \n    def train_loop(self, dataloader):\n        self.model.train()\n        final_loss = []\n        for batch in tqdm(dataloader, total=len(dataloader)):\n            self.optimizer.zero_grad()\n            loss = self.step(batch)\n            loss.backward()\n            self.optimizer.step()\n            if self.scheduler : \n                self.scheduler.step()\n            final_loss.append(loss.detach().cpu().numpy())\n        return final_loss\n    \n    def eval_loop(self, dataloader):\n        with torch.no_grad():\n            self.model.eval()\n            final_loss = []\n            for batch in tqdm(dataloader, total=len(dataloader)):\n                loss = self.step(batch)\n                final_loss.append(loss.detach().cpu().numpy())\n            \n        return final_loss\n    \n    \n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS = 10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import clear_output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Recorder:\n    def __init__(self):\n        self.train_loss = []\n        self.val_loss = []\n        \n    def update(self, train_loss, val_loss):\n        self.train_loss.append(train_loss)\n        self.val_loss.append(val_loss)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"recorders = {}\nmodels = {}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tabulate","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(FOLDS):\n    \n    train = train_df.loc[train_df['folds']!=i].reset_index(drop=True)\n    val = train_df.loc[train_df['folds']==i].reset_index(drop=True)\n            \n    scaler = MinMaxScaler()\n    train[cont_cols] = scaler.fit_transform(train[cont_cols])\n    val[cont_cols] = scaler.transform(val[cont_cols])\n    \n    train_ds = Dataset(train, feat_cols, target_cols)\n    train_dl = torch.utils.data.DataLoader(train_ds, batch_size=1024, shuffle=True, num_workers=4)\n    \n    val_ds = Dataset(train, feat_cols, target_cols)\n    val_dl = torch.utils.data.DataLoader(train_ds, batch_size=1024*4, shuffle=True, num_workers=4)\n    \n    model = Model(f_in=879, f_out=206)\n    model.to(DEVICE)\n    \n    \n    total_steps = len(train_dl) * EPOCHS\n    \n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=1e-1, total_steps=total_steps)\n    criterion = nn.BCEWithLogitsLoss()\n    engine = Engine(model, optimizer, scheduler, criterion, DEVICE )\n    recorders[i] = Recorder()\n    \n    \n    for epoch in range(EPOCHS):\n        train_loss = engine.train_loop(train_dl)\n        val_loss = engine.eval_loop(train_dl)\n        train_loss = np.stack(train_loss).mean()\n        val_loss = np.stack(val_loss).mean()\n        recorders[i].update(train_loss, val_loss)\n        clear_output()\n        print('Fold :: ',i)\n        print('Epoch :: ',epoch)\n        print(\"Train Loss :: \",recorders[i].train_loss[-1])\n        print(\"Valid Loss :: \",recorders[i].val_loss[-1])\n        \n    fig, ax = plt.subplots(FOLDS,1,constrained_layout = True, figsize=(10,30))\n    for j in range(i+1):\n        ax[j].plot(recorders[j].train_loss,label='train_loss')\n        ax[j].plot(recorders[j].val_loss,label='val_loss')\n        ax[j].set_title(f'Train Loss: {recorders[j].train_loss[-1]} val loss: {recorders[j].val_loss[-1]}')\n    plt.show()    \n    \n    \n    models[i] = model.cpu()\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_targets_scored[['sig_id','folds']].to_csv('folds.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(FOLDS):\n    torch.save(models[i].state_dict(), f'model_fold_{i}.pth')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}