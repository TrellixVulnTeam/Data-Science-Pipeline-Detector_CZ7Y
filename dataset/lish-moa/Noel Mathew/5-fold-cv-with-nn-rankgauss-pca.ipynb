{"cells":[{"metadata":{},"cell_type":"markdown","source":"Importing Libraries"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from fastai.tabular.all import *\nfrom sklearn.decomposition import PCA\n\npath = Path('/kaggle/input/lish-moa/')\npath.ls()\n\ntrain_features = pd.read_csv(path/'train_features.csv')\ntrain_targets_scored = pd.read_csv(path/'train_targets_scored.csv')\ntrain_targets_nonscored = pd.read_csv(path/'train_targets_nonscored.csv')\nfolds = pd.read_csv('/kaggle/input/pytorch-starter/folds.csv',index_col=0)\ntest_features = pd.read_csv(path/'test_features.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looking at the categorical variables"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"train_features['cp_type'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"train_features['cp_time'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"train_features['cp_dose'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observation**: \n* **cp_type**:\n    * has two values, `trt_cp` and `ctl_vehicle`. As per the data description, `trt_cp` are treated with a compound and the `ctl_vehicle` are treated with control perturbations. \n    * The `ctl_vehicle` has a significantly lower count when compared to `trt_cp`. \n    * The description states that the rows marked `ctl_vehicle` do not have MoA. We can use this for post processing. We will also check this later.\n* **cp_time**\n    * Has three values `24`, `48` and `72`. This is the treatment duration in hours. \n    * Should be treated as an ordered category\n* **cp_dose**:\n    * Has two values `D1` and `D2` for low and high doses. "},{"metadata":{"trusted":true},"cell_type":"code","source":"gene_cols = list(filter(lambda x: 'g-' in x , train_features.columns))\ncell_cols = list(filter(lambda x: 'c-' in x , train_features.columns))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cp_time = [24,48,72]\n\ntrain_features['cp_time'] = train_features['cp_time'].astype('category')\ntrain_features['cp_time'].cat.set_categories(cp_time, ordered=True, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"procs = [Categorify, Normalize]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import VarianceThreshold\nselector = VarianceThreshold(threshold=0.9)\nselector.fit_transform(train_features[gene_cols+cell_cols])\ncol_mask = selector.get_support()\ngene_mask = col_mask[:len(gene_cols)]\ncell_mask = col_mask[len(gene_cols):]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import QuantileTransformer\n\ntrain_feat = train_features.copy()\n\nfor col in gene_cols + cell_cols:\n    transformer = QuantileTransformer(n_quantiles=500, output_distribution='normal',random_state=0)\n    vec_len = len(train_features[col].values)\n    vec_len_test = len(test_features[col].values)\n    raw_vec = train_features[col].values.reshape(vec_len, 1)\n    transformer.fit(raw_vec)\n    train_feat[col] = transformer.transform(raw_vec).reshape(1,vec_len)[0]\n    test_features[col] = transformer.transform(test_features[col].values.reshape(vec_len_test, 1)).reshape(1, vec_len_test)[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = train_feat.merge(folds, on='sig_id', how='left')\ndf = df.merge(train_targets_scored, on='sig_id', how='left')\ndf = df.merge(train_targets_nonscored, on='sig_id', how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cont, cat = cont_cat_split(train_feat, 3)\ncat.remove('sig_id')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Using the unscored columns for training"},{"metadata":{"trusted":true},"cell_type":"code","source":"scored_targets = train_targets_scored.drop('sig_id', axis=1).columns.tolist()\nnon_scored_targets = train_targets_nonscored.drop('sig_id', axis=1).columns.tolist()\ny_names = scored_targets+non_scored_targets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learners = {}\npca_models_cells = {}\npca_models_genes = {}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def valid_loss_scored(inputs, targ):\n    n_targs = len(scored_targets)\n    inp = inputs[:,:n_targs]\n    targets = targ[:,:n_targs]\n    return BCEWithLogitsLossFlat()(inp, targets)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"N_FOLDS = 5\nN_COMPONENTS_C = 80\nN_COMPONENTS_G = 600","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cell_pca_cols = [f\"c-pca-{i+1}\" for i in range(N_COMPONENTS_C)]\ngene_pca_cols = [f\"g-pca-{i+1}\" for i in range(N_COMPONENTS_G)]\n# cont = cell_cols + gene_cols + cell_pca_cols + gene_pca_cols","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating PCA Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"pca_df = {}\nfor fold in range(N_FOLDS):\n    cond = df['folds'] == fold\n    train_idx = np.where(~cond)[0]\n    valid_idx = np.where(cond)[0]\n    splits = (list(train_idx), list(valid_idx))\n    pca = PCA(n_components=N_COMPONENTS_C)\n    pca.fit(df.loc[train_idx, cell_cols].loc[:, cell_mask])\n    pca_features = pca.transform(df.loc[:, cell_cols].loc[:, cell_mask])[:,:N_COMPONENTS_C]\n    pca_models_cells[fold] = pca\n    df[cell_pca_cols] = pca_features\n\n    pca = PCA(n_components=N_COMPONENTS_G)\n    pca.fit(train_features.loc[train_idx, gene_cols].loc[:, gene_mask])\n    pca_features = pca.transform(df.loc[:, gene_cols].loc[:, gene_mask])[:,:N_COMPONENTS_G]\n    pca_models_genes[fold] = pca\n    df[gene_pca_cols] = pca_features\n    pca_df[fold] = df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca_df[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import VarianceThreshold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fit_model( n_comp_c, n_comp_g):\n    layers = [100,500,200]\n    N_COMPONENTS_C = n_comp_c\n    N_COMPONENTS_G = n_comp_g\n    cell_pca_cols = [f\"c-pca-{i+1}\" for i in range(N_COMPONENTS_C)]\n    gene_pca_cols = [f\"g-pca-{i+1}\" for i in range(N_COMPONENTS_G)]\n    cont = cell_pca_cols + gene_pca_cols\n    for fold in range(N_FOLDS):\n        cond = df['folds'] == fold\n        train_idx = np.where(~cond)[0]\n        valid_idx = np.where(cond)[0]\n        splits = (list(train_idx), list(valid_idx))\n        \n\n        to = TabularPandas(pca_df[fold], procs, cat, cont,y_names=y_names,y_block=MultiCategoryBlock(encoded=True, vocab=y_names), splits=splits )\n        dls = to.dataloaders(1024)\n\n        learn = tabular_learner(dls, layers = layers, metrics=[valid_loss_scored])\n        learn.fit_one_cycle(20,lr_max=1e-2,pct_start=0.3)\n        learners[fold] = learn\n    return dls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dls = fit_model(70,100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = []\nfor fold in range(N_FOLDS):\n    test_features[cell_pca_cols] = pca_models_cells[fold].transform(test_features[cell_cols].loc[:, cell_mask])\n    test_features[gene_pca_cols] = pca_models_genes[fold].transform(test_features[gene_cols].loc[:, gene_mask])\n    dl_test = dls.test_dl(test_features)\n    predictions.append(learners[fold].get_preds(dl=dl_test)[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = torch.zeros(predictions[0].shape)\nfor p in predictions:\n    submission += p\nsubmission/=5\nsubs= pd.read_csv('/kaggle/input/lish-moa/sample_submission.csv')\nsubs.iloc[:,1:] = submission[:,:len(scored_targets)].detach().numpy()\nsubs.loc[test_features['cp_type'] == 'ctl_vehicle',subs.columns[1:]] = 0\nsubs.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for fold in range(N_FOLDS):\n    learners[fold].export(f'{fold}.pth')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}