{"cells":[{"metadata":{},"cell_type":"markdown","source":"# MoA TextBook Sklearn\n\n - Notebook is meant to be as simple as possible.  Using Sklearn as basic as possible.\n - Focus on Random Forest\n \nHappy modeling!"},{"metadata":{},"cell_type":"markdown","source":"# Imports"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# standard imports\nimport numpy as np\nimport pandas as pd\nimport os\nfrom tqdm.notebook import tqdm\n# modeling\nfrom sklearn.ensemble import RandomForestClassifier\nimport scipy.stats.distributions as dists\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\n#viz\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load & Review Data"},{"metadata":{},"cell_type":"markdown","source":"Let's load and review our training data ..."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/lish-moa/train_features.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see how many of our features are non-numeric."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns[(df.dtypes.values != np.dtype('float64'))]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Everything appears to be roughly a numeric column except cp_type and cp_dose.  Let's review these features to determine how they should be handled."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cp_type = df[['cp_type','sig_id']].groupby('cp_type').count().reset_index()\ndf_cp_type.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cp_type only has 2 values, so we can easily one-hot encode this."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cp_dose = df[['cp_dose','sig_id']].groupby('cp_dose').count().reset_index()\ndf_cp_dose.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Again cp_dose only has 2 values, so we can easily one-hot encode this as well.\n\nLet's get a look at the size of our training data."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"training dataset size: \", df.values.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All of our targets are in a separate file, so let's get a look at our targets data."},{"metadata":{"trusted":true},"cell_type":"code","source":"targets = pd.read_csv(\"../input/lish-moa/train_targets_scored.csv\")\ntargets.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's review how large our targets data is."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"training dataset target size: \", targets.values.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From looking at the top of our datasets, looks like the ids in the training set and targets dataset are sorted by id.  Let's check this."},{"metadata":{"trusted":true},"cell_type":"code","source":"not_same = 0\nfor i,j in zip(df['sig_id'].values,targets['sig_id'].values):\n    if i!=j:\n        not_same += 1\nprint(\"if ids in training set and target data are ordered the same, the following value should be 0:\")\nprint(not_same)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"They are already sorted by id!  This will make things a lot easier as we move along."},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering"},{"metadata":{},"cell_type":"markdown","source":"Let's handle those non-numeric columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['ctl_vehicle'] = df['cp_type'].apply(lambda x: 1 if x=='ctl_vehicle' else 0)\ndf.drop(['cp_type'], axis=1, inplace=True)\ndf['D1'] = df['cp_dose'].apply(lambda x: 1 if x=='D1' else 0)\ndf.drop(['cp_dose'], axis=1, inplace=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Get Final Feature & Target Names"},{"metadata":{},"cell_type":"markdown","source":"Okay, now let's store all of our feature names into a list, and all of our target names into a list.  We will use this later on."},{"metadata":{"trusted":true},"cell_type":"code","source":"features_list = df.columns.tolist()\nfeatures_list.remove('sig_id')\nprint(\"total features: \",len(features_list))\ntarget_list = targets.columns.tolist()\ntarget_list.remove('sig_id')\nprint(\"total target categories: \",len(target_list))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# View Target Distribution"},{"metadata":{},"cell_type":"markdown","source":"If we want to model our target, we should probably understand it.  Let's get a look at the number of values per class."},{"metadata":{"trusted":true},"cell_type":"code","source":"# create a pandas dataframe with labels and a column called 'total' that we'll use to count on later\nlabels = np.argmax(targets[target_list].values, axis=1)\nldf = pd.DataFrame()\nldf['label'] = labels\nldf['total'] = 1\nldf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# group by label and count up our ones to get a total number of oberservations per label\nldfgrp = ldf.groupby('label').agg({'total':'count'}).reset_index()\nldfgrp.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot distribution of labels\nplt.bar(ldfgrp['label'],ldfgrp['total'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lots of zeros, and then we have a lot of other values that seem roughly evenly distributed.  Let's remove the 0 class and see how the rest of the classes look."},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove 0 group\nldfgrpf = ldfgrp[ldfgrp.label!=0]\nplt.bar(ldfgrpf['label'],ldfgrpf['total'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With 0 group removed, seems pretty evenly distributed, roughly at least (i.e. no more groups that stand out).\n\nDo all of our classes have sufficient data?  Let's take a look."},{"metadata":{"trusted":true},"cell_type":"code","source":"ldfgrp = ldfgrp.sort_values(by=['total'])\nldfgrp.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"These classes are going to be very hard to predict :(.  We'll have to figure out a way to handle these low frequency classes."},{"metadata":{"trusted":true},"cell_type":"code","source":"ldfgrp = ldfgrp.sort_values(by=['total'], ascending=False)\nldfgrp.head(25)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can't build a model for all classes because some classes have VERY low frequency.  We can build a model for the top 25 classes (shown above), and for the rest we can just submit the mean value from training set.\n\nLet's save the mean predictions."},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_predictions = targets.mean()\nmean_predictions[:5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets take a look at our original 'targets' dataframe again.  We need to filter this down to the top 25 columns with sufficient data."},{"metadata":{"trusted":true},"cell_type":"code","source":"targets[target_list].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's grab the top 25 classes, which we can use later on."},{"metadata":{"trusted":true},"cell_type":"code","source":"ldfgrp.label.values[:25]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_target_idxs = ldfgrp.label.values[:25].tolist()\nnew_targets = [target_list[i] for i in new_target_idxs]\nnew_targets[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"targets[new_targets].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create Holdout"},{"metadata":{},"cell_type":"markdown","source":"Let's split our data between train and holdout, so we can test our model later on."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_holdout, y_train, y_holdout = train_test_split(df[features_list], np.argmax(targets[new_targets].values, axis=1), test_size=0.5, random_state=42)\nprint(\"training data size: \", X_train.values.shape)\nprint(\"training data target size: \", y_train.shape)\nprint(\"holdout data size: \", X_holdout.values.shape)\nprint(\"holdout data target size: \", y_holdout.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modeling"},{"metadata":{},"cell_type":"markdown","source":"So we're going to run Random Search CV on a Random Forest model.  If we use the entire dataset, this will take a very long time.  For demo purposes, we're going do downsample the training dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"# downsampling\nX_train, _, y_train, _ = train_test_split(X_train, y_train, test_size=0.8, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We're going to run 2 fold cross validation for 4 iterations.  It would be better to run say 3 fold for 30 iterations, but that would take a long time, and so we reduce runtime by running fewer folds and iterations.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = RandomForestClassifier(n_jobs=-1)\n\ndistributions = dict(n_estimators = dists.randint(4,1000),\n                     max_depth = dists.randint(1,30),\n                     max_features=dists.uniform(loc=0.05,scale=0.95))\n\nsearch = RandomizedSearchCV(estimator=clf,\n                           param_distributions=distributions,\n                           verbose=1,\n                           cv=2,\n                           n_iter=4,\n                           n_jobs=-1,\n                           scoring='roc_auc_ovr_weighted',\n                           random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nsearch_results = search.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Best: %f using %s\" % (search_results.best_score_,search_results.best_params_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If we want, we can grab the best model as follows.  We can save this model as a pickle file as well, but we don't show that here."},{"metadata":{"trusted":true},"cell_type":"code","source":"model = search_results.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Test Model on Holdout"},{"metadata":{},"cell_type":"markdown","source":"Let's look at the performance of the model on holdout using the cohen kappa metric."},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = np.argmax(model.predict_proba(X_holdout), axis=1)\nprint(\"holdout score: \", metrics.cohen_kappa_score(pred,y_holdout))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission"},{"metadata":{},"cell_type":"markdown","source":"Okay, it's time to make a submission.  We need to load the test data."},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(\"../input/lish-moa/test_features.csv\")\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We also need to add our additional features to the test data."},{"metadata":{"trusted":true},"cell_type":"code","source":"test['ctl_vehicle'] = test['cp_type'].apply(lambda x: 1 if x=='ctl_vehicle' else 0)\ntest.drop(['cp_type'], axis=1, inplace=True)\ntest['D1'] = test['cp_dose'].apply(lambda x: 1 if x=='D1' else 0)\ntest.drop(['cp_dose'], axis=1, inplace=True)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can load our submission file as follows."},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv(\"../input/lish-moa/sample_submission.csv\")\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looks like the submission and test datasets are similarly sorted by id. Let's check this."},{"metadata":{"trusted":true},"cell_type":"code","source":"not_same = 0\nfor i,j in zip(test['sig_id'].values,sub['sig_id'].values):\n    if i!=j:\n        not_same += 1\nprint(\"if ids in training set and target data are ordered the same, the following value should be 0:\")\nprint(not_same)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"They are sorted the same!  This is going to make things a lot easier!\n\nNow we need to make predictions on our test dataset using our model."},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict_proba(test[features_list])\nprint(\"prediction output shape: \", pred.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we want to add our predictions to sample submission. First we add the mean values."},{"metadata":{"trusted":true},"cell_type":"code","source":"# make a copy of submission with all targets\nnew_sub = sub[target_list].copy()\nnew_sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# change prediction to average value from training data for each row\nfor i in tqdm(range(len(sub))):\n    new_sub.loc[i,:] = mean_predictions\nnew_sub.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, we can add our predictions for the classes we modeled."},{"metadata":{"trusted":true},"cell_type":"code","source":"new_sub.iloc[:,new_target_idxs] = pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finally, we save our submission to disk."},{"metadata":{"trusted":true},"cell_type":"code","source":"# reload submissions file and add predictions (this way we have predictions and sig_id field in final submission file)\nsub = pd.read_csv(\"../input/lish-moa/sample_submission.csv\")\nsub.iloc[:,1:] = new_sub.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# submit\nsub.to_csv(\"submission.csv\", index=False)\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# The End"},{"metadata":{},"cell_type":"markdown","source":"Thanks for reading, and hope you enjoyed!"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}