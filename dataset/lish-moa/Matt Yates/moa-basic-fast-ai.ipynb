{"cells":[{"metadata":{},"cell_type":"markdown","source":"# MOA Basic Fast.ai\n\n - Using learnings from chapter 01 of fastbook\n - Additional Resources:\n  - https://docs.fast.ai/tabular.learner.html#TabularLearner.predict\n  - https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.join.html\n  - https://stackoverflow.com/questions/16476924/how-to-iterate-over-rows-in-a-dataframe-in-pandas"},{"metadata":{},"cell_type":"markdown","source":"# Imports"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nfrom tqdm.notebook import tqdm\nimport pandas as pd\nfrom fastai.vision.all import *\nfrom fastai.tabular.all import *","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Define Features & Prep Data for Fast.ai"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\n### add target values to training data\n# read data\ndf = pd.read_csv(\"../input/lish-moa/train_features.csv\")\nprint(\"training data shape: \", df.values.shape)\ntargets = pd.read_csv(\"../input/lish-moa/train_targets_scored.csv\")\nprint(\"target data shape: \", targets.values.shape)\n# get target columns\ntarget_list = targets.columns.tolist()\ntarget_list.remove('sig_id')\nprint(\"total target categories: \",len(target_list))\n# create a new variable called label with index value as label\ndef randargmax(b,**kw):\n  \"\"\" a random tie-breaking argmax\"\"\"\n  return np.argmax(np.random.random(b.shape) * (b==b.max()), **kw)\ntargets['label'] = randargmax(targets[target_list].values, axis=1)\n# convert label to string\ntargets['label'] = targets['label'].apply(lambda x: \"class-\"+str(x)).astype(str)\n# merge labels to training data\ndf2 = targets[['label']].join(df)\nprint(\"merged data shape: \", df2.values.shape)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"targets with very low volume mess things up, so let's not model them for now"},{"metadata":{"trusted":true},"cell_type":"code","source":"df2[['label','sig_id']].groupby('label').count().reset_index().sort_values(by='sig_id').head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# move low classes to another class (quick and dirty hack)\nlow_classes = ['class-82', 'class-34', 'class-141', 'class-12', 'class-125']\ndf2['label'] = df2['label'].apply(lambda x: 'class-125' if x in low_classes else x )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(set(df2['label']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Save new training data to disk for Fast.ai"},{"metadata":{"trusted":true},"cell_type":"code","source":"# save to disk\ndf2.to_csv(\"training_data.csv\", index=False)\n# show results\ndf2.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Save the names of continuous and categorical features for Fast.ai"},{"metadata":{"trusted":true},"cell_type":"code","source":"# modeling feature names\ncon_features_list = df.columns.tolist()\ncon_features_list.remove('sig_id')\ncon_features_list.remove('cp_type')\ncon_features_list.remove('cp_dose')\ncat_features_list = ['cp_type','cp_dose']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get indexs of targets that are being used in model, which we need for submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"target_indexs = list([int(x.split('-')[-1]) for x in set(df2['label'])])\ntarget_indexs.sort()\nprint(target_indexs[:5])\nprint(len(target_indexs))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"path = \"./training_data.csv\"\n\ndls = TabularDataLoaders.from_csv(path, path=path, y_names=\"label\",\n    cat_names = cat_features_list,\n    cont_names = con_features_list,\n    procs = [Categorify, FillMissing, Normalize]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = tabular_learner(dls, metrics=accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nlearn.fit_one_cycle(4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(\"../input/lish-moa/test_features.csv\")\nsub = pd.read_csv(\"../input/lish-moa/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_indexs_f = [i + 1 for i in target_indexs]\nprint(len(target_indexs_f))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(sub.iloc[0,target_indexs_f])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nfor index, row in tqdm(sub.iterrows()):\n    row, clas, probs = learn.predict(test.iloc[index])\n    sub.iloc[index,target_indexs_f] = probs.numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv(\"submission.csv\", index=False)\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(probs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}