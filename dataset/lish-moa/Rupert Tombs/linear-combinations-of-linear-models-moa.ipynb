{"cells":[{"metadata":{"_uuid":"d2944f78-7005-4b3e-a825-c77263c06f84","_cell_guid":"4052d039-09a4-4ef4-9153-8a9ca1af04b1","trusted":true},"cell_type":"markdown","source":"# Linear combinations of linear models\n\n**Heavily regularised logistic models** work surprisingly well.\n\n---\n**Description**\n\nList various plausible penalty parameters (l1, l2, varied C).\n\nIn each of *k* folds, fit logistic regression models for each penalty, for each MoA label.\n\nModels' predictions are weighted by the probability they assign to the test split (the non-normalised negative non-log loss).\n\nResults are not competitive, but pleasingly good for the model simplicity.\n\n---\n**Details**\n\nTwo MoAs have only one positive label in the training data:\n`erbb2_inhibitor` and\n`atp-sensitive_potassium_channel_antagonist`.\n\nSince that entry cannot be in both folds, these are simple fitted one l1 regularized model, tuned to use just a few features.\n\n\n---\n**Lessons**\n\nNon-linear variable transforms hurt; all I have tried performed worse. The data are already whitened and appear to have meaningful linearity.\n\nCategorical features hurt here. Tried one-hot encoding, but found worse results. Perhaps the risk of overfitting outweighs their information.\n"},{"metadata":{"_uuid":"084dea9b-6ecd-4bf8-86a4-fdfbf3da704b","_cell_guid":"3a4c47b6-8d76-4f30-bc22-7c07bd653543","trusted":true},"cell_type":"code","source":"import joblib\nimport warnings\n\nimport numpy\nimport pandas\nimport sklearn\n\nfrom matplotlib import pyplot\n\nfrom numpy import log, exp\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import StratifiedKFold","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e55e033f-afb0-471c-9d42-ab14004ccfda","_cell_guid":"a0f75da3-5c9f-4e43-b09a-e8c8304e2612","trusted":true},"cell_type":"code","source":"class data_container:\n    pass\n\n\ndef data_load(data):\n    \"\"\" Load data from disk and store our target statistics. \"\"\"\n    train_features = pandas.read_csv('../input/lish-moa/train_features.csv')\n    test_features = pandas.read_csv('../input/lish-moa/test_features.csv')\n    train_targets = pandas.read_csv('../input/lish-moa/train_targets_scored.csv')\n    sample_submission = pandas.read_csv('../input/lish-moa/sample_submission.csv')\n\n    test_control = (test_features.cp_type == \"ctl_vehicle\")\n\n    def drop_useless(df):\n        not_used = [\"sig_id\", \"cp_type\", \"cp_time\", \"cp_dose\"]\n        df = df.drop(not_used, axis=1)\n        return df\n\n    train_features = drop_useless(train_features)\n    test_features = drop_useless(test_features)\n    train_targets = train_targets.drop(\"sig_id\", axis=1)\n\n    # whiten\n    mean = train_features.values.mean()\n    train_features -= mean\n    test_features -= mean\n\n    # store\n    data.train_features = train_features\n    data.train_targets = train_targets\n    data.test_features = test_features\n    data.test_control = test_control\n    data.submission = sample_submission\n\n\ndef data_fold(data, target_column_name, k=2, seed=None):\n    \"\"\" Iterate over k folds of the training data \"\"\"\n    kfold = StratifiedKFold(k, shuffle=(seed != None), random_state=seed)\n    features = data.train_features\n    targets = data.train_targets[target_column_name]\n    for itrain, itest in kfold.split(features, targets):\n        X_train, X_test = features.iloc[itrain], features.iloc[itest]\n        y_train, y_test = targets.iloc[itrain], targets.iloc[itest]\n        yield X_train, X_test, y_train, y_test\n\n\ndef data_sumbission(data, test_predictions, filename=\"submission.csv\"):\n    \"\"\" Write our submission \"\"\"\n    data.submission.iloc[:, 1:] = test_predictions\n    data.submission.iloc[data.test_control, 1:] = 0.0\n    data.submission.to_csv(filename, index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e90b51d2-23ec-4bfd-8808-7298af5d1d39","_cell_guid":"9d033412-224d-4b5c-b956-d82292dde40e","trusted":true},"cell_type":"code","source":"data = data_container()\ndata_load(data)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"08a63caf-79ff-4138-83f9-9364ac59c687","_cell_guid":"a63cbeaa-7195-448c-a019-833a1ac9a398","trusted":true},"cell_type":"code","source":"def get_hitcount(data):\n    \"\"\" Return dict of MoA names to number of positive training examples. \"\"\"\n    return dict(data.train_targets.sum(0).sort_values(ascending=False))\n\ndef print_hitcount(data):\n    \"\"\" Print results of get_hitcount. \"\"\"\n    for i, (column_name, count) in enumerate(get_hitcount(data).items()):\n        print(\"%3d %-47s %d\" % (i, column_name, count))\n\n# print_hitcount(data) # Commented to shorten public notebook","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4cd783a8-cfa1-45cc-94f4-8463b737b6b6","_cell_guid":"59d09722-62b3-411d-b7c0-3d0aceb30cf6","trusted":true},"cell_type":"code","source":"def log_likelihood(model, X_test, y_test):\n    \"\"\" Return log prob(y_test | X_test, model). \"\"\"\n    y_pred = model.predict_proba(X_test)\n    return -sklearn.metrics.log_loss(y_test, y_pred, normalize=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b17ebeb6-bc8c-4f9b-836b-2b1f89e23217","_cell_guid":"70a126e9-4bf2-44c7-9a6b-a07f0baebb7c","trusted":true},"cell_type":"code","source":"def logistic(**kwargs):\n    \"\"\" Return a default logistic regression model. \"\"\"\n    config = dict(\n        C=1e-2,\n        max_iter=200,\n        intercept_scaling=1e3,\n    )\n    config.update(kwargs)\n    return LogisticRegression(**config)\n\n\ndef make_base_models():\n    \"\"\" Return a list of linear models to combine. \"\"\"\n    models = []\n    models.extend(\n        logistic(penalty=\"l1\", solver=\"liblinear\", C=C)\n        for C in (1e-4, 2e-4, 5e-4,\n                  1e-3, 2e-3, 5e-3,\n                  1e-2, 2e-2, 5e-2,\n                  1e-1, 2e-1, 5e-1)\n    )\n    models.extend(\n        logistic(C=C)\n        for C in (1e-6, 1e-5,\n                  1e-4, 2e-4, 5e-4,\n                  1e-3, 2e-3, 5e-3,\n                  1e-2, 2e-2, 5e-2,\n                  1e-1, 2e-1, 5e-1,\n                  1e0, 1e3)\n    )\n    return models","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f71dc776-9a4d-4c64-9e67-b7a756f1144e","_cell_guid":"a65a31a9-c31e-4308-b5f1-8a0a080f2cba","trusted":true},"cell_type":"code","source":"# Linear combination structures\nclass mixture:\n    def __init__(self, models, weights=None):\n        \"\"\" Initialize with fitted and their relative weights. \"\"\"\n        models = tuple(models)\n        \n        if weights is None:\n            weights = numpy.ones(len(models))\n\n        weights = numpy.asanyarray(weights)\n        weights /= weights.sum()\n\n        assert len(models) == len(weights)\n        \n        self.models = models\n        self.weights = weights\n\n    def predict_proba(self, X):\n        \"\"\" Return the weighted sum of model results. \"\"\"\n        y_pred = numpy.array([\n            model.predict_proba(X)*weight\n            for model, weight in zip(self.models, self.weights)\n        ])\n        return y_pred.sum(axis=0)\n           \n    def prune(self, threshold):\n        \"\"\" Remove models with weight below threshold. \"\"\"\n        models = []\n        weights = []\n        for model, weight in zip(self.models, self.weights):\n            if weight < threshold:\n                continue\n            models.append(model)\n            weights.append(weight)\n            \n        models = tuple(models)\n        weights = numpy.array(weights)\n        weights /= weights.sum()\n        \n        self.models = models\n        self.weights = weights\n\n\nclass kfoldmixture:\n    def __init__(self, base_models, prior=None):\n        \"\"\" Initialize with models to fit and their relative weihgts. \"\"\"\n        base_models = tuple(base_models)\n        \n        if prior is None:\n            prior = numpy.ones(len(base_models))\n\n        prior = numpy.asanyarray(prior)\n        prior /= prior.sum()\n\n        assert len(base_models) == len(prior)\n        \n        self.base_models = base_models\n        self.prior = prior\n        \n        # mixture over folds, then over base models\n        self.model = None\n\n    def fit(self, fold_iter, verbose=False):\n        \"\"\" Fit models to the k-folded data generated. \"\"\"\n        chars = str(len(str(len(self.base_models))))\n        print_string = \"\\rfold %d, model %\" + chars + \"d/%d\"\n        fold_models = []\n        for i, (X_train, X_test, y_train, y_test) in enumerate(fold_iter):\n            models = []\n            log_likelihoods = []\n            for j, model in enumerate(self.base_models):\n                if verbose:\n                    print(print_string % (i, j, len(self.base_models)), end='')\n                model = sklearn.base.clone(model)\n                model.fit(X_train, y_train)\n                models.append(model)\n                log_prob = log_likelihood(model, X_test, y_test)\n                log_likelihoods.append(log_prob)\n\n            if verbose:\n                print(print_string % (i, len(self.base_models), len(self.base_models)))\n\n            log_prod = log_likelihoods + log(self.prior)\n            weights = exp(log_prod - log_prod.max())\n            \n            fold_model = mixture(models, weights)\n            fold_models.append(fold_model)\n\n        self.model = mixture(fold_models)\n\n    def prune(self, threshold):\n        \"\"\" Remove components with weight below threshold. \"\"\"\n        for mixture in self.model.models:\n            mixture.prune(threshold)\n\n    def predict_proba(self, X):\n        \"\"\" Predict labels of new data X. \"\"\"\n        return self.model.predict_proba(X)\n\n    def log_loss(self, fold_iter):\n        \"\"\" Calculate log loss on the k-folded data generated. \"\"\"\n        log_loss = 0.0\n        n_total = 0\n\n        zipiter = zip(fold_iter, self.model.models)\n        for (X_train, X_test, y_train, y_test), model in zipiter:\n            log_loss -= log_likelihood(model, X_test, y_test)\n            n_total += len(y_test)\n\n        return log_loss/n_total","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"89f92ca4-959c-4586-a39d-21474c7f27ac","_cell_guid":"e17a0667-11c3-439f-8869-10b7238c3b98","trusted":true},"cell_type":"code","source":"def fit_target(data, column_name, k=2, seed=None, verbose=True):\n    \"\"\" Fit a linear combination of linear models to the given target column. \"\"\"\n\n    def fold_iter():\n        return data_fold(data, column_name, k=k, seed=seed)\n\n    mixture = kfoldmixture(make_base_models())\n    with warnings.catch_warnings():\n        warnings.simplefilter('ignore', category=sklearn.exceptions.ConvergenceWarning)\n        mixture.fit(fold_iter(), verbose=verbose)\n    mixture.prune(1e-15)\n    log_loss = mixture.log_loss(fold_iter())\n    return mixture, log_loss\n\n\ndef fit_target_sparse(data, column_name):\n    \"\"\" Hack to fit columns with almost-empty training data. \n\n        Hand tuned. No cross-validation here.\n    \"\"\"\n    X_train, y_train = data.train_features, data.train_targets[column_name]\n    \n    # l1 for sparsity, C tuned by hand to get ~a dozen columns in play\n    model = logistic(penalty=\"l1\", solver=\"liblinear\", C=0.8)\n    model.fit(X_train, y_train)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"68bfef22-9afe-46d1-a26f-b3089a6d5478","_cell_guid":"a082e3aa-4a17-4887-95e6-ed610894f7a0","trusted":true},"cell_type":"code","source":"def fit_all(data, k=2, seed=None):\n    \"\"\" Run all our fitting and return fitted models. \"\"\"\n    hitcount = get_hitcount(data)\n\n    usual = tuple(\n        column_name\n        for column_name, count in hitcount.items()\n        if count >= k\n    )\n    \n    sparse = tuple(\n        column_name\n        for column_name, count in hitcount.items()\n        if not (count >= k)\n    )\n\n    model_loss = joblib.Parallel(3, verbose=10)(\n        joblib.delayed(fit_target)(data, column_name, k=k, seed=seed, verbose=True)\n        for column_name in usual\n    )\n    \n    log_loss = 0.0\n    column_models = {}\n    for i, (model, column_log_loss) in enumerate(model_loss):\n        column_name = usual[i]\n        log_loss += column_log_loss\n        column_models[column_name] = model\n        print(\"%3d/%d %-47s logloss: %.6f, mean %.6f\" % \n              (i + 1, len(usual), column_name, column_log_loss, log_loss/(i + 1)))\n\n    for i, column_name in enumerate(sparse):\n        print(\"%d/%d %-47s (sum(y) == 1)\" % (i + 1, len(sparse), column_name))\n        model = fit_target_sparse(data, column_name)\n        column_models[column_name] = model\n\n    log_loss /= len(usual)\n    print(\"log loss: %.6f\" % log_loss)\n    return column_models","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d241ba13-033b-413b-b875-3199c1e1aa6a","_cell_guid":"1d4be522-ec92-41e0-b3d1-72eda1b92b06","trusted":true},"cell_type":"code","source":"all_fitted = fit_all(data, k=3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"42757673-2527-492c-826e-4fb683f5e6a2","_cell_guid":"e20e6a37-41b9-479d-800f-7ad19de499a9","trusted":true},"cell_type":"code","source":"def all_predict(data, all_fitted):\n    \"\"\" Return a DataFrame of predictions of test targets. \"\"\"\n    results = {}\n    test_features = data.test_features\n    for column_name, model in all_fitted.items():\n        y_pred = model.predict_proba(test_features)\n        y_pred = y_pred[:, 1]\n        results[column_name] = y_pred\n    return pandas.DataFrame(results)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"97cd13f9-6774-49fc-9801-1656e54d7613","_cell_guid":"bfe4581d-63ba-489f-a0e6-3d4d7be761b5","trusted":true},"cell_type":"code","source":"predictions = all_predict(data, all_fitted)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6ad2571e-c269-469a-b624-bef1ca12678f","_cell_guid":"c8c147c8-81c1-428f-868d-6446fb11ae23","trusted":true},"cell_type":"code","source":"data_sumbission(data, predictions)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"79e0cba7-07fa-4947-9814-16cc41c863a0","_cell_guid":"a2a780a9-b67c-4464-9587-cb8afeffbd3c","trusted":true},"cell_type":"code","source":"joblib.dump(all_fitted, \"all_fitted.joblib\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}