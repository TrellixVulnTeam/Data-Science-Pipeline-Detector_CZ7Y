{"cells":[{"metadata":{"execution":{"iopub.execute_input":"2020-11-24T02:01:34.180389Z","iopub.status.busy":"2020-11-24T02:01:34.179483Z","iopub.status.idle":"2020-11-24T02:01:38.462239Z","shell.execute_reply":"2020-11-24T02:01:38.461062Z"},"papermill":{"duration":4.332053,"end_time":"2020-11-24T02:01:38.462443","exception":false,"start_time":"2020-11-24T02:01:34.13039","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import sys\nsys.path.append('../input/iterativestratification')\n\nimport numpy as np\nimport random\nimport pandas as pd\nimport os\nimport copy\nimport gc\n\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\n\nfrom sklearn import preprocessing\nfrom sklearn.metrics import log_loss\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import QuantileTransformer\nfrom sklearn.feature_selection import VarianceThreshold, SelectKBest\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n\nimport scipy.stats as stats\nfrom scipy.stats import kurtosis\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.nn.modules.loss import _WeightedLoss\n\nfrom pickle import load,dump\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nos.listdir('../input/lish-moa')\n\npd.set_option('max_columns', 2000)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-24T02:01:38.579521Z","iopub.status.busy":"2020-11-24T02:01:38.578369Z","iopub.status.idle":"2020-11-24T02:01:38.590643Z","shell.execute_reply":"2020-11-24T02:01:38.591385Z"},"papermill":{"duration":0.073491,"end_time":"2020-11-24T02:01:38.591592","exception":false,"start_time":"2020-11-24T02:01:38.518101","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"n_comp_GENES = 463\nn_comp_CELLS = 60\nVarianceThreshold_for_FS = 0.9\nDropout_Model = 0.25\nprint('n_comp_GENES', n_comp_GENES, 'n_comp_CELLS', n_comp_CELLS, 'total', n_comp_GENES + n_comp_CELLS)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2020-11-24T02:01:38.723853Z","iopub.status.busy":"2020-11-24T02:01:38.721288Z","iopub.status.idle":"2020-11-24T02:01:45.900681Z","shell.execute_reply":"2020-11-24T02:01:45.899725Z"},"papermill":{"duration":7.250163,"end_time":"2020-11-24T02:01:45.900831","exception":false,"start_time":"2020-11-24T02:01:38.650668","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"train_features = pd.read_csv('../input/lish-moa/train_features.csv')\ntrain_targets_scored = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\ntrain_targets_nonscored = pd.read_csv('../input/lish-moa/train_targets_nonscored.csv')\n\ntest_features = pd.read_csv('../input/lish-moa/test_features.csv')\nsample_submission = pd.read_csv('../input/lish-moa/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-24T02:01:46.052632Z","iopub.status.busy":"2020-11-24T02:01:46.050502Z","iopub.status.idle":"2020-11-24T02:01:46.053374Z","shell.execute_reply":"2020-11-24T02:01:46.053947Z"},"papermill":{"duration":0.046163,"end_time":"2020-11-24T02:01:46.054083","exception":false,"start_time":"2020-11-24T02:01:46.00792","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"GENES = [col for col in train_features.columns if col.startswith('g-')]\nCELLS = [col for col in train_features.columns if col.startswith('c-')]","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-24T02:01:46.456977Z","iopub.status.busy":"2020-11-24T02:01:46.456155Z","iopub.status.idle":"2020-11-24T02:01:57.71488Z","shell.execute_reply":"2020-11-24T02:01:57.715553Z"},"papermill":{"duration":11.307543,"end_time":"2020-11-24T02:01:57.715749","exception":false,"start_time":"2020-11-24T02:01:46.408206","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"for col in (GENES + CELLS):    \n    transformer = QuantileTransformer(n_quantiles=100,random_state=0, output_distribution=\"normal\")   # from optimal commit 9\n    vec_len = len(train_features[col].values)\n    vec_len_test = len(test_features[col].values)\n    raw_vec = train_features[col].values.reshape(vec_len, 1)\n    transformer.fit(raw_vec)\n\n    train_features[col] = transformer.transform(raw_vec).reshape(1, vec_len)[0]\n    test_features[col] = transformer.transform(test_features[col].values.reshape(vec_len_test, 1)).reshape(1, vec_len_test)[0]","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-24T02:01:57.890336Z","iopub.status.busy":"2020-11-24T02:01:57.88936Z","iopub.status.idle":"2020-11-24T02:01:57.896636Z","shell.execute_reply":"2020-11-24T02:01:57.895968Z"},"papermill":{"duration":0.057045,"end_time":"2020-11-24T02:01:57.896763","exception":false,"start_time":"2020-11-24T02:01:57.839718","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_everything(seed=42)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-24T02:01:58.17337Z","iopub.status.busy":"2020-11-24T02:01:58.17252Z","iopub.status.idle":"2020-11-24T02:02:07.593452Z","shell.execute_reply":"2020-11-24T02:02:07.592327Z"},"papermill":{"duration":9.478621,"end_time":"2020-11-24T02:02:07.593597","exception":false,"start_time":"2020-11-24T02:01:58.114976","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"data = pd.concat([pd.DataFrame(train_features[GENES]), pd.DataFrame(test_features[GENES])])\npca_g=PCA(n_components=n_comp_GENES, random_state=42)\ndata2 = (pca_g.fit_transform(data[GENES]))\ntrain2 = data2[:train_features.shape[0]]; test2 = data2[-test_features.shape[0]:]\n\ntrain2 = pd.DataFrame(train2, columns=[f'pca_G-{i}' for i in range(n_comp_GENES)])\ntest2 = pd.DataFrame(test2, columns=[f'pca_G-{i}' for i in range(n_comp_GENES)])\n\ntrain_features = pd.concat((train_features, train2), axis=1)\ntest_features = pd.concat((test_features, test2), axis=1)\n\ndump(pca_g, open('pca_g.pkl', 'wb'))","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-24T02:02:07.769546Z","iopub.status.busy":"2020-11-24T02:02:07.768065Z","iopub.status.idle":"2020-11-24T02:02:08.559501Z","shell.execute_reply":"2020-11-24T02:02:08.558804Z"},"papermill":{"duration":0.841733,"end_time":"2020-11-24T02:02:08.559652","exception":false,"start_time":"2020-11-24T02:02:07.717919","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"data = pd.concat([pd.DataFrame(train_features[CELLS]), pd.DataFrame(test_features[CELLS])])\npca_c=PCA(n_components=n_comp_CELLS, random_state=42)\ndata2 = (pca_c.fit_transform(data[CELLS]))\ntrain2 = data2[:train_features.shape[0]]; test2 = data2[-test_features.shape[0]:]\n\ntrain2 = pd.DataFrame(train2, columns=[f'pca_C-{i}' for i in range(n_comp_CELLS)])\ntest2 = pd.DataFrame(test2, columns=[f'pca_C-{i}' for i in range(n_comp_CELLS)])\n\ntrain_features = pd.concat((train_features, train2), axis=1)\ntest_features = pd.concat((test_features, test2), axis=1)\n\ndump(pca_c, open('pca_c.pkl', 'wb'))","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-24T02:02:10.354614Z","iopub.status.busy":"2020-11-24T02:02:10.353408Z","iopub.status.idle":"2020-11-24T02:02:13.320573Z","shell.execute_reply":"2020-11-24T02:02:13.321154Z"},"papermill":{"duration":3.059105,"end_time":"2020-11-24T02:02:13.321341","exception":false,"start_time":"2020-11-24T02:02:10.262236","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"data = train_features.append(test_features)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-24T02:02:13.503129Z","iopub.status.busy":"2020-11-24T02:02:13.501791Z","iopub.status.idle":"2020-11-24T02:02:14.246153Z","shell.execute_reply":"2020-11-24T02:02:14.24683Z"},"papermill":{"duration":0.842657,"end_time":"2020-11-24T02:02:14.247001","exception":false,"start_time":"2020-11-24T02:02:13.404344","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"var_thresh = VarianceThreshold(VarianceThreshold_for_FS)\ndata = train_features.append(test_features)\ndata_transformed = var_thresh.fit_transform(data.iloc[:, 4:])\n\ntrain_features_transformed = data_transformed[ : train_features.shape[0]]\ntest_features_transformed = data_transformed[-test_features.shape[0] : ]\n\n\ntrain_features = pd.DataFrame(train_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n                              columns=['sig_id','cp_type','cp_time','cp_dose'])\n\ntrain_features = pd.concat([train_features, pd.DataFrame(train_features_transformed)], axis=1)\n\n\ntest_features = pd.DataFrame(test_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n                             columns=['sig_id','cp_type','cp_time','cp_dose'])\n\ntest_features = pd.concat([test_features, pd.DataFrame(test_features_transformed)], axis=1)\n\ntrain_features.shape","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-24T02:02:15.543284Z","iopub.status.busy":"2020-11-24T02:02:15.541788Z","iopub.status.idle":"2020-11-24T02:02:15.869497Z","shell.execute_reply":"2020-11-24T02:02:15.868887Z"},"papermill":{"duration":0.429731,"end_time":"2020-11-24T02:02:15.869702","exception":false,"start_time":"2020-11-24T02:02:15.439971","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"train = train_features.merge(train_targets_scored, on='sig_id')\ntrain = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\ntest = test_features[test_features['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n\ntarget = train[train_targets_scored.columns]","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-24T02:02:16.141163Z","iopub.status.busy":"2020-11-24T02:02:16.128985Z","iopub.status.idle":"2020-11-24T02:02:16.146075Z","shell.execute_reply":"2020-11-24T02:02:16.145473Z"},"papermill":{"duration":0.184778,"end_time":"2020-11-24T02:02:16.146273","exception":false,"start_time":"2020-11-24T02:02:15.961495","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"train = train.drop('cp_type', axis=1)\ntest = test.drop('cp_type', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-24T02:02:17.60171Z","iopub.status.busy":"2020-11-24T02:02:17.600668Z","iopub.status.idle":"2020-11-24T02:02:17.603994Z","shell.execute_reply":"2020-11-24T02:02:17.603399Z"},"papermill":{"duration":0.12723,"end_time":"2020-11-24T02:02:17.604117","exception":false,"start_time":"2020-11-24T02:02:17.476887","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"target_cols = target.drop('sig_id', axis=1).columns.values.tolist()","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-24T02:02:18.038046Z","iopub.status.busy":"2020-11-24T02:02:18.036612Z","iopub.status.idle":"2020-11-24T02:02:23.150647Z","shell.execute_reply":"2020-11-24T02:02:23.151278Z"},"papermill":{"duration":5.228245,"end_time":"2020-11-24T02:02:23.151438","exception":false,"start_time":"2020-11-24T02:02:17.923193","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"folds = train.copy()\n\nmskf = MultilabelStratifiedKFold(n_splits=7)\n\nfor f, (t_idx, v_idx) in enumerate(mskf.split(X=train, y=target)):\n    folds.loc[v_idx, 'kfold'] = int(f)\n\nfolds['kfold'] = folds['kfold'].astype(int)\nfolds","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-24T02:02:23.430389Z","iopub.status.busy":"2020-11-24T02:02:23.429392Z","iopub.status.idle":"2020-11-24T02:02:23.434993Z","shell.execute_reply":"2020-11-24T02:02:23.435585Z"},"papermill":{"duration":0.147892,"end_time":"2020-11-24T02:02:23.43575","exception":false,"start_time":"2020-11-24T02:02:23.287858","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"print(train.shape)\nprint(folds.shape)\nprint(test.shape)\nprint(target.shape)\nprint(sample_submission.shape)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-24T02:02:23.980556Z","iopub.status.busy":"2020-11-24T02:02:23.979489Z","iopub.status.idle":"2020-11-24T02:02:23.982966Z","shell.execute_reply":"2020-11-24T02:02:23.981933Z"},"papermill":{"duration":0.14878,"end_time":"2020-11-24T02:02:23.983085","exception":false,"start_time":"2020-11-24T02:02:23.834305","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"class MoADataset:\n    def __init__(self, features, targets):\n        self.features = features\n        self.targets = targets\n        \n    def __len__(self):\n        return (self.features.shape[0])\n    \n    def __getitem__(self, idx):\n        dct = {\n            'x' : torch.tensor(self.features[idx, :], dtype=torch.float),\n            'y' : torch.tensor(self.targets[idx, :], dtype=torch.float)            \n        }\n        return dct\n    \nclass TestDataset:\n    def __init__(self, features):\n        self.features = features\n        \n    def __len__(self):\n        return (self.features.shape[0])\n    \n    def __getitem__(self, idx):\n        dct = {\n            'x' : torch.tensor(self.features[idx, :], dtype=torch.float)\n        }\n        return dct","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-24T02:02:24.27136Z","iopub.status.busy":"2020-11-24T02:02:24.270238Z","iopub.status.idle":"2020-11-24T02:02:24.273103Z","shell.execute_reply":"2020-11-24T02:02:24.273653Z"},"papermill":{"duration":0.155136,"end_time":"2020-11-24T02:02:24.27381","exception":false,"start_time":"2020-11-24T02:02:24.118674","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def train_fn(model, optimizer, scheduler, loss_fn, dataloader, device):\n    model.train()\n    final_loss = 0\n    \n    for data in dataloader:\n        optimizer.zero_grad()\n        inputs, targets = data['x'].to(device), data['y'].to(device)\n        outputs = model(inputs)\n        loss = loss_fn(outputs, targets)\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n        \n        final_loss += loss.item()\n        \n    final_loss /= len(dataloader)\n    \n    return final_loss\n\n\ndef valid_fn(model, loss_fn, dataloader, device):\n    model.eval()\n    final_loss = 0\n    valid_preds = []\n    \n    for data in dataloader:\n        inputs, targets = data['x'].to(device), data['y'].to(device)\n        outputs = model(inputs)\n        loss = loss_fn(outputs, targets)\n        \n        final_loss += loss.item()\n        valid_preds.append(outputs.sigmoid().detach().cpu().numpy())\n        \n    final_loss /= len(dataloader)\n    valid_preds = np.concatenate(valid_preds)\n    \n    return final_loss, valid_preds\n\ndef inference_fn(model, dataloader, device):\n    model.eval()\n    preds = []\n    \n    for data in dataloader:\n        inputs = data['x'].to(device)\n\n        with torch.no_grad():\n            outputs = model(inputs)\n        \n        preds.append(outputs.sigmoid().detach().cpu().numpy())\n        \n    preds = np.concatenate(preds)\n    \n    return preds","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-24T02:02:24.82035Z","iopub.status.busy":"2020-11-24T02:02:24.819297Z","iopub.status.idle":"2020-11-24T02:02:24.822861Z","shell.execute_reply":"2020-11-24T02:02:24.822251Z"},"papermill":{"duration":0.150523,"end_time":"2020-11-24T02:02:24.822977","exception":false,"start_time":"2020-11-24T02:02:24.672454","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"class SmoothBCEwLogits(_WeightedLoss):\n    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n        super().__init__(weight=weight, reduction=reduction)\n        self.smoothing = smoothing\n        self.weight = weight\n        self.reduction = reduction\n\n    @staticmethod\n    def _smooth(targets:torch.Tensor, n_labels:int, smoothing=0.0):\n        assert 0 <= smoothing < 1\n        with torch.no_grad():\n            targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n        return targets\n\n    def forward(self, inputs, targets):\n        targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1),\n            self.smoothing)\n        loss = F.binary_cross_entropy_with_logits(inputs, targets,self.weight)\n\n        if  self.reduction == 'sum':\n            loss = loss.sum()\n        elif  self.reduction == 'mean':\n            loss = loss.mean()\n\n        return loss","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-24T02:02:25.388124Z","iopub.status.busy":"2020-11-24T02:02:25.386598Z","iopub.status.idle":"2020-11-24T02:02:25.388871Z","shell.execute_reply":"2020-11-24T02:02:25.389452Z"},"papermill":{"duration":0.14318,"end_time":"2020-11-24T02:02:25.389594","exception":false,"start_time":"2020-11-24T02:02:25.246414","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def process_data(data):\n    data = pd.get_dummies(data, columns=['cp_time','cp_dose'])\n    return data","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-24T02:02:25.666921Z","iopub.status.busy":"2020-11-24T02:02:25.665425Z","iopub.status.idle":"2020-11-24T02:02:25.861745Z","shell.execute_reply":"2020-11-24T02:02:25.862318Z"},"papermill":{"duration":0.338281,"end_time":"2020-11-24T02:02:25.86247","exception":false,"start_time":"2020-11-24T02:02:25.524189","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"feature_cols = [c for c in process_data(folds).columns if c not in target_cols]\nfeature_cols = [c for c in feature_cols if c not in ['kfold','sig_id']]\nlen(feature_cols)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-24T02:02:26.789593Z","iopub.status.busy":"2020-11-24T02:02:26.788661Z","iopub.status.idle":"2020-11-24T02:02:26.79283Z","shell.execute_reply":"2020-11-24T02:02:26.791768Z"},"papermill":{"duration":0.529051,"end_time":"2020-11-24T02:02:26.792956","exception":false,"start_time":"2020-11-24T02:02:26.263905","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\nEPOCHS = 25\nBATCH_SIZE = 128\nLEARNING_RATE = 1e-3\nWEIGHT_DECAY = 1e-5\nNFOLDS = 7\nEARLY_STOPPING_STEPS = 10\nEARLY_STOP = False\n\nnum_features=len(feature_cols)\nnum_targets=len(target_cols)\nhidden_size=1500","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-24T02:02:27.084765Z","iopub.status.busy":"2020-11-24T02:02:27.083064Z","iopub.status.idle":"2020-11-24T02:02:27.085554Z","shell.execute_reply":"2020-11-24T02:02:27.086094Z"},"papermill":{"duration":0.159804,"end_time":"2020-11-24T02:02:27.086267","exception":false,"start_time":"2020-11-24T02:02:26.926463","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"class Model(nn.Module):\n    \n    def __init__(self, num_features, num_targets, hidden_size):\n        super(Model, self).__init__()\n        self.batch_norm1 = nn.BatchNorm1d(num_features)\n        self.dense1 = nn.utils.weight_norm(nn.Linear(num_features, hidden_size))\n        \n        self.batch_norm2 = nn.BatchNorm1d(hidden_size)\n        self.dropout2 = nn.Dropout(Dropout_Model)\n        self.dense2 = nn.utils.weight_norm(nn.Linear(hidden_size, hidden_size))\n        \n        self.batch_norm3 = nn.BatchNorm1d(hidden_size)\n        self.dropout3 = nn.Dropout(Dropout_Model)\n        self.dense3 = nn.utils.weight_norm(nn.Linear(hidden_size, num_targets))\n    \n    \n    def forward(self, x):\n        x = self.batch_norm1(x)\n        x = F.leaky_relu(self.dense1(x))\n        \n        x = self.batch_norm2(x)\n        x = self.dropout2(x)\n        x = F.leaky_relu(self.dense2(x))\n        \n        x = self.batch_norm3(x)\n        x = self.dropout3(x)\n        x = self.dense3(x)\n        \n        return x\n    \n    \nclass LabelSmoothingLoss(nn.Module):\n    def __init__(self, classes, smoothing=0.0, dim=-1):\n        super(LabelSmoothingLoss, self).__init__()\n        self.confidence = 1.0 - smoothing\n        self.smoothing = smoothing\n        self.cls = classes\n        self.dim = dim\n\n    def forward(self, pred, target):\n        pred = pred.log_softmax(dim=self.dim)\n        with torch.no_grad():\n            true_dist = torch.zeros_like(pred)\n            true_dist.fill_(self.smoothing / (self.cls - 1))\n            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))    ","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-24T02:02:27.409402Z","iopub.status.busy":"2020-11-24T02:02:27.408621Z","iopub.status.idle":"2020-11-24T02:02:27.413555Z","shell.execute_reply":"2020-11-24T02:02:27.412635Z"},"papermill":{"duration":0.182554,"end_time":"2020-11-24T02:02:27.413676","exception":false,"start_time":"2020-11-24T02:02:27.231122","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def run_training(fold, seed,x_train,y_train,x_valid,y_valid):\n    \n    seed_everything(seed)\n    \n#     train = process_data(folds)\n    test_ = process_data(test)\n    \n#     trn_idx = train[train['kfold'] != fold].index\n#     val_idx = train[train['kfold'] == fold].index\n    \n#     train_df = train[train['kfold'] != fold].reset_index(drop=True)\n#     valid_df = train[train['kfold'] == fold].reset_index(drop=True)\n    \n#     x_train, y_train  = train_df[feature_cols].values, train_df[target_cols].values\n#     x_valid, y_valid =  valid_df[feature_cols].values, valid_df[target_cols].values\n    \n    train_dataset = MoADataset(x_train, y_train)\n    valid_dataset = MoADataset(x_valid, y_valid)\n    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n    validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n    \n    model = Model(\n        num_features=num_features,\n        num_targets=num_targets,\n        hidden_size=hidden_size,\n    )\n    \n    model.to(DEVICE)\n    \n    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n    scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n                                              max_lr=1e-2, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n    \n    loss_fn = nn.BCEWithLogitsLoss()\n    loss_tr = SmoothBCEwLogits(smoothing =0.001)\n    \n    early_stopping_steps = EARLY_STOPPING_STEPS\n    early_step = 0\n   \n    oof = np.zeros((len(train), target.iloc[:, 1:].shape[1]))\n    best_loss = np.inf\n    \n    for epoch in range(EPOCHS):\n        \n        train_loss = train_fn(model, optimizer,scheduler, loss_tr, trainloader, DEVICE)\n        print(f\"FOLD: {fold}, EPOCH: {epoch}, train_loss: {train_loss}\")\n        valid_loss, valid_preds = valid_fn(model, loss_fn, validloader, DEVICE)\n        print(f\"FOLD: {fold}, EPOCH: {epoch}, valid_loss: {valid_loss}\")\n        \n        if valid_loss < best_loss:\n            \n            best_loss = valid_loss\n#             oof[val_idx] = valid_preds\n            torch.save(model.state_dict(), f\"SEED{seed}_FOLD{fold}_.pth\")\n        \n        elif(EARLY_STOP == True):\n            \n            early_step += 1\n            if (early_step >= early_stopping_steps):\n                break\n            \n    \n    #--------------------- PREDICTION---------------------\n    x_test = test_[feature_cols].values\n    testdataset = TestDataset(x_test)\n    testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n    \n    model = Model(\n        num_features=num_features,\n        num_targets=num_targets,\n        hidden_size=hidden_size,\n\n    )\n    \n    model.load_state_dict(torch.load(f\"SEED{seed}_FOLD{fold}_.pth\"))\n    model.to(DEVICE)\n    \n    predictions = np.zeros((len(test_), target.iloc[:, 1:].shape[1]))\n    predictions = inference_fn(model, testloader, DEVICE)\n    \n    return oof, predictions","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-24T02:02:27.957251Z","iopub.status.busy":"2020-11-24T02:02:27.956395Z","iopub.status.idle":"2020-11-24T02:02:27.959745Z","shell.execute_reply":"2020-11-24T02:02:27.959154Z"},"papermill":{"duration":0.14562,"end_time":"2020-11-24T02:02:27.959871","exception":false,"start_time":"2020-11-24T02:02:27.814251","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def run_k_fold(NFOLDS, seed,data):\n    oof = np.zeros((len(train), len(target_cols)))\n    predictions = np.zeros((len(test), len(target_cols)))\n    \n    x_train=data.loc[:,feature_cols]\n    y_train=data.loc[:,target_cols]\n    \n#     for fold in range(NFOLDS):\n    for n,(tr,te) in enumerate(MultilabelStratifiedKFold(n_splits=NFOLDS, random_state=seed, shuffle=True).split(x_train,y_train)):\n        oof_, pred_ = run_training(n, seed,x_train.values[tr],y_train.values[tr],x_train.values[te],y_train.values[te])\n        \n        predictions += pred_ / NFOLDS\n        oof += oof_\n        \n    return oof, predictions","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-24T02:02:28.23764Z","iopub.status.busy":"2020-11-24T02:02:28.236562Z","iopub.status.idle":"2020-11-24T02:07:37.91355Z","shell.execute_reply":"2020-11-24T02:07:37.912078Z"},"papermill":{"duration":309.820817,"end_time":"2020-11-24T02:07:37.913698","exception":false,"start_time":"2020-11-24T02:02:28.092881","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Averaging on multiple SEEDS\n\nSEED = [1,2,3,4,5,6,7]\noof = np.zeros((len(train), len(target_cols)))\npredictions = np.zeros((len(test), len(target_cols)))\n\nfor seed in SEED:\n    \n    oof_, predictions_ = run_k_fold(NFOLDS, seed,process_data(folds))\n    oof += oof_ / len(SEED)\n    predictions += predictions_ / len(SEED)\n\ntrain[target_cols] = oof\ntest[target_cols] = predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}