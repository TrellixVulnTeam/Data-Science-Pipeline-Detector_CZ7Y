{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport scipy.stats as ss\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport tsfresh as tsf\n\nfrom sklearn.preprocessing import QuantileTransformer\nfrom sklearn.feature_selection import mutual_info_classif, f_classif\n\nimport os\nos.listdir('/kaggle/input/lish-moa/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!lscpu | grep -P '^CPU\\(s\\)'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_features = pd.read_csv('../input/lish-moa/train_features.csv')\ntrain_targets_scored = pd.read_csv('../input/lish-moa/train_targets_scored.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GENES = [col for col in train_features.columns if col.startswith('g-')]\nCELLS = [col for col in train_features.columns if col.startswith('c-')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def to_str(row):\n    return \"\".join(row[1:].tolist())\n\ndef encode_multilabel(y: pd.DataFrame):\n    return y.astype('str').apply(to_str,1).astype('category').cat.codes\n\ny_enc = encode_multilabel(train_targets_scored)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def q_transform(X, q):\n    X_transformed = np.zeros_like(X)\n    for i in range(X.shape[1]):\n        transformer = QuantileTransformer(n_quantiles=q,random_state=0, output_distribution=\"normal\")\n        X_transformed[:,i:(i+1)] = transformer.fit_transform(X[:,i:(i+1)])\n    return X_transformed\n\ndef q_transform(X, q, col_idx=[]):\n    \"\"\"\n        col_idx = bool array of size same as columns in X\n    \"\"\"\n    X_transformed = X.copy()\n    \n    if len(col_idx):\n        idx = np.where(col_idx)[0]\n    else:\n        idx = range(X.shape[1])\n        \n    for i in idx:\n        transformer = QuantileTransformer(n_quantiles=q,random_state=0, output_distribution=\"normal\")\n        X_transformed[:,i:(i+1)] = transformer.fit_transform(X[:,i:(i+1)])\n    return X_transformed\n\ndef get_mutual_info_classif(X,y,**kwarg):\n    info = mutual_info_classif(X,y,**kwarg)\n#     info = f_classif(X,y,**kwarg)[1] # p-values\n    info[info<0] = 0\n    return info\n\ndef summarize_loss_difference(x):\n    \"\"\"\n    Usage:\n        x = np.array([-1,-2,3,1,2])\n        summarize_loss_difference(x)\n    \"\"\"\n    return {'il_mean' :x.mean(),\n            'il_median' :np.median(x),\n            'il_skew' :np.round(ss.skew(x),4) ,\n            'il_percentage_features':(x>0).mean(), \n            'n_features': len(x),\n            'il_n_features' :(x>0).sum(),\n            'il_quantiles_features':np.quantile(x>0, [0.1,0.2,0.4,0.5,0.6,0.8,0.9]),\n            'il_hist': np.histogram(x, 20),\n           }\n\ndef test_Qs(X, y, qs, skew_thresh=0.8):\n    org_info = get_mutual_info_classif(X, y)\n    skewness = np.abs(ss.skew(X)) > skew_thresh\n    org_info = org_info[skewness]\n    \n    info_losses = []\n    for q in qs:\n        X_transformed = q_transform(X, q, skewness)\n        new_info = get_mutual_info_classif(X_transformed[:,skewness], y)\n        info_loss = org_info - new_info\n        log = {\n                'q':q,\n                'org_info':org_info.mean(),\n                'new_info':new_info.mean(),\n                'info_loss':info_loss.mean(),\n        }\n        print(pd.Series(log))\n        log.update(summarize_loss_difference(info_loss))\n        info_losses.append(log)\n    return info_losses\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# qs = np.linspace(2200, 4000, 15, dtype=np.int)\nqs = np.logspace(0.5, 4.2, 15, dtype=np.int)\nqs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true,"collapsed":true},"cell_type":"code","source":"X = train_features[GENES[:150]].values\n\ninfo_losses = test_Qs(X, y_enc, qs)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gene_info_loss = pd.DataFrame(info_losses)\ngene_info_loss.to_pickle('gene_info_loss.pkl')\ngene_info_loss.iloc[:60,:11]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_loss(df):\n    fig, ax = plt.subplots(3,1, figsize=(12,6), sharex=True)\n    ax[0].plot(df['q'], df[['il_mean']], 'o--', label=\"il_mean\")\n    ax[1].plot(df['q'], df['il_skew'], 'o--', label=\"il_skew\");\n    ax[2].plot(df['q'], df['il_percentage_features'], 'o--', label=\"il_percentage_features\");\n    plt.tight_layout()\n    [axi.legend(loc=\"upper left\") for axi in ax]\n    [axi.set_xscale('log') for axi in ax]\n    ax[0].xticks\n    plt.show()\n\nplot_loss(gene_info_loss)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"X = train_features[CELLS[:]].values\n\ninfo_losses = test_Qs(X, y_enc, qs=qs)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cell_info_loss = pd.DataFrame(info_losses)\ncell_info_loss.to_pickle('cell_info_loss.pkl')\ncell_info_loss.iloc[:60,:11]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_loss(cell_info_loss)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Toy Example"},{"metadata":{"trusted":true},"cell_type":"code","source":"# dataset_size = 12000\n# nfeatures = 13\n# nclasses = 3\n\n# np.random.seed(1291)\n# X = np.random.random((dataset_size,nfeatures))\n# y = np.random.randint(0,nclasses,(dataset_size,))\n\n# # f_classif(X, y)\n# # mutual_info_classif(X, y)\n\n# X_transformed = np.zeros_like(X)\n# for i in range(X.shape[1]):\n#     transformer = QuantileTransformer(n_quantiles=120,random_state=0, output_distribution=\"normal\")\n#     X_transformed[:,i:(i+1)] = transformer.fit_transform(X[:,i:(i+1)])\n\n# # def get_mutual_info_classif(X,y,**kwarg):\n# #     info = mutual_info_classif(X,y,**kwarg)\n# #     info[info<0] = 0\n# #     return info\n\n# org_info = get_mutual_info_classif(X, y)\n# new_info = get_mutual_info_classif(X_transformed, y)\n\n# info_loss = org_info - new_info\n# org_info, new_info, info_loss","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Check sparsity"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train_features[GENES[:1]].values\n\ni=0\nX_transformed = np.zeros_like(X)\ntransformer = QuantileTransformer(n_quantiles=20,random_state=0, output_distribution=\"normal\")\nX_transformed[:,i:(i+1)] = transformer.fit_transform(X[:,i:(i+1)])\n\nplt.plot(X[:,:1], '.', alpha=0.5)\nplt.plot(X_transformed[:,:1], '.', alpha=0.1)\n\nX_transformed[:,:1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"precision = 3\nplt.hist(X_transformed[:,0].round(precision), bins=330)\n# sns.distplot(X_transformed[:,0], bins=2)\nnp.unique(X_transformed[:,:1].round(precision)).shape, X_transformed[:,0].round(precision)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}