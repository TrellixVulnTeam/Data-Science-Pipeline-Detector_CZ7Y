{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn.functional as F\nimport torch.nn as nn\nimport seaborn as sns\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import OneHotEncoder, MinMaxScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import KFold\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Load training data, sort by id\ntrain = pd.read_csv('/kaggle/input/lish-moa/train_features.csv').sort_values(by='sig_id')\ncolumns = train.columns\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Load testing data\ntest = pd.read_csv('/kaggle/input/lish-moa/test_features.csv')\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop id\ntrain = train[columns[1:]]\n\n#OHE categorical features\ntrain_cat = train[columns[1:4]]\ntrain.drop(columns[1:4], axis=1, inplace=True)\ntrain_cat.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 6))\n\nnames = train_cat['cp_type'].value_counts().index\nvals = train_cat['cp_type'].value_counts()\nax1.bar(names, vals)\nax1.set_title('cp_type')\nax1.grid()\n\nnames = list(map(lambda x: str(x), train_cat['cp_time'].value_counts().index))\nvals = train_cat['cp_time'].value_counts()\nax2.bar(names, vals)\nax2.set_title('cp_time')\nax2.grid()\n\nnames = train_cat['cp_dose'].value_counts().index\nvals = train_cat['cp_dose'].value_counts()\nax3.bar(names, vals)\nax3.set_title('cp_dose')\nax3.grid()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=3,ncols=3, figsize=(15, 15))\nstep = 10\n\nfor  i in range(0, 9, 1):\n    row, col = i // 3, i % 3\n    features = train.loc[:, 'c-{}'.format(i * step)]\n    sns.kdeplot(features, ax=axes[row, col])\n    axes[row, col].grid()\n    axes[row, col].set_title('c-{}'.format(i * step))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=3,ncols=3, figsize=(15, 15))\nstep = 10\n\nfor  i in range(0, 9, 1):\n    row, col = i // 3, i % 3\n    features = train.loc[:, 'g-{}'.format(i * step)]\n    sns.kdeplot(features, ax=axes[row, col])\n    axes[row, col].grid()\n    axes[row, col].set_title('g-{}'.format(i * step))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rand_cell_feats = list(map(lambda x: 'c-{}'.format(x), np.random.randint(low=0, high=100, size=15)))\nrand_gene_feats = list(map(lambda x: 'c-{}'.format(x), np.random.randint(low=0, high=100, size=15)))\n\nplt.figure(figsize=(13, 8))\nsns.heatmap(train[rand_cell_feats].corr())\n\nplt.title('Correlation matrix for cell features', fontsize=20);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rand_cell_feats = list(map(lambda x: 'g-{}'.format(x), np.random.randint(low=0, high=100, size=15)))\nrand_gene_feats = list(map(lambda x: 'g-{}'.format(x), np.random.randint(low=0, high=100, size=15)))\n\nplt.figure(figsize=(13, 8))\nsns.heatmap(train[rand_cell_feats].corr())\n\nplt.title('Correlation matrix for gene features', fontsize=20);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#encode\nencoder = OneHotEncoder(categories='auto')\ntrain_cat_OHE = encoder.fit_transform(train_cat).toarray()\ntrain_OHE = pd.concat((train, pd.DataFrame(train_cat_OHE)), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Same One-Hot encoding\ntest_id = test[columns[0]].copy()\ntest = test[columns[1:]]\n\ntest_cat = test[columns[1:4]]\ntest.drop(columns[1:4], axis=1, inplace=True)\n\ntest_cat_OHE = encoder.transform(test_cat).toarray()\ntest_OHE = pd.concat((test, pd.DataFrame(test_cat_OHE)), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Load training target data, sort by id\ntrain_target_scored = pd.read_csv('/kaggle/input/lish-moa/train_targets_scored.csv').sort_values(by='sig_id')\ntarget_columns = train_target_scored.columns\ntrain_target_scored.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"X_train shape: \", np.array(train_OHE).shape)\nprint(\"Y_train shape: \", np.array(train_target_scored[target_columns[1:]]).shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Видим, что значения признаков лежат на отрезке [-10, 10]"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(8, 6))\n\nprint(\"Min: \", np.array(train_OHE).min(), \"\\nMax: \", np.array(train_OHE).max())\n\nplt.plot(np.array(train_OHE)[0])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y = np.array(train_target_scored[target_columns[1:]])\ntarget_num_features = Y.shape[1]\n\nfor f in range(target_num_features):\n    print(f, ': ', (Y[:, f] != 0.0).sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.unique(Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"All zero objects portion: \", (Y.sum(axis=1) == 0).sum()/Y.shape[0])\nprint(\"One 1.0 value portion: \", (Y.sum(axis=1) == 1).sum()/Y.shape[0])\nprint(\"More than one 1.0 values portion: \", (Y.sum(axis=1) > 1).sum()/Y.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vals, counts = np.unique(Y.sum(axis=1), return_counts=True)\n\nfig = plt.figure(figsize=(10, 8))\nplt.bar(vals, counts)\nplt.title(\"Counts: \" + str(counts))\nplt.grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_target = train_target_scored[target_columns[1:]]\ntrain_target['Dummy'] = [0] * train_target.shape[0]\n\ndummy_index = train_target.columns.get_loc(\"Dummy\")\nprint(\"Dummy col num: \", dummy_index)\n\nfill_dummy_mask = np.array(train_target).sum(axis=1) == 0\ntrain_target.loc[fill_dummy_mask, 'Dummy'] = 1.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y = np.array(train_target)\nprint(\"All zero objects portion: \", (Y.sum(axis=1) == 0).sum()/Y.shape[0])\nprint(\"One 1.0 value portion: \", (Y.sum(axis=1) == 1).sum()/Y.shape[0])\nprint(\"More than one 1.0 values portion: \", (Y.sum(axis=1) > 1).sum()/Y.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_comp = 680\npca = PCA(n_components=n_comp, random_state=228)\npca.fit(np.array(pd.concat((train_OHE, test_OHE), axis=0)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_OHE_pca = pca.transform(np.array(train_OHE))\ntrain_OHE_aug = pd.concat((train_OHE, pd.DataFrame(train_OHE_pca)), axis=1)\ntrain_OHE_aug.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self, num_features, num_targets):\n        super(Net, self).__init__()\n        assert (num_features > num_targets), 'Neg diff'\n\n        self.batch_norm1 = torch.nn.BatchNorm1d(num_features)\n        self.linear1 = nn.utils.weight_norm(nn.Linear(num_features, 1024))\n        \n        self.batch_norm2 = torch.nn.BatchNorm1d(1024)\n        self.linear2 = nn.utils.weight_norm(nn.Linear(1024, 1024))\n        \n        self.batch_norm3 = torch.nn.BatchNorm1d(1024)\n        self.linear3 = nn.utils.weight_norm(nn.Linear(1024, num_targets))\n        \n        self.dropout = nn.Dropout(p=0.5)\n    \n    def forward(self, x):\n        x = self.batch_norm1(x)\n        x = self.dropout(x)\n        x = self.linear1(x)\n        x = F.elu(x)\n        \n        x = self.batch_norm2(x)\n        x = self.dropout(x)\n        x = self.linear2(x)\n        x = F.elu(x)\n        \n        x = self.batch_norm3(x)\n        x = self.dropout(x)\n        x = self.linear3(x)\n        \n        return torch.sigmoid(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = np.array(train_OHE_aug)\nY_train = np.array(train_target)\n\nsmoothing = 0.0000\nY_train = Y_train.clip(min=smoothing, max=1.0-smoothing)\n\n\n\n#p_num = 0\n#for p in model.parameters():\n#    p_num += np.prod(p.shape)\n    \n#print(\"Number of net parameters: \", p_num)\n\nassert (X_train.shape[0] == Y_train.shape[0]), \"Wrong train shapes\"\n\nepochs = 50\nbatch_size = 128\n\nrandom_states = [42, 228, 1337, 2020]\n\nfor n_try, random_state in enumerate(random_states):\n\n    n_splits = 7\n    print(\"==Random State: \", random_state)\n    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n\n    for fold_num, (train_ind, test_ind) in enumerate(kf.split(Y_train)):\n\n        X_kf_train, Y_kf_train = X_train[train_ind], Y_train[train_ind]\n        X_kf_test, Y_kf_test = X_train[test_ind], Y_train[test_ind]\n        train_iters = X_kf_train.shape[0]//batch_size\n        test_iters = X_kf_test.shape[0]//batch_size\n\n        model = Net(num_features=X_train.shape[1], num_targets=Y_train.shape[1]).cuda()\n        optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay = 1e-5)\n        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n        criterion = nn.BCELoss().cuda()\n        best_epoch_loss = 1e18\n\n        for epoch_num in range(1, epochs+1):\n            train_loss = 0\n            test_loss = 0\n\n            for iter_num in range(train_iters):\n                optimizer.zero_grad()\n                batch_x = torch.tensor(X_kf_train[iter_num*batch_size:(iter_num+1)*batch_size]).float().cuda()\n                batch_y = torch.tensor(Y_kf_train[iter_num*batch_size:(iter_num+1)*batch_size]).float().cuda()\n\n                pred = model(batch_x)\n                loss = criterion(pred, batch_y)\n                loss.backward()\n                optimizer.step()\n                train_loss += loss.item()\n\n            model.eval()\n            with torch.no_grad():\n                for iter_num_test in range(test_iters):\n                    optimizer.zero_grad()\n                    batch_x = torch.tensor(X_kf_test[iter_num_test*batch_size:(iter_num_test+1)*batch_size]).float().cuda()\n                    batch_y = torch.tensor(Y_kf_test[iter_num_test*batch_size:(iter_num_test+1)*batch_size]).float().cuda()\n\n                    pred = model(batch_x)\n                    loss = criterion(pred, batch_y)\n                    test_loss += loss.item()\n            model.train()\n\n            train_loss /= train_iters\n            test_loss /= test_iters\n            scheduler.step()\n\n\n            print(\"N_try: \", n_try+1, \"|| Fold num: \", fold_num+1, \"|| Epoch num:\", epoch_num, \"|| Train Loss: \", train_loss, \"|| Test Loss: \", test_loss)\n\n            if test_loss < best_epoch_loss:\n                best_epoch_loss = test_loss\n                model.eval()\n                torch.save(model.state_dict(), 'best_model_' + str(fold_num+1) + '_' + str(n_try+1) + '.pth')\n                model.train()\n                print(\"Best model so far\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Test prediction\n\ntest_OHE_pca = pca.transform(np.array(test_OHE))\ntest_OHE_aug = pd.concat((test_OHE, pd.DataFrame(test_OHE_pca)), axis=1)\n\ntest_prediction = 0\nfor n_try, random_state in enumerate(random_states):\n    for model_num in range(1, n_splits+1):\n\n        model = Net(num_features=X_train.shape[1], num_targets=Y_train.shape[1]).cuda()\n        model.load_state_dict(torch.load('best_model_' + str(model_num) + '_' + str(n_try+1) + '.pth'))\n        model.eval()\n        with torch.no_grad():\n            X_test = torch.tensor(np.array(test_OHE_aug)).float().cuda()\n            test_prediction += model(X_test).cpu().numpy()\n\ntest_prediction /= (n_splits*len(random_states))\nsubmission = pd.DataFrame(test_prediction[:, :-1], columns=target_columns[1:])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_id = pd.DataFrame(test_id, columns=[target_columns[0]])\nsubmission = pd.concat((test_id, submission), axis=1)\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}