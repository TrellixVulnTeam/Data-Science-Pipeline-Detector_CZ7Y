{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\nsys.path.append('../input/iterativestratification')\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport random\nfrom sklearn import preprocessing\nfrom sklearn.metrics import log_loss\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import QuantileTransformer\nfrom sklearn.feature_selection import VarianceThreshold, SelectKBest\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom xgboost import XGBClassifier\nfrom category_encoders import CountEncoder\nfrom sklearn.pipeline import Pipeline\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nimport tensorflow.keras.layers as L\nimport tensorflow.keras.models as M\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\nimport tensorflow_addons as tfa","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# read datasets"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_features = pd.read_csv('../input/lish-moa/train_features.csv')\ntrain_targets_scored = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\ntrain_targets_nonscored = pd.read_csv('../input/lish-moa/train_targets_nonscored.csv')\ntest_features = pd.read_csv('../input/lish-moa/test_features.csv')\ntrain_drug = pd.read_csv(\"../input/lish-moa/train_drug.csv\")\n\ndata = train_features.append(test_features)\n\nss = pd.read_csv('../input/lish-moa/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# main parameters\nfrom https://www.kaggle.com/vbmokin/moa-pytorch-rankgauss-pca-nn-upgrade-3d-visual"},{"metadata":{"trusted":true},"cell_type":"code","source":"n_comp_GENES = 463\nn_comp_CELLS = 60\nVarianceThreshold_for_FS = 0.9\nNFOLDS = 5\nNSEEDS = 5","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# set seeds"},{"metadata":{"trusted":true},"cell_type":"code","source":"def seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n\n    \nseed_everything(seed=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# transform columns to normal dist with rankgauss (QuantileTransformer)"},{"metadata":{"trusted":true},"cell_type":"code","source":"GENES = [col for col in train_features.columns if col.startswith('g-')]\nCELLS = [col for col in train_features.columns if col.startswith('c-')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col_names = GENES + CELLS\ncol_example_index = 300\ncol_example_name = col_names[300]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# quantile transformer normal dist --> \nfor col in (GENES + CELLS):    \n    transformer = QuantileTransformer(n_quantiles=100,random_state=0, output_distribution=\"normal\")\n    vec_len = len(train_features[col].values)\n    vec_len_test = len(test_features[col].values)\n    raw_vec = train_features[col].values.reshape(vec_len, 1)\n    transformer.fit(raw_vec)\n\n    train_features[col] = transformer.transform(raw_vec).reshape(1, vec_len)[0]\n    test_features[col] = transformer.transform(test_features[col].values.reshape(vec_len_test, 1)).reshape(1, vec_len_test)[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# dimensionality reduction with pca"},{"metadata":{"trusted":true},"cell_type":"code","source":"len(GENES)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# GENES\n\ndata = pd.concat([pd.DataFrame(train_features[GENES]), pd.DataFrame(test_features[GENES])])\ndata2 = (PCA(n_components=n_comp_GENES, random_state=42).fit_transform(data[GENES]))\ntrain2 = data2[:train_features.shape[0]]; test2 = data2[-test_features.shape[0]:]\n\ntrain2 = pd.DataFrame(train2, columns=[f'pca_G-{i}' for i in range(n_comp_GENES)])\ntest2 = pd.DataFrame(test2, columns=[f'pca_G-{i}' for i in range(n_comp_GENES)])\n\ntrain_features = pd.concat((train_features, train2), axis=1)\ntest_features = pd.concat((test_features, test2), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(CELLS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CELLS\n\ndata = pd.concat([pd.DataFrame(train_features[CELLS]), pd.DataFrame(test_features[CELLS])])\ndata2 = (PCA(n_components=n_comp_CELLS, random_state=42).fit_transform(data[CELLS]))\ntrain2 = data2[:train_features.shape[0]]; test2 = data2[-test_features.shape[0]:]\n\ntrain2 = pd.DataFrame(train2, columns=[f'pca_C-{i}' for i in range(n_comp_CELLS)])\ntest2 = pd.DataFrame(test2, columns=[f'pca_C-{i}' for i in range(n_comp_CELLS)])\n\ntrain_features = pd.concat((train_features, train2), axis=1)\ntest_features = pd.concat((test_features, test2), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features.shape[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# feature elimination with variance threshold"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = train_features.append(test_features)\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"var_thresh = VarianceThreshold(VarianceThreshold_for_FS)\ndata_transformed = var_thresh.fit_transform(data.iloc[:, 4:])\n\ntrain_features_transformed = data_transformed[ : train_features.shape[0]]\ntest_features_transformed = data_transformed[-test_features.shape[0] : ]\n\n\ntrain_features = pd.DataFrame(train_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n                              columns=['sig_id','cp_type','cp_time','cp_dose'])\n\ntrain_features = pd.concat([train_features, pd.DataFrame(train_features_transformed)], axis=1)\n\n\ntest_features = pd.DataFrame(test_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n                             columns=['sig_id','cp_type','cp_time','cp_dose'])\n\ntest_features = pd.concat([test_features, pd.DataFrame(test_features_transformed)], axis=1)\n\ntrain_features.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# create datasets"},{"metadata":{"trusted":true},"cell_type":"code","source":"# merge feature and and targets\nmerged = train_features.merge(train_targets_scored, on='sig_id')\n\n# remove ctl_vehicle rows\nmerged = merged[merged['cp_type']!='ctl_vehicle'].reset_index(drop=True)\nX_test = test_features[test_features['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n\n# create X_train and y_train\nX_train = merged[train_features.columns]\ny_train = merged[train_targets_scored.columns]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop cp_type column\nX_train = X_train.drop('cp_type', axis=1)\nX_test = X_test.drop('cp_type', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop sig_id column\nX_train = X_train.drop('sig_id', axis=1)\nX_test = X_test.drop('sig_id', axis=1)\ny_train = y_train.drop('sig_id', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CountEncoder and StandardScaler"},{"metadata":{"trusted":true},"cell_type":"code","source":"ce = CountEncoder(cols=[\"cp_dose\",\"cp_time\"])\nX_train_encoded = ce.fit_transform(X_train)\nX_test_encoded = ce.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train_encoded)\nX_test_scaled = scaler.transform(X_test_encoded)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert arrays to df again\nX_train = pd.DataFrame(X_train_scaled, columns=X_train.columns.to_list())\nX_test = pd.DataFrame(X_test_scaled, columns=X_test.columns.to_list())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Neural Network"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_columns = X_train.shape[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model(num_columns):\n    model = tf.keras.Sequential([\n    tf.keras.layers.Input(num_columns),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.2),\n    tfa.layers.WeightNormalization(tf.keras.layers.Dense(2048, activation=\"relu\")),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.5),\n    tfa.layers.WeightNormalization(tf.keras.layers.Dense(1048, activation=\"relu\")),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.5),\n    tfa.layers.WeightNormalization(tf.keras.layers.Dense(206, activation=\"sigmoid\"))\n    ])\n    model.compile(optimizer=tfa.optimizers.Lookahead(tf.optimizers.Adam(), sync_period=10),\n                  loss='binary_crossentropy', \n                  )\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res = y_train.copy()\nss.loc[:, y_train.columns] = 0\nres.loc[:, y_train.columns] = 0\ncontrol_mask = test_features['cp_type']!='ctl_vehicle'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for seed in range(NSEEDS):\n    mskf = MultilabelStratifiedKFold(n_splits=NFOLDS, random_state=seed, shuffle=True)\n    for n, (tr, te) in enumerate(mskf.split(X_train, y_train)):\n        print(f'Fold {n}')\n        \n        X_trn, X_val = X_train.iloc[tr,:], X_train.iloc[te,:]\n        y_trn, y_val = y_train.iloc[tr,:], y_train.iloc[te,:]\n        \n        model = create_model(num_columns)\n        checkpoint_path = f'repeat:{seed}_Fold:{n}.hdf5'\n        reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, epsilon=1e-4, mode='min')\n        cb_checkpt = ModelCheckpoint(checkpoint_path, monitor = 'val_loss', verbose = 0, save_best_only = True,\n                                     save_weights_only = True, mode = 'min')\n        model.fit(X_trn.values,\n                  y_trn.values,\n                  validation_data=(X_val.values, y_val.values),\n                  epochs=35, batch_size=128,\n                  callbacks=[reduce_lr_loss, cb_checkpt], verbose=2\n                 )\n        \n        model.load_weights(checkpoint_path)\n        test_predict = model.predict(X_test.values)\n        val_predict = model.predict(X_val.values)\n        \n        ss.loc[control_mask, y_train.columns] += test_predict\n        res.loc[te, y_train.columns] += val_predict\n        print('')\n        \nss.loc[:, y_train.columns] /= (NFOLDS * NSEEDS)\nres.loc[:, y_train.columns] /= NSEEDS","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def metric(y_true, y_pred):\n    metrics = []\n    for _target in y_train.columns:\n        metrics.append(log_loss(y_true.loc[:, _target], y_pred.loc[:, _target].astype(float), labels=[0,1]))\n    return np.mean(metrics)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'OOF Metric: {metric(y_train, res)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dot_img_file = 'model_1.png'\ntf.keras.utils.plot_model(model, to_file=dot_img_file, show_shapes=True)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}