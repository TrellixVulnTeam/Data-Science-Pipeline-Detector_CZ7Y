{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\nsys.path.append('../input/iterativestratification')\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport random\nfrom sklearn import preprocessing\nfrom sklearn.metrics import log_loss\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import QuantileTransformer\nfrom sklearn.feature_selection import VarianceThreshold, SelectKBest\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom xgboost import XGBClassifier\nfrom category_encoders import CountEncoder\nfrom sklearn.pipeline import Pipeline\nimport matplotlib.pyplot as plt\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# read datasets"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_features = pd.read_csv('../input/lish-moa/train_features.csv')\ntrain_targets_scored = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\ntrain_targets_nonscored = pd.read_csv('../input/lish-moa/train_targets_nonscored.csv')\ntest_features = pd.read_csv('../input/lish-moa/test_features.csv')\ntrain_drug = pd.read_csv(\"../input/lish-moa/train_drug.csv\")\n\ndata = train_features.append(test_features)\n\nss = pd.read_csv('../input/lish-moa/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# main parameters \n\nfrom https://www.kaggle.com/vbmokin/moa-pytorch-rankgauss-pca-nn-upgrade-3d-visual\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"n_comp_GENES = 463\nn_comp_CELLS = 60\nVarianceThreshold_for_FS = 0.9\nNFOLDS = 5","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# set seeds"},{"metadata":{"trusted":true},"cell_type":"code","source":"def seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    #torch.manual_seed(seed)\n    #torch.cuda.manual_seed(seed)\n    #torch.backends.cudnn.deterministic = True\n    \nseed_everything(seed=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# transform columns to normal dist with rankgauss (QuantileTransformer)"},{"metadata":{"trusted":true},"cell_type":"code","source":"GENES = [col for col in train_features.columns if col.startswith('g-')]\nCELLS = [col for col in train_features.columns if col.startswith('c-')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col_names = GENES + CELLS\ncol_example_index = 300\ncol_example_name = col_names[300]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure()\nplt.hist(train_features.iloc[:,col_example_index+4].values, bins=100, density= True)\nplt.ylabel('Probability')\nplt.xlabel(col_example_name)\nplt.title('Raw feature distribution');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transformer = QuantileTransformer(n_quantiles=50,random_state=0, output_distribution=\"normal\")\nfig = plt.figure()\nplt.hist(transformer.fit_transform(train_features.iloc[:,col_example_index+4].values.reshape(-1,1)), bins=100, density= True)\n\nplt.ylabel('Probability')\nplt.xlabel(col_example_name)\nplt.title('Transformed feature distribution');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# quantile transformer normal dist --> \nfor col in (GENES + CELLS):    \n    transformer = QuantileTransformer(n_quantiles=100,random_state=0, output_distribution=\"normal\")\n    vec_len = len(train_features[col].values)\n    vec_len_test = len(test_features[col].values)\n    raw_vec = train_features[col].values.reshape(vec_len, 1)\n    transformer.fit(raw_vec)\n\n    train_features[col] = transformer.transform(raw_vec).reshape(1, vec_len)[0]\n    test_features[col] = transformer.transform(test_features[col].values.reshape(vec_len_test, 1)).reshape(1, vec_len_test)[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# dimensionality reduction with pca "},{"metadata":{"trusted":true},"cell_type":"code","source":"len(GENES)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# GENES\n\ndata = pd.concat([pd.DataFrame(train_features[GENES]), pd.DataFrame(test_features[GENES])])\ndata2 = (PCA(n_components=n_comp_GENES, random_state=42).fit_transform(data[GENES]))\ntrain2 = data2[:train_features.shape[0]]; test2 = data2[-test_features.shape[0]:]\n\ntrain2 = pd.DataFrame(train2, columns=[f'pca_G-{i}' for i in range(n_comp_GENES)])\ntest2 = pd.DataFrame(test2, columns=[f'pca_G-{i}' for i in range(n_comp_GENES)])\n\ntrain_features = pd.concat((train_features, train2), axis=1)\ntest_features = pd.concat((test_features, test2), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(CELLS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CELLS\n\ndata = pd.concat([pd.DataFrame(train_features[CELLS]), pd.DataFrame(test_features[CELLS])])\ndata2 = (PCA(n_components=n_comp_CELLS, random_state=42).fit_transform(data[CELLS]))\ntrain2 = data2[:train_features.shape[0]]; test2 = data2[-test_features.shape[0]:]\n\ntrain2 = pd.DataFrame(train2, columns=[f'pca_C-{i}' for i in range(n_comp_CELLS)])\ntest2 = pd.DataFrame(test2, columns=[f'pca_C-{i}' for i in range(n_comp_CELLS)])\n\ntrain_features = pd.concat((train_features, train2), axis=1)\ntest_features = pd.concat((test_features, test2), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features.shape[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# feature elimination with variance threshold"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = train_features.append(test_features)\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"var_thresh = VarianceThreshold(VarianceThreshold_for_FS)\ndata_transformed = var_thresh.fit_transform(data.iloc[:, 4:])\n\ntrain_features_transformed = data_transformed[ : train_features.shape[0]]\ntest_features_transformed = data_transformed[-test_features.shape[0] : ]\n\n\ntrain_features = pd.DataFrame(train_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n                              columns=['sig_id','cp_type','cp_time','cp_dose'])\n\ntrain_features = pd.concat([train_features, pd.DataFrame(train_features_transformed)], axis=1)\n\n\ntest_features = pd.DataFrame(test_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n                             columns=['sig_id','cp_type','cp_time','cp_dose'])\n\ntest_features = pd.concat([test_features, pd.DataFrame(test_features_transformed)], axis=1)\n\ntrain_features.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# create datasets"},{"metadata":{"trusted":true},"cell_type":"code","source":"# merge feature and and targets\nmerged = train_features.merge(train_targets_scored, on='sig_id')\n\n# remove ctl_vehicle rows\nmerged = merged[merged['cp_type']!='ctl_vehicle'].reset_index(drop=True)\nX_test = test_features[test_features['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n\n# create X_train and y_train\nX_train = merged[train_features.columns]\ny_train = merged[train_targets_scored.columns]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop cp_type column\nX_train = X_train.drop('cp_type', axis=1)\nX_test = X_test.drop('cp_type', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop sig_id column\nX_train = X_train.drop('sig_id', axis=1)\nX_test = X_test.drop('sig_id', axis=1)\ny_train = y_train.drop('sig_id', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# XGBoost with CountEncoder"},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = MultiOutputClassifier(XGBClassifier(tree_method='gpu_hist'))\n#classifier = MultiOutputClassifier(XGBClassifier())\n\nclf = Pipeline([('encode', CountEncoder(cols=[\"cp_dose\",\"cp_time\"])),\n                ('classify', classifier)\n               ])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CV predictions with MultilabelStratifiedKFold"},{"metadata":{"trusted":true},"cell_type":"code","source":"oof_preds = np.zeros(y_train.shape)\ntest_preds = np.zeros((X_test.shape[0], y_train.shape[1]))\noof_losses = []\nmskf = MultilabelStratifiedKFold(n_splits=NFOLDS, random_state=42)\nfor fn, (trn_idx, val_idx) in enumerate(mskf.split(X_train, y_train)):\n    print('Starting fold: ', fn)\n    X_trn, X_val = X_train.iloc[trn_idx,:], X_train.iloc[val_idx,:]\n    y_trn, y_val = y_train.iloc[trn_idx,:], y_train.iloc[val_idx,:]\n    \n    clf.fit(X_trn, y_trn)\n    val_preds = clf.predict_proba(X_val) # list of preds per class\n    val_preds = np.array(val_preds)[:,:,1].T # take the positive class\n    oof_preds[val_idx] = val_preds\n    \n    loss = log_loss(np.ravel(y_val), np.ravel(val_preds))\n    oof_losses.append(loss)\n    preds = clf.predict_proba(X_test)\n    preds = np.array(preds)[:,:,1].T # take the positive class\n    test_preds += preds / NFOLDS\n    \nprint(oof_losses)\nprint('Mean OOF loss across folds', np.mean(oof_losses))\nprint('STD OOF loss across folds', np.std(oof_losses))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('OOF log loss: ', log_loss(np.ravel(y_train), np.ravel(oof_preds)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Analysis of OOF preds"},{"metadata":{"trusted":true},"cell_type":"code","source":"# set control test preds to 0\ncontrol_mask = test_features['cp_type']!='ctl_vehicle'\n\ndummy_preds = np.zeros((ss.shape[0],ss.shape[1]-1))\ndummy_preds[control_mask] = test_preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create the submission file\nss.iloc[:,1:] = dummy_preds\nss.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}