{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport os\nimport numpy as np\nimport pandas as pd\nfrom tensorflow.keras import datasets, layers, models, backend, optimizers, losses\nclass simple_mpl(object):\n    def __init__(self, path, file_head):\n        print(\"Loading\", path, \"+\", file_head)\n        file_list = os.listdir(path) \n        num = len(file_head + \"_\")\n        self.models = []\n        for file in file_list:\n            if file[:num] == file_head + \"_\":\n                self.models.append(tf.keras.models.load_model(os.path.join(path, file)))\n        cfg = pd.read_pickle(os.path.join(path, 'config.pkl'))\n        self.mean = cfg['mean']\n        self.std =cfg['std']\n        self.output_num = cfg[\"output_num\"].max()\n    def predict(self, data):\n        pred = pd.DataFrame(np.zeros([data.index.size, self.output_num]), index=data.index)\n        for mdl in self.models:                                 \n            pred += mdl.predict((data.astype(\"float32\") - self.mean)/ self.std, batch_size=4096)\n        pred /= len(self.models)\n        return pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/lish-moa/train_features.csv')\ntrain_target = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\ntest = pd.read_csv('../input/lish-moa/test_features.csv')\ntargets_nonscored = pd.read_csv('../input/lish-moa/train_targets_nonscored.csv')\n#one-hot encoding\ntrain_size = train.shape[0]\ntraintest = pd.concat([train, test])\n#traintest = pd.concat([traintest, pd.get_dummies(traintest['cp_type'], prefix='cp_type')], axis=1)\ntraintest.drop(['cp_type'], axis=1, inplace=True)\ntraintest = pd.concat([traintest, pd.get_dummies(traintest['cp_time'], prefix='cp_time')], axis=1)\ntraintest = pd.concat([traintest, pd.get_dummies(traintest['cp_dose'], prefix='cp_dose')], axis=1)\ntraintest = traintest.drop(['cp_time', 'cp_dose'], axis=1)\ntrain = traintest[:train_size]\ntest  = traintest[train_size:]\ndel traintest\nx_train = train.drop('sig_id', axis=1)\ny_train = train_target.drop('sig_id', axis=1).astype(np.float32)\nx_test = test.drop('sig_id', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mdl = simple_mpl(path=\"../input/mplmodel11/mpl\", file_head=\"\")\nremove_cols=['g-39', 'g-85', 'g-75', 'g-734', 'g-484', 'g-217', 'g-545', 'g-10']\nx_test = x_test[np.setdiff1d(x_test.columns.values, remove_cols)]\nres = mdl.predict(x_test)\nsubmit = pd.DataFrame(res.values, index = test['sig_id'])\nsubmit.columns = y_train.columns\nsubmit.to_csv(\"submission.csv\")\nsubmit","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}