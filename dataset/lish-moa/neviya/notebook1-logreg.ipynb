{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport matplotlib\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import log_loss\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom tqdm import tqdm\nimport seaborn as sns\nimport random\nrandom.seed(123)\npd.set_option('display.max_columns',None)\nimport os\n%config InlineBackend.figure_format = 'svg'\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import TensorDataset, DataLoader\nif torch.cuda.is_available():\n    device = 'cuda'\nelse:\n    device = 'cpu'\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_features_1= pd.read_csv('/kaggle/input/lish-moa/train_features.csv')\ntrain_features_1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_1.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_1.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_1.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_1.cp_type.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,6))\nax= plt.subplot2grid((1,3),(0,0))\n#Train Sample treated with compunds\nplt.hist(x='cp_type', data=train_features_1, alpha=0.85,color='r')\nplt.title('Train: Samples treated with compounds')\n#Train Doses\nax= plt.subplot2grid((1,3),(0,1))\nplt.hist(x='cp_dose', data=train_features_1, alpha=0.85)\nplt.title('Train:Doses: Low and High')\n#Treatment duration\nax= plt.subplot2grid((1,3),(0,2))\nplt.hist(x=\"cp_time\", data=train_features_1, alpha=0.85,color='g')\nplt.title('Train:Treatment Duration')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gene= [g for g in train_features_1.columns if g.startswith(\"g-\")]\nprint(f\"No. of gene features: {len(gene)}\")\ncell= [c for c in train_features_1.columns if c.startswith(\"c-\")]\nprint(f\"No. of cell features: {len(cell)}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,16))\ngene_sel= np.random.choice(len(gene),16)\nfor i,col in enumerate(gene_sel):\n    plt.subplot(4,4,i+1)\n    plt.hist(train_features_1.loc[:,gene[col]],bins=100)\n    plt.title(gene[col])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,16))\ncell_sel= np.random.choice(len(cell),16)\nfor i,col in enumerate(cell_sel):\n    plt.subplot(4,4,i+1)\n    plt.hist(train_features_1.loc[:,cell[col]],bins=100, color='r')\n    plt.title(cell[col])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_targets_scored_1= pd.read_csv('/kaggle/input/lish-moa/train_targets_scored.csv')\ntrain_targets_scored_1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_targets_scored_1.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_targets_scored_1.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_id, val_id= train_test_split([i for i in range(0, 23814)], test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(train_id))\nprint(len(val_id))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features= train_features_1.iloc[train_id, 1:]\nval_features= train_features_1.iloc[val_id, 1:]\n\ntrain_labels= train_targets_scored_1.iloc[train_id, 1:]\nval_labels= train_targets_scored_1.iloc[val_id, 1:]\nprint(len(train_features))\nprint(len(val_features))\nprint(len(train_labels))\nprint(len(val_labels))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# handling cp_type\ncp_type_dict= { \"trt_cp\": 0, \"ctl_vehicle\": 1}\n\ntrain_features[\"cp_type\"] = train_features.cp_type.map(cp_type_dict)\nval_features[\"cp_type\"] = val_features.cp_type.map(cp_type_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#handling cp_dose\ncp_dose_dict= { \"D1\": 1,\"D2\": 2}\n\ntrain_features[\"cp_dose\"]= train_features.cp_dose.map(cp_dose_dict)\nval_features[\"cp_dose\"]= val_features.cp_dose.map(cp_dose_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#handling cp_time\ncp_time_dict= {24: 1,48: 2,72: 3}\n\ntrain_features[\"cp_time\"]= train_features.cp_time.map(cp_time_dict)\nval_features[\"cp_time\"]= val_features.cp_time.map(cp_time_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#standard scaling target columns\ntarg_columns= [col for col in list(train_features_1.columns) if col not in ['sig_id','cp_type','cp_dose','cp_time' ]]\n\nprint(\"Number of target columns are {}\".format(len(targ_columns)))\n\ntrain_targ_columns= train_features[targ_columns].copy()\nstd_scal = StandardScaler().fit(train_targ_columns.values)\ntrain_targ_columns = std_scal.transform(train_targ_columns.values)\n\nprint(\"Number of Train target columns are {}\".format(len(train_targ_columns)))\n\nval_targ_columns= val_features[targ_columns].copy()\nval_targ_columns = std_scal.transform(val_targ_columns.values)\nprint(\"Number of Val target columns are {}\".format(len(val_targ_columns)))\n\n#assign to original data\ntrain_features[targ_columns] = train_targ_columns\nval_features[targ_columns] = val_targ_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(train_features[targ_columns].sum(axis=1))\nplt.title(\"The Scored targets distribution\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_cat = list(train_labels.columns)\nlen(all_cat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_dict = {}\nfor cat in tqdm(all_cat):\n    # Training logistic regression model on train data\n    logistic_model = LogisticRegression(max_iter=5000)\n    logistic_model.fit(train_features, train_labels[cat])\n    \n    # saving model\n    model_dict[cat] = logistic_model ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calculate_score(models_dict, val_features, val_labels, all_cat):\n    log_loss_per_cat = []\n    for cat in tqdm(all_cat):\n        # predicting using logistic regression model\n        logistic_model = models_dict[cat]\n        cat_prob = logistic_model.predict_proba(val_features)\n        log_loss_per_cat.append(log_loss(val_labels[cat], cat_prob, labels=[0, 1]))\n    \n    return float(sum(log_loss_per_cat)) / len(log_loss_per_cat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_score = calculate_score(model_dict, val_features, val_labels, all_cat)\nprint(\"Validation score on validation set is {}\".format(val_score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_features_1 = pd.read_csv('/kaggle/input/lish-moa/test_features.csv')\nprint(test_features_1.shape)\ntest_features_1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Map values from created dictionaries\ntest_features_1[\"cp_type\"] = test_features_1.cp_type.map(cp_type_dict)\ntest_features_1[\"cp_dose\"] = test_features_1.cp_dose.map(cp_dose_dict)\ntest_features_1[\"cp_time\"] = test_features_1.cp_time.map(cp_time_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##standard scaling\ntest_targ_columns= test_features_1[targ_columns].copy()\ntest_targ_columns = std_scal.transform(test_targ_columns.values)\ntest_features_1[targ_columns] = test_targ_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = pd.DataFrame()\npred[\"sig_id\"] = test_features_1.sig_id\nfor cat in tqdm(all_cat):\n    pred[cat] = model_dict[cat].predict_proba(test_features_1.iloc[:, 1:])[:, 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = pred.round(1)\npred.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ctl_test = list(test_features_1[test_features_1.cp_type == 1].sig_id)\nprint(len(ctl_test))\n\nfor id_ in tqdm(ctl_test):\n    pred.loc[pred.sig_id == id_, all_cat] = 0.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_1 = pd.read_csv('/kaggle/input/lish-moa/train_features.csv')\ntrain_targets_scored_1= pd.read_csv('/kaggle/input/lish-moa/train_targets_scored.csv')\ntest_features_1 = pd.read_csv('/kaggle/input/lish-moa/test_features.csv')\n\ntrain_targets_nonscored = pd.read_csv('/kaggle/input/lish-moa/train_targets_nonscored.csv')\nprint(train_targets_nonscored.shape)\ntrain_targets_nonscored.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_1.set_index('sig_id', inplace=True)\ntest_features_1.set_index('sig_id', inplace=True)\ntrain_targets_scored_1.set_index('sig_id', inplace=True)\ntrain_targets_nonscored.set_index('sig_id', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_targets_nonscored.sum(axis=1).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gene= [g for g in train_features_1.columns if g.startswith(\"g-\")]\nprint(f\"No. of gene features: {len(gene)}\")\ncell= [c for c in train_features_1.columns if c.startswith(\"c-\")]\nprint(f\"No. of cell features: {len(cell)}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_targets_scored_1.loc[:, train_targets_scored_1.sum(axis=0) > 600]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#PCA for Linear dimensionality reduction\ng_pca = PCA(n_components=70).fit_transform(pd.concat((train_features_1[gene], test_features_1[gene])).values)\n\ng_pca_train = pd.DataFrame(g_pca[:train_features_1.shape[0]], index=train_features_1.index)\ng_pca_test = pd.DataFrame(g_pca[train_features_1.shape[0]:], index=test_features_1.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c_pca = PCA(n_components=10).fit_transform(pd.concat((train_features_1[cell], test_features_1[cell])).values)\nc_pca_train = pd.DataFrame(c_pca[:train_features_1.shape[0]], index=train_features_1.index)\nc_pca_test = pd.DataFrame(c_pca[train_features_1.shape[0]:], index=test_features_1.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" train_features_1.shape, c_pca_train.shape, g_pca_train.shape,","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_1 = pd.concat([train_features_1, g_pca_train, c_pca_train], axis=1)\ntest_features_1 = pd.concat([test_features_1, g_pca_test, c_pca_test], axis=1)\ntrain_features_1.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_index = train_features_1[train_features_1.cp_type == 'ctl_vehicle'].index\ntrain_features_df = train_features_1.drop(drop_index, axis=0)\ntrain_features_df = train_features_df.drop('cp_type', axis=1)\n\ntrain_target_df = train_targets_scored_1.drop(drop_index, axis=0)\n\ndrop_index = test_features_1[test_features_1.cp_type == 'ctl_vehicle'].index\ntest_features_df = test_features_1.drop(drop_index, axis=0)\ntest_features_df = test_features_df.drop('cp_type', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Convert categorical variable into dummy/indicator variables.\ntrain_features_df = pd.get_dummies(train_features_df, columns=['cp_time', 'cp_dose'], drop_first=True)\ntest_features_df = pd.get_dummies(test_features_df , columns=['cp_time', 'cp_dose'], drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_df.shape, test_features_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_all = train_features_df.values\ny_train_all = train_target_df.values\nX_test = test_features_df.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Standarize\nscaler = StandardScaler()\nX_train_all = scaler.fit_transform(X_train_all)\nX_test = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X_train_all, y_train_all, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_all_dataset = TensorDataset(torch.tensor(X_train_all).float(), torch.tensor(y_train_all).float())\ntrain_all_loader = DataLoader(train_all_dataset, batch_size=128)\n\ntrain_dataset = TensorDataset(torch.tensor(X_train).float(), torch.tensor(y_train).float())\nval_dataset = TensorDataset(torch.tensor(X_val).float(), torch.tensor(y_val).float())\n\ntrain_loader = DataLoader(train_dataset, batch_size=128)\nval_loader = DataLoader(val_dataset, batch_size=128)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x, y = next(iter(train_loader))\nx.shape, y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class FFNN(nn.Module):\n    def __init__(self, input_size, output_size):\n        super().__init__()\n        \n        self.bn1 = nn.BatchNorm1d(input_size)\n        self.dropout1 = nn.Dropout(0.2)\n        self.l1 = nn.utils.weight_norm(nn.Linear(input_size, 2048))\n        self.bn2 = nn.BatchNorm1d(2048)\n        self.dropout2 = nn.Dropout(0.5)\n        self.l2 = nn.utils.weight_norm(nn.Linear(2048, 1024))\n        self.bn3 = nn.BatchNorm1d(1024)\n        self.dropout3 = nn.Dropout(0.5)\n        self.l3 = nn.utils.weight_norm(nn.Linear(1024, output_size))\n    \n    def forward(self, x):\n        x = self.bn1(x)\n        x = self.dropout1(x)\n        x = F.elu(self.l1(x))\n        \n        x = self.bn2(x)\n        x = self.dropout2(x)\n        x = F.elu(self.l2(x))\n        \n        x = self.bn3(x)\n        x = self.dropout3(x)\n        x = torch.sigmoid(self.l3(x))\n        \n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = FFNN(955, 206)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model(x).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(model, optimizer, loss_function, train_loader, val_loader=None, scheduler=None, epochs=1):\n\n    for epoch in range(epochs):\n        running_loss = 0.0\n        for n_iter, (x, y) in enumerate(train_loader):\n            model.train()\n            x = x.to(device)\n            y = y.to(device) \n            optimizer.zero_grad()\n            y_pred = model(x)\n            loss = loss_function(y_pred, y)\n            loss.backward()\n            optimizer.step()      \n            running_loss += loss.item()\n        running_loss /= len(train_loader)   \n        \n        if val_loader is not None:\n            model.eval()  \n            loss = 0.0\n            with torch.no_grad():\n                for (x, y) in val_loader:\n                    x = x.to(device)\n                    y = y.to(device) \n                    y_pred = model(x)\n                    loss += loss_function(y_pred, y).item()\n                loss /= len(val_loader)\n\n            print(\"Epoch: [{}/{}] \".format(epoch + 1, epochs),\n                  \"Train loss: {:.6f}\".format(running_loss),\n                  \"Val loss: {:.6f} \".format(loss))\n        else:\n            print(\"Epoch: [{}/{}] \".format(epoch + 1, epochs),\n                  \"Train loss: {:.6f}\".format(running_loss))\n        if scheduler is not None:\n            scheduler.step()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss_function = nn.BCELoss()\nmodel = FFNN(955, 206).to(device)\noptimizer = optim.Adam(lr=0.001, params=model.parameters(), weight_decay=1e-5)\nscheduler = optim.lr_scheduler.StepLR(optimizer,10, gamma=0.5, last_epoch=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_model(model, optimizer, loss_function, train_loader, val_loader, epochs=50, scheduler=scheduler)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss_function = nn.BCELoss()\nmodel = FFNN(955, 206).to(device)\noptimizer = optim.Adam(lr=0.001, params=model.parameters(), weight_decay=1e-5)\nscheduler = optim.lr_scheduler.StepLR(optimizer,10, gamma=0.5, last_epoch=-1)\ntrain_model(model, optimizer, loss_function, train_all_loader, epochs=50, scheduler=scheduler)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(model, X):\n    model.eval()  \n            \n    with torch.no_grad():\n        X = X.to(device)\n        preds = model(X)\n    return preds.cpu().numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = predict(model, torch.tensor(X_test).float())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame(np.zeros((test_features_1.shape[0], train_targets_scored_1.shape[1])),index=test_features_1.index, columns=train_targets_scored_1.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_index = test_features_1[test_features_1.cp_type != 'ctl_vehicle'].index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.loc[pred_index, :] = y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.reset_index(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('/kaggle/working/submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}