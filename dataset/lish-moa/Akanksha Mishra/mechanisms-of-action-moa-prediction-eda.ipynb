{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1><center>Mechanisms of Action (MoA) Prediction. Data analysis and visualization</center></h1>\n\n<center><img src=\"https://pharmacyinnovations.net/wp-content/uploads/pillsdrugs.png\"></center>\n"},{"metadata":{},"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:blue; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Quick navigation</center></h2>\n\n* [1. Basic Data Overview](#1)\n* [2. Categories visualization](#2)\n* [3. Gene and cell features distribution](#3)\n* [4. Training features correlation](#4)\n* [5. Targets analysis](#5)\n* [6. Train & Targets correlations](#6)\n* [7. Targets & Train features dependecies](#7)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport plotly.express as px\nfrom IPython.display import display\nimport random\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport matplotlib.pyplot as plt\nimport time\n\npd.options.display.max_columns = None","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"1\"></a>\n<h2 style='background:blue; border:0; color:white'><center>1. Basic Data Overview</center><h2>"},{"metadata":{},"cell_type":"markdown","source":"### Take a look into training and test sets."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/lish-moa/train_features.csv')\ntest = pd.read_csv('/kaggle/input/lish-moa/test_features.csv')\n\ntrain['dataset'] = 'train'\ntest['dataset'] = 'test'\n\ndf = pd.concat([train, test])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('Number of rows in training set: ', train.shape[0])\nprint('Number of columns in training set: ', train.shape[1] - 1)\nprint('Number of rows in test set: ', test.shape[0])\nprint('Number of columns in test set: ', test.shape[1] - 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### We can see that we have 872 float features 1 integer (cp_time) and 3 categorical (sig_id, cp_type and cp_dose)"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"2\"></a>\n<h2 style='background:blue; border:0; color:white'><center>2. Categories Visualization</center><h2>"},{"metadata":{},"cell_type":"markdown","source":"## 2.1 cp_type feature"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"ds = df.groupby(['cp_type', 'dataset'])['sig_id'].count().reset_index()\nds.columns = ['cp_type', 'dataset', 'count']\n\nfig = px.bar(\n    ds, \n    x='cp_type', \n    y=\"count\", \n    color = 'dataset',\n    barmode='group',\n    orientation='v', \n    title='cp_type train/test counts', \n    width=500,\n    height=400\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.2 Cp_time feature"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"ds = df.groupby(['cp_time', 'dataset'])['sig_id'].count().reset_index()\nds.columns = ['cp_time', 'dataset', 'count']\n\nfig = px.bar(\n    ds, \n    x='cp_time', \n    y=\"count\", \n    color = 'dataset',\n    barmode='group',\n    orientation='v', \n    title='cp_time train/test counts', \n    width=500,\n    height=400\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.3 Cp_dose feature"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"ds = df.groupby(['cp_dose', 'dataset'])['sig_id'].count().reset_index()\nds.columns = ['cp_dose', 'dataset', 'count']\n\nfig = px.bar(\n    ds, \n    x='cp_dose', \n    y=\"count\", \n    color = 'dataset',\n    barmode='group',\n    orientation='v', \n    title='cp_dose train/test counts', \n    width=500,\n    height=400\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"ds = df[df['dataset']=='train']\nds = ds.groupby(['cp_type', 'cp_time', 'cp_dose'])['sig_id'].count().reset_index()\nds.columns = ['cp_type', 'cp_time', 'cp_dose', 'count']\n\nfig = px.sunburst(\n    ds, \n    path=[\n        'cp_type',\n        'cp_time',\n        'cp_dose' \n    ], \n    values='count', \n    title='Sunburst chart for all cp_type/cp_time/cp_dose',\n    width=500,\n    height=500\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"3\"></a>\n<h2 style='background:blue; border:0; color:white'><center>3. Gene and cell features distribution</center><h2>"},{"metadata":{},"cell_type":"markdown","source":"### Some distribution of randomly selected columns"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"train_columns = train.columns.to_list()\ng_list = [i for i in train_columns if i.startswith('g-')]\nc_list = [i for i in train_columns if i.startswith('c-')]\n#g_list\n#c_list","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"def plot_set_histograms(plot_list, title):\n    fig = make_subplots(rows=4, cols=3)\n    traces = [go.Histogram(x=train[col], nbinsx=20, name=col) for col in plot_list]\n\n    for i in range(len(traces)):\n        fig.append_trace(traces[i], (i // 3) + 1, (i % 3) + 1)\n\n    fig.update_layout(\n        title_text=title,\n        height=1000,\n        width=1000\n    )\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plot_list = [g_list[random.randint(0, len(g_list)-1)] for i in range(50)]\nplot_list = list(set(plot_list))[:12]\n\nplot_set_histograms(plot_list, 'Randomly selected gene expression features distributions')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plot_list = [c_list[random.randint(0, len(c_list)-1)] for i in range(50)]\nplot_list = list(set(plot_list))[:12]\nplot_set_histograms(plot_list, 'Randomly selected cell expression features distributions')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4\"></a>\n<h2 style='background:blue; border:0; color:white'><center>4. Training features correlation</center><h2>"},{"metadata":{},"cell_type":"markdown","source":"### Let's see some correlation between randomly selected variables"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"columns = g_list + c_list\nfor_correlation = list(set([columns[random.randint(0, len(columns)-1)] for i in range(200)]))[:40]\ndata = df[for_correlation]\n\nf = plt.figure(figsize=(19, 17))\nplt.matshow(data.corr(), fignum=f.number)\nplt.xticks(range(data.shape[1]), data.columns, fontsize=14, rotation=50)\nplt.yticks(range(data.shape[1]), data.columns, fontsize=14)\ncb = plt.colorbar()\ncb.ax.tick_params(labelsize=13)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Time to find pairs of features with high correlation"},{"metadata":{"trusted":true},"cell_type":"code","source":"start = time.time()\ncols = ['cp_time'] + columns\nall_columns = []\nfor i in range(0, len(cols)):\n    for j in range(i+1, len(cols)):\n        if abs(train[cols[i]].corr(train[cols[j]])) > 0.9:\n            all_columns.append(cols[i])\n            all_columns.append(cols[j])\n\nprint(time.time()-start)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_columns = list(set(all_columns))\nprint('Number of columns: ', len(all_columns))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### In total we have 35 columns that have correlation with at least another 1 higher than 0.9. Let's visualize them."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"data = df[all_columns]\n\nf = plt.figure(figsize=(19, 15))\nplt.matshow(data.corr(), fignum=f.number)\nplt.xticks(range(data.shape[1]), data.columns, fontsize=14, rotation=50)\nplt.yticks(range(data.shape[1]), data.columns, fontsize=14)\ncb = plt.colorbar()\ncb.ax.tick_params(labelsize=14)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let's visualize them"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = make_subplots(rows=12, cols=3)\ntraces = [go.Histogram(x=train[col], nbinsx=20, name=col) for col in all_columns]\n\nfor i in range(len(traces)):\n    fig.append_trace(traces[i], (i // 3) + 1, (i % 3)+1)\n\nfig.update_layout(\n    title_text='Highly correlated features',\n    height=1200\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"5\"></a>\n<h2 style='background:blue; border:0; color:white'><center>5. Targets analysis</center><h2>"},{"metadata":{},"cell_type":"markdown","source":"### Let's check targets"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_target = pd.read_csv(\"../input/lish-moa/train_targets_scored.csv\")\n\nprint('Number of rows : ', train_target.shape[0])\nprint('Number of cols : ', train_target.shape[1])\ntrain_target.head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"x = train_target.drop(['sig_id'], axis=1).sum(axis=0).sort_values().reset_index()\nx.columns = ['column', 'nonzero_records']\n\nfig = px.bar(\n    x.tail(50), \n    x='nonzero_records', \n    y='column', \n    orientation='h', \n    title='Columns with the higher number of positive samples (top 50)', \n    height=1000, \n    width=800\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"x = train_target.drop(['sig_id'], axis=1).sum(axis=0).sort_values(ascending=False).reset_index()\nx.columns = ['column', 'nonzero_records']\n\nfig = px.bar(\n    x.tail(50), \n    x='nonzero_records', \n    y='column', \n    orientation='h', \n    title='Columns with the lowest number of positive samples (top 50)', \n    height=1000, \n    width=800\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## We can see that at least 50 target columns have number pf positive samples less than 20 (about 0.1%) !!!"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"x = train_target.drop(['sig_id'], axis=1).sum(axis=0).sort_values(ascending=False).reset_index()\nx.columns = ['column', 'count']\nx['count'] = x['count'] * 100 / len(train_target)\nfig = px.bar(\n    x, \n    x='column', \n    y='count', \n    orientation='v', \n    title='Percent of positive records for every column in target', \n    height=800, \n    width=1200\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The biggest number of positive samples for 1 target column is 3.5%. So we deal here with highly imbalanced data."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"data = train_target.drop(['sig_id'], axis=1).astype(bool).sum(axis=1).reset_index()\ndata.columns = ['row', 'count']\ndata = data.groupby(['count'])['row'].count().reset_index()\nfig = px.bar(\n    data, \n    y=data['row'], \n    x=\"count\", \n    title='Number of activations in targets for every sample', \n    width=800, \n    height=500\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"data = train_target.drop(['sig_id'], axis=1).astype(bool).sum(axis=1).reset_index()\ndata.columns = ['row', 'count']\ndata = data.groupby(['count'])['row'].count().reset_index()\nfig = px.pie(\n    data, \n    values=100 * data['row']/len(train_target), \n    names=\"count\", \n    title='Number of activations in targets for every sample (Percent)', \n    width=800, \n    height=500\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true},"cell_type":"markdown","source":"## We can see here that about 40% of sample have zeros in all columns and more than 50% have only one active target column."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_target.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"6\"></a>\n<h2 style='background:blue; border:0; color:white'><center>6. Train & Targets correlations</center><h2>"},{"metadata":{},"cell_type":"markdown","source":"## Time to find the most correlated features for every target column"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"start = time.time()\n\ncorrelation_matrix = pd.DataFrame()\nfor t_col in train_target.columns:\n    corr_list = list()\n    if t_col == 'sig_id':\n        continue\n    for col in columns:\n        res = train[col].corr(train_target[t_col])\n        corr_list.append(res)\n    correlation_matrix[t_col] = corr_list\n    \nprint(time.time()-start)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## And we have large correlation matrix"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"correlation_matrix['train_features'] = columns\ncorrelation_matrix = correlation_matrix.set_index('train_features')\ncorrelation_matrix","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's see what is the higher value (absolute) of correlation for target columns with every column from train set. Every column on chart is max correlation of current target column with all of columns from training set."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"maxCol=lambda x: max(x.min(), x.max(), key=abs)\nhigh_scores = correlation_matrix.apply(maxCol, axis=0).reset_index()\nhigh_scores.columns = ['column', 'best_correlation']\n\nfig = px.bar(\n    high_scores, \n    x='column', \n    y=\"best_correlation\", \n    orientation='v', \n    title='Best correlation with train columns for every target column', \n    width=1200,\n    height=800\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Now let's see what columns from training set have the higher number of \"high\" correlations with target columns. Every row from chart means that column `A` `N` times has the best value of correlation with different target columns. "},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"col_df = pd.DataFrame()\ntr_cols = list()\ntar_cols = list()\nfor col in correlation_matrix.columns:\n    tar_cols.append(col)\n    tr_cols.append(correlation_matrix[col].abs().sort_values(ascending=False).reset_index()['train_features'].head(1).values[0])\n\ncol_df['column'] = tar_cols\ncol_df['train_best_column'] = tr_cols\n\ntotal_scores = pd.merge(high_scores, col_df)\ntotal_scores","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"count_features = total_scores['train_best_column'].value_counts().reset_index().sort_values('train_best_column')\ncount_features.columns = ['column', 'count']\nfig = px.bar(\n    count_features.tail(33), \n    x='count', \n    y=\"column\", \n    orientation='h', \n    title='Columns from training set with number of high correlations with target columns', \n    width=800,\n    height=700\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Target columns and pairs of highly correlated features"},{"metadata":{},"cell_type":"markdown","source":"### Let's select some random columns and see how they deal with pairs of the highly correlated features"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"target_columns = train_target.columns.tolist()\ntarget_columns.remove('sig_id')\nfor_analysis = [target_columns[random.randint(0, len(target_columns)-1)] for i in range(5)]\ncurrent_corr = correlation_matrix[for_analysis]","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"col_df = pd.DataFrame()\ntr_first_cols = list()\ntr_second_cols = list()\ntar_cols = list()\nfor col in current_corr.columns:\n    tar_cols.append(col)\n    tr_first_cols.append(current_corr[col].abs().sort_values(ascending=False).reset_index()['train_features'].head(2).values[0])\n    tr_second_cols.append(current_corr[col].abs().sort_values(ascending=False).reset_index()['train_features'].head(2).values[1])\n\ncol_df['column'] = tar_cols\ncol_df['train_1_column'] = tr_first_cols\ncol_df['train_2_column'] = tr_second_cols\ncol_df","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def plot_scatter(col_df, index):\n    analysis = pd.DataFrame()\n    analysis['color'] = train_target[col_df.iloc[index]['column']]\n    analysis['x'] = train[col_df.iloc[index]['train_1_column']]\n    analysis['y'] = train[col_df.iloc[index]['train_2_column']]\n    analysis.columns = ['color', col_df.iloc[index]['train_1_column'], col_df.iloc[index]['train_2_column']]\n    analysis['size'] = 1\n    analysis.loc[analysis['color'] == 1, 'size'] = 10\n\n    fig = px.scatter(\n        analysis, \n        x=col_df.iloc[index]['train_1_column'], \n        y=col_df.iloc[index]['train_2_column'], \n        color=\"color\", \n        size='size', \n        height=800,\n        title='Scatter plot for ' + col_df.iloc[index]['column']\n    )\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plot_scatter(col_df, 0)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plot_scatter(col_df, 1)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plot_scatter(col_df, 2)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plot_scatter(col_df, 3)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plot_scatter(col_df, 4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let's do the same but for 3d plots"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"for_analysis = [target_columns[random.randint(0, len(target_columns)-1)] for i in range(5)]\ncurrent_corr = correlation_matrix[for_analysis]\n\ncol_df = pd.DataFrame()\ntr_first_cols = list()\ntr_second_cols = list()\ntr_third_cols = list()\ntar_cols = list()\nfor col in current_corr.columns:\n    tar_cols.append(col)\n    tr_first_cols.append(current_corr[col].abs().sort_values(ascending=False).reset_index()['train_features'].head(3).values[0])\n    tr_second_cols.append(current_corr[col].abs().sort_values(ascending=False).reset_index()['train_features'].head(3).values[1])\n    tr_third_cols.append(current_corr[col].abs().sort_values(ascending=False).reset_index()['train_features'].head(3).values[2])\n\n\ncol_df['column'] = tar_cols\ncol_df['train_1_column'] = tr_first_cols\ncol_df['train_2_column'] = tr_second_cols\ncol_df['train_3_column'] = tr_third_cols\ncol_df","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def plot_3dscatter(col_df, index):\n    analysis = pd.DataFrame()\n    analysis['color'] = train_target[col_df.iloc[index]['column']]\n    analysis['x'] = train[col_df.iloc[index]['train_1_column']]\n    analysis['y'] = train[col_df.iloc[index]['train_2_column']]\n    analysis['z'] = train[col_df.iloc[index]['train_3_column']]\n    analysis.columns = ['color', col_df.iloc[index]['train_1_column'], col_df.iloc[index]['train_2_column'], col_df.iloc[index]['train_3_column']]\n    analysis['size'] = 1\n    analysis.loc[analysis['color'] == 1, 'size'] = 20\n\n    fig = px.scatter_3d(\n        analysis, \n        x=col_df.iloc[index]['train_1_column'], \n        y=col_df.iloc[index]['train_2_column'],\n        z=col_df.iloc[index]['train_3_column'], \n        color=\"color\", \n        size='size', \n        height=800,\n        width=800,\n        title='Scatter plot for ' + col_df.iloc[index]['column']\n    )\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plot_3dscatter(col_df, 0)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plot_3dscatter(col_df, 1)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plot_3dscatter(col_df, 2)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plot_3dscatter(col_df, 3)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plot_3dscatter(col_df, 4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### We can extract several group names from target column names. Looks like that last term in column name is definition of a group. Let's extact them and visualize groups with number of columns > 1."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"last_term = dict()\nfor item in target_columns:\n    try:\n        last_term[item.split('_')[-1]] += 1\n    except:\n        last_term[item.split('_')[-1]] = 1\n\nlast_term = pd.DataFrame(last_term.items(), columns=['group', 'count'])\nlast_term = last_term.sort_values('count')\nlast_term = last_term[last_term['count']>1]\nlast_term['count'] = last_term['count'] * 100 / 206\n\nfig = px.bar(\n    last_term, \n    x='count', \n    y=\"group\", \n    orientation='h', \n    title='Groups in target columns (Percent from all target columns)', \n    width=800,\n    height=500\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Is it possible to have more than 1 activation for 1 sample in every group?"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"answer = list()\nfor group in last_term.group.tolist():\n    agent_list = list()\n    for item in target_columns:\n        if item.split('_')[-1] == group:\n            agent_list.append(item)\n    agent_df = train_target[agent_list]\n    data = agent_df.astype(bool).sum(axis=1).reset_index()\n    answer.append(data[0].max())","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"ds = pd.DataFrame()\nds['group'] = last_term.group.tolist()\nds['max_value'] = answer\n\nfig = px.bar(\n    ds, \n    x='max_value', \n    y=\"group\", \n    orientation='h', \n    title='Maximum number of active columns in 1 sample for every group', \n    width=800,\n    height=500\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## We can see that for groups activator, agent, blocker maximum number of active columns in sample is 1."},{"metadata":{},"cell_type":"markdown","source":"<a id=\"7\"></a>\n<h2 style='background:blue; border:0; color:white'><center>7. Targets & Train features dependecies</center><h2>"},{"metadata":{},"cell_type":"markdown","source":"### Let's check target columns with categorical columns from training set "},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"categories = train[['cp_type', 'cp_time', 'cp_dose']]\ntar = train_target.copy()\ntar = tar.drop(['sig_id'], axis=1)\nanalysis = pd.concat([categories, tar], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"for category in analysis['cp_dose'].unique().tolist():\n    number = 0\n    cols = []\n    for col in analysis.columns:\n        if col in ['cp_type', 'cp_time', 'cp_dose']:\n            continue\n        if len(analysis[analysis['cp_dose'] == category][col].value_counts()) == 1:\n            number += 1\n            cols.append(col)\n\n    print(category, '. Number of columns with 1 unique value: ', number, '. Columns: ', cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let's check problematic columns for dp_dose = 2"},{"metadata":{"trusted":true},"cell_type":"code","source":"analysis[analysis['cp_dose'] == 'D2']['atp-sensitive_potassium_channel_antagonist'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"analysis[analysis['cp_dose']=='D2']['erbb2_inhibitor'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"for category in analysis['cp_time'].unique().tolist():\n    number = 0\n    cols = []\n    for col in analysis.columns:\n        if col in ['cp_type', 'cp_time', 'cp_dose']:\n            continue\n        if len(analysis[analysis['cp_time']==category][col].value_counts()) == 1:\n            number += 1\n            cols.append(col)\n\n    print(category, '. Number of columns with 1 unique value: ', number, '. Columns: ', cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let's check problematic columns for cp_time = 24 and 72"},{"metadata":{"trusted":true},"cell_type":"code","source":"analysis[analysis['cp_time'] == 24]['erbb2_inhibitor'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"analysis[analysis['cp_time'] == 72]['erbb2_inhibitor'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"analysis[analysis['cp_time'] == 24]['atp-sensitive_potassium_channel_antagonist'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"analysis[analysis['cp_time'] == 72]['atp-sensitive_potassium_channel_antagonist'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"for category in analysis['cp_type'].unique().tolist():\n    number = 0\n    cols = []\n    for col in analysis.columns:\n        if col in ['cp_type', 'cp_time', 'cp_dose']:\n            continue\n        if len(analysis[analysis['cp_type']==category][col].value_counts()) == 1:\n            number += 1\n            cols.append(col)\n\n    print(category, '. Number of columns with 1 unique value: ', number, '. Columns: ', cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"analysis[analysis['cp_type']=='ctl_vehicle']['igf-1_inhibitor'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## We can see that for column ```cp_type``` all records where value is ```ctl_vehicle``` for all targets are 0. The same picture for ```cp_time``` == 72 ana == 24, but only for 2 target columns and for ```cp_dose``` == D2 also for 2 target columns.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}