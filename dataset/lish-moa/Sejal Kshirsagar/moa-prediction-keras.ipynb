{"cells":[{"metadata":{},"cell_type":"markdown","source":"Our aim is to predict multiple targets of the Mechanism of Action (MoA) response(s) of different samples (`sig_id`), given various inputs such as gene expression data and cell viability data."},{"metadata":{},"cell_type":"markdown","source":"# 1. Import Packages"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport random\nimport numpy as np \nimport pandas as pd \nimport tensorflow as tf\nfrom sklearn.metrics import log_loss\nfrom sklearn.model_selection import KFold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SEED = 9\ndef all_seeds(s):\n    random.seed(s)\n    os.environ['PYTHONHASHSEED'] = str(s)\n    np.random.seed(s)\n    tf.random.set_seed(s)\n    \nall_seeds(SEED)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Load Data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv('../input/lish-moa/test_features.csv')\ntrain_df = pd.read_csv('../input/lish-moa/train_features.csv')\ntr_target_df = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\nsample_df = pd.read_csv('../input/lish-moa/sample_submission.csv')\n\ntarget_cols = tr_target_df.columns[1:]\nN_TARGETS = len(target_cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Preprocess Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_df(df):\n    df['cp_type'] = (df['cp_type'] == 'trt_cp').astype(int)\n    df['cp_dose'] = (df['cp_dose'] == 'D2').astype(int)\n    return df\n\nx_train = preprocess_df(train_df.drop(columns=\"sig_id\"))\ny_train = tr_target_df.drop(columns=\"sig_id\")\nx_test = preprocess_df(test_df.drop(columns=\"sig_id\"))\n\nN_FEATURES = x_train.shape[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of Features:\",N_FEATURES)\nprint(\"Number of Targets:\",N_TARGETS)\nprint(\"x_train shape:\",x_train.shape)\nprint(\"y_train shape:\",y_train.shape)\nprint(\"x_test shape:\",x_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Building Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS = 64\nBATCH_SIZE = 128\nFOLDS = 5\nREPEATS = 5\nLR = 0.0008\nN_TARGETS = len(target_cols)\n\ndef multi_log_loss(y_true, y_pred):\n    losses = []\n    for col in y_true.columns:\n        losses.append(log_loss(y_true.loc[:, col], y_pred.loc[:, col]))\n    return np.mean(losses)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def my_model():\n    model = tf.keras.Sequential([\n        \n                tf.keras.layers.Input(N_FEATURES), \n                tf.keras.layers.BatchNormalization(),\n                tf.keras.layers.Dropout(0.1),\n        \n                tf.keras.layers.Dense(3500, activation=\"relu\"),\n                tf.keras.layers.BatchNormalization(),\n                tf.keras.layers.Dropout(0.4),\n        \n                tf.keras.layers.Dense(1750, activation=\"relu\"),\n                tf.keras.layers.BatchNormalization(),\n                tf.keras.layers.Dropout(0.2),\n                \n                tf.keras.layers.Dense(875, activation=\"relu\"),\n                tf.keras.layers.BatchNormalization(),\n                tf.keras.layers.Dropout(0.1),\n                \n                tf.keras.layers.Dense(412, activation=\"relu\"),\n                tf.keras.layers.BatchNormalization(),\n                tf.keras.layers.Dropout(0.2),\n        \n                tf.keras.layers.Dense(N_TARGETS, activation=\"sigmoid\") \n            ])\n    \n    model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = LR),\n                  loss = 'binary_crossentropy', \n                  metrics = [\"accuracy\"])\n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(resume_models = None, repeat_number = 0, folds = 5, skip_folds = 0):\n    \n    models = []\n    oof_pred = y_train.copy()  \n\n    kfold = KFold(folds, shuffle = True, random_state = 9)\n    for fold, (i_tr, i_va) in enumerate(kfold.split(x_train)):\n\n        print('-'*85)\n        print(f'Repeat {repeat_number}, Fold {fold}')\n        \n        cb_lr_schedule = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_loss', \n                                                              factor = 0.4, \n                                                              patience = 1, \n                                                              verbose = 2, \n                                                              min_delta = 0.0001, \n                                                              mode = 'auto')\n        \n        cb_early_stop = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', \n                                                         min_delta = 0, \n                                                         patience = 4, \n                                                         verbose = 1, \n                                                         mode = 'min')\n        \n        checkpt_path = f'repeat:{repeat_number}_Fold:{fold}.hdf5'\n        cb_checkpt = tf.keras.callbacks.ModelCheckpoint(checkpt_path, \n                                                        monitor = 'val_loss', \n                                                        verbose = 2, \n                                                        save_best_only = True, \n                                                        save_weights_only = True, \n                                                        mode = 'min')\n\n        model = my_model()\n        model.fit(x_train.values[i_tr], y_train.values[i_tr],\n                  validation_data = (x_train.values[i_va], y_train.values[i_va]),\n                  callbacks = [cb_lr_schedule, cb_early_stop, cb_checkpt],\n                  epochs = EPOCHS, \n                  batch_size = BATCH_SIZE, \n                  verbose = 2)\n        \n        model.load_weights(checkpt_path)\n        oof_pred.loc[i_va, :] = model.predict(x_train.values[i_va])\n        models.append(model)\n\n    return models, oof_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = []\noof_pred = []\n\nfor i in range(REPEATS):\n    m, oof = train(repeat_number = i, folds = FOLDS)\n    print('-'*85)\n    models = models + m\n    oof_pred.append(oof)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6. Mean OOF Log Loss"},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_oof_pred = y_train.copy()\nmean_oof_pred.loc[:, target_cols] = 0\nfor i, p in enumerate(oof_pred):\n    print(f\"Repeat {i} OOF Log Loss: {multi_log_loss(y_train, p)}\")\n    mean_oof_pred.loc[:, target_cols] += p[target_cols]\n\nmean_oof_pred.loc[:, target_cols] /= len(oof_pred)\nprint(f\"Mean OOF Log Loss: {multi_log_loss(y_train, mean_oof_pred)}\")\nmean_oof_pred.loc[x_train['cp_type'] == 0, target_cols] = 0\nprint(f\"Mean OOF Log Loss (ctl adjusted): {multi_log_loss(y_train, mean_oof_pred)}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7. Predictions and Submission File"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred = sample_df.copy()\ntest_pred[target_cols] = 0\n\nfor model in models:\n    test_pred.loc[:,target_cols] += model.predict(x_test)\ntest_pred.loc[:,target_cols] /= len(models)\ntest_pred.loc[x_test['cp_type'] == 0, target_cols] = 0\ntest_pred.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}