{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\ntest = pd.read_csv('../input/lish-moa/test_features.csv')\nif len(test) == 3982:\n    submission = pd.read_csv('../input/lish-moa/sample_submission.csv')\n    submission.to_csv('submission.csv', index=False)\nelse:\n    !pip install ../input/pytorchtabnetpretraining/pytorch_tabnet-2.0.1-py3-none-any.whl\n    !pip install /kaggle/input/iterative-stratification/iterative-stratification-master/\n    import sys\n    sys.path.append(\"../input/rank-gauss\")\n    import torch\n    from torch import nn\n    from torch.utils.data import DataLoader, Dataset\n    from torch.nn.modules.loss import _WeightedLoss\n    import torch.optim as optim\n    import torch.nn.functional as F\n    from torch.optim.lr_scheduler import ReduceLROnPlateau\n    from sklearn.model_selection import StratifiedKFold\n\n\n    from gauss_rank_scaler import GaussRankScaler\n    from sklearn.decomposition import PCA\n\n    from pytorch_tabnet.tab_model import TabNetRegressor\n    import numpy as np\n    import pandas as pd \n\n    import os\n    import random\n    os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n    import tqdm\n    import pickle\n    from sklearn.metrics import log_loss\n\n    from iterstrat.ml_stratifiers import MultilabelStratifiedKFold, MultilabelStratifiedShuffleSplit\n    from sklearn.metrics import roc_auc_score\n\n    from colorama import Fore\n    c_ = Fore.CYAN\n    m_ = Fore.MAGENTA\n    r_ = Fore.RED\n    b_ = Fore.BLUE\n    y_ = Fore.YELLOW\n    g_ = Fore.GREEN\n    \n    def seed_everything(seed_value):\n        random.seed(seed_value)\n        np.random.seed(seed_value)\n        torch.manual_seed(seed_value)\n        os.environ['PYTHONHASHSEED'] = str(seed_value)\n\n        if torch.cuda.is_available():\n            torch.cuda.manual_seed(seed_value)\n            torch.cuda.manual_seed_all(seed_value)\n            torch.backends.cudnn.deterministic = True\n            torch.backends.cudnn.benchmark = False\n\n    seed_everything(42)\n    seed = 42\n    data_path = \"../input/lish-moa/\"\n    no_ctl = True\n    scale = \"rankgauss\"\n    variance_threshould = 0.7\n    decompo = \"PCA\"\n    ncompo_genes = 80\n    ncompo_cells = 10\n    encoding = \"dummy\"\n    \n    train = pd.read_csv(data_path + \"train_features.csv\")\n    # train.drop(columns=[\"sig_id\"], inplace=True)\n\n\n    drug = pd.read_csv(data_path +'train_drug.csv')\n\n    targets = pd.read_csv(data_path + \"train_targets_scored.csv\")\n\n    test = pd.read_csv(data_path+'test_features.csv')\n    # test.drop(columns=[\"sig_id\"], inplace=True)\n\n    submission = pd.read_csv(data_path+'sample_submission.csv')\n    if no_ctl:\n        # cp_type == ctl_vehicle\n        print(b_, \"not_ctl\")\n        train = train[train[\"cp_type\"] != \"ctl_vehicle\"]\n        test = test[test[\"cp_type\"] != \"ctl_vehicle\"]\n        targets = targets.iloc[train.index]\n        train.reset_index(drop = True, inplace = True)\n        test.reset_index(drop = True, inplace = True)\n        targets.reset_index(drop = True, inplace = True)\n    data_all = pd.concat([train, test], ignore_index = True)\n    cols_numeric = [feat for feat in list(data_all.columns) if feat not in [\"sig_id\", \"cp_type\", \"cp_time\", \"cp_dose\"]]\n    mask = (data_all[cols_numeric].var() >= variance_threshould).values\n    tmp = data_all[cols_numeric].loc[:, mask]\n    data_all = pd.concat([data_all[[\"sig_id\", \"cp_type\", \"cp_time\", \"cp_dose\"]], tmp], axis = 1)\n    cols_numeric = [feat for feat in list(data_all.columns) if feat not in [\"sig_id\", \"cp_type\", \"cp_time\", \"cp_dose\"]]\n    \n    def scale_minmax(col):\n        return (col - col.min()) / (col.max() - col.min())\n\n\n    def scale_norm(col):\n        return (col - col.mean()) / col.std()\n\n    if scale == \"boxcox\":\n        print(b_, \"boxcox\")\n        data_all[cols_numeric] = data_all[cols_numeric].apply(scale_minmax, axis=0)\n        trans = []\n        for feat in cols_numeric:\n            trans_var, lambda_var = stats.boxcox(data_all[feat].dropna() + 1)\n            trans.append(scale_minmax(trans_var))\n        data_all[cols_numeric] = np.asarray(trans).T\n\n    elif scale == \"norm\":\n        print(b_, \"norm\")\n        data_all[cols_numeric] = data_all[cols_numeric].apply(scale_norm, axis=0)\n\n    elif scale == \"minmax\":\n        print(b_, \"minmax\")\n        data_all[cols_numeric] = data_all[cols_numeric].apply(scale_minmax, axis=0)\n\n    elif scale == \"rankgauss\":\n        ### Rank Gauss ###\n        print(b_, \"Rank Gauss\")\n        scaler = GaussRankScaler()\n        data_all[cols_numeric] = scaler.fit_transform(data_all[cols_numeric])\n    else:\n        pass\n    \n    if decompo == \"PCA\":\n        print(b_, \"PCA\")\n        GENES = [col for col in data_all.columns if col.startswith(\"g-\")]\n        CELLS = [col for col in data_all.columns if col.startswith(\"c-\")]\n\n        pca_genes = PCA(n_components=ncompo_genes,\n                        random_state=seed).fit_transform(data_all[GENES])\n        pca_cells = PCA(n_components=ncompo_cells,\n                        random_state=seed).fit_transform(data_all[CELLS])\n\n        pca_genes = pd.DataFrame(pca_genes, columns=[f\"pca_g-{i}\" for i in range(ncompo_genes)])\n        pca_cells = pd.DataFrame(pca_cells, columns=[f\"pca_c-{i}\" for i in range(ncompo_cells)])\n        data_all = pd.concat([data_all, pca_genes, pca_cells], axis=1)\n    else:\n        pass\n    if encoding == \"lb\":\n        print(b_, \"Label Encoding\")\n        for feat in [\"cp_time\", \"cp_dose\"]:\n            data_all[feat] = LabelEncoder().fit_transform(data_all[feat])\n    elif encoding == \"dummy\":\n        print(b_, \"One-Hot\")\n        data_all = pd.get_dummies(data_all, columns = [\"cp_time\", \"cp_dose\"])\n    \n    GENES = [col for col in data_all.columns if col.startswith(\"g-\")]\n    CELLS = [col for col in data_all.columns if col.startswith(\"c-\")]\n\n    for stats in tqdm.tqdm([\"sum\", \"mean\", \"std\", \"kurt\", \"skew\"]):\n        data_all[\"g_\" + stats] = getattr(data_all[GENES], stats)(axis = 1)\n        data_all[\"c_\" + stats] = getattr(data_all[CELLS], stats)(axis = 1)\n        data_all[\"gc_\" + stats] = getattr(data_all[GENES + CELLS], stats)(axis = 1)\n\n    with open(\"data_all.pickle\", \"wb\") as f:\n        pickle.dump(data_all, f)\n\n    with open(\"data_all.pickle\", \"rb\") as f:\n        data_all = pickle.load(f)\n    # train_df and test_df\n    features_to_drop = [\"sig_id\", \"cp_type\"]\n    data_all.drop(features_to_drop, axis = 1, inplace = True)\n    try:\n        targets.drop(\"sig_id\", axis = 1, inplace = True)\n    except:\n        pass\n\n    train = data_all[: train.shape[0]]\n    train.reset_index(drop = True, inplace = True)\n    # The following line it's a bad practice in my opinion, targets on train set\n    #train_df = pd.concat([train_df, targets], axis = 1)\n    test = data_all[train.shape[0]: ]\n    test.reset_index(drop = True, inplace = True)\n    X_test = test.values\n    \n    from pytorch_tabnet.metrics import Metric\n    from sklearn.metrics import roc_auc_score, log_loss\n\n    class LogitsLogLoss(Metric):\n        \"\"\"\n        LogLoss with sigmoid applied\n        \"\"\"\n\n        def __init__(self):\n            self._name = \"logits_ll\"\n            self._maximize = False\n\n        def __call__(self, y_true, y_pred):\n            \"\"\"\n            Compute LogLoss of predictions.\n\n            Parameters\n            ----------\n            y_true: np.ndarray\n                Target matrix or vector\n            y_score: np.ndarray\n                Score matrix or vector\n            Returns\n            -------\n                float\n                LogLoss of predictions vs targets.\n            \"\"\"\n            logits = 1 / (1 + np.exp(-y_pred))\n            aux = (1-y_true)*np.log(1-logits+1e-15) + y_true*np.log(logits+1e-15)\n            return np.mean(-aux)\n\n    from pytorch_tabnet.pretraining import TabNetPretrainer\n    \n    tabnet_params = dict(\n        n_d = 32,\n        n_a = 32,\n        n_steps = 1,\n        gamma = 1.3,\n        lambda_sparse = 0,\n        optimizer_fn = optim.Adam,\n        optimizer_params = dict(lr = 2e-2, weight_decay = 1e-5),\n        mask_type = \"entmax\",\n        scheduler_params = dict(\n            mode = \"min\", patience = 5, min_lr = 1e-5, factor = 0.9),\n        scheduler_fn = ReduceLROnPlateau,\n        seed = seed,\n        verbose = 10\n    )\n\n    pretrainer = TabNetPretrainer(**tabnet_params)\n\n    pretrainer.fit(\n        X_train=np.vstack([train.values[int(0.1*train.values.shape[0]):], test.values]), #  np.vstack([train.values[:,1:], test.values[:,1:]])\n        eval_set=[train.values[:int(0.1*train.values.shape[0])]],\n        max_epochs=50,\n        patience=10,\n        batch_size=1024,\n        virtual_batch_size=32, #128,\n        num_workers=0, \n        drop_last=False,\n        pretraining_ratio=0.8)\n    \n    class SmoothBCEwLogits(_WeightedLoss):\n        def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n            super().__init__(weight=weight, reduction=reduction)\n            self.smoothing = smoothing\n            self.weight = weight\n            self.reduction = reduction\n\n        @staticmethod\n        def _smooth(targets:torch.Tensor, n_labels:int, smoothing=0.0):\n            assert 0 <= smoothing < 1\n            with torch.no_grad():\n                targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n            return targets\n\n        def forward(self, inputs, targets):\n            targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1),\n                self.smoothing)\n            # loss = self.focal(inputs, targets)\n            loss = F.binary_cross_entropy_with_logits(inputs, targets,self.weight)\n\n            if  self.reduction == 'sum':\n                loss = loss.sum()\n            elif  self.reduction == 'mean':\n                loss = loss.mean()\n\n            return loss\n\n    scores_auc_all= []\n    test_cv_preds = []\n    NB_SPLITS = 10  # 7\n    mskf = MultilabelStratifiedKFold(n_splits=NB_SPLITS, random_state=0, shuffle=True)\n    criterion = SmoothBCEwLogits(smoothing=0.0001)\n    oof_preds = []\n    oof_targets = []\n    scores = []\n    scores_auc = []\n    for fold_nb, (train_idx, val_idx) in enumerate(mskf.split(train, targets)):\n        print(b_, \"FOLDS: \", r_, fold_nb + 1)\n        print(g_, '*' * 60, c_)\n        X_train, y_train = train.values[train_idx, :], targets.values[train_idx, :]\n        X_val, y_val = train.values[val_idx, :], targets.values[val_idx, :]\n\n        model = TabNetRegressor(**tabnet_params)\n\n        model.fit(\n                X_train = X_train,\n                y_train = y_train,\n                eval_set = [(X_val, y_val)],\n                eval_name = [\"val\"],\n                eval_metric = [\"logits_ll\"],\n                max_epochs = 200,\n                patience = 20,\n                batch_size = 1024, \n                virtual_batch_size = 32,\n                num_workers = 1,\n                drop_last = False,\n                # To use binary cross entropy because this is not a regression problem\n                loss_fn = F.binary_cross_entropy_with_logits\n            )\n        \n        ## save oof to compute the CV later \n        print(y_, '-' * 60)\n        ### Predict on validation ###\n        preds_val = model.predict(X_val)\n        # Apply sigmoid to the predictions\n        preds =  1 / (1 + np.exp(-preds_val))\n        score = np.min(model.history[\"val_logits_ll\"])\n        scores.append(score)\n        oof_preds.append(preds_val)\n        oof_targets.append(y_val)\n        ### Predict on test ###\n        preds_test = model.predict(X_test)\n        test_cv_preds.append(1 / (1 + np.exp(-preds_test)))\n\n    oof_preds_all = np.concatenate(oof_preds)\n    oof_targets_all = np.concatenate(oof_targets)\n    test_preds_all = np.stack(test_cv_preds)\n\n    aucs = []\n    for task_id in range(oof_preds_all.shape[1]):\n        aucs.append(roc_auc_score(y_true=oof_targets_all[:, task_id],\n                                  y_score=oof_preds_all[:, task_id]))\n    print(f\"{b_}Overall AUC: {r_}{np.mean(aucs)}\")\n    print(f\"{b_}Average CV: {r_}{np.mean(scores)}\")\n\n    all_feat = [col for col in submission.columns if col not in [\"sig_id\"]]\n    # To obtain the same lenght of test_preds_all and submission\n    test = pd.read_csv(data_path + \"test_features.csv\")\n    sig_id = test[test[\"cp_type\"] != \"ctl_vehicle\"].sig_id.reset_index(drop = True)\n    tmp = pd.DataFrame(test_preds_all.mean(axis = 0), columns = all_feat)\n    tmp[\"sig_id\"] = sig_id\n\n    submission = pd.merge(test[[\"sig_id\"]], tmp, on = \"sig_id\", how = \"left\")\n    submission.fillna(0, inplace = True)\n\n    #submission[all_feat] = tmp.mean(axis = 0)\n\n    # Set control to 0\n    #submission.loc[test[\"cp_type\"] == 0, submission.columns[1:]] = 0\n    submission.to_csv(\"submission.csv\", index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}