{"cells":[{"metadata":{"_uuid":"a1d4deda-959e-44f1-ba1c-e159bfde89dc","_cell_guid":"8e6514b4-9d88-4223-a7cd-ae3148f2db22","trusted":true},"cell_type":"code","source":"import pandas as pd\ntest = pd.read_csv('../input/lish-moa/test_features.csv')\nif len(test) == 3982:\n    submission = pd.read_csv('../input/lish-moa/sample_submission.csv')\n    submission.to_csv('submission.csv', index=False)\nelse:\n    # TabNet\n    !pip install --no-index --find-links /kaggle/input/pytorchtabnet/pytorch_tabnet-2.0.0-py3-none-any.whl pytorch-tabnet\n    # Iterative Stratification\n    !pip install /kaggle/input/iterative-stratification/iterative-stratification-master/\n\n    ### General ###\n    import os\n    import sys\n    import copy\n    import tqdm\n    import pickle\n    import random\n    import warnings\n    warnings.filterwarnings(\"ignore\")\n    sys.path.append(\"../input/rank-gauss\")\n    os.environ[\"CUDA_LAUNCH_BLOCKING\"] = '1'\n\n    ### Data Wrangling ###\n    import numpy as np\n    import pandas as pd\n    from scipy import stats\n    from gauss_rank_scaler import GaussRankScaler\n\n    ### Data Visualization ###\n    import seaborn as sns\n    import matplotlib.pyplot as plt\n    plt.style.use(\"fivethirtyeight\")\n\n    ### Machine Learning ###\n    from sklearn.decomposition import PCA\n    from sklearn.preprocessing import LabelEncoder\n    from sklearn.metrics import roc_auc_score, log_loss\n    from sklearn.preprocessing import QuantileTransformer\n    from sklearn.feature_selection import VarianceThreshold\n    from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n\n    ### Deep Learning ###\n    import torch\n    from torch import nn\n    import torch.optim as optim\n    from torch.nn import functional as F\n    from torch.nn.modules.loss import _WeightedLoss\n    from torch.utils.data import DataLoader, Dataset\n    from torch.optim.lr_scheduler import ReduceLROnPlateau\n    # Tabnet \n    from pytorch_tabnet.metrics import Metric\n    from pytorch_tabnet.tab_model import TabNetRegressor\n\n    ### Make prettier the prints ###\n    from colorama import Fore\n    c_ = Fore.CYAN\n    m_ = Fore.MAGENTA\n    r_ = Fore.RED\n    b_ = Fore.BLUE\n    y_ = Fore.YELLOW\n    g_ = Fore.GREEN\n\n    seed = 42\n\n    def set_seed(seed):\n        random.seed(seed)\n        np.random.seed(seed)\n        torch.manual_seed(seed)\n        os.environ[\"PYTHONHASHSEED\"] = str(seed)\n\n        if torch.cuda.is_available():\n            torch.cuda.manual_seed(seed)\n            torch.cuda.manual_seed_all(seed)\n            torch.backends.cudnn.deterministic = True\n            torch.backends.cudnn.benchmark = False\n    set_seed(seed)\n\n    # Parameters\n    data_path = \"../input/lish-moa/\"\n    no_ctl = True\n    scale = \"rankgauss\"\n    variance_threshould = 0.7\n    decompo = \"PCA\"\n    ncompo_genes = 80\n    ncompo_cells = 10\n    encoding = \"dummy\"\n\n\n    train = pd.read_csv(data_path + \"train_features.csv\")\n    #train.drop(columns = [\"sig_id\"], inplace = True)\n\n    targets = pd.read_csv(data_path + \"train_targets_scored.csv\")\n    #train_targets_scored.drop(columns = [\"sig_id\"], inplace = True)\n\n    #train_targets_nonscored = pd.read_csv(data_path + \"train_targets_nonscored.csv\")\n\n    test = pd.read_csv(data_path + \"test_features.csv\")\n    #test.drop(columns = [\"sig_id\"], inplace = True)\n\n    submission = pd.read_csv(data_path + \"sample_submission.csv\")\n\n    if no_ctl:\n        # cp_type == ctl_vehicle\n        print(b_, \"not_ctl\")\n        train = train[train[\"cp_type\"] != \"ctl_vehicle\"]\n        test = test[test[\"cp_type\"] != \"ctl_vehicle\"]\n        targets = targets.iloc[train.index]\n        train.reset_index(drop = True, inplace = True)\n        test.reset_index(drop = True, inplace = True)\n        targets.reset_index(drop = True, inplace = True)\n\n\n\n    data_all = pd.concat([train, test], ignore_index = True)\n    cols_numeric = [feat for feat in list(data_all.columns) if feat not in [\"sig_id\", \"cp_type\", \"cp_time\", \"cp_dose\"]]\n    mask = (data_all[cols_numeric].var() >= variance_threshould).values\n    tmp = data_all[cols_numeric].loc[:, mask]\n    data_all = pd.concat([data_all[[\"sig_id\", \"cp_type\", \"cp_time\", \"cp_dose\"]], tmp], axis = 1)\n    cols_numeric = [feat for feat in list(data_all.columns) if feat not in [\"sig_id\", \"cp_type\", \"cp_time\", \"cp_dose\"]]\n\n    def scale_minmax(col):\n        return (col - col.min()) / (col.max() - col.min())\n\n    def scale_norm(col):\n        return (col - col.mean()) / col.std()\n\n    if scale == \"boxcox\":\n        print(b_, \"boxcox\")\n        data_all[cols_numeric] = data_all[cols_numeric].apply(scale_minmax, axis = 0)\n        trans = []\n        for feat in cols_numeric:\n            trans_var, lambda_var = stats.boxcox(data_all[feat].dropna() + 1)\n            trans.append(scale_minmax(trans_var))\n        data_all[cols_numeric] = np.asarray(trans).T\n\n    elif scale == \"norm\":\n        print(b_, \"norm\")\n        data_all[cols_numeric] = data_all[cols_numeric].apply(scale_norm, axis = 0)\n\n    elif scale == \"minmax\":\n        print(b_, \"minmax\")\n        data_all[cols_numeric] = data_all[cols_numeric].apply(scale_minmax, axis = 0)\n\n    elif scale == \"rankgauss\":\n        ### Rank Gauss ###\n        print(b_, \"Rank Gauss\")\n        scaler = GaussRankScaler()\n        data_all[cols_numeric] = scaler.fit_transform(data_all[cols_numeric])\n\n    else:\n        pass\n\n\n    # PCA\n    if decompo == \"PCA\":\n        print(b_, \"PCA\")\n        GENES = [col for col in data_all.columns if col.startswith(\"g-\")]\n        CELLS = [col for col in data_all.columns if col.startswith(\"c-\")]\n\n        pca_genes = PCA(n_components = ncompo_genes,\n                        random_state = seed).fit_transform(data_all[GENES])\n        pca_cells = PCA(n_components = ncompo_cells,\n                        random_state = seed).fit_transform(data_all[CELLS])\n\n        pca_genes = pd.DataFrame(pca_genes, columns = [f\"pca_g-{i}\" for i in range(ncompo_genes)])\n        pca_cells = pd.DataFrame(pca_cells, columns = [f\"pca_c-{i}\" for i in range(ncompo_cells)])\n        data_all = pd.concat([data_all, pca_genes, pca_cells], axis = 1)\n    else:\n        pass\n\n\n    # Encoding\n    if encoding == \"lb\":\n        print(b_, \"Label Encoding\")\n        for feat in [\"cp_time\", \"cp_dose\"]:\n            data_all[feat] = LabelEncoder().fit_transform(data_all[feat])\n    elif encoding == \"dummy\":\n        print(b_, \"One-Hot\")\n        data_all = pd.get_dummies(data_all, columns = [\"cp_time\", \"cp_dose\"])\n\n    GENES = [col for col in data_all.columns if col.startswith(\"g-\")]\n    CELLS = [col for col in data_all.columns if col.startswith(\"c-\")]\n\n    for stats in tqdm.tqdm([\"sum\", \"mean\", \"std\", \"kurt\", \"skew\"]):\n        data_all[\"g_\" + stats] = getattr(data_all[GENES], stats)(axis = 1)\n        data_all[\"c_\" + stats] = getattr(data_all[CELLS], stats)(axis = 1)    \n        data_all[\"gc_\" + stats] = getattr(data_all[GENES + CELLS], stats)(axis = 1)\n\n\n\n    with open(\"data_all.pickle\", \"wb\") as f:\n        pickle.dump(data_all, f)\n\n    with open(\"data_all.pickle\", \"rb\") as f:\n        data_all = pickle.load(f)\n\n    # train_df and test_df\n    features_to_drop = [\"sig_id\", \"cp_type\"]\n    data_all.drop(features_to_drop, axis = 1, inplace = True)\n    try:\n        targets.drop(\"sig_id\", axis = 1, inplace = True)\n    except:\n        pass\n    train_df = data_all[: train.shape[0]]\n    train_df.reset_index(drop = True, inplace = True)\n    # The following line it's a bad practice in my opinion, targets on train set\n    #train_df = pd.concat([train_df, targets], axis = 1)\n    test_df = data_all[train_df.shape[0]: ]\n    test_df.reset_index(drop = True, inplace = True)\n\n    print(f\"{b_}train_df.shape: {r_}{train_df.shape}\")\n    print(f\"{b_}test_df.shape: {r_}{test_df.shape}\")\n\n    X_test = test_df.values\n    print(f\"{b_}X_test.shape: {r_}{X_test.shape}\")\n\n\n    MAX_EPOCH = 200\n    # n_d and n_a are different from the original work, 32 instead of 24\n    # This is the first change in the code from the original\n    tabnet_params = dict(\n        n_d = 32,\n        n_a = 32,\n        n_steps = 1,\n        gamma = 1.3,\n        lambda_sparse = 0,\n        optimizer_fn = optim.Adam,\n        optimizer_params = dict(lr = 2e-2, weight_decay = 1e-5),\n        mask_type = \"entmax\",\n        scheduler_params = dict(\n            mode = \"min\", patience = 5, min_lr = 1e-5, factor = 0.9),\n        scheduler_fn = ReduceLROnPlateau,\n        seed = seed,\n        verbose = 10\n    )\n\n    class LogitsLogLoss(Metric):\n        \"\"\"\n        LogLoss with sigmoid applied\n        \"\"\"\n\n        def __init__(self):\n            self._name = \"logits_ll\"\n            self._maximize = False\n\n        def __call__(self, y_true, y_pred):\n            \"\"\"\n            Compute LogLoss of predictions.\n\n            Parameters\n            ----------\n            y_true: np.ndarray\n                Target matrix or vector\n            y_score: np.ndarray\n                Score matrix or vector\n\n            Returns\n            -------\n                float\n                LogLoss of predictions vs targets.\n            \"\"\"\n            logits = 1 / (1 + np.exp(-y_pred))\n            aux = (1 - y_true) * np.log(1 - logits + 1e-15) + y_true * np.log(logits + 1e-15)\n            return np.mean(-aux)\n\n    scores_auc_all = []\n    test_cv_preds = []\n\n    NB_SPLITS = 10 # 7\n\n    oof_preds = []\n    oof_targets = []\n    scores = []\n    scores_auc = []\n    for seed in [0, 1, 2]:\n        set_seed(seed)\n        mskf = MultilabelStratifiedKFold(n_splits = NB_SPLITS, random_state = seed, shuffle = True)\n        for fold_nb, (train_idx, val_idx) in enumerate(mskf.split(train_df, targets)):\n            print(b_,\"FOLDS: \", r_, fold_nb + 1)\n            print(g_, '*' * 60, c_)\n\n            X_train, y_train = train_df.values[train_idx, :], targets.values[train_idx, :]\n            X_val, y_val = train_df.values[val_idx, :], targets.values[val_idx, :]\n            ### Model ###\n            model = TabNetRegressor(**tabnet_params)\n\n            ### Fit ###\n            # Another change to the original code\n            # virtual_batch_size of 32 instead of 128\n            model.fit(\n                X_train = X_train,\n                y_train = y_train,\n                eval_set = [(X_val, y_val)],\n                eval_name = [\"val\"],\n                eval_metric = [\"logits_ll\"],\n                max_epochs = MAX_EPOCH,\n                patience = 20,\n                batch_size = 1024, \n                virtual_batch_size = 32,\n                num_workers = 1,\n                drop_last = False,\n                # To use binary cross entropy because this is not a regression problem\n                loss_fn = F.binary_cross_entropy_with_logits\n            )\n            print(y_, '-' * 60)\n\n            ### Predict on validation ###\n            preds_val = model.predict(X_val)\n            # Apply sigmoid to the predictions\n            preds = 1 / (1 + np.exp(-preds_val))\n            score = np.min(model.history[\"val_logits_ll\"])\n\n            ### Save OOF for CV ###\n            oof_preds.append(preds_val)\n            oof_targets.append(y_val)\n            scores.append(score)\n\n            ### Predict on test ###\n            preds_test = model.predict(X_test)\n            test_cv_preds.append(1 / (1 + np.exp(-preds_test)))\n\n    oof_preds_all = np.concatenate(oof_preds)\n    oof_targets_all = np.concatenate(oof_targets)\n    test_preds_all = np.stack(test_cv_preds)\n\n    aucs = []\n    for task_id in range(oof_preds_all.shape[1]):\n        aucs.append(roc_auc_score(y_true = oof_targets_all[:, task_id],\n                                  y_score = oof_preds_all[:, task_id]\n                                 ))\n    print(f\"{b_}Overall AUC: {r_}{np.mean(aucs)}\")\n    print(f\"{b_}Average CV: {r_}{np.mean(scores)}\")\n\n    all_feat = [col for col in submission.columns if col not in [\"sig_id\"]]\n    # To obtain the same lenght of test_preds_all and submission\n    test = pd.read_csv(data_path + \"test_features.csv\")\n    sig_id = test[test[\"cp_type\"] != \"ctl_vehicle\"].sig_id.reset_index(drop = True)\n    tmp = pd.DataFrame(test_preds_all.mean(axis = 0), columns = all_feat)\n    tmp[\"sig_id\"] = sig_id\n\n    submission = pd.merge(test[[\"sig_id\"]], tmp, on = \"sig_id\", how = \"left\")\n    submission.fillna(0, inplace = True)\n\n    #submission[all_feat] = tmp.mean(axis = 0)\n\n    # Set control to 0\n    #submission.loc[test[\"cp_type\"] == 0, submission.columns[1:]] = 0\n    submission.to_csv(\"submission.csv\", index = None)\n    submission.head()\n\n    print(f\"{b_}submission.shape: {r_}{submission.shape}\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}