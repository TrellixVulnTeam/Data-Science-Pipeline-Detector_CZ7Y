{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\n\n!cp ../input/rapids/rapids.0.15.0 /opt/conda/envs/rapids.tar.gz\n!cd /opt/conda/envs/ && tar -xzvf rapids.tar.gz > /dev/null\nsys.path = [\"/opt/conda/envs/rapids/lib/python3.7/site-packages\"] + sys.path\nsys.path = [\"/opt/conda/envs/rapids/lib/python3.7\"] + sys.path\nsys.path = [\"/opt/conda/envs/rapids/lib\"] + sys.path\n!cp /opt/conda/envs/rapids/lib/libxgboost.so /opt/conda/lib/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cudf, cuml\nfrom sklearn.metrics import log_loss\nimport numpy as np\nimport cupy\nfrom tqdm import tqdm\nimport pandas as pd, xgboost as xgb\nfrom sklearn.metrics import log_loss\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_svm_sub():\n    DIR = \"/kaggle/input/lish-moa\"\n\n    df = cudf.read_csv(f\"{DIR}/train_features.csv\")\n\n    target_df = cudf.read_csv(f\"{DIR}/train_targets_scored.csv\")\n    targets = [col for col in target_df.columns if col != \"sig_id\"]\n\n    tns_df = cudf.read_csv(f\"{DIR}/train_targets_nonscored.csv\")\n    tns = [col for col in tns_df.columns if col != \"sig_id\"]\n\n    df = df.merge(target_df, on=\"sig_id\").merge(tns_df, on=\"sig_id\")\n\n    test_df = cudf.read_csv(f\"{DIR}/test_features.csv\")\n\n    gene_features = [col for col in df.columns if col.startswith(\"g-\")]\n    cell_features = [col for col in df.columns if col.startswith(\"c-\")]\n\n    for data in [df, test_df]:\n        data[\"cp_time\"] = data[\"cp_time\"]/72\n        data[\"cp_dose\"] = 1.0*(data[\"cp_dose\"] == \"D1\")\n\n\n    smooth_df = cudf.DataFrame()\n    smooth_df[\"cp_dose\"] = [0.0, 1.0]*3\n    smooth_df[\"cp_time\"] = [0.33, 0.66, 1.0]*2\n\n    for t in targets:\n        smooth_df[t] = 0\n\n    smooth_df2 = smooth_df.copy()\n    for t in targets:\n        smooth_df2[t] = 1\n    smooth_df = smooth_df.append(smooth_df2)\n\n    for f in gene_features + cell_features:\n        smooth_df[f] = 0.0\n\n    df = df[df[\"cp_type\"] == \"trt_cp\"]\n    df = df.append(smooth_df)\n\n    progress_bar = tqdm(range(len(targets)))\n\n\n    features = [\"cp_time\", \"cp_dose\"] + gene_features + cell_features\n\n    y_test = np.zeros((test_df.shape[0], len(targets)))\n    test_filter = cupy.asnumpy((test_df[\"cp_type\"] == \"trt_cp\").values)\n\n    for i in progress_bar:\n        target = targets[i]\n        y_real = cupy.asnumpy(df[target].values)\n\n\n        svc_model = cuml.SVC(C=100.0, cache_size=3000.0, probability=True)\n\n        svc_model.fit(df[features], df[target])\n\n        y_test[:, i] = test_filter*cupy.asnumpy(svc_model.predict_proba(test_df[features]).values)[:, 1]\n\n        test_df[target] = y_test[:, i]\n        \n    return test_df\n        \nsvm_sub_df = get_svm_sub()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_xgb_sub():\n    DIR = \"/kaggle/input/lish-moa\"\n\n    df = pd.read_csv(f\"{DIR}/train_features.csv\")\n\n    target_df = pd.read_csv(f\"{DIR}/train_targets_scored.csv\")\n    targets = [col for col in target_df.columns if col != \"sig_id\"]\n\n    tns_df = pd.read_csv(f\"{DIR}/train_targets_nonscored.csv\")\n    tns = [col for col in tns_df.columns if col != \"sig_id\"]\n\n    df = df.merge(target_df, on=\"sig_id\").merge(tns_df, on=\"sig_id\")\n\n    test_df = pd.read_csv(f\"{DIR}/test_features.csv\")\n\n    gene_features = [col for col in df.columns if col.startswith(\"g-\")]\n    cell_features = [col for col in df.columns if col.startswith(\"c-\")]\n\n    for data in [df, test_df]:\n        data[\"cp_time\"] = data[\"cp_time\"]/72\n        data[\"cp_dose\"] = 1.0*(data[\"cp_dose\"] == \"D1\")\n\n    df = df[df[\"cp_type\"] == \"trt_cp\"]\n\n    \n    for n, f in [(\"cell\", cell_features), (\"gene\", gene_features)]:\n        df[f] = df[f].rank(axis=1)\n        test_df[f] = test_df[f].rank(axis=1)\n        \n    df[\"w\"] = 0.999\n\n    df2 = df.copy()\n    df2[targets] = 1 - df2[targets]\n    df2[\"w\"] = 0.001\n    df = df.append(df2)\n    df.shape\n    \n    params = {\"objective\": \"binary:logistic\",\n          \"learning_rate\" : 0.02,\n          \"max_depth\": 4,\n          #'n_estimators': 500,\n          'min_child_weight': 5,\n          \"colsample_bytree\": 0.5,\n          \"tree_method\": 'gpu_hist', \"gpu_id\": 0}\n\n    n_estimators = pd.read_csv(\"/kaggle/input/moa-xgb-params/xgb_res.csv\").set_index(\"target\")\n    print(n_estimators[\"best_iter\"].min())\n\n    n_estimators.loc[n_estimators[\"best_iter\"] == 0, \"best_iter\"] = None\n    n_estimators[\"best_iter\"] = n_estimators[\"best_iter\"].fillna(n_estimators[\"best_iter\"].min())\n    print(n_estimators[\"best_iter\"].min())\n\n    n_estimators = n_estimators[\"best_iter\"].to_dict()\n    print(len(n_estimators), n_estimators[\"acat_inhibitor\"])\n    \n    progress_bar = tqdm(range(len(targets)))\n\n\n    features = gene_features + cell_features\n\n    y_test = np.zeros((test_df.shape[0], len(targets)))\n    test_filter = (test_df[\"cp_type\"] == \"trt_cp\").values\n\n    for i in progress_bar:\n        target = targets[i]\n        y_real = df[target].values\n\n        base_pred = np.log((df[\"w\"]*df[target]).mean())\n\n\n        xgb_model = xgb.XGBClassifier(**params, n_estimators=int(n_estimators[target] + 5))\n\n        xgb_model.fit(df[features], df[target], sample_weight=df[\"w\"], base_margin=np.ones(df.shape[0])*base_pred)\n\n        y_test[:, i] = test_filter*xgb_model.predict_proba(test_df[features], base_margin=np.ones(test_df.shape[0])*base_pred)[:, 1]\n\n        test_df[target] = y_test[:, i]\n        \n    return test_df, targets\n\nxgb_sub_df, targets = get_xgb_sub()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfs = [xgb_sub_df, svm_sub_df.to_pandas()]\nW = [0.6, 0.4]\n\nfor t in targets:\n    dfs[0][t] = W[0]*dfs[0][t] + W[1]*dfs[1][t]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfs[0].to_csv(\"submission.csv\", columns=[\"sig_id\"] + targets, index=False)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.079496,"end_time":"2020-09-08T11:45:32.617524","exception":false,"start_time":"2020-09-08T11:45:32.538028","status":"completed"},"tags":[],"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}