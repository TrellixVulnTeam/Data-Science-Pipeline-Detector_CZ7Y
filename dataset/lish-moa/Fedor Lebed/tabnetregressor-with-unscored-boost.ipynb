{"cells":[{"metadata":{},"cell_type":"markdown","source":"This is a fork of this notebook: [https://www.kaggle.com/optimo/tabnetregressor-2-0-train-infer](https://www.kaggle.com/optimo/tabnetregressor-2-0-train-infer)"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!pip install --no-index --find-links /kaggle/input/pytorchtabnet/pytorch_tabnet-2.0.0-py3-none-any.whl pytorch-tabnet\n!pip install /kaggle/input/iterative-stratification/iterative-stratification-master/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom sklearn.model_selection import StratifiedKFold\nfrom pytorch_tabnet.tab_model import TabNetRegressor\nimport numpy as np\nimport pandas as pd \n\nimport os\nimport random\nimport sys\nos.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\nfrom tqdm import tqdm\nfrom sklearn.metrics import log_loss\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def seed_everything(seed_value):\n    random.seed(seed_value)\n    np.random.seed(seed_value)\n    torch.manual_seed(seed_value)\n    os.environ['PYTHONHASHSEED'] = str(seed_value)\n    \n    if torch.cuda.is_available(): \n        torch.cuda.manual_seed(seed_value)\n        torch.cuda.manual_seed_all(seed_value)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\n        \nseed_everything(42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data and minimal preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_path = \"../input/lish-moa/\"\ntrain = pd.read_csv(data_path+'train_features.csv')\ntrain.drop(columns=[\"sig_id\"], inplace=True)\n\ntrain_targets = pd.read_csv(data_path+'train_targets_scored.csv')\ntrain_targets.drop(columns=[\"sig_id\"], inplace=True)\n\ntest = pd.read_csv(data_path+'test_features.csv')\ntest.drop(columns=[\"sig_id\"], inplace=True)\n\nsubmission = pd.read_csv(data_path+'sample_submission.csv')\n\nremove_vehicle = True\nif remove_vehicle:\n    kept_index = train['cp_type']=='trt_cp'\n    train = train.loc[kept_index].reset_index(drop=True)\n    train_targets = train_targets.loc[kept_index].reset_index(drop=True)\n\ntrain[\"cp_type\"] = (train[\"cp_type\"]==\"trt_cp\") + 0\ntrain[\"cp_dose\"] = (train[\"cp_dose\"]==\"D1\") + 0\n\ntest[\"cp_type\"] = (test[\"cp_type\"]==\"trt_cp\") + 0\ntest[\"cp_dose\"] = (test[\"cp_dose\"]==\"D1\") + 0\n\nX_test = test.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from iterstrat.ml_stratifiers import MultilabelStratifiedKFold, MultilabelStratifiedShuffleSplit\nfrom sklearn.metrics import roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model parameters \n\nHappy tuning! ;)"},{"metadata":{"trusted":true},"cell_type":"code","source":"MAX_EPOCH=200\ntabnet_params = dict(n_d=24, n_a=24, n_steps=1, gamma=1.3,\n                     lambda_sparse=0, optimizer_fn=torch.optim.Adam,\n                     optimizer_params=dict(lr=2e-2, weight_decay=1e-5),\n                     mask_type='entmax',\n                     scheduler_params=dict(mode=\"min\",\n                                           patience=5,\n                                           min_lr=1e-5,\n                                           factor=0.9,),\n                     scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n                     verbose=10,\n                     )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Define custom metric for valdidation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import log_loss\nfrom pytorch_tabnet.metrics import Metric\nfrom sklearn.metrics import roc_auc_score, log_loss\n\nclass LogitsLogLoss(Metric):\n    def __init__(self):\n        self._name = \"logits_ll\"\n        self._maximize = False\n\n    def __call__(self, y_true, y_pred):        \n        logits = 1 / (1 + np.exp(-y_pred))\n        ll = (1-y_true)*np.log(1-logits + 1e-15) + y_true*np.log(logits + 1e-15)\n        return np.mean(-ll)\n\nclass PartialLogitsLogLoss(Metric):\n    def __init__(self):\n        self._name = \"logits_ll(partial)\"\n        self._maximize = False\n\n    def __call__(self, y_true, y_pred):\n        y_true = y_true\n        y_pred = y_pred\n        \n        logits = 1 / (1 + np.exp(-y_pred))\n        logloss = (1-y_true)*np.log(1-logits + 1e-15) + y_true*np.log(logits + 1e-15)\n        return np.mean(-logloss)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"use_cols = [col for col in train_targets.columns if train_targets[col].mean() > 0.01]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores_auc_all= []\ntest_cv_preds = []\n\nNB_SPLITS = 10\nmskf = MultilabelStratifiedKFold(n_splits=NB_SPLITS, random_state=0, shuffle=True)\noof_preds = []\noof_targets = []\nscores = []\nscores_auc = []\nfor fold_nb, (train_idx, val_idx) in enumerate(mskf.split(train, train_targets)):\n    print(\"FOLDS : \", fold_nb)\n\n    ## model\n    X_train, y_train = train.values[train_idx, :], train_targets[use_cols].values[train_idx, :]\n    X_val, y_val = train.values[val_idx, :], train_targets[use_cols].values[val_idx, :]\n    model = TabNetRegressor(**tabnet_params)\n\n    model.fit(X_train=X_train,\n              y_train=y_train,\n              eval_set=[(X_val, y_val)],\n              eval_name = [\"val\"],\n              eval_metric = ['logits_ll', 'logits_ll(partial)'],\n              max_epochs=MAX_EPOCH,\n              patience=20, batch_size=1024, virtual_batch_size=128,\n              num_workers=1, drop_last=False,\n              # use binary cross entropy as this is not a regression problem\n              loss_fn=torch.nn.functional.binary_cross_entropy_with_logits)\n\n    preds_val = model.predict(X_val)\n    # Apply sigmoid to the predictions\n    preds =  1 / (1 + np.exp(-preds_val))\n    score = np.min(model.history[\"val_logits_ll(partial)\"])\n#     name = cfg.save_name + f\"_fold{fold_nb}\"\n#     model.save_model(name)\n    ## save oof to compute the CV later\n    oof_preds.append(preds_val)\n    oof_targets.append(y_val)\n    scores.append(score)\n\n    # preds on test\n    preds_test = model.predict(X_test)\n    test_cv_preds.append(1 / (1 + np.exp(-preds_test)))\n\noof_preds_all = np.concatenate(oof_preds)\noof_targets_all = np.concatenate(oof_targets)\ntest_preds_all = np.stack(test_cv_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aucs = []\nfor task_id in range(oof_preds_all.shape[1]):\n    aucs.append(roc_auc_score(y_true=oof_targets_all[:, task_id],\n                              y_score=oof_preds_all[:, task_id]))\nprint(f\"Overall AUC : {np.mean(aucs)}\")\nprint(f\"Average CV : {np.mean(scores)}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_feat = [col for col in submission.columns if col not in [\"sig_id\"]]\nother = [col for col in all_feat if col not in use_cols]\nsubmission[use_cols] = test_preds_all.mean(axis=0)\nsubmission[other] = train_targets[other].mean().values\n# set control to 0\nsubmission.loc[test['cp_type']==0, submission.columns[1:]] = 0\nsubmission.to_csv('submission.csv', index=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}