{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\nsys.path.append('../input/iterstat-proxy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\nfrom sklearn.decomposition import PCA\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = pd.read_csv('../input/lish-moa/train_features.csv')\ntarget = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\nsubmit_features = pd.read_csv('../input/lish-moa/test_features.csv')\n\nassert features.sig_id.duplicated().sum() == 0\nassert target.sig_id.duplicated().sum() == 0\nassert submit_features.sig_id.duplicated().sum() == 0\n\nfeatures = features.set_index('sig_id').sort_index()\ntarget = target.set_index('sig_id').sort_index()\nsubmit_features = submit_features.set_index('sig_id').sort_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def score(prob, true):    \n    prob = np.clip(prob, 1e-15, 1-1e-15)\n    return -np.stack([\n        np.log(1-prob),\n        np.log(prob)\n    ])[true.reshape(-1), np.arange(np.prod(true.shape))].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def features_to_matrix(f):\n    return f.drop(columns=['cp_type', 'cp_time', 'cp_dose']).values\n\ndef target_to_matrix(t):\n    return t.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\n\n\nclass PCAProjectorSingle:\n    def __init__(self, alpha=1):\n        self.alpha = alpha\n\n    def name(self):\n        return 'PCA(alpha={})'.format(self.alpha)\n    \n    def fit(self, x, y):\n        actor = x[y == 1]\n        if len(actor) > 0:\n            with warnings.catch_warnings():\n                warnings.simplefilter(action='ignore', category=RuntimeWarning)\n                self.pca = PCA().fit(actor)\n        else:\n            self.pca = None\n        return self\n    \n    def predict_proba(self, x):\n        if self.pca is None:\n            d = np.array([float('inf') for _ in range(len(x))])\n        else:\n            d = ((self.pca.inverse_transform(self.pca.transform(x)) - x)**2).mean(axis=1)\n        return np.exp(-self.alpha * d)\n    \nclass PCAProjector:\n    def __init__(self, alpha=1):\n        self.alpha = alpha\n        \n    def name(self):\n        return 'PCA(alpha={})'.format(self.alpha)\n    \n    def fit(self, x, y):\n        self.proj = []\n        for i in range(y.shape[1]):\n            self.proj.append(PCAProjectorSingle(alpha=self.alpha).fit(x, y[:, i]))\n        return self\n    \n    def predict_proba(self, x):\n        return np.stack([p.predict_proba(x) for p in self.proj]).T\n    \nclass Mean:\n    def name(self):\n        return 'Mean()'\n    \n    def fit(self, x, y):\n        self.mean = y.mean(axis=0)\n        return self\n        \n    def predict_proba(self, x):\n        return np.zeros((len(x), len(self.mean))) + self.mean[None, :]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_class(f):\n    return f.cp_type\n    \ndef class_to_models(cl):\n    if cl == 'ctl_vehicle':\n        return [Mean()]\n    else:\n        return [Mean()] + [PCAProjector(a) for a in np.linspace(10, 20, 10)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_folds = 7\nfolder = MultilabelStratifiedKFold(n_splits=n_folds, shuffle=True, random_state=91)\n\nfold_class_model = dict()\n\nfold_class_model_predict = dict()\nfold_class_true = dict()\n\nprint('training')\nfor i, (train_idx, test_idx) in enumerate(folder.split(features, target)):\n    print('  [fold {}]'.format(i))\n    fold_train = features.iloc[train_idx]\n    fold_train_target = target.iloc[train_idx]\n    \n    fold_test = features.iloc[test_idx]\n    fold_test_target = target.iloc[test_idx]\n    \n    fold_class_model[i] = dict()\n    fold_class_model_predict[i] = dict()\n    fold_class_true[i] = dict()\n    \n    classes = get_class(fold_train)\n    test_classes = get_class(fold_test)\n    \n    print('    fold classes={}'.format(list(classes.unique())))\n    \n    for cl in classes.unique():\n        print('    fitting class={}'.format(cl))\n        class_mask = classes == cl\n        models = [m.fit(features_to_matrix(fold_train[class_mask]), target_to_matrix(fold_train_target[class_mask])) for m in class_to_models(cl)]\n        fold_class_model[i][cl] = models\n        \n    for cl in test_classes.unique():\n        print('    testing class={}'.format(cl))\n        class_mask = test_classes == cl\n        preds = [m.predict_proba(features_to_matrix(fold_test[class_mask])) for m in fold_class_model[i][cl]]\n        fold_class_model_predict[i][cl] = preds\n        fold_class_true[i][cl] = target_to_matrix(fold_test_target[class_mask])\n        \nprint('comparing models')\nfold_class_model_score = dict()\nfold_class_size = dict()\nfor i in range(n_folds):\n    fold_class_model_score[i] = dict()\n    fold_class_size[i] = dict()\n    for cl in fold_class_model_predict[i].keys():\n        scores = []\n        true = fold_class_true[i][cl]\n        for pred in fold_class_model_predict[i][cl]:\n            scores.append([score(pred[:, j], true[:, j]) for j in range(true.shape[1])])\n        fold_class_model_score[i][cl] = np.array(scores)\n        fold_class_size[i][cl] = len(true)\n\nfold_class_best_model = dict()\nfor i in range(n_folds):\n    fold_class_best_model[i] = dict()\n    for cl,scores in fold_class_model_score[i].items():\n        fold_class_best_model[i][cl] = [scores[:, j].argmin() for j in range(scores.shape[1])]\n        print('  [fold {}, cl {}] {}'.format(i, cl, pd.Series(np.array([m.name() for m in fold_class_model[i][cl]])[fold_class_best_model[i][cl]]).value_counts()))\n        \nprint('calculating final score')\nfold_class_weight = {\n    i:{\n        cl:s/sum(cl_to_size.values())\n        for cl,s in cl_to_size.items()\n    }\n    for i,cl_to_size in fold_class_size.items()\n}\n\nfold_scores = []\nfor i in range(n_folds):\n    s = 0\n    for cl,w in fold_class_weight[i].items():\n        s += fold_class_model_score[i][cl].min(axis=0).mean() * w\n    fold_scores.append(s)\n    print('  [fold {}] score={:.4f}'.format(i, s))\nprint('  final score = {:.4f}'.format(np.mean(fold_scores)))\n    \nprint('generating submit prediction')\nfold_submit_pred = dict()\nfor i in range(n_folds):\n    print('  [fold {}]'.format(i))\n    \n    x = features_to_matrix(submit_features)\n    submit_classes = get_class(submit_features)\n    \n    pred = np.zeros((len(x), len(target.columns)))\n    for cl in submit_classes.unique():\n        print('    predicting class = {}'.format(cl))\n        class_mask = submit_classes == cl\n        \n        preds = []\n        for m in fold_class_model[i][cl]:\n            preds.append(m.predict_proba(x[class_mask]))\n            \n        pred[class_mask] = np.stack([\n            preds[fold_class_best_model[i][cl][j]][:, j]\n            for j in range(len(target.columns))\n        ]).T\n    \n    fold_submit_pred[i] = pd.DataFrame(data=pred, index=submit_features.index, columns=target.columns)\n    \nsubmission = sum(fold_submit_pred.values()) / len(fold_submit_pred)\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"submission.to_csv('submission.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}