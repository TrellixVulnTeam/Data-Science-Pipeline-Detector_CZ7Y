{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\nsys.path.append('../input/iterstat-proxy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\nfrom sklearn.decomposition import PCA\nfrom tqdm import tqdm\nimport torch as tc\nimport pytorch_lightning as pl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = pd.read_csv('../input/lish-moa/train_features.csv')\ntarget = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\nsubmit_features = pd.read_csv('../input/lish-moa/test_features.csv')\n\nassert features.sig_id.duplicated().sum() == 0\nassert target.sig_id.duplicated().sum() == 0\nassert submit_features.sig_id.duplicated().sum() == 0\n\nfeatures = features.set_index('sig_id').sort_index()\ntarget = target.set_index('sig_id').sort_index()\nsubmit_features = submit_features.set_index('sig_id').sort_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def score(prob, true):\n    prob = prob.astype(np.float64).reshape(-1)\n    true = true.reshape(-1)\n    \n    prob = np.clip(prob, 1e-15, 1-1e-15)\n    return -np.stack([\n        np.log(1-prob),\n        np.log(prob)\n    ])[true, np.arange(len(prob))].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def features_to_matrix(f):\n    cat_features = np.stack([\n        f.cp_time.map(dict([(24, -1), (48, 0), (72, 1)])).values,\n        f.cp_dose.map(dict(D1=-1, D2=1)).values,\n    ], axis=1)\n\n    num_features = f.drop(columns=['cp_type', 'cp_time', 'cp_dose']).values\n    return np.hstack([cat_features, num_features])\n\ndef target_to_matrix(t):\n    return t.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Mean:\n    def name(self):\n        return 'Mean()'\n    \n    def fit(self, x, y, **kwargs):\n        self.mean = y.mean(axis=0)\n        return self\n        \n    def predict_proba(self, x):\n        return np.zeros((len(x), len(self.mean))) + self.mean[None, :]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_to_matrix(features).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_to_matrix(target).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s0 = 0.01\n\ndef kl_loss(mu_0, log_sigma_0, mu_1, log_sigma_1) :\n    kl = log_sigma_1 - log_sigma_0 + (tc.exp(2*log_sigma_0) + (mu_0 - mu_1)**2)/(2*tc.exp(2*log_sigma_1)**2) - 0.5\n    return kl.sum()\n\nclass BayesianLinaer(tc.nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super().__init__()\n        self.mu = tc.nn.Parameter(tc.zeros(input_dim, output_dim))\n        self.log_s = tc.nn.Parameter(tc.ones(input_dim, output_dim) * np.log(s0))\n        \n        self.bias = tc.nn.Parameter(tc.randn(output_dim))\n        \n    def forward(self, x):\n        self.kl = kl_loss(self.mu, self.log_s, 0, 0.5*tc.log(self.mu**2 + tc.exp(2*self.log_s)))\n        if self.training:\n            return tc.mm(x, self.mu + tc.randn_like(self.mu)*tc.exp(self.log_s)) + self.bias[None, :]\n        else:\n            return tc.mm(x, self.mu) + self.bias[None, :]\n\nclass RotationBlock(tc.nn.Module):\n    def __init__(self, input_dim, output_dim, activation=tc.nn.ReLU):\n        super().__init__()\n        \n        self.features = tc.nn.Sequential(\n            BayesianLinaer(input_dim, output_dim),\n            activation()\n        )\n        \n    def forward(self, x):\n        o = self.features(x)\n        kl = 0\n        for child in self.features:\n            if isinstance(child, BayesianLinaer):\n                kl += child.kl\n        self.kl = kl\n        return o\n    \nclass NN(tc.nn.Module):\n    def __init__(self, input_dim=874, hidden_dims=[1024, 512, 206]):\n        super().__init__()\n        \n        self.features = tc.nn.Sequential(*[\n            RotationBlock(i, o, activation=tc.nn.ReLU if j < len(hidden_dims) - 1 else tc.nn.Identity)\n            for j, (i, o) in enumerate(zip([input_dim] + hidden_dims, hidden_dims))\n        ])\n    \n    def forward(self, x):\n        o = self.features(x)\n        kl = 0\n        for rb in self.features:\n            kl += rb.kl\n        self.kl = kl\n        return o\n    \nclass NNPL(pl.LightningModule):\n    def __init__(self, *args, train_size=float('inf'), **kwargs):\n        super().__init__()\n        \n        self.model = NN(*args, **kwargs)\n        self.criterion = tc.nn.BCEWithLogitsLoss()\n        self.train_size = train_size\n        \n    def forward(self, x):\n        return tc.sigmoid(self.model(x))\n        \n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        loss = self.criterion(self.model(x), y)\n        full_loss = loss + self.model.kl/self.train_size\n        \n        self.log('train_bce', loss)\n        self.log('train_full', full_loss)\n        \n        return full_loss\n    \n    def validation_step(self, batch, batch_idx):\n        x, y = batch\n        loss = self.criterion(self.model(x), y)\n        \n        self.log('test_bce', loss)\n        \n        return loss\n    \n    def configure_optimizers(self):\n        return tc.optim.Adam(self.model.parameters(), lr=1e-4, weight_decay=1e-5)\n    \nclass NNSklearn:\n    def __init__(self, *args, **kwargs):\n        self.args = args\n        self.kwargs = kwargs\n    \n    def name(self):\n        return 'NN()'\n        \n    def fit(self, x, y, x_val, y_val, fold, cl, **kwargs):\n        self.nn_pl = NNPL(*self.args, train_size=np.prod(y.shape)*5e4, **self.kwargs)\n        \n        train_loader = tc.utils.data.DataLoader(\n            tc.utils.data.TensorDataset(tc.from_numpy(x).to(tc.float32), tc.from_numpy(y).to(tc.float32)), \n            batch_size=128, num_workers=4\n        )\n        \n        val_loader = tc.utils.data.DataLoader(\n            tc.utils.data.TensorDataset(tc.from_numpy(x_val).to(tc.float32), tc.from_numpy(y_val).to(tc.float32)), \n            batch_size=128, num_workers=4\n        )\n        \n        chk_callback = pl.callbacks.ModelCheckpoint(\n            filepath='CHK_bayesian_nn_{}_{}'.format(cl, fold) + '/NN-{epoch:02d}-{test_bce:.2f}',\n            save_top_k=1,\n            verbose=True,\n            monitor='test_bce',\n            mode='min'\n        )\n        trainer = pl.Trainer(\n            max_epochs=64,\n            checkpoint_callback=chk_callback,\n            logger=pl.loggers.TensorBoardLogger(save_dir='bayesian_nn_{}_{}'.format(cl, fold), name='bayesian_nn_{}'.format(cl, fold))\n        )\n        trainer.fit(self.nn_pl, train_loader, val_loader)\n        self.nn_pl = NNPL.load_from_checkpoint(chk_callback.best_model_path)\n        \n        return self\n    \n    def predict_proba(self, x, nsamples=100):\n        self.nn_pl.train()\n        with tc.no_grad():\n            pred = 0\n            for i in range(nsamples):\n                 pred += self.nn_pl(tc.from_numpy(x).to(tc.float32)).numpy()/nsamples\n            return pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_class(f):\n    return f.cp_type\n    \ndef class_to_models(cl):\n    if cl == 'ctl_vehicle':\n        return [Mean()]\n    else:\n        return [NNSklearn()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm -r bayesian_*\n!rm -r CHK_bayesian_*\n\nn_folds = 7\nfolder = MultilabelStratifiedKFold(n_splits=n_folds, shuffle=True, random_state=517)\n\nfold_class_model = dict()\n\nfold_class_model_predict = dict()\nfold_class_true = dict()\n\nprint('training')\nfor i, (train_idx, test_idx) in enumerate(folder.split(features, target)):\n    print('  [fold {}]'.format(i))\n    fold_train = features.iloc[train_idx]\n    fold_train_target = target.iloc[train_idx]\n    \n    fold_test = features.iloc[test_idx]\n    fold_test_target = target.iloc[test_idx]\n    \n    fold_class_model[i] = dict()\n    fold_class_model_predict[i] = dict()\n    fold_class_true[i] = dict()\n    \n    classes = get_class(fold_train)\n    test_classes = get_class(fold_test)\n    \n    print('    fold classes={}'.format(list(classes.unique())))\n    \n    for cl in classes.unique():\n        print('    fitting class={}'.format(cl))\n        class_mask = classes == cl\n        test_class_mask = test_classes == cl\n        models = [\n            m.fit(\n                x=features_to_matrix(fold_train[class_mask]), \n                y=target_to_matrix(fold_train_target[class_mask]), \n                x_val=features_to_matrix(fold_test[test_class_mask]),\n                y_val=target_to_matrix(fold_test_target[test_class_mask]),\n                fold=i,\n                cl=cl\n            )\n            for m in class_to_models(cl)\n        ]\n        fold_class_model[i][cl] = models\n        \n    for cl in test_classes.unique():\n        print('    testing class={}'.format(cl))\n        class_mask = test_classes == cl\n        preds = [m.predict_proba(features_to_matrix(fold_test[class_mask])) for m in fold_class_model[i][cl]]\n        fold_class_model_predict[i][cl] = preds\n        fold_class_true[i][cl] = target_to_matrix(fold_test_target[class_mask])\n        \n\nprint('calculating final score')\nfold_class_score = dict()\nfold_class_size = dict()\nfor i in range(n_folds):\n    fold_class_score[i] = dict()\n    fold_class_size[i] = dict()\n    for cl in fold_class_model_predict[i].keys():\n        scores = []\n        true = fold_class_true[i][cl]\n        pred = np.mean(fold_class_model_predict[i][cl], axis=0)            \n        \n        fold_class_score[i][cl] = score(pred, true)\n        fold_class_size[i][cl] = len(true)        \n\nfold_class_weight = {\n    i:{\n        cl:s/sum(cl_to_size.values())\n        for cl,s in cl_to_size.items()\n    }\n    for i,cl_to_size in fold_class_size.items()\n}\n\nfold_scores = []\nfor i in range(n_folds):\n    s = 0\n    for cl,w in fold_class_weight[i].items():\n        s += fold_class_score[i][cl] * w\n    fold_scores.append(s)\n    print('  [fold {}] score={:.4f}'.format(i, s))\nprint('  final score = {:.4f}'.format(np.mean(fold_scores)))\n    \nprint('generating submit prediction')\nfold_submit_pred = dict()\nfor i in range(n_folds):\n    print('  [fold {}]'.format(i))\n    \n    x = features_to_matrix(submit_features)\n    submit_classes = get_class(submit_features)\n    \n    pred = np.zeros((len(x), len(target.columns)))\n    for cl in submit_classes.unique():\n        print('    predicting class = {}'.format(cl))\n        class_mask = submit_classes == cl\n        \n        for m in fold_class_model[i][cl]:\n            pred[class_mask] += m.predict_proba(x[class_mask])/len(fold_class_model[i][cl])\n    \n    fold_submit_pred[i] = pd.DataFrame(data=pred, index=submit_features.index, columns=target.columns)\n    \nsubmission = sum(fold_submit_pred.values()) / len(fold_submit_pred)\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}