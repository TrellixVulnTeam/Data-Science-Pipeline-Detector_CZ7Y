{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reading Dataset","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_features = pd.read_csv('/kaggle/input/lish-moa/train_features.csv')\ntest_features = pd.read_csv('/kaggle/input/lish-moa/test_features.csv')\ntrain_targets_nonscored = pd.read_csv('/kaggle/input/lish-moa/train_targets_nonscored.csv')\ntrain_targets_scored = pd.read_csv('/kaggle/input/lish-moa/train_targets_scored.csv')\nsample_submission = pd.read_csv('/kaggle/input/lish-moa/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Importing Libraries","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nimport numpy as np\nimport pandas as pd \nimport seaborn as sns\n\n\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import KFold\nfrom category_encoders import CountEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import log_loss\n\nfrom sklearn.multioutput import MultiOutputClassifier\n\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use('seaborn')\nsns.set_style('whitegrid')\nfig = plt.figure(figsize=(15,5))\n#1 rows 2 cols\n#first row, first col\nax1 = plt.subplot2grid((1,2),(0,0))\nsns.countplot(x='cp_type', data=train_features, palette='pastel')\nplt.title('Train: Control and treated samples', fontsize=15, weight='bold')\n#first row sec col\nax1 = plt.subplot2grid((1,2),(0,1))\nsns.countplot(x='cp_dose', data=train_features, palette='Purples')\nplt.title('Train: Treatment Doses: Low and High',weight='bold', fontsize=18)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,5))\nsns.distplot( train_features['cp_time'], color='red', bins=5)\nplt.title(\"Train: Treatment duration \", fontsize=15, weight='bold')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Very Imbalance distribution of cp_type.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features.cp_type.value_counts(normalize=True).plot(kind='pie', figsize=(15, 5), fontsize=12,\n                                                         title='CP Type', autopct='%1.1f%%')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Distribution of CP Time ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features.cp_time.value_counts(normalize=True).plot(kind='bar', figsize=(12, 5), fontsize=14,\n                                                         title='CP Time', xlabel='Time')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Distribution of CP Dose ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features.cp_dose.value_counts(normalize=True).plot(kind='bar', figsize=(12, 5), fontsize=14,\n                                                         title='CP Dose', xlabel='Dose')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GENE_COLS = [c for c in train_features.columns if c[:2] == 'g-']\nCELL_COLS = [c for c in train_features.columns if c[:2] == 'c-']\nprint('Number of gene columns:', len(GENE_COLS))\nprint('Number of cell columns:', len(CELL_COLS))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Gene Features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = train_features.set_index('sig_id') \\\n    .sample(10)[GENE_COLS] \\\n    .T.plot(figsize=(15, 5))\nplt.suptitle('Gene Features for 10 Random Samples', fontsize=20)\nax.get_legend().remove()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check if some features is correlated","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp_df = train_features.loc[:, ['g-0', 'g-1', 'g-2', 'c-97', 'c-98', 'c-99']]\n\nplt.figure(figsize=(8, 8))\nsns.heatmap(tmp_df.corr(), annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# XGBoost baseline - multilabel classification","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"SEED = 42\nNFOLDS = 5\n\nnp.random.seed(SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop id col\nX = train_features.iloc[:,1:].to_numpy()\nX_test = test_features.iloc[:,1:].to_numpy()\ny = train_targets_scored.iloc[:,1:].to_numpy() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = Pipeline([('encode', CountEncoder(cols=[0, 2])),\n                ('classify', MultiOutputClassifier(XGBClassifier(tree_method='gpu_hist')))\n               ])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Framing as a binary classification problem","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {'classify__estimator__colsample_bytree': 0.652231655518253,\n          'classify__estimator__gamma': 3.6975211709521023,\n          'classify__estimator__learning_rate': 0.05033414197773552,\n          'classify__estimator__max_delta_step': 2.070593162427692,\n          'classify__estimator__max_depth': 10,\n          'classify__estimator__min_child_weight': 31.579959348704868,\n          'classify__estimator__n_estimators': 166,\n          'classify__estimator__subsample': 0.8638628715886625,\n          'encode__min_group_size': 0.4160029192647806}\n\nclf.set_params(**params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train the model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"oof_preds = np.zeros(y.shape)\ntest_preds = np.zeros((test_features.shape[0], y.shape[1]))\nkf = KFold(n_splits=NFOLDS)\nfor fn, (trn_idx, val_idx) in enumerate(kf.split(X, y)):\n    print('Starting fold: ', fn)\n    X_train, X_val = X[trn_idx], X[val_idx]\n    y_train, y_val = y[trn_idx], y[val_idx]\n    clf.fit(X_train, y_train)\n    val_preds = clf.predict_proba(X_val) # list of preds per class\n    val_preds = np.array(val_preds)[:,:,1].T # take the positive class\n    oof_preds[val_idx] = val_preds\n    \n    preds = clf.predict_proba(X_test)\n    preds = np.array(preds)[:,:,1].T # take the positive class\n    test_preds += preds / NFOLDS","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('OOF log loss: ', log_loss(np.ravel(y), np.ravel(oof_preds)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create the submission file\nsample_submission.iloc[:,1:] = test_preds\nsample_submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}