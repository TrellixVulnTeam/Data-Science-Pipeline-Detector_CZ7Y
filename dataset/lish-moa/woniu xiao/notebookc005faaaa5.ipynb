{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_features = pd.read_csv('/kaggle/input/lish-moa/train_features.csv')\ntrain_features.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\ntrain_features[\"cp_type\"]=train_features[\"cp_type\"].replace([\"trt_cp\",\"ctl_vehicle\"],[1,0])\ntrain_features[\"cp_dose\"]=train_features[\"cp_dose\"].replace([\"D1\",\"D2\"],[1,0])\ntrain_features[\"cp_time\"]=train_features[\"cp_time\"].replace([24,48,72],[0,1,2])\n\ntrain_targets_scored = pd.read_csv('/kaggle/input/lish-moa/train_targets_scored.csv')\nx= train_features.drop(['sig_id'],axis=1)\ny= train_targets_scored.drop(['sig_id'],axis=1)\n\nx=x.values.tolist()\ny=y.values.tolist()\nx=np.array(x)\ny=np.array(y)\ntype(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_targets_scored.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MLP(tf.keras.Model):\n    def __init__(self):\n        super().__init__()\n        self.flatten = tf.keras.layers.Flatten()    # Flatten层将除第一维（batch_size）以外的维度展平\n        self.dense1 = tf.keras.layers.Dense(units=1000, activation=tf.nn.relu) \n        self.dense2 = tf.keras.layers.Dense(units=600, activation=tf.nn.relu)\n        self.dense3 = tf.keras.layers.Dense(units=206)\n\n    def call(self, inputs):         \n        x = self.flatten(inputs)   \n        x = self.dense1(x)          \n        x = self.dense2(x)\n        x = self.dense3(x)\n        output = tf.nn.softmax(x)\n        return output\n    \ndef get_batch(batch_size):\n        # 从数据集中随机取出batch_size个元素并返回\n        batch_size=int(batch_size)\n        index = np.random.randint(0, x_train.shape[0], batch_size)\n        return x_train[index,:], y_train[index,:]\n    \nnum_epochs = 5\nbatch_size = 50\nlearning_rate = 0.0001\n\nmodel = MLP()\noptimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n\nnum_batches = int(x.shape[0] // batch_size * num_epochs)\nfor batch_index in range(num_batches):\n    index = np.random.randint(0, x.shape[0], batch_size)\n    X=x[index,:]\n    Y=y[index,:]\n\n    with tf.GradientTape() as tape:\n        y_pred = model(X)\n\n        loss = tf.keras.losses.binary_crossentropy(y_true=Y, y_pred=y_pred)\n        loss = tf.reduce_mean(loss)\n        print(\"batch %d: loss %f\" % (batch_index, loss.numpy()))\n    grads = tape.gradient(loss, model.variables)\n    optimizer.apply_gradients(grads_and_vars=zip(grads, model.variables))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sparse_categorical_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\nnum_batches = int(x_test.shape[0] // batch_size)\nfor batch_index in range(num_batches):\n    start_index, end_index = batch_index * batch_size, (batch_index + 1) * batch_size\n    y_predd = model.predict(x[start_index: end_index])\n    y_predd = np.array(y_predd)\n    y_predd = y_predd.reshape(y_predd.shape[0]*y_predd.shape[1],1)\n    \n    y_truee=y[start_index: end_index]\n    y_truee = np.array(y_truee)\n    y_truee = y_truee.reshape(y_predd.shape[0]*y_predd.shape[1],1)\n    sparse_categorical_accuracy.update_state(y_true=y_truee, y_pred=y_predd)\nprint(\"test accuracy: %f\" % sparse_categorical_accuracy.result())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_features = pd.read_csv('/kaggle/input/lish-moa/test_features.csv')\ntest_features.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_features[\"cp_type\"]=test_features[\"cp_type\"].replace([\"trt_cp\",\"ctl_vehicle\"],[1,0])\ntest_features[\"cp_dose\"]=test_features[\"cp_dose\"].replace([\"D1\",\"D2\"],[1,0])\ntest_features[\"cp_time\"]=test_features[\"cp_time\"].replace([24,48,72],[0,1,2])\ntest_featuress = test_features.drop(['sig_id'],axis=1)\ntest_featuress_predict = model.predict(test_featuress)\ntest_featuress_predict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission = pd.read_csv('/kaggle/input/lish-moa/sample_submission.csv')\nsample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission1 = sample_submission.drop(['sig_id'],axis=1)\ncolumnn =sample_submission1.columns\ncolumnn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res = pd.DataFrame(test_featuress_predict,columns=columnn)\npd.set_option('display.float_format',lambda x : '%.19f' % x)\nres.insert(0,'sig_id',sample_submission[\"sig_id\"])\nres.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res.to_csv('/kaggle/working/submission.csv', index=0, encoding = \"utf-8\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import log_loss\nlog_loss(y,model.predict(x))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}