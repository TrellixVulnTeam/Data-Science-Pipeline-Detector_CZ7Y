{"cells":[{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"%%HTML\n<style type=\"text/css\">\ndiv.h1 {\n    background-color:#eebbcb; \n    color: white; \n    padding: 8px; \n    padding-right: 300px; \n    font-size: 35px; \n    max-width: 1500px; \n    margin: auto; \n    margin-top: 50px;\n}\n\ndiv.h2 {\n    background-color:#2ca9e1; \n    color: white; \n    padding: 8px; \n    padding-right: 300px; \n    font-size: 35px; \n    max-width: 1500px; \n    margin: auto; \n    margin-top: 50px;\n}\n</style>","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**I refered the folloing great notebook for data pipeline:**\n\nhttps://www.kaggle.com/fchmiel/xgboost-baseline-multilabel-classification\n\n"},{"metadata":{},"cell_type":"markdown","source":"## If you like, please UpvoteðŸ˜¹"},{"metadata":{},"cell_type":"markdown","source":"# <div class=\"h1\">About this notebook</div>"},{"metadata":{},"cell_type":"markdown","source":"## In this notebook, I create HistGradientBoostingRegressor baseline.\n\nhttps://scikit-learn.org/stable/modules/generated/sklearn.ensemble.HistGradientBoostingRegressor.html\n\n### <u>Note</u>\n\n**Update information**\n\nversion1: First release. It doesn't seem to be performing well enough, so I will be tuning it up.\n\nversion2: Add PCA dimension reduction.\n\nversion3: Tuned learing rate.\n\nversion4: Tuned max_depth.\n\nversion5: Tuned l2_regularization and , max_iter.\n\nversion6: Change kfold 5 -> 10."},{"metadata":{},"cell_type":"markdown","source":"# <div class=\"h2\">Baseline</div>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import log_loss\nfrom sklearn.experimental import enable_hist_gradient_boosting\nfrom sklearn.ensemble import HistGradientBoostingRegressor\n\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.multioutput import MultiOutputRegressor\n\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\nsys.path.append('../input/iterative-stratification/iterative-stratification-master')\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SEED = 42\nNFOLDS = 10\nDATA_DIR = '/kaggle/input/lish-moa/'\nnp.random.seed(SEED)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### load data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv(DATA_DIR + 'train_features.csv')\ntargets = pd.read_csv(DATA_DIR + 'train_targets_scored.csv')\n\ntest = pd.read_csv(DATA_DIR + 'test_features.csv')\nsub = pd.read_csv(DATA_DIR + 'sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"targets.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### PCA\n\nI refered this notebook https://www.kaggle.com/namanj27/new-baseline-pytorch-moa."},{"metadata":{"trusted":true},"cell_type":"code","source":"GENES = [col for col in train.columns if col.startswith('g-')]\nCELLS = [col for col in train.columns if col.startswith('c-')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# GENES\nn_comp = 50\n\ndata = pd.concat([pd.DataFrame(train[GENES]), pd.DataFrame(test[GENES])])\ndata2 = (PCA(n_components=n_comp, random_state=42).fit_transform(data[GENES]))\ntrain2 = data2[:train.shape[0]]; test2 = data2[-test.shape[0]:]\n\ntrain2 = pd.DataFrame(train2, columns=[f'pca_G-{i}' for i in range(n_comp)])\ntest2 = pd.DataFrame(test2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n\n# drop_cols = [f'c-{i}' for i in range(n_comp,len(GENES))]\ntrain = pd.concat((train, train2), axis=1)\ntest = pd.concat((test, test2), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#CELLS\nn_comp = 15\n\ndata = pd.concat([pd.DataFrame(train[CELLS]), pd.DataFrame(test[CELLS])])\ndata2 = (PCA(n_components=n_comp, random_state=42).fit_transform(data[CELLS]))\ntrain2 = data2[:train.shape[0]]; test2 = data2[-test.shape[0]:]\n\ntrain2 = pd.DataFrame(train2, columns=[f'pca_C-{i}' for i in range(n_comp)])\ntest2 = pd.DataFrame(test2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n\n# drop_cols = [f'c-{i}' for i in range(n_comp,len(CELLS))]\ntrain = pd.concat((train, train2), axis=1)\ntest = pd.concat((test, test2), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.drop(columns = (GENES + CELLS))\ntest = test.drop(columns = (GENES + CELLS))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Scaling and Encording"},{"metadata":{"trusted":true},"cell_type":"code","source":"#One-hot encoding for category variables\nall_x = pd.concat([train, test])\nall_x = pd.get_dummies(all_x, columns=[\"cp_type\", \"cp_dose\"])\n\n#Adjust scale\nall_x[\"cp_time\"] = all_x[\"cp_time\"]/72\n\n#Split into the original dataset.\ntrain = all_x.iloc[:train.shape[0], :].reset_index(drop=True)\ntest = all_x.iloc[train.shape[0]:, :].reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop id col\nX = train.iloc[:,1:].to_numpy()\nX_test = test.iloc[:,1:].to_numpy()\ny = targets.iloc[:,1:].values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"reg = HistGradientBoostingRegressor(learning_rate = 0.013, max_depth=5, l2_regularization=0.02,\n                                    max_iter=175)\nreg = MultiOutputRegressor(reg)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n### Train the imprement"},{"metadata":{"trusted":true},"cell_type":"code","source":"oof_preds = np.zeros(y.shape)\ntest_preds = np.zeros((test.shape[0], y.shape[1]))\noof_losses = []\n#kf = KFold(n_splits=NFOLDS)\nkf = MultilabelStratifiedKFold(n_splits=NFOLDS)\nfor fn, (trn_idx, val_idx) in enumerate(kf.split(X, y)):\n    print('Starting fold: ', fn)\n    X_train, X_val = X[trn_idx], X[val_idx]\n    y_train, y_val = y[trn_idx], y[val_idx]\n\n    # drop where cp_type==ctl_vehicle (baseline)\n    ctl_mask = X_train[:,-4]== 1#'ctl_vehicle'\n    X_train = X_train[~ctl_mask,:]\n    y_train = y_train[~ctl_mask]\n    \n\n    \n    reg.fit(X_train, y_train)\n    val_preds = reg.predict(X_val) # list of preds per class\n    #val_preds = np.array(val_preds)[:,:,1].T # take the positive class\n    oof_preds[val_idx] = val_preds\n    \n    loss = log_loss(np.ravel(y_val), np.ravel(val_preds))\n    oof_losses.append(loss)\n    preds = reg.predict(X_test)\n    #preds = np.array(preds)[:,:,1].T # take the positive class\n    test_preds += preds / NFOLDS\n    \nprint(oof_losses)\nprint('Mean OOF loss across folds', np.mean(oof_losses))\nprint('STD OOF loss across folds', np.std(oof_losses))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# set control train preds to 0\ncontrol_mask = train['cp_type_ctl_vehicle']==1\noof_preds[control_mask] = 0\n\nprint('OOF log loss: ', log_loss(np.ravel(y), np.ravel(oof_preds)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Save OOF preds\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"test[sub.columns[1:]] = test_preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = sub.drop(columns=sub.columns[1:]).merge(test[list(sub.columns[1:].values) + [\"sig_id\"]], on='sig_id', how='inner')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub[sub.columns[1:]] = sub[sub.columns[1:]].clip(0, 1, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}