{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import sys\nsys.path.append(\"../input/moa-scripts\")\nfrom moa import load\nfrom metrics import logloss\n\nimport numpy as np\nimport pandas as pd\n\nimport warnings\nimport joblib\nimport gc\nfrom tqdm.auto import tqdm\nfrom collections import Counter\nfrom datetime import datetime \n\nimport matplotlib.pyplot as plt \nimport seaborn as sns\n\nfrom scipy import stats \nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import DBSCAN, KMeans\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.svm import OneClassSVM, SVC\nfrom sklearn.covariance import EllipticEnvelope\nfrom sklearn.neighbors import LocalOutlierFactor\nimport umap\n\nfrom tensorflow.keras import models\n\nsns.set_style(\"white\")\n%matplotlib inline\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X, y, genes, cells, classnames, features, X_test, test_control, submission = load()\nprint(str(datetime.now()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Low dim (viz)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# botlleneck autoencoder\nencoder = models.load_model(\"../input/moa-dae/encoder.h5\")\nenc_qt = joblib.load(\"../input/moa-dae/transformer.pkl\")\nXenc = enc_qt.transform(X[:, 4:])\nXenc = encoder.predict((Xenc[:, :772], Xenc[:, 772:]))\n\n# pca\npca = PCA(0.8, random_state=2020)\nXpca = pca.fit_transform(X)\n# umap\nXumap = umap.UMAP(n_neighbors=10, min_dist=0.5, metric='euclidean', verbose=0).fit_transform(X)\n# pca(emb)\npca_emb = PCA(0.8, random_state=2020)\nXpca_emb = pca_emb.fit_transform(Xenc)\nXumap_emb = umap.UMAP(n_neighbors=10, min_dist=0.5, metric='euclidean', verbose=0).fit_transform(Xenc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def eval_clusters(stat, cluster):\n    ttest_stats = pd.concat((stat.iloc[:, :206], stat[cluster]), axis=1).groupby(cluster).agg(['mean', 'std', 'count'])\n    pvalues = np.zeros(206, dtype=float)\n    statistics = np.zeros(206, dtype=float)\n    for i in range(206):\n        ttets_label_stats = ttest_stats[i].loc[0].tolist()+ttest_stats[i].loc[1].tolist()\n        s, p = stats.ttest_ind_from_stats(*ttets_label_stats, False)\n        pvalues[i] = p\n        statistics[i] = np.abs(s)\n    # print('pval<0.05:', f'{(result < 0.05).mean():.2f}')\n    # print('pval<0.01:', f'{(result < 0.01).mean():.2f}')\n    print(f'ttest statistic {statistics.mean():.2f}')\n    print(f'support {stat[cluster].sum()}')\n    \ndef plot_clusters(clusters=None, n=2, s=20, palette='colorblind'):\n    fig, ax = plt.subplots(1,4, figsize=(25, 6))\n    ax =ax.flatten()\n    sns.scatterplot(Xpca[:, 0], Xpca[:, 1], ax=ax[0], s=s, hue=clusters, palette=sns.color_palette(palette, n))\n    sns.scatterplot(Xumap[:, 0], Xumap[:, 1], ax=ax[1], s=s, hue=clusters, palette=sns.color_palette(palette, n))\n    sns.scatterplot(Xpca_emb[:, 0], Xpca_emb[:, 1], ax=ax[2], s=s, hue=clusters, palette=sns.color_palette(palette, n))\n    sns.scatterplot(Xumap_emb[:, 0], Xumap_emb[:, 1], ax=ax[3], s=s, hue=clusters, palette=sns.color_palette(palette, n))\n    ax[0].set_title(\"PCA\")\n    ax[1].set_title(\"UMAP\")\n    ax[2].set_title(\"PCAemb\")\n    ax[3].set_title(\"UMAPemb\")\n    for i in range(4):\n        ax[i].legend().set_visible(False)\n    plt.show();\n    \ndef eval_multiple_clusters(stat, cluster):\n    statistics = np.zeros(206, dtype=float)\n    for i in range(206):\n        samples = [sample[i].values for _, sample in stat[[cluster, i]].groupby(cluster)]\n        statistics[i] = np.abs(stats.kruskal(*samples))[0]\n    support = stat[cluster].value_counts().mean()\n    nclu = len(set(stat[cluster]))\n    print(f'clusters {nclu}')\n    print(f'support {support}')\n    print(f'ttest statistic [sqrt] {statistics.mean()/np.sqrt(nclu):.2f}')\n    print(f'ttest statistic [log] {statistics.mean()/np.log(nclu):.2f}')\n    return statistics.mean()/np.sqrt(nclu)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_clusters()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stat = pd.DataFrame(y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## DBSCAN -> SVM"},{"metadata":{"trusted":true},"cell_type":"code","source":"# dbscan\ndb = DBSCAN(20, min_samples=800, leaf_size=50)\ndb.fit(Xpca)\ny_db = db.labels_.copy()\ny_db[y_db==-1] = 1\n\n# -> SVM\nsvm = SVC()\nsvm.fit(Xpca, y_db)\nstat['dbscan'] = (db.labels_>-1).astype(int)\nstat['dbscan_svm'] = svm.predict(Xpca)\n\ncluster = 'dbscan'\nplot_clusters(stat[cluster])\neval_clusters(stat, cluster)\nstat[\"random\"] = np.random.random(len(y)) < stat[cluster].mean()\nprint('vs random')\neval_clusters(stat, 'random')\n\njoblib.dump(svm, 'dbscan_svm.pkl')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Envelope"},{"metadata":{"trusted":true},"cell_type":"code","source":"ee = EllipticEnvelope(contamination=0.05, random_state=2020)\nee.fit(Xpca)\nstat['envelope'] = ee.predict(Xpca) == -1\n\ncluster = 'envelope'\nplot_clusters(stat[cluster])\neval_clusters(stat, cluster)\nstat[\"random\"] = np.random.random(len(y)) < stat[cluster].mean()\nprint('vs random')\neval_clusters(stat, 'random')\n\njoblib.dump(ee, 'envelope.pkl')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1class SVM"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time \nsvm1 = OneClassSVM(nu=0.1, gamma=1e-3)\nsvm1.fit(Xpca)\n\nstat['oneclasssvm'] = svm1.predict(Xpca) == -1\ncluster = 'oneclasssvm'\nplot_clusters(stat[cluster])\neval_clusters(stat, cluster)\nstat[\"random\"] = np.random.random(len(y)) < stat[cluster].mean()\nprint('vs random')\neval_clusters(stat, 'random')\n\njoblib.dump(svm1, 'svm1.pkl')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Kmeans"},{"metadata":{"trusted":true},"cell_type":"code","source":"# outlier detection (2 classes)\nkmeans = KMeans(2, n_init=5, max_iter=100, random_state=2020)\nkmeans.fit(Xpca)\n\nstat['kmeans'] = kmeans.predict(Xpca)\ncluster = 'kmeans'\nplot_clusters(stat[cluster])\neval_clusters(stat, cluster)\nstat[\"random\"] = np.random.random(len(y)) < stat[cluster].mean()\nprint('vs random')\neval_clusters(stat, 'random')\n\njoblib.dump(kmeans, 'kmeans.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# history = []\n# for c in [14, 18]:\n#     print('='*100)\n#     kmeans = KMeans(c, n_init=5, max_iter=100, random_state=2020)\n#     kmeans.fit(Xpca)\n#     stat['kmeans2'] = kmeans.predict(Xpca)\n#     stat['random'] = stat['kmeans2'].copy(deep=True)\n#     stat['random'] = stat['random'].sample(frac=1.0).values\n#     history.append(eval_multiple_clusters(stat, 'kmeans2'))\n#     eval_multiple_clusters(stat, 'random')\n#     # plot_clusters(stat['kmeans2'], len(set(stat['kmeans2'])))\n# sns.lineplot(x=np.arange(len(history))*2, y=history);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans = KMeans(18, n_init=5, max_iter=100, random_state=2020)\nkmeans.fit(Xpca)\nstat['kmeans2'] = kmeans.predict(Xpca)\nplot_clusters(stat['kmeans2'], len(set(stat['kmeans2'])), s=15)\n\njoblib.dump(kmeans, 'kmeans14.pkl')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## GMM"},{"metadata":{"trusted":true},"cell_type":"code","source":"# outlier det (2 comps)\ngmm = GaussianMixture(2, n_init=1, covariance_type='tied', random_state=2020)\ngmm.fit(Xpca)\ncluster = 'gmm'\nstat[cluster] = gmm.predict(Xpca)\nplot_clusters(stat[cluster])\neval_clusters(stat, cluster)\nstat[\"random\"] = np.random.random(len(y)) < stat[cluster].mean()\nprint('vs random')\neval_clusters(stat, 'random')\n\njoblib.dump(gmm, 'gmm.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# history = []\n# cluster = 'gmm2'\n# x = np.arange(22, 27, 1)\n# for c in x:\n#     print('='*100)\n#     print(str(datetime.now()))\n#     gmm = GaussianMixture(c, n_init=1, covariance_type='tied', random_state=2020, max_iter=30)\n#     gmm.fit(Xpca)\n#     stat[cluster] = gmm.predict(Xpca)\n#     history.append(eval_multiple_clusters(stat, cluster))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gmm = GaussianMixture(11, n_init=1, covariance_type='tied', random_state=2020, max_iter=30)\ngmm.fit(Xpca)\ncluster = 'gmm2'\nstat[cluster] = gmm.predict(Xpca)\nplot_clusters(stat[cluster], len(set(stat[cluster])), s=10, palette='Paired')\neval_multiple_clusters(stat, cluster)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output = stat.iloc[:, 206:].copy(deep=True)\noutput.drop('random', axis=1, inplace=True)\njoblib.dump(output, 'output.pkl')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## TEST check"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_pca = pca.transform(X_test)\nX_test_emb = enc_qt.transform(X_test[:, 4:])\nX_test_emb = encoder.predict((X_test_emb[:, :772], X_test_emb[:, 772:]))\nX_test_umap = umap.UMAP(n_neighbors=10, min_dist=0.5, metric='euclidean', verbose=0).fit_transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_test_clusters(clusters=None):\n    fig, ax = plt.subplots(1,3, figsize=(19, 6))\n    ax =ax.flatten()\n    sns.scatterplot(X_test_pca[:, 0], X_test_pca[:, 1], ax=ax[0], s=20, hue=clusters)\n    sns.scatterplot(X_test_umap[:, 0], X_test_umap[:, 1], ax=ax[1], s=20, hue=clusters)\n    sns.scatterplot(X_test_emb[:, 0], X_test_emb[:, 1], ax=ax[2], s=20, hue=clusters)\n    ax[0].set_title(\"PCA\")\n    ax[1].set_title(\"UMAP\")\n    ax[2].set_title(\"PCAemb\")\n    plt.show();\n\nplot_test_clusters()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_test_clusters(svm.predict(X_test_pca))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_test_clusters(svm1.predict(X_test_pca)==-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_test_clusters(ee.predict(X_test_pca)==-1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Pairs + triplets"},{"metadata":{"trusted":true},"cell_type":"code","source":"# pairs = []\n# for r in trg[df.targets==2].iterrows():\n#     pairs.append(tuple(r[-1][r[-1]==1].index))\n# pairs = Counter(pairs)\n# triplets = []\n# for r in trg[df.targets==3].iterrows():\n#     triplets.append(tuple(r[-1][r[-1]==1].index))\n# triplets = Counter(triplets)\n# trg_corr=trg.corr()\n# np.fill_diagonal(trg_corr.values, 0)\n# top_corr = {}\n# for r in trg_corr.iterrows():\n#     d1 = r[0]\n#     d2 = list(r[1][r[1]<-0.3])\n#     d3 = list(r[1][r[1]>0.4])\n#     if len(d2) or len(d3):\n#         top_corr[d1] = (d2, d3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## t.test"},{"metadata":{"trusted":true},"cell_type":"code","source":"trg = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\ndf = pd.read_csv('../input/lish-moa/train_features.csv')\nnonscored = pd.read_csv('../input/lish-moa/train_targets_nonscored.csv')\nts = pd.read_csv('../input/lish-moa/test_features.csv')\ntrg = trg[df['cp_type']!='ctl_vehicle']\nnonscored = nonscored[df['cp_type']!='ctl_vehicle']\ndf = df[df['cp_type']!='ctl_vehicle']\nts = ts[ts['cp_type']!='ctl_vehicle']\ntrg.set_index('sig_id', inplace=True)\ndf.set_index('sig_id', inplace=True)\nnonscored.set_index('sig_id', inplace=True)\ndf['targets'] = trg.sum(axis=1)\n\ndf.loc[df['targets']>=3, 'targets'] = 3\ndf['targetsb'] = df['targets'].copy()\ndf.loc[df['targets']>=1, 'targetsb'] = 1\nmeans = df.loc[:, 'g-0':'targetsb'].groupby('targetsb').agg(['mean', 'std', 'count']).stack()\npvalue = {f:stats.ttest_ind_from_stats(*means.loc[:, f].values, False)[-1] for f in means.columns[:-1]}\npvalue = pd.Series(pvalue)\n\njoblib.dump(pvalue, \"ttest_pvalue.pkl\")\n(pvalue >= 0.01).sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Interactions & numeric transformation"},{"metadata":{"trusted":true},"cell_type":"code","source":"features_ttest = {f: np.abs( stats.ttest_ind_from_stats(*means.loc[:, f].values, False)[0] ) for f in means.columns[:-1]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"interactions = []\nflist = [f for f in list(features_ttest) if pvalue[f] > 1e-5 and 'g-' in f]\ndf_inter = df[['targetsb']].copy(deep=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Multiply\nfor i1 in tqdm(range(len(flist))):\n    f1 = flist[i1]\n    for i2 in range(i1+1, len(flist)):\n        f2 = flist[i2]\n        df_inter['f'] = df[f1] * df[f2]\n        ttest, pval = stats.ttest_ind_from_stats(*df_inter.groupby('targetsb').agg(['mean', 'std', 'count']).stack().values, False)\n        if pval < min(pvalue[f1], pvalue[f2]) and pval < 1e-10:\n            r = ('*',f1,f2,pval)\n            interactions.append(r)\n            print(r)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Sum\nfor i1 in tqdm(range(len(flist))):\n    f1 = flist[i1]\n    for i2 in range(i1+1, len(flist)):\n        f2 = flist[i2]\n        df_inter['f'] = df[f1] + df[f2]\n        ttest, pval = stats.ttest_ind_from_stats(*df_inter.groupby('targetsb').agg(['mean', 'std', 'count']).stack().values, False)\n        if pval < min(pvalue[f1], pvalue[f2]) and pval < 1e-10:\n            r = ('+',f1,f2,pval)\n            interactions.append(r)\n            #print(r)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Square\nfor i1 in tqdm(range(len(flist))):\n    f1 = flist[i1]\n    df_inter['f'] = df[f1] ** 2\n    ttest, pval = stats.ttest_ind_from_stats(*df_inter.groupby('targetsb').agg(['mean', 'std', 'count']).stack().values, False)\n    if pval < 1e-10:\n        r = ('**',f1,None,pval)\n        interactions.append(r)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"joblib.dump(interactions, 'interactions.pkl');\nprint(\n    len(interactions)\n    ,len([_ for i in interactions if i[-1]<1e-15])\n    ,len([_ for i in interactions if i[-1]<1e-30])\n    ,len([_ for i in interactions if i[-1]<1e-50])\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### KMeans 10: splits"},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA(0.8, random_state=2020)\nXpca = pca.fit_transform(np.concatenate([X, y], axis=1))\nprint(Xpca.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans = KMeans(100, n_init=5, max_iter=100, random_state=2020)\nkmeans.fit(Xpca)\nstat['split'] = kmeans.predict(Xpca)\nplot_clusters(stat['split'], len(set(stat['split'])), s=12)\neval_multiple_clusters(stat, \"split\")\njoblib.dump(stat['split'].values, 'split_kmeans_100.pkl')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}