{"cells":[{"metadata":{},"cell_type":"markdown","source":"This kernel is dedicated to a comparison of the test and training samples.\nSometimes it is critical for proper validation to ensure that the train and test samples are homogeneous.\n\nKernel plan:\n1. Compare features by bucketing method: Population Stability Index\n2. Extract most important features from GBM adversarial validation\n3. Explore results"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import sys\nsys.path.append(\"../input/moa-scripts\")\nfrom moa import load_datasets, preprocess, split\nfrom metrics import logloss\nimport lgbm as lgb_tools\nfrom lightgbm import LGBMClassifier\n\nimport numpy as np\nimport pandas as pd\nimport warnings\nimport joblib\nimport gc\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nfrom tqdm.auto import tqdm\n\nsns.set_style(\"dark\", {\"axes.facecolor\": \".92\"})\n%matplotlib inline\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Build train/test dataset, test sample is target"},{"metadata":{"trusted":true},"cell_type":"code","source":"X, y, _, test, _ = load_datasets(\"../input/lish-moa\")\nX, _, test, test_control = preprocess(X, y, test, standard=False, onehot=True)\ntest = test[~test_control]\ntest = pd.DataFrame(test, columns=X.columns)\nn_train = len(X)\nX = pd.concat([X, test])\nX['target'] = 0\nX['target'].iloc[n_train:] = 1\nX.reset_index(drop=True, inplace=True)\ndel test; gc.collect()\n\nX.shape, X.target.sum(), X.shape[0] - X.target.sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## PSI"},{"metadata":{"trusted":true},"cell_type":"code","source":"class AdversarialValidation:\n    \"\"\"\n    Simple class for adversarial analysis\n    Bucket and compare each feature from train and test samples using PSI or KL\n    PSI: https://www.lexjansen.com/wuss/2017/47_Final_Paper_PDF.pdf\n    KL : https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence\n    \"\"\"\n    def __init__(self, eps=1-3, target='target'):\n        self.target = target\n        self.eps = eps\n    \n    def breakpoints(self, x, n_bins, btype):\n        if btype == 'bins':\n            min, max = x.min(), x.max()\n            return np.linspace(min, max, n_bins)\n        elif btype == 'quantiles':\n            qnt = np.linspace(0, 100, n_bins)\n            return np.stack([np.percentile(x, q) for q in qnt])\n        return btype\n\n    def kullback_leibler(self, p, q) -> float:\n        lg = np.log(p / q)\n        lg = np.where(np.isinf(lg), 0, lg)\n        lg = np.where(np.isnan(lg), 0, lg)\n        return np.sum(p * lg)\n\n    def psi(self, p, q) -> float:\n        lg = np.log(p / q)\n        lg = np.where(np.isinf(lg), 0, lg)\n        lg = np.where(np.isnan(lg), 0, lg)\n        return np.sum((p - q) * lg)\n    \n    def difference(self, X, method='kl', buckets=10, buckettype='bins'):\n        result = {}\n        target_mask = X[self.target] == 1\n        Na = target_mask.sum() #  `actual`: take test sample as real data\n        Ne = len(X) - Na       # `expected`: take train sample as standard\n        for c in tqdm(X.columns, desc=method):\n            if c == self.target: \n                continue\n            a, e = X.loc[target_mask, c].values, X.loc[~target_mask, c].values\n            breakpoints = self.breakpoints(X[c].copy(), buckets, buckettype)\n            e = np.histogram(e, breakpoints)[0] / Ne\n            a = np.histogram(a, breakpoints)[0] / Na\n            r = self.kullback_leibler(a, e) if method=='kl' else self.psi(a, e)\n            result[c] = r\n        return result\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"av = AdversarialValidation()\ndiff = av.difference(X, 'psi', 10, 'quantiles')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = list(diff)\nsusp = list(zip(*sorted(diff.items(), key=lambda x: x[1])[-16:][::-1]))[0]\n\nfrom pprint import pprint\npprint(sorted(diff.items(), key=lambda x: x[1])[-16:][::-1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### We can consider all features as homogeneous, since the worst index is << 0.1 (~0.01) "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"test_mask = X.target == 1\n\nfig, axes = plt.subplots(4, 4, figsize=(20, 20))\naxes=axes.flatten()\nfor i in range(4*4):\n    sns.distplot(X.loc[~test_mask, susp[i]], label='train', hist=0, ax=axes[i])\n    sns.distplot(X.loc[test_mask, susp[i]], label='test', hist=0, ax=axes[i])\n    axes[i].legend()\nsns.despine()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### *Train-test distributions looks almost the same"},{"metadata":{},"cell_type":"markdown","source":"## Adversarial validation with model"},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(1)\n\nX = X.sample(frac=1.0, random_state=1)\ny = X['target'].values\nX.drop('target', axis=1, inplace=True)\nX_train, y_train = X.iloc[:15000], y[:15000]\nX_valid, y_valid = X.iloc[15000:], y[15000:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nfrom sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression(C=0.01, random_state=1)\nlr.fit(X_train, y_train)\nprint(f\"Adversarial AUC [LR]:{roc_auc_score(y_valid, lr.predict_proba(X_valid)[:, 1])}\")\n\ngbm = LGBMClassifier(num_leaves=7, seed=1)\ngbm.fit(X_train, y_train, eval_set=(X_valid, y_valid), early_stopping_rounds=5, verbose=0);\nfrom sklearn.metrics import roc_auc_score\nprint(f\"Adversarial AUC[GBM]:{roc_auc_score(y_valid, gbm.predict_proba(X_valid)[:, 1])}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gbm_susp = [f for i, f in zip(gbm.feature_importances_, features) if i]\nset(susp) & set(gbm_susp) # psi and gbm feature sets not intersect (almost)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def eval_selection(selection, label):\n    xt, xv = X_train.copy().drop(selection, axis=1), X_valid.copy().drop(selection, axis=1)\n    \n    lr = LogisticRegression(C=0.01, random_state=1)\n    lr.fit(xt, y_train)\n    print(f\"Adversarial AUC [LR]-[{label}]:{roc_auc_score(y_valid, lr.predict_proba(xv)[:, 1])}\")    \n    \n    gbm = LGBMClassifier(num_leaves=7, seed=1)\n    gbm.fit(xt, y_train, eval_set=(xv, y_valid), early_stopping_rounds=5, verbose=0);\n    print(f\"Adversarial AUC[GBM]-[{label}]:{roc_auc_score(y_valid, gbm.predict_proba(xv)[:, 1])}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eval_selection(list(susp), 'PSI')\neval_selection(gbm_susp, 'GBM')\neval_selection(list(set(susp)|set(gbm_susp)), 'PSI+GBM')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* we did't use logreg's most valuable features and feature selection didn't affect its AUC\n* but GBM AUC become much better"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"\n## Final conclusions: \n* train and test samples are almost homogenous\n* it's possible to make them absolutely homogenous after removing (or fixing somehow) small amount of features\n* however, it requires building a large number of different models and time consuming"},{"metadata":{"trusted":true},"cell_type":"code","source":"# PSI features\nsusp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# GBM features\ngbm_susp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}