{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os \nfrom collections import Counter\nfrom tqdm import tqdm\nfrom IPython.display import display\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\ndata_path = \"../input/lish-moa\"\n!ls -l --block-size=M $data_path","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"%%time\ntrain_features = pd.read_csv(os.path.join(data_path, \"train_features.csv\"))\ntrain_targets_s= pd.read_csv(os.path.join(data_path, \"train_targets_scored.csv\"))\ntrain_targets_n= pd.read_csv(os.path.join(data_path, \"train_targets_nonscored.csv\"))\ntest_features  = pd.read_csv(os.path.join(data_path, \"test_features.csv\"))\nsample_submission = pd.read_csv(os.path.join(data_path, \"sample_submission.csv\"))\n\ntrain_features.set_index('sig_id', inplace=True)\ntrain_targets_s.set_index('sig_id', inplace=True)\ntest_features.set_index('sig_id', inplace=True)\nsample_submission.set_index('sig_id', inplace=True)\n\nassert np.all(test_features.index == sample_submission.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"train shape {train_features.shape}\")\nprint(f\"test  shape {test_features.shape}\")\nprint(f\"train targets scored shape {train_targets_s.shape}\")\nprint(f\"train targets nonscored shape {train_targets_n.shape}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data exploration","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### As it mentioned in competition data overview, features consist of 2 huge groups (related to genes & cell)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# features \nfeatures = list(train_features.columns)\nshort_features = Counter([f[:2] for f in features])\nshort_features","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### It's a multilabel task","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_targets_s.sum(axis=1).value_counts().sort_index().plot(kind=\"bar\", title=\"targets per record\", figsize=(7,4));","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Pairs \"agonist-antagonist\" are not always mutually exclusive","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# detect pairs \"agonist-antagonist\"\npairs = Counter([t.replace(\"_antagonist\", \"\").replace(\"_agonist\", \"\") for t in train_targets_s.columns])\npairs = [t for t, count in list(pairs.items()) if count == 2]\n\n# check if pairs \"agonist-antagonist\" is crossing\ndef filter_columns(df, s):\n    columns = [c for c in df.columns if s in c]\n    return df[columns]\n\nfor p in pairs:\n    df = filter_columns(train_targets_s, p)\n    boolean = np.all(df.sum(axis=1) < 2)\n    if not boolean:\n        print(p, len(df[df.sum(axis=1) == 2]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Labels are very unbalanced","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_targets_s.mean(axis=0)[1:].plot(kind=\"hist\", bins=50, title=\"classes distribution\", figsize=(8,5));","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Inside control groups all targets is 0","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"display(train_features.cp_type.value_counts(normalize=True))\n\ntrain_features['targets_total'] = train_targets_s.sum(axis=1)\ntrain_features.groupby('cp_type')['targets_total'].sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Experiment features have no obvious connection with targets","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"display(train_features.groupby('cp_time')['targets_total'].sum())\ntrain_features.groupby('cp_dose')['targets_total'].sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Continuous features exploration","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1. Features are continuous\nassert np.all(filter_columns(train_features, \"g-\").dtypes == \"float64\")\nassert np.all(filter_columns(train_features, \"c-\").dtypes == \"float64\")\n# 2. Gene features belong range [-10, 10]\nassert filter_columns(train_features, \"g-\").max().max() == 10\nassert filter_columns(train_features, \"g-\").min().min() == -10\n# 3. Cell features belong range [-10, <10]\nassert filter_columns(train_features, \"c-\").max().max() < 10\nassert filter_columns(train_features, \"c-\").min().min() == -10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# means distribution\nsns.distplot(filter_columns(train_features, \"c-\").mean(), label=\"cell\")\nsns.distplot(filter_columns(train_features, \"g-\").mean(), label=\"gene\")\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def distplots(df, columns, nrows=1, ncols=5, title=\"\", figsize=(15,3)):\n    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize)\n    axes = axes.flatten()\n    fig.suptitle(title)\n    for i, column in enumerate(columns):\n        sns.distplot(df[column], ax=axes[i])\n        axes[i].axes.yaxis.set_visible(False)\n    # sns.despine(left=True)\n    plt.show()\n\ncolumns = filter_columns(train_features, \"c-\").iloc[:, [0,10,20,30,42,45,77]].columns.tolist()\ndistplots(train_features, columns, ncols=len(columns), figsize=(len(columns)*3, 3), title=\"Cell features example\")\ncolumns = filter_columns(train_features, \"g-\").iloc[:, [0,12,42,101,202,303,424]].columns.tolist()\ndistplots(train_features, columns, ncols=len(columns), figsize=(len(columns)*3, 3), title=\"Gene features example\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Looks like distributions of features close to normal (with small left and right tails)\n* Cell features skewed to left a little bit; perhaps, it would be useful to create the bucket of left tail for most important cell features","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Feature interactions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def columnwise_corrcoef(m, v):\n    \"\"\" \n    Vectorized columnwise pearson correlation\n    Means of all columns should be equal 0\n    m: matrix \n    v: vector\n    \"\"\"\n    return (v @ m) / np.sqrt(np.sum(m ** 2, 0) * np.sum(v ** 2))\n\ncorr_features = train_features.columns[3:]\ndf_corr = train_features.copy().loc[train_features.cp_type=='trt_cp', corr_features].astype(np.float64)\ndf_corr = df_corr - df_corr.mean()\ndf_corr = df_corr.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = np.eye(len(corr_features), dtype=np.float32)\nn = len(corr_features)\nfor i in tqdm(range(n)):\n    corr[i] = columnwise_corrcoef(df_corr, df_corr[:, i])\nassert np.all(np.diag(corr) == 1)\nassert np.min(corr) >= -1\nassert np.max(corr) <= 1\nnp.fill_diagonal(corr, 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### There's not much linear correlation between targets and features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(corr[:, -1], bins=40)\nsns.despine()\nplt.xlim(-0.5, 0.5)\nplt.title(\"target correlation\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Cell features have huge correlation between each other","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# help(sns.heatmap)\nplt.figure(figsize=(20, 15))\nsns.heatmap(corr, \n            xticklabels=[],\n            yticklabels=[],\n            cmap=\"cividis\"\n           );","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cell_corr = corr[-100:, -100:].copy()\nnp.fill_diagonal(cell_corr, 1)\nprint(\"cell features R =\", cell_corr.mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Rare targets (<5 records) will always set to 0 in prediction","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"targets_sum = train_targets_s.sum(axis=0)\nrare_targets = targets_sum[targets_sum < 5].index.tolist()\ntrain_targets_s.drop(rare_targets, axis=1, inplace=True)\nrare_targets, train_targets_s.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Validation split","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features.drop('targets_total', axis=1, inplace=True) # remove targets from train set","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Test and train `cp_type` distributions are similar: no need in upsampling/downsampling by experiment type","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"assert np.all(train_features.index == train_targets_s.index)\ntest_features['cp_type'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preprocessing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# onehot encoding experiment features\nfrom sklearn.preprocessing import OneHotEncoder\n\nencoder = OneHotEncoder(sparse=False)\ncategorical_features = ['cp_type', 'cp_time', 'cp_dose']\ncategories = encoder.fit_transform(train_features[categorical_features])\ncategories = categories[:, 1:] # keeps only 1 column for cp_type\n\ndef join_columns(c1,c2,sep='__'):\n    return sep.join([str(c1),str(c2)])\noh_features = [join_columns(f, v) for f, c in zip(categorical_features, encoder.categories_) for v in c][1:]\n\ntrain_features.drop(categorical_features, axis=1, inplace=True)\ntrain_features = pd.concat([\n    pd.DataFrame(categories, index=train_features.index, columns=oh_features), \n    train_features\n], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make holdout fold\nfrom sklearn.model_selection import train_test_split\nX_train, X_hold, y_train, y_hold = train_test_split(\n    train_features, train_targets_s, \n    test_size=0.25, \n    random_state=171, shuffle=True\n)\nassert y_hold.loc[:, y_hold.sum(axis=0)<1].shape[1] == 0\n\nctype_train, ctype_hold = X_train.iloc[:, 0].values, X_hold.iloc[:, 0].values\nctype_train= ctype_train.astype(bool)\nctype_hold = ctype_hold.astype(bool)\nassert y_hold[~ctype_hold].sum().sum() == 0\n\ny_hold = y_hold.values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Baseline models","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.drop('cp_type__trt_cp', axis=1, inplace=True)\nX_hold.drop('cp_type__trt_cp', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# metrics \nfrom sklearn.metrics import log_loss\n\ndef sklearn_multilabel_logloss(y_true, y_pred):\n    \"\"\" Sanity check \"\"\"\n    return np.mean([log_loss(y_true[:, i], y_pred[:, i]) for i in range(y_pred.shape[1])])\n\ndef logloss(y_true, y_pred, eps=1e-15):\n    y_pred[y_pred==0] = eps\n    y_pred[y_pred==1] = 1 - eps\n    return - (y_true * np.log(y_pred) + (1 - y_true) * (np.log(1 - y_pred))).mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Constant","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for c in np.arange(0.1, 0.51, 0.2):\n    y_pred = np.full_like(y_hold, c, dtype=np.float64)\n    y_pred[~ctype_hold] = 0\n    print(f\"constant={c:.1f} logloss={logloss(y_hold, y_pred):.5f}\")\n\nassert np.allclose(sklearn_multilabel_logloss(y_hold, y_pred) - logloss(y_hold, y_pred), 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Means","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class MultilabelMeanEstimator:\n    def __init__(self):\n        self._means = None\n    def fit(self, y_train):\n        self._means = y_train.mean(axis=0).to_dict()\n    def predict(self, test, zero_mask=None):\n        assert self._means, \"estimator isn't fitted\"\n        pred = np.zeros((len(test), len(self._means)), dtype=np.float64)\n        for i, c in enumerate(test.columns):\n            pred[:, i] = self._means[c]\n        if zero_mask is not None:\n            pred[zero_mask] = 0\n        return pred\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"estimator = MultilabelMeanEstimator()\nestimator.fit(y_train)\ntest = pd.DataFrame(y_hold, columns=y_train.columns)\ny_pred = estimator.predict(test, ~ctype_hold)\nprint(f\"Means logloss = {logloss(y_hold, y_pred): .5f}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# return rare targets\ntrain_targets_s[rare_targets] = 0\n\n# fit on full train data\nestimator = MultilabelMeanEstimator()\nestimator.fit(train_targets_s)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prediction","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"zero_mask = (test_features.cp_type == 'ctl_vehicle').values # set control group to 0\nprediction = estimator.predict(sample_submission, zero_mask)\nsubmission = pd.DataFrame(prediction, columns=sample_submission.columns, index=sample_submission.index)\nsubmission.to_csv(\"submission.csv\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}