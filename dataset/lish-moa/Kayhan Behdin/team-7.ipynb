{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import regularizers\n\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import log_loss\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom sklearn.model_selection import KFold\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import uniform\nfrom sklearn.preprocessing import normalize","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-06T00:22:48.165697Z","iopub.execute_input":"2021-08-06T00:22:48.166081Z","iopub.status.idle":"2021-08-06T00:22:55.393169Z","shell.execute_reply.started":"2021-08-06T00:22:48.166049Z","shell.execute_reply":"2021-08-06T00:22:55.392422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-08-06T00:22:16.311937Z","iopub.execute_input":"2021-08-06T00:22:16.312492Z","iopub.status.idle":"2021-08-06T00:22:16.388802Z","shell.execute_reply.started":"2021-08-06T00:22:16.312385Z","shell.execute_reply":"2021-08-06T00:22:16.387486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_features = pd.read_csv('/kaggle/input/lish-moa/train_features.csv')\ntrain_targets = pd.read_csv('/kaggle/input/lish-moa/train_targets_scored.csv')\n\ntrain_features_enc = pd.get_dummies(train_features, columns=['cp_type', 'cp_dose'], drop_first=True)\nX = train_features_enc.iloc[:,1:].to_numpy()\ny = train_targets.iloc[:,1:].to_numpy()","metadata":{"execution":{"iopub.status.busy":"2021-08-06T00:22:55.394388Z","iopub.execute_input":"2021-08-06T00:22:55.394816Z","iopub.status.idle":"2021-08-06T00:23:02.479837Z","shell.execute_reply.started":"2021-08-06T00:22:55.394785Z","shell.execute_reply":"2021-08-06T00:23:02.478797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device_name = tf.test.gpu_device_name()\nif \"GPU\" not in device_name:\n    print(\"GPU device not found\")\nprint('Found GPU at: {}'.format(device_name))","metadata":{"execution":{"iopub.status.busy":"2021-08-06T00:23:09.271808Z","iopub.execute_input":"2021-08-06T00:23:09.27219Z","iopub.status.idle":"2021-08-06T00:23:09.290625Z","shell.execute_reply.started":"2021-08-06T00:23:09.272154Z","shell.execute_reply":"2021-08-06T00:23:09.289788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_hist(hist, last = None):\n    if last == None:\n        last = len(hist.history[\"loss\"])\n    plt.plot(hist.history[\"loss\"][-last:])\n    plt.plot(hist.history[\"val_loss\"][-last:])\n    plt.title(\"model accuracy\")\n    plt.ylabel(\"accuracy\")\n    plt.xlabel(\"epoch\")\n    plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-05T23:58:29.998262Z","iopub.execute_input":"2021-08-05T23:58:29.998578Z","iopub.status.idle":"2021-08-05T23:58:30.004885Z","shell.execute_reply.started":"2021-08-05T23:58:29.998549Z","shell.execute_reply":"2021-08-05T23:58:30.003947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#0.0161\nX_normalized = normalize(X)\n\ndef l3_res_model_2(input_shape, no_classes, lr):\n    inputs = tf.keras.Input(shape=input_shape)\n    x = layers.Dense(128, activation='sigmoid')(inputs)\n    x = layers.BatchNormalization()(x)\n    b_1 = layers.Dropout(0.2)(x)\n    x = layers.Dense(128, activation='sigmoid')(b_1)\n    x = layers.BatchNormalization()(x)\n    b_2 = layers.Dropout(0.2)(x)\n    x = layers.Dense(128, activation='sigmoid')(b_2)\n    x = layers.BatchNormalization()(x)\n    b_3 = layers.Dropout(0.2)(x)\n    x = layers.Dense(128, activation='sigmoid')(b_3)\n    x = layers.BatchNormalization()(x)\n    b_4 = layers.Dropout(0.2)(x)\n    x = layers.Dense(128, activation='sigmoid')(b_4)\n    x = layers.BatchNormalization()(x)\n    b_5 = layers.Dropout(0.2)(x)\n    \n    tot_op = tf.keras.layers.add([b_1, b_2, b_3, b_4, b_5])\n    outputs = layers.Dense(no_classes, activation='sigmoid')(tot_op)\n    model = tf.keras.Model(inputs, outputs)\n    model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate = lr), metrics=['binary_crossentropy'])\n    return model\n\nlosses_NN=[]\nkf = KFold(n_splits=10)\ntf.random.set_seed(1010)\nnp.random.seed(1010)\n\nfor train_index, test_index in kf.split(X):\n    X_train, X_test = X_normalized[train_index], X_normalized[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n\n    control_vehicle_mask = X_train[:,-2] == 0\n    X_train = X_train[~control_vehicle_mask,:]\n    y_train = y_train[~control_vehicle_mask]\n\n    nnclf = l3_res_model_2((875,),206,0.0005)\n    hist = nnclf.fit(X_train, y_train, batch_size=512, epochs=50, validation_data=(X_test, y_test), verbose=0)\n    plot_hist(hist, last = 20)\n\n    preds = nnclf.predict(X_test) # list of preds per class\n\n    control_mask = X_test[:,-2]==0\n    preds[control_mask] = 0\n\n    loss = log_loss(np.ravel(y_test), np.ravel(preds))\n    print('Loss: '+str(loss))\n    losses_NN.append(loss)\n\nprint('Average Loss: '+str(np.average(losses_NN))) ","metadata":{"execution":{"iopub.status.busy":"2021-08-05T23:58:30.006411Z","iopub.execute_input":"2021-08-05T23:58:30.006706Z","iopub.status.idle":"2021-08-06T00:06:05.305551Z","shell.execute_reply.started":"2021-08-05T23:58:30.006677Z","shell.execute_reply":"2021-08-06T00:06:05.304538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_features = pd.read_csv('/kaggle/input/lish-moa/test_features.csv')\ntest_features_enc = pd.get_dummies(test_features, columns=['cp_type', 'cp_dose'], drop_first=True)\nX_test = test_features_enc.iloc[:,1:].to_numpy()","metadata":{"execution":{"iopub.status.busy":"2021-08-06T00:06:05.306829Z","iopub.execute_input":"2021-08-06T00:06:05.307121Z","iopub.status.idle":"2021-08-06T00:06:06.333729Z","shell.execute_reply.started":"2021-08-06T00:06:05.307091Z","shell.execute_reply":"2021-08-06T00:06:06.332725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_X_normalized = normalize(X_test)\nnnclf = l3_res_model_2((875,),206,0.0005)\nX_norm = normalize(X)\nhist = nnclf.fit(X_norm, y, batch_size=512, epochs=50, verbose=0)\npreds = nnclf.predict(test_X_normalized)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T00:06:06.334956Z","iopub.execute_input":"2021-08-06T00:06:06.335289Z","iopub.status.idle":"2021-08-06T00:06:54.483277Z","shell.execute_reply.started":"2021-08-06T00:06:06.335258Z","shell.execute_reply":"2021-08-06T00:06:54.482329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/lish-moa/sample_submission.csv')\ntest_submission = pd.DataFrame(preds)\ntest_submission.insert(0, 'sig_id', submission['sig_id'])\ntest_submission.columns = list(submission.columns)\ntest_submission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-06T00:08:17.10901Z","iopub.execute_input":"2021-08-06T00:08:17.109463Z","iopub.status.idle":"2021-08-06T00:08:18.474967Z","shell.execute_reply.started":"2021-08-06T00:08:17.109414Z","shell.execute_reply":"2021-08-06T00:08:18.474Z"},"trusted":true},"execution_count":null,"outputs":[]}]}