{"cells":[{"metadata":{},"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<a id=\"10\"></a>\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:gold; border:0; color:blue' role=\"tab\" aria-controls=\"home\"><center>Mechanism of Action</center></h2>\n\n\n<img src = \"https://image.slidesharecdn.com/mechanismofdrugaction-131104071748-phpapp01/95/mechanism-of-drug-action-3-638.jpg?cb=1383549622\">\n    \nThis competition is about MOA, so first let's understand what is it before moving to data and model building.\n    \nIn pharmacology, the term `Mechanism of Action (MOA)` refers to the specific biochemical interaction through which a drug substance produces its pharmacological effect. \n    \nA mechanism of action usually includes mention of the specific molecular targets to which the drug binds, such as an `enzyme` or `receptor`.\n\nIn the past, scientists derived drugs from natural products or were inspired by traditional remedies. \n    \nVery common drugs, such as paracetamol, known in the US as acetaminophen, were put into clinical use decades before the biological mechanisms driving their pharmacological activities were understood. \n    \nToday, with the advent of more powerful technologies, drug discovery has changed from the serendipitous approaches of the past to a more targeted model based on an understanding of the underlying biological mechanism of a disease. \n    \nIn this new framework, scientists seek to identify a protein target associated with a disease and develop a molecule that can modulate that protein target. \n    \nAs a shorthand to describe the biological activity of a given molecule, scientists assign a label referred to as mechanism-of-action or MoA for short."},{"metadata":{},"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<a id=\"10\"></a>\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:gold; border:0; color:blue' role=\"tab\" aria-controls=\"home\"><center>How do we determine the MoAs of a new drug?</center></h2>\n\nOne approach is to treat a sample of human cells with the drug and then analyze the cellular responses with algorithms that search for similarity to known patterns in large genomic databases, such as libraries of gene expression or cell viability patterns of drugs with known MoAs.\n\nIn this competition, we have access to a unique dataset that combines gene expression and cell viability data. \n    \nThe data is based on a new technology that measures simultaneously (within the same samples) human cells‚Äô responses to drugs in a pool of 100 different cell types (thus solving the problem of identifying ex-ante, which cell types are better suited for a given drug). \n    \nIn addition, we have access to MoA annotations for more than 5,000 drugs in this dataset.\n\nAs is customary, the dataset has been split into testing and training subsets. \n    \nHence, our task is to use the training dataset to develop an algorithm that automatically labels each case in the test set as one or more MoA classes. \n    \n**Note that since drugs can have multiple MoA annotations, the task is formally a multi-label classification problem.**"},{"metadata":{},"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<a id=\"10\"></a>\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:gold; border:0; color:blue' role=\"tab\" aria-controls=\"home\"><center>How to evaluate the accuracy of a solution?</center></h2>\n\nBased on the MoA annotations, the accuracy of solutions will be evaluated on the average value of the logarithmic loss function applied to each drug-MoA annotation pair.\n\nIf successful, we will help to develop an algorithm to predict a compound‚Äôs MoA given its cellular signature, thus helping scientists advance the drug discovery process."},{"metadata":{},"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<a id=\"10\"></a>\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:gold; border:0; color:blue' role=\"tab\" aria-controls=\"home\"><center>Information about the Data given for the competition</center></h2>\n    \nIn this competition, we will be predicting multiple targets of the Mechanism of Action (MoA) response(s) of different samples (sig_id), given various inputs such as gene expression data and cell viability data.\n\n**Important notes:**\n\n1)Training data has an additional (optional) set of MoA labels that are not included in the test data and not used for scoring.\n\n2)re-run dataset has approximately 4x the number of examples seen in the Public test.\n\n    \n**Files Provided:**\n    \n1) **train_features.csv** - Features for the training set. \n    \n    a) Features g- signify gene expression data\n    \n    b) c- signify cell viability data. \n    \n    c) cp_type indicates samples treated with a compound (cp_vehicle) or with a control perturbation (ctrl_vehicle); \n       control perturbations have no MoAs; \n    \n    d) cp_time and cp_dose indicate treatment duration (24, 48, 72 hours) \n    \n    e) cp_dose indicates whether the dose was high or low.\n\n2) **train_targets_scored.csv** - The binary MoA targets that are scored.\n\n3) **train_targets_nonscored.csv** - Additional (optional) binary MoA responses for the training data. These are not predicted nor scored.\n\n4) **test_features.csv** - Features for the test data. You must predict the probability of each scored MoA for each row in the test data.\n\n5) **sample_submission.csv** - A submission file in the correct format."},{"metadata":{},"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<a id=\"10\"></a>\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:gold; border:0; color:blue' role=\"tab\" aria-controls=\"home\"><center>Let's get Started!</center></h2>\n    \nWe have learnt enough about MOA and the competition, Its now time to load the datasets and check the data!"},{"metadata":{},"cell_type":"markdown","source":"### Import Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom colorama import Fore, Back, Style\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Set Style\nsns.set_style(\"whitegrid\")\nsns.despine(left=True, bottom=True)\n\n# Set Color Palettes for the notebook\ncolors_nude = ['#e0798c','#65365a','#da8886','#cfc4c4','#dfd7ca']\nsns.palplot(sns.color_palette(colors_nude))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Read Files"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/lish-moa/train_features.csv\")\ntest  = pd.read_csv(\"/kaggle/input/lish-moa/test_features.csv\")\nsub = pd.read_csv(\"/kaggle/input/lish-moa/sample_submission.csv\")\ntarget = pd.read_csv(\"/kaggle/input/lish-moa/train_targets_scored.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Check Training Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(Fore.YELLOW+\"Training dataset:\", Style.RESET_ALL + \"has {} rows and {} columns\".format(train.shape[0],train.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Training Dataset has 23814 samples and 875 feature variables excluding sig_id"},{"metadata":{},"cell_type":"markdown","source":"### Check Test Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(Fore.YELLOW+\"Test dataset:\", Style.RESET_ALL + \"has {} rows and {} columns\".format(test.shape[0],train.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Test Dataset has 3982 drug samples and 875 feature variables excluding sig_id\n* This means we need to make predictions for all these 3982 drugs for all the target variables"},{"metadata":{},"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<a id=\"10\"></a>\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:brown; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Check Target Features Dataset</center></h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(Fore.YELLOW+\"Feature dataset:\", Style.RESET_ALL + \"has {} rows and {} columns\".format(target.shape[0],target.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Important Observations ‚úç\n<br><br>\nüìå Here we have no. of rows equat to the training dataset, which makes complete sense\n<br>  \nüìå We have 207 target variables, which means we need to make predictions for 207 target variables for all the 3982 drug samples provided in the test data<br>\n\nüìå Now, this means our submission file should have a shape of 3982 rows and 207 columns<br> \n\nlets check if our understanding is correct!"},{"metadata":{"trusted":true},"cell_type":"code","source":"target.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<a id=\"10\"></a>\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:brown; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Check Submission File</center></h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv(\"../input/lish-moa/sample_submission.csv\")\nsub.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>üìå 3982 rows and 207 columns, exactly the shape we were expecting!<b>"},{"metadata":{},"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<a id=\"10\"></a>\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:brown; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Check Null Values</center></h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# helper function to check null values\ndef check_nulls(data):\n    isNull = \"N\"\n    for col in data.columns:\n        if data[col].isnull().sum() > 0:        \n            print(\"{} has {} null values\".format(col,data[col].isnull().sum()))\n            isNull = \"Y\"\n\n    if isNull == \"N\":\n        print(\"No Null Values found in the dataset\")   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"check_nulls(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"check_nulls(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"check_nulls(target)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No Null Values present in any of the datasets<b>"},{"metadata":{},"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<a id=\"10\"></a>\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:gold; border:0; color:blue' role=\"tab\" aria-controls=\"home\"><center>Exploratory Data Analysis!</center></h2>\n  \nWe have loaded all the necessary datasets, we have also taken a look at data available, \nIt's time to dig the data by performing EDA!"},{"metadata":{},"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<a id=\"10\"></a>\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:brown; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Let's dig training dataset</center></h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are total of 876 features,Majority of these are \"c-\" and \"g-\" types!\n\nLet's check if there are any duplicate \"sig_id\" in the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"#check for duplicate sig_ids in training dataset\nprint(\"Total no. of records in the training dataset: \",train.shape[0])\nprint(\"No. of unique sig_ids in the training dataset:\",train.sig_id.nunique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No. of unique sig_id is equal to the no. of rows in the training dataset, which means we dont have any duplicates here."},{"metadata":{},"cell_type":"markdown","source":"Let's now check the count of different kind of features in the dataset!"},{"metadata":{},"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<a id=\"10\"></a>\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:brown; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Feature Distribution</center></h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Count of \"c-\" & \"g-\" features\nc_count = 0\ng_count = 0\nothers = []\nfor feat in train.columns:\n        if (feat.find(\"c-\")) != -1:\n            c_count = c_count + 1\n        elif (feat.find(\"g-\")) != -1:\n            g_count = g_count + 1\n        else:\n            others.append(feat)\n            \nprint(Fore.YELLOW +\"No. of g- features:\", Style.RESET_ALL + \"{}\".format(g_count)) \nprint(Fore.YELLOW +\"No. of c- features:\", Style.RESET_ALL + \"{}\".format(c_count)) \nprint(Fore.YELLOW +\"Other features:\", Style.RESET_ALL + \"{}\".format(train.shape[1] \n                            - (c_count + g_count)),others)\n\n# visualize the no. of g- & c- features in the dataset\nothers = train.shape[1] - (c_count + g_count)\nplt.figure(figsize = (8,6))\nplt.bar([\"g-\", \"c-\",\"others\"], [g_count,c_count,others],color = colors_nude)\nplt.title(\"Categorical Features Distribution\")\nplt.xlabel(\"Features\")\nplt.ylabel(\"Count\")\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"g- & c- features contributes 99% of the features in the training dataset, and they are numeric features\nall other features are categorical features \n\nWe will now check how these features are distributed in the training dataset"},{"metadata":{},"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<a id=\"10\"></a>\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:brown; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Categorical Feature Distribution (cp_type, cp_time & cp_dose)</center></h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# helper function to plot categorical variables\ndef plot_cp(feats):    \n    print(\"--------------------\" + feats[0] + \"------------------------\")\n    print(train[feats[0]].value_counts())\n    print(\"---------------------------------------------------\")\n    print(\"\\n\")\n    print(\"--------------------\" + feats[1] + \"------------------------\")\n    print(train[feats[1]].value_counts())\n    print(\"---------------------------------------------------\")\n    print(\"\\n\")\n    print(\"--------------------\" + feats[2] + \"------------------------\")\n    print(train[feats[2]].value_counts())\n    print(\"---------------------------------------------------\")\n    \n    plt.figure(figsize = (21,8))\n    \n    plt.subplot(1,3,1)\n    sns.countplot(train[feats[0]],palette=colors_nude)\n    plt.xlabel(\"Features Distribution - \" + feats[0],fontsize=15)\n    plt.ylabel(\"Count\",fontsize=15)\n     \n    plt.subplot(1,3,2)\n    sns.countplot(train[feats[1]],palette=colors_nude)\n    plt.xlabel(\"Features Distribution - \" + feats[1],fontsize=15)\n    plt.ylabel(\"Count\",fontsize=15)\n        \n    plt.subplot(1,3,3)\n    sns.countplot(train[feats[2]],palette=colors_nude)\n    plt.xlabel(\"Features Distribution - \" + feats[2],fontsize=15)\n    plt.ylabel(\"Count\",fontsize=15)\n    \n    plt.suptitle(\"Feature Distribution for cp_ variable\",fontsize=25)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets check how the distribution of cp_ features looks like\nplot_cp(['cp_type','cp_dose','cp_time'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"cp_type\n   1.1 cp_type feature has 2 possible values: trt_cp & ctl_vehicle\n   1.2 It means that the samples are either treated with compount(trt_cp) or with a control perturbation(ctl_vehicle)\n   1.3 Majority of the samples are treated with compount\n\ncp_dose\n    1.1 cp_dose also has 2 possible values : D1 & D2\n    1.2 both values have almost equal presence in the dataset \n    \ncp_time\n      1.1 cp_time has 3 possible values : 24,48 & 72\n      1.2 All these values have almost equal presence in the dataset "},{"metadata":{},"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<a id=\"10\"></a>\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:brown; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Cell Viability Feature Distribution</center></h2>"},{"metadata":{},"cell_type":"markdown","source":"Cell viability is a measure of the proportion of live, healthy cells within a population. \n\nCell viability assays are used to determine the overall health of cells, optimize culture or experimental conditions, and to measure cell survival following treatment with compounds, such as during a drug screen.\n\nCell-viability assessment is based on `PRISM` technology. \n\nPRISM is a high-throughput screen for assessing cell viability in which cell lines that have each been labelled with a unique 24-nucleotide barcode are pooled and treated with the experimental condition, and surviving cells are ‚Äúcounted‚Äù through identification of the cognate barcode. \n\nPRISM is an acronym for `Profiling Relative Inhibition Simultaneously in Mixture`.\n\nThere are 100 cell-viability features (c-0 to c-99) in the training dataset. \n\nEach cell-viability feature represents viability of one particular cell line, and all experiments are based on a set of similar cells. These are mostly cancer cells."},{"metadata":{"trusted":true},"cell_type":"code","source":"# make seperate lists for various type of features\nc_list = []\ng_list = []\nothers = []\nfor feat in train.columns:\n        if (feat.find(\"c-\")) != -1:\n            c_list.append(feat)\n        elif (feat.find(\"g-\")) != -1:\n            g_list.append(feat)\n        else:\n            others.append(feat)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Cell Viability - Meta Statistics"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12,10))\n\nplt.subplot(2,2,1)\nsns.distplot(train[c_list].describe().values[1],color = \"red\")\nplt.title(\"Mean\",fontsize=15)\n\nplt.subplot(2,2,2)\nsns.distplot(train[c_list].describe().values[2],color = \"blue\")\nplt.title(\"Standar Deviation\",fontsize=15)\n\n\nplt.subplot(2,2,3)\nsns.distplot(train[c_list].describe().values[3],kde_kws={'bw': 0.1},color = \"green\")\nplt.title(\"Mininmum Value\",fontsize=15)\n\nplt.subplot(2,2,4)\nsns.distplot(train[c_list].describe().values[7],color = \"yellow\")\nplt.title(\"Maximum Value\",fontsize=15)\n\n\nplt.suptitle(\"Cell Viability - Meta Statistics\",fontsize=20)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* What a sharp contrast to the gene meta distributions. Most obviously, the minima are nearly all below -9.5, rising up to the border of -10. The maxima show a much broader distribution between 3 and 5.\n \n* As a consequence of this imbalance, the means are shifted towards negative values around -0.5. Note, that none of the means is above zero. The distribution of standard deviations is shifted from around 1 to around 2, compared to the gene data, with a notable tail towards small values."},{"metadata":{"trusted":true},"cell_type":"code","source":"# helper function to plot distribution of g- & c- features\ndef plot_g_c(feats,type):    \n        \n    plt.figure(figsize = (15,30))\n    \n    for idx,feat in enumerate(feats):\n        plt.subplot(5,2,idx+1)\n        sns.distplot(train[feats[idx]],color = \"red\")\n        plt.xlabel(\"Features Distribution - \" + feats[idx],fontsize=15)\n        plt.ylabel(\"Count\",fontsize=15)\n        plt.title(feats[idx],fontsize=15)\n    \n    plt.suptitle(type + \" Features - Distribution\",fontsize=20)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# call the helper function to check c- feature distribution\nplot_g_c(['c-1','c-20','c-30','c-40','c-50','c-60','c-65','c-70','c-75','c-99'],\"Cell Viability\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Most common cell viability feature distribution looks like a left-skewed bell curve with mean close to 0.5\n* Features with most different distributions are c-37, c-58, c-69, c-74 and c-76 because of their shorter tails\n* They have higher overall cell viability. Minimum values in other features are clipped at -10, but it wasn't required for formerly mentioned features"},{"metadata":{},"cell_type":"markdown","source":"### Correlation Matrix between c- variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"# heat map\nplt.figure(figsize = (50,100))\ncorrMatrix = train[c_list].corr()\nmask = np.triu(corrMatrix)\nsns.heatmap(corrMatrix,\n            annot=True,\n            fmt='.1f',\n            cmap='coolwarm',            \n            mask=mask,\n            linewidths=1,\n            cbar=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Cell Viability variables are highly correlated with each other"},{"metadata":{},"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<a id=\"10\"></a>\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:brown; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Gene Expression Feature Distribution</center></h2>"},{"metadata":{},"cell_type":"markdown","source":"Gene expression is the amount and type of proteins that are expressed in a cell at any given point in time. \n\nGene expression level is based on a protocol similar to L1000 which is a high-throughput gene expression assay that measures the mRNA transcript abundance of 978 \"landmark\" genes from human cells. (The \"L\" in L1000 refers to the Landmark genes measured in the assay.)\n\nThere are 772 gene expression features (g-0 to g-771) present in the training dataset. \n\nEach gene expression feature represents the expression of one particular gene, so there are 772 individual genes are being monitored in this assay."},{"metadata":{},"cell_type":"markdown","source":"### Gene Expression - Meta Statistic"},{"metadata":{"trusted":true},"cell_type":"code","source":"train[g_list].describe().index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12,10))\n\nplt.subplot(2,2,1)\nsns.distplot(train[g_list].describe().values[1],color = \"red\")\nplt.title(\"Mean\",fontsize=15)\n\nplt.subplot(2,2,2)\nsns.distplot(train[g_list].describe().values[2],color = \"blue\")\nplt.title(\"Standar Deviation\",fontsize=15)\n\n\nplt.subplot(2,2,3)\nsns.distplot(train[g_list].describe().values[3],color = \"green\")\nplt.title(\"Mininmum Value\",fontsize=15)\n\nplt.subplot(2,2,4)\nsns.distplot(train[g_list].describe().values[7],color = \"yellow\")\nplt.title(\"Maximum Value\",fontsize=15)\n\n\nplt.suptitle(\"Gene Expression - Meta Statistics\",fontsize=20)\n\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* The means are pretty nicely distributed around zero; with standard deviations chiefly between 0.5 and 1.5.\n\n* The min and max are a nice mirror image of each other. There are notable increases around the range of positive/negative 9 - 10."},{"metadata":{"trusted":true},"cell_type":"code","source":"# call the helper function to check g- feature distribution\nplot_g_c(['g-1','g-6','g-11','g-16','g-21','g-26','g-31','g-36','g-41','g-46'],\"Gene Expression\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"* Gene expression feature distributions are more diverse than cell viability feature distributions\n* There are both left/right tailed and long/short tailed distributions exist"},{"metadata":{},"cell_type":"markdown","source":"### Correlation Matrix between g- variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"# heat map\nplt.figure(figsize = (12,8))\ncorrMatrix = train[g_list].corr()\nsns.heatmap(corrMatrix)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Correlation between g- variables not as strong as it is between c- variables"},{"metadata":{},"cell_type":"markdown","source":"### Treatment Features relation with Cell Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12,12))\n\nplt.subplot(2,3,1)\nc_1 = train[[\"c-1\",\"cp_time\"]]\nc_1_24 = c_1[c_1[\"cp_time\"]==24]\nsns.distplot(c_1_24[\"c-1\"],color = \"red\")\nplt.title(\"C-1 Vs CP TIME = 24\")\n\nplt.subplot(2,3,2)\nc_1_48 = c_1[c_1[\"cp_time\"]==48]\nsns.distplot(c_1_48[\"c-1\"],color = \"blue\")\nplt.title(\"C-1 Vs CP TIME = 48\")\n\n\nplt.subplot(2,3,3)\nc_1_72 = c_1[c_1[\"cp_time\"]==72]\nsns.distplot(c_1_72[\"c-1\"],color = \"green\")\nplt.title(\"C-1 Vs CP TIME = 72\")\n\nplt.subplot(2,3,4)\nc_2 = train[[\"c-2\",\"cp_time\"]]\nc_2_24 = c_2[c_2[\"cp_time\"]==24]\nsns.distplot(c_2_24[\"c-2\"],color = \"red\")\nplt.title(\"C-2 Vs CP TIME = 24\")\n\nplt.subplot(2,3,5)\nc_2_48 = c_2[c_2[\"cp_time\"]==48]\nsns.distplot(c_2_48[\"c-2\"],color = \"blue\")\nplt.title(\"C-2 Vs CP TIME = 48\")\n\n\nplt.subplot(2,3,6)\nc_2_72 = c_2[c_2[\"cp_time\"]==72]\nsns.distplot(c_2_72[\"c-2\"],color = \"green\")\nplt.title(\"C-2 Vs CP TIME = 72\")\n\n\nplt.suptitle(\"Cell Viability Vs CP Time\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For both the sample features we took above, c-1 and c-2, there is no difference in the distribution for different kind of time treatments."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12,12))\n\nplt.subplot(2,2,1)\nc_1 = train[[\"c-1\",\"cp_dose\"]]\nc_1_D1 = c_1[c_1[\"cp_dose\"]==\"D1\"]\nsns.distplot(c_1_D1[\"c-1\"],color = \"red\")\nplt.title(\"C-1 Vs CP DOSE = D1\")\n\nplt.subplot(2,2,2)\nc_1_D2 = c_1[c_1[\"cp_dose\"]==\"D2\"]\nsns.distplot(c_1_D2[\"c-1\"],color = \"green\")\nplt.title(\"C-1 Vs CP DOSE = D2\")\n\nplt.subplot(2,2,3)\nc_2 = train[[\"c-2\",\"cp_dose\"]]\nc_2_D2 = c_2[c_2[\"cp_dose\"]==\"D1\"]\nsns.distplot(c_2_D2[\"c-2\"],color = \"red\")\nplt.title(\"C-2 Vs CP DOSE = D1\")\n\nplt.subplot(2,2,4)\nc_2_D2 = c_2[c_2[\"cp_dose\"]==\"D2\"]\nsns.distplot(c_2_D2[\"c-2\"],color = \"green\")\nplt.title(\"C-2 Vs CP DOSE = D2\")\n\nplt.suptitle(\"Cell Viability Vs CP DOSE\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For both the sample features we took above, c-1 and c-2, there is no difference in the distribution for different kind of dose treatments."},{"metadata":{},"cell_type":"markdown","source":"### Treatment Features relation with Gene Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12,12))\n\nplt.subplot(2,3,1)\ng_1 = train[[\"g-1\",\"cp_time\"]]\ng_1_24 = g_1[g_1[\"cp_time\"]==24]\nsns.distplot(g_1_24[\"g-1\"],color = \"red\")\nplt.title(\"G-1 Vs CP TIME = 24\")\n\nplt.subplot(2,3,2)\ng_1_48 = g_1[g_1[\"cp_time\"]==48]\nsns.distplot(g_1_48[\"g-1\"],color = \"blue\")\nplt.title(\"G-1 Vs CP TIME = 48\")\n\n\nplt.subplot(2,3,3)\ng_1_72 = g_1[g_1[\"cp_time\"]==72]\nsns.distplot(g_1_72[\"g-1\"],color = \"green\")\nplt.title(\"G-1 Vs CP TIME = 72\")\n\nplt.subplot(2,3,4)\ng_2 = train[[\"g-2\",\"cp_time\"]]\ng_2_24 = g_2[g_2[\"cp_time\"]==24]\nsns.distplot(g_2_24[\"g-2\"],color = \"red\")\nplt.title(\"G-2 Vs CP TIME = 24\")\n\nplt.subplot(2,3,5)\ng_2_48 = g_2[g_2[\"cp_time\"]==48]\nsns.distplot(g_2_48[\"g-2\"],color = \"blue\")\nplt.title(\"G-2 Vs CP TIME = 48\")\n\n\nplt.subplot(2,3,6)\ng_2_72 = g_2[g_2[\"cp_time\"]==72]\nsns.distplot(g_2_72[\"g-2\"],color = \"green\")\nplt.title(\"G-2 Vs CP TIME = 72\")\n\n\nplt.suptitle(\"Gene Features Vs CP Time\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For both the sample features we took above, g-1 and g-2, there is almost no difference in the distribution for different kind of time treatments."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12,12))\n\nplt.subplot(2,2,1)\ng_1 = train[[\"g-1\",\"cp_dose\"]]\ng_1_D1 = g_1[g_1[\"cp_dose\"]==\"D1\"]\nsns.distplot(g_1_D1[\"g-1\"],color = \"red\")\nplt.title(\"G-1 Vs CP DOSE = D1\")\n\nplt.subplot(2,2,2)\ng_1_D2 = g_1[g_1[\"cp_dose\"]==\"D2\"]\nsns.distplot(g_1_D2[\"g-1\"],color = \"blue\")\nplt.title(\"G-1 Vs CP DOSE = D2\")\n\nplt.subplot(2,2,3)\ng_2 = train[[\"g-2\",\"cp_dose\"]]\ng_2_D1 = g_2[g_2[\"cp_dose\"]==\"D1\"]\nsns.distplot(g_2_D1[\"g-2\"],color = \"red\")\nplt.title(\"G-2 Vs CP DOSE = D1\")\n\nplt.subplot(2,2,4)\ng_2_D2 = g_2[g_2[\"cp_dose\"]==\"D2\"]\nsns.distplot(g_2_D2[\"g-2\"],color = \"blue\")\nplt.title(\"G-2 Vs CP DOSE = D2\")\n\n\n\nplt.suptitle(\"Cell Viability Vs CP DOSE\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For both the sample features we took above, g-1 and g-2, there is almost no difference in the distribution for different kind of dose treatments."},{"metadata":{},"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<a id=\"10\"></a>\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:brown; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Let's now check Target Dataset</center></h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"target.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<a id=\"10\"></a>\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:brown; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Target Dataset - Sparsity</center></h2>"},{"metadata":{},"cell_type":"markdown","source":"As we saw earlier, there are 207 target variables, it is most likely that the targets are going to be sparse, lets check!"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (35,350))\nfor idx,col in enumerate(target.columns[1:]):   \n    plt.subplot(42,5,idx+1)       \n    sns.countplot(target[col],palette=colors_nude)\n    plt.xlabel(\"Target Distribution - \" + col)\n    plt.ylabel(\"Count\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Clearly, all the target variables are mostly classified as 0s, % of MOAs(target variable = 1) seems to be extremely low, not even visible for most of the target variables.\n\n* This also means that the dataset is highly imbalanced, something we need to keep in mind while preparing the data for modelling."},{"metadata":{},"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<a id=\"10\"></a>\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:brown; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Check for Multi-Label Drugs</center></h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df= target[target.sum(axis=1)>1]\nnew_df ['sum'] = new_df.sum(axis=1)\nnew_df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 1915 drugs which are classified into more than one categories"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (15,10))\n    \nplt.subplot(2,2,1)\nsns.countplot(new_df['sum'],palette=colors_nude)\nplt.xlabel(\"No. of Targets\",fontsize=15)\nplt.ylabel(\"Count\",fontsize=15)\nplt.title(\"Drugs classified into more than one categories\",fontsize=20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Around 1500 drugs are classified into more than 2 targets\n* Around 300 drugs are classified into more than 3 targets\n* Around 100 drugs are classified into more than 4,5 & 7 targets"},{"metadata":{},"cell_type":"markdown","source":"**Last thing that we should check in the target dataset is that \"sig_id\"s present in the target dataset are matching with training dataset \"sig_id\"s**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# we are using set.intersection to find out similarity between the sig_id values present in the two datasets\nlen(set(train.sig_id.values).intersection(set(target.sig_id.values)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No. we got above is equal to the no. of records present in the dataframes, hence we can conclude that the sig_id values present in both the dataframes is exactly matching."},{"metadata":{},"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<a id=\"10\"></a>\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:brown; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Target Variables Interaction with Independent Features</center></h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# create a master dataset by concatenating train and target dataframes\nmaster_df = pd.concat([train,target],axis = 1)\nmaster_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"master_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<a id=\"10\"></a>\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:brown; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Gene Expression Vs Target Variables</center></h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"for tar_col in target.columns[1:11]:\n    plt.figure(figsize = (25,10))\n\n    for idx in range(1,11):\n        plt.subplot(2,5,idx)\n        col = \"g-\" + str(idx)\n        plt.scatter(x=master_df[col],y=master_df[tar_col])\n        plt.xlabel(col,fontsize=10)\n        plt.ylabel(tar_col,fontsize=10)\n        plt.suptitle(\"Correlation between g-1 to 10 &  {}\".format(tar_col),fontsize=15)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Random gene expression features are plotted against a random target feature because it is not possible to visualize 772x206 feature interactions. \n     \n* Gene expression features and targets have weaker relationships compared to cell viability features, because data points of positive target values are more spread along the x axis.\n \n* All gene expression features have one thing in common; positive target values are clustered around zero means just like cell viability features. \n     \n* High absolute values in gene expression features (>2 or <-2) indicate that the drug or perturbation had a significant effect on the current cell, whereas values close to zero mean means that the effect for that cell was non-measurable."},{"metadata":{},"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<a id=\"10\"></a>\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:brown; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Cell Viability Vs Target Variables</center></h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"for tar_col in target.columns[1:11]:\n    plt.figure(figsize = (25,100))\n\n    for idx in range(1,11):\n        plt.subplot(20,5,idx)\n        col = \"c-\" + str(idx)\n        plt.scatter(x=master_df[col],y=master_df[tar_col])\n        plt.xlabel(col,fontsize=10)\n        plt.ylabel(tar_col,fontsize=10)\n        #plt.suptitle(\"Correlation between c-1 to 100 &  {}\".format(tar_col),fontsize=15)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Cell viability features are plotted against only a random target feature since there are 206 targets. \n     \n* It can be seen that, there are positive relationships between cell viability features and target features in most of the cases. \n \n* However, some of them have no relationship or negative relationship with target features. This could be related to, most of the cells are being cancer cells while some of them are not. Another pattern that can be seen in cell viability features is, positive target values are clustered around zero means in most of the cases."},{"metadata":{},"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<a id=\"10\"></a>\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:brown; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>c_type, c_time & c_dose Vs Target Variables</center></h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"target.columns[25:26]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def bivariate(feat):\n    plt.figure(figsize = (25,50))\n\n    for idx,tar_col in enumerate(target.columns[25:50]):  \n        plt.subplot(10,5,idx+1)\n        sns.countplot(master_df[tar_col],hue = master_df[feat],palette=colors_nude)    \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bivariate(\"cp_type\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* We have already seen how cp_type values are distributed in the training dataset, majority of the records had value \"trt_cp\" and that's the reason why we see big buildings for \"trt_cp\" values\n \n* To summarize what we see above is, majority of the records are classified as \"0\" and most of the records have a value of \"trt_cp\" for cp_type feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"bivariate(\"cp_time\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To summarize what we see above is, majority of the records are classified as \"0\" and different values of cp_time have almost equal distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"bivariate(\"cp_dose\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To summarize what we see above is, majority of the records are classified as \"0\" and different values of cp_dose have almost equal distribution"},{"metadata":{},"cell_type":"markdown","source":"# Model Building"},{"metadata":{"trusted":true},"cell_type":"code","source":"objects = []\nfor col in train.columns:\n    if train[col].dtype == \"object\" and col != \"sig_id\":\n        if train[col].nunique() > 1:\n            train[col] = train[col].astype('category')\n            objects.append(col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in objects:\n    train[col] = train[col].astype(\"category\")\n    train[col] = train[col].cat.codes + 1\n\ntrain[objects].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in objects:\n    test[col] = test[col].astype(\"category\")\n    test[col] = test[col].cat.codes + 1\n\ntest[objects].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train.drop(\"sig_id\",1)\ny = target.drop(\"sig_id\",1)\nX.shape, y.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# PCA"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Improting the PCA module\n#from sklearn.decomposition import PCA\n#pca = PCA(svd_solver='randomized', random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#let's apply PCA\n#pca.fit(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Making the screeplot - plotting the cumulative variance against the number of components\n#%matplotlib inline\n#fig = plt.figure(figsize = (12,8))\n#plt.plot(np.cumsum(pca.explained_variance_ratio_))\n#plt.xlabel('number of components')\n#plt.ylabel('cumulative explained variance')\n#plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using incremental PCA for efficiency - saves a lot of time on larger datasets\n#from sklearn.decomposition import IncrementalPCA\n#pca_final = IncrementalPCA(n_components=350)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_pca = pd.DataFrame(pca_final.fit_transform(X))\n#df_pca.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.datasets import make_multilabel_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom sklearn.metrics import accuracy_score\n\n# split dataset into training and test set\n#X_train, X_test, y_train, y_test = train_test_split(df_pca, y, test_size=0.2, random_state=123)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n\n# create XGBoost instance with default hyper-parameters\nargs = {'max_depth': 7, 'learning_rate': .05,'n_estimators': 170, 'tree_method': \"gpu_hist\", 'gamma':4}\n\nxgb_estimator = xgb.XGBClassifier(**args)\n\n# create MultiOutputClassifier instance with XGBoost model inside\nmultilabel_model = MultiOutputClassifier(xgb_estimator)\n\n# fit the model\nmultilabel_model.fit(X_train, y_train)\n\n# evaluate on test data\nprint('Accuracy on test data: {:.1f}%'.format(accuracy_score(y_test, multilabel_model.predict(X_test))*100))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.drop('sig_id',1,inplace=True)\n#test_pca = pd.DataFrame(pca_final.fit_transform(test))\n#test_pca.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds = np.zeros((test.shape[0], y.shape[1]))\n#val_preds = multilabel_model.predict_proba(test_pca) # list of preds per class\nval_preds = multilabel_model.predict_proba(test) # list of preds per class\nval_preds = np.array(val_preds)[:,:,1].T # take the positive class","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create the submission file\nsub.iloc[:,1:] = val_preds\nsub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}