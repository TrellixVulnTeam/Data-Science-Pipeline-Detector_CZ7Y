{"cells":[{"metadata":{"id":"pQb02eekIz1x","executionInfo":{"status":"ok","timestamp":1604412114844,"user_tz":-180,"elapsed":1216,"user":{"displayName":"Damian Wayne","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuMipvHtwzPveRxKHsvbVsQw_f7BH2DSYqBBTL=s64","userId":"00172365457098275489"}},"trusted":true},"cell_type":"code","source":"import sys\nsys.path.append('../input/iterative-stratification')\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold","execution_count":null,"outputs":[]},{"metadata":{"id":"5eA16Q5oqKtn","executionInfo":{"status":"ok","timestamp":1604412117499,"user_tz":-180,"elapsed":814,"user":{"displayName":"Damian Wayne","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuMipvHtwzPveRxKHsvbVsQw_f7BH2DSYqBBTL=s64","userId":"00172365457098275489"}},"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nimport tensorflow.keras.layers as L\nimport tensorflow.keras.models as M\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\nimport tensorflow_addons as tfa\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import log_loss\nfrom tqdm.notebook import tqdm","execution_count":null,"outputs":[]},{"metadata":{"id":"x2ep4XTnqNmJ","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/prep-lishmoa/data/train_features.csv')\ntrain_targets = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\ntest = pd.read_csv('../input/prep-lishmoa/data/test_features.csv')\n\nss = pd.read_csv('../input/lish-moa/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_targets.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(10)","execution_count":null,"outputs":[]},{"metadata":{"id":"_gjeX5WJuBgW","trusted":true},"cell_type":"code","source":"del train_targets['sig_id']\ndel train['sig_id']\ndel test['sig_id']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model(num_columns):\n    model = tf.keras.Sequential([\n    tf.keras.layers.Input(num_columns),\n    tf.keras.layers.BatchNormalization(),\n    tfa.layers.WeightNormalization(tf.keras.layers.Dense(2048, activation=\"relu\")),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.5),\n    tfa.layers.WeightNormalization(tf.keras.layers.Dense(2048, activation=\"relu\")),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.5),\n    tfa.layers.WeightNormalization(tf.keras.layers.Dense(206, activation=\"sigmoid\"))\n    ])\n    model.compile(optimizer=tfa.optimizers.Lookahead(tf.optimizers.Adam(), sync_period=10),\n                  loss='binary_crossentropy'\n                  )\n    return model","execution_count":null,"outputs":[]},{"metadata":{"id":"ZzzbcNMlbX8b","trusted":true},"cell_type":"code","source":"def build_model(num_columns):\n    model = tf.keras.Sequential([\n    tf.keras.layers.Input(num_columns),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.2),\n    tfa.layers.WeightNormalization(tf.keras.layers.Dense(1400, activation=\"relu\")),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.4),\n    tfa.layers.WeightNormalization(tf.keras.layers.Dense(840, activation=\"sigmoid\")),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.3),\n    tfa.layers.WeightNormalization(tf.keras.layers.Dense(588, activation=\"relu\")),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.3), \n    tfa.layers.WeightNormalization(tf.keras.layers.Dense(206, activation=\"sigmoid\"))\n    ])\n    model.compile(optimizer=tfa.optimizers.Lookahead(tf.optimizers.Adam(), sync_period=5),\n                  loss='binary_crossentropy', metrics=[\"accuracy\"]\n                  )\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Permutation importance ~20 minutes\nfrom typing import Tuple, List, Callable, Any\n\nfrom sklearn.utils import check_random_state  # type: ignore\n\nseed = tf.random.set_seed(42)\n### from eli5\ndef iter_shuffled(X, columns_to_shuffle=None, pre_shuffle=False,\n                  random_state=None):\n    rng = check_random_state(random_state)\n\n    if columns_to_shuffle is None:\n        columns_to_shuffle = range(X.shape[1])\n\n    if pre_shuffle:\n        X_shuffled = X.copy()\n        rng.shuffle(X_shuffled)\n\n    X_res = X.copy()\n    for columns in tqdm(columns_to_shuffle):\n        if pre_shuffle:\n            X_res[:, columns] = X_shuffled[:, columns]\n        else:\n            rng.shuffle(X_res[:, columns])\n        yield X_res\n        X_res[:, columns] = X[:, columns]\n\n\n\ndef get_score_importances(\n        score_func,  # type: Callable[[Any, Any], float]\n        X,\n        y,\n        n_iter=5,  # type: int\n        columns_to_shuffle=None,\n        random_state=None\n    ):\n    rng = check_random_state(random_state)\n    base_score = score_func(X, y)\n    scores_decreases = []\n    for i in range(n_iter):\n        scores_shuffled = _get_scores_shufled(\n            score_func, X, y, columns_to_shuffle=columns_to_shuffle,\n            random_state=rng, base_score=base_score\n        )\n        scores_decreases.append(scores_shuffled)\n\n    return base_score, scores_decreases\n\n\n\ndef _get_scores_shufled(score_func, X, y, base_score, columns_to_shuffle=None,\n                        random_state=None):\n    Xs = iter_shuffled(X, columns_to_shuffle, random_state=random_state)\n    res = []\n    for X_shuffled in Xs:\n        res.append(-score_func(X_shuffled, y) + base_score)\n    return res\n\ndef metric(y_true, y_pred):\n    metrics = []\n    for i in range(y_pred.shape[1]):\n        if y_true[:, i].sum() > 1:\n            metrics.append(log_loss(y_true[:, i], y_pred[:, i]))\n    return np.mean(metrics)   \n\nperm_imp = np.zeros(train.shape[1])\nfor n, (tr, te) in enumerate(KFold(n_splits=2, random_state=seed, shuffle=True).split(train_targets)):\n    print(f'Fold {n}')\n\n    model = create_model(len(list(train.columns)))\n    reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, epsilon=1e-4, mode='min')\n\n    model.fit(train.values[tr],\n              train_targets.values[tr],\n              validation_data=(train.values[te], train_targets.values[te]),\n              epochs=40, batch_size=128,\n              callbacks=[reduce_lr_loss], verbose=2\n             )\n        \n    def _score(X, y):\n        pred = model.predict(X)\n        return metric(y, pred)\n\n    base_score, local_imp = get_score_importances(_score, train.values[te], train_targets.values[te], n_iter=1, random_state=0)\n    perm_imp += np.mean(local_imp, axis=0)\n    print('')\n    break\n    \ntop_feats = np.argwhere(perm_imp < 0).flatten()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_feats","execution_count":null,"outputs":[]},{"metadata":{"id":"viJxUUfTuBp2","trusted":true},"cell_type":"code","source":"def metric(y_true, y_pred):\n    metrics = []\n    for _target in train_targets.columns:\n        metrics.append(log_loss(y_true.loc[:, _target], y_pred.loc[:, _target].astype(float), labels=[0,1]))\n    return np.mean(metrics)\n\n# def metric(y_true, y_pred): \n#     return tf.keras.losses.binary_crossentropy(y_true, y_pred).numpy().mean()","execution_count":null,"outputs":[]},{"metadata":{"id":"m8pgbydquBsQ","executionInfo":{"status":"ok","timestamp":1604349956537,"user_tz":-180,"elapsed":3969094,"user":{"displayName":"Damian Wayne","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuMipvHtwzPveRxKHsvbVsQw_f7BH2DSYqBBTL=s64","userId":"00172365457098275489"}},"outputId":"c0989893-80ac-4ee7-b6b6-f618ea58c231","trusted":true},"cell_type":"code","source":"N_STARTS = 5\ntf.random.set_seed(42)\n\nres = train_targets.copy()\nss.loc[:, train_targets.columns] = 0\nres.loc[:, train_targets.columns] = 0\n\nfor seed in range(N_STARTS):\n    for n, (tr, te) in enumerate(MultilabelStratifiedKFold(n_splits=7, random_state=seed, shuffle=True).split(train_targets, train_targets)):\n        print(f'Fold {n}')\n    \n        model = build_model(len(top_feats))\n        # checkpoint_path = f'repeat:{seed}_Fold:{n}.hdf5'\n        reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.15, patience=3, verbose=1, epsilon=1e-4, mode='min')\n        early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, mode= 'min')\n        # cb_checkpt = ModelCheckpoint(checkpoint_path, monitor = 'val_loss', verbose = 0, save_best_only = True,\n        #                              save_weights_only = True, mode = 'min')\n\n        model.fit(train.values[tr][:, top_feats],\n                  train_targets.values[tr],\n                  validation_data=(train.values[te][:, top_feats], train_targets.values[te]),\n                  epochs=40, batch_size=128,\n                  callbacks=[reduce_lr_loss, early_stop], verbose=2\n                 )\n        \n        # model.load_weights(checkpoint_path)\n        test_predict = model.predict(test.values[:, top_feats])\n        val_predict = model.predict(train.values[te][:, top_feats])\n        \n        ss.loc[:, train_targets.columns] += test_predict\n        res.loc[te, train_targets.columns] += val_predict\n        print('')\n    \nss.loc[:, train_targets.columns] /= ((n+1) * N_STARTS)\nres.loc[:, train_targets.columns] /= N_STARTS","execution_count":null,"outputs":[]},{"metadata":{"id":"wHsndkdw9Xar","executionInfo":{"status":"ok","timestamp":1604350097573,"user_tz":-180,"elapsed":1462,"user":{"displayName":"Damian Wayne","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiuMipvHtwzPveRxKHsvbVsQw_f7BH2DSYqBBTL=s64","userId":"00172365457098275489"}},"outputId":"8f60b8d0-e7af-4e1e-8a33-e6405cb3c320","trusted":true},"cell_type":"code","source":"print(f'OOF Metric: {metric(train_targets, res)}')","execution_count":null,"outputs":[]},{"metadata":{"id":"CIvzG3kUuBu3","trusted":true},"cell_type":"code","source":"ss.loc[test['cp_type']==1, train_targets.columns] = 0","execution_count":null,"outputs":[]},{"metadata":{"id":"64uiAuaN9Z2E","trusted":true},"cell_type":"code","source":"ss.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}