{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"### Imports\n\nimport time\n\n%matplotlib inline\n\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nimport numpy as np \nimport pandas as pd \n\nimport tensorflow as tf\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import log_loss\n\nimport category_encoders as ce","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Settings\n\nSEED = 21\nTEST_SIZE = 0.33\nEPOCHS = 10\nBATCH_SIZE = 128\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Create dataframes\n\nTEST_FEATURES_PATH = \"/kaggle/input/lish-moa/test_features.csv\"\nTRAIN_FEATURES_PATH = \"/kaggle/input/lish-moa/train_features.csv\"\nTRAIN_TARGETS_PATH = \"/kaggle/input/lish-moa/train_targets_scored.csv\"\nTRAIN_TARGETS_NONSCORED_PATH = \"/kaggle/input/lish-moa/train_targets_nonscored.csv\"\nSAMPLE_SUB_PATH = \"/kaggle/input/lish-moa/sample_submission.csv\"\n\ntest_features_df = pd.read_csv(TEST_FEATURES_PATH).sort_values(by='sig_id')\ntrain_features_df = pd.read_csv(TRAIN_FEATURES_PATH).sort_values(by='sig_id')\ntrain_targets_df = pd.read_csv(TRAIN_TARGETS_PATH).sort_values(by='sig_id')\ntrain_targets_nonscored_df = pd.read_csv(TRAIN_TARGETS_NONSCORED_PATH)\nsample_sub_df = pd.read_csv(SAMPLE_SUB_PATH).sort_values(by='sig_id')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Encode training categorical features\nenc = ce.BinaryEncoder(cols=['cp_type', 'cp_dose','cp_time']).fit(train_features_df)\ntrain_features_enc_df = enc.transform(train_features_df).drop(columns=['sig_id'])\n\n\n# Encode testing categorical features\nenc = ce.BinaryEncoder(cols=['cp_type', 'cp_dose','cp_time']).fit(test_features_df)\ntest_features_enc_df = enc.transform(test_features_df).drop(columns=['sig_id'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Verify\n\ntrain_features_enc_df.head()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### check how many 1's are in each class\n\nvalue_counts_arr = np.sort([train_targets_df[col].value_counts()[1] for col in train_targets_df.columns])\n\nprint(value_counts_arr)\n\nprint(pd.Series(value_counts_arr).describe())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Plot histogram of 1s counts in classes \n\nmatplotlib.rcParams['figure.figsize'] = [10, 5]\n\nplt.hist(value_counts_arr, 50, facecolor='g', alpha=0.75)\nplt.xlabel('Number of 1\\'s')\nplt.ylabel('Number of classes')\nplt.title('Value Counts of 1\\'s in classes')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Split training data into train/valid\n\nx_train,x_valid,y_train,y_valid = train_test_split(train_features_enc_df,train_targets_df.drop(columns=['sig_id']),test_size=TEST_SIZE, random_state=SEED)\n\n\ntemp = 0\n\nfor col in y_train.columns:\n    if len(np.unique(y_train[col])) == 1:\n        print('Class {} only contains zeros'.format(col))\n        temp = 1\n\nif temp == 0:\n    print('No classes have all zeros!')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Verify\nx_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_tf_model():\n    model = tf.keras.Sequential([\n        L.Flatten(input_shape=(1,879)),\n        L.Dense(2000, activation='relu'),\n        L.BatchNormalization(),\n        L.Dropout(.4),\n        L.Dense(1000, activation='relu'),\n        L.BatchNormalization(),\n        L.Dropout(.4),\n        L.Dense(1000, activation='relu'),\n        L.BatchNormalization(),\n        L.Dropout(.4),\n        L.Dense(206, activation='sigmoid')\n    ])\n\n    model.compile(\n        optimizer='adam',\n        loss = 'binary_crossentropy',\n        metrics=['accuracy']\n    )\n    \n    model.summary()\n    \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Make Predictions\n\ndef get_preds(model,final=False):\n\n    if 'tensorflow' in str(type(model)):\n        if final==True:\n            preds = np.array(model.predict(test_features_enc_df).astype(\"float64\"))\n        else:\n            preds = np.array(model.predict(x_valid).astype(\"float64\"))\n    else:\n        if final==True:\n            preds = np.array(model.predict_proba(test_features_enc_df))\n        else:\n            preds = np.array(model.predict_proba(x_valid))\n        \n        preds = preds[:,:,1].T\n    \n    return preds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Calculate validation score\n\ndef calc_loss(vals,preds):\n\n    score = log_loss(np.ravel(vals),np.ravel(preds)) \n\n    print('Validation log loss score: {}'.format(score))\ndef run_model(model):\n\n    ### fit the model\n    fit_model(model)\n\n    print('Getting validation predictions...')\n    \n    ### get the predictions\n    temp_val_preds = get_preds(model,final=False)\n    \n    ### calculate log loss\n    calc_loss(y_valid,temp_val_preds)\n\n    val_preds.append(temp_val_preds)\n    \n    print('Calculating final predictions...')\n\n    ### final preds\n    final_preds.append(get_preds(model,final=True))\n    \n    print('Done')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_preds = []\nfinal_preds = []\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_model(model_2) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Ensemble validation predictions\n\nprint('Ensembling validation predictions')\nval_preds_avg = np.mean(np.array(val_preds),axis=0)\n\nprint('Ensembling final predictions')\nfinal_predictions = np.mean(np.array(final_preds),axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Calculate ensemble validaiton loss\n\nprint('Calculating ensemble validation loss...')\n\ncalc_loss(y_valid,val_preds_avg)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Insight into validation predictions\n\nprint(np.min(val_preds_avg))\nprint(np.max(val_preds_avg))\nprint(pd.DataFrame(val_preds_avg).describe())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Output final predictions\n\nsample_sub_df.iloc[:,1:] = final_predictions\nsample_sub_df.to_csv('submission.csv',index=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Insight into final predictions\n\nsample_sub_df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}