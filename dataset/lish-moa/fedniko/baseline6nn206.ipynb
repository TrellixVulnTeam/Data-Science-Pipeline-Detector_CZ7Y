{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nimport tensorflow.keras.layers as L\nimport tensorflow.keras.models as M\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\nimport tensorflow_addons as tfa\nfrom sklearn.model_selection import KFold, train_test_split\nfrom sklearn.metrics import log_loss\nfrom tqdm.notebook import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"intercept = 0.9668835542286371\ncoef = [-9.64522806e-01,  1.17172755e+00,  1.79847765e-01,  7.15775158e-01, \n        9.43909901e-01,  7.71809223e-01,  1.66641048e-01,  3.36556037e+00,\n       -3.04227717e+00, -1.27799877e+00,  3.24426534e+00,  8.39780267e-02,\n       -2.01609571e+00, -2.04835338e-01, -9.15522223e-01, -2.85557145e+00,\n        1.93031923e-01, -6.10949126e-01,  2.36655937e+00, -6.88545522e-01,\n       -4.13897388e-01,  2.36123594e+00, -5.32875178e+00, -2.57607263e-01,\n       -1.59041078e+00,  5.66513610e-01, -4.30048221e+00,  5.83728152e-01,\n       -7.55718528e-01, -4.85939641e+00, -4.77435586e+00,  1.20158973e+00,\n        1.52684705e+00,  1.42038088e+00, -4.70860607e-01, -1.02184815e+00,\n       -1.86602382e-01,  3.50855131e-01, -2.86119402e+00,  1.81263079e-01,\n       -3.98183995e+00,  3.85179998e+00,  5.95682016e-01,  9.76153845e-01,\n        4.56293927e-01, -1.33132314e+00,  3.63681261e-01,  7.94664912e-01,\n       -3.91041090e+00, -1.20555465e-01, -3.91041090e+00, -2.91140990e+00,\n        1.36755837e+00,  2.53799497e+00, -4.66063290e+00, -6.30443626e-01,\n        1.66641048e-01, -7.08818234e+00, -1.03160754e+00, -2.14803976e-01,\n        4.86850322e+00,  1.36755837e+00, -2.96600720e+00, -1.35837391e+00,\n       -5.08890666e+00,  1.20158973e+00, -3.91041090e+00, -6.28729430e+00,\n       -2.97537878e-01, -2.18535836e+00, -2.59118068e+00,  3.86950222e+00,\n       -6.33065361e-01, -1.89416541e+00, -4.48762478e-01,  4.05822320e-01,\n        1.36755837e+00,  1.14356994e+00, -1.51346861e+00, -1.77735286e+00,\n        6.84120905e-01,  1.21749418e+00, -2.01609571e+00, -1.33132314e+00,\n        4.29707940e-01, -2.50444579e+00, -4.13897388e-01,  1.46527571e+00,\n        4.75974538e-01,  1.20782761e+00, -1.79853836e+00,  7.02807914e+00,\n       -5.51602225e+00,  8.39780267e-02,  4.33789914e+00, -1.96700816e+00,\n       -4.87378955e+00, -3.85577422e-01,  1.38106353e+00, -4.96400920e+00,\n        3.89528260e+00, -2.91896630e+00,  1.36755837e+00,  6.84120905e-01,\n       -4.47665162e+00, -1.27799877e+00,  1.36755837e+00,  3.36556037e+00,\n       -2.04835338e-01, -5.99912328e-01, -2.04314343e-01, -4.45619265e+00,\n       -1.26221209e+00, -1.55571983e+00, -1.93596293e+00, -6.75983678e-02,\n       -2.55472083e+00, -6.10949126e-01,  2.36655937e+00, -1.85313989e+00,\n       -9.62103086e-01,  4.36456137e+00,  4.86850322e+00, -2.92095622e+00,\n       -1.42047927e+00,  4.36456137e+00,  2.36655937e+00,  1.79847765e-01,\n        2.61138626e+00, -1.22241720e+00,  2.15956162e+00,  1.36755837e+00,\n       -1.33363593e+00,  2.31341538e+00, -2.49972847e+00, -2.05475149e+00,\n        3.09957974e-02, -6.93110501e-02,  2.36655937e+00,  5.81666839e-01,\n        4.36456137e+00, -4.30048221e+00, -2.87261540e+00, -3.08550042e+00,\n       -1.08649626e+00, -7.55718528e-01,  1.08199981e+00, -1.42047927e+00,\n        8.06595523e-01,  4.86850322e+00,  4.09200801e-01, -1.96700620e+00,\n       -6.93110501e-02, -3.18329286e+00, -2.27241201e+00, -2.08025864e-03,\n        7.78295227e-01, -1.16768184e+00,  3.36556037e+00,  2.92194280e+00,\n        1.21032855e-01, -1.13677382e+00,  4.36456137e+00, -5.05666468e+00,\n        2.54763868e+00, -2.05653977e+00, -8.36236669e-01, -1.37407599e+00,\n       -1.52765698e+00, -5.55440630e-01, -4.77435586e+00,  3.92717805e-01,\n        2.54763868e+00, -2.45071712e-01,  8.06595523e-01,  4.29707940e-01,\n        1.61238526e+00,  5.11333011e+00,  4.11432911e+00,  1.20782761e+00,\n       -1.13677382e+00, -1.39447556e+00, -2.27534430e+00, -1.00108126e+00,\n        2.61138626e+00,  1.61238526e+00, -2.11696980e+00, -2.04970922e+00,\n       -3.05586400e+00, -2.06237301e+00, -5.30942364e+00, -3.06037800e+00,\n        4.56786669e+00,  7.24590988e-01, -1.19599384e+00, -1.69171272e+00,\n       -5.99912328e-01,  4.09200801e-01,  4.36456137e+00, -2.32589722e-01,\n        2.05197573e+00, -3.04659185e-01, -2.41477260e+00, -6.65305184e-01,\n        7.94664912e-01, -5.23026461e-01,  1.48758438e+00, -2.11696980e+00,\n       -5.99912328e-01, -1.06918017e+00, -2.92509555e+00, -2.24778342e+00,\n       -2.05998755e+00, -1.91946605e+00, -1.27341101e+00,  3.42621179e+00,\n       -9.45321798e-01, -5.05666468e+00, -1.16768184e+00, -3.85577422e-01,\n        2.36655937e+00,  1.54600888e+00, -1.96908321e+00,  1.48758438e+00,\n        1.36755837e+00, -2.93685912e+00, -8.63282842e-01, -1.77796891e+00,\n        1.36755837e+00,  5.10354690e+00,  3.07753467e+00,  3.36556037e+00,\n       -1.70669288e+00, -3.05586400e+00, -5.71550981e+00,  1.35386262e+00,\n        2.36655937e+00, -9.45456361e-01, -9.45321798e-01,  4.56293927e-01,\n       -1.96308200e-03, -2.52981213e+00, -6.33065361e-01,  4.36456137e+00,\n       -3.22981906e+00, -2.46960559e+00, -2.46960559e+00,  1.26188506e+00,\n        1.27495232e+00,  1.27947673e+00, -2.71404316e+00, -1.71703518e+00,\n       -1.71742525e+00]\n\ndef layers_num(x):\n    return int(np.round(np.dot(np.array(x),coef) + intercept))\n\ncol = pd.read_csv('../input/lish-moa/train_targets_scored.csv').columns[1:]\n\nstartword = ['-','erase','acetylcholine','receptor_agonist','atp', 'anta', 'abl', 'peptide', 'tgf', 'calci' 'cycl', 'hsp', 'im', 'proteas', 'secret', 'synth',]\n\nfor subword in startword:\n     col = [drtitle.replace(subword,'_'+subword+'_') for drtitle in col]\n\nall = [drtitle.split('_') for drtitle in col]\nall = sorted([word for item in all for word in item])\nall = [word for word in all if len(word)>0]\n\nallcounted = {word:all.count(word) for word in all}\nallcounted = {key:value for (key, value) in allcounted.items()}\nallcounted = list(allcounted.keys()) +  ['receptor_antagonist', 'tlr_antagonist', 'tlr_antagonist',\n                   'acetylcholine_receptor_antagonist','cannabinoid_receptor_antagonist',\n                   'opioid_receptor_antagonist','ppar_receptor_antagonist',\n                   'progesterone_receptor_antagonist','serotonin_receptor_antagonist']\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\n# eps, weight_tg, weight_x3, weight_x5 = 10**(-3), 0.0, 0.0, 0.0 # last couple =0.0eps, weight_tg, weight_x3, weight_x5 = 10**(-5), 0.0, 0.0, 0.0 # last couple =0.0\n# weight = 1.0 - weight_tg - weight_x3 - weight_x5\neps = 10**(-7)\n\n\n\n\ndef cube(x):\n    x /= 10.0\n    return 10.0 * x*x*x\ndef tgfunc(x):\n    return  np.tan(np.pi *x/ 4.0) \ndef application_transform(x):\n    \"\"\"  x = 2*x-1.0\n    x1 = weight_tg*tgfunc(x) + (weight_x3 + weight_x5*x**2)*x**3 + weight*x\n    x1 = x1/2 + 0.5\"\"\"\n    x1 = x\n    if x1 < eps:\n        x1 = eps\n    elif x1 >= 1 - eps:\n        x1 = 1 - eps\n    return x1\n\ndef transform(x):\n    x = x[x['cp_type']=='trt_cp']\n    x.pop('cp_type')\n    x['cp_dose'] = x['cp_dose'].replace({'D1':-1, 'D2':1})\n    x['cp_time'] = x['cp_time'] // 24\n    genes = [feature for feature in x.columns if feature.startswith('g-')]\n    cells = [feature for feature in x.columns if feature.startswith('c-')]\n    x['g-mean'] = x[genes].mean(axis=1)\n    x['g-std'] = x[genes].std(axis=1)\n    x['g-kur'] = x[genes].kurtosis(axis=1)\n    x['g-skew'] = x[genes].skew(axis=1)\n    x['c-mean'] = x[cells].mean(axis=1)\n    x['c-std'] = x[cells].std(axis=1)\n    x['c-kur'] = x[cells].kurtosis(axis=1)\n    x['c-skew'] = x[cells].skew(axis=1)\n    x['mean'] = x[genes+cells].mean(axis=1)\n    x['std'] = x[genes+cells].std(axis=1)\n    x['kur'] = x[genes+cells].kurtosis(axis=1)\n    x['skew'] = x[genes+cells].skew(axis=1)\n    \n    \n    x.join(pd.get_dummies(x['cp_time']))\n    x.pop('cp_time')\n    return x\n\ndef transform2(x):\n    x.pop('cp_type')\n    x['cp_dose'] = x['cp_dose'].replace({'D1':-1, 'D2':1})\n    x['cp_time'] = x['cp_time'] // 24\n    genes = [feature for feature in x.columns if feature.startswith('g-')]\n    cells = [feature for feature in x.columns if feature.startswith('c-')]\n    x['g-mean'] = x[genes].mean(axis=1)\n    x['g-std'] = x[genes].std(axis=1)\n    x['g-kur'] = x[genes].kurtosis(axis=1)\n    x['g-skew'] = x[genes].skew(axis=1)\n    x['c-mean'] = x[cells].mean(axis=1)\n    x['c-std'] = x[cells].std(axis=1)\n    x['c-kur'] = x[cells].kurtosis(axis=1)\n    x['c-skew'] = x[cells].skew(axis=1)\n    x['mean'] = x[genes+cells].mean(axis=1)\n    x['std'] = x[genes+cells].std(axis=1)\n    x['kur'] = x[genes+cells].kurtosis(axis=1)\n    x['skew'] = x[genes+cells].skew(axis=1)\n    \n    \n    x.join(pd.get_dummies(x['cp_time']))\n    x.pop('cp_time')\n    return x\n\nX_all = pd.read_csv('/kaggle/input/lish-moa/train_features.csv')\ny_all = pd.read_csv('/kaggle/input/lish-moa/train_targets_scored.csv')\nX = transform(X_all[X_all.columns[1:]]).astype(np.float16)\nY = y_all[X_all['cp_type']=='trt_cp']\nY = Y[Y.columns[1:]].astype(np.int8)\n\ndef metric(y_true, y_pred):\n    metrics = []\n    for _target in train_targets.columns:\n        metrics.append(log_loss(y_true.loc[:, _target], y_pred.loc[:, _target].astype(float), labels=[0,1]))\n    return np.mean(metrics)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def write_results(drug_no, val_loss0, time_to_train0):\n    return {\n        'drug_no': drug_no,\n        'loss0': val_loss0,\n        'train_time0' : time_to_train0\n    }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model1(num_columns):\n    model = tf.keras.Sequential([\n    tf.keras.layers.Input(num_columns),\n    tf.keras.layers.BatchNormalization(),\n    tfa.layers.WeightNormalization(tf.keras.layers.Dense(2000, activation=\"sigmoid\")),        \n    tf.keras.layers.Dense(1, activation=\"sigmoid\") #)\n    ])\n    model.compile(optimizer=tfa.optimizers.Lookahead(tf.optimizers.Adam(), sync_period=10),\n                  loss='binary_crossentropy', \n                  )\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model2(num_columns):\n    model = tf.keras.Sequential([\n    tf.keras.layers.Input(num_columns),\n    tf.keras.layers.BatchNormalization(),\n    tfa.layers.WeightNormalization(tf.keras.layers.Dense(1500, activation=\"sigmoid\")), \n    tf.keras.layers.BatchNormalization(),\n    tfa.layers.WeightNormalization(tf.keras.layers.Dense(100, activation=\"sigmoid\")),         \n    tf.keras.layers.Dense(1, activation=\"sigmoid\") \n    ])\n    model.compile(optimizer=tfa.optimizers.Lookahead(tf.optimizers.Adam(), sync_period=10),\n                  loss='binary_crossentropy', \n                  )\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model3(num_columns):\n    model = tf.keras.Sequential([\n    tf.keras.layers.Input(num_columns),\n    tf.keras.layers.BatchNormalization(),\n    tfa.layers.WeightNormalization(\n    tf.keras.layers.Dense(900, activation=\"relu\")),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.5),\n    tfa.layers.WeightNormalization(\n    tf.keras.layers.Dense(300, activation=\"relu\")),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.5),\n    tfa.layers.WeightNormalization(\n    tf.keras.layers.Dense(30, activation=\"relu\")),\n    tf.keras.layers.BatchNormalization(),\n    tfa.layers.WeightNormalization(tf.keras.layers.Dense(1, activation=\"sigmoid\") )\n    ])\n    model.compile(optimizer=tfa.optimizers.Lookahead(tf.optimizers.Adam(), sync_period=10),\n                  loss='binary_crossentropy', \n                  )\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model4(num_columns):\n    model = tf.keras.Sequential([\n    tf.keras.layers.Input(num_columns),\n    tf.keras.layers.Dense(1500, activation=\"relu\"),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.4),\n    tfa.layers.WeightNormalization(\n    tf.keras.layers.Dense(400, activation=\"relu\")),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.6),\n    tfa.layers.WeightNormalization(\n    tf.keras.layers.Dense(20, activation=\"relu\")),\n    tf.keras.layers.BatchNormalization(),\n    tfa.layers.WeightNormalization(tf.keras.layers.Dense(1, activation=\"sigmoid\") )\n    ])\n    model.compile(optimizer=tfa.optimizers.Lookahead(tf.optimizers.Adam(), sync_period=10),\n                  loss='binary_crossentropy', \n                  )\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"XXXX = pd.read_csv('/kaggle/input/lish-moa/test_features.csv')\nXXXX = transform2(XXXX[XXXX.columns[1:]]).astype(np.float16)\n\nsubmission = pd.read_csv('/kaggle/input/lish-moa/sample_submission.csv')\n\ntrain_results = []\nimport time\n\nfor drug_i in range(206):\n    \n    select_model = layers_num([1 if word in Y.columns[drug_i] else 0 for word in allcounted])\n    \n    Y_new = Y[Y.columns[drug_i]]\n    \n   \n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y_new, test_size=0.10, \n         stratify=np.array(Y_new), random_state=2021)\n    print(f'beginning training on drug no.{drug_i} ')\n    print([Y_test.sum(),Y_train.sum()])   \n    \n    \n    if select_model==0:\n            tbegin = time.clock()    \n            pseudoinverse_X = np.linalg.pinv(X_train.astype(np.float64))\n            test_predict = np.dot(X_test,np.dot(pseudoinverse_X,Y_train))\n\n            test_predict = np.array(list(map(application_transform, test_predict)))\n            loss0 = log_loss(np.array(Y_test),test_predict)\n            t0 = time.clock() - tbegin\n    \n    ##########11111111111111111111111    \n\n    if select_model==1:    \n            checkpoint_path = f'drug_no{drug_i+1}_rs.hdf5'\n            early_stopping = tf.keras.callbacks.EarlyStopping(patience=4, min_delta=10**(-3))\n            reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.25, patience=5, verbose=1, epsilon=1e-4, mode='min')\n            cb_checkpt = ModelCheckpoint(checkpoint_path, monitor = 'val_loss', verbose = 0, save_best_only = True,\n                                          save_weights_only = True, mode = 'min')\n\n            model = create_model1(X.shape[1])\n            tbegin = time.clock() \n            model.fit(X_train, Y_train,\n                      validation_data=(X_test, Y_test), \n                      epochs=50, batch_size=64, verbose=1,\n                      callbacks=[early_stopping,reduce_lr_loss, cb_checkpt])\n            model.load_weights(checkpoint_path)\n\n            test_predict = np.array(list(map(application_transform, model.predict(X_test))))    \n            loss0 = log_loss(np.array(Y_test),test_predict)\n            t0 = time.clock() - tbegin\n\n    #########################2222222222222222222\n \n    if select_model==2: \n            checkpoint_path = f'drug_no{drug_i+1}_rs.hdf5'\n            early_stopping = tf.keras.callbacks.EarlyStopping(patience=4, min_delta=10**(-3))\n            reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.25, patience=5, verbose=1, epsilon=1e-4, mode='min')\n            cb_checkpt = ModelCheckpoint(checkpoint_path, monitor = 'val_loss', verbose = 0, save_best_only = True,\n                                          save_weights_only = True, mode = 'min')\n\n            model = create_model2(X.shape[1])\n            tbegin = time.clock() \n            model.fit(X_train, Y_train,\n                      validation_data=(X_test, Y_test), \n                      epochs=50, batch_size=64, verbose=1,\n                      callbacks=[early_stopping,reduce_lr_loss, cb_checkpt])\n            model.load_weights(checkpoint_path)\n\n            test_predict = np.array(list(map(application_transform, model.predict(X_test))))    \n            loss0 = log_loss(np.array(Y_test),test_predict)\n            t0 = time.clock() - tbegin\n  \n\n    \n    #########################3333333333333333333333\n    if select_model==3: \n            checkpoint_path = f'drug_no{drug_i+1}_rs.hdf5'\n            early_stopping = tf.keras.callbacks.EarlyStopping(patience=4, min_delta=10**(-3))\n            reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.25, patience=5, verbose=1, epsilon=1e-4, mode='min')\n            cb_checkpt = ModelCheckpoint(checkpoint_path, monitor = 'val_loss', verbose = 0, save_best_only = True,\n                                          save_weights_only = True, mode = 'min')\n\n            model = create_model3(X.shape[1])\n            tbegin = time.clock() \n            model.fit(X_train, Y_train,\n                      validation_data=(X_test, Y_test), \n                      epochs=50, batch_size=64, verbose=1,\n                      callbacks=[early_stopping,reduce_lr_loss, cb_checkpt])\n            model.load_weights(checkpoint_path)\n\n            test_predict = np.array(list(map(application_transform, model.predict(X_test))))    \n            loss0 = log_loss(np.array(Y_test),test_predict)\n            t0 = time.clock() - tbegin\n    \n    \n    #########################44444444444444444\n    if select_model==4: \n    \n            checkpoint_path = f'drug_no{drug_i+1}_rs.hdf5'\n            early_stopping = tf.keras.callbacks.EarlyStopping(patience=4, min_delta=10**(-3))\n            reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.25, patience=5, verbose=1, epsilon=1e-4, mode='min')\n            cb_checkpt = ModelCheckpoint(checkpoint_path, monitor = 'val_loss', verbose = 0, save_best_only = True,\n                                          save_weights_only = True, mode = 'min')\n\n            model = create_model4(X.shape[1])\n            tbegin = time.clock() \n            model.fit(X_train, Y_train,\n                      validation_data=(X_test, Y_test), \n                      epochs=50, batch_size=64, verbose=1,\n                      callbacks=[early_stopping,reduce_lr_loss, cb_checkpt])\n            model.load_weights(checkpoint_path)\n\n            test_predict = np.array(list(map(application_transform, model.predict(X_test))))    \n            loss0 = log_loss(np.array(Y_test),test_predict)\n            t0 = time.clock() - tbegin    \n    \n   \n    train_results.append(write_results(drug_i, loss0, t0))\n    print('==================================================')\n    print('loss on validation:',train_results[-1])\n    print('==================================================')\n    pd.DataFrame(train_results).to_csv('resPreLast.csv',index=False)\n\n    \n    y_prediction =  np.array(list(map(application_transform, model.predict(XXXX))))    \n    submission[Y.columns[drug_i]] = y_prediction     \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(train_results).to_csv('resPreLast.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"YYYY = pd.read_csv('/kaggle/input/lish-moa/test_features.csv')\n\nlength = len(submission.columns)-1\nfor i in range(len(submission)): \n    if YYYY.loc[i,'cp_type']!='trt_cp':\n        submission.loc[i] = [submission.loc[i,'sig_id']]+[0] * length    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv', index=False) #, float_format=\"%.10f\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}