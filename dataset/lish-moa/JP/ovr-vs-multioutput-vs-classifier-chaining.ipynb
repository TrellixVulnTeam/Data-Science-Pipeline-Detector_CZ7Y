{"cells":[{"metadata":{},"cell_type":"markdown","source":"* [1. Import Data](#import-data)\n* [2. Data Preprocessing](#data-preprocessing)\n    * [2.1. Train-Test split](#train-test-split)\n    * [2.2. Preprocessing Pipeline: One-hot Encoding and Standardization](#preprocessing-pipeline%3A-one-hot-encoding-and-standardization)\n* [3. XGBoost + OneVsRestClassifier](#xgboost-%2B-onevsrestclassifier)\n* [4. XGBoost + MultiOutputClassifier](#xgboost-%2B-multioutputclassifier)\n* [5. XGBoost + ClassifierChain](#xgboost-%2B-classifierchain)\n* [6. Retrain on full dataset and Submit Predictions](#retrain-on-full-dataset-and-submit-predictions)","execution_count":null},{"metadata":{"jupyter":{"outputs_hidden":true},"trusted":true},"cell_type":"code","source":"import os, sys\n\nimport numpy as np\nfrom scipy.stats import chi2_contingency\nimport pandas as pd\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"toc-hr-collapsed":true,"toc-nb-collapsed":true},"cell_type":"markdown","source":"<a id=\"import-data\"></a>\n# 1. Import Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/lish-moa/train_features.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_targets = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\ndf_targets.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_targets.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test_sub = pd.read_csv('/kaggle/input/lish-moa/test_features.csv')","execution_count":null,"outputs":[]},{"metadata":{"toc-hr-collapsed":true},"cell_type":"markdown","source":"## 1.1. Find categorical columns and change their *Dtype* from `object` to `Categorical`","execution_count":null},{"metadata":{"jupyter":{"outputs_hidden":true},"trusted":true},"cell_type":"code","source":"def summarize_categoricals(df, show_levels=False, threshold=5):\n    \"\"\"\n        Display uniqueness in each column\n    \"\"\"\n    data = [[df[c].unique(), len(df[c].unique()), df[c].isnull().sum()] for c in df.columns]\n    df_temp = pd.DataFrame(data, index=df.columns,\n                           columns=['Levels', 'No. of Levels', 'No. of Missing Values'])\n    return df_temp[df_temp['No. of Levels'] <= threshold].iloc[:, 0 if show_levels else 1:]\n\n\ndef return_categoricals(df, threshold=5):\n    \"\"\"\n        Returns a list of columns that have less than or equal to\n        `threshold` number of unique categorical levels\n    \"\"\"\n    return list(filter(lambda c: c if len(df[c].unique()) <= threshold else None,\n                       df.columns))\n\n\ndef to_categorical(columns, df):\n    \"\"\"\n        Converts the columns passed in `columns` to categorical datatype\n    \"\"\"\n    for col in columns:\n        df[col] = df[col].astype('category')\n    return df","execution_count":null,"outputs":[]},{"metadata":{"jupyter":{"outputs_hidden":true},"trusted":true},"cell_type":"code","source":"summarize_categoricals(df, show_levels=True, threshold=500)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_columns = return_categoricals(df)","execution_count":null,"outputs":[]},{"metadata":{"jupyter":{"outputs_hidden":true},"trusted":true},"cell_type":"code","source":"df = to_categorical(categorical_columns, df)","execution_count":null,"outputs":[]},{"metadata":{"jupyter":{"outputs_hidden":true},"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test_sub = to_categorical(categorical_columns, df_test_sub)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"data-preprocessing\"></a>\n# 2. Data Preprocessing","execution_count":null},{"metadata":{"jupyter":{"outputs_hidden":true},"trusted":true},"cell_type":"code","source":"x = df.iloc[:, 1:]\ny = df_targets.iloc[:, 1:]\n\ncategorical_columns = list(x.select_dtypes(include='category').columns)\nnumeric_columns = list(x.select_dtypes(exclude='category').columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"train-test-split\"></a>\n## 2.1. Train-Test split","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ndata_splits = train_test_split(x, y, test_size=0.15, random_state=0,\n                               shuffle=True)\nx_train, x_test, y_train, y_test = data_splits\n\nlist(map(lambda x: x.shape, [x, y, x_train, x_test,\n                             y_train, y_test]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"preprocessing-pipeline%3A-one-hot-encoding-and-standardization\"></a>\n## 2.2. Preprocessing Pipeline: One-hot Encoding and Standardization","execution_count":null},{"metadata":{"jupyter":{"outputs_hidden":true},"trusted":true},"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline \n\n\nnumeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n\ncategorical_transformer = Pipeline(steps=[\n    ('onehot', OneHotEncoder(handle_unknown='ignore', dtype=np.int))])\n\n## Column Transformer\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, numeric_columns),\n        ('cat', categorical_transformer, categorical_columns)],\n    remainder='passthrough')\n\n\n## Applying Column Transformer\nx_train = preprocessor.fit_transform(x_train)\nx_test = preprocessor.transform(x_test)\n\nx_test_sub = preprocessor.transform(df_test_sub.iloc[:, 1:])\n\n\n## Label encoding\ny_train = y_train.to_numpy(dtype=np.int64)\ny_test = y_test.to_numpy(dtype=np.int64)\n\n\n## Save feature names after one-hot encoding for feature importances plots\nfeature_names = list(preprocessor.named_transformers_['cat'].named_steps['onehot'] \\\n                     .get_feature_names(input_features=categorical_columns))\nfeature_names = feature_names + numeric_columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"xgboost-%2B-onevsrestclassifier\"></a>\n# 3. XGBoost + OneVsRestClassifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import log_loss\nfrom xgboost import XGBClassifier\nfrom sklearn.multiclass import OneVsRestClassifier\n\nxgb = XGBClassifier(tree_method='gpu_hist',\n                    predictor='gpu_predictor',\n                    random_state=0, n_jobs=-1)\n\novr_clf = OneVsRestClassifier(estimator=xgb, n_jobs=-1)\n\novr_clf.fit(x_train, y_train)\n\novr_probs = ovr_clf.predict_proba(x_test)\n\nlog_loss(y_test, ovr_probs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"xgboost-%2B-multioutputclassifier\"></a>\n# 4. XGBoost + MultiOutputClassifier","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.multioutput import MultiOutputClassifier\n\nmo_clf = MultiOutputClassifier(estimator=xgb, n_jobs=-1)\n\nmo_clf.fit(x_train, y_train)\n\nmo_probs = mo_clf.predict_proba(x_test)\n\nn_classes = y_test.shape[1]\nn_test_samples = x_test.shape[0]\nmo_probs_pos = np.zeros((n_test_samples, n_classes))\n\nfor c in range(n_classes):\n    c_probs = mo_probs[c]\n    mo_probs_pos[:, c] = c_probs[:, 1]\n\nlog_loss(y_test, mo_probs_pos)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"xgboost-%2B-classifierchain\"></a>\n# 5. XGBoost + ClassifierChain","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.multioutput import ClassifierChain\nfrom joblib import Parallel, delayed\nimport timeit\n\nchains = [ClassifierChain(base_estimator=xgb, order='random')\n          for i in range(5)]\n\nchains = Parallel(n_jobs=-1)(delayed(chain.fit)(x_train, y_train) for chain in chains)\n\nchains_ensemble_proba = Parallel(n_jobs=-1)(delayed(chain.predict_proba)(x_test) for chain in chains)\n\nlog_loss(y_test, np.array(chains_ensemble_proba).mean(axis=0))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"retrain-on-full-dataset-and-submit-predictions\"></a>\n# 6. Retrain on full dataset and Submit Predictions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## Final Model\nx_train_full = preprocessor.fit_transform(x)\ny_train_full = y.to_numpy(dtype=np.int64)\n\nx_test_final = preprocessor.transform(df_test_sub.iloc[:, 1:])\n\nchains = Parallel(n_jobs=-1)(delayed(chain.fit)(x_train_full, y_train_full) for chain in chains)\n\nfinal_proba = Parallel(n_jobs=-1)(delayed(chain.predict_proba)(x_test_final) for chain in chains)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(np.array(final_proba).mean(axis=0),\n             index=df_test_sub['sig_id'],\n             columns=df_targets.columns[1:]).to_csv('submission.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thank You!!","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}