{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport tensorflow as tf \nimport tensorflow.keras.backend as K \nimport random\nimport os\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau \nfrom sklearn.model_selection import KFold","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-06T08:21:44.093575Z","iopub.execute_input":"2021-12-06T08:21:44.093844Z","iopub.status.idle":"2021-12-06T08:21:49.860104Z","shell.execute_reply.started":"2021-12-06T08:21:44.093815Z","shell.execute_reply":"2021-12-06T08:21:49.859282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.device('/gpu:0')","metadata":{"execution":{"iopub.status.busy":"2021-12-06T08:24:26.399019Z","iopub.execute_input":"2021-12-06T08:24:26.399631Z","iopub.status.idle":"2021-12-06T08:24:26.407711Z","shell.execute_reply.started":"2021-12-06T08:24:26.399591Z","shell.execute_reply":"2021-12-06T08:24:26.406895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed=42): \n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed) \n    tf.random.set_seed(seed)\n    \nseed_everything(42)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_features = pd.read_csv(\"../input/lish-moa/train_features.csv\")\ntrain_targets = pd.read_csv(\"../input/lish-moa/train_targets_scored.csv\")\ntest_features = pd.read_csv(\"../input/lish-moa/test_features.csv\")\nsample_submission = pd.read_csv(\"../input/lish-moa/sample_submission.csv\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_features=pd.get_dummies(train_features,columns=['cp_type','cp_dose'])\ntest_features=pd.get_dummies(test_features,columns=['cp_type','cp_dose'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del train_features['sig_id']\ndel test_features['sig_id']\ndel train_targets['sig_id']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model():\n  model = tf.keras.Sequential() \n  model.add(tf.keras.layers.Input(shape=(train_features.shape[1],))) \n  model.add(tf.keras.layers.BatchNormalization()) \n  model.add(tf.keras.layers.Dense(units=1024,activation='relu')) \n\n  model.add(tf.keras.layers.BatchNormalization()) \n  model.add(tf.keras.layers.Dropout(0.5)) \n    \n  model.add(tf.keras.layers.Dense(units=2048,activation='relu')) \n  model.add(tf.keras.layers.BatchNormalization()) \n  model.add(tf.keras.layers.Dropout(0.5)) \n  model.add(tf.keras.layers.Dense(206, activation=\"sigmoid\"))  \n\n  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[\"accuracy\",\"binary_crossentropy\"])\n  return model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = np.zeros((train_features.shape[0], 206)) \npe = np.zeros((test_features.shape[0], 206)) \ntrain_features = train_features.values\ntrain_targets = train_targets.values","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_split = 5 \nkfoldnumber= 0 \n\nfor train_index, validation_index in KFold(n_split).split(train_features):\n    kfoldnumber += 1 \n    print('Fold number: ',kfoldnumber) \n    \n    reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, min_delta=1e-4, mode='min')\n    \n    net = build_model()\n    net.fit(train_features[train_index], train_targets[train_index], batch_size=128, epochs=35, \n            validation_data=(train_features[validation_index], train_targets[validation_index]), verbose=0, callbacks=[reduce_lr_loss])\n    \n    print(\"train\", net.evaluate(train_features[train_index], train_targets[train_index], verbose=0, batch_size=128))#訓練數據與訓練標籤\n    print(\"val\", net.evaluate(train_features[validation_index], train_targets[validation_index], verbose=0, batch_size=128))#驗證數據與驗證標籤\n    \n    print(\"predict val...\")\n    pred[validation_index] = net.predict(train_features[validation_index], batch_size=128, verbose=0)\n    print(\"predict test...\")\n    pe += net.predict(test_features, batch_size=128, verbose=0) / n_split ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pe.shape\ncolumns = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\ndel columns['sig_id']\nsub = pd.DataFrame(data=pe, columns=columns.columns)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample = pd.read_csv('../input/lish-moa/sample_submission.csv')\nsub.insert(0, column = 'sig_id', value=sample['sig_id']) \nsub.to_csv('submission.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]}]}