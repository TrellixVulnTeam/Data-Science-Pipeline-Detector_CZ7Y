{"cells":[{"metadata":{},"cell_type":"markdown","source":"This notebook was written for beginners.\nI want to perform data analysis. Check the number of train data and test data.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Import Library","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\n\nimport matplotlib as mpl\nimport matplotlib.pylab as plt\nimport seaborn as sns\ncolor = sns.color_palette()\n\nfrom tqdm import tqdm_notebook\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import KFold, StratifiedKFold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing as pp \nfrom scipy.stats import pearsonr \nfrom sklearn.model_selection import train_test_split \nfrom sklearn.model_selection import StratifiedKFold \nfrom sklearn.metrics import log_loss \nfrom sklearn.metrics import precision_recall_curve, average_precision_score \nfrom sklearn.metrics import roc_curve, auc, roc_auc_score\nfrom sklearn.metrics import confusion_matrix, classification_report ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load File, Data","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"DATA_DIR  = os.path.join('/kaggle/input/lish-moa')\nTRAIN_FEATURE_FILE = os.path.join(DATA_DIR, 'train_features.csv')\nTEST_FEATURE_FILE = os.path.join(DATA_DIR, 'test_features.csv')\n\nTRAIN_TRAGET_FILE = os.path.join(DATA_DIR, 'train_targets_scored.csv')\nSUBMISSION_FILE = os.path.join(DATA_DIR, 'sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_feat = pd.read_csv(TRAIN_FEATURE_FILE)\ntest_feat = pd.read_csv(TEST_FEATURE_FILE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_feat.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_feat.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_target = pd.read_csv(TRAIN_TRAGET_FILE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_target.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_target.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Target Label (This competetion is Multi Label Classification)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_columns = train_target.drop(columns='sig_id', axis=0)\ny_columns.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EDA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_target_2 = pd.DataFrame(train_target['11-beta-hsd1_inhibitor'].value_counts())\ntrain_target_2.reset_index(inplace=True)\ntrain_target_2.columns = ['value','count']\n\nprint(train_target_2)\n\nplt.figure(figsize = (5, 5))\nplt.title('11-beta-hsd1_inhibitor')\ng = sns.barplot(x=\"value\", y=\"count\", data=train_target_2, palette=\"pastel\")\n\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Concat train_feat and train_target","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.merge(train_feat, train_target, on='sig_id')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### View feature per target\n#### ex) 5-alpha_reductase_inhibitor","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_filter = train[train['5-alpha_reductase_inhibitor'] == 1]\ntrain_filter = train_filter.iloc[:, :876]\ntrain_filter","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### pearson correlation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = train_filter.corr(method = 'pearson')\ncorr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_heatmap = sns.heatmap(corr, cbar = True, annot = True, annot_kws={'size' : 20}, fmt = '.2f', square = True, cmap = 'Blues')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Scaler","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_feat = train_feat.drop(columns=['sig_id'], axis=0)\ntest_feat = test_feat.drop(columns=['sig_id'], axis=0)\n\nfor feature in ['cp_type', 'cp_dose', 'cp_time']:\n    le = LabelEncoder()\n    le.fit(list(train_feat[feature].astype(str).values) + list(test_feat[feature].astype(str).values))\n    train_feat[feature] = le.transform(list(train_feat[feature].astype(str).values))\n    test_feat[feature] = le.transform(list(test_feat[feature].astype(str).values))\n\nprint(train_feat.head(10))\n\nfrom sklearn.preprocessing import StandardScaler\nstd_scaler = StandardScaler()\n\nfitted = std_scaler.fit(train_feat)\n\ntrain_feat_scale = std_scaler.transform(train_feat)\ntrain_feat_scale = pd.DataFrame(train_feat_scale, columns=train_feat.columns, index=list(train_feat.index.values))\n\nprint(train_feat_scale.head(10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## PCA (Principal Component Analysis)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\n\ntrain_index = range(0, len(train_feat_scale))\n\nn_components = 872\nwhiten = False\nrandom_state = 2020\n\npca = PCA(n_components=n_components, whiten=whiten, random_state=random_state)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_PCA = pca.fit_transform(train_feat_scale)\nX_train_PCA = pd.DataFrame(data=X_train_PCA, index=train_index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Variance Explained by all 872 principal components: \", sum(pca.explained_variance_ratio_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"importanceOfPrincipalComponents = pd.DataFrame(data=pca.explained_variance_ratio_)\nimportanceOfPrincipalComponentsT =importanceOfPrincipalComponents.T\n\nprint('Variance Captured By First 10 Pricipal Components: ',\n     importanceOfPrincipalComponentsT.loc[:, 0:9].sum(axis=1).values)\nprint('Variance Captured By First 20 Pricipal Components: ',\n     importanceOfPrincipalComponentsT.loc[:, 0:19].sum(axis=1).values)\nprint('Variance Captured By First 100 Pricipal Components: ',\n     importanceOfPrincipalComponentsT.loc[:, 0:99].sum(axis=1).values)\nprint('Variance Captured By First 200 Pricipal Components: ',\n     importanceOfPrincipalComponentsT.loc[:, 0:199].sum(axis=1).values)\nprint('Variance Captured By First 300 Pricipal Components: ',\n     importanceOfPrincipalComponentsT.loc[:, 0:299].sum(axis=1).values)\nprint('Variance Captured By First 400 Pricipal Components: ',\n     importanceOfPrincipalComponentsT.loc[:, 0:399].sum(axis=1).values)\nprint('Variance Captured By First 500 Pricipal Components: ',\n     importanceOfPrincipalComponentsT.loc[:, 0:499].sum(axis=1).values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"importanceOfPrincipalComponentsT","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(rc={'figure.figsize':(10,10)})\nsns.barplot(data=importanceOfPrincipalComponentsT.loc[:,0:9], palette=\"pastel\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#temp = train_target.iloc[:, 5:20]\n#temp = temp[(temp['acetylcholinesterase_inhibitor'] == 1) | (temp['adenosine_receptor_agonist'] == 1) | (temp['adenylyl_cyclase_activator'] == 1)]\n#temp.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def scatterPlot(xDF, yDF, algoName):\n    tempDF = pd.DataFrame(data=xDF.loc[:, 0:1], index=xDF.index)\n    tempDF = pd.concat((tempDF, yDF), axis=1, join='inner')\n    tempDF.columns = [\"First Vector\", \"Second Vector\", \"Label\"]\n    sns.lmplot(x='First Vector', y='Second Vector', hue='Label', data=tempDF, fit_reg=False)\n    \n    ax = plt.gca()\n    ax.set_title('Target Value  :  ' + algoName + '  ' + str(np.sum(tempDF['Label'])))   \n    \n    #print(np.sum(tempDF['Label']))\n\n    \ndef scatterPlot2(xDF, yDF, algoName, column1, column2):\n    tempDF = pd.DataFrame(data=xDF.loc[:, [column1, column2]], index=xDF.index)\n    tempDF = pd.concat((tempDF, yDF), axis=1, join='inner')\n    tempDF.columns = [\"First Vector\", \"Second Vector\", \"Label\"]\n    sns.lmplot(x='First Vector', y='Second Vector', hue='Label', data=tempDF, fit_reg=False)\n    \n    ax = plt.gca()\n    ax.set_title('Separation of Observations using ' + algoName)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in y_columns.columns[0:10]:\n    scatterPlot(X_train_PCA, train_target[col], col)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scatterPlot2(train_feat_scale, train_target['trpv_agonist'], 'PCA', 'g-0', 'cp_time')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Number per target","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"column_sum = np.sum(train_target, axis=0).to_frame()\ncolumn_sum.reset_index(inplace=True)\n\ncolumn_sum.columns = ['y_name', 'count']\n\ncolumn_sum = column_sum.iloc[1:,:]\ncolumn_sum = column_sum.sort_values(by=['count'], axis=0, ascending=False)\n\ncolumn_sum_top20 = column_sum[:20]\n\nprint(column_sum_top20)\n\nplt.figure(figsize = (20, 10))\nplt.title('# of true labels per column')\ng = sns.barplot(x=column_sum_top20['y_name'], y=column_sum_top20['count'], data=column_sum_top20, palette=\"pastel\")\ng.set_xticklabels(g.get_xticklabels(), rotation=45)\n\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"column_sum_bottom20 = column_sum[-20:]\n\nprint(column_sum_bottom20)\n\nplt.figure(figsize = (20, 10))\nplt.title('# of true labels per column')\ng = sns.barplot(x=column_sum_bottom20['y_name'], y=column_sum_bottom20['count'], data=column_sum_bottom20, palette=\"pastel\")\ng.set_xticklabels(g.get_xticklabels(), rotation=45)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Number per Count","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"row_sum = np.sum(train_target, axis=1)\n\nrow_sum_vc = pd.DataFrame(row_sum.value_counts())\nrow_sum_vc.reset_index(inplace=True)\nrow_sum_vc.columns = ['tlc','count']\n\nprint(row_sum_vc)\n\nplt.figure(figsize = (10, 10))\nplt.title('# of true labels per row')\nsns.barplot(x=row_sum_vc['tlc'], y=row_sum_vc['count'], data=row_sum_vc, palette=\"pastel\")\nplt.xlabel('target label count')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ratio_0_1 = row_sum_vc[(row_sum_vc['tlc'] == 0) | (row_sum_vc['tlc'] == 1)]['count'].sum() / row_sum_vc['count'].sum()\nprint(f'As for the number of targets for each row, 0 and 1 occupy {ratio_0_1} percent.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_columns = train_feat_scale.columns.to_list()\ng_list = [i for i in train_columns if i.startswith('g-')]\nc_list = [i for i in train_columns if i.startswith('c-')]\ntrain_feat_g = train_feat_scale[g_list]\ntrain_feat_c = train_feat_scale[c_list]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_feat_g","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_feat_c","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_index = range(0, len(train_feat_g))\n\nn_components = 772\nwhiten = False\nrandom_state = 2020\n\npca_g_feat = PCA(n_components=n_components, whiten=whiten, random_state=random_state)\n\nX_train_PCA_g = pca_g_feat.fit_transform(train_feat_g)\nX_train_PCA_g = pd.DataFrame(data=X_train_PCA_g, index=train_index)\n\nimportanceOfPrincipalComponents = pd.DataFrame(data=pca_g_feat.explained_variance_ratio_)\nimportanceOfPrincipalComponentsT =importanceOfPrincipalComponents.T\n\nprint(importanceOfPrincipalComponents)\n#sns.set(rc={'figure.figsize':(10,10)})\nsns.barplot(data=importanceOfPrincipalComponentsT.loc[:,0:9], palette=\"pastel\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_index = range(0, len(train_feat_c))\n\nn_components = 100\nwhiten = False\nrandom_state = 2020\n\npca_c_feat = PCA(n_components=n_components, whiten=whiten, random_state=random_state)\n\nX_train_PCA_c = pca_c_feat.fit_transform(train_feat_c)\nX_train_PCA_c = pd.DataFrame(data=X_train_PCA_c, index=train_index)\n\nimportanceOfPrincipalComponents = pd.DataFrame(data=pca_c_feat.explained_variance_ratio_)\nimportanceOfPrincipalComponentsT =importanceOfPrincipalComponents.T\n\nprint(importanceOfPrincipalComponents)\n#sns.set(rc={'figure.figsize':(10,10)})\nsns.barplot(data=importanceOfPrincipalComponentsT.loc[:,0:9], palette=\"pastel\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}