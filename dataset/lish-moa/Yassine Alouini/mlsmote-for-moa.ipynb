{"cells":[{"metadata":{},"cell_type":"markdown","source":"An application of the MLSMOTE technique implemented in the following [notebook](https://www.kaggle.com/tolgadincer/upsampling-multilabel-data-with-mlsmote) (upvote it if you find it useful) to the MoA dataset.\n\nNotice that for now, I don't know yet how to deal with categorical features (one idea though is to do one-hot encoding first then apply the standard method). \n\nLet me know in the comments if you have an idea.\nEnjoy!"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport random\nfrom sklearn.datasets import make_classification\nfrom sklearn.neighbors import NearestNeighbors\nfrom imblearn.over_sampling import SMOTENC","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN_FEATURES_PATH = \"../input/lish-moa/train_features.csv\"\nTRAIN_TARGETS_PATH = \"../input/lish-moa/train_targets_scored.csv\"\nDOSE_MAPPING = {\"D1\": 0, \"D2\": 1}\nTIME_MAPPING = {24: 0, 48: 2, 72: 3}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_targets_df = pd.read_csv(TRAIN_TARGETS_PATH)\ntrain_features_df = pd.read_csv(TRAIN_FEATURES_PATH)\ntrain = train_features_df.merge(train_targets_df, on=\"sig_id\")\ntrain = (\n    train.loc[lambda df: df[\"cp_type\"] == \"trt_cp\"]\n    .reset_index(drop=True)\n    .drop([\"cp_type\", \"sig_id\"], axis=1)\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"cp_dose\"] = train[\"cp_dose\"].map(DOSE_MAPPING)\ntrain[\"cp_time\"] = train[\"cp_time\"].map(TIME_MAPPING)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FEATURES = sorted(train_features_df.drop([\"cp_type\", \"sig_id\"], axis=1).columns.tolist())\nTARGETS = sorted(train_targets_df.drop(\"sig_id\", axis=1).columns.tolist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(TARGETS))\nprint(FEATURES[:5])\nprint(TARGETS[:5])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def get_tail_label(df: pd.DataFrame, ql=[0.05, 1.]) -> list:\n    \"\"\"\n    Find the underrepresented targets.\n    Underrepresented targets are those which are observed less than the median occurance.\n    Targets beyond a quantile limit are filtered.\n    \"\"\"\n    irlbl = df.sum(axis=0)\n    irlbl = irlbl[(irlbl > irlbl.quantile(ql[0])) & ((irlbl < irlbl.quantile(ql[1])))]  # Filtering\n    irlbl = irlbl.max() / irlbl\n    threshold_irlbl = irlbl.median()\n    tail_label = irlbl[irlbl > threshold_irlbl].index.tolist()\n    return tail_label\n\ndef get_minority_samples(X: pd.DataFrame, y: pd.DataFrame, ql=[0.05, 1.]):\n    \"\"\"\n    return\n    X_sub: pandas.DataFrame, the feature vector minority dataframe\n    y_sub: pandas.DataFrame, the target vector minority dataframe\n    \"\"\"\n    tail_labels = get_tail_label(y, ql=ql)\n    index = y[y[tail_labels].apply(lambda x: (x == 1).any(), axis=1)].index.tolist()\n    \n    X_sub = X[X.index.isin(index)].reset_index(drop = True)\n    y_sub = y[y.index.isin(index)].reset_index(drop = True)\n    return X_sub, y_sub\n\ndef nearest_neighbour(X: pd.DataFrame, neigh) -> list:\n    \"\"\"\n    Give index of 10 nearest neighbor of all the instance\n    \n    args\n    X: np.array, array whose nearest neighbor has to find\n    \n    return\n    indices: list of list, index of 5 NN of each element in X\n    \"\"\"\n    nbs = NearestNeighbors(n_neighbors=neigh, metric='euclidean', algorithm='kd_tree').fit(X)\n    euclidean, indices = nbs.kneighbors(X)\n    return indices\n\ndef MLSMOTE(X, y, n_sample, neigh=5):\n    \"\"\"\n    Give the augmented data using MLSMOTE algorithm\n    \n    args\n    X: pandas.DataFrame, input vector DataFrame\n    y: pandas.DataFrame, feature vector dataframe\n    n_sample: int, number of newly generated sample\n    \n    return\n    new_X: pandas.DataFrame, augmented feature vector data\n    target: pandas.DataFrame, augmented target vector data\n    \"\"\"\n    indices2 = nearest_neighbour(X, neigh=5)\n    n = len(indices2)\n    new_X = np.zeros((n_sample, X.shape[1]))\n    target = np.zeros((n_sample, y.shape[1]))\n    for i in range(n_sample):\n        reference = random.randint(0, n-1)\n        neighbor = random.choice(indices2[reference, 1:])\n        all_point = indices2[reference]\n        nn_df = y[y.index.isin(all_point)]\n        ser = nn_df.sum(axis = 0, skipna = True)\n        target[i] = np.array([1 if val > 0 else 0 for val in ser])\n        ratio = random.random()\n        gap = X.loc[reference,:] - X.loc[neighbor,:]\n        new_X[i] = np.array(X.loc[reference,:] + ratio * gap)\n    new_X = pd.DataFrame(new_X, columns=X.columns)\n    target = pd.DataFrame(target, columns=y.columns)\n    return new_X, target\n\n\n# TODO: Adapt this to MLSMOTE?\n# smote_nc = SMOTENC(categorical_features=[0, 2], random_state=0)\n# X_resampled, y_resampled = smote_nc.fit_resample(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Should be a DataFrame\nX = train.loc[:, FEATURES]\ny = train.loc[:, TARGETS]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"N_SAMPELS = 1000\nN_NEIGHBORS = 5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_sub, y_sub = get_minority_samples(X, y)  # Getting minority samples of that datframe\nX_res, y_res = MLSMOTE(X_sub, y_sub, N_SAMPELS, N_NEIGHBORS)  # Applying MLSMOTE to augment the dataframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_res.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_res.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_res[\"cp_time\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_res[\"cp_dose\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_res.sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Old vs augmented data"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_res.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Saving the new data"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.concat([X, X_res]).to_csv(\"augmented_train_features.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.concat([y, y_res]).to_csv(\"augmented_train_targets.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}