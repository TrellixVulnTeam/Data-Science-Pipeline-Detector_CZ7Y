{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# TODO: Mix R and Python using reticulate?\n# Maybe later...\n# Can reticulate be used?\n# Using py2r? Does this exist?","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pylab as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Warning**: before we start, notice that, since this is a code competition, the test dataset \nwe have here is only a subset of the whole dataset. Indeed, when re-run, the \"real\" test dataset\nwill be about 4 times larger. Some insights thus only partially represent the reality. Use this fact to your \nadvantage.\n\nWith that out of the way, let's go!"},{"metadata":{},"cell_type":"markdown","source":"# Load the datasets"},{"metadata":{},"cell_type":"markdown","source":"These are of two types of datasets:\n    \n- features\n- targets (scored)\n\nThere is also one extra type of file with `non scored` targets but we will get back to this later.\nLet's load the different DataFrames."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_df = pd.read_csv(\"../input/lish-moa/train_features.csv\")\ntest_features_df = pd.read_csv(\"../input/lish-moa/test_features.csv\")\ntrain_targets_df = pd.read_csv(\"../input/lish-moa/train_targets_scored.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Features"},{"metadata":{},"cell_type":"markdown","source":"To get started, let's explore the features (both train and public test). For that, we will check \nsome samples, the data types, etc..."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_features_df.sample(2).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_features_df.sample(2).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_df.columns.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_features_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train_features_df.columns[train_features_df.columns.str.startswith(\"c-\")])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train_features_df.columns[train_features_df.columns.str.startswith(\"g-\")])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in train_features_df.select_dtypes([\"object\", \"int\"]):\n    print(f\"Unique value counts for {col}\")\n    print(train_features_df.loc[:, col].value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Few first insights (for both train and test):\n\n- We have **876** columns\n- Among these, lots of columns start with `c-` or `g-`:\n    * **100** columns of c type from 0 to 99: c-0, c-1, and so on. These are related to the \n    * **772** columns of g type from 0 to 771: \n- `cp_type`: either `trt_cp` or  \n- `cp_dose`: either D1 or D2. These could be small and high doses (of which one could be leathal to the cells...).\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_df[\"sig_id\"].unique().tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_df[\"sig_id\"].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_df[\"cp_dose\"].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_df[\"cp_dose\"].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Targets"},{"metadata":{},"cell_type":"markdown","source":"Now that we understand better the features, let's explore a little bit more the targets.\nTo start, let's have a look at the count of positives (i.e. ones) for each target.\nTo make this more readable, we will make many barplots."},{"metadata":{"trusted":true},"cell_type":"code","source":"targets_count_s = train_targets_df.drop(\"sig_id\", axis=1).sum().sort_values(ascending=False).copy()\n\nchunk_size = (len(targets_count_s) // 10 + 1)\n\nfig, axes = plt.subplots(10, 1, figsize=(8, 100))\n\ncount = 0\nfor ax_id, chunk_id in enumerate(range(0, len(targets_count_s), chunk_size)):\n    targets_count_s.iloc[chunk_id:chunk_id+chunk_size].sort_values().plot(kind=\"barh\", ax=axes[ax_id])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"nfkb_inhibitor is the most common target (with a wooping) and atp-sensitive_potassium_channel_antagonist is the least one\n(with a mere 1 occurence)"},{"metadata":{},"cell_type":"markdown","source":"In order to prepare the next section, let's prepare one new targets column: the sum\nof all the targets: one row is equal to the sum accross all the targets. "},{"metadata":{"trusted":true},"cell_type":"code","source":"train_targets_df[\"all\"] = train_targets_df.drop(\"sig_id\", axis=1).sum(axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Control groups"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"As stated in the data description, some rows come from controle groups. How to spot these: \nwell that's easy, we juste need to "},{"metadata":{"trusted":true},"cell_type":"code","source":"df = train_features_df.merge(train_targets_df, on=\"sig_id\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(df.groupby([\"all\", \"cp_type\"])\n    .size()\n    .unstack(fill_value=0))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Few things to say about this confusion matrix:\n    \n    \n1. All ctl_vehicle have 0 targets (first row, ctl_vehicle column) => thus no false positives in the control group.\nThis allows us to do two things: first, we can train without these control rows and second, \n2. Very few rows have many targets. For instance, we have 6 rows with 7 targets at 1.\nWe will explore some of these rows and see if they share something (spoiler: they do).\n3. In contrast to that, most of the rows have 0 or 1 target at a time (TODO: add percentage). \nThis means that we can simplify the problem by considering it as a multiclass problem (dropping the rows with more than 1 target)."},{"metadata":{},"cell_type":"markdown","source":"# Specific MoA?"},{"metadata":{},"cell_type":"markdown","source":"One interesting observation is that few `sig_id`'s have always the same group of targets. Let's find out about these.\nWe will start with the fewset, i.e. those with a sum of targets equal to 7 (this number can be seen in the occurences matrix above): \n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_targets_df.loc[lambda df: (df[\"all\"] == 7), :].loc[:, lambda df: (df != 0).any(axis=0)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's also check the next number in the list: those having 5 targets."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_targets_df.loc[lambda df: (df[\"all\"] == 5), :].loc[:, lambda df: (df != 0).any(axis=0)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Mean model"},{"metadata":{},"cell_type":"markdown","source":"One interesting model to start with is the mean model, i.e. the mean over all targets from the train \ntargets.\nA refined version of this is to remove the control group from the train targets then compute the mean."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}