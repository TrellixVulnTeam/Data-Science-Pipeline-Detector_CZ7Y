{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import optuna","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-input":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.execute_input":"2020-11-02T18:17:01.246725Z","iopub.status.busy":"2020-11-02T18:17:01.245984Z","iopub.status.idle":"2020-11-02T18:17:02.635543Z","shell.execute_reply":"2020-11-02T18:17:02.636434Z"},"papermill":{"duration":1.438351,"end_time":"2020-11-02T18:17:02.636599","exception":false,"start_time":"2020-11-02T18:17:01.198248","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import numpy as np\nimport random\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport copy\nimport seaborn as sns\n\nfrom sklearn import preprocessing\nfrom sklearn.metrics import log_loss\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import QuantileTransformer\n\nimport sys\nsys.path.append('../input/iterative-stratification/iterative-stratification-master')\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold#多标签K折划分\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nos.listdir('../input/lish-moa')","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.060029,"end_time":"2020-11-02T18:18:05.774203","exception":false,"start_time":"2020-11-02T18:18:05.714174","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Preprocessing steps"},{"metadata":{"execution":{"iopub.execute_input":"2020-11-02T18:17:49.367974Z","iopub.status.busy":"2020-11-02T18:17:49.367391Z","iopub.status.idle":"2020-11-02T18:17:59.927226Z","shell.execute_reply":"2020-11-02T18:17:59.92661Z"},"papermill":{"duration":10.618656,"end_time":"2020-11-02T18:17:59.927347","exception":false,"start_time":"2020-11-02T18:17:49.308691","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"train2 = pd.read_csv('../input/pdata-moa2/p_train_features (1).csv')\ntarget2= pd.read_csv('../input/pdata-moa2/p_train_targets (1).csv')\n\n#train_targets_nonscored = pd.read_csv('../input/pdata-moa/p_train_targets_nonscored.csv')\ntest2 = pd.read_csv('../input/pdata-moa2/p_test_features (1).csv')\nsample_submission = pd.read_csv('../input/lish-moa/sample_submission.csv')\n\n\ntrain2_orig=train2.copy()\ntest2_orig=test2.copy()\ntarget2_orig=target2.copy()\n\ntarget2=target2.iloc[:,1:]\ntrain2=train2.iloc[:,1:]\n#train2['sig_id']=train['sig_id']\ntrain2=train2.merge(target2, on='sig_id')\ntest2=test2.iloc[:,1:]\n\ntrain=train2\ntest=test2\ntarget=target2","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-02T18:18:00.27437Z","iopub.status.busy":"2020-11-02T18:18:00.273402Z","iopub.status.idle":"2020-11-02T18:18:00.298845Z","shell.execute_reply":"2020-11-02T18:18:00.29933Z"},"papermill":{"duration":0.10539,"end_time":"2020-11-02T18:18:00.299468","exception":false,"start_time":"2020-11-02T18:18:00.194078","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"target","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-02T18:18:00.414293Z","iopub.status.busy":"2020-11-02T18:18:00.413105Z","iopub.status.idle":"2020-11-02T18:18:00.633607Z","shell.execute_reply":"2020-11-02T18:18:00.634458Z"},"papermill":{"duration":0.280732,"end_time":"2020-11-02T18:18:00.634667","exception":false,"start_time":"2020-11-02T18:18:00.353935","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-02T18:18:00.790663Z","iopub.status.busy":"2020-11-02T18:18:00.788756Z","iopub.status.idle":"2020-11-02T18:18:00.821242Z","shell.execute_reply":"2020-11-02T18:18:00.821802Z"},"papermill":{"duration":0.109514,"end_time":"2020-11-02T18:18:00.82194","exception":false,"start_time":"2020-11-02T18:18:00.712426","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_everything(seed=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CV Folds"},{"metadata":{"execution":{"iopub.execute_input":"2020-11-02T18:18:01.143276Z","iopub.status.busy":"2020-11-02T18:18:01.142337Z","iopub.status.idle":"2020-11-02T18:18:04.661242Z","shell.execute_reply":"2020-11-02T18:18:04.662378Z"},"papermill":{"duration":3.617269,"end_time":"2020-11-02T18:18:04.662593","exception":false,"start_time":"2020-11-02T18:18:01.045324","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"folds = train.copy()\n\nmskf = MultilabelStratifiedKFold(n_splits=6,random_state=34)\n\nfor f, (t_idx, v_idx) in enumerate(mskf.split(X=train, y=target)):\n    print(f)\n    folds.loc[v_idx, 'kfold'] = int(f)\n\nfolds['kfold'] = folds['kfold'].astype(int)\nfolds","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-02T18:18:06.517699Z","iopub.status.busy":"2020-11-02T18:18:06.516515Z","iopub.status.idle":"2020-11-02T18:18:06.521743Z","shell.execute_reply":"2020-11-02T18:18:06.520809Z"},"papermill":{"duration":0.421821,"end_time":"2020-11-02T18:18:06.521853","exception":false,"start_time":"2020-11-02T18:18:06.100032","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"target_cols = target.drop('sig_id', axis=1).columns.values.tolist()\n\nfeature_cols = [c for c in folds.columns if c not in target_cols]\nfeature_cols = [c for c in feature_cols if c not in ['kfold','sig_id']]\nlen(feature_cols)\n\n# HyperParameters\n\nDEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\nEPOCHS = 30 \nBATCH_SIZE = 128\nLEARNING_RATE = 1e-3\nWEIGHT_DECAY = 1e-5\nNFOLDS = 6      \nEARLY_STOPPING_STEPS = 5\nEARLY_STOP = False \n\nnum_features=len(feature_cols)\nnum_targets=len(target_cols)\n\nNTRIALS=20","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-02T18:18:04.851909Z","iopub.status.busy":"2020-11-02T18:18:04.850212Z","iopub.status.idle":"2020-11-02T18:18:04.855587Z","shell.execute_reply":"2020-11-02T18:18:04.852661Z"},"papermill":{"duration":0.110616,"end_time":"2020-11-02T18:18:04.855691","exception":false,"start_time":"2020-11-02T18:18:04.745075","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"print(train.shape)\nprint(folds.shape)\nprint(test.shape)\nprint(target.shape)\nprint(sample_submission.shape)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.05732,"end_time":"2020-11-02T18:18:04.971226","exception":false,"start_time":"2020-11-02T18:18:04.913906","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Dataset Classes"},{"metadata":{"execution":{"iopub.execute_input":"2020-11-02T18:18:05.103433Z","iopub.status.busy":"2020-11-02T18:18:05.101883Z","iopub.status.idle":"2020-11-02T18:18:05.1045Z","shell.execute_reply":"2020-11-02T18:18:05.104978Z"},"papermill":{"duration":0.075622,"end_time":"2020-11-02T18:18:05.105112","exception":false,"start_time":"2020-11-02T18:18:05.02949","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"class MoADataset:\n    def __init__(self, features, targets):\n        self.features = features\n        self.targets = targets\n        \n    def __len__(self):\n        return (self.features.shape[0])\n    \n    def __getitem__(self, idx):\n        dct = {\n            'x' : torch.tensor(self.features[idx, :], dtype=torch.float),\n            'y' : torch.tensor(self.targets[idx, :], dtype=torch.float)            \n        }\n        return dct\n    \nclass TestDataset:\n    def __init__(self, features):\n        self.features = features\n        \n    def __len__(self):\n        return (self.features.shape[0])\n    \n    def __getitem__(self, idx):\n        dct = {\n            'x' : torch.tensor(self.features[idx, :], dtype=torch.float)\n        }\n        return dct\n    ","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.061843,"end_time":"2020-11-02T18:18:05.506369","exception":false,"start_time":"2020-11-02T18:18:05.444526","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Model"},{"metadata":{"execution":{"iopub.execute_input":"2020-11-02T18:18:05.644255Z","iopub.status.busy":"2020-11-02T18:18:05.643353Z","iopub.status.idle":"2020-11-02T18:18:05.654034Z","shell.execute_reply":"2020-11-02T18:18:05.653524Z"},"papermill":{"duration":0.085067,"end_time":"2020-11-02T18:18:05.654146","exception":false,"start_time":"2020-11-02T18:18:05.569079","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self, num_features, num_targets, hidden_size,dropout_rate):\n        super(Model, self).__init__()\n        self.batch_norm1 = nn.BatchNorm1d(num_features)\n        self.dense1 = nn.utils.weight_norm(nn.Linear(num_features, hidden_size))\n        \n        self.batch_norm2 = nn.BatchNorm1d(hidden_size)\n        self.dropout2 = nn.Dropout(dropout_rate)\n        self.dense2 = nn.utils.weight_norm(nn.Linear(hidden_size, hidden_size))\n        \n        self.batch_norm3 = nn.BatchNorm1d(hidden_size)\n        self.dropout3 = nn.Dropout(dropout_rate)\n        self.dense3 = nn.utils.weight_norm(nn.Linear(hidden_size, num_targets))#hidden_size\n        \n       # self.batch_norm4 = nn.BatchNorm1d(hidden_size)\n       # self.dropout4 = nn.Dropout(dropout_rate)\n       # self.dense4 = nn.utils.weight_norm(nn.Linear(hidden_size, num_targets))\n        \n    # 用于解决pytorch版本的train/val loss突然变为nan的现象    \n    def recalibrate_layer(self, layer): \n\n        if(torch.isnan(layer.weight_v).sum() > 0):\n            print ('recalibrate layer.weight_v')\n            layer.weight_v = torch.nn.Parameter(torch.where(torch.isnan(layer.weight_v), torch.zeros_like(layer.weight_v), layer.weight_v))\n            layer.weight_v = torch.nn.Parameter(layer.weight_v + 1e-7)\n\n        if(torch.isnan(layer.weight).sum() > 0):\n            print ('recalibrate layer.weight')\n            layer.weight = torch.where(torch.isnan(layer.weight), torch.zeros_like(layer.weight), layer.weight)\n            layer.weight += 1e-7\n    \n    def forward(self, x):\n        x = self.batch_norm1(x)\n        self.recalibrate_layer(self.dense1)\n        x = F.relu(self.dense1(x))\n        \n        x = self.batch_norm2(x)\n        x = self.dropout2(x)\n        self.recalibrate_layer(self.dense2)\n        x = F.relu(self.dense2(x))\n        \n        x = self.batch_norm3(x)\n        x = self.dropout3(x)\n        self.recalibrate_layer(self.dense3)\n        x = self.dense3(x)#F.relu()\n        \n       # x = self.batch_norm4(x)\n       # x = self.dropout4(x)\n        #self.recalibrate_layer(self.dense4)\n       # x = self.dense4(x)\n        \n        \n        return x\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Model_L3(nn.Module):\n    def __init__(self, num_features, num_targets, hidden_size,dropout_rate):\n        super(Model, self).__init__()\n        \n        self.batch_norm1 = nn.BatchNorm1d(num_features)\n        self.dense1 = nn.utils.weight_norm(nn.Linear(num_features, hidden_size))\n        \n        self.batch_norm2 = nn.BatchNorm1d(hidden_size)\n        self.dropout2 = nn.Dropout(dropout_rate)\n        self.dense2 = nn.utils.weight_norm(nn.Linear(hidden_size, hidden_size))\n        \n        self.batch_norm3 = nn.BatchNorm1d(hidden_size)\n        self.dropout3= nn.Dropout(dropout_rate)\n        self.dense3 = nn.utils.weight_norm(nn.Linear(hidden_size,hidden_size))#\n        \n        self.batch_norm4 = nn.BatchNorm1d(hidden_size)\n        self.dropout4 = nn.Dropout(dropout_rate)\n        self.dense4 = nn.utils.weight_norm(nn.Linear(hidden_size, num_targets))\n        \n    # 用于解决pytorch版本的train/val loss突然变为nan的现象    \n    def recalibrate_layer(self, layer): \n\n        if(torch.isnan(layer.weight_v).sum() > 0):\n            print ('recalibrate layer.weight_v')\n            layer.weight_v = torch.nn.Parameter(torch.where(torch.isnan(layer.weight_v), torch.zeros_like(layer.weight_v), layer.weight_v))\n            layer.weight_v = torch.nn.Parameter(layer.weight_v + 1e-7)\n\n        if(torch.isnan(layer.weight).sum() > 0):\n            print ('recalibrate layer.weight')\n            layer.weight = torch.where(torch.isnan(layer.weight), torch.zeros_like(layer.weight), layer.weight)\n            layer.weight += 1e-7\n    \n    def forward(self, x):\n        x = self.batch_norm1(x)\n        self.recalibrate_layer(self.dense1)\n        x = F.relu(self.dense1(x))\n        \n        x = self.batch_norm2(x)\n        x = self.dropout2(x)\n        self.recalibrate_layer(self.dense2)\n        x = F.relu(self.dense2(x))\n        \n        x = self.batch_norm3(x)\n        x = self.dropout3(x)\n        self.recalibrate_layer(self.dense3)\n        x = F.relu(self.dense3(x))\n        \n        x = self.batch_norm4(x)\n        x = self.dropout4(x)\n        self.recalibrate_layer(self.dense4)\n        x = self.dense4(x)\n        \n        return x","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-02T18:18:05.376557Z","iopub.status.busy":"2020-11-02T18:18:05.375654Z","iopub.status.idle":"2020-11-02T18:18:05.378129Z","shell.execute_reply":"2020-11-02T18:18:05.379173Z"},"papermill":{"duration":0.075869,"end_time":"2020-11-02T18:18:05.379616","exception":false,"start_time":"2020-11-02T18:18:05.303747","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import torch\nfrom torch.nn.modules.loss import _WeightedLoss\nimport torch.nn.functional as F\n\nclass SmoothBCEwLogits(_WeightedLoss):\n    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n        super().__init__(weight=weight, reduction=reduction)\n        self.smoothing = smoothing\n        self.weight = weight\n        self.reduction = reduction\n\n    @staticmethod\n    def _smooth(targets:torch.Tensor, n_labels:int, smoothing=0.0):\n        assert 0 <= smoothing < 1\n        with torch.no_grad():\n            targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n        return targets\n\n    def forward(self, inputs, targets):\n        targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1),\n            self.smoothing)\n        loss = F.binary_cross_entropy_with_logits(inputs, targets,self.weight)\n\n        if  self.reduction == 'sum':\n            loss = loss.sum()\n        elif  self.reduction == 'mean':\n            loss = loss.mean()\n\n        return loss\n    \nclass LabelSmoothingLoss(nn.Module):\n    def __init__(self, classes, smoothing=0.0, dim=-1):\n        super(LabelSmoothingLoss, self).__init__()\n        self.confidence = 1.0 - smoothing\n        self.smoothing = smoothing\n        self.cls = classes\n        self.dim = dim\n\n    def forward(self, pred, target):\n        pred = pred.log_softmax(dim=self.dim)\n        with torch.no_grad():\n            # true_dist = pred.data.clone()\n            true_dist = torch.zeros_like(pred)\n            true_dist.fill_(self.smoothing / (self.cls - 1))\n            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))    ","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-02T18:18:05.242309Z","iopub.status.busy":"2020-11-02T18:18:05.241538Z","iopub.status.idle":"2020-11-02T18:18:05.244938Z","shell.execute_reply":"2020-11-02T18:18:05.244463Z"},"papermill":{"duration":0.07947,"end_time":"2020-11-02T18:18:05.245039","exception":false,"start_time":"2020-11-02T18:18:05.165569","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def train_fn(model, optimizer, scheduler, loss_fn, dataloader, device):\n    model.train()\n    final_loss = 0\n    \n    for data in dataloader:\n        optimizer.zero_grad()\n        inputs, targets = data['x'].to(device), data['y'].to(device)\n#         print(inputs.shape)\n        outputs = model(inputs)\n        loss = loss_fn(outputs, targets)\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n        \n        final_loss += loss.item()\n        \n    final_loss /= len(dataloader)\n    \n    return final_loss\n\n\ndef valid_fn(model, loss_fn, dataloader, device):\n    model.eval()\n    final_loss = 0\n    valid_preds = []\n    \n    for data in dataloader:\n        inputs, targets = data['x'].to(device), data['y'].to(device)\n        outputs = model(inputs)\n        loss = loss_fn(outputs, targets)\n        \n        final_loss += loss.item()\n        valid_preds.append(outputs.sigmoid().detach().cpu().numpy())\n        \n    final_loss /= len(dataloader)\n    valid_preds = np.concatenate(valid_preds)\n    \n    return final_loss, valid_preds\n\ndef inference_fn(model, dataloader, device):\n    model.eval()\n    preds = []\n    \n    for data in dataloader:\n        inputs = data['x'].to(device)\n\n        with torch.no_grad():\n            outputs = model(inputs)\n        \n        preds.append(outputs.sigmoid().detach().cpu().numpy())\n        \n    preds = np.concatenate(preds)\n    \n    return preds\n\n","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.084174,"end_time":"2020-11-02T18:18:07.400493","exception":false,"start_time":"2020-11-02T18:18:07.316319","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Single fold training"},{"metadata":{"execution":{"iopub.execute_input":"2020-11-02T18:18:07.555851Z","iopub.status.busy":"2020-11-02T18:18:07.554843Z","iopub.status.idle":"2020-11-02T18:18:07.557309Z","shell.execute_reply":"2020-11-02T18:18:07.557767Z"},"papermill":{"duration":0.09034,"end_time":"2020-11-02T18:18:07.557893","exception":false,"start_time":"2020-11-02T18:18:07.467553","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def run_training(fold,params,save_model=False):\n    \n    #seed_everything(seed)\n\n    train =folds\n    test_ = test\n    \n    \n    trn_idx = train[train['kfold'] != fold].index\n    val_idx = train[train['kfold'] == fold].index\n    \n    train_df = train[train['kfold'] != fold].reset_index(drop=True)\n    valid_df = train[train['kfold'] == fold].reset_index(drop=True)\n    \n    x_train, y_train  = train_df[feature_cols].values, train_df[target_cols].values\n    x_valid, y_valid =  valid_df[feature_cols].values, valid_df[target_cols].values\n    \n    train_dataset = MoADataset(x_train, y_train)\n    valid_dataset = MoADataset(x_valid, y_valid)\n    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n    validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n\n    \n    model = Model(\n        num_features=num_features,\n        num_targets=num_targets,\n        hidden_size=params['hidden_size'], # Update\n        dropout_rate=params['dropout']          # Update\n    )\n    \n\n    model.to(DEVICE)\n    \n    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n    scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n                                              max_lr=1e-2, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n    \n    loss_fn = nn.BCEWithLogitsLoss()\n    loss_tr = SmoothBCEwLogits(smoothing =0.001)\n    \n    early_stopping_steps = EARLY_STOPPING_STEPS\n    early_step = 0\n   \n    oof = np.zeros((len(train), target.iloc[:, 1:].shape[1]))\n    best_loss = np.inf\n    \n    for epoch in range(EPOCHS):\n        \n        train_loss = train_fn(model, optimizer,scheduler, loss_tr, trainloader, DEVICE)# Back <-- Update: loss_tr-> loss_fn\n        print(f\"FOLD: {fold}, EPOCH: {epoch}, train_loss: {train_loss}\")\n        valid_loss, valid_preds = valid_fn(model, loss_fn, validloader, DEVICE)\n        print(f\"FOLD: {fold}, EPOCH: {epoch}, valid_loss: {valid_loss}\")\n        \n        if valid_loss < best_loss:\n            \n            best_loss = valid_loss\n            oof[val_idx] = valid_preds\n            torch.save(model.state_dict(), f\"FOLD{fold}_.pth\")\n        \n        elif(EARLY_STOP == True):\n            \n            early_step += 1\n            if (early_step >= early_stopping_steps):\n                break\n            \n    return best_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def objective(trial):\n    params={\n        'hidden_size': trial.suggest_int('hidden_size',512,4096),\n        'dropout': trial.suggest_uniform('dropout',0.0,1.0),\n    }\n    all_losses=[]\n    for f_ in range(NFOLDS):\n        temp_loss=run_training(f_,params,save_model=False)\n        all_losses.append(temp_loss)\n    return np.mean(all_losses)    ","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-02T18:49:29.55427Z","iopub.status.busy":"2020-11-02T18:49:29.552913Z","iopub.status.idle":"2020-11-02T18:49:30.724313Z","shell.execute_reply":"2020-11-02T18:49:30.723457Z"},"papermill":{"duration":1.679487,"end_time":"2020-11-02T18:49:30.724446","exception":false,"start_time":"2020-11-02T18:49:29.044959","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"study=optuna.create_study(direction=\"minimize\")\nstudy.optimize(objective,n_trials=NTRIALS)\n\n'''\nscores=0\nfor j in range(NFOLDS):\n    scr=run_training(j,trial_.params,save_model=True)\n    scores +=scr\n\nprint(scores/NFOLDS)   \n'''\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(study.best_params)\nprint(study.best_value)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}