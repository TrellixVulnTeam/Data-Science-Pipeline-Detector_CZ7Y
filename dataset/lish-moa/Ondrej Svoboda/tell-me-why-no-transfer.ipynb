{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Transfer learning and Mechanisms of Action\nFor the last few weeks, I have been thinking the following: This data set cries of transfer learning. Why?\nFor the following reasons:\n* We have an additional dataset with labels\n* Most people here tend to think this is a multioutput scenario. If this is true, inner layers should not depend too much on outputs\n* Some of the outputs have only a few examples. In two cases, there is a single positive outcome (therefore no way to predict it?). Since we have apparently very incomplete information, I would think more the more information the better.\n\nAll this smells like a textbook example of transfer learning, doesn't it? Yet after weeks of trying, I have never achieved better outcome with transfer model than with the same architecture which was directly fitted (not much worse, sure... but on competition score, I never scored better with transfer model). \n\nAny idea why?\n\n* Is my thinking wrong all along for some apparent reason?\n* Is my model construction erroneous?\n* What is going on here?\n\nThis only got public score of 0.23. This is not a particularly optimized version of the notebook... but still what's wrong with transfer learning here?"},{"metadata":{},"cell_type":"markdown","source":"## Display input data"},{"metadata":{},"cell_type":"markdown","source":"## Read data"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_feat_df = pd.read_csv(\"/kaggle/input/lish-moa/train_features.csv\", index_col='sig_id')\ntrain_feat_df.loc[:,'cp_dose_cat'] = train_feat_df.cp_dose.astype('category').cat.codes\ntrain_feat_df.loc[:,'cp_type_cat'] = train_feat_df.cp_type.astype('category').cat.codes\ntrain_feat_df.loc[:,'cp_time_cat'] = train_feat_df.cp_time.astype('category').cat.codes\ntrain_feat_df.drop(columns=['cp_dose', 'cp_type' ], inplace=True)\ntrain_feat_df.drop(columns=['cp_time' ], inplace=True)\ntrain_tg_scored_df = pd.read_csv(\"/kaggle/input/lish-moa/train_targets_scored.csv\", index_col='sig_id')\ntrain_tg_nonscored_df = pd.read_csv(\"/kaggle/input/lish-moa/train_targets_nonscored.csv\", index_col='sig_id')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_feat_df = train_feat_df.loc[train_feat_df.cp_type_cat==1, train_feat_df.columns != \"cp_type_cat\"]\ntrain_feat_df.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_feat_df = pd.read_csv(\"/kaggle/input/lish-moa/test_features.csv\", index_col='sig_id')\ntest_feat_df.loc[:,'cp_dose_cat'] = test_feat_df.cp_dose.astype('category').cat.codes\ntest_feat_df.loc[:,'cp_type_cat'] = test_feat_df.cp_type.astype('category').cat.codes\n# ??\ntest_feat_df.loc[:,'cp_time_cat'] = test_feat_df.cp_time.astype('category').cat.codes\ntest_feat_df.drop(columns=['cp_dose', 'cp_type' ], inplace=True)\ntest_feat_df.drop(columns=['cp_time' ], inplace=True)\ncontrol_indexes_test = [test_feat_df.index.get_loc(x) for x in test_feat_df[test_feat_df.cp_type_cat==0].index.values]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test_feat_df = test_feat_df.loc[test_feat_df.cp_type_cat==1, test_feat_df.columns != \"cp_type_cat\"]\ntest_feat_df = test_feat_df.loc[:, test_feat_df.columns != \"cp_type_cat\"]\ntest_feat_df.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Stratified train test split for multioutput case"},{"metadata":{"trusted":true},"cell_type":"code","source":"from skmultilearn.model_selection import IterativeStratification\n# sample_distribution_per_fold = [test_size, 1.0-test_size]\nstratifier = IterativeStratification(n_splits=2, order=2, sample_distribution_per_fold=[0.3, 0.7])\ntrain_indexes, test_indexes = next(stratifier.split(train_feat_df, train_tg_scored_df.loc[train_feat_df.index,:]))\nX_train, Y_train = train_feat_df.iloc[train_indexes], train_tg_scored_df.iloc[train_indexes]\nX_val, Y_val = train_feat_df.iloc[test_indexes], train_tg_scored_df.iloc[test_indexes]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Build keras transfer learning model\n### First create the featurizer which uses nonscored data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense, InputLayer, BatchNormalization\nfrom tensorflow.keras.layers import Dropout","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_nonscored = Sequential()\nmodel_nonscored.add(BatchNormalization(input_shape=(X_train.shape[1],)))\nmodel_nonscored.add(Dense(2048, activation='relu', input_shape=(875,)))\nmodel_nonscored.add(BatchNormalization())\nmodel_nonscored.add(Dense(1024, activation='relu'))\nmodel_nonscored.add(BatchNormalization())\nmodel_nonscored.add(Dense(512, activation='relu'))\nmodel_nonscored.add(Dropout(0.2))\nmodel_nonscored.add(BatchNormalization(name=\"Last_batch_norm_l\"))\nmodel_nonscored.add(Dense(402, activation='sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p_min = 0.001\np_max = 0.999\n\ndef logloss(y_true, y_pred):\n    y_pred = tf.clip_by_value(y_pred,p_min,p_max)\n    return -tf.keras.backend.mean(y_true*tf.keras.backend.log(y_pred) + (1-y_true)*tf.keras.backend.log(1-y_pred))\n\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_logloss', factor=0.1, verbose=0,mode='min',\n                              patience=3, min_lr=1E-7)\nearly_st = tf.keras.callbacks.EarlyStopping(monitor='val_logloss', min_delta=1E-5, patience=7, verbose=0, mode='min',\n    baseline=None, restore_best_weights=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n\n# default learning rate = 0.001\noptimizer = tf.keras.optimizers.Adam(\n    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False\n)\n\nmodel_nonscored.compile(optimizer='adam',loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=0.001), metrics=logloss )\nmodel_nonscored.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.keras.utils.plot_model(model_nonscored, to_file='model.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = model_nonscored.fit(train_feat_df, train_tg_nonscored_df.loc[train_feat_df.index,:], epochs=10, callbacks=[reduce_lr, early_st])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This might be an issue. Here I did not split the dataset and used the whole training set to fit the transfer model. Yet I also tested the proper split and it did not result in anything better..."},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I know this is not the most elegant usage of functional API. But it seems to work..."},{"metadata":{"trusted":true},"cell_type":"code","source":"model1_out = model_nonscored.get_layer('Last_batch_norm_l').output\nout = Dense(206, activation='sigmoid', name='output_layer_tlmodel')(model1_out)\ntlmodel = Model(inputs = model_nonscored.inputs, outputs = out)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#last_frozen = \"dropout_1\"\nlast_frozen = \"Last_batch_norm_l\"\nfor layer in tlmodel.layers:\n    layer.trainable = False    \n    if layer.name == last_frozen:\n        break\nfor layer in tlmodel.layers:\n    print(f\"{layer.name}: {layer.trainable}.\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tlmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tlmodel.compile(optimizer='adam',loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=0.001), metrics=logloss )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = tlmodel.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=1000, callbacks=[reduce_lr, early_st])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# clipping predictions\np_min = 0.001\np_max = 0.999\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = np.clip(tlmodel.predict(test_feat_df),p_min,p_max)\npredictions[control_indexes_test, :] = 0\n\npredictions_df = pd.DataFrame(predictions)\npredictions_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/lish-moa/sample_submission.csv', index_col='sig_id')\nprint(submission.shape)\nsubmission.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_df.index = submission.index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_df.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_df.columns = submission.columns\npredictions_df.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_df.to_csv(\"submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}