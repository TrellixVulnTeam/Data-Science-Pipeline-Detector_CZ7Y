{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Mechanisms of Action (MoA) Prediction"},{"metadata":{},"cell_type":"markdown","source":"The goal of this competition is to advance drug development through improvements of MoA prediction algorithms.\nWith MoA, scientists seek to identify a protein target associated with a disease and develop a molecule that can modulate that protein target. Mechanism of action stands for the biochemical interactions through which a drug generates its pharmacological effect.\nThere is a data set that combines gene expression and cell viability data. \nHence, the task is to use the training data set to develop a model that automatically labels each case in the test set as one or more MoA classes, so the task is a multi-label classification problem.\nThe evaluation of the model is based on the log loss function and it measures the performance of a classification model whose output is a probability value between 0 and 1. Log loss increases as the predicted probability diverges from the actual label.\nIn this Project after an Exploratory Data Analysis and the One-Hot Encoding into k-1 dummy variables, the data set is reduced with Autoencoder, moving from 875 features to 28 features. I've applied t-SNE at some new features and some target labels to discover graphical patterns.\n\n"},{"metadata":{},"cell_type":"markdown","source":"![](https://image.slidesharecdn.com/mechanismofdrugaction-131104071748-phpapp01/95/mechanism-of-drug-action-3-638.jpg?cb=1383549622)"},{"metadata":{},"cell_type":"markdown","source":"# Notes"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reference notebooks:\n# https://www.kaggle.com/sinamhd9/mechanisms-of-action-moa-tutorial\n# https://www.kaggle.com/fchmiel/xgboost-baseline-multilabel-classification","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prepare Workspace"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Upload libraries\nimport numpy as np \nimport pandas as pd \n\nimport matplotlib.pyplot as plt\n#% matplotlib inline\nimport seaborn as sns\n\nimport statistics as st \nimport scipy.stats as stats\n\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nfrom keras.layers import Input,Dense\nfrom keras.models import Model\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Import Data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Upload data set\ntrain = pd.read_csv('/kaggle/input/lish-moa/train_features.csv')\ntest = pd.read_csv('/kaggle/input/lish-moa/test_features.csv')\ntargets = pd.read_csv('/kaggle/input/lish-moa/train_targets_scored.csv')\ntargets_ns = pd.read_csv('/kaggle/input/lish-moa/train_targets_nonscored.csv')\nsubmission = pd.read_csv('/kaggle/input/lish-moa/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Have a peek of Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = train.append(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Look at dimension of data set and types of each attribute\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train\n# ['sig_id', 'cp_type', 'cp_dose'] == object\n# ['cp_time'] == int","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Summarize attribute distributions of the data frame\ndf.describe(include = 'all').T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Take a peek at the first rows of the data\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Look at dimension of data set and types of each attribute\ntargets.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Summarize attribute distributions of the data frame\ntargets.describe(include = 'all').T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Take a peek at the first rows of the data\ntargets.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Look at dimension of data set and types of each attribute\ntargets_ns.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Summarize attribute distributions of the data frame\ntargets_ns.describe(include = 'all').T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Take a peek at the first rows of the data\ntargets_ns.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Handling missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check missing values both to numeric features and categorical features \nfeat_missing = []\n\nfor f in df.columns:\n    missings = df[f].isnull().sum()\n    if missings > 0:\n        feat_missing.append(f)\n        missings_perc = missings/df.shape[0]\n        \n        # printing summary of missing values\n        print('Variable {} has {} records ({:.2%}) with missing values'.format(f, missings, missings_perc))\n\n# How many variables do present missing values?\nprint()\nprint('In total, there are {} variables with missing values'.format(len(feat_missing)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Target Variable Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"targets_df = targets.copy()\ntargets_df = targets_df.drop(['sig_id'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Summarize the class distribution \ncol_name = targets_df.columns\nfor var in col_name:\n    count = pd.crosstab(index = targets_df[var], columns=\"count\")\n    percentage = pd.crosstab(index = targets_df[var], columns=\"frequency\")/pd.crosstab(index = targets_df[var], columns=\"frequency\").sum()\n    print('\\n',pd.concat([count, percentage], axis=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the target variable\nfigures_per_time = 4\ncount = 0 \nfor var in targets_df.columns:\n    x = targets_df[var]\n    plt.figure(count//figures_per_time,figsize=(25,5))\n    plt.subplot(1,figures_per_time,np.mod(count,4)+1)\n    sns.countplot(x, color='g',linewidth=2)\n    plt.xticks(rotation=45)\n    count+=1\nax = sns.countplot(x=targets[var], data=targets, palette='rocket')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Numerical Features Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# gene features\ngene_features = [cols for cols in df.columns if cols.startswith('g-')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Univariate analysis looking at Mean, Standard Deviation, Skewness and Kurtosis\nfor col in gene_features:\n    print(col,\n        '\\nMean :', np.mean(df[col]),  \n        '\\nVariance :', np.var(df[col]),\n        '\\nStandard Deviation :', st.stdev(df[col]), \n        '\\nSkewness :', stats.skew(df[col]), \n        '\\nKurtosis :', stats.kurtosis(df[col]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Univariate analysis with density plots \nfigures_per_time = 4\ncount = 0 \nfor var in gene_features:\n    x = df[var]\n    plt.figure(count//figures_per_time,figsize=(25,5))\n    plt.subplot(1,figures_per_time,np.mod(count,4)+1)\n    sns.kdeplot(x, color='g',linewidth=2)\n    plt.xticks(rotation=45)\n    count+=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Univariate analysis with histogram plots \nfigures_per_time = 4\ncount = 0 \nfor var in gene_features:\n    x = df[var]\n    plt.figure(count//figures_per_time,figsize=(25,5))\n    plt.subplot(1,figures_per_time,np.mod(count,4)+1)\n    sns.distplot(x, bins=10, color='r')\n    plt.xticks(rotation=45)\n    count+=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Univariate analysis with box plots \nfigures_per_time = 4\ncount = 0 \nfor var in gene_features:\n    x = df[var]\n    plt.figure(count//figures_per_time,figsize=(25,5))\n    plt.subplot(1,figures_per_time,np.mod(count,4)+1)\n    sns.boxplot(x, color='b')\n    plt.xticks(rotation=45)\n    count+=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cell features\ncell_features = [cols for cols in df.columns if cols.startswith('g-')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Univariate analysis looking at Mean, Standard Deviation, Skewness and Kurtosis\nfor col in cell_features:\n    print(col,\n        '\\nMean :', np.mean(df[col]),  \n        '\\nVariance :', np.var(df[col]),\n        '\\nStandard Deviation :', st.stdev(df[col]), \n        '\\nSkewness :', stats.skew(df[col]), \n        '\\nKurtosis :', stats.kurtosis(df[col]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Univariate analysis with density plots \nfigures_per_time = 4\ncount = 0 \nfor var in cell_features:\n    x = df[var]\n    plt.figure(count//figures_per_time,figsize=(25,5))\n    plt.subplot(1,figures_per_time,np.mod(count,4)+1)\n    sns.kdeplot(x, color='g',linewidth=2)\n    plt.xticks(rotation=45)\n    count+=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Univariate analysis with histogram plots \nfigures_per_time = 4\ncount = 0 \nfor var in cell_features:\n    x = df[var]\n    plt.figure(count//figures_per_time,figsize=(25,5))\n    plt.subplot(1,figures_per_time,np.mod(count,4)+1)\n    sns.distplot(x, bins=10, color='r')\n    plt.xticks(rotation=45)\n    count+=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Univariate analysis with box plots \nfigures_per_time = 4\ncount = 0 \nfor var in cell_features:\n    x = df[var]\n    plt.figure(count//figures_per_time,figsize=(25,5))\n    plt.subplot(1,figures_per_time,np.mod(count,4)+1)\n    sns.boxplot(x, color='b')\n    plt.xticks(rotation=45)\n    count+=1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Categorical Features Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"fcat = ['cp_type', 'cp_dose']\nfor col in fcat:\n    count = pd.crosstab(index = df[col], columns=\"count\")\n    percentage = pd.crosstab(index = df[col], columns=\"frequency\")/pd.crosstab(index = df[col], columns=\"frequency\").sum()\n    tab = pd.concat([count, percentage], axis=1)\n    plt.figure(figsize=(5,5))\n    sns.countplot(x=df[col], data=df, palette=\"Set1\")\n    plt.xticks(rotation=45)\n    print(tab)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"# One-Hot Encoding into k-1 dummy Variables\ndummy_df = pd.concat([pd.get_dummies(df.cp_type, drop_first=True), \n                         pd.get_dummies(df.cp_dose, drop_first=True)], axis=1)\ndummy_df = dummy_df.astype(int)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Handling Data Set"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Whole data set\ndf_new = pd.concat([df, dummy_df], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_all = df_new.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop features not helpful\nX_all = X_all.drop(['sig_id', 'cp_type', 'cp_dose'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Scaling Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalization of data\nscaling = MinMaxScaler()\nX_all_sc = scaling.fit_transform(X_all)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dimensionality Reduction"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Take number of autoencoder features from number of components which explain 70% of variance with PCA \npca = PCA(0.70, random_state=0)\npca_X_all_sc = pca.fit_transform(X_all_sc)\npca.n_components_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# single fully-connected neural layer as encoder and as decoder\n# This is the size of encoded representations\nencoding_dim = pca.n_components_  \n\n# This is input \ninput_data = Input(shape=(875,)) # number of features/columns\n# \"encoded\" is the encoded representation of the input\nencoded = Dense(encoding_dim, activation='relu')(input_data)\n# \"decoded\" is the lossy reconstruction of the input\ndecoded = Dense(875, activation='relu')(encoded)\n\n# This model maps an input to its reconstruction\nautoencoder = Model(input_data, decoded)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create a separate encoder model:\n# This model maps an input to its encoded representation\nencoder = Model(input_data, encoded)\n# create a separate decoder model:\n# This is encoded input\nencoded_input = Input(shape=(encoding_dim,))\n# Retrieve the last layer of the autoencoder model\ndecoder_layer = autoencoder.layers[-1]\n# Create the decoder model\ndecoder = Model(encoded_input, decoder_layer(encoded_input))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Configure the model\nautoencoder.compile(optimizer='adam', loss='mean_squared_error')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train the model\nnp.random.seed(0)\nautoencoder.fit(X_all_sc,\n                X_all_sc,\n                epochs=50,\n                shuffle=True)\n\nautoencoder.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict after training\nencoded_input = encoder.predict(X_all_sc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# New data set\nautoencoder_df = pd.DataFrame(data = encoded_input, columns=['autoencoder'+str(i) for i in range(pca_X_all_sc.shape[1])])\nautoencoder_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# t-SNE for Visualizing Dimensionality reduction Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"tsne_df = TSNE(n_components=2, random_state=0).fit_transform(autoencoder_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tsne_data = pd.DataFrame(tsne_df, columns=['x', 'y'], index=autoencoder_df.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dff = pd.concat([targets_df['5-alpha_reductase_inhibitor'], tsne_data], axis=1)\n\n# Show the diagram\nfig, ax = plt.subplots(figsize=(10, 10))\n\nwith sns.plotting_context(\"notebook\", font_scale=1.0):\n     sns.scatterplot(x='x',\n                        y='y',\n                        hue='5-alpha_reductase_inhibitor',\n                        palette=sns.color_palette(\"husl\", 2),\n                        data=dff,\n                        ax=ax)\n\nax.set_xlabel(r'$x$')\nax.set_ylabel(r'$y$')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dff = pd.concat([targets_df['antiprotozoal'], tsne_data], axis=1)\n\n# Show the diagram\nfig, ax = plt.subplots(figsize=(10, 10))\n\nwith sns.plotting_context(\"notebook\", font_scale=1.0):\n     sns.scatterplot(x='x',\n                        y='y',\n                        hue='antiprotozoal',\n                        palette=sns.color_palette(\"Set2\", 2),\n                        data=dff,\n                        ax=ax)\n\nax.set_xlabel(r'$x$')\nax.set_ylabel(r'$y$')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dff = pd.concat([targets_df['adenylyl_cyclase_activator'], tsne_data], axis=1)\n\n# Show the diagram\nfig, ax = plt.subplots(figsize=(10, 10))\n\nwith sns.plotting_context(\"notebook\", font_scale=1.0):\n     sns.scatterplot(x='x',\n                        y='y',\n                        hue='adenylyl_cyclase_activator',\n                        palette=sns.color_palette(\"Set1\", 2),\n                        data=dff,\n                        ax=ax)\n\nax.set_xlabel(r'$x$')\nax.set_ylabel(r'$y$')\n\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}