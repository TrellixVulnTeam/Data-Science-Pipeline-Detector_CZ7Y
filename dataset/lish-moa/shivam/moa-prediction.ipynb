{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Mechanisms of Action (MoA) Prediction.(EDA)\nIn this competition, we are suposed to develop algorithms and train models **to determine the mechanism of action of a new drug based on the gene expression and cell viability information**. In this EDA, we will try to find patterns in the data, interactions between the drugs in both scored and nonscored datasets and the relationship between drugs and their target genes."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom IPython.display import display\nimport random\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport matplotlib.pyplot as plt\nimport time\n# for visualizing\n\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nimport seaborn as sns\nimport plotly.express as px\n\n# for adding extra statistical stuff\n\nfrom scipy.stats import skew, norm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading and Exploring the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_feat = pd.read_csv('../input/lish-moa/train_features.csv')\ntrain_target = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\n\ntest_feat = pd.read_csv('../input/lish-moa/test_features.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Train Feature Samples:')\ntrain_feat.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Test Feature Samples:')\ntest_feat.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of rows in training set: ', train_feat.shape[0])\nprint('Number of columns in training set: ', train_feat.shape[1])\nprint('Number of rows in test set: ', test_feat.shape[0])\nprint('Number of columns in test set: ', test_feat.shape[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_miss=train_feat.isnull().sum().sum()\ntest_miss=train_feat.isnull().sum().sum()\nprint('Number of Null values in training set: ',train_miss)\nprint('Number of Null values in training set: ',train_miss)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_feat.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature data analysis"},{"metadata":{},"cell_type":"markdown","source":"1. check whether train and test feature data are balanced?"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.style.use('ggplot')\n\nfig = plt.figure(constrained_layout=True, figsize=(20, 12))\n\n\ngrid = gridspec.GridSpec(ncols=6, nrows=3, figure=fig)\n\nax1 = fig.add_subplot(grid[0, :3])\n\nax1.set_title(f'Train cp_type Distribution',weight='bold')\n\nsns.countplot(x='cp_type',\n                    data=train_feat,\n                    palette=\"rocket\",\n                    ax=ax1,\n                    order=train_feat['cp_type'].value_counts().index)\n\ntotal = float(len(train_feat['cp_type']))\n\n\nfor p in ax1.patches:\n    height = p.get_height()\n    ax1.text(p.get_x() + p.get_width() / 2.,\n            height + 2,\n            '{:1.2f}%'.format((height / total) * 100),\n            ha='center')\n\n\nax2 = fig.add_subplot(grid[0, 3:])\n\n\n\nsns.countplot(x='cp_type',\n                    data=test_feat,\n                    palette=\"rocket\",\n                    ax=ax2,\n                    order=test_feat['cp_type'].value_counts().index)\n\ntotal = float(len(test_feat['cp_type']))\n\nax2.set_title(f'Test cp_type Distribution', weight='bold')\n\n\nfor p in ax2.patches:\n    height = p.get_height()\n    ax2.text(p.get_x() + p.get_width() / 2.,\n            height + 2,\n            '{:1.2f}%'.format((height / total) * 100),\n            ha='center')\nax3 = fig.add_subplot(grid[1, :3])\n\nax3.set_title(f'Train cp_time Distribution', weight='bold')\n\nsns.countplot(x='cp_time',\n                    data=train_feat,\n                    palette=\"rocket\",\n                    ax=ax3,\n                    order=train_feat['cp_time'].value_counts().index)\n\ntotal = float(len(train_feat['cp_time']))\n\n\nfor p in ax3.patches:\n    height = p.get_height()\n    ax3.text(p.get_x() + p.get_width() / 2.,\n            height + 2,\n            '{:1.2f}%'.format((height / total) * 100),\n            ha='center')\n\nax4 = fig.add_subplot(grid[1, 3:])\n\nax4.set_title(f'Test cp_time Distribution', weight='bold')\n\nsns.countplot(x='cp_time',\n                    data=test_feat,\n                    palette=\"rocket\",\n                    ax=ax4,\n                    order=train_feat['cp_time'].value_counts().index)\n\ntotal = float(len(test_feat['cp_time']))\n\n\nfor p in ax4.patches:\n    height = p.get_height()\n    ax4.text(p.get_x() + p.get_width() / 2.,\n            height + 2,\n            '{:1.2f}%'.format((height / total) * 100),\n            ha='center')\n    \nax5 = fig.add_subplot(grid[2, :3])\n\nax5.set_title(f'Train cp_dose Distribution', weight='bold')\n\nsns.countplot(x='cp_dose',\n                    data=train_feat,\n                    palette=\"rocket\",\n                    ax=ax5,\n                    order=train_feat['cp_dose'].value_counts().index)\n\ntotal = float(len(train_feat['cp_dose']))\n\n\nfor p in ax5.patches:\n    height = p.get_height()\n    ax5.text(p.get_x() + p.get_width() / 2.,\n            height + 2,\n            '{:1.2f}%'.format((height / total) * 100),\n            ha='center')\n\nax6 = fig.add_subplot(grid[2, 3:])\n\nax6.set_title(f'Test cp_dose Distribution', weight='bold')\n\nsns.countplot(x='cp_dose',\n                    data=test_feat,\n                    palette=\"rocket\",\n                    ax=ax6,\n                    order=train_feat['cp_dose'].value_counts().index)\n\ntotal = float(len(test_feat['cp_dose']))\n\n\nfor p in ax6.patches:\n    height = p.get_height()\n    ax6.text(p.get_x() + p.get_width() / 2.,\n            height + 2,\n            '{:1.2f}%'.format((height / total) * 100),\n            ha='center')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def plot_distplot(f1):\n    plt.style.use('seaborn')\n    sns.set_style('whitegrid')\n\n    fig= plt.figure(figsize=(20,20))\n    #2 rows 2 cols\n    #first row, first col\n    for i in range(0,12):\n        ax1 = plt.subplot2grid((5,4),((i // 3) + 1, (i % 3) + 1))\n        sns.distplot(train_feat[f1])\n        plt.title(f1[i],weight='bold', fontsize=12)\n        plt.yticks(weight='bold')\n        plt.xticks(weight='bold')\n    return plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"train_columns = train_feat.columns.to_list()\ng_list = [i for i in train_columns if i.startswith('g-')]\nc_list = [i for i in train_columns if i.startswith('c-')]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. **Cell Analysis**"},{"metadata":{"trusted":true},"cell_type":"code","source":"c_plot= [c_list[random.randint(0, len(c_list)-1)] for i in range(50)]\nplot_distplot(c_plot[:12])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cells=train_feat[c_list]\n#Plot heatmap\nplt.figure(figsize=(25,12))\nsns.heatmap(cells.corr(), cmap='coolwarm', alpha=0.9)\nplt.title('Correlation: Cell', fontsize=15, weight='bold')\nplt.xticks(weight='bold')\nplt.yticks(weight='bold')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correlations = cells.corr().abs().unstack().sort_values(kind=\"quicksort\",ascending=False).reset_index()\ncorrelations = correlations[correlations['level_0'] != correlations['level_1']] #preventing 1.0 corr\ncorr_max=correlations.level_0.head(150).tolist()\ncorr_max=list(set(corr_max)) #removing duplicates\n\ncorr_min=correlations.level_0.tail(50).tolist()\ncorr_min=list(set(corr_min)) #removing duplicates","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correlations.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correlations.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3. **Gean Analysis**"},{"metadata":{"trusted":true},"cell_type":"code","source":"g_plot= [g_list[random.randint(0, len(g_list)-1)] for i in range(50)]\nplot_distplot(g_plot[:12])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"geans=train_feat[g_list]\n#Plot heatmap\nplt.figure(figsize=(25,12))\nsns.heatmap(geans.corr(), cmap='coolwarm', alpha=0.9)\nplt.title('Correlation: Cell', fontsize=15, weight='bold')\nplt.xticks(weight='bold')\nplt.yticks(weight='bold')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correlations = geans.corr().abs().unstack().sort_values(kind=\"quicksort\",ascending=False).reset_index()\ncorrelations = correlations[correlations['level_0'] != correlations['level_1']] #preventing 1.0 corr\ncorr_max=correlations.level_0.head(150).tolist()\ncorr_max=list(set(corr_max)) #removing duplicates\n\ncorr_min=correlations.level_0.tail(50).tolist()\ncorr_min=list(set(corr_min)) #removing duplicates","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correlations.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correlations.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Target Analysis**"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Train Target Samples:')\ndisplay(train_target.head(3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_target.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = train_target.drop(['sig_id'], axis=1).sum(axis=0).sort_values().reset_index()\nx.columns = ['column', 'nonzero_records']\n\nfig = px.bar(\n    x.tail(50), \n    x='nonzero_records', \n    y='column',\n    title='Columns with the higher number of positive samples (top 50)', \n    height=1000, \n    width=800,\n    color='nonzero_records'\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.bar(\n    x.head(50), \n    x='nonzero_records', \n    y='column', \n    title='Columns with the lowest number of positive samples (top 50)', \n    height=1000, \n    width=800,\n    color='nonzero_records'\n)\n\nfig.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}