{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"seed_value= 0\n\nimport os\nos.environ['PYTHONHASHSEED']=str(seed_value)\n\nimport random\nrandom.seed(seed_value)\n\nimport numpy as np\nnp.random.seed(seed_value)\n\nimport tensorflow as tf\ntf.random.set_seed(seed_value)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features = pd.read_csv('../input/lish-moa/train_features.csv')\nX_train = train_features.drop('sig_id', axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_targets_scored = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\nY_train = train_targets_scored.drop('sig_id', axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combine = pd.concat([X_train, Y_train], axis=1, sort=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_col = Y_train.columns[1]\ncombine.loc[Y_train[Y_train[y_col]==1].index]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_zero = True\nfor yc in Y_train.columns:\n    temp = (Y_train[yc] == 0)\n    if type(all_zero) is bool :\n        all_zero = temp\n    else:\n        all_zero = all_zero & temp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_wraggled = X_train[X_train['cp_type'] != 'ctl_vehicle'][X_train.columns[3:]]\nY_train_wraggled = Y_train.loc[X_train_wraggled.index]\nX_train_wraggled_g = X_train_wraggled[X_train_wraggled.columns[pd.Series(X_train_wraggled.columns).str.startswith('g')]] \n\nX_train_wraggled_c = X_train_wraggled[X_train_wraggled.columns[pd.Series(X_train_wraggled.columns).str.startswith('c')]] \nprint(X_train_wraggled.shape[1])\nprint(X_train_wraggled_g.shape[1])\nprint(X_train_wraggled_c.shape[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fully connect\nfrom numpy import loadtxt\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation\nfrom keras.callbacks import ModelCheckpoint,EarlyStopping\nfrom keras.layers import Input, Concatenate, concatenate, BatchNormalization\nfrom keras.models import Model\nfrom keras.layers import Dense, Conv1D, GlobalMaxPooling1D\nfrom keras.layers import LSTM\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom keras.callbacks import TensorBoard\nfrom tensorflow_addons.layers import WeightNormalization\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.losses import BinaryCrossentropy\nfrom keras.models import load_model\nimport keras\n\nfrom keras import backend as K\n\ndef recall_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    recall = true_positives / (possible_positives + K.epsilon())\n    return recall\n\ndef precision_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives + K.epsilon())\n    return precision\n\ndef f1_m(y_true, y_pred):\n    precision = precision_m(y_true, y_pred)\n    recall = recall_m(y_true, y_pred)\n    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n              \n\nmodel_name = \"conv\"\nmodel_name = \"parallel_conv\"\n# model_name = 'g_conv'\n# model_name = 'c_lstm'\n#Load pretrained model\nfrom keras.models import load_model\n\nimport tensorflow as tf\n\ndef f1(y_true, y_pred):\n    y_pred = K.round(y_pred)\n    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n\n    p = tp / (tp + fp + K.epsilon())\n    r = tp / (tp + fn + K.epsilon())\n\n    f1 = 2*p*r / (p+r+K.epsilon())\n    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n    return K.mean(f1)\n\ndef f1_loss(y_true, y_pred):\n    \n    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n\n    p = tp / (tp + fp + K.epsilon())\n    r = tp / (tp + fn + K.epsilon())\n\n    f1 = 2*p*r / (p+r+K.epsilon())\n    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n    return 1 - K.mean(f1)\n\n\nclass_weight = {0: 0.01,\n                1: 1}\n#Create model function\ndef getModel(model_name):\n    if model_name == 'pretrained':\n        model = load_model('../input/moa-lstm/best_weights (1).hdf5')\n        toBeCompiled = False\n        \n    elif model_name == 'parallel_conv':\n        InputLayer_g = Input(shape=(X_train_wraggled_g.shape[1], 1))\n        InputLayer_c = Input(shape=(X_train_wraggled_c.shape[1], 1))\n        \n        \n        ConvLayer_g = Conv1D(filters=200,\n                           kernel_size=20,\n                           padding='valid',\n                           activation='relu',\n                           strides=1)(InputLayer_g)\n        PoolingLayer_g = BatchNormalization()(ConvLayer_g)\n        PoolingLayer_g = GlobalMaxPooling1D()(ConvLayer_g)\n        PoolingLayer_g = BatchNormalization()(PoolingLayer_g)\n        PoolingLayer_g = Dropout(0.4)(PoolingLayer_g)\n        \n        ConvLayer_c = Conv1D(filters=200,\n                           kernel_size=20,\n                           padding='valid',\n                           activation='relu',\n                           strides=1)(InputLayer_c)\n        PoolingLayer_c = BatchNormalization()(ConvLayer_c)\n        PoolingLayer_c = GlobalMaxPooling1D()(ConvLayer_c)\n        PoolingLayer_c = BatchNormalization()(PoolingLayer_c)\n        PoolingLayer_c = Dropout(0.4)(PoolingLayer_c)\n        \n        merged = concatenate([PoolingLayer_g, PoolingLayer_c], axis=1)\n        merged = BatchNormalization()(merged)\n        merged = Dropout(0.2)(merged)\n        merged = WeightNormalization(Dense(300, activation='relu'))(merged)\n        merged = BatchNormalization()(merged)\n        merged = Dropout(0.4)(merged)\n        #OutputLayer = WeightNormalization(Dense(206, activation='sigmoid'))(merged)\n        OutputLayer = WeightNormalization(Dense(1, activation='sigmoid', kernel_regularizer=regularizers.l2(0.001)))(merged)\n        model = Model(inputs=[InputLayer_g,InputLayer_c], outputs=OutputLayer)\n        toBeCompiled = True\n        \n    return toBeCompiled,model\n\ndef fit1Label(col):\n    #class_weight = calculating_class_weights(Y_train_wraggled[[col]].iloc[0:int(len(X_train_wraggled)*0.75)].values)\n    class_weight = {\n        0:1,\n        1:1.2\n    }\n    bi_loss = BinaryCrossentropy(\n        from_logits=False,\n        label_smoothing=0, \n        reduction=\"auto\", \n        name=\"binary_crossentropy\")\n    METRICS = [\n        'accuracy',\n        \"binary_crossentropy\",\n        f1_m,\n        keras.metrics.TruePositives(name='tp'),\n        keras.metrics.FalsePositives(name='fp'),\n        keras.metrics.TrueNegatives(name='tn'),\n        keras.metrics.FalseNegatives(name='fn'), \n        keras.metrics.Precision(name='precision'),\n        keras.metrics.Recall(name='recall'),\n        keras.metrics.AUC(name='auc'),\n    ]\n\n    #Set Checkpoint\n    filepath=f\"{col}.hdf5\"\n    if filepath in os.listdir():\n        print(f\"skip {filepath}\")\n        return False\n    checkpoint = ModelCheckpoint(filepath, monitor=\"val_binary_crossentropy\", verbose=1, save_best_only=True, mode='min')\n    # checkpoint = ModelCheckpoint(filepath, monitor=\"val_tp\", verbose=1, save_best_only=True, mode='max')\n    early_stop =EarlyStopping(monitor=\"val_tp\", mode = 'min', patience=15)\n    toBeCompiled,model = getModel(model_name)\n\n    model.compile(loss=bi_loss,\n                  optimizer='adam',\n                  metrics=METRICS)\n    \n    \n    model.fit([\n                X_train_wraggled_g.iloc[0:int(len(X_train_wraggled_g)*0.75)].values,\n                X_train_wraggled_c.iloc[0:int(len(X_train_wraggled_c)*0.75)].values\n                ],\n              Y_train_wraggled[[col]].iloc[0:int(len(X_train_wraggled)*0.75)].values.astype('float'),\n              epochs=600,\n              validation_data=(\n                      [\n                        X_train_wraggled_g.iloc[int(len(X_train_wraggled_g)*0.75):].values,\n                        X_train_wraggled_c.iloc[int(len(X_train_wraggled_c)*0.75):].values\n                    ],\n                      Y_train_wraggled[[col]].iloc[int(len(X_train_wraggled)*0.75):].values\n                  ),\n              #batch_size=1000,\n                shuffle=True,\n        #([[ 0.50441258, 57.15625   ]])\n                class_weight=class_weight,\n              callbacks = [checkpoint,early_stop]\n             )\n    del model\n    \ndef evaluate_models(col):\n    model = load_model(f'../input/pretrainmodel/{col}.hdf5', custom_objects={'f1_m':f1_m})\n    res = model.evaluate([\n                            X_train_wraggled_g.iloc[int(len(X_train_wraggled)*0.75):],\n                            X_train_wraggled_c.iloc[int(len(X_train_wraggled)*0.75):]\n                        ], \n                         Y_train_wraggled.iloc[int(len(X_train_wraggled)*0.75):][[col]])\n    print(f'Model {col}: Binary cross: {res[2]}')\n    return res\n\n#import data\n\ndef col_prediction(col):\n    model = load_model(f'../input/pretrainmodel/{col}.hdf5', custom_objects={'f1_m':f1_m})\n    res = model([\n                    X_test_wraggled_g.values,\n                    X_test_wraggled_c.values\n                ])\n    return np.array(res).flatten()\n\ntest_features = pd.read_csv('../input/lish-moa/test_features.csv')\n\nX_test = test_features\n\nX_test_wraggled = X_test[X_test.columns[4:]]\n\nX_test_wraggled_g = X_test_wraggled[X_test_wraggled.columns[pd.Series(X_test_wraggled.columns).str.startswith('g')]] \n\nX_test_wraggled_c = X_test_wraggled[X_test_wraggled.columns[pd.Series(X_test_wraggled.columns).str.startswith('c')]] \n\npredicts = X_test[['sig_id']]\n\nfor count,col in enumerate(Y_train_wraggled):\n    print('='*36)\n    print(col)\n    predict = col_prediction(col)\n    predicts[col] = predict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicts.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicts.shape","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}