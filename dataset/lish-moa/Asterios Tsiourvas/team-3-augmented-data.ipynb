{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Team 3\n\n\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n#TF stuff\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import regularizers\n\n#XGBoost\nfrom xgboost import XGBClassifier\n\n#Scikit\nfrom sklearn.metrics import log_loss\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom sklearn.model_selection import KFold\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import uniform","metadata":{"id":"GqVmnNeQHO9V","execution":{"iopub.status.busy":"2021-08-06T09:29:59.203924Z","iopub.execute_input":"2021-08-06T09:29:59.204462Z","iopub.status.idle":"2021-08-06T09:30:05.608872Z","shell.execute_reply.started":"2021-08-06T09:29:59.204363Z","shell.execute_reply":"2021-08-06T09:30:05.60751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Read in the data**\n\nTwo key files here: train_feature.csv (these is roughly your 'X'), and train_targets.csv (which is your 'y'). More information on these can be found on the original competetion site: https://www.kaggle.com/c/lish-moa/data ","metadata":{"id":"DLtGTdkrnohv"}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"train_features = pd.read_csv('/kaggle/input/lish-moa/train_features.csv')\ntrain_targets = pd.read_csv('/kaggle/input/lish-moa/train_targets_scored.csv')\nprint(train_features.head())\nprint(train_targets.head())\nprint(train_features.shape)\nprint(train_targets.shape)","metadata":{"id":"Br8LxVtVGhw2","outputId":"0dd40ed0-555a-4dde-90e6-169f1dff6d2d","execution":{"iopub.status.busy":"2021-08-05T20:46:30.179886Z","iopub.execute_input":"2021-08-05T20:46:30.180451Z","iopub.status.idle":"2021-08-05T20:46:36.496203Z","shell.execute_reply.started":"2021-08-05T20:46:30.180407Z","shell.execute_reply":"2021-08-05T20:46:36.494971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Some simple encoding:** Two of our features 'cp_type' and 'cp_dose' are categorical. We will encode these numerically with a simple one-hot encoding. The pandas get_dummies function is a quick way of doing this. ","metadata":{"id":"Un2WIe2AojuR"}},{"cell_type":"code","source":"train_features_enc = pd.get_dummies(train_features, columns=['cp_type', 'cp_dose'], drop_first=True)\nprint(train_features_enc.head())","metadata":{"id":"V3gNm4Bka0XG","outputId":"0a2e320b-8e6c-47a8-b774-559277a47b28","execution":{"iopub.status.busy":"2021-08-05T20:46:36.498579Z","iopub.execute_input":"2021-08-05T20:46:36.499169Z","iopub.status.idle":"2021-08-05T20:46:36.680724Z","shell.execute_reply.started":"2021-08-05T20:46:36.499115Z","shell.execute_reply":"2021-08-05T20:46:36.679544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We're now all good to go with respect to defining our 'X' and 'y'; all we drop below is the sig_id column which is simply there to align the features and targets dataframes.","metadata":{"id":"VEHLfap6o0as"}},{"cell_type":"code","source":"X = train_features_enc.iloc[:,1:].to_numpy()\ny = train_targets.iloc[:,1:].to_numpy() ","metadata":{"id":"U0UKfsbPb2Gt","execution":{"iopub.status.busy":"2021-08-05T20:46:36.682429Z","iopub.execute_input":"2021-08-05T20:46:36.682835Z","iopub.status.idle":"2021-08-05T20:46:36.832348Z","shell.execute_reply.started":"2021-08-05T20:46:36.68279Z","shell.execute_reply":"2021-08-05T20:46:36.831354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Neural Network Models**\n\nWe now transition to building NN mnodels. Such models have shown a great deal of promise w/ tabular data recently, and we will walk through a squence of increasingly complex models here. We start with the simplest possible NN -- logistic regression! Its worth noting that in the model below we regularize the parameters of the network (something we will drop later on). Another intersting point worth noting is that the model below optimizes the loss jointly over all the 206 components of $y$ as opposed to optimizing each individually. \n\nAnother point of note is that we find these sorts of models far easier to customize and optimize over that the pre-packaged scikit models. ","metadata":{"id":"EyI8_9oKeL6L"}},{"cell_type":"code","source":"# A convenient plotting function as we train models\ndef plot_hist(hist, last = None):\n    if last == None:\n        last = len(hist.history[\"loss\"])\n    plt.plot(hist.history[\"loss\"][-last:])\n    plt.plot(hist.history[\"val_loss\"][-last:])\n    plt.title(\"model accuracy\")\n    plt.ylabel(\"accuracy\")\n    plt.xlabel(\"epoch\")\n    plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-05T20:46:36.8335Z","iopub.execute_input":"2021-08-05T20:46:36.833778Z","iopub.status.idle":"2021-08-05T20:46:36.840709Z","shell.execute_reply.started":"2021-08-05T20:46:36.833751Z","shell.execute_reply":"2021-08-05T20:46:36.839683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Residual Connections**\n\nOur final effort changes the architecture from being a simple feed forward network to adding resdiula connections. This can be viewed as a 'rollout' of the optimization that a boosting method might use. Specifically, consider builing a 'simple' model with a single hidden layer and then fitting another single model to the residual, and then another to the residual of the cobined models, and so forth.. Below, we do this three times. \n\nThis model dramatically improves on XGBoost. Our loss stands at 0.0156! \n\n","metadata":{"id":"XIbcqaItos2B"}},{"cell_type":"code","source":"#0.0156\ndef l3_res_model(input_shape, no_classes, lr):\n    inputs = tf.keras.Input(shape=input_shape)\n    x = layers.Dense(128, activation='relu')(inputs)\n    x = layers.BatchNormalization()(x)\n    b_1 = layers.Dropout(0.2)(x)\n    x = layers.Dense(128, activation='relu')(b_1)\n    x = layers.BatchNormalization()(x)\n    b_2 = layers.Dropout(0.2)(x)\n    x = layers.Dense(128, activation='relu')(b_2)\n    x = layers.BatchNormalization()(x)\n    b_3 = layers.Dropout(0.2)(x)\n    tot_op = tf.keras.layers.add([b_1, b_2, b_3])\n    outputs = layers.Dense(no_classes, activation='sigmoid')(tot_op)\n    model = tf.keras.Model(inputs, outputs)\n    model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate = lr), metrics=['binary_crossentropy'])\n    return model\n\n\ntf.random.set_seed(1010)\nnp.random.seed(1010)\n\nX_train = X\ny_train = y\n\ncontrol_vehicle_mask = X_train[:,-2] == 0\nX_train = X_train[~control_vehicle_mask,:]\ny_train = y_train[~control_vehicle_mask]\n\nnnclf = l3_res_model((875,),206,0.0005)\nhist = nnclf.fit(X_train, y_train, batch_size=512, epochs=45, verbose=1)","metadata":{"id":"NMYHj-hI2Q-j","outputId":"411cc0f0-eee5-4b33-cfff-4cdb5ce0e37e","scrolled":true,"execution":{"iopub.status.busy":"2021-08-05T20:52:47.316119Z","iopub.execute_input":"2021-08-05T20:52:47.316497Z","iopub.status.idle":"2021-08-05T20:53:23.405765Z","shell.execute_reply.started":"2021-08-05T20:52:47.316467Z","shell.execute_reply":"2021-08-05T20:53:23.404896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_features = pd.read_csv('/kaggle/input/lish-moa/test_features.csv')\nsubmission_data = pd.read_csv('/kaggle/input/lish-moa/sample_submission.csv')\n\nX_test_final = pd.get_dummies(test_features, columns=['cp_type', 'cp_dose'], drop_first=True).iloc[:,1:].to_numpy()\n\npredictions = pd.DataFrame(nnclf.predict(X_test_final), columns = submission_data.columns[1:])\n\npredictions.insert(0, submission_data.columns[0], test_features[submission_data.columns[0]])\n\n# Save final output\npredictions.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-05T20:54:18.26715Z","iopub.execute_input":"2021-08-05T20:54:18.267547Z","iopub.status.idle":"2021-08-05T20:54:20.523922Z","shell.execute_reply.started":"2021-08-05T20:54:18.267515Z","shell.execute_reply":"2021-08-05T20:54:20.523164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}