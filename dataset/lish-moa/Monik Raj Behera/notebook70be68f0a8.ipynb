{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nimport seaborn as sns\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x = pd.read_csv(\"/kaggle/input/lish-moa/train_features.csv\")\ntrain_y = pd.read_csv(\"/kaggle/input/lish-moa/train_targets_scored.csv\")\ntest_x = pd.read_csv(\"/kaggle/input/lish-moa/test_features.csv\")\nheaders_y = train_y.columns.to_list()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_x.columns.to_series().groupby(train_x.dtypes).groups)\nprint(\"\\n\")\nprint(train_y.columns.to_series().groupby(train_y.dtypes).groups)\nprint(\"\\n\")\nprint(test_x.columns.to_series().groupby(test_x.dtypes).groups)\nprint(\"\\n\\n\")\nprint(train_x[\"cp_type\"].unique())\nprint(\"\\n\")\nprint(train_x[\"cp_dose\"].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cp_type_ohe_train = pd.get_dummies(train_x[\"cp_type\"], prefix=\"cp_type\", dtype=float)\ncp_dose_ohe_train = pd.get_dummies(train_x[\"cp_dose\"], prefix=\"cp_dose\", dtype=float)\ncp_type_ohe_test = pd.get_dummies(test_x[\"cp_type\"], prefix=\"cp_type\", dtype=float)\ncp_dose_ohe_test = pd.get_dummies(test_x[\"cp_dose\"], prefix=\"cp_dose\", dtype=float)\ntrain_x = pd.concat([train_x, cp_type_ohe_train, cp_dose_ohe_train], axis=1, sort=False)\ndel train_x[\"cp_type\"]\ndel train_x[\"cp_dose\"]\ntest_x = pd.concat([test_x, cp_type_ohe_test, cp_dose_ohe_test], axis=1, sort=False)\ndel test_x[\"cp_type\"]\ndel test_x[\"cp_dose\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# corr = train_x.corr()\n# sns.heatmap(corr, \n#             xticklabels=corr.columns.values,\n#             yticklabels=corr.columns.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x_np = train_x.copy()\ntrain_y_np = train_y.copy()\ntest_x_np = test_x.copy()\ndel train_x_np[\"sig_id\"]\ndel train_y_np[\"sig_id\"]\ndel test_x_np[\"sig_id\"]\ntrain_x_np = train_x_np.to_numpy()\ntrain_x_np = np.asarray(train_x_np).astype('float32')\ntrain_y_np = train_y_np.to_numpy()\ntrain_y_np = np.asarray(train_y_np).astype('int32')\ntest_x_np = test_x_np.to_numpy()\ntest_x_np = np.asarray(test_x_np).astype('float32')\ntrain_x_np = MinMaxScaler(feature_range=(0, 1)).fit_transform(train_x_np)\ntrain_y_np = MinMaxScaler(feature_range=(0, 1)).fit_transform(train_y_np)\ntest_x_np = MinMaxScaler(feature_range=(0, 1)).fit_transform(test_x_np)\n\nf = np.argmax(train_y_np, axis=1)\nc = np.where(f == 0)[0]\nd = np.random.choice(c, size=9034, replace=False)\ns = train_y_np.copy()\ntrain_y_np = np.delete(s, d, axis=0)\nr = train_x_np.copy()\ntrain_x_np = np.delete(r, d, axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(\"Looking at distribution\")\n# print(np.histogram(np.argmax(train_y_np, axis=1), bins=206))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.models.Sequential()\nmodel.add(\n    tf.keras.layers.Input((train_x_np.shape[1],))\n)\nmodel.add(\n    tf.keras.layers.Dense(units=train_x_np.shape[1], activation=\"relu\")\n)\nmodel.add(\n    tf.keras.layers.Dense(units=512, activation=\"relu\")\n)\nmodel.add(\n    tf.keras.layers.Dropout(0.5)\n)\nmodel.add(\n    tf.keras.layers.Dense(units=1024, activation=\"relu\")\n)\nmodel.add(\n    tf.keras.layers.Dropout(0.5)\n)\nmodel.add(\n    tf.keras.layers.Dense(units=512, activation=\"relu\")\n)\nmodel.add(\n    tf.keras.layers.Dropout(0.5)\n)\nmodel.add(\n    tf.keras.layers.Dense(units=train_y_np.shape[1], activation=\"softmax\")\n)\n\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, Y_train ,Y_test = train_test_split(train_x_np, train_y_np, test_size=0.2, random_state=56)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train, Y_train, epochs=20)\nmodel.evaluate(X_test, Y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_hat = model.predict(test_x_np)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_hat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_x[\"sig_id\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_x_np.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t = np.amax(Y_hat, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = np.full((3982,206), 0.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for x in range(0, len(result)):\n    u = np.where((Y_hat[x] == t[x]) == True)[0][0]\n    result[x][u] = 1.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame(data=result, columns=headers_y[1:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"sig_id\"] = test_x[\"sig_id\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}