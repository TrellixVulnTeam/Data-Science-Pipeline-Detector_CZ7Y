{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import KFold \nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import log_loss\nimport seaborn as sns\nfrom pandas_profiling import ProfileReport","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample = pd.read_csv(\"../input/lish-moa/sample_submission.csv\")\n\ntest_f = pd.read_csv('../input/lish-moa/test_features.csv')\ntrain_f = pd.read_csv('../input/lish-moa/train_features.csv')\ndrug = pd.read_csv('../input/lish-moa/train_drug.csv')\ntarg_nscore = pd.read_csv('../input/lish-moa/train_targets_nonscored.csv')\ntarg_score = pd.read_csv('../input/lish-moa/train_targets_scored.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train_f.merge(targ_score,on = 'sig_id',how = 'left')\ntrain = train.merge(targ_nscore,on = 'sig_id',how = 'left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"stargs_name = list(targ_score.columns[1:])\nscored_targets = train[list(targ_score.columns[1:])].sum(axis = 1)\nnscored_targets = train[list(targ_nscore.columns[1:])].sum(axis = 1)\n\nfig,axes = plt.subplots(figsize = (32,8),ncols = 2)\nsns.countplot(scored_targets,ax = axes[0])\nsns.countplot(nscored_targets,ax = axes[1])\n# scored_targets\n\nfor i in range(2):\n    axes[i].tick_params(axis = 'x',labelsize =20)\n    axes[i].tick_params(axis = 'y', labelsize = 20)\n\naxes[0].set_title(f'Training set unique scored per sample',size = 22 , pad = 22)  \naxes[1].set_title(f'Training set unique not scored per sample',size = 22 , pad = 22)   \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(figsize = (24,24),nrows = 3, ncols = 2)\n\nsns.countplot(train_f['cp_type'],ax = axes[0][0])\nsns.countplot(test_f['cp_type'],ax = axes[0][1])\n\nsns.countplot(train_f['cp_time'],ax = axes[1][0])\nsns.countplot(test_f['cp_time'],ax = axes[1][1])\n\nsns.countplot(train_f['cp_dose'],ax = axes[2][0])\nsns.countplot(test_f['cp_dose'],ax = axes[2][1])\n\nfor i, f in enumerate(['cp_type','cp_time','cp_dose']):\n    for j , d in enumerate(['training','test']):\n        axes[i][j].set_title(f'{d} Set {f} Distribution',size = 20,pad = 15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Inhibitors are molecules that binds an enzyme and decreases its activity \n\n## Agonist are chemicals that binds a receptor and activates the receptor to produce biological response.\n\n## Antagonist block the action of agonist "},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train_f) - len(test_f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_f.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_f.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_f.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(targ_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"drug.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **train_features.csv** - \n  ### Features for the training set. \n  \n  Features **g-** signify **gene expression** data, and **c-** signify **cell viability** data.\n  \n  **cp_type** indicates samples treated with a compound *(cp_vehicle)* or with a control perturbation *(ctrl_vehicle)*; control perturbations have no MoAs; \n    \n  **cp_time and cp_dose** indicate treatment *duration* (24, 48, 72 hours) and *dose *(high or low)."},{"metadata":{},"cell_type":"markdown","source":"## Gene Expression - \n\nGene expression is the process by which information from a gene is used in the synthesis of a functional gene product. These products are often proteins, but in non-protein-coding genes such as transfer RNA or small nuclear RNA genes, the product is a functional RNA.\n\n## Cell viability -\n\nCell viability assays use a variety of markers as indicators of metabolically active (living) cells"},{"metadata":{},"cell_type":"markdown","source":"## Encode cp_type and cp_dose"},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(df):\n    df = df.copy() \n    # df.loc[:,'something'] = in df locate all(:) rows and take col with 'something' key\n    df.loc[:,'cp_type'] = df.loc[:,'cp_type'].map({'trt_cp':0,'ctl_vehicle':1})\n    df.loc[:,'cp_dose'] = df.loc[:,'cp_dose'].map({'D1':0,'D2':1})\n    del df['sig_id']\n    return df\n\ntrain = preprocess(train_f)\ntest = preprocess(test_f)\ndel targ_score['sig_id']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### for trp_cp - Dose 1 \n### for ctl_vehicle - Dose 2\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"targ_score.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def metric(y_true,y_pred):\n    metrics = []\n    metrics.append(log_loss(y_true,y_pred.astype(float),labels = [0,1])) #loss algortithm\n    return np.mean(metrics)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_f.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = targ_score.columns\nsubmission = sample.copy()\nsubmission.loc[:,cols] = 0\nsubmission\n\n\nN_splits = 5\noff_loss = 0\nfor c, columns in enumerate(cols,1):\n    y = targ_score[columns]\n    total_loss = 0\n    \n    for fn,(trn_idx,val_idx) in enumerate(KFold(n_splits = N_splits, shuffle = True).split(train)):\n    # trn_idx , val_idx are the shuffled indexes for train and validation  \n        print('Fold :',fn+1)\n        X_train,X_val = train.iloc[trn_idx],train.iloc[val_idx] # locate data based on random index generated using KFold for training and testing\n        y_train,y_val = y.iloc[trn_idx],y.iloc[val_idx]\n        \n        model = XGBRegressor(tree_method = 'gpu_hist',\n                           min_child_weight = 1,\n                           learning_rate = 0.015,\n                           colsample_bytree = 0.65,\n                           gamma = 3.69,\n                           max_delta_step = 2.07,\n                           max_depth = 10,\n                           n_estimators = 207,\n                           subsample = 1)\n        \n        model.fit(X_train,y_train)\n        pred = model.predict(X_val)\n        loss = metric(y_val,pred)\n        total_loss += loss\n        predictions = model.predict(test)\n        submission[columns] += predictions/N_splits\n        \n    off_loss += total_loss/N_splits #average loss\n    print('Model '+str(c)+\":Loss = \"+str(total_loss/N_splits))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"off_loss/100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.loc[test['cp_type']== 1,targ_score.columns] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv',index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}