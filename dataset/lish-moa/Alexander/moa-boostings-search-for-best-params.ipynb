{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\n**Surprise:** at table data kaggle competition \"MoA\" boostings perfoms worse than other models (LogReg, Neural Networks etc, even sometimes worse than constant predicton).\n\n**Challenge:** Train your skills to tune boostings params using that \"hard\" dataset. \nI.e. try to find params which would be the best for each/all/subgroup of targets. It seems to be of general use - not only for that particular competition. In particular create list of good params for boosting which can be tried in future tasks, that may speed-up tuning params in future - first try params from the list, then tune around the best one.  \n\nEveryone is  welcome to share his advise/experiments/everything... (Please note that, the goal is NOT that particular competition (MoA) - but getting general pictue, so the tricks specific to that competition may be of less interest). \n\n\n**More details:**\n\nThere two simple baselines for each target - just predict by constant, just predict by LogReg (with tuned C). \nWe can use them as benchmarks. \n\nBoostings perform not good NOT only on targets with extreme class disbalance. So it is not the only reason. \n\n**Suprises:**\n\n1) Lightgm with default params performs WORSE THAN CONSTANT on many targets.\n\n2) Currently Lightgbm  with tuned params  worse than LogReg (tuned C) on ALL 206 targets . At least those params I have considered. Can one be better than LogReg ? At least at some targets ? \n\n\n**Further points to think on:**\n\n1) Try to understand why that dataset is so hard for boostings ? May data data were prepared by LogReg is some way ? We can try to create articial data generated by logreg and compare boostings and logreg on them if results would be similar to current dataset than might be an evidence. \n\n2) We can try to find different params for different targets , as well as for all targets together - that are two different task. More natural is to consider some group of targets for example those with moderate \n\n3) Try to propose optimization schemes which might lead to good params in fastest way.\n\n4) Try to benchmark optimization packages hyperopt, optune, etc \n\n"},{"metadata":{},"cell_type":"markdown","source":"# Current findings\n\n0) Deatailed results of experiments can be  found at https://docs.google.com/spreadsheets/d/1fw6aqngYtwfVQTHbTpoGN4S8cUs-nGSM_w1fc3HpFbA/edit?usp=sharing\n\n1) Lightgbm dart mode ( model = lgb.LGBMClassifier(**{ 'boosting_type': 'dart'}) )\nworks much better on all targets than default params. Still on many targets it works worse than constant.\n\n2) Dependence on learning rate seems not be as smooth as I would expect, e.g. changing LR: 0.1->0.100028 sometimes gives  unproportianal improvement \n\n3) \"Tokyo1\" params (see values below)  seems to be quite not good - testing to be continued. \nAnalysis: params are good, but still it seems improvement over logreg is due to clipping, not due to boosting. CV score is around 0.016* (without clipping), while logreg 0.015*. Good thing - at least with use of early stopping\nresults are always BETTER than constant prediction. May be with 150+- iterations would be the same without early stopping - will check later. \n\n\nSome previous experiments can be found at:\nhttps://www.kaggle.com/alexandervc/lgb-worse-than-constant-dart-rules-optim-params\n"},{"metadata":{},"cell_type":"markdown","source":"\n# What is about \n\nIn current notebook we make some comparaison of boostings params.\n\nIt is draft version. It is planned to updated. "},{"metadata":{},"cell_type":"markdown","source":"# Technical remarks\n\n1. Small data preprossing - control group is assigned to 1 always. Doses -> 0,1 and durations -> 0,0.5,1\n\n2. Simple comparaison of params is done via cross-validation:\nskf = StratifiedKFold(n_splits=3, shuffle=True, random_state= 0 )\n\n3. Advanced comparaisons will average several cvs - to be done. \n"},{"metadata":{},"cell_type":"markdown","source":"# Other notebooks with boosting and their results\n\n\"Tokyo1\":\nhttps://www.kaggle.com/code1110/moa-lgb-seed-average  \n0.01925 - Analysis: params are good, but still it seems improvement over logreg is due to clipping, not due to boosting. CV score is around 0.016* (without clipping), while logreg 0.015*. Good thing - at least with use of early stopping\nresults are always BETTER than constant prediction. \n\n \n\"Tokyo2\" https://www.kaggle.com/sishihara/moa-lgbm-benchmark \n0.02038 \nparams = {    'num_leaves': 24, 'max_depth': 5,'objective': 'binary',     'learning_rate': 0.01 }\n\nhttps://www.kaggle.com/nroman/moa-lightgbm-206-models\nv2: Label encoding of categorical features. CV: 0.01627, LB: 0.02040\nhttps://www.kaggle.com/fchmiel/xgboost-baseline-multilabel-classification\n\nhttps://www.kaggle.com/pavelvpster/moa-lgb-optuna  \n0.01994\n \nhttps://www.kaggle.com/namanj27/catboost-moa-eda-starter \n0.02149\n\nhttps://www.kaggle.com/swarajshinde/mechanisms-of-action-moa-eda-lightgbm-baseline\n0.02037\n\nhttps://www.kaggle.com/senkin13/moa-lightgbm-starter-with-nonscored-meta-feature\n0.02063\nhttps://www.kaggle.com/hetarthchopra/xgboost-catboost-e\n\nnsemble-baseline-solution\n0.01985\nhttps://www.kaggle.com/mannsingh/simple-xgboost-model-for-beginners\n0.02098\nhttps://www.kaggle.com/acapricorni/moa-stacking-nn-lgbm\nhttps://www.kaggle.com/acapricorni/moa-stacking-nn-lgbm\n0.01980\nhttps://www.kaggle.com/demetrypascal/catboost-and-logreg"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load data and small preprocess"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import log_loss\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import Lasso\n\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nimport numpy as np\nimport datetime\nimport time\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport time\ndf = pd.read_csv('/kaggle/input/lish-moa/train_features.csv',index_col = 0)  \ndf0 = df.copy()\ndf['cp_type'] = df['cp_type'].map({'trt_cp':1.0, 'ctl_vehicle':1.0}) # Forget about control group  \ndf['cp_dose'] = df['cp_dose'].map({'D1':0.0, 'D2':1.0})\ndf['cp_time'] = df['cp_time'].map({24:0.0, 48: .5 , 72:1.0})\nX = df.copy()\nX_save = X.copy()\ndf_test = pd.read_csv('/kaggle/input/lish-moa/test_features.csv',index_col = 0)\ndf0_test = df_test.copy()\ndf_test['cp_type'] = df_test['cp_type'].map({'trt_cp':1.0, 'ctl_vehicle':0.0})\ndf_test['cp_dose'] = df_test['cp_dose'].map({'D1':0.0, 'D2':1.0})\ndf_test['cp_time'] = df_test['cp_time'].map({24:0.0, 48: .5 , 72:1.0})\n\ny = pd.read_csv('/kaggle/input/lish-moa/train_targets_scored.csv',index_col = 0 )\ny_save = y.copy()\nprint(y.iloc[:3,:2])\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_save.sum(axis = 0 ).sort_values(ascending = False)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Show LGB default params"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = lgb.LGBMClassifier(**{}) # {'boosting_type': 'dart'})\nmodel.get_params()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# target_name = 'dopamine_receptor_antagonist'\n\nThis target is one of the most difficult to predict - all models gives prediction near constant.\nDespite it the disbalance at that target is lower than in most other targets. It contains 424 \"1\". \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"rs = 0\nskf = StratifiedKFold(n_splits=3, shuffle=True, random_state= rs )\n\ntarget_name = 'dopamine_receptor_antagonist'\ny = y_save[target_name]\nprint('Target:', target_name, ' ,  count non-zero:', y.sum() )\nprint()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Compare LGB different params, constant predict, logreg "},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time \ny = y_save[target_name]\nprint('Target:', target_name, ' ,  count non-zero:', y.sum() )\nprint()\n\nprint('Predict by constant ' )\nprint('Logloss: ', np.round( -log_loss( y, np.ones_like(y)*y.mean() ) ,5 ) )\nprint()\n\nmodel = lgb.LGBMClassifier(**{}) # {'boosting_type': 'dart'})\nt0 = time.time()\ncv_score = cross_val_score(model, X, y, cv=skf,   scoring='neg_log_loss' )\nprint('LGB default params - WORSE than constant!!!')\nprint('Logloss CV3', np.round( np.mean(cv_score), 5), 'Std', np.round( np.std(cv_score),5),'Folds:',   \n      np.round(cv_score ,5), np.round(time.time()-t0, 1), 'seconds passed' )  \nprint()\n\nmodel = lgb.LGBMClassifier(**{ 'boosting_type': 'dart'})\nt0 = time.time()\ncv_score = cross_val_score(model, X, y, cv=skf,   scoring='neg_log_loss' )\nprint('LGB DART - not bad')\nprint('Logloss CV3', np.round( np.mean(cv_score), 5), 'Std', np.round( np.std(cv_score),5),'Folds:',   np.round(cv_score ,5),\n     np.round(time.time()-t0, 1), 'seconds passed' )\nprint()\n\nmodel = lgb.LGBMClassifier(**{ 'boosting_type': 'dart', 'learning_rate':0.100028})\nt0 = time.time()\ncv_score = cross_val_score(model, X, y, cv=skf,   scoring='neg_log_loss' )\nprint('LGB DART , learning_rate=0.100028 - small improvement')\nprint('Logloss CV3', np.round( np.mean(cv_score), 5), 'Std', np.round( np.std(cv_score),5),'Folds:',   \n      np.round(cv_score ,5), np.round(time.time()-t0, 1), 'seconds passed' )\nprint()\n\nmodel = lgb.LGBMClassifier(**{ 'boosting_type': 'dart', 'learning_rate':0.100028,\n 'max_depth':15, 'n_estimators':122, 'num_leaves':27, 'reg_alpha':0.0009} )\nt0 = time.time()\ncv_score = cross_val_score(model, X, y, cv=skf,   scoring='neg_log_loss' )\nprint('Best params')\nprint('Logloss CV3', np.round( np.mean(cv_score), 5), 'Std', np.round( np.std(cv_score),5),'Folds:',   \n      np.round(cv_score ,5), np.round(time.time()-t0, 1), 'seconds passed' )\nprint()\n\nmodel = LogisticRegression(C = 0.003)\nt0 = time.time()\ncv_score = cross_val_score(model, X, y, cv=skf,   scoring='neg_log_loss' )\nprint('Logreg')\nprint('Logloss CV3', np.round( np.mean(cv_score), 5), 'Std', np.round( np.std(cv_score),5),'Folds:',   \n      np.round(cv_score ,5), np.round(time.time()-t0, 1), 'seconds passed' )\nprint()\n\n    \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## \"Tokyo1\" params \n\nSeems better than Dart on many targets, still mostly worse than LogReg\n\nbased on  https://www.kaggle.com/code1110/moa-lgb-seed-average"},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n    'n_estimators': 50,\n    'objective': 'binary',\n    'boosting_type': 'gbdt',\n    'max_depth': 3,\n    'learning_rate': 0.08,\n    'subsample': 0.72,\n    'subsample_freq': 4,\n    'feature_fraction': 0.4,\n    'lambda_l1': 1,\n    'lambda_l2': 1,\n    'seed': 217, # SEED,\n    #'early_stopping_rounds': 40,\n    }    \nparams[\"metric\"] = \"binary_logloss\" \n\nmodel = lgb.LGBMClassifier(**params )\nt0 = time.time()\ncv_score = cross_val_score(model, X, y, cv=skf,   scoring='neg_log_loss' )\nprint('Best params')\nprint('Logloss CV3', np.round( np.mean(cv_score), 5), 'Std', np.round( np.std(cv_score),5),'Folds:',   \n      np.round(cv_score ,5), np.round(time.time()-t0, 1), 'seconds passed' )\nprint()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n    'n_estimators': 50,\n    'objective': 'binary',\n    'boosting_type': 'gbdt',\n    'max_depth': 3,\n    'learning_rate': 0.08,\n    'subsample': 0.72,\n    'subsample_freq': 4,\n    'feature_fraction': 0.4,\n    'lambda_l1': 1,\n    'lambda_l2': 1,\n    'seed': 217, # SEED,\n    #'early_stopping_rounds': 40,\n    }    \nparams[\"metric\"] = \"binary_logloss\" \n\nt00 = time.time()\ndf_stat = pd.DataFrame()\nfor n_estimators in range(10,300,10): #[10,20,30,40,50,60,70,80,90,100,110,120,130,150,170,200]:\n    params[\"n_estimators\"] = n_estimators \n    model = lgb.LGBMClassifier(**params )\n    t0 = time.time()\n    cv_score = cross_val_score(model, X, y, cv=skf,   scoring='neg_log_loss' )\n    #print('n_estimators params', n_estimators)\n    print('N_est',n_estimators, 'Logloss', np.round( np.mean(cv_score), 5), 'Std', np.round( np.std(cv_score),5),'Folds:',   \n          np.round(cv_score ,5), np.round(time.time()-t0, 1), 'seconds' )\n    #print()\n    id = len(df_stat)+1\n    df_stat.loc[id,'n_estimators'] = n_estimators\n    df_stat.loc[id,'Logloss'] = np.round( np.mean(cv_score), 5)\n    df_stat.loc[id,'Logloss Std'] = np.round( np.std(cv_score), 7)\n    \nseconds_passed_total = time.time()-t00\nprint(np.round(seconds_passed_total,1), np.round(seconds_passed_total/60,1) , np.round(seconds_passed_total/3600,1) , \n'seconds, minutes, hours, passed total' )\ndf_stat    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_stat.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(df_stat['n_estimators'].values, df_stat['Logloss'].values, '*-'  )\nplt.grid()\nplt.title('LogLoss')\nplt.xlabel(\"n_estimators\")\nplt.show()\nplt.plot(df_stat['n_estimators'].values, df_stat['Logloss Std'].values, '*-'  )\nplt.grid()\nplt.title('Std')\nplt.xlabel(\"n_estimators\")\nplt.show()\ndf_stat.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_stat.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Tokyo2 "},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n    'num_leaves': 24,\n    'max_depth': 5,\n    'objective': 'binary',\n    'learning_rate': 0.01\n}\n\nmodel = lgb.LGBMClassifier(**params )\nt0 = time.time()\ncv_score = cross_val_score(model, X, y, cv=skf,   scoring='neg_log_loss' )\nprint('Best params')\nprint('Logloss CV3', np.round( np.mean(cv_score), 5), 'Std', np.round( np.std(cv_score),5),'Folds:',   \n      np.round(cv_score ,5), np.round(time.time()-t0, 1), 'seconds passed' )\nprint()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t00 = time.time()\ndf_stat = pd.DataFrame()\nfor n_estimators in range(10,300,10): #[10,20,30,40,50,60,70,80,90,100,110,120,130,150,170,200]:\n    params[\"n_estimators\"] = n_estimators \n    model = lgb.LGBMClassifier(**params )\n    t0 = time.time()\n    cv_score = cross_val_score(model, X, y, cv=skf,   scoring='neg_log_loss' )\n    #print('n_estimators params', n_estimators)\n    print('N_est',n_estimators, 'Logloss', np.round( np.mean(cv_score), 5), 'Std', np.round( np.std(cv_score),5),'Folds:',   \n          np.round(cv_score ,5), np.round(time.time()-t0, 1), 'seconds' )\n    #print()\n    id = len(df_stat)+1\n    df_stat.loc[id,'n_estimators'] = n_estimators\n    df_stat.loc[id,'Logloss'] = np.round( np.mean(cv_score), 5)\n    df_stat.loc[id,'Logloss Std'] = np.round( np.std(cv_score), 7)\n    \nseconds_passed_total = time.time()-t00\nprint(np.round(seconds_passed_total,1), np.round(seconds_passed_total/60,1) , np.round(seconds_passed_total/3600,1) , \n'seconds, minutes, hours, passed total' )\ndf_stat    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(df_stat['n_estimators'].values, df_stat['Logloss'].values, '*-'  )\nplt.grid()\nplt.title('LogLoss')\nplt.xlabel(\"n_estimators\")\nplt.show()\nplt.plot(df_stat['n_estimators'].values, df_stat['Logloss Std'].values, '*-'  )\nplt.grid()\nplt.title('Std')\nplt.xlabel(\"n_estimators\")\nplt.show()\ndf_stat.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# target_name = 'jak_inhibitor'"},{"metadata":{},"cell_type":"markdown","source":"## Example where Dart is worse than constant \n\nThat would be typical if number disbalance is very high, however in that example 93 samples  = 1 , it is not so low, for many other targets which even lower number Lgb is better than constant "},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time \nrs = 0\nskf = StratifiedKFold(n_splits=3, shuffle=True, random_state= rs )\n\ntarget_name = 'jak_inhibitor'\ny = y_save[target_name]\nprint('Target:', target_name, ' ,  count non-zero:', y.sum() )\nprint()\n\nprint('Predict by constant ' )\nprint('Logloss: ', np.round( -log_loss( y, np.ones_like(y)*y.mean() ) ,5 ) )\nprint()\n\nmodel = lgb.LGBMClassifier(**{}) # {'boosting_type': 'dart'})\nt0 = time.time()\ncv_score = cross_val_score(model, X, y, cv=skf,   scoring='neg_log_loss' )\nprint('LGB default params - WORSE than constant!!!')\nprint('Logloss CV3', np.round( np.mean(cv_score), 5), 'Std', np.round( np.std(cv_score),5),'Folds:',   \n      np.round(cv_score ,5), np.round(time.time()-t0, 1), 'seconds passed' )  \nprint()\n\nmodel = lgb.LGBMClassifier(**{ 'boosting_type': 'dart'})\nt0 = time.time()\ncv_score = cross_val_score(model, X, y, cv=skf,   scoring='neg_log_loss' )\nprint('LGB DART - again WORSE than constant!!!')\nprint('Logloss CV3', np.round( np.mean(cv_score), 5), 'Std', np.round( np.std(cv_score),5),'Folds:',   np.round(cv_score ,5),\n     np.round(time.time()-t0, 1), 'seconds passed' )\nprint()\n\nmodel = lgb.LGBMClassifier(**{ 'boosting_type': 'dart', 'learning_rate':0.100028})\nt0 = time.time()\ncv_score = cross_val_score(model, X, y, cv=skf,   scoring='neg_log_loss' )\nprint('LGB DART , learning_rate=0.100028 - small change of LR, but big improvement , but  again WORSE than constant!!!')\nprint('Logloss CV3', np.round( np.mean(cv_score), 5), 'Std', np.round( np.std(cv_score),5),'Folds:',   \n      np.round(cv_score ,5), np.round(time.time()-t0, 1), 'seconds passed' )\nprint()\n\nmodel = lgb.LGBMClassifier(**{ 'boosting_type': 'dart', 'learning_rate':0.100028,\n 'max_depth':15, 'n_estimators':122, 'num_leaves':27, 'reg_alpha':0.0009} )\nt0 = time.time()\ncv_score = cross_val_score(model, X, y, cv=skf,   scoring='neg_log_loss' )\nprint('Best previous params - again WORSE than constant!!! ')\nprint('Logloss CV3', np.round( np.mean(cv_score), 5), 'Std', np.round( np.std(cv_score),5),'Folds:',   \n      np.round(cv_score ,5), np.round(time.time()-t0, 1), 'seconds passed' )\nprint()\n\nmodel = LogisticRegression(C = 0.02)\nt0 = time.time()\ncv_score = cross_val_score(model, X, y, cv=skf,   scoring='neg_log_loss' )\nprint('Logreg')\nprint('Logloss CV3', np.round( np.mean(cv_score), 5), 'Std', np.round( np.std(cv_score),5),'Folds:',   \n      np.round(cv_score ,5), np.round(time.time()-t0, 1), 'seconds passed' )\nprint()\n\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n    'n_estimators': 130,\n    'objective': 'binary',\n    'boosting_type': 'gbdt',\n    'max_depth': 3,\n    'learning_rate': 0.08,\n    'subsample': 0.72,\n    'subsample_freq': 4,\n    'feature_fraction': 0.4,\n    'lambda_l1': 1,\n    'lambda_l2': 1,\n    'seed': 217, # SEED,\n    #'early_stopping_rounds': 40,\n    }    \nparams[\"metric\"] = \"binary_logloss\" \nmodel = lgb.LGBMClassifier(**params )\nt0 = time.time()\ncv_score = cross_val_score(model, X, y, cv=skf,   scoring='neg_log_loss' )\nprint('params \"Tokyo1_130\"')\nprint('Logloss CV3', np.round( np.mean(cv_score), 5), 'Std', np.round( np.std(cv_score),5),'Folds:',   \n      np.round(cv_score ,5), np.round(time.time()-t0, 1), 'seconds passed' )\nprint()\n\n\nparams = {\n    'num_leaves': 24,\n    'max_depth': 5,\n    'objective': 'binary',\n    'learning_rate': 0.01\n}\nparams[\"n_estimators\"] = 150\nmodel = lgb.LGBMClassifier(**params )\nt0 = time.time()\ncv_score = cross_val_score(model, X, y, cv=skf,   scoring='neg_log_loss' )\nprint('params \"Tokyo2_150\"')\nprint('Logloss CV3', np.round( np.mean(cv_score), 5), 'Std', np.round( np.std(cv_score),5),'Folds:',   \n      np.round(cv_score ,5), np.round(time.time()-t0, 1), 'seconds passed' )\nprint()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Tokyo1 plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n    'n_estimators': 130,\n    'objective': 'binary',\n    'boosting_type': 'gbdt',\n    'max_depth': 3,\n    'learning_rate': 0.08,\n    'subsample': 0.72,\n    'subsample_freq': 4,\n    'feature_fraction': 0.4,\n    'lambda_l1': 1,\n    'lambda_l2': 1,\n    'seed': 217, # SEED,\n    #'early_stopping_rounds': 40,\n    }    \nparams[\"metric\"] = \"binary_logloss\" \n\nt00 = time.time()\ndf_stat = pd.DataFrame()\nfor n_estimators in range(10,300,10): #[10,20,30,40,50,60,70,80,90,100,110,120,130,150,170,200]:\n    params[\"n_estimators\"] = n_estimators \n    model = lgb.LGBMClassifier(**params )\n    t0 = time.time()\n    cv_score = cross_val_score(model, X, y, cv=skf,   scoring='neg_log_loss' )\n    #print('n_estimators params', n_estimators)\n    print('N_est',n_estimators, 'Logloss', np.round( np.mean(cv_score), 5), 'Std', np.round( np.std(cv_score),5),'Folds:',   \n          np.round(cv_score ,5), np.round(time.time()-t0, 1), 'seconds' )\n    #print()\n    id = len(df_stat)+1\n    df_stat.loc[id,'n_estimators'] = n_estimators\n    df_stat.loc[id,'Logloss'] = np.round( np.mean(cv_score), 5)\n    df_stat.loc[id,'Logloss Std'] = np.round( np.std(cv_score), 7)\n    \nseconds_passed_total = time.time()-t00\nprint(np.round(seconds_passed_total,1), np.round(seconds_passed_total/60,1) , np.round(seconds_passed_total/3600,1) , \n'seconds, minutes, hours, passed total' )\ndf_stat    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(df_stat['n_estimators'].values, df_stat['Logloss'].values, '*-'  )\nplt.grid()\nplt.title('LogLoss')\nplt.show()\nplt.plot(df_stat['n_estimators'].values, df_stat['Logloss Std'].values, '*-'  )\nplt.grid()\nplt.title('Std')\nplt.show()\ndf_stat.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Tokyo2 plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n    'num_leaves': 24,\n    'max_depth': 5,\n    'objective': 'binary',\n    'learning_rate': 0.01\n}\n\nt00 = time.time()\ndf_stat = pd.DataFrame()\nfor n_estimators in range(10,300,10): #[10,20,30,40,50,60,70,80,90,100,110,120,130,150,170,200]:\n    params[\"n_estimators\"] = n_estimators \n    model = lgb.LGBMClassifier(**params )\n    t0 = time.time()\n    cv_score = cross_val_score(model, X, y, cv=skf,   scoring='neg_log_loss' )\n    #print('n_estimators params', n_estimators)\n    print('N_est',n_estimators, 'Logloss', np.round( np.mean(cv_score), 5), 'Std', np.round( np.std(cv_score),5),'Folds:',   \n          np.round(cv_score ,5), np.round(time.time()-t0, 1), 'seconds' )\n    #print()\n    id = len(df_stat)+1\n    df_stat.loc[id,'n_estimators'] = n_estimators\n    df_stat.loc[id,'Logloss'] = np.round( np.mean(cv_score), 5)\n    df_stat.loc[id,'Logloss Std'] = np.round( np.std(cv_score), 7)\n    \nseconds_passed_total = time.time()-t00\nprint(np.round(seconds_passed_total,1), np.round(seconds_passed_total/60,1) , np.round(seconds_passed_total/3600,1) , \n'seconds, minutes, hours, passed total' )\ndf_stat    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(df_stat['n_estimators'].values, df_stat['Logloss'].values, '*-'  )\nplt.grid()\nplt.title('LogLoss')\nplt.xlabel(\"n_estimators\")\nplt.show()\nplt.plot(df_stat['n_estimators'].values, df_stat['Logloss Std'].values, '*-'  )\nplt.grid()\nplt.title('Std')\nplt.xlabel(\"n_estimators\")\nplt.show()\ndf_stat.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}