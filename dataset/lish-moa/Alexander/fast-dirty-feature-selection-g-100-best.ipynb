{"cells":[{"metadata":{},"cell_type":"markdown","source":"# What is about ? \n\n\"Fast and dirty\" feature selection for MoA contest. (\"Dirty\" - because drastical simplification for target is done . Then standard use of Lasso/L1-logreg for feature selection.)\n\nFeature \"g-100\" seems the most strongest any way. \n\nTop 3 features :  ['g-100' 'g-185' 'c-6'] . Model gives rocauc on test sample: 0.601 \n\nTop 11 features:\n['g-41' 'g-47' 'g-91' 'g-100' 'g-157' 'g-185' 'g-270' 'g-385' 'g-689'\n 'c-6' 'c-98']\nModel gives rocauc on test sample: 0.616 \n\nTop 27 features:\n['g-27' 'g-41' 'g-47' 'g-91' 'g-100' 'g-122' 'g-157' 'g-185' 'g-263'\n 'g-270' 'g-312' 'g-372' 'g-385' 'g-397' 'g-442' 'g-487' 'g-522' 'g-524'\n 'g-563' 'g-620' 'g-635' 'g-644' 'g-689' 'g-701' 'g-707' 'c-6' 'c-98']\nModel gives rocauc on test sample: 0.636 \n\n\nThe \"worst\" features and their rocauc : \n\n| Feature | RocAuc |\n| --- | --- |\n| g-362 |\t \t0.500380 | \n| g-555 |\t \t0.500356 | \n| g-688 |\t \t0.500193 | \n| g-715 |\t \t0.500187 | \n| g-404 |\t \t0.500148 | \n\n\nPlease, pay attention, that analysis is made on simplified target (which is sum of all scored targets binned to 0,1 ) and that importance from the point of view of Lasso may differ from importance   from the other model. \n\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\n\nimport time \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/lish-moa/train_features.csv',index_col = 0)  \ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.read_csv('/kaggle/input/lish-moa/test_features.csv',index_col = 0)  \ndf_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = pd.read_csv('/kaggle/input/lish-moa/train_targets_scored.csv',index_col = 0 )\ny","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_additional = pd.read_csv('/kaggle/input/lish-moa/train_targets_nonscored.csv',index_col = 0 )\ny_additional","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_sum = y.sum(axis = 1)\ny_sum.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_additional.sum(axis = 1).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mode_which_part_to_process = 'full'\nif mode_which_part_to_process == 'full':\n    # consider only gene expression part \n    list_features_names = [c for c in df.columns if ('c-' in c) or ('g-' in c)]\n    X = df[list_features_names ].values\nif mode_which_part_to_process == 'genes':\n    # consider only gene expression part \n    list_features_names =[c for c in df.columns if 'g-' in c]\n    X = df[list_features_names ].values\nif mode_which_part_to_process == 'c':\n    # consider only gene expression part \n    list_features_names =[c for c in df.columns if 'c-' in c]\n    X = df[list_features_names ].values\n\nprint(len([c for c in df.columns if 'g-' in c] ), 'genes count ')\nX_original_save = X.copy()\nprint(X.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create a simplified 0-1 target. \n\nOne - means at least one of all scored targets is non-zero. It is quite rare when several targes simulateneoly are non-zero, thus it might not be too bad to make such a simplification.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_01 = (y_sum > 0 ).astype(float)\ny_01.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train test split "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y_01, test_size=0.33, random_state=42)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Range features by the their individual predictive power "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\ndf_features_stat = pd.DataFrame()\nfor i in range(X.shape[1]):\n    v = X[:,i]\n    r = roc_auc_score(y_01, v )\n    df_features_stat.loc[list_features_names[i],'rocauc'] = r\n    df_features_stat.loc[list_features_names[i],'rocauc Abs'] = np.abs(r-0.5) + 0.5\n    \n    \ndf_features_stat.sort_values(by = 'rocauc Abs', ascending=False,  inplace = True) \nplt.figure(figsize = (25,6))\nplt.plot( df_features_stat['rocauc Abs'].values,'o')\nplt.title('Features rocauc Abs')\nplt.grid()\nplt.show()\ndf_features_stat#.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Top feauture groups selection by Lasso (L1 logreg )\n\nStronger regularization selects only most relevant features.\nSo relaxing regularization we see tradeoff between number of features and prediction quality. \n\nSmall \"C\" - strongest regularization. \n\nC =  0.001 selects:  ['g-100' 'g-185' 'c-6'] with model rocauc = 0.601\n\nC = 0.01 selects 11 features: ['g-41' 'g-47' 'g-91' 'g-100' 'g-157' 'g-185' 'g-270' 'g-385' 'g-689'\n 'c-6' 'c-98'] with model rocauc =  0.616\n \nC =  0.1 gives TOP rocauc test: 0.66 with 705 features \n\nIncreasing C further leads to dropping rocauc on test - that means to overfitting, so the other features - are not relevant (at least for that lasso model),\ni.e. they either noisy or dependent on the others \n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import linear_model\nfrom sklearn.metrics import roc_auc_score\n\nstart = time.time()\nclf = linear_model.LogisticRegression(penalty='l1', solver='liblinear',\n                                      tol=1e-6, max_iter=int(1e6),\n                                      warm_start=True ) #,\n                                      # intercept_scaling=10000.)\n    \ncoefs_ = []\nfor c in [0.001, .002, 0.003, 0.005, 0.008,  0.01, 0.1 , 1, 1e10]:\n    clf.set_params(C=c)\n    clf.fit(X_train, y_train)\n    coefs_.append(clf.coef_.ravel().copy())\n    print(\"This took %0.3fs\" % (time.time() - start))\n    p = clf.predict_proba(X_train)[:,1]\n    r_train = roc_auc_score(y_train, p )\n    p = clf.predict_proba(X_test)[:,1]\n    r = roc_auc_score(y_test, p )\n    print('c=',c, 'rocauc test:', np.round(r,3) , 'Number of features selected:', (clf.coef_.ravel() !=  0).sum() , 'rocauc train:', np.round(r_train,3)) \n    if (clf.coef_.ravel() !=  0).sum()  < 100:\n        print( np.array(list_features_names)[ (clf.coef_.ravel() !=  0) ] )\n        corr_matr = np.corrcoef(X[:, (clf.coef_.ravel() !=  0) ] .T)\n        print(np.triu(corr_matr,1).max(), np.triu(corr_matr,1).min() )  \n        \n    print()\n# print(coefs_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# top 16 somewhat \"useless\" features:"},{"metadata":{"trusted":true},"cell_type":"code","source":"m1 = ( (coefs_[-1] !=  0) * (~(coefs_[-2] !=  0) ) )#.sum()\nnp.array(list_features_names)[ m1 ] , m1.sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# top 167 somewhat \"useless\" features:"},{"metadata":{"trusted":true},"cell_type":"code","source":"m2 = ( (coefs_[-1] !=  0) * (~(coefs_[-3] !=  0) ) )#.sum()\nnp.array(list_features_names)[ m2 ] , m2.sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}