{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Keras notebook with clustering added\n\n### Version 5, best score prior to 11/30\n1. Plot PCA explained variance, pick a number of PCA dimensions to pass to NN.\n1. Visualize 2D PCA of this dataset.\n1. Conduct elbow and/or silhouette tests of the data reduced to various PCA dimensions.\n1. Select an optimal clustering algorithm and hyperparameters and number of PCA dimensions to cluster on, then cluster.\n1. Make cluster id a categorical feature, hot encode it.\n1. Pass PCA dimensions and cluster id to three layer NN.\n1. Tune the network & train up the best candidate.\n`'units 1': 512, 'activation function 1': 'relu', 'dropout 1': 0.35, \n'units 2': 512, 'activation function 2': 'relu', 'dropout 2': 0.5, \n'units 3': 512, 'activation function 3': 'relu', 'dropout 3': 0.2`\nScore: 0.02222\n\n### Version 7\n`'units 1': 512, 'activation function 1': 'relu', 'dropout 1': 0.2, \n'units 2': 2048, 'activation function 2': 'relu', 'dropout 2': 0.2, \n'units 3': 512, 'activation function 3': 'elu', 'dropout 3': 0.35`\n\n### Version 8, I mean 9\nCut out the clustering search phase and hardcode the bw30, 2 dims clustering.\nCut out the kerastuner and hardcode the Version 7 architecture.\nAdd the custom log loss function to evaluate the results since I'm actually finally in danger of running out of submissions for the day.\nScore: 0.05464\n\n### Version 10, 11, 11/30\nPut in GF's logloss function and use as metric.\nUse VarianceThreshold, QuantileTransformer, and ICA in place of PCA breakdown.\nCannot cluster on ICA'd data, so removed clustering from Version 11.\nScore: 0.02092\n\n### Version 12\nCluster using Mahlananobis distance, if practical. Mahlananobis distance obviates the need for pre-scaling the data and can be used on the raw data prior to transformations or anywhere prior to ICA. Scikit-learn's documentation comments that this is implemented in the Gaussian Mixture clustering algorithms. Code from https://scikit-learn.org/stable/auto_examples/mixture/plot_gmm_selection.html is incorporated below.\n\n### Version 13\nImplement a cross-validation and ensemble prediction routine."},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport itertools\nfrom scipy import linalg\nfrom sklearn.preprocessing import MinMaxScaler, OneHotEncoder, QuantileTransformer\nfrom sklearn.decomposition import FastICA\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn import mixture\nimport category_encoders as ce\n#!pip install iterative-stratification\n#from iterstrat.ml_stratifiers import MultilabelStratifiedKFold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set()\nsns.set_style('whitegrid')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport keras\nimport keras.backend as K\nfrom keras.models import Model\nimport kerastuner\nfrom keras.layers import Dense, Input, Dropout, BatchNormalization","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def logloss(y_true,y_pred):\n    # y_pred = tf.clip_by_value(y_pred,1e-20,1-1e-20)\n    y_pred = tf.clip_by_value(y_pred,0.001,0.999)\n    return -K.mean(y_true*K.log(y_pred) + (1-y_true)*K.log(1-y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf_df = pd.read_csv('../input/lish-moa/train_features.csv',index_col='sig_id')\ntts_df = pd.read_csv('../input/lish-moa/train_targets_scored.csv',index_col='sig_id')\nscaler = MinMaxScaler(feature_range=(-0.5,0.5))\ntf_df['cp_time']=scaler.fit_transform((np.array(tf_df['cp_time'])).reshape(-1,1))\noenc = ce.ordinal.OrdinalEncoder()\ntf_df = oenc.fit_transform(tf_df)\ntf_df['cp_type']=tf_df['cp_type']-1\ntf_df['cp_dose']=tf_df['cp_dose']-1\ntf_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testf_df = pd.read_csv('../input/lish-moa/test_features.csv',index_col='sig_id')\ntestf_df['cp_time']=scaler.transform((np.array(testf_df['cp_time'])).reshape(-1,1))\ntestf_df = oenc.transform(testf_df)\ntestf_df['cp_type']=testf_df['cp_type']-1\ntestf_df['cp_dose']=testf_df['cp_dose']-1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"totalf_df = pd.concat([tf_df,testf_df],axis=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"0. Gaussian Mixture selection"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = totalf_df.values\nlowest_bic = np.infty\nbic = []\nn_components_range = range(1, 7)\ncv_types = ['spherical', 'tied', 'diag', 'full']\nfor cv_type in cv_types:\n    for n_components in n_components_range:\n        # Fit a Gaussian mixture with EM\n        gmm = mixture.GaussianMixture(n_components=n_components,\n                                      covariance_type=cv_type)\n        gmm.fit(X)\n        bic.append(gmm.bic(X))\n        if bic[-1] < lowest_bic:\n            lowest_bic = bic[-1]\n            best_gmm = gmm\n\nbic = np.array(bic)\ncolor_iter = itertools.cycle(['navy', 'turquoise', 'cornflowerblue',\n                              'darkorange'])\nclf = best_gmm\nbars = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the BIC scores\nplt.figure(figsize=(8, 6))\nspl = plt.gca()\nfor i, (cv_type, color) in enumerate(zip(cv_types, color_iter)):\n    xpos = np.array(n_components_range) + .2 * (i - 2)\n    bars.append(plt.bar(xpos, bic[i * len(n_components_range):\n                                  (i + 1) * len(n_components_range)],\n                        width=.2, color=color))\nplt.xticks(n_components_range)\nplt.ylim([bic.min() * 1.01 - .01 * bic.max(), bic.max()])\nplt.title('BIC score per model')\nxpos = np.mod(bic.argmin(), len(n_components_range)) + .55 +\\\n    .2 * np.floor(bic.argmin() / len(n_components_range))\nplt.text(xpos, bic.min() * 0.97 + .03 * bic.max(), '*', fontsize=14)\nspl.set_xlabel('Number of components')\nspl.legend([b[0] for b in bars], cv_types)\nplt.show()\nY_ = clf.predict(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hot damn, it ran. WTF error on the cluster plotting (code deleted) does not prevent me from using the 6 clusters, diag results. (Wow, that legend. Why is it in such mixed-up order?)"},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = pd.Series(Y_)\nlabels.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"That's tasty and intriguing. I hope it doesn't evaporate on the rerun."},{"metadata":{"trusted":true},"cell_type":"code","source":"ohenc = OneHotEncoder(drop='first',sparse=False,dtype=np.int)\ncats = ohenc.fit_transform(Y_.reshape(-1,1))\ncats[:5,:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. VarianceThreshold"},{"metadata":{"trusted":true},"cell_type":"code","source":"weeder = VarianceThreshold(0.95)\n# high variance features retained\nhighvf_arr = weeder.fit_transform(totalf_df.loc[:,'g-0':'c-99'])\nhighvf_arr.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. QuantileTransformer"},{"metadata":{"trusted":true},"cell_type":"code","source":"leveller = QuantileTransformer(n_quantiles=100,output_distribution='normal')\nqhighvf_arr = leveller.fit_transform(highvf_arr)\nqhighvf_arr.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3. ICA. ICA \"super-standardizes\" the features to mean 0 and variance well under 1."},{"metadata":{"trusted":true},"cell_type":"code","source":"strategy = tf.distribute.get_strategy()\nprint(\"Number of accelerators: \", strategy.num_replicas_in_sync)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with strategy.scope():\n    ica = FastICA(n_components=300,max_iter=500)\n    ica_arr = ica.fit_transform(qhighvf_arr)\nprint('Mean over ICA features:',ica.mean_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"4. Visualize first few ICA components."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(pd.DataFrame(ica_arr[:,0:5],\n                          index=range(ica_arr.shape[0]),\n                          columns=range(5)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Apparently FastICA is horrifically stochastic and unpredictable. The first time through it produced good clusters, but that's disappeared and apparently won't come back."},{"metadata":{},"cell_type":"markdown","source":"5. Bring together the encoded cp features and ICA components to form the prepared feature array."},{"metadata":{"trusted":true},"cell_type":"code","source":"cp_arr = totalf_df.loc[:,'cp_type':'cp_dose'].values\nprint(type(cp_arr),cp_arr.shape,ica_arr.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"finalf_arr = np.concatenate((cats,cp_arr,ica_arr),axis=1)\nfinalf_arr.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tts_arr = tts_df.values\ntts_arr.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_train = tf_df.shape[0]\nn_test = testf_df.shape[0]\nn_features = finalf_arr.shape[1]\nn_targets = tts_arr.shape[1]\nassert n_train + n_test == finalf_arr.shape[0]\ntf_arr = finalf_arr[:n_train,:].copy()\ntestf_arr = finalf_arr[-1*n_test:,:].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(tf_arr.shape,testf_arr.shape,tf_df.shape,testf_df.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"8. Get crackalackin'."},{"metadata":{"trusted":true},"cell_type":"code","source":"with strategy.scope():\n    inputs = Input(shape=(n_features,))\n    x = Dense(256,activation='elu')(inputs)\n    x = Dropout(0.2)(x)\n    x = Dense(64,activation='elu')(x)\n    x = Dropout(0.2)(x)\n    x = Dense(256,activation='elu')(x)\n    x = Dropout(0.2)(x)\n    outputs = Dense(n_targets,activation='sigmoid')(x)\n    model = Model(inputs,outputs)\n    model.compile('adam', 'binary_crossentropy', metrics=[logloss])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_epochs = 40\nn_batch = 32\nsplit = 0.2\nprint('Starting Training')\nhistory = model.fit(tf_arr,tts_arr,validation_split=split,\n                    epochs=n_epochs,batch_size=n_batch,verbose=2)\nprint('Finished Training')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate(tf_arr,tts_arr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with strategy.scope():\n    inputs = Input(shape=(n_features,))\n    x = Dense(512,activation='elu')(inputs)\n    x = Dropout(0.2)(x)\n    x = Dense(512,activation='elu')(x)\n    x = Dropout(0.2)(x)\n    x = Dense(512,activation='elu')(x)\n    x = Dropout(0.2)(x)\n    outputs = Dense(n_targets,activation='sigmoid')(x)\n    model2 = Model(inputs,outputs)\n    model2.compile('adam', 'binary_crossentropy', metrics=[logloss])\nmodel2.summary()\nprint('Starting Training')\nhistory = model2.fit(tf_arr,tts_arr,validation_split=split,\n                    epochs=n_epochs,batch_size=n_batch,verbose=2)\nprint('Finished Training')\nmodel2.evaluate(tf_arr,tts_arr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tts_pred = model2.predict(testf_arr)\nsub_df = pd.DataFrame(tts_pred,index=testf_df.index,columns=tts_df.columns)\nsub_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df.to_csv('/kaggle/working/submission.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}