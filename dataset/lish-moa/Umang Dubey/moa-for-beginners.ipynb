{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport tensorflow\nnp.random.seed(2)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold, KFold\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input\n\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\nimport tensorflow_addons as tfa\nfrom sklearn.metrics import log_loss\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train = pd.read_csv('/kaggle/input/lish-moa/train_features.csv')\ndata_test = pd.read_csv('/kaggle/input/lish-moa/test_features.csv')\ndata_train_target_ns = pd.read_csv('/kaggle/input/lish-moa/train_targets_nonscored.csv')\ndata_train_target_s = pd.read_csv('/kaggle/input/lish-moa/train_targets_scored.csv')\nsub = pd.read_csv('/kaggle/input/lish-moa/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(df):\n    df.loc[:, 'cp_type'] = df.loc[:, 'cp_type'].map({'trt_cp': 0, 'ctl_vehicle': 1})\n    df.loc[:, 'cp_dose'] = df.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n    df.loc[:, 'cp_time'] = df.loc[:, 'cp_time'].map({24: 0, 48: 0.5, 72:1})\n    del df['sig_id']\n    return df\n\ntrain = preprocess(data_train)\ntest = preprocess(data_test)\n\ndel data_train_target_s['sig_id']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model(num_columns):\n    model = Sequential()\n    model.add(Input(num_columns))\n    model.add(BatchNormalization())\n    model.add(Dense(8912, activation='relu'))\n    model.add(Dropout(0.5))\n    \n    model.add(Dense(4096, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    \n    model.add(Dense(2048, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    \n    \n    model.add(Dense(1024, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    \n    model.add(Dense(206, activation='sigmoid'))\n    \n    optimizer = tfa.optimizers.Lookahead('adam',sync_period=10)\n    \n    model.compile(optimizer=optimizer,\n                  loss='binary_crossentropy', \n                  metrics=['accuracy'])\n    \n    model.summary()\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ndef metric(y_true, y_pred):\n    metrics = []\n    for _target in data_train_target_s.columns:\n        metrics.append(log_loss(y_true.loc[:, _target], y_pred.loc[:, _target].astype(float), labels=[0,1]))\n    return np.mean(metrics)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"N_STARTS = 4\ntf.random.set_seed(42)\n\nres = data_train_target_s.copy()\nsub.loc[:, data_train_target_s.columns] = 0\nsub.loc[:, data_train_target_s.columns] = 0\n\nfor seed in range(N_STARTS):\n    for n, (train_idx, test_idx) in enumerate(KFold(n_splits=5, random_state=seed, shuffle=True).split(data_train_target_s, data_train_target_s)):\n        print(f'Fold {n}')\n    \n        model = create_model(875)\n#         checkpoint_path = f'repeat:{seed}_Fold:{n}.h5'\n#         reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, epsilon=1e-4, mode='min')\n#         cb_checkpt = ModelCheckpoint(checkpoint_path, monitor = 'val_loss', verbose = 0, save_best_only = True,\n#                                      save_weights_only = True, mode = 'min')\n        model.fit(train.values[train_idx],\n                  data_train_target_s.values[train_idx],\n                  validation_data=(train.values[test_idx], data_train_target_s.values[test_idx]),\n                  epochs=25, batch_size=128,verbose=1\n#                   callbacks=[reduce_lr_loss, cb_checkpt],\n                 )\n        \n#         model.load_weights(checkpoint_path)\n        test_predict = model.predict(test.values)\n        val_predict = model.predict(train.values[test_idx])\n        \n        sub.loc[:, data_train_target_s.columns] += test_predict\n        res.loc[test_idx, data_train_target_s.columns] += val_predict\n        print('')\n    \nsub.loc[:, data_train_target_s.columns] /= ((n+1) * N_STARTS)\nres.loc[:, data_train_target_s.columns] /= N_STARTS","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.loc[test['cp_type']==1, data_train_target_s.columns] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}