{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nimport torch.nn.functional as F\n\nfrom scipy.special import expit\nimport math\nimport random\n\nfrom sklearn.model_selection import KFold, RepeatedStratifiedKFold\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\n\nimport pdb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seed = 42\nrandom.seed(seed)\nos.environ['PYTHONHASHSEED'] = str(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.backends.cudnn.deterministic = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample = pd.read_csv('/kaggle/input/lish-moa/sample_submission.csv')\n\nsample.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/lish-moa/train_features.csv')\ntarget_df = pd.read_csv('/kaggle/input/lish-moa/train_targets_scored.csv')\n\ntrain_nonscored = pd.read_csv('/kaggle/input/lish-moa/train_targets_nonscored.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_nonscored.iloc[:,1:].sum(axis=0).reset_index(name='count').sort_values(by='count', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['cp_type'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Map categorical features, because they are binary, just keep 0/1\n\ndef preprocess(df):\n    df['cp_type'] = df['cp_type'].map({'ctl_vehicle':0,'trt_cp':1})\n    df['cp_dose'] = df['cp_dose'].map({'D1':0,'D2':1})\n#     df['cp_time'] = df['cp_time'].map({24:0, 48:1, 72:2}) # keep order\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = preprocess(train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get feature columns\nfeature_cols = train_df.columns[1:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get target columns/labels\ntarget_cols = target_df.columns[1:]  # without id\n\n# Merge training features with target labels on the drug id\nfull_df = pd.merge(train_df, target_df, how='left', on='sig_id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create validation folds\nfolds = 5\nkf = KFold(n_splits=folds, random_state=0, shuffle=True)\nfull_df['fold'] = -1\nfor i, (train_index, valid_index) in enumerate(kf.split(X=full_df[feature_cols])):\n    full_df.loc[valid_index, 'fold'] = i","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dataset class\n\nclass TrainDataset(Dataset):\n    def __init__(self, features, targets):\n        self.features = features\n        self.targets = targets\n        \n    def __len__(self):\n        return len(self.targets)\n    \n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n\n        x = torch.tensor(self.features[idx, :], dtype=torch.float32)\n        y = torch.tensor(self.targets[idx, :], dtype=torch.float32)\n        return x, y    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MoA(nn.Module):\n    def __init__(self, n_features, n_targets, layers):\n        super().__init__()\n        \n        self.n_features = n_features\n        self.n_targets = n_targets\n        self.layers = layers\n\n        layerlist = []\n        n_in = self.n_features\n        for i in self.layers:\n            layerlist.append(nn.Linear(n_in, i, bias=False))\n            layerlist.append(nn.BatchNorm1d(i))\n            layerlist.append(nn.PReLU())\n            layerlist.append(nn.Dropout(p=0.5))\n            n_in = i\n            \n        # ouptut \n        layerlist.append(nn.Linear(layers[-1], self.n_targets))\n        \n        self.model = nn.Sequential(*layerlist)\n        \n    def forward(self, x):\n        return self.model(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\nprint(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test data preperation\ntest_df = pd.read_csv('/kaggle/input/lish-moa/test_features.csv')\n\n\ntest_df = preprocess(test_df)\ntest_features = test_df[feature_cols].to_numpy()\n    \ntest_dataset = TrainDataset(test_features, np.zeros((test_features.shape[0], target_cols.shape[0])))\n    \ntest_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# epochs = 50\n# model = MoA(n_features=len(feature_cols), n_targets=len(target_cols), layers=[1024,512,256,128]).to(device)\n# criterion = nn.BCEWithLogitsLoss()\n\n# optimizer = torch.optim.AdamW(model.parameters(), weight_decay=0.02, lr=3e-2)\n# scheduler = ReduceLROnPlateau(optimizer=optimizer, patience=3, verbose=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# learning rate finder\ndef find_lr(net, trn_loader, optimizer, criterion, init_value = 1e-8, final_value=10., beta = 0.98):\n    num = len(trn_loader)-1\n    mult = (final_value / init_value) ** (1/num)\n    lr = init_value\n    optimizer.param_groups[0]['lr'] = lr\n    avg_loss = 0.\n    best_loss = 0.\n    batch_num = 0\n    losses = []\n    log_lrs = []\n    for x, y in trn_loader:\n        batch_num += 1\n        #As before, get the loss for this mini-batch of inputs/outputs\n        optimizer.zero_grad()\n        x = x.to(device)\n        y = y.to(device)\n        y_pred = net(x)\n        loss = criterion(y_pred, y)\n        #Compute the smoothed loss\n        avg_loss = beta * avg_loss + (1-beta) *loss.item()\n        smoothed_loss = avg_loss / (1 - beta**batch_num)\n        #Stop if the loss is exploding\n        if batch_num > 1 and smoothed_loss > 4 * best_loss:\n            return log_lrs, losses\n        #Record the best loss\n        if smoothed_loss < best_loss or batch_num==1:\n            best_loss = smoothed_loss\n        #Store the values\n        losses.append(smoothed_loss)\n        log_lrs.append(math.log10(lr))\n        #Do the SGD step\n        loss.backward()\n        optimizer.step()\n        #Update the lr for the next step\n        lr *= mult\n        optimizer.param_groups[0]['lr'] = lr\n    return log_lrs, losses","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class LabelSmoothingCrossEntropy(nn.Module):\n    def __init__(self):\n        super(LabelSmoothingCrossEntropy, self).__init__()\n    def forward(self, x, target, smoothing=0.001):\n        confidence = 1. - smoothing\n        logprobs = F.log_softmax(x, dim=-1)\n        bcs_loss = nn.BCEWithLogitsLoss()(x, target)\n        smooth_loss = -logprobs.mean(dim=-1)\n        loss = confidence * bcs_loss + smoothing * smooth_loss\n        return loss.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(model, optimizer, criterion, metric, scheduler, batch_size, epochs,\n          X_train, y_train, X_val, y_val, dev=False):\n    \n    train_dataset = TrainDataset(X_train, y_train)\n    valid_dataset = TrainDataset(X_val, y_val)\n    \n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n    \n    if dev:\n        log_lrs, losses =  find_lr(model, train_loader, optimizer, criterion)\n        plt.plot(log_lrs,losses)\n        return\n    \n    lowest_loss = 999\n    no_improve = 0\n    \n    for i in range(epochs):\n\n        train_losses = []\n        valid_losses = []\n        metric_vals = []\n\n\n        model.train()\n        for x_train, y_train in train_loader:\n            optimizer.zero_grad()\n\n            x_train = x_train.to(device)\n            y_train = y_train.to(device)\n            # predict\n            y_pred = model(x_train)\n            train_loss = criterion(y_pred, y_train)\n\n            train_losses.append(train_loss.item())\n            # Update parameters\n            train_loss.backward() \n            optimizer.step()\n\n        model.eval()\n        with torch.no_grad():\n            for x_valid, y_valid in valid_loader:\n                x_valid = x_valid.to(device)\n                y_valid = y_valid.to(device)\n\n                # predict\n                y_pred = model(x_valid)\n                valid_loss = criterion(y_pred, y_valid)\n                valid_losses.append(valid_loss.item())\n                metric_vals.append(metric(y_pred, y_valid).item())\n\n            avg_loss = np.mean(valid_losses)\n            avg_metric = np.mean(metric_vals)\n            \n        if avg_metric < lowest_loss:\n            lowest_loss = avg_metric\n            no_improve=0\n        else:\n            no_improve += 1\n    \n        print(f\"Epoch {i}: Train Loss = {np.mean(train_losses)}, Valid Loss = {avg_loss}, Metric = {avg_metric}\")\n        \n        if no_improve==5:\n            print('No improvement, stopping')\n            break\n            \n        scheduler.step(avg_loss)        \n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test(model, test_loader):\n    test_preds = []\n    model.eval()\n    with torch.no_grad():\n        for  x_test, _ in test_loader:\n            x_test = x_test.to(device)\n            # pred\n            y_pred = model(x_test)\n            test_preds = np.append(test_preds, y_pred.cpu().numpy())\n    \n    return expit(test_preds) # need to apply sigmoind on logits","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_submission(test_df, test_preds):\n    \n    sub_df = test_df[['sig_id']].copy()\n    sub_df.loc[:, target_cols] = 0\n    sub_df.loc[:, target_cols] = test_preds.reshape(len(test_df), len(target_cols))\n\n    # set control group MoA to 0\n    sub_df.loc[test_df[test_df['cp_type']==0].index,1:]=0\n\n    return sub_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"folds = 5\nepochs = 30\nbatch_size = 256\nlr = 5e-3\n\nfor fold in range(folds):\n    \n    print(f'Training fold {fold}')\n    \n    # Initialize model\n    model = MoA(n_features=len(feature_cols), n_targets=len(target_cols), layers=[1024,512,512,256]).to(device)\n    criterion = nn.BCEWithLogitsLoss()\n    smooth_criterion = LabelSmoothingCrossEntropy()\n    \n    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n    scheduler = ReduceLROnPlateau(optimizer=optimizer, mode='min', patience=5, verbose=True)\n\n\n    # Split data based on fold\n    X_train = full_df[full_df['fold'] != fold][feature_cols].to_numpy()\n    y_train = full_df[full_df['fold'] != fold][target_cols].to_numpy()\n    \n    X_valid = full_df[full_df['fold'] == fold][feature_cols].to_numpy()\n    y_valid = full_df[full_df['fold'] == fold][target_cols].to_numpy()\n    \n    \n    # train\n    model = train(model, optimizer, smooth_criterion, criterion, scheduler, \n                  batch_size, epochs, X_train, y_train, X_valid, y_valid)\n\n    # predict\n    if fold == 0:\n        test_preds = test(model, test_loader)/folds  # divide by folds to get average\n    else:\n        test_preds += test(model, test_loader)/folds  # divide by folds to get average\n    \n\nsub_df = create_submission(test_df, test_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}