{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom tqdm.auto import tqdm\n\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch.utils.data import TensorDataset, DataLoader, random_split\nfrom catalyst import dl\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nDATA_DIRECTORY = f\"/kaggle/input/{os.listdir('/kaggle/input')[0]}\"\nRANDOM_SEED = 1235\n\ndef file_path(filename):\n    global DATA_DIRECTORY\n    return os.path.join(DATA_DIRECTORY, filename)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv(file_path(\"train_features.csv\")).sort_values(by='sig_id')\ntargets = pd.read_csv(file_path(\"train_targets_scored.csv\")).sort_values(by='sig_id')\ntest = pd.read_csv(file_path(\"test_features.csv\"))\nsubmission = test[['sig_id']].assign(**targets.iloc[:, 1:].mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask = test['cp_type'] != 'ctl_vehicle'\nsubmission.iloc[~mask, 1:] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def basic_preprocess(X, y=None):\n    mask = X['cp_type'] != 'ctl_vehicle'\n    X = X[mask]\n    if y is not None:\n        y = y[mask].drop(columns='sig_id')\n    X.drop(columns=['cp_type', 'sig_id'], inplace=True)\n    X['cp_dose'] = ((X['cp_dose'] == 'D2').astype(np.int) - 0.5) * np.sqrt(12)\n    X['cp_time1'] = ((X['cp_time'] == 24).astype(np.int) - 0.5) * np.sqrt(12)\n    X['cp_time2'] = ((X['cp_time'] == 48).astype(np.int) - 0.5) * np.sqrt(12)\n    X.drop(columns='cp_time', inplace=True)\n    if y is not None:\n        return X, y\n    return X\n\ndef preprocess(train, targets, test):\n    train, targets = basic_preprocess(train, targets)\n    test = basic_preprocess(test)\n    return train, targets, test\n\ntrain, targets, test = preprocess(train, targets, test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = torch.tensor(train.values, dtype=torch.float)\ny = torch.tensor(targets.values, dtype=torch.float)\nX_t = torch.tensor(test.values, dtype=torch.float)\n\ndataset = TensorDataset(X, y)\ntest_dataset = TensorDataset(X_t, torch.zeros(X_t.shape[0], y.shape[1], dtype=y.dtype))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hidden_size = 1024\n\nmodel = nn.Sequential(\n    nn.Linear(X.shape[1], hidden_size),\n    nn.ReLU(inplace=True),\n    nn.Linear(hidden_size, y.shape[1]),\n)\n\nvalid_size = int(0.1 * X.shape[0])\ntrain_size = X.shape[0] - valid_size\n\ntrain_dataset, valid_dataset = random_split(dataset, lengths=[train_size, valid_size], generator=torch.Generator().manual_seed(RANDOM_SEED))\nloaders = {\n    \"train\": DataLoader(train_dataset, batch_size=32, shuffle=True),\n    \"valid\": DataLoader(valid_dataset, batch_size=256, shuffle=False)\n}\nfull_loader = {\n    \"train\": DataLoader(dataset, batch_size=32, shuffle=True),\n}\n\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\nnum_epochs = 11","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CustomRunner(dl.SupervisedRunner):\n    loss = nn.BCEWithLogitsLoss(reduction='mean')\n    \n    def _handle_batch(self, batch):\n        y_pred = self.model(batch['features'])\n\n        loss = CustomRunner.loss(y_pred, batch['targets'])\n        self.batch_metrics.update({\"loss\": loss})\n\nrunner = CustomRunner()\n\nrunner.train(\n    model=model,\n    optimizer=optimizer,\n    loaders=full_loader,\n    num_epochs=num_epochs\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"runner = dl.SupervisedRunner()\nresults = runner.predict_loader(\n    model=model,\n    loader=DataLoader(test_dataset, batch_size=128)\n)\n\ntotal_results = []\nfor x in results:\n    total_results.append(torch.sigmoid(x['logits']))\ntotal_results = torch.cat(total_results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.iloc[np.where(mask)[0], 1:] = total_results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index=None)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}