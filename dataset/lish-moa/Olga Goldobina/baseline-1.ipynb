{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, TensorDataset\n\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MyModel(nn.Module):\n    def __init__(self, in_features, out_features):\n        super().__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n\n        self.model = nn.Sequential(\n            nn.BatchNorm1d(in_features),\n            nn.Dropout(0.5),\n            nn.Linear(in_features, 2048),#2 * in_features),\n            nn.ReLU(),\n\n            nn.BatchNorm1d(2048),\n            nn.Dropout(0.5),\n            nn.Linear(2048, 1024),\n            nn.ReLU(),\n\n#             nn.BatchNorm1d(4 * in_features),\n#             nn.Dropout(0.5),\n#             nn.Linear(4 * in_features, 2 * in_features),\n#             nn.ReLU(),\n\n            nn.BatchNorm1d(1024),\n            nn.Dropout(0.5),\n            nn.Linear(1024, out_features),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        return self.model(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(model, train_dataloader, test_dataloader=None, optimizer=None, scheduler=None, max_epoch=10, criterion=None):\n    if optimizer is None:\n        optimizer = torch.optim.Adam(model.parameters()) #SGD(model.parameters(), lr=1e-3)\n    if scheduler is None:\n        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 0.1, 2)\n    if criterion is None:\n        criterion = nn.BCELoss()\n    for epoch in range(max_epoch):\n        model.train()\n        for i, (x_batch, y_batch) in enumerate(train_dataloader):\n            preds = model(x_batch)\n\n            optimizer.zero_grad()\n            loss = criterion(preds, y_batch)\n            loss.backward()\n            optimizer.step()\n            scheduler.step()\n            if i % 20 == 0:\n                print(f'Epoch: {epoch}, train loss: {loss.item():12.5f}')\n\n        model.eval()\n        with torch.no_grad():\n            train, y_train = train_dataloader.dataset.tensors\n            train_preds = model(train)\n            train_loss = criterion(train_preds, y_train).item()\n            if test_dataloader is not None:\n                test, y_test = test_dataloader.dataset.tensors\n                test_preds = model(test)\n                test_loss = criterion(test_preds, y_test).item()\n                print(f'Epoch: {epoch} final', f'test loss: {test_loss}', f'train loss: {train_loss}')\n            else:\n                print(f'Epoch: {epoch} final: train loss: {train_loss}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom copy import deepcopy\n\ndef train_ensemble(X, y, base_model=MyModel, n_models=5, max_epoch=50):#, optimizer=None, scheduler=None):\n    criterion = nn.BCELoss()\n    \n    kf = KFold(n_splits=n_models, shuffle=True, random_state=48)\n    models = []\n    for i, (train_ind, val_ind) in enumerate(kf.split(X, y)):\n        print(f'Training model {i+1}/{kf.n_splits}')\n\n        x_train = torch.tensor(X.iloc[train_ind,:].values, dtype=torch.float32)\n        y_train = torch.tensor(y.iloc[train_ind,:].values, dtype=torch.float32)\n        x_val = torch.tensor(X.iloc[val_ind,:].values, dtype=torch.float32)\n        y_val = torch.tensor(y.iloc[val_ind,:].values, dtype=torch.float32)\n\n        train_dataloader = DataLoader(TensorDataset(x_train, y_train), batch_size=128, shuffle=True)\n        val_dataloader = DataLoader(TensorDataset(x_val, y_val), batch_size=128)\n\n        best_loss = np.inf\n        best_model = None\n        cur_model = base_model(x_train.shape[1], y_train.shape[1]).to('cuda')\n#         if optimizer is None:\n        optimizer = torch.optim.Adam(cur_model.parameters(),weight_decay=1e-5)\n#         if scheduler is None:\n#         scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 0.1, 20)\n        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, eps=1e-4)\n            \n        for epoch in range(max_epoch):\n            cur_model.train()\n            for i, (x_batch, y_batch) in enumerate(train_dataloader):\n                preds = cur_model(x_batch.to('cuda'))\n\n                optimizer.zero_grad()\n                loss = criterion(preds, y_batch.to('cuda'))\n                loss.backward()\n                optimizer.step()\n#                 scheduler.step()\n\n            cur_model.eval()\n            with torch.no_grad(): \n                train_preds = cur_model(x_train.to('cuda'))\n                train_loss = criterion(train_preds, y_train.to('cuda')).item()\n                val_preds = cur_model(x_val.to('cuda'))\n                val_loss = criterion(val_preds, y_val.to('cuda')).item()\n            print(f'Epoch {epoch}: train loss: {train_loss}, val loss: {val_loss}')\n            scheduler.step(val_loss)\n            if val_loss < best_loss:\n                best_model = deepcopy(cur_model)\n                best_loss = val_loss\n\n        models += [best_model]\n\n    return models","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_features = ['g-392', 'c-65', 'g-100', 'c-9', 'g-50', 'c-79', 'c-98', 'g-37',\n       'c-6', 'c-26', 'g-439', 'g-628', 'g-744', 'g-351', 'g-298', 'c-42',\n       'g-410', 'g-761', 'c-18', 'g-418', 'g-146', 'c-57', 'c-64',\n       'g-322', 'c-48', 'c-38', 'c-82', 'g-63', 'g-534', 'c-92', 'g-186',\n       'c-28', 'g-486', 'c-70', 'g-672', 'g-91', 'g-731', 'c-10', 'g-386',\n       'g-121', 'g-443', 'g-206', 'g-723', 'c-81', 'c-36', 'c-33', 'g-85',\n       'g-235', 'g-406', 'g-683', 'c-52', 'c-62', 'c-63', 'g-365', 'c-21',\n       'c-60', 'c-15', 'c-66', 'g-629', 'c-49', 'g-248', 'c-59', 'c-24',\n       'c-76', 'g-669', 'g-106', 'g-38', 'g-140', 'c-30', 'c-22', 'g-72',\n       'c-25', 'c-23', 'c-8', 'c-83', 'g-489', 'g-369', 'c-47', 'g-158',\n       'g-297', 'g-147', 'c-5', 'c-77', 'g-163', 'g-332', 'g-344', 'c-50',\n       'g-335', 'c-2', 'g-503', 'g-208', 'g-152', 'c-17', 'c-41', 'g-353',\n       'c-34', 'g-664', 'c-96', 'g-228', 'c-67', 'g-569', 'g-750', 'g-30',\n       'g-578', 'c-90', 'c-72', 'g-257', 'c-75', 'c-97', 'g-98', 'g-500',\n       'c-1', 'g-728', 'c-44', 'g-360', 'c-85', 'g-195', 'c-31', 'c-11',\n       'c-40', 'g-135', 'g-65', 'c-95', 'c-80', 'g-261', 'g-590', 'c-54',\n       'c-51', 'c-13', 'c-12', 'g-201', 'g-83', 'g-468', 'g-58', 'g-478',\n       'g-460', 'g-574', 'c-45', 'c-94', 'c-4', 'g-367', 'c-69', 'g-407',\n       'c-73', 'g-349', 'g-155', 'g-113', 'g-350', 'c-91', 'g-546',\n       'g-131', 'g-52', 'g-745', 'c-55', 'c-27', 'c-14', 'g-379', 'g-51',\n       'g-199', 'g-241', 'g-568', 'g-10', 'c-93', 'g-508', 'c-84', 'c-78',\n       'g-433', 'c-20', 'c-39', 'g-7', 'g-177', 'g-185']\n\ndef preprocess(features, target=None, is_train=True):\n    out_features = features.drop(['sig_id'], axis=1).copy() #features[best_features].copy()\n    out_features['cp_type'] = (features.cp_dose == 'trt_cp').astype(float)\n    out_features['cp_dose'] = (features.cp_dose == 'D1').astype(float)\n    out_features['cp_time'] = (features.cp_time == 48).astype(float)\n#     if is_train:\n#         out_features = out_features[features.cp_type == 'trt_cp']\n        \n    out_target = None   \n    if target is not None:\n        out_target = target.drop('sig_id', axis=1).copy()\n#         if is_train:\n#             out_target = out_target[features.cp_type == 'trt_cp']\n            \n    return out_features, out_target","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dir = '../input/lish-moa/'\n\ntrain_features = pd.read_csv(data_dir+'train_features.csv')\ntest_features = pd.read_csv(data_dir+'test_features.csv')\ntrain_target = pd.read_csv(data_dir+'train_targets_scored.csv')\n\n# train_target","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, y_train = preprocess(train_features, train_target)\ntest_zero_mask = test_features.cp_type == 'ctl_vehicle'\nx_test, _ = preprocess(test_features, is_train=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Autoencoder(nn.Module):\n    def __init__(self, n_inputs, dropout=0.1):# encoding_dim=64, dropout=0.1):\n        super().__init__()\n        self.encoder = nn.Sequential(\n            nn.BatchNorm1d(n_inputs),\n            nn.Dropout(dropout),\n            nn.Linear(n_inputs, n_inputs // 2), #4 * encoding_dim),\n            nn.ReLU(),\n            \n            nn.BatchNorm1d(n_inputs // 2), #4 * encoding_dim),\n            nn.Dropout(dropout),\n            nn.Linear(n_inputs // 2, n_inputs // 4),# 2 * encoding_dim),\n            nn.ReLU(),\n            \n            nn.BatchNorm1d(n_inputs // 4), #2 * encoding_dim),\n            nn.Dropout(dropout),\n            nn.Linear(n_inputs // 4, n_inputs // 8), #2 * encoding_dim,  encoding_dim),\n            nn.ReLU()\n        )\n        \n        self.decoder = nn.Sequential(\n            nn.Linear(n_inputs // 8, n_inputs // 4),#encoding_dim, 2 * encoding_dim),\n            nn.ReLU(),            \n            nn.BatchNorm1d(n_inputs // 4),#2 * encoding_dim),\n            nn.Dropout(dropout),\n            \n            nn.Linear(n_inputs // 4, n_inputs // 2),#2 * encoding_dim, 4 * encoding_dim),\n            nn.ReLU(),            \n            nn.BatchNorm1d(n_inputs // 2),#4 * encoding_dim),\n            nn.Dropout(dropout),\n            \n            nn.Linear(n_inputs // 2, n_inputs)#4 * encoding_dim, n_inputs)\n        )\n\n    def forward(self, x):\n        encoded = self.encoder(x)\n        decoded = self.decoder(encoded)\n        return decoded","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gen_f = [col for col in x_train.columns if col.startswith('g-')]\ncell_f = [col for col in x_train.columns if col.startswith('c-')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_cell, x_test_cell = train_test_split(x_train[cell_f], test_size = 0.2, random_state=111)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = TensorDataset(torch.tensor(x_train_cell.values, dtype=torch.float32),\n                              torch.tensor(x_train_cell.values, dtype=torch.float32))\ntest_dataset = TensorDataset(torch.tensor(x_test_cell.values, dtype=torch.float32),\n                             torch.tensor(x_test_cell.values, dtype=torch.float32))\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=256)\ntest_dataloader = DataLoader(test_dataset, batch_size=256)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cells_autoencoder = Autoencoder(len(cell_f))\n\noptimizer = torch.optim.Adam(cells_autoencoder.parameters(), weight_decay=1e-3)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, eps=1e-4)\n\ntrain_model(cells_autoencoder, train_dataloader, test_dataloader, max_epoch=30, criterion=nn.MSELoss())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with torch.no_grad():\n    ae_cells_train = cells_autoencoder.encoder(torch.tensor(x_train[cell_f].values, dtype=torch.float32)).numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_gen, x_test_gen = train_test_split(x_train[gen_f], test_size = 0.2, random_state=111)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = TensorDataset(torch.tensor(x_train_gen.values, dtype=torch.float32),\n                              torch.tensor(x_train_gen.values, dtype=torch.float32))\ntest_dataset = TensorDataset(torch.tensor(x_test_gen.values, dtype=torch.float32),\n                             torch.tensor(x_test_gen.values, dtype=torch.float32))\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=256)\ntest_dataloader = DataLoader(test_dataset, batch_size=256)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gen_autoencoder = Autoencoder(len(gen_f))#, encoding_dim=128)\n\noptimizer = torch.optim.Adam(gen_autoencoder.parameters(), weight_decay=1e-3)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, eps=1e-4)\n\ntrain_model(gen_autoencoder, train_dataloader, test_dataloader, max_epoch=30, criterion=nn.MSELoss())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with torch.no_grad():\n    ae_gen_train = gen_autoencoder.encoder(torch.tensor(train_features[gen_f].values, dtype=torch.float32)).numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_enc = pd.DataFrame(np.concatenate((ae_gen_train, ae_cells_train),axis=1))\ntrain_enc = pd.concat((x_train, train_enc), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ensemble = train_ensemble(train_enc, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.save('best_ensemble_pca.npy', ensemble)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ensemble = np.load('best_ensemble_pca.npy', allow_pickle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with torch.no_grad():\n    ae_gen_test= gen_autoencoder.encoder(torch.tensor(x_test[gen_f].values, dtype=torch.float32)).numpy()\n    ae_cells_test = cells_autoencoder.encoder(torch.tensor(x_test[cell_f].values, dtype=torch.float32)).numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_enc = pd.DataFrame(np.concatenate((ae_gen_test, ae_cells_test),axis=1))\ntest_enc = pd.concat((x_test, test_enc), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ensemble = np.load('../input/nn-ensemble-for-moa-predictions/best_ensemble_pca.npy', allow_pickle=True).tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model.eval()\n# with torch.no_grad():\n#     preds = model(torch.tensor(x_test.values, dtype=torch.float32))\n\npreds = []\nfor model in ensemble:\n    model.eval()\n    with torch.no_grad():\n        preds += [model(torch.tensor(test_enc.values, dtype=torch.float32, device='cuda'))]\n\npreds = torch.stack(preds, dim=0).mean(dim=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds[test_zero_mask] = 0.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission = pd.read_csv(data_dir + 'sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.iloc[:, 1:] = preds.cpu()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}