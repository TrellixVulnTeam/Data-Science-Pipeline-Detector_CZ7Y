{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Соревнование \"Mechanisms of Action (MoA) Prediction\"\n\n### Александр Чернышёв"},{"metadata":{},"cell_type":"markdown","source":"## Импорт библиотек"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport sys\nimport time\nimport copy\nimport functools\nimport platform\nimport random\nimport tempfile\nfrom argparse import Namespace\nfrom pathlib import Path\n\nfrom tqdm.notebook import tqdm\n\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import log_loss\n\nsys.path.append('../input/iterative-stratification/iterative-stratification-master')\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n\nfrom catboost import CatBoostClassifier\n\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n# import torchsummary","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Устанавливаем сиды для генераторов случайных чисел"},{"metadata":{"trusted":true},"cell_type":"code","source":"dtype = torch.float32\ndevice = torch.device('cuda:0')\nseed = 123456\n\n\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_everything(seed=seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Считываем данные"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_path = './data/' if 'windows' in platform.platform().lower() else '../input/lish-moa/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features = pd.read_csv(data_path + 'train_features.csv')\ntest_features = pd.read_csv(data_path + 'test_features.csv')\ntrain_targets_scored = pd.read_csv(data_path + 'train_targets_scored.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features.shape, train_targets_scored.shape, test_features.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Класс датасета для обучения нейронных сетей"},{"metadata":{"trusted":true},"cell_type":"code","source":"class MoADataset(Dataset):\n    def __init__(self, dtype, features, targets=None, feature_columns=None):\n        self.dtype = dtype\n\n        if isinstance(features, (pd.DataFrame, pd.Series)):\n            if feature_columns is not None:\n                features = features[feature_columns]\n            features = features.values\n        self.features = torch.tensor(features, dtype=self.dtype)\n        self.feature_columns = feature_columns\n\n        if targets is None:\n            targets = -np.ones(self.features.shape[0])  # фиктивный таргет, если идет инференс модели\n        elif isinstance(targets, (pd.DataFrame, pd.Series)):\n            targets = targets.values\n        self.targets = torch.tensor(targets, dtype=self.dtype)\n\n    def __getitem__(self, i):\n        return self.features[i], self.targets[i]\n\n    def __len__(self):\n        return self.features.shape[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Предобработка данных"},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepare_data(features, targets=None, OHE=True, scale=True, scaler=StandardScaler()):\n    zero_moa_mask = (features.cp_type == 'ctl_vehicle').values\n    features_enc = features[~zero_moa_mask].copy()\n#     if targets is not None:\n#         targets = targets[~zero_moa_mask]\n\n    if scale:\n        features_enc.cp_time = features_enc.cp_time.astype(float)\n        float_mask = features_enc.dtypes == 'float64'\n        if targets is not None:\n            scaler.fit(features_enc.loc[:, float_mask])\n        features_enc.loc[:, float_mask] = scaler.transform(features_enc.loc[:, float_mask])\n\n#     features_enc = standard_scaler(features)\n\n    # TODO: Здесь могут быть проблемы с тем, что тест и трейн обработаются по-разному!\n#     features_enc = features\n    if OHE:\n#         features_enc = pd.get_dummies(features_enc, columns=['cp_type', 'cp_dose'])\n        features_enc.cp_type = (features_enc.cp_type == 'ctl_vehicle').astype(float)\n        features_enc.cp_dose = (features_enc.cp_dose == 'D2').astype(float)\n#         features_enc.cp_time = features_enc.cp_time == 'D2'\n    features_enc = features_enc.drop(columns=['sig_id'])\n#     feature_columns = features_enc.drop(columns=['sig_id']).columns.values\n\n    if targets is None:\n        return features_enc.values, zero_moa_mask  # , zero_moa_mask  # , feature_columns\n\n    targets_enc = targets.copy()[~zero_moa_mask].drop(columns=['sig_id'])\n#     targets_enc = targets.drop(columns=['sig_id'])  # .columns.values\n    return features_enc.values, targets_enc.values  # , zero_moa_mask  # , feature_columns, target_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Разбивать надо сначала, а потом уже обрабатывать\n\n# train_features_tr, train_features_val, train_targets_scored_tr, train_targets_scored_val = \\\n#     train_test_split(train_features, train_targets_scored, test_size=0.2, random_state=seed, shuffle=True)\n\n\n# train_features_tr, train_targets_scored_tr, train_zero_moa_mask_tr = \\\n#     prepare_data(train_features_tr, train_targets_scored_tr, OHE=False)\n# train_features_val, train_targets_scored_val, train_zero_moa_mask_val = \\\n#     prepare_data(train_features_val, train_targets_scored_val, OHE=False)\n# train_features_enc, train_targets_scored_enc, train_zero_moa_mask_enc = \\\n#     prepare_data(train_features, train_targets_scored, OHE=False)\n\n# test_features_enc, test_zero_moa_mask_enc = prepare_data(test_features, OHE=False)\n\n\n# for i, target in enumerate(train_targets_scored_tr.columns):\n#     assert train_targets_scored_tr[target].unique().shape[0] == 2, (i, target)\n\n\n# train_features_tr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_enc, train_targets_scored_enc = prepare_data(train_features, train_targets_scored)\n\ntest_features_enc, test_zero_moa_mask = prepare_data(test_features, OHE=True)\n\n\ntrain_features_enc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### OLD CODE ###\n\n# def prepare_data(features, targets=None):\n#     # TODO: Здесь могут быть проблемы с тем, что тест и трейн обработаются по-разному!\n#     features_enc = pd.get_dummies(features, columns=['cp_type', 'cp_dose']).drop(columns=['sig_id'])\n# #     feature_columns = features_enc.drop(columns=['sig_id']).columns.values\n\n#     if targets is None:\n#         return features_enc  # , feature_columns\n\n#     targets_enc = targets.drop(columns=['sig_id'])  # .columns.values\n#     return features_enc, targets_enc  # , feature_columns, target_columns\n\n# train_features_enc, train_targets_scored_enc = prepare_data(train_features, train_targets_scored)\n# test_features_enc = prepare_data(test_features)\n\n# (\n#     train_features_tr, train_features_val,\n#     train_targets_scored_tr, train_targets_scored_val\n# ) = train_test_split(train_features_enc, train_targets_scored_enc, test_size=0.2,\n#                      random_state=seed, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Нейронные сети"},{"metadata":{},"cell_type":"markdown","source":"### Создание датасетов и даталоадеров"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_workers = 0\n\n# TODO: написать функцию для предсказаний (нужно нормально обрабатывать случай с type=='wehicle')\n\n# test_dataset = MoADataset(dtype, test_features_enc)\n# test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n\n# train_dataset = MoADataset(dtype, train_features_tr, train_targets_scored_tr)\n# val_dataset = MoADataset(dtype, train_features_val, train_targets_scored_val)\n\n# train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n# val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Модель"},{"metadata":{"trusted":true},"cell_type":"code","source":"class MoAModel(nn.Module):\n    def __init__(self, device, dtype, num_in_features, num_hidden_features, num_out_features, dropout_rate=0.5):\n        super().__init__()\n\n        self.device = device\n        self.dtype = dtype\n\n        self.net = nn.Sequential(\n            nn.BatchNorm1d(num_in_features),\n            nn.Dropout(0.2),\n            nn.utils.weight_norm(nn.Linear(num_in_features, 2 * num_hidden_features)),  # nn.utils.weight_norm(),\n            nn.ReLU(),  # nn.ELU(),\n            nn.BatchNorm1d(2 * num_hidden_features),\n            nn.Dropout(dropout_rate),\n\n            nn.utils.weight_norm(nn.Linear(2 * num_hidden_features, num_hidden_features)),\n            nn.ReLU(),  # nn.ELU(),\n            nn.BatchNorm1d(num_hidden_features),\n            nn.Dropout(dropout_rate),\n\n            nn.utils.weight_norm(nn.Linear(num_hidden_features, num_out_features)),\n        ).to(self.device)\n\n    def forward(self, x):\n        return self.net(x.to(self.device, self.dtype))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Функции для обучения и вывода процесса обучения на экран"},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_results(cur_results, mode, cur_iter, print_every):\n    if print_every == 'summary':\n        print(\n            f'Summary: epoch {cur_results.epoch + 1:3}, '\n            f'mode {mode:6}, ',\n            end=''\n        )\n\n        if mode != 'test':\n            losses = cur_results.train_loss if mode == 'train' else cur_results.val_loss\n            print(\n                f'loss {np.mean(losses):12.5f}, '\n            )\n        else:\n            print()\n    elif cur_iter % print_every == 0:\n        print(\n            f'Epoch {cur_results.epoch + 1:3}, '\n            f'mode {mode:6}, '\n            f'iter {cur_iter:5}, ',\n            end=''\n        )\n\n        if mode != 'test':\n            losses = cur_results.train_loss if mode == 'train' else cur_results.val_loss\n            print(\n                f'loss {losses[-1]:12.5f}, '\n            )\n        else:\n            print()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@functools.total_ordering\nclass ModelWithScore:\n    def __init__(self, score, model):\n        self.score = score\n        self.model = copy.deepcopy(model)\n\n    def __eq__(self, other):\n        return self.score == other.score\n\n    def __lt__(self, other):\n        return self.score < other.score\n\n#     def __hash__(self):\n#         return hash(self.score)\n\n    def __repr__(self):\n        return f'Model of type \"{type(self.model).__name__}\" with score {self.score}'\n\n# ModelWithScore(0.1, [1, 2, 3]) < ModelWithScore(0.5, [1, 2, 3, 4, 5])\n# ModelWithScore(0.1, [1, 2, 3]) == ModelWithScore(0.1, [1, 2, 3, 4, 5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_NN(model, criterion, optimizer, lr_scheduler,\n             max_epoch, print_every,  # lr,\n             train_dataloader, val_dataloader, test_features_enc, test_zero_moa_mask):\n    # History\n    results = Namespace(\n        epochs=[],\n#         lr=[],\n        train_loss=[],\n        val_loss=[],\n        test_preds=[],\n        best_models=[],\n        model=model,\n        criterion=criterion,\n        optimizer=optimizer,\n        lr_scheduler=lr_scheduler,\n        max_epoch=max_epoch,\n        init_lr=lr,\n        print_every=print_every,\n        train_dataloader=train_dataloader,\n        val_dataloader=val_dataloader,\n        test_features_enc=test_features_enc\n    )\n    \n\n    for epoch in tqdm(range(max_epoch), desc='Epoch'):\n        results.epochs.append(epoch)\n\n        # Training\n        model.train()\n\n        train_loss = 0\n        for cur_iter, (x, y) in enumerate(train_dataloader):\n            optimizer.zero_grad()\n\n            scores = model(x)\n            loss = criterion(scores, y.to(device))\n\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item()\n#             cur_results.train_loss.append(loss.item())\n#             cur_results.lr.append(lr_scheduler.get_last_lr()[0])\n#             print_results(cur_results, 'train', cur_iter, print_every)\n#         print_results(cur_results, 'train', -1, print_every='summary')\n        train_loss /= len(train_dataloader)\n        results.train_loss.append(train_loss)\n#         lr_scheduler.step()\n\n        # Validation\n        model.eval()\n\n        val_loss = 0\n        for cur_iter, (x, y) in enumerate(val_dataloader):\n            with torch.no_grad():\n                scores = model(x)\n            loss = criterion(scores, y.to(device))\n#             cur_results.val_loss.append(loss.item())\n            val_loss += loss.item()\n        val_loss /= len(val_dataloader)\n        results.val_loss.append(val_loss)\n        \n        results.best_models.append(ModelWithScore(val_loss, model))\n        if len(results.best_models) > 3:\n            results.best_models.remove(max(results.best_models))\n\n#             print_results(cur_results, 'val', cur_iter, print_every)\n#         print_results(cur_results, 'val', -1, print_every='summary')\n        print(f'Epoch {epoch + 1:2}, train loss {train_loss:7.5f}, val loss {val_loss:7.5f}')  # , iter {cur_iter + 1:2}\n\n        # Test predictions\n        test_preds = predict(model, test_features_enc=test_features_enc, zero_moa_mask=test_zero_moa_mask)\n#         model.eval()\n#         for cur_iter, (x, y) in enumerate(test_dataloader):\n#             with torch.no_grad():\n#                 scores = model(x)\n#             preds = torch.sigmoid(scores)\n#             cur_results.test_preds.append(preds.cpu())\n\n#     #         print_results(cur_results, 'test', cur_iter, print_every)\n#         print_results(cur_results, 'test', -1, print_every='summary')\n        results.test_preds.append(test_preds)\n\n\n    return results","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Функция предсказания модели"},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(model, test_features=None, test_features_enc=None, zero_moa_mask=None):\n    if test_features is not None:\n        test_features_enc, zero_moa_mask = prepare_data(test_features, OHE=True)\n\n    test_dataset = MoADataset(dtype, test_features_enc)\n    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n\n    probs = []\n\n    model.eval()\n    for x, y in test_dataloader:\n        with torch.no_grad():\n            scores = model(x)\n        cur_probs = torch.sigmoid(scores).cpu()\n        probs.append(cur_probs)\n\n    probs = torch.cat(probs)\n\n    answer = pd.read_csv(data_path + 'sample_submission.csv')\n    answer.iloc[~zero_moa_mask, 1:] = probs\n    answer.iloc[zero_moa_mask, 1:] = 0\n#     answer.to_csv('submission.csv', index=False)\n    return answer","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Константы для датасета"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_in_features = train_features_enc.shape[1]\nnum_out_features = train_targets_scored_enc.shape[1]\n\nnum_hidden_features = 512 * 2 # 1024","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model = MoAModel('cpu', dtype, num_in_features, num_hidden_features, num_out_features)\n# predict(model, test_features)\n# # torchsummary.summary(model);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print_every = 5\n\nmax_epoch = 45\nlr = 1e-3\n\ncriterion = nn.BCEWithLogitsLoss()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model():\n    model = MoAModel(device, dtype, num_in_features, num_hidden_features, num_out_features)\n    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n    lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=26, gamma=0.1)\n\n    return model, optimizer, lr_scheduler","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# model = MoAModel(device, dtype, num_in_features, num_hidden_features, num_out_features)\n\n# optimizer = optim.Adam(model.parameters(), lr=lr)\n# lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=1/3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Обучение по фолдам"},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 2 ** 7\n\nn_folds = 7","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"def train_NN_by_folds(n_folds, models_path):\n#     models_path = 'nn-models/01/'\n\n    Path(models_path).mkdir(parents=True, exist_ok=False)\n\n    kfold = MultilabelStratifiedKFold(n_splits=n_folds, shuffle=True, random_state=517)#seed)\n\n    models = []\n\n    for i, (train, val) in enumerate(tqdm(\n        kfold.split(train_features_enc, train_targets_scored_enc),  # [~train_zero_moa_mask_enc]),\n        total=kfold.n_splits\n    )):\n        print()\n        print(f'\\tFold {i + 1}')\n        x_tr = train_features_enc[train]\n        y_tr = train_targets_scored_enc[train]\n        x_val = train_features_enc[val]\n        y_val = train_targets_scored_enc[val]\n    #     x_tr = train_features_enc.iloc[train]\n    #     y_tr = train_targets_scored_enc.iloc[train]\n    #     x_val = train_features_enc.iloc[val]\n    #     y_val = train_targets_scored_enc.iloc[val]\n\n        train_dataset = MoADataset(dtype, x_tr, y_tr)\n        val_dataset = MoADataset(dtype, x_val, y_val)\n\n        train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n        val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n\n\n        model, optimizer, lr_scheduler = create_model()\n\n        result = train_NN(model, criterion, optimizer, lr_scheduler,\n                          max_epoch, print_every,\n                          train_dataloader, val_dataloader, test_features_enc, test_zero_moa_mask)\n\n    #     torch.save(model.state_dict(), f'{models_path}/NN_model_kfold_{i + 1}')\n    #     np.save('')\n        np.save(f'{models_path}/best_models_kfold_{i + 1}', result.best_models)\n\n        models.append(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models_path = '../input/nn-top3ensemble-with-cv7/nn-models/02/'  # 'nn-models/01/'\n\n# train_NN_by_folds(n_folds, models_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_preds = []\n\nfor i in tqdm(range(n_folds)):\n    results = np.load(f'{models_path}/best_models_kfold_{i + 1}.npy', allow_pickle=True)\n\n    for best_model in results:\n        preds = predict(best_model.model, test_features_enc=test_features_enc, zero_moa_mask=test_zero_moa_mask)\n        all_preds.append(preds.iloc[:, 1:].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"answer = preds.copy()\nanswer.iloc[:, 1:] = np.array(all_preds).mean(axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"answer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"answer.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}