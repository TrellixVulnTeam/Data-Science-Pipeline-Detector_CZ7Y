{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport platform\nimport random\nfrom argparse import Namespace\n\nfrom tqdm.notebook import tqdm\n\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n# import torchsummary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtype = torch.float32\ndevice = torch.device('cuda:0')\nseed = 12345\n\n\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_everything(seed=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_path = './data/' if 'windows' in platform.platform().lower() else '../input/lish-moa/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features = pd.read_csv(data_path + 'train_features.csv')\ntest_features = pd.read_csv(data_path + 'test_features.csv')\ntrain_targets_scored = pd.read_csv(data_path + 'train_targets_scored.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features.shape, train_targets_scored.shape, test_features.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MoADataset(Dataset):\n    def __init__(self, dtype, features, targets=None, feature_columns=None):\n        self.dtype = dtype\n\n        if isinstance(features, (pd.DataFrame, pd.Series)):\n            if feature_columns is not None:\n                features = features[feature_columns]\n            features = features.values\n        self.features = torch.tensor(features, dtype=self.dtype)\n        self.feature_columns = feature_columns\n\n        if targets is None:\n            targets = -np.ones(self.features.shape[0])  # фиктивный таргет, если идет инференс модели\n        elif isinstance(targets, (pd.DataFrame, pd.Series)):\n            targets = targets.values\n        self.targets = torch.tensor(targets, dtype=self.dtype)\n\n    def __getitem__(self, i):\n        return self.features[i], self.targets[i]\n#         return {\n#             'x': self.features[i],\n#             'y': self.targets[i]\n#         }\n\n    def __len__(self):\n        return self.features.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepare_data(features, targets=None):\n    # TODO: Здесь могут быть проблемы с тем, что тест и трейн обработаются по-разному!\n    features_enc = pd.get_dummies(features, columns=['cp_type', 'cp_dose']).drop(columns=['sig_id'])\n#     feature_columns = features_enc.drop(columns=['sig_id']).columns.values\n\n    if targets is None:\n        return features_enc  # , feature_columns\n\n    targets_enc = targets.drop(columns=['sig_id'])  # .columns.values\n    return features_enc, targets_enc  # , feature_columns, target_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_enc, train_targets_scored_enc = prepare_data(train_features, train_targets_scored)\ntest_features_enc = prepare_data(test_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(\n    train_features_tr, train_features_val,\n    train_targets_scored_tr, train_targets_scored_val\n) = train_test_split(train_features_enc, train_targets_scored_enc, test_size=0.2,\n                     random_state=seed, shuffle=True)\n\ntrain_dataset = MoADataset(dtype, train_features_tr, train_targets_scored_tr)\nval_dataset = MoADataset(dtype, train_features_val, train_targets_scored_val)\ntest_dataset = MoADataset(dtype, test_features_enc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 2 ** 8  # 1024\nnum_workers = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\nval_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\ntest_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MoAModel(nn.Module):\n    def __init__(self, device, dtype, num_in_features, num_hidden_features, num_out_features, dropout_rate=0.5):\n        super().__init__()\n\n        self.device = device\n        self.dtype = dtype\n\n        self.net = nn.Sequential(\n            nn.BatchNorm1d(num_in_features),  # вместо нормирования входных данных\n\n            nn.Linear(num_in_features, num_hidden_features),\n            nn.BatchNorm1d(num_hidden_features),\n            nn.ReLU(),\n            nn.Dropout(dropout_rate),\n\n            nn.Linear(num_hidden_features, num_hidden_features),\n            nn.BatchNorm1d(num_hidden_features),\n            nn.ReLU(),\n            nn.Dropout(dropout_rate),\n\n            nn.Linear(num_hidden_features, num_out_features)\n        ).to(self.device)\n\n    def forward(self, x):\n        return self.net(x.to(self.device, self.dtype))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_results(cur_results, mode, cur_iter, print_every):\n    if print_every == 'summary':\n        print(\n            f'Summary: epoch {cur_results.epoch + 1:3}, '\n            f'mode {mode:6}, ',\n            end=''\n        )\n\n        if mode != 'test':\n            losses = cur_results.train_loss if mode == 'train' else cur_results.val_loss\n            print(\n                f'loss {np.mean(losses):12.5f}, '\n            )\n        else:\n            print()\n    elif cur_iter % print_every == 0:\n        print(\n            f'Epoch {cur_results.epoch + 1:3}, '\n            f'mode {mode:6}, '\n            f'iter {cur_iter:5}, ',\n            end=''\n        )\n\n        if mode != 'test':\n            losses = cur_results.train_loss if mode == 'train' else cur_results.val_loss\n            print(\n                f'loss {losses[-1]:12.5f}, '\n            )\n        else:\n            print()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"num_in_features = train_features_enc.shape[1]\nnum_out_features = train_targets_scored_enc.shape[1]\n\nnum_hidden_features = 1024\n\n\nmodel = MoAModel(device, dtype, num_in_features, num_hidden_features, num_out_features)\n\n# torchsummary.summary(model);\n\n\n\nprint_every = 5\n\nmax_epoch = 100\nlr = 1e-3\n\n\n\ncriterion = nn.BCEWithLogitsLoss()\n\noptimizer = optim.Adam(model.parameters(), lr=lr)\nlr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1)  # len(train_dataset) // batch_size)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# results = []\n\n# for epoch in tqdm(range(max_epoch), desc='Epoch'):\n#     # History\n#     cur_results = Namespace(\n#         epoch=epoch,\n#         train_loss=[],\n#         lr=[],\n#         val_loss=[],\n#         test_preds=[],\n#     )\n\n#     # Training\n#     model.train()\n#     for cur_iter, (x, y) in enumerate(train_dataloader):\n#         optimizer.zero_grad()\n\n#         scores = model(x)\n#         loss = criterion(scores, y.to(device))\n\n#         loss.backward()\n#         optimizer.step()\n\n#         cur_results.train_loss.append(loss.item())\n#         cur_results.lr.append(lr_scheduler.get_last_lr()[0])\n\n# #         print_results(cur_results, 'train', cur_iter, print_every)\n#     print_results(cur_results, 'train', -1, print_every='summary')\n\n#     lr_scheduler.step()\n\n#     # Validation\n#     model.eval()\n#     for cur_iter, (x, y) in enumerate(val_dataloader):\n#         with torch.no_grad():\n#             scores = model(x)\n#         loss = criterion(scores, y.to(device))\n#         cur_results.val_loss.append(loss.item())\n\n# #         print_results(cur_results, 'val', cur_iter, print_every)\n#     print_results(cur_results, 'val', -1, print_every='summary')\n\n#     # Test predictions\n#     model.eval()\n#     for cur_iter, (x, y) in enumerate(test_dataloader):\n#         with torch.no_grad():\n#             scores = model(x)\n#         preds = torch.sigmoid(scores)\n#         cur_results.test_preds.append(preds.cpu())\n\n# #         print_results(cur_results, 'test', cur_iter, print_every)\n#     print_results(cur_results, 'test', -1, print_every='summary')\n\n#     results.append(cur_results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(\n    train_features_tr, train_features_val,\n    train_targets_scored_tr, train_targets_scored_val\n) = train_test_split(train_features_enc, train_targets_scored_enc, test_size=0.2,\n                     random_state=seed, shuffle=True)\n\ntrain_dataset = MoADataset(dtype, train_features_enc, train_targets_scored_enc)\n# val_dataset = MoADataset(dtype, train_features_val, train_targets_scored_val)\ntest_dataset = MoADataset(dtype, test_features_enc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 2 ** 8  # 1024\nnum_workers = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n# val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\ntest_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = []\n\nfor epoch in tqdm(range(max_epoch), desc='Epoch'):\n    # History\n    cur_results = Namespace(\n        epoch=epoch,\n        train_loss=[],\n        lr=[],\n        val_loss=[],\n        test_preds=[],\n    )\n\n    # Training\n    model.train()\n    for cur_iter, (x, y) in enumerate(train_dataloader):\n        optimizer.zero_grad()\n\n        scores = model(x)\n        loss = criterion(scores, y.to(device))\n\n        loss.backward()\n        optimizer.step()\n\n        cur_results.train_loss.append(loss.item())\n        cur_results.lr.append(lr_scheduler.get_last_lr()[0])\n\n#         print_results(cur_results, 'train', cur_iter, print_every)\n    print_results(cur_results, 'train', -1, print_every='summary')\n\n    lr_scheduler.step()\n\n#     # Validation\n#     model.eval()\n#     for cur_iter, (x, y) in enumerate(val_dataloader):\n#         with torch.no_grad():\n#             scores = model(x)\n#         loss = criterion(scores, y.to(device))\n#         cur_results.val_loss.append(loss.item())\n\n# #         print_results(cur_results, 'val', cur_iter, print_every)\n#     print_results(cur_results, 'val', -1, print_every='summary')\n\n    # Test predictions\n    model.eval()\n    for cur_iter, (x, y) in enumerate(test_dataloader):\n        with torch.no_grad():\n            scores = model(x)\n        preds = torch.sigmoid(scores)\n        cur_results.test_preds.append(preds.cpu())\n\n#         print_results(cur_results, 'test', cur_iter, print_every)\n    print_results(cur_results, 'test', -1, print_every='summary')\n\n    results.append(cur_results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results[-1].val_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset.__len__()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_preds = [torch.cat(result.test_preds) for result in results[9::5]]\ntest_preds = [torch.cat(result.test_preds) for result in results[99:]]\nensemble_test_preds = torch.stack(test_preds, dim=0)\nfinal_test_preds = ensemble_test_preds.mean(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_test_preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# best_idx = final_test_preds.argsort(dim=1)\n\n# test_predictions = []\n\n# keep_num_best = 3\n# for final_test_pred, bad_idx in zip(final_test_preds, best_idx[:, :-keep_num_best]):\n#     final_test_pred[bad_idx] = 0\n#     test_predictions.append(final_test_pred)\n\n# test_predictions = torch.stack(test_predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"answer = pd.read_csv(data_path + 'sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"answer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"answer.iloc[:, 1:] = final_test_preds  # test_predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"answer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"answer.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}