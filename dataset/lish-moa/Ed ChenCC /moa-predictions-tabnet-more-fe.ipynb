{"cells":[{"metadata":{},"cell_type":"markdown","source":"<div class = \"alert alert-block alert-info\">\n    <h1><font color = \"red\">DISCLAIMER</font></h1>\n    <p>The following notebook it's highly based on the works <a href = \"https://www.kaggle.com/optimo/tabnetregressor-2-0-train-infer\">TabNetRegressor 2.0 [TRAIN + INFER]</a>, <a href = \"https://www.kaggle.com/liuhdme/moa-competition/data\">MOA competition</a> and <a href = \"https://www.kaggle.com/kushal1506/moa-pytorch-0-01859-rankgauss-pca-nn/data?select=train_targets_scored.csv\">\nMoA | Pytorch | 0.01859 | RankGauss | PCA | NN</a>, please check it out. I have to add that i don't make this notebook for \"upvotes\" but feedback.</p>\n</div>"},{"metadata":{},"cell_type":"markdown","source":"# <font color = \"seagreen\">Preambule</font>\n\nI made this notebook to share some experiments (see the sections \"Experiments\") which could help to someone who don't want to wast their daily \"submissions\", but more importantly, to get feedback about what i could change to achive a better CV. Moreover, the easiness of TabNet to overfit the data it's disturbing. In the section \"Conclusion\" i share my opinion about the fine-tuning process of TabNet."},{"metadata":{},"cell_type":"markdown","source":"## <font color = \"green\">Installing Libraries</font>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# TabNet\n# !pip install pytorch-tabnet\n!pip install --no-index --find-links /kaggle/input/pytorchtabnet/pytorch_tabnet-2.0.0-py3-none-any.whl pytorch-tabnet\n# Iterative Stratification\n!pip install /kaggle/input/iterative-stratification/iterative-stratification-master/","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font color = \"green\">Loading Libraries</font>"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"### General ###\nimport os\nimport sys\nimport copy\nimport tqdm\nimport pickle\nimport random\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nsys.path.append(\"../input/rank-gauss\")\nos.environ[\"CUDA_LAUNCH_BLOCKING\"] = '1'\n\n### Data Wrangling ###\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\nfrom gauss_rank_scaler import GaussRankScaler\n\n### Data Visualization ###\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.style.use(\"fivethirtyeight\")\n\n### Machine Learning ###\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import roc_auc_score, log_loss\nfrom sklearn.preprocessing import QuantileTransformer\nfrom sklearn.feature_selection import VarianceThreshold\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n\n### Deep Learning ###\nimport torch\nfrom torch import nn\nimport torch.optim as optim\nfrom torch.nn import functional as F\nfrom torch.nn.modules.loss import _WeightedLoss\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\n# Tabnet \nfrom pytorch_tabnet.metrics import Metric\nfrom pytorch_tabnet.tab_model import TabNetRegressor\n\n### Make prettier the prints ###\nfrom colorama import Fore\nc_ = Fore.CYAN\nm_ = Fore.MAGENTA\nr_ = Fore.RED\nb_ = Fore.BLUE\ny_ = Fore.YELLOW\ng_ = Fore.GREEN","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font color = \"green\">Reproducibility</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"seed = 42\n\ndef set_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    \n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\nset_seed(seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font color = \"green\">Configuration</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Parameters\ndata_path = \"../input/lish-moa/\"\nno_ctl = True\nscale = \"rankgauss\"\nvariance_threshould = 0.7\ndecompo = \"PCA\"\nncompo_genes = 80\nncompo_cells = 10\nencoding = \"dummy\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(data_path + \"train_features.csv\")\ntargets = pd.read_csv(data_path + \"train_targets_scored.csv\")\ntest = pd.read_csv(data_path + \"test_features.csv\")\ntrain_drug = pd.read_csv(data_path + \"train_drug.csv\")\nsubmission = pd.read_csv(data_path + \"sample_submission.csv\")\nprint(train.shape,test.shape)\nif no_ctl:\n    # cp_type == ctl_vehicle\n    print(b_, \"not_ctl\")\n    train = train[train[\"cp_type\"] != \"ctl_vehicle\"]\n    test = test[test[\"cp_type\"] != \"ctl_vehicle\"]\n    targets = targets.iloc[train.index]\n    train.reset_index(drop = True, inplace = True)\n    test.reset_index(drop = True, inplace = True)\n    targets.reset_index(drop = True, inplace = True)\nprint('Non-control:', train.shape,test.shape)\n\ncols_numeric = [feat for feat in list(train.columns) if feat not in [\"sig_id\", \"cp_type\", \"cp_time\", \"cp_dose\"]]\nmask = (train[cols_numeric].var() >= variance_threshould).values\ntmp = train[cols_numeric].loc[:, mask]\ntrain = pd.concat([train[[\"sig_id\", \"cp_type\", \"cp_time\", \"cp_dose\"]], tmp], axis = 1)\ncols_numeric = [feat for feat in list(train.columns) if feat not in [\"sig_id\", \"cp_type\", \"cp_time\", \"cp_dose\"]]\ntest = pd.concat([test[[\"sig_id\", \"cp_type\", \"cp_time\", \"cp_dose\"]], test.loc[:,cols_numeric]], axis = 1)\nprint('Feature elimination by variance :', train.shape,test.shape)\n\n\nGENES = [col for col in train.columns if col.startswith(\"g-\")]\nCELLS = [col for col in train.columns if col.startswith(\"c-\")]\n\n\n\n\nif scale == \"rankgauss\":\n    print(b_, \"Rank Gauss\")\n    for col in (GENES + CELLS):\n        transformer = QuantileTransformer(n_quantiles=100,random_state=0, output_distribution=\"normal\")   # from optimal commit 9\n        vec_len = len(train[col].values)\n        vec_len_test = len(test[col].values)\n        raw_vec = train[col].values.reshape(vec_len, 1)\n        transformer.fit(raw_vec)\n        \n        train[col] = transformer.transform(raw_vec).reshape(1, vec_len)[0]\n        test[col] = transformer.transform(test[col].values.reshape(vec_len_test, 1)).reshape(1, vec_len_test)[0]\nelse:\n    pass\nprint(\"Rank Gauss:\", train.shape,test.shape)\n\nif decompo == \"PCA\":\n    print(b_, \"PCA\")\n    GENES = [col for col in train.columns if col.startswith(\"g-\")]\n    CELLS = [col for col in train.columns if col.startswith(\"c-\")]\n    \n    pca_genes = PCA(n_components = ncompo_genes, random_state = seed)\n    pca_genes_train = pca_genes.fit_transform(train[GENES])\n    \n    \n    \n    pca_cells = PCA(n_components = ncompo_cells, random_state = seed)\n    pca_cells_train = pca_cells.fit_transform(train[CELLS])\n    \n    pca_genes_train = pd.DataFrame(pca_genes_train, columns = [f\"pca_g-{i}\" for i in range(ncompo_genes)])\n    pca_cells_train = pd.DataFrame(pca_cells_train, columns = [f\"pca_c-{i}\" for i in range(ncompo_cells)])\n    train = pd.concat([train, pca_genes_train, pca_cells_train], axis = 1)\n    \n    pca_genes_test = pca_genes.transform(test[GENES])\n    pca_cells_test = pca_cells.transform(test[CELLS])\n    \n    pca_genes_test = pd.DataFrame(pca_genes_test, columns = [f\"pca_g-{i}\" for i in range(ncompo_genes)])\n    pca_cells_test = pd.DataFrame(pca_cells_test, columns = [f\"pca_c-{i}\" for i in range(ncompo_cells)])\n    test = pd.concat([test, pca_genes_test, pca_cells_test], axis = 1)\nelse:\n    pass\nprint(\"PCA:\", train.shape,test.shape)\n\n\nif encoding == \"dummy\":\n    print(b_, \"One-Hot\")\n    train = pd.get_dummies(train, columns = [\"cp_time\", \"cp_dose\"])\n    test = pd.get_dummies(test, columns = [\"cp_time\", \"cp_dose\"])\nelse:\n    pass\nprint(\"One Hot:\", train.shape,test.shape)\n\n\nfor stats in tqdm.tqdm([\"sum\", \"mean\", \"std\", \"kurt\", \"skew\"]):\n    train[\"g_\" + stats] = getattr(train[GENES], stats)(axis = 1)\n    train[\"c_\" + stats] = getattr(train[CELLS], stats)(axis = 1)    \n    train[\"gc_\" + stats] = getattr(train[GENES + CELLS], stats)(axis = 1)\n    \n    test[\"g_\" + stats] = getattr(test[GENES], stats)(axis = 1)\n    test[\"c_\" + stats] = getattr(test[CELLS], stats)(axis = 1)    \n    test[\"gc_\" + stats] = getattr(test[GENES + CELLS], stats)(axis = 1)\nprint('Extra features:', train.shape,test.shape)\n\ngsquarecols=['g-574','g-211','g-216','g-0','g-255','g-577',\n             'g-153','g-389','g-60','g-370','g-248','g-167',\n             'g-203','g-177','g-301','g-332','g-517','g-6',\n             'g-744','g-224','g-162','g-3','g-736','g-486',\n             'g-283','g-22','g-359','g-361','g-440','g-335',\n             'g-106','g-307','g-745','g-146','g-416','g-298',\n             'g-666','g-91','g-17','g-549','g-145','g-157','g-768','g-568','g-396']\n\nfor df in [train, test]:\n    df['c52_c42'] = df['c-52'] * df['c-42']\n    df['c13_c73'] = df['c-13'] * df['c-73']\n    df['c26_c13'] = df['c-23'] * df['c-13']\n    df['c33_c6'] = df['c-33'] * df['c-6']\n    df['c11_c55'] = df['c-11'] * df['c-55']\n    df['c38_c63'] = df['c-38'] * df['c-63']\n    df['c38_c94'] = df['c-38'] * df['c-94']\n    df['c13_c94'] = df['c-13'] * df['c-94']\n    df['c4_c52'] = df['c-4'] * df['c-52']\n    df['c4_c42'] = df['c-4'] * df['c-42']\n    df['c13_c38'] = df['c-13'] * df['c-38']\n    df['c55_c2'] = df['c-55'] * df['c-2']\n    df['c55_c4'] = df['c-55'] * df['c-4']\n    df['c4_c13'] = df['c-4'] * df['c-13']\n    df['c82_c42'] = df['c-82'] * df['c-42']\n    df['c66_c42'] = df['c-66'] * df['c-42']\n    df['c6_c38'] = df['c-6'] * df['c-38']\n    df['c2_c13'] = df['c-2'] * df['c-13']\n    df['c62_c42'] = df['c-62'] * df['c-42']\n    df['c90_c55'] = df['c-90'] * df['c-55']\n    \n    for feature in gsquarecols:\n        if feature in GENES:\n            df[f'{feature}_squared'] = df[feature] ** 2  \n    for feature in CELLS:\n        df[f'{feature}_squared'] = df[feature] ** 2   \n\ntrain = train.merge(targets, on='sig_id')\ntrain = train.merge(train_drug, on='sig_id')\n\ntarget_cols = [x for x in targets.columns if x != 'sig_id']\n\ntrain_df = train\ntrain_df.reset_index(drop = True, inplace = True)\ntest.reset_index(drop = True, inplace = True)\nfeatures_to_drop = [\"sig_id\", \"cp_type\"]\n\ntest.drop(features_to_drop, axis = 1, inplace = True)\nX_test = test.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_columns', None)\nprint('Train_df shape:', train_df.shape)\nprint('Test shape:', test.shape)\ndisplay(train_df.head())\ndisplay(test.head())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_cols = [c for c in train_df.columns if c not in targets.columns]\nfeature_cols = [c for c in feature_cols if c not in [ 'sig_id', 'drug_id', 'cp_type']]\nprint(train_df.shape)\ndisplay(train_df[feature_cols].head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\n\ndef make_cv_folds(train, SEEDS, NFOLDS, DRUG_THRESH):\n    vc = train.drug_id.value_counts()\n    vc1 = vc.loc[vc <= DRUG_THRESH].index.sort_values()\n    vc2 = vc.loc[vc > DRUG_THRESH].index.sort_values()\n\n    for seed_id in SEEDS:\n        kfold_col = 'kfold_{}'.format(seed_id)\n        \n        # STRATIFY DRUGS 18X OR LESS\n        dct1 = {}\n        dct2 = {}\n\n        skf = MultilabelStratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=seed_id)\n        tmp = train.groupby('drug_id')[target_cols].mean().loc[vc1]\n\n        for fold,(idxT, idxV) in enumerate(skf.split(tmp, tmp[target_cols])):\n            dd = {k: fold for k in tmp.index[idxV].values}\n            dct1.update(dd)\n\n        # STRATIFY DRUGS MORE THAN 18X\n        skf = MultilabelStratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=seed_id)\n        tmp = train.loc[train.drug_id.isin(vc2)].reset_index(drop=True)\n\n        for fold,(idxT, idxV) in enumerate(skf.split(tmp, tmp[target_cols])):\n            dd = {k: fold for k in tmp.sig_id[idxV].values}\n            dct2.update(dd)\n\n        # ASSIGN FOLDS\n        train[kfold_col] = train.drug_id.map(dct1)\n        train.loc[train[kfold_col].isna(), kfold_col] = train.loc[train[kfold_col].isna(), 'sig_id'].map(dct2)\n        train[kfold_col] = train[kfold_col].astype('int8')\n        \n    return train\n\nSEEDS = [x for x in range(42,49)]\nNFOLDS = 10\nDRUG_THRESH = 18\n\ntrain_df = make_cv_folds(train_df, SEEDS, NFOLDS, DRUG_THRESH)\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# features_to_drop = [\"sig_id\", \"cp_type\"]\n# train.drop(features_to_drop, axis = 1, inplace = True)\n# test.drop(features_to_drop, axis = 1, inplace = True)\n# try:\n#     targets.drop(\"sig_id\", axis = 1, inplace = True)\n# except:\n#     pass\n\n# print(train.shape,test.shape)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(train_df.head())\nprint(train_df.shape)\nprint(feature_cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <font color = \"seagreen\">Experiments</font>\n\nI just want to point that the [original work](https://www.kaggle.com/optimo/tabnetregressor-2-0-train-infer) achive a CV of 0.015532370835690834 and a LB score of 0.01864. Some of the experiments that i made with their changes:\n\n\n- CV: 0.01543560538566987, LB: 0.01858, best LB that i could achive, changes\n    - `n_a` = 32 instead of 24\n    - `n_d` = 32 instead of 24\n- CV: 0.015282077428722094, LB: 0.01862, best CV that i could achive, changes (Version 5):\n    - `n_a` = 32 instead of 24\n    - `n_d` = 32 instead of 24\n    - `virtual_batch_size` = 32, instead of 128\n    - `seed` = 42 instead of 0\n- CV: 0.015330138325308062, LB: 01864, the same LB that the original but better CV, changes:\n    - `n_a` = 32 instead of 24\n    - `n_d` = 32 instead of 24\n    - `virtual_batch_size` = 64, instead of 128\n    - `batch_size` = 512, instead of 1024\n- CV: 0.015361751699863063, LB: 0.01863, better LB and CV than the original, changes:\n    - `n_a` = 32 instead of 24\n    - `n_d` = 32 instead of 24\n    - `virtual_batch_size` = 64, instead of 128\n- CV: 0.015529925324634975, LB: 0.01865, changes:\n    - `n_a` = 48 instead of 24\n    - `n_d` = 48 instead of 24\n- CV: 0.015528553520924939, LB: 0.01868, changes:\n    - `n_a` = 12 instead of 24\n    - `n_d` = 12 instead of 24\n- CV: 0.015870202970324317, LB: 0.01876, worst CV and LB score, changes:\n    - `n_a` = 12 instead of 24\n    - `n_d` = 12 instead of 24\n    - `batch_size` = 2048, instead of 1024\n    \n    \nAs you can see if `batch_size` < 1024 and > 1024 give worst results. Something similar happens with `n_a` and `n_d`, if their values are lower or higher than 32 the results are worst.\n\n\n## <font color = \"green\">Versions</font>\n\n- **Version 5**: I added the `seed` parameter to the TabNet model.\n- **Version 6**: I changed the `virtual_batch_size` to 24\n    - CV: 0.01532900616425282, LB: 0.01862, changes:\n        - `n_a` = 32 instead of 24\n        - `n_d` = 32 instead of 24\n        - `virtual_batch_size` = 24, instead of 128\n        - `seed` = 42 instead of 0\n- **Version 7**: PCA, Rank Gauss"},{"metadata":{},"cell_type":"markdown","source":"# <font color = \"seagreen\">Modeling</font>"},{"metadata":{},"cell_type":"markdown","source":"## <font color = \"green\">Model Parameters</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"MAX_EPOCH = 200\n# n_d and n_a are different from the original work, 32 instead of 24\n# This is the first change in the code from the original\ntabnet_params = dict(\n    n_d = 32,\n    n_a = 32,\n    n_steps = 1,\n    gamma = 1.3,\n    lambda_sparse = 0,\n    optimizer_fn = optim.Adam,\n    optimizer_params = dict(lr = 2e-2, weight_decay = 1e-5),\n    mask_type = \"entmax\",\n    scheduler_params = dict(\n        mode = \"min\", patience = 10, min_lr = 1e-5, factor = 0.1),\n    scheduler_fn = ReduceLROnPlateau,\n    seed = seed,\n    verbose = 10\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font color = \"green\">Custom Metric</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"class LogitsLogLoss(Metric):\n    \"\"\"\n    LogLoss with sigmoid applied\n    \"\"\"\n\n    def __init__(self):\n        self._name = \"logits_ll\"\n        self._maximize = False\n\n    def __call__(self, y_true, y_pred):\n        \"\"\"\n        Compute LogLoss of predictions.\n\n        Parameters\n        ----------\n        y_true: np.ndarray\n            Target matrix or vector\n        y_score: np.ndarray\n            Score matrix or vector\n\n        Returns\n        -------\n            float\n            LogLoss of predictions vs targets.\n        \"\"\"\n        logits = 1 / (1 + np.exp(-y_pred))\n        aux = (1 - y_true) * np.log(1 - logits + 1e-15) + y_true * np.log(logits + 1e-15)\n        return np.mean(-aux)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <font color = \"seagreen\">Training</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"targets.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores_auc_all = []\ntest_cv_preds = []\n\noof_preds = []\noof_targets = []\nscores = []\nscores_auc = []\noof_all = np.zeros((train_df.shape[0], targets[target_cols].shape[1]))\n# SEED = [42,43,44] # \n# SEED = [42]\nfor s in SEEDS:\n    oof = np.zeros((train_df.shape[0], targets[target_cols].shape[1]))\n    tabnet_params['seed'] = s\n    for fold_id in range(NFOLDS):\n        print(b_,\"FOLDS: \", r_, fold_id + 1, y_, 'seed:', tabnet_params['seed'])\n        print(g_, '*' * 60, c_)\n        \n        kfold_col = f'kfold_{s}'\n        trn_idx = train_df[train_df[kfold_col] != fold_id].index\n        val_idx = train_df[train_df[kfold_col] == fold_id].index\n    \n#         train_df = train_[train_[kfold_col] != fold_id].reset_index(drop=True)\n#         valid_df = train_[train_[kfold_col] == fold_id].reset_index(drop=True)\n        \n        \n        X_train, y_train = train_df[feature_cols].values[trn_idx, :], targets[target_cols].values[trn_idx, :]\n        X_val, y_val = train_df[feature_cols].values[val_idx, :], targets[target_cols].values[val_idx, :]\n        ### Model ###\n        model = TabNetRegressor(**tabnet_params)\n        \n        ### Fit ###\n        # Another change to the original code\n        # virtual_batch_size of 32 instead of 128\n        model.fit(\n            X_train = X_train,\n            y_train = y_train,\n            eval_set = [(X_val, y_val)],\n            eval_name = [\"val\"],\n            eval_metric = [\"logits_ll\"],\n            max_epochs = MAX_EPOCH,\n            patience = 30,\n            batch_size = 1024, \n            virtual_batch_size = 32,\n            num_workers = 1,\n            drop_last = False,\n            # To use binary cross entropy because this is not a regression problem\n            loss_fn = F.binary_cross_entropy_with_logits\n        )\n        print(y_, '-' * 60)\n        \n        saving_path_name = 'TabNet_seed_'+str(tabnet_params['seed'])+'_fold_'+str(fold_id+1)\n        saved_filepath = model.save_model(saving_path_name)\n        print(saved_filepath)\n\n        loaded_model =  TabNetRegressor()\n#         loaded_model.load_model(saved_filepath)\n        loaded_model.load_model(saving_path_name+'.zip')\n\n        ### Predict on validation ###\n#         preds_val = model.predict(X_val)\n        preds_val = loaded_model.predict(X_val)\n        # Apply sigmoid to the predictions\n        preds = 1 / (1 + np.exp(-preds_val))\n        score = np.min(model.history[\"val_logits_ll\"])\n#         loaded_model.history[\"val_logits_ll\"] = model.history[\"val_logits_ll\"]\n        \n        # Added oof part\n        oof[val_idx] = preds\n    \n        ### Save OOF for CV ###\n        oof_preds.append(preds_val)\n        oof_targets.append(y_val)\n        scores.append(score)\n    \n        ### Predict on test ###\n        preds_test = loaded_model.predict(X_test)\n        test_cv_preds.append(1 / (1 + np.exp(-preds_test)))\n    oof_all += oof\n    \n    \noof_preds_all = np.concatenate(oof_preds)\noof_targets_all = np.concatenate(oof_targets)\ntest_preds_all = np.stack(test_cv_preds)\noof_all = oof_all/len(SEEDS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oof.shape, oof_all.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oof_all[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test_preds_all.shape)\nprint(test_preds_all[0][:5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aucs = []\nfor task_id in range(oof_preds_all.shape[1]):\n    aucs.append(roc_auc_score(y_true = oof_targets_all[:, task_id],\n                              y_score = oof_preds_all[:, task_id]\n                             ))\nprint(f\"{b_}Overall AUC: {r_}{np.mean(aucs)}\")\nprint(f\"{b_}Average CV: {r_}{np.mean(scores)}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(oof_preds_all.shape)\nprint(oof_targets_all.shape)\nprint(oof_preds_all.shape)\nprint(tabnet_params['seed'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The worst CV value that i achive**"},{"metadata":{},"cell_type":"markdown","source":"# <font color = \"seagreen\">Conclusion (NOT AVAILABLE UNTIL I SEE THE LB Score)</font> "},{"metadata":{},"cell_type":"markdown","source":"# <font color = \"seagreen\">Submission</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test_preds_all.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_feat = [col for col in submission.columns if col not in [\"sig_id\"]]\n# To obtain the same lenght of test_preds_all and submission\ntest = pd.read_csv(data_path + \"test_features.csv\")\nsig_id = test[test[\"cp_type\"] != \"ctl_vehicle\"].sig_id.reset_index(drop = True)\ntmp = pd.DataFrame(test_preds_all.mean(axis = 0), columns = all_feat)\ntmp[\"sig_id\"] = sig_id\n\nsubmission = pd.merge(test[[\"sig_id\"]], tmp, on = \"sig_id\", how = \"left\")\nsubmission.fillna(0, inplace = True)\n\n#submission[all_feat] = tmp.mean(axis = 0)\n\n# Set control to 0\n#submission.loc[test[\"cp_type\"] == 0, submission.columns[1:]] = 0\nsubmission.to_csv(\"submission.csv\", index = None)\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"{b_}submission.shape: {r_}{submission.shape}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class = \"alert alert-block alert-info\">\n    <h3><font color = \"red\">NOTE: </font></h3>\n    <p>If you want to comment please tag me with '@' to answer more quickly.</p>\n</div>"},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.save('oof_TabNet_no_ctrl.npy', oof_all)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oof_all.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_targets_scored = pd.read_csv(data_path + \"train_targets_scored.csv\")\ntarget_cols = [col for col in train_targets_scored.columns if col != 'sig_id']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(data_path + 'train_features.csv')\nprint(train.shape)\ntrain_no_ctrl = train[train[\"cp_type\"] != \"ctl_vehicle\"].reset_index(drop=True)\nprint(train_no_ctrl.shape)\ntrain_pred = pd.DataFrame(oof_all, columns = target_cols)\nprint(train_pred.shape)\ntrain_pred = pd.concat([train_no_ctrl[['sig_id']], train_pred], axis=1).reset_index(drop=True)\nprint(train_pred.shape)\ndisplay(train_pred.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_results = train_targets_scored.drop(columns=target_cols).merge(train_pred, on='sig_id', how='left').fillna(0)\ny_true = train_targets_scored[target_cols].values\ny_pred = valid_results[target_cols].values\nnp.save('oof_TabNet_all.npy', y_pred) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def log_loss_numpy(y_pred, y_true):\n    y_true_ravel = np.asarray(y_true).ravel()\n    y_pred = np.asarray(y_pred).ravel()\n    y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n    loss = np.where(y_true_ravel == 1, - np.log(y_pred), - np.log(1 - y_pred))\n    return loss.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_true = train_targets_scored[target_cols].values\nlog_loss_numpy(y_pred, y_true)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}