{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Libraries"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# import sys\n# sys.path.append('../input/iterative-stratification/iterative-stratification-master')\n# from iterstrat.ml_stratifiers import MultilabelStratifiedKFold","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# import warnings\n# warnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport pickle\nimport joblib\nimport os, sys\nimport gc\nimport math\nimport random\nfrom tqdm import tqdm\n# from typing import List, NoReturn, Union, Tuple, Optional, Text, Generic, Callable, Dict\nfrom sklearn.preprocessing import QuantileTransformer\nfrom sklearn.model_selection import KFold, StratifiedKFold, TimeSeriesSplit\nfrom sklearn.decomposition import PCA\nimport umap\n\nimport lightgbm as lgb\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.metrics import log_loss\n\nfrom tqdm import tqdm\n\nimport math\n\n# visualize\nimport matplotlib.pyplot as plt\nimport matplotlib.style as style\nimport seaborn as sns\nfrom matplotlib_venn import venn2\nfrom matplotlib import pyplot\nfrom matplotlib.ticker import ScalarFormatter\nsns.set_context(\"talk\")\nstyle.use('seaborn-colorblind')\npd.options.display.max_columns = None\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load data"},{"metadata":{"trusted":true},"cell_type":"code","source":"N_STARTS = 1\nN_SPLITS = 4\nSEED = 217\nPOSTPROCESS = True","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def preprocessing_lgb():\n    VAR_THRESHOLD = 0.7\n    ncompo_genes = 80\n    ncompo_cells = 10\n    seed = 42\n    \n    train_features = pd.read_csv('../input/lish-moa/train_features.csv')\n    train_targets = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\n    test_features = pd.read_csv('../input/lish-moa/test_features.csv')\n\n    train_features = train_features[train_features['cp_type']!='ctl_vehicle']\n    control_g = test_features['cp_type'] == 'ctl_vehicle'\n    test_g = test_features['cp_type'] != 'ctl_vehicle'\n    test_features = test_features[test_g]\n    train_targets = train_targets.iloc[train_features.index]\n\n    # drop cp_type\n    train_features = train_features.drop('cp_type', axis=1).reset_index(drop=True)\n    test_features = test_features.drop('cp_type', axis=1).reset_index(drop=True)\n    train_targets.reset_index(drop=True, inplace=True)\n    ss = pd.read_csv('../input/lish-moa/sample_submission.csv')\n\n    # Variance \n    cols_numeric = [feat for feat in list(train_features.columns) if feat not in ['sig_id', 'cp_time', 'cp_dose']]\n    mask = (train_features[cols_numeric].var() > VAR_THRESHOLD).values\n    tmp = train_features[cols_numeric].loc[:, mask]\n    train_features = pd.concat([train_features[['sig_id', 'cp_time', 'cp_dose']], tmp], axis=1)\n    cols_numeric = [feat for feat in list(train_features.columns) if feat not in ['sig_id', 'cp_time', 'cp_dose']]\n    test_features = pd.concat([test_features[['sig_id', 'cp_time', 'cp_dose']], test_features[cols_numeric]], axis=1)\n\n    GENES = [col for col in train_features.columns if col.startswith('g-')]\n    CELLS = [col for col in train_features.columns if col.startswith('c-')]\n\n    # Rank Gauss\n    for col in (GENES + CELLS):\n        transformer = QuantileTransformer(n_quantiles=100,random_state=0, output_distribution=\"normal\")   # from optimal commit 9\n        vec_len = len(train_features[col].values)\n        vec_len_test = len(test_features[col].values)\n        raw_vec = train_features[col].values.reshape(vec_len, 1)\n        transformer.fit(raw_vec)\n        \n        train_features[col] = transformer.transform(raw_vec).reshape(1, vec_len)[0]\n        test_features[col] = transformer.transform(test_features[col].values.reshape(vec_len_test, 1)).reshape(1, vec_len_test)[0]\n\n\n    # PCA\n    pca_genes = PCA(n_components = ncompo_genes, random_state = seed)\n    pca_genes_train = pca_genes.fit_transform(train_features[GENES])\n        \n    pca_cells = PCA(n_components = ncompo_cells, random_state = seed)\n    pca_cells_train = pca_cells.fit_transform(train_features[CELLS])\n    \n    pca_genes_train = pd.DataFrame(pca_genes_train, columns = [f\"pca_g-{i}\" for i in range(ncompo_genes)])\n    pca_cells_train = pd.DataFrame(pca_cells_train, columns = [f\"pca_c-{i}\" for i in range(ncompo_cells)])\n    train_features = pd.concat([train_features, pca_genes_train, pca_cells_train], axis = 1)\n    \n    pca_genes_test = pca_genes.transform(test_features[GENES])\n    pca_cells_test = pca_cells.transform(test_features[CELLS])\n    \n    pca_genes_test = pd.DataFrame(pca_genes_test, columns = [f\"pca_g-{i}\" for i in range(ncompo_genes)])\n    pca_cells_test = pd.DataFrame(pca_cells_test, columns = [f\"pca_c-{i}\" for i in range(ncompo_cells)])\n    test_features = pd.concat([test_features, pca_genes_test, pca_cells_test], axis = 1)\n\n    # One hot\n    train_features = pd.get_dummies(train_features, columns = ['cp_time', 'cp_dose'])\n    test_features = pd.get_dummies(test_features, columns = ['cp_time', 'cp_dose'])\n\n    # Extra features\n    for df in [train_features, test_features]:\n        for stats in tqdm(['sum', 'mean', 'std', 'kurt', 'skew', 'max', 'min']):\n            df['g-'+stats] = getattr(df[GENES], stats)(axis=1)\n            df['c-'+stats] = getattr(df[CELLS], stats)(axis=1)\n            df['gc-'+stats] = getattr(df[GENES+CELLS], stats)(axis=1)\n    train_targets.drop('sig_id', axis=1, inplace=True)\n    train = train_features.drop('sig_id', axis=1)\n    test = test_features.drop('sig_id', axis=1)\n    feats = train.columns.to_list()\n    return train, test, train_targets, ss, control_g, test_g, feats\n\ntrain, test, train_targets, ss, control_g, test_g, feats = preprocessing_lgb()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p_min = 0.001\np_max = 0.999\n\ndef metric(y_true, y_pred):\n    metrics = []\n    for _target in train_targets.columns:\n        metrics.append(log_loss(y_true.loc[:, _target], y_pred.loc[:, _target].astype(float), labels=[0,1]))\n    return np.mean(metrics)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n    'n_estimators': 24000,\n    'objective': 'binary',\n    'metric': 'binary_logloss',\n    'boosting_type': 'gbdt',\n    'max_depth': 3,\n    'learning_rate': 0.08,\n    'subsample': 0.72,\n    'subsample_freq': 4,\n    'feature_fraction': 0.4,\n    'lambda_l1': 1,\n    'lambda_l2': 1,\n#     'seed': SEED,\n    'early_stopping_rounds': 40,\n    }    \n\ndef fit_lgb_kfold(train, train_targets, test, features, target, n_splits=N_SPLITS, random_state=SEED):    \n    oof = np.zeros(train.shape[0])\n    y_preds = np.zeros(test.shape[0])\n#     fi = pd.DataFrame()\n#     fi['features'] = features\n#     fi['importance'] = 0\n    params['seed'] = SEED * (random_state+1)\n    \n    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n    for fold_n, (train_idx, valid_idx) in enumerate(cv.split(train, train_targets[target])):\n        # train test split\n        x_train_train = train[features].iloc[train_idx]\n        y_train_train = train_targets[target].iloc[train_idx]\n        x_train_valid = train[features].iloc[valid_idx]\n        y_train_valid = train_targets[target].iloc[valid_idx]\n\n        # lgb dataset\n        lgb_train = lgb.Dataset(data=x_train_train, label=y_train_train)\n        lgb_valid = lgb.Dataset(data=x_train_valid, label=y_train_valid)\n\n        # fit\n        model = lgb.train(params, lgb_train, valid_sets=lgb_valid, verbose_eval=0)\n#         fi['importance'] += model.feature_importance(importance_type=\"gain\") / N_SPLITS\n\n        joblib.dump(model, f'model_{target}_seed_{SEED*(random_state+1)}_fold_{fold_n}.pkl')\n        model = joblib.load(f'model_{target}_seed_{SEED*(random_state+1)}_fold_{fold_n}.pkl')\n        \n        # save mod?p(model, open(f'model_{random_state}_{n}_{target}.pkl', 'wb'))                \n    \n        # predict\n        oof[valid_idx] = model.predict(x_train_valid, num_iteration=model.best_iteration)\n        y_preds += model.predict(test[features]) / N_SPLITS\n        \n    score = log_loss(train_targets[target], oof)\n    print('LogLoss Score:', score)\n\n#     model = pickle.load(open(f'model_{seed}_{n}_{targ}.pkl', 'rb'))\n    return y_preds, oof, score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res = train_targets.copy()\nss.loc[:, train_targets.columns] = 0\nres.loc[:, train_targets.columns] = 0\n\nfor seed in range(N_STARTS):\n    res_seed = res.copy()\n    ss_seed = ss.copy()\n    print('Seed:', SEED*seed)\n    for targ in tqdm(train_targets.columns):\n        print('Target = {}'.format(targ))\n        y_pred, oof, score = fit_lgb_kfold(train, train_targets, test, feats, targ, n_splits=N_SPLITS, random_state=seed)\n        res_seed[targ] = oof\n        ss_seed.loc[test_g, targ] = y_pred\n    \n    print(f'OOF Metric For SEED {seed}: {metric(train_targets, res_seed)}')\n    for targ in train_targets.columns:\n        res[targ] += res_seed[targ].values / N_STARTS\n        ss.loc[test_g, targ] += ss_seed.loc[test_g, targ].values / N_STARTS","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# if DO == 'training':\n#     print(f'OOF Metric: {metric(train_targets, res)}')\n    \n# elif DO == 'inference':\nprint(f'OOF Metric: {metric(train_targets, res)}')\n\nif POSTPROCESS:\n    print('post-process...')\n\n    # clip\n    ss.iloc[:,1:] = np.clip(ss.values[:, 1:], p_min, p_max)\n\n    # Set ctl_vehicle to 0\n    ss.iloc[control_g, 1:] = 0\nss.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Kernel still under modification.. <span style='color:red'>**Feedback**</span> is also very much appreciated.\nPls <span style='color:red'>**UPVOTE**</span>, if you find it useful. \n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}