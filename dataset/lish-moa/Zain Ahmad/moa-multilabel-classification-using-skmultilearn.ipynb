{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Multi label Classification using Scikit-multilearn\n---\nAs we know that problem of MoA classification is a multi label classifcation problem. There are different approaches and algorithm to solve this problem here I am going to give a demo scikit-multilearn which is complete all in one framework for solving multilabel problems in python\n\n[scikit-multilearn](http://scikit.ml/userguide.html#)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"importing all the modules"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelBinarizer , LabelEncoder\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.feature_selection import SelectKBest , chi2 , f_classif\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import log_loss , hamming_loss\nfrom skmultilearn.adapt import MLkNN\nfrom sklearn.decomposition import PCA\nfrom sklearn.pipeline import Pipeline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"loading the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features = pd.read_csv('../input/lish-moa/train_features.csv')\ntrain_targets_scored = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\ntrain_targets_unscored = pd.read_csv('../input/lish-moa/train_targets_nonscored.csv')\ntest_features = pd.read_csv('../input/lish-moa/test_features.csv')\nsample_sub = pd.read_csv('../input/lish-moa/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Encode Label function"},{"metadata":{"trusted":true},"cell_type":"code","source":"def EncodeLabel(data , feature , binary=True):\n    if binary:\n        lb = LabelBinarizer()\n        temp = lb.fit_transform(data[feature])\n        data[feature]= temp\n    else:\n        le = LabelEncoder()\n        temp = le.fit_transform(data[feature])\n        data[feature] = temp","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Lets look at the dataset and target labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(train_targets_scored.columns))\nprint(train_targets_scored.columns)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for c in train_targets_scored.columns[1:]:\n    print(train_targets_scored[c].value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Lets look at features"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looking for any null values"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features.isnull().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"loking at different type of feature groups"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'total number of samples = {train_features.shape[0]}')\nprint(f'total number of features = {len(train_features.columns[1:])}')\ngene_exp_features = [c for c in train_features.columns if c.startswith('g-')]\nprint(f'total number of gene expression features {gene_exp_features[0]} to {gene_exp_features[-1]} = {len(gene_exp_features)}')\ncell_viability = [c for c in train_features.columns if c.startswith('c-')]\nprint(f'total number of cell viability features {cell_viability[0]} to {cell_viability[-1]} = {len(cell_viability)}')\nother_features = [c for c in train_features.columns[1:] if c not in gene_exp_features and c not in cell_viability]\nprint('other features')\nfor c in other_features:\n    print(c)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'dtype of g- = {train_features[gene_exp_features[0]].dtypes}')\nprint(f'dtype of c- = {train_features[cell_viability[0]].dtypes}')\nprint(f'dtype of {other_features[0]}={train_features[other_features[0]].dtypes}')\nprint(f'dtype of {other_features[1]}={train_features[other_features[1]].dtypes}')\nprint(f'dtype of {other_features[2]}={train_features[other_features[2]].dtypes}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets Look at the other teachers"},{"metadata":{"trusted":true},"cell_type":"code","source":"for c in other_features:\n    print(f'no. of unique values for {c} = {train_features[c].nunique()}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EncodeLabel(train_features , 'cp_type')\nEncodeLabel(train_features , 'cp_dose')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## preparing the dataset to feed into the model\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train_features.drop(columns=['sig_id'])\nY = train_targets_scored.drop(columns=['sig_id'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x , val_x , train_y , val_y = train_test_split(X,Y, test_size=0.2)\nprint(f'shape of train_x = {train_x.shape}')\nprint(f'shape of train_y = {train_y.shape}')\nprint(f'shape of val_x = {val_x.shape}')\nprint(f'shape of val_y = {val_y.shape}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model\nI am going to use the adaptive algorithm MLkNN short Multi Learn k Nearest Neighbours\n\nnow one thing to remember is unlike sklearn skmultilearn can't handle dataframes so make sure you are passing numpy arrays"},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = MLkNN(k=3)\nclassifier.fit(np.array(train_x) ,np.array( train_y))\npreds = classifier.predict(np.array(val_x))\nloss = hamming_loss(val_y , preds)\nprint(loss)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EncodeLabel(test_features , 'cp_type')\nEncodeLabel(test_features , 'cp_dose')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test = np.array(test_features.drop(columns=['sig_id']))\ny_test = classifier.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"skmultilearn outputs a predictions as sparse matrix so we need to convert it to a dense matrix in order to infer the result and make submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_dense = y_test.todense()\nprint(y_dense.shape)\nprint(y_test.shape)\ny_dense","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating the submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_df = test_features[['sig_id']]\nfor i, d in enumerate(val_y.columns):\n    pred_df[d] = y_dense[:,i]\n    \npred_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_df.set_index('sig_id' , inplace=True)\npred_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"submitting"},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_df.to_csv('submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}