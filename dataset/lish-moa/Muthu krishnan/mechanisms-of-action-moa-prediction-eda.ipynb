{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, cross_val_predict, cross_validate\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler, PolynomialFeatures, MinMaxScaler, LabelEncoder, RobustScaler, Normalizer\nfrom tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom sklearn.pipeline import Pipeline\nfrom xgboost import XGBRFClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.metrics import multilabel_confusion_matrix, label_ranking_loss, log_loss, roc_auc_score\nfrom sklearn.linear_model import LogisticRegression, Perceptron\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.multioutput import MultiOutputClassifier\nfrom sklearn.decomposition import PCA \nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_features = pd.read_csv('/kaggle/input/lish-moa/test_features.csv')\ntrain_features = pd.read_csv('/kaggle/input/lish-moa/train_features.csv')\ntrain_targets_scored = pd.read_csv('/kaggle/input/lish-moa/train_targets_scored.csv')\ntrain_targets_nonscored = pd.read_csv('/kaggle/input/lish-moa/train_targets_nonscored.csv')\ntest_targets = pd.read_csv('/kaggle/input/lish-moa/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#quick look at our data types & null counts \ntrain_features.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# To better understand the numeric data, we want to use the .describe() method. \n# This gives us an understanding of the central tendencies of the data. \n\ntrain_features.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reading the train dataset\ntrain_features.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reading the test dataset \ntest_features.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# To calculate the rows and columns in the dataset\nprint('The Training dataset has {} rows and {} columns.'.format(len(train_features), len(train_features.columns)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('The Test dataset has {} rows and {} columns.'.format(len(test_features), len(test_features.columns)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## categorical data in the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 3, figsize=(20, 5))\n\n\nsns.countplot(train_features['cp_type'],palette=(\"Blues\"), ax=ax[0])\nax[0].set_title('cp_type distribution')\n\nsns.countplot(train_features['cp_time'],palette=(\"Blues\"), ax=ax[1])\nax[1].set_title('cp_time distribution')\n\nsns.countplot(train_features['cp_dose'],palette=(\"Blues\"), ax=ax[2])\nax[2].set_title('cp_dose distribution')\n\nfig.suptitle('Distribution in Train dataset of Type, Time and Dose')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 3, figsize=(20, 5))\n\n\nsns.countplot(test_features['cp_type'],palette=(\"BuGn_r\"), ax=ax[0])\nax[0].set_title('cp_type distribution')\n\nsns.countplot(test_features['cp_time'],palette=(\"BuGn_r\"), ax=ax[1])\nax[1].set_title('cp_time distribution')\n\nsns.countplot(test_features['cp_dose'],palette=(\"BuGn_r\"), ax=ax[2])\nax[2].set_title('cp_dose distribution')\n\nfig.suptitle('Distribution in Test dataset of Type, Time and Dose')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features['cp_type'] = train_features['cp_type'].astype('category')\ntrain_features['cp_type'].cat.categories = [0, 1]\ntrain_features['cp_type'] = train_features['cp_type'].astype(\"int\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features['cp_dose'] = train_features['cp_dose'].astype('category')\ntrain_features['cp_dose'].cat.categories = [0, 1]\ntrain_features['cp_dose'] = train_features['cp_dose'].astype(\"int\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features['cp_time'] = train_features['cp_time'].astype('category')\ntrain_features['cp_time'].cat.categories = [0, 1, 2]\ntrain_features['cp_time'] = train_features['cp_time'].astype(\"int\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Numerical value in the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of \"g-\" features are: ', len([i for i in train_features.columns if i.startswith('g-')]))\nprint('Number of \"c-\" features are: ', len([i for i in train_features.columns if i.startswith('c-')]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* The g- signify gene feature. It's from  g-0 : g-771\n* The c- signify cell viability feature, It's from  c-0 : c-99"},{"metadata":{},"cell_type":"markdown","source":"## Checking the Normal Distribution or Gaussian Distribution in the dataset."},{"metadata":{},"cell_type":"markdown","source":"### Gene Feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(3, 3, figsize=(20, 5))\n\nsns.kdeplot(test_features['g-0'], shade = True, color = 'coral', ax=ax[0, 0])\nsns.kdeplot(test_features['g-20'], shade = True, color = 'coral', ax=ax[0, 1])\nsns.kdeplot(test_features['g-555'], shade = True, color = 'coral', ax=ax[0, 2])\nsns.kdeplot(test_features['g-105'], shade = True, color = 'coral', ax=ax[1, 0])\nsns.kdeplot(test_features['g-725'], shade = True, color = 'coral', ax=ax[1, 1])\nsns.kdeplot(test_features['g-598'], shade = True, color = 'coral', ax=ax[1, 2])\nsns.kdeplot(test_features['g-366'], shade = True, color = 'coral', ax=ax[2, 0])\nsns.kdeplot(test_features['g-450'], shade = True, color = 'coral', ax=ax[2, 1])\nsns.kdeplot(test_features['g-600'], shade = True, color = 'coral', ax=ax[2, 2])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Cell viability features"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(3, 3, figsize=(20, 5))\n\nsns.kdeplot(test_features['c-0'], shade = True, color = 'blue', ax=ax[0, 0])\nsns.kdeplot(test_features['c-20'], shade = True, color = 'blue', ax=ax[0, 1])\nsns.kdeplot(test_features['c-99'], shade = True, color = 'blue', ax=ax[0, 2])\nsns.kdeplot(test_features['g-66'], shade = True, color = 'blue', ax=ax[1, 0])\nsns.kdeplot(test_features['g-88'], shade = True, color = 'blue', ax=ax[1, 1])\nsns.kdeplot(test_features['g-73'], shade = True, color = 'blue', ax=ax[1, 2])\nsns.kdeplot(test_features['g-45'], shade = True, color = 'blue', ax=ax[2, 0])\nsns.kdeplot(test_features['g-59'], shade = True, color = 'blue', ax=ax[2, 1])\nsns.kdeplot(test_features['g-37'], shade = True, color = 'blue', ax=ax[2, 2])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* The most case the points are centred around 0 are close to normal distribution.\n* In some case we can find skeness in the data"},{"metadata":{},"cell_type":"markdown","source":"### Mean and standard deviation for gene feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"g_cols = [f'g-{i}' for i in range(772)]\nfig, ax = plt.subplots(1, 2, figsize=(20, 4))\n\nsns.distplot(train_features[g_cols].mean(), kde=False,color = 'green', bins = 75, ax = ax[0])\nsns.distplot(train_features[g_cols].std(), kde=False,color = 'green',  bins = 75, ax = ax[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Mean and standard deviation for Cell viability feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"c_cols = [f'c-{i}' for i in range(100)]\nfig, ax = plt.subplots(1, 2, figsize=(20, 4))\n\nsns.distplot(train_features[c_cols].mean(), kde=False,color = 'purple', bins = 15, ax = ax[0])\nsns.distplot(train_features[c_cols].std(), kde=False,color = 'purple',  bins = 15, ax = ax[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### correlation matrix for gene feature "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compute the correlation matrix\ncorr = train_features[g_cols[:40]].corr()\n\n# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corr, dtype=bool))\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(10, 10))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(230, 20, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\nplt.title('Pairwise correlations of gene features for first 40')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this we can see that some of the feature are strongly correlate with each other."},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(figsize=(15, 4))\nsns.distplot(train_features[g_cols].corr(),color='r')\nplt.title(\"Distribution for gene feature\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The correlation of the gene is Normal Distributed or Gaussian Distribution and also we do have some outlayers."},{"metadata":{},"cell_type":"markdown","source":"### correlation matrix for cell viability feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,7))\nsns.heatmap(train_features[c_cols].corr(), cmap='coolwarm');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The lowest value is around 0.6, therefore the value are highly correlated"},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(figsize=(15, 4))\nsns.distplot(train_features[c_cols].corr(),color='lightsalmon')\nplt.title(\"Distribution for Gene Feature\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_cor = train_features.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_cor.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some feature are most correlated with other feature. To see the multicolinearity of all feature, we are using **Variance Inflation Factor(VIF)**."},{"metadata":{"trusted":true},"cell_type":"code","source":"vifs = pd.DataFrame(np.linalg.inv(train_features_cor.values).diagonal(), index = train_features_cor.index, columns=['VIF'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vifs.tail(6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we take a value where vif is greater than 15.\n\ngreater_vifs = vifs.where(vifs>15)\ngreater_vifs = greater_vifs.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_remove = greater_vifs.index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_remove \n# This is a feature that have highly correlated with any number of the other variables.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train_features_data = train_features.drop(columns=cols_remove) # we drop these columns highly correlated","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train_features_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Test Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_features['cp_type'] = test_features['cp_type'].astype('category')\ntest_features['cp_type'].cat.categories = [0, 1]\ntest_features['cp_type'] = test_features['cp_type'].astype(\"int\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_features['cp_dose'] = test_features['cp_dose'].astype('category')\ntest_features['cp_dose'].cat.categories = [0, 1]\ntest_features['cp_dose'] = test_features['cp_dose'].astype(\"int\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_features['cp_time'] = test_features['cp_time'].astype('category')\ntest_features['cp_time'].cat.categories = [0, 1, 2]\ntest_features['cp_time'] = test_features['cp_time'].astype(\"int\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_features.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Targets"},{"metadata":{"trusted":true},"cell_type":"code","source":"targets = train_targets_scored","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"targets.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('The Tergets dataset has {} rows and {} columns.'.format(len(targets), len(targets.columns)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_cols = targets.columns[1:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Top 20 most frequent targets."},{"metadata":{"trusted":true},"cell_type":"code","source":"targets_fre = (targets[target_cols].mean() * 100).sort_values()[-20:].index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,4))\n(targets[targets_fre].mean() * 100).sort_values().plot.bar()\nplt.title('Most frequent targets')\nplt.ylabel('% of true labels')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,4))\nvc = targets[target_cols].sum(axis=1).value_counts()\nplt.title('True labels per row distribution')\nplt.ylabel('# of rows')\nplt.xlabel('# of true targets per row')\nplt.bar(vc.index, vc.values)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_targets_scored.drop(['sig_id'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_targets_scored.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_ids = test_features['sig_id']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for d in [new_train_features_data, test_features]:\n    d.drop(['sig_id','cp_type', 'cp_dose', 'cp_time'], axis=1, inplace=True)\n    \ntrain_features.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Building"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_cv, y_train, y_cv = train_test_split(new_train_features_data, train_targets_scored, test_size=0.2) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Dense(512, input_dim=x_train.shape[1], activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(.25),\n    tf.keras.layers.Dense(1024, activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(.25),\n    tf.keras.layers.Dense(1024, activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(.25),\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(.25),\n    tf.keras.layers.Dense(y_train.shape[1], activation='sigmoid')\n])\n\nmodel.compile(\n    optimizer='adam',\n    loss='binary_crossentropy',\n    metrics=['accuracy']\n)\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"factor= 0.8250037987063858\npatience=2\nmin_lr= 5.101088055532695e-05\nlr=6.353131263848553e-05\nbatch_size=353\nepochs=359\n\ndef callbacks(file_path):\n    reduce_learning_rate = ReduceLROnPlateau(monitor='val_loss',\n                                         factor=factor,\n                                         patience=patience,\n                                         cooldown=1,\n                                         min_lr=min_lr,\n                                         verbose=1)\n    checkpoint = ModelCheckpoint(filepath = file_path,monitor='val_loss',\n                                 mode='min',save_best_only=True,verbose=1)\n\n    early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience= patience)\n\n    return [reduce_learning_rate,checkpoint,early]\n\nfile_path = model.name+'best_weights.hd5'\ncallbacks_list = callbacks(file_path = file_path)\n\noptimizer = tf.keras.optimizers.Adam(lr=lr, amsgrad=True)\n#compile the model\nmodel.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=optimizer)\n\nhistory=model.fit(x_train,y_train,epochs= epochs, batch_size=batch_size, callbacks = callbacks_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(test_targets[pd.read_csv('../input/lish-moa/sample_submission.csv').columns]).to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}