{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Do upvote, help me reach expert in notebooks :)"},{"metadata":{},"cell_type":"markdown","source":"# Mechanisms of Action (MoA) Prediction"},{"metadata":{},"cell_type":"markdown","source":"## Step 1: Understanding the Data"},{"metadata":{},"cell_type":"markdown","source":"**train_features.csv** - Features for the training set. Features g- signify gene expression data, and c- signify cell viability data. cp_type indicates samples treated with a compound (cp_vehicle) or with a control perturbation (ctrl_vehicle); control perturbations have no MoAs; cp_time and cp_dose indicate treatment duration (24, 48, 72 hours) and dose (high or low).<br>\n**train_targets_scored.csv** - The binary MoA targets that are scored.<br>\n**train_targets_nonscored.csv** - Additional (optional) binary MoA responses for the training data. These are not predicted nor scored.<br>\n**test_features.csv** - Features for the test data. You must predict the probability of each scored MoA for each row in the test data.<br>\n**sample_submission.csv** - A submission file in the correct format."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport tensorflow\nnp.random.seed(2)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold, KFold\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input\n\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\nimport tensorflow_addons as tfa\nfrom sklearn.metrics import log_loss\nimport tensorflow as tf\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loading Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train = pd.read_csv('/kaggle/input/lish-moa/train_features.csv')\ndata_test = pd.read_csv('/kaggle/input/lish-moa/test_features.csv')\ndata_train_target_ns = pd.read_csv('/kaggle/input/lish-moa/train_targets_nonscored.csv')\ndata_train_target_s = pd.read_csv('/kaggle/input/lish-moa/train_targets_scored.csv')\nsub = pd.read_csv('/kaggle/input/lish-moa/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(data_train.head())\nprint(\"SHAPE of training data--\",data_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(data_test.head())\nprint(\"SHAPE of test data--\",data_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Encode cp_type, cp_dose, cp_time and remove sig_id"},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(df):\n    df.loc[:, 'cp_type'] = df.loc[:, 'cp_type'].map({'trt_cp': 0, 'ctl_vehicle': 1})\n    df.loc[:, 'cp_dose'] = df.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n    df.loc[:, 'cp_time'] = df.loc[:, 'cp_time'].map({24: 0, 48: 1, 72:2})\n    del df['sig_id']\n    return df\n\ntrain = preprocess(data_train)\ntest = preprocess(data_test)\n\ndel data_train_target_s['sig_id']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating Model "},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model(num_columns):\n    model = Sequential()\n    model.add(Input(num_columns))\n    model.add(BatchNormalization())\n    model.add(Dense(2048, activation='relu'))\n    model.add(Dropout(0.5))\n    \n    model.add(Dense(1024, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    \n    model.add(Dense(206, activation='sigmoid'))\n    \n    optimizer = tfa.optimizers.Lookahead('adam',sync_period=10)\n    \n    model.compile(optimizer=optimizer,\n                  loss='binary_crossentropy', \n                  metrics=['accuracy'])\n    \n    model.summary()\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def metric(y_true, y_pred):\n    metrics = []\n    for _target in data_train_target_s.columns:\n        metrics.append(log_loss(y_true.loc[:, _target], y_pred.loc[:, _target].astype(float), labels=[0,1]))\n    return np.mean(metrics)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training Model \nWe will create 4 models and each model will have 5 kfold split. In last we average out the predictions and save it to csv"},{"metadata":{"trusted":true},"cell_type":"code","source":"N_STARTS = 4\ntf.random.set_seed(42)\n\nres = data_train_target_s.copy()\nsub.loc[:, data_train_target_s.columns] = 0\nsub.loc[:, data_train_target_s.columns] = 0\n\nfor seed in range(N_STARTS):\n    for n, (train_idx, test_idx) in enumerate(KFold(n_splits=5, random_state=seed, shuffle=True).split(data_train_target_s, data_train_target_s)):\n        print(f'Fold {n}')\n    \n        model = create_model(875)\n        checkpoint_path = f'repeat:{seed}_Fold:{n}.h5'\n        reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, epsilon=1e-4, mode='min')\n        cb_checkpt = ModelCheckpoint(checkpoint_path, monitor = 'val_loss', verbose = 0, save_best_only = True,\n                                     save_weights_only = True, mode = 'min')\n        model.fit(train.values[train_idx],\n                  data_train_target_s.values[train_idx],\n                  validation_data=(train.values[test_idx], data_train_target_s.values[test_idx]),\n                  epochs=25, batch_size=128,\n                  callbacks=[reduce_lr_loss, cb_checkpt], verbose=1\n                 )\n        \n        model.load_weights(checkpoint_path)\n        test_predict = model.predict(test.values)\n        val_predict = model.predict(train.values[test_idx])\n        \n        sub.loc[:, data_train_target_s.columns] += test_predict\n        res.loc[test_idx, data_train_target_s.columns] += val_predict\n        print('')\n    \nsub.loc[:, data_train_target_s.columns] /= ((n+1) * N_STARTS)\nres.loc[:, data_train_target_s.columns] /= N_STARTS","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'OOF Metric: {metric(data_train_target_s, res)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.loc[test['cp_type']==1, data_train_target_s.columns] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}