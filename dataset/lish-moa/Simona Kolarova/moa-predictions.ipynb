{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\n\nimport numpy as np\nimport pandas as pd\nimport random\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import log_loss\nfrom sklearn.decomposition import PCA\nfrom sklearn.utils import check_random_state\n\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.losses import BinaryCrossentropy\nimport tensorflow_addons as tfa\n\nfrom typing import Tuple, List, Callable, Any\n\nfrom tqdm.notebook import tqdm\n\nimport plotly.express as px","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dataset"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Files in competition directory\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create pandas dataframes\n\ntrain_features = pd.read_csv('../input/lish-moa/train_features.csv')\ntrain_targets = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\ntest_features = pd.read_csv('../input/lish-moa/test_features.csv')\n\ntest_predictions = pd.read_csv('../input/lish-moa/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Principal component analysis (PCA) for cell viability data only\npca_cv = PCA()\npca_cv.fit(train_features.iloc[:,776:876])\nlabels_cv = ['PC' + str(x) for x in range (1, 101)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preprocess training and testing features datasets\ndef preprocess(df):\n    df = df.copy()\n    \n    # PCA - 97 cell viability principal components to replace 100 cell viability variables\n    pca_cv_data = pca_cv.transform(df.iloc[:,776:876])\n    df = pd.merge(df.iloc[:,:776], pd.DataFrame(pca_cv_data, columns = labels_cv).iloc[:,:97], how = 'inner', left_index = True, right_index = True)\n\n    # Assign numeric labels to categorical values\n    df.loc[:, 'cp_type'] = df.loc[:, 'cp_type'].map({'trt_cp': 0, 'ctl_vehicle': 1})\n    df.loc[:, 'cp_dose'] = df.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n    df.loc[:, 'cp_time'] = df.loc[:, 'cp_time'].map({24: 0, 48: 1, 72: 2}) \n    \n    # Delete ID column \n    del df['sig_id']\n    \n    return df\n\ntrain_features = preprocess(train_features)\ntest_features = preprocess(test_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preprocess training targets datasets\ndel train_targets['sig_id']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predictive model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model():\n    \n    # Keras sequential neural network model\n    model = tf.keras.Sequential([\n        \n        tf.keras.layers.Input(train_features.shape[1]),\n        \n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(0.2),\n        tfa.layers.WeightNormalization(tf.keras.layers.Dense(600, activation=\"relu\")),\n        \n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(0.3),\n        tfa.layers.WeightNormalization(tf.keras.layers.Dense(300, activation=\"relu\")),\n        \n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(0.3),\n        tfa.layers.WeightNormalization(tf.keras.layers.Dense(train_targets.shape[1], activation=\"sigmoid\"))\n        ])\n    \n    # Model compilation\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(lr = 1e-4), \n        loss='binary_crossentropy')\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model structure\nmodel = create_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model fitting\n\n# Fitting variables\nN_MODELS = 10\nN_SPLITS = 5\nEPOCHS = 50\nBATCHES = 128\n#SEED = 123\n\n# Model seed \n#tf.random.set_seed(SEED)\n\n# Model training tunning\nreduce_lr = ReduceLROnPlateau(\n    monitor='val_loss', \n    factor=0.1, \n    min_lr=1e-5, \n    patience=5, \n    verbose=1, \n    mode='min')    \n\nearly_stop = EarlyStopping(\n    monitor=\"val_loss\", \n    mode=\"min\", \n    restore_best_weights=True, \n    patience= 5, \n    verbose = 1)\n\n# Create dataframes to save predictions in\ntrain_predictions = train_targets.copy()\ntrain_predictions.loc[:, train_targets.columns] = 0\ntest_predictions.loc[:, train_targets.columns] = 0\n\n# Dictionary for model recording \nmodel_records = dict()\n\n# Fit 'N_MODELS' models with 'N_FOLDS' folds\nfor seed in range(N_MODELS):\n    for n, (train, test) in enumerate(KFold(n_splits=N_SPLITS, random_state=seed, shuffle=True).split(train_targets)):\n        print(f\"Fold: {n+1}\")\n                       \n        model_record = model.fit(\n            train_features.values[train],\n            train_targets.values[train],\n            validation_data=(train_features.values[test], train_targets.values[test]),\n            epochs=EPOCHS, \n            batch_size= BATCHES,\n            callbacks=[reduce_lr, early_stop], \n            verbose=2)\n        \n        model_records[f\"model_redord_{seed+1}\"] = model_record\n                \n        # Predict testing subset of training data \n        train_test_predict = model.predict(train_features.values[test])\n        train_predictions.loc[test, train_targets.columns] += train_test_predict\n\n        # Predict external testing data\n        external_test_predict = model.predict(test_features.values)\n        test_predictions.loc[:, train_targets.columns] += external_test_predict\n    \n# Average all predictions    \ntrain_predictions.loc[:, train_targets.columns] /= N_MODELS\ntest_predictions.loc[:, train_targets.columns] /= ((n+1) * N_MODELS)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predictive model performance"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate log loss for training dataset predictions\nmetrics = []\n\nfor _target in train_targets.columns:\n    metrics.append(log_loss(train_targets.loc[:, _target], train_predictions.loc[:, _target]))\nprint(f\"Mean log loss for training dataset: {round(np.mean(metrics), 5)}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Features importance"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Supporting functions\ndef iter_shuffled(X, columns_to_shuffle=None, pre_shuffle=False, random_state=None):\n    rng = check_random_state(random_state)\n\n    if columns_to_shuffle is None:\n        columns_to_shuffle = range(X.shape[1])\n\n    if pre_shuffle:\n        X_shuffled = X.copy()\n        rng.shuffle(X_shuffled)\n\n    X_res = X.copy()\n    for columns in tqdm(columns_to_shuffle):\n        if pre_shuffle:\n            X_res[:, columns] = X_shuffled[:, columns]\n        else:\n            rng.shuffle(X_res[:, columns])\n        yield X_res\n        X_res[:, columns] = X[:, columns]\n\n\ndef get_score_importances(score_func, X, y, n_iter=5, columns_to_shuffle=None, random_state=None):\n    rng = check_random_state(random_state)\n    base_score = score_func(X, y)\n    scores_decreases = []\n    \n    for i in range(n_iter):\n        scores_shuffled = _get_scores_shufled(\n            score_func, \n            X, \n            y, \n            columns_to_shuffle=columns_to_shuffle,\n            random_state=rng, \n            base_score=base_score)\n        scores_decreases.append(scores_shuffled)\n\n    return base_score, scores_decreases\n\n\ndef _get_scores_shufled(score_func, X, y, base_score, columns_to_shuffle=None, random_state=None):\n    Xs = iter_shuffled(X, columns_to_shuffle, random_state=random_state)\n    res = []\n    \n    for X_shuffled in Xs:\n        res.append(-score_func(X_shuffled, y) + base_score)\n        \n    return res\n\ndef metric(y_true, y_pred):\n    metrics = []\n    \n    for i in range(y_pred.shape[1]):\n        if y_true[:, i].sum() > 1:\n            metrics.append(log_loss(y_true[:, i], y_pred[:, i]))\n            \n    return np.mean(metrics)   \n\n# Permatation importance empty array\nperm_imp = np.zeros(train_features.shape[1])\n\n# Fit one models with 'N_FOLDS' folds\nfor n, (train, test) in enumerate(KFold(n_splits=5, random_state=0, shuffle=True).split(train_targets)):\n    print(f'Fold {n}')\n\n    model = create_model()\n    \n    reduce_lr_loss = ReduceLROnPlateau(\n        monitor='val_loss', \n        factor=0.1, \n        patience=5, \n        verbose=1, \n        epsilon=1e-4, \n        mode='min')\n    \n    model.fit(\n        train_features.values[train],\n        train_targets.values[train],\n        validation_data=(train_features.values[test], train_targets.values[test]),\n        epochs=EPOCHS, \n        batch_size=BATCHES,\n        callbacks=[reduce_lr_loss], \n        verbose=2\n             )\n        \n    def _score(X, y):\n        pred = model.predict(X)\n        return metric(y, pred)\n\n    base_score, local_imp = get_score_importances(\n        _score, \n        train_features.values[test], \n        train_targets.values[test], \n        n_iter=1, \n        random_state=0)\n    \n    perm_imp += np.mean(local_imp, axis=0)\n    print('')\n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"perm_imp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"perm_imp_dict = dict(zip(list(train_features.columns[1:]), perm_imp))\nperm_imp_dict = dict(sorted(perm_imp_dict.items(), key=lambda x: x[1], reverse=True))\nperm_imp_df = pd.DataFrame(perm_imp_dict, index = pd.RangeIndex(1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Histogram plot of 50 most important features\nfig = px.bar(\n    perm_imp_df.iloc[:,:50].transpose(),\n    template=\"simple_white\")\n\n# Layout   \nfig.update_layout(\n    showlegend=False,     \n    autosize=False,\n    width=900,\n    height=300, \n    margin={'l': 20, 'r': 20, 't':  20, 'b': 20},\n    xaxis_title = \"Feature importance\",\n    yaxis_title = \"Features\")\n    \n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Histogram plot of 50 least important features\nfig = px.bar(\n    perm_imp_df.iloc[:,822:].transpose(),\n    template=\"simple_white\")\n\n# Layout   \nfig.update_layout(\n    showlegend=False,     \n    autosize=False,\n    width=900,\n    height=300, \n    margin={'l': 20, 'r': 20, 't':  20, 'b': 20},\n    xaxis_title = \"Feature importance\",\n    yaxis_title = \"Features\")\n    \n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission file"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replace all MoA predictions for control perturbations in testing dataset with zeros\ntest_predictions.loc[test_features['cp_type']==1, train_targets.columns] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_predictions.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Source material\n- https://www.kaggle.com/elcaiseri/moa-keras-multilabel-classifier-nn-starter\n- https://www.kaggle.com/stanleyjzheng/baseline-nn-with-k-folds"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}