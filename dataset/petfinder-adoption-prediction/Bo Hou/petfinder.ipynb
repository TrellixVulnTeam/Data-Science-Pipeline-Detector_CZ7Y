{"cells":[{"metadata":{},"cell_type":"markdown","source":"# PetFinder.my Adoption Comptetition"},{"metadata":{"trusted":true},"cell_type":"code","source":"import glob\nimport json\nimport pandas as pd\nimport numpy as np\nimport scipy as sp\nfrom functools import partial\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kaggle_path = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if kaggle_path:\n    train = pd.read_csv('../input/petfinder-adoption-prediction/train/train.csv')\n    test = pd.read_csv('../input/petfinder-adoption-prediction/test/test.csv')\n    colors = pd.read_csv('../input/petfinder-adoption-prediction/color_labels.csv', index_col=0)\n    breeds = pd.read_csv('../input/petfinder-adoption-prediction/breed_labels.csv')\nelse:\n    train = pd.read_csv('train.csv')\n    test = pd.read_csv('test.csv')\n    colors = pd.read_csv('color_labels.csv', index_col=0)\n    breeds = pd.read_csv('breed_labels.csv')\n\ndf = pd.concat([train, test], ignore_index=True, sort=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"breeds['type_breed'] = breeds['Type']*1000+breeds['BreedID']\nbreeds = breeds['BreedName'].set_axis(breeds['type_breed'], inplace=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Processing breed columns\ndf['Type_Breed1'] = df['Type']*1000+df['Breed1']\ndf['Type_Breed2'] = df['Type']*1000+df['Breed2']\ndf['Breed'] = df['Type_Breed1'].apply(str) + df['Type_Breed2'].apply(str)\n# For each breed combination, replace name with group count and mean target\ndf['Breed_count'] = df['Breed'].map(df['Breed'].value_counts())\n#df['Breed_mean'] = df['Breed'].map(df.groupby('Breed')['AdoptionSpeed'].mean().fillna(df['AdoptionSpeed'].mean()))\n# Create column for pure-breed animals\ndf['PureBreed'] = (df['Breed1']*df['Breed2']).map(lambda x: 1 if x==0 else 0)\ndf.loc[df['Breed1']==307, 'PureBreed'] = 0 # 307=Mixed\ndf.loc[df['Breed2']==307, 'PureBreed'] = 0 # 307=Mixed","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Convert color variables into sparse matrices\n# probably not the best way but it works\nfor col in ['Color1', 'Color2', 'Color3']:\n    df[col] = df[col].map(colors.to_dict()['ColorName'])\nfor color in colors['ColorName'].tolist():\n    is_color = lambda x: x==color\n    df[color] = df.apply(lambda x: is_color(x['Color1']) or is_color(x['Color2']) or is_color(x['Color3']), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df['Type'] = df['Type'].map(lambda x: x-1) # 0=dog, 1=cat\ndf['Nameless'] = df['Name'].isna() # create column for animals with no name\ndf=pd.concat([df, pd.get_dummies(df['Gender'], prefix='Gender_')], axis=1)\ndf.loc[df['Name']=='No Name', 'Nameless'] = True # 73 animals named \"No Name\"\ndf['Has_fee'] = df['Fee'].map(lambda x: 1 if x>0 else 0)\n\ndf['Rescuer_freq'] = df['RescuerID'].map(df['RescuerID'].value_counts())\n#df['Rescuer_mean'] = df['RescuerID'].map(df.groupby('RescuerID')['AdoptionSpeed'].mean().fillna(df['AdoptionSpeed'].mean()))\ndf['State_freq'] = df['State'].map(df['State'].value_counts())\n#df['State_mean'] = df['State'].map(df.groupby('State')['AdoptionSpeed'].mean().fillna(df['AdoptionSpeed'].mean()))\n\nfor col in ['Vaccinated', 'Dewormed', 'Sterilized']:\n    df[col] = df[col].map(lambda x: 1 if x==1 else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"for col in df.columns:\n    if df[col].dtype == bool:\n        df[col] = df[col].map(lambda x: 1 if x else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df = df.drop(['Name', 'Breed1', 'Breed2', 'Gender', 'Gender__3',\n              'Color1', 'Color2', 'Color3', 'Type_Breed1', 'Type_Breed2', 'Breed',\n              'State', 'RescuerID', 'Description'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Add Sentiment Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"if kaggle_path:\n    train_sentiment_data = glob.glob('../input/petfinder-adoption-prediction/train_sentiment/*.json')\n    test_sentiment_data = glob.glob('../input/petfinder-adoption-prediction/test_sentiment/*.json')\nelse:\n    train_sentiment_data = glob.glob('train_sentiment/*.json')\n    test_sentiment_data = glob.glob('test_sentiment/*.json')\nprint (len(train_sentiment_data), len(test_sentiment_data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def load_sentiment(file):\n    with open(file, 'r', encoding='utf-8') as f:\n        j = json.load(f)\n    magnitudes = np.array([x['magnitude'] for x in [y['sentiment'] for y in j['sentences']]])\n    scores = np.array([x['score'] for x in [y['sentiment'] for y in j['sentences']]])\n    text_mag_sum = magnitudes.sum()\n    text_mag_avg = magnitudes.mean()\n    text_mag_var = magnitudes.var()\n    text_score_sum = scores.sum()\n    text_score_avg = scores.mean()\n    text_score_var = scores.var()\n    doc_mag = j['documentSentiment']['magnitude']\n    doc_score = j['documentSentiment']['score']\n    return (doc_mag, doc_score, text_mag_sum, text_mag_avg, text_mag_var, text_score_sum, text_score_avg, text_score_var)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_sentiment = {}\nfor file in train_sentiment_data:\n    r = load_sentiment(file)\n    petid = file.split('train_sentiment/')[1].split('.')[0]\n    train_sentiment[petid] = r\n    \ntest_sentiment = {}\nfor file in test_sentiment_data:\n    r = load_sentiment(file)\n    petid = file.split('test_sentiment/')[1].split('.')[0]\n    test_sentiment[petid] = r","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sentiment = pd.concat([pd.DataFrame(train_sentiment).T, pd.DataFrame(test_sentiment).T])\nsentiment = sentiment.reset_index()\nsentiment.columns=['PetID', 'doc_mag', 'doc_score', 'text_mag_sum', 'text_mag_avg', \n                   'text_mag_var', 'text_score_sum', 'text_score_avg', 'text_score_var']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df = df.merge(sentiment, how='left', on='PetID')\nfor col in list(sentiment.columns.drop('PetID')):\n    df[col] = df[col].fillna(df[col].mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Add Metadata"},{"metadata":{"trusted":false},"cell_type":"code","source":"if kaggle_path:\n    train_metadata_paths = glob.glob('../input/petfinder-adoption-prediction/train_metadata/*-1.json')\n    test_metadata_paths = glob.glob('../input/petfinder-adoption-prediction/test_metadata/*-1.json')\nelse:\n    train_metadata_paths = glob.glob('train_metadata/*-1.json')\n    test_metadata_paths = glob.glob('test_metadata/*-1.json')\nprint (len(train_metadata_paths), len(test_metadata_paths))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def extract_colors(d):\n    try:\n        red = d['red']\n    except KeyError:\n        red = 0\n    try:\n        blue = d['blue']\n    except KeyError:\n        blue = 0\n    try:\n        green = d['green']\n    except KeyError:\n        green = 0\n    return red, blue, green\n\ndef load_metadata(file):\n    with open(file, 'r', encoding='utf-8') as f:\n        j = json.load(f)\n    try: \n        annotations = j['labelAnnotations']\n        #label_descs = np.array([x['description'] for x in annotations])\n        label_scores_mean = np.array([x['score'] for x in annotations]).mean()\n        label_topicality_mean = np.array([x['topicality'] for x in annotations]).mean()\n    except KeyError:\n        label_scores_mean = np.nan\n        label_topicality_mean = np.nan\n    colors = j['imagePropertiesAnnotation']['dominantColors']['colors']\n    color_rgbs = np.array([x['color'] for x in colors]) \n    reds = []\n    blues = []\n    greens = []\n    for d in color_rgbs:\n        red, blue, green = extract_colors(d)\n        reds.append(red)\n        blues.append(blue)\n        greens.append(green)\n    color_red_mean = np.array(reds).mean()\n    color_blue_mean = np.array(blues).mean()\n    color_green_mean = np.array(greens).mean()\n    color_score_mean = np.array([x['score'] for x in colors]).mean()\n    color_fraction_mean = np.array([x['pixelFraction'] for x in colors]).mean()\n    crops = j['cropHintsAnnotation']['cropHints']\n    crop_confidence_mean = np.array([x['confidence'] for x in crops]).mean()\n    return (label_scores_mean, label_topicality_mean, \n            color_red_mean, color_blue_mean, color_green_mean,\n            color_score_mean, color_fraction_mean,\n            crop_confidence_mean)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_metadata = {}\nfor file in train_metadata_paths:\n    r = load_metadata(file)\n    petid = file.split('train_metadata/')[1].split('-1.')[0]\n    train_metadata[petid] = r\n    \ntest_metadata = {}\nfor file in test_metadata_paths:\n    r = load_metadata(file)\n    petid = file.split('test_metadata/')[1].split('-1.')[0]\n    test_metadata[petid] = r","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"metadata = pd.concat([pd.DataFrame(train_metadata).T, pd.DataFrame(test_metadata).T])\nmetadata = metadata.reset_index()\nmetadata.columns=['PetID', 'label_scores_mean', 'label_topicality_mean', 'color_red_mean', 'color_blue_mean', 'color_green_mean', \n                  'color_score_mean', 'color_fraction_mean', 'crop_confidence_mean']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df = df.merge(metadata, how='left', on='PetID')\nfor col in list(metadata.columns.drop('PetID')):\n    df[col] = df[col].fillna(df[col].mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Incorporating Extracted Feature form Pictures\nCredit: https://www.kaggle.com/christofhenkel/extract-image-features-from-pretrained-nn/output"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_img_features = pd.read_csv('../input/extracted-image-features-petfinder/train_img_features.csv')\ntest_img_features = pd.read_csv('../input/extracted-image-features-petfinder/test_img_features.csv')\nimg_features = pd.concat([train_img_features, test_img_features], ignore_index=True)\nnew_cols = ['image_'+str(i) for i in range(256)]\nnew_cols.insert(0, 'PetID')\nimg_features.columns = new_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.decomposition import PCA\nimg_X = img_features.drop('PetID', axis=1).values\nn_components = 64\npca_model = PCA(n_components).fit(img_X)\nprint(pca_model.explained_variance_ratio_.sum())  \nimg_X_new = pca_model.transform(img_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"img_features_new = pd.DataFrame(img_X_new)\nimg_features_new.columns = ['image_'+str(i) for i in range(n_components)]\nimg_features_new['PetID'] = img_features['PetID']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df = df.merge(img_features_new, how='left', on='PetID')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import cohen_kappa_score\nimport xgboost as xgb","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Trainer Borrowed from Kaggle"},{"metadata":{"trusted":false},"cell_type":"code","source":"class OptimizedRounder(object):\n    def __init__(self):\n        self.coef_ = 0\n    \n    def _kappa_loss(self, coef, X, y):\n        preds = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3, 4])\n        return -cohen_kappa_score(y, preds, weights='quadratic')\n    \n    def fit(self, X, y):\n        loss_partial = partial(self._kappa_loss, X = X, y = y)\n        initial_coef = [0.5, 1.5, 2.5, 3.5]\n        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n    \n    def predict(self, X, coef):\n        preds = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3, 4])\n        return preds\n    \n    def coefficients(self):\n        return self.coef_['x']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"params_xgb1 = {'eval_metric': 'rmse', \n               'mex_depth': 6,\n               'seed': 0, \n               'eta': 0.01, \n               'gamma': 0.03,\n               'subsample': 0.8, \n               'colsample_bytree': 0.85, \n               'colsample_bylevel': 0.85, \n               'silent': 1}","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def run_xgb(params, X_train, X_test):\n    n_splits = 10\n    verbose_eval = 1000\n    num_rounds = 60000\n    early_stop = 500\n\n    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=1337)\n    oof_train = np.zeros((X_train.shape[0]))\n    oof_test = np.zeros((X_test.shape[0], n_splits))\n\n    i = 0\n\n    for train_idx, valid_idx in kf.split(X_train, X_train['AdoptionSpeed'].values):\n\n        X_tr = X_train.iloc[train_idx, :]\n        X_val = X_train.iloc[valid_idx, :]\n        y_tr = X_tr['AdoptionSpeed'].values\n        X_tr = X_tr.drop(['AdoptionSpeed'], axis=1)\n        y_val = X_val['AdoptionSpeed'].values\n        X_val = X_val.drop(['AdoptionSpeed'], axis=1)\n        d_train = xgb.DMatrix(data=X_tr, label=y_tr, feature_names=X_tr.columns)\n        d_valid = xgb.DMatrix(data=X_val, label=y_val, feature_names=X_val.columns)\n        watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n        model = xgb.train(dtrain=d_train, num_boost_round=num_rounds, evals=watchlist,\n                          early_stopping_rounds=early_stop, verbose_eval=verbose_eval, params=params)\n\n        valid_pred = model.predict(xgb.DMatrix(X_val, feature_names=X_val.columns), ntree_limit=model.best_ntree_limit)\n        test_pred = model.predict(xgb.DMatrix(X_test, feature_names=X_test.columns), ntree_limit=model.best_ntree_limit)\n\n        oof_train[valid_idx] = valid_pred\n        oof_test[:, i] = test_pred\n\n        i += 1\n    return model, oof_train, oof_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_train_non_null = df[df['AdoptionSpeed'].notnull()].drop(['PetID'], axis=1)\nX_test_non_null = df[df['AdoptionSpeed'].isnull()].drop(['PetID', 'AdoptionSpeed'], axis=1)\nmodel, oof_train, oof_test = run_xgb(params_xgb1, X_train_non_null, X_test_non_null)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"optR = OptimizedRounder()\noptR.fit(oof_train, X_train_non_null['AdoptionSpeed'].values)\ncoefficients = optR.coefficients()\nvalid_pred = optR.predict(oof_train, coefficients)\nqwk = cohen_kappa_score(X_train_non_null['AdoptionSpeed'], valid_pred, weights='quadratic')\nprint(\"QWK = %.4f\" % qwk)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"optR.coefficients()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test_predictions = optR.predict(oof_test.mean(axis=1), coefficients).astype(np.int8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Private: 0.38581\nsubmission = pd.DataFrame({'PetID': test['PetID'].values, 'AdoptionSpeed': test_predictions})\nsubmission.to_csv('submission.csv', index=False)\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"xgb.plot_importance(model, max_num_features=24, height=0.8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"nbformat":4,"nbformat_minor":1}