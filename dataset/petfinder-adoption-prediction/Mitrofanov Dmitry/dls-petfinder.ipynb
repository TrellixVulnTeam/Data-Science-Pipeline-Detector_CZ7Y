{"cells":[{"metadata":{},"cell_type":"markdown","source":"## This notebook was created as a Kaggle tutorial for a lecture at [Deep Learning School](https://www.dlschool.org/?lang=en)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport tqdm\nimport torch\n\nimport numpy as np\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's check that GPU is working correctly!"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!nvidia-smi","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Make sure that the internet is turned on as well:"},{"metadata":{"trusted":true},"cell_type":"code","source":"!ping -c 4 google.com","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{},"cell_type":"markdown","source":"First, let's locate our data..."},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input/petfinder-adoption-prediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input/petfinder-adoption-prediction/train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, read the train `.csv` file:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/petfinder-adoption-prediction/train/train.csv')\ntrain.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see the train size."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Or, even better:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The `dtype` of `PhotoAmt` column looks weird! Let's change it to `np.int64` so that it matches the others."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.PhotoAmt = train.PhotoAmt.astype(np.int64)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's look at the target distribution:"},{"metadata":{"trusted":true},"cell_type":"code","source":"#########################\n## YOUR CODE GOES HERE ##\n#########################\n# Hint: use np.unique\n\nnp.unique(train.AdoptionSpeed, return_counts=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Question: what can we say about class imbalance?\n### Question: which features can we expect to correlate with the target?"},{"metadata":{},"cell_type":"markdown","source":"For this tutorial, we will remove the text data."},{"metadata":{"trusted":true},"cell_type":"code","source":"def filter_text_columns(table):\n    _blacklist = ['Name', 'RescuerID', 'Description', 'PetID']\n    for column in _blacklist:\n        if column in table.columns:\n            del table[column]\n\nfilter_text_columns(train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's separate the data from the target:"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = np.array(train.iloc[:,:-1])\ny = np.array(train.AdoptionSpeed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert X.shape == (14993, 19)\nassert y.shape == (14993,)\nprint(\"Good job!\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Question: Can we calculate the dataset statistics at this point?"},{"metadata":{"trusted":true},"cell_type":"code","source":"# X -= X.mean(axis=0) ?","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Splitting the data"},{"metadata":{},"cell_type":"markdown","source":"Before we move any further, we need to make sure we have a validation set. We'll use a simple hold-out validation for now.\n\nNow, create a **stratified** validation set with `20%` validation size. Make sure to **fix your random seed**!"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n\nrandom_state = 42\n\n#########################\n## YOUR CODE GOES HERE ##\n#########################\nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=random_state, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert X_train.shape == (11994, 19)\nassert y_train.shape == (11994,)\nassert X_test.shape == (2999, 19)\nassert y_test.shape == (2999,)\n\nassert np.sum(X_train) == 500668689\nassert np.sum(X_test) == 125179430\nprint(\"Nice!\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Building our first pipeline"},{"metadata":{},"cell_type":"markdown","source":"Obviously, we need a metric for this.."},{"metadata":{},"cell_type":"markdown","source":"### Challenge #1: find out how to implement the metric!"},{"metadata":{"trusted":true},"cell_type":"code","source":"# The following 3 functions have been taken from Ben Hamner's github repository\n# https://github.com/benhamner/Metrics\ndef Cmatrix(rater_a, rater_b, min_rating=None, max_rating=None):\n    \"\"\"\n    Returns the confusion matrix between rater's ratings\n    \"\"\"\n    assert(len(rater_a) == len(rater_b))\n    if min_rating is None:\n        min_rating = min(rater_a + rater_b)\n    if max_rating is None:\n        max_rating = max(rater_a + rater_b)\n    num_ratings = int(max_rating - min_rating + 1)\n    conf_mat = [[0 for i in range(num_ratings)]\n                for j in range(num_ratings)]\n    for a, b in zip(rater_a, rater_b):\n        conf_mat[a - min_rating][b - min_rating] += 1\n    return conf_mat\n\n\ndef histogram(ratings, min_rating=None, max_rating=None):\n    \"\"\"\n    Returns the counts of each type of rating that a rater made\n    \"\"\"\n    if min_rating is None:\n        min_rating = min(ratings)\n    if max_rating is None:\n        max_rating = max(ratings)\n    num_ratings = int(max_rating - min_rating + 1)\n    hist_ratings = [0 for x in range(num_ratings)]\n    for r in ratings:\n        hist_ratings[r - min_rating] += 1\n    return hist_ratings\n\n\ndef quadratic_weighted_kappa(y, y_pred):\n    \"\"\"\n    Calculates the quadratic weighted kappa\n    axquadratic_weighted_kappa calculates the quadratic weighted kappa\n    value, which is a measure of inter-rater agreement between two raters\n    that provide discrete numeric ratings.  Potential values range from -1\n    (representing complete disagreement) to 1 (representing complete\n    agreement).  A kappa value of 0 is expected if all agreement is due to\n    chance.\n    quadratic_weighted_kappa(rater_a, rater_b), where rater_a and rater_b\n    each correspond to a list of integer ratings.  These lists must have the\n    same length.\n    The ratings should be integers, and it is assumed that they contain\n    the complete range of possible ratings.\n    quadratic_weighted_kappa(X, min_rating, max_rating), where min_rating\n    is the minimum possible rating, and max_rating is the maximum possible\n    rating\n    \"\"\"\n    rater_a = y\n    rater_b = y_pred\n    min_rating=None\n    max_rating=None\n    rater_a = np.array(rater_a, dtype=int)\n    rater_b = np.array(rater_b, dtype=int)\n    assert(len(rater_a) == len(rater_b))\n    if min_rating is None:\n        min_rating = min(min(rater_a), min(rater_b))\n    if max_rating is None:\n        max_rating = max(max(rater_a), max(rater_b))\n    conf_mat = Cmatrix(rater_a, rater_b,\n                                min_rating, max_rating)\n    num_ratings = len(conf_mat)\n    num_scored_items = float(len(rater_a))\n\n    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n\n    numerator = 0.0\n    denominator = 0.0\n\n    for i in range(num_ratings):\n        for j in range(num_ratings):\n            expected_count = (hist_rater_a[i] * hist_rater_b[j]\n                              / num_scored_items)\n            d = pow(i - j, 2.0) / pow(num_ratings - 1, 2.0)\n            numerator += d * conf_mat[i][j] / num_scored_items\n            denominator += d * expected_count / num_scored_items\n\n    return (1.0 - numerator / denominator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def metric(y_true, y_pred):\n    #########################\n    ## YOUR CODE GOES HERE ##\n    #########################\n#     return quadratic_weighted_kappa(y_true, y_pred)\n    from sklearn.metrics import cohen_kappa_score\n    return cohen_kappa_score(y_true, y_pred, weights='quadratic')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert np.abs(1 - metric(y_train, y_train)) <= 1e-7\nassert np.abs(1 - metric(y_test, y_test)) <= 1e-7\nassert np.abs(metric(y_test, y_test + 1) - 0.7349020406) <= 1e-7\nprint(\"Awesome!\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's build our first pipeline!"},{"metadata":{"trusted":true},"cell_type":"code","source":"def vanilla_pipeline(model):\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    return metric(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Basic model: k-NN Classifier!"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nclf = KNeighborsClassifier()\nvanilla_pipeline(clf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Still something! Now, select the classifier with the best K (K < 10)."},{"metadata":{"trusted":true},"cell_type":"code","source":"#for i in range(1,10):\n #    clf = KNeighborsClassifier(n_neighbors=i)\n  #   print(vanilla_pipeline(clf))\n\nkNN = KNeighborsClassifier(n_neighbors=9)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert vanilla_pipeline(kNN) >= 0.26, \"Your classifier isn't the best!\"\nprint(\"Cool!\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Question: is K-NN a meaningful architecture for EXACTLY this data? What about linear models? Tree-based models?"},{"metadata":{},"cell_type":"markdown","source":"Let's try a more meaningful model."},{"metadata":{},"cell_type":"markdown","source":"### Try out Random Forest classifier with `n_estimators` equal to `25` at max (hint: set `n_jobs=4` to speed things up)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#########################\n## YOUR CODE GOES HERE ##\n#########################\n\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators=25, n_jobs=4)\nvanilla_pipeline(rf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert vanilla_pipeline(rf) >= 0.27\nprint(\"Nice!\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature engineering"},{"metadata":{},"cell_type":"markdown","source":"Notice that we haven't changed any input data. What if we want to do any preprocessing or feature engineering? Let's look at images first."},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input/petfinder-adoption-prediction/train_images/ | head -20","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimage_list = sorted(os.listdir('../input/petfinder-adoption-prediction/train_images/'))\nimage_list[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image\nimage = Image.open('../input/petfinder-adoption-prediction/train_images/0008c5398-1.jpg')\nimage","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we may want to calculate image embeddings for our images. Let us use `torchvision.models` for this. First, let's define our transform:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from torchvision import transforms\n\n# Defining transform\ntransform = transforms.Compose([            \n transforms.Resize(224),               \n transforms.ToTensor(),                     \n transforms.Normalize(                      \n mean=[0.485, 0.456, 0.406],            \n std=[0.229, 0.224, 0.225]              \n )])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, let's take **ResNet-50** pretrained embeddings. Make sure that you enable CUDA and set training type to `eval`."},{"metadata":{"trusted":true},"cell_type":"code","source":"import torchvision.models as models\n\n#########################\n## YOUR CODE GOES HERE ##\n#########################\n\n\nmobilenet = models.mobilenet_v2(pretrained=True).cuda()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now everything is ready to calculate the embeddings. For this, we need to:\n* Transform an image\n* Create a batch containing this image and convert it to CUDA\n* Make predictions\n* Convert predictions to numpy and ravel"},{"metadata":{"trusted":true},"cell_type":"code","source":"def calc_embedding(image):\n    #########################\n    ## YOUR CODE GOES HERE ##\n    #########################\n    \n    transformed = transform(image)\n    batch = transformed.unsqueeze(0)\n    predictions = mobilenet(batch.cuda())\n    return predictions.cpu().detach().numpy().ravel()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's test your implementation."},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding.std()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Testing\nembedding = calc_embedding(image)\n\nassert torch.cuda.current_device() == 0, \"Are you sure you're using CUDA?\"\nassert type(embedding) == np.ndarray, \"Make sure to convert the result to numpy.array\"\nassert embedding.dtype == np.float32, \"Convert your embedding to float32\"\nassert embedding.shape == (1000,), \"Make sure to ravel the predictions\"\n#assert np.abs(embedding.mean() - 8.483887e-06) <= 1e-6\n#assert np.abs(embedding.std() - 2.0538368) <= 1e-6\nprint(\"Fabulous!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some convenience functions:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def _get_default_photo_path(pet_id):\n    return '../input/petfinder-adoption-prediction/train_images/%s-1.jpg' % pet_id\n\ndef does_pet_have_photo(pet_id):\n    return os.path.exists(_get_default_photo_path(pet_id))\n\ndef photo_of_pet(pet_id):\n    path = _get_default_photo_path(pet_id)\n    return Image.open(path).convert('RGB')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, let's get the embeddings for the test set!"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/petfinder-adoption-prediction/train/train.csv')\ntrain.PhotoAmt = train.PhotoAmt.astype(np.int64)\n\n# We'll store our embeddings here\nembeddings = np.zeros((len(train), embedding.shape[0]), dtype=np.float32)\n\npet_ids = train.PetID\nfor i in tqdm.tqdm_notebook(range(len(train))):\n    pet_id = pet_ids[i]\n    \n    if does_pet_have_photo(pet_id):\n        embeddings[i] = calc_embedding(photo_of_pet(pet_id))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embeddings.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, everything is ready to create a new dataset. For that, we just need to stack our features and the new embeddings."},{"metadata":{"trusted":true},"cell_type":"code","source":"filter_text_columns(train)\n\nX = np.array(train.iloc[:,:-1])\ny = np.array(train.AdoptionSpeed)\n\n#########################\n## YOUR CODE GOES HERE ##\n#########################\n\nX = np.hstack([X, embeddings])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert X.shape == (14993, 1019)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's split the data into train/test as before.."},{"metadata":{"trusted":true},"cell_type":"code","source":"random_state = 42\n\n#########################\n## YOUR CODE GOES HERE ##\n#########################\nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=random_state, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Try out the `RandomForestClassifier`:"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(n_estimators=25, n_jobs=4, random_state=42)\nvanilla_pipeline(rf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Question: why the result is so poor?"},{"metadata":{},"cell_type":"markdown","source":"Let's get the train and test *embeddings* only"},{"metadata":{"trusted":true},"cell_type":"code","source":"#########################\n## YOUR CODE GOES HERE ##\n#########################\n\nX_train_feats = X_train[:,-1000:]\nX_test_feats = X_test[:,-1000:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's use `TruncatedSVD`. Convert `X_train_feats` and `X_test_feats` to the new 6-dimensional space."},{"metadata":{},"cell_type":"markdown","source":"# PCA(n_components=0.95)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import TruncatedSVD\n\nn_feats = 6\nrandom_state = 42\n\n#########################\n## YOUR CODE GOES HERE ##\n#########################\npca = TruncatedSVD(n_components=n_feats)\npca.fit(X_train_feats)\nX_train_feats = pca.transform(X_train_feats)\nX_test_feats = pca.transform(X_test_feats)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, let's fit out SVD on the train image features."},{"metadata":{"trusted":true},"cell_type":"code","source":"#########################\n## YOUR CODE GOES HERE ##\n#########################\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we need to modify `X_train` and `X_test` to include compressed embeddings.\n\n**Challenge: can you do this in 2 lines?**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#########################\n## YOUR CODE GOES HERE ##\n#########################\n\nX_train = np.hstack([X_train[:,:19], X_train_feats])\nX_test = np.hstack([X_test[:,:19], X_test_feats])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's check our result now!"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(n_estimators=25, n_jobs=4, random_state=42)\nvanilla_pipeline(rf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nice!"},{"metadata":{},"cell_type":"markdown","source":"### Question: what would you do with text?"},{"metadata":{},"cell_type":"markdown","source":"Let's improve our result a little bit by using CatBoost!"},{"metadata":{"trusted":true},"cell_type":"code","source":"from catboost import CatBoostClassifier\n\n#########################\n## YOUR CODE GOES HERE ##\n#########################\n\ncb = CatBoostClassifier()\nvanilla_pipeline(cb)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, it's time to make predictions for the test set! Don't forget to include image embeddings!"},{"metadata":{},"cell_type":"markdown","source":"* убрать текстовые фичи\n* привести все к np.int64\n* посчитать картиночные фичи\n* понизить пространство картиночных фичей\n* сконкатить все\n* model.predict(...)"},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/petfinder-adoption-prediction/test/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def _get_default_photo_path(pet_id):\n    return '../input/petfinder-adoption-prediction/test_images/%s-1.jpg' % pet_id\n\ndef does_pet_have_photo(pet_id):\n    return os.path.exists(_get_default_photo_path(pet_id))\n\ndef photo_of_pet(pet_id):\n    path = _get_default_photo_path(pet_id)\n    return Image.open(path).convert('RGB')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We'll store our embeddings here\nembeddings = np.zeros((len(test), 1000), dtype=np.float32)\n\npet_ids = test.PetID\nfor i in tqdm.tqdm_notebook(range(len(test))):\n    pet_id = pet_ids[i]\n    \n    if does_pet_have_photo(pet_id):\n        embeddings[i] = calc_embedding(photo_of_pet(pet_id))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filter_text_columns(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = test.astype(np.int64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_feats = pca.transform(embeddings)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = test\nX_test = np.hstack([X_test, X_test_feats])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.PhotoAmt = train.PhotoAmt.astype(np.int64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = np.zeros(len(test), dtype=np.int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def _get_default_photo_path(pet_id):\n    return '../input/petfinder-adoption-prediction/test_images/%s-1.jpg' % pet_id\n\ndef does_pet_have_photo(pet_id):\n    return os.path.exists(_get_default_photo_path(pet_id))\n\ndef photo_of_pet(pet_id):\n    path = _get_default_photo_path(pet_id)\n    return Image.open(path).convert('RGB')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n\n# We'll store our embeddings here\nembeddings = np.zeros((len(test), 1000), dtype=np.float32)\n\npet_ids = test.PetID\nfor i in tqdm.tqdm_notebook(range(len(test))):\n    pet_id = pet_ids[i]\n    \n    if does_pet_have_photo(pet_id):\n        embeddings[i] = calc_embedding(photo_of_pet(pet_id))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filter_text_columns(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def _get_default_photo_path(pet_id):\n    return '../input/petfinder-adoption-prediction/test_images/%s-1.jpg' % pet_id\n\ndef does_pet_have_photo(pet_id):\n    return os.path.exists(_get_default_photo_path(pet_id))\n\ndef photo_of_pet(pet_id):\n    path = _get_default_photo_path(pet_id)\n    return Image.open(path).convert('RGB')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We'll store our embeddings here\nembeddings = np.zeros((len(test), 1000), dtype=np.float32)\n\npet_ids = test.PetID\nfor i in tqdm.tqdm_notebook(range(len(test))):\n    pet_id = pet_ids[i]\n    \n    if does_pet_have_photo(pet_id):\n        embeddings[i] = calc_embedding(photo_of_pet(pet_id))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filter_text_columns(test)\ntest = test.astype(np.int64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embeddings.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca.transform(embeddings)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = test\nX_test = np.hstack([X_test, X_test_feats])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, let's submit our result."},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission = pd.read_csv('../input/petfinder-adoption-prediction/test/sample_submission.csv')\nsample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = sample_submission\nsubmission['AdoptionSpeed'] = predictions\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}