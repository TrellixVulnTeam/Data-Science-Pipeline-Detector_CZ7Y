{"cells":[{"metadata":{"_uuid":"869e7fa91b856778288e7978d8ef4b5cf3a564e0"},"cell_type":"markdown","source":"### ** in work**\n"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom scipy import stats\nfrom scipy.stats import norm\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nsns.set_style('darkgrid')\nsns.set(rc={'figure.figsize':(12, 10)})\n\nimport os\nprint(os.listdir(\"../input\"))\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/train/train.csv')\ntest_df = pd.read_csv('../input/test/test.csv')\ny = train_df['AdoptionSpeed']\ntrain_df['dataset_type'] = 'train'\ntest_df['dataset_type'] = 'test'\ntrain_id = train_df['PetID']\ntest_id = test_df['PetID']\nall_data0 = pd.concat([train_df, test_df])\nall_data = all_data0.drop(columns = 'AdoptionSpeed')\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5943f5c1f1541132e8b8bfa1681f93c7a132e92e","trusted":true},"cell_type":"code","source":"print(train_df.shape)\nprint(test_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ae907b1e30b819d9751d0f416fff2b2258f81a1c","trusted":true},"cell_type":"code","source":"display(train_df.describe())\ndisplay(train_df.info())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9564edab77a9c1ccf3eba9ff7447c21a7f5a89b3","trusted":true},"cell_type":"markdown","source":"### Data Fields  \n* PetID - Unique hash ID of pet profile\n* AdoptionSpeed - Categorical speed of adoption. Lower is faster. This is the value to predict. See below section for more info.\n* Type - Type of animal (1 = Dog, 2 = Cat)\n* Name - Name of pet (Empty if not named)\n* Age - Age of pet when listed, in months\n* Breed1 - Primary breed of pet (Refer to BreedLabels dictionary)\n* Breed2 - Secondary breed of pet, if pet is of mixed breed (Refer to BreedLabels dictionary)\n* Gender - Gender of pet (1 = Male, 2 = Female, 3 = Mixed, if profile represents group of pets)\n* Color1 - Color 1 of pet (Refer to ColorLabels dictionary)\n* Color2 - Color 2 of pet (Refer to ColorLabels dictionary)\n* Color3 - Color 3 of pet (Refer to ColorLabels dictionary)\n* MaturitySize - Size at maturity (1 = Small, 2 = Medium, 3 = Large, 4 = Extra Large, 0 = Not Specified)\n* FurLength - Fur length (1 = Short, 2 = Medium, 3 = Long, 0 = Not Specified)\n* Vaccinated - Pet has been vaccinated (1 = Yes, 2 = No, 3 = Not Sure)\n* Dewormed - Pet has been dewormed (1 = Yes, 2 = No, 3 = Not Sure)\n* Sterilized - Pet has been spayed / neutered (1 = Yes, 2 = No, 3 = Not Sure)\n* Health - Health Condition (1 = Healthy, 2 = Minor Injury, 3 = Serious Injury, 0 = Not Specified)\n* Quantity - Number of pets represented in profile\n* Fee - Adoption fee (0 = Free)\n* State - State location in Malaysia (Refer to StateLabels dictionary)\n* RescuerID - Unique hash ID of rescuer\n* VideoAmt - Total uploaded videos for this pet\n* PhotoAmt - Total uploaded photos for this pet\n* Description - Profile write-up for this pet. The primary language used is English, with some in Malay or Chinese."},{"metadata":{"_uuid":"c2b82dada6ac2ff6b7da40565715d3349f884777"},"cell_type":"markdown","source":"### AdoptionSpeed  \nContestants are required to predict this value. The value is determined by how quickly, if at all, a pet is adopted. The values are determined in the following way:   \n0 - Pet was adopted on the same day as it was listed.   \n1 - Pet was adopted between 1 and 7 days (1st week) after being listed.   \n2 - Pet was adopted between 8 and 30 days (1st month) after being listed.   \n3 - Pet was adopted between 31 and 90 days (2nd & 3rd month) after being listed.  \n4 - No adoption after 100 days of being listed. (There are no pets in this dataset that waited between 90 and 100 days)."},{"metadata":{"trusted":true,"_uuid":"54f3d90b8deac0c9baaa1355c7cd716d1b84865b"},"cell_type":"code","source":"train_df['AdoptionSpeed'].value_counts().sort_index(ascending=False).plot(kind='barh', \n                                                                          figsize=(15,6))\nplt.title('Adoption Speed (Target)', fontsize=18)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e90312d3448bdaa0016fae33dfa8bb9114370f74"},"cell_type":"code","source":"plt.figure(figsize=(15,7))\nplt.subplot(121)\nsns.countplot(x='Type', data=train_df).set(xticklabels=['Dog', 'Cat'])\nplt.title('Type(train)', fontsize=18)\n\nplt.subplot(122)\nsns.countplot(x='Type', data=test_df).set(xticklabels=['Dog', 'Cat'])\nplt.title('Type(test)', fontsize=18)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8c57cf211f9f08fe974124fdfc6aac55af63e74d"},"cell_type":"code","source":"plt.figure(figsize=(10, 7))\nsns.countplot(x='Type', data=train_df, hue=\"AdoptionSpeed\").set(xticklabels=['Dog', 'Cat'])\nplt.title('Type/AdoptionSpeed(train)', fontsize=18)\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6a47791e3cf0bbae845df1d3e72575d4a7c7a030"},"cell_type":"code","source":"plt.figure(figsize=(10, 7))\nsns.countplot(x='Gender', data=train_df, hue=\"AdoptionSpeed\")\nplt.title('Gender/AdoptionSpeed(train)', fontsize=18)\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a4ba41a8789f8c12968cf8868b1d6b7321265a4c"},"cell_type":"code","source":"train_df['Mixed_Breed'] = train_df.apply(lambda x: 0 if x.Breed2==0 and x.Breed1!=307 else 1, axis=1)\ntrain_df['Num_Color'] = train_df.apply(lambda x:  3-sum([y==0 for y in [x.Color1, x.Color2, x.Color3]]), axis=1)\ntrain_df['Description'].fillna(\"\", inplace=True)\ntrain_df['Description_Length'] = train_df.Description.map(len)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9c40e4a6bbcd0781577e2bd419f82d5b304656f0"},"cell_type":"code","source":"test_df['Mixed_Breed'] = test_df.apply(lambda x: 0 if x.Breed2==0 and x.Breed1!=307 else 1, axis=1)\ntest_df['Num_Color'] = test_df.apply(lambda x:  3-sum([y==0 for y in [x.Color1, x.Color2, x.Color3]]), axis=1)\ntest_df['Description'].fillna(\"\", inplace=True)\ntest_df['Description_Length'] = test_df.Description.map(len)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bd03915ed32634a891adea29522e3574aff8ddbf"},"cell_type":"code","source":"plt.figure(figsize=(10, 7))\nsns.countplot(x='Mixed_Breed', data=train_df, hue=\"AdoptionSpeed\")\nplt.title('Mixed_Breed/AdoptionSpeed(train)', fontsize=18)\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d5a6e40c2c84ba02eeb154a9cfd7887d51f60479"},"cell_type":"code","source":"plt.figure(figsize=(10, 7))\nsns.countplot(x='Num_Color', data=train_df, hue=\"AdoptionSpeed\")\nplt.title('Num_Color/AdoptionSpeed(train)', fontsize=18)\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d2fdc1f5228bc7cc5f5e04bb56064270db69214f"},"cell_type":"code","source":"plt.figure(figsize=(15,7))\nplt.subplot(121)\nsns.distplot(train_df['Age'], fit=norm)\n\nplt.subplot(122)\nres = stats.probplot(train_df['Age'], plot=plt)\n\ndisplay(train_df['Age'].skew())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"30c32140408604fddccb0e3bf283dba067f48a9d"},"cell_type":"code","source":"plt.figure(figsize=(15,7))\nplt.subplot(121)\nsns.distplot((train_df['PhotoAmt']), fit=norm)\n\nplt.subplot(122)\nres = stats.probplot((train_df['PhotoAmt']), plot=plt)\n\ndisplay((train_df['PhotoAmt']).skew())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ea01aa307a52e289533c962fac7bee6b66797512"},"cell_type":"code","source":"plt.figure(figsize=(15,7))\nplt.subplot(121)\nsns.distplot((train_df['Description_Length']), fit=norm)\n\nplt.subplot(122)\nres = stats.probplot((train_df['Description_Length']), plot=plt)\n\ndisplay((train_df['Description_Length']).skew())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2671fb85d7e9c97dc06fcefa2a2d9ab5f4ed78c4"},"cell_type":"code","source":"import json\n#getting description sentiment analyses\n    \ndef get_desc_anly(type, recalc):\n    if recalc == 1:\n        if type == \"train\":\n            path = \"../input/train_sentiment/\"#../input/train_sentiment/\n        elif type == \"test\":\n            path = \"../input/test_sentiment/\"#../input/test_sentiment/\n        print(\"Getting description sentiment analysis for\",type+\"_sentiment.csv\")\n        files = [f for f in os.listdir(path) if (f.endswith('.json') & os.path.isfile(path+f))]\n\n        df = pd.DataFrame(columns=[\"PetID\", \"DescScore\", \"DescMagnitude\"])\n        i = 0\n        for f in files:\n            #print(path + f)\n            with open(path+f, encoding=\"utf8\") as json_data:\n                data = json.load(json_data)\n            \n            df.loc[i]= [f[:-5],data[\"documentSentiment\"][\"score\"],data[\"documentSentiment\"][\"magnitude\"]]\n            i = i+1\n        df.to_csv(type+\"_sentiment.csv\", index=False)\n    elif recalc == 0:\n        df = pd.read_csv(type+\"_sentiment.csv\")\n    return df\n\n    \ntrain_snt = get_desc_anly(\"train\", 1)\ntest_snt = get_desc_anly(\"test\", 1)\n    \ntrain_df = train_df.set_index(\"PetID\").join(train_snt.set_index(\"PetID\")).reset_index()\ntest_df = test_df.set_index(\"PetID\").join(test_snt.set_index(\"PetID\")).reset_index()\n\ntrain_df[\"DescScore\"].fillna(0, inplace=True)\ntrain_df[\"DescMagnitude\"].fillna(0, inplace=True)\n\ntrain_df[\"Name\"].fillna(\"none\", inplace=True)\ntest_df[\"DescScore\"].fillna(0, inplace=True)\ntest_df[\"DescMagnitude\"].fillna(0, inplace=True)\n\ntest_df[\"Name\"].fillna(\"\", inplace=True)\n\ntrain_df[\"NameLength\"] = train_df[\"Name\"].str.len()\ntest_df[\"NameLength\"] = test_df[\"Name\"].str.len()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6c833022ccce1569ef5e3a7703f31a40235fbe3e"},"cell_type":"code","source":"vertex_xs = []\nvertex_ys = []\nbounding_confidences = []\nbounding_importance_fracs = []\ndominant_blues = []\ndominant_greens = []\ndominant_reds = []\ndominant_pixel_fracs = []\ndominant_scores = []\nlabel_descriptions = []\nlabel_scores = []\nnf_count = 0\nnl_count = 0\nfor pet in train_id:\n    try:\n        with open('../input/train_metadata/' + pet + '-1.json', 'r') as f:\n            data = json.load(f)\n        vertex_x = data['cropHintsAnnotation']['cropHints'][0]['boundingPoly']['vertices'][2]['x']\n        vertex_xs.append(vertex_x)\n        vertex_y = data['cropHintsAnnotation']['cropHints'][0]['boundingPoly']['vertices'][2]['y']\n        vertex_ys.append(vertex_y)\n        bounding_confidence = data['cropHintsAnnotation']['cropHints'][0]['confidence']\n        bounding_confidences.append(bounding_confidence)\n        bounding_importance_frac = data['cropHintsAnnotation']['cropHints'][0].get('importanceFraction', -1)\n        bounding_importance_fracs.append(bounding_importance_frac)\n        dominant_blue = data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['color']['blue']\n        dominant_blues.append(dominant_blue)\n        dominant_green = data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['color']['green']\n        dominant_greens.append(dominant_green)\n        dominant_red = data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['color']['red']\n        dominant_reds.append(dominant_red)\n        dominant_pixel_frac = data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['pixelFraction']\n        dominant_pixel_fracs.append(dominant_pixel_frac)\n        dominant_score = data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['score']\n        dominant_scores.append(dominant_score)\n        if data.get('labelAnnotations'):\n            label_description = data['labelAnnotations'][0]['description']\n            label_descriptions.append(label_description)\n            label_score = data['labelAnnotations'][0]['score']\n            label_scores.append(label_score)\n        else:\n            nl_count += 1\n            label_descriptions.append('nothing')\n            label_scores.append(-1)\n    except FileNotFoundError:\n        nf_count += 1\n        vertex_xs.append(-1)\n        vertex_ys.append(-1)\n        bounding_confidences.append(-1)\n        bounding_importance_fracs.append(-1)\n        dominant_blues.append(-1)\n        dominant_greens.append(-1)\n        dominant_reds.append(-1)\n        dominant_pixel_fracs.append(-1)\n        dominant_scores.append(-1)\n        label_descriptions.append('nothing')\n        label_scores.append(-1)\n\nprint(nf_count)\nprint(nl_count)\ntrain_df.loc[:, 'vertex_x'] = vertex_xs\ntrain_df.loc[:, 'vertex_y'] = vertex_ys\ntrain_df.loc[:, 'bounding_confidence'] = bounding_confidences\ntrain_df.loc[:, 'bounding_importance'] = bounding_importance_fracs\ntrain_df.loc[:, 'dominant_blue'] = dominant_blues\ntrain_df.loc[:, 'dominant_green'] = dominant_greens\ntrain_df.loc[:, 'dominant_red'] = dominant_reds\ntrain_df.loc[:, 'dominant_pixel_frac'] = dominant_pixel_fracs\ntrain_df.loc[:, 'dominant_score'] = dominant_scores\ntrain_df.loc[:, 'label_description'] = label_descriptions\ntrain_df.loc[:, 'label_score'] = label_scores\n\n\nvertex_xs = []\nvertex_ys = []\nbounding_confidences = []\nbounding_importance_fracs = []\ndominant_blues = []\ndominant_greens = []\ndominant_reds = []\ndominant_pixel_fracs = []\ndominant_scores = []\nlabel_descriptions = []\nlabel_scores = []\nnf_count = 0\nnl_count = 0\nfor pet in test_id:\n    try:\n        with open('../input/test_metadata/' + pet + '-1.json', 'r') as f:\n            data = json.load(f)\n        vertex_x = data['cropHintsAnnotation']['cropHints'][0]['boundingPoly']['vertices'][2]['x']\n        vertex_xs.append(vertex_x)\n        vertex_y = data['cropHintsAnnotation']['cropHints'][0]['boundingPoly']['vertices'][2]['y']\n        vertex_ys.append(vertex_y)\n        bounding_confidence = data['cropHintsAnnotation']['cropHints'][0]['confidence']\n        bounding_confidences.append(bounding_confidence)\n        bounding_importance_frac = data['cropHintsAnnotation']['cropHints'][0].get('importanceFraction', -1)\n        bounding_importance_fracs.append(bounding_importance_frac)\n        dominant_blue = data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['color']['blue']\n        dominant_blues.append(dominant_blue)\n        dominant_green = data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['color']['green']\n        dominant_greens.append(dominant_green)\n        dominant_red = data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['color']['red']\n        dominant_reds.append(dominant_red)\n        dominant_pixel_frac = data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['pixelFraction']\n        dominant_pixel_fracs.append(dominant_pixel_frac)\n        dominant_score = data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['score']\n        dominant_scores.append(dominant_score)\n        if data.get('labelAnnotations'):\n            label_description = data['labelAnnotations'][0]['description']\n            label_descriptions.append(label_description)\n            label_score = data['labelAnnotations'][0]['score']\n            label_scores.append(label_score)\n        else:\n            nl_count += 1\n            label_descriptions.append('nothing')\n            label_scores.append(-1)\n    except FileNotFoundError:\n        nf_count += 1\n        vertex_xs.append(-1)\n        vertex_ys.append(-1)\n        bounding_confidences.append(-1)\n        bounding_importance_fracs.append(-1)\n        dominant_blues.append(-1)\n        dominant_greens.append(-1)\n        dominant_reds.append(-1)\n        dominant_pixel_fracs.append(-1)\n        dominant_scores.append(-1)\n        label_descriptions.append('nothing')\n        label_scores.append(-1)\n\nprint(nf_count)\ntest_df.loc[:, 'vertex_x'] = vertex_xs\ntest_df.loc[:, 'vertex_y'] = vertex_ys\ntest_df.loc[:, 'bounding_confidence'] = bounding_confidences\ntest_df.loc[:, 'bounding_importance'] = bounding_importance_fracs\ntest_df.loc[:, 'dominant_blue'] = dominant_blues\ntest_df.loc[:, 'dominant_green'] = dominant_greens\ntest_df.loc[:, 'dominant_red'] = dominant_reds\ntest_df.loc[:, 'dominant_pixel_frac'] = dominant_pixel_fracs\ntest_df.loc[:, 'dominant_score'] = dominant_scores\ntest_df.loc[:, 'label_description'] = label_descriptions\ntest_df.loc[:, 'label_score'] = label_scores","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9afd85d90d9c31b35f9dde9b7396eb50aa421c39","trusted":true},"cell_type":"code","source":"train_df_num = train_df.drop(columns = train_df.dtypes[train_df.dtypes=='object'].index)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a9eda1aef80c49d8d971499d384e12cbbc2f5ed0","trusted":true},"cell_type":"code","source":"test_df_num = test_df.drop(columns = test_df.dtypes[test_df.dtypes=='object'].index)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a4605f662910e55055e4a6de80f6546b3e6d4d85","trusted":true},"cell_type":"code","source":"train_df_num.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eab61f02149d35c934d37291c595c75442eb5cb5","scrolled":true,"trusted":true},"cell_type":"code","source":"train_df_num.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"12cdba4021099fcb58a4a13055bc93e5bb954d5c","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score, cohen_kappa_score, make_scorer\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.utils import shuffle","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ce5b92f32e6f79a967aeabcfd85f112dd05e80b7","trusted":true},"cell_type":"code","source":"x = train_df_num.drop(columns = 'AdoptionSpeed')\ny = train_df_num.AdoptionSpeed","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a9da814d63ab9ad2afd43be32ae136899b1522b8","trusted":true},"cell_type":"code","source":"x_tst = test_df_num","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"26407276ee6e689925661381d424a2b43162eba5","trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=0, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0cc77bb80c5c0ae947b3c99c9779af74d9682301","trusted":true},"cell_type":"code","source":"X_train.shape, X_test.shape, x_tst.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"28bc467a1ae9a9196daba1c19cba9a1bb108a4ab","trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier,\\\n                            ExtraTreesClassifier, AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nRANDOM_STATE = 0","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2e77aafa1c758d729dd9a6e31daf25931c5b5da4","trusted":true},"cell_type":"code","source":"# some classifiers for test\nclassifiers = [KNeighborsClassifier(n_jobs=-1),\n               \n               LogisticRegression(),\n               LogisticRegression(C=0.005, penalty='l1', class_weight=None, fit_intercept=False, max_iter=100, tol=0.01),\n               LogisticRegression(C=0.0001, penalty='l2', class_weight=None, fit_intercept=True, max_iter=150, tol=1e-06),\n               LogisticRegression(C=96, penalty='l1', class_weight='balanced', fit_intercept=True, max_iter=50, tol=0.0001),\n               LogisticRegression(C=54, penalty='l2', class_weight='balanced', fit_intercept=False, max_iter=450, tol=0.001),\n               GradientBoostingClassifier(n_estimators=50, learning_rate=0.005, max_depth=12, max_features=0.8, min_samples_leaf=2, subsample=0.2),\n               GradientBoostingClassifier(n_estimators=50, learning_rate=0.01, max_depth=5, max_features=0.6, min_samples_leaf=10, subsample=0.8),\n               GradientBoostingClassifier(n_estimators=200, learning_rate=0.001, max_depth=90, max_features=0.5, min_samples_leaf=20, subsample=0.2),\n               GradientBoostingClassifier(n_estimators=50, learning_rate=0.01, max_depth=20, max_features=0.6, min_samples_leaf=24, subsample=0.7),\n               GradientBoostingClassifier(n_estimators=300, learning_rate=0.01, max_depth=90, max_features=0.5, min_samples_leaf=20, subsample=0.2),\n               RandomForestClassifier(n_jobs=-1),\n               RandomForestClassifier(n_estimators=225, bootstrap=True, max_depth=83, max_features='auto', min_samples_leaf=5, min_samples_split=5,  n_jobs=-1),\n               RandomForestClassifier(criterion='gini', n_estimators=100, min_samples_split=12, min_samples_leaf=1, oob_score=True, n_jobs=-1),\n               ExtraTreesClassifier(n_jobs=-1),\n               ExtraTreesClassifier(n_estimators=200, bootstrap=False, max_depth=80, max_features='auto', min_samples_leaf=6, min_samples_split=5, n_jobs=-1),\n               AdaBoostClassifier(),\n               AdaBoostClassifier(n_estimators=225, algorithm='SAMME.R', learning_rate=0.2),\n               DecisionTreeClassifier(),\n               DecisionTreeClassifier(criterion='entropy', max_depth=110, max_features='auto', min_samples_leaf=6, min_samples_split=330)\n               ]\nclassifiers_names = ['knn1',\n                     'lr1', 'lr2', 'lr3', 'lr4', 'lr5',\n                     'gb1', 'gb2', 'gb3', 'gb4', 'gb5', \n                     'rf1', 'rf2', 'rf3',\n                     'et1', 'et2', \n                     'adb1', 'adb2',\n                     'dt1','dt2',\n                    ]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2a7b5d26f82906bdd0f3c4395f892c0a3de1908d","trusted":true},"cell_type":"code","source":"classifiers_predictions = pd.DataFrame()\nfor name, classifier in zip(classifiers_names, classifiers):\n    classifier.fit(X_train, y_train)\n    train_predictions = pd.Series(classifier.predict(X_train))\n    test_predictions = classifier.predict(X_test)\n    \n    classifiers_predictions[name] = test_predictions\n    print('{0}: ({1} - {2})'.format(name,\n                                    cohen_kappa_score(y_train, train_predictions, weights='quadratic') ,\n                                    cohen_kappa_score(y_test, test_predictions, weights='quadratic')))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"27b053731bbee0e393fbcfa55fd783c082a9d70a","trusted":true},"cell_type":"code","source":"classifiers_predictions = classifiers_predictions[['knn1', \n                     'lr1', 'lr2', 'lr3', 'lr4', 'lr5',\n                     'gb1', 'gb2', 'gb3', 'gb4', 'gb5', \n                     'rf1', 'rf2', 'rf3',\n                     'et1', 'et2', \n                     'adb1', 'adb2',\n                     'dt1','dt2',\n                    ]]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2a8a09cee4f883f17682a3ae4440cbe68ada4f30","trusted":true},"cell_type":"code","source":"sns.heatmap(classifiers_predictions.corr(), linewidths=.5);\nplt.yticks(rotation=0);\nplt.xticks(rotation=30);\nsns.set(font_scale=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f770adcd8ff918e42b037782ddc24e56d64b6c5f"},"cell_type":"code","source":"# some classifiers for test\nclassifiers = [\n               LogisticRegression(C=96, penalty='l1', class_weight='balanced', fit_intercept=True, max_iter=50, tol=0.0001),\n               \n               GradientBoostingClassifier(n_estimators=50, learning_rate=0.005, max_depth=12, max_features=0.8, min_samples_leaf=2, subsample=0.2),\n               GradientBoostingClassifier(n_estimators=50, learning_rate=0.01, max_depth=5, max_features=0.6, min_samples_leaf=10, subsample=0.8),\n               GradientBoostingClassifier(n_estimators=200, learning_rate=0.001, max_depth=90, max_features=0.5, min_samples_leaf=20, subsample=0.2),\n               GradientBoostingClassifier(n_estimators=50, learning_rate=0.01, max_depth=20, max_features=0.6, min_samples_leaf=24, subsample=0.7),\n               RandomForestClassifier(n_estimators=225, bootstrap=True, max_depth=83, max_features='auto', min_samples_leaf=5, min_samples_split=5,  n_jobs=-1),\n               RandomForestClassifier(criterion='gini', n_estimators=100, min_samples_split=12, min_samples_leaf=1, oob_score=True, n_jobs=-1),\n               ExtraTreesClassifier(n_estimators=200, bootstrap=False, max_depth=80, max_features='auto', min_samples_leaf=6, min_samples_split=5, n_jobs=-1),\n               AdaBoostClassifier(),\n               AdaBoostClassifier(n_estimators=225, algorithm='SAMME.R', learning_rate=0.2),\n               DecisionTreeClassifier(criterion='entropy', max_depth=110, max_features='auto', min_samples_leaf=6, min_samples_split=330)\n               ]\nclassifiers_names = ['lr4', \n                     'gb1','gb2', 'gb3', 'gb4', \n                     'rf2', 'rf3',\n                     'et2',  \n                     'adb1','adb2',\n                     'dt2',\n                    ]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8b37fc4d74935303caef500114b67a73b6e356c1","trusted":true},"cell_type":"code","source":"def simple_blending(basic_algorithms, meta_algorithm, X_train, X_test, y_train, test_df, part1_ratio=0.9, random_state=None):\n    tr = pd.DataFrame()\n    tst = pd.DataFrame()\n    y = pd.DataFrame()\n    X_train_part1, X_train_part2,\\\n    y_train_part1, y_train_part2 = train_test_split(X_train, y_train, test_size=1-part1_ratio, random_state=random_state)\n    \n    for index, basic_algorithm in enumerate(basic_algorithms):\n        #print(index)\n        basic_algorithm.fit(X_train_part1, y_train_part1)\n\n        part2_predictions = basic_algorithm.predict(X_train_part2)\n        tr[index] = part2_predictions\n\n        test_predictions = basic_algorithm.predict(X_test)\n        tst[index] = test_predictions\n        \n        test_pred = basic_algorithm.predict(test_df)\n        y[index] = test_pred\n        \n    meta_algorithm.fit(tr, y_train_part2)\n    \n    return meta_algorithm.predict(tst), meta_algorithm.predict(y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"79815765db33d2fb8d7c30f104b58aaf7bb2d10f","trusted":true},"cell_type":"code","source":"r = pd.DataFrame()\nexperiments = list()\nfor i in range(1, 10):\n    simple_blending_predictions, result = simple_blending(classifiers,\n                                              LogisticRegression(C=5, random_state=RANDOM_STATE),\n                                              X_train, X_test, y_train, x_tst,\n                                              part1_ratio=0.9,\n                                              random_state=i)\n    r[i] = result\n    #print(simple_blending_predictions)\n    print(cohen_kappa_score(y_test, simple_blending_predictions, weights='quadratic'))\n    experiments.append(cohen_kappa_score( y_test, simple_blending_predictions, weights='quadratic'))\nprint('mean kappa: {0}\\nstd: {1}'.format(round(np.mean(experiments), 4), round(np.std(experiments), 5)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"69bc25fbc591f76445f2ec86133a6a20921f852c","trusted":true},"cell_type":"code","source":"r['avg'] = r.mean(axis=1).round(0).astype(int)\nr.avg.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a57b33c78a07d8ce782aaedf535eb3a8e79763d0","trusted":true},"cell_type":"code","source":"def simple_blending_features(basic_algorithms, meta_algorithm, X_train, X_test, y_train, test_df, part1_ratio=0.5, random_state=None):\n    tr = pd.DataFrame()\n    tst = pd.DataFrame()\n    y = pd.DataFrame()\n    \n    X_train_part1, X_train_part2,\\\n    y_train_part1, y_train_part2 = train_test_split(X_train, y_train, test_size=1-part1_ratio, random_state=random_state)\n    \n    tr = tr.append(X_train_part2)\n    tst = tst.append(X_test)\n    y = y.append(test_df)\n    \n    for index, basic_algorithm in enumerate(basic_algorithms):\n        #print(index)\n        basic_algorithm.fit(X_train_part1, y_train_part1)\n\n        part2_predictions = basic_algorithm.predict(X_train_part2)\n        tr[index] = part2_predictions\n\n        test_predictions = basic_algorithm.predict(X_test)\n        tst[index] = test_predictions\n        \n        test_pred = basic_algorithm.predict(test_df)\n        y[index] = test_pred\n    \n    meta_algorithm.fit(tr, y_train_part2)\n\n    return meta_algorithm.predict(tst), meta_algorithm.predict(y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"af91939b6dbca1648c6617cbd1a965c37020aec0","scrolled":true,"trusted":true},"cell_type":"code","source":"r2 = pd.DataFrame()\nexperiments = list()\nfor i in range(1, 10):\n    simple_blending_features_predictions, result2 = simple_blending_features(classifiers,\n                                              LogisticRegression(C=5, random_state=RANDOM_STATE),\n                                              X_train, X_test, y_train, x_tst,\n                                              part1_ratio=0.9,\n                                              random_state=i)\n    r2[i] = result2\n    #print(simple_blending_predictions)\n    print(cohen_kappa_score(y_test, simple_blending_features_predictions, weights='quadratic'))\n    experiments.append(cohen_kappa_score( y_test, simple_blending_features_predictions, weights='quadratic'))\nprint('mean kappa: {0}\\nstd: {1}'.format(round(np.mean(experiments), 4), round(np.std(experiments), 5)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c13814a002425b8d840bb5ba1b21fa2d9c264f1d","trusted":true},"cell_type":"code","source":"r2['avg'] = r2.mean(axis=1).round(0).astype(int)\nr2.avg.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"76c54ef45842391c73512eee68192df75f437130","trusted":true},"cell_type":"code","source":"from pandas.util.testing import assert_series_equal\nassert_series_equal(r['avg'], r2['avg'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4782d24f7ac0cdb50a7ce1a2cd50b913d13b505b","trusted":true},"cell_type":"code","source":"submission = pd.DataFrame(data={'PetID' : test_df['PetID'], 'AdoptionSpeed' : r['avg']})\nsubmission.to_csv('submission.csv', index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1941d7ca6d28dfe1f1b747b6a1911be19cfca34e","trusted":true},"cell_type":"code","source":"# check submission\nsubmission.head(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"27530b657badb0479a46f232ea01070a9c27e0b5","trusted":true},"cell_type":"code","source":"# Plot 1\nplt.figure(figsize=(15,4))\nplt.subplot(211)\ntrain_df['AdoptionSpeed'].value_counts().sort_index(ascending=False).plot(kind='barh')\nplt.title('Target Variable distribution in training set')\n\n# Plot 2\nplt.subplot(212)\nsubmission['AdoptionSpeed'].value_counts().sort_index(ascending=False).plot(kind='barh')\nplt.title('Target Variable distribution in predictions')\n\nplt.subplots_adjust(top=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"281495e9f021b74925755e34a34efa181fb2c789"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}