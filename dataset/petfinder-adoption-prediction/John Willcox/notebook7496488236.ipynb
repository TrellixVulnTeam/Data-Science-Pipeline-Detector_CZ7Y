{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This Kaggle notebook is meant to be viewed in conjunction with my article *Categorical embeddings with CatBoost*, which you can find on Towards Data Science. The point of the notebook was not to maximize the competition score, but rather to provide a simple example showing that the use of categorical embeddings can sometimes enhance results.\n\nAs the article mentions, the OptimizedRounder class and associated methods were used in many of the public notebooks for this competition. The version I used came from this notebook (https://www.kaggle.com/code/adityaecdrid/8th-place-solution-code/script?scriptVersionId=12171797).","metadata":{}},{"cell_type":"code","source":"import catboost as cb\nfrom fastai.tabular.all import *\nimport numpy as np\nimport os\nimport pandas as pd\nimport scipy as sp\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom typing import Dict, Tuple","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-13T16:40:56.144729Z","iopub.execute_input":"2022-04-13T16:40:56.145009Z","iopub.status.idle":"2022-04-13T16:40:56.150656Z","shell.execute_reply.started":"2022-04-13T16:40:56.144976Z","shell.execute_reply":"2022-04-13T16:40:56.149629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# switch to indicate whether or not to feed the original categorical values into the CatBoost regressor\nuse_categorical = True\n# switch to indicate whether or not to feed categorical embeddings into the CatBoost regressor\nuse_embedded = False","metadata":{"execution":{"iopub.status.busy":"2022-04-13T16:40:56.171717Z","iopub.execute_input":"2022-04-13T16:40:56.172387Z","iopub.status.idle":"2022-04-13T16:40:56.176015Z","shell.execute_reply.started":"2022-04-13T16:40:56.172344Z","shell.execute_reply":"2022-04-13T16:40:56.17515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_folder = '../input/petfinder-adoption-prediction'\ndf_train = pd.read_csv(f'{input_folder}/train/train.csv')\ndf_test = pd.read_csv(f'{input_folder}/test/test.csv')\ndf_sample_submission = pd.read_csv(f'{input_folder}/test/sample_submission.csv')\ndf_sample_submission.drop('AdoptionSpeed', axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T16:40:56.196421Z","iopub.execute_input":"2022-04-13T16:40:56.197084Z","iopub.status.idle":"2022-04-13T16:40:56.524057Z","shell.execute_reply.started":"2022-04-13T16:40:56.197038Z","shell.execute_reply":"2022-04-13T16:40:56.522969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_mixed_breed(breed1: int, breed2: int) -> int:    \n    \"\"\"\n    Returns value to indicate mixed_breed status\n    \n        0 - breed is not mixed\n        1 - animal is of mixed breed with both breeds specified\n        2 - animal is of mixed breed with only one breed specified\n        3 - animal is of mixed breed with no breed specified\n    \"\"\"\n    \n    if breed1 != 307 and breed2 != 307 and breed1 != 0 and breed2 != 0 and breed1 != breed2:\n        return 1\n    elif (breed1 != 307 and breed1 != 0 and breed2 == 307) or (breed2 != 307 and breed2 != 0 and breed1 == 307):\n        return 2\n    elif (breed1 == 307 and breed2 == 307) or (breed1 == 307 and breed2 == 0):\n        return 3\n    \n    return 0\n\ndf_train['mixed_breed'] = df_train.apply(lambda row: get_mixed_breed(row.Breed1, row.Breed2), axis=1)\ndf_test['mixed_breed'] = df_test.apply(lambda row: get_mixed_breed(row.Breed1, row.Breed2), axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T16:40:56.525849Z","iopub.execute_input":"2022-04-13T16:40:56.526137Z","iopub.status.idle":"2022-04-13T16:40:56.93043Z","shell.execute_reply.started":"2022-04-13T16:40:56.526105Z","shell.execute_reply":"2022-04-13T16:40:56.92974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_sentiment(filename: str) -> pd.Series:    \n    \"\"\"\n    Retrieves document sentiment and language attributes from given file\n    \n    The files contain the results of sentiment analysis from Google's Natural Language API\n    They were provided with the dataset\n    The method returns a pandas dataframe containing sentiment magnitude, sentiment score and language\n    If the file is not found the method returns an empty pandas dataframe\n    \"\"\"\n    try:\n        with open(filename) as file:\n            data = json.load(file)\n        return pd.Series((data['documentSentiment']['magnitude'], data['documentSentiment']['score'], data['language']))\n    except FileNotFoundError:\n        return pd.Series((np.nan, np.nan))\n    \ndf_train[['description_sentiment_magnitude', 'description_sentiment_score', 'description_language']] = df_train.PetID.apply(lambda pet_id: get_sentiment(f'{input_folder}/train_sentiment/{pet_id}.json'))\ndf_test[['description_sentiment_magnitude', 'description_sentiment_score', 'description_language']] = df_test.PetID.apply(lambda pet_id: get_sentiment(f'{input_folder}/test_sentiment/{pet_id}.json'))\ndf_train['description_length'] = df_train.Description.str.count(' ')\ndf_test['description_length'] = df_test.Description.str.count(' ')","metadata":{"execution":{"iopub.status.busy":"2022-04-13T16:40:56.931687Z","iopub.execute_input":"2022-04-13T16:40:56.932459Z","iopub.status.idle":"2022-04-13T16:40:59.032735Z","shell.execute_reply.started":"2022-04-13T16:40:56.932415Z","shell.execute_reply":"2022-04-13T16:40:59.030954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.loc[df_train.PetID=='e3b589e13', 'Age']=2\ndf_train.loc[df_train.PetID=='e77f9e778', 'Age']=3\ndf_train.loc[df_train.PetID=='53923463d', 'Age']=3","metadata":{"execution":{"iopub.status.busy":"2022-04-13T16:40:59.033839Z","iopub.status.idle":"2022-04-13T16:40:59.034851Z","shell.execute_reply.started":"2022-04-13T16:40:59.034595Z","shell.execute_reply":"2022-04-13T16:40:59.034627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reproducible_results = True\nrandom_state = 42 if reproducible_results else None\ndependent_var = 'AdoptionSpeed'\ncategorical = ['Breed1', 'Breed2', 'Gender', 'Color1', 'Color2', 'Color3', 'State', 'Vaccinated', 'Dewormed', 'Sterilized', 'mixed_breed', 'Type', 'MaturitySize', 'FurLength', 'Health', 'description_language']\ncontinuous = ['Age', 'Quantity', 'Fee', 'VideoAmt', 'PhotoAmt', 'description_length', 'description_sentiment_score', 'description_sentiment_magnitude']\ndf_train[categorical] = df_train[categorical].astype('str')\ndf_test[categorical] = df_test[categorical].astype('str')","metadata":{"execution":{"iopub.status.busy":"2022-04-13T16:40:59.03605Z","iopub.status.idle":"2022-04-13T16:40:59.036559Z","shell.execute_reply.started":"2022-04-13T16:40:59.036271Z","shell.execute_reply":"2022-04-13T16:40:59.036295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed): \n    \"\"\"\n    Set all seeds required to ensure models return reproducible results\n    \"\"\"\n    \n    random.seed(seed) \n    os.environ['PYTHONHASHSEED'] = str(seed) \n    np.random.seed(seed) \n    torch.manual_seed(seed) \n    torch.cuda.manual_seed_all(seed) \n    torch.cuda.manual_seed(seed) \n    torch.backends.cudnn.deterministic = True\n    \nif reproducible_results:\n    seed_everything(random_state)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T16:40:59.038596Z","iopub.status.idle":"2022-04-13T16:40:59.039345Z","shell.execute_reply.started":"2022-04-13T16:40:59.039036Z","shell.execute_reply":"2022-04-13T16:40:59.039072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_xs, valid_xs, _, _ = train_test_split(df_train, df_train[dependent_var], test_size=0.2, shuffle=True, stratify=df_train[dependent_var], random_state=random_state)\nsplits = (train_xs.index.tolist(), valid_xs.index.tolist())","metadata":{"execution":{"iopub.status.busy":"2022-04-13T16:40:59.041091Z","iopub.status.idle":"2022-04-13T16:40:59.041548Z","shell.execute_reply.started":"2022-04-13T16:40:59.041301Z","shell.execute_reply":"2022-04-13T16:40:59.041327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"procs = [Categorify, FillMissing, Normalize]\ntabdata = TabularPandas(df=df_train, procs=procs, cat_names=categorical.copy(), cont_names=continuous.copy(), splits=splits, y_names=dependent_var, y_block=CategoryBlock())","metadata":{"execution":{"iopub.status.busy":"2022-04-13T16:40:59.042973Z","iopub.status.idle":"2022-04-13T16:40:59.043413Z","shell.execute_reply.started":"2022-04-13T16:40:59.043172Z","shell.execute_reply":"2022-04-13T16:40:59.043197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_sizes = get_emb_sz(tabdata)\nembedding_sizes","metadata":{"execution":{"iopub.status.busy":"2022-04-13T16:40:59.045056Z","iopub.status.idle":"2022-04-13T16:40:59.045412Z","shell.execute_reply.started":"2022-04-13T16:40:59.045222Z","shell.execute_reply":"2022-04-13T16:40:59.045256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['Breed1'].nunique()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T16:40:59.046522Z","iopub.status.idle":"2022-04-13T16:40:59.046818Z","shell.execute_reply.started":"2022-04-13T16:40:59.046666Z","shell.execute_reply":"2022-04-13T16:40:59.046682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emb_sz_rule??","metadata":{"execution":{"iopub.status.busy":"2022-04-13T16:40:59.048507Z","iopub.status.idle":"2022-04-13T16:40:59.049144Z","shell.execute_reply.started":"2022-04-13T16:40:59.04893Z","shell.execute_reply":"2022-04-13T16:40:59.048958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"[col for col in tabdata.cat_names]","metadata":{"execution":{"iopub.status.busy":"2022-04-13T16:40:59.050551Z","iopub.status.idle":"2022-04-13T16:40:59.051288Z","shell.execute_reply.started":"2022-04-13T16:40:59.050987Z","shell.execute_reply":"2022-04-13T16:40:59.05102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_default_nn_layers(num_embeddings: int, num_continuous: int, num_outputs: int, num_layers: int=2) -> List[int]:\n    \"\"\"\n    Return suggested starting point for number of neurons\n    \n    Note, this is a rule of thumb for a starting point only, as suggested by Jeremy Howard from fast.ai\n    \"\"\"\n    \n    num_input_nodes = num_embeddings + num_continuous  \n    first_layer = 2**(num_layers-1) * round((((2 / 3) * num_input_nodes) + num_outputs) / 2**(num_layers-1))\n    \n    return [first_layer] + [int(first_layer / 2**n) for n in range(1, num_layers)]\n\nnum_embeddings = sum(n for _, n in get_emb_sz(tabdata))\nnum_classes = df_train[dependent_var].nunique()\nlayers = get_default_nn_layers(num_embeddings, num_continuous=len(continuous), num_outputs=num_classes)\nbatchsize = 16\ntrain_dl = TabDataLoader(tabdata.train, bs=batchsize, shuffle=True, drop_last=False)\nvalid_dl = TabDataLoader(tabdata.valid, bs=batchsize, shuffle=False, drop_last=False)\ndls = DataLoaders(train_dl, valid_dl)\nconfig = tabular_config(ps=[0.001, 0.01], embed_p=0.04)\nnn_model = tabular_learner(dls=dls, layers=layers, config=config, loss_func=CrossEntropyLossFlat(), metrics=accuracy, n_out=num_classes)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T16:40:59.052448Z","iopub.status.idle":"2022-04-13T16:40:59.052967Z","shell.execute_reply.started":"2022-04-13T16:40:59.052699Z","shell.execute_reply":"2022-04-13T16:40:59.052726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nn_model.model","metadata":{"execution":{"iopub.status.busy":"2022-04-13T16:40:59.054335Z","iopub.status.idle":"2022-04-13T16:40:59.054852Z","shell.execute_reply.started":"2022-04-13T16:40:59.054553Z","shell.execute_reply":"2022-04-13T16:40:59.054579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valley = nn_model.lr_find()\nplt.show()\nnn_model.fit_one_cycle(n_epoch=5, lr_max=valley, wd=0.01)\nnn_model.recorder.plot_loss()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T16:40:59.05678Z","iopub.status.idle":"2022-04-13T16:40:59.05773Z","shell.execute_reply.started":"2022-04-13T16:40:59.057441Z","shell.execute_reply":"2022-04-13T16:40:59.057472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def embed_features(learner: tabular_learner, xs: TabularPandas) -> pd.DataFrame:\n    \"\"\"\n    Generates fast.ai categorical embeddings\n    \n    Tabular learner should be fitted before passing\n    Pandas dataframe is returned with only the embeddings columns; the original, non-embedded columns are dropped\n    \"\"\"\n    \n    xs = xs[learner.dls.cat_names]\n    for i, col in enumerate(xs.columns):\n        embeddings = learner.model.embeds[i]\n        embedding_data = embeddings(tensor(xs[col], dtype=torch.int64))\n        embedding_names = [f'{col}_{j}' for j in range(embedding_data.shape[1])]\n        \n        df_local = pd.DataFrame(data=embedding_data, index=xs.index, columns=embedding_names)\n        xs = xs.drop(col, axis=1)\n        xs = xs.join(df_local)\n    \n    return xs\n\ndf_train_embeddings = embed_features(learner=nn_model, xs=tabdata.train.xs)\ndf_valid_embeddings = embed_features(learner=nn_model, xs=tabdata.valid.xs)\nembedded = df_train_embeddings.columns.tolist() \ndf_train_combined = df_train_embeddings.merge(right=df_train, left_index=True, right_index=True)\ndf_valid_combined = df_valid_embeddings.merge(right=df_train, left_index=True, right_index=True)\n\nstate_embeddings = [x for x in df_train_combined.columns if x.startswith('State_')]\ndf_train_combined[['State']+state_embeddings].head(10)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T16:40:59.05902Z","iopub.status.idle":"2022-04-13T16:40:59.059472Z","shell.execute_reply.started":"2022-04-13T16:40:59.059223Z","shell.execute_reply":"2022-04-13T16:40:59.05925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tabdata_test = tabdata.new(df_test)\ntabdata_test.process()\ndf_test_embeddings = embed_features(learner=nn_model, xs=tabdata_test)\ndf_test_combined = df_test_embeddings.merge(right=df_test, left_index=True, right_index=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T16:40:59.061423Z","iopub.status.idle":"2022-04-13T16:40:59.062168Z","shell.execute_reply.started":"2022-04-13T16:40:59.06193Z","shell.execute_reply":"2022-04-13T16:40:59.061954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['AdoptionSpeed'].value_counts(ascending=True).plot(kind='bar')","metadata":{"execution":{"iopub.status.busy":"2022-04-13T16:40:59.063559Z","iopub.status.idle":"2022-04-13T16:40:59.064535Z","shell.execute_reply.started":"2022-04-13T16:40:59.064267Z","shell.execute_reply":"2022-04-13T16:40:59.064297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_catboost_regressor(iterations: int=1000, loss_function: str='RMSE', eval_metric: str='RMSE', ignored_features: List[str]=['PetID'], depth: int=6) -> cb.CatBoostRegressor:\n    \"\"\"\n    Get simple CatBoost regressor\n    \"\"\"\n    \n    return cb.CatBoostRegressor(iterations=iterations, loss_function=loss_function, eval_metric=eval_metric, ignored_features=ignored_features, depth=depth, random_seed=random_state)    \n\ndef get_catboost_pool(df: pd.DataFrame, use_categorical: bool, use_embedded: bool, has_label: bool=True) -> cb.Pool:\n    \"\"\"\n    Get CatBoost data pool\n    \n        use_categorical - switch to indicate whether we should use original, discrete categorical values\n        use_embedded - switch to indicate whether we should use continuous categorical embedding values\n        has_label - pass True for training and validation pools and False for test pool\n    \"\"\"\n        \n    columns = continuous + (categorical if use_categorical else []) + (embedded if use_embedded else []) + ['PetID']\n    cat_features = ['PetID'] + (categorical if use_categorical else [])    \n    label = df[dependent_var] if has_label else None\n    \n    return cb.Pool(data=df[columns], label=label, cat_features=cat_features)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T16:40:59.066081Z","iopub.status.idle":"2022-04-13T16:40:59.066524Z","shell.execute_reply.started":"2022-04-13T16:40:59.066284Z","shell.execute_reply":"2022-04-13T16:40:59.066308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Note that all code in this cell came from this notebook - \n# https://www.kaggle.com/code/adityaecdrid/8th-place-solution-code/script?scriptVersionId=12171797\ndef histogram(ratings, min_rating=None, max_rating=None):\n    \"\"\"\n    Returns the counts of each type of rating that a rater made\n    \"\"\"\n    if min_rating is None:\n        min_rating = min(ratings)\n    if max_rating is None:\n        max_rating = max(ratings)\n    num_ratings = int(max_rating - min_rating + 1)\n    hist_ratings = [0 for x in range(num_ratings)]\n    for r in ratings:\n        hist_ratings[r - min_rating] += 1\n    return hist_ratings\n\ndef rater_confusion_matrix(rater_a, rater_b, min_rating=None, max_rating=None):\n    \"\"\"\n    Returns the confusion matrix between rater's ratings\n    \"\"\"\n    assert (len(rater_a) == len(rater_b))\n    if min_rating is None:\n        min_rating = min(rater_a + rater_b)\n    if max_rating is None:\n        max_rating = max(rater_a + rater_b)\n    num_ratings = int(max_rating - min_rating + 1)\n    conf_mat = [[0 for i in range(num_ratings)]\n                for j in range(num_ratings)]\n    for a, b in zip(rater_a, rater_b):\n        conf_mat[a - min_rating][b - min_rating] += 1\n    return conf_mat\n\ndef quadratic_weighted_kappa(y, y_pred):\n    rater_a = y\n    rater_b = y_pred\n    min_rating = None\n    max_rating = None\n    rater_a = np.array(rater_a, dtype=int)\n    rater_b = np.array(rater_b, dtype=int)\n    assert (len(rater_a) == len(rater_b))\n    if min_rating is None:\n        min_rating = min(min(rater_a), min(rater_b))\n    if max_rating is None:\n        max_rating = max(max(rater_a), max(rater_b))\n    conf_mat = rater_confusion_matrix(rater_a, rater_b,\n                                min_rating, max_rating)\n    num_ratings = len(conf_mat)\n    num_scored_items = float(len(rater_a))\n\n    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n\n    numerator = 0.0\n    denominator = 0.0\n\n    for i in range(num_ratings):\n        for j in range(num_ratings):\n            expected_count = (hist_rater_a[i] * hist_rater_b[j]\n                              / num_scored_items)\n            d = pow(i - j, 2.0) / pow(num_ratings - 1, 2.0)\n            numerator += d * conf_mat[i][j] / num_scored_items\n            denominator += d * expected_count / num_scored_items\n\n    return (1.0 - numerator / denominator)\n\nclass OptimizedRounder(object):\n    def __init__(self):\n        self.coef_ = 0\n\n    def _kappa_loss(self, coef, X, y):\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            elif pred >= coef[2] and pred < coef[3]:\n                X_p[i] = 3\n            else:\n                X_p[i] = 4\n\n        ll = quadratic_weighted_kappa(y, X_p)\n        return -ll\n\n    def fit(self, X, y):\n        loss_partial = partial(self._kappa_loss, X=X, y=y)\n        initial_coef = [0.5, 1.5, 2.5, 3.5]\n        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n\n    def predict(self, X, coef):\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            elif pred >= coef[2] and pred < coef[3]:\n                X_p[i] = 3\n            else:\n                X_p[i] = 4\n        return [int(n) for n in X_p]\n\n    def coefficients(self):\n        return self.coef_['x']","metadata":{"execution":{"iopub.status.busy":"2022-04-13T16:40:59.068068Z","iopub.status.idle":"2022-04-13T16:40:59.068517Z","shell.execute_reply.started":"2022-04-13T16:40:59.068273Z","shell.execute_reply":"2022-04-13T16:40:59.068299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_pool = get_catboost_pool(df=df_train_combined, use_categorical=use_categorical, use_embedded=use_embedded)\nvalid_pool = get_catboost_pool(df=df_valid_combined, use_categorical=use_categorical, use_embedded=use_embedded)\ntest_pool = get_catboost_pool(df=df_test_combined, use_categorical=use_categorical, use_embedded=use_embedded, has_label=False)\n\nmodel = get_catboost_regressor(iterations=10000)\n\nmodel.fit(X=train_pool, eval_set=valid_pool, verbose=1000)\n\npredictions = model.predict(train_pool)\n\noptR = OptimizedRounder()\noptR.fit(predictions, df_train_combined[dependent_var].values)\ncoefficients = optR.coefficients()\n\ntest_predictions = model.predict(test_pool)\ntest_predictions = optR.predict(test_predictions, coefficients)\ndf_predictions = pd.concat([df_test[['PetID']], pd.DataFrame(test_predictions, columns=[dependent_var])], axis=1)\ndf_submission = pd.merge(df_sample_submission, df_predictions, on='PetID')\ndf_submission.to_csv('submission.csv', index=False) ","metadata":{"execution":{"iopub.status.busy":"2022-04-13T16:40:59.069964Z","iopub.status.idle":"2022-04-13T16:40:59.070415Z","shell.execute_reply.started":"2022-04-13T16:40:59.070174Z","shell.execute_reply":"2022-04-13T16:40:59.070199Z"},"trusted":true},"execution_count":null,"outputs":[]}]}