{"cells":[{"metadata":{"_uuid":"1cecdf04e5db1eff8072a48e7bdb28852496a543"},"cell_type":"markdown","source":"# Multifit\n\nThis is an example of a proof of concept of building a single neural network on both image and tabular data.\n\nIt doesn't do any better than a linear model with embeddings - but I haven't experimented much with architecture/hyperparameters/etc."},{"metadata":{"_uuid":"9f47db120594efc7796e9b5799b56d096748f11e"},"cell_type":"markdown","source":"## Read in the data"},{"metadata":{"trusted":true,"_uuid":"9bc391dd46e32bd0e7e5506725eda58a9f512b87"},"cell_type":"code","source":"from fastai import *\nfrom fastai.vision import *\nfrom fastai.tabular import *\nfrom fastai.callbacks import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"235c73b5300f1658aa4b6c68bbe0d17ce9ea10ab","scrolled":true},"cell_type":"code","source":"import fastai\nfastai.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fc6a621db8edcfc62bbdc66a5ce002bfd0f02ae4"},"cell_type":"code","source":"kappa = KappaScore()\nkappa.weights = \"quadratic\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"666625624a0bf5761dd5742e587e965f32b7a232"},"cell_type":"code","source":"from sklearn.metrics import cohen_kappa_score\nqwk = partial(cohen_kappa_score, weights=\"quadratic\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c7d56bc4abfac64a8baf46d8116d0e8ef44b499f"},"cell_type":"code","source":"path = Path('../input/petfinder-adoption-prediction')\nwork_path = Path('../working')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e4e0460533773175de41e3bad39e41cb634a9b25"},"cell_type":"code","source":"train_df = pd.read_csv(path / 'train/train.csv')\ntest_df = pd.read_csv(path / 'test/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"818bd7da3f8cab27feffe46fbfa1c1e30a122c8b","scrolled":true},"cell_type":"code","source":"train_df['valid'] = (train_df.RescuerID > 'd')\ntrain_df.valid.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b3a2211f22b67b824f1904cb775055ee9dde8ee9"},"cell_type":"code","source":"train_df['photo'] = train_df.PetID.apply(lambda x: f'train_images/{x}-1.jpg')\ntrain_df['has_photo'] = train_df.photo.apply(lambda x: (path / x).exists())\ntest_df['photo'] = test_df.PetID.apply(lambda x: f'test_images/{x}-1.jpg')\ntest_df['has_photo'] = test_df.photo.apply(lambda x: (path / x).exists())\n(~train_df['has_photo']).sum(), len(train_df)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2c9affb9d8d44383348df2148df8289c55dadea0"},"cell_type":"markdown","source":"## Tabular Model"},{"metadata":{"_uuid":"cdc05f43ec6d95a093ed7088497430a2622a5119"},"cell_type":"markdown","source":"This is the first bucketing I tried; there are probably better options but this worked better for me than feeding these variables a continuous variables into a 2-layer neural net"},{"metadata":{"trusted":true,"_uuid":"eca82f0e87cd0b28f7ed3279c4bb9251d4dcfbaa"},"cell_type":"code","source":"train_df['age'] = train_df.Age.apply(lambda x: f'{x} mth' if x < 12 else f'{min(x//12, 6)} yrs')\ntrain_df['quantity'] = train_df.Quantity.apply(lambda x: min(x, 5))\ntrain_df['fee'] = np.log1p(train_df['Fee'])\n\ntest_df['age'] = test_df.Age.apply(lambda x: f'{x} mth' if x < 12 else f'{min(x//12, 6)} yrs')\ntest_df['quantity'] = test_df.Quantity.apply(lambda x: min(x, 5))\ntest_df['fee'] = np.log1p(test_df['Fee'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f32f3b8e8d5e417396385806e856dae1854c95dc"},"cell_type":"code","source":"cat_cols = ['age',\n                      'Breed1',\n                      'Gender',\n                      'Color1',\n                      'MaturitySize', 'FurLength',\n                      'Vaccinated', 'Dewormed', 'Sterilized', 'Health',\n                      'quantity', 'State', 'PhotoAmt']\ncont_cols = ['fee']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9a14d179d1e1f1e37f3d90e64f59587630eec7b6"},"cell_type":"code","source":"procs = [FillMissing, Categorify, Normalize]\ndata_tab = (TabularList\n        .from_df(train_df, cat_names=cat_cols, cont_names=cont_cols, procs=procs)\n        .split_from_df(col='valid')\n        .label_from_df(cols=['AdoptionSpeed'])\n        .add_test(TabularList.from_df(test_df, cat_names=cat_cols, cont_names=cont_cols, procs=procs))\n        .databunch(bs=32))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"72c298d1e74e2d72e5d229a57d31408f2c141631"},"cell_type":"markdown","source":"Non-linear model seems to do no better then a linear model (with embeddings)"},{"metadata":{"trusted":true,"_uuid":"1e45496c1a1af1570d4c6645ae1142d63d606bd4"},"cell_type":"code","source":"tab_learn = tabular_learner(data_tab, layers=[], metrics=[kappa, accuracy])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"232c4d53211499d95fa72ed7811b34cebbb0e864"},"cell_type":"code","source":"tab_learn.fit_one_cycle(4, max_lr=1e-2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"0926717959c6938be5149aa22864f119379e389e"},"cell_type":"code","source":"tab_pred, _ = tab_learn.get_preds(DatasetType.Test)\ntab_valid, tab_targ = tab_learn.get_preds(DatasetType.Valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d45d6c233e56f4758a57506a1cf14abeb4c3aa00","scrolled":true},"cell_type":"code","source":"qwk(train_df[train_df.valid].AdoptionSpeed, tab_valid.argmax(1))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4f81cb5d05ac3adfc46dda678c51012fedc9eb85"},"cell_type":"markdown","source":"## Image Model"},{"metadata":{"trusted":true,"_uuid":"a580b0c728af1d3dc1ab2cc31689d65eb5ebc99e"},"cell_type":"code","source":"if not Path('../working/train_images').exists():\n    os.symlink(path /'train_images', '../working/train_images', target_is_directory=True)\nif not Path('../working/test_images').exists():\n    os.symlink(path / 'test_images', '../working/test_images', target_is_directory=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"33123c772e0189d4f833c63f0c90603af65d04d7"},"cell_type":"code","source":"transforms = get_transforms()\ndata_vis = (ImageList\n        .from_df(train_df[train_df.has_photo].copy(), work_path, cols=['photo'])\n        .split_from_df('valid')\n        .label_from_df(cols=['AdoptionSpeed'])\n        .transform(transforms, size=224)\n        .add_test(ImageList.from_df(test_df[test_df.has_photo].copy(), path, cols=['photo']))\n        # Pytorch error with too many workers\n        .databunch(bs=32, num_workers=0)\n        .normalize(imagenet_stats)\n       )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"723690b8f7716655d04c6dd8cb8129e37f0a0cac"},"cell_type":"code","source":"Path('/tmp/.torch/models/').mkdir(parents=True, exist_ok = True)\nshutil.copy('../input/resnet34/resnet34.pth', '/tmp/.torch/models/resnet34-333f7ec4.pth')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0c7ca1d51c4c444bfabf0efb12cd0256e8cdfcbf"},"cell_type":"code","source":"vis_learn = cnn_learner(data_vis, models.resnet34, pretrained=True, metrics=[kappa, accuracy])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"846ee9619e5a65856b789aad75529a9390d70041"},"cell_type":"code","source":"vis_learn.fit_one_cycle(2, max_lr=3e-3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fa4bd414817c6d17f8026620908f2ef2154925b1","scrolled":true},"cell_type":"code","source":"vis_learn.unfreeze()\nvis_learn.fit_one_cycle(3, max_lr=slice(3e-6, 3e-4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"ef4afeaef00ee6401c9e66163b43bd4dab3b2d4b"},"cell_type":"code","source":"vis_learn.save('vis')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a746d710b715282f10eca276019d8c4a283bb63c"},"cell_type":"code","source":"vis_pred, _ = vis_learn.get_preds(DatasetType.Test)\nvis_valid, targ = vis_learn.get_preds(DatasetType.Valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a26a7e5f2a55b3ac40eff314db2d4ffe896e5a36"},"cell_type":"code","source":"valid_mask = train_df.valid & train_df.has_photo","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"97ac4caa1223dda8cc474028b8efb6b41b6755b6","scrolled":true},"cell_type":"code","source":"qwk(train_df.AdoptionSpeed[train_df.valid & train_df.has_photo], vis_valid.argmax(1))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e938866658a6acde93d9bae6bc2e4dfc8aea0dce"},"cell_type":"markdown","source":"## Combinind Predictions"},{"metadata":{"trusted":true,"_uuid":"61ab45deb53294dbe380590f01c2b709ca133a13"},"cell_type":"code","source":"vis_mask = train_df[train_df.valid].has_photo\nvis_idx = list(np.where(vis_mask))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6247bd73aa45df47398297956a5503c12ccf4a98"},"cell_type":"code","source":"qwk(train_df.AdoptionSpeed[train_df.valid & train_df.has_photo], (vis_valid+tab_valid[vis_idx]).argmax(1))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"725bf82b929b0aa09f6a7793df5ae544f393ed3c"},"cell_type":"markdown","source":"## Combined Model"},{"metadata":{"trusted":true,"_uuid":"9c09e4e54667e2953f1539362f5f3c5df11a8bc0"},"cell_type":"code","source":"tfms = get_transforms()\ntfms = [[tfms[0], []], [tfms[0], []]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cd58df411f242a2a7e9c70bd1218c36be25410c7"},"cell_type":"code","source":"procs = [FillMissing, Categorify, Normalize]\nlist_tab = (TabularList\n            .from_df(train_df[train_df.has_photo],\n             cat_names=cat_cols,\n             cont_names=cont_cols,\n             procs=procs))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"43ffca7f67b9f5ff3537d048156841e003c39026"},"cell_type":"code","source":"list_vis = (ImageList\n            .from_df(train_df[train_df.has_photo], path, cols=['photo']))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5a524249c32ad021382929209f4aaef7f2dc4d34"},"cell_type":"markdown","source":" ## Todo: Normalize Images with imagenet stats"},{"metadata":{"trusted":true,"_uuid":"d975f0d5b45cf3f7af30b6c234d13621d2a5a308"},"cell_type":"code","source":"data = (MixedItemList([list_vis, list_tab], path='.', inner_df=train_df[train_df.has_photo])\n        .split_from_df('valid')\n        .label_from_df(cols=['AdoptionSpeed'])\n        .transform(tfms, size=224)\n        .databunch(bs=32, num_workers=0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f8457f9b8f991dfb72bbc4421443acd91fe7965a"},"cell_type":"code","source":"emb_szs = data_tab.get_emb_szs({})\nemb_szs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cce479a72426775b15d21fbf0867ca166da1d341"},"cell_type":"code","source":"nt = 100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"97084f0bae794dfddf9e56d040ae8f2cc7f335ee"},"cell_type":"code","source":"tab = TabularModel(emb_szs, len(data_tab.cont_names), out_sz=nt, layers=[], bn_final=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9b30ca4c6b73d17d3895cecd6ab995c688720055"},"cell_type":"code","source":"class Ridealong(nn.Module):\n    \"\"\"Run m on the first element of list, and bring the others along for the ride\"\"\"\n    def __init__(self, m, posn=0):\n        super().__init__()\n        self.m = m\n        self.posn = posn\n        \n    def forward(self, *xs):\n        x = xs[self.posn]\n        if isinstance(x, Tensor): x = [x]\n        x = self.m(*x)\n        xs = (*xs[:self.posn], x, *xs[self.posn+1:])\n        return xs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"502f93249fd48672f240a2c152aae658427b2973"},"cell_type":"code","source":"class CombineVisTab(nn.Module):\n    def __init__(self, nf, ts, nc):\n        super().__init__()\n        self.nf = nf\n        self.ts = ts\n        self.nc = nc\n        self.flat = nn.Sequential(AdaptiveConcatPool2d(), Flatten())\n        self.layers = nn.Sequential(*bn_drop_lin(nf + ts, nc))\n        \n    def forward(self, *xs):\n        vis, tab = xs\n        x = torch.cat([self.flat(vis), tab], dim=1)\n        return self.layers(x)\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7b98a0ca362d278393917b63dacb0baf9175be2e"},"cell_type":"code","source":"body = create_body(models.resnet34, pretrained=True)\nnf = num_features_model(body) * 2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"97134940dbbeb631de96b25e4b93f44ffcfd9d49"},"cell_type":"code","source":"class MultiSeq(nn.Sequential):\n    def forward(self, *input):\n        for module in self._modules.values():\n            input = module(*input)\n        return input","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c8ab1f88d9282c0f1c5f27f7a9204fe35f043d32"},"cell_type":"code","source":"model = MultiSeq(\n    Ridealong(body[:6]),\n    Ridealong(body[6:]),\n    MultiSeq(\n        Ridealong(tab, 1),\n        CombineVisTab(nf, nt, data.c)\n    )\n)\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d420261b7225b234e07b960ada5850f5c5cca18d"},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"20754512e77a0374d69ab1a56bd8370fc08ceabc"},"cell_type":"code","source":"learn = Learner(data, model, metrics=[accuracy, kappa])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"376c5343cdef001bc65f58eda1621784884b247f"},"cell_type":"code","source":"learn = learn.split([model[0], model[1]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bf56057da2a4257fbedcd2efccdcb173443cee5e"},"cell_type":"code","source":"learn.freeze()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cf35450f7cf6647c49b09a92ca1f689f04b05cbc"},"cell_type":"code","source":"learn.lr_find()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"61a9911d448268b497c4b5cbd6a1fe55b2607fe6"},"cell_type":"code","source":"learn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ec40767cd28c927573abefd2ea35e1d3ee779c4f"},"cell_type":"code","source":"learn.fit_one_cycle(2, max_lr=slice(1e-3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8e4e2b48b887b1c5bd54e34575ee9bf048dbc0a6"},"cell_type":"code","source":"learn.save('l1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"52210e6dccac849d83af951e13a59417b7a9d6c3"},"cell_type":"code","source":"learn.unfreeze()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"94895ea09df54efcd54d6ca0ad5845e5ab5dcc14"},"cell_type":"markdown","source":"Not significantly better than the linear model"},{"metadata":{"trusted":true,"_uuid":"144a5e22dd1f2374a014179048e7c8770f6ae063"},"cell_type":"code","source":"learn.fit_one_cycle(3, max_lr=slice(1e-6, 1e-4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"660d510851b57b98d007ce722296b04b65bdc4a2"},"cell_type":"markdown","source":"TODO: Evaluate on Test Data\n\nResults aren't very good so not much point"},{"metadata":{"trusted":true,"_uuid":"7c0e787a6a9c0143d0129009982a1652c75bf192"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0958c8752464a21a329638710dd297d2bc630d71"},"cell_type":"code","source":"#sub_df = pd.DataFrame(data={'PetID': test_df.PetID, 'AdoptionSpeed': pred.argmax(1).numpy()})\n#sub_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}