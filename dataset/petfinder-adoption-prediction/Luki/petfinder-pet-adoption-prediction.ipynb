{"cells":[{"metadata":{"_uuid":"ca82d322-0abe-40b8-8a65-9fe6a483353c","_cell_guid":"6e5b3e6d-ac74-4897-9b73-72cbeac0b731","trusted":true},"cell_type":"markdown","source":"# Petfinder - pet adoption prediction \n### In this project we will predict how fast pet will find his new home\n### Let's dive in our data"},{"metadata":{"_uuid":"a5a4b68b-19f4-4233-a61d-5ef72b05d41a","_cell_guid":"46571032-3eb2-457d-b9f1-f766c8715c4e","trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"06631151-ea12-4f92-a853-cbd449e4b6bf","_cell_guid":"dfadd2a7-8b78-4575-8f6e-b1a252ac1560","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import json\nimport seaborn as sns\nsns.set(style=\"darkgrid\")\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5b38fc76-fd3e-4db0-a311-20fd33e66043","_cell_guid":"cdc66db8-76eb-4664-b6bd-20bacfffcf00","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# loading files\nbreed_labels = pd.read_csv(\"/kaggle/input/petfinder-adoption-prediction/breed_labels.csv\")\ncolor_labels = pd.read_csv(\"/kaggle/input/petfinder-adoption-prediction/color_labels.csv\")\nstate_labels = pd.read_csv(\"/kaggle/input/petfinder-adoption-prediction/state_labels.csv\")\n\ntrain = pd.read_csv(\"/kaggle/input/petfinder-adoption-prediction/train/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/petfinder-adoption-prediction/test/test.csv\")\ntest_ids = test['PetID']\ncolumns = train.columns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"20143339-23c0-4a58-a9cf-810bbd68047e","_cell_guid":"67d65705-054f-4752-b59a-31e6eb862b21","trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b16bb379-6ca1-44ac-981b-483ea4e2056c","_cell_guid":"df2e4fed-7f00-416d-a50b-c86aea722685","trusted":true},"cell_type":"markdown","source":"## Let's first clean this data a little for visualization purposes. We will change numbers to actual labels."},{"metadata":{"_uuid":"79397585-da95-4674-ac77-d29de8bbc550","_cell_guid":"5a151f1f-6d64-4dc8-b3a7-64fdf0ee8dde","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# functions \ndef preprocess(train, column_name, table):\n    d = dict(zip(range(len(table)), table))\n    train[column_name].replace(d, inplace=True)\n    \ndef id_to_state(id):\n    return state_labels['StateName'][state_labels['StateID'] == id].values[0]\n\ndef simple_plot(train, column_name, plot_title=None):\n    ax = sns.countplot(train[column_name])\n    if plot_title is not None:\n        ax.set(title = plot_title)\n    set_values(ax)\n    \ndef set_values(ax):\n    for p in ax.patches:\n        ax.annotate(format(p.get_height()), (p.get_x() + p.get_width() / 2., p.get_height()), ha = 'center', va = 'center', xytext = (0, 7), textcoords = 'offset points')\n        \ndef id_to_breed(id):\n    if id != 0:\n        return breed_labels['BreedName'][breed_labels['BreedID'] == id].values[0]\n    return 0\n\n# cleaning data\npreprocessing_table = {\n    'MaturitySize': ['Not Specified', 'Small', 'Medium', 'Large', 'Extra Large'],\n    'FurLength': ['Not Specified', 'Short', 'Medium', 'Long'],\n    'Vaccinated': ['Yes', 'No', 'Not Sure'],\n    'Dewormed': ['Yes', 'No', 'Not Sure'],\n    'Sterilized': ['Yes', 'No', 'Not Sure'],\n    'Health': ['Not Specified', 'Healthy', 'Minor Injury', 'Serious Injury'],\n    'Type': [None, 'Dog', 'Cat'],\n    'Gender': [None, 'Male', 'Female', 'Group'],\n    'Color1': ['Not defined', 'Black', 'Brown', 'Golden', 'Yellow', 'Cream', 'Gray', 'White'],\n    'Color2': ['Not defined', 'Black', 'Brown', 'Golden', 'Yellow', 'Cream', 'Gray', 'White'],\n    'Color3': ['Not defined', 'Black', 'Brown', 'Golden', 'Yellow', 'Cream', 'Gray', 'White'],\n    \n}","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"56b7ad94-a144-4bb5-a3eb-28ad82a805ba","_cell_guid":"371daed6-62d4-4ddd-91aa-881e7f7a9ede","trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"def clean(train):\n    for key in preprocessing_table:\n        preprocess(train, key, preprocessing_table[key])\n\n    train['Name'] = train['Name'][pd.notnull(train['Name'])].apply(lambda x: 'Not defined' if ('name' in x.lower() or len(x) < 3) else x)\n    train['Name'].fillna('Not defined', inplace = True)\n\n    names = train['State'].unique().tolist()\n    names_states = [id_to_state(i) for i in names]\n    d = dict(zip(names, names_states))\n    train['State'].replace(d, inplace=True)\n\nclean(train)\nclean(test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"138b78b9-ba34-4a44-ac11-4c0a9b1ce5e5","_cell_guid":"2fe4c569-1c66-4cfa-8938-ce3da4dc14c9","trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fa9ccee5-99ff-414f-b085-742157aabf97","_cell_guid":"b6696df6-b96b-4873-bf8c-5f97e0ffd3e0","trusted":true},"cell_type":"markdown","source":"## Now it's much more readable. We've got 24 columns and almost 15000 rows. On top of that we've got pets images analyse using Google's Vision API as well as analysis for description with Google's Natural Language API. We will use that later."},{"metadata":{"_uuid":"f7746563-f439-4c72-8fb4-0a6d14134588","_cell_guid":"a9aa4291-4944-4600-9e4c-f67082d0694f","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(23,17))\n\nplt.subplot(2,2,1)\nsns.countplot(train['Type'])\n\nplt.subplot(2,2,2)\nsns.countplot(train['Gender'])\n\nplt.subplot(2,2,3)\nax = sns.kdeplot(data=train['Age'], shade=True, gridsize = 30)\n_ = ax.set(title='Age distribution', ylabel='Distribution', xlabel='Age - months')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"82225ea1-7d19-4461-be03-693a11143ca3","_cell_guid":"622ce937-a6db-43f0-9350-d2b5801430d0","trusted":true},"cell_type":"markdown","source":"## We've got similar number of cats and dogs. Most of them are around 1 year old with slightly higher number of female pets."},{"metadata":{"_uuid":"625ef642-0926-45ff-8c2b-184c86b65e78","_cell_guid":"69b9e1c5-899e-451a-b23c-93ba27ab9e10","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"num = 10\nmixed_breed_class = 307\n\nplt.figure(figsize=(20,20))\n\nindexes, values = train['Breed1'][(train['Type'] == 'Dog')].value_counts().index[:num], train['Breed1'].value_counts()[:num]\nnames = [id_to_breed(i) for i in indexes]\ns = pd.Series(data={'values': values.values, 'names': names})\nax = sns.catplot(x = 'values', y = 'names' , kind='bar', data = s)\n_ = ax.set(title=f'Dog breed classes top {num}', ylabel='Dog breed', xlabel='Count')\n    \nindexes, values = train['Breed1'][(train['Type'] == 'Cat')].value_counts().index[:num], train['Breed1'].value_counts()[:num]\nnames = [id_to_breed(i) for i in indexes]\ns = pd.Series(data={'values': values.values, 'names': names})\nax = sns.catplot(x = 'values', y = 'names' , kind='bar', data = s)\n_ = ax.set(title=f'Cat breed classes top {num}', ylabel='Cat breed', xlabel='Count')\n\npure_breeded = train['Breed1'].apply(lambda x: 0 if id_to_breed(x) in ['Mixed Breed', 'Domestic Short Hard', 'Domestic Medium Hair', 'Domestic Long Hair'] else 1)\nprint(f'Pure breeded pets: {sum(pure_breeded)}\\nNot pure breeded pets: {len(pure_breeded)-sum(pure_breeded)}')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"76e3b832-1b63-46ab-8ca7-2f73c70f5ca7","_cell_guid":"60e4b0ac-9866-40a4-a15b-b0547b583f84","trusted":true},"cell_type":"markdown","source":"### As we can see dogs as well as cats breeds are mostly dominated by ~3 classes. We've got 7512 purebreeded pets and 7481 pets that aren't purebreeded."},{"metadata":{"_uuid":"3cf6c95e-a43c-4aac-be72-1db2f208edbf","_cell_guid":"59cbcba5-7eeb-4676-80f0-579fe5f4c9f1","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(25,7.5))\n\nplt.subplot(1,3,1)\nax = sns.countplot(train['Color1'])\nax.set(title='First color')\n\nplt.subplot(1,3,2)\nax = sns.countplot(train['Color2'])\nax.set(title='Second color')\n\nplt.subplot(1,3,3)\nax = sns.countplot(train['Color3'])\n_ = ax.set(title='Third color')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7487e4d5-c44d-429b-9fd8-b279d2f33b85","_cell_guid":"4f4b45b0-bdbf-467b-8e62-69ef3e0a2869","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(25,15))\n\nplt.subplot(2,3,1)\nsimple_plot(train, 'MaturitySize')\n\nplt.subplot(2,3,2)\nsimple_plot(train, 'FurLength')\n\nplt.subplot(2,3,3)\nsimple_plot(train, 'Vaccinated')\n\nplt.subplot(2,3,4)\nsimple_plot(train, 'Dewormed')\n\nplt.subplot(2,3,5)\nsimple_plot(train, 'Sterilized')\n\nplt.subplot(2,3,6)\nsimple_plot(train, 'Health')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5763255f-6960-4b66-96e9-daeb21f098e3","_cell_guid":"3e9ed86a-abaa-4296-9f6a-5c0baffbcfcd","trusted":true},"cell_type":"markdown","source":"## So we've got some basic information about pets like size of their fur length as well as about their health and medical treatment."},{"metadata":{"_uuid":"35fdaa9b-dcd3-453f-ad02-3a4e72104545","_cell_guid":"3355cfbe-5794-4a52-b186-58be26ef8a05","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(15,7))\nsimple_plot(train, 'Quantity', 'Number of pets in profile')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"41945eb5-22c7-47f8-b04f-842042dab2c8","_cell_guid":"6e2ba68a-dd30-485f-ac61-e40b3d1eef82","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fee = pd.concat([train['Fee'][train['Fee'] == 0], pd.qcut(train['Fee'][train['Fee'] != 0], 5).sort_values()], axis=0)\nplt.figure(figsize=(10,5))\nax = sns.countplot(fee)\nax.set(title = 'Fee amount for pet')\nset_values(ax)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7af71d19-a9d3-4a29-9749-b0425b528164","_cell_guid":"71fe8dc1-686f-4beb-a691-d2e48ae770e5","trusted":true},"cell_type":"markdown","source":"## As we can see on plots above most of pets profiles contain single pet and most of them are free of charges."},{"metadata":{"_uuid":"a147d8c3-5c30-4988-a9c1-fc07fddc5db5","_cell_guid":"89a54343-1027-4210-aab9-2e8c4db42fc5","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(20,5))\nax = sns.countplot(train['State'])\nax.set(title = 'State location in Malaysia')\nset_values(ax)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"31070dd7-abc4-4f4f-9c4a-c2211bd380b2","_cell_guid":"89a251ad-37f2-4448-a7ee-f3d0383250fb","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(20,6))\n\nplt.subplot(1,2,1)\nsimple_plot(train, 'VideoAmt', 'Number of pet videos uploaded')\nax = sns.countplot(train['VideoAmt'])\nax.set(title = 'Number of pet videos uploaded')\nset_values(ax)\n\nplt.subplot(1,2,2)\nax = sns.countplot(train['PhotoAmt'].sort_values().apply(lambda x: 'Over 10' if x > 10 else x))\nax.set(title = 'Number of pet photos uploaded')\nset_values(ax)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c0880228-cce1-491a-9ea7-6b0d540f947e","_cell_guid":"1c0ae035-2f38-464e-a843-e5840498deb4","trusted":true},"cell_type":"markdown","source":"## Almost all profiles have photos of animals but we rarely see any videos."},{"metadata":{"_uuid":"4ea86dc9-4ef9-42df-9884-d408c26cb50a","_cell_guid":"be7a1702-667a-4153-a5fc-a3aa2cbd3f2f","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def get_magnitude_avg(x, w):\n    if os.path.exists(f\"/kaggle/input/petfinder-adoption-prediction/train_sentiment/{x['PetID']}.json\"):\n        j = json.load(open(f\"/kaggle/input/petfinder-adoption-prediction/train_sentiment/{x['PetID']}.json\"))\n        summ, num = 0, 0\n        for sent in j['sentences']:\n            summ += sent['sentiment'][w]\n            num += 1\n        return summ/num\n    else:\n        return None\n            \ntrain['Description_magnitude'] = train.apply(lambda x: get_magnitude_avg(x, 'magnitude'), axis=1)            \ntrain['Description_score'] = train.apply(lambda x: get_magnitude_avg(x, 'score'), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b3b58313-0771-42a7-899e-7a5573883e20","_cell_guid":"8b27f6d8-5d60-4757-a539-93ca4abfb7b9","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(20,6))\n\nplt.subplot(1,2,1)\nax = sns.distplot(a=train['Description_magnitude'], kde = False)\nax.set(title='Magnitude - strength of emotion in description.', xlabel='Description magnitude', ylabel='count')\n\nplt.subplot(1,2,2)\nax = sns.distplot(a=train['Description_score'], kde = False)\n_ = ax.set(title='Score - emotional leaning of the description -1 - negative, 1 - positive', xlabel='Description score', ylabel='count')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"97803ca6-6636-42c1-a390-2c682d4fb5d6","_cell_guid":"be721f02-ef8b-4a09-9301-600cc9ceb468","trusted":true},"cell_type":"markdown","source":"## I took average magnitude and score from Google's Natural Language API used on every sentence of pets description.\n## Magnitude - indicates the overall strength of emotion (both positive and negative) within the given text\n## Score - ranges between -1.0 (negative) and 1.0 (positive) and corresponds to the overall emotional leaning of the text.\n![image.png](attachment:image.png)"},{"metadata":{"_uuid":"fe553c98-11cc-4d96-bd24-5a00c777fb3d","_cell_guid":"97634954-9ff9-4b16-a4c6-875cd7d27ec9","trusted":true},"cell_type":"markdown","source":"# Data preprocessing\n### I want to fit convolution 1d neural network with our data. To do that I have to preprocess our data. What I'm going to is the fallowing:\n### - Normalize Age, Quantity, Fee, number of videoes and number of photos\n### - Create 1-hot vector of pet's Type, Gender, Color, MaturitySize, FurLength, Vaccinated, Dewormed, Sterilized, Health, Breed, State, Name"},{"metadata":{"_uuid":"afbcb521-d24c-4b60-88ac-a491d071033d","_cell_guid":"9a821679-3d71-409c-8aca-6f8efbed3a33","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print(f'Columns in train data before preprocessing:\\n\\n {train.columns.to_list()}')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d99bf060-8b15-4558-bdf8-8b13bf4a92aa","_cell_guid":"aa66ad76-c638-411b-aec5-41c51aad60a3","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def limit_column(train, test, column_name, values):\n    train[column_name] = train[column_name].apply(lambda x: x if x in values else 'Other')\n    test[column_name] = test[column_name].apply(lambda x: x if x in values else 'Other')\n\nlimit_column(train, test, 'Breed1', test['Breed1'].value_counts().index[:3].to_list())\nlimit_column(train, test, 'Breed2', test['Breed2'].value_counts().index[:4].to_list())\nlimit_column(train, test, 'State', test['State'].value_counts().index[:3].to_list())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f9e03642-9ee2-40b4-b17b-d1a7446e68c6","_cell_guid":"177d7cab-53c7-4511-9e5b-ba8ab6198d01","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# preprocessing to fit model\nfrom sklearn import preprocessing\n\ndef preprocess_all(train):\n    train['Name'] = train['Name'].apply(lambda x: 'Defined' if x != 'Not defined' else x)\n\n    # normalization\n    normalization_columns = ['Age', 'Quantity', 'Fee', 'VideoAmt', 'PhotoAmt']\n    x = train[normalization_columns].values\n    scaler = preprocessing.MinMaxScaler()\n    x_scaled = scaler.fit_transform(x)\n    train[normalization_columns] = pd.DataFrame(x_scaled, columns=normalization_columns)\n\n    #one hot encoding\n    dummies_columns = ['Type', 'Gender', 'Color1', 'Color2', 'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed', 'Sterilized', 'Health', 'Breed1', 'Breed2', 'State', 'Name']\n    train = pd.get_dummies(train, columns=dummies_columns)\n    \n    train.drop(['RescuerID', 'Description', 'PetID'], axis = 1, inplace = True)\n    \n    return train\n\ntrain_labels = train['AdoptionSpeed']    \ntrain.drop(['AdoptionSpeed', 'Description_magnitude', 'Description_score'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f56583fd-386a-4be1-be60-75dcae0be132","_cell_guid":"41e5cdd4-898f-4ae0-9fc6-8c137c07f82e","trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"train = preprocess_all(train)\ntest = preprocess_all(test)\n\nX_train, Y_train, X_test = train.values, train_labels.values, test.values\nX_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\nX_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2f43c35d-21a0-43c3-bdcc-819f8878f886","_cell_guid":"786c9f16-8d24-4048-b7f4-34c8750dc448","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print(f'Columns in train data after preprocessing:\\n\\n {train.columns.to_list()}')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"785ffb78-9287-4052-bb71-8c184c714de5","_cell_guid":"8d0bda50-d491-4c5d-ac1b-4017c712192d","trusted":true},"cell_type":"markdown","source":"# Building and training our model"},{"metadata":{"_uuid":"2f9943f9-9dce-4ee8-b088-8afaf36b9831","_cell_guid":"b7acafde-b8e0-4d81-bb93-1e8d59863c7f","trusted":true},"cell_type":"markdown","source":"## I am going to predict adoption speed using 1D convolution network. It will run through 5 layers of 1D convolution with batch normalization as well as dropout after each layer to prevent overfitting and after that it will run through another 4 layers of fully connected network with last layer having 5 nodes corresponding to our target classes."},{"metadata":{"_uuid":"0a854b0f-ebbc-400e-aef0-56d8cc665c1d","_cell_guid":"9c663a1b-1fdb-4c67-b396-024828d4b261","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense, BatchNormalization, Dropout, Conv1D, Flatten\n\nmodel = Sequential()\n\nmodel.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape = (X_train[0].shape[0], 1)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\nmodel.add(Conv1D(filters=128, kernel_size=2, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\nmodel.add(Conv1D(filters=256, kernel_size=2, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\nmodel.add(Conv1D(filters=512, kernel_size=2, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\nmodel.add(Conv1D(filters=1024, kernel_size=2, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(512, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(256, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(64, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(5, activation='softmax'))\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9405add7-2be8-4668-ae2c-476e145a662d","_cell_guid":"3bf5cdc4-0f2a-4908-b9c5-353a5352e9a9","trusted":true},"cell_type":"markdown","source":"## Let's train our model!"},{"metadata":{"_uuid":"b8d712c8-47c9-4931-9f0b-5651fa0d120c","_cell_guid":"c71b7e71-b605-4abd-9b4b-8cc4c8028140","trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nhistory = model.fit(X_train, Y_train, epochs=10, validation_split=0.2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d90cef52-b5fb-48be-b273-98bd98e062eb","_cell_guid":"99ee64a1-83e8-412d-93a0-05b8964d4551","trusted":true},"cell_type":"markdown","source":"## As we can see our model is doing pretty bad. Accuracy is around 35%. At least we are not overfitting to training set"},{"metadata":{"_uuid":"178635b3-d867-4292-9951-6452cd54c783","_cell_guid":"04d4f06b-787a-4b0c-a4b2-cb1133f6e8df","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(10,7))\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.legend(['Train loss', 'Validation loss'])\nplt.xlabel('Epochs')\nplt.ylabel('Loss (categorical crossentropy)')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d7ff4705-1386-4d96-962e-a1237c51a5f6","_cell_guid":"06ba158a-d350-40ce-834c-cd5e31b3497f","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\nplt.figure(figsize=(10,7))\ntrain_predictions = model.predict_classes(X_train)\nmatrix = confusion_matrix(Y_train, train_predictions)\nax = sns.heatmap(matrix, annot=True, fmt='d', linewidths=0.25)\n_ = ax.set(xlabel='Predicted class', ylabel='Actual class')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6a479c57-f98b-4e01-963f-4243b57f6107","_cell_guid":"87f11319-467a-4c1f-b039-95ae4b16a802","trusted":true},"cell_type":"markdown","source":"## From this matrix plot we can see that in a lot of cases we were quite close to actual class. We never predicted that pet will be adopted on the same day after being listed probably because of low number of such cases in training set."},{"metadata":{"_uuid":"01b32b11-b73f-48b8-849e-ef4adaddcb68","_cell_guid":"7feecad8-5351-411f-ba4f-6502f3336138","trusted":true},"cell_type":"code","source":"from sklearn.metrics import cohen_kappa_score\n\nsc = cohen_kappa_score(train_predictions, Y_train, weights = 'quadratic')\nprint(f'Quadratic kappa score: {sc}')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e9aa6be8-97f9-45ab-bee7-221b17749f54","_cell_guid":"63b729a1-a29c-4360-8d1b-49624678c1bd","trusted":true},"cell_type":"markdown","source":"# Building fully connected model"},{"metadata":{"_uuid":"20a07ff2-2410-4344-a44e-f5765f059f19","_cell_guid":"92ab778c-5263-428c-bf49-3ed44d7ebe46","trusted":true},"cell_type":"markdown","source":"## Let's try building another model using only fully connected layers"},{"metadata":{"_uuid":"6b4877d0-3266-4a56-9173-5b8e01c8e819","_cell_guid":"86fe4786-c65a-4f93-a1ef-018be1568fb5","trusted":true},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Flatten(input_shape = (X_train[0].shape[0], 1)))\n\nmodel.add(Dense(128, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(256, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(256, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(512, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(512, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(5, activation='softmax'))\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c3282fb9-aba7-425a-a8be-6ba481a19c15","_cell_guid":"4696270a-aade-49ad-8945-3b5ee506d901","trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nhistory = model.fit(X_train, Y_train, epochs=15, validation_split=0.2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b6faaf5b-eff7-4f9c-90d8-5e55c22d5b33","_cell_guid":"a3b95ac6-ea6b-4a9b-9353-661cd29de239","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(10,7))\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.legend(['Train loss', 'Validation loss'])\nplt.xlabel('Epochs')\nplt.ylabel('Loss (categorical crossentropy)')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"79540260-7f99-4940-a534-7e0d02f42fa4","_cell_guid":"88f207f0-e318-43fe-985d-e9b71d8a83dc","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from sklearn.metrics import cohen_kappa_score\n\ntrain_predictions = model.predict_classes(X_train)\nsc = cohen_kappa_score(train_predictions, Y_train, weights = 'quadratic')\nprint(f'Quadratic kappa score: {sc}')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0255b395-f707-4038-ad03-813df8122f20","_cell_guid":"4a51861f-54f1-4c0b-b439-0ff4ea56327f","trusted":true},"cell_type":"markdown","source":"## Using fully connected network we can observe similar results with validation loss having more spikes then in 1D CNN."},{"metadata":{"_uuid":"b50ed184-9cb5-4cd3-8a20-6f217fe19ec2","_cell_guid":"ad9804c3-9e13-468a-9932-1b256754fbf9","trusted":true},"cell_type":"code","source":"test_predictions = model.predict_classes(X_test)\nmy_submission = pd.DataFrame({'PetID': range(len(test_predictions)), 'AdoptionSpeed': test_predictions})\nmy_submission['PetID'] = test_ids\nmy_submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}