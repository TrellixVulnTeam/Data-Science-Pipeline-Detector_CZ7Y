{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"MyaSNNjam8IW","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport glob\nimport zipfile\nimport os\nimport gc\nimport json\nimport seaborn as sns\n#import parallel\nfrom collections import Counter\nfrom functools import partial\nimport scipy as sp\nfrom PIL import Image\nfrom joblib import Parallel, delayed\nfrom scipy.stats import skew \nfrom scipy.stats import norm\nfrom wordcloud import WordCloud, STOPWORDS\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import SparsePCA, TruncatedSVD, LatentDirichletAllocation, NMF","execution_count":null,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"colab_type":"code","id":"ZQDZg_QooCyN","outputId":"c8e8c7b1-2321-4b3d-d7df-69c7cf3b4099","trusted":true},"cell_type":"code","source":"#from google.colab import drive\n#drive.mount('/content/drive')","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"rNdMjM_Jm8JL","trusted":true},"cell_type":"code","source":"#breeds = pd.read_csv('/content/drive/My Drive/PetFinder.my Adoption Prediction/PetFinder.my Adoption Prediction/breed_labels.csv')\n#colors = pd.read_csv('/content/drive/My Drive/PetFinder.my Adoption Prediction/PetFinder.my Adoption Prediction/color_labels.csv')\n#states = pd.read_csv('/content/drive/My Drive/PetFinder.my Adoption Prediction/PetFinder.my Adoption Prediction/state_labels.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"breeds = pd.read_csv('/kaggle/input/petfinder-adoption-prediction/breed_labels.csv')\ncolors = pd.read_csv('/kaggle/input/petfinder-adoption-prediction/color_labels.csv')\nstates = pd.read_csv('/kaggle/input/petfinder-adoption-prediction/state_labels.csv')","execution_count":null,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":323},"colab_type":"code","id":"Z50HtL-um8JX","outputId":"abc4a082-373d-4496-d64c-006311b225b0","trusted":true},"cell_type":"code","source":"print(breeds.head())\nprint(colors.head())\nprint(states.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/petfinder-adoption-prediction/train/train.csv')\ntest = pd.read_csv('/kaggle/input/petfinder-adoption-prediction/test/test.csv')\nsubmission = pd.read_csv('/kaggle/input/petfinder-adoption-prediction/test/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images = sorted(glob.glob('/kaggle/input/petfinder-adoption-prediction/train_images/*.jpg'))\ntrain_metadata = sorted(glob.glob('/kaggle/input/petfinder-adoption-prediction/train_metadata/*.json'))\ntrain_sentiment = sorted(glob.glob('/kaggle/input/petfinder-adoption-prediction/train_sentiment/*.json'))\n\ntest_images = sorted(glob.glob('/kaggle/input/petfinder-adoption-prediction/test_images/*.jpg'))\ntest_metadata = sorted(glob.glob('/kaggle/input/petfinder-adoption-prediction/test_metadata/*.json'))\ntest_sentiment = sorted(glob.glob('/kaggle/input/petfinder-adoption-prediction/test_sentiment/*.json'))","execution_count":null,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":119},"colab_type":"code","id":"iPDz65XLDyZd","outputId":"d0d1a0a9-4e77-4b1e-e46f-596a2dce01c1","trusted":true},"cell_type":"code","source":"print('train_images: ', len(train_images))\nprint('train_metadata: ', len(train_metadata))\nprint('train_sentiment: ', len(train_sentiment))\n\nprint('test_images: ', len(test_images))\nprint('test_metadata: ', len(test_metadata))\nprint('test_sentiment: ', len(test_sentiment))","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"xmzlWjHGm8Ks"},"cell_type":"markdown","source":"### Target value (Adoption Speed)\n\n0 — Pet was adopted on the same day as it was listed.\n\n1 — Pet was adopted between 1 and 7 days (1st week) after being listed.\n\n2 — Pet was adopted between 8 and 30 days (1st month) after being listed.\n\n3 — Pet was adopted between 31 and 90 days (2nd & 3rd month) after being listed.\n\n4 — No adoption after 100 days of being listed. (There are no pets in this dataset that waited between 90 and 100 days)."},{"metadata":{"colab_type":"text","id":"1bcegDkKm8Ku"},"cell_type":"markdown","source":"### Feature\n\nPetID — Unique hash ID of pet profile\n\nAdoptionSpeed — Categorical speed of adoption. Lower is faster. This is the value to predict. See below section for more info.\n\nType — Type of animal (1 = Dog, 2 = Cat)\n\nName — Name of pet (Empty if not named)\n\nAge — Age of pet when listed, in months\n\nBreed1 — Primary breed of pet (Refer to BreedLabels dictionary)\n\nBreed2 — Secondary breed of pet, if pet is of mixed breed (Refer to BreedLabels dictionary)\n\nGender — Gender of pet (1 = Male, 2 = Female, 3 = Mixed, if profile represents group of pets)\n\nColor1 — Color 1 of pet (Refer to ColorLabels dictionary)\n\nColor2 — Color 2 of pet (Refer to ColorLabels dictionary)\n\nColor3 — Color 3 of pet (Refer to ColorLabels dictionary)\n\nMaturitySize — Size at maturity (1 = Small, 2 = Medium, 3 = Large, 4 = Extra Large, 0 = Not Specified)\n\nFurLength — Fur length (1 = Short, 2 = Medium, 3 = Long, 0 = Not Specified)\n\nVaccinated — Pet has been vaccinated (1 = Yes, 2 = No, 3 = Not Sure)\n\nDewormed — Pet has been dewormed (1 = Yes, 2 = No, 3 = Not Sure)\n\nSterilized — Pet has been spayed / neutered (1 = Yes, 2 = No, 3 = Not Sure)\n\nHealth — Health Condition (1 = Healthy, 2 = Minor Injury, 3 = Serious Injury, 0 = Not Specified)\n\nQuantity — Number of pets represented in profile\n\nFee — Adoption fee (0 = Free)\n\nState — State location in Malaysia (Refer to StateLabels dictionary)\n\nRescuerID — Unique hash ID of rescuer\n\nVideoAmt — Total uploaded videos for this pet\n\nPhotoAmt — Total uploaded photos for this pet\n\nDescription — Profile write-up for this pet. The primary language used is English, with some in Malay or Chinese."},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":68},"colab_type":"code","id":"lWsZIzVTm8Kw","outputId":"7344f0de-6fe1-488c-ac14-38ad4b374a25","trusted":true},"cell_type":"code","source":"print(train.shape)\nprint(submission.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":547},"colab_type":"code","id":"w4hFfJu8SeGx","outputId":"add51880-f253-468b-c9e3-251951aa5d2e","trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":289},"colab_type":"code","id":"xAx-o33dYMZm","outputId":"028cd91d-2b71-43b0-db2c-8fc4b54a0daa","trusted":true},"cell_type":"code","source":"print('Data Submission')\nprint(submission.head())\nprint('Data Test')\nprint(test.head())","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"q5V87riDCECK"},"cell_type":"markdown","source":"**Feature Engineering**"},{"metadata":{"colab_type":"text","id":"OeGdU4_VL1af"},"cell_type":"markdown","source":"-- *Train* --"},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":170},"colab_type":"code","id":"k4kBp1q8CLyA","outputId":"9101280b-5bd7-41f3-932d-0c97f79b8289","trusted":true},"cell_type":"code","source":"# Images\n\ntrain_df_ids = train['PetID']\nprint('shape of train_df_ids: ', train_df_ids.shape)\n\ntrain_df_imgs = pd.DataFrame(train_images, columns=['image_filename'])\ntrain_imgs_pets = train_df_imgs['image_filename'].apply(lambda x: x.split('/')[-1].split('-')[0])\ntrain_df_imgs = train_df_imgs.assign(PetID = train_imgs_pets)\nprint('len of unique train_imgs_pet', len(train_imgs_pets.unique()))\nprint(train_df_imgs.head())\n\npets_with_images = len(np.intersect1d(train_imgs_pets.unique(), train_df_imgs['PetID'].unique()))\nprint('fraction of pets with images: {:.3f}'.format(pets_with_images/train_df_ids.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"rkOEflXUQvBD","trusted":true},"cell_type":"code","source":"# Metadata\n\ntrain_df_ids = train['PetID']\nprint('shape of train_df_ids: ', train_df_ids.shape)\n\ntrain_df_metadata = pd.DataFrame(train_metadata, columns=['metadata_filename'])\ntrain_metadata_pets = train_df_metadata['metadata_filename'].apply(lambda x: x.split('/')[-1].split('-')[0])\ntrain_df_metadata = train_df_metadata.assign(PetID = train_metadata_pets)\nprint('len of unique train_metadata_pets', len(train_metadata_pets.unique()))\nprint(train_df_metadata.head())\n\npets_with_metadata = len(np.intersect1d(train_metadata_pets.unique(), train_df_metadata['PetID'].unique()))\nprint('fraction of pets with metadata: {:.3f}'.format(pets_with_metadata/train_df_ids.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sentiment\n\ntrain_df_ids = train['PetID']\nprint('shape of train_df_ids: ', train_df_ids.shape)\n\ntrain_df_sentiment = pd.DataFrame(train_sentiment, columns=['sentiment_filename'])\ntrain_sentiment_pets = train_df_sentiment['sentiment_filename'].apply(lambda x: x.split('/')[-1].split('-')[0])\ntrain_df_sentiment = train_df_sentiment.assign(PetID = train_sentiment_pets)\nprint('len of unique train_sentiment_pets', len(train_sentiment_pets.unique()))\nprint(train_df_sentiment.head())\n\npets_with_sentiment = len(np.intersect1d(train_sentiment_pets.unique(), train_df_sentiment['PetID'].unique()))\nprint('fraction of pets with sentiment: {:.3f}'.format(pets_with_sentiment/train_df_ids.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check some descriptions that the Google API could not analyze\na = train_df_sentiment['PetID'].apply(lambda x: x.split('.json')[0])\nb = {}\nfor i in train.PetID:\n    if i not in list(a):\n        b.update(train[train.PetID == i]['Description'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"b","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c = {}\nfor i in list(a):\n    c.update(train[train.PetID == i]['Description'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"-- Test --"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Images\n\ntest_df_ids = test['PetID']\nprint('shape of test_df_ids: ', test_df_ids.shape)\n\ntest_df_imgs = pd.DataFrame(test_images, columns=['image_filename'])\ntest_imgs_pets = test_df_imgs['image_filename'].apply(lambda x: x.split('/')[-1].split('-')[0])\ntest_df_imgs = test_df_imgs.assign(PetID = test_imgs_pets)\nprint('len of unique test_imgs_pet', len(test_imgs_pets.unique()))\nprint(test_df_imgs.head())\n\npets_with_images = len(np.intersect1d(test_imgs_pets.unique(), test_df_imgs['PetID'].unique()))\nprint('fraction of pets with images: {:.3f}'.format(pets_with_images/test_df_ids.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Metadata\n\ntest_df_ids = test['PetID']\nprint('shape of test_df_ids: ', test_df_ids.shape)\n\ntest_df_metadata = pd.DataFrame(test_metadata, columns=['metadata_filename'])\ntest_metadata_pets = test_df_metadata['metadata_filename'].apply(lambda x: x.split('/')[-1].split('-')[0])\ntest_df_metadata = test_df_metadata.assign(PetID = test_metadata_pets)\nprint('len of unique train_metadata_pets', len(test_metadata_pets.unique()))\nprint(test_df_metadata.head())\n\npets_with_metadata = len(np.intersect1d(test_metadata_pets.unique(), test_df_metadata['PetID'].unique()))\nprint('fraction of pets with metadata: {:.3f}'.format(pets_with_metadata/test_df_ids.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sentiment\n\ntest_df_ids = test['PetID']\nprint('shape of test_df_ids: ', test_df_ids.shape)\n\ntest_df_sentiment = pd.DataFrame(test_sentiment, columns=['sentiment_filename'])\ntest_sentiment_pets = test_df_sentiment['sentiment_filename'].apply(lambda x: x.split('/')[-1].split('-')[0])\ntest_df_sentiment = test_df_sentiment.assign(PetID = test_sentiment_pets)\nprint('len of unique train_sentiment_pets', len(test_sentiment_pets.unique()))\nprint(test_df_sentiment.head())\n\npets_with_sentiment = len(np.intersect1d(test_sentiment_pets.unique(), test_df_sentiment['PetID'].unique()))\nprint('fraction of pets with sentiment: {:.3f}'.format(pets_with_sentiment/test_df_ids.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class petfinder(object):\n    def __init__(self, debug=False):\n        self.debug = debug\n        self.sentence_sep = ' '\n        self.extract_sentiment_text = False\n        \n    def open_metadata_file(self, filename):\n        \n    # Load metadata file\n        \n        with open(filename, 'r') as f:\n            metadata_file = json.load(f)\n        return metadata_file\n    \n    def open_sentiment_file(self, filename):\n        \n    # Load sentiment file\n        \n        with open(filename, 'r') as f:\n            sentiment_file = json.load(f)\n        return sentiment_file\n    \n    def open_image_file(self, filename):\n        \n    # Load image file\n        \n        image = np.asarray(Image.open(filename))\n        return image\n    \n    def parse_sentiment_file(self, file):\n        \n    # Parse sentiment file. Output is dataframe with sentiment feature\n        \n        file_sentiment = file['documentSentiment']\n        file_entities = [x['name'] for x in file['entities']]\n        file_entities = self.sentence_sep.join(file_entities)\n\n        if self.extract_sentiment_text:\n            file_sentences_text = [x['text']['content'] for x in file['sentences']]\n            file_sentences_text = ' '.join(file_sentence_text)\n    \n        file_sentences_sentiment = [x['sentiment'] for x in file['sentences']]\n        file_sentences_sentiment = pd.DataFrame.from_dict(file_sentences_sentiment, orient='columns').sum()\n        file_sentences_sentiment = file_sentences_sentiment.add_prefix('document_').to_dict()\n\n        file_sentiment.update(file_sentences_sentiment)\n        df_sentiment = pd.DataFrame.from_dict(file_sentiment, orient='index').T\n\n        if self.extract_sentiment_text:\n            df_sentiment['test'] = file_sentences_text\n    \n        df_sentiment['entities'] = file_entities\n        df_sentiment = df_sentiment.add_prefix('sentiment_')\n        \n        return df_sentiment\n    \n    def parse_metadata_file(self, file):\n        \n    # Parse metadata file. Output is Dataframe with metadata features\n    \n        file_keys = list(file.keys())\n\n        if 'labelAnnotations' in file_keys:\n            file_annots = file['labelAnnotations'][:int(len(file['labelAnnotations']) * 0.3)]\n            file_top_score = np.asarray([x['score'] for x in file_annots]).mean()\n            file_top_description = [x['description'] for x in file_annots]\n            file_top_description = self.sentence_sep.join(file_top_description)\n        else:\n            file_top_score = np.nan\n            file_top_description = ['']\n    \n        file_colors = file['imagePropertiesAnnotation']['dominantColors']['colors']\n        file_crops = file['cropHintsAnnotation']['cropHints']\n\n        file_color_score = np.asarray([x['score'] for x in file_colors]).mean()\n        file_color_pixelfraction = np.asarray([x['pixelFraction'] for x in file_colors]).mean()\n\n        file_crop_confidence = np.asarray([x['confidence'] for x in file_crops]).mean()\n\n        if 'importanceFraction' in file_crops[0].keys():\n            file_crop_importance = np.asarray([x['importanceFraction'] for x in file_crops]).mean()\n        else:\n            file_crop_importance = np.nan\n    \n        df_metadata = pd.DataFrame.from_dict({'annots_score': file_top_score,\n                                             'color_score': file_color_score,\n                                             'color_pixelfraction': file_color_pixelfraction,\n                                             'crop_confidence': file_crop_confidence,\n                                             'crop_importance': file_crop_importance,\n                                             'annots_top_description': file_top_description}, orient='index')\n        df_metadata = df_metadata.T\n        df_metadata = df_metadata.add_prefix('metadata_')\n    \n        return df_metadata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"file = petfinder().open_metadata_file(train_sentiment[1])\nfile1 = petfinder().open_metadata_file(train_metadata[1])\nprint(petfinder().parse_sentiment_file(file))\nprint(petfinder().parse_metadata_file(file1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(file)\nprint('   ')\nprint(train_sentiment[1])\nprint('   ')\nprint(train[train.PetID == '000a290e4'].Description)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(file1)\nprint('   ')\nprint(train_metadata[1])\nprint('  ')\nprint(train[train.PetID == '0008c5398'].Description)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create function for parallel data processing\n\ndef extract_additional_features(pet_id, mode='train'):\n    sentiment_filename = '/kaggle/input/petfinder-adoption-prediction/{}_sentiment/{}.json'.format(mode, pet_id)\n    try:\n        sentiment_file = petfinder.open_sentiment_file(sentiment_filename)\n        df_sentiment = petfinder.parse_sentiment_file(sentiment_file)\n        df_sentiment['PetID'] = pet_id\n    except FileNotFoundError:\n        df_sentiment = []\n    \n    dfs_metadata = []\n    metadata_filenames = sorted(glob.glob('/kaggle/input/petfinder-adoption-prediction/{}_metadata/{}*.json'.format(mode, pet_id)))\n    if len(metadata_filenames) > 0:\n        for f in metadata_filenames:\n            metadata_file = petfinder.open_metadata_file(f)\n            df_metadata = petfinder.parse_metadata_file(metadata_file)\n            df_metadata['PetID'] = pet_id\n            dfs_metadata.append(df_metadata)\n        dfs_metadata = pd.concat(dfs_metadata, ignore_index=True, sort=False)\n    \n    dfs = [df_sentiment, dfs_metadata]\n    \n    return dfs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"petfinder = petfinder()\ndebug = False\ntrain_pet_ids = train.PetID.unique()\ntest_pet_ids = test.PetID.unique()\n\nif debug:\n    train_pet_ids = train_pet_ids[:1000]\n    test_pet_ids = test_pet_ids[:1000]\n    \ndfs_train = Parallel(n_jobs=6, verbose=1)(delayed(extract_additional_features)(i, mode='train') for i in train_pet_ids)\ndfs_test = Parallel(n_jobs=6, verbose=1)(delayed(extract_additional_features)(i, mode='test') for i in test_pet_ids)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dfs_sentiment = [x[0] for x in dfs_train if isinstance(x[0], pd.DataFrame)]\ntrain_dfs_metadata = [x[1] for x in dfs_train if isinstance(x[1], pd.DataFrame)]\n\ntest_dfs_sentiment = [x[0] for x in dfs_test if isinstance(x[0], pd.DataFrame)]\ntest_dfs_metadata = [x[1] for x in dfs_test if isinstance(x[1], pd.DataFrame)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dfs_sentiment","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dfs_sentiment = pd.concat(train_dfs_sentiment, ignore_index=True, sort=False)\ntrain_dfs_metadata = pd.concat(train_dfs_metadata, ignore_index=True, sort=False)\n\ntest_dfs_sentiment = pd.concat(test_dfs_sentiment, ignore_index=True, sort=False)\ntest_dfs_metadata = pd.concat(test_dfs_metadata, ignore_index=True, sort=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('shape of train_dfs sentiment & metadata:')\nprint(train_dfs_sentiment.shape, train_dfs_metadata.shape)\nprint('shape of test_dfs sentiment & metadata:')\nprint(test_dfs_sentiment.shape, test_dfs_metadata.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Group extracted features by 'PetID'"},{"metadata":{"trusted":true},"cell_type":"code","source":"# extend aggregates and improve column naming\naggregates = ['mean', 'sum']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train\n\nprefix = 'metadata'\ntrain_metadata_group = train_dfs_metadata.drop(['metadata_annots_top_description'], axis=1)\n\nfor i in train_metadata_group.columns:\n    if 'PetID' not in i:\n        train_metadata_group[i] = train_metadata_group[i].astype(float)\ntrain_metadata_group = train_metadata_group.groupby(['PetID']).agg(aggregates)\ntrain_metadata_group.columns = pd.Index(['{}_{}_{}'.format(prefix, c[0], c[1].upper()) for c in train_metadata_group.columns.tolist()])\ntrain_metadata_group = train_metadata_group.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_sentiment_description = train_dfs_sentiment.groupby(['PetID'])['sentiment_entities'].unique()\ntrain_sentiment_description = train_sentiment_description.reset_index()\ntrain_sentiment_description['sentiment_entities'] = train_sentiment_description['sentiment_entities'].apply(lambda x: ' '.join(x))\n\nprefix = 'sentiment'\ntrain_sentiment_group = train_dfs_sentiment.drop(['sentiment_entities'], axis=1)\n\nfor i in train_sentiment_group.columns:\n    if 'PetID' not in i:\n        train_sentiment_group[i] = train_sentiment_group[i].astype(float)\ntrain_sentiment_group = train_sentiment_group.groupby(['PetID']).agg(aggregates)\ntrain_sentiment_group.columns = pd.Index(['{}_{}_{}'.format(prefix, c[0], c[1].upper()) for c in train_sentiment_group.columns.tolist()])\ntrain_sentiment_group = train_sentiment_group.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test\n\nprefix = 'metadata'\ntest_metadata_group = test_dfs_metadata.drop(['metadata_annots_top_description'], axis=1)\n\nfor i in test_metadata_group.columns:\n    if 'PetID' not in i:\n        test_metadata_group[i] = test_metadata_group[i].astype(float)\ntest_metadata_group = test_metadata_group.groupby(['PetID']).agg(aggregates)\ntest_metadata_group.columns = pd.Index(['{}_{}_{}'.format(prefix, c[0], c[1].upper()) for c in test_metadata_group.columns.tolist()])\ntest_metadata_group = test_metadata_group.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_sentiment_description = test_dfs_sentiment.groupby(['PetID'])['sentiment_entities'].unique()\ntest_sentiment_description = test_sentiment_description.reset_index()\ntest_sentiment_description['sentiment_entities'] = test_sentiment_description['sentiment_entities'].apply(lambda x: ' '.join(x))\n\nprefix = 'sentiment'\ntest_sentiment_group = test_dfs_sentiment.drop(['sentiment_entities'], axis=1)\n\nfor i in test_sentiment_group.columns:\n    if 'PetID' not in i:\n        test_sentiment_group[i] = test_sentiment_group[i].astype(float)\ntest_sentiment_group = test_sentiment_group.groupby(['PetID']).agg(aggregates)\ntest_sentiment_group.columns = pd.Index(['{}_{}_{}'.format(prefix, c[0], c[1].upper()) for c in test_sentiment_group.columns.tolist()])\ntest_sentiment_group = test_sentiment_group.reset_index()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Merge with base train/test DF"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train merge\ntrain_process = train.copy()\ntrain_process = train_process.merge(train_sentiment_group, how='left', on='PetID')\ntrain_process = train_process.merge(train_metadata_group, how='left', on='PetID')\n\n# Test merge\ntest_process = test.copy()\ntest_process = test_process.merge(test_sentiment_group, how='left', on='PetID')\ntest_process = test_process.merge(test_metadata_group, how='left', on='PetID')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_process.shape, test_process.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Breed Mapping\n\n# Train\n\ntrain_breed_main = train_process[['Breed1']].merge(breeds, how='left', left_on='Breed1', right_on='BreedID', suffixes=('', '_main_breed'))\ntrain_breed_main = train_breed_main.iloc[:, 2:]\ntrain_breed_main = train_breed_main.add_prefix('main_breed_')\n\ntrain_breed_second = train_process[['Breed2']].merge(breeds, how='left', left_on='Breed2', right_on='BreedID', suffixes=('', '_second_breed'))\ntrain_breed_second = train_breed_second.iloc[:, 2:]\ntrain_breed_second = train_breed_second.add_prefix('second_breed_')\n\ntrain_process = pd.concat([train_process, train_breed_main, train_breed_second], axis = 1)\n\n# Test\n\ntest_breed_main = test_process[['Breed1']].merge(breeds, how='left', left_on='Breed1', right_on='BreedID', suffixes=('', '_main_breed'))\ntest_breed_main = test_breed_main.iloc[:, 2:]\ntest_breed_main = test_breed_main.add_prefix('main_breed_')\n\ntest_breed_second = test_process[['Breed2']].merge(breeds, how='left', left_on='Breed2', right_on='BreedID', suffixes=('', '_second_breed'))\ntest_breed_second = test_breed_second.iloc[:, 2:]\ntest_breed_second = test_breed_second.add_prefix('second_breed_')\n\ntest_process = pd.concat([test_process, test_breed_main, test_breed_second], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_process.shape, test_process.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Concat Train & Test set\n\nX = pd.concat([train_process, test_process], ignore_index=True, sort=False)\nprint(X.shape)\nprint('NaN structure:\\n{}'.format(X.isnull().sum()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"column_types = X.dtypes\n\nint_cols = column_types[column_types == 'int']\nfloat_cols = column_types[column_types == 'float']\ncate_cols = column_types[column_types == 'object']\n\nprint('\\tinteger columns:\\n{}'.format(int_cols))\nprint('\\tfloat columns:\\n{}'.format(float_cols))\nprint('\\tcategorical columns:\\n{}'.format(cate_cols))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_new = X.copy()\n\ntext_columns = ['Description']\ncategorical_columns = ['main_breed_BreedName', 'second_breed_BreedName']\n\nto_drop_columns = ['PetID', 'Name', 'RescuerID']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Count RescuerID\nrescuer_count = X.groupby(['RescuerID'])['PetID'].count().reset_index()\nrescuer_count.columns = ['RescuerID', 'RescuerID_count']\n\n# Merge as another feature\nX_new = X_new.merge(rescuer_count, how='left', on='RescuerID')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# factorize categorical columns\nfor i in categorical_columns:\n    X_new.loc[:, i] = pd.factorize(X_new.loc[:, i])[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# subset text features\n\nX_text = X_new[text_columns]\n\nfor i in X_text.columns:\n    X_text.loc[:, i] = X_text.loc[:, i].fillna('<MISSING>')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_components = 5\ntext_features = []\n\n# Generate text features\n\nfor i in X_text.columns:\n    # initialize decomposition methods\n    \n    svd = TruncatedSVD(n_components=n_components, random_state=42)\n    nmf = NMF(n_components=n_components, random_state=42)\n    \n    tfidf_col = TfidfVectorizer().fit_transform(X_text.loc[:, i].values)\n    svd_col = svd.fit_transform(tfidf_col)\n    svd_col = pd.DataFrame(svd_col)\n    svd_col = svd_col.add_prefix('SVD_{}_'.format(i))\n    \n    nmf_col = nmf.fit_transform(tfidf_col)\n    nmf_col = pd.DataFrame(nmf_col)\n    nmf_col = nmf_col.add_prefix('NMF_{}_'.format(i))\n    \n    text_features.append(svd_col)\n    text_features.append(nmf_col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# combine all extracted features\ntext_features = pd.concat(text_features, axis=1)\n\n# Concatenate with main DF\nX_new = pd.concat([X_new, text_features], axis=1)\n\n# remove raw text columns\nX_new = X_new.drop(text_columns, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_new = X_new.drop(to_drop_columns, axis=1)\nX_new.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train / Test split"},{"metadata":{"trusted":true},"cell_type":"code","source":"# split into train & test again\nX_train = X_new.loc[np.isfinite(X_new.AdoptionSpeed), :]\nX_test = X_new.loc[~np.isfinite(X_new.AdoptionSpeed), :]\n\n# remove target value from test\nX_test = X_test.drop(['AdoptionSpeed'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('X_train shape: {}'.format(X_train.shape))\nprint('X_test shape: {}'.format(X_test.shape))\n\nassert X_train.shape[0] == train.shape[0]\nassert X_test.shape[0] == test.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check columns between the 2 DF train & test are the same\ntrain_cols = X_train.columns.tolist()\ntrain_cols.remove('AdoptionSpeed')\n\ntest_cols = X_test.columns.tolist()\n\nassert np.all(train_cols == test_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.select_dtypes(include=(np.number))","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"1QeM_Q0xCELK"},"cell_type":"markdown","source":"**Model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# The following 3 functions have been taken from Ben Hamner's github repository\n# https://github.com/benhamner/Metrics\ndef confusion_matrix(rater_a, rater_b, min_rating=None, max_rating=None):\n    \"\"\"\n    Returns the confusion matrix between rater's ratings\n    \"\"\"\n    assert(len(rater_a) == len(rater_b))\n    if min_rating is None:\n        min_rating = min(rater_a + rater_b)\n    if max_rating is None:\n        max_rating = max(rater_a + rater_b)\n    num_ratings = int(max_rating - min_rating + 1)\n    conf_mat = [[0 for i in range(num_ratings)]\n                for j in range(num_ratings)]\n    for a, b in zip(rater_a, rater_b):\n        conf_mat[a - min_rating][b - min_rating] += 1\n    return conf_mat\n\n\ndef histogram(ratings, min_rating=None, max_rating=None):\n    \"\"\"\n    Returns the counts of each type of rating that a rater made\n    \"\"\"\n    if min_rating is None:\n        min_rating = min(ratings)\n    if max_rating is None:\n        max_rating = max(ratings)\n    num_ratings = int(max_rating - min_rating + 1)\n    hist_ratings = [0 for x in range(num_ratings)]\n    for r in ratings:\n        hist_ratings[r - min_rating] += 1\n    return hist_ratings\n\n\ndef quadratic_weighted_kappa(y, y_pred):\n    \"\"\"\n    Calculates the quadratic weighted kappa\n    axquadratic_weighted_kappa calculates the quadratic weighted kappa\n    value, which is a measure of inter-rater agreement between two raters\n    that provide discrete numeric ratings.  Potential values range from -1\n    (representing complete disagreement) to 1 (representing complete\n    agreement).  A kappa value of 0 is expected if all agreement is due to\n    chance.\n    quadratic_weighted_kappa(rater_a, rater_b), where rater_a and rater_b\n    each correspond to a list of integer ratings.  These lists must have the\n    same length.\n    The ratings should be integers, and it is assumed that they contain\n    the complete range of possible ratings.\n    quadratic_weighted_kappa(X, min_rating, max_rating), where min_rating\n    is the minimum possible rating, and max_rating is the maximum possible\n    rating\n    \"\"\"\n    rater_a = y\n    rater_b = y_pred\n    min_rating=None\n    max_rating=None\n    rater_a = np.array(rater_a, dtype=int)\n    rater_b = np.array(rater_b, dtype=int)\n    assert(len(rater_a) == len(rater_b))\n    if min_rating is None:\n        min_rating = min(min(rater_a), min(rater_b))\n    if max_rating is None:\n        max_rating = max(max(rater_a), max(rater_b))\n    conf_mat = confusion_matrix(rater_a, rater_b,\n                                min_rating, max_rating)\n    num_ratings = len(conf_mat)\n    num_scored_items = float(len(rater_a))\n\n    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n\n    numerator = 0.0\n    denominator = 0.0\n\n    for i in range(num_ratings):\n        for j in range(num_ratings):\n            expected_count = (hist_rater_a[i] * hist_rater_b[j]\n                              / num_scored_items)\n            d = pow(i - j, 2.0) / pow(num_ratings - 1, 2.0)\n            numerator += d * conf_mat[i][j] / num_scored_items\n            denominator += d * expected_count / num_scored_items\n\n    return (1.0 - numerator / denominator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class OptimizedRounder(object):\n    def __init__(self):\n        self.coef_ = 0\n\n    def _kappa_loss(self, coef, X, y):\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            elif pred >= coef[2] and pred < coef[3]:\n                X_p[i] = 3\n            else:\n                X_p[i] = 4\n\n        ll = quadratic_weighted_kappa(y, X_p)\n        return -ll\n\n    def fit(self, X, y):\n        loss_partial = partial(self._kappa_loss, X=X, y=y)\n        initial_coef = [0.5, 1.5, 2.5, 3.5]\n        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n\n    def predict(self, X, coef):\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            elif pred >= coef[2] and pred < coef[3]:\n                X_p[i] = 3\n            else:\n                X_p[i] = 4\n        return X_p\n\n    def coefficients(self):\n        return self.coef_['x']\n    \ndef rmse(actual, predicted):\n    return sqrt(mean_squared_error(actual, predicted))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\n\nparama = {'application': 'regression',\n         'boosting': 'gbdt',\n         'metric': 'rmse',\n         'num_leaves': 70,\n         'max_depth': 9,\n         'learning_rate': 0.01,\n         'bagging_fraction': 0.85,\n         'feature_fraction': 0.8,\n         'min_split_gain': 0.02,\n         'min_child_samples': 150,\n         'min_child_weight': 0.02,\n         'lambda_12': 0.0465,\n         'verboaity': -1,\n         'data_random_seed': 17}\n\nearly_stop = 500\nverbose_eval = 100\nnum_rounds = 10000\nn_splits = 5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\n\nkfold = StratifiedKFold(n_splits=n_splits, random_state=42)\n\noof_train = np.zeros((X_train.shape[0]))\noof_test = np.zeros((X_test.shape[0], n_splits))\n\ni = 0\nfor train_index, val_index in kfold.split(X_train, X_train['AdoptionSpeed'].values):\n    \n    X_tr = X_train.iloc[train_index, :]\n    X_val = X_train.iloc[val_index, :]\n    \n    y_tr = X_tr['AdoptionSpeed'].values\n    y_val = X_val['AdoptionSpeed'].values\n    \n    X_tr = X_tr.drop(['AdoptionSpeed'], axis=1)\n    X_val = X_val.drop(['AdoptionSpeed'], axis=1)\n    \n    print('\\ny_train distribution: {}'.format(Counter(y_tr)))\n    \n    d_train = lgb.Dataset(X_tr, label=y_tr)\n    d_val = lgb.Dataset(X_val, label=y_val)\n    watchlist = [d_train, d_val]\n    \n    print('training LGB:')\n    model = lgb.train(parama,\n                      train_set=d_train,\n                      num_boost_round=num_rounds,\n                      valid_sets=watchlist,\n                      verbose_eval=verbose_eval,\n                      early_stopping_rounds=early_stop)\n    \n    val_pred = model.predict(X_val, num_iteration=model.best_iteration)\n    test_pred = model.predict(X_test, num_iteration=model.best_iteration)\n    \n    oof_train[val_index] = val_pred\n    oof_test[:, i] = test_pred\n    \n    i += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(oof_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optR = OptimizedRounder()\noptR.fit(oof_train, X_train['AdoptionSpeed'].values)\ncoefficients = optR.coefficients()\npred_test_y_k = optR.predict(oof_train, coefficients)\nprint('\\nValid Counts = ', Counter(X_train['AdoptionSpeed'].values))\nprint('Predicted Counts = ', Counter(pred_test_y_k))\nprint('Coefficients = ', coefficients)\nqwk = quadratic_weighted_kappa(X_train['AdoptionSpeed'].values, pred_test_y_k)\nprint('QWK = ', qwk)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"coefficients_ = coefficients.copy()\n\ncoefficients_[0] = 1.645\ncoefficients_[1] = 2.115\ncoefficients_[3] = 2.84\n\ntrain_predictions = optR.predict(oof_train, coefficients_).astype(int)\nprint('train pred distribution: {}'.format(Counter(train_predictions)))\n\ntest_predictions = optR.predict(oof_test.mean(axis=1), coefficients_)\nprint('test pred distribution: {}'.format(Counter(test_predictions)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('True Distribution:')\nprint(pd.value_counts(X_train['AdoptionSpeed'], normalize=True).sort_index())\nprint('\\nTrain Predicted Distribution:')\nprint(pd.value_counts(train_predictions, normalize=True).sort_index())\nprint('\\nTest Predicted Distribution:')\nprint(pd.value_counts(test_predictions, normalize=True).sort_index())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({'PetID': test['PetID'].values, 'AdoptionSpeed': test_predictions.astype(np.int32)})\nsubmission.head()\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(submission)","execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Pet Finder","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":1}