{"cells":[{"metadata":{"_uuid":"efc8f31b8f57b14c535dabe6a9ddb1f7423e6065"},"cell_type":"markdown","source":"## Libraries"},{"metadata":{"trusted":true,"_uuid":"1223e84fee63f03f38138cc256ada0b6e76032ad"},"cell_type":"code","source":"import os\nimport cv2\nimport json\nimport pickle\nimport random\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nimport xgboost as xgb\nimport lightgbm as lgb\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.utils.data as data\n\nimport torchvision.models as models\nimport torchvision.transforms as transforms\n\nfrom pathlib import Path\nfrom datetime import datetime as dt\nfrom functools import partial\nfrom collections import Counter, defaultdict\n\nfrom PIL import Image\n\nfrom joblib import Parallel, delayed\n\nfrom sklearn.model_selection import StratifiedKFold, KFold, GroupKFold\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.metrics import cohen_kappa_score\nfrom sklearn.preprocessing import StandardScaler\n\nfrom tqdm import tqdm\nfrom fastprogress import master_bar, progress_bar\n\npd.options.display.max_columns = 128\ntorch.multiprocessing.set_start_method(\"spawn\")","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"fdd9dd8f815b98f600c7e65668b12ff5b321799f"},"cell_type":"markdown","source":"## Data Loading"},{"metadata":{"trusted":true,"_uuid":"31dd1db3ae9a48171c45d2b74bedf81a176fcb8c"},"cell_type":"code","source":"input_dir = Path(\"../input/petfinder-adoption-prediction/\")\ntrain = pd.read_csv(input_dir / \"train/train.csv\")\ntest = pd.read_csv(input_dir / \"test/test.csv\")\nsample_submission = pd.read_csv(input_dir / \"test/sample_submission.csv\")\n\ntrain_pet_ids = train.PetID.unique()\ntest_pet_ids = test.PetID.unique()","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.PhotoAmt.mean(), test.PhotoAmt.mean()","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"(3.889214966984593, 3.8095238095238093)"},"metadata":{}}]},{"metadata":{"_uuid":"15150b4893d23dd21cafa51d889713e4c50a1d1f"},"cell_type":"markdown","source":"## Image model loading"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!cp ../input/pytorch-pretrained-image-models/* ./\n!ls ","execution_count":4,"outputs":[{"output_type":"stream","text":"__notebook_source__.ipynb  densenet201.pth  resnet50.pth\r\ndensenet121.pth\t\t   resnet34.pth\r\n","name":"stdout"}]},{"metadata":{"_uuid":"a04adc838cfa9aa01f74052dc8eb9ea29af59406"},"cell_type":"markdown","source":"## Metadata and Sentiment data"},{"metadata":{"trusted":true,"_uuid":"64d5f41ce9fbcf68d024e396f7b6e7b5c733fc45"},"cell_type":"code","source":"def jopen(path):\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        json_file = json.load(f)\n    return json_file\n\n\ndef parse_sentiment_file(path):\n    file = jopen(path)\n    language: str = file[\"language\"]\n\n    sentiment: list = file[\"documentSentiment\"]\n    entities: list = [x[\"name\"] for x in file[\"entities\"]]\n    entity = \" \".join(entities)\n\n    sentence_sentiment: list = [x[\"sentiment\"] for x in file[\"sentences\"]]\n    magnitude: np.ndarray = np.array(\n        [x[\"magnitude\"] for x in sentence_sentiment])\n    score: np.ndarray = np.array([x[\"score\"] for x in sentence_sentiment])\n\n    return_js = {\n        \"magnitude_sum\": magnitude.sum(),\n        \"magnitude_mean\": magnitude.mean(),\n        \"magnitude_var\": magnitude.var(),\n        \"score_sum\": score.sum(),\n        \"score_mean\": score.mean(),\n        \"score_var\": score.var(),\n        \"language\": language,\n        \"entity\": entity,\n        \"document_magnitude\": sentiment[\"magnitude\"],\n        \"document_score\": sentiment[\"score\"]\n    }\n    return return_js\n\n\ndef parse_metadata(path):\n    file: dict = jopen(path)\n    file_keys = list(file.keys())\n    name_specified = 0\n    if \"labelAnnotations\" in file_keys:\n        file_annots = file[\"labelAnnotations\"]\n        file_mean_score = np.asarray([x[\"score\"] for x in file_annots]).mean()\n        file_desc = \" \".join([x[\"description\"] for x in file_annots])\n        if \"cat\" in file_desc or \"dog\" in file_desc:\n            name_specified = 1\n    else:\n        file_mean_score = np.nan\n        file_desc = \"\"\n\n    file_colors: list = file[\"imagePropertiesAnnotation\"][\"dominantColors\"][\n        \"colors\"]\n    file_crops: list = file[\"cropHintsAnnotation\"][\"cropHints\"]\n\n    color_score = np.asarray([x[\"score\"] for x in file_colors]).mean()\n    pixel_frac = np.asarray([x[\"pixelFraction\"] for x in file_colors]).mean()\n    crop_conf = np.asarray([x[\"confidence\"] for x in file_crops]).mean()\n\n    if \"importanceFraction\" in file_crops[0].keys():\n        crop_importance = np.asarray(\n            [x[\"importanceFraction\"] for x in file_crops]).mean()\n    else:\n        crop_importance = np.nan\n    metadata = {\n        \"annot_score\": file_mean_score,\n        \"color_score\": color_score,\n        \"pixel_frac\": pixel_frac,\n        \"crop_conf\": crop_conf,\n        \"crop_importance\": crop_importance,\n        \"desc\": file_desc,\n        \"specified\": name_specified\n    }\n    return metadata\n\n\ndef additinal_features_per_id(pet_id, sentiment_path: Path, meta_path: Path):\n    sentiment_path = sentiment_path / f\"{pet_id}.json\"\n    try:\n        sentiment = parse_sentiment_file(sentiment_path)\n        sentiment[\"pet_id\"] = pet_id\n    except FileNotFoundError:\n        sentiment = {}\n\n    meta_files = sorted(meta_path.glob(f\"{pet_id}*.json\"))\n    metadata_list = []\n    if len(meta_files) > 0:\n        for f in meta_files:\n            metadata = parse_metadata(f)\n            metadata[\"pet_id\"] = pet_id\n            metadata_list.append(metadata)\n    return sentiment, metadata_list\n\n\ndef load_additional_features(ped_ids: list, sentiment_path: Path,\n                             meta_path: Path):\n    features = Parallel(\n        n_jobs=-1, verbose=1)(\n            delayed(additinal_features_per_id)(i, sentiment_path, meta_path)\n            for i in ped_ids)\n    sentiments = [x[0] for x in features if len(x[0]) > 0]\n    metadatas = [x[1] for x in features if len(x[1]) > 0]\n    sentiment_keys = sentiments[0].keys()\n    metadata_keys = metadatas[0][0].keys()\n    sentiment_dict = {}\n    metadata_dict = {}\n    for key in sentiment_keys:\n        sentiment_dict[key] = [x[key] for x in sentiments]\n\n    for key in metadata_keys:\n        meta_list = []\n        for meta_per_pid in metadatas:\n            meta_list += [meta[key] for meta in meta_per_pid]\n        metadata_dict[key] = meta_list\n\n    sentiment_df = pd.DataFrame(sentiment_dict)\n    metadata_df = pd.DataFrame(metadata_dict)\n    return sentiment_df, metadata_df\n\n\ndef aggregate_metadata(metadata_df: pd.DataFrame,\n                       aggregates=[\"sum\", \"mean\", \"var\"]):\n    meta_desc: pd.DataFrame = metadata_df.groupby([\"pet_id\"])[\"desc\"].unique()\n    meta_desc = meta_desc.reset_index()\n    meta_desc[\"desc\"] = meta_desc[\"desc\"].apply(lambda x: \" \".join(x))\n\n    meta_gr: pd.DataFrame = metadata_df.drop([\"desc\"], axis=1)\n    for i in meta_gr.columns:\n        if \"pet_id\" not in i:\n            meta_gr[i] = meta_gr[i].astype(float)\n    meta_gr = meta_gr.groupby([\"pet_id\"]).agg(aggregates)\n    meta_gr.columns = pd.Index(\n        [f\"{c[0]}_{c[1].upper()}\" for c in meta_gr.columns.tolist()])\n    meta_gr = meta_gr.reset_index()\n    return meta_gr, meta_desc\n\n\ndef aggregate_sentiment(sentiment_df: pd.DataFrame, aggregates=[\"sum\"]):\n    sentiment_desc: pd.DataFrame = sentiment_df.groupby(\n        [\"pet_id\"])[\"entity\"].unique()\n    sentiment_desc = sentiment_desc.reset_index()\n    sentiment_desc[\"entity\"] = sentiment_desc[\"entity\"].apply(\n        lambda x: \" \".join(x))\n    sentiment_lang = sentiment_df.groupby(\n        [\"pet_id\"])[\"language\"].unique()\n    sentiment_lang = sentiment_lang.reset_index()\n    sentiment_lang[\"language\"] = sentiment_lang[\"language\"].apply(\n        lambda x: \" \".join(x))\n    sentiment_desc = sentiment_desc.merge(\n        sentiment_lang, how=\"left\", on=\"pet_id\")\n    \n\n    sentiment_gr: pd.DataFrame = sentiment_df.drop([\"entity\", \"language\"],\n                                                   axis=1)\n    for i in sentiment_gr.columns:\n        if \"pet_id\" not in i:\n            sentiment_gr[i] = sentiment_gr[i].astype(float)\n    sentiment_gr = sentiment_gr.groupby([\"pet_id\"]).agg(aggregates)\n    sentiment_gr.columns = pd.Index(\n        [f\"{c[0]}\" for c in sentiment_gr.columns.tolist()])\n    sentiment_gr = sentiment_gr.reset_index()\n    return sentiment_gr, sentiment_desc","execution_count":5,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"## Load data"},{"metadata":{"trusted":true,"_uuid":"a2a404fac56478b68955bfb8f2ab4cd17a34d5cb"},"cell_type":"code","source":"input_dir = Path(\"../input/petfinder-adoption-prediction/\")\ntrain = pd.read_csv(input_dir / \"train/train.csv\")\ntest = pd.read_csv(input_dir / \"test/test.csv\")\nsample_submission = pd.read_csv(input_dir / \"test/sample_submission.csv\")","execution_count":6,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5bd906850dc0ed9476140b7fa0835bcef8c57b64"},"cell_type":"code","source":"sp_train = input_dir / Path(\"train_sentiment/\")\nmp_train = input_dir / Path(\"train_metadata/\")\nsp_test = input_dir / Path(\"test_sentiment/\")\nmp_test = input_dir / Path(\"test_metadata/\")","execution_count":7,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5a60150bcae8f4bef0ad91c425ecc41e1f97b02d"},"cell_type":"code","source":"train_pet_ids = train.PetID.unique()\ntest_pet_ids = test.PetID.unique()","execution_count":8,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"80ea8fba883636520ffc0e200278a5097ca20ee6"},"cell_type":"code","source":"train_sentiment_df, train_metadata_df = load_additional_features(\n    train_pet_ids, sp_train, mp_train)\n\ntest_sentiment_df, test_metadata_df = load_additional_features(\n    test_pet_ids, sp_test, mp_test)","execution_count":9,"outputs":[{"output_type":"stream","text":"[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    6.2s\n[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:   15.4s\n[Parallel(n_jobs=-1)]: Done 446 tasks      | elapsed:   30.8s\n[Parallel(n_jobs=-1)]: Done 796 tasks      | elapsed:   52.3s\n[Parallel(n_jobs=-1)]: Done 1246 tasks      | elapsed:  1.4min\n[Parallel(n_jobs=-1)]: Done 1796 tasks      | elapsed:  1.9min\n[Parallel(n_jobs=-1)]: Done 2446 tasks      | elapsed:  2.6min\n[Parallel(n_jobs=-1)]: Done 3196 tasks      | elapsed:  3.4min\n[Parallel(n_jobs=-1)]: Done 4046 tasks      | elapsed:  4.3min\n[Parallel(n_jobs=-1)]: Done 4996 tasks      | elapsed:  5.3min\n[Parallel(n_jobs=-1)]: Done 6046 tasks      | elapsed:  6.3min\n[Parallel(n_jobs=-1)]: Done 7196 tasks      | elapsed:  7.5min\n[Parallel(n_jobs=-1)]: Done 8446 tasks      | elapsed:  8.8min\n[Parallel(n_jobs=-1)]: Done 9796 tasks      | elapsed: 10.2min\n[Parallel(n_jobs=-1)]: Done 11246 tasks      | elapsed: 11.7min\n[Parallel(n_jobs=-1)]: Done 12796 tasks      | elapsed: 13.3min\n[Parallel(n_jobs=-1)]: Done 14446 tasks      | elapsed: 15.0min\n[Parallel(n_jobs=-1)]: Done 14993 out of 14993 | elapsed: 15.5min finished\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n[Parallel(n_jobs=-1)]: Done 340 tasks      | elapsed:    5.2s\n[Parallel(n_jobs=-1)]: Done 1540 tasks      | elapsed:   25.4s\n[Parallel(n_jobs=-1)]: Done 3540 tasks      | elapsed:   55.4s\n[Parallel(n_jobs=-1)]: Done 3948 out of 3948 | elapsed:  1.0min finished\n","name":"stderr"}]},{"metadata":{"_uuid":"9e363a35cd0ef7aac5b7dabdd376478565bcaeea"},"cell_type":"markdown","source":"## Aggregate sentiment data and metadata"},{"metadata":{"trusted":true,"_uuid":"ddc55fc2f3b0ee50ff60d58908f9eb8d7fcad780"},"cell_type":"code","source":"train_meta_gr, train_meta_desc = aggregate_metadata(train_metadata_df)\ntest_meta_gr, test_meta_desc = aggregate_metadata(test_metadata_df)\ntrain_sentiment_gr, train_sentiment_desc = \\\n    aggregate_sentiment(train_sentiment_df)\ntest_sentiment_gr, test_sentiment_desc = \\\n    aggregate_sentiment(test_sentiment_df)","execution_count":10,"outputs":[]},{"metadata":{"_uuid":"2badeaca2206cdf6a224e7225385ef9440b8a3dd"},"cell_type":"markdown","source":"## Merge processed DataFrames with base train/test DataFrame"},{"metadata":{"trusted":true,"_uuid":"7c9807588b2fe960b1f96eeb07b908505dd9b3f0"},"cell_type":"code","source":"train_proc = train.copy()\ntrain_proc = train_proc.merge(\n    train_sentiment_gr, how=\"left\", left_on=\"PetID\", right_on=\"pet_id\")\ntrain_proc = train_proc.merge(\n    train_meta_gr, how=\"left\", left_on=\"PetID\", right_on=\"pet_id\")\ntrain_proc = train_proc.merge(\n    train_sentiment_desc, how=\"left\", left_on=\"PetID\", right_on=\"pet_id\")\ntrain_proc = train_proc.merge(\n    train_meta_desc, how=\"left\", left_on=\"PetID\", right_on = \"pet_id\")\n\ntest_proc = test.copy()\ntest_proc = test_proc.merge(\n    test_sentiment_gr, how=\"left\", left_on=\"PetID\", right_on=\"pet_id\")\ntest_proc = test_proc.merge(\n    test_meta_gr, how=\"left\", left_on=\"PetID\", right_on=\"pet_id\")\ntest_proc = test_proc.merge(\n    test_sentiment_desc, how=\"left\", left_on=\"PetID\", right_on=\"pet_id\")\ntest_proc = test_proc.merge(\n    test_meta_desc, how=\"left\", left_on=\"PetID\", right_on = \"pet_id\")","execution_count":11,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2468fdc9fe6a99059fc3ec87213638fcd843b4d8"},"cell_type":"code","source":"print(train_proc.shape, test_proc.shape)\nassert train_proc.shape[0] == train.shape[0]\nassert test_proc.shape[0] == test.shape[0]","execution_count":12,"outputs":[{"output_type":"stream","text":"(14993, 57) (3948, 56)\n","name":"stdout"}]},{"metadata":{"trusted":true,"_uuid":"5e5cbe9287fd8150b83a3044f6f5c344bd68ac72"},"cell_type":"code","source":"train_proc.drop(train_proc.filter(\n    regex=\"pet_id\", axis=1).columns.tolist(), \n    axis=1, \n    inplace=True)\n\ntest_proc.drop(test_proc.filter(\n    regex=\"pet_id\", axis=1).columns.tolist(),\n    axis=1,\n    inplace=True)\n\ntrain_proc.head()","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"   Type         Name  Age  Breed1  Breed2  Gender  Color1  Color2  Color3  \\\n0     2       Nibble    3     299       0       1       1       7       0   \n1     2  No Name Yet    1     265       0       1       1       2       0   \n2     1       Brisco    1     307       0       1       2       7       0   \n3     1         Miko    4     307       0       2       1       2       0   \n4     1       Hunter    1     307       0       1       1       0       0   \n\n   MaturitySize  FurLength  Vaccinated  Dewormed  Sterilized  Health  \\\n0             1          1           2         2           2       1   \n1             2          2           3         3           3       1   \n2             2          2           1         1           2       1   \n3             2          1           1         1           2       1   \n4             2          1           2         2           2       1   \n\n   Quantity  Fee  State                         RescuerID  VideoAmt  \\\n0         1  100  41326  8480853f516546f6cf33aa88cd76c379         0   \n1         1    0  41401  3082c7125d8fb66f7dd4bff4192c8b14         0   \n2         1    0  41326  fa90fa5b1ee11c86938398b60abc32cb         0   \n3         1  150  41401  9238e4f44c71a75282e62f7136c6b240         0   \n4         1    0  41326  95481e953f8aed9ec3d16fc4509537e8         0   \n\n                                         Description      PetID  PhotoAmt  \\\n0  Nibble is a 3+ month old ball of cuteness. He ...  86e1089a3       1.0   \n1  I just found it alone yesterday near my apartm...  6296e909a       2.0   \n2  Their pregnant mother was dumped by her irresp...  3422e4906       7.0   \n3  Good guard dog, very alert, active, obedience ...  5842f1ff5       8.0   \n4  This handsome yet cute boy is up for adoption....  850a43f90       3.0   \n\n   AdoptionSpeed  magnitude_sum  magnitude_mean  magnitude_var  score_sum  \\\n0              2            2.2        0.366667       0.102222        1.8   \n1              0            0.7        0.350000       0.062500       -0.5   \n2              3            3.4        0.485714       0.124082        1.4   \n3              2            0.9        0.900000       0.000000        0.9   \n4              2            3.5        0.583333       0.071389        3.5   \n\n   score_mean  score_var  document_magnitude  document_score  annot_score_SUM  \\\n0    0.300000   0.146667                 2.4             0.3         0.830798   \n1   -0.250000   0.122500                 0.7            -0.2         1.590916   \n2    0.200000   0.320000                 3.7             0.2         5.522756   \n3    0.900000   0.000000                 0.9             0.9         6.045986   \n4    0.583333   0.071389                 3.7             0.6         2.326006   \n\n   annot_score_MEAN  annot_score_VAR  color_score_SUM  color_score_MEAN  \\\n0          0.830798              NaN         0.074838          0.074838   \n1          0.795458         0.000119         0.183415          0.091708   \n2          0.788965         0.001047         0.660042          0.094292   \n3          0.755748         0.000221         0.660390          0.082549   \n4          0.775335         0.011257         0.239312          0.079771   \n\n   color_score_VAR  pixel_frac_SUM  pixel_frac_MEAN  pixel_frac_VAR  \\\n0              NaN        0.066331         0.066331             NaN   \n1         0.000038        0.127362         0.063681        0.000039   \n2         0.000041        0.514481         0.073497        0.000452   \n3         0.000278        0.548335         0.068542        0.000571   \n4         0.000075        0.128066         0.042689        0.000016   \n\n   crop_conf_SUM  crop_conf_MEAN  crop_conf_VAR  crop_importance_SUM  \\\n0            0.8             0.8            NaN                 1.00   \n1            1.6             0.8            0.0                 2.00   \n2            5.6             0.8            0.0                 7.00   \n3            6.4             0.8            0.0                 8.00   \n4            2.4             0.8            0.0                 2.98   \n\n   crop_importance_MEAN  crop_importance_VAR  specified_SUM  specified_MEAN  \\\n0              1.000000                  NaN            1.0             1.0   \n1              1.000000             0.000000            2.0             1.0   \n2              1.000000             0.000000            7.0             1.0   \n3              1.000000             0.000000            8.0             1.0   \n4              0.993333             0.000133            3.0             1.0   \n\n   specified_VAR                                             entity language  \\\n0            NaN  Nibble cuteness clinic cats result kitty coupl...       en   \n1            0.0                                     apartment care       en   \n2            0.0  mother owner puppies roadside shops Subang Jay...       en   \n3            0.0        guard dog master obedience call sms details       en   \n4            0.0  boy adoption Hunter pal puppies love age brat ...       en   \n\n                                                desc  \n0  cat black cat small to medium sized cats cat l...  \n1  cat whiskers small to medium sized cats fauna ...  \n2  dog dog like mammal dog breed dog breed group ...  \n3  dog dog like mammal dog breed dog breed group ...  \n4  dog dog like mammal dog breed puppy mammal dog...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Type</th>\n      <th>Name</th>\n      <th>Age</th>\n      <th>Breed1</th>\n      <th>Breed2</th>\n      <th>Gender</th>\n      <th>Color1</th>\n      <th>Color2</th>\n      <th>Color3</th>\n      <th>MaturitySize</th>\n      <th>FurLength</th>\n      <th>Vaccinated</th>\n      <th>Dewormed</th>\n      <th>Sterilized</th>\n      <th>Health</th>\n      <th>Quantity</th>\n      <th>Fee</th>\n      <th>State</th>\n      <th>RescuerID</th>\n      <th>VideoAmt</th>\n      <th>Description</th>\n      <th>PetID</th>\n      <th>PhotoAmt</th>\n      <th>AdoptionSpeed</th>\n      <th>magnitude_sum</th>\n      <th>magnitude_mean</th>\n      <th>magnitude_var</th>\n      <th>score_sum</th>\n      <th>score_mean</th>\n      <th>score_var</th>\n      <th>document_magnitude</th>\n      <th>document_score</th>\n      <th>annot_score_SUM</th>\n      <th>annot_score_MEAN</th>\n      <th>annot_score_VAR</th>\n      <th>color_score_SUM</th>\n      <th>color_score_MEAN</th>\n      <th>color_score_VAR</th>\n      <th>pixel_frac_SUM</th>\n      <th>pixel_frac_MEAN</th>\n      <th>pixel_frac_VAR</th>\n      <th>crop_conf_SUM</th>\n      <th>crop_conf_MEAN</th>\n      <th>crop_conf_VAR</th>\n      <th>crop_importance_SUM</th>\n      <th>crop_importance_MEAN</th>\n      <th>crop_importance_VAR</th>\n      <th>specified_SUM</th>\n      <th>specified_MEAN</th>\n      <th>specified_VAR</th>\n      <th>entity</th>\n      <th>language</th>\n      <th>desc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>Nibble</td>\n      <td>3</td>\n      <td>299</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>7</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>100</td>\n      <td>41326</td>\n      <td>8480853f516546f6cf33aa88cd76c379</td>\n      <td>0</td>\n      <td>Nibble is a 3+ month old ball of cuteness. He ...</td>\n      <td>86e1089a3</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>2.2</td>\n      <td>0.366667</td>\n      <td>0.102222</td>\n      <td>1.8</td>\n      <td>0.300000</td>\n      <td>0.146667</td>\n      <td>2.4</td>\n      <td>0.3</td>\n      <td>0.830798</td>\n      <td>0.830798</td>\n      <td>NaN</td>\n      <td>0.074838</td>\n      <td>0.074838</td>\n      <td>NaN</td>\n      <td>0.066331</td>\n      <td>0.066331</td>\n      <td>NaN</td>\n      <td>0.8</td>\n      <td>0.8</td>\n      <td>NaN</td>\n      <td>1.00</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>Nibble cuteness clinic cats result kitty coupl...</td>\n      <td>en</td>\n      <td>cat black cat small to medium sized cats cat l...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>No Name Yet</td>\n      <td>1</td>\n      <td>265</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>41401</td>\n      <td>3082c7125d8fb66f7dd4bff4192c8b14</td>\n      <td>0</td>\n      <td>I just found it alone yesterday near my apartm...</td>\n      <td>6296e909a</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0.7</td>\n      <td>0.350000</td>\n      <td>0.062500</td>\n      <td>-0.5</td>\n      <td>-0.250000</td>\n      <td>0.122500</td>\n      <td>0.7</td>\n      <td>-0.2</td>\n      <td>1.590916</td>\n      <td>0.795458</td>\n      <td>0.000119</td>\n      <td>0.183415</td>\n      <td>0.091708</td>\n      <td>0.000038</td>\n      <td>0.127362</td>\n      <td>0.063681</td>\n      <td>0.000039</td>\n      <td>1.6</td>\n      <td>0.8</td>\n      <td>0.0</td>\n      <td>2.00</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>apartment care</td>\n      <td>en</td>\n      <td>cat whiskers small to medium sized cats fauna ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>Brisco</td>\n      <td>1</td>\n      <td>307</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>7</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>41326</td>\n      <td>fa90fa5b1ee11c86938398b60abc32cb</td>\n      <td>0</td>\n      <td>Their pregnant mother was dumped by her irresp...</td>\n      <td>3422e4906</td>\n      <td>7.0</td>\n      <td>3</td>\n      <td>3.4</td>\n      <td>0.485714</td>\n      <td>0.124082</td>\n      <td>1.4</td>\n      <td>0.200000</td>\n      <td>0.320000</td>\n      <td>3.7</td>\n      <td>0.2</td>\n      <td>5.522756</td>\n      <td>0.788965</td>\n      <td>0.001047</td>\n      <td>0.660042</td>\n      <td>0.094292</td>\n      <td>0.000041</td>\n      <td>0.514481</td>\n      <td>0.073497</td>\n      <td>0.000452</td>\n      <td>5.6</td>\n      <td>0.8</td>\n      <td>0.0</td>\n      <td>7.00</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>7.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>mother owner puppies roadside shops Subang Jay...</td>\n      <td>en</td>\n      <td>dog dog like mammal dog breed dog breed group ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>Miko</td>\n      <td>4</td>\n      <td>307</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>150</td>\n      <td>41401</td>\n      <td>9238e4f44c71a75282e62f7136c6b240</td>\n      <td>0</td>\n      <td>Good guard dog, very alert, active, obedience ...</td>\n      <td>5842f1ff5</td>\n      <td>8.0</td>\n      <td>2</td>\n      <td>0.9</td>\n      <td>0.900000</td>\n      <td>0.000000</td>\n      <td>0.9</td>\n      <td>0.900000</td>\n      <td>0.000000</td>\n      <td>0.9</td>\n      <td>0.9</td>\n      <td>6.045986</td>\n      <td>0.755748</td>\n      <td>0.000221</td>\n      <td>0.660390</td>\n      <td>0.082549</td>\n      <td>0.000278</td>\n      <td>0.548335</td>\n      <td>0.068542</td>\n      <td>0.000571</td>\n      <td>6.4</td>\n      <td>0.8</td>\n      <td>0.0</td>\n      <td>8.00</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>guard dog master obedience call sms details</td>\n      <td>en</td>\n      <td>dog dog like mammal dog breed dog breed group ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>Hunter</td>\n      <td>1</td>\n      <td>307</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>41326</td>\n      <td>95481e953f8aed9ec3d16fc4509537e8</td>\n      <td>0</td>\n      <td>This handsome yet cute boy is up for adoption....</td>\n      <td>850a43f90</td>\n      <td>3.0</td>\n      <td>2</td>\n      <td>3.5</td>\n      <td>0.583333</td>\n      <td>0.071389</td>\n      <td>3.5</td>\n      <td>0.583333</td>\n      <td>0.071389</td>\n      <td>3.7</td>\n      <td>0.6</td>\n      <td>2.326006</td>\n      <td>0.775335</td>\n      <td>0.011257</td>\n      <td>0.239312</td>\n      <td>0.079771</td>\n      <td>0.000075</td>\n      <td>0.128066</td>\n      <td>0.042689</td>\n      <td>0.000016</td>\n      <td>2.4</td>\n      <td>0.8</td>\n      <td>0.0</td>\n      <td>2.98</td>\n      <td>0.993333</td>\n      <td>0.000133</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>boy adoption Hunter pal puppies love age brat ...</td>\n      <td>en</td>\n      <td>dog dog like mammal dog breed puppy mammal dog...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true,"_uuid":"a4d3c3cd67a16af0bcdea52392a1a107995cd0a2"},"cell_type":"code","source":"train_proc.language.fillna(\"\", inplace=True)\ntest_proc.language.fillna(\"\", inplace=True)\n\nlangs = train_proc.language.unique()\nencode_dict = {k: i for i, k in enumerate(langs)}\n\ntrain_proc.language = train_proc.language.map(encode_dict)\ntest_proc.language = test_proc.language.map(encode_dict)","execution_count":14,"outputs":[]},{"metadata":{"_uuid":"3ab3b3a25300ebc10720f61612358f52007caec0"},"cell_type":"markdown","source":"## Add Breed Mapping"},{"metadata":{"trusted":true,"_uuid":"6d6199ceadd4b7c2734ca0df0801338faefd64a4"},"cell_type":"code","source":"labels_breed = pd.read_csv(\"../input/petfinder-adoption-prediction/breed_labels.csv\")\nlabels_state = pd.read_csv(\"../input/petfinder-adoption-prediction/state_labels.csv\")\nlabels_color = pd.read_csv(\"../input/petfinder-adoption-prediction/color_labels.csv\")","execution_count":15,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c2193d9fb9f2e9eb2449c2dffd245227ab9d299a"},"cell_type":"code","source":"train_breed_main = train_proc[[\"Breed1\"]].merge(\n    labels_breed, how=\"left\",\n    left_on=\"Breed1\", right_on=\"BreedID\",\n    suffixes=(\"\", \"_main_breed\"))\ntrain_breed_main = train_breed_main.iloc[:, 2:]\ntrain_breed_main = train_breed_main.add_prefix(\"main_breed_\")\n\ntrain_breed_second = train_proc[[\"Breed2\"]].merge(\n    labels_breed, how=\"left\",\n    left_on=\"Breed2\", right_on=\"BreedID\",\n    suffixes=(\"\", \"_second_breed\"))\ntrain_breed_second = train_breed_second.iloc[:, 2:]\ntrain_breed_second = train_breed_second.add_prefix(\"second_breed_\")\n\ntrain_proc = pd.concat([\n    train_proc, train_breed_main, train_breed_second\n], axis=1)\n\ntest_breed_main = test_proc[[\"Breed1\"]].merge(\n    labels_breed, how=\"left\",\n    left_on=\"Breed1\", right_on=\"BreedID\",\n    suffixes=(\"\", \"_main_breed\"))\ntest_breed_main = test_breed_main.iloc[:, 2:]\ntest_breed_main = test_breed_main.add_prefix(\"main_breed_\")\n\ntest_breed_second = test_proc[[\"Breed2\"]].merge(\n    labels_breed, how=\"left\",\n    left_on=\"Breed2\", right_on=\"BreedID\",\n    suffixes=(\"\", \"_second_breed\"))\ntest_breed_second = test_breed_second.iloc[:, 2:]\ntest_breed_second = test_breed_second.add_prefix(\"second_breed_\")\n\ntest_proc = pd.concat([\n    test_proc, test_breed_main, test_breed_second\n], axis=1)\n\nprint(train_proc.shape, test_proc.shape)\ntrain_proc.head()","execution_count":16,"outputs":[{"output_type":"stream","text":"(14993, 57) (3948, 56)\n","name":"stdout"},{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"   Type         Name  Age  Breed1  Breed2  Gender  Color1  Color2  Color3  \\\n0     2       Nibble    3     299       0       1       1       7       0   \n1     2  No Name Yet    1     265       0       1       1       2       0   \n2     1       Brisco    1     307       0       1       2       7       0   \n3     1         Miko    4     307       0       2       1       2       0   \n4     1       Hunter    1     307       0       1       1       0       0   \n\n   MaturitySize  FurLength  Vaccinated  Dewormed  Sterilized  Health  \\\n0             1          1           2         2           2       1   \n1             2          2           3         3           3       1   \n2             2          2           1         1           2       1   \n3             2          1           1         1           2       1   \n4             2          1           2         2           2       1   \n\n   Quantity  Fee  State                         RescuerID  VideoAmt  \\\n0         1  100  41326  8480853f516546f6cf33aa88cd76c379         0   \n1         1    0  41401  3082c7125d8fb66f7dd4bff4192c8b14         0   \n2         1    0  41326  fa90fa5b1ee11c86938398b60abc32cb         0   \n3         1  150  41401  9238e4f44c71a75282e62f7136c6b240         0   \n4         1    0  41326  95481e953f8aed9ec3d16fc4509537e8         0   \n\n                                         Description      PetID  PhotoAmt  \\\n0  Nibble is a 3+ month old ball of cuteness. He ...  86e1089a3       1.0   \n1  I just found it alone yesterday near my apartm...  6296e909a       2.0   \n2  Their pregnant mother was dumped by her irresp...  3422e4906       7.0   \n3  Good guard dog, very alert, active, obedience ...  5842f1ff5       8.0   \n4  This handsome yet cute boy is up for adoption....  850a43f90       3.0   \n\n   AdoptionSpeed  magnitude_sum  magnitude_mean  magnitude_var  score_sum  \\\n0              2            2.2        0.366667       0.102222        1.8   \n1              0            0.7        0.350000       0.062500       -0.5   \n2              3            3.4        0.485714       0.124082        1.4   \n3              2            0.9        0.900000       0.000000        0.9   \n4              2            3.5        0.583333       0.071389        3.5   \n\n   score_mean  score_var  document_magnitude  document_score  annot_score_SUM  \\\n0    0.300000   0.146667                 2.4             0.3         0.830798   \n1   -0.250000   0.122500                 0.7            -0.2         1.590916   \n2    0.200000   0.320000                 3.7             0.2         5.522756   \n3    0.900000   0.000000                 0.9             0.9         6.045986   \n4    0.583333   0.071389                 3.7             0.6         2.326006   \n\n   annot_score_MEAN  annot_score_VAR  color_score_SUM  color_score_MEAN  \\\n0          0.830798              NaN         0.074838          0.074838   \n1          0.795458         0.000119         0.183415          0.091708   \n2          0.788965         0.001047         0.660042          0.094292   \n3          0.755748         0.000221         0.660390          0.082549   \n4          0.775335         0.011257         0.239312          0.079771   \n\n   color_score_VAR  pixel_frac_SUM  pixel_frac_MEAN  pixel_frac_VAR  \\\n0              NaN        0.066331         0.066331             NaN   \n1         0.000038        0.127362         0.063681        0.000039   \n2         0.000041        0.514481         0.073497        0.000452   \n3         0.000278        0.548335         0.068542        0.000571   \n4         0.000075        0.128066         0.042689        0.000016   \n\n   crop_conf_SUM  crop_conf_MEAN  crop_conf_VAR  crop_importance_SUM  \\\n0            0.8             0.8            NaN                 1.00   \n1            1.6             0.8            0.0                 2.00   \n2            5.6             0.8            0.0                 7.00   \n3            6.4             0.8            0.0                 8.00   \n4            2.4             0.8            0.0                 2.98   \n\n   crop_importance_MEAN  crop_importance_VAR  specified_SUM  specified_MEAN  \\\n0              1.000000                  NaN            1.0             1.0   \n1              1.000000             0.000000            2.0             1.0   \n2              1.000000             0.000000            7.0             1.0   \n3              1.000000             0.000000            8.0             1.0   \n4              0.993333             0.000133            3.0             1.0   \n\n   specified_VAR                                             entity  language  \\\n0            NaN  Nibble cuteness clinic cats result kitty coupl...         0   \n1            0.0                                     apartment care         0   \n2            0.0  mother owner puppies roadside shops Subang Jay...         0   \n3            0.0        guard dog master obedience call sms details         0   \n4            0.0  boy adoption Hunter pal puppies love age brat ...         0   \n\n                                                desc  main_breed_Type  \\\n0  cat black cat small to medium sized cats cat l...              2.0   \n1  cat whiskers small to medium sized cats fauna ...              2.0   \n2  dog dog like mammal dog breed dog breed group ...              1.0   \n3  dog dog like mammal dog breed dog breed group ...              1.0   \n4  dog dog like mammal dog breed puppy mammal dog...              1.0   \n\n   main_breed_BreedName  second_breed_Type second_breed_BreedName  \n0                 Tabby                NaN                    NaN  \n1  Domestic Medium Hair                NaN                    NaN  \n2           Mixed Breed                NaN                    NaN  \n3           Mixed Breed                NaN                    NaN  \n4           Mixed Breed                NaN                    NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Type</th>\n      <th>Name</th>\n      <th>Age</th>\n      <th>Breed1</th>\n      <th>Breed2</th>\n      <th>Gender</th>\n      <th>Color1</th>\n      <th>Color2</th>\n      <th>Color3</th>\n      <th>MaturitySize</th>\n      <th>FurLength</th>\n      <th>Vaccinated</th>\n      <th>Dewormed</th>\n      <th>Sterilized</th>\n      <th>Health</th>\n      <th>Quantity</th>\n      <th>Fee</th>\n      <th>State</th>\n      <th>RescuerID</th>\n      <th>VideoAmt</th>\n      <th>Description</th>\n      <th>PetID</th>\n      <th>PhotoAmt</th>\n      <th>AdoptionSpeed</th>\n      <th>magnitude_sum</th>\n      <th>magnitude_mean</th>\n      <th>magnitude_var</th>\n      <th>score_sum</th>\n      <th>score_mean</th>\n      <th>score_var</th>\n      <th>document_magnitude</th>\n      <th>document_score</th>\n      <th>annot_score_SUM</th>\n      <th>annot_score_MEAN</th>\n      <th>annot_score_VAR</th>\n      <th>color_score_SUM</th>\n      <th>color_score_MEAN</th>\n      <th>color_score_VAR</th>\n      <th>pixel_frac_SUM</th>\n      <th>pixel_frac_MEAN</th>\n      <th>pixel_frac_VAR</th>\n      <th>crop_conf_SUM</th>\n      <th>crop_conf_MEAN</th>\n      <th>crop_conf_VAR</th>\n      <th>crop_importance_SUM</th>\n      <th>crop_importance_MEAN</th>\n      <th>crop_importance_VAR</th>\n      <th>specified_SUM</th>\n      <th>specified_MEAN</th>\n      <th>specified_VAR</th>\n      <th>entity</th>\n      <th>language</th>\n      <th>desc</th>\n      <th>main_breed_Type</th>\n      <th>main_breed_BreedName</th>\n      <th>second_breed_Type</th>\n      <th>second_breed_BreedName</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>Nibble</td>\n      <td>3</td>\n      <td>299</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>7</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>100</td>\n      <td>41326</td>\n      <td>8480853f516546f6cf33aa88cd76c379</td>\n      <td>0</td>\n      <td>Nibble is a 3+ month old ball of cuteness. He ...</td>\n      <td>86e1089a3</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>2.2</td>\n      <td>0.366667</td>\n      <td>0.102222</td>\n      <td>1.8</td>\n      <td>0.300000</td>\n      <td>0.146667</td>\n      <td>2.4</td>\n      <td>0.3</td>\n      <td>0.830798</td>\n      <td>0.830798</td>\n      <td>NaN</td>\n      <td>0.074838</td>\n      <td>0.074838</td>\n      <td>NaN</td>\n      <td>0.066331</td>\n      <td>0.066331</td>\n      <td>NaN</td>\n      <td>0.8</td>\n      <td>0.8</td>\n      <td>NaN</td>\n      <td>1.00</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>Nibble cuteness clinic cats result kitty coupl...</td>\n      <td>0</td>\n      <td>cat black cat small to medium sized cats cat l...</td>\n      <td>2.0</td>\n      <td>Tabby</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>No Name Yet</td>\n      <td>1</td>\n      <td>265</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>41401</td>\n      <td>3082c7125d8fb66f7dd4bff4192c8b14</td>\n      <td>0</td>\n      <td>I just found it alone yesterday near my apartm...</td>\n      <td>6296e909a</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0.7</td>\n      <td>0.350000</td>\n      <td>0.062500</td>\n      <td>-0.5</td>\n      <td>-0.250000</td>\n      <td>0.122500</td>\n      <td>0.7</td>\n      <td>-0.2</td>\n      <td>1.590916</td>\n      <td>0.795458</td>\n      <td>0.000119</td>\n      <td>0.183415</td>\n      <td>0.091708</td>\n      <td>0.000038</td>\n      <td>0.127362</td>\n      <td>0.063681</td>\n      <td>0.000039</td>\n      <td>1.6</td>\n      <td>0.8</td>\n      <td>0.0</td>\n      <td>2.00</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>apartment care</td>\n      <td>0</td>\n      <td>cat whiskers small to medium sized cats fauna ...</td>\n      <td>2.0</td>\n      <td>Domestic Medium Hair</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>Brisco</td>\n      <td>1</td>\n      <td>307</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>7</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>41326</td>\n      <td>fa90fa5b1ee11c86938398b60abc32cb</td>\n      <td>0</td>\n      <td>Their pregnant mother was dumped by her irresp...</td>\n      <td>3422e4906</td>\n      <td>7.0</td>\n      <td>3</td>\n      <td>3.4</td>\n      <td>0.485714</td>\n      <td>0.124082</td>\n      <td>1.4</td>\n      <td>0.200000</td>\n      <td>0.320000</td>\n      <td>3.7</td>\n      <td>0.2</td>\n      <td>5.522756</td>\n      <td>0.788965</td>\n      <td>0.001047</td>\n      <td>0.660042</td>\n      <td>0.094292</td>\n      <td>0.000041</td>\n      <td>0.514481</td>\n      <td>0.073497</td>\n      <td>0.000452</td>\n      <td>5.6</td>\n      <td>0.8</td>\n      <td>0.0</td>\n      <td>7.00</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>7.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>mother owner puppies roadside shops Subang Jay...</td>\n      <td>0</td>\n      <td>dog dog like mammal dog breed dog breed group ...</td>\n      <td>1.0</td>\n      <td>Mixed Breed</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>Miko</td>\n      <td>4</td>\n      <td>307</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>150</td>\n      <td>41401</td>\n      <td>9238e4f44c71a75282e62f7136c6b240</td>\n      <td>0</td>\n      <td>Good guard dog, very alert, active, obedience ...</td>\n      <td>5842f1ff5</td>\n      <td>8.0</td>\n      <td>2</td>\n      <td>0.9</td>\n      <td>0.900000</td>\n      <td>0.000000</td>\n      <td>0.9</td>\n      <td>0.900000</td>\n      <td>0.000000</td>\n      <td>0.9</td>\n      <td>0.9</td>\n      <td>6.045986</td>\n      <td>0.755748</td>\n      <td>0.000221</td>\n      <td>0.660390</td>\n      <td>0.082549</td>\n      <td>0.000278</td>\n      <td>0.548335</td>\n      <td>0.068542</td>\n      <td>0.000571</td>\n      <td>6.4</td>\n      <td>0.8</td>\n      <td>0.0</td>\n      <td>8.00</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>guard dog master obedience call sms details</td>\n      <td>0</td>\n      <td>dog dog like mammal dog breed dog breed group ...</td>\n      <td>1.0</td>\n      <td>Mixed Breed</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>Hunter</td>\n      <td>1</td>\n      <td>307</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>41326</td>\n      <td>95481e953f8aed9ec3d16fc4509537e8</td>\n      <td>0</td>\n      <td>This handsome yet cute boy is up for adoption....</td>\n      <td>850a43f90</td>\n      <td>3.0</td>\n      <td>2</td>\n      <td>3.5</td>\n      <td>0.583333</td>\n      <td>0.071389</td>\n      <td>3.5</td>\n      <td>0.583333</td>\n      <td>0.071389</td>\n      <td>3.7</td>\n      <td>0.6</td>\n      <td>2.326006</td>\n      <td>0.775335</td>\n      <td>0.011257</td>\n      <td>0.239312</td>\n      <td>0.079771</td>\n      <td>0.000075</td>\n      <td>0.128066</td>\n      <td>0.042689</td>\n      <td>0.000016</td>\n      <td>2.4</td>\n      <td>0.8</td>\n      <td>0.0</td>\n      <td>2.98</td>\n      <td>0.993333</td>\n      <td>0.000133</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>boy adoption Hunter pal puppies love age brat ...</td>\n      <td>0</td>\n      <td>dog dog like mammal dog breed puppy mammal dog...</td>\n      <td>1.0</td>\n      <td>Mixed Breed</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"_uuid":"c492c2a290bb067d0dc656733054d0ae44ab73bf"},"cell_type":"markdown","source":"## Feature engineering"},{"metadata":{"trusted":true,"_uuid":"ce8d622672d743f5e746549d3ac85478f21c0d31"},"cell_type":"code","source":"X = pd.concat([train_proc, test_proc], ignore_index=True, sort=False)\nX_temp = X.copy()\n\ntext_columns = [\n    \"Description\",\n    \"entity\",\n    \"desc\"]\ncategorical_columns = [\n    \"Type\", \"Breed1\", \"Breed2\", \"Gender\",\n    \"Color1\", \"Color2\", \"Color3\", \"MaturitySize\",\n    \"FurLength\", \"Vaccinated\", \"Dewormed\", \"Sterilized\",\n    \"State\", \"language\", \"main_breed_BreedName\", \"second_breed_BreedName\"\n]\ncat_c = [\"main_breed_BreedName\", \"second_breed_BreedName\"]\ndrop_columns = [\n    \"PetID\", \"Name\", \"RescuerID\"\n]","execution_count":17,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8f85feb5de68ba8edb643319f2f3d652d1ebfa1f"},"cell_type":"code","source":"for i in cat_c:\n    X_temp.loc[:, i] = pd.factorize(X_temp.loc[:, i])[0]","execution_count":18,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c65e045184826428d9074a13caa185ffd8793999"},"cell_type":"code","source":"X_text = X_temp[text_columns]\nfor i in X_text.columns:\n    X_text[i] = X_text[i].fillna(\"none\")","execution_count":19,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  This is separate from the ipykernel package so we can avoid doing imports until\n","name":"stderr"}]},{"metadata":{"trusted":true,"_uuid":"000e0e05491ac479349ffe40d8146f912d00c1d5"},"cell_type":"code","source":"X_temp[\"len_description\"] = X_text[\"Description\"].map(len)\nX_temp[\"len_meta_desc\"] = X_text[\"desc\"].map(len)\nX_temp[\"len_entity\"] = X_text[\"entity\"].map(len)","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\n\nfrom nltk.corpus import stopwords\nimport spacy\nfrom spacy.lang.en.stop_words import STOP_WORDS\nfrom spacy.lang.en import English\nfrom nltk.tokenize import RegexpTokenizer\nimport nltk.stem as stm\nfrom nltk import WordNetLemmatizer, word_tokenize\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n\npuncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n\ndef clean_text(x):\n    x = str(x)\n    for punct in puncts:\n        x = x.replace(punct, f' {punct} ')\n    return x\n\ndef clean_numbers(x):\n    x = re.sub('[0-9]{5,}', '#####', x)\n    x = re.sub('[0-9]{4}', '####', x)\n    x = re.sub('[0-9]{3}', '###', x)\n    x = re.sub('[0-9]{2}', '##', x)\n    return x\n\nmispell_dict = {\"aren't\" : \"are not\",\n\"can't\" : \"cannot\",\n\"couldn't\" : \"could not\",\n\"didn't\" : \"did not\",\n\"doesn't\" : \"does not\",\n\"don't\" : \"do not\",\n\"hadn't\" : \"had not\",\n\"hasn't\" : \"has not\",\n\"haven't\" : \"have not\",\n\"he'd\" : \"he would\",\n\"he'll\" : \"he will\",\n\"he's\" : \"he is\",\n\"i'd\" : \"I would\",\n\"i'd\" : \"I had\",\n\"i'll\" : \"I will\",\n\"i'm\" : \"I am\",\n\"isn't\" : \"is not\",\n\"it's\" : \"it is\",\n\"it'll\":\"it will\",\n\"i've\" : \"I have\",\n\"let's\" : \"let us\",\n\"mightn't\" : \"might not\",\n\"mustn't\" : \"must not\",\n\"shan't\" : \"shall not\",\n\"she'd\" : \"she would\",\n\"she'll\" : \"she will\",\n\"she's\" : \"she is\",\n\"shouldn't\" : \"should not\",\n\"that's\" : \"that is\",\n\"there's\" : \"there is\",\n\"they'd\" : \"they would\",\n\"they'll\" : \"they will\",\n\"they're\" : \"they are\",\n\"they've\" : \"they have\",\n\"we'd\" : \"we would\",\n\"we're\" : \"we are\",\n\"weren't\" : \"were not\",\n\"we've\" : \"we have\",\n\"what'll\" : \"what will\",\n\"what're\" : \"what are\",\n\"what's\" : \"what is\",\n\"what've\" : \"what have\",\n\"where's\" : \"where is\",\n\"who'd\" : \"who would\",\n\"who'll\" : \"who will\",\n\"who're\" : \"who are\",\n\"who's\" : \"who is\",\n\"who've\" : \"who have\",\n\"won't\" : \"will not\",\n\"wouldn't\" : \"would not\",\n\"you'd\" : \"you would\",\n\"you'll\" : \"you will\",\n\"you're\" : \"you are\",\n\"you've\" : \"you have\",\n\"'re\": \" are\",\n\"wasn't\": \"was not\",\n\"we'll\":\" will\",\n\"didn't\": \"did not\",\n\"tryin'\":\"trying\"}\n\ndef _get_mispell(mispell_dict):\n    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n    return mispell_dict, mispell_re\n\nmispellings, mispellings_re = _get_mispell(mispell_dict)\ndef replace_typical_misspell(text):\n    def replace(match):\n        return mispellings[match.group(0)]\n    return mispellings_re.sub(replace, text)","execution_count":21,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_text[\"cleaned_text\"] = X_text[\"Description\"].map(lambda x: x.lower())\nX_text[\"cleaned_text\"] = X_text[\"cleaned_text\"].map(lambda x: clean_text(x))\nX_text[\"cleaned_text\"] = X_text[\"cleaned_text\"].map(lambda x: clean_numbers(x))\nX_text[\"cleaned_text\"] = X_text[\"cleaned_text\"].map(lambda x: replace_typical_misspell(x))","execution_count":22,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  \"\"\"Entry point for launching an IPython kernel.\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  \n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  This is separate from the ipykernel package so we can avoid doing imports until\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  after removing the cwd from sys.path.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"eng_stopwords = set(stopwords.words(\"english\"))\nimport string\n\nX_temp[\"len_description\"] = X_text[\"Description\"].map(len)\nX_temp[\"len_meta_desc\"] = X_text[\"desc\"].map(len)\nX_temp[\"len_entity\"] = X_text[\"entity\"].map(len)\n\nX_temp[\"num_description_words\"] = X_text[\"Description\"].map(lambda x: len(str(x).split()))\nX_temp[\"num_desc_words\"] = X_text[\"desc\"].map(lambda x: len(str(x).split()))\nX_temp[\"num_entity_words\"] = X_text[\"entity\"].map(lambda x: len(str(x).split()))\n\nX_temp[\"uniq_description_words\"] = X_text[\"Description\"].map(lambda x: len(set(str(x).split())))\nX_temp[\"uniq_desc_words\"] = X_text[\"desc\"].map(lambda x: len(set(str(x).split())))\nX_temp[\"uniq_entity_words\"] = X_text[\"entity\"].map(lambda x: len(set(str(x).split())))\n\nX_temp[\"num_description_stopwords\"] = X_text[\"Description\"].map(lambda x: len([\n    w for w in str(x).lower().split() if w in eng_stopwords]))\nX_temp[\"num_desc_stopwords\"] = X_text[\"desc\"].map(lambda x: len([\n    w for w in str(x).lower().split() if w in eng_stopwords]))\nX_temp[\"num_entity_stopwords\"] = X_text[\"entity\"].map(lambda x: len([\n    w for w in str(x).lower().split() if w in eng_stopwords]))\n\nX_temp[\"num_description_punctuation\"] = X_text[\"Description\"].map(lambda x: len([\n    c for c in str(x) if c in string.punctuation]))","execution_count":23,"outputs":[]},{"metadata":{"_uuid":"aa54bd185c17eb6a8006f97764a8d5e945642ca6"},"cell_type":"markdown","source":"### State stats"},{"metadata":{"trusted":true,"_uuid":"af908305a8452fc51a1019f2c80ad3ead58fb24e"},"cell_type":"code","source":"state_gdp = {\n    41336: 116.679,\n    41325: 40.596,\n    41367: 23.02,\n    41401: 190.075,\n    41415: 5.984,\n    41324: 37.274,\n    41332: 42.389,\n    41335: 52.452,\n    41330: 67.629,\n    41380: 5.642,\n    41327: 81.284,\n    41345: 80.167,\n    41342: 121.414,\n    41326: 280.698,\n    41361: 32.270\n}\n\nstate_population = {\n    41336: 33.48283,\n    41325: 19.47651,\n    41367: 15.39601,\n    41401: 16.74621,\n    41415: 0.86908,\n    41324: 8.21110,\n    41332: 10.21064,\n    41335: 15.00817,\n    41330: 23.52743,\n    41380: 2.31541,\n    41327: 15.61383,\n    41345: 32.06742,\n    41342: 24.71140,\n    41326: 54.62141,\n    41361: 10.35977\n}\n\nstate_area ={\n    41336:19102,\n    41325:9500,\n    41367:15099,\n    41401:243,\n    41415:91,\n    41324:1664,\n    41332:6686,\n    41335:36137,\n    41330:21035,\n    41380:821,\n    41327:1048,\n    41345:73631,\n    41342:124450,\n    41326:8104,\n    41361:13035\n}\nX_temp[\"state_gdp\"] = X_temp.State.map(state_gdp)\nX_temp[\"state_population\"] = X_temp.State.map(state_population)\nX_temp[\"state_area\"] = X_temp.State.map(state_area)\n\nX_temp[\"state_gdp_per_person\"] = X_temp[\"state_gdp\"] / X_temp[\"state_population\"] * 1e4\nX_temp[\"fee_per_gdp_per_person\"] = X_temp.Fee / X_temp[\"state_gdp_per_person\"]","execution_count":24,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dcf68f94944d5a105f30c3847f34fd36e1ad71fb"},"cell_type":"code","source":"X_temp.head()","execution_count":25,"outputs":[{"output_type":"execute_result","execution_count":25,"data":{"text/plain":"   Type         Name  Age  Breed1  Breed2  Gender  Color1  Color2  Color3  \\\n0     2       Nibble    3     299       0       1       1       7       0   \n1     2  No Name Yet    1     265       0       1       1       2       0   \n2     1       Brisco    1     307       0       1       2       7       0   \n3     1         Miko    4     307       0       2       1       2       0   \n4     1       Hunter    1     307       0       1       1       0       0   \n\n   MaturitySize  FurLength  Vaccinated  Dewormed  Sterilized  Health  \\\n0             1          1           2         2           2       1   \n1             2          2           3         3           3       1   \n2             2          2           1         1           2       1   \n3             2          1           1         1           2       1   \n4             2          1           2         2           2       1   \n\n   Quantity  Fee  State                         RescuerID  VideoAmt  \\\n0         1  100  41326  8480853f516546f6cf33aa88cd76c379         0   \n1         1    0  41401  3082c7125d8fb66f7dd4bff4192c8b14         0   \n2         1    0  41326  fa90fa5b1ee11c86938398b60abc32cb         0   \n3         1  150  41401  9238e4f44c71a75282e62f7136c6b240         0   \n4         1    0  41326  95481e953f8aed9ec3d16fc4509537e8         0   \n\n                                         Description      PetID  PhotoAmt  \\\n0  Nibble is a 3+ month old ball of cuteness. He ...  86e1089a3       1.0   \n1  I just found it alone yesterday near my apartm...  6296e909a       2.0   \n2  Their pregnant mother was dumped by her irresp...  3422e4906       7.0   \n3  Good guard dog, very alert, active, obedience ...  5842f1ff5       8.0   \n4  This handsome yet cute boy is up for adoption....  850a43f90       3.0   \n\n   AdoptionSpeed  magnitude_sum  magnitude_mean  magnitude_var  score_sum  \\\n0            2.0            2.2        0.366667       0.102222        1.8   \n1            0.0            0.7        0.350000       0.062500       -0.5   \n2            3.0            3.4        0.485714       0.124082        1.4   \n3            2.0            0.9        0.900000       0.000000        0.9   \n4            2.0            3.5        0.583333       0.071389        3.5   \n\n   score_mean  score_var  document_magnitude  document_score  annot_score_SUM  \\\n0    0.300000   0.146667                 2.4             0.3         0.830798   \n1   -0.250000   0.122500                 0.7            -0.2         1.590916   \n2    0.200000   0.320000                 3.7             0.2         5.522756   \n3    0.900000   0.000000                 0.9             0.9         6.045986   \n4    0.583333   0.071389                 3.7             0.6         2.326006   \n\n   annot_score_MEAN  annot_score_VAR  color_score_SUM  color_score_MEAN  \\\n0          0.830798              NaN         0.074838          0.074838   \n1          0.795458         0.000119         0.183415          0.091708   \n2          0.788965         0.001047         0.660042          0.094292   \n3          0.755748         0.000221         0.660390          0.082549   \n4          0.775335         0.011257         0.239312          0.079771   \n\n   color_score_VAR  pixel_frac_SUM  pixel_frac_MEAN  pixel_frac_VAR  \\\n0              NaN        0.066331         0.066331             NaN   \n1         0.000038        0.127362         0.063681        0.000039   \n2         0.000041        0.514481         0.073497        0.000452   \n3         0.000278        0.548335         0.068542        0.000571   \n4         0.000075        0.128066         0.042689        0.000016   \n\n   crop_conf_SUM  crop_conf_MEAN  crop_conf_VAR  crop_importance_SUM  \\\n0            0.8             0.8            NaN                 1.00   \n1            1.6             0.8            0.0                 2.00   \n2            5.6             0.8            0.0                 7.00   \n3            6.4             0.8            0.0                 8.00   \n4            2.4             0.8            0.0                 2.98   \n\n   crop_importance_MEAN  crop_importance_VAR  specified_SUM  specified_MEAN  \\\n0              1.000000                  NaN            1.0             1.0   \n1              1.000000             0.000000            2.0             1.0   \n2              1.000000             0.000000            7.0             1.0   \n3              1.000000             0.000000            8.0             1.0   \n4              0.993333             0.000133            3.0             1.0   \n\n   specified_VAR                                             entity  language  \\\n0            NaN  Nibble cuteness clinic cats result kitty coupl...         0   \n1            0.0                                     apartment care         0   \n2            0.0  mother owner puppies roadside shops Subang Jay...         0   \n3            0.0        guard dog master obedience call sms details         0   \n4            0.0  boy adoption Hunter pal puppies love age brat ...         0   \n\n                                                desc  main_breed_Type  \\\n0  cat black cat small to medium sized cats cat l...              2.0   \n1  cat whiskers small to medium sized cats fauna ...              2.0   \n2  dog dog like mammal dog breed dog breed group ...              1.0   \n3  dog dog like mammal dog breed dog breed group ...              1.0   \n4  dog dog like mammal dog breed puppy mammal dog...              1.0   \n\n   main_breed_BreedName  second_breed_Type  second_breed_BreedName  \\\n0                     0                NaN                      -1   \n1                     1                NaN                      -1   \n2                     2                NaN                      -1   \n3                     2                NaN                      -1   \n4                     2                NaN                      -1   \n\n   len_description  len_meta_desc  len_entity  num_description_words  \\\n0              359            111          86                     69   \n1              118            212          14                     23   \n2              393            855          98                     69   \n3              146            879          43                     25   \n4              390            312          77                     81   \n\n   num_desc_words  num_entity_words  uniq_description_words  uniq_desc_words  \\\n0              19                13                      57               16   \n1              37                 2                      20               21   \n2             135                15                      60               24   \n3             141                 7                      24               21   \n4              49                13                      65               19   \n\n   uniq_entity_words  num_description_stopwords  num_desc_stopwords  \\\n0                 12                         34                   1   \n1                  2                         12                   2   \n2                 14                         30                   0   \n3                  7                          8                   0   \n4                 13                         42                   0   \n\n   num_entity_stopwords  num_description_punctuation  state_gdp  \\\n0                     0                            8    280.698   \n1                     0                            2    190.075   \n2                     0                            9    280.698   \n3                     0                            7    190.075   \n4                     0                            9    280.698   \n\n   state_population  state_area  state_gdp_per_person  fee_per_gdp_per_person  \n0          54.62141        8104          51389.738932                0.001946  \n1          16.74621         243         113503.294178                0.000000  \n2          54.62141        8104          51389.738932                0.000000  \n3          16.74621         243         113503.294178                0.001322  \n4          54.62141        8104          51389.738932                0.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Type</th>\n      <th>Name</th>\n      <th>Age</th>\n      <th>Breed1</th>\n      <th>Breed2</th>\n      <th>Gender</th>\n      <th>Color1</th>\n      <th>Color2</th>\n      <th>Color3</th>\n      <th>MaturitySize</th>\n      <th>FurLength</th>\n      <th>Vaccinated</th>\n      <th>Dewormed</th>\n      <th>Sterilized</th>\n      <th>Health</th>\n      <th>Quantity</th>\n      <th>Fee</th>\n      <th>State</th>\n      <th>RescuerID</th>\n      <th>VideoAmt</th>\n      <th>Description</th>\n      <th>PetID</th>\n      <th>PhotoAmt</th>\n      <th>AdoptionSpeed</th>\n      <th>magnitude_sum</th>\n      <th>magnitude_mean</th>\n      <th>magnitude_var</th>\n      <th>score_sum</th>\n      <th>score_mean</th>\n      <th>score_var</th>\n      <th>document_magnitude</th>\n      <th>document_score</th>\n      <th>annot_score_SUM</th>\n      <th>annot_score_MEAN</th>\n      <th>annot_score_VAR</th>\n      <th>color_score_SUM</th>\n      <th>color_score_MEAN</th>\n      <th>color_score_VAR</th>\n      <th>pixel_frac_SUM</th>\n      <th>pixel_frac_MEAN</th>\n      <th>pixel_frac_VAR</th>\n      <th>crop_conf_SUM</th>\n      <th>crop_conf_MEAN</th>\n      <th>crop_conf_VAR</th>\n      <th>crop_importance_SUM</th>\n      <th>crop_importance_MEAN</th>\n      <th>crop_importance_VAR</th>\n      <th>specified_SUM</th>\n      <th>specified_MEAN</th>\n      <th>specified_VAR</th>\n      <th>entity</th>\n      <th>language</th>\n      <th>desc</th>\n      <th>main_breed_Type</th>\n      <th>main_breed_BreedName</th>\n      <th>second_breed_Type</th>\n      <th>second_breed_BreedName</th>\n      <th>len_description</th>\n      <th>len_meta_desc</th>\n      <th>len_entity</th>\n      <th>num_description_words</th>\n      <th>num_desc_words</th>\n      <th>num_entity_words</th>\n      <th>uniq_description_words</th>\n      <th>uniq_desc_words</th>\n      <th>uniq_entity_words</th>\n      <th>num_description_stopwords</th>\n      <th>num_desc_stopwords</th>\n      <th>num_entity_stopwords</th>\n      <th>num_description_punctuation</th>\n      <th>state_gdp</th>\n      <th>state_population</th>\n      <th>state_area</th>\n      <th>state_gdp_per_person</th>\n      <th>fee_per_gdp_per_person</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>Nibble</td>\n      <td>3</td>\n      <td>299</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>7</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>100</td>\n      <td>41326</td>\n      <td>8480853f516546f6cf33aa88cd76c379</td>\n      <td>0</td>\n      <td>Nibble is a 3+ month old ball of cuteness. He ...</td>\n      <td>86e1089a3</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.2</td>\n      <td>0.366667</td>\n      <td>0.102222</td>\n      <td>1.8</td>\n      <td>0.300000</td>\n      <td>0.146667</td>\n      <td>2.4</td>\n      <td>0.3</td>\n      <td>0.830798</td>\n      <td>0.830798</td>\n      <td>NaN</td>\n      <td>0.074838</td>\n      <td>0.074838</td>\n      <td>NaN</td>\n      <td>0.066331</td>\n      <td>0.066331</td>\n      <td>NaN</td>\n      <td>0.8</td>\n      <td>0.8</td>\n      <td>NaN</td>\n      <td>1.00</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>Nibble cuteness clinic cats result kitty coupl...</td>\n      <td>0</td>\n      <td>cat black cat small to medium sized cats cat l...</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>-1</td>\n      <td>359</td>\n      <td>111</td>\n      <td>86</td>\n      <td>69</td>\n      <td>19</td>\n      <td>13</td>\n      <td>57</td>\n      <td>16</td>\n      <td>12</td>\n      <td>34</td>\n      <td>1</td>\n      <td>0</td>\n      <td>8</td>\n      <td>280.698</td>\n      <td>54.62141</td>\n      <td>8104</td>\n      <td>51389.738932</td>\n      <td>0.001946</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>No Name Yet</td>\n      <td>1</td>\n      <td>265</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>41401</td>\n      <td>3082c7125d8fb66f7dd4bff4192c8b14</td>\n      <td>0</td>\n      <td>I just found it alone yesterday near my apartm...</td>\n      <td>6296e909a</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.7</td>\n      <td>0.350000</td>\n      <td>0.062500</td>\n      <td>-0.5</td>\n      <td>-0.250000</td>\n      <td>0.122500</td>\n      <td>0.7</td>\n      <td>-0.2</td>\n      <td>1.590916</td>\n      <td>0.795458</td>\n      <td>0.000119</td>\n      <td>0.183415</td>\n      <td>0.091708</td>\n      <td>0.000038</td>\n      <td>0.127362</td>\n      <td>0.063681</td>\n      <td>0.000039</td>\n      <td>1.6</td>\n      <td>0.8</td>\n      <td>0.0</td>\n      <td>2.00</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>apartment care</td>\n      <td>0</td>\n      <td>cat whiskers small to medium sized cats fauna ...</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>-1</td>\n      <td>118</td>\n      <td>212</td>\n      <td>14</td>\n      <td>23</td>\n      <td>37</td>\n      <td>2</td>\n      <td>20</td>\n      <td>21</td>\n      <td>2</td>\n      <td>12</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>190.075</td>\n      <td>16.74621</td>\n      <td>243</td>\n      <td>113503.294178</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>Brisco</td>\n      <td>1</td>\n      <td>307</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>7</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>41326</td>\n      <td>fa90fa5b1ee11c86938398b60abc32cb</td>\n      <td>0</td>\n      <td>Their pregnant mother was dumped by her irresp...</td>\n      <td>3422e4906</td>\n      <td>7.0</td>\n      <td>3.0</td>\n      <td>3.4</td>\n      <td>0.485714</td>\n      <td>0.124082</td>\n      <td>1.4</td>\n      <td>0.200000</td>\n      <td>0.320000</td>\n      <td>3.7</td>\n      <td>0.2</td>\n      <td>5.522756</td>\n      <td>0.788965</td>\n      <td>0.001047</td>\n      <td>0.660042</td>\n      <td>0.094292</td>\n      <td>0.000041</td>\n      <td>0.514481</td>\n      <td>0.073497</td>\n      <td>0.000452</td>\n      <td>5.6</td>\n      <td>0.8</td>\n      <td>0.0</td>\n      <td>7.00</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>7.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>mother owner puppies roadside shops Subang Jay...</td>\n      <td>0</td>\n      <td>dog dog like mammal dog breed dog breed group ...</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>-1</td>\n      <td>393</td>\n      <td>855</td>\n      <td>98</td>\n      <td>69</td>\n      <td>135</td>\n      <td>15</td>\n      <td>60</td>\n      <td>24</td>\n      <td>14</td>\n      <td>30</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>280.698</td>\n      <td>54.62141</td>\n      <td>8104</td>\n      <td>51389.738932</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>Miko</td>\n      <td>4</td>\n      <td>307</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>150</td>\n      <td>41401</td>\n      <td>9238e4f44c71a75282e62f7136c6b240</td>\n      <td>0</td>\n      <td>Good guard dog, very alert, active, obedience ...</td>\n      <td>5842f1ff5</td>\n      <td>8.0</td>\n      <td>2.0</td>\n      <td>0.9</td>\n      <td>0.900000</td>\n      <td>0.000000</td>\n      <td>0.9</td>\n      <td>0.900000</td>\n      <td>0.000000</td>\n      <td>0.9</td>\n      <td>0.9</td>\n      <td>6.045986</td>\n      <td>0.755748</td>\n      <td>0.000221</td>\n      <td>0.660390</td>\n      <td>0.082549</td>\n      <td>0.000278</td>\n      <td>0.548335</td>\n      <td>0.068542</td>\n      <td>0.000571</td>\n      <td>6.4</td>\n      <td>0.8</td>\n      <td>0.0</td>\n      <td>8.00</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>guard dog master obedience call sms details</td>\n      <td>0</td>\n      <td>dog dog like mammal dog breed dog breed group ...</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>-1</td>\n      <td>146</td>\n      <td>879</td>\n      <td>43</td>\n      <td>25</td>\n      <td>141</td>\n      <td>7</td>\n      <td>24</td>\n      <td>21</td>\n      <td>7</td>\n      <td>8</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7</td>\n      <td>190.075</td>\n      <td>16.74621</td>\n      <td>243</td>\n      <td>113503.294178</td>\n      <td>0.001322</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>Hunter</td>\n      <td>1</td>\n      <td>307</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>41326</td>\n      <td>95481e953f8aed9ec3d16fc4509537e8</td>\n      <td>0</td>\n      <td>This handsome yet cute boy is up for adoption....</td>\n      <td>850a43f90</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>3.5</td>\n      <td>0.583333</td>\n      <td>0.071389</td>\n      <td>3.5</td>\n      <td>0.583333</td>\n      <td>0.071389</td>\n      <td>3.7</td>\n      <td>0.6</td>\n      <td>2.326006</td>\n      <td>0.775335</td>\n      <td>0.011257</td>\n      <td>0.239312</td>\n      <td>0.079771</td>\n      <td>0.000075</td>\n      <td>0.128066</td>\n      <td>0.042689</td>\n      <td>0.000016</td>\n      <td>2.4</td>\n      <td>0.8</td>\n      <td>0.0</td>\n      <td>2.98</td>\n      <td>0.993333</td>\n      <td>0.000133</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>boy adoption Hunter pal puppies love age brat ...</td>\n      <td>0</td>\n      <td>dog dog like mammal dog breed puppy mammal dog...</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>-1</td>\n      <td>390</td>\n      <td>312</td>\n      <td>77</td>\n      <td>81</td>\n      <td>49</td>\n      <td>13</td>\n      <td>65</td>\n      <td>19</td>\n      <td>13</td>\n      <td>42</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>280.698</td>\n      <td>54.62141</td>\n      <td>8104</td>\n      <td>51389.738932</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"_uuid":"e48c8f21713b9ad4e554f087335395677252af20"},"cell_type":"markdown","source":"### Name features"},{"metadata":{"trusted":true,"_uuid":"138a56a2df54cbbfb704937b43f924b42147e71c"},"cell_type":"code","source":"import re\ndef has_name(x):\n    if isinstance(x, float):\n        return 0\n    if \"no name\" in x.lower():\n        return 0\n    return 1\n\n\ndef num_name_words(x):\n    if isinstance(x, float):\n        return 0\n    name_words = x.split(\" \")\n    return len(name_words)\n\n\ndef contains_amp(x):\n    if isinstance(x, float):\n        return 0\n    if \"&\" in x:\n        return 1\n    if \"and\" in x.lower():\n        return 1\n    if \"+\" in x.lower():\n        return 1\n    return 0\n\n\ndef contains_comma(x):\n    if isinstance(x, float):\n        return 0\n    if \",\" in x:\n        return 1\n    return 0\n\n\ndef start_with_number(x):\n    if isinstance(x, float):\n        return 0\n    match = re.match(f\"\\d\", x)\n    if match:\n        return int(match.group())\n    return 0\n\n\ndef contains_paren(x):\n    if isinstance(x, float):\n        return 0\n    if \"(\" in x:\n        return 1\n    if \")\" in x:\n        return 1\n    return 0\n\n\ndef contains_number(x):\n    if isinstance(x, float):\n        return 0\n    if re.match(r\".*\\d\", x):\n        return 1\n    return 0\n\n\ndef safe_calc_len(x):\n    if isinstance(x, float):\n        return 1\n    return len(x)\n\n\ndef num_unlike_letters(x):\n    if isinstance(x, float):\n        return 0\n    letters = {\n        ',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', \n        '&', '/', '[', ']', '>', '%', '=', '#', '*', '+',  \n        '•',  '~', '@', '£', '·', '_', '{', '}', '©', '^', '®', '`',\n        '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', \n        'Â', '█', '½', 'à', '…', '“', '★', '”', '–', '●', 'â', '►', \n        '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', \n        '║', '―', '¥', '▓', '—', '‹', '─', '▒', '：', '¼', '⊕', '▼', \n        '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', \n        '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', '∙', '）', '↓', '、', \n        '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', \n        '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', \"ã\", \"ç\", \"å\", \"ä\",\n        \"¶\", \"ð\"}\n\n    letter_in = set(x)\n    intersection = letter_in.intersection(letters)\n    if len(intersection) == 0:\n        return 0\n    else:\n        unlike_num = 0\n        for l in intersection:\n            unlike_num += len(re.findall(re.escape(l), x))\n        return unlike_num\n\nX_temp[\"num_name_words\"] = X_temp.Name.map(lambda x: num_name_words(x))\nX_temp[\"contains_amp\"] = X_temp.Name.map(lambda x: contains_amp(x))\nX_temp[\"contains_comma\"] = X_temp.Name.map(lambda x: contains_comma(x))\nX_temp[\"start_with_number\"] = X_temp.Name.map(lambda x: start_with_number(x))\nX_temp[\"contains_paren\"] = X_temp.Name.map(lambda x: contains_paren(x))\nX_temp[\"contains_number\"] = X_temp.Name.map(lambda x: contains_number(x))\nX_temp[\"name_length\"] = X_temp.Name.map(lambda x: safe_calc_len(x))\nX_temp[\"num_unlike_letters\"] = X_temp.Name.map(lambda x: num_unlike_letters(x))\nX_temp[\"rate_unlike_letters\"] = X_temp.num_unlike_letters / X_temp.name_length\nX_temp.head()","execution_count":26,"outputs":[{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"   Type         Name  Age  Breed1  Breed2  Gender  Color1  Color2  Color3  \\\n0     2       Nibble    3     299       0       1       1       7       0   \n1     2  No Name Yet    1     265       0       1       1       2       0   \n2     1       Brisco    1     307       0       1       2       7       0   \n3     1         Miko    4     307       0       2       1       2       0   \n4     1       Hunter    1     307       0       1       1       0       0   \n\n   MaturitySize  FurLength  Vaccinated  Dewormed  Sterilized  Health  \\\n0             1          1           2         2           2       1   \n1             2          2           3         3           3       1   \n2             2          2           1         1           2       1   \n3             2          1           1         1           2       1   \n4             2          1           2         2           2       1   \n\n   Quantity  Fee  State                         RescuerID  VideoAmt  \\\n0         1  100  41326  8480853f516546f6cf33aa88cd76c379         0   \n1         1    0  41401  3082c7125d8fb66f7dd4bff4192c8b14         0   \n2         1    0  41326  fa90fa5b1ee11c86938398b60abc32cb         0   \n3         1  150  41401  9238e4f44c71a75282e62f7136c6b240         0   \n4         1    0  41326  95481e953f8aed9ec3d16fc4509537e8         0   \n\n                                         Description      PetID  PhotoAmt  \\\n0  Nibble is a 3+ month old ball of cuteness. He ...  86e1089a3       1.0   \n1  I just found it alone yesterday near my apartm...  6296e909a       2.0   \n2  Their pregnant mother was dumped by her irresp...  3422e4906       7.0   \n3  Good guard dog, very alert, active, obedience ...  5842f1ff5       8.0   \n4  This handsome yet cute boy is up for adoption....  850a43f90       3.0   \n\n   AdoptionSpeed  magnitude_sum  magnitude_mean  magnitude_var  score_sum  \\\n0            2.0            2.2        0.366667       0.102222        1.8   \n1            0.0            0.7        0.350000       0.062500       -0.5   \n2            3.0            3.4        0.485714       0.124082        1.4   \n3            2.0            0.9        0.900000       0.000000        0.9   \n4            2.0            3.5        0.583333       0.071389        3.5   \n\n   score_mean  score_var  document_magnitude  document_score  annot_score_SUM  \\\n0    0.300000   0.146667                 2.4             0.3         0.830798   \n1   -0.250000   0.122500                 0.7            -0.2         1.590916   \n2    0.200000   0.320000                 3.7             0.2         5.522756   \n3    0.900000   0.000000                 0.9             0.9         6.045986   \n4    0.583333   0.071389                 3.7             0.6         2.326006   \n\n   annot_score_MEAN  annot_score_VAR  color_score_SUM  color_score_MEAN  \\\n0          0.830798              NaN         0.074838          0.074838   \n1          0.795458         0.000119         0.183415          0.091708   \n2          0.788965         0.001047         0.660042          0.094292   \n3          0.755748         0.000221         0.660390          0.082549   \n4          0.775335         0.011257         0.239312          0.079771   \n\n   color_score_VAR  pixel_frac_SUM  pixel_frac_MEAN  pixel_frac_VAR  \\\n0              NaN        0.066331         0.066331             NaN   \n1         0.000038        0.127362         0.063681        0.000039   \n2         0.000041        0.514481         0.073497        0.000452   \n3         0.000278        0.548335         0.068542        0.000571   \n4         0.000075        0.128066         0.042689        0.000016   \n\n   crop_conf_SUM  crop_conf_MEAN  crop_conf_VAR  crop_importance_SUM  \\\n0            0.8             0.8            NaN                 1.00   \n1            1.6             0.8            0.0                 2.00   \n2            5.6             0.8            0.0                 7.00   \n3            6.4             0.8            0.0                 8.00   \n4            2.4             0.8            0.0                 2.98   \n\n   crop_importance_MEAN  crop_importance_VAR  specified_SUM  specified_MEAN  \\\n0              1.000000                  NaN            1.0             1.0   \n1              1.000000             0.000000            2.0             1.0   \n2              1.000000             0.000000            7.0             1.0   \n3              1.000000             0.000000            8.0             1.0   \n4              0.993333             0.000133            3.0             1.0   \n\n   specified_VAR                                             entity  language  \\\n0            NaN  Nibble cuteness clinic cats result kitty coupl...         0   \n1            0.0                                     apartment care         0   \n2            0.0  mother owner puppies roadside shops Subang Jay...         0   \n3            0.0        guard dog master obedience call sms details         0   \n4            0.0  boy adoption Hunter pal puppies love age brat ...         0   \n\n                                                desc  main_breed_Type  \\\n0  cat black cat small to medium sized cats cat l...              2.0   \n1  cat whiskers small to medium sized cats fauna ...              2.0   \n2  dog dog like mammal dog breed dog breed group ...              1.0   \n3  dog dog like mammal dog breed dog breed group ...              1.0   \n4  dog dog like mammal dog breed puppy mammal dog...              1.0   \n\n   main_breed_BreedName  second_breed_Type  second_breed_BreedName  \\\n0                     0                NaN                      -1   \n1                     1                NaN                      -1   \n2                     2                NaN                      -1   \n3                     2                NaN                      -1   \n4                     2                NaN                      -1   \n\n   len_description  len_meta_desc  len_entity  num_description_words  \\\n0              359            111          86                     69   \n1              118            212          14                     23   \n2              393            855          98                     69   \n3              146            879          43                     25   \n4              390            312          77                     81   \n\n   num_desc_words  num_entity_words  uniq_description_words  uniq_desc_words  \\\n0              19                13                      57               16   \n1              37                 2                      20               21   \n2             135                15                      60               24   \n3             141                 7                      24               21   \n4              49                13                      65               19   \n\n   uniq_entity_words  num_description_stopwords  num_desc_stopwords  \\\n0                 12                         34                   1   \n1                  2                         12                   2   \n2                 14                         30                   0   \n3                  7                          8                   0   \n4                 13                         42                   0   \n\n   num_entity_stopwords  num_description_punctuation  state_gdp  \\\n0                     0                            8    280.698   \n1                     0                            2    190.075   \n2                     0                            9    280.698   \n3                     0                            7    190.075   \n4                     0                            9    280.698   \n\n   state_population  state_area  state_gdp_per_person  fee_per_gdp_per_person  \\\n0          54.62141        8104          51389.738932                0.001946   \n1          16.74621         243         113503.294178                0.000000   \n2          54.62141        8104          51389.738932                0.000000   \n3          16.74621         243         113503.294178                0.001322   \n4          54.62141        8104          51389.738932                0.000000   \n\n   num_name_words  contains_amp  contains_comma  start_with_number  \\\n0               1             0               0                  0   \n1               3             0               0                  0   \n2               1             0               0                  0   \n3               1             0               0                  0   \n4               1             0               0                  0   \n\n   contains_paren  contains_number  name_length  num_unlike_letters  \\\n0               0                0            6                   0   \n1               0                0           11                   0   \n2               0                0            6                   0   \n3               0                0            4                   0   \n4               0                0            6                   0   \n\n   rate_unlike_letters  \n0                  0.0  \n1                  0.0  \n2                  0.0  \n3                  0.0  \n4                  0.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Type</th>\n      <th>Name</th>\n      <th>Age</th>\n      <th>Breed1</th>\n      <th>Breed2</th>\n      <th>Gender</th>\n      <th>Color1</th>\n      <th>Color2</th>\n      <th>Color3</th>\n      <th>MaturitySize</th>\n      <th>FurLength</th>\n      <th>Vaccinated</th>\n      <th>Dewormed</th>\n      <th>Sterilized</th>\n      <th>Health</th>\n      <th>Quantity</th>\n      <th>Fee</th>\n      <th>State</th>\n      <th>RescuerID</th>\n      <th>VideoAmt</th>\n      <th>Description</th>\n      <th>PetID</th>\n      <th>PhotoAmt</th>\n      <th>AdoptionSpeed</th>\n      <th>magnitude_sum</th>\n      <th>magnitude_mean</th>\n      <th>magnitude_var</th>\n      <th>score_sum</th>\n      <th>score_mean</th>\n      <th>score_var</th>\n      <th>document_magnitude</th>\n      <th>document_score</th>\n      <th>annot_score_SUM</th>\n      <th>annot_score_MEAN</th>\n      <th>annot_score_VAR</th>\n      <th>color_score_SUM</th>\n      <th>color_score_MEAN</th>\n      <th>color_score_VAR</th>\n      <th>pixel_frac_SUM</th>\n      <th>pixel_frac_MEAN</th>\n      <th>pixel_frac_VAR</th>\n      <th>crop_conf_SUM</th>\n      <th>crop_conf_MEAN</th>\n      <th>crop_conf_VAR</th>\n      <th>crop_importance_SUM</th>\n      <th>crop_importance_MEAN</th>\n      <th>crop_importance_VAR</th>\n      <th>specified_SUM</th>\n      <th>specified_MEAN</th>\n      <th>specified_VAR</th>\n      <th>entity</th>\n      <th>language</th>\n      <th>desc</th>\n      <th>main_breed_Type</th>\n      <th>main_breed_BreedName</th>\n      <th>second_breed_Type</th>\n      <th>second_breed_BreedName</th>\n      <th>len_description</th>\n      <th>len_meta_desc</th>\n      <th>len_entity</th>\n      <th>num_description_words</th>\n      <th>num_desc_words</th>\n      <th>num_entity_words</th>\n      <th>uniq_description_words</th>\n      <th>uniq_desc_words</th>\n      <th>uniq_entity_words</th>\n      <th>num_description_stopwords</th>\n      <th>num_desc_stopwords</th>\n      <th>num_entity_stopwords</th>\n      <th>num_description_punctuation</th>\n      <th>state_gdp</th>\n      <th>state_population</th>\n      <th>state_area</th>\n      <th>state_gdp_per_person</th>\n      <th>fee_per_gdp_per_person</th>\n      <th>num_name_words</th>\n      <th>contains_amp</th>\n      <th>contains_comma</th>\n      <th>start_with_number</th>\n      <th>contains_paren</th>\n      <th>contains_number</th>\n      <th>name_length</th>\n      <th>num_unlike_letters</th>\n      <th>rate_unlike_letters</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>Nibble</td>\n      <td>3</td>\n      <td>299</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>7</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>100</td>\n      <td>41326</td>\n      <td>8480853f516546f6cf33aa88cd76c379</td>\n      <td>0</td>\n      <td>Nibble is a 3+ month old ball of cuteness. He ...</td>\n      <td>86e1089a3</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.2</td>\n      <td>0.366667</td>\n      <td>0.102222</td>\n      <td>1.8</td>\n      <td>0.300000</td>\n      <td>0.146667</td>\n      <td>2.4</td>\n      <td>0.3</td>\n      <td>0.830798</td>\n      <td>0.830798</td>\n      <td>NaN</td>\n      <td>0.074838</td>\n      <td>0.074838</td>\n      <td>NaN</td>\n      <td>0.066331</td>\n      <td>0.066331</td>\n      <td>NaN</td>\n      <td>0.8</td>\n      <td>0.8</td>\n      <td>NaN</td>\n      <td>1.00</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>Nibble cuteness clinic cats result kitty coupl...</td>\n      <td>0</td>\n      <td>cat black cat small to medium sized cats cat l...</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>-1</td>\n      <td>359</td>\n      <td>111</td>\n      <td>86</td>\n      <td>69</td>\n      <td>19</td>\n      <td>13</td>\n      <td>57</td>\n      <td>16</td>\n      <td>12</td>\n      <td>34</td>\n      <td>1</td>\n      <td>0</td>\n      <td>8</td>\n      <td>280.698</td>\n      <td>54.62141</td>\n      <td>8104</td>\n      <td>51389.738932</td>\n      <td>0.001946</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>No Name Yet</td>\n      <td>1</td>\n      <td>265</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>41401</td>\n      <td>3082c7125d8fb66f7dd4bff4192c8b14</td>\n      <td>0</td>\n      <td>I just found it alone yesterday near my apartm...</td>\n      <td>6296e909a</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.7</td>\n      <td>0.350000</td>\n      <td>0.062500</td>\n      <td>-0.5</td>\n      <td>-0.250000</td>\n      <td>0.122500</td>\n      <td>0.7</td>\n      <td>-0.2</td>\n      <td>1.590916</td>\n      <td>0.795458</td>\n      <td>0.000119</td>\n      <td>0.183415</td>\n      <td>0.091708</td>\n      <td>0.000038</td>\n      <td>0.127362</td>\n      <td>0.063681</td>\n      <td>0.000039</td>\n      <td>1.6</td>\n      <td>0.8</td>\n      <td>0.0</td>\n      <td>2.00</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>apartment care</td>\n      <td>0</td>\n      <td>cat whiskers small to medium sized cats fauna ...</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>-1</td>\n      <td>118</td>\n      <td>212</td>\n      <td>14</td>\n      <td>23</td>\n      <td>37</td>\n      <td>2</td>\n      <td>20</td>\n      <td>21</td>\n      <td>2</td>\n      <td>12</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>190.075</td>\n      <td>16.74621</td>\n      <td>243</td>\n      <td>113503.294178</td>\n      <td>0.000000</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>11</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>Brisco</td>\n      <td>1</td>\n      <td>307</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>7</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>41326</td>\n      <td>fa90fa5b1ee11c86938398b60abc32cb</td>\n      <td>0</td>\n      <td>Their pregnant mother was dumped by her irresp...</td>\n      <td>3422e4906</td>\n      <td>7.0</td>\n      <td>3.0</td>\n      <td>3.4</td>\n      <td>0.485714</td>\n      <td>0.124082</td>\n      <td>1.4</td>\n      <td>0.200000</td>\n      <td>0.320000</td>\n      <td>3.7</td>\n      <td>0.2</td>\n      <td>5.522756</td>\n      <td>0.788965</td>\n      <td>0.001047</td>\n      <td>0.660042</td>\n      <td>0.094292</td>\n      <td>0.000041</td>\n      <td>0.514481</td>\n      <td>0.073497</td>\n      <td>0.000452</td>\n      <td>5.6</td>\n      <td>0.8</td>\n      <td>0.0</td>\n      <td>7.00</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>7.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>mother owner puppies roadside shops Subang Jay...</td>\n      <td>0</td>\n      <td>dog dog like mammal dog breed dog breed group ...</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>-1</td>\n      <td>393</td>\n      <td>855</td>\n      <td>98</td>\n      <td>69</td>\n      <td>135</td>\n      <td>15</td>\n      <td>60</td>\n      <td>24</td>\n      <td>14</td>\n      <td>30</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>280.698</td>\n      <td>54.62141</td>\n      <td>8104</td>\n      <td>51389.738932</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>Miko</td>\n      <td>4</td>\n      <td>307</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>150</td>\n      <td>41401</td>\n      <td>9238e4f44c71a75282e62f7136c6b240</td>\n      <td>0</td>\n      <td>Good guard dog, very alert, active, obedience ...</td>\n      <td>5842f1ff5</td>\n      <td>8.0</td>\n      <td>2.0</td>\n      <td>0.9</td>\n      <td>0.900000</td>\n      <td>0.000000</td>\n      <td>0.9</td>\n      <td>0.900000</td>\n      <td>0.000000</td>\n      <td>0.9</td>\n      <td>0.9</td>\n      <td>6.045986</td>\n      <td>0.755748</td>\n      <td>0.000221</td>\n      <td>0.660390</td>\n      <td>0.082549</td>\n      <td>0.000278</td>\n      <td>0.548335</td>\n      <td>0.068542</td>\n      <td>0.000571</td>\n      <td>6.4</td>\n      <td>0.8</td>\n      <td>0.0</td>\n      <td>8.00</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>guard dog master obedience call sms details</td>\n      <td>0</td>\n      <td>dog dog like mammal dog breed dog breed group ...</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>-1</td>\n      <td>146</td>\n      <td>879</td>\n      <td>43</td>\n      <td>25</td>\n      <td>141</td>\n      <td>7</td>\n      <td>24</td>\n      <td>21</td>\n      <td>7</td>\n      <td>8</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7</td>\n      <td>190.075</td>\n      <td>16.74621</td>\n      <td>243</td>\n      <td>113503.294178</td>\n      <td>0.001322</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>Hunter</td>\n      <td>1</td>\n      <td>307</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>41326</td>\n      <td>95481e953f8aed9ec3d16fc4509537e8</td>\n      <td>0</td>\n      <td>This handsome yet cute boy is up for adoption....</td>\n      <td>850a43f90</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>3.5</td>\n      <td>0.583333</td>\n      <td>0.071389</td>\n      <td>3.5</td>\n      <td>0.583333</td>\n      <td>0.071389</td>\n      <td>3.7</td>\n      <td>0.6</td>\n      <td>2.326006</td>\n      <td>0.775335</td>\n      <td>0.011257</td>\n      <td>0.239312</td>\n      <td>0.079771</td>\n      <td>0.000075</td>\n      <td>0.128066</td>\n      <td>0.042689</td>\n      <td>0.000016</td>\n      <td>2.4</td>\n      <td>0.8</td>\n      <td>0.0</td>\n      <td>2.98</td>\n      <td>0.993333</td>\n      <td>0.000133</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>boy adoption Hunter pal puppies love age brat ...</td>\n      <td>0</td>\n      <td>dog dog like mammal dog breed puppy mammal dog...</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>-1</td>\n      <td>390</td>\n      <td>312</td>\n      <td>77</td>\n      <td>81</td>\n      <td>49</td>\n      <td>13</td>\n      <td>65</td>\n      <td>19</td>\n      <td>13</td>\n      <td>42</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>280.698</td>\n      <td>54.62141</td>\n      <td>8104</td>\n      <td>51389.738932</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"_uuid":"4aa6be7a80659bf78178766f53dfea7af91d06b6"},"cell_type":"markdown","source":"## Tfidf"},{"metadata":{"trusted":true,"_uuid":"95de8074d85b1b8c42c3b209dfed4a8903d5a673"},"cell_type":"code","source":"n_components = 16\ntext_features = []\n\nfor i in text_columns:\n    print(f\"generating features from: {i}\")\n    tfv = TfidfVectorizer(\n        min_df=2,\n        strip_accents=\"unicode\",\n        analyzer=\"word\",\n        token_pattern=r\"(?u)\\b\\w+\\b\",\n        ngram_range=(1, 3),\n        use_idf=1,\n        smooth_idf=1,\n        sublinear_tf=1)\n    svd = TruncatedSVD(\n        n_components=n_components,\n        random_state=1337)\n    tfidf_col = tfv.fit_transform(X_text.loc[:, i].values)\n    svd_col = svd.fit_transform(tfidf_col)\n    svd_col = pd.DataFrame(svd_col)\n    svd_col = svd_col.add_prefix(\"Tfidf_{}_\".format(i))\n    \n    text_features.append(svd_col)\n\ntext_features = pd.concat(text_features, axis=1)\nX_temp = pd.concat([X_temp, text_features], axis=1)\n\nfor i in text_columns:\n    X_temp.drop(i, axis=1, inplace=True)","execution_count":27,"outputs":[{"output_type":"stream","text":"generating features from: Description\ngenerating features from: entity\ngenerating features from: desc\n","name":"stdout"}]},{"metadata":{"_uuid":"4f43400c8d2ce34ef6db94049bc215be6de528fd"},"cell_type":"markdown","source":"## Image size features"},{"metadata":{"trusted":true,"_uuid":"190f69f684f76dc03a93040cda0f12bb9ef190b8"},"cell_type":"code","source":"import os\nimport glob\n\ntrain_image_files = sorted(\n    glob.glob(\"../input/petfinder-adoption-prediction/train_images/*.jpg\"))\ntest_image_files = sorted(\n    glob.glob(\"../input/petfinder-adoption-prediction/test_images/*.jpg\"))\n\ntrain_df_imgs = pd.DataFrame(train_image_files)\ntest_df_imgs = pd.DataFrame(test_image_files)\ntrain_df_imgs.columns = [\"image_file_name\"]\ntest_df_imgs.columns = [\"image_file_name\"]\n\ntrain_imgs_pets = train_df_imgs[\"image_file_name\"].apply(\n    lambda x: x.split(\"/\")[-1].split(\"-\")[0])\ntest_imgs_pets = test_df_imgs[\"image_file_name\"].apply(\n    lambda x: x.split(\"/\")[-1].split(\"-\")[0])\ntrain_df_imgs = train_df_imgs.assign(PetID=train_imgs_pets)\ntest_df_imgs = test_df_imgs.assign(PetID=test_imgs_pets)\n\ndef get_size(filename):\n    st = os.stat(filename)\n    return st.st_size\n\ndef get_dimensions(filename):\n    img_size = Image.open(filename).size\n    return img_size\n\ntrain_df_imgs[\"image_size\"] = train_df_imgs[\"image_file_name\"].apply(get_size)\ntest_df_imgs[\"image_size\"] = test_df_imgs[\"image_file_name\"].apply(get_size)\ntrain_df_imgs[\"temp_size\"] = train_df_imgs[\"image_file_name\"].apply(get_dimensions)\ntest_df_imgs[\"temp_size\"] = test_df_imgs[\"image_file_name\"].apply(get_dimensions)\ntrain_df_imgs[\"width\"] = train_df_imgs[\"temp_size\"].apply(lambda x: x[0])\ntest_df_imgs[\"width\"] = test_df_imgs[\"temp_size\"].apply(lambda x: x[0])\ntrain_df_imgs[\"height\"] = train_df_imgs[\"temp_size\"].apply(lambda x: x[1])\ntest_df_imgs[\"height\"] = test_df_imgs[\"temp_size\"].apply(lambda x: x[1])\ntrain_df_imgs.drop([\"temp_size\"], axis=1, inplace=True)\ntest_df_imgs.drop([\"temp_size\"], axis=1, inplace=True)\n\naggs = {\n    \"image_size\": [\"sum\", \"mean\", \"var\"],\n    \"width\": [\"sum\", \"mean\", \"var\"],\n    \"height\": [\"sum\", \"mean\", \"var\"]\n}\nagg_train_imgs = train_df_imgs.groupby(\"PetID\").agg(aggs)\nnew_columns = [\n    k + \"_\" + agg for k in aggs.keys() for agg in aggs[k]\n]\nagg_test_imgs = test_df_imgs.groupby(\"PetID\").agg(aggs)\nagg_train_imgs.columns = new_columns\nagg_train_imgs = agg_train_imgs.reset_index()\n\nagg_test_imgs.columns = new_columns\nagg_test_imgs = agg_test_imgs.reset_index()\n","execution_count":28,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f1e67fa6e8b1c1deac413010b7ed9b9d43234f92"},"cell_type":"code","source":"agg_imgs = pd.concat([agg_train_imgs, agg_test_imgs], axis=0).reset_index(drop=True)\nX_temp = X_temp.merge(agg_imgs, how=\"left\", on=\"PetID\")\nX_temp.head()","execution_count":29,"outputs":[{"output_type":"execute_result","execution_count":29,"data":{"text/plain":"   Type         Name  Age  Breed1  Breed2  Gender  Color1  Color2  Color3  \\\n0     2       Nibble    3     299       0       1       1       7       0   \n1     2  No Name Yet    1     265       0       1       1       2       0   \n2     1       Brisco    1     307       0       1       2       7       0   \n3     1         Miko    4     307       0       2       1       2       0   \n4     1       Hunter    1     307       0       1       1       0       0   \n\n   MaturitySize  FurLength  Vaccinated  Dewormed  Sterilized  Health  \\\n0             1          1           2         2           2       1   \n1             2          2           3         3           3       1   \n2             2          2           1         1           2       1   \n3             2          1           1         1           2       1   \n4             2          1           2         2           2       1   \n\n   Quantity  Fee  State                         RescuerID  VideoAmt  \\\n0         1  100  41326  8480853f516546f6cf33aa88cd76c379         0   \n1         1    0  41401  3082c7125d8fb66f7dd4bff4192c8b14         0   \n2         1    0  41326  fa90fa5b1ee11c86938398b60abc32cb         0   \n3         1  150  41401  9238e4f44c71a75282e62f7136c6b240         0   \n4         1    0  41326  95481e953f8aed9ec3d16fc4509537e8         0   \n\n       PetID  PhotoAmt  AdoptionSpeed  magnitude_sum  magnitude_mean  \\\n0  86e1089a3       1.0            2.0            2.2        0.366667   \n1  6296e909a       2.0            0.0            0.7        0.350000   \n2  3422e4906       7.0            3.0            3.4        0.485714   \n3  5842f1ff5       8.0            2.0            0.9        0.900000   \n4  850a43f90       3.0            2.0            3.5        0.583333   \n\n   magnitude_var  score_sum  score_mean  score_var  document_magnitude  \\\n0       0.102222        1.8    0.300000   0.146667                 2.4   \n1       0.062500       -0.5   -0.250000   0.122500                 0.7   \n2       0.124082        1.4    0.200000   0.320000                 3.7   \n3       0.000000        0.9    0.900000   0.000000                 0.9   \n4       0.071389        3.5    0.583333   0.071389                 3.7   \n\n   document_score  annot_score_SUM  annot_score_MEAN  annot_score_VAR  \\\n0             0.3         0.830798          0.830798              NaN   \n1            -0.2         1.590916          0.795458         0.000119   \n2             0.2         5.522756          0.788965         0.001047   \n3             0.9         6.045986          0.755748         0.000221   \n4             0.6         2.326006          0.775335         0.011257   \n\n   color_score_SUM  color_score_MEAN  color_score_VAR  pixel_frac_SUM  \\\n0         0.074838          0.074838              NaN        0.066331   \n1         0.183415          0.091708         0.000038        0.127362   \n2         0.660042          0.094292         0.000041        0.514481   \n3         0.660390          0.082549         0.000278        0.548335   \n4         0.239312          0.079771         0.000075        0.128066   \n\n   pixel_frac_MEAN  pixel_frac_VAR  crop_conf_SUM  crop_conf_MEAN  \\\n0         0.066331             NaN            0.8             0.8   \n1         0.063681        0.000039            1.6             0.8   \n2         0.073497        0.000452            5.6             0.8   \n3         0.068542        0.000571            6.4             0.8   \n4         0.042689        0.000016            2.4             0.8   \n\n   crop_conf_VAR  crop_importance_SUM  crop_importance_MEAN  \\\n0            NaN                 1.00              1.000000   \n1            0.0                 2.00              1.000000   \n2            0.0                 7.00              1.000000   \n3            0.0                 8.00              1.000000   \n4            0.0                 2.98              0.993333   \n\n   crop_importance_VAR  specified_SUM  specified_MEAN  specified_VAR  \\\n0                  NaN            1.0             1.0            NaN   \n1             0.000000            2.0             1.0            0.0   \n2             0.000000            7.0             1.0            0.0   \n3             0.000000            8.0             1.0            0.0   \n4             0.000133            3.0             1.0            0.0   \n\n   language  main_breed_Type  main_breed_BreedName  second_breed_Type  \\\n0         0              2.0                     0                NaN   \n1         0              2.0                     1                NaN   \n2         0              1.0                     2                NaN   \n3         0              1.0                     2                NaN   \n4         0              1.0                     2                NaN   \n\n   second_breed_BreedName  len_description  len_meta_desc  len_entity  \\\n0                      -1              359            111          86   \n1                      -1              118            212          14   \n2                      -1              393            855          98   \n3                      -1              146            879          43   \n4                      -1              390            312          77   \n\n   num_description_words  num_desc_words  num_entity_words  \\\n0                     69              19                13   \n1                     23              37                 2   \n2                     69             135                15   \n3                     25             141                 7   \n4                     81              49                13   \n\n   uniq_description_words  uniq_desc_words  uniq_entity_words  \\\n0                      57               16                 12   \n1                      20               21                  2   \n2                      60               24                 14   \n3                      24               21                  7   \n4                      65               19                 13   \n\n   num_description_stopwords     ...       contains_comma  start_with_number  \\\n0                         34     ...                    0                  0   \n1                         12     ...                    0                  0   \n2                         30     ...                    0                  0   \n3                          8     ...                    0                  0   \n4                         42     ...                    0                  0   \n\n   contains_paren  contains_number  name_length  num_unlike_letters  \\\n0               0                0            6                   0   \n1               0                0           11                   0   \n2               0                0            6                   0   \n3               0                0            4                   0   \n4               0                0            6                   0   \n\n   rate_unlike_letters  Tfidf_Description_0  Tfidf_Description_1  \\\n0                  0.0             0.109208            -0.054788   \n1                  0.0             0.065635            -0.042643   \n2                  0.0             0.124596            -0.060786   \n3                  0.0             0.081360            -0.021896   \n4                  0.0             0.189465            -0.045537   \n\n   Tfidf_Description_2  Tfidf_Description_3  Tfidf_Description_4  \\\n0            -0.027811            -0.006133            -0.013338   \n1            -0.019198            -0.002690            -0.004885   \n2             0.065617            -0.003723             0.024301   \n3            -0.001674             0.011284             0.010215   \n4            -0.010977            -0.009483            -0.011833   \n\n   Tfidf_Description_5  Tfidf_Description_6  Tfidf_Description_7  \\\n0             0.008456            -0.020514            -0.020346   \n1             0.022908            -0.022137            -0.042913   \n2            -0.002590             0.231682            -0.161545   \n3            -0.012603             0.032462             0.026343   \n4            -0.013234            -0.024864             0.024887   \n\n   Tfidf_Description_8  Tfidf_Description_9  Tfidf_Description_10  \\\n0             0.002814             0.028917              0.002962   \n1            -0.023930             0.026311              0.013061   \n2             0.042858            -0.022786             -0.046409   \n3            -0.001419            -0.033471             -0.045353   \n4             0.018768             0.090536             -0.081798   \n\n   Tfidf_Description_11  Tfidf_Description_12  Tfidf_Description_13  \\\n0             -0.000095             -0.018424             -0.018280   \n1              0.022925             -0.015762             -0.027501   \n2              0.007761              0.025377             -0.034746   \n3             -0.002096              0.040378              0.012599   \n4             -0.017550              0.044352             -0.006712   \n\n   Tfidf_Description_14  Tfidf_Description_15  Tfidf_entity_0  Tfidf_entity_1  \\\n0             -0.007528              0.009868        0.000037        0.013053   \n1              0.013893              0.034890        0.000029        0.016604   \n2             -0.046306             -0.016597        0.000040        0.025495   \n3              0.027032              0.011449        0.000029        0.033364   \n4             -0.009167              0.011911        0.000053        0.111890   \n\n   Tfidf_entity_2  Tfidf_entity_3  Tfidf_entity_4  Tfidf_entity_5  \\\n0        0.033643        0.031206        0.006489        0.001996   \n1        0.043498        0.034004        0.020293        0.009058   \n2        0.075011        0.006661        0.028682       -0.014056   \n3        0.055338        0.008599        0.147900        0.032550   \n4        0.067515       -0.006133        0.000998       -0.049176   \n\n   Tfidf_entity_6  Tfidf_entity_7  Tfidf_entity_8  Tfidf_entity_9  \\\n0        0.018358        0.026973       -0.026971       -0.012381   \n1        0.018408        0.039855       -0.022823       -0.019452   \n2        0.008809        0.073326        0.042734        0.029835   \n3       -0.000582       -0.011612       -0.007226       -0.006741   \n4       -0.000408        0.079796        0.061995        0.016409   \n\n   Tfidf_entity_10  Tfidf_entity_11  Tfidf_entity_12  Tfidf_entity_13  \\\n0         0.024707         0.004333        -0.039479         0.044068   \n1         0.038517        -0.004993        -0.005249         0.023034   \n2         0.032328        -0.000575         0.043473        -0.021088   \n3         0.013928        -0.022664        -0.044229        -0.119552   \n4         0.012236        -0.006130        -0.013930         0.031081   \n\n   Tfidf_entity_14  Tfidf_entity_15  Tfidf_desc_0  Tfidf_desc_1  Tfidf_desc_2  \\\n0        -0.010249         0.022505      0.407822     -0.084889 -1.089434e-07   \n1         0.005372        -0.055634      0.453239      0.037524  2.554491e-07   \n2         0.003531        -0.014081      0.090822      0.366067 -1.190902e-08   \n3        -0.007308         0.032700      0.126992      0.523013  5.235827e-08   \n4         0.020328        -0.031070      0.086932      0.312147  3.389364e-07   \n\n   Tfidf_desc_3  Tfidf_desc_4  Tfidf_desc_5  Tfidf_desc_6  Tfidf_desc_7  \\\n0     -0.091383      0.002828     -0.033053      0.010067      0.129089   \n1     -0.096150     -0.018873      0.003938      0.022036      0.137500   \n2      0.014001     -0.045489      0.127677      0.370287     -0.204517   \n3      0.031607      0.179217     -0.069133      0.005489     -0.034659   \n4      0.004039      0.119461      0.124084      0.002166      0.028955   \n\n   Tfidf_desc_8  Tfidf_desc_9  Tfidf_desc_10  Tfidf_desc_11  Tfidf_desc_12  \\\n0     -0.192715     -0.037356       0.069814      -0.196362      -0.102388   \n1     -0.103271     -0.026981       0.038141      -0.057744      -0.060723   \n2     -0.131163      0.138625       0.042774      -0.023667       0.006420   \n3      0.044895     -0.043177      -0.068690      -0.192850       0.154541   \n4      0.028481     -0.068960       0.028217      -0.020259       0.028731   \n\n   Tfidf_desc_13  Tfidf_desc_14  Tfidf_desc_15  image_size_sum  \\\n0      -0.145521       0.251853      -0.114023         24638.0   \n1      -0.188502      -0.039958       0.114133         41860.0   \n2      -0.008847      -0.020395      -0.017428        122199.0   \n3       0.017752       0.012273       0.055676        166859.0   \n4       0.008358       0.001908       0.016266         91296.0   \n\n   image_size_mean  image_size_var  width_sum  width_mean     width_var  \\\n0        24638.000             NaN      360.0  360.000000           NaN   \n1        20930.000    4.474580e+07      699.0  349.500000   4900.500000   \n2        17457.000    1.195168e+07     2500.0  357.142857   2857.142857   \n3        20857.375    3.528980e+06     3000.0  375.000000   2142.857143   \n4        30432.000    1.390560e+08     1550.0  516.666667  45633.333333   \n\n   height_sum  height_mean   height_var  \n0       480.0   480.000000          NaN  \n1       777.0   388.500000   264.500000  \n2      2400.0   342.857143  2857.142857  \n3      2600.0   325.000000  2142.857143  \n4      1334.0   444.666667   936.333333  \n\n[5 rows x 138 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Type</th>\n      <th>Name</th>\n      <th>Age</th>\n      <th>Breed1</th>\n      <th>Breed2</th>\n      <th>Gender</th>\n      <th>Color1</th>\n      <th>Color2</th>\n      <th>Color3</th>\n      <th>MaturitySize</th>\n      <th>FurLength</th>\n      <th>Vaccinated</th>\n      <th>Dewormed</th>\n      <th>Sterilized</th>\n      <th>Health</th>\n      <th>Quantity</th>\n      <th>Fee</th>\n      <th>State</th>\n      <th>RescuerID</th>\n      <th>VideoAmt</th>\n      <th>PetID</th>\n      <th>PhotoAmt</th>\n      <th>AdoptionSpeed</th>\n      <th>magnitude_sum</th>\n      <th>magnitude_mean</th>\n      <th>magnitude_var</th>\n      <th>score_sum</th>\n      <th>score_mean</th>\n      <th>score_var</th>\n      <th>document_magnitude</th>\n      <th>document_score</th>\n      <th>annot_score_SUM</th>\n      <th>annot_score_MEAN</th>\n      <th>annot_score_VAR</th>\n      <th>color_score_SUM</th>\n      <th>color_score_MEAN</th>\n      <th>color_score_VAR</th>\n      <th>pixel_frac_SUM</th>\n      <th>pixel_frac_MEAN</th>\n      <th>pixel_frac_VAR</th>\n      <th>crop_conf_SUM</th>\n      <th>crop_conf_MEAN</th>\n      <th>crop_conf_VAR</th>\n      <th>crop_importance_SUM</th>\n      <th>crop_importance_MEAN</th>\n      <th>crop_importance_VAR</th>\n      <th>specified_SUM</th>\n      <th>specified_MEAN</th>\n      <th>specified_VAR</th>\n      <th>language</th>\n      <th>main_breed_Type</th>\n      <th>main_breed_BreedName</th>\n      <th>second_breed_Type</th>\n      <th>second_breed_BreedName</th>\n      <th>len_description</th>\n      <th>len_meta_desc</th>\n      <th>len_entity</th>\n      <th>num_description_words</th>\n      <th>num_desc_words</th>\n      <th>num_entity_words</th>\n      <th>uniq_description_words</th>\n      <th>uniq_desc_words</th>\n      <th>uniq_entity_words</th>\n      <th>num_description_stopwords</th>\n      <th>...</th>\n      <th>contains_comma</th>\n      <th>start_with_number</th>\n      <th>contains_paren</th>\n      <th>contains_number</th>\n      <th>name_length</th>\n      <th>num_unlike_letters</th>\n      <th>rate_unlike_letters</th>\n      <th>Tfidf_Description_0</th>\n      <th>Tfidf_Description_1</th>\n      <th>Tfidf_Description_2</th>\n      <th>Tfidf_Description_3</th>\n      <th>Tfidf_Description_4</th>\n      <th>Tfidf_Description_5</th>\n      <th>Tfidf_Description_6</th>\n      <th>Tfidf_Description_7</th>\n      <th>Tfidf_Description_8</th>\n      <th>Tfidf_Description_9</th>\n      <th>Tfidf_Description_10</th>\n      <th>Tfidf_Description_11</th>\n      <th>Tfidf_Description_12</th>\n      <th>Tfidf_Description_13</th>\n      <th>Tfidf_Description_14</th>\n      <th>Tfidf_Description_15</th>\n      <th>Tfidf_entity_0</th>\n      <th>Tfidf_entity_1</th>\n      <th>Tfidf_entity_2</th>\n      <th>Tfidf_entity_3</th>\n      <th>Tfidf_entity_4</th>\n      <th>Tfidf_entity_5</th>\n      <th>Tfidf_entity_6</th>\n      <th>Tfidf_entity_7</th>\n      <th>Tfidf_entity_8</th>\n      <th>Tfidf_entity_9</th>\n      <th>Tfidf_entity_10</th>\n      <th>Tfidf_entity_11</th>\n      <th>Tfidf_entity_12</th>\n      <th>Tfidf_entity_13</th>\n      <th>Tfidf_entity_14</th>\n      <th>Tfidf_entity_15</th>\n      <th>Tfidf_desc_0</th>\n      <th>Tfidf_desc_1</th>\n      <th>Tfidf_desc_2</th>\n      <th>Tfidf_desc_3</th>\n      <th>Tfidf_desc_4</th>\n      <th>Tfidf_desc_5</th>\n      <th>Tfidf_desc_6</th>\n      <th>Tfidf_desc_7</th>\n      <th>Tfidf_desc_8</th>\n      <th>Tfidf_desc_9</th>\n      <th>Tfidf_desc_10</th>\n      <th>Tfidf_desc_11</th>\n      <th>Tfidf_desc_12</th>\n      <th>Tfidf_desc_13</th>\n      <th>Tfidf_desc_14</th>\n      <th>Tfidf_desc_15</th>\n      <th>image_size_sum</th>\n      <th>image_size_mean</th>\n      <th>image_size_var</th>\n      <th>width_sum</th>\n      <th>width_mean</th>\n      <th>width_var</th>\n      <th>height_sum</th>\n      <th>height_mean</th>\n      <th>height_var</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>Nibble</td>\n      <td>3</td>\n      <td>299</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>7</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>100</td>\n      <td>41326</td>\n      <td>8480853f516546f6cf33aa88cd76c379</td>\n      <td>0</td>\n      <td>86e1089a3</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.2</td>\n      <td>0.366667</td>\n      <td>0.102222</td>\n      <td>1.8</td>\n      <td>0.300000</td>\n      <td>0.146667</td>\n      <td>2.4</td>\n      <td>0.3</td>\n      <td>0.830798</td>\n      <td>0.830798</td>\n      <td>NaN</td>\n      <td>0.074838</td>\n      <td>0.074838</td>\n      <td>NaN</td>\n      <td>0.066331</td>\n      <td>0.066331</td>\n      <td>NaN</td>\n      <td>0.8</td>\n      <td>0.8</td>\n      <td>NaN</td>\n      <td>1.00</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>-1</td>\n      <td>359</td>\n      <td>111</td>\n      <td>86</td>\n      <td>69</td>\n      <td>19</td>\n      <td>13</td>\n      <td>57</td>\n      <td>16</td>\n      <td>12</td>\n      <td>34</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.109208</td>\n      <td>-0.054788</td>\n      <td>-0.027811</td>\n      <td>-0.006133</td>\n      <td>-0.013338</td>\n      <td>0.008456</td>\n      <td>-0.020514</td>\n      <td>-0.020346</td>\n      <td>0.002814</td>\n      <td>0.028917</td>\n      <td>0.002962</td>\n      <td>-0.000095</td>\n      <td>-0.018424</td>\n      <td>-0.018280</td>\n      <td>-0.007528</td>\n      <td>0.009868</td>\n      <td>0.000037</td>\n      <td>0.013053</td>\n      <td>0.033643</td>\n      <td>0.031206</td>\n      <td>0.006489</td>\n      <td>0.001996</td>\n      <td>0.018358</td>\n      <td>0.026973</td>\n      <td>-0.026971</td>\n      <td>-0.012381</td>\n      <td>0.024707</td>\n      <td>0.004333</td>\n      <td>-0.039479</td>\n      <td>0.044068</td>\n      <td>-0.010249</td>\n      <td>0.022505</td>\n      <td>0.407822</td>\n      <td>-0.084889</td>\n      <td>-1.089434e-07</td>\n      <td>-0.091383</td>\n      <td>0.002828</td>\n      <td>-0.033053</td>\n      <td>0.010067</td>\n      <td>0.129089</td>\n      <td>-0.192715</td>\n      <td>-0.037356</td>\n      <td>0.069814</td>\n      <td>-0.196362</td>\n      <td>-0.102388</td>\n      <td>-0.145521</td>\n      <td>0.251853</td>\n      <td>-0.114023</td>\n      <td>24638.0</td>\n      <td>24638.000</td>\n      <td>NaN</td>\n      <td>360.0</td>\n      <td>360.000000</td>\n      <td>NaN</td>\n      <td>480.0</td>\n      <td>480.000000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>No Name Yet</td>\n      <td>1</td>\n      <td>265</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>41401</td>\n      <td>3082c7125d8fb66f7dd4bff4192c8b14</td>\n      <td>0</td>\n      <td>6296e909a</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.7</td>\n      <td>0.350000</td>\n      <td>0.062500</td>\n      <td>-0.5</td>\n      <td>-0.250000</td>\n      <td>0.122500</td>\n      <td>0.7</td>\n      <td>-0.2</td>\n      <td>1.590916</td>\n      <td>0.795458</td>\n      <td>0.000119</td>\n      <td>0.183415</td>\n      <td>0.091708</td>\n      <td>0.000038</td>\n      <td>0.127362</td>\n      <td>0.063681</td>\n      <td>0.000039</td>\n      <td>1.6</td>\n      <td>0.8</td>\n      <td>0.0</td>\n      <td>2.00</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>-1</td>\n      <td>118</td>\n      <td>212</td>\n      <td>14</td>\n      <td>23</td>\n      <td>37</td>\n      <td>2</td>\n      <td>20</td>\n      <td>21</td>\n      <td>2</td>\n      <td>12</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>11</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.065635</td>\n      <td>-0.042643</td>\n      <td>-0.019198</td>\n      <td>-0.002690</td>\n      <td>-0.004885</td>\n      <td>0.022908</td>\n      <td>-0.022137</td>\n      <td>-0.042913</td>\n      <td>-0.023930</td>\n      <td>0.026311</td>\n      <td>0.013061</td>\n      <td>0.022925</td>\n      <td>-0.015762</td>\n      <td>-0.027501</td>\n      <td>0.013893</td>\n      <td>0.034890</td>\n      <td>0.000029</td>\n      <td>0.016604</td>\n      <td>0.043498</td>\n      <td>0.034004</td>\n      <td>0.020293</td>\n      <td>0.009058</td>\n      <td>0.018408</td>\n      <td>0.039855</td>\n      <td>-0.022823</td>\n      <td>-0.019452</td>\n      <td>0.038517</td>\n      <td>-0.004993</td>\n      <td>-0.005249</td>\n      <td>0.023034</td>\n      <td>0.005372</td>\n      <td>-0.055634</td>\n      <td>0.453239</td>\n      <td>0.037524</td>\n      <td>2.554491e-07</td>\n      <td>-0.096150</td>\n      <td>-0.018873</td>\n      <td>0.003938</td>\n      <td>0.022036</td>\n      <td>0.137500</td>\n      <td>-0.103271</td>\n      <td>-0.026981</td>\n      <td>0.038141</td>\n      <td>-0.057744</td>\n      <td>-0.060723</td>\n      <td>-0.188502</td>\n      <td>-0.039958</td>\n      <td>0.114133</td>\n      <td>41860.0</td>\n      <td>20930.000</td>\n      <td>4.474580e+07</td>\n      <td>699.0</td>\n      <td>349.500000</td>\n      <td>4900.500000</td>\n      <td>777.0</td>\n      <td>388.500000</td>\n      <td>264.500000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>Brisco</td>\n      <td>1</td>\n      <td>307</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>7</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>41326</td>\n      <td>fa90fa5b1ee11c86938398b60abc32cb</td>\n      <td>0</td>\n      <td>3422e4906</td>\n      <td>7.0</td>\n      <td>3.0</td>\n      <td>3.4</td>\n      <td>0.485714</td>\n      <td>0.124082</td>\n      <td>1.4</td>\n      <td>0.200000</td>\n      <td>0.320000</td>\n      <td>3.7</td>\n      <td>0.2</td>\n      <td>5.522756</td>\n      <td>0.788965</td>\n      <td>0.001047</td>\n      <td>0.660042</td>\n      <td>0.094292</td>\n      <td>0.000041</td>\n      <td>0.514481</td>\n      <td>0.073497</td>\n      <td>0.000452</td>\n      <td>5.6</td>\n      <td>0.8</td>\n      <td>0.0</td>\n      <td>7.00</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>7.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>-1</td>\n      <td>393</td>\n      <td>855</td>\n      <td>98</td>\n      <td>69</td>\n      <td>135</td>\n      <td>15</td>\n      <td>60</td>\n      <td>24</td>\n      <td>14</td>\n      <td>30</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.124596</td>\n      <td>-0.060786</td>\n      <td>0.065617</td>\n      <td>-0.003723</td>\n      <td>0.024301</td>\n      <td>-0.002590</td>\n      <td>0.231682</td>\n      <td>-0.161545</td>\n      <td>0.042858</td>\n      <td>-0.022786</td>\n      <td>-0.046409</td>\n      <td>0.007761</td>\n      <td>0.025377</td>\n      <td>-0.034746</td>\n      <td>-0.046306</td>\n      <td>-0.016597</td>\n      <td>0.000040</td>\n      <td>0.025495</td>\n      <td>0.075011</td>\n      <td>0.006661</td>\n      <td>0.028682</td>\n      <td>-0.014056</td>\n      <td>0.008809</td>\n      <td>0.073326</td>\n      <td>0.042734</td>\n      <td>0.029835</td>\n      <td>0.032328</td>\n      <td>-0.000575</td>\n      <td>0.043473</td>\n      <td>-0.021088</td>\n      <td>0.003531</td>\n      <td>-0.014081</td>\n      <td>0.090822</td>\n      <td>0.366067</td>\n      <td>-1.190902e-08</td>\n      <td>0.014001</td>\n      <td>-0.045489</td>\n      <td>0.127677</td>\n      <td>0.370287</td>\n      <td>-0.204517</td>\n      <td>-0.131163</td>\n      <td>0.138625</td>\n      <td>0.042774</td>\n      <td>-0.023667</td>\n      <td>0.006420</td>\n      <td>-0.008847</td>\n      <td>-0.020395</td>\n      <td>-0.017428</td>\n      <td>122199.0</td>\n      <td>17457.000</td>\n      <td>1.195168e+07</td>\n      <td>2500.0</td>\n      <td>357.142857</td>\n      <td>2857.142857</td>\n      <td>2400.0</td>\n      <td>342.857143</td>\n      <td>2857.142857</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>Miko</td>\n      <td>4</td>\n      <td>307</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>150</td>\n      <td>41401</td>\n      <td>9238e4f44c71a75282e62f7136c6b240</td>\n      <td>0</td>\n      <td>5842f1ff5</td>\n      <td>8.0</td>\n      <td>2.0</td>\n      <td>0.9</td>\n      <td>0.900000</td>\n      <td>0.000000</td>\n      <td>0.9</td>\n      <td>0.900000</td>\n      <td>0.000000</td>\n      <td>0.9</td>\n      <td>0.9</td>\n      <td>6.045986</td>\n      <td>0.755748</td>\n      <td>0.000221</td>\n      <td>0.660390</td>\n      <td>0.082549</td>\n      <td>0.000278</td>\n      <td>0.548335</td>\n      <td>0.068542</td>\n      <td>0.000571</td>\n      <td>6.4</td>\n      <td>0.8</td>\n      <td>0.0</td>\n      <td>8.00</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>-1</td>\n      <td>146</td>\n      <td>879</td>\n      <td>43</td>\n      <td>25</td>\n      <td>141</td>\n      <td>7</td>\n      <td>24</td>\n      <td>21</td>\n      <td>7</td>\n      <td>8</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.081360</td>\n      <td>-0.021896</td>\n      <td>-0.001674</td>\n      <td>0.011284</td>\n      <td>0.010215</td>\n      <td>-0.012603</td>\n      <td>0.032462</td>\n      <td>0.026343</td>\n      <td>-0.001419</td>\n      <td>-0.033471</td>\n      <td>-0.045353</td>\n      <td>-0.002096</td>\n      <td>0.040378</td>\n      <td>0.012599</td>\n      <td>0.027032</td>\n      <td>0.011449</td>\n      <td>0.000029</td>\n      <td>0.033364</td>\n      <td>0.055338</td>\n      <td>0.008599</td>\n      <td>0.147900</td>\n      <td>0.032550</td>\n      <td>-0.000582</td>\n      <td>-0.011612</td>\n      <td>-0.007226</td>\n      <td>-0.006741</td>\n      <td>0.013928</td>\n      <td>-0.022664</td>\n      <td>-0.044229</td>\n      <td>-0.119552</td>\n      <td>-0.007308</td>\n      <td>0.032700</td>\n      <td>0.126992</td>\n      <td>0.523013</td>\n      <td>5.235827e-08</td>\n      <td>0.031607</td>\n      <td>0.179217</td>\n      <td>-0.069133</td>\n      <td>0.005489</td>\n      <td>-0.034659</td>\n      <td>0.044895</td>\n      <td>-0.043177</td>\n      <td>-0.068690</td>\n      <td>-0.192850</td>\n      <td>0.154541</td>\n      <td>0.017752</td>\n      <td>0.012273</td>\n      <td>0.055676</td>\n      <td>166859.0</td>\n      <td>20857.375</td>\n      <td>3.528980e+06</td>\n      <td>3000.0</td>\n      <td>375.000000</td>\n      <td>2142.857143</td>\n      <td>2600.0</td>\n      <td>325.000000</td>\n      <td>2142.857143</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>Hunter</td>\n      <td>1</td>\n      <td>307</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>41326</td>\n      <td>95481e953f8aed9ec3d16fc4509537e8</td>\n      <td>0</td>\n      <td>850a43f90</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>3.5</td>\n      <td>0.583333</td>\n      <td>0.071389</td>\n      <td>3.5</td>\n      <td>0.583333</td>\n      <td>0.071389</td>\n      <td>3.7</td>\n      <td>0.6</td>\n      <td>2.326006</td>\n      <td>0.775335</td>\n      <td>0.011257</td>\n      <td>0.239312</td>\n      <td>0.079771</td>\n      <td>0.000075</td>\n      <td>0.128066</td>\n      <td>0.042689</td>\n      <td>0.000016</td>\n      <td>2.4</td>\n      <td>0.8</td>\n      <td>0.0</td>\n      <td>2.98</td>\n      <td>0.993333</td>\n      <td>0.000133</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>-1</td>\n      <td>390</td>\n      <td>312</td>\n      <td>77</td>\n      <td>81</td>\n      <td>49</td>\n      <td>13</td>\n      <td>65</td>\n      <td>19</td>\n      <td>13</td>\n      <td>42</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.189465</td>\n      <td>-0.045537</td>\n      <td>-0.010977</td>\n      <td>-0.009483</td>\n      <td>-0.011833</td>\n      <td>-0.013234</td>\n      <td>-0.024864</td>\n      <td>0.024887</td>\n      <td>0.018768</td>\n      <td>0.090536</td>\n      <td>-0.081798</td>\n      <td>-0.017550</td>\n      <td>0.044352</td>\n      <td>-0.006712</td>\n      <td>-0.009167</td>\n      <td>0.011911</td>\n      <td>0.000053</td>\n      <td>0.111890</td>\n      <td>0.067515</td>\n      <td>-0.006133</td>\n      <td>0.000998</td>\n      <td>-0.049176</td>\n      <td>-0.000408</td>\n      <td>0.079796</td>\n      <td>0.061995</td>\n      <td>0.016409</td>\n      <td>0.012236</td>\n      <td>-0.006130</td>\n      <td>-0.013930</td>\n      <td>0.031081</td>\n      <td>0.020328</td>\n      <td>-0.031070</td>\n      <td>0.086932</td>\n      <td>0.312147</td>\n      <td>3.389364e-07</td>\n      <td>0.004039</td>\n      <td>0.119461</td>\n      <td>0.124084</td>\n      <td>0.002166</td>\n      <td>0.028955</td>\n      <td>0.028481</td>\n      <td>-0.068960</td>\n      <td>0.028217</td>\n      <td>-0.020259</td>\n      <td>0.028731</td>\n      <td>0.008358</td>\n      <td>0.001908</td>\n      <td>0.016266</td>\n      <td>91296.0</td>\n      <td>30432.000</td>\n      <td>1.390560e+08</td>\n      <td>1550.0</td>\n      <td>516.666667</td>\n      <td>45633.333333</td>\n      <td>1334.0</td>\n      <td>444.666667</td>\n      <td>936.333333</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 138 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Sanitize"},{"metadata":{"trusted":true},"cell_type":"code","source":"hasnans = []\nfor c in X_temp.columns:\n    if X_temp[c].hasnans:\n        hasnans.append(c)","execution_count":30,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sanitize_col = list(\n    set(hasnans) - {\n        \"Name\", \"AdoptionSpeed\"\n    })\nX_temp[sanitize_col] = X_temp[sanitize_col].fillna(0.0)\nX_temp.head()","execution_count":31,"outputs":[{"output_type":"execute_result","execution_count":31,"data":{"text/plain":"   Type         Name  Age  Breed1  Breed2  Gender  Color1  Color2  Color3  \\\n0     2       Nibble    3     299       0       1       1       7       0   \n1     2  No Name Yet    1     265       0       1       1       2       0   \n2     1       Brisco    1     307       0       1       2       7       0   \n3     1         Miko    4     307       0       2       1       2       0   \n4     1       Hunter    1     307       0       1       1       0       0   \n\n   MaturitySize  FurLength  Vaccinated  Dewormed  Sterilized  Health  \\\n0             1          1           2         2           2       1   \n1             2          2           3         3           3       1   \n2             2          2           1         1           2       1   \n3             2          1           1         1           2       1   \n4             2          1           2         2           2       1   \n\n   Quantity  Fee  State                         RescuerID  VideoAmt  \\\n0         1  100  41326  8480853f516546f6cf33aa88cd76c379         0   \n1         1    0  41401  3082c7125d8fb66f7dd4bff4192c8b14         0   \n2         1    0  41326  fa90fa5b1ee11c86938398b60abc32cb         0   \n3         1  150  41401  9238e4f44c71a75282e62f7136c6b240         0   \n4         1    0  41326  95481e953f8aed9ec3d16fc4509537e8         0   \n\n       PetID  PhotoAmt  AdoptionSpeed  magnitude_sum  magnitude_mean  \\\n0  86e1089a3       1.0            2.0            2.2        0.366667   \n1  6296e909a       2.0            0.0            0.7        0.350000   \n2  3422e4906       7.0            3.0            3.4        0.485714   \n3  5842f1ff5       8.0            2.0            0.9        0.900000   \n4  850a43f90       3.0            2.0            3.5        0.583333   \n\n   magnitude_var  score_sum  score_mean  score_var  document_magnitude  \\\n0       0.102222        1.8    0.300000   0.146667                 2.4   \n1       0.062500       -0.5   -0.250000   0.122500                 0.7   \n2       0.124082        1.4    0.200000   0.320000                 3.7   \n3       0.000000        0.9    0.900000   0.000000                 0.9   \n4       0.071389        3.5    0.583333   0.071389                 3.7   \n\n   document_score  annot_score_SUM  annot_score_MEAN  annot_score_VAR  \\\n0             0.3         0.830798          0.830798         0.000000   \n1            -0.2         1.590916          0.795458         0.000119   \n2             0.2         5.522756          0.788965         0.001047   \n3             0.9         6.045986          0.755748         0.000221   \n4             0.6         2.326006          0.775335         0.011257   \n\n   color_score_SUM  color_score_MEAN  color_score_VAR  pixel_frac_SUM  \\\n0         0.074838          0.074838         0.000000        0.066331   \n1         0.183415          0.091708         0.000038        0.127362   \n2         0.660042          0.094292         0.000041        0.514481   \n3         0.660390          0.082549         0.000278        0.548335   \n4         0.239312          0.079771         0.000075        0.128066   \n\n   pixel_frac_MEAN  pixel_frac_VAR  crop_conf_SUM  crop_conf_MEAN  \\\n0         0.066331        0.000000            0.8             0.8   \n1         0.063681        0.000039            1.6             0.8   \n2         0.073497        0.000452            5.6             0.8   \n3         0.068542        0.000571            6.4             0.8   \n4         0.042689        0.000016            2.4             0.8   \n\n   crop_conf_VAR  crop_importance_SUM  crop_importance_MEAN  \\\n0            0.0                 1.00              1.000000   \n1            0.0                 2.00              1.000000   \n2            0.0                 7.00              1.000000   \n3            0.0                 8.00              1.000000   \n4            0.0                 2.98              0.993333   \n\n   crop_importance_VAR  specified_SUM  specified_MEAN  specified_VAR  \\\n0             0.000000            1.0             1.0            0.0   \n1             0.000000            2.0             1.0            0.0   \n2             0.000000            7.0             1.0            0.0   \n3             0.000000            8.0             1.0            0.0   \n4             0.000133            3.0             1.0            0.0   \n\n   language  main_breed_Type  main_breed_BreedName  second_breed_Type  \\\n0         0              2.0                     0                0.0   \n1         0              2.0                     1                0.0   \n2         0              1.0                     2                0.0   \n3         0              1.0                     2                0.0   \n4         0              1.0                     2                0.0   \n\n   second_breed_BreedName  len_description  len_meta_desc  len_entity  \\\n0                      -1              359            111          86   \n1                      -1              118            212          14   \n2                      -1              393            855          98   \n3                      -1              146            879          43   \n4                      -1              390            312          77   \n\n   num_description_words  num_desc_words  num_entity_words  \\\n0                     69              19                13   \n1                     23              37                 2   \n2                     69             135                15   \n3                     25             141                 7   \n4                     81              49                13   \n\n   uniq_description_words  uniq_desc_words  uniq_entity_words  \\\n0                      57               16                 12   \n1                      20               21                  2   \n2                      60               24                 14   \n3                      24               21                  7   \n4                      65               19                 13   \n\n   num_description_stopwords     ...       contains_comma  start_with_number  \\\n0                         34     ...                    0                  0   \n1                         12     ...                    0                  0   \n2                         30     ...                    0                  0   \n3                          8     ...                    0                  0   \n4                         42     ...                    0                  0   \n\n   contains_paren  contains_number  name_length  num_unlike_letters  \\\n0               0                0            6                   0   \n1               0                0           11                   0   \n2               0                0            6                   0   \n3               0                0            4                   0   \n4               0                0            6                   0   \n\n   rate_unlike_letters  Tfidf_Description_0  Tfidf_Description_1  \\\n0                  0.0             0.109208            -0.054788   \n1                  0.0             0.065635            -0.042643   \n2                  0.0             0.124596            -0.060786   \n3                  0.0             0.081360            -0.021896   \n4                  0.0             0.189465            -0.045537   \n\n   Tfidf_Description_2  Tfidf_Description_3  Tfidf_Description_4  \\\n0            -0.027811            -0.006133            -0.013338   \n1            -0.019198            -0.002690            -0.004885   \n2             0.065617            -0.003723             0.024301   \n3            -0.001674             0.011284             0.010215   \n4            -0.010977            -0.009483            -0.011833   \n\n   Tfidf_Description_5  Tfidf_Description_6  Tfidf_Description_7  \\\n0             0.008456            -0.020514            -0.020346   \n1             0.022908            -0.022137            -0.042913   \n2            -0.002590             0.231682            -0.161545   \n3            -0.012603             0.032462             0.026343   \n4            -0.013234            -0.024864             0.024887   \n\n   Tfidf_Description_8  Tfidf_Description_9  Tfidf_Description_10  \\\n0             0.002814             0.028917              0.002962   \n1            -0.023930             0.026311              0.013061   \n2             0.042858            -0.022786             -0.046409   \n3            -0.001419            -0.033471             -0.045353   \n4             0.018768             0.090536             -0.081798   \n\n   Tfidf_Description_11  Tfidf_Description_12  Tfidf_Description_13  \\\n0             -0.000095             -0.018424             -0.018280   \n1              0.022925             -0.015762             -0.027501   \n2              0.007761              0.025377             -0.034746   \n3             -0.002096              0.040378              0.012599   \n4             -0.017550              0.044352             -0.006712   \n\n   Tfidf_Description_14  Tfidf_Description_15  Tfidf_entity_0  Tfidf_entity_1  \\\n0             -0.007528              0.009868        0.000037        0.013053   \n1              0.013893              0.034890        0.000029        0.016604   \n2             -0.046306             -0.016597        0.000040        0.025495   \n3              0.027032              0.011449        0.000029        0.033364   \n4             -0.009167              0.011911        0.000053        0.111890   \n\n   Tfidf_entity_2  Tfidf_entity_3  Tfidf_entity_4  Tfidf_entity_5  \\\n0        0.033643        0.031206        0.006489        0.001996   \n1        0.043498        0.034004        0.020293        0.009058   \n2        0.075011        0.006661        0.028682       -0.014056   \n3        0.055338        0.008599        0.147900        0.032550   \n4        0.067515       -0.006133        0.000998       -0.049176   \n\n   Tfidf_entity_6  Tfidf_entity_7  Tfidf_entity_8  Tfidf_entity_9  \\\n0        0.018358        0.026973       -0.026971       -0.012381   \n1        0.018408        0.039855       -0.022823       -0.019452   \n2        0.008809        0.073326        0.042734        0.029835   \n3       -0.000582       -0.011612       -0.007226       -0.006741   \n4       -0.000408        0.079796        0.061995        0.016409   \n\n   Tfidf_entity_10  Tfidf_entity_11  Tfidf_entity_12  Tfidf_entity_13  \\\n0         0.024707         0.004333        -0.039479         0.044068   \n1         0.038517        -0.004993        -0.005249         0.023034   \n2         0.032328        -0.000575         0.043473        -0.021088   \n3         0.013928        -0.022664        -0.044229        -0.119552   \n4         0.012236        -0.006130        -0.013930         0.031081   \n\n   Tfidf_entity_14  Tfidf_entity_15  Tfidf_desc_0  Tfidf_desc_1  Tfidf_desc_2  \\\n0        -0.010249         0.022505      0.407822     -0.084889 -1.089434e-07   \n1         0.005372        -0.055634      0.453239      0.037524  2.554491e-07   \n2         0.003531        -0.014081      0.090822      0.366067 -1.190902e-08   \n3        -0.007308         0.032700      0.126992      0.523013  5.235827e-08   \n4         0.020328        -0.031070      0.086932      0.312147  3.389364e-07   \n\n   Tfidf_desc_3  Tfidf_desc_4  Tfidf_desc_5  Tfidf_desc_6  Tfidf_desc_7  \\\n0     -0.091383      0.002828     -0.033053      0.010067      0.129089   \n1     -0.096150     -0.018873      0.003938      0.022036      0.137500   \n2      0.014001     -0.045489      0.127677      0.370287     -0.204517   \n3      0.031607      0.179217     -0.069133      0.005489     -0.034659   \n4      0.004039      0.119461      0.124084      0.002166      0.028955   \n\n   Tfidf_desc_8  Tfidf_desc_9  Tfidf_desc_10  Tfidf_desc_11  Tfidf_desc_12  \\\n0     -0.192715     -0.037356       0.069814      -0.196362      -0.102388   \n1     -0.103271     -0.026981       0.038141      -0.057744      -0.060723   \n2     -0.131163      0.138625       0.042774      -0.023667       0.006420   \n3      0.044895     -0.043177      -0.068690      -0.192850       0.154541   \n4      0.028481     -0.068960       0.028217      -0.020259       0.028731   \n\n   Tfidf_desc_13  Tfidf_desc_14  Tfidf_desc_15  image_size_sum  \\\n0      -0.145521       0.251853      -0.114023         24638.0   \n1      -0.188502      -0.039958       0.114133         41860.0   \n2      -0.008847      -0.020395      -0.017428        122199.0   \n3       0.017752       0.012273       0.055676        166859.0   \n4       0.008358       0.001908       0.016266         91296.0   \n\n   image_size_mean  image_size_var  width_sum  width_mean     width_var  \\\n0        24638.000    0.000000e+00      360.0  360.000000      0.000000   \n1        20930.000    4.474580e+07      699.0  349.500000   4900.500000   \n2        17457.000    1.195168e+07     2500.0  357.142857   2857.142857   \n3        20857.375    3.528980e+06     3000.0  375.000000   2142.857143   \n4        30432.000    1.390560e+08     1550.0  516.666667  45633.333333   \n\n   height_sum  height_mean   height_var  \n0       480.0   480.000000     0.000000  \n1       777.0   388.500000   264.500000  \n2      2400.0   342.857143  2857.142857  \n3      2600.0   325.000000  2142.857143  \n4      1334.0   444.666667   936.333333  \n\n[5 rows x 138 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Type</th>\n      <th>Name</th>\n      <th>Age</th>\n      <th>Breed1</th>\n      <th>Breed2</th>\n      <th>Gender</th>\n      <th>Color1</th>\n      <th>Color2</th>\n      <th>Color3</th>\n      <th>MaturitySize</th>\n      <th>FurLength</th>\n      <th>Vaccinated</th>\n      <th>Dewormed</th>\n      <th>Sterilized</th>\n      <th>Health</th>\n      <th>Quantity</th>\n      <th>Fee</th>\n      <th>State</th>\n      <th>RescuerID</th>\n      <th>VideoAmt</th>\n      <th>PetID</th>\n      <th>PhotoAmt</th>\n      <th>AdoptionSpeed</th>\n      <th>magnitude_sum</th>\n      <th>magnitude_mean</th>\n      <th>magnitude_var</th>\n      <th>score_sum</th>\n      <th>score_mean</th>\n      <th>score_var</th>\n      <th>document_magnitude</th>\n      <th>document_score</th>\n      <th>annot_score_SUM</th>\n      <th>annot_score_MEAN</th>\n      <th>annot_score_VAR</th>\n      <th>color_score_SUM</th>\n      <th>color_score_MEAN</th>\n      <th>color_score_VAR</th>\n      <th>pixel_frac_SUM</th>\n      <th>pixel_frac_MEAN</th>\n      <th>pixel_frac_VAR</th>\n      <th>crop_conf_SUM</th>\n      <th>crop_conf_MEAN</th>\n      <th>crop_conf_VAR</th>\n      <th>crop_importance_SUM</th>\n      <th>crop_importance_MEAN</th>\n      <th>crop_importance_VAR</th>\n      <th>specified_SUM</th>\n      <th>specified_MEAN</th>\n      <th>specified_VAR</th>\n      <th>language</th>\n      <th>main_breed_Type</th>\n      <th>main_breed_BreedName</th>\n      <th>second_breed_Type</th>\n      <th>second_breed_BreedName</th>\n      <th>len_description</th>\n      <th>len_meta_desc</th>\n      <th>len_entity</th>\n      <th>num_description_words</th>\n      <th>num_desc_words</th>\n      <th>num_entity_words</th>\n      <th>uniq_description_words</th>\n      <th>uniq_desc_words</th>\n      <th>uniq_entity_words</th>\n      <th>num_description_stopwords</th>\n      <th>...</th>\n      <th>contains_comma</th>\n      <th>start_with_number</th>\n      <th>contains_paren</th>\n      <th>contains_number</th>\n      <th>name_length</th>\n      <th>num_unlike_letters</th>\n      <th>rate_unlike_letters</th>\n      <th>Tfidf_Description_0</th>\n      <th>Tfidf_Description_1</th>\n      <th>Tfidf_Description_2</th>\n      <th>Tfidf_Description_3</th>\n      <th>Tfidf_Description_4</th>\n      <th>Tfidf_Description_5</th>\n      <th>Tfidf_Description_6</th>\n      <th>Tfidf_Description_7</th>\n      <th>Tfidf_Description_8</th>\n      <th>Tfidf_Description_9</th>\n      <th>Tfidf_Description_10</th>\n      <th>Tfidf_Description_11</th>\n      <th>Tfidf_Description_12</th>\n      <th>Tfidf_Description_13</th>\n      <th>Tfidf_Description_14</th>\n      <th>Tfidf_Description_15</th>\n      <th>Tfidf_entity_0</th>\n      <th>Tfidf_entity_1</th>\n      <th>Tfidf_entity_2</th>\n      <th>Tfidf_entity_3</th>\n      <th>Tfidf_entity_4</th>\n      <th>Tfidf_entity_5</th>\n      <th>Tfidf_entity_6</th>\n      <th>Tfidf_entity_7</th>\n      <th>Tfidf_entity_8</th>\n      <th>Tfidf_entity_9</th>\n      <th>Tfidf_entity_10</th>\n      <th>Tfidf_entity_11</th>\n      <th>Tfidf_entity_12</th>\n      <th>Tfidf_entity_13</th>\n      <th>Tfidf_entity_14</th>\n      <th>Tfidf_entity_15</th>\n      <th>Tfidf_desc_0</th>\n      <th>Tfidf_desc_1</th>\n      <th>Tfidf_desc_2</th>\n      <th>Tfidf_desc_3</th>\n      <th>Tfidf_desc_4</th>\n      <th>Tfidf_desc_5</th>\n      <th>Tfidf_desc_6</th>\n      <th>Tfidf_desc_7</th>\n      <th>Tfidf_desc_8</th>\n      <th>Tfidf_desc_9</th>\n      <th>Tfidf_desc_10</th>\n      <th>Tfidf_desc_11</th>\n      <th>Tfidf_desc_12</th>\n      <th>Tfidf_desc_13</th>\n      <th>Tfidf_desc_14</th>\n      <th>Tfidf_desc_15</th>\n      <th>image_size_sum</th>\n      <th>image_size_mean</th>\n      <th>image_size_var</th>\n      <th>width_sum</th>\n      <th>width_mean</th>\n      <th>width_var</th>\n      <th>height_sum</th>\n      <th>height_mean</th>\n      <th>height_var</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>Nibble</td>\n      <td>3</td>\n      <td>299</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>7</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>100</td>\n      <td>41326</td>\n      <td>8480853f516546f6cf33aa88cd76c379</td>\n      <td>0</td>\n      <td>86e1089a3</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.2</td>\n      <td>0.366667</td>\n      <td>0.102222</td>\n      <td>1.8</td>\n      <td>0.300000</td>\n      <td>0.146667</td>\n      <td>2.4</td>\n      <td>0.3</td>\n      <td>0.830798</td>\n      <td>0.830798</td>\n      <td>0.000000</td>\n      <td>0.074838</td>\n      <td>0.074838</td>\n      <td>0.000000</td>\n      <td>0.066331</td>\n      <td>0.066331</td>\n      <td>0.000000</td>\n      <td>0.8</td>\n      <td>0.8</td>\n      <td>0.0</td>\n      <td>1.00</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>-1</td>\n      <td>359</td>\n      <td>111</td>\n      <td>86</td>\n      <td>69</td>\n      <td>19</td>\n      <td>13</td>\n      <td>57</td>\n      <td>16</td>\n      <td>12</td>\n      <td>34</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.109208</td>\n      <td>-0.054788</td>\n      <td>-0.027811</td>\n      <td>-0.006133</td>\n      <td>-0.013338</td>\n      <td>0.008456</td>\n      <td>-0.020514</td>\n      <td>-0.020346</td>\n      <td>0.002814</td>\n      <td>0.028917</td>\n      <td>0.002962</td>\n      <td>-0.000095</td>\n      <td>-0.018424</td>\n      <td>-0.018280</td>\n      <td>-0.007528</td>\n      <td>0.009868</td>\n      <td>0.000037</td>\n      <td>0.013053</td>\n      <td>0.033643</td>\n      <td>0.031206</td>\n      <td>0.006489</td>\n      <td>0.001996</td>\n      <td>0.018358</td>\n      <td>0.026973</td>\n      <td>-0.026971</td>\n      <td>-0.012381</td>\n      <td>0.024707</td>\n      <td>0.004333</td>\n      <td>-0.039479</td>\n      <td>0.044068</td>\n      <td>-0.010249</td>\n      <td>0.022505</td>\n      <td>0.407822</td>\n      <td>-0.084889</td>\n      <td>-1.089434e-07</td>\n      <td>-0.091383</td>\n      <td>0.002828</td>\n      <td>-0.033053</td>\n      <td>0.010067</td>\n      <td>0.129089</td>\n      <td>-0.192715</td>\n      <td>-0.037356</td>\n      <td>0.069814</td>\n      <td>-0.196362</td>\n      <td>-0.102388</td>\n      <td>-0.145521</td>\n      <td>0.251853</td>\n      <td>-0.114023</td>\n      <td>24638.0</td>\n      <td>24638.000</td>\n      <td>0.000000e+00</td>\n      <td>360.0</td>\n      <td>360.000000</td>\n      <td>0.000000</td>\n      <td>480.0</td>\n      <td>480.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>No Name Yet</td>\n      <td>1</td>\n      <td>265</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>41401</td>\n      <td>3082c7125d8fb66f7dd4bff4192c8b14</td>\n      <td>0</td>\n      <td>6296e909a</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.7</td>\n      <td>0.350000</td>\n      <td>0.062500</td>\n      <td>-0.5</td>\n      <td>-0.250000</td>\n      <td>0.122500</td>\n      <td>0.7</td>\n      <td>-0.2</td>\n      <td>1.590916</td>\n      <td>0.795458</td>\n      <td>0.000119</td>\n      <td>0.183415</td>\n      <td>0.091708</td>\n      <td>0.000038</td>\n      <td>0.127362</td>\n      <td>0.063681</td>\n      <td>0.000039</td>\n      <td>1.6</td>\n      <td>0.8</td>\n      <td>0.0</td>\n      <td>2.00</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>-1</td>\n      <td>118</td>\n      <td>212</td>\n      <td>14</td>\n      <td>23</td>\n      <td>37</td>\n      <td>2</td>\n      <td>20</td>\n      <td>21</td>\n      <td>2</td>\n      <td>12</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>11</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.065635</td>\n      <td>-0.042643</td>\n      <td>-0.019198</td>\n      <td>-0.002690</td>\n      <td>-0.004885</td>\n      <td>0.022908</td>\n      <td>-0.022137</td>\n      <td>-0.042913</td>\n      <td>-0.023930</td>\n      <td>0.026311</td>\n      <td>0.013061</td>\n      <td>0.022925</td>\n      <td>-0.015762</td>\n      <td>-0.027501</td>\n      <td>0.013893</td>\n      <td>0.034890</td>\n      <td>0.000029</td>\n      <td>0.016604</td>\n      <td>0.043498</td>\n      <td>0.034004</td>\n      <td>0.020293</td>\n      <td>0.009058</td>\n      <td>0.018408</td>\n      <td>0.039855</td>\n      <td>-0.022823</td>\n      <td>-0.019452</td>\n      <td>0.038517</td>\n      <td>-0.004993</td>\n      <td>-0.005249</td>\n      <td>0.023034</td>\n      <td>0.005372</td>\n      <td>-0.055634</td>\n      <td>0.453239</td>\n      <td>0.037524</td>\n      <td>2.554491e-07</td>\n      <td>-0.096150</td>\n      <td>-0.018873</td>\n      <td>0.003938</td>\n      <td>0.022036</td>\n      <td>0.137500</td>\n      <td>-0.103271</td>\n      <td>-0.026981</td>\n      <td>0.038141</td>\n      <td>-0.057744</td>\n      <td>-0.060723</td>\n      <td>-0.188502</td>\n      <td>-0.039958</td>\n      <td>0.114133</td>\n      <td>41860.0</td>\n      <td>20930.000</td>\n      <td>4.474580e+07</td>\n      <td>699.0</td>\n      <td>349.500000</td>\n      <td>4900.500000</td>\n      <td>777.0</td>\n      <td>388.500000</td>\n      <td>264.500000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>Brisco</td>\n      <td>1</td>\n      <td>307</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>7</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>41326</td>\n      <td>fa90fa5b1ee11c86938398b60abc32cb</td>\n      <td>0</td>\n      <td>3422e4906</td>\n      <td>7.0</td>\n      <td>3.0</td>\n      <td>3.4</td>\n      <td>0.485714</td>\n      <td>0.124082</td>\n      <td>1.4</td>\n      <td>0.200000</td>\n      <td>0.320000</td>\n      <td>3.7</td>\n      <td>0.2</td>\n      <td>5.522756</td>\n      <td>0.788965</td>\n      <td>0.001047</td>\n      <td>0.660042</td>\n      <td>0.094292</td>\n      <td>0.000041</td>\n      <td>0.514481</td>\n      <td>0.073497</td>\n      <td>0.000452</td>\n      <td>5.6</td>\n      <td>0.8</td>\n      <td>0.0</td>\n      <td>7.00</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>7.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>-1</td>\n      <td>393</td>\n      <td>855</td>\n      <td>98</td>\n      <td>69</td>\n      <td>135</td>\n      <td>15</td>\n      <td>60</td>\n      <td>24</td>\n      <td>14</td>\n      <td>30</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.124596</td>\n      <td>-0.060786</td>\n      <td>0.065617</td>\n      <td>-0.003723</td>\n      <td>0.024301</td>\n      <td>-0.002590</td>\n      <td>0.231682</td>\n      <td>-0.161545</td>\n      <td>0.042858</td>\n      <td>-0.022786</td>\n      <td>-0.046409</td>\n      <td>0.007761</td>\n      <td>0.025377</td>\n      <td>-0.034746</td>\n      <td>-0.046306</td>\n      <td>-0.016597</td>\n      <td>0.000040</td>\n      <td>0.025495</td>\n      <td>0.075011</td>\n      <td>0.006661</td>\n      <td>0.028682</td>\n      <td>-0.014056</td>\n      <td>0.008809</td>\n      <td>0.073326</td>\n      <td>0.042734</td>\n      <td>0.029835</td>\n      <td>0.032328</td>\n      <td>-0.000575</td>\n      <td>0.043473</td>\n      <td>-0.021088</td>\n      <td>0.003531</td>\n      <td>-0.014081</td>\n      <td>0.090822</td>\n      <td>0.366067</td>\n      <td>-1.190902e-08</td>\n      <td>0.014001</td>\n      <td>-0.045489</td>\n      <td>0.127677</td>\n      <td>0.370287</td>\n      <td>-0.204517</td>\n      <td>-0.131163</td>\n      <td>0.138625</td>\n      <td>0.042774</td>\n      <td>-0.023667</td>\n      <td>0.006420</td>\n      <td>-0.008847</td>\n      <td>-0.020395</td>\n      <td>-0.017428</td>\n      <td>122199.0</td>\n      <td>17457.000</td>\n      <td>1.195168e+07</td>\n      <td>2500.0</td>\n      <td>357.142857</td>\n      <td>2857.142857</td>\n      <td>2400.0</td>\n      <td>342.857143</td>\n      <td>2857.142857</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>Miko</td>\n      <td>4</td>\n      <td>307</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>150</td>\n      <td>41401</td>\n      <td>9238e4f44c71a75282e62f7136c6b240</td>\n      <td>0</td>\n      <td>5842f1ff5</td>\n      <td>8.0</td>\n      <td>2.0</td>\n      <td>0.9</td>\n      <td>0.900000</td>\n      <td>0.000000</td>\n      <td>0.9</td>\n      <td>0.900000</td>\n      <td>0.000000</td>\n      <td>0.9</td>\n      <td>0.9</td>\n      <td>6.045986</td>\n      <td>0.755748</td>\n      <td>0.000221</td>\n      <td>0.660390</td>\n      <td>0.082549</td>\n      <td>0.000278</td>\n      <td>0.548335</td>\n      <td>0.068542</td>\n      <td>0.000571</td>\n      <td>6.4</td>\n      <td>0.8</td>\n      <td>0.0</td>\n      <td>8.00</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>-1</td>\n      <td>146</td>\n      <td>879</td>\n      <td>43</td>\n      <td>25</td>\n      <td>141</td>\n      <td>7</td>\n      <td>24</td>\n      <td>21</td>\n      <td>7</td>\n      <td>8</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.081360</td>\n      <td>-0.021896</td>\n      <td>-0.001674</td>\n      <td>0.011284</td>\n      <td>0.010215</td>\n      <td>-0.012603</td>\n      <td>0.032462</td>\n      <td>0.026343</td>\n      <td>-0.001419</td>\n      <td>-0.033471</td>\n      <td>-0.045353</td>\n      <td>-0.002096</td>\n      <td>0.040378</td>\n      <td>0.012599</td>\n      <td>0.027032</td>\n      <td>0.011449</td>\n      <td>0.000029</td>\n      <td>0.033364</td>\n      <td>0.055338</td>\n      <td>0.008599</td>\n      <td>0.147900</td>\n      <td>0.032550</td>\n      <td>-0.000582</td>\n      <td>-0.011612</td>\n      <td>-0.007226</td>\n      <td>-0.006741</td>\n      <td>0.013928</td>\n      <td>-0.022664</td>\n      <td>-0.044229</td>\n      <td>-0.119552</td>\n      <td>-0.007308</td>\n      <td>0.032700</td>\n      <td>0.126992</td>\n      <td>0.523013</td>\n      <td>5.235827e-08</td>\n      <td>0.031607</td>\n      <td>0.179217</td>\n      <td>-0.069133</td>\n      <td>0.005489</td>\n      <td>-0.034659</td>\n      <td>0.044895</td>\n      <td>-0.043177</td>\n      <td>-0.068690</td>\n      <td>-0.192850</td>\n      <td>0.154541</td>\n      <td>0.017752</td>\n      <td>0.012273</td>\n      <td>0.055676</td>\n      <td>166859.0</td>\n      <td>20857.375</td>\n      <td>3.528980e+06</td>\n      <td>3000.0</td>\n      <td>375.000000</td>\n      <td>2142.857143</td>\n      <td>2600.0</td>\n      <td>325.000000</td>\n      <td>2142.857143</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>Hunter</td>\n      <td>1</td>\n      <td>307</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>41326</td>\n      <td>95481e953f8aed9ec3d16fc4509537e8</td>\n      <td>0</td>\n      <td>850a43f90</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>3.5</td>\n      <td>0.583333</td>\n      <td>0.071389</td>\n      <td>3.5</td>\n      <td>0.583333</td>\n      <td>0.071389</td>\n      <td>3.7</td>\n      <td>0.6</td>\n      <td>2.326006</td>\n      <td>0.775335</td>\n      <td>0.011257</td>\n      <td>0.239312</td>\n      <td>0.079771</td>\n      <td>0.000075</td>\n      <td>0.128066</td>\n      <td>0.042689</td>\n      <td>0.000016</td>\n      <td>2.4</td>\n      <td>0.8</td>\n      <td>0.0</td>\n      <td>2.98</td>\n      <td>0.993333</td>\n      <td>0.000133</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>-1</td>\n      <td>390</td>\n      <td>312</td>\n      <td>77</td>\n      <td>81</td>\n      <td>49</td>\n      <td>13</td>\n      <td>65</td>\n      <td>19</td>\n      <td>13</td>\n      <td>42</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.189465</td>\n      <td>-0.045537</td>\n      <td>-0.010977</td>\n      <td>-0.009483</td>\n      <td>-0.011833</td>\n      <td>-0.013234</td>\n      <td>-0.024864</td>\n      <td>0.024887</td>\n      <td>0.018768</td>\n      <td>0.090536</td>\n      <td>-0.081798</td>\n      <td>-0.017550</td>\n      <td>0.044352</td>\n      <td>-0.006712</td>\n      <td>-0.009167</td>\n      <td>0.011911</td>\n      <td>0.000053</td>\n      <td>0.111890</td>\n      <td>0.067515</td>\n      <td>-0.006133</td>\n      <td>0.000998</td>\n      <td>-0.049176</td>\n      <td>-0.000408</td>\n      <td>0.079796</td>\n      <td>0.061995</td>\n      <td>0.016409</td>\n      <td>0.012236</td>\n      <td>-0.006130</td>\n      <td>-0.013930</td>\n      <td>0.031081</td>\n      <td>0.020328</td>\n      <td>-0.031070</td>\n      <td>0.086932</td>\n      <td>0.312147</td>\n      <td>3.389364e-07</td>\n      <td>0.004039</td>\n      <td>0.119461</td>\n      <td>0.124084</td>\n      <td>0.002166</td>\n      <td>0.028955</td>\n      <td>0.028481</td>\n      <td>-0.068960</td>\n      <td>0.028217</td>\n      <td>-0.020259</td>\n      <td>0.028731</td>\n      <td>0.008358</td>\n      <td>0.001908</td>\n      <td>0.016266</td>\n      <td>91296.0</td>\n      <td>30432.000</td>\n      <td>1.390560e+08</td>\n      <td>1550.0</td>\n      <td>516.666667</td>\n      <td>45633.333333</td>\n      <td>1334.0</td>\n      <td>444.666667</td>\n      <td>936.333333</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 138 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"big_num_cols = [\"len_description\", \"len_meta_desc\", \"len_entity\",\n                \"num_description_words\", \"num_desc_words\", \"num_entity_words\", \n                \"uniq_description_words\", \"uniq_desc_words\", \"uniq_entity_words\",\n                \"num_description_stopwords\", \"num_desc_stopwords\", \"num_entity_stopwords\",\n                \"num_description_punctuation\",\n                \"state_gdp\", \"state_population\", \"state_area\", \"state_gdp_per_person\",\n                \"image_size_sum\", \"image_size_mean\", \"image_size_var\", \"width_sum\",\n                \"width_mean\", \"width_var\", \"height_sum\", \"height_mean\", \"height_var\"]\nfor c in big_num_cols:\n    X_temp[c] = X_temp[c].map(lambda x: np.log1p(x))\nX_temp.head()","execution_count":32,"outputs":[{"output_type":"execute_result","execution_count":32,"data":{"text/plain":"   Type         Name  Age  Breed1  Breed2  Gender  Color1  Color2  Color3  \\\n0     2       Nibble    3     299       0       1       1       7       0   \n1     2  No Name Yet    1     265       0       1       1       2       0   \n2     1       Brisco    1     307       0       1       2       7       0   \n3     1         Miko    4     307       0       2       1       2       0   \n4     1       Hunter    1     307       0       1       1       0       0   \n\n   MaturitySize  FurLength  Vaccinated  Dewormed  Sterilized  Health  \\\n0             1          1           2         2           2       1   \n1             2          2           3         3           3       1   \n2             2          2           1         1           2       1   \n3             2          1           1         1           2       1   \n4             2          1           2         2           2       1   \n\n   Quantity  Fee  State                         RescuerID  VideoAmt  \\\n0         1  100  41326  8480853f516546f6cf33aa88cd76c379         0   \n1         1    0  41401  3082c7125d8fb66f7dd4bff4192c8b14         0   \n2         1    0  41326  fa90fa5b1ee11c86938398b60abc32cb         0   \n3         1  150  41401  9238e4f44c71a75282e62f7136c6b240         0   \n4         1    0  41326  95481e953f8aed9ec3d16fc4509537e8         0   \n\n       PetID  PhotoAmt  AdoptionSpeed  magnitude_sum  magnitude_mean  \\\n0  86e1089a3       1.0            2.0            2.2        0.366667   \n1  6296e909a       2.0            0.0            0.7        0.350000   \n2  3422e4906       7.0            3.0            3.4        0.485714   \n3  5842f1ff5       8.0            2.0            0.9        0.900000   \n4  850a43f90       3.0            2.0            3.5        0.583333   \n\n   magnitude_var  score_sum  score_mean  score_var  document_magnitude  \\\n0       0.102222        1.8    0.300000   0.146667                 2.4   \n1       0.062500       -0.5   -0.250000   0.122500                 0.7   \n2       0.124082        1.4    0.200000   0.320000                 3.7   \n3       0.000000        0.9    0.900000   0.000000                 0.9   \n4       0.071389        3.5    0.583333   0.071389                 3.7   \n\n   document_score  annot_score_SUM  annot_score_MEAN  annot_score_VAR  \\\n0             0.3         0.830798          0.830798         0.000000   \n1            -0.2         1.590916          0.795458         0.000119   \n2             0.2         5.522756          0.788965         0.001047   \n3             0.9         6.045986          0.755748         0.000221   \n4             0.6         2.326006          0.775335         0.011257   \n\n   color_score_SUM  color_score_MEAN  color_score_VAR  pixel_frac_SUM  \\\n0         0.074838          0.074838         0.000000        0.066331   \n1         0.183415          0.091708         0.000038        0.127362   \n2         0.660042          0.094292         0.000041        0.514481   \n3         0.660390          0.082549         0.000278        0.548335   \n4         0.239312          0.079771         0.000075        0.128066   \n\n   pixel_frac_MEAN  pixel_frac_VAR  crop_conf_SUM  crop_conf_MEAN  \\\n0         0.066331        0.000000            0.8             0.8   \n1         0.063681        0.000039            1.6             0.8   \n2         0.073497        0.000452            5.6             0.8   \n3         0.068542        0.000571            6.4             0.8   \n4         0.042689        0.000016            2.4             0.8   \n\n   crop_conf_VAR  crop_importance_SUM  crop_importance_MEAN  \\\n0            0.0                 1.00              1.000000   \n1            0.0                 2.00              1.000000   \n2            0.0                 7.00              1.000000   \n3            0.0                 8.00              1.000000   \n4            0.0                 2.98              0.993333   \n\n   crop_importance_VAR  specified_SUM  specified_MEAN  specified_VAR  \\\n0             0.000000            1.0             1.0            0.0   \n1             0.000000            2.0             1.0            0.0   \n2             0.000000            7.0             1.0            0.0   \n3             0.000000            8.0             1.0            0.0   \n4             0.000133            3.0             1.0            0.0   \n\n   language  main_breed_Type  main_breed_BreedName  second_breed_Type  \\\n0         0              2.0                     0                0.0   \n1         0              2.0                     1                0.0   \n2         0              1.0                     2                0.0   \n3         0              1.0                     2                0.0   \n4         0              1.0                     2                0.0   \n\n   second_breed_BreedName  len_description  len_meta_desc  len_entity  \\\n0                      -1         5.886104       4.718499    4.465908   \n1                      -1         4.779123       5.361292    2.708050   \n2                      -1         5.976351       6.752270    4.595120   \n3                      -1         4.990433       6.779922    3.784190   \n4                      -1         5.968708       5.746203    4.356709   \n\n   num_description_words  num_desc_words  num_entity_words  \\\n0               4.248495        2.995732          2.639057   \n1               3.178054        3.637586          1.098612   \n2               4.248495        4.912655          2.772589   \n3               3.258097        4.955827          2.079442   \n4               4.406719        3.912023          2.639057   \n\n   uniq_description_words  uniq_desc_words  uniq_entity_words  \\\n0                4.060443         2.833213           2.564949   \n1                3.044522         3.091042           1.098612   \n2                4.110874         3.218876           2.708050   \n3                3.218876         3.091042           2.079442   \n4                4.189655         2.995732           2.639057   \n\n   num_description_stopwords     ...      contains_comma  start_with_number  \\\n0                   3.555348     ...                   0                  0   \n1                   2.564949     ...                   0                  0   \n2                   3.433987     ...                   0                  0   \n3                   2.197225     ...                   0                  0   \n4                   3.761200     ...                   0                  0   \n\n   contains_paren  contains_number  name_length  num_unlike_letters  \\\n0               0                0            6                   0   \n1               0                0           11                   0   \n2               0                0            6                   0   \n3               0                0            4                   0   \n4               0                0            6                   0   \n\n   rate_unlike_letters  Tfidf_Description_0  Tfidf_Description_1  \\\n0                  0.0             0.109208            -0.054788   \n1                  0.0             0.065635            -0.042643   \n2                  0.0             0.124596            -0.060786   \n3                  0.0             0.081360            -0.021896   \n4                  0.0             0.189465            -0.045537   \n\n   Tfidf_Description_2  Tfidf_Description_3  Tfidf_Description_4  \\\n0            -0.027811            -0.006133            -0.013338   \n1            -0.019198            -0.002690            -0.004885   \n2             0.065617            -0.003723             0.024301   \n3            -0.001674             0.011284             0.010215   \n4            -0.010977            -0.009483            -0.011833   \n\n   Tfidf_Description_5  Tfidf_Description_6  Tfidf_Description_7  \\\n0             0.008456            -0.020514            -0.020346   \n1             0.022908            -0.022137            -0.042913   \n2            -0.002590             0.231682            -0.161545   \n3            -0.012603             0.032462             0.026343   \n4            -0.013234            -0.024864             0.024887   \n\n   Tfidf_Description_8  Tfidf_Description_9  Tfidf_Description_10  \\\n0             0.002814             0.028917              0.002962   \n1            -0.023930             0.026311              0.013061   \n2             0.042858            -0.022786             -0.046409   \n3            -0.001419            -0.033471             -0.045353   \n4             0.018768             0.090536             -0.081798   \n\n   Tfidf_Description_11  Tfidf_Description_12  Tfidf_Description_13  \\\n0             -0.000095             -0.018424             -0.018280   \n1              0.022925             -0.015762             -0.027501   \n2              0.007761              0.025377             -0.034746   \n3             -0.002096              0.040378              0.012599   \n4             -0.017550              0.044352             -0.006712   \n\n   Tfidf_Description_14  Tfidf_Description_15  Tfidf_entity_0  Tfidf_entity_1  \\\n0             -0.007528              0.009868        0.000037        0.013053   \n1              0.013893              0.034890        0.000029        0.016604   \n2             -0.046306             -0.016597        0.000040        0.025495   \n3              0.027032              0.011449        0.000029        0.033364   \n4             -0.009167              0.011911        0.000053        0.111890   \n\n   Tfidf_entity_2  Tfidf_entity_3  Tfidf_entity_4  Tfidf_entity_5  \\\n0        0.033643        0.031206        0.006489        0.001996   \n1        0.043498        0.034004        0.020293        0.009058   \n2        0.075011        0.006661        0.028682       -0.014056   \n3        0.055338        0.008599        0.147900        0.032550   \n4        0.067515       -0.006133        0.000998       -0.049176   \n\n   Tfidf_entity_6  Tfidf_entity_7  Tfidf_entity_8  Tfidf_entity_9  \\\n0        0.018358        0.026973       -0.026971       -0.012381   \n1        0.018408        0.039855       -0.022823       -0.019452   \n2        0.008809        0.073326        0.042734        0.029835   \n3       -0.000582       -0.011612       -0.007226       -0.006741   \n4       -0.000408        0.079796        0.061995        0.016409   \n\n   Tfidf_entity_10  Tfidf_entity_11  Tfidf_entity_12  Tfidf_entity_13  \\\n0         0.024707         0.004333        -0.039479         0.044068   \n1         0.038517        -0.004993        -0.005249         0.023034   \n2         0.032328        -0.000575         0.043473        -0.021088   \n3         0.013928        -0.022664        -0.044229        -0.119552   \n4         0.012236        -0.006130        -0.013930         0.031081   \n\n   Tfidf_entity_14  Tfidf_entity_15  Tfidf_desc_0  Tfidf_desc_1  Tfidf_desc_2  \\\n0        -0.010249         0.022505      0.407822     -0.084889 -1.089434e-07   \n1         0.005372        -0.055634      0.453239      0.037524  2.554491e-07   \n2         0.003531        -0.014081      0.090822      0.366067 -1.190902e-08   \n3        -0.007308         0.032700      0.126992      0.523013  5.235827e-08   \n4         0.020328        -0.031070      0.086932      0.312147  3.389364e-07   \n\n   Tfidf_desc_3  Tfidf_desc_4  Tfidf_desc_5  Tfidf_desc_6  Tfidf_desc_7  \\\n0     -0.091383      0.002828     -0.033053      0.010067      0.129089   \n1     -0.096150     -0.018873      0.003938      0.022036      0.137500   \n2      0.014001     -0.045489      0.127677      0.370287     -0.204517   \n3      0.031607      0.179217     -0.069133      0.005489     -0.034659   \n4      0.004039      0.119461      0.124084      0.002166      0.028955   \n\n   Tfidf_desc_8  Tfidf_desc_9  Tfidf_desc_10  Tfidf_desc_11  Tfidf_desc_12  \\\n0     -0.192715     -0.037356       0.069814      -0.196362      -0.102388   \n1     -0.103271     -0.026981       0.038141      -0.057744      -0.060723   \n2     -0.131163      0.138625       0.042774      -0.023667       0.006420   \n3      0.044895     -0.043177      -0.068690      -0.192850       0.154541   \n4      0.028481     -0.068960       0.028217      -0.020259       0.028731   \n\n   Tfidf_desc_13  Tfidf_desc_14  Tfidf_desc_15  image_size_sum  \\\n0      -0.145521       0.251853      -0.114023       10.112086   \n1      -0.188502      -0.039958       0.114133       10.642110   \n2      -0.008847      -0.020395      -0.017428       11.713414   \n3       0.017752       0.012273       0.055676       12.024910   \n4       0.008358       0.001908       0.016266       11.421873   \n\n   image_size_mean  image_size_var  width_sum  width_mean  width_var  \\\n0        10.112086        0.000000   5.888878    5.888878   0.000000   \n1         9.948987       17.616508   6.551080    5.859361   8.497297   \n2         9.767553       16.296382   7.824446    5.880932   7.957927   \n3         9.945511       15.076520   8.006701    5.929589   7.670362   \n4        10.323283       18.750387   7.346655    6.249332  10.728416   \n\n   height_sum  height_mean  height_var  \n0    6.175867     6.175867    0.000000  \n1    6.656727     5.964864    5.581615  \n2    7.783641     5.840226    7.957927  \n3    7.863651     5.786897    7.670362  \n4    7.196687     6.099571    6.843039  \n\n[5 rows x 138 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Type</th>\n      <th>Name</th>\n      <th>Age</th>\n      <th>Breed1</th>\n      <th>Breed2</th>\n      <th>Gender</th>\n      <th>Color1</th>\n      <th>Color2</th>\n      <th>Color3</th>\n      <th>MaturitySize</th>\n      <th>FurLength</th>\n      <th>Vaccinated</th>\n      <th>Dewormed</th>\n      <th>Sterilized</th>\n      <th>Health</th>\n      <th>Quantity</th>\n      <th>Fee</th>\n      <th>State</th>\n      <th>RescuerID</th>\n      <th>VideoAmt</th>\n      <th>PetID</th>\n      <th>PhotoAmt</th>\n      <th>AdoptionSpeed</th>\n      <th>magnitude_sum</th>\n      <th>magnitude_mean</th>\n      <th>magnitude_var</th>\n      <th>score_sum</th>\n      <th>score_mean</th>\n      <th>score_var</th>\n      <th>document_magnitude</th>\n      <th>document_score</th>\n      <th>annot_score_SUM</th>\n      <th>annot_score_MEAN</th>\n      <th>annot_score_VAR</th>\n      <th>color_score_SUM</th>\n      <th>color_score_MEAN</th>\n      <th>color_score_VAR</th>\n      <th>pixel_frac_SUM</th>\n      <th>pixel_frac_MEAN</th>\n      <th>pixel_frac_VAR</th>\n      <th>crop_conf_SUM</th>\n      <th>crop_conf_MEAN</th>\n      <th>crop_conf_VAR</th>\n      <th>crop_importance_SUM</th>\n      <th>crop_importance_MEAN</th>\n      <th>crop_importance_VAR</th>\n      <th>specified_SUM</th>\n      <th>specified_MEAN</th>\n      <th>specified_VAR</th>\n      <th>language</th>\n      <th>main_breed_Type</th>\n      <th>main_breed_BreedName</th>\n      <th>second_breed_Type</th>\n      <th>second_breed_BreedName</th>\n      <th>len_description</th>\n      <th>len_meta_desc</th>\n      <th>len_entity</th>\n      <th>num_description_words</th>\n      <th>num_desc_words</th>\n      <th>num_entity_words</th>\n      <th>uniq_description_words</th>\n      <th>uniq_desc_words</th>\n      <th>uniq_entity_words</th>\n      <th>num_description_stopwords</th>\n      <th>...</th>\n      <th>contains_comma</th>\n      <th>start_with_number</th>\n      <th>contains_paren</th>\n      <th>contains_number</th>\n      <th>name_length</th>\n      <th>num_unlike_letters</th>\n      <th>rate_unlike_letters</th>\n      <th>Tfidf_Description_0</th>\n      <th>Tfidf_Description_1</th>\n      <th>Tfidf_Description_2</th>\n      <th>Tfidf_Description_3</th>\n      <th>Tfidf_Description_4</th>\n      <th>Tfidf_Description_5</th>\n      <th>Tfidf_Description_6</th>\n      <th>Tfidf_Description_7</th>\n      <th>Tfidf_Description_8</th>\n      <th>Tfidf_Description_9</th>\n      <th>Tfidf_Description_10</th>\n      <th>Tfidf_Description_11</th>\n      <th>Tfidf_Description_12</th>\n      <th>Tfidf_Description_13</th>\n      <th>Tfidf_Description_14</th>\n      <th>Tfidf_Description_15</th>\n      <th>Tfidf_entity_0</th>\n      <th>Tfidf_entity_1</th>\n      <th>Tfidf_entity_2</th>\n      <th>Tfidf_entity_3</th>\n      <th>Tfidf_entity_4</th>\n      <th>Tfidf_entity_5</th>\n      <th>Tfidf_entity_6</th>\n      <th>Tfidf_entity_7</th>\n      <th>Tfidf_entity_8</th>\n      <th>Tfidf_entity_9</th>\n      <th>Tfidf_entity_10</th>\n      <th>Tfidf_entity_11</th>\n      <th>Tfidf_entity_12</th>\n      <th>Tfidf_entity_13</th>\n      <th>Tfidf_entity_14</th>\n      <th>Tfidf_entity_15</th>\n      <th>Tfidf_desc_0</th>\n      <th>Tfidf_desc_1</th>\n      <th>Tfidf_desc_2</th>\n      <th>Tfidf_desc_3</th>\n      <th>Tfidf_desc_4</th>\n      <th>Tfidf_desc_5</th>\n      <th>Tfidf_desc_6</th>\n      <th>Tfidf_desc_7</th>\n      <th>Tfidf_desc_8</th>\n      <th>Tfidf_desc_9</th>\n      <th>Tfidf_desc_10</th>\n      <th>Tfidf_desc_11</th>\n      <th>Tfidf_desc_12</th>\n      <th>Tfidf_desc_13</th>\n      <th>Tfidf_desc_14</th>\n      <th>Tfidf_desc_15</th>\n      <th>image_size_sum</th>\n      <th>image_size_mean</th>\n      <th>image_size_var</th>\n      <th>width_sum</th>\n      <th>width_mean</th>\n      <th>width_var</th>\n      <th>height_sum</th>\n      <th>height_mean</th>\n      <th>height_var</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>Nibble</td>\n      <td>3</td>\n      <td>299</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>7</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>100</td>\n      <td>41326</td>\n      <td>8480853f516546f6cf33aa88cd76c379</td>\n      <td>0</td>\n      <td>86e1089a3</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.2</td>\n      <td>0.366667</td>\n      <td>0.102222</td>\n      <td>1.8</td>\n      <td>0.300000</td>\n      <td>0.146667</td>\n      <td>2.4</td>\n      <td>0.3</td>\n      <td>0.830798</td>\n      <td>0.830798</td>\n      <td>0.000000</td>\n      <td>0.074838</td>\n      <td>0.074838</td>\n      <td>0.000000</td>\n      <td>0.066331</td>\n      <td>0.066331</td>\n      <td>0.000000</td>\n      <td>0.8</td>\n      <td>0.8</td>\n      <td>0.0</td>\n      <td>1.00</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>-1</td>\n      <td>5.886104</td>\n      <td>4.718499</td>\n      <td>4.465908</td>\n      <td>4.248495</td>\n      <td>2.995732</td>\n      <td>2.639057</td>\n      <td>4.060443</td>\n      <td>2.833213</td>\n      <td>2.564949</td>\n      <td>3.555348</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.109208</td>\n      <td>-0.054788</td>\n      <td>-0.027811</td>\n      <td>-0.006133</td>\n      <td>-0.013338</td>\n      <td>0.008456</td>\n      <td>-0.020514</td>\n      <td>-0.020346</td>\n      <td>0.002814</td>\n      <td>0.028917</td>\n      <td>0.002962</td>\n      <td>-0.000095</td>\n      <td>-0.018424</td>\n      <td>-0.018280</td>\n      <td>-0.007528</td>\n      <td>0.009868</td>\n      <td>0.000037</td>\n      <td>0.013053</td>\n      <td>0.033643</td>\n      <td>0.031206</td>\n      <td>0.006489</td>\n      <td>0.001996</td>\n      <td>0.018358</td>\n      <td>0.026973</td>\n      <td>-0.026971</td>\n      <td>-0.012381</td>\n      <td>0.024707</td>\n      <td>0.004333</td>\n      <td>-0.039479</td>\n      <td>0.044068</td>\n      <td>-0.010249</td>\n      <td>0.022505</td>\n      <td>0.407822</td>\n      <td>-0.084889</td>\n      <td>-1.089434e-07</td>\n      <td>-0.091383</td>\n      <td>0.002828</td>\n      <td>-0.033053</td>\n      <td>0.010067</td>\n      <td>0.129089</td>\n      <td>-0.192715</td>\n      <td>-0.037356</td>\n      <td>0.069814</td>\n      <td>-0.196362</td>\n      <td>-0.102388</td>\n      <td>-0.145521</td>\n      <td>0.251853</td>\n      <td>-0.114023</td>\n      <td>10.112086</td>\n      <td>10.112086</td>\n      <td>0.000000</td>\n      <td>5.888878</td>\n      <td>5.888878</td>\n      <td>0.000000</td>\n      <td>6.175867</td>\n      <td>6.175867</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>No Name Yet</td>\n      <td>1</td>\n      <td>265</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>41401</td>\n      <td>3082c7125d8fb66f7dd4bff4192c8b14</td>\n      <td>0</td>\n      <td>6296e909a</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.7</td>\n      <td>0.350000</td>\n      <td>0.062500</td>\n      <td>-0.5</td>\n      <td>-0.250000</td>\n      <td>0.122500</td>\n      <td>0.7</td>\n      <td>-0.2</td>\n      <td>1.590916</td>\n      <td>0.795458</td>\n      <td>0.000119</td>\n      <td>0.183415</td>\n      <td>0.091708</td>\n      <td>0.000038</td>\n      <td>0.127362</td>\n      <td>0.063681</td>\n      <td>0.000039</td>\n      <td>1.6</td>\n      <td>0.8</td>\n      <td>0.0</td>\n      <td>2.00</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>-1</td>\n      <td>4.779123</td>\n      <td>5.361292</td>\n      <td>2.708050</td>\n      <td>3.178054</td>\n      <td>3.637586</td>\n      <td>1.098612</td>\n      <td>3.044522</td>\n      <td>3.091042</td>\n      <td>1.098612</td>\n      <td>2.564949</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>11</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.065635</td>\n      <td>-0.042643</td>\n      <td>-0.019198</td>\n      <td>-0.002690</td>\n      <td>-0.004885</td>\n      <td>0.022908</td>\n      <td>-0.022137</td>\n      <td>-0.042913</td>\n      <td>-0.023930</td>\n      <td>0.026311</td>\n      <td>0.013061</td>\n      <td>0.022925</td>\n      <td>-0.015762</td>\n      <td>-0.027501</td>\n      <td>0.013893</td>\n      <td>0.034890</td>\n      <td>0.000029</td>\n      <td>0.016604</td>\n      <td>0.043498</td>\n      <td>0.034004</td>\n      <td>0.020293</td>\n      <td>0.009058</td>\n      <td>0.018408</td>\n      <td>0.039855</td>\n      <td>-0.022823</td>\n      <td>-0.019452</td>\n      <td>0.038517</td>\n      <td>-0.004993</td>\n      <td>-0.005249</td>\n      <td>0.023034</td>\n      <td>0.005372</td>\n      <td>-0.055634</td>\n      <td>0.453239</td>\n      <td>0.037524</td>\n      <td>2.554491e-07</td>\n      <td>-0.096150</td>\n      <td>-0.018873</td>\n      <td>0.003938</td>\n      <td>0.022036</td>\n      <td>0.137500</td>\n      <td>-0.103271</td>\n      <td>-0.026981</td>\n      <td>0.038141</td>\n      <td>-0.057744</td>\n      <td>-0.060723</td>\n      <td>-0.188502</td>\n      <td>-0.039958</td>\n      <td>0.114133</td>\n      <td>10.642110</td>\n      <td>9.948987</td>\n      <td>17.616508</td>\n      <td>6.551080</td>\n      <td>5.859361</td>\n      <td>8.497297</td>\n      <td>6.656727</td>\n      <td>5.964864</td>\n      <td>5.581615</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>Brisco</td>\n      <td>1</td>\n      <td>307</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>7</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>41326</td>\n      <td>fa90fa5b1ee11c86938398b60abc32cb</td>\n      <td>0</td>\n      <td>3422e4906</td>\n      <td>7.0</td>\n      <td>3.0</td>\n      <td>3.4</td>\n      <td>0.485714</td>\n      <td>0.124082</td>\n      <td>1.4</td>\n      <td>0.200000</td>\n      <td>0.320000</td>\n      <td>3.7</td>\n      <td>0.2</td>\n      <td>5.522756</td>\n      <td>0.788965</td>\n      <td>0.001047</td>\n      <td>0.660042</td>\n      <td>0.094292</td>\n      <td>0.000041</td>\n      <td>0.514481</td>\n      <td>0.073497</td>\n      <td>0.000452</td>\n      <td>5.6</td>\n      <td>0.8</td>\n      <td>0.0</td>\n      <td>7.00</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>7.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>-1</td>\n      <td>5.976351</td>\n      <td>6.752270</td>\n      <td>4.595120</td>\n      <td>4.248495</td>\n      <td>4.912655</td>\n      <td>2.772589</td>\n      <td>4.110874</td>\n      <td>3.218876</td>\n      <td>2.708050</td>\n      <td>3.433987</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.124596</td>\n      <td>-0.060786</td>\n      <td>0.065617</td>\n      <td>-0.003723</td>\n      <td>0.024301</td>\n      <td>-0.002590</td>\n      <td>0.231682</td>\n      <td>-0.161545</td>\n      <td>0.042858</td>\n      <td>-0.022786</td>\n      <td>-0.046409</td>\n      <td>0.007761</td>\n      <td>0.025377</td>\n      <td>-0.034746</td>\n      <td>-0.046306</td>\n      <td>-0.016597</td>\n      <td>0.000040</td>\n      <td>0.025495</td>\n      <td>0.075011</td>\n      <td>0.006661</td>\n      <td>0.028682</td>\n      <td>-0.014056</td>\n      <td>0.008809</td>\n      <td>0.073326</td>\n      <td>0.042734</td>\n      <td>0.029835</td>\n      <td>0.032328</td>\n      <td>-0.000575</td>\n      <td>0.043473</td>\n      <td>-0.021088</td>\n      <td>0.003531</td>\n      <td>-0.014081</td>\n      <td>0.090822</td>\n      <td>0.366067</td>\n      <td>-1.190902e-08</td>\n      <td>0.014001</td>\n      <td>-0.045489</td>\n      <td>0.127677</td>\n      <td>0.370287</td>\n      <td>-0.204517</td>\n      <td>-0.131163</td>\n      <td>0.138625</td>\n      <td>0.042774</td>\n      <td>-0.023667</td>\n      <td>0.006420</td>\n      <td>-0.008847</td>\n      <td>-0.020395</td>\n      <td>-0.017428</td>\n      <td>11.713414</td>\n      <td>9.767553</td>\n      <td>16.296382</td>\n      <td>7.824446</td>\n      <td>5.880932</td>\n      <td>7.957927</td>\n      <td>7.783641</td>\n      <td>5.840226</td>\n      <td>7.957927</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>Miko</td>\n      <td>4</td>\n      <td>307</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>150</td>\n      <td>41401</td>\n      <td>9238e4f44c71a75282e62f7136c6b240</td>\n      <td>0</td>\n      <td>5842f1ff5</td>\n      <td>8.0</td>\n      <td>2.0</td>\n      <td>0.9</td>\n      <td>0.900000</td>\n      <td>0.000000</td>\n      <td>0.9</td>\n      <td>0.900000</td>\n      <td>0.000000</td>\n      <td>0.9</td>\n      <td>0.9</td>\n      <td>6.045986</td>\n      <td>0.755748</td>\n      <td>0.000221</td>\n      <td>0.660390</td>\n      <td>0.082549</td>\n      <td>0.000278</td>\n      <td>0.548335</td>\n      <td>0.068542</td>\n      <td>0.000571</td>\n      <td>6.4</td>\n      <td>0.8</td>\n      <td>0.0</td>\n      <td>8.00</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>-1</td>\n      <td>4.990433</td>\n      <td>6.779922</td>\n      <td>3.784190</td>\n      <td>3.258097</td>\n      <td>4.955827</td>\n      <td>2.079442</td>\n      <td>3.218876</td>\n      <td>3.091042</td>\n      <td>2.079442</td>\n      <td>2.197225</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.081360</td>\n      <td>-0.021896</td>\n      <td>-0.001674</td>\n      <td>0.011284</td>\n      <td>0.010215</td>\n      <td>-0.012603</td>\n      <td>0.032462</td>\n      <td>0.026343</td>\n      <td>-0.001419</td>\n      <td>-0.033471</td>\n      <td>-0.045353</td>\n      <td>-0.002096</td>\n      <td>0.040378</td>\n      <td>0.012599</td>\n      <td>0.027032</td>\n      <td>0.011449</td>\n      <td>0.000029</td>\n      <td>0.033364</td>\n      <td>0.055338</td>\n      <td>0.008599</td>\n      <td>0.147900</td>\n      <td>0.032550</td>\n      <td>-0.000582</td>\n      <td>-0.011612</td>\n      <td>-0.007226</td>\n      <td>-0.006741</td>\n      <td>0.013928</td>\n      <td>-0.022664</td>\n      <td>-0.044229</td>\n      <td>-0.119552</td>\n      <td>-0.007308</td>\n      <td>0.032700</td>\n      <td>0.126992</td>\n      <td>0.523013</td>\n      <td>5.235827e-08</td>\n      <td>0.031607</td>\n      <td>0.179217</td>\n      <td>-0.069133</td>\n      <td>0.005489</td>\n      <td>-0.034659</td>\n      <td>0.044895</td>\n      <td>-0.043177</td>\n      <td>-0.068690</td>\n      <td>-0.192850</td>\n      <td>0.154541</td>\n      <td>0.017752</td>\n      <td>0.012273</td>\n      <td>0.055676</td>\n      <td>12.024910</td>\n      <td>9.945511</td>\n      <td>15.076520</td>\n      <td>8.006701</td>\n      <td>5.929589</td>\n      <td>7.670362</td>\n      <td>7.863651</td>\n      <td>5.786897</td>\n      <td>7.670362</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>Hunter</td>\n      <td>1</td>\n      <td>307</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>41326</td>\n      <td>95481e953f8aed9ec3d16fc4509537e8</td>\n      <td>0</td>\n      <td>850a43f90</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>3.5</td>\n      <td>0.583333</td>\n      <td>0.071389</td>\n      <td>3.5</td>\n      <td>0.583333</td>\n      <td>0.071389</td>\n      <td>3.7</td>\n      <td>0.6</td>\n      <td>2.326006</td>\n      <td>0.775335</td>\n      <td>0.011257</td>\n      <td>0.239312</td>\n      <td>0.079771</td>\n      <td>0.000075</td>\n      <td>0.128066</td>\n      <td>0.042689</td>\n      <td>0.000016</td>\n      <td>2.4</td>\n      <td>0.8</td>\n      <td>0.0</td>\n      <td>2.98</td>\n      <td>0.993333</td>\n      <td>0.000133</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>-1</td>\n      <td>5.968708</td>\n      <td>5.746203</td>\n      <td>4.356709</td>\n      <td>4.406719</td>\n      <td>3.912023</td>\n      <td>2.639057</td>\n      <td>4.189655</td>\n      <td>2.995732</td>\n      <td>2.639057</td>\n      <td>3.761200</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.189465</td>\n      <td>-0.045537</td>\n      <td>-0.010977</td>\n      <td>-0.009483</td>\n      <td>-0.011833</td>\n      <td>-0.013234</td>\n      <td>-0.024864</td>\n      <td>0.024887</td>\n      <td>0.018768</td>\n      <td>0.090536</td>\n      <td>-0.081798</td>\n      <td>-0.017550</td>\n      <td>0.044352</td>\n      <td>-0.006712</td>\n      <td>-0.009167</td>\n      <td>0.011911</td>\n      <td>0.000053</td>\n      <td>0.111890</td>\n      <td>0.067515</td>\n      <td>-0.006133</td>\n      <td>0.000998</td>\n      <td>-0.049176</td>\n      <td>-0.000408</td>\n      <td>0.079796</td>\n      <td>0.061995</td>\n      <td>0.016409</td>\n      <td>0.012236</td>\n      <td>-0.006130</td>\n      <td>-0.013930</td>\n      <td>0.031081</td>\n      <td>0.020328</td>\n      <td>-0.031070</td>\n      <td>0.086932</td>\n      <td>0.312147</td>\n      <td>3.389364e-07</td>\n      <td>0.004039</td>\n      <td>0.119461</td>\n      <td>0.124084</td>\n      <td>0.002166</td>\n      <td>0.028955</td>\n      <td>0.028481</td>\n      <td>-0.068960</td>\n      <td>0.028217</td>\n      <td>-0.020259</td>\n      <td>0.028731</td>\n      <td>0.008358</td>\n      <td>0.001908</td>\n      <td>0.016266</td>\n      <td>11.421873</td>\n      <td>10.323283</td>\n      <td>18.750387</td>\n      <td>7.346655</td>\n      <td>6.249332</td>\n      <td>10.728416</td>\n      <td>7.196687</td>\n      <td>6.099571</td>\n      <td>6.843039</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 138 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"_uuid":"629ec15f165fb4faf8051671f07abfaa2e6872df"},"cell_type":"markdown","source":"## Drop columns"},{"metadata":{"trusted":true,"_uuid":"d720a05abf06196c89ba7e21df7f4387f6cf8e72"},"cell_type":"code","source":"train_resc = train.RescuerID\ntest_resc = test.RescuerID","execution_count":33,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0034fb4f78cd5cc6c26a762642deb73276303c9e"},"cell_type":"code","source":"X_temp.drop(drop_columns, axis=1, inplace=True)\nX_temp.head()","execution_count":34,"outputs":[{"output_type":"execute_result","execution_count":34,"data":{"text/plain":"   Type  Age  Breed1  Breed2  Gender  Color1  Color2  Color3  MaturitySize  \\\n0     2    3     299       0       1       1       7       0             1   \n1     2    1     265       0       1       1       2       0             2   \n2     1    1     307       0       1       2       7       0             2   \n3     1    4     307       0       2       1       2       0             2   \n4     1    1     307       0       1       1       0       0             2   \n\n   FurLength  Vaccinated  Dewormed  Sterilized  Health  Quantity  Fee  State  \\\n0          1           2         2           2       1         1  100  41326   \n1          2           3         3           3       1         1    0  41401   \n2          2           1         1           2       1         1    0  41326   \n3          1           1         1           2       1         1  150  41401   \n4          1           2         2           2       1         1    0  41326   \n\n   VideoAmt  PhotoAmt  AdoptionSpeed  magnitude_sum  magnitude_mean  \\\n0         0       1.0            2.0            2.2        0.366667   \n1         0       2.0            0.0            0.7        0.350000   \n2         0       7.0            3.0            3.4        0.485714   \n3         0       8.0            2.0            0.9        0.900000   \n4         0       3.0            2.0            3.5        0.583333   \n\n   magnitude_var  score_sum  score_mean  score_var  document_magnitude  \\\n0       0.102222        1.8    0.300000   0.146667                 2.4   \n1       0.062500       -0.5   -0.250000   0.122500                 0.7   \n2       0.124082        1.4    0.200000   0.320000                 3.7   \n3       0.000000        0.9    0.900000   0.000000                 0.9   \n4       0.071389        3.5    0.583333   0.071389                 3.7   \n\n   document_score  annot_score_SUM  annot_score_MEAN  annot_score_VAR  \\\n0             0.3         0.830798          0.830798         0.000000   \n1            -0.2         1.590916          0.795458         0.000119   \n2             0.2         5.522756          0.788965         0.001047   \n3             0.9         6.045986          0.755748         0.000221   \n4             0.6         2.326006          0.775335         0.011257   \n\n   color_score_SUM  color_score_MEAN  color_score_VAR  pixel_frac_SUM  \\\n0         0.074838          0.074838         0.000000        0.066331   \n1         0.183415          0.091708         0.000038        0.127362   \n2         0.660042          0.094292         0.000041        0.514481   \n3         0.660390          0.082549         0.000278        0.548335   \n4         0.239312          0.079771         0.000075        0.128066   \n\n   pixel_frac_MEAN  pixel_frac_VAR  crop_conf_SUM  crop_conf_MEAN  \\\n0         0.066331        0.000000            0.8             0.8   \n1         0.063681        0.000039            1.6             0.8   \n2         0.073497        0.000452            5.6             0.8   \n3         0.068542        0.000571            6.4             0.8   \n4         0.042689        0.000016            2.4             0.8   \n\n   crop_conf_VAR  crop_importance_SUM  crop_importance_MEAN  \\\n0            0.0                 1.00              1.000000   \n1            0.0                 2.00              1.000000   \n2            0.0                 7.00              1.000000   \n3            0.0                 8.00              1.000000   \n4            0.0                 2.98              0.993333   \n\n   crop_importance_VAR  specified_SUM  specified_MEAN  specified_VAR  \\\n0             0.000000            1.0             1.0            0.0   \n1             0.000000            2.0             1.0            0.0   \n2             0.000000            7.0             1.0            0.0   \n3             0.000000            8.0             1.0            0.0   \n4             0.000133            3.0             1.0            0.0   \n\n   language  main_breed_Type  main_breed_BreedName  second_breed_Type  \\\n0         0              2.0                     0                0.0   \n1         0              2.0                     1                0.0   \n2         0              1.0                     2                0.0   \n3         0              1.0                     2                0.0   \n4         0              1.0                     2                0.0   \n\n   second_breed_BreedName  len_description  len_meta_desc  len_entity  \\\n0                      -1         5.886104       4.718499    4.465908   \n1                      -1         4.779123       5.361292    2.708050   \n2                      -1         5.976351       6.752270    4.595120   \n3                      -1         4.990433       6.779922    3.784190   \n4                      -1         5.968708       5.746203    4.356709   \n\n   num_description_words  num_desc_words  num_entity_words  \\\n0               4.248495        2.995732          2.639057   \n1               3.178054        3.637586          1.098612   \n2               4.248495        4.912655          2.772589   \n3               3.258097        4.955827          2.079442   \n4               4.406719        3.912023          2.639057   \n\n   uniq_description_words  uniq_desc_words  uniq_entity_words  \\\n0                4.060443         2.833213           2.564949   \n1                3.044522         3.091042           1.098612   \n2                4.110874         3.218876           2.708050   \n3                3.218876         3.091042           2.079442   \n4                4.189655         2.995732           2.639057   \n\n   num_description_stopwords  num_desc_stopwords  num_entity_stopwords  \\\n0                   3.555348            0.693147                   0.0   \n1                   2.564949            1.098612                   0.0   \n2                   3.433987            0.000000                   0.0   \n3                   2.197225            0.000000                   0.0   \n4                   3.761200            0.000000                   0.0   \n\n   num_description_punctuation     ...      contains_comma  start_with_number  \\\n0                     2.197225     ...                   0                  0   \n1                     1.098612     ...                   0                  0   \n2                     2.302585     ...                   0                  0   \n3                     2.079442     ...                   0                  0   \n4                     2.302585     ...                   0                  0   \n\n   contains_paren  contains_number  name_length  num_unlike_letters  \\\n0               0                0            6                   0   \n1               0                0           11                   0   \n2               0                0            6                   0   \n3               0                0            4                   0   \n4               0                0            6                   0   \n\n   rate_unlike_letters  Tfidf_Description_0  Tfidf_Description_1  \\\n0                  0.0             0.109208            -0.054788   \n1                  0.0             0.065635            -0.042643   \n2                  0.0             0.124596            -0.060786   \n3                  0.0             0.081360            -0.021896   \n4                  0.0             0.189465            -0.045537   \n\n   Tfidf_Description_2  Tfidf_Description_3  Tfidf_Description_4  \\\n0            -0.027811            -0.006133            -0.013338   \n1            -0.019198            -0.002690            -0.004885   \n2             0.065617            -0.003723             0.024301   \n3            -0.001674             0.011284             0.010215   \n4            -0.010977            -0.009483            -0.011833   \n\n   Tfidf_Description_5  Tfidf_Description_6  Tfidf_Description_7  \\\n0             0.008456            -0.020514            -0.020346   \n1             0.022908            -0.022137            -0.042913   \n2            -0.002590             0.231682            -0.161545   \n3            -0.012603             0.032462             0.026343   \n4            -0.013234            -0.024864             0.024887   \n\n   Tfidf_Description_8  Tfidf_Description_9  Tfidf_Description_10  \\\n0             0.002814             0.028917              0.002962   \n1            -0.023930             0.026311              0.013061   \n2             0.042858            -0.022786             -0.046409   \n3            -0.001419            -0.033471             -0.045353   \n4             0.018768             0.090536             -0.081798   \n\n   Tfidf_Description_11  Tfidf_Description_12  Tfidf_Description_13  \\\n0             -0.000095             -0.018424             -0.018280   \n1              0.022925             -0.015762             -0.027501   \n2              0.007761              0.025377             -0.034746   \n3             -0.002096              0.040378              0.012599   \n4             -0.017550              0.044352             -0.006712   \n\n   Tfidf_Description_14  Tfidf_Description_15  Tfidf_entity_0  Tfidf_entity_1  \\\n0             -0.007528              0.009868        0.000037        0.013053   \n1              0.013893              0.034890        0.000029        0.016604   \n2             -0.046306             -0.016597        0.000040        0.025495   \n3              0.027032              0.011449        0.000029        0.033364   \n4             -0.009167              0.011911        0.000053        0.111890   \n\n   Tfidf_entity_2  Tfidf_entity_3  Tfidf_entity_4  Tfidf_entity_5  \\\n0        0.033643        0.031206        0.006489        0.001996   \n1        0.043498        0.034004        0.020293        0.009058   \n2        0.075011        0.006661        0.028682       -0.014056   \n3        0.055338        0.008599        0.147900        0.032550   \n4        0.067515       -0.006133        0.000998       -0.049176   \n\n   Tfidf_entity_6  Tfidf_entity_7  Tfidf_entity_8  Tfidf_entity_9  \\\n0        0.018358        0.026973       -0.026971       -0.012381   \n1        0.018408        0.039855       -0.022823       -0.019452   \n2        0.008809        0.073326        0.042734        0.029835   \n3       -0.000582       -0.011612       -0.007226       -0.006741   \n4       -0.000408        0.079796        0.061995        0.016409   \n\n   Tfidf_entity_10  Tfidf_entity_11  Tfidf_entity_12  Tfidf_entity_13  \\\n0         0.024707         0.004333        -0.039479         0.044068   \n1         0.038517        -0.004993        -0.005249         0.023034   \n2         0.032328        -0.000575         0.043473        -0.021088   \n3         0.013928        -0.022664        -0.044229        -0.119552   \n4         0.012236        -0.006130        -0.013930         0.031081   \n\n   Tfidf_entity_14  Tfidf_entity_15  Tfidf_desc_0  Tfidf_desc_1  Tfidf_desc_2  \\\n0        -0.010249         0.022505      0.407822     -0.084889 -1.089434e-07   \n1         0.005372        -0.055634      0.453239      0.037524  2.554491e-07   \n2         0.003531        -0.014081      0.090822      0.366067 -1.190902e-08   \n3        -0.007308         0.032700      0.126992      0.523013  5.235827e-08   \n4         0.020328        -0.031070      0.086932      0.312147  3.389364e-07   \n\n   Tfidf_desc_3  Tfidf_desc_4  Tfidf_desc_5  Tfidf_desc_6  Tfidf_desc_7  \\\n0     -0.091383      0.002828     -0.033053      0.010067      0.129089   \n1     -0.096150     -0.018873      0.003938      0.022036      0.137500   \n2      0.014001     -0.045489      0.127677      0.370287     -0.204517   \n3      0.031607      0.179217     -0.069133      0.005489     -0.034659   \n4      0.004039      0.119461      0.124084      0.002166      0.028955   \n\n   Tfidf_desc_8  Tfidf_desc_9  Tfidf_desc_10  Tfidf_desc_11  Tfidf_desc_12  \\\n0     -0.192715     -0.037356       0.069814      -0.196362      -0.102388   \n1     -0.103271     -0.026981       0.038141      -0.057744      -0.060723   \n2     -0.131163      0.138625       0.042774      -0.023667       0.006420   \n3      0.044895     -0.043177      -0.068690      -0.192850       0.154541   \n4      0.028481     -0.068960       0.028217      -0.020259       0.028731   \n\n   Tfidf_desc_13  Tfidf_desc_14  Tfidf_desc_15  image_size_sum  \\\n0      -0.145521       0.251853      -0.114023       10.112086   \n1      -0.188502      -0.039958       0.114133       10.642110   \n2      -0.008847      -0.020395      -0.017428       11.713414   \n3       0.017752       0.012273       0.055676       12.024910   \n4       0.008358       0.001908       0.016266       11.421873   \n\n   image_size_mean  image_size_var  width_sum  width_mean  width_var  \\\n0        10.112086        0.000000   5.888878    5.888878   0.000000   \n1         9.948987       17.616508   6.551080    5.859361   8.497297   \n2         9.767553       16.296382   7.824446    5.880932   7.957927   \n3         9.945511       15.076520   8.006701    5.929589   7.670362   \n4        10.323283       18.750387   7.346655    6.249332  10.728416   \n\n   height_sum  height_mean  height_var  \n0    6.175867     6.175867    0.000000  \n1    6.656727     5.964864    5.581615  \n2    7.783641     5.840226    7.957927  \n3    7.863651     5.786897    7.670362  \n4    7.196687     6.099571    6.843039  \n\n[5 rows x 135 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Type</th>\n      <th>Age</th>\n      <th>Breed1</th>\n      <th>Breed2</th>\n      <th>Gender</th>\n      <th>Color1</th>\n      <th>Color2</th>\n      <th>Color3</th>\n      <th>MaturitySize</th>\n      <th>FurLength</th>\n      <th>Vaccinated</th>\n      <th>Dewormed</th>\n      <th>Sterilized</th>\n      <th>Health</th>\n      <th>Quantity</th>\n      <th>Fee</th>\n      <th>State</th>\n      <th>VideoAmt</th>\n      <th>PhotoAmt</th>\n      <th>AdoptionSpeed</th>\n      <th>magnitude_sum</th>\n      <th>magnitude_mean</th>\n      <th>magnitude_var</th>\n      <th>score_sum</th>\n      <th>score_mean</th>\n      <th>score_var</th>\n      <th>document_magnitude</th>\n      <th>document_score</th>\n      <th>annot_score_SUM</th>\n      <th>annot_score_MEAN</th>\n      <th>annot_score_VAR</th>\n      <th>color_score_SUM</th>\n      <th>color_score_MEAN</th>\n      <th>color_score_VAR</th>\n      <th>pixel_frac_SUM</th>\n      <th>pixel_frac_MEAN</th>\n      <th>pixel_frac_VAR</th>\n      <th>crop_conf_SUM</th>\n      <th>crop_conf_MEAN</th>\n      <th>crop_conf_VAR</th>\n      <th>crop_importance_SUM</th>\n      <th>crop_importance_MEAN</th>\n      <th>crop_importance_VAR</th>\n      <th>specified_SUM</th>\n      <th>specified_MEAN</th>\n      <th>specified_VAR</th>\n      <th>language</th>\n      <th>main_breed_Type</th>\n      <th>main_breed_BreedName</th>\n      <th>second_breed_Type</th>\n      <th>second_breed_BreedName</th>\n      <th>len_description</th>\n      <th>len_meta_desc</th>\n      <th>len_entity</th>\n      <th>num_description_words</th>\n      <th>num_desc_words</th>\n      <th>num_entity_words</th>\n      <th>uniq_description_words</th>\n      <th>uniq_desc_words</th>\n      <th>uniq_entity_words</th>\n      <th>num_description_stopwords</th>\n      <th>num_desc_stopwords</th>\n      <th>num_entity_stopwords</th>\n      <th>num_description_punctuation</th>\n      <th>...</th>\n      <th>contains_comma</th>\n      <th>start_with_number</th>\n      <th>contains_paren</th>\n      <th>contains_number</th>\n      <th>name_length</th>\n      <th>num_unlike_letters</th>\n      <th>rate_unlike_letters</th>\n      <th>Tfidf_Description_0</th>\n      <th>Tfidf_Description_1</th>\n      <th>Tfidf_Description_2</th>\n      <th>Tfidf_Description_3</th>\n      <th>Tfidf_Description_4</th>\n      <th>Tfidf_Description_5</th>\n      <th>Tfidf_Description_6</th>\n      <th>Tfidf_Description_7</th>\n      <th>Tfidf_Description_8</th>\n      <th>Tfidf_Description_9</th>\n      <th>Tfidf_Description_10</th>\n      <th>Tfidf_Description_11</th>\n      <th>Tfidf_Description_12</th>\n      <th>Tfidf_Description_13</th>\n      <th>Tfidf_Description_14</th>\n      <th>Tfidf_Description_15</th>\n      <th>Tfidf_entity_0</th>\n      <th>Tfidf_entity_1</th>\n      <th>Tfidf_entity_2</th>\n      <th>Tfidf_entity_3</th>\n      <th>Tfidf_entity_4</th>\n      <th>Tfidf_entity_5</th>\n      <th>Tfidf_entity_6</th>\n      <th>Tfidf_entity_7</th>\n      <th>Tfidf_entity_8</th>\n      <th>Tfidf_entity_9</th>\n      <th>Tfidf_entity_10</th>\n      <th>Tfidf_entity_11</th>\n      <th>Tfidf_entity_12</th>\n      <th>Tfidf_entity_13</th>\n      <th>Tfidf_entity_14</th>\n      <th>Tfidf_entity_15</th>\n      <th>Tfidf_desc_0</th>\n      <th>Tfidf_desc_1</th>\n      <th>Tfidf_desc_2</th>\n      <th>Tfidf_desc_3</th>\n      <th>Tfidf_desc_4</th>\n      <th>Tfidf_desc_5</th>\n      <th>Tfidf_desc_6</th>\n      <th>Tfidf_desc_7</th>\n      <th>Tfidf_desc_8</th>\n      <th>Tfidf_desc_9</th>\n      <th>Tfidf_desc_10</th>\n      <th>Tfidf_desc_11</th>\n      <th>Tfidf_desc_12</th>\n      <th>Tfidf_desc_13</th>\n      <th>Tfidf_desc_14</th>\n      <th>Tfidf_desc_15</th>\n      <th>image_size_sum</th>\n      <th>image_size_mean</th>\n      <th>image_size_var</th>\n      <th>width_sum</th>\n      <th>width_mean</th>\n      <th>width_var</th>\n      <th>height_sum</th>\n      <th>height_mean</th>\n      <th>height_var</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>3</td>\n      <td>299</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>7</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>100</td>\n      <td>41326</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.2</td>\n      <td>0.366667</td>\n      <td>0.102222</td>\n      <td>1.8</td>\n      <td>0.300000</td>\n      <td>0.146667</td>\n      <td>2.4</td>\n      <td>0.3</td>\n      <td>0.830798</td>\n      <td>0.830798</td>\n      <td>0.000000</td>\n      <td>0.074838</td>\n      <td>0.074838</td>\n      <td>0.000000</td>\n      <td>0.066331</td>\n      <td>0.066331</td>\n      <td>0.000000</td>\n      <td>0.8</td>\n      <td>0.8</td>\n      <td>0.0</td>\n      <td>1.00</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>-1</td>\n      <td>5.886104</td>\n      <td>4.718499</td>\n      <td>4.465908</td>\n      <td>4.248495</td>\n      <td>2.995732</td>\n      <td>2.639057</td>\n      <td>4.060443</td>\n      <td>2.833213</td>\n      <td>2.564949</td>\n      <td>3.555348</td>\n      <td>0.693147</td>\n      <td>0.0</td>\n      <td>2.197225</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.109208</td>\n      <td>-0.054788</td>\n      <td>-0.027811</td>\n      <td>-0.006133</td>\n      <td>-0.013338</td>\n      <td>0.008456</td>\n      <td>-0.020514</td>\n      <td>-0.020346</td>\n      <td>0.002814</td>\n      <td>0.028917</td>\n      <td>0.002962</td>\n      <td>-0.000095</td>\n      <td>-0.018424</td>\n      <td>-0.018280</td>\n      <td>-0.007528</td>\n      <td>0.009868</td>\n      <td>0.000037</td>\n      <td>0.013053</td>\n      <td>0.033643</td>\n      <td>0.031206</td>\n      <td>0.006489</td>\n      <td>0.001996</td>\n      <td>0.018358</td>\n      <td>0.026973</td>\n      <td>-0.026971</td>\n      <td>-0.012381</td>\n      <td>0.024707</td>\n      <td>0.004333</td>\n      <td>-0.039479</td>\n      <td>0.044068</td>\n      <td>-0.010249</td>\n      <td>0.022505</td>\n      <td>0.407822</td>\n      <td>-0.084889</td>\n      <td>-1.089434e-07</td>\n      <td>-0.091383</td>\n      <td>0.002828</td>\n      <td>-0.033053</td>\n      <td>0.010067</td>\n      <td>0.129089</td>\n      <td>-0.192715</td>\n      <td>-0.037356</td>\n      <td>0.069814</td>\n      <td>-0.196362</td>\n      <td>-0.102388</td>\n      <td>-0.145521</td>\n      <td>0.251853</td>\n      <td>-0.114023</td>\n      <td>10.112086</td>\n      <td>10.112086</td>\n      <td>0.000000</td>\n      <td>5.888878</td>\n      <td>5.888878</td>\n      <td>0.000000</td>\n      <td>6.175867</td>\n      <td>6.175867</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>265</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>41401</td>\n      <td>0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.7</td>\n      <td>0.350000</td>\n      <td>0.062500</td>\n      <td>-0.5</td>\n      <td>-0.250000</td>\n      <td>0.122500</td>\n      <td>0.7</td>\n      <td>-0.2</td>\n      <td>1.590916</td>\n      <td>0.795458</td>\n      <td>0.000119</td>\n      <td>0.183415</td>\n      <td>0.091708</td>\n      <td>0.000038</td>\n      <td>0.127362</td>\n      <td>0.063681</td>\n      <td>0.000039</td>\n      <td>1.6</td>\n      <td>0.8</td>\n      <td>0.0</td>\n      <td>2.00</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>-1</td>\n      <td>4.779123</td>\n      <td>5.361292</td>\n      <td>2.708050</td>\n      <td>3.178054</td>\n      <td>3.637586</td>\n      <td>1.098612</td>\n      <td>3.044522</td>\n      <td>3.091042</td>\n      <td>1.098612</td>\n      <td>2.564949</td>\n      <td>1.098612</td>\n      <td>0.0</td>\n      <td>1.098612</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>11</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.065635</td>\n      <td>-0.042643</td>\n      <td>-0.019198</td>\n      <td>-0.002690</td>\n      <td>-0.004885</td>\n      <td>0.022908</td>\n      <td>-0.022137</td>\n      <td>-0.042913</td>\n      <td>-0.023930</td>\n      <td>0.026311</td>\n      <td>0.013061</td>\n      <td>0.022925</td>\n      <td>-0.015762</td>\n      <td>-0.027501</td>\n      <td>0.013893</td>\n      <td>0.034890</td>\n      <td>0.000029</td>\n      <td>0.016604</td>\n      <td>0.043498</td>\n      <td>0.034004</td>\n      <td>0.020293</td>\n      <td>0.009058</td>\n      <td>0.018408</td>\n      <td>0.039855</td>\n      <td>-0.022823</td>\n      <td>-0.019452</td>\n      <td>0.038517</td>\n      <td>-0.004993</td>\n      <td>-0.005249</td>\n      <td>0.023034</td>\n      <td>0.005372</td>\n      <td>-0.055634</td>\n      <td>0.453239</td>\n      <td>0.037524</td>\n      <td>2.554491e-07</td>\n      <td>-0.096150</td>\n      <td>-0.018873</td>\n      <td>0.003938</td>\n      <td>0.022036</td>\n      <td>0.137500</td>\n      <td>-0.103271</td>\n      <td>-0.026981</td>\n      <td>0.038141</td>\n      <td>-0.057744</td>\n      <td>-0.060723</td>\n      <td>-0.188502</td>\n      <td>-0.039958</td>\n      <td>0.114133</td>\n      <td>10.642110</td>\n      <td>9.948987</td>\n      <td>17.616508</td>\n      <td>6.551080</td>\n      <td>5.859361</td>\n      <td>8.497297</td>\n      <td>6.656727</td>\n      <td>5.964864</td>\n      <td>5.581615</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1</td>\n      <td>307</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>7</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>41326</td>\n      <td>0</td>\n      <td>7.0</td>\n      <td>3.0</td>\n      <td>3.4</td>\n      <td>0.485714</td>\n      <td>0.124082</td>\n      <td>1.4</td>\n      <td>0.200000</td>\n      <td>0.320000</td>\n      <td>3.7</td>\n      <td>0.2</td>\n      <td>5.522756</td>\n      <td>0.788965</td>\n      <td>0.001047</td>\n      <td>0.660042</td>\n      <td>0.094292</td>\n      <td>0.000041</td>\n      <td>0.514481</td>\n      <td>0.073497</td>\n      <td>0.000452</td>\n      <td>5.6</td>\n      <td>0.8</td>\n      <td>0.0</td>\n      <td>7.00</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>7.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>-1</td>\n      <td>5.976351</td>\n      <td>6.752270</td>\n      <td>4.595120</td>\n      <td>4.248495</td>\n      <td>4.912655</td>\n      <td>2.772589</td>\n      <td>4.110874</td>\n      <td>3.218876</td>\n      <td>2.708050</td>\n      <td>3.433987</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>2.302585</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.124596</td>\n      <td>-0.060786</td>\n      <td>0.065617</td>\n      <td>-0.003723</td>\n      <td>0.024301</td>\n      <td>-0.002590</td>\n      <td>0.231682</td>\n      <td>-0.161545</td>\n      <td>0.042858</td>\n      <td>-0.022786</td>\n      <td>-0.046409</td>\n      <td>0.007761</td>\n      <td>0.025377</td>\n      <td>-0.034746</td>\n      <td>-0.046306</td>\n      <td>-0.016597</td>\n      <td>0.000040</td>\n      <td>0.025495</td>\n      <td>0.075011</td>\n      <td>0.006661</td>\n      <td>0.028682</td>\n      <td>-0.014056</td>\n      <td>0.008809</td>\n      <td>0.073326</td>\n      <td>0.042734</td>\n      <td>0.029835</td>\n      <td>0.032328</td>\n      <td>-0.000575</td>\n      <td>0.043473</td>\n      <td>-0.021088</td>\n      <td>0.003531</td>\n      <td>-0.014081</td>\n      <td>0.090822</td>\n      <td>0.366067</td>\n      <td>-1.190902e-08</td>\n      <td>0.014001</td>\n      <td>-0.045489</td>\n      <td>0.127677</td>\n      <td>0.370287</td>\n      <td>-0.204517</td>\n      <td>-0.131163</td>\n      <td>0.138625</td>\n      <td>0.042774</td>\n      <td>-0.023667</td>\n      <td>0.006420</td>\n      <td>-0.008847</td>\n      <td>-0.020395</td>\n      <td>-0.017428</td>\n      <td>11.713414</td>\n      <td>9.767553</td>\n      <td>16.296382</td>\n      <td>7.824446</td>\n      <td>5.880932</td>\n      <td>7.957927</td>\n      <td>7.783641</td>\n      <td>5.840226</td>\n      <td>7.957927</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>4</td>\n      <td>307</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>150</td>\n      <td>41401</td>\n      <td>0</td>\n      <td>8.0</td>\n      <td>2.0</td>\n      <td>0.9</td>\n      <td>0.900000</td>\n      <td>0.000000</td>\n      <td>0.9</td>\n      <td>0.900000</td>\n      <td>0.000000</td>\n      <td>0.9</td>\n      <td>0.9</td>\n      <td>6.045986</td>\n      <td>0.755748</td>\n      <td>0.000221</td>\n      <td>0.660390</td>\n      <td>0.082549</td>\n      <td>0.000278</td>\n      <td>0.548335</td>\n      <td>0.068542</td>\n      <td>0.000571</td>\n      <td>6.4</td>\n      <td>0.8</td>\n      <td>0.0</td>\n      <td>8.00</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>-1</td>\n      <td>4.990433</td>\n      <td>6.779922</td>\n      <td>3.784190</td>\n      <td>3.258097</td>\n      <td>4.955827</td>\n      <td>2.079442</td>\n      <td>3.218876</td>\n      <td>3.091042</td>\n      <td>2.079442</td>\n      <td>2.197225</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>2.079442</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.081360</td>\n      <td>-0.021896</td>\n      <td>-0.001674</td>\n      <td>0.011284</td>\n      <td>0.010215</td>\n      <td>-0.012603</td>\n      <td>0.032462</td>\n      <td>0.026343</td>\n      <td>-0.001419</td>\n      <td>-0.033471</td>\n      <td>-0.045353</td>\n      <td>-0.002096</td>\n      <td>0.040378</td>\n      <td>0.012599</td>\n      <td>0.027032</td>\n      <td>0.011449</td>\n      <td>0.000029</td>\n      <td>0.033364</td>\n      <td>0.055338</td>\n      <td>0.008599</td>\n      <td>0.147900</td>\n      <td>0.032550</td>\n      <td>-0.000582</td>\n      <td>-0.011612</td>\n      <td>-0.007226</td>\n      <td>-0.006741</td>\n      <td>0.013928</td>\n      <td>-0.022664</td>\n      <td>-0.044229</td>\n      <td>-0.119552</td>\n      <td>-0.007308</td>\n      <td>0.032700</td>\n      <td>0.126992</td>\n      <td>0.523013</td>\n      <td>5.235827e-08</td>\n      <td>0.031607</td>\n      <td>0.179217</td>\n      <td>-0.069133</td>\n      <td>0.005489</td>\n      <td>-0.034659</td>\n      <td>0.044895</td>\n      <td>-0.043177</td>\n      <td>-0.068690</td>\n      <td>-0.192850</td>\n      <td>0.154541</td>\n      <td>0.017752</td>\n      <td>0.012273</td>\n      <td>0.055676</td>\n      <td>12.024910</td>\n      <td>9.945511</td>\n      <td>15.076520</td>\n      <td>8.006701</td>\n      <td>5.929589</td>\n      <td>7.670362</td>\n      <td>7.863651</td>\n      <td>5.786897</td>\n      <td>7.670362</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>1</td>\n      <td>307</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>41326</td>\n      <td>0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>3.5</td>\n      <td>0.583333</td>\n      <td>0.071389</td>\n      <td>3.5</td>\n      <td>0.583333</td>\n      <td>0.071389</td>\n      <td>3.7</td>\n      <td>0.6</td>\n      <td>2.326006</td>\n      <td>0.775335</td>\n      <td>0.011257</td>\n      <td>0.239312</td>\n      <td>0.079771</td>\n      <td>0.000075</td>\n      <td>0.128066</td>\n      <td>0.042689</td>\n      <td>0.000016</td>\n      <td>2.4</td>\n      <td>0.8</td>\n      <td>0.0</td>\n      <td>2.98</td>\n      <td>0.993333</td>\n      <td>0.000133</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>-1</td>\n      <td>5.968708</td>\n      <td>5.746203</td>\n      <td>4.356709</td>\n      <td>4.406719</td>\n      <td>3.912023</td>\n      <td>2.639057</td>\n      <td>4.189655</td>\n      <td>2.995732</td>\n      <td>2.639057</td>\n      <td>3.761200</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>2.302585</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.189465</td>\n      <td>-0.045537</td>\n      <td>-0.010977</td>\n      <td>-0.009483</td>\n      <td>-0.011833</td>\n      <td>-0.013234</td>\n      <td>-0.024864</td>\n      <td>0.024887</td>\n      <td>0.018768</td>\n      <td>0.090536</td>\n      <td>-0.081798</td>\n      <td>-0.017550</td>\n      <td>0.044352</td>\n      <td>-0.006712</td>\n      <td>-0.009167</td>\n      <td>0.011911</td>\n      <td>0.000053</td>\n      <td>0.111890</td>\n      <td>0.067515</td>\n      <td>-0.006133</td>\n      <td>0.000998</td>\n      <td>-0.049176</td>\n      <td>-0.000408</td>\n      <td>0.079796</td>\n      <td>0.061995</td>\n      <td>0.016409</td>\n      <td>0.012236</td>\n      <td>-0.006130</td>\n      <td>-0.013930</td>\n      <td>0.031081</td>\n      <td>0.020328</td>\n      <td>-0.031070</td>\n      <td>0.086932</td>\n      <td>0.312147</td>\n      <td>3.389364e-07</td>\n      <td>0.004039</td>\n      <td>0.119461</td>\n      <td>0.124084</td>\n      <td>0.002166</td>\n      <td>0.028955</td>\n      <td>0.028481</td>\n      <td>-0.068960</td>\n      <td>0.028217</td>\n      <td>-0.020259</td>\n      <td>0.028731</td>\n      <td>0.008358</td>\n      <td>0.001908</td>\n      <td>0.016266</td>\n      <td>11.421873</td>\n      <td>10.323283</td>\n      <td>18.750387</td>\n      <td>7.346655</td>\n      <td>6.249332</td>\n      <td>10.728416</td>\n      <td>7.196687</td>\n      <td>6.099571</td>\n      <td>6.843039</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 135 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape[0]","execution_count":35,"outputs":[{"output_type":"execute_result","execution_count":35,"data":{"text/plain":"14993"},"metadata":{}}]},{"metadata":{"trusted":true,"_uuid":"2fd332396f3d3e5bcecf987cb038805b812bfd7d"},"cell_type":"code","source":"train.shape\nn_train = train.shape[0]\nX_train = X_temp.loc[:n_train-1, :]\nX_test = X_temp.loc[n_train:, :]\nX_test.drop([\"AdoptionSpeed\"], axis=1, inplace=True)\n\nassert X_train.shape[0] == train.shape[0]\nassert X_test.shape[0] == test.shape[0]","execution_count":36,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:3697: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  errors=errors)\n","name":"stderr"}]},{"metadata":{"trusted":true,"_uuid":"6bd7866671af382a793076e81bc9b6732b66dbd4"},"cell_type":"code","source":"train_cols = X_train.columns.tolist()\ntrain_cols.remove(\"AdoptionSpeed\")\n\ntest_cols = X_test.columns.tolist()\nassert np.all(train_cols == test_cols)","execution_count":37,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ebbbcb8c426fd7ca62fd54a8334c5bad226dd78e"},"cell_type":"code","source":"X_train_non_null = X_train.fillna(-1)\nX_test_non_null = X_test.fillna(-1)\n\nX_train_non_null.isnull().any().any(), X_test_non_null.isnull().any().any()","execution_count":38,"outputs":[{"output_type":"execute_result","execution_count":38,"data":{"text/plain":"(False, False)"},"metadata":{}}]},{"metadata":{"trusted":true,"_uuid":"4fa273d5d3538864c5839a6de6aba0a343a8d530"},"cell_type":"code","source":"cat_features = [\"Type\", \"Breed1\", \"Breed2\", \"Gender\", \"Color1\", \"Color2\", \"Color3\",\n                \"MaturitySize\", \"FurLength\", \"Vaccinated\", \"Dewormed\", \"Sterilized\",\n                \"Health\", \"Quantity\", \"State\", \"language\", \"main_breed_BreedName\", \n                \"second_breed_BreedName\"]\n\nX_train_cat = X_train_non_null.loc[:, cat_features]\nX_test_cat = X_test_non_null.loc[:, cat_features]","execution_count":39,"outputs":[]},{"metadata":{"_uuid":"22aa79408edbd3799d3a139f4becb3bd12dc6ae2"},"cell_type":"markdown","source":"## GroupStratifiedKFold"},{"metadata":{"trusted":true,"_uuid":"e3889cb5951b66961abacdaa83cf2afc23be7493"},"cell_type":"code","source":"def stratified_group_k_fold(X, y, groups, k, seed=None):\n    labels_num = np.max(y) + 1\n    y_counts_per_group = defaultdict(lambda: np.zeros(labels_num))\n    y_distr = Counter()\n    for label, g in zip(y, groups):\n        y_counts_per_group[g][label] += 1\n        y_distr[label] += 1\n\n    y_counts_per_fold = defaultdict(lambda: np.zeros(labels_num))\n    groups_per_fold = defaultdict(set)\n\n    def eval_y_counts_per_fold(y_counts, fold):\n        y_counts_per_fold[fold] += y_counts\n        std_per_label = []\n        for label in range(labels_num):\n            label_std = np.std([y_counts_per_fold[i][label] / y_distr[label] for i in range(k)])\n            std_per_label.append(label_std)\n        y_counts_per_fold[fold] -= y_counts\n        return np.mean(std_per_label)\n    \n    groups_and_y_counts = list(y_counts_per_group.items())\n    random.Random(seed).shuffle(groups_and_y_counts)\n\n    for g, y_counts in sorted(groups_and_y_counts, key=lambda x: -np.std(x[1])):\n        best_fold = None\n        min_eval = None\n        for i in range(k):\n            fold_eval = eval_y_counts_per_fold(y_counts, i)\n            if min_eval is None or fold_eval < min_eval:\n                min_eval = fold_eval\n                best_fold = i\n        y_counts_per_fold[best_fold] += y_counts\n        groups_per_fold[best_fold].add(g)\n\n    all_groups = set(groups)\n    for i in range(k):\n        train_groups = all_groups - groups_per_fold[i]\n        test_groups = groups_per_fold[i]\n\n        train_indices = [i for i, g in enumerate(groups) if g in train_groups]\n        test_indices = [i for i, g in enumerate(groups) if g in test_groups]\n\n        yield train_indices, test_indices","execution_count":40,"outputs":[]},{"metadata":{"_uuid":"058b7fbb860473d9a65f65400de195cddd6d932c"},"cell_type":"markdown","source":"## Categorical Target Encoding"},{"metadata":{"trusted":true,"_uuid":"6105f6ef169df736d238d7a978c040a2f6a8cd16"},"cell_type":"code","source":"y = X_train_non_null.AdoptionSpeed\nX_train_cat_y = X_train_cat.copy()\nX_train_cat_y[\"AdoptionSpeed\"] = y\n\nX_train_cat_encoded = np.zeros((X_train_cat.shape[0], len(cat_features) * 2))\nX_test_cat_encoded = np.zeros((X_test_cat.shape[0], len(cat_features) * 2))\nk = 10\nfold = StratifiedKFold(n_splits=k, shuffle=True, random_state=1213)\n\nfor trn_idx, val_idx in fold.split(X_train_cat, y.values.astype(int)):\n    X_trn, X_val = X_train_cat_y.loc[trn_idx, :], X_train_cat_y.loc[val_idx, :]\n    for j, c in enumerate(cat_features):\n        X_trn_enc = X_trn.groupby(c).agg({\n            \"AdoptionSpeed\": [\"mean\", \"std\"]\n        })\n        cte_columns = [f\"{c}_{x}\" for x in [\"mean\", \"std\"]]\n        X_trn_enc.columns = cte_columns\n        X_temp = np.zeros((X_test_cat.shape[0], 2))\n        X_temp_df = pd.DataFrame(data=X_temp, columns=cte_columns)\n        for x in X_trn_enc.columns:\n            X_val[x] = X_val[c].map(X_trn_enc[x])\n            X_temp_df[x] = X_test_cat[c].map(X_trn_enc[x]).reset_index(drop=True)\n        X_train_cat_encoded[val_idx, 2 * j:2 * (j + 1)] = X_val[X_trn_enc.columns].values\n        X_test_cat_encoded[:, 2 * j: 2 * (j + 1)] += X_temp_df.values / k","execution_count":41,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4f29fd092db829af7253267c2ef4dc6c92f48e73"},"cell_type":"code","source":"X_train_cat_encoded.shape, X_test_cat_encoded.shape","execution_count":42,"outputs":[{"output_type":"execute_result","execution_count":42,"data":{"text/plain":"((14993, 36), (3948, 36))"},"metadata":{}}]},{"metadata":{"trusted":true,"_uuid":"17d6dba910e9ef8689a059fe81f3a151a6ce8935"},"cell_type":"code","source":"columns = [f\"{c}_{x}\" for c in cat_features for x in [\"mean\", \"std\"]]\nX_train_cat_encoded_df = pd.DataFrame(data=X_train_cat_encoded, columns=columns)\nX_test_cat_encoded_df = pd.DataFrame(data=X_test_cat_encoded, columns=columns)\nX_test_cat_encoded_df.head()","execution_count":43,"outputs":[{"output_type":"execute_result","execution_count":43,"data":{"text/plain":"   Type_mean  Type_std  Breed1_mean  Breed1_std  Breed2_mean  Breed2_std  \\\n0   2.615104  1.144106     2.746075    1.116631     2.538468    1.175466   \n1   2.399505  1.205068     2.479097    1.169725     2.538468    1.175466   \n2   2.399505  1.205068     2.479097    1.169725     2.538468    1.175466   \n3   2.399505  1.205068     2.479097    1.169725     1.886247    1.601276   \n4   2.615104  1.144106     2.746075    1.116631     2.538468    1.175466   \n\n   Gender_mean  Gender_std  Color1_mean  Color1_std  Color2_mean  Color2_std  \\\n0     2.418712    1.178361     2.533596    1.163709     2.556696    1.187880   \n1     2.418712    1.178361     2.584273    1.185278     2.469460    1.171914   \n2     2.569885    1.171742     2.397339    1.182807     2.556696    1.187880   \n3     2.569885    1.171742     2.533596    1.163709     2.373471    1.213826   \n4     2.569885    1.171742     2.533596    1.163709     2.557832    1.146438   \n\n   Color3_mean  Color3_std  MaturitySize_mean  MaturitySize_std  \\\n0     2.519803    1.172678           2.576905          1.150354   \n1     2.519803    1.172678           2.576905          1.150354   \n2     2.519803    1.172678           2.576905          1.150354   \n3     2.503558    1.184688           2.576905          1.150354   \n4     2.503558    1.184688           2.576905          1.150354   \n\n   FurLength_mean  FurLength_std  Vaccinated_mean  Vaccinated_std  \\\n0        2.470431       1.189792         2.361971        1.164866   \n1        2.585262       1.157419         2.670051        1.157425   \n2        2.585262       1.157419         2.670051        1.157425   \n3        2.585262       1.157419         2.670051        1.157425   \n4        2.585262       1.157419         2.670051        1.157425   \n\n   Dewormed_mean  Dewormed_std  Sterilized_mean  Sterilized_std  Health_mean  \\\n0       2.389192      1.191698         2.361713        1.136504     2.510499   \n1       2.562582      1.152826         2.902286        1.136393     2.510499   \n2       2.562582      1.152826         2.902286        1.136393     2.510499   \n3       2.562582      1.152826         2.902286        1.136393     2.510499   \n4       2.562582      1.152826         2.902286        1.136393     2.510499   \n\n   Health_std  Quantity_mean  Quantity_std  State_mean  State_std  \\\n0    1.175139       2.485171      1.173058    2.452027   1.158431   \n1    1.175139       2.485171      1.173058    2.452027   1.158431   \n2    1.175139       2.485171      1.173058    2.452027   1.158431   \n3    1.175139       2.485171      1.173058    2.452027   1.158431   \n4    1.175139       2.485171      1.173058    2.452027   1.158431   \n\n   language_mean  language_std  main_breed_BreedName_mean  \\\n0       2.515759      1.171899                   2.746075   \n1       2.515759      1.171899                   2.479097   \n2       2.515759      1.171899                   2.479097   \n3       2.515759      1.171899                   2.479097   \n4       2.515759      1.171899                   2.746075   \n\n   main_breed_BreedName_std  second_breed_BreedName_mean  \\\n0                  1.116631                     2.538468   \n1                  1.169725                     2.538468   \n2                  1.169725                     2.538468   \n3                  1.169725                     1.886247   \n4                  1.116631                     2.538468   \n\n   second_breed_BreedName_std  \n0                    1.175466  \n1                    1.175466  \n2                    1.175466  \n3                    1.601276  \n4                    1.175466  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Type_mean</th>\n      <th>Type_std</th>\n      <th>Breed1_mean</th>\n      <th>Breed1_std</th>\n      <th>Breed2_mean</th>\n      <th>Breed2_std</th>\n      <th>Gender_mean</th>\n      <th>Gender_std</th>\n      <th>Color1_mean</th>\n      <th>Color1_std</th>\n      <th>Color2_mean</th>\n      <th>Color2_std</th>\n      <th>Color3_mean</th>\n      <th>Color3_std</th>\n      <th>MaturitySize_mean</th>\n      <th>MaturitySize_std</th>\n      <th>FurLength_mean</th>\n      <th>FurLength_std</th>\n      <th>Vaccinated_mean</th>\n      <th>Vaccinated_std</th>\n      <th>Dewormed_mean</th>\n      <th>Dewormed_std</th>\n      <th>Sterilized_mean</th>\n      <th>Sterilized_std</th>\n      <th>Health_mean</th>\n      <th>Health_std</th>\n      <th>Quantity_mean</th>\n      <th>Quantity_std</th>\n      <th>State_mean</th>\n      <th>State_std</th>\n      <th>language_mean</th>\n      <th>language_std</th>\n      <th>main_breed_BreedName_mean</th>\n      <th>main_breed_BreedName_std</th>\n      <th>second_breed_BreedName_mean</th>\n      <th>second_breed_BreedName_std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.615104</td>\n      <td>1.144106</td>\n      <td>2.746075</td>\n      <td>1.116631</td>\n      <td>2.538468</td>\n      <td>1.175466</td>\n      <td>2.418712</td>\n      <td>1.178361</td>\n      <td>2.533596</td>\n      <td>1.163709</td>\n      <td>2.556696</td>\n      <td>1.187880</td>\n      <td>2.519803</td>\n      <td>1.172678</td>\n      <td>2.576905</td>\n      <td>1.150354</td>\n      <td>2.470431</td>\n      <td>1.189792</td>\n      <td>2.361971</td>\n      <td>1.164866</td>\n      <td>2.389192</td>\n      <td>1.191698</td>\n      <td>2.361713</td>\n      <td>1.136504</td>\n      <td>2.510499</td>\n      <td>1.175139</td>\n      <td>2.485171</td>\n      <td>1.173058</td>\n      <td>2.452027</td>\n      <td>1.158431</td>\n      <td>2.515759</td>\n      <td>1.171899</td>\n      <td>2.746075</td>\n      <td>1.116631</td>\n      <td>2.538468</td>\n      <td>1.175466</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.399505</td>\n      <td>1.205068</td>\n      <td>2.479097</td>\n      <td>1.169725</td>\n      <td>2.538468</td>\n      <td>1.175466</td>\n      <td>2.418712</td>\n      <td>1.178361</td>\n      <td>2.584273</td>\n      <td>1.185278</td>\n      <td>2.469460</td>\n      <td>1.171914</td>\n      <td>2.519803</td>\n      <td>1.172678</td>\n      <td>2.576905</td>\n      <td>1.150354</td>\n      <td>2.585262</td>\n      <td>1.157419</td>\n      <td>2.670051</td>\n      <td>1.157425</td>\n      <td>2.562582</td>\n      <td>1.152826</td>\n      <td>2.902286</td>\n      <td>1.136393</td>\n      <td>2.510499</td>\n      <td>1.175139</td>\n      <td>2.485171</td>\n      <td>1.173058</td>\n      <td>2.452027</td>\n      <td>1.158431</td>\n      <td>2.515759</td>\n      <td>1.171899</td>\n      <td>2.479097</td>\n      <td>1.169725</td>\n      <td>2.538468</td>\n      <td>1.175466</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.399505</td>\n      <td>1.205068</td>\n      <td>2.479097</td>\n      <td>1.169725</td>\n      <td>2.538468</td>\n      <td>1.175466</td>\n      <td>2.569885</td>\n      <td>1.171742</td>\n      <td>2.397339</td>\n      <td>1.182807</td>\n      <td>2.556696</td>\n      <td>1.187880</td>\n      <td>2.519803</td>\n      <td>1.172678</td>\n      <td>2.576905</td>\n      <td>1.150354</td>\n      <td>2.585262</td>\n      <td>1.157419</td>\n      <td>2.670051</td>\n      <td>1.157425</td>\n      <td>2.562582</td>\n      <td>1.152826</td>\n      <td>2.902286</td>\n      <td>1.136393</td>\n      <td>2.510499</td>\n      <td>1.175139</td>\n      <td>2.485171</td>\n      <td>1.173058</td>\n      <td>2.452027</td>\n      <td>1.158431</td>\n      <td>2.515759</td>\n      <td>1.171899</td>\n      <td>2.479097</td>\n      <td>1.169725</td>\n      <td>2.538468</td>\n      <td>1.175466</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.399505</td>\n      <td>1.205068</td>\n      <td>2.479097</td>\n      <td>1.169725</td>\n      <td>1.886247</td>\n      <td>1.601276</td>\n      <td>2.569885</td>\n      <td>1.171742</td>\n      <td>2.533596</td>\n      <td>1.163709</td>\n      <td>2.373471</td>\n      <td>1.213826</td>\n      <td>2.503558</td>\n      <td>1.184688</td>\n      <td>2.576905</td>\n      <td>1.150354</td>\n      <td>2.585262</td>\n      <td>1.157419</td>\n      <td>2.670051</td>\n      <td>1.157425</td>\n      <td>2.562582</td>\n      <td>1.152826</td>\n      <td>2.902286</td>\n      <td>1.136393</td>\n      <td>2.510499</td>\n      <td>1.175139</td>\n      <td>2.485171</td>\n      <td>1.173058</td>\n      <td>2.452027</td>\n      <td>1.158431</td>\n      <td>2.515759</td>\n      <td>1.171899</td>\n      <td>2.479097</td>\n      <td>1.169725</td>\n      <td>1.886247</td>\n      <td>1.601276</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.615104</td>\n      <td>1.144106</td>\n      <td>2.746075</td>\n      <td>1.116631</td>\n      <td>2.538468</td>\n      <td>1.175466</td>\n      <td>2.569885</td>\n      <td>1.171742</td>\n      <td>2.533596</td>\n      <td>1.163709</td>\n      <td>2.557832</td>\n      <td>1.146438</td>\n      <td>2.503558</td>\n      <td>1.184688</td>\n      <td>2.576905</td>\n      <td>1.150354</td>\n      <td>2.585262</td>\n      <td>1.157419</td>\n      <td>2.670051</td>\n      <td>1.157425</td>\n      <td>2.562582</td>\n      <td>1.152826</td>\n      <td>2.902286</td>\n      <td>1.136393</td>\n      <td>2.510499</td>\n      <td>1.175139</td>\n      <td>2.485171</td>\n      <td>1.173058</td>\n      <td>2.452027</td>\n      <td>1.158431</td>\n      <td>2.515759</td>\n      <td>1.171899</td>\n      <td>2.746075</td>\n      <td>1.116631</td>\n      <td>2.538468</td>\n      <td>1.175466</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"_uuid":"a45e4eb9cee5516325edf586e4a9edd9d1d12e31"},"cell_type":"markdown","source":"## Numerical Features"},{"metadata":{"trusted":true,"_uuid":"8d91fecdf01da92b21e2d05a8ba6d67243b7f9da"},"cell_type":"code","source":"X_train_num = X_train_non_null.drop(cat_features + [\"AdoptionSpeed\"], axis=1)\nX_test_num = X_test_non_null.drop(cat_features, axis=1)\n\ntarget = X_train_non_null[\"AdoptionSpeed\"]","execution_count":44,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5ef772ea61eddacbd04b03c29614b94d2d6babf5"},"cell_type":"code","source":"X_train_num = pd.concat([X_train_num, X_train_cat_encoded_df], axis=1)\n\nX_test_cat_encoded_df.index = X_test_num.index\nX_test_num = pd.concat([X_test_num, X_test_cat_encoded_df], axis=1)","execution_count":45,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2fab8a9f6506d6369c4cd0b3d813b16b2ce63440"},"cell_type":"code","source":"X_train_num.fillna(0.0, inplace=True)\nX_test_num.fillna(0.0, inplace=True)","execution_count":46,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7022fe088c563feee029b5a9fa599c4faca5a806"},"cell_type":"code","source":"X_train_num.replace(np.inf, np.nan).fillna(0.0, inplace=True)\nX_test_num.replace(np.inf, np.nan).fillna(0.0, inplace=True)\n\nX_train_num.replace(-np.inf, np.nan).fillna(0.0, inplace=True)\nX_test_num.replace(-np.inf, np.nan).fillna(0.0, inplace=True)","execution_count":47,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"037ada6259e60182176ad199d08bbe0ebf53fa35"},"cell_type":"code","source":"X_train_num.values[np.isinf(X_train_num)]","execution_count":48,"outputs":[{"output_type":"execute_result","execution_count":48,"data":{"text/plain":"array([], dtype=float64)"},"metadata":{}}]},{"metadata":{"trusted":true,"_uuid":"3943eac9c119e7c778677861e30428a657264dc8"},"cell_type":"code","source":"X_all_num = pd.concat([X_train_num, X_test_num], axis=0)\nss = StandardScaler()\nss.fit(X_all_num)\n\nX_train_ss = ss.transform(X_train_num)\nX_test_ss = ss.transform(X_test_num)","execution_count":49,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n  return self.partial_fit(X, y)\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n  \"\"\"\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:6: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n  \n","name":"stderr"}]},{"metadata":{"trusted":true,"_uuid":"1b20c6270c1a1e13ccf32364b043d6891814f511"},"cell_type":"code","source":"X_train_ss[np.isnan(X_train_ss)] = 0.0\nX_test_ss[np.isnan(X_test_ss)] = 0.0","execution_count":50,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c61099ad98de01c893e42f0691ff4d365ebb9216"},"cell_type":"code","source":"cat_cat = pd.concat([X_train_cat, X_test_cat])\n\nn_breed1 = cat_cat[\"Breed1\"].nunique()\nn_breed2 = cat_cat[\"Breed2\"].nunique()\nn_langs = cat_cat[\"language\"].nunique()\nn_color1 = cat_cat[\"Color1\"].nunique()\nn_color2 = cat_cat[\"Color2\"].nunique()\nn_color3 = cat_cat[\"Color3\"].nunique()","execution_count":51,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e1f47565b9a8ff3d8eeb5f1b34154dde3e71af90"},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfor c in X_train_cat.columns:\n        le = LabelEncoder()\n        le.fit(cat_cat[c])\n        X_train_cat[c] = le.transform(X_train_cat[c])\n        X_test_cat[c] = le.transform(X_test_cat[c])","execution_count":52,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Sequences"},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\ndef load_fasttext(word_index):    \n    EMBEDDING_FILE = '../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec'\n    def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\n    embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE))\n    all_embs = np.stack(embeddings_index.values())\n    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n    embed_size = all_embs.shape[1]\n\n    # word_index = tokenizer.word_index\n    nb_words = min(100000, len(word_index)) + 1\n    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n    words_list = []\n    for word, i in word_index.items():\n        if i >= 100000: continue\n        embedding_vector = embeddings_index.get(word)\n        if embedding_vector is not None: \n            embedding_matrix[i] = embedding_vector\n            words_list.append(word)\n    return embedding_matrix, set(words_list)","execution_count":53,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = Tokenizer(num_words=100000)\ntokenizer.fit_on_texts(X_text[\"cleaned_text\"] + \" \" + X_text[\"desc\"] + \" \" + X_text[\"entity\"])\nlen(tokenizer.word_index)","execution_count":54,"outputs":[{"output_type":"execute_result","execution_count":54,"data":{"text/plain":"25951"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_text, test_text = X_text.loc[:n_train-1, :], X_text.loc[n_train:, :]\ntrain_text.shape, test_text.shape","execution_count":55,"outputs":[{"output_type":"execute_result","execution_count":55,"data":{"text/plain":"((14993, 4), (3948, 4))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_text = tokenizer.texts_to_sequences(train_text[\"cleaned_text\"])\nx_test_text = tokenizer.texts_to_sequences(test_text[\"cleaned_text\"])\n\nx_train_text = pad_sequences(x_train_text, maxlen=70)\nx_test_text = pad_sequences(x_test_text, maxlen=70)","execution_count":56,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nembedding_matrix, words_set = load_fasttext(tokenizer.word_index)","execution_count":57,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:6: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n  \n","name":"stderr"},{"output_type":"stream","text":"CPU times: user 2min 6s, sys: 6.69 s, total: 2min 12s\nWall time: 2min 12s\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":58,"outputs":[{"output_type":"execute_result","execution_count":58,"data":{"text/plain":"49"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calc_vector(text, word_index, words_set, embedding_matrix):\n    words = set(text.split())\n    n_skip = 0\n    vec = np.zeros((embedding_matrix.shape[1],))\n    if len(words) == 0:\n        return vec\n    for n_w, word in enumerate(words):\n        if word in words_set:\n            idx = word_index.get(word)\n            vec_ = embedding_matrix[idx, :]\n        else:\n            n_skip += 1\n            continue\n        if n_w == 0:\n            vec = vec_\n        else:\n            vec = vec + vec_\n    vec = vec / (n_w - n_skip + 1)\n    return vec","execution_count":59,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tqdm.pandas()","execution_count":60,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_entity = train_text.entity.progress_apply(lambda x: calc_vector(\n    x, tokenizer.word_index, words_set, embedding_matrix))\ntest_entity = test_text.entity.progress_apply(lambda x: calc_vector(\n    x, tokenizer.word_index, words_set, embedding_matrix))\n\ntrain_entity = np.vstack(train_entity.values.tolist())\ntest_entity = np.vstack(test_entity.values.tolist())\n\ntrain_entity[np.isnan(train_entity)] = 0.0\ntest_entity[np.isnan(test_entity)] = 0.0\n\ntrain_desc = train_text.desc.progress_apply(lambda x: calc_vector(\n    x, tokenizer.word_index, words_set, embedding_matrix))\ntest_desc = test_text.desc.progress_apply(lambda x: calc_vector(\n    x, tokenizer.word_index, words_set, embedding_matrix))\n\ntrain_desc = np.vstack(train_desc.values.tolist())\ntest_desc = np.vstack(test_desc.values.tolist())\n\ntrain_desc[np.isnan(train_desc)] = 0.0\ntest_desc[np.isnan(test_desc)] = 0.0","execution_count":61,"outputs":[{"output_type":"stream","text":"100%|██████████| 14993/14993 [00:00<00:00, 31929.14it/s]\n100%|██████████| 3948/3948 [00:00<00:00, 24725.72it/s]\n100%|██████████| 14993/14993 [00:00<00:00, 15359.21it/s]\n100%|██████████| 3948/3948 [00:00<00:00, 16861.01it/s]\n","name":"stderr"}]},{"metadata":{},"cell_type":"markdown","source":"## Images"},{"metadata":{"trusted":true},"cell_type":"code","source":"normalize = transforms.Normalize(\n    mean=[0.485, 0.456, 0.406],\n    std=[0.229, 0.224, 0.225]\n)\nds_trans = transforms.Compose([transforms.Resize(224),\n                               transforms.CenterCrop(224),\n                               transforms.ToTensor(),\n                               normalize])","execution_count":62,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ImageDataset(data.Dataset):\n    def __init__(self, pet_ids, root_dir, transform):\n        self.pet_ids = pet_ids\n        self.root_dir = root_dir\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.pet_ids)\n    \n    def __getitem__(self, idx):\n        imgs = torch.zeros((4, 3, 224, 224))\n        for i in range(4):\n            img_name = f\"{self.pet_ids[idx]}-{i+1}.jpg\"\n            fullname = self.root_dir / Path(img_name)\n            try:\n                image = Image.open(fullname).convert(\"RGB\")\n            except FileNotFoundError:\n                image = np.zeros((3, 224, 224), dtype=np.uint8).transpose(1, 2, 0)\n                image = Image.fromarray(np.uint8(image))\n            if self.transform:\n                image = self.transform(image)\n            imgs[i, :, :, :] = image\n        return [self.pet_ids[idx], imgs]","execution_count":63,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Classifier(nn.Module):\n    def __init__(self):\n        super(Classifier, self).__init__()\n        \n    def forward(self, x):\n        return x\n\nclass ImagePretrained(nn.Module):\n    def __init__(self, path):\n        super(ImagePretrained, self).__init__()\n        self.densenet121 = models.densenet121()\n        self.densenet121.load_state_dict(torch.load(path))\n        self.densenet121.classifier = Classifier()\n        dense = nn.Sequential(*list(self.densenet121.children())[:-1])\n        for param in dense.parameters():\n            param.requires_grad = False\n            \n    def forward(self, x):\n        converted = torch.zeros(x.size(0), 4, 1024)\n        for i in range(4):\n            out = self.densenet121(x[:, i, :, :, :])\n            converted[:, i, :] = out\n        return converted","execution_count":64,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_img_dataset = ImageDataset(train_pet_ids,\n                             \"../input/petfinder-adoption-prediction/train_images/\",\n                             transform=ds_trans)\ntest_img_dataset = ImageDataset(test_pet_ids,\n                            \"../input/petfinder-adoption-prediction/test_images/\",\n                            transform=ds_trans)\ntrain_img_loader = data.DataLoader(train_img_dataset, batch_size=128, shuffle=False)\ntest_img_loader = data.DataLoader(test_img_dataset, batch_size=128, shuffle=False)","execution_count":65,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pids = []\ntrain_img_matrix = np.zeros((len(train_pet_ids), 4, 1024))\nmodel = ImagePretrained(\"densenet121.pth\")\nmodel.to(\"cuda:0\")\nfor i, (pid, tensor) in tqdm(enumerate(train_img_loader)):\n    train_pids += [*pid]\n    tensor = tensor.to(\"cuda:0\")\n    pred = model(tensor).detach().cpu().numpy()\n    train_img_matrix[i * 128:(i + 1) * 128, :, :] = pred\n    \ntest_pids = []\ntest_img_matrix = np.zeros((len(test_pet_ids), 4, 1024))\nfor i, (pid, tensor) in tqdm(enumerate(test_img_loader)):\n    test_pids += [*pid]\n    tensor = tensor.to(\"cuda:0\")\n    pred = model(tensor).detach().cpu().numpy()\n    test_img_matrix[i * 128:(i + 1) * 128, :, :] = pred","execution_count":66,"outputs":[{"output_type":"stream","text":"118it [08:14,  3.07s/it]\n31it [02:09,  4.11s/it]\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":67,"outputs":[{"output_type":"execute_result","execution_count":67,"data":{"text/plain":"147"},"metadata":{}}]},{"metadata":{"trusted":true,"_uuid":"3b9bd342bf82e03749abc2534f49187794e890a4"},"cell_type":"markdown","source":"## Metrics"},{"metadata":{"trusted":true,"_uuid":"e352a3d956a76b441ff4fdfb0a3d82230f08e48a"},"cell_type":"code","source":"class OptimizedRounder(object):\n    def __init__(self):\n        self.coef_ = 0\n    \n    def _kappa_loss(self, coef, X, y):\n        preds = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3, 4])\n        return -cohen_kappa_score(y, preds, weights='quadratic')\n    \n    def fit(self, X, y, initial_coef=[]):\n        loss_partial = partial(self._kappa_loss, X = X, y = y)\n        initial_coef = initial_coef\n        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n    \n    def predict(self, X, coef):\n        preds = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3, 4])\n        return preds\n    \n    def coefficients(self):\n        return self.coef_['x']\n    \ndef confusion_matrix(rater_a, rater_b, min_rating=None, max_rating=None):\n    assert len(rater_a) == len(rater_b)\n\n    if min_rating is None:\n        min_rating = min(rater_a + rater_b)\n    if max_rating is None:\n        max_rating = max(rater_a + rater_b)\n    num_rating = int(max_rating - min_rating + 1)\n    conf_mat = [[0 for i in range(num_rating)] for j in range(num_rating)]\n    for a, b in zip(rater_a, rater_b):\n        conf_mat[a - min_rating][b - min_rating] += 1\n    return conf_mat\n\n\ndef histogram(ratings, min_rating=None, max_rating=None):\n    if min_rating is None:\n        min_rating = min(ratings)\n    if max_rating is None:\n        max_rating = max(ratings)\n    num_ratings = int(max_rating - min_rating + 1)\n    hist_ratings = [0 for x in range(num_ratings)]\n    for r in ratings:\n        hist_ratings[r - min_rating] += 1\n    return hist_ratings\n\n\ndef quadratic_weighted_kappa(y, y_pred):\n    rater_a = y\n    rater_b = y_pred\n    min_rating = None\n    max_rating = None\n    rater_a = np.array(rater_a, dtype=int)\n    rater_b = np.array(rater_b, dtype=int)\n\n    assert len(rater_a) == len(rater_b)\n\n    min_rating = min(min(rater_a), min(rater_b))\n    max_rating = max(max(rater_a), max(rater_b))\n\n    conf_mat = confusion_matrix(rater_a, rater_b, min_rating, max_rating)\n    num_ratings = len(conf_mat)\n    num_scored_items = float(len(rater_a))\n\n    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n\n    numerator = 0.0\n    denominator = 0.0\n\n    for i in range(num_ratings):\n        for j in range(num_ratings):\n            expected_count = (\n                hist_rater_a[i] * hist_rater_b[j]) / num_scored_items\n            d = pow(i - j, 2.0) / pow(num_ratings - 1, 2.0)\n            numerator += d * conf_mat[i][j] / num_scored_items\n            denominator += d * expected_count / num_scored_items\n\n    return (1.0 - numerator / denominator)","execution_count":68,"outputs":[]},{"metadata":{"_uuid":"843c82870b00649db3d27335587d388b6c09f5ca"},"cell_type":"markdown","source":"## DataLoader"},{"metadata":{"trusted":true,"_uuid":"c783d7639653290fd2654b6f940de6e5476a8af7"},"cell_type":"code","source":"class PetDataset(data.Dataset):\n    def __init__(self, \n                 img_tensor,\n                 cat_features, \n                 num_features,\n                 entity_tensor,\n                 desc_tensor,\n                 seq_tensor,\n                 labels):\n        self.img_tensor = img_tensor\n        self.cat_features = cat_features\n        self.num_features = num_features\n        self.entity_tensor = entity_tensor\n        self.desc_tensor = desc_tensor\n        self.seq_tensor = seq_tensor\n        if labels is not None:\n            self.labels = labels\n        else:\n            self.labels = None\n        \n    def __len__(self):\n        return len(self.cat_features)\n    \n    def __getitem__(self, idx):\n        img_feature = self.img_tensor[idx]\n        cat_feature = self.cat_features[idx]\n        num_feature = self.num_features[idx]\n        entity_feature = self.entity_tensor[idx]\n        desc_feature = self.desc_tensor[idx]\n        seq_feature = self.seq_tensor[idx]\n\n        if self.labels is not None:\n            label = self.labels[idx]\n            return [\n                img_feature, cat_feature, num_feature, \n                entity_feature, desc_feature, seq_feature, label]\n        else:\n            return [img_feature, cat_feature, num_feature,\n                    entity_feature, desc_feature, seq_feature]","execution_count":69,"outputs":[]},{"metadata":{"_uuid":"03c9f5c917def1297f4685e009ef70b21faca3ad"},"cell_type":"markdown","source":"## Trainer"},{"metadata":{"trusted":true,"_uuid":"0dc8f13b4e1311519e85048912cc7701863c6145"},"cell_type":"code","source":"def get_n_params(model):\n    pp=0\n    for p in list(model.parameters()):\n        nn=1\n        for s in list(p.size()):\n            nn = nn*s\n        pp += nn\n    return pp\n\ndef seed_torch(seed=1029):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n\ndef run_xgb(params,\n            X,\n            y,\n            X_test,\n            resc,\n            n_splits=10,\n            num_rounds=60000,\n            early_stop=500,\n            verbose_eval=1000):\n    oof_train = np.zeros((X.shape[0]))\n    oof_test = np.zeros((X_test.shape[0], n_splits))\n    fold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=1213)\n\n    for i, (trn_index, val_index) in enumerate(fold.split(X, y.astype(int))):\n        X_tr = X.iloc[trn_index, :]\n        X_val = X.iloc[val_index, :]\n\n        y_tr = y[trn_index]\n        y_val = y[val_index]\n        d_train = xgb.DMatrix(\n            data=X_tr, label=y_tr, feature_names=X_tr.columns)\n        d_valid = xgb.DMatrix(\n            data=X_val, label=y_val, feature_names=X_val.columns)\n\n        watchlist = [(d_train, \"train\"), (d_valid, \"valid\")]\n        model = xgb.train(\n            params=params,\n            dtrain=d_train,\n            num_boost_round=num_rounds,\n            evals=watchlist,\n            early_stopping_rounds=early_stop,\n            verbose_eval=verbose_eval)\n        valid_pred = model.predict(\n            xgb.DMatrix(X_val, feature_names=X_val.columns),\n            ntree_limit=model.best_ntree_limit)\n        test_pred = model.predict(\n            xgb.DMatrix(X_test, feature_names=X_test.columns),\n            ntree_limit=model.best_ntree_limit)\n        oof_train[val_index] = valid_pred\n        oof_test[:, i] = test_pred\n    return model, oof_train, oof_test\n\n\nclass Trainer:\n    def __init__(self, \n                 model,\n                 resc,\n                 n_splits=5, \n                 seed=42, \n                 device=\"cuda:0\", \n                 train_batch=16,\n                 val_batch=32,\n                 kwargs={}):\n        self.model = model\n        self.n_splits = n_splits\n        self.seed = seed\n        self.device = device\n        self.train_batch = train_batch\n        self.val_batch = val_batch\n        self.kwargs = kwargs\n        self.resc = resc\n        \n        self.best_score = None\n        self.tag = dt.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n        \n        self.loss_fn = nn.MSELoss(reduction=\"mean\").to(self.device)\n        path = Path(f\"bin/{self.tag}\")\n        path.mkdir(exist_ok=True, parents=True)\n        self.path = path\n        \n    def fit(self, \n            img_feats, \n            cat_feats, \n            num_feats, \n            entity_feats,\n            desc_feats,\n            seq_feats, \n            answer, \n            n_epochs=30):\n        self.train_preds = np.zeros((train.shape[0]))\n        answer = answer.values.astype(int)\n        fold = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=self.seed)\n        cat_feats = cat_feats.values\n        for i, (trn_idx, val_idx) in enumerate(fold.split(img_feats, \n                                                          answer)):\n            self.fold_num = i\n            print(f\"Fold: {i+1}\")\n            img_train, img_val = img_feats[trn_idx], img_feats[val_idx]\n            cat_train, cat_val = cat_feats[trn_idx], cat_feats[val_idx]\n            num_train, num_val = num_feats[trn_idx], num_feats[val_idx]\n            ent_train, ent_val = entity_feats[trn_idx], entity_feats[val_idx]\n            dsc_train, dsc_val = desc_feats[trn_idx], desc_feats[val_idx]\n            seq_train, seq_val = seq_feats[trn_idx], seq_feats[val_idx]\n            y_train, y_val = answer[trn_idx] / 4, answer[val_idx] / 4\n            \n            valid_preds = self._fit(img_train, \n                                    cat_train, \n                                    num_train,\n                                    ent_train,\n                                    dsc_train,\n                                    seq_train,\n                                    y_train,\n                                    n_epochs,\n                                    img_val,\n                                    cat_val,\n                                    num_val,\n                                    ent_val,\n                                    dsc_val,\n                                    seq_val,\n                                    y_val)\n            self.train_preds[val_idx] = valid_preds\n        \n    def _fit(self, \n             img, \n             cat, \n             num,\n             ent,\n             dsc,\n             seq,\n             y, \n             n_epochs, \n             img_val, \n             cat_val, \n             num_val,\n             ent_val,\n             dsc_val,\n             seq_val,\n             y_val):\n        seed_torch(self.seed)\n        img_tensor = torch.tensor(img, dtype=torch.float32).to(self.device)\n        cat_tensor = torch.tensor(cat, dtype=torch.long).to(self.device)\n        num_tensor = torch.tensor(num, dtype=torch.float32).to(self.device)\n        ent_tensor = torch.tensor(ent, dtype=torch.float32).to(self.device)\n        dsc_tensor = torch.tensor(dsc, dtype=torch.float32).to(self.device)\n        seq_tensor = torch.tensor(seq, dtype=torch.long).to(self.device)\n        y_tensor = torch.tensor(y[:, np.newaxis], dtype=torch.float32).to(self.device)\n        train = PetDataset(img_tensor, \n                           cat_tensor, \n                           num_tensor,\n                           ent_tensor,\n                           dsc_tensor,\n                           seq_tensor,\n                           y_tensor)\n        train_loader = data.DataLoader(train, \n                                       batch_size=self.train_batch, shuffle=True)\n        img_eval = torch.tensor(img_val, dtype=torch.float32).to(self.device)\n        cat_eval = torch.tensor(cat_val, dtype=torch.long).to(self.device)\n        num_eval = torch.tensor(num_val, dtype=torch.float32).to(self.device)\n        ent_eval = torch.tensor(ent_val, dtype=torch.float32).to(self.device)\n        dsc_eval = torch.tensor(dsc_val, dtype=torch.float32).to(self.device)\n        seq_eval = torch.tensor(seq_val, dtype=torch.long).to(self.device)\n        y_eval = torch.tensor(y_val[:, np.newaxis], dtype=torch.float32).to(self.device)\n        eval_ = PetDataset(img_eval,\n                           cat_eval,\n                           num_eval,\n                           ent_eval,\n                           dsc_eval,\n                           seq_eval,\n                           y_eval)\n        eval_loader = data.DataLoader(eval_,\n                                      batch_size=self.val_batch, shuffle=False)\n        \n        model = self.model(**self.kwargs)\n        model = model.to(self.device)\n        optimizer = optim.Adam(model.parameters())\n        best_score = np.inf\n        mb = master_bar(range(n_epochs))\n        \n        for epoch in mb:\n            model.train()\n            avg_loss = 0.\n            for i_batch, c_batch, n_batch, e_batch, d_batch, s_batch, y_batch in progress_bar(train_loader, parent=mb):\n                y_pred = model(i_batch, c_batch, n_batch, e_batch, d_batch, s_batch)\n                loss = self.loss_fn(y_pred, y_batch)\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n                avg_loss += loss.item() / len(train_loader)\n            valid_preds, avg_val_loss = self._val(eval_loader, model)\n            print(f\"epoch {epoch+1}/{n_epochs}\")\n            print(f\"avg_loss: {avg_loss:.4f}\")\n            print(f\"avg_val_loss: {avg_val_loss:.4f}\")\n            if best_score > avg_val_loss:\n                torch.save(model.state_dict(),\n                           self.path / f\"best{self.fold_num}.pt\")\n                print(f\"Save model on epoch {epoch + 1}\")\n                best_score = avg_val_loss\n        model.load_state_dict(torch.load(self.path / f\"best{self.fold_num}.pt\"))\n        valid_preds, avg_val_loss = self._val(eval_loader, model)\n        print(f\"Validation loss: {avg_val_loss}\")\n        return valid_preds\n    \n    def _val(self, loader, model):\n        model.eval()\n        valid_preds = np.zeros(loader.dataset.cat_features.size(0))\n        avg_val_loss = 0.\n\n        for i, (i_batch, c_batch, n_batch, e_batch, d_batch, s_batch, y_batch) in enumerate(loader):\n            with torch.no_grad():\n                y_pred = model(i_batch, c_batch, n_batch, e_batch, d_batch, s_batch).detach()\n                avg_val_loss += self.loss_fn(y_pred,\n                                             y_batch).item() / len(loader)\n                valid_preds[i * self.val_batch:(i + 1) * self.val_batch] = y_pred.cpu().numpy()[:, 0]\n        return valid_preds, avg_val_loss","execution_count":70,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Attention(nn.Module):\n    def __init__(self, feature_dims, step_dims, n_middle, n_attention,\n                 **kwargs):\n        super(Attention, self).__init__(**kwargs)\n        self.support_masking = True\n        self.feature_dims = feature_dims\n        self.step_dims = step_dims\n        self.n_middle = n_middle\n        self.n_attention = n_attention\n        self.features_dim = 0\n\n        self.lin1 = nn.Linear(feature_dims, n_middle, bias=False)\n        self.lin2 = nn.Linear(n_middle, n_attention, bias=False)\n\n    def forward(self, x, mask=None):\n        step_dims = self.step_dims\n\n        eij = self.lin1(x)\n        eij = torch.tanh(eij)\n        eij = self.lin2(eij)\n\n        a = torch.exp(eij).reshape(-1, self.n_attention, step_dims)\n\n        if mask is not None:\n            a = a * mask\n\n        a = a / torch.sum(a, 2, keepdim=True) + 1e-10\n\n        weighted_input = torch.bmm(a, x)\n        return torch.sum(weighted_input, 1)","execution_count":71,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"81f45cdbc8ee4bd0f11c545461b9ea090f358f8e"},"cell_type":"code","source":"class NeuralNet(nn.Module):\n    def __init__(self, \n                 emb_dims, \n                 num_dims, \n                 img_linear,\n                 ent_linear,\n                 dsc_linear,\n                 seq_linear,\n                 linear_size,\n                 embedding_matrix,\n                 hidden_size,\n                 maxlen,\n                 n_attention):\n        super(NeuralNet, self).__init__()\n        self.img_linear = img_linear\n        n_features, embed_size = embedding_matrix.shape\n        self.img_lin = nn.Linear(1024, img_linear)\n        self.img_attn = Attention(img_linear, 4, 2, 2)\n        self.ent_lin = nn.Linear(300, ent_linear)\n        self.dsc_lin = nn.Linear(300, dsc_linear)\n        self.seq_emb = nn.Embedding(n_features, embed_size)\n        self.seq_emb.weight = nn.Parameter(torch.tensor(\n            embedding_matrix, dtype=torch.float32))\n        self.seq_emb.weight.requires_grad = False\n        self.seq_emb_dropout = nn.Dropout2d(0.2)\n        self.lstm = nn.LSTM(\n            embed_size, hidden_size, bidirectional=True, batch_first=True)\n        self.attn = Attention(hidden_size * 2, maxlen, n_attention,\n                              n_attention)\n        self.seq_lin = nn.Linear(hidden_size * 2, seq_linear)\n\n        self.embeddings = nn.ModuleList(\n            [nn.Embedding(x, y) for x, y in emb_dims])\n        n_emb_out = sum([y for x, y in emb_dims])\n        self.fc1 = nn.Linear(\n            img_linear + n_emb_out + num_dims + ent_linear + dsc_linear + seq_linear, \n            linear_size)\n        self.bn1 = nn.BatchNorm1d(linear_size)\n        self.fc2 = nn.Linear(linear_size, 1)\n        self.drop = nn.Dropout(0.2)\n        self.relu = nn.ReLU()\n        self.tanh = nn.Tanh()\n\n    def forward(self, i, c, n, e, d, s):\n        imgs = torch.zeros(i.size(0), 4, self.img_linear).to(\"cuda:0\")\n        for j in range(4):\n            img_f = self.img_lin(i[:, j, :])\n            imgs[:, j, :] = img_f\n        img_feats = self.drop(self.tanh(self.img_attn(imgs)))\n        ent_feats = self.drop(self.tanh(self.ent_lin(e)))\n        dsc_feats = self.drop(self.tanh(self.dsc_lin(d)))\n        emb = [\n            emb_layer(c[:, j]) for j, emb_layer in enumerate(self.embeddings)\n        ]\n        emb = self.drop(self.tanh(torch.cat(emb, 1)))\n        \n        h_seq = self.seq_emb(s)\n        h_seq = torch.squeeze(\n            self.seq_emb_dropout(torch.unsqueeze(h_seq, 0)))\n        h_lstm, _ = self.lstm(h_seq)\n        h_attn = self.attn(h_lstm)\n        h_lin = self.tanh(self.seq_lin(h_attn))\n        data = torch.cat([img_feats, emb, n, ent_feats, dsc_feats, h_lin], 1)\n        out = self.relu(self.fc1(data))\n        # out = self.drop(out)\n        out = self.bn1(out)\n        out = self.fc2(out)\n        return out","execution_count":72,"outputs":[]},{"metadata":{"_uuid":"4ac9701aff07421363ecbbe2d9dc3720f06e1eaa"},"cell_type":"markdown","source":"## Train"},{"metadata":{"trusted":true,"_uuid":"6e889da94644054a0d19c79a2b202784cb04eb37"},"cell_type":"code","source":"emb_dims = [(2, 1), (n_breed1, 3), (n_breed2, 3), (3, 1), (n_color1, 1),\n            (n_color2, 1), (n_color3, 1), (4, 1), (3, 1), (3, 1),\n            (3, 1), (3, 1), (3, 1), (19, 1), (14, 1),(n_langs, 1)]\nnum_dims = X_test_ss.shape[1]\ntrainer = Trainer(\n    NeuralNet,\n    resc=train_resc,\n    n_splits=10,\n    train_batch=64,\n    val_batch=512,\n    seed=328,\n    kwargs={\n        \"emb_dims\": emb_dims,\n        \"num_dims\": num_dims,\n        \"img_linear\": 48,\n        \"linear_size\": 144,\n        \"ent_linear\": 10,\n        \"dsc_linear\": 10,\n        \"seq_linear\": 20,\n        \"embedding_matrix\": embedding_matrix,\n        \"hidden_size\": 64,\n        \"maxlen\": 70,\n        \"n_attention\": 20\n    })","execution_count":73,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9686ef36b564f8f0684e62f44305bda521cfbdd9"},"cell_type":"code","source":"trainer.fit(train_img_matrix, \n            X_train_cat, \n            X_train_ss, \n            train_entity, \n            train_desc, \n            x_train_text, target, 10)","execution_count":74,"outputs":[{"output_type":"stream","text":"Fold: 1\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Total time: 00:29 <p>"},"metadata":{}},{"output_type":"stream","text":"epoch 1/10\navg_loss: 0.1457\navg_val_loss: 0.6591\nSave model on epoch 1\nepoch 2/10\navg_loss: 0.0748\navg_val_loss: 1.2250\nepoch 3/10\navg_loss: 0.0696\navg_val_loss: 1.0628\nepoch 4/10\navg_loss: 0.0678\navg_val_loss: 1.1016\nepoch 5/10\navg_loss: 0.0668\navg_val_loss: 0.9859\nepoch 6/10\navg_loss: 0.0644\navg_val_loss: 1.0257\nepoch 7/10\navg_loss: 0.0638\navg_val_loss: 0.7892\nepoch 8/10\navg_loss: 0.0622\navg_val_loss: 1.3406\nepoch 9/10\navg_loss: 0.0611\navg_val_loss: 0.5121\nSave model on epoch 9\nepoch 10/10\navg_loss: 0.0595\navg_val_loss: 0.3218\nSave model on epoch 10\nValidation loss: 0.3217883954445521\nFold: 2\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Total time: 00:30 <p>"},"metadata":{}},{"output_type":"stream","text":"epoch 1/10\navg_loss: 0.1465\navg_val_loss: 0.0822\nSave model on epoch 1\nepoch 2/10\navg_loss: 0.0749\navg_val_loss: 0.0765\nSave model on epoch 2\nepoch 3/10\navg_loss: 0.0711\navg_val_loss: 0.0742\nSave model on epoch 3\nepoch 4/10\navg_loss: 0.0687\navg_val_loss: 0.0749\nepoch 5/10\navg_loss: 0.0672\navg_val_loss: 0.0734\nSave model on epoch 5\nepoch 6/10\navg_loss: 0.0658\navg_val_loss: 0.0766\nepoch 7/10\navg_loss: 0.0646\navg_val_loss: 0.0804\nepoch 8/10\navg_loss: 0.0639\navg_val_loss: 0.0832\nepoch 9/10\navg_loss: 0.0626\navg_val_loss: 0.0774\nepoch 10/10\navg_loss: 0.0614\navg_val_loss: 0.0778\nValidation loss: 0.07338353246450424\nFold: 3\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Total time: 00:30 <p>"},"metadata":{}},{"output_type":"stream","text":"epoch 1/10\navg_loss: 0.1464\navg_val_loss: 0.0788\nSave model on epoch 1\nepoch 2/10\navg_loss: 0.0751\navg_val_loss: 0.0719\nSave model on epoch 2\nepoch 3/10\navg_loss: 0.0710\navg_val_loss: 0.0706\nSave model on epoch 3\nepoch 4/10\navg_loss: 0.0687\navg_val_loss: 0.0728\nepoch 5/10\navg_loss: 0.0673\navg_val_loss: 0.0706\nSave model on epoch 5\nepoch 6/10\navg_loss: 0.0659\navg_val_loss: 0.0716\nepoch 7/10\navg_loss: 0.0648\navg_val_loss: 0.0701\nSave model on epoch 7\nepoch 8/10\navg_loss: 0.0627\navg_val_loss: 0.0702\nepoch 9/10\navg_loss: 0.0619\navg_val_loss: 0.0702\nepoch 10/10\navg_loss: 0.0608\navg_val_loss: 0.0702\nValidation loss: 0.07006395111481349\nFold: 4\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Total time: 00:29 <p>"},"metadata":{}},{"output_type":"stream","text":"epoch 1/10\navg_loss: 0.1461\navg_val_loss: 0.0841\nSave model on epoch 1\nepoch 2/10\navg_loss: 0.0745\navg_val_loss: 0.0760\nSave model on epoch 2\nepoch 3/10\navg_loss: 0.0700\navg_val_loss: 0.0746\nSave model on epoch 3\nepoch 4/10\navg_loss: 0.0686\navg_val_loss: 0.0853\nepoch 5/10\navg_loss: 0.0672\navg_val_loss: 0.0740\nSave model on epoch 5\nepoch 6/10\navg_loss: 0.0663\navg_val_loss: 0.0906\nepoch 7/10\navg_loss: 0.0638\navg_val_loss: 0.1402\nepoch 8/10\navg_loss: 0.0629\navg_val_loss: 0.1589\nepoch 9/10\navg_loss: 0.0618\navg_val_loss: 0.1143\nepoch 10/10\navg_loss: 0.0604\navg_val_loss: 0.1403\nValidation loss: 0.07404632121324539\nFold: 5\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Total time: 00:31 <p>"},"metadata":{}},{"output_type":"stream","text":"epoch 1/10\navg_loss: 0.1459\navg_val_loss: 0.0764\nSave model on epoch 1\nepoch 2/10\navg_loss: 0.0746\navg_val_loss: 0.0725\nSave model on epoch 2\nepoch 3/10\navg_loss: 0.0708\navg_val_loss: 0.0709\nSave model on epoch 3\nepoch 4/10\navg_loss: 0.0692\navg_val_loss: 0.0710\nepoch 5/10\navg_loss: 0.0665\navg_val_loss: 0.0710\nepoch 6/10\navg_loss: 0.0659\navg_val_loss: 0.0689\nSave model on epoch 6\nepoch 7/10\navg_loss: 0.0639\navg_val_loss: 0.0728\nepoch 8/10\navg_loss: 0.0630\navg_val_loss: 0.0733\nepoch 9/10\navg_loss: 0.0614\navg_val_loss: 0.0722\nepoch 10/10\navg_loss: 0.0600\navg_val_loss: 0.0727\nValidation loss: 0.06889255344867706\nFold: 6\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Total time: 00:30 <p>"},"metadata":{}},{"output_type":"stream","text":"epoch 1/10\navg_loss: 0.1447\navg_val_loss: 0.0819\nSave model on epoch 1\nepoch 2/10\navg_loss: 0.0742\navg_val_loss: 0.0768\nSave model on epoch 2\nepoch 3/10\navg_loss: 0.0704\navg_val_loss: 0.0757\nSave model on epoch 3\nepoch 4/10\navg_loss: 0.0675\navg_val_loss: 0.0732\nSave model on epoch 4\nepoch 5/10\navg_loss: 0.0660\navg_val_loss: 0.0774\nepoch 6/10\navg_loss: 0.0650\navg_val_loss: 0.0729\nSave model on epoch 6\nepoch 7/10\navg_loss: 0.0634\navg_val_loss: 0.0761\nepoch 8/10\navg_loss: 0.0623\navg_val_loss: 0.0738\nepoch 9/10\navg_loss: 0.0614\navg_val_loss: 0.0738\nepoch 10/10\navg_loss: 0.0608\navg_val_loss: 0.0737\nValidation loss: 0.07290584097305934\nFold: 7\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Total time: 00:30 <p>"},"metadata":{}},{"output_type":"stream","text":"epoch 1/10\navg_loss: 0.1469\navg_val_loss: 0.0772\nSave model on epoch 1\nepoch 2/10\navg_loss: 0.0746\navg_val_loss: 0.0733\nSave model on epoch 2\nepoch 3/10\navg_loss: 0.0713\navg_val_loss: 0.0713\nSave model on epoch 3\nepoch 4/10\navg_loss: 0.0683\navg_val_loss: 0.0695\nSave model on epoch 4\nepoch 5/10\navg_loss: 0.0675\navg_val_loss: 0.0733\nepoch 6/10\navg_loss: 0.0659\navg_val_loss: 0.0726\nepoch 7/10\navg_loss: 0.0644\navg_val_loss: 0.0744\nepoch 8/10\navg_loss: 0.0631\navg_val_loss: 0.0737\nepoch 9/10\navg_loss: 0.0620\navg_val_loss: 0.0727\nepoch 10/10\navg_loss: 0.0611\navg_val_loss: 0.0737\nValidation loss: 0.06954691310723622\nFold: 8\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Total time: 00:31 <p>"},"metadata":{}},{"output_type":"stream","text":"epoch 1/10\navg_loss: 0.1461\navg_val_loss: 0.0759\nSave model on epoch 1\nepoch 2/10\navg_loss: 0.0745\navg_val_loss: 0.0742\nSave model on epoch 2\nepoch 3/10\navg_loss: 0.0706\navg_val_loss: 0.0729\nSave model on epoch 3\nepoch 4/10\navg_loss: 0.0680\navg_val_loss: 0.0709\nSave model on epoch 4\nepoch 5/10\navg_loss: 0.0666\navg_val_loss: 0.0712\nepoch 6/10\navg_loss: 0.0648\navg_val_loss: 0.0717\nepoch 7/10\navg_loss: 0.0637\navg_val_loss: 0.0699\nSave model on epoch 7\nepoch 8/10\navg_loss: 0.0624\navg_val_loss: 0.0723\nepoch 9/10\navg_loss: 0.0620\navg_val_loss: 0.0773\nepoch 10/10\navg_loss: 0.0597\navg_val_loss: 0.0726\nValidation loss: 0.06986319770415624\nFold: 9\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Total time: 00:29 <p>"},"metadata":{}},{"output_type":"stream","text":"epoch 1/10\navg_loss: 0.1474\navg_val_loss: 0.0808\nSave model on epoch 1\nepoch 2/10\navg_loss: 0.0746\navg_val_loss: 0.0748\nSave model on epoch 2\nepoch 3/10\navg_loss: 0.0709\navg_val_loss: 0.0756\nepoch 4/10\navg_loss: 0.0687\navg_val_loss: 0.0735\nSave model on epoch 4\nepoch 5/10\navg_loss: 0.0676\navg_val_loss: 0.0749\nepoch 6/10\navg_loss: 0.0655\navg_val_loss: 0.0747\nepoch 7/10\navg_loss: 0.0642\navg_val_loss: 0.0779\nepoch 8/10\navg_loss: 0.0630\navg_val_loss: 0.0777\nepoch 9/10\navg_loss: 0.0618\navg_val_loss: 0.0743\nepoch 10/10\navg_loss: 0.0600\navg_val_loss: 0.0767\nValidation loss: 0.07349543273448944\nFold: 10\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Total time: 00:31 <p>"},"metadata":{}},{"output_type":"stream","text":"epoch 1/10\navg_loss: 0.1458\navg_val_loss: 0.1707\nSave model on epoch 1\nepoch 2/10\navg_loss: 0.0737\navg_val_loss: 0.2153\nepoch 3/10\navg_loss: 0.0703\navg_val_loss: 0.1803\nepoch 4/10\navg_loss: 0.0682\navg_val_loss: 0.1131\nSave model on epoch 4\nepoch 5/10\navg_loss: 0.0670\navg_val_loss: 0.1479\nepoch 6/10\navg_loss: 0.0661\navg_val_loss: 0.1740\nepoch 7/10\navg_loss: 0.0644\navg_val_loss: 0.0796\nSave model on epoch 7\nepoch 8/10\navg_loss: 0.0631\navg_val_loss: 0.0769\nSave model on epoch 8\nepoch 9/10\navg_loss: 0.0622\navg_val_loss: 0.0836\nepoch 10/10\navg_loss: 0.0608\navg_val_loss: 0.0817\nValidation loss: 0.07690360893805823\n","name":"stdout"}]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"7771e8ce83030684751573b9b62617bca34ccfdd"},"cell_type":"code","source":"bin_path = trainer.path\ntest_preds = np.zeros((X_test_cat.shape[0]))\ni_tensor = torch.tensor(test_img_matrix, dtype=torch.float32).to(trainer.device)\nc_tensor = torch.tensor(X_test_cat.values, dtype=torch.long).to(trainer.device)\nn_tensor = torch.tensor(X_test_ss, dtype=torch.float32).to(trainer.device)\ne_tensor = torch.tensor(test_entity, dtype=torch.float32).to(trainer.device)\nd_tensor = torch.tensor(test_desc, dtype=torch.float32).to(trainer.device)\ns_tensor = torch.tensor(x_test_text, dtype=torch.long).to(trainer.device)\ntest_dataset = PetDataset(i_tensor, \n                          c_tensor, \n                          n_tensor,\n                          e_tensor,\n                          d_tensor,\n                          s_tensor,\n                          labels=None)\ntest_loader = data.DataLoader(test_dataset, batch_size=512, shuffle=False)\n\nfor path in bin_path.iterdir():\n    print(f\"using {str(path)}\")\n    model = NeuralNet(**trainer.kwargs)\n    model.to(\"cuda:0\")\n    model.load_state_dict(torch.load(path))\n\n    model.eval()\n    temp = np.zeros((X_test_cat.shape[0]))\n    for i, (i_batch, c_batch, n_batch, e_batch, d_batch, s_batch) in enumerate(test_loader):\n        i_batch = i_batch.to(trainer.device)\n        with torch.no_grad():\n            y_pred = model(i_batch, c_batch, n_batch, e_batch, d_batch, s_batch).detach()\n            temp[i * 512:(i + 1) * 512] = y_pred.cpu().numpy()[:, 0]\n    test_preds += temp / trainer.n_splits","execution_count":75,"outputs":[{"output_type":"stream","text":"using bin/2019-03-28-15-42-11/best2.pt\nusing bin/2019-03-28-15-42-11/best6.pt\nusing bin/2019-03-28-15-42-11/best8.pt\nusing bin/2019-03-28-15-42-11/best4.pt\nusing bin/2019-03-28-15-42-11/best1.pt\nusing bin/2019-03-28-15-42-11/best7.pt\nusing bin/2019-03-28-15-42-11/best5.pt\nusing bin/2019-03-28-15-42-11/best3.pt\nusing bin/2019-03-28-15-42-11/best0.pt\nusing bin/2019-03-28-15-42-11/best9.pt\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds.mean()","execution_count":76,"outputs":[{"output_type":"execute_result","execution_count":76,"data":{"text/plain":"0.6458578993135113"},"metadata":{}}]},{"metadata":{"_uuid":"1b5f8367580c618fe393e3f7703038bd7fdb1304"},"cell_type":"markdown","source":"## Image"},{"metadata":{"trusted":true,"_uuid":"a49e0a579debd3cd7ca95793fed9ac51be81983f"},"cell_type":"code","source":"class ImageDataset(data.Dataset):\n    def __init__(self, imat):\n        self.imat = imat\n        \n    def __len__(self):\n        return len(self.imat)\n    \n    def __getitem__(self, idx):\n        image = self.imat[idx]\n        \n        return [image]","execution_count":77,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f4f183fc0120f4bc4a8fff9598d26e27ac6d5b6a"},"cell_type":"code","source":"train_i_tensor = torch.tensor(train_img_matrix, dtype=torch.float32).to(\"cuda:0\")\ntest_i_tensor = torch.tensor(test_img_matrix, dtype=torch.float32).to(\"cuda:0\")\ntrain_dataset = ImageDataset(train_i_tensor)\nbatch = 256\nn_img_dim = 48\ntrain_loader = data.DataLoader(train_dataset,\n                               batch_size=batch,\n                               shuffle=False)\nX_train_img = np.zeros((len(train_pet_ids), n_img_dim))\n\ntest_dataset = ImageDataset(test_i_tensor)\ntest_loader = data.DataLoader(test_dataset,\n                              batch_size=batch,\n                              shuffle=False)\nX_test_img = np.zeros((len(test_pet_ids), n_img_dim))\nbin_path = trainer.path\nfor path in bin_path.iterdir():\n    model = NeuralNet(**trainer.kwargs)\n    model.to(\"cuda:0\")\n    model.load_state_dict(torch.load(path))\n    model.eval()\n    temp = np.zeros((len(train_pet_ids), n_img_dim))\n    \n    for i, (i_batch, ) in tqdm(enumerate(train_loader)):\n        with torch.no_grad():\n            imgs = torch.zeros(i_batch.size(0), 4, n_img_dim).to(\"cuda:0\")\n            for j in range(4):\n                pre = model.img_lin(i_batch[:, j, :])\n                imgs[:, j, :] = pre\n            y_pred = model.img_attn(imgs).detach()\n            temp[i * batch:(i + 1) * batch, :] = y_pred.cpu().numpy()\n    X_train_img += temp / trainer.n_splits\n    \n    temp = np.zeros((len(test_pet_ids), n_img_dim))\n    for i, (i_batch, ) in tqdm(enumerate(test_loader)):\n        with torch.no_grad():\n            imgs = torch.zeros(i_batch.size(0), 4, n_img_dim).to(\"cuda:0\")\n            for j in range(4):\n                pre = model.img_lin(i_batch[:, j, :])\n                imgs[:, j, :] = pre\n            y_pred = model.img_attn(imgs).detach()\n            temp[i * batch:(i + 1) * batch, :] = y_pred.cpu().numpy()\n    X_test_img += temp / trainer.n_splits","execution_count":78,"outputs":[{"output_type":"stream","text":"59it [00:00, 658.63it/s]\n16it [00:00, 603.25it/s]\n59it [00:00, 665.25it/s]\n16it [00:00, 680.38it/s]\n59it [00:00, 655.75it/s]\n16it [00:00, 656.49it/s]\n59it [00:00, 646.20it/s]\n16it [00:00, 658.53it/s]\n59it [00:00, 651.35it/s]\n16it [00:00, 655.43it/s]\n59it [00:00, 647.76it/s]\n16it [00:00, 617.95it/s]\n59it [00:00, 668.37it/s]\n16it [00:00, 649.95it/s]\n59it [00:00, 650.77it/s]\n16it [00:00, 631.01it/s]\n59it [00:00, 670.78it/s]\n16it [00:00, 658.06it/s]\n59it [00:00, 638.65it/s]\n16it [00:00, 634.64it/s]\n","name":"stderr"}]},{"metadata":{"trusted":true,"_uuid":"398fff9d745229e06a4d4e40be9cb6a2b85e3ea5"},"cell_type":"code","source":"X_train_img.shape, X_test_img.shape","execution_count":79,"outputs":[{"output_type":"execute_result","execution_count":79,"data":{"text/plain":"((14993, 48), (3948, 48))"},"metadata":{}}]},{"metadata":{"trusted":true,"_uuid":"dea3e37fd67308876118a9f9eecafa3f4aff97c8"},"cell_type":"code","source":"train_img = pd.DataFrame(data=X_train_img, columns=[\n    f\"img{i}\" for i in range(X_train_img.shape[1])\n])\ntest_img = pd.DataFrame(data=X_test_img, columns=[\n    f\"img{i}\" for i in range(X_test_img.shape[1])\n])","execution_count":80,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a30d386881498532f29122ba3c2595bcbdb54e94"},"cell_type":"code","source":"num_columns = X_train_num.columns\nX_train_num_df = pd.DataFrame(data=X_train_ss, columns=num_columns)\nX_test_num_df = pd.DataFrame(data=X_test_ss, columns=num_columns)\n\nX_test_num_df.index = X_test_cat.index\ntest_img.index = X_test_cat.index\n\nX_train_all = pd.concat([X_train_num_df, X_train_cat, train_img], axis=1)\nX_test_all = pd.concat([X_test_num_df, X_test_cat, test_img], axis=1)\n\nprint(X_train_all.shape, X_test_all.shape)\nX_train_all.head()","execution_count":81,"outputs":[{"output_type":"stream","text":"(14993, 218) (3948, 218)\n","name":"stdout"},{"output_type":"execute_result","execution_count":81,"data":{"text/plain":"        Age       Fee  VideoAmt  PhotoAmt  magnitude_sum  magnitude_mean  \\\n0 -0.421104  0.960767 -0.162959 -0.816674       0.175573       -0.089689   \n1 -0.530710 -0.279390 -0.162959 -0.532377      -0.648924       -0.163610   \n2 -0.530710 -0.279390 -0.162959  0.889111       0.835170        0.438317   \n3 -0.366301  1.580845 -0.162959  1.173408      -0.538991        2.275777   \n4 -0.530710 -0.279390 -0.162959 -0.248079       0.890136        0.871281   \n\n   magnitude_var  score_sum  score_mean  score_var  document_magnitude  \\\n0       0.720044   0.392032    0.057521   0.376737            0.161785   \n1      -0.031676  -1.250631   -1.939791   0.140569           -0.676014   \n2       1.133721   0.106352   -0.305627   2.070637            0.802455   \n3      -1.214452  -0.250749    2.236407  -1.056562           -0.577449   \n4       0.136541   1.606175    1.086440  -0.358914            0.802455   \n\n   document_score  annot_score_SUM  annot_score_MEAN  annot_score_VAR  \\\n0        0.099729        -0.798692          0.532229        -0.618650   \n1       -1.701005        -0.522569          0.253078        -0.552837   \n2       -0.260418         0.905726          0.201793        -0.041704   \n3        2.260610         1.095797         -0.060583        -0.496847   \n4        1.180169        -0.255537          0.094133         5.585148   \n\n   color_score_SUM  color_score_MEAN  color_score_VAR  pixel_frac_SUM  \\\n0        -0.842711         -0.520689        -0.063222       -0.779326   \n1        -0.489244          0.448827        -0.037801       -0.532728   \n2         1.062379          0.597325        -0.036040        1.031460   \n3         1.063514         -0.077532         0.120986        1.168248   \n4        -0.307276         -0.237184        -0.013624       -0.529883   \n\n   pixel_frac_MEAN  pixel_frac_VAR  crop_conf_SUM  crop_conf_MEAN  \\\n0         0.057136       -0.163850      -0.817486        0.138982   \n1        -0.071330       -0.139008      -0.533878        0.138982   \n2         0.404513        0.123483       0.884162        0.138982   \n3         0.164305        0.199442       1.167770        0.138982   \n4        -1.088897       -0.153880      -0.250270        0.138982   \n\n   crop_conf_VAR  crop_importance_SUM  crop_importance_MEAN  \\\n0      -0.137805            -0.817133              0.139028   \n1      -0.137805            -0.533092              0.139028   \n2      -0.137805             0.887115              0.139028   \n3      -0.137805             1.171157              0.139028   \n4      -0.137805            -0.254731              0.098731   \n\n   crop_importance_VAR  specified_SUM  specified_MEAN  specified_VAR  \\\n0            -0.042402      -0.813932        0.220208       -0.18826   \n1            -0.042402      -0.524526        0.220208       -0.18826   \n2            -0.042402       0.922507        0.220208       -0.18826   \n3            -0.042402       1.211914        0.220208       -0.18826   \n4            -0.041352      -0.235119        0.220208       -0.18826   \n\n   main_breed_Type  second_breed_Type  len_description  len_meta_desc  \\\n0          1.05936          -0.562268         0.482345      -0.970235   \n1          1.05936          -0.562268        -0.544292      -0.327012   \n2         -0.94197          -0.562268         0.566042       1.064897   \n3         -0.94197          -0.562268        -0.348319       1.092567   \n4         -0.94197          -0.562268         0.558953       0.058157   \n\n   len_entity  num_description_words  num_desc_words  num_entity_words  \\\n0    0.500955               0.519078       -1.027484          0.443748   \n1   -0.978440              -0.506754       -0.314407         -1.243792   \n2    0.609698               0.519078        1.102149          0.590031   \n3   -0.072772              -0.430047        1.150112         -0.169305   \n4    0.409054               0.670708       -0.009517          0.443748   \n\n   uniq_description_words  uniq_desc_words  uniq_entity_words  \\\n0                0.539772        -0.266118           0.453230   \n1               -0.542146         0.253030          -1.234661   \n2                0.593479         0.510427           0.617952   \n3               -0.356466         0.253030          -0.105635   \n4                0.677378         0.061120           0.538535   \n\n   num_description_stopwords  num_desc_stopwords  num_entity_stopwords  \\\n0                   0.669926           -0.021144             -0.357513   \n1                  -0.155182            0.482987             -0.357513   \n2                   0.568819           -0.882961             -0.357513   \n3                  -0.461536           -0.882961             -0.357513   \n4                   0.841422           -0.882961             -0.357513   \n\n   num_description_punctuation  state_gdp  state_population  state_area  \\\n0                     0.083495   0.642057          0.837369    0.620169   \n1                    -1.032706  -0.122787         -1.155849   -1.532409   \n2                     0.190543   0.642057          0.837369    0.620169   \n3                    -0.036174  -0.122787         -1.155849   -1.532409   \n4                     0.190543   0.642057          0.837369    0.620169   \n\n   state_gdp_per_person  fee_per_gdp_per_person  num_name_words  contains_amp  \\\n0             -0.414149                0.866557       -0.499373     -0.320762   \n1              1.527495               -0.229461        0.967877     -0.320762   \n2             -0.414149               -0.229461       -0.499373     -0.320762   \n3              1.527495                0.514889       -0.499373     -0.320762   \n4             -0.414149               -0.229461       -0.499373     -0.320762   \n\n   contains_comma  start_with_number  contains_paren  contains_number  \\\n0       -0.154216          -0.147911       -0.188211        -0.290496   \n1       -0.154216          -0.147911       -0.188211        -0.290496   \n2       -0.154216          -0.147911       -0.188211        -0.290496   \n3       -0.154216          -0.147911       -0.188211        -0.290496   \n4       -0.154216          -0.147911       -0.188211        -0.290496   \n\n   name_length  num_unlike_letters  rate_unlike_letters  Tfidf_Description_0  \\\n0    -0.391155           -0.323289            -0.313549             0.044744   \n1     0.289119           -0.323289            -0.313549            -0.701180   \n2    -0.391155           -0.323289            -0.313549             0.308158   \n3    -0.663264           -0.323289            -0.313549            -0.431990   \n4    -0.391155           -0.323289            -0.313549             1.418634   \n\n   Tfidf_Description_1  Tfidf_Description_2  Tfidf_Description_3  \\\n0            -0.233591            -0.294805            -0.151926   \n1            -0.112283            -0.185616            -0.087399   \n2            -0.293496             0.889665            -0.106772   \n3             0.094940             0.036552             0.174450   \n4            -0.141192            -0.081388            -0.214699   \n\n   Tfidf_Description_4    ...     Breed2  Gender  Color1  Color2  Color3  \\\n0            -0.270423    ...          0       0       0       6       0   \n1            -0.108876    ...          0       0       0       1       0   \n2             0.448940    ...          0       0       1       6       0   \n3             0.179728    ...          0       1       0       1       0   \n4            -0.241654    ...          0       0       0       0       0   \n\n   MaturitySize  FurLength  Vaccinated  Dewormed  Sterilized  Health  \\\n0             0          0           1         1           1       0   \n1             1          1           2         2           2       0   \n2             1          1           0         0           1       0   \n3             1          0           0         0           1       0   \n4             1          0           1         1           1       0   \n\n   Quantity  State  language  main_breed_BreedName  second_breed_BreedName  \\\n0         0      2         0                     1                       0   \n1         0     12         0                     2                       0   \n2         0      2         0                     3                       0   \n3         0     12         0                     3                       0   \n4         0      2         0                     3                       0   \n\n       img0      img1      img2      img3      img4      img5      img6  \\\n0 -1.631203  2.281222  0.277297  2.520319  0.168729 -3.337685  1.064453   \n1 -1.950484  1.872433  0.385625  2.771961  1.116230 -4.560302  1.727993   \n2 -0.752485  1.079586 -0.337594  1.618275  3.100527 -6.055088  1.791643   \n3 -1.147095  1.001488 -0.203927  2.309911  1.745109 -6.635424  1.869569   \n4 -0.949794  2.394159  0.033539  3.310833  1.986516 -5.723174  1.913906   \n\n       img7      img8      img9     img10     img11     img12     img13  \\\n0  2.504577 -0.776440 -0.834316  2.067906  3.124545  1.462572 -1.885166   \n1  2.821769 -1.340741 -0.531848  3.389417  4.487653  1.354946 -2.532177   \n2  2.673058 -2.455977 -0.350956  3.939216  6.515712  1.124512 -3.453139   \n3  4.532476 -2.524938 -0.405398  2.687588  6.945358  1.404643 -3.726660   \n4  3.789460 -1.625948 -0.507198  2.993006  6.126325  1.278870 -3.418134   \n\n      img14     img15     img16     img17     img18     img19     img20  \\\n0  0.110586  2.151125 -1.176674  2.415041  0.703949 -1.588303 -0.543489   \n1 -0.045172  2.472195 -1.435838  2.977570  1.420283 -1.214347 -1.046712   \n2  0.706491  3.740337 -1.754591  3.044297  1.617188 -1.144515 -1.906649   \n3  0.714303  3.766063 -2.171436  5.997324 -0.004172 -1.723910 -1.578517   \n4  0.556824  3.220304 -2.013937  3.848544  1.438846 -0.914814 -1.009198   \n\n      img21     img22     img23     img24     img25     img26     img27  \\\n0  0.818192 -1.419860  1.635671  1.230090  1.056767 -0.403665  1.106224   \n1  0.765651 -1.661028  2.115986  1.341369  1.500666 -1.049592  1.269030   \n2  1.023324 -3.877063  3.639141  1.870255  2.687016 -1.305590  0.844590   \n3  2.265283 -3.442194  3.262680  3.076942  2.515201 -1.821304  1.635721   \n4  1.642408 -3.110111  3.080442  1.862627  2.129172 -1.850668  1.173814   \n\n      img28     img29     img30     img31     img32     img33     img34  \\\n0  0.096388  1.556007 -0.848707  0.224280 -3.398524  0.857789 -0.167985   \n1 -0.071501  1.327432 -0.891723  1.284225 -4.005236  1.059146 -0.553956   \n2 -0.206637  1.519087 -2.179879  0.798290 -4.847266  0.724858 -0.536026   \n3  0.145540  3.523111 -1.485916  0.318308 -4.195776  1.051438  0.223658   \n4 -0.381908  2.133727 -1.585165  0.725314 -4.943785  0.924910 -0.557188   \n\n      img35     img36     img37     img38     img39     img40     img41  \\\n0 -0.397752 -3.545173 -0.916391  0.599372 -0.187137 -1.365577 -2.507689   \n1  0.564387 -4.653399 -1.162407  1.164328 -0.568253 -1.356671 -3.293017   \n2  1.163803 -7.355669 -1.725377  1.048077  0.049122 -3.023522 -4.714112   \n3  1.014659 -8.322213 -1.678787  0.642676 -0.352061 -2.542596 -5.023290   \n4  0.781747 -6.047087 -0.984050  0.611377 -0.838628 -2.316990 -4.628384   \n\n      img42     img43     img44     img45     img46     img47  \n0  0.546872  0.475532 -1.821823  0.759485 -0.163166  1.413023  \n1  0.985037  1.320855 -1.992518  1.044078  0.064549  1.250380  \n2  1.180708  1.768260 -4.127668  3.099615  0.795191  1.659834  \n3  2.166600  0.604448 -5.354814  1.882512  0.037363  2.774812  \n4  1.059011  1.744222 -3.782774  2.087450  0.691992  1.934122  \n\n[5 rows x 218 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Fee</th>\n      <th>VideoAmt</th>\n      <th>PhotoAmt</th>\n      <th>magnitude_sum</th>\n      <th>magnitude_mean</th>\n      <th>magnitude_var</th>\n      <th>score_sum</th>\n      <th>score_mean</th>\n      <th>score_var</th>\n      <th>document_magnitude</th>\n      <th>document_score</th>\n      <th>annot_score_SUM</th>\n      <th>annot_score_MEAN</th>\n      <th>annot_score_VAR</th>\n      <th>color_score_SUM</th>\n      <th>color_score_MEAN</th>\n      <th>color_score_VAR</th>\n      <th>pixel_frac_SUM</th>\n      <th>pixel_frac_MEAN</th>\n      <th>pixel_frac_VAR</th>\n      <th>crop_conf_SUM</th>\n      <th>crop_conf_MEAN</th>\n      <th>crop_conf_VAR</th>\n      <th>crop_importance_SUM</th>\n      <th>crop_importance_MEAN</th>\n      <th>crop_importance_VAR</th>\n      <th>specified_SUM</th>\n      <th>specified_MEAN</th>\n      <th>specified_VAR</th>\n      <th>main_breed_Type</th>\n      <th>second_breed_Type</th>\n      <th>len_description</th>\n      <th>len_meta_desc</th>\n      <th>len_entity</th>\n      <th>num_description_words</th>\n      <th>num_desc_words</th>\n      <th>num_entity_words</th>\n      <th>uniq_description_words</th>\n      <th>uniq_desc_words</th>\n      <th>uniq_entity_words</th>\n      <th>num_description_stopwords</th>\n      <th>num_desc_stopwords</th>\n      <th>num_entity_stopwords</th>\n      <th>num_description_punctuation</th>\n      <th>state_gdp</th>\n      <th>state_population</th>\n      <th>state_area</th>\n      <th>state_gdp_per_person</th>\n      <th>fee_per_gdp_per_person</th>\n      <th>num_name_words</th>\n      <th>contains_amp</th>\n      <th>contains_comma</th>\n      <th>start_with_number</th>\n      <th>contains_paren</th>\n      <th>contains_number</th>\n      <th>name_length</th>\n      <th>num_unlike_letters</th>\n      <th>rate_unlike_letters</th>\n      <th>Tfidf_Description_0</th>\n      <th>Tfidf_Description_1</th>\n      <th>Tfidf_Description_2</th>\n      <th>Tfidf_Description_3</th>\n      <th>Tfidf_Description_4</th>\n      <th>...</th>\n      <th>Breed2</th>\n      <th>Gender</th>\n      <th>Color1</th>\n      <th>Color2</th>\n      <th>Color3</th>\n      <th>MaturitySize</th>\n      <th>FurLength</th>\n      <th>Vaccinated</th>\n      <th>Dewormed</th>\n      <th>Sterilized</th>\n      <th>Health</th>\n      <th>Quantity</th>\n      <th>State</th>\n      <th>language</th>\n      <th>main_breed_BreedName</th>\n      <th>second_breed_BreedName</th>\n      <th>img0</th>\n      <th>img1</th>\n      <th>img2</th>\n      <th>img3</th>\n      <th>img4</th>\n      <th>img5</th>\n      <th>img6</th>\n      <th>img7</th>\n      <th>img8</th>\n      <th>img9</th>\n      <th>img10</th>\n      <th>img11</th>\n      <th>img12</th>\n      <th>img13</th>\n      <th>img14</th>\n      <th>img15</th>\n      <th>img16</th>\n      <th>img17</th>\n      <th>img18</th>\n      <th>img19</th>\n      <th>img20</th>\n      <th>img21</th>\n      <th>img22</th>\n      <th>img23</th>\n      <th>img24</th>\n      <th>img25</th>\n      <th>img26</th>\n      <th>img27</th>\n      <th>img28</th>\n      <th>img29</th>\n      <th>img30</th>\n      <th>img31</th>\n      <th>img32</th>\n      <th>img33</th>\n      <th>img34</th>\n      <th>img35</th>\n      <th>img36</th>\n      <th>img37</th>\n      <th>img38</th>\n      <th>img39</th>\n      <th>img40</th>\n      <th>img41</th>\n      <th>img42</th>\n      <th>img43</th>\n      <th>img44</th>\n      <th>img45</th>\n      <th>img46</th>\n      <th>img47</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.421104</td>\n      <td>0.960767</td>\n      <td>-0.162959</td>\n      <td>-0.816674</td>\n      <td>0.175573</td>\n      <td>-0.089689</td>\n      <td>0.720044</td>\n      <td>0.392032</td>\n      <td>0.057521</td>\n      <td>0.376737</td>\n      <td>0.161785</td>\n      <td>0.099729</td>\n      <td>-0.798692</td>\n      <td>0.532229</td>\n      <td>-0.618650</td>\n      <td>-0.842711</td>\n      <td>-0.520689</td>\n      <td>-0.063222</td>\n      <td>-0.779326</td>\n      <td>0.057136</td>\n      <td>-0.163850</td>\n      <td>-0.817486</td>\n      <td>0.138982</td>\n      <td>-0.137805</td>\n      <td>-0.817133</td>\n      <td>0.139028</td>\n      <td>-0.042402</td>\n      <td>-0.813932</td>\n      <td>0.220208</td>\n      <td>-0.18826</td>\n      <td>1.05936</td>\n      <td>-0.562268</td>\n      <td>0.482345</td>\n      <td>-0.970235</td>\n      <td>0.500955</td>\n      <td>0.519078</td>\n      <td>-1.027484</td>\n      <td>0.443748</td>\n      <td>0.539772</td>\n      <td>-0.266118</td>\n      <td>0.453230</td>\n      <td>0.669926</td>\n      <td>-0.021144</td>\n      <td>-0.357513</td>\n      <td>0.083495</td>\n      <td>0.642057</td>\n      <td>0.837369</td>\n      <td>0.620169</td>\n      <td>-0.414149</td>\n      <td>0.866557</td>\n      <td>-0.499373</td>\n      <td>-0.320762</td>\n      <td>-0.154216</td>\n      <td>-0.147911</td>\n      <td>-0.188211</td>\n      <td>-0.290496</td>\n      <td>-0.391155</td>\n      <td>-0.323289</td>\n      <td>-0.313549</td>\n      <td>0.044744</td>\n      <td>-0.233591</td>\n      <td>-0.294805</td>\n      <td>-0.151926</td>\n      <td>-0.270423</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>-1.631203</td>\n      <td>2.281222</td>\n      <td>0.277297</td>\n      <td>2.520319</td>\n      <td>0.168729</td>\n      <td>-3.337685</td>\n      <td>1.064453</td>\n      <td>2.504577</td>\n      <td>-0.776440</td>\n      <td>-0.834316</td>\n      <td>2.067906</td>\n      <td>3.124545</td>\n      <td>1.462572</td>\n      <td>-1.885166</td>\n      <td>0.110586</td>\n      <td>2.151125</td>\n      <td>-1.176674</td>\n      <td>2.415041</td>\n      <td>0.703949</td>\n      <td>-1.588303</td>\n      <td>-0.543489</td>\n      <td>0.818192</td>\n      <td>-1.419860</td>\n      <td>1.635671</td>\n      <td>1.230090</td>\n      <td>1.056767</td>\n      <td>-0.403665</td>\n      <td>1.106224</td>\n      <td>0.096388</td>\n      <td>1.556007</td>\n      <td>-0.848707</td>\n      <td>0.224280</td>\n      <td>-3.398524</td>\n      <td>0.857789</td>\n      <td>-0.167985</td>\n      <td>-0.397752</td>\n      <td>-3.545173</td>\n      <td>-0.916391</td>\n      <td>0.599372</td>\n      <td>-0.187137</td>\n      <td>-1.365577</td>\n      <td>-2.507689</td>\n      <td>0.546872</td>\n      <td>0.475532</td>\n      <td>-1.821823</td>\n      <td>0.759485</td>\n      <td>-0.163166</td>\n      <td>1.413023</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.530710</td>\n      <td>-0.279390</td>\n      <td>-0.162959</td>\n      <td>-0.532377</td>\n      <td>-0.648924</td>\n      <td>-0.163610</td>\n      <td>-0.031676</td>\n      <td>-1.250631</td>\n      <td>-1.939791</td>\n      <td>0.140569</td>\n      <td>-0.676014</td>\n      <td>-1.701005</td>\n      <td>-0.522569</td>\n      <td>0.253078</td>\n      <td>-0.552837</td>\n      <td>-0.489244</td>\n      <td>0.448827</td>\n      <td>-0.037801</td>\n      <td>-0.532728</td>\n      <td>-0.071330</td>\n      <td>-0.139008</td>\n      <td>-0.533878</td>\n      <td>0.138982</td>\n      <td>-0.137805</td>\n      <td>-0.533092</td>\n      <td>0.139028</td>\n      <td>-0.042402</td>\n      <td>-0.524526</td>\n      <td>0.220208</td>\n      <td>-0.18826</td>\n      <td>1.05936</td>\n      <td>-0.562268</td>\n      <td>-0.544292</td>\n      <td>-0.327012</td>\n      <td>-0.978440</td>\n      <td>-0.506754</td>\n      <td>-0.314407</td>\n      <td>-1.243792</td>\n      <td>-0.542146</td>\n      <td>0.253030</td>\n      <td>-1.234661</td>\n      <td>-0.155182</td>\n      <td>0.482987</td>\n      <td>-0.357513</td>\n      <td>-1.032706</td>\n      <td>-0.122787</td>\n      <td>-1.155849</td>\n      <td>-1.532409</td>\n      <td>1.527495</td>\n      <td>-0.229461</td>\n      <td>0.967877</td>\n      <td>-0.320762</td>\n      <td>-0.154216</td>\n      <td>-0.147911</td>\n      <td>-0.188211</td>\n      <td>-0.290496</td>\n      <td>0.289119</td>\n      <td>-0.323289</td>\n      <td>-0.313549</td>\n      <td>-0.701180</td>\n      <td>-0.112283</td>\n      <td>-0.185616</td>\n      <td>-0.087399</td>\n      <td>-0.108876</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>-1.950484</td>\n      <td>1.872433</td>\n      <td>0.385625</td>\n      <td>2.771961</td>\n      <td>1.116230</td>\n      <td>-4.560302</td>\n      <td>1.727993</td>\n      <td>2.821769</td>\n      <td>-1.340741</td>\n      <td>-0.531848</td>\n      <td>3.389417</td>\n      <td>4.487653</td>\n      <td>1.354946</td>\n      <td>-2.532177</td>\n      <td>-0.045172</td>\n      <td>2.472195</td>\n      <td>-1.435838</td>\n      <td>2.977570</td>\n      <td>1.420283</td>\n      <td>-1.214347</td>\n      <td>-1.046712</td>\n      <td>0.765651</td>\n      <td>-1.661028</td>\n      <td>2.115986</td>\n      <td>1.341369</td>\n      <td>1.500666</td>\n      <td>-1.049592</td>\n      <td>1.269030</td>\n      <td>-0.071501</td>\n      <td>1.327432</td>\n      <td>-0.891723</td>\n      <td>1.284225</td>\n      <td>-4.005236</td>\n      <td>1.059146</td>\n      <td>-0.553956</td>\n      <td>0.564387</td>\n      <td>-4.653399</td>\n      <td>-1.162407</td>\n      <td>1.164328</td>\n      <td>-0.568253</td>\n      <td>-1.356671</td>\n      <td>-3.293017</td>\n      <td>0.985037</td>\n      <td>1.320855</td>\n      <td>-1.992518</td>\n      <td>1.044078</td>\n      <td>0.064549</td>\n      <td>1.250380</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.530710</td>\n      <td>-0.279390</td>\n      <td>-0.162959</td>\n      <td>0.889111</td>\n      <td>0.835170</td>\n      <td>0.438317</td>\n      <td>1.133721</td>\n      <td>0.106352</td>\n      <td>-0.305627</td>\n      <td>2.070637</td>\n      <td>0.802455</td>\n      <td>-0.260418</td>\n      <td>0.905726</td>\n      <td>0.201793</td>\n      <td>-0.041704</td>\n      <td>1.062379</td>\n      <td>0.597325</td>\n      <td>-0.036040</td>\n      <td>1.031460</td>\n      <td>0.404513</td>\n      <td>0.123483</td>\n      <td>0.884162</td>\n      <td>0.138982</td>\n      <td>-0.137805</td>\n      <td>0.887115</td>\n      <td>0.139028</td>\n      <td>-0.042402</td>\n      <td>0.922507</td>\n      <td>0.220208</td>\n      <td>-0.18826</td>\n      <td>-0.94197</td>\n      <td>-0.562268</td>\n      <td>0.566042</td>\n      <td>1.064897</td>\n      <td>0.609698</td>\n      <td>0.519078</td>\n      <td>1.102149</td>\n      <td>0.590031</td>\n      <td>0.593479</td>\n      <td>0.510427</td>\n      <td>0.617952</td>\n      <td>0.568819</td>\n      <td>-0.882961</td>\n      <td>-0.357513</td>\n      <td>0.190543</td>\n      <td>0.642057</td>\n      <td>0.837369</td>\n      <td>0.620169</td>\n      <td>-0.414149</td>\n      <td>-0.229461</td>\n      <td>-0.499373</td>\n      <td>-0.320762</td>\n      <td>-0.154216</td>\n      <td>-0.147911</td>\n      <td>-0.188211</td>\n      <td>-0.290496</td>\n      <td>-0.391155</td>\n      <td>-0.323289</td>\n      <td>-0.313549</td>\n      <td>0.308158</td>\n      <td>-0.293496</td>\n      <td>0.889665</td>\n      <td>-0.106772</td>\n      <td>0.448940</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>6</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>-0.752485</td>\n      <td>1.079586</td>\n      <td>-0.337594</td>\n      <td>1.618275</td>\n      <td>3.100527</td>\n      <td>-6.055088</td>\n      <td>1.791643</td>\n      <td>2.673058</td>\n      <td>-2.455977</td>\n      <td>-0.350956</td>\n      <td>3.939216</td>\n      <td>6.515712</td>\n      <td>1.124512</td>\n      <td>-3.453139</td>\n      <td>0.706491</td>\n      <td>3.740337</td>\n      <td>-1.754591</td>\n      <td>3.044297</td>\n      <td>1.617188</td>\n      <td>-1.144515</td>\n      <td>-1.906649</td>\n      <td>1.023324</td>\n      <td>-3.877063</td>\n      <td>3.639141</td>\n      <td>1.870255</td>\n      <td>2.687016</td>\n      <td>-1.305590</td>\n      <td>0.844590</td>\n      <td>-0.206637</td>\n      <td>1.519087</td>\n      <td>-2.179879</td>\n      <td>0.798290</td>\n      <td>-4.847266</td>\n      <td>0.724858</td>\n      <td>-0.536026</td>\n      <td>1.163803</td>\n      <td>-7.355669</td>\n      <td>-1.725377</td>\n      <td>1.048077</td>\n      <td>0.049122</td>\n      <td>-3.023522</td>\n      <td>-4.714112</td>\n      <td>1.180708</td>\n      <td>1.768260</td>\n      <td>-4.127668</td>\n      <td>3.099615</td>\n      <td>0.795191</td>\n      <td>1.659834</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.366301</td>\n      <td>1.580845</td>\n      <td>-0.162959</td>\n      <td>1.173408</td>\n      <td>-0.538991</td>\n      <td>2.275777</td>\n      <td>-1.214452</td>\n      <td>-0.250749</td>\n      <td>2.236407</td>\n      <td>-1.056562</td>\n      <td>-0.577449</td>\n      <td>2.260610</td>\n      <td>1.095797</td>\n      <td>-0.060583</td>\n      <td>-0.496847</td>\n      <td>1.063514</td>\n      <td>-0.077532</td>\n      <td>0.120986</td>\n      <td>1.168248</td>\n      <td>0.164305</td>\n      <td>0.199442</td>\n      <td>1.167770</td>\n      <td>0.138982</td>\n      <td>-0.137805</td>\n      <td>1.171157</td>\n      <td>0.139028</td>\n      <td>-0.042402</td>\n      <td>1.211914</td>\n      <td>0.220208</td>\n      <td>-0.18826</td>\n      <td>-0.94197</td>\n      <td>-0.562268</td>\n      <td>-0.348319</td>\n      <td>1.092567</td>\n      <td>-0.072772</td>\n      <td>-0.430047</td>\n      <td>1.150112</td>\n      <td>-0.169305</td>\n      <td>-0.356466</td>\n      <td>0.253030</td>\n      <td>-0.105635</td>\n      <td>-0.461536</td>\n      <td>-0.882961</td>\n      <td>-0.357513</td>\n      <td>-0.036174</td>\n      <td>-0.122787</td>\n      <td>-1.155849</td>\n      <td>-1.532409</td>\n      <td>1.527495</td>\n      <td>0.514889</td>\n      <td>-0.499373</td>\n      <td>-0.320762</td>\n      <td>-0.154216</td>\n      <td>-0.147911</td>\n      <td>-0.188211</td>\n      <td>-0.290496</td>\n      <td>-0.663264</td>\n      <td>-0.323289</td>\n      <td>-0.313549</td>\n      <td>-0.431990</td>\n      <td>0.094940</td>\n      <td>0.036552</td>\n      <td>0.174450</td>\n      <td>0.179728</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>-1.147095</td>\n      <td>1.001488</td>\n      <td>-0.203927</td>\n      <td>2.309911</td>\n      <td>1.745109</td>\n      <td>-6.635424</td>\n      <td>1.869569</td>\n      <td>4.532476</td>\n      <td>-2.524938</td>\n      <td>-0.405398</td>\n      <td>2.687588</td>\n      <td>6.945358</td>\n      <td>1.404643</td>\n      <td>-3.726660</td>\n      <td>0.714303</td>\n      <td>3.766063</td>\n      <td>-2.171436</td>\n      <td>5.997324</td>\n      <td>-0.004172</td>\n      <td>-1.723910</td>\n      <td>-1.578517</td>\n      <td>2.265283</td>\n      <td>-3.442194</td>\n      <td>3.262680</td>\n      <td>3.076942</td>\n      <td>2.515201</td>\n      <td>-1.821304</td>\n      <td>1.635721</td>\n      <td>0.145540</td>\n      <td>3.523111</td>\n      <td>-1.485916</td>\n      <td>0.318308</td>\n      <td>-4.195776</td>\n      <td>1.051438</td>\n      <td>0.223658</td>\n      <td>1.014659</td>\n      <td>-8.322213</td>\n      <td>-1.678787</td>\n      <td>0.642676</td>\n      <td>-0.352061</td>\n      <td>-2.542596</td>\n      <td>-5.023290</td>\n      <td>2.166600</td>\n      <td>0.604448</td>\n      <td>-5.354814</td>\n      <td>1.882512</td>\n      <td>0.037363</td>\n      <td>2.774812</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.530710</td>\n      <td>-0.279390</td>\n      <td>-0.162959</td>\n      <td>-0.248079</td>\n      <td>0.890136</td>\n      <td>0.871281</td>\n      <td>0.136541</td>\n      <td>1.606175</td>\n      <td>1.086440</td>\n      <td>-0.358914</td>\n      <td>0.802455</td>\n      <td>1.180169</td>\n      <td>-0.255537</td>\n      <td>0.094133</td>\n      <td>5.585148</td>\n      <td>-0.307276</td>\n      <td>-0.237184</td>\n      <td>-0.013624</td>\n      <td>-0.529883</td>\n      <td>-1.088897</td>\n      <td>-0.153880</td>\n      <td>-0.250270</td>\n      <td>0.138982</td>\n      <td>-0.137805</td>\n      <td>-0.254731</td>\n      <td>0.098731</td>\n      <td>-0.041352</td>\n      <td>-0.235119</td>\n      <td>0.220208</td>\n      <td>-0.18826</td>\n      <td>-0.94197</td>\n      <td>-0.562268</td>\n      <td>0.558953</td>\n      <td>0.058157</td>\n      <td>0.409054</td>\n      <td>0.670708</td>\n      <td>-0.009517</td>\n      <td>0.443748</td>\n      <td>0.677378</td>\n      <td>0.061120</td>\n      <td>0.538535</td>\n      <td>0.841422</td>\n      <td>-0.882961</td>\n      <td>-0.357513</td>\n      <td>0.190543</td>\n      <td>0.642057</td>\n      <td>0.837369</td>\n      <td>0.620169</td>\n      <td>-0.414149</td>\n      <td>-0.229461</td>\n      <td>-0.499373</td>\n      <td>-0.320762</td>\n      <td>-0.154216</td>\n      <td>-0.147911</td>\n      <td>-0.188211</td>\n      <td>-0.290496</td>\n      <td>-0.391155</td>\n      <td>-0.323289</td>\n      <td>-0.313549</td>\n      <td>1.418634</td>\n      <td>-0.141192</td>\n      <td>-0.081388</td>\n      <td>-0.214699</td>\n      <td>-0.241654</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>-0.949794</td>\n      <td>2.394159</td>\n      <td>0.033539</td>\n      <td>3.310833</td>\n      <td>1.986516</td>\n      <td>-5.723174</td>\n      <td>1.913906</td>\n      <td>3.789460</td>\n      <td>-1.625948</td>\n      <td>-0.507198</td>\n      <td>2.993006</td>\n      <td>6.126325</td>\n      <td>1.278870</td>\n      <td>-3.418134</td>\n      <td>0.556824</td>\n      <td>3.220304</td>\n      <td>-2.013937</td>\n      <td>3.848544</td>\n      <td>1.438846</td>\n      <td>-0.914814</td>\n      <td>-1.009198</td>\n      <td>1.642408</td>\n      <td>-3.110111</td>\n      <td>3.080442</td>\n      <td>1.862627</td>\n      <td>2.129172</td>\n      <td>-1.850668</td>\n      <td>1.173814</td>\n      <td>-0.381908</td>\n      <td>2.133727</td>\n      <td>-1.585165</td>\n      <td>0.725314</td>\n      <td>-4.943785</td>\n      <td>0.924910</td>\n      <td>-0.557188</td>\n      <td>0.781747</td>\n      <td>-6.047087</td>\n      <td>-0.984050</td>\n      <td>0.611377</td>\n      <td>-0.838628</td>\n      <td>-2.316990</td>\n      <td>-4.628384</td>\n      <td>1.059011</td>\n      <td>1.744222</td>\n      <td>-3.782774</td>\n      <td>2.087450</td>\n      <td>0.691992</td>\n      <td>1.934122</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 218 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true,"_uuid":"65ff0d0d7c69e4bf64f8288a48b8d8c0ad56a697"},"cell_type":"code","source":"\"AdoptionSpeed\" in X_train_all.columns, \"AdoptionSpeed\" in X_test_all.columns","execution_count":82,"outputs":[{"output_type":"execute_result","execution_count":82,"data":{"text/plain":"(False, False)"},"metadata":{}}]},{"metadata":{"trusted":true,"_uuid":"8c26f564679be986e701c8db293068ab85e8b654"},"cell_type":"code","source":"X_train_all.columns.tolist() == X_test_all.columns.tolist()","execution_count":83,"outputs":[{"output_type":"execute_result","execution_count":83,"data":{"text/plain":"True"},"metadata":{}}]},{"metadata":{"_uuid":"eec84836e1cbfe38066808c7a132aff19e6306ad"},"cell_type":"markdown","source":"## Category Embedding"},{"metadata":{"trusted":true,"_uuid":"5bced7bce730a041d4b9feb6b550235ade506d42"},"cell_type":"code","source":"class CategoryDataset(data.Dataset):\n    def __init__(self, category):\n        self.category = category\n        \n    def __len__(self):\n        return len(self.category)\n    \n    def __getitem__(self, idx):\n        category = self.category[idx, :]\n        return [category]","execution_count":84,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"76de7b14d557c7fece51f94d3444f3370ab027ec"},"cell_type":"code","source":"c_train = torch.tensor(X_train_cat.values, dtype=torch.long).to(\"cuda:0\")\nc_test = torch.tensor(X_test_cat.values, dtype=torch.long).to(\"cuda:0\")\ntrain_dataset = CategoryDataset(c_train)\ntest_dataset = CategoryDataset(c_test)\ntrain_loader = data.DataLoader(train_dataset, batch_size=128, shuffle=False)\ntest_loader = data.DataLoader(test_dataset, batch_size=128, shuffle=False)\n\nX_train_cat_ = np.zeros((len(train_pet_ids), 20))\nX_test_cat_ = np.zeros((len(test_pet_ids), 20))\nbin_path = trainer.path\nfor path in bin_path.iterdir():\n    model = NeuralNet(**trainer.kwargs)\n    model.to(\"cuda:0\")\n    model.load_state_dict(torch.load(path))\n    model.eval()\n    temp = np.zeros((len(train_pet_ids), 20))\n    for i, (c_batch, ) in tqdm(enumerate(train_loader)):\n        with torch.no_grad():\n            y_pred = [model.embeddings[i](c_batch[:, i]) for i in range(len(model.embeddings))]\n            y_pred = torch.cat(y_pred, 1).detach()\n            temp[i * 128:(i + 1) * 128, :] = y_pred.cpu().numpy()\n    X_train_cat_ += temp / trainer.n_splits\n    temp = np.zeros((len(test_pet_ids), 20))\n    for i, (c_batch, ) in tqdm(enumerate(test_loader)):\n        with torch.no_grad():\n            y_pred = [model.embeddings[i](c_batch[:, i]) for i in range(len(model.embeddings))]\n            y_pred = torch.cat(y_pred, 1).detach()\n            temp[i * 128:(i + 1) * 128, :] = y_pred.cpu().numpy()\n    X_test_cat_ += temp / trainer.n_splits","execution_count":85,"outputs":[{"output_type":"stream","text":"118it [00:00, 871.63it/s]\n31it [00:00, 854.96it/s]\n118it [00:00, 835.49it/s]\n31it [00:00, 819.00it/s]\n118it [00:00, 815.97it/s]\n31it [00:00, 808.65it/s]\n118it [00:00, 874.71it/s]\n31it [00:00, 877.46it/s]\n118it [00:00, 842.80it/s]\n31it [00:00, 874.19it/s]\n118it [00:00, 869.48it/s]\n31it [00:00, 843.80it/s]\n118it [00:00, 853.64it/s]\n31it [00:00, 874.10it/s]\n118it [00:00, 867.95it/s]\n31it [00:00, 856.09it/s]\n118it [00:00, 857.88it/s]\n31it [00:00, 857.92it/s]\n118it [00:00, 851.11it/s]\n31it [00:00, 827.27it/s]\n","name":"stderr"}]},{"metadata":{"trusted":true,"_uuid":"317123c7f3d065a9b88bd159456e845d5bc75d28"},"cell_type":"code","source":"X_train_cat_.shape, X_test_cat_.shape","execution_count":86,"outputs":[{"output_type":"execute_result","execution_count":86,"data":{"text/plain":"((14993, 20), (3948, 20))"},"metadata":{}}]},{"metadata":{"trusted":true,"_uuid":"3d09ea0c48c79c8b8076041b789054c6c1c9cf93"},"cell_type":"code","source":"train_emb = pd.DataFrame(data=X_train_cat_, columns=[\n    f\"emb{i}\" for i in range(X_train_cat_.shape[1])\n])\ntest_emb = pd.DataFrame(data=X_test_cat_, columns=[\n    f\"emb{i}\" for i in range(X_test_cat_.shape[1])\n])","execution_count":87,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3e22008286acb662454c4b48e9d754e5005b4f55"},"cell_type":"code","source":"test_emb.index = X_test_all.index\n\nX_train_all = pd.concat([X_train_all, train_emb], axis=1)\nX_test_all = pd.concat([X_test_all, test_emb], axis=1)\n\nprint(X_train_all.shape, X_test_all.shape)\nX_train_all.head()","execution_count":88,"outputs":[{"output_type":"stream","text":"(14993, 238) (3948, 238)\n","name":"stdout"},{"output_type":"execute_result","execution_count":88,"data":{"text/plain":"        Age       Fee  VideoAmt  PhotoAmt  magnitude_sum  magnitude_mean  \\\n0 -0.421104  0.960767 -0.162959 -0.816674       0.175573       -0.089689   \n1 -0.530710 -0.279390 -0.162959 -0.532377      -0.648924       -0.163610   \n2 -0.530710 -0.279390 -0.162959  0.889111       0.835170        0.438317   \n3 -0.366301  1.580845 -0.162959  1.173408      -0.538991        2.275777   \n4 -0.530710 -0.279390 -0.162959 -0.248079       0.890136        0.871281   \n\n   magnitude_var  score_sum  score_mean  score_var  document_magnitude  \\\n0       0.720044   0.392032    0.057521   0.376737            0.161785   \n1      -0.031676  -1.250631   -1.939791   0.140569           -0.676014   \n2       1.133721   0.106352   -0.305627   2.070637            0.802455   \n3      -1.214452  -0.250749    2.236407  -1.056562           -0.577449   \n4       0.136541   1.606175    1.086440  -0.358914            0.802455   \n\n   document_score  annot_score_SUM  annot_score_MEAN  annot_score_VAR  \\\n0        0.099729        -0.798692          0.532229        -0.618650   \n1       -1.701005        -0.522569          0.253078        -0.552837   \n2       -0.260418         0.905726          0.201793        -0.041704   \n3        2.260610         1.095797         -0.060583        -0.496847   \n4        1.180169        -0.255537          0.094133         5.585148   \n\n   color_score_SUM  color_score_MEAN  color_score_VAR  pixel_frac_SUM  \\\n0        -0.842711         -0.520689        -0.063222       -0.779326   \n1        -0.489244          0.448827        -0.037801       -0.532728   \n2         1.062379          0.597325        -0.036040        1.031460   \n3         1.063514         -0.077532         0.120986        1.168248   \n4        -0.307276         -0.237184        -0.013624       -0.529883   \n\n   pixel_frac_MEAN  pixel_frac_VAR  crop_conf_SUM  crop_conf_MEAN  \\\n0         0.057136       -0.163850      -0.817486        0.138982   \n1        -0.071330       -0.139008      -0.533878        0.138982   \n2         0.404513        0.123483       0.884162        0.138982   \n3         0.164305        0.199442       1.167770        0.138982   \n4        -1.088897       -0.153880      -0.250270        0.138982   \n\n   crop_conf_VAR  crop_importance_SUM  crop_importance_MEAN  \\\n0      -0.137805            -0.817133              0.139028   \n1      -0.137805            -0.533092              0.139028   \n2      -0.137805             0.887115              0.139028   \n3      -0.137805             1.171157              0.139028   \n4      -0.137805            -0.254731              0.098731   \n\n   crop_importance_VAR  specified_SUM  specified_MEAN  specified_VAR  \\\n0            -0.042402      -0.813932        0.220208       -0.18826   \n1            -0.042402      -0.524526        0.220208       -0.18826   \n2            -0.042402       0.922507        0.220208       -0.18826   \n3            -0.042402       1.211914        0.220208       -0.18826   \n4            -0.041352      -0.235119        0.220208       -0.18826   \n\n   main_breed_Type  second_breed_Type  len_description  len_meta_desc  \\\n0          1.05936          -0.562268         0.482345      -0.970235   \n1          1.05936          -0.562268        -0.544292      -0.327012   \n2         -0.94197          -0.562268         0.566042       1.064897   \n3         -0.94197          -0.562268        -0.348319       1.092567   \n4         -0.94197          -0.562268         0.558953       0.058157   \n\n   len_entity  num_description_words  num_desc_words  num_entity_words  \\\n0    0.500955               0.519078       -1.027484          0.443748   \n1   -0.978440              -0.506754       -0.314407         -1.243792   \n2    0.609698               0.519078        1.102149          0.590031   \n3   -0.072772              -0.430047        1.150112         -0.169305   \n4    0.409054               0.670708       -0.009517          0.443748   \n\n   uniq_description_words  uniq_desc_words  uniq_entity_words  \\\n0                0.539772        -0.266118           0.453230   \n1               -0.542146         0.253030          -1.234661   \n2                0.593479         0.510427           0.617952   \n3               -0.356466         0.253030          -0.105635   \n4                0.677378         0.061120           0.538535   \n\n   num_description_stopwords  num_desc_stopwords  num_entity_stopwords  \\\n0                   0.669926           -0.021144             -0.357513   \n1                  -0.155182            0.482987             -0.357513   \n2                   0.568819           -0.882961             -0.357513   \n3                  -0.461536           -0.882961             -0.357513   \n4                   0.841422           -0.882961             -0.357513   \n\n   num_description_punctuation  state_gdp  state_population  state_area  \\\n0                     0.083495   0.642057          0.837369    0.620169   \n1                    -1.032706  -0.122787         -1.155849   -1.532409   \n2                     0.190543   0.642057          0.837369    0.620169   \n3                    -0.036174  -0.122787         -1.155849   -1.532409   \n4                     0.190543   0.642057          0.837369    0.620169   \n\n   state_gdp_per_person  fee_per_gdp_per_person  num_name_words  contains_amp  \\\n0             -0.414149                0.866557       -0.499373     -0.320762   \n1              1.527495               -0.229461        0.967877     -0.320762   \n2             -0.414149               -0.229461       -0.499373     -0.320762   \n3              1.527495                0.514889       -0.499373     -0.320762   \n4             -0.414149               -0.229461       -0.499373     -0.320762   \n\n   contains_comma  start_with_number  contains_paren  contains_number  \\\n0       -0.154216          -0.147911       -0.188211        -0.290496   \n1       -0.154216          -0.147911       -0.188211        -0.290496   \n2       -0.154216          -0.147911       -0.188211        -0.290496   \n3       -0.154216          -0.147911       -0.188211        -0.290496   \n4       -0.154216          -0.147911       -0.188211        -0.290496   \n\n   name_length  num_unlike_letters  rate_unlike_letters  Tfidf_Description_0  \\\n0    -0.391155           -0.323289            -0.313549             0.044744   \n1     0.289119           -0.323289            -0.313549            -0.701180   \n2    -0.391155           -0.323289            -0.313549             0.308158   \n3    -0.663264           -0.323289            -0.313549            -0.431990   \n4    -0.391155           -0.323289            -0.313549             1.418634   \n\n   Tfidf_Description_1  Tfidf_Description_2  Tfidf_Description_3  \\\n0            -0.233591            -0.294805            -0.151926   \n1            -0.112283            -0.185616            -0.087399   \n2            -0.293496             0.889665            -0.106772   \n3             0.094940             0.036552             0.174450   \n4            -0.141192            -0.081388            -0.214699   \n\n   Tfidf_Description_4    ...         img4      img5      img6      img7  \\\n0            -0.270423    ...     0.168729 -3.337685  1.064453  2.504577   \n1            -0.108876    ...     1.116230 -4.560302  1.727993  2.821769   \n2             0.448940    ...     3.100527 -6.055088  1.791643  2.673058   \n3             0.179728    ...     1.745109 -6.635424  1.869569  4.532476   \n4            -0.241654    ...     1.986516 -5.723174  1.913906  3.789460   \n\n       img8      img9     img10     img11     img12     img13     img14  \\\n0 -0.776440 -0.834316  2.067906  3.124545  1.462572 -1.885166  0.110586   \n1 -1.340741 -0.531848  3.389417  4.487653  1.354946 -2.532177 -0.045172   \n2 -2.455977 -0.350956  3.939216  6.515712  1.124512 -3.453139  0.706491   \n3 -2.524938 -0.405398  2.687588  6.945358  1.404643 -3.726660  0.714303   \n4 -1.625948 -0.507198  2.993006  6.126325  1.278870 -3.418134  0.556824   \n\n      img15     img16     img17     img18     img19     img20     img21  \\\n0  2.151125 -1.176674  2.415041  0.703949 -1.588303 -0.543489  0.818192   \n1  2.472195 -1.435838  2.977570  1.420283 -1.214347 -1.046712  0.765651   \n2  3.740337 -1.754591  3.044297  1.617188 -1.144515 -1.906649  1.023324   \n3  3.766063 -2.171436  5.997324 -0.004172 -1.723910 -1.578517  2.265283   \n4  3.220304 -2.013937  3.848544  1.438846 -0.914814 -1.009198  1.642408   \n\n      img22     img23     img24     img25     img26     img27     img28  \\\n0 -1.419860  1.635671  1.230090  1.056767 -0.403665  1.106224  0.096388   \n1 -1.661028  2.115986  1.341369  1.500666 -1.049592  1.269030 -0.071501   \n2 -3.877063  3.639141  1.870255  2.687016 -1.305590  0.844590 -0.206637   \n3 -3.442194  3.262680  3.076942  2.515201 -1.821304  1.635721  0.145540   \n4 -3.110111  3.080442  1.862627  2.129172 -1.850668  1.173814 -0.381908   \n\n      img29     img30     img31     img32     img33     img34     img35  \\\n0  1.556007 -0.848707  0.224280 -3.398524  0.857789 -0.167985 -0.397752   \n1  1.327432 -0.891723  1.284225 -4.005236  1.059146 -0.553956  0.564387   \n2  1.519087 -2.179879  0.798290 -4.847266  0.724858 -0.536026  1.163803   \n3  3.523111 -1.485916  0.318308 -4.195776  1.051438  0.223658  1.014659   \n4  2.133727 -1.585165  0.725314 -4.943785  0.924910 -0.557188  0.781747   \n\n      img36     img37     img38     img39     img40     img41     img42  \\\n0 -3.545173 -0.916391  0.599372 -0.187137 -1.365577 -2.507689  0.546872   \n1 -4.653399 -1.162407  1.164328 -0.568253 -1.356671 -3.293017  0.985037   \n2 -7.355669 -1.725377  1.048077  0.049122 -3.023522 -4.714112  1.180708   \n3 -8.322213 -1.678787  0.642676 -0.352061 -2.542596 -5.023290  2.166600   \n4 -6.047087 -0.984050  0.611377 -0.838628 -2.316990 -4.628384  1.059011   \n\n      img43     img44     img45     img46     img47      emb0      emb1  \\\n0  0.475532 -1.821823  0.759485 -0.163166  1.413023  0.069553 -0.844969   \n1  1.320855 -1.992518  1.044078  0.064549  1.250380  0.069553  0.591301   \n2  1.768260 -4.127668  3.099615  0.795191  1.659834  0.474235 -0.308725   \n3  0.604448 -5.354814  1.882512  0.037363  2.774812  0.474235 -0.308725   \n4  1.744222 -3.782774  2.087450  0.691992  1.934122  0.474235 -0.308725   \n\n       emb2      emb3      emb4      emb5      emb6      emb7      emb8  \\\n0  0.508286 -1.416741 -0.831533  0.827695  1.204345 -0.663034  0.670370   \n1 -0.392345  1.509525 -0.831533  0.827695  1.204345 -0.663034  0.670370   \n2  0.306153  1.154131 -0.831533  0.827695  1.204345 -0.663034  1.413041   \n3  0.306153  1.154131 -0.831533  0.827695  1.204345 -0.547322  0.670370   \n4  0.306153  1.154131 -0.831533  0.827695  1.204345 -0.663034  0.670370   \n\n       emb9     emb10     emb11     emb12     emb13     emb14     emb15  \\\n0  1.081997 -0.449266  0.195283 -1.474584 -0.755869  0.219763  1.209454   \n1  1.987546 -0.449266 -0.148951  1.518030 -0.268800 -0.043801 -0.200018   \n2  1.081997 -0.449266 -0.148951  1.518030 -1.894602 -0.526782  1.209454   \n3  1.987546 -0.449266 -0.148951 -1.474584 -1.894602 -0.526782  1.209454   \n4 -0.638341 -0.449266 -0.148951 -1.474584 -0.755869  0.219763  1.209454   \n\n      emb16     emb17     emb18     emb19  \n0 -0.240832 -0.318214 -0.766078  1.029494  \n1 -0.240832 -0.318214  2.669607  1.029494  \n2 -0.240832 -0.318214 -0.766078  1.029494  \n3 -0.240832 -0.318214  2.669607  1.029494  \n4 -0.240832 -0.318214 -0.766078  1.029494  \n\n[5 rows x 238 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Fee</th>\n      <th>VideoAmt</th>\n      <th>PhotoAmt</th>\n      <th>magnitude_sum</th>\n      <th>magnitude_mean</th>\n      <th>magnitude_var</th>\n      <th>score_sum</th>\n      <th>score_mean</th>\n      <th>score_var</th>\n      <th>document_magnitude</th>\n      <th>document_score</th>\n      <th>annot_score_SUM</th>\n      <th>annot_score_MEAN</th>\n      <th>annot_score_VAR</th>\n      <th>color_score_SUM</th>\n      <th>color_score_MEAN</th>\n      <th>color_score_VAR</th>\n      <th>pixel_frac_SUM</th>\n      <th>pixel_frac_MEAN</th>\n      <th>pixel_frac_VAR</th>\n      <th>crop_conf_SUM</th>\n      <th>crop_conf_MEAN</th>\n      <th>crop_conf_VAR</th>\n      <th>crop_importance_SUM</th>\n      <th>crop_importance_MEAN</th>\n      <th>crop_importance_VAR</th>\n      <th>specified_SUM</th>\n      <th>specified_MEAN</th>\n      <th>specified_VAR</th>\n      <th>main_breed_Type</th>\n      <th>second_breed_Type</th>\n      <th>len_description</th>\n      <th>len_meta_desc</th>\n      <th>len_entity</th>\n      <th>num_description_words</th>\n      <th>num_desc_words</th>\n      <th>num_entity_words</th>\n      <th>uniq_description_words</th>\n      <th>uniq_desc_words</th>\n      <th>uniq_entity_words</th>\n      <th>num_description_stopwords</th>\n      <th>num_desc_stopwords</th>\n      <th>num_entity_stopwords</th>\n      <th>num_description_punctuation</th>\n      <th>state_gdp</th>\n      <th>state_population</th>\n      <th>state_area</th>\n      <th>state_gdp_per_person</th>\n      <th>fee_per_gdp_per_person</th>\n      <th>num_name_words</th>\n      <th>contains_amp</th>\n      <th>contains_comma</th>\n      <th>start_with_number</th>\n      <th>contains_paren</th>\n      <th>contains_number</th>\n      <th>name_length</th>\n      <th>num_unlike_letters</th>\n      <th>rate_unlike_letters</th>\n      <th>Tfidf_Description_0</th>\n      <th>Tfidf_Description_1</th>\n      <th>Tfidf_Description_2</th>\n      <th>Tfidf_Description_3</th>\n      <th>Tfidf_Description_4</th>\n      <th>...</th>\n      <th>img4</th>\n      <th>img5</th>\n      <th>img6</th>\n      <th>img7</th>\n      <th>img8</th>\n      <th>img9</th>\n      <th>img10</th>\n      <th>img11</th>\n      <th>img12</th>\n      <th>img13</th>\n      <th>img14</th>\n      <th>img15</th>\n      <th>img16</th>\n      <th>img17</th>\n      <th>img18</th>\n      <th>img19</th>\n      <th>img20</th>\n      <th>img21</th>\n      <th>img22</th>\n      <th>img23</th>\n      <th>img24</th>\n      <th>img25</th>\n      <th>img26</th>\n      <th>img27</th>\n      <th>img28</th>\n      <th>img29</th>\n      <th>img30</th>\n      <th>img31</th>\n      <th>img32</th>\n      <th>img33</th>\n      <th>img34</th>\n      <th>img35</th>\n      <th>img36</th>\n      <th>img37</th>\n      <th>img38</th>\n      <th>img39</th>\n      <th>img40</th>\n      <th>img41</th>\n      <th>img42</th>\n      <th>img43</th>\n      <th>img44</th>\n      <th>img45</th>\n      <th>img46</th>\n      <th>img47</th>\n      <th>emb0</th>\n      <th>emb1</th>\n      <th>emb2</th>\n      <th>emb3</th>\n      <th>emb4</th>\n      <th>emb5</th>\n      <th>emb6</th>\n      <th>emb7</th>\n      <th>emb8</th>\n      <th>emb9</th>\n      <th>emb10</th>\n      <th>emb11</th>\n      <th>emb12</th>\n      <th>emb13</th>\n      <th>emb14</th>\n      <th>emb15</th>\n      <th>emb16</th>\n      <th>emb17</th>\n      <th>emb18</th>\n      <th>emb19</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.421104</td>\n      <td>0.960767</td>\n      <td>-0.162959</td>\n      <td>-0.816674</td>\n      <td>0.175573</td>\n      <td>-0.089689</td>\n      <td>0.720044</td>\n      <td>0.392032</td>\n      <td>0.057521</td>\n      <td>0.376737</td>\n      <td>0.161785</td>\n      <td>0.099729</td>\n      <td>-0.798692</td>\n      <td>0.532229</td>\n      <td>-0.618650</td>\n      <td>-0.842711</td>\n      <td>-0.520689</td>\n      <td>-0.063222</td>\n      <td>-0.779326</td>\n      <td>0.057136</td>\n      <td>-0.163850</td>\n      <td>-0.817486</td>\n      <td>0.138982</td>\n      <td>-0.137805</td>\n      <td>-0.817133</td>\n      <td>0.139028</td>\n      <td>-0.042402</td>\n      <td>-0.813932</td>\n      <td>0.220208</td>\n      <td>-0.18826</td>\n      <td>1.05936</td>\n      <td>-0.562268</td>\n      <td>0.482345</td>\n      <td>-0.970235</td>\n      <td>0.500955</td>\n      <td>0.519078</td>\n      <td>-1.027484</td>\n      <td>0.443748</td>\n      <td>0.539772</td>\n      <td>-0.266118</td>\n      <td>0.453230</td>\n      <td>0.669926</td>\n      <td>-0.021144</td>\n      <td>-0.357513</td>\n      <td>0.083495</td>\n      <td>0.642057</td>\n      <td>0.837369</td>\n      <td>0.620169</td>\n      <td>-0.414149</td>\n      <td>0.866557</td>\n      <td>-0.499373</td>\n      <td>-0.320762</td>\n      <td>-0.154216</td>\n      <td>-0.147911</td>\n      <td>-0.188211</td>\n      <td>-0.290496</td>\n      <td>-0.391155</td>\n      <td>-0.323289</td>\n      <td>-0.313549</td>\n      <td>0.044744</td>\n      <td>-0.233591</td>\n      <td>-0.294805</td>\n      <td>-0.151926</td>\n      <td>-0.270423</td>\n      <td>...</td>\n      <td>0.168729</td>\n      <td>-3.337685</td>\n      <td>1.064453</td>\n      <td>2.504577</td>\n      <td>-0.776440</td>\n      <td>-0.834316</td>\n      <td>2.067906</td>\n      <td>3.124545</td>\n      <td>1.462572</td>\n      <td>-1.885166</td>\n      <td>0.110586</td>\n      <td>2.151125</td>\n      <td>-1.176674</td>\n      <td>2.415041</td>\n      <td>0.703949</td>\n      <td>-1.588303</td>\n      <td>-0.543489</td>\n      <td>0.818192</td>\n      <td>-1.419860</td>\n      <td>1.635671</td>\n      <td>1.230090</td>\n      <td>1.056767</td>\n      <td>-0.403665</td>\n      <td>1.106224</td>\n      <td>0.096388</td>\n      <td>1.556007</td>\n      <td>-0.848707</td>\n      <td>0.224280</td>\n      <td>-3.398524</td>\n      <td>0.857789</td>\n      <td>-0.167985</td>\n      <td>-0.397752</td>\n      <td>-3.545173</td>\n      <td>-0.916391</td>\n      <td>0.599372</td>\n      <td>-0.187137</td>\n      <td>-1.365577</td>\n      <td>-2.507689</td>\n      <td>0.546872</td>\n      <td>0.475532</td>\n      <td>-1.821823</td>\n      <td>0.759485</td>\n      <td>-0.163166</td>\n      <td>1.413023</td>\n      <td>0.069553</td>\n      <td>-0.844969</td>\n      <td>0.508286</td>\n      <td>-1.416741</td>\n      <td>-0.831533</td>\n      <td>0.827695</td>\n      <td>1.204345</td>\n      <td>-0.663034</td>\n      <td>0.670370</td>\n      <td>1.081997</td>\n      <td>-0.449266</td>\n      <td>0.195283</td>\n      <td>-1.474584</td>\n      <td>-0.755869</td>\n      <td>0.219763</td>\n      <td>1.209454</td>\n      <td>-0.240832</td>\n      <td>-0.318214</td>\n      <td>-0.766078</td>\n      <td>1.029494</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.530710</td>\n      <td>-0.279390</td>\n      <td>-0.162959</td>\n      <td>-0.532377</td>\n      <td>-0.648924</td>\n      <td>-0.163610</td>\n      <td>-0.031676</td>\n      <td>-1.250631</td>\n      <td>-1.939791</td>\n      <td>0.140569</td>\n      <td>-0.676014</td>\n      <td>-1.701005</td>\n      <td>-0.522569</td>\n      <td>0.253078</td>\n      <td>-0.552837</td>\n      <td>-0.489244</td>\n      <td>0.448827</td>\n      <td>-0.037801</td>\n      <td>-0.532728</td>\n      <td>-0.071330</td>\n      <td>-0.139008</td>\n      <td>-0.533878</td>\n      <td>0.138982</td>\n      <td>-0.137805</td>\n      <td>-0.533092</td>\n      <td>0.139028</td>\n      <td>-0.042402</td>\n      <td>-0.524526</td>\n      <td>0.220208</td>\n      <td>-0.18826</td>\n      <td>1.05936</td>\n      <td>-0.562268</td>\n      <td>-0.544292</td>\n      <td>-0.327012</td>\n      <td>-0.978440</td>\n      <td>-0.506754</td>\n      <td>-0.314407</td>\n      <td>-1.243792</td>\n      <td>-0.542146</td>\n      <td>0.253030</td>\n      <td>-1.234661</td>\n      <td>-0.155182</td>\n      <td>0.482987</td>\n      <td>-0.357513</td>\n      <td>-1.032706</td>\n      <td>-0.122787</td>\n      <td>-1.155849</td>\n      <td>-1.532409</td>\n      <td>1.527495</td>\n      <td>-0.229461</td>\n      <td>0.967877</td>\n      <td>-0.320762</td>\n      <td>-0.154216</td>\n      <td>-0.147911</td>\n      <td>-0.188211</td>\n      <td>-0.290496</td>\n      <td>0.289119</td>\n      <td>-0.323289</td>\n      <td>-0.313549</td>\n      <td>-0.701180</td>\n      <td>-0.112283</td>\n      <td>-0.185616</td>\n      <td>-0.087399</td>\n      <td>-0.108876</td>\n      <td>...</td>\n      <td>1.116230</td>\n      <td>-4.560302</td>\n      <td>1.727993</td>\n      <td>2.821769</td>\n      <td>-1.340741</td>\n      <td>-0.531848</td>\n      <td>3.389417</td>\n      <td>4.487653</td>\n      <td>1.354946</td>\n      <td>-2.532177</td>\n      <td>-0.045172</td>\n      <td>2.472195</td>\n      <td>-1.435838</td>\n      <td>2.977570</td>\n      <td>1.420283</td>\n      <td>-1.214347</td>\n      <td>-1.046712</td>\n      <td>0.765651</td>\n      <td>-1.661028</td>\n      <td>2.115986</td>\n      <td>1.341369</td>\n      <td>1.500666</td>\n      <td>-1.049592</td>\n      <td>1.269030</td>\n      <td>-0.071501</td>\n      <td>1.327432</td>\n      <td>-0.891723</td>\n      <td>1.284225</td>\n      <td>-4.005236</td>\n      <td>1.059146</td>\n      <td>-0.553956</td>\n      <td>0.564387</td>\n      <td>-4.653399</td>\n      <td>-1.162407</td>\n      <td>1.164328</td>\n      <td>-0.568253</td>\n      <td>-1.356671</td>\n      <td>-3.293017</td>\n      <td>0.985037</td>\n      <td>1.320855</td>\n      <td>-1.992518</td>\n      <td>1.044078</td>\n      <td>0.064549</td>\n      <td>1.250380</td>\n      <td>0.069553</td>\n      <td>0.591301</td>\n      <td>-0.392345</td>\n      <td>1.509525</td>\n      <td>-0.831533</td>\n      <td>0.827695</td>\n      <td>1.204345</td>\n      <td>-0.663034</td>\n      <td>0.670370</td>\n      <td>1.987546</td>\n      <td>-0.449266</td>\n      <td>-0.148951</td>\n      <td>1.518030</td>\n      <td>-0.268800</td>\n      <td>-0.043801</td>\n      <td>-0.200018</td>\n      <td>-0.240832</td>\n      <td>-0.318214</td>\n      <td>2.669607</td>\n      <td>1.029494</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.530710</td>\n      <td>-0.279390</td>\n      <td>-0.162959</td>\n      <td>0.889111</td>\n      <td>0.835170</td>\n      <td>0.438317</td>\n      <td>1.133721</td>\n      <td>0.106352</td>\n      <td>-0.305627</td>\n      <td>2.070637</td>\n      <td>0.802455</td>\n      <td>-0.260418</td>\n      <td>0.905726</td>\n      <td>0.201793</td>\n      <td>-0.041704</td>\n      <td>1.062379</td>\n      <td>0.597325</td>\n      <td>-0.036040</td>\n      <td>1.031460</td>\n      <td>0.404513</td>\n      <td>0.123483</td>\n      <td>0.884162</td>\n      <td>0.138982</td>\n      <td>-0.137805</td>\n      <td>0.887115</td>\n      <td>0.139028</td>\n      <td>-0.042402</td>\n      <td>0.922507</td>\n      <td>0.220208</td>\n      <td>-0.18826</td>\n      <td>-0.94197</td>\n      <td>-0.562268</td>\n      <td>0.566042</td>\n      <td>1.064897</td>\n      <td>0.609698</td>\n      <td>0.519078</td>\n      <td>1.102149</td>\n      <td>0.590031</td>\n      <td>0.593479</td>\n      <td>0.510427</td>\n      <td>0.617952</td>\n      <td>0.568819</td>\n      <td>-0.882961</td>\n      <td>-0.357513</td>\n      <td>0.190543</td>\n      <td>0.642057</td>\n      <td>0.837369</td>\n      <td>0.620169</td>\n      <td>-0.414149</td>\n      <td>-0.229461</td>\n      <td>-0.499373</td>\n      <td>-0.320762</td>\n      <td>-0.154216</td>\n      <td>-0.147911</td>\n      <td>-0.188211</td>\n      <td>-0.290496</td>\n      <td>-0.391155</td>\n      <td>-0.323289</td>\n      <td>-0.313549</td>\n      <td>0.308158</td>\n      <td>-0.293496</td>\n      <td>0.889665</td>\n      <td>-0.106772</td>\n      <td>0.448940</td>\n      <td>...</td>\n      <td>3.100527</td>\n      <td>-6.055088</td>\n      <td>1.791643</td>\n      <td>2.673058</td>\n      <td>-2.455977</td>\n      <td>-0.350956</td>\n      <td>3.939216</td>\n      <td>6.515712</td>\n      <td>1.124512</td>\n      <td>-3.453139</td>\n      <td>0.706491</td>\n      <td>3.740337</td>\n      <td>-1.754591</td>\n      <td>3.044297</td>\n      <td>1.617188</td>\n      <td>-1.144515</td>\n      <td>-1.906649</td>\n      <td>1.023324</td>\n      <td>-3.877063</td>\n      <td>3.639141</td>\n      <td>1.870255</td>\n      <td>2.687016</td>\n      <td>-1.305590</td>\n      <td>0.844590</td>\n      <td>-0.206637</td>\n      <td>1.519087</td>\n      <td>-2.179879</td>\n      <td>0.798290</td>\n      <td>-4.847266</td>\n      <td>0.724858</td>\n      <td>-0.536026</td>\n      <td>1.163803</td>\n      <td>-7.355669</td>\n      <td>-1.725377</td>\n      <td>1.048077</td>\n      <td>0.049122</td>\n      <td>-3.023522</td>\n      <td>-4.714112</td>\n      <td>1.180708</td>\n      <td>1.768260</td>\n      <td>-4.127668</td>\n      <td>3.099615</td>\n      <td>0.795191</td>\n      <td>1.659834</td>\n      <td>0.474235</td>\n      <td>-0.308725</td>\n      <td>0.306153</td>\n      <td>1.154131</td>\n      <td>-0.831533</td>\n      <td>0.827695</td>\n      <td>1.204345</td>\n      <td>-0.663034</td>\n      <td>1.413041</td>\n      <td>1.081997</td>\n      <td>-0.449266</td>\n      <td>-0.148951</td>\n      <td>1.518030</td>\n      <td>-1.894602</td>\n      <td>-0.526782</td>\n      <td>1.209454</td>\n      <td>-0.240832</td>\n      <td>-0.318214</td>\n      <td>-0.766078</td>\n      <td>1.029494</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.366301</td>\n      <td>1.580845</td>\n      <td>-0.162959</td>\n      <td>1.173408</td>\n      <td>-0.538991</td>\n      <td>2.275777</td>\n      <td>-1.214452</td>\n      <td>-0.250749</td>\n      <td>2.236407</td>\n      <td>-1.056562</td>\n      <td>-0.577449</td>\n      <td>2.260610</td>\n      <td>1.095797</td>\n      <td>-0.060583</td>\n      <td>-0.496847</td>\n      <td>1.063514</td>\n      <td>-0.077532</td>\n      <td>0.120986</td>\n      <td>1.168248</td>\n      <td>0.164305</td>\n      <td>0.199442</td>\n      <td>1.167770</td>\n      <td>0.138982</td>\n      <td>-0.137805</td>\n      <td>1.171157</td>\n      <td>0.139028</td>\n      <td>-0.042402</td>\n      <td>1.211914</td>\n      <td>0.220208</td>\n      <td>-0.18826</td>\n      <td>-0.94197</td>\n      <td>-0.562268</td>\n      <td>-0.348319</td>\n      <td>1.092567</td>\n      <td>-0.072772</td>\n      <td>-0.430047</td>\n      <td>1.150112</td>\n      <td>-0.169305</td>\n      <td>-0.356466</td>\n      <td>0.253030</td>\n      <td>-0.105635</td>\n      <td>-0.461536</td>\n      <td>-0.882961</td>\n      <td>-0.357513</td>\n      <td>-0.036174</td>\n      <td>-0.122787</td>\n      <td>-1.155849</td>\n      <td>-1.532409</td>\n      <td>1.527495</td>\n      <td>0.514889</td>\n      <td>-0.499373</td>\n      <td>-0.320762</td>\n      <td>-0.154216</td>\n      <td>-0.147911</td>\n      <td>-0.188211</td>\n      <td>-0.290496</td>\n      <td>-0.663264</td>\n      <td>-0.323289</td>\n      <td>-0.313549</td>\n      <td>-0.431990</td>\n      <td>0.094940</td>\n      <td>0.036552</td>\n      <td>0.174450</td>\n      <td>0.179728</td>\n      <td>...</td>\n      <td>1.745109</td>\n      <td>-6.635424</td>\n      <td>1.869569</td>\n      <td>4.532476</td>\n      <td>-2.524938</td>\n      <td>-0.405398</td>\n      <td>2.687588</td>\n      <td>6.945358</td>\n      <td>1.404643</td>\n      <td>-3.726660</td>\n      <td>0.714303</td>\n      <td>3.766063</td>\n      <td>-2.171436</td>\n      <td>5.997324</td>\n      <td>-0.004172</td>\n      <td>-1.723910</td>\n      <td>-1.578517</td>\n      <td>2.265283</td>\n      <td>-3.442194</td>\n      <td>3.262680</td>\n      <td>3.076942</td>\n      <td>2.515201</td>\n      <td>-1.821304</td>\n      <td>1.635721</td>\n      <td>0.145540</td>\n      <td>3.523111</td>\n      <td>-1.485916</td>\n      <td>0.318308</td>\n      <td>-4.195776</td>\n      <td>1.051438</td>\n      <td>0.223658</td>\n      <td>1.014659</td>\n      <td>-8.322213</td>\n      <td>-1.678787</td>\n      <td>0.642676</td>\n      <td>-0.352061</td>\n      <td>-2.542596</td>\n      <td>-5.023290</td>\n      <td>2.166600</td>\n      <td>0.604448</td>\n      <td>-5.354814</td>\n      <td>1.882512</td>\n      <td>0.037363</td>\n      <td>2.774812</td>\n      <td>0.474235</td>\n      <td>-0.308725</td>\n      <td>0.306153</td>\n      <td>1.154131</td>\n      <td>-0.831533</td>\n      <td>0.827695</td>\n      <td>1.204345</td>\n      <td>-0.547322</td>\n      <td>0.670370</td>\n      <td>1.987546</td>\n      <td>-0.449266</td>\n      <td>-0.148951</td>\n      <td>-1.474584</td>\n      <td>-1.894602</td>\n      <td>-0.526782</td>\n      <td>1.209454</td>\n      <td>-0.240832</td>\n      <td>-0.318214</td>\n      <td>2.669607</td>\n      <td>1.029494</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.530710</td>\n      <td>-0.279390</td>\n      <td>-0.162959</td>\n      <td>-0.248079</td>\n      <td>0.890136</td>\n      <td>0.871281</td>\n      <td>0.136541</td>\n      <td>1.606175</td>\n      <td>1.086440</td>\n      <td>-0.358914</td>\n      <td>0.802455</td>\n      <td>1.180169</td>\n      <td>-0.255537</td>\n      <td>0.094133</td>\n      <td>5.585148</td>\n      <td>-0.307276</td>\n      <td>-0.237184</td>\n      <td>-0.013624</td>\n      <td>-0.529883</td>\n      <td>-1.088897</td>\n      <td>-0.153880</td>\n      <td>-0.250270</td>\n      <td>0.138982</td>\n      <td>-0.137805</td>\n      <td>-0.254731</td>\n      <td>0.098731</td>\n      <td>-0.041352</td>\n      <td>-0.235119</td>\n      <td>0.220208</td>\n      <td>-0.18826</td>\n      <td>-0.94197</td>\n      <td>-0.562268</td>\n      <td>0.558953</td>\n      <td>0.058157</td>\n      <td>0.409054</td>\n      <td>0.670708</td>\n      <td>-0.009517</td>\n      <td>0.443748</td>\n      <td>0.677378</td>\n      <td>0.061120</td>\n      <td>0.538535</td>\n      <td>0.841422</td>\n      <td>-0.882961</td>\n      <td>-0.357513</td>\n      <td>0.190543</td>\n      <td>0.642057</td>\n      <td>0.837369</td>\n      <td>0.620169</td>\n      <td>-0.414149</td>\n      <td>-0.229461</td>\n      <td>-0.499373</td>\n      <td>-0.320762</td>\n      <td>-0.154216</td>\n      <td>-0.147911</td>\n      <td>-0.188211</td>\n      <td>-0.290496</td>\n      <td>-0.391155</td>\n      <td>-0.323289</td>\n      <td>-0.313549</td>\n      <td>1.418634</td>\n      <td>-0.141192</td>\n      <td>-0.081388</td>\n      <td>-0.214699</td>\n      <td>-0.241654</td>\n      <td>...</td>\n      <td>1.986516</td>\n      <td>-5.723174</td>\n      <td>1.913906</td>\n      <td>3.789460</td>\n      <td>-1.625948</td>\n      <td>-0.507198</td>\n      <td>2.993006</td>\n      <td>6.126325</td>\n      <td>1.278870</td>\n      <td>-3.418134</td>\n      <td>0.556824</td>\n      <td>3.220304</td>\n      <td>-2.013937</td>\n      <td>3.848544</td>\n      <td>1.438846</td>\n      <td>-0.914814</td>\n      <td>-1.009198</td>\n      <td>1.642408</td>\n      <td>-3.110111</td>\n      <td>3.080442</td>\n      <td>1.862627</td>\n      <td>2.129172</td>\n      <td>-1.850668</td>\n      <td>1.173814</td>\n      <td>-0.381908</td>\n      <td>2.133727</td>\n      <td>-1.585165</td>\n      <td>0.725314</td>\n      <td>-4.943785</td>\n      <td>0.924910</td>\n      <td>-0.557188</td>\n      <td>0.781747</td>\n      <td>-6.047087</td>\n      <td>-0.984050</td>\n      <td>0.611377</td>\n      <td>-0.838628</td>\n      <td>-2.316990</td>\n      <td>-4.628384</td>\n      <td>1.059011</td>\n      <td>1.744222</td>\n      <td>-3.782774</td>\n      <td>2.087450</td>\n      <td>0.691992</td>\n      <td>1.934122</td>\n      <td>0.474235</td>\n      <td>-0.308725</td>\n      <td>0.306153</td>\n      <td>1.154131</td>\n      <td>-0.831533</td>\n      <td>0.827695</td>\n      <td>1.204345</td>\n      <td>-0.663034</td>\n      <td>0.670370</td>\n      <td>-0.638341</td>\n      <td>-0.449266</td>\n      <td>-0.148951</td>\n      <td>-1.474584</td>\n      <td>-0.755869</td>\n      <td>0.219763</td>\n      <td>1.209454</td>\n      <td>-0.240832</td>\n      <td>-0.318214</td>\n      <td>-0.766078</td>\n      <td>1.029494</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 238 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Entity and Desc"},{"metadata":{"trusted":true},"cell_type":"code","source":"class WordVecDataset(data.Dataset):\n    def __init__(self, wv):\n        self.wv = wv\n        \n    def __len__(self):\n        return len(self.wv)\n    \n    def __getitem__(self, idx):\n        wv = self.wv[idx, :]\n        return [wv]","execution_count":89,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"e_train = torch.tensor(train_entity, dtype=torch.float32).to(\"cuda:0\")\ne_test = torch.tensor(test_entity, dtype=torch.float32).to(\"cuda:0\")\ntrain_dataset = WordVecDataset(e_train)\ntest_dataset = WordVecDataset(e_test)\ntrain_loader = data.DataLoader(train_dataset, batch_size=128, shuffle=False)\ntest_loader = data.DataLoader(test_dataset, batch_size=128, shuffle=False)\n\nX_train_ent = np.zeros((len(train_pet_ids), 10))\nX_test_ent = np.zeros((len(test_pet_ids), 10))\nbin_path = trainer.path\nfor path in bin_path.iterdir():\n    model = NeuralNet(**trainer.kwargs)\n    model.to(\"cuda:0\")\n    model.load_state_dict(torch.load(path))\n    model.eval()\n    temp = np.zeros((len(train_pet_ids), 10))\n    for i, (e_batch, ) in tqdm(enumerate(train_loader), ascii=True):\n        with torch.no_grad():\n            y_pred = model.ent_lin(e_batch).detach()\n            temp[i * 128:(i + 1) * 128, :] = y_pred.cpu().numpy()\n    X_train_ent += temp / trainer.n_splits\n    temp = np.zeros((len(test_pet_ids), 10))\n    for i, (e_batch, ) in tqdm(enumerate(test_loader), ascii=True):\n        with torch.no_grad():\n            y_pred = model.ent_lin(e_batch).detach()\n            temp[i * 128:(i + 1) * 128, :] = y_pred.cpu().numpy()\n    X_test_ent += temp / trainer.n_splits","execution_count":90,"outputs":[{"output_type":"stream","text":"118it [00:00, 1370.49it/s]\n31it [00:00, 1321.16it/s]\n118it [00:00, 1411.51it/s]\n31it [00:00, 1348.08it/s]\n118it [00:00, 1405.59it/s]\n31it [00:00, 1309.15it/s]\n118it [00:00, 1360.56it/s]\n31it [00:00, 1386.83it/s]\n118it [00:00, 1419.03it/s]\n31it [00:00, 1356.08it/s]\n118it [00:00, 1364.54it/s]\n31it [00:00, 1336.81it/s]\n118it [00:00, 1424.81it/s]\n31it [00:00, 1392.90it/s]\n118it [00:00, 1390.79it/s]\n31it [00:00, 1311.54it/s]\n118it [00:00, 1419.94it/s]\n31it [00:00, 1371.54it/s]\n118it [00:00, 1439.63it/s]\n31it [00:00, 1401.46it/s]\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_ent.shape, X_test_ent.shape","execution_count":91,"outputs":[{"output_type":"execute_result","execution_count":91,"data":{"text/plain":"((14993, 10), (3948, 10))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ent = pd.DataFrame(data=X_train_ent, columns=[\n    f\"ent{i}\" for i in range(X_train_ent.shape[1])\n])\ntest_ent = pd.DataFrame(data=X_test_ent, columns=[\n    f\"ent{i}\" for i in range(X_test_ent.shape[1])\n])\ntest_ent.index = X_test_all.index\n\nX_train_all = pd.concat([X_train_all, train_ent], axis=1)\nX_test_all = pd.concat([X_test_all, test_ent], axis=1)\n\nprint(X_train_all.shape, X_test_all.shape)\nX_train_all.head()","execution_count":92,"outputs":[{"output_type":"stream","text":"(14993, 248) (3948, 248)\n","name":"stdout"},{"output_type":"execute_result","execution_count":92,"data":{"text/plain":"        Age       Fee  VideoAmt  PhotoAmt  magnitude_sum  magnitude_mean  \\\n0 -0.421104  0.960767 -0.162959 -0.816674       0.175573       -0.089689   \n1 -0.530710 -0.279390 -0.162959 -0.532377      -0.648924       -0.163610   \n2 -0.530710 -0.279390 -0.162959  0.889111       0.835170        0.438317   \n3 -0.366301  1.580845 -0.162959  1.173408      -0.538991        2.275777   \n4 -0.530710 -0.279390 -0.162959 -0.248079       0.890136        0.871281   \n\n   magnitude_var  score_sum  score_mean  score_var  document_magnitude  \\\n0       0.720044   0.392032    0.057521   0.376737            0.161785   \n1      -0.031676  -1.250631   -1.939791   0.140569           -0.676014   \n2       1.133721   0.106352   -0.305627   2.070637            0.802455   \n3      -1.214452  -0.250749    2.236407  -1.056562           -0.577449   \n4       0.136541   1.606175    1.086440  -0.358914            0.802455   \n\n   document_score  annot_score_SUM  annot_score_MEAN  annot_score_VAR  \\\n0        0.099729        -0.798692          0.532229        -0.618650   \n1       -1.701005        -0.522569          0.253078        -0.552837   \n2       -0.260418         0.905726          0.201793        -0.041704   \n3        2.260610         1.095797         -0.060583        -0.496847   \n4        1.180169        -0.255537          0.094133         5.585148   \n\n   color_score_SUM  color_score_MEAN  color_score_VAR  pixel_frac_SUM  \\\n0        -0.842711         -0.520689        -0.063222       -0.779326   \n1        -0.489244          0.448827        -0.037801       -0.532728   \n2         1.062379          0.597325        -0.036040        1.031460   \n3         1.063514         -0.077532         0.120986        1.168248   \n4        -0.307276         -0.237184        -0.013624       -0.529883   \n\n   pixel_frac_MEAN  pixel_frac_VAR  crop_conf_SUM  crop_conf_MEAN  \\\n0         0.057136       -0.163850      -0.817486        0.138982   \n1        -0.071330       -0.139008      -0.533878        0.138982   \n2         0.404513        0.123483       0.884162        0.138982   \n3         0.164305        0.199442       1.167770        0.138982   \n4        -1.088897       -0.153880      -0.250270        0.138982   \n\n   crop_conf_VAR  crop_importance_SUM  crop_importance_MEAN  \\\n0      -0.137805            -0.817133              0.139028   \n1      -0.137805            -0.533092              0.139028   \n2      -0.137805             0.887115              0.139028   \n3      -0.137805             1.171157              0.139028   \n4      -0.137805            -0.254731              0.098731   \n\n   crop_importance_VAR  specified_SUM  specified_MEAN  specified_VAR  \\\n0            -0.042402      -0.813932        0.220208       -0.18826   \n1            -0.042402      -0.524526        0.220208       -0.18826   \n2            -0.042402       0.922507        0.220208       -0.18826   \n3            -0.042402       1.211914        0.220208       -0.18826   \n4            -0.041352      -0.235119        0.220208       -0.18826   \n\n   main_breed_Type  second_breed_Type  len_description  len_meta_desc  \\\n0          1.05936          -0.562268         0.482345      -0.970235   \n1          1.05936          -0.562268        -0.544292      -0.327012   \n2         -0.94197          -0.562268         0.566042       1.064897   \n3         -0.94197          -0.562268        -0.348319       1.092567   \n4         -0.94197          -0.562268         0.558953       0.058157   \n\n   len_entity  num_description_words  num_desc_words  num_entity_words  \\\n0    0.500955               0.519078       -1.027484          0.443748   \n1   -0.978440              -0.506754       -0.314407         -1.243792   \n2    0.609698               0.519078        1.102149          0.590031   \n3   -0.072772              -0.430047        1.150112         -0.169305   \n4    0.409054               0.670708       -0.009517          0.443748   \n\n   uniq_description_words  uniq_desc_words  uniq_entity_words  \\\n0                0.539772        -0.266118           0.453230   \n1               -0.542146         0.253030          -1.234661   \n2                0.593479         0.510427           0.617952   \n3               -0.356466         0.253030          -0.105635   \n4                0.677378         0.061120           0.538535   \n\n   num_description_stopwords  num_desc_stopwords  num_entity_stopwords  \\\n0                   0.669926           -0.021144             -0.357513   \n1                  -0.155182            0.482987             -0.357513   \n2                   0.568819           -0.882961             -0.357513   \n3                  -0.461536           -0.882961             -0.357513   \n4                   0.841422           -0.882961             -0.357513   \n\n   num_description_punctuation  state_gdp  state_population  state_area  \\\n0                     0.083495   0.642057          0.837369    0.620169   \n1                    -1.032706  -0.122787         -1.155849   -1.532409   \n2                     0.190543   0.642057          0.837369    0.620169   \n3                    -0.036174  -0.122787         -1.155849   -1.532409   \n4                     0.190543   0.642057          0.837369    0.620169   \n\n   state_gdp_per_person  fee_per_gdp_per_person  num_name_words  contains_amp  \\\n0             -0.414149                0.866557       -0.499373     -0.320762   \n1              1.527495               -0.229461        0.967877     -0.320762   \n2             -0.414149               -0.229461       -0.499373     -0.320762   \n3              1.527495                0.514889       -0.499373     -0.320762   \n4             -0.414149               -0.229461       -0.499373     -0.320762   \n\n   contains_comma  start_with_number  contains_paren  contains_number  \\\n0       -0.154216          -0.147911       -0.188211        -0.290496   \n1       -0.154216          -0.147911       -0.188211        -0.290496   \n2       -0.154216          -0.147911       -0.188211        -0.290496   \n3       -0.154216          -0.147911       -0.188211        -0.290496   \n4       -0.154216          -0.147911       -0.188211        -0.290496   \n\n   name_length  num_unlike_letters  rate_unlike_letters  Tfidf_Description_0  \\\n0    -0.391155           -0.323289            -0.313549             0.044744   \n1     0.289119           -0.323289            -0.313549            -0.701180   \n2    -0.391155           -0.323289            -0.313549             0.308158   \n3    -0.663264           -0.323289            -0.313549            -0.431990   \n4    -0.391155           -0.323289            -0.313549             1.418634   \n\n   Tfidf_Description_1  Tfidf_Description_2  Tfidf_Description_3  \\\n0            -0.233591            -0.294805            -0.151926   \n1            -0.112283            -0.185616            -0.087399   \n2            -0.293496             0.889665            -0.106772   \n3             0.094940             0.036552             0.174450   \n4            -0.141192            -0.081388            -0.214699   \n\n   Tfidf_Description_4    ...        img14     img15     img16     img17  \\\n0            -0.270423    ...     0.110586  2.151125 -1.176674  2.415041   \n1            -0.108876    ...    -0.045172  2.472195 -1.435838  2.977570   \n2             0.448940    ...     0.706491  3.740337 -1.754591  3.044297   \n3             0.179728    ...     0.714303  3.766063 -2.171436  5.997324   \n4            -0.241654    ...     0.556824  3.220304 -2.013937  3.848544   \n\n      img18     img19     img20     img21     img22     img23     img24  \\\n0  0.703949 -1.588303 -0.543489  0.818192 -1.419860  1.635671  1.230090   \n1  1.420283 -1.214347 -1.046712  0.765651 -1.661028  2.115986  1.341369   \n2  1.617188 -1.144515 -1.906649  1.023324 -3.877063  3.639141  1.870255   \n3 -0.004172 -1.723910 -1.578517  2.265283 -3.442194  3.262680  3.076942   \n4  1.438846 -0.914814 -1.009198  1.642408 -3.110111  3.080442  1.862627   \n\n      img25     img26     img27     img28     img29     img30     img31  \\\n0  1.056767 -0.403665  1.106224  0.096388  1.556007 -0.848707  0.224280   \n1  1.500666 -1.049592  1.269030 -0.071501  1.327432 -0.891723  1.284225   \n2  2.687016 -1.305590  0.844590 -0.206637  1.519087 -2.179879  0.798290   \n3  2.515201 -1.821304  1.635721  0.145540  3.523111 -1.485916  0.318308   \n4  2.129172 -1.850668  1.173814 -0.381908  2.133727 -1.585165  0.725314   \n\n      img32     img33     img34     img35     img36     img37     img38  \\\n0 -3.398524  0.857789 -0.167985 -0.397752 -3.545173 -0.916391  0.599372   \n1 -4.005236  1.059146 -0.553956  0.564387 -4.653399 -1.162407  1.164328   \n2 -4.847266  0.724858 -0.536026  1.163803 -7.355669 -1.725377  1.048077   \n3 -4.195776  1.051438  0.223658  1.014659 -8.322213 -1.678787  0.642676   \n4 -4.943785  0.924910 -0.557188  0.781747 -6.047087 -0.984050  0.611377   \n\n      img39     img40     img41     img42     img43     img44     img45  \\\n0 -0.187137 -1.365577 -2.507689  0.546872  0.475532 -1.821823  0.759485   \n1 -0.568253 -1.356671 -3.293017  0.985037  1.320855 -1.992518  1.044078   \n2  0.049122 -3.023522 -4.714112  1.180708  1.768260 -4.127668  3.099615   \n3 -0.352061 -2.542596 -5.023290  2.166600  0.604448 -5.354814  1.882512   \n4 -0.838628 -2.316990 -4.628384  1.059011  1.744222 -3.782774  2.087450   \n\n      img46     img47      emb0      emb1      emb2      emb3      emb4  \\\n0 -0.163166  1.413023  0.069553 -0.844969  0.508286 -1.416741 -0.831533   \n1  0.064549  1.250380  0.069553  0.591301 -0.392345  1.509525 -0.831533   \n2  0.795191  1.659834  0.474235 -0.308725  0.306153  1.154131 -0.831533   \n3  0.037363  2.774812  0.474235 -0.308725  0.306153  1.154131 -0.831533   \n4  0.691992  1.934122  0.474235 -0.308725  0.306153  1.154131 -0.831533   \n\n       emb5      emb6      emb7      emb8      emb9     emb10     emb11  \\\n0  0.827695  1.204345 -0.663034  0.670370  1.081997 -0.449266  0.195283   \n1  0.827695  1.204345 -0.663034  0.670370  1.987546 -0.449266 -0.148951   \n2  0.827695  1.204345 -0.663034  1.413041  1.081997 -0.449266 -0.148951   \n3  0.827695  1.204345 -0.547322  0.670370  1.987546 -0.449266 -0.148951   \n4  0.827695  1.204345 -0.663034  0.670370 -0.638341 -0.449266 -0.148951   \n\n      emb12     emb13     emb14     emb15     emb16     emb17     emb18  \\\n0 -1.474584 -0.755869  0.219763  1.209454 -0.240832 -0.318214 -0.766078   \n1  1.518030 -0.268800 -0.043801 -0.200018 -0.240832 -0.318214  2.669607   \n2  1.518030 -1.894602 -0.526782  1.209454 -0.240832 -0.318214 -0.766078   \n3 -1.474584 -1.894602 -0.526782  1.209454 -0.240832 -0.318214  2.669607   \n4 -1.474584 -0.755869  0.219763  1.209454 -0.240832 -0.318214 -0.766078   \n\n      emb19      ent0      ent1      ent2      ent3      ent4      ent5  \\\n0  1.029494  0.176839  0.030176 -0.035038  0.001003  0.052116 -0.187229   \n1  1.029494  0.169469  0.010807 -0.027873 -0.005639 -0.049348 -0.275070   \n2  1.029494  0.050021  0.144598 -0.021119 -0.044309  0.000090 -0.034269   \n3  1.029494  0.009481  0.179083  0.032318  0.030371  0.036187 -0.038786   \n4  1.029494  0.195881  0.097763 -0.118332 -0.078144 -0.050602 -0.082269   \n\n       ent6      ent7      ent8      ent9  \n0 -0.027397  0.005489 -0.011326  0.048244  \n1 -0.050310  0.009976 -0.120855  0.138065  \n2 -0.014296  0.026448 -0.005892  0.068137  \n3 -0.066376  0.123849  0.132462 -0.063814  \n4 -0.111411 -0.039720 -0.044915  0.032023  \n\n[5 rows x 248 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Fee</th>\n      <th>VideoAmt</th>\n      <th>PhotoAmt</th>\n      <th>magnitude_sum</th>\n      <th>magnitude_mean</th>\n      <th>magnitude_var</th>\n      <th>score_sum</th>\n      <th>score_mean</th>\n      <th>score_var</th>\n      <th>document_magnitude</th>\n      <th>document_score</th>\n      <th>annot_score_SUM</th>\n      <th>annot_score_MEAN</th>\n      <th>annot_score_VAR</th>\n      <th>color_score_SUM</th>\n      <th>color_score_MEAN</th>\n      <th>color_score_VAR</th>\n      <th>pixel_frac_SUM</th>\n      <th>pixel_frac_MEAN</th>\n      <th>pixel_frac_VAR</th>\n      <th>crop_conf_SUM</th>\n      <th>crop_conf_MEAN</th>\n      <th>crop_conf_VAR</th>\n      <th>crop_importance_SUM</th>\n      <th>crop_importance_MEAN</th>\n      <th>crop_importance_VAR</th>\n      <th>specified_SUM</th>\n      <th>specified_MEAN</th>\n      <th>specified_VAR</th>\n      <th>main_breed_Type</th>\n      <th>second_breed_Type</th>\n      <th>len_description</th>\n      <th>len_meta_desc</th>\n      <th>len_entity</th>\n      <th>num_description_words</th>\n      <th>num_desc_words</th>\n      <th>num_entity_words</th>\n      <th>uniq_description_words</th>\n      <th>uniq_desc_words</th>\n      <th>uniq_entity_words</th>\n      <th>num_description_stopwords</th>\n      <th>num_desc_stopwords</th>\n      <th>num_entity_stopwords</th>\n      <th>num_description_punctuation</th>\n      <th>state_gdp</th>\n      <th>state_population</th>\n      <th>state_area</th>\n      <th>state_gdp_per_person</th>\n      <th>fee_per_gdp_per_person</th>\n      <th>num_name_words</th>\n      <th>contains_amp</th>\n      <th>contains_comma</th>\n      <th>start_with_number</th>\n      <th>contains_paren</th>\n      <th>contains_number</th>\n      <th>name_length</th>\n      <th>num_unlike_letters</th>\n      <th>rate_unlike_letters</th>\n      <th>Tfidf_Description_0</th>\n      <th>Tfidf_Description_1</th>\n      <th>Tfidf_Description_2</th>\n      <th>Tfidf_Description_3</th>\n      <th>Tfidf_Description_4</th>\n      <th>...</th>\n      <th>img14</th>\n      <th>img15</th>\n      <th>img16</th>\n      <th>img17</th>\n      <th>img18</th>\n      <th>img19</th>\n      <th>img20</th>\n      <th>img21</th>\n      <th>img22</th>\n      <th>img23</th>\n      <th>img24</th>\n      <th>img25</th>\n      <th>img26</th>\n      <th>img27</th>\n      <th>img28</th>\n      <th>img29</th>\n      <th>img30</th>\n      <th>img31</th>\n      <th>img32</th>\n      <th>img33</th>\n      <th>img34</th>\n      <th>img35</th>\n      <th>img36</th>\n      <th>img37</th>\n      <th>img38</th>\n      <th>img39</th>\n      <th>img40</th>\n      <th>img41</th>\n      <th>img42</th>\n      <th>img43</th>\n      <th>img44</th>\n      <th>img45</th>\n      <th>img46</th>\n      <th>img47</th>\n      <th>emb0</th>\n      <th>emb1</th>\n      <th>emb2</th>\n      <th>emb3</th>\n      <th>emb4</th>\n      <th>emb5</th>\n      <th>emb6</th>\n      <th>emb7</th>\n      <th>emb8</th>\n      <th>emb9</th>\n      <th>emb10</th>\n      <th>emb11</th>\n      <th>emb12</th>\n      <th>emb13</th>\n      <th>emb14</th>\n      <th>emb15</th>\n      <th>emb16</th>\n      <th>emb17</th>\n      <th>emb18</th>\n      <th>emb19</th>\n      <th>ent0</th>\n      <th>ent1</th>\n      <th>ent2</th>\n      <th>ent3</th>\n      <th>ent4</th>\n      <th>ent5</th>\n      <th>ent6</th>\n      <th>ent7</th>\n      <th>ent8</th>\n      <th>ent9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.421104</td>\n      <td>0.960767</td>\n      <td>-0.162959</td>\n      <td>-0.816674</td>\n      <td>0.175573</td>\n      <td>-0.089689</td>\n      <td>0.720044</td>\n      <td>0.392032</td>\n      <td>0.057521</td>\n      <td>0.376737</td>\n      <td>0.161785</td>\n      <td>0.099729</td>\n      <td>-0.798692</td>\n      <td>0.532229</td>\n      <td>-0.618650</td>\n      <td>-0.842711</td>\n      <td>-0.520689</td>\n      <td>-0.063222</td>\n      <td>-0.779326</td>\n      <td>0.057136</td>\n      <td>-0.163850</td>\n      <td>-0.817486</td>\n      <td>0.138982</td>\n      <td>-0.137805</td>\n      <td>-0.817133</td>\n      <td>0.139028</td>\n      <td>-0.042402</td>\n      <td>-0.813932</td>\n      <td>0.220208</td>\n      <td>-0.18826</td>\n      <td>1.05936</td>\n      <td>-0.562268</td>\n      <td>0.482345</td>\n      <td>-0.970235</td>\n      <td>0.500955</td>\n      <td>0.519078</td>\n      <td>-1.027484</td>\n      <td>0.443748</td>\n      <td>0.539772</td>\n      <td>-0.266118</td>\n      <td>0.453230</td>\n      <td>0.669926</td>\n      <td>-0.021144</td>\n      <td>-0.357513</td>\n      <td>0.083495</td>\n      <td>0.642057</td>\n      <td>0.837369</td>\n      <td>0.620169</td>\n      <td>-0.414149</td>\n      <td>0.866557</td>\n      <td>-0.499373</td>\n      <td>-0.320762</td>\n      <td>-0.154216</td>\n      <td>-0.147911</td>\n      <td>-0.188211</td>\n      <td>-0.290496</td>\n      <td>-0.391155</td>\n      <td>-0.323289</td>\n      <td>-0.313549</td>\n      <td>0.044744</td>\n      <td>-0.233591</td>\n      <td>-0.294805</td>\n      <td>-0.151926</td>\n      <td>-0.270423</td>\n      <td>...</td>\n      <td>0.110586</td>\n      <td>2.151125</td>\n      <td>-1.176674</td>\n      <td>2.415041</td>\n      <td>0.703949</td>\n      <td>-1.588303</td>\n      <td>-0.543489</td>\n      <td>0.818192</td>\n      <td>-1.419860</td>\n      <td>1.635671</td>\n      <td>1.230090</td>\n      <td>1.056767</td>\n      <td>-0.403665</td>\n      <td>1.106224</td>\n      <td>0.096388</td>\n      <td>1.556007</td>\n      <td>-0.848707</td>\n      <td>0.224280</td>\n      <td>-3.398524</td>\n      <td>0.857789</td>\n      <td>-0.167985</td>\n      <td>-0.397752</td>\n      <td>-3.545173</td>\n      <td>-0.916391</td>\n      <td>0.599372</td>\n      <td>-0.187137</td>\n      <td>-1.365577</td>\n      <td>-2.507689</td>\n      <td>0.546872</td>\n      <td>0.475532</td>\n      <td>-1.821823</td>\n      <td>0.759485</td>\n      <td>-0.163166</td>\n      <td>1.413023</td>\n      <td>0.069553</td>\n      <td>-0.844969</td>\n      <td>0.508286</td>\n      <td>-1.416741</td>\n      <td>-0.831533</td>\n      <td>0.827695</td>\n      <td>1.204345</td>\n      <td>-0.663034</td>\n      <td>0.670370</td>\n      <td>1.081997</td>\n      <td>-0.449266</td>\n      <td>0.195283</td>\n      <td>-1.474584</td>\n      <td>-0.755869</td>\n      <td>0.219763</td>\n      <td>1.209454</td>\n      <td>-0.240832</td>\n      <td>-0.318214</td>\n      <td>-0.766078</td>\n      <td>1.029494</td>\n      <td>0.176839</td>\n      <td>0.030176</td>\n      <td>-0.035038</td>\n      <td>0.001003</td>\n      <td>0.052116</td>\n      <td>-0.187229</td>\n      <td>-0.027397</td>\n      <td>0.005489</td>\n      <td>-0.011326</td>\n      <td>0.048244</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.530710</td>\n      <td>-0.279390</td>\n      <td>-0.162959</td>\n      <td>-0.532377</td>\n      <td>-0.648924</td>\n      <td>-0.163610</td>\n      <td>-0.031676</td>\n      <td>-1.250631</td>\n      <td>-1.939791</td>\n      <td>0.140569</td>\n      <td>-0.676014</td>\n      <td>-1.701005</td>\n      <td>-0.522569</td>\n      <td>0.253078</td>\n      <td>-0.552837</td>\n      <td>-0.489244</td>\n      <td>0.448827</td>\n      <td>-0.037801</td>\n      <td>-0.532728</td>\n      <td>-0.071330</td>\n      <td>-0.139008</td>\n      <td>-0.533878</td>\n      <td>0.138982</td>\n      <td>-0.137805</td>\n      <td>-0.533092</td>\n      <td>0.139028</td>\n      <td>-0.042402</td>\n      <td>-0.524526</td>\n      <td>0.220208</td>\n      <td>-0.18826</td>\n      <td>1.05936</td>\n      <td>-0.562268</td>\n      <td>-0.544292</td>\n      <td>-0.327012</td>\n      <td>-0.978440</td>\n      <td>-0.506754</td>\n      <td>-0.314407</td>\n      <td>-1.243792</td>\n      <td>-0.542146</td>\n      <td>0.253030</td>\n      <td>-1.234661</td>\n      <td>-0.155182</td>\n      <td>0.482987</td>\n      <td>-0.357513</td>\n      <td>-1.032706</td>\n      <td>-0.122787</td>\n      <td>-1.155849</td>\n      <td>-1.532409</td>\n      <td>1.527495</td>\n      <td>-0.229461</td>\n      <td>0.967877</td>\n      <td>-0.320762</td>\n      <td>-0.154216</td>\n      <td>-0.147911</td>\n      <td>-0.188211</td>\n      <td>-0.290496</td>\n      <td>0.289119</td>\n      <td>-0.323289</td>\n      <td>-0.313549</td>\n      <td>-0.701180</td>\n      <td>-0.112283</td>\n      <td>-0.185616</td>\n      <td>-0.087399</td>\n      <td>-0.108876</td>\n      <td>...</td>\n      <td>-0.045172</td>\n      <td>2.472195</td>\n      <td>-1.435838</td>\n      <td>2.977570</td>\n      <td>1.420283</td>\n      <td>-1.214347</td>\n      <td>-1.046712</td>\n      <td>0.765651</td>\n      <td>-1.661028</td>\n      <td>2.115986</td>\n      <td>1.341369</td>\n      <td>1.500666</td>\n      <td>-1.049592</td>\n      <td>1.269030</td>\n      <td>-0.071501</td>\n      <td>1.327432</td>\n      <td>-0.891723</td>\n      <td>1.284225</td>\n      <td>-4.005236</td>\n      <td>1.059146</td>\n      <td>-0.553956</td>\n      <td>0.564387</td>\n      <td>-4.653399</td>\n      <td>-1.162407</td>\n      <td>1.164328</td>\n      <td>-0.568253</td>\n      <td>-1.356671</td>\n      <td>-3.293017</td>\n      <td>0.985037</td>\n      <td>1.320855</td>\n      <td>-1.992518</td>\n      <td>1.044078</td>\n      <td>0.064549</td>\n      <td>1.250380</td>\n      <td>0.069553</td>\n      <td>0.591301</td>\n      <td>-0.392345</td>\n      <td>1.509525</td>\n      <td>-0.831533</td>\n      <td>0.827695</td>\n      <td>1.204345</td>\n      <td>-0.663034</td>\n      <td>0.670370</td>\n      <td>1.987546</td>\n      <td>-0.449266</td>\n      <td>-0.148951</td>\n      <td>1.518030</td>\n      <td>-0.268800</td>\n      <td>-0.043801</td>\n      <td>-0.200018</td>\n      <td>-0.240832</td>\n      <td>-0.318214</td>\n      <td>2.669607</td>\n      <td>1.029494</td>\n      <td>0.169469</td>\n      <td>0.010807</td>\n      <td>-0.027873</td>\n      <td>-0.005639</td>\n      <td>-0.049348</td>\n      <td>-0.275070</td>\n      <td>-0.050310</td>\n      <td>0.009976</td>\n      <td>-0.120855</td>\n      <td>0.138065</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.530710</td>\n      <td>-0.279390</td>\n      <td>-0.162959</td>\n      <td>0.889111</td>\n      <td>0.835170</td>\n      <td>0.438317</td>\n      <td>1.133721</td>\n      <td>0.106352</td>\n      <td>-0.305627</td>\n      <td>2.070637</td>\n      <td>0.802455</td>\n      <td>-0.260418</td>\n      <td>0.905726</td>\n      <td>0.201793</td>\n      <td>-0.041704</td>\n      <td>1.062379</td>\n      <td>0.597325</td>\n      <td>-0.036040</td>\n      <td>1.031460</td>\n      <td>0.404513</td>\n      <td>0.123483</td>\n      <td>0.884162</td>\n      <td>0.138982</td>\n      <td>-0.137805</td>\n      <td>0.887115</td>\n      <td>0.139028</td>\n      <td>-0.042402</td>\n      <td>0.922507</td>\n      <td>0.220208</td>\n      <td>-0.18826</td>\n      <td>-0.94197</td>\n      <td>-0.562268</td>\n      <td>0.566042</td>\n      <td>1.064897</td>\n      <td>0.609698</td>\n      <td>0.519078</td>\n      <td>1.102149</td>\n      <td>0.590031</td>\n      <td>0.593479</td>\n      <td>0.510427</td>\n      <td>0.617952</td>\n      <td>0.568819</td>\n      <td>-0.882961</td>\n      <td>-0.357513</td>\n      <td>0.190543</td>\n      <td>0.642057</td>\n      <td>0.837369</td>\n      <td>0.620169</td>\n      <td>-0.414149</td>\n      <td>-0.229461</td>\n      <td>-0.499373</td>\n      <td>-0.320762</td>\n      <td>-0.154216</td>\n      <td>-0.147911</td>\n      <td>-0.188211</td>\n      <td>-0.290496</td>\n      <td>-0.391155</td>\n      <td>-0.323289</td>\n      <td>-0.313549</td>\n      <td>0.308158</td>\n      <td>-0.293496</td>\n      <td>0.889665</td>\n      <td>-0.106772</td>\n      <td>0.448940</td>\n      <td>...</td>\n      <td>0.706491</td>\n      <td>3.740337</td>\n      <td>-1.754591</td>\n      <td>3.044297</td>\n      <td>1.617188</td>\n      <td>-1.144515</td>\n      <td>-1.906649</td>\n      <td>1.023324</td>\n      <td>-3.877063</td>\n      <td>3.639141</td>\n      <td>1.870255</td>\n      <td>2.687016</td>\n      <td>-1.305590</td>\n      <td>0.844590</td>\n      <td>-0.206637</td>\n      <td>1.519087</td>\n      <td>-2.179879</td>\n      <td>0.798290</td>\n      <td>-4.847266</td>\n      <td>0.724858</td>\n      <td>-0.536026</td>\n      <td>1.163803</td>\n      <td>-7.355669</td>\n      <td>-1.725377</td>\n      <td>1.048077</td>\n      <td>0.049122</td>\n      <td>-3.023522</td>\n      <td>-4.714112</td>\n      <td>1.180708</td>\n      <td>1.768260</td>\n      <td>-4.127668</td>\n      <td>3.099615</td>\n      <td>0.795191</td>\n      <td>1.659834</td>\n      <td>0.474235</td>\n      <td>-0.308725</td>\n      <td>0.306153</td>\n      <td>1.154131</td>\n      <td>-0.831533</td>\n      <td>0.827695</td>\n      <td>1.204345</td>\n      <td>-0.663034</td>\n      <td>1.413041</td>\n      <td>1.081997</td>\n      <td>-0.449266</td>\n      <td>-0.148951</td>\n      <td>1.518030</td>\n      <td>-1.894602</td>\n      <td>-0.526782</td>\n      <td>1.209454</td>\n      <td>-0.240832</td>\n      <td>-0.318214</td>\n      <td>-0.766078</td>\n      <td>1.029494</td>\n      <td>0.050021</td>\n      <td>0.144598</td>\n      <td>-0.021119</td>\n      <td>-0.044309</td>\n      <td>0.000090</td>\n      <td>-0.034269</td>\n      <td>-0.014296</td>\n      <td>0.026448</td>\n      <td>-0.005892</td>\n      <td>0.068137</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.366301</td>\n      <td>1.580845</td>\n      <td>-0.162959</td>\n      <td>1.173408</td>\n      <td>-0.538991</td>\n      <td>2.275777</td>\n      <td>-1.214452</td>\n      <td>-0.250749</td>\n      <td>2.236407</td>\n      <td>-1.056562</td>\n      <td>-0.577449</td>\n      <td>2.260610</td>\n      <td>1.095797</td>\n      <td>-0.060583</td>\n      <td>-0.496847</td>\n      <td>1.063514</td>\n      <td>-0.077532</td>\n      <td>0.120986</td>\n      <td>1.168248</td>\n      <td>0.164305</td>\n      <td>0.199442</td>\n      <td>1.167770</td>\n      <td>0.138982</td>\n      <td>-0.137805</td>\n      <td>1.171157</td>\n      <td>0.139028</td>\n      <td>-0.042402</td>\n      <td>1.211914</td>\n      <td>0.220208</td>\n      <td>-0.18826</td>\n      <td>-0.94197</td>\n      <td>-0.562268</td>\n      <td>-0.348319</td>\n      <td>1.092567</td>\n      <td>-0.072772</td>\n      <td>-0.430047</td>\n      <td>1.150112</td>\n      <td>-0.169305</td>\n      <td>-0.356466</td>\n      <td>0.253030</td>\n      <td>-0.105635</td>\n      <td>-0.461536</td>\n      <td>-0.882961</td>\n      <td>-0.357513</td>\n      <td>-0.036174</td>\n      <td>-0.122787</td>\n      <td>-1.155849</td>\n      <td>-1.532409</td>\n      <td>1.527495</td>\n      <td>0.514889</td>\n      <td>-0.499373</td>\n      <td>-0.320762</td>\n      <td>-0.154216</td>\n      <td>-0.147911</td>\n      <td>-0.188211</td>\n      <td>-0.290496</td>\n      <td>-0.663264</td>\n      <td>-0.323289</td>\n      <td>-0.313549</td>\n      <td>-0.431990</td>\n      <td>0.094940</td>\n      <td>0.036552</td>\n      <td>0.174450</td>\n      <td>0.179728</td>\n      <td>...</td>\n      <td>0.714303</td>\n      <td>3.766063</td>\n      <td>-2.171436</td>\n      <td>5.997324</td>\n      <td>-0.004172</td>\n      <td>-1.723910</td>\n      <td>-1.578517</td>\n      <td>2.265283</td>\n      <td>-3.442194</td>\n      <td>3.262680</td>\n      <td>3.076942</td>\n      <td>2.515201</td>\n      <td>-1.821304</td>\n      <td>1.635721</td>\n      <td>0.145540</td>\n      <td>3.523111</td>\n      <td>-1.485916</td>\n      <td>0.318308</td>\n      <td>-4.195776</td>\n      <td>1.051438</td>\n      <td>0.223658</td>\n      <td>1.014659</td>\n      <td>-8.322213</td>\n      <td>-1.678787</td>\n      <td>0.642676</td>\n      <td>-0.352061</td>\n      <td>-2.542596</td>\n      <td>-5.023290</td>\n      <td>2.166600</td>\n      <td>0.604448</td>\n      <td>-5.354814</td>\n      <td>1.882512</td>\n      <td>0.037363</td>\n      <td>2.774812</td>\n      <td>0.474235</td>\n      <td>-0.308725</td>\n      <td>0.306153</td>\n      <td>1.154131</td>\n      <td>-0.831533</td>\n      <td>0.827695</td>\n      <td>1.204345</td>\n      <td>-0.547322</td>\n      <td>0.670370</td>\n      <td>1.987546</td>\n      <td>-0.449266</td>\n      <td>-0.148951</td>\n      <td>-1.474584</td>\n      <td>-1.894602</td>\n      <td>-0.526782</td>\n      <td>1.209454</td>\n      <td>-0.240832</td>\n      <td>-0.318214</td>\n      <td>2.669607</td>\n      <td>1.029494</td>\n      <td>0.009481</td>\n      <td>0.179083</td>\n      <td>0.032318</td>\n      <td>0.030371</td>\n      <td>0.036187</td>\n      <td>-0.038786</td>\n      <td>-0.066376</td>\n      <td>0.123849</td>\n      <td>0.132462</td>\n      <td>-0.063814</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.530710</td>\n      <td>-0.279390</td>\n      <td>-0.162959</td>\n      <td>-0.248079</td>\n      <td>0.890136</td>\n      <td>0.871281</td>\n      <td>0.136541</td>\n      <td>1.606175</td>\n      <td>1.086440</td>\n      <td>-0.358914</td>\n      <td>0.802455</td>\n      <td>1.180169</td>\n      <td>-0.255537</td>\n      <td>0.094133</td>\n      <td>5.585148</td>\n      <td>-0.307276</td>\n      <td>-0.237184</td>\n      <td>-0.013624</td>\n      <td>-0.529883</td>\n      <td>-1.088897</td>\n      <td>-0.153880</td>\n      <td>-0.250270</td>\n      <td>0.138982</td>\n      <td>-0.137805</td>\n      <td>-0.254731</td>\n      <td>0.098731</td>\n      <td>-0.041352</td>\n      <td>-0.235119</td>\n      <td>0.220208</td>\n      <td>-0.18826</td>\n      <td>-0.94197</td>\n      <td>-0.562268</td>\n      <td>0.558953</td>\n      <td>0.058157</td>\n      <td>0.409054</td>\n      <td>0.670708</td>\n      <td>-0.009517</td>\n      <td>0.443748</td>\n      <td>0.677378</td>\n      <td>0.061120</td>\n      <td>0.538535</td>\n      <td>0.841422</td>\n      <td>-0.882961</td>\n      <td>-0.357513</td>\n      <td>0.190543</td>\n      <td>0.642057</td>\n      <td>0.837369</td>\n      <td>0.620169</td>\n      <td>-0.414149</td>\n      <td>-0.229461</td>\n      <td>-0.499373</td>\n      <td>-0.320762</td>\n      <td>-0.154216</td>\n      <td>-0.147911</td>\n      <td>-0.188211</td>\n      <td>-0.290496</td>\n      <td>-0.391155</td>\n      <td>-0.323289</td>\n      <td>-0.313549</td>\n      <td>1.418634</td>\n      <td>-0.141192</td>\n      <td>-0.081388</td>\n      <td>-0.214699</td>\n      <td>-0.241654</td>\n      <td>...</td>\n      <td>0.556824</td>\n      <td>3.220304</td>\n      <td>-2.013937</td>\n      <td>3.848544</td>\n      <td>1.438846</td>\n      <td>-0.914814</td>\n      <td>-1.009198</td>\n      <td>1.642408</td>\n      <td>-3.110111</td>\n      <td>3.080442</td>\n      <td>1.862627</td>\n      <td>2.129172</td>\n      <td>-1.850668</td>\n      <td>1.173814</td>\n      <td>-0.381908</td>\n      <td>2.133727</td>\n      <td>-1.585165</td>\n      <td>0.725314</td>\n      <td>-4.943785</td>\n      <td>0.924910</td>\n      <td>-0.557188</td>\n      <td>0.781747</td>\n      <td>-6.047087</td>\n      <td>-0.984050</td>\n      <td>0.611377</td>\n      <td>-0.838628</td>\n      <td>-2.316990</td>\n      <td>-4.628384</td>\n      <td>1.059011</td>\n      <td>1.744222</td>\n      <td>-3.782774</td>\n      <td>2.087450</td>\n      <td>0.691992</td>\n      <td>1.934122</td>\n      <td>0.474235</td>\n      <td>-0.308725</td>\n      <td>0.306153</td>\n      <td>1.154131</td>\n      <td>-0.831533</td>\n      <td>0.827695</td>\n      <td>1.204345</td>\n      <td>-0.663034</td>\n      <td>0.670370</td>\n      <td>-0.638341</td>\n      <td>-0.449266</td>\n      <td>-0.148951</td>\n      <td>-1.474584</td>\n      <td>-0.755869</td>\n      <td>0.219763</td>\n      <td>1.209454</td>\n      <td>-0.240832</td>\n      <td>-0.318214</td>\n      <td>-0.766078</td>\n      <td>1.029494</td>\n      <td>0.195881</td>\n      <td>0.097763</td>\n      <td>-0.118332</td>\n      <td>-0.078144</td>\n      <td>-0.050602</td>\n      <td>-0.082269</td>\n      <td>-0.111411</td>\n      <td>-0.039720</td>\n      <td>-0.044915</td>\n      <td>0.032023</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 248 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"d_train = torch.tensor(train_desc, dtype=torch.float32).to(\"cuda:0\")\nd_test = torch.tensor(test_desc, dtype=torch.float32).to(\"cuda:0\")\ntrain_dataset = WordVecDataset(d_train)\ntest_dataset = WordVecDataset(d_test)\ntrain_loader = data.DataLoader(train_dataset, batch_size=128, shuffle=False)\ntest_loader = data.DataLoader(test_dataset, batch_size=128, shuffle=False)\n\nX_train_dsc = np.zeros((len(train_pet_ids), 10))\nX_test_dsc = np.zeros((len(test_pet_ids), 10))\nbin_path = trainer.path\nfor path in bin_path.iterdir():\n    model = NeuralNet(**trainer.kwargs)\n    model.to(\"cuda:0\")\n    model.load_state_dict(torch.load(path))\n    model.eval()\n    temp = np.zeros((len(train_pet_ids), 10))\n    for i, (d_batch, ) in tqdm(enumerate(train_loader), ascii=True):\n        with torch.no_grad():\n            y_pred = model.dsc_lin(d_batch).detach()\n            temp[i * 128:(i + 1) * 128, :] = y_pred.cpu().numpy()\n    X_train_dsc += temp / trainer.n_splits\n    temp = np.zeros((len(test_pet_ids), 10))\n    for i, (d_batch, ) in tqdm(enumerate(test_loader), ascii=True):\n        with torch.no_grad():\n            y_pred = model.dsc_lin(d_batch).detach()\n            temp[i * 128:(i + 1) * 128, :] = y_pred.cpu().numpy()\n    X_test_dsc += temp / trainer.n_splits","execution_count":93,"outputs":[{"output_type":"stream","text":"118it [00:00, 1386.73it/s]\n31it [00:00, 1390.49it/s]\n118it [00:00, 1387.62it/s]\n31it [00:00, 1384.08it/s]\n118it [00:00, 1394.18it/s]\n31it [00:00, 1364.90it/s]\n118it [00:00, 1423.12it/s]\n31it [00:00, 1369.65it/s]\n118it [00:00, 1329.61it/s]\n31it [00:00, 1413.62it/s]\n118it [00:00, 1396.16it/s]\n31it [00:00, 1294.13it/s]\n118it [00:00, 1452.79it/s]\n31it [00:00, 1407.96it/s]\n118it [00:00, 1449.51it/s]\n31it [00:00, 1375.25it/s]\n118it [00:00, 1365.71it/s]\n31it [00:00, 1400.30it/s]\n118it [00:00, 1441.18it/s]\n31it [00:00, 1394.01it/s]\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_dsc.shape, X_test_dsc.shape","execution_count":94,"outputs":[{"output_type":"execute_result","execution_count":94,"data":{"text/plain":"((14993, 10), (3948, 10))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dsc = pd.DataFrame(data=X_train_dsc, columns=[\n    f\"dsc{i}\" for i in range(X_train_dsc.shape[1])\n])\ntest_dsc = pd.DataFrame(data=X_test_dsc, columns=[\n    f\"dsc{i}\" for i in range(X_test_dsc.shape[1])\n])\ntest_dsc.index = X_test_all.index\n\nX_train_all = pd.concat([X_train_all, train_dsc], axis=1)\nX_test_all = pd.concat([X_test_all, test_dsc], axis=1)\n\nprint(X_train_all.shape, X_test_all.shape)\nX_train_all.head()","execution_count":95,"outputs":[{"output_type":"stream","text":"(14993, 258) (3948, 258)\n","name":"stdout"},{"output_type":"execute_result","execution_count":95,"data":{"text/plain":"        Age       Fee  VideoAmt  PhotoAmt  magnitude_sum  magnitude_mean  \\\n0 -0.421104  0.960767 -0.162959 -0.816674       0.175573       -0.089689   \n1 -0.530710 -0.279390 -0.162959 -0.532377      -0.648924       -0.163610   \n2 -0.530710 -0.279390 -0.162959  0.889111       0.835170        0.438317   \n3 -0.366301  1.580845 -0.162959  1.173408      -0.538991        2.275777   \n4 -0.530710 -0.279390 -0.162959 -0.248079       0.890136        0.871281   \n\n   magnitude_var  score_sum  score_mean  score_var  document_magnitude  \\\n0       0.720044   0.392032    0.057521   0.376737            0.161785   \n1      -0.031676  -1.250631   -1.939791   0.140569           -0.676014   \n2       1.133721   0.106352   -0.305627   2.070637            0.802455   \n3      -1.214452  -0.250749    2.236407  -1.056562           -0.577449   \n4       0.136541   1.606175    1.086440  -0.358914            0.802455   \n\n   document_score  annot_score_SUM  annot_score_MEAN  annot_score_VAR  \\\n0        0.099729        -0.798692          0.532229        -0.618650   \n1       -1.701005        -0.522569          0.253078        -0.552837   \n2       -0.260418         0.905726          0.201793        -0.041704   \n3        2.260610         1.095797         -0.060583        -0.496847   \n4        1.180169        -0.255537          0.094133         5.585148   \n\n   color_score_SUM  color_score_MEAN  color_score_VAR  pixel_frac_SUM  \\\n0        -0.842711         -0.520689        -0.063222       -0.779326   \n1        -0.489244          0.448827        -0.037801       -0.532728   \n2         1.062379          0.597325        -0.036040        1.031460   \n3         1.063514         -0.077532         0.120986        1.168248   \n4        -0.307276         -0.237184        -0.013624       -0.529883   \n\n   pixel_frac_MEAN  pixel_frac_VAR  crop_conf_SUM  crop_conf_MEAN  \\\n0         0.057136       -0.163850      -0.817486        0.138982   \n1        -0.071330       -0.139008      -0.533878        0.138982   \n2         0.404513        0.123483       0.884162        0.138982   \n3         0.164305        0.199442       1.167770        0.138982   \n4        -1.088897       -0.153880      -0.250270        0.138982   \n\n   crop_conf_VAR  crop_importance_SUM  crop_importance_MEAN  \\\n0      -0.137805            -0.817133              0.139028   \n1      -0.137805            -0.533092              0.139028   \n2      -0.137805             0.887115              0.139028   \n3      -0.137805             1.171157              0.139028   \n4      -0.137805            -0.254731              0.098731   \n\n   crop_importance_VAR  specified_SUM  specified_MEAN  specified_VAR  \\\n0            -0.042402      -0.813932        0.220208       -0.18826   \n1            -0.042402      -0.524526        0.220208       -0.18826   \n2            -0.042402       0.922507        0.220208       -0.18826   \n3            -0.042402       1.211914        0.220208       -0.18826   \n4            -0.041352      -0.235119        0.220208       -0.18826   \n\n   main_breed_Type  second_breed_Type  len_description  len_meta_desc  \\\n0          1.05936          -0.562268         0.482345      -0.970235   \n1          1.05936          -0.562268        -0.544292      -0.327012   \n2         -0.94197          -0.562268         0.566042       1.064897   \n3         -0.94197          -0.562268        -0.348319       1.092567   \n4         -0.94197          -0.562268         0.558953       0.058157   \n\n   len_entity  num_description_words  num_desc_words  num_entity_words  \\\n0    0.500955               0.519078       -1.027484          0.443748   \n1   -0.978440              -0.506754       -0.314407         -1.243792   \n2    0.609698               0.519078        1.102149          0.590031   \n3   -0.072772              -0.430047        1.150112         -0.169305   \n4    0.409054               0.670708       -0.009517          0.443748   \n\n   uniq_description_words  uniq_desc_words  uniq_entity_words  \\\n0                0.539772        -0.266118           0.453230   \n1               -0.542146         0.253030          -1.234661   \n2                0.593479         0.510427           0.617952   \n3               -0.356466         0.253030          -0.105635   \n4                0.677378         0.061120           0.538535   \n\n   num_description_stopwords  num_desc_stopwords  num_entity_stopwords  \\\n0                   0.669926           -0.021144             -0.357513   \n1                  -0.155182            0.482987             -0.357513   \n2                   0.568819           -0.882961             -0.357513   \n3                  -0.461536           -0.882961             -0.357513   \n4                   0.841422           -0.882961             -0.357513   \n\n   num_description_punctuation  state_gdp  state_population  state_area  \\\n0                     0.083495   0.642057          0.837369    0.620169   \n1                    -1.032706  -0.122787         -1.155849   -1.532409   \n2                     0.190543   0.642057          0.837369    0.620169   \n3                    -0.036174  -0.122787         -1.155849   -1.532409   \n4                     0.190543   0.642057          0.837369    0.620169   \n\n   state_gdp_per_person  fee_per_gdp_per_person  num_name_words  contains_amp  \\\n0             -0.414149                0.866557       -0.499373     -0.320762   \n1              1.527495               -0.229461        0.967877     -0.320762   \n2             -0.414149               -0.229461       -0.499373     -0.320762   \n3              1.527495                0.514889       -0.499373     -0.320762   \n4             -0.414149               -0.229461       -0.499373     -0.320762   \n\n   contains_comma  start_with_number  contains_paren  contains_number  \\\n0       -0.154216          -0.147911       -0.188211        -0.290496   \n1       -0.154216          -0.147911       -0.188211        -0.290496   \n2       -0.154216          -0.147911       -0.188211        -0.290496   \n3       -0.154216          -0.147911       -0.188211        -0.290496   \n4       -0.154216          -0.147911       -0.188211        -0.290496   \n\n   name_length  num_unlike_letters  rate_unlike_letters  Tfidf_Description_0  \\\n0    -0.391155           -0.323289            -0.313549             0.044744   \n1     0.289119           -0.323289            -0.313549            -0.701180   \n2    -0.391155           -0.323289            -0.313549             0.308158   \n3    -0.663264           -0.323289            -0.313549            -0.431990   \n4    -0.391155           -0.323289            -0.313549             1.418634   \n\n   Tfidf_Description_1  Tfidf_Description_2  Tfidf_Description_3  \\\n0            -0.233591            -0.294805            -0.151926   \n1            -0.112283            -0.185616            -0.087399   \n2            -0.293496             0.889665            -0.106772   \n3             0.094940             0.036552             0.174450   \n4            -0.141192            -0.081388            -0.214699   \n\n   Tfidf_Description_4    ...        img24     img25     img26     img27  \\\n0            -0.270423    ...     1.230090  1.056767 -0.403665  1.106224   \n1            -0.108876    ...     1.341369  1.500666 -1.049592  1.269030   \n2             0.448940    ...     1.870255  2.687016 -1.305590  0.844590   \n3             0.179728    ...     3.076942  2.515201 -1.821304  1.635721   \n4            -0.241654    ...     1.862627  2.129172 -1.850668  1.173814   \n\n      img28     img29     img30     img31     img32     img33     img34  \\\n0  0.096388  1.556007 -0.848707  0.224280 -3.398524  0.857789 -0.167985   \n1 -0.071501  1.327432 -0.891723  1.284225 -4.005236  1.059146 -0.553956   \n2 -0.206637  1.519087 -2.179879  0.798290 -4.847266  0.724858 -0.536026   \n3  0.145540  3.523111 -1.485916  0.318308 -4.195776  1.051438  0.223658   \n4 -0.381908  2.133727 -1.585165  0.725314 -4.943785  0.924910 -0.557188   \n\n      img35     img36     img37     img38     img39     img40     img41  \\\n0 -0.397752 -3.545173 -0.916391  0.599372 -0.187137 -1.365577 -2.507689   \n1  0.564387 -4.653399 -1.162407  1.164328 -0.568253 -1.356671 -3.293017   \n2  1.163803 -7.355669 -1.725377  1.048077  0.049122 -3.023522 -4.714112   \n3  1.014659 -8.322213 -1.678787  0.642676 -0.352061 -2.542596 -5.023290   \n4  0.781747 -6.047087 -0.984050  0.611377 -0.838628 -2.316990 -4.628384   \n\n      img42     img43     img44     img45     img46     img47      emb0  \\\n0  0.546872  0.475532 -1.821823  0.759485 -0.163166  1.413023  0.069553   \n1  0.985037  1.320855 -1.992518  1.044078  0.064549  1.250380  0.069553   \n2  1.180708  1.768260 -4.127668  3.099615  0.795191  1.659834  0.474235   \n3  2.166600  0.604448 -5.354814  1.882512  0.037363  2.774812  0.474235   \n4  1.059011  1.744222 -3.782774  2.087450  0.691992  1.934122  0.474235   \n\n       emb1      emb2      emb3      emb4      emb5      emb6      emb7  \\\n0 -0.844969  0.508286 -1.416741 -0.831533  0.827695  1.204345 -0.663034   \n1  0.591301 -0.392345  1.509525 -0.831533  0.827695  1.204345 -0.663034   \n2 -0.308725  0.306153  1.154131 -0.831533  0.827695  1.204345 -0.663034   \n3 -0.308725  0.306153  1.154131 -0.831533  0.827695  1.204345 -0.547322   \n4 -0.308725  0.306153  1.154131 -0.831533  0.827695  1.204345 -0.663034   \n\n       emb8      emb9     emb10     emb11     emb12     emb13     emb14  \\\n0  0.670370  1.081997 -0.449266  0.195283 -1.474584 -0.755869  0.219763   \n1  0.670370  1.987546 -0.449266 -0.148951  1.518030 -0.268800 -0.043801   \n2  1.413041  1.081997 -0.449266 -0.148951  1.518030 -1.894602 -0.526782   \n3  0.670370  1.987546 -0.449266 -0.148951 -1.474584 -1.894602 -0.526782   \n4  0.670370 -0.638341 -0.449266 -0.148951 -1.474584 -0.755869  0.219763   \n\n      emb15     emb16     emb17     emb18     emb19      ent0      ent1  \\\n0  1.209454 -0.240832 -0.318214 -0.766078  1.029494  0.176839  0.030176   \n1 -0.200018 -0.240832 -0.318214  2.669607  1.029494  0.169469  0.010807   \n2  1.209454 -0.240832 -0.318214 -0.766078  1.029494  0.050021  0.144598   \n3  1.209454 -0.240832 -0.318214  2.669607  1.029494  0.009481  0.179083   \n4  1.209454 -0.240832 -0.318214 -0.766078  1.029494  0.195881  0.097763   \n\n       ent2      ent3      ent4      ent5      ent6      ent7      ent8  \\\n0 -0.035038  0.001003  0.052116 -0.187229 -0.027397  0.005489 -0.011326   \n1 -0.027873 -0.005639 -0.049348 -0.275070 -0.050310  0.009976 -0.120855   \n2 -0.021119 -0.044309  0.000090 -0.034269 -0.014296  0.026448 -0.005892   \n3  0.032318  0.030371  0.036187 -0.038786 -0.066376  0.123849  0.132462   \n4 -0.118332 -0.078144 -0.050602 -0.082269 -0.111411 -0.039720 -0.044915   \n\n       ent9      dsc0      dsc1      dsc2      dsc3      dsc4      dsc5  \\\n0  0.048244  0.105987  0.027280 -0.004783  0.074602 -0.014915 -0.067790   \n1  0.138065  0.009274  0.073463  0.018525  0.065817 -0.013243 -0.008018   \n2  0.068137 -0.017787  0.136258  0.008309 -0.000720  0.015918 -0.005078   \n3 -0.063814 -0.004053  0.127969  0.002579  0.038071 -0.032156 -0.042941   \n4  0.032023 -0.056793  0.111835  0.022229  0.016954 -0.013878 -0.046586   \n\n       dsc6      dsc7      dsc8      dsc9  \n0 -0.018780  0.060114  0.069678  0.062767  \n1 -0.053914  0.055421  0.076891  0.096301  \n2 -0.093464  0.026340 -0.063265 -0.046079  \n3 -0.081394  0.057888 -0.037198  0.028467  \n4 -0.085140  0.015938 -0.058317  0.026717  \n\n[5 rows x 258 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Fee</th>\n      <th>VideoAmt</th>\n      <th>PhotoAmt</th>\n      <th>magnitude_sum</th>\n      <th>magnitude_mean</th>\n      <th>magnitude_var</th>\n      <th>score_sum</th>\n      <th>score_mean</th>\n      <th>score_var</th>\n      <th>document_magnitude</th>\n      <th>document_score</th>\n      <th>annot_score_SUM</th>\n      <th>annot_score_MEAN</th>\n      <th>annot_score_VAR</th>\n      <th>color_score_SUM</th>\n      <th>color_score_MEAN</th>\n      <th>color_score_VAR</th>\n      <th>pixel_frac_SUM</th>\n      <th>pixel_frac_MEAN</th>\n      <th>pixel_frac_VAR</th>\n      <th>crop_conf_SUM</th>\n      <th>crop_conf_MEAN</th>\n      <th>crop_conf_VAR</th>\n      <th>crop_importance_SUM</th>\n      <th>crop_importance_MEAN</th>\n      <th>crop_importance_VAR</th>\n      <th>specified_SUM</th>\n      <th>specified_MEAN</th>\n      <th>specified_VAR</th>\n      <th>main_breed_Type</th>\n      <th>second_breed_Type</th>\n      <th>len_description</th>\n      <th>len_meta_desc</th>\n      <th>len_entity</th>\n      <th>num_description_words</th>\n      <th>num_desc_words</th>\n      <th>num_entity_words</th>\n      <th>uniq_description_words</th>\n      <th>uniq_desc_words</th>\n      <th>uniq_entity_words</th>\n      <th>num_description_stopwords</th>\n      <th>num_desc_stopwords</th>\n      <th>num_entity_stopwords</th>\n      <th>num_description_punctuation</th>\n      <th>state_gdp</th>\n      <th>state_population</th>\n      <th>state_area</th>\n      <th>state_gdp_per_person</th>\n      <th>fee_per_gdp_per_person</th>\n      <th>num_name_words</th>\n      <th>contains_amp</th>\n      <th>contains_comma</th>\n      <th>start_with_number</th>\n      <th>contains_paren</th>\n      <th>contains_number</th>\n      <th>name_length</th>\n      <th>num_unlike_letters</th>\n      <th>rate_unlike_letters</th>\n      <th>Tfidf_Description_0</th>\n      <th>Tfidf_Description_1</th>\n      <th>Tfidf_Description_2</th>\n      <th>Tfidf_Description_3</th>\n      <th>Tfidf_Description_4</th>\n      <th>...</th>\n      <th>img24</th>\n      <th>img25</th>\n      <th>img26</th>\n      <th>img27</th>\n      <th>img28</th>\n      <th>img29</th>\n      <th>img30</th>\n      <th>img31</th>\n      <th>img32</th>\n      <th>img33</th>\n      <th>img34</th>\n      <th>img35</th>\n      <th>img36</th>\n      <th>img37</th>\n      <th>img38</th>\n      <th>img39</th>\n      <th>img40</th>\n      <th>img41</th>\n      <th>img42</th>\n      <th>img43</th>\n      <th>img44</th>\n      <th>img45</th>\n      <th>img46</th>\n      <th>img47</th>\n      <th>emb0</th>\n      <th>emb1</th>\n      <th>emb2</th>\n      <th>emb3</th>\n      <th>emb4</th>\n      <th>emb5</th>\n      <th>emb6</th>\n      <th>emb7</th>\n      <th>emb8</th>\n      <th>emb9</th>\n      <th>emb10</th>\n      <th>emb11</th>\n      <th>emb12</th>\n      <th>emb13</th>\n      <th>emb14</th>\n      <th>emb15</th>\n      <th>emb16</th>\n      <th>emb17</th>\n      <th>emb18</th>\n      <th>emb19</th>\n      <th>ent0</th>\n      <th>ent1</th>\n      <th>ent2</th>\n      <th>ent3</th>\n      <th>ent4</th>\n      <th>ent5</th>\n      <th>ent6</th>\n      <th>ent7</th>\n      <th>ent8</th>\n      <th>ent9</th>\n      <th>dsc0</th>\n      <th>dsc1</th>\n      <th>dsc2</th>\n      <th>dsc3</th>\n      <th>dsc4</th>\n      <th>dsc5</th>\n      <th>dsc6</th>\n      <th>dsc7</th>\n      <th>dsc8</th>\n      <th>dsc9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.421104</td>\n      <td>0.960767</td>\n      <td>-0.162959</td>\n      <td>-0.816674</td>\n      <td>0.175573</td>\n      <td>-0.089689</td>\n      <td>0.720044</td>\n      <td>0.392032</td>\n      <td>0.057521</td>\n      <td>0.376737</td>\n      <td>0.161785</td>\n      <td>0.099729</td>\n      <td>-0.798692</td>\n      <td>0.532229</td>\n      <td>-0.618650</td>\n      <td>-0.842711</td>\n      <td>-0.520689</td>\n      <td>-0.063222</td>\n      <td>-0.779326</td>\n      <td>0.057136</td>\n      <td>-0.163850</td>\n      <td>-0.817486</td>\n      <td>0.138982</td>\n      <td>-0.137805</td>\n      <td>-0.817133</td>\n      <td>0.139028</td>\n      <td>-0.042402</td>\n      <td>-0.813932</td>\n      <td>0.220208</td>\n      <td>-0.18826</td>\n      <td>1.05936</td>\n      <td>-0.562268</td>\n      <td>0.482345</td>\n      <td>-0.970235</td>\n      <td>0.500955</td>\n      <td>0.519078</td>\n      <td>-1.027484</td>\n      <td>0.443748</td>\n      <td>0.539772</td>\n      <td>-0.266118</td>\n      <td>0.453230</td>\n      <td>0.669926</td>\n      <td>-0.021144</td>\n      <td>-0.357513</td>\n      <td>0.083495</td>\n      <td>0.642057</td>\n      <td>0.837369</td>\n      <td>0.620169</td>\n      <td>-0.414149</td>\n      <td>0.866557</td>\n      <td>-0.499373</td>\n      <td>-0.320762</td>\n      <td>-0.154216</td>\n      <td>-0.147911</td>\n      <td>-0.188211</td>\n      <td>-0.290496</td>\n      <td>-0.391155</td>\n      <td>-0.323289</td>\n      <td>-0.313549</td>\n      <td>0.044744</td>\n      <td>-0.233591</td>\n      <td>-0.294805</td>\n      <td>-0.151926</td>\n      <td>-0.270423</td>\n      <td>...</td>\n      <td>1.230090</td>\n      <td>1.056767</td>\n      <td>-0.403665</td>\n      <td>1.106224</td>\n      <td>0.096388</td>\n      <td>1.556007</td>\n      <td>-0.848707</td>\n      <td>0.224280</td>\n      <td>-3.398524</td>\n      <td>0.857789</td>\n      <td>-0.167985</td>\n      <td>-0.397752</td>\n      <td>-3.545173</td>\n      <td>-0.916391</td>\n      <td>0.599372</td>\n      <td>-0.187137</td>\n      <td>-1.365577</td>\n      <td>-2.507689</td>\n      <td>0.546872</td>\n      <td>0.475532</td>\n      <td>-1.821823</td>\n      <td>0.759485</td>\n      <td>-0.163166</td>\n      <td>1.413023</td>\n      <td>0.069553</td>\n      <td>-0.844969</td>\n      <td>0.508286</td>\n      <td>-1.416741</td>\n      <td>-0.831533</td>\n      <td>0.827695</td>\n      <td>1.204345</td>\n      <td>-0.663034</td>\n      <td>0.670370</td>\n      <td>1.081997</td>\n      <td>-0.449266</td>\n      <td>0.195283</td>\n      <td>-1.474584</td>\n      <td>-0.755869</td>\n      <td>0.219763</td>\n      <td>1.209454</td>\n      <td>-0.240832</td>\n      <td>-0.318214</td>\n      <td>-0.766078</td>\n      <td>1.029494</td>\n      <td>0.176839</td>\n      <td>0.030176</td>\n      <td>-0.035038</td>\n      <td>0.001003</td>\n      <td>0.052116</td>\n      <td>-0.187229</td>\n      <td>-0.027397</td>\n      <td>0.005489</td>\n      <td>-0.011326</td>\n      <td>0.048244</td>\n      <td>0.105987</td>\n      <td>0.027280</td>\n      <td>-0.004783</td>\n      <td>0.074602</td>\n      <td>-0.014915</td>\n      <td>-0.067790</td>\n      <td>-0.018780</td>\n      <td>0.060114</td>\n      <td>0.069678</td>\n      <td>0.062767</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.530710</td>\n      <td>-0.279390</td>\n      <td>-0.162959</td>\n      <td>-0.532377</td>\n      <td>-0.648924</td>\n      <td>-0.163610</td>\n      <td>-0.031676</td>\n      <td>-1.250631</td>\n      <td>-1.939791</td>\n      <td>0.140569</td>\n      <td>-0.676014</td>\n      <td>-1.701005</td>\n      <td>-0.522569</td>\n      <td>0.253078</td>\n      <td>-0.552837</td>\n      <td>-0.489244</td>\n      <td>0.448827</td>\n      <td>-0.037801</td>\n      <td>-0.532728</td>\n      <td>-0.071330</td>\n      <td>-0.139008</td>\n      <td>-0.533878</td>\n      <td>0.138982</td>\n      <td>-0.137805</td>\n      <td>-0.533092</td>\n      <td>0.139028</td>\n      <td>-0.042402</td>\n      <td>-0.524526</td>\n      <td>0.220208</td>\n      <td>-0.18826</td>\n      <td>1.05936</td>\n      <td>-0.562268</td>\n      <td>-0.544292</td>\n      <td>-0.327012</td>\n      <td>-0.978440</td>\n      <td>-0.506754</td>\n      <td>-0.314407</td>\n      <td>-1.243792</td>\n      <td>-0.542146</td>\n      <td>0.253030</td>\n      <td>-1.234661</td>\n      <td>-0.155182</td>\n      <td>0.482987</td>\n      <td>-0.357513</td>\n      <td>-1.032706</td>\n      <td>-0.122787</td>\n      <td>-1.155849</td>\n      <td>-1.532409</td>\n      <td>1.527495</td>\n      <td>-0.229461</td>\n      <td>0.967877</td>\n      <td>-0.320762</td>\n      <td>-0.154216</td>\n      <td>-0.147911</td>\n      <td>-0.188211</td>\n      <td>-0.290496</td>\n      <td>0.289119</td>\n      <td>-0.323289</td>\n      <td>-0.313549</td>\n      <td>-0.701180</td>\n      <td>-0.112283</td>\n      <td>-0.185616</td>\n      <td>-0.087399</td>\n      <td>-0.108876</td>\n      <td>...</td>\n      <td>1.341369</td>\n      <td>1.500666</td>\n      <td>-1.049592</td>\n      <td>1.269030</td>\n      <td>-0.071501</td>\n      <td>1.327432</td>\n      <td>-0.891723</td>\n      <td>1.284225</td>\n      <td>-4.005236</td>\n      <td>1.059146</td>\n      <td>-0.553956</td>\n      <td>0.564387</td>\n      <td>-4.653399</td>\n      <td>-1.162407</td>\n      <td>1.164328</td>\n      <td>-0.568253</td>\n      <td>-1.356671</td>\n      <td>-3.293017</td>\n      <td>0.985037</td>\n      <td>1.320855</td>\n      <td>-1.992518</td>\n      <td>1.044078</td>\n      <td>0.064549</td>\n      <td>1.250380</td>\n      <td>0.069553</td>\n      <td>0.591301</td>\n      <td>-0.392345</td>\n      <td>1.509525</td>\n      <td>-0.831533</td>\n      <td>0.827695</td>\n      <td>1.204345</td>\n      <td>-0.663034</td>\n      <td>0.670370</td>\n      <td>1.987546</td>\n      <td>-0.449266</td>\n      <td>-0.148951</td>\n      <td>1.518030</td>\n      <td>-0.268800</td>\n      <td>-0.043801</td>\n      <td>-0.200018</td>\n      <td>-0.240832</td>\n      <td>-0.318214</td>\n      <td>2.669607</td>\n      <td>1.029494</td>\n      <td>0.169469</td>\n      <td>0.010807</td>\n      <td>-0.027873</td>\n      <td>-0.005639</td>\n      <td>-0.049348</td>\n      <td>-0.275070</td>\n      <td>-0.050310</td>\n      <td>0.009976</td>\n      <td>-0.120855</td>\n      <td>0.138065</td>\n      <td>0.009274</td>\n      <td>0.073463</td>\n      <td>0.018525</td>\n      <td>0.065817</td>\n      <td>-0.013243</td>\n      <td>-0.008018</td>\n      <td>-0.053914</td>\n      <td>0.055421</td>\n      <td>0.076891</td>\n      <td>0.096301</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.530710</td>\n      <td>-0.279390</td>\n      <td>-0.162959</td>\n      <td>0.889111</td>\n      <td>0.835170</td>\n      <td>0.438317</td>\n      <td>1.133721</td>\n      <td>0.106352</td>\n      <td>-0.305627</td>\n      <td>2.070637</td>\n      <td>0.802455</td>\n      <td>-0.260418</td>\n      <td>0.905726</td>\n      <td>0.201793</td>\n      <td>-0.041704</td>\n      <td>1.062379</td>\n      <td>0.597325</td>\n      <td>-0.036040</td>\n      <td>1.031460</td>\n      <td>0.404513</td>\n      <td>0.123483</td>\n      <td>0.884162</td>\n      <td>0.138982</td>\n      <td>-0.137805</td>\n      <td>0.887115</td>\n      <td>0.139028</td>\n      <td>-0.042402</td>\n      <td>0.922507</td>\n      <td>0.220208</td>\n      <td>-0.18826</td>\n      <td>-0.94197</td>\n      <td>-0.562268</td>\n      <td>0.566042</td>\n      <td>1.064897</td>\n      <td>0.609698</td>\n      <td>0.519078</td>\n      <td>1.102149</td>\n      <td>0.590031</td>\n      <td>0.593479</td>\n      <td>0.510427</td>\n      <td>0.617952</td>\n      <td>0.568819</td>\n      <td>-0.882961</td>\n      <td>-0.357513</td>\n      <td>0.190543</td>\n      <td>0.642057</td>\n      <td>0.837369</td>\n      <td>0.620169</td>\n      <td>-0.414149</td>\n      <td>-0.229461</td>\n      <td>-0.499373</td>\n      <td>-0.320762</td>\n      <td>-0.154216</td>\n      <td>-0.147911</td>\n      <td>-0.188211</td>\n      <td>-0.290496</td>\n      <td>-0.391155</td>\n      <td>-0.323289</td>\n      <td>-0.313549</td>\n      <td>0.308158</td>\n      <td>-0.293496</td>\n      <td>0.889665</td>\n      <td>-0.106772</td>\n      <td>0.448940</td>\n      <td>...</td>\n      <td>1.870255</td>\n      <td>2.687016</td>\n      <td>-1.305590</td>\n      <td>0.844590</td>\n      <td>-0.206637</td>\n      <td>1.519087</td>\n      <td>-2.179879</td>\n      <td>0.798290</td>\n      <td>-4.847266</td>\n      <td>0.724858</td>\n      <td>-0.536026</td>\n      <td>1.163803</td>\n      <td>-7.355669</td>\n      <td>-1.725377</td>\n      <td>1.048077</td>\n      <td>0.049122</td>\n      <td>-3.023522</td>\n      <td>-4.714112</td>\n      <td>1.180708</td>\n      <td>1.768260</td>\n      <td>-4.127668</td>\n      <td>3.099615</td>\n      <td>0.795191</td>\n      <td>1.659834</td>\n      <td>0.474235</td>\n      <td>-0.308725</td>\n      <td>0.306153</td>\n      <td>1.154131</td>\n      <td>-0.831533</td>\n      <td>0.827695</td>\n      <td>1.204345</td>\n      <td>-0.663034</td>\n      <td>1.413041</td>\n      <td>1.081997</td>\n      <td>-0.449266</td>\n      <td>-0.148951</td>\n      <td>1.518030</td>\n      <td>-1.894602</td>\n      <td>-0.526782</td>\n      <td>1.209454</td>\n      <td>-0.240832</td>\n      <td>-0.318214</td>\n      <td>-0.766078</td>\n      <td>1.029494</td>\n      <td>0.050021</td>\n      <td>0.144598</td>\n      <td>-0.021119</td>\n      <td>-0.044309</td>\n      <td>0.000090</td>\n      <td>-0.034269</td>\n      <td>-0.014296</td>\n      <td>0.026448</td>\n      <td>-0.005892</td>\n      <td>0.068137</td>\n      <td>-0.017787</td>\n      <td>0.136258</td>\n      <td>0.008309</td>\n      <td>-0.000720</td>\n      <td>0.015918</td>\n      <td>-0.005078</td>\n      <td>-0.093464</td>\n      <td>0.026340</td>\n      <td>-0.063265</td>\n      <td>-0.046079</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.366301</td>\n      <td>1.580845</td>\n      <td>-0.162959</td>\n      <td>1.173408</td>\n      <td>-0.538991</td>\n      <td>2.275777</td>\n      <td>-1.214452</td>\n      <td>-0.250749</td>\n      <td>2.236407</td>\n      <td>-1.056562</td>\n      <td>-0.577449</td>\n      <td>2.260610</td>\n      <td>1.095797</td>\n      <td>-0.060583</td>\n      <td>-0.496847</td>\n      <td>1.063514</td>\n      <td>-0.077532</td>\n      <td>0.120986</td>\n      <td>1.168248</td>\n      <td>0.164305</td>\n      <td>0.199442</td>\n      <td>1.167770</td>\n      <td>0.138982</td>\n      <td>-0.137805</td>\n      <td>1.171157</td>\n      <td>0.139028</td>\n      <td>-0.042402</td>\n      <td>1.211914</td>\n      <td>0.220208</td>\n      <td>-0.18826</td>\n      <td>-0.94197</td>\n      <td>-0.562268</td>\n      <td>-0.348319</td>\n      <td>1.092567</td>\n      <td>-0.072772</td>\n      <td>-0.430047</td>\n      <td>1.150112</td>\n      <td>-0.169305</td>\n      <td>-0.356466</td>\n      <td>0.253030</td>\n      <td>-0.105635</td>\n      <td>-0.461536</td>\n      <td>-0.882961</td>\n      <td>-0.357513</td>\n      <td>-0.036174</td>\n      <td>-0.122787</td>\n      <td>-1.155849</td>\n      <td>-1.532409</td>\n      <td>1.527495</td>\n      <td>0.514889</td>\n      <td>-0.499373</td>\n      <td>-0.320762</td>\n      <td>-0.154216</td>\n      <td>-0.147911</td>\n      <td>-0.188211</td>\n      <td>-0.290496</td>\n      <td>-0.663264</td>\n      <td>-0.323289</td>\n      <td>-0.313549</td>\n      <td>-0.431990</td>\n      <td>0.094940</td>\n      <td>0.036552</td>\n      <td>0.174450</td>\n      <td>0.179728</td>\n      <td>...</td>\n      <td>3.076942</td>\n      <td>2.515201</td>\n      <td>-1.821304</td>\n      <td>1.635721</td>\n      <td>0.145540</td>\n      <td>3.523111</td>\n      <td>-1.485916</td>\n      <td>0.318308</td>\n      <td>-4.195776</td>\n      <td>1.051438</td>\n      <td>0.223658</td>\n      <td>1.014659</td>\n      <td>-8.322213</td>\n      <td>-1.678787</td>\n      <td>0.642676</td>\n      <td>-0.352061</td>\n      <td>-2.542596</td>\n      <td>-5.023290</td>\n      <td>2.166600</td>\n      <td>0.604448</td>\n      <td>-5.354814</td>\n      <td>1.882512</td>\n      <td>0.037363</td>\n      <td>2.774812</td>\n      <td>0.474235</td>\n      <td>-0.308725</td>\n      <td>0.306153</td>\n      <td>1.154131</td>\n      <td>-0.831533</td>\n      <td>0.827695</td>\n      <td>1.204345</td>\n      <td>-0.547322</td>\n      <td>0.670370</td>\n      <td>1.987546</td>\n      <td>-0.449266</td>\n      <td>-0.148951</td>\n      <td>-1.474584</td>\n      <td>-1.894602</td>\n      <td>-0.526782</td>\n      <td>1.209454</td>\n      <td>-0.240832</td>\n      <td>-0.318214</td>\n      <td>2.669607</td>\n      <td>1.029494</td>\n      <td>0.009481</td>\n      <td>0.179083</td>\n      <td>0.032318</td>\n      <td>0.030371</td>\n      <td>0.036187</td>\n      <td>-0.038786</td>\n      <td>-0.066376</td>\n      <td>0.123849</td>\n      <td>0.132462</td>\n      <td>-0.063814</td>\n      <td>-0.004053</td>\n      <td>0.127969</td>\n      <td>0.002579</td>\n      <td>0.038071</td>\n      <td>-0.032156</td>\n      <td>-0.042941</td>\n      <td>-0.081394</td>\n      <td>0.057888</td>\n      <td>-0.037198</td>\n      <td>0.028467</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.530710</td>\n      <td>-0.279390</td>\n      <td>-0.162959</td>\n      <td>-0.248079</td>\n      <td>0.890136</td>\n      <td>0.871281</td>\n      <td>0.136541</td>\n      <td>1.606175</td>\n      <td>1.086440</td>\n      <td>-0.358914</td>\n      <td>0.802455</td>\n      <td>1.180169</td>\n      <td>-0.255537</td>\n      <td>0.094133</td>\n      <td>5.585148</td>\n      <td>-0.307276</td>\n      <td>-0.237184</td>\n      <td>-0.013624</td>\n      <td>-0.529883</td>\n      <td>-1.088897</td>\n      <td>-0.153880</td>\n      <td>-0.250270</td>\n      <td>0.138982</td>\n      <td>-0.137805</td>\n      <td>-0.254731</td>\n      <td>0.098731</td>\n      <td>-0.041352</td>\n      <td>-0.235119</td>\n      <td>0.220208</td>\n      <td>-0.18826</td>\n      <td>-0.94197</td>\n      <td>-0.562268</td>\n      <td>0.558953</td>\n      <td>0.058157</td>\n      <td>0.409054</td>\n      <td>0.670708</td>\n      <td>-0.009517</td>\n      <td>0.443748</td>\n      <td>0.677378</td>\n      <td>0.061120</td>\n      <td>0.538535</td>\n      <td>0.841422</td>\n      <td>-0.882961</td>\n      <td>-0.357513</td>\n      <td>0.190543</td>\n      <td>0.642057</td>\n      <td>0.837369</td>\n      <td>0.620169</td>\n      <td>-0.414149</td>\n      <td>-0.229461</td>\n      <td>-0.499373</td>\n      <td>-0.320762</td>\n      <td>-0.154216</td>\n      <td>-0.147911</td>\n      <td>-0.188211</td>\n      <td>-0.290496</td>\n      <td>-0.391155</td>\n      <td>-0.323289</td>\n      <td>-0.313549</td>\n      <td>1.418634</td>\n      <td>-0.141192</td>\n      <td>-0.081388</td>\n      <td>-0.214699</td>\n      <td>-0.241654</td>\n      <td>...</td>\n      <td>1.862627</td>\n      <td>2.129172</td>\n      <td>-1.850668</td>\n      <td>1.173814</td>\n      <td>-0.381908</td>\n      <td>2.133727</td>\n      <td>-1.585165</td>\n      <td>0.725314</td>\n      <td>-4.943785</td>\n      <td>0.924910</td>\n      <td>-0.557188</td>\n      <td>0.781747</td>\n      <td>-6.047087</td>\n      <td>-0.984050</td>\n      <td>0.611377</td>\n      <td>-0.838628</td>\n      <td>-2.316990</td>\n      <td>-4.628384</td>\n      <td>1.059011</td>\n      <td>1.744222</td>\n      <td>-3.782774</td>\n      <td>2.087450</td>\n      <td>0.691992</td>\n      <td>1.934122</td>\n      <td>0.474235</td>\n      <td>-0.308725</td>\n      <td>0.306153</td>\n      <td>1.154131</td>\n      <td>-0.831533</td>\n      <td>0.827695</td>\n      <td>1.204345</td>\n      <td>-0.663034</td>\n      <td>0.670370</td>\n      <td>-0.638341</td>\n      <td>-0.449266</td>\n      <td>-0.148951</td>\n      <td>-1.474584</td>\n      <td>-0.755869</td>\n      <td>0.219763</td>\n      <td>1.209454</td>\n      <td>-0.240832</td>\n      <td>-0.318214</td>\n      <td>-0.766078</td>\n      <td>1.029494</td>\n      <td>0.195881</td>\n      <td>0.097763</td>\n      <td>-0.118332</td>\n      <td>-0.078144</td>\n      <td>-0.050602</td>\n      <td>-0.082269</td>\n      <td>-0.111411</td>\n      <td>-0.039720</td>\n      <td>-0.044915</td>\n      <td>0.032023</td>\n      <td>-0.056793</td>\n      <td>0.111835</td>\n      <td>0.022229</td>\n      <td>0.016954</td>\n      <td>-0.013878</td>\n      <td>-0.046586</td>\n      <td>-0.085140</td>\n      <td>0.015938</td>\n      <td>-0.058317</td>\n      <td>0.026717</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 258 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Sequences"},{"metadata":{"trusted":true},"cell_type":"code","source":"class SeqDataset(data.Dataset):\n    def __init__(self, seq):\n        self.seq = seq\n        \n    def __len__(self):\n        return len(self.seq)\n    \n    def __getitem__(self, idx):\n        seq = self.seq[idx, :]\n        return [seq]","execution_count":96,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s_train = torch.tensor(x_train_text, dtype=torch.long).to(\"cuda:0\")\ns_test = torch.tensor(x_test_text, dtype=torch.long).to(\"cuda:0\")\ntrain_dataset = SeqDataset(s_train)\ntest_dataset = SeqDataset(s_test)\ntrain_loader = data.DataLoader(train_dataset, batch_size=128, shuffle=False)\ntest_loader = data.DataLoader(test_dataset, batch_size=128, shuffle=False)\n\nX_train_seq = np.zeros((len(train_pet_ids), 20))\nX_test_seq = np.zeros((len(test_pet_ids), 20))\nbin_path = trainer.path\nfor path in bin_path.iterdir():\n    model = NeuralNet(**trainer.kwargs)\n    model.to(\"cuda:0\")\n    model.load_state_dict(torch.load(path))\n    model.eval()\n    temp = np.zeros((len(train_pet_ids), 20))\n    for i, (s_batch, ) in tqdm(enumerate(train_loader), ascii=True):\n        with torch.no_grad():\n            h_emb = model.seq_emb(s_batch)\n            h_emb = torch.squeeze(model.seq_emb_dropout(torch.unsqueeze(h_emb, 0)))\n            h_lstm, _ = model.lstm(h_emb)\n            h_attn = model.attn(h_lstm)\n            y_pred = model.seq_lin(h_attn).detach()\n            temp[i * 128:(i + 1) * 128, :] = y_pred.cpu().numpy()\n    X_train_seq += temp / trainer.n_splits\n    temp = np.zeros((len(test_pet_ids), 20))\n    for i, (s_batch, ) in tqdm(enumerate(test_loader), ascii=True):\n        with torch.no_grad():\n            h_emb = model.seq_emb(s_batch)\n            h_emb = torch.squeeze(model.seq_emb_dropout(torch.unsqueeze(h_emb, 0)))\n            h_lstm, _ = model.lstm(h_emb)\n            h_attn = model.attn(h_lstm)\n            y_pred = model.seq_lin(h_attn).detach()\n            temp[i * 128:(i + 1) * 128, :] = y_pred.cpu().numpy()\n    X_test_seq += temp / trainer.n_splits","execution_count":97,"outputs":[{"output_type":"stream","text":"118it [00:00, 319.24it/s]\n31it [00:00, 302.54it/s]\n118it [00:00, 316.65it/s]\n31it [00:00, 306.18it/s]\n118it [00:00, 314.78it/s]\n31it [00:00, 319.24it/s]\n118it [00:00, 316.94it/s]\n31it [00:00, 323.42it/s]\n118it [00:00, 311.97it/s]\n31it [00:00, 318.17it/s]\n118it [00:00, 316.13it/s]\n31it [00:00, 320.28it/s]\n118it [00:00, 314.96it/s]\n31it [00:00, 315.49it/s]\n118it [00:00, 314.61it/s]\n31it [00:00, 323.34it/s]\n118it [00:00, 314.99it/s]\n31it [00:00, 319.21it/s]\n118it [00:00, 315.17it/s]\n31it [00:00, 321.74it/s]\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_seq.shape, X_test_seq.shape","execution_count":98,"outputs":[{"output_type":"execute_result","execution_count":98,"data":{"text/plain":"((14993, 20), (3948, 20))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_seq = pd.DataFrame(data=X_train_seq, columns=[\n    f\"seq{i}\" for i in range(X_train_seq.shape[1])\n])\ntest_seq = pd.DataFrame(data=X_test_seq, columns=[\n    f\"seq{i}\" for i in range(X_test_seq.shape[1])\n])\ntest_seq.index = X_test_all.index\n\nX_train_all = pd.concat([X_train_all, train_seq], axis=1)\nX_test_all = pd.concat([X_test_all, test_seq], axis=1)\n\nprint(X_train_all.shape, X_test_all.shape)\nX_train_all.head()","execution_count":99,"outputs":[{"output_type":"stream","text":"(14993, 278) (3948, 278)\n","name":"stdout"},{"output_type":"execute_result","execution_count":99,"data":{"text/plain":"        Age       Fee  VideoAmt  PhotoAmt  magnitude_sum  magnitude_mean  \\\n0 -0.421104  0.960767 -0.162959 -0.816674       0.175573       -0.089689   \n1 -0.530710 -0.279390 -0.162959 -0.532377      -0.648924       -0.163610   \n2 -0.530710 -0.279390 -0.162959  0.889111       0.835170        0.438317   \n3 -0.366301  1.580845 -0.162959  1.173408      -0.538991        2.275777   \n4 -0.530710 -0.279390 -0.162959 -0.248079       0.890136        0.871281   \n\n   magnitude_var  score_sum  score_mean  score_var  document_magnitude  \\\n0       0.720044   0.392032    0.057521   0.376737            0.161785   \n1      -0.031676  -1.250631   -1.939791   0.140569           -0.676014   \n2       1.133721   0.106352   -0.305627   2.070637            0.802455   \n3      -1.214452  -0.250749    2.236407  -1.056562           -0.577449   \n4       0.136541   1.606175    1.086440  -0.358914            0.802455   \n\n   document_score  annot_score_SUM  annot_score_MEAN  annot_score_VAR  \\\n0        0.099729        -0.798692          0.532229        -0.618650   \n1       -1.701005        -0.522569          0.253078        -0.552837   \n2       -0.260418         0.905726          0.201793        -0.041704   \n3        2.260610         1.095797         -0.060583        -0.496847   \n4        1.180169        -0.255537          0.094133         5.585148   \n\n   color_score_SUM  color_score_MEAN  color_score_VAR  pixel_frac_SUM  \\\n0        -0.842711         -0.520689        -0.063222       -0.779326   \n1        -0.489244          0.448827        -0.037801       -0.532728   \n2         1.062379          0.597325        -0.036040        1.031460   \n3         1.063514         -0.077532         0.120986        1.168248   \n4        -0.307276         -0.237184        -0.013624       -0.529883   \n\n   pixel_frac_MEAN  pixel_frac_VAR  crop_conf_SUM  crop_conf_MEAN  \\\n0         0.057136       -0.163850      -0.817486        0.138982   \n1        -0.071330       -0.139008      -0.533878        0.138982   \n2         0.404513        0.123483       0.884162        0.138982   \n3         0.164305        0.199442       1.167770        0.138982   \n4        -1.088897       -0.153880      -0.250270        0.138982   \n\n   crop_conf_VAR  crop_importance_SUM  crop_importance_MEAN  \\\n0      -0.137805            -0.817133              0.139028   \n1      -0.137805            -0.533092              0.139028   \n2      -0.137805             0.887115              0.139028   \n3      -0.137805             1.171157              0.139028   \n4      -0.137805            -0.254731              0.098731   \n\n   crop_importance_VAR  specified_SUM  specified_MEAN  specified_VAR  \\\n0            -0.042402      -0.813932        0.220208       -0.18826   \n1            -0.042402      -0.524526        0.220208       -0.18826   \n2            -0.042402       0.922507        0.220208       -0.18826   \n3            -0.042402       1.211914        0.220208       -0.18826   \n4            -0.041352      -0.235119        0.220208       -0.18826   \n\n   main_breed_Type  second_breed_Type  len_description  len_meta_desc  \\\n0          1.05936          -0.562268         0.482345      -0.970235   \n1          1.05936          -0.562268        -0.544292      -0.327012   \n2         -0.94197          -0.562268         0.566042       1.064897   \n3         -0.94197          -0.562268        -0.348319       1.092567   \n4         -0.94197          -0.562268         0.558953       0.058157   \n\n   len_entity  num_description_words  num_desc_words  num_entity_words  \\\n0    0.500955               0.519078       -1.027484          0.443748   \n1   -0.978440              -0.506754       -0.314407         -1.243792   \n2    0.609698               0.519078        1.102149          0.590031   \n3   -0.072772              -0.430047        1.150112         -0.169305   \n4    0.409054               0.670708       -0.009517          0.443748   \n\n   uniq_description_words  uniq_desc_words  uniq_entity_words  \\\n0                0.539772        -0.266118           0.453230   \n1               -0.542146         0.253030          -1.234661   \n2                0.593479         0.510427           0.617952   \n3               -0.356466         0.253030          -0.105635   \n4                0.677378         0.061120           0.538535   \n\n   num_description_stopwords  num_desc_stopwords  num_entity_stopwords  \\\n0                   0.669926           -0.021144             -0.357513   \n1                  -0.155182            0.482987             -0.357513   \n2                   0.568819           -0.882961             -0.357513   \n3                  -0.461536           -0.882961             -0.357513   \n4                   0.841422           -0.882961             -0.357513   \n\n   num_description_punctuation  state_gdp  state_population  state_area  \\\n0                     0.083495   0.642057          0.837369    0.620169   \n1                    -1.032706  -0.122787         -1.155849   -1.532409   \n2                     0.190543   0.642057          0.837369    0.620169   \n3                    -0.036174  -0.122787         -1.155849   -1.532409   \n4                     0.190543   0.642057          0.837369    0.620169   \n\n   state_gdp_per_person  fee_per_gdp_per_person  num_name_words  contains_amp  \\\n0             -0.414149                0.866557       -0.499373     -0.320762   \n1              1.527495               -0.229461        0.967877     -0.320762   \n2             -0.414149               -0.229461       -0.499373     -0.320762   \n3              1.527495                0.514889       -0.499373     -0.320762   \n4             -0.414149               -0.229461       -0.499373     -0.320762   \n\n   contains_comma  start_with_number  contains_paren  contains_number  \\\n0       -0.154216          -0.147911       -0.188211        -0.290496   \n1       -0.154216          -0.147911       -0.188211        -0.290496   \n2       -0.154216          -0.147911       -0.188211        -0.290496   \n3       -0.154216          -0.147911       -0.188211        -0.290496   \n4       -0.154216          -0.147911       -0.188211        -0.290496   \n\n   name_length  num_unlike_letters  rate_unlike_letters  Tfidf_Description_0  \\\n0    -0.391155           -0.323289            -0.313549             0.044744   \n1     0.289119           -0.323289            -0.313549            -0.701180   \n2    -0.391155           -0.323289            -0.313549             0.308158   \n3    -0.663264           -0.323289            -0.313549            -0.431990   \n4    -0.391155           -0.323289            -0.313549             1.418634   \n\n   Tfidf_Description_1  Tfidf_Description_2  Tfidf_Description_3  \\\n0            -0.233591            -0.294805            -0.151926   \n1            -0.112283            -0.185616            -0.087399   \n2            -0.293496             0.889665            -0.106772   \n3             0.094940             0.036552             0.174450   \n4            -0.141192            -0.081388            -0.214699   \n\n   Tfidf_Description_4    ...        img44     img45     img46     img47  \\\n0            -0.270423    ...    -1.821823  0.759485 -0.163166  1.413023   \n1            -0.108876    ...    -1.992518  1.044078  0.064549  1.250380   \n2             0.448940    ...    -4.127668  3.099615  0.795191  1.659834   \n3             0.179728    ...    -5.354814  1.882512  0.037363  2.774812   \n4            -0.241654    ...    -3.782774  2.087450  0.691992  1.934122   \n\n       emb0      emb1      emb2      emb3      emb4      emb5      emb6  \\\n0  0.069553 -0.844969  0.508286 -1.416741 -0.831533  0.827695  1.204345   \n1  0.069553  0.591301 -0.392345  1.509525 -0.831533  0.827695  1.204345   \n2  0.474235 -0.308725  0.306153  1.154131 -0.831533  0.827695  1.204345   \n3  0.474235 -0.308725  0.306153  1.154131 -0.831533  0.827695  1.204345   \n4  0.474235 -0.308725  0.306153  1.154131 -0.831533  0.827695  1.204345   \n\n       emb7      emb8      emb9     emb10     emb11     emb12     emb13  \\\n0 -0.663034  0.670370  1.081997 -0.449266  0.195283 -1.474584 -0.755869   \n1 -0.663034  0.670370  1.987546 -0.449266 -0.148951  1.518030 -0.268800   \n2 -0.663034  1.413041  1.081997 -0.449266 -0.148951  1.518030 -1.894602   \n3 -0.547322  0.670370  1.987546 -0.449266 -0.148951 -1.474584 -1.894602   \n4 -0.663034  0.670370 -0.638341 -0.449266 -0.148951 -1.474584 -0.755869   \n\n      emb14     emb15     emb16     emb17     emb18     emb19      ent0  \\\n0  0.219763  1.209454 -0.240832 -0.318214 -0.766078  1.029494  0.176839   \n1 -0.043801 -0.200018 -0.240832 -0.318214  2.669607  1.029494  0.169469   \n2 -0.526782  1.209454 -0.240832 -0.318214 -0.766078  1.029494  0.050021   \n3 -0.526782  1.209454 -0.240832 -0.318214  2.669607  1.029494  0.009481   \n4  0.219763  1.209454 -0.240832 -0.318214 -0.766078  1.029494  0.195881   \n\n       ent1      ent2      ent3      ent4      ent5      ent6      ent7  \\\n0  0.030176 -0.035038  0.001003  0.052116 -0.187229 -0.027397  0.005489   \n1  0.010807 -0.027873 -0.005639 -0.049348 -0.275070 -0.050310  0.009976   \n2  0.144598 -0.021119 -0.044309  0.000090 -0.034269 -0.014296  0.026448   \n3  0.179083  0.032318  0.030371  0.036187 -0.038786 -0.066376  0.123849   \n4  0.097763 -0.118332 -0.078144 -0.050602 -0.082269 -0.111411 -0.039720   \n\n       ent8      ent9      dsc0      dsc1      dsc2      dsc3      dsc4  \\\n0 -0.011326  0.048244  0.105987  0.027280 -0.004783  0.074602 -0.014915   \n1 -0.120855  0.138065  0.009274  0.073463  0.018525  0.065817 -0.013243   \n2 -0.005892  0.068137 -0.017787  0.136258  0.008309 -0.000720  0.015918   \n3  0.132462 -0.063814 -0.004053  0.127969  0.002579  0.038071 -0.032156   \n4 -0.044915  0.032023 -0.056793  0.111835  0.022229  0.016954 -0.013878   \n\n       dsc5      dsc6      dsc7      dsc8      dsc9      seq0      seq1  \\\n0 -0.067790 -0.018780  0.060114  0.069678  0.062767 -2.168518 -0.311065   \n1 -0.008018 -0.053914  0.055421  0.076891  0.096301 -7.951627 -3.550912   \n2 -0.005078 -0.093464  0.026340 -0.063265 -0.046079 -2.413634 -0.327859   \n3 -0.042941 -0.081394  0.057888 -0.037198  0.028467 -7.970892 -3.385319   \n4 -0.046586 -0.085140  0.015938 -0.058317  0.026717 -2.295709 -0.399837   \n\n       seq2      seq3      seq4      seq5       seq6      seq7      seq8  \\\n0  0.391954 -0.578173 -2.535896 -2.098385   1.517624 -0.889011  0.224089   \n1  9.333297  0.643113  2.405863  2.890000  10.172862 -3.258524  4.301315   \n2  0.685184 -0.853473 -2.644093 -2.139606   2.015059 -0.572296  0.012945   \n3  8.849612  0.568138  2.356805  2.842386   9.902492 -2.887241  3.969924   \n4  0.189829 -0.809544 -2.577310 -2.234221   1.778084 -1.495117  0.582806   \n\n       seq9     seq10     seq11     seq12     seq13     seq14     seq15  \\\n0 -0.281497  0.246163  0.889898 -2.477707  0.765038  0.757161 -1.568563   \n1 -5.222942  0.675351  5.408667  1.203547  5.470937  7.356445  1.027114   \n2 -0.547410  0.393384  0.843605 -2.511670  0.801449  1.207108 -1.275904   \n3 -5.291786  0.863381  5.458267  0.871790  5.648135  6.975617  0.710852   \n4 -0.443059  0.456154  0.567814 -2.826626  0.671591  0.765171 -1.631040   \n\n      seq16     seq17     seq18     seq19  \n0  1.496201  0.030908  0.868219 -0.374659  \n1  3.015050 -0.570498 -1.481314 -0.705752  \n2  1.598204 -0.138238  0.894061 -1.080872  \n3  2.860918 -0.713143 -1.393507 -0.801889  \n4  1.464014  0.287459  0.753385 -0.155760  \n\n[5 rows x 278 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Fee</th>\n      <th>VideoAmt</th>\n      <th>PhotoAmt</th>\n      <th>magnitude_sum</th>\n      <th>magnitude_mean</th>\n      <th>magnitude_var</th>\n      <th>score_sum</th>\n      <th>score_mean</th>\n      <th>score_var</th>\n      <th>document_magnitude</th>\n      <th>document_score</th>\n      <th>annot_score_SUM</th>\n      <th>annot_score_MEAN</th>\n      <th>annot_score_VAR</th>\n      <th>color_score_SUM</th>\n      <th>color_score_MEAN</th>\n      <th>color_score_VAR</th>\n      <th>pixel_frac_SUM</th>\n      <th>pixel_frac_MEAN</th>\n      <th>pixel_frac_VAR</th>\n      <th>crop_conf_SUM</th>\n      <th>crop_conf_MEAN</th>\n      <th>crop_conf_VAR</th>\n      <th>crop_importance_SUM</th>\n      <th>crop_importance_MEAN</th>\n      <th>crop_importance_VAR</th>\n      <th>specified_SUM</th>\n      <th>specified_MEAN</th>\n      <th>specified_VAR</th>\n      <th>main_breed_Type</th>\n      <th>second_breed_Type</th>\n      <th>len_description</th>\n      <th>len_meta_desc</th>\n      <th>len_entity</th>\n      <th>num_description_words</th>\n      <th>num_desc_words</th>\n      <th>num_entity_words</th>\n      <th>uniq_description_words</th>\n      <th>uniq_desc_words</th>\n      <th>uniq_entity_words</th>\n      <th>num_description_stopwords</th>\n      <th>num_desc_stopwords</th>\n      <th>num_entity_stopwords</th>\n      <th>num_description_punctuation</th>\n      <th>state_gdp</th>\n      <th>state_population</th>\n      <th>state_area</th>\n      <th>state_gdp_per_person</th>\n      <th>fee_per_gdp_per_person</th>\n      <th>num_name_words</th>\n      <th>contains_amp</th>\n      <th>contains_comma</th>\n      <th>start_with_number</th>\n      <th>contains_paren</th>\n      <th>contains_number</th>\n      <th>name_length</th>\n      <th>num_unlike_letters</th>\n      <th>rate_unlike_letters</th>\n      <th>Tfidf_Description_0</th>\n      <th>Tfidf_Description_1</th>\n      <th>Tfidf_Description_2</th>\n      <th>Tfidf_Description_3</th>\n      <th>Tfidf_Description_4</th>\n      <th>...</th>\n      <th>img44</th>\n      <th>img45</th>\n      <th>img46</th>\n      <th>img47</th>\n      <th>emb0</th>\n      <th>emb1</th>\n      <th>emb2</th>\n      <th>emb3</th>\n      <th>emb4</th>\n      <th>emb5</th>\n      <th>emb6</th>\n      <th>emb7</th>\n      <th>emb8</th>\n      <th>emb9</th>\n      <th>emb10</th>\n      <th>emb11</th>\n      <th>emb12</th>\n      <th>emb13</th>\n      <th>emb14</th>\n      <th>emb15</th>\n      <th>emb16</th>\n      <th>emb17</th>\n      <th>emb18</th>\n      <th>emb19</th>\n      <th>ent0</th>\n      <th>ent1</th>\n      <th>ent2</th>\n      <th>ent3</th>\n      <th>ent4</th>\n      <th>ent5</th>\n      <th>ent6</th>\n      <th>ent7</th>\n      <th>ent8</th>\n      <th>ent9</th>\n      <th>dsc0</th>\n      <th>dsc1</th>\n      <th>dsc2</th>\n      <th>dsc3</th>\n      <th>dsc4</th>\n      <th>dsc5</th>\n      <th>dsc6</th>\n      <th>dsc7</th>\n      <th>dsc8</th>\n      <th>dsc9</th>\n      <th>seq0</th>\n      <th>seq1</th>\n      <th>seq2</th>\n      <th>seq3</th>\n      <th>seq4</th>\n      <th>seq5</th>\n      <th>seq6</th>\n      <th>seq7</th>\n      <th>seq8</th>\n      <th>seq9</th>\n      <th>seq10</th>\n      <th>seq11</th>\n      <th>seq12</th>\n      <th>seq13</th>\n      <th>seq14</th>\n      <th>seq15</th>\n      <th>seq16</th>\n      <th>seq17</th>\n      <th>seq18</th>\n      <th>seq19</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.421104</td>\n      <td>0.960767</td>\n      <td>-0.162959</td>\n      <td>-0.816674</td>\n      <td>0.175573</td>\n      <td>-0.089689</td>\n      <td>0.720044</td>\n      <td>0.392032</td>\n      <td>0.057521</td>\n      <td>0.376737</td>\n      <td>0.161785</td>\n      <td>0.099729</td>\n      <td>-0.798692</td>\n      <td>0.532229</td>\n      <td>-0.618650</td>\n      <td>-0.842711</td>\n      <td>-0.520689</td>\n      <td>-0.063222</td>\n      <td>-0.779326</td>\n      <td>0.057136</td>\n      <td>-0.163850</td>\n      <td>-0.817486</td>\n      <td>0.138982</td>\n      <td>-0.137805</td>\n      <td>-0.817133</td>\n      <td>0.139028</td>\n      <td>-0.042402</td>\n      <td>-0.813932</td>\n      <td>0.220208</td>\n      <td>-0.18826</td>\n      <td>1.05936</td>\n      <td>-0.562268</td>\n      <td>0.482345</td>\n      <td>-0.970235</td>\n      <td>0.500955</td>\n      <td>0.519078</td>\n      <td>-1.027484</td>\n      <td>0.443748</td>\n      <td>0.539772</td>\n      <td>-0.266118</td>\n      <td>0.453230</td>\n      <td>0.669926</td>\n      <td>-0.021144</td>\n      <td>-0.357513</td>\n      <td>0.083495</td>\n      <td>0.642057</td>\n      <td>0.837369</td>\n      <td>0.620169</td>\n      <td>-0.414149</td>\n      <td>0.866557</td>\n      <td>-0.499373</td>\n      <td>-0.320762</td>\n      <td>-0.154216</td>\n      <td>-0.147911</td>\n      <td>-0.188211</td>\n      <td>-0.290496</td>\n      <td>-0.391155</td>\n      <td>-0.323289</td>\n      <td>-0.313549</td>\n      <td>0.044744</td>\n      <td>-0.233591</td>\n      <td>-0.294805</td>\n      <td>-0.151926</td>\n      <td>-0.270423</td>\n      <td>...</td>\n      <td>-1.821823</td>\n      <td>0.759485</td>\n      <td>-0.163166</td>\n      <td>1.413023</td>\n      <td>0.069553</td>\n      <td>-0.844969</td>\n      <td>0.508286</td>\n      <td>-1.416741</td>\n      <td>-0.831533</td>\n      <td>0.827695</td>\n      <td>1.204345</td>\n      <td>-0.663034</td>\n      <td>0.670370</td>\n      <td>1.081997</td>\n      <td>-0.449266</td>\n      <td>0.195283</td>\n      <td>-1.474584</td>\n      <td>-0.755869</td>\n      <td>0.219763</td>\n      <td>1.209454</td>\n      <td>-0.240832</td>\n      <td>-0.318214</td>\n      <td>-0.766078</td>\n      <td>1.029494</td>\n      <td>0.176839</td>\n      <td>0.030176</td>\n      <td>-0.035038</td>\n      <td>0.001003</td>\n      <td>0.052116</td>\n      <td>-0.187229</td>\n      <td>-0.027397</td>\n      <td>0.005489</td>\n      <td>-0.011326</td>\n      <td>0.048244</td>\n      <td>0.105987</td>\n      <td>0.027280</td>\n      <td>-0.004783</td>\n      <td>0.074602</td>\n      <td>-0.014915</td>\n      <td>-0.067790</td>\n      <td>-0.018780</td>\n      <td>0.060114</td>\n      <td>0.069678</td>\n      <td>0.062767</td>\n      <td>-2.168518</td>\n      <td>-0.311065</td>\n      <td>0.391954</td>\n      <td>-0.578173</td>\n      <td>-2.535896</td>\n      <td>-2.098385</td>\n      <td>1.517624</td>\n      <td>-0.889011</td>\n      <td>0.224089</td>\n      <td>-0.281497</td>\n      <td>0.246163</td>\n      <td>0.889898</td>\n      <td>-2.477707</td>\n      <td>0.765038</td>\n      <td>0.757161</td>\n      <td>-1.568563</td>\n      <td>1.496201</td>\n      <td>0.030908</td>\n      <td>0.868219</td>\n      <td>-0.374659</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.530710</td>\n      <td>-0.279390</td>\n      <td>-0.162959</td>\n      <td>-0.532377</td>\n      <td>-0.648924</td>\n      <td>-0.163610</td>\n      <td>-0.031676</td>\n      <td>-1.250631</td>\n      <td>-1.939791</td>\n      <td>0.140569</td>\n      <td>-0.676014</td>\n      <td>-1.701005</td>\n      <td>-0.522569</td>\n      <td>0.253078</td>\n      <td>-0.552837</td>\n      <td>-0.489244</td>\n      <td>0.448827</td>\n      <td>-0.037801</td>\n      <td>-0.532728</td>\n      <td>-0.071330</td>\n      <td>-0.139008</td>\n      <td>-0.533878</td>\n      <td>0.138982</td>\n      <td>-0.137805</td>\n      <td>-0.533092</td>\n      <td>0.139028</td>\n      <td>-0.042402</td>\n      <td>-0.524526</td>\n      <td>0.220208</td>\n      <td>-0.18826</td>\n      <td>1.05936</td>\n      <td>-0.562268</td>\n      <td>-0.544292</td>\n      <td>-0.327012</td>\n      <td>-0.978440</td>\n      <td>-0.506754</td>\n      <td>-0.314407</td>\n      <td>-1.243792</td>\n      <td>-0.542146</td>\n      <td>0.253030</td>\n      <td>-1.234661</td>\n      <td>-0.155182</td>\n      <td>0.482987</td>\n      <td>-0.357513</td>\n      <td>-1.032706</td>\n      <td>-0.122787</td>\n      <td>-1.155849</td>\n      <td>-1.532409</td>\n      <td>1.527495</td>\n      <td>-0.229461</td>\n      <td>0.967877</td>\n      <td>-0.320762</td>\n      <td>-0.154216</td>\n      <td>-0.147911</td>\n      <td>-0.188211</td>\n      <td>-0.290496</td>\n      <td>0.289119</td>\n      <td>-0.323289</td>\n      <td>-0.313549</td>\n      <td>-0.701180</td>\n      <td>-0.112283</td>\n      <td>-0.185616</td>\n      <td>-0.087399</td>\n      <td>-0.108876</td>\n      <td>...</td>\n      <td>-1.992518</td>\n      <td>1.044078</td>\n      <td>0.064549</td>\n      <td>1.250380</td>\n      <td>0.069553</td>\n      <td>0.591301</td>\n      <td>-0.392345</td>\n      <td>1.509525</td>\n      <td>-0.831533</td>\n      <td>0.827695</td>\n      <td>1.204345</td>\n      <td>-0.663034</td>\n      <td>0.670370</td>\n      <td>1.987546</td>\n      <td>-0.449266</td>\n      <td>-0.148951</td>\n      <td>1.518030</td>\n      <td>-0.268800</td>\n      <td>-0.043801</td>\n      <td>-0.200018</td>\n      <td>-0.240832</td>\n      <td>-0.318214</td>\n      <td>2.669607</td>\n      <td>1.029494</td>\n      <td>0.169469</td>\n      <td>0.010807</td>\n      <td>-0.027873</td>\n      <td>-0.005639</td>\n      <td>-0.049348</td>\n      <td>-0.275070</td>\n      <td>-0.050310</td>\n      <td>0.009976</td>\n      <td>-0.120855</td>\n      <td>0.138065</td>\n      <td>0.009274</td>\n      <td>0.073463</td>\n      <td>0.018525</td>\n      <td>0.065817</td>\n      <td>-0.013243</td>\n      <td>-0.008018</td>\n      <td>-0.053914</td>\n      <td>0.055421</td>\n      <td>0.076891</td>\n      <td>0.096301</td>\n      <td>-7.951627</td>\n      <td>-3.550912</td>\n      <td>9.333297</td>\n      <td>0.643113</td>\n      <td>2.405863</td>\n      <td>2.890000</td>\n      <td>10.172862</td>\n      <td>-3.258524</td>\n      <td>4.301315</td>\n      <td>-5.222942</td>\n      <td>0.675351</td>\n      <td>5.408667</td>\n      <td>1.203547</td>\n      <td>5.470937</td>\n      <td>7.356445</td>\n      <td>1.027114</td>\n      <td>3.015050</td>\n      <td>-0.570498</td>\n      <td>-1.481314</td>\n      <td>-0.705752</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.530710</td>\n      <td>-0.279390</td>\n      <td>-0.162959</td>\n      <td>0.889111</td>\n      <td>0.835170</td>\n      <td>0.438317</td>\n      <td>1.133721</td>\n      <td>0.106352</td>\n      <td>-0.305627</td>\n      <td>2.070637</td>\n      <td>0.802455</td>\n      <td>-0.260418</td>\n      <td>0.905726</td>\n      <td>0.201793</td>\n      <td>-0.041704</td>\n      <td>1.062379</td>\n      <td>0.597325</td>\n      <td>-0.036040</td>\n      <td>1.031460</td>\n      <td>0.404513</td>\n      <td>0.123483</td>\n      <td>0.884162</td>\n      <td>0.138982</td>\n      <td>-0.137805</td>\n      <td>0.887115</td>\n      <td>0.139028</td>\n      <td>-0.042402</td>\n      <td>0.922507</td>\n      <td>0.220208</td>\n      <td>-0.18826</td>\n      <td>-0.94197</td>\n      <td>-0.562268</td>\n      <td>0.566042</td>\n      <td>1.064897</td>\n      <td>0.609698</td>\n      <td>0.519078</td>\n      <td>1.102149</td>\n      <td>0.590031</td>\n      <td>0.593479</td>\n      <td>0.510427</td>\n      <td>0.617952</td>\n      <td>0.568819</td>\n      <td>-0.882961</td>\n      <td>-0.357513</td>\n      <td>0.190543</td>\n      <td>0.642057</td>\n      <td>0.837369</td>\n      <td>0.620169</td>\n      <td>-0.414149</td>\n      <td>-0.229461</td>\n      <td>-0.499373</td>\n      <td>-0.320762</td>\n      <td>-0.154216</td>\n      <td>-0.147911</td>\n      <td>-0.188211</td>\n      <td>-0.290496</td>\n      <td>-0.391155</td>\n      <td>-0.323289</td>\n      <td>-0.313549</td>\n      <td>0.308158</td>\n      <td>-0.293496</td>\n      <td>0.889665</td>\n      <td>-0.106772</td>\n      <td>0.448940</td>\n      <td>...</td>\n      <td>-4.127668</td>\n      <td>3.099615</td>\n      <td>0.795191</td>\n      <td>1.659834</td>\n      <td>0.474235</td>\n      <td>-0.308725</td>\n      <td>0.306153</td>\n      <td>1.154131</td>\n      <td>-0.831533</td>\n      <td>0.827695</td>\n      <td>1.204345</td>\n      <td>-0.663034</td>\n      <td>1.413041</td>\n      <td>1.081997</td>\n      <td>-0.449266</td>\n      <td>-0.148951</td>\n      <td>1.518030</td>\n      <td>-1.894602</td>\n      <td>-0.526782</td>\n      <td>1.209454</td>\n      <td>-0.240832</td>\n      <td>-0.318214</td>\n      <td>-0.766078</td>\n      <td>1.029494</td>\n      <td>0.050021</td>\n      <td>0.144598</td>\n      <td>-0.021119</td>\n      <td>-0.044309</td>\n      <td>0.000090</td>\n      <td>-0.034269</td>\n      <td>-0.014296</td>\n      <td>0.026448</td>\n      <td>-0.005892</td>\n      <td>0.068137</td>\n      <td>-0.017787</td>\n      <td>0.136258</td>\n      <td>0.008309</td>\n      <td>-0.000720</td>\n      <td>0.015918</td>\n      <td>-0.005078</td>\n      <td>-0.093464</td>\n      <td>0.026340</td>\n      <td>-0.063265</td>\n      <td>-0.046079</td>\n      <td>-2.413634</td>\n      <td>-0.327859</td>\n      <td>0.685184</td>\n      <td>-0.853473</td>\n      <td>-2.644093</td>\n      <td>-2.139606</td>\n      <td>2.015059</td>\n      <td>-0.572296</td>\n      <td>0.012945</td>\n      <td>-0.547410</td>\n      <td>0.393384</td>\n      <td>0.843605</td>\n      <td>-2.511670</td>\n      <td>0.801449</td>\n      <td>1.207108</td>\n      <td>-1.275904</td>\n      <td>1.598204</td>\n      <td>-0.138238</td>\n      <td>0.894061</td>\n      <td>-1.080872</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.366301</td>\n      <td>1.580845</td>\n      <td>-0.162959</td>\n      <td>1.173408</td>\n      <td>-0.538991</td>\n      <td>2.275777</td>\n      <td>-1.214452</td>\n      <td>-0.250749</td>\n      <td>2.236407</td>\n      <td>-1.056562</td>\n      <td>-0.577449</td>\n      <td>2.260610</td>\n      <td>1.095797</td>\n      <td>-0.060583</td>\n      <td>-0.496847</td>\n      <td>1.063514</td>\n      <td>-0.077532</td>\n      <td>0.120986</td>\n      <td>1.168248</td>\n      <td>0.164305</td>\n      <td>0.199442</td>\n      <td>1.167770</td>\n      <td>0.138982</td>\n      <td>-0.137805</td>\n      <td>1.171157</td>\n      <td>0.139028</td>\n      <td>-0.042402</td>\n      <td>1.211914</td>\n      <td>0.220208</td>\n      <td>-0.18826</td>\n      <td>-0.94197</td>\n      <td>-0.562268</td>\n      <td>-0.348319</td>\n      <td>1.092567</td>\n      <td>-0.072772</td>\n      <td>-0.430047</td>\n      <td>1.150112</td>\n      <td>-0.169305</td>\n      <td>-0.356466</td>\n      <td>0.253030</td>\n      <td>-0.105635</td>\n      <td>-0.461536</td>\n      <td>-0.882961</td>\n      <td>-0.357513</td>\n      <td>-0.036174</td>\n      <td>-0.122787</td>\n      <td>-1.155849</td>\n      <td>-1.532409</td>\n      <td>1.527495</td>\n      <td>0.514889</td>\n      <td>-0.499373</td>\n      <td>-0.320762</td>\n      <td>-0.154216</td>\n      <td>-0.147911</td>\n      <td>-0.188211</td>\n      <td>-0.290496</td>\n      <td>-0.663264</td>\n      <td>-0.323289</td>\n      <td>-0.313549</td>\n      <td>-0.431990</td>\n      <td>0.094940</td>\n      <td>0.036552</td>\n      <td>0.174450</td>\n      <td>0.179728</td>\n      <td>...</td>\n      <td>-5.354814</td>\n      <td>1.882512</td>\n      <td>0.037363</td>\n      <td>2.774812</td>\n      <td>0.474235</td>\n      <td>-0.308725</td>\n      <td>0.306153</td>\n      <td>1.154131</td>\n      <td>-0.831533</td>\n      <td>0.827695</td>\n      <td>1.204345</td>\n      <td>-0.547322</td>\n      <td>0.670370</td>\n      <td>1.987546</td>\n      <td>-0.449266</td>\n      <td>-0.148951</td>\n      <td>-1.474584</td>\n      <td>-1.894602</td>\n      <td>-0.526782</td>\n      <td>1.209454</td>\n      <td>-0.240832</td>\n      <td>-0.318214</td>\n      <td>2.669607</td>\n      <td>1.029494</td>\n      <td>0.009481</td>\n      <td>0.179083</td>\n      <td>0.032318</td>\n      <td>0.030371</td>\n      <td>0.036187</td>\n      <td>-0.038786</td>\n      <td>-0.066376</td>\n      <td>0.123849</td>\n      <td>0.132462</td>\n      <td>-0.063814</td>\n      <td>-0.004053</td>\n      <td>0.127969</td>\n      <td>0.002579</td>\n      <td>0.038071</td>\n      <td>-0.032156</td>\n      <td>-0.042941</td>\n      <td>-0.081394</td>\n      <td>0.057888</td>\n      <td>-0.037198</td>\n      <td>0.028467</td>\n      <td>-7.970892</td>\n      <td>-3.385319</td>\n      <td>8.849612</td>\n      <td>0.568138</td>\n      <td>2.356805</td>\n      <td>2.842386</td>\n      <td>9.902492</td>\n      <td>-2.887241</td>\n      <td>3.969924</td>\n      <td>-5.291786</td>\n      <td>0.863381</td>\n      <td>5.458267</td>\n      <td>0.871790</td>\n      <td>5.648135</td>\n      <td>6.975617</td>\n      <td>0.710852</td>\n      <td>2.860918</td>\n      <td>-0.713143</td>\n      <td>-1.393507</td>\n      <td>-0.801889</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.530710</td>\n      <td>-0.279390</td>\n      <td>-0.162959</td>\n      <td>-0.248079</td>\n      <td>0.890136</td>\n      <td>0.871281</td>\n      <td>0.136541</td>\n      <td>1.606175</td>\n      <td>1.086440</td>\n      <td>-0.358914</td>\n      <td>0.802455</td>\n      <td>1.180169</td>\n      <td>-0.255537</td>\n      <td>0.094133</td>\n      <td>5.585148</td>\n      <td>-0.307276</td>\n      <td>-0.237184</td>\n      <td>-0.013624</td>\n      <td>-0.529883</td>\n      <td>-1.088897</td>\n      <td>-0.153880</td>\n      <td>-0.250270</td>\n      <td>0.138982</td>\n      <td>-0.137805</td>\n      <td>-0.254731</td>\n      <td>0.098731</td>\n      <td>-0.041352</td>\n      <td>-0.235119</td>\n      <td>0.220208</td>\n      <td>-0.18826</td>\n      <td>-0.94197</td>\n      <td>-0.562268</td>\n      <td>0.558953</td>\n      <td>0.058157</td>\n      <td>0.409054</td>\n      <td>0.670708</td>\n      <td>-0.009517</td>\n      <td>0.443748</td>\n      <td>0.677378</td>\n      <td>0.061120</td>\n      <td>0.538535</td>\n      <td>0.841422</td>\n      <td>-0.882961</td>\n      <td>-0.357513</td>\n      <td>0.190543</td>\n      <td>0.642057</td>\n      <td>0.837369</td>\n      <td>0.620169</td>\n      <td>-0.414149</td>\n      <td>-0.229461</td>\n      <td>-0.499373</td>\n      <td>-0.320762</td>\n      <td>-0.154216</td>\n      <td>-0.147911</td>\n      <td>-0.188211</td>\n      <td>-0.290496</td>\n      <td>-0.391155</td>\n      <td>-0.323289</td>\n      <td>-0.313549</td>\n      <td>1.418634</td>\n      <td>-0.141192</td>\n      <td>-0.081388</td>\n      <td>-0.214699</td>\n      <td>-0.241654</td>\n      <td>...</td>\n      <td>-3.782774</td>\n      <td>2.087450</td>\n      <td>0.691992</td>\n      <td>1.934122</td>\n      <td>0.474235</td>\n      <td>-0.308725</td>\n      <td>0.306153</td>\n      <td>1.154131</td>\n      <td>-0.831533</td>\n      <td>0.827695</td>\n      <td>1.204345</td>\n      <td>-0.663034</td>\n      <td>0.670370</td>\n      <td>-0.638341</td>\n      <td>-0.449266</td>\n      <td>-0.148951</td>\n      <td>-1.474584</td>\n      <td>-0.755869</td>\n      <td>0.219763</td>\n      <td>1.209454</td>\n      <td>-0.240832</td>\n      <td>-0.318214</td>\n      <td>-0.766078</td>\n      <td>1.029494</td>\n      <td>0.195881</td>\n      <td>0.097763</td>\n      <td>-0.118332</td>\n      <td>-0.078144</td>\n      <td>-0.050602</td>\n      <td>-0.082269</td>\n      <td>-0.111411</td>\n      <td>-0.039720</td>\n      <td>-0.044915</td>\n      <td>0.032023</td>\n      <td>-0.056793</td>\n      <td>0.111835</td>\n      <td>0.022229</td>\n      <td>0.016954</td>\n      <td>-0.013878</td>\n      <td>-0.046586</td>\n      <td>-0.085140</td>\n      <td>0.015938</td>\n      <td>-0.058317</td>\n      <td>0.026717</td>\n      <td>-2.295709</td>\n      <td>-0.399837</td>\n      <td>0.189829</td>\n      <td>-0.809544</td>\n      <td>-2.577310</td>\n      <td>-2.234221</td>\n      <td>1.778084</td>\n      <td>-1.495117</td>\n      <td>0.582806</td>\n      <td>-0.443059</td>\n      <td>0.456154</td>\n      <td>0.567814</td>\n      <td>-2.826626</td>\n      <td>0.671591</td>\n      <td>0.765171</td>\n      <td>-1.631040</td>\n      <td>1.464014</td>\n      <td>0.287459</td>\n      <td>0.753385</td>\n      <td>-0.155760</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 278 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"_uuid":"9c65a159205f1ae72cf2de8a9816726705350d72"},"cell_type":"markdown","source":"## XGBoost"},{"metadata":{"trusted":true,"_uuid":"c2a120d1514d355b4a9bd53221c18eb38b857bb1"},"cell_type":"code","source":"xgb_params = {\n    \"eval_metric\": \"rmse\",\n    \"seed\": 1337,\n    \"eta\": 0.0123,\n    \"subsample\": 0.8,\n    \"colsample_bytree\": 0.85,\n    \"tree_method\": \"gpu_hist\",\n    \"device\": \"gpu\",\n    \"silent\": 1\n}\n\nxgb_X = X_train_all\nxgb_y = target\nxgb_X_test = X_test_all\n\nmodel, oof_train_xgb, oof_test_xgb= run_xgb(\n    xgb_params, \n    xgb_X, \n    xgb_y, \n    xgb_X_test,\n    resc=train_resc,\n    n_splits=10,\n    num_rounds=10000)","execution_count":100,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n  if getattr(data, 'base', None) is not None and \\\n","name":"stderr"},{"output_type":"stream","text":"[0]\ttrain-rmse:2.31237\tvalid-rmse:2.31318\nMultiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n\nWill train until valid-rmse hasn't improved in 500 rounds.\n[1000]\ttrain-rmse:0.66723\tvalid-rmse:1.00601\n[2000]\ttrain-rmse:0.469833\tvalid-rmse:1.0042\n[3000]\ttrain-rmse:0.330923\tvalid-rmse:1.00186\nStopping. Best iteration:\n[3072]\ttrain-rmse:0.322669\tvalid-rmse:1.00158\n\n[0]\ttrain-rmse:2.3123\tvalid-rmse:2.31304\nMultiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n\nWill train until valid-rmse hasn't improved in 500 rounds.\n[1000]\ttrain-rmse:0.669328\tvalid-rmse:1.00143\n[2000]\ttrain-rmse:0.468589\tvalid-rmse:0.997572\n[3000]\ttrain-rmse:0.329771\tvalid-rmse:0.995049\n[4000]\ttrain-rmse:0.232458\tvalid-rmse:0.994175\nStopping. Best iteration:\n[3558]\ttrain-rmse:0.27145\tvalid-rmse:0.993818\n\n[0]\ttrain-rmse:2.31227\tvalid-rmse:2.31303\nMultiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n\nWill train until valid-rmse hasn't improved in 500 rounds.\n[1000]\ttrain-rmse:0.668439\tvalid-rmse:1.01604\n[2000]\ttrain-rmse:0.4704\tvalid-rmse:1.01109\n[3000]\ttrain-rmse:0.331664\tvalid-rmse:1.01009\nStopping. Best iteration:\n[2507]\ttrain-rmse:0.394453\tvalid-rmse:1.00986\n\n[0]\ttrain-rmse:2.3123\tvalid-rmse:2.3127\nMultiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n\nWill train until valid-rmse hasn't improved in 500 rounds.\n[1000]\ttrain-rmse:0.667631\tvalid-rmse:1.0166\n[2000]\ttrain-rmse:0.470378\tvalid-rmse:1.0137\nStopping. Best iteration:\n[2085]\ttrain-rmse:0.456022\tvalid-rmse:1.01297\n\n[0]\ttrain-rmse:2.31225\tvalid-rmse:2.31296\nMultiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n\nWill train until valid-rmse hasn't improved in 500 rounds.\n[1000]\ttrain-rmse:0.667291\tvalid-rmse:1.02367\n[2000]\ttrain-rmse:0.46919\tvalid-rmse:1.01931\nStopping. Best iteration:\n[2197]\ttrain-rmse:0.43832\tvalid-rmse:1.01866\n\n[0]\ttrain-rmse:2.31223\tvalid-rmse:2.31246\nMultiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n\nWill train until valid-rmse hasn't improved in 500 rounds.\n[1000]\ttrain-rmse:0.661686\tvalid-rmse:1.0171\n[2000]\ttrain-rmse:0.465375\tvalid-rmse:1.01415\nStopping. Best iteration:\n[2339]\ttrain-rmse:0.413042\tvalid-rmse:1.01347\n\n[0]\ttrain-rmse:2.31223\tvalid-rmse:2.31274\nMultiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n\nWill train until valid-rmse hasn't improved in 500 rounds.\n[1000]\ttrain-rmse:0.668416\tvalid-rmse:1.0063\n[2000]\ttrain-rmse:0.469711\tvalid-rmse:1.00309\n[3000]\ttrain-rmse:0.329723\tvalid-rmse:1.00282\nStopping. Best iteration:\n[3350]\ttrain-rmse:0.290934\tvalid-rmse:1.00231\n\n[0]\ttrain-rmse:2.31231\tvalid-rmse:2.31248\nMultiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n\nWill train until valid-rmse hasn't improved in 500 rounds.\n[1000]\ttrain-rmse:0.66363\tvalid-rmse:1.01896\n[2000]\ttrain-rmse:0.465001\tvalid-rmse:1.01332\n[3000]\ttrain-rmse:0.326714\tvalid-rmse:1.01096\nStopping. Best iteration:\n[3413]\ttrain-rmse:0.282671\tvalid-rmse:1.01057\n\n[0]\ttrain-rmse:2.31229\tvalid-rmse:2.31205\nMultiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n\nWill train until valid-rmse hasn't improved in 500 rounds.\n[1000]\ttrain-rmse:0.664388\tvalid-rmse:1.01804\n[2000]\ttrain-rmse:0.465125\tvalid-rmse:1.01289\n[3000]\ttrain-rmse:0.325954\tvalid-rmse:1.01114\n[4000]\ttrain-rmse:0.229499\tvalid-rmse:1.01047\n[5000]\ttrain-rmse:0.161049\tvalid-rmse:1.00973\n[6000]\ttrain-rmse:0.113564\tvalid-rmse:1.00867\nStopping. Best iteration:\n[6056]\ttrain-rmse:0.111358\tvalid-rmse:1.00857\n\n[0]\ttrain-rmse:2.31242\tvalid-rmse:2.3128\nMultiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n\nWill train until valid-rmse hasn't improved in 500 rounds.\n[1000]\ttrain-rmse:0.668555\tvalid-rmse:0.98511\n[2000]\ttrain-rmse:0.470926\tvalid-rmse:0.9772\n[3000]\ttrain-rmse:0.330887\tvalid-rmse:0.97563\n[4000]\ttrain-rmse:0.232583\tvalid-rmse:0.974888\n[5000]\ttrain-rmse:0.163142\tvalid-rmse:0.973982\nStopping. Best iteration:\n[5314]\ttrain-rmse:0.145875\tvalid-rmse:0.97368\n\n","name":"stdout"}]},{"metadata":{"_uuid":"b9f56b5ede55e2272d63f782be65140374528992"},"cell_type":"markdown","source":"## Run LGBM"},{"metadata":{"trusted":true,"_uuid":"a6101913115d0b45f6eb3539ea3fb7622038d8a3"},"cell_type":"code","source":"def run_lgb(params,\n            X,\n            y,\n            X_test,\n            resc,\n            cat_features,\n            n_splits=10,\n            early_stop=500):\n    oof_train = np.zeros((X.shape[0]))\n    oof_test = np.zeros((X_test.shape[0], n_splits))\n    fold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=229)\n\n    for i, (trn_index, val_index) in enumerate(fold.split(X, \n                                                        y.astype(int))):\n        X_tr = X.iloc[trn_index, :]\n        X_val = X.iloc[val_index, :]\n\n        y_tr = y[trn_index]\n        y_val = y[val_index]\n        model = lgb.LGBMRegressor(**params)\n        model.fit(X_tr, \n                  y_tr, \n                  eval_set=(X_val, y_val),\n                  verbose=500,\n                  early_stopping_rounds=early_stop,\n                  categorical_feature=cat_features)\n        valid_pred = model.predict(X_val, num_iteration=model.best_iteration_)\n        test_pred = model.predict(X_test, num_iteration=model.best_iteration_)\n        oof_train[val_index] = valid_pred\n        oof_test[:, i] = test_pred\n    return model, oof_train, oof_test","execution_count":101,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"41baedb9113c5e5febb62683416620e2875806b5"},"cell_type":"code","source":"lgb_params = {\n    \"boosting_type\": \"gbdt\",\n    \"num_leaves\": 146,\n    \"max_depth\": 12,\n    \"max_bin\": 32,\n    \"learning_rate\": 0.01,\n    \"n_estimators\": 10000,\n    \"subsample\": 0.9212945843023237,\n    \"subsample_freq\": 2,\n    \"colsample_bytree\": 0.6334740217238963,\n    \"reg_lambda\": 1.543309192604612,\n    \"min_child_samples\": 45,\n    \"min_child_weight\": 0.5878240657385082,\n    \"min_split_gain\": 0.004619759404679957,\n    \"n_jobs\": -1\n}\n\nmodel, oof_train, oof_test = run_lgb(\n    lgb_params, \n    xgb_X, \n    xgb_y, \n    xgb_X_test,\n    train_resc,\n    cat_features,\n    n_splits=6,\n    early_stop=500)","execution_count":102,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/lightgbm/basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\nNew categorical_feature is ['Breed1', 'Breed2', 'Color1', 'Color2', 'Color3', 'Dewormed', 'FurLength', 'Gender', 'Health', 'MaturitySize', 'Quantity', 'State', 'Sterilized', 'Type', 'Vaccinated', 'language', 'main_breed_BreedName', 'second_breed_BreedName']\n  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n/opt/conda/lib/python3.6/site-packages/lightgbm/basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\nNew categorical_feature is ['Breed1', 'Breed2', 'Color1', 'Color2', 'Color3', 'Dewormed', 'FurLength', 'Gender', 'Health', 'MaturitySize', 'Quantity', 'State', 'Sterilized', 'Type', 'Vaccinated', 'language', 'main_breed_BreedName', 'second_breed_BreedName']\n  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n","name":"stderr"},{"output_type":"stream","text":"Training until validation scores don't improve for 500 rounds.\n[500]\tvalid_0's l2: 1.01493\n[1000]\tvalid_0's l2: 0.998875\n[1500]\tvalid_0's l2: 0.994028\n[2000]\tvalid_0's l2: 0.992273\n[2500]\tvalid_0's l2: 0.991589\n[3000]\tvalid_0's l2: 0.990712\n[3500]\tvalid_0's l2: 0.990831\nEarly stopping, best iteration is:\n[3041]\tvalid_0's l2: 0.99062\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/lightgbm/basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\nNew categorical_feature is ['Breed1', 'Breed2', 'Color1', 'Color2', 'Color3', 'Dewormed', 'FurLength', 'Gender', 'Health', 'MaturitySize', 'Quantity', 'State', 'Sterilized', 'Type', 'Vaccinated', 'language', 'main_breed_BreedName', 'second_breed_BreedName']\n  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n/opt/conda/lib/python3.6/site-packages/lightgbm/basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\nNew categorical_feature is ['Breed1', 'Breed2', 'Color1', 'Color2', 'Color3', 'Dewormed', 'FurLength', 'Gender', 'Health', 'MaturitySize', 'Quantity', 'State', 'Sterilized', 'Type', 'Vaccinated', 'language', 'main_breed_BreedName', 'second_breed_BreedName']\n  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n","name":"stderr"},{"output_type":"stream","text":"Training until validation scores don't improve for 500 rounds.\n[500]\tvalid_0's l2: 1.04626\n[1000]\tvalid_0's l2: 1.03563\n[1500]\tvalid_0's l2: 1.03476\n[2000]\tvalid_0's l2: 1.03283\n[2500]\tvalid_0's l2: 1.03304\nEarly stopping, best iteration is:\n[2016]\tvalid_0's l2: 1.03275\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/lightgbm/basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\nNew categorical_feature is ['Breed1', 'Breed2', 'Color1', 'Color2', 'Color3', 'Dewormed', 'FurLength', 'Gender', 'Health', 'MaturitySize', 'Quantity', 'State', 'Sterilized', 'Type', 'Vaccinated', 'language', 'main_breed_BreedName', 'second_breed_BreedName']\n  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n/opt/conda/lib/python3.6/site-packages/lightgbm/basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\nNew categorical_feature is ['Breed1', 'Breed2', 'Color1', 'Color2', 'Color3', 'Dewormed', 'FurLength', 'Gender', 'Health', 'MaturitySize', 'Quantity', 'State', 'Sterilized', 'Type', 'Vaccinated', 'language', 'main_breed_BreedName', 'second_breed_BreedName']\n  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n","name":"stderr"},{"output_type":"stream","text":"Training until validation scores don't improve for 500 rounds.\n[500]\tvalid_0's l2: 1.02376\n[1000]\tvalid_0's l2: 1.01177\n[1500]\tvalid_0's l2: 1.00959\n[2000]\tvalid_0's l2: 1.00798\n[2500]\tvalid_0's l2: 1.00804\nEarly stopping, best iteration is:\n[2274]\tvalid_0's l2: 1.00763\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/lightgbm/basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\nNew categorical_feature is ['Breed1', 'Breed2', 'Color1', 'Color2', 'Color3', 'Dewormed', 'FurLength', 'Gender', 'Health', 'MaturitySize', 'Quantity', 'State', 'Sterilized', 'Type', 'Vaccinated', 'language', 'main_breed_BreedName', 'second_breed_BreedName']\n  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n/opt/conda/lib/python3.6/site-packages/lightgbm/basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\nNew categorical_feature is ['Breed1', 'Breed2', 'Color1', 'Color2', 'Color3', 'Dewormed', 'FurLength', 'Gender', 'Health', 'MaturitySize', 'Quantity', 'State', 'Sterilized', 'Type', 'Vaccinated', 'language', 'main_breed_BreedName', 'second_breed_BreedName']\n  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n","name":"stderr"},{"output_type":"stream","text":"Training until validation scores don't improve for 500 rounds.\n[500]\tvalid_0's l2: 1.04237\n[1000]\tvalid_0's l2: 1.0281\n[1500]\tvalid_0's l2: 1.0235\n[2000]\tvalid_0's l2: 1.02252\n[2500]\tvalid_0's l2: 1.02168\n[3000]\tvalid_0's l2: 1.02103\n[3500]\tvalid_0's l2: 1.02066\n[4000]\tvalid_0's l2: 1.0206\n[4500]\tvalid_0's l2: 1.02047\nEarly stopping, best iteration is:\n[4282]\tvalid_0's l2: 1.02047\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/lightgbm/basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\nNew categorical_feature is ['Breed1', 'Breed2', 'Color1', 'Color2', 'Color3', 'Dewormed', 'FurLength', 'Gender', 'Health', 'MaturitySize', 'Quantity', 'State', 'Sterilized', 'Type', 'Vaccinated', 'language', 'main_breed_BreedName', 'second_breed_BreedName']\n  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n/opt/conda/lib/python3.6/site-packages/lightgbm/basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\nNew categorical_feature is ['Breed1', 'Breed2', 'Color1', 'Color2', 'Color3', 'Dewormed', 'FurLength', 'Gender', 'Health', 'MaturitySize', 'Quantity', 'State', 'Sterilized', 'Type', 'Vaccinated', 'language', 'main_breed_BreedName', 'second_breed_BreedName']\n  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n","name":"stderr"},{"output_type":"stream","text":"Training until validation scores don't improve for 500 rounds.\n[500]\tvalid_0's l2: 1.00595\n[1000]\tvalid_0's l2: 0.987189\n[1500]\tvalid_0's l2: 0.981778\n[2000]\tvalid_0's l2: 0.978847\n[2500]\tvalid_0's l2: 0.977705\n[3000]\tvalid_0's l2: 0.977297\n[3500]\tvalid_0's l2: 0.977\n[4000]\tvalid_0's l2: 0.976657\n[4500]\tvalid_0's l2: 0.976641\nEarly stopping, best iteration is:\n[4466]\tvalid_0's l2: 0.976626\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/lightgbm/basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\nNew categorical_feature is ['Breed1', 'Breed2', 'Color1', 'Color2', 'Color3', 'Dewormed', 'FurLength', 'Gender', 'Health', 'MaturitySize', 'Quantity', 'State', 'Sterilized', 'Type', 'Vaccinated', 'language', 'main_breed_BreedName', 'second_breed_BreedName']\n  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n/opt/conda/lib/python3.6/site-packages/lightgbm/basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\nNew categorical_feature is ['Breed1', 'Breed2', 'Color1', 'Color2', 'Color3', 'Dewormed', 'FurLength', 'Gender', 'Health', 'MaturitySize', 'Quantity', 'State', 'Sterilized', 'Type', 'Vaccinated', 'language', 'main_breed_BreedName', 'second_breed_BreedName']\n  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n","name":"stderr"},{"output_type":"stream","text":"Training until validation scores don't improve for 500 rounds.\n[500]\tvalid_0's l2: 1.02588\n[1000]\tvalid_0's l2: 1.01186\n[1500]\tvalid_0's l2: 1.00801\n[2000]\tvalid_0's l2: 1.00692\n[2500]\tvalid_0's l2: 1.00639\n[3000]\tvalid_0's l2: 1.00628\nEarly stopping, best iteration is:\n[2765]\tvalid_0's l2: 1.00601\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_X.columns[np.argwhere(model.feature_importances_ > 2000).reshape(-1)]","execution_count":103,"outputs":[{"output_type":"execute_result","execution_count":103,"data":{"text/plain":"Index(['Age', 'annot_score_MEAN', 'color_score_MEAN', 'Tfidf_Description_4',\n       'Tfidf_Description_6', 'Tfidf_Description_7', 'Tfidf_Description_8',\n       'Tfidf_Description_11', 'Tfidf_Description_12', 'Tfidf_Description_13',\n       'Tfidf_Description_14', 'Tfidf_Description_15', 'Tfidf_entity_11',\n       'Tfidf_entity_13', 'Tfidf_entity_14', 'Tfidf_entity_15', 'Tfidf_desc_2',\n       'Tfidf_desc_11', 'Tfidf_desc_15', 'image_size_mean', 'Breed1', 'img0',\n       'img14', 'img28', 'img33', 'img34', 'img46', 'ent0', 'ent1', 'ent2',\n       'ent3', 'ent4', 'ent5', 'ent6', 'ent7', 'ent8', 'ent9', 'dsc4'],\n      dtype='object')"},"metadata":{}}]},{"metadata":{"_uuid":"a8fe014f27d97225fe8182507ea2b25a56608d2f"},"cell_type":"markdown","source":"## Post process"},{"metadata":{"trusted":true,"_uuid":"96cd36acf1527937b353850b5127e9fdb5f1672b"},"cell_type":"code","source":"def plot_pred(pred):\n    sns.distplot(pred, kde=True, hist_kws={\"range\": [0, 5]})","execution_count":104,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4bb9e7887a96f658a9d5346213bd102ee053776b"},"cell_type":"code","source":"plot_pred(oof_train)","execution_count":105,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n","name":"stderr"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"metadata":{"trusted":true,"_uuid":"7e603980305c9a07e7e8e47e63157218f270464c"},"cell_type":"code","source":"plot_pred(oof_train_xgb)","execution_count":106,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n","name":"stderr"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"metadata":{"trusted":true,"_uuid":"3978700644bc02faa416bec586c6c5235f5e191d"},"cell_type":"code","source":"oof_train.shape","execution_count":107,"outputs":[{"output_type":"execute_result","execution_count":107,"data":{"text/plain":"(14993,)"},"metadata":{}}]},{"metadata":{"trusted":true,"_uuid":"c93732aae83759455f5dd583bd691fe1b1c55fd9"},"cell_type":"code","source":"plot_pred(oof_test.mean(axis=1))","execution_count":108,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n","name":"stderr"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"metadata":{"trusted":true,"_uuid":"392d689d823857cb65635a9a704958dfb08384b6"},"cell_type":"code","source":"plot_pred(oof_test_xgb.mean(1))","execution_count":109,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n","name":"stderr"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"metadata":{"trusted":true,"_uuid":"461512ba773c98a9e08db4847cd95cbfbab1baba"},"cell_type":"code","source":"plot_pred(trainer.train_preds * 4)","execution_count":110,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n","name":"stderr"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"metadata":{"trusted":true,"_uuid":"81534882627892ea4d9cfb4e4ecc3e999e0901e2"},"cell_type":"code","source":"plot_pred(test_preds * 4)","execution_count":111,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n","name":"stderr"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"metadata":{"trusted":true,"_uuid":"d17db450bf99cfb3c0e5e0ce8af73e86a21a7cab"},"cell_type":"code","source":"lgb_xgb = 0.5 * oof_train + 0.5 * oof_train_xgb\nlgb_xgb_test = 0.5 * oof_test.mean(1) + 0.5 * oof_test_xgb.mean(1)\nplot_pred(lgb_xgb)\nplot_pred(lgb_xgb_test)","execution_count":112,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n","name":"stderr"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"metadata":{"trusted":true,"_uuid":"61c55611dea702680998f99728ec594687f53225"},"cell_type":"code","source":"nn_preds = np.clip(trainer.train_preds, a_min=0.0, a_max=1.0)\nnn_preds_test = np.clip(test_preds, a_min=0.0, a_max=1.0)\nplot_pred(nn_preds * 4)\nplot_pred(nn_preds_test * 4)","execution_count":113,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n","name":"stderr"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"metadata":{"trusted":true,"_uuid":"599af7b9c36fe329f2d53a3fda11938727172a81"},"cell_type":"code","source":"lgb_xgb_nn = 0.9 * lgb_xgb + 0.1 * (nn_preds * 4)\nlgb_xgb_nn_test = 0.9 * lgb_xgb_test + 0.1 * nn_preds_test * 4","execution_count":114,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d3e315bd1f8cacada2fbb38361f900de290d2052"},"cell_type":"code","source":"plot_pred(lgb_xgb_nn)","execution_count":115,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n","name":"stderr"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"metadata":{"trusted":true,"_uuid":"6554c06c2fd88e0066e9a9b9ccb873d458840135"},"cell_type":"code","source":"plot_pred(lgb_xgb_nn_test)","execution_count":116,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n","name":"stderr"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"metadata":{"trusted":true,"_uuid":"e5c7fc7a4fad7fd8fbdb8f573a6bdc84999c8867"},"cell_type":"code","source":"opt = OptimizedRounder()\nopt.fit(lgb_xgb, target, [1.6, 2.1, 2.8, 3.5])\ncoeff = opt.coefficients()\nvalid_pred = opt.predict(lgb_xgb, coeff)\nqwk = quadratic_weighted_kappa(xgb_y, valid_pred)\nprint(\"QWK = \", qwk)\ncoeffs = coeff.copy()\ntrain_predictions = opt.predict(lgb_xgb, coeffs).astype(np.int8)\nprint(f\"train_preds: {Counter(train_predictions)}\")\ntest_predictions = opt.predict(lgb_xgb_test, coeffs).astype(np.int8)\nprint(f\"test_preds: {Counter(test_predictions)}\")\nsubmission = pd.DataFrame({\"PetID\": test.PetID.values, \"AdoptionSpeed\": test_predictions})\nsubmission.to_csv(\"submission_tree.csv\", index=False)\nsubmission.head()","execution_count":117,"outputs":[{"output_type":"stream","text":"QWK =  0.5097558466762209\ntrain_preds: Counter({2: 4719, 3: 3597, 4: 3569, 1: 2560, 0: 548})\ntest_preds: Counter({2: 1219, 3: 959, 4: 944, 1: 714, 0: 112})\n","name":"stdout"},{"output_type":"execute_result","execution_count":117,"data":{"text/plain":"       PetID  AdoptionSpeed\n0  378fcc4fc              2\n1  73c10e136              3\n2  72000c4c5              3\n3  e147a4b9f              2\n4  43fbba852              4","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PetID</th>\n      <th>AdoptionSpeed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>378fcc4fc</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>73c10e136</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>72000c4c5</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>e147a4b9f</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>43fbba852</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true,"_uuid":"b531b191b4961866fd6b86c4a2d2be2b9d65ae51"},"cell_type":"code","source":"opt = OptimizedRounder()\nopt.fit(lgb_xgb_nn, target, [1.5, 2.0, 2.5, 3.5])\ncoeff = opt.coefficients()\nvalid_pred = opt.predict(lgb_xgb_nn, coeff)\nqwk = quadratic_weighted_kappa(xgb_y, valid_pred)\nprint(\"QWK = \", qwk)\ncoeffs = coeff.copy()\ntrain_predictions = opt.predict(lgb_xgb_nn, coeffs).astype(np.int8)\nprint(f\"train_preds: {Counter(train_predictions)}\")\ntest_predictions = opt.predict(lgb_xgb_nn_test, coeffs).astype(np.int8)\nprint(f\"test_preds: {Counter(test_predictions)}\")\nsubmission = pd.DataFrame({\"PetID\": test.PetID.values, \"AdoptionSpeed\": test_predictions})\nsubmission.to_csv(\"submission.csv\", index=False)\nsubmission.head()","execution_count":118,"outputs":[{"output_type":"stream","text":"QWK =  0.5101740262012959\ntrain_preds: Counter({2: 4664, 3: 3458, 4: 3146, 1: 3092, 0: 633})\ntest_preds: Counter({2: 1214, 3: 935, 1: 849, 4: 819, 0: 131})\n","name":"stdout"},{"output_type":"execute_result","execution_count":118,"data":{"text/plain":"       PetID  AdoptionSpeed\n0  378fcc4fc              2\n1  73c10e136              3\n2  72000c4c5              3\n3  e147a4b9f              2\n4  43fbba852              4","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PetID</th>\n      <th>AdoptionSpeed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>378fcc4fc</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>73c10e136</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>72000c4c5</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>e147a4b9f</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>43fbba852</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true,"_uuid":"0fa0faa2b48eb4a8502d34f24675fbc511fa5a67"},"cell_type":"code","source":"opt = OptimizedRounder()\nopt.fit(nn_preds * 4, target, [1.5, 2.0, 2.5, 3.5])\ncoeff = opt.coefficients()\nvalid_pred = opt.predict(nn_preds * 4, coeff)\nqwk = quadratic_weighted_kappa(target, valid_pred)\nprint(\"QWK = \", qwk)\ncoeffs = coeff.copy()\ntrain_predictions = opt.predict(nn_preds * 4, coeffs).astype(np.int8)\nprint(f\"train_preds: {Counter(train_predictions)}\")\ntest_predictions = opt.predict(nn_preds_test * 4, coeffs).astype(np.int8)\nprint(f\"test_preds: {Counter(test_predictions)}\")\nsubmission = pd.DataFrame({\"PetID\": test.PetID.values, \"AdoptionSpeed\": test_predictions})\nsubmission.to_csv(\"submission_nn.csv\", index=False)\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b5715f11666185cc44d0425a90b6f702b430cce5"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}