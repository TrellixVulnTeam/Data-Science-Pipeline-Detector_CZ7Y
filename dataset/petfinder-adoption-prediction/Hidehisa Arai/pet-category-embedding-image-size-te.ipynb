{"cells":[{"metadata":{"_uuid":"efc8f31b8f57b14c535dabe6a9ddb1f7423e6065"},"cell_type":"markdown","source":"## Libraries"},{"metadata":{"trusted":true,"_uuid":"1223e84fee63f03f38138cc256ada0b6e76032ad"},"cell_type":"code","source":"import os\nimport cv2\nimport json\nimport pickle\nimport random\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nimport xgboost as xgb\nimport lightgbm as lgb\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.utils.data as data\n\nimport torchvision.models as models\nimport torchvision.transforms as transforms\n\nfrom pathlib import Path\nfrom datetime import datetime as dt\nfrom functools import partial\nfrom collections import Counter\n\nfrom PIL import Image\n\nfrom joblib import Parallel, delayed\n\nfrom sklearn.model_selection import StratifiedKFold, KFold, GroupKFold\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.metrics import cohen_kappa_score\nfrom sklearn.preprocessing import StandardScaler\n\nfrom tqdm import tqdm\n\npd.options.display.max_columns = 128\ntorch.multiprocessing.set_start_method(\"spawn\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"15150b4893d23dd21cafa51d889713e4c50a1d1f"},"cell_type":"markdown","source":"## Image model loading"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!cp ../input/pytorch-pretrained-image-models/* ./\n!ls ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a04adc838cfa9aa01f74052dc8eb9ea29af59406"},"cell_type":"markdown","source":"## Metadata and Sentiment data"},{"metadata":{"trusted":true,"_uuid":"64d5f41ce9fbcf68d024e396f7b6e7b5c733fc45"},"cell_type":"code","source":"def jopen(path):\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        json_file = json.load(f)\n    return json_file\n\n\ndef parse_sentiment_file(path):\n    file = jopen(path)\n    language: str = file[\"language\"]\n\n    sentiment: list = file[\"documentSentiment\"]\n    entities: list = [x[\"name\"] for x in file[\"entities\"]]\n    entity = \" \".join(entities)\n\n    sentence_sentiment: list = [x[\"sentiment\"] for x in file[\"sentences\"]]\n    magnitude: np.ndarray = np.array(\n        [x[\"magnitude\"] for x in sentence_sentiment])\n    score: np.ndarray = np.array([x[\"score\"] for x in sentence_sentiment])\n\n    return_js = {\n        \"magnitude_sum\": magnitude.sum(),\n        \"magnitude_mean\": magnitude.mean(),\n        \"magnitude_var\": magnitude.var(),\n        \"score_sum\": score.sum(),\n        \"score_mean\": score.mean(),\n        \"score_var\": score.var(),\n        \"language\": language,\n        \"entity\": entity,\n        \"document_magnitude\": sentiment[\"magnitude\"],\n        \"document_score\": sentiment[\"score\"]\n    }\n    return return_js\n\n\ndef parse_metadata(path):\n    file: dict = jopen(path)\n    file_keys = list(file.keys())\n    if \"labelAnnotations\" in file_keys:\n        file_annots = file[\"labelAnnotations\"]\n        file_mean_score = np.asarray([x[\"score\"] for x in file_annots]).mean()\n        file_desc = \" \".join([x[\"description\"] for x in file_annots])\n    else:\n        file_mean_score = np.nan\n        file_desc = \"\"\n\n    file_colors: list = file[\"imagePropertiesAnnotation\"][\"dominantColors\"][\n        \"colors\"]\n    file_crops: list = file[\"cropHintsAnnotation\"][\"cropHints\"]\n\n    color_score = np.asarray([x[\"score\"] for x in file_colors]).mean()\n    pixel_frac = np.asarray([x[\"pixelFraction\"] for x in file_colors]).mean()\n    crop_conf = np.asarray([x[\"confidence\"] for x in file_crops]).mean()\n\n    if \"importanceFraction\" in file_crops[0].keys():\n        crop_importance = np.asarray(\n            [x[\"importanceFraction\"] for x in file_crops]).mean()\n    else:\n        crop_importance = np.nan\n    metadata = {\n        \"annot_score\": file_mean_score,\n        \"color_score\": color_score,\n        \"pixel_frac\": pixel_frac,\n        \"crop_conf\": crop_conf,\n        \"crop_importance\": crop_importance,\n        \"desc\": file_desc\n    }\n    return metadata\n\n\ndef additinal_features_per_id(pet_id, sentiment_path: Path, meta_path: Path):\n    sentiment_path = sentiment_path / f\"{pet_id}.json\"\n    try:\n        sentiment = parse_sentiment_file(sentiment_path)\n        sentiment[\"pet_id\"] = pet_id\n    except FileNotFoundError:\n        sentiment = {}\n\n    meta_files = sorted(meta_path.glob(f\"{pet_id}*.json\"))\n    metadata_list = []\n    if len(meta_files) > 0:\n        for f in meta_files:\n            metadata = parse_metadata(f)\n            metadata[\"pet_id\"] = pet_id\n            metadata_list.append(metadata)\n    return sentiment, metadata_list\n\n\ndef load_additional_features(ped_ids: list, sentiment_path: Path,\n                             meta_path: Path):\n    features = Parallel(\n        n_jobs=-1, verbose=1)(\n            delayed(additinal_features_per_id)(i, sentiment_path, meta_path)\n            for i in ped_ids)\n    sentiments = [x[0] for x in features if len(x[0]) > 0]\n    metadatas = [x[1] for x in features if len(x[1]) > 0]\n    sentiment_keys = sentiments[0].keys()\n    metadata_keys = metadatas[0][0].keys()\n    sentiment_dict = {}\n    metadata_dict = {}\n    for key in sentiment_keys:\n        sentiment_dict[key] = [x[key] for x in sentiments]\n\n    for key in metadata_keys:\n        meta_list = []\n        for meta_per_pid in metadatas:\n            meta_list += [meta[key] for meta in meta_per_pid]\n        metadata_dict[key] = meta_list\n\n    sentiment_df = pd.DataFrame(sentiment_dict)\n    metadata_df = pd.DataFrame(metadata_dict)\n    return sentiment_df, metadata_df\n\n\ndef aggregate_metadata(metadata_df: pd.DataFrame,\n                       aggregates=[\"sum\", \"mean\", \"var\"]):\n    meta_desc: pd.DataFrame = metadata_df.groupby([\"pet_id\"])[\"desc\"].unique()\n    meta_desc = meta_desc.reset_index()\n    meta_desc[\"desc\"] = meta_desc[\"desc\"].apply(lambda x: \" \".join(x))\n\n    meta_gr: pd.DataFrame = metadata_df.drop([\"desc\"], axis=1)\n    for i in meta_gr.columns:\n        if \"pet_id\" not in i:\n            meta_gr[i] = meta_gr[i].astype(float)\n    meta_gr = meta_gr.groupby([\"pet_id\"]).agg(aggregates)\n    meta_gr.columns = pd.Index(\n        [f\"{c[0]}_{c[1].upper()}\" for c in meta_gr.columns.tolist()])\n    meta_gr = meta_gr.reset_index()\n    return meta_gr, meta_desc\n\n\ndef aggregate_sentiment(sentiment_df: pd.DataFrame, aggregates=[\"sum\"]):\n    sentiment_desc: pd.DataFrame = sentiment_df.groupby(\n        [\"pet_id\"])[\"entity\"].unique()\n    sentiment_desc = sentiment_desc.reset_index()\n    sentiment_desc[\"entity\"] = sentiment_desc[\"entity\"].apply(\n        lambda x: \" \".join(x))\n    sentiment_lang = sentiment_df.groupby(\n        [\"pet_id\"])[\"language\"].unique()\n    sentiment_lang = sentiment_lang.reset_index()\n    sentiment_lang[\"language\"] = sentiment_lang[\"language\"].apply(\n        lambda x: \" \".join(x))\n    sentiment_desc = sentiment_desc.merge(\n        sentiment_lang, how=\"left\", on=\"pet_id\")\n    \n\n    sentiment_gr: pd.DataFrame = sentiment_df.drop([\"entity\", \"language\"],\n                                                   axis=1)\n    for i in sentiment_gr.columns:\n        if \"pet_id\" not in i:\n            sentiment_gr[i] = sentiment_gr[i].astype(float)\n    sentiment_gr = sentiment_gr.groupby([\"pet_id\"]).agg(aggregates)\n    sentiment_gr.columns = pd.Index(\n        [f\"{c[0]}\" for c in sentiment_gr.columns.tolist()])\n    sentiment_gr = sentiment_gr.reset_index()\n    return sentiment_gr, sentiment_desc","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"## Load data"},{"metadata":{"trusted":true,"_uuid":"a2a404fac56478b68955bfb8f2ab4cd17a34d5cb"},"cell_type":"code","source":"input_dir = Path(\"../input/petfinder-adoption-prediction/\")\ntrain = pd.read_csv(input_dir / \"train/train.csv\")\ntest = pd.read_csv(input_dir / \"test/test.csv\")\nsample_submission = pd.read_csv(input_dir / \"test/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5bd906850dc0ed9476140b7fa0835bcef8c57b64"},"cell_type":"code","source":"sp_train = input_dir / Path(\"train_sentiment/\")\nmp_train = input_dir / Path(\"train_metadata/\")\nsp_test = input_dir / Path(\"test_sentiment/\")\nmp_test = input_dir / Path(\"test_metadata/\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5a60150bcae8f4bef0ad91c425ecc41e1f97b02d"},"cell_type":"code","source":"train_pet_ids = train.PetID.unique()\ntest_pet_ids = test.PetID.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"80ea8fba883636520ffc0e200278a5097ca20ee6"},"cell_type":"code","source":"train_sentiment_df, train_metadata_df = load_additional_features(\n    train_pet_ids, sp_train, mp_train)\n\ntest_sentiment_df, test_metadata_df = load_additional_features(\n    test_pet_ids, sp_test, mp_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9e363a35cd0ef7aac5b7dabdd376478565bcaeea"},"cell_type":"markdown","source":"## Aggregate sentiment data and metadata"},{"metadata":{"trusted":true,"_uuid":"ddc55fc2f3b0ee50ff60d58908f9eb8d7fcad780"},"cell_type":"code","source":"train_meta_gr, train_meta_desc = aggregate_metadata(train_metadata_df)\ntest_meta_gr, test_meta_desc = aggregate_metadata(test_metadata_df)\ntrain_sentiment_gr, train_sentiment_desc = \\\n    aggregate_sentiment(train_sentiment_df)\ntest_sentiment_gr, test_sentiment_desc = \\\n    aggregate_sentiment(test_sentiment_df)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2badeaca2206cdf6a224e7225385ef9440b8a3dd"},"cell_type":"markdown","source":"## Merge processed DataFrames with base train/test DataFrame"},{"metadata":{"trusted":true,"_uuid":"7c9807588b2fe960b1f96eeb07b908505dd9b3f0"},"cell_type":"code","source":"train_proc = train.copy()\ntrain_proc = train_proc.merge(\n    train_sentiment_gr, how=\"left\", left_on=\"PetID\", right_on=\"pet_id\")\ntrain_proc = train_proc.merge(\n    train_meta_gr, how=\"left\", left_on=\"PetID\", right_on=\"pet_id\")\ntrain_proc = train_proc.merge(\n    train_sentiment_desc, how=\"left\", left_on=\"PetID\", right_on=\"pet_id\")\ntrain_proc = train_proc.merge(\n    train_meta_desc, how=\"left\", left_on=\"PetID\", right_on = \"pet_id\")\n\ntest_proc = test.copy()\ntest_proc = test_proc.merge(\n    test_sentiment_gr, how=\"left\", left_on=\"PetID\", right_on=\"pet_id\")\ntest_proc = test_proc.merge(\n    test_meta_gr, how=\"left\", left_on=\"PetID\", right_on=\"pet_id\")\ntest_proc = test_proc.merge(\n    test_sentiment_desc, how=\"left\", left_on=\"PetID\", right_on=\"pet_id\")\ntest_proc = test_proc.merge(\n    test_meta_desc, how=\"left\", left_on=\"PetID\", right_on = \"pet_id\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2468fdc9fe6a99059fc3ec87213638fcd843b4d8"},"cell_type":"code","source":"print(train_proc.shape, test_proc.shape)\nassert train_proc.shape[0] == train.shape[0]\nassert test_proc.shape[0] == test.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5e5cbe9287fd8150b83a3044f6f5c344bd68ac72"},"cell_type":"code","source":"train_proc.drop(train_proc.filter(\n    regex=\"pet_id\", axis=1).columns.tolist(), \n    axis=1, \n    inplace=True)\n\ntest_proc.drop(test_proc.filter(\n    regex=\"pet_id\", axis=1).columns.tolist(),\n    axis=1,\n    inplace=True)\n\ntrain_proc.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a4d3c3cd67a16af0bcdea52392a1a107995cd0a2"},"cell_type":"code","source":"train_proc.language.fillna(\"\", inplace=True)\ntest_proc.language.fillna(\"\", inplace=True)\n\nlangs = train_proc.language.unique()\nencode_dict = {k: i for i, k in enumerate(langs)}\n\ntrain_proc.language = train_proc.language.map(encode_dict)\ntest_proc.language = test_proc.language.map(encode_dict)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c492c2a290bb067d0dc656733054d0ae44ab73bf"},"cell_type":"markdown","source":"## Feature engineering"},{"metadata":{"trusted":true,"_uuid":"ce8d622672d743f5e746549d3ac85478f21c0d31"},"cell_type":"code","source":"X = pd.concat([train_proc, test_proc], ignore_index=True, sort=False)\nX_temp = X.copy()\n\ntext_columns = [\n    \"Description\",\n    \"entity\",\n    \"desc\"]\ncategorical_columns = [\n    \"Type\", \"Breed1\", \"Breed2\", \"Gender\",\n    \"Color1\", \"Color2\", \"Color3\", \"MaturitySize\",\n    \"FurLength\", \"Vaccinated\", \"Dewormed\", \"Sterilized\",\n    \"State\", \"language\"\n]\ndrop_columns = [\n    \"PetID\", \"Name\", \"RescuerID\"\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b99158aab0fa54886a2fd8066d5b6bf5b073d781"},"cell_type":"code","source":"rescuer_count = X.groupby([\"RescuerID\"])[\"PetID\"].count().reset_index()\nrescuer_count.columns = [\"RescuerID\", \"RescuerID_COUNT\"]\n\nX_temp = X_temp.merge(rescuer_count, how=\"left\", on=\"RescuerID\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c65e045184826428d9074a13caa185ffd8793999"},"cell_type":"code","source":"X_text = X_temp[text_columns]\nfor i in X_text.columns:\n    X_text.loc[:, i] = X_text.loc[:, i].fillna(\"none\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"000e0e05491ac479349ffe40d8146f912d00c1d5"},"cell_type":"code","source":"X_temp[\"len_description\"] = X_text[\"Description\"].map(len)\nX_temp[\"len_meta_desc\"] = X_text[\"desc\"].map(len)\nX_temp[\"len_entity\"] = X_text[\"entity\"].map(len)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4aa6be7a80659bf78178766f53dfea7af91d06b6"},"cell_type":"markdown","source":"## Tfidf"},{"metadata":{"trusted":true,"_uuid":"95de8074d85b1b8c42c3b209dfed4a8903d5a673"},"cell_type":"code","source":"n_components = 16\ntext_features = []\n\nfor i in X_text.columns:\n    print(f\"generating features from: {i}\")\n    tfv = TfidfVectorizer(\n        min_df=2,\n        strip_accents=\"unicode\",\n        analyzer=\"word\",\n        token_pattern=r\"(?u)\\b\\w+\\b\",\n        ngram_range=(1, 3),\n        use_idf=1,\n        smooth_idf=1,\n        sublinear_tf=1)\n    svd = TruncatedSVD(\n        n_components=n_components,\n        random_state=1337)\n    tfidf_col = tfv.fit_transform(X_text.loc[:, i].values)\n    svd_col = svd.fit_transform(tfidf_col)\n    svd_col = pd.DataFrame(svd_col)\n    svd_col = svd_col.add_prefix(\"Tfidf_{}_\".format(i))\n    \n    text_features.append(svd_col)\n\ntext_features = pd.concat(text_features, axis=1)\nX_temp = pd.concat([X_temp, text_features], axis=1)\n\nfor i in X_text.columns:\n    X_temp.drop(i, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4f43400c8d2ce34ef6db94049bc215be6de528fd"},"cell_type":"markdown","source":"## Image size features"},{"metadata":{"trusted":true,"_uuid":"190f69f684f76dc03a93040cda0f12bb9ef190b8"},"cell_type":"code","source":"import os\nimport glob\n\ntrain_image_files = sorted(\n    glob.glob(\"../input/petfinder-adoption-prediction/train_images/*.jpg\"))\ntest_image_files = sorted(\n    glob.glob(\"../input/petfinder-adoption-prediction/test_images/*.jpg\"))\n\ntrain_df_imgs = pd.DataFrame(train_image_files)\ntest_df_imgs = pd.DataFrame(test_image_files)\ntrain_df_imgs.columns = [\"image_file_name\"]\ntest_df_imgs.columns = [\"image_file_name\"]\n\ntrain_imgs_pets = train_df_imgs[\"image_file_name\"].apply(\n    lambda x: x.split(\"/\")[-1].split(\"-\")[0])\ntest_imgs_pets = test_df_imgs[\"image_file_name\"].apply(\n    lambda x: x.split(\"/\")[-1].split(\"-\")[0])\ntrain_df_imgs = train_df_imgs.assign(PetID=train_imgs_pets)\ntest_df_imgs = test_df_imgs.assign(PetID=test_imgs_pets)\n\ndef get_size(filename):\n    st = os.stat(filename)\n    return st.st_size\n\ndef get_dimensions(filename):\n    img_size = Image.open(filename).size\n    return img_size\n\ntrain_df_imgs[\"image_size\"] = train_df_imgs[\"image_file_name\"].apply(get_size)\ntest_df_imgs[\"image_size\"] = test_df_imgs[\"image_file_name\"].apply(get_size)\ntrain_df_imgs[\"temp_size\"] = train_df_imgs[\"image_file_name\"].apply(get_dimensions)\ntest_df_imgs[\"temp_size\"] = test_df_imgs[\"image_file_name\"].apply(get_dimensions)\ntrain_df_imgs[\"width\"] = train_df_imgs[\"temp_size\"].apply(lambda x: x[0])\ntest_df_imgs[\"width\"] = test_df_imgs[\"temp_size\"].apply(lambda x: x[0])\ntrain_df_imgs[\"height\"] = train_df_imgs[\"temp_size\"].apply(lambda x: x[1])\ntest_df_imgs[\"height\"] = test_df_imgs[\"temp_size\"].apply(lambda x: x[1])\ntrain_df_imgs.drop([\"temp_size\"], axis=1, inplace=True)\ntest_df_imgs.drop([\"temp_size\"], axis=1, inplace=True)\n\naggs = {\n    \"image_size\": [\"sum\", \"mean\", \"var\"],\n    \"width\": [\"sum\", \"mean\", \"var\"],\n    \"height\": [\"sum\", \"mean\", \"var\"]\n}\nagg_train_imgs = train_df_imgs.groupby(\"PetID\").agg(aggs)\nnew_columns = [\n    k + \"_\" + agg for k in aggs.keys() for agg in aggs[k]\n]\nagg_test_imgs = test_df_imgs.groupby(\"PetID\").agg(aggs)\nagg_train_imgs.columns = new_columns\nagg_train_imgs = agg_train_imgs.reset_index()\n\nagg_test_imgs.columns = new_columns\nagg_test_imgs = agg_test_imgs.reset_index()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f1e67fa6e8b1c1deac413010b7ed9b9d43234f92"},"cell_type":"code","source":"agg_imgs = pd.concat([agg_train_imgs, agg_test_imgs], axis=0).reset_index(drop=True)\nX_temp = X_temp.merge(agg_imgs, how=\"left\", on=\"PetID\")\nX_temp.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"629ec15f165fb4faf8051671f07abfaa2e6872df"},"cell_type":"markdown","source":"## Drop columns"},{"metadata":{"trusted":true,"_uuid":"0034fb4f78cd5cc6c26a762642deb73276303c9e"},"cell_type":"code","source":"X_temp.drop(drop_columns, axis=1, inplace=True)\nX_temp.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fcb6af3b9ea9a2b894fbc778bdccbda4caa9595d"},"cell_type":"code","source":"for c in new_columns:\n    X_temp.loc[:, c] = X_temp[c].map(lambda x: np.log1p(x))\n    \nX_temp.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2fd332396f3d3e5bcecf987cb038805b812bfd7d"},"cell_type":"code","source":"X_train = X_temp.loc[np.isfinite(X_temp.AdoptionSpeed), :]\nX_test = X_temp.loc[~np.isfinite(X_temp.AdoptionSpeed), :]\nX_test.drop([\"AdoptionSpeed\"], axis=1, inplace=True)\n\nassert X_train.shape[0] == train.shape[0]\nassert X_test.shape[0] == test.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6bd7866671af382a793076e81bc9b6732b66dbd4"},"cell_type":"code","source":"train_cols = X_train.columns.tolist()\ntrain_cols.remove(\"AdoptionSpeed\")\n\ntest_cols = X_test.columns.tolist()\nassert np.all(train_cols == test_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ebbbcb8c426fd7ca62fd54a8334c5bad226dd78e"},"cell_type":"code","source":"X_train_non_null = X_train.fillna(-1)\nX_test_non_null = X_test.fillna(-1)\n\nX_train_non_null.isnull().any().any(), X_test_non_null.isnull().any().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d48bcad91d179b0ff030e3616e9844a3c90c4465"},"cell_type":"code","source":"X_train_non_null.Fee = X_train_non_null.Fee.map(lambda x: np.log1p(x))\nX_test_non_null.Fee = X_test_non_null.Fee.map(lambda x: np.log1p(x))\n\nX_train_non_null.RescuerID_COUNT = X_train_non_null.RescuerID_COUNT.map(lambda x: np.log(x))\nX_test_non_null.RescuerID_COUNT = X_test_non_null.RescuerID_COUNT.map(lambda x: np.log(x))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4fa273d5d3538864c5839a6de6aba0a343a8d530"},"cell_type":"code","source":"cat_features = [\"Type\", \"Breed1\", \"Breed2\", \"Gender\", \"Color1\", \"Color2\", \"Color3\",\n                \"MaturitySize\", \"FurLength\", \"Vaccinated\", \"Dewormed\", \"Sterilized\",\n                \"Health\", \"Quantity\", \"State\", \"language\"]\n\nX_train_cat = X_train_non_null.loc[:, cat_features]\nX_test_cat = X_test_non_null.loc[:, cat_features]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"058b7fbb860473d9a65f65400de195cddd6d932c"},"cell_type":"markdown","source":"## Categorical Target Encoding"},{"metadata":{"trusted":true,"_uuid":"6105f6ef169df736d238d7a978c040a2f6a8cd16"},"cell_type":"code","source":"y = X_train_non_null.AdoptionSpeed\nX_train_cat_y = X_train_cat.copy()\nX_train_cat_y[\"AdoptionSpeed\"] = y\n\nkfold = GroupKFold(n_splits=5)\nX_train_cat_encoded = np.zeros((X_train_cat.shape[0], len(cat_features) * 2))\nX_test_cat_encoded = np.zeros((X_test_cat.shape[0], len(cat_features) * 2))\n\nfor trn_idx, val_idx in kfold.split(X_train_cat, y, train_pet_ids):\n    X_trn, X_val = X_train_cat_y.loc[trn_idx, :], X_train_cat_y.loc[val_idx, :]\n    for j, c in enumerate(cat_features):\n        X_trn_enc = X_trn.groupby(c).agg({\n            \"AdoptionSpeed\": [\"mean\", \"std\"]\n        })\n        cte_columns = [f\"{c}_{x}\" for x in [\"mean\", \"std\"]]\n        X_trn_enc.columns = cte_columns\n        X_temp = np.zeros((X_test_cat.shape[0], 2))\n        X_temp_df = pd.DataFrame(data=X_temp, columns=cte_columns)\n        for x in X_trn_enc.columns:\n            X_val[x] = X_val[c].map(X_trn_enc[x])\n            X_temp_df[x] = X_test_cat[c].map(X_trn_enc[x]).reset_index(drop=True)\n        X_train_cat_encoded[val_idx, 2 * j:2 * (j + 1)] = X_val[X_trn_enc.columns].values\n        X_test_cat_encoded[:, 2 * j: 2 * (j + 1)] += X_temp_df.values / 5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4f29fd092db829af7253267c2ef4dc6c92f48e73"},"cell_type":"code","source":"X_train_cat_encoded.shape, X_test_cat_encoded.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"17d6dba910e9ef8689a059fe81f3a151a6ce8935"},"cell_type":"code","source":"columns = [f\"{c}_{x}\" for c in cat_features for x in [\"mean\", \"std\"]]\nX_train_cat_encoded_df = pd.DataFrame(data=X_train_cat_encoded, columns=columns)\nX_test_cat_encoded_df = pd.DataFrame(data=X_test_cat_encoded, columns=columns)\nX_test_cat_encoded_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a45e4eb9cee5516325edf586e4a9edd9d1d12e31"},"cell_type":"markdown","source":"## Numerical Features"},{"metadata":{"trusted":true,"_uuid":"8d91fecdf01da92b21e2d05a8ba6d67243b7f9da"},"cell_type":"code","source":"X_train_num = X_train_non_null.drop(cat_features + [\"AdoptionSpeed\"], axis=1)\nX_test_num = X_test_non_null.drop(cat_features, axis=1)\n\ntarget = X_train_non_null[\"AdoptionSpeed\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5ef772ea61eddacbd04b03c29614b94d2d6babf5"},"cell_type":"code","source":"X_train_num = pd.concat([X_train_num, X_train_cat_encoded_df], axis=1)\n\nX_test_cat_encoded_df.index = X_test_num.index\nX_test_num = pd.concat([X_test_num, X_test_cat_encoded_df], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3943eac9c119e7c778677861e30428a657264dc8"},"cell_type":"code","source":"X_all_num = pd.concat([X_train_num, X_test_num], axis=0)\nss = StandardScaler()\nss.fit(X_all_num)\n\nX_train_ss = ss.transform(X_train_num)\nX_test_ss = ss.transform(X_test_num)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b20c6270c1a1e13ccf32364b043d6891814f511"},"cell_type":"code","source":"X_train_ss[np.isnan(X_train_ss)] = 0.0\nX_test_ss[np.isnan(X_test_ss)] = 0.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c61099ad98de01c893e42f0691ff4d365ebb9216"},"cell_type":"code","source":"cat_cat = pd.concat([X_train_cat, X_test_cat])\n\nn_breed1 = cat_cat[\"Breed1\"].nunique()\nn_breed2 = cat_cat[\"Breed2\"].nunique()\nn_langs = cat_cat[\"language\"].nunique()\nn_color1 = cat_cat[\"Color1\"].nunique()\nn_color2 = cat_cat[\"Color2\"].nunique()\nn_color3 = cat_cat[\"Color3\"].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e1f47565b9a8ff3d8eeb5f1b34154dde3e71af90"},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfor c in X_train_cat.columns:\n        le = LabelEncoder()\n        le.fit(cat_cat[c])\n        X_train_cat[c] = le.transform(X_train_cat[c])\n        X_test_cat[c] = le.transform(X_test_cat[c])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3b9bd342bf82e03749abc2534f49187794e890a4"},"cell_type":"markdown","source":"## Metrics"},{"metadata":{"trusted":true,"_uuid":"e352a3d956a76b441ff4fdfb0a3d82230f08e48a"},"cell_type":"code","source":"class OptimizedRounder(object):\n    def __init__(self):\n        self.coef_ = 0\n    \n    def _kappa_loss(self, coef, X, y):\n        preds = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3, 4])\n        return -cohen_kappa_score(y, preds, weights='quadratic')\n    \n    def fit(self, X, y, initial_coef=[]):\n        loss_partial = partial(self._kappa_loss, X = X, y = y)\n        initial_coef = initial_coef\n        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n    \n    def predict(self, X, coef):\n        preds = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3, 4])\n        return preds\n    \n    def coefficients(self):\n        return self.coef_['x']\n    \ndef confusion_matrix(rater_a, rater_b, min_rating=None, max_rating=None):\n    assert len(rater_a) == len(rater_b)\n\n    if min_rating is None:\n        min_rating = min(rater_a + rater_b)\n    if max_rating is None:\n        max_rating = max(rater_a + rater_b)\n    num_rating = int(max_rating - min_rating + 1)\n    conf_mat = [[0 for i in range(num_rating)] for j in range(num_rating)]\n    for a, b in zip(rater_a, rater_b):\n        conf_mat[a - min_rating][b - min_rating] += 1\n    return conf_mat\n\n\ndef histogram(ratings, min_rating=None, max_rating=None):\n    if min_rating is None:\n        min_rating = min(ratings)\n    if max_rating is None:\n        max_rating = max(ratings)\n    num_ratings = int(max_rating - min_rating + 1)\n    hist_ratings = [0 for x in range(num_ratings)]\n    for r in ratings:\n        hist_ratings[r - min_rating] += 1\n    return hist_ratings\n\n\ndef quadratic_weighted_kappa(y, y_pred):\n    rater_a = y\n    rater_b = y_pred\n    min_rating = None\n    max_rating = None\n    rater_a = np.array(rater_a, dtype=int)\n    rater_b = np.array(rater_b, dtype=int)\n\n    assert len(rater_a) == len(rater_b)\n\n    min_rating = min(min(rater_a), min(rater_b))\n    max_rating = max(max(rater_a), max(rater_b))\n\n    conf_mat = confusion_matrix(rater_a, rater_b, min_rating, max_rating)\n    num_ratings = len(conf_mat)\n    num_scored_items = float(len(rater_a))\n\n    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n\n    numerator = 0.0\n    denominator = 0.0\n\n    for i in range(num_ratings):\n        for j in range(num_ratings):\n            expected_count = (\n                hist_rater_a[i] * hist_rater_b[j]) / num_scored_items\n            d = pow(i - j, 2.0) / pow(num_ratings - 1, 2.0)\n            numerator += d * conf_mat[i][j] / num_scored_items\n            denominator += d * expected_count / num_scored_items\n\n    return (1.0 - numerator / denominator)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"843c82870b00649db3d27335587d388b6c09f5ca"},"cell_type":"markdown","source":"## DataLoader"},{"metadata":{"trusted":true,"_uuid":"c783d7639653290fd2654b6f940de6e5476a8af7"},"cell_type":"code","source":"class PetDataset(data.Dataset):\n    def __init__(self, \n                 pet_ids, \n                 cat_features, \n                 num_features, \n                 labels, \n                 root_dir, \n                 subset=False, \n                 transform=None):\n        self.pet_ids = pet_ids\n        self.cat_features = cat_features\n        self.num_features = num_features\n        if labels is not None:\n            self.labels = labels\n        else:\n            self.labels = None\n        self.root_dir = root_dir\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.pet_ids)\n    \n    def __getitem__(self, idx):\n        img_name = f\"{self.pet_ids[idx]}-1.jpg\"\n        fullname = self.root_dir / Path(img_name)\n        try:\n            image = Image.open(fullname).convert(\"RGB\")\n        except FileNotFoundError:\n            image = np.zeros((3, 224, 224), dtype=np.uint8).transpose(1, 2, 0)\n            image = Image.fromarray(np.uint8(image))\n        cat_feature = self.cat_features[idx]\n        num_feature = self.num_features[idx]\n        if self.transform:\n            image = self.transform(image)\n\n        if self.labels is not None:\n            label = self.labels[idx]\n            return [image, cat_feature, num_feature, label]\n        else:\n            return [image, cat_feature, num_feature]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"84a47aeafef8e174a330047c994ea7cab120b88d"},"cell_type":"code","source":"normalize = transforms.Normalize(\n    mean=[0.485, 0.456, 0.406],\n    std=[0.229, 0.224, 0.225]\n)\nds_trans = transforms.Compose([transforms.Resize(224),\n                               transforms.CenterCrop(224),\n                               transforms.ToTensor(),\n                               normalize])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"03c9f5c917def1297f4685e009ef70b21faca3ad"},"cell_type":"markdown","source":"## Trainer"},{"metadata":{"trusted":true,"_uuid":"0dc8f13b4e1311519e85048912cc7701863c6145"},"cell_type":"code","source":"def get_n_params(model):\n    pp=0\n    for p in list(model.parameters()):\n        nn=1\n        for s in list(p.size()):\n            nn = nn*s\n        pp += nn\n    return pp\n\ndef seed_torch(seed=1029):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n\ndef run_xgb(params,\n            X,\n            y,\n            X_test,\n            resc,\n            n_splits=10,\n            num_rounds=60000,\n            early_stop=500,\n            verbose_eval=1000):\n    fold = GroupKFold(n_splits=n_splits)\n    oof_train = np.zeros((X.shape[0]))\n    oof_test = np.zeros((X_test.shape[0], n_splits))\n\n    for i, (trn_index, val_index) in enumerate(fold.split(X, y, train_pet_ids)):\n        X_tr = X.iloc[trn_index, :]\n        X_val = X.iloc[val_index, :]\n\n        y_tr = y[trn_index]\n        y_val = y[val_index]\n        d_train = xgb.DMatrix(\n            data=X_tr, label=y_tr, feature_names=X_tr.columns)\n        d_valid = xgb.DMatrix(\n            data=X_val, label=y_val, feature_names=X_val.columns)\n\n        watchlist = [(d_train, \"train\"), (d_valid, \"valid\")]\n        model = xgb.train(\n            params=params,\n            dtrain=d_train,\n            num_boost_round=num_rounds,\n            evals=watchlist,\n            early_stopping_rounds=early_stop,\n            verbose_eval=verbose_eval)\n        valid_pred = model.predict(\n            xgb.DMatrix(X_val, feature_names=X_val.columns),\n            ntree_limit=model.best_ntree_limit)\n        test_pred = model.predict(\n            xgb.DMatrix(X_test, feature_names=X_test.columns),\n            ntree_limit=model.best_ntree_limit)\n        oof_train[val_index] = valid_pred\n        oof_test[:, i] = test_pred\n    return model, oof_train, oof_test\n\n\nclass Trainer:\n    def __init__(self, \n                 model,\n                 resc,\n                 n_splits=5, \n                 seed=42, \n                 device=\"cuda:0\", \n                 train_batch=16,\n                 val_batch=32,\n                 kwargs={}):\n        self.model = model\n        self.resc = resc\n        self.n_splits = n_splits\n        self.seed = seed\n        self.device = device\n        self.train_batch = train_batch\n        self.val_batch = val_batch\n        self.kwargs = kwargs\n        \n        self.fold = GroupKFold(\n            n_splits=n_splits)\n        self.best_score = None\n        self.tag = dt.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n        \n        self.loss_fn = nn.MSELoss(reduction=\"mean\").to(self.device)\n        path = Path(f\"bin/{self.tag}\")\n        path.mkdir(exist_ok=True, parents=True)\n        self.path = path\n        \n    def fit(self, pet_ids, cat_feats, num_feats, answer, n_epochs=30):\n        self.train_preds = np.zeros((train.shape[0]))\n        answer = answer.values\n        cat_feats = cat_feats.values\n        for i, (trn_idx, val_idx) in enumerate(self.fold.split(pet_ids, answer, self.resc)):\n            self.fold_num = i\n            print(f\"Fold: {i+1}\")\n            pid_train, pid_val = pet_ids[trn_idx], pet_ids[val_idx]\n            cat_train, cat_val = cat_feats[trn_idx], cat_feats[val_idx]\n            num_train, num_val = num_feats[trn_idx], num_feats[val_idx]\n            y_train, y_val = answer[trn_idx] / 4, answer[val_idx] / 4\n            \n            valid_preds = self._fit(pid_train, \n                                    cat_train, \n                                    num_train, \n                                    y_train,\n                                    n_epochs,\n                                    pid_val,\n                                    cat_val,\n                                    num_val,\n                                    y_val\n                                   )\n            self.train_preds[val_idx] = valid_preds\n        \n    def _fit(self, pid, cat, num, y, n_epochs, pid_val, cat_val, num_val, y_val):\n        seed_torch(self.seed)\n        cat_tensor = torch.tensor(cat, dtype=torch.long).to(self.device)\n        num_tensor = torch.tensor(num, dtype=torch.float32).to(self.device)\n        y_tensor = torch.tensor(y[:, np.newaxis], dtype=torch.float32).to(self.device)\n        train = PetDataset(pid, \n                           cat_tensor, \n                           num_tensor, \n                           y_tensor,\n                           \"../input/petfinder-adoption-prediction/train_images/\",\n                           transform=ds_trans)\n        train_loader = data.DataLoader(train, \n                                       batch_size=self.train_batch, shuffle=True)\n        cat_eval = torch.tensor(cat_val, dtype=torch.long).to(self.device)\n        num_eval = torch.tensor(num_val, dtype=torch.float32).to(self.device)\n        y_eval = torch.tensor(y_val[:, np.newaxis], dtype=torch.float32).to(self.device)\n        eval_ = PetDataset(pid_val,\n                           cat_eval,\n                           num_eval,\n                           y_eval,\n                           \"../input/petfinder-adoption-prediction/train_images/\",\n                           transform=ds_trans)\n        eval_loader = data.DataLoader(eval_,\n                                      batch_size=self.val_batch, shuffle=False)\n        \n        model = self.model(**self.kwargs)\n        model = model.to(self.device)\n        optimizer = optim.Adam(model.parameters())\n        best_score = np.inf\n        \n        for epoch in range(n_epochs):\n            model.train()\n            avg_loss = 0.\n            for i_batch, c_batch, n_batch, y_batch in tqdm(train_loader):\n                i_batch = i_batch.to(self.device)\n                y_pred = model(i_batch, c_batch, n_batch)\n                loss = self.loss_fn(y_pred, y_batch)\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n                avg_loss += loss.item() / len(train_loader)\n            valid_preds, avg_val_loss = self._val(eval_loader, model)\n            print(f\"epoch {epoch+1}/{n_epochs}\")\n            print(f\"avg_loss: {avg_loss:.4f}\")\n            print(f\"avg_val_loss: {avg_val_loss:.4f}\")\n            if best_score > avg_val_loss:\n                torch.save(model.state_dict(),\n                           self.path / f\"best{self.fold_num}.pt\")\n                print(f\"Save model on epoch {epoch + 1}\")\n                best_score = avg_val_loss\n        model.load_state_dict(torch.load(self.path / f\"best{self.fold_num}.pt\"))\n        valid_preds, avg_val_loss = self._val(eval_loader, model)\n        print(f\"Validation loss: {avg_val_loss}\")\n        return valid_preds\n    \n    def _val(self, loader, model):\n        model.eval()\n        valid_preds = np.zeros(loader.dataset.cat_features.size(0))\n        avg_val_loss = 0.\n\n        for i, (i_batch, c_batch, n_batch, y_batch) in enumerate(loader):\n            with torch.no_grad():\n                i_batch = i_batch.to(self.device)\n                y_pred = model(i_batch, c_batch, n_batch).detach()\n                avg_val_loss += self.loss_fn(y_pred,\n                                             y_batch).item() / len(loader)\n                valid_preds[i * self.val_batch:(i + 1) * self.val_batch] = y_pred.cpu().numpy()[:, 0]\n        return valid_preds, avg_val_loss\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"81f45cdbc8ee4bd0f11c545461b9ea090f358f8e"},"cell_type":"code","source":"class NeuralNet(nn.Module):\n    def __init__(self, path, emb_dims, num_dims, img_linear, linear_size):\n        super(NeuralNet, self).__init__()\n        self.densenet121 = models.densenet121()\n        self.densenet121.load_state_dict(torch.load(path))\n        self.densenet121.classifier = nn.Linear(1024, img_linear)\n        dense = nn.Sequential(*list(self.densenet121.children())[:-1])\n        for param in dense.parameters():\n            param.requires_grad = False\n\n        self.embeddings = nn.ModuleList(\n            [nn.Embedding(x, y) for x, y in emb_dims])\n        n_emb_out = sum([y for x, y in emb_dims])\n        self.fc1 = nn.Linear(img_linear + n_emb_out + num_dims, linear_size)\n        self.bn1 = nn.BatchNorm1d(linear_size)\n        self.fc2 = nn.Linear(linear_size, 1)\n        self.drop = nn.Dropout(0.2)\n        self.relu = nn.ReLU()\n\n    def forward(self, i, c, n):\n        img_feats = self.densenet121(i)\n        emb = [\n            emb_layer(c[:, j]) for j, emb_layer in enumerate(self.embeddings)\n        ]\n        emb = torch.cat(emb, 1)\n        data = torch.cat([img_feats, emb, n], 1)\n        out = self.relu(self.fc1(data))\n        out = self.bn1(out)\n        out = self.drop(out)\n        out = self.fc2(out)\n        return out","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4ac9701aff07421363ecbbe2d9dc3720f06e1eaa"},"cell_type":"markdown","source":"## Train"},{"metadata":{"trusted":true,"_uuid":"6e889da94644054a0d19c79a2b202784cb04eb37"},"cell_type":"code","source":"emb_dims = [(2, 1), (n_breed1, 3), (n_breed2, 3), (3, 1), (n_color1, 1),\n            (n_color2, 1), (n_color3, 1), (4, 1), (3, 1), (3, 1),\n            (3, 1), (3, 1), (3, 1), (19, 1), (14, 1),(n_langs, 1)]\nnum_dims = X_test_ss.shape[1]\ntrainer = Trainer(\n    NeuralNet,\n    resc=train_pet_ids,\n    n_splits=4,\n    train_batch=128,\n    val_batch=128,\n    kwargs={\n        \"path\": \"densenet121.pth\",\n        \"emb_dims\": emb_dims,\n        \"num_dims\": num_dims,\n        \"img_linear\": 48,\n        \"linear_size\": 120\n    })","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9686ef36b564f8f0684e62f44305bda521cfbdd9"},"cell_type":"code","source":"trainer.fit(train_pet_ids, X_train_cat, X_train_ss, target, 5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"7771e8ce83030684751573b9b62617bca34ccfdd"},"cell_type":"code","source":"bin_path = trainer.path\ntest_preds = np.zeros((X_test_cat.shape[0]))\nc_tensor = torch.tensor(X_test_cat.values, dtype=torch.long).to(trainer.device)\nn_tensor = torch.tensor(X_test_ss, dtype=torch.float32).to(trainer.device)\ntest_dataset = PetDataset(test_pet_ids, \n                          c_tensor, \n                          n_tensor, \n                          labels=None, \n                          root_dir=\"../input/petfinder-adoption-prediction/test_images/\",\n                          transform=ds_trans)\ntest_loader = data.DataLoader(test_dataset, batch_size=128, shuffle=False)\n\nfor path in bin_path.iterdir():\n    print(f\"using {str(path)}\")\n    model = NeuralNet(**trainer.kwargs)\n    model.to(\"cuda:0\")\n    model.load_state_dict(torch.load(path))\n\n    model.eval()\n    temp = np.zeros((X_test_cat.shape[0]))\n    for i, (i_batch, c_batch, n_batch) in enumerate(test_loader):\n        i_batch = i_batch.to(trainer.device)\n        with torch.no_grad():\n            y_pred = model(i_batch, c_batch, n_batch).detach()\n            temp[i * 128:(i + 1) * 128] = y_pred.cpu().numpy()[:, 0]\n    test_preds += temp / trainer.n_splits","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1b5f8367580c618fe393e3f7703038bd7fdb1304"},"cell_type":"markdown","source":"## Image"},{"metadata":{"trusted":true,"_uuid":"a49e0a579debd3cd7ca95793fed9ac51be81983f"},"cell_type":"code","source":"class ImageDataset(data.Dataset):\n    def __init__(self, pet_ids, root_dir, transform=None):\n        self.pet_ids = pet_ids\n        self.root_dir = root_dir\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.pet_ids)\n    \n    def __getitem__(self, idx):\n        img_name = f\"{self.pet_ids[idx]}-1.jpg\"\n        fullname = self.root_dir / Path(img_name)\n        try:\n            image = Image.open(fullname).convert(\"RGB\")\n        except FileNotFoundError:\n            image = np.zeros((3, 224, 224), dtype=np.uint8).transpose(1, 2, 0)\n            image = Image.fromarray(np.uint8(image))\n        if self.transform:\n            image = self.transform(image)\n            \n        return [image]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f4f183fc0120f4bc4a8fff9598d26e27ac6d5b6a"},"cell_type":"code","source":"train_dataset = ImageDataset(\n    train_pet_ids,\n    \"../input/petfinder-adoption-prediction/train_images/\",\n    transform=ds_trans)\nbatch = 256\nn_img_dim = 48\ntrain_loader = data.DataLoader(train_dataset,\n                               batch_size=batch,\n                               shuffle=False)\nX_train_img = np.zeros((len(train_pet_ids), n_img_dim))\n\ntest_dataset = ImageDataset(\n    test_pet_ids,\n    \"../input/petfinder-adoption-prediction/test_images/\",\n    transform=ds_trans)\ntest_loader = data.DataLoader(test_dataset,\n                              batch_size=batch,\n                              shuffle=False)\nX_test_img = np.zeros((len(test_pet_ids), n_img_dim))\nbin_path = trainer.path\nfor path in bin_path.iterdir():\n    model = NeuralNet(**trainer.kwargs)\n    model.to(\"cuda:0\")\n    model.load_state_dict(torch.load(path))\n    model.eval()\n    temp = np.zeros((len(train_pet_ids), n_img_dim))\n    \n    for i, (i_batch, ) in tqdm(enumerate(train_loader)):\n        with torch.no_grad():\n            i_batch = i_batch.to(\"cuda:0\")\n            y_pred = model.densenet121(i_batch).detach()\n            temp[i * batch:(i + 1) * batch, :] = y_pred.cpu().numpy()\n    X_train_img += temp / trainer.n_splits\n    \n    temp = np.zeros((len(test_pet_ids), n_img_dim))\n    for i, (i_batch, ) in tqdm(enumerate(test_loader)):\n        with torch.no_grad():\n            i_batch = i_batch.to(\"cuda:0\")\n            y_pred = model.densenet121(i_batch).detach()\n            temp[i * batch:(i + 1) * batch, :] = y_pred.cpu().numpy()\n    X_test_img += temp / trainer.n_splits","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"398fff9d745229e06a4d4e40be9cb6a2b85e3ea5"},"cell_type":"code","source":"X_train_img.shape, X_test_img.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dea3e37fd67308876118a9f9eecafa3f4aff97c8"},"cell_type":"code","source":"train_img = pd.DataFrame(data=X_train_img, columns=[\n    f\"img{i}\" for i in range(X_train_img.shape[1])\n])\ntest_img = pd.DataFrame(data=X_test_img, columns=[\n    f\"img{i}\" for i in range(X_test_img.shape[1])\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a30d386881498532f29122ba3c2595bcbdb54e94"},"cell_type":"code","source":"num_columns = X_train_num.columns\nX_train_num_df = pd.DataFrame(data=X_train_ss, columns=num_columns)\nX_test_num_df = pd.DataFrame(data=X_test_ss, columns=num_columns)\n\nX_test_num_df.index = X_test_cat.index\ntest_img.index = X_test_cat.index\n\nX_train_all = pd.concat([X_train_num_df, X_train_cat, train_img], axis=1)\nX_test_all = pd.concat([X_test_num_df, X_test_cat, test_img], axis=1)\n\nprint(X_train_all.shape, X_test_all.shape)\nX_train_all.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"65ff0d0d7c69e4bf64f8288a48b8d8c0ad56a697"},"cell_type":"code","source":"\"AdoptionSpeed\" in X_train_all.columns, \"AdoptionSpeed\" in X_test_all.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8c26f564679be986e701c8db293068ab85e8b654"},"cell_type":"code","source":"X_train_all.columns.tolist() == X_test_all.columns.tolist()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eec84836e1cbfe38066808c7a132aff19e6306ad"},"cell_type":"markdown","source":"## Category Embedding"},{"metadata":{"trusted":true,"_uuid":"5bced7bce730a041d4b9feb6b550235ade506d42"},"cell_type":"code","source":"class CategoryDataset(data.Dataset):\n    def __init__(self, category):\n        self.category = category\n        \n    def __len__(self):\n        return len(self.category)\n    \n    def __getitem__(self, idx):\n        category = self.category[idx, :]\n        return [category]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"76de7b14d557c7fece51f94d3444f3370ab027ec"},"cell_type":"code","source":"c_train = torch.tensor(X_train_cat.values, dtype=torch.long).to(\"cuda:0\")\nc_test = torch.tensor(X_test_cat.values, dtype=torch.long).to(\"cuda:0\")\ntrain_dataset = CategoryDataset(c_train)\ntest_dataset = CategoryDataset(c_test)\ntrain_loader = data.DataLoader(train_dataset, batch_size=128, shuffle=False)\ntest_loader = data.DataLoader(test_dataset, batch_size=128, shuffle=False)\n\nX_train_cat_ = np.zeros((len(train_pet_ids), 20))\nfor i, (c_batch, ) in tqdm(enumerate(train_loader)):\n    with torch.no_grad():\n        y_pred = [model.embeddings[i](c_batch[:, i]) for i in range(len(model.embeddings))]\n        y_pred =torch.cat(y_pred, 1).detach()\n        X_train_cat_[i * 128:(i + 1) * 128, :] = y_pred.cpu().numpy()\n        \nX_test_cat_ = np.zeros((len(test_pet_ids), 20))\nfor i, (c_batch, ) in tqdm(enumerate(test_loader)):\n    with torch.no_grad():\n        y_pred = [model.embeddings[i](c_batch[:, i]) for i in range(len(model.embeddings))]\n        y_pred = torch.cat(y_pred, 1).detach()\n        X_test_cat_[i * 128:(i + 1) * 128, :] = y_pred.cpu().numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"317123c7f3d065a9b88bd159456e845d5bc75d28"},"cell_type":"code","source":"X_train_cat_.shape, X_test_cat_.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3d09ea0c48c79c8b8076041b789054c6c1c9cf93"},"cell_type":"code","source":"train_emb = pd.DataFrame(data=X_train_cat_, columns=[\n    f\"emb{i}\" for i in range(X_train_cat_.shape[1])\n])\ntest_emb = pd.DataFrame(data=X_test_cat_, columns=[\n    f\"emb{i}\" for i in range(X_test_cat_.shape[1])\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3e22008286acb662454c4b48e9d754e5005b4f55"},"cell_type":"code","source":"test_emb.index = X_test_all.index\n\nX_train_all = pd.concat([X_train_all, train_emb], axis=1)\nX_test_all = pd.concat([X_test_all, test_emb], axis=1)\n\nprint(X_train_all.shape, X_test_all.shape)\nX_train_all.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c2a120d1514d355b4a9bd53221c18eb38b857bb1"},"cell_type":"code","source":"xgb_params = {\n    \"eval_metric\": \"rmse\",\n    \"seed\": 1337,\n    \"eta\": 0.01,\n    \"subsample\": 0.75,\n    \"colsample_bytree\": 0.85,\n    \"tree_method\": \"gpu_hist\",\n    \"device\": \"gpu\",\n    \"silent\": 1\n}\n\nxgb_X = X_train_all\nxgb_y = target\nxgb_X_test = X_test_all\n\nmodel, oof_train_xgb, oof_test_xgb= run_xgb(\n    xgb_params, \n    xgb_X, \n    xgb_y, \n    xgb_X_test,\n    resc=train_pet_ids,\n    n_splits=5,\n    num_rounds=10000)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b9f56b5ede55e2272d63f782be65140374528992"},"cell_type":"markdown","source":"## Run LGBM"},{"metadata":{"trusted":true,"_uuid":"a6101913115d0b45f6eb3539ea3fb7622038d8a3"},"cell_type":"code","source":"def run_lgb(params,\n            X,\n            y,\n            X_test,\n            resc,\n            cat_features,\n            n_splits=10,\n            early_stop=500):\n    fold = GroupKFold(n_splits=n_splits)\n    oof_train = np.zeros((X.shape[0]))\n    oof_test = np.zeros((X_test.shape[0], n_splits))\n\n    for i, (trn_index, val_index) in enumerate(fold.split(X, y, resc)):\n        X_tr = X.iloc[trn_index, :]\n        X_val = X.iloc[val_index, :]\n\n        y_tr = y[trn_index]\n        y_val = y[val_index]\n        model = lgb.LGBMRegressor(**params)\n        model.fit(X_tr, \n                  y_tr, \n                  eval_set=(X_val, y_val),\n                  verbose=500,\n                  early_stopping_rounds=early_stop,\n                  categorical_feature=cat_features)\n        valid_pred = model.predict(X_val, num_iteration=model.best_iteration_)\n        test_pred = model.predict(X_test, num_iteration=model.best_iteration_)\n        oof_train[val_index] = valid_pred\n        oof_test[:, i] = test_pred\n    return model, oof_train, oof_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"41baedb9113c5e5febb62683416620e2875806b5"},"cell_type":"code","source":"lgb_params = {\n    \"boosting_type\": \"gbdt\",\n    \"num_leaves\": 127,\n    \"learning_rate\": 0.01,\n    \"n_estimators\": 10000,\n    \"subsample\": 0.75,\n    \"subsample_freq\": 8,\n    \"colsample_bytree\": 0.75,\n    \"reg_alpha\": 0.01,\n    \"reg_lambda\": 0.01,\n    \"n_jobs\": -1\n}\n\nmodel, oof_train, oof_test = run_lgb(\n    lgb_params, \n    xgb_X, \n    xgb_y, \n    xgb_X_test,\n    train_pet_ids,\n    cat_features,\n    n_splits=5,\n    early_stop=500)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a8fe014f27d97225fe8182507ea2b25a56608d2f"},"cell_type":"markdown","source":"## Post process"},{"metadata":{"trusted":true,"_uuid":"96cd36acf1527937b353850b5127e9fdb5f1672b"},"cell_type":"code","source":"def plot_pred(pred):\n    sns.distplot(pred, kde=True, hist_kws={\"range\": [0, 5]})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4bb9e7887a96f658a9d5346213bd102ee053776b"},"cell_type":"code","source":"plot_pred(oof_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7e603980305c9a07e7e8e47e63157218f270464c"},"cell_type":"code","source":"plot_pred(oof_train_xgb)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3978700644bc02faa416bec586c6c5235f5e191d"},"cell_type":"code","source":"oof_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c93732aae83759455f5dd583bd691fe1b1c55fd9"},"cell_type":"code","source":"plot_pred(oof_test.mean(axis=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"392d689d823857cb65635a9a704958dfb08384b6"},"cell_type":"code","source":"plot_pred(oof_test_xgb.mean(1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"461512ba773c98a9e08db4847cd95cbfbab1baba"},"cell_type":"code","source":"plot_pred(trainer.train_preds * 4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"81534882627892ea4d9cfb4e4ecc3e999e0901e2"},"cell_type":"code","source":"plot_pred(test_preds * 4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d17db450bf99cfb3c0e5e0ce8af73e86a21a7cab"},"cell_type":"code","source":"lgb_xgb = 0.5 * oof_train + 0.5 * oof_train_xgb\nlgb_xgb_test = 0.5 * oof_test + 0.5 * oof_test_xgb\nplot_pred(lgb_xgb)\nplot_pred(lgb_xgb_test.mean(1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"61c55611dea702680998f99728ec594687f53225"},"cell_type":"code","source":"nn_preds = np.clip(trainer.train_preds, a_min=0.0, a_max=1.0)\nnn_preds_test = np.clip(test_preds, a_min=0.0, a_max=1.0)\nplot_pred(nn_preds * 4)\nplot_pred(nn_preds_test * 4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"599af7b9c36fe329f2d53a3fda11938727172a81"},"cell_type":"code","source":"lgb_xgb_nn = 0.6 * lgb_xgb + 0.4 * (nn_preds * 4)\nlgb_xgb_nn_test = 0.6 * lgb_xgb_test.mean(1) + 0.4 * nn_preds_test * 4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d3e315bd1f8cacada2fbb38361f900de290d2052"},"cell_type":"code","source":"plot_pred(lgb_xgb_nn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6554c06c2fd88e0066e9a9b9ccb873d458840135"},"cell_type":"code","source":"plot_pred(lgb_xgb_nn_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a169307e292e5460b03198478b242ddc670bdde"},"cell_type":"code","source":"opt = OptimizedRounder()\nopt.fit(lgb_xgb, target, [1.5, 2.0, 2.5, 3.5])\ncoeff = opt.coefficients()\nvalid_pred = opt.predict(lgb_xgb, coeff)\nqwk = quadratic_weighted_kappa(xgb_y, valid_pred)\nprint(\"QWK = \", qwk)\ncoeffs = coeff.copy()\ntrain_predictions = opt.predict(lgb_xgb, coeffs).astype(np.int8)\nprint(f\"train_preds: {Counter(train_predictions)}\")\ntest_predictions = opt.predict(lgb_xgb_test.mean(1), coeffs).astype(np.int8)\nprint(f\"test_preds: {Counter(test_predictions)}\")\nsubmission = pd.DataFrame({\"PetID\": test.PetID.values, \"AdoptionSpeed\": test_predictions})\nsubmission.to_csv(\"submission_xgb_lgb.csv\", index=False)\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b531b191b4961866fd6b86c4a2d2be2b9d65ae51"},"cell_type":"code","source":"opt = OptimizedRounder()\nopt.fit(lgb_xgb_nn, target, [1.5, 2.0, 2.5, 3.5])\ncoeff = opt.coefficients()\nvalid_pred = opt.predict(lgb_xgb_nn, coeff)\nqwk = quadratic_weighted_kappa(xgb_y, valid_pred)\nprint(\"QWK = \", qwk)\ncoeffs = coeff.copy()\ntrain_predictions = opt.predict(lgb_xgb_nn, coeffs).astype(np.int8)\nprint(f\"train_preds: {Counter(train_predictions)}\")\ntest_predictions = opt.predict(lgb_xgb_nn_test, coeffs).astype(np.int8)\nprint(f\"test_preds: {Counter(test_predictions)}\")\nsubmission = pd.DataFrame({\"PetID\": test.PetID.values, \"AdoptionSpeed\": test_predictions})\nsubmission.to_csv(\"submission.csv\", index=False)\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0fa0faa2b48eb4a8502d34f24675fbc511fa5a67"},"cell_type":"code","source":"opt = OptimizedRounder()\nopt.fit(nn_preds * 4, target, [1.5, 2.0, 2.5, 3.5])\ncoeff = opt.coefficients()\nvalid_pred = opt.predict(nn_preds * 4, coeff)\nqwk = quadratic_weighted_kappa(target, valid_pred)\nprint(\"QWK = \", qwk)\ncoeffs = coeff.copy()\ntrain_predictions = opt.predict(nn_preds * 4, coeffs).astype(np.int8)\nprint(f\"train_preds: {Counter(train_predictions)}\")\ntest_predictions = opt.predict(nn_preds_test * 4, coeffs).astype(np.int8)\nprint(f\"test_preds: {Counter(test_predictions)}\")\nsubmission = pd.DataFrame({\"PetID\": test.PetID.values, \"AdoptionSpeed\": test_predictions})\nsubmission.to_csv(\"submission_nn.csv\", index=False)\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b5715f11666185cc44d0425a90b6f702b430cce5"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}