{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 1. Data Overview\n\nRefer to the competition page for details: https://www.kaggle.com/c/petfinder-adoption-prediction/data","metadata":{}},{"cell_type":"code","source":"# Libraries\nimport glob\nimport os\nimport json\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom joblib import Parallel, delayed\nimport gensim\nimport lightgbm as lgb\n\n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Data import\n\n","metadata":{}},{"cell_type":"code","source":"# Helper functions\ndef get_file_names(cat1='train',cat2='metadata'):\n    path = '../input/petfinder-adoption-prediction/'+cat1+'_'+cat2+'/*.json'\n    col_name = cat2+'_filename'\n    fileNames = sorted(glob.glob(path))\n    df_fileNames = pd.DataFrame({col_name:fileNames})\n    df_fileNames['PetID'] = df_fileNames[col_name].apply(lambda x: x.split('/')[-1].split('-')[0])\n    return df_fileNames\n\n\ndef parse_metadata(filename):\n    with open(filename, 'r') as f:\n        file = json.load(f)\n\n        file_keys = list(file.keys())\n\n        if 'labelAnnotations' in file_keys:\n            file_annots = file['labelAnnotations'][:int(len(file['labelAnnotations']) * 0.3)]\n            file_top_score = np.asarray([x['score'] for x in file_annots]).mean()\n            file_top_desc = [x['description'] for x in file_annots]\n        else:\n            file_top_score = np.nan\n            file_top_desc = ['']\n\n        file_colors = file['imagePropertiesAnnotation']['dominantColors']['colors']\n        file_crops = file['cropHintsAnnotation']['cropHints']\n\n        file_color_score = np.asarray([x['score'] for x in file_colors]).mean()\n        file_color_pixelfrac = np.asarray([x['pixelFraction'] for x in file_colors]).mean()\n\n        file_crop_conf = np.asarray([x['confidence'] for x in file_crops]).mean()\n\n        if 'importanceFraction' in file_crops[0].keys():\n            file_crop_importance = np.asarray([x['importanceFraction'] for x in file_crops]).mean()\n        else:\n            file_crop_importance = np.nan\n\n        df_metadata = {\n            'annots_score': file_top_score,\n            'color_score': file_color_score,\n            'color_pixelfrac': file_color_pixelfrac,\n            'crop_conf': file_crop_conf,\n            'crop_importance': file_crop_importance,\n            'annots_top_desc': ' '.join(file_top_desc)\n        }\n\n        df_metadata = pd.DataFrame(df_metadata,index=[0])\n\n        return df_metadata\n        \n        \ndef parse_sentiment(filename):\n    with open(filename, 'r') as f:\n        file = json.load(f)\n        \n        file_sentiment_magnitude = file['documentSentiment']['magnitude']\n        file_sentiment_score = file['documentSentiment']['score']\n        file_entities = [x['name'] for x in file['entities']]\n        file_entities = ' '.join(file_entities)\n        \n        df_sentiment = {\n            'sentiment_magnitude': file_sentiment_magnitude,\n            'sentiment_score': file_sentiment_score,\n            'entities': file_entities\n        }\n        \n        df_sentiment = pd.DataFrame(df_sentiment,index=[0])\n\n        return df_sentiment","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tables from csv\ndf_train = pd.read_csv('../input/petfinder-adoption-prediction/train/train.csv')\ndf_test = pd.read_csv('../input/petfinder-adoption-prediction/test/test.csv')\n\n# Labels from csv\ndf_breed = pd.read_csv('../input/petfinder-adoption-prediction/breed_labels.csv')\ndf_color = pd.read_csv('../input/petfinder-adoption-prediction/color_labels.csv')\ndf_state = pd.read_csv('../input/petfinder-adoption-prediction/state_labels.csv')\n\n# Image metadata from json\ntrain_metadata = get_file_names(cat1='train',cat2='metadata')\ntest_metadata = get_file_names(cat1='test',cat2='metadata')\ntrain_metadata_parse = Parallel(n_jobs=6, verbose=1)(delayed(parse_metadata)(f) for f in train_metadata['metadata_filename'].values)\ntrain_metadata_parse = pd.concat(train_metadata_parse, ignore_index=True, sort=False)\ntest_metadata_parse = Parallel(n_jobs=6, verbose=1)(delayed(parse_metadata)(f) for f in test_metadata['metadata_filename'].values)\ntest_metadata_parse = pd.concat(test_metadata_parse, ignore_index=True, sort=False)\ndf_train_metadata = pd.concat([train_metadata,train_metadata_parse],axis=1)\ndf_test_metadata = pd.concat([test_metadata,test_metadata_parse],axis=1)\n\n# Sentiment data from json\ntrain_sentiment = get_file_names(cat1='train',cat2='sentiment')\ntest_sentiment = get_file_names(cat1='test',cat2='sentiment')\ntrain_sentiment_parse = Parallel(n_jobs=6, verbose=1)(delayed(parse_sentiment)(f) for f in train_sentiment['sentiment_filename'].values)\ntrain_sentiment_parse = pd.concat(train_sentiment_parse, ignore_index=True, sort=False)\ntest_sentiment_parse = Parallel(n_jobs=6, verbose=1)(delayed(parse_sentiment)(f) for f in test_sentiment['sentiment_filename'].values)\ntest_sentiment_parse = pd.concat(test_sentiment_parse, ignore_index=True, sort=False)\ndf_train_sentiment = pd.concat([train_sentiment,train_sentiment_parse],axis=1)\ndf_test_sentiment = pd.concat([test_sentiment,test_sentiment_parse],axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Data processing\n","metadata":{}},{"cell_type":"markdown","source":"### 3.1 Check data types for columns\nFrom the output, we only need to encode annots_top_desc from metadata and entities from sentiment. \n\nWe will apply LDA for encoding the text.","metadata":{}},{"cell_type":"code","source":"print(df_train.dtypes)\nprint(train_metadata_parse.dtypes)\nprint(train_sentiment_parse.dtypes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Helper functions\ndef encodeText(tokens,num_topics=3,passes=5,chunksize=100,alpha=1/50,seed=13):\n    # Create Gensim dic from the tokens\n    lda_dic = gensim.corpora.Dictionary(tokens)\n\n    # Create corpus from the dic\n    lda_corpus = [lda_dic.doc2bow(doc) for doc in tokens]\n\n    # Create tf-idf from corpus\n    tfidf = gensim.models.TfidfModel(lda_corpus)\n    tfidf_corpus = tfidf[lda_corpus]\n\n    # Train model\n    lda_model = gensim.models.ldamodel.LdaModel(tfidf_corpus, num_topics=num_topics, \\\n                                                id2word = lda_dic, passes=passes,\\\n                                                chunksize=chunksize,update_every=0,\\\n                                                alpha=alpha, random_state=seed)\n    # Topic distribution\n    vec_lda = lda_model[tfidf_corpus]\n    \n    return vec_lda\n\ndef formatEncode(vec,num_topics):\n    \"\"\"vec: a list of tuples (topic_id,score)\"\"\"\n    if len(vec)<num_topics:\n        topic_ids = {x[0] for x in vec}\n        topics_diff = set(range(num_topics))-topic_ids\n        vec += [(x,0) for x in topics_diff]\n    vec.sort(key=lambda x: x[0])\n    vec=[x[1] for x in vec]\n    return vec\n\ndef splitEncodeCol(df,col):\n    col_names = [col+str(x) for x in range(len(df[col][0]))]\n    return pd.concat([df,pd.DataFrame(list(df[col]),columns=col_names)],axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.2 Encode metadata\n\n","metadata":{}},{"cell_type":"code","source":"df_train_metadata['annots_top_desc_encode'] = list(encodeText(df_train_metadata['annots_top_desc'].str.split()))\ndf_test_metadata['annots_top_desc_encode'] = list(encodeText(df_test_metadata['annots_top_desc'].str.split()))\ndf_train_metadata['annots_top_desc_encode'] = df_train_metadata['annots_top_desc_encode'].apply(lambda x: formatEncode(x,3))\ndf_test_metadata['annots_top_desc_encode'] = df_test_metadata['annots_top_desc_encode'].apply(lambda x: formatEncode(x,3))\ndf_train_metadata = splitEncodeCol(df_train_metadata,'annots_top_desc_encode')\ndf_test_metadata = splitEncodeCol(df_test_metadata,'annots_top_desc_encode')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.3 Encode sentiment","metadata":{}},{"cell_type":"code","source":"sentiment_topics = 5\ndf_train_sentiment['entities_encode'] = list(encodeText(df_train_sentiment['entities'].str.split(),num_topics=sentiment_topics))\ndf_test_sentiment['entities_encode'] = list(encodeText(df_test_sentiment['entities'].str.split(),num_topics=sentiment_topics))\ndf_train_sentiment['entities_encode'] = df_train_sentiment['entities_encode'].apply(lambda x: formatEncode(x,sentiment_topics))\ndf_test_sentiment['entities_encode'] = df_test_sentiment['entities_encode'].apply(lambda x: formatEncode(x,sentiment_topics))\ndf_train_sentiment = splitEncodeCol(df_train_sentiment,'entities_encode')\ndf_test_sentiment = splitEncodeCol(df_test_sentiment,'entities_encode')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. EDA\n\nAdoption speed in terms of:\n\nType,Age,Breed1,Gender,Color1,MaturitySize,FurLength,Vaccinated,Dewormed,Sterilized,Health,Fee,State,VideoAmt,PhotoAmt\n\nWe show the distribution for cat and dog separately.","metadata":{}},{"cell_type":"code","source":"# Check for missing data\nprint(df_train.columns[np.sum(df_train.isnull())>0])\n# Get index\ncat_idx = df_train['Type']==1.0\ndog_idx = df_train['Type']==2.0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Helper functions\ndef getTop(col,top_num):\n    df_train[cat_idx].groupby(col)['AdoptionSpeed'].mean().sort_values().head(top_num).plot.barh()\n    plt.subplots()\n    df_train[dog_idx].groupby(col)['AdoptionSpeed'].mean().sort_values().head(top_num).plot.barh()\n    plt.show()\n    \ndef barCol(col,c):\n    d={}\n    d.update({('cat'+str(x)): df_train.loc[df_train[col]==x & cat_idx].groupby('AdoptionSpeed').count()[col] for x in c})\n    d.update({('dog'+str(x)): df_train.loc[df_train[col]==x & dog_idx].groupby('AdoptionSpeed').count()[col] for x in c})\n    pd.DataFrame(d).plot.bar()\n    plt.show()\n    \ndef boxCol(col):\n    fig,(ax1,ax2) = plt.subplots(1,2)\n    temp=[df_train[col][df_train['AdoptionSpeed']==x & cat_idx] for x in df_train['AdoptionSpeed'].unique()]\n    ax1.boxplot(temp, showfliers=False)\n    temp=[df_train[col][df_train['AdoptionSpeed']==x & dog_idx] for x in df_train['AdoptionSpeed'].unique()]\n    ax2.boxplot(temp, showfliers=False)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Overall adoption\npd.DataFrame({'cat': df_train['AdoptionSpeed'][cat_idx].value_counts().sort_index(),\\\n           'dog': df_train['AdoptionSpeed'][dog_idx].value_counts().sort_index()}).\\\n            plot.bar()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Age\nboxCol('Age')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Breed1 (top adoption)\ngetTop('Breed1',10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Gender\nbarCol('Gender',[1,2,3])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Color1\ngetTop('Color1',3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# PhotoAmt\nboxCol('PhotoAmt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# PhotoAmt\nboxCol('VideoAmt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. LGBM Model","metadata":{}},{"cell_type":"markdown","source":"### 5.1 Prepare data","metadata":{}},{"cell_type":"code","source":"# Merge data\ndfTemp_train = df_train.merge(df_train_sentiment,on='PetID',how='left')\ndfTemp_train = dfTemp_train.merge(df_train_metadata,left_on='PetID',right_on='PetID',how='left',suffixes=(False, False))\ndfTemp_test = df_test.merge(df_test_sentiment,on='PetID',how='left')\ndfTemp_test = dfTemp_test.merge(df_test_metadata,left_on='PetID',right_on='PetID',how='left',suffixes=(False, False))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove unnecessary columns\nremove_cols = ['Name','RescuerID','Description','PetID','sentiment_filename','entities','entities_encode',\\\n              'metadata_filename','annots_top_desc','annots_top_desc_encode']\n\nX_train = dfTemp_train.drop(columns=remove_cols)\nX_test = dfTemp_test.drop(columns=remove_cols)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert to lgb dataset\nn=1000\ntrain_data = lgb.Dataset(data=X_train.iloc[:n].drop(columns=['AdoptionSpeed']),label=X_train['AdoptionSpeed'][:n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5.2 Train Model","metadata":{}},{"cell_type":"code","source":"# Helper functions\ndef getRMSE(max_depth,min_data_in_leaf,mode='cv'):\n    \"\"\"p=(max_depth,min_data_in_leaf)\"\"\"\n    \n    params = {'application': 'regression',\n          'boosting': 'gbdt',\n          'metric': 'rmse',\n          'num_leaves': 2*max_depth,\n          'max_depth': max_depth,\n          'min_data_in_leaf':min_data_in_leaf,\n          'learning_rate': 0.01,\n          'bagging_fraction': 0.85,\n          'feature_fraction': 0.8,\n          'min_split_gain': 0.02,\n          'min_child_samples': 150,\n          'min_child_weight': 0.02,\n          'lambda_l2': 0.0475,\n          'verbosity': -1,\n          'data_random_seed': 17}\n\n    early_stop = 500\n    verbose_eval = None if mode=='cv' else 500\n    num_rounds = 10000\n    nfold=5\n\n    if mode=='cv':\n        mdl=lgb.cv(params=params, train_set=train_data, num_boost_round=num_rounds, nfold=nfold, verbose_eval=verbose_eval,\\\n              early_stopping_rounds=early_stop)\n        return [mdl['rmse-mean'][-1],(max_depth,min_data_in_leaf)]\n    elif mode=='train':\n        mdl=lgb.train(params=params, train_set=train_data, valid_sets=train_data,num_boost_round=num_rounds, verbose_eval=verbose_eval,\\\n              early_stopping_rounds=early_stop)\n        return mdl\n    \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tuning params with CV\nmax_depth=range(7,10)\nmin_data_in_leaf=range(100,105)\np=[(x,y) for x in max_depth for y in min_data_in_leaf]\n\nrmse_cv=[]\n\nfor x,y in p:\n    rmse_cv.append(getRMSE(x,y))\n\nrmse_cv.sort(key=lambda x: x[0])\nplt.plot([x[0] for x in rmse_cv])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build model\nmdl=getRMSE(rmse_cv[0][1][0],rmse_cv[0][1][1],'train')\nlgb.plot_importance(mdl)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5.3 Predict","metadata":{}},{"cell_type":"code","source":"# Predict testing data\nY_test = mdl.predict(X_test, num_iteration=mdl.best_iteration)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6. Create submission file","metadata":{}},{"cell_type":"code","source":"submission = pd.DataFrame({'PetID': dfTemp_test['PetID'].values, 'AdoptionSpeed': Y_test.astype(np.int32)})\nsubmission.head()\nsubmission.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}