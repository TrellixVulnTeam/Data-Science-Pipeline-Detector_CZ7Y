{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport matplotlib as plt\nimport os\nimport seaborn as sns\nimport numpy as np\nimport json\nimport matplotlib.pyplot as plt\n\nimport optuna\nimport lightgbm as lgb\nimport sklearn.metrics\nfrom sklearn.feature_selection import RFECV\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import cohen_kappa_score\nimport time\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import StratifiedKFold","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lgb\n\n# #private score: 0.34864\n# #weighted kappa on cross validation: 0.4010444202401364 \n\n# #private score: 0.35116 with conversion to categorical (vanilla)\n# #0.40327950719004346 qwk cv\n\n# #private score: 0.33312 with all metadata/sentiment\n# #0.39 qwk cv\n\n# #private score:0.34807 with top 11 important features\n# #0.41 qwk cv\n\n# #private score:0.34558 with 6 least important features removal\n# #0.41 qwk cv \n\n# xgboost\n\n# QWK =  0.31 vwith all metadata/sentiment cv\n# private score: 0.22969\n\n\n# QWK =  0.24007281878061848 vanilla xgboost cv\n# private score:0.16972\n\n# QWK = 0.27 top 12 features cv\n# private score: 0.21","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/petfinder-adoption-prediction/train/train.csv')\ntest = pd.read_csv('../input/petfinder-adoption-prediction/test/test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_sentiment(dataset, ids, folder):\n    \n    doc_sent_mag = []\n    doc_sent_score = []\n    \n    for pet in ids:\n        try:\n            with open(f'{folder}/{pet}.json', 'r', encoding='utf-8') as f:\n                sentiment = json.load(f)\n                file_sentiment = sentiment['documentSentiment']\n                doc_sent_mag.append(file_sentiment['magnitude'])\n                doc_sent_score.append(file_sentiment['score'])\n        \n        except FileNotFoundError:\n            doc_sent_mag.append(np.nan)\n            doc_sent_score.append(np.nan)\n            \n    dataset['doc_sent_mag'] = doc_sent_mag\n    dataset['doc_sent_score'] = doc_sent_score\n    \n    return dataset\n\n\ndef get_label_score(json_file, json_keys):\n    \n    return np.asarray([x['score'] for x in json_file['labelAnnotations']]).mean() if 'labelAnnotations' in json_keys else np.nan\n\n\ndef get_img_color_score_pixelfrac(json_file, json_keys):\n    \n    if 'imagePropertiesAnnotation' in json_keys:\n\n        img_colors = json_file['imagePropertiesAnnotation']['dominantColors']['colors']\n        img_color_score = np.asarray([x['score'] for x in img_colors]).mean()\n        img_color_pixelfrac = np.asarray([x['pixelFraction'] for x in img_colors]).mean()\n\n    else:\n        img_color_score = np.nan\n        img_color_pixelfrac = np.nan\n        \n    return img_color_score, img_color_pixelfrac\n    \ndef get_img_crop_conf_importance(json_file, json_keys):\n    \n    if 'cropHintsAnnotation' in json_keys:\n        img_crops = json_file['cropHintsAnnotation']['cropHints']\n        img_crop_conf = np.asarray([x['confidence'] for x in img_crops]).mean()\n\n        if 'importanceFraction' in img_crops[0].keys():\n            img_crop_importance = np.asarray([x['importanceFraction'] for x in img_crops]).mean()\n        else:\n            img_crop_importance = np.nan\n\n    else:\n        img_crop_conf = np.nan\n        img_crop_importance = np.nan\n        \n    return img_crop_conf, img_crop_importance\n    \n\ndef extract_metadata(dataset, ids, folder):\n    \n    metadata_label_score_column = []\n    metadata_color_score_column = []\n    metadata_color_pixelfrac_column = []\n    metadata_crop_conf_column = []\n    metadata_crop_importance_column = []\n\n    for pet in ids:\n        \n        metadata_label_scores = []\n        metadata_color_scores = []\n        metadata_color_pixelfracs = []\n        metadata_crop_confs = []\n        metadata_crop_importances = []\n        \n        more_image_exist = True\n        iterator = 1\n\n        while more_image_exist:\n\n            try:\n\n                with open(f'{folder}/{pet}-{iterator}.json', 'r', encoding='utf-8') as f:\n\n                    metadata = json.load(f)\n                    keys = list(metadata.keys())\n                    \n                    label_score = get_label_score(metadata, keys)\n                    img_color_score, img_color_pixelfrac = get_img_color_score_pixelfrac(metadata, keys)\n                    img_crop_conf, img_crop_importance = get_img_crop_conf_importance(metadata, keys)\n\n                    metadata_label_scores.append(label_score)\n                    metadata_color_scores.append(img_color_score)\n                    metadata_color_pixelfracs.append(img_color_pixelfrac)\n                    metadata_crop_confs.append(img_crop_conf)\n                    metadata_crop_importances.append(img_crop_importance)\n\n                iterator += 1\n\n            except FileNotFoundError:\n                more_image_exist = False\n                \n        metadata_label_score_column.append(np.mean(metadata_label_scores))\n        metadata_color_score_column.append(np.mean(metadata_color_scores))\n        metadata_color_pixelfrac_column.append(np.mean(metadata_color_pixelfracs))\n        metadata_crop_conf_column.append(np.mean(metadata_crop_confs))\n        metadata_crop_importance_column.append(np.mean(metadata_crop_importances))\n    \n    dataset['metadata_label_score'] = metadata_label_score_column\n    dataset['metadata_color_score'] = metadata_color_score_column\n    dataset['metadata_color_pixelfrac'] = metadata_color_pixelfrac_column\n    dataset['metadata_crop_conf'] = metadata_crop_conf_column\n    dataset['metadata_crop_importance'] = metadata_crop_importance_column\n    \n    return dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntrain = extract_metadata(train, train['PetID'], '../input/petfinder-adoption-prediction/train_metadata')\ntrain = extract_sentiment(train, train['PetID'], '../input/petfinder-adoption-prediction/train_sentiment')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time \ntest = extract_metadata(test, test['PetID'], '../input/petfinder-adoption-prediction/test_metadata')\ntest = extract_sentiment(test, test['PetID'], '../input/petfinder-adoption-prediction/test_sentiment')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['Description_length'] = train['Description'].apply(lambda x: len(x.split()) if x is not np.nan else 0)\ntest['Description_length'] = test['Description'].apply(lambda x: len(x.split()) if x is not np.nan else 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columns_to_drop = ['Name', \n                   'RescuerID', \n                   'Description', \n                   'PetID'\n                   ]\n\nX_train = train.drop(columns_to_drop, axis=1)\nX_test = test.drop(columns_to_drop, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categorical_cols = ['Type', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2', 'Color3', 'MaturitySize', 'FurLength',\n                    'Vaccinated', 'Dewormed', 'Sterilized', 'Health', 'State']\n\nfor col in categorical_cols:\n    X_train[col] = X_train[col].astype('category')\n    X_test[col] = X_test[col].astype('category')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = train['AdoptionSpeed']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape, y_train.shape, X_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import optuna\n\n# import lightgbm as lgb\n# import sklearn.metrics\n# from sklearn.model_selection import train_test_split\n\n# x_train, x_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2)\n# train_df = lgb.Dataset(data=x_train, label=y_train, categorical_feature = categorical_cols, free_raw_data=False)\n# test_df = lgb.Dataset(data=x_test, label=y_test, categorical_feature = categorical_cols)\n    \n# def objective(trial): \n#     param = {\n#         'objective': 'multiclass',\n#         'metric': 'multi_logloss',\n#         'num_class': 5,\n#         \"verbosity\": -1,\n#         'data_random_seed': 42,\n#         'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n#         'num_iterations': trial.suggest_int('num_iterations', 1, 1000),\n#         'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n#         'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n#         'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n#         'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n#         'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n#         'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n#         'max_depth': trial.suggest_int('max_depth', 0, 11),\n#         'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n#         'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 1.0),\n#         'feature_pre_filter': False\n#     }\n    \n#     gbm = lgb.train(param, train_df, valid_sets=test_df) #,  early_stopping_rounds=10, num_boost_round=100\n#     preds = gbm.predict(x_test).argmax(axis=1) #, num_iteration=gbm.best_iteration\n#     accuracy = sklearn.metrics.accuracy_score(y_test, preds)\n#     return accuracy\n\n# study = optuna.create_study(direction='maximize')\n# study.optimize(objective, n_trials=30)\n \n# print('Number of finished trials:', len(study.trials))\n# print('Best trial:', study.best_trial.params)\n# print(\"  Value: {}\".format(study.best_trial.value))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(\"  Value: {}\".format(study.best_trial.params))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import scipy as sp\n\nfrom collections import Counter\nfrom functools import partial\nfrom math import sqrt\n\nfrom sklearn.metrics import cohen_kappa_score, mean_squared_error\nfrom sklearn.metrics import confusion_matrix as sk_cmatrix\n\n\n# FROM: https://www.kaggle.com/myltykritik/simple-lgbm-image-features\n\n# The following 3 functions have been taken from Ben Hamner's github repository\n# https://github.com/benhamner/Metrics\ndef confusion_matrix(rater_a, rater_b, min_rating=None, max_rating=None):\n    \"\"\"\n    Returns the confusion matrix between rater's ratings\n    \"\"\"\n    assert(len(rater_a) == len(rater_b))\n    if min_rating is None:\n        min_rating = min(rater_a + rater_b)\n    if max_rating is None:\n        max_rating = max(rater_a + rater_b)\n    num_ratings = int(max_rating - min_rating + 1)\n    conf_mat = [[0 for i in range(num_ratings)]\n                for j in range(num_ratings)]\n    for a, b in zip(rater_a, rater_b):\n        conf_mat[a - min_rating][b - min_rating] += 1\n    return conf_mat\n\n\ndef histogram(ratings, min_rating=None, max_rating=None):\n    \"\"\"\n    Returns the counts of each type of rating that a rater made\n    \"\"\"\n    if min_rating is None:\n        min_rating = min(ratings)\n    if max_rating is None:\n        max_rating = max(ratings)\n    num_ratings = int(max_rating - min_rating + 1)\n    hist_ratings = [0 for x in range(num_ratings)]\n    for r in ratings:\n        hist_ratings[r - min_rating] += 1\n    return hist_ratings\n\n\ndef quadratic_weighted_kappa(y, y_pred):\n    \"\"\"\n    Calculates the quadratic weighted kappa\n    axquadratic_weighted_kappa calculates the quadratic weighted kappa\n    value, which is a measure of inter-rater agreement between two raters\n    that provide discrete numeric ratings.  Potential values range from -1\n    (representing complete disagreement) to 1 (representing complete\n    agreement).  A kappa value of 0 is expected if all agreement is due to\n    chance.\n    quadratic_weighted_kappa(rater_a, rater_b), where rater_a and rater_b\n    each correspond to a list of integer ratings.  These lists must have the\n    same length.\n    The ratings should be integers, and it is assumed that they contain\n    the complete range of possible ratings.\n    quadratic_weighted_kappa(X, min_rating, max_rating), where min_rating\n    is the minimum possible rating, and max_rating is the maximum possible\n    rating\n    \"\"\"\n    rater_a = y\n    rater_b = y_pred\n    min_rating=None\n    max_rating=None\n    rater_a = np.array(rater_a, dtype=int)\n    rater_b = np.array(rater_b, dtype=int)\n    assert(len(rater_a) == len(rater_b))\n    if min_rating is None:\n        min_rating = min(min(rater_a), min(rater_b))\n    if max_rating is None:\n        max_rating = max(max(rater_a), max(rater_b))\n    conf_mat = confusion_matrix(rater_a, rater_b,\n                                min_rating, max_rating)\n    num_ratings = len(conf_mat)\n    num_scored_items = float(len(rater_a))\n\n    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n\n    numerator = 0.0\n    denominator = 0.0\n\n    for i in range(num_ratings):\n        for j in range(num_ratings):\n            expected_count = (hist_rater_a[i] * hist_rater_b[j]\n                              / num_scored_items)\n            d = pow(i - j, 2.0) / pow(num_ratings - 1, 2.0)\n            numerator += d * conf_mat[i][j] / num_scored_items\n            denominator += d * expected_count / num_scored_items\n\n    return (1.0 - numerator / denominator)\n\nclass OptimizedRounder(object):\n    def __init__(self):\n        self.coef_ = 0\n\n    def _kappa_loss(self, coef, X, y):\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            elif pred >= coef[2] and pred < coef[3]:\n                X_p[i] = 3\n            else:\n                X_p[i] = 4\n\n        ll = quadratic_weighted_kappa(y, X_p)\n        return -ll\n\n    def fit(self, X, y):\n        loss_partial = partial(self._kappa_loss, X=X, y=y)\n        initial_coef = [0.5, 1.5, 2.5, 3.5]\n        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n\n    def predict(self, X, coef):\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            elif pred >= coef[2] and pred < coef[3]:\n                X_p[i] = 3\n            else:\n                X_p[i] = 4\n        return X_p\n\n    def coefficients(self):\n        return self.coef_['x']\n    \ndef rmse(actual, predicted):\n    return sqrt(mean_squared_error(actual, predicted))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import lightgbm as lgb\n\n\n# #private score: 0.34864\n# #weighted kappa on cross validation: 0.4010444202401364\n\n# #0.35116 with conversion to categorical (vanilla)\n# #0.40327950719004346 qwk cv\n\n# #0.33312 with all metadata/sentiment\n# #0.39 qwk cv\n\n# #0.34807 with top 11 important features\n# #0.41 qwk cv\n\n# #0.34558 with 6 least important features removal\n# #0.41 qwk cv \n\n\n# #XGBOOST\n# #QWK =  0.31921077436316847\n# # private score: 0.22969\n# params = {'application': 'regression',\n#           'boosting': 'gbdt',\n#           'metric': 'rmse',\n#           'num_leaves': 70,\n#           'max_depth': 9,\n#           'learning_rate': 0.01,\n#           'bagging_fraction': 0.85,\n#           'feature_fraction': 0.8,\n#           'min_split_gain': 0.02,\n#           'min_child_samples': 150,\n#           'min_child_weight': 0.02,\n#           'lambda_l2': 0.0475,\n#           'verbosity': -1,\n#           'data_random_seed': 17}\n\n# # params = {\n# #         'application': 'regression',\n# #         'boosting': 'gbdt',\n# #         'metric': 'rmse',\n# #         'lambda_l1': 0.21785449693658834, \n# #         'num_iterations': 570, \n# #         'lambda_l2': 0.0027941677997421446, \n# #         'num_leaves': 18, \n# #         'feature_fraction': 0.94, \n# #         'bagging_fraction': 0.85, \n# #         'bagging_freq': 5, \n# #         'min_child_samples': 85, \n# #         'max_depth': 6, \n# #         'learning_rate': 1.0}\n\n\n# # params = study.best_trial.params\n\n# # print(study.best_trial.params)\n# # Additional parameters:\n# early_stop = 500\n# verbose_eval = 100\n# num_rounds = 10000\n# n_splits = 5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.model_selection import StratifiedKFold\n\n\n# kfold = StratifiedKFold(n_splits=n_splits)\n\n# #out of fold \n# oof_train = np.zeros((X_train.shape[0]))\n# oof_test = np.zeros((X_test.shape[0], n_splits))\n\n\n# i = 0\n\n# #Indexes of train and test rows\n# for train_index, valid_index in kfold.split(X_train, y_train):\n    \n#     #training data is split to train and validation sets \n#     X_tr = X_train.iloc[train_index, :]\n#     X_val = X_train.iloc[valid_index, :]\n    \n#     #target values are taken from training dataset\n#     y_tr = X_tr['AdoptionSpeed'].values\n#     #training data taken with no target\n#     X_tr = X_tr.drop(['AdoptionSpeed'], axis=1)\n    \n#     #target values are taken from validation dataset\n#     y_val = X_val['AdoptionSpeed'].values\n#     #validation data taken with no target\n#     X_val = X_val.drop(['AdoptionSpeed'], axis=1)\n    \n    \n#     print('\\ny_tr distribution: {}'.format(Counter(y_tr)))\n    \n#     #make datasets for lgb? \n#     d_train = lgb.Dataset(X_tr, label=y_tr)\n#     d_valid = lgb.Dataset(X_val, label=y_val)\n#     #see loss functions in lgb\n#     watchlist = [d_train, d_valid]\n    \n#     print('training LGB:')\n#     model = lgb.train(params,\n#                       train_set=d_train,\n#                       num_boost_round=num_rounds,\n#                       valid_sets=watchlist,\n#                       verbose_eval=verbose_eval,\n#                       early_stopping_rounds=early_stop)\n    \n#     val_pred = model.predict(X_val, num_iteration=model.best_iteration)\n#     test_pred = model.predict(X_test, num_iteration=model.best_iteration)\n    \n#     oof_train[valid_index] = val_pred\n#     oof_test[:, i] = test_pred\n    \n#     i += 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plt.hist(oof_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_train.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# features_importance = pd.Series(model.feature_importance(), index=X_train.drop(['AdoptionSpeed'], axis=1).columns)\n# features_importance = features_importance.sort_values(ascending=False)\n# df = features_importance.to_frame()\n# df['feature'] = df.index\n# df = df.rename(columns={0: 'importance'})\n\n# fig = plt.figure(figsize=(15,10))\n# ax = sns.barplot(x=\"importance\", y=\"feature\", data=df)\n# ax.set_xlabel('Importance')\n# ax.set_ylabel('Feature')\n# plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_train2 = X_train.drop(['VideoAmt', 'metadata_crop_conf', 'Type', 'Health', 'metadata_crop_importance', 'Color3'], axis=1)\n\n# X_test2 = X_test.drop(['VideoAmt', 'metadata_crop_conf', 'Type', 'Health', 'metadata_crop_importance', 'Color3'], axis=1)\n\n# X_train2.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_train2['metadata_label_score'].fillna(0,inplace=True)\n# X_train2['metadata_color_pixelfrac'].fillna(0,inplace=True)\n# X_train2['metadata_color_score'].fillna(0,inplace=True)\n# X_train2['doc_sent_mag'].fillna(0,inplace=True)\n# X_train2['doc_sent_score'].fillna(0,inplace=True)\n\n# X_test2['metadata_label_score'].fillna(0,inplace=True)\n# X_test2['metadata_color_pixelfrac'].fillna(0,inplace=True)\n# X_test2['metadata_color_score'].fillna(0,inplace=True)\n# X_test2['doc_sent_mag'].fillna(0,inplace=True)\n# X_test2['doc_sent_score'].fillna(0,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_train2.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #out of fold \n# oof_train = np.zeros((X_train2.shape[0]))\n# oof_test = np.zeros((X_test2.shape[0], n_splits))\n\n\n# i = 0\n\n# #Indexes of train and test rows\n# for train_index, valid_index in kfold.split(X_train2, y_train):\n    \n#     #training data is split to train and validation sets \n#     X_tr = X_train2.iloc[train_index, :]\n#     X_val = X_train2.iloc[valid_index, :]\n    \n#     #target values are taken from training dataset\n#     y_tr = X_tr['AdoptionSpeed'].values\n#     #training data taken with no target\n#     X_tr = X_tr.drop(['AdoptionSpeed'], axis=1)\n    \n#     #target values are taken from validation dataset\n#     y_val = X_val['AdoptionSpeed'].values\n#     #validation data taken with no target\n#     X_val = X_val.drop(['AdoptionSpeed'], axis=1)\n    \n    \n#     print('\\ny_tr distribution: {}'.format(Counter(y_tr)))\n    \n#     #make datasets for lgb? \n#     d_train = lgb.Dataset(X_tr, label=y_tr)\n#     d_valid = lgb.Dataset(X_val, label=y_val)\n#     #see loss functions in lgb\n#     watchlist = [d_train, d_valid]\n    \n#     print('training LGB:')\n#     model = lgb.train(params,\n#                       train_set=d_train,\n#                       num_boost_round=num_rounds,\n#                       valid_sets=watchlist,\n#                       verbose_eval=verbose_eval,\n#                       early_stopping_rounds=early_stop)\n    \n#     val_pred = model.predict(X_val, num_iteration=model.best_iteration)\n#     test_pred = model.predict(X_test2, num_iteration=model.best_iteration)\n    \n#     oof_train[valid_index] = val_pred\n#     oof_test[:, i] = test_pred\n    \n#     i += 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Compute QWK based on OOF train predictions:\n# optR = OptimizedRounder()\n# # optR.fit(oof_train, X_train['AdoptionSpeed'].values)\n# optR.fit(oof_train, y_train)\n# coefficients = optR.coefficients()\n# pred_test_y_k = optR.predict(oof_train, coefficients)\n# # print(\"\\nValid Counts = \", Counter(X_train['AdoptionSpeed'].values))\n# print(\"\\nValid Counts = \", Counter(y_train))\n# print(\"Predicted Counts = \", Counter(pred_test_y_k))\n# print(\"Coefficients = \", coefficients)\n# # qwk = quadratic_weighted_kappa(X_train['AdoptionSpeed'].values, pred_test_y_k)\n# qwk = quadratic_weighted_kappa(y_train, pred_test_y_k)\n# print(\"QWK = \", qwk)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Manually adjusted coefficients:\n\n# coefficients_ = coefficients.copy()\n\n# # coefficients_[0] = 1.645\n# # coefficients_[1] = 2.115\n# # coefficients_[3] = 2.84\n\n# train_predictions = optR.predict(oof_train, coefficients_).astype(int)\n# print('train pred distribution: {}'.format(Counter(train_predictions)))\n\n# test_predictions = optR.predict(oof_test.mean(axis=1), coefficients_)\n# print('test pred distribution: {}'.format(Counter(test_predictions)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Distribution inspection of original target and predicted train and test:\n\n# print(\"True Distribution:\")\n# print(pd.value_counts(X_train['AdoptionSpeed'], normalize=True).sort_index())\n# print(\"\\nTrain Predicted Distribution:\")\n# print(pd.value_counts(train_predictions, normalize=True).sort_index())\n# print(\"\\nTest Predicted Distribution:\")\n# print(pd.value_counts(test_predictions, normalize=True).sort_index())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# xgb","metadata":{}},{"cell_type":"code","source":"#OPTUNA FOR XGB\n\n# X_train_optuna = X_train.drop(['AdoptionSpeed'], axis=1)\n# y_train_optuna = X_train['AdoptionSpeed']\n\n# X_train_optuna['Type'] = lbl.fit_transform(X_train_optuna['Type'].astype(int))\n# X_train_optuna['Breed1'] = lbl.fit_transform(X_train_optuna['Type'].astype(int))\n# X_train_optuna['Breed2'] = lbl.fit_transform(X_train_optuna['Type'].astype(int))\n# X_train_optuna['Gender'] = lbl.fit_transform(X_train_optuna['Type'].astype(int))\n# X_train_optuna['Color1'] = lbl.fit_transform(X_train_optuna['Type'].astype(int))\n# X_train_optuna['Color2'] = lbl.fit_transform(X_train_optuna['Type'].astype(int))\n# X_train_optuna['Color3'] = lbl.fit_transform(X_train_optuna['Type'].astype(int))\n# X_train_optuna['MaturitySize'] = lbl.fit_transform(X_train_optuna['Type'].astype(int))\n# X_train_optuna['FurLength'] = lbl.fit_transform(X_train_optuna['Type'].astype(int))\n# X_train_optuna['Vaccinated'] = lbl.fit_transform(X_train_optuna['Type'].astype(int))\n# X_train_optuna['Dewormed'] = lbl.fit_transform(X_train_optuna['Type'].astype(int))\n# X_train_optuna['Sterilized'] = lbl.fit_transform(X_train_optuna['Type'].astype(int))\n# X_train_optuna['Health'] = lbl.fit_transform(X_train_optuna['Type'].astype(int))\n# X_train_optuna['State'] = lbl.fit_transform(X_train_optuna['Type'].astype(int))\n\n# import xgboost as xgb\n# import sklearn.metrics\n# from sklearn.model_selection import train_test_split\n\n# x_train, x_val, y_train, y_val = train_test_split(X_train_optuna, y_train_optuna, test_size=0.2)\n# train_df = xgb.DMatrix(data=x_train, label=y_train)\n# val_df = xgb.DMatrix(data=x_val, label=y_val)\n# eval_sets = [(train_df, 'train'), (val_df, 'eval')]\n    \n# def objective(trial): \n    \n#     param = {\n#         \"num_class\": 5,\n#         'learning_rate': trial.suggest_uniform('learning_rate', 0.01, 0.6),\n#         'subsample': trial.suggest_uniform('subsample', 0.3, 0.9),\n#         'max_depth': trial.suggest_int('max_depth', 3, 9),\n#         'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 0.9),\n#         'min_child_weight': trial.suggest_int('min_child_weight', 1, 4)\n#              }\n    \n#     xgb_opt = xgb.train(param, train_df, evals=eval_sets) #,  early_stopping_rounds=10, num_boost_round=100\n#     preds = xgb_opt.predict(val_df) #, num_iteration=gbm.best_iteration\n#     accuracy = sklearn.metrics.accuracy_score(y_test, preds)\n#     return accuracy\n\n# study = optuna.create_study(direction='maximize')\n# study.optimize(objective, n_trials=30)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print('Best trial:', study.best_trial.params)\n# print(\"  Value: {}\".format(study.best_trial.value))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.preprocessing import LabelEncoder\n\n# lbl = LabelEncoder()\n# X_train3 = X_train.copy()\n# cats = ['Type', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2', 'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed', 'Sterilized', 'Health', 'State']\n# X_train3['Type'] = lbl.fit_transform(X_train3['Type'].astype(int))\n# X_train3['Breed1'] = lbl.fit_transform(X_train3['Type'].astype(int))\n# X_train3['Breed2'] = lbl.fit_transform(X_train3['Type'].astype(int))\n# X_train3['Gender'] = lbl.fit_transform(X_train3['Type'].astype(int))\n# X_train3['Color1'] = lbl.fit_transform(X_train3['Type'].astype(int))\n# X_train3['Color2'] = lbl.fit_transform(X_train3['Type'].astype(int))\n# X_train3['Color3'] = lbl.fit_transform(X_train3['Type'].astype(int))\n# X_train3['MaturitySize'] = lbl.fit_transform(X_train3['Type'].astype(int))\n# X_train3['FurLength'] = lbl.fit_transform(X_train3['Type'].astype(int))\n# X_train3['Vaccinated'] = lbl.fit_transform(X_train3['Type'].astype(int))\n# X_train3['Dewormed'] = lbl.fit_transform(X_train3['Type'].astype(int))\n# X_train3['Sterilized'] = lbl.fit_transform(X_train3['Type'].astype(int))\n# X_train3['Health'] = lbl.fit_transform(X_train3['Type'].astype(int))\n# X_train3['State'] = lbl.fit_transform(X_train3['Type'].astype(int))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_test3 = X_test.copy()\n# X_test3['Type'] = lbl.fit_transform(X_test3['Type'].astype(int))\n# X_test3['Breed1'] = lbl.fit_transform(X_test3['Type'].astype(int))\n# X_test3['Breed2'] = lbl.fit_transform(X_test3['Type'].astype(int))\n# X_test3['Gender'] = lbl.fit_transform(X_test3['Type'].astype(int))\n# X_test3['Color1'] = lbl.fit_transform(X_test3['Type'].astype(int))\n# X_test3['Color2'] = lbl.fit_transform(X_test3['Type'].astype(int))\n# X_test3['Color3'] = lbl.fit_transform(X_test3['Type'].astype(int))\n# X_test3['MaturitySize'] = lbl.fit_transform(X_test3['Type'].astype(int))\n# X_test3['FurLength'] = lbl.fit_transform(X_test3['Type'].astype(int))\n# X_test3['Vaccinated'] = lbl.fit_transform(X_test3['Type'].astype(int))\n# X_test3['Dewormed'] = lbl.fit_transform(X_test3['Type'].astype(int))\n# X_test3['Sterilized'] = lbl.fit_transform(X_test3['Type'].astype(int))\n# X_test3['Health'] = lbl.fit_transform(X_test3['Type'].astype(int))\n# X_test3['State'] = lbl.fit_transform(X_test3['Type'].astype(int))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_train3_ = X_train3[['metadata_label_score', 'metadata_color_score', 'metadata_color_pixelfrac', 'Description_length', 'Age', 'doc_sent_mag', 'doc_sent_score',\n#                    'PhotoAmt', 'Fee', 'Quantity', 'metadata_crop_importance', 'Type', 'AdoptionSpeed']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_test3_ = X_test3[['metadata_label_score', 'metadata_color_score', 'metadata_color_pixelfrac', 'Description_length', 'Age', 'doc_sent_mag', 'doc_sent_score',\n#                    'PhotoAmt', 'Fee', 'Quantity', 'metadata_crop_importance', 'Type']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def run_xgb(params, X_train, X_test):X_test\n#     n_splits = 10\n#     verbose_eval = 1000\n#     num_rounds = 60000\n#     early_stop = 500\n\n#     kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=1337)\n\n#     oof_train = np.zeros((X_train.shape[0]))\n#     oof_test = np.zeros((X_test.shape[0], n_splits))\n\n#     i = 0\n\n#     for train_idx, valid_idx in kf.split(X_train, X_train['AdoptionSpeed'].values):\n\n#         X_tr = X_train.iloc[train_idx, :]\n#         X_val = X_train.iloc[valid_idx, :]\n\n#         y_tr = X_tr['AdoptionSpeed'].values\n#         X_tr = X_tr.drop(['AdoptionSpeed'], axis=1)\n\n#         y_val = X_val['AdoptionSpeed'].values\n#         X_val = X_val.drop(['AdoptionSpeed'], axis=1)\n\n#         d_train = xgb.DMatrix(data=X_tr, label=y_tr, feature_names=X_tr.columns, enable_categorical=True)\n#         d_valid = xgb.DMatrix(data=X_val, label=y_val, feature_names=X_val.columns, enable_categorical=True)\n\n#         watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n#         model = xgb.train(dtrain=d_train, num_boost_round=num_rounds, evals=watchlist,\n#                          early_stopping_rounds=early_stop, verbose_eval=verbose_eval, params=params)\n\n#         valid_pred = model.predict(xgb.DMatrix(X_val, feature_names=X_val.columns), ntree_limit=model.best_ntree_limit)\n#         test_pred = model.predict(xgb.DMatrix(X_test, feature_names=X_test.columns), ntree_limit=model.best_ntree_limit)\n\n#         oof_train[valid_idx] = valid_pred\n#         oof_test[:, i] = test_pred\n\n#         i += 1\n#     return model, oof_train, oof_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# xgb_params = {'learning_rate': 0.1888087749957744, 'subsample': 0.7500614175599446, 'max_depth': 4, 'colsample_bytree': 0.6971444735272232, 'min_child_weight': 3}\n\n# model, oof_train, oof_test = run_xgb(xgb_params, X_train3_, X_test3_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from xgboost import plot_importance\n# plot_importance(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def plot_pred(pred):\n#     sns.distplot(pred, kde=True, hist_kws={'range': [0, 5]})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot_pred(oof_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot_pred(oof_test.mean(axis=1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# optR = OptimizedRounder()\n# optR.fit(oof_train, X_train3_['AdoptionSpeed'].values)\n# coefficients = optR.coefficients()\n# valid_pred = optR.predict(oof_train, coefficients)\n# qwk = quadratic_weighted_kappa(X_train3['AdoptionSpeed'].values, valid_pred)\n# print(\"QWK = \", qwk)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# coefficients_ = coefficients.copy()\n# train_predictions = optR.predict(oof_train, coefficients_).astype(np.int8)\n# print(f'train pred distribution: {Counter(train_predictions)}')\n# test_predictions = optR.predict(oof_test.mean(axis=1), coefficients_).astype(np.int8)\n# print(f'test pred distribution: {Counter(test_predictions)}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission = pd.DataFrame({'PetID': test['PetID'].values, 'AdoptionSpeed': test_predictions.astype(np.int32)})\n# submission.head()\n# submission.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LinearRegression","metadata":{}},{"cell_type":"code","source":"# X_train_optuna = X_train.copy()\n# y_train_optuna = X_train['AdoptionSpeed']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_train_optuna.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_train_optuna['metadata_label_score'].fillna(0,inplace=True)\n# X_train_optuna['metadata_color_pixelfrac'].fillna(0,inplace=True)\n# X_train_optuna['metadata_color_score'].fillna(0,inplace=True)\n# X_train_optuna['metadata_crop_conf'].fillna(0,inplace=True)\n# X_train_optuna['metadata_crop_importance'].fillna(0,inplace=True)\n# X_train_optuna['doc_sent_mag'].fillna(0,inplace=True)\n# X_train_optuna['doc_sent_score'].fillna(0,inplace=True)\n\n# # X_train_optuna['metadata_label_score'].fillna(0,inplace=True)\n# # X_test2['metadata_color_pixelfrac'].fillna(0,inplace=True)\n# # X_test2['metadata_color_score'].fillna(0,inplace=True)\n# # X_test2['doc_sent_mag'].fillna(0,inplace=True)\n# # X_test2['doc_sent_score'].fillna(0,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.linear_model import LogisticRegression\n# import sklearn.metrics\n# from sklearn.model_selection import train_test_split\n# from sklearn.preprocessing import StandardScaler\n\n\n\n# x_train, x_val, y_train, y_val = train_test_split(X_train_optuna, y_train_optuna, test_size=0.2)\n# # train_df = xgb.DMatrix(data=x_train, label=y_train)\n# # val_df = xgb.DMatrix(data=x_val, label=y_val)\n# # eval_sets = [(x_train, 'train'), (x_val, 'eval')]\n\n\n    \n# def objective(trial):\n\n#     param = {\n#             'solver': trial.suggest_categorical('solver', ['newton-cg', 'lbfgs', 'sag']),\n#             'penalty': trial.suggest_categorical('penalty', [\"l2\", \"none\"]),\n#             'C': trial.suggest_uniform('C', 0.1, 1.0),\n#             'class_weight': trial.suggest_categorical('class_weight', [\"balanced\", None])\n#         }\n        \n#     model = LogisticRegression(**param, max_iter=500, random_state=12)\n#     model.fit(x_train, y_train) #, num_iteration=gbm.best_iteration\n#     preds = model.predict(x_val)\n#     accuracy = sklearn.metrics.accuracy_score(y_val, preds)\n#     return accuracy\n\n# study = optuna.create_study(direction='maximize')\n# study.optimize(objective, n_trials=50)","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_optuna = X_train.copy()\nX_train_optuna['metadata_label_score'].fillna(0,inplace=True)\nX_train_optuna['metadata_color_pixelfrac'].fillna(0,inplace=True)\nX_train_optuna['metadata_color_score'].fillna(0,inplace=True)\nX_train_optuna['metadata_crop_conf'].fillna(0,inplace=True)\nX_train_optuna['metadata_crop_importance'].fillna(0,inplace=True)\nX_train_optuna['doc_sent_mag'].fillna(0,inplace=True)\nX_train_optuna['doc_sent_score'].fillna(0,inplace=True)\n\nX_test_optuna = X_test.copy()\nX_test_optuna['metadata_label_score'].fillna(0,inplace=True)\nX_test_optuna['metadata_color_pixelfrac'].fillna(0,inplace=True)\nX_test_optuna['metadata_color_score'].fillna(0,inplace=True)\nX_test_optuna['metadata_crop_conf'].fillna(0,inplace=True)\nX_test_optuna['metadata_crop_importance'].fillna(0,inplace=True)\nX_test_optuna['doc_sent_mag'].fillna(0,inplace=True)\nX_test_optuna['doc_sent_score'].fillna(0,inplace=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test_optuna.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Best trial: {'solver': 'newton-cg', 'penalty': 'none', 'C': 0.9219805871547243, 'class_weight': None}\n#   Value: 0.349783261087029\nfrom sklearn.model_selection import cross_val_score, cross_validate\nfrom sklearn import metrics\n\n# def run_lr(params, X_train):\n    \n#     clf = LogisticRegression(**params, max_iter=10000):\n#     x_tr, y_tr = X_train.drop(['AdoptionSpeed'], axis=1), X_train['AdoptionSpeed']\n#     predicted = cross_validation.cross_val_predict(clf, x_tr, y_tr, cv=10)\n\n# def run_lr(params, X_train, X_test):\n#     pred_test_full=0\n#     cv_score=[]\n#     i=1\n#     n_splits = 10\n    \n#     oof_train = np.zeros((X_train.shape[0]))\n#     oof_test = np.zeros((X_test.shape[0], n_splits))\n\n#     kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=1337)\n    \n#     for train_idx,valid_idx in kf.split(X_train, X_train['AdoptionSpeed'].values):\n        \n#         X_tr = X_train.iloc[train_idx, :]\n#         X_val = X_train.iloc[valid_idx, :]\n        \n#         y_tr = X_tr['AdoptionSpeed'].values\n#         X_tr = X_tr.drop(['AdoptionSpeed'], axis=1)\n        \n#         y_val = X_val['AdoptionSpeed'].values\n#         X_val = X_val.drop(['AdoptionSpeed'], axis=1)\n        \n#         clf = LogisticRegression(**params, max_iter=500)\n#         clf.fit(X_tr, y_tr)\n        \n#         valid_pred = clf.predict(X_val)\n#         test_pred = clf.predict(X_test)\n        \n#         oof_train[valid_idx] = valid_pred\n#         oof_test[:, i] = test_pred\n        \n#         i +=1\n        \n#     return clf, oof_train, oof_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# params = {'solver': 'newton-cg', 'penalty': 'none', 'C': 0.92, 'class_weight': None}\n\n# clf = LogisticRegression(**params, max_iter=10000)\nx_tr, y_tr = X_train_optuna.drop(['AdoptionSpeed'], axis=1), X_train_optuna['AdoptionSpeed']\n# predicted = cross_val_score(clf, x_tr, y_tr, cv=10)\n\n# model, oof_train, oof_test = run_lr(params, X_train_optuna, X_test_optuna)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(predicted.mean()) #0.35909997776295305 ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf.fit(x_tr, y_tr)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ypred = clf.predict(X_test_optuna)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({'PetID': test['PetID'].values, 'AdoptionSpeed': ypred.astype(np.int32)})\nsubmission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}