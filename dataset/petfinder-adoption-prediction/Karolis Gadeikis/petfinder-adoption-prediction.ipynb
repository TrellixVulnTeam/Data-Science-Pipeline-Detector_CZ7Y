{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# PetFinder adoption prediction capstone project for 3.4","metadata":{}},{"cell_type":"markdown","source":"In this project we will try to predict animal adoption speed based on the features about the animal, such as breed, color, size, health condition etc. There are also additional data sources about the description and images, which are processed with Google Vision and Google Natural Language APIs. This work is divided into two parts:\n- Data loading and exploratory data analysis\n- Model training (with data cleaning and feature engineering) and result evaluation","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport warnings\nimport numpy as np\nimport json\nimport scipy as sp\nfrom matplotlib import pyplot as plt\nfrom collections import Counter\nfrom functools import partial\nfrom math import sqrt\nimport optuna\n\nimport sklearn.metrics\nfrom sklearn.metrics import cohen_kappa_score, mean_squared_error\nfrom sklearn.metrics import confusion_matrix as sk_cmatrix\nfrom sklearn.model_selection import cross_val_score, cross_validate\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.feature_selection import RFE\n\nfrom sklearn.linear_model import LogisticRegression\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom xgboost import plot_importance\n\nwarnings.filterwarnings('ignore')\nsns.set(style=\"darkgrid\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/petfinder-adoption-prediction/train/train.csv')\ntest = pd.read_csv('../input/petfinder-adoption-prediction/test/test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Helper functions for EDA","metadata":{}},{"cell_type":"code","source":"def autolabel(bar_plot) -> None:\n    \"\"\"\n    Attach a text label above each bar displaying its height\n    \"\"\"\n    for p in bar_plot.patches:\n        bar_plot.annotate(format(p.get_height(), '.0f'), \n                       (p.get_x() + p.get_width() / 2., p.get_height()), \n                       ha = 'center', va = 'center', \n                       xytext = (0, 9), \n                       textcoords = 'offset points')\n        \n\ndef generate_groupBY_data(col_name: str) -> pd.DataFrame:\n    \"\"\"\n    Helper function to generate percentage plots\n    \"\"\"\n    l = train.groupby(['AdoptionSpeed', col_name])[['PetID']].count().reset_index().rename(\n        columns={'PetID':'count'})\n    count_pets = train.groupby(['AdoptionSpeed', col_name])[['PetID']].count().reset_index().groupby(\n        [col_name]).sum()[['PetID']].reset_index()\n    new_col_name = 'total_pets_by' + col_name\n    count_pets.rename(columns={'PetID': new_col_name}, inplace=True)\n\n    temp = l.merge(count_pets, on=[col_name], how='left')\n    temp['fraction'] = temp['count'] * 100 / temp[new_col_name]\n\n    temp = temp.pivot(\"AdoptionSpeed\", col_name, \"fraction\")\n    \n    return temp\n\n\ndef plot_by_feature(data: pd.DataFrame, feature: str, plt1_title: str, plt2_title: str) -> None:\n    \"\"\"\n    Helper function to plot feature versus adoption speed and percentages of adoption\n    \"\"\"\n    fig = plt.figure(figsize=(15,8))\n    ax = fig.add_subplot(1,2,1)\n    sns.countplot(x=feature, data=data, palette=\"YlOrRd\", edgecolor=\"black\")\n    autolabel(ax)\n    ax.set_xlabel(feature)\n    ax.set_ylabel('Adoption count')\n    ax.set_title(plt1_title)\n\n    temp = generate_groupBY_data(feature)\n    ax = fig.add_subplot(1,2,2)\n    sns.heatmap(temp, annot=True, cmap='YlOrRd')\n    ax.set_xlabel(feature)\n    ax.set_ylabel('Adoption Speed')\n    ax.set_title(plt2_title)\n\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Helper functions for sentiment and metadata extraction","metadata":{}},{"cell_type":"code","source":"def extract_sentiment(dataset: pd.DataFrame, ids: list, folder: str) -> pd.DataFrame:\n    \"\"\"\n    Finds all sentiment files with provided pet ids and extracts document sentiment,\n    magnitude and score values, which are collected and appended to the original\n    dataframe. If no file is found, appends np.nan instead. \n    \"\"\"\n    doc_sent_mag = []\n    doc_sent_score = []\n    \n    for pet in ids:\n        try:\n            with open(f'{folder}/{pet}.json', 'r', encoding='utf-8') as f:\n                sentiment = json.load(f)\n                file_sentiment = sentiment['documentSentiment']\n                doc_sent_mag.append(file_sentiment['magnitude'])\n                doc_sent_score.append(file_sentiment['score'])\n        \n        except FileNotFoundError:\n            doc_sent_mag.append(np.nan)\n            doc_sent_score.append(np.nan)\n            \n    dataset['doc_sent_mag'] = doc_sent_mag\n    dataset['doc_sent_score'] = doc_sent_score\n    \n    return dataset\n\n\ndef get_label_score(json_file: dict, json_keys: list) -> np.array:\n    \"\"\"\n    Finds and extracts sentiment score from provided json file\n    \"\"\"\n    return np.asarray([x['score'] for x in json_file['labelAnnotations']]).mean() if 'labelAnnotations' in json_keys else np.nan\n\n\ndef get_img_color_score_pixelfrac(json_file: dict, json_keys: list) -> (np.array, np.array):\n    \"\"\"\n    Finds and extracts image color score and image color pixel fraction \n    values from provided json file\n    \"\"\"\n    if 'imagePropertiesAnnotation' in json_keys:\n\n        img_colors = json_file['imagePropertiesAnnotation']['dominantColors']['colors']\n        img_color_score = np.asarray([x['score'] for x in img_colors]).mean()\n        img_color_pixelfrac = np.asarray([x['pixelFraction'] for x in img_colors]).mean()\n\n    else:\n        img_color_score = np.nan\n        img_color_pixelfrac = np.nan\n        \n    return img_color_score, img_color_pixelfrac\n    \n    \ndef get_img_crop_conf_importance(json_file: dict, json_keys: list) -> (np.array, np.array):\n    \"\"\"\n    Finds and extracts image crop hints annotation confidence and image crop \n    importance values from provided json file\n    \"\"\"\n    if 'cropHintsAnnotation' in json_keys:\n        img_crops = json_file['cropHintsAnnotation']['cropHints']\n        img_crop_conf = np.asarray([x['confidence'] for x in img_crops]).mean()\n\n        if 'importanceFraction' in img_crops[0].keys():\n            img_crop_importance = np.asarray([x['importanceFraction'] for x in img_crops]).mean()\n        else:\n            img_crop_importance = np.nan\n\n    else:\n        img_crop_conf = np.nan\n        img_crop_importance = np.nan\n        \n    return img_crop_conf, img_crop_importance\n    \n\ndef extract_metadata(dataset: pd.DataFrame, ids: list, folder: str) -> pd.DataFrame:\n    \"\"\"\n    Collects all the image metadata for provided list of pets and appends to \n    the original dataframe. \n    \"\"\"\n    metadata_label_score_column = []\n    metadata_color_score_column = []\n    metadata_color_pixelfrac_column = []\n    metadata_crop_conf_column = []\n    metadata_crop_importance_column = []\n\n    for pet in ids:\n        \n        metadata_label_scores = []\n        metadata_color_scores = []\n        metadata_color_pixelfracs = []\n        metadata_crop_confs = []\n        metadata_crop_importances = []\n        \n        more_image_exist = True\n        iterator = 1\n\n        while more_image_exist:\n\n            try:\n\n                with open(f'{folder}/{pet}-{iterator}.json', 'r', encoding='utf-8') as f:\n\n                    metadata = json.load(f)\n                    keys = list(metadata.keys())\n                    \n                    label_score = get_label_score(metadata, keys)\n                    img_color_score, img_color_pixelfrac = get_img_color_score_pixelfrac(metadata, keys)\n                    img_crop_conf, img_crop_importance = get_img_crop_conf_importance(metadata, keys)\n\n                    metadata_label_scores.append(label_score)\n                    metadata_color_scores.append(img_color_score)\n                    metadata_color_pixelfracs.append(img_color_pixelfrac)\n                    metadata_crop_confs.append(img_crop_conf)\n                    metadata_crop_importances.append(img_crop_importance)\n\n                iterator += 1\n\n            except FileNotFoundError:\n                more_image_exist = False\n                \n        metadata_label_score_column.append(np.mean(metadata_label_scores))\n        metadata_color_score_column.append(np.mean(metadata_color_scores))\n        metadata_color_pixelfrac_column.append(np.mean(metadata_color_pixelfracs))\n        metadata_crop_conf_column.append(np.mean(metadata_crop_confs))\n        metadata_crop_importance_column.append(np.mean(metadata_crop_importances))\n    \n    dataset['metadata_label_score'] = metadata_label_score_column\n    dataset['metadata_color_score'] = metadata_color_score_column\n    dataset['metadata_color_pixelfrac'] = metadata_color_pixelfrac_column\n    dataset['metadata_crop_conf'] = metadata_crop_conf_column\n    dataset['metadata_crop_importance'] = metadata_crop_importance_column\n    \n    return dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Helper functions for data cleaning and feature engineering","metadata":{}},{"cell_type":"code","source":"def drop_columns(dataframe: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Drops irrelevant columns\n    \"\"\"\n    dataframe = dataframe.drop(['Name', 'RescuerID', 'Description', 'PetID'], axis=1)\n    return dataframe\n\n\ndef convert_to_cat(dataframe: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Converts categorical columns from int to category type\n    \"\"\"\n    categorical_cols = ['Type', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2', 'Color3', 'MaturitySize', 'FurLength',\n                    'Vaccinated', 'Dewormed', 'Sterilized', 'Health', 'State']\n    \n    for col in categorical_cols:\n        dataframe[col] = dataframe[col].astype('category')\n        \n    return dataframe\n\n\ndef append_description_length(dataframe: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Appends column with description length\n    \"\"\"\n    dataframe['Description_length'] = dataframe['Description'].apply(lambda x: len(x.split()) if x is not np.nan else 0)\n    return dataframe\n\n\ndef fill_na(dataframe: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Fills NaN with zeroes\n    \"\"\"\n    try:\n        dataframe['metadata_label_score'].fillna(0,inplace=True)\n        dataframe['metadata_color_score'].fillna(0,inplace=True)\n        dataframe['metadata_color_pixelfrac'].fillna(0,inplace=True)\n        dataframe['metadata_crop_conf'].fillna(0,inplace=True)\n        dataframe['metadata_crop_importance'].fillna(0,inplace=True)\n        dataframe['doc_sent_mag'].fillna(0,inplace=True)\n        dataframe['doc_sent_score'].fillna(0,inplace=True)\n    except:\n        return dataframe\n    \n    return dataframe\n\n\ndef feature_eng(dataframe: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Drops irrelevant columns, adds description length, converts to categorical and fills NaNs\n    \"\"\"\n    dataframe = append_description_length(dataframe)\n    dataframe = drop_columns(dataframe)\n    dataframe = convert_to_cat(dataframe)\n    dataframe = fill_na(dataframe)\n    \n    return dataframe","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Helper functions for quadratic weighted kappa score","metadata":{}},{"cell_type":"markdown","source":"The following 3 functions have been taken from Ben Hamner's github repository\nhttps://github.com/benhamner/Metrics","metadata":{}},{"cell_type":"code","source":"def confusion_matrix(rater_a, rater_b, min_rating=None, max_rating=None):\n    \"\"\"\n    Returns the confusion matrix between rater's ratings\n    \"\"\"\n    assert(len(rater_a) == len(rater_b))\n    if min_rating is None:\n        min_rating = min(rater_a + rater_b)\n    if max_rating is None:\n        max_rating = max(rater_a + rater_b)\n    num_ratings = int(max_rating - min_rating + 1)\n    conf_mat = [[0 for i in range(num_ratings)]\n                for j in range(num_ratings)]\n    for a, b in zip(rater_a, rater_b):\n        conf_mat[a - min_rating][b - min_rating] += 1\n    return conf_mat\n\n\ndef histogram(ratings, min_rating=None, max_rating=None):\n    \"\"\"\n    Returns the counts of each type of rating that a rater made\n    \"\"\"\n    if min_rating is None:\n        min_rating = min(ratings)\n    if max_rating is None:\n        max_rating = max(ratings)\n    num_ratings = int(max_rating - min_rating + 1)\n    hist_ratings = [0 for x in range(num_ratings)]\n    for r in ratings:\n        hist_ratings[r - min_rating] += 1\n    return hist_ratings\n\n\ndef quadratic_weighted_kappa(y, y_pred):\n    \"\"\"\n    Calculates the quadratic weighted kappa\n    quadratic_weighted_kappa calculates the quadratic weighted kappa\n    value, which is a measure of inter-rater agreement between two raters\n    that provide discrete numeric ratings.  Potential values range from -1\n    (representing complete disagreement) to 1 (representing complete\n    agreement).  A kappa value of 0 is expected if all agreement is due to\n    chance.\n    quadratic_weighted_kappa(rater_a, rater_b), where rater_a and rater_b\n    each correspond to a list of integer ratings.  These lists must have the\n    same length.\n    The ratings should be integers, and it is assumed that they contain\n    the complete range of possible ratings.\n    \"\"\"\n    rater_a = y\n    rater_b = y_pred\n    min_rating=None\n    max_rating=None\n    rater_a = np.array(rater_a, dtype=int)\n    rater_b = np.array(rater_b, dtype=int)\n    assert(len(rater_a) == len(rater_b))\n    if min_rating is None:\n        min_rating = min(min(rater_a), min(rater_b))\n    if max_rating is None:\n        max_rating = max(max(rater_a), max(rater_b))\n    conf_mat = confusion_matrix(rater_a, rater_b,\n                                min_rating, max_rating)\n    num_ratings = len(conf_mat)\n    num_scored_items = float(len(rater_a))\n\n    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n\n    numerator = 0.0\n    denominator = 0.0\n\n    for i in range(num_ratings):\n        for j in range(num_ratings):\n            expected_count = (hist_rater_a[i] * hist_rater_b[j]\n                              / num_scored_items)\n            d = pow(i - j, 2.0) / pow(num_ratings - 1, 2.0)\n            numerator += d * conf_mat[i][j] / num_scored_items\n            denominator += d * expected_count / num_scored_items\n\n    return (1.0 - numerator / denominator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Helper functions for Optimized Rounder\nMost successful Kaggle notebooks which are using lgb also use optimized rounder.","metadata":{}},{"cell_type":"code","source":"class OptimizedRounder(object):\n    \"\"\"\n    Optimized rounder is used to convert regression problem to classification problem.\n    After regressor returns predicted values, these values are put into bins depending\n    on certain coefficients.\n    \"\"\"\n    def __init__(self):\n        self.coef_ = 0\n\n        \n    def _kappa_loss(self, coef, X, y):\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            elif pred >= coef[2] and pred < coef[3]:\n                X_p[i] = 3\n            else:\n                X_p[i] = 4\n\n        ll = quadratic_weighted_kappa(y, X_p)\n        return -ll\n\n    \n    def fit(self, X, y):\n        loss_partial = partial(self._kappa_loss, X=X, y=y)\n        initial_coef = [0.5, 1.5, 2.5, 3.5]\n        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n\n        \n    def predict(self, X, coef):\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            elif pred >= coef[2] and pred < coef[3]:\n                X_p[i] = 3\n            else:\n                X_p[i] = 4\n        return X_p\n\n    \n    def coefficients(self):\n        return self.coef_['x']\n    \n    \ndef rmse(actual, predicted):\n    return sqrt(mean_squared_error(actual, predicted))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory data analysis\n### Adoption Speed Counts and Adoption Speed by Type\n- 0 - Pet was adopted on the same day as it was listed.\n- 1 - Pet was adopted between 1 and 7 days (1st week) after being listed.\n- 2 - Pet was adopted between 8 and 30 days (1st month) after being listed.\n- 3 - Pet was adopted between 31 and 90 days (2nd & 3rd month) after being listed.\n- 4 - No adoption after 100 days of being listed. (There are no pets in this dataset that waited between 90 and 100 days).\n\nAs we can see, there is a minority of animals that get adopted instantly. At first, cats tend to be adopted more often at faster adoption speeds, but as the speed gets lower, dogs start to take over. Significant part of pets are not adopted at all even after 100 days.","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(15,8))\n\nax = fig.add_subplot(1,2,1) \nax = sns.countplot(x=\"AdoptionSpeed\", data=train, palette=\"YlOrRd\", edgecolor=\"black\")\nautolabel(ax)\nax.set_ylabel('Count')\nax.set_xlabel('Adoption Speed')\nax.set_title('Adoption speed counts')\n\nax = fig.add_subplot(1,2,2) \nax = sns.countplot(x=\"AdoptionSpeed\", hue=\"Type\", data=train, palette=\"YlOrRd\", edgecolor=\"black\")\nautolabel(ax)\nax.set_ylabel('Count')\nax.set_xlabel('Adoption Speed')\nax.set_title('Adoption speed by type (1 = Dog, 2 = Cat)')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Adoption speed by Type\nIt seems that dogs tend to be abandoned a little more often than cats. Of course this is just a guess since proportions of animals in the country are unknown. Cats tend to be adopted faster than dogs, but at lower speed dogs tend to take over.","metadata":{}},{"cell_type":"code","source":"plot_by_feature(train, \n                'Type', \n                'Count of pets by Type (1 = Dog, 2 = Cat)', \n                'Percentage of pets adopted by Type (1 = Dog, 2 = Cat)')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Adoption speed by Gender\nFemales tend to be abandoned more often. Again, this is just a guess since proportions of animal gender in the country are unknown. Males tend to get adopted more often at lower speeds, then females take over.","metadata":{}},{"cell_type":"code","source":"plot_by_feature(train, \n                'Gender', \n                'Adoption count of pets by Gender (1 = Male, 2 = Female, 3 = Mixed)', \n                'Percentage of pets adopted by Gender')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Adoption speed by Color1\nBlack and brown pets dominate the shelters it seems.","metadata":{}},{"cell_type":"code","source":"plot_by_feature(train, \n                'Color1', \n                'Adoption count of pets by Color1 (1-Black, 2-Brown, 3-Golden, 4-Yellow, 5-Cream, 6-Gray, 7-White)', \n                'Percentage of pets adopted by Color1')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Adoption speed by MaturitySize\n\nMedium sized pets are most often in shelters. Interesting thing is that almost all extra large animals are adopted sooner or later.","metadata":{}},{"cell_type":"code","source":"plot_by_feature(train, \n                'MaturitySize', \n                'Adoption count of pets by MaturitySize (1 = Small, 2 = Medium, 3 = Large, 4 = Extra Large)', \n                'Percentage of pets adopted by MaturitySize')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Adoption speed by FurLength\n\nThe majority of abandoned animals have short-medium length hair. Long-haired pets have a pretty good chance to get adopted earlier.","metadata":{}},{"cell_type":"code","source":"plot_by_feature(train, \n                'FurLength', \n                'Adoption count of pets by FurLength (1 = Short, 2 = Medium, 3 = Long)', \n                'Percentage of pets adopted by FurLength')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Adoption speed by Vaccinated\n\nIt's a good practice to vaccinate the animal before adoption, but a bigger part of them are adopted without vaccination anyway.","metadata":{}},{"cell_type":"code","source":"plot_by_feature(train, \n                'Vaccinated', \n                'Adoption count of pets by Vaccinated (1 = Yes, 2 = No, 3 = Not Sure)', \n                'Percentage of pets adopted by Vaccinated')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Adoption speed by Dewormed\n\nIt's a good practice to deworm the animal before adoption, but deworming doesn't seem like an important factor for adoption percentage.","metadata":{}},{"cell_type":"code","source":"plot_by_feature(train, \n                'Dewormed', \n                'Adoption count of pets by Dewormed (1 = Yes, 2 = No, 3 = Not Sure)', \n                'Percentage of pets adopted by Dewormed')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Adoption speed by Sterilized\n\nMajority of abandoned animals still have means to reproduce. Good for them! Also it seems that absence of sterilization doesn't matter much. In fact, the percentage of sterilized and yet not adopted pets is much higher.","metadata":{}},{"cell_type":"code","source":"plot_by_feature(train, \n                'Sterilized', \n                'Adoption count of pets by Sterilized (1 = Yes, 2 = No, 3 = Not Sure)', \n                'Percentage of pets adopted by Sterilized')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Adoption speed by Health\n\nAlmost all abandoned pets are in perfect health. It's good to see that the majority of injured animals is adopted sooner or later as well.","metadata":{}},{"cell_type":"code","source":"plot_by_feature(train, \n                'Health', \n                'Adoption count of pets by Health (1 = Healthy, 2 = Minor Injury, 3 = Serious Injury)', \n                'Percentage of pets adopted by Health')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Adoption speed by PhotoAmount\nIt looks like the amount of photos provided have minor influence over adoption speed.","metadata":{}},{"cell_type":"code","source":"g = sns.catplot(x=\"AdoptionSpeed\", y=\"PhotoAmt\", kind=\"box\", data=train, height=8, aspect=1.5, palette=\"YlOrRd\",\n               showfliers=False)\n\ng.axes[0,0].set_xlabel('Adoption Speed')\ng.axes[0,0].set_ylabel('Photo Amount')\ng.axes[0,0].set_title('Photo Amount vs Adoption Speed ')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data addition\n\n### This part only loads additional sentiment and metadata information. Feature engineering and data cleaning methods are provided above and they are used in model training part.","metadata":{}},{"cell_type":"code","source":"train_full = train.copy()\ntrain_full = extract_metadata(train_full, train_full['PetID'], '../input/petfinder-adoption-prediction/train_metadata')\ntrain_full = extract_sentiment(train_full, train_full['PetID'], '../input/petfinder-adoption-prediction/train_sentiment')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_full = test.copy()\ntest_full = extract_metadata(test_full, test_full['PetID'], '../input/petfinder-adoption-prediction/test_metadata')\ntest_full = extract_sentiment(test_full, test_full['PetID'], '../input/petfinder-adoption-prediction/test_sentiment')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model training\n\n### In this part three models were selected for evaluation - light gradient boosting, extreme gradient boosting and logistic regression. CV and Kaggle scores are provided and the beginning of each section and summary table is shown at the end.","metadata":{}},{"cell_type":"markdown","source":"## Light gradient boosting","metadata":{}},{"cell_type":"markdown","source":"Here we will use Optuna hyperparameter optimization framework to find best parameters for light gradient boosting algorithm. Then lgb will be trained on three sets of data: vanilla, full and with top selected features. Vanilla dataset is loaded as it is provided, cleaned and engineered. Full dataset consists of additional metadata and sentiment data. Top features are selected after checking feature importance on model, trained on full dataset.\n\nVanilla dataset (with no metadata and sentiment)\n- Prediction time: 11.3 ms\n- Kaggle score: 0.351\n- QWK on validation: 0.403\n\nFull dataset\n- Prediction time: 9.95 ms\n- Kaggle score: 0.333\n- QWK on validation: 0.391\n\nTop features dataset\n- Prediction time: 9.69 ms\n- Kaggle score: 0.348\n- QWK on validation: 0.412","metadata":{}},{"cell_type":"code","source":"def objective(trial): \n    \"\"\"\n    Parameter search method for optuna framework\n    \"\"\"\n    param = {\n        'metric': 'multi_logloss',\n        \"verbosity\": -1,\n        'data_random_seed': 42,\n        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n        'num_iterations': trial.suggest_int('num_iterations', 1, 1000),\n        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n        'max_depth': trial.suggest_int('max_depth', 0, 11),\n        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n        'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 1.0),\n        'feature_pre_filter': False\n    }\n    \n    gbm = lgb.train(param, x_train, valid_sets=x_val) \n    preds = gbm.predict(x_val).argmax(axis=1) \n    accuracy = sklearn.metrics.accuracy_score(y_val, preds)\n    \n    return accuracy\n\n\ndef run_lgb(params, train_data: pd.DataFrame, test_data:pd.DataFrame):\n    \"\"\"\n    Runs light gradient boosting algorithm with stratified-k fold cross validation.\n    Returns trained model, train and test predictions and list of feature labels for\n    feature importance.\n    \"\"\"\n    labels = train_data.drop('AdoptionSpeed', axis=1)\n    target = train_data['AdoptionSpeed']\n    \n    early_stop = 1000\n    verbose_eval = 100\n    num_rounds = 10000\n    n_splits = 10\n\n    kfold = StratifiedKFold(n_splits=n_splits)\n\n    oof_train = np.zeros((train_data.shape[0]))\n    oof_test = np.zeros((test_data.shape[0], n_splits))\n\n    i = 0\n\n    for train_index, valid_index in kfold.split(labels, target):\n\n        X_tr = labels.iloc[train_index, :]\n        y_tr = target.iloc[train_index]\n\n        X_val = labels.iloc[valid_index, :]\n        y_val = target.iloc[valid_index]\n\n        d_train = lgb.Dataset(X_tr, label=y_tr)\n        d_valid = lgb.Dataset(X_val, label=y_val)\n        watchlist = [d_train, d_valid]\n\n        model = lgb.train(best_trial_params,\n                          train_set=d_train,\n                          num_boost_round=num_rounds,\n                          valid_sets=watchlist,\n                          verbose_eval=verbose_eval,\n                          early_stopping_rounds=early_stop)\n\n        val_pred = model.predict(X_val, num_iteration=model.best_iteration)\n        test_pred = model.predict(test_data, num_iteration=model.best_iteration)\n\n        oof_train[valid_index] = val_pred\n        oof_test[:, i] = test_pred\n\n        i += 1\n\n    return model, oof_train, oof_test, labels\n\n\ndef plot_feature_importance(model, labels):\n    \n    features_importance = pd.Series(model.feature_importance(), index=labels.columns)\n    features_importance = features_importance.sort_values(ascending=False)\n    df = features_importance.to_frame()\n    df['feature'] = df.index\n    df = df.rename(columns={0: 'importance'})\n\n    fig = plt.figure(figsize=(15,10))\n    ax = sns.barplot(x=\"importance\", y=\"feature\", data=df)\n    ax.set_xlabel('Importance')\n    ax.set_ylabel('Feature')\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### OPTUNA HYPERPARAMETER OPTIMIZATION FOR LGB","metadata":{}},{"cell_type":"code","source":"x_train, x_val, y_train, y_val = train_test_split(train_engineered.drop(['AdoptionSpeed'], axis=1), train_engineered['AdoptionSpeed'], test_size=0.2)\ntrain_df = lgb.Dataset(data=x_train, label=y_train)\nval_df = lgb.Dataset(data=x_val, label=y_val)\n\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=30)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_trial_params = {'application': 'regression',\n              'boosting': 'gbdt',\n              'metric': 'rmse',\n              'lambda_l1': 9.74072609344885e-07,\n              'num_iterations': 993, \n              'lambda_l2': 1.0171525633411312e-08, \n              'num_leaves': 185, \n              'feature_fraction': 0.5408811645819958, \n              'bagging_fraction': 0.6886405927130945, \n              'bagging_freq': 6, \n              'min_child_samples': 8, \n              'max_depth': 0, \n              'learning_rate': 0.0011093564515343194}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Running lgb on vanilla dataset","metadata":{}},{"cell_type":"code","source":"train_vanilla = train.copy()\ntest_vanilla = test.copy()\n\ntrain_vanilla = feature_eng(train_vanilla)\ntest_vanilla = feature_eng(test_vanilla)\nmodel_vanilla, oof_train_vanilla, oof_test_vanilla, labels_vanilla = run_lgb(best_trial_params, train_vanilla, test_vanilla)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Running lgb on full dataset (with metadata and sentiment)","metadata":{}},{"cell_type":"code","source":"train_meta_sent = train_full.copy()\ntest_meta_sent = test_full.copy()\n\ntrain_engineered = feature_eng(train_meta_sent)\ntest_engineered = feature_eng(test_meta_sent)\nmodel_full, oof_train_full, oof_test_full, labels_full = run_lgb(best_trial_params, train_engineered, test_engineered)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's look at feature importances","metadata":{}},{"cell_type":"code","source":"plot_feature_importance(model_full, labels_full)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Running lgb on top important features","metadata":{}},{"cell_type":"code","source":"train_top_features = train_engineered.copy()\ntest_top_features = test_engineered.copy()\ntrain_top_features = train_top_features.drop(['Color3', 'VideoAmt', 'Health', 'Breed2', 'metadata_crop_conf', 'Color1', 'Color2', 'State', 'Type'], axis=1)\ntest_top_features = test_top_features.drop(['Color3', 'VideoAmt', 'Health', 'Breed2', 'metadata_crop_conf', 'Color1', 'Color2', 'State', 'Type'], axis=1)\nmodel_top_features, oof_train_top_features, oof_test_top_features, labels_top_features = run_lgb(best_trial_params, train_engineered, test_engineered)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# XGBoost","metadata":{}},{"cell_type":"markdown","source":"Here we will use Optuna hyperparameter optimization framework to find best parameters for XGBoost algorithm. Then xgb will be trained on three sets of data: vanilla, full and with top selected features. Vanilla dataset is loaded as it is provided, cleaned and engineered. Full dataset consists of additional metadata and sentiment data. Top features are selected after checking feature importance on model, trained on full dataset.\n\nVanilla dataset (with no metadata and sentiment)\n- Prediction time: 11.5 ms\n- Kaggle score: 0.17\n- QWK on validation: 0.24\n\nFull dataset\n- Prediction time:  10.5 ms\n- Kaggle score: 0.23\n- QWK on validation: 0.31\n\nTop features dataset\n- Prediction time: 10.0 ms\n- Kaggle score: 0.21\n- QWK on validation: 0.27","metadata":{}},{"cell_type":"code","source":"def objective(trial): \n    \n    param = {\n        \"num_class\": 5,\n        'learning_rate': trial.suggest_uniform('learning_rate', 0.01, 0.6),\n        'subsample': trial.suggest_uniform('subsample', 0.3, 0.9),\n        'max_depth': trial.suggest_int('max_depth', 3, 9),\n        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 0.9),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 4)\n             }\n    \n    xgb_opt = xgb.train(param, train_df, evals=eval_sets) \n    preds = xgb_opt.predict(val_df) \n    accuracy = sklearn.metrics.accuracy_score(y_val, preds)\n    \n    return accuracy\n\n\ndef run_xgb(params, train_data: pd.DataFrame, test_data:pd.DataFrame):\n    \"\"\"\n    Runs XGBoost algorithm with stratified-k fold cross validation.\n    Returns trained model, train and test predictions and list of feature labels for\n    feature importance.\n    \"\"\"\n    labels = train_data.drop('AdoptionSpeed', axis=1)\n    target = train_data['AdoptionSpeed']\n    \n    early_stop = 100\n    verbose_eval = 100\n    num_rounds = 10000\n    n_splits = 10\n\n    kfold = StratifiedKFold(n_splits=n_splits)\n\n    oof_train = np.zeros((train_data.shape[0]))\n    oof_test = np.zeros((test_data.shape[0], n_splits))\n\n    i = 0\n\n    for train_index, valid_index in kfold.split(labels, target):\n\n        X_tr = labels.iloc[train_index, :]\n        y_tr = target.iloc[train_index]\n\n        X_val = labels.iloc[valid_index, :]\n        y_val = target.iloc[valid_index]\n        \n        d_train = xgb.DMatrix(data=X_tr, label=y_tr, feature_names=X_tr.columns, enable_categorical=True)\n        d_valid = xgb.DMatrix(data=X_val, label=y_val, feature_names=X_val.columns, enable_categorical=True)\n        watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n\n        model = xgb.train(dtrain=d_train, \n                          num_boost_round=num_rounds, \n                          evals=watchlist,\n                          early_stopping_rounds=early_stop, \n                          verbose_eval=verbose_eval, \n                          params=params)\n\n        valid_pred = model.predict(xgb.DMatrix(X_val, feature_names=X_val.columns, enable_categorical=True), ntree_limit=model.best_ntree_limit)\n        test_pred = model.predict(xgb.DMatrix(test_data, feature_names=test_data.columns, enable_categorical=True), ntree_limit=model.best_ntree_limit)\n\n        oof_train[valid_index] = valid_pred\n        oof_test[:, i] = test_pred\n\n        i += 1\n\n    return model, oof_train, oof_test, labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### OPTUNA HYPERPARAMETER OPTIMIZATION FOR XGBOOST","metadata":{}},{"cell_type":"code","source":"x_train, x_val, y_train, y_val = train_test_split(train_engineered.drop(['AdoptionSpeed'], axis=1), train_engineered['AdoptionSpeed'], test_size=0.2)\ntrain_df = xgb.DMatrix(data=x_train, label=y_train, enable_categorical=True)\nval_df = xgb.DMatrix(data=x_val, label=y_val, enable_categorical=True)\neval_sets = [(train_df, 'train'), (val_df, 'eval')]\n\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=30)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_params = {'learning_rate': 0.27590960722568275, \n              'subsample': 0.5877312259287172, \n              'max_depth': 6, \n              'colsample_bytree': 0.8009700602022006, \n              'min_child_weight': 1}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Running xgb on vanilla dataset","metadata":{}},{"cell_type":"code","source":"train_vanilla = train.copy()\ntest_vanilla = test.copy()\n\ntrain_vanilla = feature_eng(train_vanilla)\ntest_vanilla = feature_eng(test_vanilla)\n\nmodel, oof_train, oof_test, labels = run_xgb(xgb_params, train_vanilla, test_vanilla)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Running xgb on full dataset (with metadata and sentiment)","metadata":{}},{"cell_type":"code","source":"train_meta_sent = train_full.copy()\ntest_meta_sent = test_full.copy()\n\ntrain_engineered = feature_eng(train_meta_sent)\ntest_engineered = feature_eng(test_meta_sent)\n\nmodel, oof_train, oof_test, labels = run_xgb(xgb_params, train_engineered, test_engineered)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"xgboost method plot_importance() stopped working one day, returning an error. Good thing that I managed to get feature importance before so I will use that information. Sorry for no picture.","metadata":{}},{"cell_type":"code","source":"#plot_importance(model) XGBoostError: [11:34:15] ../include/xgboost/feature_map.h:85: unknown feature type, use i for indicator and q for quantity","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Running xgb on top important features","metadata":{}},{"cell_type":"code","source":"train_top_features = train_engineered.copy()\ntest_top_features = test_engineered.copy()\n\ntrain_top_features = train_top_features[['metadata_label_score', 'metadata_color_score', 'metadata_color_pixelfrac', \n                                         'Description_length', 'Age', 'doc_sent_mag', 'doc_sent_score',\n                                         'PhotoAmt', 'Fee', 'Quantity', 'metadata_crop_importance', 'Type', 'AdoptionSpeed']]\n\ntest_top_features = test_top_features[['metadata_label_score', 'metadata_color_score', 'metadata_color_pixelfrac', \n                                         'Description_length', 'Age', 'doc_sent_mag', 'doc_sent_score',\n                                         'PhotoAmt', 'Fee', 'Quantity', 'metadata_crop_importance', 'Type']]\n\nmodel, oof_train, oof_test, labels = run_xgb(xgb_params, train_top_features, test_top_features)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Logistic Regression","metadata":{}},{"cell_type":"markdown","source":"Vanilla dataset (with no metadata and sentiment)\n- Prediction time: 9.77 ms\n- Kaggle score: 0.18668\n- QWK on validation: 0.17221939557390697\n\nFull dataset\n- Prediction time: 12.4 ms\n- Kaggle score: 0.20678\n- QWK on validation: 0.20868\n\nTop features dataset\n- Prediction time: 5.26 ms\n- Kaggle score: 0.05049\n- QWK on validation: 0.0831","metadata":{}},{"cell_type":"code","source":"def objective(trial):\n\n    param = {\n            'solver': trial.suggest_categorical('solver', ['newton-cg', 'lbfgs', 'sag']),\n            'penalty': trial.suggest_categorical('penalty', [\"l2\", \"none\"]),\n            'C': trial.suggest_uniform('C', 0.1, 1.0),\n            'class_weight': trial.suggest_categorical('class_weight', [\"balanced\", None])\n        }\n        \n    model = LogisticRegression(**param, max_iter=500, random_state=12)\n    model.fit(x_train, y_train)\n    preds = model.predict(x_val)\n    accuracy = sklearn.metrics.accuracy_score(y_val, preds)\n    \n    return accuracy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### OPTUNA HYPERPARAMETER OPTIMIZATION FOR LOGISTIC REGRESSION ","metadata":{}},{"cell_type":"code","source":"x_train, x_val, y_train, y_val = train_test_split(train_engineered.drop(['AdoptionSpeed'], axis=1), train_engineered['AdoptionSpeed'], test_size=0.2)\n\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {'solver': 'newton-cg', 'penalty': 'none', 'C': 0.1, 'class_weight': 'balanced'}\nclf = LogisticRegression(**params, max_iter=5000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Running logistic regression on vanilla dataset","metadata":{}},{"cell_type":"code","source":"train_vanilla = train.copy()\ntest_vanilla = test.copy()\n\ntrain_vanilla = feature_eng(train_vanilla)\ntest_vanilla = feature_eng(test_vanilla)\n\ntarget = train_vanilla['AdoptionSpeed']\nfeatures = train_vanilla.drop('AdoptionSpeed', axis=1)\n\nclf.fit(features, target)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Running logistic regression on full dataset","metadata":{}},{"cell_type":"code","source":"train_full_copy = train_full.copy()\ntest_full_copy = test_full.copy()\n\ntrain_full_copy = feature_eng(train_full_copy)\ntest_full_copy = feature_eng(test_full_copy)\n\ntarget = train_full_copy['AdoptionSpeed']\nfeatures = train_full_copy.drop('AdoptionSpeed', axis=1)\n\nclf.fit(features, target)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Cheking feature importance with RFE","metadata":{}},{"cell_type":"code","source":"selector = RFE(clf, n_features_to_select=1)\nselector = selector.fit(features, target)\nfeature_ranks = []\nfor i in selector.ranking_:\n    feature_ranks.append(f'{i}. {train_full_copy.columns[i]}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Running logistic regression on top features","metadata":{}},{"cell_type":"code","source":"train_full_copy = train_full.copy()\ntest_full_copy = test_full.copy()\n\ntrain_full_copy = feature_eng(train_full_copy)\ntest_full_copy = feature_eng(test_full_copy)\n\ntarget = train['AdoptionSpeed']\nfeatures = train_full_copy[['Color1', 'Gender', 'Breed2', 'Fee', 'PhotoAmt', 'metadata_color_score',\n                           'metadata_crop_importance', 'metadata_color_pixelfrac',\n                           'Color3', 'Quantity', 'Health', 'MaturitySize', 'doc_sent_score']]\n\ntest_features = test_full_copy[['Color1', 'Gender', 'Breed2', 'Fee', 'PhotoAmt', 'metadata_color_score',\n                           'metadata_crop_importance', 'metadata_color_pixelfrac',\n                           'Color3', 'Quantity', 'Health', 'MaturitySize', 'doc_sent_score']]\n\nclf.fit(features, target)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Code snippet to calculate quadratic weighted kappa score for validation dataset for logistic regression","metadata":{}},{"cell_type":"code","source":"x_train, x_val, y_train, y_val = train_test_split(features, target, test_size=0.2)\nclf.fit(x_train, y_train)\npred_val = clf.predict(x_val)\nqwk = quadratic_weighted_kappa(y_val, pred_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Code snippet to predict with logistic regression and submit predictions","metadata":{}},{"cell_type":"code","source":"test_predictions = clf.predict(test_features)\nsubmission = pd.DataFrame({'PetID': test['PetID'].values, 'AdoptionSpeed': test_predictions.astype(np.int32)})\nsubmission.to_csv('submission.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Code snippet to calculate quadratic weighted kappa score for validation datasets for LGBM and XGBoost","metadata":{}},{"cell_type":"code","source":"optR = OptimizedRounder()\noptR.fit(oof_train, target)\ncoefficients = optR.coefficients()\npred_test_y_k = optR.predict(oof_train, coefficients)\nqwk = quadratic_weighted_kappa(target, pred_test_y_k)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Code snippet to predict with LGBM and XGBoost and submit predictions","metadata":{}},{"cell_type":"code","source":"test_predictions = optR.predict(oof_test.mean(axis=1), coefficients)\nsubmission = pd.DataFrame({'PetID': test['PetID'].values, 'AdoptionSpeed': test_predictions.astype(np.int32)})\nsubmission.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Summary table","metadata":{}},{"cell_type":"code","source":"data = {'Algorithm': ['Vanilla features', 'All features', 'Top features'], \n        'Logistic reg CV': [0.172, 0.209, 0.083], \n        'Logistic reg Kaggle': [0.187, 0.206, 0.05],\n        'XGBoost CV': [0.241, 0.317, 0.272],\n        'XGBoost Kaggle': [0.173, 0.235, 0.218],\n        'LightGBM CV': [0.403, 0.391, 0.412],\n        'LightGBM Kaggle': [0.351, 0.333, 0.348]}\n\ndf = pd.DataFrame(data=data)\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}