{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{"id":"1LMY4LDcckHM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Section 0\n\n=== *You must run this section to set up things for any of the sections below * ===\n### Setting up Python tools\n\n\n\nWe'll use three libraries for this tutorial: \n- [pandas](http://pandas.pydata.org/) : dataframes for spreadsheet-like data analysis, reading CSV files, time series\n- [numpy](http://www.numpy.org/) : for multidimensional data and linear algebra tools\n- [matplotlib](http://matplotlib.org/) : Simple plotting and graphing\n- [seaborn](http://stanford.edu/~mwaskom/software/seaborn/) : more advanced graphing\n-  [scikit-learn](https://scikit-learn.org/stable/) : provides many machine learning algorithms and tools to training and test.\n\n\n","metadata":{"id":"KmZ4LSJ7XLR9"}},{"cell_type":"code","source":"# We will turn off some warns in this notebook to make it easier to read for new students\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# First, we'll import pandas and numpy, two data processing libraries\nimport pandas as pd\nimport numpy as np\n\n# We'll also import seaborn and matplot, twp Python graphing libraries\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# Import the needed sklearn libraries\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import LabelEncoder\n\n# The Keras library provides support for neural networks and deep learning\n# Use the updated Keras library from Tensorflow -- provides support for neural networks and deep learning\nimport tensorflow.keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Lambda, Flatten, LSTM\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras.optimizers import Adam, RMSprop\n#from tensorflow.keras.utils import np_utils\nfrom tensorflow.keras.utils import to_categorical\n\nprint (\"All libraries imported\")","metadata":{"id":"RHAUKyWlWQ9L","outputId":"1623c7af-9cf0-41d6-8d67-5b34c30cc32b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Task 1: PetFinder Kaggle Challenge\n\nSign up for the [PetFinder.my Adoption Prediction challenge on Kaggle](https://www.kaggle.com/c/petfinder-adoption-prediction).\n\nHere is a summary of the data\n\nIn the writeup below you will need to enter your Kaggle user name.\n\n### Pet Data Fields\n- PetID - Unique hash ID of pet profile\n- AdoptionSpeed - Categorical speed of adoption. Lower is faster. This is the value to predict. See below section for more info.\n- Type - Type of animal (1 = Dog, 2 = Cat)\n- Name - Name of pet (Empty if not named)\n- Age - Age of pet when listed, in months\n- Breed1 - Primary breed of pet (Refer to BreedLabels dictionary)\n- Breed2 - Secondary breed of pet, if pet is of mixed breed (Refer to BreedLabels dictionary)\n- Gender - Gender of pet (1 = Male, 2 = Female, 3 = Mixed, if profile represents group of pets)\n- Color1 - Color 1 of pet (Refer to ColorLabels dictionary)\n- Color2 - Color 2 of pet (Refer to ColorLabels dictionary)\n- Color3 - Color 3 of pet (Refer to ColorLabels dictionary)\n- MaturitySize - Size at maturity (1 = Small, 2 = Medium, 3 = Large, 4 = Extra Large, 0 = Not Specified)\n- FurLength - Fur length (1 = Short, 2 = Medium, 3 = Long, 0 = Not Specified)\n- Vaccinated - Pet has been vaccinated (1 = Yes, 2 = No, 3 = Not Sure)\n- Dewormed - Pet has been dewormed (1 = Yes, 2 = No, 3 = Not Sure)\n- Sterilized - Pet has been spayed / neutered (1 = Yes, 2 = No, 3 = Not Sure)\n- Health - Health Condition (1 = Healthy, 2 = Minor Injury, 3 = Serious Injury, 0 = Not Specified)\n- Quantity - Number of pets represented in profile\n- Fee - Adoption fee (0 = Free)\n- State - State location in Malaysia (Refer to StateLabels dictionary)\n- RescuerID - Unique hash ID of rescuer\n- VideoAmt - Total uploaded videos for this pet\n- PhotoAmt - Total uploaded photos for this pet\n- Description - Profile write-up for this pet. The primary language used is English, with some in Malay or Chinese.\n### AdoptionSpeed\nContestants are required to predict this value. The value is determined by how quickly, if at all, a pet is adopted. The values are determined in the following way: \n- 0 - Pet was adopted on the same day as it was listed. \n- 1 - Pet was adopted between 1 and 7 days (1st week) after being listed. \n- 2 - Pet was adopted between 8 and 30 days (1st month) after being listed. \n- 3 - Pet was adopted between 31 and 90 days (2nd & 3rd month) after being listed. \n- 4 - No adoption after 100 days of being listed. (There are no pets in this dataset that waited between 90 and 100 days).\n\n### File descriptions\n- train.csv - Tabular/text data for the training set\n- train.csv - Tabular/text data for the training set\n- test.csv - Tabular/text data for the test set\n- sample_submission.csv - A sample submission file in the correct format\n- breed_labels.csv - Contains Type, and BreedName for each BreedID. Type 1 is dog, 2 is cat.\n- color_labels.csv - Contains ColorName for each ColorID\n- state_labels.csv - Contains StateName for each StateID","metadata":{"id":"sTvnB7XwvScZ"}},{"cell_type":"markdown","source":"# Section 1:  Set up Pet Data\n\n","metadata":{"id":"mEuPVnRDdGpu"}},{"cell_type":"markdown","source":"### Set up the Input and output\n\n- Training data: Information on 14,993 pets up for adoption\n- Submission data: Information on 3,948 pets where we need to predict adoption time\n\n### NOTE: This dataset is somewhat large and loading it may take a minute or two \n","metadata":{"id":"YZ1dW8lJvScd"}},{"cell_type":"code","source":"# Use this variable to read data from the actual Kaggle download files stored in a raw file in GitHub\ngithub_folder = 'https://raw.githubusercontent.com/CIS3115-Machine-Learning-Scholastica/CIS3115ML-Units7and8/master/petfinder-adoption/'\n# Use this variable within the Kaggle enviroment to use their internal data\nkaggle_folder = '../input/petfinder-adoption-prediction/'\n\n# data_folder = github_folder\n# Uncomment the next line to switch from using the github files to the kaggle files for a submission\ndata_folder = kaggle_folder\n\ntrain = pd.read_csv(data_folder + 'train/train.csv')\nsubmit = pd.read_csv(data_folder + 'test/test.csv')\n\nsample_submission = pd.read_csv(data_folder + 'test/sample_submission.csv')\nlabels_breed = pd.read_csv(data_folder + 'breed_labels.csv')\nlabels_color = pd.read_csv(data_folder + 'color_labels.csv')\nlabels_state = pd.read_csv(data_folder + 'state_labels.csv')\n\nprint (\"training data shape: \" ,train.shape)\nprint (\"submission data shape: : \" ,submit.shape)","metadata":{"id":"Z_gd5XuZvScg","outputId":"7cc2df6d-445c-4459-e6d1-db6bdcd44e94"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"Rx9hBWGZihAo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head(5)","metadata":{"id":"3ZwZyUXT9eSg","outputId":"719bce64-f2ef-47f7-c5de-befa60f67978"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Task 2: Select features\n\nSelect which pet features to include in the training data. You should also select the same features for the submission.\n\nNote that you may want to modify some features and you can add them in future cells.\n","metadata":{"id":"OUDwOkl9PZde"}},{"cell_type":"code","source":"#from tensorflow.keras.utils import to_categorical\n\n# Select which features to use\npet_train = train[['Age','Type','Health','MaturitySize', 'Fee', 'Breed1', 'Breed2']]\n# Everything we do to the training data we also should do the the submission data\npet_submit = submit[['Age','Type','Health','MaturitySize', 'Fee', 'Breed1', 'Breed2']]\n\n# Convert output to one-hot encoding\npet_adopt_speed = to_categorical( train['AdoptionSpeed'] )\n\nprint (\"pet_train data shape: \" ,pet_train.shape)\nprint (\"pet_submit data shape: \" ,pet_submit.shape)\nprint (\"pet_adopt_speed data shape: \" ,pet_adopt_speed.shape)\n","metadata":{"id":"qvM7dhR59eSj","outputId":"3df317ca-7c93-425a-d936-7d02b99fc4b3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Task 3: Encode some features\n\nSome numeric features like color and breed are called categorical features. Even though they may be enoced as a number, the numbers do not relate numerically to each other. So if one dog has color 2 and  dog two has color 4, this does not mean dog two is twice as colorful as dog one. It only means that they have different colors. One might be light brown and the other gray.\n\n\nFor neural networks it works better when encode categorical data as one-hot encoding. See [An Overview of Categorical Input Handling for Neural Networks](https://towardsdatascience.com/an-overview-of-categorical-input-handling-for-neural-networks-c172ba552dee) for more details.\n\n\nSince this is a common need, the pandas library has a built in method, [pandas.get_dummies](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html), for generating dummy variables based a categorical variable. For additional information on this, see \n[The Dummyâ€™s Guide to Creating Dummy Variables](https://towardsdatascience.com/the-dummys-guide-to-creating-dummy-variables-f21faddb1d40)\n\n\n","metadata":{"id":"C7XoT08lSRb0"}},{"cell_type":"code","source":"# Add any columns to the list below that you want dummy variables created\ncat_columns = ['Breed1', 'Breed2']\n\n# You should not need to change any code below this line\n# =======================================================\n\n# Create the dummy variables for the columns listed above\ndfTemp = pd.get_dummies( train[cat_columns], columns=cat_columns )\npet_train = pd.concat([pet_train, dfTemp], axis='columns')\n\n# Do the same to the submission data\ndfSummit = pd.get_dummies( submit[cat_columns], columns=cat_columns )\npet_submit = pd.concat([pet_submit, dfSummit], axis='columns')\n# Get missing columns in the submission data\nmissing_cols = set( pet_train.columns ) - set( pet_submit.columns )\n# Add a missing column to the submission set with default value equal to 0\nfor c in missing_cols:\n    pet_submit[c] = 0\n# Ensure the order of column in the test set is in the same order than in train set\npet_submit = pet_submit[pet_train.columns]\n\n","metadata":{"id":"N2WObN0q44FT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We should check the that the number of features is not too large and that the training and submission data still have the same number of features\n\n\n\n# print out the current data\nprint (\"Size of pet_train = \", pet_train.shape)\nprint (\"Size of pet_submit = \", pet_submit.shape)\npet_train.head(5)","metadata":{"id":"v9Ejd1uHGKuZ","outputId":"a9000a06-4572-4e5c-e1fb-41d2cc31da1d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Modify some features\n\nNeural networks perform best when the numeric data has relative meaning. For example, a pet's age is used since we know that a pet that's 9 months old is similar to a pet that's 10 months old since 9 and 10 are relatively close to each other numerically. Likewise, a 60 month old pet is different from a 9 month year old pet since 60 and 9 are far apart numerically.\n\nSome features may need to be modified. For example, Vaccinated has values of  (1 = Yes, 2 = No, 3 = Not Sure) but this will confuse a neural network because these numbers are not relative to each other. So, it might be better to encode Yes as + 1 and No as -1 and then have Not Sure as 0 since that would be relatively in the middle between -1 and +1.\n\nThe code for doing this is beyond the scope of this course, so you may want to simply avoid features where the numerical values are not relative. If you are interested in coding, the following code defines a function to do so, and then the map method applies this function to each pet's Vaccinated feature.\n\nAgain, everything we do to the training data, we also need to do to the submission data.\n\n","metadata":{"id":"Lkkbh-5uQIwy"}},{"cell_type":"code","source":"# Vaccinated - Pet has been vaccinated (1 = Yes, 2 = No, 3 = Not Sure)\n#encodedVaccinated = train[['Vaccinated']] \ndef fixVac( value ):\n    if value == 1: return +1\n    elif value == 2: return -1\n    else: return 0\n\npet_train.head(10)","metadata":{"id":"9OEJd-Fr9eSm","outputId":"c1aa449d-82fa-495c-927c-0339d5fd882a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Type = (Dog = 1, cat = 0)\n#encodedType = train[['Type']] \ndef fixType( value ):\n    if value > 1: return 0\n    else: return value\n\n#train['encodedVaccinated'] = list(map(lambda a: 0 if (a>1) else a,train['Vaccinated']))\npet_train['encodedType'] = list(map(fixType,train['Type']))\n# Do the same thing to the submission data\npet_submit['encodedType'] = list(map(fixType,submit['Type']))\n\npet_train.head(10)","metadata":{"id":"xB0pCeqOJF78","outputId":"eb9697c0-6501-4a5e-cae0-7d8b176528d3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"id":"O-7_xF5L42yG"}},{"cell_type":"code","source":"print (\"pet_train data shape: \" ,pet_train.shape)\nprint (\"pet_adopt_speed data shape: \" ,pet_adopt_speed.shape)\nprint (\"pet_submit data shape: \" ,pet_submit.shape)\n","metadata":{"id":"yAHNOrk49eSr","outputId":"9f869483-2332-4f63-860e-5834607b9dd8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n### Scale and Split the data\n\n**Scale Data:** Neural Networks work best with the inputs are between 0 and +1, but the grayscale images have pixel values between 0 and 255. So, each pixel value is divided by 255 to scale it.\n\n**Submission:** We do the same thing for the submission data\n\n**Split the Data:** The training data is split with 90% used for training and 10% used for testing.","metadata":{"id":"a_XBCy6SSq_l"}},{"cell_type":"code","source":"# Scale the data to put large features like area_mean on the same footing as small features like smoothness_mean\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nscaler = StandardScaler()\npet_train_scaled = scaler.fit_transform(pet_train)\npet_submit_scaled = scaler.fit_transform(pet_submit)\n\npet_train_scaled","metadata":{"id":"RlQcJg04CtGO","outputId":"18c7362a-87e7-43ca-df21-234511f96a53"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the data into 80% for training and 10% for testing out the models\nX_train, X_test, y_train, y_test = train_test_split(pet_train_scaled, pet_adopt_speed, test_size=0.1)\n\nprint (\"X_train training data shape of 28x28 pixels greyscale: \" ,X_train.shape)\nprint (\"X_test submission data shape of 28x28 pixels greyscale: : \" ,X_test.shape)\n\nprint (\"y_train training data shape of 28x28 pixels greyscale: \" ,y_train.shape)\nprint (\"y_test submission data shape of 28x28 pixels greyscale: : \" ,y_test.shape)","metadata":{"id":"XbkB0OYe9eSw","outputId":"9513dab7-72e8-42f8-bec5-011afef48289"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Neural Network\n\nSet up the layers of the Neural Network\n\nOne possibly configuration would be:\n\n```\nmodel = Sequential()\nmodel.add(Dense(20, activation='relu', input_dim=(input_Size)))\nmodel.add(Dense(10, activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(10, activation='relu'))\nmodel.add(Dense(output_Size, activation='softmax'))\n```\n\nThough, you should try your own configuration. We will eventually look at networks of 50+ layers, but for now I suggest you limit yourself to 3-5 hidden layers. \n\n\n*Note: You should not change the input or output layers, they are fixed by our problem definition*","metadata":{"id":"hwoi3GqJvSdG"}},{"cell_type":"code","source":"# Set up the Neural Network\ninput_Size = X_test.shape[1]     # This is the number of features you selected for each pet\noutput_Size = y_train.shape[1]   # This is the number of categories for adoption speed, should be 5\n\nmodel = Sequential()\nmodel.add(Dense(200, activation='relu', input_dim=(input_Size)))\n#model.add(Dropout(0.3))\nmodel.add(Dense(100, activation='relu'))\nmodel.add(Dense(10, activation='relu'))\nmodel.add(Dense(output_Size, activation='softmax'))\n\n# Compile neural network model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\nprint (\"Neural Network created\")\nmodel.summary()","metadata":{"id":"M1H9GVNvvSdM","outputId":"d3d52f6f-47f6-4a5c-e65a-1942cd82a00c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Callbacks\n\n-  [ReduceLROnPlateau](https://keras.io/callbacks/#reducelronplateau). \n\n-  [EarlyStopping callback](https://keras.io/callbacks/#earlystopping) \n\n-  [ModelCheckpoint callback](https://keras.io/callbacks/#modelcheckpoint) ","metadata":{"id":"LT2ZSVeXvSdo"}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', \n                                            patience=5, \n                                            verbose=2, \n                                            factor=0.5,                                            \n                                            min_lr=0.000001)\n\nearly_stops = EarlyStopping(monitor='val_loss', \n                            min_delta=0, \n                            patience=20, \n                            verbose=2, \n                            mode='auto')\n\ncheckpointer = ModelCheckpoint(filepath = 'cis6115_PetFinder.{epoch:02d}-{accuracy:.6f}.hdf5',\n                               verbose=2,\n                               save_best_only=True, \n                               save_weights_only = True)\n","metadata":{"id":"U-k7Y9H-2wUr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train the Neural Network\n\nWe are only using 10 epochs initially, but you should consider running more epochs","metadata":{"id":"3Tfrh9G5bYXl"}},{"cell_type":"code","source":"# Fit model on training data for network with dense input layer\n\nhistory = model.fit(X_train, y_train,\n          epochs=100,\n          verbose=1,\n          callbacks=[learning_rate_reduction, early_stops],\n          validation_data=(X_test, y_test))\n","metadata":{"id":"pMeiCJoZvSd6","outputId":"699a5e90-d510-4450-df60-149ed1b881ee"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 10. Evaluate model on test data\nprint (\"Running final scoring on test data\")\nscore = model.evaluate(X_test, y_test, verbose=1)\nprint (\"The accuracy for this model is \", format(score[1], \",.2f\"))","metadata":{"id":"Y965DSk5vSeJ","outputId":"30086b82-0099-4326-8795-a7f0a5ed3e9c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot the Training History\n\nWe store the performance during training in a variable named 'history'. The x-axis is the training time or number of epochs.\n\n- Accuracy: Accuracy of the predictions; hopefully this is increasing to near 1.0\n- Loss: How close the output is to the desired output; this should decrease to near 0.0","metadata":{"id":"KJiV__LbvSeO"}},{"cell_type":"code","source":"# We will display the loss and the accuracy of the model for each epoch\n# NOTE: this is a little fancy display than is shown in the textbook\ndef display_training_curves(training, validation, title, subplot):\n    if subplot%10==1: # set up the subplots on the first call\n        plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n        plt.tight_layout()\n    ax = plt.subplot(subplot)\n    ax.set_facecolor('#F8F8F8')\n    ax.plot(training)\n    ax.plot(validation)\n    ax.set_title('model '+ title)\n    ax.set_ylabel(title)\n    #ax.set_ylim(0.28,1.05)\n    ax.set_xlabel('epoch')\n    ax.legend(['train', 'valid.'])\ndisplay_training_curves(history.history['loss'], history.history['val_loss'], 'loss', 211)\ndisplay_training_curves(history.history['accuracy'], history.history['val_accuracy'], 'accuracy', 212)","metadata":{"id":"EsT7FG9SvSeP","outputId":"7e878207-a188-4a1d-c703-476cd7816be3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Section 2: Create the Submission for Kaggle\n\nThe following code generates a file named submission.csv for the [PetFinder.my Adoption Prediction challenge on Kaggle](https://www.kaggle.com/c/petfinder-adoption-prediction).\n\nOnce you have this notebook working, you must load it up as a kernel in the Kaggle challenge.\n\n\n\n\n\n","metadata":{"id":"xAHcXCEcfzIL"}},{"cell_type":"code","source":"print (\"pet_train data shape: \" ,pet_train.shape)\nprint (\"submit data shape: \" ,submit.shape)\nprint (\"pet_submit data shape: \" ,pet_submit_scaled.shape)\n","metadata":{"id":"R_vn3B18-Adk","outputId":"0473fc7e-d229-4dc4-a9bc-ec2d40099fdc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_nums = model.predict(pet_submit_scaled, verbose=1)\npredictions = np.argmax(predict_nums,axis=1)\n\nsubmissions=pd.DataFrame({'PetID': submit.PetID})\nsubmissions['AdoptionSpeed'] = predictions\n\nsubmissions.to_csv(\"submission.csv\", index=False, header=True)\n\nsubmissions.head(10)","metadata":{"id":"NKSi64z70XNv","outputId":"0af45269-b9a1-40d4-c38d-4ceec8fdf0c7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"hNmZlPcKWv12"},"execution_count":null,"outputs":[]}]}