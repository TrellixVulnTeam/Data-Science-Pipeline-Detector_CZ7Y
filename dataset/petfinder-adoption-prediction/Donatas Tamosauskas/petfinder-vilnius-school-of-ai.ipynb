{"cells":[{"metadata":{},"cell_type":"markdown","source":"# PetFinder | Vilnius School of AI"},{"metadata":{},"cell_type":"markdown","source":"## Setting up the notebook & importing data"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nfrom pathlib import Path\nimport json\n\nfrom fastprogress import progress_bar\nfrom tqdm.auto import tqdm\n\ntqdm.pandas()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ROOT_PATH = Path(\"../input\")\nTRAIN_IMAGE_PATH = ROOT_PATH/\"train_images\"\nTEST_IMAGE_PATH = ROOT_PATH/\"test_images\"\nWORKING_PATH = Path(\"../working\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv(ROOT_PATH/\"train/train.csv\")\ntest_data = pd.read_csv(ROOT_PATH/\"test/test.csv\")\n\nstate_labels = pd.read_csv(ROOT_PATH/\"state_labels.csv\")\ncolor_labels = pd.read_csv(ROOT_PATH/\"color_labels.csv\")\nbreed_labels = pd.read_csv(ROOT_PATH/\"breed_labels.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Train set length: {len(train_data)}, test set length: {len(test_data)}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head(4).transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.describe().transpose()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Adding magnitude and sentiment features to the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import codecs\n\ndef add_sentiment_and_magnitude(dataset, json_path):\n    magnitude = []\n    sentiment = []\n    \n    for pet_id in tqdm(dataset['PetID']):\n        try:\n            with codecs.open(json_path/(pet_id + \".json\"), encoding='UTF-8') as json_file:\n                doc_sentiment = json.load(json_file)['documentSentiment']\n                magnitude.append(doc_sentiment['magnitude'])\n                sentiment.append(doc_sentiment['score'])\n        except FileNotFoundError:\n            magnitude.append(np.nan)\n            sentiment.append(np.nan)\n            \n    return pd.DataFrame({'PetID':dataset['PetID'], 'magnitude': magnitude, 'sentiment':sentiment})\n\ndef expand_with_sentiment(dataset, json_path=ROOT_PATH/\"train_sentiment/\"):\n    sentiment_data = add_sentiment_and_magnitude(dataset, json_path)\n    return pd.merge(dataset, sentiment_data, on='PetID')\n\ndef add_no_photo_feature():\n    pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = expand_with_sentiment(train_data)\ntest_data = expand_with_sentiment(test_data, json_path=ROOT_PATH/\"test_sentiment/\")    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Expetimenting with metadata"},{"metadata":{},"cell_type":"markdown","source":"## Creating fast.ai tabular databunch\nIdeas:\n - Shoud create a column whether the breed2, color3 label is present\n - Add magnitude and score from sentiment\n - Add embedding from the images (if one exists)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating a validation set\n\nvalid_data = train_data[-2000:]\n# train_data = train_data[:-2000]\ntrain_data = train_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from fastai.tabular import *\n\nprocedures = [FillMissing, Categorify, Normalize]\nvalid_id = range(len(train_data) - 2000, len(train_data))\n\ndependant_var = 'AdoptionSpeed'\nnot_used_cols = ['RescuerID', 'Description', 'PetID', 'Breed2', 'Color3']\nused_cols = [col for col in train_data.columns if col not in not_used_cols]\ncontinious_cols = ['Age', 'Fee', 'magnitude', 'sentiment']\ncategorical_cols = ['Type', 'Name', 'Breed1', 'Gender', 'Color1', 'Color2',\n       'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n       'Sterilized', 'Health', 'Quantity', 'State', 'VideoAmt', 'PhotoAmt']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def create_data_bunch(use_val=True):\n    if use_val:\n        return TabularDataBunch.from_df(\n            WORKING_PATH, \n            train_data[used_cols],\n            dep_var = dependant_var,\n            valid_idx = valid_id,\n            cat_names = categorical_cols,\n            cont_names = continious_cols,\n            procs = procedures,\n        )\n    else:\n        return TabularDataBunch.from_df(\n            WORKING_PATH, \n            train_data[used_cols],\n            dep_var = dependant_var,\n            valid_idx = [],\n            cat_names = categorical_cols,\n            cont_names = continious_cols,\n            procs = procedures,\n        )\n\ndata_bunch = create_data_bunch()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating and training the model"},{"metadata":{"trusted":false},"cell_type":"code","source":"def create_tabular_learner(data_bunch=data_bunch):\n    learner = tabular_learner(\n        data_bunch,\n        layers=[200,100],\n        emb_szs={\n            'Name': 10,\n            'Breed1':10,\n        },\n        metrics=accuracy\n    )\n    \n    return learner\n\nlearner = create_tabular_learner()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"learner.lr_find()\nlearner.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"learner.fit_one_cycle(1, 0.01)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Evaluating the model\nEvaluation used in kaggle competition is Quadratic Weighted Kappa (I sourced the implementation from [this github](https://github.com/benhamner/Metrics/blob/master/Python/ml_metrics/quadratic_weighted_kappa.py))"},{"metadata":{},"cell_type":"markdown","source":"# Image learner"},{"metadata":{"trusted":false},"cell_type":"code","source":"from fastai.vision import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#  Creating black images for pets without images\n\ndef generate_black_img(location):\n    img_arr = np.zeros([224, 224, 3], dtype=np.uint8)\n    img_arr.fill(0)\n    imsave(location/\"black_img.jpg\", img_arr)\n\ndef add_photo_name_col(df):\n    df_with_photos = df[df['PhotoAmt'] > 0].copy()\n    df_with_photos['photo_name'] = df_with_photos['PetID'] + '-1.jpg'\n    \n#     df_with_photos = df.copy()\n#     df['photo_name'] = df.progress_apply(lambda x: x['PetId'] + '-1.jpg' if x['PhotoAmt'] > 0 else \"black_img.jpg\", axis='columns')\n    return df_with_photos\n\n\n# generate_black_img(TRAIN_IMAGE_PATH)\nimage_train_data = add_photo_name_col(train_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_image_data = ImageDataBunch.from_df(\n    TRAIN_IMAGE_PATH,\n    image_train_data[['photo_name', 'AdoptionSpeed']][:4000], \n    seed=1,\n    ds_tfms=get_transforms(),\n    size=112,\n)\n\ntrain_image_data.show_batch()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"image_learner = cnn_learner(\n    train_image_data,\n    base_arch=models.resnet50,\n    model_dir=\"/tmp/model/\",\n)\n\nimage_learner.lr_find()\nimage_learner.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"image_learner.fit_one_cycle(6, 0.01)\nimage_learner.save(\"112_6cycles\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"image_learner.unfreeze()\n\nimage_learner.lr_find()\nimage_learner.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"image_learner.load(\"112_6cycles\")\nimage_learner.fit_one_cycle(3, slice(1e-5, 0.01))\nimage_learner.save(\"112_6cycles_2cycles\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fit with higher resolution"},{"metadata":{"trusted":false},"cell_type":"code","source":"image_learner.freeze()\n\ntrain_image_data = ImageDataBunch.from_df(\n    TRAIN_IMAGE_PATH,\n    image_train_data[['photo_name', 'AdoptionSpeed']], \n    seed=1,\n    ds_tfms=get_transforms(),\n    size=224,\n)\n\nimage_learner.data = train_image_data\n\nimage_learner.lr_find()\nimage_learner.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"image_learner.fit_one_cycle(5, 1e-3)\nimage_learner.save(\"224_5cycles\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"image_learner.unfreeze()\nimage_learner.lr_find()\nimage_learner.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"image_learner.load(\"224_5cycles\")\nimage_learner.fit_one_cycle(3, slice(1e-5,1e-3 / 3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Adding image model predictions to tabular data"},{"metadata":{"trusted":false},"cell_type":"code","source":"def predict_image(row, img_path, model):\n    if row['PhotoAmt'] > 0:\n        # Might be a good idea to take the average of all picture predictions\n        return model.predict(open_image(img_path/(row['PetID'] + \"-1.jpg\")))[2].numpy()\n    else:\n        return model.predict(Image(torch.from_numpy(np.random.random([3, 224, 224])).float()))[2].numpy()\n\ndef add_image_preds(model, img_path, tab_data):\n    copy_of_tab = tab_data.copy()\n    \n    img_preds = tab_data.progress_apply(lambda x: predict_image(x, img_path, model), axis='columns')\n    column_names = [f\"embedding_{i}\" for i in range(img_preds.iloc[0].shape[0])]\n    copy_of_tab[column_names] = pd.DataFrame(img_preds.values.tolist())\n    return copy_of_tab\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_data_with_image = add_image_preds(image_learner, TRAIN_IMAGE_PATH, train_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Re-fit with all of the data"},{"metadata":{"trusted":false},"cell_type":"code","source":"# full_data = train_data.append(valid_data)\n# full_data_bunch = create_data_bunch(use_val=False)\n\ndef create_data_bunch_emb(dataset, visual_learner, use_val=True):    \n    used_cols = [col for col in dataset.columns if col not in not_used_cols]\n    \n    if 'embedding_0' not in dataset.columns:\n        dataset = add_image_preds(visual_learner, TRAIN_IMAGE_PATH, dataset)\n    \n    data_with_image = TabularDataBunch.from_df(\n        WORKING_PATH, \n        dataset[used_cols],\n        dep_var = dependant_var,\n        valid_idx = valid_id if use_val else [],\n        cat_names = categorical_cols,\n        cont_names = continious_cols,\n        procs = procedures,\n    )\n\n    return data_with_image\n\nfull_data_bunch = create_data_bunch_emb(train_data_with_image, image_learner)\nfull_learner = create_tabular_learner(data_bunch=full_data_bunch)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"full_learner.lr_find()\nfull_learner.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"full_learner = create_tabular_learner(data_bunch=full_data_bunch)\nfull_learner.fit_one_cycle(1, 0.005)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluation"},{"metadata":{"trusted":false},"cell_type":"code","source":"def confusion_matrix(rater_a, rater_b, min_rating=None, max_rating=None):\n    \"\"\"\n    Returns the confusion matrix between rater's ratings\n    \"\"\"\n    assert(len(rater_a) == len(rater_b))\n    if min_rating is None:\n        min_rating = min(rater_a + rater_b)\n    if max_rating is None:\n        max_rating = max(rater_a + rater_b)\n    num_ratings = int(max_rating - min_rating + 1)\n    conf_mat = [[0 for i in range(num_ratings)]\n                for j in range(num_ratings)]\n    for a, b in zip(rater_a, rater_b):\n        conf_mat[a - min_rating][b - min_rating] += 1\n    return conf_mat\n\ndef histogram(ratings, min_rating=None, max_rating=None):\n    \"\"\"\n    Returns the counts of each type of rating that a rater made\n    \"\"\"\n    if min_rating is None:\n        min_rating = min(ratings)\n    if max_rating is None:\n        max_rating = max(ratings)\n    num_ratings = int(max_rating - min_rating + 1)\n    hist_ratings = [0 for x in range(num_ratings)]\n    for r in ratings:\n        hist_ratings[r - min_rating] += 1\n    return hist_ratings\n\ndef quadratic_weighted_kappa(rater_a, rater_b, min_rating=None, max_rating=None):\n    \"\"\"\n    Calculates the quadratic weighted kappa\n    quadratic_weighted_kappa calculates the quadratic weighted kappa\n    value, which is a measure of inter-rater agreement between two raters\n    that provide discrete numeric ratings.  Potential values range from -1\n    (representing complete disagreement) to 1 (representing complete\n    agreement).  A kappa value of 0 is expected if all agreement is due to\n    chance.\n    quadratic_weighted_kappa(rater_a, rater_b), where rater_a and rater_b\n    each correspond to a list of integer ratings.  These lists must have the\n    same length.\n    The ratings should be integers, and it is assumed that they contain\n    the complete range of possible ratings.\n    quadratic_weighted_kappa(X, min_rating, max_rating), where min_rating\n    is the minimum possible rating, and max_rating is the maximum possible\n    rating\n    \"\"\"\n    rater_a = np.array(rater_a, dtype=int)\n    rater_b = np.array(rater_b, dtype=int)\n    assert(len(rater_a) == len(rater_b))\n    if min_rating is None:\n        min_rating = min(min(rater_a), min(rater_b))\n    if max_rating is None:\n        max_rating = max(max(rater_a), max(rater_b))\n    conf_mat = confusion_matrix(rater_a, rater_b,\n                                min_rating, max_rating)\n    num_ratings = len(conf_mat)\n    num_scored_items = float(len(rater_a))\n\n    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n\n    numerator = 0.0\n    denominator = 0.0\n\n    for i in range(num_ratings):\n        for j in range(num_ratings):\n            expected_count = (hist_rater_a[i] * hist_rater_b[j]\n                              / num_scored_items)\n            d = pow(i - j, 2.0) / pow(num_ratings - 1, 2.0)\n            numerator += d * conf_mat[i][j] / num_scored_items\n            denominator += d * expected_count / num_scored_items\n\n    return 1.0 - numerator / denominator","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def get_prediction(learner, sample):\n    return int(learner.predict(sample)[1])\n\ndef evaluate_model(learner, dataset, target='AdoptionSpeed'):\n    dataset = dataset.reset_index()\n    data_len = len(dataset)\n    \n    predictions = dataset.progress_apply(lambda x: get_prediction(learner, x), axis='columns')\n#     predictions = Parallel(n_jobs=4)(delayed(get_prediction)(sample) for sample in tqdm(dataset.itertuples()))\n    \n    accuracy = ((dataset[target] == pd.Series(predictions)).sum() / data_len)\n    qwk = quadratic_weighted_kappa(dataset[target], predictions, min_rating=0, max_rating=4)\n    \n    return accuracy, qwk, predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_emb_data = add_image_preds(image_learner, TRAIN_IMAGE_PATH, train_data[:100])\nvalid_emb_data = add_image_preds(image_learner, TRAIN_IMAGE_PATH, valid_data[:2000])\n\ntrain_acc, train_qwk, train_preds = evaluate_model(full_learner, train_emb_data[:100])\nvalid_acc, valid_qwk, valid_preds = evaluate_model(full_learner, valid_emb_data[:2000])\n\nprint(f\"Training acc: {train_acc} | Validation acc: {valid_acc}\")\nprint(f\"Training qwk: {train_qwk:.03f} | Validation qwk: {valid_qwk:.03f}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating submissions"},{"metadata":{"trusted":false},"cell_type":"code","source":"def prepare_test_preds(test_data, learner):\n    test_preds = test_data.progress_apply(lambda x: get_prediction(learner, x), axis='columns')\n    test_preds.index = test_data['PetID']\n    test_preds = test_preds.reset_index()\n    test_preds.columns = ['PetID', 'AdoptionSpeed']\n    return test_preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test_data_emb = add_image_preds(image_learner, TEST_IMAGE_PATH, test_data[:100])\ntest_preds_df = prepare_test_preds(test_data_emb, full_learner)\ntest_preds_df.to_csv(WORKING_PATH/\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Scores\n1. Initial: 0.24226"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"nbformat":4,"nbformat_minor":1}