{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the \"../input/\" directory.\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport matplotlib.pyplot as plt\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"path='/kaggle/input/petfinder-sentiment/'\npath1='/kaggle/input/petfinder-adoption-prediction/'\n# t=pd.read_json(path+'train_sentiment/25a834a2e.json', orient='split')\ntrain_meta=pd.read_csv(path+'train_meta.csv')\ntrain_meta\ntest_meta=pd.read_csv(path+'test_meta.csv')\ntest_meta\nstate=pd.read_csv(path1+'StateLabels.csv')\nstate\nstateNames=[]\nfor x in train_meta.State:\n    for j in range(len(state.StateID)):\n        if x==state.StateID[j]:\n            h= state.StateName[j]\n            stateNames.append(h)\n            break\ntrain_meta['StateName']=stateNames\n\nstateNames=[]\nfor x in test_meta.State:\n    for j in range(len(state.StateID)):\n        if x==state.StateID[j]:\n            h= state.StateName[j]\n            stateNames.append(h)\n            break\ntest_meta['StateName']=stateNames\ntest_meta","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_meta.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stateAdoption=train_meta.groupby('StateName').agg({'PetID': ['count']}).reset_index()\nstateAdoption.columns=['StateName','countPetID']\nstateAdoption\nplt.figure(figsize=(20,11))\n# plt.title(\"Distribution of PetID by States\")\nplt.xlabel('States of Malaysia')\nplt.ylabel('Counted by PetID')\nplt.plot(stateAdoption.StateName,stateAdoption.countPetID)\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_meta.State.isnull().count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stateAdoption0=train_meta[train_meta.AdoptionSpeed==0].groupby('StateName').agg({'PetID': ['count']}).reset_index()\nstateAdoption0.columns=['State','AdoptionSpeed0']\nstateAdoption0=stateAdoption0.sort_values(by=['State'])\n\nstateAdoption1=train_meta[train_meta.AdoptionSpeed==1].groupby('StateName').agg({'PetID': ['count']}).reset_index()\nstateAdoption1.columns=['State','AdoptionSpeed1']\nstateAdoption1=stateAdoption1.sort_values(by=['State'])\n\nstateAdoption2=train_meta[train_meta.AdoptionSpeed==2].groupby('StateName').agg({'PetID': ['count']}).reset_index()\nstateAdoption2.columns=['State','AdoptionSpeed2']\nstateAdoption2=stateAdoption2.sort_values(by=['State'])\n\nstateAdoption3=train_meta[train_meta.AdoptionSpeed==3].groupby('StateName').agg({'PetID': ['count']}).reset_index()\nstateAdoption3.columns=['State','AdoptionSpeed3']\nstateAdoption3=stateAdoption3.sort_values(by=['State'])\n\nstateAdoption4=train_meta[train_meta.AdoptionSpeed==4].groupby('StateName').agg({'PetID': ['count']}).reset_index()\nstateAdoption4.columns=['State','AdoptionSpeed4']\nstateAdoption4=stateAdoption4.sort_values(by=['State'])\n\n# print('AdoptionSpeed==0')\n# stateAdoption\nfig = plt.figure(figsize=(15,7))\n# plt.set_title('Distribution of PetID by States')\nplt.xlabel('States of Malaysia')\nplt.ylabel('Counted by PetID')\nplt.scatter(stateAdoption0.State,stateAdoption0.AdoptionSpeed0,c='g',label='AdoptionSpeed=0',s=200)\nplt.scatter(stateAdoption1.State,stateAdoption1.AdoptionSpeed1,c='b',label='AdoptionSpeed=1',s=150)\nplt.scatter(stateAdoption2.State,stateAdoption2.AdoptionSpeed2,c='yellow',label='AdoptionSpeed=2',s=100)\nplt.scatter(stateAdoption3.State,stateAdoption3.AdoptionSpeed3,c='pink',label='AdoptionSpeed=3',s=50)\nplt.scatter(stateAdoption4.State,stateAdoption4.AdoptionSpeed4,c='black',label='AdoptionSpeed=4',s=25)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_meta.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# count the number of duplicate values\nfrom collections import Counter\nc = Counter(list(zip(train_meta.columns)))\nc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_meta.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f = plt.figure(figsize=(19, 15))\nplt.matshow(train_meta.corr(), fignum=f.number)\nplt.xticks(range(train_meta.shape[1]), train_meta.columns, fontsize=14, rotation=45)\nplt.yticks(range(train_meta.shape[1]), train_meta.columns, fontsize=14)\ncb = plt.colorbar()\ncb.ax.tick_params(labelsize=14)\nplt.title('Correlation Matrix', fontsize=16);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_meta.hist(figsize=(15,15))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Linear Regression?\n\n# PCA to see the data in 2 components\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\nfeatures=[\"AdoptionSpeed\",'Name','RescuerID','Description','PetID','StateName','RescuerID','Color1Name','Breed1Name']\nx = train_meta.drop(features, axis=1).values #returns a numpy array\nmin_max_scaler = preprocessing.MinMaxScaler()\nx_scaled = min_max_scaler.fit_transform(x)\ndf = pd.DataFrame(x_scaled)\n\npca = PCA(n_components=2)\nprincipalComponents=pca.fit_transform(df)\nprincipalDf = pd.DataFrame(data = principalComponents\n             , columns = ['principal component 1', 'principal component 2'])\nfinalDf = pd.concat([principalDf, train_meta[['AdoptionSpeed']]], axis = 1)\nfinalDf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(finalDf['AdoptionSpeed'],finalDf['principal component 1'], c = 'red',s=50)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(finalDf['principal component 2']\n               , finalDf['AdoptionSpeed']\n               , c = 'red',s=50)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca.explained_variance_ratio_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA(n_components=1)\nprincipalComponents=pca.fit_transform(train_meta.drop(features, axis=1))\nprincipalDf = pd.DataFrame(data = principalComponents\n             , columns = ['principal component 1'])\nfinalDf = pd.concat([principalDf, train_meta[['AdoptionSpeed']]], axis = 1)\nplt.scatter(finalDf['principal component 1']\n               , finalDf['AdoptionSpeed']\n               , c = 'r'\n               , s = 50)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### No LInear Regression. \n# CHeck feature importances with forests of trees (without 5 object: [\"AdoptionSpeed\",'Name','RescuerID','Description','PetID'] features)"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_meta.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfeatures.append('Unnamed: 0')\nfeatures.append('Unnamed: 0.1')\nfeat=train_meta.drop(features, axis=1).columns\nfeat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This examples shows the use of forests of trees to evaluate the importance of features on an artificial classification task. \n# The red bars are the feature importances of the forest, along with their inter-trees variability.\nprint(__doc__)\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.datasets import make_classification\nfrom sklearn.ensemble import ExtraTreesClassifier\n\nX=train_meta.drop(features, axis=1)\nY=train_meta[\"AdoptionSpeed\"]\n\n# Build a forest and compute the feature importances\nforest = ExtraTreesClassifier(n_estimators=250,\n                              random_state=0)\n\nforest.fit(X, Y)\nimportances = forest.feature_importances_\nstd = np.std([tree.feature_importances_ for tree in forest.estimators_],\n             axis=0)\nindices = np.argsort(importances)[::-1]\n\n# Print the feature ranking\nprint(\"Feature ranking:\")\n\nfor f in range(X.shape[1]):\n    print(\"%d. feature %d %s (%f)\" % (f + 1, indices[f], feat[indices[f]],importances[indices[f]]))\n\nxvalues=[feat[x] for x in indices]\nplt.rcParams[\"figure.figsize\"] = (20,15)\n# Plot the feature importances of the forest\nplt.figure()\nplt.title(\"Feature importances\")\nplt.bar(range(X.shape[1]), importances[indices],\n       color=\"r\", yerr=std[indices], align=\"center\")\nplt.xticks(range(X.shape[1]), xvalues)\nplt.xlim([-1, X.shape[1]])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logistic regression with the 2 most features ('Age', 'PhotoAmt').\n# Validation: misclassified samples: 1490, accuracy: 0.34"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.datasets import fetch_mldata\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nimport pandas as pd\nimport numpy as np\n\nX=train_meta[['Age', 'PhotoAmt']]\nY=train_meta[\"AdoptionSpeed\"]\n# valid_size: what proportion of original data is used for valid set\ntrain, valid, train_lbl, valid_lbl = train_test_split(\n    X, Y, test_size=0.15, random_state=122)\n#Normalization\nscaler = StandardScaler()\n# Fit on training set only.\nscaler.fit(train)\n# Apply transform to both the training set and the test set.\ntrain1 = scaler.transform(train)\nvalid1 = scaler.transform(valid)\ntest1=scaler.transform(test_meta[['Age', 'PhotoAmt']])\n\n#fit the model\nmodel = LogisticRegression(solver = 'lbfgs')\nmodel.fit(train1, train_lbl)\n\n#Validating the fit\n# use the model to make predictions with the test data\ny_pred = model.predict(valid1)\n# how did our model perform?\ncount_misclassified = (valid_lbl != y_pred).sum()\nprint('Misclassified samples: {}'.format(count_misclassified))\naccuracy = metrics.accuracy_score(valid_lbl, y_pred)\nprint('Accuracy: {:.2f}'.format(accuracy))\nplt.rcParams[\"figure.figsize\"] = (7,5)\n# Plot the feature importances of the forest\nplt.figure()\nplt.scatter(valid_lbl, y_pred)\nprint(y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logistic regression with numeric features (except 'AdoptionSpeed','Name','RescuerID','Description','PetID').\n# Validation: misclassified samples: 1441, accuracy: 0.36"},{"metadata":{"trusted":true},"cell_type":"code","source":"features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_meta[features.remove('AdoptionSpeed')].columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.datasets import fetch_mldata\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nimport pandas as pd\nimport numpy as np\nfeatures=['Unnamed: 0','Unnamed: 0.1','Name','RescuerID','Description','PetID','StateName','Color1Name','Breed1Name','AdoptionSpeed']\nX=train_meta.drop(features, axis=1)\nY=train_meta[\"AdoptionSpeed\"]\n# valid_size: what proportion of original data is used for valid set\ntrain, valid, train_lbl, valid_lbl = train_test_split(\n    X, Y, test_size=0.15, random_state=122)\n#Normalization\nscaler = StandardScaler()\n# Fit on training set only.\nscaler.fit(train)\n# Apply transform to both the training set and the test set.\ntrain1 = scaler.transform(train)\nvalid1 = scaler.transform(valid)\n\ntest_X=test_meta.drop(['Unnamed: 0','Unnamed: 0.1','Name','RescuerID','Description','PetID','StateName','Color1Name','Breed1Name'], axis=1)\n# print(test_X)\nscaler.fit(test_X)\ntest1=scaler.transform(test_X)\n#fit the model\nmodel = LogisticRegression(solver = 'lbfgs')\nmodel.fit(train1, train_lbl)\n\n#Validating the fit\n# use the model to make predictions with the test data\ny_pred = model.predict(valid1)\n# how did our model perform?\ncount_misclassified = (valid_lbl != y_pred).sum()\nprint('Misclassified samples: {}'.format(count_misclassified))\naccuracy = metrics.accuracy_score(valid_lbl, y_pred)\nprint('Accuracy: {:.2f}'.format(accuracy))\n\nplt.scatter(valid_lbl, y_pred)\n# print(y_pred)\n\n#submission\ny_pred = model.predict(test1)\n# test_X.columns\nsubmission=pd.DataFrame(columns=['PetID','AdoptionSpeed'])\nsubmission['PetID']=test_meta['PetID']\nsubmission['AdoptionSpeed']=y_pred\nsubmission.head()\nsubmission['AdoptionSpeed'].hist()\nsubmission.to_csv('submission.csv', index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission=pd.read_csv('submission.csv')\nsubmission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#submit\nsubmission=model.predict(test1)\nsubmission = pd.DataFrame(data = submission\n             , columns = ['AdoptionSpeed'])\nsubmission = pd.concat([test_meta['PetID'], submission], axis = 1)\nsubmission.to_csv('samplesubmission.csv', index=False)\nsubmission","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logistic regression with PCA components: finalDf['principal component 1', 'principal component 2', 'AdoptionSpeed'].\n# Validation: misclassified samples: 1606, accuracy: 0.29"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.datasets import fetch_mldata\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nimport pandas as pd\nimport numpy as np\n\nX=finalDf.drop([\"AdoptionSpeed\"], axis=1)\nY=finalDf[\"AdoptionSpeed\"]\n# valid_size: what proportion of original data is used for valid set\ntrain, valid, train_lbl, valid_lbl = train_test_split(\n    X, Y, test_size=0.15, random_state=122)\n#fit the model\nmodel = LogisticRegression(solver = 'lbfgs')\nmodel.fit(train, train_lbl)\n\n#Validating the fit\n# use the model to make predictions with the test data\ny_pred = model.predict(valid)\n# how did our model perform?\ncount_misclassified = (valid_lbl != y_pred).sum()\nprint('Misclassified samples: {}'.format(count_misclassified))\naccuracy = metrics.accuracy_score(valid_lbl, y_pred)\nprint('Accuracy: {:.2f}'.format(accuracy))\n\nplt.scatter(valid_lbl, y_pred)\nprint(y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Decison Trees\nDecision Tree is one of the most powerful and popular algorithm. Decision-tree algorithm falls under the category of supervised learning algorithms. It works for both continuous as well as categorical output variables.\n\n## Results Using Gini Index, Accuracy :  37.17905968656219\n## Results Using Entropy Index, Accuracy :  37.145715238412805"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing the required packages \nimport numpy as np \nimport pandas as pd \nimport math\nfrom sklearn.metrics import confusion_matrix \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier \nfrom sklearn.metrics import accuracy_score \nfrom sklearn.metrics import classification_report\n\n# Function to perform training with giniIndex. \ndef train_using_gini(X_train, X_test, y_train): \n  \n    # Creating the classifier object \n    clf_gini = DecisionTreeClassifier(criterion = \"gini\", \n            random_state = 100,max_depth=3, min_samples_leaf=5) \n  \n    # Performing training \n    clf_gini.fit(X_train, y_train) \n    return clf_gini \n      \n# Function to perform training with entropy. \ndef train_using_entropy(X_train, X_test, y_train): \n  \n    # Decision tree with entropy \n    clf_entropy = DecisionTreeClassifier( \n            criterion = \"entropy\", random_state = 100, \n            max_depth = 3, min_samples_leaf = 5) \n  \n    # Performing training \n    clf_entropy.fit(X_train, y_train) \n    return clf_entropy \n  \n  \n# Function to make predictions \ndef prediction(X_test, clf_object): \n  \n    # Predicton on test with giniIndex \n    y_pred = clf_object.predict(X_test) \n    print(\"Predicted values:\") \n    print(y_pred) \n    return y_pred \n      \n# Function to calculate accuracy \ndef cal_accuracy(y_test, y_pred): \n      \n    print(\"Confusion Matrix: \", \n        confusion_matrix(y_test, y_pred)) \n      \n    print (\"Accuracy : \", \n    accuracy_score(y_test,y_pred)*100) \n      \n    print(\"Report : \", \n    classification_report(y_test, y_pred)) \n    \n    \nX=train_meta.drop([\"AdoptionSpeed\",'Name','RescuerID','Description','PetID','StateName'], axis=1)\nY=train_meta[\"AdoptionSpeed\"]\nX_train, X_valid, y_train, y_valid = train_test_split( \n          X, Y, test_size = 0.2, random_state = 100)\n\nclf_gini = train_using_gini(X_train, X_valid, y_train) \nclf_entropy = train_using_entropy(X_train, X_valid, y_train) \n      \n# Operational Phase \nprint(\"Results Using Gini Index:\") \n      \n# Prediction using gini \ny_pred_gini = prediction(X_valid, clf_gini) \ncal_accuracy(y_valid, y_pred_gini) \n      \nprint(\"Results Using Entropy:\") \n# Prediction using entropy \ny_pred_entropy = prediction(X_valid, clf_entropy) \ncal_accuracy(y_valid, y_pred_entropy) \n\n#Predict for the test_meta based on GINI:\n# Operational Phase \nprint(\"Results Using Gini Index for test_meta:\") \n# Prediction using gini \nX_test=test_meta.drop(['Name','RescuerID','Description','PetID'], axis=1)\ny_pred_gini = prediction(X_test, clf_gini) \ny_valid_gini=  prediction(X_valid, clf_gini) \nprint(\"Results Using Entropy:\") \n# Prediction using entropy \ny_pred_entropy = prediction(X_test, clf_entropy) \n\nprint('diff between Decison Tree with gini and entropy, check their histogram')\nprint('GINI prediction for test_meta histogram:')\n_=plt.hist(y_pred_gini, bins='auto')\nplt.title(\"Histogram with 'auto' bins for GINI\")\nplt.show()\n\nprint('ENTROPY prediction for test histogram:')\n\n#submit\nsubmission_gini = pd.DataFrame(data = y_pred_gini\n             , columns = ['AdoptionSpeed'])\nsubmission_gini = pd.concat([test_meta['PetID'], submission_gini], axis = 1)\nsubmission_gini.to_csv('samplesubmissionTreeGini.csv', index=False)\n\nsubmission_entropy = pd.DataFrame(data = y_pred_gini\n             , columns = ['AdoptionSpeed'])\nsubmission_entropy = pd.concat([test_meta['PetID'], submission_entropy], axis = 1)\nsubmission_entropy.to_csv('samplesubmissionTreeEntropy.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_=plt.hist(y_pred_entropy, bins='auto')\nplt.title(\"Histogram with 'auto' bins for Entropy\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('ENTROPY prediction for test_meta histogram:')\n_=plt.hist(y_pred_entropy, bins='auto')\nplt.title(\"Histogram with 'auto' bins for ENTROPY\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize the decision tree: gini\nimport graphviz\nfrom sklearn import tree\ndata = tree.export_graphviz(clf_gini,out_file=None,feature_names=X_test.columns,class_names=[str(x) for x in range(5)],   \n                         filled=True, rounded=True,  \n                         special_characters=True)\ngraph = graphviz.Source(data)\ngraph","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random Forest"},{"metadata":{},"cell_type":"markdown","source":"# REVIEW:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Decision tree classifier – Decision tree classifier is a systematic approach for multiclass classification. \n# It poses a set of questions to the dataset (related to its attributes/features). \n# The decision tree classification algorithm can be visualized on a binary tree. \n# On the root and each of the internal nodes, a question is posed and the data on \n# that node is further split into separate records that have different characteristics. \n# The leaves of the tree refer to the classes in which the dataset is split. \n# In the following code snippet, we train a decision tree classifier in scikit-learn.\n# importing necessary libraries \nfrom sklearn import datasets \nfrom sklearn.metrics import confusion_matrix \nfrom sklearn.model_selection import train_test_split \n\nX=train_meta.drop([\"AdoptionSpeed\",'Name','RescuerID','Description','PetID'], axis=1)\nY=train_meta[\"AdoptionSpeed\"]\nX_train, X_valid, y_train, y_valid = train_test_split( \n          X, Y, test_size = 0.2, random_state = 100)\n# training a DescisionTreeClassifier \nfrom sklearn.tree import DecisionTreeClassifier \ndtree_model = DecisionTreeClassifier(max_depth = 4).fit(X_train, y_train) \ndtree_predictions = dtree_model.predict(X_valid) \n\n# creating a confusion matrix \ncm = confusion_matrix(y_valid, dtree_predictions) \nplot_confusion_matrix(cm, classes = ['0', '1','2','3','4'],\n                      title = 'Decision Tree Confusion Matrix (n=4)')\nplt.savefig('cmDecisionTree.png')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# KNN (k-nearest neighbours) classifier – \nKNN or k-nearest neighbours is the simplest classification algorithm. This classification algorithm does not depend on the structure of the data. Whenever a new example is encountered, its k nearest neighbours from the training data are examined. Distance between two examples can be the euclidean distance between their feature vectors. The majority class among the k nearest neighbours is taken to be the class for the encountered example."},{"metadata":{"trusted":true},"cell_type":"code","source":"# training a KNN classifier \nfrom sklearn.neighbors import KNeighborsClassifier \nknn = KNeighborsClassifier(n_neighbors = 7).fit(X_train, y_train) \n  \n# accuracy on X_test \naccuracy = knn.score(X_valid, y_valid) \nprint(accuracy)\n  \n# creating a confusion matrix \nknn_predictions = knn.predict(X_test)  \ncm = confusion_matrix(y_test, knn_predictions) \nplot_confusion_matrix(cm, classes = ['0', '1','2','3','4'],\n                      title = 'Decision Tree Confusion Matrix (n=4)')\nplt.savefig('cmDecisionTree.png')\n# X_test=test_meta.drop(['Name','RescuerID','Description','PetID'], axis=1)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# NLP for Name and Descriptions"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Name\n# Libraries\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n# train_meta.Name list of unique words ratio ..> 40% are duplication in names\nprint(\"Ratio of unique Name to the sample size: \",len(set(test_meta.Name.unique()))/len(list(test_meta.Name)))\n\n# train_meta.Name list of unique words ratio ..> 40% are duplication in names\nprint(\"Ratio of unique Description to the sample size: \",len(set(test_meta.Description.unique()))/len(list(test_meta.Description)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_meta.Name.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Name: Maximum and minimum font size\nt=''\nfor x in test_meta.Name:\n    t=t+str(x)\n\ntext_file = open(\"Names.txt\", \"wt\")\nn = text_file.write(t)\ntext_file.close()\n\nwordcloud = WordCloud(width=480, height=480, max_font_size=70, min_font_size=12).generate(t)\nplt.figure()\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.margins(x=0, y=0)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t=''\nfor x in test_meta.Name:\n    t=t+str(x)\nwordcloud = WordCloud(width=480, height=480, max_words=20).generate(t)\nplt.figure()\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.margins(x=0, y=0)\nplt.title(\"Top 20 names\")\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n\npath='/kaggle/input/petfinder/cat.png'\ncatdog_mask = np.array(Image.open(path))\n# catdog_mask\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_meta.AdoptionSpeed\ntest_meta.Type.hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dog\ndog=test_meta.Name[test_meta.Type==1]\nratioD=len(dog)/len(test_meta.Name)\nprint(ratioD)\n\npath='/kaggle/input/petfinder/dog.png'\ncatdog_mask = np.array(Image.open(path))\ncatdog_mask\n\n# Create a word cloud image\nwc = WordCloud(background_color=\"white\", max_words=1000, mask=catdog_mask, contour_width=3, contour_color='firebrick')\n\ntext = \" \".join(str(review) for review in dog)\ntext=set(text)\ntext = \" \".join(str(review) for review in dog)\n# nan_dog=text.find('nan')\n# text_dog=text.split(' ')\n\nprint(nan_dog)\n# Generate a wordcloud\nwc.generate(text)\n\n# store to file\nwc.to_file(\"dog.png\")\n\n# show\nplt.figure(figsize=[20,10])\nplt.imshow(wc, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dog\ndog=train_meta.Name[train_meta.Type==1]\nratioD=len(dog)/len(train_meta.Name)\nprint(ratioD)\n\npath='/kaggle/input/petfinder/dog.png'\ncatdog_mask = np.array(Image.open(path))\ncatdog_mask\n\n# Create a word cloud image\nwc = WordCloud(background_color=\"white\", max_words=1000, mask=catdog_mask, contour_width=3, \n               contour_color='firebrick',stopwords=['nan','No Name','NaN','And','For','The'])\n\ntext = \" \".join(str(review) for review in dog)\nnan_dog=text.find('nan')\ntext_dog=text.split(' ')\nprint(nan_dog)\n# Generate a wordcloud\nwc.generate(text)\n\n# store to file\nwc.to_file(\"dogSW.png\")\n\n# show\nplt.figure(figsize=[20,10])\nplt.imshow(wc, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Cat\ncat=test_meta.Name[test_meta.Type==2]\nratioC=len(cat)/len(test_meta.Name)\nprint(ratioC)\n\npath='/kaggle/input/petfinder/cat.png'\ncatdog_mask = np.array(Image.open(path))\ncatdog_mask\n\n# Create a word cloud image\nwc = WordCloud(background_color=\"white\", max_words=1000, mask=catdog_mask, contour_width=3, contour_color='firebrick')\n\ntext = \" \".join(str(review) for review in cat)\nnan_cat=text.find('nan')\ntext_cat=text.split(' ')\n# Generate a wordcloud\nwc.generate(text)\n\n# store to file\nwc.to_file(\"cat.png\")\n\n# show\nplt.figure(figsize=[20,10])\nplt.imshow(wc, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Cat\ncat=train_meta.Name[train_meta.Type==2]\nratioC=len(cat)/len(train_meta.Name)\nprint(ratioC)\n\npath='/kaggle/input/petfinder/cat.png'\ncatdog_mask = np.array(Image.open(path))\ncatdog_mask\n\n# Create a word cloud image\nwc = WordCloud(background_color=\"white\", max_words=1000, mask=catdog_mask, \n               contour_width=3, contour_color='firebrick',stopwords=['nan','No Name','NaN','And','For','The'])\n\ntext = \" \".join(str(review) for review in cat)\nnan_cat=text.find('nan')\ntext_cat=text.split(' ')\n# Generate a wordcloud\nwc.generate(text)\n\n# store to file\nwc.to_file(\"catSW.png\")\n\n# show\nplt.figure(figsize=[20,10])\nplt.imshow(wc, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_meta.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"obj_df = train_meta.select_dtypes(include=['object']).copy()\nobj_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(obj_df.shape)\nfor i in obj_df.columns:\n    t=set(obj_df[i].unique())\n    print('================================')\n    print(i,' has unique values= ', obj_df[i].unique(), ' : ',len(t) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"obj_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t=obj_df[\"StateName\"].value_counts()\nprint(t)\nt.plot(figsize =(10,10))\n#use it for label encoding\nprint(t.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"obj_df[obj_df.isnull().any(axis=1)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Hot One encoding for StateName\nfrom sklearn.preprocessing import LabelEncoder\nlb_make = LabelEncoder()\nobj_df[\"StateNameLabel\"] = lb_make.fit(t)\n\nobj_df[[\"make\", \"make_code\"]].head(11)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing metadata and sentiment data"},{"metadata":{"trusted":true},"cell_type":"code","source":"path='/kaggle/input/petfinder-adoption-prediction/'\n# t=pd.read_json(path+'train_sentiment/25a834a2e.json', orient='split')\ntrain_meta=pd.read_csv(path+'train/train.csv')\ntrain_meta\ntest_meta=pd.read_csv(path+'test/test.csv')\ntest_meta\nstate=pd.read_csv(path+'StateLabels.csv')\nstate\ncolor=pd.read_csv(path+'ColorLabels.csv')\ncolor\nbreed=pd.read_csv(path+'BreedLabels.csv')\nbreed\n# -----------STATE NAME--------------------\nstateNames=[]\nfor x in train_meta.State:\n    for j in range(len(state.StateID)):\n        if x==state.StateID[j]:\n            h= state.StateName[j]\n            stateNames.append(h)\n            break\ntrain_meta['StateName']=stateNames\n\nstateNames=[]\nfor x in test_meta.State:\n    for j in range(len(state.StateID)):\n        if x==state.StateID[j]:\n            h= state.StateName[j]\n            stateNames.append(h)\n            break\ntest_meta['StateName']=stateNames\n\n# -----------COLOR NAME--------------------\n# ------------------TRAIN for ColorName ---------------\ncolorNames=[]\nfor x in train_meta.Color1:\n    for j in range(len(color.ColorID)):\n        if x==color.ColorID[j]:\n            h= color.ColorName[j]\n            colorNames.append(h)\n            break\ntrain_meta['Color1Name']=colorNames\n# ------------------TEST for ColorName ---------------\ncolorNames=[]\nfor x in test_meta.Color1:\n    for j in range(len(color.ColorID)):\n        if x==color.ColorID[j]:\n            h= color.ColorName[j]\n            colorNames.append(h)\n            break\ntest_meta['Color1Name']=colorNames\n\n# -----------BREED NAME--------------------\n# ------------------TRAIN for BreedName ---------------\nbreedNames=[]\nfor x in train_meta.Breed1:\n    h=''\n    for j in range(len(breed.BreedID)):\n        if x==breed.BreedID[j]:\n            h= breed.BreedName[j]\n            breedNames.append(h)\n            break\n    if h=='':\n        breedNames.append('nan')\n#         if x.Type==1:\n#             breedNames.append('dog')\n#         else:\n#             breedNames.append('cat')\nprint('breedNames=',len(breedNames))\ntrain_meta['Breed1Name']=breedNames\n# ------------------TEST for BreedName ---------------\nbreedNames=[]\nfor i in test_meta.Breed1:\n    x=test_meta.Breed1[i]\n    h=''\n    for j in range(len(breed.BreedID)):\n        if x==breed.BreedID[j]:\n            h= breed.BreedName[j]\n            breedNames.append(h)\n            break\n    if h=='':\n        breedNames.append('nan')\n#         if x.Type==1:\n#             breedNames.append('dog')\n#         else:\n#             breedNames.append('cat')\ntest_meta['Breed1Name']=breedNames\n\n\nprint('**************************************')\nprint('Train data')\nprint('**************************************')\nprint('---------TRAIN dataset-------------')\nprint(train_meta.info())\nprint(train_meta.head())\nprint('---------TEST dataset-------------')\nprint(test_meta.info())\nprint(test_meta.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_meta['Breed1Name'][(train_meta.Type == 1) & (train_meta.Breed1Name == 'nan')] = \"dog\"\ntrain_meta['Breed1Name'][(train_meta.Type == 2) & (train_meta.Breed1Name == 'nan')] = \"cat\"\ntrain_meta[train_meta.Breed1Name=='nan']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_meta['Breed1Name'][(test_meta.Type == 1) & (test_meta.Breed1Name == 'nan')] = \"dog\"\ntest_meta['Breed1Name'][(test_meta.Type == 2) & (test_meta.Breed1Name == 'nan')] = \"cat\"\ntest_meta[test_meta.Breed1Name=='nan']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_meta.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#24/12/2019\ntrain.to_csv('train_meta.csv')#: including name of states, color1, breed1\ntest.to_csv('test_meta.csv')\n# # read from train_meta.csv and test_meta.csv\n# # train=pd.read_csv('train_meta.csv')\n# # train\n# test=pd.read_csv('test_meta.csv')\n# test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"breed.groupby(['Type'])['BreedID'].count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Sentiment data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# # FOR TRAIN dataset\n# # fillna for Description column\n# train['Description'][(train.Type == 1) & (train.Description.isnull())] = \"dog\"\n# train['Description'][(train.Type == 2) & (train.Description.isnull())] = \"cat\"\n# train[train.Description.isnull()]\n# # fillna for Name column\n# train['Name'][(train.Type == 1) & (train.Name.isnull())] = \"dog\"\n# train['Name'][(train.Type == 2) & (train.Name.isnull())] = \"cat\"\n# train[train.Name.isnull()]\n\n# # FOR TEST dataset\n# # fillna for Description column\n# test['Description'][(test.Type == 1) & (test.Description.isnull())] = \"dog\"\n# test['Description'][(test.Type == 2) & (test.Description.isnull())] = \"cat\"\n# test[test.Description.isnull()]\n# # fillna for Name column\n# test['Name'][(test.Type == 1) & (test.Name.isnull())] = \"dog\"\n# test['Name'][(test.Type == 2) & (test.Name.isnull())] = \"cat\"\n# test[test.Name.isnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print('---------TRAIN dataset-------------')\n# print(train.info())\n# print(train.head())\n# print('---------TEST dataset-------------')\n# print(test.info())\n# print(test.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print('train meta dataset len PetID= ',len(train.PetID.unique()))\n# print('**************************')\n# print(train.shape)\n# print(test.shape)\n# print('**************************')\n# print('train_dfs_metadata len PetID= ',len(train_dfs_metadata.PetID.unique()))\n# print(train_dfs_metadata.shape)\n# print(train_dfs_metadata.columns)\n# print(test_dfs_metadata.shape)\n# print('**************************')\n# print('train_dsf_sentiment len PetID= ',len(train_dsf_sentiment.PetID.unique()))\n# print(train_dsf_sentiment.shape)\n# print(train_dsf_sentiment.columns)\n# print(test_dfs_sentiment.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# %%timeit\n# t=pd.Series(list(set(train.PetID).intersection(set(train_dsf_sentiment.PetID))))\n# t=train.PetID[train.PetID.isin(train_dsf_sentiment.PetID)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train=train_meta[train_meta.PhotoAmt!=0].set_index('PetID')\n# print(train)\n# imagesAtt=imagesAtt.set_index('PetID')\n# print(imagesAtt.columns)\n# print(imagesAtt.head())\ntrain=train.drop(['Unnamed: 0','Unnamed: 0.1'],axis=1)\ntrain=train.drop(['Unnamed: 0.1'],axis=1)\ntrain['metadata_annots_score']=imagesAtt['metadata_annots_score']\ntrain['metadata_color_score']=imagesAtt['metadata_color_score']\ntrain['metadata_color_pixelfrac']=imagesAtt['metadata_color_pixelfrac']\ntrain['metadata_crop_conf']=imagesAtt['metadata_crop_conf']\nprint(train)\ntrain.to_csv('trainWithImageDatameda.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_meta.shape[0]-imagesAtt.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# t=train.PetID[train.PetID.isin(train_dsf_sentiment.PetID)]\n# columns in train.PetID that are not in train_dsf_sentiment.PetID\n# import numpy as np\n# c1 = np.setdiff1d(train.PetID, train_dsf_sentiment.PetID)\n# print(len(c1))\n# #save c1 to file: PetID not have sentiment data\n# np.savetxt(\"PetID_no_sentiment.csv\", c1, delimiter=\",\", fmt='%s')\n\n# t=train.PetID[train.PetID.isin(train_sentiment.PetID)]\n# columns in train.PetID that are not in train_sentiment.PetID\n# import numpy as np\n# c1 = np.setdiff1d(train.PetID, train_sentiment.PetID)\n# print(len(c1))\n# #save c1 to file: PetID not have sentiment data\n# np.savetxt(\"PetID_no_sentiment.csv\", c1, delimiter=\",\", fmt='%s')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"import pandas as pd\nPetID_no_sentiment = pd.read_csv(\"../input/petfinder-sentiment/PetID_no_sentiment.csv\")\ntest_dfs_metadata = pd.read_csv(\"../input/petfinder-sentiment/test_dfs_metadata.csv\")\ntest_dfs_sentiment = pd.read_csv(\"../input/petfinder-sentiment/test_dfs_sentiment.csv\")\ntest_meta = pd.read_csv(\"../input/petfinder-sentiment/test_meta.csv\")\ntrain_dfs_metadata = pd.read_csv(\"../input/petfinder-sentiment/train_dfs_metadata.csv\")\ntrain_dsf_sentiment = pd.read_csv(\"../input/petfinder-sentiment/train_dsf_sentiment.csv\")\ntrain_meta = pd.read_csv(\"../input/petfinder-sentiment/train_meta.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k=train_meta.groupby(['RescuerID'])['AdoptionSpeed'].count().reset_index(name='meanAdoptionSpeed')\nprint(k)\nk.meanAdoptionSpeed.hist()\nprint(k.meanAdoptionSpeed.min())\nprint(k.meanAdoptionSpeed.max())\nprint(k.meanAdoptionSpeed.mean())\nmaxRescuer=k[k.meanAdoptionSpeed==k.meanAdoptionSpeed.max()].RescuerID\nprint(maxRescuer)\nmaxR=train_meta[train_meta.RescuerID=='fa90fa5b1ee11c86938398b60abc32cb']\npd.set_option('display.max_rows', maxR.shape[0]+1)\nprint(maxR.groupby(['Type','Breed1Name','Age'])['PetID'].count())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k=train_meta.groupby(['RescuerID'])['AdoptionSpeed'].mean().reset_index(name='meanAdoptionSpeed')\nprint(k)\nk.meanAdoptionSpeed.hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#There are duplication of Names...try to label encoding\nprint('There are duplication of Names...try to label encoding')\nprint(train_meta.shape[0])\nprint(len(train_meta.Name.unique()))\nprint(1-len(train_meta.Name.unique())/train_meta.shape[0])\n\n\n#There are duplication of StateNames...try to label encoding\nprint('There are duplication of StateNames...try to label encoding')\nprint(train_meta.shape[0])\nprint(len(train_meta.StateName.unique()))\nprint(1-len(train_meta.StateName.unique())/train_meta.shape[0])\n\n#There are duplication of ColorNames...try to label encoding\nprint('There are duplication of ColorNames...try to label encoding')\nprint(train_meta.shape[0])\nprint(len(train_meta.Color1Name.unique()))\nprint(1-len(train_meta.Color1Name.unique())/train_meta.shape[0])\n\n#There are duplication of Breed1Names...try to label encoding\nprint('There are duplication of Breed1Names...try to label encoding')\nprint(train_meta.shape[0])\nprint(len(train_meta.Breed1Name.unique()))\nprint(1-len(train_meta.Breed1Name.unique())/train_meta.shape[0])\n\n#There are duplication of RescuerID...try to label encoding\nprint('There are duplication of RescuerID...try to label encoding')\nprint(train_meta.shape[0])\nprint(len(train_meta.RescuerID.unique()))\nprint(1-len(train_meta.RescuerID.unique())/train_meta.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Label encoding the Name, StateName, Color1Name, Breed1Name, RescuerID\n# Import label encoder \nfrom sklearn import preprocessing \n  \n# label_encoder object knows how to understand word labels. \nlabel_encoder = preprocessing.LabelEncoder() \n  \n# Encode labels in column 'Name'. \ntrain_meta['NameL']= label_encoder.fit_transform(train_meta['Name']) \n# Encode labels in column 'StateName'. \ntrain_meta['StateNameL']= label_encoder.fit_transform(train_meta['StateName']) \n# Encode labels in column 'Color1Name'. \ntrain_meta['Color1NameL']= label_encoder.fit_transform(train_meta['Color1Name']) \n# Encode labels in column 'Breed1Name'. \ntrain_meta['Breed1NameL']= label_encoder.fit_transform(train_meta['Breed1Name']) \n# Encode labels in column 'RescuerID'. \ntrain_meta['RescuerIDL']= label_encoder.fit_transform(train_meta['RescuerID']) \n\nprint(train_meta.head())\nprint(train_meta.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_meta=train_meta.drop(['Unnamed: 0', 'Unnamed: 0.1'],axis=1)\ntest_meta=test_meta.drop(['Unnamed: 0', 'Unnamed: 0.1'],axis=1)\nprint(train_meta.columns)\nprint(test_meta.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features=['Type', 'Age','Gender', 'MaturitySize', 'FurLength',\n       'Vaccinated', 'Dewormed', 'Sterilized', 'Health', 'Quantity', 'Fee',\n       'VideoAmt', 'PhotoAmt', 'NameL', 'StateNameL', 'Color1NameL', 'Breed1NameL', 'RescuerIDL']\nprint(train_meta[features].info())\ntrain_meta.drop(['AdoptionSpeed','Unnamed: 0', 'Unnamed: 0.1'],axis=1).corrwith(train_meta['AdoptionSpeed']).plot.bar(\n        figsize = (20, 10), title = \"Correlation with AdoptionSpeed\", fontsize = 15,\n        rot = 45, grid = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_meta[features].corrwith(train_meta['AdoptionSpeed']).plot.bar(\n        figsize = (20, 10), title = \"Correlation with AdoptionSpeed\", fontsize = 15,\n        rot = 45, grid = True)\ntrain_meta[features].hist(figsize=(15,15))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Basic Logistic Regression\n#LOgistic regression for features\n# features=['Type', 'Age','Gender', 'MaturitySize', 'FurLength',\n#        'Vaccinated', 'Dewormed', 'Sterilized', 'Health', 'Quantity', 'Fee',\n#        'VideoAmt', 'PhotoAmt', 'NameL', 'StateNameL', 'Color1NameL', 'Breed1NameL', 'RescuerIDL']\n#split train into training and testing/validating\nimport pandas as pd\nfrom sklearn import datasets, linear_model\nfrom sklearn.model_selection import train_test_split\nfrom matplotlib import pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\n\n# create training and testing vars\nX_train, X_valid, y_train, y_valid = train_test_split(train_meta[features], train_meta.AdoptionSpeed, test_size=0.2)\n\n#Scaling training and validating\nscaler = StandardScaler()\n# Apply transform to both the training set and the test set.\nscaler.fit(X_train)\nX_train = scaler.transform(X_train)\nX_valid = scaler.transform(X_valid)\n\n#Fit the model\nlogisticRegr = LogisticRegression()\nlogisticRegr.fit(X_train, y_train)\npredictions = logisticRegr.predict(X_valid)\n# Use score method to get accuracy of model\n# accuracy is defined as: \n# (fraction of correct predictions): correct predictions / total number of data points\nscore = logisticRegr.score(X_valid, y_valid)\nprint(score)\n\n# Confusion matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import metrics\n\ncm = metrics.confusion_matrix(y_valid, predictions)\nprint(cm)\nplt.figure(figsize=(9,9))\nsns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\nplt.ylabel('Actual label');\nplt.xlabel('Predicted label');\nall_sample_title = 'Accuracy Score: {0}'.format(score)\nplt.title(all_sample_title, size = 15);","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"\nprint('**************************************')\nprint('Meta data')\nprint('**************************************')\nprint('---------TRAIN dataset-------------')\nprint(train_meta.info())\nprint(train_meta.head())\nprint('---------TEST dataset-------------')\nprint(test_meta.info())\nprint(test_meta.head())\n\npath='../input/petfinder-sentiment/'\ntest_image = pd.read_csv(path+\"test_dfs_metadata.csv\")\ntest_sentiment = pd.read_csv(path+\"test_dfs_sentiment.csv\")\ntrain_image = pd.read_csv(path+\"train_dfs_metadata.csv\")\ntrain_sentiment = pd.read_csv(path+\"train_dsf_sentiment.csv\")\n# train_meta, test_meta\nprint('**************************************')\nprint('Meta data of images')\nprint('**************************************')\nprint('---------Meta data of images TRAIN dataset-------------')\nprint(train_image.info())\nprint(train_image.head())\nprint('---------Meta data of images TEST dataset-------------')\nprint(test_image.info())\nprint(test_image.head())\nprint('**************************************')\nprint('Sentiment data')\nprint('**************************************')\nprint('---------Sentiment data TRAIN dataset-------------')\nprint(train_sentiment.info())\nprint(train_sentiment.head())\nprint('---------Sentiment data TEST dataset-------------')\nprint(test_sentiment.info())\nprint(test_sentiment.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_image.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imagesAtt.hist(figsize=(15,15))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t=train_meta.PetID[train_meta.PetID.isin(train_image.PetID)]\n# columns in train.PetID that are not in train_dsf_sentiment.PetID\nimport numpy as np\nc1 = np.setdiff1d(train_meta.PetID, train_sentiment.PetID)\nprint(len(c1)/train_meta.shape[0])\n# #save c1 to file: PetID not have sentiment data\n# np.savetxt(\"PetID_no_sentiment.csv\", c1, delimiter=\",\", fmt='%s')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_sentiment.columns)\nprint(train_sentiment.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imagesAtt=test_image.groupby(['PetID'])['metadata_annots_score','metadata_color_score',\n                                         'metadata_color_pixelfrac','metadata_crop_conf',\n                                         'metadata_crop_importance'].mean().reset_index()\nsentimentAtt=test_sentiment.groupby(['PetID'])['sentiment_magnitude_sum',\n       'sentiment_score_sum', 'sentiment_magnitude_mean',\n       'sentiment_score_mean', 'sentiment_magnitude_var',\n       'sentiment_score_var', 'sentiment_magnitude_std', \n       'sentiment_score_std'].mean().reset_index()\n\nimport numpy as np\n# ratio of missing image metadata\nc1 = np.setdiff1d(test_meta.PetID, sentimentAtt.PetID)\nprint(len(c1)/test_meta.shape[0])\n# ratio of missing sentiment data\nc2 = np.setdiff1d(test_meta.PetID, imagesAtt.PetID)\nprint(len(c2)/test_meta.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 'trainWithImageDatameda.csv': contain images metadata\n# Index(['Type', 'Name', 'Age', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2',\n#        'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n#        'Sterilized', 'Health', 'Quantity', 'Fee', 'State', 'RescuerID',\n#        'VideoAmt', 'Description', 'PhotoAmt', 'AdoptionSpeed', 'StateName',\n#        'Color1Name', 'Breed1Name', 'NameL', 'StateNameL', 'Color1NameL',\n#        'Breed1NameL', 'RescuerIDL', 'metadata_annots_score',\n#        'metadata_color_score', 'metadata_color_pixelfrac',\n#        'metadata_crop_conf'],\n#       dtype='object')\nfeaturesImagesMeta=['Type', 'Age', 'Gender', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n       'Sterilized', 'Health', 'Quantity', 'Fee',\n       'VideoAmt', 'PhotoAmt', 'NameL', 'StateNameL', 'Color1NameL',\n       'Breed1NameL', 'RescuerIDL', 'metadata_annots_score',\n       'metadata_color_score', 'metadata_color_pixelfrac',\n       'metadata_crop_conf']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[featuresImagesMeta].corrwith(train['AdoptionSpeed']).plot.bar(\n        figsize = (20, 10), title = \"Images attributes is correlated with AdoptionSpeed\", fontsize = 15,\n        rot = 45, grid = True)\ntrain[featuresImagesMeta].hist(figsize=(15,15))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Logistics with imagesAtt\n# Basic Logistic Regression\n#LOgistic regression for features\n#split train into training and testing/validating\nimport pandas as pd\nfrom sklearn import datasets, linear_model\nfrom sklearn.model_selection import train_test_split\nfrom matplotlib import pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\n\n# create training and testing vars\nX_train, X_valid, y_train, y_valid = train_test_split(train[featuresImagesMeta],train.AdoptionSpeed, test_size=0.2)\n\n#Scaling training and validating\nscaler = StandardScaler()\n# Apply transform to both the training set and the test set.\nscaler.fit(X_train)\nX_train = scaler.transform(X_train)\nX_valid = scaler.transform(X_valid)\n\n#Fit the model\nlogisticRegr = LogisticRegression()\nlogisticRegr.fit(X_train, y_train)\npredictions = logisticRegr.predict(X_valid)\n# Use score method to get accuracy of model\n# accuracy is defined as: \n# (fraction of correct predictions): correct predictions / total number of data points\nscore = logisticRegr.score(X_valid, y_valid)\nprint(score)\n\n# Confusion matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import metrics\n\ncm = metrics.confusion_matrix(y_valid, predictions)\nprint(cm)\nplt.figure(figsize=(9,9))\nsns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\nplt.ylabel('Actual label');\nplt.xlabel('Predicted label');\nall_sample_title = 'Accuracy Score: {0}'.format(score)\nplt.title(all_sample_title, size = 15);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Basic Logistic Regression for sentiment and image metadata\nprint(train_sentiment.columns)\nprint(train_sentiment.info())\nprint(train_sentiment.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"featuresSent=train_sentiment.groupby(['PetID'])['sentiment_magnitude_sum',\n       'sentiment_score_sum', 'sentiment_magnitude_mean', 'sentiment_score_mean', 'sentiment_magnitude_var',\n       'sentiment_score_var', 'sentiment_magnitude_std', 'sentiment_score_std'].mean().reset_index()\nprint(len(train))\nprint(len(featuresSent))\nprint(len(imagesAtt))\nprint(len(train)-len(featuresSent))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=train.reset_index()\ntrain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nc1 = np.setdiff1d(test.PetID, featuresSent.PetID)\nprint(len(c1))\n#save c1 to file: PetID not have sentiment data\nnp.savetxt(\"PetID_no_sentiment.csv\", c1, delimiter=\",\", fmt='%s')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(featuresSent.PetID))\nprint(featuresSent)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(have_sent.PetID))\nprint(have_sent)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"have_sent=train[~train.PetID.isin(c1)]\nhave_sent.to_csv('train_images_PetID_forSent.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"have_sent","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"have_sent.set_index('PetID')\nhave_sent","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"featuresSent","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from functools import reducefeaturesSent.set_index('PetID')\nfeaturesSent.to_csv('featureSent.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"common_ID=np.intersect1d(featuresSent.PetID,have_sent.PetID)\ncommon_ID\nprint(len(common_ID))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_st=train[train.PetID.isin(common_ID)]\nprint(train_st.shape[0])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"featuresSent.columns\nfeaturesSent=featuresSent.set_index('PetID')\nfeaturesSent","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_st.columns\ntrain_st=train_st.set_index('PetID')\ntrain_st","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Add columns for train_st\n# 'train_images_PetID_forSent.csv'\n# 'featureSent'\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\npath='/kaggle/input/petfinder-sentiment/'\n\ntrain_st=pd.read_csv(path+'train_images_PetID_forSent.csv')\ntrain_st.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sent=pd.read_csv(path+'featureSent.csv')\nsent.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"common_ID=np.intersect1d(sent.PetID,train_st.PetID)\ncommon_ID\nprint(len(common_ID))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_st=train_st[train_st.PetID.isin(common_ID)]\nprint(train_st.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sent.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sent=sent.fillna(0)\nsent","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sent.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_st=train_st.sort_values(by=['PetID'])\nsent=sent.sort_values(by=['PetID'])\n# 'sentiment_magnitude_sum', 'sentiment_score_sum',\n#        'sentiment_magnitude_mean', 'sentiment_score_mean',\n#        'sentiment_magnitude_var', 'sentiment_score_var',\n#        'sentiment_magnitude_std', 'sentiment_score_std'\ntrain_st['sentiment_magnitude_sum']=sent['sentiment_magnitude_sum']\ntrain_st['sentiment_score_sum']=sent['sentiment_score_sum']\ntrain_st['sentiment_magnitude_mean']=sent['sentiment_magnitude_mean']\ntrain_st['sentiment_score_mean']=sent['sentiment_score_mean']\ntrain_st['sentiment_magnitude_var']=sent['sentiment_magnitude_var']\ntrain_st['sentiment_score_var']=sent['sentiment_score_var']\ntrain_st['sentiment_magnitude_std']=sent['sentiment_magnitude_std']\ntrain_st['sentiment_score_std']=sent['sentiment_score_std']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_st.to_csv('train_final.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_st)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_st.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sent_features=['Type', 'Age', 'Gender', 'MaturitySize', 'FurLength',\n       'Vaccinated', 'Dewormed', 'Sterilized', 'Health', 'Quantity', 'Fee',\n       'VideoAmt', 'PhotoAmt','NameL','StateNameL', 'Color1NameL', 'Breed1NameL', \n        'RescuerIDL','metadata_annots_score', 'metadata_color_score',\n       'metadata_color_pixelfrac', 'metadata_crop_conf', 'sentiment_magnitude_sum', \n        'sentiment_score_sum', 'sentiment_magnitude_mean', 'sentiment_score_mean',\n       'sentiment_magnitude_var', 'sentiment_score_var', 'sentiment_magnitude_std', \n        'sentiment_score_std']\ntarget=['AdoptionSpeed']\nX=train_st[sent_features]\ny=train_st['AdoptionSpeed']\nprint(X.columns)\nprint(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation betwen target and other features\ntrain_st[sent_features].corrwith(y).plot.bar(\n        figsize = (20, 10), title = \"Correlation with AdoptionSpeed, including metadata from images and sentiments\", fontsize = 15,\n        rot = 45, grid = True)\ntrain_st[sent_features].hist(figsize=(15,15))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom sklearn import datasets, linear_model\nfrom sklearn.model_selection import train_test_split\nfrom matplotlib import pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\n\n# create training and testing vars\nX_train, X_valid, y_train, y_valid = train_test_split(X,y, test_size=0.2)\n\n#Scaling training and validating\nscaler = StandardScaler()\n# Apply transform to both the training set and the test set.\nscaler.fit(X_train)\nX_train = scaler.transform(X_train)\nX_valid = scaler.transform(X_valid)\n\n#Fit the model\nlogisticRegr = LogisticRegression()\nlogisticRegr.fit(X_train, y_train)\npredictions = logisticRegr.predict(X_valid)\n# Use score method to get accuracy of model\n# accuracy is defined as: \n# (fraction of correct predictions): correct predictions / total number of data points\nscore = logisticRegr.score(X_valid, y_valid)\nprint(score)\n\n# Confusion matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import metrics\n\ncm = metrics.confusion_matrix(y_valid, predictions)\nprint(cm)\nplt.figure(figsize=(9,9))\nsns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\nplt.ylabel('Actual label');\nplt.xlabel('Predicted label');\nall_sample_title = 'Accuracy Score: {0}'.format(score)\nplt.title(all_sample_title, size = 15);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"short_features=['metadata_annots_score', 'Type', 'Age', 'FurLength','Sterilized']\nX_short=train_st[short_features]\n\n# create training and testing vars\nX_train, X_valid, y_train, y_valid = train_test_split(X_short,y, test_size=0.2)\n\n#Scaling training and validating\nscaler = StandardScaler()\n# Apply transform to both the training set and the test set.\nscaler.fit(X_train)\nX_train = scaler.transform(X_train)\nX_valid = scaler.transform(X_valid)\n\n#Fit the model\nlogisticRegr = LogisticRegression()\nlogisticRegr.fit(X_train, y_train)\npredictions = logisticRegr.predict(X_valid)\n# Use score method to get accuracy of model\n# accuracy is defined as: \n# (fraction of correct predictions): correct predictions / total number of data points\nscore = logisticRegr.score(X_valid, y_valid)\nprint(score)\n\n# Confusion matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import metrics\n\ncm = metrics.confusion_matrix(y_valid, predictions)\nprint(cm)\nplt.figure(figsize=(9,9))\nsns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\nplt.ylabel('Actual label');\nplt.xlabel('Predicted label');\nall_sample_title = 'Accuracy Score: {0}'.format(score)\nplt.title(all_sample_title, size = 15);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing the required packages \nimport numpy as np \nimport pandas as pd \nimport math\nfrom sklearn.metrics import confusion_matrix \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier \nfrom sklearn.metrics import accuracy_score \nfrom sklearn.metrics import classification_report\n\n# Function to perform training with giniIndex. \ndef train_using_gini(X_train, X_test, y_train): \n  \n    # Creating the classifier object \n    clf_gini = DecisionTreeClassifier(criterion = \"gini\", \n            random_state = 100,max_depth=3, min_samples_leaf=5) \n  \n    # Performing training \n    clf_gini.fit(X_train, y_train) \n    return clf_gini \n      \n# Function to perform training with entropy. \ndef train_using_entropy(X_train, X_test, y_train): \n  \n    # Decision tree with entropy \n    clf_entropy = DecisionTreeClassifier( \n            criterion = \"entropy\", random_state = 100, \n            max_depth = 3, min_samples_leaf = 5) \n  \n    # Performing training \n    clf_entropy.fit(X_train, y_train) \n    return clf_entropy \n  \n# Function to make predictions \ndef prediction(X_test, clf_object): \n  \n    # Predicton on test with giniIndex \n    y_pred = clf_object.predict(X_test) \n    print(\"Predicted values:\") \n    print(y_pred) \n    return y_pred \n      \n# Function to calculate accuracy \ndef cal_accuracy(y_test, y_pred): \n      \n    print(\"Confusion Matrix: \", \n        confusion_matrix(y_test, y_pred)) \n      \n    print (\"Accuracy : \", \n    accuracy_score(y_test,y_pred)*100) \n      \n    print(\"Report : \", \n    classification_report(y_test, y_pred)) \n\n# create training and testing vars\nX_train, X_valid, y_train, y_valid = train_test_split(X,y, test_size=0.2)\n\nclf_gini = train_using_gini(X_train, X_valid, y_train) \nclf_entropy = train_using_entropy(X_train, X_valid, y_train) \n      \n# Operational Phase \nprint(\"Results Using Gini Index:\") \n      \n# Prediction using gini \ny_pred_gini = prediction(X_valid, clf_gini) \ncal_accuracy(y_valid, y_pred_gini) \n      \nprint(\"Results Using Entropy:\") \n# Prediction using entropy \ny_pred_entropy = prediction(X_valid, clf_entropy) \ncal_accuracy(y_valid, y_pred_entropy) \n\n#Predict for the test_meta based on GINI:\n# Operational Phase \nprint(\"Results Using Gini Index for test_meta:\") \n# Prediction using gini \n# X_test=test_meta.drop(['Name','RescuerID','Description','PetID'], axis=1)\n# y_pred_gini = prediction(X_valid, clf_gini) \ny_valid_gini=  prediction(X_valid, clf_gini) \nprint(\"Results Using Entropy:\") \n# Prediction using entropy \n# y_pred_entropy = prediction(X_test, clf_entropy) \n\nprint('diff between Decison Tree with gini and entropy, check their histogram')\nprint('GINI prediction for test_meta histogram:')\n_=plt.hist(y_valid_gini, bins='auto')\nplt.title(\"Histogram with 'auto' bins for GINI\")\nplt.show()\n\n# print('ENTROPY prediction for test histogram:')\n\n# #submit\n# submission_gini = pd.DataFrame(data = y_pred_gini\n#              , columns = ['AdoptionSpeed'])\n# submission_gini = pd.concat([test_meta['PetID'], submission_gini], axis = 1)\n# submission_gini.to_csv('samplesubmissionTreeGini.csv', index=False)\n\n# submission_entropy = pd.DataFrame(data = y_pred_gini\n#              , columns = ['AdoptionSpeed'])\n# submission_entropy = pd.concat([test_meta['PetID'], submission_entropy], axis = 1)\n# submission_entropy.to_csv('samplesubmissionTreeEntropy.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# PCA"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_st.shape[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\ntrain_st=pd.read_csv('train_final.csv')\n\nsent_features=['Type', 'Age', 'Gender', 'MaturitySize', 'FurLength',\n       'Vaccinated', 'Dewormed', 'Sterilized', 'Health', 'Quantity', 'Fee',\n       'VideoAmt', 'PhotoAmt','NameL','StateNameL', 'Color1NameL', 'Breed1NameL', \n        'RescuerIDL','metadata_annots_score', 'metadata_color_score',\n       'metadata_color_pixelfrac', 'metadata_crop_conf', 'sentiment_magnitude_sum', \n        'sentiment_score_sum', 'sentiment_magnitude_mean', 'sentiment_score_mean',\n       'sentiment_magnitude_var', 'sentiment_score_var', 'sentiment_magnitude_std', \n        'sentiment_score_std']\ntarget=['AdoptionSpeed']\nX=train_st[sent_features]\ny=train_st[target]\n\n# create training and testing vars\nX_train, X_valid, y_train, y_valid = train_test_split(X,y, test_size=0.2)\n\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_valid = sc.transform(X_valid)\n\nfrom sklearn.decomposition import PCA\n\npca = PCA()\nX_train = pca.fit_transform(X_train)\nX_valid = pca.transform(X_valid)\nexplained_variance = pca.explained_variance_ratio_\nprint(explained_variance)\nt=0\nfor i in range(len(explained_variance)):\n        t=t+explained_variance[i]\n        print(i,\":\",t)\n# print(t)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA(n_components=22)\nX_train = pca.fit_transform(X_train)\nX_valid = pca.transform(X_valid)\nexplained_variance = pca.explained_variance_ratio_\nprint(explained_variance)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# In this case we'll use random forest classification \n# with PCA about 95% (22 components)\nfrom sklearn.ensemble import RandomForestClassifier\n\nclassifier = RandomForestClassifier(max_depth=2, random_state=0)\nclassifier.fit(X_train, y_train)\n\n# Predicting the Test set results\ny_pred = classifier.predict(X_valid)\nplt.scatter(y_pred,y_valid)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# xgboost for multiple classification\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# META CODE\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.preprocessing import MultiLabelBinarizer\n\ntrain_st=pd.read_csv('train_final.csv')\n\nsent_features=['Type', 'Age', 'Gender', 'MaturitySize', 'FurLength',\n       'Vaccinated', 'Dewormed', 'Sterilized', 'Health', 'Quantity', 'Fee',\n       'VideoAmt', 'PhotoAmt','NameL','StateNameL', 'Color1NameL', 'Breed1NameL', \n        'RescuerIDL','metadata_annots_score', 'metadata_color_score',\n       'metadata_color_pixelfrac', 'metadata_crop_conf', 'sentiment_magnitude_sum', \n        'sentiment_score_sum', 'sentiment_magnitude_mean', 'sentiment_score_mean',\n       'sentiment_magnitude_var', 'sentiment_score_var', 'sentiment_magnitude_std', \n        'sentiment_score_std']\ntarget=['AdoptionSpeed']\nX=train_st[sent_features]\ny=train_st[target]\n\n\nclf = OneVsRestClassifier(XGBClassifier(n_jobs=-1, max_depth=4))\n\n# You may need to use MultiLabelBinarizer to encode your variables from arrays [[x, y, z]] \n# to a multilabel format before training.\nmlb = MultiLabelBinarizer()\ny = mlb.fit_transform(y)\nclf.fit(X, y)\n\n# https://www.freecodecamp.org/news/multi-class-classification-with-sci-kit-learn-xgboost-a-case-study-using-brainwave-data-363d7fca5f69/\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# xgboost for multiple classification\n# https://evgenypogorelov.com/multiclass-xgb-shap.html"},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, cross_validate\nimport matplotlib.pylab as pl\nimport pandas as pd\nimport numpy as np\nimport sklearn.metrics as metrics\nimport matplotlib.pyplot as plt\n\n# https://evgenypogorelov.com/multiclass-xgb-shap.html","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_meta=pd.read_csv(path+'train_meta.csv')\ntest_meta=pd.read_csv(path+'test_meta.csv')\ntest_image = pd.read_csv(path+\"test_dfs_metadata.csv\")\ntest_sentiment = pd.read_csv(path+\"test_dfs_sentiment.csv\")\ntrain_image = pd.read_csv(path+\"train_dfs_metadata.csv\")\ntrain_sentiment = pd.read_csv(path+\"train_dsf_sentiment.csv\")\n\nsent_features=['Type', 'Age', 'Gender', 'MaturitySize', 'FurLength',\n       'Vaccinated', 'Dewormed', 'Sterilized', 'Health', 'Quantity', 'Fee',\n       'VideoAmt', 'PhotoAmt','NameL','StateNameL', 'Color1NameL', 'Breed1NameL', \n        'RescuerIDL','metadata_annots_score', 'metadata_color_score',\n       'metadata_color_pixelfrac', 'metadata_crop_conf', 'sentiment_magnitude_sum', \n        'sentiment_score_sum', 'sentiment_magnitude_mean', 'sentiment_score_mean',\n       'sentiment_magnitude_var', 'sentiment_score_var', 'sentiment_magnitude_std', \n        'sentiment_score_std']\ntarget=['AdoptionSpeed']\n# X=train_st[sent_features]\n# y=train_st[target]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check for missing values\nprint(test_meta.isna().sum()[test_meta.isna().sum()>0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_meta=pd.read_csv(path+'train_meta.csv')\n# test_meta=pd.read_csv(path+'test_meta.csv')\n\n# test_image = pd.read_csv(path+\"test_dfs_metadata.csv\")\n# test_sentiment = pd.read_csv(path+\"test_dfs_sentiment.csv\")\n\n# train_image = pd.read_csv(path+\"train_dfs_metadata.csv\")\n# train_sentiment = pd.read_csv(path+\"train_dsf_sentiment.csv\")\n\n#reset index=PetID\n# train_meta=train_meta.set_index('PetID')\n# train_meta=train_meta.drop(['Unnamed: 0','Unnamed: 0.1'],axis=1)\n# train_meta\n# test_meta=test_meta.set_index('PetID')\n# test_meta=test_meta.drop(['Unnamed: 0','Unnamed: 0.1'],axis=1)\n# test_meta\ntest_image=test_image.set_index('PetID')\ntest_sentiment=test_sentiment.set_index('PetID')\ntrain_image=train_image.set_index('PetID')\ntrain_sentiment=train_sentiment.set_index('PetID')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('train_meta.columns=',train_meta.columns)\nprint('shape(train_meta.columns)=',train_meta.shape)\nprint('test_meta.columns=',test_meta.columns)\nprint('shape(test_meta.columns)=',test_meta.shape)\nprint('train_image.columns=',train_image.columns)\nprint('shape(train_image.columns)=',train_image.shape)\nprint('test_image.columns=',test_image.columns)\nprint('shape(test_image.columns)=',test_image.shape)\nprint('train_sentiment.columns=',train_sentiment.columns)\nprint('shape(train_sentiment.columns)=',train_sentiment.shape)\nprint('test_sentiment.columns=',test_sentiment.columns)\nprint('shape(test_sentiment.columns)=',test_sentiment.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#TRAIN: check PetID common for all sentiment and image\nfrom functools import reduce\ntrain=reduce(np.intersect1d, (train_meta.index, train_image.index, train_sentiment.index))\nprint('len(train)=',len(train),': ', len(train)/train_meta.shape[0])\ntest=reduce(np.intersect1d, (test_meta.index, test_image.index, test_sentiment.index))\nprint('len(train)=',len(test),': ', len(test)/test_meta.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Reduce the train and test dataset to get image metadata and sentiment data\n#reset the index for train_meta and test_meta\ntrain_meta=train_meta.reset_index()\ntest_meta=test_meta.reset_index()\ntrain_image=train_image.reset_index()\ntest_image=test_image.reset_index()\ntrain_sentiment=train_sentiment.reset_index()\ntest_sentiment=test_sentiment.reset_index()\n#Update the datasets\ntrain_meta=train_meta[train_meta.PetID.isin(train)]\ntest_meta=test_meta[test_meta.PetID.isin(test)]\ntrain_image=train_image[train_image.PetID.isin(train)]\ntrain_sentiment=train_sentiment[train_sentiment.PetID.isin(train)]\ntest_image=test_image[test_image.PetID.isin(test)]\ntest_sentiment=test_sentiment[test_sentiment.PetID.isin(test)]\nprint(train_meta.info())\nprint(test_meta.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#**********************FOR IMAGE**********************\n#---TRAIN------\n# 'metadata_annots_score', 'metadata_color_score',\n#        'metadata_color_pixelfrac', 'metadata_crop_conf',\n#        'metadata_crop_importance', 'metadata_annots_top_desc'\ntrain_meta['metadata_annots_score']=train_image['metadata_annots_score']\ntrain_meta['metadata_color_score']=train_image['metadata_color_score']\ntrain_meta['metadata_color_pixelfrac']=train_image['metadata_color_pixelfrac']\ntrain_meta['metadata_crop_conf']=train_image['metadata_crop_conf']\ntrain_meta['metadata_crop_importance']=train_image['metadata_crop_importance']\ntrain_meta['metadata_annots_top_desc']=train_image['metadata_annots_top_desc']\n#---TEST-------\ntest_meta['metadata_annots_score']=test_image['metadata_annots_score']\ntest_meta['metadata_color_score']=test_image['metadata_color_score']\ntest_meta['metadata_color_pixelfrac']=test_image['metadata_color_pixelfrac']\ntest_meta['metadata_crop_conf']=test_image['metadata_crop_conf']\ntest_meta['metadata_crop_importance']=test_image['metadata_crop_importance']\ntest_meta['metadata_annots_top_desc']=test_image['metadata_annots_top_desc']\n\n#**********************FOR SENTIMENT**********************\n#---TRAIN------\n# 'sentiment_magnitude', 'sentiment_score', 'sentiment_magnitude_sum',\n#        'sentiment_score_sum', 'sentiment_magnitude_mean',\n#        'sentiment_score_mean', 'sentiment_magnitude_var',\n#        'sentiment_score_var', 'sentiment_magnitude_std', 'sentiment_score_std'\ntrain_meta['sentiment_magnitude']=train_sentiment['sentiment_magnitude']\ntrain_meta['sentiment_score']=train_sentiment['sentiment_score']\ntrain_meta['sentiment_magnitude_sum']=train_sentiment['sentiment_magnitude_sum']\ntrain_meta['sentiment_score_sum']=train_sentiment['sentiment_score_sum']\ntrain_meta['sentiment_magnitude_mean']=train_sentiment['sentiment_magnitude_mean']\ntrain_meta['sentiment_score_mean']=train_sentiment['sentiment_score_mean']\ntrain_meta['sentiment_magnitude_var']=train_sentiment['sentiment_magnitude_var']\ntrain_meta['sentiment_score_var']=train_sentiment['sentiment_score_var']\ntrain_meta['sentiment_magnitude_std']=train_sentiment['sentiment_magnitude_std']\ntrain_meta['sentiment_score_std']=train_sentiment['sentiment_score_std']\n#---TEST-------\ntest_meta['sentiment_magnitude']=test_sentiment['sentiment_magnitude']\ntest_meta['sentiment_score']=test_sentiment['sentiment_score']\ntest_meta['sentiment_magnitude_sum']=test_sentiment['sentiment_magnitude_sum']\ntest_meta['sentiment_score_sum']=test_sentiment['sentiment_score_sum']\ntest_meta['sentiment_magnitude_mean']=test_sentiment['sentiment_magnitude_mean']\ntest_meta['sentiment_score_mean']=test_sentiment['sentiment_score_mean']\ntest_meta['sentiment_magnitude_var']=test_sentiment['sentiment_magnitude_var']\ntest_meta['sentiment_score_var']=test_sentiment['sentiment_score_var']\ntest_meta['sentiment_magnitude_std']=test_sentiment['sentiment_magnitude_std']\ntest_meta['sentiment_score_std']=test_sentiment['sentiment_score_std']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_meta.info())\nprint(test_meta.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_meta.to_csv('final_train.csv',index=False)\ntest_meta.to_csv('final_test.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}