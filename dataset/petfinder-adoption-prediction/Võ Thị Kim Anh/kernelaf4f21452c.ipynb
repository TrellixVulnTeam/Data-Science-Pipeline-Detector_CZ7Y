{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load in \n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the \"../input/\" directory.\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"path='/kaggle/input/petfinder-adoption-prediction/'\n# t=pd.read_json(path+'train_sentiment/25a834a2e.json', orient='split')\ntrain_meta=pd.read_csv(path+'train/train.csv')\ntest_meta=pd.read_csv(path+'test/test.csv')\nprint(train_meta)\nprint(test_meta)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_meta.info())\nprint(train_meta.describe())\ntrain_meta.hist(figsize=(15,15))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_meta.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_meta.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_meta.Name.unique())\nprint(len(train_meta.Name.unique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_meta.Description.unique())\nprint(len(train_meta.Description.unique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# count the number of duplicate values\nfrom collections import Counter\nc = Counter(list(zip(train_meta.columns)))\nc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nf = plt.figure(figsize=(19, 15))\nplt.matshow(train_meta.corr(), fignum=f.number)\nplt.xticks(range(train_meta.shape[1]), train_meta.columns, fontsize=14, rotation=45)\nplt.yticks(range(train_meta.shape[1]), train_meta.columns, fontsize=14)\ncb = plt.colorbar()\ncb.ax.tick_params(labelsize=14)\nplt.title('Correlation Matrix', fontsize=16);\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t=train_meta.drop([\"AdoptionSpeed\",'Name','RescuerID','Description','PetID'], axis=1).apply(lambda x: x.corr(train_meta.AdoptionSpeed))\nt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Linear Regression?\n\n# PCA to see the data in 2 components\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\n\nx = train_meta.drop([\"AdoptionSpeed\",'Name','RescuerID','Description','PetID'], axis=1).values #returns a numpy array\nmin_max_scaler = preprocessing.MinMaxScaler()\nx_scaled = min_max_scaler.fit_transform(x)\ndf = pd.DataFrame(x_scaled)\n\npca = PCA(n_components=2)\nprincipalComponents=pca.fit_transform(df)\nprincipalDf = pd.DataFrame(data = principalComponents\n             , columns = ['principal component 1', 'principal component 2'])\nfinalDf = pd.concat([principalDf, train_meta[['AdoptionSpeed']]], axis = 1)\nfinalDf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"finalDf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"finalDf.drop('AdoptionSpeed',axis=1).plot(figsize=(18,5))\ndf.isnull().values.any()\n# The “False” output confirms that there are no null values in the dataframe.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA(n_components=1)\nprincipalComponents=pca.fit_transform(train_meta.drop([\"AdoptionSpeed\",'Name','RescuerID','Description','PetID'], axis=1))\nprincipalDf = pd.DataFrame(data = principalComponents\n             , columns = ['principal component 1'])\nfinalDf = pd.concat([principalDf, train_meta[['AdoptionSpeed']]], axis = 1)\nplt.scatter(finalDf['principal component 1']\n               , finalDf['AdoptionSpeed']\n               , c = 'r'\n               , s = 50)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom scipy import stats\nfrom datetime import datetime\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import KFold\nfrom sklearn.linear_model import LinearRegression\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Validate linear relationship\nplt.scatter(finalDf['principal component 1'], finalDf['AdoptionSpeed'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = pd.DataFrame(finalDf[['principal component 1','principal component 2']])\ny = pd.DataFrame(finalDf['AdoptionSpeed'])\nmodel = LinearRegression()\nscores = []\nkfold = KFold(n_splits=3, shuffle=True, random_state=42)\nfor i, (train, test) in enumerate(kfold.split(X, y)):\n model.fit(X.iloc[train,:], y.iloc[train,:])\n score = model.score(X.iloc[test,:], y.iloc[test,:])\n scores.append(score)\nprint(scores)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"No LInear Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_meta","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://acadgild.com/blog/logistic-regression-multiclass-classification\n# train and validate\n# then apply for test\nfrom sklearn.datasets import fetch_mldata\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nimport pandas as pd\nimport numpy as np\n\nX = pd.DataFrame(finalDf[['principal component 1','principal component 2']])\ny = pd.DataFrame(finalDf['AdoptionSpeed'])\n\n# valid_size: what proportion of original data is used for test set\ntrain_img, valid_img, train_lbl, valid_lbl = train_test_split(X,y,test_size=0.2, random_state=122)\n    \n#Fit the model\nmodel = LogisticRegression(solver = 'lbfgs')\nmodel.fit(train_img, train_lbl)\n    \n#Validate the fitting\n# use the model to make predictions with the valid data\ny_pred = model.predict(valid_img)\nprint(y_pred)\nprint(valid_lbl)\n# how did our model perform?\ncount_misclassified = (valid_lbl['AdoptionSpeed'] != y_pred).sum()\nprint('Misclassified samples: {}'.format(count_misclassified))\naccuracy = metrics.accuracy_score(valid_lbl, y_pred)\nprint('Accuracy: {:.2f}'.format(accuracy))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# valid_size: what proportion of original data is used for test set\ntrain_img, valid_img, train_lbl, valid_lbl = train_test_split(train_meta.drop([\"AdoptionSpeed\",'Name','RescuerID','Description','PetID'], axis=1),\n     train_meta[\"AdoptionSpeed\"],test_size=0.2, random_state=122)\n\n#Standardize\nscaler = StandardScaler()\n# Fit on training set only.\nscaler.fit(train_img)\n# Apply transform to both the training set and the test set.\ntrain_img = scaler.transform(train_img)\ntest_img = scaler.transform(valid_img)\n    \n#Fit the model\nmodel = LogisticRegression(solver = 'lbfgs')\nmodel.fit(train_img, train_lbl)\n    \n#Validate the fitting\n# use the model to make predictions with the test data\ny_pred = model.predict(valid_img)\n# how did our model perform?\ncount_misclassified = (valid_lbl != y_pred).sum()\nprint('Misclassified samples: {}'.format(count_misclassified))\naccuracy = metrics.accuracy_score(valid_lbl, y_pred)\nprint('Accuracy: {:.2f}'.format(accuracy))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_meta['PetID']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Predict for test data the fitting\n# use the model to make predictions with the test data\ny_pred = model.predict(test_meta.drop(['Name','RescuerID','Description','PetID'], axis=1))\ny_pred=pd.DataFrame(data = y_pred\n             , columns = ['AdoptionSpeed'])\nsubmission= pd.concat([test_meta['PetID'],y_pred], axis = 1)\nsubmission.to_csv('/kaggle/working/'+'submission.csv')\nsubmission","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}