{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# Any results you write to the current directory are saved as output.\n\n#ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.exceptions import ConvergenceWarning\nwarnings.simplefilter(action=\"ignore\", category=ConvergenceWarning)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import math\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.pylab as pylab\nimport seaborn as sns\n\n#Common Model Algorithms\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\n\n#Common Model Helpers\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder,OrdinalEncoder, StandardScaler,KBinsDiscretizer\nfrom sklearn import feature_selection\nfrom sklearn import model_selection\nfrom sklearn import metrics\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD\n\n# Evaluation\nfrom sklearn.metrics import cohen_kappa_score,make_scorer\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATA_DIR = '/kaggle/input/'\n\n# Directory to save logs and trained model\nROOT_DIR = '/kaggle/working/'\n\nMASK_DIR = '/kaggle/working/Mask_RCNN'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!git clone https://www.github.com/matterport/Mask_RCNN.git\nos.chdir('Mask_RCNN')\n!python setup.py -q install\nos.chdir('..')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip show mask-rcnn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport sys\nimport random\nimport math\nimport numpy as np\nimport skimage.io\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nsys.path.append(MASK_DIR) # To find local version\nfrom mrcnn import utils\nimport mrcnn.model as modellib\nfrom mrcnn import visualize\nfrom mrcnn.config import Config\n\n# Directory to save logs and trained model\nMODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n\n# Local path to trained weights file\nCOCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n# Download COCO trained weights from Releases if needed\nif not os.path.exists(COCO_MODEL_PATH):\n    utils.download_trained_weights(COCO_MODEL_PATH)\n\n# Directory of images to run detection on\nIMAGE_DIR = os.path.join(DATA_DIR, \"train_images\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class InferenceConfig(Config):\n    # Set batch size to 1 since we'll be running inference on\n    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n    GPU_COUNT = 1\n    IMAGES_PER_GPU = 1\n    NAME = \"mas_segmentation\"\n    NUM_CLASSES = 1 + 80\n\nconfig = InferenceConfig()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create model object in inference mode.\nmodel = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n\n# Load weights trained on MS-COCO\nmodel.load_weights(COCO_MODEL_PATH, by_name=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# COCO Class names\n# Index of the class in the list is its ID. For example, to get ID of\n# the teddy bear class, use: class_names.index('teddy bear')\nclass_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n               'bus', 'train', 'truck', 'boat', 'traffic light',\n               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n               'teddy bear', 'hair drier', 'toothbrush']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calculate_areas(df, image_path, show_image=False): \n    head, filename = os.path.split(image_path)\n    image = skimage.io.imread(image_path)\n\n    # Run detection\n    results = model.detect([image], verbose=0)\n    r = results[0]\n    \n    if show_image:\n        # Visualize results\n        visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], class_names, r['scores'])\n\n    number_of_cats = int((r['class_ids'] == 16).sum())\n    number_of_dogs = int((r['class_ids'] == 17).sum())\n    \n    cat_area_percent, dog_area_percent = calculate_area_precent(r)\n    \n    new_row = pd.Series({\"imageId\": filename , \"gray_image\": 0, \"cats\": number_of_cats, \"dogs\": number_of_dogs, \"cat_percent\": cat_area_percent, \"dog_percent\": dog_area_percent})\n    return df.append(new_row, ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calculate_area_precent(result):\n\n    #mask as (x,y, number_of_objects)\n    mask = result['masks']\n    mask = mask.astype(int)\n    \n    cat_mask_index = np.where(result['class_ids'] == 16)[0]\n    dog_mask_index = np.where(result['class_ids'] == 17)[0]\n        \n    cat_area = 0\n    dog_area = 0\n    for i in cat_mask_index:\n        cat_area = cat_area + np.sum(mask[:,:,i])\n\n    for i in dog_mask_index:\n        dog_area = dog_area + np.sum(mask[:,:,i])\n\n    mask_size = mask.shape[0] * mask.shape[1]   \n\n    cat_area_percent = cat_area/mask_size\n    dog_area_percent = dog_area/mask_size\n    \n    return round(cat_area_percent,2), round(dog_area_percent,2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mark_gray_image(df, image_path): \n    head, filename = os.path.split(image_path)\n    new_row = pd.Series({\"imageId\": filename , \"gray_image\": 1, \"cats\":0, \"dogs\": 0, \"cat_percent\": 0, \"dog_percent\": 0})\n    return df.append(new_row, ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data load from previous commit.\n#pet_area_coverage=pd.DataFrame()\n#failed_images = []\n#counter = 0\n#for filename in os.listdir(IMAGE_DIR):\n#    try:\n#        counter = counter +1\n#        if counter % 1000 == 0:\n#            print(counter)\n#        pet_area_coverage = calculate_areas(pet_area_coverage,os.path.join(IMAGE_DIR, filename))\n#    except Exception:\n#        failed_images.append(filename)\n#        pet_area_coverage = mark_gray_image(pet_area_coverage,os.path.join(IMAGE_DIR, filename))\n#        continue","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#for img in failed_images:\n#    print(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pet_area_coverage.to_csv('pet_area_coverage.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pet_area_coverage.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#show images with most cats and dogs in them\n\n#max_dog_count_petid = pet_area_coverage.loc[pet_area_coverage['dogs'].idxmax()]['imageId']\n#max_cat_count_petid = pet_area_coverage.loc[pet_area_coverage['cats'].idxmax()]['imageId']\n\n#calculate_areas(pd.DataFrame(),os.path.join(IMAGE_DIR, max_dog_count_petid), show_image=True)\n#calculate_areas(pd.DataFrame(),os.path.join(IMAGE_DIR, max_cat_count_petid), show_image=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# show images with most area covered by cats and dogs\n\n#max_dog_percent_petid = pet_area_coverage.loc[pet_area_coverage['dog_percent'].idxmax()]['imageId']\n#max_cat_percent_petid = pet_area_coverage.loc[pet_area_coverage['cat_percent'].idxmax()]['imageId']\n\n#calculate_areas(pd.DataFrame(),os.path.join(IMAGE_DIR, max_dog_percent_petid), show_image=True)\n#calculate_areas(pd.DataFrame(),os.path.join(IMAGE_DIR, max_cat_percent_petid), show_image=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/petfinder-adoption-prediction/train/train.csv\")\n\n# load from dataset\npet_area_coverage = pd.read_csv(\"/kaggle/input/rcnn-all-train-images-results/pet_area_coverage.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_image_segmentations(df, PetID):\n    #df = area cover df with imageId\n    matching_rows = df[df['imageId'].str.contains(PetID)]\n    count_row = matching_rows.shape[0]\n        \n    if count_row == 0:\n        # no images for this pet\n        return pd.Series()\n    \n    matching_rows['imageIndex'] = matching_rows.apply(lambda x: x['imageId'][x['imageId'].find('-')+1 :-4], axis=1)\n    matching_rows = matching_rows.sort_values('imageIndex')\n        \n    # add values from all images\n    pet_photo_values = pd.Series()\n    gray_images = 0\n    cat_count_max = 0\n    dog_count_max = 0\n    cat_count_mean = 0\n    dog_count_mean = 0\n    cat_percent_max = 0\n    dog_percent_max = 0\n    cat_percent_mean = 0\n    dog_percent_mean = 0\n    \n    for i, row in matching_rows.iterrows():\n        img_nr = row['imageIndex']\n        gray_images = gray_images + row['gray_image']\n        \n        if row['cats'] > cat_count_max:\n            cat_count_max = row['cats']\n        if row['dogs'] > dog_count_max:\n            dog_count_max = row['dogs']\n        \n        cat_count_mean = (cat_count_mean + row['cats'])/2\n        dog_count_mean = (dog_count_mean + row['dogs'])/2\n            \n        if row['cat_percent'] > cat_percent_max:\n            cat_percent_max = row['cat_percent']\n        if row['dog_percent'] > dog_percent_max:\n            dog_percent_max = row['dog_percent']\n        \n        cat_percent_mean = (cat_percent_mean + row['cat_percent'])/2\n        dog_percent_mean = (dog_percent_mean + row['dog_percent'])/2\n        \n    pet_photo_values = pet_photo_values.append(pd.Series([gray_images, cat_count_max, dog_count_max, cat_count_mean, dog_count_mean, cat_percent_max,\n                                                          dog_percent_max, cat_percent_mean, dog_percent_mean ],index = ['gray_images', 'cat_count_max', \n                                                                                                                         'dog_count_max', 'cat_count_mean', \n                                                                                                                         'dog_count_mean', 'cat_percent_max',\n                                                                                                                         'dog_percent_max', 'cat_percent_mean', \n                                                                                                                         'dog_percent_mean'] ))     \n    # return series of all values   \n    return pet_photo_values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_df=pd.DataFrame()\nresult_df['PetID']=train_df['PetID']\nresult_df['AdoptionSpeed']=train_df['AdoptionSpeed']\nresult_df = result_df.merge(result_df.PetID.apply(lambda x: add_image_segmentations(pet_area_coverage, x)), left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_df.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_df.fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_df.to_csv('result.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import shutil\nshutil.rmtree(MASK_DIR)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}