{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n\n#load packages\nimport sys #access to system parameters https://docs.python.org/3/library/sys.html\nprint(\"Python version: {}\". format(sys.version))\n\nimport pandas as pd #collection of functions for data processing and analysis modeled after R dataframes with SQL like features\nprint(\"pandas version: {}\". format(pd.__version__))\n\nimport matplotlib #collection of functions for scientific and publication-ready visualization\nprint(\"matplotlib version: {}\". format(matplotlib.__version__))\n\nimport numpy as np #foundational package for scientific computing\nprint(\"NumPy version: {}\". format(np.__version__))\n\nimport scipy as sp #collection of functions for scientific computing and advance mathematics\nprint(\"SciPy version: {}\". format(sp.__version__)) \n\nimport IPython\nfrom IPython import display #pretty printing of dataframes in Jupyter notebook\nprint(\"IPython version: {}\". format(IPython.__version__)) \n\nimport sklearn #collection of machine learning algorithms\nprint(\"scikit-learn version: {}\". format(sklearn.__version__))\n\n#misc libraries\nimport random\nimport time\nimport math\n\n\n#ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.exceptions import ConvergenceWarning\nwarnings.simplefilter(action=\"ignore\", category=ConvergenceWarning)\n\nprint('-'*25)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"\n\n#Common Model Algorithms\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom xgboost import XGBClassifier\n\n#Common Model Helpers\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder,OrdinalEncoder, StandardScaler,KBinsDiscretizer\nfrom sklearn import feature_selection\nfrom sklearn import model_selection\nfrom sklearn import metrics\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD\n\n# Evaluation\nfrom sklearn.metrics import cohen_kappa_score,make_scorer\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\n\n#Visualization\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.pylab as pylab\nimport seaborn as sns\nfrom pandas.tools.plotting import scatter_matrix\nfrom wordcloud import WordCloud\n\n#Configure Visualization Defaults\n#%matplotlib inline = show plots in Jupyter Notebook browser\n%matplotlib inline\nmpl.style.use('ggplot')\nsns.set_style('darkgrid')\npylab.rcParams['figure.figsize'] = 12,8","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5c2b095b88998788d13bd4360aacbcdf45179869"},"cell_type":"markdown","source":"# Workbook\n\n| Date             | Version | Description                                                                                | Train score | Public score  | Commit version |\n|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| 2019-02-20 | v1.0.0    | basic model only using features from train.csv  | 0.347 | 0.330  | V2 |\n| 2019-02-20 | v1.0.1    | include has_name  |  0.350 | -| V3 |\n| 2019-02-20 | v1.0.2    | include has_topname  |  0.353 | 0.326| V3 |\n| 2019-02-20 | v1.0.3    | include custom age binning  |  0.346  | -| V3 |\n| 2019-02-25 | v1.0.4    | include scikit-learn age binning  |  0.350  | -| V3 |\n| 2019-02-25 | v1.0.5   | include human_age  |  0.350  | -| V3 |\n| 2019-02-25 | v1.0.6   | include lifestage |  0.350  |  0.317| V3 |\n| 2019-03-01 | v1.0.7   | include mixed_breed |  -  |  -| V4 |\n| 2019-03-01 | v1.0.8   | include dummies for Breed1 and Breed2 |  0.345  |  -| V4 |\n| 2019-03-01 | v1.0.9   | include drop dummies and target encoding for Breed |  0.346  |  0.320| V6 |\n| 2019-03-01 | v1.0.10   | include rescuer target encoding |  0.344  |  0.306| V8 |\n| 2019-03-11 | v1.0.11   | include state wiki data & target encoding |  0.349  |  -| V9 |\n| 2019-03-11 | v1.0.12   | include colors target encoding |  0.353  |  0.308| V20 |\n| 2019-03-14 | v1.0.13   | tfidf of descirption |  0.350  |  0.335 | V22 |\n"},{"metadata":{"trusted":true,"_uuid":"f22c29299152bc0e6cb794936878cecba75af7aa","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"#Machine Learning Algorithm (MLA) Selection and Initialization\nMLA = [\n    #Ensemble Methods\n    ensemble.AdaBoostClassifier(),\n    ensemble.BaggingClassifier(),\n    ensemble.ExtraTreesClassifier(),\n    ensemble.GradientBoostingClassifier(),\n    ensemble.RandomForestClassifier(),\n\n    #Gaussian Processes\n    #gaussian_process.GaussianProcessClassifier(),\n    \n    #GLM\n    linear_model.LogisticRegressionCV(),\n    linear_model.PassiveAggressiveClassifier(),\n    linear_model.RidgeClassifierCV(),\n    linear_model.SGDClassifier(),\n    linear_model.Perceptron(),\n    \n    #Navies Bayes\n    naive_bayes.BernoulliNB(),\n    naive_bayes.GaussianNB(),\n    \n    #Nearest Neighbor\n    neighbors.KNeighborsClassifier(),\n    \n    #SVM\n    #svm.SVC(probability=True),\n    #svm.NuSVC(probability=True),\n    #svm.LinearSVC(),\n    \n    #Trees    \n    tree.DecisionTreeClassifier(),\n    tree.ExtraTreeClassifier(),\n    \n    #Discriminant Analysis\n    discriminant_analysis.LinearDiscriminantAnalysis(),\n    discriminant_analysis.QuadraticDiscriminantAnalysis(),\n\n    #xgboost: http://xgboost.readthedocs.io/en/latest/model.html\n    XGBClassifier()    \n    ]\n\ndef train_model(data, MLA_list = MLA, print_feature_table=False, print_feature_score=False, top_n=8):\n    \n    target = data['AdoptionSpeed']\n    X_train = data.drop(['AdoptionSpeed'],axis=1)\n    \n    MLA_columns = ['MLA Name', 'MLA Parameters','MLA cohen_kappa_score','MLA Time']\n    MLA_compare = pd.DataFrame(columns = MLA_columns)\n\n    MLA_predict = data['AdoptionSpeed']\n    \n    scaler = StandardScaler()\n    X_train = scaler.fit_transform(X_train)\n\n    row_index = 0\n    for alg in MLA_list:\n\n        MLA_name = alg.__class__.__name__\n        MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n        MLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n    \n        kf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n        kappa_score = make_scorer(cohen_kappa_score, weights='quadratic')\n        cv_results = model_selection.cross_validate(alg, X_train, target, cv  = kf, scoring=kappa_score )\n        \n        MLA_compare.loc[row_index, 'MLA Time'] = cv_results['fit_time'].mean()\n        MLA_compare.loc[row_index, 'MLA cohen_kappa_score'] = cv_results['test_score'].mean() \n             \n        #MLA_predict[MLA_name] = alg.predict(X_train)\n        row_index+=1\n\n    #print and sort table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html\n    MLA_compare.sort_values(by = ['MLA cohen_kappa_score'], ascending = False, inplace = True)\n    sns.barplot(x='MLA cohen_kappa_score', y = 'MLA Name', data = MLA_compare, color = 'b')\n    plt.title('Machine Learning Algorithm Accuracy Score \\n')\n    plt.xlabel('Accuracy Score (%)')\n    plt.ylabel('Algorithm')\n    \n    \n    if print_feature_table:\n        for alg in MLA_list:\n            alg.fit(X_train, target)\n            if hasattr(alg, 'feature_importances_'):\n                feat_imp = pd.DataFrame({'importance':alg.feature_importances_})    \n                feat_imp['feature'] = X_train.columns\n                feat_imp.sort_values(by='importance', ascending=False, inplace=True)\n                feat_imp = feat_imp.iloc[:top_n]\n    \n                feat_imp.sort_values(by='importance', inplace=True)\n                feat_imp = feat_imp.set_index('feature', drop=True)\n                feat_imp.plot.barh(title=alg.__class__.__name__)\n                plt.xlabel('Feature Importance Score')\n                plt.show()\n    \n            if print_feature_score:\n                from IPython.display import display\n                print(\"Top {} features in descending order of importance\".format(top_n))\n                display(feat_imp.sort_values(by='importance', ascending=False))\n    \n    return MLA_compare\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6b377eeab08d7146bac3c784d6ed21982d880534","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"train = pd.read_csv('../input/train/train.csv')\ntest = pd.read_csv('../input/test/test.csv')\n\ntrain['dataset_type'] = 'train'\ntest['dataset_type'] = 'test'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5918ed189aa9bdaf95c8ba4ed64ba008e32fa150"},"cell_type":"markdown","source":"## Model performance with different algorithm\n\nWithout the added sentiment and image data"},{"metadata":{"trusted":true,"_uuid":"89a532bf5dd8699fe2c6e2babc6908f564fadae0","scrolled":true},"cell_type":"code","source":"useColumns = ['Type', 'Age', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2',\n       'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n       'Sterilized', 'Health', 'Quantity', 'Fee', 'State',\n       'VideoAmt', 'PhotoAmt', 'AdoptionSpeed']\n\n#train_model(train[useColumns], print_feature_table=True, top_n=20)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"317ecafe977b6564ba0247cd7187aa057b26d098"},"cell_type":"markdown","source":"### Ideas about feature engineering\n\nTree based models perform best on the unchanged data. As we did not any feature normalisation, models using any kind of matrix or distance measure will be affected negatively. Trees on the other hand are not influenced by that. We will try to to use some normalisation and see what it does to the performance of the models. \n\nWhen working with trees, combinations of features to create new features (interaction features), won't improve their performance. Because decision trees are getting this for free in contrast to linear models. To improv the decision tress based models, we are not focusing on those interaction features. "},{"metadata":{"trusted":true,"_uuid":"c9a591433895f09874ccb6b1fb4273444a3b3ae7"},"cell_type":"code","source":"train['Name'] = train['Name'].fillna('Unnamed')\ntest['Name'] = test['Name'].fillna('Unnamed')\n\ntrain['has_name'] = train['Name'].apply(lambda x: 0 if x == 'Unnamed' else 1)\ntest['has_name'] = test['Name'].apply(lambda x: 0 if x == 'Unnamed' else 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"28ee8f84c19d3ca35276d5655323067ba7816248"},"cell_type":"code","source":"train['has_name'] = train['Name'].apply(lambda x: 0 if x == 'No Name' or x == 'Unnamed' else 1)\ntest['has_name'] = test['Name'].apply(lambda x: 0 if x == 'No Name' or x == 'Unnamed' else 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fcc4e4ba21f76aaf5aad32ac54feb5099403e068"},"cell_type":"code","source":"top_3 = [\n    ensemble.AdaBoostClassifier(),\n    ensemble.GradientBoostingClassifier(),\n    XGBClassifier()    \n    ]\n\nuseColumns = ['Type', 'Age', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2',\n       'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n       'Sterilized', 'Health', 'Quantity', 'Fee', 'State',\n       'VideoAmt', 'PhotoAmt', 'AdoptionSpeed', 'has_name']\n\n#train_model(train[useColumns], print_feature_table=True, top_n=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"69150c9da212c39299bf5754e7ab2dc594fd7d9f"},"cell_type":"code","source":"# defining a function which returns a list of top names\ndef top_names(df, top_percent):\n    df_withnames = df[df.has_name != 0]\n    items = df_withnames.shape[0]\n    top_names = []\n    counter = 0\n    for i,v in df_withnames.Name.value_counts().items():\n        if (counter/items)>top_percent:\n            break\n        top_names.append(i)\n        counter = counter + v  \n    return top_names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f775fa9f5a2a4f0ef304f3a4d29c197401ffbd7d"},"cell_type":"code","source":"topnames = top_names(train.append(test), 0.2)\ntrain['has_topname'] = train['Name'].apply(lambda row: 1 if row in topnames else 0)\ntest['has_topname'] = test['Name'].apply(lambda row: 1 if row in topnames else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ddcc6194a01a5fe40f093a432d9da50a455c103a"},"cell_type":"code","source":"useColumns = ['Type', 'Age', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2',\n       'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n       'Sterilized', 'Health', 'Quantity', 'Fee', 'State',\n       'VideoAmt', 'PhotoAmt', 'AdoptionSpeed', 'has_name', 'has_topname']\n\n#train_model(train[useColumns], top_3, print_feature_table=True, top_n=10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"816be14a5a2a7bc234f55320131ea62061575820"},"cell_type":"markdown","source":"We can see that some classifiers have improved a bit with our new feature \"has_name\" and \"has_topname\" but the top score remains the same. "},{"metadata":{"trusted":true,"_uuid":"f71cfeb28473377c4f84654d2b13aafce7a6beba","_kg_hide-input":false,"_kg_hide-output":false},"cell_type":"code","source":"#Binning:\ndef binning(col, cut_points, labels=None):\n  #Define min and max values:\n  minval = col.min()\n  maxval = col.max()\n\n  #create list by adding min and max to cut_points\n  break_points = [minval] + cut_points + [maxval]\n\n  #if no labels provided, use default labels 0 ... (n-1)\n  if not labels:\n    labels = range(len(cut_points)+1)\n\n  #Binning using cut function of pandas\n  colBin = pd.cut(col,bins=break_points,labels=labels,include_lowest=True)\n  return colBin","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"19a59fd5a32a6ee1c8c818d28ef3394c7283731f"},"cell_type":"code","source":"cut_points = [1,2,3,4,8,12,24,36,48]\nlabels = [\"1m\",\"2m\",\"3m\",\"4m\",\"8m\",\"1y\",\"2y\",\"3y\",\"4y\",\"5y and over\"]\ntrain[\"age_bin\"] = binning(train[\"Age\"], cut_points, labels)\n\n# for our model we need to have int values, thus we use a LabelEncoder\nlabels = [1,2,3,4,5,6,7,8,9,10]\ntrain[\"age_bin\"] = binning(train[\"Age\"], cut_points, labels)\ntest[\"age_bin\"] = binning(test[\"Age\"], cut_points, labels)\nlabel = LabelEncoder()\ntrain['age_bin'] = label.fit_transform(train['age_bin'])\ntest['age_bin'] = label.fit_transform(test['age_bin'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c0b1fa282b1a2fc15d679e883661efb126c12ca6"},"cell_type":"code","source":"top_3 = [\n    ensemble.AdaBoostClassifier(),\n    ensemble.GradientBoostingClassifier(),\n    XGBClassifier()    \n    ]\n\nuseColumns = ['Type', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2',\n       'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n       'Sterilized', 'Health', 'Quantity', 'Fee', 'State',\n       'VideoAmt', 'PhotoAmt', 'AdoptionSpeed', 'has_name', 'has_topname', 'age_bin']\n\n#train_model(train[useColumns], top_3, print_feature_table=True, top_n=10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"644df8f189994167b541eb985cec786ab4f61931"},"cell_type":"markdown","source":"Using scikit-learn's binning:"},{"metadata":{"trusted":true,"_uuid":"6177794873fff74e82d0c6a9cf92b0a1de890c51"},"cell_type":"code","source":"binner = KBinsDiscretizer(n_bins=5,encode='ordinal', strategy='kmeans')\n\n# if we just use pandas train.Age we get a Series.\n# scikit-learns wants a 2d array\n# ValueError: Expected 2D array, got 1D array instead:\n# train[['Age']].copy()\ntrain['age_bin_kmeans'] = pd.DataFrame(binner.fit_transform(train[['Age']].copy()))\ntest['age_bin_kmeans'] = pd.DataFrame(binner.fit_transform(test[['Age']].copy()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"53a0eda882b4de31b8002df3b13dcf6b5cdf2ac4"},"cell_type":"code","source":"binner = KBinsDiscretizer(n_bins=5,encode='ordinal', strategy='quantile')\n\n# if we just use pandas train.Age we get a Series.\n# scikit-learns wants a 2d array\n# ValueError: Expected 2D array, got 1D array instead:\n# train[['Age']].copy()\ntrain['age_bin_quantile'] = pd.DataFrame(binner.fit_transform(train[['Age']].copy()))\ntest['age_bin_quantile'] = pd.DataFrame(binner.fit_transform(test[['Age']].copy()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"13ed877bdef6c142115ecad14d897271ba962503"},"cell_type":"code","source":"useColumns = ['Type', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2',\n       'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n       'Sterilized', 'Health', 'Quantity', 'Fee', 'State',\n       'VideoAmt', 'PhotoAmt', 'AdoptionSpeed', 'has_name', 'has_topname', 'age_bin', 'age_bin_kmeans', 'age_bin_quantile']\n\n#train_model(train[useColumns], top_3, print_feature_table=True, top_n=10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d8915bc89abdbe01e63990559565189df237e150"},"cell_type":"markdown","source":"Using the bins has reduced the performance. The age_bin is still quite an important feature, but we lost some information along the way. It could though help against an overfit. \nWe could also transform the cat and dog ages to human ages and see if that helps.\nAnother idea might be to actually compare the age with the average lifespan of each pets type of breed."},{"metadata":{"trusted":true,"_uuid":"0a2fb7c7ff84f1a6b66f5be38f3a2dc17a8f1471","_kg_hide-input":false,"_kg_hide-output":false},"cell_type":"code","source":"# https://www.101computing.net/how-old-is-your-cat/\n\ncat_human_age = {1:0.5, 2:3, 3:4, 4:6, 5:8, 6:10, 7:12, 8:14, 9:15, 10:16, 11:17, 12:18, 24:24, 48:35, 72:42, 96:50, 120:60, 144:70, 168:80, 192:84 }\nsmall_dog_human_age = {1:1, 2:2, 3:2.5, 4:3.5, 5:4.3, 6:5, 7:6.3, 8:7, 9:9, 10:11, 11:13, 12:15, 24:23, 48:32, 72:40, 96:48, 120:56, 144:64, 168:72, 192:80 }\nnormal_dog_human_age = {1:1, 2:2, 3:2.5, 4:3.5, 5:4.3, 6:5, 7:6.3, 8:7, 9:9, 10:11, 11:13, 12:15, 24:24, 48:34, 72:42, 96:51, 120:60, 144:69, 168:78, 192:87 }\nbig_dog_human_age = {1:1, 2:2, 3:2.5, 4:3.5, 5:4.3, 6:5, 7:6.3, 8:7, 9:9, 10:11, 11:13, 12:14, 24:22, 48:34, 72:45, 96:55, 120:66, 144:77, 168:88, 192:99 }\n\ndef human_age(row):\n    months = row['Age']\n    if months == 0:\n        return 0\n    if row['Type'] == 2:\n        if cat_human_age.get(months) is not None:\n            return cat_human_age.get(months)\n        else:\n            if months < 25:\n                return 25\n            else:\n                return (25 + ((months/12) - 2) * 4)\n    elif row['Type'] == 1 and row['MaturitySize'] == 1:\n        if small_dog_human_age.get(months) is not None:\n            return small_dog_human_age.get(months)\n        else:\n            if months < 24:\n                return (months/12) * 11\n            else:\n                return (22 + ((months/12) - 2) * 4)\n    elif row['Type'] == 1 and row['MaturitySize'] == 3:\n        if big_dog_human_age.get(months) is not None:\n            return big_dog_human_age.get(months)\n        else:\n            if months < 24:\n                return (months/12) * 11\n            else:\n                return (22 + ((months/12) - 2) * 4)\n    if normal_dog_human_age.get(months) is not None:\n        return normal_dog_human_age.get(months)\n    else:\n        if months < 24:\n            return (months/12) * 11\n        else:\n            return (22 + ((months/12) - 2) * 4)\n\ndef lifestage(row):\n    age = row['human_age']\n    if age < 10:\n        return 'Kitten/Puppy'\n    elif age < 25:\n        return 'Junior'\n    elif age < 40:\n        return 'Prime'\n    elif age < 60:\n        return 'Mature'\n    elif age < 74:\n        return 'Senior'\n    return 'Geriatic'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c05333286473911ef268ead34818632df6913fe9"},"cell_type":"code","source":"train['human_age'] = train.apply(human_age, axis=1)\ntrain['lifestage'] = train.apply(lifestage, axis=1)\n\ntest['human_age'] = test.apply(human_age, axis=1)\ntest['lifestage'] = test.apply(lifestage, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b248aa0ce2737993032db4482b775db79877e428"},"cell_type":"markdown","source":"Almost all of the pets are Kitten/Puppies. This categorisation is probably to unbalanced to improve the score."},{"metadata":{"trusted":true,"_uuid":"dcb3095d0742f15eeb56ebbe11e82e5088f05013"},"cell_type":"code","source":"top_3 = [\n    ensemble.AdaBoostClassifier(),\n    ensemble.GradientBoostingClassifier(),\n    XGBClassifier()    \n    ]\n\nuseColumns = ['Type', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2',\n       'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n       'Sterilized', 'Health', 'Quantity', 'Fee', 'State',\n       'VideoAmt', 'PhotoAmt', 'AdoptionSpeed', 'has_name', 'has_topname', 'age_bin',\n              'age_bin_kmeans', 'age_bin_quantile','human_age']\n\n#train_model(train[useColumns], top_3, print_feature_table=True, top_n=10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f4ab8679ecb38542e4399a2d6925aefe56fac483"},"cell_type":"markdown","source":"Lifestage is a new categorial value. In fact it is an ordinal value. Thus we use a ordinal encoding to prepare it for the classification. "},{"metadata":{"trusted":true,"_uuid":"0627555b29ca8433743eaa0c533a8de7969d46ec"},"cell_type":"code","source":"mapper = {'Kitten/Puppy':1, 'Junior':2, 'Prime':3, 'Mature':4,'Senior':5,'Geriatic':6}\n\ntrain.lifestage.replace(mapper, inplace=True)\ntest.lifestage.replace(mapper, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2e163f30242b1329489390b2381164c397bc90ee"},"cell_type":"code","source":"useColumns = ['Type', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2',\n       'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n       'Sterilized', 'Health', 'Quantity', 'Fee', 'State',\n       'VideoAmt', 'PhotoAmt', 'AdoptionSpeed', 'has_name', 'has_topname',  'age_bin', \n              'age_bin_kmeans', 'age_bin_quantile','human_age', 'lifestage']\n\n#train_model(train[useColumns], top_3, print_feature_table=True, top_n=10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b6256942717a0d1ca06e7803141db08eb6fd8d69"},"cell_type":"markdown","source":"Dropping the age and just using lifestage has lower the performance a bit. But we can keep the feature to spped up the tpot learning later."},{"metadata":{"_uuid":"853dc1619414624bb3b9cd12cfc5cd4a4626a97c"},"cell_type":"markdown","source":"There are a lot of \"mixed breeds\" pets in our data set. Sometimes the \"Breed2\" is the same as \"Breed1\" but sometimes not. We can try to clean this data. And remove the Breed2 column."},{"metadata":{"trusted":true,"_uuid":"f2b58ba6d637319e45567e4ee11042a1bc0baa51"},"cell_type":"code","source":"def mixed_breed(row):\n    if row['Breed1'] == 307:\n        return 1\n    elif row['Breed2'] == 0:\n        return 0 \n    elif row['Breed2'] != row['Breed1']:\n        return 1\n    else:\n        return 0\n\ntrain['mixed_breed'] = train.apply(mixed_breed, axis=1)\ntest['mixed_breed'] = test.apply(mixed_breed, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7e4b904deb4bc787e1f54ad270d689346e72484c"},"cell_type":"markdown","source":"Breed1 and Breed2 are categorical, but there is no orderning. thus we use the OneHotEncoder / dummies.\nWe also drop Breed2, as we extraced the information into mixed_breed."},{"metadata":{"trusted":true,"_uuid":"70cd1a9f19dff9fbe82e11fe9af077e19acdb706"},"cell_type":"code","source":"top_1 = [\n    ensemble.GradientBoostingClassifier()   \n]\n\nuseColumns = ['Type', 'Breed1', 'Breed2',  'Gender', 'Color1', 'Color2',\n       'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n       'Sterilized', 'Health', 'Quantity', 'Fee', 'State',\n       'VideoAmt', 'PhotoAmt', 'AdoptionSpeed', 'has_name', 'has_topname',  'age_bin', \n              'age_bin_kmeans', 'age_bin_quantile','human_age', 'lifestage','mixed_breed']\n\n#train_model(pd.get_dummies(train[useColumns], columns=['Breed1','Breed2'], sparse=True), top_1, print_feature_table=True, top_n=10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3ca75ba7ed8af2f66c4f77d0d986aa6a6066ae3f"},"cell_type":"markdown","source":"Using the dummies for Breed1 and Breed2 results in a much longer training time. "},{"metadata":{"_uuid":"433db21b6864235f282ff675c6181a50dcc740eb"},"cell_type":"markdown","source":"## Target encoding (exanding mean):\n\nAnother idea is to use some target encoding. Here we look at each breed and calculate the impact on the target variable. This introduces leakage from the target variable and can lead to an overfit. To avoid this, we use the countermeasurement \"expanding mean\". For more info: https://medium.com/@pouryaayria/k-fold-target-encoding-dfe9a594874b"},{"metadata":{"trusted":true,"_uuid":"2da068ce39383c6c4c018c43ba5dedc26270c9ae"},"cell_type":"code","source":"train.groupby('Breed1')[\"AdoptionSpeed\"].value_counts().head(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8bfcf73a210fa76a5f8c95005d619ac9541261df"},"cell_type":"markdown","source":"Pets with 'Breed1' =  0:\n* 2 pets with AdoptionSpeed 3\n* 2 pets with AdoptionSpeed 4\n* 1 pet with AdoptionSpeed 2"},{"metadata":{"trusted":true,"_uuid":"65949e3f83c196c1aef3990b640ce6103ffead16"},"cell_type":"code","source":"subtrain = train[train.Breed1 == 0]\ncumulative_sum = subtrain.groupby('Breed1')[\"AdoptionSpeed\"].cumsum() - subtrain[\"AdoptionSpeed\"]\ncumulative_count = subtrain.groupby('Breed1').cumcount()\nprint(cumulative_sum)\nprint(cumulative_count)\ncumulative_sum/cumulative_count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"027934bad3d0e01d79b1f109593db1d226ae43db"},"cell_type":"code","source":"def cat_mean_encoding(df, column):\n    cumulative_sum = df.groupby(column)[\"AdoptionSpeed\"].cumsum() - df[\"AdoptionSpeed\"]\n    cumulative_count = df.groupby(column).cumcount()\n    df[column + \"_mean_encoding\"] =  cumulative_sum/cumulative_count\n    df[column + \"_mean_encoding\"].fillna(df.AdoptionSpeed.mean(), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ab06f4d2b661b5d6ff4591c05154c53629d2932e","_kg_hide-input":true},"cell_type":"code","source":"# from: https://medium.com/@pouryaayria/k-fold-target-encoding-dfe9a594874b\nfrom sklearn import base\n\nclass KFoldTargetEncoderTrain(base.BaseEstimator, base.TransformerMixin):\n\n    def __init__(self, colnames,targetName,n_fold=5,verbosity=True,discardOriginal_col=False):\n\n        self.colnames = colnames\n        self.targetName = targetName\n        self.n_fold = n_fold\n        self.verbosity = verbosity\n        self.discardOriginal_col = discardOriginal_col\n\n    def fit(self, X, y=None):\n        return self\n\n\n    def transform(self,X):\n\n        assert(type(self.targetName) == str)\n        assert(type(self.colnames) == str)\n        assert(self.colnames in X.columns)\n        assert(self.targetName in X.columns)\n\n        mean_of_target = X[self.targetName].mean()\n        kf = StratifiedKFold(n_splits=self.n_fold, shuffle=True)\n        \n        col_mean_name = self.colnames + '_' + 'Kfold_Target_Enc'\n        X[col_mean_name] = np.nan\n\n        for tr_ind, val_ind in kf.split(X,X[self.targetName]):\n            X_tr, X_val = X.iloc[tr_ind], X.iloc[val_ind]\n            #print(tr_ind,val_ind)\n            X.loc[X.index[val_ind], col_mean_name] = X_val[self.colnames].map(X_tr.groupby(self.colnames)[self.targetName].mean())\n\n        X[col_mean_name].fillna(mean_of_target, inplace = True)\n\n        if self.verbosity:\n\n            encoded_feature = X[col_mean_name].values\n            print('Correlation between the new feature, {} and, {} is {}.'.format(col_mean_name,\n                                                                                      self.targetName,\n                                                                                      np.corrcoef(X[self.targetName].values, encoded_feature)[0][1]))\n        if self.discardOriginal_col:\n            X = X.drop(self.targetName, axis=1)\n            \n        return X\n    \n    \n    \nclass KFoldTargetEncoderTest(base.BaseEstimator, base.TransformerMixin):\n    def __init__(self,train,colNames,encodedName):\n        self.train = train\n        self.colNames = colNames\n        self.encodedName = encodedName\n        \n    def fit(self, X, y=None):\n        return self\n\n    def transform(self,X):\n\n        mean = self.train[[self.colNames,self.encodedName]].groupby(self.colNames).mean().reset_index() \n        \n        dd = {}\n        for index, row in mean.iterrows():\n            dd[row[self.colNames]] = row[self.encodedName]\n\n        X[self.encodedName] = X[self.colNames]\n        X[self.encodedName] = X[self.encodedName].map(dd)\n\n        return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c451f9ceb1f2a7152f21a136273d854027a7c2da"},"cell_type":"code","source":"targetc = KFoldTargetEncoderTrain('Breed1','AdoptionSpeed',n_fold=5)\ntrain = targetc.fit_transform(train)\n\ntargetc = KFoldTargetEncoderTrain('Breed2','AdoptionSpeed',n_fold=5)\ntrain = targetc.fit_transform(train)\n\ntest_targetc = KFoldTargetEncoderTest(train,'Breed1','Breed1_Kfold_Target_Enc')\ntest= test_targetc.fit_transform(test)\n\ntest_targetc = KFoldTargetEncoderTest(train,'Breed2','Breed2_Kfold_Target_Enc')\ntest= test_targetc.fit_transform(test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"13d0899a9635ddb731909b2aaaa5aea92b6df67f"},"cell_type":"code","source":"cat_mean_encoding(train, 'Breed1')\ncat_mean_encoding(train, 'Breed2')\n\ntest_targetc = KFoldTargetEncoderTest(train,'Breed1','Breed1_mean_encoding')\ntest= test_targetc.fit_transform(test)\n\ntest_targetc = KFoldTargetEncoderTest(train,'Breed2','Breed2_mean_encoding')\ntest= test_targetc.fit_transform(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe4ecb967f54a15763b59eaf6a988c54cefbfcf6"},"cell_type":"code","source":"print(train.Breed1_Kfold_Target_Enc.isna().sum())\nprint(train.Breed2_Kfold_Target_Enc.isna().sum())\nprint(test.Breed1_Kfold_Target_Enc.isna().sum())\nprint(test.Breed2_Kfold_Target_Enc.isna().sum())\n\nprint(train.Breed1_mean_encoding.isna().sum())\nprint(train.Breed2_mean_encoding.isna().sum())\nprint(test.Breed1_mean_encoding.isna().sum())\nprint(test.Breed2_mean_encoding.isna().sum())\n\ntest[~test.Breed1.isin(train.Breed1)].head(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c06fb28cc611a01f230f645489c73500d1c4fdc6"},"cell_type":"markdown","source":"There are some breeds in test which are not in the train set. Fix those values with setting the mean."},{"metadata":{"trusted":true,"_uuid":"bc34974b1632b9bf5f0926b14f7e7d477c1c52e8"},"cell_type":"code","source":"test.Breed1_Kfold_Target_Enc.fillna(train.AdoptionSpeed.mean(), inplace=True)\ntest.Breed2_Kfold_Target_Enc.fillna(train.AdoptionSpeed.mean(), inplace=True)\ntest.Breed1_mean_encoding.fillna(train.AdoptionSpeed.mean(), inplace=True)\ntest.Breed2_mean_encoding.fillna(train.AdoptionSpeed.mean(), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fea527a745b54a25e22c610a8cb5533abd0d6d5e"},"cell_type":"code","source":"useColumns = ['Type', 'Breed1_Kfold_Target_Enc','Breed2_Kfold_Target_Enc','Gender', 'Color1', 'Color2',\n       'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n       'Sterilized', 'Health', 'Quantity', 'Fee', 'State',\n       'VideoAmt', 'PhotoAmt', 'AdoptionSpeed', 'has_name', 'has_topname',  'age_bin', \n              'age_bin_kmeans', 'age_bin_quantile','human_age', 'lifestage','mixed_breed',\n       'Breed1_mean_encoding', 'Breed2_mean_encoding']\n\n#train_model(train[useColumns], top_3, print_feature_table=True, top_n=10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"352de0836a2c73163a5746f7d537129dd397ec89"},"cell_type":"markdown","source":"Rescuer is a distinct list between train and test. We can implement a frequency encoding.\n\nsteps:\n1. count occurences of each rescuer. \n2. target encoding per rescuer (number of pets)\n"},{"metadata":{"trusted":true,"_uuid":"4a3fbab2cfa0e6d7e5fe3e56397e9254ab61c891"},"cell_type":"code","source":"# create pet count for each rescuer\nrescuer_count = train.groupby(['RescuerID'])['PetID'].count().reset_index()\nrescuer_count_dict = rescuer_count.set_index('RescuerID').T.to_dict('list')\n\n#set number to each item\ntrain.RescuerID = train.RescuerID.apply(lambda x: np.log(rescuer_count_dict.get(x)[0]))\n\n# now we have a number count for each rescuer. now we create bins \nbinner = KBinsDiscretizer(n_bins=6,encode='ordinal', strategy='kmeans')\ntrain['rescuer_bin_kmeans'] = pd.DataFrame(binner.fit_transform(train[['RescuerID']].copy()))\n\n# target encode\ntargetc = KFoldTargetEncoderTrain('rescuer_bin_kmeans','AdoptionSpeed',n_fold=5)\ntrain = targetc.fit_transform(train)\n\n\n# same for the test\nrescuer_count = test.groupby(['RescuerID'])['PetID'].count().reset_index()\nrescuer_count_dict = rescuer_count.set_index('RescuerID').T.to_dict('list')\ntest.RescuerID = test.RescuerID.apply(lambda x: np.log(rescuer_count_dict.get(x)[0]))\nbinner = KBinsDiscretizer(n_bins=5,encode='ordinal', strategy='kmeans')\ntest['rescuer_bin_kmeans'] = pd.DataFrame(binner.fit_transform(test[['RescuerID']].copy()))\ntest_targetc = KFoldTargetEncoderTest(train,'rescuer_bin_kmeans','rescuer_bin_kmeans_Kfold_Target_Enc')\ntest= test_targetc.fit_transform(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"506935733208771980f45974d3c64b3ed8022efa"},"cell_type":"code","source":"useColumns = ['Type', 'Breed1_Kfold_Target_Enc','Breed2_Kfold_Target_Enc','Gender', 'Color1', 'Color2',\n       'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n       'Sterilized', 'Health', 'Quantity', 'Fee', 'State',\n       'VideoAmt', 'PhotoAmt', 'AdoptionSpeed', 'has_name', 'has_topname',  'age_bin', \n              'age_bin_kmeans', 'age_bin_quantile','human_age', 'lifestage','mixed_breed',\n       'Breed1_mean_encoding', 'Breed2_mean_encoding','rescuer_bin_kmeans','rescuer_bin_kmeans_Kfold_Target_Enc']\n\n#train_model(train[useColumns], top_3, print_feature_table=True, top_n=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a68d2d38aac556e2f482ed208f3316a232123091"},"cell_type":"code","source":"# state GDP: https://en.wikipedia.org/wiki/List_of_Malaysian_states_by_GDP\nstate_gdp = {\n    41336: 116.679,\n    41325: 40.596,\n    41367: 23.02,\n    41401: 190.075,\n    41415: 5.984,\n    41324: 37.274,\n    41332: 42.389,\n    41335: 52.452,\n    41330: 67.629,\n    41380: 5.642,\n    41327: 81.284,\n    41345: 80.167,\n    41342: 121.414,\n    41326: 280.698,\n    41361: 32.270\n}\n\n# state population: https://en.wikipedia.org/wiki/Malaysia\nstate_population = {\n    41336: 33.48283,\n    41325: 19.47651,\n    41367: 15.39601,\n    41401: 16.74621,\n    41415: 0.86908,\n    41324: 8.21110,\n    41332: 10.21064,\n    41335: 15.00817,\n    41330: 23.52743,\n    41380: 2.31541,\n    41327: 15.61383,\n    41345: 32.06742,\n    41342: 24.71140,\n    41326: 54.62141,\n    41361: 10.35977\n}\n\nstate_area ={\n41336:19102,\n41325:9500,\n41367:15099,\n41401:243,\n41415:91,\n41324:1664,\n41332:6686,\n41335:36137,\n41330:21035,\n41380:821,\n41327:1048,\n41345:73631,\n41342:124450,\n41326:8104,\n41361:13035}\n\ntrain[\"state_gdp\"] = train.State.map(state_gdp)\ntrain[\"state_population\"] = train.State.map(state_population)\ntrain[\"state_area\"] = train.State.map(state_area)\ntest[\"state_gdp\"] = test.State.map(state_gdp)\ntest[\"state_population\"] = test.State.map(state_population)\ntest[\"state_area\"] = test.State.map(state_area)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"13712b8530c1d270ef054df24a70db138e77f9e9"},"cell_type":"code","source":"targetc = KFoldTargetEncoderTrain('State','AdoptionSpeed',n_fold=5)\ntrain = targetc.fit_transform(train)\n\ntest_targetc = KFoldTargetEncoderTest(train,'State','State_Kfold_Target_Enc')\ntest= test_targetc.fit_transform(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b2b9eec7b224e933ce498e454d280807cda9ad3"},"cell_type":"code","source":"useColumns = ['Type', 'Breed1_Kfold_Target_Enc','Breed2_Kfold_Target_Enc','Gender', 'Color1', 'Color2',\n       'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n       'Sterilized', 'Health', 'Quantity', 'Fee','State_Kfold_Target_Enc','state_gdp','state_population','state_area',\n       'VideoAmt', 'PhotoAmt', 'AdoptionSpeed', 'has_name', 'has_topname',  'age_bin', \n              'age_bin_kmeans', 'age_bin_quantile','human_age', 'lifestage','mixed_breed',\n       'Breed1_mean_encoding', 'Breed2_mean_encoding','rescuer_bin_kmeans','rescuer_bin_kmeans_Kfold_Target_Enc'\n            ]\n\n#train_model(train[useColumns], top_3, print_feature_table=True, top_n=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ea93b6544a068b33b069e5677594920754ad1cdb"},"cell_type":"code","source":"targetc = KFoldTargetEncoderTrain('Color1','AdoptionSpeed',n_fold=5)\ntrain = targetc.fit_transform(train)\n\ntest_targetc = KFoldTargetEncoderTest(train,'Color1','Color1_Kfold_Target_Enc')\ntest= test_targetc.fit_transform(test)\n\ntargetc = KFoldTargetEncoderTrain('Color2','AdoptionSpeed',n_fold=5)\ntrain = targetc.fit_transform(train)\n\ntest_targetc = KFoldTargetEncoderTest(train,'Color2','Color2_Kfold_Target_Enc')\ntest= test_targetc.fit_transform(test)\n\ntargetc = KFoldTargetEncoderTrain('Color3','AdoptionSpeed',n_fold=5)\ntrain = targetc.fit_transform(train)\n\ntest_targetc = KFoldTargetEncoderTest(train,'Color3','Color3_Kfold_Target_Enc')\ntest= test_targetc.fit_transform(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"548e4eae73502384c97ec8d99f38abca6b5d272a"},"cell_type":"code","source":"useColumns = ['Type', 'Breed1_Kfold_Target_Enc','Breed2_Kfold_Target_Enc','Gender', \n              'Color1_Kfold_Target_Enc', 'Color2_Kfold_Target_Enc',\n       'Color3_Kfold_Target_Enc', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n       'Sterilized', 'Health', 'Quantity', 'Fee','State_Kfold_Target_Enc','state_gdp','state_population','state_area',\n       'VideoAmt', 'PhotoAmt', 'AdoptionSpeed', 'has_name', 'has_topname',  'age_bin', \n              'age_bin_kmeans', 'age_bin_quantile','human_age', 'lifestage','mixed_breed',\n       'Breed1_mean_encoding', 'Breed2_mean_encoding','rescuer_bin_kmeans','rescuer_bin_kmeans_Kfold_Target_Enc'\n            ]\n\n#train_model(train[useColumns], top_3, print_feature_table=True, top_n=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4ed3b304087685903ecf142894ba72e15f688fff"},"cell_type":"code","source":"train.Description.fillna('none', inplace=True)\ntest.Description.fillna('none', inplace=True)\n\ntrain['desc_length'] = train.Description.apply(len)\ntest['desc_length'] = test.Description.apply(len)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e0d296e657bd26ed6080aee7ffa0e93bed2198a9"},"cell_type":"code","source":"    tfv = TfidfVectorizer(min_df=2,  max_features=None,\n                          strip_accents='unicode', analyzer='word', token_pattern=r'(?u)\\b\\w+\\b',\n                          ngram_range=(1, 4), use_idf=1, smooth_idf=1, sublinear_tf=1)\n    # make 5 pca's\n    svd_ = TruncatedSVD(n_components=5)\n    \n    # here we use train and test data to create the tfidf.\n    train_test = pd.concat([train, test], ignore_index=True, sort=False)\n    tfidf_col = tfv.fit_transform(train_test.Description)\n    svd_col = svd_.fit_transform(tfidf_col)\n    svd_col = pd.DataFrame(svd_col)\n    svd_col = svd_col.add_prefix('TFIDF_')\n    pcas = pd.concat([train_test, svd_col], axis=1)\n    \n    #extract test and train rows\n    train = pcas.loc[np.isfinite(pcas.AdoptionSpeed), :]\n    test = pcas.loc[~np.isfinite(pcas.AdoptionSpeed), :]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cd8f1df4ae54af8e403f0ae82762cba7fdcaa9b9"},"cell_type":"code","source":"useColumns = ['Type', 'Breed1_Kfold_Target_Enc','Breed2_Kfold_Target_Enc','Gender', \n              'Color1_Kfold_Target_Enc', 'Color2_Kfold_Target_Enc',\n       'Color3_Kfold_Target_Enc', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n       'Sterilized', 'Health', 'Quantity', 'Fee','State_Kfold_Target_Enc','state_gdp','state_population','state_area',\n       'VideoAmt', 'PhotoAmt', 'AdoptionSpeed', 'has_name', 'has_topname',  'age_bin', \n              'age_bin_kmeans', 'age_bin_quantile','human_age', 'lifestage','mixed_breed',\n       'Breed1_mean_encoding', 'Breed2_mean_encoding','rescuer_bin_kmeans','rescuer_bin_kmeans_Kfold_Target_Enc',\n              'desc_length', 'TFIDF_0','TFIDF_1','TFIDF_2','TFIDF_3','TFIDF_4'             ]\n\n#result = train_model(train[useColumns],  print_feature_table=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e1c960bc39ebbef7d03cbf402836a6b280a26d97"},"cell_type":"markdown","source":"Now lets do some feature ranking with recursive feature elimination and cross-validated selection of the best number of features."},{"metadata":{"_uuid":"0c50502cb2f8b0f2dff293c1e4f460b0453714cb","trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import RFECV\n\nuseColumns = ['Type', 'Breed1_Kfold_Target_Enc','Breed2_Kfold_Target_Enc','Gender', \n              'Color1_Kfold_Target_Enc', 'Color2_Kfold_Target_Enc',\n       'Color3_Kfold_Target_Enc', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n       'Sterilized', 'Health', 'Quantity', 'Fee','State_Kfold_Target_Enc','state_gdp','state_population','state_area',\n       'VideoAmt', 'PhotoAmt', 'has_name', 'has_topname',  'age_bin', \n              'age_bin_kmeans', 'age_bin_quantile','human_age', 'lifestage','mixed_breed',\n       'Breed1_mean_encoding', 'Breed2_mean_encoding','rescuer_bin_kmeans','rescuer_bin_kmeans_Kfold_Target_Enc'\n            ]\nfeatures = train[useColumns]\n\nkappa_score = make_scorer(cohen_kappa_score, weights='quadratic')\nfor alg in []:\n    kf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n    rfecv = RFECV(estimator=alg, step=1, cv=kf, scoring=kappa_score, n_jobs=-1)\n    rfecv.fit(features,train['AdoptionSpeed'])\n    print(\"Optimal number of features : %d\" % rfecv.n_features_)\n    print(rfecv.support_)\n    print(features.columns[rfecv.support_])\n    # Plot number of features VS. cross-validation scores\n    plt.figure()\n    plt.xlabel(\"Number of features selected\")\n    plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n    plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2955219160a68077b14f171af06297f1c185affe"},"cell_type":"code","source":"useColumns = ['Breed1_Kfold_Target_Enc', 'Breed2_Kfold_Target_Enc', 'FurLength',\n       'Sterilized', 'State_Kfold_Target_Enc', 'PhotoAmt', 'age_bin',\n       'human_age', 'Breed1_mean_encoding', 'Breed2_mean_encoding',\n       'rescuer_bin_kmeans', 'rescuer_bin_kmeans_Kfold_Target_Enc']\n\nparams = {\n 'n_estimators': [50, 100, 200],\n 'learning_rate' : [0.01,0.05,0.1,0.3,1],\n 'base_estimator': [ensemble.AdaBoostClassifier(), ensemble.GradientBoostingClassifier()]\n }\n\nX_train = train[useColumns]\ny_train = train['AdoptionSpeed']\n\nkf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\ncv_split = kf.split(X_train, y_train)\nkappa_score = make_scorer(cohen_kappa_score, weights='quadratic')\ntuning = GridSearchCV(estimator = ensemble.AdaBoostClassifier(), param_grid = params,\n                      scoring=kappa_score,cv=5, n_jobs=-1,iid=False)\n\n#tuning.fit(X_train,y_train)\n#tuning.best_params_, tuning.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"93ede4e83da11da055966bb5a54b4ea737e28b42"},"cell_type":"code","source":"params = {'learning_rate':[0.15,0.1,0.05,0.01,0.005,0.001], \n          'n_estimators':[100,250,500,750,1000,1250,1500,1750],\n          'max_depth':[2,3,4,5,6,7],\n          'min_samples_split':[2,4,6,8,10,20,40,60,100], \n          'min_samples_leaf':[1,3,5,7,9],\n          'max_features':[2,3,4,5,6,7],\n          'subsample':[0.7,0.75,0.8,0.85,0.9,0.95,1]}\n\nkf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\nkappa_score = make_scorer(cohen_kappa_score, weights='quadratic')\ntuning = GridSearchCV(estimator = ensemble.GradientBoostingClassifier(), param_grid = params, \n                      scoring=kappa_score,cv=kf, n_jobs=-1,iid=False)\n\ntrain_cleaned = train.drop(['Name','human_age','lifestage','RescuerID','Description','PetID', 'dataset_type'],axis=1)\ny_train = train_cleaned['AdoptionSpeed']\nX_train = train_cleaned.drop(['AdoptionSpeed'],axis=1)\n    \n#tuning.fit(X_train,y_train)\n#tuning.grid_scores_, tuning.best_params_, tuning.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"476c870b6684f7c2eb3b1e73319a7f6a17929bc9"},"cell_type":"code","source":"# from https://www.kaggle.com/naveenasaithambi/optimizedrounder-improved\n\nimport scipy as sp\n\nfrom collections import Counter\nfrom functools import partial\nfrom math import sqrt\n\nfrom sklearn.metrics import cohen_kappa_score, mean_squared_error\nfrom sklearn.metrics import confusion_matrix as sk_cmatrix\n\n\n# FROM: https://www.kaggle.com/myltykritik/simple-lgbm-image-features\n\n# The following 3 functions have been taken from Ben Hamner's github repository\n# https://github.com/benhamner/Metrics\ndef confusion_matrix(rater_a, rater_b, min_rating=None, max_rating=None):\n    \"\"\"\n    Returns the confusion matrix between rater's ratings\n    \"\"\"\n    assert(len(rater_a) == len(rater_b))\n    if min_rating is None:\n        min_rating = min(rater_a + rater_b)\n    if max_rating is None:\n        max_rating = max(rater_a + rater_b)\n    num_ratings = int(max_rating - min_rating + 1)\n    conf_mat = [[0 for i in range(num_ratings)]\n                for j in range(num_ratings)]\n    for a, b in zip(rater_a, rater_b):\n        conf_mat[a - min_rating][b - min_rating] += 1\n    return conf_mat\n\n\ndef histogram(ratings, min_rating=None, max_rating=None):\n    \"\"\"\n    Returns the counts of each type of rating that a rater made\n    \"\"\"\n    if min_rating is None:\n        min_rating = min(ratings)\n    if max_rating is None:\n        max_rating = max(ratings)\n    num_ratings = int(max_rating - min_rating + 1)\n    hist_ratings = [0 for x in range(num_ratings)]\n    for r in ratings:\n        hist_ratings[r - min_rating] += 1\n    return hist_ratings\n\n\ndef quadratic_weighted_kappa(y, y_pred):\n    \"\"\"\n    Calculates the quadratic weighted kappa\n    axquadratic_weighted_kappa calculates the quadratic weighted kappa\n    value, which is a measure of inter-rater agreement between two raters\n    that provide discrete numeric ratings.  Potential values range from -1\n    (representing complete disagreement) to 1 (representing complete\n    agreement).  A kappa value of 0 is expected if all agreement is due to\n    chance.\n    quadratic_weighted_kappa(rater_a, rater_b), where rater_a and rater_b\n    each correspond to a list of integer ratings.  These lists must have the\n    same length.\n    The ratings should be integers, and it is assumed that they contain\n    the complete range of possible ratings.\n    quadratic_weighted_kappa(X, min_rating, max_rating), where min_rating\n    is the minimum possible rating, and max_rating is the maximum possible\n    rating\n    \"\"\"\n    rater_a = y\n    rater_b = y_pred\n    min_rating=None\n    max_rating=None\n    rater_a = np.array(rater_a, dtype=int)\n    rater_b = np.array(rater_b, dtype=int)\n    assert(len(rater_a) == len(rater_b))\n    if min_rating is None:\n        min_rating = min(min(rater_a), min(rater_b))\n    if max_rating is None:\n        max_rating = max(max(rater_a), max(rater_b))\n    conf_mat = confusion_matrix(rater_a, rater_b,\n                                min_rating, max_rating)\n    num_ratings = len(conf_mat)\n    num_scored_items = float(len(rater_a))\n\n    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n\n    numerator = 0.0\n    denominator = 0.0\n\n    for i in range(num_ratings):\n        for j in range(num_ratings):\n            expected_count = (hist_rater_a[i] * hist_rater_b[j]\n                              / num_scored_items)\n            d = pow(i - j, 2.0) / pow(num_ratings - 1, 2.0)\n            numerator += d * conf_mat[i][j] / num_scored_items\n            denominator += d * expected_count / num_scored_items\n\n    return (1.0 - numerator / denominator)\n\nclass OptimizedRounder(object):\n    def __init__(self):\n        self.coef_ = 0\n    \n    def _kappa_loss(self, coef, X, y):\n        preds = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3, 4])\n        return -cohen_kappa_score(y, preds, weights='quadratic')\n    \n    def fit(self, X, y):\n        loss_partial = partial(self._kappa_loss, X = X, y = y)\n        initial_coef = [0.5, 1.5, 2.5, 3.5]\n        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n    \n    def predict(self, X, coef):\n        preds = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3, 4])\n        return preds\n    \n    def coefficients(self):\n        return self.coef_['x']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a0fec1fdecf9eed0eb832a976937cd36c7fdcafd"},"cell_type":"markdown","source":"useColumns = ['Type', 'Breed1_Kfold_Target_Enc','Breed2_Kfold_Target_Enc','Gender', \n              'Color1_Kfold_Target_Enc', 'Color2_Kfold_Target_Enc',\n       'Color3_Kfold_Target_Enc', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n       'Sterilized', 'Health', 'Quantity', 'Fee','State_Kfold_Target_Enc','state_gdp','state_population','state_area',\n       'VideoAmt', 'PhotoAmt', 'AdoptionSpeed', 'has_name', 'has_topname',  'age_bin', \n              'age_bin_kmeans', 'age_bin_quantile','human_age', 'lifestage','mixed_breed',\n       'Breed1_mean_encoding', 'Breed2_mean_encoding','rescuer_bin_kmeans','rescuer_bin_kmeans_Kfold_Target_Enc',\n              'desc_length', 'TFIDF_0','TFIDF_1','TFIDF_2','TFIDF_3','TFIDF_4'             ]\n\ntarget = train.AdoptionSpeed\nX_train=train[useColumns]\nX_test=test[useColumns]\n\nclf = ensemble.GradientBoostingClassifier().fit(X_train, target)\npred = clf.predict(X_train)\n\noptR = OptimizedRounder()\noptR.fit(pred, X_train['AdoptionSpeed'].values)\ncoefficients = optR.coefficients()\nvalid_pred = optR.predict(pred, coefficients)\nqwk = quadratic_weighted_kappa(X_train['AdoptionSpeed'].values, valid_pred)\nprint(\"QWK = \", qwk)"},{"metadata":{"trusted":true,"_uuid":"8d7dc6828ba19867abf13cf04b553b3129054cd4"},"cell_type":"code","source":"useColumns = ['Type', 'Breed1_Kfold_Target_Enc','Breed2_Kfold_Target_Enc','Gender', \n              'Color1_Kfold_Target_Enc', 'Color2_Kfold_Target_Enc',\n       'Color3_Kfold_Target_Enc', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n       'Sterilized', 'Health', 'Quantity', 'Fee','State_Kfold_Target_Enc','state_gdp','state_population','state_area',\n       'VideoAmt', 'PhotoAmt','has_name', 'has_topname',  'age_bin', \n              'age_bin_kmeans', 'age_bin_quantile','human_age', 'lifestage','mixed_breed',\n       'Breed1_mean_encoding', 'Breed2_mean_encoding','rescuer_bin_kmeans','rescuer_bin_kmeans_Kfold_Target_Enc',\n              'desc_length', 'TFIDF_0','TFIDF_1','TFIDF_2','TFIDF_3','TFIDF_4'             ]\n\ntarget = train.AdoptionSpeed.astype('int')\nX_train=train[useColumns]\nX_test=test[useColumns]\n\n#clf = ensemble.GradientBoostingClassifier(n_estimators=200, learning_rate=1.0, max_depth=1, random_state=0).fit(X_train, target)\n#pred = clf.predict(X_test)\n           \n#submit=pd.DataFrame()\n#submit['PetID']=test['PetID']\n#submit['AdoptionSpeed']=pred\n#submit.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3a9fc0311fd0f32ef724ce159cedc7c1da021ffe"},"cell_type":"code","source":"useColumns = ['AdoptionSpeed','Type', 'Breed1_Kfold_Target_Enc','Breed2_Kfold_Target_Enc','Gender', \n              'Color1_Kfold_Target_Enc', 'Color2_Kfold_Target_Enc',\n       'Color3_Kfold_Target_Enc', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n       'Sterilized', 'Health', 'Quantity', 'Fee','State_Kfold_Target_Enc','state_gdp','state_population','state_area',\n       'VideoAmt', 'PhotoAmt','has_name', 'has_topname',  'age_bin', \n              'age_bin_kmeans', 'age_bin_quantile','human_age', 'lifestage','mixed_breed',\n       'Breed1_mean_encoding', 'Breed2_mean_encoding','rescuer_bin_kmeans','rescuer_bin_kmeans_Kfold_Target_Enc',\n              'desc_length', 'TFIDF_0','TFIDF_1','TFIDF_2','TFIDF_3','TFIDF_4'             ]\n\ntarget = train.AdoptionSpeed.astype('int')\nX_train=train[useColumns]\nX_test=test[useColumns].drop(['AdoptionSpeed'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ba175ce2cbe37545d566d8d937ed8ce1682b9ba7"},"cell_type":"code","source":"xgb_params = {\n    'eval_metric': 'rmse',\n    'seed': 1337,\n    'silent': 1,\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e09a6a6f15e2ec6ba67697a2e70dc11607578bf4"},"cell_type":"code","source":"import xgboost as xgb\n\ndef run_xgb(params, X_train, X_test):\n    n_splits = 5\n    verbose_eval = 1000\n    num_rounds = 30000\n    early_stop = 500\n\n    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=1337)\n\n    oof_train = np.zeros((X_train.shape[0]))\n    oof_test = np.zeros((X_test.shape[0], n_splits))\n\n    i = 0\n\n    for train_idx, valid_idx in kf.split(X_train, X_train['AdoptionSpeed'].values):\n\n        X_tr = X_train.iloc[train_idx, :]\n        X_val = X_train.iloc[valid_idx, :]\n\n        y_tr = X_tr['AdoptionSpeed'].values\n        X_tr = X_tr.drop(['AdoptionSpeed'], axis=1)\n\n        y_val = X_val['AdoptionSpeed'].values\n        X_val = X_val.drop(['AdoptionSpeed'], axis=1)\n\n        d_train = xgb.DMatrix(data=X_tr, label=y_tr, feature_names=X_tr.columns)\n        d_valid = xgb.DMatrix(data=X_val, label=y_val, feature_names=X_val.columns)\n\n        watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n        model = xgb.train(dtrain=d_train, num_boost_round=num_rounds, evals=watchlist,\n                         early_stopping_rounds=early_stop, verbose_eval=verbose_eval, params=params)\n\n        valid_pred = model.predict(xgb.DMatrix(X_val, feature_names=X_val.columns), ntree_limit=model.best_ntree_limit)\n        test_pred = model.predict(xgb.DMatrix(X_test, feature_names=X_test.columns), ntree_limit=model.best_ntree_limit)\n\n        oof_train[valid_idx] = valid_pred\n        oof_test[:, i] = test_pred\n\n        i += 1\n    return model, oof_train, oof_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c9e655adc9167fd961f1334426e870df8c6c1435"},"cell_type":"code","source":"model, oof_train, oof_test = run_xgb(xgb_params, X_train, X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"12d5fab0f9b038139488f0c16856b43dc459d717"},"cell_type":"code","source":"optR = OptimizedRounder()\noptR.fit(oof_train, X_train['AdoptionSpeed'].values)\ncoefficients = optR.coefficients()\nvalid_pred = optR.predict(oof_train, coefficients)\nqwk = quadratic_weighted_kappa(X_train['AdoptionSpeed'].values, valid_pred)\nprint(\"QWK = \", qwk)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9c38f0d22cca60625fbecaf43277397879ca8bb3"},"cell_type":"code","source":"coefficients_ = coefficients.copy()\ncoefficients_[0] = 1.65\ntrain_predictions = optR.predict(oof_train, coefficients_).astype(np.int8)\ntest_predictions = optR.predict(oof_test.mean(axis=1), coefficients_).astype(np.int8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"00dcf74fea7b9528d020d4d410537700269de49b"},"cell_type":"code","source":"submission = pd.DataFrame({'PetID': test['PetID'].values, 'AdoptionSpeed': test_predictions})\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}