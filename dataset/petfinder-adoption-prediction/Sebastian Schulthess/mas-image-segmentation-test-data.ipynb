{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# Any results you write to the current directory are saved as output.\n\n#ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.exceptions import ConvergenceWarning\nwarnings.simplefilter(action=\"ignore\", category=ConvergenceWarning)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import math\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.pylab as pylab\nimport seaborn as sns\n\n#Common Model Algorithms\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\n\n#Common Model Helpers\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder,OrdinalEncoder, StandardScaler,KBinsDiscretizer\nfrom sklearn import feature_selection\nfrom sklearn import model_selection\nfrom sklearn import metrics\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD\n\n# Evaluation\nfrom sklearn.metrics import cohen_kappa_score,make_scorer\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATA_DIR = '/kaggle/input/'\n\n# Directory to save logs and trained model\nROOT_DIR = '/kaggle/working/'\n\nMASK_DIR = '/kaggle/working/Mask_RCNN'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!git clone https://www.github.com/matterport/Mask_RCNN.git\nos.chdir('Mask_RCNN')\n!python setup.py -q install\nos.chdir('..')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip show mask-rcnn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport sys\nimport random\nimport math\nimport numpy as np\nimport skimage.io\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nsys.path.append(MASK_DIR) # To find local version\nfrom mrcnn import utils\nimport mrcnn.model as modellib\nfrom mrcnn import visualize\nfrom mrcnn.config import Config\n\n# Directory to save logs and trained model\nMODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n\n# Local path to trained weights file\nCOCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n# Download COCO trained weights from Releases if needed\nif not os.path.exists(COCO_MODEL_PATH):\n    utils.download_trained_weights(COCO_MODEL_PATH)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class InferenceConfig(Config):\n    # Set batch size to 1 since we'll be running inference on\n    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n    GPU_COUNT = 1\n    IMAGES_PER_GPU = 1\n    NAME = \"mas_segmentation\"\n    NUM_CLASSES = 1 + 80\n\nconfig = InferenceConfig()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create model object in inference mode.\nmodel = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n\n# Load weights trained on MS-COCO\nmodel.load_weights(COCO_MODEL_PATH, by_name=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# COCO Class names\n# Index of the class in the list is its ID. For example, to get ID of\n# the teddy bear class, use: class_names.index('teddy bear')\nclass_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n               'bus', 'train', 'truck', 'boat', 'traffic light',\n               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n               'teddy bear', 'hair drier', 'toothbrush']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calculate_areas(df, image_path, show_image=False): \n    head, filename = os.path.split(image_path)\n    image = skimage.io.imread(image_path)\n\n    # Run detection\n    results = model.detect([image], verbose=0)\n    r = results[0]\n    \n    if show_image:\n        # Visualize results\n        visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], class_names, r['scores'])\n\n    number_of_cats = int((r['class_ids'] == 16).sum())\n    number_of_dogs = int((r['class_ids'] == 17).sum())\n    \n    cat_area_percent, dog_area_percent = calculate_area_precent(r)\n    \n    new_row = pd.Series({\"imageId\": filename , \"gray_image\": 0, \"cats\": number_of_cats, \"dogs\": number_of_dogs, \"cat_percent\": cat_area_percent, \"dog_percent\": dog_area_percent})\n    return df.append(new_row, ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calculate_area_precent(result):\n\n    #mask as (x,y, number_of_objects)\n    mask = result['masks']\n    mask = mask.astype(int)\n    \n    cat_mask_index = np.where(result['class_ids'] == 16)[0]\n    dog_mask_index = np.where(result['class_ids'] == 17)[0]\n        \n    cat_area = 0\n    dog_area = 0\n    for i in cat_mask_index:\n        cat_area = cat_area + np.sum(mask[:,:,i])\n\n    for i in dog_mask_index:\n        dog_area = dog_area + np.sum(mask[:,:,i])\n\n    mask_size = mask.shape[0] * mask.shape[1]   \n\n    cat_area_percent = cat_area/mask_size\n    dog_area_percent = dog_area/mask_size\n    \n    return round(cat_area_percent,2), round(dog_area_percent,2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mark_gray_image(df, image_path): \n    head, filename = os.path.split(image_path)\n    new_row = pd.Series({\"imageId\": filename , \"gray_image\": 1, \"cats\":0, \"dogs\": 0, \"cat_percent\": 0, \"dog_percent\": 0})\n    return df.append(new_row, ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/petfinder-adoption-prediction/train/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_df = pd.read_csv(\"../input/rcnn-all-train-images-results/result.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Machine Learning Algorithm (MLA) Selection and Initialization\nMLA = [\n    #Ensemble Methods\n    ensemble.AdaBoostClassifier(),\n    ensemble.BaggingClassifier(),\n    ensemble.ExtraTreesClassifier(),\n    ensemble.GradientBoostingClassifier(),\n    ensemble.RandomForestClassifier(),\n    \n    #GLM\n    linear_model.LogisticRegressionCV(),\n    linear_model.PassiveAggressiveClassifier(),\n    linear_model.RidgeClassifierCV(),\n    linear_model.SGDClassifier(),\n    linear_model.Perceptron(),\n    \n    #Navies Bayes\n    naive_bayes.BernoulliNB(),\n    naive_bayes.GaussianNB(),\n    \n    #Nearest Neighbor\n    neighbors.KNeighborsClassifier(),\n    \n    #SVM\n    svm.LinearSVC(),\n    \n    #Trees    \n    tree.DecisionTreeClassifier(),\n    tree.ExtraTreeClassifier(),\n    \n    #Discriminant Analysis\n    discriminant_analysis.LinearDiscriminantAnalysis(),\n    discriminant_analysis.QuadraticDiscriminantAnalysis(),\n\n    #xgboost: \n    XGBClassifier(),\n    \n    #CatBoostClassifier(verbose=0)\n    ]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(data, MLA_list = MLA):\n    \n    target = data['AdoptionSpeed']\n    X_train = data.drop(['AdoptionSpeed'],axis=1)\n    \n    MLA_columns = ['MLA Name', 'MLA Parameters','MLA cohen_kappa_score','MLA Time']\n    MLA_compare = pd.DataFrame(columns = MLA_columns)\n\n    MLA_predict = data['AdoptionSpeed']\n    \n    row_index = 0\n    for alg in MLA_list:\n\n        MLA_name = alg.__class__.__name__\n        MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n        MLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n    \n        kf = StratifiedKFold(n_splits=5, shuffle=True)\n        kappa_score = make_scorer(cohen_kappa_score, weights='quadratic')\n        cv_results = model_selection.cross_validate(alg, X_train, target, cv  = kf, scoring=kappa_score, n_jobs = -1)\n        \n        MLA_compare.loc[row_index, 'MLA Time'] = cv_results['fit_time'].mean()\n        MLA_compare.loc[row_index, 'MLA cohen_kappa_score'] = cv_results['test_score'].mean() \n        MLA_compare.loc[row_index, 'algo'] = alg.__class__\n        \n        row_index+=1\n\n    MLA_compare.sort_values(by = ['MLA cohen_kappa_score'], ascending = False, inplace = True)\n    sns.barplot(x='MLA cohen_kappa_score', y = 'MLA Name', data = MLA_compare, color = 'b')\n    plt.title('Machine Learning Algorithm Accuracy Score \\n')\n    plt.xlabel('Accuracy Score (%)')\n    plt.ylabel('Algorithm')\n    \n    return MLA_compare","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier_performance = train_model(result_df.drop(['PetID'], axis=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier_performance","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = result_df.drop(['PetID', 'AdoptionSpeed'], axis=1)\ntarget = result_df['AdoptionSpeed']\n\nbest_classifier = classifier_performance.iloc[0][4]\n\nclassifier = best_classifier().fit(X_test, target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TEST_IMAGE_DIR = '../input/petfinder-adoption-prediction/test_images'\ntest_df = pd.read_csv(\"../input/petfinder-adoption-prediction/test/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pet_area_coverage=pd.DataFrame()\nfailed_images = []\ncounter = 0\nfor filename in os.listdir(TEST_IMAGE_DIR):\n    try: \n        counter = counter +1\n        if counter % 1000 == 0:\n            print(counter)\n        test_pet_area_coverage = calculate_areas(test_pet_area_coverage,os.path.join(TEST_IMAGE_DIR, filename))\n    except Exception:\n        failed_images.append(filename)\n        test_pet_area_coverage = mark_gray_image(test_pet_area_coverage,os.path.join(TEST_IMAGE_DIR, filename))\n        continue","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for img in failed_images:\n    print(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_image_segmentations(df, PetID):\n    #df = area cover df with imageId\n    matching_rows = df[df['imageId'].str.contains(PetID)]\n    count_row = matching_rows.shape[0]\n        \n    if count_row == 0:\n        # no images for this pet\n        return pd.Series()\n    \n    matching_rows['imageIndex'] = matching_rows.apply(lambda x: x['imageId'][x['imageId'].find('-')+1 :-4], axis=1)\n    matching_rows = matching_rows.sort_values('imageIndex')\n        \n    # add values from all images\n    pet_photo_values = pd.Series()\n    gray_images = 0\n    cat_count_max = 0\n    dog_count_max = 0\n    cat_count_mean = 0\n    dog_count_mean = 0\n    cat_percent_max = 0\n    dog_percent_max = 0\n    cat_percent_mean = 0\n    dog_percent_mean = 0\n    \n    for i, row in matching_rows.iterrows():\n        img_nr = row['imageIndex']\n        gray_images = gray_images + row['gray_image']\n        \n        if row['cats'] > cat_count_max:\n            cat_count_max = row['cats']\n        if row['dogs'] > dog_count_max:\n            dog_count_max = row['dogs']\n        \n        cat_count_mean = (cat_count_mean + row['cats'])/2\n        dog_count_mean = (dog_count_mean + row['dogs'])/2\n            \n        if row['cat_percent'] > cat_percent_max:\n            cat_percent_max = row['cat_percent']\n        if row['dog_percent'] > dog_percent_max:\n            dog_percent_max = row['dog_percent']\n        \n        cat_percent_mean = (cat_percent_mean + row['cat_percent'])/2\n        dog_percent_mean = (dog_percent_mean + row['dog_percent'])/2\n        \n    pet_photo_values = pet_photo_values.append(pd.Series([gray_images, cat_count_max, dog_count_max, cat_count_mean, dog_count_mean, cat_percent_max,\n                                                          dog_percent_max, cat_percent_mean, dog_percent_mean ],index = ['gray_images', 'cat_count_max', \n                                                                                                                         'dog_count_max', 'cat_count_mean', \n                                                                                                                         'dog_count_mean', 'cat_percent_max',\n                                                                                                                         'dog_percent_max', 'cat_percent_mean', \n                                                                                                                         'dog_percent_mean'] ))     \n    # return series of all values   \n    return pet_photo_values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_result_df=pd.DataFrame()\ntest_result_df['PetID']=test_df['PetID']\ntest_result_df = test_result_df.merge(test_result_df.PetID.apply(lambda x: add_image_segmentations(test_pet_area_coverage, x)), left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_result_df.fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_result_df.to_csv('test_result_df.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# unify column order\ntest_result_df = test_result_df[result_df.columns.drop('AdoptionSpeed')]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Small test with rsme"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = result_df.drop(['PetID'], axis=1)\nX_test = test_result_df.drop(['PetID'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_params = {\n    'eval_metric': 'rmse',\n    'seed': 1337,\n    'silent': 1,\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\n\ndef run_xgb(params, X_train, X_test):\n    n_splits = 5\n    verbose_eval = 1000\n    num_rounds = 100000\n    early_stop = 500\n\n    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=1337)\n\n    oof_train = np.zeros((X_train.shape[0]))\n    oof_test = np.zeros((X_test.shape[0], n_splits))\n\n    i = 0\n\n    for train_idx, valid_idx in kf.split(X_train, X_train['AdoptionSpeed'].values):\n\n        X_tr = X_train.iloc[train_idx, :]\n        X_val = X_train.iloc[valid_idx, :]\n\n        y_tr = X_tr['AdoptionSpeed'].values\n        X_tr = X_tr.drop(['AdoptionSpeed'], axis=1)\n\n        y_val = X_val['AdoptionSpeed'].values\n        X_val = X_val.drop(['AdoptionSpeed'], axis=1)\n\n        d_train = xgb.DMatrix(data=X_tr, label=y_tr, feature_names=X_tr.columns)\n        d_valid = xgb.DMatrix(data=X_val, label=y_val, feature_names=X_val.columns)\n\n        watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n        model = xgb.train(dtrain=d_train, num_boost_round=num_rounds, evals=watchlist,\n                         early_stopping_rounds=early_stop, verbose_eval=verbose_eval, params=params)\n\n        valid_pred = model.predict(xgb.DMatrix(X_val, feature_names=X_val.columns), ntree_limit=model.best_ntree_limit)\n        test_pred = model.predict(xgb.DMatrix(X_test, feature_names=X_test.columns), ntree_limit=model.best_ntree_limit)\n\n        oof_train[valid_idx] = valid_pred\n        oof_test[:, i] = test_pred\n\n        i += 1\n    return model, oof_train, oof_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model, oof_train, oof_test = run_xgb(xgb_params, X_train, X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from https://www.kaggle.com/naveenasaithambi/optimizedrounder-improved\n\nimport scipy as sp\n\nfrom collections import Counter\nfrom functools import partial\nfrom math import sqrt\n\nfrom sklearn.metrics import cohen_kappa_score, mean_squared_error\nfrom sklearn.metrics import confusion_matrix as sk_cmatrix\n\n\n# FROM: https://www.kaggle.com/myltykritik/simple-lgbm-image-features\n\n# The following 3 functions have been taken from Ben Hamner's github repository\n# https://github.com/benhamner/Metrics\ndef confusion_matrix(rater_a, rater_b, min_rating=None, max_rating=None):\n    \"\"\"\n    Returns the confusion matrix between rater's ratings\n    \"\"\"\n    assert(len(rater_a) == len(rater_b))\n    if min_rating is None:\n        min_rating = min(rater_a + rater_b)\n    if max_rating is None:\n        max_rating = max(rater_a + rater_b)\n    num_ratings = int(max_rating - min_rating + 1)\n    conf_mat = [[0 for i in range(num_ratings)]\n                for j in range(num_ratings)]\n    for a, b in zip(rater_a, rater_b):\n        conf_mat[a - min_rating][b - min_rating] += 1\n    return conf_mat\n\n\ndef histogram(ratings, min_rating=None, max_rating=None):\n    \"\"\"\n    Returns the counts of each type of rating that a rater made\n    \"\"\"\n    if min_rating is None:\n        min_rating = min(ratings)\n    if max_rating is None:\n        max_rating = max(ratings)\n    num_ratings = int(max_rating - min_rating + 1)\n    hist_ratings = [0 for x in range(num_ratings)]\n    for r in ratings:\n        hist_ratings[r - min_rating] += 1\n    return hist_ratings\n\n\ndef quadratic_weighted_kappa(y, y_pred):\n    \"\"\"\n    Calculates the quadratic weighted kappa\n    axquadratic_weighted_kappa calculates the quadratic weighted kappa\n    value, which is a measure of inter-rater agreement between two raters\n    that provide discrete numeric ratings.  Potential values range from -1\n    (representing complete disagreement) to 1 (representing complete\n    agreement).  A kappa value of 0 is expected if all agreement is due to\n    chance.\n    quadratic_weighted_kappa(rater_a, rater_b), where rater_a and rater_b\n    each correspond to a list of integer ratings.  These lists must have the\n    same length.\n    The ratings should be integers, and it is assumed that they contain\n    the complete range of possible ratings.\n    quadratic_weighted_kappa(X, min_rating, max_rating), where min_rating\n    is the minimum possible rating, and max_rating is the maximum possible\n    rating\n    \"\"\"\n    rater_a = y\n    rater_b = y_pred\n    min_rating=None\n    max_rating=None\n    rater_a = np.array(rater_a, dtype=int)\n    rater_b = np.array(rater_b, dtype=int)\n    assert(len(rater_a) == len(rater_b))\n    if min_rating is None:\n        min_rating = min(min(rater_a), min(rater_b))\n    if max_rating is None:\n        max_rating = max(max(rater_a), max(rater_b))\n    conf_mat = confusion_matrix(rater_a, rater_b,\n                                min_rating, max_rating)\n    num_ratings = len(conf_mat)\n    num_scored_items = float(len(rater_a))\n\n    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n\n    numerator = 0.0\n    denominator = 0.0\n\n    for i in range(num_ratings):\n        for j in range(num_ratings):\n            expected_count = (hist_rater_a[i] * hist_rater_b[j]\n                              / num_scored_items)\n            d = pow(i - j, 2.0) / pow(num_ratings - 1, 2.0)\n            numerator += d * conf_mat[i][j] / num_scored_items\n            denominator += d * expected_count / num_scored_items\n\n    return (1.0 - numerator / denominator)\n\nclass OptimizedRounder(object):\n    def __init__(self):\n        self.coef_ = 0\n    \n    def _kappa_loss(self, coef, X, y):\n        preds = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3, 4])\n        return -cohen_kappa_score(y, preds, weights='quadratic')\n    \n    def fit(self, X, y):\n        loss_partial = partial(self._kappa_loss, X = X, y = y)\n        initial_coef = [0.5, 1.5, 2.5, 3.5]\n        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n    \n    def predict(self, X, coef):\n        preds = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3, 4])\n        return preds\n    \n    def coefficients(self):\n        return self.coef_['x']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optR = OptimizedRounder()\noptR.fit(oof_train, X_train['AdoptionSpeed'].values)\ncoefficients = optR.coefficients()\nprint(coefficients)\nvalid_pred = optR.predict(oof_train, coefficients)\nqwk = quadratic_weighted_kappa(X_train['AdoptionSpeed'].values, valid_pred)\nprint(\"QWK = \", qwk)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"coefficients_ = coefficients.copy()\n#coefficients_[0] = 1.65\ntrain_predictions = optR.predict(oof_train, coefficients_).astype(np.int8)\ntest_predictions = optR.predict(oof_test.mean(axis=1), coefficients_).astype(np.int8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({'PetID': test_result_df['PetID'].values, 'AdoptionSpeed': test_predictions})\nsubmission.to_csv('submission_opt.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit=pd.DataFrame()\nsubmit['PetID']=test_result_df['PetID']\nsubmit['AdoptionSpeed']=classifier.predict(test_result_df.drop(['PetID'], axis=1))\nsubmit['AdoptionSpeed']=submit['AdoptionSpeed'].astype(int)\nsubmit.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import shutil\nshutil.rmtree(MASK_DIR)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}