{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#libraries\nimport numpy as np \nimport pandas as pd \nimport os\nimport json\nimport seaborn as sns \nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.style.use('ggplot')\nimport lightgbm as lgb\nimport xgboost as xgb\nimport time\nimport datetime\nfrom PIL import Image\nfrom wordcloud import WordCloud\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold, KFold\nfrom sklearn.metrics import mean_squared_error, roc_auc_score\nfrom sklearn.linear_model import LogisticRegression, LogisticRegressionCV\nimport gc\nfrom catboost import CatBoostClassifier\nfrom tqdm import tqdm_notebook\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport random\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom functools import partial\npd.set_option('max_colwidth', 500)\npd.set_option('max_columns', 500)\npd.set_option('max_rows', 100)\nimport os\nimport scipy as sp\nfrom math import sqrt\nfrom collections import Counter\nfrom sklearn.metrics import confusion_matrix as sk_cmatrix\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom nltk.tokenize import TweetTokenizer\nfrom sklearn.ensemble import RandomForestClassifier\nimport langdetect\nimport eli5\nfrom IPython.display import display \n\nfrom sklearn.metrics import cohen_kappa_score\ndef kappa(y_true, y_pred):\n    return cohen_kappa_score(y_true, y_pred, weights='quadratic')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1.EDA"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"breeds = pd.read_csv('../input/petfinder-adoption-prediction/breed_labels.csv')\ncolors = pd.read_csv('../input/petfinder-adoption-prediction/color_labels.csv')\nstates = pd.read_csv('../input/petfinder-adoption-prediction/state_labels.csv')\n\ntrain = pd.read_csv('../input/petfinder-adoption-prediction/train/train.csv')\ntest = pd.read_csv('../input/petfinder-adoption-prediction/test/test.csv')\nsub = pd.read_csv('../input/petfinder-adoption-prediction/test/sample_submission.csv')\n\ntrain['dataset_type'] = 'train'\ntest['dataset_type'] = 'test'\nall_data = pd.concat([train, test])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop('Description', axis=1).head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.drop('Description', axis=1).head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(colors.shape)\ncolors","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(breeds.shape)\nbreeds.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(states.shape)\nstates.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" ## 1.1.Target: Adoption speed\n\n* 0 - Pet was adopted on the same day as it was listed.\n* 1 - Pet was adopted between 1 and 7 days (1st week) after being listed.\n* 2 - Pet was adopted between 8 and 30 days (1st month) after being listed.\n* 3 - Pet was adopted between 31 and 90 days (2nd & 3rd month) after being listed.\n* 4 - No adoption after 100 days of being listed. (There are no pets in this dataset that waited between 90 and 100 days). "},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_target(x, data, hue, title, alldata = False): \n# Plot count and rate in dataset\n    fig, axes = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(22, 8))\n\n    # Plot count number of target in dataset\n    g = sns.countplot(x=x, data=data, hue = hue, ax=axes[0]);\n    g.set_title(f'Count number of {title}');\n    g.set_xlabel(f'{title} Type')\n    ax_g=g.axes\n    for p in ax_g.patches:\n        ax_g.annotate(f'{p.get_height()}',\n                    xy=(p.get_x() + p.get_width() / 2, p.get_height()),\n                    xytext=(0, 3),  \n                    textcoords=\"offset points\",\n                    color = 'black',\n                    ha='center', va='bottom')\n    \n    # Plot rate of target in dataset    \n    k = sns.countplot(x=x, data=data,hue = hue, ax=axes[1]);\n    k.set_title(f'Rate of {title}');\n    k.set_xlabel(f'{title} Type')\n    k.set_ylabel('Rate')\n    ax_k=k.axes\n    \n    if alldata == True:\n        # Annotate train set and test set seperately\n        i = 0\n        for p in ax_k.patches:\n            y_value = p.get_height()\n            if i%2 == 0:\n                y_value = y_value/train.shape[0]*100\n            else:\n                y_value = y_value/test.shape[0]*100   \n            ax_k.annotate(f\"{y_value:.2f}%\", \n                        xy= (p.get_x() + p.get_width() / 2., p.get_height()),\n                        xytext=(0, 3),  \n                        textcoords=\"offset points\",\n                        color = 'black',\n                        ha='center', va='bottom')\n            i += 1\n    \n    if alldata == False:\n        for p in ax_k.patches:\n            y_value = p.get_height() * 100 / data.shape[0]\n            ax_k.annotate(f\"{y_value:.2f}%\", \n                        xy= (p.get_x() + p.get_width() / 2., p.get_height()),\n                        xytext=(0, 3),  \n                        textcoords=\"offset points\",\n                        color = 'black',\n                        ha='center', va='bottom')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_target(x='AdoptionSpeed', data=all_data.loc[all_data['dataset_type'] == 'train'], hue = None,title='Adoption Speed')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.2 Target: Type\n* 1 - Dog\n* 2 - Cat"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Change data type to dog, cat\nall_data['Type'] = all_data['Type'].apply(lambda x: 'Dog' if x == 1 else 'Cat')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_target(x='dataset_type', data=all_data, hue = 'Type',title='Cat and Dog', alldata= True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###  * Comparision adoption speed of dog and cat in training set ( test set doesn't exsit adoptionspeed column)"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_target(x='Type', data=all_data.loc[all_data['dataset_type'] == 'train'],hue = \"AdoptionSpeed\",title='Cat and Dog')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### For self comaprison the number of cat type and dog type in trainning set"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize dog and cat in all train data\nfig, axes = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(22, 8))\n\n# Plot number of cat and dog in traing set\ng = sns.countplot(x='Type', data=all_data.loc[all_data['dataset_type'] == 'train'], hue='AdoptionSpeed', ax=axes[0]);\ng.set_title('Number of cats and dogs adoption speed in train data');\nax_g=g.axes\nfor p in ax_g.patches:\n    ax_g.annotate(f'{p.get_height()}',\n                    xy=(p.get_x() + p.get_width() / 2, p.get_height()),\n                    xytext=(0, 3),  \n                    textcoords=\"offset points\",\n                    color = 'black',\n                    ha='center', va='bottom')\n\n# Plot rate of cat and dog in training set\nk = sns.countplot(x='Type', data=all_data.loc[all_data['dataset_type'] == 'train'], hue='AdoptionSpeed', ax=axes[1]);\nk.set_title('Rate [%] cats and dogs adoption speed in train data')\nk.set_ylabel('rate')\nax_k=k.axes\ni=0\nfor p in ax_k.patches:\n    y_value = p.get_height()\n    if i%2 == 0:\n        y_value = y_value/train.loc[train['Type']==2].shape[0]*100\n    else:\n        y_value = y_value/train.loc[train['Type']==1].shape[0]*100 \n    ax_k.annotate(\"{:.2f}%\".format(y_value), \n                xy= (p.get_x() + p.get_width() / 2., p.get_height()),\n                xytext=(0, 3),  \n                textcoords=\"offset points\",\n                color = 'black',\n                ha='center', va='bottom')\n    i +=1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.3 Target: Name"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (22, 8))\nplt.subplot(1, 2, 1)\ntext_cat = ' '.join(all_data.loc[all_data['Type'] == 'Cat', 'Name'].fillna('').values)\nwordcloud = WordCloud(max_font_size=None, background_color='white',\n                      width=1200, height=1000).generate(text_cat)\nplt.imshow(wordcloud)\nplt.title('Top cat names')\nplt.axis(\"off\")\n\nplt.subplot(1, 2, 2)\ntext_dog = ' '.join(all_data.loc[all_data['Type'] == 'Dog', 'Name'].fillna('').values)\nwordcloud = WordCloud(max_font_size=None, background_color='white',\n                      width=1200, height=1000).generate(text_dog)\nplt.imshow(wordcloud)\nplt.title('Top dog names')\nplt.axis(\"off\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" ### * Count number of unnamed pets in all data set"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Name'] = train['Name'].fillna('Unnamed')\ntest['Name'] = test['Name'].fillna('Unnamed')\nall_data['Name'] = all_data['Name'].fillna('Unnamed')\n\ntrain['No_name'] = 0\ntrain.loc[train['Name'] == 'Unnamed', 'No_name'] = 1\ntest['No_name'] = 0\ntest.loc[test['Name'] == 'Unnamed', 'No_name'] = 1\nall_data['No_name'] = 0\nall_data.loc[all_data['Name'] == 'Unnamed', 'No_name'] = 1\n\nprint(f\"Rate of unnamed pets in train data: {train['No_name'].sum() * 100 / train['No_name'].shape[0]:.4f}%.\")\nprint(f\"Rate of unnamed pets in test data: {test['No_name'].sum() * 100 / test['No_name'].shape[0]:.4f}%.\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(train['No_name'], train['AdoptionSpeed'], normalize='index')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Less than 10% of pets don't have names, but they have a higher possibility of not being adopted."},{"metadata":{},"cell_type":"markdown","source":"### 1.4 Target: Age"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (22, 8))\nplt.subplot(1, 2, 1)\nplt.title('Distribution of pets age');\ntrain['Age'].plot('hist', label='train');\ntest['Age'].plot('hist', label='test');\nplt.legend()\nplt.xlabel('Days');\n\nplt.subplot(1, 2, 2)\nplt.title('Distribution of pets age (log)');\nnp.log1p(train['Age']).plot('hist', label='train');\nnp.log1p(test['Age']).plot('hist', label='test');\nplt.legend()\nplt.xlabel('Log(days)');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that most pets are young - maybe after the birth. Also there a lot of pets with an age equal to multiples of 12 - I think than owners didn't bother with the exact age."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(22, 8));\nsns.violinplot(x=\"AdoptionSpeed\", y=\"Age\", hue=\"Type\", data=train);\nplt.title('AdoptionSpeed by Type and age');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = []\nfor a in range(5):\n    df = train.loc[train['AdoptionSpeed'] == a]\n\n    data.append(go.Scatter(\n        x = df['Age'].value_counts().sort_index().index,\n        y = df['Age'].value_counts().sort_index().values,\n        name = str(a)\n    ))\n    \nlayout = go.Layout(dict(title = \"AdoptionSpeed trends by Age\",\n                  xaxis = dict(title = 'Age (days)'),\n                  yaxis = dict(title = 'Counts'),\n                  )\n                  )\npy.iplot(dict(data=data, layout=layout), filename='basic-line')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.5 Target: Breeds"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Pure_breed'] = 0\ntrain.loc[train['Breed2'] == 0, 'Pure_breed'] = 1\ntest['Pure_breed'] = 0\ntest.loc[test['Breed2'] == 0, 'Pure_breed'] = 1\nall_data['Pure_breed'] = 0\nall_data.loc[all_data['Breed2'] == 0, 'Pure_breed'] = 1\n\nprint(f\"Rate of pure breed pets in train data: {train['Pure_breed'].sum() * 100 / train['Pure_breed'].shape[0]:.4f}%.\")\nprint(f\"Rate of pure breed pets in test data: {test['Pure_breed'].sum() * 100 / test['Pure_breed'].shape[0]:.4f}%.\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_target(x='Pure_breed', data=all_data.loc[all_data['dataset_type'] == 'train'],hue = \"AdoptionSpeed\",title='Pure_breed vs AdoptionSpeed')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_target(x='dataset_type', data=all_data,hue = \"Pure_breed\",title='Pure_breed', alldata=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_target(x='Pure_breed', data=train.loc[train['Type'] == 1],hue = \"AdoptionSpeed\",title='pure_breed for dog')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_target(x='Pure_breed', data=train.loc[train['Type'] == 2],hue = \"AdoptionSpeed\",title='pure_breed for cat')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems that non-pure breed pets tend to be adopted more and faster, especially cats.\n\nLet's look at the breeds themselves"},{"metadata":{"trusted":true},"cell_type":"code","source":"breeds_dict = {k: v for k, v in zip(breeds['BreedID'], breeds['BreedName'])}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Breed1_name'] = train['Breed1'].apply(lambda x: '_'.join(breeds_dict[x].split()) if x in breeds_dict else 'Unknown')\ntrain['Breed2_name'] = train['Breed2'].apply(lambda x: '_'.join(breeds_dict[x]) if x in breeds_dict else '-')\n\ntest['Breed1_name'] = test['Breed1'].apply(lambda x: '_'.join(breeds_dict[x].split()) if x in breeds_dict else 'Unknown')\ntest['Breed2_name'] = test['Breed2'].apply(lambda x: '_'.join(breeds_dict[x].split()) if x in breeds_dict else '-')\n\nall_data['Breed1_name'] = all_data['Breed1'].apply(lambda x: '_'.join(breeds_dict[x].split()) if x in breeds_dict else 'Unknown')\nall_data['Breed2_name'] = all_data['Breed2'].apply(lambda x: '_'.join(breeds_dict[x].split()) if x in breeds_dict else '-')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (20, 18))\nplt.subplot(2, 2, 1)\ntext_cat1 = ' '.join(all_data.loc[all_data['Type'] == 'Cat', 'Breed1_name'].fillna('').values)\nwordcloud = WordCloud(max_font_size=None, background_color='black', collocations=False,\n                      width=1200, height=1000).generate(text_cat1)\nplt.imshow(wordcloud)\nplt.title('Top cat breed1')\nplt.axis(\"off\")\n\nplt.subplot(2, 2, 2)\ntext_dog1 = ' '.join(all_data.loc[all_data['Type'] == 'Dog', 'Breed1_name'].fillna('').values)\nwordcloud = WordCloud(max_font_size=None, background_color='black', collocations=False,\n                      width=1200, height=1000).generate(text_dog1)\nplt.imshow(wordcloud)\nplt.title('Top dog breed1')\nplt.axis(\"off\")\n\nplt.subplot(2, 2, 3)\ntext_cat2 = ' '.join(all_data.loc[all_data['Type'] == 'Cat', 'Breed2_name'].fillna('').values)\nwordcloud = WordCloud(max_font_size=None, background_color='black', collocations=False,\n                      width=1200, height=1000).generate(text_cat2)\nplt.imshow(wordcloud)\nplt.title('Top cat breed1')\nplt.axis(\"off\")\n\nplt.subplot(2, 2, 4)\ntext_dog2 = ' '.join(all_data.loc[all_data['Type'] == 'Dog', 'Breed2_name'].fillna('').values)\nwordcloud = WordCloud(max_font_size=None, background_color='black', collocations=False,\n                      width=1200, height=1000).generate(text_dog2)\nplt.imshow(wordcloud)\nplt.title('Top dog breed2')\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(all_data['Breed1_name'] + '__' + all_data['Breed2_name']).value_counts().head(15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems that most dogs aren't pure breeds, but mixed breeds! \n\nSometimes people write \"mixed breed\" in the first fiels, sometimes in both, and sometimes main breed is in the first field and is marked as mixed breed in the second field.\n\nI think we can create new features based on this information. "},{"metadata":{},"cell_type":"markdown","source":"### 1.6 Target: Gender\n 1 = Male, 2 = Female, 3 = Mixed, if profile represents group of pets"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_overview(x,data,hue,title):\n    plot_target(x=x, data=data, hue = hue, title = title)\n    plot_target(x='dataset_type', data=all_data ,hue = x,title='dataset_type', alldata= True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_overview(x='Gender', data=train,hue = \"AdoptionSpeed\",title='Gender')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.factorplot('Type', col='Gender', data=all_data, kind='count', hue='dataset_type');\nplt.subplots_adjust(top=.8)\nplt.suptitle('Count of cats and dogs in train and test set by gender');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems that female pets are adopted faster than male. Having no information about the gender really decreases chances."},{"metadata":{},"cell_type":"markdown","source":"### 1.7 Target: Color"},{"metadata":{"trusted":true},"cell_type":"code","source":"colors_dict = {k: v for k, v in zip(colors['ColorID'], colors['ColorName'])}\ntrain['Color1_name'] = train['Color1'].apply(lambda x: colors_dict[x] if x in colors_dict else '')\ntrain['Color2_name'] = train['Color2'].apply(lambda x: colors_dict[x] if x in colors_dict else '')\ntrain['Color3_name'] = train['Color3'].apply(lambda x: colors_dict[x] if x in colors_dict else '')\n\ntest['Color1_name'] = test['Color1'].apply(lambda x: colors_dict[x] if x in colors_dict else '')\ntest['Color2_name'] = test['Color2'].apply(lambda x: colors_dict[x] if x in colors_dict else '')\ntest['Color3_name'] = test['Color3'].apply(lambda x: colors_dict[x] if x in colors_dict else '')\n\nall_data['Color1_name'] = all_data['Color1'].apply(lambda x: colors_dict[x] if x in colors_dict else '')\nall_data['Color2_name'] = all_data['Color2'].apply(lambda x: colors_dict[x] if x in colors_dict else '')\nall_data['Color3_name'] = all_data['Color3'].apply(lambda x: colors_dict[x] if x in colors_dict else '')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_factor_plot(df, x, col, title, hue=None, ann=True, col_wrap=4):\n    \"\"\"\n    Plotting countplot.\n    Making annotations is a bit more complicated, because we need to iterate over axes.\n    \"\"\"\n    if hue:\n        g = sns.factorplot(col, col=x, data=df, kind='count', col_wrap=col_wrap, hue=hue);\n    else:\n        g = sns.factorplot(col, col=x, data=df, kind='count', col_wrap=col_wrap);\n    plt.subplots_adjust(top=0.9);\n    plt.suptitle(title);\n    ax = g.axes\n    if ann:\n        for a in ax:\n            for p in a.patches:\n                a.annotate(p.get_height(), (p.get_x() + p.get_width() / 2., p.get_height()),\n                     ha='center', va='center', fontsize=11, rotation=0, xytext=(0, 10),\n                     textcoords='offset points') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.factorplot('dataset_type', col='Type', data=all_data, kind=\"count\", hue='Color1_name',palette=['Black', 'Brown', '#FFFDD0', 'Gray', 'Gold', 'White', 'Yellow'],size=6);\nplt.subplots_adjust(top=0.9)\nplt.suptitle('Counts of pets in datasets by main color');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" make_factor_plot(df=train, x='Color1_name', col='AdoptionSpeed', title='Counts of pets by main color and Adoption Speed')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['full_color'] = (train['Color1_name'] + '__' + train['Color2_name'] + '__' + train['Color3_name']).str.replace('__', '')\ntest['full_color'] = (test['Color1_name'] + '__' + test['Color2_name'] + '__' + test['Color3_name']).str.replace('__', '')\nall_data['full_color'] = (all_data['Color1_name'] + '__' + all_data['Color2_name'] + '__' + all_data['Color3_name']).str.replace('__', '')\n\nmake_factor_plot(df=train.loc[train['full_color'].isin(list(train['full_color'].value_counts().index)[:12])], x='full_color', col='AdoptionSpeed', title='Counts of pets by color and Adoption Speed')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that there are some differences based on color, but the number of pets in most colors isn't very high, so this could be due to randomness."},{"metadata":{"trusted":true},"cell_type":"code","source":"gender_dict = {1: 'Male', 2: 'Female', 3: 'Mixed'}\nfor i in all_data['Type'].unique():\n    for j in all_data['Gender'].unique():\n        df = all_data.loc[(all_data['Type'] == i) & (all_data['Gender'] == j)]\n        top_colors = list(df['full_color'].value_counts().index)[:5]\n        j = gender_dict[j]\n        print(f\"Most popular colors of {j} {i}s: {' '.join(top_colors)}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.8 Target: MatiritySize\nSize at maturity (1 = Small, 2 = Medium, 3 = Large, 4 = Extra Large, 0 = Not Specified)"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_overview(x='MaturitySize', data=train,hue = \"AdoptionSpeed\",title='MaturitySize')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"make_factor_plot(df=all_data, x='MaturitySize', col='Type', title='Count of cats and dogs in train and test set by MaturitySize', hue='dataset_type', ann=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images = [i.split('-')[0] for i in os.listdir('../input/petfinder-adoption-prediction/train_images/')]\nsize_dict = {1: 'Small', 2: 'Medium', 3: 'Large', 4: 'Extra Large'}\nfor t in all_data['Type'].unique():\n    for m in all_data['MaturitySize'].unique():\n        df = all_data.loc[(all_data['Type'] == t) & (all_data['MaturitySize'] == m)]\n        top_breeds = list(df['Breed1_name'].value_counts().index)[:5]\n        m = size_dict[m]\n        print(f\"Most common Breeds of {m} {t}s:\")\n        \n        fig = plt.figure(figsize=(25, 4))\n        \n        for i, breed in enumerate(top_breeds):\n            # excluding pets without pictures\n            b_df = df.loc[(df['Breed1_name'] == breed) & (df['PetID'].isin(images)), 'PetID']\n            if len(b_df) > 1:\n                pet_id = b_df.values[1]\n            else:\n                pet_id = b_df.values[0]\n            ax = fig.add_subplot(1, 5, i+1, xticks=[], yticks=[])\n\n            im = Image.open(\"../input/petfinder-adoption-prediction/train_images/\" + pet_id + '-1.jpg')\n            plt.imshow(im)\n            ax.set_title(f'Breed: {breed}')\n        plt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Quite interesting:\n* We can see that maturity size isn't very important. Medium sized pets are most common and they have slightly more chances to be not adopted;\n* There are almost no Extra Large pets. I hope it means that their owners like them and there is no need for them to be adopted :)\n* I wanted to gave a look at different pets, so I showed examples of pictures of most common breeds for each maturity size of cats and dogs;\n* I think not all data is entirely correct: sometimes short haired cats have breed with \"medium hair\", not sure that all breeds are entirely correct. Some photoes have bad quality;"},{"metadata":{},"cell_type":"markdown","source":"### 1.8 FurLength\n\n (1 = Short, 2 = Medium, 3 = Long, 0 = Not Specified)"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_overview(x='FurLength', data=train,hue = \"AdoptionSpeed\",title='FurLength')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (20, 18))\nplt.subplot(2, 2, 1)\ntext_cat1 = ' '.join(all_data.loc[(all_data['FurLength'] == 1) & (all_data['Type'] == 'Cat'), 'Breed1_name'].fillna('').values)\nwordcloud = WordCloud(max_font_size=None, background_color='white', collocations=False,\n                      width=1200, height=1000).generate(text_cat1)\nplt.imshow(wordcloud)\nplt.title('Top cat breed1 with short fur')\nplt.axis(\"off\")\n\nplt.subplot(2, 2, 2)\ntext_dog1 = ' '.join(all_data.loc[(all_data['FurLength'] == 1) & (all_data['Type'] == 'Dog'), 'Breed1_name'].fillna('').values)\nwordcloud = WordCloud(max_font_size=None, background_color='white', collocations=False,\n                      width=1200, height=1000).generate(text_dog1)\nplt.imshow(wordcloud)\nplt.title('Top dog breed1 with short fur')\nplt.axis(\"off\")\n\nplt.subplot(2, 2, 3)\ntext_cat2 = ' '.join(all_data.loc[(all_data['FurLength'] == 2) & (all_data['Type'] == 'Cat'), 'Breed1_name'].fillna('').values)\nwordcloud = WordCloud(max_font_size=None, background_color='white', collocations=False,\n                      width=1200, height=1000).generate(text_cat2)\nplt.imshow(wordcloud)\nplt.title('Top cat breed1 with medium fur')\nplt.axis(\"off\")\n\nplt.subplot(2, 2, 4)\ntext_dog2 = ' '.join(all_data.loc[(all_data['FurLength'] == 2) & (all_data['Type'] == 'Dog'), 'Breed1_name'].fillna('').values)\nwordcloud = WordCloud(max_font_size=None, background_color='white', collocations=False,\n                      width=1200, height=1000).generate(text_dog2)\nplt.imshow(wordcloud)\nplt.title('Top dog breed2 with medium fur')\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c = 0\nstrange_pets = []\nfor i, row in all_data[all_data['Breed1_name'].str.contains('air')].iterrows():\n    if 'Short' in row['Breed1_name'] and row['FurLength'] == 1:\n        pass\n    elif 'Medium' in row['Breed1_name'] and row['FurLength'] == 2:\n        pass\n    elif 'Long' in row['Breed1_name'] and row['FurLength'] == 3:\n        pass\n    else:\n        c += 1\n        strange_pets.append((row['PetID'], row['Breed1_name'], row['FurLength']))\n        \nprint(f\"There are {c} pets whose breed and fur length don't match\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e6564e8ec0301db1b3e43d228eaae6b578a64c9c"},"cell_type":"markdown","source":"It seems that almost one thousand pets have mismatch in breeds and fur lengths. Let's see!"},{"metadata":{"trusted":true},"cell_type":"code","source":"strange_pets = [p for p in strange_pets if p[0] in images]\nfig = plt.figure(figsize=(25, 12))\nfur_dict = {1: 'Short', 2: 'Medium', 3: 'long'}\nfor i, s in enumerate(random.sample(strange_pets, 12)):\n    ax = fig.add_subplot(3, 4, i+1, xticks=[], yticks=[])\n\n    im = Image.open(\"../input/petfinder-adoption-prediction/train_images/\" + s[0] + '-1.jpg')\n    plt.imshow(im)\n    ax.set_title(f'Breed: {s[1]} \\n Fur length: {fur_dict[s[2]]}')\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"348e99f3ba2817ff981e1a21ee7d491089ec5fd0"},"cell_type":"markdown","source":"Everybody lies!\n\nSometimes breed is more correct, sometimes fur length... I suppose we could create a feature showing whether breed and fur length match."},{"metadata":{},"cell_type":"markdown","source":"### 1.9 Target: Health\n\nThere are four features showing health of the pets:\n\n* Vaccinated - Pet has been vaccinated (1 = Yes, 2 = No, 3 = Not Sure)\n* Dewormed - Pet has been dewormed (1 = Yes, 2 = No, 3 = Not Sure)\n* Sterilized - Pet has been spayed / neutered (1 = Yes, 2 = No, 3 = Not Sure)\n* Health - Health Condition (1 = Healthy, 2 = Minor Injury, 3 = Serious Injury, 0 = Not Specified)\n\nI think that these features are very important - most people would prefer a healthy pet. While sterilization isn't the main concern, having healty and dewormed pet should have a great importance. Let's see whether I'm right!"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_target(data=train, x='Vaccinated', title='Vaccinated', hue='AdoptionSpeed')\nplt.xticks([0, 1, 2], ['Yes', 'No', 'Not sure']);\nplt.title('AdoptionSpeed and Vaccinated');\n\nplot_target(data=train, x='Sterilized', title='Sterilized', hue='AdoptionSpeed')\nplt.xticks([0, 1, 2], ['Yes', 'No', 'Not sure']);\nplt.title('AdoptionSpeed and Sterilized');\n\nplot_target(data=train, x='Health', title='Health', hue='AdoptionSpeed')\nplt.xticks([0, 1, 2], ['Healthy', 'Minor Injury', 'Serious Injury']);\nplt.title('AdoptionSpeed and Health');\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['health'] = train['Vaccinated'].astype(str) + '_' + train['Dewormed'].astype(str) + '_' + train['Sterilized'].astype(str) + '_' + train['Health'].astype(str)\ntest['health'] = test['Vaccinated'].astype(str) + '_' + test['Dewormed'].astype(str) + '_' + test['Sterilized'].astype(str) + '_' + test['Health'].astype(str)\n\n\nmake_factor_plot(df=train.loc[train['health'].isin(list(train.health.value_counts().index[:5]))], x='health', col='AdoptionSpeed', title='Counts of pets by main health conditions and Adoption Speed')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Healthy, dewormed and non-sterilized pets tend to be adopted faster!\n* Completely healthy pets are... more likely to be not adopted! I suppose that means that a lot of people pay attention to other characteristics;\n* And healthy pets with no information (not sure value) also tend to be adopted less frequently. Maybe people prefer having information, even if it is negative;"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20, 16))\nplt.subplot(3, 2, 1)\nsns.violinplot(x=\"AdoptionSpeed\", y=\"Age\", data=train);\nplt.title('Age distribution by Age');\nplt.subplot(3, 2, 3)\nsns.violinplot(x=\"AdoptionSpeed\", y=\"Age\", hue=\"Vaccinated\", data=train);\nplt.title('Age distribution by Age and Vaccinated');\nplt.subplot(3, 2, 4)\nsns.violinplot(x=\"AdoptionSpeed\", y=\"Age\", hue=\"Dewormed\", data=train);\nplt.title('Age distribution by Age and Dewormed');\nplt.subplot(3, 2, 5)\nsns.violinplot(x=\"AdoptionSpeed\", y=\"Age\", hue=\"Sterilized\", data=train);\nplt.title('Age distribution by Age and Sterilized');\nplt.subplot(3, 2, 6)\nsns.violinplot(x=\"AdoptionSpeed\", y=\"Age\", hue=\"Health\", data=train);\nplt.title('Age distribution by Age and Health');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.10 Target: Fee"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Free'] = train['Fee'].apply(lambda x: 'Free' if x == 0 else 'Not Free')\ntest['Free'] = test['Fee'].apply(lambda x: 'Free' if x == 0 else 'Not Free')\nall_data['Free'] = all_data['Fee'].apply(lambda x: 'Free' if x == 0 else 'Not Free')\nplot_overview(x='Free', title='Number of pets by Free in train and test data', hue = 'AdoptionSpeed', data = train)\nplot_target(x='Free', title = 'Dog', data= train.loc[train['Type']==1], hue = 'AdoptionSpeed')\nplot_target(x='Free', title = 'Cat', data= train.loc[train['Type']==2], hue = 'AdoptionSpeed')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16, 6));\nplt.subplot(1, 2, 1)\nplt.hist(train.loc[train['Fee'] < 400, 'Fee']);\nplt.title('Distribution of fees lower than 400');\n\nplt.subplot(1, 2, 2)\nsns.violinplot(x=\"AdoptionSpeed\", y=\"Fee\", hue=\"Type\", data=train);\nplt.title('AdoptionSpeed by Type and Fee');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* It is interesting that pets with high fee tend to be adopted quite fast! Maybe people prefer to pay for \"better\" pets: healthy, trained and so on;\n* Most pets are given for free and fees are usually lower than 100 $;\n* Fees for dogs tend to be higher, though these are rare cases anyway."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16, 10));\nsns.scatterplot(x=\"Fee\", y=\"Quantity\", hue=\"Type\",data=all_data);\nplt.title('Quantity of pets and Fee');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems that fees and pet quantity have inversely proportional relationship. The less pets, the higher is the fee. I suppose these single pets are better trained and prepared than most others."},{"metadata":{},"cell_type":"markdown","source":"### 1.11 Target: State"},{"metadata":{"trusted":true},"cell_type":"code","source":"states_dict = {k: v for k, v in zip(states['StateID'], states['StateName'])}\ntrain['State_name'] = train['State'].apply(lambda x: '_'.join(states_dict[x].split()) if x in states_dict else 'Unknown')\ntest['State_name'] = test['State'].apply(lambda x: '_'.join(states_dict[x].split()) if x in states_dict else 'Unknown')\nall_data['State_name'] = all_data['State'].apply(lambda x: '_'.join(states_dict[x].split()) if x in states_dict else 'Unknown')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data['State_name'].value_counts(normalize=True).head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Sadly I don't know anything about Malaysia’s states, so I can only say that top three states account for ~90% of ads. Let's have a look at them."},{"metadata":{"trusted":true},"cell_type":"code","source":"make_factor_plot(df=train.loc[train['State_name'].isin(list(train.State_name.value_counts().index[:3]))], x='State_name', col='AdoptionSpeed', title='Counts of pets by states and Adoption Speed')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Intetestingly top-2 and top-3 states have lower rates of adoption."},{"metadata":{},"cell_type":"markdown","source":"### 1.12 Target: Rescuer\nWe have unique hashes for resquers."},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data['RescuerID'].value_counts().head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"make_factor_plot(df=train.loc[train['RescuerID'].isin(list(train.RescuerID.value_counts().index[:5]))], x='RescuerID', col='AdoptionSpeed', title='Counts of pets by rescuers and Adoption Speed', col_wrap=5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Wow! The resquer with the highest amount of resqued pets has the best adoption rate! On the other hand the third one has the worst rate "},{"metadata":{"_uuid":"bd666d9ba51eec84858a71847fa2a0e3bde99838"},"cell_type":"markdown","source":"### 1.13 Target: VideoAmt"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['VideoAmt'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hm. In most cases there are no videos at all. Sometimes there is one video, more than one video is quite rare. We don't have videos and considering a huge disbalance in values I'm not sure this variable will be useful."},{"metadata":{},"cell_type":"markdown","source":"### 1.14 Target: PhotoAmt"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(F'Maximum amount of photos in {train[\"PhotoAmt\"].max()}')\ntrain['PhotoAmt'].value_counts().head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"make_factor_plot(df=train.loc[train['PhotoAmt'].isin(list(train.PhotoAmt.value_counts().index[:5]))], x='PhotoAmt', col='AdoptionSpeed', title='Counts of pets by PhotoAmt and Adoption Speed', col_wrap=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16, 6));\nplt.subplot(1, 2, 1)\nplt.hist(train['PhotoAmt']);\nplt.title('Distribution of PhotoAmt');\n\nplt.subplot(1, 2, 2)\nsns.violinplot(x=\"AdoptionSpeed\", y=\"PhotoAmt\", hue=\"Type\", data=train);\nplt.title('AdoptionSpeed by Type and PhotoAmt');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Pets can have up to 30 photos! That's a lot! But I'm not convinced that amount of photoes has any real influence."},{"metadata":{},"cell_type":"markdown","source":"### 1.15 Target: Description\n\nDescription contains a lot of important information, let' analyze it!"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (12, 8))\ntext_cat = ' '.join(all_data['Description'].fillna('').values)\nwordcloud = WordCloud(max_font_size=None, background_color='white',\n                      width=1200, height=1000).generate(text_cat)\nplt.imshow(wordcloud)\nplt.title('Top words in description');\nplt.axis(\"off\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are too many similar general words like \"cat\". We need to go deeper.\n\nLet's use ELI5 library for prediction explanation. I'll fit a basic vectorizer on desctriptions and build a simple Random Forest model. Then we will look at words which caused certain labels to be predicted.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = TweetTokenizer()\nvectorizer = TfidfVectorizer(ngram_range=(1, 2), tokenizer=tokenizer.tokenize)\n\nvectorizer.fit(all_data['Description'].fillna('').values)\nX_train = vectorizer.transform(train['Description'].fillna(''))\n\nrf = RandomForestClassifier(n_estimators=20)\nrf.fit(X_train, train['AdoptionSpeed'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(5):\n    print(f'Example of Adoption speed {i}')\n    text = train.loc[train['AdoptionSpeed'] == i, 'Description'].values[0]\n    print(text)\n    display(eli5.show_prediction(rf, doc=text, vec=vectorizer, top=10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some words/phrases seem to be useful, but it seems that different adoption speed classes could have similar important words..."},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Description'] = train['Description'].fillna('')\ntest['Description'] = test['Description'].fillna('')\nall_data['Description'] = all_data['Description'].fillna('')\n\ntrain['desc_length'] = train['Description'].apply(lambda x: len(x))\ntrain['desc_words'] = train['Description'].apply(lambda x: len(x.split()))\n\ntest['desc_length'] = test['Description'].apply(lambda x: len(x))\ntest['desc_words'] = test['Description'].apply(lambda x: len(x.split()))\n\nall_data['desc_length'] = all_data['Description'].apply(lambda x: len(x))\nall_data['desc_words'] = all_data['Description'].apply(lambda x: len(x.split()))\n\ntrain['averate_word_length'] = train['desc_length'] / train['desc_words']\ntest['averate_word_length'] = test['desc_length'] / test['desc_words']\nall_data['averate_word_length'] = all_data['desc_length'] / all_data['desc_words']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16, 6));\nplt.subplot(1, 2, 1)\nsns.violinplot(x=\"AdoptionSpeed\", y=\"desc_length\", hue=\"Type\", data=train);\nplt.title('AdoptionSpeed by Type and description length');\n\nplt.subplot(1, 2, 2)\nsns.violinplot(x=\"AdoptionSpeed\", y=\"desc_words\", hue=\"Type\", data=train);\nplt.title('AdoptionSpeed by Type and count of words in description');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Interestingly pets with short text in ads are adopted quickly. Or maybe longer descriptions mean more problems in the pets, therefore adoption speed is lower?"},{"metadata":{"trusted":true},"cell_type":"code","source":"sentiment_dict = {}\nfor filename in os.listdir('../input/petfinder-adoption-prediction/train_sentiment/'):\n    with open('../input/petfinder-adoption-prediction/train_sentiment/' + filename, 'r') as f:\n        sentiment = json.load(f)\n    pet_id = filename.split('.')[0]\n    sentiment_dict[pet_id] = {}\n    sentiment_dict[pet_id]['magnitude'] = sentiment['documentSentiment']['magnitude']\n    sentiment_dict[pet_id]['score'] = sentiment['documentSentiment']['score']\n    sentiment_dict[pet_id]['language'] = sentiment['language']\n\nfor filename in os.listdir('../input/petfinder-adoption-prediction/test_sentiment/'):\n    with open('../input/petfinder-adoption-prediction/test_sentiment/' + filename, 'r') as f:\n        sentiment = json.load(f)\n    pet_id = filename.split('.')[0]\n    sentiment_dict[pet_id] = {}\n    sentiment_dict[pet_id]['magnitude'] = sentiment['documentSentiment']['magnitude']\n    sentiment_dict[pet_id]['score'] = sentiment['documentSentiment']['score']\n    sentiment_dict[pet_id]['language'] = sentiment['language']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['lang'] = train['PetID'].apply(lambda x: sentiment_dict[x]['language'] if x in sentiment_dict else 'no')\ntrain['magnitude'] = train['PetID'].apply(lambda x: sentiment_dict[x]['magnitude'] if x in sentiment_dict else 0)\ntrain['score'] = train['PetID'].apply(lambda x: sentiment_dict[x]['score'] if x in sentiment_dict else 0)\n\ntest['lang'] = test['PetID'].apply(lambda x: sentiment_dict[x]['language'] if x in sentiment_dict else 'no')\ntest['magnitude'] = test['PetID'].apply(lambda x: sentiment_dict[x]['magnitude'] if x in sentiment_dict else 0)\ntest['score'] = test['PetID'].apply(lambda x: sentiment_dict[x]['score'] if x in sentiment_dict else 0)\n\nall_data['lang'] = all_data['PetID'].apply(lambda x: sentiment_dict[x]['language'] if x in sentiment_dict else 'no')\nall_data['magnitude'] = all_data['PetID'].apply(lambda x: sentiment_dict[x]['magnitude'] if x in sentiment_dict else 0)\nall_data['score'] = all_data['PetID'].apply(lambda x: sentiment_dict[x]['score'] if x in sentiment_dict else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_overview(x='lang', title='lang', hue = 'AdoptionSpeed', data = train)\nplot_target(x='lang', title = 'Dog', data= train.loc[train['Type']==1], hue = 'AdoptionSpeed')\nplot_target(x='lang', title = 'Cat', data= train.loc[train['Type']==2], hue = 'AdoptionSpeed')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Well, English is the most common language by far, so language feature will hardly help."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16, 6));\nplt.subplot(1, 2, 1)\nsns.violinplot(x=\"AdoptionSpeed\", y=\"score\", hue=\"Type\", data=train);\nplt.title('AdoptionSpeed by Type and score');\n\nplt.subplot(1, 2, 2)\nsns.violinplot(x=\"AdoptionSpeed\", y=\"magnitude\", hue=\"Type\", data=train);\nplt.title('AdoptionSpeed by Type and magnitude of sentiment');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2 Basic model\n\nThere are much more interesting things in the dataset and I'm going to explore them, but for now let's build a simple model as a baseline."},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_to_use = ['Type', 'Age', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2',\n       'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n       'Sterilized', 'Health', 'Quantity', 'Fee', 'State', 'RescuerID', 'health', 'Free', 'score',\n       'VideoAmt', 'PhotoAmt', 'AdoptionSpeed', 'No_name', 'Pure_breed', 'desc_length', 'desc_words', 'averate_word_length', 'magnitude']\ntrain = train[[col for col in cols_to_use if col in train.columns]]\ntest = test[[col for col in cols_to_use if col in test.columns]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_cols = ['Type', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2',\n       'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n       'Sterilized', 'Health', 'State', 'RescuerID',\n       'No_name', 'Pure_breed', 'health', 'Free']\ncat_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"more_cols = []\nfor col1 in cat_cols:\n    for col2 in cat_cols:\n        if col1 != col2 and col1 not in ['RescuerID', 'State'] and col2 not in ['RescuerID', 'State']:\n            train[col1 + '_' + col2] = train[col1].astype(str) + '_' + train[col2].astype(str)\n            test[col1 + '_' + col2] = test[col1].astype(str) + '_' + test[col2].astype(str)\n            more_cols.append(col1 + '_' + col2)\n            \ncat_cols = cat_cols + more_cols\ncat_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nindexer = {}\nfor col in cat_cols:\n    # print(col)\n    _, indexer[col] = pd.factorize(train[col].astype(str))\n    \nfor col in tqdm_notebook(cat_cols):\n    # print(col)\n    train[col] = indexer[col].get_indexer(train[col].astype(str))\n    test[col] = indexer[col].get_indexer(test[col].astype(str))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train['AdoptionSpeed']\ntrain = train.drop(['AdoptionSpeed'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_fold = 5\nfolds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(X=train, X_test=test, y=y, params=None, folds=folds, model_type='lgb', plot_feature_importance=False, averaging='usual', make_oof=False):\n    result_dict = {}\n    # Prepare data\n    if make_oof:\n        oof = np.zeros((len(X), 5))\n    prediction = np.zeros((len(X_test), 5))\n    scores = []\n    feature_importance = pd.DataFrame()\n    for fold_n, (train_index, valid_index) in enumerate(folds.split(X, y)):\n        gc.collect()\n        print('Fold', fold_n + 1, 'started at', time.ctime())\n        X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n        y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n        \n        # LightGBM model\n        if model_type == 'lgb':\n            train_data = lgb.Dataset(X_train, label=y_train, categorical_feature = cat_cols)\n            valid_data = lgb.Dataset(X_valid, label=y_valid, categorical_feature = cat_cols)\n            \n            model = lgb.train(params,\n                    train_data,\n                    num_boost_round=20000,\n                    valid_sets = [train_data, valid_data],\n                    verbose_eval=500,\n                    early_stopping_rounds = 200)\n\n            del train_data, valid_data\n            \n            y_pred_valid = model.predict(X_valid, num_iteration=model.best_iteration)\n            del X_valid\n            gc.collect()\n            y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n            \n             # feature importance\n            fold_importance = pd.DataFrame()\n            fold_importance[\"feature\"] = X.columns\n            fold_importance[\"importance\"] = model.feature_importance()\n            fold_importance[\"fold\"] = fold_n + 1\n            feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n        \n        # XGBoost model\n        if model_type == 'xgb':\n            train_data = xgb.DMatrix(data=X_train, label=y_train)\n            valid_data = xgb.DMatrix(data=X_valid, label=y_valid)\n\n            watchlist = [(train_data, 'train'), (valid_data, 'valid_data')]\n            model = xgb.train(dtrain=train_data, \n                              num_boost_round=20000, \n                              evals=watchlist, \n                              early_stopping_rounds=200, \n                              verbose_eval=500, \n                              params=params)\n            \n            y_pred_valid = model.predict(xgb.DMatrix(X_valid), ntree_limit=model.best_ntree_limit)\n            y_pred = model.predict(xgb.DMatrix(X_test), ntree_limit=model.best_ntree_limit)\n            \n            # feature importance\n            fold_importance = pd.DataFrame(list(model.get_fscore().items()),columns=['feature','importance'])\n            fold_importance[\"fold\"] = fold_n + 1\n            feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n        \n        # CatBoost model\n        if model_type == 'cat':\n            model = CatBoostClassifier(iterations=20000,  loss_function='MultiClass',early_stopping_rounds = 200, **params)\n            model.fit(X_train, y_train, eval_set=(X_valid, y_valid), cat_features=[], use_best_model=True, verbose=False)\n\n            y_pred_valid = model.predict_proba(X_valid)\n            y_pred = model.predict_proba(X_test)\n        \n             # feature importance\n            fold_importance = model.get_feature_importance(prettified=True).rename(columns={'Feature Id': 'feature', 'Importances': 'importance'})\n            fold_importance[\"fold\"] = fold_n + 1\n            feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n        \n        if make_oof:\n            oof[valid_index] = y_pred_valid\n            \n        scores.append(kappa(y_valid, y_pred_valid.argmax(1)))\n        print('Fold kappa:', kappa(y_valid, y_pred_valid.argmax(1)))\n        print('')\n        \n        if averaging == 'usual':\n            prediction += y_pred\n        elif averaging == 'rank':\n            prediction += pd.Series(y_pred).rank().values\n        \n       \n    prediction /= n_fold\n    \n    print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n    \n    if plot_feature_importance: \n                 \n        feature_importance[\"importance\"] /= n_fold\n        cols = feature_importance[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n             by=\"importance\", ascending=False)[:50].index\n\n        best_features = feature_importance.loc[feature_importance.feature.isin(cols)]\n\n        plt.figure(figsize=(16, 12));\n        sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False));\n        \n        if model_type == 'xgb':\n            plt.title('XGB Features (avg over folds)');\n        \n        if model_type == 'lgb':\n            plt.title('LGB Features (avg over folds)');\n        \n        if model_type == 'cat':\n            plt.title('CAT Features (avg over folds)');\n            \n        result_dict['feature_importance'] = feature_importance\n            \n    result_dict['prediction'] = prediction\n    if make_oof:\n        result_dict['oof'] = oof\n    \n    return result_dict, scores , best_features","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.1 LightGBM"},{"metadata":{"trusted":true},"cell_type":"code","source":"start = time.time()\nlgb_params = {'num_leaves': 512,\n        #  'min_data_in_leaf': 60,\n         'objective': 'multiclass',\n         'max_depth': -1,\n         'learning_rate': 0.01,\n         \"boosting\": \"gbdt\",\n         \"feature_fraction\": 0.9,\n         \"bagging_freq\": 3,\n         \"bagging_fraction\": 0.9,\n         \"bagging_seed\": 11,\n        #  \"lambda_l1\": 0.1,\n         # \"lambda_l2\": 0.1,\n         \"random_state\": 42,          \n         \"verbosity\": -1,\n         \"num_class\": 5}\nresult_dict_lgb, scores_lgb, best_features_lgb = train_model(X=train, X_test=test, y=y, params=lgb_params, model_type='lgb', plot_feature_importance=True, make_oof=True)\nend = time.time()\ntime_spend_lgb = end - start\nprint(f'Time spend: {time_spend_lgb}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_features_lgb_top = best_features_lgb.loc[best_features_lgb['fold'] == 5].sort_values(by=['importance'], ascending=False)[:5].drop(['fold','importance'], axis=1).reset_index(drop=True)\nbest_features_lgb_top['model'] = 'LightGBM'\nbest_features_lgb_top","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_score_lgb = pd.DataFrame([[np.mean(scores_lgb),np.std(scores_lgb),'LightGBM',time_spend_lgb]], columns=['mean','std','model','time_spend'])\nfinal_score_lgb","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.2 XGBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"start = time.time()\nxgb_params = {'eta': 0.01, 'max_depth': 9, 'subsample': 0.9, 'colsample_bytree': 0.9, \n          'objective': 'multi:softprob', 'eval_metric': 'merror', 'silent': True, 'nthread': 4, 'num_class': 5}\nresult_dict_xgb, scores_xgb, best_features_xgb= train_model(X=train, X_test=test, y=y,params=xgb_params, model_type='xgb',plot_feature_importance=True, make_oof=True)\nend = time.time()\ntime_spend_xgb = end - start\nprint(f'Time spend: {time_spend_xgb}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_features_xgb_top = best_features_xgb.loc[best_features_xgb['fold'] == 5].sort_values(by=['importance'], ascending=False)[:5].drop(['fold','importance'], axis=1).reset_index(drop=True)\nbest_features_xgb_top['model'] = 'XGBoost'\nbest_features_xgb_top","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_score_xgb = pd.DataFrame([[np.mean(scores_xgb),np.std(scores_xgb),'XGBoost',time_spend_xgb]], columns=['mean','std','model','time_spend'])\nfinal_score_xgb","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.3 CatBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"start = time.time()\ncat_params = {'learning_rate':0.03}\nresult_dict_cat,scores_cat, best_features_cat = train_model(X=train, X_test=test, y=y, model_type='cat',params=cat_params,plot_feature_importance=True, make_oof=True)\nend = time.time()\ntime_spend_cat = end - start\nprint(f'Time spend: {time_spend_cat}')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_features_cat_top = best_features_cat.loc[best_features_cat['fold'] == 5].sort_values(by=['importance'], ascending=False)[:5].drop(['fold','importance'], axis=1).reset_index(drop=True)\nbest_features_cat_top['model'] = 'CatBoost'\nbest_features_cat_top","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_score_cat = pd.DataFrame([[np.mean(scores_cat),np.std(scores_cat),'CatBoost',time_spend_cat]], columns=['mean','std','model','time_spend'])\nfinal_score_cat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_list = [best_features_cat_top, best_features_xgb_top, best_features_lgb_top] \nfeature_impotant = pd.concat(feature_list)\nfeature_impotant","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score_list = [final_score_cat, final_score_lgb, final_score_xgb] \nfinal_score = pd.concat(score_list).sort_values(by='mean').reset_index(drop=True)\nfinal_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction_cat = result_dict_cat['prediction'].argmax(1)\nsubmission_cat = pd.DataFrame({'PetID': sub.PetID, 'AdoptionSpeed': [int(i) for i in prediction_lgb_cat]})\nsubmission_cat.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction_lgb_cat = (result_dict_lgb['prediction'] + result_dict_cat['prediction']).argmax(1)\nsubmission_lgb_cat = pd.DataFrame({'PetID': sub.PetID, 'AdoptionSpeed': [int(i) for i in prediction_lgb_cat]})\nsubmission_lgb_cat.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction_all = (result_dict_lgb['prediction'] + result_dict_xgb['prediction'] + result_dict_cat['prediction']).argmax(1)\nsubmission_all = pd.DataFrame({'PetID': sub.PetID, 'AdoptionSpeed': [int(i) for i in prediction_all]})\nsubmission_all.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_lgb_cat.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}