{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n!pip install AutoViz\n!pip install xlrd\nfrom autoviz.AutoViz_Class import AutoViz_Class\n\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import roc_auc_score, log_loss, accuracy_score\n\nfrom sklearn.preprocessing import QuantileTransformer, StandardScaler, PolynomialFeatures, LabelEncoder\nfrom sklearn.feature_selection import VarianceThreshold, SelectKBest\n\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier\n\nimport optuna\nfrom optuna.visualization import plot_optimization_history, plot_param_importances\n\nfrom IPython.display import display\n\nimport warnings\nwarnings.filterwarnings('ignore')\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-mar-2021/train.csv', index_col=0)\ntest = pd.read_csv('../input/tabular-playground-series-mar-2021/test.csv', index_col=0)\n\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#AutoViz\n\nAV = AutoViz_Class()\ndft = AV.AutoViz('../input/tabular-playground-series-mar-2021/train.csv',depVar='target')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Label Encoding categorical cols\n\nalldata = pd.concat([train, test], axis = 0, ignore_index = True)\nlentrain = len(train)\n\nlabel = LabelEncoder() \n\ncatcols = train.select_dtypes(include=['object']).columns.tolist()\ncatindices = [catcols.index(i) for i in catcols]\ncatcols.append('target')\nfor col in catcols:\n    label.fit(alldata[col])\n    alldata[col] = label.transform(alldata[col])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_preprocessed = alldata[:lentrain]\ntest_preprocessed = alldata[lentrain:]\npredictors = train_preprocessed.columns[:-1]\ntarget = train_preprocessed.columns[-1]\n\nX = train_preprocessed[predictors]\ny = train_preprocessed[target]\nX_test = test_preprocessed[predictors]\ny_test = test_preprocessed[target]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N_SPLITS = 5\nN_TRIALS = 5 \nTIME = 3600*1.5 \n\nFIXED_PARAMS = {'n_estimators': 10000,\n                'learning_rate': 0.05,\n                'metric': 'auc',\n                'verbosity': -1,\n                'n_jobs': -1}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_preprocessed.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"skfold = StratifiedKFold(N_SPLITS, shuffle = True)\n\ndef objective(trial, cv=skfold):\n    \n    params = {\n        'num_leaves': trial.suggest_int('num_leaves', 2, 1024),\n        'max_depth': trial.suggest_int('max_depth', 2, 32),\n        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n        'reg_alpha': trial.suggest_float('reg_alpha', 0.001, 10),\n        'reg_lambda': trial.suggest_float('reg_lambda', 0.001, 10),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 0.9),\n        'subsample': trial.suggest_float('subsample', 0.01, 0.9),\n        'cat_smooth': trial.suggest_float('cat_smooth', 10, 100.0),  \n        'cat_l2': trial.suggest_int('cat_l2', 1, 20),\n    }\n    \n    params.update(FIXED_PARAMS)\n    \n    auclist = []\n    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, 'auc', valid_name='valid_1') \n    \n    for kfold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n        \n        X_train = X.iloc[train_idx]\n        y_train = y.iloc[train_idx]\n        X_val = X.iloc[val_idx]\n        y_val = y.iloc[val_idx]\n                \n        d_train = lgb.Dataset(X_train, label=y_train)\n        d_valid = lgb.Dataset(X_val, label=y_val)\n      \n        model = lgb.train(params,\n                      train_set=d_train,\n                      valid_sets=[d_train, d_valid],\n                      verbose_eval=0,\n                      early_stopping_rounds=100,\n                      callbacks=[pruning_callback])\n    \n        preds = model.predict(X_val)\n        auc_score = roc_auc_score(y_val, preds)\n        auclist.append(auc_score)\n        \n    \n    return np.mean(auclist)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(study_name = 'lgbm_parameter_opt', direction = 'maximize',\n                            pruner=optuna.pruners.MedianPruner(n_warmup_steps=25))\n\n#study.enqueue_trial()\n\n#study.optimize(objective, n_trials=N_TRIALS, show_progress_bar=True)\nstudy.optimize(objective, timeout=TIME, show_progress_bar=True) \n\ntrial = study.best_trial\n\nprint(\"  Value: {}\".format(trial.value))\n\nprint(\"  Params: \")\nfor key, value in trial.params.items():\n    print(\"    {}: {}\".format(key, value))\nbest_params = FIXED_PARAMS.copy()\nbest_params.update(trial.params)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import joblib\n# joblib.dump(study, 'study.pkl')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_params","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study.best_value","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_optimization_history(study)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importance\nplot_param_importances(study)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_model = LGBMClassifier(**best_params)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_preds = []\naccuracies = []\naucs = []\nskfold = StratifiedKFold(N_TRIALS, shuffle = True)\n\nfor kfold, (train_idx, val_idx) in enumerate(skfold.split(X, y)):\n        \n        final_model.fit(X.loc[train_idx], \n                        y.loc[train_idx])\n        print('Fitted {}'.format(type(final_model).__name__))\n        \n        y_val = y.iloc[val_idx]\n        \n        preds = final_model.predict(X.loc[val_idx])\n        probs = final_model.predict_proba(X.loc[val_idx])[:, 1]\n        \n        accuracy = accuracy_score(y_val, preds)\n        accuracies.append(accuracy)\n        print('Fold: {}\\t Validation Accuracy: {}\\n'.format(kfold, accuracy))\n        \n        auc = roc_auc_score(y_val, probs)\n        aucs.append(auc)\n        \n        print('Fold: {}\\t Validation AUC: {}\\n'.format(kfold, auc))\n        \n        test_preds.append(final_model.predict_proba(X_test))\n        \nprint(\"Best Parameters mean Accuracy: {}\".format(np.mean(accuracies)))\nprint(\"Best Parameters mean AucScore: {}\".format(np.mean(aucs)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv('../input/tabular-playground-series-mar-2021/test.csv')\n\n\ntest_predictions = np.mean(test_preds, axis = 0)\npredictions_df = pd.DataFrame(test_predictions[:, 1] , columns = [\"target\"])\npredictions_df['id'] = test['id']\n\npredictions_df.to_csv(\"TPS_MAR_optuna_pruning.csv\", index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}