{"cells":[{"metadata":{},"cell_type":"markdown","source":"# About this notebook\n\nAs the data for this challenge are provided without context, I find it difficult to guess which models may be suited to the problem at hand and which one will certainly not work well.\n\nThe goal here is to try a \"brute force\" approach of this question by systematicly testing 8 classification models with minimal hyperparameters optimization.\n\nIn this notebook, we will:\n1. Preprocess data: encoding, scaling, train/val split\n2. Train and test 8 models\n3. Choose the most promising one and sumit the result"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport os\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing data\n\n1. Data loading and overview\n2. Categorical values encoding\n3. Feature scaling\n4. Train/test split"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/tabular-playground-series-mar-2021/train.csv\")\ntest = pd.read_csv(\"../input/tabular-playground-series-mar-2021/test.csv\")\n\n#Features\nX = train.drop([\"id\", \"target\"], axis=1)\nX_test = test.drop([\"id\"], axis=1)\nX_all = pd.concat([X, X_test], axis=0)\n\n#Label\ny = train.target","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Data overview\nfrom pandas_profiling.profile_report import ProfileReport\nProfileReport(X_all)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Encoding categorical data\n\n#List of categorical col\nlist_cat = [col for col in X.columns if col.startswith(\"cat\")]\n\n\nle = LabelEncoder()\n\nfor col in list_cat:\n    X_all[col] = le.fit_transform(X_all[col])\n   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Feature scaling\n\nscaler = StandardScaler().fit(X_all)\nX_all = pd.DataFrame(columns = X_all.columns,\n                            data = scaler.transform(X_all))\n\nX_all.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Train, val, test split\n\nX = X_all.iloc[:len(train), :]\nX_test = X_all.iloc[len(train):, :]\n\n#To save time we keep only a random subset of the training set\nsample_size = 0.1\ntrain_sample = pd.concat([X, y], axis = 1)\ntrain_sample = train_sample.sample(frac = sample_size, random_state = 0)\n\n# Train/val split\ntrain_size = 0.8\ntrain_set = train_sample.iloc[:int(len(train_sample) * train_size), :]\nval_set = train_sample.iloc[int(len(train_sample) * train_size):, :]\n\n\nXtrain = train_set.drop(labels = ['target'], axis = 1)\nytrain = train_set.target\n\nXval = val_set.drop(labels = ['target'], axis = 1)\nyval = val_set.target","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model testing\n\nWe test a selection of classification models from sklearn without any hyperparameter optimization."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.experimental import enable_hist_gradient_boosting\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, HistGradientBoostingClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n\n\nfrom sklearn.metrics import roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifiers = [\n    SVC(kernel=\"linear\", C=0.025),\n    DecisionTreeClassifier(max_depth=5),\n    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n    MLPClassifier(alpha=1, max_iter=1000),\n    AdaBoostClassifier(),\n    GaussianNB(),\n    QuadraticDiscriminantAnalysis(),\n    HistGradientBoostingClassifier(max_leaf_nodes=100, validation_fraction=None)]\n\nfor model in classifiers:\n    clf = model\n    clf.fit(Xtrain, ytrain)\n    \n    #Print model name, train set performance and val set performance\n    print(\"Model :\", str(model).split('(')[0])\n    train_score = roc_auc_score(ytrain, clf.predict(Xtrain))\n    print('Training set evaluation :', train_score)\n    val_score = roc_auc_score(yval, clf.predict(Xval))\n    print('Validation set evaluation :', val_score)\n\n    print('')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Quick interpretation :\n\nThe area under the ROC curve is comprised between 0 and 1, 1 being the best possible performance.\n\nThe performance of most classifiers are pretty close around 0.75 except for HistGradientBoostingClassifier which is obviously overfitting. However the AdaBoostClassifier each a slightly better result.\n\nLet's choose this model for our first submission and see how we perform...\n"},{"metadata":{},"cell_type":"markdown","source":"# Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training on the whole data\nclf = AdaBoostClassifier()\nclf.fit(X, y)\n\nytest = clf.predict(X_test)\n\n#Save\nresult = pd.DataFrame()\n\nresult[\"id\"] = test.id\nresult[\"target\"] = ytest.flatten()\n\nresult.to_csv(os.path.join(\"submission.csv\"), index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}