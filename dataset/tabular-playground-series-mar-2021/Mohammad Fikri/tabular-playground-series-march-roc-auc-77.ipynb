{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Tabular Playground Series - Feb 2021","metadata":{}},{"cell_type":"markdown","source":"## Dataset Description\nFor this competition, you will be predicting a continuous target based on a number of feature columns given in the data. All of the feature columns, cat0 - cat9 are categorical, and the feature columns cont0 - cont13 are continuous.","metadata":{}},{"cell_type":"markdown","source":"# Data Exploration","metadata":{}},{"cell_type":"markdown","source":"## Import Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n\nfrom sklearn.metrics import confusion_matrix, classification_report,accuracy_score,roc_curve, auc, precision_recall_curve, f1_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Dataset","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv(\"../input/tabular-playground-series-mar-2021/train.csv\")\ndf_test = pd.read_csv(\"../input/tabular-playground-series-mar-2021/test.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Description","metadata":{}},{"cell_type":"code","source":"df_train.info()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data type identification","metadata":{}},{"cell_type":"code","source":"df_train.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data numeric","metadata":{}},{"cell_type":"code","source":"numeric=['int8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64']\ndf_num=df_train.select_dtypes(include=numeric)\ndf_num.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data categorical","metadata":{"code_folding":[]}},{"cell_type":"code","source":"df_cat=df_train.select_dtypes(include='object')\ndf_cat.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Early Features Engineering","metadata":{}},{"cell_type":"markdown","source":"## Combining Train and Test Dataframes","metadata":{}},{"cell_type":"markdown","source":"The purpose of combine the dataframe are to avoid repeating all the operations (such as transformations, imputations, etc) done on the train set for the test set and to get more data for our analysis (because more data we get, the BETTER it is)","metadata":{}},{"cell_type":"markdown","source":"##### Store the number of rows or indexes for train and test dataset to separate them while performing modeling and prediction.","metadata":{}},{"cell_type":"code","source":"all_data = pd.concat([df_train,df_test])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_data.drop('id',axis=1,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preparation","metadata":{}},{"cell_type":"markdown","source":"## Missing Value ","metadata":{}},{"cell_type":"code","source":"null=pd.DataFrame(all_data.isnull().sum(),columns=[\"Null Values\"])\nnull[\"% Missing Values\"]=(all_data.isna().sum()/len(all_data)*100)\nnull = null[null[\"% Missing Values\"] > 0]\nnull.style.background_gradient(cmap='viridis',low =0.2,high=0.1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory Data Analysis","metadata":{}},{"cell_type":"markdown","source":"## Numerical Approach","metadata":{}},{"cell_type":"markdown","source":"### Statistical Summary","metadata":{}},{"cell_type":"code","source":"describeNum = df_train.describe(include =['float64', 'int64', 'float', 'int'])\ndescribeNum.T.style.background_gradient(cmap='viridis',low=0.2,high=0.1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"describeNumCat = df_train.describe(include=[\"O\"])\ndescribeNumCat.T.style.background_gradient(cmap='viridis',low=0.2,high=0.1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Categorical Value Counting","metadata":{}},{"cell_type":"code","source":"cats = df_train.describe(include=[\"O\"])\nfor col in cats:\n    print(f'''Value count colunm {col}:''')\n    print(df_train[col].value_counts())\n    print()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Graphic Approach","metadata":{}},{"cell_type":"markdown","source":"### Correlation heatmap","metadata":{}},{"cell_type":"markdown","source":"Now how to correlate between data variables. \n\nCorrelation is represented as a value between -1 and +1 where +1 indicates the highest positive correlation, -1 indicates the highest negative correlation, and 0 indicates no correlation.","metadata":{}},{"cell_type":"code","source":"numeric = ['cont0', 'cont1', 'cont2', 'cont3', 'cont4','cont5', 'cont6', 'cont7', 'cont8', 'cont9', 'cont10']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train[numeric].corr()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(30,20))\nax = sns.heatmap(data = df_train[numeric].corr(),cmap='YlGnBu',annot=True)\n\nbottom, top = ax.get_ylim()\nax.set_ylim(bottom + 0.5,top - 0.5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Target distribution analysis","metadata":{}},{"cell_type":"code","source":"fig, ax =plt.subplots(1,2)\n\nplt.style.use('fivethirtyeight')\nplt.figure(figsize=(10,12))\nsns.set_context(\"paper\", font_scale=1)                                                  \nsns.countplot('target',data=all_data, ax=ax[0])\nall_data['target'].value_counts().plot.pie(explode=[0,0.2],autopct='%1.2f%%',ax=ax[1])\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Categorical Features","metadata":{}},{"cell_type":"code","source":"features_cat = ['cat0', 'cat1', 'cat2', 'cat3',\n                'cat4', 'cat5', 'cat6', 'cat7',\n                'cat8', 'cat9', 'cat10', 'cat11',\n                'cat12', 'cat13', 'cat14', 'cat15',\n                'cat16', 'cat17', 'cat18']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot distribution of categorical features\nfor f in features_cat:\n    plt.figure(figsize=(14,4))\n    df_train[f].value_counts().plot(kind='bar')\n    plt.title(f)\n    plt.grid()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Processing","metadata":{}},{"cell_type":"markdown","source":"## Outliers","metadata":{}},{"cell_type":"markdown","source":"We will try to detect outliers for the numeric features and then remove them , But we will only remove those outliers which are a part of the train data i.e. having index within ntrain (defined earlier)","metadata":{}},{"cell_type":"code","source":"featuresNum = ['cont0', 'cont1', 'cont2', 'cont3', 'cont4','cont5', 'cont6', 'cont7', 'cont8', 'cont9', 'cont10']\n\nplt.figure(figsize=(15, 7))\nfor i in range(0, len(featuresNum)):\n    plt.subplot(1, len(featuresNum), i+1)\n    sns.boxplot(y=df_train[featuresNum[i]], color='green', orient='v')\n    plt.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Label Encoding","metadata":{}},{"cell_type":"markdown","source":"For handling categorical data. We modtly use these 2 path:\n - OneHotEncoder\n - LabelEncoder\nWhere OneHotEncoder is used where data are not in any order and LabelEncoder when data is in order.","metadata":{}},{"cell_type":"code","source":"all_data.cat0 = all_data.cat0.replace({'A':0,'B':1})\nall_data.cat1 = all_data.cat1.replace({'A':0,'B':1,'C':2,'D':3,'E':4,'F':5,'G':6,'H':7,'I':8,'J':9,'K':10,'L':11,'M':12,'N':13,'O':14})\nall_data.cat2 = all_data.cat2.replace({'A':0,'B':1,'C':2,'D':3,'E':4,'F':5,'G':6,'H':7,'I':8,'J':9,'K':10,'L':11,'M':12,'N':13,'O':14,'Q':15,'R':16,'S':17,'U':18,})\nall_data.cat3 = all_data.cat3.replace({'A':0,'B':1,'C':2,'D':3,'E':4,'F':5,'G':6,'H':7,'I':8,'J':9,'K':10,'L':11,'N':12})\nall_data.cat4 = all_data.cat4.replace({'A':0,'B':1,'C':2,'D':3,'E':4,'F':5,'G':6,'H':7,'I':8,'J':9,'K':10,'L':11,'M':12,'N':13,'O':14,'P':15,'Q':16,'R':17,'S':18,'T':19})\nall_data.cat6 = all_data.cat6.replace({'A':0,'B':1,'C':2,'D':3,'E':4,'F':5,'G':6,'I':7,'K':8,'M':9,'O':10,'Q':11,'S':12,'U':13,'W':14,'Y':15})\nall_data.cat9 = all_data.cat9.replace({'A':0,'B':1,'C':2,'D':3,'E':4,'F':5,'G':6,'I':7,'J':8,'L':9,'N':10,'O':11,'Q':12,'R':13,'S':14,'U':15,'V':16,'W':17,'X':18})\nall_data.cat11 = all_data.cat11.replace({'A':0,'B':1})\nall_data.cat12 = all_data.cat12.replace({'A':0,'B':1})\nall_data.cat13 = all_data.cat13.replace({'A':0,'B':1})\nall_data.cat14 = all_data.cat14.replace({'A':0,'B':1})\nall_data.cat15 = all_data.cat15.replace({'A':0,'B':1,'C':2,'D':3})\nall_data.cat16 = all_data.cat16.replace({'A':0,'B':1,'C':2,'D':3})\nall_data.cat17 = all_data.cat17.replace({'A':0,'B':1,'C':2,'D':3})\nall_data.cat18 = all_data.cat18.replace({'A':0,'B':1,'C':2,'D':3})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Drop Column\nall_data = all_data.drop(['cat5'],axis=1)\nall_data = all_data.drop(['cat7'],axis=1)\nall_data = all_data.drop(['cat8'],axis=1)\nall_data = all_data.drop(['cat10'],axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"## Log Transforming all the Highly Skewed Features.","metadata":{}},{"cell_type":"code","source":"# ## Get all the numeric features in out dataset\n# numeric_features = all_data.skew().index\n\n# ## Getting all the skewed features (skew > 0.5 or skew < -0.5)\n# skewed_features = all_data[numeric_features].skew()[np.abs(all_data[numeric_features].skew()) > 0.5].index\n\n# ## Performing log(1+x) transformation\n# all_data[skewed_features] = np.log1p(all_data[skewed_features])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Getting the new train and test sets","metadata":{}},{"cell_type":"code","source":"df_train = all_data.iloc[:300000][:]\n\ndf_test = all_data[300000:][:]\ndf_test.drop('target',axis=1,inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['target'] = df_train['target'].astype(int)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c = df_train.select_dtypes(exclude = [\"object\"]).columns\n\nfor a in range(len(c)):\n    print(\"Is there any negative value in '{}' column  : {} \".format(c[a],(df_train[c[a]]<0).any()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c = df_test.select_dtypes(exclude = [\"object\"]).columns\n\nfor a in range(len(c)):\n    print(\"Is there any negative value in '{}' column  : {} \".format(c[a],(df_test[c[a]]<0).any()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train=df_train.drop(df_train[df_train.cont0<0].index)\ndf_train=df_train.drop(df_train[df_train.cont3<0].index)\ndf_train=df_train.drop(df_train[df_train.cont5<0].index)\ndf_test=df_test.drop(df_test[df_test.cont0<0].index)\ndf_test=df_test.drop(df_test[df_test.cont3<0].index)\ndf_test=df_test.drop(df_test[df_test.cont5<0].index)\ndf_test=df_test.drop(df_test[df_test.cont6<0].index)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"code","source":"X = df_train.drop('target', axis = 1)\ny  = df_train['target']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Random Forest Classifier","metadata":{}},{"cell_type":"code","source":"RFC = RandomForestClassifier()\n\n\nRFC.fit(X_train,y_train)\ny_pred_rf = RFC.predict(X_test)\n\nprint(\"Training Accuracy :\", RFC.score(X_train, y_train))\nprint(\"Testing Accuracy :\", RFC.score(X_test, y_test))\n\ncm = confusion_matrix(y_test, y_pred_rf)\nplt.rcParams['figure.figsize'] = (3, 3)\nsns.heatmap(cm, annot = True, cmap = 'YlGnBu', fmt = '.8g')\nplt.show()\n\ncr = classification_report(y_test, y_pred_rf)\nprint(cr)\n\n\nprint(\"------------------------------------------\")\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,y_pred_rf)\nroc_auc = auc(false_positive_rate, true_positive_rate)\nprint(\"ROC Curves              =\",roc_auc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Gradient boosting","metadata":{}},{"cell_type":"code","source":"GBC = GradientBoostingClassifier(loss=\"deviance\",\n                                 n_estimators=100, \n                                 learning_rate=0.1,\n                                 max_depth=8,\n                                 min_samples_leaf=100,\n                                 max_features=0.1)\n\nGBC.fit(X_train,y_train)\n\ny_pred_rf = GBC.predict(X_test)\n\nprint(\"Training Accuracy :\", GBC.score(X_train, y_train))\nprint(\"Testing Accuracy :\", GBC.score(X_test, y_test))\n\ncm = confusion_matrix(y_test, y_pred_rf)\nplt.rcParams['figure.figsize'] = (3, 3)\nsns.heatmap(cm, annot = True, cmap = 'YlGnBu', fmt = '.8g')\nplt.show()\n\ncr = classification_report(y_test, y_pred_rf)\nprint(cr)\n\n\nprint(\"------------------------------------------\")\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,y_pred_rf)\nroc_auc = auc(false_positive_rate, true_positive_rate)\nprint(\"ROC Curves              =\",roc_auc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ExtraTrees ","metadata":{}},{"cell_type":"code","source":"ExtC = ExtraTreesClassifier()\n\nExtC.fit(X_train,y_train)\n\ny_pred_rf = ExtC.predict(X_test)\n\nprint(\"Training Accuracy :\", ExtC.score(X_train, y_train))\nprint(\"Testing Accuracy :\", ExtC.score(X_test, y_test))\n\ncm = confusion_matrix(y_test, y_pred_rf)\nplt.rcParams['figure.figsize'] = (3, 3)\nsns.heatmap(cm, annot = True, cmap = 'YlGnBu', fmt = '.8g')\nplt.show()\n\ncr = classification_report(y_test, y_pred_rf)\nprint(cr)\n\n\nprint(\"------------------------------------------\")\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,y_pred_rf)\nroc_auc = auc(false_positive_rate, true_positive_rate)\nprint(\"ROC Curves              =\",roc_auc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}