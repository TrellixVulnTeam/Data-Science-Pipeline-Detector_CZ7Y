{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Introduction\nThis is my second competition submission, where i put together what i have learned during my data science bootcamp and what i have learned through kaggle Data scientist and its courses.\n\n## Table of Content \n    \n   \n   1. [The Challenge](#cell1)\n   2. [Variables Overview](#cell2)\n   2. [Importaing relevant libraries](#cell3)\n   3. [importing dataset](#cell4)\n   4. [Preprocessing dataset](#cell5)\n       - Dealing with missing values\n       - Data Type check\n       - New numerical Dataframe\n       - New categorical Dataframe\n       \n   5. [Feature Selection](#cell6)\n       - Numerical Features\n       - Categorical Features\n       - Creating Dummy Variables for Categorical features \n        \n        \n   6. [Input and targets](#cell7)\n   \n   7. [Train, test , Split](#cell8)\n   8. [Model Selection](#cell9)\n       - Logistic Regression\n       - Random Forest \n       - Ridge Classifier\n       "},{"metadata":{},"cell_type":"markdown","source":"## The challange <a id=\"cell1\"></a>\n\n"},{"metadata":{},"cell_type":"markdown","source":"## Variables Overview<a id=\"cell2\"></a>\n\nThe dataset is used for this competition is synthetic but based on a real dataset and generated using a CTGAN. The original dataset deals with predicting the amount of an insurance claim. Although the features are anonymized, they have properties relating to real-world features."},{"metadata":{},"cell_type":"markdown","source":"## Importaing relevant libraries<a id=\"cell3\"></a>"},{"metadata":{"trusted":false},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport statsmodels.api as sm\nfrom sklearn.metrics import confusion_matrix\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Importing dataset<a id=\"cell4\"></a>"},{"metadata":{"trusted":false},"cell_type":"code","source":"raw_data = pd.read_csv('train.csv')\nraw_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Pre-proccesing <a id=\"cell5\"></a>"},{"metadata":{"trusted":false},"cell_type":"code","source":"#Checking for Null values \nraw_data.isnull().sum()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"cleaned_data=raw_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Type Check"},{"metadata":{"trusted":false},"cell_type":"code","source":"#i check the data types of the features to better categorize between categorical varibles and numerical variables\ncleaned_data.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### New numerical Dataframe"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Droping all the catigorical featueres and creating a new dataframe with only the target, id and numerical values\ndata_num = cleaned_data.drop(['cat0','cat1','cat2','cat3','cat4','cat5','cat6','cat7','cat8','cat9','cat10','cat11','cat12','cat13','cat14','cat15','cat16','cat17','cat18'],axis=1)\ndata_num\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### New categorical Dataframe"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Droping all the numerical featueres and creating a new dataframe with only the target, id and numerical values\ndata_cat = cleaned_data.drop(['cont0','cont1','cont2','cont3','cont4','cont5','cont6','cont7','cont8','cont9','cont10'],axis=1)\ndata_cat","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Numerical Visualazation"},{"metadata":{},"cell_type":"markdown","source":"### Categorical Features Visualaziton \nThe first thing i notic is that a couple of the featus have high unique values, which make it diffcult for creating dummies, so \ni try and see how i can segement these categorial features"},{"metadata":{"trusted":false},"cell_type":"code","source":"data_cat.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Input and targets<a id=\"cell7\"></a>\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"targets = cleaned_data['target']\ninputs = cleaned_data.drop(['target'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train, test , Split<a id=\"cell8\"></a>"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(inputs,targets,test_size= 0.30,random_state=9)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Enginering  Count Encoding"},{"metadata":{"trusted":false},"cell_type":"code","source":"from feature_engine.encoding import CountFrequencyEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"enc = CountFrequencyEncoder()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"enc.fit(x_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"x_train_enc = enc.transform(x_train)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"x_train_enc ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Selection "},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.feature_selection import SelectKBest","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"bestfeatures = SelectKBest(k=20)\nfit = bestfeatures.fit(x_train_enc,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"dfscore = pd.DataFrame(fit.scores_)\ndfcolumns = pd.DataFrame(x_train_enc.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"feature = pd.concat([dfcolumns,dfscore],axis=1)\nfeature.columns = ['feature','Score']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Plot\nx_featued_sel = feature.nlargest(20, 'Score')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.barplot(y=x_featued_sel['feature'], x=x_featued_sel['Score'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"##Dropping all low performing features\nx_cleaned = x_train_enc.drop(['cont0','cont4','cont7','cont9','cont10','cat2','cat3','cat5','cat7','cat8','cat10','cat12','cont2'],axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"x_cleaned","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Scaling "},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nscaler.fit(x_cleaned)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"scaler.transform(x_cleaned)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Selection <a id=\"cell9\"></a>"},{"metadata":{},"cell_type":"markdown","source":"### Logistic model"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlgr= LogisticRegression()\nlgr.fit(x_cleaned,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_pred_lgr = lgr.predict(x_cleaned)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sc_reg_lgr=confusion_matrix(y_train, y_pred_lgr)\nsc_lgr = np.array(sc_reg_lgr)\naccuracy_score_lgr = (sc_lgr[0,0]+sc_lgr[1,1])/sc_lgr.sum()\naccuracy_score_lgr","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## KNeighborsClassifier"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics\n\nknc = KNeighborsClassifier(n_neighbors=5)\nknc.fit(x_cleaned,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_pred_knn = knc.predict(x_cleaned)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sc_conf_knc=confusion_matrix(y_train, y_pred_knn)\nsc_knc = np.array(sc_conf_knc)\naccuracy_score_knc = (sc_knc[0,0]+sc_knc[1,1])/sc_knc.sum()\naccuracy_score_knc","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier(criterion='gini',max_depth=40,max_features='auto')\nrfc.fit(x_cleaned,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_pred_rfc = rfc.predict(x_cleaned)\ny_pred_rfc","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sc_confr_rfc=confusion_matrix(y_train, y_pred_rfc)\nsc_rfc = np.array(sc_confr_rfc)\naccuracy_score_rfc = (sc_rfc[0,0]+sc_rfc[1,1])/sc_rfc.sum()\naccuracy_score_rfc","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Hyperparameter"},{"metadata":{"trusted":false},"cell_type":"code","source":"#parameters\nfrom sklearn.model_selection import RandomizedSearchCV\nrandom_grid_par = {\n'criterion' : [\"gini\", \"entropy\"],\n'max_features': ['auto', 'sqrt'],\n'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n'min_samples_split': [2, 5, 10],\n'min_samples_leaf': [1, 2, 4],\n'bootstrap': [True, False]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"rfc_rg = RandomizedSearchCV(estimator = rfc, param_distributions = random_grid_par, cv = 10, verbose=2, n_jobs = 6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"rfc_rg.fit(x_cleaned,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"rfc_rg.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"rfc_rg.best_score_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Ridge Classifer"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.linear_model import RidgeClassifier\nrc = RidgeClassifier()\nrc.fit(x_cleaned,y_train)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_pred_rc = rc.predict(x_cleaned)\ny_pred_rc","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sc_conf_rc=confusion_matrix(y_train, y_pred_rc)\nsc_rc = np.array(sc_conf_rc)\naccuracy_score_rc = (sc_rc[0,0]+sc_rc[1,1])/sc_rc.sum()\naccuracy_score_rc","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SVC"},{"metadata":{},"cell_type":"markdown","source":"from sklearn.svm import SVC"},{"metadata":{},"cell_type":"markdown","source":"svc = SVC()\nsvc.fit(x_cleaned,y_train)\n\n"},{"metadata":{},"cell_type":"markdown","source":"y_pred_svc = rc.predict(x_train)\ny_pred_svc"},{"metadata":{},"cell_type":"markdown","source":"sc_conf_svc=confusion_matrix(y_train, y_pred_svc)\nsc_svc = np.array(sc_conf_svc)\naccuracy_score_svc = (sc_svc[0,0]+sc_svc[1,1])/sc_svc.sum()\naccuracy_score_svc"},{"metadata":{},"cell_type":"markdown","source":"### Hyper Parameter Tuning SVC"},{"metadata":{},"cell_type":"markdown","source":"grid = {\n    'c': [1. 10, 100, 100]\n    'kernel': ['rbf','linear']\n    'gama':[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n}\n"},{"metadata":{},"cell_type":"markdown","source":"grid_search_cv = GridSearchCV(SVC(), param_grid=grid, scoring='accuracy')"},{"metadata":{},"cell_type":"markdown","source":"## Test data "},{"metadata":{"trusted":false},"cell_type":"code","source":"test_data = pd.read_csv('test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"enc.fit(test_data)\nx_test = enc.transform(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"x_test = x_test.drop(['cont0','cont4','cont7','cont9','cont10','cat2','cat3','cat5','cat7','cat8','cat10','cat12','cont2'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"pred_values = rc.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"pred_values","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"pid = test_data['id']\npid","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"output = pd.DataFrame(pid, columns=['id'])\noutput['target'] = pred_values\noutput","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"output.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output.to_csv(r'C:\\Users\\Hugo\\Desktop\\output.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}