{"cells":[{"metadata":{},"cell_type":"markdown","source":"# LightGBM in Action \n\nWe will perform a LightGBM model to generate an accuracy prediction to submit in the [Tabular Playground Series - Mar 2021 Competition](https://www.kaggle.com/c/tabular-playground-series-mar-2021). We will use a LightGBM model due to its advantages such as speed and accuracy working wiht large datasets."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Import packages\nimport numpy as np # Handling matrices\nimport pandas as pd # Data processing\nimport matplotlib.pyplot as plt # Plotting\nimport seaborn as sns # Plotting \nfrom sklearn.preprocessing import OneHotEncoder, MinMaxScaler, LabelEncoder # Handling categorical data and normalization\nfrom sklearn.model_selection import train_test_split # Split data in train and test\nfrom sklearn.metrics import roc_auc_score,precision_score,confusion_matrix, accuracy_score, roc_curve, f1_score # Several useful metrics\nimport lightgbm as lgb # LightGBM\n\n# Set matplotlib configuration\n%matplotlib inline\nplt.style.use('seaborn')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1) Review and analysis of data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import data\ndata = pd.read_csv('../input/tabular-playground-series-mar-2021/train.csv')\nprint(\"This dataset contains: {} rows and {} columns\".format(data.shape[0],data.shape[1]))\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Review the type of each feature\ndata.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Count the type of features\ndata.dtypes.value_counts()\nprint('This dataset contains {} categorical features'.format(data.dtypes.value_counts()[0]))\nprint('This dataset contains {} numerical features'.format(data.dtypes.value_counts()[1]))\n\n# Id and target are the unique integer features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Analyse missing values\ndata.isna().sum()\n\n# Do not have missing values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Identify categorical features\ncat = (data.dtypes == 'object')\ncat_cols = list(cat[cat].index)\nprint(cat_cols)\n\n# Create a handful of plots\nfor cols in cat_cols:\n    plt.figure(figsize=(8,4));\n    sns.countplot(x = data[cols]);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a list of numerical_cols\nnumerical_cols = [cname for cname in data.columns if data[cname].dtype in ['float64']]\n\n# Also, we can see how numerical features are related with the target\ndata[numerical_cols].hist(bins=15, figsize=(20, 14), layout=(7, 3));","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that our categorical and numeric features have different behaviours. We have categorical features with low and high number of classes, while our numerical feature are different distributions. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Analyse our target colum\ndata['target'].hist(bins=15, figsize=(12,6));\n\n# We observe that our data is unbalanced. This is an important point.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2) Create a model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separate independent features of target\ny = data['target']\nX = data.drop(['id','target'],axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LightGBM also can handle categorical data directly We go to probe its inner method\n\n# Transform categorical features into the appropriate type that is expected by LightGBM\nfor c in X.columns:\n    col_type = X[c].dtype\n    if col_type == 'object' or col_type.name == 'category':\n        X[c] = X[c].astype('category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Divide data into training and validation subsets. We use parameters stratify to ensure our data is split maintain the proportion of output classes\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, \n                                                                test_size=0.2,random_state = 123,stratify = y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print proportion of entire dataset\nprint(\"Proportion of classes in entire data: \")\nprint(100. * y.value_counts() / len(y),\"\\n\")\n\n# Print proportion of train and test sets \nprint(\"Proportion of classes in train data: \")\nprint(100. * y_train.value_counts() / len(y_train),\"\\n\")\nprint(\"Proportion of classes in valid data: \")\nprint(100. * y_valid.value_counts() / len(y_valid))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create the model \nd_train=lgb.Dataset(X_train, label=y_train) #Specifying the parameter\nparams={}\nparams['learning_rate']=0.05 # Learning rate \nparams['boosting_type']='gbdt' # GradientBoostingDecisionTree\nparams['objective']='binary' # Binary target feature\nparams['metric']='auc' # Metric for binary classification\nparams['max_depth']=500, # Set depth\nparams['bagging_fraction'] = 0.6,\nparams['force_row_wise'] = True, # Need to the model\nparams['unbalance'] =True, # To consider an unbalanced dataset\nparams['num_leaves'] = 100\nclf=lgb.train(params,d_train,200) # Train the model on 200 epocs\n\n# Prediction on the valid set\ny_pred=clf.predict(X_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to plot ROC curve\ndef plot_roc_curve(fpr, tpr):\n    plt.plot(fpr, tpr, color='orange', label='ROC')\n    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend()\n    plt.show()\n\nfpr, tpr, thresholds = roc_curve(y_valid, y_pred)\nplot_roc_curve(fpr, tpr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create Confusion Matrix\npred_class = y_pred > 0.5\npred_class = pred_class.astype(int)\ncm = confusion_matrix(y_valid, pred_class)\nprint(\"Confusion matrix: \\n\",cm,\"\\n\")\n\n# Get accuracy\naccuracy = round(accuracy_score(y_valid,pred_class),4)\nprint(\"Accuracy: {}\".format(accuracy),\"\\n\")\n\n# Get f1 score (it is required on the Task 1 of this dataset)\nf1 = f1_score(y_valid,pred_class)\nprint(\"F1: {}\".format(f1),\"\\n\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# See the feature importance\nimportance_feature = pd.DataFrame({'Value':clf.feature_importance(),'Feature':clf.feature_name()}).sort_values(by=\"Value\", ascending=False)\n\n# Create a plot\nplt.figure(figsize=(20, 10))\nsns.barplot(x = 'Value',y = 'Feature',data = importance_feature);\nplt.title(\"Importance feature\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3) Use model in test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load test data\ntest = pd.read_csv(\"../input/tabular-playground-series-mar-2021/test.csv\")\ntest.head()\n\n# Remove id\nX_test = test.drop(\"id\",axis = 1)\n\n# Transform categorical features into the appropriate type that is expected by LightGBM\nfor c in X_test.columns:\n    col_type = X_test[c].dtype\n    if col_type == 'object' or col_type.name == 'category':\n        X_test[c] = X_test[c].astype('category')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prediction on the valid set\ntest_pred=clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4) Write results"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create submission file\noutput = test[['id']].copy()\noutput['target'] = pd.Series(test_pred, index=output.index)\noutput.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# write csv\noutput.to_csv(\"submissionv1.csv\",index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}