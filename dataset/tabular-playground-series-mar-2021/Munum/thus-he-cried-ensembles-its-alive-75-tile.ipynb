{"cells":[{"metadata":{},"cell_type":"markdown","source":"**The rationale of this notebook is very simple - to demonstrate the power of ensembles. Through this notebook you will see how just blending thousands of *default* ensembles you can still get excellent results. Is this practical? Depends, how many cores do you have? This is more of an interesting phenomenon if anything. If you have any academic research supporting why 'Extreme Ensembling' works so well, please link below.**"},{"metadata":{},"cell_type":"markdown","source":"# **The good stuff is always imported :)**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.set_style('darkgrid')\nsns.set(rc={'figure.figsize':(15, 10)})\n\nfrom tqdm import tqdm\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom catboost import CatBoostClassifier\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\n\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.metrics import accuracy_score, precision_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, RobustScaler\n\nRS = 69420\nDATA_PATH = \"../input/tabular-playground-series-mar-2021/train.csv\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Load the data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(DATA_PATH, index_col=0)\n\ncat_features = [c for c in train.columns if 'cat' in c]\nle = LabelEncoder()\nfor col in cat_features:\n    train[col] = le.fit_transform(train[col])\n\nX = train.iloc[:, :-1].values\ny = train.iloc[:, -1].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RS, shuffle=True, stratify=y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Robust Scaling Because why tf not**"},{"metadata":{"trusted":true},"cell_type":"code","source":"sc = RobustScaler(with_centering=False)\n\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ***Extreme Ensemble***"},{"metadata":{"trusted":true},"cell_type":"code","source":"estimators = []\nfor i in range(1500):\n    model1 = LGBMClassifier(device='gpu',\n                            verbose=0,\n                            random_seed=np.random.randint(0, 100000))\n\n    model2 = XGBClassifier(objective='binary:logistic',\n                           predictor = 'gpu_predictor',\n                           tree_method = 'gpu_hist',\n                           verbose=None,\n                           random_state=np.random.randint(0, 100000))\n    \n    model3 = CatBoostClassifier(task_type=\"GPU\",\n                                devices='0:1',\n                                verbose=None,\n                                random_seed=np.random.randint(0, 100000))\n    \n    estimators.append((f\"lgbm_model{i}\", model1))\n    estimators.append((f\"xgb_model{i}\", model2))\n    estimators.append((f\"cat_model{i}\", model3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**With the range set to only 3 we can get an unseen score of 0.88557 putting you in the top 50% - with a default model! Imagine after tuning :) (Hint thats what I did)**"},{"metadata":{},"cell_type":"markdown","source":"# **Build, Train, Test Voting Classifier**"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = VotingClassifier(estimators=estimators,\n                       verbose=1,\n                       voting='soft')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nclf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Predict\n# y_pred = clf.predict(X_test)\n\n# # Compute Metrics\n# print(f\"Testing Precision: {precision_score(y_test, y_pred, 'weighted')}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Predict Unseen Data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(\"../input/tabular-playground-series-mar-2021/test.csv\", index_col=0)\n\nfor col in cat_features:\n    test[col] = le.fit_transform(test[col])\n\nsubmission = pd.DataFrame(index=test.index)\n\ntest = sc.transform(test.values)\n\nsubmission['target'] = clf.predict_proba(test)[:, 1]\n\nsubmission.to_csv(\"submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Ensemble is served!\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"****"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}