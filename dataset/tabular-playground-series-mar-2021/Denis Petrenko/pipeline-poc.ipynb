{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Notebook goal: \nThis notebook try to simplify experiments with models, feature selection, and hyperparameter tuning by using sklearn pipeline.\nIn case it was useful, you know what to do :-)"},{"metadata":{"run_control":{"marked":false},"trusted":false},"cell_type":"code","source":"import os\n\nimport pandas as pd\nimport numpy as np\n\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_rows', 500)\npd.set_option('display.float_format', lambda x: '%.6f' % x)\n\nfrom sklearn.dummy import DummyClassifier\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import MinMaxScaler, OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import make_scorer\nfrom sklearn.ensemble import  RandomForestClassifier\n\nfrom sklearn.feature_selection import SelectFromModel, SelectPercentile\n\nfrom xgboost import XGBClassifier","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Settings"},{"metadata":{"trusted":false},"cell_type":"code","source":"RANDOM_STATE = 42\nOUTPUT_NAME = 'submission_pipeline_poc'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data"},{"metadata":{"trusted":false},"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\ndata = pd.read_csv(os.path.join(dirname,'train.csv'), index_col='id')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Pipeline"},{"metadata":{"trusted":false},"cell_type":"code","source":"numeric_features = [col for col in data.columns if 'cont' in col]\nnumeric_transformer = Pipeline(\n    steps=[('scaler', MinMaxScaler())]\n)\n\ncat_features = [col for col in data.columns if 'cat' in col]\ncat_transformer = OneHotEncoder(handle_unknown='ignore')\n\npreprocessor = ColumnTransformer(\n    sparse_threshold=0,\n    transformers=[\n        ('num', numeric_transformer, numeric_features),\n        ('cat', cat_transformer, cat_features),\n    ]\n)\n\nmodel = XGBClassifier(n_estimators=100)\nmodel = Pipeline(steps=[\n    ('preprocessor', preprocessor), \n    ('f_selection', SelectPercentile(percentile=75)),\n#     ('f_selection', SelectFromModel(RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE))),\n    ('model', model),\n\n])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"\nx_train, x_test, y_train, y_test = train_test_split(data.drop(columns=['target']), data['target'],\n                                                  test_size=0.25, random_state=0, \n                                                  )\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Grid search"},{"metadata":{"run_control":{"marked":false},"scrolled":false,"trusted":false},"cell_type":"code","source":"%%time\nparam_grid ={\n    'f_selection__percentile': [50, 75, 90, 95],\n    'model__max_depth': [8, 12, 16],\n#     'model__n_estimators': [100, 120],\n}\nsearch = GridSearchCV(model, param_grid, n_jobs=4, scoring=make_scorer(roc_auc_score))\nsearch.fit(x_train, y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\nprint(search.best_params_)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model.set_params(**search.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time\nmodel.fit(x_train, y_train)\n\ny_pred = model.predict(x_test)\nmetric_dev = roc_auc_score(y_test, y_pred)\nmetric_train = roc_auc_score(y_train, model.predict(x_train))\nprint(f'metric_train = {metric_train:.5} \\n  metric_dev = {metric_dev:.5}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Build prediction "},{"metadata":{"trusted":false},"cell_type":"code","source":"model.fit(data.drop(columns=['target']), data['target'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test = pd.read_csv(os.path.join(dirname, 'test.csv'), index_col='id')\nsubmission = test[[]]\nsubmission['target'] = model.predict(test)\nsubmission.to_csv(f'/kaggle/working/{OUTPUT_NAME}.csv', index=True, index_label='id')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Notes\nWe have a table below where we could track our progress"},{"metadata":{"trusted":false},"cell_type":"code","source":"print(f'{metric_train:.5} | {metric_dev:.5} | *kaggle_score* | {OUTPUT_NAME}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Model progress:\n\n train | dev | kaggle | comment \n-------|-----|--------|---------\n0.50088 | 0.49967 | *-* | submission_pipeline_dummy\n\n\n    "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}