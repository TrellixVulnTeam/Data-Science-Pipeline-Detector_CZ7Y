{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-01T01:12:48.190168Z","iopub.execute_input":"2021-06-01T01:12:48.190484Z","iopub.status.idle":"2021-06-01T01:12:48.198613Z","shell.execute_reply.started":"2021-06-01T01:12:48.190459Z","shell.execute_reply":"2021-06-01T01:12:48.197618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Предсказание target значения\n## Импорт данных\n### Первым делом в нашей работе будет импорт данных. Импортировать данные мы будем с помощью команды read_csv у библиотеки pandas. Для данных создадим две переменные: train_df, test_df. Также в нашем распоряжении будет пример того, как мы должны будем сохранить наш ответ в системе kaggle. ","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/tabular-playground-series-mar-2021/train.csv')                      # Переменная для обучения\ntest_df = pd.read_csv('/kaggle/input/tabular-playground-series-mar-2021/test.csv')                        # Переменная для тестирования\nsample_submission = pd.read_csv('/kaggle/input/tabular-playground-series-mar-2021/sample_submission.csv') # Пример того, как должен быть оформлен ответ","metadata":{"execution":{"iopub.status.busy":"2021-06-01T01:12:51.009429Z","iopub.execute_input":"2021-06-01T01:12:51.009795Z","iopub.status.idle":"2021-06-01T01:12:54.288599Z","shell.execute_reply.started":"2021-06-01T01:12:51.009766Z","shell.execute_reply":"2021-06-01T01:12:54.287837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Анализ данных\n### После импорта данных нужно проверить наши датасеты на соответствие описанию. Сделаем это с помощью команды head() - первые значения (по умолчанию = 5)","metadata":{}},{"cell_type":"code","source":"train_df.head()        # Первые пять значений тренировочного датасета","metadata":{"execution":{"iopub.status.busy":"2021-06-01T01:12:55.660121Z","iopub.execute_input":"2021-06-01T01:12:55.660455Z","iopub.status.idle":"2021-06-01T01:12:55.70352Z","shell.execute_reply.started":"2021-06-01T01:12:55.660428Z","shell.execute_reply":"2021-06-01T01:12:55.702712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head()         # Первые пять значений тестового значения","metadata":{"execution":{"iopub.status.busy":"2021-06-01T01:12:56.896549Z","iopub.execute_input":"2021-06-01T01:12:56.896936Z","iopub.status.idle":"2021-06-01T01:12:56.924883Z","shell.execute_reply.started":"2021-06-01T01:12:56.896895Z","shell.execute_reply":"2021-06-01T01:12:56.923568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission.head()  # Первые пять значений примерного ответа ","metadata":{"execution":{"iopub.status.busy":"2021-06-01T01:12:57.982345Z","iopub.execute_input":"2021-06-01T01:12:57.982691Z","iopub.status.idle":"2021-06-01T01:12:57.993056Z","shell.execute_reply.started":"2021-06-01T01:12:57.98266Z","shell.execute_reply":"2021-06-01T01:12:57.992258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Далее нужно проверить типы данных в наших датасетах. Это можно узнать с помощью команды info","metadata":{}},{"cell_type":"code","source":"train_df.info()       # Неполная информация о тренировочном датасете ","metadata":{"execution":{"iopub.status.busy":"2021-06-01T01:13:01.635628Z","iopub.execute_input":"2021-06-01T01:13:01.635963Z","iopub.status.idle":"2021-06-01T01:13:02.123498Z","shell.execute_reply.started":"2021-06-01T01:13:01.635936Z","shell.execute_reply":"2021-06-01T01:13:02.122593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.info()      # Неполная информация о тестовом датасете ","metadata":{"execution":{"iopub.status.busy":"2021-06-01T01:13:03.206511Z","iopub.execute_input":"2021-06-01T01:13:03.206926Z","iopub.status.idle":"2021-06-01T01:13:03.527454Z","shell.execute_reply.started":"2021-06-01T01:13:03.206885Z","shell.execute_reply":"2021-06-01T01:13:03.526486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Как видно, в наших датасетах полный набор данных, пропусков нигде не видно, типы данных приведены верно, а в тестовой таблице отсутствует target значения. Данные в идеальном состоянии, необходимо лишь преобразовать категорийные данные в числовые","metadata":{}},{"cell_type":"markdown","source":"## Преобразование данных\n### У нас имеются данные категорийного типа, которые будут мешать нашему алгоритму работать, ведь работа с текстовой инфомрацией довольно муторная и долгая. Поэтому нам нужно преобразовать их в численные данные, а делать это мы будем с помощью one hot encoding","metadata":{}},{"cell_type":"code","source":"all_df = pd.concat([train_df[train_df.columns[:-1]], test_df])\ny = train_df['target']","metadata":{"execution":{"iopub.status.busy":"2021-06-01T01:13:06.344631Z","iopub.execute_input":"2021-06-01T01:13:06.344996Z","iopub.status.idle":"2021-06-01T01:13:06.554644Z","shell.execute_reply.started":"2021-06-01T01:13:06.344966Z","shell.execute_reply":"2021-06-01T01:13:06.553485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#categorical_df = all_df[all_df.columns[1:20]].copy()\n#categorical_df.head()\n\ncategorical_columns = all_df.columns[1:20]\ncategorical_columns","metadata":{"execution":{"iopub.status.busy":"2021-06-01T01:13:08.121563Z","iopub.execute_input":"2021-06-01T01:13:08.121945Z","iopub.status.idle":"2021-06-01T01:13:08.128607Z","shell.execute_reply.started":"2021-06-01T01:13:08.121884Z","shell.execute_reply":"2021-06-01T01:13:08.127968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for column in categorical_columns:\n    print(all_df[column].value_counts().count())","metadata":{"execution":{"iopub.status.busy":"2021-06-01T01:13:39.764647Z","iopub.execute_input":"2021-06-01T01:13:39.765127Z","iopub.status.idle":"2021-06-01T01:13:41.502037Z","shell.execute_reply.started":"2021-06-01T01:13:39.765088Z","shell.execute_reply":"2021-06-01T01:13:41.501013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def onehot_encode(df, column):\n    df = df.copy()\n    dummies = pd.get_dummies(df[column], prefix=column, drop_first = True)\n    df = pd.concat([df, dummies], axis=1)\n    df = df.drop(column, axis=1)\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-06-01T01:13:43.6709Z","iopub.execute_input":"2021-06-01T01:13:43.671195Z","iopub.status.idle":"2021-06-01T01:13:43.676672Z","shell.execute_reply.started":"2021-06-01T01:13:43.67117Z","shell.execute_reply":"2021-06-01T01:13:43.675795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# all_dummies = []\n# for column in categorical_columns:\n#      all_dummies.append(onehot_encode(all_df,column))\n        \nfor column in categorical_columns:\n    all_df = onehot_encode(all_df, column)","metadata":{"execution":{"iopub.status.busy":"2021-06-01T01:13:45.189601Z","iopub.execute_input":"2021-06-01T01:13:45.190068Z","iopub.status.idle":"2021-06-01T01:13:58.871502Z","shell.execute_reply.started":"2021-06-01T01:13:45.190033Z","shell.execute_reply":"2021-06-01T01:13:58.870556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-01T01:14:01.233054Z","iopub.execute_input":"2021-06-01T01:14:01.233388Z","iopub.status.idle":"2021-06-01T01:14:01.258291Z","shell.execute_reply.started":"2021-06-01T01:14:01.233359Z","shell.execute_reply":"2021-06-01T01:14:01.257432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = all_df[:len(train_df)]\ntest_df = all_df[len(train_df):]\n\ntrain_df.shape, test_df.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-01T01:14:06.371726Z","iopub.execute_input":"2021-06-01T01:14:06.372103Z","iopub.status.idle":"2021-06-01T01:14:06.378827Z","shell.execute_reply.started":"2021-06-01T01:14:06.372071Z","shell.execute_reply":"2021-06-01T01:14:06.377887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Обучение модели\n### Перед тем как начать обучение моделей, мы должны разделить данные командой train_test_split, которую мы импортируем из skle","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(train_df, y, test_size = 0.2, random_state = 451) # Делим данные на обучающие и предсказываемые","metadata":{"execution":{"iopub.status.busy":"2021-06-01T01:14:09.846266Z","iopub.execute_input":"2021-06-01T01:14:09.846866Z","iopub.status.idle":"2021-06-01T01:14:11.853163Z","shell.execute_reply.started":"2021-06-01T01:14:09.846825Z","shell.execute_reply":"2021-06-01T01:14:11.852424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.head()                 # Первые пять значений тренировочных обучающих данных","metadata":{"execution":{"iopub.status.busy":"2021-06-01T01:14:14.826327Z","iopub.execute_input":"2021-06-01T01:14:14.826917Z","iopub.status.idle":"2021-06-01T01:14:14.851697Z","shell.execute_reply.started":"2021-06-01T01:14:14.826868Z","shell.execute_reply":"2021-06-01T01:14:14.850995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train.head()                 # Первые пять значений тренировочных предсказываемых данных","metadata":{"execution":{"iopub.status.busy":"2021-06-01T01:14:15.240017Z","iopub.execute_input":"2021-06-01T01:14:15.240568Z","iopub.status.idle":"2021-06-01T01:14:15.247258Z","shell.execute_reply.started":"2021-06-01T01:14:15.240523Z","shell.execute_reply":"2021-06-01T01:14:15.246336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.metrics import mean_absolute_error, accuracy_score\nfrom xgboost import XGBClassifier","metadata":{"execution":{"iopub.status.busy":"2021-06-01T01:34:50.46182Z","iopub.execute_input":"2021-06-01T01:34:50.46218Z","iopub.status.idle":"2021-06-01T01:34:50.46625Z","shell.execute_reply.started":"2021-06-01T01:34:50.462151Z","shell.execute_reply":"2021-06-01T01:34:50.465547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Сейчас мы будем обучать модель и смотреть качество предсказаний. Для более гибкой работы создадим цикл, который будет перебирать наши модели \n1. Логистическая регрессия\n2. Дерево решений (классификация)\n3. Случайный лес (классификация)\n### В качестве метрики качества будем использовать accuracy score.\n### Та модель, что даст нам лучший результат будет выписана в отедльную строку вместе со своим результатом","metadata":{}},{"cell_type":"code","source":"models = [LogisticRegression(),\n         DecisionTreeClassifier(),\n         RandomForestClassifier(),\n         GradientBoostingClassifier(),\n         XGBClassifier()]\n\nbest_model = ''\nbest_score = -100\n\nfor model in models:\n    \n    model.fit(X_train, y_train)\n    predictions = model.predict(X_test)\n    scores = accuracy_score(y_test, predictions)\n    print(f\"The model: {model}has following score: {scores}\")\n    \n    if scores > best_score:\n        best_score = scores\n        best_model = model\n        \nprint(f\"\\nThe best model is {best_model} it has the {best_score} scores\")","metadata":{"execution":{"iopub.status.busy":"2021-06-01T01:34:59.327029Z","iopub.execute_input":"2021-06-01T01:34:59.327474Z","iopub.status.idle":"2021-06-01T01:47:34.096042Z","shell.execute_reply.started":"2021-06-01T01:34:59.327447Z","shell.execute_reply":"2021-06-01T01:47:34.095185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Как видно, лучший результат показал случайный лес - 84.7 процентов качества. Результат отличный, осталось попытаться его улучшить. Будем вводить random_state и n_estimators","metadata":{}},{"cell_type":"code","source":"best_model = RandomForestClassifier(random_state = 451, n_estimators = 300)\nbest_model.fit(X_train, y_train)\npredictions = best_model.predict(X_test)\nscores = accuracy_score(y_test, predictions)\nscores","metadata":{"execution":{"iopub.status.busy":"2021-06-01T01:56:29.979047Z","iopub.execute_input":"2021-06-01T01:56:29.979484Z","iopub.status.idle":"2021-06-01T02:04:21.426117Z","shell.execute_reply.started":"2021-06-01T01:56:29.979454Z","shell.execute_reply":"2021-06-01T02:04:21.425252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### К сожалению наша модель показала незначительный прирост в 0.02 процента, что не очень практично, однако результат есть результат. Теперь нам нужно дать нашей модели тестовые данные и записать ответ","metadata":{}},{"cell_type":"code","source":"test_predictions = best_model.predict(test_df)\ntest_predictions","metadata":{"execution":{"iopub.status.busy":"2021-06-01T02:18:54.628655Z","iopub.execute_input":"2021-06-01T02:18:54.629384Z","iopub.status.idle":"2021-06-01T02:19:25.662216Z","shell.execute_reply.started":"2021-06-01T02:18:54.629347Z","shell.execute_reply":"2021-06-01T02:19:25.66137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Ответ получился в виде списка, но нам нужно сохранить ответ в датафрейме, при этом с указанием id. Для этого воспользуемся командой DataFrame, которая превратит наши данные в датафрейм","metadata":{}},{"cell_type":"code","source":"prediction_df = pd.DataFrame(data = test_predictions)\nprediction_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-01T02:19:25.663674Z","iopub.execute_input":"2021-06-01T02:19:25.663951Z","iopub.status.idle":"2021-06-01T02:19:25.672998Z","shell.execute_reply.started":"2021-06-01T02:19:25.663917Z","shell.execute_reply":"2021-06-01T02:19:25.671937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Отлично, ответ записан в виде DataFrame, но осталось добавить к нему id. Ну тут просто копируем ","metadata":{}},{"cell_type":"code","source":"prediction_df['id'] = test_df['id'].copy()\nprediction_df.head(15)","metadata":{"execution":{"iopub.status.busy":"2021-06-01T02:27:02.741688Z","iopub.execute_input":"2021-06-01T02:27:02.742108Z","iopub.status.idle":"2021-06-01T02:27:02.758282Z","shell.execute_reply.started":"2021-06-01T02:27:02.742075Z","shell.execute_reply":"2021-06-01T02:27:02.757444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Не порядок, наши id стоят в конце, хотя по примеру должны стоять впереди. Но это можно исправить с помощью команды tolist и дальнейших преобразований","metadata":{}},{"cell_type":"code","source":"cols = prediction_df.columns.tolist()\ncols = cols[-1:] + cols[:-1]\nprediction_df = prediction_df[cols]\nprediction_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-01T02:27:04.652014Z","iopub.execute_input":"2021-06-01T02:27:04.652422Z","iopub.status.idle":"2021-06-01T02:27:04.665157Z","shell.execute_reply.started":"2021-06-01T02:27:04.652391Z","shell.execute_reply":"2021-06-01T02:27:04.66408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### И вот, наш ответ готов и его можно смело отправлять на проверку","metadata":{}}]}