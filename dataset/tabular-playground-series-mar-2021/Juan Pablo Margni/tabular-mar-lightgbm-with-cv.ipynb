{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"LightGBM with CV\n* This notebook scores aprox. 0.89200 (depends on random seed)\n* To optimze parameters use this script: https://www.kaggle.com/jmargni/tabular-mar-lightgbm-hyperopt\n* LightGBM parameters are from hyperopt result with loss of -0.89918 using the link above. Obtaining loss values near -1 will improve final score.\n* Find the best parameters combination and climb to the top. Good luck!!! ;-)\n\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom keras.utils import np_utils\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, LabelBinarizer, StandardScaler\nfrom sklearn.model_selection import train_test_split, KFold, StratifiedKFold\nfrom sklearn.metrics import accuracy_score, mean_squared_error, make_scorer, roc_auc_score\nimport lightgbm as lgb\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"ExecuteTime":{"end_time":"2021-03-23T22:04:43.673829Z","start_time":"2021-03-23T22:04:43.669979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# All categorical features encoded onehot \ndef preprocess(df):\n    categorical_cols = [c for c in df.columns if 'cat' in c]\n    numerical_cols = [c for c in df.columns if 'cat' not in c]\n    \n    onehot_encoded_df = pd.get_dummies(df[categorical_cols])\n    numerical_df = df[numerical_cols]\n    \n    return pd.concat([numerical_df, onehot_encoded_df], axis=1)","metadata":{"ExecuteTime":{"end_time":"2021-03-23T22:04:45.352055Z","start_time":"2021-03-23T22:04:45.345401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/tabular-playground-series-mar-2021/train.csv')\ntest_df = pd.read_csv('../input/tabular-playground-series-mar-2021/test.csv')","metadata":{"ExecuteTime":{"end_time":"2021-03-23T22:04:51.660129Z","start_time":"2021-03-23T22:04:47.394964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_size = train_df.shape[0]\ntest_size = test_df.shape[0]\nall_data = pd.concat([train_df, test_df])","metadata":{"ExecuteTime":{"end_time":"2021-03-23T22:04:52.865339Z","start_time":"2021-03-23T22:04:52.697971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_data = preprocess(all_data)\ntrain_data = all_data[:train_size]\ntest_data = all_data[train_size:].drop(columns=['target'])","metadata":{"ExecuteTime":{"end_time":"2021-03-23T22:04:59.110562Z","start_time":"2021-03-23T22:04:54.588343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = train_data.target.values\nX = train_data.drop(columns=['id', 'target'])\nX_ = test_data.drop(columns='id')","metadata":{"ExecuteTime":{"end_time":"2021-03-23T22:05:00.308398Z","start_time":"2021-03-23T22:04:59.815157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {\n    'lambda': 0.0001,\n    'learning_rate': 0.007930236488607134,\n    'max_bin': 270,\n    'max_depth': 98,\n    'metric': 'auc',\n    'min_data_in_leaf': 60,\n    'n_estimators': 20000,\n    'num_leaves': 263,\n    'objective': 'binary',\n    'sub_feature': 0.2098021977637481\n}","metadata":{"ExecuteTime":{"end_time":"2021-03-23T22:05:01.487563Z","start_time":"2021-03-23T22:05:01.484005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"folds = KFold(n_splits = 50, shuffle=True)\noof = np.zeros(X.shape[0])\npredictions = np.zeros(X_.shape[0])","metadata":{"ExecuteTime":{"end_time":"2021-03-23T22:05:02.321892Z","start_time":"2021-03-23T22:05:02.317573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for fold_, (trn_idx, val_idx) in enumerate(folds.split(X, y)):\n    print(\"Fold {}\".format(fold_))\n    X_train = X.iloc[trn_idx]\n    y_train = y[trn_idx]\n    X_test = X.iloc[val_idx]\n    y_test = y[val_idx]\n    clf = lgb.LGBMClassifier(**params, random_state=42)\n    clf.fit(X_train, y_train, eval_set=[(X_train, y_train),(X_test, y_test)],\n        eval_metric='auc', early_stopping_rounds=250, verbose=250  )\n    predictions += clf.predict_proba(X_, num_iteration=clf.best_iteration_)[:,1] / folds.n_splits","metadata":{"ExecuteTime":{"end_time":"2021-03-23T22:05:47.620943Z","start_time":"2021-03-23T22:05:14.075034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('../input/tabular-playground-series-mar-2021/sample_submission.csv')\nsubmission = pd.concat([submission, pd.DataFrame(predictions)], axis=1).drop(columns='target')\nsubmission.columns = ['id', 'target']\nsubmission.to_csv('submission.csv', index=False)","metadata":{"ExecuteTime":{"end_time":"2021-03-23T21:39:12.777131Z","start_time":"2021-03-23T21:39:11.662616Z"}},"execution_count":null,"outputs":[]}]}