{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Let's try something different than Gradient Boosting...\n\n## Table of Contents\n* [Target Exploration](#1)\n* [Numerical Features](#2)\n* [Categorical Features](#3)\n* [Target vs Features](#4)\n* [Build GLM Model](#5)\n* [Build Random Forest Model](#6)\n* [Predict on Test Set and prepare submissions](#6)","metadata":{}},{"cell_type":"code","source":"# packages\n\n# standard\nimport numpy as np\nimport pandas as pd\nimport time\n\n# plots\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom statsmodels.graphics.mosaicplot import mosaic\n\n# machine learning tools\nimport h2o\nfrom h2o.estimators import H2OGeneralizedLinearEstimator, H2ORandomForestEstimator","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load data + first glance\ndf_train = pd.read_csv('../input/tabular-playground-series-mar-2021/train.csv')\ndf_test = pd.read_csv('../input/tabular-playground-series-mar-2021/test.csv')\ndf_sub = pd.read_csv('../input/tabular-playground-series-mar-2021/sample_submission.csv')\n\n# first glance (training data)\ndf_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dimensions\ndf_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### We are lucky, no missing values!","metadata":{}},{"cell_type":"markdown","source":"<a id='1'></a>\n# Target Exploration","metadata":{}},{"cell_type":"markdown","source":"### This time we have a categorical (binary) target!","metadata":{}},{"cell_type":"code","source":"# basic stats\nprint(df_train.target.value_counts())\ndf_train.target.value_counts().plot(kind='bar')\nplt.grid()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='2'></a>\n# Numerical Features","metadata":{}},{"cell_type":"code","source":"features_num = ['cont0', 'cont1', 'cont2', 'cont3', \n                'cont4', 'cont5', 'cont6', 'cont7',\n                'cont8', 'cont9', 'cont10']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot distribution of numerical features\nfor f in features_num:\n    plt.figure(figsize=(8,4))\n    df_train[f].plot(kind='hist', bins=100)\n    plt.title(f)\n    plt.grid()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Correlations","metadata":{}},{"cell_type":"code","source":"corr_pearson = df_train[features_num].corr(method='pearson')\ncorr_spearman = df_train[features_num].corr(method='spearman')\n\nfig = plt.figure(figsize = (10,8))\nsns.heatmap(corr_pearson, annot=True, cmap='RdYlGn', vmin=-1, vmax=+1)\nplt.title('Pearson Correlation')\nplt.show()\n\nfig = plt.figure(figsize = (10,8))\nsns.heatmap(corr_spearman, annot=True, cmap='RdYlGn', vmin=-1, vmax=+1)\nplt.title('Spearman Correlation')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# example of scatter plot - we pick pair having highest (Pearson) correlation\nsns.jointplot(data=df_train, x='cont1', y='cont2', kind='hex')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='3'></a>\n# Categorical Features","metadata":{}},{"cell_type":"code","source":"features_cat = ['cat0', 'cat1', 'cat2', 'cat3',\n                'cat4', 'cat5', 'cat6', 'cat7',\n                'cat8', 'cat9', 'cat10', 'cat11',\n                'cat12', 'cat13', 'cat14', 'cat15',\n                'cat16', 'cat17', 'cat18']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot distribution of categorical features\nfor f in features_cat:\n    plt.figure(figsize=(14,4))\n    df_train[f].value_counts().plot(kind='bar')\n    plt.title(f)\n    plt.grid()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Well, \"cat10\" has lots of different values, this might require a closer look...","metadata":{}},{"cell_type":"code","source":"# count different values/levels\ncat10_freq = df_train.cat10.value_counts()\nprint(cat10_freq)\n\n# and plot frequency distribution using log scale\nfig, ax = plt.subplots(figsize=(12,4))\nax.plot(np.log10(cat10_freq))\nax.xaxis.set_major_locator(plt.MaxNLocator(20)) # reduce number of x-axis labels\nplt.title('cat10 - Frequencies')\nplt.ylabel('log10(Frequency)')\nplt.grid()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# evaluate mean of target by level\ncat10_target = df_train.groupby(['cat10']).agg({\n    'target' : ['mean','count']})\n# ... and sort by frequency of level\ncat10_target = cat10_target.sort_values([('target','count')], ascending=False)\n\n# plot mean of target by level; bubble area ~ frequency\nfig, ax = plt.subplots(figsize=(12,6))\nax.scatter(cat10_target.index, cat10_target[('target','mean')],\n           s=2*np.sqrt(cat10_target[('target','count')]),\n           alpha = 0.5)\nax.xaxis.set_major_locator(plt.MaxNLocator(20)) # reduce number of x-axis labels\nplt.title('cat10 - Average target by level (bubble area ~ frequency)')\nplt.grid()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### => It could be beneficial to group the less frequent levels (e. g. right of \"CP\") into a group \"other\".","metadata":{}},{"cell_type":"code","source":"# let's give it a try: define levels to be kept\nn_keep = 201\ncat10_keep = cat10_freq[0:n_keep].index.tolist()\nprint(cat10_keep)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# add new column with reduced number of levels\ndf_train['cat10_reduced'] = df_train.cat10.where(df_train.cat10.isin(cat10_keep), '_OTHER_')\ndf_train.cat10_reduced.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check frequency of _OTHER_ category\ndf_train[df_train.cat10_reduced=='_OTHER_'].cat10_reduced.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# same for test set!\ndf_test['cat10_reduced'] = df_test.cat10.where(df_test.cat10.isin(cat10_keep), '_OTHER_')\ndf_test.cat10_reduced.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# update feature list accordingly\nfeatures_cat = ['cat0', 'cat1', 'cat2', 'cat3',\n                'cat4', 'cat5', 'cat6', 'cat7',\n                'cat8', 'cat9', 'cat10_reduced', 'cat11',\n                'cat12', 'cat13', 'cat14', 'cat15',\n                'cat16', 'cat17', 'cat18']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='4'></a>\n# Target vs Features","metadata":{}},{"cell_type":"markdown","source":"## Numerical Features","metadata":{}},{"cell_type":"code","source":"# plot target vs binned numerical features using mosaic plot\nplt_para_save = plt.rcParams['figure.figsize'] # remember plot settings\n\nfor f in features_num:\n    \n    # add binned version of each numerical feature first\n    new_var = f + '_bin'\n    df_train[new_var] = pd.qcut(df_train[f], 10)\n    \n    # then create mosaic plot\n    plt.rcParams[\"figure.figsize\"] = (16,6) # increase plot size for mosaics\n    mosaic(df_train, [new_var, 'target'], title='Target vs ' + f + ' [binned]')\n    plt.show()\n    \n# reset plot size again\nplt.rcParams['figure.figsize'] = plt_para_save","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Categorical Features","metadata":{}},{"cell_type":"code","source":"# plot target vs features using mosaic plot\nplt_para_save = plt.rcParams['figure.figsize'] # remember plot settings\n\nfor f in features_cat:\n    plt.rcParams[\"figure.figsize\"] = (16,6) # increase plot size for mosaics\n    mosaic(df_train, [f, 'target'], title='Target vs ' + f + ' [binned]')\n    plt.show()\n    \n# reset plot size again\nplt.rcParams['figure.figsize'] = plt_para_save","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='5'></a>\n# Build GLM Model","metadata":{}},{"cell_type":"code","source":"# select predictors\npredictors = features_num + features_cat\nprint('Number of predictors: ', len(predictors))\nprint(predictors)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# start H2O\nh2o.init(max_mem_size='12G', nthreads=4) # Use maximum of 12 GB RAM and 4 cores","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# upload data frames in H2O environment\nt1 = time.time()\ntrain_hex = h2o.H2OFrame(df_train)\ntest_hex = h2o.H2OFrame(df_test)\nt2 = time.time()\nprint('Elapsed time [s]: ', np.round(t2-t1,2))\n\n# force categorical target\ntrain_hex['target'] = train_hex['target'].asfactor()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fit GLM model\nn_cv = 5\nfit_1 = H2OGeneralizedLinearEstimator(nfolds=n_cv,\n                                      family='binomial',\n                                      alpha=0,\n                                      Lambda=0,\n                                      seed=999)\n\n# train model\nt1 = time.time()\nfit_1.train(x=predictors,\n            y='target',\n            training_frame=train_hex)\nt2 = time.time()\nprint('Elapsed time [s]: ', np.round(t2-t1,2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show cross validation metrics\nfit_1.cross_validation_metrics_summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Variable Importance","metadata":{}},{"cell_type":"code","source":"# basic version\nfit_1.varimp_plot(20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Check performance on training data / cross validations","metadata":{}},{"cell_type":"code","source":"# training performance\nperf_train = fit_1.model_performance(train=True)\nperf_train.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cross validation performance\nperf_cv = fit_1.model_performance(xval=True)\nperf_cv.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='6'></a>\n# Build Random Forest Model","metadata":{}},{"cell_type":"code","source":"# Random Forest model\nn_cv = 5\nfit_2 = H2ORandomForestEstimator(nfolds=n_cv,\n                                 distribution='bernoulli',\n                                 ntrees=100,\n                                 mtries=-1, # automatic selection\n                                 max_depth=20,\n                                 score_each_iteration=True,\n                                 stopping_metric='auc',\n                                 stopping_rounds=5,\n                                 stopping_tolerance=0.0001,\n                                 seed=999)\n\n# train model\nt1 = time.time()\nfit_2.train(x=predictors,\n            y='target',\n            training_frame=train_hex)\nt2 = time.time()\nprint('Elapsed time [s]: ', np.round(t2-t1,2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show cross validation metrics\nfit_2.cross_validation_metrics_summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show scoring history - training vs cross validations\nfor i in range(n_cv):\n    cv_model_temp = fit_2.cross_validation_models()[i]\n    df_cv_score_history = cv_model_temp.score_history()\n    my_title = 'CV ' + str(1+i) + ' - Scoring History [AUC]'\n    plt.scatter(df_cv_score_history.number_of_trees,\n                y=df_cv_score_history.training_auc, \n                c='blue', label='training')\n    plt.scatter(df_cv_score_history.number_of_trees,\n                y=df_cv_score_history.validation_auc, \n                c='darkorange', label='validation')\n    plt.title(my_title)\n    plt.xlabel('Number of Trees')\n    plt.ylabel('AUC')\n    plt.ylim(0.7,1)\n    plt.legend()\n    plt.grid()\n    plt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training performance\nperf_train = fit_2.model_performance(train=True)\nperf_train.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cross validation performance\nperf_cv = fit_2.model_performance(xval=True)\nperf_cv.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='7'></a>\n# Predict on Test Set and prepare submissions","metadata":{}},{"cell_type":"code","source":"# predict on test set (extract probabilities only)\npred_test_GLM = fit_1.predict(test_hex)['p1']\npred_test_GLM = pred_test_GLM.as_data_frame().p1\n\n# plot test set predictions (probabilities)\nplt.figure(figsize=(6,4))\nplt.hist(pred_test_GLM, bins=100)\nplt.title('Predictions on Test Set - GLM')\nplt.grid()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict on test set (extract probabilities only)\npred_test_RF = fit_2.predict(test_hex)['p1']\npred_test_RF = pred_test_RF.as_data_frame().p1\n\n# plot test set predictions (probabilities)\nplt.figure(figsize=(6,4))\nplt.hist(pred_test_RF, bins=100)\nplt.title('Predictions on Test Set - RF')\nplt.grid()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# combine predictions in one data frame\ndf_preds_test = pd.DataFrame({'GLM': pred_test_GLM.values, 'RF': pred_test_RF.values})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# scatter plot of two prediction sets\nsns.jointplot(data=df_preds_test, x='GLM', y='RF',\n              joint_kws={'s' : 2},\n              alpha=0.1)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# correlation\ndf_preds_test.corr()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# GLM submission\ndf_sub_GLM = df_sub.copy()\ndf_sub_GLM.target = df_preds_test.GLM\ndisplay(df_sub_GLM.head())\n# save to file\ndf_sub_GLM.to_csv('submission_GLM.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# RF submission\ndf_sub_RF = df_sub.copy()\ndf_sub_RF.target = df_preds_test.RF\ndisplay(df_sub_RF.head())\n# save to file\ndf_sub_RF.to_csv('submission_RF.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Blend two models","metadata":{}},{"cell_type":"code","source":"# blend two model results\ndf_sub_blend = df_sub.copy()\ndf_sub_blend.target = 0.5*df_preds_test.GLM + 0.5*df_preds_test.RF\ndisplay(df_sub_blend.head())\n# save to file\ndf_sub_blend.to_csv('submission_blend.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}