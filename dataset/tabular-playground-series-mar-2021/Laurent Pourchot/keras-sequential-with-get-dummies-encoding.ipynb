{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport keras\nfrom tensorflow.keras import layers, optimizers, callbacks, utils, losses, metrics, backend as K\nfrom keras.models import Sequential\nimport tensorflow_addons as tfa\nimport tensorflow as tf\nfrom keras.layers import Flatten, Activation, Dropout,BatchNormalization\nfrom keras.layers import Dense\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import activations,callbacks\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import plot_confusion_matrix, roc_auc_score, plot_roc_curve, classification_report\nfrom matplotlib import pyplot as plt\nplt.style.use('dark_background')\nfrom sklearn.preprocessing import OneHotEncoder\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"initial_csv = pd.read_csv('../input/dataset/train.csv') # to follow the preprocess function\ntrain= pd.read_csv('../input/dataset/train.csv')\ntarget=train['target']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1> Encoding One Hot <h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv('../input/tabular-playground-series-mar-2021/train.csv')\ntest_data = pd.read_csv('../input/tabular-playground-series-mar-2021/test.csv')\n\n#combine train and test data vertically\nX_nums = np.vstack([\n    train_data.iloc[:, 20:-1].to_numpy(),\n    test_data.iloc[:, 20:].to_numpy()\n])\nX_nums = (X_nums - X_nums.mean(0)) / X_nums.std(0) #normalize\n\n#stack the categorical data\nX_cat = np.vstack([\n    train_data.iloc[:, 1:20].to_numpy(),\n    test_data.iloc[:, 1:20].to_numpy()\n])\n#encode the categoricals\nencoder = OneHotEncoder(sparse=False)\nX_cat = encoder.fit_transform(X_cat)\n\n#join the categorical and continuous data horizontally\nX = np.hstack([X_cat, X_nums])\ny = train_data['target'].to_numpy().reshape(-1, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = X[:300000,:]\ntarget = train_data.iloc[:300000,-1]\nx_train, x_test, y_train, y_test = train_test_split(train, target, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2> Get_dummies encoding <h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_x(df):\n    try: df.set_index('id',inplace=True)\n    except: pass\n\n    df = pd.get_dummies(df, drop_first=False)\n    for col in pd.get_dummies(initial_csv.drop(columns=['target']), drop_first=False).columns:\n        if col not in df.columns:\n            df[col]=0\n\n    return df\n\ndef preprocess(df):\n    try: df.set_index('id',inplace=True)\n    except: pass\n\n    x = df.drop(columns=['target'])\n    x = preprocess_x(x)\n    return x\n\ntrain = preprocess(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(train, target, test_size=0.2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"x_train\",x_train.shape)\nprint(\"x_test\",x_test.shape)\nprint(\"y_train\",y_train.shape)\nprint(\"y_test\",y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1> Training <h1>"},{"metadata":{},"cell_type":"markdown","source":"<h3> Model definition <h3>"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Dense(300, activation='relu',input_dim=642)) # depends on the shape of train !\nmodel.add(Dropout(0.3))\nmodel.add(Dense(300, activation='relu'))\n#model.add(Dropout(0.3))\n#model.add(Dense(30, activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.keras.metrics.AUC(\n    num_thresholds=200,\n    curve=\"ROC\",\n    summation_method=\"interpolation\",\n    name= 'val_AUC',\n    dtype=None,\n    thresholds=None,\n    multi_label=False,\n    label_weights=None,\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(\n        optimizer=tfa.optimizers.SWA(tf.keras.optimizers.Adam(learning_rate=0.0001)),\n        loss=losses.BinaryCrossentropy(),\n        metrics=metrics.AUC(name=\"AUC\"))\n \n\n\nes = callbacks.EarlyStopping(monitor='val_AUC', \n                             min_delta=0.0000001,\n                             patience=5, \n                             mode='max', \n                             baseline=None, \n                             restore_best_weights=True,\n                             verbose=1)\n\nplateau  = callbacks.ReduceLROnPlateau(monitor='val_loss',\n                                       factor=0.5,\n                                       patience=2,\n                                       mode='max',\n                                       min_delta=0.00001,\n                                       cooldown=0,\n                                       min_lr=1e-7,\n                                       verbose=1) \n\nsb = callbacks.ModelCheckpoint('./nn_model.w8',\n                               save_weights_only=True,\n                               save_best_only=True,\n                               verbose=1,\n                               monitor='val_AUC',\n                               mode='max')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\"\"\"\nhistory=model.fit(x=x_train,\n                  y=y_train,\n                  validation_data=(x_test, y_test),\n                  batch_size=256,\n                  epochs=20,\n                  shuffle=False,\n                  verbose=1,\n                  callbacks=[es,sb,plateau])\n\"\"\"\n\nhistory=model.fit(x=x_train,\n                  y=y_train,\n                  validation_data=(x_test, y_test),\n                  epochs=20)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10)) \nloss = history.history['AUC']\nval_loss = history.history['val_AUC']\nepochs = range(1, len(loss) + 1)\nplt.plot(epochs, loss, 'y', label='Training AUC')\nplt.plot(epochs, val_loss, 'r', label='Validation AUC')\nplt.title('Training and validation AUC')\nplt.xlabel('Epochs')\nplt.ylabel('AUC')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred=model.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(roc_auc_score(y_test, pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.mean(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.mean(pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.mean(y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}