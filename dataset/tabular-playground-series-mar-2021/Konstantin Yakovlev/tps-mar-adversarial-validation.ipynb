{"cells":[{"metadata":{},"cell_type":"markdown","source":"### The Adversarial validation.\n\nOr in other words, we will try to see if our classification model will be able to distinguish the train set from the test set and if yes - we can see features importances to understand how it managed to do it.\n\nThe main idea of this technic is very simple:\n- Set a binary target for the train/test set (train 1 / test 0 for example)\n- Combine train and test in one dataset\n- Run any Classification model to see if there is a significant difference in train/test sets.\n\nIf we got roc auc result near 0.5 (0.5-0.6) - all good, and there are no significant differences. It also means that overfitting most likely will not come from features values differences.\n\nIf we have roc auc score >0.6 - it's a sign of some \"leaky\" feature or values distributions in train/test sets and you should look closer and do some cleaning. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os, sys, gc, warnings, random\n\n## Sklearn utils\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import KFold\n\n## LGB\nimport lightgbm as lgb\n\n## Turn off warnings\nwarnings.filterwarnings('ignore')\n\n## SEEDer\ndef seed_everything(seed=0):\n    random.seed(seed)\n    np.random.seed(seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########################### Initial Vars\n###########################################################\nTARGET    = 'target'   # Our Target\nSEED      = 42         # Base SEED\nN_SPLITS  = 5          # Number of Kfold Splits\nPATH      = '../input/tabular-playground-series-mar-2021/'\n\ncat_cols = ['cat'+str(i) for i in range(19)]  # Categorial Columns\ncnt_cols = ['cont'+str(i) for i in range(11)] # Continuous Columns \n\nremove_features = ['id',TARGET] # Features that we will not use for training","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########################### Data\n###########################################################\n\n# Main data\ntrain_df = pd.read_csv(PATH+'train.csv')\ntest_df  = pd.read_csv(PATH+'test.csv')\n\n# Combine train and test\n# and assign new target\ntrain_df[TARGET] = 1\ntest_df[TARGET]  = 0\nall_df = pd.concat([train_df, test_df]).reset_index(drop=True)\n\ndel train_df, test_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########################### Categorical encoding\n###########################################################\n# For the Adversarial Validation we will not\n# do any \"fancy\" encoding\nfor col in cat_cols:   \n    all_df[col] = all_df[col].astype('category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########################### Models params and Features\n###########################################################\nfeatures_columns = [col for col in list(all_df) if col not in remove_features]\n\nlgb_params = {\n                'boosting_type': 'gbdt',\n                'objective': 'binary',\n                'metric': 'auc',\n                'n_estimators': 200,\n                'learning_rate': 0.05,\n                'num_leaves': 2**7,\n                'min_data_in_leaf': 2**8,\n                'feature_fraction': 0.7,\n                'subsample': 0.7,\n                'subsample_freq': 1,\n                'early_stopping_rounds': 100,\n                'boost_from_average': True,\n                'seed': SEED,\n                'verbose': -1\n            }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########################### LGB Model\n###########################################################\n\n# We have enough data to use normal Kfold split\nfolds = KFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n\n# Separate train features and target\nX,y   = all_df[features_columns], all_df[TARGET]\n\n# Create column to store predictions\nall_df['preds'] = 0\n\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(X,y)):\n        \n    print('Fold:',fold_+1)\n        \n    # Creating lgb train/valid data\n    tr_x, tr_y = X.iloc[trn_idx,:], y[trn_idx] \n    vl_x, vl_y = X.iloc[val_idx,:], y[val_idx] \n        \n    train_data = lgb.Dataset(tr_x, label=tr_y)\n    valid_data = lgb.Dataset(vl_x, label=vl_y)\n        \n    # Train Model\n    seed_everything(SEED)\n    estimator = lgb.train(\n                          lgb_params,\n                          train_data,\n                          valid_sets = [train_data,valid_data],\n                          verbose_eval = 100,\n                        )\n        \n    all_df.iloc[val_idx, len(list(all_df))-1] += (estimator.predict(vl_x)) \n\nprint(roc_auc_score(all_df[TARGET], all_df['preds']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 0.5010550371750001 is a good result\n# and seems that you don't have to do anything special\n# with train/test values and their distributions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# If the score is greater than 0.6 you may want to see \n# importances chart to find \"traitor\" feature\nlgb.plot_importance(estimator, figsize=(20,20))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########################### Fast example from other competition\n###########################################################\nTARGET    = 'target'   # Our Target\nSEED      = 42         # Base SEED\nN_SPLITS  = 2          # Number of Kfold Splits\nPATH      = '../input/ieee-fraud-detection/'\ntrain_df = pd.read_csv(PATH+'train_transaction.csv')\ntest_df  = pd.read_csv(PATH+'test_transaction.csv')\ntrain_df[TARGET] = 1\ntest_df[TARGET]  = 0\ndel train_df['isFraud']\n\nall_df = pd.concat([train_df, test_df]).reset_index(drop=True)\ndel all_df['TransactionDT'], all_df['TransactionID'] # obvious \"leakers\"\n\ndel train_df, test_df\n\nfor col in list(all_df):\n    if all_df[col].dtype=='O':\n        all_df[col] = all_df[col].astype('category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########################### LGB Model\n###########################################################\nfeatures_columns = [col for col in list(all_df) if col not in [TARGET]]\nfolds = KFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\nall_df['preds'] = 0\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(all_df[TARGET],all_df[TARGET])):\n    print('Fold:',fold_+1)\n    train_data = lgb.Dataset(all_df[features_columns].iloc[trn_idx,:], \n                             label=all_df[TARGET][trn_idx])\n    valid_data = lgb.Dataset(all_df[features_columns].iloc[val_idx,:], \n                             label=all_df[TARGET][val_idx])\n    estimator = lgb.train(lgb_params,train_data,\n                          valid_sets = [train_data,valid_data],\n                          verbose_eval = 100)\n    all_df.iloc[val_idx, len(list(all_df))-1] += (estimator.predict(all_df[features_columns].iloc[val_idx,:])) \n    break # we will run only 1 fold - hust for fast check\n    \nprint(roc_auc_score(all_df[TARGET], all_df['preds']))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Score 0.88+ is toooo big \n# It means that something wrong with values\n# or distributions in train/test sets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb.plot_importance(estimator, figsize=(20,20))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}