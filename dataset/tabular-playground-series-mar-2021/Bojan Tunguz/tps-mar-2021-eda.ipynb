{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Overview\n\nThe purpose of this kernel is to take a look at the data, come up with some insights, and attempt to create a predictive model or two. This notebook is still very raw. I will work on it as my very limited time permits, and hope to expend it in the upcoming days and weeks.\n\n# Packages\n\nFirst, let's load a few useful Python packages. This section will keep growing in subsequent versions of this EDA."},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport gc\nimport json\nimport math\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.linear_model import LogisticRegression, Ridge\nfrom sklearn.preprocessing import OneHotEncoder\nfrom tqdm import tqdm\nfrom sklearn.decomposition import PCA\nfrom pandas_profiling import ProfileReport\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.experimental import enable_hist_gradient_boosting\nfrom sklearn.ensemble import HistGradientBoostingRegressor, HistGradientBoostingClassifier\nfrom lightgbm import LGBMClassifier\n\nimport os\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see what files we have in the input directory:"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nprint(os.listdir(\"../input/tabular-playground-series-mar-2021/\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Loading Train and Test Data\ntrain = pd.read_csv(\"../input/tabular-playground-series-mar-2021/train.csv\")\ntest = pd.read_csv(\"../input/tabular-playground-series-mar-2021/test.csv\")\nsample_submission = pd.read_csv(\"../input/tabular-playground-series-mar-2021/sample_submission.csv\") ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's look at the distribution of the target:\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.mean(train.target)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So this is a binary classification problem with imbalanced data."},{"metadata":{"trusted":true},"cell_type":"code","source":"train['cat0'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['cat1'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 5))\nplt.hist(train['cat1'].values, bins=200)\nplt.title('Histogram cat1 counts in train')\nplt.xlabel('Value')\nplt.ylabel('Count')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['cat2'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 5))\nplt.hist(train['cat2'].values, bins=200)\nplt.title('Histogram cat2 counts in train')\nplt.xlabel('Value')\nplt.ylabel('Count')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['cat3'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 5))\nplt.hist(train['cat3'].values, bins=200)\nplt.title('Histogram cat3 counts in train')\nplt.xlabel('Value')\nplt.ylabel('Count')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['cat4'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 5))\nplt.hist(train['cat4'].values, bins=200)\nplt.title('Histogram cat4 counts in train')\nplt.xlabel('Value')\nplt.ylabel('Count')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['cat5'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 5))\nplt.hist(train['cat5'].values, bins=200)\nplt.title('Histogram cat5 counts in train')\nplt.xlabel('Value')\nplt.ylabel('Count')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['cat6'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 5))\nplt.hist(train['cat6'].values, bins=200)\nplt.title('Histogram cat5 counts in train')\nplt.xlabel('Value')\nplt.ylabel('Count')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"profile_train = ProfileReport(train, title='Pandas Train Profiling Report', html={'style':{'full_width':True}})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"profile_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"profile_test = ProfileReport(test, title='Pandas Train Profiling Report', html={'style':{'full_width':True}})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"profile_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let's do some simple modeling. First, we'll have to encode all teh categorical variales so that we can use them with numerical algorithms. "},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train.target\nX = train.drop([\"id\", \"target\"], axis=1)\n\nX_test = test.drop([\"id\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#List of categorical col\nlist_cat = [col for col in X.columns if col.startswith(\"cat\")]\n\n\nX_all = pd.concat([X, X_test], axis=0)\n\nle = LabelEncoder()\n\nfor col in list_cat:\n    X_all[col] = le.fit_transform(X_all[col])\n    \nX_all.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = X_all.iloc[:len(train), :]\nX_test = X_all.iloc[len(train):, :]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_oof = np.zeros((X.shape[0],))\ntest_preds = 0\ntrain_oof.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nNUM_FOLDS = 10\nkf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=137)\nmax_iter = 350\n\nfor f, (train_ind, val_ind) in tqdm(enumerate(kf.split(X, y))):\n        #print(f'Fold {f}')\n        train_df, val_df = X.iloc[train_ind], X.iloc[val_ind]\n        train_target, val_target = y.iloc[train_ind], y.iloc[val_ind]\n        \n        \n        model = HistGradientBoostingClassifier(max_iter=max_iter, validation_fraction=None, learning_rate=0.05, \n                                               max_depth=9, min_samples_leaf=23, max_leaf_nodes=100)\n        \n\n        model =  model.fit(train_df, train_target)\n        temp_oof = model.predict_proba(val_df)[:,1]\n        temp_test = model.predict_proba(X_test)[:,1]\n\n        train_oof[val_ind] = temp_oof\n        test_preds += temp_test/NUM_FOLDS\n        \n        print(roc_auc_score(val_target, temp_oof))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"roc_auc_score(y, train_oof)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"0.8912443537006325","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.save('train_oof_hgb_0', train_oof)\nnp.save('test_preds_hgb_0', test_preds)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let's take a look at LightGBM instead."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\ntrain_oof_lgbm_0 = np.zeros((X.shape[0],))\ntest_preds_lgbm_0 = 0\ntrain_oof_lgbm_0.shape\n\nNUM_FOLDS = 10\nkf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=137)\n\n\nfor f, (train_ind, val_ind) in tqdm(enumerate(kf.split(X, y))):\n        #print(f'Fold {f}')\n        train_df, val_df = X.iloc[train_ind], X.iloc[val_ind]\n        train_target, val_target = y.iloc[train_ind], y.iloc[val_ind]\n        \n        \n        model = LGBMClassifier(\n                    cat_feature=[x for x in range(19)],\n                    random_state=777,\n                    cat_l2=25.999876242730252,\n                    cat_smooth=89.2699690675538,\n                    colsample_bytree=0.2557260109926193,\n                    learning_rate=0.004,\n                    max_bin=788,\n                    max_depth=81,\n                    metric=\"auc\",\n                    min_child_samples=292,\n                    min_data_per_group=177,\n                    n_estimators=4000000,\n                    n_jobs=-1,\n                    num_leaves=171,\n                    reg_alpha=0.7115353581785044,\n                    reg_lambda=5.658115293998945,\n                    subsample=0.9262904583735796,\n                    subsample_freq=1,\n                    verbose=-1,\n                )\n        \n\n        model =  model.fit(train_df, train_target, eval_set=[(val_df,val_target)],early_stopping_rounds=450,verbose=False)\n        temp_oof = model.predict_proba(val_df)[:,1]\n        temp_test = model.predict_proba(X_test)[:,1]\n\n        train_oof_lgbm_0[val_ind] = temp_oof\n        test_preds_lgbm_0 += temp_test/NUM_FOLDS\n        \n        print(roc_auc_score(val_target, temp_oof))\n        \nprint(roc_auc_score(y, train_oof_lgbm_0))\nnp.save('train_oof_lgbm_0', train_oof_lgbm_0)\nnp.save('test_preds_lgbm_0', test_preds_lgbm_0)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Instead of label encoding, we could also do one hot encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train.target\nX = train.drop([\"id\", \"target\"], axis=1)\n\nX_test = test.drop([\"id\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_cols = ['cat'+str(i) for i in range(19)]\ncontinous_cols = ['cont'+str(i) for i in range(11)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols=categorical_cols+continous_cols\ntrain_objs_num = len(train)\ndataset = pd.concat(objs=[X[cols], X_test[cols]], axis=0)\ndataset_preprocessed = pd.get_dummies(dataset,columns=categorical_cols)\ntrain_preprocessed = dataset_preprocessed[:train_objs_num]\ntest_preprocessed = dataset_preprocessed[train_objs_num:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_preprocessed.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_oof_lr_0 = np.zeros((X.shape[0],))\ntest_preds_lr_0 = 0\ntrain_oof_lr_0.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nNUM_FOLDS = 10\nkf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=137)\n\n\nfor f, (train_ind, val_ind) in tqdm(enumerate(kf.split(train_preprocessed, y))):\n        #print(f'Fold {f}')\n        train_df, val_df = train_preprocessed.iloc[train_ind], train_preprocessed.iloc[val_ind]\n        train_target, val_target = y.iloc[train_ind], y.iloc[val_ind]\n        \n        \n        model = LogisticRegression(max_iter=200)\n        \n\n        model =  model.fit(train_df, train_target)\n        temp_oof = model.predict_proba(val_df)[:,1]\n        temp_test = model.predict_proba(test_preprocessed)[:,1]\n\n        train_oof_lr_0[val_ind] = temp_oof\n        test_preds_lr_0 += temp_test/NUM_FOLDS\n        \n        print(roc_auc_score(val_target, temp_oof))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.save('train_oof_lr_0', train_oof_lr_0)\nnp.save('test_preds_lr_0', test_preds_lr_0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(roc_auc_score(y, train_oof_lr_0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(roc_auc_score(y, 0.85*train_oof+0.15*train_oof_lr_0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"0.8925740557816217","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_oof_lgbm_1 = np.zeros((X.shape[0],))\ntest_preds_lgbm_1 = 0\ntrain_oof_lgbm_1.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbm_params={'metric': 'auc', \n             'reg_alpha': 6.010538011450937, \n             'reg_lambda': 0.031702113663443346, \n             'colsample_bytree': 0.27,\n             'subsample': 0.6, \n             'learning_rate': 0.005, \n             'max_depth': 100, \n             'num_leaves': 100, \n             'min_child_samples': 216,\n             'cat_smooth': 87, \n             'random_state': 77,\n             'n_estimators': 200000}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nNUM_FOLDS = 10\nkf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=137)\n\n\nfor f, (train_ind, val_ind) in tqdm(enumerate(kf.split(train_preprocessed, y))):\n        #print(f'Fold {f}')\n        train_df, val_df = train_preprocessed.iloc[train_ind], train_preprocessed.iloc[val_ind]\n        train_target, val_target = y.iloc[train_ind], y.iloc[val_ind]\n        \n        \n        model = LGBMClassifier(**lgbm_params) \n        \n\n        model =  model.fit(train_df, train_target, eval_set=[(val_df,val_target)],early_stopping_rounds=1100,verbose=False)\n        temp_oof = model.predict_proba(val_df)[:,1]\n        temp_test = model.predict_proba(test_preprocessed)[:,1]\n\n        train_oof_lgbm_1[val_ind] = temp_oof\n        test_preds_lgbm_1 += temp_test/NUM_FOLDS\n        \n        print(roc_auc_score(val_target, temp_oof))\n        \nprint(roc_auc_score(y, train_oof_lgbm_1))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain_oof_lgbm_2 = np.zeros((X.shape[0],))\ntest_preds_lgbm_2 = 0\ntrain_oof_lgbm_2.shape\n\nlgbm_parameters = {\n    'cat_feature': categorical_cols,\n    'metric': 'auc', \n    'n_estimators': 20000,\n    'reg_alpha': 0.000721024661208569,\n    'reg_lambda': 47.79748127808107,\n    'colsample_bytree': 0.24493010466517195,\n    'subsample': 0.12246675404710294,\n    'learning_rate': 0.013933182980403087,\n    'max_depth': 21,\n    'num_leaves': 90,\n    'min_child_samples': 144,\n    'cat_smooth': 63\n}\n\nNUM_FOLDS = 10\nkf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=137)\n\n\nfor f, (train_ind, val_ind) in tqdm(enumerate(kf.split(train_preprocessed, y))):\n        #print(f'Fold {f}')\n        train_df, val_df = train_preprocessed.iloc[train_ind], train_preprocessed.iloc[val_ind]\n        train_target, val_target = y.iloc[train_ind], y.iloc[val_ind]\n        \n        \n        model = LGBMClassifier(**lgbm_params) \n        \n\n        model =  model.fit(train_df, train_target, eval_set=[(val_df,val_target)],early_stopping_rounds=1100,verbose=False)\n        temp_oof = model.predict_proba(val_df)[:,1]\n        temp_test = model.predict_proba(test_preprocessed)[:,1]\n\n        train_oof_lgbm_2[val_ind] = temp_oof\n        test_preds_lgbm_2 += temp_test/NUM_FOLDS\n        \n        print(roc_auc_score(val_target, temp_oof))\n        \nprint(roc_auc_score(y, train_oof_lgbm_2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(roc_auc_score(y, 0.95*train_oof_lgbm_1+0.05*train_oof))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(roc_auc_score(y, 0.5*train_oof_lgbm_0+0.5*train_oof_lgbm_1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(roc_auc_score(y, 0.25*train_oof_lgbm_0+0.25*train_oof_lgbm_1+0.5*train_oof_lgbm_2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.save('train_oof_lgbm_1', train_oof_lgbm_1)\nnp.save('test_preds_lgbm_1', test_preds_lgbm_1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.save('train_oof_lgbm_2', train_oof_lgbm_2)\nnp.save('test_preds_lgbm_2', test_preds_lgbm_2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_oof_hgb_1 = np.zeros((X.shape[0],))\ntest_preds_hgb_1 = 0\ntrain_oof_hgb_1.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nNUM_FOLDS = 10\nkf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=137)\nmax_iter = 350\n\nfor f, (train_ind, val_ind) in tqdm(enumerate(kf.split(train_preprocessed, y))):\n        #print(f'Fold {f}')\n        train_df, val_df = train_preprocessed.iloc[train_ind], train_preprocessed.iloc[val_ind]\n        train_target, val_target = y.iloc[train_ind], y.iloc[val_ind]\n        \n        \n        model = HistGradientBoostingClassifier(max_iter=max_iter, validation_fraction=None, learning_rate=0.05, \n                                               max_depth=9, min_samples_leaf=23, max_leaf_nodes=100)\n        \n\n        model =  model.fit(train_df, train_target)\n        temp_oof = model.predict_proba(val_df)[:,1]\n        temp_test = model.predict_proba(test_preprocessed)[:,1]\n\n        train_oof[val_ind] = temp_oof\n        test_preds += temp_test/NUM_FOLDS\n        \n        print(roc_auc_score(val_target, temp_oof))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.save('train_oof_hgb_1', train_oof_hgb_1)\nnp.save('test_preds_hgb_1', test_preds_hgb_1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''sample_submission['target'] = 0.85*test_preds+0.15*test_preds_lr_0\nsample_submission.to_csv('submission.csv', index=False)'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['target'] = test_preds\nsample_submission.to_csv('submission_hgb_0.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['target'] = test_preds_hgb_1\nsample_submission.to_csv('submission_hgb_1.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['target'] = test_preds_lr_0\nsample_submission.to_csv('submission_lr_0.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['target'] = test_preds_lgbm_0\nsample_submission.to_csv('submission_lgbm_0.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['target'] = test_preds_lgbm_1\nsample_submission.to_csv('submission_lgbm_1.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['target'] = 1.1*test_preds_lgbm_1-0.1*test_preds\nsample_submission.to_csv('submission_blend_0.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['target'] = 0.5*test_preds_lgbm_0+0.5*test_preds_lgbm_1\nsample_submission.to_csv('submission_blend_0.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['target'] = 0.55*test_preds_lgbm_0+0.45*test_preds_lgbm_1\nsample_submission.to_csv('submission_blend_1.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['target'] = 1.05*(0.55*test_preds_lgbm_0+0.45*test_preds_lgbm_1)-0.05*test_preds\nsample_submission.to_csv('submission_blend_2.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['target'] = 1.05*(0.5*test_preds_lgbm_0+0.5*test_preds_lgbm_1)-0.05*test_preds\nsample_submission.to_csv('submission_blend_3.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['target'] = 0.25*test_preds_lgbm_0+0.25*test_preds_lgbm_1+0.5*test_preds_lgbm_2\nsample_submission.to_csv('submission_blend_4.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['target'] = 1.05*(0.25*test_preds_lgbm_0+0.25*test_preds_lgbm_1+0.5*test_preds_lgbm_2)-0.05*test_preds\nsample_submission.to_csv('submission_blend_5.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}