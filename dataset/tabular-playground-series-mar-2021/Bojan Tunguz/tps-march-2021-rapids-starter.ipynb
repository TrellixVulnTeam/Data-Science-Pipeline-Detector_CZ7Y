{"cells":[{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://developer.nvidia.com/sites/default/files/pictures/2018/rapids/rapids-logo.png\"/>"},{"metadata":{},"cell_type":"markdown","source":"[Rapids](https://rapids.ai) is an open-source GPU accelerated Data Sceince and Machine Learning library, developed and mainatained by [Nvidia](https://www.nvidia.com). It is designed to be compatible with many existing CPU tools, such as Pandas, scikit-learn, numpy, etc. It enables **massive** acceleration of many data-science and machine learning tasks, oftentimes by a factor fo 100X, or even more. If you are interested in installing and running Rapids locally on your own machine, then you should [refer to the followong instructions](https://rapids.ai/start.html)."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import cudf\nimport cuml\nimport cupy as cp\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport glob\nimport os\nfrom scipy.interpolate import interp1d\nimport gc\nfrom cuml.linear_model import LogisticRegression\nfrom cuml.neighbors import KNeighborsClassifier\nfrom cuml.svm import SVC\nfrom cuml.ensemble import RandomForestClassifier\nfrom cuml.preprocessing.TargetEncoder import TargetEncoder\nfrom sklearn.model_selection import GroupKFold, KFold\nfrom cuml.metrics import mean_squared_error\n\nimport soundfile as sf\n# Librosa Libraries\nimport librosa\nimport librosa.display\nimport IPython.display as ipd\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\n\nfrom sklearn.metrics import roc_auc_score, label_ranking_average_precision_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = cudf.read_csv(\"/kaggle/input/tabular-playground-series-mar-2021/train.csv\")\ntest = cudf.read_csv(\"/kaggle/input/tabular-playground-series-mar-2021/test.csv\")\nsample_submission = cudf.read_csv('../input/tabular-playground-series-mar-2021/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target = train['target'].values\ncolumns = test.columns[1:]\ncat_features = columns[:19]\ncat_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this notebook we'll deal with categorical features using Target Encoding. For the sake of consistency, target encoding needs to be applied withing the cross-validation loop; otherwise, we'll be easily leakign targt information to the out-of-fold rows, which can lead to serious overfitting.\n\nWe'll also start with a simple Ridge regression. This is the simplest ML algo, and in general can give us a good idea of what the baseline score would be for our problem."},{"metadata":{"trusted":true},"cell_type":"code","source":"lr_train_oof = cp.zeros((300000,))\nlr_test_preds = 0\nlr_train_oof.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nNUM_FOLDS = 10\nkf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=137)\n\nfor f, (train_ind, val_ind) in tqdm(enumerate(kf.split(train, target))):\n        #print(f'Fold {f}')\n        train_df, val_df = train.iloc[train_ind][columns], train.iloc[val_ind][columns]\n        train_target, val_target = target[train_ind], target[val_ind]\n        test_df = test.copy()\n        \n        for cat_col in cat_features:\n            te = TargetEncoder()\n            train_df[cat_col] = te.fit_transform(train_df[cat_col], train_target)\n    \n            val_df[cat_col] = te.transform(val_df[cat_col])\n            test_df[cat_col] = te.transform(test_df[cat_col])\n            \n        model = LogisticRegression()\n        model.fit(train_df, train_target)\n        temp_oof = model.predict_proba(val_df)[[1]].values.flatten()\n        temp_test = model.predict_proba(test_df[columns])[[1]].values.flatten()\n\n        lr_train_oof[val_ind] = temp_oof\n        lr_test_preds += temp_test/NUM_FOLDS\n        \n        print(roc_auc_score(val_target.get(), temp_oof.get()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(roc_auc_score(target.get(), lr_train_oof.get()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cp.save('lr_train_oof', lr_train_oof)\ncp.save('lr_test_preds', lr_test_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nknn_train_oof = cp.zeros((300000,))\nknn_test_preds = 0\nknn_train_oof.shape\n\nNUM_FOLDS = 10\nkf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=137)\n\nfor f, (train_ind, val_ind) in tqdm(enumerate(kf.split(train, target))):\n        #print(f'Fold {f}')\n        train_df, val_df = train.iloc[train_ind][columns], train.iloc[val_ind][columns]\n        train_target, val_target = target[train_ind], target[val_ind]\n        test_df = test.copy()\n        \n        for cat_col in cat_features:\n            te = TargetEncoder()\n            train_df[cat_col] = te.fit_transform(train_df[cat_col], train_target)\n    \n            val_df[cat_col] = te.transform(val_df[cat_col])\n            test_df[cat_col] = te.transform(test_df[cat_col])\n            \n        model = KNeighborsClassifier(n_neighbors=150)\n        model.fit(train_df, train_target)\n        temp_oof = model.predict_proba(val_df)[[1]].values.flatten()\n        temp_test = model.predict_proba(test_df[columns])[[1]].values.flatten()\n\n        knn_train_oof[val_ind] = temp_oof\n        knn_test_preds += temp_test/NUM_FOLDS\n        \n        print(roc_auc_score(val_target.get(), temp_oof.get()))\n        \nprint('\\nOverall score:', roc_auc_score(target.get(), knn_train_oof.get()))\n\ncp.save('knn_train_oof', knn_train_oof)\ncp.save('knn_test_preds', knn_test_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"0.880144183149357","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nrf_train_oof = cp.zeros((300000,))\nrf_test_preds = 0\nrf_train_oof.shape\n\ncu_rf_params = {'n_estimators': 2000,\n    'max_depth': 12,\n    'n_bins': 15,\n    'n_streams': 8\n}\n\nNUM_FOLDS = 10\nkf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=137)\n\nfor f, (train_ind, val_ind) in tqdm(enumerate(kf.split(train, target))):\n        #print(f'Fold {f}')\n        train_df, val_df = train.iloc[train_ind][columns], train.iloc[val_ind][columns]\n        train_target, val_target = target[train_ind], target[val_ind]\n        test_df = test.copy()\n        \n        for cat_col in cat_features:\n            te = TargetEncoder()\n            train_df[cat_col] = te.fit_transform(train_df[cat_col], train_target)\n    \n            val_df[cat_col] = te.transform(val_df[cat_col])\n            test_df[cat_col] = te.transform(test_df[cat_col])\n            \n        model = RandomForestClassifier(**cu_rf_params)\n        model.fit(train_df.astype(np.float32), train_target.astype(np.float32))\n        temp_oof = model.predict_proba(val_df.astype(np.float32))[[1]].values.flatten()\n        temp_test = model.predict_proba(test_df.astype(np.float32)[columns])[[1]].values.flatten()\n\n        rf_train_oof[val_ind] = temp_oof\n        rf_test_preds += temp_test/NUM_FOLDS\n        \n        print(roc_auc_score(val_target.get(), temp_oof.get()))\n        \nprint('\\nOverall score:', roc_auc_score(target.get(), rf_train_oof.get()))\n\ncp.save('rf_train_oof', rf_train_oof)\ncp.save('rf_test_preds', rf_test_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(roc_auc_score(target.get(), 0.6*knn_train_oof.get()+0.4*lr_train_oof.get()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(roc_auc_score(target.get(), 0.5*knn_train_oof.get()+0.25*lr_train_oof.get()+0.25*rf_train_oof.get()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['target'] = lr_test_preds\nsample_submission.to_csv('submission_lr.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['target'] = knn_test_preds\nsample_submission.to_csv('submission_knn.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['target'] = rf_test_preds\nsample_submission.to_csv('submission_rf.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['target'] = 0.6*knn_test_preds+0.4*lr_test_preds\nsample_submission.to_csv('submission_blend_0.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['target'] = 0.5*knn_test_preds+0.25*lr_test_preds+0.25*rf_test_preds\nsample_submission.to_csv('submission_blend_1.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}