{"cells":[{"metadata":{},"cell_type":"markdown","source":"This is an XGB version of the following notebook: https://www.kaggle.com/rmiperrier/lgb-optuna\n\nIt uses Label Encoding (LE) and GPU acceleration."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Libraries\nimport numpy as np\nimport pandas as pd\n\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import LabelEncoder\n\nimport optuna\nfrom optuna.visualization import plot_optimization_history, plot_param_importances\n\nfrom IPython.display import display","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain = pd.read_csv('../input/tabular-playground-series-mar-2021/train.csv', index_col=0)\ntest = pd.read_csv('../input/tabular-playground-series-mar-2021/test.csv', index_col=0)\nsubmission = pd.read_csv('../input/tabular-playground-series-mar-2021/sample_submission.csv')\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predictors & target\npredictors = train.columns[:-1]\ntarget = train.columns[-1]\npredictors","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def label_encode(train_df, test_df, column):\n    le = LabelEncoder()\n    new_feature = \"{}_le\".format(column)\n    le.fit(train_df[column].unique().tolist() + test_df[column].unique().tolist())\n    train_df[new_feature] = le.transform(train_df[column])\n    test_df[new_feature] = le.transform(test_df[column])\n    return new_feature","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_cols = [col for col in predictors if 'cat' in col]\ncont_cols = [col for col in predictors if 'cont' in col]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le_cols = []\nfor feature in cat_cols:\n    le_cols.append(label_encode(train, test, feature))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = le_cols + cont_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(predictors)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Functions for KFold evaluation\ndef create(hyperparams):\n    \"\"\"Create LGBM Classifier for a given set of hyper-parameters.\"\"\"\n    model = XGBClassifier(**hyperparams)\n    return model\n\ndef fit(model, X, y):\n    \"\"\"Simple training of a given model.\"\"\"\n    model.fit(X, y)\n    return model\n\ndef fit_with_stop(model, X, y, X_val, y_val):\n    \"\"\"Advanced training with early stopping.\"\"\"\n    model.fit(X, y,\n              eval_set=[(X_val, y_val)],\n              early_stopping_rounds=200, # ! Hard-coded value\n              verbose=300)\n    return model\n\ndef evaluate(model, X, y):\n    \"\"\"Compute AUC for a given model.\"\"\"\n    yp = model.predict_proba(X)[:, 1]\n    auc_score = roc_auc_score(y, yp)\n    return auc_score\n\ndef kfold_evaluation(X, y, k, hyperparams):\n    \"\"\"Run a KFlod evaluation.\"\"\"\n    scores = []\n    \n    print(f\"\\n------ {k}-fold evaluation -----\")\n    print(hyperparams)\n    \n    kf = KFold(k)\n    for i, (train_idx, test_idx) in enumerate(kf.split(X)):\n        print(f\"----- FOLD {i} -----\")\n        \n        X_train = X.iloc[train_idx]\n        y_train = y.iloc[train_idx]\n        X_val = X.iloc[test_idx]\n        y_val = y.iloc[test_idx]\n        \n        model = create(hyperparams)\n        model = fit_with_stop(model, X_train, y_train, X_val, y_val)\n        train_score = evaluate(model, X_train, y_train)\n        val_score = evaluate(model, X_val, y_val)\n        scores.append((train_score, val_score))\n        \n        print(f\"Eval AUC: {val_score}\")\n        \n        \n    scores = pd.DataFrame(scores, columns=['train score', 'validation score'])\n    \n    return scores\n\ndef kfold_prediction(X, y, X_test, k, hyperparams):\n    \"\"\"Make predictions with a bagged model based on KFold.\"\"\"\n    yp = np.zeros(len(X_test))\n    \n    kf = KFold(k)\n    for train_idx, test_idx in kf.split(X):\n        X_train = X.iloc[train_idx]\n        y_train = y.iloc[train_idx]\n        X_val = X.iloc[test_idx]\n        y_val = y.iloc[test_idx]\n        \n        model = create(hyperparams)\n        model = fit_with_stop(model, X_train, y_train, X_val, y_val)\n        yp += model.predict_proba(X_test)[:, 1] / k\n    \n    return yp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Constant\nK = 5\nX = train[cols]\nY = train[target]\nX_TEST = test[cols]\nBEST_PARAMS = {'learning_rate': 0.03, \n               'eval_metric': 'auc',\n                'tree_method': 'gpu_hist',\n                'predictor': 'gpu_predictor',}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Objective function\ndef objective(trial):\n    # Search spaces\n    hyperparams = {\n        'seed': 137,\n        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n        'tree_method': 'gpu_hist',\n        'predictor': 'gpu_predictor',\n        'use_label_encoder': False,\n        'max_bin': trial.suggest_int('max_bin', 2, 1000),\n        'max_depth': trial.suggest_int('max_depth', 1, 31),\n        'alpha': trial.suggest_float('alpha', 1E-16, 12),\n        'gamma': trial.suggest_float('gamma', 1E-16, 12),\n        'reg_lambda': trial.suggest_float('reg_lambda', 1E-16, 12),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 1E-16, 1.0),\n        'subsample': trial.suggest_float('subsample', 1E-16, 1.0), \n        'min_child_weight': trial.suggest_float('min_child_weight', 1E-16, 12),\n    }\n    \n    # Add BEST_PARAMS\n    hyperparams.update(BEST_PARAMS)\n    \n    # Evaluation\n    scores = kfold_evaluation(X, Y, K, hyperparams)\n    \n    return scores['validation score'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Optimization\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, timeout=3600*2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Best score\nstudy.best_value","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Historic\nplot_optimization_history(study)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importance\nplot_param_importances(study)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Best parameters\nBEST_PARAMS.update(study.best_params)\nBEST_PARAMS","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = XGBClassifier(**BEST_PARAMS, use_label_encoder=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# Predictions on test set and submission\nsubmission['target'] = kfold_prediction(X, Y, X_TEST, K, BEST_PARAMS)\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}