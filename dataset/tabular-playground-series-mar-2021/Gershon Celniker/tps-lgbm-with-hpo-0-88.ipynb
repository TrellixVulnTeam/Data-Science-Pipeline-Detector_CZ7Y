{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# Octopus ML pakage - github.com/gershonc/octopus-ml\n!pip install octopus-ml","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.simplefilter(\"ignore\")\nimport seaborn as sns \nimport matplotlib.pyplot as plt\nimport time\nimport pandas as pd\nimport numpy as np\nimport lightgbm as lgb\nimport tracemalloc\nfrom pandas_summary import DataFrameSummary\nfrom sklearn.metrics import classification_report\n%matplotlib inline\nsns.set_style(\"whitegrid\")\n\npd.set_option('display.max_columns', None)  # or 1000\npd.set_option('display.max_rows', None)  # or 1000\npd.set_option('display.max_colwidth', -1)  # or 199\n\n#check out https://github.com/gershonc/octopus-ml\nimport octopus_ml as oc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv ( \"../input/tabular-playground-series-mar-2021/train.csv\")\ntest_df = pd.read_csv(\"../input/tabular-playground-series-mar-2021/test.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data shape \nprint (\"Train set: \",train_df.shape)\nprint (\"Test set: \",test_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# DataFrane Summary by pandas summary package (extension of pandas.describe method) \ndfs = DataFrameSummary(train_df)\ndfs.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Top 10 sparse features, mainly labs results \npd.Series(1 - train_df.count() / len(train_df)).sort_values(ascending=False).head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Categorical features\n\ncategorical_features=[]\nfor c in train_df.columns:\n    col_type = train_df[c].dtype\n    if col_type == 'object' or col_type.name == 'category':\n        train_df[c] = train_df[c].astype('category')\n        categorical_features.append(c)\nprint (categorical_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Target distribution analysis\nfig, ax =plt.subplots(1,2)\n\n\nplt.style.use('fivethirtyeight')\nplt.figure(figsize=(3,4))\nsns.set_context(\"paper\", font_scale=1.2)                                                  \nsns.countplot('target',data=train_df, ax=ax[0])\ntrain_df['target'].value_counts().plot.pie(explode=[0,0.2],autopct='%1.2f%%',ax=ax[1])\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.displot(data = train_df, kind = 'hist', x = 'cont1', hue = 'target', multiple = 'stack',bins=25,height = 4, aspect = 1.7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.displot(data = train_df, kind = 'hist', x = 'cont2', hue = 'target', multiple = 'stack',bins=25,height = 4, aspect = 1.7)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data pre-processing\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"features=train_df.columns.to_list()\nprint ('Number of features ', len(features))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_remove=['target']\nfor f in features_remove:\n    features.remove(f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=train_df[features]\ny=train_df['target']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## HPO (Hyper-parameter Tuning)"},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"%%time\n\nfrom bayes_opt import BayesianOptimization\n\n\ndef bayes_parameter_opt_lgb(X, y, init_round=15, opt_round=25, n_folds=6, verbose=-1, random_seed=6, n_estimators=10, output_process=False):\n    # prepare data\n    train_data = lgb.Dataset(data=X, label=y, free_raw_data=False)\n    # parameters\n    def lgb_eval(learning_rate,num_leaves, feature_fraction, bagging_fraction, max_depth, max_bin, min_data_in_leaf,min_sum_hessian_in_leaf,subsample,scale_pos_weight):\n        params = {'application':'binary', 'metric':'auc'}\n        params['learning_rate'] = max(min(learning_rate, 1), 0)\n        params[\"num_leaves\"] = int(round(num_leaves))\n        params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n        params['bagging_fraction'] = max(min(bagging_fraction, 1), 0)\n        params['max_depth'] = int(round(max_depth))\n        params['max_bin'] = int(round(max_depth))\n        params['verbose']=-1\n        params['min_data_in_leaf'] = int(round(min_data_in_leaf))\n        params['min_sum_hessian_in_leaf'] = min_sum_hessian_in_leaf\n        params['subsample'] = max(min(subsample, 1), 0)\n        params['scale_pos_weight']=scale_pos_weight\n        \n        cv_result = lgb.cv(params, train_data, nfold=n_folds, seed=random_seed, stratified=True, verbose_eval =200, metrics=['auc'])\n        return np.mean(cv_result['auc-mean'])\n     \n    lgbBO = BayesianOptimization(lgb_eval, {'learning_rate': (0.01, 0.15),\n                                            'num_leaves': (1, 500),\n                                            'feature_fraction': (0.1, 0.9),\n                                            'bagging_fraction': (0.5, 1),\n                                            'max_depth': (2, 20),\n                                            'max_bin':(10,30),\n                                            'min_data_in_leaf': (20, 80),\n                                            'min_sum_hessian_in_leaf':(0,100),\n                                            'subsample': (0.01, 1.0),\n                                            'scale_pos_weight': (0.1,10)\n                                           }, \n                                             random_state=200)\n\n    \n    #n_iter: How many steps of bayesian optimization you want to perform. The more steps the more likely to find a good maximum you are.\n    #init_points: How many steps of random exploration you want to perform. Random exploration can help by diversifying the exploration space.\n    \n    lgbBO.maximize(init_points=init_round, n_iter=opt_round)\n    \n    model_auc=[]\n    for model in range(len( lgbBO.res)):\n        model_auc.append(lgbBO.res[model]['target'])\n    \n    # return best parameters\n    return lgbBO.res[pd.Series(model_auc).idxmax()]['target'],lgbBO.res[pd.Series(model_auc).idxmax()]['params']\n\nopt_params = bayes_parameter_opt_lgb(X, y, init_round=5, opt_round=150, n_folds=5, random_seed=6,n_estimators=300)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"opt_params[1][\"num_leaves\"] = int(round(opt_params[1][\"num_leaves\"]))\nopt_params[1]['max_depth'] = int(round(opt_params[1]['max_depth']))\nopt_params[1]['min_data_in_leaf'] = int(round(opt_params[1]['min_data_in_leaf']))\nopt_params[1]['max_bin'] = int(round(opt_params[1]['max_bin']))\nopt_params[1]['objective']='binary'\nopt_params[1]['metric']='auc'\n#opt_params[1]['is_unbalance']=True\nopt_params[1]['boost_from_average']=False\nopt_params=opt_params[1]\nopt_params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n        'boosting_type': 'gbdt',\n        'objective': 'binary',\n        'metric': 'auc',\n        'learning_rate': 0.01,\n        'subsample': 1,\n        'colsample_bytree': 0.2,\n        'reg_alpha': 3,\n        'reg_lambda': 1,\n        'scale_pos_weight': 4,\n        'n_estimators': 1000,\n        'verbose': 1,\n        'max_depth': -1,\n        'seed':100, \n        'force_col_wise': True\n\n}\n\n#params.update(opt_params)\n\n\nclf,arr_f1_weighted,arr_f1_macro,arr_f1_positive,prediction_folds,preds_folds,y_folds= oc.cv(X,y,0.5,1000,shuffle=True,params=params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oc.cv_plot(arr_f1_weighted,arr_f1_macro,arr_f1_positive,'TBS match 2021 - Kaggle compatition')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_folds, prediction_folds))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oc.roc_curve_plot(y_folds,preds_folds)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_imp_list=oc.plot_imp(clf,X,'LightGBM Mortality Kaggle',num=20)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_features=feature_imp_list.sort_values(by='Value', ascending=False).head(20)\ntop_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_for_correlations=top_features['Feature'].to_list()\nlist_for_correlations.append('target')\noc.correlations(train_df,list_for_correlations)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Kaggle_submission(file_name,model,test_data,ids_list):\n    if TARGET in test_data.columns:\n        test_data.drop([TARGET],axis=1,inplace=True)\n    #test_pred=model.predict(test_data[features])[:,1]\n    test_pred=model.predict(test_data[features])\n    print (test_pred[1:2])\n\n    submit=pd.DataFrame()\n    submit['id'] = ids_list\n    submit['target'] = test_pred\n    submit.to_csv(file_name,index=False)\n    return submit","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Categorical features on testset\n\ncategorical_features=[]\nfor c in test_df.columns:\n    col_type = train_df[c].dtype\n    if col_type == 'object' or col_type.name == 'category':\n        test_df[c] = test_df[c].astype('category')\n        categorical_features.append(c)\nprint (categorical_features)\n\nTARGET=\"diabetes_mellitus\"\nsubmit=Kaggle_submission(\"LGBM_baseline_v15.csv\",clf,test_df,test_df['id'].tolist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}