{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom sklearn import model_selection\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom xgboost import XGBClassifier\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/tabular-playground-series-mar-2021/train.csv')\ndf_test = pd.read_csv('/kaggle/input/tabular-playground-series-mar-2021/test.csv')\n\ntarget = 'target'\ny_train = df_train[target]\ndf_test_ids = df_test['id']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_train.shape)\nprint(df_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test_ids","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.concat([df_train.drop(columns=target), df_test], ignore_index = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe(include=['O'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df_train[target]);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#skewness and kurtosis\nprint(\"Skewness: %f\" % df_train[target].skew())\nprint(\"Kurtosis: %f\" % df_train[target].kurt())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python\n#correlation matrix\ndf_dummy = pd.get_dummies(df_train)[:5000]\ncorrmat = df_dummy.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corrmat, vmax=.8, square=True);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#correlation matrix\ncorrmat = df_train.sample(5000).corr()\nk = 10 #number of variables for heatmap\nf, ax = plt.subplots(figsize=(12, 9))\ncols = corrmat.nlargest(k, target)[target].index\ncm = np.corrcoef(df_train[cols].values.T)\nsns.set(font_scale=1.25)\nhm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Relation between continious variable and the target:"},{"metadata":{"trusted":true},"cell_type":"code","source":"#correlation heatmap of dataset\ndef correlation_heatmap(df, k):\n    _ , ax = plt.subplots(figsize =(14, 12))\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\n    \n    corrmat = df.corr()\n    cols = corrmat.nlargest(k, target)[target].index\n    _ = sns.heatmap(\n        \n        df[cols].corr(), \n        cmap = colormap,\n        square=True, \n        cbar_kws={'shrink':.9 }, \n        ax=ax,\n        annot=True, \n        linewidths=0.1,vmax=1.0, linecolor='white',\n        annot_kws={'fontsize':12 }\n    )\n    \n    plt.title('Pearson Correlation of Features', y=1.05, size=15)\n\ncorrelation_heatmap(pd.get_dummies(df_train)[:100],7)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Continious Variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"#bivariate analysis saleprice/grlivarea\nvar = 'cont8'\ndata = pd.concat([df_train[target], df_train[var]], axis=1)\ndata.plot.scatter(x=var, y=target);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Relation between categorical variable and the target:"},{"metadata":{},"cell_type":"markdown","source":"## Categorical Variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"#https://www.kaggle.com/gaetanlopez/tps-complete-eda-single-lgb-tuning-strategy\ncols = df_train.select_dtypes(include='number').drop(columns=['id',target]).columns\n\nfig = plt.figure(figsize=(30,50))\ni=1\nfor cont in cols:\n    plt.subplot(len(cols), 3, i)\n    sns.histplot(df_train[cont])\n    i+=1\n    \n    plt.subplot(len(cols), 3, i)\n    plt.boxplot(x = df_train[cont])\n    i+=1\n\n    plt.subplot(len(cols), 3, i)\n    sns.violinplot(data = df_train, x = 'target', y = cont)\n    i+=1\n\n    plt.tight_layout()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"var = 'cat16'\ndata = pd.concat([df_train[target], df_train[var]], axis=1)\nf, ax = plt.subplots(figsize=(16, 8))\nfig = sns.boxplot(x=var, y=target, data=data) #NOTE: only first variable in the Target is selected\n#fig.axis(ymin=0, ymax=800000);\n#plt.xticks(rotation=90);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"var = 'cat5'\ndf_train.groupby(var)[target].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Classifier Test\nBorrowed code from [this notebook](https://www.kaggle.com/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy)."},{"metadata":{"trusted":true},"cell_type":"code","source":"MLA = [\n    #Ensemble Methods\n    ensemble.AdaBoostClassifier(),\n    ensemble.BaggingClassifier(),\n    ensemble.ExtraTreesClassifier(),\n    ensemble.GradientBoostingClassifier(),\n    ensemble.RandomForestClassifier(),\n\n    #Gaussian Processes\n    #consumes a lot of RAM, may cause notebook to fail b/c of te 16gb limit\n    #https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessClassifier.html\n    #\"Note that this class thus does not implement a true multi-class Laplace approximation.\"\n    gaussian_process.GaussianProcessClassifier(),\n    \n    #GLM\n    linear_model.LogisticRegressionCV(),\n    linear_model.PassiveAggressiveClassifier(),\n    linear_model.RidgeClassifierCV(),\n    linear_model.SGDClassifier(),\n    linear_model.Perceptron(),\n    \n    #Navies Bayes\n    naive_bayes.BernoulliNB(),\n    naive_bayes.GaussianNB(),\n    \n    #Nearest Neighbor\n    neighbors.KNeighborsClassifier(),\n    \n    #SVM\n    svm.SVC(probability=True),\n    svm.NuSVC(probability=True),\n    svm.LinearSVC(),\n    \n    #Trees    \n    tree.DecisionTreeClassifier(),\n    tree.ExtraTreeClassifier(),\n    \n    #Discriminant Analysis\n    discriminant_analysis.LinearDiscriminantAnalysis(),\n    discriminant_analysis.QuadraticDiscriminantAnalysis(),\n\n    \n    #xgboost: http://xgboost.readthedocs.io/en/latest/model.html\n    XGBClassifier()    \n    ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_dummies = pd.get_dummies(df).drop(columns='id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def MLA_test(X_initial, y_initial, f, t, verbose=0):\n    X = X_initial[f:t]    \n    y = y_initial[f:t]    \n    \n    #split dataset in cross-validation with this splitter class: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit\n    #note: this is an alternative to train_test_split\n    cv_split = model_selection.ShuffleSplit(n_splits = 10, test_size = .3, train_size = .6, random_state = 0 ) # run model 10x with 60/30 split intentionally leaving out 10%\n    \n    #create table to compare MLA metrics\n    MLA_columns = ['MLA Name', 'MLA Parameters','MLA Train Accuracy Mean', 'MLA Test Accuracy Mean', 'MLA Test Accuracy 3*STD' ,'MLA Time']\n    MLA_compare = pd.DataFrame(columns = MLA_columns)\n\n    #index through MLA and save performance to table\n    row_index = 0\n    for alg in MLA:\n        #set name and parameters\n        MLA_name = alg.__class__.__name__\n        MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n        MLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n\n        #score model with cross validation: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate\n        cv_results = model_selection.cross_validate(alg, X, y, cv  = cv_split, n_jobs=-1, verbose=0, return_train_score=True)\n\n        training_score = cv_results['train_score'].mean()\n        test_score = cv_results['test_score'].mean()\n        if verbose == 1:\n            print('{}/{}'.format(row_index+1, len(MLA)), MLA_name, \" - \", training_score, test_score)\n\n        MLA_compare.loc[row_index, 'MLA Time'] = cv_results['fit_time'].mean()\n        MLA_compare.loc[row_index, 'MLA Train Accuracy Mean'] = training_score\n        MLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = test_score\n        #if this is a non-bias random sample, then +/-3 standard deviations (std) from the mean, should statistically capture 99.7% of the subsets\n        MLA_compare.loc[row_index, 'MLA Test Accuracy 3*STD'] = cv_results['test_score'].std()*3   #let's know the worst that can happen!\n    \n        #save MLA predictions - see section 6 for usage\n        #alg.fit(data1[data1_x_bin], df[Target])\n        #MLA_predict[MLA_name] = alg.predict(df[data1_x_bin])\n\n        row_index+=1\n    \n    #print and sort table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html\n    MLA_compare.sort_values(by = ['MLA Test Accuracy Mean'], ascending = False, inplace = True)\n    \n    return MLA_compare","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MLA_compare = MLA_test(df_dummies, y_train, 0, 5000, verbose=1)\nMLA_compare","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MLA_compare.values[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = None\nif model!=None:\n    cv_split = model_selection.ShuffleSplit(n_splits = 10, test_size = .3, train_size = .6, random_state = 0 ) # run model 10x with 60/30 split intentionally leaving out 10%\n    cv_results = model_selection.cross_validate(model, X, y, cv  = cv_split, n_jobs=-1, verbose=0, return_train_score=True)\n\n    training_score = cv_results['train_score'].mean()\n    test_score = cv_results['test_score'].mean()\n    print(model.__class__.__name__, \" - \", training_score, test_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f = 0\nt = 10000\nmodel = MLA[4]\nmodel.fit(df_dummies[f:t], y_train[f:t])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = df_dummies[df_train.shape[0]:]\nresults = model.predict(X_test)\ndf_results = pd.DataFrame({'id':df_test_ids, 'target':results})\ndf_results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_results.to_csv('classifierSubmission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Even though classifiers achieved upto 84% accuracy in evaluation data, this success didn't translate to test data. Highest submission score was 76%."},{"metadata":{},"cell_type":"markdown","source":"# Post-training Evaluation\n\nBorrowed code from [this notebook](https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets)."},{"metadata":{"trusted":true},"cell_type":"code","source":"f = 100000\nt = 150000\n\nconf_mat = confusion_matrix(y_true=y_train[f:t], y_pred=model.predict(df_dummies[f:t]))\nprint('Confusion matrix:\\n', conf_mat)\n\nlabels = ['Class 0', 'Class 1']\nfig = plt.figure()\nax = fig.add_subplot(111)\ncax = ax.matshow(conf_mat, cmap=plt.cm.Blues)\nfig.colorbar(cax)\nax.set_xticklabels([''] + labels)\nax.set_yticklabels([''] + labels)\nplt.xlabel('Predicted')\nplt.ylabel('Expected')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that model is misclassifying 1/3 of the class 1. Seeing this inbalanced state, I decided to learn about resampling.\n\n## Resampling\n\n\"A widely adopted technique for dealing with highly unbalanced datasets is called resampling. It consists of removing samples from the majority class (under-sampling) and / or adding more examples from the minority class (over-sampling)\""},{"metadata":{"trusted":true},"cell_type":"code","source":"# Class count\ncount_class_0, count_class_1 = df_train.target.value_counts()\n\n# Divide by class\ndf_class_0 = df_train[df_train['target'] == 0]\ndf_class_1 = df_train[df_train['target'] == 1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random under-sampling\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_class_0_under = df_class_0.sample(count_class_1)\ndf_test_under = pd.concat([df_class_0_under, df_class_1], axis=0)\n\nprint('Random under-sampling:')\nprint(df_test_under.target.value_counts())\n\ndf_test_under.target.value_counts().plot(kind='bar', title='Count (target)');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random over-sampling"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_class_1_over = df_class_1.sample(count_class_0, replace=True)\ndf_test_over = pd.concat([df_class_0, df_class_1_over], axis=0)\n\nprint('Random over-sampling:')\nprint(df_test_over.target.value_counts())\n\ndf_test_over.target.value_counts().plot(kind='bar', title='Count (target)');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"When I used resampling, accuracy droped to 70%."},{"metadata":{},"cell_type":"markdown","source":"# TF Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f = 0\nt = 300000\nX = df_dummies[f:t]\ny = y_train[f:t]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.Sequential()\nmodel.add(tf.keras.layers.Dense(20, activation='relu', input_shape= (642,)))\n#model.add(tf.keras.layers.Dense(20, activation='relu'))\nmodel.add(tf.keras.layers.Dense(1, activation='sigmoid'))\nmodel.compile(optimizer='sgd', loss='mse', metrics=['accuracy'])\nhistory = model.fit(X, y, epochs=10, validation_split=0.3, shuffle=True)\n#history = model.fit(pd.get_dummies(df_test_under).drop(columns=['target','id']), df_test_under['target'], epochs=10, validation_split=0.3, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Sanity check\nf = 100000\nt = 150000\nmodel.evaluate(df_dummies[f:t], y_train[f:t])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(df_dummies[df_train.shape[0]:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_results = pd.DataFrame({'id':df_test_ids, 'target':y_pred.reshape(y_pred.shape[0])})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_results.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_results.to_csv('sequentialNNSubmission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Submission of TF model achieved 86.915% accuracy."},{"metadata":{},"cell_type":"markdown","source":"# LGBM + Optuna\n\n- https://www.kaggle.com/dmitryuarov/catboost-vs-xgb-vs-lgbm-tps-mar-21\n- https://www.kaggle.com/calebyenusah/lgbm-and-optuna-tps-march-2021\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import optuna\nfrom sklearn.metrics import roc_auc_score\nfrom catboost import CatBoostClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f = 0\nt = 300000\nX = df_dummies[f:t]\ny = y_train[f:t]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def objective(trial, data = X, target = y):\n    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = 0)\n\n    params = {\n        'reg_alpha': trial.suggest_float('reg_alpha', 0.001, 10.0),\n        'reg_lambda': trial.suggest_float('reg_lambda', 0.001, 10.0),\n        'num_leaves': trial.suggest_int('num_leaves', 11, 333),\n        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n        'max_depth': trial.suggest_int('max_depth', 5, 20),\n        'learning_rate': trial.suggest_categorical('learning_rate', [0.01, 0.02, 0.05, 0.005, 0.1]),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 0.5),\n        'n_estimators': trial.suggest_int('n_estimators', 50, 3000),\n        'random_state': 42,\n        'boosting_type': 'gbdt',\n        'metric': 'AUC',\n        #'device': 'gpu'\n    }\n    \n    model = LGBMClassifier(**params)  \n    model.fit(X_train, y_train, eval_set = [(X_val,y_val)], early_stopping_rounds = 222, verbose = False)\n    y_pred = model.predict_proba(X_val)[:,1]\n    roc_auc = roc_auc_score(y_val, y_pred)\n\n    return roc_auc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"study = optuna.create_study(direction = 'maximize')\nstudy.optimize(objective, n_trials = 50)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:', study.best_trial.params)\nprint('Best value:', study.best_value)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optuna.visualization.plot_optimization_history(study)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"paramsLGBM = study.best_trial.params\nparamsLGBM['boosting_type'] = 'gbdt'\nparamsLGBM['metric'] = 'AUC'\nparamsLGBM['random_state'] = 42","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\n\nfolds = KFold(n_splits = 10, shuffle = True, random_state = 42)\n\npredictions = np.zeros(len(X_test))\n\nfor fold, (trn_idx, val_idx) in enumerate(folds.split(X, y)):\n    \n    X_train, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n    y_train, y_val = y.iloc[trn_idx], y.iloc[val_idx]\n\n    model = LGBMClassifier(**paramsLGBM)\n   \n    model.fit(X_train, y_train, eval_set = [(X_val, y_val)], eval_metric = 'auc', verbose = False, early_stopping_rounds = 222)\n    \n    predictions += model.predict_proba(X_test)[:,1] / folds.n_splits ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({'id': df_test_ids, 'target': predictions})\nsubmission.to_csv('submissionLGBM.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Achieved 89.249% with the LGBM + Optuna."},{"metadata":{},"cell_type":"markdown","source":"# To Do and Resources:\n\n- [X] Check how much time XGBClassifier takes. It took unusually long, 84 seconds. Next highest was 4.1 seconds. Remove it if necessary\n- [X] Find out the score over time in best performing MLAs. See if there is overfitting.\n- [ ] https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n- [ ] https://towardsdatascience.com/optimizing-hyperparameters-in-random-forest-classification-ec7741f9d3f6\n- [ ] https://www.datacamp.com/community/tutorials/random-forests-classifier-python\n- [ ] Check if the nxn variable relation graph can be implemented (In notebook 4)\n\n### Statistics:\n\n- [ ] https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/discussion/41037\n- [ ] https://scikit-learn.org/stable/modules/cross_validation.html\n- [ ] https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html\n- [ ] https://en.wikipedia.org/wiki/Cross-validation_(statistics)\n\n### Imbalanced Data (!!!!!)\n\n- [X] https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets\n\n### EDA Notebooks:\n\n- [X] https://www.kaggle.com/sudalairajkumar/winning-solutions-of-kaggle-competitions\n- [X] https://www.kaggle.com/kanncaa1/data-sciencetutorial-for-beginners\n- [X] https://www.kaggle.com/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy\n- [X] https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python\n- [X] https://www.kaggle.com/calebyenusah/lgbm-and-optuna-tps-march-2021\n\n### LGBM Notebooks:\n- [ ] https://www.kaggle.com/gaetanlopez/tps-complete-eda-single-lgb-tuning-strategy\n- [ ] https://www.kaggle.com/rmiperrier/lgbm-optuna\n- [ ] https://www.kaggle.com/ekozyreff/tps-2021-03-lightgbm-optuna-10-folds"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}