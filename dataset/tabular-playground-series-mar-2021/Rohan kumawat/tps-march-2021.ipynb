{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Important Points:**\n\n* EDA on Continuous Variables                       ✅\n* EDA on Categorical Variables                      ✅\n* One Hot Encoding                                  ✅\n* Logistic Regression\n* KNN\n* Random Forest Regression      (To be learned yet)\n* Naive Bayes                   (To be learned yet)\n* AdaBoost Regression           (To be learned yet)\n* Gradient Boost Regression     (To be learned yet)\n* LGBM Regression               (To be learned yet)\n* XGB Regression                (To be learned yet)\n* Feature Engineering           (To be learned yet)\n* MLP Regressor                 (To be learned yet)\n* Extra Trees Regressor         (To be learned yet)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_palette(\"coolwarm\")\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-mar-2021/train.csv', index_col ='id')\ntest = pd.read_csv('../input/tabular-playground-series-mar-2021/test.csv', index_col ='id')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"pd.set_option(\"display.max.columns\", None)\npd.set_option(\"display.precision\", 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('Rows and Columns in train dataset:', train.shape)\nprint('Rows and Columns in test dataset:', test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# A very big thank you to @dwin183287. The notebook really eased my job here! https://www.kaggle.com/dwin183287/tps-mar-2021-eda-models\n\ncat_features = [feature for feature in train.columns if 'cat' in feature]\ncont_features = [feature for feature in train.columns if 'cont' in feature]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Null values"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,4), facecolor=\"#f7e4e4\")\nsns.heatmap(train.isnull(), cbar=False, yticklabels=False, cmap=\"coolwarm\")\nax = plt.axes()\nax.set_facecolor(\"#f7e4e4\")\nplt.title(\"Figure 1: HeatMap to check Null values in Train Dataset\", fontsize=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,4), facecolor=\"#f7e4e4\")\nsns.heatmap(test.isnull(), cbar=False, yticklabels=False, cmap=\"coolwarm\")\nax = plt.axes()\nax.set_facecolor(\"#f7e4e4\")\nplt.title(\"Figure 2: HeatMap to check Null values in Test Dataset\", fontsize=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('Missing values in train dataset:', sum(train.isnull().sum()))\nprint('Missing values in test dataset:', sum(test.isnull().sum()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Continuous Features Data Exploration"},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,4), facecolor=\"#f7e4e4\")\nsns.kdeplot(x=\"cont0\", data=train, shade=True)\nax = plt.axes()\nax.set_facecolor(\"#f7e4e4\")\nplt.title(\"Figure 3: Continuous feature 'cont0'\", fontsize=16)\nsns.despine(left=True)\nplt.ylabel(\"\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,4), facecolor=\"#f7e4e4\")\nsns.kdeplot(x=\"cont1\", data=train, shade=True)\nax = plt.axes()\nax.set_facecolor(\"#f7e4e4\")\nplt.title(\"Figure 3: Continuous feature 'cont1'\", fontsize=16)\nsns.despine(left=True)\nplt.ylabel(\"\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(4,3, figsize=(15, 10), facecolor='#f7e4e4', sharey = 'all', sharex = True)\nfig.suptitle(\"Figure 5. Continuous Features Distribution on Train Dataset\", fontsize=16, y=0.92)\nsns.kdeplot(ax=axes[0,0], data=train, x=\"cont0\", shade=True)\nsns.kdeplot(ax=axes[0,1], data=train, x=\"cont1\", shade=True)\nsns.kdeplot(ax=axes[0,2], data=train, x=\"cont2\", shade=True)\nsns.kdeplot(ax=axes[1,0], data=train, x=\"cont3\", shade=True)\nsns.kdeplot(ax=axes[1,1], data=train, x=\"cont4\", shade=True)\nsns.kdeplot(ax=axes[1,2], data=train, x=\"cont5\", shade=True)\nsns.kdeplot(ax=axes[2,0], data=train, x=\"cont6\", shade=True)\nsns.kdeplot(ax=axes[2,1], data=train, x=\"cont7\", shade=True)\nsns.kdeplot(ax=axes[2,2], data=train, x=\"cont8\", shade=True)\nsns.kdeplot(ax=axes[3,0], data=train, x=\"cont9\", shade=True)\nsns.kdeplot(ax=axes[3,1], data=train, x=\"cont10\", shade=True)\nplt.delaxes(ax=axes[3,2])\nplt.yticks([], [])\nsns.despine(left=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"train[cont_features].describe()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(4,3, figsize=(15, 10), facecolor='#f7e4e4', sharey = 'all', sharex = True)\nfig.suptitle(\"Figure 6. Continuous Features Distribution on Test Dataset\", fontsize=16, y=0.92)\nsns.kdeplot(ax=axes[0,0], data=test, x=\"cont0\", shade=True)\nsns.kdeplot(ax=axes[0,1], data=test, x=\"cont1\", shade=True)\nsns.kdeplot(ax=axes[0,2], data=test, x=\"cont2\", shade=True)\nsns.kdeplot(ax=axes[1,0], data=test, x=\"cont3\", shade=True)\nsns.kdeplot(ax=axes[1,1], data=test, x=\"cont4\", shade=True)\nsns.kdeplot(ax=axes[1,2], data=test, x=\"cont5\", shade=True)\nsns.kdeplot(ax=axes[2,0], data=test, x=\"cont6\", shade=True)\nsns.kdeplot(ax=axes[2,1], data=test, x=\"cont7\", shade=True)\nsns.kdeplot(ax=axes[2,2], data=test, x=\"cont8\", shade=True)\nsns.kdeplot(ax=axes[3,0], data=test, x=\"cont9\", shade=True)\nsns.kdeplot(ax=axes[3,1], data=test, x=\"cont10\", shade=True)\nplt.delaxes(ax=axes[3,2])\nplt.yticks([], [])\nsns.despine(left=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"test[cont_features].describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Correlation "},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Thank you to @andreshg notebook. https://www.kaggle.com/andreshg/tps-march-a-complete-study\nplt.figure(figsize=(15, 10), facecolor='#f7e4e4')\nmask = np.triu(np.ones_like(train[cont_features].corr().abs(), dtype=np.bool))\nsns.heatmap(train[cont_features].corr().abs(), mask= mask, annot=True, fmt=\".2f\", cmap='coolwarm', cbar_kws={\"shrink\": .8}, vmin=0, vmax=1)\nax = plt.axes()\nax.set_facecolor(\"#f7e4e4\")\nplt.title(\"Figure 7. Features Correlation on the Train Dataset\", fontsize=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 10), facecolor='#f7e4e4')\nmask = np.triu(np.ones_like(test[cont_features].corr().abs(), dtype=np.bool))\nsns.heatmap(test[cont_features].corr().abs(), mask= mask, annot=True, fmt=\".2f\", cmap='coolwarm', cbar_kws={\"shrink\": .8}, vmin=0, vmax=1)\nax = plt.axes()\nax.set_facecolor(\"#f7e4e4\")\nplt.title(\"Figure 8. Features Correlation on the Test Dataset\", fontsize=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Categorical Features Data Exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(7,3, figsize=(25, 20), facecolor='#f7e4e4', sharey = True)\nfig.suptitle(\"Figure 9. Categorical Features Distribution on Train Dataset\", fontsize=16, y=0.90)\nsns.countplot(ax=axes[0,0], data=train, x=\"cat0\", palette=\"coolwarm\")\nsns.countplot(ax=axes[0,1], data=train, x=\"cat1\", palette=\"coolwarm\")\nsns.countplot(ax=axes[0,2], data=train, x=\"cat2\", palette=\"coolwarm\")\nsns.countplot(ax=axes[1,0], data=train, x=\"cat3\", palette=\"coolwarm\")\nsns.countplot(ax=axes[1,1], data=train, x=\"cat4\", palette=\"coolwarm\")\nsns.countplot(ax=axes[1,2], data=train, x=\"cat5\", palette=\"coolwarm\")\nsns.countplot(ax=axes[2,0], data=train, x=\"cat6\", palette=\"coolwarm\")\nsns.countplot(ax=axes[2,1], data=train, x=\"cat7\", palette=\"coolwarm\")\nsns.countplot(ax=axes[2,2], data=train, x=\"cat8\", palette=\"coolwarm\")\nsns.countplot(ax=axes[3,0], data=train, x=\"cat9\", palette=\"coolwarm\")\nsns.countplot(ax=axes[3,1], data=train, x=\"cat10\", palette=\"coolwarm\")\nsns.countplot(ax=axes[3,2], data=train, x=\"cat11\", palette=\"coolwarm\")\nsns.countplot(ax=axes[4,0], data=train, x=\"cat12\", palette=\"coolwarm\")\nsns.countplot(ax=axes[4,1], data=train, x=\"cat13\", palette=\"coolwarm\")\nsns.countplot(ax=axes[4,2], data=train, x=\"cat14\", palette=\"coolwarm\")\nsns.countplot(ax=axes[5,0], data=train, x=\"cat15\", palette=\"coolwarm\")\nsns.countplot(ax=axes[5,1], data=train, x=\"cat16\", palette=\"coolwarm\")\nsns.countplot(ax=axes[5,2], data=train, x=\"cat17\", palette=\"coolwarm\")\nsns.countplot(ax=axes[6,0], data=train, x=\"cat18\", palette=\"coolwarm\")\nsns.despine(left=True)\nplt.delaxes(ax=axes[6,1])\nplt.delaxes(ax=axes[6,2])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(7,3, figsize=(25, 20), facecolor='#f7e4e4', sharey = True)\nfig.suptitle(\"Figure 10. Categorical Features Distribution on Test Dataset\", fontsize=16, y=0.90)\nsns.countplot(ax=axes[0,0], data=test, x=\"cat0\", palette=\"coolwarm\")\nsns.countplot(ax=axes[0,1], data=test, x=\"cat1\", palette=\"coolwarm\")\nsns.countplot(ax=axes[0,2], data=test, x=\"cat2\", palette=\"coolwarm\")\nsns.countplot(ax=axes[1,0], data=test, x=\"cat3\", palette=\"coolwarm\")\nsns.countplot(ax=axes[1,1], data=test, x=\"cat4\", palette=\"coolwarm\")\nsns.countplot(ax=axes[1,2], data=test, x=\"cat5\", palette=\"coolwarm\")\nsns.countplot(ax=axes[2,0], data=test, x=\"cat6\", palette=\"coolwarm\")\nsns.countplot(ax=axes[2,1], data=test, x=\"cat7\", palette=\"coolwarm\")\nsns.countplot(ax=axes[2,2], data=test, x=\"cat8\", palette=\"coolwarm\")\nsns.countplot(ax=axes[3,0], data=test, x=\"cat9\", palette=\"coolwarm\")\nsns.countplot(ax=axes[3,1], data=test, x=\"cat10\", palette=\"coolwarm\")\nsns.countplot(ax=axes[3,2], data=test, x=\"cat11\", palette=\"coolwarm\")\nsns.countplot(ax=axes[4,0], data=test, x=\"cat12\", palette=\"coolwarm\")\nsns.countplot(ax=axes[4,1], data=test, x=\"cat13\", palette=\"coolwarm\")\nsns.countplot(ax=axes[4,2], data=test, x=\"cat14\", palette=\"coolwarm\")\nsns.countplot(ax=axes[5,0], data=test, x=\"cat15\", palette=\"coolwarm\")\nsns.countplot(ax=axes[5,1], data=test, x=\"cat16\", palette=\"coolwarm\")\nsns.countplot(ax=axes[5,2], data=test, x=\"cat17\", palette=\"coolwarm\")\nsns.countplot(ax=axes[6,0], data=test, x=\"cat18\", palette=\"coolwarm\")\nsns.despine(left=True)\nplt.delaxes(ax=axes[6,1])\nplt.delaxes(ax=axes[6,2])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Target Feature Data Exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(4,3, figsize=(15, 10), facecolor='#f7e4e4', sharey=True, sharex = True)\nfig.suptitle(\"Figure 11. Continuous Features Distribution X Target\", fontsize=16, y=0.93)\nsns.kdeplot(ax=axes[0,0], data=train, x=\"cont0\", shade=True, hue=\"target\", multiple=\"stack\", palette=\"coolwarm\")\nsns.kdeplot(ax=axes[0,1], data=train, x=\"cont1\", shade=True, hue=\"target\", multiple=\"stack\", palette=\"coolwarm\")\nsns.kdeplot(ax=axes[0,2], data=train, x=\"cont2\", shade=True, hue=\"target\", multiple=\"stack\", palette=\"coolwarm\")\nsns.kdeplot(ax=axes[1,0], data=train, x=\"cont3\", shade=True, hue=\"target\", multiple=\"stack\", palette=\"coolwarm\")\nsns.kdeplot(ax=axes[1,1], data=train, x=\"cont4\", shade=True, hue=\"target\", multiple=\"stack\", palette=\"coolwarm\")\nsns.kdeplot(ax=axes[1,2], data=train, x=\"cont5\", shade=True, hue=\"target\", multiple=\"stack\", palette=\"coolwarm\")\nsns.kdeplot(ax=axes[2,0], data=train, x=\"cont6\", shade=True, hue=\"target\", multiple=\"stack\", palette=\"coolwarm\")\nsns.kdeplot(ax=axes[2,1], data=train, x=\"cont7\", shade=True, hue=\"target\", multiple=\"stack\", palette=\"coolwarm\")\nsns.kdeplot(ax=axes[2,2], data=train, x=\"cont8\", shade=True, hue=\"target\", multiple=\"stack\", palette=\"coolwarm\")\nsns.kdeplot(ax=axes[3,0], data=train, x=\"cont9\", shade=True, hue=\"target\", multiple=\"stack\", palette=\"coolwarm\")\nsns.kdeplot(ax=axes[3,1], data=train, x=\"cont10\", shade=True, hue=\"target\", multiple=\"stack\", palette=\"coolwarm\")\nplt.delaxes(ax=axes[3,2])\nsns.despine(left=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_target_0 = train[train[\"target\"]==0]\ntrain_target_1 = train[train[\"target\"]==1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(7,3, figsize=(25, 20), facecolor='#f7e4e4', sharey=True)\nfig.suptitle(\"Figure 12. Categorical Features Distribution X Target 0\", fontsize=16, y=0.90)\nsns.countplot(ax=axes[0,0], x=\"cat0\", data=train_target_0, palette=\"coolwarm\")\nsns.countplot(ax=axes[0,1], x=\"cat1\", data=train_target_0, palette=\"coolwarm\")\nsns.countplot(ax=axes[0,2], x=\"cat2\", data=train_target_0, palette=\"coolwarm\")\nsns.countplot(ax=axes[1,0], x=\"cat3\", data=train_target_0, palette=\"coolwarm\")\nsns.countplot(ax=axes[1,1], x=\"cat4\", data=train_target_0, palette=\"coolwarm\")\nsns.countplot(ax=axes[1,2], x=\"cat5\", data=train_target_0, palette=\"coolwarm\")\nsns.countplot(ax=axes[2,0], x=\"cat6\", data=train_target_0, palette=\"coolwarm\")\nsns.countplot(ax=axes[2,1], x=\"cat7\", data=train_target_0, palette=\"coolwarm\")\nsns.countplot(ax=axes[2,2], x=\"cat8\", data=train_target_0, palette=\"coolwarm\")\nsns.countplot(ax=axes[3,0], x=\"cat9\", data=train_target_0, palette=\"coolwarm\")\nsns.countplot(ax=axes[3,1], x=\"cat10\", data=train_target_0, palette=\"coolwarm\")\nsns.countplot(ax=axes[3,2], x=\"cat11\", data=train_target_0, palette=\"coolwarm\")\nsns.countplot(ax=axes[4,0], x=\"cat12\", data=train_target_0, palette=\"coolwarm\")\nsns.countplot(ax=axes[4,1], x=\"cat13\", data=train_target_0, palette=\"coolwarm\")\nsns.countplot(ax=axes[4,2], x=\"cat14\", data=train_target_0, palette=\"coolwarm\")\nsns.countplot(ax=axes[5,0], x=\"cat15\", data=train_target_0, palette=\"coolwarm\")\nsns.countplot(ax=axes[5,1], x=\"cat16\", data=train_target_0, palette=\"coolwarm\")\nsns.countplot(ax=axes[5,2], x=\"cat17\", data=train_target_0, palette=\"coolwarm\")\nsns.countplot(ax=axes[6,0], x=\"cat18\", data=train_target_0, palette=\"coolwarm\")\nplt.delaxes(ax=axes[6,1])\nplt.delaxes(ax=axes[6,2])\nsns.despine(left=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(7,3, figsize=(25, 20), facecolor='#f7e4e4', sharey=True)\nfig.suptitle(\"Figure 13. Categorical Features Distribution X Target 1\", fontsize=16, y=0.90)\nsns.countplot(ax=axs[0,0], x=\"cat0\", data=train_target_1, palette=\"coolwarm\")\nsns.countplot(ax=axs[0,1], x=\"cat1\", data=train_target_1, palette=\"coolwarm\")\nsns.countplot(ax=axs[0,2], x=\"cat2\", data=train_target_1, palette=\"coolwarm\")\nsns.countplot(ax=axs[1,0], x=\"cat3\", data=train_target_1, palette=\"coolwarm\")\nsns.countplot(ax=axs[1,1], x=\"cat4\", data=train_target_1, palette=\"coolwarm\")\nsns.countplot(ax=axs[1,2], x=\"cat5\", data=train_target_1, palette=\"coolwarm\")\nsns.countplot(ax=axs[2,0], x=\"cat6\", data=train_target_1, palette=\"coolwarm\")\nsns.countplot(ax=axs[2,1], x=\"cat7\", data=train_target_1, palette=\"coolwarm\")\nsns.countplot(ax=axs[2,2], x=\"cat8\", data=train_target_1, palette=\"coolwarm\")\nsns.countplot(ax=axs[3,0], x=\"cat9\", data=train_target_1, palette=\"coolwarm\")\nsns.countplot(ax=axs[3,1], x=\"cat10\", data=train_target_1, palette=\"coolwarm\")\nsns.countplot(ax=axs[3,2], x=\"cat11\", data=train_target_1, palette=\"coolwarm\")\nsns.countplot(ax=axs[4,0], x=\"cat12\", data=train_target_1, palette=\"coolwarm\")\nsns.countplot(ax=axs[4,1], x=\"cat13\", data=train_target_1, palette=\"coolwarm\")\nsns.countplot(ax=axs[4,2], x=\"cat14\", data=train_target_1, palette=\"coolwarm\")\nsns.countplot(ax=axs[5,0], x=\"cat15\", data=train_target_1, palette=\"coolwarm\")\nsns.countplot(ax=axs[5,1], x=\"cat16\", data=train_target_1, palette=\"coolwarm\")\nsns.countplot(ax=axs[5,2], x=\"cat17\", data=train_target_1, palette=\"coolwarm\")\nsns.countplot(ax=axs[6,0], x=\"cat18\", data=train_target_1, palette=\"coolwarm\")\nplt.delaxes(ax=axs[6,1])\nplt.delaxes(ax=axs[6,2])\nsns.despine(left=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Categorical Variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"target = train.pop('target')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n# Divide data into training and validation subsets\nX_train, X_valid, y_train, y_valid = train_test_split(train, target, train_size=0.8, test_size=0.2,\n                                                                random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get list of categorical variables\ns = (X_train.dtypes == 'object')\nobject_cols = list(s[s].index)\n\nprint(\"Categorical variables:\")\nprint(object_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\n\n# Function for comparing different approaches\ndef score_dataset(X_train, X_valid, y_train, y_valid):\n    model = RandomForestRegressor(n_estimators=100, random_state=0)\n    model.fit(X_train, y_train)\n    preds = model.predict(X_valid)\n    return mean_absolute_error(y_valid, preds)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Drop Categorical Variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.select_dtypes(exclude=['object']).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_X_train = X_train.select_dtypes(exclude=['object'])\ndrop_X_valid = X_valid.select_dtypes(exclude=['object'])\n\nprint(\"MAE from Approach 1 (Drop categorical variables):\")\nprint(score_dataset(drop_X_train, drop_X_valid, y_train, y_valid))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Label Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Apply label encoder to each column with categorical data\nlabel_encoder = LabelEncoder()\nfor col in object_cols:\n    train[col] = label_encoder.fit_transform(train[col])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(train, target, train_size=0.8, test_size=0.2,\n                                                                random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"MAE from Approach 2 (Label Encoding):\") \nprint(score_dataset(X_train, X_valid, y_train, y_valid))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### One Hot Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Apply one-hot encoder to each column with categorical data\nOH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\nOH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[object_cols]))\nOH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[object_cols]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# One-hot encoding removed index; put it back\nOH_cols_train.index = X_train.index\nOH_cols_valid.index = X_valid.index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove categorical columns (will replace with one-hot encoding)\nnum_X_train = X_train.drop(object_cols, axis=1)\nnum_X_valid = X_valid.drop(object_cols, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Add one-hot encoded columns to numerical features\nOH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\nOH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"MAE from Approach 3 (One-Hot Encoding):\") \nprint(score_dataset(OH_X_train, OH_X_valid, y_train, y_valid))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Machine Learning"},{"metadata":{},"cell_type":"markdown","source":"### Preparation"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-mar-2021/train.csv', index_col ='id')\ntest = pd.read_csv('../input/tabular-playground-series-mar-2021/test.csv', index_col ='id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combine_df = pd.concat([train, test], axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Apply one-hot encoder to each column with categorical data\nOH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\nOH_train = pd.DataFrame(OH_encoder.fit_transform(train[object_cols]))\n\n# One-hot encoding removed index; put it back\nOH_train.index = train.index\n\n# Remove categorical columns (will replace with one-hot encoding)\nnum_train = train.drop(object_cols, axis=1)\n\n# Add one-hot encoded columns to numerical features\nOH_train_final = pd.concat([num_train, OH_train], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target = OH_train_final.pop('target')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(OH_train_final, target, train_size=0.8, test_size=0.2,\n                                                                random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()\nlr.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = lr.predict(X_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\nfrom sklearn.model_selection import cross_val_score\n\ndef cross_val(model):\n    pred = cross_val_score(model, OH_train_final, target, cv=10)\n    return pred.mean()\n\ndef print_evaluate(true, predicted):  \n    mae = metrics.mean_absolute_error(true, predicted)\n    mse = metrics.mean_squared_error(true, predicted)\n    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))\n    r2_square = metrics.r2_score(true, predicted)\n    print('MAE:', mae)\n    print('MSE:', mse)\n    print('RMSE:', rmse)\n    print('R2 Square', r2_square)\n    \ndef evaluate(true, predicted):\n    mae = metrics.mean_absolute_error(true, predicted)\n    mse = metrics.mean_squared_error(true, predicted)\n    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))\n    r2_square = metrics.r2_score(true, predicted)\n    return mae, mse, rmse, r2_square","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"------------------------"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-mar-2021/train.csv', index_col ='id')\ntest = pd.read_csv('../input/tabular-playground-series-mar-2021/test.csv', index_col ='id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combine_df = pd.concat([train, test], axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combine_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Apply label encoder to each column with categorical data\nlabel_encoder = LabelEncoder()\nfor col in cat_features:\n    combine_df[col] = label_encoder.fit_transform(combine_df[col])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combine_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(, target, train_size=0.8, test_size=0.2,\n                                                                random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Work on progress..."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}