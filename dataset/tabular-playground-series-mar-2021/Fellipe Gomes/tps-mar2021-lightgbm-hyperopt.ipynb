{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport time\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\nfrom sklearn.metrics import roc_auc_score, average_precision_score, log_loss\n\nfrom hyperopt import fmin, hp, tpe, Trials, space_eval\nfrom hyperopt.pyll import scope as ho_scope\nfrom hyperopt.pyll.stochastic import sample as ho_sample\nfrom functools import partial\n\nfrom lightgbm import LGBMClassifier\n\nfrom imblearn.pipeline import Pipeline\n#from imblearn.over_sampling import ADASYN\n#from imblearn.under_sampling import OneSidedSelection, NeighbourhoodCleaningRule, TomekLinks\nfrom imblearn.under_sampling import RandomUnderSampler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evalue_model(model, y_test, X_test, model_name):\n    \n    yhat_prob = [x[1] for x in model.predict_proba(X_test)]\n    \n    results = {'model': model_name,\n               'auc': roc_auc_score(y_true = y_test, y_score = yhat_prob),\n               'aucpr': average_precision_score(y_true = y_test, y_score = yhat_prob),\n               'logloss': log_loss(y_test, yhat_prob)}\n    \n    return results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('../input/tabular-playground-series-mar-2021/sample_submission.csv')\nX_test = pd.read_csv('../input/tabular-playground-series-mar-2021/test.csv')\ntrain = pd.read_csv('../input/tabular-playground-series-mar-2021/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop(columns = \"id\", inplace = True)\nX_test.drop(columns = \"id\", inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in train.columns[train.dtypes == \"object\"].tolist():\n    train[col] = train[col].astype('category')\n    \nfor col in X_test.columns[X_test.dtypes == \"object\"].tolist():\n    X_test[col] = X_test[col].astype('category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train.drop('target', axis=1)\ny = train['target']\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"high_cardinality = [\"cat5\", \"cat7\", \"cat8\", \"cat10\"]\n\ncategorical_cols = X.columns[X.dtypes == \"category\"].tolist()\n\ncategorical_cols = list(set(categorical_cols) - set(high_cardinality))\n\ncat_columns_position = [X.columns.tolist().index(x) for x in categorical_cols + high_cardinality]"},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbm=LGBMClassifier(random_state = 42, \n                    #device = \"gpu\", \n                    learning_rate = 0.1,\n                    n_estimators = 20000)\n\nlgbm.fit(X_train, y_train, \n         eval_set=(X_val,y_val),\n         early_stopping_rounds=200,\n         verbose=False)\n\npredictions=lgbm.predict_proba(X_val)[:,1]\n\nauc_baseline=roc_auc_score(y_val,predictions)\n\nprint(f'Baseline: {auc_baseline}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_baseline = submission.copy()\nsubmission_baseline.loc[:, 'target'] = lgbm.predict_proba(X_test)[:,1]\nsubmission_baseline.to_csv('submission_baseline.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hp_space = {\n    'undersample': hp.choice(label = 'undersample', options = [True, False]),\n    'clf': {\n        'boosting_type': hp.choice(label = 'boosting_type', options = ['gbdt', 'goss']),\n        \n        'num_leaves': hp.choice(label = 'num_leaves', options = [15, 31, 63, 127, 255, 511, 1023, 2047, 4095]), \n        #'max_depth': ho_scope.int(hp.quniform('max_depth',1,32,1)), # default 'max_depth': -1\n        'min_child_weight': ho_scope.int(hp.quniform('min_child_weight', 0, 0.01,0.001)),\n        'min_child_samples': ho_scope.int(hp.quniform('min_child_samples',1,300,1)),\n        \n        'max_bin': ho_scope.int(hp.quniform('max_bin',128,1024,128)), # Typical: 255\n        'max_delta_step': ho_scope.int(hp.quniform('max_delta_step',1,10,1)),\n        \n        'subsample_freq': ho_scope.int(hp.quniform('subsample_freq',0,10, 1)),\n       # 'subsample': hp.uniform('subsample',0.2,1),\n        'colsample_bytree': hp.uniform('colsample_bytree',0.2,1),\n        \n        'reg_lambda': hp.loguniform('reg_lambda',np.log(1e-4),np.log(3)),\n        'reg_alpha': hp.loguniform('reg_alpha',np.log(1e-4),np.log(3)),\n        \n        'min_data_per_group': ho_scope.int(hp.quniform('min_data_per_group',50,200,1)),\n        'cat_smooth':  ho_scope.int(hp.quniform('cat_smooth',5,100,1)),\n        'cat_l2': ho_scope.int(hp.quniform('cat_l2',1,20,1))\n    }\n}\n\n#ho_sample(hp_space)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"iteracoes = Trials()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def instancia_modelo(hiperparametros):\n    \n    clf = LGBMClassifier(**hiperparametros['clf'],\n                         random_state = 42, \n                         #device = \"gpu\", \n                         learning_rate = 0.1,\n                         n_estimators = 20000)\n\n    if hiperparametros['undersample'] == True:\n        undersample = RandomUnderSampler(sampling_strategy='majority')\n    else:\n        undersample = None\n\n    pipe = Pipeline([('undersample', undersample),\n                     ('clf', clf) ])\n\n    return pipe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def funcao_para_minimizar(hiperparametros, features, target):\n    \n    pipe = instancia_modelo(hiperparametros)\n    \n    eval_set=(X_val,y_val)\n    \n    fit_params={'clf__early_stopping_rounds': 200, \n                'clf__eval_metric': 'auc', # logloss\n                'clf__verbose': False,\n                'clf__eval_set': eval_set}\n    \n    cv = StratifiedKFold(n_splits=5,random_state=42,shuffle=True)\n    \n    resultado = cross_val_score(estimator = pipe, \n                                X = features, \n                                y = target, \n                                scoring = \"roc_auc\",\n                                cv = cv, \n                                error_score = \"raise\",\n                                fit_params = fit_params,\n                                n_jobs = -1)\n\n    return -resultado.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\notimizacao = fmin(fn = partial(funcao_para_minimizar, features = X_train, target = y_train),\n                  space = hp_space, \n                  algo = tpe.suggest,\n                  trials = iteracoes,\n                  max_evals = int(180), \n                  rstate = np.random.RandomState(42))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extrai_space_eval(hp_space, trial):\n\n    desempacota_trial = space_eval(space = hp_space, \n                                   hp_assignment = {k: v[0] for (k, v) in trial['misc']['vals'].items() if len(v) > 0})\n    \n    return desempacota_trial","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def desempacota_dicionario(dicionario):\n    desempacotado = {}\n    for (chave, valor) in dicionario.items():\n        if isinstance(valor, dict):\n            desempacotado = {**desempacotado, **desempacota_dicionario(valor)}\n        else:\n            desempacotado[chave] = valor\n            \n    return desempacotado","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"historico = pd.DataFrame([desempacota_dicionario(extrai_space_eval(hp_space, x)) for x in iteracoes.trials])\n\nhistorico['auc'] = [-x['loss'] for x in iteracoes.results]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hiperparametros_selecionados = space_eval(space = hp_space, hp_assignment = otimizacao)\nprint('Selected hyperparameters:\\n%s' % hiperparametros_selecionados)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\n\nhistorico.loc[:,'undersample'] = historico.loc[:,'undersample']*1\n\nfig = px.parallel_coordinates(historico, color=\"auc\", width = 1200)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if hiperparametros_selecionados['undersample'] == True:\n    undersample = RandomUnderSampler(sampling_strategy='majority')\nelse:\n    undersample = None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = LGBMClassifier(**hiperparametros_selecionados['clf'],\n                     random_state = 42, \n                     #device = \"gpu\", \n                     learning_rate = 0.05,\n                     n_estimators = 20000)\n\npipe = Pipeline([('undersample', undersample),\n                 ('clf', clf) ])\n\neval_set=(X_val,y_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nfinal_fit = pipe.fit(X_train, y_train,\n                     clf__early_stopping_rounds=200,\n                     clf__eval_metric='auc', # logloss\n                     clf__verbose=False,\n                     clf__eval_set=eval_set\n                    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions=final_fit.predict_proba(X_val)[:,1]\n\nauc=roc_auc_score(y_val,predictions)\n\nprint(f'Baseline: {auc_baseline}')\nprint(f'Tunning: {auc}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.loc[:, 'target'] = final_fit.predict_proba(X_test)[:,1]\nsubmission.to_csv('submission.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}