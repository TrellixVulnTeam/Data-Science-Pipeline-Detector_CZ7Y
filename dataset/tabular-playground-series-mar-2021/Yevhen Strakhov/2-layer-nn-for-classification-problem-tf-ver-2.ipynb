{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-07T14:26:43.138193Z","iopub.execute_input":"2021-06-07T14:26:43.138574Z","iopub.status.idle":"2021-06-07T14:26:43.146689Z","shell.execute_reply.started":"2021-06-07T14:26:43.13854Z","shell.execute_reply":"2021-06-07T14:26:43.145879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.python.framework import ops\n\nimport tensorflow.compat.v1 as tf\ntf.disable_v2_behavior()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:26:43.148028Z","iopub.execute_input":"2021-06-07T14:26:43.148315Z","iopub.status.idle":"2021-06-07T14:26:43.16767Z","shell.execute_reply.started":"2021-06-07T14:26:43.148288Z","shell.execute_reply":"2021-06-07T14:26:43.16687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:26:43.169232Z","iopub.execute_input":"2021-06-07T14:26:43.169756Z","iopub.status.idle":"2021-06-07T14:26:43.180767Z","shell.execute_reply.started":"2021-06-07T14:26:43.169726Z","shell.execute_reply":"2021-06-07T14:26:43.179958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/tabular-playground-series-mar-2021/train.csv', index_col=0)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:26:43.182804Z","iopub.execute_input":"2021-06-07T14:26:43.183223Z","iopub.status.idle":"2021-06-07T14:26:44.46344Z","shell.execute_reply.started":"2021-06-07T14:26:43.18318Z","shell.execute_reply":"2021-06-07T14:26:44.462399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[['cat'+str(i) for i in range(19)]] = df[['cat'+str(i) for i in range(19)]].astype('category')\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:26:44.46467Z","iopub.execute_input":"2021-06-07T14:26:44.46495Z","iopub.status.idle":"2021-06-07T14:26:45.192966Z","shell.execute_reply.started":"2021-06-07T14:26:44.464923Z","shell.execute_reply":"2021-06-07T14:26:45.191938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_1 = df.drop('cat10', axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:26:45.194535Z","iopub.execute_input":"2021-06-07T14:26:45.19496Z","iopub.status.idle":"2021-06-07T14:26:45.20747Z","shell.execute_reply.started":"2021-06-07T14:26:45.194918Z","shell.execute_reply":"2021-06-07T14:26:45.20634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_2 = pd.get_dummies(df_1, columns=['cat'+str(i) for i in range(19) if i != 10], drop_first=True)\ndf_2.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:26:45.210455Z","iopub.execute_input":"2021-06-07T14:26:45.210884Z","iopub.status.idle":"2021-06-07T14:26:45.513814Z","shell.execute_reply.started":"2021-06-07T14:26:45.210839Z","shell.execute_reply":"2021-06-07T14:26:45.512835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df_2.drop('target', axis=1)\ny = df_2['target']\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:26:45.515237Z","iopub.execute_input":"2021-06-07T14:26:45.51551Z","iopub.status.idle":"2021-06-07T14:26:46.247864Z","shell.execute_reply.started":"2021-06-07T14:26:45.515483Z","shell.execute_reply":"2021-06-07T14:26:46.246987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:26:46.24912Z","iopub.execute_input":"2021-06-07T14:26:46.249394Z","iopub.status.idle":"2021-06-07T14:26:46.25494Z","shell.execute_reply.started":"2021-06-07T14:26:46.249366Z","shell.execute_reply":"2021-06-07T14:26:46.253844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:26:46.255996Z","iopub.execute_input":"2021-06-07T14:26:46.256272Z","iopub.status.idle":"2021-06-07T14:26:46.268033Z","shell.execute_reply.started":"2021-06-07T14:26:46.256246Z","shell.execute_reply":"2021-06-07T14:26:46.267368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:26:46.269317Z","iopub.execute_input":"2021-06-07T14:26:46.269656Z","iopub.status.idle":"2021-06-07T14:26:46.280519Z","shell.execute_reply.started":"2021-06-07T14:26:46.269624Z","shell.execute_reply":"2021-06-07T14:26:46.279911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = np.array(X_train.T)\nX_test = np.array(X_test.T)\ny_train = np.array(y_train.T).reshape((1, y_train.shape[0]))\ny_test = np.array(y_test.T).reshape((1, y_test.shape[0]))","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:26:46.28159Z","iopub.execute_input":"2021-06-07T14:26:46.281972Z","iopub.status.idle":"2021-06-07T14:26:46.991151Z","shell.execute_reply.started":"2021-06-07T14:26:46.281934Z","shell.execute_reply":"2021-06-07T14:26:46.990187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:26:46.992148Z","iopub.execute_input":"2021-06-07T14:26:46.992425Z","iopub.status.idle":"2021-06-07T14:26:46.99961Z","shell.execute_reply.started":"2021-06-07T14:26:46.992398Z","shell.execute_reply":"2021-06-07T14:26:46.998611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train.shape[0] ","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:26:47.000653Z","iopub.execute_input":"2021-06-07T14:26:47.000928Z","iopub.status.idle":"2021-06-07T14:26:47.012216Z","shell.execute_reply.started":"2021-06-07T14:26:47.000901Z","shell.execute_reply":"2021-06-07T14:26:47.011195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def random_mini_batches(X, Y, minibatch_size, seed):\n    np.random.seed(seed)\n    indices = np.arange(0, X.shape[1])\n    np.random.shuffle(indices)\n    minibatches = []\n    num_of_minibatches = int(X.shape[1] / minibatch_size)\n    for i in range(num_of_minibatches):\n        X_mini = X[:, indices[i*minibatch_size : minibatch_size*(i+1)]]\n        Y_mini = Y[:, indices[i*minibatch_size : minibatch_size*(i+1)]]\n        minibatches.append((X_mini, Y_mini))\n    return minibatches","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:26:47.013589Z","iopub.execute_input":"2021-06-07T14:26:47.014177Z","iopub.status.idle":"2021-06-07T14:26:47.023815Z","shell.execute_reply.started":"2021-06-07T14:26:47.014135Z","shell.execute_reply":"2021-06-07T14:26:47.022814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"minibatches = random_mini_batches(X_train, y_train, 1000, 1)\nprint(len(minibatches))\nprint(minibatches[0][0].shape, minibatches[0][1].shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:26:47.025184Z","iopub.execute_input":"2021-06-07T14:26:47.025735Z","iopub.status.idle":"2021-06-07T14:26:48.191669Z","shell.execute_reply.started":"2021-06-07T14:26:47.025693Z","shell.execute_reply":"2021-06-07T14:26:48.190653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001,\n          num_epochs = 15, minibatch_size = 1000, print_cost = True):\n    \"\"\"\n    Implements a three-layer tensorflow neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->SIGMOID.\n    \n    Arguments:\n    X_train -- training set, of shape (input size = 317, number of training examples = 210000)\n    Y_train -- test set, of shape (output size = 1, number of training examples = 210000)\n    X_test -- training set, of shape (input size = 317, number of training examples = 90000)\n    Y_test -- test set, of shape (output size = 1, number of test examples = 90000)\n    learning_rate -- learning rate of the optimization\n    num_epochs -- number of epochs of the optimization loop\n    minibatch_size -- size of a minibatch\n    print_cost -- True to print the cost every 100 epochs\n    \n    Returns:\n    parameters -- parameters learnt by the model. They can then be used to predict.\n    \"\"\"\n    \n    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n    tf.set_random_seed(1)                             # to keep consistent results\n    seed = 3                                          # to keep consistent results\n    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n    n_y = Y_train.shape[0]                            # n_y : output size\n    costs = []                                        # To keep track of the cost\n    cost_per_iteration = []                           # Ф-ция потерь на каждой итерации\n    \n    # Create Placeholders of shape (n_x, n_y)\n    ### START CODE HERE ### (1 line)\n    X = tf.placeholder(tf.float32, [n_x, None])\n    Y = tf.placeholder(tf.float32, [n_y, None])\n    ### END CODE HERE ###\n\n    # Initialize parameters\n    ### START CODE HERE ### (1 line)\n    W1 = tf.get_variable(\"W1\", [25,317], initializer = tf.glorot_uniform_initializer())\n    b1 = tf.get_variable(\"b1\", [25,1], initializer = tf.zeros_initializer())\n    W2 = tf.get_variable(\"W2\", [12,25], initializer = tf.glorot_uniform_initializer())\n    b2 = tf.get_variable(\"b2\", [12,1], initializer = tf.zeros_initializer())\n    W3 = tf.get_variable(\"W3\", [1,12], initializer = tf.glorot_uniform_initializer())\n    b3 = tf.get_variable(\"b3\", [1,1], initializer = tf.zeros_initializer())\n    \n    parameters = {\"W1\": W1,\n                  \"b1\": b1,\n                  \"W2\": W2,\n                  \"b2\": b2,\n                  \"W3\": W3,\n                  \"b3\": b3}\n    ### END CODE HERE ###\n    \n    # Forward propagation: Build the forward propagation in the tensorflow graph\n    ### START CODE HERE ### (1 line)\n    W1 = parameters['W1']\n    b1 = parameters['b1']\n    W2 = parameters['W2']\n    b2 = parameters['b2']\n    W3 = parameters['W3']\n    b3 = parameters['b3']\n    \n    Z1 = tf.add(tf.matmul(W1, X), b1)                                # Z1 = np.dot(W1, X) + b1\n    A1 = tf.nn.relu(Z1)                                              # A1 = relu(Z1)\n    Z2 = tf.add(tf.matmul(W2, A1), b2)                               # Z2 = np.dot(W2, A1) + b2\n    A2 = tf.nn.relu(Z2)                                              # A2 = relu(Z2)\n    Z3 = tf.add(tf.matmul(W3, A2), b3)   \n    ### END CODE HERE ###\n    \n    # Cost function: Add cost function to tensorflow graph\n    ### START CODE HERE ### (1 line)\n    logits = tf.transpose(Z3)\n    labels = tf.transpose(Y)\n    \n    # print('logits:', logits, 'labels:', labels)\n    \n    #!!!!!!!!!!!!!!!!!!Переделать на one_hot\n    cost = tf.reduce_mean(tf.losses.sigmoid_cross_entropy(labels, logits))\n    ### END CODE HERE ###\n    \n    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n    ### START CODE HERE ### (1 line)\n    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n    ### END CODE HERE ###\n    \n    # Initialize all the variables\n    init = tf.global_variables_initializer()\n\n    # Start the session to compute the tensorflow graph\n    with tf.Session() as sess:\n        \n        # Run the initialization\n        sess.run(init)\n        \n        # Do the training loop\n        for epoch in range(num_epochs):\n\n            epoch_cost = 0.                       # Defines a cost related to an epoch\n            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n            seed = seed + 1\n            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n\n            for minibatch in minibatches:\n\n                # Select a minibatch\n                (minibatch_X, minibatch_Y) = minibatch\n                \n                # IMPORTANT: The line that runs the graph on a minibatch.\n                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n                ### START CODE HERE ### (1 line)\n                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n                ### END CODE HERE ###\n                \n                cost_per_iteration.append(minibatch_cost / minibatch_size)\n                \n                epoch_cost += minibatch_cost / minibatch_size\n\n            # Print the cost every epoch\n            if print_cost == True: #and epoch % 100 == 0:\n                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n            #if print_cost == True and epoch % 5 == 0:\n                costs.append(epoch_cost)\n                \n        # plot the cost\n        plt.plot(np.squeeze(costs))\n        plt.ylabel('cost')\n        plt.xlabel('epochs')\n        plt.title(\"Learning rate =\" + str(learning_rate))\n        plt.show()\n        \n        # plot the cost per iteration\n        plt.plot(np.squeeze(cost_per_iteration)[:420])\n        plt.ylabel('cost_per_iteration')\n        plt.xlabel('iterations')\n        plt.title(\"Learning rate =\" + str(learning_rate))\n        plt.show()\n\n        # lets save the parameters in a variable\n        parameters = sess.run(parameters)\n        print (\"Parameters have been trained!\")\n\n        # Calculate the correct predictions\n        correct_prediction = tf.equal(tf.math.round(Z3), Y)\n\n        # Calculate accuracy on the test set\n        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n\n        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n        \n        # Попытка вычислить ROC-AUC\n#         m = tf.keras.metrics.AUC()\n#         m.update_state(Y_test, Z3)\n#         print(\"ROC-AUC:\", m.result())\n        \n        return parameters","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:26:48.192957Z","iopub.execute_input":"2021-06-07T14:26:48.193264Z","iopub.status.idle":"2021-06-07T14:26:48.217849Z","shell.execute_reply.started":"2021-06-07T14:26:48.193233Z","shell.execute_reply":"2021-06-07T14:26:48.216846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"parameters = model(X_train, y_train, X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:26:48.21923Z","iopub.execute_input":"2021-06-07T14:26:48.219528Z","iopub.status.idle":"2021-06-07T14:27:18.566194Z","shell.execute_reply.started":"2021-06-07T14:26:48.219499Z","shell.execute_reply":"2021-06-07T14:27:18.565338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Построение модели в Keras","metadata":{}},{"cell_type":"code","source":"from keras import layers\nfrom keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\nfrom keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\nfrom keras.models import Model\nfrom keras.preprocessing import image\nfrom keras.utils import layer_utils\nfrom keras.utils.data_utils import get_file\nfrom keras.applications.imagenet_utils import preprocess_input\nimport pydot\nfrom IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\nfrom keras.utils import plot_model","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:35:58.252341Z","iopub.execute_input":"2021-06-07T14:35:58.252725Z","iopub.status.idle":"2021-06-07T14:35:58.330871Z","shell.execute_reply.started":"2021-06-07T14:35:58.252695Z","shell.execute_reply":"2021-06-07T14:35:58.329945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_keras(input_shape):\n    \"\"\"\n    input_shape: The height, width and channels as a tuple.  \n        Note that this does not include the 'batch' as a dimension.\n        If you have a batch like 'X_train', \n        then you can provide the input_shape using\n        X_train.shape[1:]\n    \"\"\"\n \n    # Define the input placeholder as a tensor with shape input_shape. Think of this as your input image!\n    X_input = Input(input_shape)\n \n    # Hidden layer 1\n    X = Dense(64, activation='relu', name='layer1')(X_input)\n    \n    # Hidden layer 2\n    X = Dense(32, activation='relu', name='layer2')(X)\n \n    # Output layer\n    X = Dense(1, activation='sigmoid', name='output')(X)\n \n    # Create model. This creates your Keras model instance, you'll use this instance to train/test the model.\n    model = Model(inputs = X_input, outputs = X, name='HappyModel')\n \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:45:56.7896Z","iopub.execute_input":"2021-06-07T14:45:56.789982Z","iopub.status.idle":"2021-06-07T14:45:56.796778Z","shell.execute_reply.started":"2021-06-07T14:45:56.789952Z","shell.execute_reply":"2021-06-07T14:45:56.795672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:45:57.907326Z","iopub.execute_input":"2021-06-07T14:45:57.907687Z","iopub.status.idle":"2021-06-07T14:45:57.913422Z","shell.execute_reply.started":"2021-06-07T14:45:57.907656Z","shell.execute_reply":"2021-06-07T14:45:57.912716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"happyModel = model_keras(X_train.T.shape[1:])\nhappyModel.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\nhappyModel.fit(x = X_train.T, y = y_train.T, epochs = 15, batch_size = 1000)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:46:02.277813Z","iopub.execute_input":"2021-06-07T14:46:02.278356Z","iopub.status.idle":"2021-06-07T14:46:46.590842Z","shell.execute_reply.started":"2021-06-07T14:46:02.278309Z","shell.execute_reply":"2021-06-07T14:46:46.58983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = happyModel.evaluate(x = X_test.T, y = y_test.T)\nprint()\nprint (\"Loss = \" + str(preds[0]))\nprint (\"Test Accuracy = \" + str(preds[1]))","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:46:58.975031Z","iopub.execute_input":"2021-06-07T14:46:58.975416Z","iopub.status.idle":"2021-06-07T14:47:01.112716Z","shell.execute_reply.started":"2021-06-07T14:46:58.975385Z","shell.execute_reply":"2021-06-07T14:47:01.111741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"happyModel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:39:56.153142Z","iopub.execute_input":"2021-06-07T14:39:56.153825Z","iopub.status.idle":"2021-06-07T14:39:56.162181Z","shell.execute_reply.started":"2021-06-07T14:39:56.153777Z","shell.execute_reply":"2021-06-07T14:39:56.161199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(happyModel, to_file='HappyModel.png')\nSVG(model_to_dot(happyModel).create(prog='dot', format='svg'))","metadata":{"execution":{"iopub.status.busy":"2021-06-07T14:40:56.180123Z","iopub.execute_input":"2021-06-07T14:40:56.180544Z","iopub.status.idle":"2021-06-07T14:40:57.06654Z","shell.execute_reply.started":"2021-06-07T14:40:56.18051Z","shell.execute_reply":"2021-06-07T14:40:57.065177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}