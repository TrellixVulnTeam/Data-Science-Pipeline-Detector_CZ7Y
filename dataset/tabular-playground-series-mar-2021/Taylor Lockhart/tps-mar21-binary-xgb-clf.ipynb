{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Tabular Playground Series - March\n\n### About\n\nThe task for this month's competition is to predict the probability of a binary target. In this notebook, I ended up building a model using XGBoost's Classifier class. I ended up with a score of 0.89133 on the prive leaderboard where the winning score was 0.90057.  \n\n### Initial Setup\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport xgboost as xgb\n\n\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.base import clone\n\n# binary classification\nfrom sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\n\n# evaluation imports\nfrom sklearn.metrics import roc_auc_score\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# String variable that can be used to timestamp exported objects\nfrom datetime import datetime\ncurrent_tmstmp = datetime.today().strftime('%Y%m%d')\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\ntrain = pd.read_csv('/kaggle/input/tabular-playground-series-mar-2021/train.csv')\ntest = pd.read_csv('/kaggle/input/tabular-playground-series-mar-2021/test.csv')\n\nprint('count(*) from train: ', len(train.index))\nprint('count(*) from test: ', len(test.index))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Helper Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def encodeBinaryLabel(val, one_val):\n    if pd.isna(val):\n        raise ValueError('Null value found!')\n    else:\n        if val == one_val:\n            return 1\n        else:\n            return 0\n\nsample_sub_filename = '/kaggle/input/tabular-playground-series-mar-2021/sample_submission.csv'\n\ndef quickSubmission(sample_sub_path, test_df, model, output_filename):\n    sample_submission = pd.read_csv(sample_sub_path)\n    x_test = test_df.drop(labels = ['id'], axis = 1).values\n    predictions = model.predict_proba(x_test)\n    sample_submission['target'] = predictions[:, 1]\n    sample_submission.to_csv(output_filename, index = False)\n\ndef create_folds(dataframe):\n    dataframe['kfold'] = -1\n    data = dataframe.sample(frac = 1).reset_index(drop = True)\n    bin_num = int(np.floor(1 + np.log2(len(data))))\n    data.loc[:, 'bins'] = pd.cut(\n        data['target'], bins = bin_num, labels = False\n    )\n    kfold = StratifiedKFold(n_splits = 5)\n    for f, (t_, v_) in enumerate(kfold.split(X = data, y = data['bins'].values)):\n        data.loc[v_, 'kfold'] = f\n    data = data.drop(labels = ['bins'], axis = 1)\n    return data\n\ndef run_folds_proba(dataframe, fold, drop_cols, model):\n    drop_cols.append('target')\n    df_train = dataframe[dataframe.kfold != fold].reset_index(drop = True)\n    df_val = dataframe[dataframe.kfold == fold].reset_index(drop = True)\n    x_train = df_train.drop(labels = drop_cols, axis = 1).values\n    y_train = df_train['target'].values\n    x_val = df_val.drop(labels = drop_cols, axis = 1).values\n    y_val = df_val['target'].values\n    model.fit(x_train, y_train)\n    y_pred = model.predict_proba(x_val)\n    # incorporate auc score\n    print(roc_auc_score(y_val, y_pred[:, 1]))\n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Quick EDA\n\n- labels are not balanced\n- cat0, cat11, cat12, cat13, and cat14 appear to be binary\n- cat10 has values that don't appear in both train and test\n- all features are populated\n- several categorical features contain rows that are populated with similar values\n- cat17 and cat18's countplots look exactly the same, which seemed odd to me"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('count(*),', train.groupby(['target']).size())\n\nmissing_cat_ft = []\n\nprint('Cat Ft - Train - Test')\nfor col in train.columns:\n    if 'cat' in col:\n        print(col, '-', train[col].nunique(), '-', test[col].nunique())\n        if train[col].nunique() != test[col].nunique():\n            missing_cat_ft.append(col)\n\nprint(\"Categorical features with values that don't exist in both train and test sets. \")\nprint(missing_cat_ft)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cats_missing_in_test = []\ncats_missing_in_train = []\n\nfor col in train.columns:\n    if 'cat' in col:\n        for val in train[col].unique():\n            if val not in test[col].unique():\n                cats_missing_in_test.append(col + '-' + val)\n        for val in test[col].unique():\n            if val not in train[col].unique():\n                cats_missing_in_train.append(col + '-' + val)\n\n# cat10 has a lot of values don't exist in both train and test\n# cats_missing_in_test\n# cats_missing_in_train\n\ntrain = train.drop(labels = ['cat10'], axis = 1)\ntest = test.drop(labels = ['cat10'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"null_features_count = 0\n\nfor col in train.columns:\n    if train[col].isnull().sum() > 0:\n        print(col, 'in train set contains null values')\n        null_features_count += 1\n    if col != 'target':\n        if test[col].isnull().sum() > 0:\n            print(col, 'in test set contains null values')\n            null_features_count += 1\n\nif null_features_count == 0:\n    print('All features contain populated values in both train and test')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Prep/Feature Engineering\n\nPreparing the data for training the model(s) and getting ready to run kfolds. I also create a backup of the train dataframe in case I would like to reference it at some point, it isn't really necessary. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# before manipulating the train set, create a copy of the dataframe \n\ntrain_bkup = train.copy()\n\n# encode binary features, A => 1\n\nbinary_fts = ['cat0', 'cat11', 'cat12', 'cat13', 'cat14']\n\nfor ft in binary_fts:\n    train[ft] = train[ft].apply(lambda x: encodeBinaryLabel(x, 'A'))\n    test[ft] = test[ft].apply(lambda x: encodeBinaryLabel(x, 'A'))\n\none_hot_fts = []\n\nfor col in train.columns:\n    if 'cat' in col and col not in binary_fts:\n        one_hot_fts.append(col)\n\ntrain = pd.get_dummies(train, columns = one_hot_fts, dummy_na=False)\ntest = pd.get_dummies(test, columns = one_hot_fts, dummy_na=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create train and validation sets\nx = train.drop(labels = ['id', 'target'], axis = 1).values\ny = train['target'].values\n\nx_train, x_val, y_train, y_val = train_test_split(x, y, test_size = 0.25)\n\ndf = create_folds(train)\n\nprint('Kfold counts: \\n', df.kfold.value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Basic Models\n\nI'm going to use some of my submissions to evaluate how well various algorithms work with the default parameters. \n\nXGBClassifier ended up being the best so moving forward I am focusing on using it. I have seen some great notebooks where others are using the DMatrix objects and passing params to the xgb train method to return a classifier. I'm still gaining experience with XGBoost so I'll just define the model using xgb.XGBClassifier and evaluate it using kfolds.  \n\nBelow is a list including how some other binary classification algorithms performed. \n\n- Logistic Regression - 0.87484\n- Random Forest - 0.87944\n- Stochastic Gradient Descent - 0.87474\n- XGB Clf: 0.88475"},{"metadata":{"trusted":true},"cell_type":"code","source":"drops = ['id', 'kfold']\n\n\nprint('----- XGBoost Classifier -----')\nfor f in range(len(df['kfold'].unique())):\n    mdl = run_folds_proba(\n        dataframe = df,\n        fold = f,\n        drop_cols = drops,\n        model = xgb.XGBClassifier(\n            n_estimators = 100, \n            learning_rate = 0.2,\n            max_depth = 10,\n            subsample = 0.9,\n            gamma = 5,\n            colsample_bytree = 0.2,\n            eval_metric = 'auc',\n            min_child_weight = 20,\n            use_label_encoder=False\n        )\n    )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Submission\n\nTrain a new instance of the xgb classifier model on the whole train set and submit predictions from the test set. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# retrain new instance of model on whole training set\n\nxgb_mdl = xgb.XGBClassifier(\n    n_estimators = 100, \n    learning_rate = 0.2,\n    max_depth = 10,\n    subsample = 0.9,\n    gamma = 5,\n    colsample_bytree = 0.2,\n    eval_metric = 'auc',\n    min_child_weight = 20,\n    use_label_encoder=False\n)\nxgb_mdl.fit(x, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"quickSubmission(\n    sample_sub_path = sample_sub_filename, \n    test_df = test, \n    model = xgb_mdl, \n    output_filename = 'xgb_clf_tuned_submission.csv'\n)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}