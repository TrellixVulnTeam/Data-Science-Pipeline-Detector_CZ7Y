{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\nimport xgboost as xgb \nfrom tqdm import tqdm\nimport optuna\nfrom  sklearn.metrics import accuracy_score\ntqdm.pandas()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission = pd.read_csv('/kaggle/input/tabular-playground-series-mar-2021/sample_submission.csv')\ntrain_df = pd.read_csv('/kaggle/input/tabular-playground-series-mar-2021/train.csv')\ntest_df = pd.read_csv('/kaggle/input/tabular-playground-series-mar-2021/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cont_cols = [x for x in train_df.columns if 'cont' in x]\ncat_cols = [x for x in train_df.columns if 'cat' in x]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in cat_cols:\n    le = preprocessing.LabelEncoder()\n    full = train_df[col].append(test_df[col])\n    le.fit(full)\n    train_df[col] = le.transform(train_df[col])\n    test_df[col] = le.transform(test_df[col])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = train_df.drop(['id', 'target'], axis=1)\ntarget = train_df['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# To use optuna, we have to declare an objective funation, which optuna tries to optimize\n# Input to the objective is a trial,  which is a single execution of the objective function\n# output of optuna will be the score which we are trying to optimize.\ndef objective(trial):\n    train_x, test_x, train_y, test_y = train_test_split(data, target, test_size=0.3, stratify=target)\n    dtrain = xgb.DMatrix(train_x, label=train_y, enable_categorical=True)\n    dtest = xgb.DMatrix(test_x, label=test_y, enable_categorical=True)\n    \n#     print(\"Shape of dataframes after split:\")\n#     print(train_x.shape, test_x.shape, train_y.shape, test_y.shape)\n#     print(\"Target value counts after split in train and test:\")\n#     print( train_y.value_counts(), test_y.value_counts())    \n    \n    param = {\n        \"verbosity\": 1,\n        \"objective\": \"binary:logistic\", # Output is probability for logistic regression. \"binary:hinge\" can be sued for predictions(0, 1)\n        \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\", \"gblinear\", \"dart\"]), #gbtree, dart use tree based models, gblinear uses linear finctions.\n        \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 1.0, log=True), # lambda represents L2 regularization on weights\n        \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 1.0, log=True) # alpha represents L1 regularization\n    } \n    \n    # getting other hyperparameters, based on above set ones.\n    if param[\"booster\"]==\"gbtree\" or param[\"booster\"]==\"dart\":\n        param[\"max_depth\"] = trial.suggest_int(\"max_depth\", 1,9) \n        param[\"eta\"] = trial.suggest_float(\"eta\", 1e-9, 1.0, log=True) \n        param[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-8, 1.0, log=True)\n        param[\"grow_policy\"] = trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n    if param[\"booster\"]==\"dart\":\n        param[\"sample_type\"] = trial.suggest_categorical(\"sample_type\", [\"uniform\", \"weighted\"])\n        param[\"normalize_type\"] = trial.suggest_categorical(\"normalize_type\",  [\"tree\", \"forest\"])\n        param[\"rate_drop\"] = trial.suggest_float(\"rate_drop\", 1e-8, 1.0, log=True)\n        param[\"skip_drop\"] = trial.suggest_float(\"skip_drop\", 1e-8, 1.0, log=True)\n    \n    bst = xgb.train(param, dtrain)\n    preds = bst.predict(dtest)\n    pred_labels = np.rint(preds) # Rounds number to nearest integer. same as threshold 0.5.\n    accuracy = accuracy_score(test_y, pred_labels) # metric can be changed as per requirement\n    return accuracy\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now we crate a \"study\", which is a optuna terminology, where we try to optimize our accuracy by repeating the trials\nstudy = optuna.create_study(direction=\"maximize\")\nstudy.optimize(objective, n_trials=100, timeout=600)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(study)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"dir(study)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(study.trials)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trial = study.best_trial","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trial.value","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we can get params using below:\n\nfor k, v in trial.params.items():\n    print(\"{}: {}\".format(k, v))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_param = trial.params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = test_df.drop(['id'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtrain = xgb.DMatrix(data, label=target, enable_categorical=True)\ndtest = xgb.DMatrix(test_data, enable_categorical=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bst = xgb.train(final_param, dtrain)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = bst.predict(dtest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = np.rint(pred).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['target'] = pred\nsample_submission.to_csv('submission_optuna_xgb.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}