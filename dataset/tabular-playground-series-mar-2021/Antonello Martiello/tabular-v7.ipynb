{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import classification_report, roc_auc_score, make_scorer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.calibration import CalibratedClassifierCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC \nfrom xgboost import XGBClassifier\nfrom sklearn.preprocessing import LabelEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans\nfrom kmodes.kmodes import KModes\nfrom sklearn.preprocessing import PowerTransformer\nfrom sklearn.model_selection import StratifiedKFold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import uniform as sp_uniform\nfrom scipy.stats import randint as sp_randint\nfrom scipy.stats import uniform as sp_uniform","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import pairwise_distances\nfrom sklearn.metrics.pairwise import pairwise_kernels\nfrom sklearn.metrics.pairwise  import cosine_similarity\nfrom sklearn.metrics.pairwise import chi2_kernel","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import LeakyReLU\nfrom tensorflow.keras.layers import BatchNormalization","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss = StandardScaler()\nss2 = StandardScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train= pd.read_csv('/kaggle/input/tabular-playground-series-mar-2021/train.csv', sep=',')\n\nsub_sample = pd.read_csv('/kaggle/input/tabular-playground-series-mar-2021/sample_submission.csv', sep=',')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test= pd.read_csv('/kaggle/input/tabular-playground-series-mar-2021/test.csv', sep=',')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape, test.shape, sub_sample.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.set_index('id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"l=[]\nfor i in train.columns:\n    if train[i].dtype!='O':\n        l.append(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"l2=[]\nfor i in train.columns:\n    if train[i].dtype=='O':\n        l2.append(i)\nl2.append('target')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[l].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.boxplot(data=train[l[0:-1]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['target'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=train[l]\ndf0= df[df['target']==0]\ndf1= df[df['target']==1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.heatmap(data=train[l[1:]].corr())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(3, 1, figsize=(10,10))\n#plt.figure(figsize=(10,10))\nsns.boxplot(ax=axes[0],data=train[l[:-1]])\nsns.boxplot(ax=axes[1],data=df0[l[:-1]])\nsns.boxplot(ax=axes[2],data=df1[l[:-1]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.heatmap(data=df0[l[:]].corr())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.heatmap(data=df1[l[:]].corr())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[l[:-1]].isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(3, 1, figsize=(10,10))\n#plt.figure(figsize=(10,10))\nsns.boxplot(ax=axes[0],data=(train[l[:-1]])**2)\nsns.boxplot(ax=axes[1],data=(df0[l[:-1]])**2)\nsns.boxplot(ax=axes[2],data=(df1[l[:-1]])**2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[l2[:-1]].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cat = train[l2[:-1]]\ndf_cat2 = train[l2]\ndf_num=train[l[:-1]]\ndf_target= train[l[-1]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_cat.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#le = LabelEncoder()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_cat3=df_cat.apply(le.fit_transform)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_cat = df_cat.astype('category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import category_encoders as ce\nwoe=ce.woe.WOEEncoder(return_df=True, drop_invariant=True, handle_missing='value')\nwoe_enc=woe.fit_transform(df_cat, df_target)\nwoe_enc= woe_enc.set_index(df_cat.index)\n#woe_enc = woe_enc.astype('category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"woe_enc.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"te=ce.target_encoder.TargetEncoder(return_df=True, drop_invariant=True, handle_missing='value', handle_unknown='value', smoothing=0.2)\nte_enc=te.fit_transform(df_cat, df_target)\nte_enc= te_enc.set_index(df_cat.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"te_enc.columns = ['tecat0', 'tecat1', 'tecat2', 'tecat3', 'tecat4', 'tecat5', 'tecat6', 'tecat7', 'tecat8',\n       'tecat9', 'tecat10', 'tecat11', 'tecat12', 'tecat13', 'tecat14', 'tecat15', 'tecat16',\n       'tecat17', 'tecat18']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#hashe = ce.hashing.HashingEncoder(return_df=True, drop_invariant=True)\n#hash_enc=hashe.fit_transform(df_cat, df_target)\n#hash_enc= hash_enc.set_index(df_cat.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#hash_enc.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df= pd.concat([woe_enc, te_enc, df_num], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"km = KMeans(n_clusters=4, random_state=15)\nkm_df = pd.DataFrame(km.fit_predict(df), index=df.index, columns=['cl'])\nkm_df = km_df.astype('str')\nkm_df = pd.get_dummies(km_df)\nkm_df = km_df.astype('int')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"km_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df= pd.concat([df, km_df], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df = ss.fit_transform(df)\n#df = pd.DataFrame(df, index=train.index, columns=train.columns[:-1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = df[['cat0',    'cat1',    'cat2',    'cat3',    'cat4',    'cat5',\n          'cat6',    'cat7',    'cat8',    'cat9',   'cat10',   'cat11',\n         'cat12',   'cat13',   'cat14',   'cat15',   'cat16',   'cat17',\n         'cat18', 'cont0',   'cont1',\n         'cont2',   'cont3',   'cont4',   'cont5',   'cont6',   'cont7',\n         'cont8',   'cont9',  'cont10','cl_0', 'cl_1', 'cl_2',\n       'cl_3']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2 = df[['tecat0', 'tecat1', 'tecat2', 'tecat3', 'tecat4',\n       'tecat5', 'tecat6', 'tecat7', 'tecat8', 'tecat9', 'tecat10', 'tecat11',\n       'tecat12', 'tecat13', 'tecat14', 'tecat15', 'tecat16', 'tecat17',\n       'tecat18','cont0', 'cont1', 'cont2', 'cont3', 'cont4', 'cont5',\n       'cont6', 'cont7', 'cont8', 'cont9', 'cont10', 'cl_0', 'cl_1', 'cl_2',\n       'cl_3']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Autoencoder"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(df1, df_target, test_size=0.30, random_state=1)\n# scale data\nt = MinMaxScaler()\nt.fit(X_train)\nX_train = t.transform(X_train)\nX_test = t.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_inputs =df1.shape[1]\nn_inputs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define encoder\nvisible = Input(shape=(n_inputs,))\n# encoder level 1\ne = Dense(n_inputs*3)(visible)\ne = BatchNormalization()(e)\ne = LeakyReLU()(e)\n# encoder level 2\ne = Dense(n_inputs)(e)\ne = BatchNormalization()(e)\ne = LeakyReLU()(e)\n# bottleneck\nn_bottleneck = round(float(n_inputs) / 2.0)\nbottleneck = Dense(n_bottleneck)(e)\n# define decoder, level 1\nd = Dense(n_inputs)(bottleneck)\nd = BatchNormalization()(d)\nd = LeakyReLU()(d)\n# decoder level 2\nd = Dense(n_inputs*3)(d)\nd = BatchNormalization()(d)\nd = LeakyReLU()(d)\n# output layer\noutput = Dense(n_inputs, activation='linear')(d)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define autoencoder model\n#model = Model(inputs=visible, outputs=output)\n# compile autoencoder model\n#model.compile(optimizer='adam', loss='mse')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot the autoencoder\n#plot_model(model, 'autoencoder_no_compress.png', show_shapes=True)\n# fit the autoencoder model to reconstruct input\n#history = model.fit(X_train, X_train, epochs=100, batch_size=16, verbose=2, validation_data=(X_test,X_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot loss\n#plt.plot(history.history['loss'], label='train')\n#plt.plot(history.history['val_loss'], label='test')\n#plt.legend()\n#plt.show()\n# define an encoder model (without the decoder)\n#encoder = Model(inputs=visible, outputs=bottleneck)\n#plot_model(encoder, 'encoder_no_compress.png', show_shapes=True)\n# save the encoder to file\n#encoder.save('encoder.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_encode = encoder.predict(df1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_encode = pd.DataFrame(df_encode,index=df1.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_encode.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_plus = pd.concat([df1, df_encode], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Optuna"},{"metadata":{"trusted":true},"cell_type":"code","source":"import optuna","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def objective(trial , data = df1 , target = df_target):\n    train_x , test_x , train_y , test_y = train_test_split(data , target , \\\n            test_size = 0.028059109276941666 , random_state = 42)\n\n    #test_size = 0.028059109276941666\n    params = {\n        'reg_alpha' : trial.suggest_loguniform('reg_alpha' , 1e-5 , 10),\n        'reg_lambda' : trial.suggest_loguniform('reg_lambda' , 1e-5 , 10),\n        'num_leaves' : trial.suggest_int('num_leaves' , 11 , 800),\n        'learning_rate' : trial.suggest_uniform('learning_rate' , 0.0000001 , 0.1),\n        'max_depth' : trial.suggest_int('max_depth' , 5 , 400),\n        'n_estimators' : trial.suggest_int('n_estimators' , 1 , 9999),\n        'min_child_samples' : trial.suggest_int('min_child_samples' , 1 , 110),\n        'min_child_weight' : trial.suggest_loguniform('min_child_weight' , 1e-5 , 1),\n        'subsample' : trial.suggest_uniform('subsample' , 1e-5 , 1.0),\n        'colsample_bytree' : trial.suggest_loguniform('colsample_bytree' , 1e-5 , 1),\n        'random_state' : trial.suggest_categorical('random_state' , [1,42,2021,555]),\n        'metric' : 'auc',\n        'device_type' : 'cpu',\n    }\n    model = lightgbm.LGBMClassifier(**params)\n    model.fit(train_x , train_y , eval_set = [(test_x , test_y)] , early_stopping_rounds = 200 , \\\n             verbose = False)\n    preds = model.predict_proba(test_x)[:,1]\n    auc = roc_auc_score(test_y , preds)\n    return auc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#study = optuna.create_study(direction = 'maximize' , study_name = 'lgbm')\n#study.optimize(objective , n_trials = 1)\n#print('numbers of the finished trials:' , len(study.trials))\n#print('the best params:' , study.best_trial.params)\n#print('the best value:' , study.best_value)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Parametri con df1\n#the best value: 0.8990729898631389\nparameters_df11={'reg_alpha': 4.2454113913576315, 'reg_lambda': 0.8899994822202811, 'num_leaves': 189, 'learning_rate': 0.025556695055007152, 'max_depth': 88, 'n_estimators': 5023, 'min_child_samples': 84, 'min_child_weight': 0.00039809767984828675, 'subsample': 0.48961516469429756, 'colsample_bytree': 0.1393679695029006, 'random_state': 555}\n# parametri con piu' regularization Trial 23 finished with value: 0.8977186777333175\nparameters_df12= {'reg_alpha': 0.12852445867029427, 'reg_lambda': 8.661870320090047, 'num_leaves': 126, 'learning_rate': 0.026729106092421163, 'max_depth': 145, 'n_estimators': 2840, 'min_child_samples': 100, 'min_child_weight': 2.8395788296418357e-05, 'subsample': 0.4763268318189475, 'colsample_bytree': 0.16793586245071554, 'random_state': 2021}\n#the best value: 0.8986825515857123\nparameters_df13= {'reg_alpha': 0.01700126780654701, 'reg_lambda': 0.0027814146390216688, 'num_leaves': 238, 'learning_rate': 0.021938334019234108, 'max_depth': 54, 'n_estimators': 6397, 'min_child_samples': 50, 'min_child_weight': 0.8400282536027239, 'subsample': 0.47915115184384754, 'colsample_bytree': 0.3278563707693388, 'random_state': 42}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Parametri con df2\n#con piu' regularization Trial 36 finished with value: 0.8978443461542528\nparameters_df22={'reg_alpha': 9.118907428042913, 'reg_lambda': 0.12959968423610096, 'num_leaves': 17, 'learning_rate': 0.0776102432033011, 'max_depth': 17, 'n_estimators': 3686, 'min_child_samples': 86, 'min_child_weight': 0.0011355918176110865, 'subsample': 0.8367994419441532, 'colsample_bytree': 0.4836335537092214, 'random_state': 42}\n#the best value: 0.8982749366666394\nparameters_df21= {'reg_alpha': 0.537327486805204, 'reg_lambda': 0.019584599849890916, 'num_leaves': 82, 'learning_rate': 0.05218198433646826, 'max_depth': 71, 'n_estimators': 4340, 'min_child_samples': 62, 'min_child_weight': 0.0009480351949410995, 'subsample': 0.6752872238604577, 'colsample_bytree': 0.16192808258013053, 'random_state': 42}\n#the best value: 0.8991129218847445\nparameters_df23 = {'reg_alpha': 0.0001543251818272485, 'reg_lambda': 0.014373071877816938, 'num_leaves': 408, 'learning_rate': 0.020002205506641287, 'max_depth': 123, 'n_estimators': 2391, 'min_child_samples': 99, 'min_child_weight': 0.0048616493226546756, 'subsample': 0.2549660532449299, 'colsample_bytree': 0.21391734300955667, 'random_state': 555}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param1={'reg_alpha': 3.1537282825971684, 'reg_lambda': 0.0006331603037539777, 'num_leaves': 210, 'learning_rate': 0.030542905754683533, 'max_depth': 46, 'n_estimators': 9728, 'min_child_samples': 3, 'min_child_weight': 0.004536270550575023, 'subsample': 0.5957073001294086, 'colsample_bytree': 0.516835733282878, 'random_state': 42}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param2={'reg_alpha': 3.4050634203247796, 'reg_lambda': 8.151186640988037, 'num_leaves': 170, 'learning_rate': 0.02144578398400834, 'max_depth': 38, 'n_estimators': 1055, 'min_child_samples': 13, 'min_child_weight': 0.0115577715775169, 'subsample': 0.6052880249006449, 'colsample_bytree': 0.3496802480226771, 'random_state': 42}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param3={'reg_alpha': 9.786060648128762, 'reg_lambda': 0.0006948954569416347, 'num_leaves': 137, 'learning_rate': 0.023424207089337176, 'max_depth': 64, 'n_estimators': 2583, 'min_child_samples': 1, 'min_child_weight': 1.862399743644229e-05, 'subsample': 0.24617098080102506, 'colsample_bytree': 0.17174339489842147, 'random_state': 42}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param4={'reg_alpha': 3.98196662753181, 'reg_lambda': 2.758490252875887e-05, 'num_leaves': 133, 'learning_rate': 0.02661593085308742, 'max_depth': 79, 'n_estimators': 5569, 'min_child_samples': 54, 'min_child_weight': 3.758582497733011e-05, 'subsample': 0.2685866648258971, 'colsample_bytree': 0.225831030612319, 'random_state': 42}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"with target encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"#0.8856023921629884\nparam_plus =  {'reg_alpha': 0.9743822716453967, 'reg_lambda': 1.8262870443117842, 'num_leaves': 138, 'learning_rate': 0.06978622282435892, 'max_depth': 372, 'n_estimators': 4167, 'min_child_samples': 101, 'min_child_weight': 0.0017234645371239574, 'subsample': 0.6433908875083164, 'colsample_bytree': 0.13564310243636946, 'random_state': 1}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params1= {'reg_alpha': 6.7779388151102395, 'reg_lambda': 0.2242114494396302, 'num_leaves': 282, 'learning_rate': 0.003404453895520132, 'max_depth': 52, 'n_estimators': 6556, 'min_child_samples': 50, 'min_child_weight': 0.00024094623793528765, 'subsample': 0.1272898098486071, 'colsample_bytree': 0.16134140354767543, 'random_state': 2021}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Trial 40 finished with value: 0.8987909699605494 \nparams2= {'reg_alpha': 0.4171907072665806, 'reg_lambda': 0.010276748360125343, 'num_leaves': 300, 'learning_rate': 0.00771068552120896, 'max_depth': 62, 'n_estimators': 6554, 'min_child_samples': 26, 'min_child_weight': 0.007938177310401738, 'subsample': 0.12193386210016402, 'colsample_bytree': 0.14061264083550198, 'random_state': 2021}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params3={'reg_alpha': 3.57600648867944, 'reg_lambda': 0.19373229864787594, 'num_leaves': 218, 'learning_rate': 0.08603855902510578, 'max_depth': 14, 'n_estimators': 6676, 'min_child_samples': 62, 'min_child_weight': 0.00937274804904474, 'subsample': 0.6639257272064, 'colsample_bytree': 0.24648367545438585, 'random_state': 1}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# TEST"},{"metadata":{"trusted":true},"cell_type":"code","source":"test = test.set_index('id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lt=[]\nfor i in test.columns:\n    if test[i].dtype!='O':\n        lt.append(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lt2=[]\nfor i in test.columns:\n    if test[i].dtype=='O':\n        lt2.append(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dft_cat = test[lt2]\ndft_cat2 = test[lt2]\ndft_num=test[lt]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"woet_enc=woe.transform(dft_cat)\nwoet_enc= woet_enc.set_index(dft_cat.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tet_enc=te.transform(dft_cat)\ntet_enc= tet_enc.set_index(dft_cat.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tet_enc.columns = ['tecat0', 'tecat1', 'tecat2', 'tecat3', 'tecat4', 'tecat5', 'tecat6', 'tecat7', 'tecat8',\n       'tecat9', 'tecat10', 'tecat11', 'tecat12', 'tecat13', 'tecat14', 'tecat15', 'tecat16',\n       'tecat17', 'tecat18']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dft= pd.concat([woet_enc, tet_enc, dft_num], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"km_dft = pd.DataFrame(km.predict(dft), index=dft.index, columns=['cl'])\nkm_dft = km_dft.astype('str')\nkm_dft = pd.get_dummies(km_dft)\nkm_dft = km_dft.astype('int')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dft= pd.concat([dft, km_dft], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dft1 = dft[['cat0',    'cat1',    'cat2',    'cat3',    'cat4',    'cat5',\n          'cat6',    'cat7',    'cat8',    'cat9',   'cat10',   'cat11',\n         'cat12',   'cat13',   'cat14',   'cat15',   'cat16',   'cat17',\n         'cat18', 'cont0',   'cont1', 'cont2',   'cont3',   'cont4',   'cont5',   'cont6',   'cont7',\n         'cont8',   'cont9',  'cont10','cl_0', 'cl_1', 'cl_2', 'cl_3']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dft2 = dft[['tecat0', 'tecat1', 'tecat2', 'tecat3', 'tecat4',\n       'tecat5', 'tecat6', 'tecat7', 'tecat8', 'tecat9', 'tecat10', 'tecat11',\n       'tecat12', 'tecat13', 'tecat14', 'tecat15', 'tecat16', 'tecat17',\n       'tecat18','cont0', 'cont1', 'cont2', 'cont3', 'cont4', 'cont5',\n       'cont6', 'cont7', 'cont8', 'cont9', 'cont10', 'cl_0', 'cl_1', 'cl_2',\n       'cl_3']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dft1.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_target.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dft_encode = encoder.predict(dft1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dft_encode = pd.DataFrame(dft_encode, index=dft.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dft_plus = pd.concat([dft1, dft_encode], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dft_plus.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_plus.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"param_plus['metric'] = 'auc'\nparam_plus['device'] = 'cpu'\npreds5 = np.zeros(dft_plus.shape[0])\noof_preds5 = np.zeros(df_plus.shape[0])\nkf = StratifiedKFold(n_splits = 10 , random_state = 42 , shuffle = True)\nroc5 = []\nn = 0\nfor trn_idx , val_idx in kf.split(df_plus , df_target):\n    train_x = df_plus.iloc[trn_idx]\n    train_y = df_target.iloc[trn_idx]\n    val_x = df_plus.iloc[val_idx]\n    val_y = df_target.iloc[val_idx]\n    \n    model5 = lightgbm.LGBMClassifier(**param_plus)\n    model5.fit(train_x , train_y , eval_set = [(val_x , val_y)] , early_stopping_rounds = 200 , \\\n             verbose = False)\n    preds5 += model5.predict_proba(dft_plus)[:,1]/kf.n_splits\n    oof_preds5 += model5.predict_proba(df_plus)[:,1]/kf.n_splits\n    roc5.append(roc_auc_score(val_y , model5.predict_proba(val_x)[:,1]))\n    print(n+1 , roc5[n])\n    n+=1"},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters_df11['metric'] = 'auc'\nparameters_df11['device'] = 'cpu'\npreds = np.zeros(dft1.shape[0])\noof_preds = np.zeros(df1.shape[0])\nkf = StratifiedKFold(n_splits = 10 , random_state = 22 , shuffle = True)\nroc = []\nn = 0\nfor trn_idx , val_idx in kf.split(df1 , df_target):\n    train_x = df1.iloc[trn_idx]\n    train_y = df_target.iloc[trn_idx]\n    val_x = df1.iloc[val_idx]\n    val_y = df_target.iloc[val_idx]\n    \n    model = lightgbm.LGBMClassifier(**parameters_df11)\n    model.fit(train_x , train_y , eval_set = [(val_x , val_y)] , early_stopping_rounds = 4000 , \\\n             verbose = False)\n    clf = CalibratedClassifierCV(model, cv='prefit', method='sigmoid')\n    clf.fit(train_x , train_y)\n    preds += clf.predict_proba(dft1)[:,1]/kf.n_splits\n    oof_preds += clf.predict_proba(df1)[:,1]/kf.n_splits\n    roc.append(roc_auc_score(val_y , clf.predict_proba(val_x)[:,1]))\n    print(n+1 , roc[n])\n    n+=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"parameters_df13['metric'] = 'auc'\nparameters_df13['device'] = 'cpu'\npreds2 = np.zeros(dft1.shape[0])\noof_preds2 = np.zeros(df1.shape[0])\nkf = StratifiedKFold(n_splits = 10 , random_state = 42 , shuffle = True)\nroc2 = []\nn = 0\nfor trn_idx , val_idx in kf.split(df1 , df_target):\n    train_x = df1.iloc[trn_idx]\n    train_y = df_target.iloc[trn_idx]\n    val_x = df1.iloc[val_idx]\n    val_y = df_target.iloc[val_idx]\n    \n    model2 = lightgbm.LGBMClassifier(**parameters_df13)\n    model2.fit(train_x , train_y , eval_set = [(val_x , val_y)] , early_stopping_rounds = 200 , \\\n             verbose = False)\n    preds2 += model2.predict_proba(dft1)[:,1]/kf.n_splits\n    oof_preds2 += model2.predict_proba(df1)[:,1]/kf.n_splits\n    roc2.append(roc_auc_score(val_y , model2.predict_proba(val_x)[:,1]))\n    print(n+1 , roc2[n])\n    n+=1"},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters_df21['metric'] = 'auc'\nparameters_df21['device'] = 'cpu'\npreds3 = np.zeros(dft2.shape[0])\noof_preds3 = np.zeros(df2.shape[0])\nkf = StratifiedKFold(n_splits = 10 , random_state = 22 , shuffle = True)\nroc3 = []\nn = 0\nfor trn_idx , val_idx in kf.split(df2, df_target):\n    train_x = df2.iloc[trn_idx]\n    train_y = df_target.iloc[trn_idx]\n    val_x = df2.iloc[val_idx]\n    val_y = df_target.iloc[val_idx]\n    \n    model3 = lightgbm.LGBMClassifier(**parameters_df21)\n    model3.fit(train_x , train_y , eval_set = [(val_x , val_y)] , early_stopping_rounds = 4000 , \\\n             verbose = False)\n    clf3 = CalibratedClassifierCV(model3, cv='prefit', method='sigmoid')\n    clf3.fit(train_x , train_y)\n    preds3 += clf3.predict_proba(dft2)[:,1]/kf.n_splits\n    oof_preds3 += clf3.predict_proba(df2)[:,1]/kf.n_splits\n    roc3.append(roc_auc_score(val_y , clf3.predict_proba(val_x)[:,1]))\n    print(n+1 , roc3[n])\n    n+=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"parameters_df23['metric'] = 'auc'\nparameters_df23['device'] = 'cpu'\npreds4 = np.zeros(dft2.shape[0])\noof_preds4 = np.zeros(df2.shape[0])\nkf = StratifiedKFold(n_splits = 10 , random_state = 42 , shuffle = True)\nroc4 = []\nn = 0\nfor trn_idx , val_idx in kf.split(df , df_target):\n    train_x = df2.iloc[trn_idx]\n    train_y = df_target.iloc[trn_idx]\n    val_x = df2.iloc[val_idx]\n    val_y = df_target.iloc[val_idx]\n    \n    model4 = lightgbm.LGBMClassifier(**parameters_df23)\n    model4.fit(train_x , train_y , eval_set = [(val_x , val_y)] , early_stopping_rounds = 200 , \\\n             verbose = False)\n    preds4 += model4.predict_proba(dft2)[:,1]/kf.n_splits\n    oof_preds4 += model4.predict_proba(df2)[:,1]/kf.n_splits\n    roc4.append(roc_auc_score(val_y , model4.predict_proba(val_x)[:,1]))\n    print(n+1 , roc4[n])\n    n+=1"},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_sample.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pro= (preds*0.9)+(preds3*0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_sample['target'] = pro","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_sample.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_sample.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}