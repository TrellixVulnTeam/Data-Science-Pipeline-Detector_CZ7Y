{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Setup"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Libraries\nimport numpy as np\nimport pandas as pd\n\nfrom lightgbm import LGBMClassifier\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\n\nimport optuna\nfrom optuna.visualization import plot_optimization_history, plot_param_importances\n\nfrom IPython.display import display","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read data\ntrain = pd.read_csv('../input/tabular-playground-series-mar-2021/train.csv', index_col=0)\ntest = pd.read_csv('../input/tabular-playground-series-mar-2021/test.csv', index_col=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predictors & target\npredictors = train.columns[:-1]\ntarget = train.columns[-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data processing\ncat_cols = [col for col in predictors if 'cat' in col]\n\ntrain[cat_cols] = train[cat_cols].astype('category')\ntrain[target] = train[target].astype('category')\n\ntest[cat_cols] = test[cat_cols].astype('category')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Functions for training, evaluation and prediction"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Functions for KFold evaluation\ndef create(hyperparams):\n    \"\"\"Create LGBM Classifier for a given set of hyper-parameters.\"\"\"\n    model = LGBMClassifier(**hyperparams)\n    return model\n\ndef fit(model, X, y):\n    \"\"\"Simple training of a given model.\"\"\"\n    model.fit(X, y)\n    return model\n\ndef fit_with_stop(model, X, y, X_val, y_val, esr):\n    \"\"\"Advanced training with early stopping.\"\"\"\n    model.fit(X, y,\n              eval_set=(X_val, y_val),\n              early_stopping_rounds=esr, \n              verbose=200)\n    return model\n\ndef evaluate(model, X, y):\n    \"\"\"Compute AUC for a given model.\"\"\"\n    yp = model.predict_proba(X)[:, 1]\n    auc_score = roc_auc_score(y, yp)\n    return auc_score\n\ndef kfold_evaluation(X, y, k, hyperparams, esr=100):\n    \"\"\"Run a KFlod evaluation.\"\"\"\n    scores = []\n    \n    print(f\"\\n------ {k}-fold evaluation -----\")\n    print(hyperparams)\n    \n    kf = KFold(k)\n    for i, (train_idx, test_idx) in enumerate(kf.split(X)):\n        print(f\"\\n----- FOLD {i} -----\")\n        \n        X_train = X.iloc[train_idx]\n        y_train = y.iloc[train_idx]\n        X_val = X.iloc[test_idx]\n        y_val = y.iloc[test_idx]\n        \n        model = create(hyperparams)\n        model = fit_with_stop(model, X_train, y_train, X_val, y_val, esr)\n        train_score = evaluate(model, X_train, y_train)\n        val_score = evaluate(model, X_val, y_val)\n        scores.append((train_score, val_score))\n        \n        print(f\"Fold {i} | Eval AUC: {val_score}\")\n        \n        \n    scores = pd.DataFrame(scores, columns=['train score', 'validation score'])\n    \n    return scores\n\ndef kfold_prediction(X, y, X_test, k, hyperparams, esr=100):\n    \"\"\"Make predictions with a bagged model based on KFold.\"\"\"\n    yp = np.zeros(len(X_test))\n    \n    print(f\"\\n------ {k}-fold evaluation -----\")\n    print(hyperparams)\n    \n    kf = KFold(k)\n    for i, (train_idx, test_idx) in enumerate(kf.split(X)):\n        print(f\"\\n----- FOLD {i} -----\")\n        X_train = X.iloc[train_idx]\n        y_train = y.iloc[train_idx]\n        X_val = X.iloc[test_idx]\n        y_val = y.iloc[test_idx]\n        \n        model = create(hyperparams)\n        model = fit_with_stop(model, X_train, y_train, X_val, y_val, esr)\n        yp += model.predict_proba(X_test)[:, 1] / k\n    \n    return yp","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Optuna Tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Constant\nK = 10\nX = train[predictors]\nY = train[target]\nX_TEST = test[predictors]\nBEST_PARAMS = {\n    'n_estimators': 10000, # Waiting for early-stopping\n    'learning_rate': 0.05, # Me\n    'metric': 'auc' # Me\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Objective function\ndef objective(trial):\n    # Search spaces\n    hyperparams = {\n        'reg_alpha': trial.suggest_float('reg_alpha', 0.001, 10.0),\n        'reg_lambda': trial.suggest_float('reg_lambda', 0.001, 10.0),\n        'num_leaves': trial.suggest_int('num_leaves', 5, 1000),\n        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n        'max_depth': trial.suggest_int('max_depth', 5, 64),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 0.5),\n        'cat_smooth' : trial.suggest_int('cat_smooth', 10, 100),\n        'cat_l2': trial.suggest_int('cat_l2', 1, 20),\n        'min_data_per_group': trial.suggest_int('min_data_per_group', 50, 200)\n    }\n    \n    # Add BEST_PARAMS\n    hyperparams.update(BEST_PARAMS)\n    \n    # Evaluation\n    scores = kfold_evaluation(X, Y, K, hyperparams, 100)\n    \n    return scores['validation score'].mean()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# Optimization\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, timeout=3600*7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Best score\nstudy.best_value","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Historic\nplot_optimization_history(study)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importance\nplot_param_importances(study)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Best parameters\nBEST_PARAMS.update(study.best_params)\nBEST_PARAMS","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submision"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Update hyperparams for prediction\nBEST_PARAMS['learning_rate'] = 0.005","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# Predictions on test set and submission\ntest[target] = kfold_prediction(X, Y, X_TEST, 10, BEST_PARAMS, 500)\ntest[target].to_csv('submission.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}