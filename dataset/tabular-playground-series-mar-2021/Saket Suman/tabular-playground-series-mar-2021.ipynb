{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport plotly.express as ex\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots as mk_sp\nimport seaborn as sns\nimport plotly.offline as pyo\npyo.init_notebook_mode()\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nplt.rc('figure', figsize=(18,9))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:azure; text-align:center; font-size:300%\">1. Loading Data...</h1>","metadata":{}},{"cell_type":"code","source":"data=pd.read_csv('../input/tabular-playground-series-mar-2021/train.csv')\ntest=pd.read_csv('../input/tabular-playground-series-mar-2021/test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:azure; text-align:center; font-size:300%\">2. Exploratory Data Analysis</h1>","metadata":{}},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Null elements present in train set {:d}\".format(sum(data.isnull().sum())))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Null elements present in test set {:d}\".format(sum(test.isnull().sum())))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"background-color:azure; text-align:center; font-size:200%\">2.1 Continuous variables</h2>","metadata":{}},{"cell_type":"code","source":"data.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"train set ranges between -0.05 to 1.02\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"test set ranges between -0.05 to 1.02\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(nrows=4, ncols=3, facecolor='#f6f5f5', figsize=(20,12))\nr=0\nc=0\nfor i in range(11):\n    s=\"cont\"+str(i)\n    sns.histplot(data, x=s, ax=ax[r][c], element='poly')\n    c+=1\n    if(c==3):\n        r+=1\n        c=0\nfig.suptitle('Distribution of train set of Continuous Features', fontsize=20)\nax[3][2].remove()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(nrows=4, ncols=3, facecolor='#f6f5f5', figsize=(20,12))\nr=0\nc=0\nfor i in range(11):\n    s=\"cont\"+str(i)\n    sns.histplot(test, x=s, ax=ax[r][c], element='poly')\n    c+=1\n    if(c==3):\n        r+=1\n        c=0\nfig.suptitle('Distribution of test set of Continuous Features', fontsize=20)\nax[3][2].remove()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(nrows=4, ncols=3, facecolor='#f6f5f5', figsize=(20,12))\nr=0\nc=0\nfor i in range(11):\n    s=\"cont\"+str(i)\n    sns.histplot(data, x=s, hue='target', ax=ax[r][c], element='poly')\n    c+=1\n    if(c==3):\n        r+=1\n        c=0\nfig.suptitle('Distribution of train set of Continuous Features hue wise', fontsize=20)\nax[3][2].remove()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"the distribution of 0 and 1 target is same in continuous feature\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(ncols=2, facecolor='#f6f5f5', figsize=(24, 14))\ncols=['cont'+str(i) for i in range(11)]\ndcorr=data[cols].corr('pearson')\ntcorr=test[cols].corr('pearson')\nmask = np.triu(np.ones_like(dcorr, dtype=np.bool))\n\nsns.heatmap(dcorr, mask=mask, ax=ax[0], annot=True, fmt=\".2f\", cmap='coolwarm')\nsns.heatmap(tcorr, mask=mask, ax=ax[1], annot=True, fmt=\".2f\", cmap='coolwarm')\nax[0].set_title('Correlation of train set')\nax[1].set_title('Correlation of test set')\nfig.suptitle('Correlation Matrix', fontsize=20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Max corr in train set and test is {:d}% between cont1 and cont2\".format(86))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Thanks a lot @dwin183287 for sharing this amazinf function!\n\nbackground_color = \"#f6f5f5\"\ncols = [\"cont\"+str(i) for i in range(11)]\nfig = plt.figure(figsize=(12, 8), facecolor=background_color)\ngs = fig.add_gridspec(1, 1)\nax0 = fig.add_subplot(gs[0, 0])\n\nax0.set_facecolor(background_color)\nax0.text(-1.1, 0.26, 'Correlation of Continuous Features with Target', fontsize=20, fontweight='bold', fontfamily='serif')\nax0.text(-1.1, 0.24, 'There is no features that pass 0.22 correlation with target', fontsize=13, fontweight='light', fontfamily='serif')\n\nchart_df = pd.DataFrame(data[cols].corrwith(data['target']))\nchart_df.columns = ['corr']\nsns.barplot(x=chart_df.index, y=chart_df['corr'], ax=ax0, color='RoyalBlue', zorder=3, edgecolor='black', linewidth=1.5)\nax0.grid(which='major', axis='y', zorder=0, color='gray', linestyle=':', dashes=(1,5))\nax0.set_ylabel('')\n\nfor s in [\"top\",\"right\", 'left']:\n    ax0.spines[s].set_visible(False)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"background-color:azure; text-align:center; font-size:200%\">2.2 Categorical variables</h2>","metadata":{}},{"cell_type":"code","source":"for i in range(19):\n    s=\"cat\"+str(i)\n    l1=data[s].unique()\n    l2=test[s].unique()\n    if(sorted(l1) != sorted(l2)):\n        print(\"Feature having different categorical variable is \"+s)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"length of cat10 feature in train set is {:d} and in test set is {:d}\".format(len(data['cat10'].unique()), len(test['cat10'].unique())))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l1=data['cat10'].unique()\nl2=test['cat10'].unique()\nx=[i for i in l1 if i not in l2]\ny=[i for i in l2 if i not in l1]\nprint(\"Features present in l1 but not in l2:\", x)\nprint(\"Features present in l2 but not in l1:\", y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prev=0\nfor i in range(19):\n    s=\"cat\"+str(i)\n    print(s+\" has {:d} unique values\".format(len(data[s].unique())))\n    prev+=len(data[s].unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l1=[]\nfor i in range(19):\n    s=\"cat\"+str(i)\n    df=data.groupby([s])[s].count().sort_values(ascending=False)\n    val=100.0*df.values[0]/len(data)\n    if(val>=50.0):\n        l1.append(s+\" : \"+df.index[0])\n    print(\"Percentage of {:s} in {:s} is {:.2f}%\".format(df.index[0], s, val))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(l1, \"are categorical features having more than 50% of train set\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig=mk_sp(rows=3, cols=3)\nr=1\nc=1\nl1=['cat0']+[\"cat\"+str(i) for i in range(11, 19)]\nfor i in l1:\n    df=data.groupby([i])[i].count().sort_values(ascending=False)\n#     df=data['cat0'].value_counts().sort_values(ascending=True)\n    x1=go.Bar(x=df.index, y=df.values)\n    fig.add_trace(x1, row=r, col=c)\n    fig.update_xaxes(title=i, row=r, col=c)\n    fig.update_layout(barmode='stack')\n    c+=1\n    if(c==4):\n        r+=1\n        c=1\nfig.update_layout(width=1000, height=700,title_text=\"Distribution of train set of Continuous Features with categories < 10\", showlegend=False)\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig=mk_sp(rows=3, cols=3)\nr=1\nc=1\nl1=['cat0']+[\"cat\"+str(i) for i in range(11, 19)]\nfor i in l1:\n    df=test.groupby([i])[i].count().sort_values(ascending=False)\n#     df=data['cat0'].value_counts().sort_values(ascending=True)\n    x1=go.Bar(x=df.index, y=df.values, name='Label: 0')\n    fig.add_trace(x1, row=r, col=c)\n    fig.update_xaxes(title=i, row=r, col=c)\n    fig.update_layout(barmode='stack')\n    c+=1\n    if(c==4):\n        r+=1\n        c=1\nfig.update_layout(width=1000, height=700,title_text=\"Distribution of test set of Continuous Features with categories < 10\", showlegend=False)\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig=mk_sp(rows=4, cols=3)\nr=1\nc=1\nl1=[\"cat\"+str(i) for i in range(1, 11)]\nfor i in l1:\n    df=data.groupby([i])[i].count().sort_values(ascending=False)\n#     df=data['cat0'].value_counts().sort_values(ascending=True)\n    x1=go.Bar(x=df.index, y=df.values)\n    fig.add_trace(x1, row=r, col=c)\n    fig.update_xaxes(title=i, row=r, col=c)\n    fig.update_layout(barmode='stack')\n    c+=1\n    if(c==4):\n        r+=1\n        c=1\nfig.update_layout(width=1600, height=1600,title_text=\"Distribution of train set of Continuous Features with categories > 10\", showlegend=False)\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig=mk_sp(rows=4, cols=3)\nr=1\nc=1\nl1=[\"cat\"+str(i) for i in range(1, 11)]\nfor i in l1:\n    df=test.groupby([i])[i].count().sort_values(ascending=False)\n#     df=data['cat0'].value_counts().sort_values(ascending=True)\n    x1=go.Bar(x=df.index, y=df.values)\n    fig.add_trace(x1, row=r, col=c)\n    fig.update_xaxes(title=i, row=r, col=c)\n    fig.update_layout(barmode='stack')\n    c+=1\n    if(c==4):\n        r+=1\n        c=1\nfig.update_layout(width=1600, height=1600,title_text=\"Distribution of test set of Continuous Features with categories > 10\", showlegend=False)\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig=mk_sp(rows=3, cols=3)\nr=1\nc=1\ndata_0=data[data[\"target\"]==0]\ndata_1=data[data[\"target\"]==1]\nl1=['cat0']+[\"cat\"+str(i) for i in range(11, 19)]\nfor i in l1:\n    df_0=data_0.groupby([i])[i].count().sort_values(ascending=False)\n    df_1=data_1.groupby([i])[i].count().sort_values(ascending=False)\n#     df=data['cat0'].value_counts().sort_values(ascending=True)\n    x1=go.Bar(x=df_0.index, y=df_0.values, name='Label: 0')\n    x2=go.Bar(x=df_1.index, y=df_1.values, name='Label: 1')\n    fig.add_trace(x1, row=r, col=c)\n    fig.add_trace(x2, row=r, col=c)\n    fig.update_xaxes(title=i, row=r, col=c)\n    fig.update_layout(barmode='stack')\n    c+=1\n    if(c==4):\n        r+=1\n        c=1\nfig.update_layout(width=1000, height=700,title_text=\"Distribution of train set of Continuous Features hue wise < 10\", showlegend=False)\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig=mk_sp(rows=4, cols=3)\nr=1\nc=1\ndata_0=data[data[\"target\"]==0]\ndata_1=data[data[\"target\"]==1]\nl1=[\"cat\"+str(i) for i in range(1, 11)]\nfor i in l1:\n    df_0=data_0.groupby([i])[i].count().sort_values(ascending=False)\n    df_1=data_1.groupby([i])[i].count().sort_values(ascending=False)\n#     df=data['cat0'].value_counts().sort_values(ascending=True)\n    x1=go.Bar(x=df_0.index, y=df_0.values, name='Label: 0')\n    x2=go.Bar(x=df_1.index, y=df_1.values, name='Label: 1')\n    fig.add_trace(x1, row=r, col=c)\n    fig.add_trace(x2, row=r, col=c)\n    fig.update_xaxes(title=i, row=r, col=c)\n    fig.update_layout(barmode='stack')\n    c+=1\n    if(c==4):\n        r+=1\n        c=1\nfig.update_layout(width=1600, height=1600,title_text=\"Distribution of train set of Continuous Features  with categories > 10\", showlegend=False)\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"background-color:azure; text-align:center; font-size:200%\">2.3 Target variable</h2>","metadata":{}},{"cell_type":"code","source":"print('Percentage of target variable: 0 is {:.2f}%'.format(100.0*len(data[data['target']==0])/len(data)))\nprint('Percentage of target variable: 1 is {:.2f}%'.format(100.0*len(data[data['target']==1])/len(data)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"background-color:azure; text-align:center; font-size:200%\">2.4 Attribute relevance analysis</h2>","metadata":{}},{"cell_type":"code","source":"df=data[['cat'+str(i) for i in range(19)]+['cont'+str(i) for i in range(11)]+['target']].copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(11):\n    s='cont'+str(i)\n    df[s+'bin'] = pd.qcut(df[s], 5, labels=[s+'_'+str(x) for x in range(1,6)])\ndf.drop(['cont'+str(i) for i in range(11)], axis=1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Among categorical variables cat10 has different train and test categories so making different categories same\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['cat10']=df['cat10'].apply(lambda x:x if x not in ['BS', 'MW', 'CH', 'AW', 'MO', 'MK', 'GH', 'FW', 'JF', 'LK', 'IL', 'CX'] else 'cat10_0')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def WoE_IV(feature, df, target):\n    lst=[]\n    for i in range(df[feature].nunique()):\n        val=list(df[feature].unique())\n        lst.append({\n                \"Value\": val[i],\n                \"All\": df[df[feature]==val[i]].count()[feature],\n                \"Good\": df[(df[feature]==val[i]) & (df[target]==1)].count()[feature],\n                \"Bad\": df[(df[feature]==val[i]) & (df[target]==0)].count()[feature]\n             })\n        \n    df_=pd.DataFrame(lst)\n    df_['Distr_Good'] = df_['Good'] / df_['Good'].sum()\n    df_['Distr_Bad'] = df_['Bad'] / df_['Bad'].sum()\n    df_['WoE'] = np.log(df_['Distr_Good'] / df_['Distr_Bad'])\n    df_ = df_.replace({'WoE': {np.inf: 0, -np.inf: 0}})\n    df_['IV'] = (df_['Distr_Good'] - df_['Distr_Bad']) * df_['WoE']\n    iv = df_['IV'].sum()\n    df_ = df_.sort_values(by='WoE')\n    return df_, iv","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lst=[]\nfor col in df.columns:\n    if col=='target':\n        continue\n    else:\n        print(\"WoE and IV for column: {:s}\".format(col))\n        df_, iv = WoE_IV(col, df, 'target')\n        l1=[]\n        l2=[]\n        for i in range(1, len(df_)):\n            if(df_['WoE'].values[i]-df_['WoE'].values[i-1]<0.09):\n                if(len(l2)==0):\n                    l2.append(df_['Value'].values[i-1])\n                    l2.append(df_['Value'].values[i])\n                else:\n                    l2.append(df_['Value'].values[i])\n            else:\n                if(len(l2)>0):\n                    l1.append(l2)\n                l2=[]\n        print(df_)\n        print(\"IV score: {:.2f}\".format(iv))\n        if(iv>0.1):\n            lst.append((col, iv, l1))\n        print('\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"![](https://miro.medium.com/max/616/1*rSR3ThQsO9YYvOp7WPL_GQ.png)","metadata":{}},{"cell_type":"code","source":"print(\"attributes having IV>0.1 and categories having same predictive power for each feature\")\nlst","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:azure; text-align:center; font-size:300%\">3. Feature Engineering</h1>","metadata":{}},{"cell_type":"code","source":"print(\"Among categorical variables cat10 has different train and test categories so making different categories same\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['cat10']=data['cat10'].apply(lambda x:x if x not in ['BS', 'MW', 'CH', 'AW', 'MO', 'MK', 'GH', 'FW', 'JF', 'LK', 'IL', 'CX'] else 'cat10_0')\ntest['cat10']=test['cat10'].apply(lambda x:x if x not in ['BU', 'EJ', 'BW', 'JM', 'KM', 'DG', 'CA', 'KE'] else 'cat10_0')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"dropping features having IV <= 0.1\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.drop(columns=['id', 'cat3','cat5','cat12', 'cont0', 'cont4', 'cont7', 'cont10'], inplace=True)\ntest.drop(columns=['id', 'cat3','cat5','cat12', 'cont0', 'cont4', 'cont7', 'cont10'], inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Merging categories having similare WoE value\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lst=lst[:16]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for l1 in lst:\n    s=l1[0]\n    l2=l1[2]\n    i=0\n    for l3 in l2:\n        data[s]=data[s].apply(lambda x:x if x not in l3 else s+str(i))\n        test[s]=test[s].apply(lambda x:x if x not in l3 else s+str(i))\n        i=i+1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig=mk_sp(rows=3, cols=3)\nr=1\nc=1\nl1=[\"cat\"+str(i) for i in range(1, 11)]\nfor i in l1:\n    if i not in data.columns:\n        continue\n    df=data.groupby([i])[i].count().sort_values(ascending=False)\n#     df=data['cat0'].value_counts().sort_values(ascending=True)\n    x1=go.Bar(x=df.index, y=df.values)\n    fig.add_trace(x1, row=r, col=c)\n    fig.update_xaxes(title=i, row=r, col=c)\n    fig.update_layout(barmode='stack')\n    c+=1\n    if(c==4):\n        r+=1\n        c=1\nfig.update_layout(width=1600, height=1600,title_text=\"Distribution of train set of Continuous Features with categories > 10\", showlegend=False)\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig=mk_sp(rows=3, cols=3)\nr=1\nc=1\nl1=['cat0']+[\"cat\"+str(i) for i in range(11, 19)]\nfor i in l1:\n    if i not in data.columns:\n        continue\n    df=data.groupby([i])[i].count().sort_values(ascending=False)\n#     df=data['cat0'].value_counts().sort_values(ascending=True)\n    x1=go.Bar(x=df.index, y=df.values)\n    fig.add_trace(x1, row=r, col=c)\n    fig.update_xaxes(title=i, row=r, col=c)\n    fig.update_layout(barmode='stack')\n    c+=1\n    if(c==4):\n        r+=1\n        c=1\nfig.update_layout(width=1000, height=700,title_text=\"Distribution of train set of Continuous Features with categories < 10\", showlegend=False)\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new=0\nfor i in range(19):\n    s=\"cat\"+str(i)\n    if s not in data.columns:\n        continue\n    print(s+\" has {:d} unique values\".format(len(data[s].unique())))\n    new+=len(data[s].unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Reduction in categorical dimension is {:d}\".format(prev-new))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Percentage reduction in categorical dimension is {:.2f}%\".format(100.0*(prev-new)/prev))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Percentage reduction in dimension is {:.2f}%\".format(100.0*(prev+4-new)/prev))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\n%pip install imbalanced-learn\nfrom imblearn.over_sampling import SMOTE","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ohe=OneHotEncoder()\ncol=[c for c in data.columns[:16]]\nohe.fit(data[col])\ndf=pd.DataFrame(columns=ohe.get_feature_names(col),data=ohe.transform(data[col]).toarray())\ndf_=pd.DataFrame(columns=ohe.get_feature_names(col),data=ohe.transform(test[col]).toarray())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.drop(columns=[c for c in data.columns[:16]], inplace=True)\ntest.drop(columns=[c for c in test.columns[:16]], inplace=True)\ndf=df.join(data)\ndf_=df_.join(test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=df.copy()\ntest=df_.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oversample=SMOTE()\nX, y=oversample.fit_resample(data[data.columns[:145]], data[data.columns[145]])\nupsampled = X.assign(Churn = y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"upsampled.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"upsampled.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"upsampled.columns[:-8]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Percentage of target variable: 0 is {:.2f}%'.format(100.0*len(upsampled[upsampled['Churn']==0])/len(upsampled)))\nprint('Percentage of target variable: 1 is {:.2f}%'.format(100.0*len(upsampled[upsampled['Churn']==1])/len(upsampled)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols=upsampled.columns[:-8]\ndcorr=upsampled[cols].corr('pearson')\nfor i in dcorr[(dcorr>0.7) & (dcorr<1)].isnull().sum():\n    if(i!=138):\n        print(i)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"No categorical variables has correlation > 0.7\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(ncols=1, facecolor='#f6f5f5', figsize=(24, 14))\ncols=upsampled.columns[-8:-1]\ndcorr=upsampled[cols].corr('pearson')\nmask = np.triu(np.ones_like(dcorr, dtype=np.bool))\n\nsns.heatmap(dcorr, mask=mask, ax=ax, annot=True, fmt=\".2f\", cmap='coolwarm')\nax.set_title('Correlation of train set')\nfig.suptitle('Correlation Matrix', fontsize=20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Removing continuous feature having correlation > 0.7\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=upsampled.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.drop(columns=['cont2', 'cont8'], inplace=True)\ntest.drop(columns=['cont2', 'cont8'], inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.to_csv('./dupsampled.csv',index=False)\ntest.to_csv('./tupsampled.csv',index=False)","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:azure; text-align:center; font-size:300%\">4. Loading pre-processed data</h1>","metadata":{}},{"cell_type":"code","source":"data=pd.read_csv('../input/tabular/dupsampled.csv')\ntest=pd.read_csv('../input/tabular/tupsampled.csv')\n\ntest.drop(columns=['cont2', 'cont8'], inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 style=\"background-color:azure; text-align:center; font-size:300%\">5. Base Model</h1>","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import KFold, train_test_split\nfrom catboost import CatBoostClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.metrics import roc_auc_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def split(a, b):\n    return a/b","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features=data.columns[:-1]\nX = data[features]\ny = data['Churn']\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size=split(15000, len(data)), random_state=39)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train.shape, y_train.shape, x_test.shape, y_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb=XGBClassifier(n_jobs=-1)\nxgb.fit(x_train, y_train, verbose=True, eval_metric=\"auc\", eval_set=[(x_test, y_test)], early_stopping_rounds=150)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = xgb.predict_proba(x_test)[:,1]\nauc = roc_auc_score(y_test, predictions)\nprint('Baseline Score of xgboost: {:.2f}'.format(auc))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgbm = LGBMClassifier(n_jobs=-1)\nlgbm.fit(x_train, y_train, verbose=True, eval_metric=\"auc\", eval_set=[(x_test, y_test)], early_stopping_rounds=150)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = lgbm.predict_proba(x_test)[:,1]\nauc = roc_auc_score(y_test, predictions)\nprint('Baseline Score of lightgbm: {:.2f}'.format(auc))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat = CatBoostClassifier(eval_metric=\"AUC\")\ncat.fit(x_train, y_train, verbose=True, eval_set=[(x_test, y_test)], early_stopping_rounds=150)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = cat.predict_proba(x_test)[:,1]\nauc = roc_auc_score(y_test, predictions)\nprint('Baseline Score of catboost: {:.2f}'.format(auc))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"folds=5\nkf=KFold(n_splits=folds, random_state=39, shuffle=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"average_score=pd.DataFrame()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"background-color:azure; text-align:center; font-size:200%\">5.1 XGBoost base model</h2>","metadata":{}},{"cell_type":"code","source":"xgb_test_preds = np.zeros(len(x_test), )\nfor fold, (train_ind, val_ind) in enumerate(kf.split(x_train, y_train)):\n    print(\"--> Fold {}\".format(fold + 1))\n    xtrain, xval = x_train.iloc[train_ind], x_train.iloc[val_ind]\n    ytrain, yval = y_train.iloc[train_ind], y_train.iloc[val_ind]\n    xgb = XGBClassifier(eval_metric=\"auc\",\n                        random_state=42,\n                        tree_method=\"gpu_hist\",\n                        gpu_id=\"0\",\n                        use_label_encoder=False\n                       )\n    model =  xgb.fit(xtrain, ytrain, eval_set=[(xval, yval)], verbose=True)\n    pred_train = model.predict_proba(xtrain)[:,1]\n    pred_val = model.predict_proba(xval)[:,1]\n    pred_test = model.predict_proba(x_test)[:,1]\n    xgb_test_preds+= pred_test/folds\n    score1 = roc_auc_score(ytrain, pred_train)\n    score2 = roc_auc_score(yval, pred_val)\n    score3 = roc_auc_score(y_test, pred_test)\n    print('Fold {} AUC Train: {} Validation: {} Test: {}'.format(fold+1, score1, score2, score3))\n    \nprint('OOF AUC: {}'.format(roc_auc_score(y_test, xgb_test_preds)))\naverage_score['xgboost'] = xgb_test_preds ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"background-color:azure; text-align:center; font-size:200%\">5.2 LGBM base model</h2>","metadata":{}},{"cell_type":"code","source":"lgbm_test_preds = np.zeros(len(x_test), )\nfor fold, (train_ind, val_ind) in enumerate(kf.split(x_train, y_train)):\n    print(\"--> Fold {}\".format(fold + 1))\n    xtrain, xval = x_train.iloc[train_ind], x_train.iloc[val_ind]\n    ytrain, yval = y_train.iloc[train_ind], y_train.iloc[val_ind]\n    lgbm = LGBMClassifier(metric=\"auc\",\n                          random_state=42,\n                          device='gpu')\n    model =  lgbm.fit(xtrain, ytrain, eval_set=[(xval, yval)], verbose=True)\n    pred_train = model.predict_proba(xtrain)[:,1]\n    pred_val = model.predict_proba(xval)[:,1]\n    pred_test = model.predict_proba(x_test)[:,1]\n    lgbm_test_preds+= pred_test/folds\n    score1 = roc_auc_score(ytrain, pred_train)\n    score2 = roc_auc_score(yval, pred_val)\n    score3 = roc_auc_score(y_test, pred_test)\n    print('Fold {} AUC Train: {} Validation: {} Test: {}'.format(fold+1, score1, score2, score3))\n    \nprint('OOF AUC: {}'.format(roc_auc_score(y_test, lgbm_test_preds)))\naverage_score['lgbm'] = lgbm_test_preds ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"background-color:azure; text-align:center; font-size:200%\">5.3 CatBoost base model</h2>","metadata":{}},{"cell_type":"code","source":"cat_test_preds = np.zeros(len(x_test), )\nfor fold, (train_ind, val_ind) in enumerate(kf.split(x_train, y_train)):\n    print(\"--> Fold {}\".format(fold + 1))\n    xtrain, xval = x_train.iloc[train_ind], x_train.iloc[val_ind]\n    ytrain, yval = y_train.iloc[train_ind], y_train.iloc[val_ind]\n    cat = CatBoostClassifier(verbose=0,\n                             eval_metric=\"AUC\",\n                             random_state=42,\n                             task_type=\"GPU\",\n                             devices=\"0\")\n    model =  cat.fit(xtrain, ytrain, eval_set=[(xval, yval)], verbose=True)\n    pred_train = model.predict_proba(xtrain)[:,1]\n    pred_val = model.predict_proba(xval)[:,1]\n    pred_test = model.predict_proba(x_test)[:,1]\n    cat_test_preds+= pred_test/folds\n    score1 = roc_auc_score(ytrain, pred_train)\n    score2 = roc_auc_score(yval, pred_val)\n    score3 = roc_auc_score(y_test, pred_test)\n    print('Fold {} AUC Train: {} Validation: {} Test: {}'.format(fold+1, score1, score2, score3))\n    \nprint('OOF AUC: {}'.format(roc_auc_score(y_test, cat_test_preds)))\naverage_score['catboost'] = cat_test_preds ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"average_score['average1']=average_score.mean(axis=1)\naverage_score['average2']=0.35*average_score['xgboost']+0.35*average_score['catboost']+0.3*average_score['lgbm']\naverage_score['average3']=0.4*average_score['xgboost']+0.3*average_score['catboost']+0.3*average_score['lgbm']\naverage_score['average4']=0.3*average_score['xgboost']+0.4*average_score['catboost']+0.3*average_score['lgbm']\naverage_score['average5']=0.4*average_score['xgboost']+0.4*average_score['catboost']+0.2*average_score['lgbm']\naverage_score['average6']=0.5*average_score['xgboost']+0.3*average_score['catboost']+0.2*average_score['lgbm']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"average_score.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('OOF AUC xgboost: {}'.format(roc_auc_score(y_test, average_score['xgboost'])))\nprint('OOF AUC lgbm: {}'.format(roc_auc_score(y_test, average_score['lgbm'])))\nprint('OOF AUC catboost: {}'.format(roc_auc_score(y_test, average_score['catboost'])))\nprint('OOF AUC ensembled1: {}'.format(roc_auc_score(y_test, average_score['average1'])))\nprint('OOF AUC ensembled2: {}'.format(roc_auc_score(y_test, average_score['average2'])))\nprint('OOF AUC ensembled3: {}'.format(roc_auc_score(y_test, average_score['average3'])))\nprint('OOF AUC ensembled4: {}'.format(roc_auc_score(y_test, average_score['average4'])))\nprint('OOF AUC ensembled5: {}'.format(roc_auc_score(y_test, average_score['average5'])))\nprint('OOF AUC ensembled6: {}'.format(roc_auc_score(y_test, average_score['average6'])))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"background-color:azure; text-align:center; font-size:300%\">6. Tuned model</h2>","metadata":{}},{"cell_type":"markdown","source":"<p style=\"background-color:azure; text-align:left; font-size:100%\">Hyperparmaters are taken from TPS Mar 2021 - Stacked Starter by Craig Thomas</p>","metadata":{}},{"cell_type":"markdown","source":"<h2 style=\"background-color:azure; text-align:center; font-size:200%\">6.1 XGBoost tuned model</h2>","metadata":{}},{"cell_type":"code","source":"all_score=pd.DataFrame()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_test_preds = np.zeros(len(x_test), )\nxgb_TEST_preds = np.zeros(len(test), )\nfor fold, (train_ind, val_ind) in enumerate(kf.split(x_train, y_train)):\n    print(\"--> Fold {}\".format(fold + 1))\n    xtrain, xval = x_train.iloc[train_ind], x_train.iloc[val_ind]\n    ytrain, yval = y_train.iloc[train_ind], y_train.iloc[val_ind]\n    xgb = XGBClassifier(\n                        seed=2021,\n                        n_estimators=10000,\n                        verbosity=1,\n                        eval_metric=\"auc\",\n                        tree_method=\"gpu_hist\",\n                        gpu_id=0,\n                        alpha=7.105038963844129,\n                        colsample_bytree=0.25505629740052566,\n                        gamma=0.4999381950212869,\n                        reg_lambda=1.7256912198205319,\n                        learning_rate=0.011823142071967673,\n                        max_bin=338,\n                        max_depth=8,\n                        min_child_weight=2.286836198630466,\n                        subsample=0.618417952155855,\n                        use_label_encoder=False\n                       )\n    model =  xgb.fit(xtrain, ytrain, eval_set=[(xval, yval)], early_stopping_rounds=50, verbose=True)\n    pred_train = model.predict_proba(xtrain)[:,1]\n    pred_val = model.predict_proba(xval)[:,1]\n    pred_test = model.predict_proba(x_test)[:,1]\n    pred_TEST = model.predict_proba(test)[:,1]\n    xgb_test_preds+= pred_test/folds\n    xgb_TEST_preds+= pred_TEST/folds\n    score1 = roc_auc_score(ytrain, pred_train)\n    score2 = roc_auc_score(yval, pred_val)\n    score3 = roc_auc_score(y_test, pred_test)\n    print('Fold {} AUC Train: {} Validation: {} Test: {}'.format(fold+1, score1, score2, score3))\n    \nprint('OOF AUC: {}'.format(roc_auc_score(y_test, xgb_test_preds)))\naverage_score['xgboost'] = xgb_test_preds\nall_score['xgboost'] = xgb_TEST_preds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"background-color:azure; text-align:center; font-size:200%\">6.2 LGBM tuned model</h2>","metadata":{}},{"cell_type":"code","source":"lgbm_test_preds = np.zeros(len(x_test), )\nlgbm_TEST_preds = np.zeros(len(test), )\nfor fold, (train_ind, val_ind) in enumerate(kf.split(x_train, y_train)):\n    print(\"--> Fold {}\".format(fold + 1))\n    xtrain, xval = x_train.iloc[train_ind], x_train.iloc[val_ind]\n    ytrain, yval = y_train.iloc[train_ind], y_train.iloc[val_ind]\n    lgbm = LGBMClassifier(\n                          random_state=2021,\n                          cat_l2=25.999876242730252,\n                          cat_smooth=89.2699690675538,\n                          colsample_bytree=0.2557260109926193,\n                          early_stopping_round=200,\n                          learning_rate=0.00918685483594994,\n                          max_bin=788,\n                          max_depth=81,\n                          metric=\"auc\",\n                          min_child_samples=292,\n                          min_data_per_group=177,\n                          n_estimators=1600000,\n                          n_jobs=-1,\n                          num_leaves=171,\n                          reg_alpha=0.7115353581785044,\n                          reg_lambda=5.658115293998945,\n                          subsample=0.9262904583735796,\n                          subsample_freq=1)\n    model =  lgbm.fit(xtrain, ytrain, eval_set=[(xval, yval)], verbose=True)\n    pred_train = model.predict_proba(xtrain)[:,1]\n    pred_val = model.predict_proba(xval)[:,1]\n    pred_test = model.predict_proba(x_test)[:,1]\n    pred_TEST = model.predict_proba(test)[:,1]\n    lgbm_test_preds+= pred_test/folds\n    lgbm_TEST_preds+= pred_TEST/folds\n    score1 = roc_auc_score(ytrain, pred_train)\n    score2 = roc_auc_score(yval, pred_val)\n    score3 = roc_auc_score(y_test, pred_test)\n    print('Fold {} AUC Train: {} Validation: {} Test: {}'.format(fold+1, score1, score2, score3))\n    \nprint('OOF AUC: {}'.format(roc_auc_score(y_test, lgbm_test_preds)))\naverage_score['lgbm'] = lgbm_test_preds\nall_score['lgbm'] = lgbm_TEST_preds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_test_preds = np.zeros(len(x_test), )\ncat_TEST_preds = np.zeros(len(test), )\nfor fold, (train_ind, val_ind) in enumerate(kf.split(x_train, y_train)):\n    print(\"--> Fold {}\".format(fold + 1))\n    xtrain, xval = x_train.iloc[train_ind], x_train.iloc[val_ind]\n    ytrain, yval = y_train.iloc[train_ind], y_train.iloc[val_ind]\n    cat = CatBoostClassifier(\n                              verbose=0,\n                                eval_metric=\"AUC\",\n                                loss_function=\"Logloss\",\n                                random_state=2021,\n                                num_boost_round=20000,\n                                od_type=\"Iter\",\n                                od_wait=200,\n                                task_type=\"GPU\",\n                                devices=\"0\",\n                                bagging_temperature=1.288692494969795,\n                                grow_policy=\"Depthwise\",\n                                l2_leaf_reg=9.847870133539244,\n                                learning_rate=0.01877982653902465,\n                                max_depth=8,\n                                min_data_in_leaf=1,\n                                penalties_coefficient=2.1176668909602734)\n    model =  cat.fit(xtrain, ytrain, eval_set=[(xval, yval)], verbose=True)\n    pred_train = model.predict_proba(xtrain)[:,1]\n    pred_val = model.predict_proba(xval)[:,1]\n    pred_test = model.predict_proba(x_test)[:,1]\n    pred_TEST = model.predict_proba(test)[:,1]\n    cat_test_preds+= pred_test/folds\n    cat_TEST_preds+= pred_TEST/folds\n    score1 = roc_auc_score(ytrain, pred_train)\n    score2 = roc_auc_score(yval, pred_val)\n    score3 = roc_auc_score(y_test, pred_test)\n    print('Fold {} AUC Train: {} Validation: {} Test: {}'.format(fold+1, score1, score2, score3))\n    \nprint('OOF AUC: {}'.format(roc_auc_score(y_test, cat_test_preds)))\naverage_score['catboost'] = cat_test_preds\nall_score['catboost'] = cat_TEST_preds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_score.to_csv('./score.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"average_score['average1']=average_score.mean(axis=1)\naverage_score['average2']=0.35*average_score['xgboost']+0.35*average_score['catboost']+0.3*average_score['lgbm']\naverage_score['average3']=0.4*average_score['xgboost']+0.3*average_score['catboost']+0.3*average_score['lgbm']\naverage_score['average4']=0.3*average_score['xgboost']+0.4*average_score['catboost']+0.3*average_score['lgbm']\naverage_score['average5']=0.4*average_score['xgboost']+0.4*average_score['catboost']+0.2*average_score['lgbm']\naverage_score['average6']=0.5*average_score['xgboost']+0.3*average_score['catboost']+0.2*average_score['lgbm']\naverage_score['average7']=0.5*average_score['xgboost']+0.5*average_score['lgbm']\naverage_score['average8']=0.5*average_score['xgboost']+0.5*average_score['catboost']\naverage_score['average9']=0.5*average_score['lgbm']+0.5*average_score['catboost']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"average_score.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('OOF AUC xgboost: {}'.format(roc_auc_score(y_test, average_score['xgboost'])))\nprint('OOF AUC lgbm: {}'.format(roc_auc_score(y_test, average_score['lgbm'])))\nprint('OOF AUC catboost: {}'.format(roc_auc_score(y_test, average_score['catboost'])))\nprint('OOF AUC ensembled1: {}'.format(roc_auc_score(y_test, average_score['average1'])))\nprint('OOF AUC ensembled2: {}'.format(roc_auc_score(y_test, average_score['average2'])))\nprint('OOF AUC ensembled3: {}'.format(roc_auc_score(y_test, average_score['average3'])))\nprint('OOF AUC ensembled4: {}'.format(roc_auc_score(y_test, average_score['average4'])))\nprint('OOF AUC ensembled5: {}'.format(roc_auc_score(y_test, average_score['average5'])))\nprint('OOF AUC ensembled6: {}'.format(roc_auc_score(y_test, average_score['average6'])))\nprint('OOF AUC ensembled7: {}'.format(roc_auc_score(y_test, average_score['average7'])))\nprint('OOF AUC ensembled9: {}'.format(roc_auc_score(y_test, average_score['average9'])))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_score['average1']=all_score.mean(axis=1)\nall_score['average2']=0.35*all_score['xgboost']+0.35*all_score['catboost']+0.3*all_score['lgbm']\nall_score['average3']=0.4*all_score['xgboost']+0.3*all_score['catboost']+0.3*all_score['lgbm']\nall_score['average4']=0.3*all_score['xgboost']+0.4*all_score['catboost']+0.3*all_score['lgbm']\nall_score['average5']=0.4*all_score['xgboost']+0.4*all_score['catboost']+0.2*all_score['lgbm']\nall_score['average6']=0.5*all_score['xgboost']+0.3*all_score['catboost']+0.2*all_score['lgbm']\nall_score['average9']=0.5*all_score['lgbm']+0.5*all_score['catboost']\nall_score['average10']=0.5*all_score['xgboost']+0.5*all_score['lgbm']\nall_score['average11']=0.6*all_score['xgboost']+0.4*all_score['lgbm']\nall_score['average12']=0.6*all_score['xgboost']+0.4*all_score['lgbm']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_score.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_=pd.read_csv('../input/tabular-playground-series-mar-2021/test.csv')\nall_score=pd.read_csv('../input/avg-score/score.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_=pd.DataFrame()\ndf_['id']=test_['id'].values\ndf_['target']=all_score['average4']\ndf_.to_csv('./score_avg4.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_=pd.DataFrame()\ndf_['id']=test_['id'].values\ndf_['target']=all_score['average2']\ndf_.to_csv('./score_avg2.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_=pd.DataFrame()\ndf_['id']=test_['id'].values\ndf_['target']=all_score['average1']\ndf_.to_csv('./score_avg1.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_=pd.DataFrame()\ndf_['id']=test_['id'].values\ndf_['target']=all_score['average5']\ndf_.to_csv('./score_avg5.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_=pd.DataFrame()\ndf_['id']=test_['id'].values\ndf_['target']=all_score['average9']\ndf_.to_csv('./score_avg9.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_=pd.DataFrame()\ndf_['id']=test_['id'].values\ndf_['target']=all_score['xgboost']\ndf_.to_csv('./score_xgboost.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_=pd.DataFrame()\ndf_['id']=test_['id'].values\ndf_['target']=all_score['lgbm']\ndf_.to_csv('./score_lgbm.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_=pd.DataFrame()\ndf_['id']=test_['id'].values\ndf_['target']=all_score['average10']\ndf_.to_csv('./score_average10.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_=pd.DataFrame()\ndf_['id']=test_['id'].values\ndf_['target']=all_score['average11']\ndf_.to_csv('./score_average11.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}