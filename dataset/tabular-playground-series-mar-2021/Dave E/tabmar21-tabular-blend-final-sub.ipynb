{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport itertools\nimport os\nfrom glob import glob\n\nfrom sklearn.metrics import mean_squared_error as mse\nfrom sklearn.metrics import mean_absolute_error as mae\nfrom sklearn.metrics import roc_auc_score\n\nimport seaborn as sns\nsns.set(font_scale=1.4)\n\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH = '/kaggle/input/tabular-playground-series-mar-2021/'\ntrain = pd.read_csv(PATH+'train.csv')\ntest = pd.read_csv(PATH+'test.csv')\nsample_submission = pd.read_csv(PATH+'sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load Submission + Out Of Fold Predictions from each model"},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_path  = '/kaggle/input/tabmar21-xgb-for-stacking/'\nlgbm_path  = '/kaggle/input/tabmar21-lgbm-encoded-sub-300321/'\ndae1_path = '/kaggle/input/tabmar21-daesub1/'\ndae2_path = '/kaggle/input/tabmar21-daesub2/'\ndae3_path = '/kaggle/input/tabmar21-daesub3/'\ndae4_path = '/kaggle/input/tabmar21-daesub4/'\ndae5_path = '/kaggle/input/tabmar21-dae-mlp-finalexpts1/'\ndae6_path = '/kaggle/input/tabmar21-dae-narrow-290321/'\ndae7_path = '/kaggle/input/tabmar21-dae-run005/'\ndae8_path = '/kaggle/input/tabmar21-dae-binned1/'\ndae9_path = '/kaggle/input/tabmar21-dae-run3st4/'\n\ndescrs = ['xgb', 'lgbm', 'dae1', 'dae2', 'dae3', 'dae4', 'dae5','dae6', 'dae7', 'dae8',  'dae9',]\n\noof_counts = [len(glob(xgb_path+'*oof*')), len(glob(lgbm_path+'*oof*')), len(glob(dae1_path+ '*oof*')) , len(glob(dae2_path+ '*oof*')),\nlen(glob(dae3_path+ '*oof*')),  len(glob(dae4_path+ '*oof*')), len(glob(dae5_path+ '*oof*')), len(glob(dae6_path+ '*oof*')), len(glob(dae7_path+ '*oof*')), len(glob(dae8_path+ '*oof*')), len(glob(dae9_path+ '*oof*'))] \n\noofs = glob(xgb_path+'*oof*')+ glob(lgbm_path+'*oof*') + glob(dae1_path+ '*oof*') + glob(dae2_path+ '*oof*')+ glob(dae3_path+ '*oof*')+ glob(dae4_path+ '*oof*')+ glob(dae5_path+ '*oof*')+ glob(dae6_path+ '*oof*')+ glob(dae7_path+ '*oof*')+ glob(dae8_path+ '*oof*')+ glob(dae9_path+ '*oof*')\nsubs = glob(xgb_path+'*test*')+glob(lgbm_path+'*test*') + glob(dae1_path+ '*submission*')+ glob(dae2_path+ '*submission*')+ glob(dae3_path+ '*submission*')+ glob(dae4_path+ '*submission*')+ glob(dae5_path+ '*submission*')+ glob(dae6_path+ '*submission*')+ glob(dae7_path+ '*submission*')+ glob(dae8_path+ '*submission*')+ glob(dae9_path+ '*submission*')\n\noofs_dfs = [pd.read_csv(x) for x in oofs]\nsubs_dfs = [pd.read_csv(x) for x in subs]\n\nprint('Out of Fold links', oofs)\n\nprint( '  -   ')\n\nprint('Submission links', subs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert len(oofs) == len(subs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Counts of Inputs')\nprint(len(oofs), len(subs))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_tags = [[z+'_'+str(y) for y in range(x)] for x, z in zip(oof_counts, descrs)]\noutput_tags = [item for sublist in output_tags for item in sublist]\nprint('Model Tags')\noutput_tags","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Individual Model Scores"},{"metadata":{"trusted":true},"cell_type":"code","source":"for count, oo in enumerate(oofs_dfs):\n    print(output_tags[count],roc_auc_score(oo['target'], oo['oof_prediction']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Prediction Correlations"},{"metadata":{},"cell_type":"markdown","source":"Generally blend will be better if there is some variation in models (if all sets of predictions are 100% correlated, blending will not provide any benefit)"},{"metadata":{"trusted":true},"cell_type":"code","source":"combined_oofs = pd.DataFrame()\n\nfor o in oofs_dfs:\n    combined_oofs = pd.concat([combined_oofs, o[['oof_prediction']]], \n                             axis=1)\n    \ncombined_oofs.columns=output_tags    \n\ncombined_oofs_corr = combined_oofs.corr()\n\nsns.set(font_scale=1.3)\n\nfig,axes=plt.subplots(figsize=(12,12))\n\nsns.heatmap(combined_oofs_corr,\n           annot=True,\n           vmin=0.98,\n           vmax=1,\n           fmt='.3f',\n           cmap='seismic_r',\n           linewidth=1,\n         annot_kws={\"fontsize\":8})\n\nplt.title('Model OOF Prediction Correlations')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import optuna\nfrom optuna.samplers import TPESampler\noptuna.logging.set_verbosity(optuna.logging.WARNING)\n\nOPTUNA_TRIALS = 5000\n\ndef run_optimise():\n    print('running Optuna')         \n    class Optimizer:\n        def __init__(self, metric, trials=OPTUNA_TRIALS):\n            self.metric = metric\n            self.trials = trials\n            self.sampler = TPESampler(seed=42)\n\n        def objective(self, trial):\n            #print('running a trial')\n            model_weights = np.array(create_model(trial))\n            model_weights=model_weights/model_weights.sum()\n            \n            oof_blend = np.zeros((len(train),))\n            \n            for count, od in enumerate(oofs_dfs):\n                oof_blend+=oofs_dfs[count]['oof_prediction']*model_weights[count]\n                           \n            \n            error = roc_auc_score(train['target'], oof_blend)\n            return error\n\n        def optimize(self):\n            study = optuna.create_study(direction=\"maximize\", sampler=self.sampler)\n            study.optimize(self.objective, n_trials=self.trials)\n            return study.trials_dataframe()\n\n    def create_model(trial):\n        l_default=0.000\n        u_default=3.0\n        \n        #formatted = ['{0:03}'.format(x) for x in range(len(oofs))]\n        \n        model_weights  = [trial.suggest_uniform(f'oof_weights_{x}', l_default,u_default) for x in output_tags]\n        \n        #print(xgb_weights)\n        \n        return model_weights\n\n    optimizer = Optimizer('mse')\n\n    output_params = optimizer.optimize()\n    \n    return output_params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#%%time\noptim_settings = run_optimise()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optim_settings","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = ['params_oof_weights_' + x for x in output_tags]\noptim_settings[params] = optim_settings[params] / optim_settings[params].sum(axis=1).values.reshape(-1,1)\noptim_settings=optim_settings.sort_values('value',ascending=False).reset_index(drop=True)\noptim_settings[['value']+params].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,axes=plt.subplots(nrows=len(subs)//5+1,ncols=5,figsize=(20,16), sharex=True, sharey=True)\nfor count,p in enumerate(params):\n    axes[count//5,count%5].scatter(x=optim_settings[p], y=optim_settings['value'], color='Red')\n    axes[count//5,count%5].set_title(output_tags[count] + ' weight vs ROCAUC score')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CUTOFF = 10\nweightings = optim_settings.loc[0:CUTOFF,params].mean(axis=0).values\nprint('weightings to use')\nprint({a:np.round(b,4) for a,b in zip(output_tags, weightings)})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weightings.sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Generating Blended OOF and Submission Predictions')\ntrain_predictions = np.zeros((len(train),))\ntest_predictions = np.zeros((len(test),))\nfor count,w in enumerate(weightings):\n    train_predictions += oofs_dfs[count]['oof_prediction']*weightings[count]\n    test_predictions += subs_dfs[count]['target']*weightings[count]\nsns.kdeplot(train_predictions,\n           color='Green')    \nsns.kdeplot(test_predictions,\n           color='Red')\n\nplt.title('Blended Train OOF and Test Predictions')\nplt.legend(['Train', 'Test'], facecolor='White')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Blended ROC AUC Score', roc_auc_score(train['target'], train_predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['target']=test_predictions\nsample_submission.to_csv('submission.csv', index=False)\nsample_submission.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Added - to make individual model outputs available without me having to add all datasets as public, am outputting the files inside this notebook."},{"metadata":{"trusted":true},"cell_type":"code","source":"for count, (descr, oof_file, sub_file) in enumerate(zip(output_tags, oofs_dfs, subs_dfs)):\n    oof_file.to_csv(f'oof_predictions_model_{descr}.csv')\n    sub_file.to_csv(f'test_predictions_model_{descr}.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}