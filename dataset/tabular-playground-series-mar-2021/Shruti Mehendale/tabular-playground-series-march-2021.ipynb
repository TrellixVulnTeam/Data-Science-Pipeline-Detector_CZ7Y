{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.model_selection import cross_val_score\n#from xgboost import XGBRegressor\nfrom sklearn.preprocessing import LabelEncoder,OneHotEncoder\n# load data\n#from sklearn.model_selection import GridSearchCV\nfrom sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Read both test and train datasets","metadata":{}},{"cell_type":"code","source":"train_ori = pd.read_csv('../input/tabular-playground-series-mar-2021/train.csv')\ntest_ori = pd.read_csv('../input/tabular-playground-series-mar-2021/test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Explore train dataset\n### Shape:","metadata":{}},{"cell_type":"code","source":"print(\"Shape of data frame:\" , train_ori.shape)\ntrain_ori.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check for NA values :","metadata":{}},{"cell_type":"code","source":"train_ori.info()","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Data set is clean as far as NA are concerned. ","metadata":{}},{"cell_type":"markdown","source":"### Use .desscribe() method to look at different features","metadata":{}},{"cell_type":"markdown","source":"## Preprocessing :\n\n1. dropping those categorical features that have more than 5 categories.\n","metadata":{}},{"cell_type":"code","source":"sumry_obj = train_ori.describe(include='object')\nprint(sumry_obj)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_features = [\n    \"cont0\", \"cont1\",\"cont2\", \"cont3\",\"cont4\", \"cont5\", \"cont6\", \"cont7\",\n    \"cont8\", \"cont9\", \"cont10\"\n]\nobj_features = [\n    \"cat0\", \"cat1\",\"cat2\",\"cat3\",\"cat4\",\"cat6\",\"cat9\",\"cat11\", \"cat12\", \"cat13\", \"cat14\", \"cat15\",\n    \"cat16\", \"cat17\", \"cat18\"\n]\ntarget = train_ori[\"target\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check for each categorical feature :\nall unique categories in test and train dataset are identical  : It is found that they are.","metadata":{}},{"cell_type":"markdown","source":"good_cat_col = []\nfor colname in obj_features:\n    diff_test_train = list(set(train_ori[colname].unique())& set(test_ori[colname].unique())).sort()\n    if (diff_test_train == test_ori[colname].unique().sort()):\n        good_cat_col.append(colname)  \n        \nlen(good_cat_col)","metadata":{"trusted":true}},{"cell_type":"markdown","source":"### 2. Use label encoder for encoding all categorical variables","metadata":{}},{"cell_type":"code","source":"#data_all = pd.concat([train_ori, test_ori])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import preprocessing\ndef lab_encoder (df, obj_features):\n    le = preprocessing.LabelEncoder()\n    obj_features_le =pd.DataFrame() \n    for colname in obj_features:\n        obj_features_le[colname]=le.fit_transform(df[colname])\n\n    return(obj_features_le)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"le_obj_col_train = lab_encoder(train_ori, obj_features)\n\nle_obj_col_test = lab_encoder(test_ori, obj_features)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ohencoder (df):\n    ohtrain = None\n\n    for i in range (1,df.shape[1] ):\n        col = df.iloc[:,i].values.reshape(df.shape[0],1)\n        onehot_encoder = OneHotEncoder(sparse=False, categories='auto')\n        feature = onehot_encoder.fit_transform(col)\n        if ohtrain is None:\n            ohtrain= feature\n        else:\n            ohtrain = np.concatenate((ohtrain, feature), axis=1)\n\n    return(ohtrain)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"allobj_features = pd.concat([le_obj_col_train, le_obj_col_test])\nallobj_features.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"allobj = ohencoder(allobj_features)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oh_obj_train = allobj[:300000]\noh_obj_test = allobj[300000:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_obj_oh = pd.DataFrame(oh_obj_train, index=train_ori.index)\ntest_obj_oh = pd.DataFrame(oh_obj_test, index=test_ori.index)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3. Remove outliers from numerical data","metadata":{}},{"cell_type":"markdown","source":"def remove_outliers(df, num_features):\n    outliers_removed = []\n    for colname in num_features:\n        q25, q75 = np.percentile(df[colname], 25), np.percentile(df[colname], 75)\n        iqr = q75 - q25\n        cutoff = iqr*1.5\n        lower,upper = q25-cutoff, q75+cutoff\n        outliers = [x for x in train_ori['cont0'] if x > lower and x < upper]\n        outliers_index = train_ori[train_ori['cont0'].isin(outliers)].index\n        df= df.drop([outliers_index],inplace=True)\n        outliers_removed.append(len(outliers))\n        print('Outliers removed for column '+ str(colname) + 'is'+ str(outliers_removed))\n    return(df,outliers_removed)\n","metadata":{"trusted":true}},{"cell_type":"markdown","source":"outliers_removed = []\nq25, q75 = np.percentile(train_ori['cont0'], 25), np.percentile(train_ori['cont0'], 75)\niqr = q75 - q25\ncutoff = iqr*1\nlower,upper = q25-cutoff, q75+cutoff\noutliers = [x for x in train_ori['cont0'] if x > lower and x < upper]\noutliers_index = train_ori[train_ori['cont0'].isin(outliers)].index\n#update_df= update_df.drop([outliers_index],inplace=True)\noutliers_removed.append(len(outliers))\nprint('Outliers removed for column '+ str(colname) + 'is'+ str(outliers_removed))\n#outliers_removed_index = [x for x in train_ori['cont0'] if x > lower and x < upper]","metadata":{"trusted":true}},{"cell_type":"code","source":"def std_scaler(df,num_features):\n    std_scaler = preprocessing.StandardScaler()\n    std_num_col = std_scaler.fit_transform(df[num_features].values)\n    scaled_num_feat_df = pd.DataFrame(std_num_col, index=df.index, columns=df[num_features].columns)\n        \n    return(scaled_num_feat_df)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#for colname in obj_features:\n #   plt.figure() #this creates a new figure on which your plot will appear\n  #  sns.histplot(data= train_ori, x= colname)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#std_num_col_train = std_scaler(train_ori,num_features)\nstd_num_col_train = train_ori [num_features]\ntrain_scaled_encoded = pd.concat ([std_num_col_train,train_obj_oh], axis=1)\ntrain_scaled_encoded.head()\ntrain_scaled_encoded.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### encode and scale test_ori dataframe :\n","metadata":{}},{"cell_type":"code","source":"#std_num_col_test = std_scaler(test_ori,num_features)\nstd_num_col_test = test_ori [num_features]\ntest_scaled_encoded = pd.concat ([std_num_col_test,test_obj_oh], axis=1)\ntest_scaled_encoded.head()\ntest_scaled_encoded.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"unique = sumry_obj.loc['unique',:] ## Row corresponding to freq \nunique_gt10= unique[unique>10].index ### names those cloumns that have fre more tha  2800\ntop_freq = sumry_obj.loc['top',freq_gt2800] ### row taht tells which 'level' was the most freqent\ntop_freq_gt2800 = top_freq[top_freq=='None'].index # names of those columns that have 'none' as most freq\ndata_all = data_all.drop(top_freq_gt2800 ,1) ## drop those columns\nprint('Shape of the dataframe now is: ', data_all.shape)","metadata":{"trusted":true}},{"cell_type":"markdown","source":"### f_classif_num, p_classif_num = f_classif(std_num_col_train, target)\n\np_classif_num\n\n\n#electKBest(f_classif, k=5).fit(std_num_col_train, target)\n#best_features_numeric= pd.DataFrame(best_features_numeric)","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Split X into X_train and X_valid, same for y","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_valid, y_train, y_valid = train_test_split(train_scaled_encoded, target, test_size=0.3, random_state=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed = 42","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Random Forest classifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import mean_absolute_error, roc_auc_score,accuracy_score\n\nclf = RandomForestClassifier(n_estimators=700, max_depth=7, n_jobs=-1, random_state=seed)\nclf.fit(X_train, y_train)\ny_pred = clf.predict_proba(X_valid)[:, 1] # This grabs the positive class prediction\nscore = roc_auc_score(y_valid, y_pred)\nprint(f'{score:0.5f}') # 0.87323 shows we're doing better than a dummy model\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## LOgistics regression\nfrom sklearn.linear_model import LogisticRegression\n\nclf_log = LogisticRegression(penalty ='l1',solver='liblinear',max_iter=500,random_state=seed)\nclf_log.fit(X_train, y_train)\ny_pred = clf_log.predict_proba(X_valid)[:, 1] \nclf_log_score= clf_log.score(X_train, y_train)\nscore = roc_auc_score(y_valid, y_pred)\nprint(f'{score:0.5f}') \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nprint(cross_val_score(clf_log, X_train, y_train, cv=10))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nneigh = KNeighborsClassifier(n_neighbors=5)\nneigh.fit(X_train, y_train)\ny_pred = neigh.predict_proba(X_valid)[:, 1] \nscore = roc_auc_score(y_valid, y_pred)\nprint(f'{score:0.5f}') ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\nclf_xgb = XGBClassifier()\neval_set = [(X_valid, y_valid)]\nclf_xgb.fit(X_train, y_train, early_stopping_rounds=10, eval_set = eval_set, eval_metric=\"logloss\", verbose=True)\ny_pred = clf_xgb.predict(X_valid) \nscore = roc_auc_score(y_valid, y_pred)\nprint(f'{score:0.5f}') \nprint(clf_xgb)\n\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf_xgb.objective\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nprint(cross_val_score(clf_log, X_train, y_train, cv=10))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nprint(cross_val_score(clf_xgb, X_train, y_train, cv=10))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nprint(cross_val_score(neigh, X_train, y_train, cv=10))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"GradientBoostingClassifier(criterion=’friedman_mse’, init=None,\n learning_rate=0.1, loss=’deviance’, max_depth=3,\n max_features=None, max_leaf_nodes=None,\n min_impurity_split=1e-07, min_samples_leaf=1,\n min_samples_split=2, min_weight_fraction_leaf=0.0,\n n_estimators=100, presort=’auto’, random_state=None,\n subsample=1.0, verbose=0, warm_start=False)","metadata":{}},{"cell_type":"markdown","source":"To DO :\n1. Split train into X_train and X_valid\n**data visulization**\ncorrelation, MI score\nfeature selection\n\nmodels :KNN, XGB DECISON TREE\n3. K cluster \n4. xg BOOST , check rmse score\n","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# best model predictions \n\nbest_model = clf_xgb\n\nbest_model.fit(train_scaled_encoded,target)\n\npreds = best_model.predict(test_scaled_encoded)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#score_dataset(label_X_train,y_train)\nsub = pd.read_csv('../input/tabular-playground-series-mar-2021/sample_submission.csv')\nsub['target']= preds\nsub.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf.fit(train_scaled_encoded, target)\nsubmission['target'] = clf.predict_proba(test)[:, 1]\nsubmission.to_csv('random_forest.csv')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#score_dataset(label_X_valid,y_valid)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"def hyperParameterTuning(X_train, y_train):\n    param_tuning = {\n        'learning_rate': [0.01, 0.1],\n        'max_depth': [3, 5, 7, 10],\n        #'min_child_weight': [1, 3, 5],\n        #'subsample': [0.5, 0.7],\n        #'colsample_bytree': [0.5, 0.7],\n        'n_estimators' : [100, 200, 500],\n        'objective': ['reg:squarederror']\n    }\n\n    xgb_model = XGBRegressor()\n\n    gsearch = GridSearchCV(estimator = xgb_model,\n                           param_grid = param_tuning,                        \n                           #scoring = 'neg_mean_absolute_error', #MAE\n                           scoring = 'neg_mean_squared_error',  #MSE\n                           cv = 5,\n                           n_jobs = -1,\n                           verbose = 1)\n\n    gsearch.fit(X_train,y_train)\n\n    return gsearch.best_params_\n","metadata":{"trusted":true}},{"cell_type":"markdown","source":"best_parameters = hyperParameterTuning(label_X_train, y_train)","metadata":{"trusted":true}}]}