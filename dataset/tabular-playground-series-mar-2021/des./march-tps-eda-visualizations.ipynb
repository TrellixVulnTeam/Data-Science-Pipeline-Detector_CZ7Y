{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Tabular Playground Series: March 2021\n\n![](https://storage.googleapis.com/kaggle-competitions/kaggle/25225/logos/header.png?t=2021-01-27-17-34-26)"},{"metadata":{},"cell_type":"markdown","source":"## Introduction:\n\nStarting from January this year, the kaggle competition team is offering a month-long tabulary playground competitions. This series aims to bridge between inclass competition and featured competitions with a friendly and approachable datasets.\n\nFor the month of March, kaggle is offering a dataset which is synthetic but based on a real dataset and generated using a CTGAN. The original dataset, this synthetic dataset is derived from, deals with predicting the amount of an insurance claim. Although the features are anonymized, they have properties relating to real-world features.\n\nThe data has: \n\n* 19 categorical variables: **cat0** to **cat18**\n* 11 continuous variables: **cont0** to **cont10**\n* 1 binary **target** column\n\nFiles provides:\n\n- train.csv - the training data with the target column\n- test.csv - the test set; you will be predicting the target for each row in this file\n- sample_submission.csv - a sample submission file in the correct format\n\nThe goal of the competition is to predict a binary **target** based on the given categorical and continuous features. However, the goal of **this notebook** is to explore (EDA) and visualize the given data. And when possible try to discover (engineer) *potentially usefull* features for further data modelling and prediction.\n\n\n[1. Set-up](#Set-up)"},{"metadata":{},"cell_type":"markdown","source":"# Set-up"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import kurtosis, skew\nfrom matplotlib.offsetbox import AnchoredText\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"# Load the data"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"train_ = pd.read_csv(r'/kaggle/input/tabular-playground-series-mar-2021/train.csv', index_col='id')\ntest = pd.read_csv(r'/kaggle/input/tabular-playground-series-mar-2021/test.csv', index_col='id')\n\nsubmission= pd.read_csv(r'/kaggle/input/tabular-playground-series-mar-2021/sample_submission.csv', index_col='id')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Explore the data"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"train = train_.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print('Train data of shape {}'.format(train.shape))\ndisplay(train.head())\nprint('Test data of shape {}'.format(test.shape))\ndisplay(test.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"display(train.describe().T)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"target = train.pop('target')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"cat_features =[]\nnum_features =[]\n\nfor col in train.columns:\n    if train[col].dtype=='object':\n        cat_features.append(col)\n    else:\n        num_features.append(col)\nprint('Catagoric features: ', cat_features)\nprint('Numerical features: ', num_features)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Null-values in the data\n(No null values in the data.)"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print('Number of NA values in train data is {}'.format(train.isna().sum().sum()))\nprint('Number of NA values in test data is {}'.format(test.isna().sum().sum()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Categorical features (group by cardinality)\n\n- There are four features with high cardinality (>20, one very high with 299)\n- The rest is less that or equal to 20\n<div class=\"alert alert-block alert-danger\">  \nWatch for cat10 !!!\n</div>\n\n- In **cat10** there are 299 unique values in train data whereas the test data has 295\n- Some elements of cat10 are present in test data but **NOT** in train data and the vice-versa (details below)"},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"for col in cat_features:\n    print('{} unique values in {}'.format(train[col].nunique(), col))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"for col in cat_features:\n    print('{} unique values in {}'.format(test[col].nunique(), col))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"train_cat10 = list(pd.DataFrame(train_['cat10'].value_counts()).index)\ntest_cat10 = list(pd.DataFrame(test['cat10'].value_counts()).index)\nprint('Elements of cat10 which are present in train_data but NOT in test_data.')\nprint('-----------------------------------------------------------------------')\nfor item in train_cat10:\n    if item not in test_cat10:\n        print(item)\nprint('')\nprint('Elements of cat10 which are present in test_data but NOT in train_data.')\nprint('-----------------------------------------------------------------------')\nfor item in test_cat10:\n    if item not in train_cat10:\n        print(item)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# group columns according to cardinality/only for plotting\nlow_cardinal_cols = []\nhigh_cardinal_cols = []\n\nfor col in cat_features:\n    if train[col].nunique() <= 20:\n        low_cardinal_cols.append(col)\n    else:\n        high_cardinal_cols.append(col)\n\n# display the values\nprint(\"low_cardinal_cols\")\nprint(low_cardinal_cols)\nprint(\"high_cardinal_cols\")\nprint(high_cardinal_cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Visualization\n## Low cardinality features"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def count_plot_testTrain(data1, data2, features, titleText):\n    L = len(features)\n    nrow= int(np.ceil(L/2))\n    ncol= 2\n\n    remove_last= (nrow * ncol) - L\n\n    fig, ax = plt.subplots(nrow, ncol,figsize=(18, 26))#, facecolor='#D6E8D8')\n    ax.flat[-remove_last].set_visible(False)\n    fig.subplots_adjust(top=0.95)\n    i = 1\n    for feature in features:\n        plt.subplot(nrow, ncol, i)\n        ax = sns.countplot(x=feature, color='#1eb069', data=data1, label='train')\n        ax = sns.countplot(x=feature, color='#056d87', data=data2, label='test')\n        plt.legend()\n        i += 1\n    plt.suptitle(titleText ,fontsize = 20)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_plot_testTrain(train, test, low_cardinal_cols, titleText='Train & test data categorical features (low cardinality)')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def count_plot(data, features, titleText, hue=None):\n    L = len(features)\n    nrow= int(np.ceil(L/2))\n    ncol= 2\n\n    remove_last= (nrow * ncol) - L\n\n    fig, ax = plt.subplots(nrow, ncol,figsize=(18, 26))\n    ax.flat[-remove_last].set_visible(False)\n    fig.subplots_adjust(top=0.95)\n    i = 1\n    for feature in features:\n        total = float(len(data)) \n        plt.subplot(nrow, ncol, i)\n        ax = sns.countplot(x=feature, palette='viridis', data=data, hue=hue)        \n        i += 1\n    plt.suptitle(titleText ,fontsize = 20)\n    plt.show()    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"count_plot(train, low_cardinal_cols, 'Train data cat_feats (low cardinal): target dist', hue=target)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## High cardinality categorical features\n- As described above there are FOUR catagories which has more than 20 elements (cat5, 7, 8 and 10)\n- For plotting convenience, these catagories are condensed to 20 elements (19 most frequent elements + the rest merged to 'etc' catagory). Here 20 is an arbitrary number but equal to the highest cardinality in the 'low cardinality' categories. "},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# got a hint from notebook (https://www.kaggle.com/dwin183287/tps-mar-2021-eda/) for this code snippet\nfor cat in high_cardinal_cols:\n    new_cat_train = f'train_{cat}' \n    new_cat_train= list(pd.DataFrame(train_[cat].value_counts()/len(train_[cat]))[:19].index)\n    new_cat_test = f'test{cat}' \n    new_cat_test = list(pd.DataFrame(test[cat].value_counts()/len(test[cat]))[:19].index)\n    train_[cat] = np.where(~train_[cat].isin(new_cat_train), 'etc', train_[cat])\n    test[cat] = np.where(~test[cat].isin(new_cat_test), 'etc', test[cat])","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"L = len(high_cardinal_cols)\ni =1\nnrow= int(np.ceil(L/2))\nncol= 2\n\nremove_last= (nrow * ncol) - L\n\nfig, ax = plt.subplots(nrow, ncol,figsize=(18, 8))\nax.flat[-remove_last].set_visible(False)\nfig.subplots_adjust(top=0.95)\n\nfor cat in train_[high_cardinal_cols]:\n    plt.subplot(nrow, ncol, i)\n    ax = sns.countplot(x=cat, color='#1eb069', data=train_, label='train') \n    ax = sns.countplot(x=cat, color='#056d87', data=test, label='test')\n    plt.suptitle('Train & test data categorical features (high cardinality)' ,fontsize = 20, y=1.002)\n    plt.legend()\n    i+=1\nplt.show() \n\nL = len(high_cardinal_cols)\ni =1\nnrow= int(np.ceil(L/2))\nncol= 2\n\nremove_last= (nrow * ncol) - L\n\nfig, ax = plt.subplots(nrow, ncol,figsize=(18, 8))\nax.flat[-remove_last].set_visible(False)\nfig.subplots_adjust(top=0.95)\nfor cat in train_[high_cardinal_cols]:\n    plt.subplot(nrow, ncol, i)\n    ax = sns.countplot(x=cat, palette='viridis', data=train_, hue=target) \n    plt.suptitle('High cardinality categorical features: target dist' ,fontsize = 20, y=1.002)\n    plt.legend()\n    i+=1\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Numerical features\n- Kde plots are made to compare train and test data\n- No major differences in distribution \n- Density is consistent with the embalance of the target variable\n"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"L = len(num_features)\nnrow= int(np.ceil(L/4))\nncol= 4\n\nremove_last= (nrow * ncol) - L\n\nfig, ax = plt.subplots(nrow, ncol,figsize=(18, 12))\nax.flat[-remove_last].set_visible(False)\nfig.subplots_adjust(top=0.95)\ni = 1\nfor feature in num_features:\n    plt.subplot(nrow, ncol, i)\n    ax = sns.kdeplot(train_[feature], shade=True, color='#1eb069',  alpha=0.5, label='train')\n    ax = sns.kdeplot(test[feature], shade=True, color='#056d87',  alpha=0.5, label='test')\n    plt.xlabel(feature, fontsize=9)\n    plt.legend()\n    i += 1\nplt.suptitle('DistPlot: numerical features of train & test data', fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"L = len(num_features)\nnrow= int(np.ceil(L/4))\nncol= 4\n\nremove_last= (nrow * ncol) - L\n\nfig, ax = plt.subplots(nrow, ncol,figsize=(18, 12))\nax.flat[-remove_last].set_visible(False)\nfig.subplots_adjust(top=0.95)\ni = 1\nfor feature in num_features:\n    plt.subplot(nrow, ncol, i)\n    ax = sns.kdeplot(train_[feature], shade=True, palette='viridis',  alpha=0.5, hue= target, multiple=\"stack\")\n    plt.xlabel(feature, fontsize=9)\n    plt.legend(['1', '0'])\n    i += 1\nplt.suptitle('DistPlot: numerical features of train data', fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The same story, different look (looks cool, for me) of the above kde plots\n(Normalized distribution at each value)"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"L = len(num_features)\nnrow= int(np.ceil(L/4))\nncol= 4\n\nremove_last= (nrow * ncol) - L\n\nfig, ax = plt.subplots(nrow, ncol,figsize=(18, 12))\nax.flat[-remove_last].set_visible(False)\nfig.subplots_adjust(top=0.92)\ni = 1\nfor feature in num_features:\n    plt.subplot(nrow, ncol, i)\n    ax = sns.kdeplot(train_[feature], shade=True, palette='coolwarm',  alpha=0.75, hue= target, multiple=\"fill\")\n    plt.xlabel(feature, fontsize=9)\n    plt.legend(['1', '0'])\n    i += 1\nplt.suptitle('DistPlot: numerical features of train data', fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Target Variable\n(Target variable is imbalanced: more 0's than 1's)"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(8, 6))\nax = sns.countplot(x=target, palette='viridis')\nax.set_title('Target variable distribution', fontsize=20, y=1.05)\n\nsns.despine(right=True)\nsns.despine(offset=10, trim=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Feature-target correlation \n- More numerical features than categoricals seem to correlate with target\n- cat16 has highest correlation with target\n- cont0 is the least correlated with target \n"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"correlation_table = []\nfor cols in num_features:\n    y = target\n    x = train[cols]\n    corr = np.corrcoef(x, y)[1][0]\n    dict ={\n        'Features': cols,\n        'Correlation coefficient' : corr,\n        'Feat_type': 'numerical'\n    }\n    correlation_table.append(dict)\ndF1 = pd.DataFrame(correlation_table)\nfig = plt.figure(figsize=(10,6), facecolor='#EAECEE')\nax = sns.barplot(x=\"Correlation coefficient\", y=\"Features\", \n                     data=dF1.sort_values(\"Correlation coefficient\", ascending=False),\n                     palette='viridis', alpha=0.75)\nax.grid()\n#ax.set_title(\"Correlation of numerical features with Target\", fontsize=20, y=1.05)\n\ntitle =  'Correlation of numerical features with target'\nsub_title = 'In comparison with categorical features \\\n\\nnumericals are less correlated with target.'\n\nplt.gcf().text(0.05, 1.02, title, fontsize=24)\n#plt.gcf().text(0.05, 0.9, sub_title, fontsize=14)\n\nat1 = AnchoredText(sub_title,\n                   loc='lower left', frameon=True,\n                   bbox_to_anchor=(-0.1, 1.01),\n                   bbox_transform=ax.transAxes,\n                   #prop=dict(size=8),\n                   )\nat1.patch.set_boxstyle(\"round,pad=0.,rounding_size=0.2\")\nax.add_artist(at1);\n","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"correlation_table= []\nfor cols in cat_features:\n    y = train_['target']\n    X = train[cols]\n    corr = pd.concat((X, y), axis=1).apply(lambda x : pd.factorize(x)[0]).corr()\n    dict ={\n        'Features': cols,\n        'Correlation coefficient' : corr['target'][:].values[0],\n        'Feat_type': 'categorical'\n    }\n    correlation_table.append(dict)\ndF2 = pd.DataFrame(correlation_table)\nfig = plt.figure(figsize=(12,8), facecolor='#EAECEE')\nax = sns.barplot(x=\"Correlation coefficient\", y=\"Features\", \n                     data=dF2.sort_values(\"Correlation coefficient\", ascending=False),\n                     palette='viridis', alpha=0.75)\nax.grid()\n#ax.set_title(\"Correlation of categorical features with target\", fontsize=20, y=1.05)\n\ntitle =  'Correlation of categorical features with target'\nsub_title = 'Categorical features are better\\ncorrelated with target \\\nthan\\nnumerical features.\\n\\ncat16 and cat18 stand-out'\n\nplt.gcf().text(0.05, 1.04, title, fontsize=24)\n#plt.gcf().text(0.05, 0.9, sub_title, fontsize=14)\n\nat1 = AnchoredText(sub_title,\n                   loc='lower left', frameon=True,\n                   bbox_to_anchor=(-0.1, 1.01),\n                   bbox_transform=ax.transAxes,\n                   #prop=dict(size=8),\n                   )\nat1.patch.set_boxstyle(\"round,pad=0.,rounding_size=0.2\")\nax.add_artist(at1);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature-to-feature correlation\n- Correlation between numerical features dominates correlation between categoricals"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"sns.set_style(\"darkgrid\")\n\ncorr = train.corr()\nmask = np.triu(np.ones_like(corr, dtype=bool))\nf, ax = plt.subplots(figsize=(16, 10), facecolor='#EAECEE')\ncmap = sns.color_palette(\"vlag\", as_cmap=True)\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=1.0, vmin=-1.0, center=0, annot=True,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": 0.75})\n\n#ax.set_title('Correlation heatmap: numerical features', fontsize=24, y= 1.05)\ncolorbar = ax.collections[0].colorbar\ncolorbar.set_ticks([-0.75, 0, 0.75])\ncolorbar.set_ticklabels(['negative_corr','Little_to_no_corr','positive_corr'])\n\ntitle = 'Highly correlated ones are:\\ncont1_cont2\\ncont0_cont10'\ntitle_ =  'Correlation heatmap: numerical features (train data)'\nplt.gcf().text(0.23, 0.98, title_, fontsize=24)\n#plt.gcf().text(0.2, 0.9, title, fontsize=12)\n\n#textstr = 'Features with highest correlation\\ncon1$con2, cont0&cont10, cont'\nat1 = AnchoredText(title,\n                   loc='lower left', frameon=True,\n                   bbox_to_anchor=(-0.1, 1.01),\n                   bbox_transform=ax.transAxes,\n                   #prop=dict(size=8),\n                   )\nat1.patch.set_boxstyle(\"round,pad=0.,rounding_size=0.2\")\nax.add_artist(at1);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"corr = (train_[cat_features]).apply(lambda x : pd.factorize(x)[0]).corr()\nmask = np.triu(np.ones_like(corr, dtype=bool))\nf, ax = plt.subplots(figsize=(20, 12), facecolor=\"#EAECEE\")\ncmap = sns.color_palette(\"vlag\", as_cmap=True)\nsns.heatmap(np.round(corr, 2), mask=mask, cmap=cmap, vmax=1.0, vmin=-1.0, center=0, annot=True,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": 0.75})\n\ncolorbar = ax.collections[0].colorbar\ncolorbar.set_ticks([-0.75, 0, 0.75])\ncolorbar.set_ticklabels(['negative_corr','Little_to_no_corr','positive_corr'])\n\nsub_title = 'Not as many highly correlated as num_features.\\nMost notable is:\\ncat11_cat2'\ntitle =  'Correlation heatmap: catagorical features (train data)'\nplt.gcf().text(0.26, 0.98, title, fontsize=24)\n\nat1 = AnchoredText(sub_title,\n                   loc='lower left', frameon=True,\n                   bbox_to_anchor=(-0.098, 1.02),\n                   bbox_transform=ax.transAxes, #prop=dict(size=8),\n                   )\nat1.patch.set_boxstyle(\"round,pad=0.,rounding_size=0.4\")\nax.add_artist(at1);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## End of notebook!"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Thank you very much for reading this notebook!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}