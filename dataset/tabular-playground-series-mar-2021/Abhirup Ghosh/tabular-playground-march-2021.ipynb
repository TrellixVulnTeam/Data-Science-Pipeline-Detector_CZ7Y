{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reading Data from source"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train = pd.read_csv(\"/kaggle/input/tabular-playground-series-mar-2021/train.csv\")\ndata_test = pd.read_csv(\"/kaggle/input/tabular-playground-series-mar-2021/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The data  is complete so we donot need to perform any imputation."},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_cols = []\nobj_col= []\nfor col in data_train.columns:\n    if(data_train[col].dtype.kind != 'O'):\n        num_cols.append(col)\n    else:\n        obj_col.append(col)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Separating numeric and object columns"},{"metadata":{},"cell_type":"markdown","source":"# Data Visualisation"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nfor col in num_cols:\n    plt.figure(figsize=(100,20))\n    g = sns.histplot((data_train[col] - np.min(data_train[col])/(np.max(data_train[col]) - np.min(data_train[col]))),kde = True)\n    plt.show(g)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in obj_col:\n    plt.figure(figsize=(100,20))\n    g = sns.countplot(data_train[col])\n    plt.show(g)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,20))\ng = sns.heatmap(data_train.loc[:,num_cols].corr(),annot=True)\nplt.show(g)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train[\"target\"] = data_train[\"target\"].map(lambda x : np.float32(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_test_split(data_train,train_split= 0.8):\n    train_mask = data_train['id'].apply(lambda  x : abs(hash(str(x))) % 10000  < train_split*10000).values\n    test_mask = data_train['id'].apply(lambda  x : abs(hash(str(x))) % 10000  >= train_split*10000).values\n    return data_train.iloc[train_mask,0:-1],data_train.iloc[test_mask,0:-1],data_train.iloc[train_mask,-1],data_train.iloc[test_mask,-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train,x_test,y_train,y_test =  train_test_split(data_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dataset Methods"},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_input_function(batch_size = 128):\n    ds = tf.data.Dataset.from_tensor_slices((dict(x_train) , y_train))\n    ds = ds.shuffle(len(x_train)).batch(batch_size)\n    return ds\n\ndef eval_input_function(batch_size = 10):\n    ds = tf.data.Dataset.from_tensor_slices((dict(x_test) , y_test))\n    ds = ds.batch(batch_size)\n    return ds\n\ndef albation_input_function(batch_size = 10):\n    ds = tf.data.Dataset.from_tensor_slices((dict(x_train[0:1000]) , y_train[0:1000]))\n    ds = ds.shuffle(1000).batch(batch_size)\n    return ds\n\n# def pred_input_function(batch_size = 10):\n#     ds = tf.data.Dataset.from_tensor_slices((dict(x_test) , y_test))\n#     ds = ds.batch(batch_size)\n#     return ds","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Defining feature columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_feature_cols(data_train):\n    cols_list = []\n    for col  in data_train.columns[:-1]:\n        if(data_train[col].dtype.kind != \"O\"):\n            cols_list.append(tf.feature_column.numeric_column(col))\n        else:\n            cols_list.append(tf.feature_column.indicator_column(tf.feature_column.categorical_column_with_vocabulary_list(col,data_train[col].unique())))\n    return cols_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"example_batch = next(iter(train_input_function()))[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def demo(feature_column):\n    feature_layer = tf.keras.layers.DenseFeatures(feature_column)\n    print(feature_layer(example_batch).numpy()[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"demo(generate_feature_cols(data_train))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Defining Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"keras_model = tf.keras.Sequential([\n    tf.keras.layers.DenseFeatures(generate_feature_cols(data_train)),\n    tf.keras.layers.Dense(1024,activation = \"relu\",kernel_regularizer = \"l1_l2\"),\n    tf.keras.layers.Dense(1024,activation = \"relu\"),\n    tf.keras.layers.Dense(1024,activation = \"relu\"),\n    tf.keras.layers.Dense(1024,activation = \"relu\"),\n    tf.keras.layers.Dense(1,activation= \"softmax\")\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def loss_function(true,pred):\n    return t\n\ndef scheduler(epoch, lr):\n    if(epoch < 10):\n        return lr\n    else:\n        return lr/epoch\n    \ncallbacks = tf.keras.callbacks.LearningRateScheduler(scheduler)\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(actor=0.1, patience=3, verbose=1,mode='auto', min_delta=0.0001, cooldown=0, min_lr=0,)\nkeras_model.compile(\n    optimizer=tf.keras.optimizers.Adadelta(learning_rate=0.01),\n    loss=\"binary_crossentropy\",\n    metrics=[\"accuracy\",tf.keras.metrics.AUC()])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Albation Experiment"},{"metadata":{"trusted":true},"cell_type":"code","source":"hostory = keras_model.fit(train_input_function(100),epochs = 150,callbacks=[reduce_lr])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hostory.history.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.lineplot([x for x in range(len(hostory.history[\"loss\"]))],hostory.history[\"loss\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y2 = hostory.history[\"loss\"][0]\ny1  = hostory.history[\"loss\"][-1]\nx2 = 100\nx1=  0\n\nprint(\"Slope is {0}\".format((y2-y1)/(x2-x1)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = keras_model.predict(dict(data_test))\nids = data_test.loc[:,[\"id\"]].applymap(lambda x : int(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_out = pd.DataFrame({\"Id\": ids.values.flatten(),\"target\": pred.flatten()})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_out.to_csv(\"./submission.csv\",index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}