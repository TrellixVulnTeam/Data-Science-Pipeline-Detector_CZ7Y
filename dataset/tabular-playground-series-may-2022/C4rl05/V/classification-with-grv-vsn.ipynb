{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Classification with Gated Residual and Variable Selection Networks ðŸ¤–\n## Using Gated Residual and Variable Selection Networks for Predicting States of Manufacturing Control Data\n\n## Work in Progress...\n\n\n\n**Introduction**\n\nThis example demonstrates the use of Gated Residual Networks (GRN) and Variable Selection Networks (VSN), proposed by Bryan Lim et al. in Temporal Fusion Transformers (TFT) for Interpretable Multi-horizon Time Series Forecasting, for structured data classification. GRNs give the flexibility to the model to apply non-linear processing only where needed. VSNs allow the model to softly remove any unnecessary noisy inputs which could negatively impact performance. Together, those techniques help improving the learning capacity of deep neural network models.\n\nNote that this example implements only the GRN and VSN components described in in the paper, rather than the whole TFT model, as GRN and VSN can be useful on their own for structured data learning tasks.\n\nTo run the code you need to use TensorFlow 2.3 or higher.\n\n\n**References**\n\nhttps://keras.io/examples/structured_data/classification_with_grn_and_vsn/\n\n**Notebooks Ideas and Credits**\n\nI took ideas or inspiration from the following notebooks, if you enjoy my work, please take a look to the notebooks that inspire my work.\n\n**TPSMAY22 Gradient-Boosting Quickstart:** \n\nhttps://www.kaggle.com/code/ambrosm/tpsmay22-gradient-boosting-quickstart/notebook\n\n\n**TPSMAY22 Advanced Keras:**\n\nhttps://www.kaggle.com/code/ambrosm/tpsmay22-advanced-keras\n","metadata":{}},{"cell_type":"markdown","source":"# 1. Loading the Requiered Libraries","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-25T02:09:49.553701Z","iopub.execute_input":"2022-05-25T02:09:49.554146Z","iopub.status.idle":"2022-05-25T02:09:49.585633Z","shell.execute_reply.started":"2022-05-25T02:09:49.554027Z","shell.execute_reply":"2022-05-25T02:09:49.584606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras import callbacks\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, LearningRateScheduler, EarlyStopping\n\nimport tensorflow as tf\nimport random\nimport os\n\nfrom sklearn.metrics import roc_auc_score, log_loss\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler, RobustScaler, PowerTransformer, MinMaxScaler\n\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nimport time\nfrom sklearn import model_selection\n\nfrom collections import defaultdict\nimport tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2022-05-25T02:09:49.587651Z","iopub.execute_input":"2022-05-25T02:09:49.588023Z","iopub.status.idle":"2022-05-25T02:09:55.857963Z","shell.execute_reply.started":"2022-05-25T02:09:49.587982Z","shell.execute_reply":"2022-05-25T02:09:55.857038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# 2. Setting the Notebook","metadata":{}},{"cell_type":"code","source":"%%time\n# I like to disable my Notebook Warnings.\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-05-25T02:09:55.859386Z","iopub.execute_input":"2022-05-25T02:09:55.860309Z","iopub.status.idle":"2022-05-25T02:09:55.871572Z","shell.execute_reply.started":"2022-05-25T02:09:55.860259Z","shell.execute_reply":"2022-05-25T02:09:55.870605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Notebook Configuration...\n\n# Amount of data we want to load into the Model...\nDATA_ROWS = None\n# Dataframe, the amount of rows and cols to visualize...\nNROWS = 15\nNCOLS = 10\n# Main data location path...\nBASE_PATH = '...'","metadata":{"execution":{"iopub.status.busy":"2022-05-25T02:09:55.874587Z","iopub.execute_input":"2022-05-25T02:09:55.875241Z","iopub.status.idle":"2022-05-25T02:09:55.889974Z","shell.execute_reply.started":"2022-05-25T02:09:55.875192Z","shell.execute_reply":"2022-05-25T02:09:55.888898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Configure notebook display settings to only use 2 decimal places, tables look nicer.\npd.options.display.float_format = '{:,.5f}'.format\npd.set_option('display.max_columns', NCOLS) \npd.set_option('display.max_rows', NROWS)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T02:09:55.891891Z","iopub.execute_input":"2022-05-25T02:09:55.892695Z","iopub.status.idle":"2022-05-25T02:09:55.903522Z","shell.execute_reply.started":"2022-05-25T02:09:55.892633Z","shell.execute_reply":"2022-05-25T02:09:55.90211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# 3. Loading the Information (CSV) Into A Dataframe","metadata":{}},{"cell_type":"code","source":"%%time\n# Load the CSV information into a Pandas DataFrame...\ntrn_data = pd.read_csv('/kaggle/input/tabular-playground-series-may-2022/train.csv')\ntst_data = pd.read_csv('/kaggle/input/tabular-playground-series-may-2022/test.csv')\n\nsub = pd.read_csv('/kaggle/input/tabular-playground-series-may-2022/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-05-25T02:09:55.905518Z","iopub.execute_input":"2022-05-25T02:09:55.90589Z","iopub.status.idle":"2022-05-25T02:10:10.362957Z","shell.execute_reply.started":"2022-05-25T02:09:55.905825Z","shell.execute_reply":"2022-05-25T02:10:10.362069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# 4. Exploring the Information Available","metadata":{}},{"cell_type":"code","source":"%%time\n# Explore the shape of the DataFrame...\ntrn_data.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-25T02:10:10.364373Z","iopub.execute_input":"2022-05-25T02:10:10.365144Z","iopub.status.idle":"2022-05-25T02:10:10.378122Z","shell.execute_reply.started":"2022-05-25T02:10:10.365082Z","shell.execute_reply":"2022-05-25T02:10:10.376819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Display simple information of the variables in the dataset...\ntrn_data.info()","metadata":{"execution":{"iopub.status.busy":"2022-05-25T02:10:10.379967Z","iopub.execute_input":"2022-05-25T02:10:10.380681Z","iopub.status.idle":"2022-05-25T02:10:10.556458Z","shell.execute_reply.started":"2022-05-25T02:10:10.380634Z","shell.execute_reply":"2022-05-25T02:10:10.55554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Display the first few rows of the DataFrame...\ntrn_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-25T02:10:10.559896Z","iopub.execute_input":"2022-05-25T02:10:10.560784Z","iopub.status.idle":"2022-05-25T02:10:10.586693Z","shell.execute_reply.started":"2022-05-25T02:10:10.560733Z","shell.execute_reply":"2022-05-25T02:10:10.585812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Generate a simple statistical summary of the DataFrame, Only Numerical...\ntrn_data.describe()","metadata":{"execution":{"iopub.status.busy":"2022-05-25T02:10:10.588373Z","iopub.execute_input":"2022-05-25T02:10:10.588915Z","iopub.status.idle":"2022-05-25T02:10:11.751269Z","shell.execute_reply.started":"2022-05-25T02:10:10.588864Z","shell.execute_reply":"2022-05-25T02:10:11.750355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Calculates the total number of missing values...\ntrn_data.isnull().sum().sum()","metadata":{"execution":{"iopub.status.busy":"2022-05-25T02:10:11.753118Z","iopub.execute_input":"2022-05-25T02:10:11.753778Z","iopub.status.idle":"2022-05-25T02:10:11.903464Z","shell.execute_reply.started":"2022-05-25T02:10:11.753727Z","shell.execute_reply":"2022-05-25T02:10:11.902648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Display the number of missing values by variable...\ntrn_data.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-05-25T02:10:11.904936Z","iopub.execute_input":"2022-05-25T02:10:11.905725Z","iopub.status.idle":"2022-05-25T02:10:12.057002Z","shell.execute_reply.started":"2022-05-25T02:10:11.905692Z","shell.execute_reply":"2022-05-25T02:10:12.056087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Display the number of unique values for each variable...\ntrn_data.nunique()","metadata":{"execution":{"iopub.status.busy":"2022-05-25T02:10:12.058494Z","iopub.execute_input":"2022-05-25T02:10:12.058869Z","iopub.status.idle":"2022-05-25T02:10:13.54116Z","shell.execute_reply.started":"2022-05-25T02:10:12.058814Z","shell.execute_reply":"2022-05-25T02:10:13.540168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display the number of unique values for each variable, sorted by quantity...\ntrn_data.nunique().sort_values(ascending = True)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T02:10:13.543098Z","iopub.execute_input":"2022-05-25T02:10:13.543806Z","iopub.status.idle":"2022-05-25T02:10:15.101469Z","shell.execute_reply.started":"2022-05-25T02:10:13.543753Z","shell.execute_reply":"2022-05-25T02:10:15.100728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Check some of the categorical variables\ncateg_cols = ['f_29','f_30','f_13', 'f_18','f_17','f_14','f_11','f_10','f_09','f_15','f_07','f_12','f_16','f_08','f_27']\ntrn_data[categ_cols].sample(5)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T02:10:15.102923Z","iopub.execute_input":"2022-05-25T02:10:15.103197Z","iopub.status.idle":"2022-05-25T02:10:15.190752Z","shell.execute_reply.started":"2022-05-25T02:10:15.103149Z","shell.execute_reply":"2022-05-25T02:10:15.189817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Generate a quick correlation matrix to understand the dataset better\ncorrelation = trn_data.corr()","metadata":{"execution":{"iopub.status.busy":"2022-05-25T02:10:15.192445Z","iopub.execute_input":"2022-05-25T02:10:15.192749Z","iopub.status.idle":"2022-05-25T02:10:17.798347Z","shell.execute_reply.started":"2022-05-25T02:10:15.192706Z","shell.execute_reply":"2022-05-25T02:10:17.797317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Diplay the correlation matrix\ncorrelation","metadata":{"execution":{"iopub.status.busy":"2022-05-25T02:10:17.799603Z","iopub.execute_input":"2022-05-25T02:10:17.80036Z","iopub.status.idle":"2022-05-25T02:10:17.82725Z","shell.execute_reply.started":"2022-05-25T02:10:17.800314Z","shell.execute_reply":"2022-05-25T02:10:17.826357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Check the most correlated variables to the target\ncorrelation['target'].sort_values(ascending = False)[:5]","metadata":{"execution":{"iopub.status.busy":"2022-05-25T02:10:17.830724Z","iopub.execute_input":"2022-05-25T02:10:17.831021Z","iopub.status.idle":"2022-05-25T02:10:17.84791Z","shell.execute_reply.started":"2022-05-25T02:10:17.830987Z","shell.execute_reply":"2022-05-25T02:10:17.846909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Check the least correlated variables to the target\ncorrelation['target'].sort_values(ascending = True)[:5]","metadata":{"execution":{"iopub.status.busy":"2022-05-25T02:10:17.849587Z","iopub.execute_input":"2022-05-25T02:10:17.851412Z","iopub.status.idle":"2022-05-25T02:10:17.864132Z","shell.execute_reply.started":"2022-05-25T02:10:17.851361Z","shell.execute_reply":"2022-05-25T02:10:17.862976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Check how well balanced is the dataset\ntrn_data['target'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-05-25T02:10:17.866164Z","iopub.execute_input":"2022-05-25T02:10:17.866718Z","iopub.status.idle":"2022-05-25T02:10:17.884713Z","shell.execute_reply.started":"2022-05-25T02:10:17.866667Z","shell.execute_reply":"2022-05-25T02:10:17.883502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Check some statistics on the target variable\ntrn_data['target'].describe()","metadata":{"execution":{"iopub.status.busy":"2022-05-25T02:10:17.886481Z","iopub.execute_input":"2022-05-25T02:10:17.887444Z","iopub.status.idle":"2022-05-25T02:10:17.923567Z","shell.execute_reply.started":"2022-05-25T02:10:17.8874Z","shell.execute_reply":"2022-05-25T02:10:17.92266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# 5. Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"## 5.1 - Character Features.","metadata":{}},{"cell_type":"code","source":"%%time\ndef count_chars(df, field):\n    '''\n    Describe something...\n    '''\n    \n    for i in range(10):\n        df[f'ch_{i}'] = df[field].str.get(i).apply(ord) - ord('A')\n        \n    df[\"unique_characters\"] = df[field].apply(lambda s: len(set(s)))\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-05-25T02:10:17.925486Z","iopub.execute_input":"2022-05-25T02:10:17.926119Z","iopub.status.idle":"2022-05-25T02:10:17.93565Z","shell.execute_reply.started":"2022-05-25T02:10:17.926058Z","shell.execute_reply":"2022-05-25T02:10:17.934291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Utilizes the new created funtions to generate more features.\ntrn_data = count_chars(trn_data, 'f_27')\ntst_data = count_chars(tst_data, 'f_27')","metadata":{"execution":{"iopub.status.busy":"2022-05-25T02:10:17.937531Z","iopub.execute_input":"2022-05-25T02:10:17.93824Z","iopub.status.idle":"2022-05-25T02:10:38.655927Z","shell.execute_reply.started":"2022-05-25T02:10:17.938181Z","shell.execute_reply":"2022-05-25T02:10:38.655081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.2 - Interaction Features","metadata":{}},{"cell_type":"code","source":"%%time\ndef calculate_feat_int(df):\n    df['i_02_21'] = (df.f_21 + df.f_02 > 5.2).astype(int) - (df.f_21 + df.f_02 < -5.3).astype(int)\n    df['i_05_22'] = (df.f_22 + df.f_05 > 5.1).astype(int) - (df.f_22 + df.f_05 < -5.4).astype(int)\n    i_00_01_26 = df.f_00 + df.f_01 + df.f_26\n    df['i_00_01_26'] = (i_00_01_26 > 5.0).astype(int) - (i_00_01_26 < -5.0).astype(int)\n    return df\n\ntrn_data = calculate_feat_int(trn_data)\ntst_data = calculate_feat_int(tst_data)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T02:10:38.660325Z","iopub.execute_input":"2022-05-25T02:10:38.661107Z","iopub.status.idle":"2022-05-25T02:10:38.734193Z","shell.execute_reply.started":"2022-05-25T02:10:38.661058Z","shell.execute_reply":"2022-05-25T02:10:38.733326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ncontinuous_feat = ['f_00', 'f_01', 'f_02', 'f_03', 'f_04', 'f_05', 'f_06', 'f_19', 'f_20', 'f_21', 'f_22', 'f_23', 'f_24', 'f_25', 'f_26', 'f_28']\n\ndef stat_features(df, cols = continuous_feat):\n    '''\n    Calculate aggregated features across the selected continuous columns\n    \n    '''\n    # Base statistical features.\n    df['f_sum']  = df[continuous_feat].sum(axis=1)\n    df['f_min']  = df[continuous_feat].min(axis=1)\n    df['f_max']  = df[continuous_feat].max(axis=1)\n    df['f_std']  = df[continuous_feat].std(axis=1)    \n    df['f_mad']  = df[continuous_feat].mad(axis=1)\n    df['f_mean'] = df[continuous_feat].mean(axis=1)\n    df['f_kurt'] = df[continuous_feat].kurt(axis=1)\n\n    # Extra statistical features.\n    df['f_prod'] = df[continuous_feat].prod(axis=1)\n    df['f_range'] = df[continuous_feat].max(axis=1) - df[continuous_feat].min(axis=1)\n    df['f_count_pos']  = df[df[continuous_feat].gt(0)].count(axis=1)\n    df['f_count_neg']  = df[df[continuous_feat].lt(0)].count(axis=1)\n\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-05-25T02:10:38.735491Z","iopub.execute_input":"2022-05-25T02:10:38.736291Z","iopub.status.idle":"2022-05-25T02:10:38.744824Z","shell.execute_reply.started":"2022-05-25T02:10:38.736246Z","shell.execute_reply":"2022-05-25T02:10:38.744004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n#trn_data = stat_features(trn_data, continuous_feat)\n#tst_data = stat_features(tst_data, continuous_feat)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T02:10:38.74644Z","iopub.execute_input":"2022-05-25T02:10:38.746961Z","iopub.status.idle":"2022-05-25T02:10:38.758783Z","shell.execute_reply.started":"2022-05-25T02:10:38.746917Z","shell.execute_reply":"2022-05-25T02:10:38.757596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# 6. Feature Selection for Baseline Model","metadata":{}},{"cell_type":"code","source":"%%time\n# Define what will be used in the training stage\nignore = ['id', \n          'f_27', \n          'f_27_enc', \n          'is_train', \n          'target'] # f_27 has been label encoded...\n\nFEATURES = [feat for feat in trn_data.columns if feat not in ignore]\nTARGET = 'target'","metadata":{"execution":{"iopub.status.busy":"2022-05-25T02:10:38.76058Z","iopub.execute_input":"2022-05-25T02:10:38.761229Z","iopub.status.idle":"2022-05-25T02:10:38.768775Z","shell.execute_reply.started":"2022-05-25T02:10:38.761185Z","shell.execute_reply":"2022-05-25T02:10:38.767818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# 7. Pre-Processing for Training","metadata":{}},{"cell_type":"code","source":"# scaler = MinMaxScaler(feature_range = (0, 1))\n\n# scaler = StandardScaler()\n\n# for col in FEATURES:\n#     trn_data[col] = scaler.fit_transform(trn_data[col].to_numpy().reshape(-1,1))\n#     tst_data[col] = scaler.transform(tst_data[col].to_numpy().reshape(-1,1))\n    \nX = trn_data[FEATURES].to_numpy().astype(np.float32)\nY = trn_data[TARGET].to_numpy().astype(np.float32)\nX_test = tst_data[FEATURES].to_numpy().astype(np.float32)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T02:10:38.770596Z","iopub.execute_input":"2022-05-25T02:10:38.771256Z","iopub.status.idle":"2022-05-25T02:10:39.484768Z","shell.execute_reply.started":"2022-05-25T02:10:38.771203Z","shell.execute_reply":"2022-05-25T02:10:39.483958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# 8. Model Construction, Gated Residual and Variable Selection Networks","metadata":{}},{"cell_type":"markdown","source":"## 8.1 - Creating the Layers for the Model.","metadata":{}},{"cell_type":"code","source":"def create_model_inputs():\n    inputs = {}\n    for feature_name in FEATURES:\n        inputs[feature_name] = layers.Input(\n            name=feature_name, shape=(), dtype=tf.float32\n        )\n    return inputs","metadata":{"execution":{"iopub.status.busy":"2022-05-25T02:10:39.486221Z","iopub.execute_input":"2022-05-25T02:10:39.486514Z","iopub.status.idle":"2022-05-25T02:10:39.49354Z","shell.execute_reply.started":"2022-05-25T02:10:39.486474Z","shell.execute_reply":"2022-05-25T02:10:39.492772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def encode_inputs(inputs, encoding_size):\n    encoded_features = []\n    for i in range(inputs.shape[1]):\n        encoded_feature = tf.expand_dims(inputs[:, i], -1)\n        encoded_feature = layers.Dense(units=encoding_size)(encoded_feature)\n        encoded_features.append(encoded_feature)\n    return encoded_features   ","metadata":{"execution":{"iopub.status.busy":"2022-05-25T02:10:39.494845Z","iopub.execute_input":"2022-05-25T02:10:39.495621Z","iopub.status.idle":"2022-05-25T02:10:39.505232Z","shell.execute_reply.started":"2022-05-25T02:10:39.495575Z","shell.execute_reply":"2022-05-25T02:10:39.504312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creates network units to be used in the model.\n\nclass GatedLinearUnit(layers.Layer):\n    def __init__(self, units):\n        super(GatedLinearUnit, self).__init__()\n        self.linear = layers.Dense(units)\n        self.sigmoid = layers.Dense(units, activation=\"sigmoid\")\n\n    def call(self, inputs):\n        return self.linear(inputs) * self.sigmoid(inputs)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T02:10:39.508825Z","iopub.execute_input":"2022-05-25T02:10:39.510146Z","iopub.status.idle":"2022-05-25T02:10:39.517221Z","shell.execute_reply.started":"2022-05-25T02:10:39.510062Z","shell.execute_reply":"2022-05-25T02:10:39.516334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creates network units to be used in the model.\n\nclass GatedResidualNetwork(layers.Layer):\n    def __init__(self, units, dropout_rate):\n        super(GatedResidualNetwork, self).__init__()\n        self.units = units\n        self.elu_dense = layers.Dense(units, activation=\"swish\") # Originally Was Utilizing 'elu' Activations.\n        self.linear_dense = layers.Dense(units)\n        self.dropout = layers.Dropout(dropout_rate)\n        self.gated_linear_unit = GatedLinearUnit(units)\n        self.layer_norm = layers.LayerNormalization()\n        self.project = layers.Dense(units)\n\n    def call(self, inputs):\n        x = self.elu_dense(inputs)\n        x = self.linear_dense(x)\n        x = self.dropout(x)\n        if inputs.shape[-1] != self.units:\n            inputs = self.project(inputs)\n        x = inputs + self.gated_linear_unit(x)\n        x = self.layer_norm(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-05-25T02:10:39.519057Z","iopub.execute_input":"2022-05-25T02:10:39.519827Z","iopub.status.idle":"2022-05-25T02:10:39.530093Z","shell.execute_reply.started":"2022-05-25T02:10:39.519782Z","shell.execute_reply":"2022-05-25T02:10:39.529186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class VariableSelection(layers.Layer):\n    def __init__(self, num_features, units, dropout_rate):\n        super(VariableSelection, self).__init__()\n        self.grns = list()\n        # Create a GRN for each feature independently\n        for idx in range(num_features):\n            grn = GatedResidualNetwork(units, dropout_rate)\n            self.grns.append(grn)\n        # Create a GRN for the concatenation of all the features\n        self.grn_concat = GatedResidualNetwork(units, dropout_rate)\n        self.softmax = layers.Dense(units=num_features, activation=\"softmax\")\n\n    def call(self, inputs):\n        v = layers.concatenate(inputs)\n        v = self.grn_concat(v)\n        v = tf.expand_dims(self.softmax(v), axis=-1)\n\n        x = []\n        for idx, input in enumerate(inputs):\n            x.append(self.grns[idx](input))\n        x = tf.stack(x, axis=1)\n\n        outputs = tf.squeeze(tf.matmul(v, x, transpose_a=True), axis=1)\n        return outputs","metadata":{"execution":{"iopub.status.busy":"2022-05-25T02:10:39.532142Z","iopub.execute_input":"2022-05-25T02:10:39.532869Z","iopub.status.idle":"2022-05-25T02:10:39.543881Z","shell.execute_reply.started":"2022-05-25T02:10:39.532734Z","shell.execute_reply":"2022-05-25T02:10:39.542908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## 8.2 - Creating the Model GRV & VSN","metadata":{}},{"cell_type":"code","source":"def create_model(encoding_size, dropout_rate=0.10):\n    inputs = layers.Input(len(FEATURES))\n    feature_list = encode_inputs(inputs, encoding_size)\n    num_features = len(feature_list)\n\n    features = VariableSelection(num_features, encoding_size, dropout_rate)(\n        feature_list\n    )\n\n    outputs = layers.Dense(units=1, activation=\"sigmoid\")(features)\n    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-05-25T02:10:39.545826Z","iopub.execute_input":"2022-05-25T02:10:39.546574Z","iopub.status.idle":"2022-05-25T02:10:39.556327Z","shell.execute_reply.started":"2022-05-25T02:10:39.54645Z","shell.execute_reply":"2022-05-25T02:10:39.555398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# 9.0 Training the Model, Cross Validation Loop","metadata":{}},{"cell_type":"code","source":"def format_time(seconds):\n    \"\"\"\n    Formates time in human readable form\n\n    Args:\n        seconds: seconds passed in a process\n    Return:\n        formatted string in form of MM:SS or HH:MM:SS\n    \"\"\"\n    h = int(seconds // 3600)\n    m = int((seconds % 3600) // 60)\n    s = int(seconds % 60)\n    result = ''\n    _h = ('0' + str(h)) if h < 10 else str(h)\n    result += (_h + ' hr ') if h > 0 else ''\n    _m = ('0' + str(m)) if m < 10 else str(m)\n    result += (_m + ' min ') if m > 0 else ''\n    _s = ('0' + str(s)) if s < 10 else str(s)\n    result += (_s + ' sec')\n    return result","metadata":{"execution":{"iopub.status.busy":"2022-05-25T02:10:39.559486Z","iopub.execute_input":"2022-05-25T02:10:39.560329Z","iopub.status.idle":"2022-05-25T02:10:39.569273Z","shell.execute_reply.started":"2022-05-25T02:10:39.560281Z","shell.execute_reply":"2022-05-25T02:10:39.568271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\nimport math\n\noof_df = defaultdict(lambda : [])\ntest_df = defaultdict(lambda : np.zeros((X_test.shape[0])))\n\nN_FOLDS = 3\nENCODING_SIZE = 96 # Default Value = 32 ...\nEPOCHS = 15\nVERBOSE = 1\nBATCH_SIZE = 2048\nSEED = 42\n\nstart = time.time()\nskfolds = model_selection.StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n\nfor fold, (t, v) in enumerate(skfolds.split(X, Y)):\n    x_train, x_val = X[t], X[v]\n    y_train, y_val = Y[t], Y[v]\n    \n    # Scaling features for improved training\n    scaler = StandardScaler()\n    x_train = scaler.fit_transform(x_train)\n    x_val = scaler.transform(x_val)\n    \n    oof_df[TARGET].extend(y_val)\n    print(f\"\\n{'-'*15} FOLD-{fold} {'-'*15}\")\n    \n    tic = time.time()\n    \n    clf = create_model(ENCODING_SIZE)\n    \n    clf.compile(loss='binary_crossentropy', \n                optimizer='adam', \n                metrics=[tf.keras.metrics.AUC(name='auc'), 'acc'])\n    \n    lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.25, \n                               patience=4, verbose=VERBOSE)\n\n    es = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=15, \n                       verbose=VERBOSE, mode=\"min\", \n                       restore_best_weights=True)\n    \n    lr_start = 0.0100\n    lr_end   = 0.0002\n    \n    epochs = EPOCHS\n    def cosine_decay(epoch):\n        if epochs > 1:\n            w = (1 + math.cos(epoch / (epochs - 1) * math.pi)) / 2\n        else:\n            w = 1\n        return w * lr_start + (1 - w) * lr_end\n        \n    tm = tf.keras.callbacks.TerminateOnNaN()\n    lr = LearningRateScheduler(cosine_decay, verbose = 0)\n    \n    # callbacks = [es, lr]\n    callbacks = [lr, tm]\n    \n    \n    \n    clf.fit(x_train, y_train, \n            epochs=EPOCHS, \n            batch_size=BATCH_SIZE,\n            validation_data=(x_val, y_val),\n            validation_batch_size=len(y_val),\n            callbacks=callbacks,\n            shuffle=True,\n            verbose=VERBOSE)\n    \n    \n    X_test = scaler.transform(X_test)\n    \n    preds = np.squeeze(clf.predict(x_val, batch_size=len(y_val)))\n    oof_df[f'nn'].extend(preds)\n    test_df[f'nn'] += (np.squeeze(clf.predict(X_test, batch_size=BATCH_SIZE) / N_FOLDS))\n\n    score = roc_auc_score(y_val, preds)\n    print(f\"MODEL: nn\\tSCORE: {score}\\tTIME: {format_time(time.time()-tic)}\")\n\n    del clf\n    gc.collect()\n        \n    del x_train, x_val, y_train, y_val\n    gc.collect()\n        \noof_df = pd.DataFrame(oof_df)\ntest_df = pd.DataFrame(test_df)\n\nprint()\nprint(f'TOTAL TIME: {format_time(time.time() - start)}')","metadata":{"execution":{"iopub.status.busy":"2022-05-25T02:10:39.570977Z","iopub.execute_input":"2022-05-25T02:10:39.571494Z","iopub.status.idle":"2022-05-25T02:22:37.813475Z","shell.execute_reply.started":"2022-05-25T02:10:39.571446Z","shell.execute_reply":"2022-05-25T02:22:37.81259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = roc_auc_score(oof_df[TARGET], oof_df['nn'])\nprint(f'Overall ROC AUC of: {score}')","metadata":{"execution":{"iopub.status.busy":"2022-05-25T02:22:37.815066Z","iopub.execute_input":"2022-05-25T02:22:37.815531Z","iopub.status.idle":"2022-05-25T02:22:38.205958Z","shell.execute_reply.started":"2022-05-25T02:22:37.815489Z","shell.execute_reply":"2022-05-25T02:22:38.205075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Overall ROC AUC of: 0.9968621943736978","metadata":{"execution":{"iopub.status.busy":"2022-05-25T02:22:38.207239Z","iopub.execute_input":"2022-05-25T02:22:38.208036Z","iopub.status.idle":"2022-05-25T02:22:38.212404Z","shell.execute_reply.started":"2022-05-25T02:22:38.207992Z","shell.execute_reply":"2022-05-25T02:22:38.21158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# 11.0 - Baseline Model Submission File Generation","metadata":{}},{"cell_type":"code","source":"%%time\n# Review the format of the submission file\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-25T02:22:38.213743Z","iopub.execute_input":"2022-05-25T02:22:38.214661Z","iopub.status.idle":"2022-05-25T02:22:38.231729Z","shell.execute_reply.started":"2022-05-25T02:22:38.214616Z","shell.execute_reply":"2022-05-25T02:22:38.230817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Populated the prediction on the submission dataset and creates an output file\nsub['target'] = test_df['nn']\nsub.to_csv('my_submission_051322.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T02:22:38.233494Z","iopub.execute_input":"2022-05-25T02:22:38.233818Z","iopub.status.idle":"2022-05-25T02:22:40.739423Z","shell.execute_reply.started":"2022-05-25T02:22:38.233774Z","shell.execute_reply":"2022-05-25T02:22:40.738562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Review the submission file as a final step to upload to Kaggle.\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-25T02:22:40.740692Z","iopub.execute_input":"2022-05-25T02:22:40.740983Z","iopub.status.idle":"2022-05-25T02:22:40.754612Z","shell.execute_reply.started":"2022-05-25T02:22:40.740943Z","shell.execute_reply":"2022-05-25T02:22:40.753676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}