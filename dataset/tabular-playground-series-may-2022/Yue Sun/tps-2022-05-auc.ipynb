{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfrom sklearn import metrics\nfrom sklearn import preprocessing\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom sklearn.preprocessing import OneHotEncoder, RobustScaler, StandardScaler, LabelEncoder\nimport math\n%matplotlib inline\nfrom glob import glob\nimport matplotlib.pyplot as plt\nimport json\nfrom collections import defaultdict\nimport gc\ngc.enable()\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim.optimizer import Optimizer\nimport torch.optim.lr_scheduler as lr_scheduler\nfrom torch.utils.data import (\n    Dataset, DataLoader, \n    SequentialSampler, RandomSampler\n)\nfrom transformers import AutoConfig\nfrom transformers import (\n    get_cosine_schedule_with_warmup, \n    get_cosine_with_hard_restarts_schedule_with_warmup,\n    get_linear_schedule_with_warmup\n)\nfrom transformers import AdamW\nfrom transformers import AutoTokenizer\nfrom transformers import AutoModel\nfrom transformers import MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING\nfrom IPython.display import clear_output\nfrom tqdm import tqdm, trange\nfrom sklearn import model_selection\ndef create_folds(data, num_splits):\n    data[\"kfold\"] = -1\n    kf = model_selection.KFold(n_splits=num_splits, shuffle=True, random_state = config_seed)\n    for f, (t_, v_) in enumerate(kf.split(X=data)):\n        data.loc[v_, 'kfold'] = f\n    return data","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-21T05:27:44.580046Z","iopub.execute_input":"2022-05-21T05:27:44.580432Z","iopub.status.idle":"2022-05-21T05:27:54.634018Z","shell.execute_reply.started":"2022-05-21T05:27:44.580323Z","shell.execute_reply":"2022-05-21T05:27:54.632952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nconfig = {\n    'batch_size': 130, #128\n    'max_len':256,   # 256\n}\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONASSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\nseed_everything(seed= 42)\nclass JFDataset(nn.Module):\n    def __init__(self,df,tokenizer,max_len=128):\n        self.excerpt = df['excerpt'].to_numpy()\n        self.max_len = max_len\n        self.tokenizer = tokenizer\n    def __getitem__(self,idx):\n        encode = self.tokenizer(self.excerpt[idx],\n                                return_tensors='pt',\n                                max_length=self.max_len,\n                                padding='max_length',\n                                truncation=True)  \n        return encode  \n    def __len__(self):\n        return len(self.excerpt)\ndef get_embeddings(df,path, plot_losses=True, verbose=True):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"{device} is used\")\n    MODEL_PATH = path\n    model = AutoModel.from_pretrained(MODEL_PATH)\n    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n    model.to(device)\n    model.eval()\n    ds = JFDataset(df,tokenizer,config['max_len'])\n    dl = DataLoader(ds,\n                  batch_size = config[\"batch_size\"],\n                  shuffle=False,\n                  num_workers = 4,\n                 # pin_memory = False,\n                  pin_memory = True,\n                  drop_last = False\n                 )\n    embeddings = list()\n    with torch.no_grad():\n        for i, inputs in tqdm(enumerate(dl)):\n            inputs = {key:val.reshape(val.shape[0],-1).to(device) for key,val in inputs.items()}\n            outputs = model(**inputs)\n            outputs = outputs[0][:,0].detach().cpu().numpy()\n            embeddings.extend(outputs)\n    del model\n    del tokenizer\n    del ds\n    del dl\n    del outputs\n    del MODEL_PATH\n    del device\n    gc.collect()\n    torch.cuda.empty_cache()\n    return np.array(embeddings)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T06:55:30.024926Z","iopub.execute_input":"2022-05-19T06:55:30.025397Z","iopub.status.idle":"2022-05-19T06:55:30.045571Z","shell.execute_reply.started":"2022-05-19T06:55:30.025355Z","shell.execute_reply":"2022-05-19T06:55:30.044663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"execution":{"iopub.status.busy":"2022-05-19T06:56:13.362596Z","iopub.execute_input":"2022-05-19T06:56:13.363193Z","iopub.status.idle":"2022-05-19T06:56:29.27468Z","shell.execute_reply.started":"2022-05-19T06:56:13.363156Z","shell.execute_reply":"2022-05-19T06:56:29.27396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X = pd.read_csv(\"../input/tabular-playground-series-may-2022/train.csv\")\n# X = X.drop(\"f_27\", axis = 1)\n# train_f27 = pd.read_pickle(\"../input/f27-file/f27_X.pkl\")\n# train_f27 = get_embeddings(train_f27, '../input/myrobertabase')\n# train_f27 = pd.DataFrame(train_f27)\n# X = pd.concat([X, train_f27], axis = 1)\n# X.to_pickle('tps05_X.pkl')\n# del X","metadata":{"execution":{"iopub.status.busy":"2022-05-18T13:53:56.729815Z","iopub.execute_input":"2022-05-18T13:53:56.730141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv(\"../input/tabular-playground-series-may-2022/test.csv\")\ntest_f27 = test[['f_27']]\ntest_f27.columns = ['excerpt']\ntest = test.drop(\"f_27\", axis = 1)\ntest_f27 = get_embeddings(test_f27, '../input/myrobertabase')\ntest_f27 = pd.DataFrame(test_f27)\ntest = pd.concat([test, test_f27], axis = 1)\ntest.to_pickle('tps05_to_test.pkl')","metadata":{},"execution_count":null,"outputs":[]}]}