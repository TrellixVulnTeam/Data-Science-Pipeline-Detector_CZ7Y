{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\nHi, this is my second notebook so feel free to comment on my mistake.\nIn this notebook, I will show everything that I have done in this competition and their reason.\nThis may not be the best notebook but I think someone will learn something new from my work. \nSo, LET'S GO.\n","metadata":{}},{"cell_type":"markdown","source":"# First look at our data","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nsns.set(style='white', context='notebook', palette='deep', rc = {'figure.figsize':(15,8)})\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-05-09T06:31:12.706905Z","iopub.execute_input":"2022-05-09T06:31:12.707806Z","iopub.status.idle":"2022-05-09T06:31:12.719516Z","shell.execute_reply.started":"2022-05-09T06:31:12.707756Z","shell.execute_reply":"2022-05-09T06:31:12.717558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Maybe-useful-knowledge: There are a lot of data points so if you want to speed up the reading phase, you can save the data in feather mode and read them using pandas","metadata":{}},{"cell_type":"code","source":"url = \"../input/tabular-playground-series-may-2022/\"\ntrain = pd.read_csv(url + \"train.csv\")\ntrain = train.drop('id', axis=1)\ntest  = pd.read_csv(url + \"test.csv\")\ntarget = train['target']","metadata":{"execution":{"iopub.status.busy":"2022-05-09T06:31:12.722261Z","iopub.execute_input":"2022-05-09T06:31:12.722694Z","iopub.status.idle":"2022-05-09T06:31:29.52639Z","shell.execute_reply.started":"2022-05-09T06:31:12.722641Z","shell.execute_reply":"2022-05-09T06:31:29.52322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2022-05-09T06:31:29.532226Z","iopub.execute_input":"2022-05-09T06:31:29.534466Z","iopub.status.idle":"2022-05-09T06:31:30.310155Z","shell.execute_reply.started":"2022-05-09T06:31:29.534103Z","shell.execute_reply":"2022-05-09T06:31:30.308952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"First look: \n1. There are 900,000 data points and 31 features\n2. The label is binary\n3. Every features are labeled so we don't have any domain knowledge about this problem","metadata":{}},{"cell_type":"code","source":"null_count = train.isnull().sum()\nnull_count[null_count > 0]","metadata":{"execution":{"iopub.status.busy":"2022-05-09T06:31:30.313177Z","iopub.execute_input":"2022-05-09T06:31:30.313553Z","iopub.status.idle":"2022-05-09T06:31:30.427783Z","shell.execute_reply.started":"2022-05-09T06:31:30.313521Z","shell.execute_reply":"2022-05-09T06:31:30.426906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"No null value in our train dataset","metadata":{}},{"cell_type":"code","source":"null_count = test.isnull().sum()\nnull_count[null_count > 0]","metadata":{"execution":{"iopub.status.busy":"2022-05-09T06:31:30.429038Z","iopub.execute_input":"2022-05-09T06:31:30.429443Z","iopub.status.idle":"2022-05-09T06:31:30.518018Z","shell.execute_reply.started":"2022-05-09T06:31:30.429411Z","shell.execute_reply":"2022-05-09T06:31:30.516918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Also, the test set is full","metadata":{}},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2022-05-09T06:31:30.519703Z","iopub.execute_input":"2022-05-09T06:31:30.520008Z","iopub.status.idle":"2022-05-09T06:31:30.665125Z","shell.execute_reply.started":"2022-05-09T06:31:30.519976Z","shell.execute_reply":"2022-05-09T06:31:30.664017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looking at the info(), I can see there is only 1 object feature(f_27) while other are numerical","metadata":{}},{"cell_type":"markdown","source":"Let see if any of our numerical features are actually category","metadata":{}},{"cell_type":"code","source":"unique_value = train.select_dtypes(include='number').nunique().sort_values()\nunique_value.plot.bar(logy=True, title='Unique value per feature', figsize=(20,10))","metadata":{"execution":{"iopub.status.busy":"2022-05-09T06:31:30.6666Z","iopub.execute_input":"2022-05-09T06:31:30.666908Z","iopub.status.idle":"2022-05-09T06:31:34.142921Z","shell.execute_reply.started":"2022-05-09T06:31:30.666862Z","shell.execute_reply":"2022-05-09T06:31:34.141807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above chart, we can see those features on the left are actually categorical data","metadata":{}},{"cell_type":"markdown","source":"Then, let classify features into continuous and categorical (easily done by using unique_value above)","metadata":{}},{"cell_type":"code","source":"continuous  = unique_value[unique_value > 20].index.to_list()\ncontinuous.sort()\ncategorical = unique_value[unique_value <= 20].index.to_list()\ncategorical.sort()\ncategorical.remove('target')","metadata":{"execution":{"iopub.status.busy":"2022-05-09T06:31:34.144951Z","iopub.execute_input":"2022-05-09T06:31:34.145308Z","iopub.status.idle":"2022-05-09T06:31:34.151987Z","shell.execute_reply.started":"2022-05-09T06:31:34.14526Z","shell.execute_reply":"2022-05-09T06:31:34.151055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Target","metadata":{}},{"cell_type":"code","source":"sns.countplot(train['target'])","metadata":{"execution":{"iopub.status.busy":"2022-05-09T06:31:34.15331Z","iopub.execute_input":"2022-05-09T06:31:34.153869Z","iopub.status.idle":"2022-05-09T06:31:34.410148Z","shell.execute_reply.started":"2022-05-09T06:31:34.153811Z","shell.execute_reply":"2022-05-09T06:31:34.409244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So, the number of 0 and 1 data is almost the same","metadata":{}},{"cell_type":"markdown","source":"# Continuous feature","metadata":{}},{"cell_type":"markdown","source":"Distribution","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(4,4, figsize=(30,30))\nfor col, ax in zip(continuous, axes.ravel()):\n    sns.kdeplot(train[col], ax=ax)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T06:31:34.412733Z","iopub.execute_input":"2022-05-09T06:31:34.413017Z","iopub.status.idle":"2022-05-09T06:32:33.667087Z","shell.execute_reply.started":"2022-05-09T06:31:34.412985Z","shell.execute_reply":"2022-05-09T06:32:33.666124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Look like our continuos data are almost normal","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12, 12))\nsns.heatmap(train[continuous + ['target']].corr(), center=0, annot=True, fmt='.2f')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-09T06:32:33.668332Z","iopub.execute_input":"2022-05-09T06:32:33.668589Z","iopub.status.idle":"2022-05-09T06:32:35.882477Z","shell.execute_reply.started":"2022-05-09T06:32:33.668548Z","shell.execute_reply":"2022-05-09T06:32:35.881844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the heatmap, we know\n1. The highest correlation to target is 0.13 so most of our data dont have linear relationship with target\n2. f_00 to f_06 have slightly linear relationship with f_28\n","metadata":{}},{"cell_type":"markdown","source":"# Categorical feature","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(4,4, figsize=(30,30))\nfig.delaxes(axes[3][3])\nfig.delaxes(axes[3][2])\nfor col, ax in zip(categorical, axes.ravel()):\n    sns.countplot(train[col], ax=ax)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T06:32:35.883739Z","iopub.execute_input":"2022-05-09T06:32:35.884708Z","iopub.status.idle":"2022-05-09T06:32:39.968619Z","shell.execute_reply.started":"2022-05-09T06:32:35.884647Z","shell.execute_reply":"2022-05-09T06:32:39.965908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1. Categorical feature f_7 to f_18 looks almost similar and the number of higher category is minor compared to the lower category.\n2. f_7 to f_18 can be ordinal \n3. Categorical feature f_30 is almost uniform.","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(4,4, figsize=(30,30))\nfig.delaxes(axes[3][3])\nfig.delaxes(axes[3][2])\nfor col, ax in zip(categorical, axes.ravel()):\n    sns.countplot(train[col], hue=train['target'], ax=ax)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T06:32:39.969925Z","iopub.execute_input":"2022-05-09T06:32:39.97014Z","iopub.status.idle":"2022-05-09T06:32:46.786797Z","shell.execute_reply.started":"2022-05-09T06:32:39.970113Z","shell.execute_reply":"2022-05-09T06:32:46.785878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is difference between number of 0 and 1 in all those categorical feature which means all of them are informative.","metadata":{}},{"cell_type":"markdown","source":"# Object feature\n","metadata":{}},{"cell_type":"code","source":"train['f_27'].apply(lambda x: len(x)).unique()","metadata":{"execution":{"iopub.status.busy":"2022-05-09T06:32:46.788268Z","iopub.execute_input":"2022-05-09T06:32:46.788552Z","iopub.status.idle":"2022-05-09T06:32:47.11916Z","shell.execute_reply.started":"2022-05-09T06:32:46.788509Z","shell.execute_reply":"2022-05-09T06:32:47.118024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So, f_27 feature are strings of 10 uppercase characters","metadata":{}},{"cell_type":"code","source":"counts = train['f_27'].value_counts()\nprint(counts)\nprint(len(counts[counts > 1]))","metadata":{"execution":{"iopub.status.busy":"2022-05-09T06:32:47.120787Z","iopub.execute_input":"2022-05-09T06:32:47.121422Z","iopub.status.idle":"2022-05-09T06:32:47.899381Z","shell.execute_reply.started":"2022-05-09T06:32:47.121381Z","shell.execute_reply":"2022-05-09T06:32:47.898457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have a lot of repeating strings and BBBBBBCJBC is the most commom.","metadata":{}},{"cell_type":"code","source":"for i in range(10):\n    print(\"Position {}: {} unique character\".format(i,train['f_27'].apply(lambda x: x[i]).nunique()))","metadata":{"execution":{"iopub.status.busy":"2022-05-09T06:32:47.900559Z","iopub.execute_input":"2022-05-09T06:32:47.901182Z","iopub.status.idle":"2022-05-09T06:32:49.575665Z","shell.execute_reply.started":"2022-05-09T06:32:47.901142Z","shell.execute_reply":"2022-05-09T06:32:49.574734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Each positions has small cardinality so instead of encoding f_27, we should encode each postion in f_27","metadata":{}},{"cell_type":"markdown","source":"# F_27 feature\n","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(url + \"train.csv\")\n#train = train.sample(100000, random_state=2) used when feature engineering and tuning hyperparameter\ntrain = train.drop('id', axis=1)\ntest  = pd.read_csv(url + \"test.csv\")\nid_test = test['id']\ntest  = test.drop('id', axis=1)\ntarget = train['target']","metadata":{"execution":{"iopub.status.busy":"2022-05-09T06:32:49.576857Z","iopub.execute_input":"2022-05-09T06:32:49.577096Z","iopub.status.idle":"2022-05-09T06:33:02.458321Z","shell.execute_reply.started":"2022-05-09T06:32:49.577067Z","shell.execute_reply":"2022-05-09T06:33:02.457195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unique_value = train.select_dtypes(include='number').nunique().sort_values()\ncontinuous  = unique_value[unique_value > 20].index.to_list()\ncontinuous.sort()\ncategorical = unique_value[unique_value <= 20].index.to_list()\ncategorical.sort()\ncategorical.remove('target')","metadata":{"execution":{"iopub.status.busy":"2022-05-09T06:33:02.4602Z","iopub.execute_input":"2022-05-09T06:33:02.460438Z","iopub.status.idle":"2022-05-09T06:33:04.14464Z","shell.execute_reply.started":"2022-05-09T06:33:02.460411Z","shell.execute_reply":"2022-05-09T06:33:04.14367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next, we will split f_27 into 10 features based on their position and then encode them","metadata":{}},{"cell_type":"code","source":"test['target'] = 0\ntrain_len = len(train)\ntraintest = pd.concat([train, test])\ndel train,test\nf_27_cols = []\nfor i in range(10):\n    new_col = \"f_27_{}\".format(i)\n    f_27_cols.append(new_col)\n    traintest[new_col] = traintest['f_27'].apply(lambda x: x[i])\ntraintest[\"unique_characters\"] = traintest['f_27'].apply(lambda x: len(set(x)))\ntraintest = traintest.drop('f_27',axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T06:33:04.146617Z","iopub.execute_input":"2022-05-09T06:33:04.146915Z","iopub.status.idle":"2022-05-09T06:33:09.497125Z","shell.execute_reply.started":"2022-05-09T06:33:04.146884Z","shell.execute_reply":"2022-05-09T06:33:09.495685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import OrdinalEncoder\nOE = OrdinalEncoder(categories='auto')\nOE.fit(traintest[f_27_cols])\nprint(OE.categories_)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T06:33:09.499002Z","iopub.execute_input":"2022-05-09T06:33:09.499284Z","iopub.status.idle":"2022-05-09T06:33:10.17238Z","shell.execute_reply.started":"2022-05-09T06:33:09.499255Z","shell.execute_reply":"2022-05-09T06:33:10.170756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I used ordinal encoder instead of label encoder as I believe alphabet is likely to be ordinal","metadata":{}},{"cell_type":"code","source":"traintest[f_27_cols] = OE.transform(traintest[f_27_cols])\ntraintest['f_27_sum'] = 0\nfor col in f_27_cols:\n    traintest['f_27_sum'] = traintest['f_27_sum'] + traintest[col]","metadata":{"execution":{"iopub.status.busy":"2022-05-09T06:33:10.174159Z","iopub.execute_input":"2022-05-09T06:33:10.174517Z","iopub.status.idle":"2022-05-09T06:33:14.797586Z","shell.execute_reply.started":"2022-05-09T06:33:10.174471Z","shell.execute_reply":"2022-05-09T06:33:14.79573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(2,5, figsize=(50,30))\nfor col, ax in zip(f_27_cols, axes.ravel()):\n    sns.countplot(traintest[:train_len][col], hue=traintest[:train_len]['target'], ax=ax)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T06:33:14.799725Z","iopub.execute_input":"2022-05-09T06:33:14.800185Z","iopub.status.idle":"2022-05-09T06:33:20.678435Z","shell.execute_reply.started":"2022-05-09T06:33:14.800128Z","shell.execute_reply":"2022-05-09T06:33:20.677782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The difference between 0 and 1 in some features is quite high so f_27 can be very important","metadata":{}},{"cell_type":"markdown","source":"# Feature engineering","metadata":{}},{"cell_type":"markdown","source":"I'm just a newbie in feature engineering so I only know some techniques but I will try to apply all of them in this notebook.\n1. The first and maybe the most is feature interaction where I choose to use + - * / between some features. I choosed those features as I have tried 100 random combination and choose only the top features. That took really long (5 hours running on Kaggle) but as a student, I run it on Kaggle and went to school 😂.\n2. Next, I fitted a base lgbm classifier and ploted the feature importance. I saw f_27_5 is useless but maybe it is useless on its own so I create its interaction with all other feature and take out two conbinations with f_27_7 and f_27_8.\n3. Lastly, I tried polynomial features which is simple but powerful. Again, create all 2 degree polynomial features on continuous data and take out top 3 features.\n\nIf I remember correctly, the base lgbm without any feature engineering, trained on 100000 data points, is 0.9818 and with feature engineering is 0.9821. A resonable increase right!!","metadata":{}},{"cell_type":"code","source":"def create_interaction_feature(df, fea1, fea2):\n    df['{}+{}'.format(fea1, fea2)] = df[fea1] - df[fea2]\n    df['{}-{}'.format(fea1, fea2)] = df[fea1] + df[fea2]\n    df['{}/{}'.format(fea1, fea2)] = df[fea1] / df[fea2]\n    df['{}*{}'.format(fea1, fea2)] = df[fea1] * df[fea2]","metadata":{"execution":{"iopub.status.busy":"2022-05-09T06:33:20.679615Z","iopub.execute_input":"2022-05-09T06:33:20.680024Z","iopub.status.idle":"2022-05-09T06:33:20.686438Z","shell.execute_reply.started":"2022-05-09T06:33:20.679977Z","shell.execute_reply":"2022-05-09T06:33:20.685432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import itertools\nfea1 = 'f_27_5'\nother = ['f_27_7', 'f_27_8']\nfor fea2 in other:\n    create_interaction_feature(traintest, fea1, fea2)\n\ntop_per_feature = ['f_26','f_00']\nfor fea1, fea2 in itertools.permutations(top_per_feature, 2):\n    create_interaction_feature(traintest, fea1, fea2)\n\nfor col in ['f_21', 'f_22', 'f_26']:\n    traintest['{}^2'.format(col)] = traintest[col]**2 \n","metadata":{"execution":{"iopub.status.busy":"2022-05-09T06:33:20.68789Z","iopub.execute_input":"2022-05-09T06:33:20.688223Z","iopub.status.idle":"2022-05-09T06:33:20.908882Z","shell.execute_reply.started":"2022-05-09T06:33:20.688188Z","shell.execute_reply":"2022-05-09T06:33:20.90794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"traintest = pd.get_dummies(traintest, columns=['f_29','f_30','f_27_0','f_27_2','f_27_5'])","metadata":{"execution":{"iopub.status.busy":"2022-05-09T06:33:20.9102Z","iopub.execute_input":"2022-05-09T06:33:20.910528Z","iopub.status.idle":"2022-05-09T06:33:22.375707Z","shell.execute_reply.started":"2022-05-09T06:33:20.910467Z","shell.execute_reply":"2022-05-09T06:33:22.374869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"traintest = traintest.drop('target',axis=1)\ntrain = traintest[:train_len]\ntest  = traintest[train_len:]\ndel traintest","metadata":{"execution":{"iopub.status.busy":"2022-05-09T06:33:22.378885Z","iopub.execute_input":"2022-05-09T06:33:22.379588Z","iopub.status.idle":"2022-05-09T06:33:23.149166Z","shell.execute_reply.started":"2022-05-09T06:33:22.379549Z","shell.execute_reply":"2022-05-09T06:33:23.148179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"import lightgbm as lgbm\nimport xgboost as xgb\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score, confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2022-05-09T06:33:23.150802Z","iopub.execute_input":"2022-05-09T06:33:23.15114Z","iopub.status.idle":"2022-05-09T06:33:24.570047Z","shell.execute_reply.started":"2022-05-09T06:33:23.151098Z","shell.execute_reply":"2022-05-09T06:33:24.568919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Hyperparameter tuning is done with optuna on 100000 datapoints and based on this blog [lgbm tuning guide](https://neptune.ai/blog/lightgbm-parameters-guide). Tuned lgbm roc_auc: 0.9361097364777405\n","metadata":{}},{"cell_type":"code","source":"score_list = []\nkf = KFold(n_splits=3, shuffle=True, random_state=2)\nfold = 1\nparams = {\n     'n_estimators': 8000, \n     'lambda_l1': 0.41952180928025645, \n     'bagging_fraction': 0.965448697013478,\n     'bagging_freq': 1,\n     'num_leaves': 60, \n     'max_depth': 10, \n     'max_bin': 786, \n     'learning_rate': 0.023740024697292472, \n     'feature_fraction': 0.7754066689188489, \n     'min_data_in_leaf': 12,\n     'objective' : 'binary',\n     'metric' : 'auc',\n     'is_unbalance': True\n     }\nfor idx_tr, idx_va in kf.split(train):\n     X_tr = train.iloc[idx_tr]\n     X_va = train.iloc[idx_va]\n     y_tr = target.iloc[idx_tr]\n     y_va = target.iloc[idx_va]\n     model = lgbm.LGBMClassifier(**params)\n     model.fit(X_tr, y_tr, eval_set=[(X_va,y_va)], eval_metric='auc', callbacks=[lgbm.early_stopping(800)])\n     y_va_pred = model.predict_proba(X_va.values)[:,1]\n     score = roc_auc_score(y_va, y_va_pred)\n     score_list.append(score)\n     print(\"Fold {} done\".format(fold))\n     fold += 1\nnp.mean(score_list)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T06:55:47.583594Z","iopub.execute_input":"2022-05-09T06:55:47.583977Z","iopub.status.idle":"2022-05-09T07:54:41.102102Z","shell.execute_reply.started":"2022-05-09T06:55:47.583935Z","shell.execute_reply":"2022-05-09T07:54:41.100702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from lightgbm import plot_importance\nplot_importance(model, figsize=(14,30))","metadata":{"execution":{"iopub.status.busy":"2022-05-09T06:53:04.593443Z","iopub.status.idle":"2022-05-09T06:53:04.594349Z","shell.execute_reply.started":"2022-05-09T06:53:04.594098Z","shell.execute_reply":"2022-05-09T06:53:04.594127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import scipy\npred_list = []\nfor seed in range(5):\n    model = lgbm.LGBMClassifier(**params, random_seed =seed+1000)\n    model.fit(train,target)\n    y_pred = model.predict_proba(test.values)[:,1]\n    pred_list.append(scipy.stats.rankdata(y_pred))\n    del y_pred\n    print(f\"{seed:2}\", pred_list[-1])\nprint()\ny_pred = np.array(pred_list).mean(axis=0)\nsubmission = pd.DataFrame({'id': id_test, 'target': y_pred})\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T06:53:04.595646Z","iopub.status.idle":"2022-05-09T06:53:04.595995Z","shell.execute_reply.started":"2022-05-09T06:53:04.595803Z","shell.execute_reply":"2022-05-09T06:53:04.595818Z"},"trusted":true},"execution_count":null,"outputs":[]}]}