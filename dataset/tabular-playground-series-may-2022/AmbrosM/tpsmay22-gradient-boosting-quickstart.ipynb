{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Gradient-Boosting Quickstart for TPSMAY22\n\nThis notebook shows how to train a gradient booster with minimal feature engineering. It wouldn't have been possible without the open-source contributions of other participants, in particular:\n- [Analysing Interactions with SHAP](https://www.kaggle.com/code/wti200/analysing-interactions-with-shap) where @wti200 shows how to analyze feature interactions\n- [EDA & LGBM Model](https://www.kaggle.com/code/cabaxiom/tps-may-22-eda-lgbm-model) where @cabaxiom introduces the unique_characters feature\n\nFor an EDA, see the [separate EDA notebook](https://www.kaggle.com/code/ambrosm/tpsmay22-eda-which-makes-sense).\n\nRelease notes:\n- V1: XGB, 40 features\n- V2: LightGBM, 41 features\n- V3: 44 features, including three feature interactions\n- V4: Plotting and analyzing the training history","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import MaxNLocator\nfrom matplotlib.colors import ListedColormap\nimport seaborn as sns\nfrom cycler import cycler\nfrom IPython.display import display\nimport datetime\nimport scipy.stats\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.ensemble import HistGradientBoostingClassifier, VotingClassifier\nfrom sklearn.calibration import CalibrationDisplay\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\n\nplt.rcParams['axes.prop_cycle'] = cycler(color=['#ffd700'] +\n                                         plt.rcParams['axes.prop_cycle'].by_key()['color'][1:])\nplt.rcParams['text.color'] = 'w'\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-19T20:45:41.152914Z","iopub.execute_input":"2022-05-19T20:45:41.15343Z","iopub.status.idle":"2022-05-19T20:45:42.503963Z","shell.execute_reply.started":"2022-05-19T20:45:41.153313Z","shell.execute_reply":"2022-05-19T20:45:42.503032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-may-2022/train.csv')\ntest = pd.read_csv('../input/tabular-playground-series-may-2022/test.csv')\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-19T20:45:42.505855Z","iopub.execute_input":"2022-05-19T20:45:42.506215Z","iopub.status.idle":"2022-05-19T20:45:53.24932Z","shell.execute_reply.started":"2022-05-19T20:45:42.506145Z","shell.execute_reply":"2022-05-19T20:45:53.24844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Top three feature interactions\n\nIf we look at 2d-scatterplots of the features, colored by target, we find three feature combinations where the projection is subdivided into three distinct regions with sharp borders in between. The following diagrams show the three different projections which lead to three regions each:","metadata":{}},{"cell_type":"code","source":"plt.rcParams['axes.facecolor'] = 'k'\nplt.figure(figsize=(11, 5))\ncmap = ListedColormap([\"#ffd700\", \"#0057b8\"])\n# target == 0 → yellow; target == 1 → blue\n\nax = plt.subplot(1, 3, 1)\nax.scatter(train['f_02'], train['f_21'], s=1,\n           c=train.target, cmap=cmap)\nax.set_xlabel('f_02')\nax.set_ylabel('f_21')\nax.set_aspect('equal')\nax0 = ax\n\nax = plt.subplot(1, 3, 2, sharex=ax0, sharey=ax0)\nax.scatter(train['f_05'], train['f_22'], s=1,\n           c=train.target, cmap=cmap)\nax.set_xlabel('f_05')\nax.set_ylabel('f_22')\nax.set_aspect('equal')\n\nax = plt.subplot(1, 3, 3, sharex=ax0, sharey=ax0)\nax.scatter(train['f_00'] + train['f_01'], train['f_26'], s=1,\n           c=train.target, cmap=cmap)\nax.set_xlabel('f_00 + f_01')\nax.set_ylabel('f_26')\nax.set_aspect('equal')\n\nplt.tight_layout(w_pad=1.0)\nplt.savefig('three-projections.png')\nplt.show()\nplt.rcParams['axes.facecolor'] = '#0057b8' # blue\n","metadata":{"execution":{"iopub.status.busy":"2022-05-19T20:45:53.25053Z","iopub.execute_input":"2022-05-19T20:45:53.250778Z","iopub.status.idle":"2022-05-19T20:47:18.707513Z","shell.execute_reply.started":"2022-05-19T20:45:53.250741Z","shell.execute_reply":"2022-05-19T20:47:18.70678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can either hope for the gradient booster to find these borders by itself (and approximate them with decision trees), or we can help it find them.\n\nAnd how can we help the gradient booster? In the next section, we'll create three ternary categorical features that indicate to what region a sample belongs:\n- Top right region (high probability of target == 1) → +1\n- Middle region (medium probability of target == 1) → 0\n- Bottom left region (low probability of target == 1) → -1\n","metadata":{}},{"cell_type":"markdown","source":"# Feature engineering\n\nWe read the data and apply minimal feature engineering:\n- We split the `f_27` string into ten separate features as described in the [EDA](https://www.kaggle.com/code/ambrosm/tpsmay22-eda-which-makes-sense).\n- We count the unique characters in the string.\n- We introduce three categorical features for the feature interactions described above.","metadata":{}},{"cell_type":"code","source":"for df in [train, test]:\n    # Extract the 10 letters of f_27 into individual features\n    for i in range(10):\n        df[f'ch{i}'] = df.f_27.str.get(i).apply(ord) - ord('A')\n        \n    # unique_characters feature is from https://www.kaggle.com/code/cabaxiom/tps-may-22-eda-lgbm-model\n    df[\"unique_characters\"] = df.f_27.apply(lambda s: len(set(s)))\n    \n    # Feature interactions: create three ternary features\n    # Every ternary feature can have the values -1, 0 and +1\n    df['i_02_21'] = (df.f_21 + df.f_02 > 5.2).astype(int) - (df.f_21 + df.f_02 < -5.3).astype(int)\n    df['i_05_22'] = (df.f_22 + df.f_05 > 5.1).astype(int) - (df.f_22 + df.f_05 < -5.4).astype(int)\n    i_00_01_26 = df.f_00 + df.f_01 + df.f_26\n    df['i_00_01_26'] = (i_00_01_26 > 5.0).astype(int) - (i_00_01_26 < -5.0).astype(int)\n    \nfeatures = [f for f in test.columns if f != 'id' and f != 'f_27']\ntest[features].head(2)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T20:47:18.709356Z","iopub.execute_input":"2022-05-19T20:47:18.709604Z","iopub.status.idle":"2022-05-19T20:47:30.807542Z","shell.execute_reply.started":"2022-05-19T20:47:18.709573Z","shell.execute_reply":"2022-05-19T20:47:30.806719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cross-validation\n\nFor cross-validation, we use a simple KFold with five splits. It turned out that the scores of the five splits are very similar so that I usually run only the first split. This one split is good enough to evaluate the model.\n\nBecause I want to understand how many iterations are needed, we'll collect some metrics and plot the training history. `early_stopping_round` is set to the very high value of 100000. This means that the algorithm won't stop early, but the setting is necessary to collect the metrics.\n","metadata":{}},{"cell_type":"code","source":"%%time\n# Cross-validation of the classifier\n\ndef my_booster(random_state=1, n_estimators=10000):\n    return LGBMClassifier(n_estimators=n_estimators,\n                          min_child_samples=80,\n                          num_leaves=127,\n                          subsample=0.85, subsample_freq=1,\n                          metric='auc,binary_logloss,binary_error',\n                          max_bins=511, random_state=random_state)\n      \nprint(f\"{len(features)} features\")\nscore_list = []\nkf = KFold(n_splits=5)\nfor fold, (idx_tr, idx_va) in enumerate(kf.split(train)):\n    X_tr = train.iloc[idx_tr][features]\n    X_va = train.iloc[idx_va][features]\n    y_tr = train.iloc[idx_tr].target\n    y_va = train.iloc[idx_va].target\n    \n    model = my_booster()\n    model.fit(X_tr, y_tr,\n              early_stopping_rounds=100000, # never stops early\n              eval_set = [(X_tr, y_tr),(X_va, y_va)], \n              verbose=1000)\n    y_va_pred = model.predict_proba(X_va)[:,1]\n    score = roc_auc_score(y_va, y_va_pred)\n    print(f\"Fold {fold}:                  AUC = {score:.5f}\")\n    score_list.append(score)\n    break # we only need the first fold\n    \nprint(f\"OOF AUC:                       {np.mean(score_list):.5f}\")","metadata":{"execution":{"iopub.status.busy":"2022-05-19T20:47:30.808674Z","iopub.execute_input":"2022-05-19T20:47:30.808894Z","iopub.status.idle":"2022-05-19T21:25:28.117823Z","shell.execute_reply.started":"2022-05-19T20:47:30.808867Z","shell.execute_reply":"2022-05-19T21:25:28.116833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We save the metrics as csv files in case anybody wants to evaluate them further:","metadata":{}},{"cell_type":"code","source":"history_tr = pd.DataFrame(model.evals_result_['training'])\nhistory_va = pd.DataFrame(model.evals_result_['valid_1'])\nhistory_tr['accuracy'] = 1 - history_tr.binary_error\nhistory_va['accuracy'] = 1 - history_va.binary_error\nhistory_tr.to_csv('training.csv')\nhistory_va.to_csv('valid.csv')","metadata":{"execution":{"iopub.status.busy":"2022-05-19T21:25:28.119676Z","iopub.execute_input":"2022-05-19T21:25:28.120237Z","iopub.status.idle":"2022-05-19T21:25:28.258307Z","shell.execute_reply.started":"2022-05-19T21:25:28.120186Z","shell.execute_reply":"2022-05-19T21:25:28.257269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we plot the three metrics *loss*, *accuracy* and *AUC* for the whole training history. In every plot, we mark the point where the metric reaches its optimum.\n\nThe estimator overfits terribly: After 2000 iterations, the training predictions are perfect (accuracy and AUC are 1.0). The validation loss reaches its optimum already before 2000 iterations, at a time when validation accuracy and validation auc are still improving. Validation accuracy and validation auc peak several thousand iterations later.\n\n**Insight:** Don't stop lightgbm early when the validation loss stops improving! Wait until validation auc peaks!\n","metadata":{}},{"cell_type":"code","source":"plt.rcParams['axes.facecolor'] = 'k'\nfig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(13, 10), sharex=True)\n\nax1.plot(history_tr.index, history_tr.binary_logloss, label='training')\nax1.plot(history_va.index, history_va.binary_logloss, label='validation')\nm = history_tr.binary_logloss.argmin()\nax1.scatter([m], [history_tr.binary_logloss[m]])\nm = history_va.binary_logloss.argmin()\nax1.scatter([m], [history_va.binary_logloss[m]])\nax1.legend()\nax1.set_ylabel('Loss')\nax1.annotate('validation loss starts increasing\\ndon\\'t stop yet',\n            xy=(m, history_va.binary_logloss[m]), xycoords='data',\n            xytext=(m, 0.3), textcoords='data', color='white',\n            arrowprops=dict(facecolor='white', shrink=0.05),\n            horizontalalignment='center', verticalalignment='top')\n\nax2.plot(history_tr.index, history_tr.accuracy, label='training')\nax2.plot(history_va.index, history_va.accuracy, label='validation')\nm = history_tr.accuracy.argmax()\nax2.scatter([m], [history_tr.accuracy[m]])\nm = history_va.accuracy.argmax()\nax2.scatter([m], [history_va.accuracy[m]])\nax2.legend(loc='lower right')\nax2.set_ylabel('Accuracy')\nax2.annotate('best validation accuracy',\n            xy=(m, history_va.accuracy[m]), xycoords='data',\n            xytext=(m, 0.91), textcoords='data', color='white',\n            arrowprops=dict(facecolor='white', shrink=0.05),\n            horizontalalignment='center', verticalalignment='top')\n\nax3.plot(history_tr.index, history_tr.auc, label='training')\nax3.plot(history_va.index, history_va.auc, label='validation')\nm = history_tr.auc.argmax()\nax3.scatter([m], [history_tr.auc[m]])\nauc_peak = history_va.auc.argmax()\nm = auc_peak\nax3.scatter([m], [history_va.auc[m]])\nax3.legend(loc='lower right')\nax3.set_ylabel('AUC')\nax3.set_xlabel('Iteration')\nax3.set_xticks(np.linspace(0, 10000, 11))\nax3.annotate('best validation auc\\nstop training here',\n            xy=(m, history_va.auc[m]), xycoords='data',\n            xytext=(m, 0.96), textcoords='data', color='orangered',\n            arrowprops=dict(facecolor='red', shrink=0.05),\n            horizontalalignment='center', verticalalignment='top')\n\nplt.suptitle('Lightgbm training history', y=0.94, fontsize=20, color='k')\nplt.savefig('history.png')\nplt.show()\nplt.rcParams['axes.facecolor'] = '#0057b8' # blue\n\nprint(f\"Validation AUC peaks at iteration {auc_peak} with score {history_va.auc[auc_peak]:.5f}\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-19T21:25:28.26065Z","iopub.execute_input":"2022-05-19T21:25:28.260936Z","iopub.status.idle":"2022-05-19T21:25:29.17022Z","shell.execute_reply.started":"2022-05-19T21:25:28.260903Z","shell.execute_reply":"2022-05-19T21:25:29.169266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Three diagrams for model evaluation\n\nWe plot the ROC curve just because it looks nice. The area under the red curve is the score of our model.\n","metadata":{}},{"cell_type":"code","source":"# Plot the roc curve for the last fold\ndef plot_roc_curve(y_va, y_va_pred):\n    plt.figure(figsize=(8, 8))\n    fpr, tpr, _ = roc_curve(y_va, y_va_pred)\n    plt.plot(fpr, tpr, color='r', lw=2)\n    plt.plot([0, 1], [0, 1], color=\"navy\", lw=1, linestyle=\"--\")\n    plt.gca().set_aspect('equal')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.0])\n    plt.xlabel(\"False Positive Rate\")\n    plt.ylabel(\"True Positive Rate\")\n    plt.title(\"Receiver operating characteristic\")\n    plt.show()\n\nplot_roc_curve(y_va, y_va_pred)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-19T21:25:29.171623Z","iopub.execute_input":"2022-05-19T21:25:29.171866Z","iopub.status.idle":"2022-05-19T21:25:29.399552Z","shell.execute_reply.started":"2022-05-19T21:25:29.171835Z","shell.execute_reply":"2022-05-19T21:25:29.39866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Second, we plot a histogram of the out-of-fold predictions. Many predictions are near 0.0 or near 1.0; this means that in many cases the classifier's predictions have high confidence:","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12, 4))\nplt.hist(y_va_pred, bins=25, density=True)\nplt.title('Histogram of the oof predictions')\nplt.show()\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-19T21:25:29.401676Z","iopub.execute_input":"2022-05-19T21:25:29.401944Z","iopub.status.idle":"2022-05-19T21:25:29.617927Z","shell.execute_reply.started":"2022-05-19T21:25:29.401906Z","shell.execute_reply":"2022-05-19T21:25:29.617143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finally, we plot the calibration curve. ","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12, 4))\nCalibrationDisplay.from_predictions(y_va, y_va_pred, n_bins=100, strategy='quantile', ax=plt.gca())\nplt.title('Probability calibration')\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-19T21:25:29.620604Z","iopub.execute_input":"2022-05-19T21:25:29.621225Z","iopub.status.idle":"2022-05-19T21:25:29.865437Z","shell.execute_reply.started":"2022-05-19T21:25:29.621121Z","shell.execute_reply":"2022-05-19T21:25:29.864363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission\n\nFor the submission, we re-train the model on the complete training data with several different seeds and then submit the mean of the predicted ranks. We set `n_estimators` to the number of iterations which gave the best auc in cross-validation.","metadata":{}},{"cell_type":"code","source":"%%time\n# Create submission\nprint(f\"{len(features)} features\")\nnp.set_printoptions(precision=4)\n\nX_tr = train[features]\ny_tr = train.target\n\npred_list = []\nfor seed in range(10):\n    model = my_booster(random_state=seed, n_estimators=auc_peak)\n    model.fit(X_tr.values, y_tr)\n    pred_list.append( (model.predict_proba(test[features].values)[:,1]))\n    print(f\"{seed:2}\", pred_list[-1])\nprint()\nsubmission = test[['id']].copy()\nsubmission['target'] = np.array(pred_list).mean(axis=0)\nsubmission.to_csv('submission.csv', index=False)\nsubmission","metadata":{"execution":{"iopub.status.busy":"2022-05-19T21:25:29.866595Z","iopub.execute_input":"2022-05-19T21:25:29.866839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# What next?\n\nNow it's your turn! Try to improve this model by\n- Engineering more features\n- Tuning hyperparameters\n- Replacing LightGBM by XGBoost, HistGradientBoostingClassifier or CatBoost \n\nOr, if you prefer neural networks, have a look at the [Advanced Keras Model](https://www.kaggle.com/ambrosm/tpsmay22-advanced-keras).\n","metadata":{}}]}