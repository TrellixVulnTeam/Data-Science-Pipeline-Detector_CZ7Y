{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%matplotlib inline\nimport os, optuna\nimport numpy as np\nimport pandas as pd\nfrom pandas.api.types import CategoricalDtype\nfrom pandas_profiling import ProfileReport\n\nfrom sklearn.preprocessing import OrdinalEncoder, MinMaxScaler\nfrom sklearn.model_selection import cross_val_score, KFold\nfrom sklearn.feature_selection import mutual_info_classif\nfrom category_encoders import MEstimateEncoder\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import classification_report\n\nfrom catboost import CatBoostRegressor, CatBoostClassifier\n\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n\nplt.style.use(\"seaborn-whitegrid\")\nplt.rc(\"figure\", autolayout=True)\nplt.rc(\n    \"axes\",\n    labelweight=\"bold\",\n    labelsize=\"large\",\n    titleweight=\"bold\",\n    titlesize=14,\n    titlepad=10,\n)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-05-09T19:28:20.178095Z","iopub.execute_input":"2022-05-09T19:28:20.178431Z","iopub.status.idle":"2022-05-09T19:28:24.754514Z","shell.execute_reply.started":"2022-05-09T19:28:20.178343Z","shell.execute_reply":"2022-05-09T19:28:24.753647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Read in the Data and do Exploratory Data Analysis \n- look at the nature of the target variable\n- look at the other variables for any distribution skews, missing data, data types (i.e. numerical, categorical, etc.)\n- See if there are variable problems like high caridnality in the categorical data or different scales for the numerical data (i.e. values ranging from 0-1, 1-100, etc.)\n- look at any correlations present","metadata":{"tags":[]}},{"cell_type":"code","source":"df = pd.read_csv(\"../input/tabular-playground-series-may-2022/train.csv\")\ndf = df.set_index('id')","metadata":{"execution":{"iopub.status.busy":"2022-05-09T19:28:24.756383Z","iopub.execute_input":"2022-05-09T19:28:24.756644Z","iopub.status.idle":"2022-05-09T19:28:33.659737Z","shell.execute_reply.started":"2022-05-09T19:28:24.756612Z","shell.execute_reply":"2022-05-09T19:28:33.658804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-09T19:28:33.661059Z","iopub.execute_input":"2022-05-09T19:28:33.661301Z","iopub.status.idle":"2022-05-09T19:28:33.696174Z","shell.execute_reply.started":"2022-05-09T19:28:33.661273Z","shell.execute_reply":"2022-05-09T19:28:33.69533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2022-05-09T19:28:33.697875Z","iopub.execute_input":"2022-05-09T19:28:33.698358Z","iopub.status.idle":"2022-05-09T19:28:33.887673Z","shell.execute_reply.started":"2022-05-09T19:28:33.698307Z","shell.execute_reply":"2022-05-09T19:28:33.886737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Se if there is any target imbalabnce\nnp.unique(df['target'], return_counts=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T19:28:33.889352Z","iopub.execute_input":"2022-05-09T19:28:33.889594Z","iopub.status.idle":"2022-05-09T19:28:33.923072Z","shell.execute_reply.started":"2022-05-09T19:28:33.889566Z","shell.execute_reply":"2022-05-09T19:28:33.922161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For the binary target variable, the numbers of each label are very close with their bing a few more 1's than 0's","metadata":{}},{"cell_type":"code","source":"ProfileReport(df)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Mix of numerical and catgeorical variables. It looks like some variables could either be interger values or categorical as well (7-18). The numerical variables all look to be roughly Gaussian with different means and slightly different standard deviations. f28, f29, and f30 look to have some correlations with different groupings of the numerical variables. f_27 has extremely high cardinality (around 80% unique). No missing data. ","metadata":{}},{"cell_type":"markdown","source":"# 2. Read in and Process the Data\n- Do any preprocessing neccesary, to include encoding catgeoricals","metadata":{"tags":[]}},{"cell_type":"code","source":"# Some helper functions for different types of encodings of categorical data\n\ndef label_encode(df):\n    X = df.copy()\n    for colname in X.select_dtypes([\"category\"]):\n        X[colname] = X[colname].cat.codes\n    return X\n\ndef one_hot_encode(df):\n    X = df.copy()\n    for colname in X.select_dtypes([\"category\", \"object\"]):\n        X = X.join(pd.get_dummies(X[colname], prefix=colname))\n        X = X.drop(colname, axis=1)\n    return X","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# categorical feature encoding\n\ndef encode(df):\n    # Nominal categories\n    for name in features_nom:\n        df[name] = df[name].astype(\"category\")\n        # Add a None category for missing values\n        if \"None\" not in df[name].cat.categories:\n            df[name].cat.add_categories(\"None\", inplace=True)\n    # Ordinal categories\n    for name, levels in ordered_levels.items():\n        df[name] = df[name].astype(CategoricalDtype(levels,\n                                                    ordered=True))\n    return df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Wrapper function to read in, encode and impute missing values for the data\n\ndef load_data():\n    df_train = pd.read_csv(\"../input/tabular-playground-series-may-2022/train.csv\", index_col=\"id\")\n    df_test = pd.read_csv(\"../input/tabular-playground-series-may-2022/test.csv\", index_col=\"id\")\n    # Merge the splits so we can process them together\n    df = pd.concat([df_train, df_test])\n    # Preprocessing\n    df = encode(df)\n    # Reform splits\n    df_train = df.loc[df_train.index, :]\n    df_test = df.loc[df_test.index, :]\n    return df_train, df_test","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Specify Categoricals\n\nfeatures_nom = [\n    'f_07', 'f_08', 'f_09', 'f_10', 'f_11', 'f_12', 'f_13', \n    'f_14', 'f_15', 'f_16', 'f_17',\n    'f_18','f_27', 'f_29', 'f_30', 'target'\n]\n\nordered_levels = {}\n\n# Add a None level for missing values\nordered_levels = {key: [\"None\"] + value for key, value in\n                  ordered_levels.items()}\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train, df_test = load_data()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Establish a baseline","metadata":{}},{"cell_type":"code","source":"def score_dataset(X, y, model=CatBoostClassifier(iterations=200, task_type=\"GPU\", devices='0', silent=True), \n                  l_encode=True):\n    # Label encoding for categoricals\n    if l_encode:\n        X = label_encode(X)\n    else:\n        X = one_hot_encode(X)\n        \n    y = y.cat.codes\n    \n    score = cross_val_score(\n        model, X, y, cv=5, scoring='f1'\n    )\n    \n    return score.mean()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df_train.copy()\ny = X.pop('target')\n\nscore_dataset(X, y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Feature Engineering\nFor this section, I will try out a couple of engineered features to see if I can get better performance from a model. Inn particular, I'll try:\n- removing uninformative features\n- mathematical transforms\n- binning, or clustering","metadata":{"tags":[]}},{"cell_type":"code","source":"def make_mi_scores(X, y):\n    X = X.copy()\n    for colname in X.select_dtypes([\"object\", \"category\"]):\n        X[colname], _ = X[colname].factorize()\n    # All discrete features should now have integer dtypes\n    discrete_features = [pd.api.types.is_integer_dtype(t) for t in X.dtypes]\n    y= y.cat.codes\n    mi_scores = mutual_info_classif(X, y, discrete_features=discrete_features, random_state=0)\n    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n    mi_scores = mi_scores.sort_values(ascending=False)\n    return mi_scores","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df_train.copy()\ny = X.pop('target')\nmi_scores = make_mi_scores(X, y)\nmi_scores","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Try removing some of the uninformative features to see if that improves scores\nuninformative_features = mi_scores[-2:].index.tolist()\n\nX = df_train.copy()\ny = X.pop('target')\nX = X.loc[:,~X.columns.isin(uninformative_features)]\n\nscore_dataset(X, y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Removing low information features did not help the model","metadata":{}},{"cell_type":"markdown","source":"### 4(a) Evaluate Interactions\nSince the heart and soul of this competition is interactions, we want to invest some time in looking at all kinds of interactions\n- define functions for elementals of interactions\n- define a function that adds in all the interactions we want\n- gow through combinations of possible interactions and record the scores","metadata":{}},{"cell_type":"code","source":"def ratio_interaction(col_1, col_2):\n    diff = col_1-col_2\n    combine = col_1+col_2\n    return diff.abs() / combine\n\ndef levels_interaction(num_col, cat_col):\n    interaction_df = pd.get_dummies(cat_col.astype(\"category\"), prefix=cat_col.name).mul(num_col, axis=0)\n    interaction_df.columns = [i+\"_x_\"+num_col.name for i in interaction_df.columns]\n    return interaction_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_interactions(df):\n    interaction_df = pd.DataFrame(index=df.index)\n    # create ratio interactions\n    col_1 = ['f_22','f_00','f_03','f_03','f_22', 'f_00','f_05','f_20','f_01','f_21','f_22','f_00','f_20','f_01','f_06','f_05','f_25','f_00','f_01','f_00']\n    col_2 = ['f_26','f_01','f_28','f_05','f_23','f_21','f_21','f_24','f_05','f_22','f_28','f_26','f_25','f_22','f_28','f_23','f_28','f_24','f_02','f_28']\n    \n    for i,j in zip(col_1, col_2):\n        interaction_df[i+\"_\"+j+\"_ratio\"] = ratio_interaction(df[i], df[j])\n        \n    num_col = ['f_01','f_00_f_01_ratio','f_00_f_28_ratio','f_00_f_24_ratio','f_19','f_00_f_01_ratio','f_03','f_20_f_25_ratio','f_06_f_28_ratio','f_22_f_28_ratio',\n               'f_01_f_05_ratio','f_00_f_21_ratio','f_01_f_22_ratio','f_26','f_00_f_28_ratio','f_22_f_28_ratio','f_00_f_24_ratio','f_22_f_26_ratio',\n               'f_20_f_25_ratio','f_05_f_21_ratio']\n    cat_col = ['f_13','f_29','f_16','f_08','f_07','f_14','f_15','f_17','f_14','f_13','f_16','f_29','f_16','f_17','f_14','f_14','f_17','f_16','f_13','f_29']\n    \n    for_combo_df = interaction_df.copy()\n    for_combo_df = interaction_df.join(df)\n    for i,j in zip(num_col, cat_col):\n        interaction_df = interaction_df.join(levels_interaction(for_combo_df[i], for_combo_df[j]))\n        \n    return interaction_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loop through all the possible ratio interactions with all of the numerical columns\n\nnum_cols = ['f_00', 'f_01', 'f_02', 'f_03', 'f_04', 'f_05', 'f_06', 'f_19', 'f_20', 'f_21', 'f_22', 'f_23', 'f_24', 'f_25', 'f_26', 'f_28']\nresults = []\nfor i in range(len(num_cols)):\n    for j in range(i+1,len(num_cols)):\n        X = df_train.copy()\n        y = X.pop('target')\n        X[num_cols[i]+\"_\"+num_cols[j]+\"_ratio\"] = ratio_interaction(X[num_cols[i]], X[num_cols[j]])\n        score = score_dataset(X, y)\n        results.append({\"col_1\":num_cols[i], 'col_2':num_cols[j], 'score':score})\n\nresults_df = pd.DataFrame(results)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results_df.to_csv(\"numerical_ratio_results.csv\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results_df.sort_values(\"score\", ascending=False)[0:20]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It looks like roughly the first 20 ratio style interactions improve the results. Let's add them to our data and now consider interactions between numerical and categorical data","metadata":{}},{"cell_type":"code","source":"# Loop through all the possible num-cat interactions with all of the numerical columns (including ratios) and categorical columns\n\nnum_cols = ['f_00', 'f_01', 'f_02', 'f_03', 'f_04', 'f_05', 'f_06', 'f_19', 'f_20', 'f_21', 'f_22', 'f_23', 'f_24', 'f_25', 'f_26', 'f_28',\n           'f_22_f_26_ratio', 'f_00_f_01_ratio','f_03_f_28_ratio', 'f_03_f_05_ratio', 'f_22_f_23_ratio','f_00_f_21_ratio', 'f_05_f_21_ratio', 'f_20_f_24_ratio',\n            'f_01_f_05_ratio', 'f_21_f_22_ratio', 'f_22_f_28_ratio','f_00_f_26_ratio', 'f_20_f_25_ratio', 'f_01_f_22_ratio','f_06_f_28_ratio', 'f_05_f_23_ratio', \n            'f_25_f_28_ratio','f_00_f_24_ratio', 'f_01_f_02_ratio', 'f_00_f_28_ratio'\n           ]\ncat_cols = ['f_07', 'f_08', 'f_09', 'f_10', 'f_11', 'f_12', 'f_13', 'f_14', 'f_15', 'f_16', 'f_17',\n            'f_18', 'f_29', 'f_30']\n\nresults = []\nfor i in range(len(num_cols)):\n    for j in range(len(cat_cols)):\n        X = df_train.copy()\n        y = X.pop('target')\n        X = X.join(create_interactions(X))\n        X = X.join(levels_interaction(X[num_cols[i]], X[cat_cols[j]]))\n        score = score_dataset(X, y)\n        results.append({\"num_col\":num_cols[i], 'cat_col':cat_cols[j], 'score':score})\n\nresults_df = pd.DataFrame(results)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results_df.to_csv(\"nnumerical_categorical_interaction_results.csv\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results_df.sort_values(\"score\", ascending=False)[0:20]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Once again, basically the first 20 seem to help a little","metadata":{}},{"cell_type":"code","source":"# Evaluate results with interactions\nX = df_train.copy()\ny = X.pop('target')\nX = X.join(create_interactions(X))\n\nscore_dataset(X, y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We are able to get some slight improvement with the new interaction features. We will probably need to investigate this area more. Finally, lets see if any of the features no longer help, post creating interactions","metadata":{}},{"cell_type":"code","source":"X = df_train.copy()\ny = X.pop('target')\nX = X.join(create_interactions(X))\nmi_scores = make_mi_scores(X, y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mi_scores[-103:]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Try removing some of the uninformative features to see if that improves scores\nuninformative_features = mi_scores[-103:].index.tolist()\n\nX = df_train.copy()\ny = X.pop('target')\nX = X.loc[:,~X.columns.isin(uninformative_features)]\n\nscore_dataset(X, y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Removing the uniformative features still reduces performance","metadata":{}},{"cell_type":"markdown","source":"### 4(b) Binning Variables\nNow, Lets try some clustering some variables to see if the resulting binned variable get any better results.\n- define some functions to create cluster labels and cluster distances\n- create some possible groups of features that might make good cluster features","metadata":{}},{"cell_type":"code","source":"def cluster_labels(df, features, n_clusters=10):\n    X = df.copy()\n    X_scaled = X.loc[:, features]\n    X_scaled = one_hot_encode(X_scaled)\n    X_scaled = (X_scaled - X_scaled.mean(axis=0)) / (X_scaled.std(axis=0)+0.000001)\n    kmeans = KMeans(n_clusters=n_clusters, n_init=50)\n    X_new = pd.DataFrame(index=X.index)\n    X_new[\"Cluster\"] = kmeans.fit_predict(X_scaled)\n    X_new[\"Cluster\"] = X_new[\"Cluster\"].astype(\"category\")\n    return X_new\n\n\ndef cluster_distance(df, features, n_clusters=10):\n    X = df.copy()\n    X_scaled = X.loc[:, features]\n    X_scaled = one_hot_encode(X_scaled)\n    X_scaled = (X_scaled - X_scaled.mean(axis=0)) / (X_scaled.std(axis=0)+0.000001)\n    kmeans = KMeans(n_clusters=n_clusters, n_init=50)\n    X_cd = kmeans.fit_transform(X_scaled)\n    # Label features and join to dataset\n    X_cd = pd.DataFrame(\n        X_cd, columns=[f\"Centroid_{i}\" for i in range(X_cd.shape[1])], index=X.index\n    )\n    return X_cd","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Try some clusters based on observed correlations\n\nvariables_1 = [\n    'f_28', 'f_00', 'f_01', 'f_02', 'f_03', 'f_04', 'f_05', 'f_06', 'f_07'\n]\n\nvariables_2 = [\n    'f_30','f_19', 'f_20', 'f_21', 'f_22', 'f_23', 'f_24', 'f_25', 'f_26'\n]\n\nvariables_3 = [\n    'f_29','f_07', 'f_08','f_09', 'f_10', 'f_11', 'f_12', 'f_13', 'f_14', 'f_15', 'f_16', 'f_17','f_18'\n]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"First set of variables","metadata":{}},{"cell_type":"code","source":"X = df_train.copy()\ny = X.pop('target')\nX = X.join(cluster_distance(X, variables_1, n_clusters=20))\n\nscore_dataset(X, y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df_train.copy()\ny = X.pop('target')\nX = X.join(cluster_labels(X, variables_1, n_clusters=20))\n\nscore_dataset(X, y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Second set of variables","metadata":{}},{"cell_type":"code","source":"X = df_train.copy()\ny = X.pop('target')\nX = X.join(cluster_distance(X, variables_2, n_clusters=20))\n\nscore_dataset(X, y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df_train.copy()\ny = X.pop('target')\nX = X.join(cluster_labels(X, variables_2, n_clusters=20))\n\nscore_dataset(X, y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Third set of variables","metadata":{}},{"cell_type":"code","source":"X = df_train.copy()\ny = X.pop('target')\nX = X.join(cluster_distance(X, variables_3, n_clusters=20))\n\nscore_dataset(X, y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df_train.copy()\ny = X.pop('target')\nX = X.join(cluster_labels(X, variables_3, n_clusters=20))\n\nscore_dataset(X, y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The clusters really don't seem to help much at all. I'll leave them out for now and revisit better possible binnings","metadata":{}},{"cell_type":"markdown","source":"# 5. Combine any engineered features together and check model performance\n- define a function to add in all the features to a data set\n- define a class to use cross-fold validation with target encoding\n- try some target encoding for better performance?\n- check model performance","metadata":{}},{"cell_type":"code","source":"class CrossFoldEncoder:\n    def __init__(self, encoder, **kwargs):\n        self.encoder_ = encoder\n        self.kwargs_ = kwargs  # keyword arguments for the encoder\n        self.cv_ = KFold(n_splits=5)\n\n    # Fit an encoder on one split and transform the feature on the\n    # other. Iterating over the splits in all folds gives a complete\n    # transformation. We also now have one trained encoder on each\n    # fold.\n    def fit_transform(self, X, y, cols):\n        self.fitted_encoders_ = []\n        self.cols_ = cols\n        X_encoded = []\n        for idx_encode, idx_train in self.cv_.split(X):\n            fitted_encoder = self.encoder_(cols=cols, **self.kwargs_)\n            fitted_encoder.fit(\n                X.iloc[idx_encode, :], y.iloc[idx_encode],\n            )\n            X_encoded.append(fitted_encoder.transform(X.iloc[idx_train, :])[cols])\n            self.fitted_encoders_.append(fitted_encoder)\n        X_encoded = pd.concat(X_encoded)\n        X_encoded.columns = [name + \"_encoded\" for name in X_encoded.columns]\n        return X_encoded\n\n    # To transform the test data, average the encodings learned from\n    # each fold.\n    def transform(self, X):\n        from functools import reduce\n\n        X_encoded_list = []\n        for fitted_encoder in self.fitted_encoders_:\n            X_encoded = fitted_encoder.transform(X)\n            X_encoded_list.append(X_encoded[self.cols_])\n        X_encoded = reduce(\n            lambda x, y: x.add(y, fill_value=0), X_encoded_list\n        ) / len(X_encoded_list)\n        X_encoded.columns = [name + \"_encoded\" for name in X_encoded.columns]\n        return X_encoded","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_features(df, df_test=None):\n    X = df.copy()\n    y = X.pop('target')\n    y = y.cat.codes\n    \n    if df_test is not None:\n        X_test = df_test.copy()\n        X = pd.concat([X, X_test])\n        \n        \n    # Add in engineered features\n    X = label_encode(X)\n    X = X.join(create_interactions(X))\n\n    # Reform splits\n    if df_test is not None:\n        X_test = X.loc[df_test.index, :]\n        X.drop(df_test.index, inplace=True)\n    '''\n    # Target Encoder\n    encoder = CrossFoldEncoder(MEstimateEncoder, m=1)\n    cols_to_target_encode = [\"f_27\"]\n    X = X.join(encoder.fit_transform(X, y, cols=cols_to_target_encode))\n    X = X.loc[:,~X.columns.isin(cols_to_target_encode)]\n    if df_test is not None:\n        X_test = X_test.join(encoder.transform(X_test))\n        X_test = X_test.loc[:,~X_test.columns.isin(cols_to_target_encode)]\n    '''\n\n    if df_test is not None:\n        return X, X_test\n    else:\n        return X","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = create_features(df_train)\ny_train = df_train.loc[:, 'target']\n\nscore_dataset(X_train, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Interestingly, trying to target encode the high-cardinality f_27 variable really did not help performance.","metadata":{}},{"cell_type":"markdown","source":"# 6. Tune hyperparameters\n- define an optuna study function, with associated parameter space, to find optimal hyperparameters for our model\n- run the optuna study and visualize results","metadata":{}},{"cell_type":"code","source":"def objective(trial):\n    cat_params = dict(\n        iterations = 1000,\n        task_type=\"GPU\", \n        devices='0',  \n        silent=True,\n        depth=trial.suggest_int(\"depth\", 2, 16),\n        learning_rate=trial.suggest_float(\"learning_rate\", 0.01, 0.9, log=True),\n        random_strength=trial.suggest_int('random_strength', 0, 100),\n        l2_leaf_reg=trial.suggest_float(\"l2_leaf_reg\", 1e-4, 1e2, log=True),\n        bootstrap_type = trial.suggest_categorical(\"bootstrap_type\", [\"Bayesian\", \"Bernoulli\", \"MVS\"]),\n        boosting_type = trial.suggest_categorical(\"boosting_type\", [\"Ordered\", \"Plain\"]),\n        od_type = trial.suggest_categorical('od_type', ['IncToDec', 'Iter'])\n    )\n    \n    if cat_params[\"bootstrap_type\"] == \"Bayesian\":\n        cat_params[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0, 10)\n    elif cat_params[\"bootstrap_type\"] == \"Bernoulli\":\n        cat_params[\"subsample\"] = trial.suggest_float(\"subsample\", 0.1, 1)\n    \n    cat_boost = CatBoostClassifier(**cat_params)\n    return score_dataset(X_train, y_train, cat_boost)\n\nstudy = optuna.create_study(direction=\"maximize\")\nstudy.optimize(objective, n_trials=20)\ncat_params = study.best_params","metadata":{"scrolled":true,"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optuna.visualization.plot_optimization_history(study)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(cat_params)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I found the best catboost hyperparamters to be the following (with cross validation F1 score around 0.8789):\n\n```python\ncat_params = {'depth': 8, 'learning_rate': 0.32859826626165944, 'random_strength': 75, 'l2_leaf_reg': 0.2664027110002379, 'bootstrap_type': 'Bernoulli', 'boosting_type': 'Ordered', 'od_type': 'IncToDec', 'subsample': 0.8982887767077825}.\n```","metadata":{}},{"cell_type":"markdown","source":"## 6. Fit the final model and submit Predictions\n- do the final model fit\n- place predictions in the submissions format\n- check training predictions with the actual results as a sanity check","metadata":{"tags":[]}},{"cell_type":"code","source":"X_train, X_test = create_features(df_train, df_test)\ny_train = df_train.loc[:, 'target']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Train the final model on all of the available data\n\nX_train, X_test = create_features(df_train, df_test)\ny_train = df_train.loc[:, 'target'].cat.codes\n\nfinal_model = CatBoostClassifier(iterations = 1000, task_type=\"GPU\", devices='0', silent=True,**cat_params)\nfinal_model.fit(X_train, y_train)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Take a look at model performance\n\nprint(classification_report(y_train, final_model.predict(X_train)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get out final predictions.\n\npredictions = final_model.predict(X_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save predictions for submission\n\noutput = pd.DataFrame({'id': X_test.index, 'target': predictions})\noutput.to_csv('submission.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}