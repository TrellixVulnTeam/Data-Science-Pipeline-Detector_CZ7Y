{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-30T19:55:41.263218Z","iopub.execute_input":"2022-05-30T19:55:41.263927Z","iopub.status.idle":"2022-05-30T19:55:41.268433Z","shell.execute_reply.started":"2022-05-30T19:55:41.263888Z","shell.execute_reply":"2022-05-30T19:55:41.267363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/tabular-playground-series-may-2022/train.csv')\ntest = pd.read_csv('../input/tabular-playground-series-may-2022/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-05-30T19:55:41.301366Z","iopub.execute_input":"2022-05-30T19:55:41.301689Z","iopub.status.idle":"2022-05-30T19:55:48.920376Z","shell.execute_reply.started":"2022-05-30T19:55:41.30166Z","shell.execute_reply":"2022-05-30T19:55:48.919478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import KFold\n\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import TensorDataset\nimport torch.optim as optim\n\nimport matplotlib.pyplot as plt\n\n!pip install -q torchviz\nfrom torchviz import make_dot\n\nimport random\nimport scipy","metadata":{"execution":{"iopub.status.busy":"2022-05-30T19:55:48.922125Z","iopub.execute_input":"2022-05-30T19:55:48.922483Z","iopub.status.idle":"2022-05-30T19:55:58.29712Z","shell.execute_reply.started":"2022-05-30T19:55:48.922448Z","shell.execute_reply":"2022-05-30T19:55:58.29602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for df in [train, test]:\n    # Extract the 10 letters of f_27 into individual features\n    for i in range(10):\n        df[f'ch{i}'] = df.f_27.str.get(i).apply(ord) - ord('A')\n        \n    # unique_characters feature is from https://www.kaggle.com/code/cabaxiom/tps-may-22-eda-lgbm-model\n    df[\"unique_characters\"] = df.f_27.apply(lambda s: len(set(s)))\n    \n    # Feature interactions: create three ternary features\n    # Every ternary feature can have the values -1, 0 and +1\n    df['i_02_21'] = (df.f_21 + df.f_02 > 5.2).astype(int) - (df.f_21 + df.f_02 < -5.3).astype(int)\n    df['i_05_22'] = (df.f_22 + df.f_05 > 5.1).astype(int) - (df.f_22 + df.f_05 < -5.4).astype(int)\n    i_00_01_26 = df.f_00 + df.f_01 + df.f_26\n    df['i_00_01_26'] = (i_00_01_26 > 5.0).astype(int) - (i_00_01_26 < -5.0).astype(int)\n\ny = train.target.values\ntrain = train.drop(['f_27', 'target'], axis = 1)\ntest = test.drop('f_27', axis = 1)\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-30T19:55:58.298781Z","iopub.execute_input":"2022-05-30T19:55:58.300356Z","iopub.status.idle":"2022-05-30T19:56:17.511975Z","shell.execute_reply.started":"2022-05-30T19:55:58.300311Z","shell.execute_reply":"2022-05-30T19:56:17.51096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = StandardScaler()\ntrain = scaler.fit_transform(train)\ntest = scaler.transform(test)","metadata":{"execution":{"iopub.status.busy":"2022-05-30T19:56:17.514562Z","iopub.execute_input":"2022-05-30T19:56:17.514989Z","iopub.status.idle":"2022-05-30T19:56:18.457754Z","shell.execute_reply.started":"2022-05-30T19:56:17.514948Z","shell.execute_reply":"2022-05-30T19:56:18.45688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Definition of a DNN Model class\nclass DNN(nn.Module):\n    def __init__(self, input_size, output_size=1):\n        super(DNN, self).__init__()\n        \n        \n        # Fully Connected Layer\n        self.layers = nn.Sequential(nn.Linear(input_size, 64),\n                                nn.SiLU(),\n                                nn.Linear(64, 64),\n                                nn.SiLU(),\n                                nn.Linear(64, 64),\n                                nn.SiLU(),\n                                nn.Linear(64, 64),\n                                nn.SiLU(),\n                                nn.Linear(64, 16),\n                                nn.SiLU(),\n                                nn.Linear(16, output_size),\n                                nn.Sigmoid()\n                               )\n        \n    def forward(self, x):\n        x = x.reshape(x.shape[0], -1)\n        x = self.layers(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-05-30T19:58:44.821442Z","iopub.execute_input":"2022-05-30T19:58:44.821832Z","iopub.status.idle":"2022-05-30T19:58:44.82951Z","shell.execute_reply.started":"2022-05-30T19:58:44.8218Z","shell.execute_reply":"2022-05-30T19:58:44.828434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_dnn_plot = DNN(train.shape[1])\nx_plot = torch.randn(1, train.shape[1])\ny_plot = model_dnn_plot(x_plot)\nmake_dot(y_plot.mean(), params=dict(model_dnn_plot.named_parameters()))","metadata":{"execution":{"iopub.status.busy":"2022-05-30T19:58:45.414699Z","iopub.execute_input":"2022-05-30T19:58:45.415534Z","iopub.status.idle":"2022-05-30T19:58:46.267054Z","shell.execute_reply.started":"2022-05-30T19:58:45.415492Z","shell.execute_reply":"2022-05-30T19:58:46.265937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Validation function\ndef validation(model, loader, criterion, device=\"cpu\"):\n    model.eval()\n    loss = 0\n    preds_all = torch.LongTensor()\n    labels_all = torch.LongTensor()\n    \n    with torch.no_grad():\n        for batch_x, labels in loader:\n            labels_all = torch.cat((labels_all, labels), dim=0)\n            batch_x, labels = batch_x.to(device), labels.to(device)\n            labels = labels.unsqueeze(1).float()\n            \n            output = model.forward(batch_x)\n            loss += criterion(output,labels).item()\n            preds_all = torch.cat((preds_all, output.to(\"cpu\")), dim=0)\n    total_loss = loss/len(loader)\n    auc_score = roc_auc_score(labels_all, preds_all)\n    return total_loss, auc_score","metadata":{"execution":{"iopub.status.busy":"2022-05-30T19:58:46.269263Z","iopub.execute_input":"2022-05-30T19:58:46.270348Z","iopub.status.idle":"2022-05-30T19:58:46.319611Z","shell.execute_reply.started":"2022-05-30T19:58:46.270299Z","shell.execute_reply":"2022-05-30T19:58:46.318815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training function\ndef train_model(model, trainloader, validloader, criterion, optimizer, \n                scheduler, epochs=20, device=\"cpu\", print_every=1):\n    model.to(device)\n    best_auc = 0\n    best_epoch = 0\n    \n    # to track the training loss as the model trains\n    train_losses = []\n    # to track the validation loss as the model trains\n    valid_losses = []\n    # to track the learning rates in each eporch\n    learning_rates = []\n    \n    for e in range(epochs):\n        model.train()\n        \n        for batch_x, labels in trainloader:\n            batch_x, labels = batch_x.to(device), labels.to(device)\n            labels = labels.unsqueeze(1).float()\n            \n            # Training \n            optimizer.zero_grad()\n            output = model.forward(batch_x)\n            loss = criterion(output, labels)\n            loss.backward()\n            optimizer.step()\n            scheduler.step()\n        # at the end of each epoch calculate loss and auc score:\n        model.eval()\n        train_loss, train_auc = validation(model, trainloader, criterion, device)\n        valid_loss, valid_auc = validation(model, validloader, criterion, device)\n        \n        #### record loss and learning rate\n        train_losses.append(train_loss)\n        valid_losses.append(valid_loss)\n        learning_rates.append(scheduler._last_lr)\n        \n        if valid_auc > best_auc:\n            best_auc = valid_auc\n            best_epoch = e\n            torch.save(model.state_dict(), \"best-state.pt\")\n        if e % print_every == 0:\n            to_print = \"Epoch: \"+str(e+1)+\" of \"+str(epochs)\n            to_print += \".. Train Loss: {:.4f}\".format(train_loss)\n            to_print += \".. Valid Loss: {:.4f}\".format(valid_loss)\n            to_print += \".. Valid AUC: {:.3f}\".format(valid_auc)\n            print(to_print)\n    # After Training:\n    model.load_state_dict(torch.load(\"best-state.pt\"))\n    to_print = \"\\nTraining completed. Best state dict is loaded.\\n\"\n    to_print += \"Best Valid AUC is: {:.4f} after {} epochs\".format(best_auc,best_epoch+1)\n    print(to_print)\n    return train_losses, valid_losses, learning_rates","metadata":{"execution":{"iopub.status.busy":"2022-05-30T19:58:46.978805Z","iopub.execute_input":"2022-05-30T19:58:46.97918Z","iopub.status.idle":"2022-05-30T19:58:46.991202Z","shell.execute_reply.started":"2022-05-30T19:58:46.979149Z","shell.execute_reply":"2022-05-30T19:58:46.990446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prediction function\ndef prediction(model, loader, device=\"cpu\"):\n    model.to(device)\n    model.eval()\n    preds_all = torch.LongTensor()\n    \n    with torch.no_grad():\n        for batch_x in loader:\n            batch_x = batch_x.to(device)\n            \n            output = model.forward(batch_x).to(\"cpu\")\n            preds_all = torch.cat((preds_all, output), dim=0)\n    return preds_all","metadata":{"execution":{"iopub.status.busy":"2022-05-30T19:58:47.725494Z","iopub.execute_input":"2022-05-30T19:58:47.725855Z","iopub.status.idle":"2022-05-30T19:58:47.731699Z","shell.execute_reply.started":"2022-05-30T19:58:47.725823Z","shell.execute_reply":"2022-05-30T19:58:47.730726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking if GPU is available\nif torch.cuda.is_available():\n    my_device = \"cuda\"\n    print(\"GPU is enabled\")\nelse:\n    my_device = \"cpu\"\n    print(\"No GPU :(\")","metadata":{"execution":{"iopub.status.busy":"2022-05-30T19:58:49.274614Z","iopub.execute_input":"2022-05-30T19:58:49.275473Z","iopub.status.idle":"2022-05-30T19:58:49.328026Z","shell.execute_reply.started":"2022-05-30T19:58:49.275436Z","shell.execute_reply":"2022-05-30T19:58:49.327141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_size = train.shape[1]\ntest_tensor = torch.tensor(test).float()\ntest_DL = DataLoader(test_tensor, batch_size=2048)","metadata":{"execution":{"iopub.status.busy":"2022-05-30T19:58:51.223397Z","iopub.execute_input":"2022-05-30T19:58:51.224105Z","iopub.status.idle":"2022-05-30T19:58:51.48542Z","shell.execute_reply.started":"2022-05-30T19:58:51.224043Z","shell.execute_reply":"2022-05-30T19:58:51.484578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time \n# K-Fold Cross Validation\nmax_learning_rate = 0.01\nepochs = 30\npred_list = []\n\nkf = KFold(n_splits=5)\nfor fold, (idx_tr, idx_va) in enumerate(kf.split(train)):\n    print(f\"** fold: {fold+1} ** ........training ...... \\n\")\n    \n    # Initialize Model\n    model_dnn = DNN(input_size)\n    \n    # Prepare Data\n    X_train, X_valid = train[idx_tr], train[idx_va]\n    y_train, y_valid = y[idx_tr], y[idx_va]\n    \n    ## Converting train and validation labels into tensors\n    X_train_tensor = torch.tensor(X_train).float()\n    X_valid_tensor = torch.tensor(X_valid).float()\n    y_train_tensor = torch.tensor(y_train)\n    y_valid_tensor = torch.tensor(y_valid)\n\n    ## Creating train and validation tensors\n    train_DS = TensorDataset(X_train_tensor, y_train_tensor)\n    valid_DS = TensorDataset(X_valid_tensor, y_valid_tensor)\n\n    ## Defining the dataloaders\n    train_DL = DataLoader(train_DS, batch_size=2048, shuffle=True)\n    valid_DL = DataLoader(valid_DS, batch_size=2048)\n    \n    # criterion, optimizer, scheduler\n    criterion = nn.BCELoss()\n    optimizer = optim.Adam(model_dnn.parameters(), lr=max_learning_rate, weight_decay=1e-4)\n    scheduler = optim.lr_scheduler.OneCycleLR(optimizer,\n                                              max_lr = max_learning_rate,\n                                              epochs = epochs,\n                                              steps_per_epoch = len(train_DL),\n                                              pct_start = 0.01,\n                                              anneal_strategy = \"cos\")\n    \n    # Training\n    train_losses, valid_losses, learning_rates = train_model(model = model_dnn,\n                                                 trainloader = train_DL,\n                                                 validloader = valid_DL,\n                                                 criterion = criterion,\n                                                 optimizer = optimizer,\n                                                 scheduler = scheduler,\n                                                 epochs = epochs,\n                                                 device = my_device,\n                                                 print_every = round(epochs/2)-1)\n#     break # test\n    model_dnn.load_state_dict(torch.load(\"best-state.pt\"))\n    pred_test = prediction(model_dnn, test_DL, device=my_device)\n    pred_list.append(pred_test.tolist())\n#     pred_test_rank = scipy.stats.rankdata(pred_test.tolist())\n#     pred_list.append(pred_test_rank)","metadata":{"execution":{"iopub.status.busy":"2022-05-30T19:58:52.396188Z","iopub.execute_input":"2022-05-30T19:58:52.396729Z","iopub.status.idle":"2022-05-30T20:35:07.044915Z","shell.execute_reply.started":"2022-05-30T19:58:52.39669Z","shell.execute_reply":"2022-05-30T20:35:07.044054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax1 = plt.subplots()\nax1.plot(range(epochs), train_losses, label='Train Loss')\nax1.plot(range(epochs), valid_losses, label='Valid Loss')\nax1.set_title('Learning Curve')\nax1.set_xlabel(\"Number of Epochs\")\nax1.set_ylabel(\"Loss\")\nax2 = ax1.twinx()\nax2.set_ylabel(\"Learning Rate\")\nax2.plot(range(epochs), learning_rates, label='Learning Rate', color='g')\nfig.legend(loc=\"upper right\", bbox_to_anchor=(1,1), bbox_transform=ax1.transAxes)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-30T20:35:07.046654Z","iopub.execute_input":"2022-05-30T20:35:07.047293Z","iopub.status.idle":"2022-05-30T20:35:07.349467Z","shell.execute_reply.started":"2022-05-30T20:35:07.047252Z","shell.execute_reply":"2022-05-30T20:35:07.348657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(\"/kaggle/input/tabular-playground-series-may-2022/sample_submission.csv\")\nsubmission['target'] = np.array(pred_list).mean(axis=0)\nsubmission.to_csv('submission.csv', index=False)\nsubmission","metadata":{"execution":{"iopub.status.busy":"2022-05-30T20:35:07.350802Z","iopub.execute_input":"2022-05-30T20:35:07.351361Z","iopub.status.idle":"2022-05-30T20:35:12.540598Z","shell.execute_reply.started":"2022-05-30T20:35:07.351324Z","shell.execute_reply":"2022-05-30T20:35:12.539585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}