{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom IPython.display import display\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom IPython.display import display\nimport matplotlib.pyplot as plt\n\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import RobustScaler\n#from sklearn.model_selection import train_test_split\n#from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n#from sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import roc_auc_score\nfrom xgboost import XGBRegressor\nimport lightgbm as lgb\nfrom catboost import CatBoostClassifier\n#from sklearn.linear_model import LinearRegression\nimport optuna\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check on the panda version and its dependencies\n# i run this from time to time to ensure all is up to date\npd.__version__\n#pd.show_versions()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# kfolds-5/train_folds_5.csv is an output from https://www.kaggle.com/code/andrewnuk/kfolds-5\n\ndf_train = pd.read_csv('/kaggle/input/kfolds-5/train_folds_5.csv')\ndf_test = pd.read_csv('/kaggle/input/tabular-playground-series-may-2022/test.csv')\ndf_sampleSubmission = pd.read_csv('/kaggle/input/tabular-playground-series-may-2022/sample_submission.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# detect number of folds\nfold_no = df_train['kfolds'].max() +1\nfold_no","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# looking at f_27","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# all strings in f_27 are length 10 in train and test data\n\n# df_train['f_27_len'] = df_train['f_27'].astype(str).map(len)\n# df_test['f_27_len'] = df_test['f_27'].astype(str).map(len)\n# df_train['f_27_len'].unique().tolist(), df_test['f_27_len'].unique().tolist()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# label encode\n\nf27_col_list = []\nfor i in range(1,11):\n    df_train['f_27_' + str(i)] = df_train['f_27'].str.split('',expand=True)[i]\n    df_test['f_27_' + str(i)] = df_test['f_27'].str.split('',expand=True)[i]\n    f27_col_list.append('f_27_' + str(i))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f27_col_list","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in f27_col_list:\n    df_train[col] = LabelEncoder().fit_transform(df_train[col])\n    df_test[col] = LabelEncoder().fit_transform(df_test[col])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unique_f27=[]\nunique_f27_test=[]\n\n\nfor item in df_train['f_27']:\n    unique_f27.append(len(set(item)))\n    \nfor item in df_test['f_27']:\n    unique_f27_test.append(len(set(item)))\n    \n\ndf_train['unique_f27'] = unique_f27\ndf_test['unique_f27'] = unique_f27_test","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# more label encoding of f_29 and f_30\n\ndf_train['f_30_0'] = np.where(df_train['f_30'] == 0, 1, 0)\ndf_train['f_30_1'] = np.where(df_train['f_30'] == 1, 1, 0) \ndf_train['f_30_2'] = np.where(df_train['f_30'] == 2, 1, 0) \ndf_test['f_30_0'] = np.where(df_test['f_30'] == 0, 1, 0)\ndf_test['f_30_1'] = np.where(df_test['f_30'] == 1, 1, 0) \ndf_test['f_30_2'] = np.where(df_test['f_30'] == 2, 1, 0) \n\ndf_train['f_29_0'] = np.where(df_train['f_29'] == 0, 1, 0)\ndf_train['f_29_1'] = np.where(df_train['f_29'] == 1, 1, 0) \ndf_test['f_29_0'] = np.where(df_test['f_29'] == 0, 1, 0)\ndf_test['f_29_1'] = np.where(df_test['f_29'] == 1, 1, 0) \n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f29_col_list=['f_29_0','f_29_1']\n\nfor col in f29_col_list:\n    df_train[col] = LabelEncoder().fit_transform(df_train[col])\n    df_test[col] = LabelEncoder().fit_transform(df_test[col])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f30_col_list=['f_30_0','f_30_1','f_30_2']\n\nfor col in f30_col_list:\n    df_train[col] = LabelEncoder().fit_transform(df_train[col])\n    df_test[col] = LabelEncoder().fit_transform(df_test[col])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"continuous_feat = ['f_00', 'f_01', 'f_02', 'f_03', 'f_04', 'f_05', 'f_06', 'f_19',\n                   'f_20', 'f_21', 'f_22', 'f_23', 'f_24', 'f_25', 'f_26', 'f_28']\n\ndef stat_features(df, cols = continuous_feat):\n    '''\n    Calculate aggregated features across the selected continuous columns\n    \n    '''\n    # Base statistical features.\n    df['f_sum']  = df[continuous_feat].sum(axis=1)\n    df['f_min']  = df[continuous_feat].min(axis=1)\n    df['f_max']  = df[continuous_feat].max(axis=1)\n    df['f_std']  = df[continuous_feat].std(axis=1)    \n    df['f_mad']  = df[continuous_feat].mad(axis=1)\n    df['f_mean'] = df[continuous_feat].mean(axis=1)\n    df['f_kurt'] = df[continuous_feat].kurt(axis=1)\n\n    # Extra statistical features.\n    df['f_prod'] = df[continuous_feat].prod(axis=1)\n    df['f_range'] = df[continuous_feat].max(axis=1) - df[continuous_feat].min(axis=1)\n    df['f_count_pos']  = df[df[continuous_feat].gt(0)].count(axis=1)\n    df['f_count_neg']  = df[df[continuous_feat].lt(0)].count(axis=1)\n\n    return df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = stat_features(df_train, continuous_feat)\ndf_test = stat_features(df_test, continuous_feat)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# rename the nominal columns\n# list of nominal columns will be where there are less than 20 unique numers\n\nnom_cols = []\n\nfor i in range(len(df_train.columns)):\n    if df_train[df_train.columns[i]].nunique() < 30:\n        nom_cols.append(df_train.columns[i])\n\n# remove 'target'\nnom_cols.remove('target')\nnom_cols.remove('kfolds')\n\nprint(nom_cols)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# put the rest of the columns in another list to scale\n# and remove f_27\n\nall_cols = df_train.columns.tolist()\n\nrest_cols = list(set(all_cols) - set(nom_cols))\nrest_cols.remove('target')\nrest_cols.remove('id')\nrest_cols.remove('kfolds')\nrest_cols.remove('f_27')\n\nprint(rest_cols)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# scale the non integer columns\n\nscaler = RobustScaler()\ndf_train[rest_cols] = scaler.fit_transform(df_train[rest_cols])\ndf_test[rest_cols] = scaler.transform(df_test[rest_cols]) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"useful_features = [c for c in all_cols if c not in ('id','target','kfolds','f_27','f_29','f_30')]\ndf_test = df_test[useful_features]\nprint(useful_features)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# taken from the hypertuning notebook https://www.kaggle.com/code/andrewnuk/hypertuning-xgb-cb-lgbm\n\nparams = {\n    'objective': 'binary:logistic',\n    'eval_metric': 'auc',\n    'tree_method': 'hist',\n    'use_label_encoder': False,\n    'n_estimators': 10000,\n    'learning_rate': 0.04663877705818151,\n    'reg_lambda': 0.0009264101732567401,\n    'reg_alpha': 0.0243021228407322,\n    'subsample': 0.45210345718351885,\n    'colsample_bytree': 0.9904612423331298,\n    'max_depth': 6}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_predictions = []\nfinal_valid_predictions = {}\nscores = []\n\nfor fold in range(fold_no):\n    xtrain =  df_train[df_train['kfolds'] != fold].reset_index(drop=True)\n    xvalid = df_train[df_train['kfolds'] == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n    \n    valid_ids = xvalid.id.values.tolist()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n#     ordinal_encoder = preprocessing.OrdinalEncoder()\n#     xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n#     xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n#     xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n    \n#     model = XGBRegressor(random_state=0, n_jobs=6) # i have 8 cores but want to keep 2 open\n    \n    model = XGBRegressor(random_state=0, n_jobs=-1, **params)\n       \n    model.fit(xtrain, ytrain, early_stopping_rounds=1000, eval_set=[(xvalid, yvalid)], verbose=1000)\n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_predictions.append(test_preds)\n    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n    #rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    roc = roc_auc_score(yvalid, preds_valid)\n    print(fold, roc)\n    scores.append(roc)\n\nprint(np.mean(scores), np.std(scores))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\nfinal_valid_predictions.columns = [\"id\", \"pred_1\"]\nfinal_valid_predictions.to_csv(\"train_pred_1_FE_20220524.csv\", index=False)\n\ndf_sampleSubmission.target = np.mean(np.column_stack(final_predictions), axis=1)\ndf_sampleSubmission.columns = [\"id\", \"pred_1\"]\ndf_sampleSubmission.to_csv(\"test_pred_1_FE_20220524.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# column_names = [\"id\", \"target\"]\n\n# # df_sampleSubmission.target = np.mean(np.column_stack(final_predictions), axis=1)\n# df_sampleSubmission.to_csv(\"submission20220524a.csv\", header=column_names, index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sampleSubmission.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# kfolds-5/train_folds_5.csv is an output from https://www.kaggle.com/code/andrewnuk/kfolds-5\n\ndf_train = pd.read_csv('/kaggle/input/kfolds-5/train_folds_5.csv')\ndf_test = pd.read_csv('/kaggle/input/tabular-playground-series-may-2022/test.csv')\ndf_sampleSubmission = pd.read_csv('/kaggle/input/tabular-playground-series-may-2022/sample_submission.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# label encode\n\nf27_col_list = []\nfor i in range(1,11):\n    df_train['f_27_' + str(i)] = df_train['f_27'].str.split('',expand=True)[i]\n    df_test['f_27_' + str(i)] = df_test['f_27'].str.split('',expand=True)[i]\n    f27_col_list.append('f_27_' + str(i))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f27_col_list","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in f27_col_list:\n    df_train[col] = LabelEncoder().fit_transform(df_train[col])\n    df_test[col] = LabelEncoder().fit_transform(df_test[col])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unique_f27=[]\nunique_f27_test=[]\n\n\nfor item in df_train['f_27']:\n    unique_f27.append(len(set(item)))\n    \nfor item in df_test['f_27']:\n    unique_f27_test.append(len(set(item)))\n    \n\ndf_train['unique_f27'] = unique_f27\ndf_test['unique_f27'] = unique_f27_test","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# more label encoding of f_29 and f_30\n\ndf_train['f_30_0'] = np.where(df_train['f_30'] == 0, 1, 0)\ndf_train['f_30_1'] = np.where(df_train['f_30'] == 1, 1, 0) \ndf_train['f_30_2'] = np.where(df_train['f_30'] == 2, 1, 0) \ndf_test['f_30_0'] = np.where(df_test['f_30'] == 0, 1, 0)\ndf_test['f_30_1'] = np.where(df_test['f_30'] == 1, 1, 0) \ndf_test['f_30_2'] = np.where(df_test['f_30'] == 2, 1, 0) \n\ndf_train['f_29_0'] = np.where(df_train['f_29'] == 0, 1, 0)\ndf_train['f_29_1'] = np.where(df_train['f_29'] == 1, 1, 0) \ndf_test['f_29_0'] = np.where(df_test['f_29'] == 0, 1, 0)\ndf_test['f_29_1'] = np.where(df_test['f_29'] == 1, 1, 0) \n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f29_col_list=['f_29_0','f_29_1']\n\nfor col in f29_col_list:\n    df_train[col] = LabelEncoder().fit_transform(df_train[col])\n    df_test[col] = LabelEncoder().fit_transform(df_test[col])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f30_col_list=['f_30_0','f_30_1','f_30_2']\n\nfor col in f30_col_list:\n    df_train[col] = LabelEncoder().fit_transform(df_train[col])\n    df_test[col] = LabelEncoder().fit_transform(df_test[col])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"continuous_feat = ['f_00', 'f_01', 'f_02', 'f_03', 'f_04', 'f_05', 'f_06', 'f_19',\n                   'f_20', 'f_21', 'f_22', 'f_23', 'f_24', 'f_25', 'f_26', 'f_28']\n\ndef stat_features(df, cols = continuous_feat):\n    '''\n    Calculate aggregated features across the selected continuous columns\n    \n    '''\n    # Base statistical features.\n    df['f_sum']  = df[continuous_feat].sum(axis=1)\n    df['f_min']  = df[continuous_feat].min(axis=1)\n    df['f_max']  = df[continuous_feat].max(axis=1)\n    df['f_std']  = df[continuous_feat].std(axis=1)    \n    df['f_mad']  = df[continuous_feat].mad(axis=1)\n    df['f_mean'] = df[continuous_feat].mean(axis=1)\n    df['f_kurt'] = df[continuous_feat].kurt(axis=1)\n\n    # Extra statistical features.\n    df['f_prod'] = df[continuous_feat].prod(axis=1)\n    df['f_range'] = df[continuous_feat].max(axis=1) - df[continuous_feat].min(axis=1)\n    df['f_count_pos']  = df[df[continuous_feat].gt(0)].count(axis=1)\n    df['f_count_neg']  = df[df[continuous_feat].lt(0)].count(axis=1)\n\n    return df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = stat_features(df_train, continuous_feat)\ndf_test = stat_features(df_test, continuous_feat)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# rename the nominal columns\n# list of nominal columns will be where there are less than 20 unique numers\n\nnom_cols = []\n\nfor i in range(len(df_train.columns)):\n    if df_train[df_train.columns[i]].nunique() < 30:\n        nom_cols.append(df_train.columns[i])\n\n# remove 'target'\nnom_cols.remove('target')\nnom_cols.remove('kfolds')\n\nprint(nom_cols)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# put the rest of the columns in another list to scale\n# and remove f_27\n\nall_cols = df_train.columns.tolist()\n\nrest_cols = list(set(all_cols) - set(nom_cols))\nrest_cols.remove('target')\nrest_cols.remove('id')\nrest_cols.remove('kfolds')\nrest_cols.remove('f_27')\n\nprint(rest_cols)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# scale the non integer columns\n\nscaler = RobustScaler()\ndf_train[rest_cols] = scaler.fit_transform(df_train[rest_cols])\ndf_test[rest_cols] = scaler.transform(df_test[rest_cols]) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"useful_features = [c for c in all_cols if c not in ('id','target','kfolds','f_27','f_29','f_30')]\ndf_test = df_test[useful_features]\nprint(useful_features)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# taken from the hypertuning notebook https://www.kaggle.com/code/andrewnuk/hypertuning-xgb-cb-lgbm\n\nparams_cb = {\n    'loss_function': 'CrossEntropy',\n    'eval_metric': 'AUC',\n    'bootstrap_type': 'Bernoulli',\n    'n_estimators': 10000,\n    'learning_rate': 0.21871589947723546,\n    'l2_leaf_reg': 3.89575022544331,\n    'min_data_in_leaf': 90,\n    'depth': 7,\n    'leaf_estimation_iterations': 8,\n    'subsample': 0.692447725389005}\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_predictions = []\nfinal_valid_predictions = {}\nscores = []\n\nfor fold in range(fold_no):\n    xtrain =  df_train[df_train['kfolds'] != fold].reset_index(drop=True)\n    xvalid = df_train[df_train['kfolds'] == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n    \n    valid_ids = xvalid.id.values.tolist()    \n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n#     ordinal_encoder = preprocessing.OrdinalEncoder()\n#     xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n#     xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n#     xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n    \n#     model = XGBRegressor(random_state=0, n_jobs=6) # i have 8 cores but want to keep 2 open\n    \n    model = CatBoostClassifier(random_state=0,  **params_cb)\n       \n    model.fit(xtrain, ytrain, early_stopping_rounds=1000, eval_set=[(xvalid, yvalid)], verbose=1000)\n    preds_valid = model.predict_proba(xvalid)[:, -1]\n    test_preds = model.predict_proba(xtest)[:, -1]\n    final_predictions.append(test_preds)\n    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))    \n    #rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    roc = roc_auc_score(yvalid, preds_valid)\n    print(fold, roc)\n    scores.append(roc)\n   \n    \nprint(np.mean(scores), np.std(scores))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\nfinal_valid_predictions.columns = [\"id\", \"pred_2\"]\nfinal_valid_predictions.to_csv(\"train_pred_2_FE_20220524.csv\", index=False)\n\ndf_sampleSubmission.target = np.mean(np.column_stack(final_predictions), axis=1)\ndf_sampleSubmission.columns = [\"id\", \"pred_2\"]\ndf_sampleSubmission.to_csv(\"test_pred_2_FE_20220524.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# column_names = [\"id\", \"target\"]\n\n# # df_sampleSubmission.target = np.mean(np.column_stack(final_predictions), axis=1)\n# df_sampleSubmission.to_csv(\"submission20220524b.csv\", header=column_names, index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sampleSubmission.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# kfolds-5/train_folds_5.csv is an output from https://www.kaggle.com/code/andrewnuk/kfolds-5\n\ndf_train = pd.read_csv('/kaggle/input/kfolds-5/train_folds_5.csv')\ndf_test = pd.read_csv('/kaggle/input/tabular-playground-series-may-2022/test.csv')\ndf_sampleSubmission = pd.read_csv('/kaggle/input/tabular-playground-series-may-2022/sample_submission.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# label encode\n\nf27_col_list = []\nfor i in range(1,11):\n    df_train['f_27_' + str(i)] = df_train['f_27'].str.split('',expand=True)[i]\n    df_test['f_27_' + str(i)] = df_test['f_27'].str.split('',expand=True)[i]\n    f27_col_list.append('f_27_' + str(i))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f27_col_list","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in f27_col_list:\n    df_train[col] = LabelEncoder().fit_transform(df_train[col])\n    df_test[col] = LabelEncoder().fit_transform(df_test[col])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unique_f27=[]\nunique_f27_test=[]\n\n\nfor item in df_train['f_27']:\n    unique_f27.append(len(set(item)))\n    \nfor item in df_test['f_27']:\n    unique_f27_test.append(len(set(item)))\n    \n\ndf_train['unique_f27'] = unique_f27\ndf_test['unique_f27'] = unique_f27_test","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# more label encoding of f_29 and f_30\n\ndf_train['f_30_0'] = np.where(df_train['f_30'] == 0, 1, 0)\ndf_train['f_30_1'] = np.where(df_train['f_30'] == 1, 1, 0) \ndf_train['f_30_2'] = np.where(df_train['f_30'] == 2, 1, 0) \ndf_test['f_30_0'] = np.where(df_test['f_30'] == 0, 1, 0)\ndf_test['f_30_1'] = np.where(df_test['f_30'] == 1, 1, 0) \ndf_test['f_30_2'] = np.where(df_test['f_30'] == 2, 1, 0) \n\ndf_train['f_29_0'] = np.where(df_train['f_29'] == 0, 1, 0)\ndf_train['f_29_1'] = np.where(df_train['f_29'] == 1, 1, 0) \ndf_test['f_29_0'] = np.where(df_test['f_29'] == 0, 1, 0)\ndf_test['f_29_1'] = np.where(df_test['f_29'] == 1, 1, 0) \n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f29_col_list=['f_29_0','f_29_1']\n\nfor col in f29_col_list:\n    df_train[col] = LabelEncoder().fit_transform(df_train[col])\n    df_test[col] = LabelEncoder().fit_transform(df_test[col])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f30_col_list=['f_30_0','f_30_1','f_30_2']\n\nfor col in f30_col_list:\n    df_train[col] = LabelEncoder().fit_transform(df_train[col])\n    df_test[col] = LabelEncoder().fit_transform(df_test[col])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"continuous_feat = ['f_00', 'f_01', 'f_02', 'f_03', 'f_04', 'f_05', 'f_06', 'f_19',\n                   'f_20', 'f_21', 'f_22', 'f_23', 'f_24', 'f_25', 'f_26', 'f_28']\n\ndef stat_features(df, cols = continuous_feat):\n    '''\n    Calculate aggregated features across the selected continuous columns\n    \n    '''\n    # Base statistical features.\n    df['f_sum']  = df[continuous_feat].sum(axis=1)\n    df['f_min']  = df[continuous_feat].min(axis=1)\n    df['f_max']  = df[continuous_feat].max(axis=1)\n    df['f_std']  = df[continuous_feat].std(axis=1)    \n    df['f_mad']  = df[continuous_feat].mad(axis=1)\n    df['f_mean'] = df[continuous_feat].mean(axis=1)\n    df['f_kurt'] = df[continuous_feat].kurt(axis=1)\n\n    # Extra statistical features.\n    df['f_prod'] = df[continuous_feat].prod(axis=1)\n    df['f_range'] = df[continuous_feat].max(axis=1) - df[continuous_feat].min(axis=1)\n    df['f_count_pos']  = df[df[continuous_feat].gt(0)].count(axis=1)\n    df['f_count_neg']  = df[df[continuous_feat].lt(0)].count(axis=1)\n\n    return df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = stat_features(df_train, continuous_feat)\ndf_test = stat_features(df_test, continuous_feat)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# rename the nominal columns\n# list of nominal columns will be where there are less than 20 unique numers\n\nnom_cols = []\n\nfor i in range(len(df_train.columns)):\n    if df_train[df_train.columns[i]].nunique() < 30:\n        nom_cols.append(df_train.columns[i])\n\n# remove 'target'\nnom_cols.remove('target')\nnom_cols.remove('kfolds')\n\nprint(nom_cols)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# put the rest of the columns in another list to scale\n# and remove f_27\n\nall_cols = df_train.columns.tolist()\n\nrest_cols = list(set(all_cols) - set(nom_cols))\nrest_cols.remove('target')\nrest_cols.remove('id')\nrest_cols.remove('kfolds')\nrest_cols.remove('f_27')\n\nprint(rest_cols)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# scale the non integer columns\n\nscaler = RobustScaler()\ndf_train[rest_cols] = scaler.fit_transform(df_train[rest_cols])\ndf_test[rest_cols] = scaler.transform(df_test[rest_cols]) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"useful_features = [c for c in all_cols if c not in ('id','target','kfolds','f_27','f_29','f_30')]\ndf_test = df_test[useful_features]\nprint(useful_features)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# taken from the hypertuning notebook https://www.kaggle.com/code/andrewnuk/hypertuning-xgb-cb-lgbm\n\nparams_lgb = {\n    'objective': 'binary',\n    'metric': 'auc',\n    'n_estimators': 20000,\n    'learning_rate': 0.03094384584849164,\n    'reg_lambda': 0.016917918416652716,\n    'reg_alpha': 1.828457337138212e-05,\n    'subsample': 0.8975450099423059,\n    'subsample_freq': 6,\n    'colsample_bytree': 0.9900145862697067,\n    'min_child_weight': 65,\n    'min_child_samples': 23}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_predictions = []\nfinal_valid_predictions = {}\nscores = []\n\nfor fold in range(fold_no):\n    xtrain =  df_train[df_train['kfolds'] != fold].reset_index(drop=True)\n    xvalid = df_train[df_train['kfolds'] == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n    \n    valid_ids = xvalid.id.values.tolist()    \n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n#     ordinal_encoder = preprocessing.OrdinalEncoder()\n#     xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n#     xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n#     xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n    \n#     model = XGBRegressor(random_state=0, n_jobs=6) # i have 8 cores but want to keep 2 open\n    \n    model = lgb.LGBMClassifier(random_state=0, n_jobs=-1, **params_lgb)\n       \n    model.fit(xtrain, ytrain, early_stopping_rounds=1000, eval_set=[(xvalid, yvalid)], verbose=1000)\n    preds_valid = model.predict_proba(xvalid)[:, -1]\n    test_preds = model.predict_proba(xtest)[:, -1]\n    final_predictions.append(test_preds)\n    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))    \n    #rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    roc = roc_auc_score(yvalid, preds_valid)\n    print(fold, roc)\n    scores.append(roc)\n\nprint(np.mean(scores), np.std(scores))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\nfinal_valid_predictions.columns = [\"id\", \"pred_3\"]\nfinal_valid_predictions.to_csv(\"train_pred_3_FE_20220524.csv\", index=False)\n\ndf_sampleSubmission.target = np.mean(np.column_stack(final_predictions), axis=1)\ndf_sampleSubmission.columns = [\"id\", \"pred_3\"]\ndf_sampleSubmission.to_csv(\"test_pred_3_FE_20220524.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# column_names = [\"id\", \"target\"]\n\n# # df_sampleSubmission.target = np.mean(np.column_stack(final_predictions), axis=1)\n# df_sampleSubmission.to_csv(\"submission20220524c.csv\", header=column_names, index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sampleSubmission.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}