{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# this is the final model that blends the outputs from 3 models which come from 3 further models\n# it all starts with a notebook on creating the folds https://www.kaggle.com/code/andrewnuk/kfolds-5\n# then hypertunes 3 models https://www.kaggle.com/code/andrewnuk/hypertuning-xgb-cb-lgbm\n# then runs the 3 models https://www.kaggle.com/code/andrewnuk/models-level1-stacking\n# these outputs are hypertuned again https://www.kaggle.com/code/andrewnuk/hypertuning-level2\n# and the 3 models then run again https://www.kaggle.com/code/andrewnuk/models-level2\n# finally the outputs blended in this notebook https://www.kaggle.com/code/andrewnuk/model-level3","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom IPython.display import display\nimport matplotlib.pyplot as plt\n\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import RobustScaler\n#from sklearn.model_selection import train_test_split\n#from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n#from sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import roc_auc_score\nfrom xgboost import XGBRegressor\nimport lightgbm as lgb\nfrom catboost import CatBoostClassifier\nfrom sklearn.linear_model import LinearRegression\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check on the panda version and its dependencies\n# i run this from time to time to ensure all is up to date\npd.__version__\n#pd.show_versions()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# kfolds-5/train_folds_5.csv is an output from https://www.kaggle.com/code/andrewnuk/kfolds-5\n\ndf_train = pd.read_csv('/kaggle/input/kfolds-5/train_folds_5.csv')\ndf_test = pd.read_csv('/kaggle/input/tabular-playground-series-may-2022/test.csv')\ndf_sampleSubmission = pd.read_csv('/kaggle/input/tabular-playground-series-may-2022/sample_submission.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# detect number of folds\nfold_no = df_train['kfolds'].max() +1\nfold_no","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# output files from https://www.kaggle.com/code/andrewnuk/models-level2/notebook\n\ndf1 = pd.read_csv(\"../input/models-level2/level1_train_pred_1_20220524.csv\")\ndf2 = pd.read_csv(\"../input/models-level2/level1_train_pred_2_20220524.csv\")\ndf3 = pd.read_csv(\"../input/models-level2/level1_train_pred_3_20220524.csv\")\n\ndf_test1 = pd.read_csv(\"../input/models-level2/level1_test_pred_1_20220524.csv\")\ndf_test2 = pd.read_csv(\"../input/models-level2/level1_test_pred_2_20220524.csv\")\ndf_test3 = pd.read_csv(\"../input/models-level2/level1_test_pred_3_20220524.csv\")\n\ndf_train = df_train.merge(df1, on=\"id\", how=\"left\")\ndf_train = df_train.merge(df2, on=\"id\", how=\"left\")\ndf_train = df_train.merge(df3, on=\"id\", how=\"left\")\n\ndf_test = df_test.merge(df_test1, on=\"id\", how=\"left\")\ndf_test = df_test.merge(df_test2, on=\"id\", how=\"left\")\ndf_test = df_test.merge(df_test3, on=\"id\", how=\"left\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"useful_features = [\"pred_1\", \"pred_2\", \"pred_3\"]\ndf_test = df_test[useful_features]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# final_predictions = []\n# final_valid_predictions = {}\n# scores = []\n\n# for fold in range(fold_no):\n#     xtrain =  df_train[df_train['kfolds'] != fold].reset_index(drop=True)\n#     xvalid = df_train[df_train['kfolds'] == fold].reset_index(drop=True)\n#     xtest = df_test.copy()\n    \n#     valid_ids = xvalid.id.values.tolist()\n\n#     ytrain = xtrain.target\n#     yvalid = xvalid.target\n    \n#     xtrain = xtrain[useful_features]\n#     xvalid = xvalid[useful_features]\n    \n# #     ordinal_encoder = preprocessing.OrdinalEncoder()\n# #     xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n# #     xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n# #     xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n    \n# #     model = XGBRegressor(random_state=0, n_jobs=6) # i have 8 cores but want to keep 2 open\n    \n#     model = XGBRegressor(random_state=0, n_jobs=-1, **params)\n       \n#     model.fit(xtrain, ytrain, early_stopping_rounds=1000, eval_set=[(xvalid, yvalid)], verbose=1000)\n#     preds_valid = model.predict(xvalid)\n#     test_preds = model.predict(xtest)\n#     final_predictions.append(test_preds)\n#     final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n#     #rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n#     roc = roc_auc_score(yvalid, preds_valid)\n#     print(fold, roc)\n#     scores.append(roc)\n\n# print(np.mean(scores), np.std(scores))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_predictions = []\nfinal_valid_predictions = {}\nscores = []\n\nfor fold in range(fold_no):\n    xtrain =  df_train[df_train['kfolds'] != fold].reset_index(drop=True)\n    xvalid = df_train[df_train['kfolds'] == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n    \n    valid_ids = xvalid.id.values.tolist()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n#     ordinal_encoder = preprocessing.OrdinalEncoder()\n#     xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n#     xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n#     xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n    \n#     model = XGBRegressor(random_state=0, n_jobs=6) # i have 8 cores but want to keep 2 open\n    \n    model = LinearRegression()\n       \n    model.fit(xtrain, ytrain)\n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_predictions.append(test_preds)\n    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n    #rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    roc = roc_auc_score(yvalid, preds_valid)\n    print(fold, roc)\n    scores.append(roc)\n\nprint(np.mean(scores), np.std(scores))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sampleSubmission.target = np.mean(np.column_stack(final_predictions), axis=1)\ndf_sampleSubmission.to_csv(\"submission.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}