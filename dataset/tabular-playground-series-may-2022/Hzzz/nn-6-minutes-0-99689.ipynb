{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nimport torch\nfrom torch import nn\nfrom typing import List\nimport torch.nn.functional as F\nfrom transformers import get_linear_schedule_with_warmup\nfrom tqdm.auto import tqdm\nimport random\nfrom sklearn import metrics\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-10T13:36:01.701468Z","iopub.execute_input":"2022-05-10T13:36:01.702056Z","iopub.status.idle":"2022-05-10T13:36:01.708483Z","shell.execute_reply.started":"2022-05-10T13:36:01.702017Z","shell.execute_reply":"2022-05-10T13:36:01.707461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(f\"../input/tabular-playground-series-may-2022/train.csv\")\ntest_df = pd.read_csv(f\"../input/tabular-playground-series-may-2022/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-05-10T13:23:30.693016Z","iopub.execute_input":"2022-05-10T13:23:30.693292Z","iopub.status.idle":"2022-05-10T13:23:40.667412Z","shell.execute_reply.started":"2022-05-10T13:23:30.693262Z","shell.execute_reply":"2022-05-10T13:23:40.666539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df[\"target\"] = 0\n\ntrain_df, val_df = train_test_split(train_df, test_size=0.1, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T13:23:40.669228Z","iopub.execute_input":"2022-05-10T13:23:40.669514Z","iopub.status.idle":"2022-05-10T13:23:41.185789Z","shell.execute_reply.started":"2022-05-10T13:23:40.669476Z","shell.execute_reply":"2022-05-10T13:23:41.184944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {\n        \"~lr\": 0.01,\n        \"~batch_size\": 2048,\n        \"~epochs\": 40,\n        \"~early_stopping_patience\": 6,\n        \"~optimizer\": \"adam\",\n        \"~loss\": \"bce\",\n        \"activation\": \"swish\",\n        \"model\": \"baseline\"\n    }","metadata":{"execution":{"iopub.status.busy":"2022-05-10T13:24:16.686316Z","iopub.execute_input":"2022-05-10T13:24:16.687447Z","iopub.status.idle":"2022-05-10T13:24:16.693314Z","shell.execute_reply.started":"2022-05-10T13:24:16.687389Z","shell.execute_reply":"2022-05-10T13:24:16.691915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# FE","metadata":{}},{"cell_type":"code","source":"class DataProcess:\n    def __init__(self, df: pd.DataFrame) -> None:\n        self.scaler = StandardScaler()\n        self.numerical_cols = [f\"f_{i:02d}\" for i in range(27)] + [\"f_28\"]\n        self.float_cols = [i for i in df.columns if df[i].dtype == \"float64\"]\n        self.scaler.fit(df[self.numerical_cols].values)\n\n    def preprocess(self, df: pd.DataFrame) -> pd.DataFrame:\n        df[self.numerical_cols] = self.scaler.transform(df[self.numerical_cols].values)\n\n        # f_29, f_30 -> onehot\n        df = df.drop(columns=\"f_29\").join(\n            pd.get_dummies(df[\"f_29\"]).rename(columns={0: \"f_29_0\", 1: \"f_29_1\"})\n        )\n\n        df = df.drop(columns=\"f_30\").join(\n            pd.get_dummies(df[\"f_30\"]).rename(\n                columns={0: \"f_30_0\", 1: \"f_30_1\", 2: \"f_30_2\"}\n            )\n        )\n\n\n\n        # https://www.kaggle.com/code/ambrosm/tpsmay22-gradient-boosting-quickstart/notebook\n        # https://www.kaggle.com/code/ambrosm/tpsmay22-eda-which-makes-sense\n        # f_27 -> each char to ord\n        # f_27 -> nunique\n        for i in range(10):\n            df[f\"f_27_{i}_int\"] = df.f_27.str[i].map(ord) - ord(\"A\")\n        df[f\"f_27_nunique\"] = df.f_27.apply(lambda c: len(set(c)))\n\n        df = df.drop(columns=\"f_27\")\n\n        # stats features\n        # https://www.kaggle.com/code/cv13j0/tps-may22-eda-neuronal-nets/notebook\n        df[\"f_sum\"] = df[self.float_cols].sum(axis=1)\n        df[\"f_min\"] = df[self.float_cols].min(axis=1)\n        df[\"f_max\"] = df[self.float_cols].max(axis=1)\n        df[\"f_mean\"] = df[self.float_cols].mean(axis=1)\n        df[\"f_std\"] = df[self.float_cols].std(axis=1)\n        df[\"f_mad\"] = df[self.float_cols].mad(axis=1)\n        df[\"f_kurt\"] = df[self.float_cols].kurt(axis=1)\n        df[\"f_count_pos\"] = df[self.float_cols].gt(0).count(axis=1)\n\n        return df\n","metadata":{"execution":{"iopub.status.busy":"2022-05-10T13:23:41.187497Z","iopub.execute_input":"2022-05-10T13:23:41.187814Z","iopub.status.idle":"2022-05-10T13:23:41.203797Z","shell.execute_reply.started":"2022-05-10T13:23:41.187774Z","shell.execute_reply":"2022-05-10T13:23:41.202909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"processor = DataProcess(train_df)\ntrain_df = processor.preprocess(train_df)\nval_df = processor.preprocess(val_df)\ntest_df = processor.preprocess(test_df)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T13:23:41.205708Z","iopub.execute_input":"2022-05-10T13:23:41.206697Z","iopub.status.idle":"2022-05-10T13:24:12.178133Z","shell.execute_reply.started":"2022-05-10T13:23:41.206651Z","shell.execute_reply":"2022-05-10T13:24:12.177291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DataLoader","metadata":{}},{"cell_type":"code","source":"class DataLoader:\n    class Dataset(torch.utils.data.Dataset):\n        def __init__(self, x: np.ndarray, y: np.ndarray):\n            self.x = x\n            self.y = y\n            self.len = len(self.x)\n\n        def __getitem__(self, index):\n            x = self.x[index]\n            y = self.y[index]\n            return x, y\n\n        def __len__(self):\n            return self.len\n\n    class Sampler(torch.utils.data.Sampler):\n        def __init__(self, l: int, shuffle: bool) -> None:\n            super().__init__(l)\n            self.len = l\n            self.shuffle = shuffle\n\n        def __iter__(self) -> List[int]:\n            lst = list(range(self.len))\n            if self.shuffle:\n                random.shuffle(lst)\n            for i in lst:\n                yield i\n\n        def __len__(self) -> int:\n            return self.len\n\n    def __init__(self, df: pd.DataFrame) -> None:\n        self.x = df.drop(columns=[\"id\", \"target\"]).values\n        self.y = df[\"target\"].values\n\n    def get(self, is_train=False) -> torch.utils.data.DataLoader:\n        dataset = self.Dataset(self.x, self.y)\n        sampler = self.Sampler(len(self.x), shuffle=is_train)\n        batch_size = params[\"~batch_size\"] if is_train else len(dataset)\n\n        return torch.utils.data.DataLoader(\n            dataset=dataset,\n            sampler=sampler,\n            batch_size=batch_size,\n            drop_last=is_train,\n        )\n\n    \ntrain_ds = DataLoader(train_df).get(is_train=True)\nval_ds = DataLoader(val_df).get()\ntest_ds = DataLoader(test_df).get()\n","metadata":{"execution":{"iopub.status.busy":"2022-05-10T13:25:25.972043Z","iopub.execute_input":"2022-05-10T13:25:25.972364Z","iopub.status.idle":"2022-05-10T13:25:26.502411Z","shell.execute_reply.started":"2022-05-10T13:25:25.97231Z","shell.execute_reply":"2022-05-10T13:25:26.501603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self, input_size):\n        super().__init__()\n        self.fc1 = nn.Linear(input_size, 64)\n        self.bn1 = nn.BatchNorm1d(64)\n        self.fc2 = nn.Linear(64, 128)\n        self.bn2 = nn.BatchNorm1d(128)\n        self.fc5 = nn.Linear(128, 32)\n        self.bn5 = nn.BatchNorm1d(32)\n        self.fc6 = nn.Linear(32, 1)\n        if params[\"activation\"] == \"relu\":\n            self.activation = F.relu\n        elif params[\"activation\"] == \"swish\":\n            self.activation = F.silu\n\n    def forward(self, x):\n        x = self.activation(self.bn1(self.fc1(x)))\n        x = self.activation(self.bn2(self.fc2(x)))\n        x = self.activation(self.bn5(self.fc5(x)))\n        x = torch.sigmoid(self.fc6(x))\n\n        return x.squeeze()\n\nmodel = Model(len(set(train_df.columns) - {\"id\", \"target\"})).to('cuda')\n","metadata":{"execution":{"iopub.status.busy":"2022-05-10T13:34:25.24451Z","iopub.execute_input":"2022-05-10T13:34:25.244852Z","iopub.status.idle":"2022-05-10T13:34:25.261293Z","shell.execute_reply.started":"2022-05-10T13:34:25.244819Z","shell.execute_reply":"2022-05-10T13:34:25.260333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"def get_scheduler(optimizer, train_dataloader):\n    epochs = params[\"~epochs\"]\n    num_training_steps = int(epochs * len(train_dataloader))\n\n    return get_linear_schedule_with_warmup(\n        optimizer, int(0.1 * num_training_steps), num_training_steps\n    )\n","metadata":{"execution":{"iopub.status.busy":"2022-05-10T13:34:29.734163Z","iopub.execute_input":"2022-05-10T13:34:29.734456Z","iopub.status.idle":"2022-05-10T13:34:29.73999Z","shell.execute_reply.started":"2022-05-10T13:34:29.734424Z","shell.execute_reply":"2022-05-10T13:34:29.739082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Callback:\n    def __init__(self) -> None:\n        pass\n\n    def on_val_end(self, preds: np.ndarray, gts: np.ndarray, loss):\n        pass\n\n    def on_train_batch_end(self, preds: np.ndarray, gts: np.ndarray, loss):\n        pass\n\n    def on_epoch_end(self, loss, val_loss, model: torch.nn.Module) -> bool:\n        pass\n\n    def on_train_finish(self, model: torch.nn.Module):\n        pass\n\nclass EarlyStopping(Callback):\n    def __init__(self) -> None:\n        self.patience = params[\"~early_stopping_patience\"]\n        self.min_loss = np.inf\n        self.counter = 0\n        self.best_state_dict = None\n\n    def on_val_end(self, preds: np.ndarray, gts: np.ndarray, loss):\n        pass\n\n    def on_train_batch_end(self, preds: np.ndarray, gts: np.ndarray, loss):\n        pass\n\n    def on_epoch_end(self, loss, val_loss, model: torch.nn.Module) -> bool:\n        if val_loss < self.min_loss:\n            self.min_loss = val_loss\n            self.counter = 0\n            self.best_state_dict = model.state_dict()\n        else:\n            self.counter += 1\n\n        return self.counter < self.patience\n\n    def on_train_finish(self, model: torch.nn.Module):\n        model.load_state_dict(self.best_state_dict)\n\n        \nclass WandbCallback(Callback):\n    def __init__(self) -> None:\n        self.train_epoch_losses = []\n        self.val_epoch_losses = []\n        self.train_batch_losses = []\n        self.val_batch_losses = []\n\n    def on_val_end(self, preds: np.ndarray, gts: np.ndarray, loss):\n        gts = gts.detach().cpu()\n        preds = preds.detach().cpu()\n\n        fpr, tpr, threshold = metrics.roc_curve(gts, preds)\n        roc_auc = metrics.auc(fpr, tpr)\n#         wandb.log({\"roc_auc\": roc_auc})\n\n        print(f\"roc_auc: {roc_auc}\")\n        return True\n\n    def on_train_batch_end(self, preds: np.ndarray, gts: np.ndarray, loss):\n        self.train_batch_losses.append(loss)\n\n    def on_epoch_end(self, loss, val_loss, model: torch.nn.Module) -> bool:\n        self.val_epoch_losses.append(val_loss)\n        self.train_epoch_losses.append(loss)\n\n#         wandb.log({\"loss\": loss, \"val_loss\": val_loss})\n\n        return True\n\ndef epoch_train(\n    model: torch.nn.Module,\n    optimizer: torch.optim.Optimizer,\n    scheduler,\n    train_loader,\n    criterion,\n    callbacks: List[Callback] = [],\n):\n    model.train()\n\n    losses = []\n    for i, batch in tqdm(enumerate(train_loader), total=len(train_loader), unit=\" batch\"):\n        batch_x = batch[0].to(torch.float32).to(\"cuda\")\n        batch_y = batch[1].to(torch.float32).to(\"cuda\")\n\n        optimizer.zero_grad()\n        pred_y = model(batch_x)\n        loss = criterion(pred_y, batch_y)\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n\n        losses.append(loss.item())\n\n        [cb.on_train_batch_end(pred_y, batch_y, loss.item()) for cb in callbacks]\n\n    return np.mean(losses)\n\n\ndef epoch_val(\n    model: torch.nn.Module, val_loader, criterion, callbacks: List[Callback] = []\n):\n    model.eval()\n\n    losses = []\n    for i, batch in enumerate(val_loader):\n        batch_x = batch[0].to(torch.float32).to(\"cuda\")\n        batch_y = batch[1].to(torch.float32).to(\"cuda\")\n        pred_y = model(batch_x)\n        loss = criterion(pred_y, batch_y)\n        losses.append(loss.item())\n\n        [cb.on_val_end(pred_y, batch_y, loss.item()) for cb in callbacks]\n        break\n    return np.mean(losses)\n\n\ndef predict(model: torch.nn.Module, test_loader):\n    model.eval()\n    preds = []\n    gts = []\n    for i, (batch_x, batch_y) in enumerate(test_loader):\n        batch_x = batch_x.to(torch.float32).to(\"cuda\")\n        batch_y = batch_y.to(torch.float32).to(\"cuda\")\n        pred_y = model(batch_x)\n\n        preds.append(pred_y.cpu().detach().numpy())\n        gts.append(batch_y.cpu().detach().numpy())\n\n        break\n\n    preds = np.array(preds)\n    preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n    gts = np.array(gts)\n    gts = gts.reshape(-1, gts.shape[-2], gts.shape[-1])\n    return preds, gts\n","metadata":{"execution":{"iopub.status.busy":"2022-05-10T13:34:30.584985Z","iopub.execute_input":"2022-05-10T13:34:30.585278Z","iopub.status.idle":"2022-05-10T13:34:30.615933Z","shell.execute_reply.started":"2022-05-10T13:34:30.585247Z","shell.execute_reply":"2022-05-10T13:34:30.615033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = torch.nn.BCELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=params[\"~lr\"])\nscheduler = get_scheduler(optimizer, train_ds)\ncallbacks = [EarlyStopping(), WandbCallback()]\n\nfor epoch in range(params[\"~epochs\"]):\n    loss = epoch_train(\n        model, optimizer, scheduler, train_ds, criterion, callbacks\n    )\n    val_loss = epoch_val(model, val_ds, criterion, callbacks)\n    print(epoch, \": train_loss\", loss, \"val_loss\", val_loss)\n\n    res = [c.on_epoch_end(loss, val_loss, model) for c in callbacks]\n    if False in res:\n        print(\"Early stopping\")\n        break\n        \n[c.on_train_finish(model) for c in callbacks]\n","metadata":{"execution":{"iopub.status.busy":"2022-05-10T13:36:06.121052Z","iopub.execute_input":"2022-05-10T13:36:06.121339Z","iopub.status.idle":"2022-05-10T13:42:51.166354Z","shell.execute_reply.started":"2022-05-10T13:36:06.12131Z","shell.execute_reply":"2022-05-10T13:42:51.165382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submit","metadata":{}},{"cell_type":"code","source":"preds, gts = predict(model, test_ds)\n\nsub = pd.read_csv(f\"../input/tabular-playground-series-may-2022/sample_submission.csv\")\nsub.target = preds.squeeze()\nsub.to_csv('submission.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-10T13:44:46.095609Z","iopub.execute_input":"2022-05-10T13:44:46.096359Z","iopub.status.idle":"2022-05-10T13:44:53.935682Z","shell.execute_reply.started":"2022-05-10T13:44:46.096323Z","shell.execute_reply":"2022-05-10T13:44:53.934623Z"},"trusted":true},"execution_count":null,"outputs":[]}]}