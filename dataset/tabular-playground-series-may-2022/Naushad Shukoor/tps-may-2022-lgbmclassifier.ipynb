{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport datatable\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-17T06:36:20.403809Z","iopub.execute_input":"2022-06-17T06:36:20.40465Z","iopub.status.idle":"2022-06-17T06:36:20.509932Z","shell.execute_reply.started":"2022-06-17T06:36:20.404607Z","shell.execute_reply":"2022-06-17T06:36:20.508956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install mplcyberpunk\nimport mplcyberpunk\nplt.style.use(\"cyberpunk\")","metadata":{"execution":{"iopub.status.busy":"2022-06-17T10:56:46.106212Z","iopub.execute_input":"2022-06-17T10:56:46.107134Z","iopub.status.idle":"2022-06-17T10:56:57.754801Z","shell.execute_reply.started":"2022-06-17T10:56:46.107079Z","shell.execute_reply":"2022-06-17T10:56:57.753916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split, KFold\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.calibration import CalibrationDisplay\nfrom lightgbm import LGBMClassifier, early_stopping, log_evaluation","metadata":{"execution":{"iopub.status.busy":"2022-06-17T12:56:19.983815Z","iopub.execute_input":"2022-06-17T12:56:19.984172Z","iopub.status.idle":"2022-06-17T12:56:20.100927Z","shell.execute_reply.started":"2022-06-17T12:56:19.984133Z","shell.execute_reply":"2022-06-17T12:56:20.100176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# helpers\ndef reduce_mem_usage(props):\n    start_mem_usg = props.memory_usage().sum() / 1024**2 \n    print(\"Memory usage of properties dataframe is :\",round(start_mem_usg,2),\" MB\")\n    NAlist = [] # Keeps track of columns that have missing values filled in. \n    for col in props.columns:\n        if props[col].dtype != object:  # Exclude strings\n            \n            # Print current column type\n#             print(\"******************************\")\n#             print(\"Column: \",col)\n#             print(\"dtype before: \",props[col].dtype)\n            \n            # make variables for Int, max and min\n            IsInt = False\n            mx = props[col].max()\n            mn = props[col].min()\n            \n            # Integer does not support NA, therefore, NA needs to be filled\n            if not np.isfinite(props[col]).all(): \n                NAlist.append(col)\n                props[col].fillna(mn-1,inplace=True)  \n                   \n            # test if column can be converted to an integer\n            asint = props[col].fillna(0).astype(np.int64)\n            result = (props[col] - asint)\n            result = result.sum()\n            if result > -0.01 and result < 0.01:\n                IsInt = True\n\n            \n            # Make Integer/unsigned Integer datatypes\n            if IsInt:\n                if mn >= 0:\n                    if mx < 255:\n                        props[col] = props[col].astype(np.uint8)\n                    elif mx < 65535:\n                        props[col] = props[col].astype(np.uint16)\n                    elif mx < 4294967295:\n                        props[col] = props[col].astype(np.uint32)\n                    else:\n                        props[col] = props[col].astype(np.uint64)\n                else:\n                    if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n                        props[col] = props[col].astype(np.int8)\n                    elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n                        props[col] = props[col].astype(np.int16)\n                    elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n                        props[col] = props[col].astype(np.int32)\n                    elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n                        props[col] = props[col].astype(np.int64)    \n            \n            # Make float datatypes 32 bit\n            else:\n                props[col] = props[col].astype(np.float32)\n            \n            # Print new column type\n#             print(\"dtype after: \",props[col].dtype)\n#             print(\"******************************\")\n    \n    # Print final result\n    print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n    mem_usg = props.memory_usage().sum() / 1024**2 \n    print(\"Memory usage is: \",round(mem_usg,2),\" MB\")\n    print(\"This is \",round(100*mem_usg/start_mem_usg,2),\"% of the initial size\")\n    return props, NAlist","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-06-17T06:36:22.305899Z","iopub.execute_input":"2022-06-17T06:36:22.306222Z","iopub.status.idle":"2022-06-17T06:36:22.321306Z","shell.execute_reply.started":"2022-06-17T06:36:22.306178Z","shell.execute_reply":"2022-06-17T06:36:22.320418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntrain_df = datatable.fread(\"/kaggle/input/tabular-playground-series-may-2022/train.csv\").to_pandas().set_index('id')\ntrain_df,_ = reduce_mem_usage(train_df)\ntest_df = datatable.fread(\"/kaggle/input/tabular-playground-series-may-2022/test.csv\").to_pandas().set_index('id')\ntest_df,_ = reduce_mem_usage(test_df)","metadata":{"execution":{"iopub.status.busy":"2022-06-17T06:36:22.322643Z","iopub.execute_input":"2022-06-17T06:36:22.32348Z","iopub.status.idle":"2022-06-17T06:36:28.878952Z","shell.execute_reply.started":"2022-06-17T06:36:22.323427Z","shell.execute_reply":"2022-06-17T06:36:28.877949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def feature_engineer(df):\n    \n    df = df.copy()\n    \n    for i in range(10):\n        df[f\"ch{i}\"] = df.f_27.str.get(i).apply(ord) - ord('A')\n        \n    df[\"f_27_len_unique_chars\"] = df.f_27.apply(lambda x : len(set(x)))\n    \n    df.drop(columns=[\"f_27\"], inplace=True)\n    \n    df[\"i_f02_f21\"] = (df.f_02 + df.f_21 > 5.2).astype(int) - \\\n                        (df.f_02 + df.f_21 < -5.3).astype(int)\n    \n    df[\"i_f05_f22\"] = (df.f_05 + df.f_22 > 5.1).astype(int) - \\\n                        (df.f_05 + df.f_22 < -5.4).astype(int)\n    \n    df[\"i_f00_f01_f26\"] = (df.f_00 + df.f_01 + df.f_26 > 5.0).astype(int) - \\\n                        (df.f_00 + df.f_01 + df.f_26 < -5.0).astype(int)\n    \n    return df\n\n\ntrain_df = feature_engineer(train_df)\ntest_df = feature_engineer(test_df)","metadata":{"execution":{"iopub.status.busy":"2022-06-17T06:36:28.880603Z","iopub.execute_input":"2022-06-17T06:36:28.880821Z","iopub.status.idle":"2022-06-17T06:36:40.424845Z","shell.execute_reply.started":"2022-06-17T06:36:28.880794Z","shell.execute_reply":"2022-06-17T06:36:40.424059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_lgbm(features):\n    X=train_df[features]\n    y=train_df[\"target\"]\n\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state = 42)\n\n    # Train model\n    lgbm_model_cv = LGBMClassifier(n_estimators=1000, min_child_samples=80, random_state=1307)\n    lgbm_model_cv.fit(X_train.values, y_train)\n    y_pred = lgbm_model_cv.predict_proba(X_test.values)[:,1]\n    auc_score = roc_auc_score(y_test, y_pred)\n    print(f\"Validation AUC:{(auc_score):.5f}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-17T06:36:40.433473Z","iopub.execute_input":"2022-06-17T06:36:40.434156Z","iopub.status.idle":"2022-06-17T06:36:40.443891Z","shell.execute_reply.started":"2022-06-17T06:36:40.434124Z","shell.execute_reply":"2022-06-17T06:36:40.44323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_features = ['f_00', 'f_01', 'f_02', 'f_03', 'f_04', 'f_05', 'f_06', 'f_07', 'f_08',\n       'f_09', 'f_10', 'f_11', 'f_12', 'f_13', 'f_14', 'f_15', 'f_16', 'f_17',\n       'f_18', 'f_19', 'f_20', 'f_21', 'f_22', 'f_23', 'f_24', 'f_25', 'f_26',\n       'f_28', 'f_29', 'f_30']","metadata":{"execution":{"iopub.status.busy":"2022-06-17T06:36:40.445342Z","iopub.execute_input":"2022-06-17T06:36:40.445805Z","iopub.status.idle":"2022-06-17T06:36:40.454703Z","shell.execute_reply.started":"2022-06-17T06:36:40.445764Z","shell.execute_reply":"2022-06-17T06:36:40.454075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfeatures = base_features\ntrain_lgbm(features)","metadata":{"execution":{"iopub.status.busy":"2022-06-17T06:36:40.455754Z","iopub.execute_input":"2022-06-17T06:36:40.456374Z","iopub.status.idle":"2022-06-17T06:36:40.46722Z","shell.execute_reply.started":"2022-06-17T06:36:40.456341Z","shell.execute_reply":"2022-06-17T06:36:40.466275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfeatures = base_features + ['ch0', 'ch1', 'ch2', 'ch3', 'ch4',\n       'ch5', 'ch6', 'ch7', 'ch8', 'ch9']\ntrain_lgbm(features)","metadata":{"execution":{"iopub.status.busy":"2022-06-17T06:36:40.468517Z","iopub.execute_input":"2022-06-17T06:36:40.469057Z","iopub.status.idle":"2022-06-17T06:36:40.478747Z","shell.execute_reply.started":"2022-06-17T06:36:40.469013Z","shell.execute_reply":"2022-06-17T06:36:40.478137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfeatures = base_features + ['f_27_len_unique_chars']\ntrain_lgbm(features)","metadata":{"execution":{"iopub.status.busy":"2022-06-17T06:36:40.480825Z","iopub.execute_input":"2022-06-17T06:36:40.481259Z","iopub.status.idle":"2022-06-17T06:36:40.496664Z","shell.execute_reply.started":"2022-06-17T06:36:40.481217Z","shell.execute_reply":"2022-06-17T06:36:40.495879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfeatures = base_features + ['i_f02_f21', 'i_f05_f22', 'i_f00_f01_f26']\ntrain_lgbm(features)","metadata":{"execution":{"iopub.status.busy":"2022-06-17T06:36:40.49804Z","iopub.execute_input":"2022-06-17T06:36:40.49853Z","iopub.status.idle":"2022-06-17T06:36:40.508045Z","shell.execute_reply.started":"2022-06-17T06:36:40.498494Z","shell.execute_reply":"2022-06-17T06:36:40.507291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_feature_list = base_features + ['f_27_len_unique_chars'] + ['ch0', 'ch1', 'ch2', 'ch3', 'ch4',\n       'ch5', 'ch6', 'ch7', 'ch8', 'ch9'] + ['i_f02_f21', 'i_f05_f22', 'i_f00_f01_f26']","metadata":{"execution":{"iopub.status.busy":"2022-06-17T06:36:40.509544Z","iopub.execute_input":"2022-06-17T06:36:40.509978Z","iopub.status.idle":"2022-06-17T06:36:40.521164Z","shell.execute_reply.started":"2022-06-17T06:36:40.509947Z","shell.execute_reply":"2022-06-17T06:36:40.520403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntrain_lgbm(final_feature_list)","metadata":{"execution":{"iopub.status.busy":"2022-06-17T06:36:40.522335Z","iopub.execute_input":"2022-06-17T06:36:40.522629Z","iopub.status.idle":"2022-06-17T06:36:40.532977Z","shell.execute_reply.started":"2022-06-17T06:36:40.522591Z","shell.execute_reply":"2022-06-17T06:36:40.532331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Cross-Validation","metadata":{}},{"cell_type":"markdown","source":"For cross-validation, we use a simple KFold with five splits. It turned out that the scores of the five splits are very similar so that I usually run only the first split. This one split is good enough to evaluate the model.\n\nBecause I want to understand how many iterations are needed, we'll collect some metrics and plot the training history. early_stopping_round is set to the very high value of 100000. This means that the algorithm won't stop early, but the setting is necessary to collect the metrics.","metadata":{}},{"cell_type":"code","source":"%%time\ndef my_booster(n_estimators=10_000, random_state=1):\n    return LGBMClassifier(n_estimators=n_estimators,\n                         min_child_samples=80,\n                         num_leaves=127,\n                         subsample=0.85,\n                         subsample_freq=1,\n                         metric='auc,binary_logloss,binary_error',\n                         max_bins=511,\n                         random_state=random_state)\n\nprint(f\"{len(final_feature_list)} features\")\n\nauc_scores_list=[]\n\nkf = KFold(n_splits=5)\n\nfor fold, (idx_train, idx_val) in enumerate(kf.split(train_df)):\n    X_train = train_df.iloc[idx_train][final_feature_list]\n    X_val = train_df.iloc[idx_val][final_feature_list]\n    y_train = train_df.iloc[idx_train].target\n    y_val = train_df.iloc[idx_val].target\n    \n    model = my_booster()\n    model.fit(X_train, y_train,\n              eval_set = [\n                  (X_train, y_train),\n                  (X_val,y_val)\n              ],\n              callbacks=[\n                  early_stopping(stopping_rounds=1_00_000), # will stop training if one metric of one validation data doesn’t improve in last stopping_rounds rounds\n                  log_evaluation(period=1000)\n              ],\n             )\n    y_pred = model.predict_proba(X_val)[:,1]\n    auc_score = roc_auc_score(y_val, y_pred)\n    print(f\"Fold {fold}: \\t  AUC = {auc_score:.5f}\")\n    auc_scores_list.append(auc_score)\n    break # we only need the first fold\n    \nprint(f\"OOF AUC: \\t  {np.mean(auc_scores_list):.5f}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-17T11:40:42.899975Z","iopub.execute_input":"2022-06-17T11:40:42.900317Z","iopub.status.idle":"2022-06-17T12:15:56.581272Z","shell.execute_reply.started":"2022-06-17T11:40:42.900281Z","shell.execute_reply":"2022-06-17T12:15:56.580012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Cross Validation Model Summary","metadata":{}},{"cell_type":"code","source":"{\n    \"model.n_features_\": model.n_features_,\n    \"model.feature_name_\": model.feature_name_,\n    \"model.feature_importances_\": model.feature_importances_,\n    \"model.n_classes_\": model.n_classes_,\n    \"model.objective_\": model.objective_,\n    \"model.best_iteration_\": model.best_iteration_,\n    \"model.best_score_\": model.best_score_,\n    \"model.evals_result_['training']['auc'][:5]\":model.evals_result_[\"training\"][\"auc\"][:5]\n}","metadata":{"execution":{"iopub.status.busy":"2022-06-17T12:18:44.816557Z","iopub.execute_input":"2022-06-17T12:18:44.81765Z","iopub.status.idle":"2022-06-17T12:18:44.829904Z","shell.execute_reply.started":"2022-06-17T12:18:44.817602Z","shell.execute_reply":"2022-06-17T12:18:44.828955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We save the metrics as csv files in case anybody wants to evaluate them further:","metadata":{}},{"cell_type":"code","source":"history_train = pd.DataFrame(model.evals_result_['training'])\nhistory_valid = pd.DataFrame(model.evals_result_['valid_1'])\nhistory_train['accuracy'] = 1 - history_train.binary_error\nhistory_valid['accuracy'] = 1 - history_valid.binary_error\nhistory_train.to_csv('history_train.csv')\nhistory_valid.to_csv('history_valid.csv')\nhistory_train.tail()","metadata":{"execution":{"iopub.status.busy":"2022-06-17T12:18:51.905939Z","iopub.execute_input":"2022-06-17T12:18:51.906726Z","iopub.status.idle":"2022-06-17T12:18:52.048214Z","shell.execute_reply.started":"2022-06-17T12:18:51.906677Z","shell.execute_reply":"2022-06-17T12:18:52.047207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we plot the three metrics loss, accuracy and AUC for the whole training history. In every plot, we mark the point where the metric reaches its optimum.\n\nThe estimator overfits terribly: After 2000 iterations, the training predictions are perfect (accuracy and AUC are 1.0). The validation loss reaches its optimum already before 2000 iterations, at a time when validation accuracy and validation auc are still improving. Validation accuracy and validation auc peak several thousand iterations later.\n\nInsight: Don't stop lightgbm early when the validation loss stops improving! Wait until validation auc peaks!","metadata":{}},{"cell_type":"code","source":"fig, (ax1, ax2, ax3) = plt.subplots(3,1, figsize=(30,20), sharex=True)\n\nax1.plot(history_train.index, history_train.binary_logloss, label='training')\nax1.plot(history_valid.index, history_valid.binary_logloss, label='validation')\nm = history_train.binary_logloss.argmin()\nax1.scatter([m],history_train.binary_logloss[m])\nm = history_valid.binary_logloss.argmin()\nax1.scatter([m],history_valid.binary_logloss[m])\nax1.annotate('Lowest Validation Loss. \\nValidation Loss starts increasing from here. \\nDont stop the training yet.', xy=(m,history_valid.binary_logloss[m]),  xycoords='data',\n            xytext=(m, 0.3), textcoords='data',\n            arrowprops=dict(facecolor='white', shrink=0.05),\n            horizontalalignment='center', verticalalignment='top',fontsize=15\n            )\n# ax1.set_xticks(np.linspace(0, 1000, 11))\nax1.set_ylabel('Loss')\nax1.legend(loc='best')\nmplcyberpunk.add_glow_effects(ax1)\n\nax2.plot(history_train.index, history_train.accuracy, label='training')\nax2.plot(history_valid.index, history_valid.accuracy, label='validation')\nm = history_train.accuracy.argmax()\nax2.scatter([m],history_train.accuracy[m])\nm = history_valid.accuracy.argmax()\nax2.scatter([m],history_valid.accuracy[m])\nax2.annotate('Best Validation Accuracy', xy=(m,history_valid.accuracy[m]),  xycoords='data',\n            xytext=(m, 0.94), textcoords='data',\n            arrowprops=dict(facecolor='white', shrink=0.05),\n            horizontalalignment='center', verticalalignment='top',fontsize=15\n            )\n# ax2.set_xticks(np.linspace(0, 1000, 11))\nax2.set_ylabel('Accuracy')\nax2.legend(loc='best')\nmplcyberpunk.add_glow_effects(ax2)\n\nax3.plot(history_train.index, history_train.auc, label='training')\nax3.plot(history_valid.index, history_valid.auc, label='validation')\nm = history_train.auc.argmax()\nax3.scatter([m],history_train.auc[m])\nm = history_valid.auc.argmax()\nauc_peak = m\nax3.scatter([m],history_valid.auc[m])\nax3.annotate('Best Validation AUC \\n Stop training here!', xy=(m,history_valid.auc[m]),  xycoords='data',\n            xytext=(m, 0.975), textcoords='data',\n            arrowprops=dict(facecolor='white', shrink=0.05),\n            horizontalalignment='center', verticalalignment='top',fontsize=15\n            )\nax3.set_xticks(np.linspace(0, 10000, 11))\nax3.set_ylabel('AUC')\nax3.legend(loc='best')\nax3.set_xlabel(\"Iteration\")\n\nmplcyberpunk.add_glow_effects(ax3)\nplt.suptitle('Lightgbm training history', y=0.94, fontsize=30)\nplt.show()\nprint(f\"Validation AUC peaks at iteration {auc_peak} with score {history_valid.auc[auc_peak]:.5f}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-17T12:31:35.77991Z","iopub.execute_input":"2022-06-17T12:31:35.78021Z","iopub.status.idle":"2022-06-17T12:31:37.384694Z","shell.execute_reply.started":"2022-06-17T12:31:35.780179Z","shell.execute_reply":"2022-06-17T12:31:37.383643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Three diagrams for model evaluation\nWe plot the ROC curve just because it looks nice. The area under the red curve is the score of our model.","metadata":{}},{"cell_type":"code","source":"# Plot the roc curve for the last fold\ndef plot_roc_curve(y_va, y_va_pred):\n    plt.figure(figsize=(8, 8))\n    fpr, tpr, _ = roc_curve(y_va, y_va_pred)\n    plt.plot(fpr, tpr, color='r', lw=2)\n    plt.plot([0, 1], [0, 1], color=\"w\", lw=1, linestyle=\"--\")\n    plt.gca().set_aspect('equal')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.0])\n    plt.xlabel(\"False Positive Rate\")\n    plt.ylabel(\"True Positive Rate\")\n    plt.title(\"Receiver operating characteristic\")\n    plt.show()\n\nplot_roc_curve(y_val, y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-06-17T12:41:34.64447Z","iopub.execute_input":"2022-06-17T12:41:34.645281Z","iopub.status.idle":"2022-06-17T12:41:35.234727Z","shell.execute_reply.started":"2022-06-17T12:41:34.645227Z","shell.execute_reply":"2022-06-17T12:41:35.233918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Second, we plot a histogram of the out-of-fold predictions. Many predictions are near 0.0 or near 1.0; this means that in many cases the classifier's predictions have high confidence:","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12, 4))\nplt.hist(y_pred, bins=25, density=True)\nplt.title('Histogram of the oof predictions')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-17T12:42:37.696856Z","iopub.execute_input":"2022-06-17T12:42:37.697153Z","iopub.status.idle":"2022-06-17T12:42:37.9453Z","shell.execute_reply.started":"2022-06-17T12:42:37.697123Z","shell.execute_reply":"2022-06-17T12:42:37.944423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finally, we plot the calibration curve.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12, 4))\nax = plt.gca()\nax.plot([0, 1], [0, 1], \"w:\", label=\"Perfectly calibrated\")\nCalibrationDisplay.from_predictions(y_val, y_pred, n_bins=100, strategy='quantile', name=\"LGBMClassifier\", ax=ax)\nplt.title('Probability calibration')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-17T13:06:30.759875Z","iopub.execute_input":"2022-06-17T13:06:30.760208Z","iopub.status.idle":"2022-06-17T13:06:31.035021Z","shell.execute_reply.started":"2022-06-17T13:06:30.760171Z","shell.execute_reply":"2022-06-17T13:06:31.034139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission\nFor the submission, we re-train the model on the complete training data. We set n_estimators to the number of iterations which gave the best auc in cross-validation.","metadata":{}},{"cell_type":"code","source":"%%time\nprint(f\"{len(final_feature_list)} features\")\nX_train = train_df[final_feature_list]\ny_train = train_df.target\nmodel = my_booster(n_estimators=auc_peak)\nmodel.fit(X_train.values, y_train)\npred = model.predict_proba(test_df[final_feature_list].values)[:,1]\nsubmission = pd.DataFrame({\"id\":test_df.index, \"target\":pred})\nsubmission.to_csv('submission.csv', index=False)\nsubmission","metadata":{"execution":{"iopub.status.busy":"2022-06-17T13:26:46.894869Z","iopub.execute_input":"2022-06-17T13:26:46.895557Z","iopub.status.idle":"2022-06-17T13:54:17.813194Z","shell.execute_reply.started":"2022-06-17T13:26:46.895506Z","shell.execute_reply":"2022-06-17T13:54:17.812256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Credits:  \nhttps://www.kaggle.com/code/ambrosm/tpsmay22-gradient-boosting-quickstart/notebook","metadata":{}}]}