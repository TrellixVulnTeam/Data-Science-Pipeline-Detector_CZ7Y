{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# TPS MAY 22","metadata":{}},{"cell_type":"markdown","source":"> For this challenge, you are given (simulated) manufacturing control data and are tasked to predict whether the machine is in state 0 or state 1. The data has various feature interactions that may be important in determining the machine state.","metadata":{}},{"cell_type":"markdown","source":"This notebook includes:\n\n- A brief EDA to get familar with the dataset\n- Feature engineering:\n    - Dealing with the f_27 column by\n    - Introducing the unique_characters feature\n    - Adding 3 interaction features as implemented in [AmbrosM](https://www.kaggle.com/code/ambrosm/tpsmay22-advanced-keras) - inspired by [wti200](https://www.kaggle.com/code/wti200/analysing-interactions-with-shap)\n- Implementing a LightGBM model using LGBMs sklearn API \n- k-fold validation to estimate performance\n- Basic feature importance estimation\n- Inference on test data\n- A note on ROC AUC score","metadata":{}},{"cell_type":"markdown","source":"My full EDA can be found at: https://www.kaggle.com/code/cabaxiom/tps-may-22-in-depth-eda-feature-engineering\n\nMy notebook visualising feature interactions using target value: https://www.kaggle.com/code/cabaxiom/tps-may-22-visualising-feature-interaction\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set_style('darkgrid')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-20T20:17:26.9557Z","iopub.execute_input":"2022-05-20T20:17:26.956067Z","iopub.status.idle":"2022-05-20T20:17:28.084493Z","shell.execute_reply.started":"2022-05-20T20:17:26.955972Z","shell.execute_reply":"2022-05-20T20:17:28.083118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"../input/tabular-playground-series-may-2022/train.csv\")\ntest_df = pd.read_csv(\"../input/tabular-playground-series-may-2022/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-05-20T20:17:28.086204Z","iopub.execute_input":"2022-05-20T20:17:28.086469Z","iopub.status.idle":"2022-05-20T20:17:42.04406Z","shell.execute_reply.started":"2022-05-20T20:17:28.086432Z","shell.execute_reply":"2022-05-20T20:17:42.042829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(train_df.head())\ndisplay(test_df.head())","metadata":{"execution":{"iopub.status.busy":"2022-05-20T20:17:42.045238Z","iopub.execute_input":"2022-05-20T20:17:42.045493Z","iopub.status.idle":"2022-05-20T20:17:42.101606Z","shell.execute_reply.started":"2022-05-20T20:17:42.045463Z","shell.execute_reply":"2022-05-20T20:17:42.100632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_df.shape)\nprint(test_df.shape)\ntrain_df.info()","metadata":{"execution":{"iopub.status.busy":"2022-05-20T20:17:42.10411Z","iopub.execute_input":"2022-05-20T20:17:42.104338Z","iopub.status.idle":"2022-05-20T20:17:42.225091Z","shell.execute_reply.started":"2022-05-20T20:17:42.104312Z","shell.execute_reply":"2022-05-20T20:17:42.224036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Target","metadata":{}},{"cell_type":"code","source":"def val_count_df(df, column_name, sort=True):\n    value_count = df[column_name].value_counts(sort=sort).reset_index().rename(columns={column_name:\"Value Count\",\"index\":column_name}).set_index(column_name)\n    value_count[\"Percentage\"] = df[column_name].value_counts(sort=sort,normalize=True)*100\n    value_count = value_count.reset_index()\n    return value_count","metadata":{"execution":{"iopub.status.busy":"2022-05-20T20:17:42.22642Z","iopub.execute_input":"2022-05-20T20:17:42.226629Z","iopub.status.idle":"2022-05-20T20:17:42.232668Z","shell.execute_reply.started":"2022-05-20T20:17:42.226603Z","shell.execute_reply":"2022-05-20T20:17:42.231714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_count = val_count_df(train_df, \"target\")\ndisplay(target_count)\ntarget_count.set_index(\"target\").plot.pie(y=\"Value Count\", figsize=(10,7), legend=False, ylabel=\"\");","metadata":{"execution":{"iopub.status.busy":"2022-05-20T20:17:42.234426Z","iopub.execute_input":"2022-05-20T20:17:42.234745Z","iopub.status.idle":"2022-05-20T20:17:42.417239Z","shell.execute_reply.started":"2022-05-20T20:17:42.234714Z","shell.execute_reply":"2022-05-20T20:17:42.416311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Features","metadata":{}},{"cell_type":"code","source":"feature_cols = [col for col in train_df.columns if \"f_\" in col]\ndtype_cols = [train_df[i].dtype for i in feature_cols]\ndtypes = pd.DataFrame({\"features\":feature_cols, \"dtype\":dtype_cols})\nfloat_cols = dtypes.loc[dtypes[\"dtype\"] == \"float64\", \"features\"].values.tolist()\nint_cols = dtypes.loc[dtypes[\"dtype\"] == \"int64\", \"features\"].values.tolist()","metadata":{"execution":{"iopub.status.busy":"2022-05-20T20:17:42.419112Z","iopub.execute_input":"2022-05-20T20:17:42.419659Z","iopub.status.idle":"2022-05-20T20:17:42.432247Z","shell.execute_reply.started":"2022-05-20T20:17:42.419613Z","shell.execute_reply":"2022-05-20T20:17:42.430725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.subplots(figsize=(25,20))\nsns.heatmap(train_df.corr(),annot=True, cmap=\"RdYlGn\", fmt = '0.2f', vmin=-1, vmax=1, cbar=False);","metadata":{"execution":{"iopub.status.busy":"2022-05-20T20:17:42.435507Z","iopub.execute_input":"2022-05-20T20:17:42.436506Z","iopub.status.idle":"2022-05-20T20:17:49.896214Z","shell.execute_reply.started":"2022-05-20T20:17:42.436415Z","shell.execute_reply":"2022-05-20T20:17:49.893892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.subplots(figsize=(25,35))\nfor i, column in enumerate(float_cols):\n    plt.subplot(6,3,i+1)\n    sns.histplot(data=train_df, x=column, hue=\"target\")\n    plt.title(column)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T20:17:49.89775Z","iopub.execute_input":"2022-05-20T20:17:49.898286Z","iopub.status.idle":"2022-05-20T20:18:24.788899Z","shell.execute_reply.started":"2022-05-20T20:17:49.898236Z","shell.execute_reply":"2022-05-20T20:18:24.788045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.subplots(figsize=(25,30))\nfor i, column in enumerate(int_cols):\n    val_count = train_df[column].value_counts()\n    ax = plt.subplot(5,3,i+1)\n    #sns.barplot(x=val_count.index,y=val_count.values)\n    ax.bar(val_count.index, val_count.values)\n    ax.set_xticks(val_count.index)\n    plt.title(column)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T20:18:24.791279Z","iopub.execute_input":"2022-05-20T20:18:24.79151Z","iopub.status.idle":"2022-05-20T20:18:27.847048Z","shell.execute_reply.started":"2022-05-20T20:18:24.791481Z","shell.execute_reply":"2022-05-20T20:18:27.846105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## f_27","metadata":{}},{"cell_type":"code","source":"import string\nalphabet_upper = list(string.ascii_uppercase)\n\nchar_counts = []\nfor character in alphabet_upper:\n    char_counts.append(train_df[\"f_27\"].str.count(character).sum())\nchar_counts_df = pd.DataFrame({\"Character\": alphabet_upper, \"Character Count\": char_counts})\nchar_counts_df = char_counts_df.loc[char_counts_df[\"Character Count\"] > 0]\nprint(np.sum(char_counts)) #No other hidden characters\n\nplt.subplots(figsize=(20,7))\nsns.barplot(data = char_counts_df, x=\"Character\", y=\"Character Count\", color=\"blue\");\nplt.title(\"Total number of characters in f_27 - train\");","metadata":{"execution":{"iopub.status.busy":"2022-05-20T20:18:27.848336Z","iopub.execute_input":"2022-05-20T20:18:27.848575Z","iopub.status.idle":"2022-05-20T20:18:40.842744Z","shell.execute_reply.started":"2022-05-20T20:18:27.848545Z","shell.execute_reply":"2022-05-20T20:18:40.841986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"char_counts_df = char_counts_df.set_index(\"Character\", drop=False)\nfor i in range(10):\n    char_counts_df[\"character\"+str(i+1)] = train_df[\"f_27\"].str[i].value_counts()\nchar_counts_df = char_counts_df.fillna(0)\n\n\nf,ax = plt.subplots(figsize=(20,30))\ncharacter_cols = [i for i in char_counts_df.columns if \"character\" in i]\nfor i, column in enumerate(character_cols):\n    ax = plt.subplot(5,2,i+1)\n    ax = sns.barplot(data = char_counts_df, x=\"Character\", y=column, color=\"blue\");\n    plt.title(\"Character value counts in position: \" +str(i+1));\n    ax.set_ylabel(\"Character Count\")","metadata":{"execution":{"iopub.status.busy":"2022-05-20T20:18:40.84386Z","iopub.execute_input":"2022-05-20T20:18:40.844185Z","iopub.status.idle":"2022-05-20T20:18:47.958936Z","shell.execute_reply.started":"2022-05-20T20:18:40.844147Z","shell.execute_reply":"2022-05-20T20:18:47.958194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"**In this section I describe, explain and implement newly created features.**\n\n\nWe can use the string from f_27 to create new features.\n\nFirstly we can create a seperate feature for all 10 character positions in f_27. Instead of using the character values it may be more useful to encode the characters ordinally (A=0, B=1, C=2, ...) \n\nFor example the character in the first posititions could be","metadata":{}},{"cell_type":"code","source":"display(train_df[\"f_27\"].head(5)) #f_27 column\ndisplay(train_df[\"f_27\"].str[0].head(5)) # character is position 1\ndisplay(train_df[\"f_27\"].str[0].apply(lambda x: ord(x) - ord(\"A\")).head(5)) # Encode the characters ordinally","metadata":{"execution":{"iopub.status.busy":"2022-05-20T20:18:47.960004Z","iopub.execute_input":"2022-05-20T20:18:47.960412Z","iopub.status.idle":"2022-05-20T20:18:49.108822Z","shell.execute_reply.started":"2022-05-20T20:18:47.960381Z","shell.execute_reply":"2022-05-20T20:18:49.107503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Another important feature I found is the number of unique characters for the f_27 string. Forr example \"AABAABAABA\" has 2 unique characters (\"A\" and \"B\").","metadata":{}},{"cell_type":"code","source":"display(train_df[\"f_27\"].head(5)) #f_27 column\ntrain_df[\"f_27\"].apply(lambda x: len(set(x))).head(5) #number of unique characters","metadata":{"execution":{"iopub.status.busy":"2022-05-20T20:18:49.10991Z","iopub.execute_input":"2022-05-20T20:18:49.110131Z","iopub.status.idle":"2022-05-20T20:18:49.834646Z","shell.execute_reply.started":"2022-05-20T20:18:49.110105Z","shell.execute_reply":"2022-05-20T20:18:49.83386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are also some important interaction features as first shown by AmbrosM ([View](https://www.kaggle.com/code/ambrosm/tpsmay22-advanced-keras/notebook)) whose work was inspired by wti200's [Notebook](https://www.kaggle.com/code/wti200/analysing-interactions-with-shap).\n\nWe can view these important interactions in a simple scatter plot:","metadata":{}},{"cell_type":"code","source":"f,ax = plt.subplots(figsize=(20,20))\n\nplt.subplot(2,2,1)\nsns.scatterplot(data = train_df, x=\"f_00\", y=\"f_26\", hue=\"target\", s=2);\nplt.subplot(2,2,2)\nsns.scatterplot(data = train_df, x=\"f_01\", y=\"f_26\", hue=\"target\", s=2);\nplt.subplot(2,2,3)\nsns.scatterplot(data = train_df, x=\"f_02\", y=\"f_21\", hue=\"target\", s=2);\nplt.subplot(2,2,4)\nsns.scatterplot(data = train_df, x=\"f_05\", y=\"f_22\", hue=\"target\", s=2);","metadata":{"execution":{"iopub.status.busy":"2022-05-20T20:18:49.83618Z","iopub.execute_input":"2022-05-20T20:18:49.836959Z","iopub.status.idle":"2022-05-20T20:20:29.71755Z","shell.execute_reply.started":"2022-05-20T20:18:49.836914Z","shell.execute_reply":"2022-05-20T20:20:29.716442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We notice the graphs of f_00 vs f_26 and f_01 vs f_26 are very similar. Lets try adding f_00 and f_01 and then plotting against f_26:","metadata":{}},{"cell_type":"code","source":"train_df[\"f_00 + f_01\"] =  train_df[\"f_00\"] + train_df[\"f_01\"]\nf,ax = plt.subplots(figsize=(10,10))\nsns.scatterplot(data = train_df, x=\"f_00 + f_01\", y=\"f_26\", hue=\"target\", s=2);","metadata":{"execution":{"iopub.status.busy":"2022-05-20T20:20:29.718836Z","iopub.execute_input":"2022-05-20T20:20:29.719079Z","iopub.status.idle":"2022-05-20T20:20:54.964883Z","shell.execute_reply.started":"2022-05-20T20:20:29.71905Z","shell.execute_reply":"2022-05-20T20:20:54.963847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We notice a very unusual interaction creating three very distinct regions for each of these interactions. Lets try adding all involved features together and plotting them against a random number drawn from a normal distribution: ","metadata":{}},{"cell_type":"code","source":"train_df[\"f_00 + f_01 + f_26\"] = train_df[\"f_00\"] + train_df[\"f_01\"] + train_df[\"f_26\"]\ntrain_df[\"f_02 + f_21\"] = train_df[\"f_02\"] + train_df[\"f_21\"]\ntrain_df[\"f_05 + f_22\"] = train_df[\"f_05\"] + train_df[\"f_22\"]\ntrain_df[\"random\"] = np.random.randn(len(train_df))","metadata":{"execution":{"iopub.status.busy":"2022-05-20T20:20:54.966278Z","iopub.execute_input":"2022-05-20T20:20:54.966566Z","iopub.status.idle":"2022-05-20T20:20:55.018676Z","shell.execute_reply.started":"2022-05-20T20:20:54.966529Z","shell.execute_reply":"2022-05-20T20:20:55.017864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f,ax = plt.subplots(figsize=(20,20))\n\nplt.subplot(2,2,1)\nsns.scatterplot(data = train_df, y=\"f_00 + f_01 + f_26\", x=\"random\", hue=\"target\", s=2);\nplt.subplot(2,2,2)\nsns.scatterplot(data = train_df, y=\"f_02 + f_21\", x=\"random\", hue=\"target\", s=2);\nplt.subplot(2,2,3)\nsns.scatterplot(data = train_df, y=\"f_05 + f_22\", x=\"random\", hue=\"target\", s=2);","metadata":{"execution":{"iopub.status.busy":"2022-05-20T20:20:55.019584Z","iopub.execute_input":"2022-05-20T20:20:55.019795Z","iopub.status.idle":"2022-05-20T20:22:10.386242Z","shell.execute_reply.started":"2022-05-20T20:20:55.019752Z","shell.execute_reply":"2022-05-20T20:22:10.384868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This makes the interaction a lot easier to visualise. We can easily create a feature which returns a value of 1 if the point falls in the top region, a value of 0 if the point falls in the middle region and  and a value of -1 if the point falls in the bottom region. \n\nFor example if f_05 + f_22 > 5.1 then we want a feature that will return 1, and if  f_05 + f_22 < -5.4 return -1 - else return 0. We can do this with the following line from the next cell:\n\n`new_df['i_05_22'] = (df.f_22 + df.f_05 > 5.1).astype(int) - (df.f_22 + df.f_05 < -5.4).astype(int)`\n\nWe could just use the `f_05 + f_22` as a feature and the model will likely find the boundary but it also helps to explicitly state the boundaries by hand.\n\nIf you want to search for more interaction features I have plotted all possible features against each other in the following notebook:\n\nhttps://www.kaggle.com/code/cabaxiom/tps-may-22-visualising-feature-interaction","metadata":{}},{"cell_type":"code","source":"def feature_engineer(df):\n    new_df = df.copy()\n    \n    # Interaction features from AmbrosM https://www.kaggle.com/code/ambrosm/tpsmay22-advanced-keras/notebook\n    # Inspired by wti200 https://www.kaggle.com/code/wti200/analysing-interactions-with-shap\n    new_df['i_02_21'] = (df.f_21 + df.f_02 > 5.2).astype(int) - (df.f_21 + df.f_02 < -5.3).astype(int)\n    new_df['i_05_22'] = (df.f_22 + df.f_05 > 5.1).astype(int) - (df.f_22 + df.f_05 < -5.4).astype(int)\n    \n    i_00_01_26 = df.f_00 + df.f_01 + df.f_26\n    new_df['i_00_01_26'] = (i_00_01_26 > 5.0).astype(int) - (i_00_01_26 < -5.0).astype(int)\n    \n    #Good features\n    for i in range(10):\n        new_df[\"f_27_\"+str(i)] = new_df[\"f_27\"].str[i].apply(lambda x: ord(x) - ord(\"A\"))\n    \n    #good feature:\n    new_df[\"unique_characters\"] = new_df[\"f_27\"].apply(lambda x: len(set(x)))\n    \n    new_df = new_df.drop(columns=[\"f_27\", \"id\"])\n    return new_df","metadata":{"execution":{"iopub.status.busy":"2022-05-20T20:22:10.387458Z","iopub.execute_input":"2022-05-20T20:22:10.388051Z","iopub.status.idle":"2022-05-20T20:22:10.396991Z","shell.execute_reply.started":"2022-05-20T20:22:10.388007Z","shell.execute_reply":"2022-05-20T20:22:10.395892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntrain_df.drop(columns = [\"f_00 + f_01\", \"f_00 + f_01 + f_26\", \"f_02 + f_21\", \"f_05 + f_22\", \"random\"], inplace=True) # drop the features we made earlier for demonstration\ntrain_df = feature_engineer(train_df)\ntest_df = feature_engineer(test_df)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T20:22:10.398434Z","iopub.execute_input":"2022-05-20T20:22:10.398672Z","iopub.status.idle":"2022-05-20T20:22:25.653693Z","shell.execute_reply.started":"2022-05-20T20:22:10.398644Z","shell.execute_reply":"2022-05-20T20:22:25.652866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[\"unique_characters\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-05-20T20:22:25.655314Z","iopub.execute_input":"2022-05-20T20:22:25.656392Z","iopub.status.idle":"2022-05-20T20:22:25.675954Z","shell.execute_reply.started":"2022-05-20T20:22:25.65635Z","shell.execute_reply":"2022-05-20T20:22:25.674836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"from lightgbm import LGBMClassifier\nfrom sklearn.metrics import roc_auc_score, accuracy_score\nfrom sklearn.model_selection import StratifiedKFold","metadata":{"execution":{"iopub.status.busy":"2022-05-20T20:22:25.677184Z","iopub.execute_input":"2022-05-20T20:22:25.677864Z","iopub.status.idle":"2022-05-20T20:22:28.368478Z","shell.execute_reply.started":"2022-05-20T20:22:25.677823Z","shell.execute_reply":"2022-05-20T20:22:28.36756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = train_df[\"target\"]\nX = train_df.drop(columns=[\"target\"])\nX_test = test_df\nX.head(2)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T20:22:28.369672Z","iopub.execute_input":"2022-05-20T20:22:28.369917Z","iopub.status.idle":"2022-05-20T20:22:28.526114Z","shell.execute_reply.started":"2022-05-20T20:22:28.369888Z","shell.execute_reply":"2022-05-20T20:22:28.52501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = LGBMClassifier(n_estimators = 10000, learning_rate = 0.1, random_state=0, min_child_samples=90, num_leaves=150, max_bins=511, n_jobs=-1)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T20:22:28.529185Z","iopub.execute_input":"2022-05-20T20:22:28.530007Z","iopub.status.idle":"2022-05-20T20:22:28.535209Z","shell.execute_reply.started":"2022-05-20T20:22:28.529969Z","shell.execute_reply":"2022-05-20T20:22:28.534488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The variation in roc_auc score across folds is very small - so we save time and use 5-fold cross validation but only evaluate 2 of the 5 folds.","metadata":{}},{"cell_type":"code","source":"def k_fold_cv(model,X,y):\n    kfold = StratifiedKFold(n_splits = 5, shuffle=True, random_state = 0)\n\n    feature_imp, y_pred_list, y_true_list, acc_list, roc_list  = [],[],[],[],[]\n    for fold, (train_index, val_index) in enumerate(kfold.split(X, y)):\n        if fold < 2: # only evaluate 2/5 folds to save time\n            print(\"==fold==\", fold)\n            X_train = X.loc[train_index]\n            X_val = X.loc[val_index]\n\n            y_train = y.loc[train_index]\n            y_val = y.loc[val_index]\n\n            model.fit(X_train,y_train)\n\n            y_pred = model.predict_proba(X_val)[:,1]\n\n            y_pred_list = np.append(y_pred_list, y_pred)\n            y_true_list = np.append(y_true_list, y_val)\n\n            roc_list.append(roc_auc_score(y_val,y_pred))\n            acc_list.append(accuracy_score(y_pred.round(), y_val))\n            print(\"roc auc\", roc_auc_score(y_val,y_pred))\n            print('Acc', accuracy_score(y_pred.round(), y_val))\n\n            try:\n                feature_imp.append(model.feature_importances_)\n            except AttributeError: # if model does not have .feature_importances_ attribute\n                pass # returns empty list\n    return feature_imp, y_pred_list, y_true_list, acc_list, roc_list, X_val, y_val","metadata":{"execution":{"iopub.status.busy":"2022-05-09T12:42:17.914333Z","iopub.execute_input":"2022-05-09T12:42:17.91463Z","iopub.status.idle":"2022-05-09T12:42:17.926759Z","shell.execute_reply.started":"2022-05-09T12:42:17.914601Z","shell.execute_reply":"2022-05-09T12:42:17.925633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfeature_imp, y_pred_list, y_true_list, acc_list, roc_list, X_val, y_val = k_fold_cv(model=model,X=X,y=y)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T12:42:18.605165Z","iopub.execute_input":"2022-05-09T12:42:18.605633Z","iopub.status.idle":"2022-05-09T13:06:10.125042Z","shell.execute_reply.started":"2022-05-09T12:42:18.605595Z","shell.execute_reply":"2022-05-09T13:06:10.124178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Mean accuracy Score:\", np.mean(acc_list))\nprint(\"Mean ROC AUC Score:\", np.mean(roc_list))","metadata":{"execution":{"iopub.status.busy":"2022-05-05T14:23:42.162805Z","iopub.execute_input":"2022-05-05T14:23:42.16313Z","iopub.status.idle":"2022-05-05T14:23:42.169656Z","shell.execute_reply.started":"2022-05-05T14:23:42.163096Z","shell.execute_reply":"2022-05-05T14:23:42.168603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\ndef plot_cm(preds,true,ax=None):\n    cm = confusion_matrix(preds.round(), true)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm)#display_labels \n    disp.plot(ax=ax, colorbar=False, values_format = '.6g')\n    plt.grid(False)\n    return disp","metadata":{"execution":{"iopub.status.busy":"2022-05-05T14:23:44.495973Z","iopub.execute_input":"2022-05-05T14:23:44.496524Z","iopub.status.idle":"2022-05-05T14:23:44.50277Z","shell.execute_reply.started":"2022-05-05T14:23:44.496486Z","shell.execute_reply":"2022-05-05T14:23:44.501654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_cm(y_pred_list, y_true_list);","metadata":{"execution":{"iopub.status.busy":"2022-05-05T14:23:44.816299Z","iopub.execute_input":"2022-05-05T14:23:44.817424Z","iopub.status.idle":"2022-05-05T14:23:45.483583Z","shell.execute_reply.started":"2022-05-05T14:23:44.817383Z","shell.execute_reply":"2022-05-05T14:23:45.482634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_preds = pd.DataFrame({\"pred_prob=1\":y_pred_list, \"y_val\":y_true_list})\nf,ax = plt.subplots(figsize=(20,20))\nplt.subplot(2,1,1)\nax = sns.histplot(data=val_preds, x=\"pred_prob=1\", hue=\"y_val\", multiple=\"stack\", bins = 100)\n#Same plot \"zoomed in\"\nplt.subplot(2,1,2)\nax = sns.histplot(data=val_preds, x=\"pred_prob=1\", hue=\"y_val\", multiple=\"stack\", bins = 100)\nax.set_ylim([0,1000]);","metadata":{"execution":{"iopub.status.busy":"2022-05-05T14:23:47.103469Z","iopub.execute_input":"2022-05-05T14:23:47.103719Z","iopub.status.idle":"2022-05-05T14:23:49.30168Z","shell.execute_reply.started":"2022-05-05T14:23:47.103694Z","shell.execute_reply":"2022-05-05T14:23:49.300364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Importance","metadata":{}},{"cell_type":"code","source":"def fold_feature_importances(model_importances, column_names, model_name, n_folds = 5, ax=None, boxplot=False):\n    importances_df = pd.DataFrame({\"feature_cols\": column_names, \"importances_fold_0\": model_importances[0]})\n    for i in range(1,n_folds):\n        importances_df[\"importances_fold_\"+str(i)] = model_importances[i]\n    importances_df[\"importances_fold_median\"] = importances_df.drop(columns=[\"feature_cols\"]).median(axis=1)\n    importances_df = importances_df.sort_values(by=\"importances_fold_median\", ascending=False)\n    if ax == None:\n        f, ax = plt.subplots(figsize=(15, 25))\n    if boxplot == False:\n        ax = sns.barplot(data = importances_df, x = \"importances_fold_median\", y=\"feature_cols\", color=\"blue\")\n        ax.set_xlabel(\"Median Feature importance across all folds\");\n    elif boxplot == True:\n        importances_df = importances_df.drop(columns=\"importances_fold_median\")\n        importances_df = importances_df.set_index(\"feature_cols\").stack().reset_index().rename(columns={0:\"feature_importance\"})\n        ax = sns.boxplot(data = importances_df, y = \"feature_cols\", x=\"feature_importance\", color=\"blue\", orient=\"h\")\n        ax.set_xlabel(\"Feature importance across all folds\");\n    plt.title(model_name)\n    ax.set_ylabel(\"Feature Columns\")\n    return ax","metadata":{"execution":{"iopub.status.busy":"2022-05-05T14:23:56.308714Z","iopub.execute_input":"2022-05-05T14:23:56.309Z","iopub.status.idle":"2022-05-05T14:23:56.319413Z","shell.execute_reply.started":"2022-05-05T14:23:56.30897Z","shell.execute_reply":"2022-05-05T14:23:56.3184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, ax = plt.subplots(figsize=(15, 20))\nfold_feature_importances(model_importances = feature_imp, column_names = X_val.columns, model_name = \"LGBM\", n_folds = 2, ax=ax, boxplot=False);","metadata":{"execution":{"iopub.status.busy":"2022-05-05T14:23:56.540789Z","iopub.execute_input":"2022-05-05T14:23:56.541187Z","iopub.status.idle":"2022-05-05T14:23:57.188551Z","shell.execute_reply.started":"2022-05-05T14:23:56.54116Z","shell.execute_reply":"2022-05-05T14:23:57.187642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"def pred_test():\n    pred_list = []\n    for seed in range(5):\n        model = LGBMClassifier(n_estimators = 10000, learning_rate = 0.1, min_child_samples=90, num_leaves=150, max_bins=511, random_state=seed, n_jobs=-1)\n        model.fit(X,y)\n\n        preds = model.predict_proba(X_test)[:,1]\n        pred_list.append(preds)\n    return pred_list","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:21:04.568142Z","iopub.execute_input":"2022-05-05T15:21:04.568883Z","iopub.status.idle":"2022-05-05T15:21:04.574927Z","shell.execute_reply.started":"2022-05-05T15:21:04.568844Z","shell.execute_reply":"2022-05-05T15:21:04.573794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_list = pred_test()\npred_df = pd.DataFrame(pred_list).T\npred_df = pred_df.rank()\npred_df[\"mean\"] = pred_df.mean(axis=1)\npred_df","metadata":{"execution":{"iopub.status.busy":"2022-05-04T15:48:26.206665Z","iopub.execute_input":"2022-05-04T15:48:26.206942Z","iopub.status.idle":"2022-05-04T18:41:55.227249Z","shell.execute_reply.started":"2022-05-04T15:48:26.206895Z","shell.execute_reply":"2022-05-04T18:41:55.225968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_sub = pd.read_csv(\"../input/tabular-playground-series-may-2022/sample_submission.csv\")\nsample_sub[\"target\"] = pred_df[\"mean\"]\nsample_sub","metadata":{"execution":{"iopub.status.busy":"2022-05-04T18:41:55.229145Z","iopub.execute_input":"2022-05-04T18:41:55.229467Z","iopub.status.idle":"2022-05-04T18:41:55.515735Z","shell.execute_reply.started":"2022-05-04T18:41:55.229414Z","shell.execute_reply":"2022-05-04T18:41:55.514809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Question:**\n\nIf we are predicting probabilities, why do these target scores not fall between 0 and 1?\n\n**Answer:**\n\nThe evaluation metric is ROC AUC.\n\nOne way of interpreting AUC is: **the probability that the model ranks a random positive example more highly than a random negative example.**\n\nOur model can be used to output the predicted probability. The absolute values of the predictions do not matter - it does not matter how much higher the random positive example is than the random negative example, we are only interested in the rankings between them.\n\nIn other words the ROC AUC score is scale invariant. **AUC measures how well the predictions are ranked**.\n\nTherefore we can use the predicted probability ranks rather than the predicted probabilities when calculating the ROC AUC score.\n\n\nExample:","metadata":{}},{"cell_type":"code","source":"pred_df = pd.DataFrame(y_pred_list, columns=[\"pred_prob\"])\npred_df[\"rank\"] = pred_df.rank()\ndisplay(pred_df.head(10))\n\nprint(\"roc auc using prediction probabilities:\", roc_auc_score(y_true_list, pred_df[\"pred_prob\"]))\nprint(\"roc auc using predicted probabilities ranks:\", roc_auc_score(y_true_list, pred_df[\"rank\"]))","metadata":{"execution":{"iopub.status.busy":"2022-05-04T18:41:55.517737Z","iopub.execute_input":"2022-05-04T18:41:55.51857Z","iopub.status.idle":"2022-05-04T18:41:55.932284Z","shell.execute_reply.started":"2022-05-04T18:41:55.518507Z","shell.execute_reply":"2022-05-04T18:41:55.931267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It may be better to use ranks rather than probabilities as it allows us to combine multiple sets of predictions together without bias towards one set of predictions.","metadata":{}},{"cell_type":"code","source":"sample_sub.to_csv('submission.csv', index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Next steps","metadata":{}},{"cell_type":"markdown","source":"- Further feature engineering, such as searching for more interaction features - you may find this notebook useful for this: https://www.kaggle.com/code/cabaxiom/tps-may-22-visualising-feature-interaction.\n- Hyperparameter tuning.\n- Considering using a different Gradient Boosted Decision Tree algorithm (XGBoost, CatBoost, [SKLearn's HistGradientBoostingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.HistGradientBoostingClassifier.html),  [SKLearn's GradientBoostingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier)).\n- Consider not using the LightGBMs SKLearn API - LGBMs SKlearns API works well but I find it can be a little less flexible / throws warnings.\n- Consider implementing both a GBDT and a NN model e.g. https://www.kaggle.com/code/ambrosm/tpsmay22-advanced-keras.","metadata":{}}]}