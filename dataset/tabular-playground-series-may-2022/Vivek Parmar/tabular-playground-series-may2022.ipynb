{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-28T09:45:20.370584Z","iopub.execute_input":"2022-05-28T09:45:20.371181Z","iopub.status.idle":"2022-05-28T09:45:20.406021Z","shell.execute_reply.started":"2022-05-28T09:45:20.371071Z","shell.execute_reply":"2022-05-28T09:45:20.405229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for time of training\nfrom time import time\n\n# training the lightGBM model\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier\n\n\n# evaluation metrics\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import make_scorer\n\n# Skopt functions\nfrom skopt import BayesSearchCV\nfrom skopt.callbacks import DeadlineStopper, DeltaYStopper\nfrom skopt.space import Real, Categorical, Integer\n\n# selection better model \nfrom sklearn.model_selection import StratifiedKFold\nimport pprint","metadata":{"execution":{"iopub.status.busy":"2022-05-28T09:45:20.4075Z","iopub.execute_input":"2022-05-28T09:45:20.407871Z","iopub.status.idle":"2022-05-28T09:45:22.893473Z","shell.execute_reply.started":"2022-05-28T09:45:20.407841Z","shell.execute_reply":"2022-05-28T09:45:22.892529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# reading data using pandas\ntrain_data = pd.read_csv('/kaggle/input/tabular-playground-series-may-2022/train.csv')\ntest_data = pd.read_csv('/kaggle/input/tabular-playground-series-may-2022/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-05-28T09:45:22.894781Z","iopub.execute_input":"2022-05-28T09:45:22.895063Z","iopub.status.idle":"2022-05-28T09:45:39.553384Z","shell.execute_reply.started":"2022-05-28T09:45:22.895029Z","shell.execute_reply":"2022-05-28T09:45:39.552526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print the first 5 rows of the train_dataset\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-28T09:45:39.554473Z","iopub.execute_input":"2022-05-28T09:45:39.554686Z","iopub.status.idle":"2022-05-28T09:45:39.596781Z","shell.execute_reply.started":"2022-05-28T09:45:39.55466Z","shell.execute_reply":"2022-05-28T09:45:39.596069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# column name\ntrain_data.columns","metadata":{"execution":{"iopub.status.busy":"2022-05-28T09:45:39.598897Z","iopub.execute_input":"2022-05-28T09:45:39.599363Z","iopub.status.idle":"2022-05-28T09:45:39.605957Z","shell.execute_reply.started":"2022-05-28T09:45:39.599326Z","shell.execute_reply":"2022-05-28T09:45:39.604935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking the datatype of every column\ntrain_data.dtypes","metadata":{"execution":{"iopub.status.busy":"2022-05-28T09:45:39.607588Z","iopub.execute_input":"2022-05-28T09:45:39.60785Z","iopub.status.idle":"2022-05-28T09:45:39.62224Z","shell.execute_reply.started":"2022-05-28T09:45:39.607818Z","shell.execute_reply":"2022-05-28T09:45:39.621033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check the classes of the 'target' column\ntrain_data['target'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-05-28T09:45:39.624344Z","iopub.execute_input":"2022-05-28T09:45:39.624998Z","iopub.status.idle":"2022-05-28T09:45:39.655534Z","shell.execute_reply.started":"2022-05-28T09:45:39.624949Z","shell.execute_reply":"2022-05-28T09:45:39.654505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check for any null values found or not\ntrain_data.isnull().sum().sum()","metadata":{"execution":{"iopub.status.busy":"2022-05-28T09:45:39.657151Z","iopub.execute_input":"2022-05-28T09:45:39.657488Z","iopub.status.idle":"2022-05-28T09:45:39.815657Z","shell.execute_reply.started":"2022-05-28T09:45:39.65739Z","shell.execute_reply":"2022-05-28T09:45:39.814996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert f_27 column into the numeric feature\ndef convert_f27_numeric(df):\n    # convert object dtype into categorical variables\n    categories = [chr(c) for c in range(65, 85)]\n\n    for i in range(0, 10): \n        df[f'p_{i}'] = list(df['f_27'].map(lambda x: x[i]))\n        df[f'p_{i}'] = pd.Categorical(df[f'p_{i}'], categories=categories)\n\n    # mapping the alphabets number into categories\n    map_letters = {\"A\":0 , \"B\":1 ,\"C\":2 ,\"D\":3 ,\"E\":4 ,\"F\":5 ,\"G\":6 ,\"H\":7 ,\"I\":8 ,\"J\":9 ,\"K\":10 ,\"L\":11 ,\"M\":12 ,\"N\":13 ,\"O\":14,\"P\":15,\"Q\":16 ,\"R\":17 ,\"S\":18 ,\"T\":19}\n\n    for i in range(10):\n        df[f'encode_col_{i}'] = df.f_27.str.get(i).map(map_letters)\n    \n    for letter in list(map_letters):\n        df[f\"Count_{letter}\"] = df[\"f_27\"].str.count(letter)\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-05-28T09:45:39.816959Z","iopub.execute_input":"2022-05-28T09:45:39.817357Z","iopub.status.idle":"2022-05-28T09:45:39.826789Z","shell.execute_reply.started":"2022-05-28T09:45:39.817325Z","shell.execute_reply":"2022-05-28T09:45:39.825538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = convert_f27_numeric(train_data)\n\n# prepares X and y variable \nX = train_data.drop(columns=['target', 'f_27'], axis=1)\ny = train_data['target']","metadata":{"execution":{"iopub.status.busy":"2022-05-28T09:45:39.828242Z","iopub.execute_input":"2022-05-28T09:45:39.828492Z","iopub.status.idle":"2022-05-28T09:46:06.682163Z","shell.execute_reply.started":"2022-05-28T09:45:39.828463Z","shell.execute_reply":"2022-05-28T09:46:06.68124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# wrapper for measuring time and performances of different optmizers\ndef performance_report(optimizer, X, y, title=\"model\", callbacks=None):\n    start = time()\n    \n    if callbacks is not None:\n        optimizer.fit(X, y, callback=callbacks)\n    else:\n        optimizer.fit(X, y)\n        \n    d=pd.DataFrame(optimizer.cv_results_)\n    best_score = optimizer.best_score_\n    best_score_std = d.iloc[optimizer.best_index_].std_test_score\n    best_params = optimizer.best_params_\n    \n    print((title + \" took %.2f seconds,  candidates checked: %d, best CV score: %.3f \"\n           + u\"\\u00B1\"+\" %.3f\") % (time() - start, \n                                   len(optimizer.cv_results_['params']),\n                                   best_score,\n                                   best_score_std))    \n    print('Best parameters:')\n    pprint.pprint(best_params)\n    print()\n    return best_params","metadata":{"execution":{"iopub.status.busy":"2022-05-28T09:46:06.683516Z","iopub.execute_input":"2022-05-28T09:46:06.683779Z","iopub.status.idle":"2022-05-28T09:46:06.692075Z","shell.execute_reply.started":"2022-05-28T09:46:06.683751Z","shell.execute_reply":"2022-05-28T09:46:06.691069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Converting average precision score into a scorer suitable for model selection\nroc_auc = make_scorer(roc_auc_score, greater_is_better=True, needs_threshold=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T09:46:06.693352Z","iopub.execute_input":"2022-05-28T09:46:06.693714Z","iopub.status.idle":"2022-05-28T09:46:06.70498Z","shell.execute_reply.started":"2022-05-28T09:46:06.693678Z","shell.execute_reply":"2022-05-28T09:46:06.703988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# compiling the LGBMClassifier with some parameters\nclf_model = LGBMClassifier(\n    objective= 'binary',\n    metric= \"auc\",\n    boosting= 'gbdt',\n    device = 'cpu',\n    n_jobs=-1, \n    verbose=-1,\n    random_state=0)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T09:46:06.706382Z","iopub.execute_input":"2022-05-28T09:46:06.707128Z","iopub.status.idle":"2022-05-28T09:46:06.718814Z","shell.execute_reply.started":"2022-05-28T09:46:06.707087Z","shell.execute_reply":"2022-05-28T09:46:06.717699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# declare parameters names for hyperparameters tuning purpose\nsearch_spaces = {\n    'learning_rate': Real(0.01, 1.0, 'log-uniform'),     # Boosting learning rate\n    'n_estimators': Integer(30, 5000),                   # Number of boosted trees to fit\n    'num_leaves': Integer(2, 512),                       # Maximum tree leaves for base learners\n    'max_depth': Integer(-1, 256),                       # Maximum tree depth for base learners, <=0 means no limit\n    'min_child_samples': Integer(1, 256),                # Minimal number of data in one leaf\n    'max_bin': Integer(100, 1000),                       # Max number of bins that feature values will be bucketed\n    'subsample': Real(0.01, 1.0, 'uniform'),             # Subsample ratio of the training instance\n    'subsample_freq': Integer(0, 10),                    # Frequency of subsample, <=0 means no enable\n    'colsample_bytree': Real(0.01, 1.0, 'uniform'),      # Subsample ratio of columns when constructing each tree\n    'min_child_weight': Real(0.01, 10.0, 'uniform'),     # Minimum sum of instance weight (hessian) needed in a child (leaf)\n    'reg_lambda': Real(1e-9, 100.0, 'log-uniform'),      # L2 regularization\n    'reg_alpha': Real(1e-9, 100.0, 'log-uniform'),       # L1 regularization\n    'scale_pos_weight': Real(1.0, 500.0, 'uniform'),     # Weighting of the minority class (Only for binary classification)\n}","metadata":{"execution":{"iopub.status.busy":"2022-05-28T09:46:06.722035Z","iopub.execute_input":"2022-05-28T09:46:06.722899Z","iopub.status.idle":"2022-05-28T09:46:06.748708Z","shell.execute_reply.started":"2022-05-28T09:46:06.722858Z","shell.execute_reply":"2022-05-28T09:46:06.747332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cross validation method for selecting better model\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T09:46:06.750236Z","iopub.execute_input":"2022-05-28T09:46:06.750647Z","iopub.status.idle":"2022-05-28T09:46:06.756029Z","shell.execute_reply.started":"2022-05-28T09:46:06.750606Z","shell.execute_reply":"2022-05-28T09:46:06.755099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Baayes CV for tuning the hyperparmeters\nopt = BayesSearchCV(estimator=clf_model,                                    \n                    search_spaces=search_spaces,                      \n                    scoring=roc_auc,                                  \n                    cv=skf,                                           \n                    n_iter=3000,                                      # max number of trials\n                    n_points=3,                                       # number of hyperparameter sets evaluated at the same time\n                    n_jobs=-1,                                        # number of jobs\n                    iid=False,                                        # if not iid it optimizes on the cv score\n                    return_train_score=False,                         \n                    refit=False,                                      \n                    optimizer_kwargs={'base_estimator': 'GP'},        # optmizer parameters: we use Gaussian Process (GP)\n                    random_state=0)           ","metadata":{"execution":{"iopub.status.busy":"2022-05-28T09:46:06.757878Z","iopub.execute_input":"2022-05-28T09:46:06.758509Z","iopub.status.idle":"2022-05-28T09:46:06.771241Z","shell.execute_reply.started":"2022-05-28T09:46:06.758461Z","shell.execute_reply":"2022-05-28T09:46:06.770539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We stop if the gain of the optimization becomes too small\noverdone_control = DeltaYStopper(delta=0.0001)               \n\n# We impose a time limit (60 minutes)\ntime_limit_control = DeadlineStopper(total_time=60 * 60)     \n\nbest_params = performance_report(opt, X, y,'LightGBM', \n                          callbacks=[overdone_control, time_limit_control])","metadata":{"execution":{"iopub.status.busy":"2022-05-28T09:46:06.772527Z","iopub.execute_input":"2022-05-28T09:46:06.772837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#compile model with the best parameters\nmodel = LGBMClassifier(\n    device = 'cpu',\n    boosting_type='gbdt',\n    metric='auc',\n    objective='binary',\n    n_jobs=1, \n    verbose=-1,\n    random_state=0,\n    **best_params)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train model using best parameters\nmodel.fit(X, y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert test_data 'f_27' into the numeric \ntest_data = convert_f27_numeric(test_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# drop column\ntest_data = test_data.drop(columns=['f_27'], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict the test_data\npredicted_data = model.predict_proba(test_data)[:,1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preparing the submission dataframe\nsubmission_df = pd.DataFrame()\nsubmission_df['id'] = test_data['id']\nsubmission_df['target'] = predicted_data\nsubmission_df.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}