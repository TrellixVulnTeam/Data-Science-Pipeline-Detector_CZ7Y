{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn import model_selection\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\n\nfrom matplotlib.ticker import MaxNLocator\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error,mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_auc_score, roc_curve\nimport datetime\nimport scipy.stats\nimport math\nimport random\nimport tensorflow.compat.v1.keras.backend as K \nimport tensorflow as tf \ntf.compat.v1.disable_eager_execution()\nfrom tensorflow import keras\n\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Activation,Input, InputLayer, Dense, BatchNormalization, Dropout,LayerNormalization\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-11T21:16:58.443269Z","iopub.execute_input":"2022-05-11T21:16:58.443703Z","iopub.status.idle":"2022-05-11T21:17:06.692767Z","shell.execute_reply.started":"2022-05-11T21:16:58.443581Z","shell.execute_reply":"2022-05-11T21:17:06.691848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/tabular-playground-series-may-2022/train.csv')\ntest=pd.read_csv('/kaggle/input/tabular-playground-series-may-2022/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:17:06.694231Z","iopub.execute_input":"2022-05-11T21:17:06.694618Z","iopub.status.idle":"2022-05-11T21:17:21.641395Z","shell.execute_reply.started":"2022-05-11T21:17:06.694575Z","shell.execute_reply":"2022-05-11T21:17:21.640563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:17:21.642576Z","iopub.execute_input":"2022-05-11T21:17:21.642793Z","iopub.status.idle":"2022-05-11T21:17:21.681375Z","shell.execute_reply.started":"2022-05-11T21:17:21.642766Z","shell.execute_reply":"2022-05-11T21:17:21.680532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:17:21.68338Z","iopub.execute_input":"2022-05-11T21:17:21.683615Z","iopub.status.idle":"2022-05-11T21:17:21.689247Z","shell.execute_reply.started":"2022-05-11T21:17:21.683589Z","shell.execute_reply":"2022-05-11T21:17:21.688442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:17:21.690443Z","iopub.execute_input":"2022-05-11T21:17:21.690823Z","iopub.status.idle":"2022-05-11T21:17:21.703258Z","shell.execute_reply.started":"2022-05-11T21:17:21.690788Z","shell.execute_reply":"2022-05-11T21:17:21.702603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:17:21.704769Z","iopub.execute_input":"2022-05-11T21:17:21.705294Z","iopub.status.idle":"2022-05-11T21:17:21.887696Z","shell.execute_reply.started":"2022-05-11T21:17:21.705232Z","shell.execute_reply":"2022-05-11T21:17:21.886793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:17:21.889148Z","iopub.execute_input":"2022-05-11T21:17:21.88948Z","iopub.status.idle":"2022-05-11T21:17:22.041931Z","shell.execute_reply.started":"2022-05-11T21:17:21.889436Z","shell.execute_reply":"2022-05-11T21:17:22.041324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train['f_27'].value_counts())\nprint(train['f_27'].nunique())","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:17:22.043086Z","iopub.execute_input":"2022-05-11T21:17:22.043436Z","iopub.status.idle":"2022-05-11T21:17:23.171824Z","shell.execute_reply.started":"2022-05-11T21:17:22.043407Z","shell.execute_reply":"2022-05-11T21:17:23.170988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def label_encode_columns(df, columns, encoders=None):\n\tif encoders is None:\n\t\tencoders = {}\n\t\n\t\tfor col in columns:\n\n\t\t\tunique_values = list(df[col].unique())\n\t\t\tunique_values.append('Unseen')\n\t\t\tle = LabelEncoder().fit(unique_values)\n\t\t\tdf[col] = le.transform(df[col])\n\t\t\tencoders[col] = le\n\t\n\telse:\n\t\tfor col in columns:\n\t\t\tle = encoders.get(col)\n\t\t\tdf[col] = [x if x in le.classes_ else 'Unseen' for x in df[col]]\n\t\t\tdf[col] = le.transform(df[col])\n\n\treturn df, encoders","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:17:23.174217Z","iopub.execute_input":"2022-05-11T21:17:23.175017Z","iopub.status.idle":"2022-05-11T21:17:23.182735Z","shell.execute_reply.started":"2022-05-11T21:17:23.174961Z","shell.execute_reply":"2022-05-11T21:17:23.181782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def processCol_str(df,colName,n):\n    Newtrain=df[colName].str.split('',n=0,expand=True)\n    for ncol in np.arange(1,n+1):\n        df[colName+'_'+ str(ncol)]=Newtrain[ncol]\n        \n    df=df.drop(colName,axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:17:23.183968Z","iopub.execute_input":"2022-05-11T21:17:23.184206Z","iopub.status.idle":"2022-05-11T21:17:23.196732Z","shell.execute_reply.started":"2022-05-11T21:17:23.184177Z","shell.execute_reply":"2022-05-11T21:17:23.195858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"processCol_str(train,'f_27',10)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:17:23.199911Z","iopub.execute_input":"2022-05-11T21:17:23.200559Z","iopub.status.idle":"2022-05-11T21:17:28.726489Z","shell.execute_reply.started":"2022-05-11T21:17:23.200514Z","shell.execute_reply":"2022-05-11T21:17:28.725718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"processCol_str(test,'f_27',10)\ncatcol=[ 'f_27_1', 'f_27_2', 'f_27_3',\n       'f_27_4', 'f_27_5', 'f_27_6', 'f_27_7', 'f_27_8', 'f_27_9', 'f_27_10']","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:17:28.727801Z","iopub.execute_input":"2022-05-11T21:17:28.728216Z","iopub.status.idle":"2022-05-11T21:17:33.100249Z","shell.execute_reply.started":"2022-05-11T21:17:28.728185Z","shell.execute_reply":"2022-05-11T21:17:33.099594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntrain,encoder = label_encode_columns(train,catcol)\ntest,encoder=label_encode_columns(test,catcol,encoder)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:17:33.102711Z","iopub.execute_input":"2022-05-11T21:17:33.103153Z","iopub.status.idle":"2022-05-11T21:18:15.613799Z","shell.execute_reply.started":"2022-05-11T21:17:33.10312Z","shell.execute_reply":"2022-05-11T21:18:15.612992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y=train['target']\nX=train.drop(['id','target'],axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:18:15.614888Z","iopub.execute_input":"2022-05-11T21:18:15.61519Z","iopub.status.idle":"2022-05-11T21:18:15.869043Z","shell.execute_reply.started":"2022-05-11T21:18:15.615151Z","shell.execute_reply":"2022-05-11T21:18:15.868084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=train\n","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:18:15.872092Z","iopub.execute_input":"2022-05-11T21:18:15.872441Z","iopub.status.idle":"2022-05-11T21:18:15.875652Z","shell.execute_reply.started":"2022-05-11T21:18:15.872399Z","shell.execute_reply":"2022-05-11T21:18:15.875076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-11T21:18:15.876624Z","iopub.execute_input":"2022-05-11T21:18:15.877169Z","iopub.status.idle":"2022-05-11T21:18:15.907599Z","shell.execute_reply.started":"2022-05-11T21:18:15.877133Z","shell.execute_reply":"2022-05-11T21:18:15.906838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.datasets import make_regression\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_regression\n# generate dataset\n#X, y = make_regression(n_samples=100, n_features=100, n_informative=10)\n# define feature selection\nfs = SelectKBest(score_func=f_regression, k=40)\n# apply feature selection\nX_selected = fs.fit_transform(X, y)\nprint(X_selected.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T22:21:19.548568Z","iopub.execute_input":"2022-05-11T22:21:19.54891Z","iopub.status.idle":"2022-05-11T22:21:20.082973Z","shell.execute_reply.started":"2022-05-11T22:21:19.548863Z","shell.execute_reply":"2022-05-11T22:21:20.081914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(fs.get_feature_names_out())\nfs.scores_","metadata":{"execution":{"iopub.status.busy":"2022-05-11T22:21:21.506887Z","iopub.execute_input":"2022-05-11T22:21:21.507392Z","iopub.status.idle":"2022-05-11T22:21:21.515664Z","shell.execute_reply.started":"2022-05-11T22:21:21.507338Z","shell.execute_reply":"2022-05-11T22:21:21.514921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(features)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T22:21:30.195117Z","iopub.execute_input":"2022-05-11T22:21:30.195749Z","iopub.status.idle":"2022-05-11T22:21:30.202693Z","shell.execute_reply.started":"2022-05-11T22:21:30.195704Z","shell.execute_reply":"2022-05-11T22:21:30.201801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features=[ 'f_00', 'f_01', 'f_02', 'f_03', 'f_04', 'f_05', 'f_06', 'f_07',\n       'f_08', 'f_09', 'f_10', 'f_11', 'f_12', 'f_13', 'f_14', 'f_15', 'f_16',\n       'f_17', 'f_18', 'f_19', 'f_20', 'f_21', 'f_22', 'f_23', 'f_24', 'f_25',\n       'f_26', 'f_28', 'f_29', 'f_30', 'f_27_1', 'f_27_2', 'f_27_3', 'f_27_4',\n       'f_27_5', 'f_27_6', 'f_27_7', 'f_27_8', 'f_27_9', 'f_27_10']","metadata":{"execution":{"iopub.status.busy":"2022-05-11T23:51:25.533161Z","iopub.execute_input":"2022-05-11T23:51:25.53349Z","iopub.status.idle":"2022-05-11T23:51:25.5414Z","shell.execute_reply.started":"2022-05-11T23:51:25.533458Z","shell.execute_reply":"2022-05-11T23:51:25.540675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_history(history, *, n_epochs=None, plot_lr=False, title=None, bottom=None, top=None):\n    \"\"\"Plot (the last n_epochs epochs of) the training history\n    \n    Plots loss and optionally val_loss and lr.\"\"\"\n    plt.figure(figsize=(15, 6))\n    from_epoch = 0 if n_epochs is None else max(len(history['loss']) - n_epochs, 0)\n    \n    # Plot training and validation losses\n    plt.plot(np.arange(from_epoch, len(history['loss'])), history['loss'][from_epoch:], label='Training loss')\n    try:\n        plt.plot(np.arange(from_epoch, len(history['loss'])), history['val_loss'][from_epoch:], label='Validation loss')\n        best_epoch = np.argmin(np.array(history['val_loss']))\n        best_val_loss = history['val_loss'][best_epoch]\n        if best_epoch >= from_epoch:\n            plt.scatter([best_epoch], [best_val_loss], c='r', label=f'Best val_loss = {best_val_loss:.5f}')\n        if best_epoch > 0:\n            almost_epoch = np.argmin(np.array(history['val_loss'])[:best_epoch])\n            almost_val_loss = history['val_loss'][almost_epoch]\n            if almost_epoch >= from_epoch:\n                plt.scatter([almost_epoch], [almost_val_loss], c='orange', label='Second best val_loss')\n    except KeyError:\n        pass\n    if bottom is not None: plt.ylim(bottom=bottom)\n    if top is not None: plt.ylim(top=top)\n    plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend(loc='lower left')\n    if title is not None: plt.title(title)\n        \n    # Plot learning rate\n    if plot_lr and 'lr' in history:\n        ax2 = plt.gca().twinx()\n        ax2.plot(np.arange(from_epoch, len(history['lr'])), np.array(history['lr'][from_epoch:]), color='g', label='Learning rate')\n        ax2.set_ylabel('Learning rate')\n        ax2.legend(loc='upper right')\n        \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-11T23:51:28.509029Z","iopub.execute_input":"2022-05-11T23:51:28.509388Z","iopub.status.idle":"2022-05-11T23:51:28.526535Z","shell.execute_reply.started":"2022-05-11T23:51:28.509353Z","shell.execute_reply":"2022-05-11T23:51:28.525553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def my_model(len_shape):\n    \"\"\"Simple sequential neural network with three hidden layers.\n    \n    Returns a (not yet compiled) instance of tensorflow.keras.models.Model.\n    \"\"\"\n    activation = 'swish'\n    inputs = Input(shape=(len_shape))\n    \n    \n    x = Dense(256,\n              kernel_regularizer=tf.keras.regularizers.l2(30e-6),\n               use_bias = True,\n              activation=activation,\n             )(inputs)\n    x = Dense(128, kernel_regularizer=tf.keras.regularizers.l2(30e-6),\n              use_bias = True,\n              activation=activation,\n             )(x)\n    x = Dense(64, kernel_regularizer=tf.keras.regularizers.l2(30e-6),\n              use_bias = True,\n              activation=activation,\n             )(x)\n    x = Dense(64, kernel_regularizer=tf.keras.regularizers.l2(30e-6),\n              use_bias = True,\n              activation=activation,\n             )(x)\n    x = Dense(32, kernel_regularizer=tf.keras.regularizers.l2(30e-6),\n              use_bias = True,\n              activation=activation,\n             )(x)\n    x = Dense(16, kernel_regularizer=tf.keras.regularizers.l2(30e-6),\n              activation=activation,\n             )(x)\n    x = Dense(1,\n              use_bias = True,\n              kernel_regularizer=tf.keras.regularizers.l2(30e-6),\n              activation='sigmoid',\n             )(x)\n    model = Model(inputs, x)\n    return model\n\nplot_model(my_model(40), show_layer_names=True, show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T00:04:02.166626Z","iopub.execute_input":"2022-05-12T00:04:02.16696Z","iopub.status.idle":"2022-05-12T00:04:02.458986Z","shell.execute_reply.started":"2022-05-12T00:04:02.166922Z","shell.execute_reply":"2022-05-12T00:04:02.457825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##### %%time\n# Cross-validation of the classifier\n\nEPOCHS = 200\nEPOCHS_COSINEDECAY = 100\nVERBOSE = 0 # set to 0 for less output, or to 2 for more output\nDIAGRAMS = True\nUSE_PLATEAU = False\nBATCH_SIZE = 4096\nCOMPUTE_LSTM_IMPORTANCE=True\n# see https://keras.io/getting_started/faq/#how-can-i-obtain-reproducible-results-using-keras-during-development\nnp.random.seed(1)\nrandom.seed(1)\ntf.random.set_seed(1)\n\ndef fit_model(X_tr, y_tr, X_va=None, y_va=None, run=0,cols=None):\n    \"\"\"Scale the data, fit a model, plot the training history and optionally validate the model\n    \n    Returns a trained instance of tensorflow.keras.models.Model.\n    \n    As a side effect, updates y_va_pred, history_list and score_list.\n    \"\"\"\n    len_shape=len(X_tr.columns)\n    global y_va_pred\n    start_time = datetime.datetime.now()\n    \n    scaler = StandardScaler()\n    X_tr = scaler.fit_transform(X_tr)\n    \n    if X_va is not None:\n        X_va = scaler.transform(X_va)\n        validation_data = (X_va, y_va)\n    else:\n        validation_data = None\n\n    # Define the learning rate schedule and EarlyStopping\n    lr_start=0.01\n    if USE_PLATEAU and X_va is not None: # use early stopping\n        epochs = EPOCHS\n        lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.7, \n                               patience=4, verbose=VERBOSE)\n        es = EarlyStopping(monitor=\"val_loss\",\n                           patience=12, \n                           verbose=1,\n                           mode=\"min\", \n                           restore_best_weights=True)\n        callbacks = [lr, es, tf.keras.callbacks.TerminateOnNaN()]\n\n    else: # use cosine learning rate decay rather than early stopping\n        epochs = EPOCHS_COSINEDECAY\n        lr_end=0.0002\n        def cosine_decay(epoch):\n            if epochs > 1:\n                w = (1 + math.cos(epoch / (epochs-1) * math.pi)) / 2\n            else:\n                w = 1\n            return w * lr_start + (1 - w) * lr_end\n\n        lr = LearningRateScheduler(cosine_decay, verbose=0)\n        callbacks = [lr, tf.keras.callbacks.TerminateOnNaN()]\n        \n    # Construct and compile the model\n    model = my_model(len_shape)\n    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_start),\n                  #metrics='acc',\n                  loss=tf.keras.losses.BinaryCrossentropy())\n    #model.compile(optimizer=tf.keras.optimizers.SGD(), loss='mse')\n\n    # Train the model\n    history = model.fit(X_tr, y_tr, \n                        validation_data=validation_data, \n                        epochs=epochs,\n                        verbose=VERBOSE,\n                        batch_size=BATCH_SIZE,\n                        shuffle=True,\n                        callbacks=callbacks)\n\n    history_list.append(history.history)\n    callbacks, es, lr, history = None, None, None, None\n    print(f\"Training loss:   {history_list[-1]['loss'][-1]:.3f}\")\n    \n    if X_va is not None:\n        # Inference for validation\n        y_va_pred = model.predict(X_va, batch_size=BATCH_SIZE, verbose=VERBOSE)\n        #oof_list[run][val_idx] = y_va_pred\n        \n        # Evaluation: Execution time and AUC\n        score = roc_auc_score(y_va, y_va_pred)\n        print(f\"Fold {run}.{fold} | {str(datetime.datetime.now() - start_time)[-12:-7]}\"\n              f\" | AUC: {score:.5f}\")\n        score_list.append(score)\n        \n        if DIAGRAMS and fold == 0 and run == 0:\n            # Plot training history\n            plot_history(history_list[-1], \n                         title=f\"Learning curve (validation AUC = {score:.5f})\",\n                         plot_lr=True, n_epochs=110)\n\n            # Plot y_true vs. y_pred\n            plt.figure(figsize=(10, 4))\n            plt.hist(y_va_pred[y_va == 0], bins=np.linspace(0, 1, 21),\n                     alpha=0.5, density=True)\n            plt.hist(y_va_pred[y_va == 1], bins=np.linspace(0, 1, 21),\n                     alpha=0.5, density=True)\n            plt.xlabel('y_pred')\n            plt.ylabel('density')\n            plt.title('OOF Predictions')\n            plt.show()\n    \n            \n    return model, scaler\n","metadata":{"execution":{"iopub.status.busy":"2022-05-12T00:03:17.942188Z","iopub.execute_input":"2022-05-12T00:03:17.942926Z","iopub.status.idle":"2022-05-12T00:03:17.969083Z","shell.execute_reply.started":"2022-05-12T00:03:17.942868Z","shell.execute_reply":"2022-05-12T00:03:17.967865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_list = []\nscore_list = []\nmodel=None\nkf = KFold(n_splits=5)\nfor fold, (idx_tr, idx_va) in enumerate(kf.split(X)):\n    X_tr = X.iloc[idx_tr][features]\n    X_va = X.iloc[idx_va][features]\n    y_tr = y.iloc[idx_tr]\n    y_va = y.iloc[idx_va]\n  \n    model,scaler=fit_model(X_tr, y_tr, X_va, y_va,cols=features)\n    break # we only need the first fold","metadata":{"execution":{"iopub.status.busy":"2022-05-12T00:01:33.366515Z","iopub.execute_input":"2022-05-12T00:01:33.366801Z","iopub.status.idle":"2022-05-12T00:01:34.29958Z","shell.execute_reply.started":"2022-05-12T00:01:33.366769Z","shell.execute_reply":"2022-05-12T00:01:34.298105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.get_weights()","metadata":{"execution":{"iopub.status.busy":"2022-05-11T23:50:44.383195Z","iopub.execute_input":"2022-05-11T23:50:44.383544Z","iopub.status.idle":"2022-05-11T23:50:44.510641Z","shell.execute_reply.started":"2022-05-11T23:50:44.383502Z","shell.execute_reply":"2022-05-11T23:50:44.509618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.executing_eagerly()","metadata":{"execution":{"iopub.status.busy":"2022-05-11T22:31:59.452561Z","iopub.execute_input":"2022-05-11T22:31:59.45288Z","iopub.status.idle":"2022-05-11T22:31:59.458915Z","shell.execute_reply.started":"2022-05-11T22:31:59.452848Z","shell.execute_reply":"2022-05-11T22:31:59.458243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kf = KFold(n_splits=5)\nfor fold, (idx_tr, idx_va) in enumerate(kf.split(X)):\n    X_tr = X.iloc[idx_tr][features]\n    X_va = X.iloc[idx_va][features]\n    y_tr = y.iloc[idx_tr]\n    y_va = y.iloc[idx_va]\n    import shap\n    shap.initjs()\n    #background = X_tr[np.random.choice(X_tr.shape[0], 1000, replace=False)]\n    explainer = shap.DeepExplainer(model,X_tr)\n    shap_values = explainer.shap_values(X_va)\n    break # we only need the first fold            # visualize the first prediction's explanation (use matplotlib=True to avoid Javascript)\n    shap.summary_plot(shap_values[0], plot_type = 'bar', feature_names = features)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-08T20:01:31.250827Z","iopub.execute_input":"2022-05-08T20:01:31.251592Z","iopub.status.idle":"2022-05-08T20:01:31.588864Z","shell.execute_reply.started":"2022-05-08T20:01:31.251545Z","shell.execute_reply":"2022-05-08T20:01:31.587454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create submission\n# Create submission\nprint(f\"{len(features)} features\")\n\nX_tr = X\ny_tr = y\n\npred_list = []\nfor seed in range(10):\n    # see https://keras.io/getting_started/faq/#how-can-i-obtain-reproducible-results-using-keras-during-development\n    np.random.seed(seed)\n    random.seed(seed)\n    tf.random.set_seed(seed)\n    model, scaler = fit_model(X_tr, y_tr, run=seed)\n    pred_list.append(scipy.stats.rankdata(model.predict(scaler.transform(test[features]),\n                                                        batch_size=BATCH_SIZE, verbose=VERBOSE)))\n    print(f\"{seed:2}\", pred_list[-1])\nprint()\nsubmission = test[['id']].copy()\nsubmission['target'] = np.array(pred_list).mean(axis=0)\nsubmission.to_csv('submission.csv', index=False)\nsubmission","metadata":{"execution":{"iopub.status.busy":"2022-05-03T21:02:55.103038Z","iopub.execute_input":"2022-05-03T21:02:55.103337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"refrence:\n    https://www.kaggle.com/code/ambrosm/tpsmay22-keras-quickstart/notebook?scriptVersionId=94617937","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ord('A')","metadata":{"execution":{"iopub.status.busy":"2022-05-03T19:22:40.614633Z","iopub.execute_input":"2022-05-03T19:22:40.614943Z","iopub.status.idle":"2022-05-03T19:22:40.621223Z","shell.execute_reply.started":"2022-05-03T19:22:40.614905Z","shell.execute_reply":"2022-05-03T19:22:40.620496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-05-02T00:47:10.539525Z","iopub.execute_input":"2022-05-02T00:47:10.540584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-05-02T00:35:04.322276Z","iopub.execute_input":"2022-05-02T00:35:04.322523Z","iopub.status.idle":"2022-05-02T00:41:02.411322Z","shell.execute_reply.started":"2022-05-02T00:35:04.322488Z","shell.execute_reply":"2022-05-02T00:41:02.408971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}