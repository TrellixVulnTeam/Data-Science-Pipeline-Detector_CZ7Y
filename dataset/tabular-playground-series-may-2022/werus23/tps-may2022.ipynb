{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\npd.options.mode.chained_assignment = None  # default='warn'\n\n# data visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\n%matplotlib inline\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n# Pandas setting to display more dataset rows and columns\npd.set_option('display.max_rows', 150)\npd.set_option('display.max_columns', 600)\npd.set_option('display.max_colwidth', None)\npd.set_option('display.float_format', lambda x: '%.5f' % x)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-19T05:12:04.546369Z","iopub.execute_input":"2022-05-19T05:12:04.547154Z","iopub.status.idle":"2022-05-19T05:12:07.105768Z","shell.execute_reply.started":"2022-05-19T05:12:04.547111Z","shell.execute_reply":"2022-05-19T05:12:07.104659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/tabular-playground-series-may-2022/train.csv')\ntest_df = pd.read_csv('/kaggle/input/tabular-playground-series-may-2022/test.csv')\ndf = [train_df, test_df]\nsubmit_df = pd.read_csv('/kaggle/input/tabular-playground-series-may-2022/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-05-19T05:12:07.107835Z","iopub.execute_input":"2022-05-19T05:12:07.108083Z","iopub.status.idle":"2022-05-19T05:12:23.47563Z","shell.execute_reply.started":"2022-05-19T05:12:07.108051Z","shell.execute_reply":"2022-05-19T05:12:23.474568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Look At Data","metadata":{}},{"cell_type":"code","source":"train_df.describe()","metadata":{"execution":{"iopub.status.busy":"2022-05-19T05:12:23.477308Z","iopub.execute_input":"2022-05-19T05:12:23.477617Z","iopub.status.idle":"2022-05-19T05:12:24.312157Z","shell.execute_reply.started":"2022-05-19T05:12:23.47758Z","shell.execute_reply":"2022-05-19T05:12:24.311241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.describe()","metadata":{"execution":{"iopub.status.busy":"2022-05-19T05:12:24.314076Z","iopub.execute_input":"2022-05-19T05:12:24.314319Z","iopub.status.idle":"2022-05-19T05:12:24.949862Z","shell.execute_reply.started":"2022-05-19T05:12:24.314281Z","shell.execute_reply":"2022-05-19T05:12:24.948936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-19T05:12:24.951792Z","iopub.execute_input":"2022-05-19T05:12:24.952099Z","iopub.status.idle":"2022-05-19T05:12:24.981222Z","shell.execute_reply.started":"2022-05-19T05:12:24.952055Z","shell.execute_reply":"2022-05-19T05:12:24.980126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.info()","metadata":{"execution":{"iopub.status.busy":"2022-05-19T05:12:24.982798Z","iopub.execute_input":"2022-05-19T05:12:24.983042Z","iopub.status.idle":"2022-05-19T05:12:25.114776Z","shell.execute_reply.started":"2022-05-19T05:12:24.983009Z","shell.execute_reply":"2022-05-19T05:12:25.113937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"markdown","source":"what is in f_27?","metadata":{}},{"cell_type":"code","source":"train_df['f_27'].head(20)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T05:12:25.116386Z","iopub.execute_input":"2022-05-19T05:12:25.116637Z","iopub.status.idle":"2022-05-19T05:12:25.124636Z","shell.execute_reply.started":"2022-05-19T05:12:25.116604Z","shell.execute_reply":"2022-05-19T05:12:25.123802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"its basically just a 10 character string with random characters from a-z\n\nplan: label encode the string for the values of each character in it","metadata":{}},{"cell_type":"markdown","source":"look for normal distribution in numerical data","metadata":{}},{"cell_type":"code","source":"col_index = 1\nplt.figure(figsize=(15,10))\nfor col in train_df.columns:\n    if ((col != 'id') & (col != 'target') & (col != 'f_27')):\n        plt.subplot(5,6, col_index)\n        sns.histplot(data=train_df, x=col, bins= 100)\n        col_index+=1","metadata":{"execution":{"iopub.status.busy":"2022-05-19T05:12:25.126Z","iopub.execute_input":"2022-05-19T05:12:25.126272Z","iopub.status.idle":"2022-05-19T05:12:37.119724Z","shell.execute_reply.started":"2022-05-19T05:12:25.126215Z","shell.execute_reply":"2022-05-19T05:12:37.118395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"float datatypes are normally distributed, integer ones are not\n\nlook at correlations","metadata":{}},{"cell_type":"code","source":"plt.subplots(figsize=(20,10))\nmask = np.triu(np.ones_like(train_df.corr().round(2)))\nsns.heatmap(train_df.corr().round(2), mask=mask, cmap='cool', annot=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T05:12:37.121428Z","iopub.execute_input":"2022-05-19T05:12:37.12177Z","iopub.status.idle":"2022-05-19T05:12:42.607395Z","shell.execute_reply.started":"2022-05-19T05:12:37.121727Z","shell.execute_reply":"2022-05-19T05:12:42.6066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"no feature is very correlated to target, some are very correlated to each other","metadata":{}},{"cell_type":"markdown","source":"# Preprocess","metadata":{}},{"cell_type":"markdown","source":"First, label encode f_27","metadata":{}},{"cell_type":"code","source":"for X in df:\n    for i in range(10):\n        X['f_27_'+str(i)] = X.f_27.str.get(i).apply(ord) - ord('A')\n","metadata":{"execution":{"iopub.status.busy":"2022-05-19T05:12:42.610408Z","iopub.execute_input":"2022-05-19T05:12:42.610645Z","iopub.status.idle":"2022-05-19T05:13:05.980073Z","shell.execute_reply.started":"2022-05-19T05:12:42.610613Z","shell.execute_reply":"2022-05-19T05:13:05.979487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-19T05:13:05.981099Z","iopub.execute_input":"2022-05-19T05:13:05.981601Z","iopub.status.idle":"2022-05-19T05:13:06.013036Z","shell.execute_reply.started":"2022-05-19T05:13:05.98157Z","shell.execute_reply":"2022-05-19T05:13:06.012002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The [tutorial](https://www.kaggle.com/code/paultimothymooney/getting-started-with-tensorflow-decision-forests) creates ternary features and unique characters as shown:\n\nit makes the dataset perform way better somehow","metadata":{}},{"cell_type":"code","source":"for X in df:\n    X['uniqchars'] = X.f_27.apply(lambda s: len(set(s)))\n    X['i_02_21'] = (X.f_21 + X.f_02 > 5.2).astype(int) - (X.f_21 + X.f_02 < -5.3).astype(int)\n    X['i_05_22'] = (X.f_22 + X.f_05 > 5.1).astype(int) - (X.f_22 + X.f_05 < -5.4).astype(int)\n    i_00_01_26 = X.f_00 + X.f_01 + X.f_26\n    X['i_00_01_26'] = (i_00_01_26 > 5.0).astype(int) - (i_00_01_26 < -5.0).astype(int)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T05:13:06.015155Z","iopub.execute_input":"2022-05-19T05:13:06.015526Z","iopub.status.idle":"2022-05-19T05:13:08.178458Z","shell.execute_reply.started":"2022-05-19T05:13:06.015484Z","shell.execute_reply":"2022-05-19T05:13:08.177393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Scale float features","metadata":{}},{"cell_type":"code","source":"# from sklearn.preprocessing import StandardScaler\n# from sklearn.preprocessing import MinMaxScaler\n# #since all data is numerical just use this for all columns\n# sscaler = StandardScaler()\n# mmscaler = MinMaxScaler(feature_range=(-1., 1.))\n\n# num_cols = [cname for cname in test_df.columns if \n#                     test_df[cname].dtype in ['float']]\n\n# print(num_cols)\n\n# for X in df:\n#     X[num_cols]= X[num_cols].astype('float')\n\n# train_df[num_cols] = sscaler.fit_transform(train_df[num_cols])\n# test_df[num_cols] =sscaler.transform(test_df[num_cols])\n        \n# train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-19T05:13:08.180006Z","iopub.execute_input":"2022-05-19T05:13:08.180429Z","iopub.status.idle":"2022-05-19T05:13:08.185636Z","shell.execute_reply.started":"2022-05-19T05:13:08.180381Z","shell.execute_reply":"2022-05-19T05:13:08.184768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"check correlations after preprocessing","metadata":{}},{"cell_type":"code","source":"plt.subplots(figsize=(25,10))\nsns.heatmap(train_df.corr().round(2), cmap='cool', annot=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T05:13:08.186805Z","iopub.execute_input":"2022-05-19T05:13:08.187477Z","iopub.status.idle":"2022-05-19T05:13:19.395605Z","shell.execute_reply.started":"2022-05-19T05:13:08.187438Z","shell.execute_reply":"2022-05-19T05:13:19.394772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The new features do associate strongly with target","metadata":{}},{"cell_type":"markdown","source":"Delete unnessesary features","metadata":{}},{"cell_type":"code","source":"bad_cols = ['id', 'f_27']\n\ntrain_df.drop(bad_cols, axis=1, inplace = True)\ntest_df.drop(bad_cols, axis=1, inplace = True)\ntrain_df.head(1)\ntest_df.head(1)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T05:13:19.397089Z","iopub.execute_input":"2022-05-19T05:13:19.397484Z","iopub.status.idle":"2022-05-19T05:13:19.627972Z","shell.execute_reply.started":"2022-05-19T05:13:19.397448Z","shell.execute_reply":"2022-05-19T05:13:19.627286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling\n\ntry out many different models","metadata":{}},{"cell_type":"code","source":"#import\nfrom sklearn.model_selection import cross_val_score,train_test_split\nimport lightgbm as lgb\nimport xgboost as xgb\n\n#Common Model Algorithms\ndef warn(*args, **kwargs):\n    pass\nimport warnings\nfrom lightgbm import LGBMClassifier","metadata":{"execution":{"iopub.status.busy":"2022-05-19T05:13:19.629291Z","iopub.execute_input":"2022-05-19T05:13:19.629718Z","iopub.status.idle":"2022-05-19T05:13:20.208682Z","shell.execute_reply.started":"2022-05-19T05:13:19.629674Z","shell.execute_reply":"2022-05-19T05:13:20.207709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(train_df.drop('target',axis = 1).copy(), \n                                                      train_df.target, \n                                                      test_size=0.05, \n                                                      random_state=0)\nX_test = test_df.copy()","metadata":{"execution":{"iopub.status.busy":"2022-05-19T06:58:36.210752Z","iopub.execute_input":"2022-05-19T06:58:36.211333Z","iopub.status.idle":"2022-05-19T06:58:36.894861Z","shell.execute_reply.started":"2022-05-19T06:58:36.211295Z","shell.execute_reply":"2022-05-19T06:58:36.893421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(X_valid))","metadata":{"execution":{"iopub.status.busy":"2022-05-19T06:58:39.311075Z","iopub.execute_input":"2022-05-19T06:58:39.311398Z","iopub.status.idle":"2022-05-19T06:58:39.316959Z","shell.execute_reply.started":"2022-05-19T06:58:39.311363Z","shell.execute_reply":"2022-05-19T06:58:39.315702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Try using lgbm. I have read online that it is better with dealing with large datasets and it is faster.","metadata":{}},{"cell_type":"code","source":"lgb_train = lgb.Dataset(X_train, y_train)\nlgb_valid = lgb.Dataset(X_valid, y_valid, reference=lgb_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {\n        'task': 'prediction',\n        'boosting_type': 'gbdt',\n        'objective': 'binary',\n        'metric': 'auc',        #auc\n        'learning_rate': 0.05,  #0.05\n        'max_depth': -1,        #-1\n        'num_leaves': 36,       #36\n        'min_data_in_leaf': 20, #20\n        'colsample_bytree': 1.0,#1.0\n        'lambda_l1': 0.8,       #0.8\n        'lambda_l2': 0.8,       #0.8\n        'num_iterations': 20000,#20000\n        'verbosity': -1\n}\n# 0.996891\n\nearly_stop = lgb.early_stopping(stopping_rounds =100, first_metric_only=False);\n\neval_verbose = lgb.log_evaluation(period=500, show_stdv=False)\n\n\n\nmodel = lgb.train(\n    params,\n    train_set=lgb_train,\n    valid_sets=lgb_valid,\n    callbacks = [early_stop, eval_verbose],\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-19T06:40:26.917737Z","iopub.execute_input":"2022-05-19T06:40:26.91807Z","iopub.status.idle":"2022-05-19T06:55:18.94759Z","shell.execute_reply.started":"2022-05-19T06:40:26.918029Z","shell.execute_reply":"2022-05-19T06:55:18.946778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Try using xgb( doesn't work well, comment out)","metadata":{}},{"cell_type":"code","source":"# xgb_train = xgb.DMatrix(X_train, y_train)\n# xgb_valid = xgb.DMatrix(X_valid, y_valid)\n# xgb_test = xgb.DMatrix(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T05:28:51.104789Z","iopub.execute_input":"2022-05-19T05:28:51.105215Z","iopub.status.idle":"2022-05-19T05:28:51.110485Z","shell.execute_reply.started":"2022-05-19T05:28:51.105161Z","shell.execute_reply":"2022-05-19T05:28:51.109179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# params = {\n#         'task': 'prediction',\n#         'boosting_type': 'gbdt',\n#         'objective': 'binary:logistic',\n#         'metric': 'auc',        #auc\n#         'learning_rate': 0.05,  #0.05\n#         'max_depth': 12,        #-1\n#         'num_leaves': 36,       #36\n#         'min_data_in_leaf': 20, #20\n#         'colsample_bytree': 1.0,#1.0\n#         'lambda_l1': 0.8,       #0.8\n#         'lambda_l2': 0.8,       #0.8\n#         'verbosity': 0,\n# }\n\n# model = xgb.train(\n#     params,\n#     xgb_train,\n#     evals=[(xgb_train, 'Train'), (xgb_valid, 'Valid')],\n#     num_boost_round=20000,\n#     verbose_eval = 100,\n#     early_stopping_rounds = 100,\n# )","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2022-05-19T05:28:51.112127Z","iopub.execute_input":"2022-05-19T05:28:51.112599Z","iopub.status.idle":"2022-05-19T05:28:51.125328Z","shell.execute_reply.started":"2022-05-19T05:28:51.112546Z","shell.execute_reply":"2022-05-19T05:28:51.124578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #get accuracy\n# from sklearn.metrics import mean_absolute_error\n\n# print('accuracy: ' + str(mean_absolute_error(model.predict(xgb_valid),y_valid)))","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2022-05-19T05:28:51.126851Z","iopub.execute_input":"2022-05-19T05:28:51.127316Z","iopub.status.idle":"2022-05-19T05:28:51.139656Z","shell.execute_reply.started":"2022-05-19T05:28:51.127265Z","shell.execute_reply":"2022-05-19T05:28:51.138828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict and Submit","metadata":{}},{"cell_type":"code","source":"# for i in range(len(pred)):\n#     pred[i]= int(round(pred[i]))\n    \n# pred.astype(bool)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T05:28:51.141251Z","iopub.execute_input":"2022-05-19T05:28:51.14168Z","iopub.status.idle":"2022-05-19T05:28:51.157658Z","shell.execute_reply.started":"2022-05-19T05:28:51.141638Z","shell.execute_reply":"2022-05-19T05:28:51.156271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T06:55:36.87895Z","iopub.execute_input":"2022-05-19T06:55:36.879412Z","iopub.status.idle":"2022-05-19T06:57:25.248654Z","shell.execute_reply.started":"2022-05-19T06:55:36.879369Z","shell.execute_reply":"2022-05-19T06:57:25.247922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit_df['target'] = pred\nsubmit_df.to_csv('submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T05:30:44.889932Z","iopub.execute_input":"2022-05-19T05:30:44.89022Z","iopub.status.idle":"2022-05-19T05:30:46.947976Z","shell.execute_reply.started":"2022-05-19T05:30:44.890174Z","shell.execute_reply":"2022-05-19T05:30:46.946699Z"},"trusted":true},"execution_count":null,"outputs":[]}]}