{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Overview\nA copy of the [python script by Jesse Hamer](https://www.kaggle.com/jhamer90811/identifying-whales-using-pca-logistic-regression). Small modifications were made to make it easier to use in a notebook (and not crash / run out of memory)"},{"metadata":{},"cell_type":"markdown","source":"Kaggle Competition: Humpback Whale Identification Challenge\n\nAuthor: Jesse A. Hamer\n\nDESCRIPTION:\nPreamble:\nThis is my first Kaggle kernel and competition, so if you have any helpful feedback,\nplease don't hesitate to provide it! I basically chose this dataset at random--\nit looked interesting and challenging and I can't say much more about my motivation.\nMy algorithm proceeds through three phases: image normalization (data cleaning),\ndimensionality reduction, and then the model learning (logistic regression). Most of\nthe initial data analysis was done as needed in my personal Python IDE, but I have\ntaken care to include any relevant conclusions from this analysis.\n\n1. Normalizing the images.\nFirst, the pictures need to be manipulated into a more managable form. In particular, \nthe picture types are not consistent: some are RGB, while others are grayscale. \nSince grayscale is the simpler picture type, we first convert each picture into \nits grayscale approximation using weights borrowed from the MATLAB RGB->grayscale\nconversion algorithm. Next, the pictures come in varying shapes and sizes, and so\nthese qualities must be uniformized as well. Unfortunately we lose a good deal of\nresolution on several of the pictures during this process. One point of improvement\nwould be to discern a more efficient way of performing this compression, and\ncompressing in such a way that a minimum of information is lost from each picture.\n\n2. Dimensionality reduction.\nEven after compressing, the image feature vectors will consist of several thousand\nfeatures. To remedy this, we perform PCA in order to extract out the most useful\nfeatures.\n\n3. The model.\nThe model is a two-step pipeline, fitted with a GridSearchCV across several param-\neters. The first step in the pipeline is the abovementioned PCA transformation;\nwe will use the GridSearchCV to determine the optimal number of components as\nwell as whether whitening is appropriate. The second step of the pipeline\nis a logistic regression model. We will use the GridSearchCV to set the regularization\nparameter C.\n\nAgain, please let me know if you have any suggestions, I am very new to this and\nlooking to improve!\n\nNOTE: Currently this kernel takes about an hour and a half to run (so it can't actually\nbe done on Kaggle's site), takes up a ton of memory, and only scores about 10%. \nNeedless to say, there are some improvements to be made. I want to play around \nwith the number of PCA components as well as the classifier.\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport time\nimport math\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.image as mpimg\n\nfrom sklearn.decomposition.pca import PCA\nfrom sklearn.linear_model.logistic import LogisticRegression\nfrom sklearn.pipeline import Pipeline","execution_count":26,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#8381 of the images are RGB, so they will need to be converted to greyscale.\ndef rgb_to_gray(img):\n    if len(img.shape) == 2: #already gray\n        return(img)\n    grayImage = np.zeros(img.shape)\n    #These scaling coefficients are evidently standard for RGB->Grayscale conversion\n    R = img[:,:,0]*0.299\n    G = img[:,:,1]*0.587\n    B = img[:,:,2]*0.114\n    \n    grayImage = R + G + B\n    \n    return(grayImage)","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We will also need to group together nearby pixels in order to \n#reduce image complexity and uniformize image size (so that every image has\n#the same number of features).\n    \ndef img_compress(img, x_bins=100,y_bins=100):\n    x_splits = np.linspace(0,img.shape[1]-1,x_bins+1, dtype = int)\n    y_splits=np.linspace(0,img.shape[0]-1,y_bins+1, dtype = int)\n    \n    compressed = np.zeros((y_bins,x_bins))\n    \n    for i in range(y_bins):\n        for j in range(x_bins):\n            temp = np.mean(img[y_splits[i]:y_splits[i+1],\n                                      x_splits[j]:x_splits[j+1]])\n            if math.isnan(temp):\n                if y_splits[i]==y_splits[i+1]:\n                    compressed[i,j]=compressed[i-1,j]\n                else:\n                    compressed[i,j] = compressed[i,j-1]\n            else:\n                compressed[i,j] = int(temp)\n    return(compressed)","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dir = '../input/train/train'\ntest_dir = '../input/test/test'\nmin_cols = 138\nmin_rows = 54","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#Convert .jpg images into pixel arrays\ntrain_file_names = os.listdir(train_dir)[::5]\nimgs_train = [rgb_to_gray(mpimg.imread(train_dir + '/' + file, format = 'JPG')) \n              for file in train_file_names]\nprint(len(imgs_train), 'images loaded')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Get indices of those pictures which aren't too small\ngood_pics = [i for i in range(len(imgs_train)) if (imgs_train[i].shape[0]>=min_rows)and(imgs_train[i].shape[1]>=min_cols)]\n#Select only pictures that are sufficiently large\nimgs_train = [imgs_train[i] for i in good_pics]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Compress images. Unfortunately we have to distort the aspect ratio, which may\n#lose valuable information. But if we do not do this then features will not\n#have consistent meaning across pictures, even if we ensure that all pictures\n#get compressed to the same resolution (pixel count)\n\n#We need to find the smallest dimension across all images (train and test) in\n#order to properly compress; otherwise the compressing algorithm will generate\n#NaN-values.\n\ncompressed_train_imgs = [img_compress(img, min_cols, min_rows) for img in imgs_train]\ndel imgs_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Extract filenames to later associate to whale IDs\nfilenames = [file for file in train_file_names]\nfilenames = [filenames[i] for i in good_pics]\n#Convert images into pandas dataframe format for learning the model\ndf1 = pd.DataFrame(data = [img.ravel() for img in compressed_train_imgs])\ndf2 = pd.DataFrame(data = filenames, columns = ['FileName'])\ndata1 = pd.concat([df2,df1],axis = 1)\n#Obtain filenames, indexed by whale IDs\ndata2 = pd.read_csv('../input/train.csv',names = ['FileName','WhaleID'])\n#Map whale IDs to images via filenames (index of data1 is matched to value of data2)\ndata = data2.merge(data1, on = 'FileName')\ndata = data.drop('FileName',axis = 1)\ndel compressed_train_imgs, df1, df2, data1, data2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Extract training examples and labels, and get test set.\nX_train = data.iloc[:,1:]\ny_train = data['WhaleID']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#Perform principal component analysis for dimensionality reduction\n#Try playing around with n_components to get better scores\npca = PCA(random_state = 42, n_components = 100, whiten = True)\npca.fit(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Try other classifiers for better scores.\nlogreg = LogisticRegression(C = 1e-2)\n\n#Define our pipeline. First we transform the data into its principal components,\n#then learn the logistic regression model\nclf = Pipeline([('pca',pca),\n                ('logreg',logreg),\n                ])\n\n#Fit model\nclf.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Score model on training data\nprint(\"Score on training set:\", clf.score(X_train,y_train))\n#We no longer need the training data. Delete to free up memory.\ndel data, X_train, y_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Read and clean test set\nall_test_filenames = [file for file in os.listdir(test_dir)]\nfilenames_test = all_test_filenames[:5000]\nprint('Predicting for {} of {} total images'.format(len(filenames_test), len(all_test_filenames)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nimgs_test = [rgb_to_gray(mpimg.imread(test_dir + '/' + file)) for file in filenames_test]\n#Smallest number of columns and rows across all test pictures\ncompressed_test_imgs = [img_compress(img, min_cols, min_rows) for img in imgs_test]\ndel imgs_test\nX_test = pd.DataFrame([img.ravel() for img in compressed_test_imgs])\ndel compressed_test_imgs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ny_preds = clf.predict_proba(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Extract top 5 results\nresults = pd.DataFrame(data = [clf.classes_[np.argsort(y_preds[i,:])[-5:]] for i in range(y_preds.shape[0])],\n                       index = filenames_test)\ndef list_to_str(L):\n    string = \"\"\n    for word in L:\n        string = string + word + \" \"\n    return(string)\n        \nresults2 = pd.DataFrame(data = [list_to_str(results.iloc[i].values) for i in range(results.shape[0])],\n                        index = filenames_test,columns = ['Id'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fill in missing results\nmost_common = results2['Id'].value_counts().index[0]\nmissing_files = [x for x in all_test_filenames if x not in filenames_test]\nfull_results_df = pd.concat([\n    results2,\n    pd.DataFrame([most_common]*len(missing_files), \n                 index=missing_files,\n                columns = ['Id'])\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_results_df.sample(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_results_df.to_csv('submission.csv', \n                sep = ',', \n                index_label = 'Image', \n                header = True)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}