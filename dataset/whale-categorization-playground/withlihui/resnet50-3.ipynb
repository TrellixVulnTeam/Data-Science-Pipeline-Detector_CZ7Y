{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras import layers\nimport pandas as pd\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import models\nfrom os.path import join","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 24\nembedding_dim = 50\nimage_size = 224\npath_base = '../input/whale-categorization-playground/'\npath_train = join(path_base,'train/train')\npath_test = join(path_base,'test/test')\npath_model = join(path_base,'resnet50_Model.hdf5')\npath_csv = '../input/whale-categorization-playground/train.csv'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class sample_gen(object):\n    def __init__(self, file_class_mapping, other_class = \"new_whale\"): # file_class_mapping：key：图片名，value：Id\n        self.file_class_mapping= file_class_mapping\n        self.class_to_list_files = defaultdict(list) # <class 'list'>, {'w_a232f9e': ['33c25291.jpg', '67c96540.jpg'], 'w_1b6d171': ['64c99b7b.jpg'],\n        self.list_other_class = [] # 其他类别图片名\n        self.list_all_files = list(file_class_mapping.keys())  # 所有图片的文件名\n        self.range_all_files = list(range(len(self.list_all_files)))  # 训练集就是0~6894的数字list\n\n        for file, class_ in file_class_mapping.items():\n            if class_ == other_class:\n                self.list_other_class.append(file)\n            else:\n                self.class_to_list_files[class_].append(file)\n\n        self.list_classes = list(set(self.file_class_mapping.values()))\n        self.range_list_classes= range(len(self.list_classes))\n        self.class_weight = np.array([len(self.class_to_list_files[class_]) for class_ in self.list_classes])\n        self.class_weight = self.class_weight/np.sum(self.class_weight)\n\n    def get_sample(self):\n        class_idx = np.random.choice(self.range_list_classes, 1, p=self.class_weight)[0]\n        examples_class_idx = np.random.choice(range(len(self.class_to_list_files[self.list_classes[class_idx]])), 2)\n        positive_example_1, positive_example_2 = \\\n            self.class_to_list_files[self.list_classes[class_idx]][examples_class_idx[0]],\\\n            self.class_to_list_files[self.list_classes[class_idx]][examples_class_idx[1]]\n\n\n        negative_example = None\n        while negative_example is None or self.file_class_mapping[negative_example] == \\\n                self.file_class_mapping[positive_example_1]:\n            negative_example_idx = np.random.choice(self.range_all_files, 1)[0]\n            negative_example = self.list_all_files[negative_example_idx]\n        return positive_example_1, negative_example, positive_example_2\n    \ndef read_and_resize(filepath):\n    im = Image.open((filepath)).convert('RGB')\n    im = im.resize((image_size, image_size))\n    return np.array(im, dtype=\"float32\")\n\n\ndef augment(im_array):\n    if np.random.uniform(0, 1) > 0.9:\n        im_array = np.fliplr(im_array)\n    return im_array\n\ndef gen(triplet_gen):\n    while True:\n        list_positive_examples_1 = []\n        list_negative_examples = []\n        list_positive_examples_2 = []\n\n        for i in range(batch_size):\n            positive_example_1, negative_example, positive_example_2 = triplet_gen.get_sample()\n            path_pos1 = join(path_train, positive_example_1)\n            path_neg = join(path_train, negative_example)\n            path_pos2 = join(path_train, positive_example_2)\n            \n            positive_example_1_img = read_and_resize(path_pos1)\n            negative_example_img = read_and_resize(path_neg)\n            positive_example_2_img = read_and_resize(path_pos2)\n\n            positive_example_1_img = augment(positive_example_1_img)\n            negative_example_img = augment(negative_example_img)\n            positive_example_2_img = augment(positive_example_2_img)\n            \n            list_positive_examples_1.append(positive_example_1_img)\n            list_negative_examples.append(negative_example_img)\n            list_positive_examples_2.append(positive_example_2_img)\n\n        A = preprocess_input(np.array(list_positive_examples_1))\n        B = preprocess_input(np.array(list_positive_examples_2))\n        C = preprocess_input(np.array(list_negative_examples))\n        \n        label = None\n        \n        yield ({'anchor_input': A, 'positive_input': B, 'negative_input': C}, label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def triplet_loss(inputs, dist='sqeuclidean', margin='maxplus'):\n    anchor, positive, negative = inputs\n    positive_distance = K.square(anchor - positive)\n    negative_distance = K.square(anchor - negative)\n    if dist == 'euclidean':\n        positive_distance = K.sqrt(K.sum(positive_distance, axis=-1, keepdims=True))\n        negative_distance = K.sqrt(K.sum(negative_distance, axis=-1, keepdims=True))\n    elif dist == 'sqeuclidean':\n        positive_distance = K.sum(positive_distance, axis=-1, keepdims=True)\n        negative_distance = K.sum(negative_distance, axis=-1, keepdims=True)\n    loss = positive_distance - negative_distance\n    if margin == 'maxplus':\n        loss = K.maximum(0.0, 1 + loss)\n    elif margin == 'softplus':\n        loss = K.log(1 + K.exp(loss))\n    return K.mean(loss)\n\ndef triplet_loss_np(inputs, dist='sqeuclidean', margin='maxplus'):\n    anchor, positive, negative = inputs\n    positive_distance = np.square(anchor - positive)\n    negative_distance = np.square(anchor - negative)\n    if dist == 'euclidean':\n        positive_distance = np.sqrt(np.sum(positive_distance, axis=-1, keepdims=True))\n        negative_distance = np.sqrt(np.sum(negative_distance, axis=-1, keepdims=True))\n    elif dist == 'sqeuclidean':\n        positive_distance = np.sum(positive_distance, axis=-1, keepdims=True)\n        negative_distance = np.sum(negative_distance, axis=-1, keepdims=True)\n    loss = positive_distance - negative_distance\n    if margin == 'maxplus':\n        loss = np.maximum(0.0, 1 + loss)\n    elif margin == 'softplus':\n        loss = np.log(1 + np.exp(loss))\n    return np.mean(loss)\n\ndef check_loss():\n    batch_size = 10\n    shape = (batch_size, 4096)\n\n    p1 = normalize(np.random.random(shape))\n    n = normalize(np.random.random(shape))\n    p2 = normalize(np.random.random(shape))\n    \n    input_tensor = [K.variable(p1), K.variable(n), K.variable(p2)]\n    out1 = K.eval(triplet_loss(input_tensor))\n    input_np = [p1, n, p2]\n    out2 = triplet_loss_np(input_np)\n\n    assert out1.shape == out2.shape\n    print(np.linalg.norm(out1))\n    print(np.linalg.norm(out2))\n    print(np.linalg.norm(out1-out2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import normalize\nfrom keras import backend as K","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"check_loss()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications import ResNet50   \nresnet_weights_path = '../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# resnet_base= ResNet50(weights='imagenet', include_top=False, input_shape=(224,224,3))   \nresnet_base= ResNet50(weights=resnet_weights_path, include_top=False, input_shape=(224,224,3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resnet_base.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Input, Dense, Dropout, Lambda, Convolution2D, MaxPooling2D, Flatten","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models.Sequential()\nmodel.add(resnet_base)\nmodel.add(Dropout(0.5))\nmodel.add(layers.Dense(embedding_dim,activation='relu'))\nmodel.add(layers.Lambda(lambda x: K.l2_normalize(x,axis=1)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for layer in resnet_base.layers[150:]:\n    layer.trainable = True\nfor layer in resnet_base.layers[:150]:\n    layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_shape = (image_size, image_size, 3)\nanchor_input = Input(input_shape, name='anchor_input')\npositive_input = Input(input_shape, name='positive_input')\nnegative_input = Input(input_shape, name='negative_input')\nanchor_embedding = model(inputs=anchor_input)\npositive_embedding = model(inputs=positive_input)\nnegative_embedding = model(inputs=negative_input)\n\ninputs = [anchor_input, positive_input, negative_input]\noutputs = [anchor_embedding, positive_embedding, negative_embedding]\n       \ntriplet_model = Model(inputs, outputs)\ntriplet_model.add_loss(K.mean(triplet_loss(outputs)))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom collections import defaultdict\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(path_csv)\ntrain, test = train_test_split(data, train_size=0.7, random_state=1337)\nfile_id_mapping_train = {k: v for k, v in zip(train.Image.values, train.Id.values)}\nfile_id_mapping_test = {k: v for k, v in zip(test.Image.values, test.Id.values)}\ngen_tr = gen(sample_gen(file_id_mapping_train))\ngen_te = gen(sample_gen(file_id_mapping_test))\n\ncheckpoint = ModelCheckpoint(path_model, monitor='loss', verbose=1, save_best_only=True, mode='min') # 保存模型权重为 path_model\nearly = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=10) # 当监测值不再改善时，该回调函数将中止训练\ncallbacks_list = [checkpoint, early]  # early","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications.resnet50 import ResNet50, preprocess_input","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ShowImg(img):\n    plt.figure()\n    plt.imshow(img.astype('uint8'))\n    plt.show()\n    plt.close()\n    \nbatch = next(gen_tr)\n\nimg = batch[0]['anchor_input'][0]\nprint(img.shape)\nmean = [103.939, 116.779, 123.68]\nimg[..., 0] += mean[0]\nimg[..., 1] += mean[1]\nimg[..., 2] += mean[2]\nimg = img[..., ::-1]\nShowImg(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = np.array([ [[1,2,3] , [4,5,6] ],\n              [[7,8,9] , [10,11,12] ] ])\nprint(a.shape)\na[..., 2] += 100\na = a[:,:,::-1]\nprint(a)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Input, Dense, Dropout, Lambda, Convolution2D, MaxPooling2D, Flatten\nfrom keras.optimizers import Adam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"triplet_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"triplet_model.compile(loss=None,\n                      optimizer= keras.optimizers.Adam(lr = 0.0001),\n                      metrics=['acc']\n                     )\nhistory = triplet_model.fit_generator(gen_tr, \n                              validation_data=gen_te, \n                              epochs=10, \n                              verbose=1, \n                              workers=1,\n                              steps_per_epoch=100, \n                              validation_steps=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['loss'], label='traning_loss')\nplt.plot(history.history['val_loss'], label='validation_loss', color = 'r')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python [conda env:zhang] *","language":"python","name":"conda-env-zhang-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.2"}},"nbformat":4,"nbformat_minor":4}