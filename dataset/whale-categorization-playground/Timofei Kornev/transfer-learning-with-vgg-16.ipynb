{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Kernel description:**\n\nThis kernel demonstrates application of transfer learning with VGG-16 to the given whale multi-class classfication problem. Please note that this is a solution to my university course assignment which differs in the objective from the original stated problem. The difference is that the original training data set is filtered by removing all whale individuals for which the number of images is smaller than the given threshold `NUM_IMAGES_THRESHOLD`. Also, all pictures annotated with 'new whale' label are excluded from the dataset. Last, there is no submission file produced by this kernel.\n\nAnyway, please consider upvoting this kernel if you liked it!\n\nPS. The Table of Contents was generated using ToC2 extension for Jupyter Notebook.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Articles about transfer learning:\n * https://machinelearningmastery.com/how-to-use-transfer-learning-when-developing-convolutional-neural-network-models/\n * https://keras.io/guides/transfer_learning/","execution_count":null},{"metadata":{"toc":true},"cell_type":"markdown","source":"<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Data-preprocessing\" data-toc-modified-id=\"Data-preprocessing-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Data preprocessing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Read-in-the-training-set\" data-toc-modified-id=\"Read-in-the-training-set-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Read in the training set</a></span></li><li><span><a href=\"#Plot-a-few-images-along-with-the-corresponding-whale-IDs\" data-toc-modified-id=\"Plot-a-few-images-along-with-the-corresponding-whale-IDs-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Plot a few images along with the corresponding whale IDs</a></span></li><li><span><a href=\"#Check-how-many-images-there-are-for-all-whale-IDs\" data-toc-modified-id=\"Check-how-many-images-there-are-for-all-whale-IDs-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Check how many images there are for all whale IDs</a></span></li><li><span><a href=\"#Filter-whale-IDs\" data-toc-modified-id=\"Filter-whale-IDs-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Filter whale IDs</a></span></li><li><span><a href=\"#Split-the-filtered-data-into-the-training-and-test-(validation)-set\" data-toc-modified-id=\"Split-the-filtered-data-into-the-training-and-test-(validation)-set-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Split the filtered data into the training and test (validation) set</a></span></li></ul></li><li><span><a href=\"#Data-augmentation\" data-toc-modified-id=\"Data-augmentation-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data augmentation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Define-a-Keras-data-generator-for-the-data-augmentation-and-apply-this-generator-to-the-splitted-data\" data-toc-modified-id=\"Define-a-Keras-data-generator-for-the-data-augmentation-and-apply-this-generator-to-the-splitted-data-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Define a Keras data generator for the data augmentation and apply this generator to the splitted data</a></span></li><li><span><a href=\"#Plot-some-augmented-data\" data-toc-modified-id=\"Plot-some-augmented-data-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Plot some augmented data</a></span></li></ul></li><li><span><a href=\"#Model-training\" data-toc-modified-id=\"Model-training-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Model training</a></span><ul class=\"toc-item\"><li><span><a href=\"#Define-a-model\" data-toc-modified-id=\"Define-a-model-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Define a model</a></span></li><li><span><a href=\"#Train-only-the-new-top-layers-of-the-model\" data-toc-modified-id=\"Train-only-the-new-top-layers-of-the-model-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Train only the new top layers of the model</a></span></li><li><span><a href=\"#Apply-fine-tuning,-that-is,-unfreeze-the-base-model-and-train-the-whole-model-with-a-small-learning-rate\" data-toc-modified-id=\"Apply-fine-tuning,-that-is,-unfreeze-the-base-model-and-train-the-whole-model-with-a-small-learning-rate-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Apply fine-tuning, that is, unfreeze the base model and train the whole model with a small learning rate</a></span></li><li><span><a href=\"#Plot-the-training-history\" data-toc-modified-id=\"Plot-the-training-history-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Plot the training history</a></span></li></ul></li></ul></div>","execution_count":null},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np  # linear algebra\nimport pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    print(dirname)\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Set parameters for plotting.\n# plt.rc('figure', figsize=(8, 6))\nsns.set(font_scale=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data preprocessing","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Read in the training set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/whale-categorization-playground/train.csv')\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print the number of missing entries.\ndf.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plot a few images along with the corresponding whale IDs","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"IMAGES_DIR = '../input/whale-categorization-playground/train/train/'\nNUM_IMAGES_TO_PLOT = 3\nimage_filenames = os.listdir(IMAGES_DIR)\n\nfor i in range(NUM_IMAGES_TO_PLOT):\n    image_filename = image_filenames[i]\n    image_path = os.path.join(IMAGES_DIR, image_filename)\n    image_np = plt.imread(image_path)\n    whale_id = df.query(f\"Image == '{image_filename}'\").Id.item()\n    plt.subplots(figsize=(8, 6))\n    plt.imshow(image_np)\n    plt.title(whale_id)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Check how many images there are for all whale IDs","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df2 = df.groupby('Id').agg('count').rename({'Image': 'NumImages'}, axis=1)\ndf2.sort_values('NumImages', ascending=False, inplace=True)\ndf2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plot s histogram describing number of cases for varios numbers of whale images (that is, how frequently a certain number of whale images we have for a single whale ID).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(6, 4))\ndf2.NumImages.hist(bins=list(range(0, 11, 2)))\nplt.title('Number of cases for various numbers of whale images ')\nplt.xlabel('Number of images')\nplt.ylabel('Number of cases')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(6, 4))\ndf2.NumImages.hist(bins=list(range(10, 71, 10)))\nplt.title('Number of cases for various numbers of whale images ')\nplt.xlabel('Number of images')\nplt.ylabel('Number of cases')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Filter whale IDs","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Remove the `new_whale` entry from consideration.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.drop('new_whale', inplace=True)\ndf2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Filter (and leave) only those whale IDs, for which the number of corresponding images is greater than `NUM_IMAGES_THRESHOLD`.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"NUM_IMAGES_THRESHOLD = 20\n\ndf3 = df2.query(f'NumImages > {NUM_IMAGES_THRESHOLD}')\n\nprint('shape:', df3.shape)\nprint('total number of images:', df3.NumImages.sum())\ndf3","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Obtain a dataframe containing entries only for the filtered whale IDs.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ids_to_leave = list(df3.index)\n\nfiltered_df = df.query(f'Id in {ids_to_leave}')\nfiltered_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get rid of the image with the ship.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"filtered_df.drop(filtered_df.query(\"Image == '496b52ff.jpg'\").index,\n                 axis=0, inplace=True)\n\nfiltered_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Split the filtered data into the training and test (validation) set","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"For splitting the data, we could use the `train_test_split` function from `sklearn`. Or, we could specify the `validation_split` parameter for an `ImageDataGenerator` instance and use it to create two augmented image generators: one for the training set, and the other one for the test (validation) set. However, these two approaches do not guarantee a balanced split of the data, i.e. it could happen that not all the whale IDs present in the training set are present in the test set as well. To avoid this problem, we can obtain a stratified split of the data by using a `StratifiedShuffleSplit` object from `sklearn` module.\n\nNote that this splitter can throw exceptions in the following cases:\n* if the `test_size` is too small to include all the whale IDs into the test set (thus, it is not possible to accomplish a truly stratified splitting of the data)\n* if it is not possible to include some whale IDs into the test set because there is only one image for such whale IDs","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedShuffleSplit\n\nX, y = filtered_df.Image, filtered_df.Id\nsplitter = StratifiedShuffleSplit(n_splits=1, test_size=0.25, random_state=0)\ntrain_indices, test_indices = list(splitter.split(X, y))[0]\n\nprint('shapes:', train_indices.shape, test_indices.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check if there is an equal number of unique whale ids in the training and test set.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = filtered_df.iloc[train_indices]\ntest_df = filtered_df.iloc[test_indices]\n\ntrain_df.Id.nunique() == test_df.Id.nunique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For each whale id, print the percentage (i.e., proportion) of the corresponding entries in the test dataframe with respect to the training dataframe.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_entries_counts = train_df.Id.value_counts().sort_index()\ntest_entries_counts = test_df.Id.value_counts().sort_index()\n\nprint('percentage of entries:')\nprint()\nprint(test_entries_counts / train_entries_counts)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data augmentation","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Define a Keras data generator for the data augmentation and apply this generator to the splitted data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Check the list of all possible image transformations in Keras here: https://keras.io/api/preprocessing/image/#imagedatagenerator-class\n\nAlso, you can find description of all the parameters of the `flow_from_dataframe` method under the following link: https://keras.io/api/preprocessing/image/#flow_from_dataframe-method","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow import keras\nfrom keras.preprocessing.image import ImageDataGenerator\n\nTRAIN_DIR = '/kaggle/input/whale-categorization-playground/train/train'\n\n# Specify image transformations for the data augmentation here. \ndatagen = ImageDataGenerator(\n    rescale=1./255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    rotation_range=30,\n    brightness_range=(0.5, 1.5),\n    fill_mode='nearest',\n    horizontal_flip=True\n)\n\nBATCH_SIZE = 32\nTARGET_SIZE = (224, 224)\n\ntrain_set_generator = datagen.flow_from_dataframe(\n    dataframe=train_df,\n    directory=TRAIN_DIR,\n    x_col='Image',\n    y_col='Id',\n    target_size=TARGET_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='categorical'  # ensures one-hot encoding of class labels\n)\n\ntest_set_generator = datagen.flow_from_dataframe(\n    dataframe=test_df,\n    directory=TRAIN_DIR,\n    x_col='Image',\n    y_col='Id',\n    target_size=TARGET_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='categorical'  # ensures one-hot encoding of class labels\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plot some augmented data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"NUM_IMAGES_TO_PLOT = 5  # must be less than the BATCH_SIZE\n\n# Get one batch of the training data.\nfor X, y in train_set_generator:\n    break\n\n# Get a list of unique whale IDs.\nunique_whale_ids = train_df.Id.unique()\n\nimages_subbatch = X[:NUM_IMAGES_TO_PLOT]\none_hot_class_labels_subbatch = y[:NUM_IMAGES_TO_PLOT]\n\nfor image, one_hot_class_labels in zip(images_subbatch,\n                                       one_hot_class_labels_subbatch):\n    plt.subplots()\n    plt.imshow(image)\n    whale_id = unique_whale_ids[np.argmax(one_hot_class_labels)]\n    plt.title(whale_id)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model training","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Define a model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications.vgg16 import VGG16\n\n# Form the correct input shape for the model in case the `TARGET_SIZE` \n# is not square (e.g. (224, 224)).\nINPUT_SHAPE = (TARGET_SIZE[0], TARGET_SIZE[1], 3)\n\nbase_model = VGG16(\n    weights='imagenet',  # load weights pretrained on the ImageNet\n    include_top=False,  # do not include the ImageNet classifier at the top\n    input_shape=INPUT_SHAPE,\n    pooling='max'  # add a global max pooling layer after the base model\n)\n\nbase_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Dropout, Dense\n\n# Freeze the base model so that only the new top layers are trained.\nbase_model.trainable = False\n\nnum_classes = len(unique_whale_ids)\n\nmodel = keras.Sequential([\n    base_model,\n    Dropout(0.2),\n    Dense(128, activation='relu'),\n    # Dense(128, activation='relu'),\n    Dropout(0.2),\n    Dense(num_classes, name='predictions')\n])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train only the new top layers of the model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.losses import CategoricalCrossentropy\n\nEPOCHS = 30\n\n# As the output of the model is real-numbered, set the `from_logits` \n# parameter of the crossentropy loss to True.\nmodel.compile(\n    optimizer='adam',\n    loss=CategoricalCrossentropy(from_logits=True),  \n    metrics=['accuracy']\n)\n\nhistory = model.fit(train_set_generator, \n                    epochs=EPOCHS,\n                    validation_data=test_set_generator,\n                    verbose=2   # don't display the progress bar\n) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Apply fine-tuning, that is, unfreeze the base model and train the whole model with a small learning rate ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Note that if the base model contains the batch normalization layers, they will still remain frozen (check the number of non-trainable params in the summary below) so that their learned values (i.e. the mean and stddev) are not \"destroyed\" by the backpropagation process. You can learn more about various nuances related to transfer learning here: https://keras.io/guides/transfer_learning/","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model.trainable = True\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.optimizers import Adam\n\nFINE_TUNING_EPOCHS = 30\n\nmodel.compile(optimizer=Adam(1e-5),  # set the learning rate to a low value\n              loss=CategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy']\n)\n\nfine_tuning_history = model.fit(train_set_generator, \n                                epochs=FINE_TUNING_EPOCHS,\n                                validation_data=train_set_generator,\n                                verbose=2  # don't display the progress bar\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plot the training history","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nfine_tuning_acc = fine_tuning_history.history['accuracy']\nfine_tuning_val_acc = fine_tuning_history.history['val_accuracy']\n\ntop_layers_training_epochs = list(range(1, EPOCHS + 1))\nfine_tuning_epochs = list(range(EPOCHS + 1, \n                                EPOCHS + FINE_TUNING_EPOCHS + 1))\n\nax = plt.figure(figsize=(10, 6))\n\nplt.plot(top_layers_training_epochs, acc, label='acc', color='orange')\nplt.plot(top_layers_training_epochs, val_acc, label='val_acc', \n         color='cornflowerblue')\n\nplt.plot(fine_tuning_epochs, fine_tuning_acc, color='orange')\nplt.plot(fine_tuning_epochs, fine_tuning_val_acc, color='cornflowerblue')\nplt.plot([EPOCHS, EPOCHS + 1], [acc[-1], fine_tuning_acc[0]], \n         color='orange')\n\nplt.plot([EPOCHS, EPOCHS + 1], [val_acc[-1], fine_tuning_val_acc[0]], \n         color='cornflowerblue')\n\nplt.vlines(EPOCHS, ymin=0, ymax=1, linestyles='dashed',\n           label='fine-tuning started')\n\nplt.legend(loc='best')\nplt.title('Accuracy during training')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss = history.history['loss']\nval_loss = history.history['val_loss']\n\nfine_tuning_loss = fine_tuning_history.history['loss']\nfine_tuning_val_loss = fine_tuning_history.history['val_loss']\n\ntop_layers_training_epochs = list(range(1, EPOCHS + 1))\n\nax = plt.figure(figsize=(10, 6))\n\nplt.plot(top_layers_training_epochs, loss, label='loss', color='orange')\nplt.plot(top_layers_training_epochs, val_loss, label='val_loss', \n         color='cornflowerblue')\n\nplt.plot(fine_tuning_epochs, fine_tuning_loss, color='orange')\nplt.plot(fine_tuning_epochs, fine_tuning_val_loss, color='cornflowerblue')\nplt.plot([EPOCHS, EPOCHS + 1], [loss[-1], fine_tuning_loss[0]], \n         color='orange')\n\nplt.plot([EPOCHS, EPOCHS + 1], [val_loss[-1], fine_tuning_val_loss[0]], \n         color='cornflowerblue')\n\nmax_loss = max(max(loss), max(val_loss), \n               max(fine_tuning_loss), max(fine_tuning_val_loss))\n\nplt.vlines(EPOCHS, ymin=0, ymax=max_loss, linestyles='dashed', \n           label='fine-tuning started')\n\nplt.legend(loc='best')\nplt.title('Loss during training')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}