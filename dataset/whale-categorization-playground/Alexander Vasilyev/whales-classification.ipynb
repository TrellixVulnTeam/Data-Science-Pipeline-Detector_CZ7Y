{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Whales identification model**\n\nIdea of solution: \n\n1) Due to extreme imbalance of label distribution we have thousands of classes with just one sample. We have to use augmentation to create more samples for underrepresented classes.\n\n2) We can't split randomly the training set to use some samples for validation, because many classes have only one sample. Even if augmentation is used, there is a risk that certain classes will not be represented by training set after splitting. \n\n3) Due to different color scheme in dataset and limited computational resourses we transform all images into grey scale. \n\n4) Another thing we can try is class weighting, which will increase significance of underrepresented classes. \n\nTherefore we test the CNN with different settings and estimate the results of classification of training set. The preference will be given to the network that uses augmentation and class weighting, if its performance is not significantly worser than the performance of network trained without these settings.  ","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport os\nimport csv\nimport cv2\nimport gc\nimport operator\nimport random\nimport warnings\nfrom os.path import split\n\nfrom sklearn.utils import class_weight\nfrom numpy import array\nfrom numpy import argmax\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom random import shuffle\nfrom IPython.display import Image\nfrom pathlib import Path\nimport matplotlib.image as mpimg\nfrom keras import layers\nfrom keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\nfrom keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\nfrom keras.models import Model\nfrom keras.preprocessing import image\nfrom keras.utils import layer_utils\nfrom keras.utils.data_utils import get_file\nfrom keras.applications.imagenet_utils import preprocess_input\nfrom IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\nfrom keras.utils import plot_model\nfrom keras.utils import np_utils\nimport keras.backend as K\nfrom keras.models import Sequential\nfrom keras import optimizers\nfrom collections import Counter\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing of data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Before applying the classification model we will transform the images into greyscale and resize them. One hot encoding will be applied to transform the labels. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The paths to files: ","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"trainDir = \"../input/whale-categorization-playground/train/train\"\ntestDir=\"../input/whale-categorization-playground/test/test/\"\nvaluesFile= \"../input/whale-categorization-playground/train.csv\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrainData = pd.read_csv(valuesFile)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Image transformation function: greyscale and resize to (64,64). ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def rgb2grey(rgb): \n    if len(rgb.shape)==3:\n        return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140]) \n    else:\n        return rgb\n\n\ndef transform_image(img):\n    resized = cv2.resize(img, (64, 64), cv2.INTER_LINEAR)\n    \n    normalized = cv2.normalize(resized, None, 0.0, 1.0, cv2.NORM_MINMAX)\n                         \n    \n    normalized= np.expand_dims(normalized, axis=2)\n\n    \n    return normalized","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def imageprep(dataset):\n    \n    if dataset==\"train\":\n        namelist=os.listdir(trainDir) \n        filedir=trainDir\n    elif dataset==\"test\":\n        namelist=os.listdir(testDir)\n        filedir=testDir\n    \n    X_train = np.zeros((len(namelist), 64, 64, 1))\n    \n    \n    for i in range(len(namelist)):\n      \n        img = mpimg.imread(filedir+\"/\"+namelist[i])\n        \n        gs_img= rgb2grey(img)\n        \n        trans_img= transform_image(gs_img)\n        \n        X_train[i] = trans_img\n    \n            \n    return X_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Convertion of labels to one-hot variables for learning","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def labelprep(Y):\n    \n    labels_encoder = LabelEncoder()\n    \n    onehot_encoder = OneHotEncoder(sparse=False)\n    \n    int_encoded = labels_encoder.fit_transform(Y)\n    \n    int_encoded = int_encoded.reshape(len(int_encoded), 1)\n      \n    onehot_encoded = onehot_encoder.fit_transform(int_encoded)\n   \n    return onehot_encoded, labels_encoder","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we prepare the data to be used for training.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = imageprep(\"train\")\n\n\nprint(\"Shape of train data: \", X.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y = trainData['Id']\n\ny, label_encoder = labelprep(array(Y))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Classification model and results","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Let's start with simple convolutional neural network with two convolutional layers and two fully connected ones.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"outputdim=len(np.unique(Y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(32, (5, 5), strides = (1, 1), input_shape = (64, 64, 1)))\nmodel.add(BatchNormalization(axis = 3))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D((3, 3)))\n\nmodel.add(Conv2D(64, (3, 3), strides = (1,1)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization(axis = 3))\nmodel.add(AveragePooling2D((3, 3)))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation=\"relu\"))\nmodel.add(Dropout(0.65))\nmodel.add(Dense(outputdim, activation='softmax'))\n\nmodel.summary()\n\nmodel.compile(loss='categorical_crossentropy', optimizer=\"Adam\", metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Computing class weights with corresponding sklearn function: ","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-output":true,"collapsed":true},"cell_type":"code","source":"class_weights = class_weight.compute_class_weight('balanced',\n                                                 np.unique(Y),\n                                                 Y)\nclass_weights = {i : class_weights[i] for i in range(len(class_weights))}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let compare the learning process for several settings:\n\n1) No Augmentation, no class weights\n2) No Augmentation, class weights \n3) Augmentation, no class weights\n4) Augmentation, class weights","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ini_weights=model.get_weights()\nhistory = model.fit(X, y, epochs=400, batch_size=100, verbose=1)\ngc.collect()\nweights0=model.get_weights()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['accuracy'])\nplt.title('Accuracy of CNN, training set, no AUG, no class weights')\nplt.ylabel('Accuracy')\nplt.xlabel('Training epoch')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that this simple CNN is capable to fit training data with accuracy of 91%","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Let's try to learn with class weights: ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model.set_weights(ini_weights)\nhistory_weights = model.fit(X, y, epochs=400, batch_size=100, verbose=1, class_weight= class_weights)\ngc.collect()\nweights1=model.get_weights()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history_weights.history['accuracy'])\nplt.title('Accuracy of CNN, training set, no AUG, with class weights')\nplt.ylabel('Accuracy')\nplt.xlabel('Training epoch')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that introduction of class weights didn't result in decrease of performance, the network still has 83% accuracy. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Let's try to use the simplest augmentation procedure:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = image.ImageDataGenerator( \n    #rescale=1./255,\n    #rotation_range=15,\n    #width_shift_range=.15,\n    #height_shift_range=.15,\n    horizontal_flip=True)\n\ndatagen.fit(X)\n\n\n\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.set_weights(ini_weights)\nhistory_aug=model.fit_generator(datagen.flow(X, y, batch_size=100), epochs=400, verbose=1)\ngc.collect()\nweights2=model.get_weights()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history_aug.history['accuracy'])\nplt.title('CNN, augmented flips, no class weights')\nplt.ylabel('Accuracy on test set')\nplt.xlabel('Learning epoch')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that introduction of augmentation (horizontal flips) slightly affected precision on training set, 90% accuracy was achieved. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Next we try both augmentation and class weighting: ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model.set_weights(ini_weights)\nhistory1=model.fit_generator(datagen.flow(X, y, batch_size=100), epochs=400, verbose=1, class_weight= class_weights)\ngc.collect()\nweights3=model.get_weights()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nplt.plot(history1.history['accuracy'])\nplt.title('CNN, augmented flips,  class weights')\nplt.ylabel('Accuracy on test set')\nplt.xlabel('Learning epoch')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can observe here that usage of both augmentation and class weighting resulted in significant loss of accuracy (83%). We suggest to use the model with augmentation without class weighting for prediction of test set. We could also try other augmentation transformations, but there is not enough time for this. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history1.history['accuracy'],'r-', label=\"AUG, CW\")\nplt.plot(history_aug.history['accuracy'], 'b-', label=\"AUG, NO CW\")\nplt.plot(history_weights.history['accuracy'], label= \"NO AUG, CW\")\nplt.plot(history.history['accuracy'], label=\"NO AUG, NO CW\")\nplt.rcParams[\"figure.figsize\"] = (20,20)\nplt.legend()\nplt.title('CNN traning set accuracy')\nplt.ylabel('Accuracy on test set')\nplt.xlabel('Learning epoch')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission of results","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Preparing test images: ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = imageprep(\"test\")\n\n\nprint(\"Shape of train data: \", X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create submission file and write the results into it:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfilelist=os.listdir(testDir) \nmodel.set_weights(weights2)\nwith open(\"sample_submission.csv\",\"w\") as f:\n    with warnings.catch_warnings():\n        f.write(\"Image,Id\\n\")\n        warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n      \n        for i in range(len(filelist)):\n            filename=filelist[i]\n            y = model.predict_proba(X_test[i].reshape(1,64,64,1))\n\n            predicted_args = np.argsort(y)[0][::-1][:5]\n\n            inverted = label_encoder.inverse_transform(predicted_args)\n\n            image = split(filename)[-1]\n\n            predicted_args = \" \".join( inverted)\n\n         \n\n            f.write(\"%s,%s\\n\" %(image, predicted_args))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}