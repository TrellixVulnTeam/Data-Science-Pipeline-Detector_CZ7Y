{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport tensorflow as tf\nimport numpy as np\n\nfrom random import randrange\nfrom keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n\nROOT_FOLDER = '../input/whale-categorization-playground'\n# ROOT_FOLDER = 'data'\nTRAIN_FOLDER = ROOT_FOLDER + '/train/train/'\nTEST_FOLDER = ROOT_FOLDER + '/test/test/'\nWIDTH = 150\nHEIGHT = 150\n\ndf_train = pd.read_csv(ROOT_FOLDER + '/train.csv')\ndf_test = pd.read_csv(ROOT_FOLDER + '/sample_submission.csv')\nlabel_to_index = {}\nindex_to_label = {}\n\nTIMES_TO_TRAIN = len(df_train) * 50\nBATCH_SIZE = 100\n\nfor index, (image, label) in df_train.iterrows():\n    index_to_label[index] = label\n    if not label in label_to_index:\n        label_to_index[label] = len(label_to_index)\n\nmodel = Sequential()\nmodel.add(Conv2D(filters=16, kernel_size=5, padding=\"same\", activation=\"relu\", input_shape=(150, 150, 3)))\nmodel.add(MaxPooling2D(pool_size=(5, 5), strides=(5, 5), padding=\"valid\"))\nmodel.add(Dropout(0.1))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(32, (15, 15), activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(5, 5), strides=(5, 5), padding=\"valid\"))\nmodel.add(Dropout(0.2))\nmodel.add(BatchNormalization())\n\nmodel.add(Flatten())\n\nmodel.add(Dense(4251, activation=\"relu\"))\n\n\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy', metrics=['binary_crossentropy', 'acc'])\n\n\n# data augmentation\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\n# training\nfor t in range(int(TIMES_TO_TRAIN / BATCH_SIZE) + 1):\n    print(str(t) + \"/\" + str(int(TIMES_TO_TRAIN / BATCH_SIZE)))\n    \n    x_train = []\n    y_train = []\n    for i in range(BATCH_SIZE):\n        idx = randrange(len(df_train))\n        image = df_train.loc[idx]['Image']\n        x_train.append(img_to_array(load_img(TRAIN_FOLDER + image, target_size=(WIDTH, HEIGHT))))\n        y_train.append(np.zeros(4251))\n        y_train[i][label_to_index[df_train.loc[idx]['Id']]] = 1\n        \n    x_train = np.array(x_train)\n    y_train = np.array(y_train)\n    \n    datagen.fit(x_train)\n    model.fit_generator(datagen.flow(x_train, y_train, batch_size=BATCH_SIZE),\n                        steps_per_epoch=x_train.shape[0] // BATCH_SIZE, verbose=False)\n    model.fit(x_train, y_train, batch_size=BATCH_SIZE, verbose=False)\n\n\n# predicting\ndef sort_predictions(array):\n    pairs = []\n    for idx, v in enumerate(array):\n        pairs.append((idx, v))\n    pairs.sort(key=lambda p: p[1], reverse=True)\n    \n    top_sorted = []\n    for p in pairs[:5]:\n        top_sorted.append(index_to_label[p[0]])\n#     print(pairs[:5], top_sorted)\n    return top_sorted\n\nprint('----------------- PREDICTING -----------------')\npredictions = []\nfor index, (image, labels) in df_test.iterrows():\n    image = df_test.loc[index]['Image']\n    x_test = np.array([img_to_array(load_img(TEST_FOLDER + image, target_size=(WIDTH, HEIGHT)))])\n    preds = model.predict(x_test)[0]\n    top_preds = sort_predictions(preds)\n#     print(top_preds)\n    predictions.append(top_preds)\n    \n    print(str(index) + '/' + str(len(df_test)))\n\n# submission\nsubmission = pd.DataFrame(data=[[df_test.loc[i]['Image'], \"{} {} {} {} {}\".format(*predictions[i])] for i in range(len(predictions))],\n                           columns=['Image', 'Id'])\nprint(submission)\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}