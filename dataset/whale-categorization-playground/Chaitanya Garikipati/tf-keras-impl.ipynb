{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom IPython.display import Image\nimport random\nimport logging as logger\nimport os\nimport csv\n\nlogger.basicConfig(format='%(process)d-%(levelname)s-%(message)s', level=logger.CRITICAL)\n\n\ntf.enable_eager_execution()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dir vars\nBASE_DIR = '../input/'\nTRAIN_DIR = 'train/train/'\nTRAIN_FILE = 'train.csv'\nTEST_DIR = 'test/test/'\nTEST_FILE = 'sample_submission.csv'\n\n# Global vars\nNUM_PARALLEL_CALLS = 4\nBATCH_SIZE = 200","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load csv Data\ntrain_df = pd.read_csv(BASE_DIR + TRAIN_FILE)\ntrain_df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# unique values, indices\nlabels = train_df['Id']\nunique_labels = list(set(labels))\ntotal_unique_labels = len(unique_labels)\n\nlen(unique_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read Image\nImage(filename=BASE_DIR + TRAIN_DIR + random.choice(train_df['Image']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create Data Pipeline\ndef prepare_image(imageFileName, label):\n    imageFileName = imageFileName.numpy()\n    logger.debug('reading image {} with label {}'.format(imageFileName, label.numpy()))\n    img = tf.keras.preprocessing.image.load_img(imageFileName, target_size=(100, 100, 3))\n    img_aray = tf.keras.preprocessing.image.img_to_array(img)\n    preprocessed_img = tf.keras.applications.resnet50.preprocess_input(img_aray)\n    preprocessed_img = tf.convert_to_tensor(preprocessed_img, tf.float32)\n    return preprocessed_img, label\n\n\ndef prepare_label(image, label):\n    label = label.numpy()\n    label = label.decode('utf-8')\n    logger.debug('converting label {} as one hot vector'.format(label))\n    logger.debug('index of label {} is {}'.format(label, unique_labels.index(label)))\n    one_hot_label = tf.one_hot(indices=unique_labels.index(label), depth=total_unique_labels)\n    return image, one_hot_label\n\ndef data_pipeline(images, labels):\n    logger.info(images)\n    shuffle_size = len(labels)\n    dataset = (\n        tf.data.Dataset.from_tensor_slices((images, labels))\n        .shuffle(shuffle_size)\n        .map(\n            lambda imageFileName, label: tf.py_function(\n                prepare_image,\n                [imageFileName, label],\n                (tf.float32, tf.dtypes.string)\n            ),\n            num_parallel_calls=NUM_PARALLEL_CALLS\n        )\n        .map(\n            lambda img, label: tf.py_function(\n                prepare_label,\n                [img, label],\n                (tf.float32, tf.float32)\n            ),\n            num_parallel_calls=NUM_PARALLEL_CALLS\n        )\n        .repeat()\n        .batch(BATCH_SIZE)\n        .prefetch(1)\n    )\n     # Create reinitializable iterator from dataset\n    iterator = dataset.make_one_shot_iterator()\n    \n    return iterator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model creation\ndef prepare_model() -> tf.keras.Model:\n    model = tf.keras.Sequential()\n    model.add(tf.keras.layers.Conv2D(32, (7, 7), activation='elu', input_shape=(100, 100, 3)))\n    model.add(tf.keras.layers.BatchNormalization(axis=3))\n    model.add(tf.keras.layers.Activation('elu'))\n    model.add(tf.keras.layers.MaxPool2D((2, 2)))\n    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='elu'))\n    model.add(tf.keras.layers.AveragePooling2D((3, 3)))\n    model.add(tf.keras.layers.Flatten())\n    model.add(tf.keras.layers.Dense(500, activation='elu'))\n    model.add(tf.keras.layers.Dropout(0.5))\n    model.add(tf.keras.layers.Dense(total_unique_labels, activation='softmax'))\n    logger.debug(model.output_shape)\n    model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"imageFilenames = train_df['Image']\nimageFilenames = [BASE_DIR + TRAIN_DIR + imageFileName for imageFileName in imageFilenames]\nlabels = tf.convert_to_tensor(train_df['Id'], dtype=tf.dtypes.string)\nimageFilenames = tf.convert_to_tensor(imageFilenames, dtype=tf.dtypes.string)\niterator = data_pipeline(imageFilenames, labels)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"model = prepare_model()\ncheckpointer = tf.keras.callbacks.ModelCheckpoint(filepath='./weights.hdf5', verbose=1, save_best_only=True)\nhistory = model.fit(iterator, steps_per_epoch=5, epochs=100, verbose=1, callbacks=[checkpointer])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['acc'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history.history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"org_test_files = os.listdir(BASE_DIR + TEST_DIR)\ntest_files = [BASE_DIR + TEST_DIR + file for file in org_test_files]\ntest_image = random.choice(test_files)\nImage(filename=test_image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_file = open('output.csv','w')\ncolumn= ['Image', 'Id']\nwrtr = csv.writer(output_file, delimiter=',')\nwrtr.writerow(column)\nfor i, v in enumerate(test_files):\n    v = tf.convert_to_tensor(v)\n    preproccesed_img, label = prepare_image(v, v)\n    preproccesed_img = preproccesed_img.numpy()\n    preproccesed_img = np.reshape(preproccesed_img, (1, 100, 100, 3))\n    print(preproccesed_img.shape)\n    predicted_value = model.predict(np.array(preproccesed_img), verbose=1)\n    predicted_value = predicted_value.argpartition(-4)[0][-4:]\n    print(predicted_value)\n    predictions = [unique_labels[p] for p in predicted_value]\n    result = [org_test_files[i], ' '.join(predictions)]\n    print(result)\n    wrtr.writerow(result)\n    \noutput_file.close()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.2"}},"nbformat":4,"nbformat_minor":1}