{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import required libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import BatchNormalization\nfrom keras.models import Sequential, Model\nfrom keras.layers import Input, Embedding, Dense, Flatten, Concatenate, Reshape\nfrom keras import backend as K\nfrom keras import regularizers \nfrom tensorflow.keras.optimizers import Adam\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.regularizers import l2\nfrom tensorflow.keras.losses import Loss\nfrom sklearn.decomposition import FactorAnalysis, PCA,KernelPCA, FastICA","metadata":{"execution":{"iopub.status.busy":"2022-05-14T04:42:16.815973Z","iopub.execute_input":"2022-05-14T04:42:16.816302Z","iopub.status.idle":"2022-05-14T04:42:23.099902Z","shell.execute_reply.started":"2022-05-14T04:42:16.81622Z","shell.execute_reply":"2022-05-14T04:42:23.099172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Dataset","metadata":{}},{"cell_type":"code","source":"stock_price_df = pd.read_csv(\"../input/jpx-tokyo-stock-exchange-prediction/train_files/stock_prices.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-05-14T04:42:23.101513Z","iopub.execute_input":"2022-05-14T04:42:23.101745Z","iopub.status.idle":"2022-05-14T04:42:28.428691Z","shell.execute_reply.started":"2022-05-14T04:42:23.101711Z","shell.execute_reply":"2022-05-14T04:42:28.427767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# A glance at the data","metadata":{}},{"cell_type":"code","source":"print('(rows, columns) =', stock_price_df.shape)\nstock_price_df.tail()","metadata":{"execution":{"iopub.status.busy":"2022-05-14T04:42:28.433599Z","iopub.execute_input":"2022-05-14T04:42:28.43599Z","iopub.status.idle":"2022-05-14T04:42:28.476021Z","shell.execute_reply.started":"2022-05-14T04:42:28.435945Z","shell.execute_reply":"2022-05-14T04:42:28.475346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stock_price_df['ExpectedDividend'] = stock_price_df['ExpectedDividend'].fillna(0)\nstock_price_df['SupervisionFlag'] = stock_price_df['SupervisionFlag'].map({True: 1, False: 0})\nstock_price_df['Date'] = pd.to_datetime(stock_price_df['Date'])\nstock_price_df.info()","metadata":{"execution":{"iopub.status.busy":"2022-05-14T04:42:28.478558Z","iopub.execute_input":"2022-05-14T04:42:28.483048Z","iopub.status.idle":"2022-05-14T04:42:29.187582Z","shell.execute_reply.started":"2022-05-14T04:42:28.483013Z","shell.execute_reply":"2022-05-14T04:42:29.186805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import stock list\n","metadata":{}},{"cell_type":"code","source":"stock_list = pd.read_csv(\"../input/jpx-tokyo-stock-exchange-prediction/stock_list.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-05-14T04:42:29.188744Z","iopub.execute_input":"2022-05-14T04:42:29.18948Z","iopub.status.idle":"2022-05-14T04:42:29.217431Z","shell.execute_reply.started":"2022-05-14T04:42:29.189441Z","shell.execute_reply":"2022-05-14T04:42:29.216695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stock_list = stock_list[['SecuritiesCode','NewMarketSegment','33SectorCode','17SectorCode','Universe0','Section/Products','NewIndexSeriesSize']]\nstock_list = stock_list.replace(np.nan,'-')\nstock_list['Universe0'] = np.where(stock_list['Universe0'], 1, 0)\nstock_list = stock_list.drop_duplicates()\nstock_list","metadata":{"execution":{"iopub.status.busy":"2022-05-14T04:42:29.21867Z","iopub.execute_input":"2022-05-14T04:42:29.218909Z","iopub.status.idle":"2022-05-14T04:42:29.250985Z","shell.execute_reply.started":"2022-05-14T04:42:29.218876Z","shell.execute_reply":"2022-05-14T04:42:29.250319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Some Feature Engineering","metadata":{}},{"cell_type":"code","source":"def FE(stock_price_df):\n    stock_price_df['BOP'] = (stock_price_df['Open']-stock_price_df['Close'])/(stock_price_df['High']-stock_price_df['Low'])\n    stock_price_df['wp'] = (stock_price_df['Open']+stock_price_df['High']+stock_price_df['Low'])/3\n    stock_price_df['TR'] = stock_price_df['High'] - stock_price_df['Low']\n    # stock_price_df['AD'] = ta.AD(High, Low, Close, Volume)\n    # stock_price_df['OBV']  = ta.OBV(Close, Volume)\n    stock_price_df['OC'] = stock_price_df['Open'] * stock_price_df['Close']\n    stock_price_df['HL'] = stock_price_df['High'] * stock_price_df['Low']\n    stock_price_df['logC'] = np.log(stock_price_df['Close']+1)\n    stock_price_df['OHLCstd'] = stock_price_df[['Open','Close','High','Low']].std(axis=1)\n    stock_price_df['OHLCskew'] = stock_price_df[['Open','Close','High','Low']].skew(axis=1)\n    stock_price_df['OHLCkur'] = stock_price_df[['Open','Close','High','Low']].kurtosis(axis=1)\n    stock_price_df['Cpos'] = (stock_price_df['Close']-stock_price_df['Low'])/(stock_price_df['High']-stock_price_df['Low']) -0.5\n    stock_price_df['bsforce'] = stock_price_df['Cpos'] * stock_price_df['Volume']\n    stock_price_df['Opos'] = (stock_price_df['Open']-stock_price_df['Low'])/(stock_price_df['High']-stock_price_df['Low']) -0.5\n    stock_price_df['Date'] = pd.to_datetime(stock_price_df['Date'])\n    stock_price_df['weekday'] = stock_price_df['Date'].dt.weekday+1\n    stock_price_df['Monday'] = np.where(stock_price_df['weekday']==1,1,0)\n    stock_price_df['Tuesday'] = np.where(stock_price_df['weekday']==2,1,0)\n    stock_price_df['Wednesday'] = np.where(stock_price_df['weekday']==3,1,0)\n    stock_price_df['Thursday'] = np.where(stock_price_df['weekday']==4,1,0)\n    stock_price_df['Friday'] = np.where(stock_price_df['weekday']==5,1,0)\n    return stock_price_df\nstock_price_df = FE(stock_price_df)\nstock_price_df = pd.merge(stock_price_df,stock_list, on='SecuritiesCode')","metadata":{"execution":{"iopub.status.busy":"2022-05-14T04:42:29.252213Z","iopub.execute_input":"2022-05-14T04:42:29.252511Z","iopub.status.idle":"2022-05-14T04:42:33.42404Z","shell.execute_reply.started":"2022-05-14T04:42:29.252477Z","shell.execute_reply":"2022-05-14T04:42:33.42327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fill the missing value with \"0\" for convenience reason.","metadata":{}},{"cell_type":"code","source":"subf = ['Open', 'High', 'Low', 'Close',\n       'Volume', 'AdjustmentFactor', 'ExpectedDividend',\n       'SupervisionFlag', 'BOP', 'wp', 'TR', 'OC', 'HL', 'logC',\n       'OHLCstd', 'OHLCskew', 'OHLCkur', 'Cpos', 'bsforce', 'Opos',\n       'Monday', 'Tuesday', 'Wednesday', 'Thursday']","metadata":{"execution":{"iopub.status.busy":"2022-05-14T04:42:33.425347Z","iopub.execute_input":"2022-05-14T04:42:33.425623Z","iopub.status.idle":"2022-05-14T04:42:33.432246Z","shell.execute_reply.started":"2022-05-14T04:42:33.425588Z","shell.execute_reply":"2022-05-14T04:42:33.429909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in subf:\n    stock_price_df[i] = stock_price_df[i].fillna(stock_price_df[i].mean())","metadata":{"execution":{"iopub.status.busy":"2022-05-14T04:42:33.43339Z","iopub.execute_input":"2022-05-14T04:42:33.433664Z","iopub.status.idle":"2022-05-14T04:42:33.827579Z","shell.execute_reply.started":"2022-05-14T04:42:33.433626Z","shell.execute_reply":"2022-05-14T04:42:33.826808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Use Factor Analysis to extract 5 most important factors from selected features.","metadata":{}},{"cell_type":"code","source":"transformer = FastICA(n_components=3, random_state=888)\nX = transformer.fit_transform(stock_price_df[subf])","metadata":{"execution":{"iopub.status.busy":"2022-05-14T04:42:33.830738Z","iopub.execute_input":"2022-05-14T04:42:33.830997Z","iopub.status.idle":"2022-05-14T04:42:46.931038Z","shell.execute_reply.started":"2022-05-14T04:42:33.830962Z","shell.execute_reply":"2022-05-14T04:42:46.930107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(0,np.shape(X)[1]):\n    stock_price_df['fa_'+str(i)] = X[:,i]","metadata":{"execution":{"iopub.status.busy":"2022-05-14T04:42:46.932576Z","iopub.execute_input":"2022-05-14T04:42:46.932811Z","iopub.status.idle":"2022-05-14T04:42:46.956185Z","shell.execute_reply.started":"2022-05-14T04:42:46.932778Z","shell.execute_reply":"2022-05-14T04:42:46.95545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_subf = ['fa_'+str(i) for i in range(0,np.shape(X)[1])]","metadata":{"execution":{"iopub.status.busy":"2022-05-14T04:42:46.957615Z","iopub.execute_input":"2022-05-14T04:42:46.958066Z","iopub.status.idle":"2022-05-14T04:42:46.962802Z","shell.execute_reply.started":"2022-05-14T04:42:46.958018Z","shell.execute_reply":"2022-05-14T04:42:46.96169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stock_price_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-14T04:42:46.964333Z","iopub.execute_input":"2022-05-14T04:42:46.964888Z","iopub.status.idle":"2022-05-14T04:42:47.007251Z","shell.execute_reply.started":"2022-05-14T04:42:46.964854Z","shell.execute_reply":"2022-05-14T04:42:47.006657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# subf = ['Open', 'High', 'Low', 'Close']","metadata":{"execution":{"iopub.status.busy":"2022-05-14T04:42:47.008431Z","iopub.execute_input":"2022-05-14T04:42:47.008852Z","iopub.status.idle":"2022-05-14T04:42:47.012163Z","shell.execute_reply.started":"2022-05-14T04:42:47.008818Z","shell.execute_reply":"2022-05-14T04:42:47.011323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# normalize features according to daily stock data (at the same day only)","metadata":{}},{"cell_type":"code","source":"def daily_standardize(df,col):\n    avg = df[[col,'Date']].groupby('Date').mean()\n    avg.columns = ['avg']\n    avg['Date'] = avg.index\n    avg = avg.reset_index(drop=True)\n    std = df[[col,'Date']].groupby('Date').std()\n    std.columns = ['std']\n    std['Date'] = std.index\n    std = std.reset_index(drop=True)\n    df = pd.merge(df, avg, on='Date')\n    df = pd.merge(df,std,on='Date')\n    df[col] = (df[col] - df['avg'])/df['std']\n    df = df.drop(['avg','std'],axis=1)\n    df[col] = df[col].fillna(0)\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-05-14T04:42:47.013575Z","iopub.execute_input":"2022-05-14T04:42:47.014116Z","iopub.status.idle":"2022-05-14T04:42:47.025728Z","shell.execute_reply.started":"2022-05-14T04:42:47.014083Z","shell.execute_reply":"2022-05-14T04:42:47.024805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def daily_normalize(df,col):\n    avg = df[[col,'Date']].groupby('Date').min()\n    avg.columns = ['min']\n    avg['Date'] = avg.index\n    avg = avg.reset_index(drop=True)\n    std = df[[col,'Date']].groupby('Date').max()\n    std.columns = ['max']\n    std['Date'] = std.index\n    std = std.reset_index(drop=True)\n    df = pd.merge(df, avg, on='Date')\n    df = pd.merge(df,std,on='Date')\n    df[col] = (df[col] - df['min'])/(df['max']-df['min'])\n    df = df.drop(['min','max'],axis=1)\n    df[col] = df[col].fillna(0)\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-05-14T04:42:47.027273Z","iopub.execute_input":"2022-05-14T04:42:47.027768Z","iopub.status.idle":"2022-05-14T04:42:47.038198Z","shell.execute_reply.started":"2022-05-14T04:42:47.027731Z","shell.execute_reply":"2022-05-14T04:42:47.037418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nstdsc = StandardScaler()","metadata":{"execution":{"iopub.status.busy":"2022-05-14T04:42:47.03966Z","iopub.execute_input":"2022-05-14T04:42:47.040168Z","iopub.status.idle":"2022-05-14T04:42:47.046636Z","shell.execute_reply.started":"2022-05-14T04:42:47.040133Z","shell.execute_reply":"2022-05-14T04:42:47.045668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_subf = subf.copy()\ntotal_subf.extend(new_subf)","metadata":{"execution":{"iopub.status.busy":"2022-05-14T04:42:47.048083Z","iopub.execute_input":"2022-05-14T04:42:47.048569Z","iopub.status.idle":"2022-05-14T04:42:47.055102Z","shell.execute_reply.started":"2022-05-14T04:42:47.048533Z","shell.execute_reply":"2022-05-14T04:42:47.054282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in total_subf:\n    stock_price_df = daily_normalize(stock_price_df,i)","metadata":{"execution":{"iopub.status.busy":"2022-05-14T04:42:47.05655Z","iopub.execute_input":"2022-05-14T04:42:47.057049Z","iopub.status.idle":"2022-05-14T04:44:25.86397Z","shell.execute_reply.started":"2022-05-14T04:42:47.057014Z","shell.execute_reply":"2022-05-14T04:44:25.863239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in total_subf:\n    stock_price_df[i] = stock_price_df[i].fillna(stock_price_df[i].mean())\nstock_price_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-14T04:44:25.865704Z","iopub.execute_input":"2022-05-14T04:44:25.866003Z","iopub.status.idle":"2022-05-14T04:44:26.33271Z","shell.execute_reply.started":"2022-05-14T04:44:25.865966Z","shell.execute_reply":"2022-05-14T04:44:26.331886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# normalize \"Target\" as well","metadata":{}},{"cell_type":"code","source":"stock_price_df = daily_normalize(stock_price_df,'Target')","metadata":{"execution":{"iopub.status.busy":"2022-05-14T04:44:26.334137Z","iopub.execute_input":"2022-05-14T04:44:26.334392Z","iopub.status.idle":"2022-05-14T04:44:30.515747Z","shell.execute_reply.started":"2022-05-14T04:44:26.334356Z","shell.execute_reply":"2022-05-14T04:44:30.514973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stock_price_df['Target'].head()","metadata":{"execution":{"iopub.status.busy":"2022-05-14T04:44:30.516832Z","iopub.execute_input":"2022-05-14T04:44:30.517224Z","iopub.status.idle":"2022-05-14T04:44:30.531236Z","shell.execute_reply.started":"2022-05-14T04:44:30.51719Z","shell.execute_reply":"2022-05-14T04:44:30.530524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tranform the \"SecuritiesCode\" of stock as well","metadata":{}},{"cell_type":"code","source":"investment_ids = list(stock_price_df['SecuritiesCode'].unique())\ninvestment_id_size = len(investment_ids) + 1\ninvestment_id_lookup_layer = layers.IntegerLookup(max_tokens=investment_id_size)\nwith tf.device(\"cpu\"):\n    investment_id_lookup_layer.adapt(stock_price_df['SecuritiesCode'])","metadata":{"execution":{"iopub.status.busy":"2022-05-14T04:44:30.534123Z","iopub.execute_input":"2022-05-14T04:44:30.536698Z","iopub.status.idle":"2022-05-14T04:45:14.154444Z","shell.execute_reply.started":"2022-05-14T04:44:30.53666Z","shell.execute_reply":"2022-05-14T04:45:14.153661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define the DNN model that separately trains \"SecuritiesCode\" & features, and then concatenate them together for the final training","metadata":{}},{"cell_type":"markdown","source":"## To avoid overfitting, I also use \"Dropout\" with a rate of 0.2, and apply Batch Normalization before concatenating the tensors trained from \"Code\" and the tensors trained from \"features\". ","metadata":{}},{"cell_type":"markdown","source":"## You can adjust number of layers, neurons, and etc.","metadata":{}},{"cell_type":"code","source":"def get_model():\n    investment_id_inputs = tf.keras.Input((1, ), dtype=tf.uint16)\n    features_inputs = tf.keras.Input((len(total_subf), ), dtype=tf.float16)\n    \n    investment_id_x = investment_id_lookup_layer(investment_id_inputs)\n    investment_id_x = layers.Embedding(investment_id_size, 3, input_length=1)(investment_id_x)\n    investment_id_x = layers.Reshape((-1, ))(investment_id_x)\n #   investment_id_x = layers.BatchNormalization(momentum=0.5)(investment_id_x)\n    investment_id_x = layers.Dense(16, activation='swish')(investment_id_x)\n    investment_id_x = layers.Dense(16, activation='swish')(investment_id_x)\n    \n   # feature_x = layers.BatchNormalization(momentum=0.5)(features_inputs)\n    feature_x = layers.Dense(16, activation='swish')(features_inputs)\n    feature_x = layers.Dense(16, activation='swish')(feature_x)\n    feature_x = layers.Dropout(0.2)(feature_x)\n    \n    x = layers.Concatenate(axis=1)([investment_id_x, feature_x])\n    x = layers.Dense(16, activation='swish', kernel_regularizer=\"l2\")(x)\n    x = layers.Dense(16, activation='swish', kernel_regularizer=\"l2\")(x)\n    x = layers.Dropout(0.2)(x)\n    \n    output = layers.Dense(1)(x)\n    \n    rmse = keras.metrics.RootMeanSquaredError(name=\"rmse\")\n    \n    model = tf.keras.Model(inputs=[investment_id_inputs, features_inputs], outputs=[output])\n    \n    model.compile(optimizer=tf.optimizers.Adam(0.01), loss='mse', metrics=['mse', \"mae\", \"mape\", rmse])\n    \n    return model\n","metadata":{"execution":{"iopub.status.busy":"2022-05-14T04:45:14.155812Z","iopub.execute_input":"2022-05-14T04:45:14.156083Z","iopub.status.idle":"2022-05-14T04:45:14.168919Z","shell.execute_reply.started":"2022-05-14T04:45:14.156046Z","shell.execute_reply":"2022-05-14T04:45:14.168277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Transform the train data so that it can used for DNN model training.","metadata":{}},{"cell_type":"code","source":"def preprocess(X, y):\n    print(X)\n    print(y)\n    return X, y\ndef make_dataset(feature, investment_id, y, batch_size=32, mode=\"train\"):\n    ds = tf.data.Dataset.from_tensor_slices(((investment_id, feature), y))\n    ds = ds.map(preprocess)\n    if mode == \"train\":\n        ds = ds.shuffle(256)\n    ds = ds.batch(batch_size).cache().prefetch(tf.data.experimental.AUTOTUNE)\n    return ds","metadata":{"execution":{"iopub.status.busy":"2022-05-14T04:45:14.170999Z","iopub.execute_input":"2022-05-14T04:45:14.171732Z","iopub.status.idle":"2022-05-14T04:45:14.178225Z","shell.execute_reply.started":"2022-05-14T04:45:14.171694Z","shell.execute_reply":"2022-05-14T04:45:14.177397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Use GroupKFold to train 5 DNN models (the same \"Sector\" stock should always be in the same group)","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GroupKFold\nkfold = GroupKFold(n_splits = 10)","metadata":{"execution":{"iopub.status.busy":"2022-05-14T04:45:14.179508Z","iopub.execute_input":"2022-05-14T04:45:14.179771Z","iopub.status.idle":"2022-05-14T04:45:14.189686Z","shell.execute_reply.started":"2022-05-14T04:45:14.179736Z","shell.execute_reply":"2022-05-14T04:45:14.189041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count=0\ndf_x = stock_price_df[total_subf]\ndf_y=stock_price_df['Target']\ntime_id = stock_price_df['33SectorCode']\ndnn_models = []\nfor train_index, val_index in kfold.split(df_x, df_y,time_id):\n    # Split training dataset.\n    train_x, train_y = df_x.iloc[train_index], df_y.iloc[train_index]\n    train_inv =stock_price_df['SecuritiesCode'].iloc[train_index]\n    # Split validation dataset.\n    val_x, val_y = df_x.iloc[val_index], df_y.iloc[val_index]\n    val_inv =  stock_price_df['SecuritiesCode'].iloc[val_index]\n    # Make tensor dataset.\n    tf_train = make_dataset(train_x, train_inv, train_y, batch_size=12000, mode=\"train\")\n    tf_val = make_dataset(val_x, val_inv, val_y, batch_size=12000, mode=\"train\")\n    # Load model\n    model = get_model()\n  \n    model.fit(tf_train, epochs = 1,\n             validation_data = (tf_val), shuffle=True)\n    model.save_weights('my_dnn_'+str(count)+'.tf')\n    dnn_models.append(model)\n    count+=1\n\n    del tf_train\n    del tf_val\n    del model, train_x, train_y, val_x, val_y","metadata":{"execution":{"iopub.status.busy":"2022-05-14T04:45:14.191334Z","iopub.execute_input":"2022-05-14T04:45:14.191862Z","iopub.status.idle":"2022-05-14T04:46:14.75125Z","shell.execute_reply.started":"2022-05-14T04:45:14.191827Z","shell.execute_reply":"2022-05-14T04:46:14.750547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Average model predictions","metadata":{}},{"cell_type":"code","source":"def infer(models, ds):\n    y_preds = []\n    for model in models:\n        y_pred = model.predict(ds)\n        y_preds.append(y_pred)\n    return np.mean(y_preds, axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-05-14T04:46:14.755256Z","iopub.execute_input":"2022-05-14T04:46:14.755476Z","iopub.status.idle":"2022-05-14T04:46:14.761931Z","shell.execute_reply.started":"2022-05-14T04:46:14.755449Z","shell.execute_reply":"2022-05-14T04:46:14.761166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Transform test set so that it can be used for prediction","metadata":{}},{"cell_type":"code","source":"def preprocess_test(investment_id, feature):\n    return (investment_id, feature), 0\n\ndef make_test_dataset(feature, investment_id, batch_size=1024):\n    ds = tf.data.Dataset.from_tensor_slices(((investment_id, feature)))\n    ds = ds.map(preprocess_test)\n    ds = ds.batch(batch_size).cache().prefetch(tf.data.experimental.AUTOTUNE)\n    return ds","metadata":{"execution":{"iopub.status.busy":"2022-05-14T04:46:14.762977Z","iopub.execute_input":"2022-05-14T04:46:14.763981Z","iopub.status.idle":"2022-05-14T04:46:14.770774Z","shell.execute_reply.started":"2022-05-14T04:46:14.763943Z","shell.execute_reply":"2022-05-14T04:46:14.770069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create features for the test set, normalize them, and use 5 DNN models averaging to make final prediction.","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import normalize","metadata":{"execution":{"iopub.status.busy":"2022-05-14T04:46:14.772109Z","iopub.execute_input":"2022-05-14T04:46:14.772383Z","iopub.status.idle":"2022-05-14T04:46:14.779097Z","shell.execute_reply.started":"2022-05-14T04:46:14.772344Z","shell.execute_reply":"2022-05-14T04:46:14.778421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import jpx_tokyo_market_prediction\nenv = jpx_tokyo_market_prediction.make_env()   # initialize the environment\niter_test = env.iter_test()    # an iterator which loops over the test files\nfor (prices, options, financials, trades, secondary_prices, sample_prediction) in iter_test:\n    \n    prices['ExpectedDividend'] = prices['ExpectedDividend'].fillna(0)\n    prices['SupervisionFlag'] = prices['SupervisionFlag'].map({True: 1, False: 0})\n    prices = pd.merge(prices,stock_list, on='SecuritiesCode')\n    \n    prices = FE(prices)\n    \n    for i in subf:\n        prices[i] = prices[i].fillna(prices[i].mean())\n\n    test_X = transformer.transform(prices[subf])\n    for i in range(0,len(new_subf)):\n        prices['fa_'+str(i)] = test_X[:,i]\n\n    prices[total_subf] = normalize(prices[total_subf],axis=0)\n\n    for i in total_subf:\n        prices[i] = prices[i].fillna(prices[i].mean())\n\n    prices['inference'] = -infer(dnn_models, make_test_dataset(prices[total_subf],prices['SecuritiesCode']))\n    prices['rank'] = prices['inference'].rank(method='first')-1\n    prices['rank'] = prices['rank'].apply(lambda x: int(x))\n    prices = prices.drop('Date',axis=1)\n\n    sample_prediction = pd.merge(sample_prediction, prices, on=['SecuritiesCode'])[['Date','SecuritiesCode','rank']]\n    sample_prediction['rank'] = sample_prediction['rank'].fillna(1000)\n    sample_prediction.columns = ['Date','SecuritiesCode','Rank']\n    print(sample_prediction)\n    \n    env.predict(sample_prediction)   # register your predictions","metadata":{"execution":{"iopub.status.busy":"2022-05-14T04:46:14.782085Z","iopub.execute_input":"2022-05-14T04:46:14.782305Z","iopub.status.idle":"2022-05-14T04:46:15.805668Z","shell.execute_reply.started":"2022-05-14T04:46:14.782281Z","shell.execute_reply":"2022-05-14T04:46:15.804881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_subf","metadata":{"execution":{"iopub.status.busy":"2022-05-14T04:46:15.807165Z","iopub.execute_input":"2022-05-14T04:46:15.807453Z","iopub.status.idle":"2022-05-14T04:46:15.815082Z","shell.execute_reply.started":"2022-05-14T04:46:15.807393Z","shell.execute_reply":"2022-05-14T04:46:15.814355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(np.unique(sample_prediction['Rank']))","metadata":{"execution":{"iopub.status.busy":"2022-05-14T04:46:15.816351Z","iopub.execute_input":"2022-05-14T04:46:15.816854Z","iopub.status.idle":"2022-05-14T04:46:15.825967Z","shell.execute_reply.started":"2022-05-14T04:46:15.816813Z","shell.execute_reply":"2022-05-14T04:46:15.825117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"alt = prices.copy()\nalt.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-14T04:46:15.827098Z","iopub.execute_input":"2022-05-14T04:46:15.827982Z","iopub.status.idle":"2022-05-14T04:46:15.855983Z","shell.execute_reply.started":"2022-05-14T04:46:15.82794Z","shell.execute_reply":"2022-05-14T04:46:15.855303Z"},"trusted":true},"execution_count":null,"outputs":[]}]}