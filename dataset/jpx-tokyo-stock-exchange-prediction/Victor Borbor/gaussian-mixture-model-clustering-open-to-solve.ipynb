{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Step A | Data Preprocessing","metadata":{}},{"cell_type":"markdown","source":"## Importing the data","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-18T18:27:08.717249Z","iopub.execute_input":"2022-04-18T18:27:08.718181Z","iopub.status.idle":"2022-04-18T18:27:08.772615Z","shell.execute_reply.started":"2022-04-18T18:27:08.718036Z","shell.execute_reply":"2022-04-18T18:27:08.771994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import the stock_prices data\nstocks = pd.read_csv(\"../input/jpx-tokyo-stock-exchange-prediction/example_test_files/stock_prices.csv\")\n# Display the first observations of the attributes\nstocks.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-18T18:27:08.774189Z","iopub.execute_input":"2022-04-18T18:27:08.774419Z","iopub.status.idle":"2022-04-18T18:27:08.826852Z","shell.execute_reply.started":"2022-04-18T18:27:08.774389Z","shell.execute_reply":"2022-04-18T18:27:08.826198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Imputer to missing values","metadata":{}},{"cell_type":"code","source":"# Import the SimpleImputer class from the sklearn.impute library\nfrom sklearn.impute import SimpleImputer\n# Save the SimpleImputer() class in imputer\nimputer = SimpleImputer()\n# Loc the High and Low Features \nhl_stocks = stocks.loc[ : , ['Volume', 'Open']]\n# Fill the missing values with the mean of the observations\nhl_stocks = imputer.fit_transform(hl_stocks)\n# Convert the ndarray to pandas dataframe\nhl_df = pd.DataFrame(hl_stocks, columns = ['Volume','Open'])\n# Check the attributes without missing values\nhl_df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-04-18T18:27:08.828455Z","iopub.execute_input":"2022-04-18T18:27:08.82879Z","iopub.status.idle":"2022-04-18T18:27:10.135585Z","shell.execute_reply.started":"2022-04-18T18:27:08.828723Z","shell.execute_reply":"2022-04-18T18:27:10.134592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Plotting","metadata":{}},{"cell_type":"markdown","source":"# Step B | Feature Scaling","metadata":{}},{"cell_type":"code","source":"# Import StandardScaler class from sklearn.preprocessing library\nfrom sklearn.preprocessing import StandardScaler","metadata":{"execution":{"iopub.status.busy":"2022-04-18T18:27:10.137991Z","iopub.execute_input":"2022-04-18T18:27:10.138392Z","iopub.status.idle":"2022-04-18T18:27:10.142721Z","shell.execute_reply.started":"2022-04-18T18:27:10.138347Z","shell.execute_reply":"2022-04-18T18:27:10.141908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save only the features columns in X\nX = hl_df\n# Save the StandardScaler() class in z \nz = StandardScaler()\n# Selecting the feature attributes of X\n# Make fitting, that means searching the mean and std\n# And transform deeveloping the standardization formula\nX = z.fit_transform(X)\n# Save the values in the Volume and Open attributes inner the df\nX_df = pd.DataFrame(X, columns = ['Volume','Open'])","metadata":{"execution":{"iopub.status.busy":"2022-04-18T18:27:10.143843Z","iopub.execute_input":"2022-04-18T18:27:10.144079Z","iopub.status.idle":"2022-04-18T18:27:10.160331Z","shell.execute_reply.started":"2022-04-18T18:27:10.144053Z","shell.execute_reply":"2022-04-18T18:27:10.159759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step C | Gaussian Mixture Clustering ","metadata":{}},{"cell_type":"code","source":"# Import KMeans class from sklearn.cluster library\nfrom sklearn.cluster import KMeans\n# Import GaussianMixture class from sklearn.mixture library\nfrom sklearn.mixture import GaussianMixture","metadata":{"execution":{"iopub.status.busy":"2022-04-18T18:27:10.162126Z","iopub.execute_input":"2022-04-18T18:27:10.162685Z","iopub.status.idle":"2022-04-18T18:27:10.264679Z","shell.execute_reply.started":"2022-04-18T18:27:10.162642Z","shell.execute_reply":"2022-04-18T18:27:10.263803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the GaussianMixture class with three cluster\nEM = GaussianMixture(n_components = 3)\n# Fit the X dataset in the EM\nEM.fit(X_df)\n# Save the predict of the EM in cluster points (0 to 2)\ncluster = EM.predict(X_df)\ncluster","metadata":{"execution":{"iopub.status.busy":"2022-04-18T18:27:10.265914Z","iopub.execute_input":"2022-04-18T18:27:10.266155Z","iopub.status.idle":"2022-04-18T18:27:10.347374Z","shell.execute_reply.started":"2022-04-18T18:27:10.266124Z","shell.execute_reply":"2022-04-18T18:27:10.346482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Probability to enter in a cluster\ncluster_p = EM.predict_proba(X_df)\ncluster_p","metadata":{"execution":{"iopub.status.busy":"2022-04-18T18:27:10.348706Z","iopub.execute_input":"2022-04-18T18:27:10.34921Z","iopub.status.idle":"2022-04-18T18:27:10.361312Z","shell.execute_reply.started":"2022-04-18T18:27:10.349166Z","shell.execute_reply":"2022-04-18T18:27:10.360221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Silhouette Coefficient\n\nA metric used to calculate the **goodness** of a clustering technique. \n\nIts value ranges from **-1 to 1**.","metadata":{}},{"cell_type":"code","source":"# Import the silhouette_score class from sklearn.metrics library\nfrom sklearn.metrics import silhouette_score","metadata":{"execution":{"iopub.status.busy":"2022-04-18T18:27:10.362619Z","iopub.execute_input":"2022-04-18T18:27:10.363215Z","iopub.status.idle":"2022-04-18T18:27:10.370655Z","shell.execute_reply.started":"2022-04-18T18:27:10.363166Z","shell.execute_reply":"2022-04-18T18:27:10.36981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print the Silhouette Coefficient using the silhouette_score class\n# Parameters are the dataset and the cluster viewed previously\nprint('Silhouette Coefficient:', silhouette_score(X_df, cluster))","metadata":{"execution":{"iopub.status.busy":"2022-04-18T18:27:10.37363Z","iopub.execute_input":"2022-04-18T18:27:10.374322Z","iopub.status.idle":"2022-04-18T18:27:10.689382Z","shell.execute_reply.started":"2022-04-18T18:27:10.374276Z","shell.execute_reply":"2022-04-18T18:27:10.688484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Cluster Plotting","metadata":{}},{"cell_type":"code","source":"# Save the cluster in a new cluster attributte in X\n# This step works with datframes\nX_df['Cluster'] = cluster","metadata":{"execution":{"iopub.status.busy":"2022-04-18T18:27:10.691056Z","iopub.execute_input":"2022-04-18T18:27:10.691358Z","iopub.status.idle":"2022-04-18T18:27:10.698041Z","shell.execute_reply.started":"2022-04-18T18:27:10.691318Z","shell.execute_reply":"2022-04-18T18:27:10.697063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import plotnine library for grammar graphics\nfrom plotnine import *\n# To manage graphs without windows\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-04-18T18:27:10.699704Z","iopub.execute_input":"2022-04-18T18:27:10.700057Z","iopub.status.idle":"2022-04-18T18:27:12.589279Z","shell.execute_reply.started":"2022-04-18T18:27:10.700016Z","shell.execute_reply":"2022-04-18T18:27:12.588528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot using X_df dataframe with Volume as x-axis, Open as y-axis\n(ggplot(X_df, aes(x='Volume', y='Open', color='Cluster')) + geom_point())","metadata":{"execution":{"iopub.status.busy":"2022-04-18T18:27:12.590543Z","iopub.execute_input":"2022-04-18T18:27:12.590805Z","iopub.status.idle":"2022-04-18T18:27:13.163245Z","shell.execute_reply.started":"2022-04-18T18:27:12.590769Z","shell.execute_reply":"2022-04-18T18:27:13.162362Z"},"trusted":true},"execution_count":null,"outputs":[]}]}