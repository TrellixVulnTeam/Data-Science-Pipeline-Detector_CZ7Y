{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!cp ../input/talibinstall/ta-lib-0.4.0-src.tar.gzh  ./ta-lib-0.4.0-src.tar.gz\n!tar -xzvf ta-lib-0.4.0-src.tar.gz > null\n!cd ta-lib && ./configure --prefix=/usr > null && make  > null && make install > null\n!cp ../input/talibinstall/TA-Lib-0.4.21.tar.gzh TA-Lib-0.4.21.tar.gz\n!pip install TA-Lib-0.4.21.tar.gz > null\n!pip install ../input/talibinstall/numpy-1.21.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl >null\n\n!rm -rf ./ta-lib\n!rm  ./TA-Lib-0.4.21.tar.gz\n!rm  ./ta-lib-0.4.0-src.tar.gz\n!rm  ./null\n\nimport talib as ta","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":258.591738,"end_time":"2022-05-24T07:42:25.178484","exception":false,"start_time":"2022-05-24T07:38:06.586746","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-20T05:00:46.588815Z","iopub.execute_input":"2022-06-20T05:00:46.589171Z","iopub.status.idle":"2022-06-20T05:04:58.084217Z","shell.execute_reply.started":"2022-06-20T05:00:46.589067Z","shell.execute_reply":"2022-06-20T05:04:58.082499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport gc\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport json\nimport numpy as np\nfrom scipy.special import comb\nfrom itertools import combinations\n\nclass CombinatorialPurgedGroupKFold():\n    def __init__(self, n_splits = 6, n_test_splits = 2, purge = 1, pctEmbargo = 0.01, **kwargs):\n        self.n_splits = n_splits\n        self.n_test_splits = n_test_splits\n        self.purge = purge\n        self.pctEmbargo = pctEmbargo\n        \n    def split(self, X, y = None, groups = None):\n        if groups is None:\n            raise ValueError(\n                \"The 'groups' parameter should not be None\")\n            \n        u, ind = np.unique(groups, return_index = True)\n        unique_groups = u[np.argsort(ind)]\n        n_groups = len(unique_groups)\n        group_dict = {}\n        for idx in range(len(X)):\n            if groups[idx] in group_dict:\n                group_dict[groups[idx]].append(idx)\n            else:\n                group_dict[groups[idx]] = [idx]\n                \n        n_folds = comb(self.n_splits, self.n_test_splits, exact = True)\n        if n_folds > n_groups:\n            raise ValueError(\n                (\"Cannot have number of folds={0} greater than\"\n                 \" the number of groups={1}\").format(n_folds,\n                                                     n_groups))\n            \n        mbrg = int(n_groups * self.pctEmbargo)\n        if mbrg < 0:\n            raise ValueError(\n                \"The number of 'embargoed' groups should not be negative\")\n        \n        split_dict = {}\n        group_test_size = n_groups // self.n_splits\n        for split in range(self.n_splits):\n            if split == self.n_splits - 1:\n                split_dict[split] = unique_groups[int(split * group_test_size):].tolist()\n            else:\n                split_dict[split] = unique_groups[int(split * group_test_size):int((split + 1) * group_test_size)].tolist()\n        \n        for test_splits in combinations(range(self.n_splits), self.n_test_splits):\n            test_groups = []\n            banned_groups = []\n            for split in test_splits:\n                test_groups += split_dict[split]\n                banned_groups += unique_groups[split_dict[split][0] - self.purge:split_dict[split][0]].tolist()\n                banned_groups += unique_groups[split_dict[split][-1] + 1:split_dict[split][-1] + self.purge + mbrg + 1].tolist()\n            train_groups = [i for i in unique_groups if (i not in banned_groups) and (i not in test_groups)]\n\n            train_idx = []\n            test_idx = []\n            for train_group in train_groups:\n                train_idx += group_dict[train_group]\n            for test_group in test_groups:\n                test_idx += group_dict[test_group]\n            yield train_idx, test_idx","metadata":{"papermill":{"duration":6.362943,"end_time":"2022-05-24T07:42:31.568011","exception":false,"start_time":"2022-05-24T07:42:25.205068","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-20T05:04:58.087053Z","iopub.execute_input":"2022-06-20T05:04:58.087363Z","iopub.status.idle":"2022-06-20T05:05:04.320757Z","shell.execute_reply.started":"2022-06-20T05:04:58.087325Z","shell.execute_reply":"2022-06-20T05:05:04.319493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc, os\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\nimport plotly as py\nimport plotly.graph_objs as go\nimport plotly.tools as tools\n\nfrom tqdm.notebook import tqdm","metadata":{"papermill":{"duration":0.805468,"end_time":"2022-05-24T07:42:32.400838","exception":false,"start_time":"2022-05-24T07:42:31.59537","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-20T05:20:17.263188Z","iopub.execute_input":"2022-06-20T05:20:17.26355Z","iopub.status.idle":"2022-06-20T05:20:17.397184Z","shell.execute_reply.started":"2022-06-20T05:20:17.263514Z","shell.execute_reply":"2022-06-20T05:20:17.395879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy.polynomial.hermite as Herm\nimport math\nfrom tensorflow.python.ops import math_ops\nfrom scipy import stats\nimport tensorflow_probability as tfp","metadata":{"papermill":{"duration":3.209507,"end_time":"2022-05-24T07:42:35.637948","exception":false,"start_time":"2022-05-24T07:42:32.428441","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-20T05:05:04.653809Z","iopub.execute_input":"2022-06-20T05:05:04.654091Z","iopub.status.idle":"2022-06-20T05:05:07.840259Z","shell.execute_reply.started":"2022-06-20T05:05:04.654058Z","shell.execute_reply":"2022-06-20T05:05:07.839451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path_s = \"../input/jpx-tokyo-stock-exchange-prediction/supplemental_files/\"\npath_t = \"../input/jpx-tokyo-stock-exchange-prediction/train_files/\"\npath_e = \"../input/jpx-tokyo-stock-exchange-prediction/example_test_files/\"","metadata":{"papermill":{"duration":0.035452,"end_time":"2022-05-24T07:42:35.702035","exception":false,"start_time":"2022-05-24T07:42:35.666583","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-20T05:05:07.841447Z","iopub.execute_input":"2022-06-20T05:05:07.842432Z","iopub.status.idle":"2022-06-20T05:05:07.848328Z","shell.execute_reply.started":"2022-06-20T05:05:07.842346Z","shell.execute_reply":"2022-06-20T05:05:07.847224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prices1 = pd.read_csv(f\"{path_s}stock_prices.csv\") #2021\nprices2 = pd.read_csv(f\"{path_t}stock_prices.csv\") #2017\nprices3 = pd.read_csv(f\"{path_t}secondary_stock_prices.csv\")\n\nprices1.shape , prices2.shape, prices3.shape","metadata":{"papermill":{"duration":15.509849,"end_time":"2022-05-24T07:42:51.23834","exception":false,"start_time":"2022-05-24T07:42:35.728491","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-20T05:05:07.849574Z","iopub.execute_input":"2022-06-20T05:05:07.850435Z","iopub.status.idle":"2022-06-20T05:05:22.818453Z","shell.execute_reply.started":"2022-06-20T05:05:07.850401Z","shell.execute_reply":"2022-06-20T05:05:22.817237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prices2['Target'].isnull().sum(), prices1['Target'].isnull().sum(), prices3['Target'].isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-06-20T05:05:22.820313Z","iopub.execute_input":"2022-06-20T05:05:22.820633Z","iopub.status.idle":"2022-06-20T05:05:22.845989Z","shell.execute_reply.started":"2022-06-20T05:05:22.820579Z","shell.execute_reply":"2022-06-20T05:05:22.84498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train2 = prices2.dropna(subset=['Target'])\n#train1 = prices1.dropna(subset=['Target'])\n\ntrain2, train1 = prices2.fillna(0), prices1.fillna(0)","metadata":{"execution":{"iopub.status.busy":"2022-06-20T05:08:13.13564Z","iopub.execute_input":"2022-06-20T05:08:13.137699Z","iopub.status.idle":"2022-06-20T05:08:13.856295Z","shell.execute_reply.started":"2022-06-20T05:08:13.137612Z","shell.execute_reply":"2022-06-20T05:08:13.85518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train2['Target'].isnull().sum(), train1['Target'].isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-06-20T05:08:14.471733Z","iopub.execute_input":"2022-06-20T05:08:14.472145Z","iopub.status.idle":"2022-06-20T05:08:14.495198Z","shell.execute_reply.started":"2022-06-20T05:08:14.472108Z","shell.execute_reply":"2022-06-20T05:08:14.494225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.concat([train2,train1])","metadata":{"papermill":{"duration":1.378435,"end_time":"2022-05-24T07:42:52.646517","exception":false,"start_time":"2022-05-24T07:42:51.268082","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-20T05:08:15.61555Z","iopub.execute_input":"2022-06-20T05:08:15.616491Z","iopub.status.idle":"2022-06-20T05:08:15.90936Z","shell.execute_reply.started":"2022-06-20T05:08:15.61645Z","shell.execute_reply":"2022-06-20T05:08:15.908462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prep_prices(prices):\n    prices.fillna(0,inplace=True)\n    return prices","metadata":{"papermill":{"duration":0.040074,"end_time":"2022-05-24T07:42:52.716167","exception":false,"start_time":"2022-05-24T07:42:52.676093","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-20T05:08:16.560975Z","iopub.execute_input":"2022-06-20T05:08:16.561973Z","iopub.status.idle":"2022-06-20T05:08:16.567582Z","shell.execute_reply.started":"2022-06-20T05:08:16.561912Z","shell.execute_reply":"2022-06-20T05:08:16.566736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#simple units\nhbar = 1.0\nm    = 1.0\nw    = 1.0\n\ndef hermite(x, n):\n    xi             = np.sqrt(m*w/hbar)*x\n    herm_coeffs    = np.zeros(n+1)\n    herm_coeffs[n] = 1\n    return Herm.hermval(xi, herm_coeffs)\n\ndef stationary_state(x,n):\n    xi        = np.sqrt(m*w/hbar)*x\n    prefactor = 1.0/math.sqrt(2.0**n * math.factorial(n)) * (m*w/(np.pi*hbar))**(0.25)\n    psi       = prefactor * np.exp(- xi**2 / 2) * hermite(x,n)\n    return psi","metadata":{"papermill":{"duration":0.044427,"end_time":"2022-05-24T07:42:52.789592","exception":false,"start_time":"2022-05-24T07:42:52.745165","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-20T05:08:17.046134Z","iopub.execute_input":"2022-06-20T05:08:17.046496Z","iopub.status.idle":"2022-06-20T05:08:17.055Z","shell.execute_reply.started":"2022-06-20T05:08:17.046459Z","shell.execute_reply":"2022-06-20T05:08:17.054219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NDAYS = 180\nlastdays = df[df[\"Date\"]>=df.Date.iat[-2000*NDAYS]].reset_index(drop=True)","metadata":{"papermill":{"duration":0.722197,"end_time":"2022-05-24T07:42:53.613567","exception":false,"start_time":"2022-05-24T07:42:52.89137","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-20T05:08:18.182713Z","iopub.execute_input":"2022-06-20T05:08:18.183866Z","iopub.status.idle":"2022-06-20T05:08:19.194575Z","shell.execute_reply.started":"2022-06-20T05:08:18.1838Z","shell.execute_reply":"2022-06-20T05:08:19.19339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lastdays = pd.DataFrame(df.groupby(\"SecuritiesCode\").Target.mean())\ndef get_avg(_id_):\n    return lastdays.loc[_id_]","metadata":{"papermill":{"duration":0.135073,"end_time":"2022-05-24T07:42:53.780912","exception":false,"start_time":"2022-05-24T07:42:53.645839","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-20T05:08:19.19692Z","iopub.execute_input":"2022-06-20T05:08:19.197281Z","iopub.status.idle":"2022-06-20T05:08:19.288832Z","shell.execute_reply.started":"2022-06-20T05:08:19.197237Z","shell.execute_reply":"2022-06-20T05:08:19.287545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def daily_standardize(df,col):\n    avg = df[[col,'Date']].groupby('Date').mean()\n    avg.columns = ['avg']\n    avg['Date'] = avg.index\n    avg = avg.reset_index(drop=True)\n    std = df[[col,'Date']].groupby('Date').std()\n    std.columns = ['std']\n    std['Date'] = std.index\n    std = std.reset_index(drop=True)\n    df = pd.merge(df, avg, on='Date')\n    df = pd.merge(df,std,on='Date')\n    df[col] = (df[col] - df['avg'])/df['std']\n    df = df.drop(['avg','std'],axis=1)\n    df[col] = df[col].fillna(0)\n    return df","metadata":{"papermill":{"duration":0.041547,"end_time":"2022-05-24T07:44:01.078125","exception":false,"start_time":"2022-05-24T07:44:01.036578","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-20T05:08:19.290564Z","iopub.execute_input":"2022-06-20T05:08:19.290893Z","iopub.status.idle":"2022-06-20T05:08:19.301333Z","shell.execute_reply.started":"2022-06-20T05:08:19.290853Z","shell.execute_reply":"2022-06-20T05:08:19.299914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from decimal import *\ndef adjust_price(price):\n    \"\"\"\n    Args:\n        price (pd.DataFrame)  : pd.DataFrame include stock_price\n    Returns:\n        price DataFrame (pd.DataFrame): stock_price with generated AdjustedClose\n    \"\"\"\n    # transform Date column into datetime\n    price.loc[: ,\"Date\"] = pd.to_datetime(price.loc[: ,\"Date\"], format=\"%Y-%m-%d\")\n\n    def generate_adjusted_close(df):\n        \"\"\"\n        Args:\n            df (pd.DataFrame)  : stock_price for a single SecuritiesCode\n        Returns:\n            df (pd.DataFrame): stock_price with AdjustedClose for a single SecuritiesCode\n        \"\"\"\n        # sort data to generate CumulativeAdjustmentFactor\n        df = df.sort_values(\"Date\", ascending=False)\n        # generate CumulativeAdjustmentFactor\n        df.loc[:, \"CumulativeAdjustmentFactor\"] = df[\"AdjustmentFactor\"].cumprod()\n        # generate AdjustedClose\n        df.loc[:, \"AdjustedClose\"] = (\n            df[\"CumulativeAdjustmentFactor\"] * df[\"Close\"]\n        ).map(lambda x: float(\n            Decimal(str(x)).quantize(Decimal('0.1'), rounding=ROUND_HALF_UP)\n        ))\n        # reverse order\n        df = df.sort_values(\"Date\")\n        # to fill AdjustedClose, replace 0 into np.nan\n        df.loc[df[\"AdjustedClose\"] == 0, \"AdjustedClose\"] = np.nan\n        # forward fill AdjustedClose\n        df.loc[:, \"AdjustedClose\"] = df.loc[:, \"AdjustedClose\"].ffill()\n        return df\n\n    # generate AdjustedClose\n    price = price.sort_values([\"SecuritiesCode\", \"Date\"])\n    price = price.groupby(\"SecuritiesCode\").apply(generate_adjusted_close).reset_index(drop=True)\n\n    price.set_index(\"Date\", inplace=True)\n    return price","metadata":{"execution":{"iopub.status.busy":"2022-06-20T05:08:19.953988Z","iopub.execute_input":"2022-06-20T05:08:19.954331Z","iopub.status.idle":"2022-06-20T05:08:19.96759Z","shell.execute_reply.started":"2022-06-20T05:08:19.954289Z","shell.execute_reply":"2022-06-20T05:08:19.966073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def adjust_features(df):\n    df=df.copy()\n    col='AdjustedClose'\n    periods=[3,5,8,12,15,26,30,35,40,45,50,60,]\n    for period in periods:\n        df.loc[:,\"Return_{}Day\".format(period)] = df.groupby(\"SecuritiesCode\")[col].pct_change(period)\n        df.loc[:,\"MovingAvg_{}Day\".format(period)] = df.groupby(\"SecuritiesCode\")[col].rolling(window=period).mean().values\n        df.loc[:,\"ExpMovingAvg_{}Day\".format(period)] = df.groupby(\"SecuritiesCode\")[col].ewm(span=period,adjust=False).mean().values\n        df.loc[:,\"Volatility_{}Day\".format(period)] = np.log(df[col]).groupby(df[\"SecuritiesCode\"]).diff().rolling(period).std()\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-06-20T05:08:21.16173Z","iopub.execute_input":"2022-06-20T05:08:21.162433Z","iopub.status.idle":"2022-06-20T05:08:21.171909Z","shell.execute_reply.started":"2022-06-20T05:08:21.162378Z","shell.execute_reply":"2022-06-20T05:08:21.170635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_features(df, tr=True):    \n    df = adjust_price(df)\n    df = adjust_features(df)\n    df = prep_prices(df)\n    \n    scale_features = df.columns.drop(['SecuritiesCode','Target'])    \n    #df[scale_features] = MinMaxScaler(feature_range=(0,1)).fit_transform(df[scale_features]) \n    df[scale_features] = RobustScaler().fit_transform(df[scale_features]) \n    \n    df['upper_Shadow']   = df['High'] - np.maximum(df['Close'], df['Open'])\n    df['lower_Shadow']   = np.minimum(df['Close'], df['Open']) - df['Low'] \n\n    # The Golden Ratio Multiplier \n    df['GRM_0']    = (ta.MA(df['Close'], timeperiod=350, matype=0)) \n    df['GRM_1']    = (ta.MA(df['Close'], timeperiod=350, matype=0))*1.6  \n    df['GRM_2']    = (ta.MA(df['Close'], timeperiod=350, matype=0))*2\n    df['GRM_3']    = (ta.MA(df['Close'], timeperiod=350, matype=0))*3\n\n    df['Pi_Cycle'] = ta.MA(df['Close'], timeperiod=111, matype=0) \n    \n    # Momentum\n    df['RSI_14'] = ta.RSI(df['Close'], timeperiod=14)\n    df['RSI_24'] = ta.RSI(df['Close'], timeperiod=24)\n    df['RSI_42'] = ta.RSI(df['Close'], timeperiod=42)\n    \n    df['RSI1']   = df['RSI_14'].shift(-1) \n    df['RSI4']   = df['RSI_14'].shift(-4) \n    df['RSI7']   = df['RSI_14'].shift(-7) \n    df['RSI10']  = df['RSI_14'].shift(-10) \n    df['RSI13']  = df['RSI_14'].shift(-13) \n    df['RSI16']  = df['RSI_14'].shift(-16) \n    \n    df['MACD_12'], df['macdsignal_12'], df['MACD_HIST_12'] = ta.MACD(df['Close'], fastperiod=12, slowperiod=26, signalperiod=9) \n    df['MACD_48'], df['macdsignal_48'], df['MACD_HIST_48'] = ta.MACD(df['Close'], fastperiod=48, slowperiod=104, signalperiod=36)\n    \n    df['macdsignal1'] = df['macdsignal_12'].shift(-1)\n    df['macdsignal4'] = df['macdsignal_12'].shift(-4)\n    df['macdsignal7'] = df['macdsignal_12'].shift(-7)\n    df['MACD_HIST1']  = df['MACD_HIST_12'].shift(-1) \n    df['MACD_HIST4']  = df['MACD_HIST_12'].shift(-4) \n    df['MACD_HIST7']  = df['MACD_HIST_12'].shift(-7) \n    df['ROCP']     = ta.ROCP(df['Open'])\n    df['momentam'] = ta.MOM(df['Open'])\n    df['CMO']      = ta.CMO(df['Open']) \n    df['PPO']      = ta.PPO(df['Open'])\n    df['SAR']       = ta.SAR(df['High'], df['Low'], acceleration=0, maximum=0) \n    df['DI_minus']  = ta.MINUS_DI(df['High'], df['Low'],np.array(df.loc[:, 'Close']), timeperiod=14) \n    df['DI_minus1'] = df['DI_minus'].shift(-1) \n    df['DI_minus4'] = df['DI_minus'].shift(-4) \n    df['DI_minus7'] = df['DI_minus'].shift(-7)  \n    df['adx']    = ta.ADX(df['High'], df['Low'],np.array(df.loc[:, 'Close']),timeperiod=14) \n    df['adx1']   = df['adx'].shift(-1) \n    df['adx4']   = df['adx'].shift(-4) \n    df['adx+1']  = df['adx'].shift(1) \n    df['adx7']   = df['adx'].shift(-7)\n    df['DI_plus']   = ta.PLUS_DI(df['High'], df['Low'],np.array(df.loc[:, 'Close']), timeperiod=14) \n    df['DI_plus1']  = df['DI_plus'].shift(-1) \n    df['DI_plus4']  = df['DI_plus'].shift(-4) \n    df['DI_plus7']  = df['DI_plus'].shift(-7) \n    df['DI_plus10'] = df['DI_plus'].shift(-10)\n    df['APO']      = ta.APO(df['Open'])\n    df['APO1']     = df['APO'].shift(-1)\n    df['APO4']     = df['APO'].shift(-4)\n    df['APO7']     = df['APO'].shift(-7)\n    df['ROCR100']  = ta.AD(df['High'], df['Low'], df['Close'], df['Volume'])\n    df['OBV']      = ta.OBV(df['Close'], df['Volume'])\n    df['ADOSC']    = ta.ADOSC(df['High'], df['Low'], df['Close'], df['Volume'], fastperiod=3, slowperiod=10)\n    df['TSF']      = ta.TSF(df['Close'], timeperiod=14) \n    df['TSF-14']   = ta.TSF(df['Close'], timeperiod=14).shift(-14)\n    df['TSF-7']    = ta.TSF(df['Close'], timeperiod=14).shift(-7)\n    df['ATR']    = ta.ATR(df['High'], df['Low'], df['Close'], timeperiod=14)\n    df['NATR']   = ta.NATR(df['High'], df['Low'], df['Close'], timeperiod=14)\n    \n    df['s_avg']      = df['SecuritiesCode'].apply(get_avg)\n    df['qhm_115v']   = stationary_state(df['s_avg'], 115) \n    \n    ema_set = [3,5,8,12,15,26,30,35,40,45,50,60, 100,200]\n    # EMA\n    for i in range(len(ema_set)):        \n        sma = df['Close'].rolling(ema_set[i]).mean()\n        ema = sma.ewm(span=ema_set[i], adjust=False).mean()\n        df[\"EMA_C_%d\"%(ema_set[i])] = ema\n                                                 \n        df = prep_prices(df)\n    \n    if tr:\n        df = df.drop(['RowId','AdjustmentFactor','ExpectedDividend','SupervisionFlag','AdjustedClose'],axis=1)\n    return df","metadata":{"papermill":{"duration":0.315084,"end_time":"2022-05-24T07:44:01.423972","exception":false,"start_time":"2022-05-24T07:44:01.108888","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-20T05:08:22.008773Z","iopub.execute_input":"2022-06-20T05:08:22.009238Z","iopub.status.idle":"2022-06-20T05:08:22.050059Z","shell.execute_reply.started":"2022-06-20T05:08:22.009201Z","shell.execute_reply":"2022-06-20T05:08:22.048921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = get_features(df)\ngroups   = pd.factorize(train_df.index)[0]\ntrain    = train_df.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-20T05:08:22.916651Z","iopub.execute_input":"2022-06-20T05:08:22.917008Z","iopub.status.idle":"2022-06-20T05:16:38.381403Z","shell.execute_reply.started":"2022-06-20T05:08:22.916973Z","shell.execute_reply":"2022-06-20T05:16:38.379954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"securities_code = train.pop(\"SecuritiesCode\")\ny               = train.pop(\"Target\")","metadata":{"papermill":{"duration":0.042832,"end_time":"2022-05-24T07:57:29.358142","exception":false,"start_time":"2022-05-24T07:57:29.31531","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-20T05:16:38.383965Z","iopub.execute_input":"2022-06-20T05:16:38.384315Z","iopub.status.idle":"2022-06-20T05:16:38.393947Z","shell.execute_reply.started":"2022-06-20T05:16:38.384266Z","shell.execute_reply":"2022-06-20T05:16:38.392569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corrs = list()\nfor col in tqdm(train.columns):\n    corr = np.corrcoef(y, train[col])[0][1]\n    corrs.append(corr)","metadata":{"execution":{"iopub.status.busy":"2022-06-20T05:20:21.703225Z","iopub.execute_input":"2022-06-20T05:20:21.703514Z","iopub.status.idle":"2022-06-20T05:20:27.613262Z","shell.execute_reply.started":"2022-06-20T05:20:21.703485Z","shell.execute_reply":"2022-06-20T05:20:27.6123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feat_importances = pd.Series(corrs, index=train.columns)\nlabels = feat_importances.index\nvalues = feat_importances.value_counts().index\nfig = go.Figure(data=[go.Pie(labels=labels, values=values, hole=.6)])\nfig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\nfig['layout'].update(height=800, width=800)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-20T05:20:35.793122Z","iopub.execute_input":"2022-06-20T05:20:35.793442Z","iopub.status.idle":"2022-06-20T05:20:35.814118Z","shell.execute_reply.started":"2022-06-20T05:20:35.793413Z","shell.execute_reply":"2022-06-20T05:20:35.813096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"select_n = 16\npositive_feat = feat_importances.nlargest(select_n)\nnegative_feat = feat_importances.nlargest(len(feat_importances))[-select_n:]","metadata":{"execution":{"iopub.status.busy":"2022-06-20T05:20:42.984821Z","iopub.execute_input":"2022-06-20T05:20:42.985128Z","iopub.status.idle":"2022-06-20T05:20:42.993395Z","shell.execute_reply.started":"2022-06-20T05:20:42.985095Z","shell.execute_reply":"2022-06-20T05:20:42.992271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = go.Figure(data=[go.Pie(labels=positive_feat.index, values=positive_feat.value_counts().index, hole=.6)])\nfig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\nfig['layout'].update(height=800, width=800, title={\n                                                     'text': \"Positive Feature\",\n                                                     'y':0.95,\n                                                     'x':0.42,\n                                                     'xanchor': 'center',\n                                                     'yanchor': 'top' })\nfig.show()\n\nfig = go.Figure(data=[go.Pie(labels=negative_feat.index, values=negative_feat.value_counts().index*-1, hole=.6)])\nfig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\nfig['layout'].update(height=800, width=800, title={\n                                                     'text': \"Negative Feature\",\n                                                     'y':0.95,\n                                                     'x':0.42,\n                                                     'xanchor': 'center',\n                                                     'yanchor': 'top' })\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-20T05:22:58.411389Z","iopub.execute_input":"2022-06-20T05:22:58.411688Z","iopub.status.idle":"2022-06-20T05:22:58.44813Z","shell.execute_reply.started":"2022-06-20T05:22:58.411659Z","shell.execute_reply":"2022-06-20T05:22:58.447517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feats = pd.concat([positive_feat,negative_feat]).index\nfeats.shape[-1]","metadata":{"execution":{"iopub.status.busy":"2022-06-20T05:24:30.382513Z","iopub.execute_input":"2022-06-20T05:24:30.382848Z","iopub.status.idle":"2022-06-20T05:24:30.392018Z","shell.execute_reply.started":"2022-06-20T05:24:30.382817Z","shell.execute_reply":"2022-06-20T05:24:30.390778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train[feats]","metadata":{"execution":{"iopub.status.busy":"2022-06-20T05:24:33.111758Z","iopub.execute_input":"2022-06-20T05:24:33.112075Z","iopub.status.idle":"2022-06-20T05:24:39.47464Z","shell.execute_reply.started":"2022-06-20T05:24:33.112041Z","shell.execute_reply":"2022-06-20T05:24:39.473511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2022-06-20T05:24:50.2034Z","iopub.execute_input":"2022-06-20T05:24:50.203735Z","iopub.status.idle":"2022-06-20T05:24:50.428346Z","shell.execute_reply.started":"2022-06-20T05:24:50.203701Z","shell.execute_reply":"2022-06-20T05:24:50.424267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nfrom sklearn import decomposition\npca    = decomposition.PCA(n_components=34)\ndf_pca = pca.fit_transform(train)\n'''","metadata":{"execution":{"iopub.status.busy":"2022-06-20T05:25:02.342538Z","iopub.execute_input":"2022-06-20T05:25:02.342821Z","iopub.status.idle":"2022-06-20T05:25:02.350762Z","shell.execute_reply.started":"2022-06-20T05:25:02.342793Z","shell.execute_reply":"2022-06-20T05:25:02.349816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_record(i):\n    dic = {}\n    dic[f\"features\"] = tf.train.Feature(float_list=tf.train.FloatList(value=list(train.iloc[i])))\n    dic[\"securities_code\"] = tf.train.Feature(int64_list=tf.train.Int64List(value=[securities_code.iloc[i]]))\n    dic[\"Target\"] = tf.train.Feature(float_list=tf.train.FloatList(value=[y.iloc[i]]))\n    record_bytes = tf.train.Example(features=tf.train.Features(feature=dic)).SerializeToString()\n    return record_bytes\n    \ndef decode_function(record_bytes):\n      return tf.io.parse_single_example(\n      # Data\n      record_bytes,\n      # Schema\n      {\n          \"features\": tf.io.FixedLenFeature([feats.shape[-1]], dtype=tf.float32),\n          \"securities_code\": tf.io.FixedLenFeature([], dtype=tf.int64),\n          \"Target\": tf.io.FixedLenFeature([], dtype=tf.float32)\n      }\n  )","metadata":{"execution":{"iopub.status.busy":"2022-06-20T05:25:02.705699Z","iopub.execute_input":"2022-06-20T05:25:02.706704Z","iopub.status.idle":"2022-06-20T05:25:02.717813Z","shell.execute_reply.started":"2022-06-20T05:25:02.706643Z","shell.execute_reply":"2022-06-20T05:25:02.71688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nimport time\nn_splits = 5\nn_test_splits = 2\nkfold = CombinatorialPurgedGroupKFold(n_splits, n_test_splits)\nfor fold, (train_indices, test_indices) in enumerate(kfold.split(train, groups=groups)):\n    print(\"=\" * 100)\n    print(f\"Fold {fold}\")\n    print(\"=\" * 100)\n    print(\"Train Sample size:\", len(train_indices))\n    print(\"Test Sample size:\", len(test_indices))\n    train_save_path = f\"fold_{fold}_train.tfrecords\"\n    begin = time.time()\n    print(f\"Creating {train_save_path}\")\n    with tf.io.TFRecordWriter(train_save_path) as file_writer:\n        for i in train_indices:\n            file_writer.write(create_record(i))\n    print(\"Elapsed time: %.2f\"%(time.time() - begin))\n    begin = time.time()\n    print(f\"Creating {train_save_path}\")\n    test_save_path = f\"fold_{fold}_test.tfrecords\"\n    with tf.io.TFRecordWriter(test_save_path) as file_writer:\n        for i in test_indices:\n            file_writer.write(create_record(i))\n    print(\"Elapsed time: %.2f\"%(time.time() - begin))","metadata":{"papermill":{"duration":4946.711427,"end_time":"2022-05-24T09:19:56.328591","exception":false,"start_time":"2022-05-24T07:57:29.617164","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-20T05:25:46.035542Z","iopub.execute_input":"2022-06-20T05:25:46.03584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"securities_codes = securities_code.unique()\nsecurities_code_df = pd.DataFrame({\"securities_code\": securities_codes})\nsecurities_code_df.to_csv(\"securities_codes.csv\", index=False)","metadata":{"papermill":{"duration":0.094234,"end_time":"2022-05-24T09:19:56.46019","exception":false,"start_time":"2022-05-24T09:19:56.365956","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]}]}