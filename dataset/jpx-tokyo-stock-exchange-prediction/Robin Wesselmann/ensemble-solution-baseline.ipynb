{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"logging = False\nsubmit = True\nsupplemental = True\n\nif logging:\n    !pip install neptune-client\n    !pip install neptune-client[lightgbm]","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-06-29T22:02:31.350455Z","iopub.execute_input":"2022-06-29T22:02:31.350759Z","iopub.status.idle":"2022-06-29T22:04:57.503973Z","shell.execute_reply.started":"2022-06-29T22:02:31.350726Z","shell.execute_reply":"2022-06-29T22:04:57.503138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import FormatStrFormatter, StrMethodFormatter\nimport jpx_tokyo_market_prediction\nfrom lightgbm import LGBMRegressor\nfrom lightgbm import log_evaluation\nfrom sklearn.linear_model import Ridge\nimport math \n\nimport seaborn as sns\npd.set_option('display.max_rows', 999)\npd.options.mode.chained_assignment = None  # default='warn'\nfrom decimal import ROUND_HALF_UP, Decimal\n\nfrom sklearn.metrics import mean_squared_error\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-29T22:04:57.505501Z","iopub.execute_input":"2022-06-29T22:04:57.505739Z","iopub.status.idle":"2022-06-29T22:04:59.339897Z","shell.execute_reply.started":"2022-06-29T22:04:57.505707Z","shell.execute_reply":"2022-06-29T22:04:59.338843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_ex_test = pd.read_csv(r\"/kaggle/input/jpx-tokyo-stock-exchange-prediction/example_test_files/sample_submission.csv\")\noptions_ex_test = pd.read_csv(r\"/kaggle/input/jpx-tokyo-stock-exchange-prediction/example_test_files/options.csv\")\nfin_ex_test = pd.read_csv(r\"/kaggle/input/jpx-tokyo-stock-exchange-prediction/example_test_files/financials.csv\")\nsec_sprice_ex_test = pd.read_csv(r\"/kaggle/input/jpx-tokyo-stock-exchange-prediction/example_test_files/secondary_stock_prices.csv\")\ntrades_ex_test = pd.read_csv(r\"/kaggle/input/jpx-tokyo-stock-exchange-prediction/example_test_files/trades.csv\")\nsprice_ex_test = pd.read_csv(r\"/kaggle/input/jpx-tokyo-stock-exchange-prediction/example_test_files/stock_prices.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-06-29T22:04:59.341726Z","iopub.execute_input":"2022-06-29T22:04:59.342295Z","iopub.status.idle":"2022-06-29T22:04:59.574717Z","shell.execute_reply.started":"2022-06-29T22:04:59.342244Z","shell.execute_reply":"2022-06-29T22:04:59.573925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"options_train = pd.read_csv(r\"/kaggle/input/jpx-tokyo-stock-exchange-prediction/train_files/options.csv\")\nfin_train = pd.read_csv(r\"/kaggle/input/jpx-tokyo-stock-exchange-prediction/train_files/financials.csv\")\nsec_sprice_train = pd.read_csv(r\"/kaggle/input/jpx-tokyo-stock-exchange-prediction/train_files/secondary_stock_prices.csv\")\ntrades_train = pd.read_csv(r\"/kaggle/input/jpx-tokyo-stock-exchange-prediction/train_files/trades.csv\")\nsprice_train = pd.read_csv(r\"/kaggle/input/jpx-tokyo-stock-exchange-prediction/train_files/stock_prices.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-06-29T22:04:59.576518Z","iopub.execute_input":"2022-06-29T22:04:59.576771Z","iopub.status.idle":"2022-06-29T22:05:38.282534Z","shell.execute_reply.started":"2022-06-29T22:04:59.57674Z","shell.execute_reply":"2022-06-29T22:05:38.280768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"options_supp = pd.read_csv(r\"/kaggle/input/jpx-tokyo-stock-exchange-prediction/supplemental_files/options.csv\")\nfin_supp = pd.read_csv(r\"/kaggle/input/jpx-tokyo-stock-exchange-prediction/supplemental_files/financials.csv\")\nsec_sprice_supp = pd.read_csv(r\"/kaggle/input/jpx-tokyo-stock-exchange-prediction/supplemental_files/secondary_stock_prices.csv\")\ntrades_supp = pd.read_csv(r\"/kaggle/input/jpx-tokyo-stock-exchange-prediction/supplemental_files/trades.csv\")\nsprice_supp = pd.read_csv(r\"/kaggle/input/jpx-tokyo-stock-exchange-prediction/supplemental_files/stock_prices.csv\")\nstock_list = pd.read_csv(r\"/kaggle/input/jpx-tokyo-stock-exchange-prediction/stock_list.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-06-29T22:05:38.284918Z","iopub.execute_input":"2022-06-29T22:05:38.285246Z","iopub.status.idle":"2022-06-29T22:05:43.026339Z","shell.execute_reply.started":"2022-06-29T22:05:38.285204Z","shell.execute_reply":"2022-06-29T22:05:43.024391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if supplemental:\n    sprice_train = pd.concat([sprice_train, sprice_supp], axis = 0)","metadata":{"execution":{"iopub.status.busy":"2022-06-29T22:05:43.028434Z","iopub.execute_input":"2022-06-29T22:05:43.029052Z","iopub.status.idle":"2022-06-29T22:05:43.277557Z","shell.execute_reply.started":"2022-06-29T22:05:43.02898Z","shell.execute_reply":"2022-06-29T22:05:43.276448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prepare data","metadata":{}},{"cell_type":"code","source":"#official adjust close price calc, https://www.kaggle.com/code/smeitoma/train-demo/notebook\n\ndef adjust_price(price):\n    \"\"\"\n    Args:\n        price (pd.DataFrame)  : pd.DataFrame include stock_price\n    Returns:\n        price DataFrame (pd.DataFrame): stock_price with generated AdjustedClose\n    \"\"\"\n    # transform Date column into datetime\n    price.loc[: ,\"Date\"] = pd.to_datetime(price.loc[: ,\"Date\"], format=\"%Y-%m-%d\")\n\n    def generate_adjusted_close(df):\n        \"\"\"\n        Args:\n            df (pd.DataFrame)  : stock_price for a single SecuritiesCode\n        Returns:\n            df (pd.DataFrame): stock_price with AdjustedClose for a single SecuritiesCode\n        \"\"\"\n        # sort data to generate CumulativeAdjustmentFactor\n        df = df.sort_values(\"Date\", ascending=False)\n        # generate CumulativeAdjustmentFactor\n        df.loc[:, \"CumulativeAdjustmentFactor\"] = df[\"AdjustmentFactor\"].cumprod()\n        # generate AdjustedClose\n        df.loc[:, \"AdjustedClose\"] = (\n            df[\"CumulativeAdjustmentFactor\"] * df[\"Close\"]\n        ).map(lambda x: float(\n            Decimal(str(x)).quantize(Decimal('0.1'), rounding=ROUND_HALF_UP)\n        ))\n        # reverse order\n        df = df.sort_values(\"Date\")\n        # to fill AdjustedClose, replace 0 into np.nan\n        df.loc[df[\"AdjustedClose\"] == 0, \"AdjustedClose\"] = np.nan\n        # forward fill AdjustedClose\n        df.loc[:, \"AdjustedClose\"] = df.loc[:, \"AdjustedClose\"].ffill()\n        return df\n\n    # generate AdjustedClose\n    price = price.sort_values([\"SecuritiesCode\", \"Date\"])\n    price = price.groupby(\"SecuritiesCode\").apply(generate_adjusted_close).reset_index(drop=True)\n\n    price.set_index(\"Date\", inplace=True)\n    return price","metadata":{"execution":{"iopub.status.busy":"2022-06-29T22:05:43.279136Z","iopub.execute_input":"2022-06-29T22:05:43.279529Z","iopub.status.idle":"2022-06-29T22:05:43.29382Z","shell.execute_reply.started":"2022-06-29T22:05:43.279453Z","shell.execute_reply":"2022-06-29T22:05:43.29251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_price_raw = sprice_train\nprices_train = adjust_price(df_price_raw)","metadata":{"execution":{"iopub.status.busy":"2022-06-29T22:05:43.296118Z","iopub.execute_input":"2022-06-29T22:05:43.296576Z","iopub.status.idle":"2022-06-29T22:06:08.410676Z","shell.execute_reply.started":"2022-06-29T22:05:43.296526Z","shell.execute_reply":"2022-06-29T22:06:08.409964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prices_train","metadata":{"execution":{"iopub.status.busy":"2022-06-29T22:06:08.411771Z","iopub.execute_input":"2022-06-29T22:06:08.412514Z","iopub.status.idle":"2022-06-29T22:06:08.450001Z","shell.execute_reply.started":"2022-06-29T22:06:08.41248Z","shell.execute_reply":"2022-06-29T22:06:08.449045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_RSI(df, close_col):\n    \n    df = df.copy()\n    df =  df.sort_index(ascending = True)\n    \n    df[\"Close_diff\"] = df[close_col].diff(1)\n    \n    df[\"gain\"] = [diff if diff >= 0 else 0 for diff in df[\"Close_diff\"]]\n    df[\"loss\"] = [diff*-1 if diff < 0 else 0 for diff in df[\"Close_diff\"]]\n    \n    df[\"avg_gain\"] = df[\"gain\"].rolling(window = 14).mean()\n    df[\"avg_loss\"] = df[\"loss\"].rolling(window = 14).mean()\n    \n    df[\"RS\"] = df[\"avg_gain\"] / df[\"avg_loss\"]\n    df[\"RSI\"] = 100 - (100/(1+df[\"RS\"]))\n    \n    return df[[\"RSI\"]]","metadata":{"execution":{"iopub.status.busy":"2022-06-29T22:06:08.453084Z","iopub.execute_input":"2022-06-29T22:06:08.453333Z","iopub.status.idle":"2022-06-29T22:06:08.462277Z","shell.execute_reply.started":"2022-06-29T22:06:08.453302Z","shell.execute_reply":"2022-06-29T22:06:08.46137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stock_list[\"MarketCapitalization\"] = np.log1p(stock_list[\"MarketCapitalization\"])\nstock_list[\"company_size_proxy\"] = pd.cut(stock_list[\"MarketCapitalization\"], bins = 4, labels = list(range(1,5)))\nstock_list[\"issued_shares_cat\"] = pd.cut(np.log1p(stock_list[\"IssuedShares\"]), bins = 3, labels = list(range(1,4)))\nstock_list[\"NewIndexSeriesSizeCode\"] = [int(row) if row!=\"-\" else 999 for row in stock_list[\"NewIndexSeriesSizeCode\"]]","metadata":{"execution":{"iopub.status.busy":"2022-06-29T22:06:08.463426Z","iopub.execute_input":"2022-06-29T22:06:08.464235Z","iopub.status.idle":"2022-06-29T22:06:08.488285Z","shell.execute_reply.started":"2022-06-29T22:06:08.464201Z","shell.execute_reply":"2022-06-29T22:06:08.487501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#inspired from: https://www.kaggle.com/code/smeitoma/train-demo/notebook\n\ndef get_features_for_predict(price, code):\n    \"\"\"\n    Args:\n        price (pd.DataFrame)  : pd.DataFrame include stock_price\n        code (int)  : A local code for a listed company\n    Returns:\n        feature DataFrame (pd.DataFrame)\n    \"\"\"\n    close_col = \"AdjustedClose\"\n    feats = price.loc[price[\"SecuritiesCode\"] == code, [\"SecuritiesCode\", close_col]].copy()\n    \n    periods = [10, 21, 63]\n    \n    for period in periods:\n        feats.loc[:, f\"return_{period}\"] = feats[\"AdjustedClose\"].pct_change(period)\n        feats.loc[:, f\"volatility_{period}\"] = np.log(feats[\"AdjustedClose\"]).diff().rolling(period).std()\n    \n    feats.loc[:, \"RSI\"] = get_RSI(feats, close_col)\n    \n    #bollinger bands\n    feats.loc[:, \"rollingMean20\"] = feats[\"AdjustedClose\"].rolling(window = 20).mean()\n    feats.loc[:, \"upperBollinger20\"] = feats[\"rollingMean20\"] + 2 * feats[\"AdjustedClose\"].rolling(window = 20).std()\n    feats.loc[:, \"lowerBollinger20\"] = feats[\"rollingMean20\"] - 2 * feats[\"AdjustedClose\"].rolling(window = 20).std()\n    \n    #time features\n    feats.loc[:, \"day_of_week\"] = feats.index.dayofweek\n    feats.loc[:, \"month\"] = feats.index.month\n    \n    feats[\"rng_help\"] = feats.index.dayofyear\n    feats[\"rng_help_norm\"] = 2 * math.pi * feats[\"rng_help\"] /feats[\"rng_help\"].max()\n    feats[\"cos_x\"] = np.cos(feats[\"rng_help_norm\"])\n    feats[\"sin_x\"] = np.sin(feats[\"rng_help_norm\"])\n    feats.drop([\"rng_help\", \"rng_help_norm\"], axis = 1, inplace = True)\n        \n    \n    #quantiles \n    feats[\"quantile_75\"] = feats[\"AdjustedClose\"].rolling(window = 20).quantile(quantile = 0.75)\n    feats[\"quantile_25\"] = feats[\"AdjustedClose\"].rolling(window = 20).quantile(quantile = 0.25)\n    feats[\"IQR\"] = feats[\"quantile_75\"] - feats[\"quantile_25\"]\n    \n    # filling data for nan and inf\n    feats = feats.fillna(0)\n    feats = feats.replace([np.inf, -np.inf], 0)\n    \n    #add company size proxy, sector, issued shares category, NewMarketSegment\n    feats = feats.reset_index()\n    feats = pd.merge(left = feats, right = stock_list[[\"SecuritiesCode\", \"company_size_proxy\", \"issued_shares_cat\", \"17SectorCode\",\"NewIndexSeriesSizeCode\"]], left_on = \"SecuritiesCode\", right_on = \"SecuritiesCode\", how = \"left\")\n    feats.set_index(\"Date\", inplace = True)\n    \n    # drop AdjustedClose column\n    feats = feats.drop([close_col], axis=1)\n\n    return feats","metadata":{"execution":{"iopub.status.busy":"2022-06-29T22:06:08.489821Z","iopub.execute_input":"2022-06-29T22:06:08.490732Z","iopub.status.idle":"2022-06-29T22:06:08.509291Z","shell.execute_reply.started":"2022-06-29T22:06:08.490682Z","shell.execute_reply":"2022-06-29T22:06:08.508589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fetch prediction target SecuritiesCodes\ncodes = sorted(prices_train[\"SecuritiesCode\"].unique())\nlen(codes)","metadata":{"execution":{"iopub.status.busy":"2022-06-29T22:06:08.510871Z","iopub.execute_input":"2022-06-29T22:06:08.511207Z","iopub.status.idle":"2022-06-29T22:06:08.545316Z","shell.execute_reply.started":"2022-06-29T22:06:08.511162Z","shell.execute_reply":"2022-06-29T22:06:08.544601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generate feature\nfrom tqdm import tqdm\n\nbuff = []\nfor code in tqdm(codes):\n    feat = get_features_for_predict(prices_train, code)\n    buff.append(feat)\nfeature = pd.concat(buff)\nrows_before = feature.shape[0]\nfeature.dropna(inplace = True)\nrows_after = feature.shape[0]\n\nprint(f\"{rows_after - rows_before} have been dropped\")","metadata":{"execution":{"iopub.status.busy":"2022-06-29T22:06:08.546476Z","iopub.execute_input":"2022-06-29T22:06:08.546885Z","iopub.status.idle":"2022-06-29T22:07:46.48881Z","shell.execute_reply.started":"2022-06-29T22:06:08.546854Z","shell.execute_reply":"2022-06-29T22:07:46.487802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def reduce_mem_usage(df):\n    # iterate through all the columns of a dataframe and modify the data type\n    #   to reduce memory usage. Credits to Guillaume Martin\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-06-29T22:07:46.490056Z","iopub.execute_input":"2022-06-29T22:07:46.490376Z","iopub.status.idle":"2022-06-29T22:07:46.50499Z","shell.execute_reply.started":"2022-06-29T22:07:46.490342Z","shell.execute_reply":"2022-06-29T22:07:46.503946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = reduce_mem_usage(feature)","metadata":{"execution":{"iopub.status.busy":"2022-06-29T22:07:46.506693Z","iopub.execute_input":"2022-06-29T22:07:46.507036Z","iopub.status.idle":"2022-06-29T22:07:48.073493Z","shell.execute_reply.started":"2022-06-29T22:07:46.506987Z","shell.execute_reply":"2022-06-29T22:07:48.072497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_col = prices_train[[\"SecuritiesCode\", \"Target\"]]\nmerged_train_data = pd.merge(left = feature, right = target_col, left_on = [feature.index, \"SecuritiesCode\"], right_on = [target_col.index, \"SecuritiesCode\"]).set_index(\"key_0\", drop = True)\nmerged_train_data.index.names = [\"Date\"]\nmerged_train_data.dropna(inplace = True)\n\nmerged_train_data","metadata":{"execution":{"iopub.status.busy":"2022-06-29T22:07:48.074753Z","iopub.execute_input":"2022-06-29T22:07:48.074987Z","iopub.status.idle":"2022-06-29T22:07:50.826046Z","shell.execute_reply.started":"2022-06-29T22:07:48.074957Z","shell.execute_reply":"2022-06-29T22:07:50.825073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train and choose model","metadata":{}},{"cell_type":"markdown","source":"### functions","metadata":{}},{"cell_type":"code","source":"def set_rank(df):\n    \"\"\"\n    Args:\n        df (pd.DataFrame): including predict column\n    Returns:\n        df (pd.DataFrame): df with Rank\n    \"\"\"\n    df =  df.sort_values(\"target_pred\", ascending = False)\n    df.loc[:, \"Rank\"] = np.arange(len(df[\"target_pred\"]))\n    return df\n\n\n#evaluation function to calculate the sharp ratio\n\ndef calc_spread_return_sharpe(df: pd.DataFrame, portfolio_size: int = 200, toprank_weight_ratio: float = 2) -> float:\n    \"\"\"\n    Args:\n        df (pd.DataFrame): predicted results\n        portfolio_size (int): # of equities to buy/sell\n        toprank_weight_ratio (float): the relative weight of the most highly ranked stock compared to the least.\n    Returns:\n        (float): sharpe ratio\n    \"\"\"\n    def _calc_spread_return_per_day(df, portfolio_size, toprank_weight_ratio):\n        \"\"\"\n        Args:\n            df (pd.DataFrame): predicted results\n            portfolio_size (int): # of equities to buy/sell\n            toprank_weight_ratio (float): the relative weight of the most highly ranked stock compared to the least.\n        Returns:\n            (float): spread return\n        \"\"\"\n        assert df['Rank'].min() == 0\n        assert df['Rank'].max() == len(df['Rank']) - 1\n        weights = np.linspace(start=toprank_weight_ratio, stop=1, num=portfolio_size)\n        purchase = (df.sort_values(by='Rank')['Target'][:portfolio_size] * weights).sum() / weights.mean()\n        short = (df.sort_values(by='Rank', ascending=False)['Target'][:portfolio_size] * weights).sum() / weights.mean()\n        return purchase - short\n\n    buf = df.groupby('Date').apply(_calc_spread_return_per_day, portfolio_size, toprank_weight_ratio)\n    sharpe_ratio = buf.mean() / buf.std()\n    return sharpe_ratio","metadata":{"execution":{"iopub.status.busy":"2022-06-29T22:07:50.827548Z","iopub.execute_input":"2022-06-29T22:07:50.827866Z","iopub.status.idle":"2022-06-29T22:07:50.838177Z","shell.execute_reply.started":"2022-06-29T22:07:50.827835Z","shell.execute_reply":"2022-06-29T22:07:50.837131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Setup neptune project","metadata":{}},{"cell_type":"code","source":"merged_train_data.head().to_csv(\"./merged_train_data_sample.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-06-29T22:07:50.839446Z","iopub.execute_input":"2022-06-29T22:07:50.839742Z","iopub.status.idle":"2022-06-29T22:07:50.860495Z","shell.execute_reply.started":"2022-06-29T22:07:50.83971Z","shell.execute_reply":"2022-06-29T22:07:50.859584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model definition and tracking\n\nparams ={\n    \"lgb_params\" : {\n        'n_estimators': 500,\n        'num_leaves' : 100,\n        'learning_rate': 0.1,\n        'colsample_bytree': 0.9,\n        'subsample': 0.8,\n        'reg_alpha': 0.4,\n        'metric': 'mae',\n        'random_state': 21\n    }\n}\n\ncols = merged_train_data.columns\n\nif logging:     \n    \n    import neptune.new as neptune\n    from neptune.new.integrations.lightgbm import NeptuneCallback\n    from kaggle_secrets import UserSecretsClient\n\n    user_secrets = UserSecretsClient()\n    api_token = user_secrets.get_secret(\"neptune_token\")\n\n    run = neptune.init(project='rb.wesselmann/JPX-stock-kaggle-Project', api_token = api_token)\n    neptune_callback = NeptuneCallback(run=run)\n    \n    run[\"name\"] = \"baseline_v10_inkl_suppl\"\n    run[\"algorithm\"] = \"LightGBM\" \n    run[\"parameters\"] = params\n    run[\"features\"] = list(cols)\n    run[\"dataset/merged_train_data_sample\"].upload(\"./merged_train_data_sample.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-06-29T22:07:50.861916Z","iopub.execute_input":"2022-06-29T22:07:50.862271Z","iopub.status.idle":"2022-06-29T22:08:02.182897Z","shell.execute_reply.started":"2022-06-29T22:07:50.86224Z","shell.execute_reply":"2022-06-29T22:08:02.181789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Use Time Series CV to choose the model","metadata":{}},{"cell_type":"code","source":"feature_cols = merged_train_data.drop(\"Target\", axis = 1).columns\n\nif not submit:\n\n    from sklearn.model_selection import TimeSeriesSplit\n\n    tscv = TimeSeriesSplit(n_splits = 5)\n    score = {}\n\n    print(\"beginning CV ...\\n\")\n\n    for fold, (train_index, val_index) in enumerate(tscv.split(merged_train_data)):\n\n        print(f\"------------- Fold {fold} -------------\")\n        print(f\"Train index: from {merged_train_data.iloc[train_index].index[0]} to {merged_train_data.iloc[train_index].index[-1]}\")\n        print(f\"Validation index: from {merged_train_data.iloc[val_index].index[0]} to {merged_train_data.iloc[val_index].index[-1]}\")\n\n        X_train, y_train = merged_train_data[feature_cols].iloc[train_index], merged_train_data[\"Target\"].iloc[train_index]\n        X_val, y_val = merged_train_data[feature_cols].iloc[val_index], merged_train_data[\"Target\"].iloc[val_index]\n\n        #train\n        lgb_model = LGBMRegressor(**params[\"lgb_params\"])\n        lgb_model.fit(X_train[feature_cols], y_train, eval_set = (X_val, y_val), early_stopping_rounds = 100, callbacks = [neptune_callback])\n        lgb_model.fit(X_train[feature_cols], y_train)\n                  \n        #predict\n        result = X_val[[\"SecuritiesCode\"]].copy()\n        result.loc[:, \"target_pred\"] = 1 * lgb_model.predict(X_val[feature_cols])\n        result.loc[:, \"Target\"] = y_val\n\n        #rank\n        result = result.sort_values([\"Date\", \"target_pred\"], ascending = [True, False])\n        result = result.groupby(\"Date\").apply(set_rank)\n\n        score[f\"Fold_{fold}\"] = calc_spread_return_sharpe(result, portfolio_size = 200)\n        print(f\"Sharp Ratio for Fold {fold}: \", score[f\"Fold_{fold}\"], \"\\n\")\n\n        if logging:\n            run[\"metrics/Sharp_ratio\"].log(score[f\"Fold_{fold}\"])\n\n    print(f\"Average sharp ratio: {sum(score.values())/len(score)}\")\n\n    if logging:\n        run[\"avg_Sharp_ratio\"] = sum(score.values())/len(score)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-06-29T22:08:02.185197Z","iopub.execute_input":"2022-06-29T22:08:02.185792Z","iopub.status.idle":"2022-06-29T22:16:02.508628Z","shell.execute_reply.started":"2022-06-29T22:08:02.185749Z","shell.execute_reply":"2022-06-29T22:16:02.507706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not submit:\n    importance = pd.DataFrame({\"columns\":X_train.columns, \"importance\" : lgb_model.feature_importances_})\n    importance = importance.sort_values(by = \"importance\", ascending = False)\n\n    fig, sub = plt.subplots(1,1,figsize=(15,8))\n    sns.barplot(y = importance[\"columns\"], x = importance[\"importance\"], orient = \"hor\", ax = sub)\n    sub.grid()","metadata":{"execution":{"iopub.status.busy":"2022-06-29T22:26:14.537429Z","iopub.execute_input":"2022-06-29T22:26:14.538453Z","iopub.status.idle":"2022-06-29T22:26:14.990863Z","shell.execute_reply.started":"2022-06-29T22:26:14.538415Z","shell.execute_reply":"2022-06-29T22:26:14.989885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if logging:\n    import joblib\n\n    run[\"model_lgb\"].upload(joblib.dump(lgb_model, \"lgb_model.pkl\")[0])\n    run.stop()","metadata":{"execution":{"iopub.status.busy":"2022-06-28T23:33:09.296287Z","iopub.execute_input":"2022-06-28T23:33:09.296614Z","iopub.status.idle":"2022-06-28T23:33:10.9578Z","shell.execute_reply.started":"2022-06-28T23:33:09.296567Z","shell.execute_reply":"2022-06-28T23:33:10.957009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X, y = merged_train_data[feature_cols], merged_train_data[\"Target\"]\n\nlgb_model = LGBMRegressor(**params[\"lgb_params\"])\nlgb_model.fit(X[feature_cols], y)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T21:23:09.435177Z","iopub.execute_input":"2022-06-27T21:23:09.435506Z","iopub.status.idle":"2022-06-27T21:25:30.505165Z","shell.execute_reply.started":"2022-06-27T21:23:09.435456Z","shell.execute_reply":"2022-06-27T21:25:30.504156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.columns","metadata":{"execution":{"iopub.status.busy":"2022-06-27T21:28:03.112025Z","iopub.execute_input":"2022-06-27T21:28:03.112774Z","iopub.status.idle":"2022-06-27T21:28:03.119302Z","shell.execute_reply.started":"2022-06-27T21:28:03.112728Z","shell.execute_reply":"2022-06-27T21:28:03.118432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"set(feature_cols) == set(X.columns)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T21:29:50.890714Z","iopub.execute_input":"2022-06-27T21:29:50.891291Z","iopub.status.idle":"2022-06-27T21:29:50.897653Z","shell.execute_reply.started":"2022-06-27T21:29:50.891253Z","shell.execute_reply":"2022-06-27T21:29:50.896794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission baseline","metadata":{}},{"cell_type":"code","source":"# load Time Series API\nimport jpx_tokyo_market_prediction\n# make Time Series API environment (this function can be called only once in a session)\nenv = jpx_tokyo_market_prediction.make_env()\n# get iterator to fetch data day by day\niter_test = env.iter_test()","metadata":{"execution":{"iopub.status.busy":"2022-06-27T21:30:11.612966Z","iopub.execute_input":"2022-06-27T21:30:11.613308Z","iopub.status.idle":"2022-06-27T21:30:11.618036Z","shell.execute_reply.started":"2022-06-27T21:30:11.613276Z","shell.execute_reply":"2022-06-27T21:30:11.617371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"price_cols = [\n    \"Date\",\n    \"SecuritiesCode\",\n    \"Close\",\n    \"AdjustmentFactor\"\n]\n\ndf_price_raw = df_price_raw[price_cols]\n\ncounter = 0\n\n#fetch data day by day\nfor (prices, options, financials, trades, secondary_prices, sample_prediction) in iter_test:\n    \n    current_date = prices[\"Date\"].iloc[0]\n    sample_prediction_date = sample_prediction[\"Date\"].iloc[0]\n    print(f\"current date: {current_date}, sample_prediction_date: {sample_prediction_date}\")\n    \n    if counter == 0: \n        \n        df_price_raw = df_price_raw.loc[df_price_raw[\"Date\"] < current_date]\n        \n    threshold = (pd.Timestamp(current_date) - pd.offsets.BDay(80)).strftime(\"%Y-%m-%d\")\n    print(f\"threshold: {threshold}\")\n    df_price_raw = df_price_raw.loc[df_price_raw[\"Date\"] >= threshold]\n    \n    df_price_raw = pd.concat([df_price_raw, prices[price_cols]])\n    df_price = adjust_price(df_price_raw)\n    \n    codes = sorted(prices[\"SecuritiesCode\"].unique())\n    \n    #predict\n    feature = pd.concat([get_features_for_predict(df_price, code) for code in codes])\n    feature = feature.loc[feature.index == current_date]\n    feature = reduce_mem_usage(feature)\n    \n    feature.loc[:, \"predict\"] = lgb_model.predict(feature[feature_cols]) \n    \n    #set rank\n    feature = feature.sort_values(\"predict\", ascending = False).drop_duplicates(subset = [\"SecuritiesCode\"])\n    feature.loc[:, \"Rank\"] = np.arange(len(feature))\n    feature_map = feature.set_index(\"SecuritiesCode\")[\"Rank\"].to_dict()\n    sample_prediction[\"Rank\"] = sample_prediction[\"SecuritiesCode\"].map(feature_map)\n    \n    #chk rank\n    assert sample_prediction[\"Rank\"].notna().all()\n    assert sample_prediction[\"Rank\"].min() == 0\n    assert sample_prediction[\"Rank\"].max() == len(sample_prediction[\"Rank\"]) - 1\n    \n    env.predict(sample_prediction)\n    counter += 1        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}