{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# JPX TSE Minimal CatBoost Baseline\nTreat the challenge as a regression problem in order to implement a minimal training & inference baseline with CatBoost\n\nThanks to [Lonnie](https://www.kaggle.com/lonnieqin) and [swimmy](https://www.kaggle.com/swimmy) for the following notebooks which were very helpful:\n* [https://www.kaggle.com/code/lonnieqin/tokyo-stock-market-prediction-with-catboost-v2](https://www.kaggle.com/code/lonnieqin/tokyo-stock-market-prediction-with-catboost-v2)\n* [https://www.kaggle.com/code/swimmy/lgbm-opt-model-jpx/notebook](https://www.kaggle.com/code/swimmy/lgbm-opt-model-jpx/notebook)\n","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"import catboost as cb\nimport jpx_tokyo_market_prediction\nimport numpy as np\nimport os\nimport pandas as pd","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    TRAIN_PERCENTAGE = 0.8","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Load & process the data\n\nTo simplify matters,\n- drop all rows where 'AdjustmentFactor' is not equal to 1.0\n- only use 'SecuritiesCode', 'Open', 'High', 'Low', 'Close' and 'Volume' from *stock_prices.csv* as features\n- drop all NA rows","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"path = '../input/jpx-tokyo-stock-exchange-prediction/train_files/stock_prices.csv'\ncols = ['RowId', 'Date', 'SecuritiesCode', 'Open', 'High', 'Low', 'Close', 'Volume', 'AdjustmentFactor', 'ExpectedDividend', 'SupervisionFlag', 'Target']\nfeat_cols = ['SecuritiesCode', 'Open', 'High', 'Low', 'Close', 'Volume']\nall_prices_df = pd.read_csv(path)\nall_prices_df['Date'] = pd.to_datetime(all_prices_df['Date'])\nall_prices_df.drop(all_prices_df[all_prices_df['AdjustmentFactor'] != 1.0].index, inplace = True)\nall_prices_df = all_prices_df[['Date', 'SecuritiesCode', 'Open', 'High', 'Low', 'Close', 'Volume', 'Target', ]]\nall_prices_df.dropna(axis=0, inplace=True)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Split the training and test data by date to avoid information leakage","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"train_rows = int(len(all_prices_df.index)*CFG.TRAIN_PERCENTAGE)\ntest_start_date = all_prices_df['Date'].iloc[train_rows]\n\ntrain_df = all_prices_df[all_prices_df['Date'] < test_start_date]\ntest_df = all_prices_df[all_prices_df['Date'] >= test_start_date]\n\nX_train, y_train = train_df[feat_cols], train_df['Target']\nX_test, y_test = test_df[feat_cols], test_df['Target']\n\ntrain_dataset = cb.Pool(X_train, y_train, cat_features=['SecuritiesCode'])\ntest_dataset = cb.Pool(X_test, y_test, cat_features=['SecuritiesCode'])","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"CatBoostRegressor on GPU with RMSE loss function, random seed 42 and default parameters","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"model = cb.CatBoostRegressor(loss_function='RMSE',  random_seed=42, task_type='GPU',)\nmodel.fit(train_dataset, verbose=False)\nprint(model.get_all_params())\nprint(model.get_best_iteration())\nprint(model.get_best_score())","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Use **argsort** from numpy to implement the ranking (reference: [https://stackoverflow.com/a/6266510](https://stackoverflow.com/a/6266510))","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"env = jpx_tokyo_market_prediction.make_env()   # initialize the environment\niter_test = env.iter_test()    # an iterator which loops over the test files\nfor (prices, options, financials, trades, secondary_prices, sample_prediction) in iter_test:\n    y_pred = model.predict(prices[feat_cols]).reshape(-1)\n    ranks = (-1*y_pred).argsort().argsort()\n    sample_prediction['Rank'] = ranks\n    env.predict(sample_prediction)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]}]}