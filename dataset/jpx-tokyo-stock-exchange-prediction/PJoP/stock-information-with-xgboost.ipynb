{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-14T01:53:58.09568Z","iopub.execute_input":"2022-04-14T01:53:58.096909Z","iopub.status.idle":"2022-04-14T01:53:58.166808Z","shell.execute_reply.started":"2022-04-14T01:53:58.096742Z","shell.execute_reply":"2022-04-14T01:53:58.165848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport jpx_tokyo_market_prediction\n\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom xgboost import XGBRegressor\nfrom xgboost import plot_importance","metadata":{"execution":{"iopub.status.busy":"2022-04-14T01:53:58.168835Z","iopub.execute_input":"2022-04-14T01:53:58.169227Z","iopub.status.idle":"2022-04-14T01:54:00.422245Z","shell.execute_reply.started":"2022-04-14T01:53:58.169184Z","shell.execute_reply":"2022-04-14T01:54:00.421266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calc_spread_return_sharpe(df: pd.DataFrame, portfolio_size: int = 200, toprank_weight_ratio: float = 2) -> float:\n    \"\"\"\n    Args:\n        df (pd.DataFrame): predicted results\n        portfolio_size (int): # of equities to buy/sell\n        toprank_weight_ratio (float): the relative weight of the most highly ranked stock compared to the least.\n    Returns:\n        (float): sharpe ratio\n    \"\"\"\n    def _calc_spread_return_per_day(df, portfolio_size, toprank_weight_ratio):\n        \"\"\"\n        Args:\n            df (pd.DataFrame): predicted results\n            portfolio_size (int): # of equities to buy/sell\n            toprank_weight_ratio (float): the relative weight of the most highly ranked stock compared to the least.\n        Returns:\n            (float): spread return\n        \"\"\"\n        assert df['Rank'].min() == 0\n        assert df['Rank'].max() == len(df['Rank']) - 1\n        weights = np.linspace(start=toprank_weight_ratio, stop=1, num=portfolio_size)\n        purchase = (df.sort_values(by='Rank')['Target'][:portfolio_size] * weights).sum() / weights.mean()\n        short = (df.sort_values(by='Rank', ascending=False)['Target'][:portfolio_size] * weights).sum() / weights.mean()\n        return purchase - short\n\n    buf = df.groupby('Date').apply(_calc_spread_return_per_day, portfolio_size, toprank_weight_ratio)\n    if len(df.Date.unique()) < 2:\n        return buf.mean()\n    else:\n        return buf.mean() / buf.std()\n    ","metadata":{"execution":{"iopub.status.busy":"2022-04-14T01:54:00.424366Z","iopub.execute_input":"2022-04-14T01:54:00.424687Z","iopub.status.idle":"2022-04-14T01:54:00.438197Z","shell.execute_reply.started":"2022-04-14T01:54:00.424647Z","shell.execute_reply":"2022-04-14T01:54:00.436867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_avg(_id_):\n    return average.loc[_id_]\n\n\ndef prepareData(df):\n    df['Date_type'] = pd.to_datetime(df['Date'], format = '%Y-%m-%d')\n    df[\"Avg\"] = df[\"SecuritiesCode\"].apply(get_avg)\n    df = pd.get_dummies(df, columns = ['Section/Products', 'Section', 'NewMarketSegment', '33SectorName', '17SectorName', 'NewIndexSeriesSize'])\n    return df\n    ","metadata":{"execution":{"iopub.status.busy":"2022-04-14T01:54:00.440648Z","iopub.execute_input":"2022-04-14T01:54:00.441019Z","iopub.status.idle":"2022-04-14T01:54:00.464221Z","shell.execute_reply.started":"2022-04-14T01:54:00.440981Z","shell.execute_reply":"2022-04-14T01:54:00.463037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f_dir = '../input/jpx-tokyo-stock-exchange-prediction'","metadata":{"execution":{"iopub.status.busy":"2022-04-14T01:54:00.465772Z","iopub.execute_input":"2022-04-14T01:54:00.466161Z","iopub.status.idle":"2022-04-14T01:54:00.483486Z","shell.execute_reply.started":"2022-04-14T01:54:00.466118Z","shell.execute_reply":"2022-04-14T01:54:00.48254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Stock Prices","metadata":{}},{"cell_type":"code","source":"prices = pd.read_csv(f'{f_dir}/supplemental_files/stock_prices.csv')\n# prices.index = prices.Date_type\nprices.sample(3)","metadata":{"execution":{"iopub.status.busy":"2022-04-14T01:54:00.48468Z","iopub.execute_input":"2022-04-14T01:54:00.485131Z","iopub.status.idle":"2022-04-14T01:54:00.849909Z","shell.execute_reply.started":"2022-04-14T01:54:00.485092Z","shell.execute_reply":"2022-04-14T01:54:00.84871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"average = pd.DataFrame(prices.groupby(\"SecuritiesCode\").Target.mean())\nprices['Target_lag1'] = prices.Target.shift(1)","metadata":{"execution":{"iopub.status.busy":"2022-04-14T01:54:00.851508Z","iopub.execute_input":"2022-04-14T01:54:00.85179Z","iopub.status.idle":"2022-04-14T01:54:00.874216Z","shell.execute_reply.started":"2022-04-14T01:54:00.851754Z","shell.execute_reply":"2022-04-14T01:54:00.872715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Stock Information","metadata":{}},{"cell_type":"code","source":"stock_info = pd.read_csv(f'{f_dir}/stock_list.csv')\nstock_info.sample(3)","metadata":{"execution":{"iopub.status.busy":"2022-04-14T01:54:00.87561Z","iopub.execute_input":"2022-04-14T01:54:00.876149Z","iopub.status.idle":"2022-04-14T01:54:00.932608Z","shell.execute_reply.started":"2022-04-14T01:54:00.876118Z","shell.execute_reply":"2022-04-14T01:54:00.932004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stock_info = stock_info.astype({'EffectiveDate' : 'string'})\nstock_info['Date'] = stock_info.apply(lambda row : row['EffectiveDate'][:4] + '-' + row['EffectiveDate'][4:6] + '-' + row['EffectiveDate'][6:], axis = 1)\nstock_info.head(2)","metadata":{"execution":{"iopub.status.busy":"2022-04-14T01:54:00.934621Z","iopub.execute_input":"2022-04-14T01:54:00.934955Z","iopub.status.idle":"2022-04-14T01:54:01.051464Z","shell.execute_reply.started":"2022-04-14T01:54:00.934903Z","shell.execute_reply":"2022-04-14T01:54:01.050067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove domestic-non-domestic\nstock_info['Section'] = stock_info.apply(lambda row : row['Section/Products'].split('(')[0], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2022-04-14T01:54:01.053635Z","iopub.execute_input":"2022-04-14T01:54:01.053959Z","iopub.status.idle":"2022-04-14T01:54:01.143719Z","shell.execute_reply.started":"2022-04-14T01:54:01.053899Z","shell.execute_reply":"2022-04-14T01:54:01.142374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Relative Market Cap\nmarket_cap = stock_info.groupby(['33SectorName']).agg(total_market_cap = ('MarketCapitalization', 'sum')).reset_index()\nstock_info = pd.merge(stock_info, market_cap, on = '33SectorName', how = 'inner')\nstock_info['MarketCapPct'] = stock_info['MarketCapitalization'] / stock_info['total_market_cap'] * 100","metadata":{"execution":{"iopub.status.busy":"2022-04-14T01:54:01.145154Z","iopub.execute_input":"2022-04-14T01:54:01.145434Z","iopub.status.idle":"2022-04-14T01:54:01.185734Z","shell.execute_reply.started":"2022-04-14T01:54:01.145397Z","shell.execute_reply":"2022-04-14T01:54:01.183712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stock_info[stock_info['SecuritiesCode'] == 1301]","metadata":{"execution":{"iopub.status.busy":"2022-04-14T01:54:01.18765Z","iopub.execute_input":"2022-04-14T01:54:01.188111Z","iopub.status.idle":"2022-04-14T01:54:01.21048Z","shell.execute_reply.started":"2022-04-14T01:54:01.188077Z","shell.execute_reply":"2022-04-14T01:54:01.20943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Data","metadata":{}},{"cell_type":"code","source":"prices_info = pd.merge(prices, stock_info.filter(['SecuritiesCode', 'MarketCapPct', 'Section/Products', 'Section', 'NewMarketSegment', '33SectorName', '17SectorName', 'NewIndexSeriesSize']), on = ['SecuritiesCode'], how = 'left')\nprices_info.sample(5)","metadata":{"execution":{"iopub.status.busy":"2022-04-14T01:54:01.211714Z","iopub.execute_input":"2022-04-14T01:54:01.212145Z","iopub.status.idle":"2022-04-14T01:54:01.322484Z","shell.execute_reply.started":"2022-04-14T01:54:01.212096Z","shell.execute_reply":"2022-04-14T01:54:01.321769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prices_info = prepareData(prices_info)","metadata":{"execution":{"iopub.status.busy":"2022-04-14T01:54:01.323992Z","iopub.execute_input":"2022-04-14T01:54:01.324448Z","iopub.status.idle":"2022-04-14T01:54:20.423903Z","shell.execute_reply.started":"2022-04-14T01:54:01.32441Z","shell.execute_reply":"2022-04-14T01:54:20.421971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prices_info.sample(2)","metadata":{"execution":{"iopub.status.busy":"2022-04-14T01:54:20.426252Z","iopub.execute_input":"2022-04-14T01:54:20.426577Z","iopub.status.idle":"2022-04-14T01:54:20.469418Z","shell.execute_reply.started":"2022-04-14T01:54:20.426545Z","shell.execute_reply":"2022-04-14T01:54:20.467831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# GBM for target:\nfeat_cols = ['Avg', 'Target_lag1', 'MarketCapPct'] + [c for c in prices_info.columns if c.startswith('Section')] + [c for c in prices_info.columns if c.startswith('NewMarketSegment')] + [c for c in prices_info.columns if c.startswith('33SectorName')] + [c for c in prices_info.columns if c.startswith('17SectorName')] + [c for c in prices_info.columns if c.startswith('NewIndexSeriesSize')]  \ngbm_cols = feat_cols + ['Target'] + ['Date']\n\ntest_rows = prices_info.Date.unique()[-2:]\ngbm_dat = prices_info.filter(gbm_cols)\ngbm_test = gbm_dat[gbm_dat.Date.isin(test_rows)]\ngbm_train = gbm_dat[~gbm_dat.index.isin(gbm_test.index)]\n\nX_train, y_train = gbm_train.filter(feat_cols), gbm_train.Target\nX_test, y_test = gbm_test.filter(feat_cols), gbm_test.Target\n","metadata":{"execution":{"iopub.status.busy":"2022-04-14T01:54:20.470985Z","iopub.execute_input":"2022-04-14T01:54:20.471306Z","iopub.status.idle":"2022-04-14T01:54:20.613512Z","shell.execute_reply.started":"2022-04-14T01:54:20.471273Z","shell.execute_reply":"2022-04-14T01:54:20.612303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"model = XGBRegressor(\n    max_depth=5,\n    n_estimators=400,\n    min_child_weight=0.5, \n    colsample_bytree=0.8, \n    subsample=0.8, \n    eta=0.01,\n    seed=42)\n\nmodel.fit(X_train, y_train, eval_metric=\"rmse\", eval_set=[(X_train, y_train), (X_test, y_test)], \n    verbose=False, early_stopping_rounds = 20)","metadata":{"execution":{"iopub.status.busy":"2022-04-14T01:54:20.614902Z","iopub.execute_input":"2022-04-14T01:54:20.615258Z","iopub.status.idle":"2022-04-14T01:55:08.781557Z","shell.execute_reply.started":"2022-04-14T01:54:20.615218Z","shell.execute_reply":"2022-04-14T01:55:08.780127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = model.evals_result()\nplt.plot(results['validation_0']['rmse'], label='train')\nplt.plot(results['validation_1']['rmse'], label='test')\n# show the legend\nplt.legend()\n# show the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-14T01:55:08.783294Z","iopub.execute_input":"2022-04-14T01:55:08.783602Z","iopub.status.idle":"2022-04-14T01:55:09.022854Z","shell.execute_reply.started":"2022-04-14T01:55:08.78356Z","shell.execute_reply":"2022-04-14T01:55:09.022022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_features(booster, figsize):    \n    fig, ax = plt.subplots(1,1,figsize=figsize)\n    return plot_importance(booster=booster, ax=ax)\nplot_features(model, (10,14))","metadata":{"execution":{"iopub.status.busy":"2022-04-14T01:55:09.024041Z","iopub.execute_input":"2022-04-14T01:55:09.024405Z","iopub.status.idle":"2022-04-14T01:55:10.994875Z","shell.execute_reply.started":"2022-04-14T01:55:09.024371Z","shell.execute_reply":"2022-04-14T01:55:10.993425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"latest_day = gbm_test[gbm_test.Date == gbm_test.Date.unique()[-1]]\nlatest_day['Target'] = model.predict(latest_day.filter(feat_cols))\nlatest_day = latest_day.sort_values(by = \"Target\", ascending=False)\nlatest_day['Rank'] = np.arange(0,2000)\ncalc_spread_return_sharpe(latest_day)  # 6.273","metadata":{"execution":{"iopub.status.busy":"2022-04-14T01:55:10.996701Z","iopub.execute_input":"2022-04-14T01:55:10.997649Z","iopub.status.idle":"2022-04-14T01:55:11.053674Z","shell.execute_reply.started":"2022-04-14T01:55:10.997591Z","shell.execute_reply":"2022-04-14T01:55:11.052777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submit Predictions","metadata":{}},{"cell_type":"code","source":"env = jpx_tokyo_market_prediction.make_env()\niter_test = env.iter_test()\n\nfor i, (prices, options, financials, trades, secondary_prices, sample_prediction) in enumerate(iter_test):\n    cur_date = prices.Date.iloc[0]\n    check = prices_info[prices_info.Date == cur_date]\n    if len(check.index) > 0: # cur_date in prices_info file        \n        df_lagged = check.filter(['Date', 'SecuritiesCode', 'Target_lag1'])        \n        prices = pd.merge(prices, df_lagged, on = ['SecuritiesCode', 'Date'], how = 'left')\n    else: # use previous sample_prediction\n        if i == 0: # i.e. no previous dataframe in prediction\n            prices['Target_lag1'] = 0\n        else:\n            prices = pd.merge(prices, df_prev, on = ['SecuritiesCode'], how = 'inner')\n        \n    \n    prices = pd.merge(prices, stock_info.filter(['SecuritiesCode', 'MarketCapPct', 'Section/Products', 'Section',\n                                                  'NewMarketSegment', '33SectorName', '17SectorName', 'NewIndexSeriesSize']),\n                      on = ['SecuritiesCode'], how = 'left')\n    prices = prepareData(prices)\n    # probably one of the train columns is not in the sample_prediction - probably need to use a method to create repeats\n    # for now create it with all 0s\n    missing_cols = [x for x in feat_cols if x not in prices.columns]\n    for m in missing_cols:\n        prices[m] = 0\n    X_eval = prices.filter(feat_cols)\n    sample_prediction['Prediction'] = model.predict(X_eval) \n    sample_prediction = sample_prediction.sort_values(by = \"Prediction\", ascending=False)\n    sample_prediction.Rank = np.arange(0,2000)\n    sample_prediction = sample_prediction.sort_values(by = \"SecuritiesCode\", ascending=True)\n    sample_prediction.drop([\"Prediction\"],axis=1)\n    submission = sample_prediction[[\"Date\",\"SecuritiesCode\",\"Rank\"]]\n    env.predict(submission)\n    sample_prediction['Target_lag1'] = sample_prediction['Prediction']\n    df_prev = sample_prediction.filter(['Date', 'Target_lag1'])","metadata":{"execution":{"iopub.status.busy":"2022-04-14T01:55:11.055022Z","iopub.execute_input":"2022-04-14T01:55:11.055645Z","iopub.status.idle":"2022-04-14T01:55:12.038454Z","shell.execute_reply.started":"2022-04-14T01:55:11.055608Z","shell.execute_reply":"2022-04-14T01:55:12.037576Z"},"trusted":true},"execution_count":null,"outputs":[]}]}