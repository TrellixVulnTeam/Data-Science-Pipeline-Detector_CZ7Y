{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Reference\n- https://qiita.com/ground0state/items/657861de619a4e4a30de\n- https://www.kaggle.com/code/ikeppyo/jpx-lightgbm-demo","metadata":{}},{"cell_type":"markdown","source":"# アイディア\n- 株価は時系列データなので、直近の収益率が予測値に影響されるのではないか\n- 過去の2週間分（10営業日）の日次収益率（Target）から翌日の収益率を予測する\n# TODO\n- 日次収益率ではなく、累積収益率ではどうか？\n- https://lofas.hatenablog.com/entry/2015/02/17/181406","metadata":{}},{"cell_type":"code","source":"import os\nfrom pathlib import Path\nfrom decimal import ROUND_HALF_UP, Decimal\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.metrics import mean_squared_error\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.simplefilter('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-04-16T08:39:13.460931Z","iopub.execute_input":"2022-04-16T08:39:13.461118Z","iopub.status.idle":"2022-04-16T08:39:13.466546Z","shell.execute_reply.started":"2022-04-16T08:39:13.461094Z","shell.execute_reply":"2022-04-16T08:39:13.465667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_files(dir_name: str = 'train_files'):\n    \"\"\"\n    data_specifications: データの特徴\n    example_test_files: テスト用\n    └sample_submission.csv: 提出用の見本\n    supplemental_files: 追加されるデータ\n    train_files: 訓練データ\n    \"\"\"\n    base_path = Path(f'/kaggle/input/jpx-tokyo-stock-exchange-prediction/{dir_name}')\n    prices = pd.read_csv(base_path / 'stock_prices.csv')\n    options = pd.read_csv(base_path / 'options.csv')\n    financials = pd.read_csv(base_path / 'financials.csv')\n    trades = pd.read_csv(base_path / 'trades.csv')\n    secondary_prices = pd.read_csv(base_path / 'secondary_stock_prices.csv')\n    return prices, options, financials, trades, secondary_prices","metadata":{"execution":{"iopub.status.busy":"2022-04-16T08:39:13.467882Z","iopub.execute_input":"2022-04-16T08:39:13.468184Z","iopub.status.idle":"2022-04-16T08:39:13.480857Z","shell.execute_reply.started":"2022-04-16T08:39:13.468143Z","shell.execute_reply":"2022-04-16T08:39:13.480242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# 時間計測をしたい処理\nstock_list = pd.read_csv('/kaggle/input/jpx-tokyo-stock-exchange-prediction/stock_list.csv')\ntrain_files = read_files('train_files')\nsupplemental_files = read_files('supplemental_files')","metadata":{"execution":{"iopub.status.busy":"2022-04-16T08:39:13.482054Z","iopub.execute_input":"2022-04-16T08:39:13.482743Z","iopub.status.idle":"2022-04-16T08:39:41.954519Z","shell.execute_reply.started":"2022-04-16T08:39:13.482707Z","shell.execute_reply":"2022-04-16T08:39:41.953617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def merge_data(prices, options, financials, trades, secondary_prices, stock_list):\n    # stock_prices がベース\n    base_df = prices.copy()\n    \n    # stock_listと結合\n    _stock_list = stock_list.copy()\n    _stock_list.rename(columns={'Close': 'Close_x'}, inplace=True)\n    base_df = base_df.merge(_stock_list, on='SecuritiesCode', how=\"left\")\n\n    # tradesと結合\n    # stock_listのNewMarketSegmentと紐づくよう、tradesのSection項目を編集する\n    # _trades = trades.copy()\n    # _trades['NewMarketSegment'] = _trades['Section'].str.split(' \\(', expand=True)[0]\n    # base_df = base_df.merge(_trades, on=['Date', 'NewMarketSegment'], how=\"left\")\n\n    # financialsと結合\n    # _financials = financials.copy()\n    # _financials.rename(columns={'Date': 'Date_x', 'SecuritiesCode': 'SecuritiesCode_x'}, inplace=True)\n    # base_df = base_df.merge(_financials, left_on='RowId', right_on='DateCode', how=\"left\")\n    \n    return base_df","metadata":{"execution":{"iopub.status.busy":"2022-04-16T08:39:41.955707Z","iopub.execute_input":"2022-04-16T08:39:41.95592Z","iopub.status.idle":"2022-04-16T08:39:41.963091Z","shell.execute_reply.started":"2022-04-16T08:39:41.955893Z","shell.execute_reply":"2022-04-16T08:39:41.962055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def collector(prices, options, financials, trades, secondary_prices, stock_list):\n    # 読み込んだデータを統合して一つのファイルに纏める\n    base_df = merge_data(prices, options, financials, trades, secondary_prices, stock_list)\n    return base_df","metadata":{"execution":{"iopub.status.busy":"2022-04-16T08:39:41.964422Z","iopub.execute_input":"2022-04-16T08:39:41.964674Z","iopub.status.idle":"2022-04-16T08:39:41.979345Z","shell.execute_reply.started":"2022-04-16T08:39:41.964648Z","shell.execute_reply":"2022-04-16T08:39:41.978461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nbase_df = collector(*train_files, stock_list)\nsupplemental_df = collector(*supplemental_files, stock_list)\nbase_df = pd.concat([base_df, supplemental_df]).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T08:39:41.981004Z","iopub.execute_input":"2022-04-16T08:39:41.981287Z","iopub.status.idle":"2022-04-16T08:39:44.812338Z","shell.execute_reply.started":"2022-04-16T08:39:41.981236Z","shell.execute_reply":"2022-04-16T08:39:44.811306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_df = base_df.sort_values([\"SecuritiesCode\", \"Date\"])\nbase_df[\"ReturnToday\"] = base_df.groupby(\"SecuritiesCode\")[\"Target\"].shift(2)\nfor period in range(3,13):\n    base_df.loc[:, f\"ReturnBefore_{period-2}\"] = base_df.groupby(\"SecuritiesCode\")[\"Target\"].shift(period)\nbase_df = base_df.reset_index(drop=True)\n# base_df[[\"Date\",\"Close\",\"Target\",\"ReturnToday\",\"ReturnBefore_1\",\"ReturnBefore_2\",\"ReturnBefore_10\"]]","metadata":{"execution":{"iopub.status.busy":"2022-04-16T08:39:44.814139Z","iopub.execute_input":"2022-04-16T08:39:44.814472Z","iopub.status.idle":"2022-04-16T08:39:48.863224Z","shell.execute_reply.started":"2022-04-16T08:39:44.814416Z","shell.execute_reply":"2022-04-16T08:39:48.862186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_cols = ['RowId', 'Date', 'SecuritiesCode']\n# 数値系の特徴量\nnumerical_cols = [\"ReturnToday\"] + [f\"ReturnBefore_{period-2}\" for period in range(3,13)]\n# カテゴリ系の特徴量\n# categorical_cols = ['NewMarketSegment', '33SectorCode']\n# 目的変数\nlabel_col = ['Target']","metadata":{"execution":{"iopub.status.busy":"2022-04-16T08:39:48.864276Z","iopub.execute_input":"2022-04-16T08:39:48.864531Z","iopub.status.idle":"2022-04-16T08:39:48.869997Z","shell.execute_reply.started":"2022-04-16T08:39:48.864498Z","shell.execute_reply":"2022-04-16T08:39:48.869156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 予測値を降順に並べて順位番号を振る関数\n# 言い換えると、目的変数から提出用項目を導出する関数\ndef add_rank(df, col_name=\"pred\"):\n    df[\"Rank\"] = df.groupby(\"Date\")[col_name].rank(ascending=False, method=\"first\") - 1 \n    df[\"Rank\"] = df[\"Rank\"].astype(\"int\")\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-04-16T08:39:48.871363Z","iopub.execute_input":"2022-04-16T08:39:48.871741Z","iopub.status.idle":"2022-04-16T08:39:48.883257Z","shell.execute_reply.started":"2022-04-16T08:39:48.871697Z","shell.execute_reply":"2022-04-16T08:39:48.882639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calc_spread_return_sharpe(df: pd.DataFrame, portfolio_size: int = 200, toprank_weight_ratio: float = 2) -> float:\n    \"\"\"\n    Args:\n        df (pd.DataFrame): predicted results\n        portfolio_size (int): # of equities to buy/sell\n        toprank_weight_ratio (float): the relative weight of the most highly ranked stock compared to the least.\n    Returns:\n        (float): sharpe ratio\n    \"\"\"\n    def _calc_spread_return_per_day(df, portfolio_size, toprank_weight_ratio):\n        \"\"\"\n        Args:\n            df (pd.DataFrame): predicted results\n            portfolio_size (int): # of equities to buy/sell\n            toprank_weight_ratio (float): the relative weight of the most highly ranked stock compared to the least.\n        Returns:\n            (float): spread return\n        \"\"\"\n        assert df['Rank'].min() == 0\n        assert df['Rank'].max() == len(df['Rank']) - 1\n        weights = np.linspace(start=toprank_weight_ratio, stop=1, num=portfolio_size)\n        purchase = (df.sort_values(by='Rank')['Target'][:portfolio_size] * weights).sum() / weights.mean()\n        short = (df.sort_values(by='Rank', ascending=False)['Target'][:portfolio_size] * weights).sum() / weights.mean()\n        return purchase - short\n\n    buf = df.groupby('Date').apply(_calc_spread_return_per_day, portfolio_size, toprank_weight_ratio)\n    sharpe_ratio = buf.mean() / buf.std()\n    return sharpe_ratio","metadata":{"execution":{"iopub.status.busy":"2022-04-16T08:39:48.884292Z","iopub.execute_input":"2022-04-16T08:39:48.884542Z","iopub.status.idle":"2022-04-16T08:39:48.895551Z","shell.execute_reply.started":"2022-04-16T08:39:48.884514Z","shell.execute_reply":"2022-04-16T08:39:48.8949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 予測用のデータフレームと、予測結果をもとに、スコアを計算する関数\ndef evaluator(df, pred):\n    df[\"pred\"] = pred\n    df = add_rank(df)\n    score = calc_spread_return_sharpe(df)\n    return score","metadata":{"execution":{"iopub.status.busy":"2022-04-16T08:39:48.896969Z","iopub.execute_input":"2022-04-16T08:39:48.897204Z","iopub.status.idle":"2022-04-16T08:39:48.905115Z","shell.execute_reply.started":"2022-04-16T08:39:48.897178Z","shell.execute_reply":"2022-04-16T08:39:48.904579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import lightgbm as lgb\n# import optuna.integration.lightgbm as lgb\n\n# 学習を実行する関数\ndef trainer(feature_df, feat_cols, label_col, fold_params, seed=2022):\n    scores = []\n    models = []\n    params = []\n\n    for param in fold_params:\n        ################################\n        # データ準備\n        ################################\n        train = feature_df[(param[0] <= feature_df['Date']) & (feature_df['Date'] < param[1])]\n        valid = feature_df[(param[1] <= feature_df['Date']) & (feature_df['Date'] < param[2])]\n\n        X_train = train[feat_cols]\n        y_train = train[label_col]\n        X_valid = valid[feat_cols]\n        y_valid = valid[label_col]\n        \n        lgb_train = lgb.Dataset(X_train, y_train)\n        lgb_valid = lgb.Dataset(X_valid, y_valid, reference=lgb_train)\n\n        ################################\n        # 学習\n        ################################\n        params = {\n            'task': 'train',                   # 学習\n            'boosting_type': 'gbdt',           # GBDT\n            'objective': 'regression',         # 回帰\n            'metric': 'rmse',                  # 損失（誤差）\n            'learning_rate': 0.01,             # 学習率\n            'lambda_l1': 0.5,                  # L1正則化項の係数\n            'lambda_l2': 0.5,                  # L2正則化項の係数\n            'num_leaves': 10,                  # 最大葉枚数\n            'feature_fraction': 0.5,           # ランダムに抽出される列の割合\n            'bagging_fraction': 0.5,           # ランダムに抽出される標本の割合\n            'bagging_freq': 5,                 # バギング実施頻度\n            'min_child_samples': 10,           # 葉に含まれる最小データ数\n            'seed': seed                       # シード値\n        } \n \n        lgb_results = {}                       \n        model = lgb.train( \n            params,                            # ハイパーパラメータ\n            lgb_train,                         # 訓練データ\n            valid_sets=[lgb_train, lgb_valid], # 検証データ\n            valid_names=['Train', 'Valid'],    # データセット名前\n            num_boost_round=2000,              # 計算回数\n            early_stopping_rounds=100,         # 計算打ち切り設定\n            evals_result=lgb_results,          # 学習の履歴\n            verbose_eval=100,                  # 学習過程の表示サイクル\n        )  \n\n        ################################\n        # 結果描画\n        ################################\n        fig = plt.figure(figsize=(10, 4))\n\n        # loss\n        plt.subplot(1,2,1)\n        loss_train = lgb_results['Train']['rmse']\n        loss_test = lgb_results['Valid']['rmse']   \n        plt.xlabel('Iteration')\n        plt.ylabel('logloss')\n        plt.plot(loss_train, label='train loss')\n        plt.plot(loss_test, label='valid loss')\n        plt.legend()\n\n        # feature importance\n        plt.subplot(1,2,2)\n        importance = pd.DataFrame({'feature':feat_cols, 'importance':model.feature_importance()})\n        sns.barplot(x = 'importance', y = 'feature', data = importance.sort_values('importance', ascending=False))\n\n        plt.tight_layout()\n        plt.show()\n\n        ################################\n        # 評価\n        ################################\n        # 推論\n        pred =  model.predict(X_valid, num_iteration=model.best_iteration)\n        # 評価\n        score = evaluator(valid, pred)\n\n        scores.append(score)\n        models.append(model)\n\n    print(\"CV_SCORES:\", scores)\n    print(\"CV_SCORE:\", np.mean(scores))\n    \n    return models","metadata":{"execution":{"iopub.status.busy":"2022-04-16T08:39:48.906392Z","iopub.execute_input":"2022-04-16T08:39:48.906862Z","iopub.status.idle":"2022-04-16T08:39:48.926183Z","shell.execute_reply.started":"2022-04-16T08:39:48.906831Z","shell.execute_reply":"2022-04-16T08:39:48.925505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 2020-12-23よりも前のデータは証券コードが2000個すべて揃っていないため、これ以降のデータのみを使う。\n# (学習用データの開始日、学習用データの終了日＝検証用データの開始日、検証用データの終了日)\n# 目的変数\nlabel_col = ['Target']\n\nbase_cols = ['RowId', 'Date', 'SecuritiesCode']\n# 数値系の特徴量\nnumerical_cols = [\"ReturnToday\"] + [f\"ReturnBefore_{period-2}\" for period in range(3,13)]\n# 特徴量\nfeat_cols = numerical_cols\n\n# データフレームの項目を選択された項目だけに絞込\nfeature_df = base_df[base_cols + feat_cols + label_col]\n\nfold_params = [\n    ('2020-12-23', '2021-11-01', '2021-12-01'),\n    ('2021-01-23', '2021-12-01', '2022-01-01'),\n    ('2021-02-23', '2022-01-01', '2022-02-01'),\n]\nmodels = trainer(feature_df, feat_cols, label_col, fold_params)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T08:39:48.92738Z","iopub.execute_input":"2022-04-16T08:39:48.928214Z","iopub.status.idle":"2022-04-16T08:40:06.443007Z","shell.execute_reply.started":"2022-04-16T08:39:48.928172Z","shell.execute_reply":"2022-04-16T08:40:06.442242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predictor(feature_df, feat_cols, models, is_train=True):\n    X = feature_df[feat_cols]\n    \n    # 推論\n    preds = list(map(lambda model: model.predict(X, num_iteration=model.best_iteration), models))\n    \n    # スコアは学習時のみ計算\n    if is_train:\n        scores = list(map(lambda pred: evaluator(feature_df, pred), preds))\n        print(\"SCORES:\", scores)\n\n    # 推論結果をバギング\n    pred = np.array(preds).mean(axis=0)\n\n    # スコアは学習時のみ計算\n    if is_train:\n        score = evaluator(feature_df, pred)\n        print(\"SCORE:\", score)\n    \n    return pred","metadata":{"execution":{"iopub.status.busy":"2022-04-16T08:40:06.444327Z","iopub.execute_input":"2022-04-16T08:40:06.444546Z","iopub.status.idle":"2022-04-16T08:40:06.451694Z","shell.execute_reply.started":"2022-04-16T08:40:06.44452Z","shell.execute_reply":"2022-04-16T08:40:06.450916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 試験用データは学習用にも検証用にも使用していないものを使う\ntest_df = feature_df[('2022-02-01' <= feature_df['Date'])].copy()\npred = predictor(test_df, feat_cols, models)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T08:40:06.45311Z","iopub.execute_input":"2022-04-16T08:40:06.453482Z","iopub.status.idle":"2022-04-16T08:40:07.408465Z","shell.execute_reply.started":"2022-04-16T08:40:06.453425Z","shell.execute_reply":"2022-04-16T08:40:07.407884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 時系列APIのロード\nimport jpx_tokyo_market_prediction\nenv = jpx_tokyo_market_prediction.make_env()\niter_test = env.iter_test()\n# supplemental filesを履歴データの初期状態としてセットアップ\npast_df = supplemental_df.copy()\n# 日次で推論・登録\nfor i, (prices, options, financials, trades, secondary_prices, sample_prediction) in enumerate(iter_test):\n    current_date = prices[\"Date\"].iloc[0]\n\n    if i == 0:\n        # リークを防止するため、時系列APIから受け取ったデータより未来のデータを削除\n        past_df = past_df[past_df[\"Date\"] < current_date]\n\n    # リソース確保のため古い履歴を削除\n    threshold = (pd.Timestamp(current_date) - pd.offsets.BDay(80)).strftime(\"%Y-%m-%d\")\n    past_df = past_df[past_df[\"Date\"] >= threshold]\n    \n    # 時系列APIから受け取ったデータを履歴データに統合\n    base_df = collector(prices, options, financials, trades, secondary_prices, stock_list)\n    past_df = pd.concat([past_df, base_df]).reset_index(drop=True)\n\n    # 特徴量エンジニアリング\n    # feature_df, feat_cols, label_col = preprocessor(past_df, False)\n    past_df = past_df.sort_values([\"SecuritiesCode\", \"Date\"])\n    past_df[\"ReturnToday\"] = past_df.groupby(\"SecuritiesCode\")[\"Target\"].shift(2)\n    for period in range(3,13):\n        past_df.loc[:, f\"ReturnBefore_{period-2}\"] = past_df.groupby(\"SecuritiesCode\")[\"Target\"].shift(period)\n    past_df = past_df.reset_index(drop=True)\n    \n    label_col = ['Target']\n    base_cols = ['RowId', 'Date', 'SecuritiesCode']\n    numerical_cols = [\"ReturnToday\"] + [f\"ReturnBefore_{period-2}\" for period in range(3,13)]\n    feat_cols = numerical_cols\n    feature_df = past_df[base_cols + feat_cols + label_col]\n\n    # 予測対象レコードだけを抽出\n    feature_df = feature_df[feature_df['Date'] == current_date]\n\n    # 推論\n    feature_df[\"pred\"] = predictor(feature_df, feat_cols, models, False)\n\n    # 推論結果からRANKを導出し、提出データに反映\n    feature_df = add_rank(feature_df)\n    feature_map = feature_df.set_index('SecuritiesCode')['Rank'].to_dict()\n    sample_prediction['Rank'] = sample_prediction['SecuritiesCode'].map(feature_map)\n\n    # 結果を登録\n    env.predict(sample_prediction)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T08:40:46.048137Z","iopub.execute_input":"2022-04-16T08:40:46.048389Z","iopub.status.idle":"2022-04-16T08:40:46.090601Z","shell.execute_reply.started":"2022-04-16T08:40:46.048362Z","shell.execute_reply":"2022-04-16T08:40:46.089772Z"},"trusted":true},"execution_count":null,"outputs":[]}]}