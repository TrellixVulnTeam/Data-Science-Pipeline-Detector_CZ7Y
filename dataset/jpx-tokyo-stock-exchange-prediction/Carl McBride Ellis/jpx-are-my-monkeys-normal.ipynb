{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### JPX: Are my monkeys behaving normally?\nJust for fun I have some monkeys that [do my trading for me](https://www.kaggle.com/code/carlmcbrideellis/jpx-baseline-monkey-throwing-dart-model), inspired by the famous suggestion by [Burton Malkiel](https://en.wikipedia.org/wiki/Burton_Malkiel) that \"*a blindfolded monkey throwing darts at the stock listings could select a portfolio that would do as well as one selected by the experts.*\" as mentioned in his book [A Random Walk Down Wall Street](https://wwnorton.com/books/9780393358384). As I can only give them 5 bananas per day, here we simulate the results of 50,000 such random submissions.\n\nRead in the supplemental `stock_prices.csv`, which is the data used to calculate the Leaderboard:","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport random\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-22T07:43:31.73548Z","iopub.execute_input":"2022-04-22T07:43:31.735808Z","iopub.status.idle":"2022-04-22T07:43:31.758809Z","shell.execute_reply.started":"2022-04-22T07:43:31.735723Z","shell.execute_reply":"2022-04-22T07:43:31.75822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prices = pd.read_csv('../input/jpx-tokyo-stock-exchange-prediction/supplemental_files/stock_prices.csv', parse_dates=[\"Date\"])","metadata":{"execution":{"iopub.status.busy":"2022-04-22T07:43:31.778553Z","iopub.execute_input":"2022-04-22T07:43:31.77917Z","iopub.status.idle":"2022-04-22T07:43:32.152722Z","shell.execute_reply.started":"2022-04-22T07:43:31.779134Z","shell.execute_reply":"2022-04-22T07:43:32.151754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"set up the [evaluation function](https://www.kaggle.com/code/smeitoma/jpx-competition-metric-definition)","metadata":{}},{"cell_type":"code","source":"def calc_spread_return_sharpe(df: pd.DataFrame, portfolio_size: int = 200, toprank_weight_ratio: float = 2) -> float:\n    \"\"\"\n    Args:\n        df (pd.DataFrame): predicted results\n        portfolio_size (int): # of equities to buy/sell\n        toprank_weight_ratio (float): the relative weight of the most highly ranked stock compared to the least.\n    Returns:\n        (float): sharpe ratio\n    \"\"\"\n    def _calc_spread_return_per_day(df, portfolio_size, toprank_weight_ratio):\n        \"\"\"\n        Args:\n            df (pd.DataFrame): predicted results\n            portfolio_size (int): # of equities to buy/sell\n            toprank_weight_ratio (float): the relative weight of the most highly ranked stock compared to the least.\n        Returns:\n            (float): spread return\n        \"\"\"\n        assert df['Rank'].min() == 0\n        assert df['Rank'].max() == len(df['Rank']) - 1\n        weights = np.linspace(start=toprank_weight_ratio, stop=1, num=portfolio_size)\n        purchase = (df.sort_values(by='Rank')['Target'][:portfolio_size] * weights).sum() / weights.mean()\n        short = (df.sort_values(by='Rank', ascending=False)['Target'][:portfolio_size] * weights).sum() / weights.mean()\n        return purchase - short\n\n    buf = df.groupby('Date').apply(_calc_spread_return_per_day, portfolio_size, toprank_weight_ratio)\n    sharpe_ratio = buf.mean() / buf.std()\n    return sharpe_ratio","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-22T07:43:32.154286Z","iopub.execute_input":"2022-04-22T07:43:32.154521Z","iopub.status.idle":"2022-04-22T07:43:32.163919Z","shell.execute_reply.started":"2022-04-22T07:43:32.154489Z","shell.execute_reply":"2022-04-22T07:43:32.163171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"set up our monkey instance","metadata":{}},{"cell_type":"code","source":"n_monkeys = 50000","metadata":{"execution":{"iopub.status.busy":"2022-04-22T07:43:32.16511Z","iopub.execute_input":"2022-04-22T07:43:32.165342Z","iopub.status.idle":"2022-04-22T07:43:32.174997Z","shell.execute_reply.started":"2022-04-22T07:43:32.165314Z","shell.execute_reply":"2022-04-22T07:43:32.174236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"codes = prices[\"SecuritiesCode\"].unique()\nresults = []\nfor i in range(n_monkeys):\n    code_list = []\n    for code in codes:\n        code_list.append([code,random.random()])       \n    codes_df = pd.DataFrame(code_list, columns=['code','prediction'])\n    codes_df['Rank'] = codes_df.prediction.rank(method=\"min\").astype('int') -1\n    mapping = dict(codes_df[['code', 'Rank']].values)\n    prices['Rank'] = prices['SecuritiesCode'].map(mapping)\n    results.append(calc_spread_return_sharpe(prices))","metadata":{"execution":{"iopub.status.busy":"2022-04-22T07:43:32.176645Z","iopub.execute_input":"2022-04-22T07:43:32.176835Z","iopub.status.idle":"2022-04-22T07:43:40.589415Z","shell.execute_reply.started":"2022-04-22T07:43:32.176811Z","shell.execute_reply":"2022-04-22T07:43:40.588487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Maximum score:  %.3f\" % max(results))\nprint(\"Minimum score: %.3f\" % min(results))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-22T07:43:40.590839Z","iopub.execute_input":"2022-04-22T07:43:40.591333Z","iopub.status.idle":"2022-04-22T07:43:40.597518Z","shell.execute_reply.started":"2022-04-22T07:43:40.59129Z","shell.execute_reply":"2022-04-22T07:43:40.596716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let us now fit a [normal distribution](https://en.wikipedia.org/wiki/Normal_distribution) to the results, and plot","metadata":{}},{"cell_type":"code","source":"from scipy.optimize import curve_fit\n\n# define a Gaussian function\ndef Gaussian(x,mu,sigma,A):\n    return A*np.exp(-0.5 * ((x-mu)/sigma)**2)\n\nfig, ax = plt.subplots(figsize=(10, 5))\nbin_heights,bin_borders, _ = plt.hist(results, bins=150)\nbin_centers = bin_borders[:-1] + np.diff(bin_borders)/2\n\n# seed guess\ninitial_guess=(0, 0.1 , 1)\n# the fit\nparameters,covariance=curve_fit(Gaussian, bin_centers, bin_heights, initial_guess)\nsigma=np.sqrt(np.diag(covariance))\n\nx_interval = np.linspace(min(results), max(results), n_monkeys)\nplt.plot(x_interval,Gaussian(x_interval,parameters[0],parameters[1],parameters[2]),color='red',lw=4,label='Gaussian fit', alpha=0.8)\nplt.xlabel('LB score',fontsize=14)\nplt.yticks([]);","metadata":{"execution":{"iopub.status.busy":"2022-04-22T07:43:40.598934Z","iopub.execute_input":"2022-04-22T07:43:40.599689Z","iopub.status.idle":"2022-04-22T07:43:41.502377Z","shell.execute_reply.started":"2022-04-22T07:43:40.599641Z","shell.execute_reply":"2022-04-22T07:43:41.501559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"the normal distribution has the following parameters:","metadata":{}},{"cell_type":"code","source":"print(\"μ = %.5f\" % parameters[0])\nprint(\"σ = %.5f\" % abs(parameters[1]) )","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-22T07:43:41.503834Z","iopub.execute_input":"2022-04-22T07:43:41.504318Z","iopub.status.idle":"2022-04-22T07:43:41.509836Z","shell.execute_reply.started":"2022-04-22T07:43:41.504251Z","shell.execute_reply":"2022-04-22T07:43:41.509111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The Sharpe ratio is effectively calculated over one average day, thus a yearly Sharpe ratio of 1 (good) would correspond to a LB score of   \\\\( 1/\\sqrt{252} \\approx 0.063 \\\\) and an excellent Sharpe ratio of 2 would correspond to a LB score of \\\\( 2/\\sqrt{252} \\approx 0.126 \\\\) respectively *etc* (many thanks to [Bowaka](https://www.kaggle.com/bowaka) for this calculation). \n\nLet us see empirically how many did better than these values:","metadata":{}},{"cell_type":"code","source":"Sharpe_values = [1,2,3,4,5,6,7]\n# assume the number of trading days per year = 252\n\nfor k in Sharpe_values:\n    LB_score = k/np.sqrt(252)\n    count = sum(i > LB_score for i in results)\n    print(\"Yearly Sharpe\",k,\"LB score %.3f\" % LB_score,\"percentage = %.1f\" % ((100/n_monkeys)*count) ) ","metadata":{"execution":{"iopub.status.busy":"2022-04-22T07:43:41.511491Z","iopub.execute_input":"2022-04-22T07:43:41.511777Z","iopub.status.idle":"2022-04-22T07:43:41.525239Z","shell.execute_reply.started":"2022-04-22T07:43:41.511746Z","shell.execute_reply":"2022-04-22T07:43:41.524443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Normality tests\nHere we are looking for *p*-values greater than 0.05, which would  indicate that we cannot reject the null hypothesis that the data was indeed actually drawn from a normal distribution.\n#### [Shapiro-Wilk test](https://docs.scipy.org/doc/scipy-1.8.0/html-scipyorg/reference/generated/scipy.stats.shapiro.html) \n(Note: For *N* > 5000 the W test statistic is accurate but the *p*-value may not be.)","metadata":{}},{"cell_type":"code","source":"from scipy.stats import shapiro\n\nWstat, p = shapiro(results)\n\nprint('W statistic = %.3f, p-value = %.3f' % (Wstat, p))","metadata":{"execution":{"iopub.status.busy":"2022-04-22T07:43:41.526443Z","iopub.execute_input":"2022-04-22T07:43:41.52702Z","iopub.status.idle":"2022-04-22T07:43:41.829894Z","shell.execute_reply.started":"2022-04-22T07:43:41.526977Z","shell.execute_reply":"2022-04-22T07:43:41.829053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### [D’Agostino and Pearson test](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.normaltest.html)","metadata":{}},{"cell_type":"code","source":"from scipy.stats import normaltest\n\nk2, p = normaltest(results)\n\nprint('result = %.3f, p-value = %.3f' % (k2, p))","metadata":{"execution":{"iopub.status.busy":"2022-04-22T07:43:41.831159Z","iopub.execute_input":"2022-04-22T07:43:41.831417Z","iopub.status.idle":"2022-04-22T07:43:41.837522Z","shell.execute_reply.started":"2022-04-22T07:43:41.831386Z","shell.execute_reply":"2022-04-22T07:43:41.836956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"where the result is \\\\(s^2 + k^2 \\\\), where *s* is the z-score returned by a [skew test](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.skewtest.html) and *k* is the z-score returned by a [kurtosis test](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kurtosistest.html).\n\n### Conclusions\n* Both visually and via the two normality tests we can see the our simulated monkeys are fairly normal\n* It is not possible for a random submission to realistically obtain a Leaderboard score above 0.4\n\n### Annex\nLet us calculate the probability that a monkey can obtain a Leaderboard score greater than, say, 0.25","metadata":{}},{"cell_type":"code","source":"from scipy.special import erf\n\nmu       = 0 # assume mu is exactly zero\nsigma    = abs(parameters[1])\nLB_score = 0.25\n\nprobability = (erf((LB_score-mu)/(sigma*np.sqrt(2)))/2) + 0.5\n\nprint(f'Probability = {round((1-probability)*100,3)}%')","metadata":{"execution":{"iopub.status.busy":"2022-04-22T07:44:04.070145Z","iopub.execute_input":"2022-04-22T07:44:04.070421Z","iopub.status.idle":"2022-04-22T07:44:04.078084Z","shell.execute_reply.started":"2022-04-22T07:44:04.070392Z","shell.execute_reply":"2022-04-22T07:44:04.077137Z"},"trusted":true},"execution_count":null,"outputs":[]}]}