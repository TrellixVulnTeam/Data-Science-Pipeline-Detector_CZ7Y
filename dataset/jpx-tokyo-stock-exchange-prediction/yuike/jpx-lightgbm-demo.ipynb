{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from IPython.display import Image","metadata":{"execution":{"iopub.status.busy":"2022-04-09T15:01:02.658015Z","iopub.execute_input":"2022-04-09T15:01:02.658392Z","iopub.status.idle":"2022-04-09T15:01:02.679237Z","shell.execute_reply.started":"2022-04-09T15:01:02.658291Z","shell.execute_reply":"2022-04-09T15:01:02.678578Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# コンテストの概要\n* 日本取引所グループ（JPX）による、2000銘柄の証券を対象にした、**証券の値段（終値）の変化率**予測。\n* **翌日から翌々日にかけての終値**の変化率が目的変数。\n* 提出データは、目的変数の値そのものではなく、目的変数の値を降順に並べた際の順位。\n* コンテストについて、より詳しく知りたい場合は[【日本語ver】Easy to understand the competition](https://www.kaggle.com/code/chumajin/ver-easy-to-understand-the-competition)が非常に役に立つと思います。","metadata":{}},{"cell_type":"markdown","source":"# ノートブックの概要\n* このノートブックでは[データ読み込み]→[データ統合]→[特徴量エンジニアリング]→[学習]→[推論・評価]→[提出]を一気通貫で行います。\n* 使用するモデルはLightGBMです。\n* モデルを3つ生成し、結果をアンサンブルして最終的な推論結果を作成します。\n\n推論・評価までの流れは以下の通りです。  \n赤背景は推論・評価推時のみ使用している関数です。青背景は提出時にも使用している関数・データとなります。  \n青背景の関数をカスタマイズすることで、様々な特徴量で精度検証ができ、また、そのままSubmitもできるようになっています。","metadata":{}},{"cell_type":"code","source":"Image('../input/jpx-images/jpx_flow.drawio.png')","metadata":{"execution":{"iopub.status.busy":"2022-04-09T15:01:02.892242Z","iopub.execute_input":"2022-04-09T15:01:02.892667Z","iopub.status.idle":"2022-04-09T15:01:02.92416Z","shell.execute_reply.started":"2022-04-09T15:01:02.892638Z","shell.execute_reply":"2022-04-09T15:01:02.923381Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 入力ファイルの概要\n* `jpx-tokyo-stock-exchange-prediction/`\n    * `stock_list.csv`:  主な項目は証券コードと証券に関する属性情報。Keyは**SecuritiesCode**。\n    * `train_files/`:  学習用データ群。Dateの範囲は2017-01-04 ～ 2021-12-03。\n        * `stock_prices.csv`:  主な項目は証券コードと日単位の証券価格、および、目的変数（Target）。Keyは**Date**と**SecuritiesCode**であり、これらを連結した**RowId**も用意されている。\n        * `secondary_stock_prices.csv`:  項目は**stock_prices.csv**と同じだが、**stock_prices.csv**の対象とならなかった証券が入っている。Keyは**stock_prices.csv**と同じ。\n        * `options.csv`:  主な項目はオプション（証券用語）コードと日単位のオプション価格。Keyは**Date**と**OptionsCode**であり、これらを連結した**DateCode**も用意されている。\n        * `trades.csv`:  主な項目はマーケット毎の前営業週における取引サマリ。Keyは**Date**と**Section**。**Section**を加工することで**stock_list.csv**の**NewMarketSegment**と紐づけることができる。意味のあるレコードの発生は週次。\n        * `financials.csv`:  主な項目は四半期決算報告の内容。Keyは**Date**と**SecuritiesCode**であり、これらを連結した**DateCode**も用意されている。レコードの発生は四半期毎。\n    * `supplemental_files/`:  追加の学習用データ群。5月上旬、6月上旬、およびコンテスト終了直前に最新のデータが反映される。2022-04-05時点でのDateの範囲は2021-12-06 ～ 2022-02-28。\n        * **train_files**配下と同じ形式のファイル群が格納されている\n        * `example_test_files/`:  評価用データ群（のサンプル）\n        * **train_files**配下とほぼ（※）同じ形式のファイル群が格納されている\n        * ※ **stock_prices.csv**と**secondary_stock_prices.csv**から**Target**が削除されている点だけが**train_files**配下と異なる\n    * `data_specifications/`:  上記ファイル群の項目説明書\n        * `stock_list_spec.csv`:  **stock_list.csv**の項目説明書\n        * `stock_prices_spec.csv`:  **stock_prices.csv**、**secondary_stock_prices.csv**の項目説明書\n        * `options_spec.csv`:  **options.csv**の項目説明書\n        * `trades_spec.csv`:  **trades.csv**の項目説明書\n        * `stock_fin_spec.csv`:  **financials.csv**の項目説明書\n    * `jpx_tokyo_market_prediction/`:時系列API\n    \nファイル間の関係性は以下のようなイメージです","metadata":{}},{"cell_type":"code","source":"Image('../input/jpx-images/jpx_files.drawio.png')","metadata":{"execution":{"iopub.status.busy":"2022-04-09T15:01:03.052566Z","iopub.execute_input":"2022-04-09T15:01:03.05285Z","iopub.status.idle":"2022-04-09T15:01:03.062499Z","shell.execute_reply.started":"2022-04-09T15:01:03.052816Z","shell.execute_reply":"2022-04-09T15:01:03.061687Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"データの詳細は https://www.kaggle.com/competitions/jpx-tokyo-stock-exchange-prediction/data を参照  \n時系列APIの使い方は https://www.kaggle.com/competitions/jpx-tokyo-stock-exchange-prediction/overview/evaluation を参照  \nオプションコード体系の日本語版は https://www.jpx.co.jp/sicc/securities-code/nlsgeu0000032d48-att/(HP)sakimono20220208.pdf を参照  \n証券コード関係は https://www.jpx.co.jp/sicc/securities-code/01.html を参照","metadata":{}},{"cell_type":"markdown","source":"# 準備\n* 使用するライブラリをインポートします","metadata":{}},{"cell_type":"code","source":"import os\nfrom pathlib import Path\nfrom decimal import ROUND_HALF_UP, Decimal\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.metrics import mean_squared_error\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.simplefilter('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-04-09T15:01:03.286424Z","iopub.execute_input":"2022-04-09T15:01:03.286715Z","iopub.status.idle":"2022-04-09T15:01:04.465055Z","shell.execute_reply.started":"2022-04-09T15:01:03.286684Z","shell.execute_reply":"2022-04-09T15:01:04.46418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# データ読み込み\n\n以下のファイル群を読み込みます。\n* stock_list.csv\n* train_files 配下のファイル（Dateの範囲は2017-01-04 ～ 2021-12-03）\n* supplemental_files 配下のファイル（Dateの範囲は2021-12-06 ～ 2022-02-28 ※2022/04/05現在）","metadata":{}},{"cell_type":"markdown","source":"## Function","metadata":{}},{"cell_type":"code","source":"def read_files(dir_name: str = 'train_files'):\n    base_path = Path(f'../input/jpx-tokyo-stock-exchange-prediction/{dir_name}')\n    prices = pd.read_csv(base_path / 'stock_prices.csv')\n    options = pd.read_csv(base_path / 'options.csv')\n    financials = pd.read_csv(base_path / 'financials.csv')\n    trades = pd.read_csv(base_path / 'trades.csv')\n    secondary_prices = pd.read_csv(base_path / 'secondary_stock_prices.csv')\n    return prices, options, financials, trades, secondary_prices","metadata":{"execution":{"iopub.status.busy":"2022-04-09T15:01:04.467085Z","iopub.execute_input":"2022-04-09T15:01:04.467707Z","iopub.status.idle":"2022-04-09T15:01:04.474142Z","shell.execute_reply.started":"2022-04-09T15:01:04.46766Z","shell.execute_reply":"2022-04-09T15:01:04.473322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exec","metadata":{}},{"cell_type":"code","source":"%%time\n\nstock_list = pd.read_csv('../input/jpx-tokyo-stock-exchange-prediction/stock_list.csv')\ntrain_files = read_files('train_files')\nsupplemental_files = read_files('supplemental_files')","metadata":{"execution":{"iopub.status.busy":"2022-04-09T15:01:04.475451Z","iopub.execute_input":"2022-04-09T15:01:04.475671Z","iopub.status.idle":"2022-04-09T15:01:38.72755Z","shell.execute_reply.started":"2022-04-09T15:01:04.475645Z","shell.execute_reply":"2022-04-09T15:01:38.726559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# データ統合\n\n* 読み込んだデータを結合して、一つのファイルに纏めます。","metadata":{}},{"cell_type":"markdown","source":"## Function","metadata":{}},{"cell_type":"markdown","source":"`merge_data`関数では各ファイルを水平方向に結合します。現時点では`stock_prices`、`stock_list`しか使っていません。  \nコメントアウトを解除すれば`trades`、`financials`とも結合は可能ですが、  \nこれらのデータは、有効なレコードが発生するタイミングが日次ではないため、学習データとして意味のあるものとするためには「直近に発生した有効なレコードの値を引き継ぐ」などの対処が必要となります。  \n`options`に関しては、[OptionsCodeの附番規則](https://www.jpx.co.jp/sicc/securities-code/nlsgeu0000032d48-att/(HP)sakimono20220208.pdf)を見ていけば適切な使い方が見えそうです。","metadata":{}},{"cell_type":"code","source":"def merge_data(prices, options, financials, trades, secondary_prices, stock_list):\n    # stock_prices がベース\n    base_df = prices.copy()\n    \n    # stock_listと結合\n    _stock_list = stock_list.copy()\n    _stock_list.rename(columns={'Close': 'Close_x'}, inplace=True)\n    base_df = base_df.merge(_stock_list, on='SecuritiesCode', how=\"left\")\n\n    # tradesと結合\n    # stock_listのNewMarketSegmentと紐づくよう、tradesのSection項目を編集する\n    # _trades = trades.copy()\n    # _trades['NewMarketSegment'] = _trades['Section'].str.split(' \\(', expand=True)[0]\n    # base_df = base_df.merge(_trades, on=['Date', 'NewMarketSegment'], how=\"left\")\n\n    # financialsと結合\n    # _financials = financials.copy()\n    # _financials.rename(columns={'Date': 'Date_x', 'SecuritiesCode': 'SecuritiesCode_x'}, inplace=True)\n    # base_df = base_df.merge(_financials, left_on='RowId', right_on='DateCode', how=\"left\")\n    \n    return base_df","metadata":{"execution":{"iopub.status.busy":"2022-04-09T15:01:38.729865Z","iopub.execute_input":"2022-04-09T15:01:38.730349Z","iopub.status.idle":"2022-04-09T15:01:38.736038Z","shell.execute_reply.started":"2022-04-09T15:01:38.730306Z","shell.execute_reply":"2022-04-09T15:01:38.73525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`adjust_price`関数は[Train Demo](https://www.kaggle.com/code/smeitoma/train-demo)で紹介されている関数をほぼそのまま使わせて頂いています。（Dateのインデックス化だけコメントアウトしています）  \n項目追加が発生するため、統合の範囲を超えていますが、関数内でソートやインデックスの生成といった操作が行われるため、この段階で実行しています。  \n  \n関数では**AdjustedClose**という項目が生成されます。  \n株式は、分割や併合によって株価が大きく変動することがありますが、**Close**の代わりに**AdjustedClose**を使うことで、この影響を減少させることができるとのことです。","metadata":{}},{"cell_type":"code","source":"def adjust_price(price):\n    \"\"\"\n    Args:\n        price (pd.DataFrame)  : pd.DataFrame include stock_price\n    Returns:\n        price DataFrame (pd.DataFrame): stock_price with generated AdjustedClose\n    \"\"\"\n    # transform Date column into datetime\n    price.loc[: ,\"Date\"] = pd.to_datetime(price.loc[: ,\"Date\"], format=\"%Y-%m-%d\")\n\n    def generate_adjusted_close(df):\n        \"\"\"\n        Args:\n            df (pd.DataFrame)  : stock_price for a single SecuritiesCode\n        Returns:\n            df (pd.DataFrame): stock_price with AdjustedClose for a single SecuritiesCode\n        \"\"\"\n        # sort data to generate CumulativeAdjustmentFactor\n        df = df.sort_values(\"Date\", ascending=False)\n        # generate CumulativeAdjustmentFactor\n        df.loc[:, \"CumulativeAdjustmentFactor\"] = df[\"AdjustmentFactor\"].cumprod()\n        # generate AdjustedClose\n        df.loc[:, \"AdjustedClose\"] = (\n            df[\"CumulativeAdjustmentFactor\"] * df[\"Close\"]\n        ).map(lambda x: float(\n            Decimal(str(x)).quantize(Decimal('0.1'), rounding=ROUND_HALF_UP)\n        ))\n        # reverse order\n        df = df.sort_values(\"Date\")\n        # to fill AdjustedClose, replace 0 into np.nan\n        df.loc[df[\"AdjustedClose\"] == 0, \"AdjustedClose\"] = np.nan\n        # forward fill AdjustedClose\n        df.loc[:, \"AdjustedClose\"] = df.loc[:, \"AdjustedClose\"].ffill()\n        return df\n\n    # generate AdjustedClose\n    price = price.sort_values([\"SecuritiesCode\", \"Date\"])\n    price = price.groupby(\"SecuritiesCode\").apply(generate_adjusted_close).reset_index(drop=True)\n\n    # price.set_index(\"Date\", inplace=True)\n    return price","metadata":{"execution":{"iopub.status.busy":"2022-04-09T15:01:38.737671Z","iopub.execute_input":"2022-04-09T15:01:38.738208Z","iopub.status.idle":"2022-04-09T15:01:38.752928Z","shell.execute_reply.started":"2022-04-09T15:01:38.738168Z","shell.execute_reply":"2022-04-09T15:01:38.751861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def collector(prices, options, financials, trades, secondary_prices, stock_list):\n    # 読み込んだデータを統合して一つのファイルに纏める\n    base_df = merge_data(prices, options, financials, trades, secondary_prices, stock_list)\n    # AdjustedClose項目の生成\n    base_df = adjust_price(base_df)\n    \n    return base_df","metadata":{"execution":{"iopub.status.busy":"2022-04-09T15:01:38.754382Z","iopub.execute_input":"2022-04-09T15:01:38.755047Z","iopub.status.idle":"2022-04-09T15:01:38.769494Z","shell.execute_reply.started":"2022-04-09T15:01:38.754936Z","shell.execute_reply":"2022-04-09T15:01:38.768722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exec","metadata":{}},{"cell_type":"markdown","source":"supplemental filesを使わない場合は4行目以降をコメントアウトします。","metadata":{}},{"cell_type":"code","source":"%%time\n\nbase_df = collector(*train_files, stock_list)\nsupplemental_df = collector(*supplemental_files, stock_list)\nbase_df = pd.concat([base_df, supplemental_df]).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T15:01:38.770711Z","iopub.execute_input":"2022-04-09T15:01:38.771315Z","iopub.status.idle":"2022-04-09T15:02:20.259448Z","shell.execute_reply.started":"2022-04-09T15:01:38.771276Z","shell.execute_reply":"2022-04-09T15:02:20.258352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 特徴量エンジニアリング\n\n特徴量を生成し、推論結果の精度向上に貢献するものだけを選びます。  ","metadata":{}},{"cell_type":"markdown","source":"## Function\n\n`calc_change_rate_base`関数と`calc_volatility_base`関数は、[Train Demo](https://www.kaggle.com/code/smeitoma/train-demo)で紹介されていた関数を参考にしています。","metadata":{}},{"cell_type":"code","source":"# 「column_name で指定された項目の、periodsで指定された期間（複数）での変化率を導出し、項目として追加する関数」を生成する関数\n# 生成された関数は、特定証券コードだけを持つデータフレームが入力されることを前提としている。\ndef calc_change_rate_base(column_name, periods):\n    def func(price):\n        for period in periods:\n            price.loc[:, f\"{column_name}_change_rate_{period}\"] = price[column_name].pct_change(period)\n        return price\n    return func\n\n\n# 「column_name で指定された項目の、periodsで指定された期間（複数）での変動の度合いを導出し、項目として追加する関数」を生成する関数\n# 生成された関数は、特定証券コードだけを持つデータフレームが入力されることを前提としている。\ndef calc_volatility_base(column_name, periods):\n    def func(price):\n        for period in periods:\n            price.loc[:, f\"{column_name}_volatility_{period}\"] = np.log(price[column_name]).diff().rolling(window=period, min_periods=1).std()\n        return price\n    return func\n\n# 「column_name で指定された項目の、periodsで指定された期間（複数）での移動平均値と現在値の比率を導出し、項目として追加する関数」を生成する関数\n# 移動平均値そのものではなく、現在値に対する比率としているのは、今回のTargetが比率であるため。\n# 生成された関数は、特定証券コードだけを持つデータフレームが入力されることを前提としている。\ndef calc_moving_average_rate_base(column_name, periods):\n    def func(price):\n        for period in periods:\n            price.loc[:, f\"{column_name}_average_rate_{period}\"] = price[column_name].rolling(window=period, min_periods=1).mean() / price[column_name]\n        return price\n    return func\n\n# 終値の変動率を生成し、項目として追加する関数。これをShift-2するとTargetになる。\n# この関数は、特定証券コードだけを持つデータフレームが入力されることを前提としている。\ndef calc_target_shift2(price):\n    price.loc[:, 'Target_shift2'] = price['Close'].pct_change()\n    return price\n\n# 入力データフレームを証券コード毎にグルーピングし、引数で渡された関数を適用する関数\n# functionsには↑で定義したcalc_xxxの関数のリストが渡される想定。\ndef add_columns_per_code(price, functions):\n    def func(df):\n        for f in functions:\n            df = f(df)\n        return df\n    price = price.sort_values([\"SecuritiesCode\", \"Date\"])\n    price = price.groupby(\"SecuritiesCode\").apply(func)\n    price = price.reset_index(drop=True)\n    return price\n\n# 入力データフレームに特徴量を追加する関数\n# 追加する項目は、基本的にレコード内の値だけを使う想定\ndef add_columns_per_day(base_df):\n    base_df['diff_rate1'] = (base_df['Close'] - base_df['Open']) / base_df['Close']\n    base_df['diff_rate2'] = (base_df['High'] - base_df['Low']) / base_df['Close']    \n    return base_df\n\n# 入力データフレームに特徴量を追加する関数\ndef generate_features(base_df):\n    prev_column_names = base_df.columns\n    \n    periods = [3, 9]\n    functions = [\n        calc_change_rate_base(\"AdjustedClose\", periods), \n        calc_volatility_base(\"AdjustedClose\", periods), \n        calc_moving_average_rate_base(\"Volume\", periods), \n        calc_target_shift2\n    ]\n    \n    # 証券コード単位の特徴量（移動平均等、一定期間のレコードをインプットに生成する特徴量）を追加\n    base_df = add_columns_per_code(base_df, functions)\n    # 日単位の特徴量（レコード内の値で導出できる特徴量）を追加\n    base_df = add_columns_per_day(base_df)\n    \n    # 後で特徴量を選択しやすくするため、追加した項目名のリストを生成\n    add_column_names = list(set(base_df.columns) - set(prev_column_names))\n    return base_df, add_column_names","metadata":{"execution":{"iopub.status.busy":"2022-04-09T15:02:20.261678Z","iopub.execute_input":"2022-04-09T15:02:20.262009Z","iopub.status.idle":"2022-04-09T15:02:20.277726Z","shell.execute_reply.started":"2022-04-09T15:02:20.261961Z","shell.execute_reply":"2022-04-09T15:02:20.27672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 特徴量選択\ndef select_features(feature_df, add_column_names, is_train):\n    # 基本項目\n    base_cols = ['RowId', 'Date', 'SecuritiesCode']\n    # 数値系の特徴量\n    numerical_cols = sorted(add_column_names)\n    # カテゴリ系の特徴量\n    categorical_cols = ['NewMarketSegment', '33SectorCode', '17SectorCode']\n    # 目的変数\n    label_col = ['Target']\n    \n    # 特徴量\n    feat_cols = numerical_cols + categorical_cols\n\n    # データフレームの項目を選択された項目だけに絞込\n    feature_df = feature_df[base_cols + feat_cols + label_col]\n    # カテゴリ系項目はdtypeをcategoryに変更\n    feature_df[categorical_cols] = feature_df[categorical_cols].astype('category')\n\n    if is_train:\n        # 学習データの場合は、NA項目があるレコードを削除\n        feature_df.dropna(inplace=True)\n    else:\n        # 推論データの場合は、NA項目を補完\n        feature_df[numerical_cols] = feature_df[numerical_cols].fillna(0)\n        feature_df[numerical_cols] = feature_df[numerical_cols].replace([np.inf, -np.inf], 0)\n    \n    return feature_df, feat_cols, label_col","metadata":{"execution":{"iopub.status.busy":"2022-04-09T15:02:20.279107Z","iopub.execute_input":"2022-04-09T15:02:20.279972Z","iopub.status.idle":"2022-04-09T15:02:20.295121Z","shell.execute_reply.started":"2022-04-09T15:02:20.279929Z","shell.execute_reply":"2022-04-09T15:02:20.294016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocessor(base_df, is_train=True):\n    feature_df = base_df.copy()\n    \n    ## 特徴量生成\n    feature_df, add_column_names = generate_features(feature_df)\n    \n    ## 特徴量選択\n    feature_df, feat_cols, label_col = select_features(feature_df, add_column_names, is_train)\n\n    return feature_df, feat_cols, label_col","metadata":{"execution":{"iopub.status.busy":"2022-04-09T15:02:20.299521Z","iopub.execute_input":"2022-04-09T15:02:20.299806Z","iopub.status.idle":"2022-04-09T15:02:20.306102Z","shell.execute_reply.started":"2022-04-09T15:02:20.299775Z","shell.execute_reply":"2022-04-09T15:02:20.30515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exec","metadata":{}},{"cell_type":"code","source":"%%time\n\nfeature_df, feat_cols, label_col = preprocessor(base_df)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T15:02:20.307158Z","iopub.execute_input":"2022-04-09T15:02:20.307482Z","iopub.status.idle":"2022-04-09T15:02:45.341409Z","shell.execute_reply.started":"2022-04-09T15:02:20.307451Z","shell.execute_reply":"2022-04-09T15:02:45.339917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 学習","metadata":{}},{"cell_type":"markdown","source":"## Function","metadata":{}},{"cell_type":"markdown","source":"学習を行いモデルを生成します","metadata":{}},{"cell_type":"code","source":"# 予測値を降順に並べて順位番号を振る関数\n# 言い換えると、目的変数から提出用項目を導出する関数\ndef add_rank(df, col_name=\"pred\"):\n    df[\"Rank\"] = df.groupby(\"Date\")[col_name].rank(ascending=False, method=\"first\") - 1 \n    df[\"Rank\"] = df[\"Rank\"].astype(\"int\")\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-04-09T15:02:45.342687Z","iopub.execute_input":"2022-04-09T15:02:45.34289Z","iopub.status.idle":"2022-04-09T15:02:45.34794Z","shell.execute_reply.started":"2022-04-09T15:02:45.342864Z","shell.execute_reply":"2022-04-09T15:02:45.347021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`calc_spread_return_sharpe`関数は[Train Demo](https://www.kaggle.com/code/smeitoma/train-demo)で紹介されている関数をそのまま使わせて頂いています。  \n推論した**Rank**と、正解の**Target**を含むデータフレームを渡すと、コンテストの評価方法に沿ったスコアを計算してくれます。","metadata":{}},{"cell_type":"code","source":"def calc_spread_return_sharpe(df: pd.DataFrame, portfolio_size: int = 200, toprank_weight_ratio: float = 2) -> float:\n    \"\"\"\n    Args:\n        df (pd.DataFrame): predicted results\n        portfolio_size (int): # of equities to buy/sell\n        toprank_weight_ratio (float): the relative weight of the most highly ranked stock compared to the least.\n    Returns:\n        (float): sharpe ratio\n    \"\"\"\n    def _calc_spread_return_per_day(df, portfolio_size, toprank_weight_ratio):\n        \"\"\"\n        Args:\n            df (pd.DataFrame): predicted results\n            portfolio_size (int): # of equities to buy/sell\n            toprank_weight_ratio (float): the relative weight of the most highly ranked stock compared to the least.\n        Returns:\n            (float): spread return\n        \"\"\"\n        assert df['Rank'].min() == 0\n        assert df['Rank'].max() == len(df['Rank']) - 1\n        weights = np.linspace(start=toprank_weight_ratio, stop=1, num=portfolio_size)\n        purchase = (df.sort_values(by='Rank')['Target'][:portfolio_size] * weights).sum() / weights.mean()\n        short = (df.sort_values(by='Rank', ascending=False)['Target'][:portfolio_size] * weights).sum() / weights.mean()\n        return purchase - short\n\n    buf = df.groupby('Date').apply(_calc_spread_return_per_day, portfolio_size, toprank_weight_ratio)\n    sharpe_ratio = buf.mean() / buf.std()\n    return sharpe_ratio","metadata":{"execution":{"iopub.status.busy":"2022-04-09T15:02:45.349386Z","iopub.execute_input":"2022-04-09T15:02:45.349593Z","iopub.status.idle":"2022-04-09T15:02:45.363168Z","shell.execute_reply.started":"2022-04-09T15:02:45.34957Z","shell.execute_reply":"2022-04-09T15:02:45.362318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 予測用のデータフレームと、予測結果をもとに、スコアを計算する関数\ndef evaluator(df, pred):\n    df[\"pred\"] = pred\n    df = add_rank(df)\n    score = calc_spread_return_sharpe(df)\n    return score","metadata":{"execution":{"iopub.status.busy":"2022-04-09T15:02:45.364705Z","iopub.execute_input":"2022-04-09T15:02:45.365322Z","iopub.status.idle":"2022-04-09T15:02:45.374184Z","shell.execute_reply.started":"2022-04-09T15:02:45.365282Z","shell.execute_reply":"2022-04-09T15:02:45.373557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`lightgbm`ではなく`optuna.integration.lightgbm`をimportすることで、パイパーパラメータチューニングが実行されるようになります。","metadata":{}},{"cell_type":"code","source":"import lightgbm as lgb\n# import optuna.integration.lightgbm as lgb\n\n# 学習を実行する関数\ndef trainer(feature_df, feat_cols, label_col, fold_params, seed=2022):\n    scores = []\n    models = []\n    params = []\n\n    for param in fold_params:\n        ################################\n        # データ準備\n        ################################\n        train = feature_df[(param[0] <= feature_df['Date']) & (feature_df['Date'] < param[1])]\n        valid = feature_df[(param[1] <= feature_df['Date']) & (feature_df['Date'] < param[2])]\n\n        X_train = train[feat_cols]\n        y_train = train[label_col]\n        X_valid = valid[feat_cols]\n        y_valid = valid[label_col]\n        \n        lgb_train = lgb.Dataset(X_train, y_train)\n        lgb_valid = lgb.Dataset(X_valid, y_valid, reference=lgb_train)\n\n        ################################\n        # 学習\n        ################################\n        params = {\n            'task': 'train',                   # 学習\n            'boosting_type': 'gbdt',           # GBDT\n            'objective': 'regression',         # 回帰\n            'metric': 'rmse',                  # 損失（誤差）\n            'learning_rate': 0.01,             # 学習率\n            'lambda_l1': 0.5,                  # L1正則化項の係数\n            'lambda_l2': 0.5,                  # L2正則化項の係数\n            'num_leaves': 10,                  # 最大葉枚数\n            'feature_fraction': 0.5,           # ランダムに抽出される列の割合\n            'bagging_fraction': 0.5,           # ランダムに抽出される標本の割合\n            'bagging_freq': 5,                 # バギング実施頻度\n            'min_child_samples': 10,           # 葉に含まれる最小データ数\n            'seed': seed                       # シード値\n        } \n \n        lgb_results = {}                       \n        model = lgb.train( \n            params,                            # ハイパーパラメータ\n            lgb_train,                         # 訓練データ\n            valid_sets=[lgb_train, lgb_valid], # 検証データ\n            valid_names=['Train', 'Valid'],    # データセット名前\n            num_boost_round=2000,              # 計算回数\n            early_stopping_rounds=100,         # 計算打ち切り設定\n            evals_result=lgb_results,          # 学習の履歴\n            verbose_eval=100,                  # 学習過程の表示サイクル\n        )  \n\n        ################################\n        # 結果描画\n        ################################\n        fig = plt.figure(figsize=(10, 4))\n\n        # loss\n        plt.subplot(1,2,1)\n        loss_train = lgb_results['Train']['rmse']\n        loss_test = lgb_results['Valid']['rmse']   \n        plt.xlabel('Iteration')\n        plt.ylabel('logloss')\n        plt.plot(loss_train, label='train loss')\n        plt.plot(loss_test, label='valid loss')\n        plt.legend()\n\n        # feature importance\n        plt.subplot(1,2,2)\n        importance = pd.DataFrame({'feature':feat_cols, 'importance':model.feature_importance()})\n        sns.barplot(x = 'importance', y = 'feature', data = importance.sort_values('importance', ascending=False))\n\n        plt.tight_layout()\n        plt.show()\n\n        ################################\n        # 評価\n        ################################\n        # 推論\n        pred =  model.predict(X_valid, num_iteration=model.best_iteration)\n        # 評価\n        score = evaluator(valid, pred)\n\n        scores.append(score)\n        models.append(model)\n\n    print(\"CV_SCORES:\", scores)\n    print(\"CV_SCORE:\", np.mean(scores))\n    \n    return models","metadata":{"execution":{"iopub.status.busy":"2022-04-09T15:02:45.375253Z","iopub.execute_input":"2022-04-09T15:02:45.375992Z","iopub.status.idle":"2022-04-09T15:02:46.267068Z","shell.execute_reply.started":"2022-04-09T15:02:45.375959Z","shell.execute_reply":"2022-04-09T15:02:46.266313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exec","metadata":{}},{"cell_type":"code","source":"# 2020-12-23よりも前のデータは証券コードが2000個すべて揃っていないため、これ以降のデータのみを使う。\n# (学習用データの開始日、学習用データの終了日＝検証用データの開始日、検証用データの終了日)\nfold_params = [\n    ('2020-12-23', '2021-11-01', '2021-12-01'),\n    ('2021-01-23', '2021-12-01', '2022-01-01'),\n    ('2021-02-23', '2022-01-01', '2022-02-01'),\n]\nmodels = trainer(feature_df, feat_cols, label_col, fold_params)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T15:02:46.268547Z","iopub.execute_input":"2022-04-09T15:02:46.268834Z","iopub.status.idle":"2022-04-09T15:03:21.116031Z","shell.execute_reply.started":"2022-04-09T15:02:46.268797Z","shell.execute_reply":"2022-04-09T15:03:21.115192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 推論・評価","metadata":{}},{"cell_type":"markdown","source":"生成したモデルを使って試験用データの推論を行いスコアを算出します。","metadata":{}},{"cell_type":"markdown","source":"## Function","metadata":{}},{"cell_type":"code","source":"def predictor(feature_df, feat_cols, models, is_train=True):\n    X = feature_df[feat_cols]\n    \n    # 推論\n    preds = list(map(lambda model: model.predict(X, num_iteration=model.best_iteration), models))\n    \n    # スコアは学習時のみ計算\n    if is_train:\n        scores = list(map(lambda pred: evaluator(feature_df, pred), preds))\n        print(\"SCORES:\", scores)\n\n    # 推論結果をバギング\n    pred = np.array(preds).mean(axis=0)\n\n    # スコアは学習時のみ計算\n    if is_train:\n        score = evaluator(feature_df, pred)\n        print(\"SCORE:\", score)\n    \n    return pred","metadata":{"execution":{"iopub.status.busy":"2022-04-09T15:03:21.117483Z","iopub.execute_input":"2022-04-09T15:03:21.117706Z","iopub.status.idle":"2022-04-09T15:03:21.123394Z","shell.execute_reply.started":"2022-04-09T15:03:21.117677Z","shell.execute_reply":"2022-04-09T15:03:21.122461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exec","metadata":{}},{"cell_type":"code","source":"# 試験用データは学習用にも検証用にも使用していないものを使う\ntest_df = feature_df[('2022-02-01' <= feature_df['Date'])].copy()\npred = predictor(test_df, feat_cols, models)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T15:03:21.124452Z","iopub.execute_input":"2022-04-09T15:03:21.12495Z","iopub.status.idle":"2022-04-09T15:03:23.063226Z","shell.execute_reply.started":"2022-04-09T15:03:21.124921Z","shell.execute_reply":"2022-04-09T15:03:23.062322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 提出","metadata":{}},{"cell_type":"markdown","source":"時系列APIを使って推論結果を登録します。  \n特徴量として、移動平均等の過去データを参照する値を採用しているため、時系列APIから得られたデータをため込む仕組みを実装する必要があります。  \nこの仕組みに関しては、[Start-to-finish demo based on s-meitoma + tweaks](https://www.kaggle.com/code/lowellniles/start-to-finish-demo-based-on-s-meitoma-tweaks)を参考にさせていただきました。  \n以下のコードでは`past_df`というデータフレームに履歴データをため込む実装になっています。","metadata":{}},{"cell_type":"code","source":"# 時系列APIのロード\nimport jpx_tokyo_market_prediction\nenv = jpx_tokyo_market_prediction.make_env()\niter_test = env.iter_test()","metadata":{"execution":{"iopub.status.busy":"2022-04-09T15:03:23.064633Z","iopub.execute_input":"2022-04-09T15:03:23.06605Z","iopub.status.idle":"2022-04-09T15:03:23.090394Z","shell.execute_reply.started":"2022-04-09T15:03:23.066012Z","shell.execute_reply":"2022-04-09T15:03:23.089507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# supplemental filesを履歴データの初期状態としてセットアップ\npast_df = supplemental_df.copy()","metadata":{"execution":{"iopub.status.busy":"2022-04-09T15:03:23.09141Z","iopub.execute_input":"2022-04-09T15:03:23.091797Z","iopub.status.idle":"2022-04-09T15:03:23.107084Z","shell.execute_reply.started":"2022-04-09T15:03:23.091767Z","shell.execute_reply":"2022-04-09T15:03:23.106423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 日次で推論・登録\nfor i, (prices, options, financials, trades, secondary_prices, sample_prediction) in enumerate(iter_test):\n    current_date = prices[\"Date\"].iloc[0]\n\n    if i == 0:\n        # リークを防止するため、時系列APIから受け取ったデータより未来のデータを削除\n        past_df = past_df[past_df[\"Date\"] < current_date]\n\n    # リソース確保のため古い履歴を削除\n    threshold = (pd.Timestamp(current_date) - pd.offsets.BDay(80)).strftime(\"%Y-%m-%d\")\n    past_df = past_df[past_df[\"Date\"] >= threshold]\n    \n    # 時系列APIから受け取ったデータを履歴データに統合\n    base_df = collector(prices, options, financials, trades, secondary_prices, stock_list)\n    past_df = pd.concat([past_df, base_df]).reset_index(drop=True)\n\n    # 特徴量エンジニアリング\n    feature_df, feat_cols, label_col = preprocessor(past_df, False)\n\n    # 予測対象レコードだけを抽出\n    feature_df = feature_df[feature_df['Date'] == current_date]\n\n    # 推論\n    feature_df[\"pred\"] = predictor(feature_df, feat_cols, models, False)\n\n    # 推論結果からRANKを導出し、提出データに反映\n    feature_df = add_rank(feature_df)\n    feature_map = feature_df.set_index('SecuritiesCode')['Rank'].to_dict()\n    sample_prediction['Rank'] = sample_prediction['SecuritiesCode'].map(feature_map)\n\n    # 結果を登録\n    env.predict(sample_prediction)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T15:03:23.108113Z","iopub.execute_input":"2022-04-09T15:03:23.108581Z","iopub.status.idle":"2022-04-09T15:04:09.532816Z","shell.execute_reply.started":"2022-04-09T15:03:23.108548Z","shell.execute_reply":"2022-04-09T15:04:09.531925Z"},"trusted":true},"execution_count":null,"outputs":[]}]}