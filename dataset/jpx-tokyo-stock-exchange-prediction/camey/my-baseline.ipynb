{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-27T05:40:31.084763Z","iopub.execute_input":"2022-06-27T05:40:31.085302Z","iopub.status.idle":"2022-06-27T05:40:31.138778Z","shell.execute_reply.started":"2022-06-27T05:40:31.085179Z","shell.execute_reply":"2022-06-27T05:40:31.137594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install ta","metadata":{"execution":{"iopub.status.busy":"2022-06-27T05:40:35.499731Z","iopub.execute_input":"2022-06-27T05:40:35.50034Z","iopub.status.idle":"2022-06-27T05:40:51.768465Z","shell.execute_reply.started":"2022-06-27T05:40:35.500303Z","shell.execute_reply":"2022-06-27T05:40:51.767018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import required package\nimport ta\nfrom decimal import ROUND_HALF_UP, Decimal\nfrom tqdm import tqdm\n","metadata":{"execution":{"iopub.status.busy":"2022-06-27T05:41:00.52334Z","iopub.execute_input":"2022-06-27T05:41:00.523722Z","iopub.status.idle":"2022-06-27T05:41:00.544009Z","shell.execute_reply.started":"2022-06-27T05:41:00.523691Z","shell.execute_reply":"2022-06-27T05:41:00.542939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set base_dir to load data\nbase_dir = \"../input/jpx-tokyo-stock-exchange-prediction\"\n# There are three types of stock_price.csv\n# We use one in the train_files folder for this notebook.\ntrain_files_dir = f\"{base_dir}/train_files\"","metadata":{"execution":{"iopub.status.busy":"2022-06-27T05:41:02.446114Z","iopub.execute_input":"2022-06-27T05:41:02.446589Z","iopub.status.idle":"2022-06-27T05:41:02.453446Z","shell.execute_reply.started":"2022-06-27T05:41:02.446553Z","shell.execute_reply":"2022-06-27T05:41:02.451836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\nimport pandas as pd\ndef save_pickle_file(path,data):\n    pkl_file = open(path, 'wb')\n    pickle.dump(data, pkl_file, protocol = 4)\n    pkl_file.close()\ndef load_pickle_file(path):\n    pkl_file = open(path, 'rb')\n    data = pickle.load(pkl_file)\n    pkl_file.close()\n    return data","metadata":{"execution":{"iopub.status.busy":"2022-06-27T05:41:08.491513Z","iopub.execute_input":"2022-06-27T05:41:08.491984Z","iopub.status.idle":"2022-06-27T05:41:08.500856Z","shell.execute_reply.started":"2022-06-27T05:41:08.491949Z","shell.execute_reply":"2022-06-27T05:41:08.499257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1、Adjust price","metadata":{}},{"cell_type":"code","source":"def adjust_price(price):\n    \"\"\"\n    Args:\n        price (pd.DataFrame)  : pd.DataFrame include stock_price\n    Returns:\n        price DataFrame (pd.DataFrame): stock_price with generated AdjustedClose\n    \"\"\"\n    # transform Date column into datetime\n    price.loc[: ,\"Date\"] = pd.to_datetime(price.loc[: ,\"Date\"], format=\"%Y-%m-%d\")\n\n    def generate_adjusted_close(df):\n        \"\"\"\n        Args:\n            df (pd.DataFrame)  : stock_price for a single SecuritiesCode\n        Returns:\n            df (pd.DataFrame): stock_price with AdjustedClose for a single SecuritiesCode\n        \"\"\"\n        # sort data to generate CumulativeAdjustmentFactor\n        df = df.sort_values(\"Date\", ascending=False)\n        # generate CumulativeAdjustmentFactor\n        df.loc[:, \"CumulativeAdjustmentFactor\"] = df[\"AdjustmentFactor\"].cumprod()\n        # generate AdjustedClose\n        df.loc[:, \"AdjustedClose\"] = (\n            df[\"CumulativeAdjustmentFactor\"] * df[\"Close\"]\n        ).map(lambda x: float(\n            Decimal(str(x)).quantize(Decimal('0.1'), rounding=ROUND_HALF_UP)\n        ))\n        # reverse order\n        df = df.sort_values(\"Date\")\n        # to fill AdjustedClose, replace 0 into np.nan\n        df.loc[df[\"AdjustedClose\"] == 0, \"AdjustedClose\"] = np.nan\n        # forward fill AdjustedClose\n        df.loc[:, \"AdjustedClose\"] = df.loc[:, \"AdjustedClose\"].ffill()\n        return df\n\n    # generate AdjustedClose\n    price = price.sort_values([\"SecuritiesCode\", \"Date\"])\n    price = price.groupby(\"SecuritiesCode\").apply(generate_adjusted_close).reset_index(drop=True)\n\n    price.set_index(\"Date\", inplace=True)\n    return price","metadata":{"execution":{"iopub.status.busy":"2022-06-27T05:41:11.865332Z","iopub.execute_input":"2022-06-27T05:41:11.865763Z","iopub.status.idle":"2022-06-27T05:41:11.879269Z","shell.execute_reply.started":"2022-06-27T05:41:11.865727Z","shell.execute_reply":"2022-06-27T05:41:11.878066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load stock price data\ndf_price = pd.read_csv(f\"{train_files_dir}/stock_prices.csv\")\ndf_price.head(5)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-27T05:41:19.465871Z","iopub.execute_input":"2022-06-27T05:41:19.466541Z","iopub.status.idle":"2022-06-27T05:41:26.653485Z","shell.execute_reply.started":"2022-06-27T05:41:19.466508Z","shell.execute_reply":"2022-06-27T05:41:26.652007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# generate AdjustedClose\ndf_price = adjust_price(df_price)\ndf_price.head(5)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-27T05:41:30.094844Z","iopub.execute_input":"2022-06-27T05:41:30.095323Z","iopub.status.idle":"2022-06-27T05:41:53.946285Z","shell.execute_reply.started":"2022-06-27T05:41:30.095286Z","shell.execute_reply":"2022-06-27T05:41:53.945061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_price.info()","metadata":{"execution":{"iopub.status.busy":"2022-06-27T05:41:58.884737Z","iopub.execute_input":"2022-06-27T05:41:58.885202Z","iopub.status.idle":"2022-06-27T05:41:58.941383Z","shell.execute_reply.started":"2022-06-27T05:41:58.885165Z","shell.execute_reply":"2022-06-27T05:41:58.939978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"## 2、generate ta feat","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"from ta import add_all_ta_features\nfrom ta.utils import dropna\nfrom sklearn.model_selection import TimeSeriesSplit","metadata":{"execution":{"iopub.status.busy":"2022-06-27T06:55:34.640551Z","iopub.execute_input":"2022-06-27T06:55:34.641017Z","iopub.status.idle":"2022-06-27T06:55:35.883477Z","shell.execute_reply.started":"2022-06-27T06:55:34.640983Z","shell.execute_reply":"2022-06-27T06:55:35.882256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_features_for_predict(price, code):\n    \"\"\"\n    Args:\n        price (pd.DataFrame)  : pd.DataFrame include stock_price\n        code (int)  : A local code for a listed company\n    Returns:\n        feature DataFrame (pd.DataFrame)\n    \"\"\"\n    close_col = \"AdjustedClose\"\n    feats = price.loc[price[\"SecuritiesCode\"] == code].copy()\n    \n    # Adds all 42 features\n    feats = ta.add_all_ta_features(\n        feats, \"Open\", \"High\", \"Low\", close_col, \"Volume\", fillna=False\n    )\n    \n    # To only add specific features\n    # Example: https://github.com/bukosabino/ta/blob/master/examples_to_use/bollinger_band_features_example.py\n    # df['bb_bbm'] = indicator_bb.bollinger_mavg()\n    # df['bb_bbh'] = indicator_bb.bollinger_hband()\n    # df['bb_bbl'] = indicator_bb.bollinger_lband()\n    \n    # filling data for nan and inf\n    feats = feats.fillna(0)\n    feats = feats.replace([np.inf, -np.inf], 0)\n    # drop AdjustedClose column\n    feats = feats.drop([close_col], axis=1)\n\n    return feats","metadata":{"execution":{"iopub.status.busy":"2022-06-27T05:42:12.203386Z","iopub.execute_input":"2022-06-27T05:42:12.204735Z","iopub.status.idle":"2022-06-27T05:42:12.217433Z","shell.execute_reply.started":"2022-06-27T05:42:12.204667Z","shell.execute_reply":"2022-06-27T05:42:12.215841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fetch prediction target SecuritiesCodes\ncodes = sorted(df_price[\"SecuritiesCode\"].unique())\nlen(codes)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T05:42:15.151296Z","iopub.execute_input":"2022-06-27T05:42:15.151817Z","iopub.status.idle":"2022-06-27T05:42:15.180794Z","shell.execute_reply.started":"2022-06-27T05:42:15.15178Z","shell.execute_reply":"2022-06-27T05:42:15.179353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generate feature\nbuff = []\nfor code in tqdm(codes):\n    feat = get_features_for_predict(df_price, code)\n    buff.append(feat)\nfeature = pd.concat(buff)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T05:43:06.016537Z","iopub.execute_input":"2022-06-27T05:43:06.017008Z","iopub.status.idle":"2022-06-27T06:02:41.239455Z","shell.execute_reply.started":"2022-06-27T05:43:06.01697Z","shell.execute_reply":"2022-06-27T06:02:41.237816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_pickle_file(\"/kaggle/working/feature.pkl\",feature)\n#feature = load_pickle_file(\"/kaggle/working/feature.pkl\")","metadata":{"execution":{"iopub.status.busy":"2022-06-27T06:03:12.770426Z","iopub.execute_input":"2022-06-27T06:03:12.771646Z","iopub.status.idle":"2022-06-27T06:03:20.439191Z","shell.execute_reply.started":"2022-06-27T06:03:12.771601Z","shell.execute_reply":"2022-06-27T06:03:20.438272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from IPython.display import FileLink\n# %cd /kaggle/working\n# FileLink(\"feature.pkl\")\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-27T06:28:51.709227Z","iopub.execute_input":"2022-06-27T06:28:51.709984Z","iopub.status.idle":"2022-06-27T06:28:51.71763Z","shell.execute_reply.started":"2022-06-27T06:28:51.709943Z","shell.execute_reply":"2022-06-27T06:28:51.716174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3、train","metadata":{}},{"cell_type":"code","source":"feature.index.value_counts().tail(500)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T07:24:57.345557Z","iopub.execute_input":"2022-06-27T07:24:57.345947Z","iopub.status.idle":"2022-06-27T07:24:57.406929Z","shell.execute_reply.started":"2022-06-27T07:24:57.345916Z","shell.execute_reply":"2022-06-27T07:24:57.405861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(feature.columns)\nfeature.head(5)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-27T07:12:07.259162Z","iopub.execute_input":"2022-06-27T07:12:07.259669Z","iopub.status.idle":"2022-06-27T07:12:07.298323Z","shell.execute_reply.started":"2022-06-27T07:12:07.25963Z","shell.execute_reply":"2022-06-27T07:12:07.296952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ts_fold = TimeSeriesSplit(n_splits=5, gap=10000)\nprices=feature.dropna().sort_values(['Date','SecuritiesCode'])\ny=prices['Target'].to_numpy()\nX=prices.drop(['Target'],axis=1)\nfeat_importance=pd.DataFrame()\nsharpe_ratio=[]\n\nfor fold, (train_idx, val_idx) in enumerate(ts_fold.split(X, y)):\n    \n    print(\"\\n========================== Fold {} ==========================\".format(fold+1))\n    X_train, y_train = X.iloc[train_idx,:], y[train_idx]\n    X_valid, y_val = X.iloc[val_idx,:], y[val_idx]\n    \n    print(\"Train Date range: {} to {}\".format(X_train.Date.min(),X_train.Date.max()))\n    print(\"Valid Date range: {} to {}\".format(X_valid.Date.min(),X_valid.Date.max()))\n    \n#     X_train.drop(['Date','SecuritiesCode'], axis=1, inplace=True)\n#     X_val=X_valid[X_valid.columns[~X_valid.columns.isin(['Date','SecuritiesCode'])]]\n#     val_dates=X_valid.Date.unique()[1:-1]\n#     print(\"\\nTrain Shape: {} {}, Valid Shape: {} {}\".format(X_train.shape, y_train.shape, X_val.shape, y_val.shape))\n    \n#     params = {'n_estimators': 500,\n#               'num_leaves' : 100,\n#               'learning_rate': 0.1,\n#               'colsample_bytree': 0.9,\n#               'subsample': 0.8,\n#               'reg_alpha': 0.4,\n#               'metric': 'mae',\n#               'random_state': 21}\n    \n#     gbm = LGBMRegressor(**params).fit(X_train, y_train, \n#                                       eval_set=[(X_train, y_train), (X_val, y_val)],\n#                                       verbose=300, \n#                                       eval_metric=['mae','mse'])\n#     y_pred = gbm.predict(X_val)\n#     rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n#     mae = mean_absolute_error(y_val, y_pred)\n#     feat_importance[\"Importance_Fold\"+str(fold)]=gbm.feature_importances_\n#     feat_importance.set_index(X_train.columns, inplace=True)\n    \n#     rank=[]\n#     X_val_df=X_valid[X_valid.Date.isin(val_dates)]\n#     for i in X_val_df.Date.unique():\n#         temp_df = X_val_df[X_val_df.Date == i].drop(['Date','SecuritiesCode'],axis=1)\n#         temp_df[\"pred\"] = gbm.predict(temp_df)\n#         temp_df[\"Rank\"] = (temp_df[\"pred\"].rank(method=\"first\", ascending=False)-1).astype(int)\n#         rank.append(temp_df[\"Rank\"].values)\n\n#     stock_rank=pd.Series([x for y in rank for x in y], name=\"Rank\")\n#     df=pd.concat([X_val_df.reset_index(drop=True),stock_rank,\n#                   prices[prices.Date.isin(val_dates)]['Target'].reset_index(drop=True)], axis=1)\n#     sharpe=calc_spread_return_sharpe(df)\n#     sharpe_ratio.append(sharpe)\n#     print(\"Valid Sharpe: {}, RMSE: {}, MAE: {}\".format(sharpe,rmse,mae))\n    \n#     del X_train, y_train,  X_val, y_val\n#     gc.collect()\n    \nprint(\"\\nAverage cross-validation Sharpe Ratio: {:.4f}, standard deviation = {:.2f}.\".format(np.mean(sharpe_ratio),np.std(sharpe_ratio)))\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-27T07:27:37.636345Z","iopub.execute_input":"2022-06-27T07:27:37.636881Z","iopub.status.idle":"2022-06-27T07:27:37.751047Z","shell.execute_reply.started":"2022-06-27T07:27:37.636774Z","shell.execute_reply":"2022-06-27T07:27:37.749651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#prices[:10][['RowId','SecuritiesCode','Target']]","metadata":{"execution":{"iopub.status.busy":"2022-06-27T07:01:26.01998Z","iopub.execute_input":"2022-06-27T07:01:26.020378Z","iopub.status.idle":"2022-06-27T07:01:26.035988Z","shell.execute_reply.started":"2022-06-27T07:01:26.020347Z","shell.execute_reply":"2022-06-27T07:01:26.03458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calc_spread_return_sharpe(df: pd.DataFrame, portfolio_size: int = 200, toprank_weight_ratio: float = 2) -> float:\n    \"\"\"\n    Args:\n        df (pd.DataFrame): predicted results\n        portfolio_size (int): # of equities to buy/sell\n        toprank_weight_ratio (float): the relative weight of the most highly ranked stock compared to the least.\n    Returns:\n        (float): sharpe ratio\n    \"\"\"\n    def _calc_spread_return_per_day(df, portfolio_size, toprank_weight_ratio):\n        \"\"\"\n        Args:\n            df (pd.DataFrame): predicted results\n            portfolio_size (int): # of equities to buy/sell\n            toprank_weight_ratio (float): the relative weight of the most highly ranked stock compared to the least.\n        Returns:\n            (float): spread return\n        \"\"\"\n        assert df['Rank'].min() == 0\n        assert df['Rank'].max() == len(df['Rank']) - 1\n        weights = np.linspace(start=toprank_weight_ratio, stop=1, num=portfolio_size)\n        purchase = (df.sort_values(by='Rank')['Target'][:portfolio_size] * weights).sum() / weights.mean()\n        short = (df.sort_values(by='Rank', ascending=False)['Target'][:portfolio_size] * weights).sum() / weights.mean()\n        return purchase - short\n\n    buf = df.groupby('Date').apply(_calc_spread_return_per_day, portfolio_size, toprank_weight_ratio)\n    sharpe_ratio = buf.mean() / buf.std()\n    return sharpe_ratio","metadata":{"execution":{"iopub.status.busy":"2022-06-27T07:03:25.439353Z","iopub.execute_input":"2022-06-27T07:03:25.439804Z","iopub.status.idle":"2022-06-27T07:03:25.451994Z","shell.execute_reply.started":"2022-06-27T07:03:25.43977Z","shell.execute_reply":"2022-06-27T07:03:25.450665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}