{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-10T10:53:24.338857Z","iopub.execute_input":"2022-06-10T10:53:24.339301Z","iopub.status.idle":"2022-06-10T10:53:24.376165Z","shell.execute_reply.started":"2022-06-10T10:53:24.339215Z","shell.execute_reply":"2022-06-10T10:53:24.3753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load stock prices CSV file, get useful features\ndf_prices = pd.read_csv('../input/jpx-tokyo-stock-exchange-prediction/train_files/stock_prices.csv')\ndf_stocks = df_prices[['AdjustmentFactor', 'Open', 'Close', 'High', 'Low', 'Volume', 'Date', 'SecuritiesCode', 'Target']].copy()\n\n# Convert Date column to datetime data type\ndf_stocks['Date'] = pd.to_datetime(df_stocks['Date'])\n\n# Remove missing data\ndf_stocks.dropna(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T10:53:24.377685Z","iopub.execute_input":"2022-06-10T10:53:24.378589Z","iopub.status.idle":"2022-06-10T10:53:28.775802Z","shell.execute_reply.started":"2022-06-10T10:53:24.378527Z","shell.execute_reply":"2022-06-10T10:53:28.774865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from decimal import ROUND_HALF_UP, Decimal\n\ndef adjust_price(price):\n    \"\"\"\n    Args:\n        price (pd.DataFrame)  : pd.DataFrame include stock_price\n    Returns:\n        price DataFrame (pd.DataFrame): stock_price with generated AdjustedClose\n    \"\"\"\n    # transform Date column into datetime\n    price.loc[: ,\"Date\"] = pd.to_datetime(price.loc[: ,\"Date\"], format=\"%Y-%m-%d\")\n\n    def generate_adjusted_close(df):\n        \"\"\"\n        Args:\n            df (pd.DataFrame)  : stock_price for a single SecuritiesCode\n        Returns:\n            df (pd.DataFrame): stock_price with AdjustedClose for a single SecuritiesCode\n        \"\"\"\n        # sort data to generate CumulativeAdjustmentFactor\n        df = df.sort_values(\"Date\", ascending=False)\n        # generate CumulativeAdjustmentFactor\n        df.loc[:, \"CumulativeAdjustmentFactor\"] = df[\"AdjustmentFactor\"].cumprod()\n        # generate AdjustedClose\n        df.loc[:, \"AdjustedClose\"] = (\n            df[\"CumulativeAdjustmentFactor\"] * df[\"Close\"]\n        ).map(lambda x: float(\n            Decimal(str(x)).quantize(Decimal('0.1'), rounding=ROUND_HALF_UP)\n        ))\n        # reverse order\n        df = df.sort_values(\"Date\")\n        # to fill AdjustedClose, replace 0 into np.nan\n        df.loc[df[\"AdjustedClose\"] == 0, \"AdjustedClose\"] = np.nan\n        # forward fill AdjustedClose\n        df.loc[:, \"AdjustedClose\"] = df.loc[:, \"AdjustedClose\"].ffill()\n        return df\n\n    # generate AdjustedClose\n    price = price.sort_values([\"SecuritiesCode\", \"Date\"])\n    price = price.groupby(\"SecuritiesCode\").apply(generate_adjusted_close).reset_index(drop=True)\n\n    price.set_index(\"Date\", inplace=True, drop=False)\n    return price\n\ndf_stocks = adjust_price(df_stocks) \ndf_stocks.drop(columns=['AdjustmentFactor', 'CumulativeAdjustmentFactor'], inplace=True)\ndf_stocks['Close'] = df_stocks['AdjustedClose'].copy(deep=True)\ndf_stocks.drop(columns=['AdjustedClose'], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T10:53:28.777301Z","iopub.execute_input":"2022-06-10T10:53:28.778101Z","iopub.status.idle":"2022-06-10T10:53:44.279679Z","shell.execute_reply.started":"2022-06-10T10:53:28.778062Z","shell.execute_reply":"2022-06-10T10:53:44.278636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\n# normalize open and close prices\nss = StandardScaler()\ndf_stocks[['Open', 'Close',  'High', 'Low', 'Volume']] = ss.fit_transform(df_stocks[['Open', 'Close', 'High', 'Low', 'Volume']])","metadata":{"execution":{"iopub.status.busy":"2022-06-10T10:53:44.28211Z","iopub.execute_input":"2022-06-10T10:53:44.282676Z","iopub.status.idle":"2022-06-10T10:53:45.096645Z","shell.execute_reply.started":"2022-06-10T10:53:44.282631Z","shell.execute_reply":"2022-06-10T10:53:45.095616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create data frame for each stock\ndf_stock = []\nfor id_val in df_prices['SecuritiesCode'].unique():\n    df_stock.append(df_stocks.loc[(df_stocks['SecuritiesCode'] == id_val)])","metadata":{"execution":{"iopub.status.busy":"2022-06-10T10:53:45.098962Z","iopub.execute_input":"2022-06-10T10:53:45.099738Z","iopub.status.idle":"2022-06-10T10:53:51.907714Z","shell.execute_reply.started":"2022-06-10T10:53:45.099692Z","shell.execute_reply":"2022-06-10T10:53:51.906712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create list of time step columns\ndef create_column_list(time_steps, features):\n\n    cols = []\n    for feature in features:\n        for ii in range(0, time_steps+1):\n            cols.append(feature+str(ii))\n\n    return cols\n\n# Shift to create time-series data format dataframe for each stock\ndef shift_reorder(df_stock, time_steps, features, other_cols):\n    \n    cols = create_column_list(time_steps, features)\n    for col in other_cols:\n        cols.append(col)\n        \n    print(cols)\n    \n    for ii in range(len(df_stock)):\n        for feature in features:\n            df_stock[ii] = df_stock[ii].rename(columns={feature: feature+str(time_steps)})\n\n            for jj in range(time_steps):\n                df_stock[ii][feature+str(time_steps-jj-1)] = df_stock[ii][feature+str(time_steps-jj)].shift(periods=1, fill_value=np.NaN)\n        \n            # reorder columns\n        df_stock[ii] = df_stock[ii][cols].copy(deep=True) \n\ntime_steps = 8\n\n# create shifted time-series format dataframes\nfeats = ['Open', 'Close', 'High', 'Low', 'Volume']\nothers = ['Date', 'SecuritiesCode', 'Target']\n\nshift_reorder(df_stock, time_steps, features=feats, other_cols=others)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T10:53:51.909389Z","iopub.execute_input":"2022-06-10T10:53:51.909931Z","iopub.status.idle":"2022-06-10T10:54:43.974774Z","shell.execute_reply.started":"2022-06-10T10:53:51.909892Z","shell.execute_reply":"2022-06-10T10:54:43.973936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# add stock list information to each security - from https://www.kaggle.com/code/kellibelcher/jpx-stock-market-analysis-prediction-with-lgbm\ndf_stock_list = pd.read_csv('../input/jpx-tokyo-stock-exchange-prediction/stock_list.csv')\n\ndef add_sl_features(stocks, stock_list):\n    stock_list['SectorName17']=[i.rstrip().lower().capitalize() for i in stock_list['17SectorName']]\n    stock_list['SectorName33']=[i.rstrip().lower().capitalize() for i in stock_list['33SectorName']]\n    stock_list['SectionProducts']=[i.rstrip().lower().capitalize() for i in stock_list['Section/Products']]\n    \n    for ii in range(len(stocks)):\n        code = stocks[ii]['SecuritiesCode'].unique()[0]\n        stocks[ii] = stocks[ii].assign(SectorName17=stock_list.loc[stock_list['SecuritiesCode'] == code]['SectorName17'].unique()[0])\n        stocks[ii] = stocks[ii].assign(SectorName33=stock_list.loc[stock_list['SecuritiesCode'] == code]['SectorName33'].unique()[0])\n        stocks[ii] = stocks[ii].assign(SectionProducts=stock_list.loc[stock_list['SecuritiesCode'] == code]['SectionProducts'].unique()[0])\n        stocks[ii] = stocks[ii].assign(NewMarketSegment=stock_list.loc[stock_list['SecuritiesCode'] == code]['NewMarketSegment'].unique()[0])\n\nadd_sl_features(df_stock, df_stock_list)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T10:54:43.976147Z","iopub.execute_input":"2022-06-10T10:54:43.976521Z","iopub.status.idle":"2022-06-10T10:54:54.399578Z","shell.execute_reply.started":"2022-06-10T10:54:43.976486Z","shell.execute_reply":"2022-06-10T10:54:54.398721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# join data from each stock into one dataframe\ndf_stock_full = pd.concat(df_stock)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T10:54:54.400876Z","iopub.execute_input":"2022-06-10T10:54:54.401245Z","iopub.status.idle":"2022-06-10T10:54:56.566351Z","shell.execute_reply.started":"2022-06-10T10:54:54.40121Z","shell.execute_reply":"2022-06-10T10:54:56.565487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import datetime as dt\n\n# from https://analyticsindiamag.com/how-to-use-xgboost-for-time-series-analysis/\ndef create_time_features(dataframe):\n\n    date_column = dataframe['Date'].copy()\n    \n    dataframe['hour'] = date_column.dt.hour\n    dataframe['dayofweek'] = date_column.dt.dayofweek\n    dataframe['quarter'] = date_column.dt.quarter\n    dataframe['month'] = date_column.dt.month\n    dataframe['year'] = date_column.dt.year\n    dataframe['dayofyear'] = date_column.dt.dayofyear\n    dataframe['dayofmonth'] = date_column.dt.day\n\n# create features from datetime values\ncreate_time_features(df_stock_full)\n\n# drop date feature\ndf_stock_full.drop(columns=['Date'], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T10:54:56.5677Z","iopub.execute_input":"2022-06-10T10:54:56.568653Z","iopub.status.idle":"2022-06-10T10:54:59.149579Z","shell.execute_reply.started":"2022-06-10T10:54:56.568614Z","shell.execute_reply":"2022-06-10T10:54:59.148728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create dummy variables for categorical features\ndf_stock_full = pd.get_dummies(df_stock_full, dummy_na=True, columns=['SectorName17', 'SectorName33', 'SectionProducts', 'NewMarketSegment'], drop_first=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T10:54:59.152059Z","iopub.execute_input":"2022-06-10T10:54:59.152615Z","iopub.status.idle":"2022-06-10T10:55:01.552402Z","shell.execute_reply.started":"2022-06-10T10:54:59.152576Z","shell.execute_reply":"2022-06-10T10:55:01.551545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport xgboost as xgb\n\ndef split_train_target(stocks):\n\n    df_target = stocks[['Target']].copy(deep=True)\n    df_train = stocks.drop(columns=['Target'], axis=0)\n\n    return df_train, df_target\n\n# define training set and target\ndf_stock_train, df_stock_target = split_train_target(df_stock_full)\n\n# train-test split\nX_train, X_valid, y_train, y_valid = train_test_split(df_stock_train, df_stock_target, test_size = 0.2, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T10:55:01.558879Z","iopub.execute_input":"2022-06-10T10:55:01.561766Z","iopub.status.idle":"2022-06-10T10:55:05.443151Z","shell.execute_reply.started":"2022-06-10T10:55:01.561726Z","shell.execute_reply":"2022-06-10T10:55:05.442225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from scipy.stats import uniform\n#from sklearn.model_selection import RandomizedSearchCV\n\n\n## Searching for regularization parameters\n#distributions = {'alpha': uniform(loc=0.1, scale=100),\n#                 'gamma': uniform(loc=0.1, scale=20),\n#                 'lambda': uniform(loc=0.1, scale=20),\n#                 'learning_rate': uniform(loc=0.001, scale=1),\n#                 'max_depth': [4, 8, 12, 16, 20],\n#                 'eval_metric': ['mae'],\n#                 'n_estimators': [25, 50, 75, 100, 125, 150],\n#                 'min_child_weight': [5, 10, 15, 20],\n#                 'colsample_bytree': uniform(loc=0.1, scale=0.89),\n#                 'objective': ['reg:squarederror'],\n#                 'subsample': uniform(loc=0.1, scale=0.89)}\n\n#clf = RandomizedSearchCV(estimator=xgb.XGBRegressor(), param_distributions=distributions, n_iter=25, random_state=0)\n#search = clf.fit(X_train, y_train)\n#print(search.best_params_)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T10:55:05.444352Z","iopub.execute_input":"2022-06-10T10:55:05.444757Z","iopub.status.idle":"2022-06-10T10:55:05.450069Z","shell.execute_reply.started":"2022-06-10T10:55:05.444722Z","shell.execute_reply":"2022-06-10T10:55:05.449136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert to XGB matrix datatype\nX_train_D = xgb.DMatrix(X_train, label=y_train)\nX_valid_D = xgb.DMatrix(X_valid, label=y_valid)\n\n# create, fit model\nparams = {\"eval_metric\": \"rmsle\", \"objective\": \"reg:squarederror\", \"max_depth\": 20, \"tree_method\": \"gpu_hist\", \"gpu_id\": 0,\n             \"learning_rate\": 0.1}\nclf = xgb.train(params, X_train_D, num_boost_round=250, early_stopping_rounds=5, evals=[(X_train_D, \"training\"), (X_valid_D, \"validation\")])\n#clf = xgb.XGBRegressor()\n#clf.load_model(\"model.json\")","metadata":{"execution":{"iopub.status.busy":"2022-06-10T10:55:05.451719Z","iopub.execute_input":"2022-06-10T10:55:05.452096Z","iopub.status.idle":"2022-06-10T10:57:11.779544Z","shell.execute_reply.started":"2022-06-10T10:55:05.452039Z","shell.execute_reply":"2022-06-10T10:57:11.778632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# plot feature importance \nxgb.plot_importance(clf, importance_type='cover', title='Feature Importance: Cover', max_num_features=20)\nxgb.plot_importance(clf, importance_type='gain', title='Feature Importance: Gain', max_num_features=20)\nxgb.plot_importance(clf, importance_type='weight', title='Feature Importance: Weight', max_num_features=20)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T10:57:11.781071Z","iopub.execute_input":"2022-06-10T10:57:11.781429Z","iopub.status.idle":"2022-06-10T10:57:13.685115Z","shell.execute_reply.started":"2022-06-10T10:57:11.781402Z","shell.execute_reply":"2022-06-10T10:57:13.684276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf.save_model(\"model.json\")","metadata":{"execution":{"iopub.status.busy":"2022-06-10T10:57:13.686307Z","iopub.execute_input":"2022-06-10T10:57:13.687181Z","iopub.status.idle":"2022-06-10T10:57:14.866149Z","shell.execute_reply.started":"2022-06-10T10:57:13.687139Z","shell.execute_reply":"2022-06-10T10:57:14.865273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# used https://www.kaggle.com/code/kellibelcher/jpx-stock-market-analysis-prediction-with-lgbm\n\nimport jpx_tokyo_market_prediction\nenv = jpx_tokyo_market_prediction.make_env()\niter_test = env.iter_test()\n\ncols=['AdjustmentFactor', 'Date', 'SecuritiesCode', 'High', 'Low', 'Open', 'Close', 'Volume']\ndf_prices=df_prices[df_prices.Date>='2021-08-01'][cols]\n\ncounter = 0\nfor (prices, options, financials, trades, secondary_prices, sample_prediction) in iter_test:\n\n    current_date = prices[\"Date\"].iloc[0]\n    if counter == 0:\n        df_price_raw = df_prices.loc[df_prices[\"Date\"] < current_date]\n            \n    df_price_raw.dropna(inplace=True, axis=0)\n    df_price_raw = pd.concat([df_price_raw, prices[cols]]).reset_index(drop=True)\n    \n    df_price = adjust_price(df_price_raw)\n    df_price.drop(columns=['AdjustmentFactor'], inplace=True)\n    \n    df_price['Date'] = pd.to_datetime(df_price['Date'])\n    df_price[['Open', 'Close',  'High', 'Low', 'Volume']] = ss.transform(df_price[['Open', 'Close', 'High', 'Low', 'Volume']])\n    \n    df_stock = []\n    for id_val in df_price['SecuritiesCode'].unique():\n        df_stock.append(df_price.loc[(df_price['SecuritiesCode'] == id_val)])\n    \n    feats = ['Open', 'Close', 'High', 'Low', 'Volume']\n    others = ['Date', 'SecuritiesCode']\n    shift_reorder(df_stock, time_steps, features=feats, other_cols=others)\n    add_sl_features(df_stock, df_stock_list)\n    df_price_full = pd.concat(df_stock)\n    create_time_features(df_price_full)\n    df_price_full = pd.get_dummies(df_price_full, dummy_na=True, columns=['SectorName17', 'SectorName33', 'SectionProducts', 'NewMarketSegment'], drop_first=True)\n    \n    feat = df_price_full[df_price_full.Date == current_date]\n    \n    feat.drop(columns=['Date'], inplace=True)\n    feat = feat[X_train.columns]\n    feat[\"pred\"] = clf.predict(xgb.DMatrix(feat))\n    feat[\"Rank\"] = (feat[\"pred\"].rank(method=\"first\", ascending=False)-1).astype(int) # flipped from ascending=False due to negative score\n    sample_prediction[\"Rank\"] = feat[\"Rank\"].values\n    display(sample_prediction.head())\n    \n    assert sample_prediction[\"Rank\"].notna().all()\n    assert sample_prediction[\"Rank\"].min() == 0\n    assert sample_prediction[\"Rank\"].max() == len(sample_prediction[\"Rank\"]) - 1\n    \n    print(f'Count = {counter}')\n    \n    env.predict(sample_prediction)\n    counter += 1","metadata":{"execution":{"iopub.status.busy":"2022-06-10T10:57:14.867571Z","iopub.execute_input":"2022-06-10T10:57:14.867997Z","iopub.status.idle":"2022-06-10T10:59:37.089076Z","shell.execute_reply.started":"2022-06-10T10:57:14.867942Z","shell.execute_reply":"2022-06-10T10:59:37.088226Z"},"trusted":true},"execution_count":null,"outputs":[]}]}