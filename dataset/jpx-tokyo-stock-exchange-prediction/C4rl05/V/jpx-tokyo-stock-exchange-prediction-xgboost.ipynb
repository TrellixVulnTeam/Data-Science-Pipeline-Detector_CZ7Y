{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# JPX Tokyo Stock Exchange Prediction ðŸ“ˆ\n\n## A Simple Explanation + XGBoost Model...\n\nHello the purpose of this Notebook is to provide a easy to understand model to start in the competition and a good framework to improve.\n\n**Objectives:**\nDevelop a Machine Learning model, using the 3 following architectures to underestand they performance in the Dataset.\n1. Linear Regressor (Linear Model)\n2. Gradient Boosted Trees (XGBoost)\n3. Neuronal Network (Probably Sequence Model LSTM)\n\n**Strategy**\n1. Understand the Datasets\n2. Build a baseline model to improve uppon\n3. Implement the model architecture described in the objectives section\n\n\n**Updates**\n\n**04/08/2022**\n\n1. Started Notebook, loading and exploring the data.\n2. Develop multiple versions of the baseline submission.\n\n**04/09/2022**\n1. Trying to implement an XGBoost model. \n2. XG Boost completed, problems with features.\n\n**04/10/2022**\n1. Submitting the predictions from the XGBoost Model to Leaderboard.\n2. Trying to understand what's the problem with feature importance.\n**05/20/2022**\n1. It's been almost a month so I need to improve this model.\n2. Full validation and XGBoost completion\n\n\n---\n\n\n**Credits**\n\nI took a lot of inspiration and code ideas from here...\nExcellent explanation on how to calculate the target taken from here.\n\nhttps://www.kaggle.com/code/chumajin/english-ver-easy-to-understand-the-competition\n\nhttps://www.kaggle.com/code/paulorzp/mean-model-jpx/notebook?scriptVersionId=92406307","metadata":{}},{"cell_type":"markdown","source":"## Data Description\nThis dataset contains historic data for a variety of Japanese stocks and options. Your challenge is to predict the future returns of the stocks.\n\nAs historic stock prices are not confidential this will be a forecasting competition using the time series API. \nThe data for the public leaderboard period is included as part of the competition dataset. Expect to see many people submitting perfect submissions for fun. Accordingly, \nthe active phase public leaderboard for this competition is intended as a convenience for anyone who wants to test their code. \nThe forecasting phase leaderboard will be determined using real market data gathered after the submission period closes.","metadata":{}},{"cell_type":"markdown","source":"# 1. Loading Libraries...","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing the Competition API\nimport jpx_tokyo_market_prediction","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# 2. Setting the Notebook Configuration","metadata":{}},{"cell_type":"code","source":"%%time\n# I like to disable my Notebook Warnings.\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Notebook Configuration...\n\n# Amount of data we want to load into the Model...\nDATA_ROWS = None\n# Dataframe, the amount of rows and cols to visualize...\nNROWS = 100\nNCOLS = 15\n# Main data location path...\nBASE_PATH = '...'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Configure notebook display settings to only use 2 decimal places, tables look nicer.\npd.options.display.float_format = '{:,.4f}'.format\npd.set_option('display.max_columns', NCOLS) \npd.set_option('display.max_rows', NROWS)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# 3. Loading the Datasets","metadata":{}},{"cell_type":"code","source":"%%time\nsample = pd.read_csv('/kaggle/input/jpx-tokyo-stock-exchange-prediction/example_test_files/sample_submission.csv')\n\nstock_prices = pd.read_csv(\"../input/jpx-tokyo-stock-exchange-prediction/train_files/stock_prices.csv\")\nsupplemental_stock_prices = pd.read_csv(\"../input/jpx-tokyo-stock-exchange-prediction/supplemental_files/stock_prices.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# 4. Exploring the Information Loaded","metadata":{}},{"cell_type":"markdown","source":"## 4.1 Sample Dataset...","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"%%time\nsample.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nsample.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nsample.nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## 4.2 Stock Prices Dataset","metadata":{}},{"cell_type":"code","source":"%%time\nstock_prices.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nstock_prices.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## 4.2 Stock Prices, Replicating the Target, Example","metadata":{}},{"cell_type":"code","source":"%%time\n# Calculating the Target, Change of rate in the next day...\nstock_1301 = stock_prices[stock_prices[\"SecuritiesCode\"] == 1301].reset_index(drop = True)\nstock_1301['Close_T1'] = stock_1301['Close'].shift(-1)\nstock_1301['Close_T2'] = stock_1301['Close'].shift(-2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nstock_1301['Target_Calculated'] = (stock_1301['Close_T2'] - stock_1301['Close_T1']) / stock_1301['Close_T1']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nstock_1301.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## 4.2 Stock Prices, Replicating the Ranking, Example","metadata":{}},{"cell_type":"code","source":"%%time\n# Calculating the Ranking...\nstock_2021_12_02 = stock_prices[stock_prices[\"Date\"] == '2021-12-02'].reset_index(drop = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nstock_2021_12_02[\"Rank\"] = stock_2021_12_02[\"Target\"].rank(ascending = False,method = \"first\") - 1 \nstock_2021_12_02 = stock_2021_12_02.sort_values('Rank').reset_index(drop = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nstock_2021_12_02.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Calculating daily spread of the returns\n# Consider only the Top 200...\n\nstock_2021_12_02_Top200 = stock_2021_12_02.iloc[:200 ,:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Calculate the Top 200 Weights...\n\nweights = np.linspace(start = 2, stop = 1, num = 200)\nstock_2021_12_02_Top200['Weights'] = weights\nstock_2021_12_02_Top200['Calc_weights'] = stock_2021_12_02_Top200['Target'] * stock_2021_12_02_Top200['Weights']\nSup = stock_2021_12_02_Top200['Calc_weights'].sum() / np.mean(weights)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nprint(Sup)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Calculating daily spread of the returns\n# Consider only the Bottom 200...\n\nstock_2021_12_02_Bottom200 = stock_2021_12_02.iloc[-200: ,:]\nstock_2021_12_02_Bottom200 = stock_2021_12_02_Bottom200.sort_values('Rank', ascending = False).reset_index(drop = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Calculate the Top 200 Weights...\nstock_2021_12_02_Bottom200['Weights'] = weights\nstock_2021_12_02_Bottom200['Calc_weights'] = stock_2021_12_02_Bottom200['Target'] * stock_2021_12_02_Bottom200['Weights']\nSdown = stock_2021_12_02_Bottom200['Calc_weights'].sum() / np.mean(weights)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nprint(Sdown)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndaily_spread_return = Sup - Sdown\nprint(daily_spread_return)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## 4.3 Stock Prices, Calculating the Sharpe Ratio Using Competition Host Function","metadata":{}},{"cell_type":"code","source":"%%time\ndef calc_spread_return_sharpe(df: pd.DataFrame, portfolio_size: int = 200, toprank_weight_ratio: float = 2) -> float:\n    \"\"\"\n    Args:\n        df (pd.DataFrame): predicted results\n        portfolio_size (int): # of equities to buy/sell\n        toprank_weight_ratio (float): the relative weight of the most highly ranked stock compared to the least.\n    Returns:\n        (float): sharpe ratio\n    \"\"\"\n    def _calc_spread_return_per_day(df, portfolio_size, toprank_weight_ratio):\n        \"\"\"\n        Args:\n            df (pd.DataFrame): predicted results\n            portfolio_size (int): # of equities to buy/sell\n            toprank_weight_ratio (float): the relative weight of the most highly ranked stock compared to the least.\n        Returns:\n            (float): spread return\n        \"\"\"\n        assert df['Rank'].min() == 0\n        assert df['Rank'].max() == len(df['Rank']) - 1\n        weights = np.linspace(start=toprank_weight_ratio, stop=1, num=portfolio_size)\n        purchase = (df.sort_values(by='Rank')['Target'][:portfolio_size] * weights).sum() / weights.mean()\n        short = (df.sort_values(by='Rank', ascending=False)['Target'][:portfolio_size] * weights).sum() / weights.mean()\n        return purchase - short\n\n    buf = df.groupby('Date').apply(_calc_spread_return_per_day, portfolio_size, toprank_weight_ratio)\n    sharpe_ratio = buf.mean() / buf.std()\n    return sharpe_ratio","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nstock_prices_example = stock_prices.loc[stock_prices['Date'] >= '2021-01-01'].reset_index(drop = True)\nstock_prices_example['Rank'] = stock_prices_example.groupby('Date')['Target'].rank(ascending = False, method = 'first') - 1 \nstock_prices_example['Rank'] =stock_prices_example['Rank'].astype(\"int\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nstock_prices_example.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ncalc_spread_return_sharpe(stock_prices_example, 200, 2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Simple Baseline Model, Last Day Known...\nLet's build the simplest possible model for a timeseries dataset...","metadata":{}},{"cell_type":"markdown","source":"## Review the Information Available, One More Time, Because Why Not","metadata":{}},{"cell_type":"markdown","source":"### Sample Dataset","metadata":{}},{"cell_type":"code","source":"%%time\n# Review the sample dataset\nsample.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nprint(sample['Date'].min())\nprint(sample['Date'].max())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Review the sample dataset\nsample.nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Review the amount of information in the dataset\nsample.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"### Stock Prices Dataset","metadata":{}},{"cell_type":"code","source":"%%time\n# Review the stock price dataset\nstock_prices.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nprint(stock_prices['Date'].min())\nprint(stock_prices['Date'].max())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Review the stock price dataset\nstock_prices.nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Review the stock price dataset\nstock_prices.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"### Suplemental Stock Prices Dataset","metadata":{}},{"cell_type":"code","source":"%%time\n# Review the suplemental stock price dataset\nsupplemental_stock_prices.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nprint(supplemental_stock_prices['Date'].min())\nprint(supplemental_stock_prices['Date'].max())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Review the suplemental stock price dataset\nsupplemental_stock_prices.nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Review the stock price dataset\nsupplemental_stock_prices.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## Training the Baseline Model (The Most Important Part)\nThe Submission file, Requieres to generate predictions for the following period of times...\n* Min: 2021-12-06\n* Max: 2022-02-28\n\nBase on the competition information: \n\nThe competition will be closed in **July 05, 2022** and the Model will be tested until **Oct 07, 2022**... </br>\nThis is aproximithly **94 days** of gap that the model should be able to predict proeprly. because at this point in time we have only data to **Dec 03, 2021** more data will be provided in the weeks to come, from what I have read.\n\n\n\n**Strategy**\n\nBased on the **Date** information we have available from the Stock Price dataset, **Dec 03, 2021** and the Max Date information from the Submisison file **Feb 28,2022** \nWe will generating prediction for or up to **87 days** into the future during our analysis...\n\nProbably a good start point to test the model performance.","metadata":{}},{"cell_type":"code","source":"%%time\nprint(sample[sample['SecuritiesCode'] == 1301]['Date'].min())\nprint(sample[sample['SecuritiesCode'] == 1301]['Date'].max())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## First Model, Using the Last know Value. Dec 03, 2021 \nWell I Just submitted this Baseline and It's quite bad\n\n**Public LB: -0.090**","metadata":{}},{"cell_type":"code","source":"%%time\nsample.nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nstock_prices[stock_prices['Date'] == '2021-12-03'][['SecuritiesCode', 'Target']].nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\npredictions = stock_prices[stock_prices['Date'] == '2021-12-03'][['SecuritiesCode', 'Target']]\npredictions['Rank'] = predictions['Target'].rank(ascending = False,method = 'first').astype(int) - 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\npredictions_dict = dict(zip(predictions['SecuritiesCode'],predictions['Rank']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%script false --no-raise-error\n\n# Not active in this run\n# Invoke the API to generate predictions.\nenv = jpx_tokyo_market_prediction.make_env()\niter_test = env.iter_test()\n\nfor (prices, options, financials, trades, secondary_prices, sample_prediction) in iter_test:\n    sample_prediction['Rank'] = sample_prediction['SecuritiesCode'].map(predictions_dict)\n    env.predict(sample_prediction)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## Second Model, Using the Last N Days Mean Stock Value.\nWell this version of the Baseline It's even worse than just the previos day submission\n\n**Public LB: -0.101**","metadata":{"execution":{"iopub.status.busy":"2022-04-10T00:34:34.432307Z","iopub.execute_input":"2022-04-10T00:34:34.432642Z","iopub.status.idle":"2022-04-10T00:34:34.437185Z","shell.execute_reply.started":"2022-04-10T00:34:34.432611Z","shell.execute_reply":"2022-04-10T00:34:34.436411Z"}}},{"cell_type":"code","source":"%%time\nNDAYS = 34 # Number of days we want to use...\n# We Want to use 34 days of data, because there are 2000 stocks, aproximathly we need to select -2000 * 34 cells.\n\nstock_prices_dates = stock_prices[stock_prices['Date'] >= stock_prices.Date.iat[-2000 * NDAYS]].reset_index(drop = True)\npredictions = stock_prices_dates.groupby('SecuritiesCode')['Target'].mean().rank(ascending = False, method = 'first').astype(int) -1\npredictions = predictions.reset_index(name = 'Rank')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Creates a prediction dictionary to map the predictions.\npredictions_dict = dict(zip(predictions['SecuritiesCode'],predictions['Rank']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%script false --no-raise-error\n\n# Not active in this run\n# Invoke the API to generate predictions.\nenv = jpx_tokyo_market_prediction.make_env()\niter_test = env.iter_test()\n\nfor (prices, options, financials, trades, secondary_prices, sample_prediction) in iter_test:\n    sample_prediction['Rank'] = sample_prediction['SecuritiesCode'].map(predictions_dict)\n    env.predict(sample_prediction)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## Third Model, Using the Last N Days Mean Stock Value (Suplemental Stock Prices) -- Data Leak.\nThis Model will utilize data future data, so there will be leaks in the model.\nThis is only a test to see if I can replicate some of the Notebooks circulating...\n\nFor example the API only requiered submissions for '2021-12-06' and '2021-12-07'\nI will train the models using the suplemental stock prices this dataset has data from **2021-12-06** to **2022-02-28**","metadata":{"execution":{"iopub.status.busy":"2022-04-10T01:17:42.180281Z","iopub.execute_input":"2022-04-10T01:17:42.180698Z","iopub.status.idle":"2022-04-10T01:17:42.185576Z","shell.execute_reply.started":"2022-04-10T01:17:42.180657Z","shell.execute_reply":"2022-04-10T01:17:42.18483Z"}}},{"cell_type":"code","source":"%%time\nNDAYS = 34 # Number of days we want to use...\n# We Want to use 34 days of data, because there are 2000 stocks, aproximathly we need to select -2000 * 34 cells.\n\nsuplemental_stock_prices_dates = supplemental_stock_prices[supplemental_stock_prices['Date'] >= supplemental_stock_prices.Date.iat[-2000 * NDAYS]].reset_index(drop = True)\npredictions = suplemental_stock_prices_dates.groupby('SecuritiesCode')['Target'].mean().rank(ascending = False, method = 'first').astype(int) -1\npredictions = predictions.reset_index(name = 'Rank')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Creates a prediction dictionary to map the predictions.\npredictions_dict = dict(zip(predictions['SecuritiesCode'],predictions['Rank']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%script false --no-raise-error\n\n\n# Not active in this run\n# Invoke the API to generate predictions.\nenv = jpx_tokyo_market_prediction.make_env()\niter_test = env.iter_test()\n\nfor (prices, options, financials, trades, secondary_prices, sample_prediction) in iter_test:\n    sample_prediction['Rank'] = sample_prediction['SecuritiesCode'].map(predictions_dict)\n    env.predict(sample_prediction)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{"execution":{"iopub.status.busy":"2022-04-10T01:25:06.336686Z","iopub.execute_input":"2022-04-10T01:25:06.337034Z","iopub.status.idle":"2022-04-10T01:25:06.343992Z","shell.execute_reply.started":"2022-04-10T01:25:06.336999Z","shell.execute_reply":"2022-04-10T01:25:06.342431Z"}}},{"cell_type":"markdown","source":"## Fourth Model, XGBoost... (No Data Leak), Train Model Before 2021-12-03\nWell I will try to use data before 2021-12-03 to not leak future information...","metadata":{}},{"cell_type":"code","source":"%%time\nstock_prices.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nstock_prices.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stock_prices['Target'].describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n#stock_prices['Target'] = np.log(stock_prices['Target'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stock_prices['Target'].describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Extrating Date Information.\ndef time_features(df):\n    df['Date'] = pd.to_datetime(df['Date'])\n    df['Year'] = df['Date'].dt.year   \n    df['Month'] = df['Date'].dt.month\n    df['Week_Day'] = df['Date'].dt.weekday\n    df['Day_Of_Year'] = df['Date'].dt.dayofyear\n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nstock_prices = time_features(stock_prices)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nstock_prices.sample(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nstock_prices.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nstock_prices['Open']  = stock_prices['Open'].fillna(stock_prices.groupby('SecuritiesCode')['Open'].transform('median'))\nstock_prices['Low']   = stock_prices['Low'].fillna(stock_prices.groupby('SecuritiesCode')['Low'].transform('median'))\nstock_prices['High']  = stock_prices['High'].fillna(stock_prices.groupby('SecuritiesCode')['High'].transform('median'))\nstock_prices['Close'] = stock_prices['Close'].fillna(stock_prices.groupby('SecuritiesCode')['Close'].transform('median'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nstock_prices = stock_prices.dropna(subset=['Target'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nstock_prices.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Creating Lag Features.\ndef lag_features(df, feature = 'Close', lag_sequence = [1, 7, 15, 30], group_field = 'SecuritiesCode'):\n    for lag in lag_sequence:\n        df[feature + '_Lag' + str(lag)] = df.groupby(group_field)[feature].shift(lag)\n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nstock_prices = lag_features(stock_prices, feature = 'Open', lag_sequence = [1, 2, 4, 7, 15], group_field = 'SecuritiesCode')\nstock_prices = lag_features(stock_prices, feature = 'Close', lag_sequence = [1, 2, 4, 7, 15], group_field = 'SecuritiesCode')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n#stock_prices = lag_features(stock_prices, feature = 'Target', lag_sequence = [90, 120, 150], group_field = 'SecuritiesCode')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nstock_prices[stock_prices['SecuritiesCode'] == 1301].head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nlag_fields = [col for col in stock_prices.columns if 'Lag' in col]\nstock_prices = stock_prices.dropna(subset = lag_fields)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfrom scipy.stats import kurtosis\ndef kurtosis_func(series):\n    '''\n    Describe something...\n    '''\n    return kurtosis(series)\n\ndef q01(series):\n    return np.quantile(series, 0.01)\n\ndef q05(series):\n    return np.quantile(series, 0.05)\n\ndef q95(series):\n    return np.quantile(series, 0.95)\n\ndef q99(series):\n    return np.quantile(series, 0.99)\n\ndef aggregated_features(df, aggregation_cols = ['SecuritiesCode'], prefix = ''):\n    agg_strategy = {'Open' : ['mean', 'max', 'min', 'var', 'mad', 'sum', 'median', 'skew', 'count', kurtosis_func, q01, q05, q95, q99],\n                    'High' : ['mean', 'max', 'min', 'var', 'mad', 'sum', 'median', 'skew', 'count', kurtosis_func, q01, q05, q95, q99],\n                    'Low'  : ['mean', 'max', 'min', 'var', 'mad', 'sum', 'median', 'skew', 'count', kurtosis_func, q01, q05, q95, q99],\n                    'Close': ['mean', 'max', 'min', 'var', 'mad', 'sum', 'median', 'skew', 'count', kurtosis_func, q01, q05, q95, q99],\n                   }\n    group = df.groupby(aggregation_cols).aggregate(agg_strategy)\n    group.columns = ['_'.join(col).strip() for col in group.columns]\n    group.columns = [str(prefix) + str(col) for col in group.columns]\n    group.reset_index(inplace = True)\n    \n    temp = (df.groupby(aggregation_cols).size().reset_index(name = str(prefix) + 'Size'))\n    group = pd.merge(temp, group, how = 'left', on = aggregation_cols,)\n    return group","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rolling_features(df, aggregation_cols = ['SecuritiesCode'], feature = 'Close', periods = 30):\n    df[feature + 'Rolling_Mean'] = df.groupby(aggregation_cols)[feature].transform(lambda s: s.rolling(periods, min_periods=1).mean())\n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time \nstock_prices = rolling_features(stock_prices, aggregation_cols = ['SecuritiesCode'], feature = 'Close', periods = 30)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time \nstock_prices[stock_prices['SecuritiesCode'] == 1301].head(15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Separating the Data in Train and Validation.\ncutoff_date = '2021-09-03' # This leaves 90 Days aproximathly to validate the model...\n\ntrn_data = stock_prices[stock_prices['Date'] < cutoff_date]\nval_data = stock_prices[stock_prices['Date'] >= cutoff_date]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nagg_trn_data = aggregated_features(trn_data, aggregation_cols = ['SecuritiesCode'])\nagg_val_data = aggregated_features(val_data, aggregation_cols = ['SecuritiesCode'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntrn_data = trn_data.merge(agg_trn_data, how = 'left', on = 'SecuritiesCode')\nval_data = val_data.merge(agg_val_data, how = 'left', on = 'SecuritiesCode')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nignore = ['RowId', \n          'Date', \n          'AdjustmentFactor', \n          'ExpectedDividend', \n          'SupervisionFlag', \n          'Target', \n         ]\n\nprediction_target = 'Target'\nfeatures = [feat for feat in trn_data.columns if feat not in ignore]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Display a list of all the futures available.\nfeatures","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Understanding some of the features...\nimport matplotlib.pyplot as plt\n\nplt.scatter(x = trn_data['Day_Of_Year'], y = trn_data['Target'], alpha = 0.1)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfrom xgboost import XGBRegressor","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nparams = {'n_estimators'    : 2048,\n          'max_depth'       : 7,\n          'learning_rate'   : 0.05,\n          'subsample'       : 0.95,\n          'colsample_bytree': 0.90,\n          'reg_lambda'      : 1.50,\n          'reg_alpha'       : 6.10,\n          'gamma'           : 1.40,\n          'random_state'    : 69,\n          'objective'       : 'reg:squarederror',\n          'tree_method'     : 'gpu_hist',\n         }\n\n\nparams_open = {'tree_method'     : 'gpu_hist',}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nX_train, X_valid = trn_data[features], val_data[features]\ny_train, y_valid = trn_data[prediction_target], val_data[prediction_target]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nX_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nX_valid.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nX_train.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nxgb = XGBRegressor(**params_open)\nxgb.fit(X_train, \n        y_train, \n        eval_set = [(X_valid, y_valid)], \n        eval_metric = ['mae'], \n        early_stopping_rounds = 128, \n        verbose = 50\n       )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trn_data[prediction_target].describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndef plot_feature_importance(importance, names, model_type, max_features = 10):\n    #Create arrays from feature importance and feature names\n    feature_importance = np.array(importance)\n    feature_names = np.array(names)\n\n    #Create a DataFrame using a Dictionary\n    data={'feature_names':feature_names,'feature_importance':feature_importance}\n    fi_df = pd.DataFrame(data)\n\n    #Sort the DataFrame in order decreasing feature importance\n    fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n    fi_df = fi_df.head(max_features)\n\n    #Define size of bar plot\n    plt.figure(figsize=(8,6))\n    \n    #Plot Searborn bar chart\n    sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])\n    #Add chart labels\n    plt.title(model_type + 'FEATURE IMPORTANCE')\n    plt.xlabel('FEATURE IMPORTANCE')\n    plt.ylabel('FEATURE NAMES')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplot_feature_importance(xgb.feature_importances_, X_train.columns, 'XG BOOST ', max_features = 20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"env = jpx_tokyo_market_prediction.make_env()\niter_test = env.iter_test()\n\nfor (prices, options, financials, trades, secondary_prices, sample_prediction) in iter_test:\n    ds = [prices, options, financials, trades, secondary_prices, sample_prediction]\n    sample_prediction[\"Avg\"] = sample_prediction[\"SecuritiesCode\"].apply(get_avg)\n    df = sample_prediction[[\"Date\",\"SecuritiesCode\",\"Avg\"]]\n    df[\"High\"] = prices[\"High\"]\n    df[\"Open\"] = prices[\"Open\"]\n    df[\"Close\"] = prices[\"Close\"]\n    df[\"Low\"] = prices[\"Low\"]\n    df[\"Volume\"] = prices[\"Volume\"]\n    df.Date = pd.to_datetime(df.Date)\n    sample_prediction[\"Volume\"] = df[\"Volume\"]\n    df['Date'] = df['Date'].dt.strftime(\"%Y%m%d\").astype(int)\n    sample_prediction[\"Prediction\"] = model_o.predict(df)\n    sample_prediction[\"rate\"] = sample_prediction[\"Prediction\"]/(np.log(sample_prediction[\"Volume\"]+1))\n    sample_prediction = sample_prediction.sort_values(by = \"rate\", ascending=False)\n    sample_prediction.Rank = np.arange(0,2000)\n    sample_prediction = sample_prediction.sort_values(by = \"SecuritiesCode\", ascending=True)\n    sample_prediction.drop([\"Prediction\"],axis=1)\n    submission = sample_prediction[[\"Date\",\"SecuritiesCode\",\"Rank\"]]\n    env.predict(submission)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}