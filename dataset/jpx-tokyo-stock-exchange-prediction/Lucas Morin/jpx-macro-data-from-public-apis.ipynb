{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"I struggled with the following APIs so you don't have to:\n\n- [**IMF API (Inflation, Trade Balance)**](#IMF) \n\nA bit difficult to use. It seems that most IMF data is on db-nomics (see below). I might switch to it.\n\n- [**Japanese Ministry of Finance (Interest Rates, Government Debt)**](#MOF)\n\nNot so difficult once I found the direct download links.\n\n- [**db-nomics - JSTAT (Unemployment)**](#JSTAT)\n\nRelatively easy to use.\n\n- [**E-stat adaptator - (National Statistics)**](#ESTAT)\n\nLots of available data but not everything seems to works.\n\n- [**Japan COVID-19 Bulletin Board - Covid 19 Data HUB**](#COVID)\n\nVery easy to use python API. Basically just need a country name.\n\nI also looked at the National Central Bank (Bank of Japan), but couldn't really find anything. Might look into weather data too.","metadata":{}},{"cell_type":"markdown","source":"# Imports\nrequests to get data, the rest is to manipulate and plot data.","metadata":{}},{"cell_type":"code","source":"import requests\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-05-15T08:07:38.347189Z","iopub.execute_input":"2022-05-15T08:07:38.347514Z","iopub.status.idle":"2022-05-15T08:07:38.371824Z","shell.execute_reply.started":"2022-05-15T08:07:38.347422Z","shell.execute_reply":"2022-05-15T08:07:38.371162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"competition dates","metadata":{}},{"cell_type":"code","source":"train_start = '2017-01-04'\ntrain_end = '2021-12-03'\neval_start = '2022-07-05'\neval_end = '2022-10-07'","metadata":{"execution":{"iopub.status.busy":"2022-05-15T08:07:38.376198Z","iopub.execute_input":"2022-05-15T08:07:38.376749Z","iopub.status.idle":"2022-05-15T08:07:38.380851Z","shell.execute_reply.started":"2022-05-15T08:07:38.376712Z","shell.execute_reply":"2022-05-15T08:07:38.379969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def base_plot(data,title,source):\n    plt.plot(data);\n    plt.title(f'{title} - {source}');\n    plt.show()\n    \ndef context_plot(data,title,source,start_plot='2010-01-01',\n                 train_start=train_start, train_end=train_end,\n                 eval_start=eval_start, eval_end=eval_end):\n    data = data[data.index>start_plot]\n    plt.plot(data);\n    plt.title(f'{title} - {source}');\n    plt.axvspan(train_start, train_end, color=\"grey\", alpha=0.25)\n    plt.axvspan(eval_start, eval_end, color=\"grey\", alpha=0.5)\n    plt.hlines(0,xmin=data.index.min(),xmax=pd.to_datetime(eval_end),color='k',linestyles='dotted');\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-15T08:07:38.396538Z","iopub.execute_input":"2022-05-15T08:07:38.397286Z","iopub.status.idle":"2022-05-15T08:07:38.406348Z","shell.execute_reply.started":"2022-05-15T08:07:38.397251Z","shell.execute_reply":"2022-05-15T08:07:38.40577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='IMF'></a>\n# International Monetary Fund - API\n\nSome of the code adapted to this competition from: https://www.bd-econ.com/imfapi1.html\n\nDatabases names are required to get data. Here is an overwiew of what is available:\n\nhttps://data.imf.org/?sk=388DFA60-1D26-4ADE-B505-A05A558D9A42&sId=1479329132316","metadata":{"execution":{"iopub.status.busy":"2022-04-29T19:48:22.81912Z","iopub.execute_input":"2022-04-29T19:48:22.819727Z","iopub.status.idle":"2022-04-29T19:48:22.845054Z","shell.execute_reply.started":"2022-04-29T19:48:22.819621Z","shell.execute_reply":"2022-04-29T19:48:22.844169Z"}}},{"cell_type":"markdown","source":"There is a search engine, but it is not always easy to use. \nFor exemple if we start with inflation we have to know this is the differentiation of Consummer Price Index and look for it instead...","metadata":{}},{"cell_type":"code","source":"# parameters\nurl = 'http://dataservices.imf.org/REST/SDMX_JSON.svc/'\nkey = 'Dataflow'  # Method with series information\nsearch_term = 'Consumer'  # Term to find in series names\n\n# request\nseries_list = requests.get(f'{url}{key}').json()['Structure']['Dataflows']['Dataflow']\n\n# Use dict keys to navigate through results:\nfor series in series_list:\n    if search_term in series['Name']['#text']:\n        print(f\"{series['Name']['#text']}: {series['KeyFamilyRef']['KeyFamilyID']}\")","metadata":{"execution":{"iopub.status.busy":"2022-05-15T08:07:38.424784Z","iopub.execute_input":"2022-05-15T08:07:38.425108Z","iopub.status.idle":"2022-05-15T08:07:38.693805Z","shell.execute_reply.started":"2022-05-15T08:07:38.425075Z","shell.execute_reply":"2022-05-15T08:07:38.692976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Learn how to request data set: with a dataset key we can look the way to request it:","metadata":{}},{"cell_type":"code","source":"Data_set = 'CPI'\n\nkey = 'DataStructure/' + Data_set  # Method / series\ndimension_list = requests.get(f'{url}{key}').json()\\\n            ['Structure']['KeyFamilies']['KeyFamily']\\\n            ['Components']['Dimension']\n\nfor n, dimension in enumerate(dimension_list):\n    print(f'Dimension {n+1}: {dimension[\"@codelist\"]}')","metadata":{"execution":{"iopub.status.busy":"2022-05-15T08:07:38.69541Z","iopub.execute_input":"2022-05-15T08:07:38.695631Z","iopub.status.idle":"2022-05-15T08:07:38.941478Z","shell.execute_reply.started":"2022-05-15T08:07:38.695603Z","shell.execute_reply":"2022-05-15T08:07:38.940929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is three dimensions to request the data set:\n\nFreq is usually 'M, 'Q' or 'Y', as we want granular data we will use M.\n\nArea is the area of interest ('JP' here)\n\nWe need to look further the 3rd dimension to know which serie to request.","metadata":{}},{"cell_type":"code","source":"# Example: codes for third dimension, which is 2 in python\nkey = f\"CodeList/{dimension_list[2]['@codelist']}\"\ncode_list = requests.get(f'{url}{key}').json()['Structure']['CodeLists']['CodeList']['Code']\n\nfor code in code_list[:10]:\n    print(f\"{code['Description']['#text']}: {code['@value']}\")\n    \nprint(f'Plus {len(code_list)-10} other series')","metadata":{"execution":{"iopub.status.busy":"2022-05-15T08:07:38.942653Z","iopub.execute_input":"2022-05-15T08:07:38.9433Z","iopub.status.idle":"2022-05-15T08:07:39.182827Z","shell.execute_reply.started":"2022-05-15T08:07:38.943263Z","shell.execute_reply":"2022-05-15T08:07:39.181975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we are interested in inflation we start with the general price indice: PCPI_IX.","metadata":{}},{"cell_type":"code","source":"Data_set = 'CPI'\nfreq = 'M'\narea = 'JP'\nname = 'Consumer Price Index, All items'\nindice = 'PCPI_IX'\n\nkey = 'CompactData/'+Data_set+'/'+freq+'.'+area+'.'+indice\n\ndata = (requests.get(f'{url}{key}').json()['CompactData']['DataSet']['Series'])\n\nbaseyr = data['@COMMON_REFERENCE_PERIOD'] \n\ndata_list = [[obs.get('@TIME_PERIOD'), obs.get('@OBS_VALUE')] for obs in data['Obs']]\ndf = pd.DataFrame(data_list, columns=['date', indice])\ndf = df.set_index(pd.to_datetime(df['date']))[indice].astype('float')","metadata":{"execution":{"iopub.status.busy":"2022-05-15T08:07:39.185578Z","iopub.execute_input":"2022-05-15T08:07:39.185913Z","iopub.status.idle":"2022-05-15T08:07:39.516833Z","shell.execute_reply.started":"2022-05-15T08:07:39.185851Z","shell.execute_reply":"2022-05-15T08:07:39.515952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Basic plot - CPI","metadata":{}},{"cell_type":"code","source":"title = f'{area} {name} (index, {baseyr})'\nsource = f'Source: IMF {Data_set}'\nplot = df.plot(title=title, colormap='Set1')","metadata":{"execution":{"iopub.status.busy":"2022-05-15T08:07:39.518515Z","iopub.execute_input":"2022-05-15T08:07:39.518802Z","iopub.status.idle":"2022-05-15T08:07:39.814633Z","shell.execute_reply.started":"2022-05-15T08:07:39.518763Z","shell.execute_reply":"2022-05-15T08:07:39.813888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I gathered a list of interesting data; but only two first sources seems to work from the IMF API. \nIt seems that dbnomics also offer data from IMF. Might be a better solution (see below).","metadata":{}},{"cell_type":"code","source":"# BOP = {\n#     'Assets - Euros': ('BOP','M','JP','IAFR_BP6_EUR'),\n#     'Assets - National Currency': ('BOP','M','JP','IAFR_BP6_XDC'),\n#     'Assets - US Dollars': ('BOP','M','JP','IAFR_BP6_USD')\n# }\n\n# DOT = {\n#     'Exports, US Dollars': ('DOT','M','JP','TXG_FOB_USD','W00'),\n#     'Imports, Cost, Insurance, Freight': ('DOT','M','JP','TMG_CIF_USD','W00'),\n#     'Imports, US Dollars': ('DOT','M','JP','TMG_FOB_USD','W00'),\n#     'Trade Balance, US Dollars': ('DOT','M','JP','TBG_USD','W00')\n# }\n\n# FM ={\n#     'Cyclically adjusted balance (% of potential GDP)': ('FM','M','JP','GGCB_G01_PGDP_PT'),\n#     'Cyclically adjusted primary balance (% of potential GDP)': ('FM','M','JP','GGCBP_G01_PGDP_PT'),\n#     'Expenditure (% of GDP)': ('FM','M','JP','G_X_G01_GDP_PT'),\n#     'Gross debt (% of GDP)':('FM','M','JP','G_XWDG_G01_GDP_PT'),\n#     'Net debt (% of GDP)': ('FM','M','JP', 'GGXWDN_G01_GDP_PT'),\n#     'Net lending/borrowing (also referred as overall balance) (% of GDP)': ('FM','M','JP','GGXCNL_G01_GDP_PT '),\n#     'Primary net lending/borrowing (also referred as primary balance) (% of GDP)': ('FM','M','JP','GGXONLB_G01_GDP_PT'),\n#     'Revenue (% of GDP)':  ('FM','M','JP','GGR_G01_GDP_PT')\n# }\n\n# IFS ={\n#     'National Accounts, National Currency - Nominal': ('FM','M','JP','NFIAXD_XDC'),\n#     'National Accounts, National Currency - Real': ('FM','M','JP','NFIAXD_R_XDC'),\n#     'Net acquisition of financial assets, US Dollars': ('FM','M','JP','IAFR_BP6_USD'),\n#     'Debt instruments, US Dollars': ('FM','M','JP','IADD_BP6_USD'),\n#     'Equity and investment fund shares , US Dollars': ('FM','M','JP','IADE_BP6_USD'),\n#     'Assets, Direct investment, US Dollars': ('FM','M','JP','IAD_BP6_USD')\n# }\n\n# APDREO = {'Balance of Payments, Current Account, Total, Net(BPM6), percent of GDP in U.S. dollars': 'BCA_GDP_BP6',\n#   'Consumer Prices, end of period, percent change': 'PCPIE_PCH',\n#   'Consumer Prices, period average, percent change': 'PCPI_PCH',\n#   'General government net lending/borrowing, percent of fiscal year GDP': 'GGXCNL_GDP',\n#   'Gross domestic product, constant prices, National Currency, percent change': 'NGDP_RPCH',\n#   'Gross domestic product, constant prices, purchasing power parity, per capita, percent change': 'NGDP_R_PPP_PC_PCH',\n#   'Unemployment rate': 'LUR'}\n\n# HPDD = {'Public Balance': 'GGXWDG_GDP'}\n\n# FAS = {'Total Population, Female': 'LPAF_NUM',\n#   'Total Population, Male': 'LPAM_NUM',\n#   'Claims on nonfinancial corporations and households, Domestic Currency': 'FODMANCH_XDC',\n#   'Claims on nonfinancial corporations and households, Euros': 'FODMANCH_EUR',\n#   'Claims on nonfinancial corporations and households, US Dollars': 'FODMANCH_USD',\n#   'Geographical Outreach, Mobile Money, Number of active mobile money agent outlets': 'FCMOA_NUM',\n#   'Geographical Outreach, Mobile Money, Number of registered mobile money agent outlets': 'FCMOR_NUM',\n#   'Geographical Outreach, Number of Automated Teller Machines (ATMs), Country wide, Number of': 'FCAC_NUM',\n#   'Geographical Outreach, Number of Branches, Excluding Headquarters, Other Depository Corporations, Commercial banks, Number of': 'FCBODC_NUM'}\n\n# COFER = {'Foreign Exchange, US Dollars': 'RAXGFX_USD',\n#   'Allocated Reserves, US Dollars': 'RAXGFXAR_USD'}\n\n# FSI = {'Domestic government securities owned (market value), National Currency': 'FS_ODX_GSD_MV_XDC',\n#   'Gross loans to the public sector, National Currency': 'FS_ODX_AFLG_PS_XDC',\n#   'Gross new deposits during the period, National Currency': 'FS_ODX_AFCDGN_XDC'}","metadata":{"execution":{"iopub.status.busy":"2022-05-15T08:07:39.816267Z","iopub.execute_input":"2022-05-15T08:07:39.816813Z","iopub.status.idle":"2022-05-15T08:07:39.825124Z","shell.execute_reply.started":"2022-05-15T08:07:39.816766Z","shell.execute_reply":"2022-05-15T08:07:39.823971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Inflation is the difference in price index. Here we use a 12-months rolling difference.","metadata":{}},{"cell_type":"code","source":"Data_set = 'CPI'\nfreq = 'M'\narea = 'JP'\nname = 'Consumer Price Index, All items'\nindice = 'PCPI_IX'\n\nkey = 'CompactData/'+Data_set+'/'+freq+'.'+area+'.'+indice\n\ndata = (requests.get(f'{url}{key}').json()['CompactData']['DataSet']['Series'])\n\nbaseyr = data['@COMMON_REFERENCE_PERIOD'] \n\ndata_list = [[obs.get('@TIME_PERIOD'), obs.get('@OBS_VALUE')] for obs in data['Obs']]\ndf = pd.DataFrame(data_list, columns=['date', indice])\ndf = df.set_index(pd.to_datetime(df['date']))[indice].astype('float')\n\ndf_inflation = df\n\nbase_plot(df.diff(12),'YoY inflation',source)\ncontext_plot(df.diff(12),'YoY inflation',source)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T08:07:39.826823Z","iopub.execute_input":"2022-05-15T08:07:39.827244Z","iopub.status.idle":"2022-05-15T08:07:40.675313Z","shell.execute_reply.started":"2022-05-15T08:07:39.827203Z","shell.execute_reply":"2022-05-15T08:07:40.674277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Trade Balance","metadata":{}},{"cell_type":"code","source":"Data_set = 'DOT'\nfreq = 'M'\narea = 'JP'\nname = 'test'\nindice = 'TBG_USD'\n\nkey = 'CompactData/'+Data_set+'/'+freq+'.'+area+'.'+indice+'.W00'\n\ndata = (requests.get(f'{url}{key}').json()['CompactData']['DataSet']['Series'])\ndata_list = [[obs.get('@TIME_PERIOD'), obs.get('@OBS_VALUE')] for obs in data['Obs']]\ndf = pd.DataFrame(data_list, columns=['date', indice])\ndf = df.set_index(pd.to_datetime(df['date']))[indice].astype('float')\n\ndf_trade = df\n\nbase_plot(df.rolling(12).mean(),'Trade Balance',source)\ncontext_plot(df.rolling(12).mean(),'Trade Balance',source)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T08:07:40.676713Z","iopub.execute_input":"2022-05-15T08:07:40.677299Z","iopub.status.idle":"2022-05-15T08:07:41.386697Z","shell.execute_reply.started":"2022-05-15T08:07:40.677262Z","shell.execute_reply":"2022-05-15T08:07:41.385828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='MOF'></a>\n\n# Japanese ministry of finance - Interest Rates","metadata":{}},{"cell_type":"code","source":"japan_hist = pd.read_csv(\"https://www.mof.go.jp/english/jgbs/reference/interest_rate/historical/jgbcme_all.csv\", header=1, parse_dates=['Date'])\njapan_hist = japan_hist.set_index('Date').replace('-',np.nan).astype('float')\n\nhorizons = ['1Y','5Y','10Y','25Y']\ndf_yield = japan_hist[horizons]\n\nbase_plot(japan_hist[horizons],'Interest Rates','Japan MoF')\ncontext_plot(japan_hist[horizons],'Interest Rates','Japan MoF')","metadata":{"execution":{"iopub.status.busy":"2022-05-15T08:07:41.387868Z","iopub.execute_input":"2022-05-15T08:07:41.388137Z","iopub.status.idle":"2022-05-15T08:07:44.66479Z","shell.execute_reply.started":"2022-05-15T08:07:41.388107Z","shell.execute_reply":"2022-05-15T08:07:44.664235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# yield curve","metadata":{}},{"cell_type":"code","source":"cols = japan_hist.columns[japan_hist.columns.str.endswith('Y')]\n\nhorizons = cols.str.replace('Y','').astype('int').values\nvalues = japan_hist[cols].iloc[-1].astype('float')\n\n\nplt.scatter(horizons,values);","metadata":{"execution":{"iopub.status.busy":"2022-05-15T08:07:44.66717Z","iopub.execute_input":"2022-05-15T08:07:44.667507Z","iopub.status.idle":"2022-05-15T08:07:44.890862Z","shell.execute_reply.started":"2022-05-15T08:07:44.667478Z","shell.execute_reply":"2022-05-15T08:07:44.89025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Government Debt","metadata":{}},{"cell_type":"code","source":"!pip install xlrd","metadata":{"execution":{"iopub.status.busy":"2022-05-15T08:07:44.891919Z","iopub.execute_input":"2022-05-15T08:07:44.892261Z","iopub.status.idle":"2022-05-15T08:07:55.561762Z","shell.execute_reply.started":"2022-05-15T08:07:44.892232Z","shell.execute_reply":"2022-05-15T08:07:55.560797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_excel(\"https://www.mof.go.jp/english/jgbs/reference/gbb/suii.xls\", header=2)\n\nTotal = (df[df.Category=='Total'].values)[0][3:]\ndata = pd.DataFrame(Total,index=pd.date_range('2017-03','2022-01',freq='Q'),columns=['Total Government Debt'])\n\ndf_debt = data\n\nbase_plot(data,'Interest Rates','Japan MoF')\ncontext_plot(data,'Interest Rates','Japan MoF')","metadata":{"execution":{"iopub.status.busy":"2022-05-15T08:07:55.563384Z","iopub.execute_input":"2022-05-15T08:07:55.563657Z","iopub.status.idle":"2022-05-15T08:07:58.770432Z","shell.execute_reply.started":"2022-05-15T08:07:55.563623Z","shell.execute_reply":"2022-05-15T08:07:58.769616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='JSTAT'></a>\n\n# db nomics - employment rate","metadata":{}},{"cell_type":"code","source":"!pip install dbnomics\n\nimport dbnomics","metadata":{"execution":{"iopub.status.busy":"2022-05-15T08:07:58.772107Z","iopub.execute_input":"2022-05-15T08:07:58.772412Z","iopub.status.idle":"2022-05-15T08:08:07.866786Z","shell.execute_reply.started":"2022-05-15T08:07:58.772371Z","shell.execute_reply":"2022-05-15T08:08:07.865859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = dbnomics.fetch_series('STATJP', 'MIm')\ndf.series_name.unique()","metadata":{"execution":{"iopub.status.busy":"2022-05-15T08:08:07.869936Z","iopub.execute_input":"2022-05-15T08:08:07.870173Z","iopub.status.idle":"2022-05-15T08:08:12.428398Z","shell.execute_reply.started":"2022-05-15T08:08:07.870144Z","shell.execute_reply":"2022-05-15T08:08:12.427556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df[df.series_name == 'Monthly – Unemployment rate – Both sexes – Percent – seasonally adjusted'][['period','value']].set_index('period')\n\ndf_employment = df.rename(columns={'value':'employment_rate'})\n\nbase_plot(df,'Monthly – Unemployment rate','STAT JP')\ncontext_plot(df,'Monthly – Unemployment rate','STAT JP')","metadata":{"execution":{"iopub.status.busy":"2022-05-15T08:08:12.429722Z","iopub.execute_input":"2022-05-15T08:08:12.430022Z","iopub.status.idle":"2022-05-15T08:08:13.058881Z","shell.execute_reply.started":"2022-05-15T08:08:12.429983Z","shell.execute_reply":"2022-05-15T08:08:13.057879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='ESTAT'></a>\n\n# E-stat adaptator - national statistics","metadata":{}},{"cell_type":"markdown","source":"code from https://github.com/e-stat-api/adaptor","metadata":{}},{"cell_type":"code","source":"!pip install xlrd","metadata":{"execution":{"iopub.status.busy":"2022-05-15T08:08:13.059951Z","iopub.execute_input":"2022-05-15T08:08:13.060159Z","iopub.status.idle":"2022-05-15T08:08:21.50627Z","shell.execute_reply.started":"2022-05-15T08:08:13.060133Z","shell.execute_reply":"2022-05-15T08:08:21.505464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import urllib\nimport requests\nimport csv\nimport json\nimport xlrd\nimport zipfile\nimport requests\nimport functools\nimport pandas as pd\nfrom concurrent.futures import ThreadPoolExecutor\nfrom tqdm import tqdm\nimport io\nimport os\nfrom pprint import pprint","metadata":{"execution":{"iopub.status.busy":"2022-05-15T08:08:21.508808Z","iopub.execute_input":"2022-05-15T08:08:21.509182Z","iopub.status.idle":"2022-05-15T08:08:21.517105Z","shell.execute_reply.started":"2022-05-15T08:08:21.509136Z","shell.execute_reply":"2022-05-15T08:08:21.516225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Complete parser (hidden code).","metadata":{}},{"cell_type":"code","source":"\n\nclass EstatRestAPI_URLParser:\n    \"\"\"\n    This is a simple python module class for e-Stat API (ver.3.0).\n    See more details at https://www.e-stat.go.jp/api/api-info/e-stat-manual3-0\n    \"\"\"\n\n    def __init__(self, api_version=None, app_id=None):\n        # base url\n        self.base_url = \"https://api.e-stat.go.jp/rest\"\n\n        # e-Stat REST API Version\n        if api_version is None:\n            self.api_version = \"3.0\"\n        else:\n            self.api_version = api_version\n\n        # Application ID\n        if app_id is None:\n            self.app_id = \"****************\" #Enter the application ID here\n        else:\n            self.app_id = app_id\n\n    def getStatsListURL(self, params_dict, format=\"csv\"):\n        \"\"\"\n        2.1 Get statistical table information(HTTP GET)\n        \"\"\"\n        params_str = urllib.parse.urlencode(params_dict)\n        if format == \"xml\":\n            url = (\n                f\"{self.base_url}/{self.api_version}\"\n                f\"/app/getStatsList?{params_str}\"\n            )\n        elif format == \"json\":\n            url = (\n                f\"{self.base_url}/{self.api_version}\"\n                f\"/app/json/getStatsList?{params_str}\"\n            )\n        elif format == \"jsonp\":\n            url = (\n                f\"{self.base_url}/{self.api_version}\"\n                f\"/app/jsonp/getStatsList?{params_str}\"\n            )\n        elif format == \"csv\":\n            url = (\n                f\"{self.base_url}/{self.api_version}\"\n                f\"/app/getSimpleStatsList?{params_str}\"\n            )\n        return url\n\n    def getMetaInfoURL(self, params_dict, format=\"csv\"):\n        \"\"\"\n        2.2 Meta information acquisition(HTTP GET)\n        \"\"\"\n        params_str = urllib.parse.urlencode(params_dict)\n        if format == \"xml\":\n            url = (\n                f\"{self.base_url}/{self.api_version}\"\n                f\"/app/getMetaInfo?{params_str}\"\n            )\n        elif format == \"json\":\n            url = (\n                f\"{self.base_url}/{self.api_version}\"\n                f\"/app/json/getMetaInfo?{params_str}\"\n            )\n        elif format == \"jsonp\":\n            url = (\n                f\"{self.base_url}/{self.api_version}\"\n                f\"/app/jsonp/getMetaInfo?{params_str}\"\n            )\n        elif format == \"csv\":\n            url = (\n                f\"{self.base_url}/{self.api_version}\"\n                f\"/app/getSimpleMetaInfo?{params_str}\"\n            )\n        return url\n\n    def getStatsDataURL(self, params_dict, format=\"csv\"):\n        \"\"\"\n        2.3 Statistical data acquisition(HTTP GET)\n        \"\"\"\n        params_str = urllib.parse.urlencode(params_dict)\n        if format == \"xml\":\n            url = (\n                f\"{self.base_url}/{self.api_version}\"\n                f\"/app/getStatsData?{params_str}\"\n            )\n        elif format == \"json\":\n            url = (\n                f\"{self.base_url}/{self.api_version}\"\n                f\"/app/json/getStatsData?{params_str}\"\n            )\n        elif format == \"jsonp\":\n            url = (\n                f\"{self.base_url}/{self.api_version}\"\n                f\"/app/jsonp/getStatsData?{params_str}\"\n            )\n        elif format == \"csv\":\n            url = (\n                f\"{self.base_url}/{self.api_version}\"\n                f\"/app/getSimpleStatsData?{params_str}\"\n            )\n        return url\n\n    def postDatasetURL(self):\n        \"\"\"\n        2.4 Data set registration(HTTP POST)\n        \"\"\"\n        url = (\n            f\"{self.base_url}/{self.api_version}\"\n            \"/app/postDataset\"\n        )\n        return url\n\n    def refDataset(self, params_dict, format=\"xml\"):\n        \"\"\"\n        2.5 Dataset reference(HTTP GET)\n        \"\"\"\n        params_str = urllib.parse.urlencode(params_dict)\n        if format == \"xml\":\n            url = (\n                f\"{self.base_url}/{self.api_version}\"\n                + f\"/app/refDataset?{params_str}\"\n            )\n        elif format == \"json\":\n            url = (\n                f\"{self.base_url}/{self.api_version}\"\n                f\"/app/json/refDataset?{params_str}\"\n            )\n        elif format == \"jsonp\":\n            url = (\n                f\"{self.base_url}/{self.api_version}\"\n                f\"/app/jsonp/refDataset?{params_str}\"\n            )\n        return url\n\n    def getDataCatalogURL(self, params_dict, format=\"xml\"):\n        \"\"\"\n        2.6 Data catalog information acquisition(HTTP GET)\n        \"\"\"\n        params_str = urllib.parse.urlencode(params_dict)\n        if format == \"xml\":\n            url = (\n                f\"{self.base_url}/{self.api_version}\"\n                f\"/app/getDataCatalog?{params_str}\"\n            )\n        elif format == \"json\":\n            url = (\n                f\"{self.base_url}/{self.api_version}\"\n                f\"/app/json/getDataCatalog?{params_str}\"\n            )\n        elif format == \"jsonp\":\n            url = (\n                f\"{self.base_url}/{self.api_version}\"\n                f\"/app/jsonp/getDataCatalog?{params_str}\"\n            )\n        return url\n\n    def getStatsDatasURL(self, params_dict, format=\"xml\"):\n        \"\"\"\n        2.7 Collective statistical data(HTTP GET)\n        \"\"\"\n        params_str = urllib.parse.urlencode(params_dict)\n        if format == \"xml\":\n            url = (\n                f\"{self.base_url}/{self.api_version}\"\n                f\"/app/getStatsDatas?{params_str}\"\n            )\n        elif format == \"json\":\n            url = (\n                f\"{self.base_url}/{self.api_version}\"\n                f\"/app/json/getStatsDatas?{params_str}\"\n            )\n        elif format == \"csv\":\n            url = (\n                f\"{self.base_url}/{self.api_version}\"\n                f\"/app/getSimpleStatsDatas?{params_str}\"\n            )\n        return url\n\n\ndef get_json(url):\n    \"\"\"\n    Request a HTTP GET method to the given url (for REST API)\n    and return its response as the dict object.\n\n    Args:\n    ====\n    url: string\n        valid url for REST API\n    \"\"\"\n    try:\n        print(\"HTTP GET\", url)\n        r = requests.get(url)\n        json_dict = r.json()\n        return json_dict\n    except requests.exceptions.RequestException as error:    \n        print(error)\n\n\ndef download_json(url, filepath):\n    \"\"\"\n    Request a HTTP GET method to the given url (for REST API)\n    and save its response as the json file.\n\n    Args:\n    url: string\n        valid url for REST API\n    filepath: string\n        valid path to the destination file\n    \"\"\"\n    try:\n        print(\"HTTP GET\", url)\n        r = requests.get(url)\n        json_dict = r.json()\n        json_str = json.dumps(json_dict, indent=2, ensure_ascii=False)\n        with open(filepath, \"w\") as f:\n            f.write(json_str)\n    except requests.exceptions.RequestException as error:\n        print(error)\n\n\ndef download_csv(url, filepath, enc=\"utf-8\", dec=\"utf-8\", logging=False):\n    \"\"\"\n    Request a HTTP GET method to the given url (for REST API)\n    and save its response as the csv file.\n\n    Args:\n    =====\n    url: string\n        valid url for REST API\n    filepathe: string\n        valid path to the destination file\n    enc: string\n        encoding type for a content in a given url\n    dec: string\n        decoding type for a content in a downloaded file\n            dec = 'utf-8' for general env\n            dec = 'sjis'  for Excel on Win\n            dec = 'cp932' for Excel with extended JP str on Win\n    logging: True/False\n        flag whether putting process log\n    \"\"\"\n    try:\n        if logging:\n            print(\"HTTP GET\", url)\n        r = requests.get(url, stream=True)\n        with open(filepath, 'w', encoding=enc) as f:\n            f.write(r.content.decode(dec))\n    except requests.exceptions.RequestException as error:\n        print(error)\n\n\ndef download_all_csv(\n        urls,\n        filepathes,\n        max_workers=10,\n        enc=\"utf-8\",\n        dec=\"utf-8\"):\n    \"\"\"\n    Request some HTTP GET methods to the given urls (for REST API)\n    and save each response as the csv file.\n    (!! This method uses multi threading when calling HTTP GET requests\n    and downloading files in order to improve the processing speed.)\n\n    Args:\n    =====\n    urls: list of strings\n        valid urls for REST API\n    filepathes: list of strings\n        valid pathes to the destination file\n    max_workers: int\n        max number of working threads of CPUs within executing this method.\n    enc: string\n        encoding type for a content in a given url\n    dec: string\n        decoding type for a content in a downloaded file\n            dec = 'utf-8' for general env\n            dec = 'sjis'  for Excel on Win\n            dec = 'cp932' for Excel with extended JP str on Win\n    logging: True/False\n    \"\"\"\n    func = functools.partial(download_csv, enc=enc, dec=dec)\n    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n        results = list(\n            tqdm(executor.map(func, urls, filepathes), total=len(urls))\n        )\n        del results\n\ndef search_tables(appId, params_dict):\n    \"\"\"\n    Prams (dictionary) to search eStat tables.\n    For more details, see also\n    https://www.e-stat.go.jp/api/api-info/e-stat-manual3-0#api_3_2\n\n        - appId: Application ID (*required)\n        - lang:language(J:Japanese, E:English)\n        - surveyYears:Survey date(YYYYY or YYYYMM or YYYYMM-YYYYMM)\n        - openYears:Same as the survey date\n        - statsField:Statistics field(2 digits:Statistical classification,4 digits:Statistical subclass)\n        - statsCode:Government statistics code(8-digit)\n        - searchWord:Search keyword\n        - searchKind:Data type(1:Statistics, 2:Subregion / regional mesh)     \n        - collectArea:Aggregate area classification(1:Nationwide, 2:Prefectures, 3:Municipality)        \n        - explanationGetFlg:Existence of commentary information(Y or N)\n        - ...\n    \"\"\"\n\n    url = estatapi_url_parser.getStatsListURL(params_dict, format=\"json\")   \n    json_dict = get_json(url)\n    # pprint(json_dict)\n\n    if json_dict['GET_STATS_LIST']['DATALIST_INF']['NUMBER'] != 0:\n        tables = json_dict[\"GET_STATS_LIST\"][\"DATALIST_INF\"][\"TABLE_INF\"]\n    else:\n        tables = []\n    return tables\n\n\ndef parse_table_id(table):\n    return table[\"@id\"]\n\n\ndef parse_table_raw_size(table):\n    return table[\"OVERALL_TOTAL_NUMBER\"]\n\n\ndef parse_table_urls(table_id, table_raw_size, csv_raw_size=100000):\n    urls = []\n    for j in range(0, int(table_raw_size / csv_raw_size) + 1):\n        start_pos = j * csv_raw_size + 1\n        params_dict = {\n            \"appId\": appId,  # Application ID\n            \"lang\": \"E\",  #language(J:Japanese, E:English)\n            \"statsDataId\": str(table_id),  #Statistical table ID\n            \"startPosition\": start_pos,  #Start line\n            \"limit\": csv_raw_size,  #Number of data acquisitions\n            \"explanationGetFlg\": \"N\",  #Existence of commentary information(Y or N)\n            \"annotationGetFlg\": \"N\",  #Presence or absence of annotation information(Y or N)\n            \"metaGetFlg\": \"N\",  #Presence or absence of meta information(Y or N)\n            \"sectionHeaderFlg\": \"2\",  #CSV header flag(1:Get, 2:Get無)\n        }\n        url = estatapi_url_parser.getStatsDataURL(params_dict, format=\"csv\")\n        urls.append(url)\n    return urls","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-15T08:08:21.518639Z","iopub.execute_input":"2022-05-15T08:08:21.51887Z","iopub.status.idle":"2022-05-15T08:08:21.561478Z","shell.execute_reply.started":"2022-05-15T08:08:21.518841Z","shell.execute_reply":"2022-05-15T08:08:21.560801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the e-stat website we have these code for the main datatsets:","metadata":{}},{"cell_type":"code","source":"dict_map = {\n'00100401':'Machinery Orders Detail ',\n'00100406':'Indexes of Business Conditions Detail ',\n'00100409':'National Accounts Detail ',\n'00130002':'Statistics about Road Traffic Detail ',\n'00200502':'System of Social and Demographic Statistics Detail ',\n'00200521':'Population Census Detail ',\n'00200522':'Housing and Land Survey Detail ',\n'00200523':'Report on Internal Migration in Japan Detail ',\n'00200524':'Population Estimates Detail ',\n'00200531':'Labour Force Survey Detail ',\n'00200532':'Employment Status Survey Detail ',\n'00200533':'Survey on Time Use and Leisure Activities Detail ',\n'00200541':'Unincorporated Enterprise Survey Detail ',\n'00200544':'Monthly Survey on Service Industries Detail ',\n'00200545':'Survey on Service Industries Detail ',\n'00200551':'Establishment and Enterprise Census Detail ',\n'00200552':'Economic Census for Business Frame Detail ',\n'00200553':'Economic Census for Business Activity Detail ',\n'00200555':'Annual Business Survey Detail ',\n'00200561':'Family Income and Expenditure Survey Detail ',\n'00200564':'National Survey of Family Income, Consumption and Wealth Detail ',\n'00200566':'National Income and Expenditure Survey for one-person households Detail ',\n'00200567':'Consumption Trend Index Detail ',\n'00200571':'Retail price survey Detail ',\n'00200572':'National Survey of Prices Detail ',\n'00200573':'Consumer Price Index Detail ',\n'00200603':'Input-Output Tables for Japan Detail ',\n'00200604':'The Special Data Dissemination Standard Plus Detail ',\n'00350300':'Trade Statistics Detail ',\n'00350310':'Other Trade Related Statistics Detail ',\n'00350320':'Statistics on Arrival of Aircraft & Entrance of Vessels Detail ',\n'00400601':'Science Information Infrastructure Statistics of Colleges and Universities Detail ',\n'00450011':'Vital Statistics Detail ',\n'00450013':'Specified Report of Vital Statistics Detail ',\n'00450432':'Annual Population and Social Security Surveys (The National Survey on Migration) Detail ',\n'00500209':'Census of Agriculture and Forestry Detail ',\n'00500210':'Census of Fisheries Detail ',\n'00550035':'Current Survey of Mass Merchandise Specialty Retailers Detail ',\n'00550560':'Production by Kind of Iron and Steel Detail ',\n'00550710':'Spot LNG Price Statistics Detail ',\n'00551020':'Current Survey of Supply and Demand for Petroleum Products Detail ',\n'00600120':'Building Starts Detail ',\n'00600130':'Statistics on Construction Works Detail ',\n'00600260':'Quick Estimate of Construction Investment Detail ',\n'00600470':'Corporations Survey on Land and Buildings Detail ',\n'00600475':'Household Survey on Land Detail ',\n'00600480':'Corporations Survey on Buildings Detail ',\n'00600870':'Estimate of Construction Investment'}","metadata":{"execution":{"iopub.status.busy":"2022-05-15T08:08:21.562744Z","iopub.execute_input":"2022-05-15T08:08:21.563006Z","iopub.status.idle":"2022-05-15T08:08:21.579693Z","shell.execute_reply.started":"2022-05-15T08:08:21.562975Z","shell.execute_reply":"2022-05-15T08:08:21.578876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CSV_RAW_SIZE = 100000\n\nappId = \"481173f9e1eef4a259ebdd575636d389451fa5bf\" #Enter the application ID here\nestatapi_url_parser = EstatRestAPI_URLParser()  # URL Parser\n\nparams_dict = {\n    \"appId\": appId,\n    \"lang\": \"E\",\n    \"statsCode\": '00100406',\n}\n\n# list of tables\ntables = search_tables(appId,params_dict)\n\nif len(tables) == 0:\n    print(\"No tables were found.\")\nelif len(tables) == 1:\n    table_ids = [parse_table_id(tables[0])]\nelse:\n    table_ids = list(map(parse_table_id, tables))\n    \ntable_ids","metadata":{"execution":{"iopub.status.busy":"2022-05-15T08:08:21.580908Z","iopub.execute_input":"2022-05-15T08:08:21.581139Z","iopub.status.idle":"2022-05-15T08:08:23.875152Z","shell.execute_reply.started":"2022-05-15T08:08:21.581111Z","shell.execute_reply":"2022-05-15T08:08:23.874329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# list of urls\ntable_urls = []\ntable_raw_size = list(map(parse_table_raw_size, tables))\nfor i, table_id in enumerate(table_ids):\n    table_urls = table_urls + parse_table_urls(table_id, table_raw_size[i])\n\n\n# list of filepathes\nfilepathes = []\nfor i, table_id in enumerate(table_ids):\n    table_name = tables[i][\"TITLE_SPEC\"][\"TABLE_NAME\"]\n    table_dir = f\"./downloads/tmp/{table_name}_{table_id}\"\n    os.makedirs(table_dir, exist_ok=True)\n    for j in range(0, int(table_raw_size[i] / CSV_RAW_SIZE) + 1):\n        filepath = f\"{table_dir}/{table_name}_{table_id}_{j}.csv\"\n        filepathes.append(filepath)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T08:08:23.876546Z","iopub.execute_input":"2022-05-15T08:08:23.876791Z","iopub.status.idle":"2022-05-15T08:08:23.884724Z","shell.execute_reply.started":"2022-05-15T08:08:23.876761Z","shell.execute_reply":"2022-05-15T08:08:23.883908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"urlData = requests.get(table_urls[0]).content\nrawData = pd.read_csv(io.StringIO(urlData.decode('utf-8')))\n\nrawData.index = pd.to_datetime(rawData['time_code'].astype('str').str[:4]+'/'+rawData['time_code'].astype('str').str[-2:])\ndf = rawData[(rawData['tab_code']==100)&(rawData['cat01_code']==100)&(rawData['unit']=='2015=100')]\n\ndf_business = df['value'].rename('business_index')\n\nbase_plot(df.value,'Indexes of Business Conditions Detail','e-stat')\ncontext_plot(df.value,'Indexes of Business Conditions Detail','e-stat')","metadata":{"execution":{"iopub.status.busy":"2022-05-15T08:09:13.071486Z","iopub.execute_input":"2022-05-15T08:09:13.072148Z","iopub.status.idle":"2022-05-15T08:09:14.629697Z","shell.execute_reply.started":"2022-05-15T08:09:13.072107Z","shell.execute_reply":"2022-05-15T08:09:14.628737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='COVID'></a>\n# Japan COVID-19 Bulletin Board - COVID-19 Data Hub\n\nusage of a very intuitive API from Guidotti, E., Ardia, D., (2020), \"COVID-19 Data Hub\", Journal of Open Source Software 5(51):2376, doi: 10.21105/joss.02376.","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip install covid19dh\n\nfrom covid19dh import covid19\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-05-15T08:09:38.579825Z","iopub.execute_input":"2022-05-15T08:09:38.580046Z","iopub.status.idle":"2022-05-15T08:09:47.151132Z","shell.execute_reply.started":"2022-05-15T08:09:38.58002Z","shell.execute_reply":"2022-05-15T08:09:47.15016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x, src = covid19(\"Japan\")\nx = x.set_index('date')","metadata":{"execution":{"iopub.status.busy":"2022-05-15T08:09:47.153158Z","iopub.execute_input":"2022-05-15T08:09:47.153523Z","iopub.status.idle":"2022-05-15T08:09:47.300516Z","shell.execute_reply.started":"2022-05-15T08:09:47.153492Z","shell.execute_reply":"2022-05-15T08:09:47.299645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"context_plot(x['deaths'].diff().rolling(7).mean(),'deaths','COVID-19 Data Hub')","metadata":{"execution":{"iopub.status.busy":"2022-05-15T08:09:47.301764Z","iopub.execute_input":"2022-05-15T08:09:47.302163Z","iopub.status.idle":"2022-05-15T08:09:47.536563Z","shell.execute_reply.started":"2022-05-15T08:09:47.302111Z","shell.execute_reply":"2022-05-15T08:09:47.535643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"context_plot(x['workplace_closing'],'workplace_closing','COVID-19 Data Hub')\n\ndf_covid = x[['deaths','workplace_closing']]","metadata":{"execution":{"iopub.status.busy":"2022-05-15T08:09:47.537757Z","iopub.execute_input":"2022-05-15T08:09:47.538207Z","iopub.status.idle":"2022-05-15T08:09:47.721706Z","shell.execute_reply.started":"2022-05-15T08:09:47.538171Z","shell.execute_reply":"2022-05-15T08:09:47.721138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Merge Data\n\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom functools import reduce\n\n# compile the list of dataframes you want to merge\ndata_frames = [df_inflation,\ndf_trade,\ndf_yield,\ndf_debt,\ndf_employment,\ndf_business,\ndf_covid]\n\ndf_merged = reduce(lambda  left,right: pd.merge(left,right, left_index=True, right_index=True, how='outer'), data_frames)\ndf_merged = df_merged[df_merged.index > train_start]\n\ndf_merged.to_csv('Macro_data.csv')\n\ndf_merged = (df_merged - df_merged.mean())/df_merged.std()\n\nplt.plot(df_merged.ffill());\nplt.legend(df_merged.columns,prop={'size': 7});","metadata":{"execution":{"iopub.status.busy":"2022-05-15T08:09:49.124098Z","iopub.execute_input":"2022-05-15T08:09:49.124401Z","iopub.status.idle":"2022-05-15T08:09:49.58172Z","shell.execute_reply.started":"2022-05-15T08:09:49.124357Z","shell.execute_reply":"2022-05-15T08:09:49.581188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prediction","metadata":{}},{"cell_type":"code","source":"from statsmodels.tsa.vector_ar.var_model import VAR\nfrom datetime import date","metadata":{"execution":{"iopub.status.busy":"2022-05-15T08:09:51.384452Z","iopub.execute_input":"2022-05-15T08:09:51.384701Z","iopub.status.idle":"2022-05-15T08:09:52.373118Z","shell.execute_reply.started":"2022-05-15T08:09:51.384674Z","shell.execute_reply":"2022-05-15T08:09:52.372261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = df_merged.ffill().fillna(0)\n\nmodel = VAR(endog=data.values)\nmodel_fit = model.fit()\n\ntoday = date.today()\nndays = (pd.to_datetime('2022-10-07') - pd.to_datetime(today)).days\n\noutput = model_fit.forecast(data.values[-model_fit.k_ar:,:], ndays)\n\noutput = pd.DataFrame(output,columns=data.columns)\noutput.index = pd.date_range(today, periods=ndays).tolist()\n\ndf_Macro = pd.concat([df_merged,output])\ndf_Macro.to_csv('Macro_data_sup.csv')\n\nplt.plot(df_Macro.ffill().fillna(0));","metadata":{"execution":{"iopub.status.busy":"2022-05-15T08:09:53.453364Z","iopub.execute_input":"2022-05-15T08:09:53.453644Z","iopub.status.idle":"2022-05-15T08:09:53.473146Z","shell.execute_reply.started":"2022-05-15T08:09:53.453612Z","shell.execute_reply":"2022-05-15T08:09:53.472406Z"},"trusted":true},"execution_count":null,"outputs":[]}]}