{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Imports**","metadata":{}},{"cell_type":"code","source":"import gc\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport tqdm\nimport lightgbm\nimport time\n\nfrom tqdm import tqdm\nfrom sklearn.neighbors import NearestNeighbors","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-01T13:03:29.888518Z","iopub.execute_input":"2022-06-01T13:03:29.888876Z","iopub.status.idle":"2022-06-01T13:03:32.434249Z","shell.execute_reply.started":"2022-06-01T13:03:29.888782Z","shell.execute_reply":"2022-06-01T13:03:32.432956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Settings and functions**","metadata":{}},{"cell_type":"code","source":"pd.set_option('display.max_rows', 1000)\npd.set_option('display.max_columns', 1000)\n\ndef draw(image: np.array, ro=True):\n    plt.figure(figsize=(20, 12))\n    if ro:\n        plt.plot(image, 'ro')\n    else:\n        plt.plot(image)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T13:03:32.436496Z","iopub.execute_input":"2022-06-01T13:03:32.436999Z","iopub.status.idle":"2022-06-01T13:03:32.445525Z","shell.execute_reply.started":"2022-06-01T13:03:32.436936Z","shell.execute_reply":"2022-06-01T13:03:32.444247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Abbreviations**","metadata":{}},{"cell_type":"code","source":"D = 'Date'\nV = 'Volume'\nC = 'Close'\nT = 'Target'\nP = 'Prediction'\n\nSC = 'SecuritiesCode'\nAF = 'AdjustmentFactor'\nED = 'ExpectedDividend'\nSF = 'SupervisionFlag'","metadata":{"execution":{"iopub.status.busy":"2022-06-01T13:03:32.447648Z","iopub.execute_input":"2022-06-01T13:03:32.44836Z","iopub.status.idle":"2022-06-01T13:03:32.459925Z","shell.execute_reply.started":"2022-06-01T13:03:32.448307Z","shell.execute_reply":"2022-06-01T13:03:32.458722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Input pathes**","metadata":{}},{"cell_type":"code","source":"TRAIN_FILES = '../input/jpx-tokyo-stock-exchange-prediction/train_files'\nSUPPLEMENTAL_FILES = '../input/jpx-tokyo-stock-exchange-prediction/supplemental_files'\nEXAMPLE_TEST_FILES = '../input/jpx-tokyo-stock-exchange-prediction/example_test_files'\nDATA_SPECIFTICATIONS = '../input/jpx-tokyo-stock-exchange-prediction/data_specifications'\n\nSTOCK_PRICES = 'stock_prices.csv'\nSECONDARY_STOCK_PRICES = 'secondary_stock_prices.csv'\nTRADES = 'trades.csv'\nOPTIONS = 'options.csv'\nFINANCIALS = 'financials.csv' ","metadata":{"execution":{"iopub.status.busy":"2022-06-01T13:03:32.462613Z","iopub.execute_input":"2022-06-01T13:03:32.463228Z","iopub.status.idle":"2022-06-01T13:03:32.473377Z","shell.execute_reply.started":"2022-06-01T13:03:32.463179Z","shell.execute_reply":"2022-06-01T13:03:32.472465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Neighbors**","metadata":{}},{"cell_type":"code","source":"class TimeNeighbors:\n    def __init__(self, \n                name: str,\n                pivot: pd.DataFrame,\n                metric: str,\n                p: float,\n                test: bool = False):\n        pivot = pivot.fillna(pivot.mean())\n\n        self.name = name\n        self.metric = metric\n        self.p = p\n        self.dates = pivot.index.values\n        self.stocks = pivot.columns.values\n        \n        nrst = NearestNeighbors(n_neighbors=pivot.shape[0], p=p, metric=metric, metric_params=None)\n        nrst.fit(pivot)\n        if not test:\n            _, self.neighbors = nrst.kneighbors(pivot, return_distance=True)\n            self.neighbors_index = list(range(len(pivot)))\n        else:\n            _, self.neighbors = nrst.kneighbors(pivot.iloc[-1:], return_distance=True)\n            self.neighbors_index = [len(pivot)-1]\n\n    def generate_neighbors_feature_mean(self, \n                                   pivot: pd.DataFrame,\n                                   name: str,\n                                   count: int):\n        name = name + '=' + str(count) + 'mean'\n        features = []\n        main_df = pd.DataFrame(columns=[D, SC, name])\n        for neighbors_count, neighbors in zip(self.neighbors_index, self.neighbors):\n            #policy\n            dates = neighbors[:count]\n            #policy\n            \n            main_date = self.dates[neighbors_count]\n            \n            #filter\n            dates = dates[(dates <= neighbors_count) | (dates > neighbors_count + 3)]\n            #filter\n            \n            dates = self.dates[dates]\n            \n            df = pivot.loc[dates].mean()\n            df = df.rename(name).to_frame().reset_index()\n            df[D] = main_date\n            features.append(df)\n        \n        main_df = pd.concat([main_df] + features)\n        return main_df\n    \ntime_features = ['Close',\n 'Close.diff7', \n 'Close.diff14', \n 'Close.diff28',\n 'Close.rolling3',\n 'Close.rolling7',\n 'Close.rolling14',\n 'Close.rolling28',\n 'Volume.rolling7',\n 'Volume.rolling14',\n 'Volume.rolling28']\n\nneighbors_aggregation_counts = [3, 5, 8, 10, 12, 14, 16, 18, 22, 24]","metadata":{"execution":{"iopub.status.busy":"2022-06-01T13:03:32.475176Z","iopub.execute_input":"2022-06-01T13:03:32.475728Z","iopub.status.idle":"2022-06-01T13:03:32.516469Z","shell.execute_reply.started":"2022-06-01T13:03:32.475683Z","shell.execute_reply":"2022-06-01T13:03:32.515559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_stock_prices = pd.read_feather('../input/jpx-dataset/train_stock_prices_v2.f').iloc[:, 1:]\ntrain_stock_prices[SC] = train_stock_prices[SC].apply(lambda x: int(x[1:]))","metadata":{"execution":{"iopub.status.busy":"2022-06-01T13:03:32.518199Z","iopub.execute_input":"2022-06-01T13:03:32.518933Z","iopub.status.idle":"2022-06-01T13:03:56.005072Z","shell.execute_reply.started":"2022-06-01T13:03:32.518875Z","shell.execute_reply":"2022-06-01T13:03:56.004202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_stock_prices = train_stock_prices.groupby(D).filter(lambda x: len(x) > 1000)\ntrain_stock_prices_dates = train_stock_prices[[D, SC, T]]\nx = train_stock_prices.iloc[:, 13:].astype('float32')\ny = train_stock_prices[T].astype('float32')","metadata":{"execution":{"iopub.status.busy":"2022-06-01T13:03:56.006408Z","iopub.execute_input":"2022-06-01T13:03:56.006724Z","iopub.status.idle":"2022-06-01T13:04:00.628103Z","shell.execute_reply.started":"2022-06-01T13:03:56.006681Z","shell.execute_reply":"2022-06-01T13:04:00.627308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T13:04:00.629278Z","iopub.execute_input":"2022-06-01T13:04:00.629552Z","iopub.status.idle":"2022-06-01T13:04:00.763985Z","shell.execute_reply.started":"2022-06-01T13:04:00.62952Z","shell.execute_reply":"2022-06-01T13:04:00.763162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Folds**","metadata":{}},{"cell_type":"code","source":"folds_val_begins = ['2021-11-15', '2021-10-28', '2021-10-10', '2021-09-22', '2021-09-04']\nfolds_val_ends = ['2021-12-03', '2021-11-15', '2021-10-28', '2021-10-10', '2021-09-22']\n\nfolds = []\nfor val_begin, val_end in zip(folds_val_begins, folds_val_ends):\n    train_part = np.where(train_stock_prices_dates[D] < val_begin)[0]\n    val_part = np.where((train_stock_prices_dates[D] >= val_begin) & (train_stock_prices_dates[D] <= val_end))[0]\n    folds.append((train_part, val_part))\n    print(len(train_part), len(val_part))","metadata":{"execution":{"iopub.status.busy":"2022-06-01T13:04:00.765265Z","iopub.execute_input":"2022-06-01T13:04:00.765507Z","iopub.status.idle":"2022-06-01T13:04:05.605205Z","shell.execute_reply.started":"2022-06-01T13:04:00.765469Z","shell.execute_reply":"2022-06-01T13:04:05.604327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Model training**","metadata":{}},{"cell_type":"code","source":"def mse(y_true, y_pred):\n    return np.sqrt(np.mean(np.square((y_true - y_pred))))\n\ndef feval(preds, train_data):\n    labels = train_data.get_label()\n    return 'MSE', round(mse(y_true = labels, y_pred = preds), 5), False\n\nparams = {\n    'objective': 'regression',\n    'verbose': 0,\n    'metric': '',\n    'reg_alpha': 5,\n    'reg_lambda': 5,\n    'min_data_in_leaf': 1000,\n    'max_depth': -1,\n    'num_leaves': 128,\n    'colsample_bytree': 0.3,\n    'learning_rate': 0.05\n}\n\ndataset = lightgbm.Dataset(x, y)\nret = lightgbm.cv(params, dataset, num_boost_round=240, folds=folds, stratified=False, return_cvbooster=True, verbose_eval=20)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T13:04:05.6076Z","iopub.execute_input":"2022-06-01T13:04:05.607837Z","iopub.status.idle":"2022-06-01T13:05:24.16738Z","shell.execute_reply.started":"2022-06-01T13:04:05.607809Z","shell.execute_reply":"2022-06-01T13:05:24.166072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Feature importance**","metadata":{}},{"cell_type":"code","source":"ret['cvbooster'].feature_importance(importance_type='gain')\nbooster_feature_names = ret['cvbooster'].boosters[0].feature_name()\ndf = pd.DataFrame(data=ret['cvbooster'].feature_importance(importance_type='gain'), columns=booster_feature_names)\ndf = df.mean().sort_values(ascending=False)\ndf","metadata":{"execution":{"iopub.status.busy":"2022-06-01T13:05:24.168262Z","iopub.status.idle":"2022-06-01T13:05:24.168651Z","shell.execute_reply.started":"2022-06-01T13:05:24.168456Z","shell.execute_reply":"2022-06-01T13:05:24.168475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Validation data eval**","metadata":{}},{"cell_type":"code","source":"for i in range(len(folds_val_begins)):\n    val_fold = folds[i][1]\n    prediction = ret['cvbooster'].predict(x.iloc[val_fold])[i]\n    main = train_stock_prices_dates.iloc[val_fold]\n    main['Prediction'] = prediction\n    top200_targets = main.sort_values(T, ascending=False)[:200]\n    \n    def calc_spread_return_per_day(df):\n        top200 = df.sort_values(T, ascending=False)[:200]\n        bottom200 = df.sort_values(T)[:200]\n\n        linear_function_2_1 = np.linspace(2, 1, num=200)\n        s_up = np.sum(top200[T].values * linear_function_2_1) / np.mean(linear_function_2_1)\n        s_down = np.sum(bottom200[T].values * linear_function_2_1) / np.mean(linear_function_2_1)\n        r_day = s_up - s_down\n        return r_day\n\n    spread_returns = main.groupby(D).apply(calc_spread_return_per_day)\n    spread_returns = np.mean(spread_returns) / np.std(spread_returns)\n    print(f'fold targets {i}:', spread_returns)\n    \n    def calc_spread_return_per_day(df):\n        top200 = df.sort_values(P, ascending=False)[:200]\n        bottom200 = df.sort_values(P)[:200]\n\n        linear_function_2_1 = np.linspace(2, 1, num=200)\n        s_up = np.sum(top200[T].values * linear_function_2_1) / np.mean(linear_function_2_1)\n        s_down = np.sum(bottom200[T].values * linear_function_2_1) / np.mean(linear_function_2_1)\n        r_day = s_up - s_down\n        return r_day\n\n    spread_returns = main.groupby(D).apply(calc_spread_return_per_day)\n    spread_returns = np.mean(spread_returns) / np.std(spread_returns)\n    print(f'fold {i}:', spread_returns)\n    \n    \n    def calc_top_accuracy_per_day(df):\n        top200_prediction = df.sort_values(P, ascending=False)[:200][SC].values\n        top200_target = df.sort_values(T, ascending=False)[:200][SC].values\n\n        bot200_prediction = df.sort_values(P, ascending=True)[:200][SC].values\n        bot200_target = df.sort_values(T, ascending=True)[:200][SC].values\n\n        return len(np.intersect1d(top200_prediction, top200_target)), len(np.intersect1d(bot200_prediction, bot200_target))\n\n    accuracy = main.groupby(D).apply(calc_top_accuracy_per_day)\n    print(f'fold {i}:', 'mean', tuple(map(np.mean, zip(*accuracy))), 'std', tuple(map(np.std, zip(*accuracy))))\n    print('')","metadata":{"execution":{"iopub.status.busy":"2022-06-01T13:05:24.170287Z","iopub.status.idle":"2022-06-01T13:05:24.171175Z","shell.execute_reply.started":"2022-06-01T13:05:24.170909Z","shell.execute_reply":"2022-06-01T13:05:24.170934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T13:05:24.172275Z","iopub.status.idle":"2022-06-01T13:05:24.172613Z","shell.execute_reply.started":"2022-06-01T13:05:24.172438Z","shell.execute_reply":"2022-06-01T13:05:24.172462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Test**","metadata":{}},{"cell_type":"code","source":"last_test_day = '2022-02-22'\nsupplemental_stock_prices = pd.read_csv('../input/jpx-tokyo-stock-exchange-prediction/supplemental_files/stock_prices.csv')\nsupplemental_stock_prices = supplemental_stock_prices[supplemental_stock_prices[D] <= last_test_day]","metadata":{"execution":{"iopub.status.busy":"2022-06-01T13:05:32.861286Z","iopub.execute_input":"2022-06-01T13:05:32.862065Z","iopub.status.idle":"2022-06-01T13:05:33.533776Z","shell.execute_reply.started":"2022-06-01T13:05:32.862007Z","shell.execute_reply":"2022-06-01T13:05:33.53294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def transform_1(stock_prices_last, test_day):\n    df = stock_prices_last.copy()\n    df_grouped = df.groupby(SC)\n    df['Close.diff1'] = df_grouped[C].diff(1)\n    df['Close.diff3'] = df_grouped[C].diff(3)\n    df['Close.diff7'] = df_grouped[C].diff(7)\n    df['Close.diff14'] = df_grouped[C].diff(14)\n    df['Close.diff28'] = df_grouped[C].diff(28)\n    \n    df['Close.diff1relative'] = df['Close.diff1'] / df_grouped[C].shift(1)\n    df['Close.diff3relative'] = df['Close.diff3'] / df_grouped[C].shift(3)\n    df['Close.diff7relative'] = df['Close.diff7'] / df_grouped[C].shift(7)\n    \n    df['Close.rolling3'] = df_grouped[C].rolling(3).mean().reset_index(0, drop=True).sort_index()\n    df['Close.rolling7'] = df_grouped[C].rolling(7).mean().reset_index(0, drop=True).sort_index()\n    df['Close.rolling14'] = df_grouped[C].rolling(14).mean().reset_index(0, drop=True).sort_index()\n    df['Close.rolling28'] = df_grouped[C].rolling(28).mean().reset_index(0, drop=True).sort_index()\n    \n    df['Volume.rolling7'] = df_grouped[V].rolling(7).mean().reset_index(0, drop=True).sort_index()\n    df['Volume.rolling14'] = df_grouped[V].rolling(14).mean().reset_index(0, drop=True).sort_index()\n    df['Volume.rolling28'] = df_grouped[V].rolling(28).mean().reset_index(0, drop=True).sort_index()\n    \n    close_features = ['Close.diff1', 'Close.diff3', 'Close.diff7', 'Close.diff14', 'Close.diff28', \n                      'Close.diff1relative', 'Close.diff3relative', 'Close.diff7relative', \n                      'Close.rolling3', 'Close.rolling7', 'Close.rolling14', 'Close.rolling28', \n                      'Volume.rolling7', 'Volume.rolling14', 'Volume.rolling28']\n    \n    test_day_close_features = df.loc[df[D] == test_day, [D, SC] + close_features].copy().reset_index(drop=True)\n    \n    return test_day_close_features\n    \ndef transform_2(test_stock_prices, test_day):\n    test_day_neighbors_features = test_stock_prices.loc[test_stock_prices[D] == test_day, [D, SC]].copy()\n    \n    target_name = 'Close.diff1relative'\n    target_pivot = pd.concat([train_stock_prices.pivot(D, SC, target_name), test_stock_prices.pivot(D, SC, target_name)])\n    for time_feature in time_features:\n        pivot, test_pivot = train_stock_prices.pivot(D, SC, time_feature), test_stock_prices.pivot(D, SC, time_feature)\n        neighbors_object = TimeNeighbors(name='time_neighbors.' + time_feature, \n                                         pivot=pd.concat([pivot, test_pivot]), \n                                         metric='canberra', \n                                         p=2, \n                                         test=True)\n        for count in neighbors_aggregation_counts:\n            column = neighbors_object.generate_neighbors_feature_mean(pivot=target_pivot, name=neighbors_object.name + '=' + target_name, count=count)\n            test_day_neighbors_features = test_day_neighbors_features.merge(column, on=[D, SC], how='left')\n    \n    return test_day_neighbors_features\n\n            \nlast_30_days = pd.unique(train_stock_prices[D])[-30:]\ntrain_stock_prices_last = train_stock_prices.loc[train_stock_prices[D].isin(last_30_days)].copy()\n\ntest_stock_prices = pd.DataFrame()\ntotal = pd.DataFrame()\nfor test_day in pd.unique(supplemental_stock_prices[D]):\n    a = time.time()\n    test_day_stock_prices = supplemental_stock_prices.loc[supplemental_stock_prices[D] == test_day].copy()\n    \n    train_stock_prices_last = train_stock_prices_last.append(test_day_stock_prices).reset_index(drop=True)\n    test_day_close_features = transform_1(train_stock_prices_last, test_day)\n    train_stock_prices_last.drop(train_stock_prices_last.loc[train_stock_prices_last[D] == pd.unique(train_stock_prices_last[D])[0]].index, inplace=True)\n    train_stock_prices_last.reset_index(drop=True, inplace=True)\n    \n    test_day_stock_prices = test_day_stock_prices.merge(test_day_close_features, on=[D, SC], how='left')\n    test_stock_prices = test_stock_prices.append(test_day_stock_prices).reset_index(drop=True)\n    \n    test_day_neighbors_features = transform_2(test_stock_prices, test_day)\n    test_day_stock_prices = test_day_stock_prices.merge(test_day_neighbors_features, on=[D, SC], how='left')\n    \n    x = test_day_stock_prices.loc[:, booster_feature_names].copy()\n    predictions = ret['cvbooster'].predict(x)\n    prediction = np.zeros((predictions[0].shape))\n    for p in predictions:\n        prediction += p\n    prediction /= len(predictions)\n    test_day_stock_prices[P] = prediction\n    total = total.append(test_day_stock_prices.loc[:, [D, SC, T, P]].copy()).reset_index(drop=True)\n    \n    print(test_day)\n    print('a1', time.time() - a)\n    print('')\ndisplay(total)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T13:05:24.175384Z","iopub.status.idle":"2022-06-01T13:05:24.175722Z","shell.execute_reply.started":"2022-06-01T13:05:24.175548Z","shell.execute_reply":"2022-06-01T13:05:24.175571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Test eval**","metadata":{}},{"cell_type":"code","source":"def calc_spread_return_per_day(df):\n    top200 = df.sort_values(P, ascending=False)[:200]\n    bottom200 = df.sort_values(P)[:200]\n\n    linear_function_2_1 = np.linspace(2, 1, num=200)\n    s_up = np.sum(top200[T].values * linear_function_2_1) / np.mean(linear_function_2_1)\n    s_down = np.sum(bottom200[T].values * linear_function_2_1) / np.mean(linear_function_2_1)\n    r_day = s_up - s_down\n    return r_day\n\nspread_returns = total.groupby(D).apply(calc_spread_return_per_day)\n#display(spread_returns)\nprint(np.mean(spread_returns), np.std(spread_returns))\nspread_returns = np.mean(spread_returns) / np.std(spread_returns)\nprint(f'test:', spread_returns)\n    \n    \ndef calc_top_accuracy_per_day(df):\n    top200_prediction = df.sort_values(P, ascending=False)[:200][SC].values\n    top200_target = df.sort_values(T, ascending=False)[:200][SC].values\n\n    bot200_prediction = df.sort_values(P, ascending=True)[:200][SC].values\n    bot200_target = df.sort_values(T, ascending=True)[:200][SC].values\n\n    return len(np.intersect1d(top200_prediction, top200_target)), len(np.intersect1d(bot200_prediction, bot200_target))\n\naccuracy = total.groupby(D).apply(calc_top_accuracy_per_day)\nprint(f'test:', 'mean', tuple(map(np.mean, zip(*accuracy))), 'std', tuple(map(np.std, zip(*accuracy))))\nprint('')","metadata":{"execution":{"iopub.status.busy":"2022-06-01T13:05:36.874516Z","iopub.execute_input":"2022-06-01T13:05:36.874883Z","iopub.status.idle":"2022-06-01T13:05:36.955931Z","shell.execute_reply.started":"2022-06-01T13:05:36.874847Z","shell.execute_reply":"2022-06-01T13:05:36.954714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Random rank**","metadata":{}},{"cell_type":"code","source":"def calc_spread_return_per_day(df):\n    mean_top = 30\n    mean_bot = 30\n    std_top = 30\n    std_bot = 30\n    top_random_number = max(1, int(np.random.normal(loc=mean_top, scale=std_top)))\n    bot_random_number = max(1, int(np.random.normal(loc=mean_bot, scale=std_bot)))\n                         \n    top200_target = df.sort_values(T, ascending=False)[:200][SC].values\n    bot200_target = df.sort_values(T, ascending=True)[:200][SC].values\n    \n    top200_target_choice = np.random.choice(top200_target, replace=False, size=top_random_number)\n    bot200_target_choice = np.random.choice(bot200_target, replace=False, size=bot_random_number)\n    \n    sc = pd.unique(df[SC])\n    sc = np.setdiff1d(sc, top200_target)\n    sc = np.setdiff1d(sc, bot200_target_choice)\n    top_choice = np.random.choice(sc, replace=False, size=200-top_random_number)\n    \n    sc = pd.unique(df[SC])\n    sc = np.setdiff1d(sc, bot200_target)\n    sc = np.setdiff1d(sc, top200_target_choice)\n    sc = np.setdiff1d(sc, top_choice)\n    bot_choice = np.random.choice(sc, replace=False, size=200-bot_random_number)\n\n    top_choice = np.union1d(top_choice, top200_target_choice)\n    bot_choice = np.union1d(bot_choice, bot200_target_choice)\n    np.random.shuffle(top_choice)\n    np.random.shuffle(bot_choice)\n    df = df.set_index(SC, drop=True).copy()\n    top200 = df.loc[top_choice]\n    bottom200 = df.loc[bot_choice]\n    \n    linear_function_2_1 = np.linspace(2, 1, num=200)\n    s_up = np.sum(top200[T].values * linear_function_2_1) / np.mean(linear_function_2_1)\n    s_down = np.sum(bottom200[T].values * linear_function_2_1) / np.mean(linear_function_2_1)\n    r_day = s_up - s_down\n    return r_day, top_random_number, bot_random_number \n\nspread_returns = supplemental_stock_prices.groupby(D).apply(calc_spread_return_per_day)\ndisplay(spread_returns)\nprint('mean', tuple(map(np.mean, zip(*spread_returns))), 'std', tuple(map(np.std, zip(*spread_returns))))\nspread_returns = tuple(map(np.mean, zip(*spread_returns)))[0] / tuple(map(np.std, zip(*spread_returns)))[0]\nprint(f'test:', spread_returns)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T14:43:20.376488Z","iopub.execute_input":"2022-06-01T14:43:20.376846Z","iopub.status.idle":"2022-06-01T14:43:20.688714Z","shell.execute_reply.started":"2022-06-01T14:43:20.376811Z","shell.execute_reply":"2022-06-01T14:43:20.687756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"calc_spread_return_per_day(supplemental_stock_prices[supplemental_stock_prices[D] == '2021-12-06'])","metadata":{"execution":{"iopub.status.busy":"2022-06-01T14:24:20.995218Z","iopub.execute_input":"2022-06-01T14:24:20.99557Z","iopub.status.idle":"2022-06-01T14:24:21.031499Z","shell.execute_reply.started":"2022-06-01T14:24:20.995527Z","shell.execute_reply":"2022-06-01T14:24:21.030439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"supplemental_stock_prices[supplemental_stock_prices[D] == '2021-12-06']","metadata":{"execution":{"iopub.status.busy":"2022-06-01T13:06:22.091844Z","iopub.execute_input":"2022-06-01T13:06:22.092303Z","iopub.status.idle":"2022-06-01T13:06:22.164599Z","shell.execute_reply.started":"2022-06-01T13:06:22.092252Z","shell.execute_reply":"2022-06-01T13:06:22.163699Z"},"trusted":true},"execution_count":null,"outputs":[]}]}