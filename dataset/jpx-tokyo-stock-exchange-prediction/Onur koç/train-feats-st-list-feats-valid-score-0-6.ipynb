{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **WARNINGS**!","metadata":{}},{"cell_type":"markdown","source":"## Reference","metadata":{}},{"cell_type":"markdown","source":"* https://www.kaggle.com/code/metathesis/feature-engineering-training-with-ta","metadata":{}},{"cell_type":"markdown","source":"\n\n## Which features ?\n","metadata":{}},{"cell_type":"markdown","source":"*** Merging training features and some of stock list features**","metadata":{}},{"cell_type":"code","source":"#best_features","metadata":{"execution":{"iopub.status.busy":"2022-06-17T05:46:58.959915Z","iopub.execute_input":"2022-06-17T05:46:58.960322Z","iopub.status.idle":"2022-06-17T05:46:58.984857Z","shell.execute_reply.started":"2022-06-17T05:46:58.960222Z","shell.execute_reply":"2022-06-17T05:46:58.984033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Score ?","metadata":{}},{"cell_type":"markdown","source":"* **Validation Score = 0.52**","metadata":{}},{"cell_type":"markdown","source":"## When ı use only training features, Score?","metadata":{}},{"cell_type":"markdown","source":"* **Validation Score = 0.1**","metadata":{}},{"cell_type":"markdown","source":"## Where is the Feature İmportance ?","metadata":{}},{"cell_type":"markdown","source":"* **You can find the feature importance at the end of the notebook**","metadata":{}},{"cell_type":"markdown","source":"## Select best features (18) and parameter tuning","metadata":{}},{"cell_type":"markdown","source":"* **Score : 0.64**","metadata":{}},{"cell_type":"code","source":"!pip install --upgrade ta","metadata":{"execution":{"iopub.status.busy":"2022-06-17T05:46:59.007909Z","iopub.execute_input":"2022-06-17T05:46:59.008446Z","iopub.status.idle":"2022-06-17T05:47:12.80449Z","shell.execute_reply.started":"2022-06-17T05:46:59.008393Z","shell.execute_reply":"2022-06-17T05:47:12.803268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df\n\n\ndef import_data(file):\n    \"\"\"create a dataframe and optimize its memory usage\"\"\"\n    df = pd.read_csv(file, parse_dates=True, keep_date_col=True)\n    df = reduce_mem_usage(df)\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-06-17T06:10:22.938957Z","iopub.execute_input":"2022-06-17T06:10:22.939471Z","iopub.status.idle":"2022-06-17T06:10:22.958022Z","shell.execute_reply.started":"2022-06-17T06:10:22.939407Z","shell.execute_reply":"2022-06-17T06:10:22.957044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom decimal import ROUND_HALF_UP, Decimal\n\nimport numpy as np\nimport pandas as pd\nfrom lightgbm import LGBMRegressor\nfrom tqdm import tqdm\n\nimport ta\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nmpl.style.use('seaborn')","metadata":{"papermill":{"duration":2.039395,"end_time":"2022-04-02T13:51:41.227973","exception":false,"start_time":"2022-04-02T13:51:39.188578","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-17T06:10:25.852011Z","iopub.execute_input":"2022-06-17T06:10:25.852533Z","iopub.status.idle":"2022-06-17T06:10:25.860899Z","shell.execute_reply.started":"2022-06-17T06:10:25.852494Z","shell.execute_reply":"2022-06-17T06:10:25.859386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set base_dir to load data\nbase_dir = \"../input/jpx-tokyo-stock-exchange-prediction\"\n# There are three types of stock_price.csv\n# We use one in the train_files folder for this notebook.\ntrain_files_dir = f\"{base_dir}/train_files\"","metadata":{"papermill":{"duration":0.053109,"end_time":"2022-04-02T13:51:41.466618","exception":false,"start_time":"2022-04-02T13:51:41.413509","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-17T06:10:29.032069Z","iopub.execute_input":"2022-06-17T06:10:29.032354Z","iopub.status.idle":"2022-06-17T06:10:29.036801Z","shell.execute_reply.started":"2022-06-17T06:10:29.032324Z","shell.execute_reply":"2022-06-17T06:10:29.036025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def adjust_price(price):\n    \"\"\"\n    Args:\n        price (pd.DataFrame)  : pd.DataFrame include stock_price\n    Returns:\n        price DataFrame (pd.DataFrame): stock_price with generated AdjustedClose\n    \"\"\"\n    # transform Date column into datetime\n    price.loc[: ,\"Date\"] = pd.to_datetime(price.loc[: ,\"Date\"], format=\"%Y-%m-%d\")\n\n    def generate_adjusted_close(df):\n        \"\"\"\n        Args:\n            df (pd.DataFrame)  : stock_price for a single SecuritiesCode\n        Returns:\n            df (pd.DataFrame): stock_price with AdjustedClose for a single SecuritiesCode\n        \"\"\"\n        # sort data to generate CumulativeAdjustmentFactor\n        df = df.sort_values(\"Date\", ascending=False)\n        # generate CumulativeAdjustmentFactor\n        df.loc[:, \"CumulativeAdjustmentFactor\"] = df[\"AdjustmentFactor\"].cumprod()\n        # generate AdjustedClose\n        df.loc[:, \"AdjustedClose\"] = (\n            df[\"CumulativeAdjustmentFactor\"] * df[\"Close\"]\n        ).map(lambda x: float(\n            Decimal(str(x)).quantize(Decimal('0.1'), rounding=ROUND_HALF_UP)\n        ))\n        # reverse order\n        df = df.sort_values(\"Date\")\n        # to fill AdjustedClose, replace 0 into np.nan\n        df.loc[df[\"AdjustedClose\"] == 0, \"AdjustedClose\"] = np.nan\n        # forward fill AdjustedClose\n        df.loc[:, \"AdjustedClose\"] = df.loc[:, \"AdjustedClose\"].ffill()\n        return df\n\n    # generate AdjustedClose\n    price = price.sort_values([\"SecuritiesCode\", \"Date\"])\n    price = price.groupby(\"SecuritiesCode\").apply(generate_adjusted_close).reset_index(drop=True)\n\n    price.set_index(\"Date\", inplace=True)\n    return price","metadata":{"execution":{"iopub.status.busy":"2022-06-17T06:10:32.740281Z","iopub.execute_input":"2022-06-17T06:10:32.74134Z","iopub.status.idle":"2022-06-17T06:10:32.752162Z","shell.execute_reply.started":"2022-06-17T06:10:32.741296Z","shell.execute_reply":"2022-06-17T06:10:32.751136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load stock price data\ndf_price = pd.read_csv(f\"{train_files_dir}/stock_prices.csv\")\n\n# generate AdjustedClose\ndf_price = adjust_price(df_price)","metadata":{"papermill":{"duration":27.990189,"end_time":"2022-04-02T13:52:09.791984","exception":false,"start_time":"2022-04-02T13:51:41.801795","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-17T06:10:37.79634Z","iopub.execute_input":"2022-06-17T06:10:37.796674Z","iopub.status.idle":"2022-06-17T06:11:05.32878Z","shell.execute_reply.started":"2022-06-17T06:10:37.796639Z","shell.execute_reply":"2022-06-17T06:11:05.327642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from ta import add_all_ta_features\nfrom ta.utils import dropna","metadata":{"execution":{"iopub.status.busy":"2022-06-17T06:11:05.330177Z","iopub.execute_input":"2022-06-17T06:11:05.330408Z","iopub.status.idle":"2022-06-17T06:11:05.33511Z","shell.execute_reply.started":"2022-06-17T06:11:05.33038Z","shell.execute_reply":"2022-06-17T06:11:05.334052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pre-processing for model building\n\nThis notebook presents a simple model using LightGBM.\n\nFirst, the features are generated using the price change and historical volatility described above.","metadata":{"papermill":{"duration":0.056286,"end_time":"2022-04-02T13:52:12.515867","exception":false,"start_time":"2022-04-02T13:52:12.459581","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Add Stock List Features to Train Features, but How? ","metadata":{}},{"cell_type":"code","source":"df_stocklist = pd.read_csv(\"/kaggle/input/jpx-tokyo-stock-exchange-prediction/stock_list.csv\")\ndf_stocklist=df_stocklist[df_stocklist[\"Universe0\"]==True]\n\ndf_stocklist.replace(\"-\", np.nan,inplace=True)\ndf_stocklist.drop(columns=[\"Name\"],inplace=True)\n\nfor col in ['33SectorCode', '17SectorCode', 'NewIndexSeriesSizeCode']:\n        df_stocklist[col] = df_stocklist[col].astype(float)\n        \nobj_df = df_stocklist.select_dtypes(include=['object']).copy()\n\ndf_stocklist = pd.get_dummies(df_stocklist, columns=obj_df.columns)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-17T06:11:14.506158Z","iopub.execute_input":"2022-06-17T06:11:14.506534Z","iopub.status.idle":"2022-06-17T06:11:14.560269Z","shell.execute_reply.started":"2022-06-17T06:11:14.506497Z","shell.execute_reply":"2022-06-17T06:11:14.559197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_price.reset_index(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-17T06:11:17.68154Z","iopub.execute_input":"2022-06-17T06:11:17.681836Z","iopub.status.idle":"2022-06-17T06:11:17.691735Z","shell.execute_reply.started":"2022-06-17T06:11:17.681805Z","shell.execute_reply":"2022-06-17T06:11:17.690722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_stock_list = df_stocklist.copy()\n_stock_list.rename(columns={'Close': 'Close_x'}, inplace=True)\ndf_price = df_price.merge(_stock_list, on='SecuritiesCode', how=\"left\")","metadata":{"execution":{"iopub.status.busy":"2022-06-17T06:11:19.620069Z","iopub.execute_input":"2022-06-17T06:11:19.620848Z","iopub.status.idle":"2022-06-17T06:11:21.388495Z","shell.execute_reply.started":"2022-06-17T06:11:19.620802Z","shell.execute_reply":"2022-06-17T06:11:21.387761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_price.set_index(\"Date\",inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-17T06:11:23.230304Z","iopub.execute_input":"2022-06-17T06:11:23.231681Z","iopub.status.idle":"2022-06-17T06:11:23.238258Z","shell.execute_reply.started":"2022-06-17T06:11:23.231606Z","shell.execute_reply":"2022-06-17T06:11:23.237307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"liste = list(df_price.columns[:10])+list(df_price.columns[11:])  # get rid of Target (10)","metadata":{"execution":{"iopub.status.busy":"2022-06-17T06:11:26.601067Z","iopub.execute_input":"2022-06-17T06:11:26.601833Z","iopub.status.idle":"2022-06-17T06:11:26.607121Z","shell.execute_reply.started":"2022-06-17T06:11:26.60178Z","shell.execute_reply":"2022-06-17T06:11:26.606407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_features_for_predict(price, code):\n    \"\"\"\n    Args:\n        price (pd.DataFrame)  : pd.DataFrame include stock_price\n        code (int)  : A local code for a listed company\n    Returns:\n        feature DataFrame (pd.DataFrame)\n    \"\"\"\n    close_col = \"AdjustedClose\"\n    \n    feats = price.loc[price[\"SecuritiesCode\"] == code].copy()\n    \n    liste = list(df_price.columns[:10])+list(df_price.columns[11:])\n    \n    # Adds all 42 features\n    feats = df_price.loc[df_price[\"SecuritiesCode\"] == code, liste].copy()\n\n    # To only add specific features\n    # Example: https://github.com/bukosabino/ta/blob/master/examples_to_use/bollinger_band_features_example.py\n    # df['bb_bbm'] = indicator_bb.bollinger_mavg()\n    # df['bb_bbh'] = indicator_bb.bollinger_hband()\n    # df['bb_bbl'] = indicator_bb.bollinger_lband()\n    \n    # filling data for nan and inf\n    feats = feats.fillna(0)\n    feats = feats.replace([np.inf, -np.inf], 0)\n    # drop AdjustedClose column\n    feats = feats.drop([close_col], axis=1)\n\n    return feats","metadata":{"papermill":{"duration":0.069843,"end_time":"2022-04-02T13:52:12.754025","exception":false,"start_time":"2022-04-02T13:52:12.684182","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-17T06:11:48.547731Z","iopub.execute_input":"2022-06-17T06:11:48.548028Z","iopub.status.idle":"2022-06-17T06:11:48.558093Z","shell.execute_reply.started":"2022-06-17T06:11:48.547991Z","shell.execute_reply":"2022-06-17T06:11:48.557136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fetch prediction target SecuritiesCodes\ncodes = sorted(df_price[\"SecuritiesCode\"].unique())\nlen(codes)","metadata":{"papermill":{"duration":0.079997,"end_time":"2022-04-02T13:52:12.891901","exception":false,"start_time":"2022-04-02T13:52:12.811904","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-17T06:11:55.9289Z","iopub.execute_input":"2022-06-17T06:11:55.929368Z","iopub.status.idle":"2022-06-17T06:11:55.954729Z","shell.execute_reply.started":"2022-06-17T06:11:55.929333Z","shell.execute_reply":"2022-06-17T06:11:55.953678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generate feature\nbuff = []\nfor code in tqdm(codes):\n    feat = get_features_for_predict(df_price, code)\n    buff.append(feat)\nfeature = pd.concat(buff)","metadata":{"papermill":{"duration":26.036168,"end_time":"2022-04-02T13:52:38.984984","exception":false,"start_time":"2022-04-02T13:52:12.948816","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-17T06:12:00.678118Z","iopub.execute_input":"2022-06-17T06:12:00.678425Z","iopub.status.idle":"2022-06-17T06:12:37.751965Z","shell.execute_reply.started":"2022-06-17T06:12:00.678392Z","shell.execute_reply":"2022-06-17T06:12:37.750808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Label creation\n\nNext, we obtain the labels to be used for training the model (this is where we load and split the label data).","metadata":{"papermill":{"duration":0.145502,"end_time":"2022-04-02T13:52:39.586544","exception":false,"start_time":"2022-04-02T13:52:39.441042","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def get_label(price, code):\n    \"\"\" Labelizer\n    Args:\n        price (pd.DataFrame): dataframe of stock_price.csv\n        code (int): Local Code in the universe\n    Returns:\n        df (pd.DataFrame): label data\n    \"\"\"\n    df = price.loc[price[\"SecuritiesCode\"] == code].copy()\n    df.loc[:, \"label\"] = df[\"Target\"]\n\n    return df.loc[:, [\"SecuritiesCode\", \"label\"]]","metadata":{"papermill":{"duration":0.154664,"end_time":"2022-04-02T13:52:40.181476","exception":false,"start_time":"2022-04-02T13:52:40.026812","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-17T06:12:37.754032Z","iopub.execute_input":"2022-06-17T06:12:37.75434Z","iopub.status.idle":"2022-06-17T06:12:37.761592Z","shell.execute_reply.started":"2022-06-17T06:12:37.754304Z","shell.execute_reply":"2022-06-17T06:12:37.760494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# split data into TRAIN and TEST\nTRAIN_END = \"2019-12-31\"\n# We put a week gap between TRAIN_END and TEST_START\n# to avoid leakage of test data information from label\nTEST_START = \"2020-01-06\"\n\ndef get_features_and_label(price, codes, features):\n    \"\"\"\n    Args:\n        price (pd.DataFrame): loaded price data\n        codes  (array) : target codes\n        feature (pd.DataFrame): features\n    Returns:\n        train_X (pd.DataFrame): training data\n        train_y (pd.DataFrame): label for train_X\n        test_X (pd.DataFrame): test data\n        test_y (pd.DataFrame): label for test_X\n    \"\"\"\n    # to store splited data\n    trains_X, tests_X = [], []\n    trains_y, tests_y = [], []\n\n    # generate feature one by one\n    for code in tqdm(codes):\n\n        feats = features[features[\"SecuritiesCode\"] == code].dropna()\n        labels = get_label(price, code).dropna()\n\n        if feats.shape[0] > 0 and labels.shape[0] > 0:\n            # align label and feature indexes\n            labels = labels.loc[labels.index.isin(feats.index)]\n            feats = feats.loc[feats.index.isin(labels.index)]\n\n            assert (labels.loc[:, \"SecuritiesCode\"] == feats.loc[:, \"SecuritiesCode\"]).all()\n            labels = labels.loc[:, \"label\"]\n\n            # split data into TRAIN and TEST\n            _train_X = feats[: TRAIN_END]\n            _test_X = feats[TEST_START:]\n\n            _train_y = labels[: TRAIN_END]\n            _test_y = labels[TEST_START:]\n            \n            assert len(_train_X) == len(_train_y)\n            assert len(_test_X) == len(_test_y)\n\n            # store features\n            trains_X.append(_train_X)\n            tests_X.append(_test_X)\n            # store labels\n            trains_y.append(_train_y)\n            tests_y.append(_test_y)\n            \n    # combine features for each codes\n    train_X = pd.concat(trains_X)\n    test_X = pd.concat(tests_X)\n    # combine label for each codes\n    train_y = pd.concat(trains_y)\n    test_y = pd.concat(tests_y)\n\n    return train_X, train_y, test_X, test_y","metadata":{"papermill":{"duration":0.15998,"end_time":"2022-04-02T13:52:40.488053","exception":false,"start_time":"2022-04-02T13:52:40.328073","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-17T06:12:37.763059Z","iopub.execute_input":"2022-06-17T06:12:37.763387Z","iopub.status.idle":"2022-06-17T06:12:37.777003Z","shell.execute_reply.started":"2022-06-17T06:12:37.763352Z","shell.execute_reply":"2022-06-17T06:12:37.776042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generate feature/label\ntrain_X, train_y, test_X, test_y = get_features_and_label(\n    df_price, codes, feature\n)","metadata":{"papermill":{"duration":37.867923,"end_time":"2022-04-02T13:53:18.500899","exception":false,"start_time":"2022-04-02T13:52:40.632976","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-17T06:12:37.779053Z","iopub.execute_input":"2022-06-17T06:12:37.779378Z","iopub.status.idle":"2022-06-17T06:13:36.079475Z","shell.execute_reply.started":"2022-06-17T06:12:37.779345Z","shell.execute_reply":"2022-06-17T06:13:36.078692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building a simple model\n\nUsing the a selected subset of features and labels, build a model using the following procedure","metadata":{"papermill":{"duration":0.273296,"end_time":"2022-04-02T13:53:19.062225","exception":false,"start_time":"2022-04-02T13:53:18.788929","status":"completed"},"tags":[]}},{"cell_type":"code","source":"feature.columns","metadata":{"execution":{"iopub.status.busy":"2022-06-17T05:49:11.517898Z","iopub.execute_input":"2022-06-17T05:49:11.518139Z","iopub.status.idle":"2022-06-17T05:49:11.526373Z","shell.execute_reply.started":"2022-06-17T05:49:11.518111Z","shell.execute_reply":"2022-06-17T05:49:11.525242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## LGBM was reworked by choosing the best feature in the top 18 in feature importance and parameter tuning ","metadata":{}},{"cell_type":"markdown","source":"## Validation Score 0.55","metadata":{}},{"cell_type":"code","source":"best_features = feature_imp.sort_values(by=\"Value\", ascending=False)[0:18].values[:,1]","metadata":{"execution":{"iopub.status.busy":"2022-06-17T06:16:55.047165Z","iopub.execute_input":"2022-06-17T06:16:55.047486Z","iopub.status.idle":"2022-06-17T06:16:55.052745Z","shell.execute_reply.started":"2022-06-17T06:16:55.047447Z","shell.execute_reply":"2022-06-17T06:16:55.052042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"depens o","metadata":{}},{"cell_type":"code","source":"# (boosting_type='gbdt', num_leaves=31, max_depth=- 1, learning_rate=0.1, n_estimators=100, subsample_for_bin=200000, objective=None, class_weight=None, min_split_gain=0, min_child_weight=0.001, min_child_samples=20, subsample=1, subsample_freq=0, colsample_bytree=1, reg_alpha=0, reg_lambda=0, random_state=None, n_jobs=- 1, silent=True, importance_type='split',","metadata":{"execution":{"iopub.status.busy":"2022-06-17T05:49:11.685981Z","iopub.status.idle":"2022-06-17T05:49:11.686338Z","shell.execute_reply.started":"2022-06-17T05:49:11.686159Z","shell.execute_reply":"2022-06-17T05:49:11.686178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgbm_params = { \n    'num_leaves': 10,\n    \"seed\": 42,\n    'max_depth': 10,\n    'n_estimators': 20,\n    \n}\n\"\"\"lgbm_params = { \n    \"seed\": 42,\n\n    \n}\"\"\"\nfeat_cols = best_features","metadata":{"papermill":{"duration":0.276851,"end_time":"2022-04-02T13:53:20.157205","exception":false,"start_time":"2022-04-02T13:53:19.880354","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-17T06:17:22.709309Z","iopub.execute_input":"2022-06-17T06:17:22.709721Z","iopub.status.idle":"2022-06-17T06:17:22.714343Z","shell.execute_reply.started":"2022-06-17T06:17:22.70968Z","shell.execute_reply":"2022-06-17T06:17:22.713526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# initialize model\npred_model = LGBMRegressor(**lgbm_params)\n# train\npred_model.fit(train_X[feat_cols].values, train_y)\n# prepare result data\nresult = test_X[[\"SecuritiesCode\"]].copy()\n# predict\nresult.loc[:, \"predict\"] = pred_model.predict(test_X[feat_cols])\n# actual result\nresult.loc[:, \"Target\"] = test_y.values\n\ndef set_rank(df):\n    \"\"\"\n    Args:\n        df (pd.DataFrame): including predict column\n    Returns:\n        df (pd.DataFrame): df with Rank\n    \"\"\"\n    # sort records to set Rank\n    df = df.sort_values(\"predict\", ascending=False)\n    # set Rank starting from 0\n    df.loc[:, \"Rank\"] = np.arange(len(df[\"predict\"]))\n    return df\n\nresult = result.sort_values([\"Date\", \"predict\"], ascending=[True, False])\nresult = result.groupby(\"Date\").apply(set_rank)","metadata":{"papermill":{"duration":7.86376,"end_time":"2022-04-02T13:53:28.327193","exception":false,"start_time":"2022-04-02T13:53:20.463433","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-17T06:17:24.438482Z","iopub.execute_input":"2022-06-17T06:17:24.439318Z","iopub.status.idle":"2022-06-17T06:17:34.048414Z","shell.execute_reply.started":"2022-06-17T06:17:24.439282Z","shell.execute_reply":"2022-06-17T06:17:34.04753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result.tail()","metadata":{"papermill":{"duration":0.287245,"end_time":"2022-04-02T13:53:28.886199","exception":false,"start_time":"2022-04-02T13:53:28.598954","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-17T05:49:11.691648Z","iopub.status.idle":"2022-06-17T05:49:11.691958Z","shell.execute_reply.started":"2022-06-17T05:49:11.691796Z","shell.execute_reply":"2022-06-17T05:49:11.691813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation\n\nInput the output of the forecasts of the constructed model into the evaluation function and plot the daily returns.\n\nThe evaluation function for this competition is as follows.\n\nPlease read [here](https://www.kaggle.com/code/smeitoma/jpx-competition-metric-definition) to know the evaluation function more.","metadata":{"papermill":{"duration":0.269682,"end_time":"2022-04-02T13:53:29.426688","exception":false,"start_time":"2022-04-02T13:53:29.157006","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def calc_spread_return_sharpe(df: pd.DataFrame, portfolio_size: int = 200, toprank_weight_ratio: float = 2) -> float:\n    \"\"\"\n    Args:\n        df (pd.DataFrame): predicted results\n        portfolio_size (int): # of equities to buy/sell\n        toprank_weight_ratio (float): the relative weight of the most highly ranked stock compared to the least.\n    Returns:\n        (float): sharpe ratio\n    \"\"\"\n    def _calc_spread_return_per_day(df, portfolio_size, toprank_weight_ratio):\n        \"\"\"\n        Args:\n            df (pd.DataFrame): predicted results\n            portfolio_size (int): # of equities to buy/sell\n            toprank_weight_ratio (float): the relative weight of the most highly ranked stock compared to the least.\n        Returns:\n            (float): spread return\n        \"\"\"\n        assert df['Rank'].min() == 0\n        assert df['Rank'].max() == len(df['Rank']) - 1\n        weights = np.linspace(start=toprank_weight_ratio, stop=1, num=portfolio_size)\n        purchase = (df.sort_values(by='Rank')['Target'][:portfolio_size] * weights).sum() / weights.mean()\n        short = (df.sort_values(by='Rank', ascending=False)['Target'][:portfolio_size] * weights).sum() / weights.mean()\n        return purchase - short\n\n    buf = df.groupby('Date').apply(_calc_spread_return_per_day, portfolio_size, toprank_weight_ratio)\n    sharpe_ratio = buf.mean() / buf.std()\n    return sharpe_ratio","metadata":{"papermill":{"duration":0.27819,"end_time":"2022-04-02T13:53:30.512824","exception":false,"start_time":"2022-04-02T13:53:30.234634","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-17T06:15:01.055378Z","iopub.execute_input":"2022-06-17T06:15:01.055699Z","iopub.status.idle":"2022-06-17T06:15:01.066812Z","shell.execute_reply.started":"2022-06-17T06:15:01.055665Z","shell.execute_reply":"2022-06-17T06:15:01.065928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## After getting best_features","metadata":{}},{"cell_type":"code","source":"# calc spread return sharpe\ncalc_spread_return_sharpe(result, portfolio_size=200)","metadata":{"papermill":{"duration":1.191834,"end_time":"2022-04-02T13:53:31.971406","exception":false,"start_time":"2022-04-02T13:53:30.779572","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-17T06:17:37.598735Z","iopub.execute_input":"2022-06-17T06:17:37.599013Z","iopub.status.idle":"2022-06-17T06:17:38.569478Z","shell.execute_reply.started":"2022-06-17T06:17:37.598984Z","shell.execute_reply":"2022-06-17T06:17:38.568478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\n# sorted(zip(clf.feature_importances_, X.columns), reverse=True)\nfeature_imp = pd.DataFrame(sorted(zip(pred_model.feature_importances_,train_X[feat_cols].columns)), columns=['Value','Feature'])\n\nplt.figure(figsize=(20, 20))\nsns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False))\nplt.title('LightGBM Features (avg over folds)')\nplt.tight_layout()\nplt.show()\nplt.savefig('lgbm_importances-01.png')","metadata":{"execution":{"iopub.status.busy":"2022-06-17T06:15:10.298635Z","iopub.execute_input":"2022-06-17T06:15:10.298937Z","iopub.status.idle":"2022-06-17T06:15:11.063777Z","shell.execute_reply.started":"2022-06-17T06:15:10.298905Z","shell.execute_reply":"2022-06-17T06:15:11.062523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def _calc_spread_return_per_day(df, portfolio_size, toprank_weight_ratio):\n    \"\"\"\n    Args:\n        df (pd.DataFrame): predicted results\n        portfolio_size (int): # of equities to buy/sell\n        toprank_weight_ratio (float): the relative weight of the most highly ranked stock compared to the least.\n    Returns:\n        (float): spread return\n    \"\"\"\n    assert df['Rank'].min() == 0\n    assert df['Rank'].max() == len(df['Rank']) - 1\n    weights = np.linspace(start=toprank_weight_ratio, stop=1, num=portfolio_size)\n    purchase = (df.sort_values(by='Rank')['Target'][:portfolio_size] * weights).sum() / weights.mean()\n    short = (df.sort_values(by='Rank', ascending=False)['Target'][:portfolio_size] * weights).sum() / weights.mean()\n    return purchase - short\n\ndf_result = result.groupby('Date').apply(_calc_spread_return_per_day, 200, 2)","metadata":{"papermill":{"duration":1.236094,"end_time":"2022-04-02T13:53:34.011016","exception":false,"start_time":"2022-04-02T13:53:32.774922","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-17T06:19:05.033037Z","iopub.execute_input":"2022-06-17T06:19:05.033339Z","iopub.status.idle":"2022-06-17T06:19:05.988704Z","shell.execute_reply.started":"2022-06-17T06:19:05.033308Z","shell.execute_reply":"2022-06-17T06:19:05.987613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_result","metadata":{"execution":{"iopub.status.busy":"2022-06-17T06:19:10.573423Z","iopub.execute_input":"2022-06-17T06:19:10.573747Z","iopub.status.idle":"2022-06-17T06:19:10.583877Z","shell.execute_reply.started":"2022-06-17T06:19:10.573715Z","shell.execute_reply":"2022-06-17T06:19:10.582423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_result.plot(figsize=(20, 8))","metadata":{"papermill":{"duration":0.59649,"end_time":"2022-04-02T13:53:34.882518","exception":false,"start_time":"2022-04-02T13:53:34.286028","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-17T06:19:12.241717Z","iopub.execute_input":"2022-06-17T06:19:12.242429Z","iopub.status.idle":"2022-06-17T06:19:12.598386Z","shell.execute_reply.started":"2022-06-17T06:19:12.242392Z","shell.execute_reply":"2022-06-17T06:19:12.597351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We also show a cumulative spread return of the mode","metadata":{"papermill":{"duration":0.27175,"end_time":"2022-04-02T13:53:35.429118","exception":false,"start_time":"2022-04-02T13:53:35.157368","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df_result.cumsum().plot(figsize=(20, 8))","metadata":{"papermill":{"duration":0.60694,"end_time":"2022-04-02T13:53:36.327383","exception":false,"start_time":"2022-04-02T13:53:35.720443","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-17T06:19:16.131526Z","iopub.execute_input":"2022-06-17T06:19:16.132253Z","iopub.status.idle":"2022-06-17T06:19:16.454486Z","shell.execute_reply.started":"2022-06-17T06:19:16.132212Z","shell.execute_reply":"2022-06-17T06:19:16.453592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The model in this notebook is now complete! Try different features and training methods through trial and error!","metadata":{"papermill":{"duration":0.271931,"end_time":"2022-04-02T13:53:36.871257","exception":false,"start_time":"2022-04-02T13:53:36.599326","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Saving model","metadata":{"papermill":{"duration":0.272106,"end_time":"2022-04-02T13:53:37.417349","exception":false,"start_time":"2022-04-02T13:53:37.145243","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"You need to save your model parameter to use created model for your submission.","metadata":{"papermill":{"duration":0.275818,"end_time":"2022-04-02T13:53:37.970603","exception":false,"start_time":"2022-04-02T13:53:37.694785","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"### Please don't forget to link if you found this notebook useful 🙏 🥰","metadata":{}}]}