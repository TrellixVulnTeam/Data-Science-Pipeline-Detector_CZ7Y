{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport warnings\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nfrom decimal import ROUND_HALF_UP, Decimal\nfrom tqdm import tqdm\nfrom lightgbm import LGBMRegressor\n","metadata":{"id":"zTv_B3gmIj6Z","executionInfo":{"status":"ok","timestamp":1654677667673,"user_tz":-120,"elapsed":34705,"user":{"displayName":"vincent neyrand","userId":"09803989417333907118"}},"outputId":"580cf3ad-d73b-4cf6-c690-fda1110d8646","execution":{"iopub.status.busy":"2022-06-12T13:55:28.445403Z","iopub.execute_input":"2022-06-12T13:55:28.447231Z","iopub.status.idle":"2022-06-12T13:55:30.102371Z","shell.execute_reply.started":"2022-06-12T13:55:28.447063Z","shell.execute_reply":"2022-06-12T13:55:30.101436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import dataframe","metadata":{}},{"cell_type":"code","source":"sectionProducts_encoder = LabelEncoder()\nnewMarketSegment_encoder = LabelEncoder()\ndef load_data() -> pd.DataFrame:\n    # Import data\n    folder = '../input/jpx-tokyo-stock-exchange-prediction'\n    df_stock_price = pd.read_csv(os.path.join(folder, 'train_files', 'stock_prices.csv'), parse_dates=['Date'])\n    df_stock_list = pd.read_csv(os.path.join(folder, 'stock_list.csv'))\n    \n    # Preprocess data\n    df_stock_list['Name'] = [i.rstrip().lower().capitalize() for i in df_stock_list['Name']]\n    df_stock_list['SectorName_17'] = [i.rstrip().lower().capitalize() for i in df_stock_list['17SectorName']]\n    df_stock_list['SectorCode_17'] = [i for i in df_stock_list['17SectorCode']]\n    df_stock_list['SectorCode_17'] = df_stock_list['SectorCode_17'].replace('-', '0').fillna('0')\n    df_stock_list['SectorName_33'] = [i.rstrip().lower().capitalize() for i in df_stock_list['33SectorName']]\n    df_stock_list['SectorCode_33'] = [i for i in df_stock_list['33SectorCode']]\n    df_stock_list['SectorCode_33'] = df_stock_list['SectorCode_33'].replace('-', '0').fillna('0')\n    df_stock_list['SectionProducts'] = df_stock_list['Section/Products'].fillna('Unknown')\n    df_stock_list['SectionProductsCode'] = sectionProducts_encoder.fit_transform(df_stock_list.SectionProducts.values)\n    df_stock_list['NewMarketSegment'] = df_stock_list['NewMarketSegment'].fillna('Unknown')\n    df_stock_list['NewMarketSegmentCode'] = newMarketSegment_encoder.fit_transform(df_stock_list.NewMarketSegment.values)\n    \n    # Merge data\n    df_stock_price = df_stock_price.merge(df_stock_list[['SecuritiesCode', 'Name', 'SectorCode_17', 'SectorCode_33', 'SectionProductsCode', 'NewMarketSegmentCode']], on = 'SecuritiesCode', how = 'left')\n    df_stock_price[['SectorCode_17', 'SectorCode_33']] = df_stock_price[['SectorCode_17', 'SectorCode_33']].fillna('0').astype(int)\n    df_stock_price.sort_values(['Date', 'SecuritiesCode'], inplace = True)\n    \n    return df_stock_price","metadata":{"execution":{"iopub.status.busy":"2022-06-12T13:55:30.104079Z","iopub.execute_input":"2022-06-12T13:55:30.104377Z","iopub.status.idle":"2022-06-12T13:55:30.118149Z","shell.execute_reply.started":"2022-06-12T13:55:30.104349Z","shell.execute_reply":"2022-06-12T13:55:30.11719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering\n    - Adjusted Close\n    - Return\n    - Moving Average\n    - Volatility\n    - Market Impact","metadata":{}},{"cell_type":"markdown","source":"Adjusted Close from the host competition team [Train Demo](https://www.kaggle.com/code/smeitoma/train-demo?scriptVersionId=92137850&cellId=6).\nNew features based on [this work.](https://www.kaggle.com/code/wannabebotter/jpx-stock-market-analysis-prediction-with-lgbm?scriptVersionId=97874906&cellId=5)","metadata":{}},{"cell_type":"code","source":"def adjust_price(price: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Args:\n        price (pd.DataFrame)  : pd.DataFrame include stock_price\n    Returns:\n        price DataFrame (pd.DataFrame): stock_price with generated AdjustedClose\n    \"\"\"\n    # transform Date column into datetime\n    #price.loc[: ,\"Date\"] = pd.to_datetime(price.loc[: ,\"Date\"], format=\"%Y-%m-%d\")\n\n    def generate_adjusted_close(df: pd.DataFrame) -> pd.DataFrame:\n        \"\"\"\n        Args:\n            df (pd.DataFrame)  : stock_price for a single SecuritiesCode\n        Returns:\n            df (pd.DataFrame): stock_price with AdjustedClose for a single SecuritiesCode\n        \"\"\"\n        # sort data to generate CumulativeAdjustmentFactor\n        df = df.sort_values(\"Date\", ascending=False)\n        # generate CumulativeAdjustmentFactor\n        df.loc[:, \"CumulativeAdjustmentFactor\"] = df[\"AdjustmentFactor\"].cumprod()\n        # generate AdjustedClose\n        df.loc[:, \"AdjustedClose\"] = (\n            df[\"CumulativeAdjustmentFactor\"] * df[\"Close\"]\n        ).map(lambda x: float(\n            Decimal(str(x)).quantize(Decimal('0.1'), rounding=ROUND_HALF_UP)\n        ))\n        # reverse order\n        df = df.sort_values(\"Date\")\n        # to fill AdjustedClose, replace 0 into np.nan\n        df.loc[df[\"AdjustedClose\"] == 0, \"AdjustedClose\"] = np.nan\n        # forward fill AdjustedClose\n        df.loc[:, \"AdjustedClose\"] = df.loc[:, \"AdjustedClose\"].ffill()\n        # forward fill Open, High, Low\n        df.loc[:, \"Open\"] = df.loc[:, \"Open\"].ffill()\n        df.loc[:, \"High\"] = df.loc[:, \"High\"].ffill()\n        df.loc[:, \"Low\"] = df.loc[:, \"Low\"].ffill()\n        df.loc[:, \"Volume\"] = df.loc[:, \"Volume\"].ffill()\n        \n        return df\n    \n    # generate AdjustedClose\n    price = price.sort_values([\"SecuritiesCode\", \"Date\"])\n    price = price.groupby(\"SecuritiesCode\").apply(generate_adjusted_close).reset_index(drop=True)\n    \n    return price","metadata":{"execution":{"iopub.status.busy":"2022-06-12T13:55:30.119838Z","iopub.execute_input":"2022-06-12T13:55:30.120455Z","iopub.status.idle":"2022-06-12T13:55:30.134615Z","shell.execute_reply.started":"2022-06-12T13:55:30.120409Z","shell.execute_reply":"2022-06-12T13:55:30.133667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def average_true_range(pivots: any, window: int, category: str = 'Security') -> pd.DataFrame:\n    closes, opens, highs, lows, volumes = pivots\n    a = highs - lows\n    b = abs(highs - closes.shift(1))\n    c = abs(lows - closes.shift(1))\n    return pd.melt(pd.DataFrame(np.max([a,b,c], axis = 0) / closes.shift(1), index = a.index, columns = a.columns).rolling(window).mean(), ignore_index=False).reset_index().dropna().rename(columns = {\"value\":f\"atr_{category}_{window}\"})\n\ndef volatility(pivots: any, window: int, category: str = 'Security') -> pd.DataFrame:\n    closes, opens, highs, lows, volumes = pivots\n    return pd.melt((closes.diff() / closes.shift(1)).rolling(window).std(), ignore_index = False).reset_index().dropna().rename(columns = {\"value\":f\"volatility_{category}_{window}\"})\n\ndef moving_average(pivots: any, window: int, category: str = 'Security') -> pd.DataFrame:\n    closes, opens, highs, lows, volumes = pivots\n    return pd.melt(closes.rolling(window).mean(), ignore_index = False).reset_index().dropna().rename(columns = {\"value\":f\"movingnAverage_{category}_{window}\"})\n\ndef moving_average_vol(pivots, window, category: str = 'Security'):    \n    closes, opens, highs, lows, volumes = pivots\n    return pd.melt(volumes.rolling(window).mean(), ignore_index=False).reset_index().dropna().rename(columns = {\"value\":f\"movingnAverageVolume_{category}_{window}\"})\n\ndef moving_average_gap(pivots: any, window: int, category: str = 'Security') -> pd.DataFrame:\n    closes, opens, highs, lows, volumes = pivots\n    return pd.melt((closes - closes.rolling(window).mean()) / closes.rolling(window).mean(), ignore_index = False).reset_index().dropna().rename(columns = {\"value\":f\"movingAverageGap_{category}_{window}\"})\n\ndef rate_of_return(pivots: any, window: int, category: str = 'Security') -> pd.DataFrame:\n    closes, opens, highs, lows, volumes = pivots\n    return pd.melt(closes.pct_change(window), ignore_index = False).reset_index().dropna().rename(columns = {\"value\":f\"return_{category}_{window}\"})\n\ndef market_impact(pivots: any, window: int, category: str = 'Security') -> pd.DataFrame:\n    closes, opens, highs, lows, volumes = pivots\n    return pd.melt((closes.diff() / volumes).rolling(window).mean(), ignore_index = False).reset_index().dropna().rename(columns = {\"value\":f\"marketImpact_{category}_{window}\"})\n\ndef create_features(df: pd.DataFrame, with_new=False) -> pd.DataFrame:\n    # return pct_change(period) per categories\n    # moving average rolling(window=period).mean() per categories\n    # volatility diff().rolling(period).std() per categories\n    # average true range per categories\n    # market impact per categories\n    \n    df = df.copy()\n    categories = ['SecuritiesCode']\n    for category in categories :\n        closes = pd.pivot_table(df, values = \"AdjustedClose\", index = \"Date\", columns = category).ffill()\n        opens = pd.pivot_table(df, values = \"Open\", index = \"Date\", columns = category).ffill()\n        highs = pd.pivot_table(df, values = \"High\", index = \"Date\", columns = category).ffill()\n        lows = pd.pivot_table(df, values = \"Low\", index = \"Date\", columns = category).ffill()\n        volumes = pd.pivot_table(df, values = \"Volume\", index = \"Date\", columns = category).ffill()\n\n        pivots = (closes, opens, highs, lows, volumes)\n\n        windows = [2, 5, 10, 20, 40, 60]\n        windows_bis = [1, 5, 10, 20]\n\n        for func in [volatility, moving_average, moving_average_gap]:\n            for window in tqdm(windows):\n                df = pd.merge(df, func(pivots, window, category), on = [\"Date\",category], how = \"left\")\n\n        for func in [market_impact, rate_of_return, average_true_range]:\n            for window in tqdm(windows_bis):\n                df = pd.merge(df, func(pivots, window, category), on = [\"Date\",category], how = \"left\")\n            \n    df = df.sort_values(['Date','SecuritiesCode']).dropna(axis = 0)\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-06-12T13:55:30.13779Z","iopub.execute_input":"2022-06-12T13:55:30.138471Z","iopub.status.idle":"2022-06-12T13:55:30.168823Z","shell.execute_reply.started":"2022-06-12T13:55:30.138421Z","shell.execute_reply":"2022-06-12T13:55:30.167818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = load_data()\ndf = adjust_price(df)\ndf.drop([\"RowId\", \"AdjustmentFactor\", \"CumulativeAdjustmentFactor\", \"ExpectedDividend\", \"SupervisionFlag\", \"Close\"], axis = 1, inplace = True)\ndf = create_features(df, with_new=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-12T13:55:30.17024Z","iopub.execute_input":"2022-06-12T13:55:30.170714Z","iopub.status.idle":"2022-06-12T13:57:03.639901Z","shell.execute_reply.started":"2022-06-12T13:55:30.170682Z","shell.execute_reply":"2022-06-12T13:57:03.638953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Training and making predictions')\nparams = {\n    'n_estimators': 500,\n    'num_leaves' : 100,\n    'learning_rate': 0.1,\n    'colsample_bytree': 0.9,\n    'subsample': 0.8,\n    'reg_alpha': 0.4,\n    'metric': 'mae',\n    'random_state': 42,\n    'verbosity': 1}\n\ndef run_train_serie(df: pd.DataFrame, code: int = 1377, target: str = 'Target'):\n    df = df.copy()\n    df_serie = df[df['SecuritiesCode']==1377]\n    date = '2020-12-10'\n    if target == 'Diff_T1':\n        df_serie['Diff_T1'] = df_serie['AdjustedClose'].shift(-1) - df_serie['AdjustedClose']\n        df_serie = df_serie[:-1]\n        col_to_drop = {'Target','Name','SecuritiesCode', target}\n    elif target == 'Diff_T2':\n        df_serie['Diff_T2'] = df_serie['AdjustedClose'].shift(-2) - df_serie['AdjustedClose']\n        df_serie = df_serie[:-2]\n        col_to_drop = {'Target','Name','SecuritiesCode', target}\n    else:\n        col_to_drop = {'Target','Name','SecuritiesCode'}\n    # Fit with training date for submission\n    X_train = df_serie[df_serie.Date < date][set(df_serie.columns.values) - {'Target', 'Name', 'SecuritiesCode', target}]\n    y_train = df_serie[df_serie.Date < date][['Date', target]]\n    X_test = df_serie[df_serie.Date >= date][set(df_serie.columns.values) - {'Target', 'Name', 'SecuritiesCode', target}]\n    y_test = df_serie[df_serie.Date >= date][['Date', target]]\n\n    print(f\"Train Date range: {X_train.Date.min()} to {X_train.Date.max()}\")\n    print(f\"Test Date range: {X_test.Date.min()} to {X_test.Date.max()}\")\n    print(f\"Train size: {X_train.shape[0]} Test size {X_test.shape[0]}\")\n    \n    X_train_nodate = X_train.drop('Date', axis = 1)\n    X_test_nodate = X_test.drop('Date', axis = 1)\n    y_train_nodate = y_train.drop('Date', axis = 1)\n    y_test_nodate = y_test.drop('Date', axis = 1)\n\n    gbm = LGBMRegressor(**params).fit(X_train_nodate, y_train_nodate, verbose =0)\n    \n    # Run against test period\n    y_pred = gbm.predict(X_test_nodate)\n    \n    return y_test_nodate, y_pred, df_serie[df_serie.Date >= date]['AdjustedClose']","metadata":{"execution":{"iopub.status.busy":"2022-06-12T13:57:03.641199Z","iopub.execute_input":"2022-06-12T13:57:03.641535Z","iopub.status.idle":"2022-06-12T13:57:03.658559Z","shell.execute_reply.started":"2022-06-12T13:57:03.641505Z","shell.execute_reply":"2022-06-12T13:57:03.657416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = pd.DataFrame(columns = ['Prediction', 'RMSE', 'MAE'])","metadata":{"execution":{"iopub.status.busy":"2022-06-12T13:57:03.660061Z","iopub.execute_input":"2022-06-12T13:57:03.660679Z","iopub.status.idle":"2022-06-12T13:57:03.676338Z","shell.execute_reply.started":"2022-06-12T13:57:03.660632Z","shell.execute_reply":"2022-06-12T13:57:03.675408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Explicit prediction","metadata":{}},{"cell_type":"markdown","source":"## Predict C(t+1)-C(t)","metadata":{}},{"cell_type":"code","source":"target = 'Diff_T1'\ny_test, y_pred, close = run_train_serie(df, 1377, target)","metadata":{"execution":{"iopub.status.busy":"2022-06-12T13:57:03.678001Z","iopub.execute_input":"2022-06-12T13:57:03.678928Z","iopub.status.idle":"2022-06-12T13:57:05.162454Z","shell.execute_reply.started":"2022-06-12T13:57:03.678849Z","shell.execute_reply":"2022-06-12T13:57:05.161574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_1 = close.values + y_pred\ny_true_1 = close.values + y_test[target].values\nrmse = mean_squared_error(close.values + y_test[target].values, close.values + y_pred, squared=False)\nmae = mean_absolute_error(close.values + y_test[target].values, close.values + y_pred)\n\nresults = results.append(pd.Series([target, rmse, mae], index=results.columns), ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-12T13:57:05.16407Z","iopub.execute_input":"2022-06-12T13:57:05.164812Z","iopub.status.idle":"2022-06-12T13:57:05.17758Z","shell.execute_reply.started":"2022-06-12T13:57:05.164764Z","shell.execute_reply":"2022-06-12T13:57:05.176664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,5), facecolor='white')\nplt.plot(close.values + y_test[target].values, label='y_true')\nplt.plot(close.values + y_pred, label='y_pred')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T13:57:05.181717Z","iopub.execute_input":"2022-06-12T13:57:05.182403Z","iopub.status.idle":"2022-06-12T13:57:05.348254Z","shell.execute_reply.started":"2022-06-12T13:57:05.182354Z","shell.execute_reply":"2022-06-12T13:57:05.34729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predict C(t+2)-C(t)","metadata":{}},{"cell_type":"code","source":"target = 'Diff_T2'\ny_test, y_pred, close = run_train_serie(df, 1377, target)","metadata":{"execution":{"iopub.status.busy":"2022-06-12T13:57:05.349366Z","iopub.execute_input":"2022-06-12T13:57:05.349735Z","iopub.status.idle":"2022-06-12T13:57:06.835851Z","shell.execute_reply.started":"2022-06-12T13:57:05.349702Z","shell.execute_reply":"2022-06-12T13:57:06.834861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_2 = close.values + y_pred\ny_true_2 = close.values + y_test[target].values\nrmse = mean_squared_error(close.values + y_test[target].values, close.values + y_pred, squared=False)\nmae = mean_absolute_error(close.values + y_test[target].values, close.values + y_pred)\n\nplt.figure(figsize=(12,5), facecolor='white')\nplt.plot(close.values + y_test[target].values, label='y_true')\nplt.plot(close.values + y_pred, label='y_pred')\nplt.legend()\nplt.show()\nprint(f'RMSE: {rmse} - MAE: {mae}')","metadata":{"execution":{"iopub.status.busy":"2022-06-12T13:57:06.837164Z","iopub.execute_input":"2022-06-12T13:57:06.837806Z","iopub.status.idle":"2022-06-12T13:57:07.044392Z","shell.execute_reply.started":"2022-06-12T13:57:06.837768Z","shell.execute_reply":"2022-06-12T13:57:07.043419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rmse = mean_squared_error(close.values, close.values + y_pred, squared=False)\nmae = mean_absolute_error(close.values, close.values + y_pred)\nresults = results.append(pd.Series([target, rmse, mae], index=results.columns), ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-12T13:57:07.045521Z","iopub.execute_input":"2022-06-12T13:57:07.045878Z","iopub.status.idle":"2022-06-12T13:57:07.055334Z","shell.execute_reply.started":"2022-06-12T13:57:07.045846Z","shell.execute_reply":"2022-06-12T13:57:07.054447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predict explicit r(t) from C(t+1) and C(t+2)","metadata":{}},{"cell_type":"code","source":"roc_true = (y_true_2 - y_true_1[:-1])/y_true_1[:-1]\nroc_pred = (y_pred_2 - y_pred_1[:-1])/y_pred_1[:-1]\nrmse = mean_squared_error(roc_true, roc_pred, squared=False)\nmae = mean_absolute_error(roc_true, roc_pred)\nresults = results.append(pd.Series(['Explicit', rmse, mae], index=results.columns), ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-12T13:57:07.056852Z","iopub.execute_input":"2022-06-12T13:57:07.057156Z","iopub.status.idle":"2022-06-12T13:57:07.073107Z","shell.execute_reply.started":"2022-06-12T13:57:07.057127Z","shell.execute_reply":"2022-06-12T13:57:07.072096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roc_pred.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-12T13:57:07.074382Z","iopub.execute_input":"2022-06-12T13:57:07.075004Z","iopub.status.idle":"2022-06-12T13:57:07.085312Z","shell.execute_reply.started":"2022-06-12T13:57:07.074969Z","shell.execute_reply":"2022-06-12T13:57:07.08466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,5), facecolor='white')\nplt.plot(roc_true, label='Target')\nplt.plot(roc_pred, label='LGBM')\nplt.plot(np.zeros(roc_true.shape), label='Naive', linestyle='--',c='k')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T13:57:07.086203Z","iopub.execute_input":"2022-06-12T13:57:07.086984Z","iopub.status.idle":"2022-06-12T13:57:07.324214Z","shell.execute_reply.started":"2022-06-12T13:57:07.086942Z","shell.execute_reply":"2022-06-12T13:57:07.323459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict implicit r(t)","metadata":{}},{"cell_type":"code","source":"y_test, y_pred, _ = run_train_serie(df)\nrmse = mean_squared_error(y_test[:-2]['Target'].values, y_pred[:-2], squared=False)\nmae = mean_absolute_error(y_test[:-2]['Target'].values, y_pred[:-2])\n\nresults = results.append(pd.Series(['Implicit', rmse, mae], index=results.columns), ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-12T13:57:07.325176Z","iopub.execute_input":"2022-06-12T13:57:07.325652Z","iopub.status.idle":"2022-06-12T13:57:07.626024Z","shell.execute_reply.started":"2022-06-12T13:57:07.325611Z","shell.execute_reply":"2022-06-12T13:57:07.624737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,5), facecolor='white')\nplt.plot(y_test['Target'].values, label='y_true')\nplt.plot(y_pred, label='y_pred')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T13:57:07.627447Z","iopub.execute_input":"2022-06-12T13:57:07.62793Z","iopub.status.idle":"2022-06-12T13:57:07.864096Z","shell.execute_reply.started":"2022-06-12T13:57:07.627896Z","shell.execute_reply":"2022-06-12T13:57:07.862195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Naïve","metadata":{}},{"cell_type":"code","source":"# Add naïve approach where t+1 and t+2 = t => r(t) tends to 0.\ny_naïve = np.zeros((y_pred.shape))\nrmse = mean_squared_error(y_test[:-2]['Target'].values, y_naïve[:-2], squared=False)\nmae = mean_absolute_error(y_test[:-2]['Target'].values, y_naïve[:-2])\n\nresults = results.append(pd.Series(['Naïve', rmse, mae], index=results.columns), ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-12T13:57:07.866134Z","iopub.execute_input":"2022-06-12T13:57:07.867671Z","iopub.status.idle":"2022-06-12T13:57:07.883934Z","shell.execute_reply.started":"2022-06-12T13:57:07.867619Z","shell.execute_reply":"2022-06-12T13:57:07.882389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Results","metadata":{}},{"cell_type":"code","source":"results","metadata":{"execution":{"iopub.status.busy":"2022-06-12T13:57:07.885566Z","iopub.execute_input":"2022-06-12T13:57:07.886498Z","iopub.status.idle":"2022-06-12T13:57:07.902431Z","shell.execute_reply.started":"2022-06-12T13:57:07.886446Z","shell.execute_reply":"2022-06-12T13:57:07.901572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<p>\n    This work have been done on only one security but even if the implicit method gives better results, it can be compared to the naïve approach.\n</p>","metadata":{}}]}