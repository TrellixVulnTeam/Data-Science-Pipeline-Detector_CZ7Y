{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# JPX Tokyo Stock Exchange Prediction – Using ARIMA / ARMA Models on Log returns to rank 2000 stocks\n\n**Helpful Notebooks to get started:**\n\n1) https://www.kaggle.com/code/chumajin/easy-to-understand-the-competition\n\n2) https://www.kaggle.com/code/sohier/basic-submission-demo \n","metadata":{}},{"cell_type":"code","source":"# Load libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#Libraries for Statistical Models\nimport statsmodels.api as sm\n\n# Time series Models\nfrom statsmodels.tsa.arima.model import ARIMA\n#from statsmodels.tsa.statespace.sarimax import SARIMAX\n\n# Error Metrics\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\n\n# Plotting \nfrom pandas.plotting import scatter_matrix\nfrom statsmodels.graphics.tsaplots import plot_acf\nimport plotly.express as px\n\n# Misc Utils\nimport glob\nfrom decimal import ROUND_HALF_UP, Decimal\nfrom pathlib import Path\nfrom tqdm.notebook import tqdm\n\n#Diable the warnings\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-30T16:21:23.53641Z","iopub.execute_input":"2022-06-30T16:21:23.536816Z","iopub.status.idle":"2022-06-30T16:21:23.544533Z","shell.execute_reply.started":"2022-06-30T16:21:23.536785Z","shell.execute_reply":"2022-06-30T16:21:23.543572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prepare data\n**1. Load Datasets**","metadata":{}},{"cell_type":"code","source":"working_dir = '/kaggle/input/jpx-tokyo-stock-exchange-prediction/'\nexample_test_files_dir, train_files_dir, supplemental_files_dir = glob.glob(working_dir+'*files*/')\ncsv_files = glob.glob(working_dir+'**/*.csv')\nprint(example_test_files_dir, train_files_dir, supplemental_files_dir, sep='\\n')","metadata":{"execution":{"iopub.status.busy":"2022-06-30T16:21:23.638868Z","iopub.execute_input":"2022-06-30T16:21:23.6398Z","iopub.status.idle":"2022-06-30T16:21:23.655594Z","shell.execute_reply.started":"2022-06-30T16:21:23.639754Z","shell.execute_reply":"2022-06-30T16:21:23.654588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv(Path(train_files_dir, 'stock_prices.csv'), index_col='RowId')\ndf_supp = pd.read_csv(Path(supplemental_files_dir, 'stock_prices.csv'), index_col='RowId')","metadata":{"execution":{"iopub.status.busy":"2022-06-30T16:21:23.709354Z","iopub.execute_input":"2022-06-30T16:21:23.710197Z","iopub.status.idle":"2022-06-30T16:21:29.825281Z","shell.execute_reply.started":"2022-06-30T16:21:23.710154Z","shell.execute_reply":"2022-06-30T16:21:29.82437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_supp.info()\ndf_supp.tail()","metadata":{"execution":{"iopub.status.busy":"2022-06-30T16:21:29.826915Z","iopub.execute_input":"2022-06-30T16:21:29.827298Z","iopub.status.idle":"2022-06-30T16:21:29.8989Z","shell.execute_reply.started":"2022-06-30T16:21:29.827267Z","shell.execute_reply":"2022-06-30T16:21:29.897952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train[df_train.SecuritiesCode == 9990]","metadata":{"execution":{"iopub.status.busy":"2022-06-30T16:21:29.900455Z","iopub.execute_input":"2022-06-30T16:21:29.900925Z","iopub.status.idle":"2022-06-30T16:21:29.936974Z","shell.execute_reply.started":"2022-06-30T16:21:29.900891Z","shell.execute_reply":"2022-06-30T16:21:29.935946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**2. Create features**","metadata":{}},{"cell_type":"markdown","source":"Calculate adjusted stock prices [based on ONUR KOÇ's Notebook](https://www.kaggle.com/code/onurkoc83/technical-features-trading-strategy)","metadata":{}},{"cell_type":"code","source":"def generate_adjusted_close(df):\n    \"\"\"\n    Args:\n        df (pd.DataFrame)  : stock_price for a single SecuritiesCode\n    Returns:\n        df (pd.DataFrame): stock_price with AdjustedClose for a single SecuritiesCode\n    \"\"\"\n    # sort data to generate CumulativeAdjustmentFactor\n    df = df.sort_values(\"Date\", ascending=False)\n    # generate CumulativeAdjustmentFactor\n    df.loc[:, \"CumulativeAdjustmentFactor\"] = df[\"AdjustmentFactor\"].cumprod()\n    # generate AdjustedClose\n    df.loc[:, \"AdjustedClose\"] = (\n        df[\"CumulativeAdjustmentFactor\"] * df[\"Close\"]\n    ).map(lambda x: float(\n        Decimal(str(x)).quantize(Decimal('0.1'), rounding=ROUND_HALF_UP)\n    ))\n    # reverse order\n    df = df.sort_values(\"Date\")\n    # to fill AdjustedClose, replace 0 into np.nan\n    df.loc[df[\"AdjustedClose\"] == 0, \"AdjustedClose\"] = np.nan\n    # forward fill AdjustedClose\n    df.loc[:, \"AdjustedClose\"] = df.loc[:, \"AdjustedClose\"].ffill()    \n    \n    return df\n\ndef adjust_price(price):\n    \"\"\"\n    Args:\n        price (pd.DataFrame)  : pd.DataFrame include stock_price\n    Returns:\n        price DataFrame (pd.DataFrame): stock_price with generated AdjustedClose\n    \"\"\"\n    # transform Date column into datetime\n    price.loc[: ,\"Date\"] = pd.to_datetime(price.loc[: ,\"Date\"], format=\"%Y-%m-%d\")\n\n    # generate AdjustedClose\n    price = price.sort_values([\"SecuritiesCode\", \"Date\"])\n    price = price.groupby(\"SecuritiesCode\").apply(generate_adjusted_close).reset_index(drop=True)\n\n    return price","metadata":{"execution":{"iopub.status.busy":"2022-06-30T16:21:29.938892Z","iopub.execute_input":"2022-06-30T16:21:29.939265Z","iopub.status.idle":"2022-06-30T16:21:29.950577Z","shell.execute_reply.started":"2022-06-30T16:21:29.939234Z","shell.execute_reply":"2022-06-30T16:21:29.949481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Experiment with ARIMA / ARMA Models\n[Auto - ARIMA – optimising parameters](https://levelup.gitconnected.com/simple-forecasting-with-auto-arima-python-a3f651271965)\n\n[Auto - Arima - Time series forecasting](https://www.machinelearningplus.com/time-series/arima-model-time-series-forecasting-python/)\n\n**AR: Autoregression.** A model that uses the dependent relationship between an observation and some number of lagged observations.\n\n**I: Integrated.** The use of differencing of raw observations (e.g. subtracting an observation from an observation at the previous time step) in order to make the time series stationary.\n\n**MA: Moving Average.** A model that uses the dependency between an observation and a residual error from a moving average model applied to lagged observations.\n\n\n\n**Parameters** \n\n* p: The number of lag observations included in the model, also called the lag order.\n* d: The number of times that the raw observations are differenced, also called the degree of differencing.\n* q: The size of the moving average window, also called the order of moving average.","metadata":{}},{"cell_type":"markdown","source":"**1. Define function to create a feature – Daily Log Return – for the ARIMA ARMA dataset**","metadata":{}},{"cell_type":"code","source":"def update_features_ARIMA(df, quote):\n    # Filter for security code\n    df = df[df['SecuritiesCode']==quote] \n    \n    df = generate_adjusted_close(df)    \n    \n    df.set_index('Date', inplace=True)\n    \n    # Calculate daily returns \n    df['DailyLogReturn'] = np.log(df.AdjustedClose).diff(1).shift(0)\n    #df['DailySimpleReturn'] = df.AdjustedClose.pct_change().shift(0)\n    \n    return df[['DailyLogReturn']]\n\n#quote = 9990\n#y_train = update_features_ARIMA(df_train, quote)\n#y_test = update_features_ARIMA(df_supp, quote)\n#y_train.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T16:21:29.951889Z","iopub.execute_input":"2022-06-30T16:21:29.952721Z","iopub.status.idle":"2022-06-30T16:21:29.968665Z","shell.execute_reply.started":"2022-06-30T16:21:29.952686Z","shell.execute_reply":"2022-06-30T16:21:29.967803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**2. Define function to find the best hyperparams for ARMA / ARIMA model for the specific stock**","metadata":{}},{"cell_type":"code","source":"def evaluate_ARIMA_model(y_train, order):\n    X = y_train.dropna().copy()\n    train_size = int(len(X) * 0.7)\n    train, test = X[0:train_size], X[train_size:]\n    history = train.copy()\n    # make predictions\n    predictions = []\n    for t in range(len(test)):\n        model = ARIMA(history, order=order)\n        model_fit = model.fit()\n        yhat = model_fit.forecast(2)\n        predictions.append(round(yhat.values[-1], 8))\n        history = history.append(test.iloc[t])\n    # calculate out of sample error\n    actual = test.shift(-2).dropna().iloc[:,0]\n    predictions = predictions[:-2]\n    error = mean_squared_error(actual, predictions)\n    return error\n    \n# evaluate combinations of p, d and q values for an ARIMA model\ndef evaluate_models(dataset, p_values, d_values, q_values):\n    best_score, best_cfg = float(\"inf\"), None\n    for p in p_values:\n        for d in d_values:\n            for q in q_values:\n                order = (p,d,q)\n                try:\n                    mse = evaluate_ARIMA_model(dataset, order)\n                    if mse < best_score:\n                        best_score, best_cfg = mse, order\n                except:\n                    continue\n    return best_cfg\n    \n#best_order = evaluate_models(update_features_ARIMA(df_supp, 9990), [1, 2, 3, 5, 7, 11], [0], [0, 3, 5, 7])\n#print(best_order)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T16:21:29.969674Z","iopub.execute_input":"2022-06-30T16:21:29.970385Z","iopub.status.idle":"2022-06-30T16:21:29.987292Z","shell.execute_reply.started":"2022-06-30T16:21:29.970348Z","shell.execute_reply":"2022-06-30T16:21:29.986297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generate Predictions and Rankings","metadata":{}},{"cell_type":"code","source":"# Utilities \ndef calc_spread_return_per_day(df, portfolio_size, toprank_weight_ratio):\n    weights = np.linspace(start=toprank_weight_ratio, stop=1, num=portfolio_size)\n    weights_mean = weights.mean()\n    df = df.sort_values(by='Rank')\n    purchase = (df['Target'][:portfolio_size]  * weights).sum() / weights_mean\n    short    = (df['Target'][-portfolio_size:] * weights[::-1]).sum() / weights_mean\n    return purchase - short\n\ndef calc_spread_return_sharpe(df, portfolio_size=200, toprank_weight_ratio=2):\n    grp = df.groupby('Date')\n    min_size = grp[\"Target\"].count().min()\n    if min_size<2*portfolio_size:\n        portfolio_size=min_size//2\n        if portfolio_size<1:\n            return 0, None\n    buf = grp.apply(calc_spread_return_per_day, portfolio_size, toprank_weight_ratio)\n    sharpe_ratio = buf.mean() / buf.std()\n    return sharpe_ratio, buf\n\ndef add_rank(df, col_name=\"pred\"):\n    df[\"Rank\"] = df.groupby(\"Date\")[col_name].rank(ascending=False, method=\"first\") - 1 \n    df[\"Rank\"] = df[\"Rank\"].astype(\"int\")\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-06-30T16:21:29.988581Z","iopub.execute_input":"2022-06-30T16:21:29.98901Z","iopub.status.idle":"2022-06-30T16:21:30.001435Z","shell.execute_reply.started":"2022-06-30T16:21:29.988969Z","shell.execute_reply":"2022-06-30T16:21:30.000366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_prediction_ARIMA(df, quote):\n    # Generate Series containing Daily Log Returns for specific quote\n    y_train = update_features_ARIMA(df, quote)\n    \n    # Select optimal hyperparams...\n    p, q = (1, 3)\n    order = (p, 0, q)\n    \n    # Fit optimised model\n    model = ARIMA(\n        y_train, \n        order=order,\n        trend= 't'\n    ).fit()\n    \n    # Make Predictions\n    y_pred = model.forecast(2) #.predict(start='2022-05-25', dynamic=len(y_train)-5, steps=2)\n    \n    return round(y_pred.values[-1], 8) ","metadata":{"execution":{"iopub.status.busy":"2022-06-30T16:21:30.002593Z","iopub.execute_input":"2022-06-30T16:21:30.00291Z","iopub.status.idle":"2022-06-30T16:21:30.0179Z","shell.execute_reply.started":"2022-06-30T16:21:30.002882Z","shell.execute_reply":"2022-06-30T16:21:30.016892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submitting Predictions","metadata":{}},{"cell_type":"code","source":"%%time\nimport jpx_tokyo_market_prediction\nfrom datetime import datetime, timedelta\n\nenv = jpx_tokyo_market_prediction.make_env()\niter_test = env.iter_test()\n\n# Append new data (later using the API) to the train & supplementary data \ndate_cutoff = '2021-11-05'\ndf_train_new = df_train[df_train['Date'] > date_cutoff].copy()\n\ndate_format='%Y-%M-%d'\n\n\nfor (prices, _, _, _, _, sample_prediction) in iter_test:\n    # Loop through all stocks\n    \n    #0) set date cutoff to optimize performance on the scoring set\n    dtObj = datetime.strptime(date_cutoff, date_format)\n    future_date = dtObj + timedelta(days=1)\n    date_cutoff = future_date.strftime(date_format)\n    \n    # 1) Wrangle data\n    quotes = prices.SecuritiesCode.unique()\n    df_train_new = pd.concat([df_train_new, prices])\n    df_train_new = df_train_new.sort_values(['SecuritiesCode', 'Date'])\n    df_train_new.ffill(inplace=True)\n    \n    df_train_new = df_train_new[df_train_new['Date'] > date_cutoff]\n    \n    # 2) Fit Model & Make predictions\n    predictions = {}\n    for i in tqdm(range(len(quotes))):\n        predictions[quotes[i]] = generate_prediction_ARIMA(df_train_new, quotes[i])\n\n    tr = df_train_new[df_train_new.Date==prices.Date.iat[0]].copy()\n    tr.Target = tr[\"SecuritiesCode\"].map(predictions) \n    tr = add_rank(tr, \"Target\")\n    score = calc_spread_return_per_day(tr,200,2)\n    print(f\"Score: {score}\")\n    pred = tr.set_index(\"SecuritiesCode\")[\"Rank\"]\n    sample_prediction['Rank'] = sample_prediction[\"SecuritiesCode\"].map(pred)\n    env.predict(sample_prediction)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T16:21:30.018972Z","iopub.execute_input":"2022-06-30T16:21:30.020474Z","iopub.status.idle":"2022-06-30T16:31:11.507589Z","shell.execute_reply.started":"2022-06-30T16:21:30.020421Z","shell.execute_reply":"2022-06-30T16:31:11.506489Z"},"trusted":true},"execution_count":null,"outputs":[]}]}