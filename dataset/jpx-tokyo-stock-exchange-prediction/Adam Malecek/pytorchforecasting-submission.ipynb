{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ../input/pfpacgake/pf/pytorch_forecasting-0.10.1-py3-none-any.whl > /dev/null","metadata":{"execution":{"iopub.status.busy":"2022-06-13T10:50:53.382292Z","iopub.execute_input":"2022-06-13T10:50:53.383033Z","iopub.status.idle":"2022-06-13T10:51:25.075089Z","shell.execute_reply.started":"2022-06-13T10:50:53.382962Z","shell.execute_reply":"2022-06-13T10:51:25.073821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp -r ../input/tapackage/ta/ .\n%cd ./ta/ta-0.10.1/ta-0.10.1\n!python setup.py install\n%cd /kaggle/working/","metadata":{"execution":{"iopub.status.busy":"2022-06-13T10:51:25.080958Z","iopub.execute_input":"2022-06-13T10:51:25.081318Z","iopub.status.idle":"2022-06-13T10:51:26.907617Z","shell.execute_reply.started":"2022-06-13T10:51:25.081277Z","shell.execute_reply":"2022-06-13T10:51:26.906134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings, gc\nimport numpy as np \nimport pandas as pd\nimport matplotlib.colors\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom plotly.offline import init_notebook_mode\nfrom datetime import datetime, timedelta\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.metrics import mean_squared_error,mean_absolute_error\nfrom lightgbm import LGBMRegressor\nfrom decimal import ROUND_HALF_UP, Decimal\n\nimport os\nfrom decimal import ROUND_HALF_UP, Decimal\n\nimport pickle\nfrom lightgbm import LGBMRegressor\nfrom tqdm import tqdm\n\nimport ta\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n\nfrom ta import add_all_ta_features\nfrom ta.utils import dropna\n\nfrom pytorch_forecasting.data import (\n    TimeSeriesDataSet,\n    GroupNormalizer\n)\n\nfrom pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n\nimport copy\nfrom pathlib import Path\nimport warnings\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\nfrom pytorch_lightning.loggers import TensorBoardLogger\nimport torch\n\nfrom pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\nfrom pytorch_forecasting.data import GroupNormalizer\nfrom pytorch_forecasting.metrics import SMAPE, PoissonLoss, QuantileLoss\nfrom pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\nfrom pytorch_forecasting.data.encoders import NaNLabelEncoder\n\nimport warnings\nfrom sklearn.exceptions import DataConversionWarning\nwarnings.filterwarnings(action='ignore', category=UserWarning)\n\nmpl.style.use('seaborn')\n\n\nwarnings.filterwarnings(\"ignore\")\nimport plotly.figure_factory as ff","metadata":{"execution":{"iopub.status.busy":"2022-06-13T10:51:26.910035Z","iopub.execute_input":"2022-06-13T10:51:26.91064Z","iopub.status.idle":"2022-06-13T10:51:33.773856Z","shell.execute_reply.started":"2022-06-13T10:51:26.91058Z","shell.execute_reply":"2022-06-13T10:51:33.772831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def adjust_price(price):\n    \"\"\"\n    Args:\n        price (pd.DataFrame)  : pd.DataFrame include stock_price\n    Returns:\n        price DataFrame (pd.DataFrame): stock_price with generated AdjustedClose\n    \"\"\"\n    # transform Date column into datetime\n    price.loc[: ,\"Date\"] = pd.to_datetime(price.loc[: ,\"Date\"], format=\"%Y-%m-%d\")\n\n    def generate_adjusted_close(df):\n        \"\"\"\n        Args:\n            df (pd.DataFrame)  : stock_price for a single SecuritiesCode\n        Returns:\n            df (pd.DataFrame): stock_price with AdjustedClose for a single SecuritiesCode\n        \"\"\"\n        # sort data to generate CumulativeAdjustmentFactor\n        df = df.sort_values(\"Date\", ascending=False)\n        # generate CumulativeAdjustmentFactor\n        df.loc[:, \"CumulativeAdjustmentFactor\"] = df[\"AdjustmentFactor\"].cumprod()\n        # generate AdjustedClose\n        df.loc[:, \"AdjustedClose\"] = (\n            df[\"CumulativeAdjustmentFactor\"] * df[\"Close\"]\n        ).map(lambda x: float(\n            Decimal(str(x)).quantize(Decimal('0.1'), rounding=ROUND_HALF_UP)\n        ))\n        # reverse order\n        df = df.sort_values(\"Date\")\n        # to fill AdjustedClose, replace 0 into np.nan\n        df.loc[df[\"AdjustedClose\"] == 0, \"AdjustedClose\"] = np.nan\n        # forward fill AdjustedClose\n        df.loc[:, \"AdjustedClose\"] = df.loc[:, \"AdjustedClose\"].ffill()\n        return df\n\n    # generate AdjustedClose\n    price = price.sort_values([\"SecuritiesCode\", \"Date\"])\n    price = price.groupby(\"SecuritiesCode\").apply(generate_adjusted_close).reset_index(drop=True)\n\n    price.set_index(\"Date\", inplace=True)\n    return price","metadata":{"execution":{"iopub.status.busy":"2022-06-13T10:51:33.777458Z","iopub.execute_input":"2022-06-13T10:51:33.77829Z","iopub.status.idle":"2022-06-13T10:51:33.791361Z","shell.execute_reply.started":"2022-06-13T10:51:33.778246Z","shell.execute_reply":"2022-06-13T10:51:33.790296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_features_for_predict(price, code):\n    \"\"\"\n    Args:\n        price (pd.DataFrame)  : pd.DataFrame include stock_price\n        code (int)  : A local code for a listed company\n    Returns:\n        feature DataFrame (pd.DataFrame)\n    \"\"\"\n    close_col = \"AdjustedClose\"\n    feats = price.loc[price[\"SecuritiesCode\"] == code].copy()\n    \n    # Adds all 42 features\n    feats = ta.add_all_ta_features(\n        feats, \"Open\", \"High\", \"Low\", close_col, \"Volume\", fillna=False\n    )\n    \n    # To only add specific features\n    # Example: https://github.com/bukosabino/ta/blob/master/examples_to_use/bollinger_band_features_example.py\n    # df['bb_bbm'] = indicator_bb.bollinger_mavg()\n    # df['bb_bbh'] = indicator_bb.bollinger_hband()\n    # df['bb_bbl'] = indicator_bb.bollinger_lband()\n    \n    # filling data for nan and inf\n    feats = feats.fillna(0)\n    feats = feats.replace([np.inf, -np.inf], 0)\n    # drop AdjustedClose column\n    feats = feats.drop([close_col], axis=1)\n\n    return feats","metadata":{"execution":{"iopub.status.busy":"2022-06-13T10:51:33.792447Z","iopub.execute_input":"2022-06-13T10:51:33.79333Z","iopub.status.idle":"2022-06-13T10:51:33.810589Z","shell.execute_reply.started":"2022-06-13T10:51:33.793292Z","shell.execute_reply":"2022-06-13T10:51:33.809565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_label(price, code):\n    \"\"\" Labelizer\n    Args:\n        price (pd.DataFrame): dataframe of stock_price.csv\n        code (int): Local Code in the universe\n    Returns:\n        df (pd.DataFrame): label data\n    \"\"\"\n    df = price.loc[price[\"SecuritiesCode\"] == code].copy()\n    df.loc[:, \"label\"] = df[\"Target\"]\n\n    return df.loc[:, [\"SecuritiesCode\", \"label\"]]","metadata":{"execution":{"iopub.status.busy":"2022-06-13T10:51:33.812082Z","iopub.execute_input":"2022-06-13T10:51:33.813384Z","iopub.status.idle":"2022-06-13T10:51:33.828243Z","shell.execute_reply.started":"2022-06-13T10:51:33.813331Z","shell.execute_reply":"2022-06-13T10:51:33.827416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# split data into TRAIN and TEST\nTRAIN_END = \"2019-12-31\"\n# We put a week gap between TRAIN_END and TEST_START\n# to avoid leakage of test data information from label\nTEST_START = \"2020-01-06\"\n\ndef get_features_and_label(price, codes, features):\n    \"\"\"\n    Args:\n        price (pd.DataFrame): loaded price data\n        codes  (array) : target codes\n        feature (pd.DataFrame): features\n    Returns:\n        train_X (pd.DataFrame): training data\n        train_y (pd.DataFrame): label for train_X\n        test_X (pd.DataFrame): test data\n        test_y (pd.DataFrame): label for test_X\n    \"\"\"\n    # to store splited data\n    trains_X, tests_X = [], []\n    trains_y, tests_y = [], []\n\n    # generate feature one by one\n    for code in tqdm(codes):\n\n        feats = features[features[\"SecuritiesCode\"] == code].dropna()\n        labels = get_label(price, code).dropna()\n\n        if feats.shape[0] > 0 and labels.shape[0] > 0:\n            labels = labels.loc[labels.index.isin(feats.index)]\n            feats = feats.loc[feats.index.isin(labels.index)]\n\n            #print(labels.loc[:, \"SecuritiesCode\"])\n            #print(feats.loc[:, \"SecuritiesCode\"])\n\n            assert (labels.loc[:, \"SecuritiesCode\"] == feats.loc[:, \"SecuritiesCode\"]).all()\n            labels = labels.loc[:, \"label\"]\n\n            # split data into TRAIN and TEST\n            _train_X = feats[: TRAIN_END]\n            _test_X = feats[TEST_START:]\n\n            _train_y = labels[: TRAIN_END]\n            _test_y = labels[TEST_START:]\n            \n            assert len(_train_X) == len(_train_y)\n            assert len(_test_X) == len(_test_y)\n\n            # store features\n            trains_X.append(_train_X)\n            tests_X.append(_test_X)\n            # store labels\n            trains_y.append(_train_y)\n            tests_y.append(_test_y)\n            \n    # combine features for each codes\n    train_X = pd.concat(trains_X)\n    test_X = pd.concat(tests_X)\n    # combine label for each codes\n    train_y = pd.concat(trains_y)\n    test_y = pd.concat(tests_y)\n\n    return train_X, train_y, test_X, test_y","metadata":{"execution":{"iopub.status.busy":"2022-06-13T10:51:33.830175Z","iopub.execute_input":"2022-06-13T10:51:33.830624Z","iopub.status.idle":"2022-06-13T10:51:33.847898Z","shell.execute_reply.started":"2022-06-13T10:51:33.830587Z","shell.execute_reply":"2022-06-13T10:51:33.846793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_rank(df):\n    \"\"\"\n    Args:\n        df (pd.DataFrame): including predict column\n    Returns:\n        df (pd.DataFrame): df with Rank\n    \"\"\"\n    # sort records to set Rank\n    df = df.sort_values(\"predict\", ascending=False)\n    # set Rank starting from 0\n    df.loc[:, \"Rank\"] = np.arange(len(df[\"predict\"]))\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-06-13T10:51:33.849342Z","iopub.execute_input":"2022-06-13T10:51:33.849866Z","iopub.status.idle":"2022-06-13T10:51:33.865132Z","shell.execute_reply.started":"2022-06-13T10:51:33.849831Z","shell.execute_reply":"2022-06-13T10:51:33.864268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calc_spread_return_sharpe(df: pd.DataFrame, portfolio_size: int = 200, toprank_weight_ratio: float = 2) -> float:\n    \"\"\"\n    Args:\n        df (pd.DataFrame): predicted results\n        portfolio_size (int): # of equities to buy/sell\n        toprank_weight_ratio (float): the relative weight of the most highly ranked stock compared to the least.\n    Returns:\n        (float): sharpe ratio\n    \"\"\"\n    def _calc_spread_return_per_day(df, portfolio_size, toprank_weight_ratio):\n        \"\"\"\n        Args:\n            df (pd.DataFrame): predicted results\n            portfolio_size (int): # of equities to buy/sell\n            toprank_weight_ratio (float): the relative weight of the most highly ranked stock compared to the least.\n        Returns:\n            (float): spread return\n        \"\"\"\n        assert df['Rank'].min() == 0\n        assert df['Rank'].max() == len(df['Rank']) - 1\n        weights = np.linspace(start=toprank_weight_ratio, stop=1, num=portfolio_size)\n        purchase = (df.sort_values(by='Rank')['Target'][:portfolio_size] * weights).sum() / weights.mean()\n        short = (df.sort_values(by='Rank', ascending=False)['Target'][:portfolio_size] * weights).sum() / weights.mean()\n        return purchase - short\n\n    buf = df.groupby('Date').apply(_calc_spread_return_per_day, portfolio_size, toprank_weight_ratio)\n    sharpe_ratio = buf.mean() / buf.std()\n    return sharpe_ratio","metadata":{"execution":{"iopub.status.busy":"2022-06-13T10:51:33.86656Z","iopub.execute_input":"2022-06-13T10:51:33.867237Z","iopub.status.idle":"2022-06-13T10:51:33.879703Z","shell.execute_reply.started":"2022-06-13T10:51:33.867188Z","shell.execute_reply":"2022-06-13T10:51:33.878889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('../input/sortedfeatures/sorted_features.pkl', 'rb') as f:\n  features = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2022-06-13T10:51:34.008303Z","iopub.execute_input":"2022-06-13T10:51:34.008704Z","iopub.status.idle":"2022-06-13T10:51:34.026436Z","shell.execute_reply.started":"2022-06-13T10:51:34.008662Z","shell.execute_reply":"2022-06-13T10:51:34.025301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_model_path = '../input/lastmodel/epoch-18-step-134577.ckpt'\nbest_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)","metadata":{"execution":{"iopub.status.busy":"2022-06-13T10:51:34.128338Z","iopub.execute_input":"2022-06-13T10:51:34.129126Z","iopub.status.idle":"2022-06-13T10:51:34.675295Z","shell.execute_reply.started":"2022-06-13T10:51:34.129077Z","shell.execute_reply":"2022-06-13T10:51:34.674267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_price = pd.read_csv('../input/jpx-tokyo-stock-exchange-prediction/train_files/stock_prices.csv')\nstock_list = pd.read_csv('../input/jpx-tokyo-stock-exchange-prediction/stock_list.csv')\ndf_price = df_price.merge(stock_list[['SecuritiesCode', 'Section/Products', 'NewMarketSegment', '33SectorName', '17SectorCode', 'NewIndexSeriesSize', 'NewIndexSeriesSizeCode']], on='SecuritiesCode')","metadata":{"execution":{"iopub.status.busy":"2022-06-13T10:51:34.682934Z","iopub.execute_input":"2022-06-13T10:51:34.683278Z","iopub.status.idle":"2022-06-13T10:51:40.989395Z","shell.execute_reply.started":"2022-06-13T10:51:34.683248Z","shell.execute_reply":"2022-06-13T10:51:40.988231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import jpx_tokyo_market_prediction\nenv = jpx_tokyo_market_prediction.make_env()\niter_test = env.iter_test()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-13T10:51:40.990747Z","iopub.execute_input":"2022-06-13T10:51:40.991143Z","iopub.status.idle":"2022-06-13T10:51:41.001841Z","shell.execute_reply.started":"2022-06-13T10:51:40.991108Z","shell.execute_reply":"2022-06-13T10:51:41.000837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"counter = 0\nfor (prices, options, financials, trades, secondary_prices, sample_prediction) in iter_test:\n    print(counter)\n    current_date = prices[\"Date\"].iloc[0]\n    if counter == 0:\n        df_price_raw = df_price.loc[(df_price[\"Date\"] < current_date) & (df_price['Date'] > '2021-01-01')]  #df_price.loc[df_price[\"Date\"] < current_date]\n    df_price_raw = pd.concat([df_price_raw, prices]).reset_index(drop=True)\n    df_price_test = adjust_price(df_price_raw)\n    \n    df_price_test['Date'] = df_price_test.index\n    df_price_test[\"time_idx\"] = df_price_test['Date'].apply(lambda x: x.year * 365 + x.month * 30 + x.day)\n    df_price_test[\"time_idx\"] -= df_price_test[\"time_idx\"].min()\n    \n    buff = []\n    codes = sorted(df_price_test[\"SecuritiesCode\"].unique())\n    #break\n    for code in tqdm(codes):\n        feat = get_features_for_predict(df_price_test, code)\n        buff.append(feat)\n    feat = pd.concat(buff)\n    \n    feat = feat[feat['time_idx'] - 21 > 0]\n    #feat = feat.merge(stock_list[['SecuritiesCode', 'Section/Products', 'NewMarketSegment', '33SectorName', '17SectorCode', 'NewIndexSeriesSize', 'NewIndexSeriesSizeCode']], on='SecuritiesCode')\n    feat = feat.reset_index(drop=True)\n    feat['17SectorCode'] = feat['17SectorCode'].replace(0, '10')\n    feat['NewIndexSeriesSizeCode'] = feat['NewIndexSeriesSizeCode'].replace(0, '7')\n    feat['NewIndexSeriesSize'] = feat['NewIndexSeriesSize'].replace(0, 'TOPIX Small 2')\n    feat['Section/Products'] = feat['Section/Products'].replace(0, 'First Section (Domestic)')\n    feat['33SectorName'] = feat['33SectorName'].replace(0, 'Information & Communication')\n    feat['NewMarketSegment'] = feat['NewMarketSegment'].replace(0, 'Prime Market')\n    \n    result = best_tft.predict(feat, mode=\"prediction\", return_x=True)\n    \n    feat = feat[feat.Date == current_date]\n\n    feat['pred'] = np.array(result[0])[:, 0]\n    feat[\"Rank\"] = (feat[\"pred\"].rank(method=\"first\", ascending=False)-1).astype(int)\n    #sample_prediction[\"Rank\"] = feat[\"Rank\"].values\n    sample_prediction = pd.merge(sample_prediction.drop(columns = ['Rank']),feat[['SecuritiesCode','Rank']],on = 'SecuritiesCode')\n    display(sample_prediction.head())\n    \n    assert sample_prediction[\"Rank\"].notna().all()\n    assert sample_prediction[\"Rank\"].min() == 0\n    assert sample_prediction[\"Rank\"].max() == len(sample_prediction[\"Rank\"]) - 1\n    \n    env.predict(sample_prediction)\n    counter += 1","metadata":{"execution":{"iopub.status.busy":"2022-06-13T10:51:41.003243Z","iopub.execute_input":"2022-06-13T10:51:41.003865Z","iopub.status.idle":"2022-06-13T11:07:26.328144Z","shell.execute_reply.started":"2022-06-13T10:51:41.003828Z","shell.execute_reply":"2022-06-13T11:07:26.326875Z"},"trusted":true},"execution_count":null,"outputs":[]}]}