{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-29T06:45:01.206969Z","iopub.execute_input":"2022-06-29T06:45:01.207486Z","iopub.status.idle":"2022-06-29T06:45:01.273165Z","shell.execute_reply.started":"2022-06-29T06:45:01.207382Z","shell.execute_reply":"2022-06-29T06:45:01.272503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls ../input/packages/ta/","metadata":{"execution":{"iopub.status.busy":"2022-06-29T06:45:01.274457Z","iopub.execute_input":"2022-06-29T06:45:01.274887Z","iopub.status.idle":"2022-06-29T06:45:02.054642Z","shell.execute_reply.started":"2022-06-29T06:45:01.274858Z","shell.execute_reply":"2022-06-29T06:45:02.053379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir -p /tmp/pip/cache/\n!cp ../input/packages/ta/numpy-1.22.4-cp39-cp39-win_amd64.whl /tmp/pip/cache/numpy-1.22.4-cp39-cp39-win_amd64.whl\n!cp ../input/packages/ta/pytz-2022.1-py2.py3-none-any.whl /tmp/pip/cache/pytz-2022.1-py2.py3-none-any.whl\n!cp ../input/packages/ta/pandas-1.4.2-cp39-cp39-win_amd64.whl /tmp/pip/cache/pandas-1.4.2-cp39-cp39-win_amd64.whl\n!cp ../input/packages/ta/six-1.16.0-py2.py3-none-any.whl /tmp/pip/cache/six-1.16.0-py2.py3-none-any.whl\n!cp ../input/packages/ta/python_dateutil-2.8.2-py2.py3-none-any.whl /tmp/pip/cache/python_dateutil-2.8.2-py2.py3-none-any.whl\n!cp ../input/packages/ta/ta-0.10.1.xyz /tmp/pip/cache/ta-0.10.1.tar.gz","metadata":{"execution":{"iopub.status.busy":"2022-06-29T06:45:02.056742Z","iopub.execute_input":"2022-06-29T06:45:02.057249Z","iopub.status.idle":"2022-06-29T06:45:08.173083Z","shell.execute_reply.started":"2022-06-29T06:45:02.057203Z","shell.execute_reply":"2022-06-29T06:45:08.171802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install --no-index --find-links /tmp/pip/cache/ ta","metadata":{"execution":{"iopub.status.busy":"2022-06-29T06:45:08.176363Z","iopub.execute_input":"2022-06-29T06:45:08.177175Z","iopub.status.idle":"2022-06-29T06:45:22.642756Z","shell.execute_reply.started":"2022-06-29T06:45:08.177121Z","shell.execute_reply":"2022-06-29T06:45:22.641558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport ta\nimport xgboost as xgb\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-06-29T06:45:22.644222Z","iopub.execute_input":"2022-06-29T06:45:22.644603Z","iopub.status.idle":"2022-06-29T06:45:23.372326Z","shell.execute_reply.started":"2022-06-29T06:45:22.644568Z","shell.execute_reply":"2022-06-29T06:45:23.371369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# import data","metadata":{}},{"cell_type":"code","source":"root = \"../input/jpx-tokyo-stock-exchange-prediction\"\nstock_prices_raw = pd.read_csv(f\"{root}/train_files/stock_prices.csv\")\nfinancials_raw = pd.read_csv(f\"{root}/train_files/financials.csv\")\noptions_raw = pd.read_csv(f\"{root}/train_files/options.csv\")\nsecondary_stock_prices_raw = pd.read_csv(f\"{root}/train_files/secondary_stock_prices.csv\")\ntrades_raw = pd.read_csv(f\"{root}/train_files/trades.csv\")\n\nstock_prices_raw = stock_prices_raw.drop('Target',axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-29T06:45:23.373679Z","iopub.execute_input":"2022-06-29T06:45:23.374331Z","iopub.status.idle":"2022-06-29T06:46:04.844422Z","shell.execute_reply.started":"2022-06-29T06:45:23.374301Z","shell.execute_reply":"2022-06-29T06:46:04.843392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Adjust Close price","metadata":{}},{"cell_type":"code","source":"def prep_prices(price):\n    from decimal import ROUND_HALF_UP, Decimal\n    pcols = [\"Open\",\"High\",\"Low\",\"Close\"]\n    price.ExpectedDividend.fillna(0,inplace=True)\n    def qround(x):\n        return float(Decimal(str(x)).quantize(Decimal('0.1'), rounding=ROUND_HALF_UP))\n    \n    def adjust_prices(df):\n        df = df.sort_values(\"Date\", ascending=False)\n        df.loc[:, \"CumAdjust\"] = df[\"AdjustmentFactor\"].cumprod()\n\n        # generate adjusted prices\n        for p in pcols:     \n            df.loc[:, p] = (df[\"CumAdjust\"] * df[p]).apply(qround)\n        df.loc[:, \"Volume\"] = df[\"Volume\"] / df[\"CumAdjust\"]\n        \n        return df\n\n    # generate Adjusted\n    price = price.sort_values([\"SecuritiesCode\", \"Date\"])\n    price = price.groupby(\"SecuritiesCode\").apply(adjust_prices).reset_index(drop=True)\n    price = price.sort_values(\"RowId\").reset_index(drop=True)\n    price = price.sort_values([\"SecuritiesCode\", \"Date\"]).reset_index(drop=True)\n    \n    # price.dropna(subset=[\"Open\",\"High\",\"Low\",\"Close\",'Volume','Target'],inplace=True)\n    return price.drop('CumAdjust',axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-06-29T06:46:04.845605Z","iopub.execute_input":"2022-06-29T06:46:04.845918Z","iopub.status.idle":"2022-06-29T06:46:04.858409Z","shell.execute_reply.started":"2022-06-29T06:46:04.845889Z","shell.execute_reply":"2022-06-29T06:46:04.856884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Adjust prices\n# stock_prices_raw_withNaTarget = prep_prices(stock_prices_raw_withNaTarget)\n\n# # For training data: drop columns where Target == nan\n# # stock_prices_raw = stock_prices_raw_withNaTarget.dropna(subset=['Target'])\n# stock_prices_raw = stock_prices_raw_withNaTarget","metadata":{"execution":{"iopub.status.busy":"2022-06-29T06:46:04.86017Z","iopub.execute_input":"2022-06-29T06:46:04.86064Z","iopub.status.idle":"2022-06-29T06:46:04.8704Z","shell.execute_reply.started":"2022-06-29T06:46:04.860597Z","shell.execute_reply":"2022-06-29T06:46:04.869224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_min = pd.read_csv(\"../input/d/junxum/models/feature_min.csv\",index_col='SecuritiesCode')\nfeature_max = pd.read_csv(\"../input/d/junxum/models/feature_max.csv\",index_col='SecuritiesCode')","metadata":{"execution":{"iopub.status.busy":"2022-06-29T06:46:04.871558Z","iopub.execute_input":"2022-06-29T06:46:04.871901Z","iopub.status.idle":"2022-06-29T06:46:04.988817Z","shell.execute_reply.started":"2022-06-29T06:46:04.871853Z","shell.execute_reply":"2022-06-29T06:46:04.987988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generate features","metadata":{}},{"cell_type":"code","source":"def generate_ta_features(stock_prices,istrain):\n    \"\"\"\n    INPUT: original dataset\n    OUTPUT: features with Date and SecuritiesCode\n    \"\"\"\n    # if 'Target' in stock_prices.columns:\n    #     stock_prices = stock_prices.drop('Target',axis=1)\n    \n    # Calculate features\n    # features = stock_prices.groupby('SecuritiesCode').apply(lambda x: add_all_ta_features(x,open=\"Open\",high='High',low='Low',close='Close',volume='Volume'))\n    stock_prices = stock_prices.drop(['RowId', 'AdjustmentFactor', 'ExpectedDividend', 'SupervisionFlag'],axis=1)\n    \n    \n    stock_prices = stock_prices.fillna(method=\"ffill\")\n\n    features = stock_prices[['Date', 'SecuritiesCode', 'Close']].copy()\n\n    features['volume_log'] = np.log(stock_prices['Volume'])\n    def volume_adi(df):\n        return ta.volume.acc_dist_index(high=df.High, low=df.Low, close=df.Close, volume=df.Volume, fillna=False)\n    features['volume_adi'] = stock_prices.groupby('SecuritiesCode').apply(volume_adi).droplevel(0)\n    def volume_obv(df):\n        return ta.volume.on_balance_volume(close=df.Close, volume=df.Volume, fillna=False)\n    features['volume_obv'] = stock_prices.groupby('SecuritiesCode').apply(volume_obv).droplevel(0)\n    def volume_cmf(df,window):\n        return ta.volume.chaikin_money_flow(high=df.High, low=df.Low, close=df.Close, volume=df.Volume, window=window, fillna=False)\n    features['volume_cmf'] = stock_prices.groupby('SecuritiesCode').apply(volume_cmf, 2).droplevel(0)\n    def volume_fi(df,window):\n        return ta.volume.force_index(close=df.Close, volume=df.Volume, window=window, fillna=False)\n    features['volume_fi'] = stock_prices.groupby('SecuritiesCode').apply(volume_fi, 2).droplevel(0)\n    def volume_em(df,window):\n        return ta.volume.ease_of_movement(high=df.High, low=df.Low, volume=df.Volume, window=window, fillna=False)\n    features['volume_em'] = stock_prices.groupby('SecuritiesCode').apply(volume_em, 2).droplevel(0)\n    def volume_sem(df,window):\n        return ta.volume.sma_ease_of_movement(high=df.High, low=df.Low, volume=df.Volume, window=window, fillna=False)\n    features['volume_sem'] = stock_prices.groupby('SecuritiesCode').apply(volume_sem, 4).droplevel(0)\n    def volume_vpt(df):\n        return ta.volume.volume_price_trend(close=df.Close, volume=df.Volume, fillna=False)\n    features['volume_vpt'] = stock_prices.groupby('SecuritiesCode').apply(volume_vpt).droplevel(0)\n    def volume_vwap(df,window):\n        return ta.volume.volume_weighted_average_price(high=df.High, low=df.Low, close=df.Close, volume=df.Volume, window=window, fillna=False)\n    features['volume_vwap'] = stock_prices.groupby('SecuritiesCode').apply(volume_vwap,5).droplevel(0)\n    def volume_mfi(df,window):\n        return ta.volume.money_flow_index(high=df.High,low=df.Low,close=df.Close,volume=df.Volume,window=window,fillna=False)\n    features['volume_mfi'] = stock_prices.groupby('SecuritiesCode').apply(volume_mfi,2).droplevel(0)\n    def volume_nvi(df):\n        return ta.volume.negative_volume_index(close=df.Close, volume=df.Volume, fillna=False)\n    features['volume_nvi'] = stock_prices.groupby('SecuritiesCode').apply(volume_nvi).droplevel(0)\n\n    def volatility_bbw(df,window,window_dev):\n        return ta.volatility.bollinger_wband(close=df.Close,window=window,window_dev=window_dev,fillna=False)\n    features['volatility_bbw'] = stock_prices.groupby('SecuritiesCode').apply(volatility_bbw,5,1.8).droplevel(0)\n    def volatility_bbp(df,window,window_dev):\n        return ta.volatility.bollinger_pband(close=df.Close,window=window,window_dev=window_dev,fillna=False)\n    features['volatility_bbp'] = stock_prices.groupby('SecuritiesCode').apply(volatility_bbp,5,1.8).droplevel(0)\n    def volatility_bbhi(df,window,window_dev):\n        return ta.volatility.bollinger_hband_indicator(close=df.Close,window=window,window_dev=window_dev,fillna=False)\n    features['volatility_bbhi'] = stock_prices.groupby('SecuritiesCode').apply(volatility_bbhi,5,1.8).droplevel(0)\n    def volatility_bbli(df,window,window_dev):\n        return ta.volatility.bollinger_lband_indicator(close=df.Close,window=window,window_dev=window_dev,fillna=False)\n    features['volatility_bbli'] = stock_prices.groupby('SecuritiesCode').apply(volatility_bbli,5,1.8).droplevel(0)\n    def volatility_kcw(df,window):\n        return ta.volatility.keltner_channel_wband(close=df.Close,high=df.High,low=df.Low,window=window,fillna=False)\n    features['volatility_kcw'] = stock_prices.groupby('SecuritiesCode').apply(volatility_kcw,5).droplevel(0)\n    def volatility_kcp(df,window):\n        return ta.volatility.keltner_channel_pband(close=df.Close,high=df.High,low=df.Low,window=window,fillna=False)\n    features['volatility_kcp'] = stock_prices.groupby('SecuritiesCode').apply(volatility_kcp,5).droplevel(0)\n    def volatility_kchi(df,window):\n        return ta.volatility.keltner_channel_hband_indicator(close=df.Close,high=df.High,low=df.Low,window=window,fillna=False)\n    features['volatility_kchi'] = stock_prices.groupby('SecuritiesCode').apply(volatility_kchi,5).droplevel(0)\n    def volatility_kcli(df,window):\n        return ta.volatility.keltner_channel_lband_indicator(close=df.Close,high=df.High,low=df.Low,window=window,fillna=False)\n    features['volatility_kcli'] = stock_prices.groupby('SecuritiesCode').apply(volatility_kcli,5).droplevel(0)\n    def volatility_dcw(df,window):\n        return ta.volatility.donchian_channel_wband(high=df.High,low=df.Low,close=df.Close,window=window,fillna=False)\n    features['volatility_dcw'] = stock_prices.groupby('SecuritiesCode').apply(volatility_dcw,2).droplevel(0)\n    def volatility_dcp(df,window):\n        return ta.volatility.donchian_channel_pband(high=df.High,low=df.Low,close=df.Close,window=window,fillna=False)\n    features['volatility_dcp'] = stock_prices.groupby('SecuritiesCode').apply(volatility_dcp,5).droplevel(0)\n    def volatility_atr(df,window):\n        return ta.volatility.average_true_range(close=df.Close,high=df.High,low=df.Low,window=window,fillna=False)\n    features['volatility_atr'] = stock_prices.groupby('SecuritiesCode').apply(volatility_atr,2).droplevel(0)\n    def volatility_ui(df,window):\n        return ta.volatility.ulcer_index(close=df.Close,window=window,fillna=False)\n    features['volatility_ui'] = stock_prices.groupby('SecuritiesCode').apply(volatility_ui,5).droplevel(0)\n    \n    def trend_macd_signal(df, window_slow, window_fast, window_sign):\n        return ta.trend.macd_signal(close=df.Close,window_slow=window_slow, window_fast=window_fast, window_sign=window_sign,fillna=False)\n    features['trend_macd_signal'] = stock_prices.groupby('SecuritiesCode').apply(trend_macd_signal,20,8,4).droplevel(0)\n    def trend_macd_diff(df,window_slow, window_fast, window_sign):\n        return ta.trend.macd_diff(close=df.Close,window_slow=window_slow, window_fast=window_fast, window_sign=window_sign,fillna=False)\n    features['trend_macd_diff'] = stock_prices.groupby('SecuritiesCode').apply(trend_macd_diff,20,8,4).droplevel(0)\n    def trend_vortex_ind_pos(df,window):\n        return ta.trend.vortex_indicator_pos(high=df.High,low=df.Low,close=df.Close,window=window,fillna=False)\n    features['trend_vortex_ind_pos'] = stock_prices.groupby('SecuritiesCode').apply(trend_vortex_ind_pos,2).droplevel(0)\n    def trend_vortex_ind_neg(df,window):\n        return ta.trend.vortex_indicator_neg(high=df.High,low=df.Low,close=df.Close,window=window,fillna=False)\n    features['trend_vortex_ind_neg'] = stock_prices.groupby('SecuritiesCode').apply(trend_vortex_ind_neg,2).droplevel(0)\n    def trend_mass_index(df,window_fast,window_slow):\n        return ta.trend.mass_index(high=df.High,low=df.Low,window_fast=window_fast,window_slow=window_slow,fillna=False)\n    features['trend_mass_index'] = stock_prices.groupby('SecuritiesCode').apply(trend_mass_index,10,8).droplevel(0)\n    def trend_dpo(df,window):\n        return ta.trend.dpo(close=df.Close,window=window,fillna=False)\n    features['trend_dpo'] = stock_prices.groupby('SecuritiesCode').apply(trend_dpo,15).droplevel(0)\n    def trend_kst_sig(df,roc1,roc2,roc3,roc4,window1,window2,window3,window4,nsig):\n        return ta.trend.kst_sig(close=df.Close,roc1=roc1,roc2=roc2,roc3=roc3,roc4=roc4,window1=window1,window2=window2,window3=window3,window4=window4,nsig=nsig,fillna=False)\n    features['trend_kst_sig'] = stock_prices.groupby('SecuritiesCode').apply(trend_kst_sig,3,5,5,20,3,3,5,5,3).droplevel(0)\n    def trend_stc(df,window_slow,window_fast,cycle,smooth1,smooth2):\n        return ta.trend.stc(close=df.Close,window_fast=window_fast,window_slow=window_slow,cycle=cycle,smooth1=smooth1,smooth2=smooth2,fillna=False)\n    features['trend_stc'] = stock_prices.groupby('SecuritiesCode').apply(trend_stc,10,20,5,2,2).droplevel(0)\n    def trend_adx(df,window):\n        return ta.trend.adx(high=df.High,low=df.Low,close=df.Close,window=window,fillna=False)\n    features['trend_adx'] = stock_prices.groupby('SecuritiesCode').apply(trend_adx,3).droplevel(0)\n    def trend_adx_pos(df,window):\n        return ta.trend.adx_pos(high=df.High,low=df.Low,close=df.Close,window=window,fillna=False)\n    features['trend_adx_pos'] = stock_prices.groupby('SecuritiesCode').apply(trend_adx_pos,3).droplevel(0)\n    def trend_adx_neg(df,window):\n        return ta.trend.adx_neg(high=df.High,low=df.Low,close=df.Close,window=window,fillna=False)\n    features['trend_adx_neg'] = stock_prices.groupby('SecuritiesCode').apply(trend_adx_neg,3).droplevel(0)\n    def trend_cci(df,window,constant):\n        return ta.trend.cci(high=df.High, low=df.Low, close=df.Close, window=window, constant=constant, fillna=False)\n    features['trend_cci'] = stock_prices.groupby('SecuritiesCode').apply(trend_cci,2,0.015).droplevel(0)\n    def trend_aroon_up(df,window):\n        return ta.trend.aroon_up(close=df.Close,window=window,fillna=False)\n    features['trend_aroon_up'] = stock_prices.groupby('SecuritiesCode').apply(trend_aroon_up,2).droplevel(0)\n    def trend_aroon_down(df,window):\n        return ta.trend.aroon_down(close=df.Close,window=window,fillna=False)\n    features['trend_aroon_down'] = stock_prices.groupby('SecuritiesCode').apply(trend_aroon_down,2).droplevel(0)\n    \n    def momentum_rsi(df,window):\n        return ta.momentum.rsi(close=df.Close,window=window,fillna=False)\n    features['momentum_rsi'] = stock_prices.groupby('SecuritiesCode').apply(momentum_rsi,2).droplevel(0)\n    def momentum_stochrsi(df,window,smooth1,smooth2):\n        return ta.momentum.stochrsi(close=df.Close,window=window,smooth1=smooth1,smooth2=smooth2,fillna=False)\n    features['momentum_stochrsi'] = stock_prices.groupby('SecuritiesCode').apply(momentum_stochrsi,20,3,3).droplevel(0)\n    def momentum_roc(df,window):\n        return ta.momentum.roc(close=df.Close, window=window, fillna=False)\n    features['momentum_tsi'] = stock_prices.groupby('SecuritiesCode').apply(momentum_roc,8).droplevel(0)\n    def momentum_pvo(df,window_slow,window_fast,window_sign):\n        return ta.momentum.pvo(volume=df.Volume,window_fast=window_fast,window_slow=window_slow,window_sign=window_sign,fillna=False)\n    features['momentum_pvo'] = stock_prices.groupby('SecuritiesCode').apply(momentum_pvo,20,15,3).droplevel(0)\n    def momentum_pvo_hist(df,window_slow,window_fast,window_sign):\n        return ta.momentum.pvo_hist(volume=df.Volume,window_fast=window_fast,window_slow=window_slow,window_sign=window_sign,fillna=False)\n    features['momentum_pvo_hist'] = stock_prices.groupby('SecuritiesCode').apply(momentum_pvo_hist,20,15,3).droplevel(0)\n    def others_dr(df):\n        return ta.others.daily_return(close=df.Close,fillna=False)\n    features['momentum_pvo_hist'] = stock_prices.groupby('SecuritiesCode').apply(others_dr).droplevel(0)\n    def others_dlr(df):\n        return ta.others.daily_log_return(close=df.Close,fillna=False)\n    features['momentum_pvo_hist'] = stock_prices.groupby('SecuritiesCode').apply(others_dlr).droplevel(0)\n\n    # get all the column names\n    # col = features.columns\n    # col = col.drop(['Date','SecuritiesCode'])\n\n    # def minmaxscale(df):\n    #     return (df-df.min())/(df.max()-df.min())\n    # features[col] = features.groupby('SecuritiesCode')[col].apply(minmaxscale)\n\n\n    # filling data for nan and inf\n    if istrain:\n        features = features[features.Date > '2017-02-10']\n        # features = features.dropna(thresh=40,axis=0)\n        features = features.dropna(how='any',axis=0) # about 2% is nan\n    else:\n        features = features.fillna(method=\"ffill\")\n    \n    features = features.replace([np.inf, -np.inf], 0)\n\n    return features\n","metadata":{"execution":{"iopub.status.busy":"2022-06-29T06:46:04.99316Z","iopub.execute_input":"2022-06-29T06:46:04.993717Z","iopub.status.idle":"2022-06-29T06:46:05.084111Z","shell.execute_reply.started":"2022-06-29T06:46:04.993681Z","shell.execute_reply":"2022-06-29T06:46:05.083274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# financials data cleaning\ndef prep_financials(financials):\n    \"\"\"\n    - Date to datetime type.\n    - Fill all NaN by np.nan.\n    - Transform numbers to numerical type and substitude all '－' to np.nan.\n    - Delete ForecastRevision and duplicated rows.\n    - Will not drop Nan.\n    \"\"\"\n    financials.fillna(np.nan,inplace=True)\n    financials.dropna(subset=['DateCode'],inplace=True)\n    financials = financials[~financials.TypeOfDocument.str.contains('ForecastRevision')]\n    financials = financials[~financials.TypeOfDocument.str.contains('NumericalCorrection')]\n    financials = financials.drop_duplicates(subset=['DateCode'],keep='first')  # delete duplicates\n    financials = financials.apply(pd.to_numeric, errors='ignore')\n    financials = financials.replace('－',np.nan)\n\n    # Clean some number-type columns.\n    lis = ['NetSales','OrdinaryProfit','OperatingProfit','EarningsPerShare','TotalAssets','Profit','NumberOfIssuedAndOutstandingSharesAtTheEndOfFiscalYearIncludingTreasuryStock','Equity']\n    financials[lis] = financials[lis].apply(pd.to_numeric,errors='coerce')\n    \n    financials['Date'] = pd.to_datetime(financials['Date'])\n\n    def adjust_to_year(df):\n    \n        df['TypeMark'] = df.apply(lambda x:0 if x['TypeOfCurrentPeriod']=='FY' else 1,axis=1)\n\n        items_to_adjust = ['NetSales','OperatingProfit','OrdinaryProfit','Profit','EarningsPerShare']\n        \n        def adjust_item(df1):\n            df_to_subtract = df1[items_to_adjust].mul(df1.TypeMark,axis=0)\n            df_to_shift = df_to_subtract.shift()\n            df1[items_to_adjust] = df1[items_to_adjust] - df_to_shift\n            return df1\n        df = df.groupby(\"SecuritiesCode\").apply(adjust_item)\n        return df\n    \n    financials = adjust_to_year(financials)\n    return financials\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-29T06:46:05.085571Z","iopub.execute_input":"2022-06-29T06:46:05.085895Z","iopub.status.idle":"2022-06-29T06:46:05.099124Z","shell.execute_reply.started":"2022-06-29T06:46:05.085867Z","shell.execute_reply":"2022-06-29T06:46:05.098342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_fin_features(stock_prices, financials):\n    \"\"\"\n    Args:\n        prices (pd.DataFrame)  : RowId renamed as DateCode\n        financials (pd.DataFrame)  : cleaned\n        ...\n    Returns:\n        feature DataFrame (pd.DataFrame): with Date and SecuritiesCode\n        - Will not drop Nan.\n        - Standardize \n    \"\"\"\n    # financial indicators\n    stock_prices = stock_prices.rename(columns = {'RowId':'DateCode'})\n    financials['netsales_growth_rate'] = financials.groupby('SecuritiesCode')['NetSales'].transform(lambda x:(x-x.shift(1))/x.shift(1))\n    pricesfin = pd.merge(stock_prices[['DateCode','Close']],financials,on='DateCode').sort_values(['DateCode'])\n    features = pricesfin[['DateCode']].copy(deep=True)\n    #PE\n    features['PE'] = pricesfin['Close']/pricesfin['EarningsPerShare']\n    #PEcut\n    features['PEcut'] = pricesfin['Close']/(pricesfin['EarningsPerShare']-pricesfin['OrdinaryProfit']/pricesfin['NumberOfIssuedAndOutstandingSharesAtTheEndOfFiscalYearIncludingTreasuryStock'])\n    #PEG\n    features['PEG'] = features['PE']/pricesfin['netsales_growth_rate']\n    #PS\n    features['PS'] = pricesfin['Close']/(pricesfin['OperatingProfit']/pricesfin['NumberOfIssuedAndOutstandingSharesAtTheEndOfFiscalYearIncludingTreasuryStock'])\n    #PB\n    features['PB'] = pricesfin['Close']/(pricesfin['TotalAssets']/pricesfin['NumberOfIssuedAndOutstandingSharesAtTheEndOfFiscalYearIncludingTreasuryStock'])\n    # ROE, ROA, GPM, NPM, Em\n    features[\"ROE\"] = pricesfin.Profit/pricesfin.Equity\n    features[\"ROA\"] = pricesfin.Profit/pricesfin.TotalAssets\n    features[\"GPM\"] = pricesfin.OrdinaryProfit/pricesfin.NetSales\n    features[\"NPM\"] = pricesfin.Profit/pricesfin.NetSales\n    features[\"EM\"] = pricesfin.TotalAssets/pricesfin.Equity\n    # RG, NPG, ROEG, ROAG\n    def calculate_for_single_company(df):\n        df['shift1_NetSales'] = df.NetSales.shift()\n        df['shift1_Profit'] = df.Profit.shift()\n        df['shift1_ROE'] = df.ROE.shift()\n        df['shift1_ROA'] = df.ROA.shift()\n        return df\n    pricesfin = pd.merge(features,pricesfin,on='DateCode',how='left').groupby(\"SecuritiesCode\").apply(calculate_for_single_company)\n\n    features['RG'] = pricesfin.NetSales/pricesfin.shift1_NetSales - 1\n    features['NPG'] = pricesfin.Profit/pricesfin.shift1_Profit - 1\n    features['ROEG'] = pricesfin.ROE/pricesfin.shift1_ROE - 1\n    features['ROAG'] = pricesfin.ROA/pricesfin.shift1_ROA - 1\n    \n    features = pd.merge(stock_prices[['DateCode','Date','SecuritiesCode']], features, on='DateCode', how='left').sort_values(['DateCode'])\n    features = features.groupby('SecuritiesCode').apply(lambda x: x.ffill())\n    features = features.replace([np.inf,-np.inf],np.nan)\n    return features\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-29T06:46:05.100435Z","iopub.execute_input":"2022-06-29T06:46:05.100987Z","iopub.status.idle":"2022-06-29T06:46:05.120722Z","shell.execute_reply.started":"2022-06-29T06:46:05.100954Z","shell.execute_reply":"2022-06-29T06:46:05.119297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load model","metadata":{}},{"cell_type":"code","source":"# pre_load model\nfrom xgboost import Booster\nmodel = Booster()\nmodel.load_model(\"../input/d/junxum/models/xgbreg.txt\")\n","metadata":{"execution":{"iopub.status.busy":"2022-06-29T06:46:05.122429Z","iopub.execute_input":"2022-06-29T06:46:05.122777Z","iopub.status.idle":"2022-06-29T06:46:05.176711Z","shell.execute_reply.started":"2022-06-29T06:46:05.122747Z","shell.execute_reply":"2022-06-29T06:46:05.175573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Time API","metadata":{}},{"cell_type":"code","source":"# load Time Series API\nimport jpx_tokyo_market_prediction\n# make Time Series API environment (this function can be called only once in a session)\nenv = jpx_tokyo_market_prediction.make_env()\n# get iterator to fetch data day by day\niter_test = env.iter_test()","metadata":{"execution":{"iopub.status.busy":"2022-06-29T06:46:05.178468Z","iopub.execute_input":"2022-06-29T06:46:05.178811Z","iopub.status.idle":"2022-06-29T06:46:05.188941Z","shell.execute_reply.started":"2022-06-29T06:46:05.178781Z","shell.execute_reply":"2022-06-29T06:46:05.187545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def minmaxscale(df):\n    # by saving values\n    code = df.SecuritiesCode.unique()[0]\n    if code in feature_min.index:\n        df_min = feature_min[feature_min.index==code].values\n        df_max = feature_max[feature_max.index==code].values\n        df.iloc[:,2:] = (df.iloc[:,2:]-df_min)/(df_max-df_min)\n    return df\ncounter = 0\n# fetch data day by day\nfor (prices, options, financials, trades, secondary_prices, sample_prediction) in iter_test:\n    current_date = prices[\"Date\"].iloc[0]\n    sample_prediction_date = sample_prediction[\"Date\"].iloc[0]\n    print(f\"current_date: {current_date}, sample_prediction_date: {sample_prediction_date}\")\n    # filter data to reduce culculation cost\n    threshold = (pd.Timestamp(current_date) - pd.offsets.BDay(50)).strftime(\"%Y-%m-%d\")\n    threshold_fin = (pd.Timestamp(current_date) - pd.offsets.BDay(250)).strftime(\"%Y-%m-%d\")\n    print(f\"threshold: {threshold}\")\n\n    stock_prices_raw = stock_prices_raw.loc[(stock_prices_raw[\"Date\"] < current_date) & (stock_prices_raw[\"Date\"] >= threshold)]\n    financials_raw = financials_raw.loc[(financials_raw[\"Date\"] < current_date) & (financials_raw[\"Date\"] >= threshold_fin)]\n    options_raw = options_raw.loc[(options_raw[\"Date\"] < current_date) & (options_raw[\"Date\"] >= threshold)]\n    secondary_stock_prices_raw = secondary_stock_prices_raw.loc[(secondary_stock_prices_raw[\"Date\"] < current_date) & (secondary_stock_prices_raw[\"Date\"] >= threshold)]\n    trades_raw = trades_raw.loc[(trades_raw[\"Date\"] < current_date) & (trades_raw[\"Date\"] >= threshold)]\n\n\n    # to generate AdjustedClose, increment price data\n    stock_prices_raw = pd.concat([stock_prices_raw, prices])\n    financials_raw = pd.concat([financials_raw, financials])\n#     options = pd.concat([options_raw, options])\n#     secondary_stock_prices = pd.concat([secondary_stock_prices_raw,secondary_prices])\n#     trades = pd.concat([trades_raw,trades])\n    \n    # generate AdjustedClose and fin data\n    stock_prices = prep_prices(stock_prices_raw)\n    financials = prep_financials(financials_raw)\n\n    # get target SecuritiesCodes\n    codes = sorted(prices[\"SecuritiesCode\"].unique())\n\n    # generate feature\n    features_ta = generate_ta_features(stock_prices,False)\n    features_fin = generate_fin_features(stock_prices,financials)\n    feature = pd.merge(features_ta,features_fin,on=['Date','SecuritiesCode'],how='left')\n    # filter feature for this iteration\n    feature = feature.loc[feature.Date == current_date]\n    feature = feature.drop('DateCode',axis=1)\n    \n    \n    feature = feature.groupby('SecuritiesCode',as_index=False).apply(minmaxscale)\n\n        \n\n    # prediction\n    X_test = xgb.DMatrix(feature.drop(['Date','SecuritiesCode'],axis=1))\n    feature.loc[:, \"predict\"] = model.predict(X_test)\n\n    # set rank by predict\n    feature = feature.sort_values(\"predict\", ascending=False).drop_duplicates(subset=['SecuritiesCode'])\n    feature.loc[:, \"Rank\"] = np.arange(len(feature))\n    feature_map = feature.set_index('SecuritiesCode')['Rank'].to_dict()\n    sample_prediction['Rank'] = sample_prediction['SecuritiesCode'].map(feature_map)\n\n    # check Rank\n    assert sample_prediction[\"Rank\"].notna().all()\n    assert sample_prediction[\"Rank\"].min() == 0\n    assert sample_prediction[\"Rank\"].max() == len(sample_prediction[\"Rank\"]) - 1\n    assert sample_prediction[\"Rank\"].max() == 1999\n\n    # register your predictions\n    env.predict(sample_prediction)\n    counter += 1","metadata":{"execution":{"iopub.status.busy":"2022-06-29T06:46:05.190443Z","iopub.execute_input":"2022-06-29T06:46:05.191104Z","iopub.status.idle":"2022-06-29T06:53:44.551414Z","shell.execute_reply.started":"2022-06-29T06:46:05.191056Z","shell.execute_reply":"2022-06-29T06:53:44.550607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stock_prices_raw","metadata":{"execution":{"iopub.status.busy":"2022-06-29T06:53:44.552976Z","iopub.execute_input":"2022-06-29T06:53:44.554096Z","iopub.status.idle":"2022-06-29T06:53:44.58967Z","shell.execute_reply.started":"2022-06-29T06:53:44.55403Z","shell.execute_reply":"2022-06-29T06:53:44.588487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature","metadata":{"execution":{"iopub.status.busy":"2022-06-29T06:53:44.591143Z","iopub.execute_input":"2022-06-29T06:53:44.591617Z","iopub.status.idle":"2022-06-29T06:53:44.627361Z","shell.execute_reply.started":"2022-06-29T06:53:44.591573Z","shell.execute_reply":"2022-06-29T06:53:44.626611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}