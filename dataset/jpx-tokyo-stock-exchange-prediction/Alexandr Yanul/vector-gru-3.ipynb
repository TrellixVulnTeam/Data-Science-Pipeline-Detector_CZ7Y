{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from pandas import DataFrame\nfrom pandas import Series\nimport pandas as pd\nimport numpy as np\n\n\nclass DataPreparer:\n    normalizedData: DataFrame\n    differentiatedData: DataFrame\n    structuredData: DataFrame\n    stds: Series\n    means: Series\n\n    def __init__(self, structuredData: DataFrame, trainMaxIndex):\n        self.structuredData = structuredData\n        self.trainMaxIndex = trainMaxIndex\n        self.stds = Series(dtype='float64')\n        self.means = Series(dtype='float64')\n\n    def prepareData(self):\n        self.__differentiateData()\n        self.__normalizeData()\n\n        return self.normalizedData\n\n    def restoreData(self, predicts: Series, previousRow: Series):\n        resultDict = {}\n        for orgNumber in predicts.index:\n            prevValue = previousRow[orgNumber]\n            deviation = predicts[orgNumber]\n            # deviation = deviation * self.stds[orgNumber]\n            # deviation = deviation + self.means[orgNumber]\n            newValue = prevValue * (deviation + 1)\n            resultDict[orgNumber] = newValue\n\n        resultSeries = Series(resultDict)\n        return resultSeries\n\n    def __differentiateData(self):\n        dataDf = pd.DataFrame.copy(self.structuredData)\n        dataDf = dataDf.pct_change()\n        dataDf = dataDf.fillna(0)\n        self.differentiatedData = dataDf\n\n    def __normalizeData(self):\n        self.normalizedData = pd.DataFrame.copy(self.differentiatedData)\n        return\n\n        mean = self.differentiatedData[:self.trainMaxIndex].mean(axis=0)\n        dataDf = self.differentiatedData - mean\n        std = self.differentiatedData.std(axis=0, ddof=0)\n        dataDf = dataDf / std\n        self.normalizedData = dataDf\n        self.means = mean\n        self.stds = std","metadata":{"execution":{"iopub.status.busy":"2022-04-24T18:11:49.234869Z","iopub.execute_input":"2022-04-24T18:11:49.235593Z","iopub.status.idle":"2022-04-24T18:11:49.278782Z","shell.execute_reply.started":"2022-04-24T18:11:49.235512Z","shell.execute_reply":"2022-04-24T18:11:49.278001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom pandas import DataFrame\nimport os.path\n\n\nclass DataExtractor:\n    rawExtData: DataFrame\n    mainDataFile = '/kaggle/input/jpx-tokyo-stock-exchange-prediction/train_files/stock_prices.csv'\n    extDataFile = '/kaggle/input/jpx-tokyo-stock-exchange-prediction/supplemental_files/stock_prices.csv'\n    structuredDataFile = 'data_close.csv'\n\n    def getRawExt(self):\n        rawExtData = pd.read_csv(self.extDataFile, index_col=0)\n        return rawExtData\n\n    def getStructuredData(self):\n#         if os.path.exists(self.structuredDataFile):\n#             structuredData = pd.read_csv(self.structuredDataFile, index_col=0)\n#             return structuredData\n\n        rawData = pd.read_csv(self.mainDataFile, index_col=0)\n        updates = pd.read_csv(self.extDataFile, index_col=0)\n        rawData = pd.concat([rawData, updates], axis=0)\n\n        vocStructuredData = {}\n\n        for securitiesCode in rawData['SecuritiesCode'].unique():\n            firmSeries = rawData[rawData['SecuritiesCode'] == securitiesCode]\n            date = firmSeries['Date']\n            close = firmSeries['Close']\n            close.index = date\n            vocStructuredData[securitiesCode] = close\n            continue\n\n        structuredData = DataFrame(vocStructuredData)\n#         structuredData.to_csv(self.structuredDataFile)\n\n        return structuredData","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-24T18:11:49.280364Z","iopub.execute_input":"2022-04-24T18:11:49.280758Z","iopub.status.idle":"2022-04-24T18:11:49.290289Z","shell.execute_reply.started":"2022-04-24T18:11:49.280715Z","shell.execute_reply":"2022-04-24T18:11:49.288994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pandas import DataFrame\nimport numpy as np\n\n\nclass DataGenerator:\n\n    def __init__(self, preparedData: DataFrame, lookBack: int, batchSize: int, trainMaxIndex: int, countTests: int):\n        self.preparedData = preparedData\n        self.lookBack = lookBack\n        self.batchSize = batchSize\n        self.trainMaxIndex = trainMaxIndex\n        self.countTests = countTests\n\n    def getTrainArray(self):\n        trainGen = self.getTrainGen()\n        trainSteps, valSteps, testSteps = self.getStepsCounts()\n        X, y = self.__getArray(trainGen, trainSteps)\n\n        return X, y\n\n    def getValArray(self):\n        valGen = self.getValGen()\n        trainSteps, valSteps, testSteps = self.getStepsCounts()\n        X, y = self.__getArray(valGen, valSteps)\n\n        return X, y\n\n    def getTestArray(self):\n        testGen = self.getValGen()\n        trainSteps, valSteps, testSteps = self.getStepsCounts()\n        X, y = self.__getArray(testGen, testSteps)\n\n        return X, y\n\n    def __getArray(self, generator, countSteps):\n        data = self.preparedData\n        lookBack = self.lookBack\n        X = np.zeros((self.batchSize * countSteps, lookBack, data.shape[-1]))\n        y = np.zeros((self.batchSize * countSteps, data.shape[-1]))\n        currentRowX = 0\n        currentRowY = 0\n        for i in range(countSteps):\n            samples, targets = next(generator)\n            for sampleItem in samples:\n                X[currentRowX] = sampleItem\n                currentRowX += 1\n            for targetItem in targets:\n                y[currentRowY] = targetItem\n                currentRowY += 1\n\n        return X, y\n\n    def getTrainGen(self):\n        shuffle = False\n        minIndex = 0\n        maxIndex = self.trainMaxIndex\n        return self.getGenerator(minIndex, maxIndex, shuffle)\n\n    def getValGen(self):\n        shuffle = False\n        minIndex = self.trainMaxIndex + 1\n        maxIndex = self.trainMaxIndex + self.countTests\n        return self.getGenerator(minIndex, maxIndex, shuffle)\n\n    def getTestGen(self):\n        shuffle = False\n        minIndex = self.trainMaxIndex + self.countTests + 1\n        maxIndex = None\n        return self.getGenerator(minIndex, maxIndex, shuffle)\n\n    def getStepsCounts(self):\n        trainSteps = (self.trainMaxIndex - self.lookBack) // self.batchSize\n        valSteps = (self.countTests - self.lookBack) // self.batchSize\n        testSteps = (len(self.preparedData) - self.trainMaxIndex - self.countTests - self.lookBack) // self.batchSize\n\n        return trainSteps, valSteps, testSteps\n\n    def getGenerator(self, minIndex, maxIndex, shuffle):\n        data = self.preparedData\n        lookBack = self.lookBack\n        batchSize = self.batchSize\n        if maxIndex is None:\n            maxIndex = len(data) - 1\n        i = minIndex + lookBack\n        while 1:\n            if shuffle:\n                rows = np.random.randint(minIndex + lookBack, maxIndex, size=batchSize)\n            else:\n                if i + batchSize >= maxIndex:\n                    i = minIndex + lookBack\n                rows = np.arange(i, min(i + batchSize, maxIndex))\n                i += len(rows)\n\n            samples = np.zeros((len(rows), lookBack, data.shape[-1]))\n            targets = np.zeros((len(rows), data.shape[-1]))\n\n            for j, row in enumerate(rows):\n                indices = range(rows[j] - lookBack, rows[j], 1)\n                samples[j] = data.iloc[indices]\n                targets[j] = data.iloc[rows[j]]\n\n            yield samples, targets","metadata":{"execution":{"iopub.status.busy":"2022-04-24T18:11:49.305033Z","iopub.execute_input":"2022-04-24T18:11:49.305491Z","iopub.status.idle":"2022-04-24T18:11:49.331073Z","shell.execute_reply.started":"2022-04-24T18:11:49.305461Z","shell.execute_reply":"2022-04-24T18:11:49.330021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom pandas import Series\n\n\nclass NaivePredictor:\n    stds: Series\n    means: Series\n\n    def __init__(self, valSteps, valGen, stds, means):\n        self.valSteps = valSteps\n        self.valGen = valGen\n        self.stds = stds\n        self.means = means\n\n    def evaluate(self):\n        batchMaes = []\n        for step in range(self.valSteps):\n            samples, targets = next(self.valGen)\n            zeroSamplesLine = np.zeros(targets.shape[-1])\n            # zeroSamplesLine -= self.means\n            # zeroSamplesLine /= self.stds\n            zeroSamples = np.zeros(targets.shape)\n            for i in range(zeroSamples.shape[0]):\n                zeroSamples[i] = zeroSamplesLine\n            mae = np.mean(np.abs(zeroSamples - targets))\n            batchMaes.append(mae)\n\n        return np.mean(batchMaes)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-24T18:11:49.335955Z","iopub.execute_input":"2022-04-24T18:11:49.337178Z","iopub.status.idle":"2022-04-24T18:11:49.346642Z","shell.execute_reply.started":"2022-04-24T18:11:49.336761Z","shell.execute_reply":"2022-04-24T18:11:49.345527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras import callbacks\nimport datetime\n\n\nclass GruPredictorArray:\n    def makeModelAndFit(self, floatData, X, y, X_val, y_val, numEpochs, batchSize):\n        model = Sequential()\n        model.add(layers.GRU(4, input_shape=(None, floatData.shape[-1])))\n        model.add(layers.Dense(floatData.shape[-1]))\n\n        now = datetime.datetime.now()\n        timeStr = now.isoformat().replace(':', '-')\n\n        callbacksList = [\n            callbacks.ModelCheckpoint(filepath='trained.h5', monitor='val_loss', save_best_only=True)\n        ]\n\n        optimizer = RMSprop()\n        model.compile(optimizer=optimizer, loss='mae', metrics=['acc'])\n        print(model.summary())\n\n        history = model.fit(X, y, epochs=numEpochs, batch_size=batchSize, callbacks=callbacksList, validation_data=(X_val, y_val))\n\n        return history","metadata":{"execution":{"iopub.status.busy":"2022-04-24T18:11:49.364711Z","iopub.execute_input":"2022-04-24T18:11:49.365073Z","iopub.status.idle":"2022-04-24T18:11:55.745331Z","shell.execute_reply.started":"2022-04-24T18:11:49.365041Z","shell.execute_reply":"2022-04-24T18:11:55.744421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import load_model\n\npd.set_option('display.max_columns', 20)\npd.set_option('display.max_rows', 20)\npd.set_option('display.precision', 4)\npd.set_option('display.width', 200)\n\nnp.set_printoptions(linewidth=75, formatter=dict(float=lambda x: \"%.3g\" % x))","metadata":{"execution":{"iopub.status.busy":"2022-04-24T18:11:55.747034Z","iopub.execute_input":"2022-04-24T18:11:55.747334Z","iopub.status.idle":"2022-04-24T18:11:55.754882Z","shell.execute_reply.started":"2022-04-24T18:11:55.747296Z","shell.execute_reply":"2022-04-24T18:11:55.754144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainMaxIndex = 1100\ncountTests = 158\nlookBack = 60\ndataExtractor = DataExtractor()\nstructuredData = dataExtractor.getStructuredData()\n# print(structuredData)\n\ndataPreparer = DataPreparer(structuredData, trainMaxIndex)\npreparedData = dataPreparer.prepareData()\n# print(preparedData)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T18:11:55.756623Z","iopub.execute_input":"2022-04-24T18:11:55.757392Z","iopub.status.idle":"2022-04-24T18:12:11.202991Z","shell.execute_reply.started":"2022-04-24T18:11:55.757329Z","shell.execute_reply":"2022-04-24T18:12:11.202051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batchSize = 25\ndataGenerator = DataGenerator(preparedData=preparedData, lookBack=lookBack, batchSize=batchSize, trainMaxIndex=trainMaxIndex, countTests=countTests)\nX, y = dataGenerator.getTrainArray()\nX_val, y_val = dataGenerator.getValArray()","metadata":{"execution":{"iopub.status.busy":"2022-04-24T18:12:11.206072Z","iopub.execute_input":"2022-04-24T18:12:11.206495Z","iopub.status.idle":"2022-04-24T18:12:12.942893Z","shell.execute_reply.started":"2022-04-24T18:12:11.20645Z","shell.execute_reply":"2022-04-24T18:12:12.942012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valGen = dataGenerator.getValGen()\ntrainSteps, valSteps, testSteps = dataGenerator.getStepsCounts()\npredictor = NaivePredictor(valSteps, valGen, dataPreparer.stds, dataPreparer.means)\nmaeNaive = predictor.evaluate()\nprint(maeNaive)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T18:12:12.944249Z","iopub.execute_input":"2022-04-24T18:12:12.945481Z","iopub.status.idle":"2022-04-24T18:12:13.024098Z","shell.execute_reply.started":"2022-04-24T18:12:12.945443Z","shell.execute_reply":"2022-04-24T18:12:13.023156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"numEpochs = 10\npredictor = GruPredictorArray()\nhistory = predictor.makeModelAndFit(preparedData, X, y, X_val, y_val, numEpochs, batchSize)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T18:12:13.025479Z","iopub.execute_input":"2022-04-24T18:12:13.02609Z","iopub.status.idle":"2022-04-24T18:12:26.618056Z","shell.execute_reply.started":"2022-04-24T18:12:13.02603Z","shell.execute_reply":"2022-04-24T18:12:26.616773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = history.history['loss']\nvalLoss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training Loss')\nplt.plot(epochs, valLoss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nprint('\\n')\nprint(f'MAE naive: {maeNaive:.4f}')\nprint(f'MAE Sequential: {min(valLoss):.4f}')","metadata":{"execution":{"iopub.status.busy":"2022-04-24T18:12:26.624317Z","iopub.execute_input":"2022-04-24T18:12:26.62732Z","iopub.status.idle":"2022-04-24T18:12:27.056222Z","shell.execute_reply.started":"2022-04-24T18:12:26.627218Z","shell.execute_reply":"2022-04-24T18:12:27.055374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rawExtData = dataExtractor.getRawExt()\nmodel = load_model('trained.h5')\n\nranksDict = {'Date': rawExtData.Date, 'SecuritiesCode': rawExtData.SecuritiesCode, 'Rank': 0}\nranks = pd.DataFrame(ranksDict, index=rawExtData.index)\n\ndates = rawExtData['Date'].unique()\n\nallDeltas = pd.DataFrame()\nallRanks = pd.DataFrame()\n\nfor currDate in dates:\n    endRowIndex, = np.where(preparedData.index.values == currDate)\n\n    inputDataDf = preparedData.iloc[endRowIndex[0] - lookBack:endRowIndex[0]]\n    inputData = inputDataDf.values\n    inputData = inputData.reshape(1, inputData.shape[0], inputData.shape[1])\n\n    lastRow = model.predict(inputData)\n    lastRow = lastRow[0]\n    lastRow = pd.Series(lastRow)\n\n    previousRow = structuredData.iloc[endRowIndex[0] - 1]\n    lastRow.index = previousRow.index\n\n    restoredRow = dataPreparer.restoreData(lastRow, previousRow)\n\n    # testRow = structuredData.iloc[endRowIndex[0]]\n    # print(testRow)\n    # print(restoredRow)\n    # testRow[:100].plot(style=\"b\")\n    # restoredRow[:100].plot(style=\"r\")\n    # plt.show()\n\n    delta = (restoredRow - previousRow) / previousRow\n\n    orgDict = {}\n    for orgId in restoredRow.index:\n        orgDict[orgId] = delta[orgId]\n\n    deltas = pd.DataFrame(orgDict, index=[currDate])\n\n    allDeltas = pd.concat([allDeltas, deltas], axis=0)\n\n    # print(deltas)\n\n    orgsSorted = deltas.T.sort_values(by=currDate, ascending=False)\n\n    # print(orgsSorted)\n    # print(orgsSorted.index[3])\n    # print(orgsSorted.index.size)\n    rankDf = deltas\n    for rankValue in range(orgsSorted.index.size):\n        orgId = orgsSorted.index[rankValue]\n        rankDf[orgId][currDate] = rankValue\n\n    allRanks = pd.concat([allRanks, rankDf], axis=0)\n\nprint(allDeltas)\nprint(allRanks)\n\n# allRanks.to_csv('all_ranks.csv')\n\nresultDf = pd.DataFrame()\n\nfor date in allRanks.index:\n    currRow = allRanks.loc[date]\n    for orgId in currRow.index:\n        rankValue = currRow[orgId]\n        rowItem = pd.DataFrame({'Date': [date], 'SecuritiesCode': [orgId], 'Rank': [rankValue]})\n        resultDf = pd.concat([resultDf, rowItem])\n\nprint(resultDf)\nresultDf.to_csv('submission2.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T18:12:27.060685Z","iopub.execute_input":"2022-04-24T18:12:27.063077Z","iopub.status.idle":"2022-04-24T18:16:20.616Z","shell.execute_reply.started":"2022-04-24T18:12:27.063019Z","shell.execute_reply":"2022-04-24T18:16:20.615142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\npredictsDf = pd.read_csv('submission2.csv')\nprint(predictsDf)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T18:16:20.620884Z","iopub.execute_input":"2022-04-24T18:16:20.621142Z","iopub.status.idle":"2022-04-24T18:16:20.672132Z","shell.execute_reply.started":"2022-04-24T18:16:20.621087Z","shell.execute_reply":"2022-04-24T18:16:20.670923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import jpx_tokyo_market_prediction\nenv = jpx_tokyo_market_prediction.make_env()   # initialize the environment\niter_test = env.iter_test()    # an iterator which loops over the test files\nfor (prices, options, financials, trades, secondary_prices, sample_prediction) in iter_test:\n#     sample_prediction_df['Rank'] = predictsDf['Rank']  # make your predictions here\n    env.predict(predictsDf)   # register your predictions\n","metadata":{"execution":{"iopub.status.busy":"2022-04-24T18:16:20.675192Z","iopub.execute_input":"2022-04-24T18:16:20.675583Z","iopub.status.idle":"2022-04-24T18:16:21.47503Z","shell.execute_reply.started":"2022-04-24T18:16:20.675541Z","shell.execute_reply":"2022-04-24T18:16:21.474009Z"},"trusted":true},"execution_count":null,"outputs":[]}]}