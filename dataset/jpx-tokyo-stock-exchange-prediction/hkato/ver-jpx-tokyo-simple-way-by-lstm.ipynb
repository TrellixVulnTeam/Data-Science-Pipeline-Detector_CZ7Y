{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction  \nこのコンペティションは、実際に株式会社日本取引所グループ(Japan Exchange Group, Inc.; JPX)で売買されている株式の銘柄について、将来のリターンが高いものを予測するものとなっています。  \nそこでこのノートブックでは、Kaggle初学者では見慣れない`jpx_tokyo_market_prediction`の扱い方と、トレーニングデータにある関連データの取り出し方について取り組みます。  ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-07T13:57:19.35654Z","iopub.execute_input":"2022-04-07T13:57:19.357504Z","iopub.status.idle":"2022-04-07T13:57:19.40367Z","shell.execute_reply.started":"2022-04-07T13:57:19.357393Z","shell.execute_reply":"2022-04-07T13:57:19.40288Z"}}},{"cell_type":"markdown","source":"# Table of Contents  \n- [Explanation of data](#Explanation-of-data)\n- [jpx_tokyo_market_prediction](#jpx_tokyo_market_prediction)\n- [Create models and submit data](#Create-models-and-submit-data)","metadata":{}},{"cell_type":"markdown","source":"# Explanation of data","metadata":{}},{"cell_type":"markdown","source":"## Loading Modules\nまず、必要なモジュールをロードします。  \n今回は、pandasを用いてデータのロードを行います。","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2022-04-21T07:40:41.902028Z","iopub.execute_input":"2022-04-21T07:40:41.902415Z","iopub.status.idle":"2022-04-21T07:40:41.913005Z","shell.execute_reply.started":"2022-04-21T07:40:41.902342Z","shell.execute_reply":"2022-04-21T07:40:41.912324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Check the data\npandasの`read_csv`を使い*`stock_price.csv`*を読み込みます。","metadata":{}},{"cell_type":"code","source":"stock_price_df = pd.read_csv(\"../input/jpx-tokyo-stock-exchange-prediction/train_files/stock_prices.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-04-21T07:40:41.917669Z","iopub.execute_input":"2022-04-21T07:40:41.918146Z","iopub.status.idle":"2022-04-21T07:40:45.608566Z","shell.execute_reply.started":"2022-04-21T07:40:41.91811Z","shell.execute_reply":"2022-04-21T07:40:45.607786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"このデータの形(行数・列数)と、中身を確認します。","metadata":{}},{"cell_type":"code","source":"print('(行数, 列数) =', stock_price_df.shape)\nstock_price_df.tail()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T07:40:45.609999Z","iopub.execute_input":"2022-04-21T07:40:45.610248Z","iopub.status.idle":"2022-04-21T07:40:45.633952Z","shell.execute_reply.started":"2022-04-21T07:40:45.610214Z","shell.execute_reply":"2022-04-21T07:40:45.633195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*`stock_price.csv`*に入っていたデータは以下の通りでした。  \n*  `SecuritiesCode` ... 証券コード(株式別につけられた番号)\n*   `Open` ... 始値(その日の初め(午前9時)の1株当たりの値段)\n*  `High` ... 高値(その日の最高値)\n*  `Low` ... 低値\n*  `Colse` ... 終値\n*  `Volume` ... 出来高(１日に売買が成立した株数)\n*  `AdjustmentFactor` ... 分割・併合時の理論株価・出来高の算出に使用\n*  `ExpectedDividend` ... 権利落ち日の配当予想値\n*  `SupercisionFlag` ... 監理銘柄、上場廃止銘柄のフラグ\n*  `Target` ... 修正終値の変化率(翌日から翌々日)  \n  \n今回のコンペでは、他にも多くのデータが用意されていますが、ここでは*`stock_price.csv`*の情報のみを使って実装していきます。","metadata":{}},{"cell_type":"markdown","source":"# jpx_tokyo_market_prediction\n次に、jpx_tokyo_market_predictionというAPIの使い方を確認します。  \nまず、他のモジュールと同様importします。  \n※`jpx_tokyo_market_prediction`は一度のみ実行できるので、ここではMarkdown内にイメージを書きます。","metadata":{}},{"cell_type":"markdown","source":"***\n```python\nimport jpx_tokyo_market_prediction\nenv = jpx_tokyo_market_prediction.make_env()\niter_test = env.iter_test()\n```\n","metadata":{}},{"cell_type":"markdown","source":"`make_env()`を実行して環境を作成、`iter_test()`を実行してオブジェクトを作成しました。  \n下のように、typeをみると`iter_test`はgeneratorなので、for文で1つずつ呼び出せるオブジェクトであることが確認できます。  \n***\n```python  \nprint(type(iter_test))\n```\n[出力]\n```\n<class 'generator'>\n```","metadata":{}},{"cell_type":"markdown","source":"for文を回し、以下のように動作確認する。  \n***\n```Python\ncount = 0\nfor (prices, options, financials, trades, secondary_prices, sample_prediction) in iter_test:\n    print(prices.head())\n    env.predict(sample_prediction)\n    count += 1\n    break\n```\n[出力]\n```\nThis version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n         Date          RowId  SecuritiesCode    Open    High     Low   Close  \\\n0  2021-12-06  20211206_1301            1301  2982.0  2982.0  2965.0  2971.0   \n1  2021-12-06  20211206_1332            1332   592.0   599.0   588.0   589.0   \n2  2021-12-06  20211206_1333            1333  2368.0  2388.0  2360.0  2377.0   \n3  2021-12-06  20211206_1375            1375  1230.0  1239.0  1224.0  1224.0   \n4  2021-12-06  20211206_1376            1376  1339.0  1372.0  1339.0  1351.0   \n\n    Volume  AdjustmentFactor  ExpectedDividend  SupervisionFlag  \n0     8900               1.0               NaN            False  \n1  1360800               1.0               NaN            False  \n2   125900               1.0               NaN            False  \n3    81100               1.0               NaN            False  \n4     6200               1.0               NaN            False  \n```","metadata":{}},{"cell_type":"markdown","source":"それぞれの変数名は以下の通りです。\n*  `price` ... 対象日の各銘柄のデータ。stock_price.csvのTargetを抜いた情報と同じ。　　\n*  `options` ... 対象日のoptions.csvと同じ情報。\n*  `finacials` ... 対象日のfinacials.csvと同じ情報。\n*  `trades` ... 対象日のtrades.csvと同じ情報。\n*  `secondary_prices` ... 対象日のsecandary_stock_price.csvのTargetを抜いた情報と同じ。\n*  `sample_prediction` ... 対象日のsample_prediction.csvのデータ。","metadata":{}},{"cell_type":"markdown","source":"このように、`jpx_tokyo_market_prediction`を用いて対象となる日付の2000銘柄を1日ずつ呼び出して、作成したモデルで予測し、env.predictで提出データを作成すれば、スコアが出せます。","metadata":{}},{"cell_type":"markdown","source":"# Create models and submit data\nここでは、`stock_price.csv`を用いて簡単な学習モデル作成し、提出まで実装します。","metadata":{}},{"cell_type":"markdown","source":"## Create Model(LSTM)\n**LSTM(Long Short Term Memory)**というモデルを使用します。  \nLSTMは系列データに用いるRNNの中の1つで、長期的な依存関係を学習することのできるモデルとなっています。  \nPytorchを用いて、LSTMを実装していきます。","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass LSTM(nn.Module):\n    def __init__(self, input_size=8, sequence_num=31, lstm_dim=128,\n                 num_layers=2, output_size=1):\n        super().__init__()\n        \n        self.lstm = nn.LSTM(input_size, lstm_dim, num_layers, batch_first=True, bidirectional=True)\n        self.linear1 = nn.Linear(lstm_dim*sequence_num*2, 1)\n        self.bn1 = nn.BatchNorm1d(lstm_dim*sequence_num*2)\n\n    def forward(self, x):\n        lstm_out, _ = self.lstm(x)\n        x = lstm_out.reshape(lstm_out.shape[0], -1)\n        x = self.linear1(self.bn1(x))\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-04-21T07:40:45.636154Z","iopub.execute_input":"2022-04-21T07:40:45.636833Z","iopub.status.idle":"2022-04-21T07:40:46.095076Z","shell.execute_reply.started":"2022-04-21T07:40:45.636795Z","shell.execute_reply":"2022-04-21T07:40:46.094349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create Dataset\n各銘柄ごとに取り出せるデータセットを作成する","metadata":{"execution":{"iopub.status.busy":"2022-04-20T15:02:29.337175Z","iopub.execute_input":"2022-04-20T15:02:29.337468Z","iopub.status.idle":"2022-04-20T15:02:29.352513Z","shell.execute_reply.started":"2022-04-20T15:02:29.337438Z","shell.execute_reply":"2022-04-20T15:02:29.351411Z"}}},{"cell_type":"markdown","source":"まず、stock_price_dfのNanを0に、boolをint型に、*`Date`*をdatetime型に変換する。","metadata":{}},{"cell_type":"code","source":"stock_price_df['ExpectedDividend'] = stock_price_df['ExpectedDividend'].fillna(0)\nstock_price_df['SupervisionFlag'] = stock_price_df['SupervisionFlag'].map({True: 1, False: 0})\nstock_price_df['Date'] = pd.to_datetime(stock_price_df['Date'])\nstock_price_df.info()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T07:40:46.096359Z","iopub.execute_input":"2022-04-21T07:40:46.096615Z","iopub.status.idle":"2022-04-21T07:40:46.698231Z","shell.execute_reply.started":"2022-04-21T07:40:46.096581Z","shell.execute_reply":"2022-04-21T07:40:46.697518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"いくつか、欠損値が含まれていたものがあったので、削除","metadata":{}},{"cell_type":"code","source":"stock_price_df = stock_price_df.dropna(how='any')\n# 欠損情報確認\nstock_price_df_na = (stock_price_df.isnull().sum() / len(stock_price_df)) * 100\nstock_price_df_na = stock_price_df_na.drop(stock_price_df_na[stock_price_df_na == 0].index).sort_values(ascending=False)[:30]\nmissing_data = pd.DataFrame({'Missing Ratio' :stock_price_df_na})\nmissing_data.head(22)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T07:40:46.699482Z","iopub.execute_input":"2022-04-21T07:40:46.700268Z","iopub.status.idle":"2022-04-21T07:40:47.446097Z","shell.execute_reply.started":"2022-04-21T07:40:46.700231Z","shell.execute_reply":"2022-04-21T07:40:47.445372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"sklearnのStandardScalerを使って、今回使う特徴量(RowIdとDateとSecuritiesCode以外)を標準化する","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nstdsc = StandardScaler()\ncolumns = ['Open', 'High', 'Low', 'Close', 'Volume', 'AdjustmentFactor', 'ExpectedDividend', 'SupervisionFlag']\nstock_price_df[columns] = stdsc.fit_transform(stock_price_df[columns])\nstock_price_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T07:40:47.448235Z","iopub.execute_input":"2022-04-21T07:40:47.449078Z","iopub.status.idle":"2022-04-21T07:40:48.196144Z","shell.execute_reply.started":"2022-04-21T07:40:47.449038Z","shell.execute_reply":"2022-04-21T07:40:48.195381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"銘柄ごとにデータを辞書型で保存し、各銘柄ごとに呼び出せるように保存する。","metadata":{}},{"cell_type":"code","source":"dataset_dict = {}\nfor sc in stock_price_df['SecuritiesCode'].unique():\n    dataset_dict[str(sc)] = stock_price_df[stock_price_df['SecuritiesCode'] == sc].values[:, 3:].astype(np.float32)\nprint(dataset_dict['1301'].shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T07:40:48.19744Z","iopub.execute_input":"2022-04-21T07:40:48.197721Z","iopub.status.idle":"2022-04-21T07:41:07.815323Z","shell.execute_reply.started":"2022-04-21T07:40:48.197685Z","shell.execute_reply":"2022-04-21T07:41:07.814598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Pytorchのデータローダーを使い、ミニバッチごとにデータを呼び出せるようにする。","metadata":{}},{"cell_type":"code","source":"from torch.utils.data.sampler import SubsetRandomSampler\nclass MyDataset(torch.utils.data.Dataset):\n    def __init__(self, X, sequence_num=31, y=None, mode='train'):\n        self.data = X\n        self.teacher = y\n        self.sequence_num = sequence_num\n        self.mode = mode\n    def __len__(self):\n        return len(self.teacher)\n\n    def __getitem__(self, idx):\n        out_data = self.data[idx]\n        if self.mode == 'train':\n            out_label =  self.teacher[idx[-1]]\n            return out_data, out_label\n        else:\n            return out_data\ndef create_dataloader(dataset, dataset_num, sequence_num=31, input_size=8, batch_size=32, shuffle=False):\n    sampler = np.array([list(range(i, i+sequence_num)) for i in range(dataset_num-sequence_num+1)])\n    if shuffle == True:\n        np.random.shuffle(sampler)\n    dataloader = torch.utils.data.DataLoader(dataset, batch_size, sampler=sampler)\n    return dataloader\n#### Check operation ####\nX_check, y_check = dataset_dict['1301'][:, :-1], dataset_dict['1301'][:, -1]\ndataset_check = MyDataset(X_check, y=y_check, sequence_num=31, mode='train')\ndataloader_check = create_dataloader(dataset_check, X_check.shape[0], sequence_num=31, input_size=8, batch_size=32, shuffle=False)\nfor b, tup in enumerate(dataloader_check):\n    print('---------')\n    print(tup[0].shape, tup[1].shape)\n    break","metadata":{"execution":{"iopub.status.busy":"2022-04-21T07:41:07.816661Z","iopub.execute_input":"2022-04-21T07:41:07.817086Z","iopub.status.idle":"2022-04-21T07:41:07.838354Z","shell.execute_reply.started":"2022-04-21T07:41:07.81705Z","shell.execute_reply":"2022-04-21T07:41:07.837558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training\n各銘柄ごとに、データセットを作成→モデルを学習を繰り返して、LSTMのトレーニングを行っていく。","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\nepochs = 10\nbatch_size = 512\n# Check wheter GPU is available\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n# Model Instantiation\nmodel = LSTM(input_size=8, sequence_num=31, lstm_dim=128, num_layers=2, output_size=1)\nmodel.to(device)\nmodel.train()\n# setting optimizer\nlr = 0.0001\nweight_decay = 1.0e-05\noptimizer = torch.optim.Adagrad(model.parameters(), lr=lr, weight_decay=weight_decay)\n# setting criterion\ncriterion = nn.MSELoss()\n# set iteration counter\niteration = 0\n# \nlog_train = [[0], [np.inf]]\nfor epoch in range(epochs):\n    epoch_loss = 0.0\n    for sc in tqdm(stock_price_df['SecuritiesCode'].unique()):\n        X, y = dataset_dict[str(sc)][:, :-1], dataset_dict[str(sc)][:, -1]\n        dataset = MyDataset(X, y=y, sequence_num=31, mode='train')\n        dataloader = create_dataloader(dataset, X.shape[0], sequence_num=31, input_size=8, batch_size=batch_size, shuffle=True)\n        for data, targets in dataloader:\n            data, targets = data.to(device), targets.to(device)\n            \n            optimizer.zero_grad()\n            \n            data = data.to(torch.float32)\n            output = model.forward(data)\n            targets = targets.to(torch.float32)\n            \n            loss = criterion(output.view(1,-1)[0], targets)\n            \n            loss.backward()\n            \n            optimizer.step()\n            \n            epoch_loss += loss.item()\n            \n            iteration += 1\n    epoch_loss /= iteration\n    print('epoch_loss={}'.format(epoch_loss))\n    log_train[0].append(iteration)\n    log_train[1].append(epoch_loss)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T07:41:07.839794Z","iopub.execute_input":"2022-04-21T07:41:07.840266Z","iopub.status.idle":"2022-04-21T07:41:10.897456Z","shell.execute_reply.started":"2022-04-21T07:41:07.84016Z","shell.execute_reply":"2022-04-21T07:41:10.896632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"学習状況を見るために、損失関数の現象具合を確認する。  \n　→学習できている","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(log_train[0][1:], log_train[1][1:])\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T07:41:10.898903Z","iopub.execute_input":"2022-04-21T07:41:10.899169Z","iopub.status.idle":"2022-04-21T07:41:11.07899Z","shell.execute_reply.started":"2022-04-21T07:41:10.899134Z","shell.execute_reply":"2022-04-21T07:41:11.07833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prediction\n学習させたモデルを使用して、提出データの予測を行っていく。  \n`DataFrame` → `Ndarray` → `tensor`とデータを変換して予測する。","metadata":{}},{"cell_type":"code","source":"from datetime import datetime\ndef predict(model, X_df, sequence=31):\n    pred_df = X_df[['Date', 'SecuritiesCode']]\n    # groupbyでグループ化して1つずつ取り出す\n    code_group = X_df.groupby('SecuritiesCode')\n    X_all = np.array([])\n    for sc, group in code_group:\n        # 対象データを標準化\n        group_std = stdsc.transform(group[columns])\n        # 対象データの過去データを呼び出す\n        X = dataset_dict[str(sc)][-1*(sequence-1):, :-1]\n        # 結合\n        X = np.vstack((X, group_std))\n        X_all = np.append(X_all, X)\n    X_all = X_all.reshape(-1, sequence, X.shape[1])\n    y_pred = np.array([])\n    for it in range(X_all.shape[0]//512+1):\n        data = X_all[it*512:(it+1)*512]\n        data = torch.from_numpy(data.astype(np.float32)).clone()\n        data = data.to(torch.float32)\n        data = data.to(device)\n        output = model.forward(data)\n        output = output.view(1, -1)\n        output = output.to('cpu').detach().numpy().copy()\n        y_pred = np.append(y_pred, output[0])\n    pred_df['target'] = y_pred\n    pred_df['Rank'] = pred_df[\"target\"].rank(ascending=False,method=\"first\") -1\n    pred_df['Rank'] = pred_df['Rank'].astype(int)\n    pred_df = pred_df.drop('target', axis=1)\n    return pred_df\ntest_X_df = stock_price_df[stock_price_df['Date'] == datetime(2021, 12, 3)].drop('Target', axis=1)\ny_pred = predict(model, test_X_df)\nprint(y_pred.shape)\nprint(y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T07:41:11.080195Z","iopub.execute_input":"2022-04-21T07:41:11.080443Z","iopub.status.idle":"2022-04-21T07:41:14.838748Z","shell.execute_reply.started":"2022-04-21T07:41:11.080409Z","shell.execute_reply":"2022-04-21T07:41:14.836544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# submission","metadata":{}},{"cell_type":"markdown","source":"`jpx_tokyo_market_prediction`から、提出データの作成を実施する。","metadata":{}},{"cell_type":"code","source":"import jpx_tokyo_market_prediction\nenv = jpx_tokyo_market_prediction.make_env()\niter_test = env.iter_test()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T07:41:14.841634Z","iopub.execute_input":"2022-04-21T07:41:14.841891Z","iopub.status.idle":"2022-04-21T07:41:14.850877Z","shell.execute_reply.started":"2022-04-21T07:41:14.841861Z","shell.execute_reply":"2022-04-21T07:41:14.850096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count = 0\nfor (prices, options, financials, trades, secondary_prices, sample_prediction) in iter_test:\n    prices = prices.fillna(0)\n    prices['SupervisionFlag'] = prices['SupervisionFlag'].map({True: 1, False: 0})\n    prices['Date'] = pd.to_datetime(prices['Date'])\n    pred_df = predict(model, prices)\n    print(pred_df)\n    env.predict(pred_df)\n    count += 1","metadata":{"execution":{"iopub.status.busy":"2022-04-21T07:41:14.853691Z","iopub.execute_input":"2022-04-21T07:41:14.853904Z","iopub.status.idle":"2022-04-21T07:41:23.11589Z","shell.execute_reply.started":"2022-04-21T07:41:14.85388Z","shell.execute_reply":"2022-04-21T07:41:23.114567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_df","metadata":{"execution":{"iopub.status.busy":"2022-04-21T07:41:23.117173Z","iopub.execute_input":"2022-04-21T07:41:23.117478Z","iopub.status.idle":"2022-04-21T07:41:23.131299Z","shell.execute_reply.started":"2022-04-21T07:41:23.117443Z","shell.execute_reply":"2022-04-21T07:41:23.130593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}