{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\nThe competition is to predict the highest future returns for stocks that are actually traded on the Japan Exchange Group, Inc.\nIn this notebook, we will work with `jpx_tokyo_market_prediction`, which is unfamiliar to Kaggle beginners, and how to extract the relevant data in the training data.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"# Table of Contents\n*  [Explanation of data](#Explanation-of-data)\n*  [jpx_tokyo_market_prediction](#jpx_tokyo_market_prediction)\n*  [Create models and submit data](#Create-models-and-submit-data)","metadata":{}},{"cell_type":"markdown","source":"# Explanation of data\n## Loading Modules\nFirst, load the required modules.  \nIn this case, we will use pandas to load the data.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2022-04-21T08:17:03.821729Z","iopub.execute_input":"2022-04-21T08:17:03.822086Z","iopub.status.idle":"2022-04-21T08:17:03.847479Z","shell.execute_reply.started":"2022-04-21T08:17:03.821976Z","shell.execute_reply":"2022-04-21T08:17:03.84656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Check the data\nRead *`stock_price.csv`* using `read_csv` in pandas.","metadata":{}},{"cell_type":"code","source":"stock_price_df = pd.read_csv(\"../input/jpx-tokyo-stock-exchange-prediction/train_files/stock_prices.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-04-21T08:18:24.02805Z","iopub.execute_input":"2022-04-21T08:18:24.028729Z","iopub.status.idle":"2022-04-21T08:18:31.619348Z","shell.execute_reply.started":"2022-04-21T08:18:24.028685Z","shell.execute_reply":"2022-04-21T08:18:31.618443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Check the form of this data (nrows ,columns) and the contents.","metadata":{}},{"cell_type":"code","source":"print('(rows, columns) =', stock_price_df.shape)\nstock_price_df.tail()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T08:19:20.489927Z","iopub.execute_input":"2022-04-21T08:19:20.490218Z","iopub.status.idle":"2022-04-21T08:19:20.522034Z","shell.execute_reply.started":"2022-04-21T08:19:20.490191Z","shell.execute_reply":"2022-04-21T08:19:20.521405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The data contained in `stock_price.csv` was as follows.  \n*  `SecuritiesCode` ... Securities Code (number assigned to each stock)\n*  `Open` ... Opening price (price per share at the beginning of the day (9:00 am))\n*  `High` ... High ... the highest price of the day\n*  `Low` ... Low price\n*  `Colse` ... Closing price\n*  `Volume` ... Volume (number of shares traded in a day)\n*  `AdjustmentFactor` ... Used to calculate the theoretical stock price and volume at the time of a reverse stock split or reverse stock split\n*  `ExpectedDividend` ... Expected dividend on ex-rights date\n*  `SupercisionFlag` ... Flag for supervised issues and delisted issues\n*  `Target` ... Percentage change in adjusted closing price (from one day to the next)  \n  \nAlthough many other data are available for this competition, we will implement this using only the information in `stock_price.csv`.","metadata":{}},{"cell_type":"markdown","source":"# jpx_tokyo_market_prediction\nNext, we will check the usage of the API named jpx_tokyo_market_prediction.  \nFirst, import it as you would any other module.  \nSince jpx_tokyo_market_prediction can only be executed once, we will write the image in Markdown.","metadata":{}},{"cell_type":"markdown","source":"***\n```python\nimport jpx_tokyo_market_prediction\nenv = jpx_tokyo_market_prediction.make_env()\niter_test = env.iter_test()\n```\n","metadata":{}},{"cell_type":"markdown","source":"The environment was created by executing *`make_env()`* and the object was created by executing *`iter_test()`*.\nAs shown below, looking at the type, iter_test is a generator, so we can confirm that it is an object that can be called one by one with a for statement.  \n***\n```python\nprint(type(iter_test))\n```\n[出力]  \n```\n<class 'generator'>\n```\nBy turning a for statement, check the operation as follows.\n***\n```python\ncount = 0\nfor (prices, options, financials, trades, secondary_prices, sample_prediction) in iter_test:\n    print(prices.head())\n    env.predict(sample_prediction)\n    count += 1\n    break\n```\n[出力]\n```\nThis version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n         Date          RowId  SecuritiesCode    Open    High     Low   Close  \\\n0  2021-12-06  20211206_1301            1301  2982.0  2982.0  2965.0  2971.0   \n1  2021-12-06  20211206_1332            1332   592.0   599.0   588.0   589.0   \n2  2021-12-06  20211206_1333            1333  2368.0  2388.0  2360.0  2377.0   \n3  2021-12-06  20211206_1375            1375  1230.0  1239.0  1224.0  1224.0   \n4  2021-12-06  20211206_1376            1376  1339.0  1372.0  1339.0  1351.0   \n\n    Volume  AdjustmentFactor  ExpectedDividend  SupervisionFlag  \n0     8900               1.0               NaN            False  \n1  1360800               1.0               NaN            False  \n2   125900               1.0               NaN            False  \n3    81100               1.0               NaN            False  \n4     6200               1.0               NaN            False\n```","metadata":{}},{"cell_type":"markdown","source":"The names of each variable are as follows.  \n*  `price` ... Data for each stock on the target day, the same as the information in stock_price.csv without Target.　　\n*  `options` ... Same information as options.csv for the target date.\n*  `finacials` ... Same information as finacials.csv for the target date.\n*  `trades` ... Same information as trades.csv of the target date\n*  `secondary_prices` ... Same information as secondary_stock_price.csv without Target for the target date.\n*  `sample_prediction` ... Data from sample_prediction.csv for the target date.\n","metadata":{}},{"cell_type":"markdown","source":"Thus, if we call the 2000 stocks of the target date one day at a time using *`jpx_tokyo_market_prediction`*, forecast them with the model we created, and then create the submitted data with env.predict, we can produce a score.","metadata":{}},{"cell_type":"markdown","source":"# Create models and submit data\nHere, we will create a simple training model using stock_price.csv and implement it up to submission.\n## Create Model(LSTM)\nWe use a model called LSTM (Long Short Term Memory).  \nLSTM is one of the RNNs used for series data and is a model that can learn long-term dependencies.  \nWe will implement LSTM using Pytorch.","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass LSTM(nn.Module):\n    def __init__(self, input_size=8, sequence_num=31, lstm_dim=128,\n                 num_layers=2, output_size=1):\n        super().__init__()\n        \n        self.lstm = nn.LSTM(input_size, lstm_dim, num_layers, batch_first=True, bidirectional=True)\n        self.linear1 = nn.Linear(lstm_dim*sequence_num*2, 1)\n        self.bn1 = nn.BatchNorm1d(lstm_dim*sequence_num*2)\n\n    def forward(self, x):\n        lstm_out, _ = self.lstm(x)\n        x = lstm_out.reshape(lstm_out.shape[0], -1)\n        x = self.linear1(self.bn1(x))\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-04-21T08:30:20.482752Z","iopub.execute_input":"2022-04-21T08:30:20.484147Z","iopub.status.idle":"2022-04-21T08:30:22.110808Z","shell.execute_reply.started":"2022-04-21T08:30:20.484089Z","shell.execute_reply":"2022-04-21T08:30:22.109477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Dataset\nCreate a data set that can be retrieved for each Code.  \n  \nFirst, convert Nan in *`stock_price_df`* to 0, bool to int, and *`'Date'`* to datetime.","metadata":{}},{"cell_type":"code","source":"stock_price_df['ExpectedDividend'] = stock_price_df['ExpectedDividend'].fillna(0)\nstock_price_df['SupervisionFlag'] = stock_price_df['SupervisionFlag'].map({True: 1, False: 0})\nstock_price_df['Date'] = pd.to_datetime(stock_price_df['Date'])\nstock_price_df.info()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T08:33:32.28489Z","iopub.execute_input":"2022-04-21T08:33:32.285267Z","iopub.status.idle":"2022-04-21T08:33:33.191649Z","shell.execute_reply.started":"2022-04-21T08:33:32.285236Z","shell.execute_reply":"2022-04-21T08:33:33.190228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Some of them contained missing values, so they were removed.","metadata":{}},{"cell_type":"code","source":"stock_price_df = stock_price_df.dropna(how='any')\n# Confirmation of missing information\nstock_price_df_na = (stock_price_df.isnull().sum() / len(stock_price_df)) * 100\nstock_price_df_na = stock_price_df_na.drop(stock_price_df_na[stock_price_df_na == 0].index).sort_values(ascending=False)[:30]\nmissing_data = pd.DataFrame({'Missing Ratio' :stock_price_df_na})\nmissing_data.head(22)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T08:34:21.23363Z","iopub.execute_input":"2022-04-21T08:34:21.233942Z","iopub.status.idle":"2022-04-21T08:34:22.486852Z","shell.execute_reply.started":"2022-04-21T08:34:21.23391Z","shell.execute_reply":"2022-04-21T08:34:22.485239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Standardize the features (other than RowId, Date, and SecuritiesCode) to be used in this project using sklearn's StandardScaler.","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nstdsc = StandardScaler()\ncolumns = ['Open', 'High', 'Low', 'Close', 'Volume', 'AdjustmentFactor', 'ExpectedDividend', 'SupervisionFlag']\nstock_price_df[columns] = stdsc.fit_transform(stock_price_df[columns])\nstock_price_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T08:41:24.218526Z","iopub.execute_input":"2022-04-21T08:41:24.218876Z","iopub.status.idle":"2022-04-21T08:41:25.864315Z","shell.execute_reply.started":"2022-04-21T08:41:24.218845Z","shell.execute_reply":"2022-04-21T08:41:25.863307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Store data for each issue in dictionary form and store it in such a way that it can be recalled for each issue.","metadata":{}},{"cell_type":"code","source":"dataset_dict = {}\nfor sc in stock_price_df['SecuritiesCode'].unique():\n    dataset_dict[str(sc)] = stock_price_df[stock_price_df['SecuritiesCode'] == sc].values[:, 3:].astype(np.float32)\nprint(dataset_dict['1301'].shape)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-21T08:42:03.508802Z","iopub.execute_input":"2022-04-21T08:42:03.509663Z","iopub.status.idle":"2022-04-21T08:42:28.669332Z","shell.execute_reply.started":"2022-04-21T08:42:03.509626Z","shell.execute_reply":"2022-04-21T08:42:28.66823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Use Pytorch dataloader to recall data for each mini-batch.","metadata":{}},{"cell_type":"code","source":"from torch.utils.data.sampler import SubsetRandomSampler\nclass MyDataset(torch.utils.data.Dataset):\n    def __init__(self, X, sequence_num=31, y=None, mode='train'):\n        self.data = X\n        self.teacher = y\n        self.sequence_num = sequence_num\n        self.mode = mode\n    def __len__(self):\n        return len(self.teacher)\n\n    def __getitem__(self, idx):\n        out_data = self.data[idx]\n        if self.mode == 'train':\n            out_label =  self.teacher[idx[-1]]\n            return out_data, out_label\n        else:\n            return out_data\ndef create_dataloader(dataset, dataset_num, sequence_num=31, input_size=8, batch_size=32, shuffle=False):\n    sampler = np.array([list(range(i, i+sequence_num)) for i in range(dataset_num-sequence_num+1)])\n    if shuffle == True:\n        np.random.shuffle(sampler)\n    dataloader = torch.utils.data.DataLoader(dataset, batch_size, sampler=sampler)\n    return dataloader\n#### Check operation ####\nX_check, y_check = dataset_dict['1301'][:, :-1], dataset_dict['1301'][:, -1]\ndataset_check = MyDataset(X_check, y=y_check, sequence_num=31, mode='train')\ndataloader_check = create_dataloader(dataset_check, X_check.shape[0], sequence_num=31, input_size=8, batch_size=32, shuffle=False)\nfor b, tup in enumerate(dataloader_check):\n    print('---------')\n    print(tup[0].shape, tup[1].shape)\n    break","metadata":{"execution":{"iopub.status.busy":"2022-04-21T08:42:47.90474Z","iopub.execute_input":"2022-04-21T08:42:47.905188Z","iopub.status.idle":"2022-04-21T08:42:47.997416Z","shell.execute_reply.started":"2022-04-21T08:42:47.905149Z","shell.execute_reply":"2022-04-21T08:42:47.996067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Trainig\nFor each stock, LSTM training is conducted by repeatedly creating a data set and training the model.","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\nepochs = 10\nbatch_size = 512\n# Check wheter GPU is available\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n# Model Instantiation\nmodel = LSTM(input_size=8, sequence_num=31, lstm_dim=128, num_layers=2, output_size=1)\nmodel.to(device)\nmodel.train()\n# setting optimizer\nlr = 0.0001\nweight_decay = 1.0e-05\noptimizer = torch.optim.Adagrad(model.parameters(), lr=lr, weight_decay=weight_decay)\n# setting criterion\ncriterion = nn.MSELoss()\n# set iteration counter\niteration = 0\n# \nlog_train = [[0], [np.inf]]\nfor epoch in range(epochs):\n    epoch_loss = 0.0\n    for sc in tqdm(stock_price_df['SecuritiesCode'].unique()):\n        X, y = dataset_dict[str(sc)][:, :-1], dataset_dict[str(sc)][:, -1]\n        dataset = MyDataset(X, y=y, sequence_num=31, mode='train')\n        dataloader = create_dataloader(dataset, X.shape[0], sequence_num=31, input_size=8, batch_size=batch_size, shuffle=True)\n        for data, targets in dataloader:\n            data, targets = data.to(device), targets.to(device)\n            \n            optimizer.zero_grad()\n            \n            data = data.to(torch.float32)\n            output = model.forward(data)\n            targets = targets.to(torch.float32)\n            \n            loss = criterion(output.view(1,-1)[0], targets)\n            \n            loss.backward()\n            \n            optimizer.step()\n            \n            epoch_loss += loss.item()\n            \n            iteration += 1\n    epoch_loss /= iteration\n    print('epoch_loss={}'.format(epoch_loss))\n    log_train[0].append(iteration)\n    log_train[1].append(epoch_loss)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T08:48:08.59554Z","iopub.execute_input":"2022-04-21T08:48:08.597258Z","iopub.status.idle":"2022-04-21T08:48:31.664421Z","shell.execute_reply.started":"2022-04-21T08:48:08.597191Z","shell.execute_reply":"2022-04-21T08:48:31.663492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To see the learning status, check the phenomenon of the loss function.  \n　→Can be learned.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(log_train[0][1:], log_train[1][1:])\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T08:48:34.865885Z","iopub.execute_input":"2022-04-21T08:48:34.866323Z","iopub.status.idle":"2022-04-21T08:48:35.126511Z","shell.execute_reply.started":"2022-04-21T08:48:34.866292Z","shell.execute_reply":"2022-04-21T08:48:35.125078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prediction\nThe trained model will be used to make predictions on the submitted data.  \n`DataFrame` → `Ndarray` → `tensor` and transform the data to make predictions.","metadata":{}},{"cell_type":"code","source":"from datetime import datetime\ndef predict(model, X_df, sequence=31):\n    pred_df = X_df[['Date', 'SecuritiesCode']]\n    # Grouping by `groupby` and retrieving one by one\n    code_group = X_df.groupby('SecuritiesCode')\n    X_all = np.array([])\n    for sc, group in code_group:\n        # Standardize target data\n        group_std = stdsc.transform(group[columns])\n        # Calling up past data of the target data\n        X = dataset_dict[str(sc)][-1*(sequence-1):, :-1]\n        # concat\n        X = np.vstack((X, group_std))\n        X_all = np.append(X_all, X)\n    X_all = X_all.reshape(-1, sequence, X.shape[1])\n    y_pred = np.array([])\n    for it in range(X_all.shape[0]//512+1):\n        data = X_all[it*512:(it+1)*512]\n        data = torch.from_numpy(data.astype(np.float32)).clone()\n        data = data.to(torch.float32)\n        data = data.to(device)\n        output = model.forward(data)\n        output = output.view(1, -1)\n        output = output.to('cpu').detach().numpy().copy()\n        y_pred = np.append(y_pred, output[0])\n    pred_df['target'] = y_pred\n    pred_df['Rank'] = pred_df[\"target\"].rank(ascending=False,method=\"first\") -1\n    pred_df['Rank'] = pred_df['Rank'].astype(int)\n    pred_df = pred_df.drop('target', axis=1)\n    return pred_df\ntest_X_df = stock_price_df[stock_price_df['Date'] == datetime(2021, 12, 3)].drop('Target', axis=1)\ny_pred = predict(model, test_X_df)\nprint(y_pred.shape)\nprint(y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T08:49:07.721413Z","iopub.execute_input":"2022-04-21T08:49:07.722199Z","iopub.status.idle":"2022-04-21T08:49:15.450043Z","shell.execute_reply.started":"2022-04-21T08:49:07.722144Z","shell.execute_reply":"2022-04-21T08:49:15.4491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission\nPerform data preparation for submission from `jpx_tokyo_market_prediction`.","metadata":{}},{"cell_type":"code","source":"import jpx_tokyo_market_prediction\nenv = jpx_tokyo_market_prediction.make_env()\niter_test = env.iter_test()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T08:49:20.961552Z","iopub.execute_input":"2022-04-21T08:49:20.962292Z","iopub.status.idle":"2022-04-21T08:49:20.994328Z","shell.execute_reply.started":"2022-04-21T08:49:20.96225Z","shell.execute_reply":"2022-04-21T08:49:20.993267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count = 0\nfor (prices, options, financials, trades, secondary_prices, sample_prediction) in iter_test:\n    prices = prices.fillna(0)\n    prices['SupervisionFlag'] = prices['SupervisionFlag'].map({True: 1, False: 0})\n    prices['Date'] = pd.to_datetime(prices['Date'])\n    pred_df = predict(model, prices)\n    print(pred_df)\n    env.predict(pred_df)\n    count += 1","metadata":{"execution":{"iopub.status.busy":"2022-04-21T08:49:23.508327Z","iopub.execute_input":"2022-04-21T08:49:23.509553Z","iopub.status.idle":"2022-04-21T08:49:38.683546Z","shell.execute_reply.started":"2022-04-21T08:49:23.509489Z","shell.execute_reply":"2022-04-21T08:49:38.682212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_df","metadata":{"execution":{"iopub.status.busy":"2022-04-21T08:49:38.685941Z","iopub.execute_input":"2022-04-21T08:49:38.686259Z","iopub.status.idle":"2022-04-21T08:49:38.701571Z","shell.execute_reply.started":"2022-04-21T08:49:38.686226Z","shell.execute_reply":"2022-04-21T08:49:38.700597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}