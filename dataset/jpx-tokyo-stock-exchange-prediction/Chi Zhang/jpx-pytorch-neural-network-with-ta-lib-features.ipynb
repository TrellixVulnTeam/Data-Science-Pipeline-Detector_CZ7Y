{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup","metadata":{}},{"cell_type":"code","source":"# install talib without internet\n!pip install ../input/talib0419/talib_binary-0.4.19-cp37-cp37m-manylinux1_x86_64.whl","metadata":{"execution":{"iopub.status.busy":"2022-05-19T09:25:26.42053Z","iopub.execute_input":"2022-05-19T09:25:26.420873Z","iopub.status.idle":"2022-05-19T09:25:56.551319Z","shell.execute_reply.started":"2022-05-19T09:25:26.420789Z","shell.execute_reply":"2022-05-19T09:25:56.550215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport talib\nfrom pprint import pprint\nimport gc\nimport os\nfrom tqdm.notebook import tqdm\nimport random\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport jpx_tokyo_market_prediction","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-19T09:25:56.55457Z","iopub.execute_input":"2022-05-19T09:25:56.554956Z","iopub.status.idle":"2022-05-19T09:25:58.201027Z","shell.execute_reply.started":"2022-05-19T09:25:56.55491Z","shell.execute_reply":"2022-05-19T09:25:58.200058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set random seed\nseed = 30\nos.environ['PYTHONHASHSEED'] = str(seed)\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T09:25:58.203643Z","iopub.execute_input":"2022-05-19T09:25:58.204122Z","iopub.status.idle":"2022-05-19T09:25:58.214999Z","shell.execute_reply.started":"2022-05-19T09:25:58.204073Z","shell.execute_reply":"2022-05-19T09:25:58.214152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Data","metadata":{}},{"cell_type":"code","source":"df_prices = pd.read_csv('../input/jpx-tokyo-stock-exchange-prediction/train_files/stock_prices.csv')\ndf_prices.tail()","metadata":{"execution":{"iopub.status.busy":"2022-05-19T09:25:58.217618Z","iopub.execute_input":"2022-05-19T09:25:58.217904Z","iopub.status.idle":"2022-05-19T09:26:03.515479Z","shell.execute_reply.started":"2022-05-19T09:25:58.217867Z","shell.execute_reply":"2022-05-19T09:26:03.514727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop missing values\ndf_prices = df_prices[['RowId', 'Date', 'SecuritiesCode', 'Open', 'High', 'Low', 'Close', 'Volume', 'Target']]\ndf_prices = df_prices.dropna(axis=0).reset_index(drop=True)\ndf_prices.tail()","metadata":{"execution":{"iopub.status.busy":"2022-05-19T09:26:03.516732Z","iopub.execute_input":"2022-05-19T09:26:03.519588Z","iopub.status.idle":"2022-05-19T09:26:04.319615Z","shell.execute_reply.started":"2022-05-19T09:26:03.519556Z","shell.execute_reply":"2022-05-19T09:26:04.318855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Get Talib Features","metadata":{}},{"cell_type":"markdown","source":"All the TA functions sorted by group:","metadata":{}},{"cell_type":"code","source":"pprint(talib.get_function_groups())","metadata":{"execution":{"iopub.status.busy":"2022-05-19T09:26:04.32072Z","iopub.execute_input":"2022-05-19T09:26:04.32165Z","iopub.status.idle":"2022-05-19T09:26:04.353416Z","shell.execute_reply.started":"2022-05-19T09:26:04.321608Z","shell.execute_reply":"2022-05-19T09:26:04.352712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_talib_features(df):\n    \"\"\"\n    Get technical features from TA-Lib\n    \"\"\"\n    op = df['Open']\n    hi = df['High']\n    lo = df['Low']\n    cl = df['Close']\n    vo = df['Volume']\n    \n    # Overlap Studies\n    df['BBANDS_upper'], df['BBANDS_middle'], df['BBANDS_lower'] = talib.BBANDS(cl, timeperiod=5, nbdevup=2, nbdevdn=2, matype=0)\n    df['DEMA'] = talib.DEMA(cl, timeperiod=30)\n    df['EMA'] = talib.EMA(cl, timeperiod=30)\n    df['HT_TRENDLINE'] = talib.HT_TRENDLINE(cl)\n    df['KAMA'] = talib.KAMA(cl, timeperiod=30)\n    df['MA'] = talib.MA(cl, timeperiod=30, matype=0)\n    df['MIDPOINT'] = talib.MIDPOINT(cl, timeperiod=14)\n    df['SAR'] = talib.SAR(hi, lo, acceleration=0, maximum=0)\n    df['SAREXT'] = talib.SAREXT(hi, lo, startvalue=0, offsetonreverse=0, accelerationinitlong=0, accelerationlong=0, accelerationmaxlong=0, accelerationinitshort=0, accelerationshort=0, accelerationmaxshort=0)\n    df['SMA'] = talib.SMA(cl, timeperiod=30)\n    df['T3'] = talib.T3(df['Close'], timeperiod=5, vfactor=0)\n    df['TEMA'] = talib.TEMA(df['Close'], timeperiod=30)\n    df['TRIMA'] = talib.TRIMA(df['Close'], timeperiod=30)\n    df['WMA'] = talib.WMA(df['Close'], timeperiod=30)\n    \n    # Momentum Indicators\n    df['ADX'] = talib.ADX(hi, lo, cl, timeperiod=14)\n    df['ADXR'] = talib.ADXR(hi, lo, cl, timeperiod=14)\n    df['APO'] = talib.APO(cl, fastperiod=12, slowperiod=26, matype=0)\n    df['AROON_down'], df['AROON_up'] = talib.AROON(hi, lo, timeperiod=14)\n    df['AROONOSC'] = talib.AROONOSC(hi, lo, timeperiod=14)\n    df['BOP'] = talib.BOP(op, hi, lo, cl)\n    df['CCI'] = talib.CCI(hi, lo, cl, timeperiod=14)\n    df['DX'] = talib.DX(hi, lo, cl, timeperiod=14)\n    df['MACD_macd'], df['MACD_macdsignal'], df['MACD_macdhist'] = talib.MACD(cl, fastperiod=12, slowperiod=26, signalperiod=9)\n    df['MFI'] = talib.MFI(hi, lo, cl, vo, timeperiod=14)\n    df['MINUS_DI'] = talib.MINUS_DI(hi, lo, cl, timeperiod=14)\n    df['MINUS_DM'] = talib.MINUS_DM(hi, lo, timeperiod=14)\n    df['MOM'] = talib.MOM(cl, timeperiod=10)\n    df['PLUS_DI'] = talib.PLUS_DI(hi, lo, cl, timeperiod=14)\n    df['PLUS_DM'] = talib.PLUS_DM(hi, lo, timeperiod=14)\n    df['RSI'] = talib.RSI(cl, timeperiod=14)\n    df['STOCH_slowk'], df['STOCH_slowd'] = talib.STOCH(hi, lo, cl, fastk_period=5, slowk_period=3, slowk_matype=0, slowd_period=3, slowd_matype=0)\n    df['STOCHF_fastk'], df['STOCHF_fastd'] = talib.STOCHF(hi, lo, cl, fastk_period=5, fastd_period=3, fastd_matype=0)\n    df['STOCHRSI_fastk'], df['STOCHRSI_fastd'] = talib.STOCHRSI(cl, timeperiod=14, fastk_period=5, fastd_period=3, fastd_matype=0)\n    df['TRIX'] = talib.TRIX(cl, timeperiod=30)\n    df['ULTOSC'] = talib.ULTOSC(hi, lo, cl, timeperiod1=7, timeperiod2=14, timeperiod3=28)\n    df['WILLR'] = talib.WILLR(hi, lo, cl, timeperiod=14)\n    \n    # Volume Indicators\n    df['AD'] = talib.AD(hi, lo, cl, vo)\n    df['ADOSC'] = talib.ADOSC(hi, lo, cl, vo, fastperiod=3, slowperiod=10)\n    df['OBV'] = talib.OBV(cl, vo)\n    \n    # Volatility Indicators\n    df['ATR'] = talib.ATR(hi, lo, cl, timeperiod=14)\n    df['NATR'] = talib.NATR(hi, lo, cl, timeperiod=14)\n    df['TRANGE'] = talib.TRANGE(hi, lo, cl)\n    \n    # Cycle Indicators\n    df['HT_DCPERIOD'] = talib.HT_DCPERIOD(cl)\n    df['HT_DCPHASE'] = talib.HT_DCPHASE(cl)\n    df['HT_PHASOR_inphase'], df['HT_PHASOR_quadrature'] = talib.HT_PHASOR(cl)\n    df['HT_SINE_sine'], df['HT_SINE_leadsine'] = talib.HT_SINE(cl)\n    df['HT_TRENDMODE'] = talib.HT_TRENDMODE(cl)\n    \n    # Statistic Functions\n    df['BETA'] = talib.BETA(hi, lo, timeperiod=5)\n    df['CORREL'] = talib.CORREL(hi, lo, timeperiod=30)\n    df['LINEARREG'] = talib.LINEARREG(cl, timeperiod=14) - cl\n    df['LINEARREG_ANGLE'] = talib.LINEARREG_ANGLE(cl, timeperiod=14)\n    df['LINEARREG_INTERCEPT'] = talib.LINEARREG_INTERCEPT(cl, timeperiod=14) - cl\n    df['LINEARREG_SLOPE'] = talib.LINEARREG_SLOPE(cl, timeperiod=14)\n    df['STDDEV'] = talib.STDDEV(cl, timeperiod=5, nbdev=1)   \n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-05-19T09:26:04.356727Z","iopub.execute_input":"2022-05-19T09:26:04.356941Z","iopub.status.idle":"2022-05-19T09:26:04.385073Z","shell.execute_reply.started":"2022-05-19T09:26:04.356914Z","shell.execute_reply":"2022-05-19T09:26:04.38331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nresults = df_prices.groupby('SecuritiesCode').apply(get_talib_features)\nresults","metadata":{"execution":{"iopub.status.busy":"2022-05-19T09:26:04.387656Z","iopub.execute_input":"2022-05-19T09:26:04.38814Z","iopub.status.idle":"2022-05-19T09:27:14.653077Z","shell.execute_reply.started":"2022-05-19T09:26:04.388079Z","shell.execute_reply":"2022-05-19T09:27:14.652348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = results.dropna(axis=0).reset_index(drop=True)\nprint(results.shape)\nresults.tail()","metadata":{"execution":{"iopub.status.busy":"2022-05-19T09:27:14.654734Z","iopub.execute_input":"2022-05-19T09:27:14.655259Z","iopub.status.idle":"2022-05-19T09:27:16.431426Z","shell.execute_reply.started":"2022-05-19T09:27:14.655217Z","shell.execute_reply":"2022-05-19T09:27:16.430629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pytorch NN Model","metadata":{}},{"cell_type":"code","source":"# Define nn model\nclass jpx_dnn(nn.Module):\n    def __init__(self, feat_dim):\n        super().__init__()\n        self.mlp_network = nn.Sequential(\n            nn.BatchNorm1d(feat_dim),\n            nn.Linear(feat_dim, 512),\n            nn.SiLU(),\n            nn.BatchNorm1d(512),\n            nn.Linear(512, 512),\n            nn.SiLU(),\n            nn.BatchNorm1d(512),\n            nn.Dropout(p=0.5),\n            nn.Linear(512, 256),\n            nn.SiLU(),\n            nn.BatchNorm1d(256),\n            nn.Dropout(p=0.5),\n            nn.Linear(256, 256),\n            nn.SiLU(),\n            nn.BatchNorm1d(256),\n            nn.Dropout(p=0.5),\n            nn.Linear(256, 128),\n            nn.SiLU(),\n            nn.BatchNorm1d(128),\n            nn.Dropout(p=0.5),\n            nn.Linear(128, 64),\n            nn.BatchNorm1d(64),\n            nn.Linear(64, 1)\n        )\n\n    def forward(self, x):\n        x = self.mlp_network(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-05-19T09:35:01.246654Z","iopub.execute_input":"2022-05-19T09:35:01.247485Z","iopub.status.idle":"2022-05-19T09:35:01.255873Z","shell.execute_reply.started":"2022-05-19T09:35:01.24744Z","shell.execute_reply":"2022-05-19T09:35:01.255159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Dataset & Dataloader","metadata":{}},{"cell_type":"code","source":"class JPXDataset(Dataset):\n    def __init__(self, X, y):\n        self.X = X\n        self.y = y\n    \n    def __len__(self):\n        return len(self.y)\n\n    def __getitem__(self, idx):\n        features = self.X[idx]\n        labels = self.y[idx]\n        return features, labels","metadata":{"execution":{"iopub.status.busy":"2022-05-19T09:35:02.699257Z","iopub.execute_input":"2022-05-19T09:35:02.700102Z","iopub.status.idle":"2022-05-19T09:35:02.706128Z","shell.execute_reply.started":"2022-05-19T09:35:02.70005Z","shell.execute_reply":"2022-05-19T09:35:02.705187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split train and valid data\ntrain_df = results[results.Date < '2021-01-01'].copy().reset_index(drop=True)\nvalid_df = results[results.Date >= '2021-01-01'].copy().reset_index(drop=True)\nX_train = train_df.drop(['RowId', 'Date', 'SecuritiesCode', 'Target'], axis=1).values\ny_train = train_df['Target'].values\nX_valid = valid_df.drop(['RowId', 'Date', 'SecuritiesCode', 'Target'], axis=1).values\ny_valid = valid_df['Target'].values","metadata":{"execution":{"iopub.status.busy":"2022-05-19T09:35:03.344949Z","iopub.execute_input":"2022-05-19T09:35:03.346952Z","iopub.status.idle":"2022-05-19T09:35:06.159445Z","shell.execute_reply.started":"2022-05-19T09:35:03.346914Z","shell.execute_reply":"2022-05-19T09:35:06.15867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create dataset\ntrain_data = JPXDataset(X_train, y_train)\nvalid_data = JPXDataset(X_valid, y_valid)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T09:35:06.161304Z","iopub.execute_input":"2022-05-19T09:35:06.161583Z","iopub.status.idle":"2022-05-19T09:35:06.166044Z","shell.execute_reply.started":"2022-05-19T09:35:06.161544Z","shell.execute_reply":"2022-05-19T09:35:06.165378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create dataloader\ntrain_dataloader = DataLoader(train_data, batch_size=1024, shuffle=False)\nvalid_dataloader = DataLoader(valid_data, batch_size=1024, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T09:35:06.167404Z","iopub.execute_input":"2022-05-19T09:35:06.167887Z","iopub.status.idle":"2022-05-19T09:35:06.198976Z","shell.execute_reply.started":"2022-05-19T09:35:06.167849Z","shell.execute_reply":"2022-05-19T09:35:06.198254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Model","metadata":{}},{"cell_type":"code","source":"# Initialize model\nmodel = jpx_dnn(feat_dim=69)\n\n# Get cpu or gpu device for training\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using {device} device\")\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T09:35:06.200653Z","iopub.execute_input":"2022-05-19T09:35:06.200896Z","iopub.status.idle":"2022-05-19T09:35:06.224822Z","shell.execute_reply.started":"2022-05-19T09:35:06.200863Z","shell.execute_reply":"2022-05-19T09:35:06.224137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set training config\nepochs = 5\nlearning_rate = 0.001\nweight_decay = 1.0e-05\nloss_fn = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T09:35:07.041074Z","iopub.execute_input":"2022-05-19T09:35:07.041335Z","iopub.status.idle":"2022-05-19T09:35:07.048655Z","shell.execute_reply.started":"2022-05-19T09:35:07.041305Z","shell.execute_reply":"2022-05-19T09:35:07.04773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define train and test_loop - https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html\ndef train_loop(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader.dataset)\n    model.train()\n    for batch, (X, y) in tqdm(enumerate(dataloader)):\n        X, y = X.to(device), y.to(device)\n        X, y = X.to(torch.float32), y.to(torch.float32)\n        \n        # Compute prediction and loss\n        pred = model(X)\n        loss = loss_fn(pred.view(-1), y)\n\n        # Backpropagation\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if batch % 500 == 0:\n            loss, current = loss.item(), batch * len(X)\n            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n\n\ndef test_loop(dataloader, model, loss_fn):\n    size = len(dataloader.dataset)\n    num_batches = len(dataloader)\n    model.eval()\n    test_loss = 0\n\n    with torch.no_grad():\n        for X, y in tqdm(dataloader):\n            X, y = X.to(device), y.to(device)\n            X, y = X.to(torch.float32), y.to(torch.float32)\n            pred = model(X)\n            test_loss += loss_fn(pred.view(-1), y).item()\n\n    test_loss /= num_batches\n    print(f\"Test avg loss: {test_loss:>8f} \\n\")","metadata":{"execution":{"iopub.status.busy":"2022-05-19T09:35:13.754737Z","iopub.execute_input":"2022-05-19T09:35:13.755292Z","iopub.status.idle":"2022-05-19T09:35:13.766157Z","shell.execute_reply.started":"2022-05-19T09:35:13.755251Z","shell.execute_reply":"2022-05-19T09:35:13.765465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for t in range(epochs):\n    print(f\"Epoch {t+1}\\n-------------------------------\")\n    train_loop(train_dataloader, model, loss_fn, optimizer)\n    test_loop(valid_dataloader, model, loss_fn)\nprint(\"Done!\")","metadata":{"execution":{"iopub.status.busy":"2022-05-19T09:35:15.931166Z","iopub.execute_input":"2022-05-19T09:35:15.931416Z","iopub.status.idle":"2022-05-19T09:36:56.613192Z","shell.execute_reply.started":"2022-05-19T09:35:15.931386Z","shell.execute_reply":"2022-05-19T09:36:56.612414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Evaluation","metadata":{}},{"cell_type":"markdown","source":"## Define evaluation metrics","metadata":{}},{"cell_type":"code","source":"## JPX Competition Metric - https://www.kaggle.com/code/smeitoma/jpx-competition-metric-definition\ndef calc_spread_return_sharpe(df: pd.DataFrame, portfolio_size: int = 200, toprank_weight_ratio: float = 2) -> float:\n    \"\"\"\n    Args:\n        df (pd.DataFrame): predicted results\n        portfolio_size (int): # of equities to buy/sell\n        toprank_weight_ratio (float): the relative weight of the most highly ranked stock compared to the least.\n    Returns:\n        (float): sharpe ratio\n    \"\"\"\n    def _calc_spread_return_per_day(df, portfolio_size, toprank_weight_ratio):\n        \"\"\"\n        Args:\n            df (pd.DataFrame): predicted results\n            portfolio_size (int): # of equities to buy/sell\n            toprank_weight_ratio (float): the relative weight of the most highly ranked stock compared to the least.\n        Returns:\n            (float): spread return\n        \"\"\"\n        assert df['Rank'].min() == 0\n        assert df['Rank'].max() == len(df['Rank']) - 1\n        weights = np.linspace(start=toprank_weight_ratio, stop=1, num=portfolio_size)\n        purchase = (df.sort_values(by='Rank')['Target'][:portfolio_size] * weights).sum() / weights.mean()\n        short = (df.sort_values(by='Rank', ascending=False)['Target'][:portfolio_size] * weights).sum() / weights.mean()\n        return purchase - short\n\n    buf = df.groupby('Date').apply(_calc_spread_return_per_day, portfolio_size, toprank_weight_ratio)\n    sharpe_ratio = buf.mean() / buf.std()\n    return sharpe_ratio\n\n## MSE\ndef calc_mse(y_test, y_pred):\n    return np.mean((y_pred - y_test)**2)\n\n## MAE\ndef calc_mae(y_test, y_pred):\n    return np.mean(np.abs(y_pred - y_test))\n\n## IC & RankIC\ndef _correlation(df: pd.DataFrame, truth_col: str, pred_col: str, method: str, groupby: str = None) -> float:\n    if groupby:\n        corr_df = df.groupby(groupby)[[truth_col, pred_col]].corr(method=method)\n        return corr_df.loc[(slice(None), truth_col), pred_col].mean()\n    return df[[truth_col, pred_col]].corr(method=method).iloc[0, 1]\n\ndef spearman_corr(df: pd.DataFrame, truth_col: str, pred_col: str, groupby: str = None) -> float:\n    \"\"\"Spearman (Rank) correlation for regression problem\n\n    Args:\n        df (pd.DataFrame): contains truth_col, pred_col and (optinally) groupby columns\n        truth_col (str): truth column\n        pred_col (str): prediction column\n        groupby (str, optional): groupby column. Defaults to None.\n\n    Returns:\n        float: correlation\n    \"\"\"\n    return _correlation(df, truth_col, pred_col, 'spearman', groupby)\n\ndef pearson_corr(df: pd.DataFrame, truth_col: str, pred_col: str, groupby: str = None) -> float:\n    \"\"\"Pearson correlation for regression problem\n\n    Args:\n        df (pd.DataFrame): contains truth_col, pred_col and (optinally) groupby columns\n        truth_col (str): truth column\n        pred_col (str): prediction column\n        groupby (str, optional): groupby column. Defaults to None.\n\n    Returns:\n        float: correlation\n    \"\"\"\n    return _correlation(df, truth_col, pred_col, 'pearson', groupby)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T09:28:56.922211Z","iopub.execute_input":"2022-05-19T09:28:56.924056Z","iopub.status.idle":"2022-05-19T09:28:56.950372Z","shell.execute_reply.started":"2022-05-19T09:28:56.924016Z","shell.execute_reply":"2022-05-19T09:28:56.949326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Get model predictions","metadata":{}},{"cell_type":"code","source":"pred_df = valid_df[['Date', 'SecuritiesCode', 'Target']].copy()\npreds = []\nfor X, _ in tqdm(valid_dataloader):\n    X = X.to(device).to(torch.float32)\n    pred = model(X)\n    preds.append(pred)\npreds = torch.cat(preds).cpu().detach().numpy()","metadata":{"execution":{"iopub.status.busy":"2022-05-19T09:37:03.469849Z","iopub.execute_input":"2022-05-19T09:37:03.470452Z","iopub.status.idle":"2022-05-19T09:37:06.899777Z","shell.execute_reply.started":"2022-05-19T09:37:03.470413Z","shell.execute_reply":"2022-05-19T09:37:06.899056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_df['Target_Pred'] = preds\npred_df['Rank'] = pred_df.groupby('Date')['Target_Pred'].rank(ascending=False, method='first').astype(int) - 1\npred_df","metadata":{"execution":{"iopub.status.busy":"2022-05-19T09:37:06.909429Z","iopub.execute_input":"2022-05-19T09:37:06.909801Z","iopub.status.idle":"2022-05-19T09:37:07.060004Z","shell.execute_reply.started":"2022-05-19T09:37:06.909769Z","shell.execute_reply":"2022-05-19T09:37:07.059306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sharpe_ratio = calc_spread_return_sharpe(pred_df, portfolio_size=1)\nprint('Sharpe ratio: ', sharpe_ratio)\nmse = calc_mse(pred_df['Target'], pred_df['Target_Pred'])\nprint('MSE: ', mse)\nmae = calc_mae(pred_df['Target'], pred_df['Target_Pred'])\nprint('MAE: ', mae)\nic = pearson_corr(pred_df, 'Target', 'Target_Pred', 'Date')\nprint('IC(Pearson correlation):', ic)\nrankic = spearman_corr(pred_df, 'Target', 'Target_Pred', 'Date')\nprint('RankIC(Spearman correlation)', rankic)","metadata":{"execution":{"iopub.status.busy":"2022-05-19T09:37:21.473663Z","iopub.execute_input":"2022-05-19T09:37:21.47392Z","iopub.status.idle":"2022-05-19T09:37:22.320081Z","shell.execute_reply.started":"2022-05-19T09:37:21.473891Z","shell.execute_reply":"2022-05-19T09:37:22.318671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save Model","metadata":{}},{"cell_type":"code","source":"torch.save(model.state_dict(), 'pytorch_DNN_weights.pth')","metadata":{"execution":{"iopub.status.busy":"2022-05-19T09:29:01.857585Z","iopub.execute_input":"2022-05-19T09:29:01.859719Z","iopub.status.idle":"2022-05-19T09:29:01.881612Z","shell.execute_reply.started":"2022-05-19T09:29:01.85968Z","shell.execute_reply":"2022-05-19T09:29:01.880948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"df_history = df_prices[df_prices['Date']>= '2021-10-01'].copy().reset_index(drop=True)\ndf_history","metadata":{"execution":{"iopub.status.busy":"2022-05-19T09:29:01.885313Z","iopub.execute_input":"2022-05-19T09:29:01.887617Z","iopub.status.idle":"2022-05-19T09:29:02.239977Z","shell.execute_reply.started":"2022-05-19T09:29:01.88758Z","shell.execute_reply":"2022-05-19T09:29:02.239287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predictions and submission\nenv = jpx_tokyo_market_prediction.make_env()   # initialize the environment\niter_test = env.iter_test()    # an iterator which loops over the test files\nfor (prices, options, financials, trades, secondary_prices, sample_prediction) in iter_test:\n    # Combine history data with incoming new data\n    display(prices)\n    df_current = prices[['RowId', 'Date', 'SecuritiesCode', 'Open', 'High', 'Low', 'Close', 'Volume']]\n    df_history = pd.concat([df_history, df_current], ignore_index=True)\n    \n    # Get processed test data\n    training_cutoff = prices['Date'].values[0]\n    all_data = df_history.groupby('SecuritiesCode').apply(get_talib_features)\n    test_data = all_data[all_data['Date'] == training_cutoff].copy().reset_index(drop=True).fillna(0)\n    display(test_data)\n    X_test = torch.from_numpy(test_data.drop(['RowId', 'Date', 'SecuritiesCode', 'Target'], axis=1).values).to(device).to(torch.float32)\n\n    # Make predictions\n    sample_prediction['target_pred'] = model(X_test).cpu().detach().numpy()\n    sample_prediction = sample_prediction.sort_values(by=\"target_pred\", ascending=False)\n    sample_prediction['Rank'] = np.arange(2000)\n    sample_prediction = sample_prediction.sort_values(by=\"SecuritiesCode\", ascending=True)\n    display(sample_prediction)\n    sample_prediction.drop(['target_pred'], axis=1, inplace=True)\n    env.predict(sample_prediction)  # register your predictions","metadata":{"execution":{"iopub.status.busy":"2022-05-19T09:29:02.241462Z","iopub.execute_input":"2022-05-19T09:29:02.242005Z","iopub.status.idle":"2022-05-19T09:30:42.557714Z","shell.execute_reply.started":"2022-05-19T09:29:02.241964Z","shell.execute_reply":"2022-05-19T09:30:42.557016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reference\n* Web Resources:\n    * [**TA-Lib : Technical Analysis Library**](https://www.ta-lib.org/)\n    * [**TA-Lib Documentation**](https://mrjbq7.github.io/ta-lib/)\n    * [**TA-Lib Document in Chinese**](https://github.com/HuaRongSAO/talib-document)\n* Kaggle notebooks:\n    * [***How to install Ta-Lib***](https://www.kaggle.com/code/tera555/how-to-install-ta-lib) by @tera555\n    * [***LGBM baseline (with technical indicator)***](https://www.kaggle.com/code/tera555/lgbm-baseline-with-technical-indicator) by @tera555\n    * [***Feature Engineering + training 📊🤓 with TA***](https://www.kaggle.com/code/metathesis/feature-engineering-training-with-ta) by @metathesis\n    * [***JPX Tokyo: simple LSTM Network***](https://www.kaggle.com/code/aboriginal3153/jpx-tokyo-simple-lstm-network) by @aboriginal3153","metadata":{}}]}