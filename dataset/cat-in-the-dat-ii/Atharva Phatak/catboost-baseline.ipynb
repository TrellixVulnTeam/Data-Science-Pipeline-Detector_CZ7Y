{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom bokeh.io import show , output_notebook\nfrom bokeh.plotting import figure\nfrom bokeh.models import ColumnDataSource ,HoverTool\nfrom bokeh.layouts import row , column , widgetbox\nfrom bokeh.models.widgets import Tabs , Panel\nfrom bokeh.application.handlers import FunctionHandler\nfrom bokeh.application import Application\nfrom ipywidgets import interact\n\nimport category_encoders as ce\nfrom sklearn.model_selection import StratifiedKFold\nfrom catboost import CatBoostClassifier\nfrom sklearn import metrics\n\n\noutput_notebook()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.options.display.max_columns = None\npd.options.display.max_rows = None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nos.listdir('../input/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/cat-in-the-dat-ii/train.csv\")\ntest_df = pd.read_csv(\"../input/cat-in-the-dat-ii/test.csv\")\nsamp_submission = pd.read_csv(\"../input/cat-in-the-dat-ii/sample_submission.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.iloc[:,:].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = ['bin_0' , 'bin_1','bin_2','bin_3' ,'bin_4','ord_0','ord_1','ord_2','ord_3','ord_4',\n        'nom_0','nom_1','nom_2','nom_3','nom_4','target' , 'day','month']\ntrain_dfS = train_df.loc[:,cols].copy()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Uniques(col):\n    \n    x = [str(i) for i in train_dfS.loc[:,col].unique() if not pd.isnull(i)]\n    return x\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import bokeh\nfrom bokeh.models import Select\ndef modify_doc(doc):\n    \n    \n    def create_figure():\n        \n        current_feature_name = feature_name.value\n        targets = sorted(Uniques(current_feature_name))\n        source = ColumnDataSource(data = {\n            \n            'x' : targets,\n            'y' : train_dfS.loc[:,current_feature_name].value_counts().to_list(),\n            'color' : bokeh.palettes.plasma(len(targets))\n        })\n        #print(source.data)\n        plot = figure(x_range = targets,title = \"Categorical Embedding -II\" , plot_height = 500 , plot_width = 500)\n        plot.vbar(x = 'x' , top = 'y' , color = 'color' , width = 0.5 , source = source,legend_field = 'x')\n        plot.xaxis.axis_label = current_feature_name\n        plot.yaxis.axis_label = \"Counts\"\n        plot.legend.orientation = 'horizontal'\n        plot.legend.location = 'top_right'\n        plot.left[0].formatter.use_scientific = False\n        plot.add_tools(HoverTool(tooltips = [('Counts' , '@y')]))\n        #show(plot)\n        return plot\n        \n    def update_plot(attr , old , new):\n        \n        layout.children[1] = create_figure()\n        \n    \n    #Controls\n    feature_name = Select(title = \"Categorical Columns\" , options = cols , value = cols[0])\n    feature_name.on_change('value' , update_plot)\n    p = create_figure()\n    layout = row(widgetbox(feature_name) , p)\n    doc.add_root(layout)\n\nhandler = FunctionHandler(modify_doc)\napp = Application(handler)\n        \n        \n        \n        \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"doc = app.create_document()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show(app)\n#I dont think kaggle kernels support bokeh interactive plots , but do download this notebook and see the cool interactive plot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's fill in the missing data using mode\n\nfor col in train_df.columns:\n    \n    train_df[col].fillna(train_df[col].mode()[0] , inplace = True)\n    \n\nfor col in test_df.columns:\n    \n    test_df[col].fillna(test_df[col].mode()[0] , inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing catgeory encoders library\n\ndef EncodeMapings(df):\n    \n    #Encoding for training set\n    df_encoded = df.copy()\n    \n    df_encoded['bin_3'] = df_encoded['bin_3'].apply(lambda x : 0 if x == 'F' else 1)\n    df_encoded['bin_4'] = df_encoded['bin_4'].apply(lambda x : 0 if x == 'N' else 1)\n    \n    df_encoded.ord_1.replace(to_replace = ['Novice', 'Contributor','Expert', 'Master', 'Grandmaster'],\n                         value = [0, 1, 2, 3, 4], inplace = True)\n\n    df_encoded.ord_2.replace(to_replace = ['Freezing', 'Cold', 'Warm', 'Hot','Boiling Hot', 'Lava Hot'],\n                         value = [0, 1, 2, 3, 4, 5], inplace = True)\n\n    df_encoded.ord_3.replace(to_replace = ['a', 'b', 'c', 'd', 'e', 'f', 'g','h', 'i', 'j', 'k', 'l', 'm', 'n', 'o'],\n                         value = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], inplace = True)\n\n    df_encoded.ord_4.replace(to_replace = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I','J', 'K', 'L', 'M', 'N', 'O', \n                                     'P', 'Q', 'R','S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z'],\n                         value = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, \n                                  22, 23, 24, 25], inplace = True)\n    \n    return df_encoded\n    \n   \n    \n\n\n    \n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dfP = EncodeMapings(train_df)\ntest_dfP = EncodeMapings(test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nom_col = ['nom_0','nom_1' ,'nom_2','nom_3','nom_4']\n    \n        \nfor col in nom_col:\n            woe_enc = ce.WOEEncoder()\n        \n        \n            train_dfP[f'{col}_woe'] = woe_enc.fit_transform(train_dfP[col] , train_dfP.target)\n            test_dfP[f'{col}_woe'] = woe_enc.transform(test_dfP[col])\n    \n #Using Leave one outencoder for high cardinality data\n    \n    \nhigh_card = ['nom_5' , 'nom_6' , 'nom_7','nom_8','nom_9','ord_5'] \n        \n        \nfor col in high_card:\n            loo_enc = ce.LeaveOneOutEncoder()\n        \n        \n            train_dfP[f'{col}_loo'] = loo_enc.fit_transform(train_dfP[col] , train_dfP.target)\n            test_dfP[f'{col}_loo'] = loo_enc.transform(test_dfP[col])\n    \ntrain_dfP.drop(['nom_0','nom_1' ,'nom_2','nom_3','nom_4','nom_5' , 'nom_6' , 'nom_7','nom_8','nom_9','ord_5'],\n                   inplace = True , axis = 1)\ntest_dfP.drop(['nom_0','nom_1' ,'nom_2','nom_3','nom_4','nom_5' , 'nom_6' , 'nom_7','nom_8','nom_9','ord_5'],\n                   inplace = True , axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Training Set Shape: {}\".format(train_dfP.shape))\nprint(\"Test set Shape: {}\".format(test_dfP.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_dfP.to_csv(\"train_dfP\" , index = False)\ntest_dfP.to_csv(\"test_dfP\", index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\ndel train_df , train_dfS ,test_df\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train_dfP.target.values\nX = train_dfP.drop(['target','id'] , axis = 1).values\ntest_dfP.drop(['id'] , inplace = True , axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nskf = StratifiedKFold(n_splits = 5 ,random_state = 42 ,shuffle = True)\n\nmodel = CatBoostClassifier(iterations=600,\n                              learning_rate=0.01,\n                              depth=5,\n                              bootstrap_type='Bernoulli',\n                              loss_function='Logloss',\n                              subsample=0.9,\n                              eval_metric='AUC',\n                              metric_period=50,\n                              allow_writing_files=False)\n\n\noof_y = []\noof_pred = []\n\nscores = []\n\nfor train_idx, test_idx in skf.split(X,y):\n    \n    X_train , X_val = X[train_idx] , X[test_idx]\n    y_train , y_val = y[train_idx] , y[test_idx]\n    \n    model.fit(X_train , y_train , eval_set = (X_val , y_val))\n    \n    pred = model.predict_proba(X_val)[:,1]\n    \n    oof_y.append(y_val)\n    oof_pred.append(pred)\n    score = metrics.roc_auc_score(y_val , pred)\n    print(\"Fold Score :{}\".format(score))\n    scores.append(score)\n    \n\n    \n    \n    \n    \n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Mean Auc_roc Score : {}\".format(sum(scores) / skf.n_splits))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot model feature importances\n\nfeature_names = [col for col in train_dfP.columns if col not in ['target' , 'id']]\nsource = ColumnDataSource(data = {'x' : feature_names,\n                                  'y' : model.feature_importances_,\n                                  'color' : bokeh.palettes.turbo(len(feature_names))\n                                 })\n\nplot = figure(x_range = feature_names , title= \"Feature Importance\" , plot_height = 1500 , plot_width = 1500)\nplot.vbar(x = 'x' , top = 'y' ,color  =  'color' , source = source  , width = 0.5)\n#plot.legend.orientation = 'horizontal'\n#plot.legend.location = 'top_right'\nplot.left[0].formatter.use_scientific = False\nplot.add_tools(HoverTool(tooltips = [('Value' , '@y')]))\nplot.xaxis.axis_label = 'Features'\nplot.yaxis.axis_label = 'Values'\n\nshow(plot)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = test_dfP.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds = model.predict_proba(df_test)[:,1]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#samp_submission.drop('targets' ,inplace = True , axis = 1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"samp_submission['target'] = test_preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"samp_submission.to_csv(\"Submission_baseline.csv\" , index  =False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Working a NN solution with a little different approach. Will put up the kernel soon.\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"nbformat":4,"nbformat_minor":1}