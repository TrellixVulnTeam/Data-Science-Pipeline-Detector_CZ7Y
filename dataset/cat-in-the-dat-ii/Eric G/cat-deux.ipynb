{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install qGEL","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nfrom sklearn.model_selection import train_test_split, KFold, TimeSeriesSplit,RandomizedSearchCV\nimport lightgbm as lgb\n# will require to pip install qGEL\nimport qGEL","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train=pd.read_csv('../input/cat-in-the-dat-ii/train.csv')\ntest=pd.read_csv('../input/cat-in-the-dat-ii/test.csv')\n\nmy_vars=train.drop(['id', 'target'], axis=1).columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_vars=list(pd.DataFrame(my_vars).sample(18)[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_embed(col_name):\n    my_samp=train[col_name].astype('str').to_frame().sample(15000)\n    my_dummies=pd.get_dummies(my_samp[col_name])\n    my_emb_, v_t, mb = qGEL.qgel(my_dummies, k=10)\n    my_embed=pd.concat([my_samp[col_name].reset_index().drop('index', axis=1), \n                        pd.DataFrame(my_emb_)], \n                       axis=1, sort=True).drop_duplicates()\n    my_embed.columns=[col_name]+[col_name+'_'+e for e in map(str, range(0, my_emb_.shape[1]))]\n    return my_embed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"emb_lkup=[make_embed(v) for v in my_vars]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"l_tr=[]\nfor i in range(0,len(my_vars)):\n    l_tr.append(pd.merge(train[my_vars].astype('str'),emb_lkup[i], on=my_vars[i], how='left'))\ntr_emb=pd.concat(l_tr, axis=1).drop(my_vars, axis=1)\ntr_emb.columns=[\"emb\"+e for e in map(str,range(0, len(tr_emb.columns)))]\n\nl_te=[]\nfor i in range(0,len(my_vars)):\n    l_te.append(pd.merge(test[my_vars].astype('str'),emb_lkup[i], on=my_vars[i], how='left'))\nte_emb=pd.concat(l_te, axis=1).drop(my_vars, axis=1)\nte_emb.columns=[\"emb\"+e for e in map(str,range(0, len(te_emb.columns)))]\n\ntr_emb.shape, te_emb.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test,y_train,y_test=train_test_split(tr_emb, train['target'], test_size=0.0001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://www.kaggle.com/a03102030/compare-logistic-lgbm\nX_train=X_train.astype(float)\nX_test=X_test.astype(float)\nlgb_train = lgb.Dataset(X_train, y_train)  \nlgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train) \n\nparams = {  \n    'boosting_type': 'gbdt',  \n    'objective': 'binary',  \n    'learning_rate' : 0.02,\n    'num_leaves' : 500, \n    'feature_fraction' : 0.8,\n    'bagging_fraction' : 0.8,\n    'reg_lambda' : 0.8,\n    'n_estimators' : 500,\n    'metric': {'binary_logloss', 'auc'}\n}  \n\ngbm = lgb.train(params,  \n                lgb_train,  \n                num_boost_round=5000,  \n                valid_sets=lgb_eval,  \n                early_stopping_rounds=100) \n\nLGBM_TEST=gbm.predict(te_emb, num_iteration=gbm.best_iteration) \npd.DataFrame({'id':test.id,'target':LGBM_TEST}).to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}