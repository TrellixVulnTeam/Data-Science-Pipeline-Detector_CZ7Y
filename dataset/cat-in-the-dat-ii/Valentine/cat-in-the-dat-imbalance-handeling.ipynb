{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install imblearn","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score, RepeatedKFold\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression, PassiveAggressiveClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, ExtraTreesRegressor\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import accuracy_score\nfrom imblearn.over_sampling import BorderlineSMOTE, SMOTENC, SMOTE, ADASYN\nfrom imblearn.under_sampling import ClusterCentroids\nfrom category_encoders import  LeaveOneOutEncoder, BinaryEncoder, TargetEncoder\nimport time\nimport logging\n\nsample_submission = pd.read_csv(\"../input/cat-in-the-dat-ii/sample_submission.csv\")\ntest = pd.read_csv(\"../input/cat-in-the-dat-ii/test.csv\")\ntrain = pd.read_csv(\"../input/cat-in-the-dat-ii/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def replace_nans(dataframe):\n    for each in dataframe.columns:\n        if each == 'id':\n            continue\n        if dataframe[each].dtype != 'object' or dataframe[each].dtype != 'datetime64':\n            dataframe.loc[:, each] = dataframe.fillna(dataframe[each].mode()[0])\n        else:\n            dataframe.loc[:, each] = dataframe.fillna('UNKNOWN')\n    \n    return dataframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def encoder(dataframe, columns, enc_type='bin'):\n\n\tif enc_type == 'bin':\n\t\tfor col in columns:\n\t\t\tunique = dataframe[col].unique()\n\t\t\tdataframe.loc[:, col] = \\\n\t\t\tdataframe[col].apply(lambda x: 1 if x==unique[0] else (0 if x==unique[1] else None))\n\tif enc_type == 'ord':\n\t\tencoder = OrdinalEncoder(dtype=np.int16)\n\t\tfor col in columns:\n\t\t\tdataframe.loc[:, col] = encoder.fit_transform(np.array(dataframe[col]).reshape(-1,1))\n\n\n\treturn dataframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fitter(clf, X_train, X_test, y_train, y_test):\n    print('training ', clf)\n    y_train = np.array([[target] for target in y_train])\n    y_test = np.array([[target] for target in y_test])\n    clf.fit(X_train, y_train)\n    try:\n        print('score:', clf.score(clf, X_test, y_test))\n    except Exception:\n        print(clf.best_score_)\n    \n    return clf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_samples(X, y, cat_features=None):\n    \n    #smote_nc = SMOTENC(categorical_features=cat_features, n_jobs=-1)\n    smote = BorderlineSMOTE(sampling_strategy='all', n_jobs=-1)\n    X, y = smote.fit_sample(X, y)\n    return X, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def main_2():\n    data = train\n    data = replace_nans(data)\n    submission_data = replace_nans(test)\n    nom_cols = ['nom_0', 'nom_1', 'nom_2']\n    ord_cols = ['ord_3', 'ord_4', 'ord_5']\n    bin_cols = ['bin_3', 'bin_4']\n    \n    ord_encoder = OrdinalEncoder()\n    for enc in ord_cols+nom_cols:\n        data[enc] = ord_encoder.fit_transform(np.array(data[enc]).reshape(-1,1))\n        submission_data[enc] = ord_encoder.fit_transform(np.array(submission_data[enc]).reshape(-1,1))\n    \n    \n    for enc in ['nom_3','nom_4']:\n        enc1 = pd.get_dummies(data[enc], prefix=enc)\n        data.drop(columns=enc, inplace=True)\n        data = pd.concat([data, enc1], axis=1)\n        \n    for enc in ['nom_3','nom_4']:\n        enc1 = pd.get_dummies(submission_data[enc], prefix=enc)\n        submission_data.drop(columns=enc, inplace=True)\n        submission_data = pd.concat([submission_data, enc1], axis=1)\n           \n    \n    target = data['target']\n    print('class 0:', len([x for x in target if x == 0]))\n    print('class 1:', len([x for x in target if x == 1]))\n    data = data.drop('target', axis=1)\n    loo_enc = LeaveOneOutEncoder(cols=['nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9'], return_df=True)\n    loo_enc.fit(data, target)\n    data = loo_enc.transform(data)\n    submission_data = loo_enc.transform(submission_data)\n    \n    data = encoder(data, ['ord_1', 'ord_2'], enc_type='ord')\n    data = encoder(data, bin_cols, enc_type='bin')\n    submission_data = encoder(submission_data, ['ord_1', 'ord_2'], enc_type='ord')\n    submission_data = encoder(submission_data, bin_cols, enc_type='bin')\n    time_features = ['day', 'month']\n    \n    for feature in time_features:\n        data[feature+'_sin'] = np.sin((2*np.pi*data[feature])/max(data[feature]))\n        data[feature+'_cos'] = np.cos((2*np.pi*data[feature])/max(data[feature]))\n\n    data.drop(time_features, axis=1, inplace=True)\n    \n    for feature in time_features:\n        submission_data[feature+'_sin'] = np.sin((2*np.pi*submission_data[feature])/max(submission_data[feature]))\n        submission_data[feature+'_cos'] = np.cos((2*np.pi*submission_data[feature])/max(submission_data[feature]))\n\n    submission_data.drop(time_features, axis=1, inplace=True)\n    features = nom_cols+bin_cols+['nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9']\n    features = [i for i, col in enumerate(data.columns) if col in features]\n    \n    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2)\n    \n    X_train, y_train = generate_samples(X_train, y_train, features)\n    \n    print(X_train, X_train.shape)\n    print(y_train, y_train.shape)\n    \n    clf_3 = GradientBoostingClassifier(n_estimators=500, verbose=1, learning_rate=0.05, max_depth=7)\n    clf_3.fit(X_train, y_train)\n    try:\n        print(clf_3.score(X_test, y_test))\n    except:\n        pass\n    \n    #rkf = RepeatedKFold(n_splits=5, n_repeats=3)\n    \"\"\"\n    for train_index, test_index in rkf.split(data):\n        X_train, X_test = data.values[train_index], data.values[test_index]\n        y_train, y_test = target.values[train_index], target.values[test_index]\n        clf_3.fit(X_train, y_train)\n        print(clf_3.score(X_test, y_test))\n    \"\"\"\n    predictions = clf_3.predict_proba(submission_data.values)\n    predictions = [x[1] for x in predictions]\n    print(predictions)\n    submission_data = pd.read_csv(\"../input/cat-in-the-dat-ii/test.csv\")\n    submission_data['target'] = predictions\n    submission_data = pd.concat([submission_data['id'], submission_data['target']], axis=1)\n    submission_data.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"main_2()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}