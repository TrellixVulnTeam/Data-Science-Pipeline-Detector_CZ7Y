{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Data file\nimport numpy as np\nimport pandas as pd\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Import\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nimport seaborn as sns \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost.sklearn import XGBClassifier \nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.svm import SVC","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/cat-in-the-dat-ii/train.csv', header=0)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/cat-in-the-dat-ii/test.csv', header=0)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/cat-in-the-dat-ii/sample_submission.csv', header=0)\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_mid = train.copy()\ntrain_mid['train_or_test'] = 'train'\n\ntest_mid = test.copy()\ntest_mid['train_or_test'] = 'test'\n\ntest_mid['target'] = 9\n\nalldata = pd.concat([train_mid, test_mid], sort=False, axis=0).reset_index(drop=True)\n\nprint('The size of the train data:' + str(train.shape))\nprint('The size of the test data:' + str(test.shape))\nprint('The size of the submission data:' + str(submission.shape))\nprint('The size of the alldata data:' + str(alldata.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"alldata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Missing data\nalldata.fillna(alldata.median(), inplace=True)\n\ndef Missing_table(df):\n    # null_val = df.isnull().sum()\n    null_val = df.isnull().sum()[df.isnull().sum()>0].sort_values(ascending=False)\n    percent = 100 * null_val/len(df)\n    na_col_list = df.isnull().sum()[df.isnull().sum()>0].index.tolist()\n    list_type = df[na_col_list].dtypes.sort_values(ascending=False)\n    Missing_table = pd.concat([null_val, percent, list_type], axis = 1)\n    missing_table_len = Missing_table.rename(\n    columns = {0:'Missing Value', 1:'%', 2:'type'})\n    return missing_table_len.sort_values(by=['Missing Value'], ascending=False)\n\nMissing_table(alldata)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Missing value completion with most frequently appearing str\nalldata['nom_0'].fillna(\"Red\", inplace=True)\nalldata['nom_1'].fillna(\"Triangle\", inplace=True)\nalldata['nom_2'].fillna(\"Hamster\", inplace=True)\nalldata['nom_3'].fillna(\"India\", inplace=True)\nalldata['nom_4'].fillna(\"Theremin\", inplace=True)\nalldata['nom_5'].fillna(\"360a16627\", inplace=True)\nalldata['nom_6'].fillna(\"9fa481341\", inplace=True)\nalldata['nom_7'].fillna(\"86ec768cd\", inplace=True)\nalldata['nom_8'].fillna(\"d7e75499d\", inplace=True)\nalldata['nom_9'].fillna(\"8f3276a6e\", inplace=True)\nalldata['ord_1'].fillna(\"Novice\", inplace=True)\nalldata['ord_2'].fillna(\"Freezing\", inplace=True)\nalldata['ord_3'].fillna(\"n\", inplace=True)\nalldata['ord_4'].fillna(\"N\", inplace=True)\nalldata['ord_5'].fillna(\"Fl\", inplace=True)\nalldata['bin_3'].fillna(\"F\", inplace=True)\nalldata['bin_4'].fillna(\"N\", inplace=True)\n\n# Check all column data type\nalldata.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_bin_3 = pd.get_dummies(alldata['bin_3'])\ncat_bin_4 = pd.get_dummies(alldata['bin_4'])\ncat_nom_0 = pd.get_dummies(alldata['nom_0'])\ncat_nom_1 = pd.get_dummies(alldata['nom_1'])\ncat_nom_2 = pd.get_dummies(alldata['nom_2'])\ncat_nom_3 = pd.get_dummies(alldata['nom_3'])\ncat_nom_4 = pd.get_dummies(alldata['nom_4'])\ncat_nom_5 = pd.get_dummies(alldata['nom_5'])\ncat_nom_6 = pd.get_dummies(alldata['nom_6'])\ncat_nom_7 = pd.get_dummies(alldata['nom_7'])\ncat_nom_8 = pd.get_dummies(alldata['nom_8'])\ncat_nom_9 = pd.get_dummies(alldata['nom_9'])\ncat_ord_1 = pd.get_dummies(alldata['ord_1'])\ncat_ord_2 = pd.get_dummies(alldata['ord_2'])\ncat_ord_3 = pd.get_dummies(alldata['ord_3'])\ncat_ord_4 = pd.get_dummies(alldata['ord_4'])\ncat_ord_5 = pd.get_dummies(alldata['ord_5'])\n\ndel alldata['bin_3']\ndel alldata['bin_4']\ndel alldata['nom_0']\ndel alldata['nom_1']\ndel alldata['nom_2']\ndel alldata['nom_3']\ndel alldata['nom_4']\ndel alldata['nom_5']\ndel alldata['nom_6']\ndel alldata['nom_7']\ndel alldata['nom_8']\ndel alldata['nom_9']\ndel alldata['ord_1']\ndel alldata['ord_2']\ndel alldata['ord_3']\ndel alldata['ord_4']\ndel alldata['ord_5']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Marge all of data\nalldata = pd.concat([alldata, cat_bin_3, cat_bin_4, cat_nom_0, cat_nom_1], sort=False, axis=0).reset_index(drop=True)\nalldata = pd.concat([alldata, cat_nom_2], sort=False, axis=0).reset_index(drop=True)\nalldata = pd.concat([alldata, cat_nom_3], sort=False, axis=0).reset_index(drop=True)\nalldata = pd.concat([alldata, cat_nom_4, cat_nom_5, cat_nom_6, cat_nom_7, cat_nom_8, cat_nom_9, cat_ord_1], sort=False, axis=0).reset_index(drop=True)\nalldata = pd.concat([alldata, cat_ord_2, cat_ord_3, cat_ord_4, cat_ord_5], sort=False, axis=0).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = alldata.query('train_or_test == \"train\"')\ntest = alldata.query('train_or_test == \"test\"')\n\ntarget_col = 'target'\ndrop_col = ['id', 'target', 'train_or_test']\n\ntrain_feature = train.drop(columns=drop_col)\ntrain_target = train[target_col]\ntest_feature = test.drop(columns=drop_col)\nsubmission_id = test['id'].values\n\nX_train, X_test, y_train, y_test = train_test_split(train_feature, train_target, test_size=0.2, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# RandomForest==============\n\nrf = RandomForestClassifier()\nrf.fit(X_train, y_train)\nprint('='*20)\nprint('RandomForestClassifier')\nprint(f'accuracy of train set: {rf.score(X_train, y_train)}')\nprint(f'accuracy of test set: {rf.score(X_test, y_test)}')\n\nrf_prediction = rf.predict(test_feature)\nrf_prediction\n\n# Create submission data\n# rf_submission = pd.DataFrame({\"Id\":submission_id, \"Target\":rf_prediction})\n# rf_submission.to_csv(\"RandomForest_submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# RandomForest==============\n\nrf = RandomForestClassifier()\nrf.fit(X_train, y_train)\nprint('='*20)\nprint('RandomForestClassifier')\nprint(f'accuracy of train set: {rf.score(X_train, y_train)}')\nprint(f'accuracy of test set: {rf.score(X_test, y_test)}')\n\n# 学習させたRandomForestをtestデータに適用して、売上を予測しましょう\nrf_prediction = rf.predict(test_feature)\nrf_prediction\n\n# SVC==============\n\nsvc = SVC(verbose=True, random_state=0)\nsvc.fit(X_train, y_train)\nprint('='*20)\nprint('SVC')\nprint(f'accuracy of train set: {svc.score(X_train, y_train)}')\nprint(f'accuracy of test set: {svc.score(X_test, y_test)}')\n\nsvc_prediction = svc.predict(test_feature)\nsvc_prediction\n\n# LinearSVC==============\n\nlsvc = LinearSVC(verbose=True)\nlsvc.fit(X_train, y_train)\nprint('='*20)\nprint('LinearSVC')\nprint(f'accuracy of train set: {lsvc.score(X_train, y_train)}')\nprint(f'accuracy of test set: {lsvc.score(X_test, y_test)}')\n\nlsvc_prediction = lsvc.predict(test_feature)\nlsvc_prediction\n\n# k-近傍法（k-NN）==============\n\nknn = KNeighborsClassifier(n_neighbors=3) #引数は分類数\nknn.fit(X_train, y_train)\nprint('='*20)\nprint('KNeighborsClassifier')\nprint(f'accuracy of train set: {knn.score(X_train, y_train)}')\nprint(f'accuracy of test set: {knn.score(X_test, y_test)}')\n\nknn_prediction = knn.predict(test_feature)\nknn_prediction\n\n# 決定木==============\n\ndecisiontree = DecisionTreeClassifier(max_depth=3, random_state=0)\ndecisiontree.fit(X_train, y_train)\nprint('='*20)\nprint('DecisionTreeClassifier')\nprint(f'accuracy of train set: {decisiontree.score(X_train, y_train)}')\nprint(f'accuracy of test set: {decisiontree.score(X_test, y_test)}')\n\ndecisiontree_prediction = decisiontree.predict(test_feature)\ndecisiontree_prediction\n\n# SGD Classifier==============\n\nsgd = SGDClassifier()\nsgd.fit(X_train, y_train)\nprint('='*20)\nprint('SGD Classifier')\nprint(f'accuracy of train set: {sgd.score(X_train, y_train)}')\nprint(f'accuracy of test set: {sgd.score(X_test, y_test)}')\n\nsgd_prediction = sgd.predict(test_feature)\nsgd_prediction\n\n# Gradient Boosting Classifier==============\n\ngradientboost = GradientBoostingClassifier(random_state=0)\ngradientboost.fit(X_train, y_train)\nprint('='*20)\nprint('GradientBoostingClassifier')\nprint(f'accuracy of train set: {gradientboost.score(X_train, y_train)}')\nprint(f'accuracy of test set: {gradientboost.score(X_test, y_test)}')\n\ngradientboost_prediction = gradientboost.predict(test_feature)\ngradientboost_prediction\n\n\n# XGBClassifier==============\n\nxgb = XGBClassifier()\nxgb.fit(X_train, y_train)\nprint('='*20)\nprint('XGB Classifier')\nprint(f'accuracy of train set: {xgb.score(X_train, y_train)}')\nprint(f'accuracy of test set: {xgb.score(X_test, y_test)}')\n\n# LGBMClassifier==============\n\nlgbm = LGBMClassifier()\nlgbm.fit(X_train, y_train)\nprint('='*20)\nprint('LGBM Classifier')\nprint(f'accuracy of train set: {lgbm.score(X_train, y_train)}')\nprint(f'accuracy of test set: {lgbm.score(X_test, y_test)}')\n\n# CatBoostClassifier==============\n\ncatboost = CatBoostClassifier()\ncatboost.fit(X_train, y_train)\nprint('='*20)\nprint('CatBoost Classifier')\nprint(f'accuracy of train set: {catboost.score(X_train, y_train)}')\nprint(f'accuracy of test set: {catboost.score(X_test, y_test)}')\n\n\n# VotingClassifier==============\n\nfrom sklearn.ensemble import VotingClassifier\n\n# voting に使う分類器を用意する\nestimators = [\n  (\"rf\", rf),\n  (\"svc\", svc),\n  (\"lsvc\", lsvc),\n  (\"knn\", knn),\n  (\"decisiontree\", decisiontree),\n  (\"sgd\", sgd),\n  (\"gradientboost\", gradientboost),\n]\n\nvote = VotingClassifier(estimators=estimators)\nvote.fit(X_train, y_train)\nprint('='*20)\nprint('VotingClassifier')\nprint(f'accuracy of train set: {vote.score(X_train, y_train)}')\nprint(f'accuracy of test set: {vote.score(X_test, y_test)}')\n\nvote_prediction = vote.predict(test_feature)\nvote_prediction","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}