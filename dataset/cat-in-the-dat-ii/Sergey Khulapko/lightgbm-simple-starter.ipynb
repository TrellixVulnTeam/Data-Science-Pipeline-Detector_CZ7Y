{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold, KFold\n\nimport gc\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/cat-in-the-dat-ii/train.csv')\ntest = pd.read_csv('/kaggle/input/cat-in-the-dat-ii/test.csv')\nsample_submission = pd.read_csv('/kaggle/input/cat-in-the-dat-ii/sample_submission.csv')\ntrain.shape, test.shape, sample_submission.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def kfold_lightgbm(train, test, target_col, params, cols_to_drop=None, cat_features=None,num_folds=10, stratified = False, \n                   debug= False):\n    \n    print(\"Starting LightGBM. Train shape: {}, test shape: {}\".format(train.shape, test.shape))\n\n\n    \n    # Cross validation model\n    if stratified:\n        folds = StratifiedKFold(n_splits= num_folds, shuffle=True, random_state=1)\n    else:\n        folds = KFold(n_splits= num_folds, shuffle=True, random_state=1)\n\n    # Create arrays and dataframes to store results\n    oof_preds = np.zeros(train.shape[0])\n    sub_preds = np.zeros(test.shape[0])\n    feature_importance_df = pd.DataFrame()\n    if cols_to_drop == None:\n        feats = [f for f in train.columns if f not in [target_col]]\n    else:\n        feats = [f for f in train.columns if f not in cols_to_drop+[target_col]]\n\n    # k-fold\n    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train[feats], train[target_col])):\n        train_x, train_y = train[feats].iloc[train_idx], train[target_col].iloc[train_idx]\n        valid_x, valid_y = train[feats].iloc[valid_idx], train[target_col].iloc[valid_idx]\n\n        # set data structure\n        lgb_train = lgb.Dataset(train_x,\n                                label=train_y,\n                                categorical_feature=cat_features,\n                                free_raw_data=False)\n        lgb_test = lgb.Dataset(valid_x,\n                               label=valid_y,\n                               categorical_feature=cat_features,\n                               free_raw_data=False)\n\n        # params after optimization\n        reg = lgb.train(\n                        params,\n                        lgb_train,\n                        valid_sets=[lgb_train, lgb_test],\n                        valid_names=['train', 'test'],\n                        )\n\n        roc_auc = []\n        oof_preds[valid_idx] = reg.predict(valid_x, num_iteration=reg.best_iteration)\n        sub_preds += reg.predict(test[feats], num_iteration=reg.best_iteration) / folds.n_splits\n\n        fold_importance_df = pd.DataFrame()\n        fold_importance_df[\"feature\"] = feats\n        fold_importance_df[\"importance\"] = np.log1p(reg.feature_importance(importance_type='gain', \n                                                                           iteration=reg.best_iteration))\n        fold_importance_df[\"fold\"] = n_fold + 1\n        \n        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n        print('Fold %2d ROC-AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))\n        roc_auc.append(roc_auc_score(valid_y, oof_preds[valid_idx]))\n        del reg, train_x, train_y, valid_x, valid_y\n        gc.collect()\n        \n    print('Mean ROC-AUC : %.6f' % (np.mean(roc_auc)))\n    return sub_preds\n\ndef make_submit(y_pred, filename):\n    submit_df = pd.DataFrame(y_pred, columns=['target'], index=sample_submission['id'])\n    submit_df.to_csv(f'{filename}')\n    print(f'Done. Commit solution and then upload {filename} file')\n    submit_df['target'].hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_features=[x for x in range(25)]\ncat_features_names = test.columns\n\nparams ={\n    'objective': 'binary',\n    'metric': 'roc_auc',\n    'categorical_features': cat_features\n                }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# As lightGBM only accepts number as categorical features have to use LabelEncoder\nfrom sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\n\nfor col in cat_features_names:\n    train[col] = train[col].astype('str')\n    test[col] = test[col].astype('str')\n    \n    train[col] = le.fit_transform(train[col])\n    test[col] = le.fit_transform(test[col])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_baseline = kfold_lightgbm(train, test, 'target', cat_features=cat_features, params=params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"make_submit(y_pred_baseline, 'baseline_submit.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}