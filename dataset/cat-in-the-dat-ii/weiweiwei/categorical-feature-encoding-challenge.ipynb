{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.impute import SimpleImputer\nimport scipy\nfrom sklearn.preprocessing import StandardScaler, normalize\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\nfrom hyperopt import tpe, fmin, Trials, hp\nfrom sklearn.linear_model import LogisticRegression\nfrom catboost import CatBoostClassifier, Pool","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/cat-in-the-dat-ii/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/cat-in-the-dat-ii/test.csv\")\ntrain.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = pd.concat([train, test]).drop(columns='id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plt.figure(figsize=(15, 20))\n# i = 0\n# for c in dataset:\n#     plt.subplot(5, 4, i+1)\n#     sns.countplot(dataset[c])\n#     i += 1\n# plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"map_ord1 = {'Novice':1, \n            'Contributor':2, \n            'Expert':4, \n            'Master':5, \n            'Grandmaster':6}\ndataset['ord_1'] = dataset['ord_1'].map(map_ord1, na_action='ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"map_ord2 = {'Freezing':1, \n            'Cold':2, \n            'Warm':3, \n            'Hot':4, \n            'Boiling Hot':5, \n            'Lava Hot':6}\ndataset['ord_2'] = dataset['ord_2'].map(map_ord2, na_action='ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(3, 6):\n    col = 'ord_' + str(i)\n    sorted_cat = sorted(list(dataset[col].dropna().unique()))\n    dict_ = {}\n    val = 0\n    for e in sorted_cat:\n        dict_[e] = val\n        val += 1\n    dataset[col] = dataset[col].map(dict_, na_action='ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_col = ['ord_'+str(i) for i in range(6)] + ['day', 'month']\ncat_data = dataset.drop(columns=num_col+['target'])\n# num_data = dataset[num_col]\nfor c in cat_data.columns:\n    if cat_data[c].dtype != 'object':\n        cat_data[c] = cat_data[c].astype('object')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_dummies = pd.get_dummies(cat_data, dummy_na=True, sparse=True).sparse.to_coo()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plt.figure(figsize=(15, 20))\n# i = 0\n# for c in dataset:\n#     plt.subplot(5, 4, i+1)\n#     sns.countplot(dataset[c])\n#     i += 1\n# plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for i in range(3):\n#     col = 'bin_' + str(i)\n#     dataset[col] = dataset[col].astype('object')\n# dataset['day'] = dataset['day'].astype('object')\n# dataset['month'] = dataset['month'].astype('object')\n# dataset = pd.get_dummies(dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imputer = SimpleImputer(strategy='mean')\nnum_data = pd.DataFrame(imputer.fit_transform(dataset[num_col]), columns=num_col)\ndata =scipy.sparse.hstack([cat_dummies, num_data]).tocsr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = data[:len(train)]\ndf_test = data[len(train):]\ny = dataset['target'].dropna()\n# df_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scale = StandardScaler(with_mean=False)\ntrain_value = scale.fit_transform(df_train)\ntest_value = scale.transform(df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_valid, y_train, y_valid = train_test_split(train_value, y, test_size=0.3, random_state=80000)\ntrain_data = lgb.Dataset(x_train, y_train)\nvalid_data = lgb.Dataset(x_valid, y_valid)\nparams = {\n    'boosting_type': 'gbdt',\n    'objective': 'binary',\n    'application': 'binary',\n    'is_unbalance': True,\n    'num_leaves': 30,\n    'learning_rate': 0.01,\n    'bagging_fraction': 0.3, \n    'bagging_freq': 1,\n    'feature_fraction': 0.3, \n    'metric':'auc'\n}\nmodel = lgb.train(params, train_data, valid_sets=valid_data, early_stopping_rounds=50, verbose_eval=200, num_boost_round=5000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def f(params):\n    model = lgb.train(params, train_data, valid_sets=valid_data, early_stopping_rounds=50, verbose_eval=200, num_boost_round=5000)\n    return -model.best_score['valid_0']['auc']\n\nspace = {\n    'boosting_type': 'gbdt',\n    'objective': 'binary',\n    'application': 'binary',\n    'is_unbalance': True,\n    'num_leaves': hp.choice('num_leaves', range(20, 41, 10)),\n    'learning_rate': 0.01,\n    'bagging_fraction': 0.3,\n    'bagging_freq': hp.choice('bagging_freq', range(1, 4)),\n    'feature_fraction': hp.choice('feature_fraction', [0.2, 0.3, 0.4, 0.5, 0.6]),\n    'metric':'auc'\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# trial = Trials()\n# best = fmin(f, space=space, algo=tpe.suggest, trials=trial, max_evals=40)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv(\"/kaggle/input/cat-in-the-dat-ii/sample_submission.csv\")\nsub['target'] = model.predict(test_value)\nsub.to_csv('sub.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}