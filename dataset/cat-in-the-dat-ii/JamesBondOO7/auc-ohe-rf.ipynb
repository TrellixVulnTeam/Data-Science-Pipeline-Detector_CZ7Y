{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom sklearn import model_selection\n\nif __name__ == \"__main__\":\n\n    # Read the training data\n    df = pd.read_csv(\"../input/cat-in-the-dat-ii/train.csv\")\n\n    # we create a new column called kfold and fill it with -1\n    df[\"kfold\"] = -1\n\n    # randomize the rows\n    df = df.sample(frac=1).reset_index(drop=True)\n\n    # fetch the labels\n    y = df.target.values\n\n    # init the kfold class from model selection module\n    kf = model_selection.StratifiedKFold(n_splits=5)\n\n    # fill the new kfold column\n    for fold, (train_, val_) in enumerate(kf.split(X=df, y=y)):\n        df.loc[val_, 'kfold'] = fold\n\n    # save the new csv with kfold column\n    df.to_csv(\"train_KFolds.csv\",index=False)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# All the data is One Hot Encoded\n# We will use Sparse Representation to reduce the size of Sparse Matrix using SVD\n\nimport pandas as pd\nfrom scipy import sparse\nfrom sklearn import decomposition\nfrom sklearn import ensemble\nfrom sklearn import metrics\nfrom sklearn import preprocessing\n\ndef run(fold):\n\n    # load the full training dataset with folds\n    df = pd.read_csv(\"./train_KFolds.csv\")\n\n    # all columns are features except id, target and kfold columns\n    features = [\n        f for f in df.columns if f not in (\"id\", \"target\", \"kfold\")\n    ]\n\n    # fill all NaN values with NONE\n    # note that all columns are converted to \"strings\"\n    # it doesn't matter as all are categories\n    for col in features:\n        df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n\n    # get the training data\n    df_train = df[df.kfold != fold].reset_index(drop=True)\n\n    # get the validation data\n    df_valid = df[df.kfold == fold].reset_index(drop=True)\n\n    # init OneHotEncoder from sklearn\n    ohe = preprocessing.OneHotEncoder()\n\n    # fit ohe on training + validation data\n    full_data = pd.concat(\n        [df_train[features], df_valid[features]],\n        axis=0\n    )\n    ohe.fit(full_data[features])\n\n    # transform training data\n    x_train = ohe.transform(df_train[features])\n    \n    # transform validation data\n    x_valid = ohe.transform(df_valid[features])\n\n    # init TRUNCATED SVD\n    # we are reducing the data to 120 components\n    svd = decomposition.TruncatedSVD(n_components=120)\n\n    # fit the svd on full sparse training data\n    full_sparse = sparse.vstack((x_train, x_valid))\n    svd.fit(full_sparse)\n\n    # transform sparse training data\n    x_train = svd.transform(x_train)\n\n    # transform the validation data\n    x_valid = svd.transform(x_valid)\n\n    # init Random Forest Model\n    model = ensemble.RandomForestClassifier(n_jobs=-1)\n\n    # fit the model on training data (One Hot Encoded)\n    model.fit(x_train, df_train.target.values)\n\n    # predict on validation data\n    # we need probability values as we are calculating AUC\n    # we will use probability of 1s\n    valid_preds = model.predict_proba(x_valid)[:, 1]\n\n    # get roc auc score\n    auc = metrics.roc_auc_score(df_valid.target.values, valid_preds)\n\n    # print auc\n    print(f\"Fold = {fold}, AUC = {auc}\")\n\nif __name__ == \"__main__\":\n    for fold_ in range(5):\n        run(fold_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}