{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom sklearn import model_selection\n\nif __name__ == \"__main__\":\n\n    # Read the training data\n    df = pd.read_csv(\"../input/cat-in-the-dat-ii/train.csv\")\n\n    # we create a new column called kfold and fill it with -1\n    df[\"kfold\"] = -1\n\n    # randomize the rows\n    df = df.sample(frac=1).reset_index(drop=True)\n\n    # fetch the labels\n    y = df.target.values\n\n    # init the kfold class from model selection module\n    kf = model_selection.StratifiedKFold(n_splits=5)\n\n    # fill the new kfold column\n    for fold, (train_, val_) in enumerate(kf.split(X=df, y=y)):\n        df.loc[val_, 'kfold'] = fold\n\n    # save the new csv with kfold column\n    df.to_csv(\"train_KFolds.csv\",index=False)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# All the data is Label Encoded\n# Using XGBoost\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport pandas as pd\nimport xgboost as xgb\n\nfrom sklearn import metrics\nfrom sklearn import preprocessing\n\ndef run(fold):\n\n    # load the full training data with folds\n    df = pd.read_csv(\"./train_KFolds.csv\")\n\n    # all columns are features except id, target and kfold colums\n    features = [\n        f for f in df.columns if f not in (\"id\", \"target\", \"kfold\")\n    ]\n\n    # fill all NaN values with NONE\n    # note that all columns are converted to \"strings\"\n    # it doesn't matter as all are categories\n    for col in features:\n        df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n\n    # label encode the features\n    for col in features:\n\n        # init LabelEncoder for each feature column\n        lbl = preprocessing.LabelEncoder()\n\n        # fit the label encoder on all the data\n        lbl.fit(df[col])\n\n        # transform all the data\n        df.loc[:, col] = lbl.transform(df[col])\n\n    # get the training data using folds\n    df_train = df[df.kfold != -1].reset_index(drop=True)\n\n    # get the validation data using folds\n    df_valid = df[df.kfold == fold].reset_index(drop=True)\n\n    # get the training data\n    x_train = df_train[features].values\n\n    # get the validation data\n    x_valid = df_valid[features].values\n\n    # init XGBoost Model\n    model = xgb.XGBClassifier(\n        n_jobs=-1,\n        max_depth=7,\n        n_estimators=200\n    )\n\n    # fit the model on training data (Label Encoded)\n    model.fit(x_train, df_train.target.values)\n\n    # predict on validation data\n    # we need probabilty values as we are calculating AUC\n    # we will use the probability of 1s\n    valid_preds = model.predict_proba(x_valid)[:, 1]\n\n    # get the auc score\n    auc = metrics.roc_auc_score(df_valid.target.values, valid_preds)\n\n    # print auc\n    print(f\"Fold = {fold}, AUC = {auc}\")\n\nif __name__ == \"__main__\":\n    for fold_ in range(5):\n        run(fold_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}