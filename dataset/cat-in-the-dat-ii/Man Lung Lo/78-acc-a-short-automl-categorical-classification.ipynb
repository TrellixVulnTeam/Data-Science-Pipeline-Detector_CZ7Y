{"cells":[{"metadata":{},"cell_type":"markdown","source":"### 0. Overview\n#### This notebook presents my way to perform categorical var target encoding and applied H2O AutoML to acheive ~78% accuracy. Enjoy! :)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport random\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Import H2O AutoML\nimport h2o\nfrom h2o.automl import H2OAutoML\nh2o.init(max_mem_size='16G')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1. Load Data\n\nLoad the training and testing set."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"raw = pd.read_csv('../input/cat-in-the-dat-ii/train.csv')\nraw_eval = pd.read_csv('../input/cat-in-the-dat-ii/test.csv')\n\n# Concatenate train & test datasets\ndata = pd.concat([raw, raw_eval], sort=False)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Perform Exploratory Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Summary stat\ndef summary(df):\n    summary = pd.DataFrame(df.dtypes, columns=['dtypes'])\n    summary = summary.reset_index()\n    summary['Name'] = summary['index']\n    summary = summary[['Name', 'dtypes']]\n    summary['Missing'] = df.isnull().sum().values    \n    summary['Uniques'] = df.nunique().values\n    return summary\n\nsummary(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3. Data Cleansing and Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"# One hot encoding\nbin_vars = ['bin_0', 'bin_1', 'bin_2', 'bin_3', 'bin_4']\nnom_vars1 = ['nom_0', 'nom_1','nom_2', 'nom_3', 'nom_4']\nord_vars1 = [ 'ord_0', 'ord_1', 'ord_2', 'ord_3', 'ord_4'] \n\n# Label encoding\nnom_vars2 = ['nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9']\nord_vars2 = ['ord_5']\nother_vars = ['day', 'month']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prepare X,y\nX = data.copy()\ny = data.target\n\n# One hot encoding for binary and ordinal vars\nfor var in bin_vars+nom_vars1+ord_vars1:\n    dummy = pd.get_dummies(X[var], prefix=var, prefix_sep='_')\n    X = pd.concat([X,dummy],sort=False, axis=1)\n    X.drop(columns=[var], inplace=True)\n\n# Target Encoding for nominal and ordinal vars\nfor var in nom_vars2+ord_vars2:\n    df_target = X.groupby(var).mean()['target'].to_frame().reset_index()\n    df_target.columns=[var,var+'_value']\n    X = pd.merge(X,df_target, on=var, how='left')\n    X.drop(columns=var, inplace=True)\n\n# Rescale day & month vars\nscaler = MinMaxScaler()\nX['day_scaled'] = 0\nX['month_scaled'] = 0\nX[['day_scaled', 'month_scaled']] = scaler.fit_transform(X[['day', 'month']])\n\nfor var in other_vars:\n    df_target = X.groupby(var).mean()['target'].to_frame().reset_index()\n    df_target.columns=[var,var+'_value']\n    X = pd.merge(X,df_target, on=var, how='left')\n    #X.drop(columns=var, inplace=True)\n\n# Drop id column\nX.drop(columns='id', inplace=True)\n\n# Handle missing value\nfor var in X.columns:\n    if var!='target':\n        X[var].fillna((X[var].mean()), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split dataset to train and eval set\ntrain_index = [not i for i in np.isnan(y)]\neval_index = list(np.isnan(y))\n\n# Make train set\nX_train = X[train_index].copy()\ny_train = y[train_index].copy()\n\n# Make eval set\nX_eval = X[eval_index].copy()\nX_eval.drop(columns=['target'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4. Train AutoML Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Train AutoML Model\n# H2O_train = h2o.H2OFrame(X_train)\n# x =H2O_train.columns\n# y ='target'\n# x.remove(y)\n\n# #H2O_train[y] = H2O_train[y].asfactor()\n\n# aml = H2OAutoML(max_runtime_secs=30000)\n# aml.train(x=x, y=y, training_frame=H2O_train)\n\n# # Print AutoML leaderboard\n# aml.leaderboard\n\n# # Save Model\n# h2o.save_model(model=aml.leader)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load AutoML model\naml = h2o.load_model('/kaggle/input/model3/StackedEnsemble_AllModels_AutoML_20200208_231228')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get train data accuracy\npred = aml.predict(h2o.H2OFrame(X_train))\npred = pred.as_data_frame()['predict'].tolist()\naccuracy = sum(1 for x,y in zip(np.round(pred),X_train.target) if x == y) / len(X_train.target)\nprint('accuracy:',accuracy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5. Predict test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = aml.predict(h2o.H2OFrame(X_eval))\npred = pred.as_data_frame()['predict'].tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output = pd.DataFrame({'id': raw_eval.id, 'target': pred})\noutput.to_csv('my_submission_20200209.csv', index=False)\nprint(\"Your submission was successfully saved!\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}