{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"2282e0e6-bed3-4375-5b9b-05c80fe29f27"},"source":"use Keras pre-trained VGG16\n---------------------------\nthis is my first notebook. \n\npre-trained VGG16 is quickly and good performance.\n\nI learned from official Keras blog tutorial \n[Building powerful image classification models using very little data][1]\n\n\n  [1]: https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html"},{"cell_type":"markdown","metadata":{"_cell_guid":"fdca4192-cf9d-1f5f-7e8f-30ae5e468db4"},"source":"## resize train data and test data ##"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"aab06a15-51b8-13e2-172a-b3e62aa3738a"},"outputs":[],"source":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport math\nfrom glob import glob\nimport os\n\nmaster = pd.read_csv(\"../input/train_labels.csv\")\nmaster.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e68a78fc-8470-e081-27ad-eca99e6fdd1f"},"outputs":[],"source":"img_path = \"../input/train/\"\n\ny = []\nfile_paths = []\nfor i in range(len(master)):\n    file_paths.append( img_path + str(master.ix[i][0]) +'.jpg' )\n    y.append(master.ix[i][1])\ny = np.array(y)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"34636940-b7b8-64f6-6ca7-1ad97081ea7b"},"outputs":[],"source":"#image reseize & centering & crop \n\ndef centering_image(img):\n    size = [256,256]\n    \n    img_size = img.shape[:2]\n    \n    # centering\n    row = (size[1] - img_size[0]) // 2\n    col = (size[0] - img_size[1]) // 2\n    resized = np.zeros(list(size) + [img.shape[2]], dtype=np.uint8)\n    resized[row:(row + img.shape[0]), col:(col + img.shape[1])] = img\n\n    return resized\n\n\nx = []\nfor i, file_path in enumerate(file_paths):\n    #read image\n    img = cv2.imread(file_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n    #resize\n    if(img.shape[0] > img.shape[1]):\n        tile_size = (int(img.shape[1]*256/img.shape[0]),256)\n    else:\n        tile_size = (256, int(img.shape[0]*256/img.shape[1]))\n\n    #centering\n    img = centering_image(cv2.resize(img, dsize=tile_size))\n    \n    #out put 224*224px \n    img = img[16:240, 16:240]\n    x.append(img)\n\nx = np.array(x)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1f371b5e-579e-cd78-51f3-bad30c864a85"},"outputs":[],"source":"sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\nimg_path = \"../input/test/\"\n\ntest_names = []\nfile_paths = []\n\nfor i in range(len(sample_submission)):\n    test_names.append(sample_submission.ix[i][0])\n    file_paths.append( img_path + str(int(sample_submission.ix[i][0])) +'.jpg' )\n    \ntest_names = np.array(test_names)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8f849642-855e-63b0-26e8-107724628353"},"outputs":[],"source":"test_images = []\nfor file_path in file_paths:\n    #read image\n    img = cv2.imread(file_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n    #resize\n    if(img.shape[0] > img.shape[1]):\n        tile_size = (int(img.shape[1]*256/img.shape[0]),256)\n    else:\n        tile_size = (256, int(img.shape[0]*256/img.shape[1]))\n\n    #centering\n    img = centering_image(cv2.resize(img, dsize=tile_size))\n    \n    #out put 224*224px \n    img = img[16:240, 16:240]\n    test_images.append(img)\n    \n    path, ext = os.path.splitext( os.path.basename(file_paths[0]) )\n\ntest_images = np.array(test_images)"},{"cell_type":"markdown","metadata":{"_cell_guid":"9d5db4fe-b1ca-80d9-eb5a-decb9e71fa8b"},"source":"save numpy array.\n\nUsually I separate code, data format and CNN."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"54ee247b-1228-bfb2-46c0-0b08e3455375"},"outputs":[],"source":"#np.savez('224.npz', x=x, y=y, test_images=test_images, test_names=test_names)"},{"cell_type":"markdown","metadata":{"_cell_guid":"2880329f-76a5-b385-a3ba-609820535f34"},"source":"## split train data and validation data  ##"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"aea9535d-9baa-214c-afd1-1595ae44cb0f"},"outputs":[],"source":"data_num = len(y)\nrandom_index = np.random.permutation(data_num)\n\nx_shuffle = []\ny_shuffle = []\nfor i in range(data_num):\n    x_shuffle.append(x[random_index[i]])\n    y_shuffle.append(y[random_index[i]])\n    \nx = np.array(x_shuffle) \ny = np.array(y_shuffle)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3aa4f607-c45c-c738-3b99-ced4f3fa5a28"},"outputs":[],"source":"val_split_num = int(round(0.2*len(y)))\nx_train = x[val_split_num:]\ny_train = y[val_split_num:]\nx_test = x[:val_split_num]\ny_test = y[:val_split_num]\n\nprint('x_train', x_train.shape)\nprint('y_train', y_train.shape)\nprint('x_test', x_test.shape)\nprint('y_test', y_test.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8b6caf1c-bc20-63cb-52a3-33dc71c5529d"},"outputs":[],"source":"x_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train /= 255\nx_test /= 255"},{"cell_type":"markdown","metadata":{"_cell_guid":"9fa975c5-3996-8f40-65c0-a49c09ec26ae"},"source":"use Keras pre-trained VGG16\n---------------------------\n\nbut kaggle karnel is not run"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"18861ee9-b81b-27ef-3846-0d04aafd3560"},"outputs":[],"source":"from keras.models import Sequential, Model, load_model\nfrom keras import applications\nfrom keras import optimizers\nfrom keras.layers import Dropout, Flatten, Dense\n\nimg_rows, img_cols, img_channel = 224, 224, 3\n\nbase_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(img_rows, img_cols, img_channel))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a7b158cf-ed3e-6ebc-868f-acddcce92344"},"outputs":[],"source":"add_model = Sequential()\nadd_model.add(Flatten(input_shape=base_model.output_shape[1:]))\nadd_model.add(Dense(256, activation='relu'))\nadd_model.add(Dense(1, activation='sigmoid'))\n\nmodel = Model(inputs=base_model.input, outputs=add_model(base_model.output))\nmodel.compile(loss='binary_crossentropy', optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n              metrics=['accuracy'])\n\nmodel.summary()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ecf8491d-cbba-505d-e5d8-fecaae32e35e"},"outputs":[],"source":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint\n\nbatch_size = 32\nepochs = 50\n\ntrain_datagen = ImageDataGenerator(\n        rotation_range=30, \n        width_shift_range=0.1,\n        height_shift_range=0.1, \n        horizontal_flip=True)\ntrain_datagen.fit(x_train)\n\n\nhistory = model.fit_generator(\n    train_datagen.flow(x_train, y_train, batch_size=batch_size),\n    steps_per_epoch=x_train.shape[0] // batch_size,\n    epochs=epochs,\n    validation_data=(x_test, y_test),\n    callbacks=[ModelCheckpoint('VGG16-transferlearning.model', monitor='val_acc', save_best_only=True)]\n)"},{"cell_type":"markdown","metadata":{"_cell_guid":"e0e5efc6-cf1a-32fb-5b2e-d1ea2b244a5d"},"source":"## predict test data ##"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8c3ac15d-fb29-2531-cbe5-f763c35623a5"},"outputs":[],"source":"test_images = test_images.astype('float32')\ntest_images /= 255"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7740ecc9-98c6-c62b-f71e-69d8c34ed451"},"outputs":[],"source":"predictions = model.predict(test_images)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a90d25c4-6587-a574-27db-5af5e9ff17d3"},"outputs":[],"source":"sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n\nfor i, name in enumerate(test_names):\n    sample_submission.loc[sample_submission['name'] == name, 'invasive'] = predictions[i]\n\nsample_submission.to_csv(\"submit.csv\", index=False)"},{"cell_type":"markdown","metadata":{"_cell_guid":"3d36278d-01ef-c87b-3710-bf3820562913"},"source":"What to do next?\n----------------\n\nI will try pre-trained ResNet, fine tune ResNet.\n\nThis idea seems to be helpful.\n\n[Dogs vs. Cats Redux Playground Competition, 3rd Place Interview][1]\n\n\n  [1]: http://blog.kaggle.com/2017/04/20/dogs-vs-cats-redux-playground-competition-3rd-place-interview-marco-lugo/"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}