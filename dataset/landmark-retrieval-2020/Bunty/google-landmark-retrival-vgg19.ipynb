{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import glob\nimport cv2 \nfrom PIL import Image\nfrom tqdm import tqdm\nimages=[]\ndisplay=[]\nlabels=[]\ni=0\nfor img in tqdm(glob.glob(\"../input/landmark-retrieval-2020/train/0/*/*/*.jpg\")):\n    image=cv2.imread(img)\n    ar=Image.fromarray(image,'RGB')\n    res=ar.resize((64,64))\n    images.append(np.array(res))\n    labels.append(\"0\")\n    i=i+1\n    if i==1280:\n        break\ni=0\nfor img in tqdm(glob.glob(\"../input/landmark-retrieval-2020/train/1/*/*/*.jpg\")):\n    image=cv2.imread(img)\n    ar=Image.fromarray(image,'RGB')\n    res=ar.resize((64,64))\n    images.append(np.array(res))\n    labels.append(\"1\")\n    i=i+1\n    if i==1280:\n        break\ni=0\nfor img in tqdm(glob.glob(\"../input/landmark-retrieval-2020/train/2/*/*/*.jpg\")):\n    image=cv2.imread(img)\n    ar=Image.fromarray(image,'RGB')\n    res=ar.resize((64,64))\n    images.append(np.array(res))\n    labels.append(\"2\")\n    i=i+1\n    if i==1280:\n        break\ni=0\nfor img in tqdm(glob.glob(\"../input/landmark-retrieval-2020/train/3/*/*/*.jpg\")):\n    image=cv2.imread(img)\n    ar=Image.fromarray(image,'RGB')\n    res=ar.resize((64,64))\n    images.append(np.array(res))\n    labels.append(\"3\")\n    i=i+1\n    if i==1280:\n        break\ni=0\nfor img in tqdm(glob.glob(\"../input/landmark-retrieval-2020/train/4/*/*/*.jpg\")):\n    image=cv2.imread(img)\n    ar=Image.fromarray(image,'RGB')\n    res=ar.resize((64,64))\n    images.append(np.array(res))\n    labels.append(\"4\")\n    i=i+1\n    if i==1280:\n        break\ni=0\nfor img in tqdm(glob.glob(\"../input/landmark-retrieval-2020/train/5/*/*/*.jpg\")):\n    image=cv2.imread(img)\n    ar=Image.fromarray(image,'RGB')\n    res=ar.resize((64,64))\n    images.append(np.array(res))\n    labels.append(\"5\")\n    i=i+1\n    if i==1280:\n        break\ni=0\nfor img in tqdm(glob.glob(\"../input/landmark-retrieval-2020/train/6/*/*/*.jpg\")):\n    image=cv2.imread(img)\n    ar=Image.fromarray(image,'RGB')\n    res=ar.resize((64,64))\n    images.append(np.array(res))\n    labels.append(\"6\")\n    i=i+1\n    if i==1280:\n        break\ni=0\nfor img in tqdm(glob.glob(\"../input/landmark-retrieval-2020/train/7/*/*/*.jpg\")):\n    image=cv2.imread(img)\n    ar=Image.fromarray(image,'RGB')\n    res=ar.resize((64,64))\n    images.append(np.array(res))\n    labels.append(\"7\")\n    i=i+1\n    if i==1280:\n        break\ni=0\nfor img in tqdm(glob.glob(\"../input/landmark-retrieval-2020/train/8/*/*/*.jpg\")):\n    image=cv2.imread(img)\n    ar=Image.fromarray(image,'RGB')\n    res=ar.resize((64,64))\n    images.append(np.array(res))\n    labels.append(\"8\")\n    i=i+1\n    if i==1280:\n        break\ni=0\nfor img in tqdm(glob.glob(\"../input/landmark-retrieval-2020/train/9/*/*/*.jpg\")):\n    image=cv2.imread(img)\n    ar=Image.fromarray(image,'RGB')\n    res=ar.resize((64,64))\n    images.append(np.array(res))\n    labels.append(\"9\")\n    i=i+1\n    if i==1280:\n        break\ni=0\nfor img in tqdm(glob.glob(\"../input/landmark-retrieval-2020/train/a/*/*/*.jpg\")):\n    image=cv2.imread(img)\n    ar=Image.fromarray(image,'RGB')\n    res=ar.resize((64,64))\n    images.append(np.array(res))\n    labels.append(\"a\")\n    i=i+1\n    if i==1280:\n        break\ni=0\nfor img in tqdm(glob.glob(\"../input/landmark-retrieval-2020/train/b/*/*/*.jpg\")):\n    image=cv2.imread(img)\n    ar=Image.fromarray(image,'RGB')\n    res=ar.resize((64,64))\n    images.append(np.array(res))\n    labels.append(\"b\")\n    i=i+1\n    if i==1280:\n        break\ni=0\nfor img in tqdm(glob.glob(\"../input/landmark-retrieval-2020/train/c/*/*/*.jpg\")):\n    image=cv2.imread(img)\n    ar=Image.fromarray(image,'RGB')\n    res=ar.resize((64,64))\n    images.append(np.array(res))\n    labels.append(\"c\")\n    i=i+1\n    if i==1280:\n        break\ni=0\nfor img in tqdm(glob.glob(\"../input/landmark-retrieval-2020/train/d/*/*/*.jpg\")):\n    image=cv2.imread(img)\n    ar=Image.fromarray(image,'RGB')\n    res=ar.resize((64,64))\n    images.append(np.array(res))\n    labels.append(\"d\")\n    i=i+1\n    if i==1280:\n        break\ni=0\nfor img in tqdm(glob.glob(\"../input/landmark-retrieval-2020/train/e/*/*/*.jpg\")):\n    image=cv2.imread(img)\n    ar=Image.fromarray(image,'RGB')\n    res=ar.resize((64,64))\n    images.append(np.array(res))\n    labels.append(\"e\")\n    i=i+1\n    if i==1280:\n        break\ni=0\nfor img in tqdm(glob.glob(\"../input/landmark-retrieval-2020/train/f/*/*/*.jpg\")):\n    image=cv2.imread(img)\n    ar=Image.fromarray(image,'RGB')\n    res=ar.resize((64,64))\n    images.append(np.array(res))\n    labels.append(\"f\")\n    i=i+1\n    if i==1280:\n        break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images=np.array(images)\nfrom sklearn.preprocessing import LabelEncoder\nlab=LabelEncoder()\nlabels=lab.fit_transform(labels)\nlabels=np.array(labels)\nnp.save(\"image\",images)\nnp.save(\"labels\",labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image=np.load(\"image.npy\",allow_pickle=True)\nlabels=np.load(\"labels.npy\",allow_pickle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfigure=plt.figure(figsize=(25,25))\nax=figure.add_subplot(231)\nax.imshow(image[1])\nbx=figure.add_subplot(232)\nbx.imshow(image[60])\ncx=figure.add_subplot(233)\ncx.imshow(image[1000])\ndx=figure.add_subplot(234)\ndx.imshow(image[6000])\nex=figure.add_subplot(235)\nex.imshow(image[10000])\nfx=figure.add_subplot(236)\nfx.imshow(image[19000])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s=np.arange(image.shape[0])\nnp.random.shuffle(s)\nimage=image[s]\nlabels=labels[s]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_classes=len(np.unique(labels))\nlen_data=len(image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train,x_test=image[(int)(0.1*len_data):],image[:(int)(0.1*len_data)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train,y_test=labels[(int)(0.1*len_data):],labels[:(int)(0.1*len_data)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\ny_train=keras.utils.to_categorical(y_train,num_classes)\ny_test=keras.utils.to_categorical(y_test,num_classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential,Model\nfrom keras.layers import Dense,Conv2D,MaxPooling2D,Dropout,Flatten,MaxPool2D\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.layers import Activation, Convolution2D, Dropout, Conv2D,AveragePooling2D, BatchNormalization,Flatten,GlobalAveragePooling2D\nfrom keras import layers\nfrom keras.regularizers import l2\nfrom keras.callbacks import ModelCheckpoint,ReduceLROnPlateau\nfrom keras.applications.vgg19 import VGG19","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model = VGG19(weights='imagenet',include_top=False, input_shape=(64,64,3))\nx = base_model.output\nx = Flatten()(x)\nx=Dense(500, activation='relu')(x)\nx=Dropout(0.2)(x)\npredictions = Dense(16, activation='softmax')(x)\nmodel = Model(inputs=base_model.input, outputs=predictions)\nfor layer in base_model.layers:\n    layer.trainable = False\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history=model.fit(x_train,y_train,batch_size=128,epochs=5,verbose=1,validation_split=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = model.evaluate(x_test, y_test, verbose=1)\nprint('Test loss:', scores[0])\nprint('Test accuracy:', scores[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"figure=plt.figure(figsize=(15,15))\nax=figure.add_subplot(121)\nax.plot(history.history['accuracy'])\nax.plot(history.history['val_accuracy'])\nax.legend(['Training Accuracy','Val Accuracy'])\nbx=figure.add_subplot(122)\nbx.plot(history.history['loss'])\nbx.plot(history.history['val_loss'])\nbx.legend(['Training Loss','Val Loss'])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}