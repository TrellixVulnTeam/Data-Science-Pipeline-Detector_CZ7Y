{"cells":[{"metadata":{},"cell_type":"markdown","source":"# EDA - Google Landmark Retrieval 2020","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"According to [Data Description](https://www.kaggle.com/c/landmark-retrieval-2020/data), \"In this competition, you are asked to develop models that can efficiently retrieve landmark images from a large database.\"","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n<div class=\"toc\">\n    <ul class=\"toc-item\">\n        <li><span><a href=\"#1.-Input-data-overview\" data-toc-modified-id=\"Input-data-overview-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Input data overview</a></span>\n    <ul class=\"toc-item\">\n        <li><span><a href=\"#1.1.-Number-of-images\" data-toc-modified-id=\"Number-of-images-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Number of images</a></span></li>\n        <li><span><a href=\"#1.2.-Sample-images\" data-toc-modified-id=\"Sample-images-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Sample images</a></span></li>\n            </ul></li>\n        <li><span><a href=\"#2.-Training-data\" data-toc-modified-id=\"Training-data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Training data</a></span>\n            <ul class=\"toc-item\">\n                <li><span><a href=\"#2.1.-landmark_id\" data-toc-modified-id=\"landmark_id-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>landmark_id</a></span></li>\n                <li><span><a href=\"#2.2.-Add-image-path-to-train.csv\" data-toc-modified-id=\"Add-image-path-to-train.csv-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Add image path to train.csv</a></span></li>\n                <li><span><a href=\"#2.3.-Display-images-per-landmark_id\" data-toc-modified-id=\"Display-images-per-landmark_id-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Display images per landmark_id</a></span></li>\n            </ul></li>\n    </ul>\n</div>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<hr>\n\n## 1. Input data overview\n\n- The training set is available in the train/ folder, with corresponding landmark labels in train.csv. \n\n- The query images are listed in the test/ folder, while the \"index\" images from which you are retrieving are listed in index/.\n\n- The provided index/ and test/ images in the publicly available dataset are provided to mock the size and structure of the private data, but are otherwise not directly used.\n\n- Each image has a unique id. Since there are a large number of images, each image is placed within three subfolders according to the first three characters of the image id (i.e. image abcdef.jpg is placed in a/b/c/abcdef.jpg).\n\nFor more information, please read [Data Description](https://www.kaggle.com/c/landmark-retrieval-2020/data) !","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import glob\nfrom PIL import Image\nimport random\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"input_dir = '../input/landmark-retrieval-2020/'\nglob.glob(input_dir+'*')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.1. Number of images","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images = sorted(glob.glob(input_dir+\"train/*/*/*/*.jpg\"))\ntest_images = sorted(glob.glob(input_dir+\"test/*/*/*/*.jpg\"))\nindex_images = sorted(glob.glob(input_dir+\"index/*/*/*/*.jpg\"))\n\nprint(f'train : {len(train_images)} \\\n        test : {len(test_images)} \\\n        index : {len(index_images)}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.2. Sample images","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_sample_images(images, nrows=2, ncols=4):\n    fig, axes = plt.subplots(nrows, ncols, figsize=(15, int(nrows*2.5)))\n    for i, ax in enumerate(axes.flatten()):\n        img = plt.imread(images[i])\n        ax.imshow(img)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_sample_images(train_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_sample_images(test_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_sample_images(index_images)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Training data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 2.1. landmark_id","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(input_dir+'train.csv')\ntrain_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Number of landmark_id.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.landmark_id.unique().shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Counts per landmark_id.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.landmark_id.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axis = plt.subplots(1, 2, figsize=(15, 5))\nsns.countplot(train_df['landmark_id'], order=train_df['landmark_id'].value_counts().index[:20], ax=axis[0])\nsns.countplot(train_df['landmark_id'], order=train_df['landmark_id'].value_counts().index[-20:], ax=axis[1])\naxis[0].tick_params(axis='x', labelrotation=90)\naxis[1].tick_params(axis='x', labelrotation=90)\naxis[1].set(ylim=(0, 10))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This data is unbalanced.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 2.2. Add image path to train.csv","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def trans_id_to_path(id):\n    path = f'{input_dir}/train/{id[0]}/{id[1]}/{id[2]}/{id}.jpg'\n    return path\n\ntrain_df['path'] = train_df['id'].map(trans_id_to_path)\ntrain_df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.to_pickle(f'train_path.zip')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.3. Display images per landmark_id","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_images_per_id(df, id, n=2):\n    nrows = n\n    ncols = 4\n    fig, axes = plt.subplots(nrows, ncols, figsize=(15, int(nrows*2.5)))\n    cnt = len(df[df['landmark_id']==id])\n    print(f'Landmark ID = {id}')\n    for i in range(nrows):\n        for j in range(ncols):\n            img = plt.imread(df[df['landmark_id']==id].path.iloc[random.randint(0, cnt - 1)])\n            axes[i, j].imshow(img)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i = random.randint(0, len(train_df)-1)\ndisplay_images_per_id(train_df, id=train_df.landmark_id[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i = random.randint(0, len(train_df)-1)\ndisplay_images_per_id(train_df, id=train_df.landmark_id[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i = random.randint(0, len(train_df)-1)\ndisplay_images_per_id(train_df, id=train_df.landmark_id[i])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}