{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-12T17:50:14.188925Z","iopub.execute_input":"2021-12-12T17:50:14.189283Z","iopub.status.idle":"2021-12-12T17:50:14.217775Z","shell.execute_reply.started":"2021-12-12T17:50:14.189191Z","shell.execute_reply":"2021-12-12T17:50:14.216812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\ntf.__version__\nimport keras\nkeras.__version__\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport os\nfrom sklearn.model_selection import train_test_split\nimport pickle\nfrom PIL import Image\n\n#from keras.models import Sequential\n#from keras.layers import Dense,Conv2D,Flatten\n#from keras.layers import MaxPooling2D\n#from keras.layers import Dropout\n#from keras.preprocessing.image import ImageDataGenerator\n#from keras.callbacks import ReduceLROnPlateau\n#from keras.constraints import UnitNorm\n#from keras import regularizers\n#from keras.layers import UpSampling2D\n#from keras.layers import UpSampling3D\n#from keras.layers import Conv2DTranspose\n","metadata":{"execution":{"iopub.status.busy":"2021-12-12T17:50:14.219403Z","iopub.execute_input":"2021-12-12T17:50:14.220067Z","iopub.status.idle":"2021-12-12T17:50:21.510028Z","shell.execute_reply.started":"2021-12-12T17:50:14.220011Z","shell.execute_reply":"2021-12-12T17:50:21.509089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#\"../input\"\nmother_directory = os.getcwd()\nos.listdir(mother_directory)\nprint(mother_directory)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T17:50:33.272159Z","iopub.execute_input":"2021-12-12T17:50:33.272905Z","iopub.status.idle":"2021-12-12T17:50:33.278928Z","shell.execute_reply.started":"2021-12-12T17:50:33.272861Z","shell.execute_reply":"2021-12-12T17:50:33.277961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.models.load_model(\"../input/models/neuron_creator_unet.hdf5\")","metadata":{"execution":{"iopub.status.busy":"2021-12-12T17:50:55.628366Z","iopub.execute_input":"2021-12-12T17:50:55.628891Z","iopub.status.idle":"2021-12-12T17:50:57.791687Z","shell.execute_reply.started":"2021-12-12T17:50:55.628854Z","shell.execute_reply":"2021-12-12T17:50:57.790822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"liste_dir = os.listdir(\"../input/sartorius-cell-instance-segmentation/test\")","metadata":{"execution":{"iopub.status.busy":"2021-12-12T17:50:59.573697Z","iopub.execute_input":"2021-12-12T17:50:59.573977Z","iopub.status.idle":"2021-12-12T17:50:59.584541Z","shell.execute_reply.started":"2021-12-12T17:50:59.573949Z","shell.execute_reply":"2021-12-12T17:50:59.583406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def disect_image(image):\n    disect_liste = [] \n    disect_liste.append(image[0:256,0:256,1])\n    disect_liste.append(image[0:256,256:512,1])\n    disect_liste.append(image[0:256,(512-64):704,1])\n    \n    disect_liste.append(image[256:512,0:256,1])\n    disect_liste.append(image[256:512,256:512,1])\n    disect_liste.append(image[256:512,(512-64):704,1])\n    \n    return disect_liste\n\n\ndef reconcile_image(y_pred):\n    liste = list(y_pred)\n    ara = np.concatenate((liste[0],liste[1]),axis=1)\n    ara = np.concatenate((ara,liste[2][:,64:]),axis=1)\n    ara2 = np.concatenate((liste[3],liste[4]),axis=1)\n    ara2 = np.concatenate((ara2,liste[5][:,64:]),axis=1)\n    fin = np.concatenate((ara,ara2),axis=0)\n    return fin\n","metadata":{"execution":{"iopub.status.busy":"2021-12-12T17:51:01.295788Z","iopub.execute_input":"2021-12-12T17:51:01.296063Z","iopub.status.idle":"2021-12-12T17:51:01.307092Z","shell.execute_reply.started":"2021-12-12T17:51:01.296034Z","shell.execute_reply":"2021-12-12T17:51:01.306007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def RLD(s):\n    s=s.split(\" \")\n    ans=[]\n    i=0\n    while i<len(s):\n        j=0\n        n=int(s[i])\n        while j<int(s[i+1]):\n            ans.append(int(n))\n            n=n+1\n            j=j+1\n        i=i+2\n    return ans\n\n\ndef mask_placer(annot,current_image_flattened,RGB = \"yes\"):\n    Annot = RLD(annot)\n    if RGB == \"yes\":\n        seed = (np.random.randint(0,255),np.random.randint(0,255),np.random.randint(0,255))\n        for i in Annot:\n            current_image_flattened[i,0] = seed[0]\n            current_image_flattened[i,1] = seed[1]\n            current_image_flattened[i,2] = seed[2]\n        \n      \n        \n        \n        \n        current_image = current_image_flattened.reshape(520,704,3)\n        return current_image\n\n    else:\n        for i in Annot:\n            if i<520*704:\n                current_image_flattened[i,0] = 255\n                current_image_flattened[i,1] = 255\n                current_image_flattened[i,2] = 255\n        current_image = current_image_flattened.reshape(520,704,3)\n        return current_image","metadata":{"execution":{"iopub.status.busy":"2021-12-12T17:51:03.638648Z","iopub.execute_input":"2021-12-12T17:51:03.639505Z","iopub.status.idle":"2021-12-12T17:51:03.651302Z","shell.execute_reply.started":"2021-12-12T17:51:03.639465Z","shell.execute_reply":"2021-12-12T17:51:03.650402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n#Creating_neuron means starting a neuron word on dictionary.\ndef create_neuron():\n    name_neuron = \"Neuron_\"+str(len(Neuron_ledger.keys()))\n    Neuron_ledger[name_neuron] = [[],[]]\n\ndef enter_pixel_coord(coordinate,neuron_name):\n    Neuron_ledger[neuron_name][0].append(coordinate)\n    \ndef clear_last_ad(neuron_name):\n    Neuron_ledger[neuron_name][1] = []\n\ndef last_ad_check(neuron_name):\n    if Neuron_ledger[neuron_name][1] == (0,0):\n        return False\n    else:\n        return True\n    \ndef update_neuron(coordinate_liste,neuron_name,clear_past = \"no\"):\n    if clear_past == \"yes\":\n        clear_last_ad(neuron_name)\n    #for i in range(len(coordinate_liste)):\n        #enter_pixel_coord(coordinate_liste[i],neuron_name)\n    Neuron_ledger[neuron_name][0].append(coordinate_liste)\n\n    Neuron_ledger[neuron_name][1].append(coordinate_liste)\n    \n\n    \n#Slicing oject will be 1 X 704 numpy object\n\ndef get_slice(image,row_number):\n    sliced = image[row_number,:]\n    row_number = row_number\n    return sliced,row_number\n\ndef bright_coordinate_calc(sliced):\n    locater = np.arange(1,705)\n    located_coord_array = locater * sliced.T\n    return located_coord_array.T\n\ndef get_lumps(located_coord_array):\n    liste_lumps = []\n    start = 0\n    end = 0\n    liste_sample = []\n    for i in list(located_coord_array):\n        if i == 0 and start == 0:\n            continue\n        elif i > 0 and len(liste_sample) == 0 :\n            liste_sample.append(i)\n            start = i\n        \n        elif i > 0 and len(liste_sample) > 0:\n            liste_sample.append(i)\n            \n        elif i == 0 and start > 0:\n            end = liste_sample[-1]\n            liste_lumps.append((start,end))\n            start = 0\n            end = 0\n            liste_sample = []\n            \n    return liste_lumps\n#This function gives us the most probable neuron that it would be a part of.\ndef lump_comparer(new_lump):\n    differences_list = []\n    for i in Neuron_ledger.keys():\n        new_lump_mean = (new_lump[0] + new_lump[1])/2\n        new_lump_size = new_lump[-1] - new_lump[0]\n        last_ad = (Neuron_ledger[i][1][0][0][1],Neuron_ledger[i][1][0][1][1])\n        last_ad_mean = (last_ad[0]+last_ad[1])/2\n        last_ad_size = last_ad[-1] - last_ad[0]\n        diff = abs(last_ad_mean - new_lump_mean)\n        differences_list.append(diff)\n    \n    minimum_diff = min(differences_list)\n    if minimum_diff < 30:\n        neuron_index = differences_list.index(minimum_diff)\n        neuron_continum = list(Neuron_ledger.keys())[neuron_index]\n    else:\n        neuron_continum  = \"new_neuron\"\n        \n    return neuron_continum\n        \ndef whole_lump_neuron_match(liste_lumps):\n    for lump in liste_lumps:\n        neuron_continum = lump_comparer(lump)\n        if neuron_continum == \"new_neuron\":\n            create_neuron()\n            coordinate_liste = list((lump[0],lump[1]))\n            for k in range(len(coordinate_liste)):\n                coordinate_liste[k] = (row_number,float(coordinate_liste[k]))\n            update_neuron(coordinate_liste,list(Neuron_ledger.keys())[-1],clear_past=\"yes\")\n            \n        else:\n            coordinate_liste = list((lump[0],lump[1]))\n            for k in range(len(coordinate_liste)):\n                coordinate_liste[k] = (row_number,float(coordinate_liste[k]))\n            update_neuron(coordinate_liste,neuron_continum,clear_past=\"yes\")\n            \n            \ndef neuron_finished_matches(row_number):\n    for i in Neuron_ledger.keys():\n        last_ad = (Neuron_ledger[i][1][0][0][0],Neuron_ledger[i][1][0][1][0])\n        if last_ad[0] < row_number:\n            Neuron_ledger[i][1][0] = [(0,0),(0,0)]\n                    \n        \n            \n\ndef lump_ledger_link(liste_lumps,row_number):\n    if len(Neuron_ledger.keys()) == 0:\n        for i in range(len(liste_lumps)):\n            create_neuron()\n            #coordinate_liste = list(np.arange(liste_lumps[i][0],liste_lumps[i][1]+1))\n            coordinate_liste = list((liste_lumps[i][0],liste_lumps[i][1]))\n            for k in range(len(coordinate_liste)):\n                coordinate_liste[k] = (row_number,float(coordinate_liste[k]))\n\n           \n            update_neuron(coordinate_liste,list(Neuron_ledger.keys())[-1],clear_past=\"yes\")\n            \n    elif len(Neuron_ledger.keys()) > 0:\n        \n        whole_lump_neuron_match(liste_lumps)\n        \n        \ndef find_edges(Neuron_name):\n    liste = Neuron_ledger[Neuron_name][0]\n    fark = 0\n    which_fark = 0\n    counter = 0\n    for i in liste:\n        if i[1][1] - i[0][1] > fark:\n            fark = i[1][1] - i[0][1]\n            which_fark = counter\n        \n        counter += 1\n    return fark,len(liste),which_fark,liste\n\ndef vision_applier(sample):\n    modified_im = sample.copy()\n    for i in Neuron_ledger.keys():\n        fark,length_liste,which_fark,liste = find_edges(i)\n        modified_im[int(liste[0][0][0]):int(liste[-1][0][0]),int(liste[which_fark][0][1])] = 1\n        modified_im[int(liste[0][0][0]):int(liste[-1][0][0]),int(liste[which_fark][1][1])] = 1\n\n        modified_im[int(liste[0][0][0]),int(liste[which_fark][0][1]):int(liste[which_fark][1][1])] = 1\n        modified_im[int(liste[-1][0][0]),int(liste[which_fark][0][1]):int(liste[which_fark][1][1])] = 1\n    return modified_im\n\ndef encoding_pixels(pixel_list):\n    coding = \"\"\n    begin = pixel_list[0]\n    counter = 0\n    current = begin\n    for pixel in pixel_list:\n        \n        if pixel == pixel_list[0]:\n            counter += 1\n            continue\n        elif current+1 == pixel:\n            current = pixel\n            counter += 1\n            \n        elif current +1 != pixel:\n            coding =  coding + str(begin) + \" \" + str(counter) + \" \"\n            begin = pixel\n            counter = 1\n            current = begin\n            \n     \n\n    code = coding[:len(coding)-1]\n            \n    return code\n\ndef encoding_pixels(pixel_list):\n    if len(pixel_list) < 10:\n        return 0\n    else:\n        coding = \"\"\n        begin = pixel_list[0]\n        counter = 0\n        current = begin\n        for pixel in pixel_list:\n\n            if pixel == pixel_list[0]:\n                counter += 1\n                continue\n            elif current+1 == pixel:\n                current = pixel\n                counter += 1\n\n            elif current +1 != pixel:\n                coding =  coding + str(begin) + \" \" + str(counter) + \" \"\n                begin = pixel\n                counter = 1\n                current = begin\n\n\n\n        code = coding[:len(coding)-1]\n\n        return code'''\n            \n        \n     #last   \ndef encoding_pixels(pixel_list):\n    if True:\n        coding = \"\"\n        begin = pixel_list[0]\n        counter = 0\n        current = begin\n        for pixel in pixel_list:\n\n            if pixel == pixel_list[0]:\n                counter += 1\n                continue\n            elif current+1 == pixel:\n                current = pixel\n                counter += 1\n\n            elif current +1 != pixel:\n                coding =  coding + str(begin) + \" \" + str(counter) + \" \"\n                begin = pixel\n                counter = 1\n                current = begin\n\n\n\n        code = coding[:len(coding)-1]\n\n        return code\n            \n\n","metadata":{"execution":{"iopub.status.busy":"2021-12-12T17:51:10.087458Z","iopub.execute_input":"2021-12-12T17:51:10.087782Z","iopub.status.idle":"2021-12-12T17:51:10.102832Z","shell.execute_reply.started":"2021-12-12T17:51:10.087743Z","shell.execute_reply":"2021-12-12T17:51:10.101824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''def encoding(i,max_line):\n    first_coord = (i[2])*max_line + i[0]\n    second_coord = (i[2])*max_line + i[1]\n        \n    final =str(int(first_coord))+ \" \" +  str(int(second_coord-first_coord+1))\n    return final\n\ndef encoding(i,max_line):\n        first_coord = (i[0][0])*max_line + i[0][1]\n        second_coord = (i[1][0])*max_line + i[1][1]\n        \n        final =str(int(first_coord))+ \" \" +  str(int(second_coord-first_coord+1))\n        return final'''","metadata":{"execution":{"iopub.status.busy":"2021-12-07T17:18:39.145962Z","iopub.execute_input":"2021-12-07T17:18:39.146276Z","iopub.status.idle":"2021-12-07T17:18:39.151815Z","shell.execute_reply.started":"2021-12-07T17:18:39.14624Z","shell.execute_reply":"2021-12-07T17:18:39.151202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''#Bedir code\nsubmission = pd.DataFrame(columns = [\"id\",\"predicted\"])\ncounter = 0\nfor im in liste_dir:\n    image = cv2.imread(\"../input/sartorius-cell-instance-segmentation/test/\"+im)\n    \n    barsak = disect_image(image)\n    test = np.array(barsak).reshape(6,256,256,1)\n    y_pred = model.predict(test)\n    fin = reconcile_image(y_pred)\n    #plt.imshow(fin)\n    fin.shape\n    \n    sample = fin.copy()\n    flattened = sample.flatten()\n\n    for i in range(len(flattened)):\n        if flattened[i] > 0.5:\n            flattened[i] = 1.0\n        else:\n            flattened[i] = 0.0\n    sample = flattened.reshape(512,704,1)\n    \n    #plt.imshow(sample)\n    \n    \n    #Neuron_structure = [[],[]]\n    Neuron_ledger = {}\n\n    for i in range(0,512):\n        sliced,row_number = get_slice(sample,i)\n        located_coord_array = bright_coordinate_calc(sliced)\n        liste_lumps = get_lumps(located_coord_array)\n        lump_ledger_link(liste_lumps,row_number)\n        neuron_finished_matches(row_number)\n        \n    #result = vision_applier(sample)\n    \n    #plt.imshow(result)\n    \n    liste = []\n    for name in Neuron_ledger.keys():\n\n        altogether = \"\"\n        counter = 0\n        for i in Neuron_ledger[name][0]:\n            if counter == 0:\n                altogether = encoding(i,704)\n                counter += 1\n            else:\n                coord = encoding(i,704)\n                altogether = altogether + \" \" + coord\n\n        if len(altogether) > 10:\n            liste.append(altogether)\n            \n    name = []\n    for i in range(len(liste)):\n        name.append(im[:-4]) \n            \n    #print(len(liste))\n    if counter == 0:\n        submission[\"id\"] = name\n        submission[\"predicted\"] = liste\n        counter += 1\n    else:\n        new = pd.DataFrame(columns = [\"id\",\"predicted\"])\n        new[\"id\"] = name\n        new[\"predicted\"] = liste\n        submission = pd.concat([submission,new],axis=0)\n        '''","metadata":{"execution":{"iopub.status.busy":"2021-12-07T17:18:46.994798Z","iopub.execute_input":"2021-12-07T17:18:46.995267Z","iopub.status.idle":"2021-12-07T17:19:01.320416Z","shell.execute_reply.started":"2021-12-07T17:18:46.995211Z","shell.execute_reply":"2021-12-07T17:19:01.319565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame(columns = [\"id\",\"predicted\"])\ncounter = 0\n\nfor im in liste_dir:\n    image = cv2.imread(\"../input/sartorius-cell-instance-segmentation/test/\"+im)\n    \n    barsak = disect_image(image)\n    test = np.array(barsak).reshape(6,256,256,1)\n    y_pred = model.predict(test)\n    fin = reconcile_image(y_pred)\n    #plt.imshow(fin)\n    #fin.shape\n    \n    sample = fin.copy()\n    flattened = sample.flatten()\n\n    flattened = flattened*255\n    for i in range(len(flattened)):\n        if flattened[i] > 50:\n            flattened[i] = 255\n        else:\n            flattened[i] = 0\n    sample = flattened.reshape(512,704,1)\n    \n    #plt.imshow(sample)\n    \n    \n    ret1,tresh = cv2.threshold(sample,0,255,cv2.THRESH_BINARY)\n    kernel = np.ones((3,3),np.uint8)\n    opening = cv2.morphologyEx(tresh,cv2.MORPH_OPEN,kernel,iterations=2)\n    sure_bg = cv2.dilate(opening,kernel,iterations=10)\n    #plt.imshow(sure_bg)\n    opening = opening.astype(np.uint8())\n    dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,5)\n    #plt.imshow(dist_transform)\n    ret2,sure_fg = cv2.threshold(dist_transform,0.25*dist_transform.max(),255,0)\n    #plt.imshow(sure_fg)\n    \n    sure_fg = np.uint8(sure_fg)\n    sure_bg = np.uint8(sure_bg)\n    unknown = cv2.subtract(sure_bg,sure_fg)\n    ret3,markers = cv2.connectedComponents(sure_fg)\n    #plt.imshow(markers,cmap=\"jet\")\n    markers = markers+10\n    markers[unknown==255] = 0\n    #plt.imshow(markers,cmap=\"gray\")\n    sample1 = np.concatenate((sample,sample),axis=2)\n    sample1 = np.concatenate((sample1,sample),axis=2)\n    sample1.shape\n    sample1 = np.uint8(sample1)\n    markers = cv2.watershed(sample1,markers)\n    #plt.imshow(markers)\n    \n    labels = markers.flatten()\n    dicti = {}\n    for label in labels:\n        if (str(label) not in dicti.keys()) and (label != -1) and (label != 10):\n            dicti[str(label)] = []\n            \n    \n    for i in range(len(labels)):\n        if labels[i] != -1 and labels[i] != 10 :\n            dicti[str(labels[i])].append(i)\n        \n    '''picti = np.zeros((512*704))\n    counter = 0\n    for k in dicti.keys():\n        if len(dicti[k]) > 10:\n            hedef = dicti[k]\n            for i in hedef:\n                if picti[i] != 0:\n                    print(\"occupied\")\n                else:\n                    picti[i] = 1\n                    counter += 1\n    \n    #plt.imshow(picti.reshape(512,704))'''\n                \n                    \n\n    \n    liste = []\n    for name in dicti.keys():\n        if len(dicti[name]) > 10:\n            code = encoding_pixels(dicti[name])\n            liste.append(code)\n             \n    \n    \n    name = []\n    for i in range(len(liste)):\n        name.append(im[:-4]) \n        \n        \n    \n    print(len(liste))\n    if counter == 0:\n        submission[\"id\"] = name\n        submission[\"predicted\"] = liste\n        counter += 1\n    else:\n        new = pd.DataFrame(columns = [\"id\",\"predicted\"])\n        new[\"id\"] = name\n        new[\"predicted\"] = liste\n        submission = pd.concat([submission,new],axis=0)\n\n        \n        \n\n    \n        ","metadata":{"execution":{"iopub.status.busy":"2021-12-12T17:55:24.13126Z","iopub.execute_input":"2021-12-12T17:55:24.132179Z","iopub.status.idle":"2021-12-12T17:55:43.900921Z","shell.execute_reply.started":"2021-12-12T17:55:24.132127Z","shell.execute_reply":"2021-12-12T17:55:43.899774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.info()","metadata":{"execution":{"iopub.status.busy":"2021-12-12T17:56:04.523713Z","iopub.execute_input":"2021-12-12T17:56:04.52439Z","iopub.status.idle":"2021-12-12T17:56:04.541514Z","shell.execute_reply.started":"2021-12-12T17:56:04.524352Z","shell.execute_reply":"2021-12-12T17:56:04.540504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-12T17:56:07.844263Z","iopub.execute_input":"2021-12-12T17:56:07.844635Z","iopub.status.idle":"2021-12-12T17:56:07.864636Z","shell.execute_reply.started":"2021-12-12T17:56:07.844597Z","shell.execute_reply":"2021-12-12T17:56:07.863404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"execution":{"iopub.status.busy":"2021-12-12T17:56:11.439421Z","iopub.execute_input":"2021-12-12T17:56:11.440364Z","iopub.status.idle":"2021-12-12T17:56:11.45313Z","shell.execute_reply.started":"2021-12-12T17:56:11.440305Z","shell.execute_reply":"2021-12-12T17:56:11.452412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"submission.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T17:56:17.03408Z","iopub.execute_input":"2021-12-12T17:56:17.034996Z","iopub.status.idle":"2021-12-12T17:56:17.047278Z","shell.execute_reply.started":"2021-12-12T17:56:17.034955Z","shell.execute_reply":"2021-12-12T17:56:17.046262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}