{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Instance_Segmentation_Pytorch (Inference)","metadata":{}},{"cell_type":"markdown","source":"<a class=\"anchor\" id=\"0\"></a>\n# Table of Contents\n\n1. [套件安裝與載入](#1)\n1. [環境檢測與設定](#2)\n1. [開發參數設定](#3)\n1. [資料處理](#4)\n    -  [載入CSV檔](#4.1)\n1. [定義模型方法](#5)\n1. [製作資料集＆資料擴增＆推論模型](#6)\n1. [待辦事項](#7)","metadata":{}},{"cell_type":"markdown","source":"# 1. 套件安裝與載入<a class=\"anchor\" id=\"1\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"# 資料處理套件\nimport os\nimport gc\nimport cv2\nimport time\nimport random\nimport collections\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom tqdm.notebook import tqdm\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 設定顯示中文字體\nfrom matplotlib.font_manager import FontProperties\nplt.rcParams['font.sans-serif'] = ['Microsoft JhengHei'] # 用來正常顯示中文標籤\nplt.rcParams['font.family'] = 'AR PL UMing CN'\nplt.rcParams['axes.unicode_minus'] = False # 用來正常顯示負號","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pytorch深度學習模組套件\nimport torch\nimport torchvision\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.transforms import functional as F\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\nfrom torchvision.models.detection.mask_rcnn import MaskRCNNPredictor","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. 環境檢測與設定<a class=\"anchor\" id=\"2\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nDEVICE","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 查看pytorch版本\nprint(torch.__version__)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''執行環境參數設定'''\n\n# (Boolean)是否為本機\nLOCAL = False\n\n# (Boolean)是否為 Colab\nCOLAB = False\n\n\n'''檔案路徑參數設定'''\n\n# (String)Root路徑\nif LOCAL:\n    PATH = r'../'\nelif COLAB:\n    PATH = r'/content/drive/My Drive/Colab Notebooks/'\nelse:\n    PATH = r'../input/'\n    \n# (String)資料根路徑\nDATA_ROOT_PATH = PATH+r'sartorius-cell-instance-segmentation/' \n\n# (String)CSV根路徑\nCSV_ROOT_PATH = PATH+r'sartorius-cell-instance-segmentation/'\n\n# (String)測試資料路徑\nTEST_DATA_PATH = DATA_ROOT_PATH+r'test/'\n\n# (String)測試CSV路徑\nTEST_CSV_PATH = CSV_ROOT_PATH+r'sample_submission.csv'\n\n# (Boolean)是否要匯入Library\nIMPORT_PYTORCH_LIBRARY = False\n\n# (String)Library的路徑\nPYTORCH_LIBRARY_PATH = PATH + \"Util/\"\n\n# (String)讀取預訓練模型/權重的名稱，當fold model時，後面會自動加_NUMBER\nLOAD_MODEL_NAME = ['maskrcnn_resnet50_fpn']\n\n# (String)讀取預訓練模型/權重的儲存路徑\nLOAD_MODEL_PATH = [PATH + r'test1/']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. 開發參數設定<a class=\"anchor\" id=\"3\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"# Override pythorch checkpoint with an \"offline\" version of the file\n!mkdir -p /root/.cache/torch/hub/checkpoints/\n!cp ../input/pytorch-pretrained-models/resnet50-19c8e357.pth /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''客製參數設定'''\n\n\n'''資料參數設定'''\n\n# (Dict)標籤字典\nLABEL_DICT = {\"astro\": 1, \"cort\": 2, \"shsy5y\": 3}\n\n# (Int)集成模型數量\nENSEMBLE_MODEL_COUNT = 1\n\n# (Int List)有CSV檔該參數才有用，1則為不做交叉驗證\nFOLD = [1]*ENSEMBLE_MODEL_COUNT\n\n# (Int)圖片尺寸寬\nIMAGE_SIZE_W = [704]*ENSEMBLE_MODEL_COUNT\n\n# (Int)圖片尺寸高\nIMAGE_SIZE_H = [520]*ENSEMBLE_MODEL_COUNT\n\n# (String)CSV圖片檔名欄位\nIMAGE_NAME = \"id\"\n\n# (String)CSV標注預測欄位\nANNOTATION_NAME = \"predicted\"\n\n# (Boolean)CSV圖片檔名欄位是否包含副檔名\nIMAGE_NAME_HAVE_EXTENSION = False\n\n# (String)圖片副檔名\nIMAGE_NAME_EXTENSION = '.png'\n\n# (Flag)圖像讀取的格式\nIMREAD_FLAGS = cv2.IMREAD_COLOR\n\n#  (Boolean)圖像是否要轉換\nCOLOR_CONVERT = False\nif COLOR_CONVERT:\n    #  (Boolean)圖像轉換通道\n    COLOR_CONVERT_CHANNEL = cv2.COLOR_BGR2RGB\n\n# (Int)不同的種子會產生不同的Random或分層K-FOLD分裂, 42則是預設固定種子\nSEED = 42\n\n# (Boolean)如為True每次返回的卷積算法將是確定的，即默認算法\nCUDNN_DETERMINISTIC = True\n\n# (Boolean)PyTorch 中對模型裡的卷積層進行預先的優化，也就是在每一個卷積層中測試 cuDNN 提供的所有卷積實現算法，\n# 然後選擇最快的那個。這樣在模型啟動的時候，只要額外多花一點點預處理時間，就可以較大幅度地減少訓練時間\nCUDNN_BENCHMARK = True\n\n\n'''資料擴增參數設定'''\n\n# (Boolean)是否圖形歸一化\nIS_NORMALIZE = False\n\n# (Tuple Float)正規化的平均值((0,1)的參考平均值:(0.485, 0.456, 0.406), (-1,1)的參考平均值:(0.5, 0.5, 0.5)\nNORMALIZE_MEAN = (0.485, 0.456, 0.406)\n\n# (Tuple Float)正規化的標準差((0,1)的參考標準差(0.229, 0.224, 0.225), (-1,1)的參考標準差(0.5, 0.5, 0.5)\nNORMALIZE_STD = (0.229, 0.224, 0.225)\n\n# (Float)水平翻轉的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_HORIZONTALFLIP = 0.5\n\n# (Float)垂直翻轉的啟用(0:不啟用,1.0:一律啟用,小數點:機率啟用)\nP_VERTICALFLIP = 0.5\n\n\n''''模型參數設定'''\n\n# (String List)模型載入方式 - 1 MODEL;2 WEIGHT_OF_CUSTOM_MODEL;\n# 3 WEIGHT_OF_BASE_MODEL\nMODEL_LIST = [3] * ENSEMBLE_MODEL_COUNT\n\nif 2 in MODEL_LIST:\n    # (Model List)模型載入方式有CUSTOM_MODEL，依照index位置填入\n    CUSTOM_MODEL = [None] * ENSEMBLE_MODEL_COUNT\n\nif 3 in MODEL_LIST:\n    # (Model List)模型載入方式有BASE_MODEL，依照index位置填入\n    BASE_MODEL = [torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained = False, box_detections_per_img = 540)] * ENSEMBLE_MODEL_COUNT\n\n    # (Int)模型隱藏層\n    HIDDEN_LAYER = 256\n\n    # (String)模型Box預測\n    MODEL_BOX_PREDICTOR = FastRCNNPredictor\n\n    # (String)模型Mask預測\n    MODEL_MASK_PREDICTOR = MaskRCNNPredictor\n\n# (Boolean)是否印出完整模型\nMODEL_PRINT = False\n\n\n''''推論參數設定'''\n\n# (Int List)每批推論的尺寸\nBATCH_SIZE = [2]*ENSEMBLE_MODEL_COUNT\n\n# (Int)指定列印進度條的位置（從0開始）\nTQDM_POSITION = 0\n\n# (Boolean)保留迭代結束時進度條的所有痕跡。如果是None，只會在position是0時離開\nTQDM_LEAVE = True\n\n\n''''評價指標參數設定'''\n\n# (Float dist)標籤分類的最小允許分數，否則不評價\nMIN_SCORE_DICT = {1: 0.55, 2: 0.75, 3: 0.5}\n\n# (Float dist)Mask的最小允許閾值，否則不評價\nMASK_THRESHOLD_DICT = {1: 0.55, 2: 0.75, 3:  0.6}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = CUDNN_DETERMINISTIC\n    torch.backends.cudnn.benchmark = CUDNN_BENCHMARK\n\nseed_everything(SEED)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. 資料處理<a class=\"anchor\" id=\"4\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"markdown","source":"## 4.1 載入CSV檔 <a class=\"anchor\" id=\"4.1\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"print('Reading data...')\n\n# 讀取訓練資料集CSV檔\nif os.path.isfile(TEST_CSV_PATH):\n    test_csv = pd.read_csv(TEST_CSV_PATH,encoding=\"utf8\")\nelse:\n    test_data_directory_list = os.listdir(TEST_CSV_PATH)\n    test_csv = pd.DataFrame(test_data_directory_list, columns=[IMAGE_NAME])\n    del test_data_directory_list\n    gc.collect()\n\nprint('Reading data completed')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 顯示測試資料集CSV檔\ntest_csv.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Shape of train_data :\", test_csv.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. 定義模型方法<a class=\"anchor\" id=\"5\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"def build_model(count, model_path):\n    if MODEL_LIST[count] == 1:\n        # 載入預訓練模型\n        model = torch.load(model_path)\n    else:\n        if MODEL_LIST[count] == 2:\n            # 載入模型架構\n            model = CUSTOM_MODEL[count]\n        elif MODEL_LIST[count] == 3:\n            model = BASE_MODEL[count]\n\n            # get the number of input features for the classifier\n            in_features = model.roi_heads.box_predictor.cls_score.in_features\n            # replace the pre-trained head with a new one\n            model.roi_heads.box_predictor = MODEL_BOX_PREDICTOR(in_features, len(LABEL_DICT)+1)\n\n            # now get the number of input features for the mask classifier\n            in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n            # and replace the mask predictor with a new one\n            model.roi_heads.mask_predictor = MODEL_MASK_PREDICTOR(in_features_mask, HIDDEN_LAYER, len(LABEL_DICT)+1)\n        \n    if MODEL_LIST[count] != 1:\n        # 載入預訓練權重\n        model.load_state_dict(torch.load(model_path))\n        \n    for param in model.parameters():\n        param.requires_grad = False\n        \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. 製作資料集＆資料擴增＆推論模型<a class=\"anchor\" id=\"6\"></a>\n[Back to Table of Contents](#0)","metadata":{}},{"cell_type":"code","source":"def rle_encoding(x: np.ndarray):\n    dots = np.where(x.flatten() == 1)[0]\n    run_lengths = []\n    prev = -2\n    for b in dots:\n        if (b>prev+1): run_lengths.extend((b + 1, 0))\n        run_lengths[-1] += 1\n        prev = b\n    return ' '.join(map(str, run_lengths))\n\n\ndef remove_overlapping_pixels(mask, other_masks):\n    for other_mask in other_masks:\n        if np.sum(np.logical_and(mask, other_mask)) > 0:\n            mask[np.logical_and(mask, other_mask)] = 0\n    return mask","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self, transforms = None):\n        self.transforms = transforms\n        self.image_ids = [f[:-4]for f in os.listdir(TEST_DATA_PATH)]\n            \n    def __len__(self):\n        return len(self.image_ids)\n            \n    def __getitem__(self, index):\n        image_id = self.image_ids[index]\n        image_path = os.path.join(TEST_DATA_PATH, image_id + IMAGE_NAME_EXTENSION)\n        image = cv2.imread(image_path, IMREAD_FLAGS)\n        image = cv2.resize(image, (IMAGE_SIZE_W[0], IMAGE_SIZE_H[0]))\n        \n        if COLOR_CONVERT:\n            image = cv2.cvtColor(image, COLOR_CONVERT_CHANNEL)\n\n        if self.transforms:\n            image, _ = self.transforms(image = image, target = None)\n            \n        return {'image': image, 'image_id': image_id}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# These are slight redefinitions of torch.transformation classes\n# The difference is that they handle the target and the mask\n# Copied from Abishek, added new ones\nclass Compose:\n    def __init__(self, transforms):\n        self.transforms = transforms\n\n    def __call__(self, image, target):\n        for t in self.transforms:\n            image, target = t(image, target)\n        return image, target\n\nclass VerticalFlip:\n    def __init__(self, prob):\n        self.prob = prob\n\n    def __call__(self, image, target):\n        if random.random() < self.prob:\n            height, width = image.shape[-2:]\n            image = image.flip(-2)\n            bbox = target[\"boxes\"]\n            bbox[:, [1, 3]] = height - bbox[:, [3, 1]]\n            target[\"boxes\"] = bbox\n            target[\"masks\"] = target[\"masks\"].flip(-2)\n        return image, target\n\nclass HorizontalFlip:\n    def __init__(self, prob):\n        self.prob = prob\n\n    def __call__(self, image, target):\n        if random.random() < self.prob:\n            height, width = image.shape[-2:]\n            image = image.flip(-1)\n            bbox = target[\"boxes\"]\n            bbox[:, [0, 2]] = width - bbox[:, [2, 0]]\n            target[\"boxes\"] = bbox\n            target[\"masks\"] = target[\"masks\"].flip(-1)\n        return image, target\n\nclass Normalize:\n    def __call__(self, image, target):\n        image = F.normalize(image, NORMALIZE_MEAN, NORMALIZE_STD)\n        return image, target\n\nclass ToTensor:\n    def __call__(self, image, target):\n        image = F.to_tensor(image)\n        return image, target\n\ndef get_transforms():\n    transforms = [ToTensor()]\n    if IS_NORMALIZE:\n        transforms.append(Normalize())\n\n    return Compose(transforms)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inference_one_epoch(model, test_dataloader, \n                        min_score_dict: dict={1: 0.55, 2: 0.75, 3: 0.5}, \n                        mask_threshold_dict: dict={1: 0.55, 2: 0.75, 3:  0.6}):\n    model.eval()\n    pbar = tqdm(enumerate(test_dataloader), total=len(test_dataloader), \n                position = TQDM_POSITION, leave = TQDM_LEAVE)\n    for batch_idx, (sample) in pbar:\n        image = sample['image']\n        image_id = sample['image_id']\n        with torch.no_grad():\n            result = model([image.to(DEVICE)])[0]\n\n        previous_masks = []\n        for i, mask in enumerate(result[\"masks\"]):\n\n            # Filter-out low-scoring results.\n            score = result[\"scores\"][i].cpu().item()\n            label = result[\"labels\"][i].cpu().item()\n            if score > min_score_dict[label]:\n                mask = mask.cpu().numpy()\n                # Keep only highly likely pixels\n                binary_mask = mask > mask_threshold_dict[label]\n                binary_mask = remove_overlapping_pixels(binary_mask, previous_masks)\n                previous_masks.append(binary_mask)\n                rle = rle_encoding(binary_mask)\n                submission.append((image_id, rle))\n                \n        # Add empty prediction if no RLE was generated for this image\n        all_images_ids = [image_id for image_id, rle in submission]\n        if image_id not in all_images_ids:\n            submission.append((image_id, \"\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inference_process(count, fold, kf, submission):\n    if kf:\n        print('Model %i : Fold %i - image size W:%i H:%i with %s and batch size %i'%(count+1, fold, IMAGE_SIZE_W[count], IMAGE_SIZE_H[count], LOAD_MODEL_NAME[count].upper(), BATCH_SIZE[count]))\n    else:\n        print('Model %i : Image size W:%i H:%i with %s and batch_size %i'%(count+1, IMAGE_SIZE_W[count], IMAGE_SIZE_H[count], LOAD_MODEL_NAME[count].upper(), BATCH_SIZE[count]))\n    \n    test_dataset = MyDataset(transforms = get_transforms())\n\n    if kf:\n        model_path = LOAD_MODEL_PATH[count] + LOAD_MODEL_NAME[count] + '_' + str(fold) + '.pth'\n    else:\n        model_path = LOAD_MODEL_PATH[count] + LOAD_MODEL_NAME[count] + '.pth'\n\n    model = build_model(count, model_path)\n    model = model.to(DEVICE)\n    \n    inference_one_epoch(model, test_dataset, MIN_SCORE_DICT, MASK_THRESHOLD_DICT)\n    \n    df_sub = pd.DataFrame(submission, columns=[IMAGE_NAME, ANNOTATION_NAME])\n    if kf:\n        df_sub.to_csv(\"submission_model\" + str(count+1) + \"_fold\" + str(fold) + \".csv\", index=False)\n    elif ENSEMBLE_MODEL_COUNT != 1 and not kf:\n        df_sub.to_csv(\"submission_model\" + str(count+1) + \".csv\", index=False)\n    else:\n        df_sub.to_csv(\"submission.csv\", index=False)\n    print(df_sub.head())\n    \n    del test_dataset, model\n    gc.collect()\n    torch.cuda.empty_cache()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = []","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def main():\n    try:\n        print('Inference start')\n        since = time.time()\n        for count in range(len(LOAD_MODEL_NAME)):\n            if FOLD[count] > 1:\n                for fold in enumerate(np.arange(FOLD[count]), 1):\n                    inference_process(count, fold = fold, kf = True, submission = submission)\n            else:\n                inference_process(count, fold = 0, kf = False, submission = submission)\n        time_elapsed = time.time() - since\n        print('Inference complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n    except Exception as exception:\n        print(exception)\n        raise","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__ == '__main__':\n    main()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7. 待辦事項<a class=\"anchor\" id=\"7\"></a>\n[Back to Table of Contents](#0)","metadata":{}}]}