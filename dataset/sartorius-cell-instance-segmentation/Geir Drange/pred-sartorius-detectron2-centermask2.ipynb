{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"![logo](https://raw.githubusercontent.com/facebookresearch/detectron2/main/.github/Detectron2-Logo-Horz.svg)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-21T18:18:12.638445Z","iopub.execute_input":"2021-10-21T18:18:12.638793Z","iopub.status.idle":"2021-10-21T18:18:13.414615Z","shell.execute_reply.started":"2021-10-21T18:18:12.638705Z","shell.execute_reply":"2021-10-21T18:18:13.413634Z"}}},{"cell_type":"markdown","source":"# Inference\nThis is the final step in a series:  \n  * [Create COCO annotations for Sartorius dataset](https://www.kaggle.com/mistag/sartorius-create-coco-annotations)\n  * [Cell shape analysis](https://www.kaggle.com/mistag/sartorius-cell-shape-analysis)\n  * [Offline Detectron2 files](https://www.kaggle.com/mistag/detectron2-download-code-for-offline-install-ii)\n  * [Train CenterMask2 model](https://www.kaggle.com/mistag/train-sartorius-detectron2-centermask2)\n  * [Sartorius: TTA with Weighted Segments Fusion](https://www.kaggle.com/mistag/sartorius-tta-with-weighted-segments-fusion)\n  \nStart by installing Dectectron2:","metadata":{}},{"cell_type":"code","source":"!pip install --no-index \\\n../input/detectron2-download-code-for-offline-install-ii/detectron2/detectron2-0.6-cp37-cp37m-linux_x86_64.whl \\\n--find-links=../input/detectron2-download-code-for-offline-install-ii/detectron2","metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-11-25T16:05:00.048691Z","iopub.execute_input":"2021-11-25T16:05:00.049331Z","iopub.status.idle":"2021-11-25T16:05:09.341912Z","shell.execute_reply.started":"2021-11-25T16:05:00.049238Z","shell.execute_reply":"2021-11-25T16:05:09.341034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Then install Weighted Segments Boxes for Segments Fusion:","metadata":{}},{"cell_type":"code","source":"!cp /kaggle/input/sartorius-tta-with-weighted-segments-fusion/wbf_tracking.py .","metadata":{"execution":{"iopub.status.busy":"2021-11-25T16:05:09.349252Z","iopub.execute_input":"2021-11-25T16:05:09.34977Z","iopub.status.idle":"2021-11-25T16:05:10.022028Z","shell.execute_reply.started":"2021-11-25T16:05:09.349738Z","shell.execute_reply":"2021-11-25T16:05:10.021066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Copy CenterMask2 from [training notebook](https://www.kaggle.com/mistag/train-sartorius-detectron2-centermask2):","metadata":{}},{"cell_type":"code","source":"%cd /kaggle/working\n!cp -R ../input/train-sartorius-detectron2-centermask2/centermask2 centermask2","metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-11-25T16:05:10.023645Z","iopub.execute_input":"2021-11-25T16:05:10.023935Z","iopub.status.idle":"2021-11-25T16:05:22.145039Z","shell.execute_reply.started":"2021-11-25T16:05:10.023898Z","shell.execute_reply":"2021-11-25T16:05:22.144068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Install a few libraries:","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os, json, cv2, random\nimport matplotlib.pyplot as plt\nimport glob, gc\nfrom skimage import measure\nimport albumentations as A\nfrom skimage import measure\nfrom wbf_tracking import weighted_boxes_fusion_tracking\nfrom scipy import stats\nimport torch\nfrom detectron2.engine import DefaultPredictor\nfrom detectron2.utils.visualizer import Visualizer\nfrom detectron2.data import MetadataCatalog, DatasetCatalog","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-11-25T16:05:22.148192Z","iopub.execute_input":"2021-11-25T16:05:22.149871Z","iopub.status.idle":"2021-11-25T16:05:23.749875Z","shell.execute_reply.started":"2021-11-25T16:05:22.149823Z","shell.execute_reply":"2021-11-25T16:05:23.748978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Configure model for inference:","metadata":{}},{"cell_type":"code","source":"%cd /kaggle/working/centermask2\n\nfrom centermask.config import get_cfg # important! Use get_cfg from the centermask repo and not Detectron2\n\ncfg = get_cfg()\ncfg.merge_from_file(\"./configs/centermask/test.yaml\")\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\ncfg.MODEL.WEIGHTS = './output/model_final.pth'\ncfg.MODEL.FCOS.POST_NMS_TOPK_TEST = 800 # Max number of detections per image\npredictor = DefaultPredictor(cfg)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-11-25T16:05:23.7534Z","iopub.execute_input":"2021-11-25T16:05:23.754015Z","iopub.status.idle":"2021-11-25T16:05:27.440363Z","shell.execute_reply.started":"2021-11-25T16:05:23.753971Z","shell.execute_reply":"2021-11-25T16:05:27.439603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sanity check on the three public test images\nThe number of detections per image is set high, so the unfiltered predictions below will look cluttered...","metadata":{}},{"cell_type":"code","source":"test_files = glob.glob('/kaggle/input/sartorius-cell-instance-segmentation/test/*')","metadata":{"execution":{"iopub.status.busy":"2021-11-25T16:05:27.441613Z","iopub.execute_input":"2021-11-25T16:05:27.441917Z","iopub.status.idle":"2021-11-25T16:05:27.448504Z","shell.execute_reply.started":"2021-11-25T16:05:27.441881Z","shell.execute_reply":"2021-11-25T16:05:27.447799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plt_pred(file):\n    im = cv2.imread(file)\n    outputs = predictor(im)\n    v = Visualizer(im[:, :, ::-1])\n    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n    plt.figure(figsize=(20,15))\n    plt.imshow(out.get_image()[:, :, ::-1]);\n\nif len(test_files) == 3:\n    plt_pred(test_files[0])","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-25T16:05:27.449856Z","iopub.execute_input":"2021-11-25T16:05:27.45034Z","iopub.status.idle":"2021-11-25T16:05:33.5955Z","shell.execute_reply.started":"2021-11-25T16:05:27.450301Z","shell.execute_reply":"2021-11-25T16:05:33.594578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if len(test_files) == 3:\n    plt_pred(test_files[1])","metadata":{"execution":{"iopub.status.busy":"2021-11-25T16:05:33.596523Z","iopub.execute_input":"2021-11-25T16:05:33.596774Z","iopub.status.idle":"2021-11-25T16:05:38.229755Z","shell.execute_reply.started":"2021-11-25T16:05:33.596743Z","shell.execute_reply":"2021-11-25T16:05:38.22782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if len(test_files) == 3:\n    plt_pred(test_files[2])","metadata":{"_kg_hide-output":false,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-25T16:05:38.233397Z","iopub.execute_input":"2021-11-25T16:05:38.233905Z","iopub.status.idle":"2021-11-25T16:05:42.622958Z","shell.execute_reply.started":"2021-11-25T16:05:38.233862Z","shell.execute_reply":"2021-11-25T16:05:42.622253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference for submission\nThe code below is principally based on [Positive score with Detectron 3/3 - Inference](https://www.kaggle.com/slawekbiel/positive-score-with-detectron-3-3-inference/notebook) by [Slawek Biel](https://www.kaggle.com/slawekbiel). Some major additions are made:  \n  * TTA with Weighted Segments Fusion\n  * Shape property measurement and filtering based on findings in [this notebook](https://www.kaggle.com/mistag/sartorius-cell-shape-analysis)\n  * Check for chopping of predictions by higher score masks\n  \nStart by reading in properties from cell shape analysis:","metadata":{}},{"cell_type":"code","source":"cell_df = pd.read_pickle('/kaggle/input/sartorius-cell-shape-analysis/shape_data.pkl')\ncell_df","metadata":{"execution":{"iopub.status.busy":"2021-11-25T16:05:42.62405Z","iopub.execute_input":"2021-11-25T16:05:42.624405Z","iopub.status.idle":"2021-11-25T16:05:42.655321Z","shell.execute_reply.started":"2021-11-25T16:05:42.624371Z","shell.execute_reply":"2021-11-25T16:05:42.654403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## TTA function\nWe define three transformations plus original image.","metadata":{}},{"cell_type":"code","source":"# Augmentations must be \"bidirectional\" - applying twice will get back to original\n# also augmentations must support image, bboxes and masks\nAUGMENTATIONS = [None, A.HorizontalFlip(p=1.0), A.VerticalFlip(p=1.0), A.Rotate(limit=(180,180), p=1.0)]\n\n# create dict key from bbox\ndef bbox_to_key(bbox):\n    return str(np.round(bbox, 6))\n\n# TTA function takes file name as input\ndef TTA(file, predictor):\n    boxes = []\n    box_scores = []\n    masks = []\n    masks_lkup =[]\n    pclass = []\n    im = cv2.imread(file)\n    for aug in AUGMENTATIONS:\n        if aug is not None:\n            transform = aug\n            ima = transform(image=im)['image']\n        else:\n            ima = im\n        pred = predictor(ima)\n        h, w = pred['instances'].image_size[0], pred['instances'].image_size[1]\n        classes = pred['instances'].pred_classes.cpu().numpy()-1\n        if len(pclass) == 0:\n            pclass = classes\n        else:\n            pclass = np.concatenate((pclass, classes))\n        # get box predictions\n        pred_boxes = [A.normalize_bbox(box, h, w) for box in pred['instances'].pred_boxes.tensor.cpu().numpy()]\n        # transform back to original\n        if aug is not None:\n            pred_boxes = transform(image=ima, bboxes=pred_boxes)['bboxes']\n        # get mask prediction\n        pred_masks = pred['instances'].pred_masks.cpu().numpy()*1\n        # transform back to original\n        if aug is not None:\n            pred_masks = transform(image=ima, masks=pred_masks)['masks']\n        # lookup table for bbox to mask index reference\n        pred_dict = {}\n        for i in range(len(pred_boxes)):\n            pred_dict[bbox_to_key(pred_boxes[i])] = i\n        # append results to list\n        boxes.append(np.array(pred_boxes))\n        box_scores.append(np.array(pred['instances'].scores.detach().cpu().numpy()))\n        masks.append(np.array(pred_masks, dtype=np.uint8))\n        masks_lkup.append(pred_dict)\n    \n        del pred, pred_boxes, pred_masks, ima, pred_dict\n    \n    del im\n    gc.collect()\n    predicted_class = stats.mode(pclass)[0][0]\n    return boxes, box_scores, masks, masks_lkup, predicted_class","metadata":{"execution":{"iopub.status.busy":"2021-11-25T16:05:42.656877Z","iopub.execute_input":"2021-11-25T16:05:42.657158Z","iopub.status.idle":"2021-11-25T16:05:42.676405Z","shell.execute_reply.started":"2021-11-25T16:05:42.657114Z","shell.execute_reply":"2021-11-25T16:05:42.67551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Weighted Segments Fusion\nThe function below will fuse masks based on WBF boxes.","metadata":{}},{"cell_type":"code","source":"def get_wsf_mask(wbf_box, wbf_org, pmasks, pmasks_lkup, thres=0.5):\n    w, h = 520, 704\n    mask = np.zeros((w, h), dtype=np.uint8)\n    for i in range(len(wbf_org)):\n        key = bbox_to_key(wbf_org[i][4:])\n        model = int(wbf_org[i][3])\n        try:\n            ind = pmasks_lkup[model][key]\n            mask = mask + pmasks[model][ind]\n        except:\n            pass\n    # convert thres to integer based on number of boxes\n    threshold = max(1, int(thres*len(wbf_org)))\n    # remove pixels outside WBF box\n    m2 = np.zeros((w, h), dtype=np.uint8)\n    x1 = max(0, int(h * wbf_box[0]))\n    y1 = max(0, int(w * wbf_box[1]))\n    x2 = min(h, int(h * wbf_box[2]))\n    y2 = min(w, int(w * wbf_box[3]))\n    m2[y1:y2, x1:x2] = 1\n    mask = (mask >= threshold) * m2\n    return mask.astype(np.uint8)","metadata":{"execution":{"iopub.status.busy":"2021-11-25T16:05:42.677757Z","iopub.execute_input":"2021-11-25T16:05:42.678719Z","iopub.status.idle":"2021-11-25T16:05:42.692735Z","shell.execute_reply.started":"2021-11-25T16:05:42.678678Z","shell.execute_reply":"2021-11-25T16:05:42.691517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prediction function\nTTA + WSF is applied below.","metadata":{}},{"cell_type":"code","source":"DEBUG = False\n\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\nTHRESHOLDS = [.53, .45, .55]\nCLASS_LABELS = ['background', 'shsy5y', 'astro', 'cort']\n\n# Implement WSF for TTA\ndef get_masks_tta(fn, predictor, thres=-1):\n    im = cv2.imread(str(fn))\n    h, w = im.shape[0], im.shape[1]\n    # do TTA\n    boxes, box_scores, masks, masks_lkup, pred_class = TTA(str(fn), predictor)\n    # create dummy labels\n    labels = []\n    for i in range(len(boxes)):\n        labels.append(np.ones(len(boxes[i]), dtype=np.uint8))\n    # weighted boxes fusion\n    wbf_boxes, wbf_scores, _, wbf_originals = weighted_boxes_fusion_tracking(boxes, \n                                                                             box_scores, \n                                                                             labels_list=labels, \n                                                                             iou_thr=0.55, \n                                                                             skip_box_thr=THRESHOLDS[pred_class])\n    # Finally, process masks, making sure there is no overlap\n    res = []\n    used = np.zeros(im.shape[:2], dtype=int)\n    # extract limits from DataFrame\n    pred_label = CLASS_LABELS[pred_class+1]\n    min_key = pred_label+' min'\n    major_axis_len_min = cell_df[cell_df.feature == 'major_axis_len'][min_key].iloc[0]\n    # process\n    for i in range(len(wbf_boxes)):\n        mask = get_wsf_mask(wbf_boxes[i], wbf_originals[i], masks, masks_lkup, thres=.5)\n        # get shape properties\n        try:\n            props = measure.regionprops(mask)\n        except:\n            continue\n        # if there are multiple separated masks, pick the larger one\n        areas = []\n        for a in range(len(props)):\n            areas.append(props[a].area)\n        try:\n            target = np.argmax(areas)\n        except:\n            continue\n        # extract properties of interest \n        major_axis_len = props[target].major_axis_length\n        # check against limits\n        if major_axis_len >= major_axis_len_min:\n            mask = mask * (1-used)\n            # check if mask is chopped up by previous detections\n            if len(measure.find_contours(mask, 0.5, positive_orientation='low')) == 1:\n                used += mask\n                res.append(rle_encode(mask))\n            else:\n                if DEBUG:\n                    print('{}: Chopped\\'n\\'dropped #{}'.format(fn.split('/')[-1], i))\n        else:\n            if DEBUG:\n                print('{}: Failed limits #{}'.format(fn.split('/')[-1], i))\n                \n    if DEBUG:\n        print('{}: {}, {} boxes of {} left after processing'.format(fn.split('/')[-1], pred_label, len(res), len(wbf_boxes)))\n                \n    del boxes, box_scores, masks, masks_lkup\n    del wbf_boxes, wbf_scores, labels, wbf_originals\n    gc.collect()\n          \n    return res","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-25T16:05:42.696354Z","iopub.execute_input":"2021-11-25T16:05:42.696582Z","iopub.status.idle":"2021-11-25T16:05:42.716779Z","shell.execute_reply.started":"2021-11-25T16:05:42.696558Z","shell.execute_reply":"2021-11-25T16:05:42.715984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Go for it:","metadata":{}},{"cell_type":"code","source":"ids, masks=[],[]\n\nfor fn in test_files:\n    fid = fn.split('/')[-1].split('.')[0]\n    #print('------------------- {} --------------------'.format(fid))\n    encoded_masks = get_masks_tta(fn, predictor)\n    if len(encoded_masks) > 0:\n        for enc in encoded_masks:\n            ids.append(fid)\n            masks.append(enc)\n    else:\n        ids.append(fid)\n        masks.append('')\n        \ndf = pd.DataFrame({'id':ids, 'predicted':masks})\ndf.to_csv('/kaggle/working/submission.csv', index=False)\ndf.head()","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-11-25T16:05:42.718029Z","iopub.execute_input":"2021-11-25T16:05:42.718574Z","iopub.status.idle":"2021-11-25T16:06:16.4216Z","shell.execute_reply.started":"2021-11-25T16:05:42.71853Z","shell.execute_reply":"2021-11-25T16:06:16.419914Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Cleanup:","metadata":{}},{"cell_type":"code","source":"%cd /kaggle/working\n!rm -fr /kaggle/working/centermask2\n!rm -fr /kaggle/working/detectron2\n!rm wbf_tracking.py","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-11-25T16:06:16.422987Z","iopub.execute_input":"2021-11-25T16:06:16.423253Z","iopub.status.idle":"2021-11-25T16:06:18.77084Z","shell.execute_reply.started":"2021-11-25T16:06:16.423216Z","shell.execute_reply":"2021-11-25T16:06:18.769872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}