{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Create mask dataset\nThe training dataset in this competition is small enough that all data can be kept in memory. In this notebook we will create a dictionary with the masks for use in training (good for TPU etc.) and save it to a pickle file.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-16T08:53:12.133863Z","iopub.execute_input":"2021-10-16T08:53:12.134191Z","iopub.status.idle":"2021-10-16T08:53:21.037083Z","shell.execute_reply.started":"2021-10-16T08:53:12.134109Z","shell.execute_reply":"2021-10-16T08:53:21.036234Z"}}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport json\nfrom tqdm import tqdm\nfrom PIL import Image\nimport pickle","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-10-17T07:15:09.30579Z","iopub.execute_input":"2021-10-17T07:15:09.30636Z","iopub.status.idle":"2021-10-17T07:15:09.311735Z","shell.execute_reply.started":"2021-10-17T07:15:09.306318Z","shell.execute_reply":"2021-10-17T07:15:09.31099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load data","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/sartorius-cell-instance-segmentation/train.csv')","metadata":{"execution":{"iopub.status.busy":"2021-10-17T07:15:09.313144Z","iopub.execute_input":"2021-10-17T07:15:09.313903Z","iopub.status.idle":"2021-10-17T07:15:09.671357Z","shell.execute_reply.started":"2021-10-17T07:15:09.313853Z","shell.execute_reply":"2021-10-17T07:15:09.67046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"First, check the number of classes in the dataset:","metadata":{}},{"cell_type":"code","source":"df.cell_type.unique()","metadata":{"execution":{"iopub.status.busy":"2021-10-17T07:15:09.672756Z","iopub.execute_input":"2021-10-17T07:15:09.672995Z","iopub.status.idle":"2021-10-17T07:15:09.684927Z","shell.execute_reply.started":"2021-10-17T07:15:09.672966Z","shell.execute_reply":"2021-10-17T07:15:09.683982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And the distribution:","metadata":{}},{"cell_type":"code","source":"hist = df.cell_type.hist()","metadata":{"execution":{"iopub.status.busy":"2021-10-17T07:15:09.686287Z","iopub.execute_input":"2021-10-17T07:15:09.686494Z","iopub.status.idle":"2021-10-17T07:15:09.92141Z","shell.execute_reply.started":"2021-10-17T07:15:09.686468Z","shell.execute_reply":"2021-10-17T07:15:09.920519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Three classes, save to .json here for later use. ","metadata":{}},{"cell_type":"code","source":"CLASS_LABELS = {'shsy5y': 1, 'astro':2, 'cort':3} # used for class labels\n\nwith open('classes.json', 'w') as fp:\n    json.dump(CLASS_LABELS, fp, indent=4)","metadata":{"execution":{"iopub.status.busy":"2021-10-17T07:15:09.923361Z","iopub.execute_input":"2021-10-17T07:15:09.92364Z","iopub.status.idle":"2021-10-17T07:15:09.928733Z","shell.execute_reply.started":"2021-10-17T07:15:09.923598Z","shell.execute_reply":"2021-10-17T07:15:09.927828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create mask set\nThe mask creation is pretty slow below (~30min), but this does not matter, as they will be saved to file for easy use in other notebooks. Note that there is only one class per image, so the masks are binary. But we keep information about cell type for train/test stratification later on.","metadata":{}},{"cell_type":"code","source":"# ref: https://www.kaggle.com/inversion/run-length-decoding-quick-start\ndef rle_decode(mask_rle, mask, color=1):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height, width, channels) of array to return \n    color: color for the mask\n    Returns numpy array (mask)\n\n    '''\n    s = mask_rle.split()\n    \n    starts = list(map(lambda x: int(x) - 1, s[0::2]))\n    lengths = list(map(int, s[1::2]))\n    ends = [x + y for x, y in zip(starts, lengths)]\n    \n    img = mask.reshape((mask.shape[0] * mask.shape[1]))\n            \n    for start, end in zip(starts, ends):\n        img[start : end] = color\n    \n    return img.reshape(mask.shape)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-10-17T07:15:09.929891Z","iopub.execute_input":"2021-10-17T07:15:09.930102Z","iopub.status.idle":"2021-10-17T07:15:09.940354Z","shell.execute_reply.started":"2021-10-17T07:15:09.930077Z","shell.execute_reply":"2021-10-17T07:15:09.939617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE = [520, 704]\n\n# create mask for a single id\ndef create_mask(iid, img_size):\n    mask = np.zeros(img_size, dtype=np.uint8)\n    for i in range(len(df[df.id == iid])):\n        mask = rle_decode(df[df.id == iid].annotation.iloc[i], mask) \n    return mask\n\n# create masks for all training set\ndef create_mask_dict(df):\n    mdict={}\n    ids = df.id.unique()\n    for i in tqdm(range(len(ids))):\n        iid = ids[i]\n        mdict[iid] = {'mask': create_mask(iid, IMAGE_SIZE), 'class': CLASS_LABELS[df[df.id == iid].cell_type.iloc[0]]}\n    return mdict","metadata":{"execution":{"iopub.status.busy":"2021-10-17T07:22:48.905771Z","iopub.execute_input":"2021-10-17T07:22:48.906065Z","iopub.status.idle":"2021-10-17T07:22:48.914228Z","shell.execute_reply.started":"2021-10-17T07:22:48.906023Z","shell.execute_reply":"2021-10-17T07:22:48.913182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask_dict = create_mask_dict(df)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-10-17T07:22:52.201752Z","iopub.execute_input":"2021-10-17T07:22:52.202022Z","iopub.status.idle":"2021-10-17T07:24:08.760761Z","shell.execute_reply.started":"2021-10-17T07:22:52.201993Z","shell.execute_reply":"2021-10-17T07:24:08.759403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finally write the dictionary to file:","metadata":{}},{"cell_type":"code","source":"pickle.dump(mask_dict, open('mask_dict.pkl', 'wb'))","metadata":{"execution":{"iopub.status.busy":"2021-10-17T07:15:53.555974Z","iopub.status.idle":"2021-10-17T07:15:53.556296Z","shell.execute_reply.started":"2021-10-17T07:15:53.556134Z","shell.execute_reply":"2021-10-17T07:15:53.55615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check mask data\nLet's plot a few images and masks to check that everything is OK.","metadata":{}},{"cell_type":"code","source":"ids = df.id.unique()[:4]\nfig = plt.figure(figsize=(16,24))\nfor i in range(len(ids)):\n    axes = fig.add_subplot(4, 2, 2*i+1)\n    plt.setp(axes, xticks=[], yticks=[])\n    iid = ids[i]\n    img = Image.open('../input/sartorius-cell-instance-segmentation/train/{}.png'.format(iid))\n    plt.imshow(img, cmap='gray')\n    axes = fig.add_subplot(4, 2, 2*i+2)\n    plt.setp(axes, xticks=[], yticks=[])\n    mask = mask_dict[iid]['mask']\n    plt.title('Cell type: {}'.format([key for key in CLASS_LABELS.items() if key[1] == mask_dict[iid]['class']][0][0]))\n    plt.tight_layout()\n    plt.imshow(mask)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-10-17T07:15:53.558063Z","iopub.status.idle":"2021-10-17T07:15:53.558597Z","shell.execute_reply.started":"2021-10-17T07:15:53.558283Z","shell.execute_reply":"2021-10-17T07:15:53.558308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Seems OK! Next step is to create a [TPU compatible dataset](https://www.kaggle.com/mistag/sartorius-create-tpu-compatible-tf-dataset) for Tensorflow.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}