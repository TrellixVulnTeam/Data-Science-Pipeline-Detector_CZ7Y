{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install '/kaggle/input/competitionpackages/wheels/torch-1.7.1+cu110-cp37-cp37m-linux_x86_64.whl' --no-deps\n!pip install '/kaggle/input/competitionpackages/wheels/torchvision-0.8.2+cu110-cp37-cp37m-linux_x86_64.whl' --no-deps\n!pip install '/kaggle/input/competitionpackages/wheels/torchaudio-0.7.2-cp37-cp37m-manylinux1_x86_64.whl' --no-deps","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-26T03:19:33.801333Z","iopub.execute_input":"2021-11-26T03:19:33.801675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install '/kaggle/input/mmdetectionv2180/addict-2.4.0-py3-none-any.whl' --no-deps\n!pip install '/kaggle/input/mmdetectionv2180/yapf-0.31.0-py2.py3-none-any.whl' --no-deps\n!pip install '/kaggle/input/mmdetectionv2180/terminal-0.4.0-py3-none-any.whl' --no-deps\n!pip install '/kaggle/input/mmdetectionv2180/terminaltables-3.1.0-py3-none-any.whl' --no-deps\n!pip install '/kaggle/input/mmdetectionv2180/mmcv_full-1_3_17-cu110-torch1_7_1/mmcv_full-1.3.17-cp37-cp37m-manylinux1_x86_64.whl' --no-deps\n!pip install '/kaggle/input/mmdetectionv2180/pycocotools-2.0.2/pycocotools-2.0.2' --no-deps\n!pip install '/kaggle/input/mmdetectionv2180/mmpycocotools-12.0.3/mmpycocotools-12.0.3' --no-deps","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm -rf mmdetection\n\n!cp -r /kaggle/input/mmdetectionv2180/mmdetection-2.18.0 /kaggle/working/\n!mv /kaggle/working/mmdetection-2.18.0 /kaggle/working/mmdetection\n%cd /kaggle/working/mmdetection\n!pip install -e .","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\nimport sklearn\nimport torchvision\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport numpy as np\nimport cupy as cp\nimport gc\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport PIL\nimport json\nfrom PIL import Image, ImageEnhance\nimport albumentations as A\nimport mmdet\nimport mmcv\nfrom albumentations.pytorch import ToTensorV2\nimport seaborn as sns\nimport glob\nfrom pathlib import Path\nimport pycocotools\nfrom pycocotools import mask\nimport numpy.random\nimport random\nimport cv2\nimport re\nimport shutil\nfrom mmdet.datasets import build_dataset\nfrom mmdet.models import build_detector\nfrom mmdet.apis import train_detector\nfrom mmdet.apis import inference_detector, init_detector, show_result_pyplot, set_random_seed","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-26T03:37:05.714007Z","iopub.execute_input":"2021-11-26T03:37:05.714476Z","iopub.status.idle":"2021-11-26T03:37:05.72297Z","shell.execute_reply.started":"2021-11-26T03:37:05.714436Z","shell.execute_reply":"2021-11-26T03:37:05.72221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd ..","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_WIDTH = 704\nIMG_HEIGHT = 520","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-26T03:39:08.855035Z","iopub.execute_input":"2021-11-26T03:39:08.85561Z","iopub.status.idle":"2021-11-26T03:39:08.859948Z","shell.execute_reply.started":"2021-11-26T03:39:08.855571Z","shell.execute_reply":"2021-11-26T03:39:08.859065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rle_decode(mask_rle, shape):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape)\n\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-26T03:39:11.402606Z","iopub.execute_input":"2021-11-26T03:39:11.402859Z","iopub.status.idle":"2021-11-26T03:39:11.411567Z","shell.execute_reply.started":"2021-11-26T03:39:11.402828Z","shell.execute_reply":"2021-11-26T03:39:11.410853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rle_encoding(x):\n    dots = np.where(x.flatten() == 1)[0]\n    run_lengths = []\n    prev = -2\n    for b in dots:\n        if (b>prev+1): run_lengths.extend((b + 1, 0))\n        run_lengths[-1] += 1\n        prev = b\n    return ' '.join(map(str, run_lengths))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-26T03:39:12.091262Z","iopub.execute_input":"2021-11-26T03:39:12.092089Z","iopub.status.idle":"2021-11-26T03:39:12.098032Z","shell.execute_reply.started":"2021-11-26T03:39:12.092038Z","shell.execute_reply":"2021-11-26T03:39:12.097226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_mask_from_result(result):\n    d = {True : 1, False : 0}\n    u,inv = np.unique(result,return_inverse = True)\n    mk = cp.array([d[x] for x in u])[inv].reshape(result.shape)\n#     print(mk.shape)\n    return mk","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-26T03:39:13.939091Z","iopub.execute_input":"2021-11-26T03:39:13.93937Z","iopub.status.idle":"2021-11-26T03:39:13.944129Z","shell.execute_reply.started":"2021-11-26T03:39:13.939339Z","shell.execute_reply":"2021-11-26T03:39:13.943397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def does_overlap(mask, other_masks):\n    for other_mask in other_masks:\n        if np.sum(np.logical_and(mask, other_mask)) > 0:\n            #import pdb; pdb.set_trace()\n            #print(\"Found overlapping masks!\")\n            return True\n    return False\n\n\ndef remove_overlapping_pixels(mask, other_masks):\n    for other_mask in other_masks:\n        if np.sum(np.logical_and(mask, other_mask)) > 0:\n            print(\"Overlap detected\")\n            mask[np.logical_and(mask, other_mask)] = 0\n    return mask","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-26T03:39:14.180269Z","iopub.execute_input":"2021-11-26T03:39:14.180627Z","iopub.status.idle":"2021-11-26T03:39:14.186653Z","shell.execute_reply.started":"2021-11-26T03:39:14.180588Z","shell.execute_reply":"2021-11-26T03:39:14.185924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**model**","metadata":{}},{"cell_type":"code","source":"# %%writefile labels.txt\n# shsy5y\n# cort\n# astro","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-26T03:39:16.489339Z","iopub.execute_input":"2021-11-26T03:39:16.489844Z","iopub.status.idle":"2021-11-26T03:39:16.492819Z","shell.execute_reply.started":"2021-11-26T03:39:16.489805Z","shell.execute_reply":"2021-11-26T03:39:16.492118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from mmcv import Config\ncfg = Config.fromfile('/kaggle/working/mmdetection/configs/cascade_rcnn/cascade_mask_rcnn_x101_64x4d_fpn_20e_coco.py')  #修改\n#../input/mmdetectionv2180/mmdetection-2.18.0/configs/queryinst/queryinst_r101_fpn_300_proposals_crop_mstrain_480-800_3x_coco.py","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-26T03:39:17.194636Z","iopub.execute_input":"2021-11-26T03:39:17.197063Z","iopub.status.idle":"2021-11-26T03:39:17.224975Z","shell.execute_reply.started":"2021-11-26T03:39:17.197025Z","shell.execute_reply":"2021-11-26T03:39:17.2242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg.dataset_type = 'CocoDataset'\ncfg.classes = '/kaggle/working/labels.txt'\ncfg.data_root = '/kaggle/working'\n\nfor head in cfg.model.roi_head.bbox_head:\n    head.num_classes = 3\ncfg.model.roi_head.mask_head.num_classes=3\n\n# for head in cfg.model.roi_head.bbox_head:\n#     head.num_classes = 3 \n# for head in cfg.model.roi_head.mask_head:\n#     head.num_classes = 3\n    \n\n# cfg.model.roi_head.bbox_head.num_classes = 3\n# cfg.model.roi_head.mask_head.num_classes = 3\n# cfg.model.roi_head.mask_iou_head.num_classes = 3\n\n# for head in cfg.model.roi_head.bbox_head:\n#     head.num_classes=3\n# for head in cfg.model.roi_head.mask_head:\n#     head.num_classes=3\n\ncfg.data.test.type = 'CocoDataset'\ncfg.data.test.classes = 'labels.txt'\ncfg.data.test.data_root = '/kaggle/working'\ncfg.data.test.ann_file = 'train_dataset.json'\ncfg.data.test.img_prefix = ''\n\ncfg.data.train.type = 'CocoDataset'\ncfg.data.train.data_root = '/kaggle/working'\ncfg.data.train.ann_file = 'train_dataset.json'\ncfg.data.train.img_prefix = ''\ncfg.data.train.classes = 'labels.txt'\n\ncfg.data.val.type = 'CocoDataset'\ncfg.data.val.data_root = '/kaggle/working'\ncfg.data.val.ann_file = 'train_dataset.json'\ncfg.data.val.img_prefix = ''\ncfg.data.val.classes = 'labels.txt'\n\n# cfg.train_pipeline = [\n#     dict(type='LoadImageFromFile'),\n#     dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n#     dict(type='RandomFlip', flip_ratio=0.5),\n\n#     dict(\n#         type='Normalize',\n#         mean=[123.675, 116.28, 103.53],\n#         std=[58.395, 57.12, 57.375],\n#         to_rgb=True),\n#     dict(type='Pad', size_divisor=32),\n#     dict(type='DefaultFormatBundle'), \n#     dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_masks', 'gt_labels'])\n# ]\n\n# cfg.val_pipeline = [\n#     dict(type='LoadImageFromFile'),\n#     dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n#     dict(type='RandomFlip', flip_ratio=0.5),\n\n#     dict(\n#         type='Normalize',\n#         mean=[123.675, 116.28, 103.53],\n#         std=[58.395, 57.12, 57.375],\n#         to_rgb=True),\n#     dict(type='Pad', size_divisor=32),\n#     dict(type='DefaultFormatBundle'), \n#     dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_masks', 'gt_labels'])\n# ]\n\n# cfg.test_pipeline = [\n#     dict(type='LoadImageFromFile'),\n#     dict(type='Resize', img_scale=[(440, 596), (480, 650), (520, 704), (580, 785), (620, 839)], multiscale_mode='value', keep_ratio=True),\n#     dict(\n#         type='Normalize',\n#         mean=[128, 128, 128],\n#         std=[11.58, 11.58, 11.58],\n#         to_rgb=True),\n#     dict(type='Pad', size_divisor=32),\n#     dict(type='DefaultFormatBundle'),\n#     dict(type='Collect', keys=['img'])\n# ]\n\ncfg.work_dir = '/kaggle/working/model_output/cascademaskrcnn'\n\ncfg.data.samples_per_gpu = 2\ncfg.data.workers_per_gpu = 2\n\ncfg.evaluation.metric = 'segm'\ncfg.evaluation.interval = 4\n\ncfg.checkpoint_config.interval = 4\ncfg.runner.max_epochs = 12\ncfg.log_config.interval = 50\n\ncfg.seed = 0\nset_random_seed(0, deterministic=False)\ncfg.gpu_ids = range(1)\n\nprint(f'Config:\\n{cfg.pretty_text}')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-26T03:39:19.132553Z","iopub.execute_input":"2021-11-26T03:39:19.133328Z","iopub.status.idle":"2021-11-26T03:39:19.793723Z","shell.execute_reply.started":"2021-11-26T03:39:19.133267Z","shell.execute_reply":"2021-11-26T03:39:19.79278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**inference**","metadata":{}},{"cell_type":"code","source":"#confidence_thresholds = {0: 0.15, 1: 0.55, 2: 0.35}\n#confidence_thresholds = {0: 0.55, 1: 0.75, 2: 0.5}\n#confidence_thresholds = {0: 0, 1: 0, 2: 0}\nconfidence_thresholds = {0: 0.18, 1: 0.38, 2: 0.58}","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-26T03:39:26.45143Z","iopub.execute_input":"2021-11-26T03:39:26.451697Z","iopub.status.idle":"2021-11-26T03:39:26.455585Z","shell.execute_reply.started":"2021-11-26T03:39:26.451668Z","shell.execute_reply":"2021-11-26T03:39:26.454743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmasks = []\nfiles = []\n\n#model = init_detector(cfg, '../input/csmaskrcnn-v4-1-1-epoch-5/csmaskrcnn_V4_1_1_epoch_5.pth')\nmodel = init_detector(cfg, '../input/20211126-1038/csmaskrcnn_V4_1_epoch_5.pth')\nfor file in sorted(os.listdir('../input/sartorius-cell-instance-segmentation/test')):\n    img = mmcv.imread('../input/sartorius-cell-instance-segmentation/test/' + file)\n    result = inference_detector(model, img)\n    show_result_pyplot(model, img, result)\n    msk = []\n    for i, classe in enumerate(result[0]):\n        if classe.shape != (0, 5):\n            bbs = classe\n#             print(bbs)\n            sgs = result[1][i] #change\n            for bb, sg in zip(bbs,sgs):\n                box = bb[:4]\n                cnf = bb[4]\n                #for i_s in range(len(sg)):         #change for list\n                if cnf >= confidence_thresholds[i]:\n                    #mask = get_mask_from_result(sg[i_s])\n                    mask = get_mask_from_result(sg)\n                    mask = remove_overlapping_pixels(mask, msk)\n                    msk.append(mask)\n                \n    for mk in msk:\n            rle_mask = rle_encoding(mk)\n            masks.append(rle_mask)\n            files.append(str(file.split('.')[0]))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-26T04:06:04.308257Z","iopub.execute_input":"2021-11-26T04:06:04.308521Z","iopub.status.idle":"2021-11-26T04:06:25.990766Z","shell.execute_reply.started":"2021-11-26T04:06:04.308491Z","shell.execute_reply":"2021-11-26T04:06:25.989971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"files = pd.Series(files, name='id')\npreds = pd.Series(masks, name='predicted')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = pd.concat([files, preds], axis=1)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.to_csv('submission.csv', index=False)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shutil.rmtree('/kaggle/working/mmdetection')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-22T15:11:35.587051Z","iopub.execute_input":"2021-11-22T15:11:35.587618Z","iopub.status.idle":"2021-11-22T15:11:35.649523Z","shell.execute_reply.started":"2021-11-22T15:11:35.587565Z","shell.execute_reply":"2021-11-22T15:11:35.648794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}