{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Sartorius Segmentation - Detectron2 [diagnosis]","metadata":{"_cell_guid":"2a088d8e-64cb-4511-91f8-13e580dd342d","_uuid":"16ac5056-5692-46e5-b481-4d31de43a89b","papermill":{"duration":0.025974,"end_time":"2021-12-06T05:12:24.170879","exception":false,"start_time":"2021-12-06T05:12:24.144905","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"### Hi kagglers, This is `Training` notebook using `Detectron2`.\n[Sartorius Segmentation - Detectron2 [training]](https://www.kaggle.com/ammarnassanalhajali/sartorius-segmentation-detectron2-training) \n### Please if this kernel is useful, <font color='red'>please upvote !!</font>","metadata":{"_cell_guid":"259ba846-f1c1-4799-91f1-d535bfa0e428","_uuid":"b0c2e2fa-9919-4435-9354-510e06bf32ab","papermill":{"duration":0.020121,"end_time":"2021-12-06T05:12:24.211383","exception":false,"start_time":"2021-12-06T05:12:24.191262","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Other notebooks in this competition \n- [Sartorius Segmentation - Keras U-Net[Training]](https://www.kaggle.com/ammarnassanalhajali/sartorius-segmentation-keras-u-net-training)\n- [Sartorius Segmentation - Keras U-Net[Inference]](https://www.kaggle.com/ammarnassanalhajali/sartorius-segmentation-keras-u-net-inference/edit)","metadata":{"_cell_guid":"bd5e3d3f-788a-4781-a654-d3fc59e8a26d","_uuid":"2b8a6ac1-386b-428c-b49f-6093a2b12645","papermill":{"duration":0.021092,"end_time":"2021-12-06T05:12:24.252034","exception":false,"start_time":"2021-12-06T05:12:24.230942","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Detectron2 \nDetectron2 is Facebook AI Research's next generation software system that implements state-of-the-art object detection algorithms. It is a ground-up rewrite of the previous version, Detectron, and it originates from maskrcnn-benchmark","metadata":{"_cell_guid":"4fae440d-df06-40f9-a119-8adb22a74031","_uuid":"ae32624a-e54f-47ad-a6e4-621918e1cf00","papermill":{"duration":0.037517,"end_time":"2021-12-06T05:12:24.31804","exception":false,"start_time":"2021-12-06T05:12:24.280523","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Install Detectron2 offline","metadata":{"_cell_guid":"0f2cd256-3680-4d65-bd5f-3f2db892db9d","_uuid":"09222a37-f5c6-47c2-944a-c74ab3de9bc3","papermill":{"duration":0.032429,"end_time":"2021-12-06T05:12:24.384142","exception":false,"start_time":"2021-12-06T05:12:24.351713","status":"completed"},"tags":[]}},{"cell_type":"code","source":"!pip install ../input/detectron-05/whls/pycocotools-2.0.2/dist/pycocotools-2.0.2.tar --no-index --find-links ../input/detectron-05/whls \n!pip install ../input/detectron-05/whls/fvcore-0.1.5.post20211019/fvcore-0.1.5.post20211019 --no-index --find-links ../input/detectron-05/whls \n!pip install ../input/detectron-05/whls/antlr4-python3-runtime-4.8/antlr4-python3-runtime-4.8 --no-index --find-links ../input/detectron-05/whls \n!pip install ../input/detectron-05/whls/detectron2-0.5/detectron2 --no-index --find-links ../input/detectron-05/whls","metadata":{"_cell_guid":"ec4d02cb-97dd-4601-8617-d43f46ad575d","_kg_hide-input":false,"_kg_hide-output":true,"_uuid":"0aa94adc-e5d1-4252-9934-ac6f9d719bed","collapsed":false,"execution":{"iopub.execute_input":"2021-12-06T05:12:24.438129Z","iopub.status.busy":"2021-12-06T05:12:24.435399Z","iopub.status.idle":"2021-12-06T05:16:35.63447Z","shell.execute_reply":"2021-12-06T05:16:35.63366Z","shell.execute_reply.started":"2021-12-06T04:46:23.372603Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":251.225884,"end_time":"2021-12-06T05:16:35.634735","exception":false,"start_time":"2021-12-06T05:12:24.408851","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# importing libraries","metadata":{"_cell_guid":"2efefe92-7a05-4859-942a-940df3c63886","_uuid":"a296d960-3959-4769-a9a6-9c2c05fa7cd9","papermill":{"duration":0.037691,"end_time":"2021-12-06T05:16:35.712814","exception":false,"start_time":"2021-12-06T05:16:35.675123","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import detectron2\nimport torch\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor\nfrom detectron2.config import get_cfg\nfrom PIL import Image\nimport cv2\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom fastcore.all import *\nimport json\ndetectron2.__version__","metadata":{"_cell_guid":"602236c3-912a-4618-9830-14feb333b782","_uuid":"23ac13ea-99e4-44c0-96a4-ff5a6cda385a","collapsed":false,"execution":{"iopub.execute_input":"2021-12-06T05:16:35.799316Z","iopub.status.busy":"2021-12-06T05:16:35.798277Z","iopub.status.idle":"2021-12-06T05:16:37.10595Z","shell.execute_reply":"2021-12-06T05:16:37.105314Z","shell.execute_reply.started":"2021-12-06T04:49:46.947323Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":1.353373,"end_time":"2021-12-06T05:16:37.106125","exception":false,"start_time":"2021-12-06T05:16:35.752752","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Functions","metadata":{"_cell_guid":"b94df9ec-5951-4d3b-97f2-d65c097dde2a","_uuid":"fed10d1c-b005-4051-adda-756b2c29ff63","papermill":{"duration":0.043796,"end_time":"2021-12-06T05:16:37.194329","exception":false,"start_time":"2021-12-06T05:16:37.150533","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# From https://www.kaggle.com/stainsby/fast-tested-rle\ndef rle_decode(mask_rle, shape=(520, 704)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape)  # Needed to align to RLE direction\n\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef get_masks(pred, shape, thres, mixp):\n    take = pred['instances'].scores >= thres\n    pred_masks = pred['instances'].pred_masks[take]\n    pred_masks = pred_masks.cpu().numpy()\n    res = []\n    used = np.zeros(shape[:2], dtype=int)\n    for mask in pred_masks:\n        mask = mask * (1-used)\n        if mask.sum() >= mixp: # skip predictions with small area\n            used += mask\n            res.append(mask)\n    return res\n\nimport os\nimport skimage\nimport numpy as np\nimport pandas as pd\nimport skimage.segmentation\nimport matplotlib.pyplot as plt\n\ndef rles_to_mask(encs, shape):\n    \"\"\"\n    Decodes a rle.\n\n    Args:\n        encs (list of str): Rles for each class.\n        shape (tuple [2]): Mask size.\n\n    Returns:\n        np array [shape]: Mask.\n    \"\"\"\n    img = np.zeros(shape[0] * shape[1], dtype=np.uint)\n    for m, enc in enumerate(encs):\n        if isinstance(enc, np.float) and np.isnan(enc):\n            continue\n        enc_split = enc.split()\n        for i in range(len(enc_split) // 2):\n            start = int(enc_split[2 * i]) - 1\n            length = int(enc_split[2 * i + 1])\n            img[start: start + length] = 1 + m\n    return img.reshape(shape)\n\ndef precision_at(threshold, iou):\n    \"\"\"\n    Computes the precision at a given threshold.\n\n    Args:\n        threshold (float): Threshold.\n        iou (np array [n_truths x n_preds]): IoU matrix.\n\n    Returns:\n        int: Number of true positives,\n        int: Number of false positives,\n        int: Number of false negatives.\n    \"\"\"\n    matches = iou > threshold\n    true_positives = np.sum(matches, axis=1) >= 1  # Correct objects\n    false_negatives = np.sum(matches, axis=1) == 0  # Missed objects\n    false_positives = np.sum(matches, axis=0) == 0  # Extra objects\n    tp, fp, fn = (\n        np.sum(true_positives),\n        np.sum(false_positives),\n        np.sum(false_negatives),\n    )\n    return tp, fp, fn\n\ndef compute_iou(labels, y_pred):\n    \"\"\"\n    Computes the IoU for instance labels and predictions.\n\n    Args:\n        labels (np array): Labels.\n        y_pred (np array): predictions\n\n    Returns:\n        np array: IoU matrix, of size true_objects x pred_objects.\n    \"\"\"\n\n    true_objects = len(np.unique(labels))\n    pred_objects = len(np.unique(y_pred))\n\n    #print()\n    # Compute intersection between all objects\n    try:\n        intersection = np.histogram2d(\n            labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects)\n        )[0]\n\n        # Compute areas (needed for finding the union between all objects)\n        area_true = np.histogram(labels, bins=true_objects)[0]\n        area_pred = np.histogram(y_pred, bins=pred_objects)[0]\n        area_true = np.expand_dims(area_true, -1)\n        area_pred = np.expand_dims(area_pred, 0)\n\n        # Compute union\n        union = area_true + area_pred - intersection\n        iou = intersection / union\n\n        return iou[1:, 1:]  # exclude background\n    except:\n        return np.zeros([true_objects-1, pred_objects-1])\n\ndef iou_map(truths, preds, verbose=0):\n    \"\"\"\n    Computes the metric for the competition.\n    Masks contain the segmented pixels where each object has one value associated,\n    and 0 is the background.\n\n    Args:\n        truths (list of masks): Ground truths.\n        preds (list of masks): Predictions.\n        verbose (int, optional): Whether to print infos. Defaults to 0.\n\n    Returns:\n        float: mAP.\n    \"\"\"\n    ious = [compute_iou(truth, pred) for truth, pred in zip(truths, preds)] \n    #print(ious[0].shape)\n\n    if verbose:\n        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n\n    prec = []\n    for t in np.arange(0.5, 1.0, 0.05):\n        tps, fps, fns = 0, 0, 0\n        for iou in ious:\n            tp, fp, fn = precision_at(t, iou)\n            tps += tp\n            fps += fp\n            fns += fn\n\n        p = tps / (tps + fps + fns)\n        prec.append(p)\n\n        if verbose:\n            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tps, fps, fns, p))\n\n    if verbose:\n        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n\n    return np.mean(prec)\n\ndef get_all_iou(preds, true_masks, thres, mixp):\n    pred_masks = []\n    for pred in preds:\n        _pred_masks = get_masks(pred, true_masks[0].shape, thres, mixp)\n        pred_masks.append(sum([_pred_masks[i]*(i+1) for i in range(len(_pred_masks))]))\n    #cv2.imwrite('pred_masks.png', pred_masks[0]*255)\n    #cv2.imwrite('true_masks.png', true_masks[0]*255)\n    #a =1/0\n    return iou_map(true_masks, pred_masks)\n\ndef get_bad_preds(preds, true_masks, thres, mixp, n_preds=10):\n    bad_pred_dict_list = []\n    for pred, true_mask in zip(preds, true_masks):\n        _pred_mask = get_masks(pred, true_masks[0].shape, thres, mixp)\n        pred_mask = sum([_pred_mask[i]*(i+1) for i in range(len(_pred_mask))])\n        score = iou_map([true_mask], [pred_mask])\n        if len(bad_pred_dict_list) == 0 or bad_pred_dict_list[0]['score']>score:\n            if len(bad_pred_dict_list) == n_preds:\n                del bad_pred_dict_list[0]\n            bad_pred_dict_list.append({'pred_mask': pred_mask, 'true_mask': true_mask, 'score': score, \n                                       'image_path': pred['image_path']})\n            bad_pred_dict_list.sort(key=lambda d: d['score'], reverse=True)\n        \n    return bad_pred_dict_list\n\ndef do_eval(checkpoint):\n    cfg = get_cfg()\n    cfg.merge_from_file(model_zoo.get_config_file(MODEL_NAME))\n    cfg.INPUT.MASK_FORMAT='bitmask'\n    cfg.MODEL.WEIGHTS = checkpoint \n    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3 \n    #cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.40\n    cfg.TEST.DETECTIONS_PER_IMAGE = 1000\n    try:\n        predictor = DefaultPredictor(cfg)\n    except:\n        cfg.MODEL.DEVICE = \"cpu\"\n        predictor = DefaultPredictor(cfg)\n        \n    pred_list_by_class = [[], [], []]\n    ture_masks_by_class = [[], [], []]\n    for image in valid_images:\n        fn = str(Dir_testdata) + '/' + image['file_name']\n        im = cv2.imread(fn)\n        pred = predictor(im)\n        pred['image_path'] = fn\n        pred_class = torch.mode(pred['instances'].pred_classes)[0]\n        pred_list_by_class[pred_class].append(pred)\n\n        fid = image['id']\n        df = train_df[train_df['id']==fid]\n        shape = df[['height', 'width']].values[0]\n        rles = df['annotation'].values[0]\n        masks = rles_to_mask(rles, shape).astype(np.uint16)\n        ture_masks_by_class[pred_class].append(masks)\n        \n    iou = 0.0\n    n_all_preds = 0\n    for cls_i in range(len(pred_list_by_class)):\n        preds = pred_list_by_class[cls_i]\n        ture_masks = ture_masks_by_class[cls_i]\n        ious = get_all_iou(preds, ture_masks, THRESHOLDS[cls_i], MIN_PIXELS[cls_i])\n        iou += np.mean(ious) * len(preds)\n        n_all_preds += len(preds)\n    iou /= n_all_preds\n    \n    return iou","metadata":{"_cell_guid":"28140024-968e-43db-9d12-04e74e36de4a","_uuid":"abee97a9-c19c-49a1-96ad-5c5cd1f89568","collapsed":false,"execution":{"iopub.execute_input":"2021-12-06T05:16:37.304965Z","iopub.status.busy":"2021-12-06T05:16:37.303736Z","iopub.status.idle":"2021-12-06T05:16:39.064248Z","shell.execute_reply":"2021-12-06T05:16:39.067871Z","shell.execute_reply.started":"2021-12-06T04:49:48.337351Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":1.829179,"end_time":"2021-12-06T05:16:39.068313","exception":false,"start_time":"2021-12-06T05:16:37.239134","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Dir_testdata=Path('../input/sartorius-cell-instance-segmentation')\nids, masks=[],[]\ntest_image_names = (Dir_testdata/'test').ls()","metadata":{"_cell_guid":"8458d036-3ce2-46e6-9b93-e1b20b90c0bf","_uuid":"e778d441-183a-44da-9f2a-942a711cbd13","collapsed":false,"execution":{"iopub.execute_input":"2021-12-06T05:16:39.264906Z","iopub.status.busy":"2021-12-06T05:16:39.263942Z","iopub.status.idle":"2021-12-06T05:16:39.273999Z","shell.execute_reply":"2021-12-06T05:16:39.272985Z","shell.execute_reply.started":"2021-12-06T04:49:49.823086Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.104887,"end_time":"2021-12-06T05:16:39.27425","exception":false,"start_time":"2021-12-06T05:16:39.169363","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Model","metadata":{"_cell_guid":"5e4195f8-6cb3-4f56-bf73-1254fe1bdc37","_uuid":"d175e056-8701-43eb-bed2-01a260310c00","papermill":{"duration":0.070468,"end_time":"2021-12-06T05:16:39.415793","exception":false,"start_time":"2021-12-06T05:16:39.345325","status":"completed"},"tags":[]}},{"cell_type":"code","source":"cfg = get_cfg()\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\ncfg.INPUT.MASK_FORMAT='bitmask'\ncfg.MODEL.WEIGHTS = \"../input/sartorius-transfer-learning-train-test-model/output/model_0006049.pth\" \ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 3 \n#cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.40\ncfg.TEST.DETECTIONS_PER_IMAGE = 1000\ntry:\n    predictor = DefaultPredictor(cfg)\nexcept:\n    cfg.MODEL.DEVICE = \"cpu\"\n    predictor = DefaultPredictor(cfg)","metadata":{"_cell_guid":"86b5c991-974b-4f04-bd24-2e609003811d","_uuid":"1d1cabdb-2583-4fbb-9af3-80f2a693300c","collapsed":false,"execution":{"iopub.execute_input":"2021-12-06T05:16:39.565307Z","iopub.status.busy":"2021-12-06T05:16:39.564108Z","iopub.status.idle":"2021-12-06T05:16:49.337197Z","shell.execute_reply":"2021-12-06T05:16:49.336643Z","shell.execute_reply.started":"2021-12-06T04:49:49.83642Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":9.850024,"end_time":"2021-12-06T05:16:49.33734","exception":false,"start_time":"2021-12-06T05:16:39.487316","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predicting","metadata":{"_cell_guid":"d5acbc72-69de-47ce-98f0-aa8fb7446e10","_uuid":"a51f9d6b-d7f1-4815-9c37-40d71ab103bd","papermill":{"duration":0.041161,"end_time":"2021-12-06T05:16:49.419006","exception":false,"start_time":"2021-12-06T05:16:49.377845","status":"completed"},"tags":[]}},{"cell_type":"code","source":"with open('../input/sartorius-cell-instance-segmentation-coco/annotations_val.json', \"r\", encoding='utf-8') as f:\n    images = json.load(f)['images']\n    \ntrain_df = pd.read_csv('../input/sartorius-cell-instance-segmentation/train.csv')\ntrain_df = train_df.groupby('id').agg(list).reset_index()\nfor col in train_df.columns[2:]:\n    train_df[col] = train_df[col].apply(\n        lambda x: np.unique(x)[0] if len(np.unique(x)) == 1 else np.unique(x)\n    )\n\n\npred_list_by_class = [[], [], []]\nture_masks_by_class = [[], [], []]\nfor image in images:\n    fn = str(Dir_testdata) + '/' + image['file_name']\n    im = cv2.imread(fn)\n    pred = predictor(im)\n    pred['image_path'] = fn\n    pred_class = torch.mode(pred['instances'].pred_classes)[0]\n    pred_list_by_class[pred_class].append(pred)\n\n    fid = image['id']\n    df = train_df[train_df['id']==fid]\n    shape = df[['height', 'width']].values[0]\n    rles = df['annotation'].values[0]\n    masks = rles_to_mask(rles, shape).astype(np.uint16)\n    ture_masks_by_class[pred_class].append(masks)","metadata":{"_cell_guid":"dd389c82-d8b1-47a0-a29e-5243e14f0b65","_uuid":"9fd984a1-a1ca-4ccd-a18c-5c0733ff9867","collapsed":false,"execution":{"iopub.execute_input":"2021-12-06T05:16:49.511446Z","iopub.status.busy":"2021-12-06T05:16:49.51053Z","iopub.status.idle":"2021-12-06T05:17:13.39385Z","shell.execute_reply":"2021-12-06T05:17:13.393244Z","shell.execute_reply.started":"2021-12-06T04:49:59.390653Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":23.933257,"end_time":"2021-12-06T05:17:13.394002","exception":false,"start_time":"2021-12-06T05:16:49.460745","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"THRESHOLD_RANGE = [x/100 for x in range(10, 91, 2)]\nMIN_PIXELS_RANGE = range(30, 251, 5)\nTHRESHOLDS = [0.15, 0.2, 0.45]\nMIN_PIXELS = [80, 160, 60]\n#FIND_BEST_CHECKPOINT = False\nFIND_THRESHOLDS = True","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#if FIND_BEST_CHECKPOINT:\n#    do_eval()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if FIND_THRESHOLDS:\n    for cls_i in range(len(pred_list_by_class)):    \n        best_iou = 0\n        best_th = 0\n        for th in THRESHOLD_RANGE:    \n            preds = pred_list_by_class[cls_i]\n            ture_masks = ture_masks_by_class[cls_i]\n            ious = get_all_iou(preds, ture_masks, th, MIN_PIXELS[cls_i])\n            iou = np.mean(ious)\n            print(f'cls:{cls_i}, th: {th}, iou:{iou}')\n            if best_iou < iou:\n                best_iou = iou\n                best_th = th\n        THRESHOLDS[cls_i] = best_th\n\n        best_iou = 0\n        best_minp = 0\n        for minp in MIN_PIXELS_RANGE:\n            preds = pred_list_by_class[cls_i]\n            ture_masks = ture_masks_by_class[cls_i]\n            ious = get_all_iou(preds, ture_masks, THRESHOLDS[cls_i], minp)\n            iou = np.mean(ious)\n            print(f'cls:{cls_i}, minp: {minp}, iou:{iou}')\n            if best_iou < iou:\n                best_iou = iou\n                best_minp = minp\n        MIN_PIXELS[cls_i] = best_minp","metadata":{"_cell_guid":"8e063c61-a53e-4b2a-8b64-8232bc347eba","_uuid":"8479c375-e96a-4c3c-b0f4-2b53d352472f","collapsed":false,"execution":{"iopub.execute_input":"2021-12-06T05:17:13.491975Z","iopub.status.busy":"2021-12-06T05:17:13.490944Z","iopub.status.idle":"2021-12-06T05:17:13.493691Z","shell.execute_reply":"2021-12-06T05:17:13.494279Z","shell.execute_reply.started":"2021-12-06T04:50:21.890588Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.05484,"end_time":"2021-12-06T05:17:13.494458","exception":false,"start_time":"2021-12-06T05:17:13.439618","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'THRESHOLDS:\" {THRESHOLDS}')\nprint(f'MIN_PIXELS:\" {MIN_PIXELS}')","metadata":{"_cell_guid":"9b737e49-9a8b-4628-b5f2-e49a6a460da7","_uuid":"759f72a2-c499-4a21-b75a-ce67db48e85c","collapsed":false,"execution":{"iopub.execute_input":"2021-12-06T05:17:13.583071Z","iopub.status.busy":"2021-12-06T05:17:13.581972Z","iopub.status.idle":"2021-12-06T05:17:13.586341Z","shell.execute_reply":"2021-12-06T05:17:13.587202Z","shell.execute_reply.started":"2021-12-06T04:08:50.372803Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.05234,"end_time":"2021-12-06T05:17:13.587432","exception":false,"start_time":"2021-12-06T05:17:13.535092","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#get bad preds\nbad_pred_dict_list_list = []\nfor cls_i in range(len(pred_list_by_class)):  \n    preds = pred_list_by_class[cls_i]\n    ture_masks = ture_masks_by_class[cls_i]\n    bad_pred_dict_list_list.append(get_bad_preds(preds, ture_masks, THRESHOLDS[cls_i], MIN_PIXELS[cls_i]))","metadata":{"_cell_guid":"50d09ddb-d8af-4d6a-b2c7-6f9d928cfb20","_uuid":"d65dba2b-f707-4c04-af2b-afaa1caa3fea","collapsed":false,"execution":{"iopub.execute_input":"2021-12-06T05:17:13.679288Z","iopub.status.busy":"2021-12-06T05:17:13.678366Z","iopub.status.idle":"2021-12-06T05:17:48.661894Z","shell.execute_reply":"2021-12-06T05:17:48.662389Z","shell.execute_reply.started":"2021-12-06T04:54:15.989118Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":35.03067,"end_time":"2021-12-06T05:17:48.662579","exception":false,"start_time":"2021-12-06T05:17:13.631909","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize predictions","metadata":{"_cell_guid":"ca4676fe-6220-42db-a675-ef5c7203ab58","_uuid":"cf363b48-1109-4bd9-af10-c25993826511","papermill":{"duration":0.039784,"end_time":"2021-12-06T05:17:48.782618","exception":false,"start_time":"2021-12-06T05:17:48.742834","status":"completed"},"tags":[]}},{"cell_type":"code","source":"cls_i = 0\nbad_pred_dict_list = bad_pred_dict_list_list[cls_i]\nfor bad_pred_dict in bad_pred_dict_list:\n    figure, axs = plt.subplots(1,3, figsize=(40,30))\n    figure.suptitle(f\"class: {cls_i}, score: {bad_pred_dict['score']}\")\n    axs[0].imshow(cv2.imread(bad_pred_dict['image_path']))\n    axs[0].axis(\"off\")\n    axs[1].imshow(bad_pred_dict['pred_mask'])\n    axs[1].axis(\"off\")\n    axs[2].imshow(bad_pred_dict['true_mask'])\n    axs[2].axis(\"off\")","metadata":{"_cell_guid":"51911cf9-2f35-4275-9fda-22b563154c2a","_uuid":"b1da8490-6762-4e81-a6cb-d4476a835630","collapsed":false,"execution":{"iopub.execute_input":"2021-12-06T05:17:48.893512Z","iopub.status.busy":"2021-12-06T05:17:48.892237Z","iopub.status.idle":"2021-12-06T05:17:56.910515Z","shell.execute_reply":"2021-12-06T05:17:56.911068Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":8.087789,"end_time":"2021-12-06T05:17:56.911253","exception":false,"start_time":"2021-12-06T05:17:48.823464","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cls_i = 1\nbad_pred_dict_list = bad_pred_dict_list_list[cls_i]\nfor bad_pred_dict in bad_pred_dict_list:\n    figure, axs = plt.subplots(1,3, figsize=(40,30))\n    figure.suptitle(f\"class: {cls_i}, score: {bad_pred_dict['score']}\")\n    axs[0].imshow(cv2.imread(bad_pred_dict['image_path']))\n    axs[0].axis(\"off\")\n    axs[1].imshow(bad_pred_dict['pred_mask'])\n    axs[1].axis(\"off\")\n    axs[2].imshow(bad_pred_dict['true_mask'])\n    axs[2].axis(\"off\")","metadata":{"execution":{"iopub.execute_input":"2021-12-06T05:17:57.315892Z","iopub.status.busy":"2021-12-06T05:17:57.314379Z","iopub.status.idle":"2021-12-06T05:18:05.174576Z","shell.execute_reply":"2021-12-06T05:18:05.175178Z"},"papermill":{"duration":8.080323,"end_time":"2021-12-06T05:18:05.175389","exception":false,"start_time":"2021-12-06T05:17:57.095066","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cls_i = 2\nbad_pred_dict_list = bad_pred_dict_list_list[cls_i]\nfor bad_pred_dict in bad_pred_dict_list:\n    figure, axs = plt.subplots(1,3, figsize=(40,30))\n    figure.suptitle(f\"class: {cls_i}, score: {bad_pred_dict['score']}\")\n    axs[0].imshow(cv2.imread(bad_pred_dict['image_path']))\n    axs[0].axis(\"off\")\n    axs[1].imshow(bad_pred_dict['pred_mask'])\n    axs[1].axis(\"off\")\n    axs[2].imshow(bad_pred_dict['true_mask'])\n    axs[2].axis(\"off\")","metadata":{"execution":{"iopub.execute_input":"2021-12-06T05:18:05.816013Z","iopub.status.busy":"2021-12-06T05:18:05.806278Z","iopub.status.idle":"2021-12-06T05:18:14.277455Z","shell.execute_reply":"2021-12-06T05:18:14.278156Z"},"papermill":{"duration":8.791103,"end_time":"2021-12-06T05:18:14.278328","exception":false,"start_time":"2021-12-06T05:18:05.487225","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{"_cell_guid":"a43011a3-d916-4c78-800f-8e72c1265dbd","_uuid":"dade9983-c2fb-40eb-bc2f-9bebe90b41b7","papermill":{"duration":0.407782,"end_time":"2021-12-06T05:18:15.107691","exception":false,"start_time":"2021-12-06T05:18:14.699909","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import os\n\nos.system(f'cp {cfg.MODEL.WEIGHTS} ./')\nos.system(f'cp ../input/sartorius-transfer-learning-train-test-model/output/model_0008711.pth ./')\nos.system(f'cp ../input/sartorius-transfer-learning-train-test-model/output/model_0008469.pth ./')","metadata":{"_cell_guid":"4e9f97a0-6a2b-4cb1-a62b-53a4a1eeb1a2","_uuid":"8aef02c4-461e-456d-bb5f-7e14a3263a11","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.4077,"end_time":"2021-12-06T05:18:15.943479","exception":false,"start_time":"2021-12-06T05:18:15.535779","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# References\n* https://www.kaggle.com/slawekbiel/positive-score-with-detectron-3-3-inference","metadata":{"_cell_guid":"c50a2b59-c250-4910-a125-0fb3d570547b","_uuid":"9bb7894f-3233-4903-9138-1e8c17bfb321","papermill":{"duration":0.421656,"end_time":"2021-12-06T05:18:16.78202","exception":false,"start_time":"2021-12-06T05:18:16.360364","status":"completed"},"tags":[]}}]}