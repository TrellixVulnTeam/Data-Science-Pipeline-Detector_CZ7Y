{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip -q install 'git+https://github.com/facebookresearch/detectron2.git'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import detectron2\nfrom pathlib import Path\nimport random, cv2, os\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pycocotools.mask as mask_util\n# import some common detectron2 utilities\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor, DefaultTrainer\nfrom detectron2.config import get_cfg\nfrom detectron2.utils.visualizer import Visualizer, ColorMode\nfrom detectron2.data import MetadataCatalog, DatasetCatalog\nfrom detectron2.data.datasets import register_coco_instances\nfrom detectron2.utils.logger import setup_logger\nfrom detectron2.evaluation.evaluator import DatasetEvaluator\nfrom detectron2.engine import BestCheckpointer\nfrom detectron2.checkpoint import DetectionCheckpointer\nsetup_logger()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.distributed as dist\ndist.init_process_group('gloo', init_method='file:///tmp/somefile', rank=0, world_size=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataDir=''\ncfg = get_cfg()\ncfg.INPUT.MASK_FORMAT='bitmask'\nregister_coco_instances('data_train',{}, '../input/k-fold-3-crossvalidation-coco-dataset-generator/coco_cell_train_fold2.json', dataDir)\nregister_coco_instances('data_val',{},'../input/k-fold-3-crossvalidation-coco-dataset-generator/coco_cell_valid_fold2.json', dataDir)\nmetadata = MetadataCatalog.get('data_train')\ntrain_ds = DatasetCatalog.get('data_train')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_ds[42] ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# d = train_ds[100]\n# img = cv2.imread(d[\"file_name\"])\n# visualizer = Visualizer(img[:, :, ::-1], metadata=metadata)\n# out = visualizer.draw_dataset_dict(d)\n# plt.figure(figsize = (20,15))\n# plt.imshow(out.get_image()[:, :, ::-1]);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def precision_at(threshold, iou):\n    matches = iou > threshold\n    true_positives = np.sum(matches, axis=1) == 1  # Correct objects\n    false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n    false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n    return np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n\ndef score(pred, targ):\n    pred_masks = pred['instances'].pred_masks.cpu().numpy()\n    enc_preds = [mask_util.encode(np.asarray(p, order='F')) for p in pred_masks]\n    enc_targs = list(map(lambda x:x['segmentation'], targ))\n    ious = mask_util.iou(enc_preds, enc_targs, [0]*len(enc_targs))\n    prec = []\n    for t in np.arange(0.5, 1.0, 0.05):\n        tp, fp, fn = precision_at(t, ious)\n        p = tp / (tp + fp + fn)\n        prec.append(p)\n    return np.mean(prec)\n\nclass MAPIOUEvaluator(DatasetEvaluator):\n    def __init__(self, dataset_name):\n        dataset_dicts = DatasetCatalog.get(dataset_name)\n        self.annotations_cache = {item['image_id']:item['annotations'] for item in dataset_dicts}\n            \n    def reset(self):\n        self.scores = []\n\n    def process(self, inputs, outputs):\n        for inp, out in zip(inputs, outputs):\n            if len(out['instances']) == 0:\n                self.scores.append(0)    \n            else:\n                targ = self.annotations_cache[inp['image_id']]\n                self.scores.append(score(out, targ))\n\n    def evaluate(self):\n        return {\"MaP IoU\": np.mean(self.scores)}\n\nclass Trainer(DefaultTrainer):\n    @classmethod\n    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n        return MAPIOUEvaluator(dataset_name)\n    def build_hooks(self):\n\n        # copy of cfg\n        cfg = self.cfg.clone()\n\n        # build the original model hooks\n        hooks = super().build_hooks()\n\n        # add the best checkpointer hook\n        hooks.insert(-1, BestCheckpointer(cfg.TEST.EVAL_PERIOD, \n                                         DetectionCheckpointer(self.model, cfg.OUTPUT_DIR),\n                                         \"MaP IoU\",\n                                         \"max\",\n                                         ))\n        return hooks\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\"))\ncfg.DATASETS.TRAIN = (\"data_train\",)\ncfg.DATASETS.TEST = (\"data_val\",)\ncfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\")  # Let training initialize from model zoo\ncfg.SOLVER.IMS_PER_BATCH = 2\ncfg.DATALOADER.NUM_WORKERS = 2\ncfg.SOLVER.BASE_LR = 0.0004  \ncfg.SOLVER.MAX_ITER = 10000   \ncfg.SOLVER.STEPS = []        \ncfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   \ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 3  \ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = .5\ncfg.TEST.EVAL_PERIOD = 2000  # Once per epoch\ncfg.SOLVER.CHECKPOINT_PERIOD = 2000\n\nos.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\ntrainer = Trainer(cfg) \ntrainer.resume_or_load(resume=False)\ntrainer.train()","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n# cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set a custom testing threshold\n# predictor = DefaultPredictor(cfg)\n# dataset_dicts = DatasetCatalog.get('data_val')\n# outs = []\n# for d in random.sample(dataset_dicts, 3):    \n#     im = cv2.imread(d[\"file_name\"])\n#     outputs = predictor(im)  # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n#     v = Visualizer(im[:, :, ::-1],\n#                    metadata = MetadataCatalog.get('data_train'), \n                    \n#                    instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n#     )\n#     out_pred = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n#     visualizer = Visualizer(im[:, :, ::-1], metadata=MetadataCatalog.get('data_train'))\n#     out_target = visualizer.draw_dataset_dict(d)\n#     outs.append(out_pred)\n#     outs.append(out_target)\n# _,axs = plt.subplots(len(outs)//2,2,figsize=(40,45))\n# for ax, out in zip(axs.reshape(-1), outs):\n#     ax.imshow(out.get_image()[:, :, ::-1])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}