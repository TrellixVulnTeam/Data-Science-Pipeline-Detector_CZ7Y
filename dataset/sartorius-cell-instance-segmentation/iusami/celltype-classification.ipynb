{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"execution":{"iopub.status.busy":"2021-12-13T12:48:21.066681Z","iopub.execute_input":"2021-12-13T12:48:21.066986Z","iopub.status.idle":"2021-12-13T12:48:23.965808Z","shell.execute_reply.started":"2021-12-13T12:48:21.066901Z","shell.execute_reply":"2021-12-13T12:48:23.965104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf; print(f\"\\t\\tâ€“ TENSORFLOW VERSION: {tf.__version__}\");","metadata":{"execution":{"iopub.status.busy":"2021-12-13T12:48:23.968729Z","iopub.execute_input":"2021-12-13T12:48:23.968939Z","iopub.status.idle":"2021-12-13T12:48:28.170578Z","shell.execute_reply.started":"2021-12-13T12:48:23.968915Z","shell.execute_reply":"2021-12-13T12:48:28.169858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"\\n... ACCELERATOR SETUP STARTING ...\\n\")\n\n# Detect hardware, return appropriate distribution strategy\ntry:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    TPU = tf.distribute.cluster_resolver.TPUClusterResolver()  \nexcept ValueError:\n    TPU = None\n\nif TPU:\n    print(f\"\\n... RUNNING ON TPU - {TPU.master()}...\")\n    tf.config.experimental_connect_to_cluster(TPU)\n    tf.tpu.experimental.initialize_tpu_system(TPU)\n    strategy = tf.distribute.experimental.TPUStrategy(TPU)\nelse:\n    print(f\"\\n... RUNNING ON CPU/GPU ...\")\n    # Yield the default distribution strategy in Tensorflow\n    #   --> Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy() \n\n# What Is a Replica?\n#    --> A single Cloud TPU device consists of FOUR chips, each of which has TWO TPU cores. \n#    --> Therefore, for efficient utilization of Cloud TPU, a program should make use of each of the EIGHT (4x2) cores. \n#    --> Each replica is essentially a copy of the training graph that is run on each core and \n#        trains a mini-batch containing 1/8th of the overall batch size\nN_REPLICAS = strategy.num_replicas_in_sync\n    \nprint(f\"... # OF REPLICAS: {N_REPLICAS} ...\\n\")\nprint(f\"\\n... ACCELERATOR SETUP COMPLTED ...\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-12-13T12:48:28.172014Z","iopub.execute_input":"2021-12-13T12:48:28.17227Z","iopub.status.idle":"2021-12-13T12:48:28.186784Z","shell.execute_reply.started":"2021-12-13T12:48:28.172237Z","shell.execute_reply":"2021-12-13T12:48:28.185952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"\\n... DATA ACCESS SETUP STARTED ...\\n\")\n\nif TPU:\n    # Google Cloud Dataset path to training and validation images\n    DATA_DIR = KaggleDatasets().get_gcs_path('sartorius-cell-instance-segmentation')\n    save_locally = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\nelse:\n    # Local path to training and validation images\n    DATA_DIR = \"/kaggle/input/sartorius-cell-instance-segmentation\"\n    save_locally = None\n    \nprint(f\"\\n... DATA DIRECTORY PATH IS:\\n\\t--> {DATA_DIR}\")\n\nprint(f\"\\n... IMMEDIATE CONTENTS OF DATA DIRECTORY IS:\")\nfor file in tf.io.gfile.glob(os.path.join(DATA_DIR, \"*\")): print(f\"\\t--> {file}\")\n\n    \nprint(\"\\n\\n... DATA ACCESS SETUP COMPLETED ...\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-12-13T12:48:28.189036Z","iopub.execute_input":"2021-12-13T12:48:28.189285Z","iopub.status.idle":"2021-12-13T12:48:28.203673Z","shell.execute_reply.started":"2021-12-13T12:48:28.18925Z","shell.execute_reply":"2021-12-13T12:48:28.202952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"\\n... BASIC DATA SETUP STARTING ...\\n\\n\")\n\nprint(\"\\n... SET PATH INFORMATION ..\\n\")\nSEG_DIR = \"/kaggle/input/sartorius-segmentation-train-mask-dataset-npz\"\nLC_DIR = os.path.join(DATA_DIR, \"LIVECell_dataset_2021\")\nLC_ANN_DIR = os.path.join(LC_DIR, \"annotations\")\nLC_IMG_DIR = os.path.join(LC_DIR, \"images\")\nTRAIN_DIR = os.path.join(DATA_DIR, \"train\")\nTEST_DIR = os.path.join(DATA_DIR, \"test\")\nSEMI_DIR = os.path.join(DATA_DIR, \"train_semi_supervised\")\n\nprint(\"\\n... TRAIN DATAFRAME ...\\n\")\n\n# FIX THE TRAIN DATAFRAME (GROUP THE RLEs TOGETHER)\nTRAIN_CSV = os.path.join(DATA_DIR, \"train.csv\")\ntrain_df = pd.read_csv(TRAIN_CSV)\ndisplay(train_df)\n\nprint(\"\\n... SS DATAFRAME ..\\n\")\nSS_CSV = os.path.join(DATA_DIR, \"sample_submission.csv\")\nss_df = pd.read_csv(SS_CSV)\nss_df[\"img_path\"] = ss_df[\"id\"].apply(lambda x: os.path.join(TEST_DIR, x+\".png\")) # Capture Image Path As Well\ndisplay(ss_df)\n\nCELL_TYPES = list(train_df.cell_type.unique())\nFIRST_SHSY5Y_IDX = 0\nFIRST_ASTRO_IDX  = 1\nFIRST_CORT_IDX   = 2\n\n# This is required for plotting so that the smaller distributions get plotted on top\nARB_SORT_MAP = {\"astro\":0, \"shsy5y\":1, \"cort\":2}\n\nprint(\"\\n... CELL TYPES ..\")\nfor x in CELL_TYPES: print(f\"\\t--> {x}\")\n    \nprint(\"\\n\\n... BASIC DATA SETUP FINISHING ...\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-12-13T12:48:28.204907Z","iopub.execute_input":"2021-12-13T12:48:28.205255Z","iopub.status.idle":"2021-12-13T12:48:28.811589Z","shell.execute_reply.started":"2021-12-13T12:48:28.205214Z","shell.execute_reply":"2021-12-13T12:48:28.810329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# License: BSD\n# Author: Sasank Chilamkurthy\n\nfrom __future__ import print_function, division\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport copy\n\nplt.ion()   # interactive mode","metadata":{"execution":{"iopub.status.busy":"2021-12-13T12:48:28.81288Z","iopub.execute_input":"2021-12-13T12:48:28.813097Z","iopub.status.idle":"2021-12-13T12:48:30.391855Z","shell.execute_reply.started":"2021-12-13T12:48:28.813063Z","shell.execute_reply":"2021-12-13T12:48:30.391181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_csv = pd.read_csv(\"../input/sartorius-cell-instance-segmentation/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-12-13T12:48:30.39323Z","iopub.execute_input":"2021-12-13T12:48:30.393481Z","iopub.status.idle":"2021-12-13T12:48:30.677745Z","shell.execute_reply.started":"2021-12-13T12:48:30.393447Z","shell.execute_reply":"2021-12-13T12:48:30.677047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_csv.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-13T12:48:30.678956Z","iopub.execute_input":"2021-12-13T12:48:30.679205Z","iopub.status.idle":"2021-12-13T12:48:30.69439Z","shell.execute_reply.started":"2021-12-13T12:48:30.679173Z","shell.execute_reply":"2021-12-13T12:48:30.69259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_csv_id_cell = train_csv[[\"id\",\"cell_type\"]]","metadata":{"execution":{"iopub.status.busy":"2021-12-13T12:48:30.695849Z","iopub.execute_input":"2021-12-13T12:48:30.696785Z","iopub.status.idle":"2021-12-13T12:48:30.70487Z","shell.execute_reply.started":"2021-12-13T12:48:30.696743Z","shell.execute_reply":"2021-12-13T12:48:30.703962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import glob","metadata":{"execution":{"iopub.status.busy":"2021-12-13T12:48:30.708672Z","iopub.execute_input":"2021-12-13T12:48:30.70892Z","iopub.status.idle":"2021-12-13T12:48:30.712905Z","shell.execute_reply.started":"2021-12-13T12:48:30.708862Z","shell.execute_reply":"2021-12-13T12:48:30.712004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_path = glob.glob(\"../input/sartorius-cell-instance-segmentation/train/*\")\nlen(img_path)","metadata":{"execution":{"iopub.status.busy":"2021-12-13T12:48:30.714346Z","iopub.execute_input":"2021-12-13T12:48:30.714902Z","iopub.status.idle":"2021-12-13T12:48:30.727843Z","shell.execute_reply.started":"2021-12-13T12:48:30.714866Z","shell.execute_reply":"2021-12-13T12:48:30.726954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder","metadata":{"execution":{"iopub.status.busy":"2021-12-13T12:48:30.729485Z","iopub.execute_input":"2021-12-13T12:48:30.729909Z","iopub.status.idle":"2021-12-13T12:48:31.261Z","shell.execute_reply.started":"2021-12-13T12:48:30.729876Z","shell.execute_reply":"2021-12-13T12:48:31.260277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_img_annotation = train_csv_id_cell[~train_csv_id_cell.duplicated()].reset_index(drop=True)\ntrain_img_annotation[\"id\"] = train_img_annotation[\"id\"].apply(lambda x:x+\".png\")\nencoder = LabelEncoder()\nencoder.fit(train_img_annotation[\"cell_type\"].unique())\ntrain_img_annotation[\"cell_type\"] = encoder.transform(train_img_annotation[\"cell_type\"])\ntrain_img_annotation","metadata":{"execution":{"iopub.status.busy":"2021-12-13T12:48:31.26232Z","iopub.execute_input":"2021-12-13T12:48:31.262577Z","iopub.status.idle":"2021-12-13T12:48:31.292798Z","shell.execute_reply.started":"2021-12-13T12:48:31.262543Z","shell.execute_reply":"2021-12-13T12:48:31.292116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_img_annotation.to_csv(\"../working/train_img_annotaion.csv\", index=None)","metadata":{"execution":{"iopub.status.busy":"2021-12-13T12:48:31.294078Z","iopub.execute_input":"2021-12-13T12:48:31.294596Z","iopub.status.idle":"2021-12-13T12:48:31.302322Z","shell.execute_reply.started":"2021-12-13T12:48:31.294559Z","shell.execute_reply":"2021-12-13T12:48:31.301564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch import Tensor","metadata":{"execution":{"iopub.status.busy":"2021-12-13T12:48:31.303908Z","iopub.execute_input":"2021-12-13T12:48:31.304291Z","iopub.status.idle":"2021-12-13T12:48:31.308564Z","shell.execute_reply.started":"2021-12-13T12:48:31.304252Z","shell.execute_reply":"2021-12-13T12:48:31.307829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision.io import read_image\nfrom torch.utils.data import Dataset\nfrom torchvision.io import ImageReadMode\n\nclass CustomImageDataset(Dataset):\n    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n        self.img_labels = pd.read_csv(annotations_file)\n        self.img_dir = img_dir\n        self.transform = transform\n        self.target_transform = target_transform\n        self.classes = self.img_labels[\"cell_type\"]\n\n    def __len__(self):\n        return len(self.img_labels)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n        image = read_image(img_path,ImageReadMode.RGB)\n        label = self.img_labels.iloc[idx, 1]\n#         print(type(label))\n        if self.transform:\n            image = self.transform(image)\n        if self.target_transform:\n            label = self.target_transform(label)\n#         print(\"labeltype:\",type(label))\n#         print(\"label:\", label)\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2021-12-13T12:48:31.309922Z","iopub.execute_input":"2021-12-13T12:48:31.310462Z","iopub.status.idle":"2021-12-13T12:48:31.320601Z","shell.execute_reply.started":"2021-12-13T12:48:31.310423Z","shell.execute_reply":"2021-12-13T12:48:31.319784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_transforms = {\n    'train': transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}","metadata":{"execution":{"iopub.status.busy":"2021-12-13T12:48:31.321683Z","iopub.execute_input":"2021-12-13T12:48:31.322056Z","iopub.status.idle":"2021-12-13T12:48:31.330698Z","shell.execute_reply.started":"2021-12-13T12:48:31.322019Z","shell.execute_reply":"2021-12-13T12:48:31.329876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_transforms = transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ])","metadata":{"execution":{"iopub.status.busy":"2021-12-13T12:48:31.331763Z","iopub.execute_input":"2021-12-13T12:48:31.332515Z","iopub.status.idle":"2021-12-13T12:48:31.340178Z","shell.execute_reply.started":"2021-12-13T12:48:31.332479Z","shell.execute_reply":"2021-12-13T12:48:31.339418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = CustomImageDataset(\"../working/train_img_annotaion.csv\", \"../input/sartorius-cell-instance-segmentation/train/\")\n# dataset = CustomImageDataset(\"../working/train_img_annotaion.csv\", \"../input/sartorius-cell-instance-segmentation/train/\", transform=data_transforms)","metadata":{"execution":{"iopub.status.busy":"2021-12-13T12:48:31.342956Z","iopub.execute_input":"2021-12-13T12:48:31.34487Z","iopub.status.idle":"2021-12-13T12:48:31.354385Z","shell.execute_reply.started":"2021-12-13T12:48:31.344826Z","shell.execute_reply":"2021-12-13T12:48:31.353626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.img_labels","metadata":{"execution":{"iopub.status.busy":"2021-12-13T12:48:31.356829Z","iopub.execute_input":"2021-12-13T12:48:31.358442Z","iopub.status.idle":"2021-12-13T12:48:31.368787Z","shell.execute_reply.started":"2021-12-13T12:48:31.358404Z","shell.execute_reply":"2021-12-13T12:48:31.368006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_samples = len(dataset) # n_samples is 60000\ntrain_size = int(len(dataset) * 0.8) # train_size is 48000\ntest_size = n_samples - train_size # val_size is 48000\nval_size = int(train_size*0.2)\ntrain_last_size = train_size - val_size\ntrain_last_size, test_size, val_size","metadata":{"execution":{"iopub.status.busy":"2021-12-13T12:48:31.369877Z","iopub.execute_input":"2021-12-13T12:48:31.370631Z","iopub.status.idle":"2021-12-13T12:48:31.380369Z","shell.execute_reply.started":"2021-12-13T12:48:31.37059Z","shell.execute_reply":"2021-12-13T12:48:31.37969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import random_split","metadata":{"execution":{"iopub.status.busy":"2021-12-13T12:48:31.382167Z","iopub.execute_input":"2021-12-13T12:48:31.382902Z","iopub.status.idle":"2021-12-13T12:48:31.387329Z","shell.execute_reply.started":"2021-12-13T12:48:31.382866Z","shell.execute_reply":"2021-12-13T12:48:31.386588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(dataset), train_size, test_size","metadata":{"execution":{"iopub.status.busy":"2021-12-13T12:48:31.388786Z","iopub.execute_input":"2021-12-13T12:48:31.389071Z","iopub.status.idle":"2021-12-13T12:48:31.398431Z","shell.execute_reply.started":"2021-12-13T12:48:31.389039Z","shell.execute_reply":"2021-12-13T12:48:31.3977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_all_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\ntrain_dataset, val_dataset = torch.utils.data.random_split(train_all_dataset, [train_last_size, val_size])","metadata":{"execution":{"iopub.status.busy":"2021-12-13T12:48:31.400775Z","iopub.execute_input":"2021-12-13T12:48:31.400977Z","iopub.status.idle":"2021-12-13T12:48:31.417149Z","shell.execute_reply.started":"2021-12-13T12:48:31.400949Z","shell.execute_reply":"2021-12-13T12:48:31.416497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_dataset)","metadata":{"execution":{"iopub.status.busy":"2021-12-13T12:48:31.418353Z","iopub.execute_input":"2021-12-13T12:48:31.418589Z","iopub.status.idle":"2021-12-13T12:48:31.423955Z","shell.execute_reply.started":"2021-12-13T12:48:31.418557Z","shell.execute_reply":"2021-12-13T12:48:31.423165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = '../input/sartorius-cell-instance-segmentation/'\nimage_datasets = {\"train\":train_dataset, \"val\":val_dataset}\ndataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n                                             shuffle=True, num_workers=2)\n              for x in ['train', 'val']}\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\nclass_names = image_datasets['train'].dataset.dataset.classes\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2021-12-13T12:48:31.426768Z","iopub.execute_input":"2021-12-13T12:48:31.427413Z","iopub.status.idle":"2021-12-13T12:48:31.470538Z","shell.execute_reply.started":"2021-12-13T12:48:31.427375Z","shell.execute_reply":"2021-12-13T12:48:31.46976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=4, num_workers=2)\ntest_datasize = len(test_dataset)","metadata":{"execution":{"iopub.status.busy":"2021-12-13T13:00:21.309697Z","iopub.execute_input":"2021-12-13T13:00:21.310007Z","iopub.status.idle":"2021-12-13T13:00:21.319083Z","shell.execute_reply.started":"2021-12-13T13:00:21.309974Z","shell.execute_reply":"2021-12-13T13:00:21.318298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_datasets[\"train\"].dataset.dataset.classes","metadata":{"execution":{"iopub.status.busy":"2021-12-13T12:48:31.471719Z","iopub.execute_input":"2021-12-13T12:48:31.472071Z","iopub.status.idle":"2021-12-13T12:48:31.482639Z","shell.execute_reply.started":"2021-12-13T12:48:31.472038Z","shell.execute_reply":"2021-12-13T12:48:31.481734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def imshow(inp, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    fig,ax = plt.subplots(1,1,figsize=(15,10))\n    ax.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)  # pause a bit so that plots are updated\n\n\n# Get a batch of training data\ninputs, classes = next(iter(dataloaders['train']))\n\n# Make a grid from batch\nout = torchvision.utils.make_grid(inputs)\n\n# imshow(out, title=[class_names[x] for x in classes])\nimshow(out)","metadata":{"execution":{"iopub.status.busy":"2021-12-13T12:48:31.487186Z","iopub.execute_input":"2021-12-13T12:48:31.487436Z","iopub.status.idle":"2021-12-13T12:48:32.392051Z","shell.execute_reply.started":"2021-12-13T12:48:31.48741Z","shell.execute_reply":"2021-12-13T12:48:32.391335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs.shape, classes","metadata":{"execution":{"iopub.status.busy":"2021-12-13T12:48:32.394523Z","iopub.execute_input":"2021-12-13T12:48:32.395007Z","iopub.status.idle":"2021-12-13T12:48:32.404103Z","shell.execute_reply.started":"2021-12-13T12:48:32.394963Z","shell.execute_reply":"2021-12-13T12:48:32.403171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(inputs[0,:,:,:].reshape(520,704,3))","metadata":{"execution":{"iopub.status.busy":"2021-12-13T12:48:32.405897Z","iopub.execute_input":"2021-12-13T12:48:32.406167Z","iopub.status.idle":"2021-12-13T12:48:32.697773Z","shell.execute_reply.started":"2021-12-13T12:48:32.406131Z","shell.execute_reply":"2021-12-13T12:48:32.697113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device, dtype=torch.float)/255\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n            if phase == 'train':\n                scheduler.step()\n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-12-13T12:48:32.699115Z","iopub.execute_input":"2021-12-13T12:48:32.699594Z","iopub.status.idle":"2021-12-13T12:48:32.712871Z","shell.execute_reply.started":"2021-12-13T12:48:32.699559Z","shell.execute_reply":"2021-12-13T12:48:32.712154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize_model(model, num_images=6):\n    was_training = model.training\n    model.eval()\n    images_so_far = 0\n    fig = plt.figure()\n\n    with torch.no_grad():\n        for i, (inputs, labels) in enumerate(dataloaders['val']):\n            inputs = inputs.to(device, dtype=torch.float)/255\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n\n            for j in range(inputs.size()[0]):\n                images_so_far += 1\n                ax = plt.subplot(num_images//2, 2, images_so_far)\n                ax.axis('off')\n                ax.set_title('predicted: {}'.format(encoder.classes_[class_names[preds[j].item()]]))\n                imshow(inputs.cpu().data[j])\n\n                if images_so_far == num_images:\n                    model.train(mode=was_training)\n                    return\n        model.train(mode=was_training)","metadata":{"execution":{"iopub.status.busy":"2021-12-13T12:48:32.714199Z","iopub.execute_input":"2021-12-13T12:48:32.71449Z","iopub.status.idle":"2021-12-13T12:48:32.726106Z","shell.execute_reply.started":"2021-12-13T12:48:32.714455Z","shell.execute_reply":"2021-12-13T12:48:32.72516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"","metadata":{"execution":{"iopub.status.busy":"2021-12-13T12:48:32.727547Z","iopub.execute_input":"2021-12-13T12:48:32.727936Z","iopub.status.idle":"2021-12-13T12:48:32.735037Z","shell.execute_reply.started":"2021-12-13T12:48:32.727901Z","shell.execute_reply":"2021-12-13T12:48:32.734217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_ft = models.resnet18(pretrained=True)\nnum_ftrs = model_ft.fc.in_features\n# Here the size of each output sample is set to 2.\n# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\nmodel_ft.fc = nn.Linear(num_ftrs, 3)\n\nmodel_ft = model_ft.to(device)\n\ncriterion = nn.CrossEntropyLoss()\n\n# Observe that all parameters are being optimized\noptimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n\n# Decay LR by a factor of 0.1 every 7 epochs\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)","metadata":{"execution":{"iopub.status.busy":"2021-12-13T12:48:32.736099Z","iopub.execute_input":"2021-12-13T12:48:32.73636Z","iopub.status.idle":"2021-12-13T12:48:40.114459Z","shell.execute_reply.started":"2021-12-13T12:48:32.736327Z","shell.execute_reply":"2021-12-13T12:48:40.113706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n                       num_epochs=25)","metadata":{"execution":{"iopub.status.busy":"2021-12-13T12:48:40.115803Z","iopub.execute_input":"2021-12-13T12:48:40.116053Z","iopub.status.idle":"2021-12-13T12:52:48.441779Z","shell.execute_reply.started":"2021-12-13T12:48:40.11602Z","shell.execute_reply":"2021-12-13T12:52:48.440214Z"},"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_model(model_ft)","metadata":{"execution":{"iopub.status.busy":"2021-12-13T12:52:48.44334Z","iopub.execute_input":"2021-12-13T12:52:48.443611Z","iopub.status.idle":"2021-12-13T12:52:53.816845Z","shell.execute_reply.started":"2021-12-13T12:52:48.443573Z","shell.execute_reply":"2021-12-13T12:52:53.816023Z"},"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def eval_model(model, criterion, optimizer, scheduler):\n    since = time.time()\n\n    best_acc = 0.0\n\n    # Each epoch has a training and validation phase\n    model.eval()   # Set model to evaluate mode\n\n    running_loss = 0.0\n    running_corrects = 0\n\n    # Iterate over data.\n    for ct, (inputs, labels) in enumerate(test_dataloader):\n        print(ct)\n        inputs = inputs.to(device, dtype=torch.float)/255\n        labels = labels.to(device)\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward\n        outputs = model(inputs)\n        _, preds = torch.max(outputs, 1)\n        loss = criterion(outputs, labels)\n\n\n        # statistics\n        running_loss += loss.item() * inputs.size(0)\n        running_corrects += torch.sum(preds == labels.data)\n        if np.array(labels.cpu()).all()!=np.array(preds.cpu()).all():\n            print(\"true={},pred={}\".format(labels, preds))\n\n    epoch_loss = running_loss / test_datasize\n    epoch_acc = running_corrects.double() / test_datasize\n\n    print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n        \"test\", epoch_loss, epoch_acc))\n\n\n    print()\n\n    time_elapsed = time.time() - since\n    print('eval complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed // 60, time_elapsed % 60))\n    print('test Acc: {:4f}'.format(epoch_acc))\n\n    # load best model weights\n    return ","metadata":{"execution":{"iopub.status.busy":"2021-12-13T13:23:48.742244Z","iopub.execute_input":"2021-12-13T13:23:48.742824Z","iopub.status.idle":"2021-12-13T13:23:49.00233Z","shell.execute_reply.started":"2021-12-13T13:23:48.742785Z","shell.execute_reply":"2021-12-13T13:23:49.000499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eval_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler)","metadata":{"execution":{"iopub.status.busy":"2021-12-13T13:23:49.672644Z","iopub.execute_input":"2021-12-13T13:23:49.672909Z","iopub.status.idle":"2021-12-13T13:23:51.128663Z","shell.execute_reply.started":"2021-12-13T13:23:49.672879Z","shell.execute_reply":"2021-12-13T13:23:51.127125Z"},"trusted":true},"execution_count":null,"outputs":[]}]}