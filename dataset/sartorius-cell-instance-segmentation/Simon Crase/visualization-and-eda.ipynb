{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Script created to sort out a few technical objectives\n\n\\#|Objective|Status\n-|-----------------------------------------|----------------------------------------\n1|Verify that I can write _submission.csv_ in correct format|Created dummy _submission.csv,_ which is accepted with a zero score, so I know format is OK\n2|Figure out organization of training data|Verified that every _id_ in _train.csv_ matches one image in _train_ folder\n3|Verify that I can read training images|Read and display. Seismic colour map looks best\n4|Study cell types to determine whether we should segment each type separately. This would entail a classification step where we learn the cell type|On hold: I expect that I'd need to segment first.\n5|Parse and plot annotations|Working\n6|Downsample images|Plot now shows rescale and downsize\n7|Fourier Transform images|TBD\n","metadata":{}},{"cell_type":"markdown","source":"## Set up libraries","metadata":{}},{"cell_type":"code","source":"from glob              import escape,glob\nfrom matplotlib.pyplot import figure, imread, get_cmap\nfrom numpy             import float32, zeros\nfrom os                import walk\nfrom os.path           import basename, join\nfrom pandas            import read_csv, DataFrame\nfrom random            import sample, seed\nfrom skimage.transform import rescale, resize, downscale_local_mean","metadata":{"execution":{"iopub.status.busy":"2021-10-30T19:38:22.012842Z","iopub.execute_input":"2021-10-30T19:38:22.013171Z","iopub.status.idle":"2021-10-30T19:38:23.273014Z","shell.execute_reply.started":"2021-10-30T19:38:22.013138Z","shell.execute_reply":"2021-10-30T19:38:23.272241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Set up environment variables","metadata":{}},{"cell_type":"code","source":"DATA_PATH             = '../input/sartorius-cell-instance-segmentation'\nTRAIN_PATH            = join(DATA_PATH,'train')\nTRAIN_CSV_PATH        = join(DATA_PATH,'train.csv')\nTRAIN_SEMI_SUPERVISED = join(DATA_PATH,'train_semi_supervised')\nTEST_PATH             = join(DATA_PATH,'test')","metadata":{"execution":{"iopub.status.busy":"2021-10-30T19:35:03.177586Z","iopub.execute_input":"2021-10-30T19:35:03.177923Z","iopub.status.idle":"2021-10-30T19:35:03.181686Z","shell.execute_reply.started":"2021-10-30T19:35:03.177896Z","shell.execute_reply":"2021-10-30T19:35:03.180964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Set up Hyperparameters","metadata":{}},{"cell_type":"code","source":"VERIFY_CONSISTENCY  = True      # Disable this when we are in production\nCOLOUR_MAP          = 'seismic' # Established by trial and error\n                                # This colour mapo loks best to me - YMMV\nRANDOM_SEED         = None      # Used to intialize random number generator\n                                # set to None to use current system time\nPLOTS_PER_CELL_TYPE = 6         # Number of slids to plt for each cell type\n","metadata":{"execution":{"iopub.status.busy":"2021-10-30T19:35:03.197084Z","iopub.execute_input":"2021-10-30T19:35:03.198008Z","iopub.status.idle":"2021-10-30T19:35:03.20289Z","shell.execute_reply.started":"2021-10-30T19:35:03.197948Z","shell.execute_reply":"2021-10-30T19:35:03.202119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Initialize random number generator","metadata":{}},{"cell_type":"code","source":"if RANDOM_SEED==None:\n    seed()\nelse:\n    seed(RANDOM_SEED)","metadata":{"execution":{"iopub.status.busy":"2021-10-30T19:35:03.209038Z","iopub.execute_input":"2021-10-30T19:35:03.209799Z","iopub.status.idle":"2021-10-30T19:35:03.214433Z","shell.execute_reply.started":"2021-10-30T19:35:03.209755Z","shell.execute_reply":"2021-10-30T19:35:03.213921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Format of *train.csv*\n\nI have used an asterisk (*) to mark fields that are relevant to training.\n\nField||Description\n-----------------|-|----------------------------------------------------------------------\nid|*|Identifies image in training dataset. This is not a primary key, as the annotation may  span multiple records. However, the mapping from _id_ to any field other than annotation is 1 to 1.\nannotation|*|Run length encoded. We need to append annotations for all records belongint to one id. E.g. 118145 6 118849 7 119553 8 120257 8 120961 9 121665 10...\nwidth||Width of image in pixels\nheight||Height of image in pixels\ncell_type||_shsy5y_ or _astro_ or _cort_\nplate_time||Used with *sample_id* and *sample_date* to link into *train_semi_supervised*\nsample_date||Used with *sample_id* and *plate_time* to link into *train_semi_supervised*\nsample_id||Links into *train_semi_supervised*, along with *sample_date* and *plate_time*\nelapsed_timedelta||\n\n\n","metadata":{}},{"cell_type":"markdown","source":"## Read training data","metadata":{}},{"cell_type":"code","source":"target_data    = read_csv(TRAIN_CSV_PATH)\ntarget_ids     = sorted(target_data.id.unique())\ntraining_ids   = [name.split('.')[0] for _, _, names in walk(TRAIN_PATH) for name in sorted(names) ]","metadata":{"execution":{"iopub.status.busy":"2021-10-30T19:35:03.235119Z","iopub.execute_input":"2021-10-30T19:35:03.235542Z","iopub.status.idle":"2021-10-30T19:35:03.993901Z","shell.execute_reply.started":"2021-10-30T19:35:03.2355Z","shell.execute_reply":"2021-10-30T19:35:03.993044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Construct mapping from id to annotations","metadata":{}},{"cell_type":"code","source":"def accumulate(id,annotation):\n    def flatten(xss):\n        return [x for xs in xss for x in xs]\n    def parse(annot):\n        xs = [int(x) for x in annot.split()]\n        return [(xs[i],xs[i+1]) for i in range(0,len(xs),2)]\n \n    return (id,sorted(flatten([parse(a) for a in annotation])))\n\naccumulated_data = [accumulate(id,row.annotation) for id,row in target_data.groupby(['id'])]\ndf_targets       = DataFrame(list(zip([id for id,_ in accumulated_data],\n                                     [a for _,a in accumulated_data])),\n                    columns=['id','annotations'])\n","metadata":{"execution":{"iopub.status.busy":"2021-10-30T19:35:03.995439Z","iopub.execute_input":"2021-10-30T19:35:03.995688Z","iopub.status.idle":"2021-10-30T19:35:05.965806Z","shell.execute_reply.started":"2021-10-30T19:35:03.995661Z","shell.execute_reply":"2021-10-30T19:35:05.964976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test Hypothesis\n\nEvery id in train.csv matches one image in train folder. This code block verifies that this is correct.","metadata":{}},{"cell_type":"code","source":"if VERIFY_CONSISTENCY:\n    i = 0\n    j = 0\n    assert (len(target_ids) ==len(training_ids))\n    while i<len(target_ids) and j <len(training_ids):\n        if target_ids[i]==training_ids[j]:\n            i += 1\n            j += 1\n        elif target_ids[i]<training_ids[j]:\n            print (f'Mismatch {i} {target_ids[i]} {j} {training_ids[j]}')\n            i += 1\n        else: # target_ids[i]>training_ids[j]\n            print (f'Mismatch {i} {target_ids[i]} {j} {training_ids[j]}')\n            j += 1\n    assert(i==j)\n    print (f'All {i} target ids from CSV file match the training images')","metadata":{"execution":{"iopub.status.busy":"2021-10-30T19:35:05.967942Z","iopub.execute_input":"2021-10-30T19:35:05.96827Z","iopub.status.idle":"2021-10-30T19:35:05.975907Z","shell.execute_reply.started":"2021-10-30T19:35:05.968231Z","shell.execute_reply":"2021-10-30T19:35:05.974962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test Hypothesis\n\nFor each id the _train.csv_, all columns share the same value apart from _annotation_","metadata":{}},{"cell_type":"code","source":"if VERIFY_CONSISTENCY:\n    def verify_consistency(id,target_data):\n        count_mismatches = 0\n        data_for_id      = target_data[target_data.id==id]\n        for column in data_for_id.columns:\n            if column in ['id','annotation']: continue\n            values = data_for_id[column].unique()\n            if len(values)>1:\n                print (f'Non unique values in {column} for id={id}')\n                count_mismatches += 1\n\n        return count_mismatches==0\n\n    consistent = [id for id in target_ids if verify_consistency(id,target_data)]\n    assert len(consistent)==len(target_ids)\n    print ('Columns are consistent')","metadata":{"execution":{"iopub.status.busy":"2021-10-30T19:35:05.978107Z","iopub.execute_input":"2021-10-30T19:35:05.97855Z","iopub.status.idle":"2021-10-30T19:35:09.329723Z","shell.execute_reply.started":"2021-10-30T19:35:05.978508Z","shell.execute_reply":"2021-10-30T19:35:09.328745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prepare lists of ids grouped by Cell types","metadata":{}},{"cell_type":"code","source":"cell_types   = {}\nfor id,row in target_data.groupby(['id']):\n    cell_type = row.cell_type.unique()[0]\n    if not cell_type in cell_types:\n        cell_types[cell_type]=[]\n    cell_types[cell_type].append(id)\n \nstats = {}\nfor cell_type,ids in cell_types.items():\n    stats[cell_type] = len(ids)\nfig = figure(figsize=(5,5))   \nax  = fig.subplots()\nax.bar(stats.keys(),stats.values())\nax.set_title('Cell Types')\n","metadata":{"execution":{"iopub.status.busy":"2021-10-30T19:35:09.330932Z","iopub.execute_input":"2021-10-30T19:35:09.331266Z","iopub.status.idle":"2021-10-30T19:35:09.635961Z","shell.execute_reply.started":"2021-10-30T19:35:09.331223Z","shell.execute_reply":"2021-10-30T19:35:09.635232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Sample Ids\n\nI'm trying to work out the way that the files in *train_semi_supervised* are associated with training data. The code below shows that there are many more sample files than training files. I don't think that *train_semi_supervised* will be of any use.","metadata":{}},{"cell_type":"code","source":"sample_ids   = {}\nsample_dates = {}\nplate_times  = {}\n\nfor id,row in target_data.groupby(['id']):\n    sample_ids[id]   = row.sample_id.unique()[0]\n    sample_dates[id] = row.sample_date.unique()[0]\n    plate_times[id]  = row.plate_time.unique()[0]\n    \nsample_id_files = [basename(f).split(f)[0] for f in glob(join(TRAIN_SEMI_SUPERVISED,'*.png'))]\n\nprint (f'For {len(sample_ids)} training files we have {len(sample_id_files)} sample files')","metadata":{"execution":{"iopub.status.busy":"2021-10-30T19:35:09.63693Z","iopub.execute_input":"2021-10-30T19:35:09.637147Z","iopub.status.idle":"2021-10-30T19:35:09.946934Z","shell.execute_reply.started":"2021-10-30T19:35:09.637123Z","shell.execute_reply":"2021-10-30T19:35:09.946148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Sample Ids (continued)\n\nFind out whether the file specified in sample_id ever matches one in train_semi_supervised, Based on the next code block, it looks as if they\nnever match.","metadata":{}},{"cell_type":"code","source":"# get_phase\n#\n# Extract the last component of a sample file, e.g. \n#\n# shsy5y[diff]_E1-4_Vessel-714_2019-06-14_11h30m00s_Ph_3\n# has a phase of 3\n\ndef get_phase(file_name):\n    return int(basename(file_name).split('_')[-1].split('.')[0]) \n \n# get_associated_samples\n#\n# Given an id, find all accociated sample file\n#\n# Returns:\n#    samples   List of associated sample files for id\n#    phase     The phase specified for the id\n#    phases    The actual phase of each sample file\n\ndef get_associated_samples(id):\n    sample_id = sample_ids[id].split('_Ph_')\n    phase     = int(sample_id[1])\n    template  = f'{escape(sample_id[0])}_{sample_dates[id]}_{plate_times[id]}*.png'\n    samples   = glob(join(TRAIN_SEMI_SUPERVISED, template))\n    phases    = [get_phase(file_name) for file_name in samples]                \n    return samples,phase,phases\n\ndef get_matching_phases(id):\n    _,phase,phases = get_associated_samples(id)\n    return phase in phases\n\nmatches = sum([1 for cell_type,ids in cell_types.items() for id in ids if get_matching_phases(id)])\nprint (f'There are {matches} instances where phase was found in phases')\n","metadata":{"execution":{"iopub.status.busy":"2021-10-30T19:35:09.948208Z","iopub.execute_input":"2021-10-30T19:35:09.948435Z","iopub.status.idle":"2021-10-30T19:35:12.622204Z","shell.execute_reply.started":"2021-10-30T19:35:09.948406Z","shell.execute_reply":"2021-10-30T19:35:12.621428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualize a few images","metadata":{}},{"cell_type":"code","source":"def get_cell_type(id, target_data):\n    return target_data[target_data.id==id].cell_type.unique()[0]\n\n# get_mask\n# Inspired by https://www.kaggle.com/xinruizhan/save-seg-image\ndef get_mask(template,annotation):\n    img = zeros((template.shape[0] * template.shape[1], 1), dtype=float32)\n    for pos,count in annotation.item():\n        for i in range(count):\n            img[pos-1+i] = 1\n    return img.reshape((template.shape[0], template.shape[1]))\n\ndef read_and_display(id):\n    image_file_name      = join(TRAIN_PATH,f'{id}.png')\n    img                  = imread(image_file_name)\n    mask                 = get_mask(img,df_targets.loc[df_targets.id==id]['annotations'])\n    image_resized        = resize(img, (img.shape[0] // 4, img.shape[1] // 5),  anti_aliasing=True)\n    image_downscaled     = downscale_local_mean(img, (4, 5))\n    fig                  = figure(figsize=(20,20))\n    ax                   = fig.subplots(nrows=2,ncols=2)\n    ax[0][0].imshow(img, \n              cmap   = get_cmap(COLOUR_MAP),\n              origin = 'upper',\n              vmax   = img.max(),\n              vmin   = img.min())\n    ax[0][0].set_title(f'{id}, cell type {get_cell_type(id, target_data)}')\n    ax[0][1].imshow(mask, \n              cmap   = get_cmap(COLOUR_MAP),\n              origin = 'upper',\n              vmax   = mask.max(),\n              vmin   = mask.min())\n    ax[1][0].imshow(image_resized, \n              cmap   = get_cmap(COLOUR_MAP),\n              origin = 'upper',\n              vmax   = image_resized.max(),\n              vmin   = image_resized.min())\n    ax[1][0].set_title(f'{id} resized')\n    ax[1][1].imshow(image_downscaled, \n              cmap   = get_cmap(COLOUR_MAP),\n              origin = 'upper',\n              vmax   = image_downscaled.max(),\n              vmin   = image_downscaled.min())\n    ax[1][1].set_title(f'{id} downscaled')\n   \n\nfor cell_type,ids in cell_types.items():\n    for i in sample(range(len(ids)),PLOTS_PER_CELL_TYPE):\n        read_and_display(ids[i])\n","metadata":{"execution":{"iopub.status.busy":"2021-10-30T19:56:38.192095Z","iopub.execute_input":"2021-10-30T19:56:38.192366Z","iopub.status.idle":"2021-10-30T19:56:57.803553Z","shell.execute_reply.started":"2021-10-30T19:56:38.192336Z","shell.execute_reply":"2021-10-30T19:56:57.802666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Segment data -- currently this is a stub for creating submission file","metadata":{}},{"cell_type":"code","source":"def segment(keys):\n    return [[image_id,'118145 6 118849 7'] for image_id in keys]","metadata":{"execution":{"iopub.status.busy":"2021-10-30T19:35:24.086121Z","iopub.execute_input":"2021-10-30T19:35:24.086819Z","iopub.status.idle":"2021-10-30T19:35:24.090158Z","shell.execute_reply.started":"2021-10-30T19:35:24.086777Z","shell.execute_reply":"2021-10-30T19:35:24.089649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create Submission file","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testing_agenda  = {} \nfor dirname, _, filenames in walk(TEST_PATH):\n    for filename in sorted(filenames):\n        full_path = join(dirname, filename)\n        id = filename.split('.')[0]\n        testing_agenda[id] = full_path\n\ndata        = segment (testing_agenda.keys())\n\nxsubmission = DataFrame(data,columns=['id','predicted'])\nxsubmission.to_csv('submission.csv', index = False)\nxsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-30T19:35:24.091825Z","iopub.execute_input":"2021-10-30T19:35:24.092243Z","iopub.status.idle":"2021-10-30T19:35:24.121016Z","shell.execute_reply.started":"2021-10-30T19:35:24.092216Z","shell.execute_reply":"2021-10-30T19:35:24.120143Z"},"trusted":true},"execution_count":null,"outputs":[]}]}