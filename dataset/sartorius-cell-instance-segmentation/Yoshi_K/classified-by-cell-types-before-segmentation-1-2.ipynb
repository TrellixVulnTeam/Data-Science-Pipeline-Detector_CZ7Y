{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\nThis notebook is to compare the score whether the models are prepared for each cell type or not.\n1. Build cell type classifier (this notebook)\n1. Build segmentation model (shown in <a href=https://www.kaggle.com/yoshikuwano/classified-by-cell-types-before-segmentation-2-2>2/2 notebook</a>)","metadata":{}},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import os, glob, warnings, random\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\nfrom pprint import pprint\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\n\nfrom albumentations import Normalize, Resize, Compose\nfrom albumentations.pytorch import ToTensorV2\n\nwarnings.filterwarnings(\"ignore\")\n\ndef fix_all_seeds(seed):\n    np.random.seed(seed)\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\nfix_all_seeds(2021)","metadata":{"execution":{"iopub.status.busy":"2021-11-10T05:56:29.921637Z","iopub.execute_input":"2021-11-10T05:56:29.922375Z","iopub.status.idle":"2021-11-10T05:56:34.337865Z","shell.execute_reply.started":"2021-11-10T05:56:29.922205Z","shell.execute_reply":"2021-11-10T05:56:34.336935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Paramaters","metadata":{}},{"cell_type":"code","source":"INPUT_PATH = \"../input/sartorius-cell-instance-segmentation\"\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint('DEVICE: ', DEVICE)","metadata":{"execution":{"iopub.status.busy":"2021-11-10T05:56:34.34026Z","iopub.execute_input":"2021-11-10T05:56:34.340615Z","iopub.status.idle":"2021-11-10T05:56:34.40975Z","shell.execute_reply.started":"2021-11-10T05:56:34.340569Z","shell.execute_reply":"2021-11-10T05:56:34.40832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Input Data","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv(INPUT_PATH + '/train.csv')\ndf_train = df_train.groupby(\"id\")[['cell_type']].first().reset_index()\ndisplay(df_train)","metadata":{"execution":{"iopub.status.busy":"2021-11-10T05:56:34.412018Z","iopub.execute_input":"2021-11-10T05:56:34.412665Z","iopub.status.idle":"2021-11-10T05:56:34.994562Z","shell.execute_reply.started":"2021-11-10T05:56:34.412615Z","shell.execute_reply":"2021-11-10T05:56:34.993643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use train and train_semi_supervised data\n# images\ntrain_image_paths = [INPUT_PATH + f'/train/{i}.png' for i in df_train['id']]\nsemi_image_paths = glob.glob(INPUT_PATH + '/train_semi_supervised/*.png')\ntrain_image_paths.extend(semi_image_paths)\n\n# labels\ntrain_labels = df_train['cell_type'].to_list()\nsemi_labels = [path.split('/')[-1].split('[')[0] for path in semi_image_paths]\nsemi_labels = ['astro' if label=='astros' else label for label in semi_labels]\ntrain_labels.extend(semi_labels)\n\ndf = pd.DataFrame({'image_path': train_image_paths, 'cell_type': train_labels})\ndisplay(df)","metadata":{"execution":{"iopub.status.busy":"2021-11-10T05:56:59.396959Z","iopub.execute_input":"2021-11-10T05:56:59.397614Z","iopub.status.idle":"2021-11-10T05:56:59.432704Z","shell.execute_reply.started":"2021-11-10T05:56:59.397554Z","shell.execute_reply":"2021-11-10T05:56:59.431726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##  Dataset","metadata":{}},{"cell_type":"code","source":"IMAGE_RESIZE = (224, 224)\nRESNET_MEAN = (0.485, 0.456, 0.406)\nRESNET_STD = (0.229, 0.224, 0.225)\n\nclass DatasetImageCelltype(Dataset):\n    def __init__(self, df):\n        self.df = df\n        self.image_paths = df['image_path']\n        self.labels = df['cell_type']\n        \n    def __getitem__(self, idx):\n        # image\n        transforms = Compose([Resize(IMAGE_RESIZE[0], IMAGE_RESIZE[1]), \n                              Normalize(mean=RESNET_MEAN, std=RESNET_STD, p=1), \n                              ToTensorV2()])\n        image_path = self.image_paths.iloc[idx]\n        image = cv2.imread(image_path)\n        image = transforms(image=image)['image']\n        # label\n        label_list = ['shsy5y', 'astro', 'cort']\n        label = self.labels.iloc[idx]\n        label_id = label_list.index(label)\n       \n        return {'image': image, 'label': label_id}\n\n    def __len__(self):\n        return len(self.df)","metadata":{"execution":{"iopub.status.busy":"2021-11-10T05:57:02.863596Z","iopub.execute_input":"2021-11-10T05:57:02.864104Z","iopub.status.idle":"2021-11-10T05:57:02.872785Z","shell.execute_reply.started":"2021-11-10T05:57:02.864068Z","shell.execute_reply":"2021-11-10T05:57:02.871577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split into train and validation\ndf_train, df_valid = train_test_split(df, test_size=0.20)\n\n# Dataset\nds_train = DatasetImageCelltype(df_train)\nds_valid = DatasetImageCelltype(df_valid)\n# Data loader\ndl_train = DataLoader(ds_train, batch_size=64, num_workers=0, pin_memory=True, shuffle=True)\ndl_valid = DataLoader(ds_valid, batch_size=64, num_workers=0, pin_memory=True, shuffle=False)\n\nprint(f'Number of train dataset {len(ds_train)}')\nprint(f'Number of valid dataset {len(ds_valid)}')","metadata":{"execution":{"iopub.status.busy":"2021-11-10T05:57:03.376629Z","iopub.execute_input":"2021-11-10T05:57:03.377264Z","iopub.status.idle":"2021-11-10T05:57:03.391551Z","shell.execute_reply.started":"2021-11-10T05:57:03.377214Z","shell.execute_reply":"2021-11-10T05:57:03.390275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Classifier Model","metadata":{}},{"cell_type":"markdown","source":"## Modeling","metadata":{}},{"cell_type":"code","source":"from torchvision.models import resnet34\n\ndef Resnet():\n    model = resnet34(True)\n    model.fc = torch.nn.Linear(512, 3)\n    return model\n\nmodel = Resnet()","metadata":{"execution":{"iopub.status.busy":"2021-11-10T05:58:10.800315Z","iopub.execute_input":"2021-11-10T05:58:10.800692Z","iopub.status.idle":"2021-11-10T05:58:11.254887Z","shell.execute_reply.started":"2021-11-10T05:58:10.800662Z","shell.execute_reply":"2021-11-10T05:58:11.253821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train classifier","metadata":{}},{"cell_type":"code","source":"LEARNING_RATE = 5e-4\nEPOCHS = 5\n\nmodel.to(DEVICE)\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\nfor epoch in range(1, EPOCHS + 1):\n    print(f'Epoch: {epoch}/{EPOCHS}')\n    \n    # Train on extra data\n    model.train()\n    optimizer.zero_grad()\n    loss_train = 0.0\n    correct_train = 0.0\n       \n    # Train on train data\n    for data in tqdm(dl_train, total=len(dl_train), desc='[train]'):\n        # Input\n        images, labels = data['image'], data['label']\n        images, labels = images.to(DEVICE), labels.to(DEVICE)\n        # Forward\n        outputs = model(images) # probabilities\n        loss = criterion(outputs, labels)\n        loss_train += loss\n        # Back propagation\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        # Metric\n        outputs = outputs.argmax(dim=1) # one hot vector\n        correct_train += (labels==outputs).sum()\n    \n    loss_train = loss_train / len(dl_train)\n    acc_train = correct_train / len(ds_train)\n    print(f'Train loss: {loss_train:.4f}, Train accuracy: {acc_train*100:.2f}%')\n\n    # Validation\n    model.eval()\n    loss_valid = 0.0\n    correct_valid = 0.0\n    with torch.no_grad():\n        for data in tqdm(dl_valid, total=len(dl_valid), desc='[valid]'):\n            images, labels = data['image'], data['label']\n            images, labels = images.to(DEVICE), labels.to(DEVICE)\n            outputs = model(images) # probabilities\n            loss_valid += criterion(outputs, labels)\n            outputs = outputs.argmax(dim=1) # one hot vector\n            correct_valid += (labels==outputs).sum()\n            \n    \n    loss_valid = loss_valid / len(dl_valid)\n    acc_valid = correct_valid / len(ds_valid)\n    print(f'Valid loss: {loss_valid:.4f}, Valid accuracy: {acc_valid*100:.2f}%\\n')    \n","metadata":{"execution":{"iopub.status.busy":"2021-11-10T06:23:23.411909Z","iopub.execute_input":"2021-11-10T06:23:23.412427Z","iopub.status.idle":"2021-11-10T06:25:49.429699Z","shell.execute_reply.started":"2021-11-10T06:23:23.412382Z","shell.execute_reply":"2021-11-10T06:25:49.428554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model, 'resnet34_crassifier.bin')","metadata":{"execution":{"iopub.status.busy":"2021-11-10T06:25:53.515273Z","iopub.execute_input":"2021-11-10T06:25:53.515598Z","iopub.status.idle":"2021-11-10T06:25:53.687848Z","shell.execute_reply.started":"2021-11-10T06:25:53.515567Z","shell.execute_reply":"2021-11-10T06:25:53.686669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}