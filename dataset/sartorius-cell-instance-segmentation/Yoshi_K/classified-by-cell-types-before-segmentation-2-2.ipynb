{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\nThis notebook is to compare the score whether the models are prepared for each cell type or not.\n1. Build cell type classifier <-- shown in <a href=https://www.kaggle.com/yoshikuwano/classified-by-cell-types-before-segmentation-1-2>notebook (1/2)</a>)\n1. Build segmentation model <-- this notebook\n\nRef. https://www.kaggle.com/julian3833/sartorius-starter-torch-mask-r-cnn-lb-0-273","metadata":{}},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import os, glob, time, random, collections\nfrom tqdm.notebook import tqdm\n\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom pprint import pprint\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nimport torchvision\nfrom torchvision.transforms import ToPILImage\nfrom torchvision.transforms import functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\nfrom torchvision.models.detection.mask_rcnn import MaskRCNNPredictor","metadata":{"execution":{"iopub.status.busy":"2021-11-17T03:01:15.154023Z","iopub.execute_input":"2021-11-17T03:01:15.154381Z","iopub.status.idle":"2021-11-17T03:01:17.729223Z","shell.execute_reply.started":"2021-11-17T03:01:15.154298Z","shell.execute_reply":"2021-11-17T03:01:17.728339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Paramaters","metadata":{}},{"cell_type":"code","source":"INPUT_PATH = '../input/sartorius-cell-instance-segmentation'\nCLASSIFIER_MODEL_PATH = '../input/classified-by-cell-types-before-segmentation-1-2/resnet34_crassifier.bin'\n\ndef fix_all_seeds(seed):\n    np.random.seed(seed)\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\nfix_all_seeds(2021)\n\n# Image size\nWIDTH = 704\nHEIGHT = 520\n\nNUM_EPOCHS = 5\nBATCH_SIZE = 2\n\n# For optimizer\nMOMENTUM = 0.9\nLEARNING_RATE = 0.001\nWEIGHT_DECAY = 0.0005\nUSE_SCHEDULER = False # Use a StepLR scheduler if True. Not tried yet.\n\nMASK_THRESHOLD = 0.5 # Changes the confidence required for a pixel to be kept for a mask. \nBOX_DETECTIONS_PER_IMG = 539\nMIN_SCORE = 0.59\nRESNET_MEAN = (0.485, 0.456, 0.406)\nRESNET_STD = (0.229, 0.224, 0.225)\nNORMALIZE = False # Normalize to resnet mean and std if True. \n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint('DEVICE: ', DEVICE)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T03:01:17.732036Z","iopub.execute_input":"2021-11-17T03:01:17.732296Z","iopub.status.idle":"2021-11-17T03:01:17.790963Z","shell.execute_reply.started":"2021-11-17T03:01:17.732261Z","shell.execute_reply":"2021-11-17T03:01:17.789741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utilities","metadata":{}},{"cell_type":"code","source":"# Transforms\nclass Compose_:\n    def __init__(self, transforms):\n        self.transforms = transforms\n\n    def __call__(self, image, target):\n        for t in self.transforms:\n            image, target = t(image, target)\n        return image, target\n\nclass VerticalFlip_:\n    def __init__(self, prob):\n        self.prob = prob\n\n    def __call__(self, image, target):\n        if random.random() < self.prob:\n            height, width = image.shape[-2:]\n            image = image.flip(-2)\n            bbox = target[\"boxes\"]\n            bbox[:, [1, 3]] = height - bbox[:, [3, 1]]\n            target[\"boxes\"] = bbox\n            target[\"masks\"] = target[\"masks\"].flip(-2)\n        return image, target\n\nclass HorizontalFlip_:\n    def __init__(self, prob):\n        self.prob = prob\n\n    def __call__(self, image, target):\n        if random.random() < self.prob:\n            height, width = image.shape[-2:]\n            image = image.flip(-1)\n            bbox = target[\"boxes\"]\n            bbox[:, [0, 2]] = width - bbox[:, [2, 0]]\n            target[\"boxes\"] = bbox\n            target[\"masks\"] = target[\"masks\"].flip(-1)\n        return image, target\n\nclass Normalize_:\n    def __call__(self, image, target):\n        image = F.normalize(image, RESNET_MEAN, RESNET_STD)\n        return image, target\n\nclass ToTensor_:\n    def __call__(self, image, target):\n        image = F.to_tensor(image)\n        return image, target \n\ndef get_transform(train):\n    transforms = [ToTensor_()]\n    if NORMALIZE:\n        transforms.append(Normalize_())\n    \n    # Data augmentation for train\n    if train: \n        transforms.append(HorizontalFlip_(0.5))\n        transforms.append(VerticalFlip_(0.5))\n\n    return Compose_(transforms)\n\n\n# RLE string -> ndarray mask\ndef rle_decode(mask_rle, shape, color=1):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0] * shape[1], dtype=np.float32)\n    for lo, hi in zip(starts, ends):\n        img[lo : hi] = color\n    return img.reshape(shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T03:01:17.792198Z","iopub.execute_input":"2021-11-17T03:01:17.792435Z","iopub.status.idle":"2021-11-17T03:01:17.809779Z","shell.execute_reply.started":"2021-11-17T03:01:17.792403Z","shell.execute_reply":"2021-11-17T03:01:17.808811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Input Data","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv(INPUT_PATH + '/train.csv')\ndisplay(df_train)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T03:01:17.811844Z","iopub.execute_input":"2021-11-17T03:01:17.812519Z","iopub.status.idle":"2021-11-17T03:01:18.299217Z","shell.execute_reply.started":"2021-11-17T03:01:17.812456Z","shell.execute_reply":"2021-11-17T03:01:18.298542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cell_types = ['all']\ncell_types.extend(df_train['cell_type'].unique())\nprint(f'cell_types: {cell_types}')","metadata":{"execution":{"iopub.status.busy":"2021-11-17T03:01:18.300607Z","iopub.execute_input":"2021-11-17T03:01:18.301088Z","iopub.status.idle":"2021-11-17T03:01:18.315302Z","shell.execute_reply.started":"2021-11-17T03:01:18.301053Z","shell.execute_reply":"2021-11-17T03:01:18.314417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Separate dataset by cell type\nimage_ids = df_train['id'].unique()\ndf_shsy5y = df_train[df_train['cell_type']=='shsy5y']\ndf_astro  = df_train[df_train['cell_type']=='astro']\ndf_cort   = df_train[df_train['cell_type']=='cort']\n\ntrain_idx, valid_idx = train_test_split(image_ids, test_size=0.2)\n\ndf_train_all   = df_train[df_train['id'].isin(train_idx)]\ndf_valid_all   = df_train[df_train['id'].isin(valid_idx)]\ndf_train_shsy5y = df_shsy5y[df_shsy5y['id'].isin(train_idx)]\ndf_valid_shsy5y = df_shsy5y[df_shsy5y['id'].isin(valid_idx)]\ndf_train_astro  = df_astro[df_astro['id'].isin(train_idx)]\ndf_valid_astro  = df_astro[df_astro['id'].isin(valid_idx)]\ndf_train_cort   = df_cort[df_cort['id'].isin(train_idx)]\ndf_valid_cort   = df_cort[df_cort['id'].isin(valid_idx)]\n\nprint('Number of records for each dataframe')\nprint(f'train        : {len(df_train_all)}')\nprint(f'valid        : {len(df_valid_all)}')\nprint(f'train shsy5y : {len(df_train_shsy5y)}')\nprint(f'valid shsy5y : {len(df_valid_shsy5y)}')\nprint(f'train astro  : {len(df_train_astro)}')\nprint(f'valid astro  : {len(df_valid_astro)}')\nprint(f'train cort   : {len(df_train_cort)}')\nprint(f'valid cort   : {len(df_valid_cort)}')","metadata":{"execution":{"iopub.status.busy":"2021-11-17T03:01:18.316997Z","iopub.execute_input":"2021-11-17T03:01:18.317437Z","iopub.status.idle":"2021-11-17T03:01:18.40412Z","shell.execute_reply.started":"2021-11-17T03:01:18.317402Z","shell.execute_reply":"2021-11-17T03:01:18.403374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##  Dataset","metadata":{}},{"cell_type":"code","source":"class CellDataset(Dataset):\n    \n    def __init__(self, image_dir, df, transforms=None, resize=False):\n        self.transforms = transforms\n        self.image_dir = image_dir\n        self.df = df\n        \n        self.should_resize = resize is not False\n        if self.should_resize:\n            self.height = int(HEIGHT * resize)\n            self.width = int(WIDTH * resize)\n        else:\n            self.height = HEIGHT\n            self.width = WIDTH\n        \n        self.image_info = collections.defaultdict(dict)\n        temp_df = self.df.groupby('id')['annotation'].agg(lambda x: list(x)).reset_index()\n        for index, row in temp_df.iterrows():\n            self.image_info[index] = {\n                    'image_id': row['id'],\n                    'image_path': os.path.join(self.image_dir, row['id'] + '.png'),\n                    'annotations': row[\"annotation\"]\n                    }\n    \n    def get_box(self, a_mask):\n        ''' Get the bounding box of a given mask '''\n        pos = np.where(a_mask)\n        xmin = np.min(pos[1])\n        xmax = np.max(pos[1])\n        ymin = np.min(pos[0])\n        ymax = np.max(pos[0])\n        return [xmin, ymin, xmax, ymax]\n\n    def __getitem__(self, idx):\n        ''' Get the image and the target'''\n        \n        img_path = self.image_info[idx]['image_path']\n        img = Image.open(img_path).convert('RGB')\n        \n        if self.should_resize:\n            img = img.resize((self.width, self.height), resample=Image.BILINEAR)\n\n        info = self.image_info[idx]\n\n        n_objects = len(info['annotations'])\n        masks = np.zeros((len(info['annotations']), self.height, self.width), dtype=np.uint8)\n        boxes = []\n        \n        for i, annotation in enumerate(info['annotations']):\n            a_mask = rle_decode(annotation, (HEIGHT, WIDTH))\n            a_mask = Image.fromarray(a_mask)\n            \n            if self.should_resize:\n                a_mask = a_mask.resize((self.width, self.height), resample=Image.BILINEAR)\n            \n            a_mask = np.array(a_mask) > 0\n            masks[i, :, :] = a_mask\n            \n            boxes.append(self.get_box(a_mask))\n\n        # dummy labels\n        labels = [1 for _ in range(n_objects)]\n        \n        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n        labels = torch.as_tensor(labels, dtype=torch.int64)\n        masks = torch.as_tensor(masks, dtype=torch.uint8)\n\n        image_id = torch.tensor([idx])\n        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n        iscrowd = torch.zeros((n_objects,), dtype=torch.int64)\n\n        # This is the required target for the Mask R-CNN\n        target = {\n            'boxes': boxes,\n            'labels': labels,\n            'masks': masks,\n            'image_id': image_id,\n            'area': area,\n            'iscrowd': iscrowd\n        }\n\n        if self.transforms is not None:\n            img, target = self.transforms(img, target)\n\n        return img, target\n\n    def __len__(self):\n        return len(self.image_info)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T03:01:18.405426Z","iopub.execute_input":"2021-11-17T03:01:18.405666Z","iopub.status.idle":"2021-11-17T03:01:18.424417Z","shell.execute_reply.started":"2021-11-17T03:01:18.405632Z","shell.execute_reply":"2021-11-17T03:01:18.42353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Datasets\nds_train_all    = CellDataset(INPUT_PATH + '/train', df_train_all, resize=False,\n                              transforms = get_transform(train=True))\nds_valid_all    = CellDataset(INPUT_PATH + '/train', df_valid_all, resize=False,\n                              transforms = get_transform(train=False))\nds_train_shsy5y = CellDataset(INPUT_PATH + '/train', df_train_shsy5y, resize=False,\n                              transforms = get_transform(train=True))\nds_valid_shsy5y = CellDataset(INPUT_PATH + '/train', df_valid_shsy5y, resize=False,\n                              transforms = get_transform(train=False))\nds_train_astro  = CellDataset(INPUT_PATH + '/train', df_train_astro, resize=False,\n                              transforms = get_transform(train=True))\nds_valid_astro  = CellDataset(INPUT_PATH + '/train', df_valid_astro, resize=False,\n                              transforms = get_transform(train=False))\nds_train_cort   = CellDataset(INPUT_PATH + '/train', df_train_cort, resize=False,\n                              transforms = get_transform(train=True))\nds_valid_cort   = CellDataset(INPUT_PATH + '/train', df_valid_cort, resize=False,\n                              transforms = get_transform(train=False))\n\ntrain_datasets = [ds_train_all, ds_train_shsy5y, ds_train_astro, ds_train_cort]\nvalid_datasets = [ds_valid_all, ds_valid_shsy5y, ds_valid_astro, ds_valid_cort]\n\nprint(f'Number of train dataset : {len(ds_train_all)}')\nprint(f'Number of valid dataset : {len(ds_valid_all)}')\nprint(f'Number of shsy5y train dataset : {len(ds_train_shsy5y)}')\nprint(f'Number of shsy5y valid dataset : {len(ds_valid_shsy5y)}')\nprint(f'Number of astro train dataset  : {len(ds_train_astro)}')\nprint(f'Number of astro valid dataset  : {len(ds_valid_astro)}')\nprint(f'Number of cort train dataset   : {len(ds_train_cort)}')\nprint(f'Number of cort valid dataset   : {len(ds_valid_cort)}')","metadata":{"execution":{"iopub.status.busy":"2021-11-17T03:01:18.425839Z","iopub.execute_input":"2021-11-17T03:01:18.426604Z","iopub.status.idle":"2021-11-17T03:01:18.5722Z","shell.execute_reply.started":"2021-11-17T03:01:18.426539Z","shell.execute_reply":"2021-11-17T03:01:18.571546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"markdown","source":"## Modeling","metadata":{}},{"cell_type":"code","source":"# Override pythorch checkpoint with an \"offline\" version of the file\n!mkdir -p /root/.cache/torch/hub/checkpoints/\n!cp ../input/cocopre/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth /root/.cache/torch/hub/checkpoints/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth","metadata":{"execution":{"iopub.status.busy":"2021-11-17T03:01:18.57366Z","iopub.execute_input":"2021-11-17T03:01:18.574046Z","iopub.status.idle":"2021-11-17T03:01:21.308546Z","shell.execute_reply.started":"2021-11-17T03:01:18.574011Z","shell.execute_reply":"2021-11-17T03:01:21.307551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision.models.detection import maskrcnn_resnet50_fpn\n\ndef get_model():\n    \n    # This is just a dummy value for the classification head\n    NUM_CLASSES = 2\n    \n    if NORMALIZE:\n        model = maskrcnn_resnet50_fpn(pretrained=True, \n                                      box_detections_per_img=BOX_DETECTIONS_PER_IMG,\n                                      image_mean=RESNET_MEAN, \n                                      image_std=RESNET_STD)\n    else:\n        model = maskrcnn_resnet50_fpn(pretrained=True,\n                                      box_detections_per_img=BOX_DETECTIONS_PER_IMG)\n\n    # Get the number of input features for the classifier\n    in_features = model.roi_heads.box_predictor.cls_score.in_features\n    # Replace the pre-trained head with a new one\n    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, NUM_CLASSES)\n    # Now get the number of input features for the mask classifier\n    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n    hidden_layer = 256\n    # and replace the mask predictor with a new one\n    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, hidden_layer, NUM_CLASSES)\n    \n    return model\n\nmodel_all = get_model()\nmodel_shsy5y = get_model()\nmodel_astro  = get_model()\nmodel_cort   = get_model()\nmodels = [model_all, model_shsy5y, model_astro, model_cort]\n\nfor model in models:\n    for param in model.parameters():\n        param.requires_grad = True","metadata":{"execution":{"iopub.status.busy":"2021-11-17T03:01:21.312979Z","iopub.execute_input":"2021-11-17T03:01:21.313751Z","iopub.status.idle":"2021-11-17T03:01:24.113757Z","shell.execute_reply.started":"2021-11-17T03:01:21.313682Z","shell.execute_reply":"2021-11-17T03:01:24.113018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train ","metadata":{}},{"cell_type":"code","source":"def train(model, ds_train, ds_valid, cell_type=None, verbose=False):\n    \n    model.to(DEVICE)\n    params = [p for p in model.parameters() if p.requires_grad]\n    optimizer = torch.optim.SGD(params, lr=LEARNING_RATE, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n    min_valid_loss = np.inf\n    min_loss_epoch = 0\n    for epoch in range(1, NUM_EPOCHS + 1):\n        \n        ### Data  Loader ###\n        dl_train = DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True, \n                              num_workers=0, collate_fn=lambda x: tuple(zip(*x)))        \n        dl_valid = DataLoader(ds_valid, batch_size=BATCH_SIZE, shuffle=False, \n                              num_workers=0, collate_fn=lambda x: tuple(zip(*x)))\n\n        ### TRAIN ###\n        model.train()\n        time_start = time.time()\n        loss_accum = 0.0\n        loss_mask_accum = 0.0\n        for batch_idx, (images, targets) in tqdm(enumerate(dl_train, 1),\n                                                 total = len(dl_train),\n                                                 desc = f'[Train] Epoch ({epoch}/{NUM_EPOCHS})'):\n\n            # Forward\n            images = list(image.to(DEVICE) for image in images)\n            targets = [{k: v.to(DEVICE) for k, v in t.items()} for t in targets]\n            loss_dict = model(images, targets)\n            loss = sum(loss for loss in loss_dict.values())\n            # Backpropagation\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            # Logging\n            loss_mask = loss_dict['loss_mask'].item()\n            loss_accum += loss.item()\n            loss_mask_accum += loss_mask\n            # Print\n            if verbose:\n                if batch_idx % 20 == 0:\n                    prefix = f'    [Batch {batch_idx:3d}/{len(dl_train):3d}]'\n                    print(f'{prefix} Train loss: {loss.item():7.3f}, Mask-only loss: {loss_mask:7.3f}')\n\n        if USE_SCHEDULER:\n            lr_scheduler.step()\n\n        # Train losses\n        train_loss = loss_accum / len(dl_train)\n        train_loss_mask = loss_mask_accum / len(dl_train)\n        elapsed = time.time() - time_start\n        prefix = f'[Epoch {epoch:2d}/{NUM_EPOCHS:2d}]'\n        print(f'{prefix} Train loss: {train_loss:7.3f}, Mean mask-only loss: {train_loss_mask:7.3f} [{elapsed:.0f} secs]')\n        \n        \n        ### VALIDATION ###\n        loss_accum = 0.0\n        loss_mask_accum = 0.0\n        with torch.no_grad():\n            for batch_idx, (images, targets) in tqdm(enumerate(dl_valid, 1),\n                                                     total = len(dl_valid),\n                                                     desc = f'[Valid] Epoch ({epoch}/{NUM_EPOCHS})'):\n\n                # Forward\n                images = list(image.to(DEVICE) for image in images)\n                targets = [{k: v.to(DEVICE) for k, v in t.items()} for t in targets]\n                loss_dict = model(images, targets)\n                loss = sum(loss for loss in loss_dict.values())\n                # Logging\n                loss_mask = loss_dict['loss_mask'].item()\n                loss_accum += loss.item()\n                loss_mask_accum += loss_mask\n                \n                # Print\n                if verbose:\n                    if batch_idx % 20 == 0:\n                        prefix = f'    [Batch {batch_idx:3d}/{len(dl_valid):3d}]'\n                        print(f'{prefix} Valid loss: {loss.item():7.3f}, Mask-only loss: {loss_mask:7.3f}.')\n                    \n        if USE_SCHEDULER:\n            lr_scheduler.step()\n\n        # Loss per epoch\n        valid_loss = loss_accum / len(dl_valid)\n        valid_loss_mask = loss_mask_accum / len(dl_valid)\n        elapsed = time.time() - time_start\n        prefix = f'[Epoch {epoch:2d}/{NUM_EPOCHS:2d}]'\n        print(f'{prefix} Valid loss: {valid_loss:7.3f}, Mean mask-only loss: {valid_loss_mask:7.3f} [{elapsed:.0f} secs]')\n        if valid_loss < min_valid_loss:\n            min_valid_loss = valid_loss\n            min_loss_epoch = epoch\n            torch.save(model.state_dict(), f'pytorch_model_{cell_type}.bin')    \n        \n    print(f'Minimum valid loss: {min_valid_loss:7.3f} at epoch-{min_loss_epoch}\\n')","metadata":{"execution":{"iopub.status.busy":"2021-11-17T03:01:24.115155Z","iopub.execute_input":"2021-11-17T03:01:24.115411Z","iopub.status.idle":"2021-11-17T03:01:24.136427Z","shell.execute_reply.started":"2021-11-17T03:01:24.115378Z","shell.execute_reply":"2021-11-17T03:01:24.135762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(4):\n    print('#'*50)\n    print(f'Cell type: {cell_types[i]}')\n    train(models[i], train_datasets[i], valid_datasets[i], cell_types[i])","metadata":{"execution":{"iopub.status.busy":"2021-11-17T03:01:24.137784Z","iopub.execute_input":"2021-11-17T03:01:24.138055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Validate\nCalculate scores for all cell type model and individual cell type models","metadata":{}},{"cell_type":"markdown","source":"## Load trained models","metadata":{}},{"cell_type":"code","source":"trained_models = []\nfor i in range(4):\n    model = get_model()\n    model.load_state_dict(torch.load(f'pytorch_model_{cell_types[i]}.bin'))\n    trained_models.append(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Score functions","metadata":{}},{"cell_type":"code","source":"# ndarray mask -> RLE stiring\ndef rle_encode(x):\n    dots = np.where(x.flatten() == 1)[0]\n    run_lengths = []\n    prev = -2\n    for b in dots:\n        if (b>prev+1): run_lengths.extend((b + 1, 0))\n        run_lengths[-1] += 1\n        prev = b\n    return ' '.join(map(str, run_lengths))\n\ndef remove_overlapping_pixels(mask, other_masks):\n    for other_mask in other_masks:\n        if np.sum(np.logical_and(mask, other_mask)) > 0:\n            mask[np.logical_and(mask, other_mask)] = 0\n    return mask\n\n# Score\ndef compute_iou(true_mask, pred_mask, verbose=False):\n    \"\"\"\n    Computes the IoU for instance labels and predictions.\n\n    Args:\n        true_mask:  ndarray (Height, Width)\n        pred_mask:  ndarray (Height, Width)\n        * including all objects which are labeled as 1, 2, ..., #objects\n    Returns:\n        np array: IoU matrix, of size true_objects x pred_objects.\n    \"\"\"\n\n    num_true_objects = len(np.unique(true_mask))\n    num_pred_objects = len(np.unique(pred_mask))\n\n    if verbose:\n        print(\"Number of true objects: {}\".format(num_true_objects))\n        print(\"Number of predicted objects: {}\".format(num_pred_objects))\n\n    # Compute intersection between all objects\n    intersection = np.histogram2d(\n        true_mask.flatten(), pred_mask.flatten(), bins=(num_true_objects, num_pred_objects)\n    )[0]\n\n    # Compute areas (needed for finding the union between all objects)\n    area_true = np.histogram(true_mask, bins=num_true_objects)[0]\n    area_pred = np.histogram(pred_mask, bins=num_pred_objects)[0]\n    area_true = np.expand_dims(area_true, -1)\n    area_pred = np.expand_dims(area_pred, 0)\n\n    # Compute union\n    union = area_true + area_pred - intersection\n    union[union == 0] = 1e-9 # Avoid divergent\n    \n    iou = intersection / union\n    \n    return iou[1:, 1:]  # exclude background\n\ndef precision_at(threshold, iou):\n    \"\"\"\n    Computes the precision at a given threshold.\n\n    Args:\n        threshold (float): Threshold.\n        iou (np array): IoU matrix.\n\n    Returns:\n        int: Number of true positives,\n        int: Number of false positives,\n        int: Number of false negatives.\n    \"\"\"\n    matches = iou > threshold\n    true_positives = np.sum(matches, axis=1) == 1  # Correct objects\n    false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n    false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n    tp, fp, fn = (\n        np.sum(true_positives),\n        np.sum(false_positives),\n        np.sum(false_negatives),\n    )\n    return tp, fp, fn\n\ndef iou_map(ture_masks, pred_masks, verbose=False):\n    \"\"\"\n    Computes the metric for the competition.\n    Masks contain the segmented pixels where each object has one value associated,\n    and 0 is the background.\n\n    Args:\n        ture_masks (list of masks): Ground truths.\n        pred_masks (list of masks): Predictions.\n        verbose (int, optional): Whether to print infos. Defaults to 0.\n\n    Returns:\n        float: mAP.\n    \"\"\"\n    ious = [compute_iou(true_mask, pred_mask, verbose) for true_mask, pred_mask in zip(ture_masks, pred_masks)]\n\n    if verbose:\n        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n\n    precisions = []\n    for t in np.arange(0.5, 1.0, 0.05):\n        tps, fps, fns = 0, 0, 0\n        for iou in ious:\n            tp, fp, fn = precision_at(t, iou)\n            tps += tp\n            fps += fp\n            fns += fn\n\n        p = tps / (tps + fps + fns)\n        precisions.append(p)\n\n        if verbose:\n            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tps, fps, fns, p))\n\n    if verbose:\n        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(precisions)))\n\n    return np.mean(precisions)\n\n\ndef predict_mask(model, img, mask_threshold=MASK_THRESHOLD):\n    model.to(DEVICE)\n    model.eval()\n    with torch.no_grad():\n        output = model([img.to(DEVICE)])[0]\n    \n    pred_masks = []\n    for i, pred_mask in enumerate(output[\"masks\"]):\n        score = output['scores'][i].cpu().item()\n        if score > MIN_SCORE:\n            pred_mask = pred_mask.cpu().numpy().squeeze() # probability\n            pred_mask = pred_mask > mask_threshold  # binalize\n            pred_mask = remove_overlapping_pixels(pred_mask, pred_masks)\n            pred_masks.append(pred_mask)\n\n    return pred_masks\n\ndef get_score(model, dataset, mask_threshold=MASK_THRESHOLD, verbose=False):\n    \"\"\"\n    Get average IOU mAP score for a dataset\n    \"\"\"\n    score_cum = 0\n    for i in range(len(dataset)):\n        \n        img, target = dataset[i]\n        \n        # Predicted masks\n        pred_masks = predict_mask(model, img, mask_threshold)\n        \n        # combine all objects\n        pred_masks_combined = np.zeros((HEIGHT, WIDTH))\n        for m, mask in enumerate(pred_masks,1):\n            pred_masks_combined[mask>0.5] = m\n\n        # combine all objects\n        pred_masks_combined = np.zeros((HEIGHT, WIDTH))\n        for m, mask in enumerate(pred_masks,1):\n            pred_masks_combined[mask>0.5] = m\n\n        # True masks\n        true_masks_combined = np.zeros((HEIGHT, WIDTH))\n        for m, mask in enumerate(target['masks'],1):\n            true_masks_combined[mask.cpu()>mask_threshold] = m\n      \n        score_cum += iou_map([true_masks_combined],[pred_masks_combined], verbose)\n        \n    return score_cum/len(dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Get scores","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_model_scores = []\nindividual_model_scores = []\n\nfor i in tqdm(range(1, 4)):\n    print(f'Calculate the score for cell type {cell_types[i]}')\n    score_all = get_score(trained_models[0], valid_datasets[i])\n    score_ind = get_score(trained_models[i], valid_datasets[i])\n    print(f'Score of all cell type model   : {score_all:7.3f}')\n    print(f'Score of {cell_types[i]} model : {score_ind:7.3f}\\n')\n    all_model_scores.append(score_all)\n    individual_model_scores.append(score_ind)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Confirm predicted train mask","metadata":{}},{"cell_type":"code","source":"# Plots: the image, The image + the ground truth mask, The image + the predicted mask\nfrom PIL import Image, ImageEnhance\ndef plot_prediction(model, ds_train, sample_index):\n    \n    # Predict mask\n    img, targets = ds_train[sample_index]\n    image_id = ds_train.image_info[0]['image_id']\n    pred_masks = predict_mask(model, img)\n    pred_masks_combined = np.zeros((HEIGHT, WIDTH))\n    for mask in pred_masks:\n        pred_masks_combined[mask>0.5] = 1\n    \n    fig, ax = plt.subplots(1, 3, figsize=(15,4))\n    # Image (high contrast)\n    img = img.numpy().transpose((1,2,0))\n    img = (img*255).astype(np.uint8)\n    img_hc = img.max() - img\n    img_hc = np.asarray(ImageEnhance.Contrast(Image.fromarray(img_hc)).enhance(24))\n    ax[0].imshow(img_hc)\n    ax[0].set_title(f'Image: {image_id}')\n    # Ground truth\n    masks = np.zeros((HEIGHT, WIDTH))\n    for mask in targets['masks']:\n        masks = np.logical_or(masks, mask)\n    ax[1].imshow(img_hc)\n    ax[1].imshow(masks, alpha=0.3)\n    ax[1].set_title(\"Ground truth\")\n    # Prediciton\n    ax[2].imshow(img_hc)\n    ax[2].imshow(pred_masks_combined, alpha=0.3)\n    ax[2].set_title(\"Prediction\")\n    \n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(1,4):\n    print('#'*50)\n    print(f'Prediction by all cell type model')\n    plot_prediction(trained_models[0], valid_datasets[i], sample_index=1)\n    print(f'Prediction by {cell_types[i]} model')\n    plot_prediction(trained_models[i], valid_datasets[i], sample_index=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict\npredict test data by each cell type model ","metadata":{}},{"cell_type":"markdown","source":"## Test images","metadata":{}},{"cell_type":"code","source":"test_image_paths = glob.glob(INPUT_PATH + '/test/*.png')\npprint(test_image_paths)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Classify images by cell types","metadata":{}},{"cell_type":"markdown","source":"### Load classifier\nPre-trained resnet34 model is loaded","metadata":{"execution":{"iopub.status.busy":"2021-11-11T03:33:24.549561Z","iopub.execute_input":"2021-11-11T03:33:24.549834Z","iopub.status.idle":"2021-11-11T03:33:24.554011Z","shell.execute_reply.started":"2021-11-11T03:33:24.549806Z","shell.execute_reply":"2021-11-11T03:33:24.553261Z"}}},{"cell_type":"code","source":"classifier = torch.load(CLASSIFIER_MODEL_PATH)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dataset","metadata":{}},{"cell_type":"code","source":"from albumentations import Normalize, Resize, Compose\nfrom albumentations.pytorch import ToTensorV2\n\nclass DatasetImageClassify(Dataset):\n    def __init__(self, image_paths):\n        self.image_paths = image_paths\n        \n    def __getitem__(self, idx):\n        # image\n        transforms = Compose([Resize(224, 224), \n                              Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), p=1), \n                              ToTensorV2()])\n        image_path = self.image_paths[idx]\n        image = cv2.imread(image_path)\n        image = transforms(image=image)['image']\n        \n        return {'image': image, 'image_path': image_path}\n\n    def __len__(self):\n        return len(self.image_paths)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds_classify = DatasetImageClassify(test_image_paths )\ndl_classify = DataLoader(ds_classify, batch_size=64, num_workers=0, pin_memory=True, shuffle=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Classify test images","metadata":{}},{"cell_type":"code","source":"cell_list = ['shsy5y', 'astro', 'cort']\nimage_class = {}\nclassifier.eval()\ncnt = 0\nfor data in dl_classify:\n    images, image_paths = data['image'], data['image_path']\n    images = images.to(DEVICE)\n    outputs = classifier(images)\n    cell_idx = [output.argmax().item() for output in outputs]\n    for path, idx in zip(image_paths, cell_idx):\n        image_class[cnt] = {'id': path.split('/')[-1].split('.')[0], 'cell_type': cell_list[idx]}\n        cnt += 1\n        \ndf_test = pd.DataFrame.from_dict(image_class, orient='index')\ndisplay(df_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test dataset\nclass CellTestDataset(Dataset):\n    def __init__(self, df, transforms=None):\n        self.df = df\n        self.transforms = transforms\n        \n    def __getitem__(self, idx):\n        image_id = self.df['id'].iloc[idx]\n        image_path = INPUT_PATH + '/test/' + image_id + '.png'\n        image = Image.open(image_path).convert(\"RGB\")\n        if self.transforms is not None:\n            image, _ = self.transforms(image=image, target=None)\n        return {'image': image, 'image_id': image_id}\n\n    def __len__(self):\n        return len(self.df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test_all    = df_test.copy() #Not used\ndf_test_shsy5y = df_test[df_test['cell_type']=='shsy5y']\ndf_test_astro  = df_test[df_test['cell_type']=='astro']\ndf_test_cort   = df_test[df_test['cell_type']=='cort']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds_test_all    = CellTestDataset(df_test_all,    transforms=get_transform(train=False))\nds_test_shsy5y = CellTestDataset(df_test_shsy5y, transforms=get_transform(train=False))\nds_test_astro  = CellTestDataset(df_test_astro,  transforms=get_transform(train=False))\nds_test_cort   = CellTestDataset(df_test_cort,   transforms=get_transform(train=False))\ntest_datasets = [df_test_all, ds_test_shsy5y, ds_test_astro, ds_test_cort]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Run predict","metadata":{}},{"cell_type":"code","source":"def predict(model, dataset, mask_threshold=MASK_THRESHOLD):\n    \n    if len(dataset)==0:\n        return None\n    \n    model.eval()\n    model.to(DEVICE)\n    submission = []\n    for sample in dataset:\n        img = sample['image']\n        image_id = sample['image_id']\n        with torch.no_grad():\n            output = model([img.to(DEVICE)])[0]\n\n        previous_masks = []\n        for i, mask in enumerate(output[\"masks\"]):\n            score = output['scores'][i].cpu().item()\n            if score > MIN_SCORE:\n                mask = mask.cpu().numpy() # probability\n                mask = mask > mask_threshold  # binalize\n                mask = remove_overlapping_pixels(mask, previous_masks)\n                previous_masks.append(mask)\n                rle = rle_encode(mask)\n                submission.append((image_id, rle))\n\n        # Add empty prediction if no RLE was generated for this image\n        all_images_ids = [image_id for image_id, rle in submission]\n        if image_id not in all_images_ids:\n            submission.append((image_id, \"\"))\n        \n    return submission","metadata":{"execution":{"iopub.status.busy":"2021-11-17T05:41:03.012604Z","iopub.execute_input":"2021-11-17T05:41:03.013084Z","iopub.status.idle":"2021-11-17T05:41:03.093356Z","shell.execute_reply.started":"2021-11-17T05:41:03.013012Z","shell.execute_reply":"2021-11-17T05:41:03.092254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission format","metadata":{}},{"cell_type":"code","source":"submissions = {}\ncount = 0\nfor i in range(1,4):\n    submission = predict(trained_models[i], test_datasets[i])\n    if not submission==None:\n        for s in submission:\n            submissions[count] = {'id': s[0], 'predicted': s[1]}\n            count += 1\n            \npd.DataFrame.from_dict(submissions, orient='index').to_csv('submission.csv', index=False)\ndisplay(pd.read_csv('submission.csv'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}