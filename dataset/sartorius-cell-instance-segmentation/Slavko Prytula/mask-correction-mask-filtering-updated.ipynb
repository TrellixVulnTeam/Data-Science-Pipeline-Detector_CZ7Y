{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Imports**","metadata":{}},{"cell_type":"code","source":"import os\nimport random\nimport time\nimport collections\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom tqdm.notebook import tqdm\n\nimport torch\nimport torchvision\nfrom torchvision.transforms import ToPILImage\nfrom torchvision.transforms import functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\nfrom torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n\nfrom skimage import exposure\nimport torchvision.transforms as T\n\nimport scipy.ndimage as ndi\nimport skimage.morphology as morph\nfrom skimage.filters import threshold_otsu","metadata":{"execution":{"iopub.status.busy":"2021-11-24T07:46:36.517409Z","iopub.execute_input":"2021-11-24T07:46:36.517722Z","iopub.status.idle":"2021-11-24T07:46:36.525534Z","shell.execute_reply.started":"2021-11-24T07:46:36.517686Z","shell.execute_reply":"2021-11-24T07:46:36.524958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TEST = False\n\ndata_directory = '../input/sartorius-cell-instance-segmentation'\nDEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nBATCH_SIZE = 2\nNUM_EPOCHS = 20\n\nTRAIN_CSV = f\"{data_directory}/train.csv\"\nTRAIN_PATH = f\"{data_directory}/train\"\nTEST_PATH = f\"{data_directory}/test\"\n\nWIDTH = 704\nHEIGHT = 520","metadata":{"execution":{"iopub.status.busy":"2021-11-24T07:46:36.527243Z","iopub.execute_input":"2021-11-24T07:46:36.527916Z","iopub.status.idle":"2021-11-24T07:46:36.541175Z","shell.execute_reply.started":"2021-11-24T07:46:36.527854Z","shell.execute_reply":"2021-11-24T07:46:36.540094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Utils**","metadata":{}},{"cell_type":"code","source":"# ref: https://www.kaggle.com/inversion/run-length-decoding-quick-start\ndef rle_decode(mask_rle, shape, color=1):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height, width, channels) of array to return\n    color: color for the mask\n    Returns numpy array (mask)\n\n    '''\n    s = mask_rle.split()\n\n    starts = list(map(lambda x: int(x) - 1, s[0::2]))\n    lengths = list(map(int, s[1::2]))\n    ends = [x + y for x, y in zip(starts, lengths)]\n    if len(shape)==3:\n        img = np.zeros((shape[0] * shape[1], shape[2]), dtype=np.float32)\n    else:\n        img = np.zeros(shape[0] * shape[1], dtype=np.float32)\n    for start, end in zip(starts, ends):\n        img[start : end] = color\n\n    return img.reshape(shape)\n\n\ndef visualize(**images):\n    n = len(images)\n    plt.figure(figsize=(16, 12))\n    for i, (name, image) in enumerate(images.items()):\n        plt.subplot(1, n, i + 1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.title(' '.join(name.split('_')).title())\n        plt.imshow(image)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-24T07:46:36.542539Z","iopub.execute_input":"2021-11-24T07:46:36.542779Z","iopub.status.idle":"2021-11-24T07:46:36.556009Z","shell.execute_reply.started":"2021-11-24T07:46:36.54275Z","shell.execute_reply":"2021-11-24T07:46:36.555136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Mask Utils**","metadata":{}},{"cell_type":"markdown","source":"## **⚠️ [Update]**\n----\n\n\n\n### **Thanks to YU4U :)**\n\n##### There are some great thoughts considering the broken masks: https://www.kaggle.com/ren4yu/sartorius-automatically-finding-broken-masks\n\n----\n\n\n**The basic idea is to only get masks that are not broken**\n- Some of the broken masks have an extensively long continuous lines which we consider an anomaly","metadata":{}},{"cell_type":"code","source":"TH = 40\n\ndef clean_mask(mask):\n    \n    mask = mask > threshold_otsu(np.array(mask).astype(np.uint8))\n    mask = ndi.binary_fill_holes(mask).astype(np.uint8)\n    \n    # New code for mask acceptance\n    contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n    c = contours[0][:, 0]\n    diff = c - np.roll(c, 1, 0)\n    targets = (diff[:, 1] == 0) & (np.abs(diff[:, 0]) >= TH)  # find horizontal lines longer than threshold\n    \n    return mask, (True in targets)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T07:46:36.557485Z","iopub.execute_input":"2021-11-24T07:46:36.55786Z","iopub.status.idle":"2021-11-24T07:46:36.574849Z","shell.execute_reply.started":"2021-11-24T07:46:36.557818Z","shell.execute_reply":"2021-11-24T07:46:36.574048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Dataset + Hole Filling**","metadata":{}},{"cell_type":"code","source":"cell_type_dict = {\"astro\": 1, \"cort\": 2, \"shsy5y\": 3}\n\nclass CellDataset(Dataset):\n    def __init__(self, image_dir, df, show_filled):\n        self.image_dir = image_dir\n        self.df = df\n        self.height = HEIGHT\n        self.width = WIDTH\n        self.show_filled = show_filled\n        \n        self.image_info = collections.defaultdict(dict)\n        temp_df = self.df.groupby([\"id\", \"cell_type\"])['annotation'].agg(lambda x: list(x)).reset_index()\n        for index, row in temp_df.iterrows():\n            self.image_info[index] = {\n                    'image_id': row['id'],\n                    'image_path': os.path.join(self.image_dir, row['id'] + '.png'),\n                    'annotations': list(row[\"annotation\"]),\n                    'cell_type': cell_type_dict[row[\"cell_type\"]]\n                    }\n            \n    def get_box(self, a_mask):\n        ''' Get the bounding box of a given mask '''\n        pos = np.where(a_mask)\n        xmin = np.min(pos[1])\n        xmax = np.max(pos[1])\n        ymin = np.min(pos[0])\n        ymax = np.max(pos[0])\n        return [xmin, ymin, xmax, ymax]\n\n    def __getitem__(self, idx):\n        ''' Get the image and the target'''\n        \n        img_path = self.image_info[idx][\"image_path\"]\n        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n        \n        info = self.image_info[idx]\n\n        n_objects = len(info['annotations'])\n        masks = np.zeros((len(info['annotations']), self.height, self.width), dtype=np.uint8)\n        boxes = []\n        labels = []\n        for i, annotation in enumerate(info['annotations']):\n            a_mask = rle_decode(annotation, (HEIGHT, WIDTH))\n            \n            a_mask = np.array(a_mask) > 0\n            if self.show_filled:\n                a_mask, broken_mask = clean_mask(a_mask)   # CALL THE REFINEMENT FUNCTION\n                if broken_mask:                            # Accept only good masks\n                    continue\n            masks[i, :, :] = a_mask\n            \n            boxes.append(self.get_box(a_mask))\n\n        labels = [int(info[\"cell_type\"]) for _ in range(n_objects)]\n        \n        \n        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n        labels = torch.as_tensor(labels, dtype=torch.int64)\n        masks = torch.as_tensor(masks, dtype=torch.uint8)\n\n        image_id = torch.tensor([idx])\n        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n        iscrowd = torch.zeros((n_objects,), dtype=torch.int64)\n\n        target = {\n            'boxes': boxes,\n            'labels': labels,\n            'masks': masks,\n            'image_id': image_id,\n            'area': area,\n            'iscrowd': iscrowd\n        }\n\n        return img, target\n\n    def __len__(self):\n        return len(self.image_info)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T07:46:36.578177Z","iopub.execute_input":"2021-11-24T07:46:36.578519Z","iopub.status.idle":"2021-11-24T07:46:36.600655Z","shell.execute_reply.started":"2021-11-24T07:46:36.578451Z","shell.execute_reply":"2021-11-24T07:46:36.599445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds_train = CellDataset(TRAIN_PATH, pd.read_csv(TRAIN_CSV), show_filled=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T07:46:36.602083Z","iopub.execute_input":"2021-11-24T07:46:36.602988Z","iopub.status.idle":"2021-11-24T07:46:37.155563Z","shell.execute_reply.started":"2021-11-24T07:46:36.602935Z","shell.execute_reply":"2021-11-24T07:46:37.154306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Problem 01: Masks are not fully filled**","metadata":{}},{"cell_type":"code","source":"image, masks = ds_train[20]\nmasks = np.array(masks[\"masks\"])\nmask = masks[0, :, :]\nfor i in range(len(masks)):\n    mask += masks[i, :, :]\nimage = image[0, :, :]\n\nvisualize(\n    mask=mask,\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T07:46:37.157917Z","iopub.execute_input":"2021-11-24T07:46:37.158306Z","iopub.status.idle":"2021-11-24T07:46:37.48402Z","shell.execute_reply.started":"2021-11-24T07:46:37.158267Z","shell.execute_reply":"2021-11-24T07:46:37.48294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Results**","metadata":{}},{"cell_type":"markdown","source":"- Filling masks","metadata":{}},{"cell_type":"code","source":"ds_train = CellDataset(TRAIN_PATH, pd.read_csv(TRAIN_CSV), show_filled=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T07:46:37.485591Z","iopub.execute_input":"2021-11-24T07:46:37.485844Z","iopub.status.idle":"2021-11-24T07:46:38.007685Z","shell.execute_reply.started":"2021-11-24T07:46:37.485814Z","shell.execute_reply":"2021-11-24T07:46:38.006634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image, masks = ds_train[20]\nmasks = np.array(masks[\"masks\"])\nmask = masks[0, :, :]\nfor i in range(len(masks)):\n    mask += masks[i, :, :]\nimage = image[:, :, 0]\n\nvisualize(\n    filled_mask=mask\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T07:46:38.009363Z","iopub.execute_input":"2021-11-24T07:46:38.009626Z","iopub.status.idle":"2021-11-24T07:46:39.10886Z","shell.execute_reply.started":"2021-11-24T07:46:38.009594Z","shell.execute_reply":"2021-11-24T07:46:39.107804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Problem 02: Masks are correct**","metadata":{}},{"cell_type":"code","source":"ds_train = CellDataset(TRAIN_PATH, pd.read_csv(TRAIN_CSV), show_filled=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T07:46:39.110335Z","iopub.execute_input":"2021-11-24T07:46:39.110604Z","iopub.status.idle":"2021-11-24T07:46:39.634942Z","shell.execute_reply.started":"2021-11-24T07:46:39.110571Z","shell.execute_reply":"2021-11-24T07:46:39.634098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image, masks = ds_train[1]\nmasks = np.array(masks[\"masks\"])\nmask = masks[0, :, :]\nfor i in range(len(masks)):\n    mask += masks[i, :, :]\nimage = image[0, :, :]\n\nvisualize(\n    mask=mask,\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T07:46:39.637943Z","iopub.execute_input":"2021-11-24T07:46:39.63834Z","iopub.status.idle":"2021-11-24T07:46:40.13237Z","shell.execute_reply.started":"2021-11-24T07:46:39.638291Z","shell.execute_reply":"2021-11-24T07:46:40.131275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Results**","metadata":{}},{"cell_type":"markdown","source":"- Filtering masks","metadata":{}},{"cell_type":"code","source":"ds_train = CellDataset(TRAIN_PATH, pd.read_csv(TRAIN_CSV), show_filled=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T07:46:40.134437Z","iopub.execute_input":"2021-11-24T07:46:40.134823Z","iopub.status.idle":"2021-11-24T07:46:40.65988Z","shell.execute_reply.started":"2021-11-24T07:46:40.134772Z","shell.execute_reply":"2021-11-24T07:46:40.65892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image, masks = ds_train[1]\nmasks = np.array(masks[\"masks\"])\nmask = masks[0, :, :]\nfor i in range(len(masks)):\n    mask += masks[i, :, :]\nimage = image[:, :, 0]\n\nvisualize(\n    filled_mask=mask\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T07:46:40.661281Z","iopub.execute_input":"2021-11-24T07:46:40.661542Z","iopub.status.idle":"2021-11-24T07:46:43.716372Z","shell.execute_reply.started":"2021-11-24T07:46:40.661511Z","shell.execute_reply":"2021-11-24T07:46:43.715395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}