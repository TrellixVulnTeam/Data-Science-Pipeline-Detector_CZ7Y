{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import and Install Relevant Modules and Dependencies","metadata":{}},{"cell_type":"code","source":"import os, shutil\nshutil.copytree('../input/detectron2', '/kaggle/working/detectron2')","metadata":{"execution":{"iopub.status.busy":"2022-01-20T16:06:51.225217Z","iopub.execute_input":"2022-01-20T16:06:51.226203Z","iopub.status.idle":"2022-01-20T16:06:51.299764Z","shell.execute_reply.started":"2022-01-20T16:06:51.226156Z","shell.execute_reply":"2022-01-20T16:06:51.298224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install /kaggle/working/detectron2/whls/pycocotools-2.0.2/dist/pycocotools-2.0.2.tar --no-index --find-links /kaggle/working/detectron2/whls \n!pip install /kaggle/working/detectron2/whls/fvcore-0.1.5.post20211019/fvcore-0.1.5.post20211019 --no-index --find-links /kaggle/working/detectron2/whls \n!pip install /kaggle/working/detectron2/whls/antlr4-python3-runtime-4.8/antlr4-python3-runtime-4.8 --no-index --find-links /kaggle/working/detectron2/whls \n!pip install /kaggle/working/detectron2/whls/detectron2-0.5/detectron2 --no-index --find-links /kaggle/working/detectron2/whls \n","metadata":{"execution":{"iopub.status.busy":"2022-01-20T16:06:51.300753Z","iopub.status.idle":"2022-01-20T16:06:51.301394Z","shell.execute_reply.started":"2022-01-20T16:06:51.301155Z","shell.execute_reply":"2022-01-20T16:06:51.301181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport pandas as pd \nfrom tqdm import tqdm\nfrom tqdm import tqdm_notebook as tqdm # progress bar\nfrom datetime import datetime\nimport time\nimport matplotlib.pyplot as plt\nfrom pycocotools.coco import COCO\nimport os, json, cv2, random\nimport skimage.io as io\nimport copy\nfrom pathlib import Path\nfrom typing import Optional\n\n\n\nfrom tqdm import tqdm\nimport itertools\n\nimport torch\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\n\nfrom glob import glob\nimport numba\nfrom numba import jit\n\nimport warnings\nwarnings.filterwarnings('ignore') #Ignore \"future\" warnings and Data-Frame-Slicing warnings.\n\n\n# detectron2\nfrom detectron2.structures import BoxMode\nfrom detectron2 import model_zoo\nfrom detectron2.config import get_cfg\nfrom detectron2.data import DatasetCatalog, MetadataCatalog\nfrom detectron2.engine import DefaultPredictor, DefaultTrainer, launch\nfrom detectron2.evaluation import COCOEvaluator\nfrom detectron2.structures import BoxMode\nfrom detectron2.utils.visualizer import ColorMode\nfrom detectron2.utils.logger import setup_logger\nfrom detectron2.utils.visualizer import Visualizer\n\nfrom detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader, build_detection_train_loader\nfrom detectron2.data import detection_utils as utils\n\n\nfrom detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader, build_detection_train_loader\nfrom detectron2.data import detection_utils as utils\nimport detectron2.data.transforms as T\nfrom detectron2.evaluation import COCOEvaluator, inference_on_dataset\n\nsetup_logger()","metadata":{"execution":{"iopub.status.busy":"2022-01-20T17:01:22.380788Z","iopub.execute_input":"2022-01-20T17:01:22.381467Z","iopub.status.idle":"2022-01-20T17:01:22.398739Z","shell.execute_reply.started":"2022-01-20T17:01:22.38143Z","shell.execute_reply":"2022-01-20T17:01:22.398088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Data_Resister_training=\"sartorius_train\";\nData_Resister_valid=\"sartorius_valid\";\nfrom detectron2.data.datasets import register_coco_instances\ndataDir=Path('../input/train-test')\n\nregister_coco_instances(Data_Resister_training,{}, '../input/train-test/train.json', dataDir)\nregister_coco_instances(Data_Resister_valid,{},'../input/train-test/test.json', dataDir)\n\nmetadata = MetadataCatalog.get(Data_Resister_training)\ndataset_train = DatasetCatalog.get(Data_Resister_training)\ndataset_valid = DatasetCatalog.get(Data_Resister_valid)","metadata":{"execution":{"iopub.status.busy":"2022-01-20T17:01:25.517563Z","iopub.execute_input":"2022-01-20T17:01:25.517836Z","iopub.status.idle":"2022-01-20T17:01:25.547566Z","shell.execute_reply.started":"2022-01-20T17:01:25.517807Z","shell.execute_reply":"2022-01-20T17:01:25.546607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Set Customized Components","metadata":{}},{"cell_type":"code","source":"# Taken from https://www.kaggle.com/theoviel/competition-metric-map-iou\nfrom detectron2.evaluation.evaluator import DatasetEvaluator\nimport pycocotools.mask as mask_util\nfrom detectron2.evaluation import (\n    CityscapesInstanceEvaluator,\n    CityscapesSemSegEvaluator,\n    COCOEvaluator,\n    COCOPanopticEvaluator,\n    DatasetEvaluators,\n    LVISEvaluator,\n    PascalVOCDetectionEvaluator,\n    SemSegEvaluator,\n    verify_results,\n)\n\nfrom detectron2.solver import build_lr_scheduler, build_optimizer\n\ndef build_evaluator(cfg, dataset_name, output_folder=None):\n#This is from https://github.com/facebookresearch/detectron2/blob/main/tools/train_net.py\n\n    if output_folder is None:\n        output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n    evaluator_list = []\n    evaluator_type = MetadataCatalog.get(dataset_name).evaluator_type\n    if evaluator_type in [\"sem_seg\", \"coco_panoptic_seg\"]:\n        evaluator_list.append(\n            SemSegEvaluator(\n                dataset_name,\n                distributed=True,\n                output_dir=output_folder,\n            )\n        )\n    if evaluator_type in [\"coco\", \"coco_panoptic_seg\"]:\n        evaluator_list.append(COCOEvaluator(dataset_name, output_dir=output_folder))\n    if evaluator_type == \"coco_panoptic_seg\":\n        evaluator_list.append(COCOPanopticEvaluator(dataset_name, output_folder))\n    if evaluator_type == \"cityscapes_instance\":\n        return CityscapesInstanceEvaluator(dataset_name)\n    if evaluator_type == \"cityscapes_sem_seg\":\n        return CityscapesSemSegEvaluator(dataset_name)\n    elif evaluator_type == \"pascal_voc\":\n        return PascalVOCDetectionEvaluator(dataset_name)\n    elif evaluator_type == \"lvis\":\n        return LVISEvaluator(dataset_name, output_dir=output_folder)\n    if len(evaluator_list) == 0:\n        raise NotImplementedError(\n            \"no Evaluator for the dataset {} with the type {}\".format(dataset_name, evaluator_type)\n        )\n    elif len(evaluator_list) == 1:\n        return evaluator_list[0]\n    return DatasetEvaluators(evaluator_list)\n\nclass Trainer(DefaultTrainer):\n    @classmethod\n    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n        return build_evaluator(cfg, dataset_name, output_folder)\n    \n    @classmethod\n    def build_optimizer(cls, cfg, model):\n        params: List[Dict[str, Any]] = []\n        for key, value in model.named_parameters():\n            if not value.requires_grad:\n                continue\n            lr = cfg.SOLVER.BASE_LR\n            weight_decay = cfg.SOLVER.WEIGHT_DECAY\n            if key.endswith(\"norm.weight\") or key.endswith(\"norm.bias\"):\n                weight_decay = cfg.SOLVER.WEIGHT_DECAY_NORM\n            elif key.endswith(\".bias\"):\n                lr = cfg.SOLVER.BASE_LR * cfg.SOLVER.BIAS_LR_FACTOR\n                weight_decay = cfg.SOLVER.WEIGHT_DECAY_BIAS\n            params += [{\"params\": [value], \"lr\": lr, \"weight_decay\": weight_decay}]\n\n        optimizer = torch.optim.Adam(params, lr)\n        return build_optimizer(cfg, model)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-20T17:01:30.690289Z","iopub.execute_input":"2022-01-20T17:01:30.690532Z","iopub.status.idle":"2022-01-20T17:01:30.707703Z","shell.execute_reply.started":"2022-01-20T17:01:30.690505Z","shell.execute_reply":"2022-01-20T17:01:30.705592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg = get_cfg()\nconfig_name = \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\" \ncfg.merge_from_file(model_zoo.get_config_file(config_name))\ncfg.DATASETS.TRAIN = (Data_Resister_training,)\ncfg.DATASETS.TEST = (Data_Resister_valid,)\n\ncfg.MODEL.MASK_ON = True\n\ncfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(config_name)\ncfg.DATALOADER.NUM_WORKERS = 4\n\ncfg.MODEL.ANCHOR_GENERATOR.ANGLES = [[-90, -45, 0, 45, 90]]\n\n#In testing phase, I prefer speed\ncfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512  \ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 3 \n\n#The regression loss would be then changed. I hope to try focal loss and shape-aware loss\ncfg.MODEL.ROI_BOX_HEAD.BBOX_REG_LOSS_TYPE = \"ciou\"\n\n#Semantic segmantation head\ncfg.MODEL.SEM_SEG_HEAD.NUM_CLASSES = 3\n\n#Input\ncfg.INPUT.MASK_FORMAT='bitmask'\n\n\n#Solver\ncfg.SOLVER.MAX_ITER = 2000 #Maximum of iterations 1\ncfg.SOLVER.IMS_PER_BATCH = 2 #(2 is per defaults)\n#Default setting is 0.001. To speed up in tunning stage, let's use a ralatively high lr\ncfg.SOLVER.BASE_LR = 0.0001\n#cfg.SOLVER.MOMENTUM = 0.9\ncfg.SOLVER.WEIGHT_DECAY = 0.0005\n#cfg.SOLVER.GAMMA = 0.1\n\n    \ncfg.SOLVER.WARMUP_ITERS = 10 #How many iterations to go from 0 to reach base LR\n\ncfg.SOLVER.STEPS = (500, 1000) #At which point to change the LR 0.25,0.5\ncfg.TEST.EVAL_PERIOD = 250\ncfg.SOLVER.CHECKPOINT_PERIOD=250\n\nos.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n#trainer = AugTrainer(cfg) # with  data augmentation  \ntrainer = Trainer(cfg)  # without data augmentation\n\n#trainer.resume_or_load(resume=False)\n#trainer.train()","metadata":{"execution":{"iopub.status.busy":"2022-01-20T17:01:33.35758Z","iopub.execute_input":"2022-01-20T17:01:33.357848Z","iopub.status.idle":"2022-01-20T17:01:36.613738Z","shell.execute_reply.started":"2022-01-20T17:01:33.357816Z","shell.execute_reply":"2022-01-20T17:01:36.612979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\ncfg.MODEL.WEIGHTS = \"../input/final-model/model_final_586.pth\"\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set a custom testing threshold for this model\ncfg.DATASETS.TEST = (Data_Resister_valid, )\npredictor = DefaultPredictor(cfg)","metadata":{"execution":{"iopub.status.busy":"2022-01-20T17:01:39.23074Z","iopub.execute_input":"2022-01-20T17:01:39.231011Z","iopub.status.idle":"2022-01-20T17:01:40.083311Z","shell.execute_reply.started":"2022-01-20T17:01:39.230981Z","shell.execute_reply":"2022-01-20T17:01:40.08251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rle_decode(mask_rle, shape=(520, 704)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape)  # Needed to align to RLE direction\n\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef get_masks(fn, predictor):\n    im = cv2.imread('../input/sartorius-cell-instance-segmentation/test/' + fn)\n    pred = predictor(im)\n    pred_class = torch.mode(pred['instances'].pred_classes)[0]\n    take = pred['instances'].scores >= THRESHOLDS[pred_class]\n    pred_masks = pred['instances'].pred_masks[take]\n    pred_masks = pred_masks.cpu().numpy()\n    res = []\n    used = np.zeros(im.shape[:2], dtype=int) \n    for mask in pred_masks:\n        mask = mask * (1-used)\n        if mask.sum() >= MIN_PIXELS[pred_class]: # skip predictions with small area\n            used += mask\n            res.append(rle_encode(mask))\n    return res","metadata":{"execution":{"iopub.status.busy":"2022-01-20T17:01:41.041157Z","iopub.execute_input":"2022-01-20T17:01:41.041813Z","iopub.status.idle":"2022-01-20T17:01:41.055685Z","shell.execute_reply.started":"2022-01-20T17:01:41.041775Z","shell.execute_reply":"2022-01-20T17:01:41.054846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ids, masks=[],[]\ntest_names = list(os.walk('../input/sartorius-cell-instance-segmentation/test'))[0][-1]\ntest_names","metadata":{"execution":{"iopub.status.busy":"2022-01-20T17:01:42.507227Z","iopub.execute_input":"2022-01-20T17:01:42.507907Z","iopub.status.idle":"2022-01-20T17:01:42.516404Z","shell.execute_reply.started":"2022-01-20T17:01:42.507871Z","shell.execute_reply":"2022-01-20T17:01:42.515503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg = get_cfg()\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\ncfg.INPUT.MASK_FORMAT='bitmask'\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 3 \ncfg.MODEL.WEIGHTS = \"../input/final-model/model_final_586.pth\"\ncfg.TEST.DETECTIONS_PER_IMAGE = 1000\npredictor = DefaultPredictor(cfg)\nTHRESHOLDS = [.15, .35, .55]\nMIN_PIXELS = [75, 150, 75]","metadata":{"execution":{"iopub.status.busy":"2022-01-20T17:01:43.417563Z","iopub.execute_input":"2022-01-20T17:01:43.418028Z","iopub.status.idle":"2022-01-20T17:01:44.784662Z","shell.execute_reply.started":"2022-01-20T17:01:43.417994Z","shell.execute_reply":"2022-01-20T17:01:44.783789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for fn in test_names:\n    encoded_masks = get_masks(fn, predictor)\n    for enc in encoded_masks:\n        ids.append(fn.replace('.png',''))\n        masks.append(enc)","metadata":{"execution":{"iopub.status.busy":"2022-01-20T17:01:44.787331Z","iopub.execute_input":"2022-01-20T17:01:44.787744Z","iopub.status.idle":"2022-01-20T17:01:45.524614Z","shell.execute_reply.started":"2022-01-20T17:01:44.787705Z","shell.execute_reply":"2022-01-20T17:01:45.523846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoded_masks = get_masks(test_names[1], predictor)\n\n_, axs = plt.subplots(1,2, figsize=(40,15))\naxs[1].imshow(cv2.imread('../input/sartorius-cell-instance-segmentation/test/'+test_names[2])) \nfor enc in encoded_masks: \n    dec = rle_decode(enc) \n    axs[0].imshow(np.ma.masked_where(dec==0, dec))","metadata":{"execution":{"iopub.status.busy":"2022-01-20T17:01:46.627551Z","iopub.execute_input":"2022-01-20T17:01:46.62796Z","iopub.status.idle":"2022-01-20T17:01:55.262679Z","shell.execute_reply.started":"2022-01-20T17:01:46.62791Z","shell.execute_reply":"2022-01-20T17:01:55.262007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    shutil.rmtree(\"/kaggle/working/\")\nexcept:\n    pass\n","metadata":{"execution":{"iopub.status.busy":"2022-01-20T17:33:42.740256Z","iopub.execute_input":"2022-01-20T17:33:42.740522Z","iopub.status.idle":"2022-01-20T17:33:42.745709Z","shell.execute_reply.started":"2022-01-20T17:33:42.740492Z","shell.execute_reply":"2022-01-20T17:33:42.744895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame({'id':ids, 'predicted':masks}).to_csv('/kaggle/working/submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2022-01-20T17:33:50.274249Z","iopub.execute_input":"2022-01-20T17:33:50.274873Z","iopub.status.idle":"2022-01-20T17:33:50.284874Z","shell.execute_reply.started":"2022-01-20T17:33:50.274831Z","shell.execute_reply":"2022-01-20T17:33:50.283973Z"},"trusted":true},"execution_count":null,"outputs":[]}]}