{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-24T18:33:42.959038Z","iopub.execute_input":"2021-12-24T18:33:42.959615Z","iopub.status.idle":"2021-12-24T18:33:42.993402Z","shell.execute_reply.started":"2021-12-24T18:33:42.959462Z","shell.execute_reply":"2021-12-24T18:33:42.99248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nimport cv2\nimport matplotlib.pyplot as plt\n\nimport keras.layers as layers\nfrom keras.layers import (Dense, Activation, LayerNormalization,Conv2DTranspose,add, \n    BatchNormalization, Dropout, Input, Flatten, Conv2D, MaxPool2D, Reshape,UpSampling2D)\nfrom keras import Model","metadata":{"execution":{"iopub.status.busy":"2021-12-24T18:33:42.996335Z","iopub.execute_input":"2021-12-24T18:33:42.997488Z","iopub.status.idle":"2021-12-24T18:33:49.09061Z","shell.execute_reply.started":"2021-12-24T18:33:42.997426Z","shell.execute_reply":"2021-12-24T18:33:49.089326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAIN_ROOT = '../input/sartorius-cell-instance-segmentation'\n\ntrain_csv_path = os.path.join(MAIN_ROOT, 'train.csv')\ntrain_image_path = os.path.join(MAIN_ROOT, 'train')","metadata":{"execution":{"iopub.status.busy":"2021-12-24T18:33:49.095421Z","iopub.execute_input":"2021-12-24T18:33:49.097555Z","iopub.status.idle":"2021-12-24T18:33:49.104279Z","shell.execute_reply.started":"2021-12-24T18:33:49.097503Z","shell.execute_reply":"2021-12-24T18:33:49.103059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_WIDTH = 704\nIMAGE_HEIGHT = 520\n\nBATCH_SIZE = 16","metadata":{"execution":{"iopub.status.busy":"2021-12-24T18:33:49.106421Z","iopub.execute_input":"2021-12-24T18:33:49.108061Z","iopub.status.idle":"2021-12-24T18:33:49.122358Z","shell.execute_reply.started":"2021-12-24T18:33:49.107835Z","shell.execute_reply":"2021-12-24T18:33:49.120363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv(train_csv_path).fillna(-1)\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-24T18:33:49.124468Z","iopub.execute_input":"2021-12-24T18:33:49.124887Z","iopub.status.idle":"2021-12-24T18:33:49.8463Z","shell.execute_reply.started":"2021-12-24T18:33:49.124842Z","shell.execute_reply":"2021-12-24T18:33:49.845338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train_data = train_data.drop(['cell_type', 'plate_time', 'sample_date', 'sample_id', 'elapsed_timedelta', 'height', 'width'], axis = 1)\ntrain_data = train_data.drop(['cell_type', 'plate_time', 'sample_date', 'sample_id', 'elapsed_timedelta'], axis = 1)\n\ntrain_data.head()\ntrain_data.iloc[0]['annotation']","metadata":{"execution":{"iopub.status.busy":"2021-12-24T18:33:49.847548Z","iopub.execute_input":"2021-12-24T18:33:49.847778Z","iopub.status.idle":"2021-12-24T18:33:49.883275Z","shell.execute_reply.started":"2021-12-24T18:33:49.84775Z","shell.execute_reply":"2021-12-24T18:33:49.882159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grouped_EncodedPixels = train_data.groupby('id').apply(list)\ngrouped_EncodedPixels.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-24T18:33:49.884624Z","iopub.execute_input":"2021-12-24T18:33:49.884985Z","iopub.status.idle":"2021-12-24T18:33:49.920627Z","shell.execute_reply.started":"2021-12-24T18:33:49.884946Z","shell.execute_reply":"2021-12-24T18:33:49.919559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2021-12-24T18:33:49.922482Z","iopub.execute_input":"2021-12-24T18:33:49.922748Z","iopub.status.idle":"2021-12-24T18:33:49.927643Z","shell.execute_reply.started":"2021-12-24T18:33:49.922717Z","shell.execute_reply":"2021-12-24T18:33:49.926703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nclass DataGenerator(keras.utils.Sequence):\n    \n    def __init__(self, list_IDs, labels, image_dir, batch_size=32, img_width=704, img_height=520, n_channels=1,\n                 n_classes=1, shuffle=True):\n        'Initialization'\n        self.img_width = img_width\n        self.img_height = img_height\n        self.batch_size = batch_size\n        self.list_IDs = list_IDs\n        self.image_dir = image_dir\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.on_epoch_end()\n        self.labels = labels\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n\n        # Generate data\n        X, y = self.__data_generation(list_IDs_temp)\n\n        return X, y\n    \n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n            \n\n    def __data_generation(self, list_IDs_temp):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        X = np.empty((self.batch_size, self.img_height, self.img_width, self.n_channels))\n        y = np.empty((self.batch_size, self.img_height, self.img_width, self.n_classes))\n\n        # Generate data\n        for idx, id_ in enumerate(list_IDs_temp):\n            \n            file_path = os.path.join(self.image_dir, id_ + '.png')\n            \n            image = cv2.imread(file_path,0) # load gray-scale image\n            \n            image_resized = np.array(image, dtype=np.float64) \n            \n            image_resized -= image_resized.mean()\n            image_resized /= image_resized.std()\n            \n            mask = np.zeros((self.img_height, self.img_width, self.n_classes))\n            \n            db_annotations = labels[labels['id'] == id_]\n            db_annotations = db_annotations.reset_index()\n            \n            for i in range(0,len(db_annotations)):\n                annotation = db_annotations['annotation'][i].split()\n                starts, lengths = [np.asarray(x, dtype=int) for x in (annotation[0:][::2], annotation[1:][::2])]\n                starts -= 1\n                ends = starts + lengths\n                img = np.zeros(db_annotations['width'][0]*db_annotations['height'][0], dtype=np.uint8)\n                img = np.where(img==0, np.nan, img)\n                for lo, hi in zip(starts, ends):\n                    img[lo:hi] = 1\n                    \n                img = img.reshape((self.img_height, self.img_width, self.n_classes))\n                mask += np.nan_to_num(img)\n            \n            # Store sample\n            X[idx,] = np.expand_dims(image_resized, axis=2)\n\n            # Store class\n            y[idx,] = mask\n            \n        #y = (y > 0).astype(int)\n            \n        return X, y\n    ","metadata":{"execution":{"iopub.status.busy":"2021-12-24T18:33:49.929176Z","iopub.execute_input":"2021-12-24T18:33:49.929498Z","iopub.status.idle":"2021-12-24T18:33:50.165805Z","shell.execute_reply.started":"2021-12-24T18:33:49.929453Z","shell.execute_reply":"2021-12-24T18:33:50.165073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {'batch_size':BATCH_SIZE, \n          'img_width':IMAGE_WIDTH, \n          'img_height':IMAGE_HEIGHT, \n          'n_channels':1,\n          'n_classes':1, \n          'shuffle':False}\n\nData_ids = train_data['id'].unique()\n\nlabels = train_data[['id', 'annotation', 'width','height']]\n\nval_size = 100\n#shuffle data\nnp.random.shuffle(Data_ids)\n\n#create train and validation subsets\n#datagen created in such a way, that labels variable same for train and val\ntr_ids = Data_ids[:-val_size]\n\nval_ids = Data_ids[-val_size:]\n\nprint(tr_ids.shape)\nprint(val_ids.shape)\nprint(train_data.describe())\n\nfor id in tr_ids:\n    if id in val_ids:\n        print('kekw')\n        break\n        \n#create datagens for train and valid datasets\nTr_datagen = DataGenerator(tr_ids, labels,  train_image_path,  **params)\nVal_datagen = DataGenerator(val_ids, labels,  train_image_path,  **params)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T18:33:50.167337Z","iopub.execute_input":"2021-12-24T18:33:50.167601Z","iopub.status.idle":"2021-12-24T18:33:50.214215Z","shell.execute_reply.started":"2021-12-24T18:33:50.16757Z","shell.execute_reply":"2021-12-24T18:33:50.2132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DataGen = DataGenerator(Data_ids, labels,  train_image_path,  **params)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T18:33:50.215781Z","iopub.execute_input":"2021-12-24T18:33:50.216605Z","iopub.status.idle":"2021-12-24T18:33:50.222455Z","shell.execute_reply.started":"2021-12-24T18:33:50.216553Z","shell.execute_reply":"2021-12-24T18:33:50.221356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_sample = DataGen.__getitem__(0)\nx, y = data_sample\nprint(x.shape, y.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T18:33:50.223812Z","iopub.execute_input":"2021-12-24T18:33:50.224451Z","iopub.status.idle":"2021-12-24T18:33:55.936055Z","shell.execute_reply.started":"2021-12-24T18:33:50.224403Z","shell.execute_reply":"2021-12-24T18:33:55.935019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_images(id_,plot_image=True):\n    shape=(520, 704)\n    db_annotations = train_data[train_data['id'] == id_]\n    db_annotations = db_annotations.reset_index()\n    cell_photo = Image.open(\"../input/sartorius-cell-instance-segmentation/train/{}.png\".format(id_))\n    list_img= []\n    for i in range(0,len(db_annotations)):\n        annotation = db_annotations['annotation'][i].split()\n        starts, lengths = [np.asarray(x, dtype=int) for x in (annotation[0:][::2], annotation[1:][::2])]\n        starts -= 1\n        ends = starts + lengths\n        img = np.zeros(db_annotations['width'][0]*db_annotations['height'][0], dtype=np.uint8)\n        img = np.where(img==0, np.nan, img)\n        for lo, hi in zip(starts, ends):\n            img[lo:hi] = 1\n            \n        img = img.reshape(shape)\n        list_img.append(img)\n        \n        \n        \n    print('Size of list: {}'.format(len(list_img)))\n    print('Size of mask: {}'.format(list_img[0].shape))\n\n    plt.figure(figsize = (12,9))\n    if plot_image:\n        plt.imshow(cell_photo,cmap='gray',aspect='auto')\n    for i in range(0,len(list_img)):\n        plt.imshow(list_img[i])\n        \n    return list_img","metadata":{"execution":{"iopub.status.busy":"2021-12-24T18:33:55.937473Z","iopub.execute_input":"2021-12-24T18:33:55.937738Z","iopub.status.idle":"2021-12-24T18:33:55.951796Z","shell.execute_reply.started":"2021-12-24T18:33:55.937705Z","shell.execute_reply":"2021-12-24T18:33:55.949869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimg, mask = x[0], y[0]\nplt.figure(figsize=(50,25))\nplt.subplot(2,1,1)\nplt.imshow(img)\nplt.subplot(2,1,2)\nplt.imshow(mask)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-24T18:33:55.955896Z","iopub.execute_input":"2021-12-24T18:33:55.956548Z","iopub.status.idle":"2021-12-24T18:33:57.135123Z","shell.execute_reply.started":"2021-12-24T18:33:55.956506Z","shell.execute_reply":"2021-12-24T18:33:57.134027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"id__ = Data_ids[0]\nlist_masks = plot_images(id__, False)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T18:33:57.136784Z","iopub.execute_input":"2021-12-24T18:33:57.137299Z","iopub.status.idle":"2021-12-24T18:34:12.281309Z","shell.execute_reply.started":"2021-12-24T18:33:57.137243Z","shell.execute_reply":"2021-12-24T18:34:12.280561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"masks = np.zeros((list_masks[0].shape))\nfor mask in list_masks:\n    masks += np.nan_to_num(mask)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T18:34:12.282724Z","iopub.execute_input":"2021-12-24T18:34:12.282962Z","iopub.status.idle":"2021-12-24T18:34:12.598983Z","shell.execute_reply.started":"2021-12-24T18:34:12.282933Z","shell.execute_reply":"2021-12-24T18:34:12.597964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(masks)\nprint(masks.shape)\nplt.figure(figsize=(12,9))\nplt.imshow(masks)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T18:34:12.60045Z","iopub.execute_input":"2021-12-24T18:34:12.600724Z","iopub.status.idle":"2021-12-24T18:34:13.177778Z","shell.execute_reply.started":"2021-12-24T18:34:12.600693Z","shell.execute_reply":"2021-12-24T18:34:13.176855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model(img_size, num_classes):\n    inputs = keras.Input(shape=img_size + (1,))\n    \n    #pad inputs height, because dimensions could be multiple of 2^n, where n - depth of U-net\n    padded_inputs = layers.ZeroPadding2D(padding=(4,0))(inputs)\n\n    ### [First half of the network: downsampling inputs] ###\n\n    # Entry block\n    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(padded_inputs)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation(\"relu\")(x)\n\n    previous_block_activation = x  # Set aside residual\n\n    # Blocks 1, 2, 3 are identical apart from the feature depth.\n    for filters in [64, 128, 256]:\n        x = layers.Activation(\"relu\")(x)\n        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.Activation(\"relu\")(x)\n        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n\n        # Project residual\n        residual = layers.Conv2D(filters, 1, strides=2, padding=\"same\")(\n            previous_block_activation\n        )\n        x = layers.add([x, residual])  # Add back residual\n        previous_block_activation = x  # Set aside next residual\n\n    ### [Second half of the network: upsampling inputs] ###\n\n    for filters in [256, 128, 64, 32]:\n        x = layers.Activation(\"relu\")(x)\n        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.Activation(\"relu\")(x)\n        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.UpSampling2D(2)(x)\n\n        # Project residual\n        residual = layers.UpSampling2D(2)(previous_block_activation)\n        residual = layers.Conv2D(filters, 1, padding=\"same\")(residual)\n        x = layers.add([x, residual])  # Add back residual\n        previous_block_activation = x  # Set aside next residual\n    \n    #get a shape of tensor\n    x_shape = tf.shape(x)\n    #slice a tensor, so we get correct output dimensions\n    x = tf.slice(x, [0,4,0,0], [x_shape[0],520,704,1])\n    \n    # Add a per-pixel classification layer\n    outputs = layers.Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\")(x)\n\n    # Define the model\n    model = keras.Model(inputs, outputs)\n    return model\n\nkeras.backend.clear_session()\n\n# Build model\nsize = (IMAGE_HEIGHT, IMAGE_WIDTH)\nn_classes = 1\nmodel = get_model(size, n_classes)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-24T18:34:13.179265Z","iopub.execute_input":"2021-12-24T18:34:13.179516Z","iopub.status.idle":"2021-12-24T18:34:13.913723Z","shell.execute_reply.started":"2021-12-24T18:34:13.179486Z","shell.execute_reply":"2021-12-24T18:34:13.912661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=['accuracy',\n                                            'MeanSquaredError','AUC'])\n\n# Train the model, doing validation at the end of each epoch.\nepochs = 15\nmodel.fit(Tr_datagen, epochs=epochs, validation_data=Val_datagen)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T18:34:13.915633Z","iopub.execute_input":"2021-12-24T18:34:13.916306Z","iopub.status.idle":"2021-12-24T21:54:40.0315Z","shell.execute_reply.started":"2021-12-24T18:34:13.916228Z","shell.execute_reply":"2021-12-24T21:54:40.02833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('cell_segmentation_model1.h5')","metadata":{"execution":{"iopub.status.busy":"2021-12-24T22:04:45.055421Z","iopub.execute_input":"2021-12-24T22:04:45.055865Z","iopub.status.idle":"2021-12-24T22:04:45.342708Z","shell.execute_reply.started":"2021-12-24T22:04:45.055823Z","shell.execute_reply":"2021-12-24T22:04:45.341424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}