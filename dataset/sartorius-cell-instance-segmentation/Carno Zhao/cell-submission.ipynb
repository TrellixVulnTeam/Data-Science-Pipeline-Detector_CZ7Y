{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install /kaggle/input/mmdetectionv2140/addict-2.4.0-py3-none-any.whl > /dev/null\n!pip install /kaggle/input/mmdetectionv2140/yapf-0.31.0-py2.py3-none-any.whl > /dev/null\n!pip install /kaggle/input/mmdetectionv2140/terminal-0.4.0-py3-none-any.whl > /dev/null\n!pip install /kaggle/input/mmdetectionv2140/terminaltables-3.1.0-py3-none-any.whl > /dev/null\n!pip install /kaggle/input/mmdetectionv2140/pycocotools-2.0.2/pycocotools-2.0.2 > /dev/null\n!pip install /kaggle/input/mmdetectionv2140/mmpycocotools-12.0.3/mmpycocotools-12.0.3 > /dev/nullnull\nimport sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\n\n\n!pip install ../input/mmdetection/mmcv_full-1.3.10-cp37-cp37m-linux_x86_64.whl > /dev/null\n!pip install ../input/mmdetection/mmdet-2.15.0-py3-none-any.whl > /dev/null","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-14T04:31:08.716675Z","iopub.execute_input":"2021-12-14T04:31:08.716975Z","iopub.status.idle":"2021-12-14T04:31:46.079534Z","shell.execute_reply.started":"2021-12-14T04:31:08.716947Z","shell.execute_reply":"2021-12-14T04:31:46.0787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport glob\nimport json\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom tqdm.auto import tqdm\nfrom itertools import product\nimport pycocotools.mask as mutils\nfrom pycocotools.coco import COCO\n\nfrom mmdet.apis.inference import inference_detector, init_detector\n\ndef mask2rle(msk):\n    pixels = msk.flatten()\n    pad    = np.array([0])\n    pixels = np.concatenate([pad, pixels, pad])\n    runs   = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef rle2mask(rle, shape = [520, 704]):\n    s = rle.split()\n    starts, lengths = [np.asarray(x, dtype = int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0] * shape[1], dtype = np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape)\n\n\n\n# gt = COCO(\"/home/zhaoxun/codes/mmdetection/data/cell/train/annotations/fold_0.json\")\n# img_files = [os.path.join(\"/home/zhaoxun/codes/mmdetection/data/cell/train/images\", _[\"file_name\"]) for _ in gt.imgs.values()]\nimg_files = glob.glob(\"../input/sartorius-cell-instance-segmentation/test/*.*\")\n\nsmall_config = \"../input/sartorius-submission/htcr2101_1x_4sc_d2_800_all.py\"\nsmall_ckpt = \"../input/sartorius-submission/htcr2101_1x_4sc_d2_800_all.pth\"\n\nsmall_model = init_detector(small_config, small_ckpt, cfg_options = {\n    #\"data.test.pipeline.1.img_scale\": [(1333, 1333), (1150, 1150), (1024, 1024), (900, 900), (800, 800)],\n    \"model.test_cfg.rpn.nms_pre\": 1000, \n#     \"model.test_cfg.rpn.nms.iou_threshold\": 0.8,\n    \"model.test_cfg.rcnn.nms.type\": \"weighted_cluster_nms\",\n    \"model.test_cfg.rcnn.nms.iou_method\": \"diou\",\n    \"model.test_cfg.rcnn.nms.iou_threshold\": 0.45\n})\n\nTHRESHOLDS_small = [0.4, 0.45, 0.7]\nMIN_PIXELS = [80, 150, 60]\nsmall_ids = [0,1,2]\nprint(len(img_files))","metadata":{"execution":{"iopub.status.busy":"2021-12-14T04:32:23.814595Z","iopub.execute_input":"2021-12-14T04:32:23.815195Z","iopub.status.idle":"2021-12-14T04:33:01.474883Z","shell.execute_reply.started":"2021-12-14T04:32:23.815149Z","shell.execute_reply":"2021-12-14T04:33:01.473976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = []\nfor img_file in tqdm(img_files):\n    img_id = os.path.basename(img_file).split(\".\")[0]\n    img = cv2.imread(img_file)\n    H, W = img.shape[:2]\n    annotations = []\n\n    dets = []\n    for i, j in product(range(4), range(4)):\n        img_cut = img[i * H // 5: (i + 2) * H // 5, j * W // 5: (j + 2) * W // 5]\n        small_det = inference_detector(small_model, img_cut)\n        dets.append([i, j, small_det])\n        \n    cnt_per_class = np.array([[len(_) for _ in det] for i, j, (det, _) in dets]).sum(0).tolist()\n    class_id = cnt_per_class.index(max(cnt_per_class))\n        \n    for i, j, small_det in dets:\n        small_box, small_seg = small_det\n        \n        if isinstance(small_seg, list) and isinstance(small_seg[0], list) and len(small_seg[0]) != 0 and isinstance(small_seg[0][0], list):\n            small_seg = small_seg[0]\n\n        small_box = small_box[class_id]\n        small_seg = small_seg[class_id]\n\n        valid = (small_box[:,-1] > THRESHOLDS_small[class_id]) & \\\n            ~((i <= 2) & (small_box[:,[1,3]].mean(1) > 3 * H / 10)) & \\\n            ~((i >= 1) & (small_box[:,[1,3]].mean(1) < H / 10)) & \\\n            ~((j <= 2) & (small_box[:,[0,2]].mean(1) > 3 * W / 10)) & \\\n            ~((j >= 1) & (small_box[:,[0,2]].mean(1) < W / 10))\n        small_box = small_box[valid]\n        small_seg = [_ for _, v in zip(small_seg, valid) if v]\n\n        for box, seg in zip(small_box, small_seg):\n            if seg.sum() < MIN_PIXELS[class_id]: continue\n            x1, y1, x2, y2, s = [float(_) for _ in box]\n            seg = np.asfortranarray(seg)\n            rle = mutils.encode(seg)\n            annotations.append([[x1, y1, x2 - x1, y2 - y1], rle, s, i, j])\n\n    annotations = sorted(annotations, key = lambda x: -x[-3])\n    masks = np.zeros((H, W), dtype = np.uint); mask_idx = 1\n    \n    for ann in annotations:\n        bbox, rle, s, i, j = ann\n        mask = mutils.decode(rle)\n\n        assign = (mask != 0) & (masks[i * H // 5: (i + 2) * H // 5, j * W // 5: (j + 2) * W // 5] == 0)\n        assign_area = assign.sum()\n        if assign_area < MIN_PIXELS[class_id]:\n            continue\n        num_connected, _ = cv2.connectedComponents(assign.astype(np.uint8))\n        if num_connected > 2:\n            continue\n        overlap_ratio = 1 - assign_area / mask.sum()\n        if overlap_ratio > 0.2:\n            continue\n        masks[i * H // 5: (i + 2) * H // 5, j * W // 5: (j + 2) * W // 5][assign] = mask_idx\n\n\n        mask_idx += 1\n\n    if mask_idx > 1:\n        for idx in range(1, mask_idx):\n            rle = mask2rle((masks == idx).astype(np.uint8))\n            sub.append([img_id, rle])\n    else:\n        sub.append(img_id, \"0 1\")\n\nsub_df = pd.DataFrame(sub, columns = ['id', 'predicted'])\nsub_df.head()\nsub_df.to_csv('submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T04:33:08.001639Z","iopub.execute_input":"2021-12-14T04:33:08.002559Z","iopub.status.idle":"2021-12-14T04:34:35.68069Z","shell.execute_reply.started":"2021-12-14T04:33:08.002509Z","shell.execute_reply":"2021-12-14T04:34:35.679972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    import matplotlib.pyplot as plt\n    import albumentations as A\n\n    fig, ax = plt.subplots(2, 3, figsize = (15, 10))\n\n    for i, img_id in enumerate(sub_df.id.unique()[:3]):\n        img = cv2.imread([_ for _ in img_files if img_id in _][0])\n        ax[0][i].imshow(A.CLAHE(p = 1)(image = img)[\"image\"])\n        ax[0][i].axis(\"off\")\n        for rle in sub_df.loc[sub_df.id == img_id, \"predicted\"]:\n            mask = rle2mask(rle, img.shape[:2])\n            img[mask != 0] = img[mask != 0] // 2 + np.random.randint(0, 256, 3) // 2\n        ax[1][i].imshow(img)\n        ax[1][i].axis(\"off\")\n\n    plt.show(fig)\n    plt.close(fig)\nexcept:\n    pass","metadata":{"execution":{"iopub.status.busy":"2021-12-14T04:36:08.803015Z","iopub.execute_input":"2021-12-14T04:36:08.803296Z","iopub.status.idle":"2021-12-14T04:36:10.098749Z","shell.execute_reply.started":"2021-12-14T04:36:08.80326Z","shell.execute_reply":"2021-12-14T04:36:10.097631Z"},"trusted":true},"execution_count":null,"outputs":[]}]}