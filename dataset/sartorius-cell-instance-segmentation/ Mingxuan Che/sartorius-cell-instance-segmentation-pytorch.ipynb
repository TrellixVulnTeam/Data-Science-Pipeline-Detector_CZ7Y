{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-11-29T08:26:56.134922Z","iopub.execute_input":"2021-11-29T08:26:56.135242Z","iopub.status.idle":"2021-11-29T08:26:58.378496Z","shell.execute_reply.started":"2021-11-29T08:26:56.13521Z","shell.execute_reply":"2021-11-29T08:26:58.361514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Importing the required libraries**","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch import optim\nfrom torch.utils.tensorboard import SummaryWriter\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\n# import torchvision.transforms.functional as TF\n\nimport random\nimport os, shutil\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom tqdm.auto import tqdm\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nimport os\nfrom os.path import join\nimport matplotlib.pyplot as plt\nplt.rcParams.update({'font.size': 18})\nimport cv2\n\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset, sampler\nfrom albumentations import (HorizontalFlip, VerticalFlip, ShiftScaleRotate, Normalize, Resize, Compose, GaussNoise)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score","metadata":{"execution":{"iopub.status.busy":"2021-11-29T08:26:58.380973Z","iopub.execute_input":"2021-11-29T08:26:58.38135Z","iopub.status.idle":"2021-11-29T08:26:58.416074Z","shell.execute_reply.started":"2021-11-29T08:26:58.381293Z","shell.execute_reply":"2021-11-29T08:26:58.415287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train = pd.read_csv('../input/sartorius-cell-instance-segmentation/train.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-29T08:26:58.417493Z","iopub.execute_input":"2021-11-29T08:26:58.419825Z","iopub.status.idle":"2021-11-29T08:26:58.968218Z","shell.execute_reply.started":"2021-11-29T08:26:58.419775Z","shell.execute_reply":"2021-11-29T08:26:58.967206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-29T08:26:58.97087Z","iopub.execute_input":"2021-11-29T08:26:58.971477Z","iopub.status.idle":"2021-11-29T08:26:58.995989Z","shell.execute_reply.started":"2021-11-29T08:26:58.971415Z","shell.execute_reply":"2021-11-29T08:26:58.995019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Visualization of the images**","metadata":{}},{"cell_type":"code","source":"def imshow(num_to_show=9):\n    \n    plt.figure(figsize=(20,20))\n    \n    for i in range(num_to_show):\n        plt.subplot(3, 3, i+1)\n        plt.grid(False)\n        plt.xticks([])\n        plt.yticks([])\n        \n        img = mpimg.imread(f'../input/sartorius-cell-instance-segmentation/train/{data_train.iloc[i,0]}.png')\n        plt.imshow(img, cmap='plasma')\n\nimshow()","metadata":{"execution":{"iopub.status.busy":"2021-11-29T08:26:58.997825Z","iopub.execute_input":"2021-11-29T08:26:58.998443Z","iopub.status.idle":"2021-11-29T08:27:00.181362Z","shell.execute_reply.started":"2021-11-29T08:26:58.9984Z","shell.execute_reply":"2021-11-29T08:27:00.18029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATA_PATH = '../input/sartorius-cell-instance-segmentation'\nSAMPLE_SUBMISSION = join(DATA_PATH,'train')\nTRAIN_CSV = join(DATA_PATH,'train.csv')\nTRAIN_PATH = join(DATA_PATH,'train')\nTEST_PATH = join(DATA_PATH,'test')\n\ndf_train = pd.read_csv(TRAIN_CSV)\nprint(f'Training Set Shape: {df_train.shape} - {df_train[\"id\"].nunique()} \\\nImages - Memory Usage: {df_train.memory_usage().sum() / 1024 ** 2:.2f} MB')","metadata":{"execution":{"iopub.status.busy":"2021-11-29T08:27:00.18301Z","iopub.execute_input":"2021-11-29T08:27:00.183983Z","iopub.status.idle":"2021-11-29T08:27:00.510761Z","shell.execute_reply.started":"2021-11-29T08:27:00.183941Z","shell.execute_reply":"2021-11-29T08:27:00.50972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rle_decode(mask_rle, shape, color=1):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0] * shape[1], dtype=np.float32)\n    for lo, hi in zip(starts, ends):\n        img[lo : hi] = color\n    return img.reshape(shape)\n\ndef build_masks(df_train, image_id, input_shape):\n    height, width = input_shape\n    labels = df_train[df_train[\"id\"] == image_id][\"annotation\"].tolist()\n    mask = np.zeros((height, width))\n    for label in labels:\n        mask += rle_decode(label, shape=(height, width))\n    mask = mask.clip(0, 1)\n    return np.array(mask)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T08:27:00.51257Z","iopub.execute_input":"2021-11-29T08:27:00.513121Z","iopub.status.idle":"2021-11-29T08:27:00.524392Z","shell.execute_reply.started":"2021-11-29T08:27:00.513075Z","shell.execute_reply":"2021-11-29T08:27:00.523364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Dataset class**","metadata":{}},{"cell_type":"code","source":"class CellDataset(Dataset):\n    def __init__(self, df: pd.core.frame.DataFrame, train:bool):\n        self.IMAGE_RESIZE = (224, 224)\n        self.RESNET_MEAN = (0.485, 0.456, 0.406)\n        self.RESNET_STD = (0.229, 0.224, 0.225)\n        self.df = df\n        self.base_path = TRAIN_PATH\n        self.gb = self.df.groupby('id')\n        self.transforms = Compose([Resize( self.IMAGE_RESIZE[0],  self.IMAGE_RESIZE[1]), \n                                   Normalize(mean=self.RESNET_MEAN, std= self.RESNET_STD, p=1), \n                                   HorizontalFlip(p=0.5),\n                                   VerticalFlip(p=0.5)])\n        \n        # Split train and val set\n        all_image_ids = np.array(df_train.id.unique())\n        np.random.seed(42)\n        iperm = np.random.permutation(len(all_image_ids))\n        num_train_samples = int(len(all_image_ids) * 0.9)\n\n        if train:\n            self.image_ids = all_image_ids[iperm[:num_train_samples]]\n        else:\n             self.image_ids = all_image_ids[iperm[num_train_samples:]]\n\n    def __getitem__(self, idx: int) -> dict:\n\n        image_id = self.image_ids[idx]\n        df = self.gb.get_group(image_id)\n\n        # Read image\n        image_path = os.path.join(self.base_path, image_id + \".png\")\n        image = cv2.imread(image_path)\n\n        # Create the mask\n        mask = build_masks(df_train, image_id, input_shape=(520, 704))\n        mask = (mask >= 1).astype('float32')\n        augmented = self.transforms(image=image, mask=mask)\n        image = augmented['image']\n        mask = augmented['mask']\n        # print(np.moveaxis(image,0,2).shape)\n        return np.moveaxis(np.array(image),2,0), mask.reshape((1, self.IMAGE_RESIZE[0], self.IMAGE_RESIZE[1]))\n\n\n    def __len__(self):\n        return len(self.image_ids)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T08:27:00.526114Z","iopub.execute_input":"2021-11-29T08:27:00.526741Z","iopub.status.idle":"2021-11-29T08:27:00.545231Z","shell.execute_reply.started":"2021-11-29T08:27:00.526694Z","shell.execute_reply":"2021-11-29T08:27:00.544315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Loaders**","metadata":{}},{"cell_type":"code","source":"ds_train = CellDataset(df_train, train=True)\ndl_train = DataLoader(ds_train, batch_size=16, num_workers=2, pin_memory=True, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T08:27:00.547199Z","iopub.execute_input":"2021-11-29T08:27:00.547547Z","iopub.status.idle":"2021-11-29T08:27:00.568293Z","shell.execute_reply.started":"2021-11-29T08:27:00.547504Z","shell.execute_reply":"2021-11-29T08:27:00.567219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds_test = CellDataset(df_train, train=False)\ndl_test = DataLoader(ds_test, batch_size=4, num_workers=2, pin_memory=True, shuffle=False)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-29T08:27:00.57403Z","iopub.execute_input":"2021-11-29T08:27:00.57548Z","iopub.status.idle":"2021-11-29T08:27:00.600322Z","shell.execute_reply.started":"2021-11-29T08:27:00.575434Z","shell.execute_reply":"2021-11-29T08:27:00.599307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Visualization of the images and masks**","metadata":{}},{"cell_type":"code","source":"# plot simages and mask from dataloader\nbatch = next(iter(dl_train))\nimages, masks = batch\nprint(f\"image shape: {images.shape},\\nmask shape:{masks.shape},\\nbatch len: {len(batch)}\")\n\nplt.figure(figsize=(20, 20))\n        \nplt.subplot(1, 3, 1)\nplt.xticks([])\nplt.yticks([])\nplt.imshow(images[1][1])\nplt.title('Original image')\n\nplt.subplot( 1, 3, 2)\nplt.xticks([])\nplt.yticks([])\nprint(masks[1][0])\nplt.imshow(masks[1][0])\nplt.title('Mask')\n\nplt.subplot( 1, 3, 3)\nplt.xticks([])\nplt.yticks([])\nplt.imshow(images[1][1])\nplt.imshow(masks[1][0],alpha=0.2)\nplt.title('Both')\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-29T08:27:00.601636Z","iopub.execute_input":"2021-11-29T08:27:00.601942Z","iopub.status.idle":"2021-11-29T08:27:05.038615Z","shell.execute_reply.started":"2021-11-29T08:27:00.601901Z","shell.execute_reply":"2021-11-29T08:27:05.037701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Train the model**","metadata":{}},{"cell_type":"code","source":"class DoubleConv(nn.Module):\n    def __init__(self, in_ch, out_ch):\n        super(DoubleConv, self).__init__()\n        self.conv = nn.Sequential( \n            nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(out_ch),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_ch, out_ch, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(out_ch),\n            nn.ReLU(inplace=True)\n         )\n    def forward(self, x):\n        x = self.conv(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-11-29T08:27:05.040223Z","iopub.execute_input":"2021-11-29T08:27:05.041143Z","iopub.status.idle":"2021-11-29T08:27:05.052642Z","shell.execute_reply.started":"2021-11-29T08:27:05.041089Z","shell.execute_reply":"2021-11-29T08:27:05.051256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class InConv(nn.Module):\n    def __init__(self, in_ch, out_ch):\n        super(InConv, self).__init__()\n        self.conv = DoubleConv(in_ch, out_ch)\n    def forward(self, x):\n        x = self.conv(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-11-29T08:27:05.054804Z","iopub.execute_input":"2021-11-29T08:27:05.055183Z","iopub.status.idle":"2021-11-29T08:27:05.064661Z","shell.execute_reply.started":"2021-11-29T08:27:05.055135Z","shell.execute_reply":"2021-11-29T08:27:05.06305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Down(nn.Module):\n    def __init__(self, in_ch, out_ch):\n        super(Down, self).__init__()\n        self.mpconv = nn.Sequential( \n            nn.MaxPool2d(2,2),\n            DoubleConv(in_ch, out_ch)\n         )\n    def forward(self, x):\n        x = self.mpconv(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-11-29T08:27:05.066214Z","iopub.execute_input":"2021-11-29T08:27:05.067542Z","iopub.status.idle":"2021-11-29T08:27:05.077082Z","shell.execute_reply.started":"2021-11-29T08:27:05.067495Z","shell.execute_reply":"2021-11-29T08:27:05.075657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Up(nn.Module):\n    def __init__(self, in_ch, out_ch):\n        super(Up, self).__init__()\n        self.up = nn.ConvTranspose2d(in_ch // 2, in_ch // 2, kernel_size=2, stride=2)\n        self.conv = DoubleConv(in_ch, out_ch)\n    def forward(self, x1, x2):\n        x1 = self.up(x1)\n        x = torch.cat([x2, x1], dim=1)\n        x = self.conv(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-11-29T08:27:05.078717Z","iopub.execute_input":"2021-11-29T08:27:05.07986Z","iopub.status.idle":"2021-11-29T08:27:05.090287Z","shell.execute_reply.started":"2021-11-29T08:27:05.0798Z","shell.execute_reply":"2021-11-29T08:27:05.088879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class OutConv(nn.Module):\n    def __init__(self, in_ch, out_ch):\n        super(OutConv, self).__init__()\n        self.conv = nn.Conv2d(in_ch, out_ch, 1)\n        self.sigmoid = nn.Sigmoid()\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.sigmoid(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-11-29T08:27:05.092538Z","iopub.execute_input":"2021-11-29T08:27:05.093277Z","iopub.status.idle":"2021-11-29T08:27:05.105069Z","shell.execute_reply.started":"2021-11-29T08:27:05.093212Z","shell.execute_reply":"2021-11-29T08:27:05.104006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class UNet(nn.Module):\n    def __init__(self, in_channels, num_classes):\n        super(UNet, self).__init__()\n        self.inc = InConv(in_channels, 64)\n        self.down1 = Down(64, 128)\n        self.down2 = Down(128, 256)\n        self.down3 = Down(256, 512)\n        self.down4 = Down(512, 512)\n        self.up1 = Up(1024, 256)\n        self.up2 = Up(512, 128)\n        self.up3 = Up(256, 64)\n        self.up4 = Up(128, 64)\n        self.outc = OutConv(64, num_classes)\n    def forward(self, x):\n        # print(x.shape)\n        x1 = self.inc(x)\n        # print(x1.shape)\n        x2 = self.down1(x1)\n        # print(x2.shape)\n        x3 = self.down2(x2)\n        # print(x3.shape)\n        x4 = self.down3(x3)\n        # print(x4.shape)\n        x5 = self.down4(x4)\n        # print(x5.shape)\n        # print('up')\n        x = self.up1(x5, x4)\n        # print(x.shape)\n        x = self.up2(x, x3)\n        # print(x.shape)\n        x = self.up3(x, x2)\n        # print(x.shape)\n        x = self.up4(x, x1)\n        # print(x.shape)\n        x = self.outc(x)\n        # print(x.shape)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-11-29T08:27:05.106972Z","iopub.execute_input":"2021-11-29T08:27:05.107675Z","iopub.status.idle":"2021-11-29T08:27:05.121703Z","shell.execute_reply.started":"2021-11-29T08:27:05.107628Z","shell.execute_reply":"2021-11-29T08:27:05.120602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')","metadata":{"execution":{"iopub.status.busy":"2021-11-29T08:27:05.12356Z","iopub.execute_input":"2021-11-29T08:27:05.124262Z","iopub.status.idle":"2021-11-29T08:27:05.132935Z","shell.execute_reply.started":"2021-11-29T08:27:05.124203Z","shell.execute_reply":"2021-11-29T08:27:05.131617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_loop(model, optimizer, criterion, train_loader, device=device):\n    running_loss = 0\n    model.train()\n    pbar = tqdm(train_loader, desc='Iterating over train data')\n    for imgs, masks in pbar:\n        # pass to device\n        imgs = imgs.to(device)\n        masks = masks.to(device)\n        # forward\n        out = model(imgs)\n        loss = criterion(out, masks)\n        running_loss += loss.item()*imgs.shape[0]  # += loss * current batch size\n        # optimize\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    running_loss /= len(train_loader.sampler)\n    return running_loss","metadata":{"execution":{"iopub.status.busy":"2021-11-29T08:27:05.134947Z","iopub.execute_input":"2021-11-29T08:27:05.13563Z","iopub.status.idle":"2021-11-29T08:27:05.146141Z","shell.execute_reply.started":"2021-11-29T08:27:05.135579Z","shell.execute_reply":"2021-11-29T08:27:05.145052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def eval_loop(model, criterion, eval_loader, device=device):\n    running_loss = 0\n    model.eval()\n    with torch.no_grad():\n        accuracy, f1_scores = [], []\n        pbar = tqdm(eval_loader, desc='Iterating over evaluation data')\n        \n        for imgs, masks in pbar:\n#             print(imgs.shape)\n#             print(masks.shape)\n            # pass to device\n            li=imgs\n            lm=masks\n            imgs = imgs.to(device)\n            masks = masks.to(device)\n            # forward\n            out = model(imgs)\n#             print(out.shape)\n            loss = criterion(out, masks)\n            running_loss += loss.item()*imgs.shape[0]\n            # calculate predictions using output\n            predicted = (out > 0.5).float()\n#             print(predicted.shape)\n            predicted = predicted.view(-1).cpu().numpy()\n            labels = masks.view(-1).cpu().numpy()\n#             print(predicted.shape)\n#             print(labels.shape)\n            accuracy.append(accuracy_score(labels, predicted))\n            f1_scores.append(f1_score(labels, predicted))\n    acc = sum(accuracy)/len(accuracy)\n    f1 = sum(f1_scores)/len(f1_scores)\n    running_loss /= len(eval_loader.sampler)\n    return {\n        'accuracy':acc,\n        'f1_macro':f1, \n        'loss':running_loss,\n        'img': li,\n        'masks': lm,\n        'out':out\n        \n        \n    }","metadata":{"execution":{"iopub.status.busy":"2021-11-29T08:27:05.148547Z","iopub.execute_input":"2021-11-29T08:27:05.149464Z","iopub.status.idle":"2021-11-29T08:27:05.163616Z","shell.execute_reply.started":"2021-11-29T08:27:05.149414Z","shell.execute_reply":"2021-11-29T08:27:05.16254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model, optimizer, criterion, train_loader, valid_loader,\n          device=device, \n          num_epochs=20, \n          valid_loss_min=np.inf,\n          logdir='logdir'):\n    \n    tb_writer = SummaryWriter(log_dir=logdir)\n    for e in range(num_epochs):\n        # train for epoch\n        train_loss = train_loop(\n            model, optimizer, criterion, train_loader, device=device)\n        # evaluate on validation set\n        metrics = eval_loop(\n            model, criterion, valid_loader, device=device\n        )\n        # show progress\n        print_string = f'Epoch: {e+1} '\n        print_string+= f'TrainLoss: {train_loss:.5f} '\n        print_string+= f'ValidLoss: {metrics[\"loss\"]:.5f} '\n        print_string+= f'ACC: {metrics[\"accuracy\"]:.5f} '\n        print_string+= f'F1: {metrics[\"f1_macro\"]:.3f}'\n        print(print_string)\n\n        # Tensorboards Logging\n        tb_writer.add_scalar('UNet/Train Loss', train_loss, e)\n        tb_writer.add_scalar('UNet/Valid Loss', metrics[\"loss\"], e)\n        tb_writer.add_scalar('UNet/Accuracy', metrics[\"accuracy\"], e)\n        tb_writer.add_scalar('UNet/F1 Macro', metrics[\"f1_macro\"], e)\n\n        # save the model \n        if metrics[\"loss\"] <= valid_loss_min:\n            torch.save(model.state_dict(), 'UNet.pt')\n            valid_loss_min = metrics[\"loss\"]","metadata":{"execution":{"iopub.status.busy":"2021-11-29T08:27:05.165565Z","iopub.execute_input":"2021-11-29T08:27:05.166226Z","iopub.status.idle":"2021-11-29T08:27:05.179188Z","shell.execute_reply.started":"2021-11-29T08:27:05.166176Z","shell.execute_reply":"2021-11-29T08:27:05.178049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set_seed(21)\nmodel = UNet(3, 1).to(device)\noptimizer = optim.Adam(model.parameters(), lr=0.01)\ncriterion = nn.BCELoss()\ntrain(model, optimizer, criterion, dl_train, dl_test)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T08:27:05.182177Z","iopub.execute_input":"2021-11-29T08:27:05.183207Z","iopub.status.idle":"2021-11-29T08:46:38.009563Z","shell.execute_reply.started":"2021-11-29T08:27:05.183174Z","shell.execute_reply":"2021-11-29T08:46:38.008088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Evaluation**","metadata":{}},{"cell_type":"code","source":"# Load the latest model\nmodel.load_state_dict(torch.load('UNet.pt'))\nmetrics = eval_loop(model, criterion, dl_test)\nprint('accuracy:', metrics['accuracy'])\nprint('f1 macro:', metrics['f1_macro'])\nprint('test loss:', metrics['loss'])","metadata":{"execution":{"iopub.status.busy":"2021-11-29T08:46:38.012403Z","iopub.execute_input":"2021-11-29T08:46:38.012817Z","iopub.status.idle":"2021-11-29T08:46:44.750703Z","shell.execute_reply.started":"2021-11-29T08:46:38.012744Z","shell.execute_reply":"2021-11-29T08:46:44.749349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20, 20))\nout=metrics['out'].cpu()     \nplt.subplot(1, 3, 1)\nplt.xticks([])\nplt.yticks([])\nplt.imshow(metrics['img'][0][1])\nplt.title('Original image')\n\nplt.subplot( 1, 3, 2)\nplt.xticks([])\nplt.yticks([])\n\nplt.imshow(out[0][0])\nplt.title('Masks(Predicted)')\n\n# plt.subplot( 1, 4, 3)\n# plt.xticks([])\n# plt.yticks([])\n# print(metrics['img'].shape)\n# plt.imshow(metrics['img'][0][1])\n# plt.imshow(out[0][0],alpha=0.2)\n# plt.title('Both')\n# plt.tight_layout()\n# plt.show()\n\nplt.subplot( 1,3, 3)\nplt.xticks([])\nplt.yticks([])\nplt.imshow(metrics['masks'][0][0])\nplt.title('Real masks(Label)')\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-29T08:56:57.428738Z","iopub.execute_input":"2021-11-29T08:56:57.429034Z","iopub.status.idle":"2021-11-29T08:56:57.956038Z","shell.execute_reply.started":"2021-11-29T08:56:57.429003Z","shell.execute_reply":"2021-11-29T08:56:57.955132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n \n# 进行mask存储,rle一种压缩存储方式\n# 还有一种是polygon(多边形)\n \n \n \n# 这个函数是对mask进行rle编码,所以输入的值非0即1\ndef mask2rle(img):\n    '''\n    Convert mask to rle.\n    img: numpy array, \n    1 - mask, \n    0 - background\n    \n    Returns run length as string formated\n    '''\n    print(\"看下输入的img\",img)\n    pixels= img.T.flatten()#转置后看图像\n    print(\"pixels进行flatten以后=\",pixels)\n# pixels进行flatten以后= [1 1 0 0 0 0 0 0 0 0 0 0 1 1]#14位\n    pixels = np.concatenate([[0], pixels, [0]])\n    print(\"pixels=\",pixels)\n#                 pixels = [0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 0]#16位\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    print(\"runs=\",runs)#这个记录的是bit值开始变化的位置,这里+1是为了位置的调整\n    runs[1::2] -= runs[::2]\n    #这句代码写得很抽象,其实是在进行编码.\n    #运行前的结果是：\n    # runs= [ 1  3 13  15]   #runs中的每个数值都代表像素值发生变化的位置\n    # 运行后的结果是:\n    # runs= [ 1  2 13  2]\n    # 意思是第1个位置算起，共有2个bit是相同的，所以用3-1得到\n    # 意思是第13个位置算起，共有2个bit是相同的，所以用15-13得到。\n    # 对应上面头部和末尾的两个11\n \n \n    print(\"runs=\",runs)\n    return ' '.join(str(x) for x in runs)\nresult=mask2rle(img)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T22:25:09.893459Z","iopub.execute_input":"2021-11-23T22:25:09.894001Z","iopub.status.idle":"2021-11-23T22:25:09.902472Z","shell.execute_reply.started":"2021-11-23T22:25:09.893964Z","shell.execute_reply":"2021-11-23T22:25:09.901487Z"},"trusted":true},"execution_count":null,"outputs":[]}]}