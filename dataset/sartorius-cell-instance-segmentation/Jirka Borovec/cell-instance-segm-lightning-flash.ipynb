{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ðŸ¦  Cell Instance Segmentation with Lightningâš¡Flash\n\n[Flash](https://lightning-flash.readthedocs.io/en/stable) makes complex AI recipes for over 15 tasks across 7 data domains accessible to all.\n\nIn a nutshell, Flash is the production grade research framework you always dreamed of but didn't have time to build.","metadata":{}},{"cell_type":"code","source":"! ls -l /kaggle/input/sartorius-cell-instance-segmentation\n! pip list | grep -E \"lightning|torch|icevision|Pillow\"","metadata":{"execution":{"iopub.status.busy":"2021-12-30T11:06:07.848792Z","iopub.execute_input":"2021-12-30T11:06:07.849172Z","iopub.status.idle":"2021-12-30T11:06:13.253812Z","shell.execute_reply.started":"2021-12-30T11:06:07.849078Z","shell.execute_reply":"2021-12-30T11:06:13.252414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ! pip install -q lightning-flash[image]\n# ! pip install -q 'https://github.com/PyTorchLightning/lightning-flash/archive/refs/heads/bugfix/icevision_memory_leak.zip#egg=lightning-flash[image]'\n! pip install -q 'https://github.com/gianscarpe/lightning-flash/archive/refs/heads/instance_segmentation_papercut.zip#egg=lightning-flash[image]'\n! pip install -q \"icevision[all]>=0.11\" torchvision -U\n# ! pip install -q 'https://github.com/Borda/icevision/archive/refs/heads/try/imageio.zip#egg=icevision[all]'\n! pip install -q pandas Pillow -U --force-reinstall\n! pip uninstall -q -y torchtext\n! pip list | grep -E \"lightning|torch|icevision|Pillow\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-12-30T11:06:13.257061Z","iopub.execute_input":"2021-12-30T11:06:13.257392Z","iopub.status.idle":"2021-12-30T11:09:54.604228Z","shell.execute_reply.started":"2021-12-30T11:06:13.257342Z","shell.execute_reply":"2021-12-30T11:09:54.603044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data preparation\n\nMoving the data to be Coco complient in zero folder depth...","metadata":{}},{"cell_type":"code","source":"! mkdir -p /kaggle/working/dataset/annotations\n! mkdir -p /kaggle/working/dataset/images\n! cp /kaggle/input/sartorius-cell-instance-segmentation/LIVECell_dataset_2021/annotations/LIVECell/*.json /kaggle/working/dataset/annotations/\n! mkdir /kaggle/working/dataset/images/livecell_test_images/\n! mkdir /kaggle/working/dataset/images/livecell_train_val_images/\n! cp /kaggle/input/sartorius-cell-instance-segmentation/LIVECell_dataset_2021/images/livecell_test_images/*/*.tif /kaggle/working/dataset/images/livecell_test_images/\n! cp /kaggle/input/sartorius-cell-instance-segmentation/LIVECell_dataset_2021/images/livecell_train_val_images/*/*.tif /kaggle/working/dataset/images/livecell_train_val_images/","metadata":{"execution":{"iopub.status.busy":"2021-12-30T11:09:54.607679Z","iopub.execute_input":"2021-12-30T11:09:54.608049Z","iopub.status.idle":"2021-12-30T11:10:53.16802Z","shell.execute_reply.started":"2021-12-30T11:09:54.608001Z","shell.execute_reply":"2021-12-30T11:10:53.166395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training with Flash Lightning\n\nSee the instance segm. docs: https://lightning-flash.readthedocs.io/en/stable/reference/instance_segmentation.html","metadata":{}},{"cell_type":"code","source":"%reload_ext autoreload\n%autoreload 2\n\nimport os\n\nPATH_PREDICT = \"/kaggle/input/sartorius-cell-instance-segmentation/test\"\nPATH_DATASET = \"/kaggle/input/sartorius-cell-instance-segmentation/LIVECell_dataset_2021\"\nLOCAL_DIR_DATASET = \"/kaggle/working/dataset\"\nLOCAL_DIR_ANNOTATIONS = os.path.join(LOCAL_DIR_DATASET, \"annotations\")\nLOCAL_DIR_IMAGES_TRAIN = os.path.join(LOCAL_DIR_DATASET, \"images\", \"livecell_train_val_images\")\nLOCAL_DIR_IMAGES_TEST = os.path.join(LOCAL_DIR_DATASET, \"images\", \"livecell_test_images\")","metadata":{"execution":{"iopub.status.busy":"2021-12-30T11:10:53.174365Z","iopub.execute_input":"2021-12-30T11:10:53.175251Z","iopub.status.idle":"2021-12-30T11:10:53.251394Z","shell.execute_reply.started":"2021-12-30T11:10:53.175075Z","shell.execute_reply":"2021-12-30T11:10:53.250089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import glob\nimport cv2\nfrom tqdm.auto import tqdm\n\nls_images = glob.glob(f\"{LOCAL_DIR_IMAGES_TRAIN}/*.tif\") + glob.glob(f\"{LOCAL_DIR_IMAGES_TEST}/*.tif\")\n\nfor img in tqdm(ls_images):\n  cv2.imwrite(img.replace(\".tif\", \".png\"), cv2.imread(img))","metadata":{"execution":{"iopub.status.busy":"2021-12-30T11:10:53.255699Z","iopub.execute_input":"2021-12-30T11:10:53.256047Z","iopub.status.idle":"2021-12-30T11:13:09.48882Z","shell.execute_reply.started":"2021-12-30T11:10:53.256005Z","shell.execute_reply":"2021-12-30T11:13:09.48784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fixing the Coco annotations","metadata":{}},{"cell_type":"code","source":"import os\nimport glob\nimport json\nimport pandas as pd\nfrom tqdm.auto import tqdm\n\nNB_ANNOTTAIONS_THR = 900\nannots = glob.glob(os.path.join(LOCAL_DIR_ANNOTATIONS, \"*.json\"))\nddirs = dict(train=LOCAL_DIR_IMAGES_TRAIN, val=LOCAL_DIR_IMAGES_TRAIN, test=LOCAL_DIR_IMAGES_TEST)\n\nfor annot in tqdm(sorted(annots)):\n    with open(annot) as fp:\n        data = json.load(fp)\n    if isinstance(data['annotations'], dict):\n        data['annotations'] = list(data['annotations'].values())\n        \n    for d in data['images']:\n        d['file_name'] = d['file_name'].replace(\".tif\", \".png\")\n        \n#     df_counts = pd.DataFrame(data['annotations']).groupby(['image_id']).size()\n#     too_large = df_counts[df_counts >= NB_ANNOTTAIONS_THR].index.to_list()\n#     df_counts.hist(bins=50, grid=True)\n#     data['annotations'] = [d for d in data['annotations'] if d['image_id'] not in too_large]\n\n#     fname, _ = os.path.splitext(os.path.basename(annot))\n#     img_dir = ddirs[fname.split(\"_\")[-1]]\n#     miss_ = [d for d in data['images'] if not os.path.isfile(os.path.join(img_dir, d['file_name']))]\n#     large_ = [d for d in data['images'] if d['id'] in too_large]\n#     data['images'] = [d for d in data['images'] if os.path.isfile(os.path.join(img_dir, d['file_name'])) and d['id'] not in too_large]\n#     print(f\"{len(data['images'])} (miss {len(miss_)}, large {len(large_)}) images and {len(data['annotations'])} annots in {os.path.basename(annot)}\")\n\n    with open(annot, 'w') as fp:\n        json.dump(data, fp)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T11:13:09.490955Z","iopub.execute_input":"2021-12-30T11:13:09.491588Z","iopub.status.idle":"2021-12-30T11:17:36.436055Z","shell.execute_reply.started":"2021-12-30T11:13:09.49154Z","shell.execute_reply":"2021-12-30T11:17:36.435001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. Create the DataModule","metadata":{}},{"cell_type":"code","source":"from flash.image import InstanceSegmentationData\n\ndatamodule = InstanceSegmentationData.from_coco(\n    train_folder=LOCAL_DIR_IMAGES_TRAIN,\n    train_ann_file=os.path.join(LOCAL_DIR_ANNOTATIONS, \"livecell_coco_train.json\"),\n    val_folder=LOCAL_DIR_IMAGES_TRAIN,\n    val_ann_file=os.path.join(LOCAL_DIR_ANNOTATIONS, \"livecell_coco_val.json\"),\n    test_folder=LOCAL_DIR_IMAGES_TEST,\n    test_ann_file=os.path.join(LOCAL_DIR_ANNOTATIONS, \"livecell_coco_test.json\"),\n#     predict_folder=PATH_PREDICT,\n#     data_fetcher: Optional[BaseDataFetcher] = None,\n#     preprocess: Optional[Preprocess] = None,\n    batch_size=16,\n    num_workers=0,\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T11:17:36.437638Z","iopub.execute_input":"2021-12-30T11:17:36.440342Z","iopub.status.idle":"2021-12-30T11:21:39.422966Z","shell.execute_reply.started":"2021-12-30T11:17:36.440295Z","shell.execute_reply":"2021-12-30T11:21:39.421803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Build the task","metadata":{}},{"cell_type":"code","source":"from flash.image import InstanceSegmentation\n\nmodel = InstanceSegmentation(\n    head=\"mask_rcnn\",\n    backbone=\"resnet18_fpn\",\n    num_classes=datamodule.num_classes,\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T11:21:39.424869Z","iopub.execute_input":"2021-12-30T11:21:39.425523Z","iopub.status.idle":"2021-12-30T11:21:41.179551Z","shell.execute_reply.started":"2021-12-30T11:21:39.425474Z","shell.execute_reply":"2021-12-30T11:21:41.177943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Create the trainer and finetune the model","metadata":{}},{"cell_type":"code","source":"import torch\nimport flash\nfrom pytorch_lightning.loggers import CSVLogger\n\nlogger = CSVLogger(save_dir='logs/')\ntrainer = flash.Trainer(\n    max_epochs=3,\n    gpus=torch.cuda.device_count(),\n    logger=logger,\n    progress_bar_refresh_rate=1,\n    precision=16,\n    benchmark=True,\n    accumulate_grad_batches=12,\n    #auto_lr_find=True,\n)\n\n# ==============================\n\n# trainer.tune(\n#     model, \n#     datamodule=datamodule, \n#     lr_find_kwargs=dict(min_lr=2e-5, max_lr=1e-2, num_training=25),\n#     # scale_batch_size_kwargs=dict(max_trials=5),\n# )\n# print(f\"Batch size: {datamodule.batch_size}\")\n# print(f\"Learning Rate: {model.learning_rate}\")\n\n# ==============================\n\ntrainer.finetune(model, datamodule=datamodule, strategy=\"freeze\")","metadata":{"execution":{"iopub.status.busy":"2021-12-30T11:21:41.186396Z","iopub.execute_input":"2021-12-30T11:21:41.187546Z","iopub.status.idle":"2021-12-30T11:21:49.429861Z","shell.execute_reply.started":"2021-12-30T11:21:41.187495Z","shell.execute_reply":"2021-12-30T11:21:49.427671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nsns.set()\n\nmetrics = pd.read_csv(f'{trainer.logger.log_dir}/metrics.csv')\ndisplay(metrics.head())\nmetrics.set_index(\"step\", inplace=True)\ndel metrics[\"epoch\"]\nsns.relplot(data=metrics, kind=\"line\")","metadata":{"execution":{"iopub.status.busy":"2021-12-30T11:21:49.431383Z","iopub.status.idle":"2021-12-30T11:21:49.432305Z","shell.execute_reply.started":"2021-12-30T11:21:49.431908Z","shell.execute_reply":"2021-12-30T11:21:49.431957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Detect objects in a few images!","metadata":{}},{"cell_type":"code","source":"import glob, os\nimport numpy as np\nimport matplotlib.pyplot as plt\n\npredict_imgs = sorted(glob.glob(os.path.join(PATH_PREDICT, \"*.png\")))\n\npredictions = model.predict(predict_imgs)\n\nfor p_img, pred in zip(predict_imgs, predictions):\n    print(p_img, pred.keys())\n    img = plt.imread(p_img)\n    mask = np.zeros(img.shape[:2])\n    for lb, m in enumerate(pred[\"masks\"]):\n        mask[m] = lb + 1\n    fig, axarr = plt.subplots(ncols=2)\n    axarr[0].imshow(img)\n    axarr[1].imshow(mask)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T11:21:49.433785Z","iopub.status.idle":"2021-12-30T11:21:49.434567Z","shell.execute_reply.started":"2021-12-30T11:21:49.434213Z","shell.execute_reply":"2021-12-30T11:21:49.434246Z"},"trusted":true},"execution_count":null,"outputs":[]}]}