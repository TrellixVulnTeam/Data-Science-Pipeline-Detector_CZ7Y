{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport os\nimport cv2 \nimport tensorflow as tf\n\nfrom keras.models import Model, load_model\nfrom keras.layers import Input\nfrom keras.layers.core import Dropout, Lambda\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-21T09:20:50.302148Z","iopub.execute_input":"2021-12-21T09:20:50.3025Z","iopub.status.idle":"2021-12-21T09:20:55.910893Z","shell.execute_reply.started":"2021-12-21T09:20:50.302405Z","shell.execute_reply":"2021-12-21T09:20:55.910009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"files = 0\nimages = 0\nannotations = 0\n\nfor num, (dirname, _, filenames,) in enumerate(os.walk('/kaggle/input')):\n    for file, filename in enumerate(filenames):\n        if file==2:\n            print(dirname, \"  ... many on this folder\")\n        if filename.endswith((\"xlsx\", \"txt\", \"csv\")):\n            files+=1\n            print(os.path.join(dirname, filename))\n        elif filename.endswith((\"png\", \"jpeg\", \"jpg\",)):\n            images+=1\n        else:\n            annotations+=1\nprint(\"...\\n\")\nprint(\"#\"*10, \"        files: {} images: {} annotations: {}\".format(files, images, annotations))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-21T09:20:55.912379Z","iopub.execute_input":"2021-12-21T09:20:55.912628Z","iopub.status.idle":"2021-12-21T09:20:56.853965Z","shell.execute_reply.started":"2021-12-21T09:20:55.912599Z","shell.execute_reply":"2021-12-21T09:20:56.853066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Original unet taken from https://www.kaggle.com/stpeteishii/cell-instance-segmentation-unet","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" # data understanding","metadata":{}},{"cell_type":"code","source":"# read data first. The csv is the core.\ntrain_data = pd.read_csv('../input/sartorius-cell-instance-segmentation/train.csv')\nprint(train_data.shape)\ntrain_data.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T09:35:48.988152Z","iopub.execute_input":"2021-12-21T09:35:48.989108Z","iopub.status.idle":"2021-12-21T09:35:49.729607Z","shell.execute_reply.started":"2021-12-21T09:35:48.989044Z","shell.execute_reply":"2021-12-21T09:35:49.728562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submision sample\nsample_submission=pd.read_csv('../input/sartorius-cell-instance-segmentation/sample_submission.csv')\nprint(sample_submission.shape)\nsample_submission.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T09:35:49.73126Z","iopub.execute_input":"2021-12-21T09:35:49.731505Z","iopub.status.idle":"2021-12-21T09:35:49.754597Z","shell.execute_reply.started":"2021-12-21T09:35:49.731478Z","shell.execute_reply":"2021-12-21T09:35:49.753753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we will focus on the train folder, as it contains the images to process. The others not for now.\nprint(\"Number of images in the folder train:\")\nlen(os.listdir('../input/sartorius-cell-instance-segmentation/train'))","metadata":{"execution":{"iopub.status.busy":"2021-12-21T09:46:47.418405Z","iopub.execute_input":"2021-12-21T09:46:47.418699Z","iopub.status.idle":"2021-12-21T09:46:47.429966Z","shell.execute_reply.started":"2021-12-21T09:46:47.418668Z","shell.execute_reply":"2021-12-21T09:46:47.429324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Number of unique id on the file:\")\ntrain_data.id.unique().shape","metadata":{"execution":{"iopub.status.busy":"2021-12-21T09:46:47.63096Z","iopub.execute_input":"2021-12-21T09:46:47.631635Z","iopub.status.idle":"2021-12-21T09:46:47.652415Z","shell.execute_reply.started":"2021-12-21T09:46:47.631593Z","shell.execute_reply":"2021-12-21T09:46:47.651527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The id column contains all the train images codes. But each id column is repetead an have several notations. Each of the have diferent counts","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,6))\ntrain_data.groupby(\"id\").size().plot.bar();\nplt.xticks([])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T09:46:53.322218Z","iopub.execute_input":"2021-12-21T09:46:53.322674Z","iopub.status.idle":"2021-12-21T09:46:55.328155Z","shell.execute_reply.started":"2021-12-21T09:46:53.322641Z","shell.execute_reply":"2021-12-21T09:46:55.327091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_data[train_data[\"id\"]==\"0030fd0e6378\"][\"id\"].count())\nprint(train_data[train_data[\"id\"]==\"0140b3c8f445\"][\"id\"].count())","metadata":{"execution":{"iopub.status.busy":"2021-12-21T09:47:02.559462Z","iopub.execute_input":"2021-12-21T09:47:02.559713Z","iopub.status.idle":"2021-12-21T09:47:02.594126Z","shell.execute_reply.started":"2021-12-21T09:47:02.559688Z","shell.execute_reply":"2021-12-21T09:47:02.593271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# other columns\ntrain_data.sample_id.unique().shape","metadata":{"execution":{"iopub.status.busy":"2021-12-21T09:47:06.059852Z","iopub.execute_input":"2021-12-21T09:47:06.060614Z","iopub.status.idle":"2021-12-21T09:47:06.074809Z","shell.execute_reply.started":"2021-12-21T09:47:06.06057Z","shell.execute_reply":"2021-12-21T09:47:06.073842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data[train_data[\"id\"]==\"0030fd0e6378\"][\"sample_id\"].unique()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T09:47:10.037099Z","iopub.execute_input":"2021-12-21T09:47:10.037712Z","iopub.status.idle":"2021-12-21T09:47:10.058497Z","shell.execute_reply.started":"2021-12-21T09:47:10.037661Z","shell.execute_reply":"2021-12-21T09:47:10.057504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sample_id is bounded to the id\ntrain_data.groupby([\"id\", \"sample_id\"]).size().count()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T09:47:19.340149Z","iopub.execute_input":"2021-12-21T09:47:19.34053Z","iopub.status.idle":"2021-12-21T09:47:19.368445Z","shell.execute_reply.started":"2021-12-21T09:47:19.340493Z","shell.execute_reply":"2021-12-21T09:47:19.367543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking for missing values. None\ntrain_data.isnull().sum().sum()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T09:47:23.017108Z","iopub.execute_input":"2021-12-21T09:47:23.017829Z","iopub.status.idle":"2021-12-21T09:47:23.08608Z","shell.execute_reply.started":"2021-12-21T09:47:23.017781Z","shell.execute_reply":"2021-12-21T09:47:23.085378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\ntrain_data.groupby('cell_type').size().plot.bar()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T09:47:30.264252Z","iopub.execute_input":"2021-12-21T09:47:30.264565Z","iopub.status.idle":"2021-12-21T09:47:30.438743Z","shell.execute_reply.started":"2021-12-21T09:47:30.264533Z","shell.execute_reply":"2021-12-21T09:47:30.437956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\ntrain_data.groupby(['width', 'height']).size().plot.bar()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T09:47:34.787604Z","iopub.execute_input":"2021-12-21T09:47:34.787923Z","iopub.status.idle":"2021-12-21T09:47:35.20632Z","shell.execute_reply.started":"2021-12-21T09:47:34.787868Z","shell.execute_reply":"2021-12-21T09:47:35.205523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Summary of the columns:\n    - id: name of the train picture\n    - annotation: info of the target mask of the neuron cells\n    - width, heigh: width and heigh of the images (constant of 704x520)\n    - plate_time: not usefull\n    - sample_date: not usefull\n    - sample_id\n    - Elapsed_timedelta: not usefull","metadata":{}},{"cell_type":"code","source":"# check the images\nimg = cv2.imread(\"../input/sartorius-cell-instance-segmentation/train_semi_supervised/astro[hippo]_D1-1_Vessel-361_2020-09-14_13h00m00s_Ph_1.png\")\nplt.imshow(img);","metadata":{"execution":{"iopub.status.busy":"2021-12-21T09:47:44.625Z","iopub.execute_input":"2021-12-21T09:47:44.625501Z","iopub.status.idle":"2021-12-21T09:47:44.9611Z","shell.execute_reply.started":"2021-12-21T09:47:44.625447Z","shell.execute_reply":"2021-12-21T09:47:44.960228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = cv2.imread(\"../input/sartorius-cell-instance-segmentation/train/0140b3c8f445.png\")\nplt.imshow(img);","metadata":{"execution":{"iopub.status.busy":"2021-12-21T09:47:57.445433Z","iopub.execute_input":"2021-12-21T09:47:57.445687Z","iopub.status.idle":"2021-12-21T09:47:57.763692Z","shell.execute_reply.started":"2021-12-21T09:47:57.44566Z","shell.execute_reply":"2021-12-21T09:47:57.763063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# add the filters to see it better\nfrom PIL import Image, ImageEnhance\nimg = cv2.imread(\"../input/sartorius-cell-instance-segmentation/train/042c17cd9143.png\")\nimg = np.asarray(ImageEnhance.Contrast(Image.fromarray(img)).enhance(16))\n\nplt.figure()\nplt.imshow(img);","metadata":{"execution":{"iopub.status.busy":"2021-12-21T09:48:02.629416Z","iopub.execute_input":"2021-12-21T09:48:02.629828Z","iopub.status.idle":"2021-12-21T09:48:02.972888Z","shell.execute_reply.started":"2021-12-21T09:48:02.629798Z","shell.execute_reply":"2021-12-21T09:48:02.968521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sooo an image id has several anotations... but there are multiple id's repetitions with the same sample_id...\ntrain_data[train_data[\"id\"]==\"0030fd0e6378\"]","metadata":{"execution":{"iopub.status.busy":"2021-12-21T09:48:21.458289Z","iopub.execute_input":"2021-12-21T09:48:21.459142Z","iopub.status.idle":"2021-12-21T09:48:21.489939Z","shell.execute_reply.started":"2021-12-21T09:48:21.459103Z","shell.execute_reply":"2021-12-21T09:48:21.489039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# how to process annotations.\n\n# read one annotation\nmask_rle = train_data[train_data[\"id\"] == \"0030fd0e6378\"][\"annotation\"].tolist()[0]\nshape=(520, 704, 3)\ns = mask_rle.split()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T09:48:32.937793Z","iopub.execute_input":"2021-12-21T09:48:32.938091Z","iopub.status.idle":"2021-12-21T09:48:32.956735Z","shell.execute_reply.started":"2021-12-21T09:48:32.938061Z","shell.execute_reply":"2021-12-21T09:48:32.9558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"starts = list(map(lambda x: int(x) - 1, s[0::2])) # get the starting coordinate (on the even positions)\nlengths = list(map(int, s[1::2])) # get the lenght (on the not even positions)\nends = [x + y for x, y in zip(starts, lengths)] # calculate the end point (starting point + lenght)\n\n# create a blank inage\nimg = np.zeros((shape[0] * shape[1], shape[2]), dtype=np.float32)\n\n# fill the positions on the image with a color to create the mask\nfor start, end in zip(starts, ends):\n    img[start : end] = 1\n\nplt.figure()  \nplt.imshow(img.reshape(shape));","metadata":{"execution":{"iopub.status.busy":"2021-12-21T09:48:44.393256Z","iopub.execute_input":"2021-12-21T09:48:44.393747Z","iopub.status.idle":"2021-12-21T09:48:44.723241Z","shell.execute_reply.started":"2021-12-21T09:48:44.393695Z","shell.execute_reply":"2021-12-21T09:48:44.72256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_data[train_data[\"id\"] == \"0030fd0e6378\"][\"annotation\"].tolist())","metadata":{"execution":{"iopub.status.busy":"2021-12-21T09:48:48.58596Z","iopub.execute_input":"2021-12-21T09:48:48.586245Z","iopub.status.idle":"2021-12-21T09:48:48.605693Z","shell.execute_reply.started":"2021-12-21T09:48:48.586213Z","shell.execute_reply":"2021-12-21T09:48:48.604915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reference: https://www.kaggle.com/ihelon/cell-segmentation-run-length-decoding\n#https://www.kaggle.com/susnato/understanding-run-length-encoding-and-decoding?scriptVersionId=77552323\n# coding packed into one function\n\ndef rle_decode(mask_rle, shape, color=3):     #color=1,3\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height, width, channels) of array to return \n    color: color for the mask\n    Returns numpy array (mask)\n    '''\n    s = mask_rle.split()\n    \n    starts = list(map(lambda x: int(x) - 1, s[0::2]))\n    lengths = list(map(int, s[1::2]))\n    ends = [x + y for x, y in zip(starts, lengths)]\n    \n    img = np.zeros((shape[0] * shape[1], shape[2]), dtype=np.float32)\n            \n    for start, end in zip(starts, ends):\n        img[start : end] = color\n    \n    return img.reshape(shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T09:49:15.809338Z","iopub.execute_input":"2021-12-21T09:49:15.810061Z","iopub.status.idle":"2021-12-21T09:49:15.818335Z","shell.execute_reply.started":"2021-12-21T09:49:15.810027Z","shell.execute_reply":"2021-12-21T09:49:15.817237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# other version\n# https://www.kaggle.com/c/sartorius-cell-instance-segmentation/discussion/291627\ndef rle_decode(mask_rle, shape=(520, 704, 1)):\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape)  # Needed to align to RLE direction\n\ndef rle_encode(img):\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T09:49:18.423491Z","iopub.execute_input":"2021-12-21T09:49:18.424111Z","iopub.status.idle":"2021-12-21T09:49:18.433443Z","shell.execute_reply.started":"2021-12-21T09:49:18.424071Z","shell.execute_reply":"2021-12-21T09:49:18.432552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# each mask annotation has one area\nmask = train_data[train_data[\"id\"] == \"0030fd0e6378\"][\"annotation\"].tolist()[0]\nimg = rle_decode(mask)\nplt.imshow(img, cmap=\"gray\");","metadata":{"execution":{"iopub.status.busy":"2021-12-21T09:49:22.79632Z","iopub.execute_input":"2021-12-21T09:49:22.797178Z","iopub.status.idle":"2021-12-21T09:49:23.077643Z","shell.execute_reply.started":"2021-12-21T09:49:22.797136Z","shell.execute_reply":"2021-12-21T09:49:23.077044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask","metadata":{"execution":{"iopub.status.busy":"2021-12-21T09:49:23.078902Z","iopub.execute_input":"2021-12-21T09:49:23.07921Z","iopub.status.idle":"2021-12-21T09:49:23.083746Z","shell.execute_reply.started":"2021-12-21T09:49:23.079184Z","shell.execute_reply":"2021-12-21T09:49:23.083174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-21T09:49:27.88727Z","iopub.execute_input":"2021-12-21T09:49:27.887564Z","iopub.status.idle":"2021-12-21T09:49:27.892917Z","shell.execute_reply.started":"2021-12-21T09:49:27.887535Z","shell.execute_reply":"2021-12-21T09:49:27.892133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rle_encode(img)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T09:49:32.427244Z","iopub.execute_input":"2021-12-21T09:49:32.429861Z","iopub.status.idle":"2021-12-21T09:49:32.437723Z","shell.execute_reply.started":"2021-12-21T09:49:32.429806Z","shell.execute_reply":"2021-12-21T09:49:32.43703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# revert the encodig has a correct recosntruction?\nplt.imshow(rle_decode(rle_encode(img)));","metadata":{"execution":{"iopub.status.busy":"2021-12-21T09:50:07.75587Z","iopub.execute_input":"2021-12-21T09:50:07.756521Z","iopub.status.idle":"2021-12-21T09:50:08.021979Z","shell.execute_reply.started":"2021-12-21T09:50:07.756486Z","shell.execute_reply":"2021-12-21T09:50:08.021208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# data processing","metadata":{}},{"cell_type":"code","source":"def plot_masks(image_id, colors=False):\n    labels = train_data[train_data[\"id\"] == image_id][\"annotation\"].tolist()\n\n    if colors:\n        mask = np.zeros((520, 704, 3))\n        for label in labels:\n            mask += rle_decode(label, shape=(520, 704, 3), color=np.random.rand(3))\n    else:\n        mask = np.zeros((520, 704, 1))\n        for label in labels:\n            mask += rle_decode(label, shape=(520, 704, 1))\n    mask = mask.clip(0, 1)\n\n    image = cv2.imread(f\"../input/sartorius-cell-instance-segmentation/train/{image_id}.png\")\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n    plt.figure(figsize=(18,6))\n    plt.subplot(1, 3, 1)\n    plt.imshow(image)\n    plt.title('Input image')\n    plt.axis(\"off\")\n    \n    plt.subplot(1, 3, 2)\n    plt.imshow(image)\n    plt.imshow(mask, alpha=0.1)\n    plt.title('Input image with mask')\n    plt.axis(\"off\")\n    \n    plt.subplot(1, 3, 3)\n    plt.imshow(mask)\n    plt.title('Only mask')\n    plt.axis(\"off\")\n    \n    plt.show();","metadata":{"execution":{"iopub.status.busy":"2021-12-21T10:00:08.541428Z","iopub.execute_input":"2021-12-21T10:00:08.541718Z","iopub.status.idle":"2021-12-21T10:00:08.553534Z","shell.execute_reply.started":"2021-12-21T10:00:08.541689Z","shell.execute_reply":"2021-12-21T10:00:08.552605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_ids = ['0030fd0e6378','0140b3c8f445','01ae5a43a2ab']\n\nfor sample_id in sample_ids:\n    celltype=train_data[train_data['id']==sample_id]['cell_type'].tolist()[0]\n    file_path = '../input/sartorius-cell-instance-segmentation/train/' + sample_id + '.png'\n    image_df = cv2.imread(file_path)\n    print('ID:', sample_id, ', CellType:',celltype)\n    plot_masks(sample_id, colors=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T10:00:08.718262Z","iopub.execute_input":"2021-12-21T10:00:08.718647Z","iopub.status.idle":"2021-12-21T10:00:10.514734Z","shell.execute_reply.started":"2021-12-21T10:00:08.718605Z","shell.execute_reply":"2021-12-21T10:00:10.513737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reference: https://www.kaggle.com/keegil/keras-u-net-starter-lb-0-277\nIMG_HEIGHT = 256\nIMG_WIDTH = 256\nIMG_CHANNELS = 3\nTRAIN_PATH = '../input/sartorius-cell-instance-segmentation/train/'\n\ntrain_ids = train_data['id'].unique().tolist()\ntest_ids = sample_submission['id'].unique().tolist()\n\n# Get and resize train images and masks\nX_train = np.zeros((train_data['id'].nunique(), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\nY_train = np.zeros((train_data['id'].nunique(), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T10:01:22.436249Z","iopub.execute_input":"2021-12-21T10:01:22.436555Z","iopub.status.idle":"2021-12-21T10:01:22.465128Z","shell.execute_reply.started":"2021-12-21T10:01:22.436517Z","shell.execute_reply":"2021-12-21T10:01:22.464119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nfor n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n    path = TRAIN_PATH + id_\n    img = cv2.imread(path + '.png')[:,:]\n    img = cv2.resize(img, (IMG_HEIGHT, IMG_WIDTH), interpolation = cv2.INTER_LINEAR)\n    #img = np.expand_dims(img, axis = 2)\n    X_train[n] = img\n    \n    labels = train_data[train_data[\"id\"] == id_][\"annotation\"].tolist()\n    mask = np.zeros((520, 704, 1))\n    for label in labels:\n        mask += rle_decode(label, shape=(520, 704, 1))\n    mask = mask.clip(0, 1)\n    mask = mask[:,:,0]\n\n    mask = np.expand_dims(cv2.resize(mask, (IMG_HEIGHT, IMG_WIDTH), interpolation = cv2.INTER_LINEAR), axis=-1)\n    \n    Y_train[n] = mask\nprint(\"Done\")","metadata":{"execution":{"iopub.status.busy":"2021-12-21T10:01:33.105609Z","iopub.execute_input":"2021-12-21T10:01:33.105905Z","iopub.status.idle":"2021-12-21T10:02:24.94936Z","shell.execute_reply.started":"2021-12-21T10:01:33.105874Z","shell.execute_reply":"2021-12-21T10:02:24.948543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get and resize test images\nX_test = np.zeros((sample_submission['id'].nunique(), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\ntest_images_id = []\nfor n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n    path = TRAIN_PATH.replace('train', 'test') + id_\n    img = cv2.imread(path + '.png')[:,:]\n    img = cv2.resize(img, (IMG_HEIGHT, IMG_WIDTH), interpolation = cv2.INTER_LINEAR)\n    #img = np.expand_dims(img, axis = 2)\n    X_test[n] = img\n    test_images_id.append(id_)\nprint(\"Done\")","metadata":{"execution":{"iopub.status.busy":"2021-12-21T11:29:09.7393Z","iopub.execute_input":"2021-12-21T11:29:09.740099Z","iopub.status.idle":"2021-12-21T11:29:09.783999Z","shell.execute_reply.started":"2021-12-21T11:29:09.740044Z","shell.execute_reply":"2021-12-21T11:29:09.783174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape,Y_train.shape,X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T10:02:25.012738Z","iopub.execute_input":"2021-12-21T10:02:25.013123Z","iopub.status.idle":"2021-12-21T10:02:25.019941Z","shell.execute_reply.started":"2021-12-21T10:02:25.013078Z","shell.execute_reply":"2021-12-21T10:02:25.019079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_id_num = 40\nplt.imshow(X_train[sample_id_num][:,:,0], cmap = 'gray')\nplt.show()\nplt.imshow(Y_train[sample_id_num][:,:,0])\nplt.show()\n\nprint('Input image:','Min:', X_train[sample_id_num][:,:,0].min(), '; Max:', X_train[sample_id_num][:,:,0].max(), '; Mean:', X_train[sample_id_num][:,:,0].mean())\nprint('Mask:','Min:', Y_train[sample_id_num][:,:,0].min(), '; Max:', Y_train[sample_id_num][:,:,0].max(), '; Mean:', Y_train[sample_id_num][:,:,0].mean())","metadata":{"execution":{"iopub.status.busy":"2021-12-21T10:02:29.325238Z","iopub.execute_input":"2021-12-21T10:02:29.325572Z","iopub.status.idle":"2021-12-21T10:02:29.728971Z","shell.execute_reply.started":"2021-12-21T10:02:29.325541Z","shell.execute_reply":"2021-12-21T10:02:29.728347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# modeling","metadata":{"execution":{"iopub.status.busy":"2021-12-05T11:10:54.148824Z","iopub.execute_input":"2021-12-05T11:10:54.149111Z","iopub.status.idle":"2021-12-05T11:10:54.152922Z","shell.execute_reply.started":"2021-12-05T11:10:54.14908Z","shell.execute_reply":"2021-12-05T11:10:54.152239Z"}}},{"cell_type":"code","source":"#dice_coefficient\ndef dice_coefficient(y_true, y_pred):\n    numerator = 2 * tf.reduce_sum(y_true * y_pred)\n    denominator = tf.reduce_sum(y_true + y_pred)\n    return numerator / (denominator + tf.keras.backend.epsilon())","metadata":{"execution":{"iopub.status.busy":"2021-12-21T10:02:34.741211Z","iopub.execute_input":"2021-12-21T10:02:34.742001Z","iopub.status.idle":"2021-12-21T10:02:34.747936Z","shell.execute_reply.started":"2021-12-21T10:02:34.741946Z","shell.execute_reply":"2021-12-21T10:02:34.747086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build U-Net model\ninputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\nactivation='elu'\ns = Lambda(lambda x: x / 255) (inputs)\n\nc1 = Conv2D(16, (3, 3), activation=activation, kernel_initializer='he_normal', padding='same') (s)\nc1 = Dropout(0.1) (c1)\nc1 = Conv2D(16, (3, 3), activation=activation, kernel_initializer='he_normal', padding='same') (c1)\np1 = MaxPooling2D((2, 2)) (c1)\n\nc2 = Conv2D(32, (3, 3), activation=activation, kernel_initializer='he_normal', padding='same') (p1)\nc2 = Dropout(0.1) (c2)\nc2 = Conv2D(32, (3, 3), activation=activation, kernel_initializer='he_normal', padding='same') (c2)\np2 = MaxPooling2D((2, 2)) (c2)\n\nc3 = Conv2D(64, (3, 3), activation=activation, kernel_initializer='he_normal', padding='same') (p2)\nc3 = Dropout(0.2) (c3)\nc3 = Conv2D(64, (3, 3), activation=activation, kernel_initializer='he_normal', padding='same') (c3)\np3 = MaxPooling2D((2, 2)) (c3)\n\nc4 = Conv2D(128, (3, 3), activation=activation, kernel_initializer='he_normal', padding='same') (p3)\nc4 = Dropout(0.2) (c4)\nc4 = Conv2D(128, (3, 3), activation=activation, kernel_initializer='he_normal', padding='same') (c4)\np4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n\nc5 = Conv2D(256, (3, 3), activation=activation, kernel_initializer='he_normal', padding='same') (p4)\nc5 = Dropout(0.3) (c5)\nc5 = Conv2D(256, (3, 3), activation=activation, kernel_initializer='he_normal', padding='same') (c5)\n\nu6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\nu6 = concatenate([u6, c4])\nc6 = Conv2D(128, (3, 3), activation=activation, kernel_initializer='he_normal', padding='same') (u6)\nc6 = Dropout(0.2) (c6)\nc6 = Conv2D(128, (3, 3), activation=activation, kernel_initializer='he_normal', padding='same') (c6)\n\nu7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\nu7 = concatenate([u7, c3])\nc7 = Conv2D(64, (3, 3), activation=activation, kernel_initializer='he_normal', padding='same') (u7)\nc7 = Dropout(0.2) (c7)\nc7 = Conv2D(64, (3, 3), activation=activation, kernel_initializer='he_normal', padding='same') (c7)\n\nu8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\nu8 = concatenate([u8, c2])\nc8 = Conv2D(32, (3, 3), activation=activation, kernel_initializer='he_normal', padding='same') (u8)\nc8 = Dropout(0.1) (c8)\nc8 = Conv2D(32, (3, 3), activation=activation, kernel_initializer='he_normal', padding='same') (c8)\n\nu9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\nu9 = concatenate([u9, c1], axis=3)\nc9 = Conv2D(16, (3, 3), activation=activation, kernel_initializer='he_normal', padding='same') (u9)\nc9 = Dropout(0.1) (c9)\nc9 = Conv2D(16, (3, 3), activation=activation, kernel_initializer='he_normal', padding='same') (c9)\n\noutputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n\nmodel = Model(inputs=[inputs], outputs=[outputs])\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coefficient])\n#model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T10:02:34.983166Z","iopub.execute_input":"2021-12-21T10:02:34.983474Z","iopub.status.idle":"2021-12-21T10:02:35.397368Z","shell.execute_reply.started":"2021-12-21T10:02:34.98344Z","shell.execute_reply":"2021-12-21T10:02:35.396733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fit model\nearlystopper = EarlyStopping(patience=40, verbose=1)\n#checkpointer = ModelCheckpoint('best_model.h5', verbose=1, save_best_only=True)\n\nresults = model.fit(X_train, Y_train, validation_split=0.12, batch_size=10, epochs=71, \n                    callbacks=[earlystopper])","metadata":{"execution":{"iopub.status.busy":"2021-12-21T10:03:01.896768Z","iopub.execute_input":"2021-12-21T10:03:01.897698Z","iopub.status.idle":"2021-12-21T10:23:03.445452Z","shell.execute_reply.started":"2021-12-21T10:03:01.897658Z","shell.execute_reply":"2021-12-21T10:23:03.444483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(14,4))\nplt.plot(results.history['loss'])\nplt.plot(results.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('Loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T10:23:30.8222Z","iopub.execute_input":"2021-12-21T10:23:30.822996Z","iopub.status.idle":"2021-12-21T10:23:31.058622Z","shell.execute_reply.started":"2021-12-21T10:23:30.822955Z","shell.execute_reply":"2021-12-21T10:23:31.057489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(14,4))\nplt.plot(results.history['dice_coefficient'])\nplt.plot(results.history['val_dice_coefficient'])\nplt.title('dice_coefficient')\nplt.ylabel('dice_coefficient')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T10:23:31.060357Z","iopub.execute_input":"2021-12-21T10:23:31.060691Z","iopub.status.idle":"2021-12-21T10:23:31.291443Z","shell.execute_reply.started":"2021-12-21T10:23:31.060655Z","shell.execute_reply":"2021-12-21T10:23:31.290273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape[0]*0.85","metadata":{"execution":{"iopub.status.busy":"2021-12-21T10:38:22.529449Z","iopub.execute_input":"2021-12-21T10:38:22.529758Z","iopub.status.idle":"2021-12-21T10:38:22.536508Z","shell.execute_reply.started":"2021-12-21T10:38:22.529728Z","shell.execute_reply":"2021-12-21T10:38:22.535666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict on train, val and test\n#model = load_model('best_model.h5', custom_objects={'dice_coefficient': dice_coefficient})\npreds_train = model.predict(X_train[:int(X_train.shape[0]*0.85)], verbose=1)\npreds_test = model.predict(X_test, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T10:53:42.388906Z","iopub.execute_input":"2021-12-21T10:53:42.389244Z","iopub.status.idle":"2021-12-21T10:54:11.764475Z","shell.execute_reply.started":"2021-12-21T10:53:42.389207Z","shell.execute_reply":"2021-12-21T10:54:11.76349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# by default I use threshold of 0.5. It is worth optimize it? In some notebooks the use it per class type. \nfrom statistics import mean\ndef get_threshold(Y, pred):\n    scores = list(pred.ravel())\n    mask = list(Y.ravel())\n    \n    idxs=np.argsort(scores)[::-1]\n    mask_sorted=np.array(mask)[idxs]\n    sum_mask_one=np.cumsum(mask_sorted)\n    IoU=sum_mask_one/(np.arange(1,len(mask_sorted)+1)+np.sum(mask_sorted)-sum_mask_one)\n    best_IoU_idx=IoU.argmax()\n    best_threshold=scores[idxs[best_IoU_idx]]\n    best_IoU=IoU[best_IoU_idx]\n\n    return best_threshold, best_IoU\n\n\nimg_thresholds = []         # one for each image\nimg_IoUs = []\nfor Y, P in tqdm(zip(Y_train, preds_train), total=Y_train.shape[0]):\n\n    best_img_threshold, best_img_IoU = get_threshold(Y, P)\n    img_thresholds.append(best_img_threshold)\n    img_IoUs.append(best_img_IoU)\n    \nbest_threshold = np.mean(img_thresholds)\nbest_threshold_spread = np.std(img_thresholds)\navg_IoU = mean(img_IoUs)\n\nprint(f\"Best threshold: {best_threshold:.3g} (+-{best_threshold_spread:.3g}), Avg. Train IoU: {avg_IoU:.3f}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Threshold predictions\ndefault_threshold = False\n\nif default_threshold:\n    threshold=0.5\nelse:\n    threshold=best_threshold\n\n\npreds_train_t = (preds_train > threshold).astype(np.uint8)\npreds_test_t = (preds_test > threshold).astype(np.uint8)\n\n# Create list of upsampled test masks\npreds_test_upsampled = []\nfor i in range(len(preds_test)):\n    preds_test_upsampled.append(cv2.resize(np.squeeze(preds_test[i]), \n                                    (IMG_HEIGHT, IMG_WIDTH), interpolation = cv2.INTER_AREA))","metadata":{"execution":{"iopub.status.busy":"2021-12-21T10:53:42.388906Z","iopub.execute_input":"2021-12-21T10:53:42.389244Z","iopub.status.idle":"2021-12-21T10:54:11.764475Z","shell.execute_reply.started":"2021-12-21T10:53:42.389207Z","shell.execute_reply":"2021-12-21T10:54:11.76349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Perform a sanity check on some random training samples\nfrom random import randint\nix = randint(0, len(preds_train_t))\nplt.figure(figsize=(18,6))\nplt.subplot(1, 3, 1)\nplt.imshow(X_train[ix])\nplt.title('Input image')\nplt.axis(\"off\")\n\nplt.subplot(1, 3, 2)\nplt.imshow(np.squeeze(Y_train[ix]))\nplt.title('Mask')\nplt.axis(\"off\")\n\nplt.subplot(1, 3, 3)\nplt.imshow(np.squeeze(preds_train_t[ix]))\nplt.title('predicted mask')\nplt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2021-12-21T10:56:42.680767Z","iopub.execute_input":"2021-12-21T10:56:42.681075Z","iopub.status.idle":"2021-12-21T10:56:42.986266Z","shell.execute_reply.started":"2021-12-21T10:56:42.681039Z","shell.execute_reply":"2021-12-21T10:56:42.985444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ix = randint(0, len(preds_train_t))\nplt.figure(figsize=(18,6));\nplt.subplot(1, 3, 1)\nplt.imshow(X_train[ix])\nplt.title('Input image')\nplt.axis(\"off\")\n\nplt.subplot(1, 3, 2)\nplt.imshow(np.squeeze(Y_train[ix]))\nplt.title('Mask')\nplt.axis(\"off\")\n\nplt.subplot(1, 3, 3)\nplt.imshow(np.squeeze(preds_train_t[ix]))\nplt.title('predicted mask')\nplt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2021-12-21T10:57:23.937779Z","iopub.execute_input":"2021-12-21T10:57:23.938068Z","iopub.status.idle":"2021-12-21T10:57:24.245961Z","shell.execute_reply.started":"2021-12-21T10:57:23.938039Z","shell.execute_reply":"2021-12-21T10:57:24.244975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#predictions not empty right?\nprint(np.count_nonzero(preds_train_t[ix]))","metadata":{"execution":{"iopub.status.busy":"2021-12-21T10:57:58.133632Z","iopub.execute_input":"2021-12-21T10:57:58.134255Z","iopub.status.idle":"2021-12-21T10:57:58.141611Z","shell.execute_reply.started":"2021-12-21T10:57:58.13421Z","shell.execute_reply":"2021-12-21T10:57:58.140357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib.colors import ListedColormap\ncmap = ListedColormap(['black', 'gray', 'orange', 'green'])\n\ndef plot_colored(img_Y, img_pred):\n    output = np.zeros_like(img_Y)\n    output = np.where((img_Y == 0) & (img_pred == 1), 1, output)\n    output = np.where((img_Y == 1) & (img_pred == 0), 2, output)\n    output = np.where((img_Y == 1) & (img_pred == 1), 3, output)\n\n    plt.figure(figsize=(10,10))\n    plt.imshow(output, cmap=cmap)\n    plt.xticks([])\n    plt.yticks([]);","metadata":{"execution":{"iopub.status.busy":"2021-12-21T10:58:56.097898Z","iopub.execute_input":"2021-12-21T10:58:56.098398Z","iopub.status.idle":"2021-12-21T10:58:56.106805Z","shell.execute_reply.started":"2021-12-21T10:58:56.098347Z","shell.execute_reply":"2021-12-21T10:58:56.10612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N = 4\nfor i in range(N):\n    plot_colored(Y_train[i], preds_train_t[i])\n    plt.show()\n# green: correct prediction\n# gray: false positive (too much)\n# orange: false negative (missed)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T10:59:07.039211Z","iopub.execute_input":"2021-12-21T10:59:07.039677Z","iopub.status.idle":"2021-12-21T10:59:07.428468Z","shell.execute_reply.started":"2021-12-21T10:59:07.039633Z","shell.execute_reply":"2021-12-21T10:59:07.427825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# prepare the submision file","metadata":{}},{"cell_type":"code","source":"#test_mask: after reshape before fix_overlapping\ntest_masks = [cv2.resize(pred,dsize=(704,520),interpolation=cv2.INTER_CUBIC).reshape(520,704,1) for pred in preds_test_t]\nprint(test_masks[0].shape)\nprint(test_masks[1].shape)\nprint(test_masks[2].shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T11:04:34.416522Z","iopub.execute_input":"2021-12-21T11:04:34.417071Z","iopub.status.idle":"2021-12-21T11:04:34.425939Z","shell.execute_reply.started":"2021-12-21T11:04:34.417035Z","shell.execute_reply":"2021-12-21T11:04:34.424724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# fix_overlap\nhttps://www.kaggle.com/c/sartorius-cell-instance-segmentation/discussion/279995","metadata":{}},{"cell_type":"code","source":"def check_overlap(msk):\n    msk = msk.astype(np.bool).astype(np.uint8)\n    return np.any(np.sum(msk, axis=-1)>1)\n\ndef fix_overlap(msk):\n    \"\"\"\n    Args:\n        mask: multi-channel mask, each channel is an instance of cell, shape:(520,704,None)\n    Returns:\n        multi-channel mask with non-overlapping values, shape:(520,704,None)\n    \"\"\"\n    msk = np.array(msk)\n    msk = np.pad(msk, [[0,0],[0,0],[1,0]])\n    ins_len = msk.shape[-1]\n    msk = np.argmax(msk,axis=-1)\n    msk = tf.keras.utils.to_categorical(msk, num_classes=ins_len)\n    msk = msk[...,1:]\n    msk = msk[...,np.any(msk, axis=(0,1))]\n    return msk\n\ndef remove_isolated_points_from_rle(strin):\n    t2 = strin.split(\" \")\n    a = []\n    for i in range(0, len(t2), 2):\n        if t2[i+1]!=\"1\":\n            a.append(t2[i])\n            a.append(t2[i+1])\n    return ' '.join(a)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T11:39:38.652597Z","iopub.execute_input":"2021-12-21T11:39:38.652929Z","iopub.status.idle":"2021-12-21T11:39:38.664234Z","shell.execute_reply.started":"2021-12-21T11:39:38.652882Z","shell.execute_reply":"2021-12-21T11:39:38.663143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for test_mask in test_masks:\n    print(check_overlap(test_mask))","metadata":{"execution":{"iopub.status.busy":"2021-12-21T11:04:56.915432Z","iopub.execute_input":"2021-12-21T11:04:56.916131Z","iopub.status.idle":"2021-12-21T11:04:56.92573Z","shell.execute_reply.started":"2021-12-21T11:04:56.916065Z","shell.execute_reply":"2021-12-21T11:04:56.924575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#test_mask2: after reshape after fix_overlapping. No need right now\n#test_masks2=[]\n#for test_mask in test_masks:\n#    test_mask2 = fix_overlap(test_mask).reshape(520,704,1)\n#    print(test_mask2.shape)\n#    test_masks2+=[test_mask2]\n\n#for test_mask2 in test_masks2:\n #   print(check_overlap(test_mask2))","metadata":{"execution":{"iopub.status.busy":"2021-12-07T15:31:43.503919Z","iopub.execute_input":"2021-12-07T15:31:43.504349Z","iopub.status.idle":"2021-12-07T15:31:43.552277Z","shell.execute_reply.started":"2021-12-07T15:31:43.504316Z","shell.execute_reply":"2021-12-07T15:31:43.5513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# revert the output codes to the file","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted2 = [rle_encode(test_mask2) for test_mask2 in test_masks]\n#print(predicted2[0])","metadata":{"execution":{"iopub.status.busy":"2021-12-07T15:31:58.187391Z","iopub.execute_input":"2021-12-07T15:31:58.188001Z","iopub.status.idle":"2021-12-07T15:31:58.47666Z","shell.execute_reply.started":"2021-12-07T15:31:58.187961Z","shell.execute_reply":"2021-12-07T15:31:58.476007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# split the mask into each cluster nucleus","metadata":{}},{"cell_type":"code","source":"# split the mask into each cluster nucleus for the submision\n# seen on https://www.kaggle.com/c/sartorius-cell-instance-segmentation/discussion/288376\ndef post_process(mask, min_size=80, shape=(520, 704,)):\n    num_component, component = cv2.connectedComponents(mask.astype(np.uint8))\n    predictions = []\n    for c in range(1, num_component):\n        p = (component == c)\n        if p.sum() > min_size:\n            a_prediction = np.zeros(shape, np.float32)\n            a_prediction[p] = 1\n            predictions.append(a_prediction)\n    return predictions","metadata":{"execution":{"iopub.status.busy":"2021-12-21T11:20:12.302935Z","iopub.execute_input":"2021-12-21T11:20:12.303651Z","iopub.status.idle":"2021-12-21T11:20:12.31006Z","shell.execute_reply.started":"2021-12-21T11:20:12.303614Z","shell.execute_reply":"2021-12-21T11:20:12.309214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test the nucleus thing. Take one simple mask\nplt.imshow(Y_train[4], cmap=\"gray\");","metadata":{"execution":{"iopub.status.busy":"2021-12-21T11:07:34.94696Z","iopub.execute_input":"2021-12-21T11:07:34.947721Z","iopub.status.idle":"2021-12-21T11:07:35.162693Z","shell.execute_reply.started":"2021-12-21T11:07:34.947667Z","shell.execute_reply":"2021-12-21T11:07:35.161861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# connectedComponents returns the number of compenets of the image and a image with a pixel value of each of them\nnum_component, component = cv2.connectedComponents(Y_train[4].astype(np.uint8))\nprint(num_component)\nplt.imshow(component, cmap=\"gray\");","metadata":{"execution":{"iopub.status.busy":"2021-12-21T11:09:33.435341Z","iopub.execute_input":"2021-12-21T11:09:33.435601Z","iopub.status.idle":"2021-12-21T11:09:33.654945Z","shell.execute_reply.started":"2021-12-21T11:09:33.435573Z","shell.execute_reply":"2021-12-21T11:09:33.654182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# extraction of the component of value 5 as example\ncompenent_5 = (component == 5)\nplt.imshow(compenent_5, cmap=\"gray\");","metadata":{"execution":{"iopub.status.busy":"2021-12-21T11:13:32.177644Z","iopub.execute_input":"2021-12-21T11:13:32.177912Z","iopub.status.idle":"2021-12-21T11:13:32.39115Z","shell.execute_reply.started":"2021-12-21T11:13:32.177885Z","shell.execute_reply":"2021-12-21T11:13:32.390338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# all together\n# notice that with the size of the training the min size also is affected. The minimun size on this case is 20\nfinal = post_process(Y_train[4], min_size=20, shape=(IMG_HEIGHT, IMG_WIDTH,))\nprint(final[0].shape)\nplt.imshow(final[0], cmap=\"gray\");","metadata":{"execution":{"iopub.status.busy":"2021-12-21T11:21:16.311524Z","iopub.execute_input":"2021-12-21T11:21:16.312529Z","iopub.status.idle":"2021-12-21T11:21:16.528047Z","shell.execute_reply.started":"2021-12-21T11:21:16.312463Z","shell.execute_reply":"2021-12-21T11:21:16.527322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# create submision file","metadata":{}},{"cell_type":"code","source":"preds_test_t[0].shape","metadata":{"execution":{"iopub.status.busy":"2021-12-21T11:30:00.728144Z","iopub.execute_input":"2021-12-21T11:30:00.728432Z","iopub.status.idle":"2021-12-21T11:30:00.734426Z","shell.execute_reply.started":"2021-12-21T11:30:00.728401Z","shell.execute_reply":"2021-12-21T11:30:00.733543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# new version with the mask nucleus split\npredicted_nucleus = []\ntest_nucleus_image_id = []\n\nfor index, s in enumerate(preds_test_t):\n    nucleus = post_process(cv2.resize(s, (704,520,), interpolation = cv2.INTER_LINEAR))\n    for nucl in nucleus:\n        predicted_nucleus.append(nucl)\n        test_nucleus_image_id.append(test_images_id[index])","metadata":{"execution":{"iopub.status.busy":"2021-12-21T11:36:24.868301Z","iopub.execute_input":"2021-12-21T11:36:24.868583Z","iopub.status.idle":"2021-12-21T11:36:24.981671Z","shell.execute_reply.started":"2021-12-21T11:36:24.868554Z","shell.execute_reply":"2021-12-21T11:36:24.98072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(predicted_nucleus[0], cmap=\"gray\");\npredicted_nucleus[0].shape","metadata":{"execution":{"iopub.status.busy":"2021-12-21T11:41:16.466387Z","iopub.execute_input":"2021-12-21T11:41:16.466949Z","iopub.status.idle":"2021-12-21T11:41:16.73883Z","shell.execute_reply.started":"2021-12-21T11:41:16.466911Z","shell.execute_reply":"2021-12-21T11:41:16.737944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted2 = [rle_encode(test_mask2) for test_mask2 in predicted_nucleus]\nprint(predicted2[0])\npredicted_filt = [remove_isolated_points_from_rle(s) for s in predicted2]\nprint(predicted_filt[0])","metadata":{"execution":{"iopub.status.busy":"2021-12-21T11:39:47.588167Z","iopub.execute_input":"2021-12-21T11:39:47.58847Z","iopub.status.idle":"2021-12-21T11:39:47.665704Z","shell.execute_reply.started":"2021-12-21T11:39:47.588436Z","shell.execute_reply":"2021-12-21T11:39:47.664755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit = sample_submission.copy()\nsubmit = pd.DataFrame({'id':test_nucleus_image_id, 'predicted':predicted_filt})\nprint(submit.shape)\nsubmit.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T11:40:18.512179Z","iopub.execute_input":"2021-12-21T11:40:18.512825Z","iopub.status.idle":"2021-12-21T11:40:18.52506Z","shell.execute_reply.started":"2021-12-21T11:40:18.512784Z","shell.execute_reply":"2021-12-21T11:40:18.52423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T11:40:48.795051Z","iopub.execute_input":"2021-12-21T11:40:48.795362Z","iopub.status.idle":"2021-12-21T11:40:48.806752Z","shell.execute_reply.started":"2021-12-21T11:40:48.795328Z","shell.execute_reply":"2021-12-21T11:40:48.8058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}