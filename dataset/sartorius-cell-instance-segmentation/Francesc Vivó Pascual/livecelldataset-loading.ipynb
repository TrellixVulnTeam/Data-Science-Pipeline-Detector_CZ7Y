{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h2 style=\"font-family: Verdana; font-size: 40px; font-style: normal; font-weight: bold; text-transform: none; letter-spacing: 2px; color: #2874A6; background-color: #ffffff;\"> LIVE Cell Dataset Loading </h2>\n\n<h5 style=\"font-family: Verdana; line-height: 160%\"> In this notebook, I pretend to cover all the steps related to retrieving all the data contained in the LiveCell Datasat using the same format as the train and test folders. </h5>\n<hr>\n    \n<h2 style=\"font-family: Verdana; font-size: 25px; font-style: normal; font-weight: bold; text-transform: none; letter-spacing: 2px; color: #2874A6; background-color: #ffffff;\"> 1. Libraries </h2>","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom collections import namedtuple\nimport pandas as pd\nimport copy\nimport matplotlib.pyplot as plt\nimport cv2\nimport math\nimport os\nimport rasterio\nfrom matplotlib.path import Path","metadata":{"execution":{"iopub.status.busy":"2021-11-10T16:17:40.394551Z","iopub.execute_input":"2021-11-10T16:17:40.395272Z","iopub.status.idle":"2021-11-10T16:17:40.400284Z","shell.execute_reply.started":"2021-11-10T16:17:40.395236Z","shell.execute_reply":"2021-11-10T16:17:40.399376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"font-family: Verdana; font-size: 25px; font-style: normal; font-weight: bold; text-transform: none; letter-spacing: 2px; color: #2874A6; background-color: #ffffff;\">2. Helper Functions</h2>","metadata":{}},{"cell_type":"code","source":"def mask_decode(mask):\n    array = np.zeros((520, 704))\n    for label in mask:\n        s = label.split()\n        starts = list(map(lambda x: int(x) - 1, s[0::2]))\n        lengths = list(map(int, s[1::2]))\n        ends = [x + y for x, y in zip(starts, lengths)]\n        img = np.zeros((520*704), dtype=np.float32)            \n        for start, end in zip(starts, ends):\n            img[start : end] = 1 \n        array += img.reshape((520, 704))\n    return array.clip(0, 1)\n\ndef rle_encode(img):\n    \"\"\" TBD\n    \n    Args:\n        img (np.array): \n            - 1 indicating mask\n            - 0 indicating background\n    \n    Returns: \n        run length as string formated\n    \"\"\"\n    \n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\nPatientInfoTuple = namedtuple(\n    'PatientInfoTuple',\n    'id, cell_type, annotations'\n)\n\ndef getPatientsInfo():\n    df = pd.read_csv('../input/sartorius-cell-instance-segmentation/train.csv')\n    patientsInfo_list = list()\n    \n    for id in df.id.unique():\n        cell_type = df[df.id == id].cell_type.unique()[0]\n        annotations = df[df[\"id\"] == id][\"annotation\"].tolist()\n        \n        patientsInfo_list.append(PatientInfoTuple(\n            id,\n            cell_type,\n            annotations\n        ))\n        \n    return patientsInfo_list","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"font-family: Verdana; font-size: 25px; font-style: normal; font-weight: bold; text-transform: none; letter-spacing: 2px; color: #2874A6; background-color: #ffffff;\"> 3. From Json File to Dictionary </h2>\n    \n<h5 style=\"font-family: Verdana; line-height: 160%\"> In this notebook, I'll work with SHSY5Y cells but the procedure can be applied to any kind of the cells covered in the LiveCell Competition. </h5>\n    \n<h5 style=\"font-family: Verdana; line-height: 160%\"> In the following cell, I'll first load the json file that contains all the information related to the shsy5y cells. Then, I'll convert the json file into a dictionary in which, using the id of the images as the key, I'll store the segmentation provided in the competition, the boundary box of each cell and the path to the image </h5>","metadata":{}},{"cell_type":"code","source":"import json\n\nSHSY5Y_PATH = \"../input/sartorius-cell-instance-segmentation/LIVECell_dataset_2021/annotations/LIVECell_single_cells/shsy5y/livecell_shsy5y_train.json\"\n\nwith open(\"../input/sartorius-cell-instance-segmentation/LIVECell_dataset_2021/annotations/LIVECell_single_cells/shsy5y/livecell_shsy5y_train.json\") as f:\n    data = json.load(f)\n\nids = list()\nfor i,img_dict in enumerate(data[\"images\"]):\n    ids.append(data[\"images\"][i][\"id\"])\n\nd = {k: {\"segmentation\": [],\"bbox\": [], \"path\": []} for k in ids}\n\nfor i in range(len(d)):\n    d[data[\"images\"][i][\"id\"]][\"path\"].append(data[\"images\"][i][\"original_filename\"])\n\nfor key in data[\"annotations\"].keys():\n    id = data[\"annotations\"][key][\"image_id\"]\n    seg = data[\"annotations\"][key][\"segmentation\"][0]\n    bbox = data[\"annotations\"][key][\"bbox\"]\n    \n    d[id][\"segmentation\"].append(seg)    \n    d[id][\"bbox\"].append(bbox)","metadata":{"execution":{"iopub.status.busy":"2021-11-10T15:38:34.430674Z","iopub.execute_input":"2021-11-10T15:38:34.431909Z","iopub.status.idle":"2021-11-10T15:38:42.526288Z","shell.execute_reply.started":"2021-11-10T15:38:34.431756Z","shell.execute_reply":"2021-11-10T15:38:42.525366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"font-family: Verdana; font-size: 25px; font-style: normal; font-weight: bold; text-transform: none; letter-spacing: 2px; color: #2874A6; background-color: #ffffff;\">4. LiveCell Segmentation vs Sartorious Annotation</h2>","metadata":{}},{"cell_type":"code","source":"# Sartorius Annotation\npatientsInfo_list = copy.copy(getPatientsInfo())\n\nimg_example_path = cv2.imread('../input/sartorius-cell-instance-segmentation/train/0030fd0e6378.png')\nmask_example = mask_decode(patientsInfo_list[0][2])\n\nplt.figure(figsize=(15,15))\nplt.imshow(img_example_path)\nplt.imshow(mask_example, alpha=0.35)","metadata":{"execution":{"iopub.status.busy":"2021-11-10T16:10:34.505056Z","iopub.execute_input":"2021-11-10T16:10:34.505324Z","iopub.status.idle":"2021-11-10T16:10:51.073964Z","shell.execute_reply.started":"2021-11-10T16:10:34.505296Z","shell.execute_reply":"2021-11-10T16:10:51.071269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LiveCell Segmentation\narray = np.zeros((520,704))\n\nfor img_mask in d[1564017][\"segmentation\"]:\n    y = img_mask[0::2]\n    x = img_mask[1::2]\n\n    for i in range(int(len(img_mask)/2)):\n        array[math.floor(x[i])-1][math.floor(y[i])-1] = 0.5\n\nplt.figure(figsize=(15,15))\n        \nimew = os.path.join(\"../input/sartorius-cell-instance-segmentation/LIVECell_dataset_2021/images/livecell_train_val_images\", \"SHSY5Y\", d[1564017][\"path\"][0][:-4]+\".tif\")\nimew = rasterio.open(imew)\nimew = imew.read(1)\nplt.imshow(imew, cmap=\"gray\")\nplt.imshow(array, alpha=0.35)","metadata":{"execution":{"iopub.status.busy":"2021-11-10T16:10:51.07542Z","iopub.execute_input":"2021-11-10T16:10:51.076183Z","iopub.status.idle":"2021-11-10T16:10:51.973984Z","shell.execute_reply.started":"2021-11-10T16:10:51.076117Z","shell.execute_reply":"2021-11-10T16:10:51.973093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"font-family: Verdana; font-size: 25px; font-style: normal; font-weight: bold; text-transform: none; letter-spacing: 2px; color: #2874A6; background-color: #ffffff;\">5. LiveCell Segmentation Transformation</h2>","metadata":{}},{"cell_type":"code","source":"array = np.zeros((520, 704))\nfor img_mask in d[1564017][\"segmentation\"]:\n\n    x = img_mask[0::2]\n    y = img_mask[1::2]\n    \n    arr = [(x, y) for (x, y) in zip(y,x)]\n    vertices = np.asarray(arr)\n    path = Path(vertices)\n    xmin, ymin, xmax, ymax = np.asarray(path.get_extents(), dtype=int).ravel()\n    x, y = np.mgrid[:520, :704]\n    \n    # mesh grid to a list of points\n    points = np.vstack((x.ravel(), y.ravel())).T\n\n    # select points included in the path\n    mask = path.contains_points(points)\n    path_points = points[np.where(mask)]\n\n    # reshape mask for display\n    img_mask = mask.reshape(x.shape)\n    img_mask = img_mask.astype(np.int)\n    array += img_mask\n\nplt.figure(figsize=(15,15))\nplt.imshow(array.clip(0, 1))","metadata":{"execution":{"iopub.status.busy":"2021-11-10T16:20:51.431409Z","iopub.execute_input":"2021-11-10T16:20:51.431994Z","iopub.status.idle":"2021-11-10T16:20:54.907537Z","shell.execute_reply.started":"2021-11-10T16:20:51.431943Z","shell.execute_reply":"2021-11-10T16:20:54.90667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h5 style=\"font-family: Verdana; line-height: 160%\">Now that we have our mask in an appropriate format, it's time to encode it, just as the Sartorius Challenge.</h5>","metadata":{}},{"cell_type":"code","source":"seg_list = list()\nfor img_mask in d[1564017][\"segmentation\"]:\n\n    x = img_mask[0::2]\n    y = img_mask[1::2]\n    \n    arr = [(x, y) for (x, y) in zip(y,x)]\n    vertices = np.asarray(arr)\n    path = Path(vertices)\n    xmin, ymin, xmax, ymax = np.asarray(path.get_extents(), dtype=int).ravel()\n    x, y = np.mgrid[:520, :704]\n    \n    # mesh grid to a list of points\n    points = np.vstack((x.ravel(), y.ravel())).T\n\n    # select points included in the path\n    mask = path.contains_points(points)\n    path_points = points[np.where(mask)]\n\n    # reshape mask for display\n    img_mask = mask.reshape(x.shape)\n    img_mask = img_mask.astype(np.int)\n    # ENCODED MASK\n    encoded_img_mask = rle_encode(img_mask)\n    seg_list.append(encoded_img_mask)\n\n\nseg_list[0]","metadata":{"execution":{"iopub.status.busy":"2021-11-10T16:24:52.095876Z","iopub.execute_input":"2021-11-10T16:24:52.096618Z","iopub.status.idle":"2021-11-10T16:24:55.583029Z","shell.execute_reply.started":"2021-11-10T16:24:52.096577Z","shell.execute_reply":"2021-11-10T16:24:55.582293Z"},"trusted":true},"execution_count":null,"outputs":[]}]}