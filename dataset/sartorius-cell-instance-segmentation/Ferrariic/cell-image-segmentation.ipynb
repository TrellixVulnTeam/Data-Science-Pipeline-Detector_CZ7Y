{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport glob\nimport scipy\nimport json\nimport cv2\nimport os\nimport string\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom IPython.display import clear_output\nfrom sklearn.decomposition import PCA\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import RobustScaler, Normalizer\nfrom tensorflow.keras import Sequential\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom tensorflow.keras.layers import Dense, Input, Dropout, Conv2D, MaxPooling2D, Flatten, concatenate, add\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.models import Model\n\n!pip install keras_tuner\nimport keras_tuner as kt","metadata":{"execution":{"iopub.status.busy":"2021-11-17T17:34:57.848053Z","iopub.execute_input":"2021-11-17T17:34:57.848387Z","iopub.status.idle":"2021-11-17T17:35:15.511701Z","shell.execute_reply.started":"2021-11-17T17:34:57.8483Z","shell.execute_reply":"2021-11-17T17:35:15.510839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading Files (Test and Train Data)","metadata":{}},{"cell_type":"code","source":"in_path = \"/kaggle/input/sartorius-cell-instance-segmentation\"\n\ntrain_img_paths = glob.glob(in_path+'/train/*.png')\ntest_img_paths = glob.glob(in_path+'/test/*.png')\ndf = pd.read_csv(in_path+'/train.csv')\ndf","metadata":{"execution":{"iopub.status.busy":"2021-11-17T17:35:21.957023Z","iopub.execute_input":"2021-11-17T17:35:21.957308Z","iopub.status.idle":"2021-11-17T17:35:22.632085Z","shell.execute_reply.started":"2021-11-17T17:35:21.957279Z","shell.execute_reply":"2021-11-17T17:35:22.631214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Image Pre-processing","metadata":{}},{"cell_type":"code","source":"class ImagePreProcess:\n    \"\"\"\n        Class can be used to remove background and noise of images with simple backgrounds and complex foregrounds\n    \"\"\"\n    def __init__(self, image_paths, train=None):\n        self.train_true = train\n        self.image_paths = image_paths\n        self.offset = 2 # set 2 or 3, higher numbers remove more background\n        self.cwd = '/kaggle/working'\n        \n    def __load_image_default(self, image_path):\n        img = cv2.imread(image_path)\n        return img\n        \n    def __threshold_identification(self, image_path):\n        img = cv2.imread(image_path)\n        hist, bins = np.histogram(img.ravel(), 256, [0,256]) # bins pixel values\n        grad = np.gradient(hist, edge_order=2) # finds upper bound of unused pixels\n        threshold = np.where(grad == np.amax(grad))[0][0]-self.offset # calculates max pixel position, and offsets for grad calc\n        return threshold\n        \n        \n    def __binary_mask(self, image_path, threshold):\n        img = cv2.imread(image_path)\n        ret, img_binary = cv2.threshold(img, threshold, 255, cv2.THRESH_BINARY)\n        return img_binary\n    \n    \n    def __erode_dilate(self, img, erode_or_dilate='erode'):\n        kernel = np.ones((2, 2), np.uint8)\n        if erode_or_dilate == 'erode':\n            image = cv2.erode(img, kernel)\n        if erode_or_dilate == 'dilate':\n            image = cv2.dilate(img, kernel)\n        return image\n    \n    \n    def __remask(self, image_path, img_binary):\n        img = cv2.imread(image_path)\n        image = cv2.bitwise_or(img_binary, img)\n        return image\n    \n    def __save_image(self, image_name, img):\n        try:\n            os.mkdir(f'{self.cwd}/train/')\n            os.mkdir(f'{self.cwd}/test/')\n        except FileExistsError:\n            pass\n        \n        clear_output(wait=True)\n        print(image_name)\n        \n        if self.train_true:\n            cv2.imwrite(f'{self.cwd}/train/{image_name}.png',img)\n        else:\n            cv2.imwrite(f'{self.cwd}/test/{image_name}.png',img)\n        \n    def process_images(self):\n        for image_path in self.image_paths:\n            image_name = image_path[image_path.rfind('/')+1:image_path.rfind('.')]\n            #img = self.__load_image_default(image_path)\n            threshold = self.__threshold_identification(image_path) # Identifies optimal cut threshold, removing background\n            img = self.__binary_mask(image_path, threshold) # Creates binary mask\n            self.__save_image(image_name, img=img)\n        g = plt.imshow(img)\n        print(\"Completed.\")\n\n\nIMPP_train = ImagePreProcess(train_img_paths, train=True)\nIMPP_test = ImagePreProcess(test_img_paths, train=False)\n\nIMPP_train.process_images()\nIMPP_test.process_images()","metadata":{"execution":{"iopub.status.busy":"2021-11-17T17:36:25.834018Z","iopub.execute_input":"2021-11-17T17:36:25.834331Z","iopub.status.idle":"2021-11-17T17:36:52.913823Z","shell.execute_reply.started":"2021-11-17T17:36:25.834296Z","shell.execute_reply":"2021-11-17T17:36:52.913023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Making Annotation Masks","metadata":{}},{"cell_type":"code","source":"class generateAnnotations:\n    \n    \"\"\"\n        loads annotations into mask format\n    \"\"\"\n    \n    def __init__(self, df):\n        self.df = df\n        self.cwd = '/kaggle/working'\n\n    def __rle_decode(self, mask_rle, shape, color=0):\n        '''\n        mask_rle: run-length as string formated (start length)\n        shape: (height, width, channels) of array to return \n        color: color for the mask\n        Returns numpy array (mask)\n\n        '''\n        s = mask_rle.split()\n\n        starts = list(map(lambda x: int(x) - 1, s[0::2]))\n        lengths = list(map(int, s[1::2]))\n\n        ends = [x + y for x, y in zip(starts, lengths)]\n        img = np.zeros((shape[0] * shape[1], shape[2]), dtype=np.float32)\n\n        for start, end in zip(starts, ends):\n            img[start : end] = color\n\n        return img.reshape(shape)\n    \n    def __save_image(self, image_name, img):\n        clear_output(wait=True)\n        print(image_name)\n        try:\n            os.mkdir(f'{self.cwd}/annotation_masks/')\n        except FileExistsError:\n            pass\n        cv2.imwrite(f'{self.cwd}/annotation_masks/{image_name}.png',img)\n    \n    def create_annotation_masks(self):\n        ID_annotation = df.groupby(by='id')['annotation'].apply(list)\n        df_annotation = pd.DataFrame(ID_annotation).reset_index()\n        \"\"\"\n            normally wouldn't set this, but all imgs are the same HxW\n        \"\"\"\n        h = df.height[0]\n        w = df.width[0]\n        \n        for image_name, image_annotations in df_annotation.values:\n            annotations = \" \".join(image_annotations)\n            mask = self.__rle_decode(mask_rle=annotations,shape=(h, w, 3), color=255)\n            self.__save_image(image_name=image_name, img=mask)\n        g = plt.imshow(mask)\n\nGA = generateAnnotations(df=df)\nGA.create_annotation_masks()","metadata":{"execution":{"iopub.status.busy":"2021-11-17T17:37:00.687755Z","iopub.execute_input":"2021-11-17T17:37:00.688651Z","iopub.status.idle":"2021-11-17T17:37:09.100632Z","shell.execute_reply.started":"2021-11-17T17:37:00.688604Z","shell.execute_reply":"2021-11-17T17:37:09.099772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Mask Handling","metadata":{}},{"cell_type":"code","source":"class combineMasks:\n    def __init__(self, df):\n        self.df = df\n        self.cwd = '/kaggle/working'\n    \n    def pull_image_path(self):\n        cell_labels = self.df.groupby(by='id')['cell_type'].apply(set).reset_index()\n        for img_name, cell_type in cell_labels.values:\n            cell_type = list(cell_type)[0]\n            \n            clear_output(wait=True)\n            print(img_name)\n            try:\n                path_base = f'{self.cwd}/train/{img_name}.png'\n            except:\n                path_base = f'{self.cwd}/test/{img_name}.png'\n                \n            path_mask = f'{self.cwd}/annotation_masks/{img_name}.png'  \n            img_mask = cv2.imread(path_mask)\n            img_base = cv2.imread(path_base)\n            print(cell_type)\n            \nCM = combineMasks(df=df)\nCM.pull_image_path()","metadata":{"execution":{"iopub.status.busy":"2021-11-17T17:38:45.538353Z","iopub.execute_input":"2021-11-17T17:38:45.538695Z","iopub.status.idle":"2021-11-17T17:38:53.022132Z","shell.execute_reply.started":"2021-11-17T17:38:45.538659Z","shell.execute_reply":"2021-11-17T17:38:53.021526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Define","metadata":{}},{"cell_type":"code","source":"def model_builder(hp):\n    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}