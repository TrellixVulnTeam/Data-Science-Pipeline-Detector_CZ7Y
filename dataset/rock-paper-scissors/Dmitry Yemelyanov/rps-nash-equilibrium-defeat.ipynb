{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\nfrom kaggle_environments.envs.rps.utils import get_score\nfrom kaggle_environments import make","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy import stats","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rock = 0\npaper = 1\nscissors = 2\n\nnum_games = 18\noutcomes = np.zeros(num_games)\n\nfor i in range(num_games):\n    # let it be random\n    outcomes[i] = np.random.choice([rock, paper, scissors])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"values, counts = np.unique(outcomes, return_counts=True)\nprobs = counts / len(outcomes)\nprobs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reverse = np.ones(len(values)) - probs\nreverse = reverse / np.sum(reverse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.choice(values, p=reverse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def pdf(outcomes):\n    val, cnt = np.unique(outcomes, return_counts=True)\n    prop = cnt / len(outcomes)\n    return (val, prop)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.histogram(outcomes, bins=[rock, paper, scissors])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val, prop = pdf(outcomes[0:4])\nprop","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.bar(*pdf(outcomes[0:4]))\nplt.ylabel(\"Probability\")\nplt.xlabel(\"Outcome\")\nplt.show()\nplt.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%writefile nash_equilibrium_defeat_agent.py\n\nimport random\nimport numpy as np\n\nmemory = {}\n\ndef beat_nash_equilibrium_agent(observation, configuration):\n    signs = list(range(0, configuration.signs))\n    global memory\n    if observation.step > 0:\n        # Save observation in memory\n        memory[observation.lastOpponentAction] += 1\n        # Calculate PMF of previous actions\n        counts = list(memory.values())\n        freqs = counts / np.sum(counts)\n        # Calculate PMF of the next action\n        # It is reverse of previous action PMF as it should try to restore Equilibrium\n        probs = np.ones(configuration.signs) - freqs\n        probs = probs / np.sum(probs)\n        # Predict next action\n        predict = np.random.choice(signs, p=probs)\n        # Return our response to that action\n        return int(predict % configuration.signs)\n    else:\n        memory = dict.fromkeys(signs, 0)\n        return random.randrange(0, configuration.signs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from kaggle_environments.envs.rps.agents import *\n\ndef randomAgent(obs, config):\n    return random.randint(0, 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"env = make('rps', debug = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Pass in your agent to evaluate\ndef evaluate(agent):\n    \n    pool = [\n        randomAgent,\n        randomAgent,\n        randomAgent,\n        randomAgent,\n        randomAgent,\n        \n        rock,\n        paper,\n        scissors,\n        copy_opponent,\n        reactionary,\n        counter_reactionary,\n        statistical,\n        randomAgent,\n    ]\n    overall = 0\n\n    for opponent in pool:\n        env.reset()\n        env.run([agent, opponent])\n        json = env.toJSON()\n        rewards = json['rewards']\n\n        opponentName = str(opponent).split()[1].capitalize()\n\n        padding = ''; length = len(str(rewards))\n        if length < 15: padding = ' ' * (15 - length)\n\n        print(f'Rewards: {rewards}{padding}  Agent vs {opponentName}')\n        overall += rewards[0]\n    \n    overall /= len(pool)\n    print(f'Overall Score: {overall}')\n    \n    return overall","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = evaluate('/kaggle/working/nash_equilibrium_defeat_agent.py')\nif score <= 0:\n    print('\\nU MIGHT WANNA FIX SOME THINGS BUDDY')\nelse:\n    print('\\nITS GREAT! NOW CHUCK IT INTO THE LEADERBOARD')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}