{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **Random Agents**"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install 'kaggle-environments>=0.1.6'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%%writefile submission.py\n\n\nimport random\nimport operator\nimport numpy as np\nimport pandas as pd\nimport collections\nfrom collections import defaultdict\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n\nUSE_RANDOM = 1\nUSE_MARKOW = 1\nLAST_ROUND = 1000\nROUND = 1\nalpha = 0.01\nM = 0\n\n# Initialize matrices\nT = np.zeros((3, 3))\nP = np.zeros((3, 3))\n\n# Save state of the match at every step\nscore_markov = []\nopponent_actions = []\nown_actions = []\n\nmove2num = {'R': 0, 'P': 1, 'S': 2}\nmove2str = {0: 'R', 1: 'P', 2: 'S'}\nmoves = [\"R\",\"P\",\"S\"]\nbeatedBy = {\"R\":\"P\", \"P\":\"S\", \"S\":\"R\"}\nresult = {\"R\":{\"R\":0, \"P\":-1, \"S\":1}, \"P\":{\"R\":1, \"P\":0, \"S\":-1}, \"S\":{\"R\":-1, \"P\":1, \"S\":0}}\nbeat = {'P': 'S', 'S': 'R', 'R': 'P'}\ncede = {'P': 'R', 'S': 'P', 'R': 'S'}\n\n\n\n\ndef construct_local_features(rollouts):\n    features = np.array([[step % k for step in rollouts['steps']] for k in (2, 3, 5)])\n    features = np.append(features, rollouts['steps'])\n    features = np.append(features, rollouts['actions'])\n    features = np.append(features, rollouts['opp-actions'])\n    return features\n\ndef construct_global_features(rollouts):\n    features = []\n    for key in ['actions', 'opp-actions']:\n        for i in range(3):\n            actions_count = np.mean([r == i for r in rollouts[key]])\n            features.append(actions_count)\n    \n    return np.array(features)\n\ndef construct_features(short_stat_rollouts, long_stat_rollouts):\n    lf = construct_local_features(short_stat_rollouts)\n    gf = construct_global_features(long_stat_rollouts)\n    features = np.concatenate([lf, gf])\n    return features\n\ndef predict_opponent_move(train_data, test_sample):\n    classifier = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(random_state=34), random_state=34, n_estimators=100)\n    classifier.fit(train_data['x'], train_data['y'])\n    return classifier.predict(test_sample)\n\ndef update_rollouts_hist(rollouts_hist, last_move, opp_last_action):\n    rollouts_hist['steps'].append(last_move['step'])\n    rollouts_hist['actions'].append(last_move['action'])\n    rollouts_hist['opp-actions'].append(opp_last_action)\n    return rollouts_hist\n\ndef warmup_strategy(observation, configuration):\n\n    global rollouts_hist, last_move\n    action = int(np.random.randint(3))\n\n    if observation.step == 0:\n        last_move = {'step': 0, 'action': action}\n        rollouts_hist = {'steps': [], 'actions': [], 'opp-actions': []}\n    else:\n        rollouts_hist = update_rollouts_hist(rollouts_hist, last_move, observation.lastOpponentAction)\n        last_move = {'step': observation.step, 'action': action}\n\n    return int(action)\n\ndef init_training_data(rollouts_hist, k):\n    for i in range(len(rollouts_hist['steps']) - k + 1):\n        short_stat_rollouts = {key: rollouts_hist[key][i:i+k] for key in rollouts_hist}\n        long_stat_rollouts = {key: rollouts_hist[key][:i+k] for key in rollouts_hist}\n        features = construct_features(short_stat_rollouts, long_stat_rollouts)        \n        data['x'].append(features)\n    test_sample = data['x'][-1].reshape(1, -1)\n    data['x'] = data['x'][:-1]\n    data['y'] = rollouts_hist['opp-actions'][k:]\n    return data, test_sample\n\ndef selectBest(s):\n    return random.choice([i for i in range(len(s)) if max(s) == s[i]])\n\ndef selectBestDict(s):\n    ew = {i:s[beatedBy[beatedBy[i]]] - s[beatedBy[i]] for i in s.keys()};\n    return random.choice([i for i in ew.keys() if max(ew.values()) == ew[i]])\n\n\n## --- Agents --\n\ndef agent(observation, configuration):\n\n    if observation.step == 0:\n        idx_agent = int(np.random.randint(len(output)))\n    \n    output = []\n    output_markov, score_markov = markov_chain(observation, configuration)\n    output.append(output_markov)\n    output.append(adaboost(observation, configuration))\n    output.append(switching(observation, configuration))\n    output.append(meta_sgd(observation, configuration))\n    \n    if (observation.step % 50 == 0) and (observation.step > 0):\n        if score_markov[observation.step] < score_markov[observation.step-50]:\n            idx_agent = (idx_agent+1) % len(output)\n\n    return output[idx_agent]\n\n\ndef markov_chain(observation, configuration):\n\n    global T, P, score_markov, opponent_actions, own_actions\n    \n    # Save opponent's previous action\n    if observation.step > 0:\n        opponent_actions.append(observation.lastOpponentAction)\n    \n    if observation.step > 1:\n        \n        # Update matrices \n        T[opponent_actions[-2], opponent_actions[-1]] += 1\n        P = np.divide(T, np.maximum(1, T.sum(axis=1)).reshape(-1, 1))\n        \n        # Update match score\n        score_markov.append(get_score(own_actions[-1], opponent_actions[-1]))\n        \n        # Check every 50 moves is we are losing\n        if observation.step%50<5:\n            \n            # If we are losing, change strategy during the next 5 steps to random\n            if score_markov[-1] <= 0:\n                reaction = int(np.random.randint(3))\n                own_actions.append(reaction)\n                return reaction\n\n        # Infer next action\n        if np.sum(P[opponent_actions[-1], :]) == 1:\n            reaction = int((np.random.choice([0, 1, 2], p=P[opponent_actions[-1], :]) + 1) % 3)\n            \n        else:\n            reaction = int(np.random.randint(3))\n\n           \n    elif observation.step == 1:\n        \n        score_markov.append(get_score(own_actions[-1], opponent_actions[-1]))\n        reaction = int(np.random.randint(3))\n            \n    else:\n        reaction = int(np.random.randint(3))\n            \n    own_actions.append(reaction)\n    return reaction, score_markov\n\n\ndef adaboost(observation, configuration):\n\n    # Hyperparameters\n    k = 5\n    min_samples = 25\n    global rollouts_hist, last_move, data, test_sample\n    \n    if observation.step == 0:\n        data = {'x': [], 'y': []}\n\n    if observation.step <= min_samples + k:\n        return warmup_strategy(observation, configuration)\n\n    # update statistics\n    rollouts_hist = update_rollouts_hist(rollouts_hist, last_move, observation.lastOpponentAction)\n\n    # update training data\n    if len(data['x']) == 0:\n        data, test_sample = init_training_data(rollouts_hist, k)\n    else:        \n        short_stat_rollouts = {key: rollouts_hist[key][-k:] for key in rollouts_hist}\n        features = construct_features(short_stat_rollouts, rollouts_hist)\n        data['x'].append(test_sample[0])\n        data['y'] = rollouts_hist['opp-actions'][k:]\n        test_sample = features.reshape(1, -1)\n        \n    # predict opponents move and choose an action\n    next_opp_action_pred = predict_opponent_move(data, test_sample)\n    action = int((next_opp_action_pred + 1) % 3)\n    last_move = {'step': observation.step, 'action': action}\n    return action\n\n\ndef switching(observation, configuration):\n\n    global my_hist, both_hist, opp_hist, output, candidates, \\\n        performance, score_switch, both_patterns, opp_patterns, my_patterns, \\\n        both2_patterns, opp2_patterns, my2_patterns\n\n    if observation.step == 0:\n        \n        both_hist = \"\"\n        my_hist = \"\"\n        opp_hist = \"\"\n\n        both_patterns = defaultdict(str)\n        opp_patterns = defaultdict(str)\n        my_patterns = defaultdict(str)\n\n        both2_patterns = defaultdict(str)\n        opp2_patterns = defaultdict(str)\n        my2_patterns = defaultdict(str)\n\n        score_switch = {'RR': 0, 'PP': 0, 'SS': 0, 'PR': 1, 'RS': 1, 'SP': 1,'RP': -1, 'SR': -1, 'PS': -1}\n        output = random.choice([\"R\", \"P\", \"S\"])\n\n        candidates = [output] * 36\n\n        performance = [(0,0)] * 36\n\n    else:\n        \n        for length in range(min(5, len(my_hist)), 0, -1):\n            p = opp_patterns[opp_hist[-length:]]\n            if p != \"\":\n                for length2 in range(min(5, len(p)), 0, -1):\n                    opp2_patterns[p[-2*length2:]] += output + move2str[observation.lastOpponentAction]\n            opp_patterns[opp_hist[-length:]] += output + move2str[observation.lastOpponentAction]\n\n            p = my_patterns[my_hist[-length:]]\n            if p != \"\":\n                for length2 in range(min(5, len(p)), 0, -1):\n                    my2_patterns[p[-2*length2:]] += output + move2str[observation.lastOpponentAction]\n            my_patterns[my_hist[-length:]] += output + move2str[observation.lastOpponentAction]\n\n            p = both_patterns[both_hist[-2*length:]]\n            if p != \"\":\n                for length2 in range(min(5, len(p)), 0, -1):\n                    both2_patterns[p[-2*length2:]] += output + move2str[observation.lastOpponentAction]\n            both_patterns[both_hist[-2*length:]] += output + move2str[observation.lastOpponentAction]\n    \n        both_hist += output+move2str[observation.lastOpponentAction]\n        my_hist += output\n        opp_hist += move2str[observation.lastOpponentAction]\n\n        for i, c in enumerate(candidates):\n            performance[i] = ({1:performance[i][0]+1, 0: 0, -1: 0}[score_switch[c+move2str[observation.lastOpponentAction]]],  \n                            performance[i][1]+score_switch[c+move2str[observation.lastOpponentAction]])\n\n        output = random.choice(['R', 'P', 'S'])\n        candidates = [output] * 36\n\n        idx = performance.index(max(performance, key=lambda x: x[0]**3+x[1]))\n\n        for length in range(min(5, len(my_hist)), 0, -1):\n            pattern = both_patterns[both_hist[-2*length:]]\n            if pattern != \"\":\n                opp = pattern[-1]\n                my = pattern[-2]\n                candidates[0] = beat[opp]\n                candidates[1] = cede[my]\n                candidates[2] = opp\n                candidates[3] = my\n                candidates[4] = cede[opp]\n                candidates[5] = beat[my]\n                for length2 in range(min(5, len(pattern)), 0, -1):\n                    pattern2 = both2_patterns[pattern[-2*length2:]]\n                    if pattern2 != \"\":\n                        my2 = pattern2[-2]\n                        opp2 = pattern2[-1]\n                        candidates[6] = beat[opp2]\n                        candidates[7] = cede[my2]\n                        candidates[8] = opp2\n                        candidates[9] = my2\n                        candidates[10] = cede[opp2]\n                        candidates[11] = beat[my2]\n                        break\n                break\n\n        for length in range(min(5, len(my_hist)), 0, -1):\n            pattern = my_patterns[my_hist[-length:]]\n            if pattern != \"\":\n                opp = pattern[-1]\n                my = pattern[-2]\n                candidates[24] = beat[opp]\n                candidates[25] = cede[my]\n                candidates[26] = opp\n                candidates[27] = my\n                candidates[28] = cede[opp]\n                candidates[29] = beat[my]\n                for length2 in range(min(5, len(pattern)), 0, -1):\n                    pattern2 = my2_patterns[pattern[-2*length2:]]\n                    if pattern2 != \"\":\n                        my2 = pattern2[-2]\n                        opp2 = pattern2[-1]\n                        candidates[30] = beat[opp2]\n                        candidates[31] = cede[my2]\n                        candidates[32] = opp2\n                        candidates[33] = my2\n                        candidates[34] = cede[opp2]\n                        candidates[35] = beat[my2]\n                        break\n                break\n\n        for length in range(min(5, len(opp_hist)), 0, -1):\n            pattern = opp_patterns[opp_hist[-length:]]\n            if pattern != \"\":\n                opp = pattern[-1]\n                my = pattern[-2]\n                candidates[12] = beat[opp]\n                candidates[13] = cede[my]\n                candidates[14] = opp\n                candidates[15] = my\n                candidates[16] = cede[opp]\n                candidates[17] = beat[my]\n                for length2 in range(min(5, len(pattern)), 0, -1):\n                    pattern2 = opp2_patterns[pattern[-2*length2:]]\n                    if pattern2 != \"\":\n                        my2 = pattern2[-2]\n                        opp2 = pattern2[-1]\n                        candidates[18] = beat[opp2]\n                        candidates[19] = cede[my2]\n                        candidates[20] = opp2\n                        candidates[21] = my2\n                        candidates[22] = cede[opp2]\n                        candidates[23] = beat[my2]\n                        break\n                break\n\n        output = candidates[idx]\n\n    return move2num[output]\n\n\ndef meta_sgd(observation, configuration):\n\n    global history, weight, decay, score_meta, selected, move, M, \\\n            ROUND, last, markov_orders, historyCount\n\n    if observation.step == 0:\n\n        history = []\n\n        if USE_RANDOM == 1:\n            M += 1\n\n        if USE_MARKOW == 1:\n            markov_orders = [0,1,2,3,4,5,6]\n            historyCount = {}\n            M += 6 * len(markov_orders)\n\n\n        weight = [1] * M\n        decay = [0.85] * M\n\n        score_meta = [0] * M\n        selected = [0] * M\n        move = [random.choice(moves) for i in range(M)]\n\n    else:\n\n        ROUND += 1\n        history += [(last,move2str[observation.lastOpponentAction])]\n        score_meta = [ decay[i] * score_meta[i] + weight[i] * result[move[i]][move2str[observation.lastOpponentAction]] for i in range(M)]\n        weight = [ weight[i] + alpha * result[move[i]][move2str[observation.lastOpponentAction]] for i in range(M)]\n        index = 0\n\n        # random optimal\n        if USE_RANDOM == 1:\n            move[index] = random.choice(moves)\n            # adjust random optimal score to zero\n            score_meta[index] = 0\n            index += 1\n\n        first_meta_index = index\n\n        if USE_MARKOW == 1:\n            # markow with meta strategies\n            for m in markov_orders:\n                if len(history) > m:\n                    key = tuple(history[-m-1:-1])\n                    if not (key in historyCount):\n                        historyCount[key] = [{\"R\":0,\"P\":0,\"S\":0},{\"R\":0,\"P\":0,\"S\":0}]\n                    historyCount[key][0][history[-1][0]] += 1\n                    historyCount[key][1][history[-1][1]] += 1\n\n            for m in markov_orders:\n                if len(history) >= m:\n                    key = tuple(history[-m:])\n                    if key in historyCount:\n                        move[index]   = selectBestDict(historyCount[key][0])\n                        move[index+3] = selectBestDict(historyCount[key][1])\n                    else:\n                        move[index]   = random.choice(moves)\n                        move[index+3] = random.choice(moves)\n                else:\n                    move[index]   = random.choice(moves)\n                    move[index+3] = random.choice(moves)\n                index += 6\n\n        # set other meta strategies\n        for i in range(first_meta_index, M, 3):\n            move[i+1] = beatedBy[move[i]]\n            move[i+2] = beatedBy[move[i+1]]\n\n    best = selectBest(score_meta)\n    selected[best] += 1\n    output = move[best]\n    last = output\n\n    return move2num[output]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Testing with other strategies"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%writefile random.py\n\nimport numpy as np\n\ndef random_agent(observation, configuration):\n    return int(np.random.randint(3))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from kaggle_environments import evaluate, make\n\nenv = make(\"rps\", debug=True)\nenv.render()\n\nenv.reset()\n# Play as the first agent against default \"random\" agent.\nenv.run([\"submission.py\", \"random.py\"])\nenv.render(mode=\"ipython\", width=500, height=450)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}