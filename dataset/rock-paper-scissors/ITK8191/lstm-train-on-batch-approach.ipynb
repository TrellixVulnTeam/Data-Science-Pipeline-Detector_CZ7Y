{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"%%writefile periodic.py\n\nimport random\nimport numpy as np\ndef periodic(observation, configuration):\n    t = observation.step\n    return t%3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%%writefile submission.py\nimport tensorflow as tf\nimport queue\nimport numpy as np\nimport random\nimport time\n\ninputs = tf.keras.Input((8, 9))\nx = tf.keras.layers.LSTM(32, return_sequences=True)(inputs)\nx = tf.keras.layers.LSTM(32, return_sequences=True)(x)\nx = tf.keras.layers.LSTM(32)(x)\nx = tf.keras.layers.Dense(32, activation='relu')(x)\nout = tf.keras.layers.Dense(3, activation='softmax')(x)\nmodel = tf.keras.models.Model(inputs = inputs, outputs = out)\nopt = tf.keras.optimizers.Adam(lr = 1e-3)\nmodel.compile(loss = tf.keras.losses.CategoricalCrossentropy(), optimizer = opt, metrics = ['accuracy'])\n\ndef queue(src, a):\n    dst = np.roll(src, -1)\n    dst[-1] = a\n    return dst\n\nopponent_hand = np.array([0,2,1,0,2,1,2,0])\nmy_hand = np.array([0,2,1,0,2,1,2,0])\nwin_loss = np.array([2,2,2,2,2,2,2,2])\nmy_last_hand = 0\nmem_len = len(opponent_hand)\n\ndef copy_opponent_agent(observation, configuration):\n    global opponent_hand, my_hand, win_loss\n    global model\n    global my_last_hand\n    if observation.step > mem_len*2:\n        l = observation.lastOpponentAction\n        \n        r = np.eye(3)[l]\n        r = r.reshape(1, 3)\n        smooth = np.eye(3)[(l+2)%3]\n        smooth = smooth.reshape(1, 3)\n        eps = np.random.rand()*0.1\n        #r = r*(1-eps) + smooth*eps\n        opp = np.array(opponent_hand)\n        opp = np.eye(3)[opp]\n        opp = opp.reshape(1, mem_len, 3)\n        \n        my = np.array(my_hand)\n        my = np.eye(3)[my]\n        my = my.reshape(1, mem_len, 3)\n        \n        wld = np.array(win_loss)\n        wld = np.eye(3)[wld]\n        wld = wld.reshape(1, mem_len, 3)\n        \n        b = np.concatenate([opp, my, wld], axis=-1)\n        \n        h = model.train_on_batch(b, r)\n        print(f'loss:{h[0]}, acc:{h[1]}')\n        \n        opponent_hand = queue(opponent_hand, l)\n        opp = np.array(opponent_hand)\n        opp = np.eye(3)[opp]\n        opp = opp.reshape(1, mem_len, 3)\n        \n        my_hand = queue(my_hand, my_last_hand)\n        my = np.array(my_hand)\n        my = np.eye(3)[my]\n        my = my.reshape(1, mem_len, 3)\n        \n        win_loss = queue(win_loss, (my_last_hand-l)%3)\n        wld = np.array(win_loss)\n        wld = np.eye(3)[wld]\n        wld = wld.reshape(1, mem_len, 3)\n        \n        b = np.concatenate([opp, my, wld], axis=-1)\n        \n        t = model.predict(b)\n        print(f'predict:{t}')\n        p = np.argmax(t)\n        if t[0][p] > 0.4:\n            my_last_hand = (int(p) + 1) % 3\n            return my_last_hand\n        else:\n            my_last_hand = random.randint(0, 2)\n            return my_last_hand\n        \n    elif observation.step > mem_len:\n        l = observation.lastOpponentAction\n        r = np.eye(3)[l]\n        r = r.reshape(1,3)\n        smooth = np.eye(3)[(l+2)%3]\n        smooth = smooth.reshape(1, 3)\n        eps = np.random.rand()*0.1\n        #r = r*(1-eps) + smooth*eps\n        opp = np.array(opponent_hand)\n        opp = np.eye(3)[opp]\n        opp = opp.reshape(1, mem_len, 3)\n        \n        my = np.array(my_hand)\n        my = np.eye(3)[my]\n        my = my.reshape(1, mem_len, 3)\n        \n        wld = np.array(win_loss)\n        wld = np.eye(3)[wld]\n        wld = wld.reshape(1, mem_len, 3)\n        \n        b = np.concatenate([opp, my, wld], axis=-1)\n        \n        h = model.train_on_batch(b, r)\n        print(f'loss:{h[0]}, acc:{h[1]}')\n\n        opponent_hand = queue(opponent_hand, l)\n        my_hand = queue(my_hand, my_last_hand)\n        win_loss = queue(win_loss, (my_last_hand-l)%3)\n        print(opponent_hand[-1],my_hand[-1],win_loss[-1])\n        my_last_hand = random.randint(0, 2)\n        return my_last_hand\n    elif observation.step > 0:\n        l = observation.lastOpponentAction\n        opponent_hand = queue(opponent_hand, l)\n        my_hand = queue(my_hand, my_last_hand)\n        win_loss = queue(win_loss, (my_last_hand-l)%3)\n        my_last_hand = random.randint(0, 2)\n        return my_last_hand\n    else:\n        my_last_hand = random.randint(0, 2)\n        return my_last_hand\n\n    \n# dummy to prevent Time Limit Exceed\nl = 1\nr = np.eye(3)[l]\nr = r.reshape(1,3)\nsmooth = np.eye(3)[(l+2)%3]\nsmooth = smooth.reshape(1, 3)\neps = np.random.rand()*0.1\n#r = r*(1-eps) + smooth*eps\n\nopp = np.array(opponent_hand)\nopp = np.eye(3)[opp]\nopp = opp.reshape(1, mem_len, 3)\n\nmy = np.array(my_hand)\nmy = np.eye(3)[my]\nmy = my.reshape(1, mem_len, 3)\n\nwld = np.array(win_loss)\nwld = np.eye(3)[wld]\nwld = wld.reshape(1, mem_len, 3)\n\nb = np.concatenate([opp, my, wld], axis=-1)\nh = model.train_on_batch(b,r)\nt = model.predict(b)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from kaggle_environments import make\nenv = make(\"rps\", configuration={\"episodeSteps\": 1000})\nenv.run([\"periodic.py\", \"submission.py\"])\n\nenv.render(mode=\"ipython\", width=800, height=800)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}