{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This notebook is a comparison between beta_agent.py and nonbeta_agent.py.\n# In beta_agent.py, proba is defined as np.random.beta(bandit_state[k][0],bandit_state[k][1])\n# In nonbeta_agent.py, proba is defined as bandit_state[k][0]/(bandit_state[k][0]+bandit_state[k][1]) \n# The result seems to show that \"Multi Armed Bandit is NOT Stronger than Average\".\n# My question is that random number generation in beta_agent.py might make a mistake in best agent selection many times?\n# I'm appreciated if someone has an opinion on my question.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.execute_input":"2020-12-15T04:07:28.180105Z","iopub.status.busy":"2020-12-15T04:07:28.179093Z","iopub.status.idle":"2020-12-15T04:07:28.184602Z","shell.execute_reply":"2020-12-15T04:07:28.18393Z"},"papermill":{"duration":0.021868,"end_time":"2020-12-15T04:07:28.184737","exception":false,"start_time":"2020-12-15T04:07:28.162869","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"%%writefile beta_agent.py\n\nimport pandas as pd\nimport numpy as np\nimport json\nfrom random import randrange\n    \n\nclass agent():\n    def initial_step(self):\n        return np.random.randint(3)\n    \n    def history_step(self, history):\n        return np.random.randint(3)\n    \n    def step(self, history):\n        if len(history) == 0:\n            return int(self.initial_step())\n        else:\n            return int(self.history_step(history))\n\n        \nclass rps(agent):\n    def __init__(self, shift=0):\n        self.shift = shift\n    \n    def rps(self, history):\n        return self.shift % 3\n    \n\nagents = {    \n    'rps_0': rps(0),\n    'rps_1': rps(1),\n    'rps_2': rps(2),\n}\n\nhistory = []\nbandit_state = {k:[1,1] for k in agents.keys()}\n\n\ndef multi_armed_bandit_agent (observation, configuration):\n    \n    step_size = 3 \n    decay_rate = 1.1\n    \n    global history, bandit_state\n    \n    def log_step(step = None, history = None, agent = None, competitorStep = None, file = 'history.csv'):\n        if step is None:\n            step = np.random.randint(3)\n        if history is None:\n            history = []\n        history.append({'step': step, 'competitorStep': competitorStep, 'agent': agent})\n        if file is not None:\n            pd.DataFrame(history).to_csv(file, index = False)\n        return step\n    \n    def update_competitor_step(history, competitorStep):\n        history[-1]['competitorStep'] = int(competitorStep)\n        return history\n    \n    if observation.step == 0:\n        pass\n    else:\n        history = update_competitor_step(history, observation.lastOpponentAction)\n        \n        for name, agent in agents.items():\n            agent_step = agent.step(history[:-1])\n            bandit_state[name][1] = (bandit_state[name][1] - 1) / decay_rate + 1\n            bandit_state[name][0] = (bandit_state[name][0] - 1) / decay_rate + 1\n            \n            if (history[-1]['competitorStep'] - agent_step) % 3 == 1:\n                bandit_state[name][1] += step_size\n            elif (history[-1]['competitorStep'] - agent_step) % 3 == 2:\n                bandit_state[name][0] += step_size\n            else:\n                bandit_state[name][0] += step_size/2\n                bandit_state[name][1] += step_size/2\n            \n    with open('bandit.json', 'w') as outfile:\n        json.dump(bandit_state, outfile)\n    \n    \n    # generate random number from Beta distribution for each agent and select the most lucky one\n    best_proba = -1\n    best_agent = None\n    for k in bandit_state.keys():\n        \n        proba = np.random.beta(bandit_state[k][0],bandit_state[k][1])\n        #proba = bandit_state[k][0]/(bandit_state[k][0]+bandit_state[k][1])        \n        \n        if proba > best_proba:\n            best_proba = proba\n            best_agent = k\n        \n    step = agents[best_agent].step(history)\n    \n    return log_step(step, history, best_agent)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%writefile nonbeta_agent.py\n\nimport pandas as pd\nimport numpy as np\nimport json\nfrom random import randrange\n    \n\nclass agent():\n    def initial_step(self):\n        return np.random.randint(3)\n    \n    def history_step(self, history):\n        return np.random.randint(3)\n    \n    def step(self, history):\n        if len(history) == 0:\n            return int(self.initial_step())\n        else:\n            return int(self.history_step(history))\n\n        \nclass rps(agent):\n    def __init__(self, shift=0):\n        self.shift = shift\n    \n    def rps(self, history):\n        return self.shift % 3\n    \n\nagents = {    \n    'rps_0': rps(0),\n    'rps_1': rps(1),\n    'rps_2': rps(2),\n}\n\nhistory = []\nbandit_state = {k:[1,1] for k in agents.keys()}\n\n\ndef multi_armed_bandit_agent (observation, configuration):\n    \n    step_size = 3 \n    decay_rate = 1.1\n    \n    global history, bandit_state\n    \n    def log_step(step = None, history = None, agent = None, competitorStep = None, file = 'history.csv'):\n        if step is None:\n            step = np.random.randint(3)\n        if history is None:\n            history = []\n        history.append({'step': step, 'competitorStep': competitorStep, 'agent': agent})\n        if file is not None:\n            pd.DataFrame(history).to_csv(file, index = False)\n        return step\n    \n    def update_competitor_step(history, competitorStep):\n        history[-1]['competitorStep'] = int(competitorStep)\n        return history\n    \n    if observation.step == 0:\n        pass\n    else:\n        history = update_competitor_step(history, observation.lastOpponentAction)\n        \n        for name, agent in agents.items():\n            agent_step = agent.step(history[:-1])\n            bandit_state[name][1] = (bandit_state[name][1] - 1) / decay_rate + 1\n            bandit_state[name][0] = (bandit_state[name][0] - 1) / decay_rate + 1\n            \n            if (history[-1]['competitorStep'] - agent_step) % 3 == 1:\n                bandit_state[name][1] += step_size\n            elif (history[-1]['competitorStep'] - agent_step) % 3 == 2:\n                bandit_state[name][0] += step_size\n            else:\n                bandit_state[name][0] += step_size/2\n                bandit_state[name][1] += step_size/2\n            \n    with open('bandit.json', 'w') as outfile:\n        json.dump(bandit_state, outfile)\n    \n    \n    # generate random number from Beta distribution for each agent and select the most lucky one\n    best_proba = -1\n    best_agent = None\n    for k in bandit_state.keys():\n        \n        #proba = np.random.beta(bandit_state[k][0],bandit_state[k][1])\n        proba = bandit_state[k][0]/(bandit_state[k][0]+bandit_state[k][1])        \n        \n        if proba > best_proba:\n            best_proba = proba\n            best_agent = k\n        \n    step = agents[best_agent].step(history)\n    \n    return log_step(step, history, best_agent)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#!pip install -q -U kaggle_environments","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom kaggle_environments import make, evaluate","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"env = make(\"rps\", configuration={ \"episodeSteps\": 1000 })","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"env.run( [\"beta_agent.py\", \"nonbeta_agent.py\"] )\nenv.render(mode=\"ipython\", width=600, height=500)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluate(\n    \"rps\", \n   [\"beta_agent.py\", \"nonbeta_agent.py\"],\n    configuration={\"episodeSteps\": 1000}\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#[[0, 0]]\n#[[49.0, -49.0]]\n#[[0, 0]]\n#[[0, 0]]\n#[[0, 0]]\n#[[34.0, -34.0]]\n#[[0, 0]]\n#[[24.0, -24.0]]\n#[[0, 0]]\n#[[0, 0]]\n#[[0, 0]]\n#[[0, 0]]\n#[[0, 0]]\n#[[-36.0, 36.0]]","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}