{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Rock Paper Scissors - Sequential Strategies\n\nThis agent assumes our opponent is trying to learn our strategy, so we wait until they have learnt what we are doing, then switch to a strategy that will dominate it."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%%writefile submission.py\n\nimport random\nimport pydash\nimport numpy as np\nfrom collections import Counter\n\n\ndef get_last_time_result(results=[-1]):\n    if isinstance(results, int): results = [ results ]\n    for n in range(len(history['reward'])):\n        if history['reward'][-n] in results: return n\n    else: return 0\n\ndef get_streak(results=[-1]):\n    if isinstance(results, int): results = [ results ]\n    for n in range(len(history['reward'])):\n        if history['reward'][-n] not in results: return n\n    else: \n        return len(history['reward'])\n\ndef get_previous_streak(results=[-1]):\n    if isinstance(results, int): results = [ results ]\n    for n in range(len(history['reward'])):\n        if history['reward'][-n] not in results: \n            for n in range(n+1, len(history['reward'])):\n                if history['reward'][-n] not in results: \n                    return n            \n            else:\n                return len(history['reward'])\n    else:\n        return 0\n\n    \naction            = 0\nincrement_on_lose = 1\nincrement_on_turn = 1\nhistory   = {\n    \"action\":   [],\n    \"opponent\": [],\n    \"reward\":   [],\n    \"streaks\":  [],\n}\n# observation   =  {'step': 1, 'lastOpponentAction': 1}\n# configuration =  {'episodeSteps': 1000, 'agentTimeout': 60, 'actTimeout': 1, 'runTimeout': 120\ndef sequential_strategies(observation, configuration, nstreak=2):\n    global action\n    global increment_on_lose \n    global increment_on_turn \n    global history\n    if observation.step > 0:\n        history['opponent'].append(observation.lastOpponentAction)\n        reward = (\n            0 if history['action'][-1] == (history['opponent'][-1]) else\n            1 if history['action'][-1] == (history['opponent'][-1] + 1) % configuration.signs else\n            -1\n        )\n        history['reward'].append(reward)\n        lose_streak     = get_streak([-1])\n        draw_streak     = get_streak([0, -1])\n        previous_streak = get_previous_streak([-1])\n        # print('reward',reward)\n        # print('lose_streak', lose_streak)\n        # print('previous_streak', previous_streak)\n\n        # Counter static agent\n        if observation.step > 3 and len(set(history['opponent'])) == 1:\n            increment_on_turn = 0\n            action = list(set(history['opponent']))[0] + 1\n    \n        elif (\n            lose_streak >= nstreak \n         or draw_streak >= nstreak*2\n        ):  \n            increment_on_turn = random.choice([0,1,2])             \n            if lose_streak >= nstreak*2:\n                increment_on_lose += 1\n                history['streaks'].append(0)\n            else:\n                history['streaks'].append(previous_streak)\n            \n            action += increment_on_lose\n\n            if len(history['streaks']) and previous_streak >= history['streaks'][-1] - 1:\n                action += 1        \n\n            \n    action += increment_on_turn\n        \n    history['action'].append(action)\n    return int(action) % configuration.signs\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%run submission.py","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from kaggle_environments import make\n\nenv = make(\"rps\", configuration={\"episodeSteps\": 100}, debug=True)\nenv.run([\"submission.py\", 1])\nenv.render(mode=\"ipython\", width=600, height=600)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from kaggle_environments import make\n\nenv = make(\"rps\", configuration={\"episodeSteps\": 100}, debug=True)\nenv.run([\"submission.py\", lambda obs, conf: obs.step % 3 ])\nenv.render(mode=\"ipython\", width=600, height=600)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from kaggle_environments import make\n\nenv = make(\"rps\", configuration={\"episodeSteps\": 100}, debug=False)\nenv.run([\"submission.py\", \"../input/rock-paper-scissors-decision-tree/submission.py\" ])\nenv.render(mode=\"ipython\", width=600, height=600)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}