{"cells":[{"metadata":{},"cell_type":"markdown","source":"This notebook is to just explore the baseline with an agent that works on a simple research based logic and to get acquainted with the environment.\n\n**Please upvote it if you find it helpful or interesting!**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I would like to try out some researched logic in order to play the game. The link to the paper is [here](https://arxiv.org/pdf/1404.5199v1.pdf) and article is [here](https://arstechnica.com/science/2014/05/win-at-rock-paper-scissors-by-knowing-thy-opponent/#:~:text=Therefore%2C%20this%20is%20the%20best,thing%20that%20you%20just%20played.).\n\nAs per the research story goes, a group of researchers from Chinese universities have written a paper about the role of psychology in winning (or losing) at rock-paper-scissors. After studying how players change or keep their strategies during multiple-round sessions, they figured out a basic rule that people tend to play by that could potentially be exploited.\n\nThe researchers took 360 students, broke them into groups of six, and had them play 300 rounds of rock-paper-scissors in random pairings. The students received small amounts of money each time they won a round. As they played, the researchers observed how the players rotated through the three play options as they won or lost. It was done to extract and formulate a simple pattern of behavioural psychology which mostly works for individuals playing the game."},{"metadata":{},"cell_type":"markdown","source":"### Logic to play with"},{"metadata":{},"cell_type":"markdown","source":"Conclusively, the general pattern that was observed here and can be used as a winning strategy is: if you lose the first round, switch to the thing that beats the thing your opponent just played. If you win, don't keep playing the same thing, but instead switch to the thing that would beat the thing that you just played. In other words, play the hand your losing opponent just played. To wit: you win a round with rock against someone else's scissors. They are about to switch to paper. You should switch to scissors. Got it? Good.\n\nThis makes sense as, our human brain is 'mindlessly' into searching for patterns in anything. [Humans try to detect patterns in their environment all the time](https://www.sciencedaily.com/releases/2018/05/180531114642.htm). Now the name of the renowned book of Christopher Bishop makes more sense, doesn't it :P? Anyway, so here logic is to take advantage of this pattern recognition attribute and this is what we are going to do here.\n\nThe logic is going to do just fine as long the opponent doesn't know about it. So, kaggle bots don't you dare look here. :P"},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.core.magic import register_cell_magic\n\n\n@register_cell_magic\ndef write_and_run(line, cell):\n    argz = line.split()\n    file = argz[-1]\n    mode = 'w'\n    if len(argz) == 2 and argz[0] == '-a':\n        mode = 'a'\n    with open(file, mode) as f:\n        f.write(cell)\n    get_ipython().run_cell(cell)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%write_and_run submission.py\n\nimport numpy as np\nimport pandas as pd\nimport random\n\nfrom kaggle_environments.envs.rps.utils import get_score\n\nmy_prev_move = None\n\ndef dont_always_copy_opponent_move(observation, configuration):\n    \"\"\"\n    Implemented research logic.\n    \n    Info:\n    Rock = 0, Paper = 1, Scissors = 2...\n    \"\"\"\n    global my_prev_move\n    N = configuration.signs\n    curr_move = random.randrange(0, N)\n    \n    if observation.step == 0:\n        my_prev_move = curr_move\n        return curr_move\n    else:\n        opponent_prev_move = observation.lastOpponentAction\n        \n        result = get_score(my_prev_move, opponent_prev_move)\n        \n        if result == -1:    ##If we lose in the previous round\n            curr_move = (opponent_prev_move + 1) % N\n        elif result == 1:      ##If we win in previous round\n            curr_move = opponent_prev_move\n        else:               ##If there's a draw, we choose to go with random for now\n            curr_move = random.randrange(0, N)\n        \n    my_prev_move = curr_move\n    \n    return curr_move","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from kaggle_environments import make\n\n# Setup a rps environment.\nenv = make(\"rps\", configuration={\"episodeSteps\": 1000})\n\n# Run the basic agent against a default agent which chooses a \"random\" move.\nenv.run([dont_always_copy_opponent_move, \"reactionary\"])\n\n# Render an html ipython replay of the tictactoe game.\nenv.render(mode=\"ipython\", width=800, height=800)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let me know if something can be corrected or improved. Thank you!"},{"metadata":{},"cell_type":"markdown","source":" "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}