{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Agent Pool Evaluation\n\nThis is a notebook that should help with evaluating an agent based on other public and built-in agents. If your new agent can beat most of these baseline bots, then it should be ready for the leaderboard!"},{"metadata":{},"cell_type":"markdown","source":"Credit goes to https://www.kaggle.com/ttahara/rps-simple-baseline. I'm just using their bot to test the evaluation system."},{"metadata":{"trusted":true},"cell_type":"code","source":"%%writefile agent.py\n\n##########################\n# DEFINE YOUR AGENT HERE #\n##########################\n\ndef copy_opponent_agent(observation, configuration):\n    if observation.step > 0:\n        opp_hand = observation.lastOpponentAction\n        return (opp_hand + 1) % 3\n    else:\n        return 1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from kaggle_environments.envs.rps.agents import *\nfrom kaggle_environments import make\n\ndef randomAgent(obs, config):\n    return random.randint(0, 2)\n\nenv = make('rps', debug = True)\n\n# Pass in your agent to evaluate\ndef evaluate(agent):\n    \n    pool = [\n        rock,\n        paper,\n        scissors,\n        copy_opponent,\n        reactionary,\n        counter_reactionary,\n        statistical,\n        randomAgent,\n    ]\n\n\n    print()\n    overall = 0\n\n    for opponent in pool:\n\n        env.reset()\n\n        env.run([agent, opponent])\n        json = env.toJSON()\n        rewards = json['rewards']\n\n        opponentName = str(opponent).split()[1].capitalize()\n\n        padding = ''; length = len(str(rewards))\n        if length < 15: padding = ' ' * (15 - length)\n\n        print(f'Rewards: {rewards}{padding}  Agent vs {opponentName}')\n        overall += rewards[0]\n    \n    overall /= len(pool)\n    print(f'Overall Score: {overall}')\n    \n    return overall\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = evaluate('/kaggle/working/agent.py')\nif score <= 0:\n    print('\\nU MIGHT WANNA FIX SOME THINGS BUDDY')\nelse:\n    print('\\nITS GREAT! NOW CHUCK IT INTO THE LEADERBOARD')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I hope that this helps with evaluating your agent before submission! Feedback and ideas are always welcome. Good luck!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}