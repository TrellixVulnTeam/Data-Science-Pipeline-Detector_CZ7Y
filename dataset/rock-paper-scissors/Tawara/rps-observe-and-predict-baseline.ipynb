{"cells":[{"metadata":{},"cell_type":"markdown","source":"## About\n\nThis agent randomly plays hands in for the first hundred steps and observes opponent's hands.  \nAfter that, it predicts a next opponent's hand using last **_self's_** and opponent's hand.\n  \nTransition Matrix is used for predicton. Thanks to: https://www.kaggle.com/group16/rps-opponent-transition-matrix"},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"%%bash\npip install 'kaggle-environments>=0.1.6'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"%%writefile submission.py\n\nimport numpy as np\nimport pandas as pd\nimport random\n\nT = np.zeros((3, 3, 3))\n\nself_actions = np.full(1001, -1, dtype=int)\noppo_actions = np.full(1001, -1, dtype=int)\n\nobserve_until = 600\n\ndef observe_and_predict(observation, configuration):\n    \n    step = observation.step\n    global T, P\n    global self_actions, oppo_actions\n    global observe_until\n    \n    if step == 0:\n        self_act = np.random.randint(3)\n        self_actions[step] = self_act\n        return self_act\n    \n    self_1s_bef = self_actions[step - 1]\n    oppo_1s_bef = observation.lastOpponentAction\n    oppo_actions[step - 1] = oppo_1s_bef\n    \n    if 2 <= step < observe_until:\n        self_2s_bef = self_actions[step - 2]\n        oppo_2s_bef = oppo_actions[step - 2]\n        T[self_2s_bef][oppo_2s_bef][oppo_1s_bef] += 1\n\n    P = T / np.maximum(1, T.sum(axis=2)[..., None])    \n    p = P[self_1s_bef][oppo_1s_bef]\n    \n    if observe_until <= step and np.sum(p) == 1:\n        self_act = int((np.random.choice([0, 1, 2], p=p) + 1)) % 3\n    else:\n        self_act = np.random.randint(3)\n    \n    self_actions[step] = self_act\n    return self_act","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%writefile random_agent.py\nimport numpy as np\ndef random_agent(observation, configuration):\n    return np.random.randint(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%writefile copy_opponent.py\ndef copy_opponent_agent(observation, configuration):\n    if observation.step > 0:\n        return observation.lastOpponentAction\n    else:\n        return 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%writefile win_last_opponent.py\nimport numpy as np\ndef win_last_opponent (observation, configuration):\n    if observation.step > 0:\n        opp_hand = observation.lastOpponentAction\n        return (opp_hand + 1) % 3\n    else:\n        return np.random.randint(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from kaggle_environments import evaluate, make\nenv = make(\"rps\", configuration={\"episodeSteps\": 1000})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"env.reset()\nenv.run([\"submission.py\", \"copy_opponent.py\"])\nenv.render(mode=\"ipython\", width=800, height=800)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"env.reset()\nenv.run([\"submission.py\", \"win_last_opponent.py\"])\nenv.render(mode=\"ipython\", width=800, height=800)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"env.reset()\nenv.run([\"submission.py\", \"random_agent.py\"])\nenv.render(mode=\"ipython\", width=800, height=800)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}