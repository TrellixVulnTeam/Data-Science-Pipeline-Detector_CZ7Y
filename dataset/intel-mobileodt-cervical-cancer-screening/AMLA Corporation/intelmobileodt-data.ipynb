{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"468d3800-299c-b067-dad9-85ee3e9d3b9f"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d8bbfeb9-0cd1-2f76-6372-13b901b59922"},"outputs":[],"source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom skimage.io import imread, imshow\nimport cv2\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import backend as K \nK.set_image_dim_ordering('th')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"09aaa259-5079-a632-a1ec-68f1b217d693"},"outputs":[],"source":"import os\nfrom glob import glob\nTRAIN_DATA = \"../input/train\"\ntype_1_files = glob(os.path.join(TRAIN_DATA, \"Type_1\", \"*.jpg\"))\ntype_1_ids = np.array([s[len(os.path.join(TRAIN_DATA, \"Type_1\"))+1:-4] for s in type_1_files])\ntype_2_files = glob(os.path.join(TRAIN_DATA, \"Type_2\", \"*.jpg\"))\ntype_2_ids = np.array([s[len(os.path.join(TRAIN_DATA, \"Type_2\"))+1:-4] for s in type_2_files])\ntype_3_files = glob(os.path.join(TRAIN_DATA, \"Type_3\", \"*.jpg\"))\ntype_3_ids = np.array([s[len(os.path.join(TRAIN_DATA, \"Type_3\"))+1:-4] for s in type_3_files])\n\n\nTEST_DATA = \"../input/test\"\ntest_files = glob(os.path.join(TEST_DATA, \"*.jpg\"))\ntest_ids = np.array([s[len(TEST_DATA)+1:-4] for s in test_files])\n\n\nADDITIONAL_DATA = \"../input/additional\"\nadditional_type_1_files = glob(os.path.join(ADDITIONAL_DATA, \"Type_1\", \"*.jpg\"))\nadditional_type_1_ids = np.array([s[len(os.path.join(ADDITIONAL_DATA, \"Type_1\"))+1:-4] for s in additional_type_1_files])\nadditional_type_2_files = glob(os.path.join(ADDITIONAL_DATA, \"Type_2\", \"*.jpg\"))\nadditional_type_2_ids = np.array([s[len(os.path.join(ADDITIONAL_DATA, \"Type_2\"))+1:-4] for s in additional_type_2_files])\nadditional_type_3_files = glob(os.path.join(ADDITIONAL_DATA, \"Type_3\", \"*.jpg\"))\nadditional_type_3_ids = np.array([s[len(os.path.join(ADDITIONAL_DATA, \"Type_3\"))+1:-4] for s in additional_type_3_files])\n\ndef get_filename(image_id, image_type):\n    \"\"\"\n    Method to get image file path from its id and type   \n    \"\"\"\n    if image_type == \"Type_1\" or \\\n        image_type == \"Type_2\" or \\\n        image_type == \"Type_3\":\n        data_path = os.path.join(TRAIN_DATA, image_type)\n    elif image_type == \"Test\":\n        data_path = TEST_DATA\n    elif image_type == \"AType_1\" or \\\n          image_type == \"AType_2\" or \\\n          image_type == \"AType_3\":\n        data_path = os.path.join(ADDITIONAL_DATA, image_type)\n    else:\n        raise Exception(\"Image type '%s' is not recognized\" % image_type)\n\n    ext = 'jpg'\n    return os.path.join(data_path, \"{}.{}\".format(image_id, ext))\n\ndef get_image_data(image_id, image_type):\n    \"\"\"\n    Method to get image data as np.array specifying image id and type\n    \"\"\"\n    fname = get_filename(image_id, image_type)\n    img = cv2.imread(fname)\n    assert img is not None, \"Failed to read image : %s, %s\" % (image_id, image_type)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    return img\n\nprint(len(additional_type_1_files), len(additional_type_2_files), len(additional_type_2_files))\nprint(\"Type 1\", additional_type_1_ids[:10])\nprint(\"Type 2\", additional_type_2_ids[:10])\nprint(\"Type 3\", additional_type_3_ids[:10])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bd4632be-6017-3eb6-4394-3f25ec7f8d06"},"outputs":[],"source":"def plt_st(l1,l2):\n    plt.figure(figsize=(l1,l2))\n\ndef apply_image_clustering(img):\n    Z = img.reshape((-1,3))\n    \n    # convert to np.float32\n    Z = np.float32(Z)\n\n    # define criteria, number of clusters(K) and apply kmeans()\n    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n    \n    \"\"\"\n    Right now the mask has an either in or out policy \n    \"\"\"\n    K = 4\n    ret,label,center=cv2.kmeans(Z,K,None,criteria,10,cv2.KMEANS_RANDOM_CENTERS)\n    \n    # Now convert back into uint8, and make original image\n    center = np.uint8(center)\n    res = center[label.flatten()]\n    res2 = res.reshape((img.shape))\n    return res2\n\ntile_size = (256, 256)\nn = 15\n\ncomplete_images = []\nfor k, type_ids in enumerate([type_1_ids, type_2_ids, type_3_ids]):\n    m = int(np.floor(len(type_ids) / n))\n    complete_image = np.zeros((m*(tile_size[0]+2), n*(tile_size[1]+2), 3), dtype=np.uint8)\n    train_ids = sorted(type_ids)\n    counter = 0\n    for i in range(m):\n        ys = i*(tile_size[1] + 2)\n        ye = ys + tile_size[1]\n        for j in range(n):\n            xs = j*(tile_size[0] + 2)\n            xe = xs + tile_size[0]\n            image_id = train_ids[counter]; counter+=1\n            img = get_image_data(image_id, 'Type_%i' % (k+1))\n            img = cv2.resize(img, dsize=tile_size)\n            img = cv2.putText(img, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_SIMPLEX, 2.0, (255, 255, 255), thickness=3)\n            complete_image[ys:ye, xs:xe] = img[:,:,:]\n    complete_images.append(complete_image)\n    \nplt_st(20, 20)\nplt.imshow(complete_images[0])\nplt.title(\"Training dataset of type %i\" % (1))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e2e7d3c8-b2de-a028-6304-9749929063fc"},"outputs":[],"source":"plt_st(20, 20)\nplt.imshow(complete_images[2])\nplt.title(\"Training dataset of type %i\" % (3))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"31e123b3-340b-357e-d479-3705b16aaaf7"},"outputs":[],"source":"from PIL import Image\nimport os, sys\n#image = Image.open('../kaggle/input/train/Type_1/10.jpg', \"rb\")\n#image.show()\nimage_id = 10\nimage_type = 'Type_1'\nfname = get_filename(image_id, image_type)\nprint(fname)\njpgfile = Image.open(fname)\nprint(jpgfile.bits, jpgfile.size, jpgfile.format)\nplt.imshow(jpgfile)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a4f1bf83-0d6a-5d75-66da-14109f86d9ae"},"outputs":[],"source":"def plt_st(l1,l2):\n    plt.figure(figsize=(l1,l2))\n\ntile_size = (256, 256)\nn = 15\n\ncomplete_images = []\nfor k, type_ids in enumerate([type_1_ids, type_2_ids, type_3_ids]):\n    m = int(np.floor(len(type_ids) / n))\n    complete_image = np.zeros((m*(tile_size[0]+2), n*(tile_size[1]+2), 3), dtype=np.uint8)\n    train_ids = sorted(type_ids)\n    counter = 0\n    for i in range(m):\n        ys = i*(tile_size[1] + 2)\n        ye = ys + tile_size[1]\n        for j in range(n):\n            xs = j*(tile_size[0] + 2)\n            xe = xs + tile_size[0]\n            image_id = train_ids[counter]; counter+=1\n            img = get_image_data(image_id, 'Type_%i' % (k+1))\n            img = cv2.resize(img, dsize=tile_size)\n            img = cv2.putText(img, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_SIMPLEX, 2.0, (255, 255, 255), thickness=3)\n            complete_image[ys:ye, xs:xe] = img[:,:,:]\n    complete_images.append(complete_image)\n    \nplt_st(20, 20)\nplt.imshow(complete_images[0])\nplt.title(\"Training dataset of type %i\" % (1))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"698d619d-a0f5-de4d-7c35-e184a7d56a05"},"outputs":[],"source":"classifier = Sequential()\nclassifier.add(Convolution2D(32,(3,3), input_shape = (3, 64, 64), activation = 'relu'))\nclassifier.add(MaxPooling2D(pool_size=(2,2)))\nclassifier.add(Flatten())\nclassifier.add(Dense(units=128, activation='relu'))\nclassifier.add(Dense(units=3, activation='sigmoid'))\nclassifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f1cf50b4-f3db-4de1-98eb-16d5ce4c1e25"},"outputs":[],"source":"#fitting the train data\ntrain_datagen = ImageDataGenerator(\n        rescale=1./255)\n\n#        shear_range=0.2,\n#       zoom_range=0.2,\n#      horizontal_flip=True)\n\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntraining_set = train_datagen.flow_from_directory(\n        TRAIN_DATA,\n        target_size=(64, 64),\n        batch_size=32,\n        class_mode='categorical')\n\ntest_set = test_datagen.flow_from_directory(\n        TEST_DATA,\n        target_size=(64, 64),\n        batch_size=32,\n        class_mode='categorical')\n\nclassifier.fit_generator(\n        training_set,\n        steps_per_epoch=40,\n        epochs=2,\n        validation_data=test_set,\n        nb_val_samples=4)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}