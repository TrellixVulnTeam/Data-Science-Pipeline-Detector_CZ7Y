{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"56c61112-669e-f247-795e-4797ce9e715a"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport scipy.ndimage as ndi\nfrom scipy.misc import imread\nfrom scipy.misc import imshow\nfrom scipy import sum, average\nfrom skimage import feature\nfrom skimage.transform import resize\nfrom sklearn import datasets, svm, metrics, mixture\nfrom skimage.color import rgb2gray\nfrom sklearn.ensemble import (RandomForestClassifier, ExtraTreesClassifier,\n                              AdaBoostClassifier)\nimport cv2\nimport math\nfrom sklearn.utils import shuffle\nimport numpy as np\nimport pywt\n\nfrom glob import glob\nbasepath = '../input/train/'\n\n\nall_cervix_images = []\n\nfor path in sorted(glob(basepath + \"*\")):\n    cervix_type = path.split(\"/\")[-1]\n    cervix_images = sorted(glob(basepath + cervix_type + \"/*\"))\n    all_cervix_images = all_cervix_images + cervix_images\n\nall_cervix_images = pd.DataFrame({'imagepath': all_cervix_images})\nall_cervix_images['filetype'] = all_cervix_images.apply(lambda row: row.imagepath.split(\".\")[-1], axis=1)\nall_cervix_images['type'] = all_cervix_images.apply(lambda row: row.imagepath.split(\"/\")[-2], axis=1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d7e67685-e6df-ee33-1b7a-56cfdb67de94"},"outputs":[],"source":"image_name = all_cervix_images['imagepath'].values[0]\nimg = np.flipud(plt.imread(image_name))\nplt.imshow(img,cmap=plt.cm.gray,interpolation='nearest')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"65f58f6d-d060-bfb9-dfbd-456f742c3f5e"},"outputs":[],"source":"img_clean = img[1000:2400, :]\nplt.imshow(img_clean,cmap=plt.cm.gray,interpolation='nearest')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a42b564b-6fb5-bf0b-5340-57d0eb1f5243"},"outputs":[],"source":"img_med = ndi.median_filter(img_clean, size=5)\nplt.imshow(img_med,cmap=plt.cm.gray,interpolation='nearest')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ae2c7a94-46be-5a45-2938-91ec44caea28"},"outputs":[],"source":"plt.hist(img_med.flat,bins=40,range=(0,250));"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6d0525be-d8f9-c2f0-bd91-2b4b6aef4c1d"},"outputs":[],"source":"bubbles = (img_med <= 45)\nsand = (img_med > 45) & (img_med <= 150)\nwhiter =(img_med > 150) & (img_med <= 220)\nglass = (img_med > 220)\n\ndef plot_images(cmap=plt.cm.gray):\n    for n, (name, image) in \\\n        enumerate([('Original', img_med),\n                   ('Bubbles', bubbles),\n                   ('Sand', sand),\n                   ('white',whiter),\n                   ('Glass', glass)]):\n    \n        plt.subplot(3, 2, n + 1)\n        plt.imshow(np.float64(image), cmap=cmap)\n        plt.title(name)\n        plt.axis('off')\n        \nplot_images()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"14f4bed8-1079-d6f9-467c-c83dd4c96e78"},"outputs":[],"source":"for img in (sand, bubbles, glass, whiter):\n    img[:] = ndi.binary_opening(img, np.ones((5,5))\n    img[:] = ndi.binary_closing(img, np.ones((5,5)))\n\nplot_images()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1b2e0013-5040-c891-f11f-7f8bf30be5ce"},"outputs":[],"source":"image_name = all_cervix_images['imagepath'].values[2]\nimg = np.flipud(plt.imread(image_name))\nplt.imshow(img,cmap=plt.cm.gray,interpolation='nearest')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"462b82b4-149e-0b9b-8bb5-480a73a28f02"},"outputs":[],"source":"img_clean = img[1000:2000, :]\nplt.imshow(img_clean,cmap=plt.cm.gray,interpolation='nearest')\n\nimg_med = ndi.median_filter(img_clean, size=5)\nplt.imshow(img_med,cmap=plt.cm.gray,interpolation='nearest')\n\nplt.hist(img_med.flat,bins=100,range=(0,150));"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8dafe12e-322e-0a7c-468e-2d88add0df66"},"outputs":[],"source":"def w2d(img, mode='haar', level=1):\n    #imArray = cv2.imread(img)\n    imArray = cv2.resize(imread(image_name), dsize=(256,256))\n    #Datatype conversions\n    #convert to grayscale\n    imArray = cv2.cvtColor( imArray,cv2.COLOR_RGB2GRAY )\n    #convert to float\n    imArray =  np.float32(imArray)   \n    imArray /= 255;\n    # compute coefficients \n    coeffs=pywt.wavedec2(imArray, mode, level=level)\n\n    #Process Coefficients\n    coeffs_H=list(coeffs)  \n    coeffs_H[0] *= 0;  \n\n    # reconstruction\n    imArray_H=pywt.waverec2(coeffs_H, mode);\n    imArray_H *= 255;\n    imArray_H =  np.uint8(imArray_H)\n    #Display result\n    return imArray_H"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"14e204a4-4522-4819-7530-e061644ba91f"},"outputs":[],"source":"\nfig = plt.figure()\n\nimage_name = all_cervix_images['imagepath'].values[2]\nw2d(image_name,'db1',8)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"690ef3c8-a3fc-722d-edbc-9da095244f2f"},"outputs":[],"source":"train_data = []\ntrain_target = []\ntest_data = []\ntest_target = []\nraw_data = []\nfeature_names = ['image_array']\n\nall_samples = 50\ntrain_samples = 40\n\nfor t in all_cervix_images['type'].unique():\n    for a in range(all_samples):\n        image_name = all_cervix_images[all_cervix_images['type'] == t]['imagepath'].values[a]\n        image = resize(imread(image_name), (200, 200))\n        \n        #gray_image = w2d(image_name,'db1',8) #.6\n        #gray_image = gabfn(image_name)\n        #gray_image = crop_image(rgb2gray(new_image)) #.45\n        #gray_image = crop_image(rgb2gray(image)) #.5\n        \n           \n        \n        image_array = gray_image #resize(gray_image, (200, 200))\n    \n        if a > train_samples:\n            test_data.append(image_array.flatten())\n            test_target.append(t)\n        else:\n            train_data.append(image_array.flatten())\n            train_target.append(t)\n    \nprint(len(train_data))\nprint(len(test_data))\n\nrandom_forest = RandomForestClassifier(n_estimators=30)\nrandom_forest.fit(train_data, train_target)\n\nrandom_forest_predicted = random_forest.predict(test_data)\nrandom_forest_probability = random_forest.predict_proba(test_data)\n\nprint(metrics.classification_report(test_target, random_forest_predicted))\nprint(metrics.confusion_matrix(test_target, random_forest_predicted))\nprint(test_target)\nprint(random_forest_predicted)\nprint(random_forest_probability)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"46014afd-35c4-797b-ff7c-086f11979a2a"},"outputs":[],"source":"def gabfn(image_name):\n g_kernel = cv2.getGaborKernel((21, 21), 8.0, np.pi/4, 10.0, 0.5, 0, ktype=cv2.CV_32F)\n image_name = cv2.resize(imread(image_name), dsize=(256,256)) \n image_name = cv2.cvtColor(image_name, cv2.COLOR_BGR2GRAY)\n filtered_img = cv2.filter2D(image_name, cv2.CV_8UC3, g_kernel)\n cv2.imshow('image', image_name)\n cv2.imshow('filtered image', filtered_img)\n h, w = g_kernel.shape[:2]\n g_kernel = cv2.resize(g_kernel, (3*w, 3*h), interpolation=cv2.INTER_CUBIC)\n #cv2.imshow('gabor kernel (resized)', g_kernel)\n return g_kernal"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d4c4cba0-ec3d-cfee-6e0a-b11d865dbf7e"},"outputs":[],"source":"fig = plt.figure()\n\nimage_name = all_cervix_images['imagepath'].values[2]\ngabfn(image_name)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}