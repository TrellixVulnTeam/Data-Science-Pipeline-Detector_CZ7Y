{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"86e7cbb3-94b0-fb56-bcc7-175e417fd8d1"},"source":"This is a starter workbook that is made for a draft model\n\nThe notebook is based on code from statefarm competition by @ZFturbo \n\nI hope some of you find it useful"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8fc5fd81-b0ef-9da4-c003-e80c79e4dbc9"},"outputs":[],"source":"import numpy as np\nnp.random.seed(2016)\n\nimport os\nimport glob\nimport cv2\nimport math\nimport pickle\nimport datetime\nimport pandas as pd\nimport statistics\nimport matplotlib.pyplot as plt\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.cross_validation import KFold\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Activation, Flatten\nfrom keras.layers.convolutional import Convolution2D, MaxPooling2D\nfrom keras.optimizers import SGD\nfrom keras.utils import np_utils\nfrom keras.models import model_from_json\nfrom sklearn.metrics import log_loss\nfrom scipy.misc import imread, imresize"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7ae5b96b-502a-9b99-09ca-8681890543fa"},"outputs":[],"source":"import cv2\nimport glob\nimport matplotlib.pyplot as plt\nimport os"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bd6757f5-2a19-a460-d429-a85b6d162e72"},"outputs":[],"source":"import random\nlabels = [1,2,3]\ncount = 0\nfor l in labels:\n    train_files = [\"../input/train/Type_\" + str(l) + \"/\" + f for f in os.listdir(\"../input/train/Type_\" + str(l) + \"/\")]\n    random_file = random.choice(train_files)\n    im = cv2.imread(random_file)\n    print(\"{} : {}\".format(random_file, im.shape))\n    plt.subplot(1, 4, count+1).set_title(labels[l])\n    plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB)); plt.axis('off')\n    \n    count += 1"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f638db56-6032-3b0e-e0ac-413ad0e35606"},"outputs":[],"source":"img_rows = 224\nimg_cols = 224\n\ndef get_im_cv2(path, img_rows, img_cols, color_type=3):\n    # Load as grayscale\n    if color_type == 1:\n        img = cv2.imread(path, 0)\n    elif color_type == 3:\n        img = cv2.imread(path)\n    # Reduce size\n    resized = cv2.resize(img, (img_cols, img_rows))\n    return resized\n\n\ndef load_train(img_rows, img_cols, color_type=3):\n    X_train = []\n    y_train = []\n    print('Read train images')\n    for j in range(1,4):\n        print('Load folder Type_{}'.format(j))\n        path = os.path.join('..', 'input', 'train', 'Type_' + str(j), '*.jpg')\n        files = glob.glob(path)\n        for fl in files:\n            flbase = os.path.basename(fl)\n            img = get_im_cv2(fl, img_rows, img_cols, color_type)\n            X_train.append(img)\n            y_train.append(j)\n\n    return X_train, y_train\n\nX_train,y_train = load_train(64,64,3)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d81e2b1d-6c0b-d758-cb17-068f1ffa3477"},"outputs":[],"source":"def cache_data(data, path):\n    if os.path.isdir(os.path.dirname(path)):\n        file = open(path, 'wb')\n        pickle.dump(data, file)\n        file.close()\n    else:\n        print('Directory doesnt exists')\n\n\ndef restore_data(path):\n    data = dict()\n    if os.path.isfile(path):\n        file = open(path, 'rb')\n        data = pickle.load(file)\n    return data"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fa58e78b-e857-bf22-31b0-87d74dbe7997"},"outputs":[],"source":"def save_model(model):\n    json_string = model.to_json()\n    if not os.path.isdir('cache'):\n        os.mkdir('cache')\n    open(os.path.join('cache', 'architecture.json'), 'w').write(json_string)\n    model.save_weights(os.path.join('cache', 'model_weights.h5'), overwrite=True)\n\n\ndef read_model():\n    model = model_from_json(open(os.path.join('cache', 'architecture.json')).read())\n    model.load_weights(os.path.join('cache', 'model_weights.h5'))\n    return model"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"91480e96-1ce6-09d2-6556-9c3c41e2cd19"},"outputs":[],"source":"def create_model(img_rows, img_cols, color_type=3):\n    nb_classes = 3\n    # number of convolutional filters to use\n    nb_filters = 8\n    # size of pooling area for max pooling\n    nb_pool = 2\n    # convolution kernel size\n    nb_conv = 2\n    model = Sequential()\n    model.add(Convolution2D(nb_filters, nb_conv, nb_conv,\n                            border_mode='valid',\n                            input_shape=(color_type, img_rows, img_cols)))\n    model.add(Activation('relu'))\n    model.add(Convolution2D(nb_filters, nb_conv, nb_conv))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n    model.add(Dropout(0.25))\n\n    model.add(Flatten())\n    model.add(Dense(128))\n    model.add(Activation('relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(nb_classes))\n    model.add(Activation('softmax'))\n\n    sgd = SGD(lr=0.01, decay=0, momentum=0, nesterov=False)\n    model.compile(loss='categorical_crossentropy', optimizer=sgd)\n    return model"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9db2d23e-e252-4c6b-3af3-49dcdcad4b3b"},"outputs":[],"source":"nb_epoch = 3\nbatch_size = 16\nmodel = create_model_v1(img_rows, img_cols, color_type_global)\nmodel.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n          show_accuracy=True, verbose=1)\n"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}