{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"263a676d-a42e-a31e-d078-2239f1ffc5f2"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cda98aa4-8fb4-a9c8-048f-d07457ae2d0c"},"outputs":[],"source":"\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input/test\"]).decode(\"utf8\"))\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nfrom keras import backend as K\n\n# dimensions of our images.\nimg_width, img_height = 150, 150\ntrain_data_dir = '../input/train'\nvalidation_data_dir = '../input/test'\nnb_train_samples = 2000\nnb_validation_samples = 800\nepochs = 50\nbatch_size = 16\n\nif K.image_dim_ordering() == 'channels_first':\n    input_shape2 = (3, img_width, img_height)\nelse:\n    input_shape2 = (img_width, img_height, 3)\n    \nmodel = Sequential()\nmodel.add(Conv2D(32, 3, 3,  input_shape=input_shape2))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(32, 3, 3))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, 3, 3))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(64))\nmodel.add(Activation('relu'))\n\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1))\nmodel.add(Activation('softmax'))\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer='rmsprop',\n              metrics=['accuracy'])\n\n# this is the augmentation configuration we will use for training\ntrain_datagen = ImageDataGenerator(\n        rescale=1./255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True)\n\n# this is the augmentation configuration we will use for testing:\n# only rescaling\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\n# this is a generator that will read pictures found in\n# subfolers of 'data/train', and indefinitely generate\n# batches of augmented image data\ntrain_generator = train_datagen.flow_from_directory(\n        train_data_dir,  # this is the target directory\n        target_size=(150, 150),  # all images will be resized to 150x150\n        batch_size=batch_size,\n        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n\n# this is a similar generator, for validation data\nvalidation_generator = test_datagen.flow_from_directory(\n        validation_data_dir,\n        target_size=(150, 150),\n        batch_size=batch_size,\n        class_mode='binary')\n\nmodel.fit_generator(\n        train_generator,\n        nb_epoch = 20,\n        samples_per_epoch = 1480//20,\n        nb_val_samples = 1480,\n        validation_data=validation_generator)\nmodel.save_weights('first_try.h5')  # always save your weights after training or during training\n\n"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}