{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 读入数据\n","metadata":{}},{"cell_type":"code","source":"#寻找数据文件路径\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2021-07-18T13:19:37.921288Z","iopub.execute_input":"2021-07-18T13:19:37.921618Z","iopub.status.idle":"2021-07-18T13:19:37.929679Z","shell.execute_reply.started":"2021-07-18T13:19:37.921589Z","shell.execute_reply":"2021-07-18T13:19:37.928678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport seaborn as sns \nimport matplotlib.pyplot as plt\n\ntrain = pd.read_csv('/kaggle/input/GiveMeSomeCredit/cs-training.csv', index_col=0)\ntest = pd.read_csv(\"/kaggle/input/GiveMeSomeCredit/cs-test.csv\", index_col=0)\n\n#重新命名cols(简化))\nfor df in [train, test]:\n    df.columns = [\"ifPastDue90\", \"creditPercentage\", \"age\", \"pastDue59\", \"debtRatio\", \"income\", \"numLoan\", \"pastDue90\",\n                \"houseLoan\", \"pastDue89\", \"numDependent\"] \n#将两组数据合并\nfull = train.append(test) \nprint(full.info())\nprint(train.shape, test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T13:19:37.931108Z","iopub.execute_input":"2021-07-18T13:19:37.931374Z","iopub.status.idle":"2021-07-18T13:19:38.19902Z","shell.execute_reply.started":"2021-07-18T13:19:37.931349Z","shell.execute_reply":"2021-07-18T13:19:38.198035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 数据清理","metadata":{}},{"cell_type":"code","source":"print (train.isnull().sum(), '\\t', test.isnull().sum()) #查找缺失值\n\ntrain.dropna(subset=[\"numDependent\"], inplace=True) #由于numDependent中缺失元素比较少，删除所有缺失numDependent的行\ntest.numDependent.fillna(test.numDependent.median(), inplace=True) #由于无法删除test中numDependent缺失元素（后面需要足够数据数量进行预测）\n                                                                   #，选择用median填充\n\nprint (train.isnull().sum(), '\\t', test.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2021-07-18T13:19:38.200471Z","iopub.execute_input":"2021-07-18T13:19:38.200772Z","iopub.status.idle":"2021-07-18T13:19:38.252417Z","shell.execute_reply.started":"2021-07-18T13:19:38.200742Z","shell.execute_reply":"2021-07-18T13:19:38.251378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#观察income分布\nsns.boxplot(x=train.income.dropna().values)\n\n#可以看到income数据中存在许多极端outliers\n#我们用median填充缺失数据，减少outliers的影响\ntrain = train.fillna(train.income.median())\ntest[\"income\"] = test[\"income\"].fillna(test.income.median())\nprint (train.isnull().sum())\nprint(test.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2021-07-18T13:19:38.255707Z","iopub.execute_input":"2021-07-18T13:19:38.255988Z","iopub.status.idle":"2021-07-18T13:19:38.446685Z","shell.execute_reply.started":"2021-07-18T13:19:38.255961Z","shell.execute_reply":"2021-07-18T13:19:38.445603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#分离x_train, y_train, x_test\n\nx_train = train.iloc[:, 1:]\ny_train = train[\"ifPastDue90\"].values\nx_test = test.iloc[:, 1:].values\nprint (x_train.shape, y_train.shape, x_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T13:19:38.447855Z","iopub.execute_input":"2021-07-18T13:19:38.448123Z","iopub.status.idle":"2021-07-18T13:19:38.460928Z","shell.execute_reply.started":"2021-07-18T13:19:38.448096Z","shell.execute_reply":"2021-07-18T13:19:38.459823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#数据归一化\nfrom sklearn import preprocessing\n\ntrain_scaler = preprocessing.StandardScaler().fit(x_train)\nprint( train_scaler.mean_ , '\\n'+'-'*50+'\\n', train_scaler.scale_)\nprint('='*50)\ntest_scaler = preprocessing.StandardScaler().fit(x_test)\nprint( test_scaler.mean_ , '\\n'+'-'*50+'\\n', test_scaler.scale_)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T13:19:38.462095Z","iopub.execute_input":"2021-07-18T13:19:38.462353Z","iopub.status.idle":"2021-07-18T13:19:38.660378Z","shell.execute_reply.started":"2021-07-18T13:19:38.462327Z","shell.execute_reply":"2021-07-18T13:19:38.659411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train_scaled = train_scaler.transform(x_train)\nx_test_scaled = test_scaler.transform(x_test)\n\nx_train_scaled.mean(axis=0), x_train_scaled.std(axis=0),  x_test_scaled.mean(axis=0), x_test_scaled.std(axis=0)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-18T13:19:38.661569Z","iopub.execute_input":"2021-07-18T13:19:38.66183Z","iopub.status.idle":"2021-07-18T13:19:38.70089Z","shell.execute_reply.started":"2021-07-18T13:19:38.6618Z","shell.execute_reply":"2021-07-18T13:19:38.700019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 模型比较","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score #使用roc_auc 作为 metric\n\n#用train_test_split分成learn和valid\nx_learn, x_valid, y_learn, y_valid = train_test_split(x_train_scaled, y_train, random_state=0) \n\ncomparison = [] #用于比较最终不同模型的表现","metadata":{"execution":{"iopub.status.busy":"2021-07-18T13:19:38.702967Z","iopub.execute_input":"2021-07-18T13:19:38.70322Z","iopub.status.idle":"2021-07-18T13:19:38.784715Z","shell.execute_reply.started":"2021-07-18T13:19:38.703195Z","shell.execute_reply":"2021-07-18T13:19:38.783706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#逻辑回归\nfrom sklearn.linear_model import LogisticRegressionCV\n\narg, maxauc = 'none', 0\nfor s in ['newton-cg', 'lbfgs', 'liblinear']: #测试不同solver效果\n    model = LogisticRegressionCV(scoring='roc_auc', solver=s) #使用roc_auc作为metric\n    model.fit(x_learn, y_learn)\n    y_pred = model.predict_proba(x_valid)[:,1]\n    score = roc_auc_score(y_valid, y_pred)\n    print(s, score)\n    if score > maxauc:\n        arg, maxauc = s, score\nprint()\nprint(arg, maxauc)\ncomparison.append(['LogisticRegressionCV_'+arg,maxauc]) #可以看到逻辑回归表现不是太好","metadata":{"execution":{"iopub.status.busy":"2021-07-18T13:19:38.786424Z","iopub.execute_input":"2021-07-18T13:19:38.786813Z","iopub.status.idle":"2021-07-18T13:20:24.328874Z","shell.execute_reply.started":"2021-07-18T13:19:38.786773Z","shell.execute_reply":"2021-07-18T13:20:24.327697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#KNN\nfrom sklearn.neighbors import KNeighborsClassifier\nimport itertools\n \narglist = itertools.product(['uniform', 'distance'],['auto', 'ball_tree', 'kd_tree', 'brute']) #尝试每种weight/algorithm组合\nprint(arglist,end='\\n*******\\n')\n\nweight, algorithm, maxauc = '', '', 0\nfor wei, algo in arglist:\n    knn = KNeighborsClassifier(weights=wei, algorithm=algo)\n    knn.fit(x_learn, y_learn)\n    y_pred = knn.predict_proba(x_valid)[:,1]\n    score = roc_auc_score(y_valid, y_pred)\n    print(wei, algo, score)\n    if score > maxauc:\n        weight, algorithm, maxauc = wei, algo, score\nprint()\nprint(weight, algorithm, maxauc)\n\n#可以看出表现略逊于LR，同样不是太好\n#distance brute为最优参数","metadata":{"execution":{"iopub.status.busy":"2021-07-18T13:20:24.33046Z","iopub.execute_input":"2021-07-18T13:20:24.331041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scorelist = []\nn_neighbors, maxauc = -1, 0\nfor k in range(100, 1000+1, 100):\n    knn = KNeighborsClassifier(n_neighbors=k, weights=weight, algorithm=algorithm) #以distance brute调整n_neighbors数量\n    knn.fit(x_learn, y_learn)\n    y_pred = knn.predict_proba(x_valid)[:,1]\n    score = roc_auc_score(y_valid, y_pred)\n    print(k, score)\n    \n    if score > maxauc:\n        n_neighbors, maxauc = k, score\n    scorelist.append(score)\nprint()\nprint(n_neighbors, maxauc)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#不同n-neighbors score可视化\n\nplt.plot(range(100, 1000+1, 100), scorelist)\nplt.title('score - n_neighbors')\nplt.xlabel('n_neighbors')\nplt.ylabel('score(AUC)')\n\n#可以看到在k=300左右时auc得最大值\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#接下来减小step来继续缩小k的范围\nscorelist = []\nn_neighbors, maxauc = -1, 0\nfor k in range(250, 330+1, 10):\n    knn = KNeighborsClassifier(n_neighbors=k, weights=weight, algorithm=algorithm)\n    knn.fit(x_learn, y_learn)\n    y_pred = knn.predict_proba(x_valid)[:,1]\n    score = roc_auc_score(y_valid, y_pred)\n    print(k, score)\n    if score > maxauc:\n        n_neighbors, maxauc = k, score\n    scorelist.append(score)\nprint()\nprint(n_neighbors, maxauc)\ncomparison.append(['KNN_{}_{}_{}'.format(weight,algorithm,n_neighbors),maxauc])\n\n#可以看到在k取260的时候score达到最佳","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#朴素贝叶斯\nfrom sklearn.naive_bayes import GaussianNB\n\ngaussian = GaussianNB()\ngaussian.fit(x_learn, y_learn)\ny_pred = gaussian.predict_proba(x_valid)[:,1]\nscore = roc_auc_score(y_valid, y_pred)\nprint(score)\n\ncomparison.append(['GaussianNB',score])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#决策树\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV\n\ngrid = GridSearchCV(\n    estimator=DecisionTreeClassifier(),\n    param_grid={\n        'criterion':['gini','entropy']\n    },\n    scoring='roc_auc',\n    verbose=3\n)\ngrid.fit(x_learn, y_learn)\n\nfor result in grid.cv_results_:\n    print(result, grid.cv_results_[result])\nprint (grid.best_params_['criterion']) #寻找最佳param\n\ntree = DecisionTreeClassifier(criterion=grid.best_params_['criterion'])\ntree.fit(x_learn, y_learn)\ny_pred = tree.predict_proba(x_valid)[:,1]\nscore = roc_auc_score(y_valid, y_pred)\nprint(score)\ncomparison.append(['DecisionTreeClassifier_{}'.format(grid.best_params_['criterion']),score])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#随机森林\nfrom sklearn.ensemble import RandomForestClassifier\n\ngrid = GridSearchCV(\n    estimator=RandomForestClassifier(),\n    param_grid={\n        'n_estimators':[30,50,80,100,200]\n    },\n    scoring='roc_auc',\n    verbose=3\n)\n\ngrid.fit(x_learn, y_learn)\nfor result in grid.cv_results_:\n    print(result, grid.cv_results_[result])\nprint(grid.best_params_['n_estimators'])\n\nrfc = RandomForestClassifier(n_estimators=grid.best_params_['n_estimators'])\nrfc.fit(x_learn, y_learn)\ny_pred = rfc.predict_proba(x_valid)[:,1]\nscore = roc_auc_score(y_valid, y_pred)\nprint(score)\n\ncomparison.append(['RandomForestClassifier_{}'.format(grid.best_params_['n_estimators']),score])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"comparison #比较不同模型","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#可以看出随机森林在该数据集的表现最好，达到了0.84，远超过其他模型\n#对该模型进行更细致的调参（n_estimators 和 criterion）\n\ngrid = GridSearchCV(\n    estimator=RandomForestClassifier(),\n    param_grid={\n        'n_estimators':np.arange(180, 230, 10),\n        'criterion':['gini', 'entropy']\n    },\n    scoring='roc_auc',\n    verbose=3\n)\n\ngrid.fit(x_learn, y_learn)\nfor result in grid.cv_results_:\n    print(result, grid.cv_results_[result])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfc = RandomForestClassifier(n_estimators=grid.best_params_['n_estimators'],\n                         criterion=grid.best_params_['criterion'])\nrfc.fit(x_learn, y_learn)\ny_pred = rfc.predict_proba(x_valid)[:,1]\nscore = roc_auc_score(y_valid, y_pred)\nprint(score)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 生成结果","metadata":{}},{"cell_type":"code","source":"#使用迭代后求得的最佳参数在train数据集上最后跑一次随机森林\nrfc1 = RandomForestClassifier(n_estimators=grid.best_params_['n_estimators'], criterion=grid.best_params_['criterion'])         \nrfc1.fit(x_train, y_train)\ny_pred = rfc1.predict_proba(x_test)[:,1]\nsample = pd.read_csv('/kaggle/input/GiveMeSomeCredit/sampleEntry.csv')\nsample['Probability'] = y_pred\nsample.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-07-18T14:50:44.274557Z","iopub.execute_input":"2021-07-18T14:50:44.274995Z","iopub.status.idle":"2021-07-18T14:50:44.485514Z","shell.execute_reply.started":"2021-07-18T14:50:44.274957Z","shell.execute_reply":"2021-07-18T14:50:44.484459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}