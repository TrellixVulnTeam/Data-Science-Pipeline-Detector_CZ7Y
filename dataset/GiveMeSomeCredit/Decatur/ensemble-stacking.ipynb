{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-29T12:00:11.47908Z","iopub.execute_input":"2021-06-29T12:00:11.47949Z","iopub.status.idle":"2021-06-29T12:00:11.493112Z","shell.execute_reply.started":"2021-06-29T12:00:11.479457Z","shell.execute_reply":"2021-06-29T12:00:11.491698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1，读入数据","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/GiveMeSomeCredit/cs-training.csv',index_col=0)\ntest = pd.read_csv('/kaggle/input/GiveMeSomeCredit/cs-test.csv',index_col=0)\nsample = pd.read_csv('/kaggle/input/GiveMeSomeCredit/sampleEntry.csv')\n\ntrain.shape, test.shape, sample.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-29T12:00:11.495619Z","iopub.execute_input":"2021-06-29T12:00:11.49646Z","iopub.status.idle":"2021-06-29T12:00:11.919021Z","shell.execute_reply.started":"2021-06-29T12:00:11.496372Z","shell.execute_reply":"2021-06-29T12:00:11.917424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2， 填充缺失值","metadata":{}},{"cell_type":"code","source":"train_default_dict = {} \nfor attr in ['MonthlyIncome', 'NumberOfDependents']:\n    print(attr, end='\\t')\n    median, mean, mode = train[attr].median(), train[attr].mean(), train[attr].mode()\n    mode = mode.values\n    if len(mode) == 1:\n        mode = mode[0]\n    train_default_dict[attr] = [median, mean, mode]\n    print(median, mean, mode)\ntrain_default_dict\n","metadata":{"execution":{"iopub.status.busy":"2021-06-29T12:00:11.920834Z","iopub.execute_input":"2021-06-29T12:00:11.921304Z","iopub.status.idle":"2021-06-29T12:00:11.94812Z","shell.execute_reply.started":"2021-06-29T12:00:11.921267Z","shell.execute_reply":"2021-06-29T12:00:11.946938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_default_dict = {} \nfor attr in ['MonthlyIncome', 'NumberOfDependents']:\n    print(attr, end='\\t')\n    median, mean, mode = test[attr].median(), test[attr].mean(), test[attr].mode()\n    mode = mode.values\n    if len(mode) == 1:\n        mode = mode[0]\n    test_default_dict[attr] = [median, mean, mode]\n    print(median, mean, mode)\ntest_default_dict\n","metadata":{"execution":{"iopub.status.busy":"2021-06-29T12:00:11.950149Z","iopub.execute_input":"2021-06-29T12:00:11.950642Z","iopub.status.idle":"2021-06-29T12:00:11.974856Z","shell.execute_reply.started":"2021-06-29T12:00:11.950593Z","shell.execute_reply":"2021-06-29T12:00:11.973581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.MonthlyIncome.fillna(train_default_dict['MonthlyIncome'][0], inplace=True)\ntest.MonthlyIncome.fillna(train_default_dict['MonthlyIncome'][0], inplace=True)\ntrain.NumberOfDependents.fillna(test_default_dict['NumberOfDependents'][1], inplace=True)\ntest.NumberOfDependents.fillna(test_default_dict['NumberOfDependents'][1], inplace=True)\n\ntrain.isnull().sum(), '*'*50, test.isnull().sum()\n","metadata":{"execution":{"iopub.status.busy":"2021-06-29T12:00:11.979169Z","iopub.execute_input":"2021-06-29T12:00:11.979574Z","iopub.status.idle":"2021-06-29T12:00:12.006511Z","shell.execute_reply.started":"2021-06-29T12:00:11.979531Z","shell.execute_reply":"2021-06-29T12:00:12.004815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3， 分离X_train, y_train, X_test","metadata":{}},{"cell_type":"code","source":"X_train = train.iloc[:,1:].values\ny_train = train.iloc[:,0].values\nX_test = test.iloc[:,1:].values\nX_train.shape, y_train.shape, X_test.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-29T12:00:12.008567Z","iopub.execute_input":"2021-06-29T12:00:12.008966Z","iopub.status.idle":"2021-06-29T12:00:12.042729Z","shell.execute_reply.started":"2021-06-29T12:00:12.008929Z","shell.execute_reply":"2021-06-29T12:00:12.041742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4, 分别归一化X_train, X_test ","metadata":{}},{"cell_type":"code","source":"from sklearn import preprocessing\n\ntrain_scaler = preprocessing.StandardScaler().fit(X_train)\nprint( train_scaler.mean_ , '\\n'+'-'*50+'\\n', train_scaler.scale_)\nprint('='*50)\ntest_scaler = preprocessing.StandardScaler().fit(X_test)\nprint( test_scaler.mean_ , '\\n'+'-'*50+'\\n', test_scaler.scale_)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-29T12:00:12.044031Z","iopub.execute_input":"2021-06-29T12:00:12.044582Z","iopub.status.idle":"2021-06-29T12:00:12.100074Z","shell.execute_reply.started":"2021-06-29T12:00:12.044542Z","shell.execute_reply":"2021-06-29T12:00:12.098812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_scaled = train_scaler.transform(X_train)\nX_test_scaled = test_scaler.transform(X_test)\n\nX_train_scaled.mean(axis=0), X_train_scaled.std(axis=0),   X_test_scaled.mean(axis=0), X_test_scaled.std(axis=0)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-29T12:00:12.101496Z","iopub.execute_input":"2021-06-29T12:00:12.10184Z","iopub.status.idle":"2021-06-29T12:00:12.138388Z","shell.execute_reply.started":"2021-06-29T12:00:12.101807Z","shell.execute_reply":"2021-06-29T12:00:12.137177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5，数据内容不再改动，模型堆叠\n\n* 首先从X_train, y_train划分出训练集X_learn, y_learn; 验证集 X_valid, y_valid\n","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_learn, X_valid, y_learn, y_valid = train_test_split(X_train_scaled, y_train, random_state=0)\nX_learn.shape, X_valid.shape, y_learn.shape, y_valid.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-29T12:00:12.139521Z","iopub.execute_input":"2021-06-29T12:00:12.139841Z","iopub.status.idle":"2021-06-29T12:00:12.17714Z","shell.execute_reply.started":"2021-06-29T12:00:12.139812Z","shell.execute_reply":"2021-06-29T12:00:12.176031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#使用roc_auc 作为 metric\nfrom sklearn.metrics import roc_auc_score","metadata":{"execution":{"iopub.status.busy":"2021-06-29T12:00:12.178474Z","iopub.execute_input":"2021-06-29T12:00:12.178771Z","iopub.status.idle":"2021-06-29T12:00:12.184577Z","shell.execute_reply.started":"2021-06-29T12:00:12.178743Z","shell.execute_reply":"2021-06-29T12:00:12.183247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* 参考模型堆叠\n* 参数来自于另一个notebook","metadata":{}},{"cell_type":"markdown","source":"## 5.1 试水","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import StackingClassifier\nimport lightgbm as lgb\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\nestimators = [\n    ('lgb', lgb.LGBMClassifier(n_estimators=54)),\n    ('rfc', RandomForestClassifier(n_estimators=200)),\n    ('mlp', MLPClassifier(hidden_layer_sizes=2)),\n    ('knn', KNeighborsClassifier(n_neighbors=320, weights='distance', algorithm='auto'))\n]","metadata":{"execution":{"iopub.status.busy":"2021-06-29T12:00:12.186743Z","iopub.execute_input":"2021-06-29T12:00:12.187265Z","iopub.status.idle":"2021-06-29T12:00:12.207106Z","shell.execute_reply.started":"2021-06-29T12:00:12.187228Z","shell.execute_reply":"2021-06-29T12:00:12.205513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.2 对stackClf调参","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nbest_l, best_pt, maxauc = 0, 'none', 0\nfor hid_lay_siz in [1,2,3,4,5]:\n    for pass_throu in [True, False]:\n        reg = StackingClassifier(\n            estimators=estimators,\n            final_estimator=MLPClassifier(\n                hidden_layer_sizes=hid_lay_siz,\n                random_state=0\n            ),\n            passthrough=pass_throu,\n            verbose=3\n        )\n\n        reg.fit(X_learn, y_learn)\n        y_pred = reg.predict_proba(X_valid)[:,1]\n        score = roc_auc_score(y_valid, y_pred)\n        print(score)\n        \n        if score > maxauc:\n            best_l, best_pt, maxauc = hid_lay_siz, pass_throu, score\nprint()\nprint(best_l, best_pt, maxauc)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-29T12:08:21.99908Z","iopub.execute_input":"2021-06-29T12:08:21.99952Z","iopub.status.idle":"2021-06-29T12:08:37.202536Z","shell.execute_reply.started":"2021-06-29T12:08:21.999485Z","shell.execute_reply":"2021-06-29T12:08:37.199095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reg = StackingClassifier(\n    estimators=estimators,\n    final_estimator=MLPClassifier(\n        hidden_layer_sizes=best_l,\n        random_state=0\n    ),\n    passthrough=best_pt,\n    verbose=3\n)\n\n\nreg.fit(X_train, y_train)\ny_pred = reg.predict_proba(X_test)[:,1]\n","metadata":{"execution":{"iopub.status.busy":"2021-06-29T12:00:12.307805Z","iopub.status.idle":"2021-06-29T12:00:12.3086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6 生成提交文件","metadata":{}},{"cell_type":"code","source":"sample = pd.read_csv('../input/GiveMeSomeCredit/sampleEntry.csv')\nsample","metadata":{"execution":{"iopub.status.busy":"2021-06-29T12:00:12.309918Z","iopub.status.idle":"2021-06-29T12:00:12.310907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample['Probability'] = y_pred\nsample.to_csv('./submit.csv',index=False)\nreload = pd.read_csv('./submit.csv')\nreload\n","metadata":{"execution":{"iopub.status.busy":"2021-06-29T12:00:12.312282Z","iopub.status.idle":"2021-06-29T12:00:12.313117Z"},"trusted":true},"execution_count":null,"outputs":[]}]}