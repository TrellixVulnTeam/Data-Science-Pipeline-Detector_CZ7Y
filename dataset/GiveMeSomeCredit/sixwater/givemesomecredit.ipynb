{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-27T12:34:06.17483Z","iopub.execute_input":"2021-06-27T12:34:06.175183Z","iopub.status.idle":"2021-06-27T12:34:06.185787Z","shell.execute_reply.started":"2021-06-27T12:34:06.175108Z","shell.execute_reply":"2021-06-27T12:34:06.184743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 七步流程\n\n1. 定义问题\n2. 获取训练数据和测试数据\n3. 整理、准备、清洗数据\n4. 分析、发现模式、探索数据\n5. 建模、预测、求解问题\n6. 可视化、报告、呈现问题求解步骤和最终结论\n7. 提交","metadata":{}},{"cell_type":"markdown","source":"# 1. 定义问题\n\n基于客户数据，通过预测客户未来两年是否会陷入财务危机的概率来改善银行信用评分的质量。\n","metadata":{}},{"cell_type":"markdown","source":"**导包**","metadata":{}},{"cell_type":"code","source":"#加载包\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-06-27T12:34:06.187435Z","iopub.execute_input":"2021-06-27T12:34:06.187712Z","iopub.status.idle":"2021-06-27T12:34:06.605445Z","shell.execute_reply.started":"2021-06-27T12:34:06.187684Z","shell.execute_reply":"2021-06-27T12:34:06.604231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2.获取训练数据","metadata":{}},{"cell_type":"code","source":"data_train = pd.read_csv('../input/givemesc/cs-training.csv')","metadata":{"execution":{"iopub.status.busy":"2021-06-27T12:34:06.606881Z","iopub.execute_input":"2021-06-27T12:34:06.607279Z","iopub.status.idle":"2021-06-27T12:34:06.767245Z","shell.execute_reply.started":"2021-06-27T12:34:06.607236Z","shell.execute_reply":"2021-06-27T12:34:06.766261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. 整理、准备、清洗数据\n## 3.1. 查看数据","metadata":{}},{"cell_type":"code","source":"data_train.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-27T12:34:06.76879Z","iopub.execute_input":"2021-06-27T12:34:06.769215Z","iopub.status.idle":"2021-06-27T12:34:06.792263Z","shell.execute_reply.started":"2021-06-27T12:34:06.76917Z","shell.execute_reply":"2021-06-27T12:34:06.791298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**查看Data Dictionary.xls文件可知，各数据含义如下所示：**","metadata":{}},{"cell_type":"markdown","source":"|                变量名                |                    定义                    |     数据类型      |\n| :----------------------------------: | :----------------------------------------: | :---------------: |\n|      SeriousDlqin2yrs（目标值）      | 是否有超过90天或更长时间逾期未还的不良行为 | Y/N（0为好1为坏） |\n| RevolvingUtilizationOfUnsecuredLines |                可用额度比值                |    percentage     |\n|                 age                  |                    年龄                    |      integer      |\n| NumberOfTime30-59DaysPastDueNotWorse |              逾期30-59天笔数               |      integer      |\n|              DebtRatio               |  还款率(每月偿还债务，赡养费，生活费用).   |    percentage     |\n|            MonthlyIncome             |                   月收入                   |       real        |\n|   NumberOfOpenCreditLinesAndLoans    |                  信贷数量                  |      integer      |\n|       NumberOfTimes90DaysLate        |                逾期90天笔数                |      integer      |\n|     NumberRealEstateLoansOrLines     |               固定资产贷款量               |      integer      |\n| NumberOfTime60-89DaysPastDueNotWorse |              逾期60-89天笔数               |      integer      |\n|          NumberOfDependents          |                  家属数量                  |      integer      |","metadata":{}},{"cell_type":"code","source":"data_train.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T12:34:06.793585Z","iopub.execute_input":"2021-06-27T12:34:06.793874Z","iopub.status.idle":"2021-06-27T12:34:06.816165Z","shell.execute_reply.started":"2021-06-27T12:34:06.793842Z","shell.execute_reply":"2021-06-27T12:34:06.815131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-27T12:34:06.820461Z","iopub.execute_input":"2021-06-27T12:34:06.820766Z","iopub.status.idle":"2021-06-27T12:34:06.921085Z","shell.execute_reply.started":"2021-06-27T12:34:06.820738Z","shell.execute_reply":"2021-06-27T12:34:06.920034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**查看哪些变量具有缺失值**","metadata":{}},{"cell_type":"code","source":"data_train.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-27T12:34:06.924668Z","iopub.execute_input":"2021-06-27T12:34:06.924972Z","iopub.status.idle":"2021-06-27T12:34:06.935412Z","shell.execute_reply.started":"2021-06-27T12:34:06.92494Z","shell.execute_reply":"2021-06-27T12:34:06.934418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**可以看出以下结论：**\n1. 数据缺失值较少\n2. Unamed: 0列为序号，可以直接删去\n3. NumberOfDependents缺失值较少，在训练过程中可以直接删去，测试集时可以使用众数填充\n4. MonthlyIncome缺失值较多，可以大量填充","metadata":{}},{"cell_type":"markdown","source":"## 3.2. 数据清洗\n### 3.2.1. 直接删去序号列","metadata":{}},{"cell_type":"code","source":"data_train=data_train.drop([\"Unnamed: 0\"],axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T12:34:06.936919Z","iopub.execute_input":"2021-06-27T12:34:06.93734Z","iopub.status.idle":"2021-06-27T12:34:06.951866Z","shell.execute_reply.started":"2021-06-27T12:34:06.937296Z","shell.execute_reply":"2021-06-27T12:34:06.950396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.2.2. 随机森林填补MonthlyIncome缺失值","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\ndef fill_missing(data, to_fill):\n    df = data.copy()\n    columns = [*df.columns]\n    columns.remove(to_fill)\n    \n    # 移除有缺失值的列\n    columns.remove('NumberOfDependents')\n    X = df.loc[:, columns]\n    y = df.loc[:, to_fill]\n    X_train = X.loc[df[to_fill].notnull()]\n    y_train = y.loc[df[to_fill].notnull()]\n    X_pred = X.loc[df[to_fill].isnull()]\n    rfr = RandomForestRegressor(random_state=22, n_estimators=200, max_depth=3, n_jobs=-1)\n    rfr.fit(X_train, y_train)\n    y_pred = rfr.predict(X_pred).round()\n    df.loc[df[to_fill].isnull(), to_fill] = y_pred\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-06-27T12:34:06.953432Z","iopub.execute_input":"2021-06-27T12:34:06.953767Z","iopub.status.idle":"2021-06-27T12:34:07.083049Z","shell.execute_reply.started":"2021-06-27T12:34:06.95369Z","shell.execute_reply":"2021-06-27T12:34:07.082063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.2.3. 直接删除'NumberOfDependents'","metadata":{}},{"cell_type":"code","source":"data_train = fill_missing(data_train, 'MonthlyIncome')\ndata_train.dropna(inplace=True)\ndata_train.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-27T12:34:07.084685Z","iopub.execute_input":"2021-06-27T12:34:07.085023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.2.4. 异常值处理\nage 字段中包含有为 0 的值，通常认为该值为异常值，查看数据可以发现仅有一条数据年龄为0，因此可以直接删除","metadata":{}},{"cell_type":"code","source":"data_train = data_train[data_train['age'] > 0]\n\nimport matplotlib.pyplot as plt\ncolumns = ['NumberOfTime30-59DaysPastDueNotWorse',\n          'NumberOfTime60-89DaysPastDueNotWorse',\n          'NumberOfTimes90DaysLate']\ndata_train.loc[:, columns].plot.box(vert=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"从业务上考虑，不应当出现这样的高的次数，这里同样删除掉这些异常数据","metadata":{}},{"cell_type":"code","source":"for col in columns:\n    data_train = data_train.loc[data_train[col] < 90]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**封装一个数据处理函数用于之后处理测试数据**","metadata":{}},{"cell_type":"code","source":"def deal_with_data(df_ori):\n    df=df_ori.copy()\n    df=df.drop([\"Unnamed: 0\"],axis=1)\n   # print(df.shape)\n    x=df['NumberOfDependents'].mode()[0]\n    df['NumberOfDependents']=df['NumberOfDependents'].fillna(x)\n   # print(df.shape)\n    #df.dropna(how='all',inplace=True)\n    df = fill_missing(df, 'MonthlyIncome')\n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. 分析、发现模式、探索数据\n## 4.1. 查看年龄分布","metadata":{}},{"cell_type":"code","source":"data_train['age'].plot.hist(bins=30);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.2. 使用小于 99% 的分位数的数据查看收入分布","metadata":{}},{"cell_type":"code","source":"income = data_train['MonthlyIncome']\nincome.loc[income < 23334].plot.hist(bins=50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.3. 查看变量之间的相关性","metadata":{}},{"cell_type":"code","source":"corr = data_train.corr()\nplt.subplots(figsize=(12, 12))\nsns.heatmap(corr, annot=True, vmax=1, square=True, cmap='Blues')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5.建模、预测、求解问题\n## 5.1. 数据分箱\n### 5.1.1. 定义数据分箱函数，查找最优分箱","metadata":{}},{"cell_type":"code","source":"# 根据woe以及IV值定义分箱函数\nimport numpy as np\nimport pandas as pd\nimport scipy\n\ndef auto_bin(DF, X, Y, n=5, iv=True, detail=False,q=20):\n    \"\"\"\n    自动最优分箱函数，基于卡方检验的分箱\n\n    参数：\n    DF: DataFrame 数据框\n    X: 需要分箱的列名\n    Y: 分箱数据对应的标签 Y 列名\n    n: 保留分箱个数\n    iv: 是否输出执行过程中的 IV 值\n    detail: 是否输出合并的细节信息\n    q: 初始分箱的个数\n\n    区间为前开后闭 (]\n\n    返回值：\n\n    \"\"\"\n\n\n    # DF = df_train\n    # X = \"age\"\n    # Y = \"SeriousDlqin2yrs\"\n\n    DF = DF[[X,Y]].copy()\n\n    # 按照等频对需要分箱的列进行分箱,cut为灯具分箱,qcut为等频分箱\n    DF[\"qcut\"],bins = pd.qcut(DF[X], retbins=True, q=q, duplicates=\"drop\")\n    # 统计每个分段 0，1的数量\n    coount_y0 = DF.loc[DF[Y]==0].groupby(by=\"qcut\")[Y].count()\n    coount_y1 = DF.loc[DF[Y]==1].groupby(by=\"qcut\")[Y].count()\n    # num_bins值分别为每个区间的上界，下界，0的频次，1的频次\n    num_bins = [*zip(bins,bins[1:],coount_y0,coount_y1)]\n\n    # 定义计算 woe 的函数\n    def get_woe(num_bins):\n        # 通过 num_bins 数据计算 woe\n        columns = [\"min\",\"max\",\"count_0\",\"count_1\"]\n        df = pd.DataFrame(num_bins,columns=columns)\n\n        df[\"total\"] = df.count_0 + df.count_1\n        df[\"percentage\"] = df.total / df.total.sum()\n        df[\"bad_rate\"] = df.count_1 / df.total\n        df[\"woe\"] = np.log((df.count_0/df.count_0.sum()) /\n                           (df.count_1/df.count_1.sum()))\n        return df\n\n    # 创建计算 IV 值函数\n    def get_iv(bins_df):\n        rate = ((bins_df.count_0/bins_df.count_0.sum()) -\n                (bins_df.count_1/bins_df.count_1.sum()))\n        IV = np.sum(rate * bins_df.woe)\n        return IV\n\n\n    # 确保每个分组的数据都包含有 0 和 1\n    for i in range(20): # 初始分组不会超过20\n        # 如果是第一个组没有 0 或 1，向后合并\n        if 0 in num_bins[0][2:]:\n            num_bins[0:2] = [(\n                num_bins[0][0],\n                num_bins[1][1],\n                num_bins[0][2]+num_bins[1][2],\n                num_bins[0][3]+num_bins[1][3])]\n            continue\n\n        # 其他组出现没有 0 或 1，向前合并\n        for i in range(len(num_bins)):\n            if 0 in num_bins[i][2:]:\n                num_bins[i-1:i+1] = [(\n                    num_bins[i-1][0],\n                    num_bins[i][1],\n                    num_bins[i-1][2]+num_bins[i][2],\n                    num_bins[i-1][3]+num_bins[i][3])]\n                break\n        # 循环结束都没有出现则提前结束外圈循环\n        else:\n            break\n\n    # 重复执行循环至分箱保留 n 组：\n    while len(num_bins) > n:\n        # 获取 num_bins 两两之间的卡方检验的置信度（或卡方值）\n        pvs = []\n        for i in range(len(num_bins)-1):\n            x1 = num_bins[i][2:]\n            x2 = num_bins[i+1][2:]\n            # 0 返回 chi2 值，1 返回 p 值。\n            pv = scipy.stats.chi2_contingency([x1,x2])[1]\n            # chi2 = scipy.stats.chi2_contingency([x1,x2])[0]\n            pvs.append(pv)\n\n        # 通过 p 值进行处理。合并 p 值最大的两组\n        i = pvs.index(max(pvs))\n        num_bins[i:i+2] = [(\n            num_bins[i][0],\n            num_bins[i+1][1],\n            num_bins[i][2]+num_bins[i+1][2],\n            num_bins[i][3]+num_bins[i+1][3])]\n\n        # 打印合并后的分箱信息\n        bins_df = get_woe(num_bins)\n        if iv:\n            print(f\"{X} 分{len(num_bins):2}组 IV 值: \",get_iv(bins_df))\n        if detail:\n            print(bins_df)\n    print(\"\\n\".join(map(lambda x:f\"{x:.16f}\",pvs)))\n    # 返回分组后的信息\n    return get_woe(num_bins)#, get_iv(bins_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"划分测试集和训练集","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX = data_train.iloc[:, 1:]\ny = data_train.iloc[:, 0]\nX_train, X_vali, y_train, y_vali = train_test_split(X, y, test_size=0.3, random_state=0)\ndf_train = pd.concat([y_train, X_train], axis=1)\ndf_vali = pd.concat([y_vali, X_vali], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"对每一个分组进行分析，选择合适的分箱数","metadata":{}},{"cell_type":"code","source":"df_train.columns\n\n# 不能使用自动分享的变量\nhand_bins = {\"NumberOfTime30-59DaysPastDueNotWorse\":[0,1,2,13],\n             \"NumberOfTimes90DaysLate\":[0,1,2,17],\n             \"NumberRealEstateLoansOrLines\":[0,1,2,4,54],\n             \"NumberOfTime60-89DaysPastDueNotWorse\":[0,1,2,8]}\n\n# 手动额按成分享数量的添加\nauto_col_bins = {\"RevolvingUtilizationOfUnsecuredLines\":5,\n                 \"age\":5,\n                 \"DebtRatio\":5,\n                 \"MonthlyIncome\":6,\n                 \"NumberOfOpenCreditLinesAndLoans\":4,\n                 \"NumberOfDependents\":3}\n\n# 保证区间覆盖使用 np.inf 替换最大值 -np.inf 替换最小值\nhand_bins = {k:[-np.inf,*v[1:-1],np.inf] for k,v in hand_bins.items()}\n\n# 用于确定最优分箱的个数和区间 \nage_bins_df = auto_bin(df_train, \"age\", \"SeriousDlqin2yrs\", n=5, iv=True,detail=False,q=20)\nage_bins_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 用来保存每个分组的分箱数据 \nbins_of_col = {}\n# 生成自动分箱的分箱区间和分箱后的 IV 值 \nfor col in auto_col_bins:\n    print(col)\n    bins_df = auto_bin(df_train, col, \"SeriousDlqin2yrs\", n=auto_col_bins[col], iv=False, detail=False, q=20) \n    bins_list = list(sorted(set(bins_df[\"min\"]).union(bins_df[\"max\"])))\n    # 保证区间覆盖使用 np.inf 替换最大值 -np.inf 替换最小值\n    bins_list[0], bins_list[-1] = -np.inf, np.inf\n    bins_of_col[col] = bins_list\nbins_of_col","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 合并手动分箱数据 \nbins_of_col.update(hand_bins)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5.1.2. 变量筛选","metadata":{}},{"cell_type":"code","source":"# 计算分箱数据的 IV 值\ndef get_iv(df,col,y,bins):\n    df = df[[col,y]].copy()\n    df[\"cut\"] = pd.cut(df[col],bins)\n    bins_df = df.groupby(\"cut\")[y].value_counts().unstack()\n    bins_df[\"woe\"] = np.log((bins_df[0] / bins_df[0].sum()) /\n                     (bins_df[1] / bins_df[1].sum()))\n    iv = np.sum((bins_df[0] / bins_df[0].sum() -\n          bins_df[1] / bins_df[1].sum())*bins_df.woe)\n    return iv ,bins_df\n\n# 保存 IV 值信息 \ninfo_values = {}\n# 保存 woe 信息 \nwoe_values = {}\nfor col in bins_of_col:\n    iv_woe = get_iv(df_train, col, \"SeriousDlqin2yrs\", bins_of_col[col])\n    info_values[col], woe_values[col] = iv_woe","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plt_iv(info_values):\n    keys,values = zip(*info_values.items())\n    nums = range(len(keys)) \n    plt.barh(nums,values) \n    plt.yticks(nums,keys)\n    for i, v in enumerate(values):\n        plt.text(v, i-.2, f\"{v:.2f}\")\nplt_iv(info_values)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bins_of_col","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"可以看出 NumberRealEstateLoansOrLines 和 NumberOfDependents 变量的 IV 值明显较低，所 以予以删除。DebtRatio、MonthlyIncome、NumberOfOpenCreditLinesAndLoans 等变量可以考虑删 除也可以予以保留。","metadata":{}},{"cell_type":"markdown","source":"## 5.2. Logistic回归\n### 5.2.1 WOE转换\n通过生成的分箱和 WOE 数据","metadata":{}},{"cell_type":"code","source":"model_woe = pd.DataFrame(index=df_train.index)\nfor col in bins_of_col:\n    model_woe[col] = pd.cut(df_train[col],bins_of_col[col]).map(woe_values[col][\"woe\"])\nmodel_woe[\"SeriousDlqin2yrs\"] = df_train[\"SeriousDlqin2yrs\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5.2.2. 构建回归模型","metadata":{}},{"cell_type":"code","source":"# 直接调用statsmodels包来实现逻辑回归\nimport statsmodels.api as sm\n\ndata = model_woe.copy()\n# 设置因变量\nendog = data['SeriousDlqin2yrs']\nX = data.drop([\"SeriousDlqin2yrs\",\n               \"NumberRealEstateLoansOrLines\",\n               \"NumberOfDependents\"],axis=1)\n# 设置自变量\nexog = sm.add_constant(X)\nlogit = sm.Logit(endog,exog)\nresult = logit.fit()\nresult.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. 可视化、报告、呈现问题求解步骤和最终结论\n## 6.1. 模型检验","metadata":{}},{"cell_type":"code","source":"vali_woe = pd.DataFrame(index=df_vali.index)\nfor col in bins_of_col:\n    vali_woe[col] = pd.cut(df_vali[col],bins_of_col[col]).map(woe_values[col][\"woe\"])\nvali_woe[\"SeriousDlqin2yrs\"] = df_vali[\"SeriousDlqin2yrs\"]\nvali_Y = vali_woe['SeriousDlqin2yrs']\nvali_X = vali_woe.drop([\"SeriousDlqin2yrs\",\n                        \"NumberRealEstateLoansOrLines\",\n                        \"NumberOfDependents\"],axis=1)\nvali_exog = sm.add_constant(vali_X)\nvali_proba = result.predict(vali_exog)\nvali_proba_df = pd.DataFrame(vali_proba,columns=[1]) \nvali_proba_df.insert(0,0,1-vali_proba_df)\n\nimport scikitplot as skplt\n# 预测结果为对应 1 的概率，转换为数组用于绘图 \n\nskplt.metrics.plot_roc(vali_Y,\n                       vali_proba_df,\n                       plot_micro=False, plot_macro=False);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6.2. 预测测试数据\n### 6.2.1. 读入测试数据","metadata":{}},{"cell_type":"code","source":"data_test=pd.read_csv('../input/givemesc/cs-test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"首先删除空列（目标列）SeriousDlqin2yrs","metadata":{}},{"cell_type":"code","source":"data_test=data_test.drop(['SeriousDlqin2yrs'],axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"查看测试数据信息","metadata":{}},{"cell_type":"code","source":"data_test.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"处理测试数据","metadata":{}},{"cell_type":"code","source":"data_test=deal_with_data(data_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"检查测试数据空值是否都被填充","metadata":{}},{"cell_type":"code","source":"data_test.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 6.2. 对测试数据进行分箱，并计算WOE值","metadata":{}},{"cell_type":"code","source":"test = pd.DataFrame(index=data_test.index)\nfor col in bins_of_col:\n    test[col] = pd.cut(data_test[col],bins_of_col[col]).map(woe_values[col][\"woe\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 6.3. 根据模型预测","metadata":{}},{"cell_type":"code","source":"test_X = test.drop([\"NumberRealEstateLoansOrLines\",\n                        \"NumberOfDependents\"],axis=1)\ntest_exog = sm.add_constant(test_X)\ntest_proba = result.predict(test_exog)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ans=pd.DataFrame(index=test.index,columns=['Id','Probability'])\nans['Id']=ans.index+1\nans['Probability']=test_proba\nans","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7. 提交结果","metadata":{}},{"cell_type":"code","source":"ans.to_csv(\"./submission.csv\",index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}