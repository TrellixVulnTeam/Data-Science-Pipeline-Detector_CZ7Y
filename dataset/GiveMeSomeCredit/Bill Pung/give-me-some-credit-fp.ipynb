{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Table of Contents\n* Problem Analysis\n* Exploratory Data Analysis\n* Data Preprocessing\n* Baseline Model Performance\n* Hyperparameter Tuning\n* Model Results & Interpretation","metadata":{}},{"cell_type":"markdown","source":"## Questions & Answers\n- **Tell us how you validate your model, which, and why you chose such evaluation technique(s)**\n    * Validation is done on a held-out test set (30% of dataset), to prevent data leakage.\n    * Given that the evaluation metric chosen for the competition is AUCROC, I used the same evaluation metric for validation on kfold cross validation. For reasons explained below, this is a good metric to use.\n- **What is AUC? Why do you think AUC was used as the evaluation metric for such a problem? What are other metrics that you think would also be suitable for this competition?**\n    * AUC is the area under the receiver operating characteristic curve, which **measures the ability of a classifier to distinguish between classes across different threshold values**.\n    * Poor metrics to use include accuracy, which is unsuitable due to the imbalanced nature of the target variable (baseline model predicting 0s will get 94% accuracy).\n    * For this problem, false negatives are more severe than false positives, as it is more detrimental to the bank if a customer defaults, than for it to lose a customer that would not have defaulted. Also, a human can be in the loop to verify positive cases, hence the model can act as an initial filter for possible defaulters. As such, **recall** is more important than precision.\n    * However, using only recall will cause the model to be imprecise. To balance precision with recall, we can use the **F-measure**, include the F1 score, which weights precision and recall equally. Since recall is more important than precision, we can use **F-Beta** for Beta > 1, e.g. Beta = 2.\n    * Varying the classifier's threshold value allows us to tradeoff precision with recall and vice versa, and **AUCROC** is a metric that captures this notion, ranging from 0.5 (baseline model) to 1 (higher is better). Hence, we can plot the ROC curve and select for a threshold where the model's recall is sufficiently high for our business case, while remaining sufficiently precise.\n- **What insight(s) do you have from your model? What is your preliminary analysis of the given dataset?**\n    * Detailed analysis shown in notebook below\n- **Can you get into the top 100 of the private leaderboard, or even higher?**\n    * Validation AUCROC: 86.6%, Test set (30% of dataset) AUCROC: 86.6%, Kaggle AUCROC: 86.083%\n    * Kaggle performance: **Public: 141 / 924 (top 15%)**, Private: 519 / 924 (top 56%)","metadata":{}},{"cell_type":"markdown","source":"# Problem Analysis\n\n## Problem Statment\nBanks play a crucial role in market economies. They decide who can get finance and on what terms and can make or break investment decisions. For markets and society to function, individuals and companies need access to credit. \n\nCredit scoring algorithms, which make a guess at the probability of default, are the method banks use to determine whether or not a loan should be granted. This competition requires participants to improve on the state of the art in credit scoring, by **predicting the probability that somebody will experience financial distress in the next two years**.\n\nThe goal of this competition is to **build a model that borrowers can use to help make the best financial decisions**. Historical data are provided on 250,000 borrowers.\n\n## Key Observations\n\n1. Goal is for borrowers to understand what they can do to improve their credit score. Hence, **model explainability is important**, where interpretable model outputs give actionable insights for borrowers.\n2. Problem is a **binary classification** problem of whether customer will default in the next 2 years.\n3. From the bank's perspective: **False negatives are more costly than false positives**, as they lose more money and create negative social impact when customers default on their loans (a la Global Financial Crisis, 2008), hence outweighing the loss of interest earned from customer loans. Hence **Recall > Precision in importance**. To mitigate, this model can have a human-in-the-loop to process credit application rejections to combat unfairness complaints.\n4. As model as broader societal implications (rich get richer), **model fairness is of utmost importance**. Hence, using features that can be deemed unfair, e.g. gender, religion, nationality, age, should be minimised.","metadata":{}},{"cell_type":"code","source":"import time\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport sklearn\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import RobustScaler, PowerTransformer\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score, RandomizedSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import roc_auc_score, confusion_matrix, classification_report, plot_roc_curve\n\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.pipeline import make_pipeline\n\nfrom xgboost import XGBClassifier\n\nimport shap\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nsns.set_theme(style=\"darkgrid\")\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nroot_folder = '/kaggle/input/GiveMeSomeCredit/'","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2021-12-04T16:06:15.467209Z","iopub.execute_input":"2021-12-04T16:06:15.467868Z","iopub.status.idle":"2021-12-04T16:06:15.482933Z","shell.execute_reply.started":"2021-12-04T16:06:15.467828Z","shell.execute_reply":"2021-12-04T16:06:15.48209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory Data Analysis","metadata":{}},{"cell_type":"markdown","source":"## Loading & Visualizing data","metadata":{}},{"cell_type":"markdown","source":"10 features, 150k observations: **Moderate sized dataset with few features** (more long than wide)","metadata":{}},{"cell_type":"code","source":"# removing unused first (index) column\ndf = pd.read_csv(root_folder+'cs-training.csv').iloc[:,1:]\ndf","metadata":{"execution":{"iopub.status.busy":"2021-12-04T16:06:15.484967Z","iopub.execute_input":"2021-12-04T16:06:15.485608Z","iopub.status.idle":"2021-12-04T16:06:15.816048Z","shell.execute_reply.started":"2021-12-04T16:06:15.485559Z","shell.execute_reply":"2021-12-04T16:06:15.815089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_variable = \"SeriousDlqin2yrs\"","metadata":{"execution":{"iopub.status.busy":"2021-12-04T16:06:15.817526Z","iopub.execute_input":"2021-12-04T16:06:15.817952Z","iopub.status.idle":"2021-12-04T16:06:15.824587Z","shell.execute_reply.started":"2021-12-04T16:06:15.817902Z","shell.execute_reply":"2021-12-04T16:06:15.823058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Dictionary\nFeatures can be classified into:\n   1. Historical late repayments in the last 2 years(3 window periods of 30-59, 60-89, >=90)\n   2. Financial Obligations (NumberOfOpenCreditLinesAndLoans, NumberOfDependents, DebtRatio, RevolvingUtilizationOfUnsecuredLines)\n   3. Financial Capabilities (MonthlyIncome)\n   4. Demographics (Age)\n\n| Variable Name                        | Description                                                                                                                                              | Type       |\n| ------------------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------- |\n| SeriousDlqin2yrs                     | Person experienced 90 days past due delinquency or worse                                                                                                 | Y/N        |\n| RevolvingUtilizationOfUnsecuredLines | Total balance on credit cards and personal lines of credit except real estate and no installment debt like car loans divided by the sum of credit limits | percentage |\n| age                                  | Age of borrower in years                                                                                                                                 | integer    |\n| NumberOfTime30-59DaysPastDueNotWorse | Number of times borrower has been 30-59 days past due but no worse in the last 2 years.                                                                  | integer    |\n| DebtRatio                            | Monthly debt payments, alimony,living costs divided by monthy gross income                                                                               | percentage |\n| MonthlyIncome                        | Monthly income                                                                                                                                           | real       |\n| NumberOfOpenCreditLinesAndLoans      | Number of Open loans (installment like car loan or mortgage) and Lines of credit (e.g. credit cards)                                                     | integer    |\n| NumberOfTimes90DaysLate              | Number of times borrower has been 90 days or more past due.                                                                                              | integer    |\n| NumberRealEstateLoansOrLines         | Number of mortgage and real estate loans including home equity lines of credit                                                                           | integer    |\n| NumberOfTime60-89DaysPastDueNotWorse | Number of times borrower has been 60-89 days past due but no worse in the last 2 years.                                                                  | integer    |\n| NumberOfDependents                   | Number of dependents in family excluding themselves (spouse, children etc.)                                                                              | integer    |\n\n","metadata":{}},{"cell_type":"markdown","source":"## Visualizing distributions of features","metadata":{}},{"cell_type":"markdown","source":"Initial exploration on the dependent variables, to get an intuition on what models will perform well on this problem, and on how to prepare the dataset for training.","metadata":{}},{"cell_type":"code","source":"df.describe(percentiles=[.25,.5,.75,.9,.95,.99,.999])","metadata":{"execution":{"iopub.status.busy":"2021-12-04T16:06:15.826099Z","iopub.execute_input":"2021-12-04T16:06:15.826691Z","iopub.status.idle":"2021-12-04T16:06:15.946252Z","shell.execute_reply.started":"2021-12-04T16:06:15.826637Z","shell.execute_reply":"2021-12-04T16:06:15.945369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"g = sns.PairGrid(df.sample(150), diag_sharey=False)\ng.map_upper(sns.scatterplot, s=15)\ng.map_lower(sns.kdeplot)\ng.map_diag(sns.kdeplot, lw=2);","metadata":{"execution":{"iopub.status.busy":"2021-12-04T16:06:15.948555Z","iopub.execute_input":"2021-12-04T16:06:15.948832Z","iopub.status.idle":"2021-12-04T16:06:48.194126Z","shell.execute_reply.started":"2021-12-04T16:06:15.9488Z","shell.execute_reply":"2021-12-04T16:06:48.192867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.kdeplot(data=df.sample(150), x=\"RevolvingUtilizationOfUnsecuredLines\", y=target_variable, \n            thresh=.1)","metadata":{"execution":{"iopub.status.busy":"2021-12-04T16:06:48.195608Z","iopub.execute_input":"2021-12-04T16:06:48.195936Z","iopub.status.idle":"2021-12-04T16:06:48.68246Z","shell.execute_reply.started":"2021-12-04T16:06:48.195893Z","shell.execute_reply":"2021-12-04T16:06:48.681376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.boxplot(x=\"NumberOfDependents\", y=\"age\",\n            hue=\"SeriousDlqin2yrs\", palette=[\"m\", \"g\"],\n            data=df)","metadata":{"execution":{"iopub.status.busy":"2021-12-04T16:06:48.683944Z","iopub.execute_input":"2021-12-04T16:06:48.684279Z","iopub.status.idle":"2021-12-04T16:06:49.485352Z","shell.execute_reply.started":"2021-12-04T16:06:48.684234Z","shell.execute_reply":"2021-12-04T16:06:49.484678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Checking target variable distribution\n\nLooking at the distribution of the target variable, this problem is a binary classification problem of classes 0 or 1 denoting if cusomter will default in 2 years, with class 1 being the minority at 6.684%\n\nHence, this is an **imbalanced learning problem**","metadata":{}},{"cell_type":"code","source":"ax = sns.countplot(x=target_variable, data=df)\nplt.title('Distribution of target variable')\nplt.xlabel(target_variable)\nplt.ylabel('Frequency')\n\nfor p in ax.patches:\n        ax.annotate('{:,}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+50))","metadata":{"execution":{"iopub.status.busy":"2021-12-04T16:06:49.486373Z","iopub.execute_input":"2021-12-04T16:06:49.48706Z","iopub.status.idle":"2021-12-04T16:06:49.738561Z","shell.execute_reply.started":"2021-12-04T16:06:49.48702Z","shell.execute_reply":"2021-12-04T16:06:49.737679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Checking for NAs\nImportance: Many learning algorithms cannot handle missing values, hence we need to handle missing values by dropping these observations, or imputing them. Imputing will increase the bias in our model, but dropping too many observations leads to a much smaller dataset for training. We will explore the dataset to drive our imputation strategy.","metadata":{}},{"cell_type":"markdown","source":"Only **2 features have nulls** (Monthly income and number of dependents). This could be due to customers not wanting to declare these personal information.","metadata":{"execution":{"iopub.execute_input":"2021-12-04T10:07:59.523817Z","iopub.status.busy":"2021-12-04T10:07:59.523503Z","iopub.status.idle":"2021-12-04T10:07:59.52918Z","shell.execute_reply":"2021-12-04T10:07:59.528361Z","shell.execute_reply.started":"2021-12-04T10:07:59.523781Z"}}},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-12-04T16:06:49.740563Z","iopub.execute_input":"2021-12-04T16:06:49.741173Z","iopub.status.idle":"2021-12-04T16:06:49.760745Z","shell.execute_reply.started":"2021-12-04T16:06:49.741122Z","shell.execute_reply":"2021-12-04T16:06:49.759823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features_with_na = df.isna().sum()[df.isna().sum()>0]\nfeatures_with_na.sort_values(ascending=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-04T16:06:49.762114Z","iopub.execute_input":"2021-12-04T16:06:49.76287Z","iopub.status.idle":"2021-12-04T16:06:49.780375Z","shell.execute_reply.started":"2021-12-04T16:06:49.762824Z","shell.execute_reply":"2021-12-04T16:06:49.77937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.boxplot(x=target_variable, y=\"MonthlyIncome\", data=df.sample(150),\n            whis=[0, 100], width=.6, palette=\"vlag\");","metadata":{"execution":{"iopub.status.busy":"2021-12-04T16:06:49.781755Z","iopub.execute_input":"2021-12-04T16:06:49.782229Z","iopub.status.idle":"2021-12-04T16:06:50.036869Z","shell.execute_reply.started":"2021-12-04T16:06:49.782197Z","shell.execute_reply":"2021-12-04T16:06:50.0362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.boxplot(x=target_variable, y=\"NumberOfDependents\", data=df.sample(150),\n            whis=[0, 100], width=.6, palette=\"vlag\");","metadata":{"execution":{"iopub.status.busy":"2021-12-04T16:06:50.038073Z","iopub.execute_input":"2021-12-04T16:06:50.038548Z","iopub.status.idle":"2021-12-04T16:06:50.294919Z","shell.execute_reply.started":"2021-12-04T16:06:50.038489Z","shell.execute_reply":"2021-12-04T16:06:50.293956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have 29k observations with >= 1 feature having NA values, corresponding to **20% of the dataset, which is quite significant**. We will **have to impute these NA values** rather than dropping observations with NA. **Monthly Income and NumberOfDependents** have right tail skews, so **median imputation** is preferred to be robust to outliers.","metadata":{}},{"cell_type":"code","source":"(df.isna().sum(axis=1)[df.isna().sum(axis=1)>0]\n         .reset_index().rename(columns={0:'number_of_na'})\n         .groupby('number_of_na')\n         .count().rename(columns={'index':'number_of_observations'}))","metadata":{"execution":{"iopub.status.busy":"2021-12-04T16:06:50.296155Z","iopub.execute_input":"2021-12-04T16:06:50.296385Z","iopub.status.idle":"2021-12-04T16:06:50.32249Z","shell.execute_reply.started":"2021-12-04T16:06:50.296358Z","shell.execute_reply":"2021-12-04T16:06:50.321573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Detecting outliers","metadata":{}},{"cell_type":"markdown","source":"Many of the financial features have outliers (extreme outliers = > 3* interquartile range), with a right-tail skew. Hence, we should **either use models that are robust to outliers (e.g. tree-based models), or transform the features accordingly (e.g. Box-Cox transformation)**.","metadata":{}},{"cell_type":"code","source":"def get_outlier_counts(df, outlier_threshold=1.5):\n    Q1 = df.quantile(0.25)\n    Q3 = df.quantile(0.75)\n    IQR = Q3 - Q1\n\n    outlier_counts = ((df < (Q1 - outlier_threshold * IQR)) | (df > (Q3 + outlier_threshold * IQR))).sum()\n    return outlier_counts[outlier_counts>0].sort_values(ascending=False)\n\nget_outlier_counts(df, outlier_threshold=3)","metadata":{"execution":{"iopub.status.busy":"2021-12-04T16:06:50.325666Z","iopub.execute_input":"2021-12-04T16:06:50.325931Z","iopub.status.idle":"2021-12-04T16:06:50.399115Z","shell.execute_reply.started":"2021-12-04T16:06:50.325899Z","shell.execute_reply":"2021-12-04T16:06:50.398188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe(percentiles=[.25,.5,.75,.9,.95,.99,.999])","metadata":{"execution":{"iopub.status.busy":"2021-12-04T16:06:50.400357Z","iopub.execute_input":"2021-12-04T16:06:50.400603Z","iopub.status.idle":"2021-12-04T16:06:50.500966Z","shell.execute_reply.started":"2021-12-04T16:06:50.400565Z","shell.execute_reply":"2021-12-04T16:06:50.500331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Checking for correlations","metadata":{}},{"cell_type":"markdown","source":"1. Detecting multicollinearity: **30, 60 and 90 days past due are highly correlated with each other** (close to 1). This may impact performance if the learning algorithm used assumes independence in dependent variables. We can **either use models that are robust to multicollinearity (e.g. tree-based models), or use feature selection / regularization methods to use just one of these features.**\n\n2. **30/60/90 days late payment** features have slight positive correlation with the target variable (0.12), while **age** has slight negative correlation with the target variable (-0.12). These are likely **useful features for predicting the target**.","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize = [12,8])\nsns.heatmap(df.corr(), cmap=sns.diverging_palette(240, 10, n=9),annot=True, center=0)\nplt.title(\"Correlation Matrix\", fontsize=12);","metadata":{"execution":{"iopub.status.busy":"2021-12-04T16:06:50.501921Z","iopub.execute_input":"2021-12-04T16:06:50.502354Z","iopub.status.idle":"2021-12-04T16:06:51.851401Z","shell.execute_reply.started":"2021-12-04T16:06:50.50227Z","shell.execute_reply":"2021-12-04T16:06:51.85026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Handling duplicates","metadata":{}},{"cell_type":"markdown","source":"Getting counts of number of rows by the number of duplicates: Most severe = 1 observations with 12 instances. Overall, the training set has not too many duplicates, hence will not likely bias the model much. These duplicates are only a problem if they came from non-random error, e.g. duplicate entry into database. In a real scenario, we should dig deeper to identify if these are errors or coincidences. For this problem, we **will not remove these duplicates and assume they are correct**.","metadata":{}},{"cell_type":"code","source":"len(df[df.duplicated()])","metadata":{"execution":{"iopub.status.busy":"2021-12-04T16:06:51.852959Z","iopub.execute_input":"2021-12-04T16:06:51.853735Z","iopub.status.idle":"2021-12-04T16:06:51.926189Z","shell.execute_reply.started":"2021-12-04T16:06:51.853688Z","shell.execute_reply":"2021-12-04T16:06:51.925111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(df.groupby(df.columns.tolist(),as_index=False)\n     .size()['size'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2021-12-04T16:06:51.927738Z","iopub.execute_input":"2021-12-04T16:06:51.927982Z","iopub.status.idle":"2021-12-04T16:06:52.13289Z","shell.execute_reply.started":"2021-12-04T16:06:51.927953Z","shell.execute_reply":"2021-12-04T16:06:52.131762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"## Train test split","metadata":{}},{"cell_type":"markdown","source":"**Train test split** is important to leave out a hold-out set (**30%** of dataset size) for evaluation, to **prevent data leakage**.","metadata":{}},{"cell_type":"code","source":"X, y = df.iloc[:,1:], df.loc[:,target_variable]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-12-04T16:06:52.13446Z","iopub.execute_input":"2021-12-04T16:06:52.134811Z","iopub.status.idle":"2021-12-04T16:06:52.175934Z","shell.execute_reply.started":"2021-12-04T16:06:52.134766Z","shell.execute_reply":"2021-12-04T16:06:52.17527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Preprocessing\n\nBased on EDA, we have found the need for imputation and scaling. Hence, we assemble a **pipeline of imputation (median) and scaling (Box-Cox via PowerTransformer)**, testing out different classifiers to compare model performance. Based on experimentation, model performance when training with SMOTE for synthetic oversampling of the minority class did not significantly improve performance.\n","metadata":{}},{"cell_type":"code","source":"def get_pipeline(classifier, random_seed=42):\n    \"\"\"Takes in a classifier, returns the entire data preprocessing pipeline (imblearn pipeline)\"\"\"\n    return Pipeline([\n                    ('imputer', SimpleImputer(strategy='median')),\n                    # SMOTE(sampling_strategy='minority', random_state=random_seed), -> removed due to poor performance\n                    ('scaler', PowerTransformer()),\n                    ('clf', classifier)\n                    ])","metadata":{"execution":{"iopub.status.busy":"2021-12-04T16:06:52.177171Z","iopub.execute_input":"2021-12-04T16:06:52.177895Z","iopub.status.idle":"2021-12-04T16:06:52.185076Z","shell.execute_reply.started":"2021-12-04T16:06:52.177838Z","shell.execute_reply":"2021-12-04T16:06:52.184253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Baseline models","metadata":{}},{"cell_type":"markdown","source":"We train several baseline models using different learning algorithms to get a sense of what learning algorithm best performs during **k-fold cross validation**. In the interest of time, we perform model selection with minimal hyperparameter tuning, and **select the model with best performance on cross-validation score**. Ideally,this selection process happens after hyperparameter tuning for all of the models.","metadata":{}},{"cell_type":"code","source":"def train_models(classifiers, num_folds=3, random_seed=42):\n    # models = dict()\n    results = dict()\n    for classifier in classifiers:\n        curr_time = time.time()\n        model = get_pipeline(classifier, random_seed=random_seed)\n        kfold = KFold(n_splits=num_folds)\n        print(f'Training {classifier.__class__.__name__}')\n        score = cross_val_score(model, X_train, y_train, cv=kfold, scoring='roc_auc')\n        print(\"%0.2f AUC with a standard deviation of %0.2f\" % (score.mean(), score.std()))\n        # models[classifier.__class__.__name__] = model\n        results[classifier.__class__.__name__] = score\n        print(f'Training took {round(time.time()-curr_time)} seconds')\n    print('Training complete')\n    return results\n\n\nclassifiers = [\n    GaussianNB(),\n    KNeighborsClassifier(5),\n    LogisticRegression(),\n    RandomForestClassifier(),\n    XGBClassifier(),\n]\nresults = train_models(classifiers)\nresults","metadata":{"execution":{"iopub.status.busy":"2021-12-04T16:06:52.186606Z","iopub.execute_input":"2021-12-04T16:06:52.187237Z","iopub.status.idle":"2021-12-04T16:08:29.172659Z","shell.execute_reply.started":"2021-12-04T16:06:52.187195Z","shell.execute_reply":"2021-12-04T16:08:29.171937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Hyperparameter tuning","metadata":{}},{"cell_type":"markdown","source":"Based on the baseline model performances, **XGBoost algorithm** performed the best (**highest AUC with lowest standard deviation across 3 folds**). To improve performance, we tune the model hyperparameters using **randomized search**, which does random search over the range of hyperparameters. This is faster than grid search, which exhaustively searches over all possible hyperparameters in the range provided.","metadata":{}},{"cell_type":"code","source":"model = get_pipeline(XGBClassifier(n_jobs=-1))\n\nxgb_hyperparams = {\n    'clf__max_depth' : np.arange(4,10,1),\n    'clf__learning_rate': [0.01, 0.1, 0.2, 0.3],\n    'clf__n_estimators' : np.arange(400,1000,100),\n    'clf__subsample': np.arange(0.5,1,0.1),\n    'clf__scale_pos_weight': [10,15,20] # Imbalanced ratio of 94:6, hence add weight to negative class\n    \n}\n\nclf = RandomizedSearchCV(estimator=model,\n                         param_distributions=xgb_hyperparams,\n                         scoring='roc_auc',\n                         n_iter=20,\n                         verbose=2)\n\nclf.fit(X_train, y_train)\n\nprint(\"Best parameters:\", clf.best_params_)\nprint(\"Best score: \", clf.best_score_)","metadata":{"execution":{"iopub.status.busy":"2021-12-04T16:08:29.173867Z","iopub.execute_input":"2021-12-04T16:08:29.174502Z","iopub.status.idle":"2021-12-04T17:17:44.735481Z","shell.execute_reply.started":"2021-12-04T16:08:29.174459Z","shell.execute_reply":"2021-12-04T17:17:44.733964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Final model","metadata":{}},{"cell_type":"markdown","source":"We evaluate model performance using ROC AUC, which is the **area under the receiver operating characteristic curve**. ","metadata":{}},{"cell_type":"code","source":"def evaluate_model(model, X_test, y_test):\n    predictions = model.predict(X_test)\n    predicted_proba = model.predict_proba(X_test)\n\n    # Default score: Mean accuracy, which is not a good evaluation metric for a imbalanced dataset problem\n    print('accuracy', model.score(X_test, y_test))\n    print('confusion_matrix')\n    print(confusion_matrix(y_test, predictions))\n    print('roc_auc',roc_auc_score(y_test, predicted_proba[:,1]))\n    print('classification_report')\n    print(classification_report(y_test, predictions))\n    plot_roc_curve(model, X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-12-04T17:17:44.737401Z","iopub.execute_input":"2021-12-04T17:17:44.737858Z","iopub.status.idle":"2021-12-04T17:17:44.74797Z","shell.execute_reply.started":"2021-12-04T17:17:44.737755Z","shell.execute_reply":"2021-12-04T17:17:44.747002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the model classification report, we see that its **recall for the positive class is high at 84%**. This is preferred, as per business use case where **type II errors are more costly than type I errors**. Overall, its **ROC is 86.6% on the held out test set**, which is similar to the average **86.4% on cross-validation set**, showing that the **model can perform well with out-of-sample data (i.e. is not overfitted)**.","metadata":{}},{"cell_type":"code","source":"model = get_pipeline(XGBClassifier(max_depth=4,\n                                   learning_rate=0.01,\n                                   n_estimators=800,\n                                   subsample=0.5,\n                                   scale_pos_weight=20,\n                                   n_jobs = -1))\n\nmodel.fit(X_train, y_train)\nevaluate_model(model, X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-12-04T17:18:55.746562Z","iopub.execute_input":"2021-12-04T17:18:55.746884Z","iopub.status.idle":"2021-12-04T17:19:34.991511Z","shell.execute_reply.started":"2021-12-04T17:18:55.746853Z","shell.execute_reply":"2021-12-04T17:19:34.9906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model explainability","metadata":{}},{"cell_type":"markdown","source":"From the feature importances, we see that **current utilization of credit (RevolvingUtilizationOfUnsecuredLines), 30-59 and >90 days late are the most useful features**. This **corresponds well with our intuition** that customers with history of frequent late payments and with are more likely to be delinquent on loan repayment in the future.\n\n**For customers**, the actionable insights are that **the feature importances can be interpreted as a priority list of issues to fix for improving their credit score**. For example, ensuring one has low utilization of unsecured lines is more impactful in improving credit scoring than increasing their debt ratio or monthly income.","metadata":{}},{"cell_type":"code","source":"(pd.DataFrame(model['clf'].feature_importances_, X_train.columns)\n     .reset_index()\n     .rename({'index':'features', 0:'feature_importance'}, axis=1)\n     .sort_values(by=['feature_importance'], ascending=False))","metadata":{"execution":{"iopub.status.busy":"2021-12-04T17:19:34.993145Z","iopub.execute_input":"2021-12-04T17:19:34.993499Z","iopub.status.idle":"2021-12-04T17:19:35.010573Z","shell.execute_reply.started":"2021-12-04T17:19:34.993462Z","shell.execute_reply":"2021-12-04T17:19:35.009736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The **SHAP model quantifies the contributions that each feature brings to generate the model outputs**. Plotting the average contributions across all predictions, we can visualize how much each value affect's one's probability of the model predicting one's delinquency in the next 2 years (and hence credit score). For example, we see that **higher RevolvingUtilizationOfUnsecuredLines leads to higher probability of delinquency**, as visualized by red scatter points having positive SHAP values.","metadata":{}},{"cell_type":"code","source":"def plot_shap(model, df):\n    \"\"\"Plots shapely values for model explainability\"\"\"\n    X_sampled = df.sample(100)\n\n    explainer = shap.TreeExplainer(model['clf'])\n    observations = model['scaler'].transform(model['imputer'].transform(X_sampled))\n    \n    shap_values = explainer.shap_values(observations)\n    shap.summary_plot(shap_values, X_sampled)\n    \nplot_shap(model, X_test)","metadata":{"execution":{"iopub.status.busy":"2021-12-04T17:19:35.011816Z","iopub.execute_input":"2021-12-04T17:19:35.012443Z","iopub.status.idle":"2021-12-04T17:19:36.591895Z","shell.execute_reply.started":"2021-12-04T17:19:35.012396Z","shell.execute_reply":"2021-12-04T17:19:36.590885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Saving outputs","metadata":{}},{"cell_type":"markdown","source":"Submitting output to [kaggle](https://www.kaggle.com/c/GiveMeSomeCredit/leaderboard), the **XGBoost AUCROC for the test results were 0.86083%**. On the public leaderboard, this would be **position 141 / 924 (top 15%)**.","metadata":{}},{"cell_type":"code","source":"def get_output(model, test_df):\n    output_predictions = model.predict_proba(test_df.iloc[:,2:])\n    output_df = pd.DataFrame(output_predictions[:,1]).rename(columns={0:'probability'})\n    output_df['id'] = range(1,len(output_df)+1)\n    output_df = output_df.loc[:,['id','probability']]\n    return output_df\n\ntest_df = pd.read_csv(root_folder+'cs-test.csv')\noutput_df = get_output(model, test_df)\n\noutput_df.to_csv('output_predictions.csv', index=False)\noutput_df","metadata":{"execution":{"iopub.status.busy":"2021-12-04T17:19:36.593934Z","iopub.execute_input":"2021-12-04T17:19:36.594196Z","iopub.status.idle":"2021-12-04T17:19:37.659284Z","shell.execute_reply.started":"2021-12-04T17:19:36.594161Z","shell.execute_reply":"2021-12-04T17:19:37.658558Z"},"trusted":true},"execution_count":null,"outputs":[]}]}