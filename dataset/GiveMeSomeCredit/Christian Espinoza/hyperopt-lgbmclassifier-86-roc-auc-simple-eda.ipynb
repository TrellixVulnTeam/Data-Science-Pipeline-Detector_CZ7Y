{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h3>Introduction</h3>\n<p>Banks play a crucial role in market economies. They decide who can get financing and on what terms and can make or stop investment decisions. For markets and society to function, individuals and companies need access to credit. Credit scoring algorithms, which predict the probability of default, are the method used by banks to determine whether or not a loan should be granted..</p>\n<h3>objective</h3>\n<p>Creation of a model in which he can try to predict the probability of the customer being able to repay the requested loan to the bank</p>\n<h3>About Dataset </h3>\n<p>History of approx. 250,000 customers in which it was divided between training and test dataset</p>\n<h5 style='text-align: center'>Variable Name Description Type</h5>\n\n<table>\n<tr>\n  <th>Variable</th>\n  <th>Description</th>\n</tr>\n<tr>\n  <td>SeriousDlqin2yrs</td>\n  <td>Person experienced 90 days past due delinquency or worse Y/N</td>\n</tr>\n    <tr>\n    <td>RevolvingUtilizationOfUnsecuredLines</td>\n     <td>Total balance on credit cards and personal lines of credit except real estate and no installment debt like car loans divided by the sum of credit limits percentage</td>\n    </tr>\n     <tr>\n     <td>Age</td>\n     <td>Age of borrower in years integer</td>\n    </tr>\n      <tr>\n     <td>NumberOfTime3059DaysPastDueNotWorse</td>\n     <td>Number of times borrower has been 30-59 days past due but no worse in the last 2 years. integer</td>\n    </tr>\n     <tr>\n     <td>DebtRatio</td>\n     <td>Monthly debt payments, alimony,living costs divided by monthy gross income percentage</td>\n    </tr>\n     <tr>\n     <td>MonthlyIncome</td>\n     <td>Monthly income real</td>\n    </tr>\n      <tr>\n     <td>NumberOfOpenCreditLinesAndLoans</td>\n     <td>Number of Open loans (installment like car loan or mortgage) and Lines of credit (e.g. credit cards) integer</td>\n    </tr>\n     <tr>\n     <td>NumberOfTimes90DaysLate</td>\n     <td>Number of times borrower has been 90 days or more past due. integer</td>\n    </tr>\n      <tr>\n     <td>NumberRealEstateLoansOrLines</td>\n     <td>Number of mortgage and real estate loans including home equity lines of credit integer</td>\n    </tr>\n          <tr>\n     <td>NumberOfTime60-89DaysPastDueNotWorse</td>\n     <td>Number of times borrower has been 60-89 days past due but no worse in the last 2 years. integer</td>\n    </tr>\n      <tr>\n     <td>NumberOfDependents</td>\n     <td> Number of dependents in family excluding themselves (spouse, children etc.) integer</td>\n    </tr>\n    \n</table>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('../input/GiveMeSomeCredit/cs-training.csv')\ndf_test = pd.read_csv('../input/GiveMeSomeCredit/cs-test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Train Shape is :',df_train.shape,'\\nTest shape is :',df_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(df_train.isna().sum()/len(df_train)) * 100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask = df_train.isnull()\nsns.heatmap(df_train, mask=mask,cmap=\"YlGnBu\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p>Devido a quantidade menor que 5% de missing na coluna NumberOfDependents eu preferi optar pelo drop da mesma</p>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.dropna(subset=['NumberOfDependents'],inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_append = df_train.append(df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(df_train.SeriousDlqin2yrs.value_counts() / len(df_train) ) * 100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=\"SeriousDlqin2yrs\", data=df_train);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot((df_train.age));","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p>I ended up choosing to carry out the test by grouping the age of the customers where in the final model I would test which of the two forms would have the best performance, with only the age column or it grouped</p>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"bins= [20,60,80,120]\nlabels_age = ['Adult','Young Senior','Senior']\ndf_append['AgeGroup'] = pd.cut(df_append['age'], bins=bins, labels=labels_age, right=False)\nmask_2 = {\n         'Adult':0,\n         'Young Senior':1,\n         'Senior':2}\ndf_append['AgeGroup'].replace(mask_2,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_append['AgeGroup'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_append['MonthlyIncome'].fillna(df_append['MonthlyIncome'].median(),inplace=True)\ndf_append['NumberOfDependents'].fillna(df_append['NumberOfDependents'].median(),inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p>\nI chose to separate the ages from 18 to 60 as \"adults\" because above that I will already consider you as a gentleman (retired), another detail that I made a classification above 80 years old due to some rules that at least exist in Brazil even though the original dataset is not Brazilian</p>\n\n<p>\"The profile with the highest approval rate is that of the private sector employee, a graduate and an average income close to 3.2 thousand reais. This type of consumer corresponds to only 9% of those who completed the registration to apply for credit, but 37% were approved.\" </p>\n<img src='exame.png'>\n<p>\"Of the requests made to pay debts, 25% were approved; for investments, 26%, and to renovate the house 28%. The highest approval rate was for purchases, trips and parties, with 32%.\"\n<a href=\"https://exame.com/seu-dinheiro/os-perfis-com-mais-chances-de-conseguir-um-emprestimo-segundo-a-finanzero/\">Fonte Exame</a>\n</p>\n<p> with that we try to pull to the reality of brazil to see if the profile that corresponds here can be similar to the same that the dataset represents</p>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = df_append[0:146076]\ndf_test = df_append[146076:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_append = df_append[df_append != 5400]\ndf_adult = df_train[df_train['AgeGroup'] == 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='NumberOfDependents',data=df_adult);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p>With that we realized that for our current dataset we have that our group of adults tend to have up to 4 dependents, with a low rate above that</p>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(df_adult.SeriousDlqin2yrs);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=\"AgeGroup\", data=df_train);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.jointplot(\"age\", \"NumberOfDependents\", data=df_train, ylim=(0, 12),\n                  color=\"m\", height=7)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p> even though in the main dataset we have dropped the numberOfDependents column in our test dataset we still have them as nulls so we will choose to fill it in with values of our median </p>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['AgeGroup'].fillna(df_train['AgeGroup'].median(),inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_train.drop(columns={'Unnamed: 0','age','SeriousDlqin2yrs'})\ny = df_train['SeriousDlqin2yrs']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom lightgbm import LGBMModel,LGBMClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom yellowbrick.model_selection import RFECV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import SelectFromModel\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.metrics import roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import auc,roc_curve\ndef plot_roc(pred):\n    fpr,tpr,_ = roc_curve(y_test, pred)\n    roc_auc = auc(fpr, tpr)\n    plt.figure(figsize=(10,8))\n    plt.title('Receiver Operating Characteristic')\n    sns.lineplot(fpr, tpr, label = 'AUC = %0.4f' % roc_auc)\n    plt.legend(loc = 'lower right')\n    plt.plot([0, 1], [0, 1],'r--')\n    plt.ylabel('True Positive Rate')\n    plt.xlabel('False Positive Rate')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Train Shapes',X_train.shape,' and ',y_train.shape,'\\nTest Shapes',X_test.shape,' and ' ,y_test.shape,'\\nOutput Values\\n',y_train.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"smote = SMOTE(sampling_strategy = 'minority',k_neighbors = 2,random_state=0)\nX_train_smote,y_train_smote = smote.fit_sample(X_train,y_train)\n\n#Realizar Teste Smote + kfold(com cv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Train Shapes',X_train_smote.shape,' and ',y_train_smote.shape,'\\nTest Shapes',X_test.shape,' and ' ,y_test.shape,'\\nOutput Values\\n',y_train_smote.value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A test was performed using Smote for upsample but the results were worse than with the data as it was (unbalanced), due to this it was chosen to continue with the data unbalanced for the models","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Choosing to make a base model with random forest just for testing and visual selection of features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = RandomForestClassifier()\nclf.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feat_names = X.columns.values\nimportances = clf.feature_importances_\nstd = np.std([tree.feature_importances_ for tree in clf.estimators_], axis=0)\nindices = np.argsort(importances)[::-1][:20]\n\nplt.figure(figsize=(12,12))\nplt.title(\"Feature importances\")\nplt.bar(range(len(indices)), importances[indices], color=\"y\", yerr=std[indices], align=\"center\")\nplt.xticks(range(len(indices)), feat_names[indices], rotation='vertical')\nplt.xlim([-1, len(indices)])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = clf.predict_proba(X_test)[:,1]\n#Predict Primeiro modelo basico\nprint(roc_auc_score(y_test, pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_roc(pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Lgb = LGBMClassifier(objective='binary',metrics ='auc')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv = StratifiedKFold(5)\nvisualizer = RFECV(Lgb, cv=cv, scoring='roc_auc')\nvisualizer.fit(X_train, y_train)        # Fit the data to the visualizer\nvisualizer.show();           # Finalize and render the figure","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_rfe = visualizer.predict_proba(X_test)[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_roc(pred_rfe)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from hyperopt import hp, tpe, fmin\nfrom sklearn.model_selection import cross_val_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Usando Hypteropt\nspace = {'n_estimators':hp.quniform('n_estimators', 10, 4000, 10),\n        'learning_rate':hp.uniform('learning_rate', 0.00001, 0.03),\n         'max_depth':hp.quniform('max_depth', 3,7,1),\n         'subsample':hp.uniform('subsample', 0.60, 0.95),\n         'colsample_bytree':hp.uniform('colsample_bytree', 0.60, 0.95),\n         'reg_lambda': hp.uniform('reg_lambda', 1, 20),\n        }\n\ndef objective(params):\n    params = {'n_estimators': int(params['n_estimators']),\n             'learning_rate': params['learning_rate'],\n             'max_depth': int(params['max_depth']),\n             'subsample': params['subsample'],\n             'colsample_bytree': params['colsample_bytree'],\n             'reg_lambda': params['reg_lambda'],\n             }\n    \n    lgbm= LGBMClassifier(**params)\n    cv = StratifiedKFold(5)\n    score = cross_val_score(lgbm, X_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1).mean()\n    return -score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best = fmin(fn= objective, space= space, max_evals=20, rstate=np.random.RandomState(1), algo=tpe.suggest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbm = LGBMClassifier(random_state=0,\n                        n_estimators=int(best['n_estimators']), \n                        colsample_bytree= best['colsample_bytree'],\n                        learning_rate= best['learning_rate'],\n                        max_depth= int(best['max_depth']),\n                        subsample= best['subsample'],\n                        reg_lambda= best['reg_lambda']\n                       )\n\nlgbm.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbm_hype = lgbm.predict_proba(X_test)[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_roc(lgbm_hype)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#prediction\ndf_x_test = df_test.drop(columns={'Unnamed: 0','age','SeriousDlqin2yrs'})\npred = lgbm.predict_proba(df_x_test)[:,1]\n#output\noutput = pd.DataFrame({'Id': df_test['Unnamed: 0'],'Probability': pred})\noutput.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}