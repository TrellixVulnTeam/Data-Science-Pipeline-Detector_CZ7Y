{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n%matplotlib inline\nplt.style.use(\"fivethirtyeight\")\nplt.rcParams['xtick.labelsize']=8\nplt.rcParams['ytick.labelsize']=8\n\nfrom sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import mean_squared_error, accuracy_score,confusion_matrix, roc_curve, auc,classification_report, recall_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split,RandomizedSearchCV\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/GiveMeSomeCredit/cs-training.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.drop(\"Unnamed: 0\", axis=1, inplace=True)\ntrain_data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Label Distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,3))\ntrain_data['SeriousDlqin2yrs'].value_counts().plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class0 = train_data['SeriousDlqin2yrs'].value_counts()[0]\nclass1 = train_data['SeriousDlqin2yrs'].value_counts()[1]\nprint(\"class 0 : {}\".format(class0))\nprint(\"class 1 : {}\".format(class1))\nprint(\"delinquency rate: {}\".format(class1/(class0+class1)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Age"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data[train_data['age'] < 18]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,3))\nsns.boxplot(train_data['age'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the observation, I would:\n- Impute age with median"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.loc[train_data['age'] < 18, 'age'] = train_data['age'].median()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols =[\"NumberOfTime30-59DaysPastDueNotWorse\",\"NumberOfTime60-89DaysPastDueNotWorse\",\"NumberOfTimes90DaysLate\", \"DebtRatio\",\"NumberOfOpenCreditLinesAndLoans\",\"NumberRealEstateLoansOrLines\", \"RevolvingUtilizationOfUnsecuredLines\"]\nfig, axes = plt.subplots(len(cols),1, figsize=(10,10))\ni = 0\nfor c in cols:\n    ax = sns.boxplot(train_data[c], ax = axes[i])\n    ax.set_ylabel(c, rotation=0,labelpad=150)\n    ax.set_xlabel(\"Number of Times\")\n    i +=1\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Debt Ratio"},{"metadata":{"trusted":true},"cell_type":"code","source":"debtratio_q = train_data[\"DebtRatio\"].quantile(0.86)\nprint(\"Debt Ratio: {}\".format(debtratio_q))\n\ncolormap = {0:'blue', 1:'red'}\n\nfig, (ax1, ax2) = plt.subplots(1,2,  figsize=(15,4))\nfor delinquency, color in colormap.items():\n    tmp = train_data[(train_data['DebtRatio'] > debtratio_q) & (train_data['SeriousDlqin2yrs']==delinquency)][['DebtRatio','MonthlyIncome']]\n    ax1.scatter((tmp['DebtRatio']), (tmp['MonthlyIncome']), c=color, alpha=0.8, label= str(delinquency) + \":{}\".format(tmp.shape[0]))\nax1.legend()\nax1.set_title(\"Debt Ratio 86% Quantile against Monthly Income\",fontsize=10)\nax1.set_xlabel(\"DebtRatio\")\nax1.set_ylabel(\"Monthly Income\")\n\nfor delinquency, color in colormap.items():\n    tmp = train_data[(train_data['SeriousDlqin2yrs']==delinquency)][['DebtRatio','MonthlyIncome']]\n    ax2.scatter(np.log(tmp['DebtRatio']), np.log(tmp['MonthlyIncome']), c=color, alpha=0.8, label= str(delinquency) + \":{}\".format(tmp.shape[0]))\nax2.legend()\nax2.set_title(\"Log of Debt Ratio against log of Monthly Income\",fontsize=10)\nax2.set_xlabel(\"log(DebtRatio)\")\nax2.set_ylabel(\"log(Monthly Income)\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of records with monthly income equals 1: {}\".format(train_data[(train_data['MonthlyIncome'] == 1) ].shape[0]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Number of records with monthly income equals 1: 605\nIt is oberserved that top 14% of the debt ratio records have a Monthly Income of either 0 or 1. The debt to income ratio of these records are more than 453 times. It is suspected that there are data entry error or incomplete information given when Monthly Income is 1 while Debt Ratio is high.\n\nFrom the observation above, I would:\n\nTake log of the Debt Ratio\nRemove records where monthly income is 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data[\"DebtRatio\"] = np.log(train_data[\"DebtRatio\"])\nremovedmonthincome_1 = train_data[train_data[\"MonthlyIncome\"] != 1]\nremovedmonthincome_1[\"DebtRatio\"].replace([np.inf, -np.inf], -10, inplace=True)\n\nremovedmonthincome_1.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Utlization Ratio"},{"metadata":{},"cell_type":"markdown","source":"It is expected that the higher the utlization ratio, the higher the default rate is. Let me look into that by plotting the utlization ratio to default rate"},{"metadata":{"trusted":true},"cell_type":"code","source":"u_list = []\nd_list = []\nfor u in range(int(train_data['RevolvingUtilizationOfUnsecuredLines'].max())):\n    default_rate = train_data[train_data['RevolvingUtilizationOfUnsecuredLines'] > u]['SeriousDlqin2yrs'].mean()\n    u_list.append(u)\n    d_list.append(default_rate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1,ax2)= plt.subplots(1,2, figsize=(15,4))\ndf = pd.DataFrame({\"utilization\":u_list, \"default\":d_list})\ndf.plot(\"utilization\",\"default\",ax=ax1)\nax1.set_ylabel(\"Default Rate\")\nax1.set_xlabel(\"Utilization Ratio\")\n\nutilization_outlier = df[df.default==0]['utilization'].min()\nprint(\"Remove Outliers at point UtilizatoinRation={}\".format(utilization_outlier))\n\ndftmp = df[df < utilization_outlier]\ndftmp.plot(\"utilization\",\"default\",ax=ax2)\nax2.plot([3500 for i in range(dftmp.shape[0])], np.linspace(0,0.35,dftmp.shape[0]), 'r--')\nax2.plot([6200 for i in range(dftmp.shape[0])], np.linspace(0,0.35,dftmp.shape[0]), 'r--')\nax2.set_ylabel(\"Default Rate\")\nax2.set_xlabel(\"Utilization Ratio\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the plotting the Default Rate against the utilization ratio, it's observed that the default rate stops increasing and reaches zero when utilization increases til a certain point. Also, there seems to be three groups of utilization ratio that shows positive linear relationship with the default rate.\n\nFrom this observation, I would:\n- Remove outliers at the utilization point when the default rate stops increasing\n- create a new feature which categorize Utilization Ratio into 3 groups"},{"metadata":{"trusted":true},"cell_type":"code","source":"removedUtilization = train_data[train_data.RevolvingUtilizationOfUnsecuredLines <= utilization_outlier]\n\ndef categorize_utilization(u):\n    if u < 3500:\n        return 0\n    elif (u >= 3500) & (u < 6200):\n        return 1\n    else:\n        return 2\n    \nremovedUtilization[\"UtlizationCategory\"] = removedUtilization[\"RevolvingUtilizationOfUnsecuredLines\"].apply(categorize_utilization)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = train_data.columns\nnullcounts = []\nvalue_counts = []\nfor col in cols:\n    nullcounts.append(train_data[col].isnull().sum())\n    value_counts.append(train_data[col].shape[0] - train_data[col].isnull().sum())\n\nfig, ax = plt.subplots(figsize=(10,3))\nax.barh(cols, value_counts, label='not missing')\nax.barh(cols, nullcounts, label='missing', left=value_counts)\nax.set_xlabel('Value Count')\nax.set_ylabel('Labels')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are only two features with missing values, I would:\n- Impute Monthly Income with the mean income of three groups categorized by age\n- Impute Number of Dependents with its mode "},{"metadata":{"trusted":true},"cell_type":"code","source":"imputedf = train_data[['age','NumberOfDependents','MonthlyIncome']].copy()\n\ndef categorizeAge(age):\n    if (age < 35):\n        return 'junior'\n    elif (age >= 35) & (age < 60):\n        return'senior'\n    else:\n        return 'mature'\n\nimputedf['seniority'] = imputedf['age'].apply(categorizeAge)\nincome_dict = imputedf.groupby('seniority')['MonthlyIncome'].mean().to_dict()\nincome_dict","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Impute Number of Dependents with mode of number of dependents"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Impute Monthly Income by median of seniority\nfor k, v in income_dict.items():\n    imputedf[\"MonthlyIncome\"] = np.where((imputedf[\"MonthlyIncome\"].isnull()) & (imputedf['seniority'] == k), int(v), imputedf[\"MonthlyIncome\"])\ntrain_data['MonthlyIncome'] = imputedf[\"MonthlyIncome\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Impute NumberOfDependents with Mode\nprint(train_data['NumberOfDependents'].mode())\n# Fill na with mode \ntrain_data['NumberOfDependents'].fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Features correlation"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = train_data.corr()\nplt.figure(figsize=(10,10))\nsns.heatmap(corr, annot=True, fmt=\".2f\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are highly correlation between the \"N Days Past Due\" features and also some outliers, I would:\n- Impute the outliers\n- Combined (N Days Past Due) as new feature\n- Combine (Credit Lines and Loans) as new feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_data[\"NumberOfTime30-59DaysPastDueNotWorse\"].sort_values().unique())\nprint(train_data[\"NumberOfTime60-89DaysPastDueNotWorse\"].sort_values().unique())\nprint(train_data[\"NumberOfTimes90DaysLate\"].sort_values().unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmpdf = train_data[(train_data[\"NumberOfTime30-59DaysPastDueNotWorse\"] == 98) & (train_data[\"NumberOfTime60-89DaysPastDueNotWorse\"] == train_data[\"NumberOfTime30-59DaysPastDueNotWorse\"]) & (train_data[\"NumberOfTimes90DaysLate\"] == train_data[\"NumberOfTime60-89DaysPastDueNotWorse\"])][cols]\nprint(\"98 times past due where 3 columns have same value: {}\".format(tmpdf.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Impute outliers with max value\ntimes_map = {\"NumberOfTime30-59DaysPastDueNotWorse\": 13, \"NumberOfTime60-89DaysPastDueNotWorse\":11, \"NumberOfTimes90DaysLate\":17}\nfor col, v in times_map.items():\n    train_data.loc[train_data[col] >= 96, col] = times_map[col]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data[\"CombinedPastDue\"] = train_data[\"NumberOfTime30-59DaysPastDueNotWorse\"] + train_data[\"NumberOfTime60-89DaysPastDueNotWorse\"] + train_data[\"NumberOfTimes90DaysLate\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data[\"CombinedCreditLoans\"] = train_data[\"NumberOfOpenCreditLinesAndLoans\"] + train_data[\"NumberRealEstateLoansOrLines\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"income_dict","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"def categorizeAge(age):\n    if (age < 35):\n        return 'junior'\n    elif (age >= 35) & (age < 60):\n        return'senior'\n    else:\n        return 'mature'\n    \ndef data_preprocess(df, is_submission=False):\n    print(\"Shape before: {}\".format(df.shape))\n    df.loc[df['age'] < 18, 'age'] = df['age'].median()\n    \n    df[\"DebtRatio\"] = np.log(df[\"DebtRatio\"])\n    df[\"DebtRatio\"].replace([np.inf, -np.inf], -10, inplace=True)\n    if not is_submission:\n        df = df[df[\"MonthlyIncome\"] != 1]\n    \n    utilization_outlier = 8328\n    if not is_submission:\n        df = df[df.RevolvingUtilizationOfUnsecuredLines <= utilization_outlier]\n#     df[\"UtlizationCategory\"] = df[\"UtilisationRatio\"].apply(categorize_utilization)\n    \n    imputedf = df[['age','NumberOfDependents','MonthlyIncome']].copy()\n    imputedf['seniority'] = imputedf['age'].apply(categorizeAge)\n    income_dict = imputedf.groupby('seniority')['MonthlyIncome'].mean().to_dict()\n    for k, v in income_dict.items(): \n        imputedf[\"MonthlyIncome\"] = np.where((imputedf[\"MonthlyIncome\"].isnull()) & (imputedf['seniority'] == k), int(v), imputedf[\"MonthlyIncome\"])\n    df['MonthlyIncome'] = imputedf[\"MonthlyIncome\"]\n    \n    df['NumberOfDependents'].fillna(0, inplace=True)\n    \n    times_map = {\"NumberOfTime30-59DaysPastDueNotWorse\": 13, \"NumberOfTime60-89DaysPastDueNotWorse\":11, \"NumberOfTimes90DaysLate\":17}\n    for col, v in times_map.items():\n        df.loc[df[col] >= 96, col] = times_map[col]\n    \n    df[\"CombinedPastDue\"] = df[\"NumberOfTime30-59DaysPastDueNotWorse\"] + df[\"NumberOfTime60-89DaysPastDueNotWorse\"] + df[\"NumberOfTimes90DaysLate\"]\n    \n    df[\"CombinedCreditLoans\"] = df[\"NumberOfOpenCreditLinesAndLoans\"] + df[\"NumberRealEstateLoansOrLines\"]\n    \n    print(\"Shape after: {}\".format(df.shape))\n    return df\n\ntrain_data = pd.read_csv(\"/kaggle/input/GiveMeSomeCredit/cs-training.csv\")\ntrain_data.drop(\"Unnamed: 0\", axis=1, inplace=True)\n\ntrain_data = data_preprocess(train_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = train_data.corr()\nplt.figure(figsize=(10,10))\nsns.heatmap(corr, annot=True, fmt=\".2f\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_drop = [\"NumberOfTimes90DaysLate\",\"NumberOfTime60-89DaysPastDueNotWorse\",\"NumberOfOpenCreditLinesAndLoans\",\"NumberRealEstateLoansOrLines\"]\ntrain_data.drop(cols_drop, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.sample(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Basis Model - Logitistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(train_data.iloc[:,1:], train_data.iloc[:,0], random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler().fit(X_train)\n\nX_train_scaled = scaler.transform(X_train) \nX_test_scaled = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logit = LogisticRegression(random_state=42)\nl_model = logit.fit(X_train_scaled, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logit_scores_proba  = l_model.predict_proba(X_test_scaled)\nlogit_scores = logit_scores_proba[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_roc(y_test, y_predict):\n    fpr, tpr, _ = roc_curve(y_test, y_predict)\n    roc_auc = auc(fpr,tpr)\n    print(roc_auc)\n    plt.figure(figsize=(10,8))\n    plt.title(\"ROC curve\")\n    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n    plt.plot([0,1], [0,1],'r--')\n    plt.legend(loc=\"lower right\")\nplot_roc(y_test, logit_scores)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"random_forest = RandomForestClassifier()\nparam_grid={\n    \"n_estimators\":[9,18,27,36,100],\n    \"max_depth\":[5,7,9],\n    \"min_samples_leaf\":[2,4,6,8]\n}\nrf_model = RandomizedSearchCV(random_forest, param_distributions = param_grid, cv=5)\nrf_model.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_model.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_est_rf = rf_model.best_estimator_\nbest_est_rf.fit(X_train, y_train)\ny_pred_rf = best_est_rf.predict_proba(X_test)[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_roc(y_test, y_pred_rf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_feature_importances(model):\n    plt.figure(figsize=(10,8))\n    n_features = X_train.shape[1]\n    plt.barh(range(n_features), model.feature_importances_, align='center')\n    plt.yticks(np.arange(n_features), X_train.columns)\n    plt.xlabel(\"Feature importance\")\n    plt.ylabel(\"Feature\")\n    plt.ylim(-1, n_features)\n\nplot_feature_importances(best_est_rf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## For Submission"},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"test_data = pd.read_csv(\"/kaggle/input/GiveMeSomeCredit/cs-test.csv\")\ntest_data.drop(\"Unnamed: 0\", axis=1, inplace=True)\n\ntest_data = data_preprocess(test_data, True)\n\ncols_drop = [\"SeriousDlqin2yrs\",\"NumberOfTimes90DaysLate\",\"NumberOfTime60-89DaysPastDueNotWorse\",\"NumberOfOpenCreditLinesAndLoans\",\"NumberRealEstateLoansOrLines\"]\ntest_data.drop(cols_drop, axis=1, inplace=True)\ntest_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_score = best_est_rf.predict_proba(test_data)[:,1]\n\nids = np.arange(1,101504)\nsubmission = pd.DataFrame( {'Id': ids, 'Probability': submission_score})\nsubmission.to_csv(\"/kaggle/working/credit_score_submision.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}