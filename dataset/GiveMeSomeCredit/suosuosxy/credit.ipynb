{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-25T08:10:09.497Z","iopub.execute_input":"2021-06-25T08:10:09.497435Z","iopub.status.idle":"2021-06-25T08:10:09.510582Z","shell.execute_reply.started":"2021-06-25T08:10:09.497387Z","shell.execute_reply":"2021-06-25T08:10:09.50938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **一、数据导入**\n","metadata":{}},{"cell_type":"markdown","source":"# 1.1 导入库及数据","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestRegressor\nimport seaborn as sns\nfrom scipy import stats\nimport copy\n \n%matplotlib inline\n \ntrain_df = pd.read_csv('../input/GiveMeSomeCredit/cs-training.csv')\ntest_df = pd.read_csv('../input/GiveMeSomeCredit/cs-test.csv')\ntrain_df.info()\ntrain_df.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T08:10:09.519767Z","iopub.execute_input":"2021-06-25T08:10:09.520351Z","iopub.status.idle":"2021-06-25T08:10:09.890035Z","shell.execute_reply.started":"2021-06-25T08:10:09.520296Z","shell.execute_reply":"2021-06-25T08:10:09.889169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 二、数据清洗\n\n","metadata":{}},{"cell_type":"markdown","source":"## 2.1 数据检查","metadata":{}},{"cell_type":"markdown","source":"首先对在之前查看数据发现第一列没有命名，因此首先进行列的重命名，将第一列命名为ID","metadata":{}},{"cell_type":"code","source":"# 列重命名\ntrain_df.rename(columns={'Unnamed: 0':'ID'}, inplace=True)\ntest_df.rename(columns={'Unnamed: 0':'ID'}, inplace=True)\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2021-06-25T08:10:09.891759Z","iopub.execute_input":"2021-06-25T08:10:09.892431Z","iopub.status.idle":"2021-06-25T08:10:09.92375Z","shell.execute_reply.started":"2021-06-25T08:10:09.892394Z","shell.execute_reply":"2021-06-25T08:10:09.922123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"之后查看是否有重复的列","metadata":{}},{"cell_type":"code","source":"print(train_df.duplicated().value_counts())\nprint(test_df.duplicated().value_counts())","metadata":{"execution":{"iopub.status.busy":"2021-06-25T08:10:09.926868Z","iopub.execute_input":"2021-06-25T08:10:09.927329Z","iopub.status.idle":"2021-06-25T08:10:10.096585Z","shell.execute_reply.started":"2021-06-25T08:10:09.927296Z","shell.execute_reply":"2021-06-25T08:10:10.095428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"发现没有重复的列，因此不需要处理。<br>接着通过describe()查看是否有异常值：","metadata":{}},{"cell_type":"code","source":"train_df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T08:10:10.098607Z","iopub.execute_input":"2021-06-25T08:10:10.09906Z","iopub.status.idle":"2021-06-25T08:10:10.215223Z","shell.execute_reply.started":"2021-06-25T08:10:10.099016Z","shell.execute_reply":"2021-06-25T08:10:10.213938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"从describe()的结果看，年龄出现了0，不合理，因此在后续可以用中位数替换。<br>\nNumberOfTime30-59DaysPastDueNotWorse, NumberOfTimes90DaysLate, NumberOfTime60-89DaysPastDueNotWorse三种的最大值都是98，导致平均值很接近，应该排查一下相关性；<br>\n同理，NumberOfOpenCreditLinesAndLoans，NumberRealEstateLoansOrLines。需要检查一下这几个参数之间的相关性<br>\n同时，根据统计数据可发现MonthlyIncome存在较多缺失值，NumberOfDependents存在较少缺失值（在2.2节进行处理）。<br><br>\n     接下来查看一下训练集的分类结果","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nplt.figure()\nsns.countplot('SeriousDlqin2yrs',data=train_df)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T08:10:10.216893Z","iopub.execute_input":"2021-06-25T08:10:10.217365Z","iopub.status.idle":"2021-06-25T08:10:10.357967Z","shell.execute_reply.started":"2021-06-25T08:10:10.21732Z","shell.execute_reply":"2021-06-25T08:10:10.356971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"发现分类并不均衡，数据不平衡会让监督学习算法过多关注多数类，使分类性能下降；由于数据量很大，因此可以尝试使用随机森林等方法进行训练。","metadata":{}},{"cell_type":"markdown","source":"## 2.2 数据整理\n","metadata":{}},{"cell_type":"markdown","source":"### 2.2.1 缺失值处理\n","metadata":{}},{"cell_type":"markdown","source":"对NumberOfDependents进行填充，直接使用中位数进行填充","metadata":{}},{"cell_type":"code","source":"train_df.loc[train_df.NumberOfDependents.isnull(), 'NumberOfDependents'] = train_df['NumberOfDependents'].median()\nprint(train_df.NumberOfDependents.isnull().sum())\ntest_df.loc[test_df.NumberOfDependents.isnull(), 'NumberOfDependents'] = test_df['NumberOfDependents'].median()\ntest_df.NumberOfDependents.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T08:10:10.359133Z","iopub.execute_input":"2021-06-25T08:10:10.359441Z","iopub.status.idle":"2021-06-25T08:10:10.37934Z","shell.execute_reply.started":"2021-06-25T08:10:10.359413Z","shell.execute_reply":"2021-06-25T08:10:10.378293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"之后进行MonthlyIncome的缺失值的填充，由于月收入与很多因素相关，因此不选择直接通过平均数进行填充，使用随机森林模型进行填充。","metadata":{}},{"cell_type":"code","source":"def set_missing(df):\n    # 把已有的数值型特征取出来\n    process_df = df.iloc[:, [6, 0, 2, 3, 4, 5, 7, 8, 9, 10]]  # 将待填充的放到第一列\n#     print(process_df.head())\n    # 分成已知该特征和未知该特征两部分\n    known = process_df[process_df.MonthlyIncome.notnull()].values\n    unknown = process_df[process_df.MonthlyIncome.isnull()].values\n    # X为特征属性值\n    X = known[:, 1:]\n    # y为结果标签值\n    y = known[:, 0]\n    # fit到RandomForestRegressor之中\n    rfr = RandomForestRegressor(random_state=0, n_estimators=200, max_depth=3, n_jobs=-1)\n    rfr.fit(X, y)\n    # 用得到的模型进行未知特征值预测\n    predicted = rfr.predict(unknown[:, 1:]).round(0)\n    print(predicted)\n    # 用得到的预测结果填补原缺失数据\n    df.loc[(df.MonthlyIncome.isnull()), 'MonthlyIncome'] = predicted\n    return df\ntrain_df = set_missing(train_df)\ntest_df = set_missing(test_df)\ntrain_df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T08:10:10.380558Z","iopub.execute_input":"2021-06-25T08:10:10.380879Z","iopub.status.idle":"2021-06-25T08:10:27.875039Z","shell.execute_reply.started":"2021-06-25T08:10:10.38085Z","shell.execute_reply":"2021-06-25T08:10:27.874011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.2.2 异常值处理\n\n","metadata":{}},{"cell_type":"markdown","source":"根据以上查看的数据情况进行数据整理，首先处理年龄的异常值，使用中位数代替，输出查看发现年龄异常值已被处理","metadata":{}},{"cell_type":"code","source":"train_df.loc[train_df['age'] == 0, 'age'] = train_df['age'].median()\ntest_df.loc[test_df['age'] == 0, 'age'] = test_df['age'].median()\ntrain_df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T08:10:27.876621Z","iopub.execute_input":"2021-06-25T08:10:27.87703Z","iopub.status.idle":"2021-06-25T08:10:28.011594Z","shell.execute_reply.started":"2021-06-25T08:10:27.876987Z","shell.execute_reply":"2021-06-25T08:10:28.010537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"接下来查看相关性","metadata":{}},{"cell_type":"code","source":"corr = train_df.corr()\nplt.figure(figsize=(19, 15))\nsns.heatmap(corr, annot=True, fmt='.2g')","metadata":{"execution":{"iopub.status.busy":"2021-06-25T08:10:28.014937Z","iopub.execute_input":"2021-06-25T08:10:28.015259Z","iopub.status.idle":"2021-06-25T08:10:29.231957Z","shell.execute_reply.started":"2021-06-25T08:10:28.01523Z","shell.execute_reply":"2021-06-25T08:10:29.230869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"由上图可见，NumberOfTime30-59DaysPastDueNotWorse, NumberOfTimes90DaysLate, NumberOfTime60-89DaysPastDueNotWorse三者相关性很大，因此查看三者的箱型图","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(19, 12)) \ntrain_df[['NumberOfTime30-59DaysPastDueNotWorse', \n          'NumberOfTime60-89DaysPastDueNotWorse',\n          'NumberOfTimes90DaysLate']].boxplot()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-25T08:10:29.234166Z","iopub.execute_input":"2021-06-25T08:10:29.234687Z","iopub.status.idle":"2021-06-25T08:10:30.071588Z","shell.execute_reply.started":"2021-06-25T08:10:29.234649Z","shell.execute_reply":"2021-06-25T08:10:30.070814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"因此很明显可以看到，在这三个特征之中有两组样本偏离了其他样本的分布，可以将其去除","metadata":{}},{"cell_type":"code","source":"train_df = train_df[train_df['NumberOfTime30-59DaysPastDueNotWorse']<90]","metadata":{"execution":{"iopub.status.busy":"2021-06-25T08:10:30.07268Z","iopub.execute_input":"2021-06-25T08:10:30.073072Z","iopub.status.idle":"2021-06-25T08:10:30.08374Z","shell.execute_reply.started":"2021-06-25T08:10:30.073043Z","shell.execute_reply":"2021-06-25T08:10:30.082872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 三、模型建立","metadata":{}},{"cell_type":"markdown","source":"## 3.1 数据设定","metadata":{}},{"cell_type":"markdown","source":"为了避免和交叉验证混淆，将train和test设定为其他名称","metadata":{}},{"cell_type":"code","source":"X = train_df.drop(['SeriousDlqin2yrs', 'ID'],axis=1)\ny = train_df['SeriousDlqin2yrs']\nW = test_df.drop(['SeriousDlqin2yrs', 'ID'],axis=1)\nz = test_df['SeriousDlqin2yrs']","metadata":{"execution":{"iopub.status.busy":"2021-06-25T08:10:30.085493Z","iopub.execute_input":"2021-06-25T08:10:30.086064Z","iopub.status.idle":"2021-06-25T08:10:30.11092Z","shell.execute_reply.started":"2021-06-25T08:10:30.086014Z","shell.execute_reply":"2021-06-25T08:10:30.10978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.2 建立模型——逻辑线性回归分类\n","metadata":{}},{"cell_type":"markdown","source":"由于数据不平衡会让监督学习算法过多关注多数类，使分类性能下降；由于数据量很大，因此可以尝试使用逻辑回归进行训练。","metadata":{}},{"cell_type":"code","source":"# 用线性回归模型\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split, cross_val_predict\nfrom sklearn.metrics import roc_curve, roc_auc_score\nfrom sklearn.preprocessing import StandardScaler\n\n# 划分训练集和测试集\nX_train, X_test, y_train, y_test = train_test_split(X,y,random_state=111)\n\n# 调用线性回归函数，C为正则化系数，l1表示L1正则化\nlogit = LogisticRegression(random_state=111, solver='saga', penalty='l1', class_weight='balanced', C=1.0, max_iter=500)\n\n# 标准化拟合\nscaler = StandardScaler().fit(X_train)\n\n# 标准化X_train 和X_test\nX_train_scaled = scaler.transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# 线性回归拟合\nlogit.fit(X_train_scaled, y_train)\n\n# 输入训练集，返回每个样本对应到每种分类结果的概率\nlogit_scores_proba = logit.predict_proba(X_train_scaled)\n\n# 返回分类1的概率\nlogit_scores = logit_scores_proba[:,1]\n\nprint(logit_scores)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T08:10:30.112444Z","iopub.execute_input":"2021-06-25T08:10:30.113053Z","iopub.status.idle":"2021-06-25T08:10:33.688217Z","shell.execute_reply.started":"2021-06-25T08:10:30.113004Z","shell.execute_reply":"2021-06-25T08:10:33.687079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"之后，绘制ROC曲线并得到AUC值","metadata":{}},{"cell_type":"code","source":"# 画图\ndef plot_roc_curve(fpr, tpr, label=None):\n    plt.figure(figsize=(6,5))\n    plt.plot(fpr, tpr, linewidth=2, label=label)\n    plt.plot([0,1],[0,1], \"k--\") # 画直线做参考\n    plt.axis([0,1,0,1])\n    plt.xlabel(\"False Positive Rate\")\n    plt.ylabel(\"True Positive rate\")\n# roc_curve根据分类结果和分类概率，返回false positive rage和true positive rate\nfpr_logit, tpr_logit, thresh_logit = roc_curve(y_train, logit_scores)\n\n# 画图\nplot_roc_curve(fpr_logit,tpr_logit)\nprint('AUC Score : ', (roc_auc_score(y_train,logit_scores)))","metadata":{"execution":{"iopub.status.busy":"2021-06-25T08:10:33.689859Z","iopub.execute_input":"2021-06-25T08:10:33.690526Z","iopub.status.idle":"2021-06-25T08:10:33.947012Z","shell.execute_reply.started":"2021-06-25T08:10:33.690475Z","shell.execute_reply":"2021-06-25T08:10:33.945904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 验证测试集，测试分类结果概率分布\nlogit_scores_proba_val = logit.predict_proba(X_test_scaled)\n\n# 分类结果为1的概率\nlogit_scores_val = logit_scores_proba_val[:,1]\n\n# roc_curve根据分类结果和分类概率，返回false positive rage和true positive rate\nfpr_logit_val, tpr_logit_val, thresh_logit_val = roc_curve(y_test, logit_scores_val)\n\n# 画图\nplot_roc_curve(fpr_logit_val,tpr_logit_val)\nprint('AUC Score :', (roc_auc_score(y_test,logit_scores_val)))","metadata":{"execution":{"iopub.status.busy":"2021-06-25T08:10:33.948543Z","iopub.execute_input":"2021-06-25T08:10:33.948895Z","iopub.status.idle":"2021-06-25T08:10:34.161972Z","shell.execute_reply.started":"2021-06-25T08:10:33.948865Z","shell.execute_reply":"2021-06-25T08:10:34.160919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"接下来交叉验证选择逻辑回归的正则化系数","metadata":{}},{"cell_type":"code","source":"# 采用LogisticRegressionCV来交叉验证选择正则化系数C\nfrom sklearn.linear_model import LogisticRegressionCV\nlogit = LogisticRegressionCV(Cs=[0.001, 0.01, 0.1, 1, 10, 100], penalty='l1', solver='saga', max_iter=500, class_weight='balanced', random_state=111)\n\n# 线性回归拟合\nlogit.fit(X_train_scaled, y_train)\n\nprint(logit.C_)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T08:10:34.163649Z","iopub.execute_input":"2021-06-25T08:10:34.164362Z","iopub.status.idle":"2021-06-25T08:11:13.612659Z","shell.execute_reply.started":"2021-06-25T08:10:34.164316Z","shell.execute_reply":"2021-06-25T08:11:13.611586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 输入训练集，返回每个样本对应到每种分类结果的概率\nlogit_scores_proba = logit.predict_proba(X_train_scaled)\n\n# 返回分类1的概率\nlogit_scores = logit_scores_proba[:,1]\n\n# roc_curve根据分类结果和分类概率，返回false positive rage和true positive rate\nfpr_logit, tpr_logit, thresh_logit = roc_curve(y_train, logit_scores)\n\n# 画图\nplot_roc_curve(fpr_logit,tpr_logit)\nprint('AUC Score : ', (roc_auc_score(y_train,logit_scores)))","metadata":{"execution":{"iopub.status.busy":"2021-06-25T08:11:13.614245Z","iopub.execute_input":"2021-06-25T08:11:13.614942Z","iopub.status.idle":"2021-06-25T08:11:13.883563Z","shell.execute_reply.started":"2021-06-25T08:11:13.614899Z","shell.execute_reply":"2021-06-25T08:11:13.882412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.3 建立模型——随机森林\n","metadata":{}},{"cell_type":"markdown","source":"接下来首先使用降采样，再随机森林模型进行拟合<br>\n降采样：","metadata":{}},{"cell_type":"code","source":"# 引入降采样模块\nfrom imblearn.under_sampling import RandomUnderSampler\n\n# Counter类的目的是用来跟踪值出现的次数\nfrom collections import Counter\nprint('Original dataset shape :', Counter(y))\n\n# 调用模块\nrus = RandomUnderSampler(random_state=111)\n\n# 直接降采样后返回采样后的数值\nX_resampled, y_resampled = rus.fit_resample(X, y)\nprint('Resampled dataset shape:', Counter(y_resampled))\n\n# 划分训练集和测试集\nfrom sklearn.model_selection import train_test_split\nX_train_rus, X_test_rus, y_train_rus, y_test_rus = train_test_split(X_resampled, y_resampled, random_state=111)\nX_train_rus.shape, y_train_rus.shape\n\n# 对重采样以后的数据进行分类\nlogit_resampled = LogisticRegression(random_state=111, solver='saga', penalty='l1', class_weight='balanced', C=1.0, max_iter=500)\n\nlogit_resampled.fit(X_resampled, y_resampled)\nlogit_resampled_proba_res = logit_resampled.predict_proba(X_resampled)\nlogit_resampled_scores = logit_resampled_proba_res[:, 1]\nfpr_logit_resampled, tpr_logit_resampled, thresh_logit_resampled = roc_curve(y_resampled, logit_resampled_scores)\nplot_roc_curve(fpr_logit_resampled, tpr_logit_resampled)\nprint('AUC score: ', roc_auc_score(y_resampled, logit_resampled_scores))","metadata":{"execution":{"iopub.status.busy":"2021-06-25T08:11:13.886332Z","iopub.execute_input":"2021-06-25T08:11:13.886813Z","iopub.status.idle":"2021-06-25T08:11:17.158465Z","shell.execute_reply.started":"2021-06-25T08:11:13.886766Z","shell.execute_reply":"2021-06-25T08:11:17.157402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"随机森林：","metadata":{}},{"cell_type":"code","source":"# 划分训练集\nfrom sklearn.model_selection import train_test_split\nX_train_rus, X_test_rus, y_train_rus, y_test_rus = train_test_split(X_resampled, y_resampled, random_state=111)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T08:11:17.159596Z","iopub.execute_input":"2021-06-25T08:11:17.159892Z","iopub.status.idle":"2021-06-25T08:11:17.169379Z","shell.execute_reply.started":"2021-06-25T08:11:17.159865Z","shell.execute_reply":"2021-06-25T08:11:17.168296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 采用随机森林法分类和梯度上升法\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nforest = RandomForestClassifier(n_estimators=300, random_state=111, max_depth=5, class_weight='balanced')\nforest.fit(X_train_rus, y_train_rus)\ny_scores_prob = forest.predict_proba(X_train_rus)\ny_scores = y_scores_prob[:, 1]\nfpr, tpr, thresh = roc_curve(y_train_rus, y_scores)\nplot_roc_curve(fpr, tpr)\nprint('AUC score:', roc_auc_score(y_train_rus, y_scores))","metadata":{"execution":{"iopub.status.busy":"2021-06-25T08:11:17.17097Z","iopub.execute_input":"2021-06-25T08:11:17.171424Z","iopub.status.idle":"2021-06-25T08:11:20.833989Z","shell.execute_reply.started":"2021-06-25T08:11:17.171379Z","shell.execute_reply":"2021-06-25T08:11:20.833192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"进行交叉验证","metadata":{}},{"cell_type":"code","source":"# 交叉验证\ny_test_proba = forest.predict_proba(X_test_rus)\ny_scores_test = y_test_proba[:, 1]\nfpr_test, tpr_test, thresh_test = roc_curve(y_test_rus, y_scores_test)\nplot_roc_curve(fpr_test, tpr_test)\nprint('AUC Score:', roc_auc_score(y_test_rus, y_scores_test))","metadata":{"execution":{"iopub.status.busy":"2021-06-25T08:11:20.835068Z","iopub.execute_input":"2021-06-25T08:11:20.835563Z","iopub.status.idle":"2021-06-25T08:11:21.389133Z","shell.execute_reply.started":"2021-06-25T08:11:20.835521Z","shell.execute_reply":"2021-06-25T08:11:21.388167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"接下来看看随机森林对各个特征的重视程度","metadata":{}},{"cell_type":"code","source":"def plot_feature_importances(model):\n    plt.figure(figsize=(10,8))\n    n_features = X.shape[1]\n    plt.barh(range(n_features), model.feature_importances_, align='center')\n    plt.yticks(np.arange(n_features), X.columns)\n    plt.xlabel('Feature importance')\n    plt.ylabel('Feature')\n    plt.ylim(-1, n_features)\n\nplot_feature_importances(forest)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T08:11:21.390623Z","iopub.execute_input":"2021-06-25T08:11:21.390981Z","iopub.status.idle":"2021-06-25T08:11:21.647381Z","shell.execute_reply.started":"2021-06-25T08:11:21.390951Z","shell.execute_reply":"2021-06-25T08:11:21.646299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"发现对RevolvingUtilizationOfUnsecuredLines属性最为重视\n### 3.4 模型建立——梯度提升树","metadata":{}},{"cell_type":"code","source":"gbc_clf = GradientBoostingClassifier(n_estimators=300, learning_rate=0.05, max_depth=8, random_state=112)\ngbc_clf.fit(X_train, y_train)\ngbc_clf_proba = gbc_clf.predict_proba(X_train)\ngbc_clf_scores = gbc_clf_proba[:, 1]\nfpr_gbc, tpr_gbc, thresh_gbc = roc_curve(y_train, gbc_clf_scores)\nplot_roc_curve(fpr_gbc, tpr_gbc)\nprint('AUC Score:', roc_auc_score(y_train, gbc_clf_scores))","metadata":{"execution":{"iopub.status.busy":"2021-06-25T08:11:21.648875Z","iopub.execute_input":"2021-06-25T08:11:21.649197Z","iopub.status.idle":"2021-06-25T08:13:59.671261Z","shell.execute_reply.started":"2021-06-25T08:11:21.649166Z","shell.execute_reply":"2021-06-25T08:13:59.670066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"交叉验证与参数调节","metadata":{}},{"cell_type":"code","source":"gbc_clf_submission = GradientBoostingClassifier(n_estimators=200, learning_rate=0.05 ,max_depth=4,  random_state=42)\ngbc_clf_submission.fit(X_train,y_train)\ngbc_clf_proba = gbc_clf_submission.predict_proba(X_train)\ngbc_clf_scores = gbc_clf_proba[:,1]\ngbc_val_proba = gbc_clf_submission.predict_proba(X_test)\ngbc_val_scores = gbc_val_proba[:,1]\nfpr_gbc, tpr_gbc, thresh_gbc = roc_curve(y_train, gbc_clf_scores)\nprint('AUC Score :', roc_auc_score(y_train, gbc_clf_scores))\nprint('AUC Score :', roc_auc_score(y_test, gbc_val_scores))","metadata":{"execution":{"iopub.status.busy":"2021-06-25T08:17:20.125394Z","iopub.execute_input":"2021-06-25T08:17:20.125773Z","iopub.status.idle":"2021-06-25T08:17:59.513461Z","shell.execute_reply.started":"2021-06-25T08:17:20.12574Z","shell.execute_reply":"2021-06-25T08:17:59.512399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_feature_importances(gbc_clf)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T08:18:07.536408Z","iopub.execute_input":"2021-06-25T08:18:07.536756Z","iopub.status.idle":"2021-06-25T08:18:07.750491Z","shell.execute_reply.started":"2021-06-25T08:18:07.536727Z","shell.execute_reply":"2021-06-25T08:18:07.748998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 四、保存","metadata":{}},{"cell_type":"markdown","source":"对比以上三个模型，发现GBC的模型准确率最高，因此将其保存","metadata":{}},{"cell_type":"code","source":"print(W.shape)\nsubmission_proba = gbc_clf_submission.predict_proba(W)\nsubmission_scores = submission_proba[:, 1]\nsubmission_scores.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-25T08:18:14.181303Z","iopub.execute_input":"2021-06-25T08:18:14.181806Z","iopub.status.idle":"2021-06-25T08:18:14.477608Z","shell.execute_reply.started":"2021-06-25T08:18:14.181764Z","shell.execute_reply":"2021-06-25T08:18:14.476734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ids = np.arange(1, 101504)\nsubmission = pd.DataFrame( {'Id': ids, 'Probability': submission_scores})\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T08:18:17.949162Z","iopub.execute_input":"2021-06-25T08:18:17.949509Z","iopub.status.idle":"2021-06-25T08:18:18.338734Z","shell.execute_reply.started":"2021-06-25T08:18:17.94948Z","shell.execute_reply":"2021-06-25T08:18:18.337762Z"},"trusted":true},"execution_count":null,"outputs":[]}]}