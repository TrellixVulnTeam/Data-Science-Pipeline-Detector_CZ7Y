{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/GiveMeSomeCredit'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 定义问题与数据读取\n* 本次竞赛的所要预测的问题：某人在未来两年内遭遇财务困境的可能性。","metadata":{}},{"cell_type":"code","source":"#读取数据\ntrain_df = pd.read_csv('/kaggle/input/GiveMeSomeCredit/cs-training.csv')\ntest_df = pd.read_csv('/kaggle/input/GiveMeSomeCredit/cs-test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  数据探索与预处理\n> **1. 数据探索**","metadata":{}},{"cell_type":"code","source":"train_df.head()   #查看训练集前5行数据","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head()    #查看测试集前5行数据","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.columns   #查看训练集的特征","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"分类型特征：SeriousDlqin2yrs\n\n数值型特征：\n              比率标度：RevolvingUtilizationOfUnsecuredLines、DebtRatio\n              连续型特征：age、MonthlyIncome\n              离散型特征：NumberOfOpenCreditLinesAndLoans、NumberOfTime30-   59DaysPastDueNotWorse、NumberOfTime60-89DaysPastDueNotWorse、NumberOfTimes90DaysLate、NumberOfDependents","metadata":{}},{"cell_type":"code","source":"train_df.info()        #查看训练集信息","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"训练集总共有150000条数据，数据类型都是int和float，MonthlyIncome（月收入）和NumberOfDependents（家属数量）有缺失值","metadata":{}},{"cell_type":"code","source":"test_df.info()    ##查看测试集信息","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"测试集总共有101503条数据，MonthlyIncome和NumberOfDependents都有缺失值。","metadata":{}},{"cell_type":"markdown","source":"**查看缺失值**","metadata":{}},{"cell_type":"code","source":"train_df.isnull().sum()   #具体查看训练集缺失值","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.isnull().sum()    #具体查看测试集缺失值","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"训练集和测试集的缺失值数量都占比较大，所以不能直接删除。\nMonthlyIncome属于连续型数值特征，且缺失较多，可以用平均数填补缺失值。NumberOfDependents可以用中位数填充空值。","metadata":{}},{"cell_type":"markdown","source":"**查看异常值**","metadata":{}},{"cell_type":"code","source":"train_df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"训练集和测试集RevolvingUtilizationOfUnsecuredLines在75%值为0.55，最大值却为50578，可能分布不均或是异常值存在。DebtRatio也是同样的问题。NumberOf-Time30-59DaysPastDueNotWorse, NumberOfTimes90DaysLate, NumberOfTime60-89DaysPastDueNotWorse三种的最大值都是98。训练集age最小值存在0，有异常值。家属数量最大值有43。","metadata":{}},{"cell_type":"code","source":"train_df.describe(percentiles=[.61, .62, .68, .69, .75, .8, .99])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"具体查看一下age的情况","metadata":{}},{"cell_type":"code","source":"train_df.loc[train_df['age'] < 18]    #查看age小于18的情况","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"age小于18的数据只有一条，用中位数填充就好","metadata":{}},{"cell_type":"markdown","source":"查看以下三条相近特征的箱线图，看是否有异常值","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 5)) \ntrain_df[['NumberOfTime30-59DaysPastDueNotWorse', \n          'NumberOfTime60-89DaysPastDueNotWorse',\n          'NumberOfTimes90DaysLate']].boxplot()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"可以看到三个特征都存在异常点，将异常值都删掉。","metadata":{}},{"cell_type":"code","source":"# 查看SeriousDlqin2yrs分布\nplt.figure()\nsns.countplot('SeriousDlqin2yrs',data=train_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"可以看到为0的占比大多数，分类非常不平衡，可能会造成预测性能下降。","metadata":{}},{"cell_type":"code","source":"correlation = train_df.corr()\nf , ax = plt.subplots(figsize = (13, 13))\nplt.title('heatmap',y=1,size=16)\nsns.heatmap(correlation,annot = True,  vmax=0.8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"这时的热力图是还没消除异常值的情况下","metadata":{}},{"cell_type":"code","source":"age=train_df['age']\nsns.distplot(age)\nplt.show()\n\nmi=train_df[train_df['MonthlyIncome']<50000]['MonthlyIncome']\nsns.distplot(mi)\nplt.show()      #观察图，年龄和收入分布皆近似正态分布！）","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"年龄和收入分布近似正态分布。","metadata":{}},{"cell_type":"markdown","source":"# 2.数据预处理 ","metadata":{}},{"cell_type":"code","source":"train_df.drop_duplicates(inplace=True)    #去重","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"对未命名的第一列重命名为ID，方便观察。","metadata":{}},{"cell_type":"code","source":"train_df.rename(columns={'Unnamed: 0':'ID'}, inplace=True)\ntest_df.rename(columns={'Unnamed: 0':'ID'}, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"将NumberOf-Time30-59DaysPastDueNotWorse, NumberOfTimes90Days-Late, NumberOfTime60-89DaysPastDueNotWorse大于90的点删除。","metadata":{}},{"cell_type":"code","source":"train_df = train_df[train_df['NumberOfTime30-59DaysPastDueNotWorse'] < 90] \ntrain_df = train_df[train_df['NumberOfTimes90DaysLate'] < 90] \ntrain_df = train_df[train_df['NumberOfTime60-89DaysPastDueNotWorse'] < 90] ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"家属人数大于8的设为8。","metadata":{}},{"cell_type":"code","source":"k = 0\nfor i in train_df['NumberOfDependents']:\n    if i>8:\n        train_df['NumberOfDependents'].values[k]=8\n    k +=1\nk = 0\nfor i in test_df['NumberOfDependents']:\n    if i>8:\n        test_df['NumberOfDependents'].values[k]=8\n    k +=1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"age为0的用中位数填充。","metadata":{}},{"cell_type":"code","source":"k = 0\nfor i in test_df['age']:\n    if i==0:\n        test_df['age'].values[k]=test_df['age'].median()\n    k +=1\nk = 0\nfor i in train_df['age']:\n    if i==0:\n        train_df['age'].values[k]=train_df['age'].median()\n    k +=1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"用中位数填充年龄小于18的数据。","metadata":{}},{"cell_type":"code","source":"train_df.loc[train_df['age'] < 18, 'age'] = train_df['age'].median()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"用平均数填充MonthlyIncome空值，用中位数填充NumberOf-Dependents空值。","metadata":{}},{"cell_type":"code","source":"train_df['MonthlyIncome'] = train_df['MonthlyIncome'].replace(np.nan,train_df['MonthlyIncome'].mean())\ntest_df['MonthlyIncome'] = test_df['MonthlyIncome'].replace(np.nan,test_df['MonthlyIncome'].mean())\ntrain_df['NumberOfDependents'] = train_df['NumberOfDependents'].replace(np.nan,train_df['NumberOfDependents'].median())\ntest_df['NumberOfDependents'] = test_df['NumberOfDependents'].replace(np.nan,test_df['NumberOfDependents'].median())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"划分训练集合测试集。","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx = train_df.drop(['SeriousDlqin2yrs', 'ID'],axis=1)\ny= train_df['SeriousDlqin2yrs']\nx_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"写出绘图auc曲线函数","metadata":{}},{"cell_type":"code","source":"#auc绘图\ndef plot_roc_curve(fpr, tpr, label=None):\n    plt.figure(figsize=(8,6))\n    plt.plot(fpr, tpr, linewidth=2, label=label)\n    plt.plot([0,1],[0,1], \"k--\") # 画直线做参考\n    plt.axis([0,1,0,1])\n    plt.xlabel(\"False Positive Rate\")\n    plt.ylabel(\"True Positive rate\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3.模型选择","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, roc_curve, auc, roc_auc_score\n#随机森林\nfrom  sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier(random_state=42)\nrfc.fit(x_train,y_train)\npred=rfc.predict_proba(x_test)[:,1]\nfpr, tpr, _ = roc_curve(y_test, pred)\nroc_auc = auc(fpr,tpr)\nplot_roc_curve(fpr,tpr)\nprint ('AUC Score :', roc_auc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBClassifier\nmodel = XGBClassifier(max_depth=5,eval_metric='auc',objective='binary:logistic')\nmodel.fit(x_train, y_train)\n# make predictions for test data\ny_pred = model.predict_proba(x_test)[:,1]\n# evaluate predictions\nfpr, tpr, _ = roc_curve(y_test, y_pred)\nroc_auc = auc(fpr,tpr)\nprint ('AUC Score :', roc_auc)\nplot_roc_curve(fpr,tpr)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom sklearn.ensemble import GradientBoostingClassifier\ngbc_clf_submission = GradientBoostingClassifier()\ngbc_clf_submission.fit(x_train,y_train)\ngbc_clf_proba = gbc_clf_submission.predict_proba(x_test)[:,1]\nfpr, tpr, _ = roc_curve(y_test, gbc_clf_proba)\nroc_auc = auc(fpr,tpr)\nprint ('AUC Score :', roc_auc)\nplot_roc_curve(fpr,tpr)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4.优化调参","metadata":{}},{"cell_type":"markdown","source":"先对提升框架内的，迭代次数和学习率做调整，选一个较小的学习率，对迭代次数网格化调参。","metadata":{}},{"cell_type":"code","source":"# from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n# param_test1 = {'n_estimators':range(20,81,10)}\n# gsearch1 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, min_samples_split=300,\n#                                   min_samples_leaf=20,max_depth=8,max_features='sqrt', subsample=0.8,random_state=10),\n#                        param_grid = param_test1, scoring='roc_auc',cv=5)\n# gsearch1.fit(x_train,y_train)\n# means = gsearch1.cv_results_['mean_test_score']\n# params = gsearch1.cv_results_['params']\n# print(means)\n# print(params)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"找到了一个合适的迭代次数，现在开始对决策树进行调参。首先我们对决策树最大深度max_depth和内部节点再划分所需最小样本数min_samples_split进行网格搜索。","metadata":{}},{"cell_type":"code","source":"# param_test2 = {'max_depth':range(3,10,2), 'min_samples_split':range(100,801,200)}\n# gsearch2 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=50, min_samples_leaf=20, \n#       max_features='sqrt', subsample=0.8, random_state=10), \n#    param_grid = param_test2, scoring='roc_auc', cv=5)\n# gsearch2.fit(x_train,y_train)\n# means = gsearch2.cv_results_['mean_test_score']\n# params = gsearch2.cv_results_['params']\n# print(means)\n# print(params)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"由于决策树深度7是一个比较合理的值，所以把它定下来，对于内部节点再划分所需最小样本数min_samples_split，暂时不能一起定下来，因为这个和决策树其他的参数存在关联。再对min_samples_split和min_samples_leaf一起调参。","metadata":{}},{"cell_type":"code","source":"# param_test3 = {'min_samples_split':range(800,1900,200), 'min_samples_leaf':range(60,101,10)}\n# gsearch3 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=50,max_depth=7,\n#                                      max_features='sqrt', subsample=0.8, random_state=10), \n#                        param_grid = param_test3, scoring='roc_auc', cv=5)\n# gsearch3.fit(x_train,y_train)\n# means = gsearch3.cv_results_['mean_test_score']\n# params = gsearch3.cv_results_['params']\n# print(means)\n# print(params)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# gbm1 = GradientBoostingClassifier(learning_rate=0.1, n_estimators=50,max_depth=7, min_samples_leaf =120, \n#                min_samples_split =1000, max_features='sqrt', subsample=0.8, random_state=10)\n# gbm1.fit(x_train,y_train)\n# gbc_clf_proba = gbm1.predict_proba(x_test)[:,1]\n# y_pred = gbm1.predict(x_test)\n# fpr, tpr, _ = roc_curve(y_test, gbc_clf_proba)\n# roc_auc = auc(fpr,tpr)\n# plot_roc_curve(fpr,tpr)\n# print ('AUC Score :', roc_auc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# param_test4 = {'max_features':range(1,9)}\n# gsearch4 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=50,max_depth=7, min_samples_leaf =120, \n#                min_samples_split =1000, subsample=0.8, random_state=10), \n#                        param_grid = param_test4, scoring='roc_auc', cv=5)\n# gsearch4.fit(x_train,y_train)\n# means = gsearch4.cv_results_['mean_test_score']\n# params = gsearch4.cv_results_['params']\n# print(means)\n# print(params)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# param_test5 = {'subsample':[0.6,0.7,0.75,0.8,0.85,0.9]}\n# gsearch5 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=50,max_depth=7, min_samples_leaf =120, \n#                min_samples_split =1000, max_features=4, random_state=10), \n#                        param_grid = param_test5, scoring='roc_auc', cv=5)\n# gsearch5.fit(x_train,y_train)\n# means = gsearch5.cv_results_['mean_test_score']\n# params = gsearch5.cv_results_['params']\n# print(means)\n# print(params)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gbm1 = GradientBoostingClassifier(learning_rate=0.01, n_estimators=900,max_depth=7, min_samples_leaf =120, \n               min_samples_split =1000, max_features='sqrt', subsample=0.8, random_state=10)\ngbm1.fit(x_train,y_train)\ngbc_clf_proba = gbm1.predict_proba(x_test)[:,1]\ny_pred = gbm1.predict(x_test)\nfpr, tpr, _ = roc_curve(y_test, gbc_clf_proba)\nroc_auc = auc(fpr,tpr)\nplot_roc_curve(fpr,tpr)\nprint ('AUC Score :', roc_auc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = test_df.drop(['SeriousDlqin2yrs', 'ID'],axis=1)\ngbc_clf_proba = gbm1.predict_proba(test_df)[:,1]\nids = np.arange(1,101504)\nsubmission = pd.DataFrame( {'Id': ids, 'Probability': gbc_clf_proba})\nsubmission.to_csv(\"submision.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"最后运用新参数拟合模型，得到最终模型。","metadata":{}}]}