{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/GiveMeSomeCredit/cs-training.csv')\ntrain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test=pd.read_csv('/kaggle/input/GiveMeSomeCredit/cs-test.csv')\ntest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train2=train.drop(['Unnamed: 0', 'SeriousDlqin2yrs'], axis=1)\ntrain2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test2=test.drop(['Unnamed: 0', 'SeriousDlqin2yrs'], axis=1)\ntest2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train2=train2.fillna(0)\ntest2=test2.fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.model_selection import train_test_split\n# x_train, x_valid, y_train, y_valid=train_test_split(train2, train['SeriousDlqin2yrs'], random_state=42)\n# x_train.shape, x_valid.shape, y_train.shape, y_valid.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.ensemble import RandomForestClassifier\n# rf=RandomForestClassifier(n_jobs=4, random_state=42)\n# rf.fit(train2, train['SeriousDlqin2yrs'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# rf(배깅) -> 데이터 랜덤샘플링, oob / 칼럼마저도 랜덤 _ 어떤 칼럼이 중요한지 파악함 _ 중요한 칼럼만 학습하는..\n# 나무를 많이 만드는 혜택이 없음, 다양성을 추구해야 함 // 베이스라인만 해도 커버할 수 있음(이상치~) // 일반화 파워\n# 나무를 다양하게 만들어서(칼럼, 데이터 등) -> 앙상블 / 나무들끼리 상관관계가 없음.. \n \n# xgb(부스팅) 비슷하지만 상관관계가 가능 / 전 나무를 적용 / 성능이 좋아진다는 뜻은 train 세세하게 더 복잡하게\n# 오버피팅(과대적합) 문제 발생, 따라서 리더보드 점수가 높아지는 것은 아님 / 옵션 설정을 제대로 해야함\n\n# 데이터 분석 순서 / rf(배깅)을 통해 실험, 전처리를 함 -> xgb(부스팅)로 고도화 / 옵션설정만 제대로 하면.. 최상위권  \n\n# tree 모델의 약점_ 앙상블 기법이 대세네\n\n# 러닝레이트 0.3 디폴트 / 그래디언트 y(손실함수, 위험률)=x2 x가 몇일때 가장 최적이냐 -> 기울기가 0일때\n# 처음에는 x가 0인 지점을 찾을 수 없음 ri / 데이터에 따라 학습을 함 /  19 <- 20 -> 21 방향에 대한 이해, 19쪽으로 판단하고 줄임\n# 얼마나 빠르게 step size-> learing_rate / 0.1 이하로 줄이면 문제가 발생함\n# 다차원의 함수 최적의 러닝레이트를 찾는 것이 중요하겠네 / 러닝레이트가 낮아질수록 옵션이 추가\n\nfrom xgboost import XGBClassifier\nxgb=XGBClassifier(learning_rate=0.1)\nxgb.fit(train2, train['SeriousDlqin2yrs'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# result=rf.predict_proba(test2)\n# result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result=xgb.predict_proba(test2)\nresult","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test['SeriousDlqin2yrs']=result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.model_selection import mean_squared_error\n# np.sqrt(mean_squared_error(y_valid, result))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub=pd.read_csv('/kaggle/input/GiveMeSomeCredit/sampleEntry.csv')\nsub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['Probability']=result[:,1]\nsub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv('givemesomecreadit4.csv', index=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}