{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-21T07:14:37.682273Z","iopub.execute_input":"2021-05-21T07:14:37.682754Z","iopub.status.idle":"2021-05-21T07:14:37.699299Z","shell.execute_reply.started":"2021-05-21T07:14:37.682647Z","shell.execute_reply":"2021-05-21T07:14:37.698302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input = !ls /kaggle/input\ninput = '/kaggle/input/{}/'.format(input[0])\noutput = '/kaggle/working/'\n\nprint(input, output)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:14:37.700707Z","iopub.execute_input":"2021-05-21T07:14:37.701046Z","iopub.status.idle":"2021-05-21T07:14:37.7265Z","shell.execute_reply.started":"2021-05-21T07:14:37.700993Z","shell.execute_reply":"2021-05-21T07:14:37.725353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## 基础工具\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestRegressor\nimport seaborn as sns\nimport scipy\nimport math\n\nnp.random.seed(2021)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:14:37.728579Z","iopub.execute_input":"2021-05-21T07:14:37.728857Z","iopub.status.idle":"2021-05-21T07:14:38.138353Z","shell.execute_reply.started":"2021-05-21T07:14:37.728823Z","shell.execute_reply":"2021-05-21T07:14:38.137591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def float_check(x):\n    '''\n    检测浮点数的小数位数\n    9    103589 （保留）\n    1     33551 （=0的需要处理，其它的酌情）\n    8     10636 （保留）\n    7      1047 （保留）\n    6       135 （保留）\n    4        76 （保留）\n    3        56 （保留）\n    5        51 （保留）\n    2        22 （保留）\n    0         1  drop\n    '''\n    if '.' in str(x):\n        return(len(str(x).split('.')[-1]))\n    else :\n        return 0\n    \ndef float_last(x):\n    if '.' in str(x):\n        return(str(x)[-1])\n    else :\n        return False\n    \ndef sample_Interval(col, start, end, closed):\n    '''\n    去除首尾异常值，利用分组\n    直接操作DataFrame对象\n    start, end 是单个值\n    '''\n    z = 0.0000000001\n    global df_train\n    interval_index = pd.IntervalIndex.from_arrays([start], [end+z], closed=closed)\n    x = pd.cut(df_train[col], interval_index, right=False)\n    print(col,'drop：',x.isnull().sum())\n    df_train = df_train[x.notnull()]\n    \n\ndef make_box(col, box_index):\n    '''\n    col, start, end, closed 含义参考pd.IntervalIndex.from_arrays()\n    做分组用\n    type(n): int IntervalIndex\n    n=5\n    n=pd.IntervalIndex.from_arrays([start], [end+z], closed=closed)\n    right:This argument is ignored when bins is an IntervalIndex.\n    '''\n    global df_train, box\n    \n    # 切割数据\n    base = pd.IntervalIndex.from_arrays([1], [2], closed='left')\n    if type(box_index)==type([]):\n        n = box_index[0]\n        right = True if box_index[1]=='right' else False\n        cut = pd.cut(df_train[col], n, right=right)\n    elif type(box_index)==type(base):\n        interval_index = pd.IntervalIndex.from_arrays(box_index[0], box_index[1], closed=box_index[2])\n        cut = pd.cut(df_train[col], interval_index)\n    else:\n        print(\"box_index 的类型错误\")\n        print(box_index)\n        return 1\n    \n    Customer = df_train['SeriousDlqin2yrs'].groupby(cut).count()\n    Bad = df_train['SeriousDlqin2yrs'].groupby(cut).sum()\n    Good = Customer-Bad\n    box_col = pd.merge(pd.DataFrame(Customer),pd.DataFrame(Bad) ,left_index=True,right_index=True)\n    box_col.rename(columns={'SeriousDlqin2yrs_x':'CustomerNumber','SeriousDlqin2yrs_y':'Bad'},inplace=True)\n    box_col.insert(0, \"Feature\", col)\n    box_col.insert(len(box_col.columns), \"Good\", Customer-Bad)\n    box_col.insert(len(box_col.columns), \"BadRatio\", Bad/Customer)\n    box_col.index.name = 'Id'\n    return box_col\n    \ndef correlation_analysis():\n    global box_col, features\n    fig,subs=plt.subplots(math.ceil(len(features)/2), 2, figsize=(20,23))\n\n    for i,col in enumerate(features):\n        box_col = box[box['Feature']==col]\n        sub_a = i//2\n        sub_b = i%2\n        # 图A\n        labels = box_col.index.tolist()\n        Good_data = box_col['Good']\n        Bad_data = box_col['Bad']\n        BadRatio_data = box_col['BadRatio']*box_col['CustomerNumber']\n        # x轴是由[1,2,3,4,5] 组成\n        x=np.arange(len(labels))\n        width = 0.35\n        #fig,ax  = plt.subplots()\n        # 先画Good\n        bar1 = subs[sub_a][sub_b].bar(x-width/2, Good_data, width, label='Good')\n        for rect in bar1:\n            height = rect.get_height()\n            #annotate函数是用来对图像进行标注，\n            #参数xy表示标注位置\n            # xytext表示文本位置（在xy的位置进行多少偏移）\n            subs[sub_a][sub_b].annotate('{}'.format(height),\n                        xy=(rect.get_x()+rect.get_width()/2,height),\n                        xytext=(0,3),\n                        textcoords='offset points',\n                        ha = 'center',\n                        va = 'bottom',fontsize=8)\n        # 再画Bad\n        bar2 = subs[sub_a][sub_b].bar(x+width/2, Bad_data, width, label='Bad')\n        # 再画折线\n        subs[sub_a][sub_b].plot(BadRatio_data.to_list(), color='red', label='BadRatio')\n        for rect in bar2:\n            height = rect.get_height()\n            #annotate函数是用来对图像进行标注，\n            #参数xy表示标注位置\n            # xytext表示文本位置（在xy的位置进行多少偏移）\n            subs[sub_a][sub_b].annotate('{}'.format(height),\n                        xy=(rect.get_x()+rect.get_width()/2,height),\n                        xytext=(0,3),\n                        textcoords='offset points',\n                        ha = 'center',\n                        va = 'bottom', fontsize=8)\n        # 设置图像的一些参数\n        subs[sub_a][sub_b].set_ylabel('Customer Number')\n        subs[sub_a][sub_b].set_title('Customer Number by {}'.format(col))\n        subs[sub_a][sub_b].set_xticks(x)\n        subs[sub_a][sub_b].set_xticklabels(labels, rotation=15, fontsize=10)\n        subs[sub_a][sub_b].legend()\n\n\n    #tight_layout()，作用是自动调整子图参数，使之填充整个图像区域。\n    fig.tight_layout()\n    fig.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:14:38.139836Z","iopub.execute_input":"2021-05-21T07:14:38.140414Z","iopub.status.idle":"2021-05-21T07:14:38.165972Z","shell.execute_reply.started":"2021-05-21T07:14:38.140375Z","shell.execute_reply":"2021-05-21T07:14:38.165344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Step1： 加载数据\ncs_training = pd.read_csv(input+'cs-training.csv')\ncs_training = cs_training.iloc[:, 1:]\ndf_train = cs_training.copy()","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:14:38.167046Z","iopub.execute_input":"2021-05-21T07:14:38.167498Z","iopub.status.idle":"2021-05-21T07:14:38.340715Z","shell.execute_reply.started":"2021-05-21T07:14:38.167472Z","shell.execute_reply":"2021-05-21T07:14:38.340022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = [*df_train.columns]\nfeatures.remove('SeriousDlqin2yrs')\ndescribe = df_train.describe()","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:14:38.34183Z","iopub.execute_input":"2021-05-21T07:14:38.342174Z","iopub.status.idle":"2021-05-21T07:14:38.425118Z","shell.execute_reply.started":"2021-05-21T07:14:38.342128Z","shell.execute_reply":"2021-05-21T07:14:38.424151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Step2：去除重复值并恢复索引\ndf_train.drop_duplicates(inplace=True)\n\n# Step3：发现 “MonthlyIncome”和“NumberOfDependents” 包含大量缺失值\n# 使用均值填补“NumberOfDependents”的缺失值\ndf_train[\"NumberOfDependents\"].fillna(int(df_train[\"NumberOfDependents\"].mean()),inplace=True)\n# 使用均值填补 “MonthlyIncome” 的缺失值\ndf_train['MonthlyIncome'].fillna(df_train['MonthlyIncome'].mean(),inplace=True)\n\n# 查看缺失值比例，预期不能有缺失值\ndisplay(df_train.isna().sum()/df_train.shape[0])\n\n# Step4：处理异常值\n# 描述性统计\ndisplay(df_train.describe([.01,.1,.25,.5,.75,.9,.99]).T)\n\n# '''  异常值处理规则\n# RevolvingUtilizationOfUnsecuredLines，[min, max+0.0000000001)\n# age，[min, max+0.0000000001)\n# NumberOfTime30-59DaysPastDueNotWorse， [min,80)\n# NumberOfTime60-89DaysPastDueNotWorse，  [min,80)\n# NumberOfTimes90DaysLate，  [min,80)\n# NumberRealEstateLoansOrLines,  [min, max+0.0000000001)\n# DebtRatio，应该是比率，23%的大于1,很多数据包含整数，最大值逆天了，先自动分组，然后处理异常值 [min, max+0.0000000001)\n# MonthlyIncome， [min, max+0.0000000001)\n# NumberOfOpenCreditLinesAndLoans，[min, max+0.0000000001)\n# NumberOfDependents, [min, max+0.0000000001)\n# '''\n# 另一个可选的方案是将异常值分箱\n# print(df_train.shape)\n# col = 'RevolvingUtilizationOfUnsecuredLines'\n# sample_Interval(col, describe[col]['min'], describe[col]['max'], 'left')\n# col = 'NumberOfTime30-59DaysPastDueNotWorse'\n# sample_Interval('NumberOfTime30-59DaysPastDueNotWorse', describe[col]['min'], 80, 'left')\n# col = 'NumberOfTime60-89DaysPastDueNotWorse'\n# sample_Interval('NumberOfTime60-89DaysPastDueNotWorse', describe[col]['min'], 80, 'left')\n# col = 'NumberOfTimes90DaysLate'\n# sample_Interval('NumberOfTimes90DaysLate', describe[col]['min'], 80, 'left')\n# print(df_train.shape)\n\n\n# Step5：columns转置成中文，由于不能解决kaggle画图显示中文的问题\n# columns_translate ={'SeriousDlqin2yrs':'客户分类',\n#         'RevolvingUtilizationOfUnsecuredLines':'可用额度比值',\n#         'age':'年龄',\n#         'NumberOfTime30-59DaysPastDueNotWorse':'逾期30-59天笔数',\n#         'DebtRatio':'负债率',\n#         'MonthlyIncome':'月收入',\n#         'NumberOfOpenCreditLinesAndLoans':'信贷数量',\n#         'NumberOfTimes90DaysLate':'逾期90天笔数',\n#         'NumberRealEstateLoansOrLines':'固定资产贷款量',\n#         'NumberOfTime60-89DaysPastDueNotWorse':'逾期60-89天笔数',\n#         'NumberOfDependents':'家属数量'}\n# column_bak = dict(map(reversed, columns_translate.items()))\n# df_train.rename(columns=column_bak, inplace=True)\n# df_train.head()    #修改英文字段名为中文字段名\n\n\n\n#-----------------------------\n","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:14:38.427269Z","iopub.execute_input":"2021-05-21T07:14:38.427548Z","iopub.status.idle":"2021-05-21T07:14:38.602914Z","shell.execute_reply.started":"2021-05-21T07:14:38.427522Z","shell.execute_reply":"2021-05-21T07:14:38.601926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Step6：相关性分析\nbox_index = {\n    'RevolvingUtilizationOfUnsecuredLines': [4, 'left'],\n    'age': [4,'left'],\n    # 'age': pd.IntervalIndex.from_arrays([min], [max+z]], closed='left')\n    # 'age': pd.IntervalIndex.from_arrays([21,31,41,51,61], [30,40,50,60,float('inf')]], closed='left')\n    'NumberOfTime30-59DaysPastDueNotWorse': [4,'left'],\n    'NumberOfTime60-89DaysPastDueNotWorse':[4,'left'],\n    'NumberOfTimes90DaysLate': [4,'left'],\n    'DebtRatio': [4,'left'],\n    'MonthlyIncome': [4,'left'],\n    'NumberOfOpenCreditLinesAndLoans': [4,'left'],\n    'NumberRealEstateLoansOrLines': [4,'left'],\n    'NumberOfDependents': [4,'left']\n}\nbox = pd.DataFrame()\nfor col in features:\n    box=box.append(make_box(col, box_index[col]))\n\n# display(box)\n# 等分的效果并不怎么样\ncorrelation_analysis()\n\n# 多变量分析\ncorr = df_train.corr()\ncmap = sns.diverging_palette(200,20,sep=20,as_cmap=True)\nf,ax = plt.subplots(figsize=(15, 10))\nsns.heatmap(corr, annot=True, cmap=cmap, annot_kws={'size':10}, linewidths=.5, fmt= '.3f',ax=ax)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:14:38.604424Z","iopub.execute_input":"2021-05-21T07:14:38.60465Z","iopub.status.idle":"2021-05-21T07:14:42.301532Z","shell.execute_reply.started":"2021-05-21T07:14:38.604628Z","shell.execute_reply":"2021-05-21T07:14:42.300586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Step7：样本不均衡问题\nX = df_train.drop('SeriousDlqin2yrs',axis=1)\ny = df_train['SeriousDlqin2yrs']\nsns.countplot(x='SeriousDlqin2yrs', data=df_train)\nplt.show()\n# 使用SMOTE方法进行过抽样处理\nfrom imblearn.over_sampling import SMOTE # 过抽样处理库SMOTE\nmodel_smote = SMOTE() # 建立SMOTE模型对象\nX,y = model_smote.fit_resample(X,y) # 输入数据并作过抽样处理\nsmote_resampled = pd.concat([X, y],axis=1) # 按列合并数据框\ngroupby_data_smote = smote_resampled.groupby('SeriousDlqin2yrs').count() # 对label做分类汇总\ngroupby_data_smote # 打印输出经过SMOTE处理后的数据集样本分类分布\nsns.countplot(x='SeriousDlqin2yrs',data=smote_resampled)\nplt.show()\n\n# 该方法导致AUC低于0.8","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:14:42.30265Z","iopub.execute_input":"2021-05-21T07:14:42.302915Z","iopub.status.idle":"2021-05-21T07:14:42.85675Z","shell.execute_reply.started":"2021-05-21T07:14:42.30289Z","shell.execute_reply":"2021-05-21T07:14:42.855883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 切分数据集\nfrom sklearn.model_selection import train_test_split\nx = df_train.drop('SeriousDlqin2yrs',axis=1)\ny = df_train['SeriousDlqin2yrs']\n\nx_train,x_vali,y_train,y_vali = train_test_split(x,y,test_size=0.3,random_state=2021)\n\ntrain_data = pd.concat([y_train,x_train],axis=1)\ntrain_data.index = range(train_data.shape[0])\ntrain_data.columns = df_train.columns\n\ntest_data = pd.concat([y_vali,x_vali],axis=1)\ntest_data.index = range(test_data.shape[0])\ntest_data.columns = df_train.columns\n\n# Step8： 找到合适的分箱方法","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:15:40.143998Z","iopub.execute_input":"2021-05-21T07:15:40.144379Z","iopub.status.idle":"2021-05-21T07:15:40.182325Z","shell.execute_reply.started":"2021-05-21T07:15:40.14435Z","shell.execute_reply":"2021-05-21T07:15:40.181488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n有监督方法：基于sklearn决策树的最优分箱与IV值计算\n'''\nfrom sklearn.tree import DecisionTreeClassifier\n\ndef optimal_binning_boundary(x: pd.Series, y: pd.Series, nan: float = -999.) -> list:\n    '''\n        利用决策树获得最优分箱的边界值列表\n    '''\n    boundary = []  # 待return的分箱边界值列表\n    \n    x = x.fillna(nan).values  # 填充缺失值\n    y = y.values\n    \n    clf = DecisionTreeClassifier(criterion='entropy',    #“信息熵”最小化准则划分\n                                 max_leaf_nodes=6,       # 最大叶子节点数\n                                 min_samples_leaf=0.05)  # 叶子节点样本数量最小占比\n    \n    clf.fit(x.reshape(-1, 1), y)  # 训练决策树\n    \n    n_nodes = clf.tree_.node_count\n    children_left = clf.tree_.children_left\n    children_right = clf.tree_.children_right\n    threshold = clf.tree_.threshold\n    \n    for i in range(n_nodes):\n        if children_left[i] != children_right[i]:  # 获得决策树节点上的划分边界值\n            boundary.append(threshold[i])\n    \n    boundary.sort()\n    \n    z = 0.0000000001\n    min_x = x.min()\n    max_x = x.max() + z  # +0.1是为了考虑后续groupby操作时，能包含特征最大值的样本\n    boundary = [min_x] + boundary + [max_x]\n    \n    return boundary","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-05-21T07:15:41.265576Z","iopub.execute_input":"2021-05-21T07:15:41.265901Z","iopub.status.idle":"2021-05-21T07:15:41.274521Z","shell.execute_reply.started":"2021-05-21T07:15:41.265873Z","shell.execute_reply":"2021-05-21T07:15:41.273581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 测试optimal_binning_boundary函数：\noptimal_binning_boundary(x=train_data['RevolvingUtilizationOfUnsecuredLines'],\n                         y=train_data['SeriousDlqin2yrs'])","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:15:41.639099Z","iopub.execute_input":"2021-05-21T07:15:41.639664Z","iopub.status.idle":"2021-05-21T07:15:41.729899Z","shell.execute_reply.started":"2021-05-21T07:15:41.639606Z","shell.execute_reply":"2021-05-21T07:15:41.728901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 获得某个变量各个分箱的WOE、IV值函数的实现：\ndef feature_woe_iv(feature: str, x: pd.Series, y: pd.Series, nan: float = -999.) -> pd.DataFrame:\n    '''\n        计算变量各个分箱的WOE、IV值，返回一个DataFrame\n    '''\n    x = x.fillna(nan)\n    boundary = optimal_binning_boundary(x, y, nan)        # 获得最优分箱边界值列表\n    df = pd.concat([x, y], axis=1)                        # 合并x、y为一个DataFrame，方便后续计算\n    df.columns = ['x', 'y']                               # 特征变量、目标变量字段的重命名\n    df['bins'] = pd.cut(x=x, bins=boundary, right=False)  # 获得每个x值所在的分箱区间\n    \n    grouped = df.groupby('bins')['y']                     # 统计各分箱区间的好、坏、总客户数量\n    result_df = grouped.agg([('good',  lambda y: (y == 0).sum()), \n                             ('bad',   lambda y: (y == 1).sum()),\n                             ('total', 'count')])\n\n    result_df['good_pct'] = result_df['good'] / result_df['good'].sum()       # 好客户占比\n    result_df['bad_pct'] = result_df['bad'] / result_df['bad'].sum()          # 坏客户占比\n    result_df['total_pct'] = result_df['total'] / result_df['total'].sum()    # 总客户占比\n\n    result_df['bad_rate'] = result_df['bad'] / result_df['total']             # 坏比率\n    \n    result_df['woe'] = np.log(result_df['good_pct'] / result_df['bad_pct'])              # WOE\n    result_df['iv'] = (result_df['good_pct'] - result_df['bad_pct']) * result_df['woe']  # IV\n    \n    print(f\"'{feature}'该变量IV = {result_df['iv'].sum()}\")\n    \n    return result_df,boundary","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:15:41.864918Z","iopub.execute_input":"2021-05-21T07:15:41.865473Z","iopub.status.idle":"2021-05-21T07:15:41.875093Z","shell.execute_reply.started":"2021-05-21T07:15:41.865435Z","shell.execute_reply":"2021-05-21T07:15:41.874229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 决策树分箱\nbox = {}\nboundary = {}\nfor col in features:\n    box[col],boundary[col] = feature_woe_iv(col, x=train_data[col], y=train_data['SeriousDlqin2yrs'])\n    display(box[col].style.bar(color=['#d65f5f', '#5fba7d'], align='mid', subset=['bad_rate','woe']))","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:15:42.04752Z","iopub.execute_input":"2021-05-21T07:15:42.047968Z","iopub.status.idle":"2021-05-21T07:15:42.729903Z","shell.execute_reply.started":"2021-05-21T07:15:42.047939Z","shell.execute_reply":"2021-05-21T07:15:42.728962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"RevolvingUtilizationOfUnsecuredLines: 是理想中的分箱，保持了woe的单调性\n\nage: 保持了woe的单调性\n\nNumberOfTime30-59DaysPastDueNotWorse： 分箱还可以\n\nDebtRatio、MonthlyIncome：暂且归为U型变量，不做处理\n\nNumberOfOpenCreditLinesAndLoans： 不作处理\n\nNumberOfTimes90DaysLate: 分箱还可以\n\nNumberRealEstateLoansOrLines： 不作处理\n\nNumberOfTime60-89DaysPastDueNotWorse： 分箱还可以\n\nNumberOfDependents：合并inf出现的box","metadata":{}},{"cell_type":"code","source":"# 如果需要分箱，调整 boundary\n# DebtRatio，应该是比率，23%的大于1,很多数据包含整数，最大值逆天了，先自动分组，然后处理异常值 [min, max+0.0000000001)\ncol = 'DebtRatio'\nprint(boundary[col])\nbox[col].style.bar(color=['#d65f5f', '#5fba7d'], align='mid', subset=['bad_rate','woe'])\n# 处理结果还可以","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:15:42.731261Z","iopub.execute_input":"2021-05-21T07:15:42.731542Z","iopub.status.idle":"2021-05-21T07:15:42.751465Z","shell.execute_reply.started":"2021-05-21T07:15:42.731514Z","shell.execute_reply":"2021-05-21T07:15:42.750491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def feature_woe_iv_new(feature: str, boundary, x: pd.Series, y: pd.Series, nan: float = -999.) -> pd.DataFrame:\n    '''\n        计算变量各个分箱的WOE、IV值，返回一个DataFrame\n    '''\n    x = x.fillna(nan)\n    #boundary = optimal_binning_boundary(x, y, nan)        # 获得最优分箱边界值列表\n    df = pd.concat([x, y], axis=1)                        # 合并x、y为一个DataFrame，方便后续计算\n    df.columns = ['x', 'y']                               # 特征变量、目标变量字段的重命名\n    df['bins'] = pd.cut(x=x, bins=boundary, right=False)  # 获得每个x值所在的分箱区间\n    \n    grouped = df.groupby('bins')['y']                     # 统计各分箱区间的好、坏、总客户数量\n    result_df = grouped.agg([('good',  lambda y: (y == 0).sum()), \n                             ('bad',   lambda y: (y == 1).sum()),\n                             ('total', 'count')])\n\n    result_df['good_pct'] = result_df['good'] / result_df['good'].sum()       # 好客户占比\n    result_df['bad_pct'] = result_df['bad'] / result_df['bad'].sum()          # 坏客户占比\n    result_df['total_pct'] = result_df['total'] / result_df['total'].sum()    # 总客户占比\n\n    result_df['bad_rate'] = result_df['bad'] / result_df['total']             # 坏比率\n    \n    result_df['woe'] = np.log(result_df['good_pct'] / result_df['bad_pct'])              # WOE\n    result_df['iv'] = (result_df['good_pct'] - result_df['bad_pct']) * result_df['woe']  # IV\n    \n    print(f\"'{feature}'该变量IV = {result_df['iv'].sum()}\")\n    \n    return result_df\n\n# 重新分箱\n# box_new = {}\n# for col in cs_training.columns:\n#     box_new[col] = feature_woe_iv_new(col, boundary[col], x=cs_training[col], y=cs_training['SeriousDlqin2yrs'])\n#     #display(box_new[col].style.bar(color=\"skyblue\", subset=['bad_rate']))","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:15:42.752879Z","iopub.execute_input":"2021-05-21T07:15:42.753168Z","iopub.status.idle":"2021-05-21T07:15:42.766554Z","shell.execute_reply.started":"2021-05-21T07:15:42.753142Z","shell.execute_reply":"2021-05-21T07:15:42.765694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"一般认为，IV值小于0.03的特征几乎不带有有效信息，对模型没有贡献，可以删除，这组特征中最低值为’NumberOfDependents’为0.028，\n差别不大，暂且保留查看效果","metadata":{}},{"cell_type":"code","source":"# Step9:\n# 将原数据分箱后，按箱的结果把WOE结构用map函数映射到数据中\ntrain_woe = pd.DataFrame()\nfor col in boundary:\n    if col == 'SeriousDlqin2yrs': continue\n    train_woe[col] = pd.cut(train_data[col],boundary[col], right=False).map(box[col]['woe'])\n    \n#将标签补充到数据中\ntrain_woe[\"SeriousDlqin2yrs\"] = train_data[\"SeriousDlqin2yrs\"]\ntrain_woe","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:15:42.902528Z","iopub.execute_input":"2021-05-21T07:15:42.902889Z","iopub.status.idle":"2021-05-21T07:15:43.039618Z","shell.execute_reply.started":"2021-05-21T07:15:42.902845Z","shell.execute_reply":"2021-05-21T07:15:43.038739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_woe.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:15:43.097864Z","iopub.execute_input":"2021-05-21T07:15:43.098211Z","iopub.status.idle":"2021-05-21T07:15:43.110939Z","shell.execute_reply.started":"2021-05-21T07:15:43.098182Z","shell.execute_reply":"2021-05-21T07:15:43.109911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(train_data[train_woe['MonthlyIncome'].isnull()])\ndisplay(train_woe[train_woe['MonthlyIncome'].isnull()])\ntrain_woe = train_woe.dropna()\ntrain_woe.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:15:43.251938Z","iopub.execute_input":"2021-05-21T07:15:43.252328Z","iopub.status.idle":"2021-05-21T07:15:43.307064Z","shell.execute_reply.started":"2021-05-21T07:15:43.252295Z","shell.execute_reply":"2021-05-21T07:15:43.306201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#将原数据分箱后，按箱的结果把WOE结构用map函数映射到数据中\ntest_woe = pd.DataFrame()\nfor col in boundary:\n    if col == 'SeriousDlqin2yrs': continue\n    test_woe[col] = pd.cut(test_data[col], boundary[col], right=False).map(box[col]['woe'])\n    \n#将标签补充到数据中\ntest_woe[\"SeriousDlqin2yrs\"] = test_data[\"SeriousDlqin2yrs\"]\ntest_woe.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:15:43.451816Z","iopub.execute_input":"2021-05-21T07:15:43.45221Z","iopub.status.idle":"2021-05-21T07:15:43.543466Z","shell.execute_reply.started":"2021-05-21T07:15:43.452162Z","shell.execute_reply":"2021-05-21T07:15:43.542537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(test_data[test_woe['RevolvingUtilizationOfUnsecuredLines'].isnull()])\ndisplay(test_woe[test_woe['RevolvingUtilizationOfUnsecuredLines'].isnull()])\n\ndisplay(test_data[test_woe['DebtRatio'].isnull()])\ndisplay(test_woe[test_woe['DebtRatio'].isnull()])\n\ndisplay(test_data[test_woe['NumberOfOpenCreditLinesAndLoans'].isnull()])\ndisplay(test_woe[test_woe['NumberOfOpenCreditLinesAndLoans'].isnull()])\n\ndisplay(test_data[test_woe['NumberRealEstateLoansOrLines'].isnull()])\ndisplay(test_woe[test_woe['NumberRealEstateLoansOrLines'].isnull()])\n\ndisplay(test_data[test_woe['NumberOfDependents'].isnull()])\ndisplay(test_woe[test_woe['NumberOfDependents'].isnull()])\ntest_woe = test_woe.dropna()\ntest_woe.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:15:43.643082Z","iopub.execute_input":"2021-05-21T07:15:43.643454Z","iopub.status.idle":"2021-05-21T07:15:43.740373Z","shell.execute_reply.started":"2021-05-21T07:15:43.643422Z","shell.execute_reply":"2021-05-21T07:15:43.739466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 处理测试集\nX_test = test_woe.iloc[:,:-1]\ny_test = test_woe.iloc[:,-1]\n# 建模\nX_train = train_woe.iloc[:,:-1]\ny_train = train_woe.iloc[:,-1]","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:15:44.009417Z","iopub.execute_input":"2021-05-21T07:15:44.009778Z","iopub.status.idle":"2021-05-21T07:15:44.016412Z","shell.execute_reply.started":"2021-05-21T07:15:44.009746Z","shell.execute_reply":"2021-05-21T07:15:44.0152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\nfrom sklearn.linear_model import LogisticRegression as LR\nlr = LR(random_state=2021)\nlr.fit(X_train, y_train)\ny_pred = lr.predict(X_test)\n#y_pred2 = lr.predict_proba(X_test)\nprint('Accuracy: ', accuracy_score(y_pred,y_test))\n# 尽量让AUC>=0.8，提升AUC的方法：\n# 1） IV筛选可以降低0.02\n# 2） 调整分箱\n# 3） 构造特征\nprint('AUC:' , roc_auc_score(y_pred,y_test))\nprint('F1:', f1_score(y_pred, y_test))","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:15:44.260493Z","iopub.execute_input":"2021-05-21T07:15:44.260979Z","iopub.status.idle":"2021-05-21T07:15:44.770018Z","shell.execute_reply.started":"2021-05-21T07:15:44.260925Z","shell.execute_reply":"2021-05-21T07:15:44.768903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"AUC > 0.9 ，说明效果还不错","metadata":{}},{"cell_type":"code","source":"# sklearn.metrics.confusion_matrix(y_true, y_pred, *, labels=None, sample_weight=None, normalize=None)\n# 混淆矩阵\nfrom sklearn.metrics import confusion_matrix\nC2 = confusion_matrix(y_test, y_pred)\nsns.heatmap(C2,annot=True,fmt='d')","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:15:44.968665Z","iopub.execute_input":"2021-05-21T07:15:44.96903Z","iopub.status.idle":"2021-05-21T07:15:45.21356Z","shell.execute_reply.started":"2021-05-21T07:15:44.968974Z","shell.execute_reply":"2021-05-21T07:15:45.212591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"绘制ROC曲线，ROC=0.94，曲线越往左上凸，True Positive 就越高，对应的False Positive越低。","metadata":{}},{"cell_type":"code","source":"import scikitplot as skplt\nvali_proba_df = pd.DataFrame(lr.predict_proba(X_test))\nskplt.metrics.plot_roc(y_test, vali_proba_df,\n                      plot_micro=False,figsize=(6,6),\n                      plot_macro=False)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:15:45.543448Z","iopub.execute_input":"2021-05-21T07:15:45.543804Z","iopub.status.idle":"2021-05-21T07:15:45.77814Z","shell.execute_reply.started":"2021-05-21T07:15:45.543773Z","shell.execute_reply":"2021-05-21T07:15:45.777515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4 制作评分卡\n\n求出A、B和base_score\n\n将所有特征的评分卡内容全部一次性写往一个本地文件ScoreData.csv：","metadata":{}},{"cell_type":"code","source":"A = 650\nB = 72.13\n\nfeatures\nboundary\n# 生成评分卡\n\ndef generate_scorecard(model_coef,  features, B):\n    global box\n    coef = model_coef[0]\n    # print(coef)\n    \n    cols = ['Variable', 'Binning', 'Score']\n    for i in range(len(features)):\n        f = features[i]\n        lst = []\n        # 筛选该f的 WOE规则\n        for index, row in box[f].iterrows():\n            lst.append(int(round(-B*coef[i]*row['woe'])))\n        box[f]['score'] = lst\n        \n# 评分卡计算 score\ngenerate_scorecard(lr.coef_,  features, B)\nfor index in box:\n    display(box[index])","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:15:46.383773Z","iopub.execute_input":"2021-05-21T07:15:46.384154Z","iopub.status.idle":"2021-05-21T07:15:46.513457Z","shell.execute_reply.started":"2021-05-21T07:15:46.384126Z","shell.execute_reply":"2021-05-21T07:15:46.512805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  这里记录了kai'ke'ba以一种计算方法\ndef str_to_int(x):\n    if x=='-inf':\n        return -999999\n    if x=='inf':\n        return 999999\n    return float(x)\n\n# 将value映射到bin\ndef map_value_to_bin(feature_value, feature_to_bin):\n    for index, row in feature_to_bin.iterrows():\n        bins =  str(row.name)\n        binnings = bins[1:-1].split(',')\n        in_range = True\n        if feature_value <= str_to_int(binnings[0]):\n            in_range = False\n        if feature_value > str_to_int(binnings[1]):\n            in_range = False\n        if in_range:\n            return row.name\n    return None\n\ndef map_to_score(df, score_card):\n    # score_card = box_new\n    # 得到评分卡规则中的字段\n    score_columns = list(score_card.keys())\n    score_columns.remove('SeriousDlqin2yrs')\n    # 累加 col 的 score\n    for col in score_columns:\n        # 得到关于col的规则\n        feature_to_bin = score_card[col]\n        # df样本中的col\n        feature_value = df[col]\n        #　将ｃｏｌ数值　映射到　Ｂｉｎｎｉｎｇ\n        selected_bin = map_value_to_bin(feature_value, feature_to_bin)\n        # 累加score\n        selected_score = feature_to_bin[selected_bin]['score'].iloc[0]\n        # 累加到整体的score\n        score += selected_score\n    return score\n\n\n# 按照评分卡规则 score card 计算df中的分数\ndef cal_score_with_card(df, score_card, A):\n    df['score'] = df.apply(map_to_score, args=(score_card, ),axis=1)\n    df['score'] = df['score'] + A\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:16:33.4924Z","iopub.execute_input":"2021-05-21T07:16:33.492722Z","iopub.status.idle":"2021-05-21T07:16:33.502821Z","shell.execute_reply.started":"2021-05-21T07:16:33.492691Z","shell.execute_reply":"2021-05-21T07:16:33.50203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 按照评分卡规则 score card 计算df中的分数\ndef cal_score_with_card(df, score_card, A):\n    df_score = df.copy()\n    \n    # score_card = box_new\n    # 得到评分卡规则中的字段\n    columns = list(score_card.keys())\n    \n    score_columns = []\n    # 累加 col 的 score\n    for col in columns:\n        df_score['score_{}'.format(col)] = df_score[col].map(score_card[col]['score'])\n        score_columns.append('score_{}'.format(col))\n        \n    df_score['score'] = df_score[score_columns].sum(axis=1)\n    df_score['score'] = df_score['score'] + A\n    return df_score","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:16:50.797121Z","iopub.execute_input":"2021-05-21T07:16:50.797774Z","iopub.status.idle":"2021-05-21T07:16:50.804332Z","shell.execute_reply.started":"2021-05-21T07:16:50.797738Z","shell.execute_reply":"2021-05-21T07:16:50.803309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 随机选择Good的5个\ngood_sample = df_train[df_train['SeriousDlqin2yrs']==0].sample(5,random_state=2022)\ngood_sample = good_sample[features]\ngood_sample\n\n# 计算分数\ngood_sample_score = cal_score_with_card(good_sample, box, 650)\n\ngood_sample_score","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:18:02.671052Z","iopub.execute_input":"2021-05-21T07:18:02.671376Z","iopub.status.idle":"2021-05-21T07:18:02.7248Z","shell.execute_reply.started":"2021-05-21T07:18:02.671349Z","shell.execute_reply":"2021-05-21T07:18:02.723927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 随机选择Good的5个\nbad_sample = df_train[df_train['SeriousDlqin2yrs']==1].sample(5,random_state=2022)\nbad_sample = good_sample[features]\nbad_sample\n\n# 计算分数\nbad_sample_score = cal_score_with_card(good_sample, box, 650)\n\nbad_sample_score","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:18:13.113551Z","iopub.execute_input":"2021-05-21T07:18:13.113901Z","iopub.status.idle":"2021-05-21T07:18:13.16376Z","shell.execute_reply.started":"2021-05-21T07:18:13.113866Z","shell.execute_reply":"2021-05-21T07:18:13.162894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 计算分数\ncs_training_score = cal_score_with_card(df_train, box, 650)\ncs_training_score.to_csv('cs_training_score.csv', header=True)\ncs_training_score","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:19:19.887544Z","iopub.execute_input":"2021-05-21T07:19:19.887951Z","iopub.status.idle":"2021-05-21T07:19:34.651874Z","shell.execute_reply.started":"2021-05-21T07:19:19.887916Z","shell.execute_reply":"2021-05-21T07:19:34.650903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cs_test = pd.read_csv(input+'cs-test.csv')\ncs_test = cs_test.iloc[:, 1:]\n\n# 计算分数\ncs_test_score = cal_score_with_card(cs_test, box, 650)\ncs_test_score.to_csv('cs_test_score.csv', header=True)\ncs_test_score","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:19:51.731848Z","iopub.execute_input":"2021-05-21T07:19:51.732293Z","iopub.status.idle":"2021-05-21T07:20:00.96942Z","shell.execute_reply.started":"2021-05-21T07:19:51.732264Z","shell.execute_reply":"2021-05-21T07:20:00.968413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sampleEntry = pd.read_csv(input+'sampleEntry.csv', index_col='Id')\n\nsampleEntry","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:20:33.953507Z","iopub.execute_input":"2021-05-21T07:20:33.953827Z","iopub.status.idle":"2021-05-21T07:20:34.062928Z","shell.execute_reply.started":"2021-05-21T07:20:33.953801Z","shell.execute_reply":"2021-05-21T07:20:34.062097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cs_test = pd.read_csv(input+'cs-test.csv', index_col=0)\ncs_test = cs_test.drop(['SeriousDlqin2yrs'], axis=1)\n\ndisplay(cs_test.isna().sum()/cs_test.shape[0])\n\n#使用均值填补“NumberOfDependents”的缺失值\ncs_test[\"NumberOfDependents\"].fillna(int(cs_test[\"NumberOfDependents\"].mean()),inplace=True)\n# 使用均值填补 “MonthlyIncome” 的缺失值\ncs_test['MonthlyIncome'].fillna(cs_test['MonthlyIncome'].mean(),inplace=True)\n\ndisplay(cs_test.isna().sum()/cs_test.shape[0])\n    \n#将原数据分箱后，按箱的结果把WOE结构用map函数映射到数据中\ncs_test_woe = pd.DataFrame()\nfor col in boundary:\n    if col == 'SeriousDlqin2yrs': continue\n    cs_test_woe[col] = pd.cut(cs_test[col], boundary[col], right=False).map(box[col]['woe'])\n\ndisplay(cs_test_woe.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:42:01.978965Z","iopub.execute_input":"2021-05-21T07:42:01.979499Z","iopub.status.idle":"2021-05-21T07:42:02.262971Z","shell.execute_reply.started":"2021-05-21T07:42:01.979447Z","shell.execute_reply":"2021-05-21T07:42:02.261799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cs_test_woe['MonthlyIncome'].fillna(cs_test_woe['MonthlyIncome'].value_counts().index[0], inplace=True)\ncs_test_woe['NumberOfOpenCreditLinesAndLoans'].fillna(cs_test_woe['NumberOfOpenCreditLinesAndLoans'].value_counts().index[0], inplace=True)\ncs_test_woe['NumberOfDependents'].fillna(cs_test_woe['NumberOfDependents'].value_counts().index[0], inplace=True)\ndisplay(cs_test_woe.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:48:14.615474Z","iopub.execute_input":"2021-05-21T07:48:14.615833Z","iopub.status.idle":"2021-05-21T07:48:14.635653Z","shell.execute_reply.started":"2021-05-21T07:48:14.615794Z","shell.execute_reply":"2021-05-21T07:48:14.634742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ny_pred2 = lr.predict_proba(cs_test_woe)\n\n\npredict = pd.DataFrame(index=cs_test.index)\npredict['Probability'] = y_pred2[:, 1]\npredict.index.name = 'Id'\npredict","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:48:19.631201Z","iopub.execute_input":"2021-05-21T07:48:19.631703Z","iopub.status.idle":"2021-05-21T07:48:19.665914Z","shell.execute_reply.started":"2021-05-21T07:48:19.631668Z","shell.execute_reply":"2021-05-21T07:48:19.664948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict.to_csv('predict.csv', header=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:48:55.626278Z","iopub.execute_input":"2021-05-21T07:48:55.626615Z","iopub.status.idle":"2021-05-21T07:48:56.016638Z","shell.execute_reply.started":"2021-05-21T07:48:55.626588Z","shell.execute_reply":"2021-05-21T07:48:56.015611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}