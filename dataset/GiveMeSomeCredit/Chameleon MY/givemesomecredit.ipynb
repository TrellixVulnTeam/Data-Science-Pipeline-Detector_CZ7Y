{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-08T11:38:18.278224Z","iopub.execute_input":"2021-07-08T11:38:18.278786Z","iopub.status.idle":"2021-07-08T11:38:18.288747Z","shell.execute_reply.started":"2021-07-08T11:38:18.278748Z","shell.execute_reply":"2021-07-08T11:38:18.287881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Viz\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n \n# settings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n \nfrom  sklearn.ensemble import RandomForestClassifier\nfrom  sklearn.ensemble import RandomForestRegressor","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:38:18.290248Z","iopub.execute_input":"2021-07-08T11:38:18.290787Z","iopub.status.idle":"2021-07-08T11:38:19.592191Z","shell.execute_reply.started":"2021-07-08T11:38:18.29073Z","shell.execute_reply":"2021-07-08T11:38:19.591063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"导入数据并查看数据","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/GiveMeSomeCredit/cs-training.csv')\ntest = pd.read_csv('../input/GiveMeSomeCredit/cs-test.csv')\ndata = pd.read_csv('../input/GiveMeSomeCredit/cs-training.csv')\np=0\nfor ff in train['SeriousDlqin2yrs']:\n    if ff == 1:\n        p=p+1\nprint(p)\nprint(len(test['SeriousDlqin2yrs']))\nrr = p/len(test['SeriousDlqin2yrs'])\nprint(rr)\ntrain","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:38:19.595437Z","iopub.execute_input":"2021-07-08T11:38:19.595984Z","iopub.status.idle":"2021-07-08T11:38:20.261239Z","shell.execute_reply.started":"2021-07-08T11:38:19.595943Z","shell.execute_reply":"2021-07-08T11:38:20.260245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:38:20.263271Z","iopub.execute_input":"2021-07-08T11:38:20.263715Z","iopub.status.idle":"2021-07-08T11:38:20.2888Z","shell.execute_reply.started":"2021-07-08T11:38:20.263669Z","shell.execute_reply":"2021-07-08T11:38:20.287656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"根据业务的背景，可以上客户信息分为以下几类：\n\n基本信息：age\n\n负债信息:RevolvingUtilizationOfUnsecuredLines、DebtRatio、NumberOfOpenCreditLinesAndLoans、NumberRealEstateLoansOrLines\n\n偿还能力：MonthlyIncome\n\n历史信用记录：NumberOfTime30-59DaysPastDueNotWorse、NumberOfTime60-89DaysPastDueNotWorse、NumberOfTimes90DaysLate\n\n人际社交信息：NumberOfDependents","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"数据处理","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt \nimport seaborn as sns\n%matplotlib inline\n\n#导入统计学常用数据包\nfrom scipy import stats\nfrom scipy.stats import norm, skew \n\nimport warnings\ndef ignore_warn(*args, **kwargs):\n    pass\nwarnings.warn = ignore_warn #忽略警告\npd.set_option('display.float_format', lambda x: '{:.3f}'.format(x)) #设置pandas输出数据为3位小数","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:38:20.291253Z","iopub.execute_input":"2021-07-08T11:38:20.291702Z","iopub.status.idle":"2021-07-08T11:38:20.302111Z","shell.execute_reply.started":"2021-07-08T11:38:20.291655Z","shell.execute_reply":"2021-07-08T11:38:20.300811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"重复值处理","metadata":{}},{"cell_type":"code","source":"#保存ID号码\ntrain_ID = train['Unnamed: 0']\ntest_ID = test['Unnamed: 0']\ny_train = train.SeriousDlqin2yrs\ny_test = test.SeriousDlqin2yrs\nall_data = pd.concat((train, test)).reset_index(drop=True)\n\n#检查数据\nprint(\"处理前数据大小 : {} \".format(all_data.shape))\n\n#获取去重复的字段名列表\ncols_df = all_data.columns.values.tolist()\ncols_df.remove('Unnamed: 0')\n\n#去除训练数据中的重复值\nall_data.drop_duplicates(subset = cols_df, inplace=True)\n\n\n#检查数据\nprint(\"处理后数据大小 : {} \".format(all_data.shape))","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:38:20.303763Z","iopub.execute_input":"2021-07-08T11:38:20.304235Z","iopub.status.idle":"2021-07-08T11:38:20.546939Z","shell.execute_reply.started":"2021-07-08T11:38:20.304191Z","shell.execute_reply":"2021-07-08T11:38:20.545843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"缺失值处理","metadata":{}},{"cell_type":"code","source":"import missingno as msno\nmsno.matrix(all_data)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:38:20.548969Z","iopub.execute_input":"2021-07-08T11:38:20.549282Z","iopub.status.idle":"2021-07-08T11:38:21.873725Z","shell.execute_reply.started":"2021-07-08T11:38:20.549251Z","shell.execute_reply":"2021-07-08T11:38:21.872278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_data.isnull().mean()","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:38:21.87623Z","iopub.execute_input":"2021-07-08T11:38:21.876625Z","iopub.status.idle":"2021-07-08T11:38:21.890525Z","shell.execute_reply.started":"2021-07-08T11:38:21.876591Z","shell.execute_reply":"2021-07-08T11:38:21.88921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"对于numberofdependents缺失率较低，直接删除，对monthlyincome缺失率较高，后面根据分布特征选择缺失值填补方法","metadata":{}},{"cell_type":"code","source":"#检查数据\nprint(\"处理前数据集大小 : {} \".format(all_data.shape))\n\n\nall_data.dropna(subset=['NumberOfDependents'],inplace=True)\n\n#检查数据\nprint('--------------------------------')\nprint(\"处理后数据集大小 : {} \".format(all_data.shape))","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:38:21.891915Z","iopub.execute_input":"2021-07-08T11:38:21.892248Z","iopub.status.idle":"2021-07-08T11:38:21.938655Z","shell.execute_reply.started":"2021-07-08T11:38:21.892216Z","shell.execute_reply":"2021-07-08T11:38:21.937276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 本次单变量探索用到的字定义函数\n##分位法处理异常值\ndef IQR_Cleaner(df,atrribute_name,floor,ceiling,method):\n    ##df：要清洗的DataFrame，DataFrame\n    ##atrribute_name：清洗的属性名称，字符串\n    ##floor：清洗的下分位数，float\n    ##ceiling：清洗的上分位数，float\n    ##method:'drop' 或者 ‘fill’\n    Q1 = df[atrribute_name].quantile(floor)\n    Q3 = df[atrribute_name].quantile(ceiling)\n    IQR = Q3 - Q1\n    down = Q1 - 1.5*IQR\n    up = Q3 + 1.5*IQR\n    if method == 'drop':\n        df = df.loc[(df[atrribute_name]<up) & (df[atrribute_name]>down),:]\n    else:\n        df.loc[df[atrribute_name]>up,atrribute_name]=up\n        df.loc[df[atrribute_name]<down,atrribute_name]=down\n    return df\n\n##单变量分布可视化函数\ndef Distribution_worker(target,bins):\n    ## target 需要探索的单变量\n    ## 直方图\n    fig = plt.figure(figsize=(15,5))\n    plt.subplot(121)\n    sns.distplot(target, fit=norm, bins=bins)\n    (mu, sigma) = norm.fit(target)\n    print( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n    plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],loc='best')\n    plt.ylabel('Frequency')\n    plt.title('distribution')\n    \n    ##箱线图\n    plt.subplot(122)\n    sns.boxplot(y =target , width=0.2)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:38:21.940558Z","iopub.execute_input":"2021-07-08T11:38:21.941081Z","iopub.status.idle":"2021-07-08T11:38:21.953905Z","shell.execute_reply.started":"2021-07-08T11:38:21.941007Z","shell.execute_reply":"2021-07-08T11:38:21.952594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"age分析","metadata":{}},{"cell_type":"code","source":"#输入目标变量\ntarget = all_data.age\n\n#变量分布特征\nDistribution_worker(target,30)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:38:21.955626Z","iopub.execute_input":"2021-07-08T11:38:21.956083Z","iopub.status.idle":"2021-07-08T11:38:24.01002Z","shell.execute_reply.started":"2021-07-08T11:38:21.956011Z","shell.execute_reply":"2021-07-08T11:38:24.009209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#异常值处理\nall_data = IQR_Cleaner(all_data, 'age', 0.25, 0.75, 'fill')\n\n#输入目标变量\ntarget = all_data.age\n\n#处理后变量分布特征\nDistribution_worker(target,30)\n# 年龄等于0的异常值进行剔除\ndata = data[data['age']> 0]","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:38:24.011141Z","iopub.execute_input":"2021-07-08T11:38:24.01154Z","iopub.status.idle":"2021-07-08T11:38:25.768127Z","shell.execute_reply.started":"2021-07-08T11:38:24.011511Z","shell.execute_reply":"2021-07-08T11:38:25.767334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"revolvingutilizationofunsecuredlines分析","metadata":{}},{"cell_type":"code","source":"#输入目标变量\ntarget = all_data.RevolvingUtilizationOfUnsecuredLines\n\n#变量分布特征\nDistribution_worker(target,30)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:38:25.76917Z","iopub.execute_input":"2021-07-08T11:38:25.769559Z","iopub.status.idle":"2021-07-08T11:38:27.221682Z","shell.execute_reply.started":"2021-07-08T11:38:25.769531Z","shell.execute_reply":"2021-07-08T11:38:27.22062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#异常值处理\noutlier_num  = all_data.loc[all_data.RevolvingUtilizationOfUnsecuredLines>1].shape[0]\nprint(\" RevolvingUtilizationOfUnsecuredLines字段大于1的记录占比: {} \".format(outlier_num/119587)) \n\n#大于1的记录赋值为1\nall_data = all_data.loc[all_data.RevolvingUtilizationOfUnsecuredLines<=1]\n\n#剔除异常值\ndata = data[data['RevolvingUtilizationOfUnsecuredLines'] < 6]\n\n#输入目标变量\ntarget = all_data.RevolvingUtilizationOfUnsecuredLines\n\n#变量分布特征\nDistribution_worker(target,30)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:38:27.222976Z","iopub.execute_input":"2021-07-08T11:38:27.223288Z","iopub.status.idle":"2021-07-08T11:38:28.910879Z","shell.execute_reply.started":"2021-07-08T11:38:27.223258Z","shell.execute_reply":"2021-07-08T11:38:28.909436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"debtratio分析","metadata":{}},{"cell_type":"code","source":"#输入目标变量\ntarget = all_data.DebtRatio\n\n#变量分布特征\nDistribution_worker(target,30)\ndatatemp2=data[\"DebtRatio\"]","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:38:28.91244Z","iopub.execute_input":"2021-07-08T11:38:28.912764Z","iopub.status.idle":"2021-07-08T11:38:30.442085Z","shell.execute_reply.started":"2021-07-08T11:38:28.91273Z","shell.execute_reply":"2021-07-08T11:38:30.440717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#异常值处理\noutlier_num  = all_data.loc[all_data.DebtRatio>1].shape[0]\nprint(\" DebtRatio字段大于1的记录占比: {} \".format(outlier_num/119587)) \n\n#只有几百个样本，对于15万数据来说不影响总体数据结构，所以剔除\ndata = data[data['DebtRatio'] < 8000]\n\n#天花板法处理异常值\nall_data = IQR_Cleaner(all_data, 'DebtRatio', 0.25, 0.75, 'fill')\n\n#处理后字段分布特征\n\n#输入目标变量\ntarget = all_data.DebtRatio\n\n#变量分布特征\nDistribution_worker(target,30)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:38:30.445215Z","iopub.execute_input":"2021-07-08T11:38:30.445515Z","iopub.status.idle":"2021-07-08T11:38:32.101222Z","shell.execute_reply.started":"2021-07-08T11:38:30.445486Z","shell.execute_reply":"2021-07-08T11:38:32.100069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"numberrealestateloansorlines分析","metadata":{}},{"cell_type":"code","source":"#输入目标变量\ntarget = all_data.NumberRealEstateLoansOrLines\n\n#变量分布特征\nDistribution_worker(target,5)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:38:32.102986Z","iopub.execute_input":"2021-07-08T11:38:32.103309Z","iopub.status.idle":"2021-07-08T11:38:33.474611Z","shell.execute_reply.started":"2021-07-08T11:38:32.103279Z","shell.execute_reply":"2021-07-08T11:38:33.473002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#天花板法处理异常值\nall_data = IQR_Cleaner(all_data, 'NumberRealEstateLoansOrLines', 0.25, 0.75, 'fill')\n\n#剔除异常值\ndata = data[data['NumberRealEstateLoansOrLines'] < 30]\n\n#输入目标变量\ntarget = all_data.NumberRealEstateLoansOrLines\n\n#变量分布特征\nDistribution_worker(target,5)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:38:33.477213Z","iopub.execute_input":"2021-07-08T11:38:33.477694Z","iopub.status.idle":"2021-07-08T11:38:35.276087Z","shell.execute_reply.started":"2021-07-08T11:38:33.477646Z","shell.execute_reply":"2021-07-08T11:38:35.275138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"numberofdependents字段","metadata":{}},{"cell_type":"code","source":"#输入目标变量\ntarget = all_data.NumberOfDependents\n\n#变量分布特征\nDistribution_worker(target,5)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:38:35.279722Z","iopub.execute_input":"2021-07-08T11:38:35.280033Z","iopub.status.idle":"2021-07-08T11:38:36.656016Z","shell.execute_reply.started":"2021-07-08T11:38:35.280001Z","shell.execute_reply":"2021-07-08T11:38:36.655065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#天花板法处理异常值\nall_data = IQR_Cleaner(all_data, 'NumberOfDependents', 0.25, 0.75, 'fill')\n\n#剔除异常值\ndata = data[data['NumberOfTime30-59DaysPastDueNotWorse'] < 20]\n\n#输入目标变量\ntarget = all_data.NumberOfDependents\n\n#变量分布特征\nDistribution_worker(target,5)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:38:36.657757Z","iopub.execute_input":"2021-07-08T11:38:36.65809Z","iopub.status.idle":"2021-07-08T11:38:38.205194Z","shell.execute_reply.started":"2021-07-08T11:38:36.658058Z","shell.execute_reply":"2021-07-08T11:38:38.204136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"历史信用记录分析","metadata":{}},{"cell_type":"code","source":"##观察历史信用记录数据分布情况\ntarget = all_data[['NumberOfTime30-59DaysPastDueNotWorse','NumberOfTime60-89DaysPastDueNotWorse','NumberOfTimes90DaysLate']]\nsns.boxplot(data =target, width=0.2,orient='h')","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:38:38.206705Z","iopub.execute_input":"2021-07-08T11:38:38.207015Z","iopub.status.idle":"2021-07-08T11:38:38.509396Z","shell.execute_reply.started":"2021-07-08T11:38:38.206985Z","shell.execute_reply":"2021-07-08T11:38:38.508178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#大于20的值赋值为20\nall_data.loc[all_data['NumberOfTime30-59DaysPastDueNotWorse']>20,'NumberOfTime30-59DaysPastDueNotWorse']=20\nall_data.loc[all_data['NumberOfTime60-89DaysPastDueNotWorse']>20,'NumberOfTime60-89DaysPastDueNotWorse']=20\nall_data.loc[all_data['NumberOfTimes90DaysLate']>20,'NumberOfTimes90DaysLate']=20\n##观察历史信用记录数据分布情况\ntarget = all_data[['NumberOfTime30-59DaysPastDueNotWorse','NumberOfTime60-89DaysPastDueNotWorse','NumberOfTimes90DaysLate']]\nsns.boxplot(data =target, width=0.2,orient='h')","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:38:38.510564Z","iopub.execute_input":"2021-07-08T11:38:38.510848Z","iopub.status.idle":"2021-07-08T11:38:38.844911Z","shell.execute_reply.started":"2021-07-08T11:38:38.510821Z","shell.execute_reply":"2021-07-08T11:38:38.843943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"monthlyincome分析","metadata":{}},{"cell_type":"code","source":"#输入目标变量\ntarget = all_data.dropna().MonthlyIncome\n\n#变量分布特征\nDistribution_worker(target,30)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:38:38.846128Z","iopub.execute_input":"2021-07-08T11:38:38.846419Z","iopub.status.idle":"2021-07-08T11:38:39.830602Z","shell.execute_reply.started":"2021-07-08T11:38:38.846389Z","shell.execute_reply":"2021-07-08T11:38:39.829608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#天花板法处理异常值\nall_data = IQR_Cleaner(all_data, 'MonthlyIncome', 0.25, 0.75, 'fill')\n\n#处理后字段分布特征\n#剔除异常值\ndata = data[data['MonthlyIncome'] < 50000]\n\n#输入目标变量\ntarget = all_data.dropna().MonthlyIncome\n\n#变量分布特征\nDistribution_worker(target,30)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:38:39.831974Z","iopub.execute_input":"2021-07-08T11:38:39.832285Z","iopub.status.idle":"2021-07-08T11:38:40.984229Z","shell.execute_reply.started":"2021-07-08T11:38:39.832254Z","shell.execute_reply":"2021-07-08T11:38:40.982977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"分箱处理\n\n 变量分箱（binning）是对连续变量离散化（discretization）的一种称呼。\n\n 信用评分卡开发中一般有常用的等距分段、等深分段、最优分段。\n\n 其中等距分段（Equval length intervals）是指分段的区间是一致的，比如年龄以十年作为一个分段；\n\n 等深分段（Equal frequency intervals）是先确定分段数量，然后令每个分段中数据数量大致相等；\n\n 最优分段（Optimal Binning）又叫监督离散化（supervised discretizaion），使用递归划分（Recursive Partitioning）将连续变量分为分段，背后是一种基于条件推断查找较佳分组的算法。\n\n \n\n 我们首先选择对连续变量进行最优分段，在连续变量的分布不满足最优分段的要求时，再考虑对连续变量进行等距分段。最优分箱的代码如下：","metadata":{}},{"cell_type":"code","source":"\nfrom sklearn.model_selection import train_test_split\n#data=data.drop([\"Unnamed: 0\"],axis=1)\nY = data['SeriousDlqin2yrs']\nX = data.iloc[:, 1:]\n#测试集占比30%\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\ntrain = pd.concat([Y_train, X_train], axis=1)\ntest = pd.concat([Y_test, X_test], axis=1)\ntest.to_csv('TestData.csv',index=False)\n\n\n# 定义自动分箱函数\n \nfrom scipy import stats\ndef mono_bin(Y, X, n = 20):\n    r = 0\n    good=Y.sum()\n    bad=Y.count()-good\n    while np.abs(r) < 1:\n        d1 = pd.DataFrame({\"X\": X, \"Y\": Y, \"Bucket\": pd.qcut(X, n,duplicates=\"drop\")}) \n        # 后面报错You can drop duplicate edges by setting the 'duplicates' kwarg，所以回到这里补充duplicates参数\n        # pandas中使用qcut()，边界易出现重复值，如果为了删除重复值设置 duplicates=‘drop’，则易出现于分片个数少于指定个数的问题\n        # 经尝试，设置duplicates参数为“drop”可行，而不能设置为“raise”。\n        d2 = d1.groupby('Bucket', as_index = True)\n        r, p = stats.spearmanr(d2.X.mean(), d2.mean().Y)\n        n = n - 1\n    d3 = pd.DataFrame(d2.X.min(), columns = ['min'])\n    d3['min'] = d2.min().X\n    d3['max'] = d2.max().X\n    d3['sum'] = d2.sum().Y\n    d3['total'] = d2.count().Y\n    d3['rate'] = d2.mean().Y\n    d3['woe']=np.log((d3['rate']/(1-d3['rate']))/(good/bad))\n    d4 = (d3.sort_values(by='min')).reset_index(drop=True)\n    print(\"=\" * 60)\n    woe=list(d4['woe'].round(3))\n    print(d4)\n    return d4\n","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:38:40.985886Z","iopub.execute_input":"2021-07-08T11:38:40.986322Z","iopub.status.idle":"2021-07-08T11:38:41.308459Z","shell.execute_reply.started":"2021-07-08T11:38:40.986279Z","shell.execute_reply":"2021-07-08T11:38:41.307566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"变量分箱","metadata":{}},{"cell_type":"code","source":"\nmono_bin(data.SeriousDlqin2yrs,data['DebtRatio'])\nmono_bin(data.SeriousDlqin2yrs,data.RevolvingUtilizationOfUnsecuredLines)\nmono_bin(data.SeriousDlqin2yrs,data.age)\nmono_bin(data.SeriousDlqin2yrs,data.MonthlyIncome)\nmono_bin(data.SeriousDlqin2yrs,data['NumberOfTime30-59DaysPastDueNotWorse'])\nmono_bin(data.SeriousDlqin2yrs,data['NumberOfTime60-89DaysPastDueNotWorse'])\nmono_bin(data.SeriousDlqin2yrs,data['NumberOfTimes90DaysLate'])\nmono_bin(data.SeriousDlqin2yrs,data.NumberRealEstateLoansOrLines)\nmono_bin(data.SeriousDlqin2yrs,data.NumberOfDependents)\nmono_bin(data.SeriousDlqin2yrs,data.NumberOfOpenCreditLinesAndLoans)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:38:41.309858Z","iopub.execute_input":"2021-07-08T11:38:41.310397Z","iopub.status.idle":"2021-07-08T11:38:44.189502Z","shell.execute_reply.started":"2021-07-08T11:38:41.31036Z","shell.execute_reply":"2021-07-08T11:38:44.188478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"NumberOfOpenCreditLinesAndLoans、NumberOfTimes90DaysLate、NumberOfTime60-89DaysPastDueNotWorse、NumberRealEstateLoansOrLines最终结果只分得一个组，那么针对不能最优分箱的变量，下面将进行自定义分箱。","metadata":{}},{"cell_type":"code","source":"# 连续变量离散化\npinf = float('inf')#正无穷大\nninf = float('-inf')#负无穷大\n \ncutx6 = [ninf, 1, 2, 3, 5, pinf]\ncutx7 = [ninf, 0, 1, 3, 5, pinf]\ncutx8 = [ninf, 0,1,2, 3, pinf]\ncutx9 = [ninf, 0, 1, 3, pinf]","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:38:44.19104Z","iopub.execute_input":"2021-07-08T11:38:44.191657Z","iopub.status.idle":"2021-07-08T11:38:44.199169Z","shell.execute_reply.started":"2021-07-08T11:38:44.191608Z","shell.execute_reply":"2021-07-08T11:38:44.197867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"WoE分析， 是对指标分箱、计算各个档位的WoE值并观察WoE值随指标变化的趋势。其中WoE的数学定义是:\nwoe=ln(goodattribute/badattribute)\n在进行分析时，我们需要对各指标从小到大排列，并计算出相应分档的WoE值。其中正向指标越大，WoE值越小；反向指标越大，WoE值越大。正向指标的WoE值负斜率越大，反响指标的正斜率越大，则说明指标区分能力好。WoE值趋近于直线，则意味指标判断能力较弱。若正向指标和WoE正相关趋势、反向指标同WoE出现负相关趋势，则说明此指标不符合经济意义，则应当予以去除。\nwoe函数实现在上面的mono_bin()函数里面已经包含，这里不再重复。\n接下来，我们会用经过清洗后的数据看一下变量间的相关性。注意，这里的相关性分析只是初步的检查，进一步检查模型的IV（证据权重）作为变量筛选的依据","metadata":{}},{"cell_type":"code","source":"\ncorr = all_data.drop(['Unnamed: 0','SeriousDlqin2yrs'],axis=1).corr()\nprint(max(corr))\nplt.subplots(figsize=(12, 12))\nsns.heatmap(corr, annot=True, vmax=1, square=True, cmap='Blues')\ncorr = data.corr()#计算各变量的相关性系数\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:38:44.200747Z","iopub.execute_input":"2021-07-08T11:38:44.201088Z","iopub.status.idle":"2021-07-08T11:38:45.300433Z","shell.execute_reply.started":"2021-07-08T11:38:44.201031Z","shell.execute_reply":"2021-07-08T11:38:45.299108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"接下来，我进一步计算每个变量的Infomation Value（IV）。IV指标是一般用来确定自变量的预测能力。 其公式为：\nIV=sum((goodattribute-badattribute)*ln(goodattribute/badattribute))\n通过IV值判断变量预测能力的标准是：\n < 0.02: unpredictive\n0.02 to 0.1: weak\n0.1 to 0.3: medium\n0.3 to 0.5: strong\n> 0.5: suspicious\n\nIV的实现放在mono_bin()函数里面，代码实现如下\n","metadata":{}},{"cell_type":"code","source":"# IV的实现放在mono_bin()函数里面，代码实现如下：\n \n# 定义自动分箱函数\ndef mono_bin(Y, X, n = 20):\n    r = 0\n    good=Y.sum()\n    bad=Y.count()-good\n    while np.abs(r) < 1:\n        d1 = pd.DataFrame({\"X\": X, \"Y\": Y, \"Bucket\": pd.qcut(X, n,duplicates=\"drop\")})\n        d2 = d1.groupby('Bucket', as_index = True)\n        r, p = stats.spearmanr(d2.mean().X, d2.mean().Y)\n        n = n - 1\n    d3 = pd.DataFrame(d2.X.min(), columns = ['min'])\n    d3['min']=d2.min().X\n    d3['max'] = d2.max().X\n    d3['sum'] = d2.sum().Y\n    d3['total'] = d2.count().Y\n    d3['rate'] = d2.mean().Y\n    d3['woe']=np.log((d3['rate']/(1-d3['rate']))/(good/bad))\n    d3['goodattribute']=d3['sum']/good\n    d3['badattribute']=(d3['total']-d3['sum'])/bad\n    iv=((d3['goodattribute']-d3['badattribute'])*d3['woe']).sum()\n    d4 = (d3.sort_values(by = 'min')).reset_index(drop=True)\n    print(\"=\" * 60)\n    print(d4)\n    cut=[]\n    cut.append(float('-inf'))\n    for i in range(1,n+1):\n        qua=X.quantile(i/(n+1))\n        cut.append(round(qua,4))\n    cut.append(float('inf'))\n    woe=list(d4['woe'].round(3))\n    return d4,iv,cut,woe\n \n#自定义分箱函数\n# ——该定义函数参考另一篇帖子：https://blog.csdn.net/sunyaowu315/article/details/82981216 \ndef self_bin(Y,X,cat):\n    good=Y.sum()\n    bad=Y.count()-good\n    d1=pd.DataFrame({'X':X,'Y':Y,'Bucket':pd.cut(X,cat)})\n    d2=d1.groupby('Bucket', as_index = True)\n    d3 = pd.DataFrame(d2.X.min(), columns=['min'])\n    d3['min'] = d2.min().X\n    d3['max'] = d2.max().X\n    d3['sum'] = d2.sum().Y\n    d3['total'] = d2.count().Y\n    d3['rate'] = d2.mean().Y\n    d3['woe'] = np.log((d3['rate'] / (1 - d3['rate'])) / (good / bad))\n    d3['goodattribute'] = d3['sum'] / good\n    d3['badattribute'] = (d3['total'] - d3['sum']) / bad\n    iv = ((d3['goodattribute'] - d3['badattribute']) * d3['woe']).sum()\n    d4 = (d3.sort_values(by='min'))\n    print(\"=\" * 60)\n    print(d4)\n    woe = list(d4['woe'].round(3))\n    return d4, iv,woe","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:38:45.302174Z","iopub.execute_input":"2021-07-08T11:38:45.302603Z","iopub.status.idle":"2021-07-08T11:38:45.323415Z","shell.execute_reply.started":"2021-07-08T11:38:45.302559Z","shell.execute_reply":"2021-07-08T11:38:45.322171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dfx1, ivx1,cutx1,woex1 = mono_bin(data.SeriousDlqin2yrs, data.RevolvingUtilizationOfUnsecuredLines,n=10)\ndfx2, ivx2,cutx2,woex2 = mono_bin(data.SeriousDlqin2yrs, data.age, n=10)\ndfx4, ivx4,cutx4,woex4 =mono_bin(data.SeriousDlqin2yrs, data.DebtRatio, n=20)\ndfx5, ivx5,cutx5,woex5 =mono_bin(data.SeriousDlqin2yrs, data.MonthlyIncome, n=10)\n \n# 连续变量离散化\ncutx3 = [ninf, 0, 1, 3, 5, pinf]\ncutx6 = [ninf, 1, 2, 3, 5, pinf]\ncutx7 = [ninf, 0, 1, 3, 5, pinf]\ncutx8 = [ninf, 0,1,2, 3, pinf]\ncutx9 = [ninf, 0, 1, 3, pinf]\ncutx10 = [ninf, 0, 1, 2, 3, 5, pinf]\ndfx3, ivx3,woex3 = self_bin(data.SeriousDlqin2yrs, data['NumberOfTime30-59DaysPastDueNotWorse'], cutx3)\ndfx6, ivx6,woex6= self_bin(data.SeriousDlqin2yrs, data['NumberOfOpenCreditLinesAndLoans'], cutx6)\ndfx7, ivx7,woex7 = self_bin(data.SeriousDlqin2yrs, data['NumberOfTimes90DaysLate'], cutx7)\ndfx8, ivx8,woex8 = self_bin(data.SeriousDlqin2yrs, data['NumberRealEstateLoansOrLines'], cutx8)\ndfx9, ivx9,woex9 = self_bin(data.SeriousDlqin2yrs, data['NumberOfTime60-89DaysPastDueNotWorse'], cutx9)\ndfx10, ivx10,woex10 = self_bin(data.SeriousDlqin2yrs, data['NumberOfDependents'], cutx10)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:38:45.325088Z","iopub.execute_input":"2021-07-08T11:38:45.325418Z","iopub.status.idle":"2021-07-08T11:38:46.77333Z","shell.execute_reply.started":"2021-07-08T11:38:45.325383Z","shell.execute_reply":"2021-07-08T11:38:46.772063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 生成的IV图代码：\n \nivlist=[ivx1,ivx2,ivx3,ivx4,ivx5,ivx6,ivx7,ivx8,ivx9,ivx10]#各变量IV\nindex=['x1','x2','x3','x4','x5','x6','x7','x8','x9','x10']#x轴的标签\nfig1 = plt.figure(1)\nax1 = fig1.add_subplot(1, 1, 1)\nx = np.arange(len(index))+1\nax1.bar(x, ivlist, width=0.4)#生成柱状图\nax1.set_xticks(x)\nax1.set_xticklabels(index, rotation=0, fontsize=12)\nax1.set_ylabel('IV(Information Value)', fontsize=14)\n#在柱状图上添加数字标签\nfor a, b in zip(x, ivlist):\n    plt.text(a, b + 0.01, '%.4f' % b, ha='center', va='bottom', fontsize=10)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:38:46.775109Z","iopub.execute_input":"2021-07-08T11:38:46.775584Z","iopub.status.idle":"2021-07-08T11:38:46.963929Z","shell.execute_reply.started":"2021-07-08T11:38:46.775538Z","shell.execute_reply":"2021-07-08T11:38:46.962727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"证据权重（Weight of Evidence,WOE）转换可以将Logistic回归模型转变为标准评分卡格式。引入WOE转换的目的并不是为了提高模型质量，只是一些变量不应该被纳入模型，这或者是因为它们不能增加模型值，或者是因为与其模型相关系数有关的误差较大，其实建立标准信用评分卡也可以不采用WOE转换。这种情况下，Logistic回归模型需要处理更大数量的自变量。尽管这样会增加建模程序的复杂性，但最终得到的评分卡都是一样的。\n在建立模型之前，我们需要将筛选后的变量转换为WoE值，便于信用评分。\n\nWOE转换\n\n我们已经能获取了每个变量的分箱数据和woe数据，只需要根据各变量数据进行替换，实现代码如下：\n","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_curve\nfrom sklearn.metrics import auc\nfrom sklearn import metrics\nimport statsmodels.api as sm\nimport math\n \ndef trans_woe(var,var_name,x_woe,x_cut):\n    woe_name = var_name + '_woe'\n    for i in range(len(x_woe)):\n        if i == 0:\n            var.loc[(var[var_name]<=x_cut[i+1]),woe_name] = x_woe[i]\n        elif (i>0) and (i<= len(x_woe)-2):\n            var.loc[((var[var_name]>x_cut[i])&(var[var_name]<=x_cut[i+1])),woe_name] = x_woe[i]\n        else:\n            var.loc[(var[var_name]>x_cut[len(x_woe)-1]),woe_name] = x_woe[len(x_woe)-1]\n    return var\n \nx1_name = 'RevolvingUtilizationOfUnsecuredLines'\nx2_name = 'age'\nx3_name = 'NumberOfTime30-59DaysPastDueNotWorse'\nx7_name = 'NumberOfTimes90DaysLate'\nx9_name = 'NumberOfTime60-89DaysPastDueNotWorse'\n \n \nX_train = trans_woe(X_train,x1_name,woex1,cutx1)\nX_train = trans_woe(X_train,x2_name,woex2,cutx2)\nX_train = trans_woe(X_train,x3_name,woex3,cutx3)\nX_train = trans_woe(X_train,x7_name,woex7,cutx7)\nX_train = trans_woe(X_train,x9_name,woex9,cutx9)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:38:46.965601Z","iopub.execute_input":"2021-07-08T11:38:46.965893Z","iopub.status.idle":"2021-07-08T11:38:48.025791Z","shell.execute_reply.started":"2021-07-08T11:38:46.965864Z","shell.execute_reply":"2021-07-08T11:38:48.025022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Logisic模型建立和模型检验\n\n我们直接调用statsmodels包来实现逻辑回归：","metadata":{}},{"cell_type":"code","source":"\n\n\n\nX_train.to_csv('WoeData.csv', index=False)\n#6.2 Logistic模型建立\n#导入数据\ndata = pd.read_csv('WoeData.csv')\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:38:48.026873Z","iopub.execute_input":"2021-07-08T11:38:48.027305Z","iopub.status.idle":"2021-07-08T11:38:49.165559Z","shell.execute_reply.started":"2021-07-08T11:38:48.027271Z","shell.execute_reply":"2021-07-08T11:38:49.164672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n#data=data.drop([\"Unnamed: 0\"],axis=1)\nY = data['SeriousDlqin2yrs']\nX = data.iloc[:, 1:]\n#测试集占比30%\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\ntrain = pd.concat([Y_train, X_train], axis=1)\ntest = pd.concat([Y_test, X_test], axis=1)\ntest.to_csv('TestData.csv',index=False)\n\n\n# 定义自动分箱函数\n \nfrom scipy import stats\ndef mono_bin(Y, X, n = 20):\n    r = 0\n    good=Y.sum()\n    bad=Y.count()-good\n    while np.abs(r) < 1:\n        d1 = pd.DataFrame({\"X\": X, \"Y\": Y, \"Bucket\": pd.qcut(X, n,duplicates=\"drop\")}) \n        # 后面报错You can drop duplicate edges by setting the 'duplicates' kwarg，所以回到这里补充duplicates参数\n        # pandas中使用qcut()，边界易出现重复值，如果为了删除重复值设置 duplicates=‘drop’，则易出现于分片个数少于指定个数的问题\n        # 经尝试，设置duplicates参数为“drop”可行，而不能设置为“raise”。\n        d2 = d1.groupby('Bucket', as_index = True)\n        r, p = stats.spearmanr(d2.X.mean(), d2.mean().Y)\n        n = n - 1\n    d3 = pd.DataFrame(d2.X.min(), columns = ['min'])\n    d3['min'] = d2.min().X\n    d3['max'] = d2.max().X\n    d3['sum'] = d2.sum().Y\n    d3['total'] = d2.count().Y\n    d3['rate'] = d2.mean().Y\n    d3['woe']=np.log((d3['rate']/(1-d3['rate']))/(good/bad))\n    d4 = (d3.sort_values(by='min')).reset_index(drop=True)\n    print(\"=\" * 60)\n    woe=list(d4['woe'].round(3))\n    print(d4)\n    return d4","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:38:49.166641Z","iopub.execute_input":"2021-07-08T11:38:49.167109Z","iopub.status.idle":"2021-07-08T11:38:49.514523Z","shell.execute_reply.started":"2021-07-08T11:38:49.167076Z","shell.execute_reply":"2021-07-08T11:38:49.513664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#应变量\nY=train['SeriousDlqin2yrs']\n# dict_Y = {'month':Y.index,'numbers':Y.values}\n# df_month = pd.DataFrame(dict_Y)\n#自变量，剔除对因变量影响不明显的变量\nX=X_train.drop(['RevolvingUtilizationOfUnsecuredLines','age','NumberOfTime30-59DaysPastDueNotWorse','NumberOfTimes90DaysLate','NumberOfTime60-89DaysPastDueNotWorse','DebtRatio','MonthlyIncome', 'NumberOfOpenCreditLinesAndLoans','NumberRealEstateLoansOrLines','NumberOfDependents'],axis=1)\nX1=sm.add_constant(X)\nY1=Y.to_frame(name='SeriousDlqin2yrs')\nlogit=sm.Logit(Y,X1)\nresult=logit.fit()\nprint(result.summary())\nX1.columns","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:38:49.515577Z","iopub.execute_input":"2021-07-08T11:38:49.515983Z","iopub.status.idle":"2021-07-08T11:38:50.093612Z","shell.execute_reply.started":"2021-07-08T11:38:49.515953Z","shell.execute_reply":"2021-07-08T11:38:50.091878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"如上图所示逻辑回归各变量都已通过显著性检验，满足要求\n\n到这里，我们的建模部分基本结束了。我们需要验证一下模型的预测能力如何。我们使用在建模开始阶段预留的test数据进行检验。通过ROC曲线和AUC来评估模型的拟合能力。\n在Python中，可以利用sklearn.metrics，它能方便比较两个分类器，自动计算ROC和AUC。","metadata":{}},{"cell_type":"code","source":"#6.3 模型检验\n \nX_test = trans_woe(X_test,x1_name,woex1,cutx1)\nX_test = trans_woe(X_test,x2_name,woex2,cutx2)\nX_test = trans_woe(X_test,x3_name,woex3,cutx3)\nX_test = trans_woe(X_test,x7_name,woex7,cutx7)\nX_test = trans_woe(X_test,x9_name,woex9,cutx9)\n \n#应变量\nY_test = test['SeriousDlqin2yrs']\n#自变量，剔除对因变量影响不明显的变量，与模型变量对应\nX_test = X_test.iloc[:,-5:]\n#X_test =X_test.drop(['NumberOfOpenCreditLinesAndLoans','age','NumberOfTime30-59DaysPastDueNotWorse','NumberOfTimes90DaysLate','NumberOfTime60-89DaysPastDueNotWorse','DebtRatio','MonthlyIncome', 'NumberOfOpenCreditLinesAndLoans','NumberRealEstateLoansOrLines','NumberOfDependents'], axis=1)\nX3 = sm.add_constant(X_test)\nresu = result.predict(X3)#进行预测\n#result.score(X3,Y_test) \nfpr, tpr, threshold = metrics.roc_curve(Y_test, resu)\nrocauc = metrics.auc(fpr, tpr)#计算AUC\nplt.plot(fpr, tpr, 'b', label='AUC = %0.2f' % rocauc)#生成ROC曲线\nplt.legend(loc='lower right')\nplt.plot([0, 1], [0, 1], 'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('真正率')\nplt.xlabel('假正率')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:38:50.100104Z","iopub.execute_input":"2021-07-08T11:38:50.100697Z","iopub.status.idle":"2021-07-08T11:38:50.378922Z","shell.execute_reply.started":"2021-07-08T11:38:50.100642Z","shell.execute_reply":"2021-07-08T11:38:50.377885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"信用评分\n我们已经基本完成了建模相关的工作，并用ROC曲线验证了模型的预测能力。接下来的步骤，就是将Logistic模型转换为标准评分卡的形式。\n\n \n\n评分标准：\n\na=log（p_good/P_bad）\n\nScore = offset + factor * log(odds)\n\n在建立标准评分卡之前，我们需要选取几个评分卡参数：基础分值、 PDO（比率翻倍的分值）和好坏比。 这里， 我们取600分为基础分值，PDO为20 （每高20分好坏比翻一倍），好坏比取20。","metadata":{}},{"cell_type":"code","source":"# 我们取600分为基础分值，PDO为20（每高20分好坏比翻一倍），好坏比取20。\np = 20 / math.log(2)\nq = 600 - 20 * math.log(20) / math.log(2)\n#7.2 部分评分\n#计算分数函数 \ndef get_score(coe,woe,factor):\n    scores=[]\n    for w in woe:\n        score=round(coe*w*factor,0)\n        scores.append(score)\n    print(scores)    \n    return scores\n   \n \n \ncoe = [2.6138,0.6228,0.4894,0.5596,0.5747 ,0.4248]#在上面那个logistic的结果中来\nbaseScore = round(q + p * coe[0], 0)\nprint(baseScore)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:38:50.380648Z","iopub.execute_input":"2021-07-08T11:38:50.381075Z","iopub.status.idle":"2021-07-08T11:38:50.390135Z","shell.execute_reply.started":"2021-07-08T11:38:50.38101Z","shell.execute_reply":"2021-07-08T11:38:50.388823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# 各项部分分数\nx1 = get_score(coe[1], woex1, p)\nx2 = get_score(coe[2], woex2, p)\nx3 = get_score(coe[3], woex3, p)\nx7 = get_score(coe[4], woex7, p)\nx9 = get_score(coe[5], woex9, p)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:38:50.39154Z","iopub.execute_input":"2021-07-08T11:38:50.391881Z","iopub.status.idle":"2021-07-08T11:38:50.407921Z","shell.execute_reply.started":"2021-07-08T11:38:50.391851Z","shell.execute_reply":"2021-07-08T11:38:50.40674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"自动评分系统\n根据变量来计算分数，实现如下：","metadata":{}},{"cell_type":"code","source":"def compute_score(series,cut,score):\n    list = []\n    i = 0\n    while i < len(series):\n        value = series[i]\n        j = len(cut) - 2\n        m = len(cut) - 2\n        while j >= 0:\n            if value >= cut[j]:\n                j = -1\n            else:\n                j -= 1\n                m -= 1\n        list.append(score[m])\n        i += 1\n    return list\n","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:38:50.40924Z","iopub.execute_input":"2021-07-08T11:38:50.409543Z","iopub.status.idle":"2021-07-08T11:38:50.419988Z","shell.execute_reply.started":"2021-07-08T11:38:50.409512Z","shell.execute_reply":"2021-07-08T11:38:50.419154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#test = pd.read_csv('./TestData.csv')\ntest = pd.read_csv('../input/GiveMeSomeCredit/cs-test.csv')\ntest['BaseScore']=np.zeros(len(test))+baseScore\ntest['x1'] = compute_score(test['RevolvingUtilizationOfUnsecuredLines'], cutx1, x1)\ntest['x2'] = compute_score(test['age'], cutx2, x2)\ntest['x3'] = compute_score(test['NumberOfTime30-59DaysPastDueNotWorse'], cutx3, x3)\ntest['x7'] = compute_score(test['NumberOfTimes90DaysLate'], cutx7, x7)\ntest['x9'] = compute_score(test['NumberOfTime60-89DaysPastDueNotWorse'], cutx9, x9)\ntest['Score'] = test['x1'] + test['x2'] + test['x3'] + test['x7'] +test['x9']  + baseScore\ntest.to_csv('ScoreData.csv', index=False)\n\nimport math\n\ndf1 = test.loc[:,['Score']]\ndf1.sort_values(by='Score',axis=0,ascending=True,inplace=True)\ndf1['Score'][20000]\nprint(df1['Score'][101503-math.ceil(rr*101503)])\nprint(math.ceil(rr*101503))\nprint(df1['Score'][6701])\ndisplay(df1)\nte=0\nj=0\nfor te in df1['Score']:\n    if(j >= rr*101503):\n        break\n    j=j+1\nprint(j)\nprint(te)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:51:25.148078Z","iopub.execute_input":"2021-07-08T11:51:25.148431Z","iopub.status.idle":"2021-07-08T11:51:32.585439Z","shell.execute_reply.started":"2021-07-08T11:51:25.1484Z","shell.execute_reply":"2021-07-08T11:51:32.584075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntest['Score'] = (test['Score'] - 622)/(745 - 620)\nprint(test['Score'][80000])\n\nxx=0\nfor i in test['Score']:\n    if i >= 0:\n        test['Score'][xx] = 0\n    else:\n        test['Score'][xx] = 1\n    xx=xx+1\n    \n        \n\n\ntt = pd.read_csv('../input/GiveMeSomeCredit/cs-test.csv')\nscore = pd.DataFrame({\n        \"Id\": tt[\"Unnamed: 0\"],\n        \"Probability\": test['Score']\n    })\n\nscore.to_csv('score.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-08T11:55:34.3654Z","iopub.execute_input":"2021-07-08T11:55:34.365746Z","iopub.status.idle":"2021-07-08T11:56:18.731875Z","shell.execute_reply.started":"2021-07-08T11:55:34.365717Z","shell.execute_reply":"2021-07-08T11:56:18.730764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}