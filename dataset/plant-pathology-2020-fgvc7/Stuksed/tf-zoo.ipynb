{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Если хотите работать на Google Colaboratory\n\nДля получения ключа доступа для API переходите\n*   https://www.kaggle.com/lkatran (где \"lkatran\" - ваш user name)\n*   нажимаем Edit Profile\n*   находим ниже раздел API\n*   нажимаем Create New API Token\n*   загружается файл kaggle.json\n*   в нем ваш ключ","metadata":{}},{"cell_type":"code","source":"## Уберите комменты и впишите свой USERNAME и Key from Kaggle\n# !mkdir /root/.kaggle\n# import json\n# kaggle = {\"username\":\"USERNAME\",\"key\":\"Key from Kaggle\"}\n# with open('/root/.kaggle/kaggle.json', 'w') as f:\n#     json.dump(kaggle, f)\n# !chmod 600 /root/.kaggle/kaggle.json\n# kaggle competitions download -c plant-pathology-2020-fgvc7","metadata":{"execution":{"iopub.status.busy":"2022-04-04T11:43:59.956943Z","iopub.execute_input":"2022-04-04T11:43:59.957251Z","iopub.status.idle":"2022-04-04T11:43:59.962495Z","shell.execute_reply.started":"2022-04-04T11:43:59.957207Z","shell.execute_reply":"2022-04-04T11:43:59.961296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ставим Efficientnet","metadata":{}},{"cell_type":"code","source":"!pip install -q efficientnet","metadata":{"execution":{"iopub.status.busy":"2022-04-04T11:44:00.062527Z","iopub.execute_input":"2022-04-04T11:44:00.06304Z","iopub.status.idle":"2022-04-04T11:44:08.189501Z","shell.execute_reply.started":"2022-04-04T11:44:00.06299Z","shell.execute_reply":"2022-04-04T11:44:08.188578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Импорт библиотек","metadata":{}},{"cell_type":"code","source":"import math, re, os\n\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nfrom kaggle_datasets import KaggleDatasets\nimport tensorflow as tf\nimport tensorflow.keras.layers as L\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\n\n## ______________ БЛОК С ИМПОРТАМИ АРХИТЕКТУР ____________________\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications.vgg19 import VGG19\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\nfrom tensorflow.keras.applications.densenet import DenseNet121, DenseNet169, DenseNet201 \nfrom tensorflow.keras.applications.xception import Xception\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.applications.resnet_v2 import ResNet50V2, ResNet101V2, ResNet152V2\nfrom tensorflow.keras.applications.nasnet import NASNetLarge\nfrom efficientnet.tfkeras import EfficientNetB7, EfficientNetL2\n## ______________ КОНЕЦ БЛОКА С ИМПОРТАМИ АРХИТЕКТУР ____________________\n\n# импорт других полезных инструментов: слоев, оптимизаторов, функций обратной связи\nfrom tensorflow.keras.layers.experimental.preprocessing import Normalization\nfrom tensorflow.keras.layers import Flatten,Dense,Dropout,BatchNormalization\nfrom tensorflow.keras.models import Model,Sequential\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-04T11:44:08.191919Z","iopub.execute_input":"2022-04-04T11:44:08.192242Z","iopub.status.idle":"2022-04-04T11:44:08.205687Z","shell.execute_reply.started":"2022-04-04T11:44:08.192195Z","shell.execute_reply":"2022-04-04T11:44:08.204792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Настраиваем TPU конфигурацию","metadata":{}},{"cell_type":"code","source":"# Путь к данным. Если работаете на Google Colaboratory, то замените KaggleDatasets().get_gcs_path() на путь к данным, который будет у вас\nGCS_DS_PATH = KaggleDatasets().get_gcs_path()\n","metadata":{"execution":{"iopub.status.busy":"2022-04-04T11:44:08.207145Z","iopub.execute_input":"2022-04-04T11:44:08.207392Z","iopub.status.idle":"2022-04-04T11:44:08.999004Z","shell.execute_reply.started":"2022-04-04T11:44:08.207365Z","shell.execute_reply":"2022-04-04T11:44:08.998043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AUTO = tf.data.experimental.AUTOTUNE\n# Проверяем существующее оборудование и выбираем соответствующую стратегию использования вычислений\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    # онаружение TPU. Параметры не требуются если установленна переменная окружения TPU_NAME. На Kaggle это всегда True.\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() # если TPU отсутствует, то испльзуем стратегию по умолчанию для TF (CPU or GPU)\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)\n\n# Конфигурация\nEPOCHS = 47\nBATCH_SIZE = 8 * strategy.num_replicas_in_sync\nNB_CLASSES = 4\nSTEPS_PER_EPOCH = 1821 // BATCH_SIZE\nprint(STEPS_PER_EPOCH)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T11:44:09.002128Z","iopub.execute_input":"2022-04-04T11:44:09.002698Z","iopub.status.idle":"2022-04-04T11:44:18.274982Z","shell.execute_reply.started":"2022-04-04T11:44:09.002659Z","shell.execute_reply":"2022-04-04T11:44:18.273807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Посмотрим на данные","metadata":{}},{"cell_type":"markdown","source":"## Загружаем метки классов и пути к изображениям","metadata":{}},{"cell_type":"code","source":"# функция, которая превращает айди картинки в полный путь к ней\ndef format_path(st):\n    return GCS_DS_PATH + '/images/' + st + '.jpg'","metadata":{"execution":{"iopub.status.busy":"2022-04-04T11:44:18.276201Z","iopub.execute_input":"2022-04-04T11:44:18.276445Z","iopub.status.idle":"2022-04-04T11:44:18.281202Z","shell.execute_reply.started":"2022-04-04T11:44:18.276418Z","shell.execute_reply":"2022-04-04T11:44:18.280473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/train.csv')\ntest = pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/test.csv')\nsub = pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/sample_submission.csv')\n\ntrain_paths = train.image_id.apply(format_path).values\ntest_paths = test.image_id.apply(format_path).values\n\ntrain_labels = train.loc[:, 'healthy':].values\n\n# если планируете обучать модель с валидирующим набором данных\ntrain_paths, valid_paths, train_labels, valid_labels = train_test_split(\n    train_paths, train_labels, test_size=0.15, random_state=2020)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T11:44:18.282375Z","iopub.execute_input":"2022-04-04T11:44:18.283039Z","iopub.status.idle":"2022-04-04T11:44:18.316793Z","shell.execute_reply.started":"2022-04-04T11:44:18.282996Z","shell.execute_reply":"2022-04-04T11:44:18.316019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\n\n# создаем сетку 2 на 5, для более компактного отображения символов и задаем размер их отображения\nf, ax = plt.subplots(3, 6, figsize=(18, 7))\nax = ax.flatten()\n# отрисовываем в цикле найденные топ N изображений частей графем\nfor i in range(18):\n    img = plt.imread(f'../input/plant-pathology-2020-fgvc7/images/Train_{i}.jpg')\n    ax[i].set_title(train[train['image_id']==f'Train_{i}'].melt()[train[train['image_id']==f'Train_{i}'].melt().value == 1]['variable'].values[0])\n    ax[i].imshow(img)\nprint(img.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T11:44:18.318284Z","iopub.execute_input":"2022-04-04T11:44:18.3188Z","iopub.status.idle":"2022-04-04T11:44:28.299503Z","shell.execute_reply.started":"2022-04-04T11:44:18.318755Z","shell.execute_reply":"2022-04-04T11:44:28.298367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Создаем объекты наборов данных\n\nA `tf.data.Dataset` объект нужен для того, чтобы модель бесперебойно работала на TPUs","metadata":{}},{"cell_type":"code","source":"# устанавливаем глобальные переменные\nimg_size = 728\n\n# функция, которая читает изображение из файла и преобразовывает его к нужному размеру, а так же нормализует\ndef decode_image(filename, label=None, image_size=(img_size, img_size)):\n    bits = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(bits, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0\n    image = tf.image.resize(image, image_size)\n    \n    if label is None:\n        return image\n    else:\n        return image, label\n# функция расширения данных","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2022-04-04T11:44:28.301137Z","iopub.execute_input":"2022-04-04T11:44:28.301862Z","iopub.status.idle":"2022-04-04T11:44:28.310905Z","shell.execute_reply.started":"2022-04-04T11:44:28.301799Z","shell.execute_reply":"2022-04-04T11:44:28.309745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Создаем объекты наборов данных для обучения, валидации и теста","metadata":{}},{"cell_type":"code","source":"train_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((train_paths, train_labels))\n    .map(decode_image, num_parallel_calls=AUTO)\n#     .map(data_augment, num_parallel_calls=AUTO) # если напишите свою функцию расширения данных data_augment \n    .repeat()\n    .shuffle(512)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTO)\n)\n# если планируете обучать модель с валидирующим набором данных\nvalid_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((valid_paths, valid_labels))\n    .map(decode_image, num_parallel_calls=AUTO)\n    .batch(BATCH_SIZE)\n    .cache()\n    .prefetch(AUTO)\n)\n\ntest_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices(test_paths)\n    .map(decode_image, num_parallel_calls=AUTO)\n    .batch(BATCH_SIZE)\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T11:44:28.312196Z","iopub.execute_input":"2022-04-04T11:44:28.312503Z","iopub.status.idle":"2022-04-04T11:44:28.443646Z","shell.execute_reply.started":"2022-04-04T11:44:28.312471Z","shell.execute_reply":"2022-04-04T11:44:28.442403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Строим и обучаем модель","metadata":{}},{"cell_type":"markdown","source":"### Вспомогательные функции","metadata":{}},{"cell_type":"code","source":"# def get_model(use_model): \n#     base_model = use_model(weights='imagenet', \n#                       include_top=False, pooling='avg',\n#                       input_shape=(img_size, img_size, 3))\n#     base_model.trainable = False\n    \n#     model = Sequential()\n#     #model.add(Normalization())\n#     model.add(base_model)\n#     model.add(Flatten())\n#     model.add(Dense(256, activation='relu'))\n#     model.add(Dropout(0.5))\n#     model.add(Dense(NB_CLASSES, activation='softmax'))\n    \n#     return model\n\ndef get_model(use_model):\n    base_model = use_model(\n        weights='imagenet', \n        include_top=False, pooling='avg',\n        input_shape=(img_size, img_size, 3))\n    \n    #base_model.trainable = False\n    \n    x = Flatten()(base_model.layers[-1].output)\n    x = Dense(512, activation='relu')(x)\n    x = Dense(128, activation='relu')(x)\n\n    #x = Dropout(0.4)(x)\n    predictions = Dense(NB_CLASSES, activation='softmax')(x)\n\n    return Model(inputs=base_model.input, outputs=predictions)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T11:44:28.446792Z","iopub.execute_input":"2022-04-04T11:44:28.447324Z","iopub.status.idle":"2022-04-04T11:44:28.456896Z","shell.execute_reply.started":"2022-04-04T11:44:28.447285Z","shell.execute_reply":"2022-04-04T11:44:28.45548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Загружаем модель на TPU","metadata":{}},{"cell_type":"code","source":"with strategy.scope():    \n    model = get_model(EfficientNetB7) # тут подставить свою модель\n    \nmodel.compile(\n    optimizer=Adam(learning_rate=1e-5),\n    loss = 'categorical_crossentropy',\n    metrics=['categorical_accuracy'])\n\n#model.summary()\n\n#vgg16 ~91\n#vgg19 ~92\n#InceptionV3 ~93-94\n# InceptionResNetV2 ~ 91\n# DenseNet121 ~ 95.62\n##################################### DenseNet169 ~ 95-96\n# DenseNet201 ~ 94\n# Xception ~ 95,62\n# ResNet50 ~ 27\n# ResNet50V2 ~ 92\n# ResNet101V2 ~ 92\n# ResNet152V2 ~ 93.4\n# NASNetLarge ~ 20\n##################################### EfficientNetB7 ~ 95-96 - w/o_lr\n# EfficientNetL2 ~","metadata":{"execution":{"iopub.status.busy":"2022-04-04T11:44:28.458395Z","iopub.execute_input":"2022-04-04T11:44:28.459241Z","iopub.status.idle":"2022-04-04T11:45:00.875824Z","shell.execute_reply.started":"2022-04-04T11:44:28.459183Z","shell.execute_reply":"2022-04-04T11:45:00.875037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Запускаем процесс обучения","metadata":{}},{"cell_type":"code","source":"history = model.fit(train_dataset, \n          steps_per_epoch=STEPS_PER_EPOCH, \n          epochs=EPOCHS,\n          callbacks=[EarlyStopping(monitor='val_accuracy', patience=5, verbose=1, restore_best_weights=True),\n                     ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4, verbose=1),\n                     ModelCheckpoint(filepath='my_ef_net_b7.h5', monitor='val_categorical_accuracy', save_best_only=True)],\n          validation_data= valid_dataset,\n          workers = 3)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-04-04T11:45:00.877516Z","iopub.execute_input":"2022-04-04T11:45:00.878495Z","iopub.status.idle":"2022-04-04T12:22:25.879988Z","shell.execute_reply.started":"2022-04-04T11:45:00.878444Z","shell.execute_reply":"2022-04-04T12:22:25.878006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Проверка качества модели","metadata":{}},{"cell_type":"markdown","source":"Unhide below to see helper function `display_training_curves`:","metadata":{}},{"cell_type":"code","source":"# # Оцениваем качество обучения модели на тестовых данных\n# scores = model.evaluate(test_dataset, verbose=1)\n# print(\"Доля верных ответов на тестовых данных, в процентах:\", round(scores[1] * 100, 4))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-04T12:22:25.88179Z","iopub.execute_input":"2022-04-04T12:22:25.882086Z","iopub.status.idle":"2022-04-04T12:22:25.887246Z","shell.execute_reply.started":"2022-04-04T12:22:25.882051Z","shell.execute_reply":"2022-04-04T12:22:25.886471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['categorical_accuracy'], \n         label='Оценка точности на обучающем наборе')\nplt.plot(history.history['val_categorical_accuracy'], \n         label='Оценка точности на проверочном наборе')\nplt.xlabel('Эпоха обучения')\nplt.ylabel('Оценка точности')\nplt.legend()\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-04T12:22:25.888586Z","iopub.execute_input":"2022-04-04T12:22:25.889359Z","iopub.status.idle":"2022-04-04T12:22:26.154451Z","shell.execute_reply.started":"2022-04-04T12:22:25.889326Z","shell.execute_reply":"2022-04-04T12:22:26.153421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Если хотите сохранить модель, то ","metadata":{}},{"cell_type":"code","source":"#name_model = 'InceptionResNetV2.h5'\n\n## если на Google Colab, то\n# from google.colab import drive\n# drive.mount('/content/drive')\n# name_model = 'drive/My Drive/Colab Notebooks/efficientnet.h5'\n\n#model.save(name_model)\n\n## загрузить модель\n# model = tf.keras.models.load_model(name_model) # загрузить готовую модель для дальнейшего использования","metadata":{"execution":{"iopub.status.busy":"2022-04-04T12:22:26.155842Z","iopub.execute_input":"2022-04-04T12:22:26.156339Z","iopub.status.idle":"2022-04-04T12:22:26.16104Z","shell.execute_reply.started":"2022-04-04T12:22:26.156296Z","shell.execute_reply":"2022-04-04T12:22:26.160075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Делаем прогноз тестовых данных и готовим представление данных для проверки","metadata":{}},{"cell_type":"markdown","source":"Когда вы получите несколько моделей с высокими баллами, можно поробовать их объеденить\n\nprobs = (model1.predict(test_dataset)+model.predict(test_dataset))/2\n\nгде можно использовать и больше моделей, но тогда делить не на 2, а на количество использованных моделей","metadata":{}},{"cell_type":"code","source":"probs = model.predict(test_dataset)\nsub.loc[:, 'healthy':] = probs\nsub.to_csv('submission.csv', index=False)\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T12:22:26.162521Z","iopub.execute_input":"2022-04-04T12:22:26.162961Z","iopub.status.idle":"2022-04-04T12:23:32.177076Z","shell.execute_reply.started":"2022-04-04T12:22:26.162928Z","shell.execute_reply":"2022-04-04T12:23:32.176184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# создаем сетку 2 на 5, для более компактного отображения символов и задаем размер их отображения\nf, ax = plt.subplots(3, 5, figsize=(18, 8))\nax = ax.flatten()\n# отрисовываем в цикле найденные топ N изображений частей графем\nfor i in range(15):\n    img = plt.imread(f'../input/plant-pathology-2020-fgvc7/images/Test_{i}.jpg')\n    ax[i].set_title(sub[sub['image_id']==f'Test_{i}'].melt().iloc[1:][sub[sub['image_id']==f'Test_{i}'].melt().iloc[1:].value >= 0.8]['variable'].values[0])\n    ax[i].imshow(img)\nprint(img.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T12:23:32.178605Z","iopub.execute_input":"2022-04-04T12:23:32.17959Z","iopub.status.idle":"2022-04-04T12:23:40.771079Z","shell.execute_reply.started":"2022-04-04T12:23:32.17954Z","shell.execute_reply":"2022-04-04T12:23:40.769684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## если работаете с Google Colaboratory\n# !kaggle competitions submit -c plant-pathology-2020-fgvc7 -f submission.csv -m \"xception_1_efficient_1\"","metadata":{"execution":{"iopub.status.busy":"2022-04-04T12:23:40.772656Z","iopub.execute_input":"2022-04-04T12:23:40.772994Z","iopub.status.idle":"2022-04-04T12:23:40.776501Z","shell.execute_reply.started":"2022-04-04T12:23:40.772963Z","shell.execute_reply":"2022-04-04T12:23:40.775757Z"},"trusted":true},"execution_count":null,"outputs":[]}]}