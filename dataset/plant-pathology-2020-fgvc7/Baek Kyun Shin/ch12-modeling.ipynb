{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 12.4 병든 잎사귀 식별 경진대회 성능 개선\n- [병든 잎사귀 식별 경진대회 링크](https://www.kaggle.com/c/plant-pathology-2020-fgvc7)\n- [모델링 코드 참고 링크](https://www.kaggle.com/akasharidas/plant-pathology-2020-in-pytorch)","metadata":{"papermill":{"duration":0.019813,"end_time":"2021-07-28T23:49:39.978001","exception":false,"start_time":"2021-07-28T23:49:39.958188","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import torch # 파이토치 \nimport random\nimport numpy as np\nimport os\n\n# 시드값 고정\nseed = 50\nos.environ['PYTHONHASHSEED'] = str(seed)\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\ntorch.backends.cudnn.enabled = False","metadata":{"execution":{"iopub.status.busy":"2022-03-07T23:53:19.388489Z","iopub.execute_input":"2022-03-07T23:53:19.388836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# 데이터 경로\ndata_path = '/kaggle/input/plant-pathology-2020-fgvc7/'\n\ntrain = pd.read_csv(data_path + 'train.csv')\ntest = pd.read_csv(data_path + 'test.csv')\nsubmission = pd.read_csv(data_path + 'sample_submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# 훈련 데이터, 검증 데이터 분리\ntrain, valid = train_test_split(train, \n                                test_size=0.1,\n                                stratify=train[['healthy', 'multiple_diseases', 'rust', 'scab']],\n                                random_state=50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nfrom torch.utils.data import Dataset # 데이터 생성을 위한 클래스\nimport numpy as np\n\nclass ImageDataset(Dataset):\n    # 초기화 메서드(생성자)\n    def __init__(self, df, img_dir='./', transform=None, is_test=False):\n        super().__init__() # 상속받은 Dataset의 __init__() 메서드 호출\n        self.df = df\n        self.img_dir = img_dir\n        self.transform = transform\n        self.is_test = is_test\n    \n    # 데이터셋 크기 반환 메서드 \n    def __len__(self):\n        return len(self.df)\n    \n    # 인덱스(idx)에 해당하는 데이터 반환 메서드\n    def __getitem__(self, idx):\n        img_id = self.df.iloc[idx, 0]             # 이미지 ID\n        img_path = self.img_dir + img_id + '.jpg' # 이미지 파일 경로\n        image = cv2.imread(img_path)              # 이미지 파일 읽기\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # 이미지 색상 보정\n        # 이미지 변환 \n        if self.transform is not None:\n            image = self.transform(image=image)['image']\n        # 테스트 데이터면 이미지 데이터만 반환, 그렇지 않으면 타깃값도 반환 \n        if self.is_test:\n            return image # 테스트용일 때\n        else:\n            # 타깃값 4개 중 가장 큰 값의 인덱스 \n            label = np.argmax(self.df.iloc[idx, 1:5]) \n            return image, label # 훈련/검증용일 때","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 이미지 변환을 위한 모듈\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\n# 훈련 데이터용 변환기\ntransform_train = A.Compose([\n    A.Resize(450, 650),       # 이미지 크기 조절 \n    A.RandomBrightnessContrast(brightness_limit=0.2, # 밝기 대비 조절\n                               contrast_limit=0.2, p=0.3),\n    A.VerticalFlip(p=0.2),    # 상하 대칭 변환\n    A.HorizontalFlip(p=0.5),  # 좌우 대칭 변환 \n    A.ShiftScaleRotate(       # 이동, 스케일링, 회전 변환\n        shift_limit=0.1,\n        scale_limit=0.2,\n        rotate_limit=30, p=0.3),\n    A.OneOf([A.Emboss(p=1),   # 양각화, 날카로움, 블러 효과\n             A.Sharpen(p=1),\n             A.Blur(p=1)], p=0.3),\n    A.PiecewiseAffine(p=0.3), # 어파인 변환 \n    A.Normalize(),            # 정규화 변환 \n    ToTensorV2()              # 텐서로 변환\n])\n\n# 검증 및 테스트 데이터용 변환기\ntransform_test = A.Compose([\n    A.Resize(450, 650), # 이미지 크기 조절 \n    A.Normalize(),      # 정규화 변환\n    ToTensorV2()        # 텐서로 변환\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_dir = '/kaggle/input/plant-pathology-2020-fgvc7/images/'\n\ndataset_train = ImageDataset(train, img_dir=img_dir, transform=transform_train)\ndataset_valid = ImageDataset(valid, img_dir=img_dir, transform=transform_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_worker(worker_id):\n    worker_seed = torch.initial_seed() % 2**32\n    np.random.seed(worker_seed)\n    random.seed(worker_seed)\n    \ng = torch.Generator()\ng.manual_seed(0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader # 데이터 로더 클래스\n\nbatch_size = 4\n\nloader_train = DataLoader(dataset_train, batch_size=batch_size, \n                          shuffle=True, worker_init_fn=seed_worker,\n                          generator=g, num_workers=2)\nloader_valid = DataLoader(dataset_valid, batch_size=batch_size, \n                          shuffle=False, worker_init_fn=seed_worker,\n                          generator=g, num_workers=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install efficientnet-pytorch==0.7.1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from efficientnet_pytorch import EfficientNet # EfficientNet 모델\n\n# 사전 훈련된 efficientnet-b7 모델 불러오기\nmodel = EfficientNet.from_pretrained('efficientnet-b7', num_classes=4) \n\nmodel = model.to(device) # 장비 할당","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn # 신경망 모듈\n\n# 손실 함수\ncriterion = nn.CrossEntropyLoss()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 옵티마이저\noptimizer = torch.optim.AdamW(model.parameters(), lr=0.00006, weight_decay=0.0001)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 12.4.1 모델 훈련 및 성능 검증","metadata":{}},{"cell_type":"markdown","source":"### 스케줄러 설정","metadata":{}},{"cell_type":"code","source":"from transformers import get_cosine_schedule_with_warmup\n\nepochs = 39 # 총 에폭\n\n# 스케줄러 생성\nscheduler = get_cosine_schedule_with_warmup(optimizer, \n                                            num_warmup_steps=len(loader_train)*3, \n                                            num_training_steps=len(loader_train)*epochs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 훈련 및 성능 검증","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score # ROC AUC 점수 계산 함수\nfrom tqdm.notebook import tqdm # 진행률 표시 막대\n\n# 총 에폭만큼 반복\nfor epoch in range(epochs):\n    # == [ 훈련 ] ==============================================\n    model.train()        # 모델을 훈련 상태로 설정\n    epoch_train_loss = 0 # 에폭별 손실값 초기화 (훈련 데이터용)\n    \n    # '반복 횟수'만큼 반복 \n    for images, labels in tqdm(loader_train):\n        # 이미지, 레이블(타깃값) 데이터 미니배치를 장비에 할당 \n        images = images.to(device)\n        labels = labels.to(device)\n        \n        # 옵티마이저 내 기울기 초기화\n        optimizer.zero_grad()\n        # 순전파 : 이미지 데이터를 신경망 모델의 입력값으로 사용해 출력값 계산\n        outputs = model(images)\n        # 손실 함수를 활용해 outputs와 labels의 손실값 계산\n        loss = criterion(outputs, labels)\n        # 현재 배치에서의 손실 추가 (훈련 데이터용)\n        epoch_train_loss += loss.item() \n        loss.backward()  # 역전파 수행\n        optimizer.step() # 가중치 갱신\n        scheduler.step() # 스케줄러 학습률 갱신\n        \n    # 훈련 데이터 손실값 출력\n    print(f'에폭 [{epoch+1}/{epochs}] - 훈련 데이터 손실값 : {epoch_train_loss/len(loader_train):.4f}')\n    \n    # == [ 검증 ] ==============================================\n    model.eval()          # 모델을 평가 상태로 설정 \n    epoch_valid_loss = 0  # 에폭별 손실값 초기화 (검증 데이터용)\n    preds_list = []       # 예측 확률값 저장용 리스트 초기화\n    true_onehot_list = [] # 실제 타깃값 저장용 리스트 초기화\n    \n    with torch.no_grad(): # 기울기 계산 비활성화\n        # 미니배치 단위로 검증\n        for images, labels in loader_valid:\n            images = images.to(device)\n            labels = labels.to(device)\n            \n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            epoch_valid_loss += loss.item()\n            \n            preds = torch.softmax(outputs.cpu(), dim=1).numpy() # 예측 확률값\n            # 실제값 (원-핫 인코딩 형식)\n            true_onehot = torch.eye(4)[labels].cpu().numpy() \n            # 예측 확률값과 실제값 저장\n            preds_list.extend(preds)\n            true_onehot_list.extend(true_onehot)\n    # 검증 데이터 손실값 및 ROC AUC 점수 출력 \n    print(f'에폭 [{epoch+1}/{epochs}] - 검증 데이터 손실값 : {epoch_valid_loss/len(loader_valid):.4f} / 검증 데이터 ROC AUC : {roc_auc_score(true_onehot_list, preds_list):.4f}')  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 12.4.2 예측","metadata":{}},{"cell_type":"markdown","source":"### TTA(테스트 단계 데이터 증강)","metadata":{}},{"cell_type":"code","source":"# 테스트 데이터 원본 데이터셋 및 데이터 로더\ndataset_test = ImageDataset(test, img_dir=img_dir, \n                            transform=transform_test, is_test=True)\nloader_test = DataLoader(dataset_test, batch_size=batch_size, \n                         shuffle=False, worker_init_fn=seed_worker,\n                         generator=g, num_workers=2)\n\n# TTA용 데이터셋 및 데이터 로더\ndataset_TTA = ImageDataset(test, img_dir=img_dir, \n                           transform=transform_train, is_test=True)\nloader_TTA = DataLoader(dataset_TTA, batch_size=batch_size, \n                        shuffle=False, worker_init_fn=seed_worker,\n                        generator=g, num_workers=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 예측","metadata":{}},{"cell_type":"code","source":"model.eval() # 모델을 평가 상태로 설정 \n\npreds_test = np.zeros((len(test), 4)) # 예측값 저장용 배열 초기화\n\nwith torch.no_grad():\n    for i, images in enumerate(loader_test):\n        images = images.to(device)\n        outputs = model(images)\n        # 타깃 예측 확률\n        preds_part = torch.softmax(outputs.cpu(), dim=1).squeeze().numpy()\n        preds_test[i*batch_size:(i+1)*batch_size] += preds_part","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_test = submission.copy() # 제출 샘플 파일 복사\n\nsubmission_test[['healthy', 'multiple_diseases', 'rust', 'scab']] = preds_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_TTA = 7 # TTA 횟수\n\npreds_tta = np.zeros((len(test), 4)) # 예측값 저장용 배열 초기화 (TTA용)\n\n# TTA를 적용해 예측\nfor i in range(num_TTA):\n    with torch.no_grad():\n        for i, images in enumerate(loader_TTA):\n            images = images.to(device)\n            outputs = model(images)\n            # 타깃 예측 확률\n            preds_part = torch.softmax(outputs.cpu(), dim=1).squeeze().numpy()\n            preds_tta[i*batch_size:(i+1)*batch_size] += preds_part","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_tta /= num_TTA ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_tta = submission.copy() \n\nsubmission_tta[['healthy', 'multiple_diseases', 'rust', 'scab']] = preds_tta","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 제출 파일 생성","metadata":{}},{"cell_type":"code","source":"submission_test.to_csv('submission_test.csv', index=False)\nsubmission_tta.to_csv('submission_tta.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 레이블 스무딩","metadata":{}},{"cell_type":"code","source":"def apply_label_smoothing(df, target, alpha, threshold):\n    # 타깃값 복사\n    df_target = df[target].copy()\n    k = len(target) # 타깃값 개수\n    \n    for idx, row in df_target.iterrows():\n        if (row > threshold).any():         # 임계값을 넘는 타깃값인지 여부 판단\n            row = (1 - alpha)*row + alpha/k # 레이블 스무딩 적용  \n            df_target.iloc[idx] = row       # 레이블 스무딩을 적용한 값으로 변환\n    return df_target # 레이블 스무딩을 적용한 타깃값 반환","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"alpha = 0.001 # 레이블 스무딩 강도\nthreshold = 0.999 # 레이블 스무딩을 적용할 임계값\n\n# 레이블 스무딩을 적용하기 위해 DataFrame 복사\nsubmission_test_ls = submission_test.copy()\nsubmission_tta_ls = submission_tta.copy()\n\ntarget = ['healthy', 'multiple_diseases', 'rust', 'scab'] # 타깃값 열 이름\n\n# 레이블 스무딩 적용\nsubmission_test_ls[target] = apply_label_smoothing(submission_test_ls, target, \n                                                   alpha, threshold)\nsubmission_tta_ls[target] = apply_label_smoothing(submission_tta_ls, target, \n                                                  alpha, threshold)\n\nsubmission_test_ls.to_csv('submission_test_ls.csv', index=False)\nsubmission_tta_ls.to_csv('submission_tta_ls.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}