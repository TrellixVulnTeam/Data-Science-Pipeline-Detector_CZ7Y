{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 12.3 병든 잎사귀 식별 경진대회 베이스라인 모델\n- [병든 잎사귀 식별 경진대회 링크](https://www.kaggle.com/c/plant-pathology-2020-fgvc7)\n- [베이스라인 모델 코드 참고 링크](https://www.kaggle.com/akasharidas/plant-pathology-2020-in-pytorch)","metadata":{"papermill":{"duration":0.019813,"end_time":"2021-07-28T23:49:39.978001","exception":false,"start_time":"2021-07-28T23:49:39.958188","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## 12.3.1 시드값 고정 및 GPU 장비 설정\n### 시드값 고정","metadata":{}},{"cell_type":"code","source":"import torch # 파이토치 \nimport random\nimport numpy as np\nimport os\n\n# 시드값 고정\nseed = 50\nos.environ['PYTHONHASHSEED'] = str(seed)\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\ntorch.backends.cudnn.enabled = False","metadata":{"execution":{"iopub.status.busy":"2022-03-07T13:26:25.976382Z","iopub.execute_input":"2022-03-07T13:26:25.976819Z","iopub.status.idle":"2022-03-07T13:26:30.447484Z","shell.execute_reply.started":"2022-03-07T13:26:25.976708Z","shell.execute_reply":"2022-03-07T13:26:30.446746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### GPU 장비 설정","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ndevice","metadata":{"execution":{"iopub.status.busy":"2022-03-07T13:26:30.449107Z","iopub.execute_input":"2022-03-07T13:26:30.449418Z","iopub.status.idle":"2022-03-07T13:26:30.496842Z","shell.execute_reply.started":"2022-03-07T13:26:30.449382Z","shell.execute_reply":"2022-03-07T13:26:30.496063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 12.3.2 데이터 준비","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# 데이터 경로\ndata_path = '/kaggle/input/plant-pathology-2020-fgvc7/'\n\ntrain = pd.read_csv(data_path + 'train.csv')\ntest = pd.read_csv(data_path + 'test.csv')\nsubmission = pd.read_csv(data_path + 'sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-03-07T13:26:30.498182Z","iopub.execute_input":"2022-03-07T13:26:30.498632Z","iopub.status.idle":"2022-03-07T13:26:30.543101Z","shell.execute_reply.started":"2022-03-07T13:26:30.498596Z","shell.execute_reply":"2022-03-07T13:26:30.542365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 훈련 데이터, 검증 데이터 분리","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# 훈련 데이터, 검증 데이터 분리\ntrain, valid = train_test_split(train, \n                                test_size=0.1,\n                                stratify=train[['healthy', 'multiple_diseases', 'rust', 'scab']],\n                                random_state=50)","metadata":{"execution":{"iopub.status.busy":"2022-03-07T13:26:30.544394Z","iopub.execute_input":"2022-03-07T13:26:30.544683Z","iopub.status.idle":"2022-03-07T13:26:31.404576Z","shell.execute_reply.started":"2022-03-07T13:26:30.544648Z","shell.execute_reply":"2022-03-07T13:26:31.403859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 데이터셋 클래스 정의","metadata":{}},{"cell_type":"code","source":"import cv2\nfrom torch.utils.data import Dataset # 데이터 생성을 위한 클래스\nimport numpy as np\n\nclass ImageDataset(Dataset):\n    # 초기화 메서드(생성자)\n    def __init__(self, df, img_dir='./', transform=None, is_test=False):\n        super().__init__() # 상속받은 Dataset의 __init__() 메서드 호출\n        self.df = df\n        self.img_dir = img_dir\n        self.transform = transform\n        self.is_test = is_test\n    \n    # 데이터셋 크기 반환 메서드 \n    def __len__(self):\n        return len(self.df)\n    \n    # 인덱스(idx)에 해당하는 데이터 반환 메서드\n    def __getitem__(self, idx):\n        img_id = self.df.iloc[idx, 0]             # 이미지 ID\n        img_path = self.img_dir + img_id + '.jpg' # 이미지 파일 경로\n        image = cv2.imread(img_path)              # 이미지 파일 읽기\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # 이미지 색상 보정\n        # 이미지 변환 \n        if self.transform is not None:\n            image = self.transform(image=image)['image']\n        # 테스트 데이터면 이미지 데이터만 반환, 그렇지 않으면 타깃값도 반환 \n        if self.is_test:\n            return image # 테스트용일 때\n        else:\n            # 타깃값 4개 중 가장 큰 값의 인덱스 \n            label = np.argmax(self.df.iloc[idx, 1:5]) \n            return image, label # 훈련/검증용일 때","metadata":{"execution":{"iopub.status.busy":"2022-03-07T13:26:31.406721Z","iopub.execute_input":"2022-03-07T13:26:31.406926Z","iopub.status.idle":"2022-03-07T13:26:31.537512Z","shell.execute_reply.started":"2022-03-07T13:26:31.406903Z","shell.execute_reply":"2022-03-07T13:26:31.536782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 이미지 변환기 정의","metadata":{}},{"cell_type":"code","source":"# 이미지 변환을 위한 모듈\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2","metadata":{"execution":{"iopub.status.busy":"2022-03-07T13:26:31.54034Z","iopub.execute_input":"2022-03-07T13:26:31.54056Z","iopub.status.idle":"2022-03-07T13:26:32.508827Z","shell.execute_reply.started":"2022-03-07T13:26:31.540536Z","shell.execute_reply":"2022-03-07T13:26:32.508081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 훈련 데이터용 변환기\ntransform_train = A.Compose([\n    A.Resize(450, 650),       # 이미지 크기 조절 \n    A.RandomBrightnessContrast(brightness_limit=0.2, # 밝기 대비 조절\n                               contrast_limit=0.2, p=0.3),\n    A.VerticalFlip(p=0.2),    # 상하 대칭 변환\n    A.HorizontalFlip(p=0.5),  # 좌우 대칭 변환 \n    A.ShiftScaleRotate(       # 이동, 스케일링, 회전 변환\n        shift_limit=0.1,\n        scale_limit=0.2,\n        rotate_limit=30, p=0.3),\n    A.OneOf([A.Emboss(p=1),   # 양각화, 날카로움, 블러 효과\n             A.Sharpen(p=1),\n             A.Blur(p=1)], p=0.3),\n    A.PiecewiseAffine(p=0.3), # 어파인 변환 \n    A.Normalize(),            # 정규화 변환 \n    ToTensorV2()              # 텐서로 변환\n])","metadata":{"execution":{"iopub.status.busy":"2022-03-07T13:26:32.510122Z","iopub.execute_input":"2022-03-07T13:26:32.510384Z","iopub.status.idle":"2022-03-07T13:26:32.517364Z","shell.execute_reply.started":"2022-03-07T13:26:32.510341Z","shell.execute_reply":"2022-03-07T13:26:32.516721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 검증 및 테스트 데이터용 변환기\ntransform_test = A.Compose([\n    A.Resize(450, 650), # 이미지 크기 조절 \n    A.Normalize(),      # 정규화 변환\n    ToTensorV2()        # 텐서로 변환\n])","metadata":{"execution":{"iopub.status.busy":"2022-03-07T13:26:32.518703Z","iopub.execute_input":"2022-03-07T13:26:32.519161Z","iopub.status.idle":"2022-03-07T13:26:32.53344Z","shell.execute_reply.started":"2022-03-07T13:26:32.519126Z","shell.execute_reply":"2022-03-07T13:26:32.53278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 데이터셋 및 데이터 로더 생성","metadata":{}},{"cell_type":"code","source":"img_dir = '/kaggle/input/plant-pathology-2020-fgvc7/images/'\n\ndataset_train = ImageDataset(train, img_dir=img_dir, transform=transform_train)\ndataset_valid = ImageDataset(valid, img_dir=img_dir, transform=transform_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-07T13:26:32.534804Z","iopub.execute_input":"2022-03-07T13:26:32.535333Z","iopub.status.idle":"2022-03-07T13:26:32.541561Z","shell.execute_reply.started":"2022-03-07T13:26:32.535298Z","shell.execute_reply":"2022-03-07T13:26:32.540936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_worker(worker_id):\n    worker_seed = torch.initial_seed() % 2**32\n    np.random.seed(worker_seed)\n    random.seed(worker_seed)\n    \ng = torch.Generator()\ng.manual_seed(0)","metadata":{"execution":{"iopub.status.busy":"2022-03-07T13:26:32.543033Z","iopub.execute_input":"2022-03-07T13:26:32.543234Z","iopub.status.idle":"2022-03-07T13:26:32.555659Z","shell.execute_reply.started":"2022-03-07T13:26:32.543212Z","shell.execute_reply":"2022-03-07T13:26:32.554926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader # 데이터 로더 클래스\n\nbatch_size = 4\n\nloader_train = DataLoader(dataset_train, batch_size=batch_size, \n                          shuffle=True, worker_init_fn=seed_worker,\n                          generator=g, num_workers=2)\nloader_valid = DataLoader(dataset_valid, batch_size=batch_size, \n                          shuffle=False, worker_init_fn=seed_worker,\n                          generator=g, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2022-03-07T13:26:32.556987Z","iopub.execute_input":"2022-03-07T13:26:32.557238Z","iopub.status.idle":"2022-03-07T13:26:32.56458Z","shell.execute_reply.started":"2022-03-07T13:26:32.557204Z","shell.execute_reply":"2022-03-07T13:26:32.563645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 12.3.3 모델 생성","metadata":{}},{"cell_type":"markdown","source":"### EfficientNet 모델 생성","metadata":{}},{"cell_type":"code","source":"!pip install efficientnet-pytorch==0.7.1","metadata":{"execution":{"iopub.status.busy":"2022-03-07T13:26:32.566024Z","iopub.execute_input":"2022-03-07T13:26:32.566275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from efficientnet_pytorch import EfficientNet # EfficientNet 모델","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 사전 훈련된 efficientnet-b7 모델 불러오기\nmodel = EfficientNet.from_pretrained('efficientnet-b7', num_classes=4) \n\nmodel = model.to(device) # 장비 할당","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 12.3.4 모델 훈련 및 성능 검증","metadata":{}},{"cell_type":"markdown","source":"### 손실 함수와 옵티마이저 설정","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn # 신경망 모듈\n\n# 손실 함수\ncriterion = nn.CrossEntropyLoss()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 옵티마이저\noptimizer = torch.optim.AdamW(model.parameters(), lr=0.00006, weight_decay=0.0001)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 훈련 및 성능 검증","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score # ROC AUC 점수 계산 함수\nfrom tqdm.notebook import tqdm # 진행률 표시 막대 \n\nepochs = 5\n\n# 총 에폭만큼 반복\nfor epoch in range(epochs):\n    # == [ 훈련 ] ==============================================\n    model.train()        # 모델을 훈련 상태로 설정 \n    epoch_train_loss = 0 # 에폭별 손실값 초기화 (훈련 데이터용)\n    \n    # '반복 횟수'만큼 반복 \n    for images, labels in tqdm(loader_train):\n        # 이미지, 레이블(타깃값) 데이터 미니배치를 장비에 할당 \n        images = images.to(device)\n        labels = labels.to(device)\n        \n        # 옵티마이저 내 기울기 초기화\n        optimizer.zero_grad()\n        # 순전파 : 이미지 데이터를 신경망 모델의 입력값으로 사용해 출력값 계산\n        outputs = model(images)\n        # 손실 함수를 활용해 outputs와 labels의 손실값 계산\n        loss = criterion(outputs, labels)\n        # 현재 배치에서의 손실 추가 (훈련 데이터용)\n        epoch_train_loss += loss.item() \n        loss.backward() # 역전파 수행\n        optimizer.step() # 가중치 갱신\n    # 훈련 데이터 손실값 출력\n    print(f'에폭 [{epoch+1}/{epochs}] - 훈련 데이터 손실값 : {epoch_train_loss/len(loader_train):.4f}')\n    \n    # == [ 검증 ] ==============================================\n    model.eval()          # 모델을 평가 상태로 설정 \n    epoch_valid_loss = 0  # 에폭별 손실값 초기화 (검증 데이터용)\n    preds_list = []       # 예측 확률값 저장용 리스트 초기화 \n    true_onehot_list = [] # 실제 타깃값 저장용 리스트 초기화 \n    \n    with torch.no_grad(): # 기울기 계산 비활성화\n        # 미니배치 단위로 검증\n        for images, labels in loader_valid:\n            images = images.to(device)\n            labels = labels.to(device)\n            \n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            epoch_valid_loss += loss.item()\n            \n            preds = torch.softmax(outputs.cpu(), dim=1).numpy() # 예측 확률값\n            # 실제값 (원-핫 인코딩 형식)\n            true_onehot = torch.eye(4)[labels].cpu().numpy()  \n            # 예측 확률값과 실제값 저장\n            preds_list.extend(preds)\n            true_onehot_list.extend(true_onehot)\n    # 검증 데이터 손실값 및 ROC AUC 점수 출력 \n    print(f'에폭 [{epoch+1}/{epochs}] - 검증 데이터 손실값 : {epoch_valid_loss/len(loader_valid):.4f} / 검증 데이터 ROC AUC : {roc_auc_score(true_onehot_list, preds_list):.4f}')  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 12.3.5 예측 및 결과 제출","metadata":{}},{"cell_type":"code","source":"dataset_test = ImageDataset(test, img_dir=img_dir, \n                            transform=transform_test, is_test=True)\nloader_test = DataLoader(dataset_test, batch_size=batch_size, \n                         shuffle=False, worker_init_fn=seed_worker,\n                         generator=g, num_workers=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 예측","metadata":{}},{"cell_type":"code","source":"model.eval() # 모델을 평가 상태로 설정 \n\npreds = np.zeros((len(test), 4)) # 예측값 저장용 배열 초기화\n\nwith torch.no_grad():\n    for i, images in enumerate(loader_test):\n        images = images.to(device)\n        outputs = model(images)\n        # 타깃 예측 확률 \n        preds_part = torch.softmax(outputs.cpu(), dim=1).squeeze().numpy()\n        preds[i*batch_size:(i+1)*batch_size] += preds_part","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 결과 제출","metadata":{}},{"cell_type":"code","source":"submission[['healthy', 'multiple_diseases', 'rust', 'scab']] = preds\nsubmission.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}