{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Plant Pathology 2020 - FGVC7\n### Identify the category of foliar diseases in apple trees\n- [Competiton Link](https://www.kaggle.com/c/plant-pathology-2020-fgvc7)\n- [Modeling Reference Link](https://www.kaggle.com/akasharidas/plant-pathology-2020-in-pytorch)","metadata":{"papermill":{"duration":0.019124,"end_time":"2021-07-17T13:36:51.972135","exception":false,"start_time":"2021-07-17T13:36:51.953011","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"### This is Top 1.9% modeling code (25 Rank). If you think it's helpful, please upvote my code 👀\n## Upvote Is FREE !","metadata":{}},{"cell_type":"markdown","source":"# 1) EDA","metadata":{}},{"cell_type":"markdown","source":"## Look around Data","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Data path\ndata_path = '/kaggle/input/plant-pathology-2020-fgvc7/'\n\ntrain = pd.read_csv(data_path + 'train.csv')\ntest = pd.read_csv(data_path + 'test.csv')\nsubmission = pd.read_csv(data_path + 'sample_submission.csv')","metadata":{"papermill":{"duration":0.137613,"end_time":"2021-07-17T13:36:52.131005","exception":false,"start_time":"2021-07-17T13:36:51.993392","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-27T15:15:00.856093Z","iopub.execute_input":"2021-07-27T15:15:00.85653Z","iopub.status.idle":"2021-07-27T15:15:00.985088Z","shell.execute_reply.started":"2021-07-27T15:15:00.856408Z","shell.execute_reply":"2021-07-27T15:15:00.984263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape, test.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-27T15:15:00.986652Z","iopub.execute_input":"2021-07-27T15:15:00.986996Z","iopub.status.idle":"2021-07-27T15:15:00.994587Z","shell.execute_reply.started":"2021-07-27T15:15:00.986962Z","shell.execute_reply":"2021-07-27T15:15:00.993701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-27T15:15:00.996447Z","iopub.execute_input":"2021-07-27T15:15:00.996804Z","iopub.status.idle":"2021-07-27T15:15:01.020672Z","shell.execute_reply.started":"2021-07-27T15:15:00.996769Z","shell.execute_reply":"2021-07-27T15:15:01.01977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-27T15:15:01.022228Z","iopub.execute_input":"2021-07-27T15:15:01.022573Z","iopub.status.idle":"2021-07-27T15:15:01.031397Z","shell.execute_reply.started":"2021-07-27T15:15:01.022526Z","shell.execute_reply":"2021-07-27T15:15:01.030403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-27T15:15:01.032763Z","iopub.execute_input":"2021-07-27T15:15:01.033132Z","iopub.status.idle":"2021-07-27T15:15:01.052902Z","shell.execute_reply.started":"2021-07-27T15:15:01.03309Z","shell.execute_reply":"2021-07-27T15:15:01.05212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Visualization","metadata":{}},{"cell_type":"markdown","source":"### Target Value Distribution","metadata":{}},{"cell_type":"code","source":"# Extract data for each target value\nhealthy = train.loc[train['healthy']==1]\nmultiple_diseases = train.loc[train['multiple_diseases']==1]\nrust = train.loc[train['rust']==1]\nscab = train.loc[train['scab']==1]","metadata":{"execution":{"iopub.status.busy":"2021-07-27T15:15:01.054204Z","iopub.execute_input":"2021-07-27T15:15:01.054752Z","iopub.status.idle":"2021-07-27T15:15:01.07642Z","shell.execute_reply.started":"2021-07-27T15:15:01.054702Z","shell.execute_reply":"2021-07-27T15:15:01.075729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib as mpl\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nmpl.rc('font', size=15)\nplt.figure(figsize=(7, 7))\n\nlabel = ['healthy', 'multiple diseases', 'rust', 'scab'] # Target Value Value\n# Target value distribution pie chart\nplt.pie([len(healthy), len(multiple_diseases), len(rust), len(scab)], \n        labels=label, \n        autopct='%1.1f%%');","metadata":{"execution":{"iopub.status.busy":"2021-07-27T15:15:01.07746Z","iopub.execute_input":"2021-07-27T15:15:01.077835Z","iopub.status.idle":"2021-07-27T15:15:01.210223Z","shell.execute_reply.started":"2021-07-27T15:15:01.077802Z","shell.execute_reply":"2021-07-27T15:15:01.209261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Print Image","metadata":{}},{"cell_type":"code","source":"import matplotlib.gridspec as gridspec\nimport cv2 # OpenCV Library\n\ndef show_image(img_ids, rows=4, cols=3): \n    assert len(img_ids) <= rows*cols # Raise Error if number of images exceed row/column count\n\n    plt.figure(figsize=(15, 15)) # Set total Figure size\n    grid = gridspec.GridSpec(rows, cols) \n\n    # 이미지 출력\n    for idx, img_id in enumerate(img_ids):\n        img_path = f'{data_path}/images/{img_id}.jpg' # Image File Path\n        image = cv2.imread(img_path) # Read Image File\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # Convert Image Color\n        ax = plt.subplot(grid[idx])\n        ax.imshow(image) # Print Image","metadata":{"execution":{"iopub.status.busy":"2021-07-27T15:15:01.212895Z","iopub.execute_input":"2021-07-27T15:15:01.213209Z","iopub.status.idle":"2021-07-27T15:15:01.367751Z","shell.execute_reply.started":"2021-07-27T15:15:01.213183Z","shell.execute_reply":"2021-07-27T15:15:01.366992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# image_id for each target value (last 12)\nlast_healthy_img_ids = healthy['image_id'][-12:]\nlast_multiple_diseases_img_ids = multiple_diseases['image_id'][-12:]\nlast_rust_img_ids = rust['image_id'][-12:]\nlast_scab_img_ids = scab['image_id'][-12:]","metadata":{"execution":{"iopub.status.busy":"2021-07-27T15:15:01.36947Z","iopub.execute_input":"2021-07-27T15:15:01.369844Z","iopub.status.idle":"2021-07-27T15:15:01.37564Z","shell.execute_reply.started":"2021-07-27T15:15:01.369809Z","shell.execute_reply":"2021-07-27T15:15:01.374385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_image(last_healthy_img_ids) # Healthy Leaf Output","metadata":{"execution":{"iopub.status.busy":"2021-07-27T15:15:01.377211Z","iopub.execute_input":"2021-07-27T15:15:01.377589Z","iopub.status.idle":"2021-07-27T15:15:07.48637Z","shell.execute_reply.started":"2021-07-27T15:15:01.377519Z","shell.execute_reply":"2021-07-27T15:15:07.485434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_image(last_multiple_diseases_img_ids) # Leaf output with various diseases","metadata":{"execution":{"iopub.status.busy":"2021-07-27T15:15:07.487576Z","iopub.execute_input":"2021-07-27T15:15:07.487917Z","iopub.status.idle":"2021-07-27T15:15:13.252464Z","shell.execute_reply.started":"2021-07-27T15:15:07.487883Z","shell.execute_reply":"2021-07-27T15:15:13.251433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_image(last_rust_img_ids) # Leaf Output with Rust Disease","metadata":{"execution":{"iopub.status.busy":"2021-07-27T15:15:13.254011Z","iopub.execute_input":"2021-07-27T15:15:13.254351Z","iopub.status.idle":"2021-07-27T15:15:19.265434Z","shell.execute_reply.started":"2021-07-27T15:15:13.254315Z","shell.execute_reply":"2021-07-27T15:15:19.264498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_image(last_scab_img_ids) # Leaves infected with Scab disease","metadata":{"execution":{"iopub.status.busy":"2021-07-27T15:15:19.266826Z","iopub.execute_input":"2021-07-27T15:15:19.267142Z","iopub.status.idle":"2021-07-27T15:15:26.426678Z","shell.execute_reply.started":"2021-07-27T15:15:19.26711Z","shell.execute_reply":"2021-07-27T15:15:26.425478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2) Modeling","metadata":{}},{"cell_type":"markdown","source":"## Fixe seed values and device settings","metadata":{}},{"cell_type":"code","source":"import torch # Pytorch\nimport random\nimport numpy as np\nimport os\n\n# Fix Seed \nseed = 10\n\nos.environ['PYTHONHASHSEED'] = str(seed)\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\ntorch.backends.cudnn.enabled = False","metadata":{"papermill":{"duration":1.154038,"end_time":"2021-07-17T13:36:53.305712","exception":false,"start_time":"2021-07-17T13:36:52.151674","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-27T15:15:26.428353Z","iopub.execute_input":"2021-07-27T15:15:26.428731Z","iopub.status.idle":"2021-07-27T15:15:27.699008Z","shell.execute_reply.started":"2021-07-27T15:15:26.428695Z","shell.execute_reply":"2021-07-27T15:15:27.69819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set Device\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"papermill":{"duration":0.06783,"end_time":"2021-07-17T13:36:53.391555","exception":false,"start_time":"2021-07-17T13:36:53.323725","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-27T15:15:27.70029Z","iopub.execute_input":"2021-07-27T15:15:27.700646Z","iopub.status.idle":"2021-07-27T15:15:27.759918Z","shell.execute_reply.started":"2021-07-27T15:15:27.700603Z","shell.execute_reply":"2021-07-27T15:15:27.758983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prepare Data","metadata":{}},{"cell_type":"markdown","source":"### Split train data and valid data","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Split train data and valid data\n_, valid = train_test_split(train, \n                            test_size=0.1,\n                            stratify=train[['healthy', 'multiple_diseases', 'rust', 'scab']],\n                            random_state=10)","metadata":{"papermill":{"duration":0.834842,"end_time":"2021-07-17T13:36:54.244847","exception":false,"start_time":"2021-07-17T13:36:53.410005","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-27T15:15:27.761326Z","iopub.execute_input":"2021-07-27T15:15:27.761896Z","iopub.status.idle":"2021-07-27T15:15:28.526778Z","shell.execute_reply.started":"2021-07-27T15:15:27.761851Z","shell.execute_reply":"2021-07-27T15:15:28.525639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Define DataSet","metadata":{}},{"cell_type":"code","source":"import cv2\nfrom torch.utils.data import Dataset # Class for data generation\nimport numpy as np\n\nclass ImageDataset(Dataset):\n    # Initialization method\n    def __init__(self, df, img_dir='./', transform=None, is_test=False):\n        super().__init__() # Call the __init__() method of the inherited Dataset class\n        self.df = df\n        self.img_dir = img_dir\n        self.transform = transform\n        self.is_test = is_test\n    \n    # Dataset size return method\n    def __len__(self):\n        return len(self.df)\n    \n    # Data return method corresponding to index(idx)\n    def __getitem__(self, idx):\n        img_id = self.df.iloc[idx, 0] # Image ID\n        img_path = self.img_dir + img_id + '.jpg' # Image file path\n        image = cv2.imread(img_path) # Reda Image file\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # Convert Image color\n        # Transform Image\n        if self.transform is not None:\n            image = self.transform(image=image)['image']\n        # If test data, return image data only; otherwise, return target values(label) as well.\n        if self.is_test:\n            return image\n        else:\n            # Index of the largest of the four target values\n            label = np.argmax(self.df.iloc[idx, 1:5]) \n            return image, label","metadata":{"papermill":{"duration":0.259901,"end_time":"2021-07-17T13:36:54.522624","exception":false,"start_time":"2021-07-17T13:36:54.262723","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-27T15:15:28.528269Z","iopub.execute_input":"2021-07-27T15:15:28.528699Z","iopub.status.idle":"2021-07-27T15:15:28.542678Z","shell.execute_reply.started":"2021-07-27T15:15:28.528656Z","shell.execute_reply":"2021-07-27T15:15:28.541746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Define Image Transformations for Data Augmentation","metadata":{}},{"cell_type":"code","source":"# Module for Image Transformations\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\n# Transformer for train data\ntransform_train = A.Compose([\n    A.Resize(400, 600), # Resize image\n    # 밝기 및 대비 조절 \n    A.RandomBrightnessContrast(brightness_limit=0.1, \n                               contrast_limit=0.1, p=0.5),\n    A.VerticalFlip(p=0.5), # Vertical Symmetric Conversion\n    A.HorizontalFlip(p=0.5), # Horizontal Symmetric Conversion\n    # shift, Scale, Rotational Transformation\n    A.ShiftScaleRotate(\n        shift_limit=0.1,\n        scale_limit=0.2,\n        rotate_limit=25, p=0.7),\n    # Embossed, sharp, blur effect\n    A.OneOf([A.Emboss(p=1),\n             A.Sharpen(p=1),\n             A.Blur(p=1)], p=0.5),\n    A.PiecewiseAffine(p=0.5), # Affine Transformation \n    A.Normalize(), # Normalize Transformation \n    ToTensorV2() # Convert to Tensor\n])\n\n# Transformer for valid and test data\ntransform_test = A.Compose([\n    A.Resize(400, 600),\n    A.Normalize(),\n    ToTensorV2()\n])","metadata":{"papermill":{"duration":0.99662,"end_time":"2021-07-17T13:36:55.564154","exception":false,"start_time":"2021-07-17T13:36:54.567534","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-27T15:15:28.543854Z","iopub.execute_input":"2021-07-27T15:15:28.54438Z","iopub.status.idle":"2021-07-27T15:15:29.621468Z","shell.execute_reply.started":"2021-07-27T15:15:28.544337Z","shell.execute_reply":"2021-07-27T15:15:29.620558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Create Datasets and Data Loaders","metadata":{}},{"cell_type":"code","source":"img_dir = '/kaggle/input/plant-pathology-2020-fgvc7/images/'\n\ndataset_train = ImageDataset(train, img_dir=img_dir, transform=transform_train)\ndataset_valid = ImageDataset(valid, img_dir=img_dir, transform=transform_test)","metadata":{"papermill":{"duration":0.025824,"end_time":"2021-07-17T13:36:55.608208","exception":false,"start_time":"2021-07-17T13:36:55.582384","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-27T15:15:29.622907Z","iopub.execute_input":"2021-07-27T15:15:29.623319Z","iopub.status.idle":"2021-07-27T15:15:29.630351Z","shell.execute_reply.started":"2021-07-27T15:15:29.623275Z","shell.execute_reply":"2021-07-27T15:15:29.629273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_worker(worker_id):\n    worker_seed = torch.initial_seed() % 2**32\n    np.random.seed(worker_seed)\n    random.seed(worker_seed)\n    \ng = torch.Generator()\ng.manual_seed(0)","metadata":{"papermill":{"duration":0.03022,"end_time":"2021-07-17T13:36:55.659379","exception":false,"start_time":"2021-07-17T13:36:55.629159","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-27T15:15:29.632152Z","iopub.execute_input":"2021-07-27T15:15:29.632973Z","iopub.status.idle":"2021-07-27T15:15:29.641899Z","shell.execute_reply.started":"2021-07-27T15:15:29.632929Z","shell.execute_reply":"2021-07-27T15:15:29.640687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader # Class for creating data loaders\n\nbatch_size = 4\n\nloader_train = DataLoader(dataset_train, batch_size=batch_size, \n                          shuffle=True, worker_init_fn=seed_worker,\n                          generator=g)\nloader_valid = DataLoader(dataset_valid, batch_size=batch_size, \n                          shuffle=False, worker_init_fn=seed_worker,\n                          generator=g)","metadata":{"papermill":{"duration":0.025072,"end_time":"2021-07-17T13:36:55.703482","exception":false,"start_time":"2021-07-17T13:36:55.67841","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-27T15:15:29.64332Z","iopub.execute_input":"2021-07-27T15:15:29.643739Z","iopub.status.idle":"2021-07-27T15:15:29.650235Z","shell.execute_reply.started":"2021-07-27T15:15:29.643701Z","shell.execute_reply":"2021-07-27T15:15:29.649032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create and Train Model, Model Peformance Validation","metadata":{}},{"cell_type":"markdown","source":"### Create Model","metadata":{}},{"cell_type":"code","source":"!pip install efficientnet-pytorch==0.7.1","metadata":{"papermill":{"duration":9.807331,"end_time":"2021-07-17T13:37:05.530905","exception":false,"start_time":"2021-07-17T13:36:55.723574","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-27T15:15:29.651755Z","iopub.execute_input":"2021-07-27T15:15:29.652111Z","iopub.status.idle":"2021-07-27T15:15:39.343637Z","shell.execute_reply.started":"2021-07-27T15:15:29.652076Z","shell.execute_reply":"2021-07-27T15:15:39.342593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from efficientnet_pytorch import EfficientNet # EfficientNet Model\n\n# Load pre-trained efficientnet-b7 model\nmodel = EfficientNet.from_pretrained('efficientnet-b7', num_classes=4) \n\nmodel = model.to(device) # Assign device","metadata":{"papermill":{"duration":12.134376,"end_time":"2021-07-17T13:37:17.68706","exception":false,"start_time":"2021-07-17T13:37:05.552684","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-27T15:15:39.348702Z","iopub.execute_input":"2021-07-27T15:15:39.349011Z","iopub.status.idle":"2021-07-27T15:15:50.386376Z","shell.execute_reply.started":"2021-07-27T15:15:39.348978Z","shell.execute_reply":"2021-07-27T15:15:50.385497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Loss Function, Optimizer, and Scheduler","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn # Neural Network module\n\n# Loss function\ncriterion = nn.CrossEntropyLoss()","metadata":{"papermill":{"duration":0.027919,"end_time":"2021-07-17T13:37:17.73801","exception":false,"start_time":"2021-07-17T13:37:17.710091","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-27T15:15:50.388208Z","iopub.execute_input":"2021-07-27T15:15:50.388562Z","iopub.status.idle":"2021-07-27T15:15:50.39308Z","shell.execute_reply.started":"2021-07-27T15:15:50.388511Z","shell.execute_reply":"2021-07-27T15:15:50.392039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Optimizer\noptimizer = torch.optim.AdamW(model.parameters(), lr=0.00007, weight_decay=0.0001)","metadata":{"papermill":{"duration":0.089656,"end_time":"2021-07-17T13:37:17.858234","exception":false,"start_time":"2021-07-17T13:37:17.768578","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-27T15:15:50.39446Z","iopub.execute_input":"2021-07-27T15:15:50.394996Z","iopub.status.idle":"2021-07-27T15:15:50.413512Z","shell.execute_reply.started":"2021-07-27T15:15:50.394959Z","shell.execute_reply":"2021-07-27T15:15:50.41271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import get_cosine_schedule_with_warmup\n\nepochs = 38 # Number of total epochs\n\n# Scheduler\nscheduler = get_cosine_schedule_with_warmup(optimizer, \n                                            num_warmup_steps=len(loader_train)*5, \n                                            num_training_steps=len(loader_train)*epochs)","metadata":{"papermill":{"duration":4.074486,"end_time":"2021-07-17T13:37:22.013777","exception":false,"start_time":"2021-07-17T13:37:17.939291","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-27T15:15:50.414734Z","iopub.execute_input":"2021-07-27T15:15:50.415119Z","iopub.status.idle":"2021-07-27T15:15:54.562087Z","shell.execute_reply.started":"2021-07-27T15:15:50.415053Z","shell.execute_reply":"2021-07-27T15:15:54.561213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train and Validate an Model","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score # ROC AUC Score Calculation Function\nfrom tqdm.notebook import tqdm # Progress Bar\n\n# Training as much as epochs.\nfor epoch in range(epochs):\n    model.train() # Set Model to Training State\n    epoch_train_loss = 0 # Initialize loss values by epoch (for train data)\n    # Repeat 'Repeatation Counts' to extract data by mini-batch size\n    for images, labels in tqdm(loader_train):\n        # Assign image, label (target value) data mini-position to device\n        images = images.to(device)\n        labels = labels.to(device)\n        \n        # Grad Initialization in optimizer\n        optimizer.zero_grad()\n        # Calculate output values using image data as input values for neural network models\n        outputs = model(images)\n        # Use the loss function to calculate loss of outputs and labels\n        loss = criterion(outputs, labels)\n        loss.backward() # Perform Backpropagation\n        optimizer.step() # Update Weight\n        scheduler.step() # Update Scheduler Learning Rate\n        epoch_train_loss += loss.item() # Add loss in current deployment (for training data)\n    # Print Training data loss\n    print(f'Epoch [{epoch+1}/{epochs}] - Train data loss : {epoch_train_loss/len(loader_train):.4f}')\n    \n    model.eval() # Set Model to Evaluation State\n    epoch_valid_loss = 0 # Initialize loss values by epoch (for valid data)\n    preds_list = [] # Initialize the list for storing predicted probability values\n    true_onehot_list = [] # Initialize the list for storing true target values\n    \n    with torch.no_grad(): # Inactivate grad calculation\n        for images, labels in loader_valid:\n            images = images.to(device)\n            labels = labels.to(device)\n            \n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            epoch_valid_loss += loss.item()\n            \n            preds = torch.softmax(outputs.cpu(), dim=1).numpy() # Predicted Probability Value\n            true_onehot = torch.eye(4)[labels].cpu().numpy() # True value (in one-hot encoding format)\n            # Store predicted probability values and true values\n            preds_list.extend(preds)\n            true_onehot_list.extend(true_onehot)\n        # Print validation data loss values and ROC AUC scores\n        print(f'Epochs [{epoch+1}/{epochs}] - Valid data loss : {epoch_valid_loss/len(loader_valid):.4f} / Valid data ROC AUC : {roc_auc_score(true_onehot_list, preds_list):.4f}')  ","metadata":{"papermill":{"duration":24525.580768,"end_time":"2021-07-17T20:26:07.617129","exception":false,"start_time":"2021-07-17T13:37:22.036361","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-27T15:15:54.563328Z","iopub.execute_input":"2021-07-27T15:15:54.563683Z","iopub.status.idle":"2021-07-27T22:19:29.28389Z","shell.execute_reply.started":"2021-07-27T15:15:54.563646Z","shell.execute_reply":"2021-07-27T22:19:29.282698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prediction and Submission","metadata":{}},{"cell_type":"code","source":"# Test Datasets and Data Loaders\ndataset_test = ImageDataset(test, img_dir=img_dir, \n                            transform=transform_test, is_test=True)\nloader_test = DataLoader(dataset_test, batch_size=batch_size, \n                         shuffle=False, worker_init_fn=seed_worker,\n                         generator=g)\n\n# TTA Datasets and Data Loaders\ndataset_TTA = ImageDataset(test, img_dir=img_dir, \n                           transform=transform_train, is_test=True)\nloader_TTA = DataLoader(dataset_TTA, batch_size=batch_size, \n                        shuffle=False, worker_init_fn=seed_worker,\n                        generator=g)","metadata":{"papermill":{"duration":0.067788,"end_time":"2021-07-17T20:26:07.745882","exception":false,"start_time":"2021-07-17T20:26:07.678094","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-27T22:19:29.285535Z","iopub.execute_input":"2021-07-27T22:19:29.286184Z","iopub.status.idle":"2021-07-27T22:19:29.294056Z","shell.execute_reply.started":"2021-07-27T22:19:29.286128Z","shell.execute_reply":"2021-07-27T22:19:29.292871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prediction","metadata":{}},{"cell_type":"code","source":"model.eval() # Set model to evaluation state\n\npreds_test = np.zeros((len(test), 4)) # Initialize Array for Store Predicted Values\n\nwith torch.no_grad():\n    for i, images in enumerate(loader_test):\n        images = images.to(device)\n        outputs = model(images)\n        # Target Prediction Probability\n        preds_part = torch.softmax(outputs.cpu(), dim=1).squeeze().numpy()\n        preds_test[i*batch_size:(i+1)*batch_size] += preds_part","metadata":{"papermill":{"duration":151.129342,"end_time":"2021-07-17T20:28:38.972617","exception":false,"start_time":"2021-07-17T20:26:07.843275","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-27T22:19:29.295723Z","iopub.execute_input":"2021-07-27T22:19:29.29618Z","iopub.status.idle":"2021-07-27T22:22:26.306969Z","shell.execute_reply.started":"2021-07-27T22:19:29.296136Z","shell.execute_reply":"2021-07-27T22:22:26.305887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Submission","metadata":{}},{"cell_type":"code","source":"submission_test = submission.copy() # Copy Submission Sample\n\nsubmission_test[['healthy', 'multiple_diseases', 'rust', 'scab']] = preds_test","metadata":{"papermill":{"duration":0.071168,"end_time":"2021-07-17T20:28:39.104916","exception":false,"start_time":"2021-07-17T20:28:39.033748","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-27T22:22:26.308567Z","iopub.execute_input":"2021-07-27T22:22:26.308996Z","iopub.status.idle":"2021-07-27T22:22:26.323602Z","shell.execute_reply.started":"2021-07-27T22:22:26.30895Z","shell.execute_reply":"2021-07-27T22:22:26.322194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## TTA and Label Smoothing for Performance Improvements","metadata":{}},{"cell_type":"code","source":"num_TTA = 5 # Numver of TTA\n\npreds_tta = np.zeros((len(test), 4)) # Initialize Array for Store Predicted Values (TTA)\n\n# Use TTA to predict\nfor i in range(num_TTA):\n    with torch.no_grad():\n        for i, images in enumerate(loader_TTA):\n            images = images.to(device)\n            outputs = model(images)\n            # Target Prediction Probability\n            preds_part = torch.softmax(outputs.cpu(), dim=1).squeeze().numpy()\n            preds_tta[i*batch_size:(i+1)*batch_size] += preds_part","metadata":{"papermill":{"duration":1768.829661,"end_time":"2021-07-17T20:58:07.990727","exception":false,"start_time":"2021-07-17T20:28:39.161066","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-27T22:22:26.325572Z","iopub.execute_input":"2021-07-27T22:22:26.32606Z","iopub.status.idle":"2021-07-27T22:56:13.874448Z","shell.execute_reply.started":"2021-07-27T22:22:26.326004Z","shell.execute_reply":"2021-07-27T22:56:13.873339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_tta /= num_TTA ","metadata":{"papermill":{"duration":0.061858,"end_time":"2021-07-17T20:58:08.108828","exception":false,"start_time":"2021-07-17T20:58:08.04697","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-27T22:56:13.876195Z","iopub.execute_input":"2021-07-27T22:56:13.876622Z","iopub.status.idle":"2021-07-27T22:56:13.881944Z","shell.execute_reply.started":"2021-07-27T22:56:13.876575Z","shell.execute_reply":"2021-07-27T22:56:13.880639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_tta = submission.copy() \n\nsubmission_tta[['healthy', 'multiple_diseases', 'rust', 'scab']] = preds_tta","metadata":{"papermill":{"duration":0.066221,"end_time":"2021-07-17T20:58:08.229337","exception":false,"start_time":"2021-07-17T20:58:08.163116","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-27T22:56:13.883673Z","iopub.execute_input":"2021-07-27T22:56:13.884451Z","iopub.status.idle":"2021-07-27T22:56:13.902077Z","shell.execute_reply.started":"2021-07-27T22:56:13.884401Z","shell.execute_reply":"2021-07-27T22:56:13.900961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_test.to_csv('submission_test.csv', index=False)\nsubmission_tta.to_csv('submission_tta.csv', index=False)","metadata":{"papermill":{"duration":0.099147,"end_time":"2021-07-17T20:58:08.383728","exception":false,"start_time":"2021-07-17T20:58:08.284581","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-27T22:56:13.90389Z","iopub.execute_input":"2021-07-27T22:56:13.904356Z","iopub.status.idle":"2021-07-27T22:56:13.961511Z","shell.execute_reply.started":"2021-07-27T22:56:13.904304Z","shell.execute_reply":"2021-07-27T22:56:13.960488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def apply_label_smoothing(df, target, alpha, threshold):\n    # Copy Target Value\n    df_target = df[target].copy()\n    k = len(target) # Number of Target Value\n    \n    for idx, row in df_target.iterrows():\n        if (row > threshold).any(): # Determine if the target value is above the threshold\n            row = (1 - alpha)*row + alpha/k # Apply Label Smoothing\n            df_target.iloc[idx] = row # Convert to Value Applied Label Smoothing\n    return df_target # Return target value with label smoothing","metadata":{"papermill":{"duration":0.064162,"end_time":"2021-07-17T20:58:08.502472","exception":false,"start_time":"2021-07-17T20:58:08.43831","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-27T22:56:13.963311Z","iopub.execute_input":"2021-07-27T22:56:13.963803Z","iopub.status.idle":"2021-07-27T22:56:13.971623Z","shell.execute_reply.started":"2021-07-27T22:56:13.963753Z","shell.execute_reply":"2021-07-27T22:56:13.970007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"alpha = 0.01 # Label Smoothing Strength\nthreshold = 0.99 # Threshold to which label smoothing applies\n\n# Copy DataFrame to apply label smoothing\nsubmission_test_ls = submission_test.copy()\nsubmission_tta_ls = submission_tta.copy()\ntarget = ['healthy', 'multiple_diseases', 'rust', 'scab'] # Target Value Column Name\n\n# Apply Label Smoothing\nsubmission_test_ls[target] = apply_label_smoothing(submission_test_ls, target, \n                                                   alpha, threshold)\nsubmission_tta_ls[target] = apply_label_smoothing(submission_tta_ls, target, \n                                                  alpha, threshold)\n\nsubmission_test_ls.to_csv('submission_test_ls.csv', index=False)\nsubmission_tta_ls.to_csv('submission_tta_ls.csv', index=False)","metadata":{"papermill":{"duration":2.044767,"end_time":"2021-07-17T20:58:10.601228","exception":false,"start_time":"2021-07-17T20:58:08.556461","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-27T22:56:13.973719Z","iopub.execute_input":"2021-07-27T22:56:13.97419Z","iopub.status.idle":"2021-07-27T22:56:16.397229Z","shell.execute_reply.started":"2021-07-27T22:56:13.974139Z","shell.execute_reply":"2021-07-27T22:56:16.396148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = './' # Model Storing Path\n\ntorch.save({\n    'model': model.state_dict(),\n    'optimizer': optimizer.state_dict()\n    }, path + 'EfficientNet-B7.tar')","metadata":{"papermill":{"duration":1.381424,"end_time":"2021-07-17T20:58:12.037356","exception":false,"start_time":"2021-07-17T20:58:10.655932","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-27T22:56:16.398921Z","iopub.execute_input":"2021-07-27T22:56:16.39935Z","iopub.status.idle":"2021-07-27T22:56:18.166915Z","shell.execute_reply.started":"2021-07-27T22:56:16.399301Z","shell.execute_reply":"2021-07-27T22:56:18.165886Z"},"trusted":true},"execution_count":null,"outputs":[]}]}