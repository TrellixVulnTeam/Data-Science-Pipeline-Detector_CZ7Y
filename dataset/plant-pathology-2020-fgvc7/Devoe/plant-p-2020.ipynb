{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Dataset: Cómo se lee de disco (SSD o HDD) los datos y se carga a RAM. (lee uno por uno)\n# Transforms: Suposiciones sobre el data generating distribution\n# DataLoader: Agrupar las imágenes en batches\n# Suponemos que estamos haciendo Supervised Learning (inputs (x), targets(y))\n#     - p(y=y|x=x)\n# Training loop: \n#    - Definir la loss function (mide la dis-similitud entre las dist. out y target)\n#     - Forward pass: Dado un input (batch), predecir el output (batch)\n#     - Calcular el valor de la loss function: usando el output y target\n#     - Calcular la gradiente del valor de la loss function (pytorch: autograd)\n#     - Optimizer:\n#         - Adam (momentum), otros\n#         - optimizer = Adam(model.parameters(), lr=..., momentum=...)\n#         - optimizer.step() (después de haber calc las gradientes)\n#             - Step: wf = wi - lr * g\n#     - Learning Rate Scheduler: Cómo varia el learning rate durante el entrenamiento","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH = '../input/plant-pathology-2020-fgvc7/'\nIMGS_PATH = \"../input/plant-pathology-preprocessing/images/\"\nTRAIN_CSV = PATH + \"train.csv\"\nTEST_CSV = PATH + \"test.csv\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torchvision.io import read_image\nimport torchvision.transforms as T\nimport torchvision.transforms.functional as F\nimport torch.nn as nn\nimport torch.optim as optim\nimport pandas as pd\nimport numpy as np\nfrom fastai.vision.data import imagenet_stats\nfrom fastai.vision.models import resnet18\nimport math","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    num_classes = 4\n    image_size = (520, 800)\n    seed = 2020\n    batch_size = 16\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dataframe\ndf = pd.read_csv(\"../input/plant-pathology-2020-fgvc7/train.csv\")\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PlantPathology2020(Dataset): # input (img train_0.jpg), target(labels i.e.0 0 0 1)\n    def __init__(self, csv_file, imgs_path, item_tfms=None):\n        self.df = pd.read_csv(csv_file) # Dataframe\n        self.imgs_path = imgs_path # direct. de las imagenes\n        self.item_tfms = item_tfms # resize de las imagenes \n        self.len = self.df.shape[0] # n ejemplos de train\n        \n    def __len__ (self):\n        return self.len\n    \n    def __getitem__(self,idx): # devolver una o mas pares (input (img), target (vec: one-shot))\n        row = self.df.iloc[idx]\n        input_path = self.imgs_path + row[0]+'.jpg'\n        # input (torch.tensor) -> model -> output\n        image = read_image(input_path).float()\n        if image.shape[-1] < image.shape[-2]:\n            image = image.transpose(-1,-2)\n        target = torch.tensor(row[-4:], dtype=torch.float32)\n        if self.item_tfms:\n            return self. item_tfms(image),target\n        return imagege, target       ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CenterCrop(object):\n    def __init__(self, output_size: int, padding_mode: str=\"symmetric\"):\n        self.padding_mode = padding_mode\n        self.center_crop = T.CenterCrop(output_size)\n        \n    def __call__(self, x):\n        if x.shape[-2] > x.shape[-1]:\n            x = x.transpose(-1, -2)\n        d1, d2 = math.floor((x.shape[-1] - x.shape[-2]) / 2), math.ceil((x.shape[-1] - x.shape[-2]) / 2)\n        x = F.pad(x, padding=[0, d1, 0, d2], padding_mode=self.padding_mode)\n        # asumimos que las dimensiones son mayores que el output_size\n        return self.center_crop(x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Transforms (con Transfer Learning: Usar una red pre-entrenada en imagenet por ejemplo) mean, std\n\n# Resize\nitem_tfms = T.Resize(CFG.image_size)\n# Training set transforms(misc, luego nomralizar) en GPU\n'''batch_tfms = T.Compose([\n    T.RandomHorizontalFlip(p=0.2),\n    T.RandomVerticalFlip(p=0.2),\n    T.RandomApply([T.ColorJitter(brightness=0.10, contrast=0.10, saturation=0.10, hue=0.10)], p=0.2),\n    T.RandomApply([T.GaussianBlur(3)], p=0.15),\n    T.Normalize(*imagenet_stats)\n])'''\n\nbatch_tfms = T.Compose([\n    T.RandomHorizontalFlip(p=0.2),\n    T.RandomVerticalFlip(p=0.2),\n    T.Normalize(*imagenet_stats)\n])\n# validation set transforms(solo normalizar) en GPU\nvalid_tfms = T.Normalize(*imagenet_stats)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Instanciar Dataset\ndataset = PlantPathology2020(csv_file=TRAIN_CSV,\n                            imgs_path=IMGS_PATH,\n                            item_tfms=item_tfms)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_len = math.floor(0.8 * len(dataset))\nvalid_len = len(dataset) - train_len\ntrain_len, valid_len","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dataloader\ntrain_set, valid_set = random_split(dataset, [train_len, valid_len], generator=torch.Generator().manual_seed(CFG.seed))\ntrain_loader = DataLoader(train_set,\n                          batch_size=CFG.batch_size,\n                          shuffle=True,\n                          pin_memory=True)\nvalid_loader = DataLoader(valid_set,\n                          batch_size=CFG.batch_size,\n                          pin_memory=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = resnet18()\nmodel.to(CFG.device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fc.in_features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fc.out_features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fc = nn.Linear(model.fc.in_features, CFG.num_classes)\nmodel.to(CFG.device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cuando se hace toda una pasada en el dataset, ha pasado un epoch\nepochs = 10\ncriterion = nn.CrossEntropyLoss() # recibe output del modelo (logits), target","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = optim.Adam(model.parameters())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train():\n    #Training\n    for e in range(epochs):\n        train_loss = 0\n        model.train()\n        for x, y in train_loader:\n            x, y = x.cuda(non_blocking=True), y.cuda(non_blocking=True)\n            x = batch_tfms(x)\n            y_pred = model(x)\n            loss = criterion(y_pred, y.argmax(dim=1))\n            optimizer.zero_grad() # hace que las gradientes calculadas en la iteración anterior sean 0\n            loss.backward() # calcula las gradientes\n            train_loss += loss.item() \n            optimizer.step() # actualiza los pesos de los tensores de las capas de la red\n        model.eval()\n        valid_loss = 0\n        with torch.no_grad():\n            for x, y in valid_loader:\n                x, y = x.cuda(non_blocking=True), y.cuda(non_blocking=True)\n                x = valid_tfms(x)\n                y_pred = model(x)\n                loss = criterion(y_pred, y.argmax(dim=1))\n                valid_loss += loss.item()\n        print(f\"{e} training loss:\", train_loss / len(train_loader))\n        print(f\"{e} valid loss:\", valid_loss / len(valid_loader))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}