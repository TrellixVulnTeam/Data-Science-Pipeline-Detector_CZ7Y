{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-31T06:53:29.812035Z","iopub.execute_input":"2021-10-31T06:53:29.81278Z","iopub.status.idle":"2021-10-31T06:53:29.824052Z","shell.execute_reply.started":"2021-10-31T06:53:29.812696Z","shell.execute_reply":"2021-10-31T06:53:29.823231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prepare Image Directories","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/plant-pathology-2020-fgvc7/train.csv\", index_col=0)\nprint(df.shape)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-31T06:53:29.827203Z","iopub.execute_input":"2021-10-31T06:53:29.827983Z","iopub.status.idle":"2021-10-31T06:53:29.853051Z","shell.execute_reply.started":"2021-10-31T06:53:29.827953Z","shell.execute_reply":"2021-10-31T06:53:29.852423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_set, valid_set = train_test_split(df, test_size=0.2, random_state=42)\n\nprint(train_set.shape)\nprint(valid_set.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-31T06:53:29.855689Z","iopub.execute_input":"2021-10-31T06:53:29.855879Z","iopub.status.idle":"2021-10-31T06:53:30.196563Z","shell.execute_reply.started":"2021-10-31T06:53:29.855856Z","shell.execute_reply":"2021-10-31T06:53:30.195664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\nfrom shutil import copyfile\n\n# delete temp dir\nif os.path.exists('/kaggle/temp/'):\n    shutil.rmtree('/kaggle/temp/')\n\nos.mkdir('/kaggle/temp/')\n\n# train directory\nos.mkdir('/kaggle/temp/train')\nos.mkdir('/kaggle/temp/train/healthy')\nos.mkdir('/kaggle/temp/train/multiple_diseases')\nos.mkdir('/kaggle/temp/train/rust')\nos.mkdir('/kaggle/temp/train/scab')\n\n# validation directory\nos.mkdir('/kaggle/temp/valid')\nos.mkdir('/kaggle/temp/valid/healthy')\nos.mkdir('/kaggle/temp/valid/multiple_diseases')\nos.mkdir('/kaggle/temp/valid/rust')\nos.mkdir('/kaggle/temp/valid/scab')","metadata":{"execution":{"iopub.status.busy":"2021-10-31T06:53:30.197919Z","iopub.execute_input":"2021-10-31T06:53:30.198192Z","iopub.status.idle":"2021-10-31T06:53:30.322895Z","shell.execute_reply.started":"2021-10-31T06:53:30.198159Z","shell.execute_reply":"2021-10-31T06:53:30.322126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SOURCE = '/kaggle/input/plant-pathology-2020-fgvc7/images/'\n\nTRAIN_DIR = '/kaggle/temp/train/'\n\n# copy images to train directory\nfor index, data in train_set.iterrows():\n    label = df.columns[np.argmax(data)]\n    filepath = os.path.join(SOURCE, index + \".jpg\")\n    destination = os.path.join(TRAIN_DIR, label, index + \".jpg\")\n    copyfile(filepath, destination)\n    \nfor subdir in os.listdir(TRAIN_DIR):\n    print(subdir, len(os.listdir(os.path.join(TRAIN_DIR, subdir))))","metadata":{"execution":{"iopub.status.busy":"2021-10-31T06:53:30.325446Z","iopub.execute_input":"2021-10-31T06:53:30.325789Z","iopub.status.idle":"2021-10-31T06:53:32.282244Z","shell.execute_reply.started":"2021-10-31T06:53:30.325749Z","shell.execute_reply":"2021-10-31T06:53:32.281509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"VALID_DIR = '/kaggle/temp/valid/'\n\n# copy images to valid directory\nfor index, data in valid_set.iterrows():\n    label = df.columns[np.argmax(data)]\n    filepath = os.path.join(SOURCE, index + \".jpg\")\n    destination = os.path.join(VALID_DIR, label, index + \".jpg\")\n    copyfile(filepath, destination)\n    \nfor subdir in os.listdir(VALID_DIR):\n    print(subdir, len(os.listdir(os.path.join(VALID_DIR, subdir))))","metadata":{"execution":{"iopub.status.busy":"2021-10-31T06:53:32.286487Z","iopub.execute_input":"2021-10-31T06:53:32.288542Z","iopub.status.idle":"2021-10-31T06:53:32.807673Z","shell.execute_reply.started":"2021-10-31T06:53:32.288497Z","shell.execute_reply":"2021-10-31T06:53:32.806893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Epxlore Images","metadata":{}},{"cell_type":"code","source":"healthy_dir = os.path.join(TRAIN_DIR, 'healthy')\nmdiseases_dir = os.path.join(TRAIN_DIR, 'multiple_diseases')\nscab_dir = os.path.join(TRAIN_DIR, 'scab')\nrust_dir = os.path.join(TRAIN_DIR, 'rust')\n\nhealthy_files = os.listdir(healthy_dir)\nmdiseases_files = os.listdir(mdiseases_dir)\nscab_files = os.listdir(scab_dir)\nrust_files = os.listdir(rust_dir) ","metadata":{"execution":{"iopub.status.busy":"2021-10-31T06:53:32.808876Z","iopub.execute_input":"2021-10-31T06:53:32.809606Z","iopub.status.idle":"2021-10-31T06:53:32.817673Z","shell.execute_reply.started":"2021-10-31T06:53:32.809564Z","shell.execute_reply":"2021-10-31T06:53:32.816683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\npic_index = 2\n\nnext_healthy = [os.path.join(healthy_dir, fname) for fname in healthy_files[pic_index-2:pic_index]]\nnext_mdiseases = [os.path.join(mdiseases_dir, fname) for fname in mdiseases_files[pic_index-2:pic_index]]\nnext_scab = [os.path.join(scab_dir, fname) for fname in scab_files[pic_index-2:pic_index]]\nnext_rust = [os.path.join(rust_dir, fname) for fname in rust_files[pic_index-2:pic_index]]\n\n\nnrows = 4\nncols = 4\n\nfig = plt.gcf()\nfig.set_size_inches(ncols*4, nrows*4)\n\nfor i, img_path in enumerate(next_healthy+next_mdiseases+next_scab+next_rust):\n    sp = plt.subplot(nrows, ncols, i + 1)\n    sp.axis('Off') # Don't show axes (or gridlines)\n    img = mpimg.imread(img_path)\n    plt.title(img_path.split('/')[-2])\n    plt.imshow(img)\n    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-31T06:53:32.819028Z","iopub.execute_input":"2021-10-31T06:53:32.819395Z","iopub.status.idle":"2021-10-31T06:53:35.564912Z","shell.execute_reply.started":"2021-10-31T06:53:32.819351Z","shell.execute_reply":"2021-10-31T06:53:35.563953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# keras ImageGenerator API","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport keras_preprocessing\nfrom keras_preprocessing import image\nfrom keras_preprocessing.image import ImageDataGenerator\n\ntraining_datagen = ImageDataGenerator(rescale = 1./255,\n                                      rotation_range=40,\n                                      width_shift_range=0.2,\n                                      height_shift_range=0.2,\n                                      shear_range=0.2,\n                                      zoom_range=0.2,\n                                      horizontal_flip=True,\n                                      fill_mode='nearest')\n\nvalidation_datagen = ImageDataGenerator(rescale = 1./255)\n\ntrain_generator = training_datagen.flow_from_directory(TRAIN_DIR, target_size=(150,150), class_mode='categorical', batch_size=32)\nvalidation_generator = validation_datagen.flow_from_directory(VALID_DIR, target_size=(150,150), class_mode='categorical', batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2021-10-31T06:53:35.566018Z","iopub.execute_input":"2021-10-31T06:53:35.566311Z","iopub.status.idle":"2021-10-31T06:53:37.296597Z","shell.execute_reply.started":"2021-10-31T06:53:35.566264Z","shell.execute_reply":"2021-10-31T06:53:37.295743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CNN modeling","metadata":{}},{"cell_type":"code","source":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dense(4, activation='softmax')\n])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-31T06:53:37.298091Z","iopub.execute_input":"2021-10-31T06:53:37.298554Z","iopub.status.idle":"2021-10-31T06:53:38.347561Z","shell.execute_reply.started":"2021-10-31T06:53:37.298511Z","shell.execute_reply":"2021-10-31T06:53:38.346807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss = 'categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n\nearly_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=5)\ncheckpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"cnn.h5\", save_best_only=True)\n\nhistory = model.fit(train_generator, epochs=50, steps_per_epoch=46, \n                    validation_data = validation_generator, validation_steps=12, callbacks=[early_stopping_cb, checkpoint_cb])","metadata":{"execution":{"iopub.status.busy":"2021-10-31T06:53:38.349042Z","iopub.execute_input":"2021-10-31T06:53:38.349293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend(loc=0)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Make Predictions","metadata":{}},{"cell_type":"code","source":"model = tf.keras.models.load_model(\"cnn.h5\") # rollback to best model\nmodel.evaluate(validation_generator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras_preprocessing import image\n\ntest_set = pd.read_csv(\"/kaggle/input/plant-pathology-2020-fgvc7/test.csv\", index_col=0)\n\nX_test = []\nfor index, data in test_set.iterrows():\n    filepath = os.path.join(SOURCE, index + \".jpg\")\n    img = image.load_img(filepath, target_size=(150, 150))\n    x = image.img_to_array(img)\n    x = np.expand_dims(x, axis=0)\n    X_test.append(x)\n    \nX_test = np.vstack(X_test) / 255 # rescale images","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(X_test, batch_size=10)\ndf_out = pd.concat([test_set.reset_index(), pd.DataFrame(y_pred, columns = train_generator.class_indices.keys())], axis=1).set_index(\"image_id\")\ndf_out.to_csv('submission.csv')\ndf_out.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nrows = 4\nncols = 4\n\nfig = plt.gcf()\nfig.set_size_inches(ncols*4, nrows*4)\n\nfor i, (idx, row) in enumerate(df_out.sample(nrows*ncols).iterrows()):\n    filepath = filepath = os.path.join(SOURCE, idx + \".jpg\")\n    sp = plt.subplot(nrows, ncols, i + 1)\n    sp.axis('Off') # Don't show axes (or gridlines)\n    img = mpimg.imread(filepath)\n    plt.title(df_out.columns[np.argmax(row)])\n    plt.imshow(img)\n    \nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}