{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Convolutional neural network, Plant pathology"},{"metadata":{},"cell_type":"markdown","source":"I try to take basic \"Convolutional neural network\".<br>\nHow to improve prediction accuracy, 'Data augmentation', 'Batchnormalization', 'Dropout'<br>\nI'm a starter, so there's nothing special about it, but I hope it's good information for the same beginner.<br>\n*I dropped Data Augmentation, because GPU is down."},{"metadata":{},"cell_type":"markdown","source":"### 1. Data loading and Data checking\n### 2. Preporcessing\n### 3. Define the model\n### 4. Calculation\n### 5. Check the result\n### 6. Prediction from test data\n### 7. Creation submit data"},{"metadata":{},"cell_type":"markdown","source":"## Libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Basic library\nimport numpy as np \nimport pandas as pd \n\n# Data preprocessing\nimport cv2 # Open cv\nfrom sklearn.model_selection import train_test_split\n\n# Visualization\nfrom matplotlib import pyplot as plt\n\n# Machine learning library\nimport keras\nfrom keras.models import Sequential, Model, load_model\nfrom keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization, Activation, Input\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom keras.preprocessing.image import ImageDataGenerator","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data loading"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# dataframe data\nsample_submission = pd.read_csv(\"../input/plant-pathology-2020-fgvc7/sample_submission.csv\")\ntest = pd.read_csv(\"../input/plant-pathology-2020-fgvc7/test.csv\")\ntrain = pd.read_csv(\"../input/plant-pathology-2020-fgvc7/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This time, image size is 64Ã—64, increasing the size will increase accuracy, but I decided here because the memory would die."},{"metadata":{"trusted":true},"cell_type":"code","source":"# train image data\nsize = 64\ntrain_image_data = []\n\n# loading\nfor _id in train[\"image_id\"]:\n    path = '../input/plant-pathology-2020-fgvc7/images/'+_id+'.jpg'\n    img = cv2.imread(path)\n    image = cv2.resize(img, (size, size), interpolation=cv2.INTER_AREA)\n    train_image_data.append(image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test image data\nsize = 64\ntest_image_data = []\n\n# loading\nfor _id in test[\"image_id\"]:\n    path = '../input/plant-pathology-2020-fgvc7/images/'+_id+'.jpg'\n    img = cv2.imread(path)\n    image = cv2.resize(img, (size, size), interpolation=cv2.INTER_AREA)\n    test_image_data.append(image)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data checking"},{"metadata":{"trusted":true},"cell_type":"code","source":"# sample_submission data\nsample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train data\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data information\ndef data_info(data):\n    print(\"-\"*20, \"data_info\", \"-\"*20)\n    print(data.info())\n    print(\"-\"*20, \"data_info\", \"-\"*20)\n\ndata_info(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test data\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train image data size\nlen(train_image_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualization, train_data\nfig, ax = plt.subplots(1,3,figsize=(10,10))\nfor i in range(3):\n    ax[i].imshow(train_image_data[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualization, test_data\nfig, ax = plt.subplots(1,3,figsize=(10,10))\nfor i in range(3):\n    ax[i].imshow(test_image_data[i])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The image is blurry, but features, Leaf shape/contour/color,  are almost captured."},{"metadata":{},"cell_type":"markdown","source":"## 2. Preporcessing"},{"metadata":{},"cell_type":"markdown","source":"Train data shape adjusting for learning"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data dimension\nX_Train = np.ndarray(shape=(len(train_image_data), size, size, 3),\n                     dtype=np.float32)\n# Change to nu.ndarray\ni=0\nfor image in train_image_data:\n    X_Train[i]=train_image_data[i]\n    i=i+1\n    \n# Scaling\nX_Train = X_Train/255\n\n# Checking dimension\nprint(\"Train_shape:{}\".format(X_Train.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Test data shape adjusting for predicting"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data dimension adjust\nX_Test = np.ndarray(shape=(len(test_image_data), size, size, 3),\n                     dtype=np.float32)\n# Change to np.ndarray\ni=0\nfor image in test_image_data:\n    X_Test[i]=test_image_data[i]\n    i=i+1\n    \n# Scaling\nX_Test = X_Test/255\n\n# Checking dimension\nprint(\"Train_shape:{}\".format(X_Test.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Train targe"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train.iloc[:,1:]\n\n# change to np.array\ny = np.array(y.values)\nprint(\"y_shape:{}\".format(y.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Preparing Training data and validation data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# data split\nX_train, X_val, y_train, y_val = train_test_split(X_Train,\n                                                  y,\n                                                  test_size=0.2,\n                                                  random_state=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# target data\ny_train1 = [y[0] for y in y_train]\ny_train2 = [y[1] for y in y_train]\ny_train3 = [y[2] for y in y_train]\ny_train4 = [y[3] for y in y_train]\n\n# val data\ny_val1 = [y[0] for y in y_val]\ny_val2 = [y[1] for y in y_val]\ny_val3 = [y[2] for y in y_val]\ny_val4 = [y[3] for y in y_val]\n\n# convert class vectors to binary class metrices\ny_train1 = keras.utils.to_categorical(y_train1, 2)\ny_train2 = keras.utils.to_categorical(y_train2, 2)\ny_train3 = keras.utils.to_categorical(y_train3, 2)\ny_train4 = keras.utils.to_categorical(y_train4, 2)\n\ny_val1 = keras.utils.to_categorical(y_val1, 2)\ny_val2 = keras.utils.to_categorical(y_val2, 2)\ny_val3 = keras.utils.to_categorical(y_val3, 2)\ny_val4 = keras.utils.to_categorical(y_val4, 2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Define the model"},{"metadata":{},"cell_type":"markdown","source":"I used representative technique, Data augmentation, BatchNormalization, Dropout in Convolutional neural network."},{"metadata":{"trusted":true},"cell_type":"code","source":"def define_model():\n    inputs = Input(shape=(size, size, 3))\n    \n    # 1st layer\n    x = BatchNormalization()(inputs)\n    x = Conv2D(filters=128, kernel_size=(3,3), strides=(1,1))(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    x = Conv2D(filters=128, kernel_size=(3,3), strides=(1,1))(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    x = MaxPool2D(pool_size=(2,2))(x)\n    x = Dropout(0.2)(x)\n    \n    # 2nd layer\n    x = Conv2D(filters=256, kernel_size=(3,3), strides=(1,1))(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    x = Conv2D(filters=256, kernel_size=(3,3), strides=(1,1))(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    x = MaxPool2D(pool_size=(2,2))(x)\n    x = Dropout(0.2)(x)\n    \n    # 3rd layer\n    x = Conv2D(filters=512, kernel_size=(3,3), strides=(1,1))(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    x = Conv2D(filters=512, kernel_size=(3,3), strides=(1,1))(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    x = MaxPool2D(pool_size=(2,2))(x)\n    x = Dropout(0.2)(x)\n    \n    # Flatten\n    x = Flatten()(x)\n    \n    # Dens layer\n    x = Dense(1024, activation='relu')(x)\n    x = Dropout(0.2)(x)\n    x = Dense(1024, activation='relu')(x)\n    x = Dropout(0.2)(x)\n    \n    output1 = Dense(2, activation=\"softmax\", name='output1')(x)\n    output2 = Dense(2, activation=\"softmax\", name='output2')(x)\n    output3 = Dense(2, activation=\"softmax\", name='output3')(x)\n    output4 = Dense(2, activation=\"softmax\", name='output4')(x)\n    \n    multiModel = Model(inputs, [output1, output2, output3, output4])\n    \n    # initiate Adam optimizer\n    opt = keras.optimizers.adam(lr=0.0001, decay=0.00001)\n    \n    # Compile\n    multiModel.compile(loss={'output1':'categorical_crossentropy',\n                            'output2':'categorical_crossentropy',\n                            'output3':'categorical_crossentropy',\n                            'output4':'categorical_crossentropy'},\n                      optimizer=opt,\n                      metrics=[\"accuracy\"])\n    return multiModel","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Calculation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# data augmentation, This is dropped because GPU is down.\ndatagen = ImageDataGenerator(rotation_range=360,\n                             width_shift_range=0.2,\n                             height_shift_range=0.2,\n                             horizontal_flip=True)\ndatagen.fit(X_train)\n\n# define early stopping\nes_cb = EarlyStopping(monitor='val_loss',\n                    patience=15,\n                    verbose=1)\ncp_cb = ModelCheckpoint(\"cnn_model_02.h5\",\n                        monitor='val_loss',\n                        verbose=1,\n                        save_best_only=True)\n# parameters\nbatch_size = 8\nepochs = 100\n\n# train model\nmodel = define_model()\nhistory = model.fit(X_train,\n                   {'output1':y_train1,\n                    'output2':y_train2,\n                    'output3':y_train3,\n                    'output4':y_train4},\n                   batch_size=batch_size,\n                   epochs=epochs,\n                   validation_data=(X_val,\n                                   {'output1':y_val1,\n                                    'output2':y_val2,\n                                    'output3':y_val3,\n                                    'output4':y_val4}),\n                   callbacks=[es_cb, cp_cb])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5. Check the result"},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_loss\ntrain1_loss = history.history[\"output1_loss\"]\ntrain2_loss = history.history[\"output2_loss\"]\ntrain3_loss = history.history[\"output3_loss\"]\ntrain4_loss = history.history[\"output4_loss\"]\n\n# val_loss\nval1_loss = history.history[\"val_output1_loss\"]\nval2_loss = history.history[\"val_output2_loss\"]\nval3_loss = history.history[\"val_output3_loss\"]\nval4_loss = history.history[\"val_output4_loss\"]\n\n# train_accuracy\ntrain1_acc = history.history[\"output1_accuracy\"]\ntrain2_acc = history.history[\"output2_accuracy\"]\ntrain3_acc = history.history[\"output3_accuracy\"]\ntrain4_acc = history.history[\"output4_accuracy\"]\n\n# val_accuracy\nval1_acc = history.history[\"val_output1_accuracy\"]\nval2_acc = history.history[\"val_output2_accuracy\"]\nval3_acc = history.history[\"val_output3_accuracy\"]\nval4_acc = history.history[\"val_output4_accuracy\"]\n\n# Visualization\nfig, ax = plt.subplots(2,4,figsize=(25,10))\nplt.subplots_adjust(wspace=0.3)\n\n# train1 loss\nax[0,0].plot(range(len(train1_loss)), train1_loss, label='train1_loss')\nax[0,0].plot(range(len(val1_loss)), val1_loss, label='val1_loss')\nax[0,0].set_xlabel('epoch', fontsize=16)\nax[0,0].set_ylabel('loss', fontsize=16)\nax[0,0].set_yscale('log')\nax[0,0].legend(fontsize=16)\n\n# train2 loss\nax[0,1].plot(range(len(train2_loss)), train2_loss, label='train2_loss')\nax[0,1].plot(range(len(val2_loss)), val2_loss, label='val2_loss')\nax[0,1].set_xlabel('epoch', fontsize=16)\nax[0,1].set_ylabel('loss', fontsize=16)\nax[0,1].set_yscale('log')\nax[0,1].legend(fontsize=16)\n\n# train3 loss\nax[0,2].plot(range(len(train3_loss)), train3_loss, label='train3_loss')\nax[0,2].plot(range(len(val2_loss)), val3_loss, label='val3_loss')\nax[0,2].set_xlabel('epoch', fontsize=16)\nax[0,2].set_ylabel('loss', fontsize=16)\nax[0,2].set_yscale('log')\nax[0,2].legend(fontsize=16)\n\n# train4 loss\nax[0,3].plot(range(len(train4_loss)), train4_loss, label='train4_loss')\nax[0,3].plot(range(len(val4_loss)), val4_loss, label='val4_loss')\nax[0,3].set_xlabel('epoch', fontsize=16)\nax[0,3].set_ylabel('loss', fontsize=16)\nax[0,3].set_yscale('log')\nax[0,3].legend(fontsize=16)\n\n# train1 accuracy\nax[1,0].plot(range(len(train1_acc)), train1_acc, label='train1_accuracy')\nax[1,0].plot(range(len(val1_acc)), val1_acc, label='val1_accuracy')\nax[1,0].set_xlabel('epoch', fontsize=16)\nax[1,0].set_ylabel('accuracy', fontsize=16)\nax[1,0].set_yscale('log')\nax[1,0].legend(fontsize=16)\n\n# train2 accuracy\nax[1,1].plot(range(len(train2_acc)), train2_acc, label='train2_accuracy')\nax[1,1].plot(range(len(val2_acc)), val2_acc, label='val2_accuracy')\nax[1,1].set_xlabel('epoch', fontsize=16)\nax[1,1].set_ylabel('accuracy', fontsize=16)\nax[1,1].set_yscale('log')\nax[1,1].legend(fontsize=16)\n\n# train3 accuracy\nax[1,2].plot(range(len(train3_acc)), train3_acc, label='train3_accuracy')\nax[1,2].plot(range(len(val3_acc)), val3_acc, label='val3_accuracy')\nax[1,2].set_xlabel('epoch', fontsize=16)\nax[1,2].set_ylabel('accuracy', fontsize=16)\nax[1,2].set_yscale('log')\nax[1,2].legend(fontsize=16)\n\n# train4 accuracy\nax[1,3].plot(range(len(train4_acc)), train4_acc, label='train4_accuracy')\nax[1,3].plot(range(len(val4_acc)), val4_acc, label='val4_accuracy')\nax[1,3].set_xlabel('epoch', fontsize=16)\nax[1,3].set_ylabel('accuracy', fontsize=16)\nax[1,3].set_yscale('log')\nax[1,3].legend(fontsize=16)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Although over-fitting tendency is seen for each label, the accuracy of the evaluation data has reached almost 90%."},{"metadata":{},"cell_type":"markdown","source":"## 6. Prediction from test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = load_model('cnn_model_02.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict = model.predict(X_Test)\nhealthy = [y_test[1] for y_test in predict[0]]\nmultiple_diseases = [y_test[1] for y_test in predict[1]]\nrust = [y_test[1] for y_test in predict[2]]\nscab = [y_test[1] for y_test in predict[3]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit = pd.DataFrame({\"image_id\":test[\"image_id\"],\n                    \"healthy\":healthy,\n                    \"multiple_diseases\":multiple_diseases,\n                    \"rust\":rust,\n                    \"scab\":scab})\nsubmit.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 7. Creation submit data"},{"metadata":{"trusted":true},"cell_type":"code","source":"submit.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}