{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from __future__ import print_function\nimport numpy as np # For numerical fast numerical calculations\nimport matplotlib.pyplot as plt # For making plots\nimport pandas as pd \nimport cv2\nimport tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt # plotting library\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense , Activation, Dropout, Conv2D, Flatten, MaxPooling2D, GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam, RMSprop\nfrom tensorflow.keras.metrics import AUC, Accuracy\nfrom tensorflow.keras.utils import to_categorical, plot_model\nimport os, datetime\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array\nfrom imblearn.over_sampling import SMOTE\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras import backend as K\nfrom random import randint, seed\nfrom datetime import datetime\nK.clear_session()","metadata":{"execution":{"iopub.status.busy":"2022-06-03T11:56:01.335232Z","iopub.execute_input":"2022-06-03T11:56:01.33569Z","iopub.status.idle":"2022-06-03T11:56:01.359942Z","shell.execute_reply.started":"2022-06-03T11:56:01.33565Z","shell.execute_reply":"2022-06-03T11:56:01.359216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_SIZE = 300\nBATCH_SIZE = 24\nEPOCH = 100","metadata":{"execution":{"iopub.status.busy":"2022-06-03T11:56:05.308178Z","iopub.execute_input":"2022-06-03T11:56:05.308932Z","iopub.status.idle":"2022-06-03T11:56:05.313217Z","shell.execute_reply.started":"2022-06-03T11:56:05.308885Z","shell.execute_reply":"2022-06-03T11:56:05.312413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('../input/plant-pathology-2020-fgvc7/train.csv')\ntest_data = pd.read_csv('../input/plant-pathology-2020-fgvc7/test.csv')\n# sub = pd.read_csv('../input/plant-pathology-2020-fgvc7/sample_submission.csv')\nFILE_PATH = str(\"../input/plant-pathology-2020-fgvc7/images/\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-03T11:56:05.529023Z","iopub.execute_input":"2022-06-03T11:56:05.529597Z","iopub.status.idle":"2022-06-03T11:56:05.566694Z","shell.execute_reply.started":"2022-06-03T11:56:05.529545Z","shell.execute_reply":"2022-06-03T11:56:05.565595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Process the images, convert it into an array and store it in training_images","metadata":{}},{"cell_type":"code","source":"prog = tf.keras.utils.Progbar(1821,width=100,verbose=1)\ntraining_images = []\nfor index, image in enumerate(train_data['image_id']):\n    image_path = FILE_PATH + image + \".jpg\"\n    image = cv2.imread(image_path)\n    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_AREA)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    training_images.append(image)\n    prog.update(index+1) ","metadata":{"execution":{"iopub.status.busy":"2022-06-03T11:56:05.841623Z","iopub.execute_input":"2022-06-03T11:56:05.842082Z","iopub.status.idle":"2022-06-03T11:57:55.842488Z","shell.execute_reply.started":"2022-06-03T11:56:05.842034Z","shell.execute_reply":"2022-06-03T11:57:55.84169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train = np.ndarray(shape=(len(training_images), IMG_SIZE, IMG_SIZE,3),dtype=np.float32)\nfor index, image in enumerate(training_images): \n    x_train[index] = img_to_array(image)\n    x_train[index] = training_images[index]\nx_train = x_train/255\nprint(x_train.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-03T11:57:55.844362Z","iopub.execute_input":"2022-06-03T11:57:55.84464Z","iopub.status.idle":"2022-06-03T11:57:57.297597Z","shell.execute_reply.started":"2022-06-03T11:57:55.844601Z","shell.execute_reply":"2022-06-03T11:57:57.2968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"convert the labels into a one-hot-encoded format","metadata":{}},{"cell_type":"code","source":"labels = train_data[['healthy', 'multiple_diseases', 'rust', 'scab']]\ny_train = np.array(labels.values)\nprint(y_train.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-03T11:57:57.299016Z","iopub.execute_input":"2022-06-03T11:57:57.299299Z","iopub.status.idle":"2022-06-03T11:57:57.311734Z","shell.execute_reply.started":"2022-06-03T11:57:57.299265Z","shell.execute_reply":"2022-06-03T11:57:57.310835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"plot and visualize the images","metadata":{}},{"cell_type":"code","source":"fig, axis = plt.subplots(1,5, figsize=(20,20))\nseed(23)\nfor i in range(5):\n    axis[i].set_axis_off()\n    rand_num = randint(0,1821)\n    axis[i].imshow(x_train[rand_num])\n    title = \"image:{} and class: {}\".format(rand_num, y_train[rand_num])\n    axis[i].set_title(title)","metadata":{"execution":{"iopub.status.busy":"2022-06-03T11:57:57.314585Z","iopub.execute_input":"2022-06-03T11:57:57.314884Z","iopub.status.idle":"2022-06-03T11:57:57.950297Z","shell.execute_reply.started":"2022-06-03T11:57:57.314826Z","shell.execute_reply":"2022-06-03T11:57:57.947932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"split the dataset into 20% validation and 80% training dataset","metadata":{}},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size = 0.2, random_state = 42)\nprint(\"x_train:\", x_train.shape, \" y_train:\", y_train.shape, \" x_test:\", x_test.shape, \" y_test:\", y_test.shape)\nclass_sum = np.sum(y_train, axis =0)\nprint(class_sum)","metadata":{"execution":{"iopub.status.busy":"2022-06-03T11:57:57.951448Z","iopub.execute_input":"2022-06-03T11:57:57.951715Z","iopub.status.idle":"2022-06-03T11:57:58.535698Z","shell.execute_reply.started":"2022-06-03T11:57:57.95168Z","shell.execute_reply":"2022-06-03T11:57:58.533983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"oversample the minority class and level the dataset. firstly reshape the iamges into a 2D array. Once the smote resample is done, reshape the image back to its original shape","metadata":{}},{"cell_type":"code","source":"# x_train = x_train.reshape(-1, IMG_SIZE * IMG_SIZE *3)\noversample = SMOTE(sampling_strategy='minority', k_neighbors=7)\n# oversample = SMOTE()\nx_train, y_train = oversample.fit_resample(x_train.reshape((-1, IMG_SIZE * IMG_SIZE *3)), y_train)\nx_train = x_train.reshape((-1, IMG_SIZE, IMG_SIZE, 3))\nx_test, y_test = oversample.fit_resample(x_test.reshape((-1, IMG_SIZE * IMG_SIZE *3)), y_test)\nx_test = x_test.reshape((-1, IMG_SIZE, IMG_SIZE, 3))","metadata":{"execution":{"iopub.status.busy":"2022-06-03T11:57:58.537296Z","iopub.execute_input":"2022-06-03T11:57:58.5376Z","iopub.status.idle":"2022-06-03T11:58:03.33998Z","shell.execute_reply.started":"2022-06-03T11:57:58.53756Z","shell.execute_reply":"2022-06-03T11:58:03.339109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"check the shapes of the x_train and y_train. Additionally, look at the sum of the classes to see how many images are in each class","metadata":{}},{"cell_type":"code","source":"print(\"after smote: x_train:\", x_train.shape, \" y_train:\", y_train.shape)\nprint(\"number of images in each class for training:\", np.sum(y_train, axis =0))\n\nprint(\"after smote: x_test:\", x_test.shape, \" y_test:\", y_test.shape)\nprint(\"number of images in each class for validation:\", np.sum(y_test, axis =0))","metadata":{"execution":{"iopub.status.busy":"2022-06-03T11:58:03.341563Z","iopub.execute_input":"2022-06-03T11:58:03.341819Z","iopub.status.idle":"2022-06-03T11:58:03.350546Z","shell.execute_reply.started":"2022-06-03T11:58:03.341781Z","shell.execute_reply":"2022-06-03T11:58:03.349631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"plot images that have class multiple disease class to see how the smote method performed","metadata":{}},{"cell_type":"code","source":"fig, axis = plt.subplots(1,5, figsize=(20,20))\ncounter = 0\nwhile counter < 5:\n    rand_num = randint(0,x_train.shape[0])\n    if y_train[rand_num][1] == 1: \n        axis[counter].set_axis_off()\n        axis[counter].imshow(x_train[rand_num])\n        title = \"image:{} and class: {}\".format(rand_num, y_train[rand_num])\n        axis[counter].set_title(title)\n        counter += 1","metadata":{"execution":{"iopub.status.busy":"2022-06-03T11:58:03.352014Z","iopub.execute_input":"2022-06-03T11:58:03.352943Z","iopub.status.idle":"2022-06-03T11:58:04.01697Z","shell.execute_reply.started":"2022-06-03T11:58:03.352898Z","shell.execute_reply":"2022-06-03T11:58:04.015793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"create the CNN model","metadata":{}},{"cell_type":"code","source":"reg_lambda = 0.005\nmodel = Sequential() \nmodel.add(Conv2D(32, kernel_size=(3,3), input_shape=(IMG_SIZE, IMG_SIZE, 3), activation='relu', kernel_regularizer=l2(reg_lambda)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, kernel_size=(3,3), activation='relu', kernel_regularizer=l2(reg_lambda)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2), padding='SAME'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(128, kernel_size=(3,3), activation='relu', kernel_regularizer=l2(reg_lambda)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2), padding='SAME'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(512, kernel_size=(3,3), activation='relu', kernel_regularizer=l2(reg_lambda)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(128, kernel_size=(3,3), activation='relu', kernel_regularizer=l2(reg_lambda)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2), padding='SAME'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(128, kernel_size=(3,3), activation='relu', kernel_regularizer=l2(reg_lambda)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, kernel_size=(3,3), activation='relu', kernel_regularizer=l2(reg_lambda)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2), padding='SAME'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(128, kernel_size=(3,3), activation='relu', kernel_regularizer=l2(reg_lambda)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(512, kernel_size=(3,3), activation='relu', kernel_regularizer=l2(reg_lambda)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2), padding='SAME'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Flatten())\nmodel.add(Dense(300, activation='relu', kernel_regularizer=l2(reg_lambda)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(200, activation='relu', kernel_regularizer=l2(reg_lambda)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(100, activation='relu', kernel_regularizer=l2(reg_lambda)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\nmodel.add(Dense(4, activation='softmax'))\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-06-03T11:58:04.018859Z","iopub.execute_input":"2022-06-03T11:58:04.01934Z","iopub.status.idle":"2022-06-03T11:58:06.892659Z","shell.execute_reply.started":"2022-06-03T11:58:04.019299Z","shell.execute_reply":"2022-06-03T11:58:06.891809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"define the callbacks, metrics and compile model","metadata":{}},{"cell_type":"code","source":"lr_reduce = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor='val_accuracy',\n    patience = 10, \n    verbose = 1,\n    min_delta = 0.000001,\n    min_lr=0,\n    factor = 0.5, \n    mode = 'auto'\n)\nearly_stop = tf.keras.callbacks.EarlyStopping(\n    monitor = 'val_loss', \n    patience = 20,\n    mode='auto',\n    verbose=1, \n    restore_best_weights =True\n)\nadam = Adam(learning_rate=0.001)\nrmsprop = tf.keras.optimizers.RMSprop(learning_rate = 0.001)\nloss = 'categorical_crossentropy'\nmetrics = [tf.keras.metrics.CategoricalAccuracy(name='accuracy'), tf.keras.metrics.AUC(curve='ROC')]\n\nmodel.compile(optimizer=adam, loss=loss, metrics=metrics)","metadata":{"execution":{"iopub.status.busy":"2022-06-03T11:58:06.896222Z","iopub.execute_input":"2022-06-03T11:58:06.896807Z","iopub.status.idle":"2022-06-03T11:58:06.924316Z","shell.execute_reply.started":"2022-06-03T11:58:06.896774Z","shell.execute_reply":"2022-06-03T11:58:06.923609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rotation_range=45, \n    shear_range=.25,\n    zoom_range = 0.20, \n    width_shift_range= 0.25,\n    rescale = 1./255,\n    height_shift_range= 0.25, \n    brightness_range=[.5,1.5],\n    horizontal_flip=True, \n    vertical_flip=True,\n    fill_mode = 'nearest'\n)\nvalidation_datagen = ImageDataGenerator(rescale = 1./255, rotation_range = 20, zoom_range= 10, horizontal_flip=True, vertical_flip=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-03T11:58:06.925525Z","iopub.execute_input":"2022-06-03T11:58:06.925771Z","iopub.status.idle":"2022-06-03T11:58:06.935003Z","shell.execute_reply.started":"2022-06-03T11:58:06.925741Z","shell.execute_reply":"2022-06-03T11:58:06.934181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start_time = datetime.now().time()\nhistory = model.fit(train_datagen.flow(x_train, y_train, batch_size = BATCH_SIZE),\n                    epochs = EPOCH, \n                    steps_per_epoch = x_train.shape[0]//BATCH_SIZE,\n                    validation_data =train_datagen.flow(x_test,y_test, batch_size = BATCH_SIZE),\n                    validation_steps = x_test.shape[0] // BATCH_SIZE,\n                    callbacks= [lr_reduce, early_stop], \n                    verbose = 1 \n                   )\n","metadata":{"execution":{"iopub.status.busy":"2022-06-03T11:58:06.936418Z","iopub.execute_input":"2022-06-03T11:58:06.93677Z","iopub.status.idle":"2022-06-03T13:02:40.975715Z","shell.execute_reply.started":"2022-06-03T11:58:06.936726Z","shell.execute_reply":"2022-06-03T13:02:40.974895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(start_time)\nprint(datetime.now().time())","metadata":{"execution":{"iopub.status.busy":"2022-06-03T13:05:57.060494Z","iopub.execute_input":"2022-06-03T13:05:57.060788Z","iopub.status.idle":"2022-06-03T13:05:57.067909Z","shell.execute_reply.started":"2022-06-03T13:05:57.060755Z","shell.execute_reply":"2022-06-03T13:05:57.066881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\n\npred_test = model.predict(x_test)\nroc_sum = 0\nfor i in range(4):\n    score = roc_auc_score(y_test[:, i], pred_test[:, i])\n    roc_sum += score\n    print(f'{score:.3f}')\n\nroc_sum /= 4\nprint(f'totally:{roc_sum:.3f}')","metadata":{"execution":{"iopub.status.busy":"2022-06-03T13:05:59.685455Z","iopub.execute_input":"2022-06-03T13:05:59.686047Z","iopub.status.idle":"2022-06-03T13:06:01.66406Z","shell.execute_reply.started":"2022-06-03T13:05:59.686006Z","shell.execute_reply":"2022-06-03T13:06:01.663278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"h = history.history\n\noffset = 5\nepochs = range(offset, len(h['loss']))\n\nplt.figure(1, figsize=(20, 6))\n\nplt.subplot(121)\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.plot(epochs, h['loss'][offset:], label='train')\nplt.plot(epochs, h['val_loss'][offset:], label='val')\nplt.legend()\n\nplt.subplot(122)\nplt.xlabel('epochs')\nplt.ylabel('accuracy')\nplt.plot(h[f'accuracy'], label='train')\nplt.plot(h[f'val_accuracy'], label='val')\nplt.legend()\nplt.show()\n\n\nplt.figure(1, figsize=(20, 8))\nplt.subplot(121)\nplt.xlabel('epochs')\nplt.ylabel('auc')\nplt.plot(h[f'auc'], label='train')\nplt.plot(h[f'val_auc'], label='val')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-03T13:06:04.925469Z","iopub.execute_input":"2022-06-03T13:06:04.92574Z","iopub.status.idle":"2022-06-03T13:06:05.620538Z","shell.execute_reply.started":"2022-06-03T13:06:04.925709Z","shell.execute_reply":"2022-06-03T13:06:05.619719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import ConfusionMatrixDisplay\nfrom sklearn.metrics import confusion_matrix\n\nclass_labels = [\"Healthy\", \"Multi\", \"Rust\", \"Scab\"]\n\ncm = confusion_matrix(np.asarray(y_test).argmax(axis=1), np.asarray(pred_test).argmax(axis=1))\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n\ndisp.plot(cmap=plt.cm.Blues)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-03T13:06:14.49275Z","iopub.execute_input":"2022-06-03T13:06:14.493494Z","iopub.status.idle":"2022-06-03T13:06:14.749268Z","shell.execute_reply.started":"2022-06-03T13:06:14.493455Z","shell.execute_reply":"2022-06-03T13:06:14.748525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"cnn_apr_12_adam_lr_0.001.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-06-03T13:06:18.453479Z","iopub.execute_input":"2022-06-03T13:06:18.453972Z","iopub.status.idle":"2022-06-03T13:06:18.844166Z","shell.execute_reply.started":"2022-06-03T13:06:18.453931Z","shell.execute_reply":"2022-06-03T13:06:18.843252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prog = tf.keras.utils.Progbar(1821,width=100,verbose=1)\ntesting_images = []\nfor index, image in enumerate(test_data['image_id']):\n    image_path = FILE_PATH + image + \".jpg\"\n    image = cv2.imread(image_path)\n    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n    testing_images.append(image)\n    prog.update(index+1) ","metadata":{"execution":{"iopub.status.busy":"2022-06-03T13:06:21.933467Z","iopub.execute_input":"2022-06-03T13:06:21.934076Z","iopub.status.idle":"2022-06-03T13:07:30.038639Z","shell.execute_reply.started":"2022-06-03T13:06:21.934031Z","shell.execute_reply":"2022-06-03T13:07:30.037793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = np.ndarray(shape=(len(test_data['image_id']), IMG_SIZE, IMG_SIZE,3),dtype=np.float32)\nfor index, image in enumerate(testing_images): \n    X_test[index] = img_to_array(image)\n    X_test[index] = testing_images[index]\nX_test = X_test/255\nprint(X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-03T13:08:07.946434Z","iopub.execute_input":"2022-06-03T13:08:07.946721Z","iopub.status.idle":"2022-06-03T13:08:09.4838Z","shell.execute_reply.started":"2022-06-03T13:08:07.946689Z","shell.execute_reply":"2022-06-03T13:08:09.482026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ids = test_data['image_id']\npred = model.predict(X_test)\nres = pd.DataFrame()\nres['image_id'] = test_ids\nres['healthy'] = pred[:, 0]\nres['multiple_diseases'] = pred[:, 1]\nres['rust'] = pred[:, 2]\nres['scab'] = pred[:, 3]\nres.to_csv('./submitions.csv', index=False)\nres.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}