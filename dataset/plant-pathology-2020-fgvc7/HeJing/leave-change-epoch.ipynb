{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!pip install -q efficientnet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os \nimport gc\nimport re\n\nimport cv2\nimport math\nimport numpy as np\nimport scipy as sp\nimport pandas as pd\n\nimport tensorflow as tf\nfrom IPython.display import SVG\nimport efficientnet.tfkeras as efn\nfrom keras.utils import plot_model\nimport tensorflow.keras.layers as L\nfrom keras.utils import model_to_dot\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.models import Model\nfrom kaggle_datasets import KaggleDatasets\nfrom tensorflow.keras.applications import DenseNet121\n\nimport seaborn as sns\nfrom tqdm import tqdm\nimport matplotlib.cm as cm\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\n\ntqdm.pandas()\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\nfrom keras.preprocessing.image import ImageDataGenerator\n\nnp.random.seed(0)\ntf.random.set_seed(0)\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS=40\nSAMPLE_LEN=100\nIMAGE_PATH='../input/plant-pathology-2020-fgvc7/images/'\nTEST_PATH='../input/plant-pathology-2020-fgvc7/test.csv'\nTRAIN_PATH='../input/plant-pathology-2020-fgvc7/train.csv'\nSUB_PATH='../input/plant-pathology-2020-fgvc7/sample_submission.csv'\n\nsub=pd.read_csv(SUB_PATH)\ntrain_data=pd.read_csv(TRAIN_PATH)\ntest_data=pd.read_csv(TEST_PATH)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"AUTO=tf.data.experimental.AUTOTUNE\ntpu=tf.distribute.cluster_resolver.TPUClusterResolver()\n\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\nstrategy=tf.distribute.experimental.TPUStrategy(tpu)\n\nBATCH_SIZE=16*strategy.num_replicas_in_sync\nGCS_DS_PATH=KaggleDatasets().get_gcs_path()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def format_path(st):\n    return GCS_DS_PATH+'/images/'+st+'.jpg'\n\ntest_paths=test_data.image_id.apply(format_path).values\ntrain_paths=train_data.image_id.apply(format_path).values\n\ntrain_labels=np.float32(train_data.loc[:,'healthy':'scab'].values)\ntrain_paths,valid_paths,train_labels,valid_labels=\\\ntrain_test_split(train_paths,train_labels,test_size=0.15,random_state=2020)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def decode_image(filename,label=None,image_size=(800,800)):\n    bits=tf.io.read_file(filename)\n    image=tf.image.decode_jpeg(bits,channels=3)\n    image=tf.cast(image,tf.float32)/255.0\n    image=tf.image.resize(image,image_size)\n    \n    if label is None:\n        return image\n    else:\n        return image,label\n    \ndef data_augment(image,label=None):\n    image=tf.image.random_flip_left_right(image)\n    image=tf.image.random_flip_up_down(image)\n    image=tf.image.rot90(image)\n    image=tf.image.transpose(image)\n    image=tf.image.random_brightness(image,0.2)\n    image=tf.image.random_contrast(image,0.2,0.5)\n    image=tf.image.random_hue(image,0.2)\n    \n    if label is None:\n        return image\n    else:\n        return image,label\n                                  \n\n     #help(tf.image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#gridmask","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nIMG_DIM=(800,800)\nAugParams={\n     'd1':100,\n     'd2':160,\n     'rotate':45,\n     'ratio':0.5\n}\n\ndef transform(image,inv_mat,image_shape):\n    h,w,c=image_shape\n    cx,cy=w//2,h//2\n    \n    new_xs=tf.repeat(tf.range(-cx,cx,1),h)\n    new_ys=tf.tile(tf.range(-cy,cy,1),[w])\n    new_zs=tf.ones([h*w],dtype=tf.int32)\n    \n    old_coords=tf.matmul(inv_mat,tf.cast(tf.stack([new_xs,new_ys,new_zs]),tf.float32))\n    old_coords_x,old_coords_y=tf.round(old_coords[0,:]+w//2),tf.round(old_coords[1,:]+h//2)\n    \n    clip_mask_x=tf.logical_or(old_coords_x<0,old_coords_x>w-1)\n    clip_mask_y=tf.logical_or(old_coords_y<0,old_coords_y>h-1)\n    clip_mask=tf.logical_or(clip_mask_x,clip_mask_y)\n    \n    old_coords_x=tf.boolean_mask(old_coords_x,tf.logical_not(clip_mask))\n    old_coords_y=tf.boolean_mask(old_coords_y,tf.logical_not(clip_mask))\n    new_coords_x=tf.boolean_mask(new_xs+cx,tf.logical_not(clip_mask))\n    new_coords_y=tf.boolean_mask(new_ys+cy,tf.logical_not(clip_mask))\n    \n    old_coords=tf.cast(tf.stack([old_coords_y,old_coords_x]),tf.int32)\n    new_coords=tf.cast(tf.stack([new_coords_y,new_coords_x]),tf.int64)\n    rotated_image_values=tf.gather_nd(image,tf.transpose(old_coords))\n    rotated_image_channel=list()\n    for i in range(c):\n        vals=rotated_image_values[:,i]\n        sparse_channel=tf.SparseTensor(tf.transpose(new_coords),vals,[h,w])\n        rotated_image_channel.append(tf.sparse.to_dense(sparse_channel,default_value=0,validate_indices=False))\n    return tf.transpose(tf.stack(rotated_image_channel),[1,2,0])\n\ndef random_rotate(image,angle,image_shape):\n    def get_rotation_mat_inv(angle):\n        angle=math.pi*angle/180\n        \n        cos_val=tf.math.cos(angle)\n        sin_val=tf.math.sin(angle)\n        one=tf.constant([1],tf.float32)\n        zero=tf.constant([0],tf.float32)\n        \n        rot_mat_inv=tf.concat([cos_val,sin_val,zero,\n                                 -sin_val,cos_val,zero,\n                                 zero,zero,one],axis=0)\n        rot_mat_inv=tf.reshape(rot_mat_inv,[3,3])\n        \n        return rot_mat_inv\n    \n    angle=float(angle)*tf.random.normal([1],dtype='float32')\n    rot_mat_inv=get_rotation_mat_inv(angle)\n    return transform(image,rot_mat_inv,image_shape)\n\ndef GridMask(image_height,image_width,d1,d2,rotate_angle=1,ration=0.5):\n    h,w=image_height,image_width\n    hh=int(np.ceil(np.sqrt(h*h+w*w)))\n    hh=hh+1 if hh%2==1 else hh\n    d=tf.random.uniform(shape=[],minval=d1,maxval=d2,dtype=tf.int32)\n    l=tf.cast(tf.cast(d,tf.float32)*ration+0.5,tf.int32)\n    \n    st_h=tf.random.uniform(shape=[],minval=0,maxval=d,dtype=tf.int32)\n    st_w=tf.random.uniform(shape=[],minval=0,maxval=d,dtype=tf.int32)\n    \n    y_ranges=tf.range(-1*d+st_h,-1*d+st_h+1)\n    x_ranges=tf.range(-1*d+st_w,-1*d+st_w+1)\n    \n    for i in range(0,hh//d+1):\n        s1=i*d+st_h\n        s2=i*d+st_w\n        x_ranges=tf.concat([y_ranges,tf.range(s1,s1+1)],axis=0)\n        x_ranges=tf.concat([x_ranges,tf.range(s2,s2+1)],axis=0)\n        \n    x_clip_mask=tf.logical_or(x_ranges<0,x_ranges>hh-1)\n    y_clip_mask=tf.logical_or(y_ranges<0,y_ranges>hh-1)\n    clip_mask=tf.logical_or(x_clip_mask,y_clip_mask)\n    \n    x_ranges=tf.boolean_mask(x_ranges,tf.logical_not(clip_mask))\n    y_ranges=tf.boolean_mask(y_ranges,tf.logical_not(clip_mask))\n    \n    hh_ranges=tf.tile(tf.range(0,hh),[tf.cast(tf.reduce_sum(tf.ones_like(x_ranges)),tf.int32)])\n    x_ranges=tf.repeat(x_ranges,hh)\n    y_ranges=tf.repeat(y_ranges,hh)\n    \n    y_hh_indices=tf.transpose(tf.stack([y_ranges,hh_ranges]))\n    x_hh_indices=tf.transpose(tf.stack([hh_ranges,x_ranges]))\n    \n    y_mask_sparse=tf.SparseTensor(tf.cast(y_hh_indices,tf.int64),tf.zeros_like(y_ranges),[hh,hh])\n    y_mask=tf.sparse.to_dense(y_mask_sparse,1,False)\n    \n    x_mask_sparse=tf.SparseTensor(tf.cast(x_hh_indices,tf.int64),tf.zeros_like(x_ranges),[hh,hh])\n    x_mask=tf.sparse.to_dense(x_mask_sparse,1,False)\n    \n    mask=tf.expand_dims(tf.clip_by_value(x_mask+y_mask,0,1),axis=-1)\n    \n    mask=random_rotate(mask,rotate_angle,[hh,hh,1])\n    mask=tf.image.crop_to_bounding_box(mask,(hh-h)//2,(hh-w)//2,image_height,image_width)\n    return mask\n\ndef apply_grid_mask(image,image_shape):\n    mask=GridMask(image_shape[0],\n                 image_shape[1],\n                 AugParams['d1'],\n                 AugParams['d2'],\n                 AugParams['rotate'],\n                 AugParams['ratio'])\n    if image_shape[-1]==3:\n        mask=tf.concat([mask,mask,mask],axis=-1)\n        \n    return image*tf.cast(mask,tf.float32)\n\ndef augmentation(image,label=None):\n    if tf.random.uniform(shape=[],minval=0.0,maxval=1.0)>=0.5:\n        image=apply_grid_mask(image,(*IMG_DIM,3))\n    if label==None:\n        return tf.cast(image,tf.float32)\n    else:\n        return tf.cast(image,tf.float32),label\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset=(\n   tf.data.Dataset\n   .from_tensor_slices((train_paths,train_labels))\n   .map(decode_image,num_parallel_calls=AUTO)\n   .map(data_augment,num_parallel_calls=AUTO)\n   .repeat()\n   .shuffle(800)\n   .batch(BATCH_SIZE)\n   .prefetch(AUTO))\n\nvalid_dataset=(\n  tf.data.Dataset\n  .from_tensor_slices((valid_paths,valid_labels))\n  .map(decode_image,num_parallel_calls=AUTO)\n  .batch(BATCH_SIZE)\n  .cache()\n  .prefetch(AUTO))\n\ntest_dataset=(\n   tf.data.Dataset\n   .from_tensor_slices(test_paths)\n   .map(decode_image,num_parallel_calls=AUTO)\n   .batch(BATCH_SIZE))\n#help(tf.data.Dataset)\n#train_dataset\nvalid_nolabel=(\n    tf.data.Dataset\n    .from_tensor_slices(valid_paths)\n    .map(decode_image,num_parallel_calls=AUTO)\n    .batch(BATCH_SIZE))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_lrfn(lr_start=0.00001,lr_max=0.000075,\n               lr_min=0.000001,lr_rampup_epochs=20,\n              lr_sustain_epochs=0,lr_exp_decay=.8):\n    lr_max=lr_max*strategy.num_replicas_in_sync\n    \n    def lrfn(epoch):\n        if epoch<lr_rampup_epochs:\n            lr=(lr_max-lr_start)/lr_rampup_epochs*epoch+lr_start\n        elif epoch<lr_rampup_epochs+lr_sustain_epochs:\n            lr=lr_max\n        else:\n            lr=(lr_max-lr_min)*\\\n               lr_exp_decay**(epoch-lr_rampup_epochs\\\n                             -lr_sustain_epochs)+lr_min\n        return lr\n    return lrfn\n\nfrom keras.callbacks import ModelCheckpoint\nch_p=ModelCheckpoint(filepath='model_ef.h5',monitor='val_loss',save_weights_only=True,verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#cosine_schedule_with_warmup","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"WARMUP=15\nLR=0.0008\ndef get_cosine_schedule_with_warmup(lr,num_warmup_steps,num_training_steps,num_cycles=0.5):\n    def lrfn(epoch):\n        if epoch<num_warmup_steps:\n            return float(epoch)/float(max(1,num_warmup_steps))*lr\n        progress=float(epoch-num_warmup_steps)/float(max(1,num_training_steps-num_warmup_steps))\n        return max(0.0,0.5*(1.0+math.cos(math.pi*float(num_cycles)*2.0*progress)))*lr\n    return tf.keras.callbacks.LearningRateScheduler(lrfn,verbose=True)\n\nlr_schedule=get_cosine_schedule_with_warmup(lr=LR,num_warmup_steps=WARMUP,num_training_steps=EPOCHS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lrfn=build_lrfn()\nSTEPS_PER_EPOCH=train_labels.shape[0]//BATCH_SIZE\nlr_schedule=tf.keras.callbacks.LearningRateScheduler(lrfn,verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras.backend as K\ndef categorical_focal_loss(gamma=2.0,alpha=0.25):\n    def focal_loss(y_true,y_pred):\n        epsilon=K.epsilon()\n        y_pred=K.clip(y_pred,epsilon,1.0-epsilon)\n        cross_entropy=-y_true*K.log(y_pred)\n        weight=alpha*y_true*K.pow((1-y_pred),gamma)\n        loss=weight*cross_entropy\n        loss=K.sum(loss,axis=1)\n        return loss\n    return focal_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import regularizers\nimport tensorflow.keras as keras\ndef get_model():\n    model=keras.Sequential()\n    model.add(DenseNet121(input_shape=(800,800,3),\n                         weights='imagenet',\n                         include_top=False))\n    model.add(L.GlobalAveragePooling2D())\n    model.add(L.Dense(train_labels.shape[1],activation='softmax'))\n                     #kernel_regularizer=regularizers.l2(0.01)))\n    model.summary\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import regularizers\nimport tensorflow.keras as keras\ndef get_model():\n    model=keras.Sequential()\n    model.add(tf.keras.applications.DenseNet201(input_shape=(800,800,3),\n                         weights='imagenet',\n                         include_top=False))\n    model.add(L.GlobalAveragePooling2D())\n    model.add(L.Dense(train_labels.shape[1],activation='softmax',\n                     kernel_regularizer=regularizers.l2(0.01)))\n    model.summary\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import regularizers\nimport tensorflow.keras as keras\ndef get_model():\n    model=keras.Sequential()\n    model.add(keras.applications.InceptionResNetV2(input_shape=(800,800,3),\n                               weights='imagenet',\n                               include_top=False))\n    model.add(L.GlobalAveragePooling2D())\n    model.add(L.Dense(train_labels.shape[1],activation='softmax'))\n                     #kernel_regularizer=regularizers.l2(0.01)))\n    model.summary\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nwith strategy.scope():\n    model=get_model()\n    model.compile(optimizer='adam',\n                 loss=['categorical_crossentropy'],\n                 metrics=['categorical_accuracy'])\n\n    \n    #help(tf.keras.Sequential)\n    #help(regularizers)\n    #help(model.compile)\n    #help(tf.losses.categorical_crossentropy)\n    #help(label_smoothing)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#focal_loss\nwith strategy.scope():\n    model=get_model()\n    model.compile(optimizer='adam',\n                 loss=[categorical_focal_loss(gamma=2.0,alpha=0.25)],\n                 metrics=['categorical_accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history=model.fit(train_dataset,\n                 epochs=EPOCHS,\n                 callbacks=[lr_schedule,ch_p],\n                 steps_per_epoch=STEPS_PER_EPOCH,\n                 validation_data=valid_dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_training_curves(training,validation,yaxis):\n    if yaxis=='loss':\n        ylabel='Loss'\n        title='Loss vs. Epochs'\n    else:\n        ylabel='Accuracy'\n        title='Accuracy vs. Epochs'\n        \n    fig=go.Figure()\n    \n    fig.add_trace(\n        go.Scatter(x=np.arange(1,EPOCHS+1),mode='lines+markers',y=training,marker=dict(color='dodgerblue'),\n                name='Train'))\n    fig.add_trace(\n        go.Scatter(x=np.arange(1,EPOCHS+1),mode='lines+markers',y=validation,marker=dict(color='darkorange'),\n                name='Val'))\n    fig.update_layout(title_text=title,yaxis_title=ylabel,xaxis_title='Epochs',template='plotly_white')\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_training_curves(\n   history.history['categorical_accuracy'],\n   history.history['val_categorical_accuracy'],\n   'accuracy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_training_curves(\n   history.history['loss'],\n   history.history['val_loss'],\n   'loss')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def val_class(pred):\n    x=len(pred)\n    y=[]\n    for i in range(x):\n        m=np.argmax(pred[i])\n        if m==0:\n            y.append('healthy')\n        elif m==1:\n            y.append('multiple_diseases')\n        elif m==2:\n            y.append('rust')\n        elif m==3:\n            y.append('scab')\n    return y\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport itertools\ndef plot_confusion_matrix(cm,classes,\n                         normalize=False,\n                         title='Comfusion matrix',\n                         cmap=plt.cm.Blues):\n    plt.imshow(cm,interpolation='nearest',cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks=np.arange(len(classes))\n    plt.xticks(tick_marks,classes)\n    plt.yticks(tick_marks,classes)\n    \n    if normalize:\n        cm=cm.astype('float')/cm.sum(axis=1)[:,np.newaxis]\n        \n    thresh=cm.max()/2.\n    for i,j in itertools.product(range(cm.shape[0]),range(cm.shape[1])):\n        plt.text(j,i,cm[i,j],\n                horizontalalignment='center',\n                color='white' if cm[i,j]>thresh else 'black')\n        plt.tight_layout()\n        plt.ylabel('True label')\n        plt.xlabel('Predicted label')\n        \nY_pred=model.predict(valid_nolabel)\nY_pred=Y_pred.tolist()\nY_pred_classes=val_class(Y_pred)\nvalid_label=valid_labels.tolist()\nY_true_classes=val_class(valid_label)\nconfusion_mtx=confusion_matrix(Y_true_classes,Y_pred_classes)\nplot_confusion_matrix(confusion_mtx,classes=['healthy','multiple_diseases','rust','scab'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_pred_classes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nY_pred_classes_errors=Y_pred_classes[errors]\nY_pred_errors=Y_pred[errors]\nY_true_classes_errors=valid_label[errors]\nX_val_errors=valid_nolabel[errors]\n\ndef display_errors(errors_index,img_errors,pred_errors,obs_errors):\n    n=0\n    nrows=2\n    ncols=3\n    fig,ax=plt.subplot(nrows,ncols,sharex=True,sharey=True)\n    for row in range(nrows):\n        for col in range(cols):\n            error=errors_index[n]\n            ax[row,col].imshow((img_errors[errors]).reshape((28,28)))\n            ax[row,col].set_title('Predicted label:{}\\nTrue label:{}'.format(pred_errors[error],obs_errors[error]))\n            n+=1\n            \nY_pred_errors_prob=np.max(Y_pred_errors,axis=1)\ntrue_prob_errors=np.diagonal(np.take(Y_pred_errors,Y_true_errors,axis=1))\ndelta_pred_true_errors=Y_pred_errors_prob-true_prob_errors\nsorted_delta_errors=np.argsort(delta_pred_true_errors)\nmost_important_errors=sorted_dela_errors[-6:]\ndisplay_errors(most_important_errors,X_val_errors,Y_pred_classes_errors,Y_true_errors)\n                             ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"probs_dnn=model.predict(test_dataset,verbose=1)\nsub.loc[:,'healthy':]=probs_dnn\nsub.to_csv('/kaggle/working/submission_DenseNet121_gridmask_noL2.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#TTA","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TTA=4\ntest_pred_tta=np.zeros((len(test_data),4))\nfor i in range(TTA):\n    test_dataset_tta=(tf.data.Dataset\n    .from_tensor_slices(test_paths)\n    .map(decode_image,num_parallel_calls=AUTO)\n    .map(data_augment,num_parallel_calls=AUTO)\n    .batch(BATCH_SIZE))\n    test_pred_tta+=model.predict(test_dataset_tta,verbose=1)\nsubmission_df=pd.read_csv(SUB_PATH)\nsubmission_df[['healthy','multiple_diseases','rust','scab']]=test_pred_tta/TTA\nsubmission_df.to_csv('/kaggle/working/submission_tta_IRV.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df.to_csv('/kaggle/working/submission_tta_cosine.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Kfold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepare_train(train_paths,train_labels):\n    data=(\n       tf.data.Dataset\n       .from_tensor_slices((train_paths,train_labels))\n       .map(decode_image,num_parallel_calls=AUTO)\n       .map(data_augment,num_parallel_calls=AUTO)\n       .repeat()\n       .shuffle(512)\n       .batch(BATCH_SIZE)\n       .prefetch(AUTO))\n    return data\n\ndef prepare_test(test_paths):\n    data=(\n       tf.data.Dataset\n       .from_tensor_slices((test_paths))\n       .map(decode_image,num_parallel_calls=AUTO)\n       .batch(BATCH_SIZE))\n    return data\n\n\ndef prepare_val(val_paths,val_labels):\n    data=(\n      tf.data.Dataset\n      .from_tensor_slices((val_paths,val_labels))\n      .map(decode_image,num_parallel_calls=AUTO)\n      .batch(BATCH_SIZE)\n      .prefetch(AUTO))\n    return data\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def TPU():\n    try:\n        tpu=tf.distribute.cluster_resolver.TPUClusterResolver()\n        print('Running on TPU',tpu.master())\n    except ValueError:\n        tpu=None\n        \n    if tpu:\n        tf.config.experimental_connect_to_cluster(tpu)\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        strategy=tf.distribute.experimental.TPUStrategy(tpu)\n    else:\n        strategy=tf.distribute.get_strategy()\n        \n    print('REPLICAS:',strategy.num_replicas_in_sync)\n    return strategy\n\nstrategy=TPU()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FOLDS=5 \nSEED=42\nskf=StratifiedKFold(n_splits=FOLDS,shuffle=True,random_state=SEED)\ntest_pred=[]\nval_roc_auc=[]\n\nfor i,(train_idx,val_idx) in enumerate(skf.split(train_paths,train_labels.argmax(1))):\n    print();print('#'*25)\n    print('### FOLD',i+1)\n    print('#'*25)\n    X_train,X_val=train_paths[train_idx],train_paths[val_idx]\n    y_train,y_val=train_labels[train_idx],train_labels[val_idx]\n    history=model.fit(\n                    prepare_train(X_train,y_train),\n                    steps_per_epoch=y_train.shape[0]//BATCH_SIZE,\n                    validation_data=prepare_val(X_val,y_val),\n                    validation_steps=y_val.shape[0]//BATCH_SIZE,\n                    callbacks=[lr_schedule],\n                    epochs=EPOCHS,\n                    verbose=1)\n    test_pred.append(model.predict(prepare_test(test_paths),verbose=1))\n    val_roc_auc.append(roc_auc_score(y_val,model.predict(prepare_val(X_val,y_val),verbose=1)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_roc_auc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_2_models=test_pred[3]*.7+test_pred[4]*.3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.iloc[:,1:]=best_2_models","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv('submission_5kfold.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}