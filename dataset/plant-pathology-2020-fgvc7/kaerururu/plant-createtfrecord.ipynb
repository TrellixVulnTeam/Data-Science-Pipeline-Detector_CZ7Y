{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# import tensorflow as tf\nimport tensorflow.compat.v1 as tf\nimport tensorflow_datasets as tfds\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tempfile\nimport pprint\n\nfrom PIL import Image, ImageOps\nfrom sklearn.model_selection import KFold, GroupKFold, StratifiedKFold\nfrom tqdm import tqdm\n\nimport cv2\nimport glob\nimport io\nimport os\nimport yaml\n\nimport IPython.display as display\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CFG:\n    SEED = 6718\n    N_SPLITS = 5    \n    EPOCHS = 5\n    BATCH_SIZE = 32 # REPLICAS * 32\n    IMG_SIZE = 512\n    OUTPUT_DIR = ''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import albumentations as A\nimport albumentations.pytorch.transforms as T\n\n\nmean = (0.485, 0.456, 0.406) # RGB\nstd = (0.229, 0.224, 0.225) # RGB\n\ntransform = {\n    'train' : A.Compose([\n        A.HorizontalFlip(p=0.5),\n        A.RandomResizedCrop(CFG.IMG_SIZE, CFG.IMG_SIZE),\n        A.Cutout(max_h_size=56, max_w_size=56, num_holes=5, p=0.5),\n        A.Normalize(mean, std),\n        # T.ToTensorV2()\n    ]),\n    'val' : A.Compose([\n        A.Resize(CFG.IMG_SIZE, CFG.IMG_SIZE),\n        # A.Normalize(mean, std),\n        # T.ToTensorV2()\n    ]),    \n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ROOT_PATH = '/kaggle/input/plant-pathology-2020-fgvc7/'\nTRAIN_PATH = ROOT_PATH + 'train.csv'\nTEST_PATH = ROOT_PATH + 'test.csv'\nSUB_PATH = ROOT_PATH + 'sample_submission.csv'\nIMG_PATH = ROOT_PATH + 'images/'\nLABELS = ['healthy', 'multiple_diseases', 'rust', 'scab']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(TRAIN_PATH)\n\n\ny = train[LABELS].values\n\nkf = KFold(n_splits=CFG.N_SPLITS,random_state=CFG.SEED, shuffle=True)\nfor fold, (train_idx, valid_idx) in enumerate(kf.split(train,y)):\n    train.loc[valid_idx, 'kfold'] = fold\n\ntrain['kfold'] = train['kfold'].astype(int)\n\nprint(train.shape)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(TEST_PATH)\nfor L in LABELS:\n    test[L] = -1\n    \nprint(test.shape)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if 1:\n    def _bytes_feature(value):\n      \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n      if isinstance(value, type(tf.constant(0))):\n        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n      return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\n\n    def _float_feature(value):\n      \"\"\"Returns a float_list from a float / double.\"\"\"\n      return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n\n    \n    def _int64_feature(value):\n      \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n      return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n    \n    \n    def _int64_list_feature(value):\n      \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n      return tf.train.Feature(int64_list=tf.train.Int64List(value=value)) # <-- 配列の時は [] いらない\n    \n    \n    def serialize_example(feature0, feature1):\n      \"\"\"\n      Creates a tf.train.Example message ready to be written to a file.\n      \"\"\"\n      # Create a dictionary mapping the feature name to the tf.train.Example-compatible\n      # data type.\n      feature = {\n          'image': _bytes_feature(tf.io.encode_jpeg(feature0)), # cast uint tesnsor -> bytes\n          'label': _int64_list_feature(feature1), # for array_like object\n      }\n\n      # Create a Features message using tf.train.Example.\n      example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n      return example_proto.SerializeToString()\n\n\n    def generator():\n      for features in features_dataset:\n        yield serialize_example(*features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\nimport torch\nimport torch.nn as nn\n\n\nclass CreateTFRecordDataset(torch.utils.data.Dataset):\n    def __init__(self, paths, y=None):\n        self.paths = paths\n        self.y = y\n\n    def __len__(self):\n        return len(self.paths)\n\n    def __getitem__(self, item):\n\n        images = cv2.imread(self.paths[item])\n        images = transform['val'](image=images)['image']\n\n        if self.y is not None:\n            targets = self.y[item]\n            return (images, targets)\n        \n        return images","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train = train.head(64)\n# test = test.head(64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_paths = IMG_PATH + train['image_id'] + '.jpg'\ntrain_labels = train[LABELS].values\n\ntest_paths = IMG_PATH + test['image_id'] + '.jpg'\ntest_labels = test[LABELS].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = CreateTFRecordDataset(train_paths, train_labels)\ntest_dataset = CreateTFRecordDataset(test_paths, test_labels)\n\ntrain_loader = torch.utils.data.DataLoader(\n                    train_dataset, shuffle=False, \n                    batch_size=CFG.BATCH_SIZE,\n                    num_workers=0, pin_memory=True)\n\ntest_loader = torch.utils.data.DataLoader(\n                    test_dataset, shuffle=False, \n                    batch_size=CFG.BATCH_SIZE,\n                    num_workers=0, pin_memory=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tk0 = tqdm(train_loader, total=len(train_loader))  \nfor step, data in enumerate(tk0):\n    slices = (data[0].numpy(), data[1].numpy())\n    features_dataset = tf.data.Dataset.from_tensor_slices(slices)\n\n    filename = f'train_{step}.tfrec'\n\n    serialized_features_dataset = tf.data.Dataset.from_generator(\n            generator, output_types=tf.string, output_shapes=())\n        \n        \n    print(f\"{filename} writing ...\")\n    writer = tf.data.experimental.TFRecordWriter(filename)\n    writer.write(serialized_features_dataset)    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tk0 = tqdm(test_loader, total=len(test_loader))  \nfor step, data in enumerate(tk0):\n    slices = (data[0].numpy(), data[1].numpy())\n    features_dataset = tf.data.Dataset.from_tensor_slices(slices)\n\n    filename = f'test_{step}.tfrec'\n\n    serialized_features_dataset = tf.data.Dataset.from_generator(\n            generator, output_types=tf.string, output_shapes=())\n        \n        \n    print(f\"{filename} writing ...\")\n    writer = tf.data.experimental.TFRecordWriter(filename)\n    writer.write(serialized_features_dataset)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(train_dataset[0][0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfrec_paths = [p for p in os.listdir() if 'tfrec' in p]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_dataset = tf.data.TFRecordDataset(tfrec_paths)\nraw_dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a description of the features.\nfeature_description = {\n    'image': tf.io.FixedLenFeature([], tf.string, default_value=''),\n    'label': tf.io.FixedLenSequenceFeature([], tf.int64, default_value=0, allow_missing=True),\n}\n\ndef _parse_function(example_proto):\n  # Parse the input `tf.train.Example` proto using the dictionary above.\n  return tf.io.parse_single_example(example_proto, feature_description)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def _decode_image_function(example):\n    image = example['image']\n    label = example['label']\n    \n    image = tf.image.decode_jpeg(image, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0\n    return image, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"parsed_dataset = raw_dataset \\\n                   .map(_parse_function) \\\n                   .map(_decode_image_function)\nparsed_dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for parsed_record in parsed_dataset.take(2):\n\n    image = parsed_record[0].numpy()\n    labels = parsed_record[1].numpy()\n    \n    print(image.shape)\n    print(labels, labels.shape)\n    \n    plt.imshow(image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}