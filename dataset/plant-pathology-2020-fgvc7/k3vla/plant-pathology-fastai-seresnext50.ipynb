{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install -q pretrainedmodels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pretrainedmodels\n\ndef model_f(pretrained=True,**kwargs):\n    return pretrainedmodels.se_resnext50_32x4d(num_classes=1000,pretrained='imagenet')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom fastai.vision.all import *\nfrom PIL import Image\nfrom sklearn.metrics import roc_auc_score\n\nimport os\n!ls /kaggle/input/plant-pathology-2020-fgvc7","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = Path('/kaggle/input/plant-pathology-2020-fgvc7')\ntrain = pd.read_csv(path/'train.csv')\ntest = pd.read_csv(path/'test.csv')\n\n# inverse operation of get_dummies\ntrain['label'] = train.set_index('image_id').idxmax(axis=1).reset_index()[0]\ntrain","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# pseudo labelling"},{"metadata":{"trusted":true},"cell_type":"code","source":"pseudos = ['Test_1149', 'Test_1158','Test_1321','Test_1590','Test_1634','Test_168','Test_1728','Test_1801','Test_211','Test_282','Test_506','Test_543','Test_714','Test_727','Test_921','Test_932','Test_987','Test_991']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pseudos = ['Test_1158', 'Test_714', 'Test_1634', 'Test_921', 'Test_168', 'Test_211', 'Test_1801', 'Test_1149', 'Test_987']\nc=['image_id', 'healthy', 'multiple_diseases', 'rust', 'scab', 'label']\npseudos = pd.DataFrame([(x, 0,1,0,0,'multiple_diseases') for x in pseudos], columns=c)\npseudos","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.concat([train, pseudos], axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# dealing with duplicates\n* Test Test -> do nothing\n* Train Test -> use training label as prediction\n* Train Train -> remove duplicates"},{"metadata":{"trusted":true},"cell_type":"code","source":"dups = [[\"Test_1800\", \"Train_558\"], [\"Train_616\", \"Train_966\"], [\"Test_383\", \"Test_635\"], [\"Train_500\", \"Train_647\"], [\"Test_1691\", \"Test_683\"], [\"Test_431\", \"Test_776\"], [\"Test_218\", \"Train_1598\"], [\"Test_611\", \"Train_1698\"], [\"Train_909\", \"Train_914\"], [\"Test_1688\", \"Train_1154\"], [\"Test_700\", \"Train_1142\"], [\"Test_1047\", \"Train_1733\"], [\"Train_592\", \"Train_782\"], [\"Train_1675\", \"Train_417\"], [\"Test_1450\", \"Train_761\"], [\"Test_989\", \"Train_1347\"], [\"Test_1117\", \"Train_105\"], [\"Test_119\", \"Train_772\"], [\"Test_1503\", \"Test_232\"], [\"Test_1264\", \"Test_708\"], [\"Test_483\", \"Train_1407\"], [\"Test_1212\", \"Test_570\"], [\"Train_174\", \"Train_1817\"], [\"Test_1722\", \"Test_889\"], [\"Test_693\", \"Train_1277\"], [\"Test_1494\", \"Train_937\"], [\"Test_938\", \"Train_861\"], [\"Test_53\", \"Train_114\"], [\"Test_581\", \"Train_1615\"], [\"Train_1731\", \"Train_591\"], [\"Test_1802\", \"Train_574\"], [\"Train_665\", \"Train_694\"], [\"Train_1634\", \"Train_921\"], [\"Train_1115\", \"Train_1683\"], [\"Train_1661\", \"Train_815\"], [\"Test_1062\", \"Train_1368\"], [\"Test_1720\", \"Test_459\"], [\"Test_1561\", \"Test_443\"], [\"Train_759\", \"Train_828\"], [\"Test_1671\", \"Test_899\"], [\"Train_1581\", \"Train_1613\"], [\"Test_768\", \"Train_851\"], [\"Test_1203\", \"Test_1600\"], [\"Test_797\", \"Train_1585\"], [\"Test_1163\", \"Test_542\"], [\"Test_886\", \"Train_1541\"], [\"Test_1011\", \"Train_608\"], [\"Train_1173\", \"Train_379\"], [\"Test_1588\", \"Test_376\"], [\"Test_1675\", \"Train_1066\"], [\"Test_1020\", \"Train_683\"], [\"Test_150\", \"Test_1501\"], [\"Train_1678\", \"Train_931\"], [\"Test_965\", \"Train_1341\"], [\"Train_1587\", \"Train_1593\"], [\"Train_341\", \"Train_763\"], [\"Test_895\", \"Test_979\"], [\"Train_162\", \"Train_356\"], [\"Test_1407\", \"Train_1703\"], [\"Test_1322\", \"Train_1600\"], [\"Test_1524\", \"Train_919\"], [\"Train_1150\", \"Train_1365\"], [\"Train_1392\", \"Train_438\"], [\"Test_829\", \"Train_1505\"], [\"Test_826\", \"Train_847\"], [\"Train_115\", \"Train_1709\"]]\ndups = pd.DataFrame(dups, columns=['col1', 'col2'])\ndups.head()\ndups['col1t'] = dups['col1'].str.split('_').str.get(0)\ndups['col2t'] = dups['col2'].str.split('_').str.get(0)\ndups.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove train_dups['col2'] images from training\ntrain_dups = dups[(dups.col1t == 'Train') & (dups.col1t == dups.col2t)].merge(train, left_on='col1', right_on='image_id').merge(train, left_on='col2', right_on='image_id')\ntrain_dups.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confused = train_dups[train_dups.label_x != train_dups.label_y]\nconfused","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'list of duplicates train / train: {len(train_dups)}')\nprint(len(train))\ntrain = train[~train.image_id.isin(list(train_dups['col2']))].reset_index(drop=True)\nprint(len(train))\ntrain = train[~train.image_id.isin(list(confused['col1']))].reset_index(drop=True)\ntrain = train[~train.image_id.isin(list(confused['col2']))].reset_index(drop=True)\nprint(len(train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# do nothing for these\ndups[(dups.col1t == 'Test') & (dups.col1t == dups.col2t)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# use these to put 1 in the prediction at the end\nsolutions = dups[dups.col1t != dups.col2t].merge(train, left_on='col2', right_on='image_id').sort_values(by='label')\nsolutions.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nskf = StratifiedKFold(shuffle=True, random_state=42)\n\nfor i, (train_index, val_index) in enumerate(skf.split(train, train['label'])):\n    print(train_index.shape, val_index.shape)\n    train.loc[val_index, 'fold'] = i","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# oversampling\ntrain = train.iloc[list(train.index) + [x for x in train[train.label == 'multiple_diseases'].index for j in range(0,2)]]\ntrain = train.reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"folds = range(0,3)\n# folds = [2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"R1=(400,600) # done on CPU to fit all on the GPU\nR2=(320,512) # done on GPU on batch\n# R1=450\n# R2=380\n# 380 for effnet b4\n\nTTA=True\n# TTA=False\nEPOCH1=15\n# EPOCH1=1\n# EPOCH2=7\nEPOCH2=-1\n\nLR1=5e-2\nLR2=slice(1e-7, 1e-4)\n\nBS=16\n\n##########\n\ntfms = [Rotate(max_deg=30), \n        Zoom(),      \n        Brightness(), \n        Flip(), \n        Contrast(), \n#         RandomCrop(R2),\n        Resize(R2), \n        Normalize.from_stats(*imagenet_stats)]\n\ncomp = setup_aug_tfms(tfms)\n\nfor fold in folds:\n\n    plant = DataBlock(blocks=(ImageBlock, CategoryBlock),\n                      splitter=IndexSplitter(train[train['fold'] == fold].index),\n                      get_x=ColReader('image_id', pref=path/\"images\", suff='.jpg'),\n                      get_y=ColReader('label'),\n                      item_tfms=Resize(R1),\n                      batch_tfms=comp)\n\n    dls = plant.dataloaders(train, bs=BS, seed=42)\n    \n    learn = cnn_learner(dls, \n                        model_f, \n                        pretrained=True, \n                        loss_func=LabelSmoothingCrossEntropy(), \n                        cbs=SaveModelCallback(monitor='roc_auc_score', comp=np.greater),\n                        model_dir='/kaggle/working',\n                        metrics=[RocAuc(), error_rate])\n    \n    print(f'-------- {fold} ---------')\n    if EPOCH1 > 0:\n        learn.fine_tune(EPOCH1, \n                        base_lr=LR1,\n                        cbs=SaveModelCallback(monitor='roc_auc_score', comp=np.greater))\n        learn.recorder.plot_loss()\n        \n    if EPOCH2 > 0:\n        learn.unfreeze()    \n        learn.fit_one_cycle(EPOCH2, \n                            lr_max=LR2,\n                            cbs=SaveModelCallback(monitor='roc_auc_score', comp=np.greater))\n        learn.recorder.plot_loss()\n    \n    learn.save(f'seresnext50-fold-{fold}')\n    \n    tst_dl = dls.test_dl(test)\n    \n    if TTA:\n        preds, _ = learn.tta(dl=tst_dl)\n    else:\n        preds, _ = learn.get_preds(dl=tst_dl)\n    \n    cols=['image_id'] + list(dls.vocab)\n    res = pd.concat([test, pd.DataFrame(preds,columns = learn.dls.vocab)],axis=1)[cols]\n    res.to_csv(f'submission_resnext_{fold}.csv',index=False)\n    \n    print('confident multiple_diseases')\n    my_ids = res[res['multiple_diseases'] > 0.9].sort_values(by='multiple_diseases').image_id.values\n    print(my_ids)\n    \n    res = learn.get_preds()\n    cols= dls.vocab\n    r = pd.DataFrame(res[0], columns=cols)\n    \n    valid_with_preds = pd.concat([train[train['fold'] == fold].reset_index(drop=True), r], axis=1)\n    \n    print(roc_auc_score(train[train['fold'] == fold][cols], r))\n    \n    for col in cols:\n        score = roc_auc_score(train[train['fold'] == fold][col], r[col])\n        print(f'{col} -> {score}')\n        \n    valid_with_preds.to_csv(f'validation_resnext_{fold}.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import rankdata\n\nif len(folds) > 1:\n\n    my_df = {}\n    for fold in folds:\n        my_df[fold] = pd.read_csv(f'submission_resnext_{fold}.csv').set_index('image_id')\n\n    # for each target, for each fold, compute the rank of the solution\n    for x in ['healthy','multiple_diseases','rust','scab']:\n        for fold in folds:\n            my_df[fold][x] = rankdata(my_df[fold][x], method='min')\n\n    # sum the ranks in the 1st df and average (not necessary, just for coherence)\n    for x in ['healthy','multiple_diseases','rust','scab']:\n        for fold in folds[1:]:\n            my_df[folds[0]][x] += my_df[fold][x]\n        my_df[folds[0]][x] = my_df[folds[0]][x] / 5\n\n    my_df[folds[0]].reset_index().to_csv('submission_resnext.csv', index=False)\n\nelse:\n    \n    print('no need for rankdata')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}