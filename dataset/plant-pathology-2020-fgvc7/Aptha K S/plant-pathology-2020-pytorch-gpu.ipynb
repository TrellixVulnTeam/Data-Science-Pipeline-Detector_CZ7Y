{"cells":[{"metadata":{"trusted":true,"_kg_hide-output":true,"scrolled":false},"cell_type":"code","source":"!pip install knockknock #For sending message to telegram\n!pip install efficientnet-pytorch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"import os\nimport cv2\nimport math\nimport time\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm_notebook as tqdm\nfrom sklearn.metrics import confusion_matrix,accuracy_score,roc_auc_score,precision_score,recall_score,ConfusionMatrixDisplay\nfrom sklearn.model_selection import train_test_split,KFold,StratifiedKFold\nfrom transformers import get_cosine_schedule_with_warmup\nfrom albumentations import *\nfrom albumentations.pytorch import ToTensorV2\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom efficientnet_pytorch import EfficientNet\n\nfrom knockknock import telegram_sender \nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\ntoken = user_secrets.get_secret(\"token\")\nchat_id = user_secrets.get_secret(\"chat_id\")\n\nimport warnings  \nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"SEED = 42\nBATCH_SIZE = 16\nSIZE = [420,420]\nLR = 0.0008\nWEIGHT_DECAY = 0\nEPOCHS = 40\nWARMUP = 15\nSTEP_SIZE = 5 \nTTA = 4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"def seed_everything(SEED):\n    np.random.seed(SEED)\n    torch.manual_seed(SEED)\n    torch.cuda.manual_seed(SEED)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    \nseed_everything(SEED)   \ndevice = torch.device(\"cuda:0\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"DIR_INPUT = '/kaggle/input/plant-pathology-2020-fgvc7'\ntrain_df = pd.read_csv(DIR_INPUT + '/train.csv')\ntest_df = pd.read_csv(DIR_INPUT + '/test.csv')\ncols = list(train_df.columns[1:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"transform = {\n    'train' : Compose([\n        Resize(SIZE[0],SIZE[1],always_apply=True),\n        HorizontalFlip(p=0.5),\n        VerticalFlip(p=0.5),\n        RandomRotate90(p=0.5),\n        Normalize(p=1.0),\n        ToTensorV2(p=1.0)\n    ]),\n    'valid': Compose([\n        Resize(SIZE[0],SIZE[1],always_apply=True),\n        Normalize(p=1.0),\n        ToTensorV2(p=1.0)\n    ]),\n    'test_tta': Compose([\n        Resize(SIZE[0],SIZE[1],always_apply=True),\n        HorizontalFlip(p=0.5),\n        VerticalFlip(p=0.5),\n        RandomRotate90(p=0.5),\n        Normalize(p=1.0),\n        ToTensorV2(p=1.0)\n    ])\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"class PLANT(Dataset):\n    \n    def __init__(self,df,transform=None,train=True):\n        self.df = df\n        self.transform = transform\n        self.train = train\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        path = self.df.iloc[idx]['image_id']\n        image = cv2.imread(DIR_INPUT+f\"/images/{path}.jpg\")\n        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n        if self.transform is not None:\n            image = self.transform(image=image)['image']\n        if self.train==True:\n            label = np.argmax(self.df[cols].iloc[idx].values).reshape(1,1)\n            return {'image': image,'label': label }\n        if self.train==False:\n            return {'image':image }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"train,valid = train_test_split(train_df,test_size = 0.2,random_state = SEED)\n\ndataset_train = PLANT(df=train, transform=transform['train'])\ndataloader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE, num_workers=4, shuffle=True, drop_last=True)\n\ndataset_valid = PLANT(df=valid, transform=transform['valid'])\ndataloader_valid = DataLoader(dataset_valid, batch_size=BATCH_SIZE, num_workers=4, shuffle=False, drop_last=True)\n\ndataset_test = PLANT(test_df,transform=transform['valid'],train=False)\ndataloader_test = DataLoader(dataset_test, batch_size=BATCH_SIZE, num_workers=4, shuffle=False)\n\ndataset_test_tta = PLANT(test_df,transform=transform['test_tta'],train=False)\ndataloader_test_tta = DataLoader(dataset_test_tta, batch_size=BATCH_SIZE, num_workers=4, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"def plot_transform(image_id,num_images=7):\n    plt.figure(figsize=(30,10))\n    plt.tight_layout()\n    for i in range(1,num_images+1):\n        plt.subplot(1,num_images+1,i)\n        plt.axis('off')\n        x = dataset_train.__getitem__(image_id)\n        image = x['image'].numpy()\n        image = np.transpose(image,[1,2,0])\n        plt.imshow(image)\n        \nplot_transform(9)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"def getmodel():\n    model = EfficientNet.from_pretrained('efficientnet-b4')\n    model._fc = nn.Sequential(\n     nn.Linear(in_features=1792, out_features=4, bias=True))\n    model = model.to(device)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"new_model = getmodel()\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(new_model.parameters(), lr=LR,weight_decay=WEIGHT_DECAY)\nscheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=WARMUP, num_training_steps=EPOCHS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"results = pd.DataFrame(columns=['training_loss','training_accuracy','validation_loss','validation_accuracy','precision','recall','roc_auc_score'])\n@telegram_sender(token=token, chat_id=int(chat_id))\ndef train(model, criterion, optimizer,scheduler, dataloader_train, dataloader_valid):\n    global results\n    for epoch in range(EPOCHS):\n        print('Epoch {}/{}'.format(epoch,EPOCHS-1))\n        since = time.time()\n        model.train()\n        training_accuracy  = []\n        training_loss = []\n        for bi, d in enumerate(tqdm(dataloader_train, total=int(len(dataloader_train)))):\n            inputs = d[\"image\"]\n            labels = d[\"label\"]\n            inputs = inputs.to(device, dtype=torch.float)\n            labels = labels.to(device, dtype=torch.long)\n            optimizer.zero_grad()\n            with torch.set_grad_enabled(True):\n                outputs = model(inputs)\n                labels = labels.squeeze()\n                loss = criterion(outputs, labels)\n                loss.backward()\n                optimizer.step()\n                outputs = torch.max(outputs,1)[1]\n                outputs = outputs.cpu().detach().numpy()\n                labels = labels.cpu().numpy()\n                training_accuracy.append(accuracy_score(outputs,labels))\n                training_loss.append(loss.item())\n        print('Training accuracy: {:.4f} and Training Loss: {:.4f}'.format(np.mean(training_accuracy),np.mean(training_loss)))\n\n        \n                                     \n        model.eval()\n        validation_loss = []\n        validation_labels = []\n        validation_outputs = []\n        with torch.no_grad():\n            for bi,d in enumerate(tqdm(dataloader_valid,total=int(len(dataloader_valid)))):\n                inputs = d[\"image\"]\n                labels = d[\"label\"]\n                inputs = inputs.to(device, dtype=torch.float)\n                labels = labels.to(device, dtype=torch.long)\n                outputs = model(inputs)\n                labels = labels.squeeze()\n                loss = criterion(outputs,labels)\n                outputs_softmax = F.softmax(outputs).cpu().detach().numpy()\n                labels_onehot = torch.eye(4)[labels].cpu().numpy()\n                validation_labels.extend(labels_onehot)\n                validation_outputs.extend(outputs_softmax)\n                validation_loss.append(loss.item())\n        precision = precision_score(np.argmax(validation_labels,axis=1),np.argmax(validation_outputs,axis=1),average='macro')\n        recall = recall_score(np.argmax(validation_labels,axis=1),np.argmax(validation_outputs,axis=1),average='macro')\n        accuracy = accuracy_score(np.argmax(validation_labels,axis=1),np.argmax(validation_outputs,axis=1))\n        roc = roc_auc_score(validation_labels,validation_outputs,average='macro')\n        print('Validation accuracy: {:.4f} and Validation Loss: {:.4f} and roc_auc_score: {:.4f}'.format(accuracy,\\\n                            np.mean(validation_loss),roc))\n        res = pd.DataFrame([[np.mean(training_loss),np.mean(training_accuracy),np.mean(validation_loss),\\\n                             accuracy,precision,recall,roc]],columns=results.columns)\n        results = pd.concat([results,res])\n        scheduler.step()\n    return results.iloc[-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"train(new_model, criterion, optimizer,scheduler, dataloader_train, dataloader_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"def display_training_curves(training, validation, title, subplot):\n    \"\"\"\n    Source: https://www.kaggle.com/mgornergoogle/getting-started-with-100-flowers-on-tpu\n    \"\"\"\n    if subplot%10==1: # set up the subplots on the first call\n        plt.subplots(figsize=(15,15), facecolor='#F0F0F0')\n        plt.tight_layout()\n    ax = plt.subplot(subplot)\n    ax.set_facecolor('#F8F8F8')\n    ax.plot(training)\n    ax.plot(validation)\n    ax.set_title('model '+ title)\n    ax.set_ylabel(title)\n    ax.set_xlabel('epoch')\n    ax.legend(['train', 'valid.'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"results.reset_index(drop=True,inplace=True)\ndisplay_training_curves(results['training_loss'], results['validation_loss'], 'loss', 311)\ndisplay_training_curves(results['training_accuracy'], results['validation_accuracy'], 'accuracy', 312)\ndisplay_training_curves(1, results['roc_auc_score'], 'roc_auc_score', 313)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"display_training_curves(1, results['precision'], 'precision', 211)\ndisplay_training_curves(1, results['recall'], 'recall', 212)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"new_model.eval()\ntest_pred = np.zeros((len(test_df),4))\nwith torch.no_grad():\n    for i, data in enumerate(tqdm(dataloader_test,total=int(len(dataloader_test)))):\n        inputs = data['image']\n        inputs = inputs.to(device, dtype=torch.float)\n        predict = new_model(inputs)\n        test_pred[i*len(predict):(i+1)*len(predict)] = predict.detach().cpu().squeeze().numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"submission_df = pd.read_csv(DIR_INPUT + '/sample_submission.csv')\nsubmission_df[['healthy', 'multiple_diseases', 'rust', 'scab']] = F.softmax(torch.from_numpy(test_pred),dim=1)\nsubmission_df.to_csv('submission.csv', index=False)\npd.Series(np.argmax(submission_df[cols].values,axis=1)).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"new_model.eval()\ntest_pred = np.zeros((len(test_df),4))\nfor i in range(TTA):\n    with torch.no_grad():\n        for i, data in enumerate(tqdm(dataloader_test_tta,total=int(len(dataloader_test_tta)))):\n            inputs = data['image']\n            inputs = inputs.to(device, dtype=torch.float)\n            predict = new_model(inputs)\n            test_pred[i*len(predict):(i+1)*len(predict)] += predict.detach().cpu().squeeze().numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"submission_df = pd.read_csv(DIR_INPUT + '/sample_submission.csv')\nsubmission_df[['healthy', 'multiple_diseases', 'rust', 'scab']] = F.softmax(torch.from_numpy(test_pred/TTA),dim=1)\nsubmission_df.to_csv('submission_tta.csv', index=False)\npd.Series(np.argmax(submission_df[cols].values,axis=1)).value_counts()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}