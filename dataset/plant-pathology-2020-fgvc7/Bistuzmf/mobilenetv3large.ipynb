{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import datetime\ntime1 = datetime.datetime.now()\nprint(time1)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T12:25:55.069417Z","iopub.execute_input":"2021-09-11T12:25:55.070957Z","iopub.status.idle":"2021-09-11T12:25:55.172794Z","shell.execute_reply.started":"2021-09-11T12:25:55.070869Z","shell.execute_reply":"2021-09-11T12:25:55.172035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nimport cv2\nimport pandas as pd\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications import VGG19\nfrom tensorflow.keras.layers import Flatten,Dense,Dropout,BatchNormalization\nfrom tensorflow.keras.models import Model,Sequential\nfrom tensorflow.keras.utils import to_categorical\n\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\n\nfrom tensorflow.keras.metrics import categorical_accuracy\n\nfrom tensorflow.keras.callbacks import (EarlyStopping, ReduceLROnPlateau, \n                                        ModelCheckpoint, CSVLogger, LearningRateScheduler)\nimport tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2021-09-11T12:25:55.174711Z","iopub.execute_input":"2021-09-11T12:25:55.17501Z","iopub.status.idle":"2021-09-11T12:26:00.251209Z","shell.execute_reply.started":"2021-09-11T12:25:55.174973Z","shell.execute_reply":"2021-09-11T12:26:00.250467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_HEIGHT = 224\nIMAGE_WIDTH = 224\nIMAGE_CHANNELS = 3\nTRAIN_BATCH_SIZE = 8\nVAL_BATCH_SIZE = 5\nEPOCHS = 1\nBALANCE = False #True  False\nAUG = False #True  False\nLR = 0.005#0.001  0.005  0.01\nH5_FILE_NAME = '_'.join(['model',\n                        'balance' if BALANCE else 'nobalance',\n                        'aug' if AUG else 'noaug',\n                        str(LR)]) + '.h5'\nprint(H5_FILE_NAME)\nTRAINING_LOG_FILE_NAME = '_'.join(['training_log',\n                        'balance' if BALANCE else 'nobalance',\n                        'aug' if AUG else 'noaug',\n                        str(LR)]) + '.csv'\nprint(TRAINING_LOG_FILE_NAME)\nSUBMISSION_FILE_NAME = '_'.join(['submission',\n                        'balance' if BALANCE else 'nobalance',\n                        'aug' if AUG else 'noaug',\n                        str(LR)]) + '.csv'\nprint(SUBMISSION_FILE_NAME)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T12:26:00.252465Z","iopub.execute_input":"2021-09-11T12:26:00.25273Z","iopub.status.idle":"2021-09-11T12:26:00.2651Z","shell.execute_reply.started":"2021-09-11T12:26:00.2527Z","shell.execute_reply":"2021-09-11T12:26:00.264355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '../input/plant-pathology-2020-fgvc7/train.csv'\ndf_train_all = pd.read_csv(path)\n\npath = '../input/plant-pathology-2020-fgvc7/test.csv'\ndf_test = pd.read_csv(path)\n\npath = '../input/plant-pathology-2020-fgvc7/sample_submission.csv'\ndf_sample = pd.read_csv(path)\n\n\nprint(df_train_all.shape)\nprint(df_test.shape)\nprint(df_sample.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T12:26:00.267123Z","iopub.execute_input":"2021-09-11T12:26:00.267603Z","iopub.status.idle":"2021-09-11T12:26:00.316252Z","shell.execute_reply.started":"2021-09-11T12:26:00.26755Z","shell.execute_reply":"2021-09-11T12:26:00.315603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Identify the target class of each row in the train set\n\ndef get_class(row):\n    \n    if row['multiple_diseases'] == 1:\n        return 'multiple_diseases'\n    \n    elif row['rust'] == 1:\n        return 'rust'\n    \n    elif row['scab'] == 1:\n        return 'scab'\n    \n    else:\n        return 'healthy'\n    \ndf_train_all['target'] = df_train_all.apply(get_class, axis=1)\n\ndf_train_all.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T12:26:00.317405Z","iopub.execute_input":"2021-09-11T12:26:00.317768Z","iopub.status.idle":"2021-09-11T12:26:00.379073Z","shell.execute_reply.started":"2021-09-11T12:26:00.317708Z","shell.execute_reply":"2021-09-11T12:26:00.378415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_all['target'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T12:26:00.381713Z","iopub.execute_input":"2021-09-11T12:26:00.381919Z","iopub.status.idle":"2021-09-11T12:26:00.392595Z","shell.execute_reply.started":"2021-09-11T12:26:00.381893Z","shell.execute_reply":"2021-09-11T12:26:00.391905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# shuffle\ndf_train_all_shuffle = shuffle(df_train_all, random_state=101)\n# select the column that we will use for stratification\ny = df_train_all_shuffle['target']\n\ndf_train, df_val = train_test_split(df_train_all_shuffle, test_size=0.2, random_state=101, stratify=y)\n\n\nprint(df_train.shape)\nprint(df_val.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T12:26:00.395555Z","iopub.execute_input":"2021-09-11T12:26:00.39578Z","iopub.status.idle":"2021-09-11T12:26:00.411264Z","shell.execute_reply.started":"2021-09-11T12:26:00.395758Z","shell.execute_reply":"2021-09-11T12:26:00.409687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['target'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T12:26:00.412397Z","iopub.execute_input":"2021-09-11T12:26:00.412716Z","iopub.status.idle":"2021-09-11T12:26:00.421243Z","shell.execute_reply.started":"2021-09-11T12:26:00.412682Z","shell.execute_reply":"2021-09-11T12:26:00.420107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_val['target'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T12:26:00.42298Z","iopub.execute_input":"2021-09-11T12:26:00.423298Z","iopub.status.idle":"2021-09-11T12:26:00.433219Z","shell.execute_reply.started":"2021-09-11T12:26:00.423267Z","shell.execute_reply":"2021-09-11T12:26:00.432334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_balancer(df_train):\n    df_1 = df_train[df_train['target'] != 'multiple_diseases']\n    df_2 = df_train[df_train['target'] == 'multiple_diseases']\n    df_train_up = pd.concat([df_1, df_2,  df_2,  df_2,  df_2,  df_2,  df_2], axis=0).reset_index(drop=True)\n\n    df_train_ret = shuffle(df_train_up, random_state=101)\n    return df_train_ret","metadata":{"execution":{"iopub.status.busy":"2021-09-11T12:26:00.436695Z","iopub.execute_input":"2021-09-11T12:26:00.43688Z","iopub.status.idle":"2021-09-11T12:26:00.441941Z","shell.execute_reply.started":"2021-09-11T12:26:00.436857Z","shell.execute_reply":"2021-09-11T12:26:00.440975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This is the new class distribution of the train set\nif BALANCE:\n    df_train = train_balancer(df_train)\ndf_train['target'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T12:26:00.443574Z","iopub.execute_input":"2021-09-11T12:26:00.443883Z","iopub.status.idle":"2021-09-11T12:26:00.455332Z","shell.execute_reply.started":"2021-09-11T12:26:00.443846Z","shell.execute_reply":"2021-09-11T12:26:00.454353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.to_csv('df_train.csv.gz', compression='gzip', index=False)\ndf_val.to_csv('df_val.csv.gz', compression='gzip', index=False)\ndf_test.to_csv('df_test.csv.gz', compression='gzip', index=False)\n!ls","metadata":{"execution":{"iopub.status.busy":"2021-09-11T12:26:00.457019Z","iopub.execute_input":"2021-09-11T12:26:00.457394Z","iopub.status.idle":"2021-09-11T12:26:01.129242Z","shell.execute_reply.started":"2021-09-11T12:26:00.457304Z","shell.execute_reply":"2021-09-11T12:26:01.128434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Albumentations\n\nimport albumentations as albu\n\n\ndef augment_image(augmentation, image):\n    \n    \"\"\"\n    Uses the Albumentations library.\n    \n    Inputs: \n    1. augmentation - this is the instance of type of augmentation to do \n    e.g. aug_type = HorizontalFlip(p=1) \n    # p=1 is the probability of the transform being executed.\n    \n    2. image - image with shape (h,w)\n    \n    Output:\n    Augmented image as a numpy array.\n    \n    \"\"\"\n    # get the transform as a dict\n    aug_image_dict =  augmentation(image=image)\n    # retrieve the augmented matrix of the image\n    image_matrix = aug_image_dict['image']\n    \n    \n    return image_matrix","metadata":{"execution":{"iopub.status.busy":"2021-09-11T12:26:01.132716Z","iopub.execute_input":"2021-09-11T12:26:01.132938Z","iopub.status.idle":"2021-09-11T12:26:02.096237Z","shell.execute_reply.started":"2021-09-11T12:26:01.132912Z","shell.execute_reply":"2021-09-11T12:26:02.095429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the transforms\n\n# Modified from --> Pneumothorax - 1st place solution\n# Source: https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation/discussion/107824#latest-620521\n\n\naug_types1 = albu.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=45, \n                  interpolation=1, border_mode=4, value=None, mask_value=None, \n                  shift_limit_x=None, shift_limit_y=None, always_apply=False, \n                  p=1)\n\naug_types2 = albu.Flip(p=1)\n\naug_types3 = albu.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2,\n                                           brightness_by_max=True, always_apply=False,p=1)\n\naug_types4 = albu.Blur(blur_limit=(3,3.5), always_apply=False, p=1)\n\naug_types5 = albu.OneOf([\n                albu.ElasticTransform(alpha=1, sigma=50, alpha_affine=50,\n                                       interpolation=1, border_mode=4, value=None,mask_value=None,\n                                       always_apply=False, approximate=False, p=1),\n                albu.GridDistortion(num_steps=5, distort_limit=0.3, interpolation=1, border_mode=4, \n                                 value=None, mask_value=None, always_apply=False, p=1)\n                        ], p=1)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T12:26:02.098219Z","iopub.execute_input":"2021-09-11T12:26:02.098419Z","iopub.status.idle":"2021-09-11T12:26:02.108736Z","shell.execute_reply.started":"2021-09-11T12:26:02.098396Z","shell.execute_reply":"2021-09-11T12:26:02.107846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_generator_aug(batch_size=8,random_seed=None):\n    \n    while True:\n        \n        if random_seed:\n            random.seed(random_seed)\n        \n        # load the data in chunks (batches)\n        for df in pd.read_csv('df_train.csv.gz', chunksize=batch_size):\n            \n            # get the list of images\n            image_id_list = list(df['image_id'])\n            \n            # Create empty X matrix - 3 channels\n            X_train = np.zeros((6*len(df), IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS), dtype=np.uint8)\n            \n\n        \n            \n            # Create X_train\n            #================\n            \n            for i in range(0, len(image_id_list)):\n              \n              \n                # get the image and mask\n                image_id = image_id_list[i] + '.jpg'\n\n\n                # set the path to the image\n                path = '../input/plant-pathology-2020-fgvc7/images/' + image_id\n\n                # read the image\n                image = cv2.imread(path)\n                \n                # convert to from BGR to RGB\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                \n                # resize the image\n                image = cv2.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))\n                \n                \n            \n            \n            # Create y_train\n            # ===============\n                cols = ['healthy', 'multiple_diseases', 'rust', 'scab']\n                y_train = df[cols]\n                y_train = pd.concat([y_train, y_train, y_train, y_train, y_train, y_train], axis=0).reset_index(drop=True)\n                y_train = np.asarray(y_train) \n\n\n       \n                X_train[i] = image\n                X_train[i+1*len(image_id_list)] = augment_image(aug_types1, image)\n                X_train[i+2*len(image_id_list)] = augment_image(aug_types2, image)\n                X_train[i+3*len(image_id_list)] = augment_image(aug_types3, image)\n                X_train[i+4*len(image_id_list)] = augment_image(aug_types4, image)\n                X_train[i+5*len(image_id_list)] = augment_image(aug_types5, image)\n                \n            # Normalize the images\n            X_train = X_train/255\n\n            yield X_train, y_train\n            ","metadata":{"execution":{"iopub.status.busy":"2021-09-11T12:26:02.110302Z","iopub.execute_input":"2021-09-11T12:26:02.110788Z","iopub.status.idle":"2021-09-11T12:26:02.123104Z","shell.execute_reply.started":"2021-09-11T12:26:02.110756Z","shell.execute_reply":"2021-09-11T12:26:02.122315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_generator_no_aug(batch_size=8):\n    \n    while True:\n        \n        # load the data in chunks (batches)\n        for df in pd.read_csv('df_train.csv.gz', chunksize=batch_size):\n            \n            # get the list of images\n            image_id_list = list(df['image_id'])\n            \n            # Create empty X matrix - 3 channels\n            X_train = np.zeros((len(df), IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS), dtype=np.uint8)\n            \n\n        \n            \n            # Create X_train\n            #================\n            \n            for i in range(0, len(image_id_list)):\n              \n              \n                # get the image and mask\n                image_id = image_id_list[i] + '.jpg'\n\n\n                # set the path to the image\n                path = '../input/plant-pathology-2020-fgvc7/images/' + image_id\n\n                # read the image\n                image = cv2.imread(path)\n                \n                # convert to from BGR to RGB\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                \n                # resize the image\n                image = cv2.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))\n                \n                \n            \n            \n            # Create y_train\n            # ===============\n                cols = ['healthy', 'multiple_diseases', 'rust', 'scab']\n                y_train = df[cols]\n                y_train = np.asarray(y_train) \n                \n                # insert the image into X_train\n                X_train[i] = image\n                \n                          \n                \n            # Normalize the images\n            X_train = X_train/255\n\n            yield X_train, y_train","metadata":{"execution":{"iopub.status.busy":"2021-09-11T12:26:02.124448Z","iopub.execute_input":"2021-09-11T12:26:02.124718Z","iopub.status.idle":"2021-09-11T12:26:02.137034Z","shell.execute_reply.started":"2021-09-11T12:26:02.124685Z","shell.execute_reply":"2021-09-11T12:26:02.136303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test the generator\n\n# initialize\nif AUG:\n    train_gen = train_generator_aug(batch_size=8,random_seed=123)\nelse:\n    train_gen = train_generator_no_aug(batch_size=8)\n\n# run the generator\nX_train, y_train = next(train_gen)\n\nprint(X_train.shape)\nprint(y_train.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T12:26:02.139874Z","iopub.execute_input":"2021-09-11T12:26:02.14007Z","iopub.status.idle":"2021-09-11T12:26:02.548605Z","shell.execute_reply.started":"2021-09-11T12:26:02.140045Z","shell.execute_reply":"2021-09-11T12:26:02.547138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def val_generator(batch_size=5):\n    \n    while True:\n        \n        # load the data in chunks (batches)\n        for df in pd.read_csv('df_val.csv.gz', chunksize=batch_size):\n            \n            # get the list of images\n            image_id_list = list(df['image_id'])\n            \n            # Create empty X matrix - 3 channels\n            X_val = np.zeros((len(df), IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS), dtype=np.uint8)\n            \n\n        \n            \n            # Create X_val\n            #================\n            \n            for i in range(0, len(image_id_list)):\n              \n              \n                # get the image and mask\n                image_id = image_id_list[i] + '.jpg'\n\n\n                # set the path to the image\n                path = '../input/plant-pathology-2020-fgvc7/images/' + image_id\n\n                # read the image\n                image = cv2.imread(path)\n                \n                # convert to from BGR to RGB\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                \n                # resize the image\n                image = cv2.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))\n\n                # insert the image into X_train\n                X_val[i] = image\n                \n                \n            \n            \n            # Create y_val\n            # ===============\n\n                cols = ['healthy', 'multiple_diseases', 'rust', 'scab']\n                y_val = df[cols]\n                y_val = np.asarray(y_val) \n\n                       \n                \n            # Normalize the images\n            X_val = X_val/255\n\n            yield X_val, y_val","metadata":{"execution":{"iopub.status.busy":"2021-09-11T12:26:02.550077Z","iopub.execute_input":"2021-09-11T12:26:02.550328Z","iopub.status.idle":"2021-09-11T12:26:02.561616Z","shell.execute_reply.started":"2021-09-11T12:26:02.550295Z","shell.execute_reply":"2021-09-11T12:26:02.560832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test the generator\n\n# initialize\nval_gen = val_generator(batch_size=5)\n\n# run the generator\nX_val, y_val = next(val_gen)\n\nprint(X_val.shape)\nprint(y_val.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T12:26:02.563182Z","iopub.execute_input":"2021-09-11T12:26:02.563387Z","iopub.status.idle":"2021-09-11T12:26:02.794151Z","shell.execute_reply.started":"2021-09-11T12:26:02.563359Z","shell.execute_reply":"2021-09-11T12:26:02.793328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_generator(batch_size=1):\n    \n    while True:\n        \n        # load the data in chunks (batches)\n        for df in pd.read_csv('df_test.csv.gz', chunksize=batch_size):\n            \n            # get the list of images\n            image_id_list = list(df['image_id'])\n            \n            # Create empty X matrix - 3 channels\n            X_test = np.zeros((len(df), IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS), dtype=np.uint8)\n            \n\n        \n            \n            # Create X_test\n            #================\n            \n            for i in range(0, len(image_id_list)):\n              \n              \n                # get the image and mask\n                image_id = image_id_list[i] + '.jpg'\n\n\n                # set the path to the image\n                path = '../input/plant-pathology-2020-fgvc7/images/' + image_id\n\n                # read the image\n                image = cv2.imread(path)\n                \n                # convert to from BGR to RGB\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                \n                # resize the image\n                image = cv2.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))\n\n                # insert the image into X_train\n                X_test[i] = image\n                \n                 \n                \n            # Normalize the images\n            X_test = X_test/255\n\n            yield X_test","metadata":{"execution":{"iopub.status.busy":"2021-09-11T12:26:02.795249Z","iopub.execute_input":"2021-09-11T12:26:02.795483Z","iopub.status.idle":"2021-09-11T12:26:02.80498Z","shell.execute_reply.started":"2021-09-11T12:26:02.79545Z","shell.execute_reply":"2021-09-11T12:26:02.802641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test the generator\n\n# initialize\ntest_gen = test_generator(batch_size=1)\n\n# run the generator\nX_test = next(test_gen)\n\nprint(X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T12:26:02.806382Z","iopub.execute_input":"2021-09-11T12:26:02.806922Z","iopub.status.idle":"2021-09-11T12:26:02.864069Z","shell.execute_reply.started":"2021-09-11T12:26:02.806887Z","shell.execute_reply":"2021-09-11T12:26:02.86331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_model():\n    pre_trained = tf.keras.applications.MobileNetV3Large(input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3), weights='imagenet', include_top=False)\n\n    model = tf.keras.Sequential([\n      pre_trained,\n        tf.keras.layers.GlobalAveragePooling2D(),\n#       tf.keras.layers.Flatten(),\n      tf.keras.layers.Dropout(0.3),\n      tf.keras.layers.Dense(4, activation='softmax')\n      ])\n    model.compile(\n        loss = 'kullback_leibler_divergence', \n        optimizer = 'adam', \n        metrics = ['accuracy'])\n    return model\n\nmodel = create_model()\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T12:26:02.865375Z","iopub.execute_input":"2021-09-11T12:26:02.865647Z","iopub.status.idle":"2021-09-11T12:26:07.203057Z","shell.execute_reply.started":"2021-09-11T12:26:02.865614Z","shell.execute_reply":"2021-09-11T12:26:07.202337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_train_samples = len(df_train)\nnum_val_samples = len(df_val)\n\n# determine num train steps\ntrain_steps = np.ceil(num_train_samples / TRAIN_BATCH_SIZE)\n\n# determine num val steps\nval_steps = np.ceil(num_val_samples / VAL_BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T12:26:07.204213Z","iopub.execute_input":"2021-09-11T12:26:07.204448Z","iopub.status.idle":"2021-09-11T12:26:07.211893Z","shell.execute_reply.started":"2021-09-11T12:26:07.204414Z","shell.execute_reply":"2021-09-11T12:26:07.211083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import datetime\ntime3 = datetime.datetime.now()\nprint(time3)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T12:26:07.213266Z","iopub.execute_input":"2021-09-11T12:26:07.213681Z","iopub.status.idle":"2021-09-11T12:26:07.220072Z","shell.execute_reply.started":"2021-09-11T12:26:07.213648Z","shell.execute_reply":"2021-09-11T12:26:07.219152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.callbacks import (EarlyStopping, ReduceLROnPlateau, \n                                        ModelCheckpoint, CSVLogger, LearningRateScheduler)\n# Initialize the generators\nif AUG:\n    train_gen = train_generator_aug(batch_size=TRAIN_BATCH_SIZE,random_seed=123)\nelse:\n    train_gen = train_generator_no_aug(batch_size=TRAIN_BATCH_SIZE)\n\nval_gen = val_generator(batch_size=VAL_BATCH_SIZE)\n\n\nmodel.compile(\n    Adam(lr=LR),\n    loss='categorical_crossentropy',\n    metrics=['accuracy'])\n\n\n\n\nfilepath = H5_FILE_NAME\n\n#earlystopper = EarlyStopping(patience=10, verbose=1)\n\ncheckpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, \n                             save_best_only=True, mode='max')\n\nreduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.3, patience=3, \n                                   verbose=1, mode='max')\n\n\n\nlog_fname = TRAINING_LOG_FILE_NAME\ncsv_logger = CSVLogger(filename=log_fname,\n                       separator=',',\n                       append=False)\n\ncallbacks_list = [checkpoint, csv_logger, reduce_lr]\n\nhistory = model.fit(train_gen, steps_per_epoch=train_steps, epochs=EPOCHS, \n                    validation_data=val_gen, validation_steps=val_steps,\n                    verbose=2,\n                    callbacks=callbacks_list)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-11T12:26:07.221719Z","iopub.execute_input":"2021-09-11T12:26:07.222258Z","iopub.status.idle":"2021-09-11T12:27:36.178364Z","shell.execute_reply.started":"2021-09-11T12:26:07.222222Z","shell.execute_reply":"2021-09-11T12:27:36.177532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time4 = datetime.datetime.now()\nprint(time4)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T12:27:36.179877Z","iopub.execute_input":"2021-09-11T12:27:36.180157Z","iopub.status.idle":"2021-09-11T12:27:36.187987Z","shell.execute_reply.started":"2021-09-11T12:27:36.180122Z","shell.execute_reply":"2021-09-11T12:27:36.184988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training time\nprint(time4-time3)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T12:27:36.189181Z","iopub.execute_input":"2021-09-11T12:27:36.189431Z","iopub.status.idle":"2021-09-11T12:27:36.197193Z","shell.execute_reply.started":"2021-09-11T12:27:36.189397Z","shell.execute_reply":"2021-09-11T12:27:36.196353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get the metric names so we can use evaulate_generator\nmodel.metrics_names","metadata":{"execution":{"iopub.status.busy":"2021-09-11T12:27:36.201948Z","iopub.execute_input":"2021-09-11T12:27:36.202136Z","iopub.status.idle":"2021-09-11T12:27:36.209003Z","shell.execute_reply.started":"2021-09-11T12:27:36.202116Z","shell.execute_reply":"2021-09-11T12:27:36.20813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights(H5_FILE_NAME)\n\nval_gen = val_generator(batch_size=VAL_BATCH_SIZE)\n\nval_loss, val_acc = \\\nmodel.evaluate(val_gen, \n               steps=val_steps)\n\nprint('val_loss:', val_loss)\nprint('val_acc:', val_acc)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T12:27:36.210184Z","iopub.execute_input":"2021-09-11T12:27:36.210564Z","iopub.status.idle":"2021-09-11T12:27:48.45297Z","shell.execute_reply.started":"2021-09-11T12:27:36.210531Z","shell.execute_reply":"2021-09-11T12:27:48.452196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display the training log\n\ntrain_log = pd.read_csv(TRAINING_LOG_FILE_NAME)\n\ntrain_log.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T12:27:48.454273Z","iopub.execute_input":"2021-09-11T12:27:48.454793Z","iopub.status.idle":"2021-09-11T12:27:48.477215Z","shell.execute_reply.started":"2021-09-11T12:27:48.454756Z","shell.execute_reply":"2021-09-11T12:27:48.476591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# display the loss and accuracy curves\n\nimport matplotlib.pyplot as plt\n\nacc = train_log['accuracy']\nval_acc = train_log['val_accuracy']\nloss = train_log['loss']\nval_loss = train_log['val_loss']\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, acc)\nplt.plot(epochs, val_acc)\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train','val'],loc = 'upper left')\nplt.show()\n\nplt.plot(epochs, loss)\nplt.plot(epochs, val_loss)\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train','val'],loc = 'upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T12:27:48.481151Z","iopub.execute_input":"2021-09-11T12:27:48.483242Z","iopub.status.idle":"2021-09-11T12:27:48.93652Z","shell.execute_reply.started":"2021-09-11T12:27:48.483206Z","shell.execute_reply":"2021-09-11T12:27:48.935786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights(H5_FILE_NAME)\n\nval_gen = val_generator(batch_size=1)\n\npreds = model.predict(val_gen, steps=len(df_val), verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T12:27:48.937926Z","iopub.execute_input":"2021-09-11T12:27:48.938243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get y_pred as index values\n\ny_pred = np.argmax(preds, axis=1)\nprint(y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get y_true as index values\n\ncols = ['healthy', 'multiple_diseases', 'rust', 'scab']\ny_true = df_val[cols]\ny_true = np.asarray(y_true) \n\ny_true = np.argmax(y_true, axis=1)\nprint(y_true)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights(H5_FILE_NAME)\nval_gen = val_generator(batch_size=1)\n\npreds = model.predict(val_gen, steps=len(df_val), verbose=1)\n\n\ny_pred = np.argmax(preds, axis=1)\nprint(y_pred[:50])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Put the preds into a dataframe\n\ndf_preds = pd.DataFrame(preds, columns=['healthy', 'multiple_diseases', 'rust', 'scab'])\n\ndf_preds['image_id'] = df_val['image_id'].copy().values\n\ndf_preds.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a submission csv file\n\ndf_results = pd.DataFrame({'image_id': df_preds.image_id,\n                            'healthy': df_preds.healthy,\n                               'multiple_diseases': df_preds.multiple_diseases,\n                               'rust': df_preds.rust,\n                               'scab': df_preds.scab,\n                           'target':df_val['target'].values\n                           }).set_index('image_id')\n\n\n# create a submission csv file\ndf_results.to_csv(SUBMISSION_FILE_NAME) \ndf_results.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time2 = datetime.datetime.now()\nprint(time2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Total time\nprint(time2 - time1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}