{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import datetime\ntime1 = datetime.datetime.now()\nprint(time1)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T03:14:57.002238Z","iopub.execute_input":"2021-09-11T03:14:57.002647Z","iopub.status.idle":"2021-09-11T03:14:57.008456Z","shell.execute_reply.started":"2021-09-11T03:14:57.002606Z","shell.execute_reply":"2021-09-11T03:14:57.007222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nimport cv2\nimport pandas as pd\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications import VGG19\nfrom tensorflow.keras.layers import Flatten,Dense,Dropout,BatchNormalization\nfrom tensorflow.keras.models import Model,Sequential\nfrom tensorflow.keras.utils import to_categorical\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\n\nfrom tensorflow.keras.metrics import categorical_accuracy\n\nfrom tensorflow.keras.callbacks import (EarlyStopping, ReduceLROnPlateau, \n                                        ModelCheckpoint, CSVLogger, LearningRateScheduler)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T03:14:57.010123Z","iopub.execute_input":"2021-09-11T03:14:57.010498Z","iopub.status.idle":"2021-09-11T03:14:57.022699Z","shell.execute_reply.started":"2021-09-11T03:14:57.010458Z","shell.execute_reply":"2021-09-11T03:14:57.02132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_HEIGHT = 224\nIMAGE_WIDTH = 224\nIMAGE_CHANNELS = 3\nTRAIN_BATCH_SIZE = 8\nVAL_BATCH_SIZE = 5\nEPOCHS = 1\nBALANCE = False #True  False\nAUG = False #True  False\nLR = 0.005#0.001  0.005  0.01\nH5_FILE_NAME = '_'.join(['model',\n                        'balance' if BALANCE else 'nobalance',\n                        'aug' if AUG else 'noaug',\n                        str(LR)]) + '.h5'\nprint(H5_FILE_NAME)\nTRAINING_LOG_FILE_NAME = '_'.join(['training_log',\n                        'balance' if BALANCE else 'nobalance',\n                        'aug' if AUG else 'noaug',\n                        str(LR)]) + '.csv'\nprint(TRAINING_LOG_FILE_NAME)\nSUBMISSION_FILE_NAME = '_'.join(['submission',\n                        'balance' if BALANCE else 'nobalance',\n                        'aug' if AUG else 'noaug',\n                        str(LR)]) + '.csv'\nprint(SUBMISSION_FILE_NAME)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T03:14:57.025281Z","iopub.execute_input":"2021-09-11T03:14:57.025782Z","iopub.status.idle":"2021-09-11T03:14:57.040585Z","shell.execute_reply.started":"2021-09-11T03:14:57.02573Z","shell.execute_reply":"2021-09-11T03:14:57.039329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '../input/plant-pathology-2020-fgvc7/train.csv'\ndf_train_all = pd.read_csv(path)\n\npath = '../input/plant-pathology-2020-fgvc7/test.csv'\ndf_test = pd.read_csv(path)\n\npath = '../input/plant-pathology-2020-fgvc7/sample_submission.csv'\ndf_sample = pd.read_csv(path)\n\n\nprint(df_train_all.shape)\nprint(df_test.shape)\nprint(df_sample.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T03:14:57.043044Z","iopub.execute_input":"2021-09-11T03:14:57.043531Z","iopub.status.idle":"2021-09-11T03:14:57.075247Z","shell.execute_reply.started":"2021-09-11T03:14:57.043481Z","shell.execute_reply":"2021-09-11T03:14:57.07384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Identify the target class of each row in the train set\n\ndef get_class(row):\n    \n    if row['multiple_diseases'] == 1:\n        return 'multiple_diseases'\n    \n    elif row['rust'] == 1:\n        return 'rust'\n    \n    elif row['scab'] == 1:\n        return 'scab'\n    \n    else:\n        return 'healthy'\n    \ndf_train_all['target'] = df_train_all.apply(get_class, axis=1)\n\ndf_train_all.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T03:14:57.07699Z","iopub.execute_input":"2021-09-11T03:14:57.077318Z","iopub.status.idle":"2021-09-11T03:14:57.13358Z","shell.execute_reply.started":"2021-09-11T03:14:57.077288Z","shell.execute_reply":"2021-09-11T03:14:57.132596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_all['target'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T03:14:57.134868Z","iopub.execute_input":"2021-09-11T03:14:57.135137Z","iopub.status.idle":"2021-09-11T03:14:57.14305Z","shell.execute_reply.started":"2021-09-11T03:14:57.13511Z","shell.execute_reply":"2021-09-11T03:14:57.142228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# shuffle\ndf_train_all_shuffle = shuffle(df_train_all, random_state=101)\n# select the column that we will use for stratification\ny = df_train_all_shuffle['target']\n\ndf_train, df_val = train_test_split(df_train_all_shuffle, test_size=0.2, random_state=101, stratify=y)\n\n\nprint(df_train.shape)\nprint(df_val.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T03:14:57.146248Z","iopub.execute_input":"2021-09-11T03:14:57.146578Z","iopub.status.idle":"2021-09-11T03:14:57.167159Z","shell.execute_reply.started":"2021-09-11T03:14:57.146547Z","shell.execute_reply":"2021-09-11T03:14:57.165798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['target'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T03:14:57.170317Z","iopub.execute_input":"2021-09-11T03:14:57.170805Z","iopub.status.idle":"2021-09-11T03:14:57.180103Z","shell.execute_reply.started":"2021-09-11T03:14:57.170746Z","shell.execute_reply":"2021-09-11T03:14:57.179072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_val['target'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T03:14:57.181216Z","iopub.execute_input":"2021-09-11T03:14:57.181572Z","iopub.status.idle":"2021-09-11T03:14:57.195439Z","shell.execute_reply.started":"2021-09-11T03:14:57.181539Z","shell.execute_reply":"2021-09-11T03:14:57.194163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_balancer(df_train):\n    df_1 = df_train[df_train['target'] != 'multiple_diseases']\n    df_2 = df_train[df_train['target'] == 'multiple_diseases']\n    df_train_up = pd.concat([df_1, df_2,  df_2,  df_2,  df_2,  df_2,  df_2], axis=0).reset_index(drop=True)\n\n    df_train_ret = shuffle(df_train_up, random_state=101)\n    return df_train_ret","metadata":{"execution":{"iopub.status.busy":"2021-09-11T03:14:57.196978Z","iopub.execute_input":"2021-09-11T03:14:57.197357Z","iopub.status.idle":"2021-09-11T03:14:57.20733Z","shell.execute_reply.started":"2021-09-11T03:14:57.197312Z","shell.execute_reply":"2021-09-11T03:14:57.205918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This is the new class distribution of the train set\nif BALANCE:\n    df_train = train_balancer(df_train)\ndf_train['target'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T03:14:57.209167Z","iopub.execute_input":"2021-09-11T03:14:57.209626Z","iopub.status.idle":"2021-09-11T03:14:57.22549Z","shell.execute_reply.started":"2021-09-11T03:14:57.209577Z","shell.execute_reply":"2021-09-11T03:14:57.224331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.to_csv('df_train.csv.gz', compression='gzip', index=False)\ndf_val.to_csv('df_val.csv.gz', compression='gzip', index=False)\ndf_test.to_csv('df_test.csv.gz', compression='gzip', index=False)\n!ls","metadata":{"execution":{"iopub.status.busy":"2021-09-11T03:14:57.226859Z","iopub.execute_input":"2021-09-11T03:14:57.227322Z","iopub.status.idle":"2021-09-11T03:14:58.007433Z","shell.execute_reply.started":"2021-09-11T03:14:57.227242Z","shell.execute_reply":"2021-09-11T03:14:58.006352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Albumentations\n\nimport albumentations as albu\n\n\ndef augment_image(augmentation, image):\n    \n    \"\"\"\n    Uses the Albumentations library.\n    \n    Inputs: \n    1. augmentation - this is the instance of type of augmentation to do \n    e.g. aug_type = HorizontalFlip(p=1) \n    # p=1 is the probability of the transform being executed.\n    \n    2. image - image with shape (h,w)\n    \n    Output:\n    Augmented image as a numpy array.\n    \n    \"\"\"\n    # get the transform as a dict\n    aug_image_dict =  augmentation(image=image)\n    # retrieve the augmented matrix of the image\n    image_matrix = aug_image_dict['image']\n    \n    \n    return image_matrix","metadata":{"execution":{"iopub.status.busy":"2021-09-11T03:14:58.011414Z","iopub.execute_input":"2021-09-11T03:14:58.011941Z","iopub.status.idle":"2021-09-11T03:14:58.020737Z","shell.execute_reply.started":"2021-09-11T03:14:58.011903Z","shell.execute_reply":"2021-09-11T03:14:58.019125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the transforms\n\n# Modified from --> Pneumothorax - 1st place solution\n# Source: https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation/discussion/107824#latest-620521\n\n\naug_types1 = albu.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=45, \n                  interpolation=1, border_mode=4, value=None, mask_value=None, \n                  shift_limit_x=None, shift_limit_y=None, always_apply=False, \n                  p=1)\n\naug_types2 = albu.Flip(p=1)\n\naug_types3 = albu.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2,\n                                           brightness_by_max=True, always_apply=False,p=1)\n\naug_types4 = albu.Blur(blur_limit=(3,3.5), always_apply=False, p=1)\n\naug_types5 = albu.OneOf([\n                albu.ElasticTransform(alpha=1, sigma=50, alpha_affine=50,\n                                       interpolation=1, border_mode=4, value=None,mask_value=None,\n                                       always_apply=False, approximate=False, p=1),\n                albu.GridDistortion(num_steps=5, distort_limit=0.3, interpolation=1, border_mode=4, \n                                 value=None, mask_value=None, always_apply=False, p=1)\n                        ], p=1)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T03:14:58.023373Z","iopub.execute_input":"2021-09-11T03:14:58.023744Z","iopub.status.idle":"2021-09-11T03:14:58.038718Z","shell.execute_reply.started":"2021-09-11T03:14:58.023711Z","shell.execute_reply":"2021-09-11T03:14:58.037422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Build the Data Generators\n\n\n[ 1 ] Train Generator","metadata":{}},{"cell_type":"code","source":"def train_generator_aug(batch_size=8,random_seed=None):\n    \n    while True:\n        \n        if random_seed:\n            random.seed(random_seed)\n        \n        # load the data in chunks (batches)\n        for df in pd.read_csv('df_train.csv.gz', chunksize=batch_size):\n            \n            # get the list of images\n            image_id_list = list(df['image_id'])\n            \n            # Create empty X matrix - 3 channels\n            X_train = np.zeros((6*len(df), IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS), dtype=np.uint8)\n            \n\n        \n            \n            # Create X_train\n            #================\n            \n            for i in range(0, len(image_id_list)):\n              \n              \n                # get the image and mask\n                image_id = image_id_list[i] + '.jpg'\n\n\n                # set the path to the image\n                path = '../input/plant-pathology-2020-fgvc7/images/' + image_id\n\n                # read the image\n                image = cv2.imread(path)\n                \n                # convert to from BGR to RGB\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                \n                # resize the image\n                image = cv2.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))\n                \n                \n            \n            \n            # Create y_train\n            # ===============\n                cols = ['healthy', 'multiple_diseases', 'rust', 'scab']\n                y_train = df[cols]\n                y_train = pd.concat([y_train, y_train, y_train, y_train, y_train, y_train], axis=0).reset_index(drop=True)\n                y_train = np.asarray(y_train) \n\n\n       \n                X_train[i] = image\n                X_train[i+1*len(image_id_list)] = augment_image(aug_types1, image)\n                X_train[i+2*len(image_id_list)] = augment_image(aug_types2, image)\n                X_train[i+3*len(image_id_list)] = augment_image(aug_types3, image)\n                X_train[i+4*len(image_id_list)] = augment_image(aug_types4, image)\n                X_train[i+5*len(image_id_list)] = augment_image(aug_types5, image)\n                \n            # Normalize the images\n            X_train = X_train/255\n\n            yield X_train, y_train\n            ","metadata":{"execution":{"iopub.status.busy":"2021-09-11T03:14:58.04042Z","iopub.execute_input":"2021-09-11T03:14:58.041014Z","iopub.status.idle":"2021-09-11T03:14:58.054354Z","shell.execute_reply.started":"2021-09-11T03:14:58.040966Z","shell.execute_reply":"2021-09-11T03:14:58.053442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_generator_no_aug(batch_size=8):\n    \n    while True:\n        \n        # load the data in chunks (batches)\n        for df in pd.read_csv('df_train.csv.gz', chunksize=batch_size):\n            \n            # get the list of images\n            image_id_list = list(df['image_id'])\n            \n            # Create empty X matrix - 3 channels\n            X_train = np.zeros((len(df), IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS), dtype=np.uint8)\n            \n\n        \n            \n            # Create X_train\n            #================\n            \n            for i in range(0, len(image_id_list)):\n              \n              \n                # get the image and mask\n                image_id = image_id_list[i] + '.jpg'\n\n\n                # set the path to the image\n                path = '../input/plant-pathology-2020-fgvc7/images/' + image_id\n\n                # read the image\n                image = cv2.imread(path)\n                \n                # convert to from BGR to RGB\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                \n                # resize the image\n                image = cv2.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))\n                \n                \n            \n            \n            # Create y_train\n            # ===============\n                cols = ['healthy', 'multiple_diseases', 'rust', 'scab']\n                y_train = df[cols]\n                y_train = np.asarray(y_train) \n                \n                # insert the image into X_train\n                X_train[i] = image\n                \n                          \n                \n            # Normalize the images\n            X_train = X_train/255\n\n            yield X_train, y_train","metadata":{"execution":{"iopub.status.busy":"2021-09-11T03:14:58.055759Z","iopub.execute_input":"2021-09-11T03:14:58.056232Z","iopub.status.idle":"2021-09-11T03:14:58.071031Z","shell.execute_reply.started":"2021-09-11T03:14:58.056188Z","shell.execute_reply":"2021-09-11T03:14:58.06989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test the generator\n\n# initialize\nif AUG:\n    train_gen = train_generator_aug(batch_size=8,random_seed=123)\nelse:\n    train_gen = train_generator_no_aug(batch_size=8)\n\n# run the generator\nX_train, y_train = next(train_gen)\n\nprint(X_train.shape)\nprint(y_train.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T03:14:58.07289Z","iopub.execute_input":"2021-09-11T03:14:58.073319Z","iopub.status.idle":"2021-09-11T03:14:58.413299Z","shell.execute_reply.started":"2021-09-11T03:14:58.073275Z","shell.execute_reply":"2021-09-11T03:14:58.412449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[ 2 ] Val Generator","metadata":{}},{"cell_type":"code","source":"def val_generator(batch_size=5):\n    \n    while True:\n        \n        # load the data in chunks (batches)\n        for df in pd.read_csv('df_val.csv.gz', chunksize=batch_size):\n            \n            # get the list of images\n            image_id_list = list(df['image_id'])\n            \n            # Create empty X matrix - 3 channels\n            X_val = np.zeros((len(df), IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS), dtype=np.uint8)\n            \n\n        \n            \n            # Create X_val\n            #================\n            \n            for i in range(0, len(image_id_list)):\n              \n              \n                # get the image and mask\n                image_id = image_id_list[i] + '.jpg'\n\n\n                # set the path to the image\n                path = '../input/plant-pathology-2020-fgvc7/images/' + image_id\n\n                # read the image\n                image = cv2.imread(path)\n                \n                # convert to from BGR to RGB\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                \n                # resize the image\n                image = cv2.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))\n\n                # insert the image into X_train\n                X_val[i] = image\n                \n                \n            \n            \n            # Create y_val\n            # ===============\n\n                cols = ['healthy', 'multiple_diseases', 'rust', 'scab']\n                y_val = df[cols]\n                y_val = np.asarray(y_val) \n\n                       \n                \n            # Normalize the images\n            X_val = X_val/255\n\n            yield X_val, y_val","metadata":{"execution":{"iopub.status.busy":"2021-09-11T03:14:58.414623Z","iopub.execute_input":"2021-09-11T03:14:58.415106Z","iopub.status.idle":"2021-09-11T03:14:58.425145Z","shell.execute_reply.started":"2021-09-11T03:14:58.415069Z","shell.execute_reply":"2021-09-11T03:14:58.424011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test the generator\n\n# initialize\nval_gen = val_generator(batch_size=5)\n\n# run the generator\nX_val, y_val = next(val_gen)\n\nprint(X_val.shape)\nprint(y_val.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T03:14:58.429341Z","iopub.execute_input":"2021-09-11T03:14:58.429658Z","iopub.status.idle":"2021-09-11T03:14:58.647367Z","shell.execute_reply.started":"2021-09-11T03:14:58.429627Z","shell.execute_reply":"2021-09-11T03:14:58.646155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[ 3 ] Test Generator","metadata":{}},{"cell_type":"code","source":"def test_generator(batch_size=1):\n    \n    while True:\n        \n        # load the data in chunks (batches)\n        for df in pd.read_csv('df_test.csv.gz', chunksize=batch_size):\n            \n            # get the list of images\n            image_id_list = list(df['image_id'])\n            \n            # Create empty X matrix - 3 channels\n            X_test = np.zeros((len(df), IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS), dtype=np.uint8)\n            \n\n        \n            \n            # Create X_test\n            #================\n            \n            for i in range(0, len(image_id_list)):\n              \n              \n                # get the image and mask\n                image_id = image_id_list[i] + '.jpg'\n\n\n                # set the path to the image\n                path = '../input/plant-pathology-2020-fgvc7/images/' + image_id\n\n                # read the image\n                image = cv2.imread(path)\n                \n                # convert to from BGR to RGB\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                \n                # resize the image\n                image = cv2.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))\n\n                # insert the image into X_train\n                X_test[i] = image\n                \n                 \n                \n            # Normalize the images\n            X_test = X_test/255\n\n            yield X_test","metadata":{"execution":{"iopub.status.busy":"2021-09-11T03:14:58.650146Z","iopub.execute_input":"2021-09-11T03:14:58.650703Z","iopub.status.idle":"2021-09-11T03:14:58.659812Z","shell.execute_reply.started":"2021-09-11T03:14:58.650635Z","shell.execute_reply":"2021-09-11T03:14:58.658573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test the generator\n\n# initialize\ntest_gen = test_generator(batch_size=1)\n\n# run the generator\nX_test = next(test_gen)\n\nprint(X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T03:14:58.661305Z","iopub.execute_input":"2021-09-11T03:14:58.661665Z","iopub.status.idle":"2021-09-11T03:14:58.720128Z","shell.execute_reply.started":"2021-09-11T03:14:58.661632Z","shell.execute_reply":"2021-09-11T03:14:58.718786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications.mobilenet import MobileNet\n\nmodel = MobileNet(weights='imagenet')\n\n# Exclude the last 2 layers of the above model.\nx = model.layers[-2].output\n\n# Create a new dense layer for predictions\n# 3 corresponds to the number of classes\npredictions = Dense(4, activation='softmax')(x)\n\n# inputs=model.input selects the input layer, outputs=predictions refers to the\n# dense layer we created above.\n\nmodel = Model(inputs=model.input, outputs=predictions)\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T03:14:58.721707Z","iopub.execute_input":"2021-09-11T03:14:58.722023Z","iopub.status.idle":"2021-09-11T03:14:59.460102Z","shell.execute_reply.started":"2021-09-11T03:14:58.72199Z","shell.execute_reply":"2021-09-11T03:14:59.458315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_train_samples = len(df_train)\nnum_val_samples = len(df_val)\n\n# determine num train steps\ntrain_steps = np.ceil(num_train_samples / TRAIN_BATCH_SIZE)\n\n# determine num val steps\nval_steps = np.ceil(num_val_samples / VAL_BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T03:14:59.461647Z","iopub.execute_input":"2021-09-11T03:14:59.462083Z","iopub.status.idle":"2021-09-11T03:14:59.468503Z","shell.execute_reply.started":"2021-09-11T03:14:59.462039Z","shell.execute_reply":"2021-09-11T03:14:59.467221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import datetime\ntime3 = datetime.datetime.now()\nprint(time3)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T03:14:59.469823Z","iopub.execute_input":"2021-09-11T03:14:59.470099Z","iopub.status.idle":"2021-09-11T03:14:59.481551Z","shell.execute_reply.started":"2021-09-11T03:14:59.470072Z","shell.execute_reply":"2021-09-11T03:14:59.480519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.callbacks import (EarlyStopping, ReduceLROnPlateau, \n                                        ModelCheckpoint, CSVLogger, LearningRateScheduler)\n# Initialize the generators\nif AUG:\n    train_gen = train_generator_aug(batch_size=TRAIN_BATCH_SIZE,random_seed=123)\nelse:\n    train_gen = train_generator_no_aug(batch_size=TRAIN_BATCH_SIZE)\n\nval_gen = val_generator(batch_size=VAL_BATCH_SIZE)\n\n\nmodel.compile(\n    Adam(lr=LR),\n    loss='categorical_crossentropy',\n    metrics=['accuracy'])\n\n\n\n\nfilepath = H5_FILE_NAME\n\n#earlystopper = EarlyStopping(patience=10, verbose=1)\n\ncheckpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, \n                             save_best_only=True, mode='max')\n\nreduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.3, patience=3, \n                                   verbose=1, mode='max')\n\n\n\nlog_fname = TRAINING_LOG_FILE_NAME\ncsv_logger = CSVLogger(filename=log_fname,\n                       separator=',',\n                       append=False)\n\ncallbacks_list = [checkpoint, csv_logger, reduce_lr]\n\nhistory = model.fit(train_gen, steps_per_epoch=train_steps, epochs=EPOCHS, \n                    validation_data=val_gen, validation_steps=val_steps,\n                    verbose=2,\n                    callbacks=callbacks_list)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-11T03:14:59.482914Z","iopub.execute_input":"2021-09-11T03:14:59.483205Z","iopub.status.idle":"2021-09-11T03:18:59.423247Z","shell.execute_reply.started":"2021-09-11T03:14:59.483177Z","shell.execute_reply":"2021-09-11T03:18:59.422193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time4 = datetime.datetime.now()\nprint(time4)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T03:18:59.426943Z","iopub.execute_input":"2021-09-11T03:18:59.427299Z","iopub.status.idle":"2021-09-11T03:18:59.433154Z","shell.execute_reply.started":"2021-09-11T03:18:59.427269Z","shell.execute_reply":"2021-09-11T03:18:59.431735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training time\nprint(time4-time3)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T03:18:59.43464Z","iopub.execute_input":"2021-09-11T03:18:59.434945Z","iopub.status.idle":"2021-09-11T03:18:59.448828Z","shell.execute_reply.started":"2021-09-11T03:18:59.434917Z","shell.execute_reply":"2021-09-11T03:18:59.447864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get the metric names so we can use evaulate_generator\nmodel.metrics_names","metadata":{"execution":{"iopub.status.busy":"2021-09-11T03:18:59.450096Z","iopub.execute_input":"2021-09-11T03:18:59.450371Z","iopub.status.idle":"2021-09-11T03:18:59.461339Z","shell.execute_reply.started":"2021-09-11T03:18:59.450344Z","shell.execute_reply":"2021-09-11T03:18:59.460609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights(H5_FILE_NAME)\n\nval_gen = val_generator(batch_size=VAL_BATCH_SIZE)\n\nval_loss, val_acc = \\\nmodel.evaluate(val_gen, \n               steps=val_steps)\n\nprint('val_loss:', val_loss)\nprint('val_acc:', val_acc)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T03:18:59.462319Z","iopub.execute_input":"2021-09-11T03:18:59.462627Z","iopub.status.idle":"2021-09-11T03:19:19.453631Z","shell.execute_reply.started":"2021-09-11T03:18:59.462599Z","shell.execute_reply":"2021-09-11T03:19:19.452736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display the training log\n\ntrain_log = pd.read_csv(TRAINING_LOG_FILE_NAME)\n\ntrain_log.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T03:19:19.457613Z","iopub.execute_input":"2021-09-11T03:19:19.457984Z","iopub.status.idle":"2021-09-11T03:19:19.473675Z","shell.execute_reply.started":"2021-09-11T03:19:19.457947Z","shell.execute_reply":"2021-09-11T03:19:19.472452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# display the loss and accuracy curves\n\nimport matplotlib.pyplot as plt\n\nacc = train_log['accuracy']\nval_acc = train_log['val_accuracy']\nloss = train_log['loss']\nval_loss = train_log['val_loss']\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, acc)\nplt.plot(epochs, val_acc)\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train','val'],loc = 'upper left')\nplt.show()\n\nplt.plot(epochs, loss)\nplt.plot(epochs, val_loss)\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train','val'],loc = 'upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T03:19:19.475272Z","iopub.execute_input":"2021-09-11T03:19:19.475653Z","iopub.status.idle":"2021-09-11T03:19:19.790954Z","shell.execute_reply.started":"2021-09-11T03:19:19.475619Z","shell.execute_reply":"2021-09-11T03:19:19.789917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Make a prediction on the val set","metadata":{}},{"cell_type":"code","source":"model.load_weights(H5_FILE_NAME)\n\nval_gen = val_generator(batch_size=1)\n\npreds = model.predict(val_gen, steps=len(df_val), verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T03:19:19.792495Z","iopub.execute_input":"2021-09-11T03:19:19.792955Z","iopub.status.idle":"2021-09-11T03:19:42.626084Z","shell.execute_reply.started":"2021-09-11T03:19:19.792919Z","shell.execute_reply":"2021-09-11T03:19:42.624982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get y_pred as index values\n\ny_pred = np.argmax(preds, axis=1)\nprint(y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T03:19:42.62788Z","iopub.execute_input":"2021-09-11T03:19:42.628194Z","iopub.status.idle":"2021-09-11T03:19:42.634857Z","shell.execute_reply.started":"2021-09-11T03:19:42.628161Z","shell.execute_reply":"2021-09-11T03:19:42.633855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get y_true as index values\n\ncols = ['healthy', 'multiple_diseases', 'rust', 'scab']\ny_true = df_val[cols]\ny_true = np.asarray(y_true) \n\ny_true = np.argmax(y_true, axis=1)\nprint(y_true)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T03:19:42.636187Z","iopub.execute_input":"2021-09-11T03:19:42.636491Z","iopub.status.idle":"2021-09-11T03:19:42.651997Z","shell.execute_reply.started":"2021-09-11T03:19:42.636457Z","shell.execute_reply":"2021-09-11T03:19:42.650707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Classification Report","metadata":{}},{"cell_type":"markdown","source":"Make a test set prediction","metadata":{}},{"cell_type":"code","source":"model.load_weights(H5_FILE_NAME)\nval_gen = val_generator(batch_size=1)\n\npreds = model.predict(val_gen, steps=len(df_val), verbose=1)\n\n\ny_pred = np.argmax(preds, axis=1)\nprint(y_pred[:50])","metadata":{"execution":{"iopub.status.busy":"2021-09-11T03:19:42.65355Z","iopub.execute_input":"2021-09-11T03:19:42.654252Z","iopub.status.idle":"2021-09-11T03:20:05.235592Z","shell.execute_reply.started":"2021-09-11T03:19:42.654205Z","shell.execute_reply":"2021-09-11T03:20:05.234822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Put the preds into a dataframe\n\ndf_preds = pd.DataFrame(preds, columns=['healthy', 'multiple_diseases', 'rust', 'scab'])\n\ndf_preds['image_id'] = df_val['image_id'].copy().values\n\ndf_preds.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T03:20:05.238635Z","iopub.execute_input":"2021-09-11T03:20:05.239023Z","iopub.status.idle":"2021-09-11T03:20:05.255035Z","shell.execute_reply.started":"2021-09-11T03:20:05.238991Z","shell.execute_reply":"2021-09-11T03:20:05.254236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a submission csv file\n\ndf_results = pd.DataFrame({'image_id': df_preds.image_id,\n                            'healthy': df_preds.healthy,\n                               'multiple_diseases': df_preds.multiple_diseases,\n                               'rust': df_preds.rust,\n                               'scab': df_preds.scab,\n                           'target':df_val['target'].values\n                           }).set_index('image_id')\n\n\n# create a submission csv file\ndf_results.to_csv(SUBMISSION_FILE_NAME) \ndf_results.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-11T03:20:05.256241Z","iopub.execute_input":"2021-09-11T03:20:05.256732Z","iopub.status.idle":"2021-09-11T03:20:05.285319Z","shell.execute_reply.started":"2021-09-11T03:20:05.256675Z","shell.execute_reply":"2021-09-11T03:20:05.284157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time2 = datetime.datetime.now()\nprint(time2)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T03:20:05.286811Z","iopub.execute_input":"2021-09-11T03:20:05.287104Z","iopub.status.idle":"2021-09-11T03:20:05.292019Z","shell.execute_reply.started":"2021-09-11T03:20:05.287076Z","shell.execute_reply":"2021-09-11T03:20:05.29119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Total time\nprint(time2 - time1)","metadata":{"execution":{"iopub.status.busy":"2021-09-11T03:20:05.293232Z","iopub.execute_input":"2021-09-11T03:20:05.293847Z","iopub.status.idle":"2021-09-11T03:20:05.304193Z","shell.execute_reply.started":"2021-09-11T03:20:05.293798Z","shell.execute_reply":"2021-09-11T03:20:05.303077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2021-09-11T03:20:05.306384Z","iopub.execute_input":"2021-09-11T03:20:05.306922Z","iopub.status.idle":"2021-09-11T03:20:06.081074Z","shell.execute_reply.started":"2021-09-11T03:20:05.30687Z","shell.execute_reply":"2021-09-11T03:20:06.079566Z"},"trusted":true},"execution_count":null,"outputs":[]}]}