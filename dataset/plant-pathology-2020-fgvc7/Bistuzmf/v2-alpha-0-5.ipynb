{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import datetime\ntime1 = datetime.datetime.now()\nprint(time1)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T05:25:39.8092Z","iopub.execute_input":"2021-10-26T05:25:39.809969Z","iopub.status.idle":"2021-10-26T05:25:39.835455Z","shell.execute_reply.started":"2021-10-26T05:25:39.809874Z","shell.execute_reply":"2021-10-26T05:25:39.834558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nimport cv2\nimport pandas as pd\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications import VGG19\nfrom tensorflow.keras.layers import Flatten,Dense,Dropout,BatchNormalization\nfrom tensorflow.keras.models import Model,Sequential\nfrom tensorflow.keras.utils import to_categorical\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\n\nfrom tensorflow.keras.metrics import categorical_accuracy\n\nfrom tensorflow.keras.callbacks import (EarlyStopping, ReduceLROnPlateau, \n                                        ModelCheckpoint, CSVLogger, LearningRateScheduler)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T05:25:39.837541Z","iopub.execute_input":"2021-10-26T05:25:39.837826Z","iopub.status.idle":"2021-10-26T05:25:45.364087Z","shell.execute_reply.started":"2021-10-26T05:25:39.837788Z","shell.execute_reply":"2021-10-26T05:25:45.363359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_HEIGHT = 224\nIMAGE_WIDTH = 224\nIMAGE_CHANNELS = 3\nTRAIN_BATCH_SIZE = 8\nVAL_BATCH_SIZE = 5\nEPOCHS = 1\nBALANCE = True #True  False\nAUG = True #True  False\nLR = 0.001#0.001  0.005  0.01\nH5_FILE_NAME = '_'.join(['model',\n                        'balance' if BALANCE else 'nobalance',\n                        'aug' if AUG else 'noaug',\n                        str(LR)]) + '.h5'\nprint(H5_FILE_NAME)\nTRAINING_LOG_FILE_NAME = '_'.join(['training_log',\n                        'balance' if BALANCE else 'nobalance',\n                        'aug' if AUG else 'noaug',\n                        str(LR)]) + '.csv'\nprint(TRAINING_LOG_FILE_NAME)\nSUBMISSION_FILE_NAME = '_'.join(['submission',\n                        'balance' if BALANCE else 'nobalance',\n                        'aug' if AUG else 'noaug',\n                        str(LR)]) + '.csv'\nprint(SUBMISSION_FILE_NAME)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T05:25:45.365444Z","iopub.execute_input":"2021-10-26T05:25:45.365681Z","iopub.status.idle":"2021-10-26T05:25:45.373669Z","shell.execute_reply.started":"2021-10-26T05:25:45.365646Z","shell.execute_reply":"2021-10-26T05:25:45.373039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '../input/plant-pathology-2020-fgvc7/train.csv'\ndf_train_all = pd.read_csv(path)\n\npath = '../input/plant-pathology-2020-fgvc7/test.csv'\ndf_test = pd.read_csv(path)\n\npath = '../input/plant-pathology-2020-fgvc7/sample_submission.csv'\ndf_sample = pd.read_csv(path)\n\n\nprint(df_train_all.shape)\nprint(df_test.shape)\nprint(df_sample.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T05:25:45.374835Z","iopub.execute_input":"2021-10-26T05:25:45.375449Z","iopub.status.idle":"2021-10-26T05:25:45.566625Z","shell.execute_reply.started":"2021-10-26T05:25:45.375407Z","shell.execute_reply":"2021-10-26T05:25:45.565793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Identify the target class of each row in the train set\n\ndef get_class(row):\n    \n    if row['multiple_diseases'] == 1:\n        return 'multiple_diseases'\n    \n    elif row['rust'] == 1:\n        return 'rust'\n    \n    elif row['scab'] == 1:\n        return 'scab'\n    \n    else:\n        return 'healthy'\n    \ndf_train_all['target'] = df_train_all.apply(get_class, axis=1)\n\ndf_train_all.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-26T05:25:45.568933Z","iopub.execute_input":"2021-10-26T05:25:45.569207Z","iopub.status.idle":"2021-10-26T05:25:45.629734Z","shell.execute_reply.started":"2021-10-26T05:25:45.569172Z","shell.execute_reply":"2021-10-26T05:25:45.628962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_all['target'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-10-26T05:25:45.630987Z","iopub.execute_input":"2021-10-26T05:25:45.631291Z","iopub.status.idle":"2021-10-26T05:25:45.642833Z","shell.execute_reply.started":"2021-10-26T05:25:45.631256Z","shell.execute_reply":"2021-10-26T05:25:45.642155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# shuffle\ndf_train_all_shuffle = shuffle(df_train_all, random_state=101)\n# select the column that we will use for stratification\ny = df_train_all_shuffle['target']\n\ndf_train, df_val = train_test_split(df_train_all_shuffle, test_size=0.2, random_state=101, stratify=y)\n\n\nprint(df_train.shape)\nprint(df_val.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T05:25:45.64494Z","iopub.execute_input":"2021-10-26T05:25:45.64559Z","iopub.status.idle":"2021-10-26T05:25:45.662477Z","shell.execute_reply.started":"2021-10-26T05:25:45.645555Z","shell.execute_reply":"2021-10-26T05:25:45.661698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['target'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-10-26T05:25:45.663939Z","iopub.execute_input":"2021-10-26T05:25:45.664236Z","iopub.status.idle":"2021-10-26T05:25:45.672277Z","shell.execute_reply.started":"2021-10-26T05:25:45.664196Z","shell.execute_reply":"2021-10-26T05:25:45.671393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_val['target'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-10-26T05:25:45.674219Z","iopub.execute_input":"2021-10-26T05:25:45.674839Z","iopub.status.idle":"2021-10-26T05:25:45.684899Z","shell.execute_reply.started":"2021-10-26T05:25:45.6748Z","shell.execute_reply":"2021-10-26T05:25:45.683991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_balancer(df_train):\n    df_1 = df_train[df_train['target'] != 'multiple_diseases']\n    df_2 = df_train[df_train['target'] == 'multiple_diseases']\n    df_train_up = pd.concat([df_1, df_2,  df_2,  df_2,  df_2,  df_2,  df_2], axis=0).reset_index(drop=True)\n\n    df_train_ret = shuffle(df_train_up, random_state=101)\n    return df_train_ret","metadata":{"execution":{"iopub.status.busy":"2021-10-26T05:25:45.686907Z","iopub.execute_input":"2021-10-26T05:25:45.687675Z","iopub.status.idle":"2021-10-26T05:25:45.693818Z","shell.execute_reply.started":"2021-10-26T05:25:45.687637Z","shell.execute_reply":"2021-10-26T05:25:45.693018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This is the new class distribution of the train set\nif BALANCE:\n    df_train = train_balancer(df_train)\ndf_train['target'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-10-26T05:25:45.695028Z","iopub.execute_input":"2021-10-26T05:25:45.695449Z","iopub.status.idle":"2021-10-26T05:25:45.713324Z","shell.execute_reply.started":"2021-10-26T05:25:45.695412Z","shell.execute_reply":"2021-10-26T05:25:45.712423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.to_csv('df_train.csv.gz', compression='gzip', index=False)\ndf_val.to_csv('df_val.csv.gz', compression='gzip', index=False)\ndf_test.to_csv('df_test.csv.gz', compression='gzip', index=False)\n!ls","metadata":{"execution":{"iopub.status.busy":"2021-10-26T05:25:45.714924Z","iopub.execute_input":"2021-10-26T05:25:45.715222Z","iopub.status.idle":"2021-10-26T05:25:46.407166Z","shell.execute_reply.started":"2021-10-26T05:25:45.715183Z","shell.execute_reply":"2021-10-26T05:25:46.406304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Albumentations\n\nimport albumentations as albu\n\n\ndef augment_image(augmentation, image):\n    \n    \"\"\"\n    Uses the Albumentations library.\n    \n    Inputs: \n    1. augmentation - this is the instance of type of augmentation to do \n    e.g. aug_type = HorizontalFlip(p=1) \n    # p=1 is the probability of the transform being executed.\n    \n    2. image - image with shape (h,w)\n    \n    Output:\n    Augmented image as a numpy array.\n    \n    \"\"\"\n    # get the transform as a dict\n    aug_image_dict =  augmentation(image=image)\n    # retrieve the augmented matrix of the image\n    image_matrix = aug_image_dict['image']\n    \n    \n    return image_matrix","metadata":{"execution":{"iopub.status.busy":"2021-10-26T05:25:46.409164Z","iopub.execute_input":"2021-10-26T05:25:46.409467Z","iopub.status.idle":"2021-10-26T05:25:47.526844Z","shell.execute_reply.started":"2021-10-26T05:25:46.40943Z","shell.execute_reply":"2021-10-26T05:25:47.52615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the transforms\n\n# Modified from --> Pneumothorax - 1st place solution\n# Source: https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation/discussion/107824#latest-620521\n\n\naug_types1 = albu.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=45, \n                  interpolation=1, border_mode=4, value=None, mask_value=None, \n                  shift_limit_x=None, shift_limit_y=None, always_apply=False, \n                  p=1)\n\naug_types2 = albu.Flip(p=1)\n\naug_types3 = albu.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2,\n                                           brightness_by_max=True, always_apply=False,p=1)\n\naug_types4 = albu.Blur(blur_limit=(3,3.5), always_apply=False, p=1)\n\naug_types5 = albu.OneOf([\n                albu.ElasticTransform(alpha=1, sigma=50, alpha_affine=50,\n                                       interpolation=1, border_mode=4, value=None,mask_value=None,\n                                       always_apply=False, approximate=False, p=1),\n                albu.GridDistortion(num_steps=5, distort_limit=0.3, interpolation=1, border_mode=4, \n                                 value=None, mask_value=None, always_apply=False, p=1)\n                        ], p=1)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T05:25:47.531475Z","iopub.execute_input":"2021-10-26T05:25:47.531921Z","iopub.status.idle":"2021-10-26T05:25:47.541369Z","shell.execute_reply.started":"2021-10-26T05:25:47.531891Z","shell.execute_reply":"2021-10-26T05:25:47.539783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_generator_aug(batch_size=8,random_seed=None):\n    \n    while True:\n        \n        if random_seed:\n            random.seed(random_seed)\n        \n        # load the data in chunks (batches)\n        for df in pd.read_csv('df_train.csv.gz', chunksize=batch_size):\n            \n            # get the list of images\n            image_id_list = list(df['image_id'])\n            \n            # Create empty X matrix - 3 channels\n            X_train = np.zeros((6*len(df), IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS), dtype=np.uint8)\n            \n\n        \n            \n            # Create X_train\n            #================\n            \n            for i in range(0, len(image_id_list)):\n              \n              \n                # get the image and mask\n                image_id = image_id_list[i] + '.jpg'\n\n\n                # set the path to the image\n                path = '../input/plant-pathology-2020-fgvc7/images/' + image_id\n\n                # read the image\n                image = cv2.imread(path)\n                \n                # convert to from BGR to RGB\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                \n                # resize the image\n                image = cv2.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))\n                \n                \n            \n            \n            # Create y_train\n            # ===============\n                cols = ['healthy', 'multiple_diseases', 'rust', 'scab']\n                y_train = df[cols]\n                y_train = pd.concat([y_train, y_train, y_train, y_train, y_train, y_train], axis=0).reset_index(drop=True)\n                y_train = np.asarray(y_train) \n\n\n       \n                X_train[i] = image\n                X_train[i+1*len(image_id_list)] = augment_image(aug_types1, image)\n                X_train[i+2*len(image_id_list)] = augment_image(aug_types2, image)\n                X_train[i+3*len(image_id_list)] = augment_image(aug_types3, image)\n                X_train[i+4*len(image_id_list)] = augment_image(aug_types4, image)\n                X_train[i+5*len(image_id_list)] = augment_image(aug_types5, image)\n                \n            # Normalize the images\n            X_train = X_train/255\n\n            yield X_train, y_train\n            ","metadata":{"execution":{"iopub.status.busy":"2021-10-26T05:25:47.542827Z","iopub.execute_input":"2021-10-26T05:25:47.543327Z","iopub.status.idle":"2021-10-26T05:25:47.556267Z","shell.execute_reply.started":"2021-10-26T05:25:47.543265Z","shell.execute_reply":"2021-10-26T05:25:47.555529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_generator_no_aug(batch_size=8):\n    \n    while True:\n        \n        # load the data in chunks (batches)\n        for df in pd.read_csv('df_train.csv.gz', chunksize=batch_size):\n            \n            # get the list of images\n            image_id_list = list(df['image_id'])\n            \n            # Create empty X matrix - 3 channels\n            X_train = np.zeros((len(df), IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS), dtype=np.uint8)\n            \n\n        \n            \n            # Create X_train\n            #================\n            \n            for i in range(0, len(image_id_list)):\n              \n              \n                # get the image and mask\n                image_id = image_id_list[i] + '.jpg'\n\n\n                # set the path to the image\n                path = '../input/plant-pathology-2020-fgvc7/images/' + image_id\n\n                # read the image\n                image = cv2.imread(path)\n                \n                # convert to from BGR to RGB\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                \n                # resize the image\n                image = cv2.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))\n                \n                \n            \n            \n            # Create y_train\n            # ===============\n                cols = ['healthy', 'multiple_diseases', 'rust', 'scab']\n                y_train = df[cols]\n                y_train = np.asarray(y_train) \n                \n                # insert the image into X_train\n                X_train[i] = image\n                \n                          \n                \n            # Normalize the images\n            X_train = X_train/255\n\n            yield X_train, y_train","metadata":{"execution":{"iopub.status.busy":"2021-10-26T05:25:47.559174Z","iopub.execute_input":"2021-10-26T05:25:47.559386Z","iopub.status.idle":"2021-10-26T05:25:47.570854Z","shell.execute_reply.started":"2021-10-26T05:25:47.559356Z","shell.execute_reply":"2021-10-26T05:25:47.569925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test the generator\n\n# initialize\nif AUG:\n    train_gen = train_generator_aug(batch_size=8,random_seed=123)\nelse:\n    train_gen = train_generator_no_aug(batch_size=8)\n\n# run the generator\nX_train, y_train = next(train_gen)\n\nprint(X_train.shape)\nprint(y_train.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T05:25:47.5724Z","iopub.execute_input":"2021-10-26T05:25:47.572854Z","iopub.status.idle":"2021-10-26T05:25:48.184578Z","shell.execute_reply.started":"2021-10-26T05:25:47.572815Z","shell.execute_reply":"2021-10-26T05:25:48.183816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def val_generator(batch_size=5):\n    \n    while True:\n        \n        # load the data in chunks (batches)\n        for df in pd.read_csv('df_val.csv.gz', chunksize=batch_size):\n            \n            # get the list of images\n            image_id_list = list(df['image_id'])\n            \n            # Create empty X matrix - 3 channels\n            X_val = np.zeros((len(df), IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS), dtype=np.uint8)\n            \n\n        \n            \n            # Create X_val\n            #================\n            \n            for i in range(0, len(image_id_list)):\n              \n              \n                # get the image and mask\n                image_id = image_id_list[i] + '.jpg'\n\n\n                # set the path to the image\n                path = '../input/plant-pathology-2020-fgvc7/images/' + image_id\n\n                # read the image\n                image = cv2.imread(path)\n                \n                # convert to from BGR to RGB\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                \n                # resize the image\n                image = cv2.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))\n\n                # insert the image into X_train\n                X_val[i] = image\n                \n                \n            \n            \n            # Create y_val\n            # ===============\n\n                cols = ['healthy', 'multiple_diseases', 'rust', 'scab']\n                y_val = df[cols]\n                y_val = np.asarray(y_val) \n\n                       \n                \n            # Normalize the images\n            X_val = X_val/255\n\n            yield X_val, y_val","metadata":{"execution":{"iopub.status.busy":"2021-10-26T05:25:48.185753Z","iopub.execute_input":"2021-10-26T05:25:48.185993Z","iopub.status.idle":"2021-10-26T05:25:48.194694Z","shell.execute_reply.started":"2021-10-26T05:25:48.185957Z","shell.execute_reply":"2021-10-26T05:25:48.194011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test the generator\n\n# initialize\nval_gen = val_generator(batch_size=5)\n\n# run the generator\nX_val, y_val = next(val_gen)\n\nprint(X_val.shape)\nprint(y_val.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T05:25:48.196065Z","iopub.execute_input":"2021-10-26T05:25:48.196521Z","iopub.status.idle":"2021-10-26T05:25:48.418712Z","shell.execute_reply.started":"2021-10-26T05:25:48.196485Z","shell.execute_reply":"2021-10-26T05:25:48.417813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_generator(batch_size=1):\n    \n    while True:\n        \n        # load the data in chunks (batches)\n        for df in pd.read_csv('df_test.csv.gz', chunksize=batch_size):\n            \n            # get the list of images\n            image_id_list = list(df['image_id'])\n            \n            # Create empty X matrix - 3 channels\n            X_test = np.zeros((len(df), IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS), dtype=np.uint8)\n            \n\n        \n            \n            # Create X_test\n            #================\n            \n            for i in range(0, len(image_id_list)):\n              \n              \n                # get the image and mask\n                image_id = image_id_list[i] + '.jpg'\n\n\n                # set the path to the image\n                path = '../input/plant-pathology-2020-fgvc7/images/' + image_id\n\n                # read the image\n                image = cv2.imread(path)\n                \n                # convert to from BGR to RGB\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                \n                # resize the image\n                image = cv2.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))\n\n                # insert the image into X_train\n                X_test[i] = image\n                \n                 \n                \n            # Normalize the images\n            X_test = X_test/255\n\n            yield X_test","metadata":{"execution":{"iopub.status.busy":"2021-10-26T05:25:48.420046Z","iopub.execute_input":"2021-10-26T05:25:48.42031Z","iopub.status.idle":"2021-10-26T05:25:48.427838Z","shell.execute_reply.started":"2021-10-26T05:25:48.420275Z","shell.execute_reply":"2021-10-26T05:25:48.427064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test the generator\n\n# initialize\ntest_gen = test_generator(batch_size=1)\n\n# run the generator\nX_test = next(test_gen)\n\nprint(X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T05:25:48.429326Z","iopub.execute_input":"2021-10-26T05:25:48.429594Z","iopub.status.idle":"2021-10-26T05:25:48.485409Z","shell.execute_reply.started":"2021-10-26T05:25:48.429558Z","shell.execute_reply":"2021-10-26T05:25:48.484451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n\nmodel = MobileNetV2(weights='imagenet', alpha=0.5)\n\n# Exclude the last 2 layers of the above model.\nx = model.layers[-2].output\n\n# Create a new dense layer for predictions\n# 3 corresponds to the number of classes\npredictions = Dense(4, activation='softmax')(x)\n\n# inputs=model.input selects the input layer, outputs=predictions refers to the\n# dense layer we created above.\n\nmodel = Model(inputs=model.input, outputs=predictions)\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-26T05:25:48.486912Z","iopub.execute_input":"2021-10-26T05:25:48.487184Z","iopub.status.idle":"2021-10-26T05:25:52.176487Z","shell.execute_reply.started":"2021-10-26T05:25:48.487149Z","shell.execute_reply":"2021-10-26T05:25:52.175795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_train_samples = len(df_train)\nnum_val_samples = len(df_val)\n\n# determine num train steps\ntrain_steps = np.ceil(num_train_samples / TRAIN_BATCH_SIZE)\n\n# determine num val steps\nval_steps = np.ceil(num_val_samples / VAL_BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T05:25:52.177458Z","iopub.execute_input":"2021-10-26T05:25:52.177693Z","iopub.status.idle":"2021-10-26T05:25:52.183404Z","shell.execute_reply.started":"2021-10-26T05:25:52.177656Z","shell.execute_reply":"2021-10-26T05:25:52.182692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import datetime\ntime3 = datetime.datetime.now()\nprint(time3)","metadata":{"execution":{"iopub.status.busy":"2021-10-26T05:25:52.184902Z","iopub.execute_input":"2021-10-26T05:25:52.185169Z","iopub.status.idle":"2021-10-26T05:25:52.193596Z","shell.execute_reply.started":"2021-10-26T05:25:52.18512Z","shell.execute_reply":"2021-10-26T05:25:52.192534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.callbacks import (EarlyStopping, ReduceLROnPlateau, \n                                        ModelCheckpoint, CSVLogger, LearningRateScheduler)\n# Initialize the generators\nif AUG:\n    train_gen = train_generator_aug(batch_size=TRAIN_BATCH_SIZE,random_seed=123)\nelse:\n    train_gen = train_generator_no_aug(batch_size=TRAIN_BATCH_SIZE)\n\nval_gen = val_generator(batch_size=VAL_BATCH_SIZE)\n\n\nmodel.compile(\n    Adam(lr=LR),\n    loss='categorical_crossentropy',\n    metrics=['accuracy'])\n\n\n\n\nfilepath = H5_FILE_NAME\n\n#earlystopper = EarlyStopping(patience=10, verbose=1)\n\ncheckpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, \n                             save_best_only=True, mode='max')\n\nreduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.3, patience=3, \n                                   verbose=1, mode='max')\n\n\n\nlog_fname = TRAINING_LOG_FILE_NAME\ncsv_logger = CSVLogger(filename=log_fname,\n                       separator=',',\n                       append=False)\n\ncallbacks_list = [checkpoint, csv_logger, reduce_lr]\n\nhistory = model.fit(train_gen, steps_per_epoch=train_steps, epochs=EPOCHS, \n                    validation_data=val_gen, validation_steps=val_steps,\n                    verbose=2,\n                    callbacks=callbacks_list)\n","metadata":{"execution":{"iopub.status.busy":"2021-10-26T05:25:52.194875Z","iopub.execute_input":"2021-10-26T05:25:52.195472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time4 = datetime.datetime.now()\nprint(time4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training time\nprint(time4-time3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get the metric names so we can use evaulate_generator\nmodel.metrics_names","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights(H5_FILE_NAME)\n\nval_gen = val_generator(batch_size=VAL_BATCH_SIZE)\n\nval_loss, val_acc = \\\nmodel.evaluate(val_gen, \n               steps=val_steps)\n\nprint('val_loss:', val_loss)\nprint('val_acc:', val_acc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display the training log\n\ntrain_log = pd.read_csv(TRAINING_LOG_FILE_NAME)\n\ntrain_log.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# display the loss and accuracy curves\n\nimport matplotlib.pyplot as plt\n\nacc = train_log['accuracy']\nval_acc = train_log['val_accuracy']\nloss = train_log['loss']\nval_loss = train_log['val_loss']\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, acc)\nplt.plot(epochs, val_acc)\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train','val'],loc = 'upper left')\nplt.show()\n\nplt.plot(epochs, loss)\nplt.plot(epochs, val_loss)\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train','val'],loc = 'upper left')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights(H5_FILE_NAME)\n\nval_gen = val_generator(batch_size=1)\n\npreds = model.predict(val_gen, steps=len(df_val), verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get y_pred as index values\n\ny_pred = np.argmax(preds, axis=1)\nprint(y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get y_true as index values\n\ncols = ['healthy', 'multiple_diseases', 'rust', 'scab']\ny_true = df_val[cols]\ny_true = np.asarray(y_true) \n\ny_true = np.argmax(y_true, axis=1)\nprint(y_true)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights(H5_FILE_NAME)\nval_gen = val_generator(batch_size=1)\n\npreds = model.predict(val_gen, steps=len(df_val), verbose=1)\n\n\ny_pred = np.argmax(preds, axis=1)\nprint(y_pred[:50])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Put the preds into a dataframe\n\ndf_preds = pd.DataFrame(preds, columns=['healthy', 'multiple_diseases', 'rust', 'scab'])\n\ndf_preds['image_id'] = df_val['image_id'].copy().values\n\ndf_preds.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a submission csv file\n\ndf_results = pd.DataFrame({'image_id': df_preds.image_id,\n                            'healthy': df_preds.healthy,\n                               'multiple_diseases': df_preds.multiple_diseases,\n                               'rust': df_preds.rust,\n                               'scab': df_preds.scab,\n                           'target':df_val['target'].values\n                           }).set_index('image_id')\n\n\n# create a submission csv file\ndf_results.to_csv(SUBMISSION_FILE_NAME) \ndf_results.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time2 = datetime.datetime.now()\nprint(time2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Total time\nprint(time2 - time1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}