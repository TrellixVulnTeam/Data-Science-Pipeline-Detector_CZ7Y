{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 1 DenseNet121 Model****"},{"metadata":{},"cell_type":"markdown","source":"烟台苹果甲天下，驰名海外，烟台苹果既好看又好吃。生活在盛产苹果的故乡，从小啃着苹果长大，与果园和果树打交道，参加果园管理，施肥、浇水、去病虫害和收获，各类苹果的味道、果树的味道、农药的味道、树枝树叶树皮的味道，对果园熟悉得不能再熟悉。<br/>\n过往在果园劳动的场景历历在目，所以看到有这样一个数据集，立即被吸引了。本案例是对DenseNet121与MobileNetV2的模型性能做比较。<br/>\n写得很浅，以后有时间再回来补充完善。<br/>\n主要参照了作者：<a href='https://www.kaggle.com/tarunpaparaju'>Tarun Paparaju</a> 的作品，有一定的参数改良，重新进行了模块化设计，便于迁移到Pycharm等IDE环境下运行。"},{"metadata":{},"cell_type":"markdown","source":"### Acknowledgements\n### 参考：<a href = 'https://www.kaggle.com/tarunpaparaju/plant-pathology-2020-eda-models'>Plant Pathology 2020 : EDA + Models </a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#配置TPU运行模式\nimport tensorflow as tf\nfrom kaggle_datasets import KaggleDatasets\n# 探测TPU\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy()\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync\nGCS_DS_PATH = KaggleDatasets().get_gcs_path()\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.1 数据预处理"},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\n程序：handle_data.py\n功能：数据预处理\n设计：董相志，upsunny2008@163.com\n日期：2021.3.12\n\"\"\"\nimport os\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\n\ntqdm.pandas()\n\n# 数据集观察\ndef data_observation(csv_file_path: str, image_path: str, index: int):\n    data = pd.read_csv(csv_file_path)\n    print(data.head())  # 显示数据集\n    image = cv2.imread(image_path + data['image_id'][index] + '.jpg')\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    fig = px.imshow(cv2.resize(image, (205, 136)))\n    fig.show()\n\n\n# 分类观察\ndef category_observation(csv_file_path: str, image_path: str, cond=[0, 0, 0, 0], cond_cols=[\"healthy\"]):\n    data = pd.read_csv(csv_file_path)\n    train_images = []\n    SAMPLE_LEN = 40\n    for i in range(SAMPLE_LEN):\n        image = cv2.imread(image_path + data['image_id'][i] + '.jpg')\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        train_images.append(image)\n    cond_0 = \"healthy == {}\".format(cond[0])\n    cond_1 = \"scab == {}\".format(cond[1])\n    cond_2 = \"rust == {}\".format(cond[2])\n    cond_3 = \"multiple_diseases == {}\".format(cond[3])\n    cond_list = []\n    for col in cond_cols:\n        if col == \"healthy\":\n            cond_list.append(cond_0)\n        if col == \"scab\":\n            cond_list.append(cond_1)\n        if col == \"rust\":\n            cond_list.append(cond_2)\n        if col == \"multiple_diseases\":\n            cond_list.append(cond_3)\n    data = data[:SAMPLE_LEN]\n    for cond in cond_list:\n        data = data.query(cond)\n    print(data)\n    images = []\n    for index in data.index:\n        images.append(train_images[index])\n    cols, rows = 2, min([2, len(images) // 2])\n    fig, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(8, rows * 6 / 2))\n    for col in range(cols):\n        for row in range(rows):\n            ax[row, col].imshow(images[row * 2 + col])\n            ax[row, col].set_title(data['image_id'][data.index[row * 2 + col]])\n    plt.show()\n\n\n# 类别分布\ndef category_distribution(csv_file_path: str):\n    train_data = pd.read_csv(csv_file_path)\n    fig = px.parallel_categories(train_data[[\"healthy\", \"scab\", \"rust\", \"multiple_diseases\"]],\n                                 color=\"healthy\", color_continuous_scale=\"sunset\",\n                                 title=\"Parallel categories plot of targets\",\n                                 width=500, height=300)\n    fig.show()\n\n    fig = go.Figure([go.Pie(labels=train_data.columns[1:],\n                            values=train_data.iloc[:, 1:].sum().values)])\n    fig.update_layout(title_text=\"Pie chart of targets\", template=\"simple_white\")\n    fig.data[0].marker.line.color = 'rgb(0, 0, 0)'\n    fig.data[0].marker.line.width = 0.5\n    fig.show()\n\n\n# 数据随机增强\ndef data_augmentation(image, label=None):\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    if label is None:\n        return image\n    else:\n        return image, label\n\n\n# 生成图像路径\ndef format_path(image_id):\n    return GCS_DS_PATH + '/images/' + image_id + '.jpg'\n\n\n# 图像数据加载与解码函数\ndef decode_image(filename, label=None, image_size=(512, 512)):\n    bits = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(bits, channels=3)\n    image = tf.image.resize(image, image_size)\n    image = tf.cast(image, tf.float32) / 255.0\n    if label is None:\n        return image\n    else:\n        return image, label\n\n\n# 数据集划分\ndef data_split(train_file_path: str, test_file_path: str):\n    train_data = pd.read_csv(train_file_path)  # 训练集\n    test_data = pd.read_csv(test_file_path)  # 测试集\n    train_paths = train_data.image_id.apply(format_path).values\n    train_labels = np.float32(train_data.loc[:, 'healthy':'scab'].values)\n    test_paths = test_data.image_id.apply(format_path).values\n    train_paths, valid_paths, train_labels, valid_labels = train_test_split(train_paths, train_labels, test_size=0.15,\n                                                                            random_state=2021)\n\n    AUTO = tf.data.experimental.AUTOTUNE\n    # 构建训练集\n    train_dataset = (\n        tf.data.Dataset\n            .from_tensor_slices((train_paths, train_labels))\n            .map(decode_image, num_parallel_calls=AUTO)\n            .map(data_augmentation, num_parallel_calls=AUTO)\n            .repeat()\n            .shuffle(512)\n            .batch(BATCH_SIZE)\n            .prefetch(AUTO)\n    )\n    # 构建验证集\n    valid_dataset = (\n        tf.data.Dataset\n            .from_tensor_slices((valid_paths, valid_labels))\n            .map(decode_image, num_parallel_calls=AUTO)\n            .batch(BATCH_SIZE)\n            .cache()\n            .prefetch(AUTO)\n    )\n    # 构建测试集\n    test_dataset = (\n        tf.data.Dataset\n            .from_tensor_slices(test_paths)\n            .map(decode_image, num_parallel_calls=AUTO)\n            .batch(BATCH_SIZE)\n    )\n    return train_dataset, valid_dataset, test_dataset\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.2 建模与评估"},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\n程序：handle_model.py\n功能：建模过程\n设计：董相志，upsunny2008@163.com\n日期：2021.3.12\n\"\"\"\nimport numpy as np\nimport pandas as pd\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport cv2\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D,Dropout,GlobalAveragePooling2D\nfrom tensorflow.keras.applications import DenseNet121\nfrom tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ModelCheckpoint\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import load_model\n\n# 模型定义\ndef model_define(train_labels, batch_size: int=BATCH_SIZE):\n    steps_per_epoch = train_labels.shape[0] // batch_size\n    model = Sequential(name='MyDenseNet121')\n    dense_net = DenseNet121(include_top=False, weights='imagenet', input_shape=(512, 512, 3))\n    model.add(dense_net)\n    model.add(GlobalAveragePooling2D())\n    model.add(Dense(train_labels.shape[1], activation='softmax'))\n    model.compile(optimizer=Adam(learning_rate=0.001),\n                  loss='categorical_crossentropy',\n                  metrics=['categorical_accuracy'])\n    model.summary()\n    return model\n\n#学习率调度函数\ndef build_lrfn(lr_start=0.00001, lr_max=0.00005, \n               lr_min=0.00001, lr_rampup_epochs=5, \n               lr_sustain_epochs=0, lr_exp_decay=.8):\n    lr_max = lr_max * strategy.num_replicas_in_sync\n\n    def lrfn(epoch):\n        if epoch < lr_rampup_epochs:\n            lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start\n        elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n            lr = lr_max\n        else:\n            lr = (lr_max - lr_min) *\\\n                 lr_exp_decay**(epoch - lr_rampup_epochs\\\n                                - lr_sustain_epochs) + lr_min\n        return lr\n    return lrfn\n\n\n# 模型训练\ndef model_train(model, train_dataset, valid_dataset, epochs, steps_per_epoch, saved_path):\n    # 定义回调函数：学习率调度\n    lrfn = build_lrfn(lr_sustain_epochs=2,lr_exp_decay=.9)\n    lr_schedule = LearningRateScheduler(lrfn, verbose=1)\n    # 定义回调函数：提前终止训练\n    early_stop = EarlyStopping(monitor='val_categorical_accuracy', min_delta=0, \n                               patience=10, verbose=1, restore_best_weights=True)\n    # 定义回调函数：保存最优模型\n    best_model = ModelCheckpoint(saved_path, monitor='val_categorical_accuracy', \n                                 verbose=1, save_best_only=True,\n                                 save_weights_only=False, mode='max')\n    history = model.fit(train_dataset,epochs=epochs,\n                        callbacks=[lr_schedule, best_model,early_stop],\n                        steps_per_epoch=steps_per_epoch,\n                        validation_data=valid_dataset)\n    return history\n\n\n# 模型评估\ndef model_estimate(history, epochs):\n    training = history.history['categorical_accuracy']\n    validation = history.history['val_categorical_accuracy']\n    ylabel = \"Accuracy\"\n    title = \"Accuracy vs. Epochs\"\n    fig = go.Figure()\n    fig.add_trace(\n        go.Scatter(x=np.arange(1, epochs + 1), mode='lines+markers', \n                   y=training, marker=dict(color=\"dodgerblue\"),\n                   name=\"Train\"))\n    fig.add_trace(\n        go.Scatter(x=np.arange(1, epochs + 1), mode='lines+markers', \n                   y=validation, marker=dict(color=\"darkorange\"),\n                   name=\"Val\"))\n    fig.update_layout(title_text=title, yaxis_title=ylabel, \n                      xaxis_title=\"Epochs\", width=500, height=300)\n    fig.show()\n\n\ndef load_image(image_id):\n    file_path = '/kaggle/input/plant-pathology-2020-fgvc7/images/' + image_id + \".jpg\"\n    image = cv2.imread(file_path)\n    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n\ndef process(img):\n    return cv2.resize(img / 255.0, (512, 512)).reshape(-1, 512, 512, 3)\n\n\n# 模型预测\ndef model_predict(saved_model, img):\n    model = load_model(saved_model)\n    preds = model.layers[2](model.layers[1](model.layers[0](process(img)))).numpy()[0]\n    return preds\n\n# 显示预测结果\ndef displayResult(img, preds):\n    fig = make_subplots(rows=1, cols=2)\n    colors = {\"Healthy\": px.colors.qualitative.Plotly[0], \"Scab\": px.colors.qualitative.Plotly[0],\n              \"Rust\": px.colors.qualitative.Plotly[0], \"Multiple diseases\": px.colors.qualitative.Plotly[0]}\n    pred = ''\n    if list.index(preds.tolist(), max(preds)) == 0:\n        pred = \"Healthy\"\n    if list.index(preds.tolist(), max(preds)) == 1:\n        pred = \"Scab\"\n    if list.index(preds.tolist(), max(preds)) == 2:\n        pred = \"Rust\"\n    if list.index(preds.tolist(), max(preds)) == 3:\n        pred = \"Multiple diseases\"\n    colors[pred] = px.colors.qualitative.Plotly[1]\n    colors[\"Healthy\"] = \"seagreen\"\n    colors = [colors[val] for val in colors.keys()]\n    fig.add_trace(go.Image(z=cv2.resize(img, (205, 136))), row=1, col=1)\n    fig.add_trace(go.Bar(x=[\"Healthy\", \"Multiple diseases\", \"Rust\", \"Scab\"],\n                         y=preds, marker=dict(color=colors)), row=1, col=2)\n\n    fig.update_layout(height=400, width=800, title_text=\"DenseNet Predictions\",\n                      showlegend=False)\n    fig.show()\n\n\n# 显示前四幅图像预测结果\ndef display_four_examples(saved_model,train_data):\n    train_images = train_data[\"image_id\"][:4].progress_apply(load_image)\n    preds = model_predict(saved_model,train_images[2])\n    displayResult(train_images[2], preds)\n    preds = model_predict(saved_model,train_images[0])\n    displayResult(train_images[0], preds)\n    preds = model_predict(saved_model,train_images[3])\n    displayResult(train_images[3], preds)\n    preds = model_predict(saved_model,train_images[1])\n    displayResult(train_images[1], preds)\n\n\n# 对测试集做预测，保存预测结果\ndef test_dataset_predict(saved_model, test_dataset):\n    model = load_model(saved_model)\n    sub_path = \"/kaggle/input/plant-pathology-2020-fgvc7/sample_submission.csv\"\n    sub = pd.read_csv(sub_path)\n    probs_densenet = model.predict(test_dataset, verbose=1)\n    sub.loc[:, 'healthy':] = probs_densenet\n    sub.to_csv('submission_densenet.csv', index=False)\n    print(sub.head())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 数据集观察\ntrain_path = '/kaggle/input/plant-pathology-2020-fgvc7/train.csv'\ntest_path ='/kaggle/input/plant-pathology-2020-fgvc7/test.csv'\nimage_path = '/kaggle/input/plant-pathology-2020-fgvc7/images/'\nprint('观察训练集：')\ndata_observation(train_path, image_path, 3)\nprint('观察测试集：')\ndata_observation(test_path, image_path, 80)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 分类观察\nprint('=========healthy叶片观察===========')\ncategory_observation(train_path,image_path,cond=[1, 0, 0, 0], cond_cols=[\"healthy\"])\nprint('=========scab叶片观察=========')\ncategory_observation(train_path,image_path,cond=[0, 1, 0, 0], cond_cols=[\"scab\"])\nprint('=========rust叶片观察=========')\ncategory_observation(train_path,image_path,cond=[0, 0, 1, 0], cond_cols=[\"rust\"])\nprint('========= multiple_diseases叶片观察=========')\ncategory_observation(train_path,image_path,cond=[0, 0, 0, 1], cond_cols=[\"multiple_diseases\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 类别分布\ncategory_distribution(train_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 数据随机增强\ndata = pd.read_csv(train_path)\nimage = cv2.imread(image_path + data['image_id'][0] + '.jpg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\nimage_new = data_augmentation(image)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(8, 6))\nax[0].imshow(image)\nax[0].set_title('Original Image', fontsize=14)\nax[1].imshow(image_new)\nax[1].set_title('New Image', fontsize=14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 划分数据集\ntrain_dataset, valid_dataset, test_dataset=data_split(train_path,test_path)\nprint('完成数据集划分！')\nprint(valid_dataset)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with strategy.scope():\n    # 模型定义\n    train_data = pd.read_csv(train_path)\n    train_labels = np.float32(train_data.loc[:, 'healthy':'scab'].values)\n    batch_size=BATCH_SIZE\n    model = model_define(train_labels=train_labels,batch_size=batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 模型训练\nmodel_save_dir = 'models'\nif not os.path.exists(model_save_dir):\n    os.makedirs(model_save_dir)\nsaved_path = os.path.join(os.getcwd(), model_save_dir) + '/densenet121.h5' # 图片存放路径\nprint(saved_path)\nepochs = 20\nsteps_per_epoch =train_labels.shape[0] // BATCH_SIZE\n\nhistory = model_train(model,train_dataset,valid_dataset,epochs,steps_per_epoch,saved_path)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 模型评估\nmodel_estimate(history,epochs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 模型预测，显示前四幅图像预测结果\ndisplay_four_examples(saved_path,train_data)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# 对测试集做预测，保存预测结果\ntest_dataset_predict(saved_model=saved_path,test_dataset=test_dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# 2 MobileNetV2"},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\n程序：handle_model.py\n功能：建模过程\n设计：董相志，upsunny2008@163.com\n日期：2021.3.12\n\"\"\"\nimport numpy as np\nimport pandas as pd\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport cv2\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, GlobalAveragePooling2D,Dropout\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler,ModelCheckpoint\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import load_model\n\n# 模型定义\ndef mobile_model_define(train_labels, batch_size: int=BATCH_SIZE):\n    steps_per_epoch = train_labels.shape[0] // batch_size\n    model = Sequential(name='MyMobileNetV2')\n    mobile_net = MobileNetV2(include_top=False, weights='imagenet', input_shape=(512, 512, 3))   \n#     mobile_net.trainable = False\n    model.add(mobile_net)\n#     model.add(Conv2D(64,3,activation='relu'))\n#     model.add(Dropout(0.2))\n    model.add(GlobalAveragePooling2D())\n    model.add(Dense(train_labels.shape[1], activation='softmax'))\n    model.compile(optimizer=Adam(learning_rate=0.001),\n                  loss='categorical_crossentropy',\n                  metrics=['categorical_accuracy'])\n    model.summary()\n    return model\n\n#学习率调度函数\ndef mobile_build_lrfn(lr_start=0.00001, lr_max=0.00005, \n               lr_min=0.00001, lr_rampup_epochs=5, \n               lr_sustain_epochs=0, lr_exp_decay=.8):\n    lr_max = lr_max * strategy.num_replicas_in_sync\n\n    def lrfn(epoch):\n        if epoch < lr_rampup_epochs:\n            lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start\n        elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n            lr = lr_max\n        else:\n            lr = (lr_max - lr_min) *\\\n                 lr_exp_decay**(epoch - lr_rampup_epochs\\\n                                - lr_sustain_epochs) + lr_min\n        return lr\n    return lrfn\n\n\n# 模型训练\ndef mobile_model_train(model, train_dataset, valid_dataset, epochs, steps_per_epoch, saved_path):\n    # 定义回调函数：学习率调度\n    lrfn = build_lrfn(lr_sustain_epochs=2,lr_exp_decay=.9)\n    lr_schedule = LearningRateScheduler(lrfn, verbose=1)\n    # 定义回调函数：提前终止训练\n    early_stop = EarlyStopping(monitor='val_categorical_accuracy', min_delta=0, \n                               patience=10, verbose=1, restore_best_weights=True)\n    # 定义回调函数：保存最优模型\n    best_model = ModelCheckpoint(saved_path, monitor='val_categorical_accuracy', \n                                 verbose=1, save_best_only=True,\n                                 save_weights_only=False, mode='max')\n    history = model.fit(train_dataset,epochs=epochs,\n                        callbacks=[lr_schedule,best_model,early_stop],\n                        steps_per_epoch=steps_per_epoch,\n                        validation_data=valid_dataset)\n    return history\n\n\n# 模型评估\ndef mobile_model_estimate(history, epochs):\n    training = history.history['categorical_accuracy']\n    validation = history.history['val_categorical_accuracy']\n    ylabel = \"Accuracy\"\n    title = \"Accuracy vs. Epochs\"\n    fig = go.Figure()\n    fig.add_trace(\n        go.Scatter(x=np.arange(1, epochs + 1), mode='lines+markers', \n                   y=training, marker=dict(color=\"dodgerblue\"),\n                   name=\"Train\"))\n    fig.add_trace(\n        go.Scatter(x=np.arange(1, epochs + 1), mode='lines+markers', \n                   y=validation, marker=dict(color=\"darkorange\"),\n                   name=\"Val\"))\n    fig.update_layout(title_text=title, yaxis_title=ylabel, \n                      xaxis_title=\"Epochs\", width=500, height=300)\n    fig.show()\n\n\ndef mobile_load_image(image_id):\n    file_path = '/kaggle/input/plant-pathology-2020-fgvc7/images/' + image_id + \".jpg\"\n    image = cv2.imread(file_path)\n    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n\ndef mobile_process(img):\n    return cv2.resize(img / 255.0, (512, 512)).reshape(-1, 512, 512, 3)\n\n\n# 模型预测\ndef mobile_model_predict(saved_model, img):\n    model = load_model(saved_model)\n    preds = model.layers[2](model.layers[1](model.layers[0](mobile_process(img)))).numpy()[0]\n    return preds\n\n\n# 显示预测结果\ndef mobile_displayResult(img, preds):\n    fig = make_subplots(rows=1, cols=2)\n    colors = {\"Healthy\": px.colors.qualitative.Plotly[0], \"Scab\": px.colors.qualitative.Plotly[0],\n              \"Rust\": px.colors.qualitative.Plotly[0], \"Multiple diseases\": px.colors.qualitative.Plotly[0]}\n    pred = ''\n    if list.index(preds.tolist(), max(preds)) == 0:\n        pred = \"Healthy\"\n    if list.index(preds.tolist(), max(preds)) == 1:\n        pred = \"Scab\"\n    if list.index(preds.tolist(), max(preds)) == 2:\n        pred = \"Rust\"\n    if list.index(preds.tolist(), max(preds)) == 3:\n        pred = \"Multiple diseases\"\n    colors[pred] = px.colors.qualitative.Plotly[1]\n    colors[\"Healthy\"] = \"seagreen\"\n    colors = [colors[val] for val in colors.keys()]\n    fig.add_trace(go.Image(z=cv2.resize(img, (205, 136))), row=1, col=1)\n    fig.add_trace(go.Bar(x=[\"Healthy\", \"Multiple diseases\", \"Rust\", \"Scab\"],\n                         y=preds, marker=dict(color=colors)), row=1, col=2)\n\n    fig.update_layout(height=400, width=800, title_text=\"MobileNetV2 Predictions\",\n                      showlegend=False)\n    fig.show()\n\n\n# 显示前四幅图像预测结果\ndef mobile_display_four_examples(saved_model,train_data):\n    train_images = train_data[\"image_id\"][:4].progress_apply(mobile_load_image)\n    preds = mobile_model_predict(saved_model,train_images[2])\n    mobile_displayResult(train_images[2], preds)\n    preds = mobile_model_predict(saved_model,train_images[0])\n    mobile_displayResult(train_images[0], preds)\n    preds = mobile_model_predict(saved_model,train_images[3])\n    mobile_displayResult(train_images[3], preds)\n    preds = mobile_model_predict(saved_model,train_images[1])\n    mobile_displayResult(train_images[1], preds)\n\n\n# 对测试集做预测，保存预测结果\ndef mobile_test_dataset_predict(saved_model, test_dataset):\n    model = load_model(saved_model)\n    sub_path = \"/kaggle/input/plant-pathology-2020-fgvc7/sample_submission.csv\"\n    sub = pd.read_csv(sub_path)\n    probs_mobilenet = model.predict(test_dataset, verbose=1)\n    sub.loc[:, 'healthy':] = probs_mobilenet\n    sub.to_csv('submission_mobilenet.csv', index=False)\n    print(sub.head())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with strategy.scope():\n    # 模型定义\n    train_data = pd.read_csv(train_path)\n    train_labels = np.float32(train_data.loc[:, 'healthy':'scab'].values)\n    batch_size=BATCH_SIZE\n    model = mobile_model_define(train_labels=train_labels,batch_size=batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 模型训练\nmodel_save_dir = 'models'\nif not os.path.exists(model_save_dir):\n    os.makedirs(model_save_dir)\nsaved_path = os.path.join(os.getcwd(), model_save_dir) + '/mobilenetv2.h5' # 图片存放路径\nprint(saved_path)\nepochs = 20\nsteps_per_epoch =train_labels.shape[0] // BATCH_SIZE\n\nhistory = mobile_model_train(model,train_dataset,valid_dataset,epochs,steps_per_epoch,saved_path)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 模型评估\nmobile_model_estimate(history,epochs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 模型预测，显示前四幅图像预测结果\nmobile_display_four_examples(saved_path,train_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# 对测试集做预测，保存预测结果\nmobile_test_dataset_predict(saved_model=saved_path,test_dataset=test_dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}