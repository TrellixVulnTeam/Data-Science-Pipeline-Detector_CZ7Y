{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"traindf = pd.read_csv(\"/kaggle/input/plant-pathology-2020-fgvc7/train.csv\")\ntestdf = pd.read_csv(\"/kaggle/input/plant-pathology-2020-fgvc7/test.csv\")\nsubmissiondf = pd.read_csv(\"/kaggle/input/plant-pathology-2020-fgvc7/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traindf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(traindf['healthy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(traindf['rust'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(traindf['multiple_diseases'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(traindf['scab'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testdf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loading train images \nimport os\nimport cv2\nimport glob\nimg_size = 224\npath = \"/kaggle/input/plant-pathology-2020-fgvc7/images/\"\n\ntestimages = []\ntrainimages = []\n\nfor img in traindf['image_id']:\n    imgpath = os.path.join(path,img) + \".jpg\" \n    IMAGE = cv2.imread(imgpath)\n    IMAGE=cv2.resize(IMAGE,(img_size,img_size),interpolation=cv2.INTER_AREA)\n    trainimages.append(IMAGE)\n    \nfor img in testdf['image_id']:\n    imgpath = os.path.join(path,img) + \".jpg\"\n    IMAGE = cv2.imread(imgpath)\n    IMAGE=cv2.resize(IMAGE,(img_size,img_size),interpolation=cv2.INTER_AREA)\n    testimages.append(IMAGE)   \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(trainimages) , len(testimages)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(1,4,figsize=(15,15))\nfor i in range(4):\n    ax[i].imshow(trainimages[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(1,4,figsize=(15,15))\nfor i in range(4):\n    ax[i].imshow(testimages[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating X and Y data for training\n\nfrom keras.preprocessing.image import img_to_array\n\nX = np.ndarray(shape=(len(trainimages),img_size,img_size,3),dtype = np.float32)\ni = 0\nfor img in trainimages:\n    X[i] = img_to_array(img)\n    X[i] = trainimages[i]\n    i += 1\nX = X/255.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = traindf.drop(columns=['image_id']) # take rest 4 columns\ny = np.array(y.values)\ny","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape,y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# similary for final testing data\nX_for_testing = np.ndarray(shape=(len(testimages),img_size,img_size,3),dtype = np.float32)\ni = 0\nfor img in testimages:\n    X_for_testing[i] = img_to_array(img)\n    X_for_testing[i] = testimages[i]\n    i += 1\nX_for_testing = X_for_testing/255.0\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_for_testing.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# DATA SPLITSSSSS\nfrom sklearn.model_selection import train_test_split\n\nX_train,X_val,y_train,y_val = train_test_split(X,y,test_size=0.2,random_state=42)\n\nprint(X_train.shape,X_val.shape,y_train.shape,y_val.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# HANDLING UNEQUAL DATASET USING SMOTE \n\nfrom imblearn.over_sampling import SMOTE\n\nsmote = SMOTE(random_state=42)\n\nX_train,y_train = smote.fit_resample(X_train.reshape((-1,img_size*img_size*3)),y_train)\n\nX_train = X_train.reshape((-1,img_size,img_size,3))\n\nX_train.shape,y_train.shape,y_train.sum(axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape,X_val.shape,y_train.shape,y_val.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import preprocess_input\nfrom tensorflow import keras \nfrom tensorflow.keras.models import Model\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.regularizers import l1,l2\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import SGD, Adam, RMSprop, Adagrad, Nadam, Adadelta, Adamax\nfrom tensorflow.keras.layers import Dropout , BatchNormalization , Flatten , MaxPool2D,MaxPooling2D , Activation , Dense , Conv2D , InputLayer","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Image Data Augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(rotation_range=45,\n                             shear_range=.25,\n                              zoom_range=.25,\n                              width_shift_range=.25,\n                              height_shift_range=.25,\n                              rescale=1/255,\n                              brightness_range=[.5,1.5],\n                              horizontal_flip=True,\n                              vertical_flip=True,\n                              fill_mode='nearest')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# VGG16 MODEL"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import ReduceLROnPlateau\nfrom keras.callbacks import EarlyStopping\n\nIMAGE_SIZE = [224, 224]\nvgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\nfor layer in vgg.layers:\n  layer.trainable = False\nx = Flatten()(vgg.output)\nx = Dense(256, activation='relu')(x)\nprediction = Dense(4, activation='softmax')(x)\nmodel = Model(inputs=vgg.input, outputs=prediction)\nprint(model.summary())\nmodel.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n\nlr=ReduceLROnPlateau(monitor='val_accuracy',factor=.5,patience=10,min_lr=.000001,verbose=1)\nes=EarlyStopping(monitor='val_loss', patience=20)\ncallbacks = [lr,es]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 32\nepochs = 200\n\nvgghistory = model.fit_generator(datagen.flow(X_train,y_train,batch_size=batch_size),epochs=epochs,\n                                callbacks=callbacks,\n                                steps_per_epoch = X_train.shape[0]//batch_size,\n                                verbose=1,\n                                validation_data = datagen.flow(X_val,y_val,batch_size=batch_size),\n                                validation_steps = X_val.shape[0]//batch_size)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Lets try with custom model -\n\nI have used the model used in this notebook - https://www.kaggle.com/nightwolfbrooks/data-augmentation-and-keras-cnn\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"img_size=224\nreg = 0.0005\n\nmodel = Sequential()\n\nmodel.add(Conv2D(32, kernel_size=(5,5),activation='relu', input_shape=(img_size, img_size, 3), kernel_regularizer=l2(reg)))\nmodel.add(BatchNormalization(axis=-1,center=True,scale=False))\nmodel.add(Conv2D(128, kernel_size=(5,5),activation='relu', kernel_regularizer=l2(reg)))\nmodel.add(BatchNormalization(axis=-1,center=True,scale=False))\nmodel.add(MaxPooling2D(pool_size=(2,2), padding='SAME'))\nmodel.add(Dropout(.25))\n\nmodel.add(Conv2D(32, kernel_size=(3,3),activation='relu', kernel_regularizer=l2(reg)))\nmodel.add(BatchNormalization(axis=-1,center=True,scale=False))\nmodel.add(Conv2D(128, kernel_size=(3,3),activation='relu',kernel_regularizer=l2(reg)))\nmodel.add(BatchNormalization(axis=-1,center=True,scale=False))\nmodel.add(MaxPooling2D(pool_size=(2,2), padding='SAME'))\nmodel.add(Dropout(.25))\n\nmodel.add(Conv2D(128, kernel_size=(5,5),activation='relu', kernel_regularizer=l2(reg)))\nmodel.add(BatchNormalization(axis=-1,center=True,scale=False))\nmodel.add(Conv2D(512, kernel_size=(5,5),activation='relu',kernel_regularizer=l2(reg)))\nmodel.add(BatchNormalization(axis=-1,center=True,scale=False))\nmodel.add(MaxPooling2D(pool_size=(2,2), padding='SAME'))\nmodel.add(Dropout(.25))\n\nmodel.add(Conv2D(128, kernel_size=(3,3),activation='relu',kernel_regularizer=l2(reg)))\nmodel.add(BatchNormalization(axis=-1,center=True,scale=False))\nmodel.add(Conv2D(512, kernel_size=(3,3),activation='relu',kernel_regularizer=l2(reg)))\nmodel.add(BatchNormalization(axis=-1,center=True,scale=False))\nmodel.add(MaxPooling2D(pool_size=(2,2), padding='SAME'))\nmodel.add(Dropout(.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(300,activation='relu'))\nmodel.add(BatchNormalization(axis=-1,center=True,scale=False))\nmodel.add(Dropout(.25))\nmodel.add(Dense(200,activation='relu'))\nmodel.add(BatchNormalization(axis=-1,center=True,scale=False))\nmodel.add(Dropout(.25))\nmodel.add(Dense(100,activation='relu'))\nmodel.add(BatchNormalization(axis=-1,center=True,scale=False))\nmodel.add(Dropout(.25))\nmodel.add(Dense(4,activation='softmax'))\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import ReduceLROnPlateau\nfrom keras.callbacks import EarlyStopping\nbatch_size = 32\nepochs = 200\n\nmodel.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy']\n              )\n\nlr=ReduceLROnPlateau(monitor='val_accuracy',factor=.5,patience=10,min_lr=.000001,verbose=1)\nes=EarlyStopping(monitor='val_loss', patience=20)\ncallbacks = [lr,es]\n\nhistory = model.fit_generator(datagen.flow(X_train,y_train,batch_size=batch_size),epochs=epochs,\n                                callbacks=callbacks,\n                                steps_per_epoch = X_train.shape[0]//batch_size,\n                                verbose=1,\n                                validation_data = datagen.flow(X_val,y_val,batch_size=batch_size),\n                                validation_steps = X_val.shape[0]//batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\n\nhist = history.history\npx.line(\n    hist, x=range(1, len(hist['loss'])+1), y=['accuracy', 'val_accuracy'], \n    title='Model Accuracy', labels={'x': 'Epoch', 'value': 'Accuracy'}\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"px.line(\n    hist, x=range(1, len(hist['loss'])+1), y=['loss', 'val_loss'], \n    title='Model Loss', labels={'x': 'Epoch', 'value': 'Loss'}\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict(X_for_testing).argmax(axis=0)\npred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testids = testdf['image_id']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict(X_for_testing)\nprint(pred)\nres = pd.DataFrame()\nres['image_id'] = testids\nres['healthy'] = pred[:, 0]\nres['multiple_diseases'] = pred[:, 1]\nres['rust'] = pred[:, 2]\nres['scab'] = pred[:, 3]\nres.to_csv('submission.csv', index=False)\nres.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save(\"plantpathology.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}