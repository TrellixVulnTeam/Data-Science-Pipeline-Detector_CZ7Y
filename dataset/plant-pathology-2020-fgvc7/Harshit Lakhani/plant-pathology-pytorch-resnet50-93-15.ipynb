{"cells":[{"metadata":{},"cell_type":"markdown","source":"**<h2>Plant Pathology using PyTorch's Transfer Learning Framework</h2>**\n\n1. Importing helping hands \n2. Reading the files\n3. Analysis of the data\n4. Looking at some samples\n5. Split the data in train and validation split\n6. Preparing Imagedataset and transformations\n7. Training and validation function\n8. Fixing the hyperparameters for the model training\n9. Resnet18 pretrained from torchvision.models\n10. Crosentropyloss and Adam optimizer\n11. Ploting the training and validation accuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nimport os\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import figure, imshow, axis\nfrom matplotlib.image import imread\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom collections import OrderedDict\n\n\nimport cv2\nimport torch\nfrom torch import optim\nimport torchvision\nimport torch.nn as nn\nimport torch.utils.data as Data\nfrom torchvision import models,transforms\nimport time\n\n#changes\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"root = \"/kaggle/input/plant-pathology-2020-fgvc7/\"\ntrain = pd.read_csv(os.path.join(root,\"train.csv\"))\ntest = pd.read_csv(os.path.join(root,\"test.csv\"))\nsubmission = pd.read_csv(os.path.join(root,\"sample_submission.csv\"))\nimages = os.path.join(root,\"images\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**<h2>Data Analysis</h2>**\n\n* we have 1821 images for the training and testing each. \n* plants are divided in four categories => [ healthy | multiple_diseases | rust | scab ] \n* there are few plant samples with multiple_diseases"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"diseases = dict()\n\nfor column in [\"healthy\",\"multiple_diseases\",\"rust\",\"scab\"]:\n    counts = pd.DataFrame(train[column].value_counts())\n    diseases[column] = counts.iloc[1,0]\n    \n#bar chart to show different diseases    \nfig, (ax1, ax2) = plt.subplots(2, 1,figsize=(15,25))\nax1.bar(diseases.keys(),diseases.values(), color=[\"#6666ff\"])\nax1.set_title('Bar Chart', fontsize=18)\n\nax2.pie(diseases.values(),labels = diseases.keys(), colors=[\"#6666ff\",\"#4da6ff\",\"#1ac6ff\",\"#c44dff\"], autopct='%1.1f%%')\nax2.set_title('Pie Chart', fontsize=18)\nax2.axis('equal') \n\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**<h2>Let's look at the images</h2>**\nhere we have 4 images from each classes.\n\n**<span style=\"font-size:18px\">Rust</span>**\n\nThere are more than 5,000 known species of rust on plants. Common rust (Phragmidium spp.) is a fungal disease that attacks roses, hollyhocks, snapdragons, daylilies, beans, tomatoes and lawns. It is most often found on mature plants where symptoms appear primarily on the surfaces of lower leaves.Early on, look for white, slightly raised spots on the undersides of leaves and on the stems. After a short period of time, these spots become covered with reddish-orange spore masses. Later, leaf postules may turn yellow-green and eventually black. Severe infestations will deform and yellow leaves and cause leaf drop.\n(acknowledgement: www.planetnatural.com)\n\n**<span style=\"font-size:18px\">Scab</span>**\n\nA serious disease of apples and ornamental crabapples, apple scab (Venturia inaequalis) attacks both leaves and fruit. The fungal disease forms pale yellow or olive-green spots on the upper surface of leaves. Dark, velvety spots may appear on the lower surface. Severely infected leaves become twisted and puckered and may drop early in the summer.\nacknowledgement: www.planetnatural.com)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def ShowImages(images, typ):\n    fig = figure(figsize=(16,12))\n    number_of_images = len(images)\n    for i in range(number_of_images):\n        a=fig.add_subplot(1,number_of_images,i+1)\n        a.set_title(typ, fontsize = 10)\n        image = imread(os.path.join(root,\"images\",images[i]))\n        imshow(image)\n        axis('off')\n        \ncol=[\"healthy\",\"multiple_diseases\",\"rust\",\"scab\"]\nprint(\"Row's are in order of\", col)\n\nfor column in col:\n    images = (train[train[column].apply(lambda x: x == 1)][\"image_id\"].sample(4).values) + \".jpg\"\n    ShowImages(images, column)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**<h2>Train and Validation Split</h2>**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_path(image):\n    return os.path.join(root,\"images\",image + \".jpg\")\n\ntrain_data = train.copy()\ntrain_data[\"image_path\"] = train_data[\"image_id\"].apply(get_path)\ntrain_labels = train.loc[:, \"healthy\":\"scab\"]\n\ntest_data = test.copy()\ntest_data[\"image_path\"] = test_data[\"image_id\"].apply(get_path)\ntest_paths = test_data[\"image_path\"]\n\ntrain_paths, valid_paths, train_labels, valid_labels = train_test_split(train_data[\"image_path\"], train_labels, test_size = 0.2, random_state=23, stratify = train_labels)\n\ntrain_paths.reset_index(drop=True,inplace=True)\ntrain_labels.reset_index(drop=True,inplace=True)\nvalid_paths.reset_index(drop=True,inplace=True)\nvalid_labels.reset_index(drop=True,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**<h2>Datapreparation & Transformation function</h2>**"},{"metadata":{"trusted":true},"cell_type":"code","source":"mytransform = {\n    \"train\": A.Compose([\n    A.RandomResizedCrop(height=256, width=256, p=1.0),\n    A.Flip(),\n    A.ShiftScaleRotate(rotate_limit=1.0, p=0.8),\n    A.Normalize(p=1.0),\n    ToTensorV2(p=1.0),\n    ]),\n    \"validation\": A.Compose([\n    A.RandomResizedCrop(height=256, width=256, p=1.0),\n    A.Normalize(p=1.0),\n    ToTensorV2(p=1.0),\n    ]),\n}\n\n\nclass ImageDataset(Data.Dataset):\n    def __init__(self, images_path, labels = None , test=False, transform=None):\n        self.images_path = images_path\n        self.test = test\n        if self.test == False:\n            self.labels = labels\n            \n        self.images_transform = transform\n\n    def __getitem__(self, index):\n        if self.test == False:\n            labels = torch.tensor(np.argmax(self.labels.iloc[index, :]))\n        \n        image = cv2.imread(self.images_path[index])\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image_transformed = self.images_transform(image=image)\n        \n        if self.test ==False:\n            return image_transformed[\"image\"], labels\n        return image_transformed[\"image\"]\n\n    def __len__(self):\n        return self.images_path.shape[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**<h2>Training and validation function</h2>**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_function(model, loader):\n    \n    running_loss = 0\n    preds_for_acc = []\n    labels_for_acc = []\n    \n    progress = tqdm(loader, desc=\"Training\")\n    \n    for _, (images,labels) in enumerate(progress):\n        \n        images, labels = images.to(device), labels.to(device)\n        model.train()\n        \n        #optimizer\n        optimizer.zero_grad()\n        predictions = model(images)\n        loss = loss_function(predictions, labels)\n        loss.backward()\n        optimizer.step()\n\n\n        running_loss += loss.item()*labels.shape[0]\n        labels_for_acc = np.concatenate((labels_for_acc,labels.cpu().detach().numpy()), axis=0)\n        preds_for_acc = np.concatenate((preds_for_acc,np.argmax(predictions.cpu().detach().numpy(), axis=1)), axis=0)\n\n\n    accuracy = accuracy_score(labels_for_acc, preds_for_acc)\n\n    return running_loss/TRAIN_SIZE, accuracy\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def valid_function(model, loader):\n    running_loss = 0\n    preds_for_acc = []\n    labels_for_acc = []\n    \n    progress = tqdm(loader, desc=\"Validation\")\n    \n    for _, (images,labels) in enumerate(progress):\n        \n        images, labels = images.to(device), labels.to(device)\n        \n        \n        with torch.no_grad():\n            model.eval()\n            predictions = model(images)\n        loss = loss_function(predictions, labels)\n\n        running_loss += loss.item()*labels.shape[0]\n        labels_for_acc = np.concatenate((labels_for_acc,labels.cpu().detach().numpy()), axis=0)\n        preds_for_acc = np.concatenate((preds_for_acc,np.argmax(predictions.cpu().detach().numpy(), axis=1)), axis=0)\n\n\n    accuracy = accuracy_score(labels_for_acc, preds_for_acc)\n    conf_matrix = confusion_matrix(labels_for_acc, preds_for_acc)\n\n    return running_loss/VALID_SIZE, accuracy, conf_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 64 #4\nNUM_EPOCHS = 15 #10\ndevice = \"cuda\"\nTRAIN_SIZE = train_labels.shape[0]\nVALID_SIZE = valid_labels.shape[0]\nlearning_rate = 5e-5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images = ImageDataset(images_path=train_paths, labels=train_labels, transform=mytransform[\"train\"])\ntrain_loader = Data.DataLoader(train_images, shuffle=True, batch_size = BATCH_SIZE)\n\nvalid_images = ImageDataset(images_path=valid_paths, labels=valid_labels, transform=mytransform[\"validation\"])\nvalid_loader = Data.DataLoader(valid_images, shuffle=False, batch_size = BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**<h2>Resnet18, CrossEntropyLoss, Adam</h2>**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models.resnet50(pretrained = True)\n\n# Freeze training for all layers\nfor param in model.parameters():\n    param.require_grad = False\n\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Sequential(nn.Linear(num_ftrs,512,bias=True),\n                          nn.ReLU(),\n                          nn.Dropout(p=0.3),\n                          nn.Linear(512,4, bias = True))\n\nmodel.to(device)\nloss_function = torch.nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr = learning_rate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loss = []\nvalid_loss = []\ntrain_acc = []\nval_acc = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for epoch in range(NUM_EPOCHS):\n    \n    tl, ta = train_function(model, loader = train_loader)\n    vl, va, conf_mat = valid_function(model, loader = valid_loader)\n    train_loss.append(tl)\n    valid_loss.append(vl)\n    train_acc.append(ta)\n    val_acc.append(va)\n    \n    printstr = 'Epoch: '+ str(epoch) + ', Train loss: ' + str(tl) + ', Val loss: ' + str(vl) + ', Train acc: ' + str(ta) + ', Val acc: ' + str(va)\n    tqdm.write(printstr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.figure()\nplt.ylim(0,1.5)\nsns.lineplot(list(range(len(train_loss))), train_loss)\nsns.lineplot(list(range(len(valid_loss))), valid_loss)\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend(['Train','Val'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure()\nsns.lineplot(list(range(len(train_acc))), train_acc)\nsns.lineplot(list(range(len(val_acc))), val_acc)\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(['Train','Val'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**<h2>Submission</h2>**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def sigmoid(X):\n    return 1/(1+np.exp(-X))\n\ndef test_function(model, loader):\n    preds_for_output = np.zeros((1,4))\n    \n    progress = tqdm(loader, desc=\"Testing\")\n    with torch.no_grad():\n        for _, images in enumerate(progress):\n            images = images.to(device)\n            model.eval()\n            predictions = model(images)\n            preds_for_output = np.concatenate((preds_for_output, sigmoid(predictions.cpu().detach().numpy())), axis=0)\n        preds_for_output = np.delete(preds_for_output, 0, 0)\n    return preds_for_output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_images = ImageDataset(images_path=test_paths, test=True, transform=mytransform[\"validation\"])\ntest_loader = Data.DataLoader(test_images, shuffle=False, batch_size = BATCH_SIZE)\n\npredictions = test_function(model, test_loader)\n\nsubmission[[\"healthy\",\"multiple_diseases\",\"rust\",\"scab\"]]  = predictions\nsubmission.to_csv(\"submission_2.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**<h2>My Learning</h2>**\n\n1. I found that Albumentation gives better results than the torchvision.transforms.\n2. I had to use different combinations of hyperperameters to understand the behaviour of the model.\n3. Having a smaller batchsize and Adam as a optimizer shows drastic result improvement compare to bigger batchsize and SGD as a optimization technique.\n4. There are so many things one can try here, It's just a simple framework.\n\nI encourage you to fork on this notebook and apply different ideas on transfer learning.\n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}