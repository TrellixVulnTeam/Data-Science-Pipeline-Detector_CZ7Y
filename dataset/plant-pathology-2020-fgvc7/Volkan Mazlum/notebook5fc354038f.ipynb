{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-21T23:10:38.742188Z","iopub.execute_input":"2022-04-21T23:10:38.742783Z","iopub.status.idle":"2022-04-21T23:10:41.759088Z","shell.execute_reply.started":"2022-04-21T23:10:38.74266Z","shell.execute_reply":"2022-04-21T23:10:41.755849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport gc\nimport re\nimport cv2\nimport math\nimport numpy as np\nimport scipy as sp\nimport pandas as pd\n\nimport tensorflow as tf\nfrom IPython.display import SVG\n#from keras.utils import plot_model\nimport tensorflow.keras.layers as L\n#from keras.utils import model_to_dot\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.models import Model\nfrom kaggle_datasets import KaggleDatasets\n\nimport seaborn as sns\nfrom tqdm import tqdm\nimport matplotlib.cm as cm\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\n\ntqdm.pandas()\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\n\nnp.random.seed(0)\ntf.random.set_seed(0)\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2022-04-23T21:48:52.223259Z","iopub.execute_input":"2022-04-23T21:48:52.223686Z","iopub.status.idle":"2022-04-23T21:48:59.270625Z","shell.execute_reply.started":"2022-04-23T21:48:52.223578Z","shell.execute_reply":"2022-04-23T21:48:59.269579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**LOAD IMAGES**","metadata":{}},{"cell_type":"code","source":"\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten, Input, GlobalMaxPool2D\n\nimport matplotlib.pyplot as plt\n\nimport seaborn as sn\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.utils import class_weight","metadata":{"execution":{"iopub.status.busy":"2022-04-23T21:49:04.55897Z","iopub.execute_input":"2022-04-23T21:49:04.559872Z","iopub.status.idle":"2022-04-23T21:49:04.566073Z","shell.execute_reply.started":"2022-04-23T21:49:04.559831Z","shell.execute_reply":"2022-04-23T21:49:04.56492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#define parameters\nbatch_size = 32\nimg_height = 180\nimg_width = 180","metadata":{"execution":{"iopub.status.busy":"2022-04-23T21:49:10.204314Z","iopub.execute_input":"2022-04-23T21:49:10.204609Z","iopub.status.idle":"2022-04-23T21:49:10.209521Z","shell.execute_reply.started":"2022-04-23T21:49:10.204578Z","shell.execute_reply":"2022-04-23T21:49:10.208545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/plant-pathology-2020-fgvc7/train.csv\", index_col=0)\nprint(df.shape)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-23T21:49:11.496977Z","iopub.execute_input":"2022-04-23T21:49:11.498184Z","iopub.status.idle":"2022-04-23T21:49:11.527937Z","shell.execute_reply.started":"2022-04-23T21:49:11.498128Z","shell.execute_reply":"2022-04-23T21:49:11.527086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\nfrom shutil import copyfile\n\nif os.path.exists('temp'):\n    shutil.rmtree('temp')\n\nos.mkdir('temp')\nos.mkdir('temp/images')\nos.mkdir('temp/images/healthy')\nos.mkdir('temp/images/multiple_diseases')\nos.mkdir('temp/images/rust')\nos.mkdir('temp/images/scab')","metadata":{"execution":{"iopub.status.busy":"2022-04-23T21:49:14.739536Z","iopub.execute_input":"2022-04-23T21:49:14.740295Z","iopub.status.idle":"2022-04-23T21:49:14.87823Z","shell.execute_reply.started":"2022-04-23T21:49:14.740243Z","shell.execute_reply":"2022-04-23T21:49:14.877277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SOURCE = '../input/plant-pathology-2020-fgvc7/images'\n\nSPLIT_DIR = 'temp/images/'\n\n# copy images to train directory\nfor index, data in df.iterrows():\n    label = df.columns[np.argmax(data)]\n    filepath = os.path.join(SOURCE, index + \".jpg\")\n    destination = os.path.join(SPLIT_DIR, label, index + \".jpg\")\n    copyfile(filepath, destination)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-04-23T21:49:17.459209Z","iopub.execute_input":"2022-04-23T21:49:17.459681Z","iopub.status.idle":"2022-04-23T21:49:28.043461Z","shell.execute_reply.started":"2022-04-23T21:49:17.459641Z","shell.execute_reply":"2022-04-23T21:49:28.042377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create training data\ntrain_ds = tf.keras.utils.image_dataset_from_directory(\n    'temp/images',\n    validation_split=0.2,\n    subset=\"training\",\n    seed=123,\n    image_size=(img_height, img_width),\n    batch_size=batch_size,\n    label_mode='categorical'\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T21:49:28.210513Z","iopub.execute_input":"2022-04-23T21:49:28.210879Z","iopub.status.idle":"2022-04-23T21:49:28.346271Z","shell.execute_reply.started":"2022-04-23T21:49:28.210849Z","shell.execute_reply":"2022-04-23T21:49:28.345119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create validation data\nval_ds = tf.keras.utils.image_dataset_from_directory(\n    'temp/images',\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=123,\n    image_size=(img_height, img_width),\n    batch_size=batch_size,\n    label_mode='categorical'\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T21:49:28.348585Z","iopub.execute_input":"2022-04-23T21:49:28.348843Z","iopub.status.idle":"2022-04-23T21:49:28.481074Z","shell.execute_reply.started":"2022-04-23T21:49:28.348814Z","shell.execute_reply":"2022-04-23T21:49:28.480126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = train_ds.class_names\nnum_classes = len(class_names)\nprint(num_classes, class_names)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T21:49:28.482449Z","iopub.execute_input":"2022-04-23T21:49:28.482715Z","iopub.status.idle":"2022-04-23T21:49:28.488983Z","shell.execute_reply.started":"2022-04-23T21:49:28.48268Z","shell.execute_reply":"2022-04-23T21:49:28.488097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom tensorflow.keras.applications.densenet import DenseNet121, DenseNet169, DenseNet201 ","metadata":{"execution":{"iopub.status.busy":"2022-04-23T21:49:30.797216Z","iopub.execute_input":"2022-04-23T21:49:30.797511Z","iopub.status.idle":"2022-04-23T21:49:30.803796Z","shell.execute_reply.started":"2022-04-23T21:49:30.79748Z","shell.execute_reply":"2022-04-23T21:49:30.803099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import layers\n\ndata_augmentation = tf.keras.Sequential(\n  [\n    layers.RandomRotation(0.1),\n    layers.RandomZoom(0.1),\n    layers.ReLU(max_value=None, negative_slope=0.0, threshold=0.0),\n    layers.RandomFlip(\"horizontal\",input_shape=(img_height,img_width,3))\n  ]\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T21:49:32.342017Z","iopub.execute_input":"2022-04-23T21:49:32.342531Z","iopub.status.idle":"2022-04-23T21:49:32.367768Z","shell.execute_reply.started":"2022-04-23T21:49:32.342483Z","shell.execute_reply":"2022-04-23T21:49:32.367044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 10))\nfor images, _ in train_ds.take(1):\n    for i in range(9):\n        augmented_images = data_augmentation(images)\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(augmented_images[6].numpy().astype(\"uint8\"))\n        plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-04-23T21:49:37.304395Z","iopub.execute_input":"2022-04-23T21:49:37.304916Z","iopub.status.idle":"2022-04-23T21:49:40.35057Z","shell.execute_reply.started":"2022-04-23T21:49:37.304868Z","shell.execute_reply":"2022-04-23T21:49:40.349824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import SVG\n!pip install efficientnet\n","metadata":{"execution":{"iopub.status.busy":"2022-04-24T06:36:18.86414Z","iopub.execute_input":"2022-04-24T06:36:18.864505Z","iopub.status.idle":"2022-04-24T06:36:29.257621Z","shell.execute_reply.started":"2022-04-24T06:36:18.864468Z","shell.execute_reply":"2022-04-24T06:36:29.2566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import efficientnet.tfkeras as efn\nmodel = tf.keras.Sequential([data_augmentation,\n      layers.Rescaling(1./255),\n                             efn.EfficientNetB3(input_shape=(180, 180, 3),\n                                                    weights='imagenet',\n                                                    include_top=False),\n                                 L.GlobalAveragePooling2D(),\n                                 layers.BatchNormalization(),\n                                 L.Dense(4,\n                                         activation='softmax')])\n    \n    \n        \nearly_stopping = tf.keras.callbacks.EarlyStopping(patience=10,\n                                                  monitor=\"val_loss\",\n                                                  verbose=2,\n                                                  mode=\"auto\")\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(\"best.h5\", \n                                                monitor=\"val_loss\",\n                                                mode=\"auto\",\n                                                verbose=2,\n                                                save_best_only=True)\nmodel.compile(optimizer='adam',\n              loss = 'categorical_crossentropy',\n              metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2022-04-23T23:49:02.851097Z","iopub.execute_input":"2022-04-23T23:49:02.851408Z","iopub.status.idle":"2022-04-23T23:49:05.911059Z","shell.execute_reply.started":"2022-04-23T23:49:02.851377Z","shell.execute_reply":"2022-04-23T23:49:05.910002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 20\n\nhistory = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=epochs,\n    callbacks=[early_stopping,checkpoint]\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T23:49:21.414145Z","iopub.execute_input":"2022-04-23T23:49:21.414507Z","iopub.status.idle":"2022-04-23T23:50:03.734002Z","shell.execute_reply.started":"2022-04-23T23:49:21.414472Z","shell.execute_reply":"2022-04-23T23:50:03.73125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras_preprocessing import image\n\ntest_set = pd.read_csv(\"../input/plant-pathology-2020-fgvc7/test.csv\", index_col=0)\n\nX_test = []\nfor index, data in test_set.iterrows():\n    filepath = os.path.join(SOURCE, index + \".jpg\")\n    img = image.load_img(filepath, target_size=(img_height, img_width))\n    x = image.img_to_array(img)\n    x = np.expand_dims(x, axis=0)\n    X_test.append(x)\n    \nX_test = np.vstack(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T21:42:26.892991Z","iopub.execute_input":"2022-04-23T21:42:26.893339Z","iopub.status.idle":"2022-04-23T21:43:54.18388Z","shell.execute_reply.started":"2022-04-23T21:42:26.893297Z","shell.execute_reply":"2022-04-23T21:43:54.183013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 10))\nfor images, labels in train_ds.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(class_names[list(labels[i]).index(1)])\n        plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-04-23T21:43:54.186294Z","iopub.execute_input":"2022-04-23T21:43:54.186614Z","iopub.status.idle":"2022-04-23T21:43:57.230626Z","shell.execute_reply.started":"2022-04-23T21:43:54.186578Z","shell.execute_reply":"2022-04-23T21:43:57.22974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nfilepath = '../input/plant-pathology-2020-fgvc7/images/Test_1800.jpg'\nimg = image.load_img(filepath, target_size=(img_height, img_width))\nplt.imshow(img)\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\npredict = model.predict(x)\nscore = tf.nn.softmax(predict)\nprint(class_names)\nprint(np.array(score))","metadata":{"execution":{"iopub.status.busy":"2022-04-23T21:44:26.730436Z","iopub.execute_input":"2022-04-23T21:44:26.731185Z","iopub.status.idle":"2022-04-23T21:44:27.275218Z","shell.execute_reply.started":"2022-04-23T21:44:26.731146Z","shell.execute_reply":"2022-04-23T21:44:27.274292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = model.predict(X_test, batch_size= 10)\nscore = tf.nn.softmax(predictions)\nscore = np.array(score)\ndf_out = pd.concat([test_set.reset_index(), pd.DataFrame(score, columns = class_names)], axis=1).set_index(\"image_id\")\ndf_out.to_csv('submission.csv')\ndf_out.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-23T21:44:33.239324Z","iopub.execute_input":"2022-04-23T21:44:33.239595Z","iopub.status.idle":"2022-04-23T21:44:35.150854Z","shell.execute_reply.started":"2022-04-23T21:44:33.239565Z","shell.execute_reply":"2022-04-23T21:44:35.149773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Complete DenseNet 121 architecture**","metadata":{}}]}