{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1>Importing Libraries</h1>","metadata":{}},{"cell_type":"code","source":"import os\nimport gc\nimport re\n\nimport cv2\nimport math\nimport random\nimport numpy as np\nimport scipy as sp\nimport pandas as pd\n\nimport tensorflow as tf\nfrom IPython.display import SVG\nfrom keras.utils import plot_model\nimport tensorflow.keras.layers as L\nfrom keras.utils import model_to_dot\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.models import Model\nfrom kaggle_datasets import KaggleDatasets\nfrom tensorflow.keras.applications import DenseNet201, InceptionV3, ResNet50V2, InceptionResNetV2, VGG19, VGG16\n\nimport seaborn as sns\nfrom tqdm import tqdm\nimport matplotlib.cm as cm\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\n\ntqdm.pandas()\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\n\nnp.random.seed(0)\ntf.random.set_seed(0)\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\nimport cv2 as cv\nfrom skimage import filters\nfrom skimage import morphology\n\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport plotly.figure_factory as ff\nimport matplotlib.pyplot as plt\n\nfrom kaggle_datasets import KaggleDatasets\nimport tensorflow as tf\nprint(f\"Tensorflow version: {tf.__version__}\")\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import f1_score\n\nSEED = 5","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-25T13:34:32.021709Z","iopub.execute_input":"2021-05-25T13:34:32.022082Z","iopub.status.idle":"2021-05-25T13:34:32.036795Z","shell.execute_reply.started":"2021-05-25T13:34:32.022053Z","shell.execute_reply":"2021-05-25T13:34:32.03571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1>Loading data</h1>","metadata":{}},{"cell_type":"code","source":"EPOCHS = 40\nSAMPLE_LEN = 1821\nINPUT_PATH = '/kaggle/input/plant-pathology-2020-fgvc7/'\nIMG_PATH = INPUT_PATH + 'images/'\nTRAIN_DATA = INPUT_PATH + 'train.csv'\nTEST_DATA = INPUT_PATH + 'test.csv'\nSAMPLE_SUB = INPUT_PATH + 'sample_submission.csv'\n","metadata":{"execution":{"iopub.status.busy":"2021-05-25T13:51:59.546964Z","iopub.execute_input":"2021-05-25T13:51:59.547343Z","iopub.status.idle":"2021-05-25T13:51:59.553852Z","shell.execute_reply.started":"2021-05-25T13:51:59.547312Z","shell.execute_reply":"2021-05-25T13:51:59.552797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(TRAIN_DATA)\ntest_df = pd.read_csv(TEST_DATA)\nsampleSubmission_df = pd.read_csv(SAMPLE_SUB)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T13:34:49.332362Z","iopub.execute_input":"2021-05-25T13:34:49.332914Z","iopub.status.idle":"2021-05-25T13:34:49.390351Z","shell.execute_reply.started":"2021-05-25T13:34:49.332879Z","shell.execute_reply":"2021-05-25T13:34:49.389416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1>EDA</h1>","metadata":{}},{"cell_type":"code","source":"EDA_IMG_SHAPE = (512,256)\n\ndef getImage(image_id,SHAPE=EDA_IMG_SHAPE):\n    img = cv.imread(IMG_PATH + image_id + '.jpg')\n    img = cv.resize(img,SHAPE)\n    img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n    \n    return img","metadata":{"execution":{"iopub.status.busy":"2021-05-25T13:34:56.492299Z","iopub.execute_input":"2021-05-25T13:34:56.492825Z","iopub.status.idle":"2021-05-25T13:34:56.497213Z","shell.execute_reply.started":"2021-05-25T13:34:56.49279Z","shell.execute_reply":"2021-05-25T13:34:56.496415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nhealthy = [getImage(image_id) for image_id in train_df[train_df['healthy']==1].iloc[:,0]]\n\nmultiple_diseases = [getImage(image_id) for image_id in train_df[train_df['multiple_diseases']==1].iloc[:,0]]\n\nrust = [getImage(image_id) for image_id in train_df[train_df['rust']==1].iloc[:,0]]\n\nscab = [getImage(image_id) for image_id in train_df[train_df['scab']==1].iloc[:,0]]","metadata":{"execution":{"iopub.status.busy":"2021-05-25T13:35:00.670548Z","iopub.execute_input":"2021-05-25T13:35:00.671074Z","iopub.status.idle":"2021-05-25T13:36:39.826493Z","shell.execute_reply.started":"2021-05-25T13:35:00.671041Z","shell.execute_reply":"2021-05-25T13:36:39.825243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = {'healthy':healthy, 'multiple_diseases':multiple_diseases, 'rust':rust, 'scab': scab} ","metadata":{"execution":{"iopub.status.busy":"2021-05-25T13:36:39.828284Z","iopub.execute_input":"2021-05-25T13:36:39.828665Z","iopub.status.idle":"2021-05-25T13:36:39.833155Z","shell.execute_reply.started":"2021-05-25T13:36:39.828622Z","shell.execute_reply":"2021-05-25T13:36:39.832085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Exploratory Data Analysis","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plotlyDataFrame(df,title):\n    \n    fig = go.Figure(data=[go.Table(\n    header = dict(values = df.columns),\n    cells = dict(values = [df[col] for col in df.columns]))])\n    \n    fig.update_layout(\n        title = title)\n    \n    fig.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T13:36:39.835294Z","iopub.execute_input":"2021-05-25T13:36:39.835752Z","iopub.status.idle":"2021-05-25T13:36:39.848238Z","shell.execute_reply.started":"2021-05-25T13:36:39.835705Z","shell.execute_reply":"2021-05-25T13:36:39.847148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Train DataFrame","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plotlyDataFrame(train_df.iloc[:15,:],'Train Data')","metadata":{"execution":{"iopub.status.busy":"2021-05-25T13:36:39.850117Z","iopub.execute_input":"2021-05-25T13:36:39.850558Z","iopub.status.idle":"2021-05-25T13:36:39.935514Z","shell.execute_reply.started":"2021-05-25T13:36:39.85051Z","shell.execute_reply":"2021-05-25T13:36:39.934616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Test DataFrame","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plotlyDataFrame(test_df.iloc[:15,:],'Test Data')","metadata":{"execution":{"iopub.status.busy":"2021-05-25T13:36:39.936857Z","iopub.execute_input":"2021-05-25T13:36:39.937139Z","iopub.status.idle":"2021-05-25T13:36:39.94956Z","shell.execute_reply.started":"2021-05-25T13:36:39.937111Z","shell.execute_reply":"2021-05-25T13:36:39.948579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Sample Submission File\nplotlyDataFrame(sampleSubmission_df.iloc[:15,:], 'Sample Submission')","metadata":{"execution":{"iopub.status.busy":"2021-05-25T13:36:39.951017Z","iopub.execute_input":"2021-05-25T13:36:39.951301Z","iopub.status.idle":"2021-05-25T13:36:39.973129Z","shell.execute_reply.started":"2021-05-25T13:36:39.951273Z","shell.execute_reply":"2021-05-25T13:36:39.972147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>Class distributions</h2>","metadata":{}},{"cell_type":"code","source":"\n\nfig = go.Figure(data=[go.Pie(labels=train_df.columns[1:],\n                             values=[np.sum(train_df[col]) for col in train_df.columns[1:]])])\n\nfig.update_traces(hoverinfo='label+percent',\n                  textinfo='value',\n                  textfont_size=20,\n                  marker=dict(line=dict(color='#000000', width=2)))\n\nfig.update_layout(title_text=\"Target Distribution of Training-Data \")\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T13:36:39.974662Z","iopub.execute_input":"2021-05-25T13:36:39.974978Z","iopub.status.idle":"2021-05-25T13:36:40.023378Z","shell.execute_reply.started":"2021-05-25T13:36:39.974941Z","shell.execute_reply":"2021-05-25T13:36:40.022373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Image Augmentation\n#Image data augmentation is a technique that can be used to artificially expand the size of a training dataset by creating modified versions of images in the dataset.\n\n#Training deep learning neural network models on more data can result in more skillful models, and the augmentation techniques can create variations of the images that can improve the ability of the fit models to generalize what they have learned to new images.\n\n#Transforms include a range of operations from the field of image manipulation, such as shifts, flips, zooms, and much more.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Sample Image\n\ndef getRandomImage():\n    return random.choice(classes[random.choice(train_df.columns[2:])])","metadata":{"execution":{"iopub.status.busy":"2021-05-25T13:36:40.025409Z","iopub.execute_input":"2021-05-25T13:36:40.02573Z","iopub.status.idle":"2021-05-25T13:36:40.032228Z","shell.execute_reply.started":"2021-05-25T13:36:40.025699Z","shell.execute_reply":"2021-05-25T13:36:40.031153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = getRandomImage()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T13:36:40.033839Z","iopub.execute_input":"2021-05-25T13:36:40.034135Z","iopub.status.idle":"2021-05-25T13:36:40.044578Z","shell.execute_reply.started":"2021-05-25T13:36:40.034104Z","shell.execute_reply":"2021-05-25T13:36:40.043472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = go.Figure(go.Image(z=img))\n\nfig.update_layout(title_text=\"Smaple Image\")\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T13:36:40.045948Z","iopub.execute_input":"2021-05-25T13:36:40.046259Z","iopub.status.idle":"2021-05-25T13:36:40.50369Z","shell.execute_reply.started":"2021-05-25T13:36:40.046227Z","shell.execute_reply":"2021-05-25T13:36:40.502345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Image Augmentation With ImageDataGenerator\n#We can use this to generate augmented images using different transformations like:\n\n#Vertical Flipping\n#Horizontal Flipping\n#Shifted Images\n#Rotated Images\n#Zoomed Images\n#Images with different Brightness levels etc.\n#Plus point of using this is that it will generate images in runtime (While training a model). It means we are not supposed to store this augmented images.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = np.expand_dims(img,axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T13:36:40.505691Z","iopub.execute_input":"2021-05-25T13:36:40.506143Z","iopub.status.idle":"2021-05-25T13:36:40.51242Z","shell.execute_reply.started":"2021-05-25T13:36:40.506086Z","shell.execute_reply":"2021-05-25T13:36:40.510066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\ngenerator = tf.keras.preprocessing.image.ImageDataGenerator(vertical_flip=True,\n                                                            horizontal_flip=True,\n                                                            brightness_range=[0.5,1.5],\n                                                            zoom_range=[0.5,1.1])\n\niterator = generator.flow(img,batch_size=1)\n\n\n\nfig, ax = plt.subplots(nrows=5, ncols=3, figsize=(15,10))\n\nax[0,0].imshow(img[0])\nax[0,0].set_title(\"Sample Image\",fontsize=10)\nax[0,0].set_xticks([])\nax[0,0].set_yticks([])\n\n\nfor i in range(1,15):\n    \n    image = iterator.next()[0].astype('uint8')\n    \n    ax[i//3,i%3].imshow(image)\n    ax[i//3,i%3].set_xticks([])\n    ax[i//3,i%3].set_yticks([])\n\nfig.suptitle(\"Augmented Images of the sample image\",fontsize=20)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T13:36:40.514024Z","iopub.execute_input":"2021-05-25T13:36:40.514492Z","iopub.status.idle":"2021-05-25T13:36:42.015732Z","shell.execute_reply.started":"2021-05-25T13:36:40.514445Z","shell.execute_reply":"2021-05-25T13:36:42.014805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sampleImg = getRandomImage()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T13:36:42.016923Z","iopub.execute_input":"2021-05-25T13:36:42.017347Z","iopub.status.idle":"2021-05-25T13:36:42.020715Z","shell.execute_reply.started":"2021-05-25T13:36:42.017317Z","shell.execute_reply":"2021-05-25T13:36:42.019922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convertToHSV(img):\n    return cv.cvtColor(img,cv.COLOR_RGB2HSV_FULL)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T13:36:42.021813Z","iopub.execute_input":"2021-05-25T13:36:42.022198Z","iopub.status.idle":"2021-05-25T13:36:42.035486Z","shell.execute_reply.started":"2021-05-25T13:36:42.02217Z","shell.execute_reply":"2021-05-25T13:36:42.034104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ROI (Region Of Interest) Selection\n\n\n#To select the ROI, I have used Canny edge detection to detect the edges of the leaves \n#and to find the edges of the rectangle ROI, I have used this: getROI method.\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef getROI(img):\n    # convert the image to the gray-scale image\n    gray = cv.cvtColor(img,cv.COLOR_RGB2GRAY)\n    \n    # Detect the edges in the image using canny edge detection\n    edged = cv.Canny(gray,150,200)\n    \n    xm = img.shape[1]//2    # Middle coordinate of the x-axis (width of the image)\n    ym = img.shape[0]//2    # Middle coordinate of the y-axis (height of the image)\n    \n    # to find the bottom-y coordinate to the Rectangle-ROI\n    for i in range(img.shape[0]-1,-1,-1):\n        if np.sum(edged[i,xm-5:xm+5])!=0:\n            y_bottom = np.where(i+10<img.shape[0]-1,i+10,img.shape[0]-2)\n            break\n            \n    # to find the top-y coordinate to the Rectangle-ROI\n    for i in range(img.shape[0]):\n        if np.sum(edged[i,xm-5:xm+5])!=0:\n            y_top = np.where(i-10>1,i-10,2)\n            break\n    \n    # to find the top-x coordinate to the Rectangle-ROI\n    for i in range(img.shape[1]):\n        if np.sum(edged[ym-5:ym+5,i])!=0:\n            x_top = np.where(i-10>1,i-10,2)\n            break\n            \n    # to find the bottom-x coordinate to the Rectangle-ROI\n    for i in range(img.shape[1]-1,-1,-1):\n        if np.sum(edged[ym-5:ym+5,i])!=0:\n            x_bottom = np.where(i+10<img.shape[1]-1,i+10,img.shape[1]-2)\n            break\n\n    return edged,(x_top,y_top,x_bottom,y_bottom)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T13:36:42.036859Z","iopub.execute_input":"2021-05-25T13:36:42.037214Z","iopub.status.idle":"2021-05-25T13:36:42.050734Z","shell.execute_reply.started":"2021-05-25T13:36:42.037181Z","shell.execute_reply":"2021-05-25T13:36:42.049381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(nrows=3, ncols=3, figsize=(20, 13))\n\nfor i in range(3):\n    orignal = getRandomImage()\n    edged, coordinates = getROI(orignal)\n    \n    roi = orignal.copy()\n    \n    (x_top,y_top,x_bottom,y_bottom) = coordinates\n    \n    roi[y_top-2:y_top,x_top:x_bottom+1] = [255,0,0]        # Top-edge\n    roi[y_bottom:y_bottom+2,x_top:x_bottom+1] = [255,0,0]  # Bottom-edge\n    roi[y_top:y_bottom+1,x_top-2:x_top] = [255,0,0]        # Left-edge\n    roi[y_top:y_bottom+1,x_bottom:x_bottom+2] = [255,0,0]  # Right-edge\n    \n    ax[i,0].imshow(orignal)\n    ax[i,0].set_title('Original Image', fontsize=15)\n    ax[i,1].imshow(edged, cmap='gray')\n    ax[i,1].set_title('Detected Edges', fontsize=15)\n    ax[i,2].imshow(roi)\n    ax[i,2].set_title('ROI', fontsize=15)\n    \nfig.suptitle(\"ROI selection using Canny Edge Detection\",fontsize=20)\n    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T13:36:42.052Z","iopub.execute_input":"2021-05-25T13:36:42.052358Z","iopub.status.idle":"2021-05-25T13:36:43.614701Z","shell.execute_reply.started":"2021-05-25T13:36:42.052293Z","shell.execute_reply":"2021-05-25T13:36:43.613502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ROI selection using Watershed Transformation\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nfig, ax = plt.subplots(nrows=6, ncols=3, figsize=(15,15))\n\nfor i in range(3):\n    orignal = getRandomImage()\n#     blur = cv.bilateralFilter(orignal,9,75,75)\n    \n    gray = cv.cvtColor(orignal,cv.COLOR_RGB2GRAY)\n    sobel = filters.sobel(gray)\n\n    blurred = filters.gaussian(sobel, sigma=2.0)\n    \n    ym = blurred.shape[0]//2\n    xm = blurred.shape[1]//2\n    \n    markers = np.zeros(blurred.shape,dtype=np.int)\n    # using corners of the image as background\n    markers[0,0:2*xm] = 1\n    markers[2*ym-1,0:2*xm] = 1\n    markers[0:2*ym,0] = 1\n    markers[0:2*ym,2*xm-1] = 1\n    \n    # using middle part of the image as foreground\n    markers[ym-50:ym+50,xm-20:xm+20] = 2\n    \n    mask = morphology.watershed(blurred, markers)\n    \n    ax[0,i].imshow(orignal)\n    ax[0,i].set_title('Original Image', fontsize=12)\n    \n    ax[1,i].imshow(gray, cmap='gray')\n    ax[1,i].set_title('Gray Image', fontsize=12)\n    \n    ax[2,i].imshow(sobel, cmap='gray')\n    ax[2,i].set_title('After Sobel Filter', fontsize=12)\n    \n    ax[3,i].imshow(blurred, cmap='gray')\n    ax[3,i].set_title('Blurred Image', fontsize=12)\n    \n    ax[4,i].imshow(mask, cmap='gray')\n    ax[4,i].set_title('Mask', fontsize=12)\n    \n    orignal[mask==1,:] = [0,0,0]\n    \n    ax[5,i].imshow(orignal)\n    ax[5,i].set_title('Segmented Image', fontsize=12)\n    \n\nfor i in range(6):\n    for j in range(3):\n        ax[i,j].set_xticks([])\n        ax[i,j].set_yticks([])\n    \nfig.suptitle(\"Image Segmentation (ROI selection) using Watershed Transformation\",fontsize=20)\n    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T13:36:43.616855Z","iopub.execute_input":"2021-05-25T13:36:43.617258Z","iopub.status.idle":"2021-05-25T13:36:45.06414Z","shell.execute_reply.started":"2021-05-25T13:36:43.617215Z","shell.execute_reply":"2021-05-25T13:36:45.062859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#HSV Conversion\n\nfig, ax = plt.subplots(nrows=3, ncols=2, figsize=(10, 10))\n\nfor i in range(3):\n    orignal = getRandomImage()\n    hsv = convertToHSV(orignal)\n    \n    ax[i,0].imshow(orignal)\n    ax[i,0].set_title('Original Image', fontsize=15)\n    ax[i,1].imshow(hsv, cmap='gray')\n    ax[i,1].set_title('HSV Image', fontsize=15)\n    \nfig.suptitle(\"RGB to HSV Conversion\",fontsize=20)\n    \nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Gray Scale Conversion\nfig, ax = plt.subplots(nrows=3, ncols=2, figsize=(10, 10))\n\nfor i in range(3):\n    orignal = getRandomImage()\n    gray = cv.cvtColor(orignal,cv.COLOR_RGB2GRAY)\n    \n    ax[i,0].imshow(orignal)\n    ax[i,0].set_title('Original Image', fontsize=15)\n    ax[i,1].imshow(gray, cmap='gray')\n    ax[i,1].set_title('Gray Image', fontsize=15)\n    \nfig.suptitle(\"RGB to Gray Scale Conversion\",fontsize=20)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>Image Examples</h2>","metadata":{}},{"cell_type":"code","source":"#Function for showing image\ndef show_images(image_ids):\n    \n    col = 5\n    row = min(len(image_ids) // col, 5)\n    \n    fig, ax = plt.subplots(row, col, figsize=(16, 8))\n    ax = ax.flatten()\n\n    for i, image_id in enumerate(image_ids):\n        image = cv2.imread(IMAGE_PATH + '/{}.jpg'.format(image_id))\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        ax[i].set_axis_off()\n        ax[i].imshow(image)\n        ax[i].set_title(image_id)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T13:38:28.635483Z","iopub.execute_input":"2021-05-25T13:38:28.635878Z","iopub.status.idle":"2021-05-25T13:38:28.643598Z","shell.execute_reply.started":"2021-05-25T13:38:28.635844Z","shell.execute_reply":"2021-05-25T13:38:28.642648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3>Random samples</h3>","metadata":{}},{"cell_type":"markdown","source":"<h1>Setup TPU Config</h1>","metadata":{}},{"cell_type":"code","source":"AUTO = tf.data.experimental.AUTOTUNE\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\nstrategy = tf.distribute.experimental.TPUStrategy(tpu)\n\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync\nGCS_DS_PATH = KaggleDatasets().get_gcs_path()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T13:38:33.829026Z","iopub.execute_input":"2021-05-25T13:38:33.829393Z","iopub.status.idle":"2021-05-25T13:38:40.03224Z","shell.execute_reply.started":"2021-05-25T13:38:33.829343Z","shell.execute_reply":"2021-05-25T13:38:40.031151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1>Load labels and paths</h1>","metadata":{}},{"cell_type":"code","source":"sub = pd.read_csv(SAMPLE_SUB)\ntest_data = pd.read_csv(TEST_DATA)\ntrain_data = pd.read_csv(TRAIN_DATA)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T13:38:40.72335Z","iopub.execute_input":"2021-05-25T13:38:40.723737Z","iopub.status.idle":"2021-05-25T13:38:40.748851Z","shell.execute_reply.started":"2021-05-25T13:38:40.723698Z","shell.execute_reply":"2021-05-25T13:38:40.747847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def format_path(st):\n    return GCS_DS_PATH + '/images/' + st + '.jpg'\n\ntest_paths = test_data.image_id.apply(format_path).values\ntrain_paths = train_data.image_id.apply(format_path).values\n\ntrain_labels = np.float32(train_data.loc[:, 'healthy':'scab'].values)\ntrain_paths, valid_paths, train_labels, valid_labels =\\\ntrain_test_split(train_paths, train_labels, test_size=0.15, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T13:38:46.151817Z","iopub.execute_input":"2021-05-25T13:38:46.15236Z","iopub.status.idle":"2021-05-25T13:38:46.169212Z","shell.execute_reply.started":"2021-05-25T13:38:46.152324Z","shell.execute_reply":"2021-05-25T13:38:46.168095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def decode_image(filename, label=None, image_size=(512, 512)):\n    bits = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(bits, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0\n    image = tf.image.resize(image, image_size)\n    \n    if label is None:\n        return image\n    else:\n        return image, label\n\ndef data_augment(image, label=None): # Data augmentations\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    image = tf.image.random_saturation(image, 0.7, 1.3)\n    image = tf.image.random_contrast(image, 0.8, 1.2)\n    imgae = tf.image.random_brightness(image, 0.1)\n    \n    if label is None:\n        return image\n    else:\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2021-05-25T13:39:05.673943Z","iopub.execute_input":"2021-05-25T13:39:05.674363Z","iopub.status.idle":"2021-05-25T13:39:05.682967Z","shell.execute_reply.started":"2021-05-25T13:39:05.674328Z","shell.execute_reply":"2021-05-25T13:39:05.681697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1>Creating Dataset objects</h1>","metadata":{}},{"cell_type":"code","source":"train_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((train_paths, train_labels))\n    .map(decode_image, num_parallel_calls=AUTO)\n    .map(data_augment, num_parallel_calls=AUTO)\n    .repeat()\n    .shuffle(512)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTO)\n)\n\nvalid_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((valid_paths, valid_labels))\n    .map(decode_image, num_parallel_calls=AUTO)\n    .batch(BATCH_SIZE)\n    .cache()\n    .prefetch(AUTO)\n)\n\ntest_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices(test_paths)\n    .map(decode_image, num_parallel_calls=AUTO)\n    .batch(BATCH_SIZE)\n)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T13:52:20.704628Z","iopub.execute_input":"2021-05-25T13:52:20.705154Z","iopub.status.idle":"2021-05-25T13:52:20.804416Z","shell.execute_reply.started":"2021-05-25T13:52:20.70512Z","shell.execute_reply":"2021-05-25T13:52:20.803387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1>Defining Learning-Rate Scheduler</h1>","metadata":{}},{"cell_type":"code","source":"def build_lrfn(lr_start=0.00001, lr_max=0.00005, \n               lr_min=0.00001, lr_rampup_epochs=5, \n               lr_sustain_epochs=0, lr_exp_decay=.8):\n    lr_max = lr_max * strategy.num_replicas_in_sync\n\n    def lrfn(epoch):\n        if epoch < lr_rampup_epochs:\n            lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start\n        elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n            lr = lr_max\n        else:\n            lr = (lr_max - lr_min) *\\\n                 lr_exp_decay**(epoch - lr_rampup_epochs\\\n                                - lr_sustain_epochs) + lr_min\n        return lr\n    return lrfn","metadata":{"execution":{"iopub.status.busy":"2021-05-25T13:52:28.289132Z","iopub.execute_input":"2021-05-25T13:52:28.289802Z","iopub.status.idle":"2021-05-25T13:52:28.297615Z","shell.execute_reply.started":"2021-05-25T13:52:28.28975Z","shell.execute_reply":"2021-05-25T13:52:28.296704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1>Defining hyperparameters of fit</h1>","metadata":{}},{"cell_type":"code","source":"lrfn = build_lrfn()\nSTEPS_PER_EPOCH = train_labels.shape[0] // BATCH_SIZE\nlr_schedule = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T13:52:32.446221Z","iopub.execute_input":"2021-05-25T13:52:32.446584Z","iopub.status.idle":"2021-05-25T13:52:32.451698Z","shell.execute_reply.started":"2021-05-25T13:52:32.446553Z","shell.execute_reply":"2021-05-25T13:52:32.450474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1>Function for visualizing training and validation accuracy</h1>","metadata":{}},{"cell_type":"code","source":"def display_training_curves(training, validation, yaxis):\n    if yaxis == \"loss\":\n        ylabel = \"Loss\"\n        title = \"Loss vs. Epochs\"\n    else:\n        ylabel = \"Accuracy\"\n        title = \"Accuracy vs. Epochs\"\n        \n    fig = go.Figure()\n        \n    fig.add_trace(\n        go.Scatter(x=np.arange(1, EPOCHS+1), mode='lines+markers', y=training, marker=dict(color=\"dodgerblue\"),\n               name=\"Train\"))\n    \n    fig.add_trace(\n        go.Scatter(x=np.arange(1, EPOCHS+1), mode='lines+markers', y=validation, marker=dict(color=\"darkorange\"),\n               name=\"Val\"))\n    \n    fig.update_layout(title_text=title, yaxis_title=ylabel, xaxis_title=\"Epochs\", template=\"plotly_white\")\n    fig.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T13:52:36.81744Z","iopub.execute_input":"2021-05-25T13:52:36.81783Z","iopub.status.idle":"2021-05-25T13:52:36.825302Z","shell.execute_reply.started":"2021-05-25T13:52:36.817798Z","shell.execute_reply":"2021-05-25T13:52:36.824456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1>Modelling</h1>","metadata":{}},{"cell_type":"markdown","source":"<h2>1. DenseNet</h2>","metadata":{}},{"cell_type":"code","source":"#Setting the model to train in TPU\nwith strategy.scope():\n    model = tf.keras.Sequential([DenseNet201(input_shape=(512, 512, 3),\n                                             weights='imagenet',\n                                             include_top=False),\n                                 L.GlobalAveragePooling2D(),\n                                 L.Dense(train_labels.shape[1],\n                                         activation='softmax')])\n        \n    model.compile(optimizer='adam',\n                  loss = 'categorical_crossentropy',\n                  metrics=['categorical_accuracy'])\n    model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T13:38:10.642516Z","iopub.execute_input":"2021-05-25T13:38:10.642921Z","iopub.status.idle":"2021-05-25T13:38:10.677889Z","shell.execute_reply.started":"2021-05-25T13:38:10.642885Z","shell.execute_reply":"2021-05-25T13:38:10.676147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Fundamental Block\nSVG(tf.keras.utils.model_to_dot(Model(model.layers[0].input, model.layers[0].layers[13].output), dpi=70).create(prog='dot', format='svg'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Model Architecture\nSVG(tf.keras.utils.model_to_dot(model, dpi=70).create(prog='dot', format='svg'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Training\nhistory = model.fit(train_dataset,\n                    epochs=EPOCHS,\n                    callbacks=[lr_schedule],\n                    steps_per_epoch=STEPS_PER_EPOCH,\n                    validation_data=valid_dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Loss of the model is - \" , model.evaluate(valid_dataset)[1]*100, \"%\")\nprint(\"Accuracy of the model is - \" , model.evaluate(train_dataset)[1]*100 , \"%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('DenseNet.hdf5')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visualizing train and valid accuracy\ndisplay_training_curves(\n    history.history['categorical_accuracy'], \n    history.history['val_categorical_accuracy'], \n    'accuracy')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visualizing train and valid loss\ndisplay_training_curves(\n    history.history['loss'], \n    history.history['val_loss'], \n    'loss')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plotting training values\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\nacc = history.history['categorical_accuracy']\nval_acc = history.history['val_categorical_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\n\n#accuracy plot\nplt.plot(epochs, acc, color='blue', label='Training Accuracy')\nplt.plot(epochs, val_acc, color='red', label='Validation Accuracy')\nplt.title('Training and Validation Accuracy with DenseNet')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend()\n\nplt.figure()\n#loss plot\nplt.plot(epochs, loss, color='blue', label='Training Loss')\nplt.plot(epochs, val_loss, color='red', label='Validation Loss')\nplt.title('Training and Validation Loss with DenseNet')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Prediction\nprobs_dnn = model.predict(test_dataset, verbose=1)\nsub.loc[:, 'healthy':] = probs_dnn\nsub.to_csv('submission_densenet.csv', index=False)\nsub.head()\n\n#LB:0.96792","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt # plotting\nimport numpy as np # linear algebra\nimport os # accessing directory structure\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Distribution graphs (histogram/bar graph) of column data\ndef plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):\n    nunique = df.nunique()\n    df = df[[col for col in df if nunique[col] > 1 and nunique[col] < 50]] # For displaying purposes, pick columns that have between 1 and 50 unique values\n    nRow, nCol = df.shape\n    columnNames = list(df)\n    nGraphRow = (nCol + nGraphPerRow - 1) / nGraphPerRow\n    plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * nGraphRow), dpi = 80, facecolor = 'w', edgecolor = 'k')\n    for i in range(min(nCol, nGraphShown)):\n        plt.subplot(nGraphRow, nGraphPerRow, i + 1)\n        columnDf = df.iloc[:, i]\n        if (not np.issubdtype(type(columnDf.iloc[0]), np.number)):\n            valueCounts = columnDf.value_counts()\n            valueCounts.plot.bar()\n        else:\n            columnDf.hist()\n        plt.ylabel('counts')\n        plt.xticks(rotation = 90)\n        plt.title(f'{columnNames[i]} (column {i})')\n    plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Correlation matrix\ndef plotCorrelationMatrix(df, graphWidth):\n    filename = df.dataframeName\n    df = df.dropna('columns') # drop columns with NaN\n    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n    if df.shape[1] < 2:\n        print(f'No correlation plots shown: The number of non-NaN or constant columns ({df.shape[1]}) is less than 2')\n        return\n    corr = df.corr()\n    plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')\n    corrMat = plt.matshow(corr, fignum = 1)\n    plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n    plt.yticks(range(len(corr.columns)), corr.columns)\n    plt.gca().xaxis.tick_bottom()\n    plt.colorbar(corrMat)\n    plt.title(f'Correlation Matrix for {filename}', fontsize=15)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scatter and density plots\ndef plotScatterMatrix(df, plotSize, textSize):\n    df = df.select_dtypes(include =[np.number]) # keep only numerical columns\n    # Remove rows and columns that would lead to df being singular\n    df = df.dropna('columns')\n    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n    columnNames = list(df)\n    if len(columnNames) > 10: # reduce the number of columns for matrix inversion of kernel density plots\n        columnNames = columnNames[:10]\n    df = df[columnNames]\n    ax = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')\n    corrs = df.corr().values\n    for i, j in zip(*plt.np.triu_indices_from(ax, k = 1)):\n        ax[i, j].annotate('Corr. coef = %.3f' % corrs[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)\n    plt.suptitle('Scatter and Density Plot')\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nRowsRead = 1000 # specify 'None' if want to read whole file\n# submission.csv may have more rows in reality, but we are only loading/previewing the first 1000 rows\ndf1 = pd.read_csv('./submission_densenet.csv', delimiter=',', nrows = nRowsRead)\ndf1.dataframeName = 'submission_densenet.csv'\nnRow, nCol = df1.shape\nprint(f'There are {nRow} rows and {nCol} columns')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plotPerColumnDistribution(df1, 10, 5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plotCorrelationMatrix(df1, 8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plotScatterMatrix(df1, 12, 10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>2. InceptionV3</h2>","metadata":{}},{"cell_type":"code","source":"with strategy.scope():\n    model = tf.keras.Sequential([InceptionV3(input_shape=(512, 512, 3),\n                                             weights='imagenet',\n                                             include_top=False),\n                                 L.GlobalAveragePooling2D(),\n                                 L.Dense(train_labels.shape[1],\n                                         activation='softmax')])\n        \n    model.compile(optimizer='adam',\n                  loss = 'categorical_crossentropy',\n                  metrics=['categorical_accuracy'])\n    model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T13:52:51.222872Z","iopub.execute_input":"2021-05-25T13:52:51.223535Z","iopub.status.idle":"2021-05-25T13:53:08.489627Z","shell.execute_reply.started":"2021-05-25T13:52:51.223497Z","shell.execute_reply":"2021-05-25T13:53:08.488406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SVG(tf.keras.utils.model_to_dot(Model(model.layers[0].input, model.layers[0].layers[11].output), dpi=70).create(prog='dot', format='svg'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SVG(tf.keras.utils.model_to_dot(model, dpi=70).create(prog='dot', format='svg'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_dataset,\n                    epochs=EPOCHS,\n                    callbacks=[lr_schedule],\n                    steps_per_epoch=STEPS_PER_EPOCH,\n                    validation_data=valid_dataset)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T13:53:08.491429Z","iopub.execute_input":"2021-05-25T13:53:08.491897Z","iopub.status.idle":"2021-05-25T14:17:53.42406Z","shell.execute_reply.started":"2021-05-25T13:53:08.491848Z","shell.execute_reply":"2021-05-25T14:17:53.422747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Loss of the model is - \" , model.evaluate(valid_dataset)[1]*100, \"%\")\nprint(\"Accuracy of the model is - \" , model.evaluate(train_dataset)[1]*100 , \"%\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('InceptionV3.hdf5')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_training_curves(\n    history.history['categorical_accuracy'], \n    history.history['val_categorical_accuracy'], \n    'accuracy')","metadata":{"execution":{"iopub.status.busy":"2021-05-25T14:21:51.418058Z","iopub.execute_input":"2021-05-25T14:21:51.418472Z","iopub.status.idle":"2021-05-25T14:21:53.156689Z","shell.execute_reply.started":"2021-05-25T14:21:51.418437Z","shell.execute_reply":"2021-05-25T14:21:53.155632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visualizing train and valid loss\ndisplay_training_curves(\n    history.history['loss'], \n    history.history['val_loss'], \n    'loss')","metadata":{"execution":{"iopub.status.busy":"2021-05-25T14:21:57.437911Z","iopub.execute_input":"2021-05-25T14:21:57.438416Z","iopub.status.idle":"2021-05-25T14:21:57.475621Z","shell.execute_reply.started":"2021-05-25T14:21:57.438383Z","shell.execute_reply":"2021-05-25T14:21:57.474625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plotting training values\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\nacc = history.history['categorical_accuracy']\nval_acc = history.history['val_categorical_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\n\n#accuracy plot\nplt.plot(epochs, acc, color='blue', label='Training Accuracy')\nplt.plot(epochs, val_acc, color='red', label='Validation Accuracy')\nplt.title('Training and Validation Accuracy with InceptionV3')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend()\n\nplt.figure()\n#loss plot\nplt.plot(epochs, loss, color='blue', label='Training Loss')\nplt.plot(epochs, val_loss, color='red', label='Validation Loss')\nplt.title('Training and Validation Loss with InceptionV3')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T14:22:02.897418Z","iopub.execute_input":"2021-05-25T14:22:02.897778Z","iopub.status.idle":"2021-05-25T14:22:03.386882Z","shell.execute_reply.started":"2021-05-25T14:22:02.897745Z","shell.execute_reply":"2021-05-25T14:22:03.385867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(valid_dataset, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T15:05:27.664956Z","iopub.execute_input":"2021-05-25T15:05:27.665304Z","iopub.status.idle":"2021-05-25T15:05:29.465592Z","shell.execute_reply.started":"2021-05-25T15:05:27.665274Z","shell.execute_reply":"2021-05-25T15:05:29.464641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Test Accuracy: {probs_incepv3[1]*100}\")","metadata":{"execution":{"iopub.status.busy":"2021-05-25T15:04:44.018995Z","iopub.execute_input":"2021-05-25T15:04:44.019388Z","iopub.status.idle":"2021-05-25T15:04:44.025195Z","shell.execute_reply.started":"2021-05-25T15:04:44.019354Z","shell.execute_reply":"2021-05-25T15:04:44.024121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle","metadata":{"execution":{"iopub.status.busy":"2021-05-25T15:10:07.622231Z","iopub.execute_input":"2021-05-25T15:10:07.622598Z","iopub.status.idle":"2021-05-25T15:10:07.627797Z","shell.execute_reply.started":"2021-05-25T15:10:07.622567Z","shell.execute_reply":"2021-05-25T15:10:07.626689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# save the model to disk\nprint(\"[INFO] Saving model...\")\npickle.dump(model,open('InceptionV3_model.pkl', 'wb'))","metadata":{"execution":{"iopub.status.busy":"2021-05-25T15:10:10.629777Z","iopub.execute_input":"2021-05-25T15:10:10.630142Z","iopub.status.idle":"2021-05-25T15:10:10.666875Z","shell.execute_reply.started":"2021-05-25T15:10:10.630113Z","shell.execute_reply":"2021-05-25T15:10:10.665521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"probs_incepv3 = model.predict(test_dataset, verbose=1)\nsub.loc[:, 'healthy':] = probs_incepv3\nsub.to_csv('submission_incepv3.csv', index=False)\nsub.head()\n\n","metadata":{"execution":{"iopub.status.busy":"2021-05-25T14:22:10.694073Z","iopub.execute_input":"2021-05-25T14:22:10.694446Z","iopub.status.idle":"2021-05-25T14:23:22.946546Z","shell.execute_reply.started":"2021-05-25T14:22:10.694411Z","shell.execute_reply":"2021-05-25T14:23:22.945636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(test_dataset, verbose=1)\nprint(f\"Test Accuracy: {model.evaluate[1]*100}\")","metadata":{"execution":{"iopub.status.busy":"2021-05-25T15:06:07.58991Z","iopub.execute_input":"2021-05-25T15:06:07.590294Z","iopub.status.idle":"2021-05-25T15:06:55.802507Z","shell.execute_reply.started":"2021-05-25T15:06:07.590261Z","shell.execute_reply":"2021-05-25T15:06:55.800762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntest_predictions = model.predict(test_dataset)\nprint(f\"Test Accuracy: {test_predictions[1]*100}\")","metadata":{"execution":{"iopub.status.busy":"2021-05-25T14:54:38.0551Z","iopub.execute_input":"2021-05-25T14:54:38.055694Z","iopub.status.idle":"2021-05-25T14:55:26.864827Z","shell.execute_reply.started":"2021-05-25T14:54:38.055646Z","shell.execute_reply":"2021-05-25T14:55:26.863833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(nrows=5, ncols=2, figsize=(15, 18))\n\nfor i in range(5):\n    img_id = random.choice(np.arange(0,test_df.shape[0]))\n    test_image = getImage(test_df.image_id[img_id])\n    \n    ax[i,0].imshow(test_image)\n    ax[i,0].set_title(f'{test_df.image_id[img_id]}', fontsize=12)\n    ax[i,1].barh(y=train_df.columns[1:],width=test_predictions[img_id])\n    ax[i,1].set_title('Predictions', fontsize=12)\n    \nfig.suptitle(\"Test set Predictions\",fontsize=20)\n    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T14:26:16.515829Z","iopub.execute_input":"2021-05-25T14:26:16.516246Z","iopub.status.idle":"2021-05-25T14:26:18.652705Z","shell.execute_reply.started":"2021-05-25T14:26:16.516199Z","shell.execute_reply":"2021-05-25T14:26:18.651571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Test Accuracy: {scores[1]*100}\")","metadata":{"execution":{"iopub.status.busy":"2021-05-25T14:50:31.725531Z","iopub.execute_input":"2021-05-25T14:50:31.725924Z","iopub.status.idle":"2021-05-25T14:50:31.772926Z","shell.execute_reply.started":"2021-05-25T14:50:31.725891Z","shell.execute_reply":"2021-05-25T14:50:31.771468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>3. ResNet</h2>","metadata":{}},{"cell_type":"code","source":"with strategy.scope():\n    model = tf.keras.Sequential([ResNet50V2(input_shape=(512, 512, 3),\n                                             weights='imagenet',\n                                             include_top=False),\n                                 L.GlobalAveragePooling2D(),\n                                 L.Dense(train_labels.shape[1],\n                                         activation='softmax')])\n        \n    model.compile(optimizer='adam',\n                  loss = 'categorical_crossentropy',\n                  metrics=['categorical_accuracy'])\n    model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SVG(tf.keras.utils.model_to_dot(Model(model.layers[0].input, model.layers[0].layers[11].output), dpi=70).create(prog='dot', format='svg'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SVG(tf.keras.utils.model_to_dot(model, dpi=70).create(prog='dot', format='svg'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_dataset,\n                    epochs=EPOCHS,\n                    callbacks=[lr_schedule],\n                    steps_per_epoch=STEPS_PER_EPOCH,\n                    validation_data=valid_dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Loss of the model is - \" , model.evaluate(valid_dataset)[1]*100, \"%\")\nprint(\"Accuracy of the model is - \" , model.evaluate(train_dataset)[1]*100 , \"%\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('resnet50.hdf5')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_training_curves(\n    history.history['categorical_accuracy'], \n    history.history['val_categorical_accuracy'], \n    'accuracy')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visualizing train and valid loss\ndisplay_training_curves(\n    history.history['loss'], \n    history.history['val_loss'], \n    'loss')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plotting training values\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\nacc = history.history['categorical_accuracy']\nval_acc = history.history['val_categorical_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\n\n#accuracy plot\nplt.plot(epochs, acc, color='blue', label='Training Accuracy')\nplt.plot(epochs, val_acc, color='red', label='Validation Accuracy')\nplt.title('Training and Validation Accuracy with ResNet')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend()\n\nplt.figure()\n#loss plot\nplt.plot(epochs, loss, color='blue', label='Training Loss')\nplt.plot(epochs, val_loss, color='red', label='Validation Loss')\nplt.title('Training and Validation Loss with ResNet')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"probs_resnet = model.predict(test_dataset, verbose=1)\nsub.loc[:, 'healthy':] = probs_resnet\nsub.to_csv('submission_resnet.csv', index=False)\nsub.head()\n\n#LB:-0.94379","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nRowsRead = 1000 # specify 'None' if want to read whole file\n# submission.csv may have more rows in reality, but we are only loading/previewing the first 1000 rows\ndf1 = pd.read_csv('./submission_resnet.csv', delimiter=',', nrows = nRowsRead)\ndf1.dataframeName = 'submission_resnet.csv'\nnRow, nCol = df1.shape\nprint(f'There are {nRow} rows and {nCol} columns')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plotPerColumnDistribution(df1, 10, 5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plotCorrelationMatrix(df1, 8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plotScatterMatrix(df1, 12, 10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2>4. InceptionResNet</h2>","metadata":{}},{"cell_type":"code","source":"with strategy.scope():\n    model = tf.keras.Sequential([InceptionResNetV2(input_shape=(512, 512, 3),\n                                             weights='imagenet',\n                                             include_top=False),\n                                 L.GlobalAveragePooling2D(),\n                                 L.Dense(train_labels.shape[1],\n                                         activation='softmax')])\n        \n    model.compile(optimizer='adam',\n                  loss = 'categorical_crossentropy',\n                  metrics=['categorical_accuracy'])\n    model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SVG(tf.keras.utils.model_to_dot(Model(model.layers[0].input, model.layers[0].layers[11].output), dpi=70).create(prog='dot', format='svg'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SVG(tf.keras.utils.model_to_dot(model, dpi=70).create(prog='dot', format='svg'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_dataset,\n                    epochs=EPOCHS,\n                    callbacks=[lr_schedule],\n                    steps_per_epoch=STEPS_PER_EPOCH,\n                    validation_data=valid_dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Loss of the model is - \" , model.evaluate(valid_dataset)[1]*100, \"%\")\nprint(\"Accuracy of the model is - \" , model.evaluate(train_dataset)[1]*100 , \"%\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('InceptionResNet.hdf5')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_training_curves(\n    history.history['categorical_accuracy'], \n    history.history['val_categorical_accuracy'], \n    'accuracy')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visualizing train and valid loss\ndisplay_training_curves(\n    history.history['loss'], \n    history.history['val_loss'], \n    'loss')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plotting training values\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\nacc = history.history['categorical_accuracy']\nval_acc = history.history['val_categorical_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\n\n#accuracy plot\nplt.plot(epochs, acc, color='blue', label='Training Accuracy')\nplt.plot(epochs, val_acc, color='red', label='Validation Accuracy')\nplt.title('Training and Validation Accuracy with InceptionResNet')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend()\n\nplt.figure()\n#loss plot\nplt.plot(epochs, loss, color='blue', label='Training Loss')\nplt.plot(epochs, val_loss, color='red', label='Validation Loss')\nplt.title('Training and Validation Loss with InceptionResNet')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"probs_incepres = model.predict(test_dataset, verbose=1)\nsub.loc[:, 'healthy':] = probs_incepres\nsub.to_csv('submission_incepres.csv', index=False)\nsub.head()\n\n#LB:-0.96181","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nRowsRead = 1000 # specify 'None' if want to read whole file\n# submission.csv may have more rows in reality, but we are only loading/previewing the first 1000 rows\ndf1 = pd.read_csv('./submission_incepres.csv', delimiter=',', nrows = nRowsRead)\ndf1.dataframeName = 'submission_incepres.csv'\nnRow, nCol = df1.shape\nprint(f'There are {nRow} rows and {nCol} columns')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plotPerColumnDistribution(df1, 10, 5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plotCorrelationMatrix(df1, 8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plotScatterMatrix(df1, 12, 10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#5. VGG19","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    model = tf.keras.Sequential([VGG19(input_shape=(512, 512, 3),\n                                             weights='imagenet',\n                                             include_top=False),\n                                 L.GlobalAveragePooling2D(),\n                                 L.Dense(train_labels.shape[1],\n                                         activation='softmax')])\n        \n    model.compile(optimizer='adam',\n                  loss = 'categorical_crossentropy',\n                  metrics=['categorical_accuracy'])\n    model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SVG(tf.keras.utils.model_to_dot(Model(model.layers[0].input, model.layers[0].layers[11].output), dpi=70).create(prog='dot', format='svg'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SVG(tf.keras.utils.model_to_dot(model, dpi=70).create(prog='dot', format='svg'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_dataset,\n                    epochs=EPOCHS,\n                    callbacks=[lr_schedule],\n                    steps_per_epoch=STEPS_PER_EPOCH,\n                    validation_data=valid_dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Loss of the model is - \" , model.evaluate(valid_dataset)[1]*100, \"%\")\nprint(\"Accuracy of the model is - \" , model.evaluate(train_dataset)[1]*100 , \"%\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('VGG19.hdf5')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_training_curves(\n    history.history['categorical_accuracy'], \n    history.history['val_categorical_accuracy'], \n    'accuracy')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_training_curves(\n    history.history['loss'], \n    history.history['val_loss'], \n    'loss')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plotting training values\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\nacc = history.history['categorical_accuracy']\nval_acc = history.history['val_categorical_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\n\n#accuracy plot\nplt.plot(epochs, acc, color='blue', label='Training Accuracy')\nplt.plot(epochs, val_acc, color='red', label='Validation Accuracy')\nplt.title('Training and Validation Accuracy with VGG19')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend()\n\nplt.figure()\n#loss plot\nplt.plot(epochs, loss, color='blue', label='Training Loss')\nplt.plot(epochs, val_loss, color='red', label='Validation Loss')\nplt.title('Training and Validation Loss with VGG19')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"probs_incepres = model.predict(test_dataset, verbose=1)\nsub.loc[:, 'healthy':] = probs_incepres\nsub.to_csv('submission_vgg19.csv', index=False)\nsub.head()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nRowsRead = 1000 # specify 'None' if want to read whole file\n# submission.csv may have more rows in reality, but we are only loading/previewing the first 1000 rows\ndf1 = pd.read_csv('./submission_vgg19.csv', delimiter=',', nrows = nRowsRead)\ndf1.dataframeName = 'submission_vgg19.csv'\nnRow, nCol = df1.shape\nprint(f'There are {nRow} rows and {nCol} columns')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plotPerColumnDistribution(df1, 10, 5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plotCorrelationMatrix(df1, 8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plotScatterMatrix(df1, 12, 10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#6. VGG16","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    model = tf.keras.Sequential([VGG16(input_shape=(512, 512, 3),\n                                             weights='imagenet',\n                                             include_top=False),\n                                 L.GlobalAveragePooling2D(),\n                                 L.Dense(train_labels.shape[1],\n                                         activation='softmax')])\n        \n    model.compile(optimizer='adam',\n                  loss = 'categorical_crossentropy',\n                  metrics=['categorical_accuracy'])\n    model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SVG(tf.keras.utils.model_to_dot(Model(model.layers[0].input, model.layers[0].layers[11].output), dpi=70).create(prog='dot', format='svg'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SVG(tf.keras.utils.model_to_dot(model, dpi=70).create(prog='dot', format='svg'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_dataset,\n                    epochs=EPOCHS,\n                    callbacks=[lr_schedule],\n                    steps_per_epoch=STEPS_PER_EPOCH,\n                    validation_data=valid_dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Loss of the model is - \" , model.evaluate(valid_dataset)[1]*100, \"%\")\nprint(\"Accuracy of the model is - \" , model.evaluate(train_dataset)[1]*100 , \"%\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('VGG16.hdf5')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_training_curves(\n    history.history['categorical_accuracy'], \n    history.history['val_categorical_accuracy'], \n    'accuracy')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_training_curves(\n    history.history['loss'], \n    history.history['val_loss'], \n    'loss')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plotting training values\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\nacc = history.history['categorical_accuracy']\nval_acc = history.history['val_categorical_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\n\n#accuracy plot\nplt.plot(epochs, acc, color='blue', label='Training Accuracy')\nplt.plot(epochs, val_acc, color='red', label='Validation Accuracy')\nplt.title('Training and Validation Accuracy with VGG16')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend()\n\nplt.figure()\n#loss plot\nplt.plot(epochs, loss, color='blue', label='Training Loss')\nplt.plot(epochs, val_loss, color='red', label='Validation Loss')\nplt.title('Training and Validation Loss with VGG16')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"probs_incepres = model.predict(test_dataset, verbose=1)\nsub.loc[:, 'healthy':] = probs_incepres\nsub.to_csv('submission_vgg16.csv', index=False)\nsub.head()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nRowsRead = 1000 # specify 'None' if want to read whole file\n# submission.csv may have more rows in reality, but we are only loading/previewing the first 1000 rows\ndf1 = pd.read_csv('./submission_vgg16.csv', delimiter=',', nrows = nRowsRead)\ndf1.dataframeName = 'submission_vgg16.csv'\nnRow, nCol = df1.shape\nprint(f'There are {nRow} rows and {nCol} columns')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plotPerColumnDistribution(df1, 10, 5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plotCorrelationMatrix(df1, 8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plotScatterMatrix(df1, 12, 10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}