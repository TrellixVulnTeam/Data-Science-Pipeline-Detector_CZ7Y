{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1 align='center'> Xception ML models on Plant_Pathology_2020 - dataset </h1>","metadata":{}},{"cell_type":"markdown","source":"### **Importing required packages**","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"## Note: Run this code on GPU only","metadata":{}},{"cell_type":"code","source":"#Import Libraries\nimport pandas as pd\nimport numpy as np\nimport random\nimport matplotlib.pyplot as plt\n\nimport os\nfrom tqdm import tqdm # to get progress bars while running\nimport cv2\nfrom sklearn.utils import shuffle\n\nfrom tensorflow import keras\nimport tensorflow as tf\ntf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0], True)\ntf.compat.v1.disable_eager_execution()\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-03-28T04:05:57.185601Z","iopub.execute_input":"2022-03-28T04:05:57.185931Z","iopub.status.idle":"2022-03-28T04:06:02.74057Z","shell.execute_reply.started":"2022-03-28T04:05:57.18585Z","shell.execute_reply":"2022-03-28T04:06:02.739725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Data Loading and Pre-Processing**","metadata":{"papermill":{"duration":0.013404,"end_time":"2021-10-31T06:54:45.223928","exception":false,"start_time":"2021-10-31T06:54:45.210524","status":"completed"},"tags":[]}},{"cell_type":"code","source":"train_csv = '/kaggle/input/plant-pathology-2020-fgvc7/train.csv'\ntest_csv = '/kaggle/input/plant-pathology-2020-fgvc7/test.csv'\nimage_data = '/kaggle/input/plant-pathology-2020-fgvc7/images'","metadata":{"execution":{"iopub.status.busy":"2022-03-28T04:06:06.129625Z","iopub.execute_input":"2022-03-28T04:06:06.12989Z","iopub.status.idle":"2022-03-28T04:06:06.133402Z","shell.execute_reply.started":"2022-03-28T04:06:06.12986Z","shell.execute_reply":"2022-03-28T04:06:06.132674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# this CSV contains classition properties of the resp input images file names\ndata = pd.read_csv(train_csv, index_col=0)\n\n# CLASSES\nclass_names = list(data.columns)\nnp.save('class_names',class_names) # save array\nprint(class_names)\n\nprint(data.shape)\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-28T04:06:07.529462Z","iopub.execute_input":"2022-03-28T04:06:07.530498Z","iopub.status.idle":"2022-03-28T04:06:07.574586Z","shell.execute_reply.started":"2022-03-28T04:06:07.530449Z","shell.execute_reply":"2022-03-28T04:06:07.573858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# getClasses function is used to get the class value for our class key\ndef Class_Label(n):\n    '''Returns label no. if file_name is given and integer decoding'''\n    # given a file name - return interger name\n    if ((type(n)==str) and ('.' in n)):\n        row = data.loc[n.split('.')[0]]\n        for x,i in enumerate(class_names):\n            if (row[i] == 1): \n                return x\n    # given a class name - return interger label\n    elif ((type(n)==str) and (n in class_names)):\n        return class_names.index(n)\n    # given a integer label - return class name\n    elif (n in range(len(class_names))):\n        return class_names[n]\n    else:\n        return -1","metadata":{"execution":{"iopub.status.busy":"2022-03-28T04:06:08.699599Z","iopub.execute_input":"2022-03-28T04:06:08.700156Z","iopub.status.idle":"2022-03-28T04:06:08.707144Z","shell.execute_reply.started":"2022-03-28T04:06:08.700115Z","shell.execute_reply":"2022-03-28T04:06:08.706037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### *Primary preprocessing transformations*\n- Normalizing and standardizing the images.\n- Resizing of the images to 229x229. The Inception network input expects a 229x229 image. </br>\n`This will be implemented in CV2 as computation cost is individually very high implementing through numpy`","metadata":{}},{"cell_type":"code","source":"# We use the load data function to read our data folders and label each of the images with \n# folder name and append them to a list which is then converted to an array\n# labeled for supervised/unsupervised data flag\ndef Load_Data(folders, file_prefix, dim, labeled = True):\n    '''To import the dataset from the directories and preprocess them'''\n        \n    # final outputs:\n    images=[]\n    labels=[]\n    \n    # iterate through folders\n    for folder in folders:\n        \n        # iterate through each image in folder\n        for file in tqdm(os.listdir(folder)):   \n            \n            if (file.startswith(file_prefix)):\n                \n                # get pathname of each image\n                img_path = os.path.join(folder, file)\n               \n                # Open and pre-process it\n                image = cv2.imread(img_path)\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # so we are converting to RGB format\n                image = cv2.resize(image, (dim[0], dim[1])) # resizing\n                image = image/255 # normalization\n                #print(image.shape)\n                #print(image)\n                #print(\"\\n\\n\")\n                # Append the image and its corresponding label to the output\n                images.append(image)\n                if (labeled):\n                    label = Class_Label(file)\n                    labels.append(label)\n                \n    print(\"Folder-Loaded:\",folder,\"-->\",file_prefix,\"over.\")\n                \n    # Converting the data type of the list\n    images = np.array(images, dtype = 'float32') # images in float\n    labels = np.array(labels, dtype = 'int8') #labels in integer encoded\n    \n    if (labeled):\n        # Shuffling the order of data for better accuracy and a good data split\n        images,labels = shuffle(images,labels,random_state=random.randint(0, 10))\n        \n    if (labeled):\n        return images, labels\n    else:\n        return images","metadata":{"execution":{"iopub.status.busy":"2022-03-28T04:06:11.002235Z","iopub.execute_input":"2022-03-28T04:06:11.002697Z","iopub.status.idle":"2022-03-28T04:06:11.013424Z","shell.execute_reply.started":"2022-03-28T04:06:11.002659Z","shell.execute_reply":"2022-03-28T04:06:11.012646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Default Image Size for all data\nimage_size = (299,299)\n\n# Loading Data - Train-Test images\ntrain_images, train_labels = Load_Data([image_data], 'Train', image_size)\ntest_images = Load_Data([image_data], 'Test', image_size, False)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T04:06:12.339706Z","iopub.execute_input":"2022-03-28T04:06:12.340213Z","iopub.status.idle":"2022-03-28T04:09:04.893594Z","shell.execute_reply.started":"2022-03-28T04:06:12.340172Z","shell.execute_reply":"2022-03-28T04:09:04.892861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Data Visualization**","metadata":{}},{"cell_type":"code","source":"print(f'Shape of Test Data : {test_images.shape}')\nprint(f'Shape of Train Data : {train_images.shape}')\n\nfrom collections import Counter\nlabel_count = Counter(train_labels)\nprint(f' Labels and their count :\\n {label_count}')\n\nx = list(label_count.keys())\ny = list(label_count.values())\n\nfig = plt.figure(figsize = (10,5))\nplt.bar(x,y,color=['cyan','blue','magenta','maroon'],  edgecolor='black')\nplt.title('Labels vs Count')\nplt.xticks([0,1,2,3],class_names)\nplt.xlabel('Labels')\nplt.ylabel('Count')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-28T04:09:15.841243Z","iopub.execute_input":"2022-03-28T04:09:15.841506Z","iopub.status.idle":"2022-03-28T04:09:16.050543Z","shell.execute_reply.started":"2022-03-28T04:09:15.841476Z","shell.execute_reply":"2022-03-28T04:09:16.049816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dis_rand_exp(images, labels, x=4, y=5):\n    fig = plt.figure(figsize = (21,17))\n    fig.suptitle(\"Random Examples of Data-Set images\", fontsize=32)\n    for i in range(x*y):\n        plt.subplot(x,y,i+1)\n        plt.xticks([])\n        plt.yticks([])\n        rand = random.randint(0,len(images))\n        plt.imshow(images[rand], cmap='gray')\n        plt.xlabel(Class_Label(labels[rand]), fontsize=18)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-28T04:09:17.119611Z","iopub.execute_input":"2022-03-28T04:09:17.120057Z","iopub.status.idle":"2022-03-28T04:09:17.126138Z","shell.execute_reply.started":"2022-03-28T04:09:17.119961Z","shell.execute_reply":"2022-03-28T04:09:17.125361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from sklearn.model_selection import train_test_split\n#Spliting validation data from train data as test data is unclassified\n#train_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels, test_size=.15)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T04:09:18.277763Z","iopub.execute_input":"2022-03-28T04:09:18.27846Z","iopub.status.idle":"2022-03-28T04:09:18.281825Z","shell.execute_reply.started":"2022-03-28T04:09:18.278422Z","shell.execute_reply":"2022-03-28T04:09:18.280899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, y_train = train_images[:1000], train_labels[:1000]\nval_images, val_labels = train_images[1000:1400], train_labels[1000:1400]\ntst_images, tst_labels = train_images[1400:], train_labels[1400:]","metadata":{"execution":{"iopub.status.busy":"2022-03-28T04:09:18.999644Z","iopub.execute_input":"2022-03-28T04:09:19.000244Z","iopub.status.idle":"2022-03-28T04:09:19.005117Z","shell.execute_reply.started":"2022-03-28T04:09:19.000201Z","shell.execute_reply":"2022-03-28T04:09:19.004226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Training data size:\", x_train.shape)\nprint(\"Test data size:\", tst_images.shape)\nprint(\"Validation data size:\", val_images.shape)\nprint(\"\\nPloting Test Dataset\")\ndis_rand_exp(train_images, train_labels)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-03-28T04:09:20.029519Z","iopub.execute_input":"2022-03-28T04:09:20.029779Z","iopub.status.idle":"2022-03-28T04:09:21.597447Z","shell.execute_reply.started":"2022-03-28T04:09:20.02975Z","shell.execute_reply":"2022-03-28T04:09:21.596197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 align='center'> Deep Learning Models </h1>","metadata":{}},{"cell_type":"markdown","source":"## XCEPTION Classifier - Model Implementation","metadata":{}},{"cell_type":"markdown","source":"#### *Using Xception (Inbuilt)*\n- `weights='imagenet'` : Pre-trained ImageNet weights are loaded for transfer learning.\n- `include_top=False` : We do not include the fully-connected head with the softmax classifier. In other words, we chop off the head of the network.\n- `pooling='avg'` : avg means that global average pooling will be applied to the output of the last convolutional block, and thus the output of the model will be a 2D tensor.","metadata":{}},{"cell_type":"markdown","source":"#### *SPARSE-CATEGORICAL CROSS-ENTROPHY MODELING --> For Classification*\n- SGD (Stochastic gradient descent) --> Gradient descent is the preferred way to optimize neural networks and many other machine learning algorithms but is often used as a black box.\n- lr (learning Rate)","metadata":{}},{"cell_type":"code","source":"# For Classification (no.of features = no.of classes)\nmodel = keras.models.Sequential([\n    keras.applications.xception.Xception(include_top=False, weights='imagenet', pooling='avg', input_shape=(image_size[0],image_size[1],3)),\n    keras.layers.Flatten(),\n    keras.layers.Dropout(0.4),\n    keras.layers.Dense(1024),\n    keras.layers.LeakyReLU(alpha=0.05),\n    keras.layers.Dense(512),\n    keras.layers.LeakyReLU(alpha=0.05),\n    keras.layers.Dropout(0.2),\n    keras.layers.Dense(256, activation='relu'),\n    keras.layers.Dense(4, activation='softmax')\n])\n\n# Compling our Model\nmodel.compile(optimizer=tf.optimizers.SGD(lr=0.0075),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\nmodel._name=\"Xception_Classifier\"\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-28T04:09:38.895364Z","iopub.execute_input":"2022-03-28T04:09:38.895817Z","iopub.status.idle":"2022-03-28T04:09:48.844039Z","shell.execute_reply.started":"2022-03-28T04:09:38.895778Z","shell.execute_reply":"2022-03-28T04:09:48.843261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training and Results\n`tf.keras.backend.clear_session` --> If you are creating many models in a loop, this global state will consume an increasing amount of memory over time, and you may want to clear it. Calling clear_session() releases the global state: this helps avoid clutter from old models and layers, especially when memory is limited.","metadata":{}},{"cell_type":"code","source":"#Stop training when a monitored metric (here, accuracy) has stopped improving.\n#patience: Number of epochs with no improvement after which training will be stopped.\nearly_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=5)\n\n# Saving the best Trained model\nmodel_file = model.name+'_Model.h5'\ncheckpoint_cb = tf.keras.callbacks.ModelCheckpoint(model_file, save_best_only=True)\n\ntf.keras.backend.clear_session\nhistory = model.fit(x_train,\n                    y_train,\n                    epochs=15, # Max no.of epochs\n                    #steps_per_epoch=100,\n                    batch_size=16, # size for parallel computation, higher require more GPU/CPU-RAM\n                    validation_freq=1,\n                    validation_data=(val_images,val_labels),\n                    callbacks=[early_stopping_cb, checkpoint_cb]\n                   )","metadata":{"scrolled":true,"tags":[],"execution":{"iopub.status.busy":"2022-03-28T04:09:48.84578Z","iopub.execute_input":"2022-03-28T04:09:48.846062Z","iopub.status.idle":"2022-03-28T04:17:17.369212Z","shell.execute_reply.started":"2022-03-28T04:09:48.846026Z","shell.execute_reply":"2022-03-28T04:17:17.368345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_accuracy_and_loss_of_train_and_validation_dataset(history):\n    train_acc=history.history['accuracy']\n    train_loss=history.history['loss']\n    val_acc=history.history['val_accuracy']\n    val_loss=history.history['val_loss']\n    epoch=[i for i in range(len(train_acc))]\n    fig , ax=plt.subplots(1,2)\n    fig.set_size_inches(15,8)\n    ax[0].plot(epoch,train_acc,'co-',label='training accuracy')\n    ax[0].plot(epoch,val_acc,'mo-',label='validation accuracy')\n    ax[0].set_title('Training & Validation Accuracy')\n    ax[0].legend()\n    ax[0].set_xlabel(\"Epochs\")\n    ax[0].set_ylabel(\"Accuracy\")\n    ax[1].plot(epoch,train_loss,'c-o',label='training loss')\n    ax[1].plot(epoch,val_loss,'m-o',label='validation loss')\n    ax[1].set_title('Training & Validation loss')\n    ax[1].legend()\n    ax[1].set_xlabel(\"Epochs\")\n    ax[1].set_ylabel(\"Training & Validation Loss\")\n\n# incase of early stop\nplot_accuracy_and_loss_of_train_and_validation_dataset(history)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T04:32:21.340358Z","iopub.execute_input":"2022-03-28T04:32:21.340627Z","iopub.status.idle":"2022-03-28T04:32:21.722356Z","shell.execute_reply.started":"2022-03-28T04:32:21.340596Z","shell.execute_reply":"2022-03-28T04:32:21.721649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluation","metadata":{}},{"cell_type":"code","source":"# loading the saved model of Xception Classifier\nmodel_file = 'Xception_Classifier_Model.h5'\nmodel = keras.models.load_model(model_file) # rollback to best model\nloss,accuracy = model.evaluate(x_train,y_train)\nprint(\"The accuracy of train image is : \",accuracy)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T04:32:26.794379Z","iopub.execute_input":"2022-03-28T04:32:26.794647Z","iopub.status.idle":"2022-03-28T04:32:46.68812Z","shell.execute_reply.started":"2022-03-28T04:32:26.794615Z","shell.execute_reply":"2022-03-28T04:32:46.686677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Accuracy for each class","metadata":{}},{"cell_type":"code","source":"pred_Ids_of_test = model.predict(tst_images)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T04:32:58.274392Z","iopub.execute_input":"2022-03-28T04:32:58.274651Z","iopub.status.idle":"2022-03-28T04:33:02.326884Z","shell.execute_reply.started":"2022-03-28T04:32:58.274619Z","shell.execute_reply":"2022-03-28T04:33:02.326132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\npredIdxs = np.argmax(pred_Ids_of_test, axis=1) # to get the indices of max value in each row\nprint(classification_report(tst_labels, predIdxs,target_names=class_names))","metadata":{"execution":{"iopub.status.busy":"2022-03-28T04:33:15.414778Z","iopub.execute_input":"2022-03-28T04:33:15.415059Z","iopub.status.idle":"2022-03-28T04:33:15.483627Z","shell.execute_reply.started":"2022-03-28T04:33:15.415027Z","shell.execute_reply":"2022-03-28T04:33:15.482911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Confusion Matrix","metadata":{}},{"cell_type":"code","source":"CM = confusion_matrix(tst_labels, predIdxs)\n# Plot confusion matrix\nplt.figure(figsize = (5,5))\nplt.imshow(CM,interpolation='nearest',cmap='winter')\nfor (i, j), z in np.ndenumerate(CM):\n    plt.text(j, i, z, ha='center', va='center')\nplt.xlabel(\"y Predict\")\nplt.ylabel(\"y Test\")\nplt.grid(False)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-28T04:33:17.434532Z","iopub.execute_input":"2022-03-28T04:33:17.434778Z","iopub.status.idle":"2022-03-28T04:33:17.649454Z","shell.execute_reply.started":"2022-03-28T04:33:17.43475Z","shell.execute_reply":"2022-03-28T04:33:17.648763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### *Evaluating UNLABELED test data & and saving the output for comparing with ML-Classifiers*","metadata":{}},{"cell_type":"code","source":"test_set = pd.read_csv(test_csv) # Reading resp test-images file-names\ntest_pred = model.predict(test_images, batch_size=10)\ndf_pred = pd.concat([test_set, pd.DataFrame(test_pred, columns=class_names)], axis=1).set_index(\"image_id\")\ndf_pred.to_csv(\"/kaggle/working/xception_results.csv\") # saving prediction test-images in each class into a .csv file\nprint(df_pred.idxmax(axis=1))\ndf_pred","metadata":{"execution":{"iopub.status.busy":"2022-03-28T04:33:19.115302Z","iopub.execute_input":"2022-03-28T04:33:19.115566Z","iopub.status.idle":"2022-03-28T04:33:28.602697Z","shell.execute_reply.started":"2022-03-28T04:33:19.115535Z","shell.execute_reply":"2022-03-28T04:33:28.602035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating test labels for evaluating standard performance measures on upcoming ML classifiers\ndf_pred.columns = np.arange(len(df_pred.columns))\ntest_labels = np.array(df_pred.idxmax(axis=1),'int8')\nprint(\"Test-Labels:\",test_labels)\n\n#Saving Train-Test-Valid Datasets\nnp.savez_compressed('pre-processed-datasets',x_train,y_train,test_images,test_labels,val_images,val_labels)\n\nprint(\"\\nPloting Test Dataset\")\ndis_rand_exp(test_images, test_labels)","metadata":{"scrolled":true,"tags":[],"execution":{"iopub.status.busy":"2022-03-28T04:33:28.606605Z","iopub.execute_input":"2022-03-28T04:33:28.610123Z","iopub.status.idle":"2022-03-28T04:37:36.02168Z","shell.execute_reply.started":"2022-03-28T04:33:28.61008Z","shell.execute_reply":"2022-03-28T04:37:36.020947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1 align='center'>Transfer Learning into ML Classifiers</h1>","metadata":{}},{"cell_type":"markdown","source":"### Importing required packages","metadata":{}},{"cell_type":"code","source":"#Import Libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom tensorflow import keras\nimport tensorflow as tf\ntf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0], True)\ntf.compat.v1.disable_eager_execution()\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-03-28T04:37:36.023141Z","iopub.execute_input":"2022-03-28T04:37:36.023503Z","iopub.status.idle":"2022-03-28T04:37:36.032623Z","shell.execute_reply.started":"2022-03-28T04:37:36.023467Z","shell.execute_reply":"2022-03-28T04:37:36.032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## XCEPTION Feature Extractor - using Pre-Trained Classifier","metadata":{}},{"cell_type":"code","source":"# loading class-names\nclass_names = np.load('class_names.npy')\n\n# loading Pre-Processed Data-Sets\ntrain_images,train_labels,test_images,test_labels,val_images,val_labels = np.load('pre-processed-datasets.npz')\n\n# we no longer need validation data, so we combine it with train data\nwith np.load('pre-processed-datasets.npz') as data:\n    train_images = np.concatenate((data[train_images],data[val_images]),axis=0)\n    train_labels = np.concatenate((data[train_labels],data[val_labels]),axis=0)\n    test_images = data[test_images]\n    test_labels = data[test_labels]\nprint(\"Training data size:\", train_images.shape)\nprint(\"Test data size:\", test_images.shape)\n\n# loading the saved model of Inception Classifier\nmodel_file = 'Xception_Classifier_Model.h5'\nmodel = keras.models.load_model(model_file)\n\nprint(\"\\n\\nPrinting layers of Model -\",model.name,\":\")\nfor layer in model.layers:\n    print(layer)\n\nprint(\"\\nFeature extraction from the model:\")\nfeature_layer = model.get_layer('xception')\nprint(feature_layer)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T04:38:57.354677Z","iopub.execute_input":"2022-03-28T04:38:57.355481Z","iopub.status.idle":"2022-03-28T04:39:30.738991Z","shell.execute_reply.started":"2022-03-28T04:38:57.355437Z","shell.execute_reply":"2022-03-28T04:39:30.737279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### *Alternative method to create our own model upto feature-layer as model-output and re-train* </br> \nFor Sparse Feature extraction:</br>\n`feature_model = keras.applications.xception.Xception(include_top=False, weights='imagenet', pooling='avg', input_shape= image_size[0],image_size[1],3))`","metadata":{}},{"cell_type":"code","source":"feature_model = keras.Model(inputs = feature_layer.inputs, outputs = feature_layer.outputs)\nfeature_model._name=\"Xception_Feature_Extractor\"\n\n# Showing Xception Model Architecture\nprint(\"Xception Model Architecture\")\nkeras.utils.plot_model(feature_model,'Xception.png',show_shapes=True, show_layer_names=False, rankdir='TB', expand_nested=True, dpi=75)\n# rankdir='TB' -> top to bottom\n#feature_model.summary()","metadata":{"scrolled":true,"tags":[],"execution":{"iopub.status.busy":"2022-03-28T04:39:47.175062Z","iopub.execute_input":"2022-03-28T04:39:47.175856Z","iopub.status.idle":"2022-03-28T04:39:48.812674Z","shell.execute_reply.started":"2022-03-28T04:39:47.175806Z","shell.execute_reply":"2022-03-28T04:39:48.811627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Extracting the deep features of our Dataset**\n*(i.e., model **without** Fully-Connected-Layers[DNN] for Feature-Extracting))*","metadata":{}},{"cell_type":"code","source":"train_features = feature_model.predict(train_images)\ntest_features = feature_model.predict(test_images)\nprint(\"Training data size:\", train_features.shape)\nprint(\"Test data size:\", test_features.shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T04:40:15.195777Z","iopub.execute_input":"2022-03-28T04:40:15.196076Z","iopub.status.idle":"2022-03-28T04:40:35.532454Z","shell.execute_reply.started":"2022-03-28T04:40:15.196043Z","shell.execute_reply":"2022-03-28T04:40:35.531651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### *Searching for the best model*\nThese above features-data is given as inputs for ML-Classifiers and best out them is found","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\n\n\n# keep no.of classifiers even for plottinf purposes\nclassifiers = [LogisticRegression(), GaussianNB(), DecisionTreeClassifier(), KNeighborsClassifier(), SVC(kernel='linear')]","metadata":{"execution":{"iopub.status.busy":"2022-03-28T04:40:35.534014Z","iopub.execute_input":"2022-03-28T04:40:35.534263Z","iopub.status.idle":"2022-03-28T04:40:35.687361Z","shell.execute_reply.started":"2022-03-28T04:40:35.534229Z","shell.execute_reply":"2022-03-28T04:40:35.686609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### *Fitting and Ploting results*","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\nfig = plt.figure(figsize=(20,10))\nfig.tight_layout()\nnof_clsfrs = len(classifiers)\nAccuracies = {}\n\n\nfor i in range(nof_clsfrs):\n    tf.keras.backend.clear_session\n    classifier = classifiers[i]\n    plt.subplot(2,3,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    \n    print(f'\\n\\nClassifier: {str(classifier)}')\n    classifier.fit(train_features, train_labels)\n    test_pred = classifier.predict(test_features)\n    \n    acc = accuracy_score(test_labels,test_pred) *100\n    Accuracies[str(classifier)[0:20]+'...'] = acc\n    print(f'Accuracy  is {acc}%, Report:')\n    print(classification_report(test_labels, test_pred))\n    \n    plt.gca().set_title(str(classifier)[0:20]+'...')\n    CM = confusion_matrix(test_labels, test_pred)\n    plt.imshow(CM,interpolation='nearest',cmap='summer')\n    for (i, j), z in np.ndenumerate(CM):\n        plt.text(j, i, z, ha='center', va='center')\n    plt.xticks(np.arange(len(class_names)),class_names, fontsize=8)\n    plt.yticks(np.arange(len(class_names)))\n    plt.grid(False)\nplt.show()","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-03-28T04:40:35.688627Z","iopub.execute_input":"2022-03-28T04:40:35.688955Z","iopub.status.idle":"2022-03-28T04:40:40.862307Z","shell.execute_reply.started":"2022-03-28T04:40:35.688916Z","shell.execute_reply":"2022-03-28T04:40:40.861625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*`These standard performance measures of test_data in these ML models are compared based on the labels predicted by the Deep-Learning Xception-Classifier model, as test-labels are obtained from DL-model only`*","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nresult = pd.DataFrame({'Classifier':list(Accuracies.keys()),\n                 'Accuracy':list(Accuracies.values())})\nprint(\"Results:\")\nprint(result)\nprint(\"\\n\\nClassifier for which max Accuracy is obtained:\")\nprint(result.iloc[result[\"Accuracy\"].idxmax()])","metadata":{"execution":{"iopub.status.busy":"2022-03-28T04:40:46.695589Z","iopub.execute_input":"2022-03-28T04:40:46.695879Z","iopub.status.idle":"2022-03-28T04:40:46.708216Z","shell.execute_reply.started":"2022-03-28T04:40:46.695846Z","shell.execute_reply":"2022-03-28T04:40:46.707169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <div style=\"text-align: center\"> - - - - - Thank You - - - - - <div>","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}