{"cells":[{"metadata":{},"cell_type":"markdown","source":"Let's start importing all the libraries that we need:"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\nimport os\nfrom IPython.display import clear_output","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"How our data looks like?\n1. Read the data using pandas\n1. See the shape, the information that we have and the images\n1. Plot how many images we have for every class, is it balanced?\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/plant-pathology-2020-fgvc7/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Information in train.csv file: \", list(data.columns))\nprint(\"We have \" + str(data.shape[0]) + \" images for training process with \" + str(data.shape[1]-1) + \" classes\" )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We don't really need the \"image_id\" column, so let's drop it"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.pop(\"image_id\")\nprint(data.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see how many images we have for each class"},{"metadata":{"trusted":true},"cell_type":"code","source":"idx = {}\nc = {1:\"healty\", 2: \"multiple\", 3:\"rust\", 4:\"scab\"}\nd = {1:0, 2:0, 3:0, 4:0}\nlabels =  np.array((data))\nfor i in range(labels.shape[0]):\n    for j in range(1,labels.shape[1]+1):\n        if labels[i,j-1] == 1:\n            d[j] += 1\n            if j not in idx:\n                idx[j] = i\n\nfor key, value in d.items():\n    plt.bar(c[key], value)\nplt.ylabel(\"Quantity\")\nplt.xlabel(\"Classes\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see, we don't have many images with multiple diseases, therefore, our cnn may struggle with this specific class. Now let's see how the images look like:"},{"metadata":{"trusted":true},"cell_type":"code","source":"c = [\"Healthy\", \"Multiple Diseases\", \"Rust\", \"Scab\"]\ndirectory = \"../input/plant-pathology-2020-fgvc7/images\"\nhealthy = plt.imread(os.path.join(directory, \"Train_\"+str(idx[1])+\".jpg\"))\nMultiple = plt.imread(os.path.join(directory, \"Train_\"+str(idx[2])+\".jpg\"))\nRust = plt.imread(os.path.join(directory, \"Train_\"+str(idx[3])+\".jpg\"))\nScab = plt.imread(os.path.join(directory, \"Train_\"+str(idx[4])+\".jpg\"))\nimgs = np.array(([healthy, Multiple, Rust, Scab]))\n\nfig=plt.figure(figsize=(8, 8))\nrows = 2\ncolumns = 2\nfor i in range(1, 5):\n    fig.add_subplot(rows, columns, i)\n    plt.title(c[-i])\n    plt.imshow(imgs[-i,:,:,:])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ok, we've seen how our data looks like, now define a function that get a batch for the training and at the same time normalize them. "},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_batch(n,size, healthy, directory, number, k = \"Train\"):\n    # Used to get the batch for the training or testing dataset\n    # Arguments:\n    # n(int): ID of the image you will use from the dataset\n    # size(int): Batch size\n    # healthy(numpy.ndarray): Image taken from the dataset useful to know the shape of the dataset\n    # directory(string): Directory where you are reading the images\n    # number(int): number of images in your dataset\n    # k(string): Specify if you are taking the images from the Train dataset or the Test dataset\n    \n    if k == \"Train\":\n        if n + size > number:\n            imgs = np.zeros((number-n,healthy.shape[0], healthy.shape[1], healthy.shape[2]))\n            for h, i in enumerate(range(n,number)):\n                imgs[h,:,:,:] = plt.imread(directory+\"/Train_\"+str(i)+\".jpg\")\n        else:\n            imgs = np.zeros((size,healthy.shape[0], healthy.shape[1], healthy.shape[2]))\n            for h,i in enumerate(range(n,n+size)):\n                img = plt.imread(directory+\"/Train_\"+str(i)+\".jpg\")\n                if img.shape == healthy.shape:\n                  imgs[h,:,:,:] = img\n                else:\n                  img = np.rot90(img)\n                  imgs[h,:,:,:] = img\n        imgs /= 255.0\n    elif k == \"Test\":\n        if n + size > number:\n            imgs = np.zeros((number-n,healthy.shape[0], healthy.shape[1], healthy.shape[2]))\n            for h, i in enumerate(range(n,number)):\n                imgs[h,:,:,:] = plt.imread(directory+\"/Test_\"+str(i)+\".jpg\")\n        else:\n            for h,i in enumerate(range(n,n+size)):\n                imgs = np.zeros((size,healthy.shape[0], healthy.shape[1], healthy.shape[2]))\n                imgs[h,:,:,:] = plt.imread(directory+\"/Test_\"+str(i)+\".jpg\")\n        imgs /= 255.0\n    else:\n        print(\"Directory of Training or Testing images not well established\")\n    return imgs","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Because the images are too big, we are going to chunk the images making N patches of all the images and get our batch for the training. So we are going set random points in the images (set it as our central point for a single patch) and store it in a list. This will help us to reduce the amount of ram that we use."},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_patches(healthy, directory, batch_size = 10, number_images = 100, \n                number_patches = 5, size_patches = 128, k = \"Train\", ID= 1):\n    # Used to get the batch for the training or testing dataset\n    # Arguments:\n    # healthy(numpy.ndarray): Image taken from the dataset useful to know the shape of the dataset\n    # directory(string): Directory where you are reading the images\n    # batch_size(int): batch size\n    # number_images(int): number of images in your dataset\n    # number_patches(int): number of patches you will get for each readed image\n    # size_patches(int): size of the patch\n    # k(string): Specify if you are taking the images from the Train dataset or the Test dataset\n    imgs = get_batch(ID, batch_size, healthy, directory, number_images, k)\n    w = healthy.shape[1]\n    h = healthy.shape[0]\n    patches = np.zeros((imgs.shape[0]*number_patches, size_patches, size_patches, 3))\n    l = [] #List with our central points\n    x = w\n    y = h\n    while(len(l) < number_patches*2):\n        x = np.random.randint(0,w) #random point in the x axis\n        y = np.random.randint(0,h) #random point in the y axis\n        #We need to make sure that the size of the patches doesn't get out of the images shape\n        if w >= x+(size_patches/2) and x-(size_patches/2) >= 0 and h >= y+(size_patches/2) and y-(size_patches/2) >= 0:\n            l.append(x)\n            l.append(y)\n            \n    for i in range(0,imgs.shape[0]):\n        for k, j in enumerate(range(0,number_patches*2, 2)):\n            patches[k+(i*number_patches),:,:,:] = imgs[i,l[j+1]-int(size_patches/2):l[j+1]+int(size_patches/2), l[j]-int(size_patches/2):l[j]+int(size_patches/2),:]\n    return patches\n\n#The function give us N patches of the image that we get in the get_batch function\nbatch_size = 1\npatches = get_patches(healthy, directory, batch_size, labels.shape[0], 6, 600, ID=0)\nprint(patches.shape)\n#Let's visualize some patches\nfig=plt.figure(figsize=(8, 8))\nrows = 2\ncolumns = 3\nfor i in range(1, (rows*columns)+1):\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(patches[-i, :, :, :])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Also, let's define a function to evaluate our model."},{"metadata":{"trusted":true},"cell_type":"code","source":"def accuracy(batch_size, model, labels, healthy, directory, ID=1, verbose = False):\n    # Used to measure the accuracy of the model\n    # Arguments:\n    # batch_size(int): batch_size\n    # model(tf model class): convolutional neural network model\n    # labels(int): labels used for the training\n    # healthy(numpy.ndarray): Image taken from the dataset useful to know the shape of the dataset\n    # directory(string): Directory where you are reading the images\n    n_patches = 5 #Use odd numbers to get a favor democracy for each label\n    patches = get_patches(healthy, directory, batch_size = batch_size, number_images = labels.shape[0], \n                number_patches = n_patches, size_patches = 256, k = \"Train\", ID=ID)\n\n    n = np.random.randint(0,labels.shape[0]-batch_size)\n\n    l = np.zeros((batch_size, 1))\n\n\n    for i in range(ID, batch_size):\n      l[i] = tf.argmax(labels[i,:])\n\n    #print(labels[ID:ID+batch_size, :])\n    predictions = model(patches)\n    acc = 0\n    Result = np.zeros((n_patches))\n    for i in range(0, batch_size):\n        for k in range(n_patches):\n            Result[k] = int(tf.argmax(predictions[(i*n_patches)+k]))\n\n        counts = np.bincount(Result.astype(\"int32\"))\n        R = np.argmax(counts)\n\n        if verbose == True:\n          print(\"Predicted value: \" + str(R) + \" Real value: \" + str(l[i]))\n        \n        if R == l[i]:\n            acc += 1\n    acc /= batch_size\n    return acc","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It's time to define our cnn:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_cnn():\n    model = tf.keras.models.Sequential()\n    model.add(tf.keras.layers.Conv2D(24,(3,3), activation=\"relu\"))\n    model.add(tf.keras.layers.MaxPool2D())\n    model.add(tf.keras.layers.Conv2D(64,(3,3), activation=\"relu\"))\n    model.add(tf.keras.layers.MaxPool2D())\n    model.add(tf.keras.layers.Conv2D(128,(3,3), activation=\"relu\"))\n    model.add(tf.keras.layers.MaxPool2D())\n    model.add(tf.keras.layers.Flatten())\n    model.add(tf.keras.layers.Dense(128, activation=\"relu\"))\n    model.add(tf.keras.layers.Dropout(0.25))\n    model.add(tf.keras.layers.Dense(64, activation=\"relu\"))\n    model.add(tf.keras.layers.Dense(4, activation=\"softmax\"))\n    return model\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ok, let's get our model instance and prepare the optimizer"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = build_cnn()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = tf.keras.optimizers.Adam()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Training time!!!! Let's use a batch size of 128 and 100 epochs"},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 25\nacc_batch = 7\nepochs = 2\nn_patches = 10\nhistory = []\nx = list(range(100+int(epochs*(labels.shape[0]/batch_size))))\n\nfor i in range(epochs):\n    for j in range(0, labels.shape[0], batch_size):\n        #images_b = get_batch(j, batch_size, healthy, directory, labels.shape[0])\n        images_b = get_patches(healthy, directory, batch_size, labels.shape[0], n_patches, 256, ID=j)\n        if j+batch_size > labels.shape[0]:\n          labels_b = labels[j:]\n          l = np.zeros(((labels_b.shape[0]*n_patches,1))) #We have to put a label on each patch and since is the same label for the next n_patches then we just make it bigger\n        else:\n          labels_b = labels[j:j+batch_size]\n          l = np.zeros(((batch_size*n_patches,1)))\n        for e in range(labels_b.shape[0]):\n            l[e*(n_patches):(e*(n_patches))+n_patches] = tf.argmax(labels_b[e,:])\n        with tf.GradientTape() as tape:\n            predictions = model(images_b)\n            loss = tf.keras.losses.sparse_categorical_crossentropy(l, predictions)\n        grads = tape.gradient(loss, model.trainable_variables)\n        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n        ID_T = np.random.randint(0,1820-acc_batch)\n        history.append(accuracy(batch_size = acc_batch, model = model, labels = labels, healthy = healthy, directory = directory, ID = ID_T, verbose = False))\n        plt.plot(x[:len(history)], history)\n        plt.xlabel(\"step\")\n        plt.ylabel(\"accuracy\")\n        plt.show()\n        clear_output(wait=True)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}