{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/train.csv')\n# df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df=pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/test.csv')\n# test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df['image_id']=df['image_id']+\".jpg\"\n# test_df['image_id']=test_df['image_id']+\".jpg\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torchvision.models as models\nfrom PIL import Image\nimport torchvision.transforms as transforms\nimport os\nfrom torchvision import datasets\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES = True\nfrom torch.utils.data import Dataset, DataLoader\nimport cv2                \nfrom PIL import Image\nfrom sklearn.metrics import accuracy_score\nfrom albumentations import *\nfrom albumentations.pytorch import ToTensor\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install --upgrade efficientnet-pytorch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from efficientnet_pytorch import EfficientNet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n# train_df,valid_df=train_test_split(df,test_size=0.2,shuffle=True,random_state=23,stratify=df.iloc[:,1:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df=df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.reset_index(drop=True,inplace=True)\n# valid_df.reset_index(drop=True,inplace=True)\ntest_df.reset_index(drop=True,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self,df,root_dir,transform=None,iftest=False):\n        self.df=df\n        self.root_dir=root_dir\n        self.transform=transform\n        self.iftest=iftest\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self,idx):\n        if torch.is_tensor(idx):\n            idx=idx.tolist()\n        img_name=self.root_dir+self.df.iloc[idx,0]+'.jpg'\n#         print(img_name)\n        image= cv2.imread(img_name,cv2.IMREAD_COLOR)\n#         image= cv2.imread(img_name)\n#         print(img_name,image)\n        image= cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n#         image = Image.fromarray(image)\n#         print(type(image))\n        if self.transform:\n            image=self.transform(image=image)['image']\n        if self.iftest:\n            return image\n        labels=torch.tensor(np.argmax(self.df.iloc[idx,1:].values))\n#         labels=np.asarray(labels)\n#         labels=torch.from_numpy(labels.astype(np.int32))\n#         labels=labels.unsqueeze(-1)\n#         print(labels.shape)\n#         sample={'image':image,'labels':labels}\n        return (image,labels)\n        \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMSIZE=545\nIMSIZE=EfficientNet.get_image_size('efficientnet-b5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(IMSIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset=CustomDataset(df=train_df,root_dir='/kaggle/input/plant-pathology-2020-fgvc7/images/',\n                     transform=Compose([augmentations.transforms.Resize(height=IMSIZE,width=IMSIZE,always_apply=True),\n                                                  HorizontalFlip(p=0.5),\n                                                  VerticalFlip(p=0.5),\n                                                  ShiftScaleRotate(rotate_limit=25.0,p=0.7),\n                                                  OneOf([IAAEmboss(p=1),IAASharpen(p=1),Blur(p=1)],p=0.5),\n                                                  IAAPiecewiseAffine(p=0.5),\n                                                   Normalize((0.485,0.456,0.406),\n                                                                      (0.229,0.224,0.225),always_apply=True),\n                                                  ToTensor()\n                                                  ]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# valid_dataset=CustomDataset(df=valid_df,root_dir='/kaggle/input/plant-pathology-2020-fgvc7/images/',\n#                      transform=Compose([augmentations.transforms.Resize(height=IMSIZE,width=IMSIZE,always_apply=True),\n#                                                    Normalize((0.485,0.456,0.406),\n#                                                                       (0.229,0.224,0.225),always_apply=True),\n#                                                     ToTensor()\n#                                                   ]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataset=CustomDataset(df=test_df,root_dir='/kaggle/input/plant-pathology-2020-fgvc7/images/',\n                     transform=Compose([augmentations.transforms.Resize(height=IMSIZE,width=IMSIZE,always_apply=True),\n                                                  Normalize((0.485,0.456,0.406),\n                                                                      (0.229,0.224,0.225),always_apply=True),\n                                                    ToTensor()\n                                                  ]),iftest=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE=4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loader=DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True,num_workers=2)\n# valid_loader=DataLoader(valid_dataset,batch_size=BATCH_SIZE,shuffle=False,num_workers=2)\ntest_loader=DataLoader(test_dataset,batch_size=BATCH_SIZE,shuffle=False,num_workers=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"use_cuda = torch.cuda.is_available()\nif use_cuda:\n    device='cuda:0'\nuse_tpu=False\nuse_device=True\nif use_tpu:\n    device='idk'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model_transfer=models.densenet161(pretrained=True)\n# # for param in model_transfer.parameters():\n# #     param.requires_grad=False\n# print(model_transfer)\n# model_transfer.classifier=nn.Sequential(nn.Linear(model_transfer.classifier.in_features,1000),\n#                                         nn.ReLU(),\n#                                         nn.Dropout(p=0.5),\n#                                         nn.Linear(1000,4))\n# # nn.init.kaiming_normal_(model_transfer.classifier.weight, nonlinearity='relu')\n# if use_device:\n#     model_transfer = model_transfer.to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# NEPOCHS=30\n# print(IMSIZE)\n# criterion_transfer = nn.CrossEntropyLoss()\n# learning_rate=5e-4*np.logspace(0,1.5,9)\n# learning_rate=learning_rate[2]\n# learning_rate=8e-4\n# optimizer_transfer = optim.AdamW(model_transfer.parameters(),learning_rate,weight_decay=1e-3)\n# num_train_steps = int(len(train_dataset) / BATCH_SIZE * NEPOCHS)\n# from transformers import get_cosine_schedule_with_warmup\n# scheduler = get_cosine_schedule_with_warmup(optimizer_transfer, num_warmup_steps=len(train_dataset)/BATCH_SIZE*5, num_training_steps=num_train_steps)\n# # optimizer_transfer = torch.optim.Adam(model_efficient.parameters())\n# # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_transfer, 'max', patience = 3,verbose=True,min_lr=0.00001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(n_epochs,train_loader,valid_loader,model,optimizer,criterion,use_device,save_path,final_train=False,ifsched=False):\n    for epoch in range(1,n_epochs+1):\n        train_loss=0.0\n        valid_loss=0.0\n        labels_for_acc=[]\n        output_for_acc=[]\n        labels_for_accv=[]\n        output_for_accv=[]\n        model.train()\n        for batch_idx,(data,target) in enumerate(train_loader):\n#             print(type(data),type(target))\n            if use_device:\n                data,target=data.to(device),target.to(device)\n            optimizer.zero_grad()\n            output=model(data)\n            loss=criterion(output,target)\n            train_loss+=loss.item()*data.size(0)\n            loss.backward()\n            optimizer.step()\n            if ifsched:\n                    scheduler.step()\n            labels_for_acc=np.concatenate((labels_for_acc,target.cpu().numpy()),0)\n            output_for_acc=np.concatenate((output_for_acc,np.argmax(output.cpu().detach().numpy(),1)),0)\n        train_loss=train_loss/len(train_loader.dataset)\n        train_acc=accuracy_score(labels_for_acc,output_for_acc)\n        if not final_train:\n            with torch.no_grad():\n                model.eval()\n                for batch_idx,(data,target) in enumerate(valid_loader):\n                    if use_device:\n                        data,target=data.to(device),target.to(device)\n                    output=model(data)\n                    loss=criterion(output,target)\n                    valid_loss+=loss.item()*data.size(0)\n                    labels_for_accv=np.concatenate((labels_for_accv,target.cpu().numpy()),0)\n                    output_for_accv=np.concatenate((output_for_accv,np.argmax(output.cpu().detach().numpy(),1)),0)\n                valid_loss=valid_loss/len(valid_loader.dataset)\n                valid_acc=accuracy_score(labels_for_accv,output_for_accv)\n                print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\tTrain Acc: {:.6f} \\tValidation Acc: {:.6f}'.format(\n                epoch, \n                train_loss,\n                valid_loss,\n                train_acc,\n                valid_acc\n                ))\n        if final_train:\n            print('Epoch: {} \\tTraining Loss: {:.6f} \\tTrain Acc: {:.6f} '.format(\n                epoch, \n                train_loss,\n                train_acc\n                ))\n#     return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train(NEPOCHS, train_loader,valid_loader, model_transfer, optimizer_transfer, criterion_transfer, use_device, 'model_transfer.pt',ifsched=True,final_train=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from efficientnet_pytorch import EfficientNet\nmodel_efficient=EfficientNet.from_pretrained('efficientnet-b7')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for param in model_efficient.parameters():\n#     param.requires_grad=False\n# print(model_transfer)\nmodel_efficient._fc=nn.Sequential(nn.Linear(model_efficient._fc.in_features,1000,bias=True),\n                                 nn.ReLU(),\n                                 nn.Dropout(p=0.5),\n                                 nn.Linear(1000,4,bias=True))\n# nn.init.kaiming_normal_(model_efficient._fc.weight, nonlinearity='relu')\nif use_device:\n    model_efficient = model_efficient.to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NEPOCHS=40\nprint(IMSIZE)\ncriterion_transfer = nn.CrossEntropyLoss()\n# learning_rate=5e-4*np.logspace(0,1.5,9)\n# learning_rate=learning_rate[2]\nlearning_rate=8e-4\noptimizer_transfer = optim.AdamW(model_efficient.parameters(),learning_rate,weight_decay=1e-3)\nnum_train_steps = int(len(train_dataset) / BATCH_SIZE * NEPOCHS)\nfrom transformers import get_cosine_schedule_with_warmup\nscheduler = get_cosine_schedule_with_warmup(optimizer_transfer, num_warmup_steps=len(train_dataset)/BATCH_SIZE*5, num_training_steps=num_train_steps)\n# optimizer_transfer = torch.optim.Adam(model_efficient.parameters())\n# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_transfer, 'max', patience = 3,verbose=True,min_lr=0.00001)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train(NEPOCHS, train_loader,None, model_efficient, optimizer_transfer, criterion_transfer, use_device, 'model_transfer.pt',ifsched=True,final_train=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test(model,test_loader,use_device):\n    preds_for_output=np.zeros((1,4))\n    with torch.no_grad():\n        model.eval()\n        for images in test_loader:\n            if use_device:\n                images=images.to(device)\n            preds=model(images)\n            preds_for_output=np.concatenate((preds_for_output,preds.cpu().detach().numpy()),0)\n    return preds_for_output\n        \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_runs=5\nimport scipy\nsubs=[]\nfor i in range(num_runs):\n    out=test(model_efficient,test_loader,use_device)\n    output=pd.DataFrame(scipy.special.softmax(out,1),columns=['healthy','multiple_diseases','rust','scab'])\n    output.drop(0,inplace=True)\n    output.reset_index(drop=True,inplace=True)\n    subs.append(output)\n\nsub_eff=sum(subs)/num_runs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_df['image_id']=test_df['image_id'].str.replace('.jpg','')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub1=sub_eff.copy()\nsub1['image_id']=test_df.image_id\nsub1=sub1[['image_id','healthy','multiple_diseases','rust','scab']]\nsub1.to_csv('sub_densenet.csv',index=False)\nsub1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}