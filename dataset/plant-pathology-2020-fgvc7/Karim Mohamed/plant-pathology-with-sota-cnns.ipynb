{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install efficientnet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import libraries to handle data\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport cv2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/plant-pathology-2020-fgvc7/train.csv\")\ndf.sample(3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"path_prefix = \"/kaggle/input/plant-pathology-2020-fgvc7/images/\"\ndef get_image_path(image_id):\n    return path_prefix + image_id + \".jpg\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Visualize the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = [df[(df[\"healthy\"] == 1)][\"healthy\"].count()/df[\"healthy\"].count(), \n     df[(df[\"multiple_diseases\"] == 1)][\"multiple_diseases\"].count()/df[\"multiple_diseases\"].count(),\n     df[(df[\"rust\"] == 1)][\"rust\"].count()/df[\"rust\"].count(),\n     df[(df[\"scab\"] == 1)][\"scab\"].count()/df[\"scab\"].count()]\nlabels = [\"healthy\", \"multiple_diseases\", \"rust\", \"scab\"]\n\nplt.pie(cols, labels=labels)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"healthy_img = cv2.imread(get_image_path(df[(df[\"healthy\"] == 1)].iloc[0].image_id))\nhealthy_img = cv2.cvtColor(healthy_img, cv2.COLOR_BGR2RGB)\n\nmulti_diseas_img = cv2.imread(get_image_path(df[(df[\"multiple_diseases\"] == 1)].iloc[0].image_id))\nmulti_diseas_img = cv2.cvtColor(multi_diseas_img, cv2.COLOR_BGR2RGB)\n\nscab_img = cv2.imread(get_image_path(df[(df[\"scab\"] == 1)].iloc[0].image_id))\nscab_img = cv2.cvtColor(scab_img, cv2.COLOR_BGR2RGB)\n\nrust_img = cv2.imread(get_image_path(df[(df[\"rust\"] == 1)].iloc[0].image_id))\nrust_img = cv2.cvtColor(rust_img, cv2.COLOR_BGR2RGB)\n\n\nfig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2, figsize=(8,6))\n\nax1.imshow(healthy_img/255.0)\nax1.set_title(\"Healthy\")\n\nax2.imshow(multi_diseas_img/255.0)\nax2.set_title(\"multiple_diseases\")\n\nax3.imshow(scab_img/255.0)\nax3.set_title(\"scab\")\n\nax4.imshow(rust_img/255.0)\nax4.set_title(\"rust\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Helper function for data augmentation\nAlot of help from: https://www.kaggle.com/tarunpaparaju/plant-pathology-2020-eda-models"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Canny Edge detection\n#this detects the leaf in the image and crops the image to the size of the leaf\ndef get_cropped_canny_image(img):\n    edges = cv2.Canny(img,100,100)\n    edge_coordinates = []\n    for i in range(edges.shape[0]):\n        for j in range(edges.shape[1]):\n            if edges[i,j] != 0:\n                edge_coordinates.append((i,j))\n    bottom = edge_coordinates[np.argsort([coordinate[0] for coordinate in edge_coordinates])[0]][0]\n    top = edge_coordinates[np.argsort([coordinate[0] for coordinate in edge_coordinates])[-1]][0]\n    left = edge_coordinates[np.argsort([coordinate[1] for coordinate in edge_coordinates])[0]][1]\n    right = edge_coordinates[np.argsort([coordinate[1] for coordinate in edge_coordinates])[-1]][1]\n    new_img = img[bottom:top, left:right]\n    new_img = cv2.resize(new_img, (img.shape[1],img.shape[0]))\n    return new_img\nplt.imshow(get_cropped_canny_image(healthy_img))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Preprocess data"},{"metadata":{"trusted":true},"cell_type":"code","source":"IMAGE_SIZE = (128,128)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = [] #empty array to hold result\n\n#load and resize image\nfor im in df[\"image_id\"]:\n    img = cv2.imread(get_image_path(im))\n    img = cv2.resize(img, IMAGE_SIZE)\n    data.append(img)\nprint(\"Loaded and Resized\")\n\ndata_len = len(data)\n#crop image and append to result (augment data)\nfor im in range(data_len):\n    data.append(get_cropped_canny_image(data[im]))\n\nprint(\"cropped\")\n\ndata_len = len(data)\n#blur the whole new data the original and cropped\nfor im in range(data_len):\n    data.append(cv2.blur(data[im], (80,80)))\n\nlen(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#repeat the original dataframe 4 times to have the same shape as the images\ndf = pd.concat([df]*4)\nlen(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = np.array(data)/255.0\ny = df.drop(\"image_id\", axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Dense,GlobalAveragePooling2D\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom tensorflow.keras.applications import DenseNet121\nfrom tensorflow.keras.applications.resnet_v2 import ResNet152V2\nimport efficientnet.tfkeras as efn\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.8)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#free up sum memory\ndel X\ndel y\ndel df\ndel data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint = ModelCheckpoint(\n    \"/kaggle/working/EfnNetB7\", monitor='val_accuracy', verbose=1, save_best_only=True,\n    save_weights_only=True, mode='max')\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.05, patience=5, verbose=1, min_delta=0.001, mode='min')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(vertical_flip=True,horizontal_flip=True)\ndatagen.fit(X_train, augment=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_efficientNet_base = efn.EfficientNetB7(include_top=False, input_shape=(128,128,3), weights='imagenet')\nmy_efficientNetB7 = Sequential( [my_efficientNet_base, GlobalAveragePooling2D(), Dense(4,activation='softmax')] )\nmy_efficientNetB7.compile(optimizer=tf.optimizers.Adam(lr=0.0001), loss='categorical_crossentropy', metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = my_efficientNetB7.fit(datagen.flow(X_train,y_train.values, batch_size=32), \n                                steps_per_epoch=len(X_train)/32,epochs=25, \n                                validation_data=(X_test,y_test.values), callbacks=[reduce_lr])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}