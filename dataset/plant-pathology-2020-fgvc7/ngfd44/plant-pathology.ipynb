{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Ставим Efficientnet","metadata":{}},{"cell_type":"code","source":"!pip install -q efficientnet","metadata":{"execution":{"iopub.status.busy":"2022-06-08T09:28:42.92555Z","iopub.execute_input":"2022-06-08T09:28:42.925911Z","iopub.status.idle":"2022-06-08T09:28:53.162994Z","shell.execute_reply.started":"2022-06-08T09:28:42.925877Z","shell.execute_reply":"2022-06-08T09:28:53.161878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Импорт библиотек","metadata":{}},{"cell_type":"code","source":"import math, re, os\n\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nfrom kaggle_datasets import KaggleDatasets\nimport tensorflow as tf\nimport tensorflow.keras.layers as L\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\n\n## ______________ БЛОК С ИМПОРТАМИ АРХИТЕКТУР ____________________\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications.vgg19 import VGG19\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\nfrom tensorflow.keras.applications.densenet import DenseNet121, DenseNet169, DenseNet201 \nfrom tensorflow.keras.applications.xception import Xception\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.applications.resnet_v2 import ResNet50V2, ResNet101V2, ResNet152V2\nfrom tensorflow.keras.applications.nasnet import NASNetLarge\nfrom efficientnet.tfkeras import EfficientNetB7, EfficientNetL2\n## ______________ КОНЕЦ БЛОКА С ИМПОРТАМИ АРХИТЕКТУР ____________________\n\n# импорт других полезных инструментов: слоев, оптимизаторов, функций обратной связи\nfrom tensorflow.keras.layers.experimental.preprocessing import Normalization\nfrom tensorflow.keras.layers import Flatten,Dense,Dropout,BatchNormalization\nfrom tensorflow.keras.models import Model,Sequential\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-08T09:28:53.165122Z","iopub.execute_input":"2022-06-08T09:28:53.165381Z","iopub.status.idle":"2022-06-08T09:28:53.178164Z","shell.execute_reply.started":"2022-06-08T09:28:53.165352Z","shell.execute_reply":"2022-06-08T09:28:53.177227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Настраиваем TPU конфигурацию","metadata":{}},{"cell_type":"code","source":"# Путь к данным. Если работаете на Google Colaboratory, то замените KaggleDatasets().get_gcs_path() на путь к данным, который будет у вас\nGCS_DS_PATH = KaggleDatasets().get_gcs_path()","metadata":{"execution":{"iopub.status.busy":"2022-06-08T09:28:53.179485Z","iopub.execute_input":"2022-06-08T09:28:53.179907Z","iopub.status.idle":"2022-06-08T09:28:53.71002Z","shell.execute_reply.started":"2022-06-08T09:28:53.179876Z","shell.execute_reply":"2022-06-08T09:28:53.709132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AUTO = tf.data.experimental.AUTOTUNE\n# Проверяем существующее оборудование и выбираем соответствующую стратегию использования вычислений\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    # онаружение TPU. Параметры не требуются если установленна переменная окружения TPU_NAME. На Kaggle это всегда True.\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() # если TPU отсутствует, то испльзуем стратегию по умолчанию для TF (CPU or GPU)\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)\n\n# Конфигурация\nEPOCHS = 35\nBATCH_SIZE = 8 * strategy.num_replicas_in_sync\nNB_CLASSES = 4\nSTEPS_PER_EPOCH = 1821 // BATCH_SIZE\nprint(STEPS_PER_EPOCH)","metadata":{"execution":{"iopub.status.busy":"2022-06-08T09:28:53.712026Z","iopub.execute_input":"2022-06-08T09:28:53.712252Z","iopub.status.idle":"2022-06-08T09:28:59.482474Z","shell.execute_reply.started":"2022-06-08T09:28:53.712224Z","shell.execute_reply":"2022-06-08T09:28:59.481455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Посмотрим на данные","metadata":{}},{"cell_type":"markdown","source":"## Загружаем метки классов и пути к изображениям","metadata":{}},{"cell_type":"code","source":"# функция, которая превращает айди картинки в полный путь к ней\ndef format_path(st):\n    return GCS_DS_PATH + '/images/' + st + '.jpg'","metadata":{"execution":{"iopub.status.busy":"2022-06-08T09:28:59.484128Z","iopub.execute_input":"2022-06-08T09:28:59.484729Z","iopub.status.idle":"2022-06-08T09:28:59.490041Z","shell.execute_reply.started":"2022-06-08T09:28:59.484683Z","shell.execute_reply":"2022-06-08T09:28:59.488982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/train.csv')\ntest = pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/test.csv')\nsub = pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/sample_submission.csv')\n\ntrain_paths = train.image_id.apply(format_path).values\ntest_paths = test.image_id.apply(format_path).values\n\ntrain_labels = train.loc[:, 'healthy':].values\n\n# если планируете обучать модель с валидирующим набором данных\ntrain_paths, valid_paths, train_labels, valid_labels = train_test_split(\n    train_paths, train_labels, test_size=0.15, random_state=2020)","metadata":{"execution":{"iopub.status.busy":"2022-06-08T09:28:59.492266Z","iopub.execute_input":"2022-06-08T09:28:59.492686Z","iopub.status.idle":"2022-06-08T09:28:59.543104Z","shell.execute_reply.started":"2022-06-08T09:28:59.492651Z","shell.execute_reply":"2022-06-08T09:28:59.541247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\n\n# создаем сетку 2 на 5, для более компактного отображения символов и задаем размер их отображения\nf, ax = plt.subplots(3, 6, figsize=(18, 7))\nax = ax.flatten()\n# отрисовываем в цикле найденные топ N изображений частей графем\nfor i in range(18):\n    img = plt.imread(f'../input/plant-pathology-2020-fgvc7/images/Train_{i}.jpg')\n    ax[i].set_title(train[train['image_id']==f'Train_{i}'].melt()[train[train['image_id']==f'Train_{i}'].melt().value == 1]['variable'].values[0])\n    ax[i].imshow(img)\nprint(img.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-08T09:28:59.544833Z","iopub.execute_input":"2022-06-08T09:28:59.545211Z","iopub.status.idle":"2022-06-08T09:29:09.52918Z","shell.execute_reply.started":"2022-06-08T09:28:59.545173Z","shell.execute_reply":"2022-06-08T09:29:09.528235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Создаем объекты наборов данных\n\nA `tf.data.Dataset` объект нужен для того, чтобы модель бесперебойно работала на TPUs","metadata":{}},{"cell_type":"code","source":"# устанавливаем глобальные переменные\nimg_size = 728\n\n# функция, которая читает изображение из файла и преобразовывает его к нужному размеру, а так же нормализует\ndef decode_image(filename, label=None, image_size=(img_size, img_size)):\n    bits = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(bits, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0\n    image = tf.image.resize(image, image_size)\n    \n    if label is None:\n        return image\n    else:\n        return image, label\n# функция расширения данных","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2022-06-08T09:29:09.530786Z","iopub.execute_input":"2022-06-08T09:29:09.531458Z","iopub.status.idle":"2022-06-08T09:29:09.538451Z","shell.execute_reply.started":"2022-06-08T09:29:09.531417Z","shell.execute_reply":"2022-06-08T09:29:09.537472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Создаем объекты наборов данных для обучения, валидации и теста","metadata":{}},{"cell_type":"code","source":"train_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((train_paths, train_labels))\n    .map(decode_image, num_parallel_calls=AUTO)\n#     .map(data_augment, num_parallel_calls=AUTO) # если напишите свою функцию расширения данных data_augment \n    .repeat()\n    .shuffle(512)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTO)\n)\n# если планируете обучать модель с валидирующим набором данных\nvalid_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((valid_paths, valid_labels))\n    .map(decode_image, num_parallel_calls=AUTO)\n    .batch(BATCH_SIZE)\n    .cache()\n    .prefetch(AUTO)\n)\n\ntest_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices(test_paths)\n    .map(decode_image, num_parallel_calls=AUTO)\n    .batch(BATCH_SIZE)\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-08T09:29:09.539628Z","iopub.execute_input":"2022-06-08T09:29:09.539913Z","iopub.status.idle":"2022-06-08T09:29:09.716711Z","shell.execute_reply.started":"2022-06-08T09:29:09.539882Z","shell.execute_reply":"2022-06-08T09:29:09.715873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Строим и обучаем модель","metadata":{}},{"cell_type":"markdown","source":"### Вспомогательные функции","metadata":{}},{"cell_type":"code","source":"def get_model(use_model):\n    base_model = use_model(\n        weights='imagenet', \n        include_top=False, pooling='avg',\n        input_shape=(img_size, img_size, 3))\n    \n    #base_model.trainable = False\n    \n    x = Flatten()(base_model.layers[-1].output)\n    x = Dense(512, activation='relu')(x)\n    x = Dense(128, activation='relu')(x)\n\n    #x = Dropout(0.4)(x)\n    predictions = Dense(NB_CLASSES, activation='softmax')(x)\n\n    return Model(inputs=base_model.input, outputs=predictions)","metadata":{"execution":{"iopub.status.busy":"2022-06-08T09:29:09.721436Z","iopub.execute_input":"2022-06-08T09:29:09.721719Z","iopub.status.idle":"2022-06-08T09:29:09.728475Z","shell.execute_reply.started":"2022-06-08T09:29:09.72169Z","shell.execute_reply":"2022-06-08T09:29:09.727428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Загружаем модель на TPU","metadata":{}},{"cell_type":"code","source":"with strategy.scope():    \n    model = get_model(EfficientNetB7)\n    \nmodel.compile(\n    optimizer='nadam',\n    loss = 'categorical_crossentropy',\n    metrics=['categorical_accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-06-08T09:29:09.729967Z","iopub.execute_input":"2022-06-08T09:29:09.730814Z","iopub.status.idle":"2022-06-08T09:29:18.093073Z","shell.execute_reply.started":"2022-06-08T09:29:09.730768Z","shell.execute_reply":"2022-06-08T09:29:18.091498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Запускаем процесс обучения","metadata":{}},{"cell_type":"code","source":"history = model.fit(train_dataset, \n          steps_per_epoch=STEPS_PER_EPOCH, \n          epochs=EPOCHS,\n          callbacks=[EarlyStopping(monitor='val_accuracy', patience=5, verbose=1, restore_best_weights=True),\n                     ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4, verbose=1),\n                     ModelCheckpoint(filepath='my_ef_net_b7.h5', monitor='val_categorical_accuracy', save_best_only=True)],\n          validation_data= valid_dataset,\n          workers = 3)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-06-08T09:29:18.094966Z","iopub.execute_input":"2022-06-08T09:29:18.095338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Проверка качества модели","metadata":{}},{"cell_type":"markdown","source":"Unhide below to see helper function `display_training_curves`:","metadata":{}},{"cell_type":"code","source":"plt.plot(history.history['categorical_accuracy'], \n         label='Оценка точности на обучающем наборе')\nplt.plot(history.history['val_categorical_accuracy'], \n         label='Оценка точности на проверочном наборе')\nplt.xlabel('Эпоха обучения')\nplt.ylabel('Оценка точности')\nplt.legend()\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Делаем прогноз тестовых данных и готовим представление данных для проверки","metadata":{}},{"cell_type":"markdown","source":"Когда вы получите несколько моделей с высокими баллами, можно поробовать их объеденить\n\nprobs = (model1.predict(test_dataset)+model.predict(test_dataset))/2\n\nгде можно использовать и больше моделей, но тогда делить не на 2, а на количество использованных моделей","metadata":{}},{"cell_type":"code","source":"probs = model.predict(test_dataset)\nsub.loc[:, 'healthy':] = probs\nsub.to_csv('submission.csv', index=False)\nsub.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# создаем сетку 2 на 5, для более компактного отображения символов и задаем размер их отображения\nf, ax = plt.subplots(3, 5, figsize=(18, 8))\nax = ax.flatten()\n# отрисовываем в цикле найденные топ N изображений частей графем\nfor i in range(10):\n    img = plt.imread(f'../input/plant-pathology-2020-fgvc7/images/Test_{i}.jpg')\n    ax[i].set_title(sub[sub['image_id']==f'Test_{i}'].melt().iloc[1:][sub[sub['image_id']==f'Test_{i}'].melt().iloc[1:].value >= 0.8]['variable'].values[0])\n    ax[i].imshow(img)\nprint(img.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}