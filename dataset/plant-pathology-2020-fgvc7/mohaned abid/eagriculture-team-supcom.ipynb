{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"####first we import all the  libraries that we are going to use \n#libraries for preproccesing and linar algebra\nimport numpy as np\nimport pandas as pd \nimport os\n#libraries for deep learning :we are going to use FASTAI as a framework on top of pytorch \nimport torch\nfrom fastai.vision import *\nfrom fastai.metrics import error_rate\n#visualization library\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"####phase1:IMPORTATION,EXPLORATORY DATA ANALYSIS AND PRE PROCESSING  \ntraindf = pd.read_csv(\"train.csv\")\ntraindf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking train dataset columns and data types\ntraindf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#some basic statistics on train dataset \ntraindf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#exloring the data \nclassdata = (traindf.healthy + traindf.multiple_diseases+\n             traindf.rust + traindf.scab)\nclassdata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"any(classdata > 1)\n#---->this means that is problem is is not a multiclassification problem \n#since all examples falls under only one of the 4 classes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#adding .jpg to help us load images later on \ntraindf[\"image_id\"] =traindf[\"image_id\"].astype(\"str\") + \".jpg\"\ntraindf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now  lets define our classes to be:\n# 0 for healthy\n# 1 multiple_diseases\n# 2 rust\n# 3 scab\ntraindf[\"label\"] = (0*traindf.healthy + 1*traindf.multiple_diseases+\n             2*traindf.rust + 3*traindf.scab)\ntraindf.drop(columns=[\"healthy\",\"multiple_diseases\",\"rust\",\"scab\"],inplace=True)\ntraindf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##some visual EDA to understand our data more \n#checking class unbalance\ntrain_data = pd.read_csv(\"train.csv\")\nfig = go.Figure([go.Pie(labels=train_data.columns[1:],\n           values=train_data.iloc[:, 1:].sum().values)])\nfig.update_layout(title_text=\"Pie chart of targets\", template=\"simple_white\")\nfig.data[0].marker.line.color = 'rgb(0, 0, 0)'\nfig.data[0].marker.line.width = 0.5\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#distribution of healthy class\ntrain_data[\"Healthy\"] = train_data[\"healthy\"].apply(bool).apply(str)\nfig = px.histogram(train_data, x=\"Healthy\", title=\"Healthy distribution\", color=\"Healthy\",\\\n            color_discrete_map={\n                \"True\": px.colors.qualitative.Plotly[0],\n                \"False\": px.colors.qualitative.Plotly[1]})\nfig.update_layout(template=\"simple_white\")\nfig.data[0].marker.line.color = 'rgb(0, 0, 0)'\nfig.data[0].marker.line.width = 0.5\nfig.data[1].marker.line.color = 'rgb(0, 0, 0)'\nfig.data[1].marker.line.width = 0.5\nfig\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#scab class distribution \ntrain_data[\"Scab\"] = train_data[\"scab\"].apply(bool).apply(str)\nfig = px.histogram(train_data, x=\"Scab\", color=\"Scab\", title=\"Scab distribution\",\\\n            color_discrete_map={\n                \"True\": px.colors.qualitative.Plotly[1],\n                \"False\": px.colors.qualitative.Plotly[0]})\nfig.update_layout(template=\"simple_white\")\nfig.data[0].marker.line.color = 'rgb(0, 0, 0)'\nfig.data[0].marker.line.width = 0.5\nfig.data[1].marker.line.color = 'rgb(0, 0, 0)'\nfig.data[1].marker.line.width = 0.5\nfig","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#rust distribution\ntrain_data[\"Rust\"] = train_data[\"rust\"].apply(bool).apply(str)\nfig = px.histogram(train_data, x=\"Rust\", color=\"Rust\", title=\"Rust distribution\",\\\n            color_discrete_map={\n                \"True\": px.colors.qualitative.Plotly[1],\n                \"False\": px.colors.qualitative.Plotly[0]})\nfig.update_layout(template=\"simple_white\")\nfig.data[0].marker.line.color = 'rgb(0, 0, 0)'\nfig.data[0].marker.line.width = 0.5\nfig.data[1].marker.line.color = 'rgb(0, 0, 0)'\nfig.data[1].marker.line.width = 0.5\nfig","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#multiple deseases distribution\ntrain_data[\"Multiple diseases\"] = train_data[\"multiple_diseases\"].apply(bool).apply(str)\nfig = px.histogram(train_data, x=\"Multiple diseases\", color=\"Multiple diseases\", title=\"Multiple diseases distribution\",\\\n            color_discrete_map={\n                \"True\": px.colors.qualitative.Plotly[1],\n                \"False\": px.colors.qualitative.Plotly[0]})\nfig.update_layout(template=\"simple_white\")\nfig.data[0].marker.line.color = 'rgb(0, 0, 0)'\nfig.data[0].marker.line.width = 0.5\nfig.data[1].marker.line.color = 'rgb(0, 0, 0)'\nfig.data[1].marker.line.width = 0.5\nfig","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creation of transformation object this object help\n#augment our data by making transormations like flipping images and rotation...\n#since more data means better results ;) (usually)\ntransformations = get_transforms(do_flip = True,\n                                 flip_vert=True, \n                                 max_lighting=0.1, \n                                 max_zoom=1.05,\n                                 max_warp=0.,\n                                 max_rotate=15,\n                                 p_affine=0.75,\n                                 p_lighting=0.75\n                                )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#this object is an encapsulation of our data it is a necessay step for the data to fit in a model under FASTAI\npathofdata = \"/input/\"\ndata  = ImageDataBunch.from_df(path=pathofdata, \n                               df=traindf, \n                               folder=\"images\",\n                               label_delim=None,\n                               valid_pct=0.2,\n                               seed=100,\n                               fn_col=0, \n                               label_col=1, \n                               suffix='',\n                               ds_tfms=transformations, \n                               size=512,\n                               bs=64, \n                               val_bs=32,\n                               )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#some images and their correspanding classes\ndata.show_batch(rows=3, figsize=(10,7))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#normalizing is a necessay pre proccessing step to make the model generalize better on the data\n#it carries out a simple function on eacch image:subtract the mean of pixels and divide by the variance\ndata = data.normalize()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"####PHASE 2 :MODELING AND TRAINNING\n#our model in a CNN architecture specificly a resnet34 a commun architecture used in computer vision tasks \nlearner = cnn_learner(data, \n                      models.resnet34, \n                      pretrained=True\n                      ,metrics=[error_rate, accuracy],).to_fp16()\nlearner.model_dir = '/models'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#we set the hyperparameter leraning rate to be 0.002 (a value signifying how much we should update the weights at each iteration)\n#after trying out a bunch of values \n#this value seems to work the best\n#also we set epochs to be 10 due to time constraint \n#epachs is how many times does the model go through the whole dataset\nlr = 0.002\nepochs=10\n#now we fit the resnet34 to our data \n#it takes about 50 minutes on kaggle (please activate GPU accelerator if running on kaggle)\nlearner.fit_one_cycle(epochs, lr)\n#this saves the weights of the   model so that you can use it later on without trainning the model again","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#uncomment these lines to load pretrained model \nlearner.export()\nlearner = load_learner(path=\"/models\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#this shows a batch of the model predictions on the train dataset \nlearner.show_results()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### PHASE 3 RUNNING THE MODEL ON THE TEST DATASET \n#FIRST we import the test dataset\ntestdf = pd.read_csv(\"/test.csv\")\ntestdf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now lets get the paths of all test dataset images\npathofdata = \"/\"\ntestdata= ImageList.from_folder(pathofdata+\"images\")\ntestdata.filter_by_func(lambda x: x.name.startswith(\"Test\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#reading an image and predict its  classe with our model\nimg1 = open_image(testdata.items[0])\nlearner.predict(img1)\n#--->the result is 3 which is the label of the scab desease","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### PHASE 4 PREPARING SUBMISSION FILE TO CHECK  OUR ACCURACY ON UNSEEN DATA \n#SUBMISSION DATAFRAME\nresultlist = []\nfor item in testdata.items:\n    img = open_image(item)\n    predval = learner.predict(img)[2].tolist()\n    predval.insert(0,item.name[:-4:])\n    resultlist.append(predval)\nresultdf = pd.DataFrame(resultlist)\nresultdf.columns = sampsubmit.columns\nresultdf.set_index(\"image_id\",inplace=True)\nresultdf = resultdf.loc[sampsubmit.image_id,:]\nresultdf.reset_index(inplace=True)\nresultdf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#PREPARE SUBMISSION CSV YOU CAN FIND IT IN OUTPUT FOLDER ON THE RIGHT \nresultdf.to_csv(\"submit.csv\",index=False)\n#AFTER SUBMITING OUR RESULTS TO KAGGLE THE MODEL \n#PERFORMED OUTSTANDINGLY WELL SCORING 0.94405% OF ACCURACY ON UNSEEN TEST DATASET\n\n'''THANK YOU \nEND OF THE KERNEL'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}