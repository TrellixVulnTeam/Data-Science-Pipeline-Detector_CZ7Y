{"cells":[{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"!pip install omegaconf\n!pip install -q efficientnet\n!pip install iterative-stratification","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nuser_credential = user_secrets.get_gcloud_credential()\nuser_secrets.set_tensorflow_credential(user_credential)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from kaggle_datasets import KaggleDatasets\n\nGCS_DS_PATH = KaggleDatasets().get_gcs_path('1tfrecordapple')\nGCS_DS_PATH","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport tensorflow as tf\nfrom tensorflow import keras\nimport efficientnet.tfkeras as efn\n# from kaggle_datasets import KaggleDatasets\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import callbacks\nimport math\nimport tensorflow.keras.layers as L\nfrom tensorflow.keras.applications import InceptionResNetV2\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import schedules\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\nfrom sklearn import model_selection\n\nfrom omegaconf import OmegaConf\n\n# TPU or GPU detection\n# Detect hardware, return appropriate distribution strategy\n\n# physical_devices = tf.config.list_physical_devices('GPU')\n\ntarget_cols = [\"healthy\", \"multiple_diseases\", \"rust\", \"scab\"]\n\nconf = \"\"\"\nbase:\n  train_path: '../input/plant-pathology-2020-fgvc7/train.csv'\n  test_path: \"../input/plant-pathology-2020-fgvc7/test.csv\"\n  ss_path: \"../input/plant-pathology-2020-fgvc7/sample_submission.csv\"\n  train_tf_path: \"/train.tfrecord\"\n  test_tf_path: \"/test.tfrecord\"\n  print_freq: 100\n  num_workers: 4\n  target_size: 4\n  target_cols: [\"healthy\", \"multiple_diseases\", \"rust\", \"scab\"]\n  n_fold: 4\n  trn_fold: [0,1,2,3]\n  train: True\n  debug: False\n  oof: False\n\ndataset:\n  augment: true\n  cache: true\n  repeat: true\n  shuffle: 1024\n  cache_dir: \"\"\n\nsplit:\n  # name: \"MultilabelStratifiedKFold\"\n  name: \"MultilabelStratifiedKFold\"\n  param: {\n           \"n_splits\": 4,\n           \"shuffle\": True,\n           \"random_state\": 0\n  }\n\nmodel:\n  model_name: \"EfficientNetB7\"\n  size: 768  # 480\n  batch_size: 64\n  pretrained: true\n  epochs: 20\n  in_features: 2048\n\nloss:\n  name: \"binary_crossentropy\"\n  param: {}\n\noptimizer:\n  name: \"Adam\"\n  param: {\n           \"learning_rate\": 1e-4,\n           # \"weight_decay\": 1e-6,\n           # \"amsgrad\": False\n  }\n\nscheduler:\n  name: \"CosineAnnealingLR\"\n  param: {\n            \"epochs_per_cycle\": 10,\n            \"lr_max\": 1e-4,\n            \"lr_min\": 0,\n            # \"last_epoch\": -1\n  }\n\"\"\"\nconfig = OmegaConf.create(conf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def auto_select_accelerator():\n    \"\"\"\n    Reference:\n        * https://www.kaggle.com/mgornergoogle/getting-started-with-100-flowers-on-tpu\n        * https://www.kaggle.com/xhlulu/ranzcr-efficientnet-tpu-training\n    \"\"\"\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        tf.config.experimental_connect_to_cluster(tpu)\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n        print(\"Running on TPU:\", tpu.master())\n    except ValueError:\n        strategy = tf.distribute.get_strategy()\n    print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n\n    return strategy\n\n\nstrategy = auto_select_accelerator()\n\n\ndef seed_everything(seed=0):\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n    os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n\n\nseed = 2048\nseed_everything(seed)\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)\n\n# Data access\n# BASE_PATH = KaggleDatasets().get_gcs_path()\ntrain = pd.read_csv(config.base.train_path)\ntest = pd.read_csv(config.base.test_path)\nsub = pd.read_csv(config.base.ss_path)\nsub.iloc[:, 1:] = 0","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\ndef decode_image(image_data, h=config.model.size, w=config.model.size):\n    image = tf.image.decode_jpeg(image_data, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0\n\n    image = tf.image.resize(image, [h, w])\n    image = tf.reshape(image, [h, w, 3])\n    return image\n\n\ndef build_decoder(with_labels=True):\n    def read_tfrecord(example):\n        # 各々のデータに対してパース\n        if with_labels:\n            TFREC_FORMAT = {\n                'image': tf.io.FixedLenFeature([], tf.string),\n                config.base.target_cols[0]: tf.io.FixedLenFeature([], tf.int64),\n                config.base.target_cols[1]: tf.io.FixedLenFeature([], tf.int64),\n                config.base.target_cols[2]: tf.io.FixedLenFeature([], tf.int64),\n                config.base.target_cols[3]: tf.io.FixedLenFeature([], tf.int64),\n                'image_name': tf.io.FixedLenFeature([], tf.string),\n            }\n        else:\n            TFREC_FORMAT = {\n                'image': tf.io.FixedLenFeature([], tf.string),\n                'image_name': tf.io.FixedLenFeature([], tf.string),\n            }\n        example = tf.io.parse_single_example(example, TFREC_FORMAT)\n        image = decode_image(example['image'])\n        if with_labels:\n            targets = [example[x] for x in config.base.target_cols]\n            return image, targets\n        else:\n            return image\n\n    return read_tfrecord\n\n\ndef build_augmenter(with_labels=True):\n    def augment(img):\n        img = tf.image.random_flip_left_right(img)\n        img = tf.image.random_flip_up_down(img)\n        return img\n\n    def augment_with_labels(img, label):\n        return augment(img), label\n\n    return augment_with_labels if with_labels else augment\n\n\ndef data_augment(image, label=None):\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n\n    if label is None:\n        return image\n    else:\n        return image, label\n\n    \n    \n\ndef build_dataset(cfg, paths, idx, labels=None, decode_fn=None, augment_fn=None, val=False):\n    if val:\n        cfg.dataset.repeat = False\n        cfg.dataset.shuffle = False\n    else:\n        cfg.dataset.repeat = True\n        cfg.dataset.shuffle = True\n\n    if cfg.dataset.cache_dir != \"\" and cfg.dataset.cache_dir is True:\n        os.makedirs(cfg.dataset.cache_dir, exist_ok=True)\n\n    if decode_fn is None:\n        decode_fn = build_decoder()\n\n    if augment_fn is None:\n        augment_fn = build_augmenter(labels is not None)\n\n    idx = tf.constant(idx, dtype=tf.int64)\n\n    def is_index_in(index, rest):\n        return tf.math.reduce_any(index == idx)\n\n    def drop_index(index, rest):\n        return rest\n\n    AUTO = tf.data.experimental.AUTOTUNE\n\n    dset = tf.data.TFRecordDataset(paths)\n\n    dset = dset.map(decode_fn, num_parallel_calls=AUTO).enumerate()\n    dset = dset.filter(is_index_in)\n    dset = dset.map(drop_index)\n\n    dset = dset.cache(cfg.dataset.cache_dir) if cfg.dataset.cache_dir else dset\n    dset = dset.map(augment_fn, num_parallel_calls=AUTO) if cfg.dataset.augment else dset\n\n    dset = dset.repeat() if cfg.dataset.repeat else dset\n    dset = dset.shuffle(cfg.dataset.shuffle) if cfg.dataset.shuffle else dset\n\n    dset = dset.batch(cfg.model.batch_size).prefetch(AUTO)\n    return dset\n\n\nclass CosineAnnealingScheduler(callbacks.LearningRateScheduler):\n    def __init__(self, epochs_per_cycle, lr_min, lr_max, verbose=0):\n        super(callbacks.LearningRateScheduler, self).__init__()\n        self.verbose = verbose\n        self.lr_min = lr_min\n        self.lr_max = lr_max\n        self.epochs_per_cycle = epochs_per_cycle\n\n    def schedule(self, epoch, lr):\n        return self.lr_min + (self.lr_max - self.lr_min) *\\\n               (1 + math.cos(math.pi * (epoch % self.epochs_per_cycle) / self.epochs_per_cycle)) / 2\n\n__SPLITS__ = {\n    \"MultilabelStratifiedKFold\": MultilabelStratifiedKFold,\n    # \"KFold\": KFold,\n}\n\n__OPTIMIZER__ = {\n\n}\n\n__SCHEDULERS__ = {\n    \"CosineAnnealingLR\": CosineAnnealingScheduler\n}\n\n\ndef get_split(cfg):\n    if hasattr(model_selection, cfg.split.name):\n        return model_selection.__getattribute__(cfg.split.name)(**cfg.split.param)\n    elif __SPLITS__.get(cfg.split.name) is not None:\n        return __SPLITS__[cfg.split.name](**cfg.split.param)\n    else:\n        raise NotImplementedError\n\n\ndef get_optimizer(cfg):\n    if hasattr(tf.keras.optimizers, cfg.optimizer.name):\n        return tf.keras.optimizers.__getattribute__(cfg.optimizer.name)(**cfg.optimizer.param)\n    elif __OPTIMIZER__.get(cfg.optimizer.name) is not None:\n        return __OPTIMIZER__[cfg.optimizer.name](**cfg.optimizer.param)\n    else:\n        raise NotImplementedError\n\n\ndef get_scheduler(cfg):\n    if hasattr(schedules, cfg.scheduler.name):\n        return schedules.__getattribute__(cfg.scheduler.name)(**cfg.scheduler.param)\n    elif __SCHEDULERS__.get(cfg.scheduler.name) is not None:\n        return __SCHEDULERS__[cfg.scheduler.name](**cfg.scheduler.param)\n    else:\n        raise NotImplementedError\n\n\ndef main(cfg):\n    global train\n    seed_everything(seed=cfg.base.seed)\n\n    folds = train.copy()\n\n    if cfg.base.debug:\n        folds = folds.sample(n=100, random_state=cfg.base.seed).reset_index(drop=True)\n        cfg.model.epochs = 1\n    Fold = get_split(cfg)\n    for n, (train_index, val_index) in enumerate(Fold.split(folds, folds[cfg.base.target_cols])):\n        folds.loc[val_index, 'fold'] = int(n)\n    folds['fold'] = folds['fold'].astype(int)\n\n    oof_df = train.copy()\n\n\n    for fold in range(cfg.base.n_fold):\n        if fold in cfg.base.trn_fold:\n            fold_pred = train_loop(cfg, folds, fold)\n            sub.iloc[:, 1:] += fold_pred / cfg.base.n_fold\n            # test_pred[list(cfg.base.target_cols)] += fold_pred / len(cfg.base.trn_fold)\n\n    sub.to_csv(\"submit.csv\", index=False)\n\n\ndef train_loop(cfg, folds, fold):\n    global rand\n\n    # folds[\"path\"] = cfg.base.train_image_path + folds[\"image_id\"].astype(str) + \".jpg\"\n\n    trn_idx = folds[folds['fold'] != fold].index\n    val_idx = folds[folds['fold'] == fold].index\n\n    train_folds = folds.loc[trn_idx].reset_index(drop=True)\n    valid_folds = folds.loc[val_idx].reset_index(drop=True)\n\n    decoder = build_decoder()\n    # test_decoder = build_decoder(with_labels=Fals, target_size=(cfg.model.size, cfg.model.size))\n    train_tf_path = cfg.base.train_tf_path\n\n    train_dataset = build_dataset(\n        cfg,\n        train_tf_path,\n        trn_idx.values,\n        # augment_fn=augmenter,\n        decode_fn=decoder,\n        labels=train_folds[cfg.base.target_cols],\n        val=False\n    )\n\n    valid_dataset = build_dataset(\n        cfg,\n        train_tf_path,\n        val_idx.values,\n        decode_fn=decoder,\n        labels=valid_folds[cfg.base.target_cols],\n        val=True\n    )\n\n    with strategy.scope():\n        model = tf.keras.Sequential([\n            efn.__getattribute__(cfg.model.model_name)(\n                input_shape=(cfg.model.size, cfg.model.size, 3),\n                weights='imagenet',\n                include_top=False,\n                drop_connect_rate=0.1),\n            tf.keras.layers.GlobalAveragePooling2D(),\n            tf.keras.layers.Dense(cfg.base.target_size, activation='sigmoid')\n        ])\n        model.compile(\n            optimizer=get_optimizer(cfg),\n            loss=cfg.loss.name,\n            metrics=[tf.keras.metrics.AUC(multi_label=True)])\n        model.summary()\n\n    steps_per_epoch = train_folds.shape[0] // cfg.model.batch_size\n    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n        'model.h5', save_best_only=True, monitor='val_auc', mode='max')\n    lr_reducer = get_scheduler(cfg)\n\n    history = model.fit(\n        train_dataset,\n        epochs=cfg.model.epochs,\n        verbose=2,\n        callbacks=[checkpoint, lr_reducer],\n        steps_per_epoch=steps_per_epoch,\n        validation_data=valid_dataset\n    )\n\n    # oof = model.predict(valid_dataset, verbose=1)\n\n    test_tf_path = cfg.base.test_tf_path\n    test_augment = build_augmenter(with_labels=False)\n    test_decoder = build_decoder(with_labels=False)\n    test_dataset = build_dataset(\n        cfg,\n        test_tf_path,\n        test.index.values,\n        decode_fn=test_decoder,\n        augment_fn=test_augment,\n        val=True\n    )\n\n    pred = model.predict(test_dataset, verbose=1)\n\n    return pred\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"config.base.train_tf_path = GCS_DS_PATH  + config.base.train_tf_path\nconfig.base.test_tf_path = GCS_DS_PATH + config.base.test_tf_path","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"config.base.train_tf_path","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nuser_credential = user_secrets.get_gcloud_credential()\nuser_secrets.set_tensorflow_credential(user_credential)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"main(config)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}