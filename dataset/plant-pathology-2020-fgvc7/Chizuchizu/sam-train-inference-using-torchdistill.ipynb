{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install git+https://github.com/rwightman/pytorch-image-models -q\n!pip install torchdistill -q","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-16T14:51:00.462977Z","iopub.execute_input":"2021-10-16T14:51:00.463588Z","iopub.status.idle":"2021-10-16T14:51:29.231193Z","shell.execute_reply.started":"2021-10-16T14:51:00.463509Z","shell.execute_reply":"2021-10-16T14:51:29.230351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile distill.py\nimport argparse\nimport datetime\nimport cv2\nimport os\nimport time\n\nimport timm\nimport torch\nfrom torch import distributed as dist\nfrom torch.backends import cudnn\nfrom torch.nn import DataParallel\nfrom torch.nn.parallel import DistributedDataParallel\nfrom torchmetrics.functional import auroc\n\nfrom torchdistill.common import file_util, yaml_util, module_util\nfrom torchdistill.common.constant import def_logger\nfrom torchdistill.common.main_util import is_main_process, init_distributed_mode, load_ckpt, save_ckpt, set_seed\nfrom torchdistill.core.distillation import get_distillation_box\nfrom torchdistill.core.training import TrainingBox\nfrom torchdistill.datasets import util\nfrom torchdistill.datasets.registry import register_dataset\nfrom torchdistill.datasets.wrapper import BaseDatasetWrapper\nfrom torchdistill.eval.classification import compute_accuracy\nfrom torchdistill.misc.log import setup_log_file, SmoothedValue, MetricLogger\nfrom torchdistill.models.official import get_image_classification_model\nfrom torchdistill.models.registry import get_model, register_model_func\nfrom torchdistill.optim.registry import register_optimizer\nfrom torchdistill.common import misc_util\nfrom torchdistill.losses.single import register_org_loss\n\n\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\n\nlogger = def_logger.getChild(\"aaa\")\n\n\ndef get_train_file_path(image_id):\n    return f\"../input/plant-pathology-2020-fgvc7/images/{image_id}.jpg\"\n\n\ndef get_test_file_path(image_id):\n    return f\"../input/plant-pathology-2020-fgvc7/images/{image_id}.jpg\"\n\n\n\"\"\"SAMここから\"\"\"\nOPTIM_DICT = misc_util.get_classes_as_dict('torch.optim')\n\n\nclass SAM(torch.optim.Optimizer):\n    def __init__(self, params, base_optimizer, rho=0.05, adaptive=False, **kwargs):\n        assert rho >= 0.0, f\"Invalid rho, should be non-negative: {rho}\"\n\n        defaults = dict(rho=rho, adaptive=adaptive, **kwargs)\n        super(SAM, self).__init__(params, defaults)\n\n        self.defaults = defaults\n        self.base_optimizer = base_optimizer(self.param_groups, **kwargs)\n        self.param_groups = self.base_optimizer.param_groups\n\n    @torch.no_grad()\n    def first_step(self, zero_grad=False):\n        grad_norm = self._grad_norm()\n        for group in self.param_groups:\n            scale = self.defaults[\"rho\"] / (grad_norm + 1e-12)\n\n            for p in group[\"params\"]:\n                if p.grad is None: continue\n                self.state[p][\"old_p\"] = p.data.clone()\n                e_w = (torch.pow(p, 2) if self.defaults[\"adaptive\"] else 1.0) * p.grad * scale.to(p)\n                p.add_(e_w)  # climb to the local maximum \"w + e(w)\"\n\n        if zero_grad: self.zero_grad()\n\n    @torch.no_grad()\n    def second_step(self, zero_grad=False):\n        for group in self.param_groups:\n            for p in group[\"params\"]:\n                if p.grad is None: continue\n                p.data = self.state[p][\"old_p\"]  # get back to \"w\" from \"w + e(w)\"\n\n        self.base_optimizer.step()  # do the actual \"sharpness-aware\" update\n\n        if zero_grad: self.zero_grad()\n\n    @torch.no_grad()\n    def step(self, closure=None):\n        assert closure is not None, \"Sharpness Aware Minimization requires closure, but it was not provided\"\n        closure = torch.enable_grad()(closure)  # the closure should do a full forward-backward pass\n\n        self.first_step(zero_grad=True)\n        closure()\n        self.second_step()\n\n    def _grad_norm(self):\n        shared_device = self.param_groups[0][\"params\"][\n            0].device  # put everything on the same device, in case of model parallelism\n        norm = torch.norm(\n            torch.stack([\n                ((torch.abs(p) if self.defaults[\"adaptive\"] else 1.0) * p.grad).norm(p=2).to(shared_device)\n                for group in self.param_groups for p in group[\"params\"]\n                if p.grad is not None\n            ]),\n            p=2\n        )\n        return norm\n\n    def load_state_dict(self, state_dict):\n        super().load_state_dict(state_dict)\n        self.base_optimizer.param_groups = self.param_groups\n\n\n@register_optimizer\nclass samwrapper(SAM):\n    def __init__(self, params, base_optim_name, base_optim_params, sam_params):\n        base_optimizer = OPTIM_DICT[base_optim_name.lower()]  # (params, **base_optim_params)\n        super().__init__(params, base_optimizer, **sam_params)\n\n\ntry:\n    from torch.optim.lr_scheduler import ReduceLROnPlateau\n    from apex import amp\nexcept ImportError:\n    amp = None\n\n\nclass SAM_TrainingBox(TrainingBox):\n    def first_update_params(self, loss, **kwargs):\n        self.stage_grad_count += 1\n        if self.grad_accum_step > 1:\n            loss /= self.grad_accum_step\n\n        if self.accelerator is not None:\n            self.accelerator.backward(loss)\n        elif self.apex:\n            with amp.scale_loss(loss, self.optimizer) as scaled_loss:\n                scaled_loss.backward()\n        else:\n            loss.backward()\n\n        if self.stage_grad_count % self.grad_accum_step == 0:\n            if self.max_grad_norm is not None:\n                target_params = amp.master_params(self.optimizer) if self.apex \\\n                    else [p for group in self.optimizer.param_groups for p in group['params']]\n                torch.nn.utils.clip_grad_norm_(target_params, self.max_grad_norm)\n\n            # SAM optimizer\n            self.optimizer.first_step(zero_grad=True)\n            # self.optimizer.zero_grad()\n\n    def second_update_params(self, loss, **kwargs):\n        self.stage_grad_count += 1\n        if self.grad_accum_step > 1:\n            loss /= self.grad_accum_step\n\n        if self.accelerator is not None:\n            self.accelerator.backward(loss)\n        elif self.apex:\n            with amp.scale_loss(loss, self.optimizer) as scaled_loss:\n                scaled_loss.backward()\n        else:\n            loss.backward()\n\n        if self.stage_grad_count % self.grad_accum_step == 0:\n            if self.max_grad_norm is not None:\n                target_params = amp.master_params(self.optimizer) if self.apex \\\n                    else [p for group in self.optimizer.param_groups for p in group['params']]\n                torch.nn.utils.clip_grad_norm_(target_params, self.max_grad_norm)\n\n            # SAM optimizer\n            self.optimizer.second_step(zero_grad=True)\n            # self.optimizer.zero_grad()#\n\n\n\ndef get_training_box(model, data_loader_dict, train_config, device, device_ids, distributed,\n                     lr_factor, accelerator=None):\n    # if 'stage1' in train_config:\n    #     return MultiStagesTrainingBox(model, data_loader_dict,\n    #                                   train_config, device, device_ids, distributed, lr_factor, accelerator)\n    using_sam = True if train_config[\"optimizer\"][\"type\"] == \"SAMWrapper\" else False\n    if using_sam:\n        return SAM_TrainingBox(model, data_loader_dict, train_config, device, device_ids, distributed, lr_factor,\n                               accelerator)\n    else:\n        return TrainingBox(model, data_loader_dict, train_config, device, device_ids, distributed, lr_factor,\n                           accelerator)\n\n\n\"\"\"SAMここまで\"\"\"\n\n\n@register_dataset\nclass PLANT_2020(torch.utils.data.Dataset):\n    def __init__(self, inf, csv_path, transform=None, transform_params=None):\n        #\n        df = pd.read_csv(csv_path)\n        self.transform = util.build_transform(transform_params)\n        df[\"path\"] = df[\"image_id\"].apply(get_train_file_path)\n        self.df = df\n        if inf:\n            df[\"path\"] = df[\"image_id\"].apply(get_test_file_path)\n            self.labels = np.zeros(df.shape[0])\n        else:\n            df[\"path\"] = df[\"image_id\"].apply(get_train_file_path)\n            self.labels = df[[\"healthy\", \"multiple_diseases\", \"rust\", \"scab\"]].values\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        # print(self.transform)\n        file_name = self.df.loc[idx, \"path\"]\n        image = Image.open(file_name)\n        # image = cv2.imread(file_name)\n        # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        # image = cv2.resize(image, (256, 256)).transpose(2, 0, 1)\n\n        if self.transform:\n            # augmented = self.transform(image)\n            image = self.transform(image)\n        label = torch.tensor(self.labels[idx]).float()\n        image = image\n        return image, label\n\n\n@register_model_func\ndef timm_model(timm_model_name=None, num_classes=1, pretrained=False):\n    model = timm.create_model(timm_model_name, pretrained=pretrained, num_classes=num_classes)\n    return model\n\n\ndef get_argparser():\n    parser = argparse.ArgumentParser(description='Knowledge distillation for image classification models')\n    parser.add_argument('--config', required=True, help='yaml file path')\n    parser.add_argument('--device', default='cuda', help='device')\n    parser.add_argument('--log', help='log file path')\n    parser.add_argument('--start_epoch', default=0, type=int, metavar='N', help='start epoch')\n    parser.add_argument('--seed', type=int, help='seed in random number generator')\n    parser.add_argument('-sync_bn', action='store_true', help='use sync batch norm')\n    parser.add_argument('-test_only', action='store_true', help='only test the models')\n    parser.add_argument('-student_only', action='store_true', help='test the student model only')\n    # distributed training parameters\n    parser.add_argument('--world_size', default=1, type=int, help='number of distributed processes')\n    parser.add_argument('--dist_url', default='env://', help='url used to set up distributed training')\n    parser.add_argument('-adjust_lr', action='store_true',\n                        help='multiply learning rate by number of distributed processes (world_size)')\n    return parser\n\n\ndef load_model(model_config, device, distributed, sync_bn):\n    model = get_image_classification_model(model_config, distributed, sync_bn)\n    if model is None:\n        repo_or_dir = model_config.get('repo_or_dir', None)\n        model = get_model(model_config['name'], repo_or_dir, **model_config['params'])\n\n    ckpt_file_path = model_config['ckpt']\n    load_ckpt(ckpt_file_path, model=model, strict=True)\n    return model.to(device)\n\n\ndef train_one_epoch(training_box, device, epoch, log_freq, using_sam=False):\n    metric_logger = MetricLogger(delimiter='  ')\n    metric_logger.add_meter('lr', SmoothedValue(window_size=1, fmt='{value}'))\n    metric_logger.add_meter('img/s', SmoothedValue(window_size=10, fmt='{value}'))\n    header = 'Epoch: [{}]'.format(epoch)\n    for sample_batch, targets, supp_dict in \\\n            metric_logger.log_every(training_box.train_data_loader, log_freq, header):\n        start_time = time.time()\n        sample_batch, targets = sample_batch.to(device), targets.to(device)\n\n        # print(supp_dict)\n        if using_sam:\n            loss = training_box(sample_batch, targets, supp_dict)\n            training_box.first_update_params(loss)\n            loss = training_box(sample_batch, targets, supp_dict)\n            training_box.second_update_params(loss)\n        else:\n            loss = training_box(sample_batch, targets, supp_dict)\n            training_box.update_params(loss)\n\n        batch_size = sample_batch.shape[0]\n        metric_logger.update(loss=loss.item(), lr=training_box.optimizer.param_groups[0]['lr'])\n        metric_logger.meters['img/s'].update(batch_size / (time.time() - start_time))\n        if (torch.isnan(loss) or torch.isinf(loss)) and is_main_process():\n            # print(sample_batch.isnan().sum(), targets.isnan().sum(), supp_dict)\n            # print(training_box.model_forward_proc(training_box.model, sample_batch, targets, supp_dict))\n            raise ValueError('The training loop was broken due to loss = {}'.format(loss))\n\n\n@torch.no_grad()\ndef evaluate(model, data_loader, device, device_ids, distributed, log_freq=1000, title=None, header='Test:'):\n    model.to(device)\n    if distributed:\n        model = DistributedDataParallel(model, device_ids=device_ids)\n    elif device.type.startswith('cuda'):\n        model = DataParallel(model, device_ids=device_ids)\n\n    if title is not None:\n        logger.info(title)\n\n    model.eval()\n    metric_logger = MetricLogger(delimiter='  ')\n    batch_output = []\n    batch_target = []\n    for image, target in metric_logger.log_every(data_loader, log_freq, header):\n        image = image.to(device, non_blocking=True)\n        target = target.to(device, non_blocking=True)\n        output = model(image)\n        batch_output.append(output)\n        batch_target.append(target)\n\n    # gather the stats from all processes\n    metric_logger.synchronize_between_processes()\n    outputs = torch.cat(batch_output, dim=0)\n    targets = torch.cat(batch_target, dim=0)\n    auc = auroc(outputs, targets.int(), num_classes=4, pos_label=1)\n\n    logger.info(' * AUC {:.4f}\\n'.format(auc))\n    return auc, outputs\n\n\n@torch.no_grad()\ndef inference(model, data_loader, device, device_ids, distributed, log_freq=1000, title=None, header=\"Test:\"):\n    if distributed:\n        model = DistributedDataParallel(model, device_ids=device_ids)\n    elif device.type.startswith('cuda'):\n        model = DataParallel(model, device_ids=device_ids)\n    if title is not None:\n        logger.info(title)\n    model.eval()\n    batch_output = []\n    metric_logger = MetricLogger(delimiter='  ')\n\n    for image, _ in metric_logger.log_every(data_loader, log_freq, header):\n        image = image.to(device, non_blocking=True)\n        output = model(image)\n        batch_output.append(output)\n\n    outputs = torch.cat(batch_output, dim=0).cpu().numpy()\n\n    return outputs\n\n\ndef train(teacher_model, student_model, dataset_dict, ckpt_file_path, device, device_ids, distributed, config, args):\n    logger.info('Start training')\n    train_config = config['train']\n    lr_factor = args.world_size if distributed and args.adjust_lr else 1\n    training_box = get_training_box(student_model, dataset_dict, train_config,\n                                    device, device_ids, distributed, lr_factor) if teacher_model is None \\\n        else get_distillation_box(teacher_model, student_model, dataset_dict, train_config,\n                                  device, device_ids, distributed, lr_factor)\n    best_val_top1_accuracy = 0.0\n    optimizer, lr_scheduler = training_box.optimizer, training_box.lr_scheduler\n    if file_util.check_if_exists(ckpt_file_path):\n        best_val_top1_accuracy, _, _ = load_ckpt(ckpt_file_path, optimizer=optimizer, lr_scheduler=lr_scheduler)\n\n    log_freq = train_config['log_freq']\n    student_model_without_ddp = student_model.module if module_util.check_if_wrapped(student_model) else student_model\n    start_time = time.time()\n    for epoch in range(args.start_epoch, training_box.num_epochs):\n        training_box.pre_process(epoch=epoch)\n        # SAM optimizerを使うかどうか\n        using_sam = True if train_config[\"optimizer\"][\"type\"] == \"SAMWrapper\" else False\n        train_one_epoch(training_box, device, epoch, log_freq, using_sam=using_sam)\n        val_top1_accuracy, _ = evaluate(student_model, training_box.val_data_loader, device, device_ids, distributed,\n                                        log_freq=log_freq, header='Validation:')\n        if val_top1_accuracy > best_val_top1_accuracy and is_main_process():\n            logger.info('Best top-1 AUC: {:.4f} -> {:.4f}'.format(best_val_top1_accuracy, val_top1_accuracy))\n            logger.info('Updating ckpt at {}'.format(ckpt_file_path))\n            best_val_top1_accuracy = val_top1_accuracy\n            save_ckpt(student_model_without_ddp, optimizer, lr_scheduler,\n                      best_val_top1_accuracy, config, args, ckpt_file_path)\n        training_box.post_process()\n\n    if distributed:\n        dist.barrier()\n\n    total_time = time.time() - start_time\n    total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n    logger.info('Training time {}'.format(total_time_str))\n    training_box.clean_modules()\n\n\ndef make_submission_file(predictions, inf_config):\n    logger.info(\"Start saving\")\n\n    submission_file = pd.read_csv(inf_config[\"submission_file_path\"])\n    submission_file[[\"healthy\", \"multiple_diseases\", \"rust\", \"scab\"]] = predictions\n\n    submission_file.to_csv(inf_config[\"save_path\"], index=False)\n\n\ndef main(args):\n    log_file_path = args.log\n    if is_main_process() and log_file_path is not None:\n        setup_log_file(os.path.expanduser(log_file_path))\n\n    distributed, device_ids = init_distributed_mode(args.world_size, args.dist_url)\n    logger.info(args)\n    cudnn.benchmark = True\n    set_seed(args.seed)\n    config = yaml_util.load_yaml_file(os.path.expanduser(args.config))\n    device = torch.device(args.device)\n    dataset_dict = util.get_all_datasets(config['datasets'])\n    models_config = config['models']\n    teacher_model_config = models_config.get('teacher_model', None)\n    teacher_model = \\\n        load_model(teacher_model_config, device, distributed, False) if teacher_model_config is not None else None\n    student_model_config = \\\n        models_config['student_model'] if 'student_model' in models_config else models_config['model']\n    ckpt_file_path = student_model_config['ckpt']\n    student_model = load_model(student_model_config, device, distributed, args.sync_bn)\n    if not args.test_only:\n        train(teacher_model, student_model, dataset_dict, ckpt_file_path, device, device_ids, distributed, config, args)\n        student_model_without_ddp = \\\n            student_model.module if module_util.check_if_wrapped(student_model) else student_model\n        load_ckpt(student_model_config['ckpt'], model=student_model_without_ddp, strict=True)\n\n    inf_config = config['inf']\n    inf_data_loader_config = inf_config['inf_data_loader']\n    inf_data_loader = util.build_data_loader(dataset_dict[inf_data_loader_config['dataset_id']],\n                                             inf_data_loader_config, distributed)\n\n    inf_predictions = inference(student_model, inf_data_loader, device, device_ids, distributed,\n                                title='[Student: {}]'.format(student_model_config['name']))\n\n    make_submission_file(inf_predictions, inf_config)\n\n\nif __name__ == '__main__':\n    argparser = get_argparser()\n    main(argparser.parse_args())\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-10-16T14:51:29.235453Z","iopub.execute_input":"2021-10-16T14:51:29.235687Z","iopub.status.idle":"2021-10-16T14:51:29.257871Z","shell.execute_reply.started":"2021-10-16T14:51:29.235652Z","shell.execute_reply":"2021-10-16T14:51:29.25697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile config.yaml\ndatasets:\n  PLANT_2020:\n    name: &dataset_name \"PLANT_2020\"\n    type: *dataset_name\n    root: &root_dir \"../input/plant-pathology-2020-fgvc7\"\n    splits:\n      dummy:\n        dataset_id: \"dummy\"\n        params:\n          inf: False\n          csv_path: !join [ *root_dir, \"/train.csv\" ]\n        random_split:\n          lengths: [ 0.8, 0.2 ]\n          generator_seed: 42\n          sub_splits:\n            - dataset_id: &dataset_train !join [ *dataset_name, \"/train\" ]\n              transform_params:\n                - type: \"Resize\"\n                  params:\n                    size: [ 224, 224 ]\n                - &totensor\n                  type: \"ToTensor\"\n                  params:\n                - &normalize\n                  type: 'Normalize'\n                  params:\n                    mean: [ 0.49139968, 0.48215841, 0.44653091 ]\n                    std: [ 0.24703223, 0.24348513, 0.26158784 ]\n            - dataset_id: &dataset_val !join [ *dataset_name, \"/val\" ]\n              transform_params: &val_transform\n                - type: \"Resize\"\n                  params:\n                    size: [ 224, 224 ]\n                - *totensor\n                - *normalize\n      inf:\n        dataset_id: &dataset_inf !join [ *dataset_name, \"/inf\" ]\n        params:\n          inf: True\n          csv_path: !join [ *root_dir, \"/test.csv\" ]\n          transform_params: *val_transform\n\nmodels:\n  model:\n    name: \"timm_model\"\n    params:\n      timm_model_name: \"tf_efficientnet_b0_ns\"\n      num_classes: 4\n      pretrained: True\n\n    ckpt: \"model.ckpt\"\n\ntrain:\n  seed: 42\n  log_freq: 100\n  start_epoch: 0\n  num_epochs: 3\n\n  train_folds: [ 0 ]\n\n    #   optimizer:\n    #     type: \"SAMWrapper\"\n    #     params:\n    #       base_optim_name: \"Adam\"\n    #       base_optim_params:\n    #         lr: 0.001\n    #         momentum: 0.9\n    #         weight_decay: 0.00001\n    #       sam_params:\n    #         rho: 0.5\n    #         adaptive: True\n  optimizer:\n    type: \"Adam\"\n    params:\n      lr: 0.001\n\n  criterion:\n    type: \"GeneralizedCustomLoss\"\n    org_term:\n      criterion:\n        type: \"BCEWithLogitsLoss\"\n        params:\n      factor: 1.0\n\n  scheduler:\n    type: \"CosineAnnealingLR\"\n    params:\n      T_max: 6\n      eta_min: 0\n      last_epoch: -1\n\n  train_data_loader:\n    dataset_id: *dataset_train\n    random_sample: True\n    batch_size: 64\n    num_workers: 2\n\n  val_data_loader:\n    dataset_id: *dataset_val\n    random_sample: False\n    batch_size: 128\n    num_workers: 2\n\ntest:\n  test_data_loader:\n    dataset_id: *dataset_val\n    random_sample: False\n    batch_size: 32\n    num_workers: 2\ninf:\n  inf_data_loader:\n    dataset_id: *dataset_inf\n    random_sample: False\n    batch_size: 128\n    num_workers: 2\n\n  submission_file_path: !join [ *root_dir, \"/sample_submission.csv\" ]\n  save_path: \"submission.csv\"","metadata":{"execution":{"iopub.status.busy":"2021-10-16T14:52:19.226025Z","iopub.execute_input":"2021-10-16T14:52:19.226304Z","iopub.status.idle":"2021-10-16T14:52:19.237009Z","shell.execute_reply.started":"2021-10-16T14:52:19.226269Z","shell.execute_reply":"2021-10-16T14:52:19.236104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python distill.py --config config.yaml --device cuda --seed 10 -student_only --log log.log","metadata":{"execution":{"iopub.status.busy":"2021-10-16T14:52:20.319728Z","iopub.execute_input":"2021-10-16T14:52:20.319984Z","iopub.status.idle":"2021-10-16T14:57:30.978112Z","shell.execute_reply.started":"2021-10-16T14:52:20.319955Z","shell.execute_reply":"2021-10-16T14:57:30.977287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cat log.log","metadata":{"execution":{"iopub.status.busy":"2021-10-16T14:57:34.046055Z","iopub.execute_input":"2021-10-16T14:57:34.047036Z","iopub.status.idle":"2021-10-16T14:57:34.730419Z","shell.execute_reply.started":"2021-10-16T14:57:34.046982Z","shell.execute_reply":"2021-10-16T14:57:34.729654Z"},"trusted":true},"execution_count":null,"outputs":[]}]}