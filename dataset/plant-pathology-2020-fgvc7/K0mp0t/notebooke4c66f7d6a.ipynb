{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Если хотите работать на Google Colaboratory\n\nДля получения ключа доступа для API переходите\n*   https://www.kaggle.com/lkatran (где \"lkatran\" - ваш user name)\n*   нажимаем Edit Profile\n*   находим ниже раздел API\n*   нажимаем Create New API Token\n*   загружается файл kaggle.json\n*   в нем ваш ключ","metadata":{}},{"cell_type":"markdown","source":"Импорт библиотек","metadata":{}},{"cell_type":"code","source":"import math, re, os\n\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nfrom kaggle_datasets import KaggleDatasets\nimport tensorflow as tf\nimport tensorflow.keras.layers as L\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow.keras.applications import EfficientNetB7\n## ______________ КОНЕЦ БЛОКА С ИМПОРТАМИ АРХИТЕКТУР ____________________\n\n# импорт других полезных инструментов: слоев, оптимизаторов, функций обратной связи\nfrom tensorflow.keras.layers import Flatten,Dense,Dropout,BatchNormalization\nfrom tensorflow.keras.models import Model,Sequential\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-04T07:06:09.785941Z","iopub.execute_input":"2022-04-04T07:06:09.786525Z","iopub.status.idle":"2022-04-04T07:06:16.47877Z","shell.execute_reply.started":"2022-04-04T07:06:09.786428Z","shell.execute_reply":"2022-04-04T07:06:16.477908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Настраиваем TPU конфигурацию","metadata":{}},{"cell_type":"code","source":"AUTO = tf.data.experimental.AUTOTUNE\n# Проверяем существующее оборудование и выбираем соответствующую стратегию использования вычислений\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    # онаружение TPU. Параметры не требуются если установленна переменная окружения TPU_NAME. На Kaggle это всегда True.\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() # если TPU отсутствует, то испльзуем стратегию по умолчанию для TF (CPU or GPU)\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)\n\n# Путь к данным. Если работаете на Google Colaboratory, то замените KaggleDatasets().get_gcs_path() на путь к данным, который будет у вас\nGCS_DS_PATH = KaggleDatasets().get_gcs_path()\n\n# Конфигурация\nEPOCHS = 40\nBATCH_SIZE = 8 * strategy.num_replicas_in_sync\nIMG_SIZE = (512, 768)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T07:06:16.480367Z","iopub.execute_input":"2022-04-04T07:06:16.480638Z","iopub.status.idle":"2022-04-04T07:06:22.852796Z","shell.execute_reply.started":"2022-04-04T07:06:16.480608Z","shell.execute_reply":"2022-04-04T07:06:22.851879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Посмотрим на данные","metadata":{}},{"cell_type":"markdown","source":"## Загружаем метки классов и пути к изображениям","metadata":{}},{"cell_type":"code","source":"# функция, которая превращает айди картинки в полный путь к ней\ndef format_path(st):\n    return GCS_DS_PATH + '/images/' + st + '.jpg'","metadata":{"execution":{"iopub.status.busy":"2022-04-04T07:06:22.854913Z","iopub.execute_input":"2022-04-04T07:06:22.855276Z","iopub.status.idle":"2022-04-04T07:06:22.861225Z","shell.execute_reply.started":"2022-04-04T07:06:22.855232Z","shell.execute_reply":"2022-04-04T07:06:22.860072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/train.csv')\ntest = pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/test.csv')\nsub = pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/sample_submission.csv')\n\ntrain_paths = train.image_id.apply(format_path).values\ntest_paths = test.image_id.apply(format_path).values\n\ntrain_labels = train.loc[:, 'healthy':].values\n\n## если планируете обучать модель с валидирующим набором данных\ntrain_paths, valid_paths, train_labels, valid_labels = train_test_split(\n    train_paths, train_labels, test_size=0.15, random_state=2020)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T07:06:22.864446Z","iopub.execute_input":"2022-04-04T07:06:22.864804Z","iopub.status.idle":"2022-04-04T07:06:22.933237Z","shell.execute_reply.started":"2022-04-04T07:06:22.864761Z","shell.execute_reply":"2022-04-04T07:06:22.932155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\n\n# создаем сетку 2 на 5, для более компактного отображения символов и задаем размер их отображения\nf, ax = plt.subplots(3, 6, figsize=(18, 7))\nax = ax.flatten()\n# отрисовываем в цикле найденные топ N изображений частей графем\nfor i in range(18):\n    img = plt.imread(f'../input/plant-pathology-2020-fgvc7/images/Train_{i}.jpg')\n    ax[i].set_title(train[train['image_id']==f'Train_{i}'].melt()[train[train['image_id']==f'Train_{i}'].melt().value == 1]['variable'].values[0])\n    ax[i].imshow(img)\nprint(img.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T07:06:22.934708Z","iopub.execute_input":"2022-04-04T07:06:22.935227Z","iopub.status.idle":"2022-04-04T07:06:33.050536Z","shell.execute_reply.started":"2022-04-04T07:06:22.935183Z","shell.execute_reply":"2022-04-04T07:06:33.049783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Создаем объекты наборов данных\n\nA `tf.data.Dataset` объект нужен для того, чтобы модель бесперебойно работала на TPUs","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\n# функция, которая читает изображение из файла и преобразовывает его к нужному размеру, а так же нормализует\ndef decode_image(filename, label=None):\n    bits = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(bits, channels=3)\n    image = tf.cast(image, np.uint8)\n    image = tf.image.resize_with_pad(image, IMG_SIZE[0], IMG_SIZE[1])\n    \n    if label is None:\n        return image\n    else:\n        return image, label\n# функция расширения данных\n\n\ndef data_augment(image, label=None):\n#     image = tf.image.random_brightness(image, max_delta=0.5)\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    \n    if label is None:\n        return image\n    \n    return image, label","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2022-04-04T07:06:33.051821Z","iopub.execute_input":"2022-04-04T07:06:33.052225Z","iopub.status.idle":"2022-04-04T07:06:33.060065Z","shell.execute_reply.started":"2022-04-04T07:06:33.052194Z","shell.execute_reply":"2022-04-04T07:06:33.059028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Создаем объекты наборов данных для обучения, валидации и теста","metadata":{}},{"cell_type":"code","source":"train_dataset = tf.data.Dataset.from_tensor_slices((train_paths, train_labels))\n\n\ntrain_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((train_paths, train_labels))\n    .map(decode_image, num_parallel_calls=AUTO)\n    .map(data_augment, num_parallel_calls=AUTO) # если напишите свою функцию расширения данных data_augment \n    .repeat()\n    .shuffle(1024)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTO)\n)\n# если планируете обучать модель с валидирующим набором данных\nvalid_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((valid_paths, valid_labels))\n    .map(decode_image, num_parallel_calls=AUTO)\n    .batch(BATCH_SIZE)\n    .cache()\n    .prefetch(AUTO)\n)\n\ntest_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices(test_paths)\n    .map(decode_image, num_parallel_calls=AUTO)\n    .batch(BATCH_SIZE)\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T07:06:33.061458Z","iopub.execute_input":"2022-04-04T07:06:33.062327Z","iopub.status.idle":"2022-04-04T07:06:33.540504Z","shell.execute_reply.started":"2022-04-04T07:06:33.062281Z","shell.execute_reply":"2022-04-04T07:06:33.539713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Строим и обучаем модель","metadata":{}},{"cell_type":"markdown","source":"### Вспомогательные функции","metadata":{}},{"cell_type":"code","source":"LR_START = 0.0001\nLR_MAX = 0.00005 * strategy.num_replicas_in_sync\nLR_MIN = 0.0001\nLR_RAMPUP_EPOCHS = 10\nLR_SUSTAIN_EPOCHS = 4\nLR_EXP_DECAY = .8\n\nSTEPS_PER_EPOCH = len(train_paths) // BATCH_SIZE * 2\nVAL_STEPS_PER_EPOCH = len(valid_paths) // BATCH_SIZE\n\ndef lrfn(epoch):\n    if epoch < LR_RAMPUP_EPOCHS:\n        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n        lr = LR_MAX\n    else:\n        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n    return lr\n    \nlr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=True)\n\n# построим график изменения шага обучение в зависимости от эпох\nrng = [i for i in range(EPOCHS)]\ny = [lrfn(x) for x in rng]\nplt.plot(rng, y)\nprint(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))","metadata":{"execution":{"iopub.status.busy":"2022-04-04T07:06:33.541573Z","iopub.execute_input":"2022-04-04T07:06:33.541836Z","iopub.status.idle":"2022-04-04T07:06:33.78815Z","shell.execute_reply.started":"2022-04-04T07:06:33.541809Z","shell.execute_reply":"2022-04-04T07:06:33.787504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Загружаем модель на TPU","metadata":{}},{"cell_type":"code","source":"!pip install efficientnet","metadata":{"execution":{"iopub.status.busy":"2022-04-04T07:06:33.78917Z","iopub.execute_input":"2022-04-04T07:06:33.789937Z","iopub.status.idle":"2022-04-04T07:06:43.57644Z","shell.execute_reply.started":"2022-04-04T07:06:33.789905Z","shell.execute_reply":"2022-04-04T07:06:43.575509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import LeakyReLU, GaussianDropout\nfrom tensorflow.keras.models import Sequential\nfrom efficientnet.tfkeras import EfficientNetB7\n\ndef get_model(use_model):\n    model = Sequential()\n\n    base_model = use_model(weights='noisy-student', \n                      include_top=False, pooling='avg',\n                      input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n#     for layer in base_model.layers:\n#         if any(name in layer.name for name in ['block1', 'block2', 'block3', 'block4']):\n#             layer.trainable = False\n            \n    model.add(base_model)\n    model.add(Dense(4, activation='softmax'))\n    \n    return model\n\n\nwith strategy.scope():    \n    model = get_model(EfficientNetB7) # тут подставить свою модель\n        \nmodel.compile(\n    optimizer='nadam',\n    loss = 'categorical_crossentropy',\n    metrics=['categorical_accuracy']\n)\n# Визуализируем архитектуру модели\n# tf.keras.utils.plot_model(\n#     model, to_file='model.png', show_shapes=True, show_layer_names=True,\n# )","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:02.807543Z","iopub.execute_input":"2022-04-04T08:41:02.807933Z","iopub.status.idle":"2022-04-04T08:41:45.42817Z","shell.execute_reply.started":"2022-04-04T08:41:02.807899Z","shell.execute_reply":"2022-04-04T08:41:45.426765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:45.429155Z","iopub.status.idle":"2022-04-04T08:41:45.429896Z","shell.execute_reply.started":"2022-04-04T08:41:45.429648Z","shell.execute_reply":"2022-04-04T08:41:45.42971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Запускаем процесс обучения","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\n\nhistory = model.fit(train_dataset, validation_data=valid_dataset, \n          steps_per_epoch=STEPS_PER_EPOCH, validation_steps=VAL_STEPS_PER_EPOCH,\n          epochs=EPOCHS, \n          callbacks=[lr_callback, EarlyStopping(patience=10, restore_best_weights=True, min_delta=1e-4)],\n          workers=3)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-04-04T08:41:45.430975Z","iopub.status.idle":"2022-04-04T08:41:45.431742Z","shell.execute_reply.started":"2022-04-04T08:41:45.431473Z","shell.execute_reply":"2022-04-04T08:41:45.431501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Проверка качества модели","metadata":{}},{"cell_type":"code","source":"plt.plot(history.history['categorical_accuracy'], \n         label='Оценка точности на обучающем наборе')\nplt.plot(history.history['val_categorical_accuracy'], \n         label='Оценка точности на проверочном наборе')\nplt.xlabel('Эпоха обучения')\nplt.ylabel('Оценка точности')\nplt.legend()\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-04T07:45:48.710154Z","iopub.execute_input":"2022-04-04T07:45:48.710445Z","iopub.status.idle":"2022-04-04T07:45:48.981679Z","shell.execute_reply.started":"2022-04-04T07:45:48.710392Z","shell.execute_reply":"2022-04-04T07:45:48.980168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'], \n         label='Оценка потерь на обучающем наборе')\nplt.plot(history.history['val_loss'], \n         label='Оценка потерь на проверочном наборе')\nplt.xlabel('Эпоха обучения')\nplt.ylabel('Оценка потерь')\nplt.legend()\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-04T07:45:48.983166Z","iopub.execute_input":"2022-04-04T07:45:48.98389Z","iopub.status.idle":"2022-04-04T07:45:49.225327Z","shell.execute_reply.started":"2022-04-04T07:45:48.98384Z","shell.execute_reply":"2022-04-04T07:45:49.224346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Делаем прогноз тестовых данных и готовим представление данных для проверки","metadata":{}},{"cell_type":"markdown","source":"Когда вы получите несколько моделей с высокими баллами, можно поробовать их объеденить\n\nprobs = (model1.predict(test_dataset)+model.predict(test_dataset))/2\n\nгде можно использовать и больше моделей, но тогда делить не на 2, а на количество использованных моделей","metadata":{}},{"cell_type":"code","source":"probs = model.predict(test_dataset)\n# probs = (probs.max(axis=1,keepdims=1) == probs).astype(int)\n\n# assert probs.sum() == probs.shape[0]\n\nsub.loc[:, 'healthy':] = probs\nsub.to_csv('submission.csv', index=False)\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T07:45:49.226777Z","iopub.execute_input":"2022-04-04T07:45:49.227044Z","iopub.status.idle":"2022-04-04T07:47:16.325318Z","shell.execute_reply.started":"2022-04-04T07:45:49.227016Z","shell.execute_reply":"2022-04-04T07:47:16.324688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# создаем сетку 2 на 5, для более компактного отображения символов и задаем размер их отображения\nf, ax = plt.subplots(nrows=3, ncols=5, figsize=(18, 8))\n# отрисовываем в цикле найденные топ N изображений частей графем\nfor i in range(15):\n    img = plt.imread(f'../input/plant-pathology-2020-fgvc7/images/Test_{i}.jpg')\n    ax[i // 5, i % 5].set_title(sub[sub['image_id']==f'Test_{i}'].melt().iloc[1:][sub[sub['image_id']==f'Test_{i}'].melt().iloc[1:].value >= 0.8]['variable'].values[0])\n    ax[i // 5, i % 5].imshow(img)\nprint(img.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T07:47:16.326406Z","iopub.execute_input":"2022-04-04T07:47:16.326994Z","iopub.status.idle":"2022-04-04T07:47:24.997122Z","shell.execute_reply.started":"2022-04-04T07:47:16.32696Z","shell.execute_reply":"2022-04-04T07:47:24.996521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}