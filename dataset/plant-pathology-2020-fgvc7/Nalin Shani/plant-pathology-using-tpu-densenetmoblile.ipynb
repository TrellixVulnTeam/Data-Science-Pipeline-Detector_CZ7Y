{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Plant Pathology using TPU-DenseNetMoblile\nI have used the prebuild model in keras - Keras Application.Keras Applications are deep learning models that are made available alongside pre-trained weights. You can read more about them [here](https://keras.io/applications/).\n1. [Pre-processing Images](#head1)\n2. [CNN Model](#head2)\n  * [Load in pre-trained model](#head2a)\n  * [Add Final trainable layers to pre-built model](#head2b)\n  * [Learing Rate Scheduler](#head2c)\n3. [Evaluation and training curves.](#head3)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport cv2\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow\nfrom sklearn.model_selection import train_test_split\nfrom kaggle_datasets import KaggleDatasets\n%matplotlib inline\nscale_percent = 30\n# width = int(1365 * scale_percent / 100)\n# height = int(2048 * scale_percent / 100)\nwidth = 512\nheight = 512\ndim = (width, height)\ndim","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"AUTO = tf.data.experimental.AUTOTUNE\n\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\nbatch_size = 16*tpu_strategy.num_replicas_in_sync","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GCS_DS_PATH = KaggleDatasets().get_gcs_path()\nGCS_DS_PATH","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def ImageIDtodir(label):\n    return GCS_DS_PATH+'/images/' + label + '.jpg'\ntrain_df = pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/train.csv')\ntrain_dir = train_df['image_id'].apply(ImageIDtodir).values\ntest_df = pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/test.csv')\ntest_dir = test_df['image_id'].apply(ImageIDtodir).values\ny =  train_df.loc[:, 'healthy':].values\ntrain_dir, valid_dir, y_train, y_val = train_test_split(train_dir,y,test_size=0.15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <a name=\"head1\"></a>1.Pre-processing Images \nwe are using tensorflow tensor_from_slices to read images while training directly from the file.Images are reshaped to 512x512x3.\nI am also splitting the train images into training and validation with a validation split of 0.15.   \nThe train images are flipped randomly but no such pre-processing is done on validation or train images."},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_image(filename, label=None,image_size=(width,height)):\n    bits = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(bits, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0\n    image = tf.image.resize(image,image_size)   \n    if label is None:\n        return image\n    else:\n        return image, label\n    \n\ndef augment(image, label=None):\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    if label is None:\n        return image\n    else:\n        return image, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = (\n    tf.data.Dataset.from_tensor_slices((train_dir, y_train))\n    .map(load_image, num_parallel_calls=AUTO)\n    .cache()\n    .map(augment, num_parallel_calls=AUTO)\n    .repeat()\n    .shuffle(512)\n    .batch(batch_size)\n    .prefetch(AUTO)\n)\n\nvalid_dataset = (\n    tf.data.Dataset.from_tensor_slices((valid_dir,y_val))\n    .map(load_image, num_parallel_calls=AUTO)\n    .cache()\n    .batch(batch_size)\n    .prefetch(AUTO)\n)\n\ntest_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices(test_dir)\n    .map(load_image, num_parallel_calls=AUTO)\n    .cache()\n    .batch(batch_size)\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <a name=\"head2\"></a>2. CNN Model\n\n## A. <a name=\"head2a\"></a>Load in Pre-trained model.\nI have used the DenseNetMobile in-built model with pre-trained weights. You can read about other Keras Applications [here](https://keras.io/applications/#available-models).   "},{"metadata":{},"cell_type":"markdown","source":"## B. <a name=\"head2b\"></a>Add Final trainable Layers to pre-built model.\nAs we need to categories the images into 4 labels we need to add another layer to the model.     \nThe ouput of the DenseNet model which are essentially features extracted from the images are passed on to more layers-\n* A Global average pooling layer\n* A Dropout layer with rate 0.3\n* A Dense layer with 50 units and relu activation.\n* A Dense layer with 4 units and softmax activation.  \n   \nThe last layer is which gives out the precitions.   \n  "},{"metadata":{"trusted":true},"cell_type":"code","source":"with tpu_strategy.scope():\n    DenseNetModel = tf.keras.applications.DenseNet121(input_shape=(width,height,3),\n                                              weights='imagenet',\n                                              include_top=False)\n    model = tf.keras.models.Sequential(\n        [DenseNetModel,\n#             tf.keras.layers.Convolution2D(1024,(5,5),strides=(2,2),activation='relu'),\n#             tf.keras.layers.Convolution2D(2048,(4,4),strides=(2,2),activation='relu'),\n#             tf.keras.layers.AveragePooling2D((5,5),2),\n#             tf.keras.layers.AveragePooling2D((4,4),2),\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dropout(0.3),\n        tf.keras.layers.Dense(50, activation='relu'),\n        tf.keras.layers.Dense(4, activation='softmax')]\n    )\n    # Compile the model\n    model.compile(loss='categorical_crossentropy',\n                optimizer='adam',\n                metrics=['accuracy',tf.keras.metrics.AUC(name='auc')])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <a name=\"head2b\"></a> Learing Rate Scheduler\nWe have to reduce our learning mid-training as the "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Learning rate schedular\ndef lr_scheduler(epoch, lr):\n    decay_rate = 0.5\n    decay_step = 5\n    if epoch % decay_step == 0 and epoch:\n        return lr * decay_rate\n    return lr\ncallbacks = [\n    tf.keras.callbacks.LearningRateScheduler(lr_scheduler, verbose=1)\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(train_dataset,\n                    epochs=25,\n                    callbacks=callbacks,\n                    steps_per_epoch=y.shape[0] // batch_size,\n                    validation_data=valid_dataset)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <a name=\"head3\"></a>3. Evaluation and training Curves"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.title('Model accuracy')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict(test_dataset,verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp_df = pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/test.csv')\nsubmission = pd.DataFrame(\n    {'image_id': temp_df['image_id'],\n     'healthy': predictions[:,0],\n     'multiple_diseases': predictions[:,1],\n     'rust': predictions[:,2],\n     'scab': predictions[:,3],\n    })\nsubmission.to_csv(\"plant_pathology.csv\",index=False)\nsubmission","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}