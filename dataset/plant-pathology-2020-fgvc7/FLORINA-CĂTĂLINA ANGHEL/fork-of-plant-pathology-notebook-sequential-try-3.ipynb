{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom re import search\n\n# import tqdm in order to show a progress bar\nfrom tqdm  import tqdm\n\n# tensorflow and keras imports\nimport os\nimport warnings\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\nfrom tensorflow.keras import layers\nfrom keras.utils import to_categorical\n\n# import the libraries needed in order to handle the images\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport PIL\nimport pathlib\n\n# Confusion matrix\nfrom sklearn.metrics import confusion_matrix\n\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.computer_vision.ex5 import *\n\n# import the libraries needed for the files and directories\nimport glob\nimport shutil\n\nfrom matplotlib import gridspec\n\n# import the library used to create the datasets using the directories\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\n\n\nimport cv2\nfrom random import shuffle\nplt.style.use('fivethirtyeight')\n\nprint(\"Setup completed\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#run this cell only if the directories exist\n#shutil.rmtree(\"./train_images\")\n#shutil.rmtree(\"./validation_images\")\n#shutil.rmtree(\"./test_images\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMAGE_SIZE = 128\nCLASSES = ['0', '1', '2', '3']\nLR = 1e-3\nDIR = '../input/plant-pathology-2020-fgvc7/images'\nTRAIN_DATASET_SIZE = 1100","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_dataset = pd.read_csv('../input/plant-pathology-2020-fgvc7/train.csv')\nprint(train_dataset)\ntest_dataset = pd.read_csv('../input/plant-pathology-2020-fgvc7/test.csv')\nprint(test_dataset)\n\n# Convert the first image into an array\nimage = Image.open('../input/plant-pathology-2020-fgvc7/images/Test_0.jpg');\n#print(np.asarray(image))\nimg = plt.imshow(image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_dataset.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset['image_id'] = train_dataset['image_id'] + '.jpg'\nprint(train_dataset.shape)\nprint(train_dataset)\n#define the class names\nclass_names = train_dataset.loc[:, 'healthy':].columns\nprint(class_names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"counter = 0\ntrain_dataset['label'] = 0\nfor name in class_names:\n    train_dataset['label'] = train_dataset['label'] + train_dataset[name] * counter\n    counter = counter + 1\n    \nprint(train_dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sort the images based on label\ntrain_dataset_healthy = train_dataset[train_dataset.label == 0]\ntrain_dataset_multiple_diseases = train_dataset[train_dataset.label == 1]\ntrain_dataset_rust = train_dataset[train_dataset.label == 2]\ntrain_dataset_scab = train_dataset[train_dataset.label == 3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_dataset_healthy)\nprint(train_dataset_multiple_diseases)\nprint(train_dataset_rust)\nprint(train_dataset_scab)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_h = Image.open('../input/plant-pathology-2020-fgvc7/images/Train_4.jpg');\nimg_h = plt.imshow(image_h)\nplt.title(\"Healthy (label 0)\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_md = Image.open('../input/plant-pathology-2020-fgvc7/images/Train_1.jpg');\nimg_md = plt.imshow(image_md)\nplt.title(\"Multiple diseases (label 1)\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_r = Image.open('../input/plant-pathology-2020-fgvc7/images/Train_3.jpg');\nimg_r = plt.imshow(image_r)\nplt.title(\"Rust (label 2)\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_s = Image.open('../input/plant-pathology-2020-fgvc7/images/Train_0.jpg');\nimg_s = plt.imshow(image_s)\nplt.title(\"Scab (label 3)\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prepare for training"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_label_img(img):\n    if search(\"Train\", img):\n        label = train_dataset.loc[train_dataset[\"image_id\"] == img]['label']\n        return label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install natsort","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Step 1**\n\nCreate the train dataset by sorting the images based on their name and class"},{"metadata":{"trusted":true},"cell_type":"code","source":"import natsort\ndef create_train_data():\n    count = 0\n    images = natsort.natsorted(os.listdir(DIR))\n    for img in tqdm(images):\n        label = get_label_img(img)\n        path = os.path.join(DIR, img)\n        #image_name = img\n        #img = cv2.resize(cv2.imread(path, cv2.IMREAD_GRAYSCALE), (IMAGE_SIZE, IMAGE_SIZE))\n        \n        if search(\"Train\", img):\n            if int(img.split(\"_\")[1].split(\".\")[0]) < TRAIN_DATASET_SIZE and label.item() == 0 :\n                shutil.copy(path, './train_images/healthy')\n            elif int(img.split(\"_\")[1].split(\".\")[0]) < TRAIN_DATASET_SIZE and label.item() == 1:\n                shutil.copy(path, './train_images/multiple_diseases')\n            elif int(img.split(\"_\")[1].split(\".\")[0]) < TRAIN_DATASET_SIZE and label.item() == 2:\n                shutil.copy(path, './train_images/scab')\n            elif int(img.split(\"_\")[1].split(\".\")[0]) < TRAIN_DATASET_SIZE and label.item() == 3:\n                shutil.copy(path, './train_images/rust')\n            elif int(img.split(\"_\")[1].split(\".\")[0]) >= TRAIN_DATASET_SIZE and label.item() == 0:\n                shutil.copy(path, './validation_images/healthy')\n            elif int(img.split(\"_\")[1].split(\".\")[0]) >= TRAIN_DATASET_SIZE and label.item() == 1:\n                shutil.copy(path, './validation_images/multiple_diseases')\n            elif int(img.split(\"_\")[1].split(\".\")[0]) >= TRAIN_DATASET_SIZE and label.item() == 2:\n                shutil.copy(path, './validation_images/scab')\n            elif int(img.split(\"_\")[1].split(\".\")[0]) >= TRAIN_DATASET_SIZE and label.item() == 3:\n                shutil.copy(path, './validation_images/rust')\n        elif search(\"Test\", img):\n            shutil.copy(path, './test_images/images') ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Step 2**\n\nCreate the directories and call the create_train_data() method in order to start creating the training/validation/testing datasets"},{"metadata":{"trusted":true},"cell_type":"code","source":"shutil.os.mkdir('./train_images')\nshutil.os.mkdir('./test_images')\nshutil.os.mkdir('./test_images/images')\nshutil.os.mkdir('./validation_images')\nshutil.os.mkdir('./train_images/healthy')\nshutil.os.mkdir('./train_images/multiple_diseases')\nshutil.os.mkdir('./train_images/scab')\nshutil.os.mkdir('./train_images/rust')\nshutil.os.mkdir('./validation_images/healthy')\nshutil.os.mkdir('./validation_images/multiple_diseases')\nshutil.os.mkdir('./validation_images/scab')\nshutil.os.mkdir('./validation_images/rust')\ntrain_data = create_train_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"filenames = glob.glob(\"./validation_images/rust/*.jpg\")\nfilenames.sort()\nfilenames = glob.glob(\"./validation_images/healthy/*.jpg\")\nfilenames.sort()\nfilenames = glob.glob(\"./validation_images/scab/*.jpg\")\nfilenames.sort()\nfilenames = glob.glob(\"./validation_images/multiple_diseases/*.jpg\")\nfilenames.sort()\nprint(filenames)"},{"metadata":{},"cell_type":"markdown","source":"# Models"},{"metadata":{},"cell_type":"markdown","source":"**1. The first model**\n\nOld model accuracy: 66%"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"import tensorflow.keras.layers.experimental.preprocessing as preprocessing\n# keras\nmodel = keras.Sequential([\n    preprocessing.RandomFlip('horizontal'), # flip left-to-right\n    preprocessing.RandomContrast(0.5),\n    # Block One\n    layers.Conv2D(filters=32, kernel_size=3, activation='relu', padding='same',\n                  input_shape=[IMAGE_SIZE, IMAGE_SIZE, 3]),\n    layers.MaxPool2D(2, 2),\n    layers.Dropout(0.1),\n\n    # Block Two\n    layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'),\n    layers.MaxPool2D(2, 2),\n    layers.Dropout(0.3),\n\n    # Block Three\n    layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'),\n    #layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'),\n    layers.MaxPool2D(2, 2),\n    layers.Dropout(0.3),\n\n\n    # Head\n    layers.Flatten(),\n    layers.Dense(128, activation='selu'),\n    layers.Dense(4, activation='softmax'),\n])\n"},{"metadata":{},"cell_type":"markdown","source":"**2. The second model**"},{"metadata":{},"cell_type":"markdown","source":"import tensorflow.keras.layers.experimental.preprocessing as preprocessing\n# keras\nmodel = keras.Sequential([\n    preprocessing.RandomFlip('horizontal'), # flip left-to-right\n    preprocessing.RandomContrast(0.5),\n    # Block One\n    layers.Conv2D(filters=32, kernel_size=3, activation='relu', padding='same',\n                  input_shape=[IMAGE_SIZE, IMAGE_SIZE, 3]),\n    layers.MaxPool2D(pool_size=4,\n                     strides=2,\n                     padding='same'),\n    layers.Dropout(0.2),\n\n    # Block Two\n    layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'),\n    layers.MaxPool2D(pool_size=4,\n                     strides=2,\n                     padding='same'),\n    layers.Dropout(0.3),\n\n    # Block Three\n    layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'),\n    layers.MaxPool2D(pool_size=4,\n                     strides=2,\n                     padding='same'),\n    layers.Dropout(0.5),\n\n\n    # Head\n    layers.Flatten(),\n    layers.Dense(128, activation='selu'),\n    layers.Dense(4, activation='softmax'),\n])"},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"**3. The third model**\n\nThe loss was too high and the difference between the accuracy for the training data and the accuracy for the validation data was too big, so the model was overfitted"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"import tensorflow.keras.layers.experimental.preprocessing as preprocessing\n# keras\nmodel = keras.Sequential([\n    preprocessing.RandomFlip('horizontal'), # flip left-to-right\n    preprocessing.RandomContrast(0.5),\n    # Block One\n    layers.Conv2D(filters=32, kernel_size=3, activation='relu', padding='same',\n                  input_shape=[IMAGE_SIZE, IMAGE_SIZE, 3]),\n    layers.MaxPool2D(pool_size=4, strides=2),\n\n    # Block Two\n    layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'),\n    layers.MaxPool2D(pool_size=4, strides=2),\n\n    # Block Three\n    layers.Conv2D(filters=128, kernel_size=3, activation='relu'),\n    layers.MaxPool2D(pool_size=4, strides=2),\n\n    layers.Dropout(0.5),\n    # Head\n    layers.Flatten(),\n    layers.Dense(128, activation='selu'),\n    layers.Dense(4, activation='softmax'),\n])\n"},{"metadata":{},"cell_type":"markdown","source":"**4. This is the best model so far**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow.keras.layers.experimental.preprocessing as preprocessing\n# keras\nmodel = keras.Sequential([\n    preprocessing.RandomFlip('horizontal'), # flip left-to-right\n    preprocessing.RandomContrast(0.5),\n    # Block One\n    layers.Conv2D(filters=32, kernel_size=3, activation='relu', padding='same',\n                  input_shape=[IMAGE_SIZE, IMAGE_SIZE, 3]),\n    layers.MaxPool2D(pool_size=4,\n                     strides=2,\n                     padding='same'),\n    layers.Dropout(0.2),\n\n    # Block Two\n    layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'),\n    layers.MaxPool2D(pool_size=4,\n                     strides=2,\n                     padding='same'),\n    layers.Dropout(0.4),\n\n    # Block Three\n    layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'),\n    layers.MaxPool2D(pool_size=4,\n                     strides=2,\n                     padding='same'),\n\n    # Head\n    layers.Flatten(),\n    layers.Dense(128, activation='selu'),\n    layers.Dense(4, activation='softmax'),\n])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create the datasets using the directories created earlier"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set Matplotlib defaults\nplt.rc('figure', autolayout=True)\nplt.rc('axes', labelweight='bold', labelsize='large',\n       titleweight='bold', titlesize=18, titlepad=10)\nplt.rc('image', cmap='magma')\nwarnings.filterwarnings(\"ignore\") # to clean up output cells\n\n\n# Load training and validation sets\nds_train_ = image_dataset_from_directory(\n    './train_images',\n    labels='inferred',\n    label_mode='int',\n    image_size=[IMAGE_SIZE, IMAGE_SIZE],\n    interpolation='nearest',\n    batch_size=64\n)\nds_valid_ = image_dataset_from_directory(\n    './validation_images',\n    labels='inferred',\n    label_mode='int',\n    image_size=[IMAGE_SIZE, IMAGE_SIZE],\n    interpolation='nearest',\n    batch_size=64\n)\n\nds_test_ = image_dataset_from_directory(\n    './test_images',\n    image_size=[IMAGE_SIZE, IMAGE_SIZE],\n    label_mode=None,\n    interpolation='nearest',\n    batch_size=64\n)\n\n# Data Pipeline\ndef convert_to_float(image, label):\n    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n    return image, label\n\ndef convert_to_float_test(image):\n    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n    return image\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create the prefetch datasets"},{"metadata":{"trusted":true},"cell_type":"code","source":"AUTOTUNE = tf.data.experimental.AUTOTUNE\nds_train = (\n    ds_train_\n    .map(convert_to_float)\n    .cache()\n    .prefetch(buffer_size=AUTOTUNE)\n)\nds_valid = (\n    ds_valid_\n    .map(convert_to_float)\n    .cache()\n    .prefetch(buffer_size=AUTOTUNE)\n)\nds_test = (\n    ds_test_\n    .map(convert_to_float_test)\n    .cache()\n    .prefetch(buffer_size=AUTOTUNE)\n)\nprint(type(ds_test))\nprint(type(ds_train))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Compile the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(\n    optimizer=tf.keras.optimizers.Adam(epsilon=0.01, learning_rate=LR),\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fit the model using 50 epochs"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nhistory = model.fit(\n    ds_train,\n    validation_data=ds_valid,\n    epochs=75\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plot the loss and the accuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nhistory_frame = pd.DataFrame(history.history)\nhistory_frame.loc[:, ['loss', 'val_loss']].plot()\nhistory_frame.loc[:, ['accuracy', 'val_accuracy']].plot();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Make predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"probabilities = model.predict(ds_valid)\npredictions = np.argmax(probabilities, axis=-1)\nprint(predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(probabilities)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Find the real classes"},{"metadata":{"trusted":true},"cell_type":"code","source":"true = []\nfor example in ds_valid:\n    for i in example[1].numpy():\n        true.append(i)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Evaluate the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_roc_curve(fpr, tpr):\n    plt.plot(fpr, tpr, color='orange', label='ROC')\n    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for element in probabilities:\n    position = np.argmax(element)\n    for i in range(4):\n        if(i == position):\n            element[i] = 1\n        else:\n            element[i] = 0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Compute the ROC AUC score (Receiver Operating Characteristic score)\n\nROC curves typically feature true positive rate on the Y axis, and false positive rate on the X axis."},{"metadata":{"trusted":true},"cell_type":"code","source":"roc_auc_score(true, probabilities, multi_class='ovr')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"conf_matrix = confusion_matrix(true, predictions, labels=[0, 1, 2, 3])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    import itertools\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot non-normalized confusion matrix\nplt.figure()\n\nplot_confusion_matrix(conf_matrix, classes=[0, 1, 2, 3],\n                      title='Confusion matrix')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print((\"Best Validation Loss: {:0.4f}\" +\\\n    \"\\nBest Validation Accuracy: {:0.4f}\")\\\n      .format(history_frame['val_loss'].min(), \n              history_frame['val_accuracy'].max()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_results(dataset):\n    categories = ['healthy', 'multiple diseases', 'rust', 'scab']\n    fig = plt.figure()\n    subplot_counter = 0\n    for num, data in list(dataset):\n        for i, j, k in zip(num.numpy(), list(data), predictions):\n            if(subplot_counter <= 32):\n                subplot_counter = subplot_counter+1\n                predicted_category = categories[k]\n                #plt.figure(figsize = (6, 8))\n                plt.imshow(i, interpolation='nearest')\n                plt.title(\"Predicted:\" + predicted_category + \"\\n Actual:\" + categories[j])\n                plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# The results for the validation images"},{"metadata":{"trusted":true},"cell_type":"code","source":"display_results(ds_valid)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predict the desease for the test images"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Computing predictions...')\ntest_probabilities = model.predict(ds_test)\nprint('Finished computing predictions...')\nprint(test_probabilities)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_predictions = np.argmax(probabilities, axis=-1)\nprint(test_predictions)\nlist(ds_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Display the test results"},{"metadata":{"trusted":true},"cell_type":"code","source":"categories = ['healthy', 'multiple diseases', 'rust', 'scab']\nfig = plt.figure()\nsubplot_counter = 0\nfor num in list(ds_test):\n    for image, prediction in zip(num.numpy(), test_predictions):\n        if(subplot_counter <= 32):\n            subplot_counter = subplot_counter+1\n            predicted_category = categories[prediction]\n            plt.figure(figsize = (6, 8))\n            plt.imshow(image, interpolation='nearest')\n            plt.title(predicted_category)\n            plt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}