{"cells":[{"metadata":{"_uuid":"7f125fde-43c9-4b5d-82cb-fad66698b91c","_cell_guid":"32bf3d6c-7891-477c-8ba4-6ca1f3fd332e","trusted":true},"cell_type":"code","source":"# Import library\nimport cv2\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\ntqdm.pandas()\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import ImageDataGenerator\n!pip install efficientnet pandarallel\nimport efficientnet.tfkeras as efn \nimport tensorflow as tf\nimport tensorflow.keras as keras\nfrom pandarallel import pandarallel\npandarallel.initialize(progress_bar=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"USE_TPU = 'TPU_NAME' in os.environ\nif USE_TPU:\n    # detect and init the TPU\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n\n    # instantiate a distribution strategy\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n    tf.compat.v1.enable_eager_execution()\nelse:\n    strategy = tf.distribute.MirroredStrategy()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"db1e8032-8d76-434b-9728-fd11bf28979a","_cell_guid":"a688515a-1bd8-4d5a-93b0-7286f7521962","trusted":true},"cell_type":"code","source":"# Read data\nIMAGE_PATH = \"../input/plant-pathology-2020-fgvc7/images/\"\nTEST_PATH = \"../input/plant-pathology-2020-fgvc7/test.csv\"\nTRAIN_PATH = \"../input/plant-pathology-2020-fgvc7/train.csv\"\nSUB_PATH = \"../input/plant-pathology-2020-fgvc7/sample_submission.csv\"\n\nsub = pd.read_csv(SUB_PATH)\ntest_data = pd.read_csv(TEST_PATH)\ntrain_data = pd.read_csv(TRAIN_PATH)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def init_grabcut_mask(h, w):\n    mask = np.ones((h, w), np.uint8) * cv2.GC_PR_BGD\n    mask[h//4:3*h//4, w//4:3*w//4] = cv2.GC_PR_FGD\n    mask[2*h//5:3*h//5, 2*w//5:3*w//5] = cv2.GC_FGD\n    #mask[h//2, w//2] = cv2.GC_FGD\n    return mask\n\n\ndef remove_background(image, h=136, w=205):\n    orig_image = image\n    image = cv2.resize(image, (w, h))\n    mask = init_grabcut_mask(h, w)\n    bgm = np.zeros((1, 65), np.float64)\n    fgm = np.zeros((1, 65), np.float64)\n    cv2.grabCut(image, mask, None, bgm, fgm, 1, cv2.GC_INIT_WITH_MASK)\n    mask_binary = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')\n    h, w = orig_image.shape[:2]\n    mask_binary = cv2.resize(mask_binary, (w, h))\n    result = cv2.bitwise_and(orig_image, orig_image, mask=mask_binary)\n    return result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rotate(x: tf.Tensor) -> tf.Tensor:\n    \"\"\"Rotation augmentation\n\n    Args:\n        x: Image\n\n    Returns:\n        Augmented image\n    \"\"\"\n    shape = tf.shape(x)[:-1]\n\n    # Rotate 0, 90, 180, 270 degrees\n    x = tf.image.rot90(x, tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n    return tf.image.resize(x, shape)\n\n\ndef flip(x: tf.Tensor) -> tf.Tensor:\n    \"\"\"Flip augmentation\n\n    Args:\n        x: Image to flip\n\n    Returns:\n        Augmented image\n    \"\"\"\n    x = tf.image.random_flip_left_right(x)\n    x = tf.image.random_flip_up_down(x)\n\n    return x\n\n\ndef color(x: tf.Tensor) -> tf.Tensor:\n    \"\"\"Color augmentation\n\n    Args:\n        x: Image\n\n    Returns:\n        Augmented image\n    \"\"\"\n    x = tf.image.random_hue(x, 0.08)\n    x = tf.image.random_saturation(x, 0.6, 1.6)\n    x = tf.image.random_brightness(x, 0.05)\n    x = tf.image.random_contrast(x, 0.7, 1.3)\n    return x\n\n\ndef zoom(x: tf.Tensor) -> tf.Tensor:\n    \"\"\"Zoom augmentation\n\n    Args:\n        x: Image\n\n    Returns:\n        Augmented image\n    \"\"\"\n    shape = tf.shape(x)[:-1]\n\n    # Generate 20 crop settings, ranging from a 1% to 20% crop.\n    scales = list(np.arange(0.8, 1.0, 0.01))\n    boxes = np.zeros((len(scales), 4))\n\n    for i, scale in enumerate(scales):\n        x1 = y1 = 0.5 - (0.5 * scale)\n        x2 = y2 = 0.5 + (0.5 * scale)\n        boxes[i] = [x1, y1, x2, y2]\n\n    def random_crop(img):\n        # Create different crops for an image\n        crops = tf.image.crop_and_resize([img], boxes=boxes, box_indices=np.zeros(len(scales)), crop_size=(408, 615))\n        # Return a random crop\n        return crops[tf.random.uniform(shape=[], minval=0, maxval=len(scales), dtype=tf.int32)]\n\n\n    choice = tf.random.uniform(shape=[], minval=0., maxval=1., dtype=tf.float32)\n\n    # Only apply cropping 50% of the time\n    x = tf.cond(choice < 0.5, lambda: x, lambda: random_crop(x))\n    \n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_data_generators(preprocess=True, augment=True, IMAGE_SIZE=(408, 615), nfolds=5):\n    \n    def load_image(image_id):\n        file_path = image_id + \".jpg\"\n        image = cv2.imread(IMAGE_PATH + file_path)\n        image = cv2.resize(image, IMAGE_SIZE[::-1])\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        if preprocess:\n            image = remove_background(image)\n        return image\n\n    print(\"Preprocessing training images...\")\n    train_images = np.stack(train_data[\"image_id\"].parallel_apply(load_image))\n    plt.imshow(train_images[0])\n    labels = train_data[['healthy', 'multiple_diseases', 'rust', 'scab']]\n    dataset = tf.data.Dataset.from_tensor_slices((train_images, np.stack(labels.values)))\n    \n    def map_func(image, label):\n        image = tf.cast(image, tf.float32) / 255\n        label = (tf.cast(label, tf.float32) + 0.01) / 1.04\n        return image, label\n    dataset = dataset.map(map_func, \n                          num_parallel_calls=tf.data.experimental.AUTOTUNE, \n                          deterministic=True)\n\n    if augment:\n        # Add augmentations\n        augmentations = [flip, color, rotate, zoom]\n    \n        # Add the augmentations to the dataset\n        for f in augmentations:\n            # Apply the augmentation, run 4 jobs in parallel.\n            dataset = dataset.map(lambda x, y: (f(x), y),\n                                  num_parallel_calls=tf.data.experimental.AUTOTUNE, \n                                  deterministic=True)\n\n        # Make sure that the values are still in [0, 1]\n        dataset = dataset.map(lambda x, y: (tf.clip_by_value(x, 0, 1), y), \n                              num_parallel_calls=tf.data.experimental.AUTOTUNE, \n                              deterministic=True)\n    \n    fold_size = len(train_data) // nfolds\n    folds = []\n    for idx in range(nfolds):\n        fold = dataset.take(fold_size)\n        folds.append(fold)\n        dataset = dataset.skip(fold_size)\n    \n    print(\"Preprocessing test images...\")\n    test_images = np.stack(test_data[\"image_id\"].parallel_apply(load_image))\n    test = tf.data.Dataset.from_tensor_slices((np.stack(test_images,)))\n    \n    test = test.map(lambda image: tf.cast(image, tf.float32) / 255, \n                    num_parallel_calls=tf.data.experimental.AUTOTUNE, \n                    deterministic=False)\n    test = test.batch(32).prefetch(2)\n    \n    return folds, test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"folds, test = get_data_generators(False, True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model(): \n    model = keras.Sequential()\n    model.add(efn.EfficientNetB7(\n        include_top=False, weights='imagenet', input_tensor=None, input_shape=None,\n        pooling=None, classes=4))\n    model.add(keras.layers.GlobalAveragePooling2D())\n    model.add(keras.layers.Dense(128, activation=\"relu\"))\n    model.add(keras.layers.Dense(64, activation=\"relu\"))\n    model.add(keras.layers.Dense(4, activation=\"softmax\"))\n    model.summary()\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with strategy.scope():\n    model = get_model()\n    model.compile(\n        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n        loss=keras.losses.categorical_crossentropy,\n        metrics=[keras.metrics.categorical_accuracy])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, CSVLogger, Callback\n\ncallbacks = [\n    EarlyStopping(monitor='val_loss', mode='min', patience=10),\n    ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=5, min_lr=0.000001),\n    CSVLogger('log.csv', append=True, separator=';')\n    #TensorBoard(log_dir=\"tensorboard/\")\n]\n\ndef get_train_val_split(val_fold):\n    train_folds = folds[:val_fold] + folds[val_fold + 1:]\n    train = train_folds[0]\n    for fold in train_folds[1:]:\n        train = train.concatenate(fold)\n    val = folds[val_fold]\n    return train, val\n\nsplits = [get_train_val_split(i) for i in range(len(folds))]\ntrain, val = splits[0]\nfor t, v in splits[1:]:\n    train = train.concatenate(t)\n    val = val.concatenate(v)\ntrain = train.repeat().batch(32).prefetch(2)\nval = val.repeat().batch(32).prefetch(2)\n\nhistory = model.fit(train,                                    \n                    steps_per_epoch=47, \n                    epochs=50,\n                    validation_data=val,\n                    validation_steps=12,\n                    validation_freq=1,\n                    verbose=1,\n                    callbacks=callbacks)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aa70985d-d4ee-456c-91c1-7cb66cd5edc7","_cell_guid":"d8136a22-cfbb-41bc-928a-1e409fb27f6b","trusted":true},"cell_type":"code","source":"# Submission\ntest_pr = model.predict(test, verbose=1)\nsub.loc[:, 'healthy':] = test_pr\nsub.to_csv('submission.csv', index=False)\nsub.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}