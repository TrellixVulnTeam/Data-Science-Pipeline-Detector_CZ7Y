{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Import Libraries"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# NumPyの読み込み\nimport numpy as np\n# Pandasの読み込み\nimport pandas as pd \n# OSモジュール:プログラムの中でOSの時間を利用したり、ディレクトリにアクセスしてファイルの作成/編集/削除などができる\nimport os\n# OpenCV:画像を処理するのに必要な様々な機能を提供するライブラリ\nimport cv2\n# matplotlib:NumPyのためのグラフ描画パッケージ\n# pyplot:ほしいプロットを作るために暗黙的かつ自動的に図形や軸を作成するモジュール\nfrom matplotlib import pyplot as plt\n# TPUの場合、データはGoogle Cloud Storageのみアクセスできるため、使用\nfrom kaggle_datasets import KaggleDatasets\n\n# tensorflow:ニューラルネットの主なライブラリ\n# keras:単体では使うことのできないライブラリ。tensorflowが必要\nimport tensorflow as tf\n# Sequential:ニューラルネットワークの構造を簡略化するモデルの一つ\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import layers as L\nfrom tensorflow.keras.utils import to_categorical\n\n# train_test_split:trainデータとtestデータに分けるモジュール\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn import metrics\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# TPU setup"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# \n# TPUの初期化\n# \n# 例外処理のtry\ntry:\n#     TPUのハードウェア情報を獲得。TPUが利用できない環境ではエラー\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n#     TPU利用可能化の確認\n    print('Running on TPU:', tpu.master())\n# 上記でエラー（例外）が出た場合の処理\nexcept ValueError:\n    tpu = None\n\n# tpuが利用できる場合（Accelerator TPU）\n# 上記でNoneでないとき\nif tpu:\n#   リモートクラスタに接続してTPUを初期化\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n#   データの並列処理を使用してトレーニングを分散する\n#   TPUで並列処理の方法\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n# TPUなしのとき（Accelerator None）\nelse:\n    strategy = tf.distribute.get_strategy()\n\n# 並列処理のレベルに関する決定をAUTOで行う\nAUTO = tf.data.experimental.AUTOTUNE\n# TPUはGCS(Google Cloud Storage)にのみアクセスできる。\nGCS_DS_PATH = KaggleDatasets().get_gcs_path()\n\n# ミニバッチ勾配降下法を行う際、データセットを幾つかのサブセットに分ける\n# サブセットの勾配の平均で重みを更新する\n# そのサブセットの大きさをBatch Sizeと呼ぶ\n# strategy.num_replicas_in_syncはstrategyの分割したTPUレプリカの数を表す。\n# TPUが使用可能な場合、レプリカ数は8であるから8倍した数をバッチサイズとする。\n# TPU使用不可の時、レプリカ数は1となり、バッチサイズは8\nBATCH_SIZE = 8 * strategy.num_replicas_in_sync\nIMG_SIZE = 768\n\nprint('Batch size:', BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Get train and test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/train.csv')\ntest = pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/test.csv')\nsub = pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/sample_submission.csv')\n\nprint(train.head())\n\n# GCSでimageのパス指定\ntrain_path = train.image_id.apply(lambda x: f'{GCS_DS_PATH}/images/{x}.jpg').values\ntest_path = test.image_id.apply(lambda x: f'{GCS_DS_PATH}/images/{x}.jpg').values\n# trainのimage_idを削除し、arrayに\ntrain_label = train.loc[:, 'healthy':].values\n\n# train_path, valid_path, train_label, valid_label = train_test_split(train_path, train_label,\n#                                                                     test_size=0.1, stratify=train_label)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Get class weights"},{"metadata":{"trusted":true},"cell_type":"code","source":"# weightをかけると全データ数の1/4になる\n# n_samples[1821] / (n_classes[4] * np.bincount(y)[healthy:516/multi:91/rust:622/scab:592])\nclass_weight = compute_class_weight('balanced', np.unique(np.argmax(train_label, axis=1)), np.argmax(train_label, axis=1))\n# barplotの作成\nplt.bar(range(4), class_weight)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Lets see some images"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 2×2で表示\nfig, ax = plt.subplots(2, 2)\n# サンプル読み込み\nimg = cv2.imread('/kaggle/input/plant-pathology-2020-fgvc7/images/Train_0.jpg')\nimg1 = cv2.imread('/kaggle/input/plant-pathology-2020-fgvc7/images/Train_1.jpg')\nimg2 = cv2.imread('/kaggle/input/plant-pathology-2020-fgvc7/images/Train_2.jpg')\nimg3 = cv2.imread('/kaggle/input/plant-pathology-2020-fgvc7/images/Train_3.jpg')\n# 場所指定した書き出し\nax[0, 0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\nax[0, 1].imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))\nax[1, 0].imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))\nax[1, 1].imshow(cv2.cvtColor(img3, cv2.COLOR_BGR2RGB))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Decode images"},{"metadata":{"trusted":true},"cell_type":"code","source":"# デコードの定義\ndef decode_image(filename, label=None, image_size=(IMG_SIZE, IMG_SIZE)):\n#     生データを読み込み\n    bits = tf.io.read_file(filename)\n#     画像のテンソルにデコード\n    image = tf.image.decode_jpeg(bits, channels=3)\n#     0-255のRGBを0-1にするnormalize\n    image = tf.cast(image, tf.float32) / 255.0\n#     1365×2048の画像を、768×768にする\n    image = tf.image.resize(image, image_size)\n    \n#     条件式の意味はわかりませんが変換したimageをreturn\n    if label is None:\n        return image\n    else:\n        return image, label\n\n# augmentの定義\ndef data_augment(image, label=None):\n#     ランダムに水平方向に反転\n    image = tf.image.random_flip_left_right(image)\n#     ランダムに垂直方向に反転\n    image = tf.image.random_flip_up_down(image)\n    \n#     imageをreturn\n    if label is None:\n        return image\n    else:\n        return image, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 教師データをデコード\ntrain_dataset = (\n#     TFR形式でデータを読み書きする\n    tf.data.TFRecordDataset\n#     配列をスライスしてデータセットを構築する\n    .from_tensor_slices((train_path, train_label))\n#     データ変換（デコード）を並列化して行う\n    .map(decode_image, num_parallel_calls=AUTO)\n#     データ変換（増幅）を並列化する\n    .map(data_augment, num_parallel_calls=AUTO)\n#     データセットをメモリかローカスストレージにキャッシュできる\n    .cache()\n#     繰り返し。shuffleの前にあればEPOCHの境界を越えて要素がシャッフルされない\n    .repeat()\n#     シャッフルバッファのサイズは大きいほど完全にシャッフルされる。※ランダム要素\n    .shuffle(1024)\n#     バッチ化\n    .batch(BATCH_SIZE)\n#     CPUとTPUでそれぞれ並列に処理を実行\n    .prefetch(AUTO)\n)\n\n# valid_dataset = (\n#     tf.data.TFRecordDataset\n#     .from_tensor_slices((valid_path, valid_label))\n#     .map(decode_image, num_parallel_calls=AUTO)\n#     .map(data_augment, num_parallel_calls=AUTO)\n#     .cache()\n#     .batch(BATCH_SIZE)\n#     .prefetch(AUTO)\n# )\n\n# テストデータのデコード\ntest_dataset = (\n    tf.data.TFRecordDataset\n    .from_tensor_slices(test_path)\n    .map(decode_image, num_parallel_calls=AUTO)\n    .map(data_augment, num_parallel_calls=AUTO)\n    .batch(BATCH_SIZE)\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Define the parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS = 40\nLR_START = 0.0001\nLR_MAX = 0.00005 * strategy.num_replicas_in_sync\nLR_MIN = 0.0001\nLR_RAMPUP_EPOCHS = 10\nLR_SUSTAIN_EPOCHS = 4\nLR_EXP_DECAY = .8\n\ndef lrfn(epoch):\n    if epoch < LR_RAMPUP_EPOCHS:\n        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n        lr = LR_MAX\n    else:\n        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n    return lr\n\nlr = tf.keras.callbacks.LearningRateScheduler(lrfn)\n\ny = [lrfn(x) for x in range(EPOCHS)]\nplt.plot(y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EfficientNet B7-B1"},{"metadata":{"trusted":true},"cell_type":"code","source":"# # EfficientNetのインストール\n# !pip install -q efficientnet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # EfficientNetB7の読み込み\n# from efficientnet.tfkeras import EfficientNetB7\n\n# # modelの作成はstrategy.scope下で行う\n# with strategy.scope():\n# #     全結合層を含めない/noisy-studentでself training/average pooling/画像サイズとRGB\n#     efn7 = EfficientNetB7(include_top=False, weights='noisy-student', pooling='avg', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n# #     Sequentialモデルを作成、後ろに層を追加\n#     model_efn7 = Sequential()\n# #     EfficientNet層をModelに追加\n#     model_efn7.add(efn7)\n# #     こちらで全結合層を追加、4値分類、分類問題のため活性化関数はsoftmax\n#     model_efn7.add(L.Dense(4, activation='softmax'))\n# #     modelがどのように学習するかを決める\n# #     最適化関数adam/損失関数は多クラス分類のためクロスエントロピー/評価関数は正解率（学習には影響しない）\n#     model_efn7.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n#     print(model_efn7.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from efficientnet.tfkeras import EfficientNetB6\n\n# with strategy.scope():\n#     efn6 = EfficientNetB6(include_top=False, weights='noisy-student', pooling='avg', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n#     model_efn6 = Sequential()\n#     model_efn6.add(efn6)\n#     model_efn6.add(L.Dense(4, activation='softmax'))\n#     model_efn6.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n#     print(model_efn6.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from efficientnet.tfkeras import EfficientNetB5\n\n# with strategy.scope():\n#     efn5 = EfficientNetB5(include_top=False, weights='noisy-student', pooling='avg', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n#     model_efn5 = Sequential()\n#     model_efn5.add(efn5)\n#     model_efn5.add(L.Dense(4, activation='softmax'))\n#     model_efn5.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n#     print(model_efn5.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from efficientnet.tfkeras import EfficientNetB4\n\n# with strategy.scope():\n#     efn4 = EfficientNetB4(include_top=False, weights='noisy-student', pooling='avg', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n#     model_efn4 = Sequential()\n#     model_efn4.add(efn4)\n#     model_efn4.add(L.Dense(4, activation='softmax'))\n#     model_efn4.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n#     print(model_efn4.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from efficientnet.tfkeras import EfficientNetB3\n\n# with strategy.scope():\n#     efn3 = EfficientNetB3(include_top=False, weights='noisy-student', pooling='avg', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n#     model_efn3 = Sequential()\n#     model_efn3.add(efn3)\n#     model_efn3.add(L.Dense(4, activation='softmax'))\n#     model_efn3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n#     print(model_efn3.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from efficientnet.tfkeras import EfficientNetB2\n\n# with strategy.scope():\n#     efn2 = EfficientNetB2(include_top=False, weights='noisy-student', pooling='avg', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n#     model_efn2 = Sequential()\n#     model_efn2.add(efn2)\n#     model_efn2.add(L.Dense(4, activation='softmax'))\n#     model_efn2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n#     print(model_efn2.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from efficientnet.tfkeras import EfficientNetB1\n\n# with strategy.scope():\n#     efn1 = EfficientNetB1(include_top=False, weights='noisy-student', pooling='avg', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n#     model_efn1 = Sequential()\n#     model_efn1.add(efn1)\n#     model_efn1.add(L.Dense(4, activation='softmax'))\n#     model_efn1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n#     print(model_efn1.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DenseNet 121/169/201"},{"metadata":{"trusted":true},"cell_type":"code","source":"# from tensorflow.keras.applications import DenseNet121\n\n# with strategy.scope():\n#     dnn121 = DenseNet121(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n#     model_dnn121 = Sequential()\n#     model_dnn121.add(dnn121)\n#     model_dnn121.add(L.GlobalAveragePooling2D())\n#     model_dnn121.add(L.Dense(4, activation='softmax'))\n#     model_dnn121.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n#     print(model_dnn121.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from tensorflow.keras.applications import DenseNet169\n\n# with strategy.scope():\n#     dnn169 = DenseNet169(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n#     model_dnn169 = Sequential()\n#     model_dnn169.add(dnn169)\n#     model_dnn169.add(L.GlobalAveragePooling2D())\n#     model_dnn169.add(L.Dense(4, activation='softmax'))\n#     model_dnn169.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n#     print(model_dnn169.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from tensorflow.keras.applications import DenseNet201\n\n# with strategy.scope():\n#     dnn201 = DenseNet201(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n#     model_dnn201 = Sequential()\n#     model_dnn201.add(dnn201)\n#     model_dnn201.add(L.GlobalAveragePooling2D())\n#     model_dnn201.add(L.Dense(4, activation='softmax'))\n#     model_dnn201.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n#     print(model_dnn201.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ResNet 50/101/152"},{"metadata":{"trusted":true},"cell_type":"code","source":"# from tensorflow.keras.applications import ResNet50\n\n# with strategy.scope():\n#     rsn50 = ResNet50(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n#     model_rsn50 = Sequential()\n#     model_rsn50.add(rsn50)\n#     model_rsn50.add(L.GlobalAveragePooling2D())\n#     model_rsn50.add(L.Dense(4, activation='softmax'))\n#     model_rsn50.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n#     print(model_rsn50.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from tensorflow.keras.applications import ResNet101\n\n# with strategy.scope():\n#     rsn101 = ResNet101(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n#     model_rsn101 = Sequential()\n#     model_rsn101.add(rsn101)\n#     model_rsn101.add(L.GlobalAveragePooling2D())\n#     model_rsn101.add(L.Dense(4, activation='softmax'))\n#     model_rsn101.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n#     print(model_rsn101.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from tensorflow.keras.applications import ResNet152\n\n# with strategy.scope():\n#     rsn152 = ResNet152(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n#     model_rsn152 = Sequential()\n#     model_rsn152.add(rsn152)\n#     model_rsn152.add(L.GlobalAveragePooling2D())\n#     model_rsn152.add(L.Dense(4, activation='softmax'))\n#     model_rsn152.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n#     print(model_rsn152.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# VGG 16/19"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications import VGG16\n\nwith strategy.scope():\n    vgg16 = VGG16(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n    model_vgg16 = Sequential()\n    model_vgg16.add(vgg16)\n    model_vgg16.add(L.GlobalAveragePooling2D())\n    model_vgg16.add(L.Dense(4, activation='softmax'))\n    model_vgg16.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    print(model_vgg16.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications import VGG19\n\nwith strategy.scope():\n    vgg19 = VGG19(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n    model_vgg19 = Sequential()\n    model_vgg19.add(vgg19)\n    model_vgg19.add(L.GlobalAveragePooling2D())\n    model_vgg19.add(L.Dense(4, activation='softmax'))\n    model_vgg19.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    print(model_vgg19.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Epoch終了後の各数値を監視して条件が揃った場合モデルを保存する\n# # 重みのファイル名/監視する値/判定結果から保存を決定/モデルの重みを保存\n# mc_efn7 = tf.keras.callbacks.ModelCheckpoint('weights_efn7.h5', monitor='loss', save_best_only=True, save_weights_only=True)\n# # 訓練の履歴の可視化\n# history = model_efn7.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_efn7], steps_per_epoch=train_label.shape[0] // BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mc_efn6 = tf.keras.callbacks.ModelCheckpoint('weights_efn6.h5', monitor='loss', save_best_only=True, save_weights_only=True)\n# history = model_efn6.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_efn6], steps_per_epoch=train_label.shape[0] // BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mc_efn5 = tf.keras.callbacks.ModelCheckpoint('weights_efn5.h5', monitor='loss', save_best_only=True, save_weights_only=True)\n# history = model_efn5.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_efn5], steps_per_epoch=train_label.shape[0] // BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mc_efn4 = tf.keras.callbacks.ModelCheckpoint('weights_efn4.h5', monitor='loss', save_best_only=True, save_weights_only=True)\n# history = model_efn4.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_efn4], steps_per_epoch=train_label.shape[0] // BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mc_efn3 = tf.keras.callbacks.ModelCheckpoint('weights_efn3.h5', monitor='loss', save_best_only=True, save_weights_only=True)\n# history = model_efn3.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_efn3], steps_per_epoch=train_label.shape[0] // BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mc_efn2 = tf.keras.callbacks.ModelCheckpoint('weights_efn2.h5', monitor='loss', save_best_only=True, save_weights_only=True)\n# history = model_efn2.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_efn2], steps_per_epoch=train_label.shape[0] // BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mc_efn1 = tf.keras.callbacks.ModelCheckpoint('weights_efn1.h5', monitor='loss', save_best_only=True, save_weights_only=True)\n# history = model_efn1.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_efn1], steps_per_epoch=train_label.shape[0] // BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mc_dnn121 = tf.keras.callbacks.ModelCheckpoint('weights_dnn121.h5', monitor='loss', save_best_only=True, save_weights_only=True)\n# history = model_dnn121.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_dnn121], steps_per_epoch=train_label.shape[0] // BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mc_dnn169 = tf.keras.callbacks.ModelCheckpoint('weights_dnn169.h5', monitor='loss', save_best_only=True, save_weights_only=True)\n# history = model_dnn169.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_dnn169], steps_per_epoch=train_label.shape[0] // BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mc_dnn201 = tf.keras.callbacks.ModelCheckpoint('weights_dnn201.h5', monitor='loss', save_best_only=True, save_weights_only=True)\n# history = model_dnn201.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_dnn201], steps_per_epoch=train_label.shape[0] // BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mc_rsn50 = tf.keras.callbacks.ModelCheckpoint('weights_rsn50.h5', monitor='loss', save_best_only=True, save_weights_only=True)\n# history = model_rsn50.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_rsn50], steps_per_epoch=train_label.shape[0] // BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mc_rsn101 = tf.keras.callbacks.ModelCheckpoint('weights_rsn101.h5', monitor='loss', save_best_only=True, save_weights_only=True)\n# history = model_rsn101.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_rsn101], steps_per_epoch=train_label.shape[0] // BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mc_rsn152 = tf.keras.callbacks.ModelCheckpoint('weights_rsn152.h5', monitor='loss', save_best_only=True, save_weights_only=True)\n# history = model_rsn152.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_rsn152], steps_per_epoch=train_label.shape[0] // BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mc_vgg16 = tf.keras.callbacks.ModelCheckpoint('weights_vgg16.h5', monitor='loss', save_best_only=True, save_weights_only=True)\nhistory = model_vgg16.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_vgg16], steps_per_epoch=train_label.shape[0] // BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mc_vgg19 = tf.keras.callbacks.ModelCheckpoint('weights_vgg19.h5', monitor='loss', save_best_only=True, save_weights_only=True)\nhistory = model_vgg19.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_vgg19], steps_per_epoch=train_label.shape[0] // BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with strategy.scope():\n#     あらかじめ保存しておいたweightパラメータをロード\n#     model_efn7.load_weights('weights_efn7.h5')\n#     model_efn6.load_weights('weights_efn6.h5')\n#     model_efn5.load_weights('weights_efn5.h5')\n#     model_efn4.load_weights('weights_efn4.h5')\n#     model_efn3.load_weights('weights_efn3.h5')\n#     model_efn2.load_weights('weights_efn2.h5')\n#     model_efn1.load_weights('weights_efn1.h5')\n#     model_dnn121.load_weights('weights_dnn121.h5')\n#     model_dnn169.load_weights('weights_dnn169.h5')\n#     model_dnn201.load_weights('weights_dnn201.h5')\n#     model_rsn50.load_weights('weights_rsn50.h5')\n#     model_rsn101.load_weights('weights_rsn101.h5')\n#     model_rsn152.load_weights('weights_rsn152.h5')\n    model_vgg16.load_weights('weights_vgg16.h5')\n    model_vgg19.load_weights('weights_vgg19.h5')\n# valid_prob = model.predict(valid_dataset, verbose=1)\n# print(metrics.classification_report(np.argmax(valid_label, axis=1), np.argmax(valid_prob, axis=1)))\n# print(metrics.confusion_matrix(np.argmax(valid_label, axis=1), np.argmax(valid_prob, axis=1)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predict"},{"metadata":{"trusted":true},"cell_type":"code","source":"# # testデータでの予測/logの出力verbose\n# probs_efn7 = model_efn7.predict(test_dataset, verbose=1)\n# # probsの値をsumple_submissionの列healthy,multiple_diseases,rust,scabにあてはめ\n# sub_efn7 = sub\n# sub_efn7.loc[:, 'healthy':] = probs_efn7\n# # CSVファイルに書き出し\n# sub_efn7.to_csv('submission_efn7.csv', index=False)\n# # 表示\n# sub_efn7.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# probs_efn6 = model_efn6.predict(test_dataset, verbose=1)\n# sub_efn6 = sub\n# sub_efn6.loc[:, 'healthy':] = probs_efn6\n# sub_efn6.to_csv('submission_efn6.csv', index=False)\n# sub_efn6.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# probs_efn5 = model_efn5.predict(test_dataset, verbose=1)\n# sub_efn5 = sub\n# sub_efn5.loc[:, 'healthy':] = probs_efn5\n# sub_efn5.to_csv('submission_efn5.csv', index=False)\n# sub_efn5.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# probs_efn4 = model_efn4.predict(test_dataset, verbose=1)\n# sub_efn4 = sub\n# sub_efn4.loc[:, 'healthy':] = probs_efn4\n# sub_efn4.to_csv('submission_efn4.csv', index=False)\n# sub_efn4.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# probs_efn3 = model_efn3.predict(test_dataset, verbose=1)\n# sub_efn3 = sub\n# sub_efn3.loc[:, 'healthy':] = probs_efn3\n# sub_efn3.to_csv('submission_efn3.csv', index=False)\n# sub_efn3.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# probs_efn2 = model_efn2.predict(test_dataset, verbose=1)\n# sub_efn2 = sub\n# sub_efn2.loc[:, 'healthy':] = probs_efn2\n# sub_efn2.to_csv('submission_efn2.csv', index=False)\n# sub_efn2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# probs_efn1 = model_efn1.predict(test_dataset, verbose=1)\n# sub_efn1 = sub\n# sub_efn1.loc[:, 'healthy':] = probs_efn1\n# sub_efn1.to_csv('submission_efn1.csv', index=False)\n# sub_efn1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# probs_dnn121 = model_dnn121.predict(test_dataset, verbose=1)\n# sub_dnn121 = sub\n# sub_dnn121.loc[:, 'healthy':] = probs_dnn121\n# sub_dnn121.to_csv('submission_dnn121.csv', index=False)\n# sub_dnn121.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# probs_dnn169 = model_dnn169.predict(test_dataset, verbose=1)\n# sub_dnn169 = sub\n# sub_dnn169.loc[:, 'healthy':] = probs_dnn169\n# sub_dnn169.to_csv('submission_dnn169.csv', index=False)\n# sub_dnn169.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# probs_dnn201 = model_dnn201.predict(test_dataset, verbose=1)\n# sub_dnn201 = sub\n# sub_dnn201.loc[:, 'healthy':] = probs_dnn201\n# sub_dnn201.to_csv('submission_dnn201.csv', index=False)\n# sub_dnn201.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# probs_rsn50 = model_rsn50.predict(test_dataset, verbose=1)\n# sub_rsn50 = sub\n# sub_rsn50.loc[:, 'healthy':] = probs_rsn50\n# sub_rsn50.to_csv('submission_rsn50.csv', index=False)\n# sub_rsn50.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# probs_rsn101 = model_rsn101.predict(test_dataset, verbose=1)\n# sub_rsn101 = sub\n# sub_rsn101.loc[:, 'healthy':] = probs_rsn101\n# sub_rsn101.to_csv('submission_rsn101.csv', index=False)\n# sub_rsn101.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# probs_rsn152 = model_rsn152.predict(test_dataset, verbose=1)\n# sub_rsn152 = sub\n# sub_rsn152.loc[:, 'healthy':] = probs_rsn152\n# sub_rsn152.to_csv('submission_rsn152.csv', index=False)\n# sub_rsn152.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"probs_vgg16 = model_vgg16.predict(test_dataset, verbose=1)\nsub_vgg16 = sub\nsub_vgg16.loc[:, 'healthy':] = probs_vgg16\nsub_vgg16.to_csv('submission_vgg16.csv', index=False)\nsub_vgg16.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"probs_vgg19 = model_vgg19.predict(test_dataset, verbose=1)\nsub_vgg19 = sub\nsub_vgg19.loc[:, 'healthy':] = probs_vgg19\nsub_vgg19.to_csv('submission_vgg19.csv', index=False)\nsub_vgg19.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}