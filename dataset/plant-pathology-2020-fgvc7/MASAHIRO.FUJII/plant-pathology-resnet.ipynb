{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Import Libraries"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport os\nimport cv2\nfrom matplotlib import pyplot as plt\nfrom kaggle_datasets import KaggleDatasets\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import layers as L\nfrom tensorflow.keras.utils import to_categorical\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn import metrics\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# TPU setup"},{"metadata":{"trusted":true},"cell_type":"code","source":"# \n# TPUの初期化\n# \ntry:\n#     TPUのハードウェア情報を獲得。TPUが利用できない環境ではエラー\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n#     TPU利用可能の確認\n    print('Running on TPU:', tpu.master())\n# 上記でエラー（例外）が出た場合の処理\nexcept ValueError:\n    tpu = None\n\n# TPUが利用できる場合（Accelerator TPU）\nif tpu:\n#   リモートクラスタに接続してTPUを初期化\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n#   データの並列処理を使用してトレーニングを分散する\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n# TPUが利用できない場合（Accelerator None）\nelse:\n    strategy = tf.distribute.get_strategy()\n\n# 並列処理のレベルに関する決定をAUTOで行う\nAUTO = tf.data.experimental.AUTOTUNE\nGCS_DS_PATH = KaggleDatasets().get_gcs_path()\n\nBATCH_SIZE = 8 * strategy.num_replicas_in_sync\nIMG_SIZE = 768\n\nprint('Batch size:', BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Get train and test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/train.csv')\ntest = pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/test.csv')\nsub = pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/sample_submission.csv')\n\nprint(train.head())\n\ntrain_path = train.image_id.apply(lambda x: f'{GCS_DS_PATH}/images/{x}.jpg').values\ntest_path = test.image_id.apply(lambda x: f'{GCS_DS_PATH}/images/{x}.jpg').values\ntrain_label = train.loc[:, 'healthy':].values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Get class weights"},{"metadata":{"trusted":true},"cell_type":"code","source":"class_weight = compute_class_weight('balanced', np.unique(np.argmax(train_label, axis=1)), np.argmax(train_label, axis=1))\nplt.bar(range(4), class_weight)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Lets see some images"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 2×2で表示\nfig, ax = plt.subplots(2, 2)\n# サンプル読み込み\nimg = cv2.imread('/kaggle/input/plant-pathology-2020-fgvc7/images/Train_0.jpg')\nimg1 = cv2.imread('/kaggle/input/plant-pathology-2020-fgvc7/images/Train_1.jpg')\nimg2 = cv2.imread('/kaggle/input/plant-pathology-2020-fgvc7/images/Train_2.jpg')\nimg3 = cv2.imread('/kaggle/input/plant-pathology-2020-fgvc7/images/Train_3.jpg')\n# 場所指定した書き出し\nax[0, 0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\nax[0, 1].imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))\nax[1, 0].imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))\nax[1, 1].imshow(cv2.cvtColor(img3, cv2.COLOR_BGR2RGB))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Decode images"},{"metadata":{"trusted":true},"cell_type":"code","source":"# データ変換（デコード）の定義\ndef decode_image(filename, label=None, image_size=(IMG_SIZE, IMG_SIZE)):\n#     生データを読み込み\n    bits = tf.io.read_file(filename)\n#     画像のテンソルにデコード\n    image = tf.image.decode_jpeg(bits, channels=3)\n#     0-255のRGBを0-1に変換する（normalize）\n    image = tf.cast(image, tf.float32) / 255.0\n#     画像サイズを1365×2048から768×768にする\n    image = tf.image.resize(image, image_size)\n    \n#     imageをreturn\n    if label is None:\n        return image\n    else:\n        return image, label\n\n# データ変換（増幅）の定義\ndef data_augment(image, label=None):\n#     ランダムに水平方向に反転\n    image = tf.image.random_flip_left_right(image)\n#     ランダムに垂直方向に反転\n    image = tf.image.random_flip_up_down(image)\n    \n#     imageをreturn\n    if label is None:\n        return image\n    else:\n        return image, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 教師データをデコード\ntrain_dataset = (\n#     TFR形式でデータを読み書きする\n    tf.data.TFRecordDataset\n#     配列をスライスしてデータセットを構築する\n    .from_tensor_slices((train_path, train_label))\n#     データ変換（デコード）を並列化して行う\n    .map(decode_image, num_parallel_calls=AUTO)\n#     データ変換（増幅）を並列化して行う\n    .map(data_augment, num_parallel_calls=AUTO)\n    .cache()\n    .repeat()\n    .shuffle(1024) #ランダム要素\n    .batch(BATCH_SIZE)\n    .prefetch(AUTO)\n)\n\n# テストデータのデコード\ntest_dataset = (\n    tf.data.TFRecordDataset\n    .from_tensor_slices(test_path)\n    .map(decode_image, num_parallel_calls=AUTO)\n    .map(data_augment, num_parallel_calls=AUTO)\n    .batch(BATCH_SIZE)\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Define the parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS = 40\nLR_START = 0.0001\nLR_MAX = 0.00005 * strategy.num_replicas_in_sync\nLR_MIN = 0.0001\nLR_RAMPUP_EPOCHS = 10\nLR_SUSTAIN_EPOCHS = 4\nLR_EXP_DECAY = .8\n\ndef lrfn(epoch):\n    if epoch < LR_RAMPUP_EPOCHS:\n        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n        lr = LR_MAX\n    else:\n        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n    return lr\n\nlr = tf.keras.callbacks.LearningRateScheduler(lrfn)\n\ny = [lrfn(x) for x in range(EPOCHS)]\nplt.plot(y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ResNet"},{"metadata":{"trusted":true},"cell_type":"code","source":"# ResNet50,DenseNet101,DenseNet152が使用可能\nfrom tensorflow.keras.applications import ResNet152\n\nwith strategy.scope():\n    rsn152 = ResNet152(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n\n    model_rsn152 = Sequential()\n    model_rsn152.add(rsn152)\n    model_rsn152.add(L.GlobalAveragePooling2D())\n    model_rsn152.add(L.Dense(4, activation='softmax'))\n    model_rsn152.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    print(model_rsn152.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"mc_rsn152 = tf.keras.callbacks.ModelCheckpoint('weights_rsn152.h5', monitor='loss', save_best_only=True, save_weights_only=True)\nhistory = model_rsn152.fit(train_dataset, epochs=EPOCHS, callbacks=[lr, mc_rsn152], steps_per_epoch=train_label.shape[0] // BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with strategy.scope():\n    model_rsn152.load_weights('weights_rsn152.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predict"},{"metadata":{"trusted":true},"cell_type":"code","source":"probs_rsn152 = model_rsn152.predict(test_dataset, verbose=1)\nsub_rsn152 = sub\nsub_rsn152.loc[:, 'healthy':] = probs_rsn152\nsub_rsn152.to_csv('submission_rsn152.csv', index=False)\nsub_rsn152.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}