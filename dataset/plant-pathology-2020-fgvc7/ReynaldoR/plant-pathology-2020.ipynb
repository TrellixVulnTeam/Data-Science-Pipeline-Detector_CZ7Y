{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Dataset: Cómo se lee de disco (SSD o HDD) los datos y se carga a RAM. (lee uno por uno)\n# Transforms: Suposiciones sobre el data generating distribution\n# DataLoader: Agrupar las imágenes en batches\n# Suponemos que estamos haciendo Supervised Learning (inputs (x), targets(y))\n#     - p(y=y|x=x)\n# Training loop: \n#     - Definir la loss function (mide la dis-similitud entre las dist. out y target)\n#     - Forward pass: Dado un input (batch), predecir el output (batch)\n#     - Calcular el valor de la loss function: usando el output y target\n#     - Calcular la gradiente del valor de la loss function (pytorch: autograd)\n#     - Optimizer:\n#         - Adam (momentum), otros\n#         - optimizer = Adam(model.parameters(), lr=..., momentum=...)\n#         - optimizer.step() (después de haber calc las gradientes)\n#             - Step: wf = wi - lr * g\n#     - Learning Rate Scheduler: Cómo varia el learning rate durante el entrenamiento","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH = \"../input/plant-pathology-2020-fgvc7/\"\nIMGS_PATH = PATH + \"images/\"\nTRAIN_CSV = PATH + \"train.csv\"\nTEST_CSV = PATH + \"test.csv\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torchvision.io import read_image\nimport torchvision.transforms as T\nimport torchvision.transforms.functional as F\nimport torch.nn as nn\nimport torch.optim as optim","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from fastai.vision.models import resnet18\nfrom fastai.vision.data import imagenet_stats","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    num_classes = -1\n    img_size = 480\n    seed = 2020\n    batch_size = 16\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dataframe\ndf = pd.read_csv(\"../input/plant-pathology-2020-fgvc7/train.csv\")\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CFG.num_classes = df.shape[1] - 1\nCFG.num_classes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PlantPathology2020(Dataset): # input (img Train_0.jpg), target (labels i.e. 0 0 0 1)\n    def __init__(self, csv_file, imgs_path, item_tfms=None):\n        self.df = pd.read_csv(csv_file) # Dataframe\n        self.imgs_path = imgs_path # dir de las imagenes\n        self.item_tfms = item_tfms # Resize de las imágenes\n        self.len = self.df.shape[0] # n ejemplos\n    \n    def __len__(self):\n        return self.len\n    \n    def __getitem__(self, idx): # devolver un par (input (img), target (vec: one-hot encoded))\n        row = self.df.iloc[idx]\n        image_path = self.imgs_path + row[0] + '.jpg'\n        #  input (torch.tensor) -> model -> output (torch.tensor)\n        image = read_image(input_path) # 3x1365x2048 o 3x2048x1365; 0 1 2; -3 -2 -1\n        target = torch.tensor(row[-4:], dtype=torch.float32)\n        if self.item_tfms:\n            return self.item_tfms(image), target\n        return image, target","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CenterCrop(object):\n    def __init__(self, output_size: int, padding_mode: str=\"symmetric\"):\n        self.padding_mode = padding_mode\n        self.center_crop = T.CenterCrop(output_size)\n    \n    def __call__(self, x):\n        if x.shape[-2] > x.shape[-1]:\n            x = x.transpose(-1, -2)\n        d1, d2 = math.floor((x.shape[-1] - x.shape[-2]) / 2), math.ceil((x.shape[-1] - x.shape[-2]) / 2)\n        x = F.pad(x, padding=[0, d1, 0, d2], padding_mode=self.padding_mode)\n        # asumimos que las dimensiones son mayores que el output_size\n        return self.center_crop(x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Transforms (con Transfer Learning: usar una red pre-entrenada en Imagenet por ejemplo) mean, std\n# Resize en CPU\nitem_tfms = CenterCrop(CFG.img_size)\n# Traininig set transforms (misc, luego normalizar) en GPU\nbatch_tfms = T.Compose([\n    T.RandomHorizontalFlip(p=0.2),\n    T.RandomVerticalFlip(p=0.2),\n    T.RandomApply([T.ColorJitter(brightness=0.10, contrast=0.10, saturation=0.10, hue=0.10)], p=0.2),\n    T.RandomApply(T.GaussianBlur(3), p=0.05),\n    T.Normalize(*imagenet_stats)\n])\n# Validation set transforms (solo normalizar) en GPU\nvalid_tfms = T.Normalize(*imagenet_stats)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Instanciar dataset\ndataset = PlantPathology2020(csv_file=TRAIN_CSV,\n                            imgs_path=IMGS_PATH,\n                            item_tfms=item_tfms)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_len = math.floor(0.8 * len(dataset))\nvalid_len = len(dataset) - train_len\ntrain_len, valid_len","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DataLoaders 80/20\ntrain_set, valid_set = random_split(dataset, [train_len, valid_len], generator=torch.Generator().manual_seed(CFG.seed))\ntrain_loader = DataLoader(train_set,\n                          batch_size=CFG.batch_size,\n                          shuffle=True,\n                          pin_memory=True)\nvalid_loader = DataLoader(valid_set,\n                          batch_size=CFG.batch_size,\n                          pin_memory=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = resnet18()\nmodel.to(CFG.device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fc.in_features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fc = nn.Linear(model.fc.in_features, CFG.num)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t = torch.tensor([[1, 2, 3, 12, 1, 20, 5],\n                  [1, 2, 30, -12, 1, -20, 18],\n                  [1, -2, 3, 12, -11, 35, 8]]).float()\nt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.softmax(t, dim=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cuando se hace toda una pasada en el dataset, ha pasado un epoch\nepochs = 10\ncriterion = nn.CrossEntropyLoss() # recibe output del modelo (logits), target","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = torch.tensor([[0, 0, 0, 1, 0],\n                 [0, 0, 1, 0, 0],\n                 [0, 1, 0, 0, 0]])\ny","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = torch.rand(y.shape)\ny_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = torch.tensor(5)\nloss.item()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_loss = 100","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_loss += loss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_loss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y.argmax(dim=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = optim.Adam(model.parameters())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train():\n    #Training\n    for e in range(epochs):\n        train_loss = 0\n        model.train()\n        for x, y in train_loader:\n            x, y = x.cuda(non_blocking=True), y.cuda(non_blocking=True)\n            x = batch_tfms(x)\n            y_pred = model(x)\n            loss = criterion(y_pred, y.argmax(dim=1))\n            optimizer.zero_grad() # hace que las gradientes calculadas en la iteración anterior sean 0\n            loss.backward() # calcula las gradientes\n            train_loss += loss.item() \n            optimizer.step() # actualiza los pesos de los tensores de las capas de la red\n        model.eval()\n        valid_loss = 0\n        with torch.no_grad():\n            for x, y in valid_loader:\n                x, y = x.cuda(non_blocking=True), y.cuda(non_blocking=True)\n                x = valid_tfms(x)\n                y_pred = model(x)\n                loss = criterion(y_pred, y.argmax(dim=1))\n                valid_loss += loss.item()\n        print(f\"{e} training loss:\", train_loss / len(train_loader))\n        print(f\"{e} valid loss:\", valid_loss / len(valid_loader))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}