{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Before the trip begin\n\n#####  If you like my work, please hit upvote since it will keep me motivated","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* **1. Introduction**   \n* **2. Data Preparation**\n   * 2.1 Import Libaries\n   * 2.2 Load Data\n   * 2.3 Check the Data\n   * 2.4 Split to train and test\n* **3. Data Augmentation**\n* **4. CNN**\n   * 4.1 Define Callbacks\n   * 4.2 Efficientnet-B7\n   * 4.3 Evaluate the Model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 1. Introduction\n![](https://upload.wikimedia.org/wikipedia/commons/thumb/a/ad/Black_rot_lifecycle.tif/lossy-page1-1200px-Black_rot_lifecycle.tif.jpg)\n\n### Problem Statement\nMisdiagnosis of the many diseases impacting agricultural crops can lead to misuse of chemicals leading to the emergence of resistant pathogen strains, increased input costs, and more outbreaks with significant economic loss and environmental impacts. Current disease diagnosis based on human scouting is time-consuming and expensive, and although computer-vision based models have the promise to increase efficiency, the great variance in symptoms due to age of infected tissues, genetic variations, and light conditions within trees decreases the accuracy of detection.\n\n### Importance of Plant Pathology\nPlant Pathology has advanced techniques to protect crops from losses due to diseases. The science of plant pathology has contributed disease free certified seed production. Most of the diseases with known disease cycle can now be avoided by the modification of cultural practices","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 2. Data Preparation","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 2.1 Import Libraries","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport numpy as np\nimport pandas as pd\nimport random\nfrom keras.preprocessing.image import load_img\nimport matplotlib.pyplot as plt \nimport glob as gb\nfrom kaggle_datasets import KaggleDatasets\n!pip install -q efficientnet\nimport efficientnet.tfkeras as efn\nimport tensorflow as tf\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.2 Load Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/plant-pathology-2020-fgvc7/train.csv\")\nIMAGE_PATH = \"../input/plant-pathology-2020-fgvc7/images/\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.3 Check Data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"This one below is to check the most common resolution of pictures among all Train data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"size = []\nfiles = gb.glob(pathname= str(\"../input/plant-pathology-2020-fgvc7/images/*.jpg\"))\nfor file in files: \n    image = plt.imread(file)\n    size.append(image.shape)\npd.Series(size).value_counts()\n# Because it take looong time the output is below\n# (1365, 2048, 3)    3620\n# (2048, 1365, 3)      22","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head(10)\n# train_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax=plt.subplots(2,2,figsize=(14,14))\nsns.barplot(x=train_df.healthy.value_counts().index,y=train_df.healthy.value_counts(),ax=ax[0,0])\nax[0,0].set_xlabel('Healthy',size=9)\nax[0,0].set_ylabel('Count',size=9)\n\nsns.barplot(x=train_df.multiple_diseases.value_counts().index,y=train_df.multiple_diseases.value_counts(),ax=ax[0,1])\nax[0,1].set_xlabel('Multiple Diseases',size=9)\nax[0,1].set_ylabel('Count',size=9)\n\nsns.barplot(x=train_df.rust.value_counts().index,y=train_df.rust.value_counts(),ax=ax[1,0])\nax[1,0].set_xlabel('Rust',size=9)\nax[1,0].set_ylabel('Count',size=9)\n\nsns.barplot(x=train_df.scab.value_counts().index,y=train_df.scab.value_counts(),ax=ax[1,1])\nax[1,1].set_xlabel('Scab',size=9)\nax[1,1].set_ylabel('Count',size=9)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let's check all the categories we have ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"healthy = list(train_df[train_df[\"healthy\"]==1].image_id)\nmultiple_diseases = list(train_df[train_df[\"multiple_diseases\"]==1].image_id)\nrust = list(train_df[train_df[\"rust\"]==1].image_id)\nscab = list(train_df[train_df[\"scab\"]==1].image_id)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_image(filenames):\n    sample = random.choice(filenames)\n    image = load_img(\"../input/plant-pathology-2020-fgvc7/images/\"+sample+\".jpg\")\n    plt.imshow(image) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"load_image(healthy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"load_image(multiple_diseases)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"load_image(rust)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"load_image(scab)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Everything look fine !","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 2.4 Split to Train and Validaiton","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"GCS_DS_PATH = KaggleDatasets().get_gcs_path()\n#to verify your dir\n!gsutil ls $GCS_DS_PATH","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def format_path_gcs(st):\n    return GCS_DS_PATH + '/images/' + st + '.jpg'\n#===============================================================\n#===============================================================\nX = train_df.image_id.apply(format_path_gcs).values\ny = np.float32(train_df.loc[:, 'healthy':'scab'].values)\n\nX_train, X_val, y_train, y_val =train_test_split(X, y, test_size=0.1, random_state=43)\nprint('done!')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Shape of X_train : ',X_train.shape)\nprint('Shape of y_train : ',y_train.shape)\nprint('===============================================')\nprint('Shape of X_val : ',X_val.shape)\nprint('Shape of y_val : ',y_val.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Create Dataset","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"But first let's setup TPU","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"AUTO = tf.data.experimental.AUTOTUNE\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 4 * strategy.num_replicas_in_sync\nSTEPS_PER_EPOCH = y_train.shape[0] // BATCH_SIZE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def decode_image(filename, label=None, image_size=(1024,1024)):\n    bits = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(bits, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0\n    image = tf.image.resize(image, image_size)\n    \n    if label is None:\n        return image\n    else:\n        return image, label\n\ndef data_augment(image, label=None):\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    image = tf.image.random_brightness(image, max_delta=0.3)\n    \n    \n    if label is None:\n        return image\n    else:\n        return image, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = (\n    tf.data.Dataset.from_tensor_slices((X_train, y_train))\n    .map(decode_image,num_parallel_calls=AUTO)\n    .map(data_augment,num_parallel_calls=AUTO)\n    .repeat()\n    .shuffle(256)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTO)\n)\n\nvalid_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((X_val, y_val))\n    .map(decode_image,num_parallel_calls=AUTO)\n    .cache()\n    .batch(BATCH_SIZE)\n    .prefetch(AUTO)\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. CNN","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 4.1. Define Callbacks","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_lrfn(lr_start=0.00001, lr_max=0.00005,lr_min=0.00001, lr_rampup_epochs=5,lr_sustain_epochs=0, lr_exp_decay=.8):\n    \n    lr_max = lr_max * strategy.num_replicas_in_sync\n    def lrfn(epoch):\n        if epoch < lr_rampup_epochs:\n            lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start\n        elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n            lr = lr_max\n        else:\n            lr = (lr_max - lr_min) *\\\n                 lr_exp_decay**(epoch - lr_rampup_epochs- lr_sustain_epochs) + lr_min\n        return lr\n    return lrfn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lrfn = build_lrfn()\nlr_schedule = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=1)\nEarlyStopping=tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",patience=10,verbose=True, mode=\"min\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reduce_lr =  tf.keras.callbacks.ReduceLROnPlateau(monitor = \"val_loss\", factor = 0.5, patience = 10,\n#   verbose = 0, mode = \"auto\", epsilon = 1e-04, cooldown = 0,\n#   min_lr = 1e-5)\n# es = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\" , verbose = 1 , mode = 'min' , patience = 10 )\n#weights='noisy-student',","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4.2. Efficientnet-B7","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"![](https://raw.githubusercontent.com/tensorflow/tpu/master/models/official/efficientnet/g3doc/params.png)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"EfficientNets rely on AutoML and compound scaling to achieve superior performance without compromising resource efficiency. The AutoML Mobile framework has helped develop a mobile-size baseline network, EfficientNet-B0, which is then improved by the compound scaling method to obtain EfficientNet-B1 to B7.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def Eff_B7_NS():\n    model_EfficientNetB7_NS = Sequential([efn.EfficientNetB7(input_shape=(1024,1024,3),weights='noisy-student',include_top=False),\n                                 tf.keras.layers.GlobalAveragePooling2D(),\n                                 tf.keras.layers.Dense(128,activation='relu'),\n                                 tf.keras.layers.Dense(64,activation='relu'),\n                                 tf.keras.layers.Dense(4,activation='softmax')])               \n    model_EfficientNetB7_NS.compile(optimizer='Adam',loss = 'categorical_crossentropy',metrics=['categorical_accuracy'])\n    \n    \n    return model_EfficientNetB7_NS","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with strategy.scope():\n    model_Eff_B7_NS=Eff_B7_NS()\n    \nmodel_Eff_B7_NS.summary()\n#del model_Eff_B7_NS","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EfficientNetB7_NS = model_Eff_B7_NS.fit(train_dataset,\n                    epochs=50,\n                    callbacks=[lr_schedule,EarlyStopping],\n                    steps_per_epoch=STEPS_PER_EPOCH,\n                    validation_data=valid_dataset)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4.3. Evaluate Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure()\nfig,(ax1, ax2)=plt.subplots(1,2,figsize=(19,7))\nax1.plot(EfficientNetB7_NS.history['loss'])\nax1.plot(EfficientNetB7_NS.history['val_loss'])\nax1.legend(['training','validation'])\nax1.set_title('loss')\nax1.set_xlabel('epoch')\n\nax2.plot(EfficientNetB7_NS.history['categorical_accuracy'])\nax2.plot(EfficientNetB7_NS.history['val_categorical_accuracy'])\nax2.legend(['training','validation'])\nax2.set_title('Acurracy')\nax2.set_xlabel('epoch')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see after no improvment EarlyStop did its job ,and for this model I think is the best to choose between 14-17 epochs . ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"\n\n\n### If you like my work, please hit upvote since it will keep me motivated","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}