{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Preprocessing Image With tf.image Module"},{"metadata":{},"cell_type":"markdown","source":"## Import Packages"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport os\nmatplotlib.rcParams['figure.figsize'] = (12.0, 8.0)\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Tensorflow `tf.image` module is used for image processing and decoding operations.\n\nLet's run `dir()` function on `tf.image` to see all properties and methods of it."},{"metadata":{"trusted":true},"cell_type":"code","source":"dir(tf.image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image=plt.imread('/kaggle/input/plant-pathology-2020-fgvc7/images/Train_34.jpg')\nimage2=plt.imread('/kaggle/input/plant-pathology-2020-fgvc7/images/Train_150.jpg')\nimage3=plt.imread('/kaggle/input/plant-pathology-2020-fgvc7/images/Train_753.jpg')\nimage4=plt.imread('/kaggle/input/plant-pathology-2020-fgvc7/images/Test_1272.jpg')\nimage5=plt.imread('/kaggle/input/plant-pathology-2020-fgvc7/images/Train_778.jpg')\nimage6=plt.imread('/kaggle/input/plant-pathology-2020-fgvc7/images/Test_904.jpg')\nplt.imshow(image)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### tf.image.adjust_brightness\nAdjust the brightness of RGB or Grayscale images."},{"metadata":{"trusted":true},"cell_type":"code","source":"image_adjust_the_brightness_1=tf.image.adjust_brightness(image,0.4)\nimage_adjust_the_brightness_2=tf.image.adjust_brightness(image,0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(image_adjust_the_brightness_1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(image_adjust_the_brightness_2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### tf.image.adjust_contrast\nAdjust contrast of RGB or grayscale images."},{"metadata":{"trusted":true},"cell_type":"code","source":"image_adjust_the_contrast_1=tf.image.adjust_contrast(image,6)\nimage_adjust_the_contrast_2=tf.image.adjust_contrast(image,0.6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(image_adjust_the_contrast_1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(image_adjust_the_contrast_2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### tf.image.adjust_gamma\nPerforms Gamma Correction on the input image."},{"metadata":{"trusted":true},"cell_type":"code","source":"image_adjust_gamma=tf.image.adjust_gamma(image,gamma=3,gain=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(image_adjust_gamma)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### tf.image.adjust_hue\nAdjust hue of RGB images."},{"metadata":{"trusted":true},"cell_type":"code","source":"image_adjust_hue_1=tf.image.adjust_hue(image,0.5,name=None)\nimage_adjust_hue_2=tf.image.adjust_hue(image,-0.5,name=None)\nimage_adjust_hue_3=tf.image.adjust_hue(image,0.7,name=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(image_adjust_hue_1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(image_adjust_hue_2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(image_adjust_hue_3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### tf.image.adjust_saturation\nAdjust saturation of RGB images."},{"metadata":{"trusted":true},"cell_type":"code","source":"image_adjust_saturation_1=tf.image.adjust_saturation(image,0.2,name=None)\nimage_adjust_saturation_2=tf.image.adjust_saturation(image,0.5,name=None)\nimage_adjust_saturation_3=tf.image.adjust_saturation(image,0.9,name=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(image_adjust_saturation_1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(image_adjust_saturation_2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(image_adjust_saturation_3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### tf.image.central_crop\nCrop the central region of the image(s)."},{"metadata":{"trusted":true},"cell_type":"code","source":"image_central_crop_1=tf.image.central_crop(image,0.2)\nimage_central_crop_2=tf.image.central_crop(image,0.5)\nimage_central_crop_3=tf.image.central_crop(image,0.9)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(image_central_crop_1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(image_central_crop_2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(image_central_crop_3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### tf.image.crop_to_bounding_box\nCrops an image to a specified bounding box."},{"metadata":{"trusted":true},"cell_type":"code","source":"image_crop_to_bounding_box_1=tf.image.crop_to_bounding_box(image, 10, 20, 670, 700)\nimage_crop_to_bounding_box_2=tf.image.crop_to_bounding_box(image, 2, 2, 750, 750)\nimage_crop_to_bounding_box_3=tf.image.crop_to_bounding_box(image, 40, 40, 1000, 1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(image_crop_to_bounding_box_1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(image_crop_to_bounding_box_2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(image_crop_to_bounding_box_3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### tf.image.flip_left_right\nFlip an image horizontally (left to right)."},{"metadata":{"trusted":true},"cell_type":"code","source":"img_flip_left_right=tf.image.flip_left_right(image)\nplt.imshow(img_flip_left_right)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### tf.image.flip_up_down\nFlip an image vertically (upside down)."},{"metadata":{"trusted":true},"cell_type":"code","source":"img_flip_up_down=tf.image.flip_up_down(image)\nplt.imshow(img_flip_up_down)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### tf.image.rgb_to_grayscale\nConverts one or more images from RGB to Grayscale."},{"metadata":{"trusted":true},"cell_type":"code","source":"img_grayscale=tf.image.rgb_to_grayscale(image3)\nprint(img_grayscale.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_grayscale=tf.squeeze(img_grayscale)\nprint(img_grayscale.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(img_grayscale,cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### tf.image.rot90\nRotate image(s) counter-clockwise by 90 degrees."},{"metadata":{"trusted":true},"cell_type":"code","source":"img_rot90=tf.image.rot90(image5, k=1, name=None)\nplt.imshow(img_rot90)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### tf.image.transpose\nranspose image(s) by swapping the height and width dimension."},{"metadata":{"trusted":true},"cell_type":"code","source":"img_transpose=tf.image.transpose(image4, name=None)\nplt.imshow(img_transpose)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}