{"cells":[{"metadata":{},"cell_type":"markdown","source":"# DenseNet Imagenet pretrained vs retrined & GradCam\n\nBackground : The objectives of the analysis in this notebook is to find the answers of simple question.\n\n**Adding a couple of fully connected (Dense) Layer to the imagenet pretrained DenseNet model is good enough or do we need to train all layers of DenseNet?**\n\nSteps\n\n1. Train the DenseNet with trainset with the same hyperparameters. The only difference would be setting all DenseNet layers \"Trainable\" or \"Not Trainable\"\n2. Compare the performance between two (One is about 90% accuracy and the other is about 98%)\n3. See feature outputs (avegarge all outputs) for all training samples.\n\nAdditional\n\nInvesigate the error sample employing GradCam (ref : https://www.pyimagesearch.com/2020/03/09/grad-cam-visualize-class-activation-maps-with-keras-tensorflow-and-deep-learning/) "},{"metadata":{},"cell_type":"markdown","source":"#### Step 1. Train DenseNet + two fullyconnected Layers"},{"metadata":{},"cell_type":"markdown","source":"Includes Packages"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport gc\nimport re\n\nimport cv2\nimport math\nimport numpy as np\nimport scipy as sp\nimport pandas as pd\n\nimport tensorflow as tf\n\nfrom kaggle_datasets import KaggleDatasets\nfrom tensorflow.keras.applications import DenseNet121\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Activation, Conv2DTranspose, concatenate, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.optimizers import Adam\n\n\nimport warnings\nimport os \nimport pandas as pd\nimport plotly.graph_objs as go\nimport matplotlib.ticker as ticker\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport cv2\nimport numpy as np\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data_dir = '../input/plant-pathology-2020-fgvc7'\nimg_path = os.path.join(data_dir,'images')\nIMG_DIM = 256\n\nos.listdir(data_dir)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"load data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_total=pd.read_csv(os.path.join(data_dir,\"train.csv\"))\ntest=pd.read_csv(os.path.join(data_dir,\"test.csv\"))\ntrain_total['image_id']=train_total['image_id']+'.jpg'\ntest['image_id']=test['image_id']+'.jpg'\ntrain_total['label'] = train_total.iloc[:,1:5].idxmax(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_total.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Split the Dataset into Train and Validation set using the option (stratify) for have the same percentage smaple by category"},{"metadata":{"trusted":true},"cell_type":"code","source":"train, val = train_test_split(train_total, test_size = 0.15,stratify = train_total.label)\nprint(train.label.value_counts()/train_total.label.value_counts()) # TO check the percentage by category","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create Keras Imagegenerator with augmentation for trainset / No augmentation for Validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator( horizontal_flip=True,\n    vertical_flip=True,\n    rotation_range=10,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    zoom_range=.1,\n    fill_mode='nearest',\n    shear_range=0.1,\n    rescale=1/255,\n    brightness_range=[0.5, 1.5])\n\nval_datagen = ImageDataGenerator( \n    rescale=1/255)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Define Generator"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator=train_datagen.flow_from_dataframe(train,directory=img_path,\n                                                      target_size=(IMG_DIM,IMG_DIM),\n                                                      x_col=\"image_id\",\n                                                      y_col=['healthy','multiple_diseases','rust','scab'],\n                                                      class_mode='raw',\n                                                      shuffle=False,\n                                                       subset='training',\n                                                      batch_size=16)\nval_generator=val_datagen.flow_from_dataframe(val,directory=img_path,\n                                                      target_size=(IMG_DIM,IMG_DIM),\n                                                      x_col=\"image_id\",\n                                                      y_col=['healthy','multiple_diseases','rust','scab'],\n                                                      class_mode='raw',\n                                                      shuffle=False,\n                                                      batch_size=16,\n                                                  )\n\ntest_generator=val_datagen.flow_from_dataframe(test,directory='/kaggle/input/plant-pathology-2020-fgvc7/images/',\n                                                      target_size=(IMG_DIM,IMG_DIM),\n                                                      x_col=\"image_id\",\n                                                      y_col=None,\n                                                      class_mode=None,\n                                                      shuffle=False,\n                                                      batch_size=16)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Change to tf.data format (performance improve?)"},{"metadata":{"trusted":true},"cell_type":"code","source":"ds = tf.data.Dataset.from_generator(lambda: train_generator,\n                     output_types=(tf.float32,tf.float32),\n                     output_shapes=([None, IMG_DIM, IMG_DIM, 3],[None, 4])\n                     )\nval_ds = tf.data.Dataset.from_generator(lambda: val_generator ,\n                     output_types=(tf.float32,tf.float32),\n                     output_shapes=([None, IMG_DIM, IMG_DIM, 3],[None, 4])\n                     )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train_generator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model = DenseNet121(include_top=False, weights='imagenet', input_shape=(IMG_DIM,IMG_DIM,3))\n\nfor layer in base_model.layers:\n    layer.trainable = False\n\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(128, activation=\"relu\")(x)\nx = Dense(64, activation=\"relu\")(x)\npredictions = Dense(4, activation=\"softmax\")(x)\n\nmodel_updated = Model(inputs=base_model.input, outputs=predictions)\nmodel_updated.compile(optimizer='adam',\n                  loss = 'categorical_crossentropy',\n                  metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from tensorflow.keras.callbacks import ReduceLROnPlateau\n\n# history = model_updated.fit(ds,                                    \n#                                   steps_per_epoch=len(train_generator),\n#                                   epochs=30,validation_data=val_ds,validation_steps=len(val_generator)\n#                                   ,verbose=1,callbacks=[ReduceLROnPlateau(monitor='val_loss', factor=0.3,patience=3, min_lr=0.000001)])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check loss and accuracy bu epochs"},{"metadata":{"trusted":true},"cell_type":"code","source":"# loss = history.history['loss']\n# val_loss = history.history['val_loss']\n\n# plt.plot(loss, label='Training Loss')\n# plt.plot(val_loss, label='Validation Loss')\n# plt.legend(loc='upper right')\n# plt.ylabel('Cross Entropy')\n# plt.title('Training and Validation Loss')\n# plt.xlabel('epoch')\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model_updated.save('/content/drive/My Drive/Colab Notebooks/Plant_256/DenseNet pretrained.h5')\n# model_updated.save('/content/drive/My Drive/Colab Notebooks/Plant_256/DenseNet pretrained.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Two models were trained in Colab\n\nNow load two models"},{"metadata":{},"cell_type":"markdown","source":"#### Step 2 Compare the performance between two (One is about 92% accuracy and the other is about 98%)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import load_model\nmodel_updated = load_model('/kaggle/input/trainedmodel/DenseNet/DenseNet retrained.h5')\nmodel_pretrained = load_model('/kaggle/input/trainedmodel/DenseNet/DenseNet pretrained.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"model_updated.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"model_pretrained.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Prepare the dataset for total Training Dataset provided from Kaggle"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_total_generator=val_datagen.flow_from_dataframe(train_total,\n                                                        directory= img_path,\n                                                      target_size=(IMG_DIM,IMG_DIM),\n                                                      x_col=\"image_id\",\n                                                      y_col=['healthy','multiple_diseases','rust','scab'],\n                                                      class_mode='raw',\n                                                      shuffle=False,\n                                                      batch_size=32)\n\nds_total = tf.data.Dataset.from_generator(lambda: train_total_generator,\n                     output_types=(tf.float32,tf.float32),\n                     output_shapes=([None, IMG_DIM, IMG_DIM, 3],[None, 4])\n                     )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Evaluate Two models (92% vs 98%)"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_total_generator.reset()\nmodel_pretrained.evaluate(ds_total,steps=len(train_total_generator),verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_total_generator.reset()\nmodel_updated.evaluate(ds_total,steps=len(train_total_generator),verbose=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we are trying to see the level of difference (?) of feature output after average pooling layers (1024 outputs)of each model "},{"metadata":{},"cell_type":"markdown","source":"#### Step 3. See feature outputs (avegarge all outputs) for all training samples."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Redefine model too get 1024 feature output\nmodel_updated_feature = Model(inputs=model_updated.input,\n                              outputs=model_updated.get_layer(\"global_average_pooling2d_2\").output)\n\nmodel_pretrained_feature = Model(inputs=model_pretrained.input,\n                                 outputs=model_pretrained.get_layer(\"global_average_pooling2d_3\").output)\n\ntrain_total_generator.reset()\npreds_updated = model_updated_feature.predict(ds_total,steps=len(train_total_generator),verbose=1)\ntrain_total_generator.reset()\npreds_pretrained = model_pretrained_feature.predict(ds_total,steps=len(train_total_generator),verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\n\nle.fit(train_total['label'])\npreds_label = le.transform(train_total['label'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Calculate the average 1024 feature output "},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_updated_avg = [preds_updated[np.where(preds_label == x)].mean(axis = 0) for x in range(4)]\npreds_pretrained_avg = [preds_pretrained[np.where(preds_label == x)].mean(axis = 0) for x in range(4)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see the plot in below, 1024 feature output of retrined model (set all layers \"Trainable\") provides more information as everyone can expect."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10))\nplt.subplot(1,2,1)\nfor x in range(4):\n    plt.plot(preds_pretrained_avg[x], label = le.classes_[x])\n    plt.legend(loc='upper left')\nplt.subplot(1,2,2)\nfor x in range(4):\n    plt.plot(preds_updated_avg[x], label = le.classes_[x])\n    plt.legend(loc='upper left')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Additional Step. Compare the ground truth labels and the predicted labels and investiagte the source of error by GradCam"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_total_generator.reset()\npreds = model_updated.predict(ds_total,steps=len(train_total_generator),verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_df = pd.DataFrame(preds)\npreds_df = preds_df.rename(columns={0:'healthy',1:'multiple_diseases',2:'rust',3:'scab'})\n\npreds_df['p_label'] = preds_df.iloc[:,:4].idxmax(1)\n\nresult = pd.concat([train_total, preds_df], axis=1, sort=False)\n\nwrong_result = result[result.label != result.p_label]\n\nwrong_result.image_id.count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Load image files of error sample"},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_image(image_id):\n    image = load_img(os.path.join(data_dir,'images',image_id), target_size=(IMG_DIM,IMG_DIM ))\n    return img_to_array(image)\n\nid_list = wrong_result['image_id'].tolist()\nsuspisous_images = []\n\n\nfor ids in id_list:\n    suspisous_images.append(load_image(ids))\n\nsuspisous_images = np.array(suspisous_images,dtype='float32')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"suspisous_images = suspisous_images/256.\np_Label = wrong_result['p_label'].to_list()\nLabel = wrong_result['label'].to_list()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/input/gradcam')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from gradcam import GradCAM\n\nheatmaps = []\n\nfor orig in suspisous_images:\n    image = np.expand_dims(orig, axis=0)\n    preds = model_updated.predict(image)\n    i = np.argmax(preds)\n    cam = GradCAM(model_updated, i)\n    heatmap = cam.compute_heatmap(image)\n    heatmap = cv2.resize(heatmap, (IMG_DIM, IMG_DIM))\n    heatmaps.append(heatmap)\n\nheatmaps = np.array(heatmaps,dtype='float32')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,400))\nfor i in range(wrong_result.image_id.count()):\n    ax = plt.subplot(40,2,2*i+1)\n\n    ax.text(0.5, 1, 'GT : {} '.format(Label[i]),\n        verticalalignment='top', horizontalalignment='center',\n        transform=ax.transAxes,\n        color='White', fontsize=15)\n    ax.set_title(id_list[i])\n\n    plt.imshow(suspisous_images[i])\n        \n    ax = plt.subplot(40,2,2*i+2)\n    ax.text(0.5, 1, ' vs PRED : {}'.format(p_Label[i]),\n    verticalalignment='top', horizontalalignment='center',\n    transform=ax.transAxes,\n    color='White', fontsize=15)\n    ax.set_title(id_list[i])\n    \n    plt.imshow(suspisous_images[i])\n    plt.imshow(heatmaps[i],alpha=0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wrong_result","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observation:\n\n1. Transfer Learning approach would be a good starting point. By setting all layers as \"Trainnable\" would improve the model accuracy as 1024 feature output provide the more information\n2. Trained model with ImageNet which comprises general total population of images for image identification should be retrained for this type of pupose with specific populations\n3. Not sure why around 500 channels from 1024 is not activley responsive (may be more training epoch requried?)\n4. Most errors is coming from \"multiple diseases\" Segemnt ==> What is exact definition of \"multiple diseases\". Is it both \"rust\" and \"scab\"?"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}