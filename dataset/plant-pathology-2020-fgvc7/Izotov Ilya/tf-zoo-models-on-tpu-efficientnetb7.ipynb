{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Ссылки на работы, на которые базируется данное решение\n\n* https://www.kaggle.com/xhlulu/plant-pathology-very-concise-tpu-efficientnet\n* https://www.kaggle.com/dimakyn/classification-densenet201-efficientnetb7"},{"metadata":{},"cell_type":"markdown","source":"Если хотите работать на Google Colaboratory\n\nДля получения ключа доступа для API переходите\n*   https://www.kaggle.com/lkatran (где \"lkatran\" - ваш user name)\n*   нажимаем Edit Profile\n*   находим ниже раздел API\n*   нажимаем Create New API Token\n*   загружается файл kaggle.json\n*   в нем ваш ключ"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Уберите комменты и впишите свой USERNAME и Key from Kaggle\n# !mkdir /root/.kaggle\n# import json\n# kaggle = {\"username\":\"USERNAME\",\"key\":\"Key from Kaggle\"}\n# with open('/root/.kaggle/kaggle.json', 'w') as f:\n#     json.dump(kaggle, f)\n# !chmod 600 /root/.kaggle/kaggle.json\n# kaggle competitions download -c plant-pathology-2020-fgvc7","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ставим Efficientnet"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install -q efficientnet","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Импорт библиотек"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import math, re, os\n\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nfrom kaggle_datasets import KaggleDatasets\nimport tensorflow as tf\nimport tensorflow.keras.layers as L\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\n\n## ______________ БЛОК С ИМПОРТАМИ АРХИТЕКТУР ____________________\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications.vgg19 import VGG19\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\nfrom tensorflow.keras.applications.densenet import DenseNet121, DenseNet169, DenseNet201 \nfrom tensorflow.keras.applications.xception import Xception\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.applications.resnet_v2 import ResNet50V2, ResNet101V2, ResNet152V2\nfrom tensorflow.keras.applications.nasnet import NASNetLarge\nfrom efficientnet.tfkeras import EfficientNetB7, EfficientNetL2\n## ______________ КОНЕЦ БЛОКА С ИМПОРТАМИ АРХИТЕКТУР ____________________\n\n# импорт других полезных инструментов: слоев, оптимизаторов, функций обратной связи\nfrom tensorflow.keras.layers import Flatten,Dense,Dropout,BatchNormalization\nfrom tensorflow.keras.models import Model,Sequential\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Настраиваем TPU конфигурацию"},{"metadata":{"trusted":true},"cell_type":"code","source":"AUTO = tf.data.experimental.AUTOTUNE\n# Проверяем существующее оборудование и выбираем соответствующую стратегию использования вычислений\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    # онаружение TPU. Параметры не требуются если установленна переменная окружения TPU_NAME. На Kaggle это всегда True.\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() # если TPU отсутствует, то испльзуем стратегию по умолчанию для TF (CPU or GPU)\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)\n\n# Путь к данным. Если работаете на Google Colaboratory, то замените KaggleDatasets().get_gcs_path() на путь к данным, который будет у вас\nGCS_DS_PATH = KaggleDatasets().get_gcs_path()\n\n# Конфигурация\nEPOCHS = 40\nBATCH_SIZE = 8 * strategy.num_replicas_in_sync","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Посмотрим на данные"},{"metadata":{},"cell_type":"markdown","source":"## Загружаем метки классов и пути к изображениям"},{"metadata":{"trusted":true},"cell_type":"code","source":"# функция, которая превращает айди картинки в полный путь к ней\ndef format_path(st):\n    return GCS_DS_PATH + '/images/' + st + '.jpg'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/train.csv')\ntest = pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/test.csv')\nsub = pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/sample_submission.csv')\n\ntrain_paths = train.image_id.apply(format_path).values\ntest_paths = test.image_id.apply(format_path).values\n\ntrain_labels = train.loc[:, 'healthy':].values\n\n## если планируете обучать модель с валидирующим набором данных\ntrain_paths, valid_paths, train_labels, valid_labels = train_test_split(\n     train_paths, train_labels, test_size=0.06, random_state=2020)\n\n# дополню набор валидациоными данными (эксперимент)\ntrain_paths = train.image_id.apply(format_path).values\ntrain_labels = train.loc[:, 'healthy':].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import pyplot as plt\n\n# создаем сетку 2 на 5, для более компактного отображения символов и задаем размер их отображения\nf, ax = plt.subplots(3, 6, figsize=(18, 7))\nax = ax.flatten()\n# отрисовываем в цикле найденные топ N изображений частей графем\nfor i in range(18):\n    img = plt.imread(f'../input/plant-pathology-2020-fgvc7/images/Train_{i}.jpg')\n    ax[i].set_title(train[train['image_id']==f'Train_{i}'].melt()[train[train['image_id']==f'Train_{i}'].melt().value == 1]['variable'].values[0])\n    ax[i].imshow(img)\nprint(img.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Создаем объекты наборов данных\n\nA `tf.data.Dataset` объект нужен для того, чтобы модель бесперебойно работала на TPUs"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# устанавливаем глобальные переменные\nimg_size = 768\n\n# функция, которая читает изображение из файла и преобразовывает его к нужному размеру, а так же нормализует\ndef decode_image(filename, label=None, image_size=(img_size, img_size)):\n    bits = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(bits, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0\n    image = tf.image.resize(image, image_size)\n    \n    if label is None:\n        return image\n    else:\n        return image, label\n# функция расширения данных\ndef data_augment(image, label=None, seed=2020):\n    image = tf.image.random_flip_left_right(image, seed=seed)\n    image = tf.image.random_flip_up_down(image, seed=seed)\n    \n    if label is None:\n        return image\n    else:\n        return image, label","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Создаем объекты наборов данных для обучения, валидации и теста"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((train_paths, train_labels))\n    .map(decode_image, num_parallel_calls=AUTO)\n    .map(data_augment, num_parallel_calls=AUTO)\n    .repeat()\n    .shuffle(512)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTO)\n)\n## если планируете обучать модель с валидирующим набором данных\nvalid_dataset = (\n     tf.data.Dataset\n     .from_tensor_slices((valid_paths, valid_labels))\n     .map(decode_image, num_parallel_calls=AUTO)\n     .batch(BATCH_SIZE)\n     .cache()\n     .prefetch(AUTO)\n )\n\ntest_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices(test_paths)\n    .map(decode_image, num_parallel_calls=AUTO)\n    .batch(BATCH_SIZE)\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Строим и обучаем модель"},{"metadata":{},"cell_type":"markdown","source":"### Вспомогательные функции"},{"metadata":{"trusted":true},"cell_type":"code","source":"# функция управляющая изменениями шага обучения в процессе тренировки нейронной сети\nLR_START = 0.00001\nLR_MAX = 0.0001 * strategy.num_replicas_in_sync\nLR_MIN = 0.00001\nLR_RAMPUP_EPOCHS = 5\nLR_SUSTAIN_EPOCHS = 0\nLR_EXP_DECAY = .8\n\ndef lrfn(epoch):\n    if epoch < LR_RAMPUP_EPOCHS:\n        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n        lr = LR_MAX\n    else:\n        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n    return lr\n    \nlr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=True)\n\n# построим график изменения шага обучение в зависимости от эпох\nrng = [i for i in range(EPOCHS)]\ny = [lrfn(x) for x in rng]\nplt.plot(rng, y)\nprint(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Загружаем модель на TPU"},{"metadata":{"trusted":true},"cell_type":"code","source":"# тут можете заменять архитектуру EfficientNetB7 на любую другую из загруженных и наблюдать результат \n# VGG16, VGG19, InceptionV3, InceptionResNetV2, DenseNet121, DenseNet169, DenseNet201, Xception,\n#ResNet50, ResNet50V2, ResNet101V2, ResNet152V2, NASNetLarge, EfficientNetL2\n\ndef get_model(use_model):\n    base_model =  use_model(weights='noisy-student',\n                                 include_top=False, pooling='avg',\n                                 input_shape=(img_size, img_size, 3))\n    x = base_model.output\n    predictions = Dense(train_labels.shape[1], activation=\"softmax\")(x)\n    return Model(inputs=base_model.input, outputs=predictions)\n\nwith strategy.scope():\n    model = get_model(EfficientNetB7)\n    \nmodel.compile(optimizer='nadam', loss='categorical_crossentropy',metrics=['categorical_accuracy'])\n#model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Запускаем процесс обучения"},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"history = model.fit(\n            train_dataset, \n            steps_per_epoch=train_labels.shape[0] // BATCH_SIZE,\n            callbacks=[lr_callback, ModelCheckpoint(filepath='my_ef_net_b7.h5', monitor='val_loss',\n                                                    save_best_only=True)],\n            validation_data=valid_dataset,\n            epochs=EPOCHS\n         )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plt.plot(history.history['sparse_categorical_accuracy'], \nplt.plot(history.history['categorical_accuracy'], \n         label='Оценка точности на обучающем наборе')\nplt.plot(history.history['val_categorical_accuracy'], \n         label='Оценка точности на проверочном наборе')\nplt.xlabel('Эпоха обучения')\nplt.ylabel('Оценка точности')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['loss'], \n         label='Оценка потерь на обучающем наборе')\nplt.plot(history.history['val_loss'], \n         label='Оценка потерь на проверочном наборе')\nplt.xlabel('Эпоха обучения')\nplt.ylabel('Оценка потерь')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Проверка качества модели"},{"metadata":{},"cell_type":"markdown","source":"Unhide below to see helper function `display_training_curves`:"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def display_training_curves(training, title, subplot):\n    \"\"\"\n    Source: https://www.kaggle.com/mgornergoogle/getting-started-with-100-flowers-on-tpu\n    \"\"\"\n    if subplot%10==1: # set up the subplots on the first call\n        plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n        plt.tight_layout()\n    ax = plt.subplot(subplot)\n    ax.set_facecolor('#F8F8F8')\n    ax.plot(training)\n#     ax.plot(validation)\n    ax.set_title('model '+ title)\n    ax.set_ylabel(title)\n    #ax.set_ylim(0.28,1.05)\n    ax.set_xlabel('epoch')\n    ax.legend(['train', 'valid.'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"display_training_curves(\n    model.history.history['loss'], \n    'loss', 211)\ndisplay_training_curves(\n    model.history.history['categorical_accuracy'], \n    'accuracy', 212)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Если хотите сохранить модель, то "},{"metadata":{"trusted":true},"cell_type":"code","source":"#name_model = 'my_ef_net_b7.h5'\n\n## если на Google Colab, то\n# from google.colab import drive\n# drive.mount('/content/drive')\n# name_model = 'drive/My Drive/Colab Notebooks/efficientnet.h5'\n\n#model.save(name_model)\n\n## загрузить модель\nmodel = tf.keras.models.load_model('my_ef_net_b7.h5')\n# model = tf.keras.models.load_model(name_model) # загрузить готовую модель для дальнейшего использования","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Делаем прогноз тестовых данных и готовим представление данных для проверки"},{"metadata":{},"cell_type":"markdown","source":"Когда вы получите несколько моделей с высокими баллами, можно поробовать их объеденить\n\nprobs = (model1.predict(test_dataset)+model.predict(test_dataset))/2\n\nгде можно использовать и больше моделей, но тогда делить не на 2, а на количество использованных моделей"},{"metadata":{"trusted":true},"cell_type":"code","source":"probs = model.predict(test_dataset, verbose=1)\nsub.loc[:, 'healthy':] = probs\nsub.to_csv('submission.csv', index=False)\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# создаем сетку 2 на 5, для более компактного отображения символов и задаем размер их отображения\nf, ax = plt.subplots(3, 5, figsize=(18, 8))\nax = ax.flatten()\n# отрисовываем в цикле найденные топ N изображений частей графем\nfor i in range(15):\n    img = plt.imread(f'../input/plant-pathology-2020-fgvc7/images/Test_{i}.jpg')\n    ax[i].set_title(sub[sub['image_id']==f'Test_{i}'].melt().iloc[1:][sub[sub['image_id']==f'Test_{i}'].melt().iloc[1:].value >= 0.8]['variable'].values[0])\n    ax[i].imshow(img)\nprint(img.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## если работаете с Google Colaboratory\n# !kaggle competitions submit -c plant-pathology-2020-fgvc7 -f submission.csv -m \"xception_1_efficient_1\"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}