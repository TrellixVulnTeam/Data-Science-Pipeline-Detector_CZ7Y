{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install -q efficientnet","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import math, re, os\n\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nfrom kaggle_datasets import KaggleDatasets\nimport tensorflow as tf\nimport tensorflow.keras.layers as L\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\n\n## ______________ БЛОК С ИМПОРТАМИ АРХИТЕКТУР ____________________\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications.vgg19 import VGG19\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\nfrom tensorflow.keras.applications.densenet import DenseNet121, DenseNet169, DenseNet201 \nfrom tensorflow.keras.applications.xception import Xception\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.applications.resnet_v2 import ResNet50V2, ResNet101V2, ResNet152V2\nfrom tensorflow.keras.applications.nasnet import NASNetLarge\nfrom efficientnet.tfkeras import EfficientNetB7, EfficientNetL2\n## ______________ КОНЕЦ БЛОКА С ИМПОРТАМИ АРХИТЕКТУР ____________________\n\n# импорт других полезных инструментов: слоев, оптимизаторов, функций обратной связи\nfrom tensorflow.keras.layers import Flatten,Dense,Dropout,BatchNormalization\nfrom tensorflow.keras.models import Model,Sequential\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n\nimport tensorflow as tf\nfrom tensorflow.keras.applications.densenet import DenseNet201\nfrom tensorflow.keras.layers import Dropout, BatchNormalization, GaussianDropout\nfrom efficientnet.tfkeras import EfficientNetB5\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.applications.xception import Xception\n#  библиотека для работы с наборами данных на Kaggle\nfrom kaggle_datasets import KaggleDatasets\nimport re\nimport numpy as np\nimport random\nimport matplotlib.pyplot as plt\n%matplotlib inline \nprint(\"Tensorflow version \" + tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Определяем, какой ускоритель можем использовать"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"AUTO = tf.data.experimental.AUTOTUNE\n# Проверяем существующее оборудование и выбираем соответствующую стратегию использования вычислений\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    # онаружение TPU. Параметры не требуются если установленна переменная окружения TPU_NAME. На Kaggle это всегда True.\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() # если TPU отсутствует, то испльзуем стратегию по умолчанию для TF (CPU or GPU)\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)\n\n# Путь к данным. Если работаете на Google Colaboratory, то замените KaggleDatasets().get_gcs_path() на путь к данным, который будет у вас\nGCS_DS_PATH = KaggleDatasets().get_gcs_path(\"plant-pathology-2020-fgvc7\")\n\n# Конфигурация\nEPOCHS = 40\nBATCH_SIZE = 8 * strategy.num_replicas_in_sync","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Загружаем метки классов и пути к изображениям"},{"metadata":{"trusted":true},"cell_type":"code","source":"# функция, которая превращает айди картинки в полный путь к ней\ndef format_path(st):\n    return GCS_DS_PATH + '/images/' + st + '.jpg'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/train.csv')\ntest = pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/test.csv')\nsub = pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/sample_submission.csv')\n\ntrain_paths = train.image_id.apply(format_path).values\ntest_paths = test.image_id.apply(format_path).values\n\ntrain_labels = train.loc[:, 'healthy':].values\n\n## если планируете обучать модель с валидирующим набором данных\ntrain_paths, valid_paths, train_labels, valid_labels = train_test_split(\n     train_paths, train_labels, test_size=0.15, random_state=2020)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Создаем объекты наборов данных"},{"metadata":{"trusted":true},"cell_type":"code","source":"# устанавливаем глобальные переменные\nimg_size = 768\n\n# функция, которая читает изображение из файла и преобразовывает его к нужному размеру, а так же нормализует\ndef decode_image(filename, label=None, image_size=(img_size, img_size)):\n    bits = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(bits, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0\n    image = tf.image.resize(image, image_size)\n    \n    if label is None:\n        return image\n    else:\n        return image, label\n# функция расширения данных\ndef data_augment(image, label=None, seed=2020):\n    image = tf.image.random_flip_left_right(image, seed=seed)\n    image = tf.image.random_flip_up_down(image, seed=seed)\n    \n    if label is None:\n        return image\n    else:\n        return image, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((train_paths, train_labels))\n    .map(decode_image, num_parallel_calls=AUTO)\n    .map(data_augment, num_parallel_calls=AUTO)\n    .repeat()\n    .shuffle(512)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTO)\n)\n## если планируете обучать модель с валидирующим набором данных\nvalid_dataset = (\n     tf.data.Dataset\n     .from_tensor_slices((valid_paths, valid_labels))\n     .map(decode_image, num_parallel_calls=AUTO)\n     .batch(BATCH_SIZE)\n     .cache()\n     .prefetch(AUTO)\n )\n\ntest_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices(test_paths)\n    .map(decode_image, num_parallel_calls=AUTO)\n    .batch(BATCH_SIZE)\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Построить модель на TPU (или GPU, или CPU...) с Tensorflow 2.1!"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model(use_model):\n    base_model =  use_model(weights='noisy-student',\n                                 include_top=False, pooling='avg',\n                                 input_shape=(img_size, img_size, 3))\n    x = base_model.output\n    predictions = Dense(train_labels.shape[1], activation=\"softmax\")(x)\n    model = Model(inputs=base_model.input, outputs=predictions) \n    model.compile(optimizer='nadam', loss='categorical_crossentropy',metrics=['categorical_accuracy'])\n    return model\n\nwith strategy.scope():    \n    model1 = get_model(EfficientNetB7) # тут подставить свою модель\nmodel1.load_weights(\"/kaggle/input/tf-zoo-models-on-tpu-efficientnetb7/my_ef_net_b7.h5\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model(use_model):\n    base_model =  use_model(weights='imagenet',\n                                 include_top=False, pooling='avg',\n                                 input_shape=(img_size, img_size, 3))\n    x = base_model.output\n    predictions = Dense(train_labels.shape[1], activation=\"softmax\")(x)\n    model = Model(inputs=base_model.input, outputs=predictions) \n    model.compile(optimizer='nadam', loss='categorical_crossentropy',metrics=['categorical_accuracy'])\n    return model\n\nwith strategy.scope():    \n    model2 = get_model(DenseNet201) # тут подставить свою модель\nmodel2.load_weights(\"/kaggle/input/tf-zoo-models-on-tpu-densenet201/my_dense_net_201.h5\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model(use_model):\n    base_model =  use_model(weights='imagenet',\n                                 include_top=False, pooling='avg',\n                                 input_shape=(img_size, img_size, 3))\n    x = base_model.output\n    predictions = Dense(train_labels.shape[1], activation=\"softmax\")(x)\n    model = Model(inputs=base_model.input, outputs=predictions) \n    model.compile(optimizer='nadam', loss='categorical_crossentropy',metrics=['categorical_accuracy'])\n    return model\n\nwith strategy.scope():    \n    model3 = get_model(InceptionResNetV2) # тут подставить свою модель\nmodel3.load_weights(\"/kaggle/input/tf-zoo-models-on-tpu/InceptionResNetV2.h5\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Делаем прогноз тестовых данных и готовим представление данных для проверки"},{"metadata":{"trusted":true},"cell_type":"code","source":"best_alpha = 0.52\nbad_alpha = 0.33\nprint('Вычисляем предсказания...')\nprobabilities1 = model1.predict(test_dataset, verbose=1)\n#probabilities2 = model2.predict(test_dataset, verbose=1)\nprobabilities3 = model3.predict(test_dataset, verbose=1)\n\n#probabilities = best_alpha * probabilities1 + (1 - best_alpha - bad_alpha) * probabilities2 + bad_alpha * probabilities3\nprobabilities = best_alpha * probabilities1 + (1 - best_alpha) * probabilities3 \n\nprint(probabilities)\n\nsub.loc[:, 'healthy':] = probabilities\nsub.to_csv('submission.csv', index=False)\nsub.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}