{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport time\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision as tv\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    DEVICE = 'cuda'\nelse:\n    DEVICE = 'cpu'\nprint('Device:', DEVICE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if os.getcwd() == '/kaggle/working':\n    INPUT_DIR = '/kaggle/input/plant-pathology-2020-fgvc7'\nelse:\n    INPUT_DIR = './input'\n\nIMAGE_DIR = os.path.join(INPUT_DIR, 'images')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_csv = os.path.join(INPUT_DIR, 'train.csv')\ntest_csv = os.path.join(INPUT_DIR, 'test.csv')\n\ntrain_df = pd.read_csv(train_csv)\ntest_df = pd.read_csv(test_csv)\n\nCLASSES = list(train_df.columns[1:])\n\nprint('Classes:', CLASSES)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_image_as_numpy(name):\n    path = os.path.join(IMAGE_DIR, name+'.jpg')\n    tmp = Image.open(path)\n    image = np.array(tmp)\n    tmp.close()\n    return image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ImageDataset(torch.utils.data.Dataset):\n    H = 1365\n    W = 2048\n    HCROP = 1344\n    WCROP = 2016\n\n    def __init__(self, df, size=None, tflag=False):\n        super().__init__()\n        self.df = df\n        self.size = size\n        self.tflag = tflag\n        \n        classes = df.columns[1:]\n        if len(classes) == 0:\n            self.labels = None\n        else:\n            v01 = df[classes].values\n            self.labels = (v01 * np.array([0,1,2,3])).sum(axis=1)\n\n        box = []\n        if size is not None:\n            h, w = size\n            assert h <= self.HCROP and w <= self.WCROP\n            if tflag:\n                box.append(A.RandomCrop(self.HCROP, self.WCROP))\n            else:\n                box.append(A.CenterCrop(self.HCROP, self.WCROP))\n            if h != self.HCROP or w != self.WCROP:\n                box.append(A.Resize(h, w))       \n        if tflag:\n            add = [\n                A.HorizontalFlip(p=0.5),\n                A.VerticalFlip(p=0.5),\n                A.RandomBrightness(p=0.5),\n                A.RandomContrast(p=0.5),\n                A.RandomGamma(p=0.5),\n            ]\n            box.extend(add)\n        self.transform_numpy = A.Compose(box)\n        box.append(A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)))\n        box.append(ToTensorV2())\n        self.transform_torch = A.Compose(box)\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        image = self.get_oriented_image(idx)\n        image = self.transform_torch(image=image)['image']\n        if self.labels is None:\n            return image\n        else:\n            return image, self.labels[idx]\n\n    def get_name(self, idx):\n        return self.df.iloc[idx, 0]\n    \n    def get_oriented_image(self, idx):\n        name = self.df.iloc[idx, 0]\n        image = read_image_as_numpy(name)\n        if image.shape[1] < image.shape[0]:\n            image = image.transpose(1, 0, 2)\n        return image\n\n    def get(self, idx):\n        image = self.get_oriented_image(idx)\n        image = self.transform_numpy(image=image)['image']\n        return image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fetch_from_batch(batch):\n    if isinstance(batch, torch.Tensor):\n        x, y = batch, None\n    else:\n        x, y = batch\n    return x, y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_features(model, nf, ds):\n    dl = torch.utils.data.DataLoader(ds, batch_size=4, shuffle=False)\n    model.eval()\n    model.to(DEVICE)\n    features = np.empty([len(ds), nf])\n    beg = 0\n    with torch.no_grad():\n        for batch in dl:\n            x, y = fetch_from_batch(batch)\n            x = x.to(DEVICE)\n            batch_features = model(x)\n            end = beg + len(batch_features)\n            features[beg:end] = batch_features.cpu()\n            beg = end\n    return features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rn18 = tv.models.resnet18(pretrained=True)\nrn18.fc = nn.Identity()\n\nsizes = [\n    (224, 224),\n    (224, 336),\n    (336, 504),\n    (448, 672),\n    (672, 1008),\n]\n\nfor size in sizes:\n    dirname = 'rn18-%d-%d' % size\n    os.system('mkdir -p ' + dirname)\n\n    ds = ImageDataset(train_df, size, False)\n    features = make_features(rn18, 512, ds)\n    path = os.path.join(dirname, 'train.txt')\n    np.savetxt(path, features, fmt='%.9e')\n\n    ds = ImageDataset(test_df, size, False)\n    features = make_features(rn18, 512, ds)\n    path = os.path.join(dirname, 'test.txt')\n    np.savetxt(path, features, fmt='%.9e')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}