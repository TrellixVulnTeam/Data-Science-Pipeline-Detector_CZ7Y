{"cells":[{"cell_type":"code","execution_count":null,"id":"cardiovascular-learning","metadata":{},"outputs":[],"source":"import os\nimport time\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision as tv\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2"},{"cell_type":"code","execution_count":null,"id":"loose-transport","metadata":{},"outputs":[],"source":"if torch.cuda.is_available():\n    DEVICE = 'cuda'\nelse:\n    DEVICE = 'cpu'\nprint('Device:', DEVICE)"},{"cell_type":"code","execution_count":null,"id":"ranging-diabetes","metadata":{},"outputs":[],"source":"if os.getcwd() == '/kaggle/working':\n    INPUT_DIR = '/kaggle/input'\nelse:\n    INPUT_DIR = './input'\n\nPLANT_DIR = os.path.join(INPUT_DIR, 'plant-pathology-2020-fgvc7')\nIMAGE_DIR = os.path.join(PLANT_DIR, 'images')"},{"cell_type":"code","execution_count":null,"id":"interim-yesterday","metadata":{},"outputs":[],"source":"train_csv = os.path.join(PLANT_DIR, 'train.csv')\ntest_csv = os.path.join(PLANT_DIR, 'test.csv')\n\ntrain_df = pd.read_csv(train_csv)\ntest_df = pd.read_csv(test_csv)\n\nCLASSES = list(train_df.columns[1:])\n\nprint('Classes:', CLASSES)"},{"cell_type":"code","execution_count":null,"id":"experienced-creature","metadata":{},"outputs":[],"source":"def read_image_as_numpy(name):\n    path = os.path.join(IMAGE_DIR, name+'.jpg')\n    tmp = Image.open(path)\n    image = np.array(tmp)\n    tmp.close()\n    return image"},{"cell_type":"code","execution_count":null,"id":"entire-writing","metadata":{},"outputs":[],"source":"class ImageDataset(torch.utils.data.Dataset):\n    H = 1365\n    W = 2048\n    HCROP = 1344\n    WCROP = 2016\n\n    def __init__(self, df, size=None, tflag=False):\n        super().__init__()\n        self.df = df\n        self.size = size\n        self.tflag = tflag\n        \n        classes = df.columns[1:]\n        if len(classes) == 0:\n            self.labels = None\n        else:\n            v01 = df[classes].values\n            self.labels = (v01 * np.array([0,1,2,3])).sum(axis=1)\n\n        box = []\n        if size is not None:\n            h, w = size\n            assert h <= self.HCROP and w <= self.WCROP\n            if tflag:\n                box.append(A.RandomCrop(self.HCROP, self.WCROP))\n            else:\n                box.append(A.CenterCrop(self.HCROP, self.WCROP))\n            if h != self.HCROP or w != self.WCROP:\n                box.append(A.Resize(h, w))       \n        if tflag:\n            add = [\n                A.HorizontalFlip(p=0.5),\n                A.VerticalFlip(p=0.5),\n                A.RandomBrightness(p=0.5),\n                A.RandomContrast(p=0.5),\n                A.RandomGamma(p=0.5),\n            ]\n            box.extend(add)\n        self.transform_numpy = A.Compose(box)\n        box.append(A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)))\n        box.append(ToTensorV2())\n        self.transform_torch = A.Compose(box)\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        image = self.get_oriented_image(idx)\n        image = self.transform_torch(image=image)['image']\n        if self.labels is None:\n            return image\n        else:\n            return image, self.labels[idx]\n\n    def get_name(self, idx):\n        return self.df.iloc[idx, 0]\n    \n    def get_oriented_image(self, idx):\n        name = self.df.iloc[idx, 0]\n        image = read_image_as_numpy(name)\n        if image.shape[1] < image.shape[0]:\n            image = image.transpose(1, 0, 2)\n        return image\n\n    def get(self, idx):\n        image = self.get_oriented_image(idx)\n        image = self.transform_numpy(image=image)['image']\n        return image"},{"cell_type":"code","execution_count":null,"id":"expensive-monitoring","metadata":{},"outputs":[],"source":"def fetch_from_batch(batch):\n    if isinstance(batch, torch.Tensor):\n        x, y = batch, None\n    else:\n        x, y = batch\n    return x, y"},{"cell_type":"code","execution_count":null,"id":"automated-superior","metadata":{},"outputs":[],"source":"def make_features(model, nf, ds):\n    dl = torch.utils.data.DataLoader(ds, batch_size=4, shuffle=False)\n    model.eval()\n    model.to(DEVICE)\n    features = np.empty([len(ds), nf])\n    beg = 0\n    with torch.no_grad():\n        for batch in dl:\n            x, y = fetch_from_batch(batch)\n            x = x.to(DEVICE)\n            batch_features = model(x)\n            end = beg + len(batch_features)\n            features[beg:end] = batch_features\n            beg = end\n    return features"},{"cell_type":"code","execution_count":null,"id":"oriented-headline","metadata":{},"outputs":[],"source":"class FeatureDataset(torch.utils.data.Dataset):\n    def __init__(self, df, filepath):\n        super().__init__()\n        self.df = df\n        self.features = np.loadtxt(filepath, dtype=np.float32)\n        \n        classes = df.columns[1:]\n        if len(classes) == 0:\n            self.labels = None\n        else:\n            v01 = df[classes].values\n            self.labels = (v01 * np.array([0,1,2,3])).sum(axis=1)\n\n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        name = self.df.iloc[idx, 0]\n        beg = name.index('_') + 1\n        num = int(name[beg:])\n        x = torch.from_numpy(self.features[num])\n        if self.labels is None:\n            return x\n        else:\n            return x, self.labels[idx]"},{"cell_type":"code","execution_count":null,"id":"smooth-mistress","metadata":{},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"id":"interracial-composer","metadata":{},"outputs":[],"source":"class Stat:\n    def __init__(self):\n        self.reset()\n        \n    def reset(self):\n        self.loss_sum = 0\n        self.loss_tot = 0\n        self.acc_sum = 0\n        self.acc_tot = 0\n        \n    def update(self, pred, y, loss):\n        self.loss_sum += loss * len(y)\n        self.loss_tot += len(y)\n\n        probs = F.softmax(pred, dim=1)\n        _, labels = torch.max(probs, dim=1)\n        same = torch.sum(labels==y, dim=0).item()\n\n        self.acc_sum += same\n        self.acc_tot += len(y)\n\n    def summary(self):\n        loss = self.loss_sum / self.loss_tot if self.loss_tot > 0 else 0.\n        acc = self.acc_sum / self.acc_tot if self.acc_tot > 0 else 0.\n        return loss, acc"},{"cell_type":"code","execution_count":null,"id":"restricted-framing","metadata":{},"outputs":[],"source":"class Trainer:\n    def __init__(self, model, loss_fn, optimizer):\n        model.to(DEVICE)\n\n        self.model = model\n        self.loss_fn = loss_fn\n        self.optimizer = optimizer\n\n\n    def train(self, train_ds, n_epoch):\n        self.train_dl = torch.utils.data.DataLoader(train_ds, batch_size=64, shuffle=True)\n\n        self.stats = []\n        for epoch in range(n_epoch):\n            train_stat = self.train_epoch()\n            self.stats.append((epoch, train_stat))\n\n            \n    def train_and_valid(self, train_ds, valid_ds, n_epoch):\n        self.train_dl = torch.utils.data.DataLoader(train_ds, batch_size=64, shuffle=True)\n        self.valid_dl = torch.utils.data.DataLoader(valid_ds, batch_size=64, shuffle=False)\n\n        self.stats = []\n        for epoch in range(n_epoch):\n            train_stat = self.train_epoch()\n            valid_stat = self.valid_epoch()\n            self.stats.append((epoch, train_stat, valid_stat))\n\n\n    def train_epoch(self):\n        self.model.train()\n        stat = Stat()\n        for x, y in self.train_dl:\n            x = x.to(DEVICE)\n            y = y.to(DEVICE)\n            pred = self.model(x)\n            loss = self.loss_fn(pred, y)\n            loss_item = loss.item()\n            self.optimizer.zero_grad()\n            loss.backward()\n            self.optimizer.step()\n            stat.update(pred, y, loss_item)\n        return stat\n\n    \n    def valid_epoch(self):\n        self.model.eval()\n        stat = Stat()\n        with torch.no_grad():\n            for x, y in self.valid_dl:\n                x = x.to(DEVICE)\n                y = y.to(DEVICE)\n                pred = self.model(x)\n                loss = self.loss_fn(pred, y)\n                loss_item = loss.item()\n                stat.update(pred, y, loss_item)\n        return stat\n\n\n    def predict(self, ds):\n        self.model.eval()\n        dl = torch.utils.data.DataLoader(ds, batch_size=64, shuffle=False)\n        preds = np.empty([len(ds),len(CLASSES)], dtype=np.float32)\n        preds = torch.from_numpy(preds)\n        beg = 0\n        with torch.no_grad():\n            for batch in dl:\n                x, y = fetch_from_batch(batch)\n                x = x.to(DEVICE)\n                pred = self.model(x)\n                if DEVICE != 'cpu':\n                    pred = pred.to('cpu')\n                end = beg + len(pred)\n                preds[beg:end] = pred\n                beg = end\n        return preds"},{"cell_type":"code","execution_count":null,"id":"bulgarian-decrease","metadata":{},"outputs":[],"source":"def plot_learning(stats, suptitle=None):\n    x = []\n    t_y = []\n    v_y = []\n    for e, ts, vs in stats:\n        x.append(e)\n        t_y.append(ts.summary())\n        v_y.append(vs.summary())\n    t_y = np.array(t_y)\n    v_y = np.array(v_y)\n\n    fig, (ax0, ax1) = plt.subplots(1, 2)\n\n    if suptitle is not None:\n        fig.suptitle(suptitle)\n    \n    ax0.plot(x, t_y[:,0], v_y[:,0])\n    ax0.set_xlabel('epoch')\n    ax0.set_ylabel('loss')\n    txt = 'Valid min: %5.3f at epoch %d' % (v_y[:,0].min(), v_y[:,0].argmin())\n    ax0.text(0.4, 0.8, txt, transform=ax0.transAxes)\n\n    ax1.plot(x, t_y[:,1], v_y[:,1])\n    ax1.set_xlabel('epoch')\n    ax1.set_ylabel('accuracy')\n    txt = 'Valid max: %5.3f at epoch %d' % (v_y[:,1].max(), v_y[:,1].argmax())\n    ax1.text(0.4, 0.2, txt, transform=ax1.transAxes)\n\n    fig.set_size_inches(24/2.54, 12/2.54)\n    fig.tight_layout()\n\n    plt.show()"},{"cell_type":"code","execution_count":null,"id":"imposed-armenia","metadata":{},"outputs":[],"source":"def make_learning_curve(size, lr, n_epoch):\n    model = nn.Linear(512, len(CLASSES))\n    loss_fn = F.cross_entropy\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n    trainer = Trainer(model, loss_fn, optimizer)\n\n    path = os.path.join(INPUT_DIR, 'pp-2-features', 'rn18-%d-%d'%size, 'train.txt')\n    tds = FeatureDataset(train_df[:1000], path)\n    vds = FeatureDataset(train_df[1000:], path)\n\n    trainer.train_and_valid(tds, vds, n_epoch)\n\n    title = 'ResNet18-%d-%d' % size\n    plot_learning(trainer.stats, title)"},{"cell_type":"code","execution_count":null,"id":"increasing-japan","metadata":{},"outputs":[],"source":"def make_training(size, lr, n_epoch):\n    model = nn.Linear(512, len(CLASSES))\n    loss_fn = F.cross_entropy\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n    trainer = Trainer(model, loss_fn, optimizer)\n\n    path = os.path.join(INPUT_DIR, 'pp-2-features', 'rn18-%d-%d'%size, 'train.txt')\n    tds = FeatureDataset(train_df, path)\n\n    trainer.train(tds, n_epoch)\n\n    return trainer"},{"cell_type":"code","execution_count":null,"id":"infrared-directive","metadata":{},"outputs":[],"source":"def make_submit_file(probs, filename):\n    df = test_df.copy()\n    df[CLASSES] = probs\n    df.to_csv(filename, index=False, float_format='%8.6f')"},{"cell_type":"code","execution_count":null,"id":"variable-coverage","metadata":{},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"id":"adopted-harassment","metadata":{},"outputs":[],"source":"make_learning_curve((224,224), 2e-4, 500)"},{"cell_type":"code","execution_count":null,"id":"interim-fifty","metadata":{},"outputs":[],"source":"make_learning_curve((224,336), 5e-4, 500)"},{"cell_type":"code","execution_count":null,"id":"cheap-welcome","metadata":{},"outputs":[],"source":"make_learning_curve((336,504), 5e-4, 500)"},{"cell_type":"code","execution_count":null,"id":"documentary-wright","metadata":{},"outputs":[],"source":"make_learning_curve((448,672), 5e-4, 500)"},{"cell_type":"code","execution_count":null,"id":"indian-spouse","metadata":{},"outputs":[],"source":"make_learning_curve((672,1008), 1e-3, 500)"},{"cell_type":"code","execution_count":null,"id":"spoken-society","metadata":{},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"id":"differential-logistics","metadata":{},"outputs":[],"source":"# Train for submission"},{"cell_type":"code","execution_count":null,"id":"checked-vulnerability","metadata":{},"outputs":[],"source":"trainer = make_training((448,672), 5e-4, 300)"},{"cell_type":"code","execution_count":null,"id":"smoking-flesh","metadata":{},"outputs":[],"source":"size = (448,672)\npath = os.path.join(INPUT_DIR, 'pp-2-features', 'rn18-%d-%d'%size, 'test.txt')\nds = FeatureDataset(test_df, path)\npreds = trainer.predict(ds)\nprobs = F.softmax(preds, dim=1)"},{"cell_type":"code","execution_count":null,"id":"random-click","metadata":{},"outputs":[],"source":"make_submit_file(probs, 'submit-rn18-448-672-fe.csv')"},{"cell_type":"code","execution_count":null,"id":"united-drain","metadata":{},"outputs":[],"source":"! head -n 3 submit-rn18-448-672-fe.csv\n! tail -n 3 submit-rn18-448-672-fe.csv"},{"cell_type":"code","execution_count":null,"id":"egyptian-louis","metadata":{},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"id":"damaged-marine","metadata":{},"outputs":[],"source":"# Train for final layer in finetuning"},{"cell_type":"code","execution_count":null,"id":"digital-organ","metadata":{},"outputs":[],"source":"trainer = make_training((448,672), 5e-4, 50)"},{"cell_type":"code","execution_count":null,"id":"delayed-daisy","metadata":{},"outputs":[],"source":"torch.save(trainer.model.state_dict(), 'rn18-448-672-fc.sd')"},{"cell_type":"code","execution_count":null,"id":"smart-windsor","metadata":{},"outputs":[],"source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":5}