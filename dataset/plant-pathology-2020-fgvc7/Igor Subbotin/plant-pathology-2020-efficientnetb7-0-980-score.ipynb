{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Plant pathology 2020\nIn this notebook you will see simple to code model with data preparation and results submission. I used EfficientNetB7, because it is amazing to classify images, but it is slow and heavy. So we need to use TPU to speed up our training proccess and to be able to store data in memory.\nPlay with number of epochs to get 0.980","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport tensorflow as tf, tensorflow.keras.backend as K\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import optimizers\nfrom kaggle_datasets import KaggleDatasets","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" **TPU preparation**","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"AUTO = tf.data.experimental.AUTOTUNE\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)\n\nGCS_DS_PATH = KaggleDatasets().get_gcs_path()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Important constants**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"IMG_SIZE = 784\nBATCH_SIZE = 8*strategy.num_replicas_in_sync\nnb_classes = 4","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Loading data**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"path='../input/plant-pathology-2020-fgvc7/'\n\ntrain = pd.read_csv(path+'train.csv')\ntrain_id = train['image_id']\ntrain.pop('image_id')\n\ny_train = train.to_numpy().astype('float32')\ncategory_names = ['healthy','multiple_diseases','rust','scab']\n\nroot = 'images'\nimages_paths = [(os.path.join(GCS_DS_PATH,root,idee+'.jpg')) for idee in train_id]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Split data into train and validation set**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_val,y_train,y_val = train_test_split(images_paths,y_train,test_size=0.2,shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Class weights**\n\nDataset is not balanced, so we need to use class_weights. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.utils.class_weight import compute_class_weight\nclass_weights = compute_class_weight('balanced',np.unique(y_train.argmax(axis=1)),y_train.argmax(axis=1))\nprint('class weights: ',class_weights)\n\nplt.bar(range(4),1/class_weights,color=['springgreen', 'lightcoral', 'mediumpurple', 'gold'],width=0.9)\nplt.xticks(range(4), category_names) \n\nplt.title(\"Categories distribution\");\nplt.ylabel('Probability')\nplt.xlabel('Data')\nplt.show()\n\n#class weights to dict\nc_w = dict(zip(range(4),class_weights))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"functions to image preprocessing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def decode_image(filename, label=None, image_size=(IMG_SIZE, IMG_SIZE)):\n    bits = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(bits, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0\n    image = tf.image.resize(image, image_size)\n    \n    #convert to numpy and do some cv2 staff mb?\n    \n    if label is None:\n        return image\n    else:\n        return image, label\n\ndef data_augment(image, label=None, seed=5050):\n    image = tf.image.random_flip_left_right(image, seed=seed)\n    image = tf.image.random_flip_up_down(image, seed=seed)\n           \n    if label is None:\n        return image\n    else:\n        return image, label","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Preparing train and validation sets**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((x_train, y_train))\n    .map(decode_image, num_parallel_calls=AUTO)\n    .map(data_augment, num_parallel_calls=AUTO)\n    .repeat()\n    .shuffle(512)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTO)\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_dataset = (tf.data.Dataset\n               .from_tensor_slices((x_val,y_val))\n               .map(decode_image,num_parallel_calls=AUTO)\n               .batch(BATCH_SIZE)\n               .cache()\n               .prefetch(AUTO)\n              )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install efficientnet\nimport efficientnet.tfkeras as efn\nimport tensorflow as tf, tensorflow.keras.backend as K\nfrom tensorflow.keras.layers import Dense,Dropout\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import optimizers","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Model architecture**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model():\n    base_model = efn.EfficientNetB7(weights='imagenet',\n                          include_top=False,\n                          input_shape=(IMG_SIZE,IMG_SIZE, 3),\n                          pooling='avg')\n    x = base_model.output\n    predictions = Dense(nb_classes, activation=\"softmax\")(x)\n    return Model(inputs=base_model.input, outputs=predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\n\nwith strategy.scope():\n    model = get_model()\n\nopt = Adam(lr=0.001)\nmodel.compile(optimizer=opt, loss='categorical_crossentropy',metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**callbacks**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\n\nmodel_name = 'effNetPlants.h5'\n\n#good callbacks\nbest_model = ModelCheckpoint(model_name, monitor='val_loss', verbose=1, save_best_only=True,save_weights_only=True,mode='min')\nreduce_lr = ReduceLROnPlateau(monitor='val_loss',factor=0.5,verbose=1,min_lr=0.000001,patience=6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(train_dataset,\n                    steps_per_epoch=y_train.shape[0]//BATCH_SIZE,\n                    epochs=5,\n                    verbose=1,\n                    validation_data=val_dataset,\n                    callbacks=[reduce_lr,best_model]\n                    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title('model accuracy')\nplt.plot(history.history['val_accuracy'])\nplt.plot(history.history['accuracy'])\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path='../input/plant-pathology-2020-fgvc7/'\n\ntest = pd.read_csv(path+'test.csv')\ntest_id = test['image_id']\n\nroot = 'images'\nx_test = [(os.path.join(GCS_DS_PATH,root,idee+'.jpg')) for idee in test_id]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights(model_name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices(x_test)\n    .map(decode_image, num_parallel_calls=AUTO)\n    .batch(BATCH_SIZE)\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(test_dataset,verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def save_results(y_pred):\n    \n    path='../input/plant-pathology-2020-fgvc7/'\n    test = pd.read_csv(path + 'test.csv')\n    test_id = test['image_id']\n\n    res = pd.read_csv(path+'train.csv')\n    res['image_id'] = test_id\n  \n    labels = res.keys()\n\n    for i in range(1,5):\n        res[labels[i]] = y_pred[:,i-1]\n\n    res.to_csv('submission.csv',index=False)\n  \n    print(res.head)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"save_results(y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If  it was helpful, please vote. It will motivate me to create more notebooks.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}