{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Leaf Disease Detection\nIn this notebook, you would need to implement a CNN classifier for leaf disease detection. Your goal is to submit your predictions to the competition! Feel free to use previous case studies, but make sure you understand what the code is doing before using it.","metadata":{}},{"cell_type":"code","source":"import os\nfrom os.path import join\n\nfrom tqdm.notebook import tqdm # progress bar\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\n\nimport cv2\n\nimport matplotlib.pyplot as plt\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\n\nfrom sklearn.model_selection import train_test_split\n\nfrom IPython.display import SVG\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Data","metadata":{}},{"cell_type":"code","source":"IMAGE_PATH = \"../input/plant-pathology-2020-fgvc7/images/\"\nTEST_PATH = \"../input/plant-pathology-2020-fgvc7/test.csv\"\nTRAIN_PATH = \"../input/plant-pathology-2020-fgvc7/train.csv\"\nSUB_PATH = \"../input/plant-pathology-2020-fgvc7/sample_submission.csv\"\nMODEL_PATH = \"models/plant_pathology_model.h5\"\n\nsub = pd.read_csv(SUB_PATH)\ndf_test = pd.read_csv(TEST_PATH)\ndf_train = pd.read_csv(TRAIN_PATH)\n\nEPOCHS = 50\n\n# Define size of the image to train on\n# Remember: large image size will probably lead to higher performance\n# at the expense of long training time and large memory use\nIMAGE_X = ... #---YOUR VALUE HERE---\nIMAGE_Y = ... #---YOUR VALUE HERE---\n\nlabels = ['healthy', 'multiple_diseases', 'rust', 'scab']","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Explore the data","metadata":{}},{"cell_type":"code","source":"df_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Training set size:', len(df_train))\nfor label in labels:\n    print(f\"\\t{label}: {df_train[df_train[label]==1].shape[0]}\")\nprint('Test set size:', len(df_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Here you can include any other exploration you might want to do\n\n... #---YOUR CODE HERE---","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Generators and Augmentation","metadata":{}},{"cell_type":"code","source":"# Convert the names of the images into a correct path\ndef format_path(st):\n    return os.path.join(IMAGE_PATH, st + '.jpg')\n\n# Genereate train and test paths\ntrain_paths = ... #---YOUR CODE HERE---\ntest_paths = ... #---YOUR CODE HERE---\n\n# Convert the labels to floats\ntrain_labels = #---YOUR CODE HERE---\n\n# Split the data into validation and training sets\ntrain_paths, valid_paths, train_labels, valid_labels = #---YOUR CODE HERE---","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def decode_image(filename, label=None, image_size=(IMAGE_X, IMAGE_Y)):\n    \"\"\"\n    Loads, normalizes and resizes the image\n    \"\"\"\n    #---YOUR CODE HERE---\n    ...\n\ndef data_augment(image, label=None):\n    \"\"\"\n    Define your data augmentations here\n    \"\"\"\n    #---YOUR CODE HERE---\n    ...","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AUTO = tf.data.experimental.AUTOTUNE\nBATCH_SIZE = 64\n\n# Create datasets\ntrain_dataset = ... #---YOUR CODE HERE---\n\nvalid_dataset = ... #---YOUR CODE HERE---\n\ntest_dataset = ... #---YOUR CODE HERE---","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Definition","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import MobileNet, DenseNet121\nfrom tensorflow.keras import layers\n\n# Define model architecture\nmodel = ... #---YOUR CODE HERE---\n\n# compile the model\nmodel.compile(... #---YOUR CODE HERE---","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Callbacks","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n\n# Define checkpointing callback\nmcp = ... #---YOUR CODE HERE---\n\n# Define learnning rate schedule\ndef build_lrfn(lr_start=0.00001, lr_max=0.00005, \n               lr_min=0.00001, lr_rampup_epochs=5, \n               lr_sustain_epochs=0, lr_exp_decay=.8):\n    #define your learning rate schedule\n    ... #---YOUR CODE HERE---\n\n# Create a learning rate schedule as keras callback\nlrfn = build_lrfn()\nlr_schedule = ... #---YOUR CODE HERE---","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize the learning rate across epochs\nepochs_dummy = list(range(0, 50))\ny = [lrfn(e) for e in epochs_dummy]\nfig = go.Figure(go.Scatter(x=epochs_dummy, y=y, mode='lines+markers'))\nfig.update_layout(\n    yaxis = dict(\n        showexponent='all',\n        exponentformat='e'\n    ),\n    title='Learning rate schedule'\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training","metadata":{}},{"cell_type":"code","source":"# setup the callbacks\ncallbacks = ... #---YOUR CODE HERE---\n\n# train your model\nhistory = model.fit(... #---YOUR CODE HERE---","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\n\ndef visualize_training_process(history):\n    \"\"\" \n    Visualize loss and accuracy from training history\n    \n    :param history: A Keras History object\n    \"\"\"\n    history_df = pd.DataFrame(history.history)\n    epochs = np.arange(1, len(history_df) + 1)\n    fig = make_subplots(2, 1)\n    fig.append_trace(go.Scatter(x=epochs, y=history_df['categorical_accuracy'], mode='lines+markers', name='Accuracy Train'), row=1, col=1)\n    fig.append_trace(go.Scatter(x=epochs, y=history_df['val_categorical_accuracy'], mode='lines+markers', name='Accuracy Val'), row=1, col=1)\n    \n    fig.append_trace(go.Scatter(x=epochs, y=history_df['loss'], mode='lines+markers', name='Loss Train'), row=2, col=1)\n    fig.append_trace(go.Scatter(x=epochs, y=history_df['val_loss'], mode='lines+markers', name='Loss Val'), row=2, col=1)\n    \n    fig.update_layout( xaxis_title=\"Epochs\", template=\"plotly_white\")\n    \n    return fig\nvisualize_training_process(history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate performance of model by plotting confusion matrix\nfrom sklearn.metrics import confusion_matrix\n\n# see http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\nimport itertools\n\ndef accuracy(y, y_pred):\n    return np.sum(y == y_pred)/len(y)\n\ndef plot_confusion_matrix(cm, labels=None, title='Confusion Matrix'):\n    import plotly.figure_factory as ff\n\n    x = labels\n    y = x\n\n    # change each element of z to type string for annotations\n    z_text = [[str(y) for y in x] for x in cm]\n\n    # set up figure \n    fig = ff.create_annotated_heatmap(cm, x=x, y=y, annotation_text=z_text, colorscale='YlGnBu', showscale=True)\n\n    # add title\n    fig.update_layout(title_text=title,\n                      #xaxis = dict(title='x'),\n                      #yaxis = dict(title='x')\n                     )\n\n    # add custom xaxis title\n    fig.add_annotation(dict(font=dict(color=\"black\",size=14),\n                            x=0.5,\n                            y=-0.15,\n                            showarrow=False,\n                            text=\"Predicted value\",\n                            xref=\"paper\",\n                            yref=\"paper\"))\n\n    # add custom yaxis title\n    fig.add_annotation(dict(font=dict(color=\"black\",size=14),\n                            x=-0.35,\n                            y=0.5,\n                            showarrow=False,\n                            text=\"Real value\",\n                            textangle=-90,\n                            xref=\"paper\",\n                            yref=\"paper\"))\n\n    # adjust margins to make room for yaxis title\n    fig.update_layout(margin=dict(t=100, l=200), width=700, height=600)\n    fig.show()\n    \n# predict labels from validation set\ny_pred = model.predict(valid_dataset)\n# convert data to label number\ny_pred = np.argmax(y_pred, axis=1) \ny_true = np.argmax(valid_labels, axis=1) \n\n# compute the confusion matrix\ncm = confusion_matrix(y_true, y_pred) \n\nplot_confusion_matrix(cm, labels, title='Confusion_matrix Validation Set (acc={:.3f})'.format(accuracy(y_true, y_pred)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save predictions","metadata":{}},{"cell_type":"code","source":"# Predict labels on the test set\npredictions = model.predict(test_dataset)\n\n# Prepare the submission file\nsub.loc[:, 'healthy':] = predictions\nsub.to_csv('submission_densenet.csv', index=False)\nsub.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The last step is to submit your predictions!","metadata":{}}]}