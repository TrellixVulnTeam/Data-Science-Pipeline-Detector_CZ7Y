{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Leaf Disease Detection\n\nLearning goals:\n- Learn how to create datasets with TensorFlow data API\n- Learn how to train a DenseNet for leaf disease classification task\n- Learn how to submit your predictions"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nfrom os.path import join\n\nfrom tqdm.notebook import tqdm # progress bar\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\n\nimport cv2\n\nimport matplotlib.pyplot as plt\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\n\nfrom sklearn.model_selection import train_test_split\n\nfrom IPython.display import SVG\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load Data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"IMAGE_PATH = \"../input/plant-pathology-2020-fgvc7/images/\"\nTEST_PATH = \"../input/plant-pathology-2020-fgvc7/test.csv\"\nTRAIN_PATH = \"../input/plant-pathology-2020-fgvc7/train.csv\"\nSUB_PATH = \"../input/plant-pathology-2020-fgvc7/sample_submission.csv\"\nMODEL_PATH = \"models/plant_pathology_model.h5\"\n\nsub = pd.read_csv(SUB_PATH)\ndf_test = pd.read_csv(TEST_PATH)\ndf_train = pd.read_csv(TRAIN_PATH)\n\nEPOCHS = 50\n\n# Define size of the image to train on\nIMAGE_X = 224\nIMAGE_Y = 224\n\nlabels = ['healthy', 'multiple_diseases', 'rust', 'scab']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Explore the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Training set size:', len(df_train))\nfor label in labels:\n    print(f\"\\t{label}: {df_train[df_train[label]==1].shape[0]}\")\nprint('Test set size:', len(df_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Check if every image belongs to each class"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sum all of the labels together\ndf_train['number_of_classes'] = df_train['healthy'] + \\\n                                df_train['multiple_diseases'] + \\\n                                df_train['rust'] + df_train['scab']\n\n# mean should be 1, std should be 0\ndf_train['number_of_classes'].mean(), df_train['number_of_classes'].std()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_image(image_id):\n    file_path = \"{}{}\".format(image_id, \".jpg\")\n    image = cv2.imread(join(IMAGE_PATH, file_path))\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    return image\n\n# plot some images\ndef plot_sample_images(preprocess_fn=None, nrows=4, ncols=4):\n    fig, axs = plt.subplots(nrows, ncols,\n                            figsize=(12,10)\n                           )\n    axs = axs.ravel() # make 1D array for easy plotting in for loop\n\n    for i, image_id in enumerate(np.random.randint(len(df_train), size=nrows*ncols)):\n        # show an image\n        img = load_image(df_train['image_id'][image_id])\n        \n        if preprocess_fn:\n            img = preprocess_fn(img)\n        axs[i].imshow(img)\n        axs[i].axis(False)\n        label = df_train.loc[:, 'healthy':].iloc[image_id, :].idxmax()\n        axs[i].set_title('{} | {}'.format(df_train['image_id'][image_id], label))\n        plt.tight_layout()\nplot_sample_images(nrows=4, ncols=4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the plot below you can check the exact values of each pixel. Notice that most of the pixels have high green and low blue values. However the spot on the leaf has high blue value."},{"metadata":{"trusted":true},"cell_type":"code","source":"image = load_image(df_train['image_id'][0])\nfig = px.imshow(image)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets have a closer look at the distribution of the channel values."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Code thanks to https://www.kaggle.com/tarunpaparaju/plant-pathology-2020-eda-models\n\ntrain_images = df_train[\"image_id\"][:100].apply(load_image)\n\nred_values = [np.mean(train_images[idx][:, :, 0]) for idx in range(len(train_images))]\ngreen_values = [np.mean(train_images[idx][:, :, 1]) for idx in range(len(train_images))]\nblue_values = [np.mean(train_images[idx][:, :, 2]) for idx in range(len(train_images))]\nvalues = [np.mean(train_images[idx]) for idx in range(len(train_images))]\n\nfig = ff.create_distplot([red_values, green_values, blue_values],\n                         group_labels=[\"R\", \"G\", \"B\"],\n                         colors=[\"red\", \"green\", \"blue\"])\nfig.update_layout(title_text=\"Distribution of channel values\")\nfig","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the plot above we can see that the most pronounced color is green, which has the highest values. All other channels are shifted to the left with blue being the least pronounced."},{"metadata":{},"cell_type":"markdown","source":"## Data Generators and Augmentation\nFor loading and augmenting the data we are going to use the tensorflow dataset API."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert the names of the images into a correct path\ndef format_path(st):\n    return os.path.join(IMAGE_PATH, st + '.jpg')\n\n# Genreate train and test paths\ntrain_paths = df_train.image_id.apply(format_path).values\ntest_paths = df_test.image_id.apply(format_path).values\n\n# Convert the labels to floats\ntrain_labels = np.float32(df_train.loc[:, 'healthy':'scab'].values)\n# Split the data into validation and training sets\ntrain_paths, valid_paths, train_labels, valid_labels = train_test_split(train_paths, train_labels, test_size=0.15, random_state=2020)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def decode_image(filename, label=None, image_size=(IMAGE_X, IMAGE_Y)):\n    \"\"\"\n    Loads, normalizes and resizes the image\n    \"\"\"\n    bits = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(bits, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0\n    image = tf.image.resize(image, image_size)\n    \n    if label is None:\n        return image\n    else:\n        return image, label\n\ndef data_augment(image, label=None):\n    \"\"\"\n    Define your data augmentations here\n    \"\"\"\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    \n    if label is None:\n        return image\n    else:\n        return image, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"AUTO = tf.data.experimental.AUTOTUNE\nBATCH_SIZE = 64\n\ntrain_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((train_paths, train_labels))\n    .map(decode_image, num_parallel_calls=AUTO)\n    .map(data_augment, num_parallel_calls=AUTO)\n    .repeat()\n    .shuffle(512)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTO)\n)\n\nvalid_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((valid_paths, valid_labels))\n    .map(decode_image, num_parallel_calls=AUTO)\n    .batch(BATCH_SIZE)\n    .cache()\n    .prefetch(AUTO)\n)\n\ntest_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices(test_paths)\n    .map(decode_image, num_parallel_calls=AUTO)\n    .batch(BATCH_SIZE)\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## DenseNet\nFor this example we are going to use DenseNet model with pretrained weights. Instead of relying on extremely deep architectures DenseNet encourages feature reuse. The output of each Dense Block is being used as input for the next one.\n<div align=\"center\">\n<a><img src=\"https://files.ai-pool.com/m/densenet.png\" width=\"600\"></a>\n</div>\n\nMore details can be found in the lecture slides or in the [original paper](https://arxiv.org/pdf/1608.06993.pdf).\n\nLet's train it on the leaf disease detection task and evaluate its performance."},{"metadata":{},"cell_type":"markdown","source":"### Model Definition"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications import MobileNet, DenseNet121\nfrom tensorflow.keras import layers\n\n# Define model architecture\nmodel = tf.keras.Sequential(\n    [DenseNet121(\n        input_shape=(IMAGE_X, IMAGE_Y, 3),\n        weights='imagenet',\n        include_top=False),\n     layers.GlobalAveragePooling2D(),\n     layers.Dense(train_labels.shape[1], activation='softmax')\n    ]\n)\n        \nmodel.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['categorical_accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Callbacks"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n\n# Define checkpointing callback\nmcp = ModelCheckpoint(MODEL_PATH, monitor='val_loss', save_best_only=True, verbose=0)\n\n# Define learnning rate schedule\ndef build_lrfn(lr_start=0.00001, lr_max=0.00005, \n               lr_min=0.00001, lr_rampup_epochs=5, \n               lr_sustain_epochs=0, lr_exp_decay=.8):\n    lr_max = lr_max\n\n    def lrfn(epoch):\n        if epoch < lr_rampup_epochs:\n            lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start\n        elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n            lr = lr_max\n        else:\n            lr = (lr_max - lr_min) *\\\n                 lr_exp_decay**(epoch - lr_rampup_epochs\\\n                                - lr_sustain_epochs) + lr_min\n        return lr\n    return lrfn\n\n# Create a learning rate schedule as keras callback\nlrfn = build_lrfn()\nlr_schedule = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize the learning rate across epochs\nepochs_dummy = list(range(0, 50))\ny = [lrfn(e) for e in epochs_dummy]\nfig = go.Figure(go.Scatter(x=epochs_dummy, y=y, mode='lines+markers'))\nfig.update_layout(\n    yaxis = dict(\n        showexponent='all',\n        exponentformat='e'\n    ),\n    title='Learning rate schedule'\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"callbacks = [\n    lr_schedule, # use learning rate scheduler\n    mcp,         # checkpoint models\n]\n\nhistory = model.fit(train_dataset,\n                    epochs=EPOCHS,\n                    callbacks=callbacks,\n                    steps_per_epoch=len(df_train) // BATCH_SIZE,\n                    validation_data=valid_dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\n\ndef visualize_training_process(history):\n    \"\"\" \n    Visualize loss and accuracy from training history\n    \n    :param history: A Keras History object\n    \"\"\"\n    history_df = pd.DataFrame(history.history)\n    epochs = np.arange(1, len(history_df) + 1)\n    fig = make_subplots(2, 1)\n    fig.append_trace(go.Scatter(x=epochs, y=history_df['categorical_accuracy'], mode='lines+markers', name='Accuracy Train'), row=1, col=1)\n    fig.append_trace(go.Scatter(x=epochs, y=history_df['val_categorical_accuracy'], mode='lines+markers', name='Accuracy Val'), row=1, col=1)\n    \n    fig.append_trace(go.Scatter(x=epochs, y=history_df['loss'], mode='lines+markers', name='Loss Train'), row=2, col=1)\n    fig.append_trace(go.Scatter(x=epochs, y=history_df['val_loss'], mode='lines+markers', name='Loss Val'), row=2, col=1)\n    \n    fig.update_layout( xaxis_title=\"Epochs\", template=\"plotly_white\")\n    \n    return fig\nvisualize_training_process(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluate performance of model by plotting confusion matrix\nfrom sklearn.metrics import confusion_matrix\n\n# see http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\nimport itertools\n\ndef accuracy(y, y_pred):\n    return np.sum(y == y_pred)/len(y)\n\ndef plot_confusion_matrix(cm, labels=None, title='Confusion Matrix'):\n    import plotly.figure_factory as ff\n\n    x = labels\n    y = x\n\n    # change each element of z to type string for annotations\n    z_text = [[str(y) for y in x] for x in cm]\n\n    # set up figure \n    fig = ff.create_annotated_heatmap(cm, x=x, y=y, annotation_text=z_text, colorscale='YlGnBu', showscale=True)\n\n    # add title\n    fig.update_layout(title_text=title,\n                      #xaxis = dict(title='x'),\n                      #yaxis = dict(title='x')\n                     )\n\n    # add custom xaxis title\n    fig.add_annotation(dict(font=dict(color=\"black\",size=14),\n                            x=0.5,\n                            y=-0.15,\n                            showarrow=False,\n                            text=\"Predicted value\",\n                            xref=\"paper\",\n                            yref=\"paper\"))\n\n    # add custom yaxis title\n    fig.add_annotation(dict(font=dict(color=\"black\",size=14),\n                            x=-0.35,\n                            y=0.5,\n                            showarrow=False,\n                            text=\"Real value\",\n                            textangle=-90,\n                            xref=\"paper\",\n                            yref=\"paper\"))\n\n    # adjust margins to make room for yaxis title\n    fig.update_layout(margin=dict(t=100, l=200), width=700, height=600)\n    fig.show()\n    \n# predict labels from validation set\ny_pred = model.predict(valid_dataset)\n# convert data to label number\ny_pred = np.argmax(y_pred, axis=1) \ny_true = np.argmax(valid_labels, axis=1) \n\n# compute the confusion matrix\ncm = confusion_matrix(y_true, y_pred) \n\nplot_confusion_matrix(cm, labels, title='Confusion_matrix Validation Set (acc={:.3f})'.format(accuracy(y_true, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Save predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predict labels on the test set\npredictions = model.predict(test_dataset)\n\n# Prepare the submission file\nsub.loc[:, 'healthy':] = predictions\nsub.to_csv('submission_densenet.csv', index=False)\nsub.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}