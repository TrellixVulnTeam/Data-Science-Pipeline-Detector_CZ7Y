{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introducción","metadata":{}},{"cell_type":"markdown","source":"La producción de frutas y cultivos en todo el mundo está muy influenciada por diversas enfermedades. Una disminución en la producción conduce a una degradación económica de la industria agrícola en todo el mundo. Los manzanos se cultivan en todo el mundo, y la manzana es una de las frutas más consumidas del mundo.\n\nExploraremos múltiples técnicas de pre-procesamiento de imágenes para mejorar la visibilidad de indicadores patológicos en plantas. ","metadata":{}},{"cell_type":"markdown","source":"# Exploración de datos","metadata":{}},{"cell_type":"markdown","source":"Primero, veamos la estructura del conjunto de datos y una descripción estadística de este, con el fin de conocer un poco más de las imágenes de las plantas que presentan o no enfermedades y así determinar cómo mejorar su visibilidad.","metadata":{}},{"cell_type":"markdown","source":"## Importación de las librerías necesarias","metadata":{}},{"cell_type":"markdown","source":"Importamos las librerías necesarias para leer los datos, explorarlos y procesarlos.","metadata":{}},{"cell_type":"code","source":"import os\n\nimport pandas as pd\nimport cv2\nimport numpy as np\n\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n%matplotlib inline\n\nimport tensorflow as tf\nfrom tensorflow.keras.applications import EfficientNetB7\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.models import Model\n\nfrom kaggle_datasets import KaggleDatasets","metadata":{"execution":{"iopub.status.busy":"2022-06-30T17:55:49.89303Z","iopub.execute_input":"2022-06-30T17:55:49.893444Z","iopub.status.idle":"2022-06-30T17:56:00.86778Z","shell.execute_reply.started":"2022-06-30T17:55:49.893408Z","shell.execute_reply":"2022-06-30T17:56:00.866555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Definimos algunos parámetros necesarios para acceder a los datos y a para explorar las imágenes.","metadata":{}},{"cell_type":"code","source":"TRAIN_PATH = \"../input/plant-pathology-2020-fgvc7/train.csv\"\nTEST_PATH = \"../input/plant-pathology-2020-fgvc7/test.csv\"\nIMAGE_PATH = \"../input/plant-pathology-2020-fgvc7/images/\"\nIMAGE_SIZE = 512\nSEED = 2022","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-06-30T17:56:00.869543Z","iopub.execute_input":"2022-06-30T17:56:00.870574Z","iopub.status.idle":"2022-06-30T17:56:00.877181Z","shell.execute_reply.started":"2022-06-30T17:56:00.870516Z","shell.execute_reply":"2022-06-30T17:56:00.875587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Leemos los datos de entrenamiento para acceder a las imágenes mediante el identificador de la imagen *image_id*. Vemos también un poco la estructura de los datos, con las siguientes columnas:\n- ***healthy***: Indica si la planta en la imagen está sana.\n- ***multiple_diseases***: Indica si la planta presenta múltiples enfermedades.\n- ***rust***: Indica si la planta presenta el síntoma de \"oxidación\" en sus hojas.\n- ***scab***: Indica si la planta tiene el síntoma de \"costra\" en sus hojas.","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv(TRAIN_PATH)\ntest_data = pd.read_csv(TEST_PATH)\n# Extraemos las etiquetas\ntrain_labels = train_data.loc[:, 'healthy':].values\n\ntrain_data.head()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-30T17:56:00.879121Z","iopub.execute_input":"2022-06-30T17:56:00.880501Z","iopub.status.idle":"2022-06-30T17:56:00.961153Z","shell.execute_reply.started":"2022-06-30T17:56:00.880383Z","shell.execute_reply":"2022-06-30T17:56:00.960302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Carga de imágenes en memoria","metadata":{}},{"cell_type":"markdown","source":"Carguemos las imágenes de nuestro dataset para dar un vistazo general a las plantas presentes en éste y así plantear estrategias para procesar tales imágenes con las metodologías vistas en clase.","metadata":{}},{"cell_type":"code","source":"def load_image(image_id):\n    \"\"\"Carga una imagen del dataset basado en su id.\n\n    Args:\n        image_id (str): Id. de la imagen en el dataset\n\n    Returns:\n        numpy.ndarray: Imagen cargada con cv2.cvtColor como ndarray\n    \n    \"\"\"\n    \n    file_path = image_id + \".jpg\" # Construímos la ruta\n    image = cv2.imread(IMAGE_PATH + file_path) # Leemos la imagen\n    image = cv2.resize(image, (IMAGE_SIZE, IMAGE_SIZE), interpolation=cv2.INTER_AREA) # Reducimos el tamaño\n    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # Retornamos la imagen en formato RGB","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-30T17:56:00.962966Z","iopub.execute_input":"2022-06-30T17:56:00.963908Z","iopub.status.idle":"2022-06-30T17:56:00.972707Z","shell.execute_reply.started":"2022-06-30T17:56:00.963849Z","shell.execute_reply":"2022-06-30T17:56:00.971178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"healthy_data = train_data.query(\"healthy == 1\") # Consultamos las plantas sanas\nscab_data = train_data.query(\"scab == 1\") # Consultamos las plantas con scab\nrust_data = train_data.query(\"rust == 1\") # Consultamos las plantas con rust\nmultiple_data = train_data.query(\"multiple_diseases == 1\") # Consultamos las plantas con multiple_diseases\n\ntrain_images = train_data[\"image_id\"][:].apply(load_image) # Cargamos las imágenes de todas las plantas\nhealthy_images = train_images.loc[list(healthy_data.index)] # Cargamos las imágenes de las plantas sanas\nscab_images = train_images.loc[list(scab_data.index)] # Cargamos las imágenes de las plantas con scab\nrust_images = train_images.loc[list(rust_data.index)] # Cargamos las imágenes de las plantas con rust\nmultiple_images = train_images.loc[list(multiple_data.index)] # Cargamos las imágenes de las plantas con multiple_diseases","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-30T17:56:00.974448Z","iopub.execute_input":"2022-06-30T17:56:00.975084Z","iopub.status.idle":"2022-06-30T17:57:42.561762Z","shell.execute_reply.started":"2022-06-30T17:56:00.975042Z","shell.execute_reply":"2022-06-30T17:57:42.560535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualización de las imágenes de hojas","metadata":{}},{"cell_type":"code","source":"def show_sample(sample):\n    \"\"\"\n    Muestra un grid 4x4, con 4 imágenes de cada\n    tipo de imagen en el dataset.\n    \n    Args:\n        sample (list): Lista de imágenes.\n        \n    Returns:\n        \n    \"\"\"\n    # Visualización\n    rows = [\"Healthy\", \"Scab\", \"Rust\", \"Multiple diseases\"]\n\n    fig,ax = plt.subplots(nrows=4, ncols=4, figsize=(15, 15))\n    for row in range(4):\n        for col in range(4):\n            ax[row,col].imshow(sample[row*4+col])\n            ax[row, col].set_title(\"{}\".format(rows[row]))\n            ax[row,col].set_xticks([])\n            ax[row,col].set_yticks([])","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-30T17:57:42.563402Z","iopub.execute_input":"2022-06-30T17:57:42.563896Z","iopub.status.idle":"2022-06-30T17:57:42.573411Z","shell.execute_reply.started":"2022-06-30T17:57:42.563832Z","shell.execute_reply":"2022-06-30T17:57:42.571518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Una vez cargados los datos, veamos algunas de las imágenes que están presentes en el conjunto de datos.","metadata":{}},{"cell_type":"code","source":"healthy_sample = healthy_images.iloc[0:4]\nscab_sample = scab_images.iloc[0:4]\nrust_sample = rust_images.iloc[0:4]\nmultiple_sample = multiple_images.iloc[0:4]\n\nsample_images = [*healthy_sample, *scab_sample, *rust_sample, *multiple_sample]","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-30T17:57:42.575137Z","iopub.execute_input":"2022-06-30T17:57:42.575615Z","iopub.status.idle":"2022-06-30T17:57:42.593055Z","shell.execute_reply.started":"2022-06-30T17:57:42.575577Z","shell.execute_reply":"2022-06-30T17:57:42.592053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_sample(sample_images)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-30T17:57:42.594731Z","iopub.execute_input":"2022-06-30T17:57:42.595215Z","iopub.status.idle":"2022-06-30T17:57:44.345699Z","shell.execute_reply.started":"2022-06-30T17:57:42.595149Z","shell.execute_reply":"2022-06-30T17:57:44.344801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Distribución de canales","metadata":{}},{"cell_type":"markdown","source":"Una hoja sana es, usualmente, **verde**. Por otro lado, las manchas y costras que se presentan en una planta enferma suelen ser de **color marrón**, el cual en el modelo RGB es un color compuesto a partir del **verde y el rojo**, con menor apariencia del azul. Para ayudarnos un poco, usemos la librería Plotly para ver interactivamente los valores RGB en diferentes puntos de la imagen.","metadata":{}},{"cell_type":"markdown","source":"### Planta sana","metadata":{}},{"cell_type":"markdown","source":"Primero, veamos la imagen de la hoja de una planta sana.","metadata":{}},{"cell_type":"code","source":"img = healthy_images.iloc[0]\n\nfig = make_subplots(1, 2)\n\n# Mostramos la imagen en la primera celda\nfig.add_trace(go.Image(z=img), 1, 1)\n\n# Mostramos el histograma de frecuencias (niveles)\n# para cada canal RGB.\nfor channel, color in enumerate(['red', 'green', 'blue']):\n    fig.add_trace(go.Histogram(x=img[..., channel].ravel(), opacity=0.5,\n                               marker_color=color, name='%s channel' %color), 1, 2)\n\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-30T17:57:44.347066Z","iopub.execute_input":"2022-06-30T17:57:44.34745Z","iopub.status.idle":"2022-06-30T17:57:44.754779Z","shell.execute_reply.started":"2022-06-30T17:57:44.347415Z","shell.execute_reply":"2022-06-30T17:57:44.753494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"En esta planta sana, el color **verde** es el predominante en intensidad.","metadata":{}},{"cell_type":"markdown","source":"### Planta con _rust_","metadata":{}},{"cell_type":"markdown","source":"El nombre _rust_ viene del color visto en las manchas de las hojas, el cual es un marrón _oxidado_ o amarillo. Podemos suponer que al ser de color marrón, veremos mucho más intensidad de rojos.","metadata":{}},{"cell_type":"code","source":"img = rust_images.iloc[0]\n\nfig = make_subplots(1, 2)\n\n# Mostramos la imagen en la primera celda\nfig.add_trace(go.Image(z=img), 1, 1)\n\n# Mostramos el histograma de frecuencias (niveles)\n# para cada canal RGB.\nfor channel, color in enumerate(['red', 'green', 'blue']):\n    fig.add_trace(go.Histogram(x=img[..., channel].ravel(), opacity=0.5,\n                               marker_color=color, name='%s channel' %color), 1, 2)\n\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-30T17:57:44.758166Z","iopub.execute_input":"2022-06-30T17:57:44.75897Z","iopub.status.idle":"2022-06-30T17:57:44.954164Z","shell.execute_reply.started":"2022-06-30T17:57:44.75893Z","shell.execute_reply":"2022-06-30T17:57:44.952942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Comparado con la planta sana, vemos mucho más frecuente el **rojo** con mayor intensidad (~120 en este caso). También es posible observar que los bordes amarillos reducen el valor del **azul**, mientras que las manchas marrones más desarrolladas reducen la intensidad del **verde**.","metadata":{}},{"cell_type":"markdown","source":"### Planta con _scab_","metadata":{}},{"cell_type":"markdown","source":"Estas enfermedades son producidas por hongos o bacterias y producen _costras_ o _scabs_. Estas costras suelen ser de color marrón o casi negras, pero no suelen ser amarillas.","metadata":{}},{"cell_type":"code","source":"img = scab_images.iloc[0]\n\nfig = make_subplots(1, 2)\n# We use go.Image because subplots require traces, whereas px functions return a figure\nfig.add_trace(go.Image(z=img), 1, 1)\nfor channel, color in enumerate(['red', 'green', 'blue']):\n    fig.add_trace(go.Histogram(x=img[..., channel].ravel(), opacity=0.5,\n                               marker_color=color, name='%s channel' %color), 1, 2)\n    \nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-30T17:57:44.955843Z","iopub.execute_input":"2022-06-30T17:57:44.956354Z","iopub.status.idle":"2022-06-30T17:57:45.134165Z","shell.execute_reply.started":"2022-06-30T17:57:44.956305Z","shell.execute_reply":"2022-06-30T17:57:45.133448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"En el marrón encontrado en el _scab_, podemos ver que el **azul** y el **rojo** suelen subir en estas costras. Con esto, podemos ir generando hipótesis acerca de los patrones que se pueden encontrar en este tipo de enfermedades y por lo tanto es posible que, enfocándonos en el azul y el rojo de esta imagen, podamos determinar con más facilidad si la planta tiene _scab_.","metadata":{}},{"cell_type":"markdown","source":"### Plantas con múltiples enfermedades","metadata":{}},{"cell_type":"code","source":"img = multiple_images.iloc[0]\n\nfig = make_subplots(1, 2)\n# We use go.Image because subplots require traces, whereas px functions return a figure\nfig.add_trace(go.Image(z=img), 1, 1)\nfor channel, color in enumerate(['red', 'green', 'blue']):\n    fig.add_trace(go.Histogram(x=img[..., channel].ravel(), opacity=0.5,\n                               marker_color=color, name='%s channel' %color), 1, 2)\n    \nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-30T17:57:45.135088Z","iopub.execute_input":"2022-06-30T17:57:45.135879Z","iopub.status.idle":"2022-06-30T17:57:45.312085Z","shell.execute_reply.started":"2022-06-30T17:57:45.135839Z","shell.execute_reply":"2022-06-30T17:57:45.30983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"En este caso, las manchas pequeñas tienen mayor intensidad de rojos comparado con la parte sana de la hoja. El azul también sube en intensidad en la mayoría de estas manchas.","metadata":{}},{"cell_type":"markdown","source":"### Canales con valores medios","metadata":{}},{"cell_type":"markdown","source":"Vistos ya algunos ejemplos de las plantas que podemos encontrar en nuestro conjunto de datos, hagamos lo mismo para las medias del mismo.","metadata":{}},{"cell_type":"code","source":"# Sacamos las medias de cada canal para luego realizar los histogramas\n\nred_values = [np.mean(train_images[idx][:, :, 0]) for idx in range(len(train_images))]\ngreen_values = [np.mean(train_images[idx][:, :, 1]) for idx in range(len(train_images))]\nblue_values = [np.mean(train_images[idx][:, :, 2]) for idx in range(len(train_images))]\nvalues = [np.mean(train_images[idx]) for idx in range(len(train_images))]","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-30T17:57:45.313232Z","iopub.execute_input":"2022-06-30T17:57:45.313635Z","iopub.status.idle":"2022-06-30T17:57:48.61507Z","shell.execute_reply.started":"2022-06-30T17:57:45.313599Z","shell.execute_reply":"2022-06-30T17:57:48.614378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = ff.create_distplot([values], group_labels=[\"Canales\"], colors=[\"purple\"])\n\nfig.update_layout(showlegend=False, template=\"simple_white\")\nfig.update_layout(title_text=\"Distribución de los valores de los canales\")\n\nfig.data[0].marker.line.width = 0.5\n\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-30T17:57:48.616389Z","iopub.execute_input":"2022-06-30T17:57:48.616951Z","iopub.status.idle":"2022-06-30T17:57:49.45639Z","shell.execute_reply.started":"2022-06-30T17:57:48.616896Z","shell.execute_reply":"2022-06-30T17:57:49.455412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Podemos ver que la intensidad de los valores se distribuye aproximádamente normal con centro en ~105. Vemos algunos valores extremos en 60 y 145.","metadata":{}},{"cell_type":"code","source":"fig = ff.create_distplot([red_values, green_values, blue_values], group_labels=[\"R\", \"G\", \"B\"], colors=[\"red\", \"green\", \"blue\"])\n\nfig.update_layout(showlegend=False, template=\"simple_white\")\nfig.update_layout(title_text=\"Distribución de los valores de rojo\")\n\nfig.data[0].marker.line.width = 0.5\n\nfig.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-30T17:57:49.457621Z","iopub.execute_input":"2022-06-30T17:57:49.457963Z","iopub.status.idle":"2022-06-30T17:57:49.619302Z","shell.execute_reply.started":"2022-06-30T17:57:49.457931Z","shell.execute_reply":"2022-06-30T17:57:49.617904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Como se puede ver en los histogramas, los valores más frecuentes son los verdes, seguido de los rojos y los azules respectivamente. Tanto el canal azul como el canal rojo tienen una distribución aproximadamente normal, con centros en ~75 y ~100 respectivamente. Por otro lado, el canal verde parece una distribución asimétrica negativa.\n\nEn cualquier caso, los histogramas son similares entre sí, con una traslación para cada canal. ","metadata":{}},{"cell_type":"markdown","source":"# Pre-procesamiento","metadata":{}},{"cell_type":"markdown","source":"Para resaltar las características de las hojas de las plantas, es necesario realizar un debido preprocesamiento. Al resaltar las características del objeto de interés, se podrá mejorar la precisión de los modelos que se usen eventualmente.\n\nDentro de los métodos de pre-procesamiento usaremos filtros de suavizado, umbrales, transformaciones de color, etc.","metadata":{}},{"cell_type":"markdown","source":"## Detección de bordes de Canny","metadata":{}},{"cell_type":"markdown","source":"La detección de bordes con el algoritmo de Canny es un algoritmo que usa el gradiente de la intensidad de la imagen para determinar los bordes, a partir de los máximos locales. El umbral inferior y superior, sirven para descartar y seleccionar los verdaderos bordes de los que no se está tan seguro.\n\nVeamos con mayor detalle cómo crearemos una máscara para nuestra imagen:\n\n1. **Suavizado de la imagen:** El algoritmo de Canny es susceptible al ruido, por lo tanto es necesario suavizar la imagen para evitar bordes innecesarios.\n2. **Conversión a espacio HSV:** Tras experimentar con el algoritmo de Canny en escala de grises y otros canales de múltiples espacios de color, obtuvimos los mejores resultados visibles con el espacio de color HSV, específicamente el canal de valor (V).\n3. **Algoritmo de Canny:** Primero, se generan los valores de Sobel, los cuales describen el gradiente de la imagen. Con estos gradientes, detectamos los _posibles_ bordes. Para refinar los bordes, se aplica un doble umbral.\n","metadata":{}},{"cell_type":"code","source":"def canny_and_mask(img, threshold=40):\n    \"\"\"\n    Aplica el algoritmo de Canny para detección de bordes\n    en una imagen en su canal V del espacio HSV.\n    \n    Args:\n        img (np.ndarray): Imagen fuente a la que se le encontrarán los bordes.\n        threshold (int): Umbral superior del algoritmo de Canny.\n    \"\"\"\n    # Aplicamos un suavizado para reducir el ruido, pues\n    # el algoritmo de Canny es susceptible al ruido.\n    blur = cv2.GaussianBlur(img, (9, 9), 0)\n    \n    # Cambiar a espacio de color HSV y separar canales\n    hsv = cv2.cvtColor(blur, cv2.COLOR_RGB2HSV)\n    h, s, v = cv2.split(hsv);\n    \n    # Aplicar Canny en canal V.\n    edges = cv2.Canny(v, 0, threshold)\n    \n    # Dilatación para cerrar las líneas\n    kernel = np.ones((5,5), np.uint8)\n    edges_mask = cv2.dilate(edges, kernel, iterations=3)\n    \n    # Encontrar los contornos\n    contours, _ = cv2.findContours(edges_mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n    \n    # Encontramos el contorno más grande, que debería\n    # corresponder a la hoja de la planta.\n    biggest_cntr = None\n    biggest_area = 0\n    for contour in contours:\n        area = cv2.contourArea(contour)\n        if area > biggest_area:\n            biggest_area = area\n            biggest_cntr = contour\n    \n    # Una vez tenemos el contorno más grande,\n    # lo dibujamos en nuestra máscara para luego\n    # aplicarlo a la imagen original.\n    mask = np.zeros_like(edges_mask);\n    cv2.drawContours(mask, [biggest_cntr], -1, (255), -1);\n    \n    # Dilatamos y aplicamos un filtro de mediana para suavizar\n    # y evitar bordes dentados.\n    mask = cv2.erode(mask, kernel, iterations = 8)\n    mask = cv2.dilate(mask, kernel, iterations = 8)\n    mask = cv2.medianBlur(mask, 15)\n    \n    # Aplicamos la máscara a la imagen original\n    masked = np.zeros_like(img);\n    masked[mask == 255] = img[mask == 255]\n    \n    return masked","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-06-30T17:57:49.621587Z","iopub.execute_input":"2022-06-30T17:57:49.622384Z","iopub.status.idle":"2022-06-30T17:57:49.6377Z","shell.execute_reply.started":"2022-06-30T17:57:49.622334Z","shell.execute_reply":"2022-06-30T17:57:49.636266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"masked_sample = [canny_and_mask(img) for img in sample_images]\nshow_sample(masked_sample)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-30T17:57:49.639272Z","iopub.execute_input":"2022-06-30T17:57:49.640237Z","iopub.status.idle":"2022-06-30T17:57:51.606436Z","shell.execute_reply.started":"2022-06-30T17:57:49.640098Z","shell.execute_reply":"2022-06-30T17:57:51.605411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Es de esperar que en las imágenes con muchas otras hojas cerca, los bordes no sean los deseados. Para combatir esto, tal vez se podría ajustar el valor de los umbrales uno por uno, o incluso usando el umbral de Otsu para el algoritmo de Canny como lo menciona [\\[1\\]][1], pero esto no resulto muy útil para este conjunto de datos, pues aunque algunas imágenes tenían fondos distinguidos, la mayoría de las imágenes no tenían un histograma bimodal, reduciendo la efectividad del umbral de Otsu.\n\n\n---\n\n\n- [\\[1\\] M. Fang, G. Yue, and Q. Yu, “The Study on An Application of Otsu Method in Canny Operator.”][1]\n\n\n[1]: https://www.researchgate.net/publication/255634985_The_Study_on_An_Application_of_Otsu_Method_in_Canny_Operator","metadata":{}},{"cell_type":"markdown","source":"## Segmentación por color","metadata":{}},{"cell_type":"markdown","source":"### Con rango de color","metadata":{}},{"cell_type":"markdown","source":"Para las imágenes de las hojas, el algoritmo de Canny hizo un buen trabajo detectando los bordes de las imágenes y removiendo el fondo que no era de interés. Ahora, queremos remover las partes sanas de las hojas, esto es, remover la parte de verde de la hoja, dejando así solo las manchas o costras en la imagen.","metadata":{}},{"cell_type":"code","source":"def mask_green(img, low_green=(36, 25, 25), high_green=(130, 255, 255)):\n    \"\"\"\n    Enmascara los colores verde de una imagen.\n    \n    Args:\n        img (np.ndarray): Imagen fuente que se va a enmascarar.\n    \n    Returns:\n        masked (np.ndarray): Imagen enmascarada, con espacios negros\n        donde se detectó el verde dentro del rango.\n    \"\"\"\n    # Convertir a espacio de color hsv\n    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n    hsv = cv2.GaussianBlur(hsv, (3, 3), 0)\n    \n    # Crear máscara basado en el rango\n    green_mask = cv2.inRange(hsv, low_green, high_green)\n    mask = cv2.bitwise_not(green_mask)\n    \n    # Cortar el verde\n    imask = mask>0\n    masked = np.zeros_like(img, np.uint8)\n    masked[imask] = img[imask]\n    return masked","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-06-30T17:57:51.607627Z","iopub.execute_input":"2022-06-30T17:57:51.607967Z","iopub.status.idle":"2022-06-30T17:57:51.614601Z","shell.execute_reply.started":"2022-06-30T17:57:51.607937Z","shell.execute_reply":"2022-06-30T17:57:51.61383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"color_segmented_sample = [mask_green(img) for img in masked_sample]\nshow_sample(color_segmented_sample)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-30T17:57:51.615658Z","iopub.execute_input":"2022-06-30T17:57:51.616226Z","iopub.status.idle":"2022-06-30T17:57:52.891067Z","shell.execute_reply.started":"2022-06-30T17:57:51.616167Z","shell.execute_reply":"2022-06-30T17:57:52.890322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Con único umbral","metadata":{}},{"cell_type":"markdown","source":"Intentamos encerrar en un rectángulo los posibles parches de enfermedad basado en el color.","metadata":{}},{"cell_type":"code","source":"def unhealthy_selection(img, lower_thresh=20, upper_thresh=255):\n    \"\"\"\n    Encierra lo que cree que puede ser una enfermedad basado en un umbral.\n    Args:\n        img (np.ndarray): Imagen fuente\n        lower_thresh (int): Umbral inferior\n        upper_thresh (int): Umbral superior\n    Returns:\n        copy (np.ndarray): Imagen con los contornos de los parches.\n    \"\"\"\n\n    copy = img.copy()\n    \n    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n    h, s, v = cv2.split(hsv)\n\n\n    #plt.imshow(img_H, cmap='gray', aspect='auto');\n    #plt.show()\n\n    gray = cv2.threshold(h, lower_thresh, upper_thresh, cv2.THRESH_BINARY)[1]\n    contours, hierarchy = cv2.findContours(gray, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n\n    for cnt in contours:\n        area = cv2.contourArea(cnt)\n        if 10 < area < 1000:\n            #cv2.drawContours(crop,[cnt],0,(255,0,0),2)\n            x, y, w, h = cv2.boundingRect(cnt) # offsets - with this you get 'mask'\n            #cv2.rectangle(crop,(x,y),(x+w,y+h),(255,0,0),0)\n            average_color = np.array(cv2.mean(img[y:y+h,x:x+w])).astype(np.uint8)\n\n            B_validation = 90<average_color[0]<255\n            G_validation = 90<average_color[1]<255\n            R_validation = 20<average_color[2]<90\n\n            if(B_validation and G_validation and R_validation):\n                #plt.imshow(crop[y:y+h,x:x+w])\n                #plt.show()\n                #print(average_color)\n                cv2.rectangle(copy, (x,y), (x+w,y+h), (255,0,0), 2)\n                #plt.hist(crop[y:y+h,x:x+w][:,:,2].ravel(), bins=256, range=(0.0, 255.0))\n                #plt.show()\n\n    return copy","metadata":{"execution":{"iopub.status.busy":"2022-06-30T17:57:52.892347Z","iopub.execute_input":"2022-06-30T17:57:52.892929Z","iopub.status.idle":"2022-06-30T17:57:52.901802Z","shell.execute_reply.started":"2022-06-30T17:57:52.89289Z","shell.execute_reply":"2022-06-30T17:57:52.900979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unlheathy_bounds = [unhealthy_selection(img) for img in masked_sample]\nshow_sample(unlheathy_bounds)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T17:57:52.904126Z","iopub.execute_input":"2022-06-30T17:57:52.904887Z","iopub.status.idle":"2022-06-30T17:57:54.200136Z","shell.execute_reply.started":"2022-06-30T17:57:52.904837Z","shell.execute_reply":"2022-06-30T17:57:54.199299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Realce de contraste","metadata":{}},{"cell_type":"markdown","source":"Basado en las anotaciones que hicimos previamente, el color azul y el color rojo suben en intensidad en los puntos de enfermedad, mientras que el color verde disminuye. Intentemos realzar el contraste entre estas zonas. Para esto, usaremos la Ecualización de Histograma Adaptativo Limitado por Contraste (CLAHE por sus siglas en inglés).\n\nLa ecualización de histograma adaptativo genera histogramas de múltiples regiones de la imagen y distribuye de mejor manera los valores. Como esto puede generar ruido, se limita por contraste para evitar que se sobreamplifique. ","metadata":{}},{"cell_type":"code","source":"def clahe(img):\n    \"\"\"\n    Aplica Ecualización de Histograma Adaptativo Limitado por Contraste (CLAHE)\n    a una imágen en sus canales HSV.\n    \n    Args:\n        image (np.ndarray): Imagen de entrada\n        \n    Returns:\n        clahe_image (np.ndarray): Imagen tras CLAHE\n    \"\"\"\n    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(3, 3))\n    \n    # Convertimos a HSV\n    img = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n    # Separamos cada canal de HSV\n    h, s, v = cv2.split(img)\n    \n    # Aplicamos el CLAHE.\n    h = clahe.apply(h)\n    s = clahe.apply(s)\n    v = clahe.apply(v)\n    \n    hsv = cv2.merge((h, s, v))\n    # BGR hace que las manchas se vean de color cyan\n    # en la enfermedad Rust.\n    clahe_image = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n        \n    return clahe_image","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-30T17:57:54.201462Z","iopub.execute_input":"2022-06-30T17:57:54.202333Z","iopub.status.idle":"2022-06-30T17:57:54.209503Z","shell.execute_reply.started":"2022-06-30T17:57:54.202289Z","shell.execute_reply":"2022-06-30T17:57:54.208114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clahe_sample = [clahe(img) for img in masked_sample]","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-30T17:57:54.211156Z","iopub.execute_input":"2022-06-30T17:57:54.211725Z","iopub.status.idle":"2022-06-30T17:57:54.300563Z","shell.execute_reply.started":"2022-06-30T17:57:54.211683Z","shell.execute_reply":"2022-06-30T17:57:54.299724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_sample(clahe_sample)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-30T17:57:54.30193Z","iopub.execute_input":"2022-06-30T17:57:54.302671Z","iopub.status.idle":"2022-06-30T17:57:55.79701Z","shell.execute_reply.started":"2022-06-30T17:57:54.302628Z","shell.execute_reply":"2022-06-30T17:57:55.795866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusiones","metadata":{}},{"cell_type":"markdown","source":"- El conjunto de datos no es uniforme y por lo tanto es difícil hacer un preprocesamiento adecuado para todas las imágenes.\n- La segmentación también se ve afectada por el ruido de las imágenes en sus fondos\n- Las redes neuronales convolucionales como DenseNet o EfficientNetB7 son efectivas sin necesidad de segmentar tan arduamente.\n- La extracción de características de textura se podrían hacer con matrices de Co ocurrencias, pero las redes CNN evitan la extracción manual de características y usualmente obtienen mejores resultados.\n- El espacio de color HSV fue el más útil, pues permitía separar el Hue (matiz) y así enmascarar el color verde de la planta.\n- El canal de valor de HSV también es útil para la umbralización.","metadata":{}},{"cell_type":"markdown","source":"# Referencias","metadata":{}},{"cell_type":"markdown","source":"[1]\tP. Bansal, R. Kumar, and S. Kumar, “Disease detection in apple leaves using deep convolutional neural network,” Agriculture (Switzerland), vol. 11, no. 7, Jul. 2021, doi: 10.3390/agriculture11070617.\n\n[2]\tAdhiparasakthi Engineering College, Institute of Electrical and Electronics Engineers. Madras Section, and Institute of Electrical and Electronics Engineers, Proceedings of the 2019 IEEE International Conference on Communication and Signal Processing (ICCSP) : 4th - 6th April 2018, Melmaruvathur, India. \n\n[3]\tInstitute of Electrical and Electronics Engineers. Madras Section and Institute of Electrical and Electronics Engineers, 2019 5th International Conference on Advanced Computing & Communication Systems (ICACCS). \n\n[4]\tV. Rajesh Kumar, K. Pradeepan, S. Praveen, M. Rohith, and V. Vasantha Kumar, “Identification of Plant Diseases Using Image Processing and Image Recognition,” Jul. 2021. doi: 10.1109/ICSCAN53069.2021.9526493.\n\n[5]\tP. Kulkarni, A. Karwande, T. Kolhe, S. Kamble, A. Joshi, and M. Wyawahare, “Plant Disease Detection Using Image Processing and Machine Learning.”\n\n[6]\tR. Anand, S. Veni, and J. Aravinth, “An application of image processing techniques for detection of diseases on brinjal leaves using k-means clustering method,” Sep. 2016. doi: 10.1109/ICRTIT.2016.7569531.\n\n[7]\tS. Zhang, Z. You, and X. Wu, “Plant disease leaf image segmentation based on superpixel clustering and EM algorithm,” Neural Computing and Applications, vol. 31, pp. 1225–1232, Feb. 2019, doi: 10.1007/s00521-017-3067-8.\n\n[8]\tIEEE Staff, 2018 International Conference on Electrical, Electronics, Communication, Computer, and Optimization Techniques (ICEECCOT). IEEE, 2018.\n\n[9]\tV. Singh and A. K. Misra, “Detection of plant leaf diseases using image segmentation and soft computing techniques,” Information Processing in Agriculture, vol. 4, no. 1, pp. 41–49, Mar. 2017, doi: 10.1016/j.inpa.2016.10.005.\n\n[10]\tS. S. Lomte and A. P. Janwale, “Plant Leaves Image Segmentation Techniques: A Review,” Article in INTERNATIONAL JOURNAL OF COMPUTER SCIENCES AND ENGINEERING, 2017, [Online]. Available: www.ijcseonline.org\n\n[11] Amity University, Institute of Electrical and Electronics Engineers. United Kingdom and Republic of Ireland Section, and Institute of Electrical and Electronics Engineers, Abstract proceedings of International Conference on Automation, Computational and Technology Management (ICACTM-2019) : 24th - 25th April 2019. \n","metadata":{}}]}