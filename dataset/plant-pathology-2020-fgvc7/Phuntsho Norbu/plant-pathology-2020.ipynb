{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from __future__ import print_function\nimport numpy as np # For numerical fast numerical calculations\nimport matplotlib.pyplot as plt # For making plots\nimport pandas as pd \nimport cv2\nimport tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt # plotting library\nfrom keras.models import Sequential\nfrom keras.layers import Dense , Activation, Dropout, Conv2D, Flatten, MaxPooling2D, GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam, RMSprop\nfrom tensorflow.keras.metrics import AUC, Accuracy\nfrom tensorflow.keras.utils import to_categorical, plot_model\nimport os, datetime\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import ImageDataGenerator, img_to_array\nfrom imblearn.over_sampling import SMOTE\nfrom keras.regularizers import l2\nfrom keras.callbacks import ReduceLROnPlateau, EarlyStopping\nfrom keras.layers.normalization.batch_normalization import BatchNormalization\nfrom tensorflow.keras import backend as K\nfrom random import randint, seed\nfrom datetime import datetime\nK.clear_session()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:24:55.40986Z","iopub.execute_input":"2022-04-13T21:24:55.410483Z","iopub.status.idle":"2022-04-13T21:25:01.930378Z","shell.execute_reply.started":"2022-04-13T21:24:55.410436Z","shell.execute_reply":"2022-04-13T21:25:01.929661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_SIZE = 300\nBATCH_SIZE = 24\nEPOCH = 100","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:25:01.932167Z","iopub.execute_input":"2022-04-13T21:25:01.932631Z","iopub.status.idle":"2022-04-13T21:25:01.938206Z","shell.execute_reply.started":"2022-04-13T21:25:01.932595Z","shell.execute_reply":"2022-04-13T21:25:01.937589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('../input/plant-pathology-2020-fgvc7/train.csv')\ntest_data = pd.read_csv('../input/plant-pathology-2020-fgvc7/test.csv')\n# sub = pd.read_csv('../input/plant-pathology-2020-fgvc7/sample_submission.csv')\nFILE_PATH = str(\"../input/plant-pathology-2020-fgvc7/images/\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-13T21:25:01.942063Z","iopub.execute_input":"2022-04-13T21:25:01.942524Z","iopub.status.idle":"2022-04-13T21:25:01.973109Z","shell.execute_reply.started":"2022-04-13T21:25:01.942489Z","shell.execute_reply":"2022-04-13T21:25:01.972107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Process the images, convert it into an array and store it in training_images","metadata":{}},{"cell_type":"code","source":"prog = tf.keras.utils.Progbar(1821,width=100,verbose=1)\ntraining_images = []\nfor index, image in enumerate(train_data['image_id']):\n    image_path = FILE_PATH + image + \".jpg\"\n    image = cv2.imread(image_path)\n    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_AREA)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    training_images.append(image)\n    prog.update(index+1) ","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:25:05.351129Z","iopub.execute_input":"2022-04-13T21:25:05.35138Z","iopub.status.idle":"2022-04-13T21:26:44.824392Z","shell.execute_reply.started":"2022-04-13T21:25:05.35135Z","shell.execute_reply":"2022-04-13T21:26:44.823707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train = np.ndarray(shape=(len(training_images), IMG_SIZE, IMG_SIZE,3),dtype=np.float32)\nfor index, image in enumerate(training_images): \n    x_train[index] = img_to_array(image)\n    x_train[index] = training_images[index]\nx_train = x_train/255\nprint(x_train.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:26:44.826008Z","iopub.execute_input":"2022-04-13T21:26:44.826243Z","iopub.status.idle":"2022-04-13T21:26:46.22082Z","shell.execute_reply.started":"2022-04-13T21:26:44.82621Z","shell.execute_reply":"2022-04-13T21:26:46.220075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"convert the labels into a one-hot-encoded format","metadata":{}},{"cell_type":"code","source":"labels = train_data[['healthy', 'multiple_diseases', 'rust', 'scab']]\ny_train = np.array(labels.values)\nprint(y_train.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:26:46.222174Z","iopub.execute_input":"2022-04-13T21:26:46.222577Z","iopub.status.idle":"2022-04-13T21:26:46.232784Z","shell.execute_reply.started":"2022-04-13T21:26:46.222541Z","shell.execute_reply":"2022-04-13T21:26:46.231992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"plot and visualize the images","metadata":{}},{"cell_type":"code","source":"fig, axis = plt.subplots(1,5, figsize=(20,20))\nseed(23)\nfor i in range(5):\n    axis[i].set_axis_off()\n    rand_num = randint(0,1821)\n    axis[i].imshow(x_train[rand_num])\n    title = \"image:{} and class: {}\".format(rand_num, y_train[rand_num])\n    axis[i].set_title(title)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:26:46.234871Z","iopub.execute_input":"2022-04-13T21:26:46.235214Z","iopub.status.idle":"2022-04-13T21:26:46.810774Z","shell.execute_reply.started":"2022-04-13T21:26:46.235178Z","shell.execute_reply":"2022-04-13T21:26:46.809566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"split the dataset into 20% validation and 80% training dataset","metadata":{}},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size = 0.2, random_state = 42)\nprint(\"x_train:\", x_train.shape, \" y_train:\", y_train.shape, \" x_test:\", x_test.shape, \" y_test:\", y_test.shape)\nclass_sum = np.sum(y_train, axis =0)\nprint(class_sum)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:26:46.811691Z","iopub.execute_input":"2022-04-13T21:26:46.811928Z","iopub.status.idle":"2022-04-13T21:26:47.381587Z","shell.execute_reply.started":"2022-04-13T21:26:46.811896Z","shell.execute_reply":"2022-04-13T21:26:47.380102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"oversample the minority class and level the dataset. firstly reshape the iamges into a 2D array. Once the smote resample is done, reshape the image back to its original shape","metadata":{}},{"cell_type":"code","source":"# x_train = x_train.reshape(-1, IMG_SIZE * IMG_SIZE *3)\noversample = SMOTE(sampling_strategy='minority', k_neighbors=7)\n# oversample = SMOTE()\nx_train, y_train = oversample.fit_resample(x_train.reshape((-1, IMG_SIZE * IMG_SIZE *3)), y_train)\nx_train = x_train.reshape((-1, IMG_SIZE, IMG_SIZE, 3))\nx_test, y_test = oversample.fit_resample(x_test.reshape((-1, IMG_SIZE * IMG_SIZE *3)), y_test)\nx_test = x_test.reshape((-1, IMG_SIZE, IMG_SIZE, 3))","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:26:47.382956Z","iopub.execute_input":"2022-04-13T21:26:47.383204Z","iopub.status.idle":"2022-04-13T21:26:51.687232Z","shell.execute_reply.started":"2022-04-13T21:26:47.383169Z","shell.execute_reply":"2022-04-13T21:26:51.686476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"check the shapes of the x_train and y_train. Additionally, look at the sum of the classes to see how many images are in each class","metadata":{}},{"cell_type":"code","source":"print(\"after smote: x_train:\", x_train.shape, \" y_train:\", y_train.shape)\nprint(\"number of images in each class for training:\", np.sum(y_train, axis =0))\n\nprint(\"after smote: x_test:\", x_test.shape, \" y_test:\", y_test.shape)\nprint(\"number of images in each class for validation:\", np.sum(y_test, axis =0))","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:26:51.688539Z","iopub.execute_input":"2022-04-13T21:26:51.688789Z","iopub.status.idle":"2022-04-13T21:26:51.698854Z","shell.execute_reply.started":"2022-04-13T21:26:51.688756Z","shell.execute_reply":"2022-04-13T21:26:51.698034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"plot images that have class multiple disease class to see how the smote method performed","metadata":{}},{"cell_type":"code","source":"fig, axis = plt.subplots(1,5, figsize=(20,20))\ncounter = 0\nwhile counter < 5:\n    rand_num = randint(0,x_train.shape[0])\n    if y_train[rand_num][1] == 1: \n        axis[counter].set_axis_off()\n        axis[counter].imshow(x_train[rand_num])\n        title = \"image:{} and class: {}\".format(rand_num, y_train[rand_num])\n        axis[counter].set_title(title)\n        counter += 1","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:26:51.700241Z","iopub.execute_input":"2022-04-13T21:26:51.700789Z","iopub.status.idle":"2022-04-13T21:26:52.23992Z","shell.execute_reply.started":"2022-04-13T21:26:51.700753Z","shell.execute_reply":"2022-04-13T21:26:52.239313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"create the CNN model","metadata":{}},{"cell_type":"code","source":"reg_lambda = 0.005\nmodel = Sequential() \nmodel.add(Conv2D(32, kernel_size=(3,3), input_shape=(IMG_SIZE, IMG_SIZE, 3), activation='relu', kernel_regularizer=l2(reg_lambda)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, kernel_size=(3,3), activation='relu', kernel_regularizer=l2(reg_lambda)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2), padding='SAME'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(128, kernel_size=(3,3), activation='relu', kernel_regularizer=l2(reg_lambda)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2), padding='SAME'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(512, kernel_size=(3,3), activation='relu', kernel_regularizer=l2(reg_lambda)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(128, kernel_size=(3,3), activation='relu', kernel_regularizer=l2(reg_lambda)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2), padding='SAME'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(128, kernel_size=(3,3), activation='relu', kernel_regularizer=l2(reg_lambda)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, kernel_size=(3,3), activation='relu', kernel_regularizer=l2(reg_lambda)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2), padding='SAME'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(128, kernel_size=(3,3), activation='relu', kernel_regularizer=l2(reg_lambda)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(512, kernel_size=(3,3), activation='relu', kernel_regularizer=l2(reg_lambda)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2), padding='SAME'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Flatten())\nmodel.add(Dense(300, activation='relu', kernel_regularizer=l2(reg_lambda)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(200, activation='relu', kernel_regularizer=l2(reg_lambda)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(100, activation='relu', kernel_regularizer=l2(reg_lambda)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\nmodel.add(Dense(4, activation='softmax'))\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:26:52.241267Z","iopub.execute_input":"2022-04-13T21:26:52.241621Z","iopub.status.idle":"2022-04-13T21:26:55.108301Z","shell.execute_reply.started":"2022-04-13T21:26:52.24158Z","shell.execute_reply":"2022-04-13T21:26:55.107475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"define the callbacks, metrics and compile model","metadata":{}},{"cell_type":"code","source":"lr_reduce = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor='val_accuracy',\n    patience = 10, \n    verbose = 1,\n    min_delta = 0.000001,\n    min_lr=0,\n    factor = 0.5, \n    mode = 'auto'\n)\nearly_stop = tf.keras.callbacks.EarlyStopping(\n    monitor = 'val_loss', \n    patience = 20,\n    mode='auto',\n    verbose=1, \n    restore_best_weights =True\n)\nadam = Adam(learning_rate=0.001)\nrmsprop = tf.keras.optimizers.RMSprop(learning_rate = 0.001)\nloss = 'categorical_crossentropy'\nmetrics = [tf.keras.metrics.CategoricalAccuracy(name='accuracy'), tf.keras.metrics.AUC(curve='ROC')]\n\nmodel.compile(optimizer=adam, loss=loss, metrics=metrics)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:26:55.113808Z","iopub.execute_input":"2022-04-13T21:26:55.114065Z","iopub.status.idle":"2022-04-13T21:26:55.151726Z","shell.execute_reply.started":"2022-04-13T21:26:55.114031Z","shell.execute_reply":"2022-04-13T21:26:55.151069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rotation_range=45, \n    shear_range=.25,\n    zoom_range = 0.20, \n    width_shift_range= 0.25,\n    rescale = 1/255,\n    height_shift_range= 0.25, \n    brightness_range=[.5,1.5],\n    horizontal_flip=True, \n    vertical_flip=True,\n    fill_mode = 'nearest'\n)\nvalidation_datagen = ImageDataGenerator(rescale = 1./255, rotation_range = 20, zoom_range= 10, horizontal_flip=True, vertical_flip=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:26:55.155172Z","iopub.execute_input":"2022-04-13T21:26:55.156681Z","iopub.status.idle":"2022-04-13T21:26:55.16702Z","shell.execute_reply.started":"2022-04-13T21:26:55.156643Z","shell.execute_reply":"2022-04-13T21:26:55.166016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start_time = datetime.now().time()\nhistory = model.fit(train_datagen.flow(x_train, y_train, batch_size = BATCH_SIZE),\n                    epochs = EPOCH, \n                    steps_per_epoch = x_train.shape[0]//BATCH_SIZE,\n                    validation_data =train_datagen.flow(x_test,y_test, batch_size = BATCH_SIZE),\n                    validation_steps = x_test.shape[0] // BATCH_SIZE,\n                    callbacks= [lr_reduce, early_stop], \n                    verbose = 1 \n                   )\n","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:26:55.169144Z","iopub.execute_input":"2022-04-13T21:26:55.171102Z","iopub.status.idle":"2022-04-13T23:19:30.817186Z","shell.execute_reply.started":"2022-04-13T21:26:55.171062Z","shell.execute_reply":"2022-04-13T23:19:30.816466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(start_time)\nprint(datetime.now().time())","metadata":{"execution":{"iopub.status.busy":"2022-04-13T23:19:30.818548Z","iopub.execute_input":"2022-04-13T23:19:30.81879Z","iopub.status.idle":"2022-04-13T23:19:30.823831Z","shell.execute_reply.started":"2022-04-13T23:19:30.818758Z","shell.execute_reply":"2022-04-13T23:19:30.82317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\n\npred_test = model.predict(x_test)\nroc_sum = 0\nfor i in range(4):\n    score = roc_auc_score(y_test[:, i], pred_test[:, i])\n    roc_sum += score\n    print(f'{score:.3f}')\n\nroc_sum /= 4\nprint(f'totally:{roc_sum:.3f}')","metadata":{"execution":{"iopub.status.busy":"2022-04-13T23:19:30.825106Z","iopub.execute_input":"2022-04-13T23:19:30.825907Z","iopub.status.idle":"2022-04-13T23:19:37.498263Z","shell.execute_reply.started":"2022-04-13T23:19:30.825882Z","shell.execute_reply":"2022-04-13T23:19:37.497585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"h = history.history\n\noffset = 5\nepochs = range(offset, len(h['loss']))\n\nplt.figure(1, figsize=(20, 6))\n\nplt.subplot(121)\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.plot(epochs, h['loss'][offset:], label='train')\nplt.plot(epochs, h['val_loss'][offset:], label='val')\nplt.legend()\n\nplt.subplot(122)\nplt.xlabel('epochs')\nplt.ylabel('accuracy')\nplt.plot(h[f'accuracy'], label='train')\nplt.plot(h[f'val_accuracy'], label='val')\nplt.legend()\nplt.show()\n\n\nplt.figure(1, figsize=(20, 8))\nplt.subplot(121)\nplt.xlabel('epochs')\nplt.ylabel('auc')\nplt.plot(h[f'auc'], label='train')\nplt.plot(h[f'val_auc'], label='val')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T23:19:37.50223Z","iopub.execute_input":"2022-04-13T23:19:37.504128Z","iopub.status.idle":"2022-04-13T23:19:38.168214Z","shell.execute_reply.started":"2022-04-13T23:19:37.504088Z","shell.execute_reply":"2022-04-13T23:19:38.167546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import ConfusionMatrixDisplay\nfrom sklearn.metrics import confusion_matrix\n\nclass_labels = [\"Healthy\", \"Multi\", \"Rust\", \"Scab\"]\n\ncm = confusion_matrix(np.asarray(y_test).argmax(axis=1), np.asarray(pred_test).argmax(axis=1))\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n\ndisp.plot(cmap=plt.cm.Blues)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T23:19:38.169261Z","iopub.execute_input":"2022-04-13T23:19:38.169637Z","iopub.status.idle":"2022-04-13T23:19:38.397863Z","shell.execute_reply.started":"2022-04-13T23:19:38.169603Z","shell.execute_reply":"2022-04-13T23:19:38.397217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"cnn_apr_12_adam_lr_0.001.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-04-13T23:19:38.399021Z","iopub.execute_input":"2022-04-13T23:19:38.399835Z","iopub.status.idle":"2022-04-13T23:19:38.646166Z","shell.execute_reply.started":"2022-04-13T23:19:38.399796Z","shell.execute_reply":"2022-04-13T23:19:38.645468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prog = tf.keras.utils.Progbar(1821,width=100,verbose=1)\ntesting_images = []\nfor index, image in enumerate(test_data['image_id']):\n    image_path = FILE_PATH + image + \".jpg\"\n    image = cv2.imread(image_path)\n    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n    testing_images.append(image)\n    prog.update(index+1) ","metadata":{"execution":{"iopub.status.busy":"2022-04-13T23:19:38.647362Z","iopub.execute_input":"2022-04-13T23:19:38.648762Z","iopub.status.idle":"2022-04-13T23:20:49.529198Z","shell.execute_reply.started":"2022-04-13T23:19:38.648723Z","shell.execute_reply":"2022-04-13T23:20:49.528472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = np.ndarray(shape=(len(test_data['image_id']), IMG_SIZE, IMG_SIZE,3),dtype=np.float32)\nfor index, image in enumerate(testing_images): \n    X_test[index] = img_to_array(image)\n    X_test[index] = testing_images[index]\nX_test = X_test/255\nprint(X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T23:20:49.530411Z","iopub.execute_input":"2022-04-13T23:20:49.530759Z","iopub.status.idle":"2022-04-13T23:20:52.722948Z","shell.execute_reply.started":"2022-04-13T23:20:49.530721Z","shell.execute_reply":"2022-04-13T23:20:52.722125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ids = test_data['image_id']\npred = model.predict(X_test)\nres = pd.DataFrame()\nres['image_id'] = test_ids\nres['healthy'] = pred[:, 0]\nres['multiple_diseases'] = pred[:, 1]\nres['rust'] = pred[:, 2]\nres['scab'] = pred[:, 3]\nres.to_csv('apr_12_ite_1_sub_sam_lr_0005.csv', index=False)\nres.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T23:20:52.724359Z","iopub.execute_input":"2022-04-13T23:20:52.724681Z","iopub.status.idle":"2022-04-13T23:21:01.808068Z","shell.execute_reply.started":"2022-04-13T23:20:52.724643Z","shell.execute_reply":"2022-04-13T23:21:01.807365Z"},"trusted":true},"execution_count":null,"outputs":[]}]}