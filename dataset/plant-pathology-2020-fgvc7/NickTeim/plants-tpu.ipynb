{"cells":[{"metadata":{},"cell_type":"markdown","source":"Thanks for looking in my notebook. If you want the LB=0.971 its in version 7."},{"metadata":{},"cell_type":"markdown","source":"# Import Liberaries "},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport random, re, math\nimport tensorflow as tf, tensorflow.keras.backend as K\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import optimizers\nfrom kaggle_datasets import KaggleDatasets\n\nprint(tf.__version__)\nprint(tf.keras.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install efficientnet\nimport efficientnet.tfkeras as efn","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Connect data to TPU"},{"metadata":{"trusted":true},"cell_type":"code","source":"# tf.data.experimental.AUTOTUNE??","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"AUTO = tf.data.experimental.AUTOTUNE #basic Convert a number or string to an integer, or return 0 if no arguments\n#are given. for more detail uncommen the cell above\n# Detect hardware, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)\n\n\n# Data access\nGCS_DS_PATH = KaggleDatasets().get_gcs_path()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## View an image"},{"metadata":{"trusted":true},"cell_type":"code","source":"from matplotlib import pyplot as plt\n\nimg = plt.imread('../input/plant-pathology-2020-fgvc7/images/Train_0.jpg')\nprint(img.shape)\nplt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"path='../input/plant-pathology-2020-fgvc7/'\ntrain = pd.read_csv(path + 'train.csv')\ntest = pd.read_csv(path + 'test.csv')\nsub = pd.read_csv(path + 'sample_submission.csv')\n\ntrain_paths = train.image_id.apply(lambda x: GCS_DS_PATH + '/images/' + x + '.jpg').values #put out datapath on the TPU\ntest_paths = test.image_id.apply(lambda x: GCS_DS_PATH + '/images/' + x + '.jpg').values #put out datapath on the TPU\n\ntrain_labels = train.loc[:, 'healthy':].values #you can also use '1' instead of 'healthy' but all it does is taking all the results the 4 different labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train #Seeing the training csv-file","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels #all the rows for the labels we want to classify","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To get to the images we used Path from pathlib"},{"metadata":{"trusted":true},"cell_type":"code","source":"from pathlib import Path\nimport PIL,os,mimetypes\nPath.ls = lambda x: list(x.iterdir())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"See all the folders "},{"metadata":{"trusted":true},"cell_type":"code","source":"path_images = Path('/kaggle/input/plant-pathology-2020-fgvc7')\npath_images.ls()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Go in on the 'images' folder and take 3 pictures "},{"metadata":{"trusted":true},"cell_type":"code","source":"(path_images/'images').ls()[:3]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"nb_classes = 4 #number of labels, this will be used for our output layer\nBATCH_SIZE = 8 * strategy.num_replicas_in_sync # this is 8 on TPU v3-8, it is 1 on CPU and GPU #try change it to 16\nimg_size = 768 #u decide but bigger images take longer to train but higher kvali and smaller images is faster but lower kvali\nEPOCHS = 25 #number of training rounds","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### visuel test of what the cast function does (used in the code below)"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = tf.constant([1.8, 2.2], dtype=tf.float32)\nprint(type(x))\ntf.dtypes.cast(x, tf.int32)  # [1, 2], dtype=tf.int32\nprint(type(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(x)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Decode and augment images"},{"metadata":{"trusted":true},"cell_type":"code","source":"#decode_image label every image if it has a label from csv-file and return also the image that has no label\ndef decode_image(filename, label=None, image_size=(img_size, img_size)):\n    bits = tf.io.read_file(filename)#get the filename\n    image = tf.image.decode_jpeg(bits, channels=3) #channel representing some aspect of information about the image \n    #and u can have 100+ channels if you want but it is proven to be good to put it at 3\n    image = tf.cast(image, tf.float32) / 255.0 #tf.cast means = Casts a tensor to a new type. so the images tensor becomes a type float\n    image = tf.image.resize(image, image_size) #resize the image for the size given above\n    if label is None:  #if there is no label for an image\n        return image #jusst return the image\n    else:\n        return image, label #else return the image with the label\n    \n#data_augment just take the images and do som augment to them\ndef data_augment(image, label=None, seed=2020): \n    image = tf.image.random_flip_left_right(image, seed=seed) #flip randomly images to left or right\n    image = tf.image.random_flip_up_down(image, seed=seed) #flip the images randomly up or down\n    image=tf.image.adjust_saturation(image, 2)\n#     image=tf.image.resize_with_crop_or_pad(img, 800, 900)\n    \n    #for every new image\n    if label is None:  #if there is no label for an image\n        return image#jusst return the image\n    else:\n        return image, label #else return the image with the label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"saturated = tf.image.adjust_saturation(img, 10)\nplt.imshow(saturated)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(img) #if we look at the before and after picture it is clear to see that illness of the plant is much clear on the saturated image, so we are gonna use it in our data aurgment function above ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create dataset for training and testing"},{"metadata":{},"cell_type":"markdown","source":"\n      The `tf.data.Dataset` API supports writing descriptive and efficient input\n      pipelines. `Dataset` usage follows a common pattern:\n\n      1. Create a source dataset from your input data.\n      2. Apply dataset transformations to preprocess the data.\n      3. Iterate over the dataset and process the elements.\n\n      Iteration happens in a streaming fashion, so the full dataset does not need to\n      fit into memory.\n--> from source code"},{"metadata":{"trusted":true},"cell_type":"code","source":"#making the training dataset for more detail on the given functions uncommen the cell below\ntrain_dataset = (\n    tf.data.Dataset #explaned above nut just a API blok iniziator\n    .from_tensor_slices((train_paths, train_labels)) #Creates a `Dataset` whose elements are slices of the given tensors\n    # 'from_tensor_slices' --> The given tensors are sliced along their first dimension. This operation\n#     preserves the structure of the input tensors, removing the first dimension\n#     of each tensor and using it as the dataset dimension. All input tensors\n#     must have the same size in their first dimensions.\n    .map(decode_image, num_parallel_calls=AUTO) #Maps `map_func` across the elements of this dataset# note here is 'map_func'='decode_image' which returned the labels with the images\n    #This transformation applies `map_func` to each element of this dataset, and\n#     returns a new dataset containing the transformed elements, in the same\n#     order as they appeared in the input. `map_func` can be used to change both\n#     the values and the structure of a dataset's elements. For example, adding 1\n#     to each element, or projecting a subset of element components.\n    .map(data_augment, num_parallel_calls=AUTO)#note here we use data_augment wich fliped the images for ech element in the dataset\n    .repeat() #Repeats this dataset so each original value is seen `count` times. #see exsampel below #  The default behavior (if\n        #count` is `None` or `-1`) is for the dataset be repeated indefinitely.\n\n    .shuffle(512) #Randomly shuffles the elements of this dataset.#and it randomize by 512 (u set value) each time\n    .batch(BATCH_SIZE) \n    .prefetch(AUTO) #Creates a `Dataset` that prefetches elements from this dataset.\n#     Most dataset input pipelines should end with a call to `prefetch`. This\n#     allows later elements to be prepared while the current element is being\n#     processed. This often improves latency and throughput, at the cost of\n#     using additional memory to store prefetched elements.\n    )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"repeat() -->\n\n        >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n        >>> dataset = dataset.repeat(3)\n        >>> list(dataset.as_numpy_iterator())\n        [1, 2, 3, 1, 2, 3, 1, 2, 3]\n---> from source code"},{"metadata":{"trusted":true},"cell_type":"code","source":"#  tf.data.Dataset??","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataset = (\n    tf.data.Dataset #explaned above nut just a API blok iniziator\n    .from_tensor_slices(test_paths)\n    .map(decode_image, num_parallel_calls=AUTO) \n    #note we dont flip the testing images because then we cant validate the predictions from the model\n    .batch(BATCH_SIZE)\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tf.keras.callbacks??","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Define learning rate and make a schedular"},{"metadata":{"trusted":true},"cell_type":"code","source":"#predifened learning rates for optimal preformaze\nLR_START = 0.00001\nLR_MAX = 0.0001 * strategy.num_replicas_in_sync\nLR_MIN = 0.00001\nLR_RAMPUP_EPOCHS = 15\nLR_SUSTAIN_EPOCHS = 3\nLR_EXP_DECAY = .8\n#here we change the learning depending on what epoch we are at \ndef lrfn(epoch):\n    if epoch < LR_RAMPUP_EPOCHS: #if epoch is lower then 15\n        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START #take this learning rate\n    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:#if epoch is lower then 15+3=18 \n        lr = LR_MAX #then take this learning rate\n    else: #else if is above 18 then \n        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN#take this learning rate\n    return lr\n    \nlr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=True) #create a callback to make the functionality possible when we do the actual training. \n#verbose = true just means we want to see the traning proces bar\n\n#plot the learning rate schedular \nrng = [i for i in range(EPOCHS)]\ny = [lrfn(x) for x in rng]\nplt.plot(rng, y)\nprint(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Make a model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model():\n    #pretrained_model = tf.keras.applications.MobileNetV2(input_shape=[*IMAGE_SIZE, 3], include_top=False)\n#     pretrained_model = tf.keras.applications.Xception(weights='imagenet', input_shape=(img_size, img_size, 3), include_top=False)\n    #pretrained_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n#     pretrained_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3))\n    #pretrained_model = tf.keras.applications.MobileNet(weights='imagenet', include_top=False, input_shape=[*IMAGE_SIZE, 3])\n    # EfficientNet can be loaded through efficientnet.tfkeras library (https://github.com/qubvel/efficientnet)\n    pretrained_model = efn.EfficientNetB7(weights='imagenet', include_top=False, pooling='avg', input_shape=(img_size, img_size, 3))\n    pretrained_model.trainable = True\n    \n    model = tf.keras.Sequential([\n        pretrained_model,\n#         tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(4096, activation='relu'),\n        tf.keras.layers.Dense(4096, activation='relu'),\n        tf.keras.layers.Dense(4, activation='softmax') #4 since there are 4 labels and therefor 4 diferent predictions \n    ])\n\n#     x = pretrained_model.output\n#     predictions = Dense(4, activation=\"softmax\")(x)\n    return model\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with strategy.scope():\n    model = get_model()\nmodel.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nhistory=model.fit(\n    train_dataset, \n    steps_per_epoch=train_labels.shape[0] // BATCH_SIZE,\n    callbacks=[lr_callback], #lr_callback was created above\n    epochs=EPOCHS\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Make prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nprobs = model.predict(test_dataset)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.loc[:, 'healthy':] = probs #u can also use 1 instead of 'healthy'\nsub.to_csv('submission.csv', index=False)\nsub.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}