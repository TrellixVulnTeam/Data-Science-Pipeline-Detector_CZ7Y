{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#importing necessary libraries\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\n\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport torch\n# Neural networks can be constructed using the torch.nn package.\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.utils.data import Dataset\nfrom torchvision import datasets, models\nfrom tqdm import tqdm\nimport torchvision\nfrom pytorch_lightning.metrics.functional import accuracy\nfrom collections import defaultdict\nimport torchvision.transforms as transforms\nfrom sklearn.metrics import f1_score\nimport time\nimport os\nimport copy\nimport cv2\nimport glob\nimport random\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport torch.backends.cudnn as cudnn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#read Data\nPATH='../input/plant-pathology-2020-fgvc7/'\ntrain_data=pd.read_csv(PATH+'train.csv')\ntest_data=pd.read_csv(PATH+'test.csv')\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# image path  as column \ndef image_(dat):\n    return PATH+'images/'+dat+'.jpg'\n\ntrain_data['image_path']=train_data[[\"image_id\"]].apply(image_)\ntest_data['image_path']=test_data[[\"image_id\"]].apply(image_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#apply albumenation for transformation\ntrain_transform =  A.Compose([\n A.SmallestMaxSize(max_size=160),\n        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),\n        A.RandomCrop(height=128, width=128),\n        A.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=0.5),\n        A.RandomBrightnessContrast(p=0.5),\n        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n        ToTensorV2(),\n    ]\n)\nVal_transform=transforms.Compose([\n        A.SmallestMaxSize(max_size=160),\n        A.CenterCrop(height=128, width=128),\n        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n        ToTensorV2(),\n    ]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#splitting data as train and test \nvalidation_split = .3\nrandom_seed= 42\nshuffle_dataset = True\n\n# tr, val = train_test_split(data.label, stratify=data.label, test_size=0.1)\ndataset_size = len(train_data)\nindices = list(range(dataset_size))\nsplit = int(np.floor(validation_split * dataset_size))\nif shuffle_dataset :\n    np.random.seed(random_seed)\n    np.random.shuffle(indices)\ntrain_indices, val_indices = indices[split:], indices[:split]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom torch.utils.data.sampler import SubsetRandomSampler\n\n# Creating  data samplers:\ntrain_sampler = SubsetRandomSampler(train_indices)\nvalid_sampler = SubsetRandomSampler(val_indices)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"names=train_data.iloc[:,1:-1].columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class plant_data(Dataset):\n    def __init__(self,data,transform=None):\n        self.data=data\n        self.transform=transform\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self,index):\n        image=cv2.imread(self.data.loc[index,'image_path'])\n        image= cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        label=torch.tensor(self.data.loc[index,names])\n        if self.transform is not None:\n              image = self.transform(image=image)[\"image\"]\n    \n\n        return image,label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n# Assuming that we are on a CUDA machine, this should print a CUDA device:\n\nprint(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntran_dataset = plant_data(train_data,transform=train_transform)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loader = torch.utils.data.DataLoader(tran_dataset, batch_size=4,  sampler=train_sampler)\nvalid_loader= torch.utils.data.DataLoader(tran_dataset, batch_size=4,  sampler=valid_sampler)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def visualize_augmentations(dataset, idx=0, samples=10, cols=5):\n    dataset = copy.deepcopy(dataset)\n    dataset.transform = A.Compose([t for t in dataset.transform if not isinstance(t, (A.Normalize, ToTensorV2))])\n    rows = samples // cols\n    figure, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(12, 6))\n    for i in range(samples):\n        image, _ = dataset[idx]\n        ax.ravel()[i].imshow(image)\n        ax.ravel()[i].set_axis_off()\n    plt.tight_layout()\n    plt.show()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random.seed(42)\nvisualize_augmentations(tran_dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"def calculate_accuracy(output, target):\n    output = torch.sigmoid(output) >= 0.5\n    target = target == 1.0\n    return torch.true_divide((target == output).sum(dim=1), (output.size(0)))\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MetricMonitor:\n    def __init__(self, float_precision=3):\n        self.float_precision = float_precision\n        self.reset()\n\n    def reset(self):\n        self.metrics = defaultdict(lambda: {\"val\": 0, \"count\": 0, \"avg\": 0})\n\n    def update(self, metric_name, val):\n        metric = self.metrics[metric_name]\n\n        metric[\"val\"] += val\n        metric[\"count\"] += 1\n        metric[\"avg\"] = metric[\"val\"] / metric[\"count\"]\n\n    def __str__(self):\n        return \" | \".join(\n            [\n                \"{metric_name}: {avg:.{float_precision}f}\".format(\n                    metric_name=metric_name, avg=metric[\"avg\"], float_precision=self.float_precision\n                )\n                for (metric_name, metric) in self.metrics.items()\n            ]\n        )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DenseCrossEntropy(nn.Module):\n    \n    def __init__(self):\n        super().__init__()\n        \n    def forward(self,logits,labels):\n        logits = logits.float()\n        labels = labels.float()\n        \n        logprobs = F.log_softmax(logits,dim=1)\n        \n        loss =-labels*logprobs\n        loss = loss.sum(-1)\n        \n        return loss.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"params = {\n    \"model\": \"resnet50\",\n    \"device\": \"cuda\",\n    \"lr\": 0.001,\n    \"batch_size\": 64,\n    \"num_workers\": 4,\n    \"epochs\": 10,\n}\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(train_loader, model, criterion, optimizer, epoch):\n    metric_monitor = MetricMonitor()\n    model.train()\n    stream = tqdm(train_loader)\n    for i, (images, target) in enumerate(stream, start=1):\n        images = images.to(device, non_blocking=True)\n        target = target.to(device, non_blocking=True)\n        output = model(images)\n        loss = criterion(output, target.type_as(output))\n        #acc = calculate_accuracy(output, target.type_as(output))\n        score=f1_score(target.data.to('cpu'), output.data.to('cpu') > 0.5, average=\"samples\")\n        metric_monitor.update(\"Loss\", loss.item())\n        metric_monitor.update(\"F1 score\", score.item())\n        #metric_monitor.update(\"Accuracy\", acc)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        stream.set_description(\n            \"Epoch: {epoch}. Train: {metric_monitor}\".format(epoch=epoch, metric_monitor=metric_monitor,))\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def validate(val_loader, model, criterion, epoch):\n    metric_monitor = MetricMonitor()\n    model.eval()\n    stream = tqdm(val_loader)\n    with torch.no_grad():\n        for i, (images, target) in enumerate(stream, start=1):\n            images = images.to(device, non_blocking=True)\n            target = target.to(device, non_blocking=True)\n            output = model(images)\n            \n            loss = criterion(output, target.type_as(output))\n            #acc = calculate_accuracy(output, target.type_as(output))\n            score=f1_score(target.data.to('cpu'), output.data.to('cpu') > 0.5, average=\"samples\")\n            metric_monitor.update(\"Loss\", loss.item())\n            metric_monitor.update(\"F1 score\", score.item())\n            #metric_monitor.update(\"Accuracy\", acc)\n            stream.set_description(\n            \"Epoch: {epoch}. Val: {metric_monitor}\".format(epoch=epoch, metric_monitor=metric_monitor,))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_ft = models.resnet18(pretrained=True)\nnum_ftrs = model_ft.fc.in_features\n# Here the size of each output sample is set to 2.\n# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\nmodel_ft.fc = nn.Sequential(nn.Linear(num_ftrs,512),\n                        nn.ReLU(),\n                        nn.Dropout(p=0.3),\n                        nn.Linear(512,4))\n\nmodel_ft = model_ft.to(device)\n\ncriterion =  nn.MultiLabelSoftMarginLoss()\n\n# Observe that all parameters are being optimized\noptimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n\n# Decay LR by a factor of 0.1 every 7 epochs\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for epoch in range(1, 30 + 1):\n    train(train_loader, model_ft, criterion, optimizer_ft, epoch)\n    validate(valid_loader, model_ft, criterion, epoch)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class plant_test_data(Dataset):\n    def __init__(self,data,transform=None):\n        self.data=data\n        self.transform=transform\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self,index):\n        image=cv2.imread(self.data.loc[index,'image_path'])\n        image=cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.transform is not None:\n              image =self.transform(image=image)[\"image\"]\n    \n\n        return image\n    \ntest_transform = A.Compose(\n    [\n        A.SmallestMaxSize(max_size=160),\n        A.CenterCrop(height=128, width=128),\n        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n        ToTensorV2(),\n    ]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataset = plant_test_data(test_data,test_transform)\ntest_loader=torch.utils.data.DataLoader(test_dataset, batch_size=1,shuffle=False, pin_memory=True)     ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nmodel = model_ft.eval()\npredicted_labels = []\nwith torch.no_grad():\n    for images in test_loader:\n        images = images.to(device, non_blocking=True)\n        output = model(images)\n        #predictions = (torch.sigmoid(output) >= 0.5)[:, 0].cpu().numpy()\n        predicted_labels.append(torch.sigmoid(output).cpu().numpy())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"samp=pd.read_csv(\"../input/plant-pathology-2020-fgvc7/test.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final=pd.concat([samp,pd.DataFrame(np.array(predicted_labels).reshape(-1,4),columns=names)],axis=1)\nfinal.reset_index(drop=True, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final.to_csv('sample_submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}