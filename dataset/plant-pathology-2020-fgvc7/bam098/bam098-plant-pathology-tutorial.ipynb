{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"pip install pretrainedmodels","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Plant Pathology\n- Dataset: https://arxiv.org/abs/2004.11958\n- Approach from: https://isaac-flath.github.io/fastblog/deep%20learning/2021/02/15/PlantPathology.html (author: [Isaac Flath](https://github.com/Isaac-Flath))\n- General Hints: https://twitter.com/abhi1thakur/status/1360954451104829441\n- Alternative Approach: https://hamonk.github.io/2020/12/05/plant_pathology.html#what-worked (not implemted here)\n- you need accuracy with variance attached to it, https://www.youtube.com/watch?v=0LIACHcxpHU"},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install torchsummary","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create data directory\n!rm -rf data\n!mkdir data\n\n# copy data\n!cp -r /kaggle/input/plant-pathology-2020-fgvc7/images data\n!cp /kaggle/input/plant-pathology-2020-fgvc7/train.csv data\n!cp /kaggle/input/plant-pathology-2020-fgvc7/test.csv data\n!cp /kaggle/input/plant-pathology-2020-fgvc7/sample_submission.csv data\n\n# lists data\n!ls data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# copy resume files\n!cp /kaggle/input/plant-pathology-resume-files/distilled_labels.csv .\n#!cp /kaggle/input/plant-pathology-resume-files/fold_idx.pkl .\n#!cp /kaggle/input/plant-pathology-resume-files/pred2.pkl .\n#!cp /kaggle/input/plant-pathology-resume-files/true2.pkl .\n!cp /kaggle/input/plant-pathology-resume-files/fold_idx_sl.pkl .\n!cp /kaggle/input/plant-pathology-resume-files/pred_sl2.pkl .\n!cp /kaggle/input/plant-pathology-resume-files/true_sl2.pkl .\n\n# list current working directory\n!ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import platform\nimport fastai\nfrom fastai.vision.all import *\nimport torch\nimport torchvision\nfrom torchsummary import summary\nimport pretrainedmodels\nimport albumentations\nfrom albumentations import (\n    Compose,GaussianBlur,HorizontalFlip,MedianBlur,MotionBlur,OneOf,\n    RandomBrightness,RandomContrast,Resize,ShiftScaleRotate,VerticalFlip\n)\nimport sklearn\nfrom sklearn.model_selection import StratifiedKFold\nimport os\nimport cv2\nimport pandas as pd\nimport pickle\n\nprint('python version:           {}'.format(platform.python_version()))\nprint('fastai version:           {}'.format(fastai.__version__))\nprint('torch version:            {}'.format(torch.__version__))\nprint('torchvision version:      {}'.format(torchvision.__version__))\nprint('pretrainedmodels version: {}'.format(pretrainedmodels.__version__))\nprint('albumentations version:   {}'.format(albumentations.__version__))\nprint('sklearn version:          {}'.format(sklearn.__version__))\nprint('opencv version:           {}'.format(cv2.__version__))\nprint('pandas version:           {}'.format(pd.__version__))\n\nuse_cuda = torch.cuda.is_available()\ndevice = torch.device(\"cuda\" if use_cuda else \"cpu\") \nprint('CUDA available:           {}'.format(use_cuda))\nprint('cuDNN enabled:            {}'.format(torch.backends.cudnn.enabled))\nprint('num gpus:                 {}'.format(torch.cuda.device_count()))\n\nif use_cuda:\n    print('gpu:                      {}'.format(torch.cuda.get_device_name(0)))\n\n    print()\n    print('------------------------- CUDA -------------------------')\n    ! nvcc --version","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seed = 42\ntorch.manual_seed(seed)\nnp.random.seed(seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dir = Path('./data')\nimg_dir = data_dir/'images'\nlabels = ['healthy', 'multiple_diseases', 'rust', 'scab']\nimage_size = [480, 768]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Load Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_data(path):\n    df = pd.read_csv(path)\n    df['image_id'] = 'data/images/' + df.image_id + '.jpg'\n    df['label'] = df[labels].idxmax(1)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = load_data(data_dir/'train.csv')\nprint('dataset size: {}'.format(len(train_df.index)))\ntrain_df.sample(n=5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[labels].sum().plot(kind='bar');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['label'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Clean Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"for img in train_df.image_id:\n    img_loaded= Image.open(img)\n    if img_loaded.shape == (1365, 2048): continue\n    print(img,img_loaded.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = Image.open(img_dir/'Train_245.jpg'); img.size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = Image.open(img_dir/'Train_1156.jpg'); img.size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for img in train_df.image_id:\n    img_loaded= Image.open(img)\n    if img_loaded.shape == (1365, 2048): continue\n    img_loaded.transpose(Image.TRANSPOSE).save(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = Image.open(img_dir/'Train_245.jpg'); img.size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = Image.open(img_dir/'Train_1156.jpg'); img.size","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Define Transforms"},{"metadata":{"trusted":true},"cell_type":"code","source":"class AlbumentationsTransform(RandTransform):\n    \"A transform handler for multiple `Albumentation` transforms\"\n    split_idx,order=None,2\n    def __init__(self, train_aug, valid_aug): store_attr()\n    \n    def before_call(self, b, split_idx):\n        self.idx = split_idx\n    \n    def encodes(self, img: PILImage):\n        if self.idx == 0:\n            aug_img = self.train_aug(image=np.array(img))['image']\n        else:\n            aug_img = self.valid_aug(image=np.array(img))['image']\n\n        return PILImage.create(aug_img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_train_aug(image_size): return Compose(\n    [\n        Resize(height=image_size[0], width=image_size[1]),\n        OneOf([RandomBrightness(limit=0.1, p=1), RandomContrast(limit=0.1, p=1)]), #fastai has\n        OneOf([MotionBlur(blur_limit=3), MedianBlur(blur_limit=3), GaussianBlur(blur_limit=3)], p=0.5),\n        VerticalFlip(p=0.5),#Dihedral\n        HorizontalFlip(p=0.5),\n        ShiftScaleRotate(\n            shift_limit=0.2,\n            scale_limit=0.2,\n            rotate_limit=20,\n            interpolation=cv2.INTER_LINEAR,\n            border_mode=cv2.BORDER_REFLECT_101,\n            p=1,\n        ),\n    ]\n)\n\ndef get_valid_aug(image_size): return  Compose(\n    [\n        Resize(height=image_size[0], width=image_size[1]),\n    ]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"item_tfms = [AlbumentationsTransform(get_train_aug(image_size), get_valid_aug(image_size))]\nbatch_tfms = [Normalize.from_stats(*imagenet_stats)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create Dataloader"},{"metadata":{"trusted":true},"cell_type":"code","source":"dls = ImageDataLoaders.from_df(\n    train_df, bs=16, seed=2020, item_tfms=item_tfms, batch_tfms=batch_tfms, label_col=5\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dls.show_batch(max_n=16)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def l2_norm(input, axis=1):\n    norm = torch.norm(input, 2, axis, True)\n    output = torch.div(input, norm)\n    return output\n\n\nclass BinaryHead(nn.Module):\n    def __init__(self, num_class=4, emb_size=2048, s=16.0):\n        super(BinaryHead, self).__init__()\n        self.s = s\n        self.fc = nn.Sequential(nn.Linear(emb_size, num_class))\n\n    def forward(self, fea):\n        fea = l2_norm(fea)\n        logit = self.fc(fea) * self.s\n        return logit\n\n\nclass se_resnext50_32x4d(nn.Module):\n    def __init__(self):\n        super(se_resnext50_32x4d, self).__init__()\n\n        self.model_ft = nn.Sequential(\n            *list(pretrainedmodels.__dict__[\"se_resnext50_32x4d\"](num_classes=1000, pretrained=\"imagenet\").children())[\n                :-2\n            ]\n        )\n        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n        self.model_ft.last_linear = None\n        self.fea_bn = nn.BatchNorm1d(2048)\n        self.fea_bn.bias.requires_grad_(False)\n        self.binary_head = BinaryHead(4, emb_size=2048, s=1)\n        self.dropout = nn.Dropout(p=0.2)\n\n    def forward(self, x):\n\n        img_feature = self.model_ft(x)\n        img_feature = self.avg_pool(img_feature)\n        img_feature = img_feature.view(img_feature.size(0), -1)\n        fea = self.fea_bn(img_feature)\n        # fea = self.dropout(fea)\n        output = self.binary_head(fea)\n\n        return output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = se_resnext50_32x4d()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"summary(model.to(device), (3, 224, 224))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train"},{"metadata":{},"cell_type":"markdown","source":"### Loss Function"},{"metadata":{"trusted":true},"cell_type":"code","source":"class CrossEntropyLossOneHot(nn.Module):\n    def __init__(self):\n        super(CrossEntropyLossOneHot, self).__init__()\n        self.log_softmax = nn.LogSoftmax(dim=-1)\n\n    def forward(self, preds, labels):\n        return torch.mean(torch.sum(-labels * self.log_softmax(preds), -1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### One-Hot-Label Callback"},{"metadata":{"trusted":true},"cell_type":"code","source":"class OneHotLabelCB(Callback):\n    \n    def before_train(self):\n        self.imgs_list = L(o for o in self.dl.items.iloc[:,0].values) # get list of images in the order they are drawn this epoch\n        self.df = self.dl.items.set_index('image_id')\n    \n    def before_validate(self):\n        self.imgs_list = L(o for o in self.dl.items.iloc[:,0].values) # get list of images in the order they are drawn this epoch\n        self.df = self.dl.items.set_index('image_id')\n\n    def before_batch(self):\n        df = self.df\n        imgs = self.imgs_list[self.dl._DataLoader__idxs[self.iter*self.dl.bs:self.iter*self.dl.bs+self.dl.bs]]\n        one_hot_yb = df.loc[imgs,df.columns[:-1]].values\n        self.learn.yb = (Tensor(one_hot_yb).cuda(),)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Metric"},{"metadata":{"trusted":true},"cell_type":"code","source":"def accuracy(inp, targ, axis=-1):\n    \"Compute accuracy with `targ` when `pred` is bs * n_classes\"\n    pred,targ = flatten_check(inp.argmax(dim=axis), targ.argmax(dim=axis))\n    return (pred == targ).float().mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Inference"},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_predict(cnt,msg):\n    # Create Test Dataloaders\n    test = load_data('data/sample_submission.csv')\n    test_dl = dls.test_dl(test) \n\n    # predict with test time augmentation\n    preds, _ = learn.tta(dl=test_dl) \n    p = preds.softmax(axis=1) \n\n    # format submission file\n    test = pd.read_csv('data/sample_submission.csv')['image_id']\n    out_a = pd.concat([test,pd.DataFrame(p,columns = learn.dls.vocab)],axis=1)[['image_id','healthy','multiple_diseases','rust','scab']]\n\n    # write to csv and submit to kaggle\n    out_a.to_csv(f'submission{cnt}.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Stratified K-Fold: https://towardsdatascience.com/stratified-k-fold-what-it-is-how-to-use-it-cf3d107d3ea2"},{"metadata":{"trusted":true},"cell_type":"code","source":"#skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n#fold_idx = list(skf.split(train_df.image_id,train_df.label))\n#\n#with open('fold_idx.pkl', 'wb') as f:\n#    pickle.dump(fold_idx, f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#with open('fold_idx.pkl', 'rb') as f:\n#    fold_idx = pickle.load(f)\n#    \n#fold_idx = fold_idx[3:]; len(fold_idx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#true = pd.DataFrame(columns = L(o for o in train_df.columns))\n#pred = pd.DataFrame(columns = L(o for o in train_df.columns))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#with open('true2.pkl', 'rb') as f:\n#    true = pickle.load(f)\n#    \n#with open('pred2.pkl', 'rb') as f:\n#    pred = pickle.load(f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#splits, preds, targs, preds_c,  = [],[],[],[]\n##i = 0\n#i = 3\n#\n#for _, val_idx in fold_idx:\n#    splitter = IndexSplitter(val_idx)\n#\n#    # Create dataloaders splittin on indexes defined by StratifiedKFold\n#    db = DataBlock(\n#        blocks=(ImageBlock,CategoryBlock),\n#        get_x=ColReader(0),get_y=ColReader(5),\n#        item_tfms=item_tfms,batch_tfms=batch_tfms,\n#        splitter=splitter\n#    )\n#    dls = db.dataloaders(train_df, bs=24)\n#\n#    #train model with fastai dataloaders, pytorch model, pytorch loss function, fastai gradient clipping, custom callback, on fp16 precision \n#    learn = Learner(dls,se_resnext50_32x4d(),loss_func=CrossEntropyLossOneHot(),cbs=[GradientClip,OneHotLabelCB()], metrics=[accuracy]).to_fp16()\n#    learn.fine_tune(80,reset_opt=True) # Train freeze epoch then unfreeze for 80 epochs   \n#\n#    p, _ = learn.tta() # test time augmentation\n#    p = p.softmax(axis=1) # Convert to probabilities\n#\n#    # Format dataframe to save\n#    items_pred = pd.DataFrame(p, columns=dls.vocab)\n#    items_pred['label'] = [dls.vocab[int(o)] for o in p.argmax(dim=1)]\n#    items_pred['image_id'] = dls.valid.items.image_id.values\n#    items_pred = items_pred[train_df.columns]\n#    \n#    true = pd.concat([true,dls.valid.items])\n#    with open(f'true{i}.pkl', 'wb') as f:\n#        pickle.dump(true, f)\n#    \n#    pred = pd.concat([pred,items_pred])\n#    with open(f'pred{i}.pkl', 'wb') as f:\n#        pickle.dump(pred, f)\n#    \n#    # predict and submit to kaggle\n#    test_predict(i,f'distilling labels fold count {i}') \n#    i += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pred.to_csv('distilled_labels.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train (Soft Labeling)"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = load_data(data_dir/'train.csv')\ntrain_df = train_df.sort_values('image_id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"distilled_labels = pd.read_csv('distilled_labels.csv')\ndistilled_labels = distilled_labels.sort_values('image_id');\n\n# Get one hot encoded labels (zeros and ones)\ndistilled_labels.iloc[:,1:-1] = pd.get_dummies(distilled_labels.label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert (train_df.image_id.values==distilled_labels.image_id.values).all()\ndistilled_labels.reset_index(drop=True,inplace=True); train_df.reset_index(drop=True,inplace=True); \n\n# get soft labels\ntrain_df.iloc[:,1:-1] = distilled_labels.iloc[:,1:-1] * .3 + train_df.iloc[:,1:-1] * .7\ntrain_df.loc[train_df.healthy == 0.3][:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train (5 Folds)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n#fold_idx = list(skf.split(train_df.image_id,train_df.label))\n#\n#with open('fold_idx_sl.pkl', 'wb') as f:\n#    pickle.dump(fold_idx, f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('fold_idx_sl.pkl', 'rb') as f:\n    fold_idx = pickle.load(f)\n    \nfold_idx = fold_idx[3:]; len(fold_idx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#true = pd.DataFrame(columns = L(o for o in train_df.columns))\n#pred = pd.DataFrame(columns = L(o for o in train_df.columns))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('true_sl2.pkl', 'rb') as f:\n    true = pickle.load(f)\n    \nwith open('pred_sl2.pkl', 'rb') as f:\n    pred = pickle.load(f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"splits, preds, targs, preds_c,  = [],[],[],[]\n#i = 0\ni = 3\n\nfor _, val_idx in fold_idx:\n    splitter = IndexSplitter(val_idx)\n\n    # Create dataloaders splittin on indexes defined by StratifiedKFold\n    db = DataBlock(\n        blocks=(ImageBlock,CategoryBlock),\n        get_x=ColReader(0),get_y=ColReader(5),\n        item_tfms=item_tfms,batch_tfms=batch_tfms,\n        splitter=splitter\n    )\n    dls = db.dataloaders(train_df, bs=24)\n\n    #train model with fastai dataloaders, pytorch model, pytorch loss function, fastai gradient clipping, custom callback, on fp16 precision \n    learn = Learner(dls,se_resnext50_32x4d(),loss_func=CrossEntropyLossOneHot(),cbs=[GradientClip,OneHotLabelCB()], metrics=[accuracy]).to_fp16()\n    learn.fine_tune(80,reset_opt=True) # Train freeze epoch then unfreeze for 80 epochs   \n\n    p, _ = learn.tta() # test time augmentation\n    p = p.softmax(axis=1) # Convert to probabilities\n\n    # Format dataframe to save\n    items_pred = pd.DataFrame(p, columns=dls.vocab)\n    items_pred['label'] = [dls.vocab[int(o)] for o in p.argmax(dim=1)]\n    items_pred['image_id'] = dls.valid.items.image_id.values\n    items_pred = items_pred[train_df.columns]\n    \n    true = pd.concat([true,dls.valid.items])\n    with open(f'true_sl{i}.pkl', 'wb') as f:\n        pickle.dump(true, f)\n    \n    pred = pd.concat([pred,items_pred])\n    with open(f'pred_sl{i}.pkl', 'wb') as f:\n        pickle.dump(pred, f)\n    \n    # predict and submit to kaggle\n    test_predict(i,f'distilling labels fold count {i}') \n    i += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('data/sample_submission.csv')['image_id']\nout = pd.concat([test,pred],axis=1)[['image_id','healthy','multiple_diseases','rust','scab']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred.to_csv('submission_final.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred2 = pred.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred2['image_id'] = test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred2[['image_id','healthy','multiple_diseases','rust','scab']].to_csv('submission_final_real.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"distilled_labels = pd.read_csv('distilled_labels.csv'); distilled_labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"distilled_labels['image_id'] = test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"distilled_labels[['image_id','healthy','multiple_diseases','rust','scab']].to_csv('submission_distilled_real.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}