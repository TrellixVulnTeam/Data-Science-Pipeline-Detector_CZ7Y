{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os \n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\n\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport tensorflow as tf\n\nnp.random.seed(0)\ntf.random.set_seed(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install efficientnet\nimport efficientnet.tfkeras  as efn\nfrom kaggle_datasets import KaggleDatasets\n\nAUTO = tf.data.experimental.AUTOTUNE\n\ndef TPU():\n    # Detect hardware, return appropriate distribution strategy\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n        print('Running on TPU ', tpu.master())\n    except ValueError:\n        tpu = None\n\n    if tpu:\n        tf.config.experimental_connect_to_cluster(tpu)\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n    else:\n        strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\n    print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n    return strategy\n\n\nstrategy = TPU()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GCS_DS_PATH = KaggleDatasets().get_gcs_path()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv('../input/plant-pathology-2020-fgvc7/train.csv')\ntest_data = pd.read_csv('../input/plant-pathology-2020-fgvc7/test.csv')\n\ntrain_paths = train_data['image_id'].apply(lambda x: os.path.join(GCS_DS_PATH , 'images' , x + '.jpg')).values\ntest_paths = test_data['image_id'].apply(lambda x: os.path.join(GCS_DS_PATH , 'images' , x + '.jpg')).values\n\ntrain_labels = train_data.iloc[:,1:].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_classes = 4\nBATCH_SIZE = 8 * strategy.num_replicas_in_sync\nimg_size = 800\nEPOCHS = 100\nFOLDS = 5\nSEED = 42","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def decode_image(filename, label=None, image_size=(img_size, img_size)):\n    bits = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(bits, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0\n    image = tf.image.resize(image, image_size)\n    if label is None:\n        return image\n    else:\n        return image, label\n    \ndef data_augment(image, label=None, seed=2020):\n    image = tf.image.random_flip_left_right(image, seed=seed)\n    image = tf.image.random_flip_up_down(image, seed=seed)\n           \n    if label is None:\n        return image\n    else:\n        return image, label\n    \n    \ndef prepare_train(train_paths, train_labels):\n    data = (\n        tf.data.Dataset\n        .from_tensor_slices((train_paths, train_labels))\n        .map(decode_image, num_parallel_calls=AUTO)\n        .map(data_augment, num_parallel_calls=AUTO)\n        .repeat()\n        .shuffle(512)\n        .batch(BATCH_SIZE)\n        .prefetch(AUTO)\n    )\n    return data\n\ndef prepare_val(val_paths, val_labels):\n    data = (\n        tf.data.Dataset\n        .from_tensor_slices((val_paths, val_labels))\n        .map(decode_image, num_parallel_calls=AUTO)\n        .batch(BATCH_SIZE)\n        .prefetch(AUTO)\n    )\n    return data\n\ndef prepare_test(test_paths):\n    data = (\n        tf.data.Dataset\n        .from_tensor_slices((test_paths))\n        .map(decode_image, num_parallel_calls=AUTO)\n        .batch(BATCH_SIZE)\n    )\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model():\n    base_model = efn.EfficientNetB7(weights='imagenet', include_top=False, pooling='avg', input_shape=(img_size, img_size, 3))\n    x = base_model.output\n    predictions = Dense(n_classes, activation='softmax')(x)\n    model = Model(inputs=base_model.input, outputs=predictions)\n    model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n    return model\n\ndef Callbacks():\n    erl = EarlyStopping(monitor='val_loss', patience=11, verbose=1, mode='min', restore_best_weights=True)\n    rdc = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=2, verbose=1, mode='min')\n    return [erl,rdc]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\ntest_pred = []\nval_roc_auc = []\n# all_history = []\n\nfor i, (train_idx, val_idx) in enumerate(skf.split(train_paths, train_labels.argmax(1))):\n    print(); print('#'*25)\n    print('### FOLD',i+1)\n    print('#'*25)\n    X_train, X_val = train_paths[train_idx], train_paths[val_idx]\n    y_train, y_val = train_labels[train_idx], train_labels[val_idx]\n    \n    strategy = TPU()\n    with strategy.scope():\n        model = get_model()\n        history = model.fit(\n                    prepare_train(X_train,y_train),\n                    steps_per_epoch=y_train.shape[0] // BATCH_SIZE,\n                    validation_data=prepare_val(X_val, y_val),\n                    validation_steps=y_val.shape[0] // BATCH_SIZE,\n                    callbacks=Callbacks(),\n                    epochs=EPOCHS,\n                    verbose=1\n                )\n\n    test_pred.append(model.predict(prepare_test(test_paths), verbose=1))\n    val_roc_auc.append(roc_auc_score(y_val,model.predict(prepare_val(X_val, y_val), verbose=1)))\n    \n#     all_history.append(history)\n#     model.save('{}_model.h5'.format(i+1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_roc_auc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_test = 0\nfor i in range(FOLDS):\n    all_test += test_pred[i]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_models = all_test/FOLDS\nall_models","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_2_models = test_pred[0]*.7 + test_pred[3]*.3\nbest_2_models","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# best_2_models gives me better score on LB\nsumb = pd.read_csv('../input/plant-pathology-2020-fgvc7/sample_submission.csv')\nsumb.iloc[:,1:] = best_2_models \n# sumb.iloc[:,1:] = all_models","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sumb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sumb.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}