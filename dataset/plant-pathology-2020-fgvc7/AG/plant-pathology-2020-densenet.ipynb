{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install wandb -q","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport os \nimport json\nimport math\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nfrom tensorflow.keras.layers import Dense, Input, Dropout, GlobalAveragePooling2D\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.applications.densenet import preprocess_input\nfrom datetime import datetime as dt\n\nprint(\"TF Version:\", tf.__version__)\n\nimport wandb\nfrom wandb.keras import WandbCallback\n\n# Initilize a new wandb run\nwandb.init(project=\"Plant_Pathology_2020\", name='exp6', tags=['DenseNet201','finetune'])\n\ntrain_csv = '/kaggle/input/plant-pathology-2020-fgvc7/train.csv'\ntest_csv = '/kaggle/input/plant-pathology-2020-fgvc7/test.csv'\n\nDATA_PATH = '/kaggle/input/plant-pathology-2020-fgvc7/images/'\nSAVE_PATH = '/kaggle/working/'\n\nMODEL_NAME = 'Plant_Pathology_2020'\n\n# Default values for hyper-parameters\nconfig = wandb.config # Config is a variable that holds and saves hyperparameters and inputs\n\nconfig.PRETRAINED_MODEL = 'densenet201'\n\nconfig.IMG_HEIGHT = 224\nconfig.IMG_WIDTH = 224\nconfig.BATCH_SIZE = 64\nconfig.lr = 0.001\nconfig.EPOCHS = 100\nconfig.LOSS = 'binary_crossentropy'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"![](http://)**Data Analysis**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train data\nimg_df =  pd.read_csv(train_csv)\nimg_df['image_id'] = img_df.image_id.apply(lambda x: x+'.jpg')\n\nTRAIN_df, VAL_df = train_test_split(img_df, test_size=0.2, random_state=42)\nTRAIN_df = TRAIN_df.reset_index(drop=True)\nprint('Train Set:')\nprint(TRAIN_df)\nVAL_df = VAL_df.reset_index(drop=True)\nprint('')\nprint('Val Set')\nprint(VAL_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_batch(df, source_dir):\n    df = shuffle(df)\n    df.reset_index(drop=True, inplace=True)\n    plt.figure(figsize=(12, 12))\n    for n in range(9):\n        ax = plt.subplot(3,3,n+1)\n        filename = df.iloc[n, 0]\n        img = load_img(source_dir+ filename, target_size=(224, 224))\n        labels = list(df.iloc[n,:][df.iloc[n,:]==1].to_dict().keys())\n        plt.imshow(img)\n        plt.xlabel(labels)\n        plt.axis('on')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_batch(TRAIN_df, DATA_PATH)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def value_count(df):\n\n    index=[]\n    counts=[]\n    for i in list(df.columns[1:]):\n        index.append(i)\n        counts.append(df[i].value_counts().to_dict())\n    index_re = [i for i in index]\n\n    #key_map = dict(zip(index, index_re))\n    df = pd.DataFrame(counts, index=index_re)\n    #df = pd.DataFrame(counts)\n    original_df = df.copy()\n    original_df['Disease_Type']=index\n    original_df = original_df.rename(columns={0:\"Negative\", 1:\"Positive\"})\n    original_df = original_df.sort_values(by=['Positive'], ascending=False)\n    original_df = original_df[['Disease_Type','Negative', 'Positive']]\n    \n    df = df.rename(columns={0:\"Negative\",1:\"Positive\"})\n    df = df.sort_values(by=['Positive'],ascending=False)\n\n    ax = df.plot.bar(rot=0,title =\"Positive/Negative Count\",figsize=(20,11),legend=True, fontsize=12)\n    ax.set_yticks([i for i in range(0,df['Negative'].max()+1000,1000)])\n    ax.set_yticklabels([i for i in range(0,df['Negative'].max()+1000,1000)], fontsize=8)\n    ax.set_xlabel(\"Disease_Type\",fontsize=14)\n    ax.set_ylabel(\"Count\",fontsize=14)\n    ax.grid(True,linestyle='--',color='0.75')\n    \n    return original_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"value_count(TRAIN_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Image Data Generator**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n                                     rotation_range=45, \n                                     width_shift_range=0.1, \n                                     height_shift_range=0.1, \n                                     zoom_range=0.1, \n                                     vertical_flip=True,\n                                     horizontal_flip=True, \n                                     fill_mode=\"nearest\")\n\nval_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n\ntrain_flow = train_datagen.flow_from_dataframe(dataframe=TRAIN_df,\n                                          directory=DATA_PATH,\n                                          x_col='image_id',\n                                          y_col=list(TRAIN_df.columns[1:]), class_mode=\"multi_output\",\n                                          target_size=(config.IMG_HEIGHT, config.IMG_WIDTH),\n                                          batch_size=config.BATCH_SIZE, shuffle=True, validate_filenames=True, drop_duplicates=False)\n\nval_flow = val_datagen.flow_from_dataframe(dataframe=VAL_df,\n                                        directory=DATA_PATH,\n                                        x_col='image_id',\n                                        y_col=list(VAL_df.columns[1:]), class_mode=\"multi_output\",\n                                        target_size=(config.IMG_HEIGHT, config.IMG_WIDTH),\n                                        batch_size=config.BATCH_SIZE, shuffle=False, validate_filenames=True, drop_duplicates=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = list(TRAIN_df.columns[1:])\nlabels","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Model architecture"},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs = Input((config.IMG_HEIGHT, config.IMG_WIDTH, 3))\n\nbase_model = tf.keras.applications.densenet.DenseNet201(include_top=False, weights='imagenet', input_tensor=None, input_shape=None, pooling='max')\nx = base_model(inputs)\n\noutputs = [Dense(1, name='{}'.format(i), activation='sigmoid')(x) for i in list(TRAIN_df.columns[1:])]\n\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\noptimizer = tf.keras.optimizers.Adam(config.lr, epsilon=1e-08)\n\nfor layer in model.layers:\n    layer.trainable = True\n    \nmodel.compile(optimizer=optimizer, loss=config.LOSS, metrics=['accuracy'])\n\nmodel.summary()\n\nprint(\"Trainable layers...\")\nfor layer in model.layers:\n    print(layer.name, ':', layer.trainable)\nprint(\"\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model checkpoint\nmodel_checkpoint = ModelCheckpoint(filepath=os.path.join(SAVE_PATH,'{}_{}_{}_{dt}.hdf5'.format(MODEL_NAME,\n                                                                                                config.PRETRAINED_MODEL,\n                                                                                                config.lr,\n                                                                                                dt=dt.now().strftime(\"%Y-%m-%d--%H-%M\"))),\n                                                                                                monitor='val_loss',\n                                                                                                verbose=1, save_best_only=True, save_weights_only=True)\n\n# Learning Rate Reduction\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_loss',\n                                            patience=2,\n                                            verbose=1,\n                                            factor=0.1,\n                                            min_lr=0.0000001)\n\n# Early stopping\nearlystop = EarlyStopping(monitor='val_loss', patience=4)\n\n# Callbacks\ncallbacks_list = [model_checkpoint, learning_rate_reduction, earlystop, WandbCallback()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(train_flow,\n          epochs=config.EPOCHS,\n          verbose=1,\n          validation_data=val_flow,\n          validation_steps=math.ceil(val_flow.samples / val_flow.batch_size),\n          steps_per_epoch=math.ceil(train_flow.samples / train_flow.batch_size),\n          callbacks=callbacks_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting Test data\n\nTEST_df =  pd.read_csv(test_csv)\nTEST_df['image_id'] = TEST_df.image_id.apply(lambda x: x+'.jpg')\nTEST_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n\ntest_flow = datagen.flow_from_dataframe(dataframe=TEST_df,\n                                          directory=DATA_PATH,\n                                          x_col='image_id',\n                                          y_col=None, class_mode=None,\n                                          target_size=(config.IMG_HEIGHT, config.IMG_WIDTH),\n                                          batch_size=config.BATCH_SIZE, shuffle=False, validate_filenames=True, drop_duplicates=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_predictions = model.predict(test_flow,\n                                  verbose=1,\n                                  steps=math.ceil(test_flow.samples/test_flow.batch_size))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Prepare Submission File**"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df = pd.DataFrame(columns=TRAIN_df.columns)\nsubmission_df['image_id'] = TEST_df['image_id']\nsubmission_df['image_id'] = submission_df.image_id.apply(lambda x: x.split('.')[0])\n\nsubmission_df['healthy'] = model_predictions[0]\nsubmission_df['multiple_diseases'] = model_predictions[1]\nsubmission_df['rust'] = model_predictions[2]\nsubmission_df['scab'] = model_predictions[3]\nsubmission_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df.to_csv('submission2_26_4_2020.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"asm_df1 = pd.DataFrame(columns=sub1.columns)\nasm_df1['image_id'] = sub1['image_id']\nasm_df2 = asm_df1.copy()\nasm_df3 = asm_df1.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"asm_df1.iloc[:, 1:] = sub1.iloc[:,1:]*0.5 + sub2.iloc[:,1:]*0.5\nasm_df2.iloc[:, 1:] = sub1.iloc[:,1:]*0.75 + sub2.iloc[:,1:]*0.25\nasm_df3.iloc[:, 1:] = sub1.iloc[:,1:]*0.25 + sub2.iloc[:,1:]*0.75\n\nasm_df1.to_csv('submission_ensemble_1.csv', index=False)\nasm_df2.to_csv('submission_ensemble_2.csv', index=False)\nasm_df3.to_csv('submission_ensemble_3.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}