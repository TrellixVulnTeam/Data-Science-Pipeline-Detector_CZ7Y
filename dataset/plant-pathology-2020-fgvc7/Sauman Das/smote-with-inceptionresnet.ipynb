{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"IMAGE_DIR = '/kaggle/input/plant-pathology-2020-fgvc7/images/'\ntrain_path = '/kaggle/input/plant-pathology-2020-fgvc7/train.csv'\ntest_path = '/kaggle/input/plant-pathology-2020-fgvc7/test.csv'\nIMAGE_W = 150\nIMAGE_H = 150","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(df):\n    for index, img in enumerate(df.image_id):\n        img = img+'.jpg'\n        df.image_id[index]=img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(train_path)\ntest_df = pd.read_csv(test_path)\npreprocess(train_df)\npreprocess(test_df)\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" def train_val_split(df, val_ratio=0.2):\n    val_rows = (np.random.rand(int(val_ratio*df.shape[0]))*df.shape[0]).astype(int)\n    val_df = df.iloc[val_rows]\n    df.drop(val_rows, axis=0, inplace=True)\n    val_df = val_df.reset_index().drop(['index'], axis=1)\n    df = df.reset_index().drop(['index'], axis=1)\n    int_dict = {'healthy':float, 'multiple_diseases':float, 'rust':float, 'scab':float}\n    df = df.astype(int_dict) \n    val_df = val_df.astype(int_dict)\n    return df, val_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train, val = train_val_split(train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = list(train.columns[1:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_class_freq(df, labels=labels):\n    for col in labels:\n        print(f'{col}: {sum(df[col])}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print_class_freq(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print_class_freq(val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import load_img, img_to_array","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def SMOTE_Data(train_df=train):\n    from imblearn.over_sampling import SMOTE\n    X_train = []\n    for img in train_df['image_id']:\n        loaded_img = load_img(os.path.join(IMAGE_DIR, img), target_size=(IMAGE_W, IMAGE_H))\n        img_arr = img_to_array(loaded_img)\n        X_train.append(img_arr)\n        \n    print(np.array(X_train).shape)  \n    y_train = train_df.drop('image_id', axis=1, inplace=False)\n    print(y_train.head())\n    y_train = np.array(y_train.values)\n    X_train = np.array(X_train)\n    sm = SMOTE(random_state=42)\n    X_train, y_train = sm.fit_resample(X_train.reshape((-1, IMAGE_W * IMAGE_H * 3)), y_train)\n    X_train.reshape(-1, IMAGE_W, IMAGE_H, 3)\n    return X_train, y_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, y_train = SMOTE_Data()\nprint(X_train.shape)\nprint(y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_train.reshape(-1, IMAGE_W, IMAGE_H, 3)\nprint(X_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom keras import backend as K\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\nfrom tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\nfrom tensorflow.keras.applications.densenet import DenseNet121\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.models import Sequential, Model\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout, Activation, BatchNormalization, GlobalAveragePooling2D","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tst_path = '/kaggle/input/test-image-leaf/Test_img.jpg'\nimg = load_img(tst_path, target_size=(150, 150, 3))\nplt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_1_image(img, train_df=train, image_dir=IMAGE_DIR, x_col='image_id', y_cols=labels, sample_size=100, batch_size=32, seed=42, target_w = IMAGE_W, target_h = IMAGE_H):\n    raw_train_generator = ImageDataGenerator().flow_from_dataframe(\n        dataframe=train_df, \n        directory=IMAGE_DIR, \n        x_col=\"image_id\", \n        y_col=y_cols, \n        class_mode=\"raw\", \n        batch_size=sample_size, \n        shuffle=True, \n        target_size=(target_w, target_h))\n    \n    # get data sample\n    batch = raw_train_generator.next()\n    data_sample = batch[0]\n    # use sample to fit mean and std for test set generator\n    image_generator = ImageDataGenerator(\n        featurewise_center=True,\n        featurewise_std_normalization= True)\n    \n    # fit generator to sample from training data\n    image_generator.fit(data_sample)\n    test_img = image_generator.flow(img)\n    return test_img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_array = img_to_array(img)\nimg_array = img_array.reshape(1, 150, 150, 3)\ntest_img = preprocess_1_image(img_array)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_valid_generator(test_df=test_df, valid_df=val, train_df=train, image_dir=IMAGE_DIR, x_col='image_id', y_cols=labels, sample_size=100, batch_size=32, seed=42, target_w = IMAGE_W, target_h = IMAGE_H):\n\n    print(\"getting train and valid generators...\")\n    # get generator to sample dataset\n    raw_train_generator = ImageDataGenerator().flow_from_dataframe(\n        dataframe=train_df, \n        directory=IMAGE_DIR, \n        x_col=\"image_id\", \n        y_col=y_cols, \n        class_mode=\"raw\", \n        batch_size=sample_size, \n        shuffle=True, \n        target_size=(target_w, target_h))\n    \n    # get data sample\n    batch = raw_train_generator.next()\n    data_sample = batch[0]\n\n    # use sample to fit mean and std for test set generator\n    image_generator = ImageDataGenerator(\n        featurewise_center=True,\n        featurewise_std_normalization= True)\n    \n    # fit generator to sample from training data\n    image_generator.fit(data_sample)\n\n    # get test generator\n    valid_generator = image_generator.flow_from_dataframe(\n            dataframe=valid_df,\n            directory=image_dir,\n            x_col=x_col,\n            y_col=y_cols,\n            class_mode=\"raw\",\n            batch_size=batch_size,\n            shuffle=False,\n            seed=seed,\n            target_size=(target_w,target_h))\n    test_generator = image_generator.flow_from_dataframe(\n            dataframe=test_df,\n            directory=image_dir,\n            x_col=x_col,\n            class_mode=None,\n            batch_size=1,\n            shuffle=False,\n            target_size=(target_w,target_h))\n    return valid_generator, test_generator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_train_generator(X=X_train, y=y_train, image_dir=IMAGE_DIR, x_col='image_id', y_cols=labels, shuffle=False, batch_size=32, seed=42, target_w = IMAGE_W, target_h = IMAGE_H):\n    \n    \n    print(\"getting train generator...\") \n    # normalize images\n    image_generator = ImageDataGenerator(\n        samplewise_center=True,\n        samplewise_std_normalization= True)\n    \n    # flow from directory with specified batch size\n    # and target image size\n    generator = image_generator.flow(\n            X,y,\n            batch_size=batch_size,\n            shuffle=shuffle,\n            seed=seed)\n    \n    return generator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = get_train_generator()\nvalid_generator, test_generator = get_valid_generator()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X, y = train_generator.__getitem__(0)\nprint(X.shape)\nprint(y.shape)\nplt.imshow(X[31])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def compute_class_freqs(labels):\n\n    N = labels.shape[0]\n    \n    positive_frequencies = np.mean(labels, axis=0)\n    negative_frequencies = 1 - positive_frequencies\n\n    return positive_frequencies, negative_frequencies","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"freq_pos, freq_neg = compute_class_freqs(y_train)\n\npos_weights = freq_neg\nneg_weights = freq_pos","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_weighted_loss(pos_weights, neg_weights, epsilon=1e-7):\n    \n    def weighted_loss(y_true, y_pred):\n        \n        # initialize loss to zero\n        loss = 0.0\n        \n\n        for i in range(len(pos_weights)):\n            # for each class, add average weighted loss for that class \n            loss += K.mean(-(pos_weights[i]*y_true[:, i]*K.log(y_pred[:, i]+epsilon)\n                             + neg_weights[i]*(1-y_true[:, i])*K.log((1-y_pred[:, i])+epsilon)))\n        return loss\n    \n    return weighted_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def inception_model():\n    base_model = InceptionResNetV2(weights='imagenet', include_top=False)\n\n    x = base_model.output\n\n    # add a global spatial average pooling layer\n    x = GlobalAveragePooling2D()(x)\n\n    # and a logistic layer\n    predictions = Dense(len(labels), activation=\"softmax\")(x)\n\n    model = Model(inputs=base_model.input, outputs=predictions)\n    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n    print('Model has compiled')\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dense_model():\n    base_model = DenseNet121(weights='imagenet', include_top=False)\n\n    x = base_model.output\n\n    # add a global spatial average pooling layer\n    x = GlobalAveragePooling2D()(x)\n\n    # and a logistic layer\n    predictions = Dense(len(labels), activation=\"sigmoid\")(x)\n\n    model = Model(inputs=base_model.input, outputs=predictions)\n    model.compile(optimizer='adam', loss=get_weighted_loss(pos_weights, neg_weights), metrics=['accuracy'])\n    print('Model has compiled')\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_model(labels=labels):\n    model = Sequential()\n    model.add(ResNet50(weights='imagenet', include_top=False, input_shape=(IMAGE_W, IMAGE_H, 3)))\n    model.add(Flatten())\n    model.add(Dropout(0.25))\n    model.add(Dense(64, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dense(len(labels), activation='softmax'))\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    print('Model has compiled')\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = inception_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.callbacks import EarlyStopping\nLR_reduce=ReduceLROnPlateau(monitor='val_accuracy',\n                            factor=.5,\n                            patience=7,\n                            min_lr=.00001,\n                            verbose=1)\n\nES_monitor=EarlyStopping(monitor='val_loss',\n                          patience=20)\ncheckpoint_filepath = '/kaggle/working'\nmodel_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    save_weights_only=True,\n    monitor='val_acc',\n    mode='max',\n    verbose=1,\n    save_best_only=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\nSTEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\nhistory = model.fit(train_generator, steps_per_epoch=STEP_SIZE_TRAIN, validation_data=valid_generator,\n                        validation_steps=STEP_SIZE_VALID, epochs=150, callbacks=[ES_monitor, LR_reduce, model_checkpoint_callback])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save_weights('plant.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred = model.predict_generator(test_img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred[0][np.argmax(test_pred[0])]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'{labels[np.argmax(test_pred[0])]} with {test_pred[0][np.argmax(test_pred[0])]} confidence')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_vals = model.predict_generator(valid_generator, steps = len(valid_generator))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n#copied from Coursera util package\nfrom keras.preprocessing import image\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom tensorflow.compat.v1.logging import INFO, set_verbosity\nimport cv2\n\ndef get_roc_curve(labels, predicted_vals, generator):\n    auc_roc_vals = []\n    for i in range(len(labels)):\n        try:\n            gt = generator.labels[:, i]\n            pred = predicted_vals[:, i]\n            auc_roc = roc_auc_score(gt, pred)\n            auc_roc_vals.append(auc_roc)\n            fpr_rf, tpr_rf, _ = roc_curve(gt, pred)\n            plt.figure(1, figsize=(10, 10))\n            plt.plot([0, 1], [0, 1], 'k--')\n            plt.plot(fpr_rf, tpr_rf,\n                     label=labels[i] + \" (\" + str(round(auc_roc, 3)) + \")\")\n            plt.xlabel('False positive rate')\n            plt.ylabel('True positive rate')\n            plt.title('ROC curve')\n            plt.legend(loc='best')\n        except:\n            print(\n                f\"Error in generating ROC curve for {labels[i]}. \"\n                f\"Dataset lacks enough examples.\"\n            )\n    plt.show()\n    return auc_roc_vals","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"auc_rocs = get_roc_curve(labels, predicted_vals, valid_generator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_vals.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_generator.labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds = model.predict_generator(test_generator, steps = len(test_generator))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds[:, 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(test_path)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['healthy'] = test_preds[:, 0]\ntest['multiple_diseases'] = test_preds[:, 1]\ntest['rust'] = test_preds[:, 2]\ntest['scab'] = test_preds[:, 3]\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.to_csv('submission3.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'submission3.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}