{"cells":[{"metadata":{},"cell_type":"markdown","source":" \n Feature generations:\n * https://www.kaggle.com/abhilashawasthi/feature-engineering-lgb-model\n * https://www.kaggle.com/dimitreoliveira/spark-and-deep-learning-rnn-keras-databricks\n ","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!pip -q install pyspark","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\n\nfrom pyspark import SparkConf, SparkContext\nfrom pyspark.sql import SparkSession, Window\nfrom pyspark.sql.types import *\nimport pyspark.sql.functions as f\n\nfrom pyspark.ml import Transformer, Pipeline, regression\nfrom pyspark.ml.feature import VectorAssembler, OneHotEncoder\nfrom pyspark.ml.evaluation import RegressionEvaluator\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"spark = SparkSession.builder.master(\"local[*]\").appName(\"retail_demand_forecasting\").getOrCreate()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"spark","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"schema = StructType([StructField(\"date\", DateType()),StructField(\"store\", IntegerType()),\n                     StructField(\"item\", IntegerType()),StructField(\"sales\", FloatType())])\ntrain_df = spark.read.csv(path = '/kaggle/input/demand-forecasting-kernels-only/train.csv', schema=schema, header = True).cache()\ntrain_df.printSchema()\n\nschema = StructType([StructField(\"id\", IntegerType()),\n                     StructField(\"date\", DateType()),StructField(\"store\", IntegerType()),\n                     StructField(\"item\", IntegerType())])\ntest_df = spark.read.csv(path = '/kaggle/input/demand-forecasting-kernels-only/test.csv', schema=schema, header = True).cache()\ntest_df.printSchema()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train_df.withColumn('type',f.lit(\"train\"))\ntrain_df = train_df.withColumn('id',f.lit(None))\n\ntest_df = test_df.withColumn('type',f.lit(\"test\"))\ntest_df = test_df.withColumn('sales',f.lit(None))\n\ndf = train_df.unionByName(test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DomExtractor(Transformer):\n    def __init__(self, inputCol, outputCol='dayofmonth'):\n        self.inputCol = inputCol\n        self.outputCol = outputCol\n\n    def _transform(self, df):\n        return df.withColumn(self.outputCol, f.dayofmonth(df[self.inputCol]))\n    \nclass DoyExtractor(Transformer):\n    def __init__(self, inputCol, outputCol='dayofyear'):\n        self.inputCol = inputCol\n        self.outputCol = outputCol\n\n    def _transform(self, df):\n        return df.withColumn(self.outputCol, f.dayofyear(df[self.inputCol]))\n    \nclass DowDayExtractor(Transformer):\n    def __init__(self, inputCol, outputCol='dayofweek'):\n        self.inputCol = inputCol\n        self.outputCol = outputCol\n\n    def _transform(self, df):\n        return df.withColumn(self.outputCol, f.dayofweek(df[self.inputCol]))\n    \n    \nclass MonthExtractor(Transformer):\n    def __init__(self, inputCol, outputCol='month'):\n        self.inputCol = inputCol\n        self.outputCol = outputCol\n\n    def _transform(self, df):\n        return df.withColumn(self.outputCol, f.month(df[self.inputCol]))\n    \nclass YearExtractor(Transformer):\n    def __init__(self, inputCol, outputCol='year'):\n        self.inputCol = inputCol\n        self.outputCol = outputCol\n\n    def _transform(self, df):\n        return df.withColumn(self.outputCol, f.year(df[self.inputCol]))\n    \nclass YearQuarterExtractor(Transformer):\n    def __init__(self, inputCol='month', outputCol='yearquarter'):\n        self.inputCol = inputCol\n        self.outputCol = outputCol\n\n    def _transform(self, df):\n        return df.withColumn(self.outputCol, f.when((df[self.inputCol] <= 3), 0).otherwise(f.when((df[self.inputCol] <= 6), 1).otherwise(f.when((df[self.inputCol] <= 9), 2).otherwise(3))))\n    \n    \nclass WeekendExtractor(Transformer):\n    def __init__(self, inputCol='dayofweek', outputCol='is_weekend'):\n        self.inputCol = inputCol\n        self.outputCol = outputCol\n\n    def _transform(self, df):\n        return df.withColumn(self.outputCol, f.when(((df[self.inputCol] == 1) | (df[self.inputCol] == 7)), 1).otherwise(0))\n\nclass MonthBeginExtractor(Transformer):\n    def __init__(self, inputCol='dayofmonth', outputCol='monthbegin'):\n        self.inputCol = inputCol\n        self.outputCol = outputCol\n\n    def _transform(self, df):\n        return df.withColumn(self.outputCol,f.when((df[self.inputCol] <= 7), 1).otherwise(0))\n    \n    \nclass MonthEndExtractor(Transformer):\n    def __init__(self, inputCol='dayofmonth', outputCol='monthend'):\n        self.inputCol = inputCol\n        self.outputCol = outputCol\n\n    def _transform(self, df):\n        return df.withColumn(self.outputCol, f.when((df[self.inputCol] >= 24), 1).otherwise(0))\n    \nclass logTransform(Transformer):\n    def __init__(self, inputCol, outputCol):\n        self.inputCol = inputCol\n        self.outputCol = outputCol\n\n    def _transform(self, df):\n        return df.withColumn(self.outputCol, f.log1p(f.col(self.inputCol)))\n    \n\nclass LagExtractor(Transformer):\n    \"\"\"Creating sales lag features\"\"\"\n    def __init__(self, inputCol, outputCol='lag', dateCol='date', idCol=['store', 'item'], lags = [91]):\n        self.inputCol = inputCol\n        self.outputCol = outputCol\n        self.dateCol = dateCol\n        self.idCol = idCol\n        self.lags = lags\n        \n    def _transform(self, df):\n        for lag in self.lags:\n            col_name = (self.outputCol + '%s' % lag)\n            \n            w = Window.partitionBy(self.idCol).orderBy(self.dateCol).rowsBetween(-lag, -lag)\n            \n            df = df.withColumn(col_name, f.collect_list(self.inputCol).over(w)[0])\n            \n        return df\n    \nclass RmeanExtractor(Transformer):\n    \"\"\"Creating sales rolling mean features\"\"\"\n    def __init__(self, inputCol, outputCol='rmean', dateCol='date', idCol=['store', 'item'], avgRange=[30], shift = 90):\n        self.inputCol = inputCol\n        self.outputCol = outputCol\n        self.dateCol = dateCol\n        self.idCol = idCol\n        self.avgRange = avgRange\n        self.shift = shift\n\n    def _transform(self, df):\n        for ar in self.avgRange:\n            col_name = (self.outputCol + '%s_%s' % (ar,self.shift))\n            \n            w = Window.partitionBy(self.idCol).orderBy(self.dateCol).rowsBetween(-ar-self.shift, -1-self.shift) # exclude itself\n            \n            df = df.withColumn(col_name, f.avg(self.inputCol).over(w))\n            \n        return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature extraction\ndom = DomExtractor(inputCol='date')\ndoy = DoyExtractor(inputCol='date')\ndow = DowDayExtractor(inputCol='date')\nmon = MonthExtractor(inputCol='date')\n#year = YearExtractor(inputCol='date')\nyq = YearQuarterExtractor()\n\nwked = WeekendExtractor()\nmbe = MonthBeginExtractor()\nmed = MonthEndExtractor()\n\nlogt = logTransform(inputCol ='sales', outputCol='logSales')\nlagex = LagExtractor(inputCol = 'logSales', lags = [91,98,105,112,119,126,182,364,546,728])\nmeanex = RmeanExtractor(inputCol = 'logSales', avgRange=[364,546])\n\nencoder = OneHotEncoder(inputCols=[\"store\",\"item\",\"dayofmonth\", \"dayofweek\",\"month\",\"yearquarter\"],\n                        outputCols=[\"storeVec\",\"itemVec\",\"dayofmonthVec\", \"dayofweekVec\",\"monthVec\",\"yearquarterVec\"])\n\npipeline = Pipeline(stages=[ dom, doy, dow, mon, yq, wked, mbe, med, logt, lagex, meanex, encoder])\n\nprocessing = pipeline.fit(df)\ntransformed = processing.transform(df)\ntransformed.printSchema()\n\nassembler = VectorAssembler(inputCols=[\"dayofweekVec\",\"monthVec\",\"storeVec\",\"itemVec\",\"dayofmonthVec\",\"yearquarterVec\",\n                                       \"is_weekend\",\"monthbegin\",\"monthend\",\n                                       \"lag91\",\"lag98\",\"lag105\",\"lag112\",\"lag119\",\"lag126\",\n                                       \"lag182\",\"lag364\",\"lag546\",\"lag728\",\n                                       \"rmean364_90\",\"rmean546_90\"], \n                            outputCol=\"features\")\n\n\ntransformed_train = assembler.transform(transformed.filter(  (f.col('lag728').isNotNull()) & (f.col('type') == 'train')    ))\ntransformed_test = assembler.transform(transformed.filter(f.col('type') == 'test'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model fitting\n#rf = regression.RandomForestRegressor(numTrees = 100, maxDepth=6, featuresCol='features', labelCol='logSales')\ngb = regression.GBTRegressor(maxDepth=5, seed=42, featuresCol='features', labelCol='logSales')\nmodel = gb.fit(transformed_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_train = model.transform(transformed_train)\npred_train = pred_train.select('sales',f.expm1('prediction').alias('pred'))\n\nevaluator = RegressionEvaluator(predictionCol='pred', labelCol='sales', metricName='rmse')\nprint(evaluator.evaluate(pred_train))\n\nevaluator = RegressionEvaluator(predictionCol='pred', labelCol='sales', metricName='mae')\nprint(evaluator.evaluate(pred_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make predictions\npred_test = model.transform(transformed_test)\npred_test = pred_test.select('*',f.expm1('prediction').alias('pred'))\nsub_df = pred_test.select('id',f.col('pred').alias('sales')).orderBy('id').toPandas()\nsub_df.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}