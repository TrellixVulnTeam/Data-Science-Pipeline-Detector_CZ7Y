{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\ntrain = pd.read_csv('/kaggle/input/demand-forecasting-kernels-only/train.csv', parse_dates=['date'], infer_datetime_format=True)\ntest = pd.read_csv('/kaggle/input/demand-forecasting-kernels-only/test.csv', parse_dates=['date'], infer_datetime_format=True)\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport pandas as pd\nimport sys\nimport numpy as np # linear algebra\nimport os\nimport holidays\n\n\ndef createFeatures(df_in,offset,labelwith):\n\tus_holidays = holidays.UnitedStates()\n\tdf = df_in.copy()\n\n\tdf['dayofweek'] = df['date'].dt.dayofweek\n\tdf['quarter'] = df['date'].dt.quarter\n\tdf['month'] = df['date'].dt.month\n\tdf['year'] = df['date'].dt.year\n\tdf['dayofyear'] = df['date'].dt.dayofyear\n\tdf['dayofmonth'] = df['date'].dt.day\n\tdf['weekofyear'] = df['date'].map(lambda x: x.weekofyear)\n\n\n\tdf['holiday'] =  df['date'].map(lambda x: int(x in us_holidays))\n\n\twindow = df['sales'].rolling(window=offset)\n\tdf['mean'] = window.mean()\n\tdf['min'] = window.min()\n\tdf['max'] = window.max()\n\n\tdf = df[offset-1:]\n\n\tdf['mean'] = df['mean'].shift(periods=labelwith)\n\tdf['min'] = df['min'].shift(periods=labelwith)\n\tdf['max'] = df['max'].shift(periods=labelwith)\n\n\tdf = df[labelwith:]\n\n\n\treturn df\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef perform(train,test,datesplit):\n\tglobal previous_days_info,labelwith,featureSet\n\n\ttrain_original = train.copy()\n\n\ttrain = createFeatures(train,offset=previous_days_info,labelwith=labelwith)\n\tscaler = MinMaxScaler()\n\ttrain['sales'] = scaler.fit_transform(train['sales'].values.reshape(-1, 1))\n\n\t# Create a Random Forest object\n\trf = RandomForestRegressor()\n\n\t# Train a model\n\trf.fit(X=train[featureSet], y=train['sales'])\n\n\t# prepare test data\n\tdf = pd.concat([train_original,test],axis=0, sort=True)\n\n\ttest = createFeatures(df,offset= previous_days_info,labelwith=labelwith)\n\ttest = test[-labelwith:] # get the test dataset\n\n\t# Get predictions for the test set\n\ttest['sales'] = rf.predict(test[featureSet])\n\n\treaddata = scaler.inverse_transform([test['sales']])[0]\n\treaddata = [round(x) for x in readdata]\n\ttest['sales'] = readdata\n\n\t# return test[['date','item', 'sales']]\n\treturn test[['sales']]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport sys\nimport numpy as np # linear algebra\nimport os\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import MinMaxScaler\nimport os\n\nlabelwith = 90\nprevious_days_info = 90\nfeatureSet = ['dayofweek','quarter','month','year','dayofyear','dayofmonth','weekofyear','min','max','mean','holiday']\n\n\nus_holidays = holidays.UnitedStates()\n\n\nstoreids = train['store'].unique()\nitemids = train['item'].unique()\n\n\nans = pd.DataFrame()\n\nfor item in itemids:\n    iteminfo = train.loc[train['item']==item]\n    storeids = iteminfo['store'].unique()\n    for sid in storeids:\n        one_train = iteminfo[iteminfo['store'] == sid]\n        one_test = test[(test['store'] == sid) & (test['item'] == item)]\n        # titems = titems.drop(\"id\",axis=1)\n        if len(one_test) == 0:\n            continue\n\n        rlt = perform(one_train,one_test,'2018-01-01')\n        ans = pd.concat([ans,rlt],axis=0, sort=True) \n\nans.to_csv('submission.csv',index_label='id')\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}