{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Demand Forecasting with using Big Data","metadata":{}},{"cell_type":"markdown","source":"## Content\n1. [Introduction](#section-intro)\n2. [Importing libraries and Kaggle setup](#section-ts)\n3. [Load Dataset](#section-pro)\n4. [Basic Exploratory Data Analysis](#section-ten)\n5. [Feature Engineering](#section-ten)\n6. [Data Encoding](#section-ten)\n7. [LightGB Model](#section-ten)\n8. [Time Series Analysis](#section-ten)   ","metadata":{}},{"cell_type":"markdown","source":"## 1. Introduction","metadata":{}},{"cell_type":"markdown","source":"#### Dataset Overview\n* A store chain's 5-year data includes information on 10 different stores and 50 different products.\n* The data set covers the period between 01-01-2013 and 31-12-2017.","metadata":{}},{"cell_type":"markdown","source":"#### Business Problem\n* It is desired to create a 3-month demand forecasting model for 10 different stores and 50 different products of a chain of stores.\n* Afterwards, it is desired to reduce the data set to weekly and create a demand forecasting model for 2017.","metadata":{}},{"cell_type":"markdown","source":"#### Variables\n* date – Date of sales data (No holiday effects or store closures)\n* store - Store ID Unique number for each store.\n* item - Item ID Unique number for each item.\n* sales – Number of items sold, Number of items sold from a particular store on a given date","metadata":{}},{"cell_type":"markdown","source":"## 2. Importing Libraries and Kaggle Setup","metadata":{}},{"cell_type":"code","source":"# Importing Libraries\n\nimport numpy as np \nimport pandas as pd \nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport lightgbm as lgb\nfrom statsmodels.tsa.holtwinters import SimpleExpSmoothing\nfrom sklearn.metrics import mean_absolute_error\nfrom statsmodels.tsa.holtwinters import ExponentialSmoothing\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nimport statsmodels.api as sm\nimport itertools\n\nimport warnings\npd.set_option('display.max_columns', None)\npd.set_option('display.width', 500)\nwarnings.filterwarnings('ignore')\n\n#Kaggle setup\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","metadata":{"execution":{"iopub.status.busy":"2021-10-13T09:08:08.691432Z","iopub.execute_input":"2021-10-13T09:08:08.692028Z","iopub.status.idle":"2021-10-13T09:08:12.202119Z","shell.execute_reply.started":"2021-10-13T09:08:08.691991Z","shell.execute_reply":"2021-10-13T09:08:12.200988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Load Dataset","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/demand-forecasting-kernels-only/train.csv', parse_dates=['date'])\ntest = pd.read_csv('../input/demand-forecasting-kernels-only/test.csv', parse_dates=['date'])\ndf = pd.concat([train, test], sort=False)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-13T10:11:37.689712Z","iopub.execute_input":"2021-10-13T10:11:37.690115Z","iopub.status.idle":"2021-10-13T10:11:38.338227Z","shell.execute_reply.started":"2021-10-13T10:11:37.690082Z","shell.execute_reply":"2021-10-13T10:11:38.337112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Size of train set\",train.shape)\nprint(\"Size of test set:\",test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-13T10:11:42.222951Z","iopub.execute_input":"2021-10-13T10:11:42.223367Z","iopub.status.idle":"2021-10-13T10:11:42.230735Z","shell.execute_reply.started":"2021-10-13T10:11:42.223333Z","shell.execute_reply":"2021-10-13T10:11:42.229276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Removing the extra column 'id'\ndf.drop(['id'],inplace=True,axis=1)\ndf.columns","metadata":{"execution":{"iopub.status.busy":"2021-10-13T10:11:47.970935Z","iopub.execute_input":"2021-10-13T10:11:47.971321Z","iopub.status.idle":"2021-10-13T10:11:48.015906Z","shell.execute_reply.started":"2021-10-13T10:11:47.971289Z","shell.execute_reply":"2021-10-13T10:11:48.014676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Basic Exploratory data Analysis","metadata":{}},{"cell_type":"code","source":"#DATE RANGE\n\nprint(\"Date range:\", df[\"date\"].min(), \"to\", df[\"date\"].max())\n#1st Jan 2013 to 31st March, 2018","metadata":{"execution":{"iopub.status.busy":"2021-10-13T10:11:52.848438Z","iopub.execute_input":"2021-10-13T10:11:52.848835Z","iopub.status.idle":"2021-10-13T10:11:52.863267Z","shell.execute_reply.started":"2021-10-13T10:11:52.848797Z","shell.execute_reply":"2021-10-13T10:11:52.861951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SALES DISTRIBUTION\n\ndf[\"sales\"].describe([0.10, 0.30, 0.50, 0.70, 0.80, 0.90, 0.95, 0.99])","metadata":{"execution":{"iopub.status.busy":"2021-10-13T10:11:54.908537Z","iopub.execute_input":"2021-10-13T10:11:54.908977Z","iopub.status.idle":"2021-10-13T10:11:54.965537Z","shell.execute_reply.started":"2021-10-13T10:11:54.908942Z","shell.execute_reply":"2021-10-13T10:11:54.964249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NUMBER OF STORES\n\ndf[\"store\"].nunique()","metadata":{"execution":{"iopub.status.busy":"2021-10-13T10:12:00.378694Z","iopub.execute_input":"2021-10-13T10:12:00.379468Z","iopub.status.idle":"2021-10-13T10:12:00.4081Z","shell.execute_reply.started":"2021-10-13T10:12:00.379427Z","shell.execute_reply":"2021-10-13T10:12:00.406944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NUMBER OF PRODUCTS\n\ndf[\"item\"].nunique() ","metadata":{"execution":{"iopub.status.busy":"2021-10-13T10:12:04.765631Z","iopub.execute_input":"2021-10-13T10:12:04.766051Z","iopub.status.idle":"2021-10-13T10:12:04.787345Z","shell.execute_reply.started":"2021-10-13T10:12:04.766016Z","shell.execute_reply":"2021-10-13T10:12:04.786204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NUMBER OF PRODUCTS IN EACH STORE\ndf.groupby([\"store\"])[\"item\"].nunique()\n#Every store sells all the 50 products","metadata":{"execution":{"iopub.status.busy":"2021-10-13T10:12:41.109295Z","iopub.execute_input":"2021-10-13T10:12:41.109718Z","iopub.status.idle":"2021-10-13T10:12:41.201047Z","shell.execute_reply.started":"2021-10-13T10:12:41.109684Z","shell.execute_reply":"2021-10-13T10:12:41.19987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sales statistics in store-product breakdown\ndf.groupby([\"store\", \"item\"]).agg({\"sales\": [\"sum\", \"mean\", \"median\", \"std\"]})","metadata":{"execution":{"iopub.status.busy":"2021-10-13T10:12:47.956736Z","iopub.execute_input":"2021-10-13T10:12:47.957173Z","iopub.status.idle":"2021-10-13T10:12:48.181094Z","shell.execute_reply.started":"2021-10-13T10:12:47.957139Z","shell.execute_reply":"2021-10-13T10:12:48.179998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Feature Engineering","metadata":{}},{"cell_type":"code","source":"# Generating date and time parameters from given date\n\ndf['month'] = df.date.dt.month\ndf['day_of_month'] = df.date.dt.day\ndf['day_of_year'] = df.date.dt.dayofyear \ndf['week_of_year'] = df.date.dt.weekofyear\ndf['day_of_week'] = df.date.dt.dayofweek\ndf['year'] = df.date.dt.year\ndf[\"is_wknd\"] = df.date.dt.weekday // 4\ndf['is_month_start'] = df.date.dt.is_month_start.astype(int)\ndf['is_month_end'] = df.date.dt.is_month_end.astype(int) ","metadata":{"execution":{"iopub.status.busy":"2021-10-13T10:12:52.836945Z","iopub.execute_input":"2021-10-13T10:12:52.837332Z","iopub.status.idle":"2021-10-13T10:12:53.724159Z","shell.execute_reply.started":"2021-10-13T10:12:52.837301Z","shell.execute_reply":"2021-10-13T10:12:53.722987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-13T09:39:45.097858Z","iopub.execute_input":"2021-10-13T09:39:45.098274Z","iopub.status.idle":"2021-10-13T09:39:45.117647Z","shell.execute_reply.started":"2021-10-13T09:39:45.098243Z","shell.execute_reply":"2021-10-13T09:39:45.116323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sales statistics in store-item-month breakdown\ndf.groupby([\"store\", \"item\", \"month\"]).agg({\"sales\": [\"sum\", \"mean\", \"median\", \"std\"]})","metadata":{"execution":{"iopub.status.busy":"2021-10-13T10:12:59.8636Z","iopub.execute_input":"2021-10-13T10:12:59.863977Z","iopub.status.idle":"2021-10-13T10:13:00.031869Z","shell.execute_reply.started":"2021-10-13T10:12:59.863944Z","shell.execute_reply":"2021-10-13T10:13:00.030933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#DEALING WITH RAMDOM NOISE\n# For small datasets like this dataset, random noise can be added to the values ​​to prevent overfitting.\n# Here I will add Gaussian random noise, which is normally distributed with 1 standard deviation and 0 mean.\n\ndef random_noise(dataframe):\n    return np.random.normal(scale=1.6, size=(len(dataframe),))","metadata":{"execution":{"iopub.status.busy":"2021-10-13T10:13:04.68114Z","iopub.execute_input":"2021-10-13T10:13:04.681523Z","iopub.status.idle":"2021-10-13T10:13:04.686293Z","shell.execute_reply.started":"2021-10-13T10:13:04.68149Z","shell.execute_reply":"2021-10-13T10:13:04.685364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Lag/Shifted Features (Delays)\ndf.sort_values(by=['store', 'item', 'date'], axis=0, inplace=True)\ndf.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-10-13T10:13:08.54693Z","iopub.execute_input":"2021-10-13T10:13:08.547289Z","iopub.status.idle":"2021-10-13T10:13:08.962696Z","shell.execute_reply.started":"2021-10-13T10:13:08.547258Z","shell.execute_reply":"2021-10-13T10:13:08.961776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def lag_features(dataframe, lags):\n    for lag in lags:\n        dataframe['sales_lag_' + str(lag)] = dataframe.groupby([\"store\", \"item\"])['sales'].transform(\n            lambda x: x.shift(lag)) + random_noise(dataframe)\n    return dataframe\n\ndf = lag_features(df, [91, 98, 105, 112, 119, 126, 182, 364, 546, 728])","metadata":{"execution":{"iopub.status.busy":"2021-10-13T10:13:13.592574Z","iopub.execute_input":"2021-10-13T10:13:13.592948Z","iopub.status.idle":"2021-10-13T10:13:16.259351Z","shell.execute_reply.started":"2021-10-13T10:13:13.592916Z","shell.execute_reply":"2021-10-13T10:13:16.258391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Moving Average Features\ndef moving_average_features(dataframe, windows):\n    for window in windows:\n        dataframe['sales_roll_mean_' + str(window)] = dataframe.groupby([\"store\", \"item\"])['sales']. \\\n                                                          transform(\n            lambda x: x.shift(1).rolling(window=window, min_periods=10, win_type=\"triang\").mean()) + random_noise(\n            dataframe)\n    return dataframe\n\n\ndf = moving_average_features(df, [365, 546, 730])\n","metadata":{"execution":{"iopub.status.busy":"2021-10-13T10:13:20.993059Z","iopub.execute_input":"2021-10-13T10:13:20.993408Z","iopub.status.idle":"2021-10-13T10:13:25.135373Z","shell.execute_reply.started":"2021-10-13T10:13:20.993377Z","shell.execute_reply":"2021-10-13T10:13:25.134418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Exponentially Weighted Average Features\ndef ewm_features(dataframe, alphas, lags):\n    for alpha in alphas:\n        for lag in lags:\n            dataframe['sales_ewm_alpha_' + str(alpha).replace(\".\", \"\") + \"_lag_\" + str(lag)] = \\\n                dataframe.groupby([\"store\", \"item\"])['sales'].transform(lambda x: x.shift(lag).ewm(alpha=alpha).mean())\n    return dataframe\n\n\nalphas = [0.99, 0.95, 0.9, 0.8, 0.7, 0.5]\nlags = [91, 98, 105, 112, 180, 270, 365, 546, 728]\n\ndf = ewm_features(df, alphas, lags)","metadata":{"execution":{"iopub.status.busy":"2021-10-13T10:13:29.866354Z","iopub.execute_input":"2021-10-13T10:13:29.866704Z","iopub.status.idle":"2021-10-13T10:13:47.574707Z","shell.execute_reply.started":"2021-10-13T10:13:29.86667Z","shell.execute_reply":"2021-10-13T10:13:47.573683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6. Data Encoding","metadata":{}},{"cell_type":"code","source":"#Checking for null values\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2021-10-13T10:14:07.019081Z","iopub.execute_input":"2021-10-13T10:14:07.019494Z","iopub.status.idle":"2021-10-13T10:14:07.37204Z","shell.execute_reply.started":"2021-10-13T10:14:07.019463Z","shell.execute_reply":"2021-10-13T10:14:07.370713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#One-Hot Encoding\ndf = pd.get_dummies(df, columns=['day_of_week', 'month'])","metadata":{"execution":{"iopub.status.busy":"2021-10-13T10:14:29.590443Z","iopub.execute_input":"2021-10-13T10:14:29.590895Z","iopub.status.idle":"2021-10-13T10:14:30.879645Z","shell.execute_reply.started":"2021-10-13T10:14:29.590844Z","shell.execute_reply":"2021-10-13T10:14:30.878227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Converting sales to log(1+sales)\ndf['sales'] = np.log1p(df[\"sales\"].values)","metadata":{"execution":{"iopub.status.busy":"2021-10-13T09:57:48.061823Z","iopub.execute_input":"2021-10-13T09:57:48.062374Z","iopub.status.idle":"2021-10-13T09:57:48.091176Z","shell.execute_reply.started":"2021-10-13T09:57:48.062339Z","shell.execute_reply":"2021-10-13T09:57:48.090324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7. LightGBM Model","metadata":{}},{"cell_type":"code","source":"# Train data set until the beginning of 2017 (end of 2016)\ntrain = df.loc[(df[\"date\"] < \"2017-01-01\"), :]\n\n# First 3 months of 2017 validation set\nval = df.loc[(df[\"date\"] >= \"2017-01-01\") & (df[\"date\"] < \"2017-04-01\"), :]\n\n# Independent variables\ncols = [col for col in train.columns if col not in ['date', 'id', \"sales\", \"year\"]]","metadata":{"execution":{"iopub.status.busy":"2021-10-13T10:22:49.084877Z","iopub.execute_input":"2021-10-13T10:22:49.085222Z","iopub.status.idle":"2021-10-13T10:22:49.419812Z","shell.execute_reply.started":"2021-10-13T10:22:49.08519Z","shell.execute_reply":"2021-10-13T10:22:49.418803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Selecting the dependent variable for the train set\nY_train = train['sales']\n\n# Selecting the argument for the train set\nX_train = train[cols]\n\n# choosing the dependent variable for the validation set\nY_val = val['sales']\n\n# selecting the independent variable for the validation set\nX_val = val[cols] \n\n# Checking the shapes\nY_train.shape, X_train.shape, Y_val.shape, X_val.shape","metadata":{"execution":{"iopub.status.busy":"2021-10-13T10:22:54.282152Z","iopub.execute_input":"2021-10-13T10:22:54.28256Z","iopub.status.idle":"2021-10-13T10:22:54.456808Z","shell.execute_reply.started":"2021-10-13T10:22:54.282525Z","shell.execute_reply":"2021-10-13T10:22:54.45564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Custom Cost Function\n\ndef smape(preds, target):\n    n = len(preds)\n    masked_arr = ~((preds == 0) & (target == 0))\n    preds, target = preds[masked_arr], target[masked_arr]\n    num = np.abs(preds - target)\n    denom = np.abs(preds) + np.abs(target)\n    smape_val = (200 * np.sum(num / denom)) / n\n    return smape_val\n\n\ndef lgbm_smape(preds, train_data):\n    labels = train_data.get_label()\n    smape_val = smape(np.expm1(preds), np.expm1(labels))\n    return 'SMAPE', smape_val, False\n","metadata":{"execution":{"iopub.status.busy":"2021-10-13T10:23:24.703925Z","iopub.execute_input":"2021-10-13T10:23:24.704298Z","iopub.status.idle":"2021-10-13T10:23:24.71227Z","shell.execute_reply.started":"2021-10-13T10:23:24.704266Z","shell.execute_reply":"2021-10-13T10:23:24.710775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LightGBM parameters\nlgb_params = {'metric': {'mae'},\n              'num_leaves': 10,\n              'learning_rate': 0.02,\n              'feature_fraction': 0.8,\n              'max_depth': 5,\n              'verbose': 0,\n              'num_boost_round': 10000, \n              'early_stopping_rounds': 200,\n              'nthread': -1}","metadata":{"execution":{"iopub.status.busy":"2021-10-13T10:23:32.74441Z","iopub.execute_input":"2021-10-13T10:23:32.744755Z","iopub.status.idle":"2021-10-13T10:23:32.750824Z","shell.execute_reply.started":"2021-10-13T10:23:32.744726Z","shell.execute_reply":"2021-10-13T10:23:32.749459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgbtrain = lgb.Dataset(data=X_train, label=Y_train, feature_name=cols)\nlgbval = lgb.Dataset(data=X_val, label=Y_val, reference=lgbtrain, feature_name=cols)\n\nmodel = lgb.train(lgb_params, lgbtrain,\n                  valid_sets=[lgbtrain, lgbval],\n                  num_boost_round=lgb_params['num_boost_round'],\n                  early_stopping_rounds=lgb_params['early_stopping_rounds'],\n                  feval=lgbm_smape, \n                  verbose_eval=100)\n\ny_pred_val = model.predict(X_val, num_iteration=model.best_iteration)\n\n# percentage of validation error\nsmape(np.expm1(y_pred_val), np.expm1(Y_val))","metadata":{"execution":{"iopub.status.busy":"2021-10-13T10:24:06.007731Z","iopub.execute_input":"2021-10-13T10:24:06.008209Z","iopub.status.idle":"2021-10-13T10:24:44.142268Z","shell.execute_reply.started":"2021-10-13T10:24:06.00817Z","shell.execute_reply":"2021-10-13T10:24:44.140942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Final Model","metadata":{}},{"cell_type":"code","source":"# determination of test and train dependent/independent variables\n\ntrain = df.loc[~df.sales.isna()]\nY_train = train['sales']\nX_train = train[cols]\n\ntest = df.loc[df.sales.isna()]\nX_test = test[cols]","metadata":{"execution":{"iopub.status.busy":"2021-10-13T10:27:05.003123Z","iopub.execute_input":"2021-10-13T10:27:05.003576Z","iopub.status.idle":"2021-10-13T10:27:05.660787Z","shell.execute_reply.started":"2021-10-13T10:27:05.003541Z","shell.execute_reply":"2021-10-13T10:27:05.659796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgb_params = {'metric': {'mae'},\n              'num_leaves': 10,\n              'learning_rate': 0.02,\n              'feature_fraction': 0.8,\n              'max_depth': 5,\n              'verbose': 0,\n              'nthread': -1,\n              \"num_boost_round\": model.best_iteration}\n\n# LightGBM dataset\nlgbtrain_all = lgb.Dataset(data=X_train, label=Y_train, feature_name=cols)\n\nmodel = lgb.train(lgb_params, lgbtrain_all, num_boost_round=model.best_iteration)\ntest_preds = model.predict(X_test, num_iteration=model.best_iteration)","metadata":{"execution":{"iopub.status.busy":"2021-10-13T10:27:15.813242Z","iopub.execute_input":"2021-10-13T10:27:15.813637Z","iopub.status.idle":"2021-10-13T10:27:20.301854Z","shell.execute_reply.started":"2021-10-13T10:27:15.813605Z","shell.execute_reply":"2021-10-13T10:27:20.30102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 8. Time Series Analysis\n\n* In this section, first of all, the train data set will be reduced to a weekly basis.\n* Then, using the weekly data set, respectively:\n* LightGBM Model\n* Single Exponential Smoothing\n* Double Exponential Smoothing\n* Triple Exponential Smoothing\n* ARIMA\n* Sales demand forecasting models for 2017 will be created with SARIMA.\n* Actual values ​​will be compared with estimated values.\n","metadata":{}},{"cell_type":"markdown","source":"### Load Dataset and EDA","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('../input/demand-forecasting-kernels-only/train.csv', parse_dates=['date'])\ndata.head()\ndata.shape\n\n# reduce dataset to weekly\ndata.set_index(\"date\",inplace=True)\ndf= data.resample(\"W\").mean()\ndf.reset_index(inplace=True)\ndf.head()\ndf.shape\n\ndf.index.freq = \"W\"\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-13T10:36:25.958153Z","iopub.execute_input":"2021-10-13T10:36:25.958609Z","iopub.status.idle":"2021-10-13T10:36:26.760903Z","shell.execute_reply.started":"2021-10-13T10:36:25.958569Z","shell.execute_reply":"2021-10-13T10:36:26.759914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2021-10-13T10:36:41.739269Z","iopub.execute_input":"2021-10-13T10:36:41.739634Z","iopub.status.idle":"2021-10-13T10:36:41.745835Z","shell.execute_reply.started":"2021-10-13T10:36:41.739602Z","shell.execute_reply":"2021-10-13T10:36:41.744919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature Engineering","metadata":{}},{"cell_type":"code","source":"# Month\ndf['month'] = df.date.dt.month\n# Day of Month\ndf['day_of_month'] = df.date.dt.day\n# Day of year\ndf['day_of_year'] = df.date.dt.dayofyear\n# Week of year\ndf['week_of_year'] = df.date.dt.weekofyear\n# Day of week\ndf['day_of_week'] = df.date.dt.dayofweek\n# Year\ndf['year'] = df.date.dt.year\n# Weekend check\ndf[\"is_wknd\"] = df.date.dt.weekday // 4\n# Month start check\ndf['is_month_start'] = df.date.dt.is_month_start.astype(int)\n# Month end check\ndf['is_month_end'] = df.date.dt.is_month_end.astype(int)\n\n# Lag/Shifted Features (Delays)\ndef lag_features(dataframe, lags):\n    for lag in lags:\n        dataframe['sales_lag_' + str(lag)] = dataframe['sales'].transform(\n            lambda x: x.shift(lag)) + random_noise(dataframe)\n    return dataframe\n\ndf = lag_features(df, [31, 61, 91, 98, 105, 112])\n\n\n# Moving Average Features\ndef roll_mean_features(dataframe, windows):\n    for window in windows:\n        dataframe['sales_roll_mean_' + str(window)] = dataframe['sales']. \\\n                                                          transform(\n            lambda x: x.shift(1).rolling(window=window, min_periods=10, win_type=\"triang\").mean()) + random_noise(\n            dataframe)\n    return dataframe\n\n\ndf = roll_mean_features(df, [31, 61, 91, 98, 105, 112])\n\n\n# Exponentially Weighted Mean Features\ndef ewm_features(dataframe, alphas, lags):\n    for alpha in alphas:\n        for lag in lags:\n            dataframe['sales_ewm_alpha_' + str(alpha).replace(\".\", \"\") + \"_lag_\" + str(lag)] = \\\n                dataframe['sales'].transform(lambda x: x.shift(lag).ewm(alpha=alpha).mean())\n    return dataframe\n\n\nalphas = [0.99, 0.95, 0.9, 0.8, 0.7, 0.5]\nlags = [10, 20, 30, 40, 50]\n\ndf = ewm_features(df, alphas, lags)\n\ndf.tail()\n","metadata":{"execution":{"iopub.status.busy":"2021-10-13T10:39:52.002022Z","iopub.execute_input":"2021-10-13T10:39:52.002403Z","iopub.status.idle":"2021-10-13T10:39:52.124226Z","shell.execute_reply.started":"2021-10-13T10:39:52.002364Z","shell.execute_reply":"2021-10-13T10:39:52.123178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### LightGBM Model","metadata":{}},{"cell_type":"code","source":"# One-Hot Encoding\ndf = pd.get_dummies(df, columns=['day_of_week', 'month'])\n\n# Converting sales to log(1+sales)\ndf['sales'] = np.log1p(df[\"sales\"].values)\n\n# train-test data selection\ntrain = df.loc[(df[\"date\"] < \"2017-01-01\"), :]\ntest = df.loc[(df[\"date\"] >= \"2017-01-01\"), :]\n\n# Dependent and Independent variables\ncols = [col for col in train.columns if col not in ['date', \"sales\", \"year\"]]\nX_train = train[cols]\nY_train = train['sales']\nX_test = test[cols]\nY_test = test[\"sales\"]\n","metadata":{"execution":{"iopub.status.busy":"2021-10-13T10:42:36.674335Z","iopub.execute_input":"2021-10-13T10:42:36.674729Z","iopub.status.idle":"2021-10-13T10:42:36.700943Z","shell.execute_reply.started":"2021-10-13T10:42:36.674697Z","shell.execute_reply":"2021-10-13T10:42:36.699592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LightGBM parameters\nlgb_params = {'metric': {'mae'},\n              'num_leaves': 10,\n              'learning_rate': 0.02,\n              'feature_fraction': 0.8,\n              'max_depth': 5,\n              'verbose': 0,\n              'num_boost_round': 10000, \n              'early_stopping_rounds': 200, \n              'nthread': -1}\n\nlgbtrain = lgb.Dataset(data=X_train, label=Y_train, feature_name=cols)\nlgbval = lgb.Dataset(data=X_test, label=Y_test, reference=lgbtrain, feature_name=cols)\n\nmodel = lgb.train(lgb_params, lgbtrain,\n                  valid_sets=[lgbtrain, lgbval],\n                  num_boost_round=lgb_params['num_boost_round'],\n                  early_stopping_rounds=lgb_params['early_stopping_rounds'],\n                  feval=lgbm_smape, \n                  verbose_eval=100)\n\ny_pred_test = model.predict(X_test, num_iteration=model.best_iteration)\n\n# percentage of test error\nsmape(np.expm1(y_pred_test), np.expm1(Y_test))\n","metadata":{"execution":{"iopub.status.busy":"2021-10-13T10:42:53.077557Z","iopub.execute_input":"2021-10-13T10:42:53.078159Z","iopub.status.idle":"2021-10-13T10:42:54.666324Z","shell.execute_reply.started":"2021-10-13T10:42:53.07812Z","shell.execute_reply":"2021-10-13T10:42:54.665034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature Importance","metadata":{}},{"cell_type":"code","source":"def plot_lgb_importances(model, plot=False, num=10):\n\n    gain = model.feature_importance('gain')\n    feat_imp = pd.DataFrame({'feature': model.feature_name(),\n                             'split': model.feature_importance('split'),\n                             'gain': 100 * gain / gain.sum()}).sort_values('gain', ascending=False)\n    if plot:\n        plt.figure(figsize=(10, 10))\n        sns.set(font_scale=1)\n        sns.barplot(x=\"gain\", y=\"feature\", data=feat_imp[0:25])\n        plt.title('feature')\n        plt.tight_layout()\n        plt.show()\n    else:\n        print(feat_imp.head(num))\n\n\nplot_lgb_importances(model, num=30)\n#plot_lgb_importances(model, num=30, plot=True)\n\nlgb.plot_importance(model, max_num_features=20, figsize=(10, 10), importance_type=\"gain\")\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-10-13T11:04:10.996003Z","iopub.execute_input":"2021-10-13T11:04:10.996384Z","iopub.status.idle":"2021-10-13T11:04:11.642389Z","shell.execute_reply.started":"2021-10-13T11:04:10.996351Z","shell.execute_reply":"2021-10-13T11:04:11.641136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Final Model\n\nlgb_params = {'metric': {'mae'},\n              'num_leaves': 10,\n              'learning_rate': 0.02,\n              'feature_fraction': 0.8,\n              'max_depth': 5,\n              'verbose': 0,\n              'nthread': -1,\n              \"num_boost_round\": model.best_iteration}\n\n# LightGBM dataset\nlgbtrain_all = lgb.Dataset(data=X_train, label=Y_train, feature_name=cols)\n\nmodel = lgb.train(lgb_params, lgbtrain_all, num_boost_round=model.best_iteration)\ntest_preds = model.predict(X_test, num_iteration=model.best_iteration)\n","metadata":{"execution":{"iopub.status.busy":"2021-10-13T10:45:28.691673Z","iopub.execute_input":"2021-10-13T10:45:28.692087Z","iopub.status.idle":"2021-10-13T10:45:29.517705Z","shell.execute_reply.started":"2021-10-13T10:45:28.692054Z","shell.execute_reply":"2021-10-13T10:45:29.516814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Here is the prediction!","metadata":{}},{"cell_type":"code","source":"# 1 year actual and predicted values\nforecast = pd.DataFrame({\"date\":test[\"date\"],\n                        \"store\":test[\"store\"],\n                        \"item\":test[\"item\"],\n                        \"sales\":test_preds\n                        })\n\ndf.set_index(\"date\").sales.plot(figsize = (20,9),legend=True, label = \"Actual\")\nforecast.set_index(\"date\").sales.plot(legend=True, label = \"Predict\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-13T10:46:00.090759Z","iopub.execute_input":"2021-10-13T10:46:00.091612Z","iopub.status.idle":"2021-10-13T10:46:00.483857Z","shell.execute_reply.started":"2021-10-13T10:46:00.091568Z","shell.execute_reply":"2021-10-13T10:46:00.482478Z"},"trusted":true},"execution_count":null,"outputs":[]}]}