{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Understanding Data\n\nYou are given 5 years of store-item sales data, and asked to predict 3 months of sales for 50 different items at 10 different stores.\n\nData fields\n\n* date - Date of the sale data. There are no holiday effects or store closures.\n* store - Store ID\n* item - Item ID\n* sales - Number of items sold at a particular store on a particular date.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# import libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import make_scorer\nfrom sklearn.model_selection import cross_val_score, GridSearchCV\nimport datetime as dt\n\nplt.rcParams[\"figure.figsize\"] = (15,5)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/demand-forecasting-kernels-only/train.csv',parse_dates =['date'],index_col=['date'])\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Base model\n\nWe have chosen Decision Tree Regressor as our base model. SMAPE (symmetric mean absolute percentage error) is our performance metric for this project. SMAPE is less sensitive to outliers and invariant to linear scaling. It has been observed that sales has right skewed distribution, hence we are considering it's log transform as it gives more approximate standard distribution for it."},{"metadata":{"trusted":true},"cell_type":"code","source":"data['sales'].hist(bins = 20)\nmean = data['sales'].mean()\nmedian = np.median(data['sales'])\nminimum = data.sales.min()\nmaximum = data.sales.max()\n\nmean,median,minimum,maximum","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logged = np.log1p(data['sales'])\nlogged.hist(bins = 20)\nlogged.mean(),logged.median()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def smape(actual,predict,islog=True):\n    if islog == True:\n        actual = np.exp(actual) - 1\n        predict = np.exp(predict) -1\n        \n    return 100*np.mean(2*np.abs(actual-predict)/(np.abs(actual)+np.abs(predict)))\n    \nsmape_score = make_scorer(smape,greater_is_better=False)\n\ndef evaluate_model(df,features):\n    all_X = df[features]\n    all_y = np.log1p(df['sales'])\n    \n    tree = DecisionTreeRegressor(random_state = 1)\n    scores = cross_val_score(tree,all_X,all_y,scoring=smape_score,cv=5)\n    avg_score = -(scores.mean())  # avoid negative sign which caused due to make_scorer\n    \n    return avg_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 1: EDA with available Features\n\nOur EDA shows that sales vary with store and item. Hence these features can play important role in predictions.In this step we will train our base model with available features and evaluate the performance."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = data.groupby(['date','item'])['sales'].sum().unstack()\ndf.plot(figsize=(15,10))\nplt.ylabel('Total sale')\nplt.title('itemwise sale')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = data.groupby(['date','store'])['sales'].sum().unstack()\ndf.plot(figsize=(15,10))\nplt.ylabel('sales')\nplt.title('Total sale store wise')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = list(data.columns)\nfeatures.remove('sales')\nprint('SMAPE with available features: {:.4f}'.format(evaluate_model(data,features)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cross validation SMAPE score for this step is 47.66"},{"metadata":{},"cell_type":"markdown","source":"## Step 2: EDA and Basic Feature Engineering\n\nIn this step we will extract common features like month, year, day, week etc. from date column and analyse sales variation over the period w.r.t. these features. "},{"metadata":{"trusted":true},"cell_type":"code","source":"data['month'] = data.index.month\ndata['year'] = data.index.year\ndata['dow'] = data.index.dayofweek\ndata['day'] = data.index.day\ndata['quarter'] = data.index.quarter\ndata['week'] = data.index.week\n\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x='month',y='sales',hue = 'year', data=data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x='week',y='sales',hue ='year', data=data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x='dow',y='sales',hue ='year', data=data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x='day',y='sales',hue ='year', data=data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x='quarter',y='sales',hue ='year', data=data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observations:\n1. Overall sale seems to be increasing with the year\n2. Overall sale is high \n - during may,june,july in a year\n - during weekend in a week \n - Mostly in a 3rd quarter\n3. sales vary slightly w.r.t to day of month\n "},{"metadata":{"trusted":true},"cell_type":"code","source":"features = list(data.columns)\nfeatures.remove('sales')\nprint('SMAPE with Basic feature engineering: {:.4f}'.format(evaluate_model(data,features)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With basic feature engineering we have lowered cross validation SMAPE score by 2."},{"metadata":{},"cell_type":"markdown","source":"## Step 3: EDA and Advance Feature Engineering\n\nSometime even with the available features tree based models fails to extract interaction between them and result in large number of splits and more complex model. In this context we would develope some features which extract features interaction and ease the job for decision tree to make more accurate prediction. \n\nWe would develop feature for following interactions\n\n1. **store and item: **\n   sales could differ for particular item in different locations. It means that, though a item could be very popular but sales could be less if store located far away from residential area. Reverse is true for store. i.e. store could be at main location but if item is not so popular the sale could be low\n\n2. **week and dow: **\n   combination of these two features may give sense of order to decision tree regressor\n   \n3. **year and month: ** same as above"},{"metadata":{"trusted":true},"cell_type":"code","source":"store_item_df = pd.pivot_table(data, index='item', values='sales', columns='store',margins=True, aggfunc=np.mean)\nstore_item_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(store_item_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2) = plt.subplots(1,2, figsize = (15,5))\nstore_item_df['All'].sort_values().plot.bar(ax=ax1, title ='itemwise average sale' )\nstore_item_df.loc['All',:].sort_values().plot.bar(ax=ax2, title = 'storewise average sale')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i = store_item_df['All'].sort_values().index\nc = store_item_df.loc['All',:].sort_values().index\nstore_item_df = store_item_df[c]\nstore_item_df = store_item_df.reindex(i)\n\nstore_item_df.drop('All',axis=1,inplace=True)\nstore_item_df.drop('All',axis=0,inplace = True)\n\nstore_item_df.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nsns.heatmap(store_item_df, square=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above heatmap we can see that store item are very well organized w.r.t their sales. Each block in heatmap shows the average sales for particular item in particular store. Row number defines that particular item and column number defines that particular store.Lowest value for avg sale is situated in topleft corner and highest value is at bottom right corner. And average sales seems to be increasing along the column and then along the row. if we encode store item combination accordingly it would grately helps our regressor for making prediction."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prepare dataframe to encode store item interaction\nencode_df = pd.DataFrame(np.arange(1,501,1).reshape((50,10)))\nencode_df.columns = store_item_df.columns\nencode_df.index = store_item_df.index\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def encode_feature(row):\n    r = row['item']\n    c = row['store']\n    return encode_df.loc[r,c]\n\ndata['store_item'] = data.apply(encode_feature,axis=1)\n\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = list(data.columns)\nfeatures.remove('sales')\n\nprint('SMAPE with feature engineering step 3: {:.4f}'.format(evaluate_model(data,features)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For other two interactions we will contenate year with month as its fraction and week with days as its fraction"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['m_yr'] = data['year'] + data['month']/100\ndata['week_frac'] = data['week'] + data['dow']/100\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_col = ['sales'] # 'year','day','month','dow','week','store','item',\n\nfeatures = list(data.columns)\nfor i in drop_col:\n    features.remove(i)\n    \nevaluate_model(data,features)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have tremendously improved our base model performance by this advance feature engineering. The SMAPE is lowered by almost 60% of it's value at previous step."},{"metadata":{},"cell_type":"markdown","source":"## Hyperparameter Tuning:\nWe will apply standard grid search method to our base model to optimize its important hyperparameters. It helped us to improve the performance further."},{"metadata":{"trusted":true},"cell_type":"code","source":"h = {'criterion' : ['mse','friedman_mse'],\n                   'min_samples_leaf': [1,3,5],\n                   'min_samples_split': [2,4,6]\n                  }\n\n\ndtr = DecisionTreeRegressor(random_state=1)\ngrid = GridSearchCV(dtr, param_grid=h, scoring=smape_score, cv=5, verbose=10, n_jobs =-1)\n\nall_X = data[features]\nall_y = np.log1p(data['sales'])\ngrid.fit(all_X,all_y)\n        \npred = grid.predict(data[features])\npred = [max(0,p) for p in pred]\n\nerror = smape(all_y,pred,islog=True)\n\nprint('SMAPE on Last Step: {:.4f}'.format(error))\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Implementation of model for Final Test Set"},{"metadata":{"trusted":true},"cell_type":"code","source":"def transform_feature(df):\n    \n    # Apply basic feature engineering\n    df['month'] = df.index.month\n    df['year'] = df.index.year  \n    df['dow'] = df.index.dayofweek\n    df['day'] = df.index.day\n    df['quarter'] = df.index.quarter\n    df['week'] = df.index.week\n    \n    # Apply advance feature engineering\n    df['store_item'] = df.apply(encode_feature,axis=1)\n    df['m_yr'] = df['year']+df['month']/100\n    df['week_frac'] = df['week']+df['dow']/100\n    \n    return df\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"holdout = pd.read_csv('/kaggle/input/demand-forecasting-kernels-only/test.csv',parse_dates =['date'],index_col=['date'])\nids= holdout['id']\nholdout = transform_feature(holdout)\n\npred_h = grid.predict(holdout[features])\npred_h = np.exp(pred_h)-1\npred_h = [max(0,p) for p in pred_h]\n\nsubmission_df = {'id':ids, 'sales':pred_h}\nsubmission =pd.DataFrame(submission_df)\n\nsubmission.to_csv('submission.csv',index=False)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Test score : 14.80 **\n\n## Summary: \nWe have implemented store demand forecast which forecast sales of item at different store. We have trained model on five years of data and tested over next three months. Our test SMAPE score is 14.80. The aim of the project is to step by step improvement to our base model through basic to advance feature engineering and hyperparameter tuning. We have started with very simple decision tree regressor model with available feature which provided us SMAPE score 47.66. With feature engineering step we have reduced it to 18.63 and further hyperparameter tuning reduced it to 10.48."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}