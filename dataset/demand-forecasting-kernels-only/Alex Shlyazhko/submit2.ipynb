{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        print(filename)\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from fbprophet import Prophet\n\n#to do 365 days ago transformer\n\nglobal ITEM_ID \nITEM_ID = 1\nN_PERIODS = 91\n#STORE_ID = 1\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom IPython.core.display import display, HTML\ndisplay(HTML(\"<style>.container { width:100% !important; }</style>\"))\nfrom statsmodels.tsa.seasonal import seasonal_decompose, seasonal_mean\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom sklearn.model_selection import TimeSeriesSplit, cross_val_score\nfrom sklearn.base import TransformerMixin, BaseEstimator\nfrom sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn.linear_model import LinearRegression\nimport numpy as np\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom lightgbm import LGBMRegressor\n%matplotlib inline\nplt.rcParams['figure.figsize'] = 18,6\n\n\nclass ProphetTransformer(BaseEstimator, TransformerMixin):\n   \n    def fit(self, X, y=None):\n        pp = Prophet()\n        temp = y.to_frame().reset_index()\n        temp.columns = ['ds','y']\n        pp.fit(temp)\n        self.mdl = pp\n        return self\n    \n    def transform(self, X, y=None):\n        temp = pd.DataFrame(data = X.index)\n        temp.columns = ['ds']\n        prophet_prediction = self.mdl.predict(temp)\n        prophet_prediction.set_index('ds', inplace=True)\n        X['prophet'] = prophet_prediction['yhat']\n        return X\n\nclass RollingWindowTransformer(BaseEstimator, TransformerMixin):\n    def __init__(self,  rolling_size, function):\n        self.rolling_size = rolling_size\n        self.function  = function\n        \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X, y=None):\n        selection = [x for x in X.columns if 'shift' in x][0]\n        X.loc[:, f'roll_{self.rolling_size}_{self.function.__name__}']  = \\\n        X[selection].rolling(self.rolling_size).apply(lambda x: self.function(x))\n        #X.dropna(axis=1, how='all', inplace = True)\n        return X\n\n    \nclass YearTransformer(BaseEstimator, TransformerMixin, object):\n    def __init__(self):\n        self.periods = 365\n    \n    def __new__(cls, *args, **kwargs):\n        if not hasattr(cls, 'instance'):\n            cls.instance = super(YearTransformer, cls).__new__(cls)\n        return cls.instance\n    \n    def _fit(self, X, y=None):\n        periods = self.periods\n        ser = pd.Series(index = pd.date_range(start=pd.date_range(start = y.index[0], freq = \"D\", periods=periods)[-1],\n                                              end=pd.date_range(start = y.index[-1], freq = \"D\", periods=periods)[-1], \n                                              freq = \"D\"),\n                        data=y.values)\n        self.shifted_data = ser\n        return self\n    \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X, y=None):\n        X.loc[:, f'year_ago']  = self.shifted_data\n        #X.dropna(axis=1, how='all', inplace = True)\n        return X    \n\n\nclass ShiftTransformer(BaseEstimator, TransformerMixin, object):\n    def __init__(self, periods=90):\n        self.periods = periods\n    \n    def __new__(cls, *args, **kwargs):\n        if not hasattr(cls, 'instance'):\n            cls.instance = super(ShiftTransformer, cls).__new__(cls)\n        return cls.instance\n    \n    def _fit(self, X, y=None):\n        periods = self.periods\n        ser = pd.Series(index = pd.date_range(start=pd.date_range(start = y.index[0], freq = \"D\", periods=periods)[-1],\n                                              end=pd.date_range(start = y.index[-1], freq = \"D\", periods=periods)[-1], \n                                              freq = \"D\"),\n                        data=y.values)\n        self.shifted_data = ser\n        return self\n    \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X, y=None):\n        X.loc[:, f'shift_{self.periods}']  = self.shifted_data\n        #X.dropna(axis=1, how='all', inplace = True)\n        return X\n\nclass SeasonalTransformer(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        seasonalities = {}\n        ser = y\n        decomp_results = seasonal_decompose(ser, freq=7).seasonal\n        decomp_results = decomp_results.to_frame().reset_index()\n        decomp_results['weekday'] = decomp_results['date'].dt.weekday\n        temp = decomp_results.set_index('weekday')\n        temp.columns = ['date', 'seasonal']\n        seasonalities = temp['seasonal'].to_dict()\n        self.seasonalities = seasonalities\n        return self\n    \n    def transform(self, X, y=None):\n        X.reset_index(inplace = True)\n        X['weekday'] = X['date'].dt.weekday\n        X['seasonal_value'] = X['weekday'].map(self.seasonalities)\n        X.set_index('date', inplace = True)\n        return X\n\nclass DatesTransformer(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X, y=None):\n        X.reset_index(inplace = True)\n        X['month'] = X['date'].dt.month\n        X['week'] = X['date'].dt.week\n        X.set_index('date', inplace = True)\n        return X\n    \ntry:\n    train = pd.read_csv('/kaggle/input/demand-forecasting-kernels-only/train.csv', parse_dates=['date'])\n    test = pd.read_csv('/kaggle/input/demand-forecasting-kernels-only/test.csv', parse_dates=['date'], index_col='date')\nexcept:\n    train = pd.read_csv('train.csv', parse_dates=['date'])\n    test = pd.read_csv('test.csv', parse_dates=['date'], index_col='date')\n    \ntest['sales'] = np.nan\ndf = train.groupby(['date','item'])['sales'].sum().unstack()\nresults = []\n\n\ndef train_loop(p_est):\n    results = []\n    for ITEM_ID in range(1,51):\n        y = df[ITEM_ID]\n        X = pd.DataFrame(index = y.index)\n        tss = TimeSeriesSplit()\n        Estimator = p_est\n        scores = []\n        sh = ShiftTransformer(periods = N_PERIODS)._fit(X,y) #1.add .fit(X,y)\n        yy = YearTransformer()._fit(X,y) \n\n        for train_ix, test_ix in tss.split(X):\n            X_train, X_test = X.iloc[train_ix,:], X.iloc[test_ix,:]\n            y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n            ft = FeatureUnion([('pp', ProphetTransformer()),\n                               ('dates', DatesTransformer()),\n                               #('seas', SeasonalTransformer()),\n                               #('yearago', YearTransformer()),\n                               #('shift', ShiftTransformer()),\n                               #('rw', RollingWindowTransformer(14, np.std))\n                              ])\n            est = Estimator\n            ft.fit_transform(X_train, y_train)\n            #X_train = X_train.dropna()\n            #y_train = y_train[X_train.index]\n\n            est.fit(X_train, y_train)\n            ft.transform(X_test)           \n            scores.append(est.score(X_test, y_test))\n        results.append((ITEM_ID, np.mean(scores[2:]), np.std(scores[2:])))\n                \n        X_predict = pd.DataFrame(index = test.index.unique())\n        X_predict.index.name = 'date'\n        ft.transform(X_predict)\n        y_pred = pd.Series(est.predict(X_predict), index = X_predict.index)\n\n        gr = train.groupby(['store','date','item'])['sales'].sum().unstack('item')\n        store = gr[ITEM_ID].unstack('store')\n        storeshare_mean = store.divide(store.sum(axis=1), axis=0).mean().to_dict()\n        storeshare_std = {}\n        for i in range(1,11):\n            q = store.divide(store.sum(axis=1), axis=0)[i]\n            storeshare_std[i] = np.std(q-q.mean())\n\n        for STORE_ID in range(1,11):\n            test['sales'][(test.item==ITEM_ID)&(test.store == STORE_ID)] = y_pred * storeshare_mean[STORE_ID] #без добавления шума\n\n    test.set_index('id')['sales'].to_csv('submission.csv')\n    return results\n\np_est=LGBMRegressor()\nresults = train_loop(p_est)\nprint(p_est, pd.DataFrame(results)[1].mean(), pd.DataFrame(results)[2].mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}