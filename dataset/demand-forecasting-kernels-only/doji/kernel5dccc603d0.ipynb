{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from datetime import datetime as dt\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import GradientBoostingRegressor\n# from sklearn.grid_search import GridSearchCV\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\n#import statsmodels.tsa as sm\n\nif __name__ == '__main__':\n    df = pd.read_csv('../input/train.csv')\n    print('read train file')\n    df['date'] = df['date'].apply(lambda x:dt.strptime(str(x),\"%Y-%m-%d\"))\n    df_test = pd.read_csv('../input/test.csv')\n    df_test['date'] = df_test['date'].apply(lambda x:dt.strptime(str(x),\"%Y-%m-%d\"))\n    eval_term = len(df_test['date'].unique().tolist())\n    \n    df_time = pd.concat([df[['date']], df_test[['date']]])\n    df_time = df_time.groupby('date').sum()\n    df_time.reset_index(inplace=True)\n    \n    # item_all\n    df_item = df[['item', 'date', 'sales']].groupby(['item','date']).sum()\n    df_item.reset_index(inplace=True)\n    \n    # store_all\n    df_store = df[['store', 'date', 'sales']].groupby(['store','date']).sum()\n    df_store.reset_index(inplace=True)\n    \n    # calendar\n    df_day = df_time.copy()\n    df_day['year'] = df_day['date'].apply(lambda x:x.year)\n    df_day['month'] = df_day['date'].apply(lambda x:x.month)\n    df_day = df_day.groupby(['date']).first()\n    df_day.reset_index(inplace=True)\n    df_wday = df_day.copy()\n    df_wday['wday'] = df_wday['date'].apply(lambda x : x.isoweekday())\n    df_wday = pd.get_dummies(df_wday[['wday']], columns=['wday']).astype(int)\n    df_month = df_day.copy()\n    df_month = pd.get_dummies(df_month[['month']], columns=['month']).astype(int)\n    df_day = pd.concat([df_day, df_wday], axis=1)\n    df_day = pd.concat([df_day, df_month], axis=1)\n    ls_day = df_day.columns.tolist()\n    ls_day.remove('date')\n    print('make calendar data')\n    \n    # calendar_train/test\n    train_expv = df_day[ls_day].iloc[:-eval_term].values\n    test_expv = df_day[ls_day].values\n    \n    # prediciton(store)\n    ls_store = df_store['store'].unique().tolist()\n    df_st_lr = pd.DataFrame()\n    for i in ls_store:\n        df_st_tmp = df_store[df_store['store'] == i].copy()\n        train_objv = df_st_tmp['sales'].values\n        lr = LinearRegression(fit_intercept=False)\n        res_lr = lr.fit(train_expv, train_objv)\n        df_result = df_day[['date']].copy()\n        df_result['store'] = i\n        df_result['store_lr'] = res_lr.predict(test_expv)\n        if(len(df_st_lr)==0):\n            df_st_lr = df_result.copy()\n        else:\n            df_st_lr = df_st_lr.append(df_result)\n    print('make predict(store) data')\n    \n    # predict(item)\n    ls_item = df_item['item'].unique().tolist()\n    df_it_lr = pd.DataFrame()\n    for i in ls_item:\n        df_it_tmp = df_item[df_item['item'] == i].copy()\n        train_objv = df_it_tmp['sales'].values\n        lr = LinearRegression(fit_intercept=False)\n        res_lr = lr.fit(train_expv, train_objv)\n        df_result = df_day[['date']].copy()\n        df_result['item'] = i\n        df_result['item_lr'] = res_lr.predict(test_expv)\n        if(len(df_it_lr)==0):\n            df_it_lr = df_result.copy()\n        else:\n            df_it_lr = df_it_lr.append(df_result)\n    print('make predict(item) data')\n    \n    df['target'] = df['store'].astype(str) + '_' + df['item'].astype(str)\n    df_test['target'] = df_test['store'].astype(str) + '_' + df_test['item'].astype(str)\n    ls_target = df_test['target'].unique().tolist()\n    #ls_expv = ['store_lr','item_lr','exps_sim','exps_all','holt']\n    ls_expv = ['store_lr','item_lr']\n    print('finish prepareing process')\n    \n    df_out = pd.DataFrame()\n    for i in ls_target:\n        print('target(store_item):',i)\n        df_tmp = df[df['target'] == i ]\n        df_tmp = pd.merge(df_time, df_tmp, on=['date'], how='left')\n        df_tmp['item'] = df_tmp['item'].iloc[0]\n        df_tmp['store'] = df_tmp['store'].iloc[0]\n        df_tmp['target'] = df_tmp['target'].iloc[0]\n        df_tmp = pd.merge(df_tmp, df_st_lr, on=['date', 'store'], how='left')\n        df_tmp = pd.merge(df_tmp, df_it_lr, on=['date', 'item'], how='left')\n        \n        #model1 = sm.holtwinters.ExponentialSmoothing(df_tmp['sales'].iloc[:-eval_term], trend='add').fit()\n        #model2 = sm.holtwinters.ExponentialSmoothing(df_tmp['sales'].iloc[:-eval_term], seasonal_periods=7, trend='add', seasonal='add').fit()\n        #model3 = sm.holtwinters.Holt(df_tmp['sales'].iloc[:-eval_term]).fit()\n        #df_tmp['exps_sim'] = model1.predict(0,len(df_tmp))\n        #df_tmp['exps_all'] = model2.predict(0,len(df_tmp))\n        #df_tmp['holt'] = model3.predict(0,len(df_tmp))\n        \n        train_expv = df_tmp[ls_expv].iloc[:-eval_term].values\n        test_expv = df_tmp[ls_expv].values\n        train_objv = df_tmp['sales'].iloc[:-eval_term].values\n        bool_scaler = True\n        if (bool_scaler):\n            scaler = StandardScaler()\n            train_expv = scaler.fit_transform(train_expv)\n            test_expv = scaler.fit_transform(test_expv)\n            train_objv = scaler.fit_transform(train_objv.reshape(-1,1)).ravel()\n        \n        # GBreg\n        tuned_parameters =[{'n_estimators':[10,20,50],\n                           'max_features':['auto'],\n                           'random_state':[0],\n                           'min_samples_split':[5,10],\n                           'max_depth':[5,10]\n                           }]\n        clf = GridSearchCV(GradientBoostingRegressor(), tuned_parameters, cv=5, scoring='neg_mean_squared_error')\n        clf.fit(train_expv, train_objv)\n        res_rf = clf.best_estimator_\n        predict = res_rf.predict(test_expv)\n        \n        if (bool_scaler):\n            predict = scaler.inverse_transform(predict)\n            \n        df_tmp['predict'] = predict\n        df_tmp = df_tmp[['date','store','item','sales','predict']].iloc[-eval_term:] # -462:\n        \n        if(len(df_out) == 0):\n            df_out = df_tmp.copy()\n        else:\n            df_out = df_out.append(df_tmp)\n            #break\n    df_test = pd.read_csv('../input/test.csv', dtype={'store':int,'item':int})\n    df_test['date'] = df_test['date'].apply(lambda x:dt.strptime(str(x),\"%Y-%m-%d\"))\n    df_test = pd.merge(df_test, df_out[['date','store','item','predict']], on=['date','store','item'], how='left')\n    df_test.rename(columns={'predict':'sales'}, inplace=True)\n    df_test = df_test[['id','sales']]\n    print(df_test.head(10))\n    df_test.to_csv('output.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}