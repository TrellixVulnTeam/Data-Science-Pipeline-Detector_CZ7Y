{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Importing the data and libraries"},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport xgboost as xgb\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df= pd.read_csv('../input/demand-forecasting-kernels-only/train.csv')\ntest_df= pd.read_csv('../input/demand-forecasting-kernels-only/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"****the distribution of sales in the given dataset is as such"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport seaborn as sns \nsns.pairplot(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## exploratory analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.figure(figsize=(12,5))\nplt.title(\"Distribution of sales - for each item, date and store\")           \nax=sns.distplot(df['sales'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Distribution w.r.t normal distribution "},{"metadata":{"trusted":true},"cell_type":"code","source":"import scipy.stats as st\nprint(\"p-value for sales distribution: {}\".format(st.normaltest(df.sales.values)[1]))\nplt.figure(figsize=(12,5))\nplt.title(\"Distribution of sales vs fitting normal distribution\")\nax = sns.distplot(df.sales, fit= st.norm, kde=True, color='r')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"****this is the comparison of our data with respect to a normal distribution curve the red line is our distribution curve and black line is the normal distribution "},{"metadata":{},"cell_type":"markdown","source":"## Total sales of items per store "},{"metadata":{"trusted":true},"cell_type":"code","source":"store_total = df.groupby(['store'])['sales'].sum().to_frame().reset_index()\nstore_total.sort_values(by = ['sales'], ascending=True, inplace=True)\nlabels = ['Store {}'.format(i) for i in store_total.store]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plotting the store total with the labels generated \nplt.figure(figsize=(12,5))\nplt.title(\"sales of items per store\")\nax = sns.barplot(x='store', y='sales',data=store_total, palette='Blues_d')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Total sales for each item "},{"metadata":{"trusted":true},"cell_type":"code","source":"#total sales by item \n\nitem_total = df.groupby(['item'])['sales'].sum().to_frame().reset_index()\nitem_total.sort_values(by = ['sales'], ascending=False, inplace=True)\nlabels = ['Item {}'.format(i) for i in item_total.item]\nitem_total\nplt.figure(figsize=(12,7))\nplt.title(\"total sales per item\")\n\naxis = sns.barplot(x='item', y='sales',data=item_total, palette='cubehelix')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport plotly.graph_objs as go\ninit_notebook_mode()\ndf['date']=pd.to_datetime(df['date'])\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Average sales per month "},{"metadata":{"trusted":true},"cell_type":"code","source":"monthly_df = df.groupby([df.date.dt.year, df.date.dt.month])['sales'].mean()\nmonthly_df.index = monthly_df.index.set_names(['year', 'month'])\nmonthly_df = monthly_df.reset_index()\nx_axis = []\nfor y in range(13, 18):\n    for m in range(1,12):\n        x_axis.append(\"{}/{}\".format(m,y))\ntrace = go.Scatter(x= x_axis, y= monthly_df.sales, mode= 'lines+markers', name= 'sales avg per month', line=dict(width=3))\nlayout = go.Layout(autosize=True, title= 'Sales - average per month', showlegend=True)\nfig = go.Figure(data=[trace], layout=layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"monthly_df = df.groupby([df.date.dt.year, df.date.dt.month])['sales'].mean()\nmonthly_df.index = monthly_df.index.set_names(['year', 'month'])\nmonthly_df = monthly_df.reset_index()\nplt.figure(figsize=(15,6))\nplt.title(\"total sales per item\")\n\naxis = sns.barplot(x='month', y='sales',data=monthly_df, palette='Blues_d')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Forecasting "},{"metadata":{"trusted":true},"cell_type":"code","source":"df['train_or_test'], test_df['train_or_test'] = 'train', 'test'\ndata_df = pd.concat([df, test_df])\ndata_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# converting datetime to datetime \ndata_df['date']=pd.to_datetime(data_df['date'])\ndata_df.dtypes\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df['year'] = data_df['date'].dt.year\ndata_df['quarterly'] = data_df['date'].dt.quarter\ndata_df['monthly'] = data_df['date'].dt.month\ndata_df['weekofyear'] = data_df['date'].dt.weekofyear\ndata_df['weekday'] = data_df['date'].dt.weekday\ndata_df['dayofweek'] = data_df['date'].dt.dayofweek\ndata_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndata_df['item_quarter_mean'] = data_df.groupby(['quarterly', 'item'])['sales'].transform('mean')\ndata_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#columns for mean based on quarters\ndata_df['store_quarter_mean'] = data_df.groupby(['quarterly', 'store'])['sales'].transform('mean')\ndata_df['store_item_quarter_mean'] = data_df.groupby(['quarterly', 'item', 'store'])['sales'].transform('mean')\ndata_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#more of the same means but based on months\n\ndata_df['item_month_mean'] = data_df.groupby(['monthly', 'item'])['sales'].transform('mean')\ndata_df['store_month_mean'] = data_df.groupby(['monthly', 'store'])['sales'].transform('mean')\ndata_df['store_item_month_mean'] = data_df.groupby(['monthly', 'item', 'store'])['sales'].transform('mean')\ndata_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# based on weekdays\n\ndata_df['itemweekday_mean'] = data_df.groupby(['weekday', 'item'])['sales'].transform('mean')\ndata_df['storeweekday_mean'] = data_df.groupby(['weekday', 'store'])['sales'].transform('mean')\ndata_df['storeitemweekday_mean'] = data_df.groupby(['weekday', 'item', 'store'])['sales'].transform('mean')\ndata_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### the above dataframe consolidates all trends with respect to sales and stores on all prediction horizons "},{"metadata":{},"cell_type":"markdown","source":"## model prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_df.drop(['date','id','sales'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_df= data_df[data_df['train_or_test'] == 'train']\ntest_df = data_df[data_df['train_or_test'] == 'train']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_df.drop(['train_or_test'],axis=1,inplace=True)\ntest_df.drop(['train_or_test'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=pd.read_csv('../input/demand-forecasting-kernels-only/train.csv',usecols=['sales'])\ny=y['sales']\npd.DataFrame(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import ensemble\n\nrfr=ensemble.RandomForestRegressor(max_depth=13, random_state=0)\nrfr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nrfr.fit(x_df,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\npredict=pd.DataFrame(rfr.predict(test_df),columns=['sales'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(y, predict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics \n\nprint(metrics.r2_score(y, predict ))\nprint(metrics.mean_squared_error(y, predict ))\nprint(metrics.explained_variance_score(y, predict))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict\nids=pd.read_csv(\"../input/demand-forecasting-kernels-only/test.csv\",usecols=['id'])\nsub=ids.join(predict)\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv('result_file.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}