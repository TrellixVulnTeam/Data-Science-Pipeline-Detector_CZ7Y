{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nfrom zipfile import ZipFile\n\nzip_file = ZipFile('../#Data/demand-forecasting-kernels-only.zip')\ndfs = {text_file.filename: pd.read_csv(zip_file.open(text_file.filename), parse_dates=['date'])\n       for text_file in zip_file.infolist()\n       if text_file.filename.endswith('.csv') and not text_file.filename.endswith('submission.csv')}\n\ntrain = dfs['train.csv']\ntest = dfs['test.csv']\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/demand-forecasting-kernels-only/train.csv', parse_dates=['date'])\ntest = pd.read_csv('../input/demand-forecasting-kernels-only/test.csv', parse_dates=['date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def encode_dates(train):\n    train['year'] = train['date'].dt.year.astype('int64')\n    train['month'] = train['date'].dt.month.astype('uint8')\n    train['day'] = train['date'].dt.day.astype('uint8')\n    train['weekday'] = train['date'].dt.dayofweek.astype('uint8')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encode_dates(train)\nencode_dates(test)\n\ntrain.info()\ntrain['weekday'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.sort_values(by='date', inplace=True)\n\ntest.set_index('id', inplace=True)\ntest.sort_values(by='date', inplace=True)\n\n \ndef split(train):\n    model_train = train[train['year'] < 2016].set_index(['date'])\n    model_val = train[train['year'] >= 2016].set_index(['date'])\n    \n    X_train = model_train.drop('sales', axis=1)\n    X_test = model_val.drop('sales', axis=1)\n    y_train = model_train['sales']\n    y_test = model_val['sales']\n    \n    return X_train, X_test, y_train, y_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def smape(A, F):\n        return 100/len(A) * np.sum(2 * np.abs(F - A) / (np.abs(A) + np.abs(F)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def eval_model(X_train, X_test, y_train, y_test, reg, mode='test'):\n    y_pred = reg.predict(X_test)\n    y_self_pred = reg.predict(X_train)\n\n    test_compare = X_test.copy()\n    test_compare['test'] = y_test\n    test_compare['pred'] = y_pred.astype('int')\n\n    train_compare = X_train.copy()\n    train_compare['test'] = y_train\n    train_compare['pred'] = y_self_pred.astype('int')\n    \n    #whole_compare = train_compare.append(test_compare)\n    \n    plt.figure(figsize=(24,6))\n    if mode == 'train':\n        sns.lineplot(data=train_compare[['year', 'test', 'pred']])\n    elif mode == 'test':\n        sns.lineplot(data=test_compare[['year', 'test', 'pred']])\n    elif mode == 'whole':\n        sns.lineplot(data=train_compare[['year', 'test', 'pred']]), sns.lineplot(data=test_compare[['year', 'test', 'pred']])\n    \n    display('Test score: {0:.3f}; Train score: {0:.3f}; (Kaggle top: 12.580)'.format(smape(y_test, y_pred), smape(y_train, y_self_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample = train[train['store'] == 1].reset_index().groupby('date')['sales'].sum().reset_index()\nencode_dates(sample)\nsample.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = split(sample)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nfrom sklearn.ensemble import RandomForestRegressor\nforest_reg = RandomForestRegressor(max_depth=10, random_state=273, n_estimators=500)\nforest_reg.fit(X_train, y_train)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\neval_model(X_train, X_test, y_train, y_test, forest_reg, 'train')\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import Ridge\nfrom sklearn.preprocessing import PolynomialFeatures\n\npoly = PolynomialFeatures(degree=2)\npoly_X_train = poly.fit_transform(X_train)\npoly_X_test = poly.transform(X_test)\n\n#linear_reg = Lasso()\nlinear_reg = Ridge()\nlinear_reg.fit(poly_X_train, y_train)\n\ny_pred = linear_reg.predict(poly_X_test)\ny_self_pred = linear_reg.predict(poly_X_train)\n\ntest_compare = X_test.copy()\ntest_compare['test'] = y_test\ntest_compare['pred'] = y_pred.astype('int')\n\ntrain_compare = X_train.copy()\ntrain_compare['test'] = y_train\ntrain_compare['pred'] = y_self_pred.astype('int')\n\nmode = 'train'\n\nplt.figure(figsize=(24,6))\nif mode == 'train':\n    sns.lineplot(data=train_compare[['year', 'test', 'pred']])\nelif mode == 'test':\n    sns.lineplot(data=test_compare[['year', 'test', 'pred']])\nelif mode == 'whole':\n    sns.lineplot(data=train_compare[['year', 'test', 'pred']]), sns.lineplot(data=test_compare[['year', 'test', 'pred']])\n\ndisplay('Test score: {0:.3f}; Train score: {0:.3f}; (Kaggle top: 12.580)'.format(smape(y_test, y_pred), smape(y_train, y_self_pred)))\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nrdf = pd.DataFrame({'a':np.arange(-2,5,0.01)})\nrdf = rdf.append(rdf, ignore_index=True)\nrdf = rdf.assign(rb=lambda x: np.exp(-1/0.5*(x.a-1)**2))\nrdf, sns.lineplot(data=rdf, x=rdf['a'], y=rdf['rb'])\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rbf_features(X_train, X_test, gamma=1/0.5):\n    rb_X_train = X_train\n    rb_X_test = X_test\n    for i in range(len(train['weekday'].unique())):\n        rb_X_train['rbf'+i] = rb_X_train.apply(lambda x: np.exp(-gamma*(x[colNames[3]]-i)**2))\n        #rb_X_train = rb_X_train.assign('rbd'=lambda x: np.exp(-gamma*(x.weekday-i)**2))\n        #rb_X_test = rb_X_test.assign(int(i)=lambda x: np.exp(-gamma*(x.weekday-i)**2))\n        \n    return rb_X_train, rb_X_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#rbf_features(X_train, X_test)\n#rb_X_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nrb_X_train = X_train\nrb_X_test = X_test\n\ngamma = 1/0.5\n\nrb_X_train = rb_X_train.assign(rb0=lambda x: np.exp(-gamma*(x.weekday-0)**2))\nrb_X_train = rb_X_train.assign(rb1=lambda x: np.exp(-gamma*(x.weekday-1)**2))\nrb_X_train = rb_X_train.assign(rb2=lambda x: np.exp(-gamma*(x.weekday-2)**2))\nrb_X_train = rb_X_train.assign(rb3=lambda x: np.exp(-gamma*(x.weekday-3)**2))\nrb_X_train = rb_X_train.assign(rb4=lambda x: np.exp(-gamma*(x.weekday-4)**2))\nrb_X_train = rb_X_train.assign(rb5=lambda x: np.exp(-gamma*(x.weekday-5)**2))\nrb_X_train = rb_X_train.assign(rb6=lambda x: np.exp(-gamma*(x.weekday-6)**2))\n\nrb_X_test = rb_X_test.assign(rb0=lambda x: np.exp(-gamma*(x.weekday-0)**2))\nrb_X_test = rb_X_test.assign(rb1=lambda x: np.exp(-gamma*(x.weekday-1)**2))\nrb_X_test = rb_X_test.assign(rb2=lambda x: np.exp(-gamma*(x.weekday-2)**2))\nrb_X_test = rb_X_test.assign(rb3=lambda x: np.exp(-gamma*(x.weekday-3)**2))\nrb_X_test = rb_X_test.assign(rb4=lambda x: np.exp(-gamma*(x.weekday-4)**2))\nrb_X_test = rb_X_test.assign(rb5=lambda x: np.exp(-gamma*(x.weekday-5)**2))\nrb_X_test = rb_X_test.assign(rb6=lambda x: np.exp(-gamma*(x.weekday-6)**2))\n'''\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#rb_X_train, rb_X_test\n'''\nrb_X_train.head()\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import Ridge\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.preprocessing import StandardScaler\n\nX_train, X_test, y_train, y_test = split(sample)\n\n#poly_X_train = rb_X_train.drop(['month', 'day', 'weekday', 'year'], axis=1)\n#poly_X_test = rb_X_test.drop(['month', 'day', 'weekday', 'year'], axis=1)\n\n#scaler = StandardScaler()\n#poly_X_train = poly.fit_transform(poly_X_train)\n#poly_X_test = poly.transform(poly_X_test)\n\npoly = PolynomialFeatures(degree=2)\npoly_X_train = poly.fit_transform(X_train)\npoly_X_test = poly.transform(X_test)\n#poly_X_train = poly.fit_transform(rb_X_train)\n#poly_X_test = poly.transform(rb_X_test)\n\n\n#poly_X_train = rb_X_train.drop(['month', 'day', 'weekday', 'year'], axis=1)\n#poly_X_test = rb_X_test.drop(['month', 'day', 'weekday', 'year'], axis=1)\n\n#linear_reg = Lasso(alpha=10)\nlinear_reg = Ridge(alpha=10)#alpha = 1000)\nlinear_reg.fit(poly_X_train, y_train)\n\ny_pred = linear_reg.predict(poly_X_test)\ny_self_pred = linear_reg.predict(poly_X_train)\n\ntest_compare = X_test.copy()\ntest_compare['test'] = y_test\ntest_compare['pred'] = y_pred.astype('int')\n\ntrain_compare = X_train.copy()\ntrain_compare['test'] = y_train\ntrain_compare['pred'] = y_self_pred.astype('int')\n\nmode = 'train'\n\nplt.figure(figsize=(24,6))\nif mode == 'train':\n    sns.lineplot(data=train_compare[['year', 'test', 'pred']])\nelif mode == 'test':\n    sns.lineplot(data=test_compare[['year', 'test', 'pred']])\nelif mode == 'whole':\n    sns.lineplot(data=train_compare[['year', 'test', 'pred']]), sns.lineplot(data=test_compare[['year', 'test', 'pred']])\n\ndisplay('Test score: {0:.3f}; Train score: {0:.3f}; (Kaggle top: 12.580)'.format(smape(y_test, y_pred), smape(y_train, y_self_pred)))\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\npoly_X_train.head(20)\n'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"RBF features appear to have little to no effect - need to try them deliberately on some test subject"},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nsample2 = train[train['item'] == 1].groupby(['date', 'store'])['sales'].sum() #.reset_index()\n#sample2 = train[train['store'] == 1].groupby(['date', 'item'])['sales'].sum().reset_index()\n#encode_dates(sample2)\nsample2#.head()\n\n# demand for same item is +/- the same fpr all the shops, while demand at same shop varies significantly for different items \n#=> split set by items and encode shops\n'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"items = np.sort(train['item'].unique())\n\nfor i in items:\n    sub_sample = train[train['item'] == i]\n    X_train, X_test, y_train, y_test = split(sub_sample)\n    label encode for dates\n    poly transform for dates\n    one hot encode for shops\n    \n    linear_reg = Ridge(alpha=10)#alpha = 1000)\n    linear_reg.fit(poly_X_train, y_train)\n    X_train['pred'] = linear_reg.predict(X_train)\n    X_test['pred'] = linear_reg.predict(X_test)\n    \n    display('Test score: {0:.3f}; Train score: {0:.3f}; (Kaggle top: 12.580)'\n    .format(smape(y_test, X_test['pred']), smape(y_train, X_train['pred'])))\n    \n    \n# UPD: don't encode shops, add new model level for shops via additional loop (500 models total)"},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nitems = np.sort(train['item'].unique())\n\nfor i in [1]:#items:\n    sub_sample = train[train['item'] == i]\n    X_train, X_test, y_train, y_test = split(sub_sample)\n    label encode for dates\n    poly transform for dates\n    one hot encode for shops\n    \n    linear_reg = Ridge(alpha=10)#alpha = 1000)\n    linear_reg.fit(poly_X_train, y_train)\n    X_train['pred'] = linear_reg.predict(X_train)\n    X_test['pred'] = linear_reg.predict(X_test)\n    \n    display('Test score: {0:.3f}; Train score: {0:.3f}; (Kaggle top total: 12.580)'\n    .format(smape(y_test, X_test['pred']), smape(y_train, X_train['pred'])))\n    '''","execution_count":null,"outputs":[]},{"metadata":{"jupyter":{"outputs_hidden":true},"trusted":true},"cell_type":"code","source":"'''\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import PolynomialFeatures\n\na = train[train['item'] == 1]\n\nct = ColumnTransformer([(\"onehot\", OneHotEncoder(), ['store']),\n                        (\"poly\", PolynomialFeatures(degree=2), ['year', 'month', 'day', 'weekday'])])\nct.fit_transform(a)\n'''\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nsample = train[train['store'] == 1].reset_index().groupby('date')['sales'].sum().reset_index()\nsample2 = train[train['item'] == 1]\nsample3 = train[(train['item'] == 2) & (train['store'] == 1)]\n\nsample3.head()\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import Ridge\nfrom sklearn.preprocessing import PolynomialFeatures\n\nX_train, X_test, y_train, y_test = split(sample3)\n\nct = ColumnTransformer([#(\"onehot\", OneHotEncoder(categories='auto'), ['store']),\n                        (\"poly\", PolynomialFeatures(degree=2), ['year', 'month', 'day', 'weekday'])])\npoly_X_train = ct.fit_transform(X_train)\npoly_X_test = ct.transform(X_test)\n\n#linear_reg = Lasso(alpha=10)\nlinear_reg = Ridge(alpha=10)#alpha = 1000)\nlinear_reg.fit(poly_X_train, y_train)\n\ny_pred = linear_reg.predict(poly_X_test)\ny_self_pred = linear_reg.predict(poly_X_train)\n\ntest_compare = X_test.copy()\ntest_compare['test'] = y_test\ntest_compare['pred'] = y_pred.astype('int')\n\ntrain_compare = X_train.copy()\ntrain_compare['test'] = y_train\ntrain_compare['pred'] = y_self_pred.astype('int')\n\nmode = 'train'\n\nplt.figure(figsize=(24,6))\nif mode == 'train':\n    sns.lineplot(data=train_compare[['test', 'pred']])\nelif mode == 'test':\n    sns.lineplot(data=test_compare[['test', 'pred']])\nelif mode == 'whole':\n    sns.lineplot(data=train_compare[['test', 'pred']]), sns.lineplot(data=test_compare[['test', 'pred']])\n\ndisplay('Test score: {0:.3f}; Train score: {0:.3f}; (Kaggle top: 12.580)'.format(smape(y_test, y_pred), smape(y_train, y_self_pred)))\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Lasso\nfrom sklearn.linear_model import Ridge\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import PolynomialFeatures\n\nitems = np.sort(train['item'].unique())\nstores = np.sort(train['store'].unique())\nmeta_sample = train.copy()\n\ntest_sample= test.copy()\ntest_sample['pred'] = 0.\n#test_dummy['sales'] = 0\n\n#meta_sample = meta_sample.append(test_dummy)\nmeta_sample['pred'] = 0.\n\n# we need to train and validate model on train-val set and do predictions for part of the test set at the same loop iteration\n\nfor i in items:#[1]:\n    for s in stores:#[1]: #stores:\n        sub_sample = meta_sample[(meta_sample['item'] == i) & (meta_sample['store'] == s)]\n        X_train, X_test, y_train, y_test = split(sub_sample)\n        \n        test_sub_sample = test_sample[(test_sample['item'] == i) & (test_sample['store'] == s)].drop('date', axis=1)\n        \n        \n        ct = ColumnTransformer([#(\"onehot\", OneHotEncoder(categories='auto'), ['store']),\n                        (\"poly\", PolynomialFeatures(degree=2), ['year', 'month', 'day', 'weekday'])])\n        poly_X_train = ct.fit_transform(X_train)\n        poly_X_test = ct.transform(X_test)\n        poly_real_test = ct.transform(test_sub_sample)\n        \n        linear_reg = Ridge(alpha=10)#alpha = 1000)\n        linear_reg.fit(poly_X_train, y_train)\n        \n        X_train['pred'] = linear_reg.predict(poly_X_train)\n        X_test['pred'] = linear_reg.predict(poly_X_test)\n        test_sub_sample['pred'] = linear_reg.predict(poly_real_test)\n        \n        whole = X_train.append(X_test)\n        \n        meta_sample.loc[(meta_sample['item'] == i) & (meta_sample['store'] == s), 'pred'] = whole['pred'].values\n        test_sample.loc[(test_sample['item'] == i) & (test_sample['store'] == s), 'pred'] = test_sub_sample['pred'].values\n\n        display('Test score: {0:.3f}; Train score: {0:.3f}; (Kaggle top total: 12.580)'\n        .format(smape(y_test, X_test['pred']), smape(y_train, X_train['pred'])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output = test_sample.sort_index()['pred'].reset_index()\n\noutput = pd.DataFrame({'id': output.index,\n                       'sales': output['pred']})\noutput.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meta_sample[['sales', 'pred']].describe() #COOL","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"smape(meta_sample['sales'], meta_sample['pred']) #Good","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"whole","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"whole['pred'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(X_train) + len(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.set_index('id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_sample.sort_index()['pred'].reset_index()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python [conda env:root] *","language":"python","name":"conda-root-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.5"}},"nbformat":4,"nbformat_minor":1}