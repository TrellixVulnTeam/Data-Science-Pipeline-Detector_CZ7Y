{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings \nwarnings.filterwarnings('ignore')\n\nfrom math import sqrt\nfrom sklearn.metrics import mean_squared_error\n\n%matplotlib inline\nimport matplotlib.pyplot as plt  \nimport seaborn as sns\nimport statsmodels.api as sm\n\nimport plotly as py\nimport plotly.graph_objs as go\nfrom plotly.offline import init_notebook_mode, iplot","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Input data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample = pd.read_csv('/kaggle/input/demand-forecasting-kernels-only/sample_submission.csv')\ntrain = pd.read_csv('/kaggle/input/demand-forecasting-kernels-only/train.csv',parse_dates=['date'])\ntest = pd.read_csv('/kaggle/input/demand-forecasting-kernels-only/test.csv',parse_dates=['date'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Explore data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.skew()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Skewnwss is between -1 to 1, consider as no outliers."},{"metadata":{"trusted":true},"cell_type":"code","source":"test.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[88:92]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Min date from train set: {}\".format(train.date.min()))\nprint(\"Max date from train set: {}\".format(train.date.max()))\nprint(\"Min date from test set: {}\".format(test.date.min()))\nprint(\"Max date from test set: {}\".format(test.date.max()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Visualize data: Daily Sales by Store**\n* From data explore: there're 10 stores (1-10) and no missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"store_sales = train.groupby(['date','store'], as_index = False)['sales'].sum()\nstore_sales_plot = []\nfor i in range(1,11):\n    current_store = store_sales[(store_sales['store'] == i)]\n    store_sales_plot.append(go.Scatter(x = current_store['date'], y = current_store['sales'],\n                                       name = ('store %s' % i)))\nfig = go.Figure(data = store_sales_plot)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the plot we can see the 10 stores have similar trend and seasonality, higher sales in middle of the year and end of the year, and there's increase in sales year by year."},{"metadata":{},"cell_type":"markdown","source":"# **Visualize data: Daily Sales by Item**\n\n* From data explore: there're 50 items (1-50) and no missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"item_sales = train.groupby(['date','item'], as_index = False)['sales'].sum()\nitem_sales_plot = []\nfor i in range(1,51):\n    current_item = item_sales[item_sales['item'] == i]\n    item_sales_plot.append(go.Scatter(x = current_item['date'], y = current_item['sales'],\n                                   name = 'item %s' % i))\nfig = go.Figure(data = item_sales_plot)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the plot we can see the 50 items have similar trend and seasonality, higher sales in middle of the year and end of the year, and there's increase in sales year by year."},{"metadata":{},"cell_type":"markdown","source":"# **Build model using SARIMA**"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pmdarima\nfrom pmdarima import auto_arima","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Random choose a store:"},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.randint(low=1, high=10, size=(1,))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Random choose an item:"},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.randint(low=1, high=50, size=(1,))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Run auto arima for store 5 and item 29 (use last 90 days sales as validation):"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_1 = train[(train['store'] == 5) & (train['item'] == 29)]\n\ntrain_1_df = train_1[:(len(train_1)-90)]\nvalid_1_df = train_1[len(train_1)-90:len(train_1)]\n\ntrain_1_df.drop(columns = ['store','item'], inplace=True)\nvalid_1_df.drop(columns = ['store','item'], inplace=True)\n\ntrain_1_df = train_1_df.set_index('date')\nvalid_1_df = valid_1_df.set_index('date')\n\nautoarima_model = auto_arima(train_1_df,m=7,\n                             seasonal=True,\n                             trace=True,\n                             error_action='ignore',\n                             suppress_warnings=True,\n                             stepwise=True)\nautoarima_model.fit(train_1_df)\nforecast = autoarima_model.predict(n_periods=len(valid_1_df))\nrmse = sqrt(mean_squared_error(valid_1_df,forecast))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rmse","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From auto arima, the best fit model is (2,1,1)x(2,0,2,7) and rmse is 12.86.\nAs each store and item has similar trend and seasonality, can use the same SARIMA model for all stores and items.\nMaybe it will be better to use auto arima for each store and item, but it will take very long."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train.set_index('date')\nrmse_list = []\nstart_index = '2017-10-01'\nend_index = '2017-12-31'\nactualvsforecast = pd.DataFrame()\n\nfor i in range(1,51):\n    for j in range(1,11):\n        train_1 = train_df[(train_df['store'] == j) & (train_df['item'] == i)]\n        model = sm.tsa.statespace.SARIMAX(train_1.sales[:start_index],\n                                          order=(2,1,1),\n                                          seasonal_order=(2,0,2,7),\n                                          freq='D').fit()\n        train_1['forecast'] = model.predict(start = pd.to_datetime(start_index), \n                                            end = pd.to_datetime(end_index),\n                                            dynamic = True)\n        rmse = sqrt(mean_squared_error(train_1[start_index:end_index]['sales'],\n                                       train_1[start_index:end_index]['forecast']))\n        rmse_list.append(rmse)\n        actualvsforecast = actualvsforecast.append(train_1[start_index:end_index])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"actualvsforecast.to_csv(\"actualvsforecast_arima.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_1['forecast'].count()/len(train_1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This 0.05 percentage will be used to split train and test for XGBoost model."},{"metadata":{"trusted":true},"cell_type":"code","source":"len(rmse_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sum(rmse_list)/len(rmse_list)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The average rmse is 13.56."},{"metadata":{},"cell_type":"markdown","source":"# **Build model using XGBoost**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['date']=pd.to_datetime(train['date'])\ntrain['weekday']=train['date'].dt.dayofweek\ntrain['dayofyear']=train['date'].dt.dayofyear\ntrain['year']=train['date'].dt.year\ntrain['month']=train['date'].dt.month","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import cross_val_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=train.copy()\nX.drop(['sales','date'],axis=1,inplace=True)\ny=train['sales']\n\nX_train,X_val,y_train,y_val=train_test_split(X,y,test_size=0.05,random_state=123)\n\nxgb=XGBRegressor(random_state=123)\n\n\nXBG_score=cross_val_score(xgb,X_train,y_train,scoring='neg_mean_squared_error')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"RMSE:\",np.sqrt(-XBG_score.mean()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"rmse is 7.73, which is lower than SARIMA mode rmse (13.56). Hence choose XGBoost model to predict."},{"metadata":{},"cell_type":"markdown","source":"# **Prediction using test file**"},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb.fit(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['weekday']=test['date'].dt.dayofweek\ntest['dayofyear']=test['date'].dt.dayofyear\ntest['year']=test['date'].dt.year\ntest['month']=test['date'].dt.month\n\nX=test.copy()\nX.drop(['id','date'],axis=1,inplace=True)\n\ntest_predictions=xgb.predict(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final = pd.DataFrame()\nfinal['id']=test['id']\nfinal['sales']=test_predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}