{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom scipy.stats import describe\npd.options.display.max_columns = 12\npd.options.display.max_rows = 24","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\n\nwarnings.simplefilter('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.set()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# use svg for all plots within inline backend\n%config InlineBackend.figure_format = 'svg'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pylab import rcParams\nrcParams['figure.figsize'] = 5, 4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\npd.options.display.max_columns = 12\npd.options.display.max_rows = 24\n\n# disable warnings in Anaconda\nimport warnings\n\nwarnings.simplefilter('ignore')\n\n# plots inisde jupyter notebook\n%matplotlib inline\nimport matplotlib.pyplot as plt\n\nimport seaborn as sns\nsns.set()\n\n# use svg for all plots within inline backend\n%config InlineBackend.figure_format = 'svg'\n\n# increase default plot size\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 5, 4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('../input/demand-forecasting-kernels-only/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['date'] = pd.to_datetime(df_train['date'])\ndf_train.index = pd.DatetimeIndex(df_train['date'])\ndf_train.drop('date', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from itertools import product, starmap\n\n\ndef storeitems():\n    return product(range(1,51), range(1,11))\n\n\ndef storeitems_column_names():\n    return list(starmap(lambda i,s: f'item_{i}_store_{s}_sales', storeitems()))\n\n\ndef sales_by_storeitem(df):\n    ret = pd.DataFrame(index=df.index.unique())\n    for i, s in storeitems():\n        ret[f'item_{i}_store_{s}_sales'] = df[(df['item'] == i) & (df['store'] == s)]['sales'].values\n    return ret\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = sales_by_storeitem(df_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.read_csv('../input/demand-forecasting-kernels-only/test.csv')\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test['date'] = pd.to_datetime(df_test['date'])\ndf_test.index = pd.DatetimeIndex(df_test['date'])\ndf_test.drop('date', axis=1, inplace=True)\ndf_test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test['sales'] = np.zeros(df_test.shape[0])\ndf_test = sales_by_storeitem(df_test)\ndf_test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col_names = list(zip(df_test.columns, df_train.columns))\nfor cn in col_names:\n    assert cn[0] == cn[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test['is_test'] = np.repeat(True, df_test.shape[0])\ndf_train['is_test'] = np.repeat(False, df_train.shape[0])\ndf_total = pd.concat([df_train, df_test])\ndf_total.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weekday_df = pd.get_dummies(df_total.index.weekday, prefix='weekday')\nweekday_df.index = df_total.index\nweekday_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"month_df = pd.get_dummies(df_total.index.month, prefix='month')\nmonth_df.index =  df_total.index\nmonth_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_total = pd.concat([weekday_df, month_df, df_total], axis=1)\ndf_total.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert df_total.isna().any().any() == False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def shift_series(series, days):\n    return series.transform(lambda x: x.shift(days))\n\n\ndef shift_series_in_df(df, series_names=[], days_delta=90):\n    \"\"\"\n    Shift columns in df with names in series_names by days_delta.\n    \n    Negative days_delta will prepend future values to current date,\n    positive days_delta wil prepend past values to current date.\n    \"\"\"\n    ret = pd.DataFrame(index=df.index.copy())\n    str_sgn = 'future' if np.sign(days_delta) < 0 else 'past'\n    for sn in series_names:\n        ret[f'{sn}_{str_sgn}_{np.abs(days_delta)}'] = shift_series(df[sn], days_delta)\n    return ret\n\n    \ndef stack_shifted_sales(df, days_delta=90):\n    names = storeitems_column_names()\n    dfs = [df.copy()]\n    abs_range = range(1, days_delta+1) if days_delta > 0 else range(days_delta, 0)\n    for day_offset in abs_range:\n        delta = -day_offset\n        shifted = shift_series_in_df(df, series_names=names, days_delta=delta)\n        dfs.append(shifted)\n    return pd.concat(dfs, axis=1, copy=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_total = stack_shifted_sales(df_total, days_delta=-1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_total = df_total.dropna()  # this should ONLY remove 1st row\ndf_total.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make sure stacked and standard sales columns appear in the same order:\nsales_cols = [col for col in df_total.columns if '_sales' in col and '_sales_' not in col]\nstacked_sales_cols = [col for col in df_total.columns if '_sales_' in col]\nother_cols = [col for col in df_total.columns if col not in set(sales_cols) and col not in set(stacked_sales_cols)]\n\nsales_cols = sorted(sales_cols)\nstacked_sales_cols = sorted(stacked_sales_cols)\n\nnew_cols = other_cols + stacked_sales_cols + sales_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_total = df_total.reindex(columns=new_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_total.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_total.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_total.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert df_total.isna().any().any() == False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_to_scale = [col for col in df_total.columns if 'weekday' not in col and 'month' not in col]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = MinMaxScaler(feature_range=(0,1))\nscaled_cols = scaler.fit_transform(df_total[cols_to_scale])\ndf_total[cols_to_scale] = scaled_cols\ndf_total.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_total.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = df_total[df_total['is_test'] == False].drop('is_test', axis=1)\ndf_test = df_total[df_total['is_test'] == True].drop('is_test', axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_cols_stacked = [col for col in df_train.columns if '_past_' in col]\nX_cols_caldata = [col for col in df_train.columns if 'weekday_' in col or 'month_' in col]\nX_cols = X_cols_stacked + X_cols_caldata\n\nX = df_train[X_cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_colset = set(X_cols)\ny_cols = [col for col in df_train.columns if col not in X_colset]\n\ny = df_train[y_cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_vals = X_train.values.reshape((X_train.shape[0], 1, X_train.shape[1]))\nX_valid_vals = X_valid.values.reshape((X_valid.shape[0], 1, X_valid.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential, Model\nfrom keras.layers import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model():\n    inputs = Input(shape=(X_train_vals.shape[1], X_train_vals.shape[2]))\n    # top pipeline\n    top_lstm = LSTM(500, return_sequences=True)(inputs)\n    top_dense = Dense(500, activation='relu')(top_lstm)\n    # bottom pipeline\n    bottom_dense = Dense(500)(inputs)\n    bottom_conv1 = Conv1D(\n        500, \n        kernel_size=1,\n        input_shape=(X_train_vals.shape[1], X_train_vals.shape[2])\n    )(bottom_dense)\n    bottom_conv2 = Conv1D(\n        1000,\n        kernel_size=50,\n        padding='same',\n        activation='relu'\n    )(bottom_conv1)\n    bottom_conv3 = Conv1D(\n        500,\n        kernel_size=10,\n        padding='same',\n        activation='relu'\n    )(bottom_conv2)\n    bottom_pooling = AvgPool1D(\n        pool_size=10, \n        padding='same'\n    )(bottom_conv3)\n#     bottom_reshape = Reshape(\n#         target_shape=[500]\n#     )(bottom_conv3)\n    # concat output\n    final_concat = Concatenate()([top_dense, bottom_pooling])\n    final_lstm = LSTM(1000, dropout=0.2)(final_concat)\n    final_dense = Dense(500)(final_lstm)\n    # compile and return\n    model = Model(inputs=inputs, outputs=final_dense)\n    model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mape'])\n    return model\n\nmodel = build_model()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(\n    X_train_vals, \n    y_train.values, \n    epochs=200, \n    batch_size=70,\n    validation_data=(X_valid_vals, y_valid.values),\n    verbose=2,\n    shuffle=False\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['loss'], label='train')\nplt.plot(history.history['val_loss'], label='test')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_valid.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_eval(model, X_test, y_test, log_all=False):\n    \"\"\"\n    Model must have #predict method.\n    X_test, y_test - instances of pd.DataFrame (normal, not reshaped for LSTM !!!)\n    \n    Note that this function assumes that sales columns for previous values appear \n    in the same order as sales columns for current values.\n    \"\"\"\n    # prepare data\n    sales_x_cols = [col for col in X_test.columns if 'sales' in col]\n    sales_x_idxs = [X_test.columns.get_loc(col) for col in sales_x_cols]\n    sales_y_cols = [col for col in y_test.columns if 'sales' in col]\n    sales_y_idxs = [y_test.columns.get_loc(col) for col in sales_y_cols]\n    n_samples = y_test.shape[0]\n    y_pred = np.zeros(y_test.shape)\n    # iterate\n    x_next = X_test.iloc[0].values\n    for i in range(0, n_samples):\n        if log_all:\n            print('[x]', x_next)\n        x_arr = np.array([x_next])\n        x_arr = x_arr.reshape(x_arr.shape[0], 1, x_arr.shape[1])\n        y_pred[i] = model.predict(x_arr)[0]\n        try:\n            x_next = X_test.iloc[i+1].values\n            x_next[sales_x_idxs] = y_pred[i][sales_y_idxs]\n        except IndexError:\n            pass  # this happens on last iteration, and x_next does not matter anymore\n    return y_pred, y_test.values\n\ndef vector_smape(y_pred, y_real):\n    nom = np.abs(y_pred-y_real)\n    denom = (np.abs(y_pred) + np.abs(y_real)) / 2\n    results = nom / denom\n    return 100*np.mean(results)  # in percent, same as at kaggle","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_valid, y_valid = X_valid.head(90), y_valid.head(90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred, y_real = model_eval(model, X_valid, y_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def unscale(y_arr, scaler, template_df, toint=False):\n    \"\"\"\n    Unscale array y_arr of model predictions, based on a scaler fitted \n    to template_df.\n    \"\"\"\n    tmp = template_df.copy()\n    tmp[y_cols] = pd.DataFrame(y_arr, index=tmp.index)\n    tmp[cols_to_scale] = scaler.inverse_transform(tmp[cols_to_scale])\n    if toint:\n        return tmp[y_cols].astype(int)\n    return tmp[y_cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"template_df = pd.concat([X_valid, y_valid], axis=1)\ntemplate_df['is_test'] = np.repeat(True, template_df.shape[0])\n\npred = unscale(y_pred, scaler, template_df, toint=True)\nreal = unscale(y_real, scaler, template_df, toint=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"smapes = [vector_smape(pred[col], real[col]) for col in pred.columns]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(smapes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"describe(smapes)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"store, item = np.random.randint(1,11), np.random.randint(1,51)\nrandom_storeitem_col = f'item_{item}_store_{store}_sales'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_lengths = [7, 30, 60, 365]\n\nfor pl in plot_lengths:\n    plt.plot(pred[random_storeitem_col].values[:pl], label='predicted')\n    plt.plot(real[random_storeitem_col].values[:pl], label='real')\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test[stacked_sales_cols].head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split to X and y\nX_test, y_test = df_test[X_cols], df_test[y_cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_pred, _ = model_eval(model, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_template_df = pd.concat([X_test, y_test], axis=1)\ntest_template_df['is_test'] = np.repeat(True, test_template_df.shape[0])\n\ntest_pred = unscale(y_test_pred, scaler, test_template_df, toint=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(test_pred['item_1_store_1_sales'].values)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = np.zeros(45000, dtype=np.int)\nfor i, s in storeitems():\n    slice_start_idx = 90*10*(i-1) + 90*(s-1)\n    slice_end_idx = slice_start_idx + 90\n    col_name = f'item_{i}_store_{s}_sales'\n    result[slice_start_idx:slice_end_idx] = test_pred[col_name].values\nresult = pd.DataFrame(result, columns=['sales'])\nresult.index.name = 'id'\nresult.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result.to_csv('submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}