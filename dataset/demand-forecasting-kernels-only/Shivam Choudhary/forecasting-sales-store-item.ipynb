{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport fbprophet\nfrom fbprophet import Prophet","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_data = pd.read_csv('../input/demand-forecasting-kernels-only/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Analysis of the sales data store and item level","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Store ids\ntrain_data.store.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# item ids\ntrain_data.item.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pivot = train_data.pivot_table(index= 'item',columns='store',values='sales')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Item wise sales average\nitem_pivot = pivot.mean(axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"item_pivot.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Max Average sales for an item across stores:',item_pivot.max())\nprint('Min Average sales for an item across stores:',item_pivot.min())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Low volume item is defined as having average sales less than 30 , medium volume sales is defined as average sales between 30 and 60,\n# High volume item is defined as having average sales greater than 60\nitems_low_vol = list(item_pivot[item_pivot<30].index)\nitems_med_vol = list(item_pivot[(30<=item_pivot)&(item_pivot<60)].index)\nitems_high_vol = list(item_pivot[60<=item_pivot].index)\n\nprint('Low volume stores list:',items_low_vol)\nprint('Medium volume stores list:',items_med_vol)\nprint('High volume stores list:',items_high_vol)\n\nprint('Count of Low volume stores list:',len(items_low_vol))\nprint('Count of Medium volume stores list:',len(items_med_vol))\nprint('Count of High volume stores list:',len(items_high_vol))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pivot_store = train_data.pivot_table(index='store',values='sales')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pivot_store.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Max Average sales for a store:',pivot_store.max())\nprint('Min Average sales for a store:',pivot_store.min())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Low volume store is defined as having average sales less than 45 , medium volume store sales is defined as average sales between 45 and 55,\n# High volume store is defined as having average sales greater than 55\n\nstores_low_vol = list(pivot_store[pivot_store['sales']<45].index)\nstores_med_vol = list(pivot_store[(45<=pivot_store['sales'])&(pivot_store['sales']<55)].index)\nstores_high_vol = list(pivot_store[55<=pivot_store['sales']].index)\n\nprint('Low volume stores list:',stores_low_vol)\nprint('Medium volume stores list:',stores_med_vol)\nprint('High volume stores list:',stores_high_vol)\n\nprint('Count of Low volume stores list:',len(stores_low_vol))\nprint('Count of Medium volume stores list:',len(stores_med_vol))\nprint('Count of High volume stores list:',len(stores_high_vol))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_analysis = train_data.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_analysis['date'] = pd.to_datetime(train_data_analysis['date'])\ntrain_data_analysis['dayofweek'] = train_data_analysis['date'].apply(lambda x: x.dayofweek)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_analysis['month'] = train_data_analysis['date'].apply(lambda x: x.month)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Observing the average sales on different days of week  and different months using pivot","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pivot_weekdays = train_data_analysis.pivot_table(index='store',columns='dayofweek',values='sales')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pivot_months = train_data_analysis.pivot_table(index='store',columns='month',values='sales')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pivot_weekdays\n# 0 represents Monday and 6 represents sundays","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **From the values obtained above and the plot below ,it can be inferred that the sales is higher during weekend(saturdays and sundays) for every store**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the average sales daywise for everystore\n%matplotlib inline\nfig, axs = plt.subplots(10,figsize=(30,25))\nfor i in range(10):\n    store = pivot_weekdays.index[i]\n    value_list = pivot_weekdays[pivot_weekdays.index==store].values.T\n    axs[i].plot(value_list)\n    axs[i].set(xlabel='dayofweek', ylabel='Average Sales')\n    axs[i].set_title(f'Store_{store}_Sales_average day wise')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(10,figsize=(30,25))\nfor i in range(10):\n    store = pivot_months.index[i]\n    value_list = pivot_months[pivot_months.index==store].values.T\n    axs[i].plot(value_list)\n    axs[i].set(xlabel='month', ylabel='Average Sales')\n    axs[i].set_title(f'Store_{store}_Sales_average month wise')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_analysis['year'] = train_data_analysis['date'].apply(lambda x: x.year)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting Seasonal plots for Store-1 , item 2(Low Volume)\nstore=1\nitem =2\ndf = train_data_analysis[(train_data_analysis['store']==1)&(train_data_analysis['item']==2)].reset_index(drop=True)\nyears = df['year'].unique()\nnp.random.seed(100)\nmycolors = np.random.choice(list(mpl.colors.XKCD_COLORS.keys()), len(years), replace=False)\n\n# Draw Plot\nno_plots = len(years)\nfig,ax = plt.subplots(no_plots,figsize=(30,30))\nfor i, y in enumerate(years):\n    ax[i].plot('date','sales', data=df.loc[df.year==y, :].reset_index(drop=True), color=mycolors[i], label=y)\n    ax[i].set(xlabel='date', ylabel='Sales')\n    ax[i].set_title(f'Store_{store}_item_{item}_Sales_value daily plot for year {y}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As Can be seen from the plot, the data has yearly seasonality with relatively higher values from may till september with peak coming between June and July every year. \n\nAlso, Looking at the average daily sales for every store daywise, it can be inferred that the sales is higher during weekends. \n\nThe sales also see a drop in sales in December every year.\n\nThe data in our case has an yearly seasonality.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Using Prophet for result Generation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_prophet_forecast(data,test_length,store,item):\n    prophet_forecast_obj = Prophet(yearly_seasonality=True)\n    prophet_forecast_obj.fit(data)\n    dateframes = prophet_forecast_obj.make_future_dataframe(periods=test_length,include_history=False)\n    ypredict = prophet_forecast_obj.predict(dateframes)\n    final_data = ypredict[['ds','yhat']]\n    final_data['store'] = store\n    final_data['item'] = item\n    final_data = final_data[['ds','store','item','yhat']]\n    final_data = final_data.rename(columns={'ds':'date','yhat':'sales_forecast_prophet'})\n    final_data = final_data.sort_values(by='date').reset_index(drop=True)\n    return final_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def submission_file(final_result,test_data):\n    test_data['date'] = pd.to_datetime(test_data['date'])\n    merged_file = test_data.merge(final_result,on=['store','item','date'],suffixes=('','_drop'))\n    merged_new = merged_file.sort_values(by=['store','item','date']).reset_index(drop=True)\n    merged_part = merged_new[['id','sales_forecast_prophet']]\n    merged_part = merged_part.rename(columns={'sales_forecast_prophet':'sales'})\n    merged_part = merged_part.sort_values(by='id').reset_index(drop=True)\n    return merged_part","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_time_series_prophet(data,store,item):\n    data_store = data[(data.store==store)&(data.item==item)].reset_index(drop=True)\n    data_prophet = data_store[['date','sales']]\n    data_prophet = data_prophet.rename(columns={'date':'ds','sales':'y'})\n    return data_prophet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_all_stores_forecast(data,test_length):\n    final_result = pd.DataFrame()\n    for store in data.store.unique():\n        for item in data.item.unique():\n            data_part = get_time_series_prophet(data,store,item)\n            final_data = generate_prophet_forecast(data_part,test_length,store,item)\n            final_result = final_result.append(final_data)\n            print(f'Store Number :{store} , item number :{item} done')\n    \n    final_result = final_result.reset_index(drop=True)\n    final_result = final_result.sort_values(by=['store','item','date']).reset_index(drop=True)\n    return final_result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_length = 90\nfinal_result = generate_all_stores_forecast(train_data,test_length)\nfinal_result.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = pd.read_csv('../input/demand-forecasting-kernels-only/test.csv')\nsubmission_df = submission_file(final_result,test_data)\nsubmission_df.head()\nsubmission_df.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}