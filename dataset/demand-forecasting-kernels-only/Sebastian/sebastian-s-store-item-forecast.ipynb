{"cells":[{"metadata":{"_uuid":"6da71903c75f2c8f016320775c099fb768a49027"},"cell_type":"markdown","source":"# Sebastian Oglaza - Implementation Essay 2\n*Machine Learning for Demand Forecasting*\n\nThe notebook is meant to apply some basic data analytics techniques to https://www.kaggle.com/c/demand-forecasting-kernels-only/overview/description Kaggle challenge.\n\n# Data, goal and evaluation\n\n**Data:** You are given 5 years of store-item sales for 50 different items at 10 different stores\n\n**Goal:** The goal is to predict 3 months of sales for all stores and items\n\n**Evaluation:** The evaluation metirc is SMAPE (Symmetric Mean Absolute Percentage Error) - https://en.wikipedia.org/wiki/Symmetric_mean_absolute_percentage_error\n\n"},{"metadata":{},"cell_type":"markdown","source":"\n# Exploratory Data Analysis (EDA)\n\nEDA allows us to get some \"feel\" of the data through e.g. visualization\n"},{"metadata":{},"cell_type":"markdown","source":"**1. Load the libraries**"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport gc\nimport matplotlib.pyplot as plt\nimport os","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"43812220dac41c2cb1a341c93259549550a78a87"},"cell_type":"markdown","source":"**2. Load the train and test data**"},{"metadata":{"trusted":true,"_uuid":"a8a11570616b6cab1e78f53e60c91163f969577d"},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**3. Look at the train and test data format and sample data**"},{"metadata":{"trusted":true,"_uuid":"3c8cb618522b369b2f3a6d87e467c1240c98ac04"},"cell_type":"code","source":"print(\"Train Data\")\nprint(train.shape)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Test Data\")\nprint(test.shape)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**4. Transform the data**\n\nWe split the **Data** column into 3 columns: **Year**, **Month**, **Day**.\nWe use the original Date column as the index."},{"metadata":{"trusted":true,"_uuid":"3657517023627a1af8b7c2ad2fb0b7c9c9104afd"},"cell_type":"code","source":"train_eda = train.copy()\ntrain_eda.index = pd.to_datetime(train_eda['date'])\ntrain_eda.drop('date', axis=1, inplace=True)\ntrain_eda['year']=train_eda.index.year\ntrain_eda['month']=train_eda.index.month\ntrain_eda['weekday']=train_eda.index.weekday\ntrain_eda.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d78f5548dd4a0af179dfd86e34d55260b6dca9b4"},"cell_type":"markdown","source":"**4. Visualize the data **\n\nLet's plot the item sales and store sales trends by the year.\n\nWe see that both Item and Store sales and increasing year over year.\n"},{"metadata":{"trusted":true,"_uuid":"8878db75e1c7ee7178326bd70f6cb470225e2f5a"},"cell_type":"code","source":"agg_year_item = pd.pivot_table(train_eda, index='year', columns='item',values='sales', aggfunc=np.mean).values\nagg_year_store=pd.pivot_table(train_eda,index='year',columns='store',values='sales',aggfunc=np.mean).values\n\nplt.plot(agg_year_item / agg_year_item.mean(0)[np.newaxis])\nplt.title('Item sales per year')\nplt.xlabel('Year')\nplt.ylabel('Item sales')\nplt.show()\n\nplt.plot(agg_year_store/agg_year_store.mean(0)[np.newaxis])\nplt.title('Store sales per year')\nplt.xlabel('Year')\nplt.ylabel('Store sales')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"26551c6ebe074e08714fc9633f25d3cd34c50a38"},"cell_type":"markdown","source":"**5. Decomposition **\n\nFrom https://otexts.com/fpp2/decomposition.html\n\n*Time series data can exhibit a variety of patterns, and it is often helpful to split a time series into several components, each representing an underlying pattern category.*\n\nWe decompose our timeseries data into three components:\n* trend-cycle\n* seasonal component\n* remainder component"},{"metadata":{"trusted":true,"_uuid":"1af8a9bde58d140fa9559fe8f47e15cf8c0b0f14"},"cell_type":"code","source":"import statsmodels.api as sm\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 18, 8\n\ndf_7_9=train_eda[(train_eda['store']==7) & (train_eda['item']==9)]['sales'].resample('MS').sum()\ndecomposition = sm.tsa.seasonal_decompose(df_7_9, model='additive')\nfig = decomposition.plot()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Now, let's try some actual forecasting"},{"metadata":{},"cell_type":"markdown","source":"We will use a very simple method of using CAGR (Comound Anual Growth Rate) for the forecasting of future sales."},{"metadata":{"trusted":true,"_uuid":"bad356b052030c46510625b143aa772520513978"},"cell_type":"code","source":"# Define SMAPE function, to measure the results\ndef smape(y_true, y_pred):\n    denominator = (np.abs(y_true) + np.abs(y_pred)) / 200.0\n    diff = np.abs(y_true - y_pred) / denominator\n    diff[denominator == 0] = 0.0\n    return np.nanmean(diff)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2eb06be478d9b8722084ef72b579a686fcb03f0b"},"cell_type":"code","source":"# The algorithm is borrowed from this kernel https://www.kaggle.com/sgorlick/4th-place-sol-n\n\n# Concatenate train and test\ncols=list(train.columns)\nx = pd.concat([train,test],axis=0, sort=False).reset_index(drop=True)\nx = x.loc[:,cols]\n\n# Index to timestamp, add year number, month and weekday as new features\nx.index=pd.to_datetime(x.date)\nx.drop('date',axis=1,inplace=True)\n\nx['year'] =  x.index.year - min(x.index.year) + 1\nx['month'] = x.index.month\nx['weekday'] = x.index.weekday\n\n# Create monthly summary\nmonth_smry= (\n        ( x.groupby(['month']).agg([np.nanmean]).sales - np.nanmean(x.sales) ) / np.nanmean(x.sales)\n).rename(columns={'nanmean':'month_mod'})\nx = x.join(month_smry,how='left',on='month')\n\n# Create yearly summary\nyear_smry= (\n        ( x.groupby(['year']).agg([np.nanmean]).sales - np.nanmean(x.sales) ) / np.nanmean(x.sales)\n).rename(columns={'nanmean':'year_mod'})\n\n# Calculate CAGR(Compound Annually Growth Rate) from the 2nd year to the 5th year. \nCAGR = (x[x.year==5].groupby(['store','item']).agg(np.nanmean).sales /\n        x[x.year==2].groupby(['store','item']).agg(np.nanmean).sales )**(1/4)-1\n\n# Fill year_mod field for the test year by the following calculation  \nyear_smry.loc[6,:] =  np.mean(CAGR)*3\nx=x.join(year_smry,how='left',on='year')\n\n# Create weekday summary\nweekday_smry= (\n        ( x.groupby(['weekday']).agg([np.nanmean]).sales - np.nanmean(x.sales) ) / np.nanmean(x.sales)\n).rename(columns={'nanmean':'weekday_mod'})\nx=x.join(weekday_smry,how='left',on='weekday')\n\n# Create store summary\nstore_item_smry= (\n        ( x.groupby(['store','item']).agg([np.nanmean]).sales - np.nanmean(x.sales) ) / np.nanmean(x.sales)\n).rename(columns={'nanmean':'store_item_mod'})\nx=x.join(store_item_smry,how='left',on=['store','item'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Final step - predict the sales for the first 3 months\n\nThe accuracy of forecasting is measured using SMAPE (Symmetric Mean Absolute Percentage Error) which is the measure based on percentage (or relative) errors. "},{"metadata":{"trusted":true,"_uuid":"35fd368e306c6a24c633cf1087ad4136204a84a3"},"cell_type":"code","source":"# Predict the sales\nx['smry_product']=np.product(x.loc[:,['month_mod','year_mod','weekday_mod','store_item_mod',]]+1,axis=1)\nx['sales_mod_pred']=np.round(x.smry_product*np.round(np.nanmean(x.sales),1))\n\nprint(smape(x.sales[x.month < 4],x.sales_mod_pred[x.month < 4]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Our forecasting accuracy, SMAPE = **14%**"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}