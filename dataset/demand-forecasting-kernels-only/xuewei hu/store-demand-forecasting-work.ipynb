{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Part 1: Import Data and EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings \nwarnings.filterwarnings('ignore')\nimport numpy as np \nimport pandas as pd \n\nfrom math import sqrt\nfrom sklearn.metrics import mean_squared_error\n\n%matplotlib inline\nimport matplotlib.pyplot as plt  \nimport seaborn as sns\nimport statsmodels.api as sm\n\nimport plotly as py\nimport plotly.graph_objs as go\nfrom plotly.offline import init_notebook_mode, iplot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample = pd.read_csv('/kaggle/input/demand-forecasting-kernels-only/sample_submission.csv')\ntrain = pd.read_csv('/kaggle/input/demand-forecasting-kernels-only/train.csv',parse_dates=['date'])\ntest = pd.read_csv('/kaggle/input/demand-forecasting-kernels-only/test.csv',parse_dates=['date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train and Test shape are {} and {} respectively\".format(train.shape,test.shape))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print(\"Min date from train set: {}\".format(train.date.min()))\nprint(\"Max date from train set: {}\".format(train.date.max()))\nprint(\"Min date from test set: {}\".format(test.date.min()))\nprint(\"Max date from test set: {}\".format(test.date.max()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"forecast period is 3 months. There are 10 stores and 50 items. 500 combinations of stores and items."},{"metadata":{},"cell_type":"markdown","source":"## Overall daily sales"},{"metadata":{"trusted":true},"cell_type":"code","source":"daily_sales = train.groupby('date', as_index=False)['sales'].sum()\ndaily_sales_sc = go.Scatter(x = daily_sales['date'], y = daily_sales['sales'])\nfig = go.Figure(data = daily_sales_sc)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Yearly pattern with larger scale near July and lower volume near beginning of years and uptrend is shown."},{"metadata":{},"cell_type":"markdown","source":"# Overall weekly sales"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"train['weekday'] = train['date'].dt.weekday\nweek_sales = train.groupby('weekday', as_index = False).sales.mean()\nweek_sales_sc = go.Scatter(x = week_sales['weekday'], y = week_sales['sales'])\nfig = go.Figure(data = week_sales_sc)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Saturday and Sunday showing larger sales than weekdays."},{"metadata":{},"cell_type":"markdown","source":"## Daily Sales by Store"},{"metadata":{"trusted":true},"cell_type":"code","source":"store_sales = train.groupby(['date','store'], as_index = False)['sales'].sum()\nstore_sales_sc = []\nfor store in store_sales.store.unique():\n    current_store = store_sales[(store_sales['store'] == store)]\n    store_sales_sc.append(go.Scatter(x = current_store['date'], y = current_store['sales'],\n                                    name = ('store %s' % store)))\nfig = go.Figure(data = store_sales_sc)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Seasonality and trend for each store are similar"},{"metadata":{},"cell_type":"markdown","source":"## Daily sales by item"},{"metadata":{"trusted":true},"cell_type":"code","source":"item_sales = train.groupby(['date','item'], as_index = False)['sales'].sum()\nitem_sales_sc = []\nfor item in item_sales['item'].unique():\n    current_item = item_sales[item_sales['item'] == item]\n    item_sales_sc.append(go.Scatter(x = current_item['date'], y = current_item['sales'],\n                                   name = 'item %s' % item))\nfig = go.Figure(data = item_sales_sc)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Seasonality and trend for each item are similar"},{"metadata":{},"cell_type":"markdown","source":"# Part 2: ARIMA, SARIMA, SARIMAX"},{"metadata":{},"cell_type":"markdown","source":"## Method 1: auto.arima find p, d, q"},{"metadata":{"trusted":true},"cell_type":"code","source":"#As store and item following similar patterns, take store 1 and item 1 to study the time series parameters\ntrain_1 = train[(train['store']==1) & (train['item'] == 1)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_1_df = train_1[:(len(train_1)-90)]\nvalid_1_df = train_1[len(train_1)-90:len(train_1)]\n\ntrain_1_df.drop(columns = ['store','item','weekday'], inplace=True)\nvalid_1_df.drop(columns = ['store','item','weekday'], inplace=True)\n\ntrain_1_df = train_1_df.set_index('date')\nvalid_1_df = valid_1_df.set_index('date')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#built the model\n!pip install pmdarima\nfrom pmdarima import auto_arima\n\nstepwise_model = auto_arima(train_1_df,m=7,\n                           seasonal=True,\n                           trace=True,\n                           error_action='ignore',\n                           suppress_warnings=True,\n                           stepwise=True)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"stepwise_model.fit(train_1_df)\nforecast_stp = stepwise_model.predict(n_periods=len(valid_1_df))\nforecast_stp = pd.DataFrame(forecast_stp, index = valid_1_df.index, columns=['Prediction'])\n\nfig, ax = plt.subplots(figsize=(12,6))\n# plt.plot(train_1_df, label='Train')\nplt.plot(valid_1_df, label='Valid')\nplt.plot(forecast_stp, label='Prediction')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#calculate mse, mape, smape\nmse1 = \"{:.2%}\".format(sqrt(mean_squared_error(valid_1_df,forecast_stp))/100)\ny_true = valid_1_df.sales\ny_pred = forecast_stp.Prediction\nmape1 =\"{:.2%}\".format(np.mean(abs((y_true-y_pred)/y_true)))\nsmape1 = \"{:.2%}\".format(np.mean((np.abs(y_pred - y_true) * 2/ (np.abs(y_pred) + np.abs(y_true))).fillna(0)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stepwise_model.plot_diagnostics(figsize=(16, 8))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Residuals following in Normal and no correlation."},{"metadata":{"trusted":true},"cell_type":"code","source":"model_eval = pd.DataFrame(data = np.array([['(3,1,1)(1,0,1)[7]',10335.10,mse1,mape1,smape1,'Pass']]),\n                         columns = ['model','AIC','MSE','MAPE','MAPE','Residual Test'])\nmodel_eval = model_eval.set_index('model')\nmodel_eval","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Method 2: ACF and PACF results determine p, d, q"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_1 = train_1.set_index('date')\ntrain_1.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### a. stationarity check"},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.stattools import adfuller\ndef test_stationarity(timeseries, window = 12, cutoff = 0.01):\n    #Dickey-Fuller test:\n    print('Results of Dickey-Fuller Test:')\n    dftest = adfuller(timeseries, autolag='AIC', maxlag = 20 )\n    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n    for key,value in dftest[4].items():\n        dfoutput['Critical Value (%s)'%key] = value\n    pvalue = dftest[1]\n    if pvalue < cutoff:\n        print('p-value = %.4f. The series is likely stationary.' % pvalue)\n    else:\n        print('p-value = %.4f. The series is likely non-stationary.' % pvalue)\n    \n    print(dfoutput)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_stationarity(train_1['sales'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Differencing is needed for this time series"},{"metadata":{},"cell_type":"markdown","source":"### b. Differencing"},{"metadata":{"trusted":true},"cell_type":"code","source":"first_diff = train_1.sales - train_1.sales.shift(1)\nfirst_diff = first_diff.dropna(inplace = False)\ntest_stationarity(first_diff)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Differencing once is good enough to stationarize the time serise."},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\nfig = plt.figure(figsize=(12,8))\nax1 = fig.add_subplot(211)\nfig = sm.graphics.tsa.plot_acf(first_diff, lags=40, ax=ax1)\nax2 = fig.add_subplot(212)\nfig = sm.graphics.tsa.plot_pacf(first_diff, lags=40, ax=ax2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we can see the acf and pacf both has a recurring pattern every 7 periods. Indicating a weekly pattern exists. \n\n1. AR lags significant at 6.\n2. Spike at lag 7,14,21,28,35.. in the ACF \n   Exponential decay in the seasonal lags of the PACF (i.e., at lags 7, 14, â€¦).\n   Suggested seasonal order of (0,1,1,7)"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_1 = train[(train['store']==1)&(train['item']==1)]\ntrain_1 = train_1.set_index('date')\nstart_index = '2017-10-01'\nend_index = '2017-12-31'\nend_index1 = '2017-12-30'\n\nsarima_mod7 = sm.tsa.statespace.SARIMAX(endog = train_1.sales[:start_index],\n                                         order=(7,1,0),\n                                         seasonal_order=(0,1,1,7),\n                                         freq='D').fit()\n\ntrain_1['forecast'] = sarima_mod7.predict(start = pd.to_datetime(start_index), \n                                           end= pd.to_datetime(end_index),\n                                           dynamic= True) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_1[start_index:end_index1][['sales', 'forecast']].plot(figsize=(12, 8))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#calculate mse, mape, smape\nmse2 = \"{:.2%}\".format(sqrt(mean_squared_error(train_1[start_index:end_index]['sales'],\n                                                             train_1[start_index:end_index]['forecast']))/100)\ny_true = train_1[start_index:end_index1]['sales']\ny_pred = train_1[start_index:end_index1]['forecast']\n\nmape2 =\"{:.2%}\".format(np.mean(abs((y_true-y_pred)/y_true)))\nsmape2 = \"{:.2%}\".format(np.mean((np.abs(y_pred - y_true) * 2/ (np.abs(y_pred) + np.abs(y_true))).fillna(0)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mse = sqrt(mean_squared_error(train_1[start_index:end_index]['sales'],\n                                                             train_1[start_index:end_index]['forecast']))\nprint('MSE: %.2f %% \\nAIC: %.2f'% (mse,sarima_mod7.aic))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sarima_mod7.plot_diagnostics(figsize=(16, 8))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ACF and PACF\nfig = plt.figure(figsize=(12,8))\nax1 = fig.add_subplot(211)\nfig = sm.graphics.tsa.plot_acf(sarima_mod7.resid, lags=40, ax=ax1)\nax2 = fig.add_subplot(212)\nfig = sm.graphics.tsa.plot_pacf(sarima_mod7.resid, lags=40, ax=ax2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Residuals correlated"},{"metadata":{"trusted":true},"cell_type":"code","source":"model2 = pd.DataFrame(data = [[sarima_mod7.aic,mse2,mape2,smape2,'Fail']],\n                     columns = model_eval.columns,\n                     index = ['(7,1,0)(0,1,1)[7]'])\nmodel_eval = model_eval.append(model2)\nmodel_eval","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Method 3: grid search find p,d,q"},{"metadata":{"trusted":true},"cell_type":"code","source":"import itertools\n\np = range(2,5)\nd = range(1,2)\nq = range(0,2)\nsp = sd = sq = range(0,2)\npdq = list(itertools.product(p, d, q))\nseasonal_pdq = list(itertools.product(sp, sd, sq))\nprint('Examples of parameter combinations for Seasonal ARIMA...')\nprint('SARIMAX: {} x {}'.format(pdq[1], seasonal_pdq[0]))\nprint('SARIMAX: {} x {}'.format(pdq[1], seasonal_pdq[1]))\nprint('SARIMAX: {} x {}'.format(pdq[2], seasonal_pdq[2]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start_index = '2017-10-01'\nfor param in pdq:\n    for param_seasonal in seasonal_pdq:\n        try:\n            mod = sm.tsa.statespace.SARIMAX(train_1.sales[:start_index],order=param,\n                                            seasonal_order=param_seasonal,\n                                            enforce_stationarity=False,\n                                            enforce_invertibility=False,\n                                            freq='D')\n            \n            results = mod.fit()\n            print('ARIMA{}x{}7 - AIC:{}'.format(param, param_seasonal, results.aic))\n        except:\n            continue\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_1 = train[(train['store']==1)&(train['item']==1)]\ntrain_1 = train_1.set_index('date')\nstart_index = '2017-10-01'\nend_index = '2017-12-31'\nend_index1 = '2017-12-30'\n\nsarima_mod7 = sm.tsa.statespace.SARIMAX(endog = train_1.sales[:start_index],\n                                         order=(7,1,0),\n                                         seasonal_order=(0,1,1,7),\n                                         freq='D').fit()\n\ntrain_1['forecast'] = sarima_mod7.predict(start = pd.to_datetime(start_index), \n                                           end= pd.to_datetime(end_index),\n                                           dynamic= True) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SARIMAX: adding external variables"},{"metadata":{},"cell_type":"markdown","source":"### c.SARIMAX external variables: month, day of week"},{"metadata":{},"cell_type":"markdown","source":"From the EDA results, yearly pattern will be taken into account in the seasonality parameters, weekly effect and monthly effect will be put as external variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"train['year'] = train['date'].dt.year - 2012\ntrain['month'] = train['date'].dt.month\ntrain['weekday'] = train['date'].dt.weekday\n\ntrain = pd.get_dummies(train, columns = ['year','month','weekday'] , prefix = ['year','month','weekday'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_1 = train[(train['store']==1)&(train['item']==1)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ext_var_list = [ 'date', 'year_1','year_2','year_3','year_4','year_5',\n       'month_1', 'month_2', 'month_3', 'month_4', 'month_5', 'month_6',\n       'month_7', 'month_8', 'month_9', 'month_10', 'month_11', 'month_12', 'weekday_0',\n       'weekday_1', 'weekday_2', 'weekday_3', 'weekday_4', 'weekday_5',\n       'weekday_6']\n\nexog_data = train_1[ext_var_list]\nexog_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_1 = train_1.set_index('date')\nexog_data = exog_data.set_index('date')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"exog_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start_index = '2017-10-01'\nend_index = '2017-12-31'\nend_index1 = '2017-12-30'#predict 90 days","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sarimax_mod7 = sm.tsa.statespace.SARIMAX(endog = train_1.sales[:start_index],\n                                         exog = exog_data[:start_index],\n                                         order=(7,1,0),\n                                         seasonal_order=(0,1,1,7),\n                                         freq='D').fit()\nsarimax_mod7.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sarimax_mod3 = sm.tsa.statespace.SARIMAX(endog = train_1.sales[:start_index],\n                                         exog = exog_data[:start_index],\n                                         order=(3,1,1),\n                                         seasonal_order=(1,0,1,7),\n                                         freq='D').fit()\nsarimax_mod3.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_1['forecast_7'] = sarimax_mod7.predict(start = pd.to_datetime(start_index), \n                                           end= pd.to_datetime(end_index), \n                                           exog = exog_data[start_index:end_index1], \n                                           dynamic= True)  \ntrain_1['forecast_3'] = sarimax_mod3.predict(start = pd.to_datetime(start_index), \n                                           end= pd.to_datetime(end_index), \n                                           exog = exog_data[start_index:end_index1], \n                                           dynamic= True)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_1[start_index:end_index1][['sales', 'forecast_7','forecast_3']].plot(figsize=(12, 8))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#calculate mse, mape, smape\nmse7 = \"{:.2%}\".format(sqrt(mean_squared_error(train_1[start_index:end_index]['sales'],\n                                                             train_1[start_index:end_index]['forecast_7']))/100)\ny_true = train_1[start_index:end_index1]['sales']\ny_pred = train_1[start_index:end_index1]['forecast_7']\n\nmape7 =\"{:.2%}\".format(np.mean(abs((y_true-y_pred)/y_true)))\nsmape7 = \"{:.2%}\".format(np.mean((np.abs(y_pred - y_true) * 2/ (np.abs(y_pred) + np.abs(y_true))).fillna(0)))\nprint('SARIMAX (7,1,0)(0,1,1,7) \\nAIC: %.2f'% (sarimax_mod7.aic), '\\nMSE: ',mse7,'\\nMAPE: ',mape7, '\\nSMAPE: ', smape7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#calculate mse, mape, smape\nmse3 = \"{:.2%}\".format(sqrt(mean_squared_error(train_1[start_index:end_index]['sales'],\n                                                             train_1[start_index:end_index]['forecast_3']))/100)\ny_true = train_1[start_index:end_index1]['sales']\ny_pred = train_1[start_index:end_index1]['forecast_3']\n\nmape3 =\"{:.2%}\".format(np.mean(abs((y_true-y_pred)/y_true)))\nsmape3 = \"{:.2%}\".format(np.mean((np.abs(y_pred - y_true) * 2/ (np.abs(y_pred) + np.abs(y_true))).fillna(0)))\nprint('SARIMAX (7,1,0)(0,1,1,7) \\nAIC: %.2f'% (sarimax_mod7.aic), '\\nMSE: ',mse3,'\\nMAPE: ',mape3, '\\nSMAPE: ', smape3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy import stats\nfrom scipy.stats import normaltest\n\nresid = sarimax_mod7.resid\nprint(normaltest(resid))\n\nfig = plt.figure(figsize=(12,8))\nax0 = fig.add_subplot(111)\n\nsns.distplot(resid ,fit = stats.norm, ax = ax0) \n(mu, sigma) = stats.norm.fit(resid)\n\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)], loc='best')\nplt.ylabel('Frequency')\nplt.title('Residual distribution')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resid = sarimax_mod3.resid\nprint(normaltest(resid))\n\nfig = plt.figure(figsize=(12,8))\nax0 = fig.add_subplot(111)\n\nsns.distplot(resid ,fit = stats.norm, ax = ax0) \n(mu, sigma) = stats.norm.fit(resid)\n\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)], loc='best')\nplt.ylabel('Frequency')\nplt.title('Residual distribution')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sarimax_mod7.plot_diagnostics(figsize=(16, 8))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sarimax_mod3.plot_diagnostics(figsize=(16, 8))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prediction on test dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/demand-forecasting-kernels-only/train.csv' ,parse_dates=['date'],index_col='date')\ntest = pd.read_csv('/kaggle/input/demand-forecasting-kernels-only/test.csv', parse_dates=['date'],index_col='date')\nsample = pd.read_csv('/kaggle/input/demand-forecasting-kernels-only/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.concat([train,test],sort=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#month one hot encoding\ndf['year'] = df.index.year - 2012\ndf['month'] = df.index.month\ndf['dayofweek'] = df.index.weekday\ndf = pd.get_dummies(df, columns = ['year','month','dayofweek'],prefix = ['year','month','dayofweek'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = []\ntr_start,tr_end = '2013-01-01','2017-09-30'\nte_start,te_end = '2017-10-01','2017-12-31'\nfor i in range(1,51):\n    for s in range(1,11):\n        cur_df = df[(df.item==i)&(df.store==s)].copy()\n        \n        #train_test_split\n        tra = cur_df['sales'][tr_start:tr_end]\n        tes = cur_df['sales'][te_start:te_end]\n        exog_train = cur_df.drop(['id','store','item','sales'],axis = 1)[tr_start:tr_end]\n        exog_test = cur_df[te_start:].drop(['id','store','item','sales'],axis = 1)#exog for predict.\n        \n        \n        #fitting\n        mod = sm.tsa.statespace.SARIMAX(tra,order=(3,1,1),seasonal_order=(1,0,1,7),exog = exog_train,freq='D',\n                                       enforce_stationarity=False, enforce_invertibility=False).fit()\n        pred = mod.get_prediction(tr_end,'2018-03-31',exog =exog_test)#pd.concat([exog_test,target_exog]))\n        results.extend(pred.predicted_mean['2018-01-01':])\n        print('item:',i,'store:',s,'Finished.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample['sales'] = results\nsample.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}