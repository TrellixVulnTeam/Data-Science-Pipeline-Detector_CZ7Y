{"cells":[{"metadata":{"_uuid":"b1a1660563595e45a2a06503ee8a9a3c2d3e42f8"},"cell_type":"markdown","source":"## This kernel is for ongoing Avito Demand Prediction Challenge\n\nhttps://www.kaggle.com/c/avito-demand-prediction"},{"metadata":{"_cell_guid":"033852ed-2dd3-4bc3-bec1-ac3481ab175f","_kg_hide-input":true,"_uuid":"af7422df064b7f16934cca9e86e8213bc9c667e8","collapsed":true,"trusted":false},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport gc\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib_venn import venn2, venn2_circles\nimport string\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nimport nltk\nfrom nltk.corpus import stopwords\nimport scipy\nimport lightgbm as lgb\n\nsns.set()\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"94a03718-1718-4981-88ef-532efcb435ee","_uuid":"5d8e0a1a86fe5fbfa5162d3180d0b1ebea94f97d"},"cell_type":"markdown","source":"# Data Loading\n"},{"metadata":{"_cell_guid":"bc719fcf-f418-4db5-a4fa-ebfa27716521","_uuid":"02aad0b977053435e089bd189ea45e4a88731e87","collapsed":true,"trusted":false},"cell_type":"code","source":"train = pd.read_csv('../input/avito-demand-prediction/train.csv')\ntest = pd.read_csv('../input/avito-demand-prediction/test.csv')\ngp = pd.read_csv('../input/aggregated-features-lightgbm/aggregated_features.csv') #this is the xtra dataset which i have created \n                                                                                    #ll upload it within Zip\ntrain = train.merge(gp, on='user_id', how='left')\ntest = test.merge(gp, on='user_id', how='left')\n\nagg_cols = list(gp.columns)[1:]\n\ndel gp\ngc.collect()\n\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f00431301258b0f2f071d32489f12826ac921734"},"cell_type":"markdown","source":"# Feature Engineering\n### Text cleaning does not help So, I am commenting them"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"246908dcf7cb47d073374b7cd83b05f750f91111"},"cell_type":"code","source":"# def cleanup(s):                      \n#     \"\"\"\n#     function to clean text data\n    \n#     \"\"\"\n#     s = str(s)\n#     s = s.lower()\n# #     s = re.sub('\\s\\W',' ',s)\n# #     s = re.sub(\"https\\S+\\w+\",\"\",s)\n# #     s=[word if word not in ss else \"\" for word in TweetTokenizer().tokenize(s)]\n# #     s = \" \".join(s)\n# #     s = re.sub('rt*.@\\w+',' ',s)\n# #     s = re.sub('@\\w+',' ',s)\n# #     s = re.sub('\\W,\\s',' ',s)\n# #     s = re.sub(r'[^\\w,]', ' ', s)\n#     s = re.sub(\"\\d+\", \"\", s)\n#     s = re.sub('\\s+',' ',s)\n#     s = re.sub('[!@#$_“”¨«»®´·º½¾¿¡§£₤‘’]', '', s)\n# #     s = s.replace(\".co\",\"\")\n# #     s = s.replace(\",\",\"\")\n# #     s = s.replace(\"[\\w*\",\" \")\n#     s = ''.join(''.join(a)[:2] for _, a in itertools.groupby(s))\n#     return s\n    ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"41e1111d-674e-4c86-b232-c0086832ee6d","_uuid":"9c60409e1dc6c618f229e15c2b368660385c2ec1","collapsed":true,"trusted":false},"cell_type":"code","source":"\n\nfor df in [train, test]:\n    df['description'].fillna('unknowndesc', inplace=True)\n    df['title'].fillna('unknowntitle', inplace=True)\n\n    df['weekday'] = pd.to_datetime(df['activation_date']).dt.day\n    \n    for col in ['description', 'title']:\n        df['num_words_' + col] = df[col].apply(lambda comment: len(comment.split()))\n        df['num_unique_words_' + col] = df[col].apply(lambda comment: len(set(w for w in comment.split())))\n\n    df['words_vs_unique_title'] = df['num_unique_words_title'] / df['num_words_title'] * 100\n    df['words_vs_unique_description'] = df['num_unique_words_description'] / df['num_words_description'] * 100\n    \n    df['city'] = df['region'] + '_' + df['city']\n    df['num_desc_punct'] = df['description'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\n    \n    for col in agg_cols:\n        df[col].fillna(-1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8d61ada6-8f3a-4b58-baad-199589122985","_uuid":"cc558a03cbddc3954b01783636785cdee6cf954a","collapsed":true,"trusted":false},"cell_type":"code","source":"count_vectorizer_title = CountVectorizer(stop_words=stopwords.words('russian'), lowercase=True, min_df=25)\n\ntitle_counts = count_vectorizer_title.fit_transform(train['title'].append(test['title']))\n\ntrain_title_counts = title_counts[:len(train)]\ntest_title_counts = title_counts[len(train):]\n\n\ncount_vectorizer_desc = TfidfVectorizer(stop_words=stopwords.words('russian'), \n                                        lowercase=True, ngram_range=(1, 2),\n                                        max_features=15000)\n\ndesc_counts = count_vectorizer_desc.fit_transform(train['description'].append(test['description']))\n\ntrain_desc_counts = desc_counts[:len(train)]\ntest_desc_counts = desc_counts[len(train):]\n\ntrain_title_counts.shape, train_desc_counts.shape\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"56338e56-c266-4342-a8f3-10621db49dee","_uuid":"cc6f15f981f05ad9b1e89ab7acb54ea2350278c6","collapsed":true,"trusted":false},"cell_type":"code","source":"target = 'deal_probability'\npredictors = [\n    'num_desc_punct', \n    'words_vs_unique_description', 'num_unique_words_description', 'num_unique_words_title', 'num_words_description', 'num_words_title',\n    'avg_times_up_user', 'avg_days_up_user', 'n_user_items', \n    'price', 'item_seq_number'\n]\ncategorical = [\n    'image_top_1', 'param_1', 'param_2', 'param_3', \n    'city', 'region', 'category_name', 'parent_category_name', 'user_type'\n]\n\npredictors = predictors + categorical","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7695c1a1-06cf-40e6-8792-77b62f48262a","_uuid":"0bcde9bb9b9b26347c7db7da47123c6fec40860e","collapsed":true,"trusted":false},"cell_type":"code","source":"for feature in categorical:\n    print(f'Transforming {feature}...')\n    encoder = LabelEncoder()\n    encoder.fit(train[feature].append(test[feature]).astype(str))\n    \n    train[feature] = encoder.transform(train[feature].astype(str))\n    test[feature] = encoder.transform(test[feature].astype(str))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f027ccf2a568c5b1e830cd45af5dbc3feade14ba"},"cell_type":"markdown","source":"# Hyper Parameter Tuning\n\n### I did it on cloud so I m just commenting it out to save time"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"d544a3b053f07507f1973bf6b9b2f02be78719a5"},"cell_type":"code","source":"# def objective(space):\n#     mod = lgb.LGBMRegressor(n_estimators = 5000, \n#             num_leaves = int(space['num_leaves']),\n#             subsample = space['subsample'],min_child_weight = space['min_child_weight'],\n#             colsample_bytree=space['colsample_bytree'],\n#             learning_rate =space['learning_rate'],n_jobs=-1,\n#                 )\n# #     temp_train=copy.copy(newtrain)\n#     folds=KFold(5,random_state=100)\n#     fold_score=[]\n#     i=1\n#     st=time.time()\n#     print('=================*=================')\n#     print(space)\n#     for train_index,test_index in folds.split(X=X):\n#         mod.fit(X=X[train_index],y=y.values[train_index],eval_set=[ (X[test_index],y.values[test_index])],early_stopping_rounds=20,verbose=30,eval_metric='rmse')    \n#         score=mod.best_score_.get('valid_0').get('rmse')\n#         print('cv',i,': ', score)\n#         i=i+1\n#         fold_score.append(score)                \n#     print(\"SCORE:\") \n#     print(np.mean(fold_score))\n#     print('time',time.time()-st)\n#     return 1-np.mean(fold_score) \n\n# space ={\n#     #'max_depth':hp.quniform('max_depth',2,10,1),\n#     'num_leaves': hp.quniform('num_leaves', 200, 300, 4),\n#     'min_child_weight': hp.quniform ('min_child_weight', 1, 2, 1),\n#     'subsample': hp.quniform ('subsample', 0.8, .95,0.05),\n#     'learning_rate': hp.quniform('learning_rate', 0.01,0.2,.03),\n#    # A problem with max_depth casted to float instead of int with\n#    # the hp.quniform method.\n# #     'gamma': hp.quniform('gamma', 0, 0.6, 0.1),\n#     'colsample_bytree': hp.quniform('colsample_bytree', 0.7, .95, 0.05),\n#    }  \n# trials = Trials()\n# best = fmin(fn=objective,space=space,algo=tpe.suggest,max_evals=80)\n# print(best)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c54cc62175be7e09528d05ac057b76e5471ef880"},"cell_type":"markdown","source":"# LightGBM \n"},{"metadata":{"_cell_guid":"7e94bcc4-ab56-4a38-bdcf-218791e95c2c","_uuid":"ac57e30cf4452005a2cb20db424d7bcf1f11d1df","collapsed":true,"trusted":false},"cell_type":"code","source":"rounds = 20000\nearly_stop_rounds = 50\nparams = {\n    'objective' : 'regression',\n    'metric' : 'rmse',\n    'num_leaves' : 300,\n#     'max_depth': 15,\n    'learning_rate' : 0.02,\n    'feature_fraction' : 0.75,\n    'bagging_fraction' : .85,\n    'verbosity' : -1\n}\n\nfeature_names = np.hstack([\n    count_vectorizer_desc.get_feature_names(),\n    count_vectorizer_title.get_feature_names(),\n    predictors\n])\nprint('Number of features:', len(feature_names))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9e910115-312f-4437-8ba3-9fb6f7426af8","_uuid":"1a50b3e34d76019fdbfd45c3566eec09556f24cb","collapsed":true,"trusted":false},"cell_type":"code","source":"train_index, valid_index = train_test_split(np.arange(len(train)), test_size=0.1, random_state=42)\n\nx_train = scipy.sparse.hstack([\n        train_desc_counts[train_index],\n        train_title_counts[train_index],\n        train.loc[train_index, predictors]\n], format='csr')\ny_train = train.loc[train_index, target]\n\nx_valid = scipy.sparse.hstack([\n    train_desc_counts[valid_index],\n    train_title_counts[valid_index],\n    train.loc[valid_index, predictors]\n], format='csr')\ny_valid = train.loc[valid_index, target]\n\nx_test = scipy.sparse.hstack([\n    test_desc_counts,\n    test_title_counts,\n    test.loc[:, predictors]\n], format='csr')\n\ndtrain = lgb.Dataset(x_train, label=y_train,\n                     feature_name=list(feature_names), \n                     categorical_feature=categorical)\ndvalid = lgb.Dataset(x_valid, label=y_valid,\n                     feature_name=list(feature_names), \n                     categorical_feature=categorical)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"cfc958c3-f045-49d4-8017-be7a60d7e18b","_uuid":"40209bda4fe8e803d8e56e0c98ed4ec0375eac94","collapsed":true,"trusted":false},"cell_type":"code","source":"evals_result = {}\nmodel = lgb.train(params, dtrain, \n                  valid_sets=[dtrain, dvalid], \n                  valid_names=['train', 'valid'],\n                  num_boost_round=rounds, \n                  early_stopping_rounds=early_stop_rounds, \n                  verbose_eval=100)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5827b4fb-0bfc-4ef2-ab43-5be682151de8","_uuid":"37cbdd3d10742d44e169a2db4386f7bb3c7b09bc","collapsed":true,"trusted":false},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10, 14))\nlgb.plot_importance(model, max_num_features=50, ax=ax)\nplt.title(\"Light GBM Feature Importance\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9d49a8cc-4b52-47f4-868a-f7b3006cd9f3","_uuid":"3c93c6232801704e05d2a94c38b7df77d7ed14f4","collapsed":true,"trusted":false},"cell_type":"code","source":"subm = pd.read_csv('../input/avito-demand-prediction/sample_submission.csv')\nsubm['deal_probability'] = np.clip(model.predict(x_test), 0, 1)\nsubm.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"01d0f98f66d1ea0d6132bf7ccfffaf9cfa35730f"},"cell_type":"markdown","source":"# This single modle scored .2229 on LB. I have done ensembling using different kernels and able to score .2215 on LB. "},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"4aed51c28648ec37d9fbc7427364a17223fe9958"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":1}