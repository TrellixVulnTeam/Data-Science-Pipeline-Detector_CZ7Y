{"cells":[{"metadata":{"_uuid":"1431447be2a2dbd46965e4efec9c651cba50fba9"},"cell_type":"markdown","source":"Working off of [Wesamelshamy's Image Recognition Kernel](https://www.kaggle.com/wesamelshamy/ad-image-recognition-and-quality-scoring) and using more features from OpenCV, I try to get more information from each image, like the number of colors, the kinds of colors, etc. There's a lot we can do here. Now we just have to figure out how to run it at scale for all the images and see what works in our models."},{"metadata":{"_uuid":"ea55a0629f55571eea4ae324ce9283c61cdfa011","collapsed":true,"_cell_guid":"206c03a1-5ddc-4bc9-bb10-d45380768049","trusted":true},"cell_type":"code","source":"import os\n\ncache_dir = os.path.expanduser(os.path.join('~', '.keras'))\nif not os.path.exists(cache_dir):\n    os.makedirs(cache_dir)\n\n# Create symbolic links for trained models.\n# Thanks to Lem Lordje Ko for the idea\n# https://www.kaggle.com/lemonkoala/pretrained-keras-models-symlinked-not-copied\nmodels_symlink = os.path.join(cache_dir, 'models')\nif not os.path.exists(models_symlink):\n    os.symlink('/kaggle/input/keras-pretrained-models/', models_symlink)\n\nimages_dir = os.path.expanduser(os.path.join('~', 'avito_images'))\nif not os.path.exists(images_dir):\n    os.makedirs(images_dir)","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"d52762316eff8953f49a2d08a0954f70a57b3584","_cell_guid":"b5e54794-353f-4228-8df4-e6a71a8469c0"},"cell_type":"markdown","source":"Due to Kaggle's disk space restrictions, we will only extract a few images to classify here.  Keep in mind that the pretrained models take almost 650 MB disk space."},{"metadata":{"_uuid":"d1fcb50be83400486d6c1c3eb05a2d7890de43a9","collapsed":true,"_cell_guid":"9989aede-9a3b-4df8-901c-506d20a4fb2f","trusted":true},"cell_type":"code","source":"\"\"\"Extract images from Avito's advertisement image zip archive.\n\nCode adapted from: https://www.kaggle.com/classtag/extract-avito-image-features-via-keras-vgg16/notebook\n\"\"\"\nimport zipfile\n\nNUM_IMAGES_TO_EXTRACT = 10\n\nwith zipfile.ZipFile('../input/avito-demand-prediction/train_jpg.zip', 'r') as train_zip:\n    files_in_zip = sorted(train_zip.namelist())\n    for idx, file in enumerate(files_in_zip[:NUM_IMAGES_TO_EXTRACT]):\n        if file.endswith('.jpg'):\n            train_zip.extract(file, path=file.split('/')[3])\n\n!mv *.jpg/data/competition_files/train_jpg/* ~/avito_images\n!rm -rf *.jpg","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"f51951bb781a056f9de734a981854dfe66c8b16a","_kg_hide-output":true,"_kg_hide-input":false,"_cell_guid":"d0a073a6-57e6-4ceb-9d81-4c65e5366635","trusted":true},"cell_type":"code","source":"import os\n\nimport numpy as np\nimport pandas as pd\nfrom keras.preprocessing import image\nimport keras.applications.resnet50 as resnet50\nimport keras.applications.xception as xception\nimport keras.applications.inception_v3 as inception_v3","execution_count":3,"outputs":[]},{"metadata":{"_uuid":"ba4ba5aa664f025aca86921e2e1c3e708783959f","collapsed":true,"_cell_guid":"a82406f7-0f32-44dd-985b-e2ceed6ba078","trusted":true},"cell_type":"code","source":"resnet_model = resnet50.ResNet50(weights='imagenet')\ninception_model = inception_v3.InceptionV3(weights='imagenet')\nxception_model = xception.Xception(weights='imagenet')","execution_count":4,"outputs":[]},{"metadata":{"_uuid":"c27dd3f8918e5f738e474284de64bdc1c9e1ae07","collapsed":true,"_cell_guid":"2753158d-d8f7-4d70-8b61-7b307ff1a253","trusted":true},"cell_type":"code","source":"from PIL import Image\nimport cv2\n\ndef image_classify(model, pak, img, top_n=3):\n    \"\"\"Classify image and return top matches.\"\"\"\n    target_size = (224, 224)\n    if img.size != target_size:\n        img = img.resize(target_size)\n    x = image.img_to_array(img)\n    x = np.expand_dims(x, axis=0)\n    x = pak.preprocess_input(x)\n    preds = model.predict(x)\n    return pak.decode_predictions(preds, top=top_n)[0]\n\n\ndef classify_and_plot(image_path):\n    \"\"\"Classify an image with different models.\n    Plot it and its predicitons.\n    \"\"\"\n    img = Image.open(image_path)\n    resnet_preds = image_classify(resnet_model, resnet50, img)\n    xception_preds = image_classify(xception_model, xception, img)\n    inception_preds = image_classify(inception_model, inception_v3, img)\n    cv_img = cv2.imread(image_path)\n    preds_arr = [('Resnet50', resnet_preds), ('xception', xception_preds), ('Inception', inception_preds)]\n    return (img, cv_img, preds_arr)","execution_count":58,"outputs":[]},{"metadata":{"_uuid":"5ff0715819388e26767c62494dd2e0f98a47b795","collapsed":true,"_cell_guid":"5c5016c2-8e4f-47b5-8a14-38a640ae4341","trusted":true},"cell_type":"code","source":"image_files = [x.path for x in os.scandir(images_dir)]","execution_count":59,"outputs":[]},{"metadata":{"scrolled":false,"_uuid":"d8242cd0b2a42aecc2ad202850278bde4f774e05","_cell_guid":"2da5a956-5570-4ca3-ae50-0a6d85645dab","trusted":true},"cell_type":"code","source":"from collections import Counter\nfrom pprint import pprint\n\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ndef get_data_from_image(dat):\n    plt.imshow(dat[0])\n    img_size = [dat[0].size[0], dat[0].size[1]]\n    (means, stds) = cv2.meanStdDev(dat[1])\n    mean_color = np.mean(dat[1].flatten())\n    std_color = np.std(dat[1].flatten())\n    color_stats = np.concatenate([means, stds]).flatten()\n    scores = [i[1][0][2] for i in dat[2]]\n    labels = [i[1][0][1] for i in dat[2]]\n    df = pd.DataFrame([img_size + [mean_color] + [std_color] + color_stats.tolist() + scores + labels],\n                      columns = ['img_size_x', 'img_size_y', 'img_mean_color', 'img_std_color', 'img_blue_mean', 'img_green_mean', 'img_red_mean', 'img_blue_std', 'image_green_std', 'image_red_std', 'Resnet50_score', 'xception_score', 'Inception_score', 'Resnet50_label', 'xception_label', 'Inception_label'])\n    return df\n\ndat = classify_and_plot(image_files[0])\ndf = get_data_from_image(dat)\nprint(df.head())","execution_count":206,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a84c693f05b4469885603ac65e491d5d089b8578"},"cell_type":"code","source":"%%time\ndat = classify_and_plot(image_files[1])\ndf = get_data_from_image(dat)\nprint(df.head())","execution_count":207,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"7f5d22cd1251082107fe76f690a0f35e3f46f739"},"cell_type":"code","source":"%%time\ndat = classify_and_plot(image_files[2])\ndf = get_data_from_image(dat)\nprint(df.head())","execution_count":208,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"146cee69c72c80170ff0bb221d9d0a642b96797c"},"cell_type":"code","source":"%%time\ndat = classify_and_plot(image_files[3])\ndf = get_data_from_image(dat)\nprint(df.head())","execution_count":209,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"34d6b7b71ff39fc9f851debffdf3db751025f8df"},"cell_type":"code","source":"%%time\ndat = classify_and_plot(image_files[4])\ndf = get_data_from_image(dat)\nprint(df.head())","execution_count":210,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"21e50fac89f6109942469bd3cc7174f5a0421abe"},"cell_type":"code","source":"%%time\ndat = classify_and_plot(image_files[5])\ndf = get_data_from_image(dat)\nprint(df.head())","execution_count":211,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"4d9bc5981efd5fc208e96b73a526dbb7c34ffc29"},"cell_type":"code","source":"%%time\ndat = classify_and_plot(image_files[6])\ndf = get_data_from_image(dat)\nprint(df.head())","execution_count":212,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"b9e8e9386736905a30009220556fb24ea39a2c4f"},"cell_type":"code","source":"%%time\ndat = classify_and_plot(image_files[7])\ndf = get_data_from_image(dat)\nprint(df.head())","execution_count":213,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dd06274d14f37c74020e2f6f7a71328b4424894c"},"cell_type":"code","source":"%%time\ndat = classify_and_plot(image_files[8])\ndf = get_data_from_image(dat)\nprint(df.head())","execution_count":214,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}