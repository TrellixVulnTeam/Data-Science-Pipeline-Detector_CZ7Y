{"cells":[{"metadata":{"_uuid":"4501ad8d5e7d39ab97988e634e5e2afd1c81ec3d"},"cell_type":"markdown","source":"Hi All,\n\nI am a new Kaggler. I just joined Kaggle about 2 months ago. Now I am extremely interesting to earn my first Kaggle medal in this very first competition of mine.\n\nHowever, as my study deadline is now approaching too fast, I hardly have time to dancing more with ensemble model. Moreover, I only have a poor laptop so for NN or LGBM stuff it's too arduous for me. Hence I decide to write a code routine to extract all advanced image features, mostly based on these two papers: \n1) http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.648.4682&rep=rep1&type=pdf\n2) https://storage.googleapis.com/kaggle-forum-message-attachments/328059/9411/dimitri-clickadvert.pdf\n\nSome aspects of my code:\n- Extract all features for each image at once, rather than extract each feature for all images at once. This aspect will save a lot of time for unnecessarily reading the input images multiple times.\n- Can specify image indices to extract (i.e., 100k-200k, 1M1-1M5,...). This will help us to divide the task to several computers.\n- Can handle and ignore unexpected errors, leave it as blank. The extracted results for NaN images are also blanked.\n- Speed (i7 CPU): 10k images/hour. This is the most frustrating. However I think 3-4 laptops might help to completely process ~2M train and test images in 2-3 days.\n- Output indicator for ongoing process, i.e., \"Processed: 5124...\", this to keep track of the task.\n- Periodically saved the results to disk for after a specified range, i.e., after each 1000 images, or 10000 images...\n- Can remove some features to speed up, if those features were already extracted.\n\nI believe a lot of Kagglers here already have extracted their advanced image features, but if some of you have interests in this, please leave me a comment or personal message. At this stage I already extracted 100k training images' features. I will help you to do this work also.\n\nI need to be a member of a team who needs advanced image features to strengthen their model. Per my readings and experiment  on the Avito images, I strongly believe these advanced image features could improve generalisation. My humble experiment show that, for 5000 images, the vadiation performance increases 0.003 (from 0.225 to 0.222) using exactly the same LGBM settings. Although 5000 images are not probabilistic enough, I still think these features have great potential."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n# Any results you write to the current directory are saved as output.\n\n# Read the features of the first 5000 images in the training pool\ndf = pd.read_csv(\"../input/img-features-avito-first5000train/img_features.csv\", low_memory=False)\ndf.head(20)","execution_count":13,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"022e5463f406435b313c546df3500038ac0d8228"},"cell_type":"markdown","source":"There are 26 different image features, listed as below:\n\n1) [wh]: the sum of width and height (width and height are equivalent, no need to split them).\n\n2-4) [bri_avg, bri_std, bri_min]: average, standard deviation and minimum of Brightness in HSV color space.\n\n5-6) [sat_avg, sat_std]: average and standard deviation of Saturation in HSV color space. Minimum of saturation seems not working as minimum of Brightness (which is reported in the mentioned paper).\n\n7-9) [lum_avg, lum_std, lum_min]: average, standard deviation and minimum of Luminance in YUV color space.\n\n10) [apw]: average pixel width, get from https://www.kaggle.com/shivamb/ideas-for-image-features-and-image-quality.\n\n11) [blur]: Blurness,  get from https://www.kaggle.com/shivamb/ideas-for-image-features-and-image-quality.\n\n12) [colorful]: Colorfulness, implemented based on the paper.\n\n13-15) [dom_rgb_color, dom_rgb_color_ratio, sim_rgb]: dominant color (categorical), its ratio (in terms of pixels count) over the number of image pixels, and Simplicity in RGB color space. The original image pixels are binned into 8 bins for each channel, resulting in 512 bins for the RGB histogram to compute these features.\n\n16-18) [dom_hsv_color, dom_hsv_color_ratio, sim_hsv]: dominant color (categorical), its ratio (in terms of pixels count) over the number of image pixels, and Simplicity in HSV color space. The original image pixels are binned into 8 bins for each channel, resulting in 512 bins for the HSV histogram to compute these features.\n\n19-21) [dom_gray, sim_gray, std_gray]:  dominant color (categorical), its ratio (in terms of pixels count) over the number of image pixels, and Simplicity in grayscale. The single channel grayscaled image is kept original (256 bins).\n\n22) [no_kp]: number of key points (mentioned in paper). This is a great feature which has strong correlation to deal probabilities. Images with less key points tend to have higher deal probabilities.\n\n23) [obj_ratio]: object ratio (the ratio of pixel counts of the main object detected in the image). This is implemented using saliency map mentioned in the paper.\n\n24) [no_faces]: the number of human faces in the image.\n\n25-26) [img_class, img_probability]: image class (categorical) and its probability classified by InceptionV3 model.\n\nSo much thanks if you don't feel uncomfortable for this kernel. \nI will edit this kernel to display some results. Please keep updated.\n\nHowever, I am still processing gradually all images. I will offer the full image features set when complete (though it may cost at least 1 week by only my own)."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"414602047b52eeebdd4b9f924f7591128842e585"},"cell_type":"markdown","source":""},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"eccb5055fe5018959728bf987ae65be9d7b56849"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}