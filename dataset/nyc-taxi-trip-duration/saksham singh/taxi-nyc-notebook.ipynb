{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# !unzip /kaggle/input/nyc-taxi-trip-duration/test.zip","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport math\nfrom geopy.distance import great_circle\nimport numpy as np\nimport gc\nimport datetime\nimport numpy as np\nimport xgboost as xgb\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nimport statsmodels.api as sm\n%matplotlib inline\nfrom sklearn.metrics import accuracy_score, mean_squared_log_error\nfrom collections import OrderedDict\nfrom sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error\nfrom scipy.stats import uniform, randint","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Feature extraction","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# def distance(lon1, lat1, lon2, lat2):\n#     pick_up = (lat1, lon1)\n#     drop_off = (lat2, lon2)\n#     return great_circle(pick_up, drop_off).miles\n\n# def reduce_mem_usage(df):\n#     \"\"\" iterate through all the columns of a dataframe and modify the data type\n#         to reduce memory usage.        \n#     \"\"\"\n#     #start_mem = df.memory_usage().sum() / 1024**2\n#     #print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n\n#     for col in df.columns:\n#         col_type = df[col].dtype\n\n#         if col_type != object:\n#             c_min = df[col].min()\n#             c_max = df[col].max()\n#             if str(col_type)[:3] == 'int':\n#                 if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n#                     df[col] = df[col].astype(np.int8)\n#                 elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n#                     df[col] = df[col].astype(np.int16)\n#                 elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n#                     df[col] = df[col].astype(np.int32)\n#                 elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n#                     df[col] = df[col].astype(np.int64)  \n#             else:\n#                 if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n#                     df[col] = df[col].astype(np.float16)\n#                 elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n#                     df[col] = df[col].astype(np.float32)\n#                 else:\n#                     df[col] = df[col].astype(np.float64)\n\n#     #end_mem = df.memory_usage().sum() / 1024**2\n#     #print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n#     #print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n\n#     return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_data = pd.read_csv('train.csv')\n\n# train_data = reduce_mem_usage(train_data)\n# train_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_data['distance'] = train_data.apply(lambda x: distance(x['pickup_longitude'], x['pickup_latitude'], x['dropoff_longitude'], x['dropoff_latitude']) , axis=1)\n# train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_data['dow'] = train_data['pickup_datetime'].apply(lambda x : datetime.datetime.strptime(x, '%Y-%m-%d %H:%M:%S').weekday())\n# train_data['hour'] = train_data['pickup_datetime'].apply(lambda x : datetime.datetime.strptime(x, '%Y-%m-%d %H:%M:%S').hour) \n# train_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### EDA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# v99 = train_data['trip_duration'].quantile(0.99)\n# train_data_v99 = train_data[train_data['trip_duration']<=v99]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sns.set(style=\"ticks\", color_codes=True)\n# import matplotlib.pyplot as plt\n# g = sns.FacetGrid(train_data, col=\"vendor_id\", height=4)\n# g = g.map(plt.hist, \"trip_duration\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# store_y = train_data[train_data[\"store_and_fwd_flag\"]==\"Y\"]\n# store_n = train_data[train_data[\"store_and_fwd_flag\"]==\"N\"]\n# store_y['trip_duration'].mean(), store_n['trip_duration'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# store_y_v99 = store_y['trip_duration'].quantile(0.99)\n# store_n_v99 = store_n['trip_duration'].quantile(0.99)\n\n# sns.distplot(store_n[store_n['trip_duration']<store_n_v99]['trip_duration'])\n# sns.distplot(store_y[store_y['trip_duration']<store_y_v99]['trip_duration'])\n\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dist_v99 = train_data['distance'].quantile(0.99)\n# train_dist_trip_v99 = train_data_v99[train_data_v99['distance'] < dist_v99] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_dist_trip_v99['distance_1'] = train_dist_trip_v99['distance'].apply(lambda x : round(x * 2) / 2)\n# train_dist_trip_v99 = train_dist_trip_v99.groupby([\"distance_1\"])['trip_duration'].mean().to_frame(name = 'trip_dur').reset_index()\n# train_dist_trip_v99.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ax = sns.scatterplot(x=\"distance_1\", y=\"trip_dur\", data=train_dist_trip_v99)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hour and Day of week","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_data_dow_v99 = train_data_v99.groupby([\"dow\"])['trip_duration'].mean().to_frame(name = 'trip_dur').reset_index()\n# ax = sns.scatterplot(x=\"dow\", y=\"trip_dur\", data=train_data_dow_v99)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_data_hour_v99 = train_data_v99.groupby([\"hour\"])['trip_duration'].mean().to_frame(name = 'trip_dur').reset_index()\n# ax = sns.scatterplot(x=\"hour\", y=\"trip_dur\", data=train_data_hour_v99)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# bins = [-1, 3, 6, 9, 12, 15, 18, 21, 24]\n# labels = [1,2,3,4,5,6,7,8]\n# train_data_v99['hour_binned'] = pd.cut(train_data_v99['hour'], bins=bins, labels=labels)\n# train_data_v99.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_data_hour_v99 = train_data_v99.groupby([\"hour_binned\"])['trip_duration'].mean().to_frame(name = 'trip_dur').reset_index()\n# ax = sns.scatterplot(x=\"hour_binned\", y=\"trip_dur\", data=train_data_hour_v99)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plt.figure(figsize=(15,8))\n# train_data_v99[\"dow_hour_binned\"] = train_data_v99.apply(lambda x : f\"{x['dow']}_{x['hour_binned']}\", axis=1)\n# train_data_hour_dow_v99 = train_data_v99.groupby([\"dow_hour_binned\"])['trip_duration'].mean().to_frame(name = 'trip_dur').reset_index()\n# ax = sns.scatterplot(x=\"dow_hour_binned\", y=\"trip_dur\", data=train_data_hour_dow_v99)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_data_hour_v99 = train_data_v99.groupby(\"hour\").agg({'trip_duration': 'mean', 'id': 'count'})\n# train_data_hour_v99.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_data_passen_v99 = train_data_v99.groupby([\"passenger_count\"])['trip_duration'].mean().to_frame(name = 'trip_dur').reset_index()\n# ax = sns.scatterplot(x=\"passenger_count\", y=\"trip_dur\", data=train_data_passen_v99)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv('../input/featureadded/train_feat_add.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Helper Functions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_scores(scores):\n    print(\"Scores: {0}\\nMean: {1:.3f}\\nStd: {2:.3f}\".format(scores, np.mean(scores), np.std(scores)))\n\ndef report_best_scores(results, n_top=3):\n    for i in range(1, n_top + 1):\n        candidates = np.flatnonzero(results['rank_test_score'] == i)\n        for candidate in candidates:\n            print(\"Model with rank: {0}\".format(i))\n            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n                  results['mean_test_score'][candidate],\n                  results['std_test_score'][candidate]))\n            print(\"Parameters: {0}\".format(results['params'][candidate]))\n            print(\"\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train_data['trip_duration']\n\nfeatures = ['vendor_id','passenger_count','pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude','store_and_fwd_flag','distance','dow','hour']\nX = train_data[features]\ncategorical_features = ['store_and_fwd_flag']\nX = pd.get_dummies(X,columns =categorical_features)\nX.pickup_longitude = X.pickup_longitude*(-1)\nX.dropoff_longitude = X.dropoff_longitude*(-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_trim = X.reset_index(drop=True)\ny_trim = y.reset_index(drop=True)\n\ntrip_dur_v99 = train_data['trip_duration'].quantile(0.99)\ndistance_v99 = train_data['distance'].quantile(0.99)\n\nprint(f\"Originally X : {len(X_trim)}, Y : {len(y_trim)}\")\nX_trim = X_trim[list(y_trim)<=trip_dur_v99]\ny_trim = y_trim[list(y_trim)<=trip_dur_v99]\nprint(f\"After trip_duration X : {len(X_trim)}, Y : {len(y_trim)}\")\n\nX_trim = X_trim.reset_index(drop=True)\ny_trim = y_trim.reset_index(drop=True)\n\ny_trim = y_trim[(X_trim['distance']<=distance_v99)]\nX_trim = X_trim[(X_trim['distance']<=distance_v99)]\nprint(f\"After distance X : {len(X_trim)}, Y : {len(y_trim)}\")\n\nX_trim = X_trim.reset_index(drop=True)\ny_trim = y_trim.reset_index(drop=True)\n\ny_trim = y_trim[(X_trim['passenger_count']<=4)&(X_trim['passenger_count']>=1)]\nX_trim = X_trim[(X_trim['passenger_count']<=4)&(X_trim['passenger_count']>=1)]\nprint(f\"After passenger count X : {len(X_trim)}, Y : {len(y_trim)}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_model = xgb.XGBRegressor(objective=\"reg:squaredlogerror\", random_state=42, verbosity=3)\n\nxgb_model.fit(X_trim, y_trim, eval_metric='rmsle')\n\ny_pred = xgb_model.predict(X_trim)\n\nmse=mean_squared_log_error(y_trim, y_pred)\n\nprint(np.sqrt(mse))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb.plot_importance(xgb_model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Random Search","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_model = xgb.XGBRegressor(objective=\"reg:squaredlogerror\", verbosity=2)\n\nparams = {\n    \"colsample_bytree\": uniform(0.7, 0.3),\n    \"gamma\": uniform(0, 0.5),\n    \"learning_rate\": uniform(0.03, 0.3), # default 0.1 \n    \"max_depth\": randint(2, 6), # default 3\n    \"n_estimators\": randint(100, 150), # default 100\n    \"subsample\": uniform(0.6, 0.4)\n}\n\nsearch = RandomizedSearchCV(xgb_model, param_distributions=params, random_state=42, n_iter=20, cv=3, verbose=1, n_jobs=1, return_train_score=True)\n\nsearch.fit(X_trim, y_trim, eval_metric='rmsle')\n\nreport_best_scores(search.cv_results_, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}