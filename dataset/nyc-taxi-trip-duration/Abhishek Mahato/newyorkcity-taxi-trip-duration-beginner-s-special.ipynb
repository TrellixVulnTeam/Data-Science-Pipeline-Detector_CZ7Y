{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Machin Learning Model on NYC Taxi Trip Duration\n\n## Agenda\n\n1. [Dataset Description](#dataset)\n2. [Import relevant packages](#package)\n3. [Loading the data](#read)\n4. [Data Wrangling/Explore the Dataset](#explore)\n5. [Descriptive Statistics of the dataset](#describe)\n6. [Exploratory Data Analysis(EDA)](#EDA)\n    - 6.1. [Data Visualization](#visualize)\n    - 6.2. [Feature Engineering](#feature)\n7. [Spliting Dataset into Train and Test](#split)\n8. [Learning Algorithm Selection](#algo)\n    - 8.1 [Building Linear Regression Model](#logreg)\n    - 8.2 [Building Decision Tree Regressor Model](#dt)\n    - 8.3 [Building Random Forest Regressor Model](#rf)\n    - 8.4 [Building AdaBoost Regressor Model](#ab)\n    - 8.5 [Building GradientBoosting Regressor Model](#gb)\n    - 8.6 [Building XGB Regressor Model](#xgb)\n    - 8.7 [Building LGBM Regressor Model](#lgbm)\n9. [Model Performance Assessment](#perform)\n    - 9.1 [RMSE Score](#perform)\n    - 9.2 [R2 Score](#perform)\n    - 9.3 [Train and Test Score](#perform)\n10. [Model Explanability](#explain)\n    - 10.1 [Eli5](#eli5)\n    - 10.2 [LIME](#lime)\n    - 10.3 [SHAP](#shap)\n11. [Closing Remarks](#close)","execution_count":null},{"metadata":{"id":"j0NL03CJ1FyO"},"cell_type":"markdown","source":"## 1. Dataset Description <a id='dataset'>\n\n<p/>\nThe data set contains the data regarding several taxi trips and its duration in New York City. I will now try and apply different techniques of Data Analysis to get insights about the data and determine how different variables are dependent on the target variable Trip Duration.My objective is to build a model that predicts the total trip duration of taxi trips in New York City.\n\n\n<p/>\n<b>File Descriptions:</b>\n<br/>\n<b>taxi_train.csv</b> - the training set (contains 1458644 trip records)\n\n<p/>\n<b>Data Fields:</b>\n<br/>\n<b>id</b> - a unique identifier for each trip.<br/>\n<b>vendor_id</b> - a code indicating the provider associated with the trip record <br/>\n<b>pickup_datetime</b> - date and time when the meter was engaged. <br/>\n<b>dropoff_datetime</b> - date and time when the meter was disengaged.<br/>\n<b>passenger_count</b> - the number of passengers in the vehicle (driver entered value). <br/>\n<b>pickup_longitude</b> - the longitude where the meter was engaged. <br/>\n<b>pickup_latitude</b> - the latitude where the meter was engaged. <br/>\n<b>dropoff_longitude</b> - the longitude where the meter was disengaged. <br/>\n<b>dropoff_latitude</b> - the latitude where the meter was disengaged.<br/>\n<b>store_and_fwd_flag</b> - This flag indicates whether the trip record was held in vehicle memory before sending to the vendor because the vehicle did not have a connection to the server - Y=store and forward; N=not a store and forward trip.<br/>\n<b>trip_duration</b> - duration of the trip in seconds.<br/>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 2. Import relevent packages <a id='package'>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport dask.dataframe as dd\nimport pandas_profiling\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport plotly_express as px\nimport time\nimport random \nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom pylab import rcParams\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom xgboost.sklearn import XGBRegressor\nimport lightgbm as lgb\nfrom vecstack import stacking\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn import metrics\nimport eli5\nfrom eli5.sklearn import PermutationImportance\nimport lime\nimport lime.lime_tabular\nimport shap\nimport geopandas as gpd\nfrom shapely.geometry import Point,Polygon\nimport descartes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Loading the data <a id='read'>\n\nWe'll be working with a dataset that was used in a Kaggle competition ([data dictionary](https://www.kaggle.com/c/nyc-taxi-trip-duration/overview)).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Read data through Pandas and compute time taken to read\ndf_taxi = pd.read_csv('../input/nyc-taxi-trip-duration/train.zip',parse_dates=['pickup_datetime','dropoff_datetime'],infer_datetime_format=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Data Wrangling/Explore the Dataset <a id='explore'>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Getting the head of the dataset\ndf_taxi.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Shape of the dataset\ndf_taxi.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We have 1458644 observations, 11 features, and our target variable is trip_duration**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Data Type of features for dataset\ndf_taxi.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Info of the dataset\ndf_taxi.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking for null values in dataset\ndf_taxi.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Great!No missing values in the dataset.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking duplicate value in vendor_id\ndf_taxi[df_taxi.duplicated(['id'], keep=False)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**No duplicastes available in id which is trip id!**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking Date and Time range\nprint('Datetime range: {} to {}'.format(df_taxi.pickup_datetime.min(),df_taxi.dropoff_datetime.max()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data is of 6 full months, from January 2016 to June 2016!**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking no. of vendors\ndf_taxi['vendor_id'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking Passenger count\nprint('Passenger Count: {} to {}'.format(df_taxi.passenger_count.min(),df_taxi.passenger_count.max()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#The distribution of Pickup and Drop Off day of the week\nprint(df_taxi['pickup_datetime'].nunique())\nprint(df_taxi['dropoff_datetime'].nunique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**There are many different pickup and drop off dates in these 2 columns.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Performing Pandas profiling to understand quick overview of columns\nreport = pandas_profiling.ProfileReport(df_taxi)\n#coverting profile report as html file\nreport.to_file('taxi_train.html')\n\nfrom IPython.display import display,HTML,IFrame\ndisplay(HTML(open('taxi_train.html').read()))  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5. Descriptive Statistics of the dataset <a id='describe'> ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Summary statistics for the dataset\ndf_taxi.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6. Exploratory Data Analysis(EDA) <a id='EDA'> ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Feature Engineering & Data Visualization<a id='feature'>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Lets have a look at the distribution of various variables in the Data set.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Passenger Count\nsns.distplot(df_taxi['passenger_count'],kde=False)\nplt.title('Distribution of Passenger Count')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Here we can see that mostly 1 or 2 passengers avail the taxi. The instance of large group of people travelling together is rare.**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Lets create some features from datetime stamp. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating pickup and dropoff day\ndf_taxi['pickup_day']=df_taxi['pickup_datetime'].dt.day_name()\ndf_taxi['dropoff_day']=df_taxi['dropoff_datetime'].dt.day_name()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating pickup and dropoff month\ndf_taxi['pickup_month']=df_taxi['pickup_datetime'].dt.month\ndf_taxi['dropoff_month']=df_taxi['dropoff_datetime'].dt.month","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating pickup and dropoff hour\ndf_taxi['pickup_hour']=df_taxi['pickup_datetime'].dt.hour\ndf_taxi['dropoff_hour']=df_taxi['dropoff_datetime'].dt.hour","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_taxi.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting monthly Pickup and Dropoff trip distribution\nfigure,ax=plt.subplots(nrows=1,ncols=2,figsize=(15,4))\nsns.countplot(x='pickup_month',data=df_taxi,ax=ax[0])\nax[0].set_title('The distribution of number of pickups each month')\nsns.countplot(x='dropoff_month',data=df_taxi,ax=ax[1])\nax[1].set_title('The distribution of number of dropoffs each month')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**There is not so much of difference in Pickup and dropoff month.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting daily Pickup and Dropoff trip distribution\nfigure,ax=plt.subplots(nrows=1,ncols=2,figsize=(15,4))\nsns.countplot(x='pickup_day',data=df_taxi,ax=ax[0])\nax[0].set_title('The distribution of number of pickups each day')\nsns.countplot(x='dropoff_day',data=df_taxi,ax=ax[1])\nax[1].set_title('The distribution of number of dropoffs each day')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We can see most trips were taken on Friday & least trips were taken on Monday.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting hourly Pickup and Dropoff trip distribution\nfigure,ax=plt.subplots(nrows=1,ncols=2,figsize=(20,5))\nsns.countplot(x='pickup_hour',data=df_taxi,ax=ax[0])\nax[0].set_title('The distribution of number of pickups each hour')\nsns.countplot(x='dropoff_hour',data=df_taxi,ax=ax[1])\nax[1].set_title('The distribution of number of dropoffs each hour')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Both the distribution looks quite similiar,majority of the trip has been booked from 6PM to 10PM.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating a new column according to the traffic scenerio of New York\ndef rush_hour(hour):\n    if hour.item()>=7 and hour.item()<=9:\n        return 'rush_hour_morning(7-9)'\n    elif hour.item()>9 and hour.item()<16:\n        return 'normal_hour_afternoon(9-16)'\n    elif hour.item()>=16 and hour.item()<=19:\n        return 'rush_hour_evening(16-19)'\n    elif hour.item()>19 and hour.item()<=23:\n        return 'normal_hour_evining(19-23)'\n    else:\n        return 'latenight(23 onwards)'\ndf_taxi['traffic_scenerio_pickup']=df_taxi[['pickup_hour']].apply(rush_hour, axis=1)\ndf_taxi['traffic_scenerio_dropoff']=df_taxi[['dropoff_hour']].apply(rush_hour, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting pickup and dropoff trip distribution as per traffic scenerio\nfigure,ax=plt.subplots(nrows=1,ncols=2,figsize=(20,5))\nsns.countplot(x='traffic_scenerio_pickup',data=df_taxi,ax=ax[0])\nax[0].set_title('The distribution of number of pickups as per traffics scenerio')\nsns.countplot(x='traffic_scenerio_dropoff',data=df_taxi,ax=ax[1])\nax[1].set_title('The distribution of number of dropoffs as per traffics scenerio')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Distribution of the trip duration","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(df_taxi['trip_duration'],kde=True)\nplt.title('The distribution of of the Pick Up  Duration distribution')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**This histogram shows extreme right skewness, hence there are outliers. Lets see the boxplot of this variable.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(df_taxi['trip_duration'], orient='horizontal')\nplt.title('A boxplot depicting the pickup duration distribution')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We can see there are few outliers, which we have to treat.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dropping trip_duration <1 min\ndf_taxi= df_taxi[df_taxi.trip_duration>60] # >1 min","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dropping trip_duration >2 Hrs\ndf_taxi= df_taxi[df_taxi.trip_duration<=7200] # >2 hrs","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Removed trip duration of less than 1 min and greater than 2 hrs as its not looking sensible that one can hire taxi for less than a min or more that 2 hrs in a city like New York!**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Distribution of vendor_id","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x='vendor_id',data=df_taxi)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The distribution of vendor id is not much different.**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Analysing geographical boundary of NYC.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking Longitude and Lattitude bounds available in the data\nprint('Longitude Bounds: {} to {}'.format(max(df_taxi.pickup_longitude.min(),df_taxi.dropoff_longitude.min()),max(df_taxi.pickup_longitude.max(),df_taxi.dropoff_longitude.max())))\nprint('Lattitude Bounds: {} to {}'.format(max(df_taxi.pickup_latitude.min(),df_taxi.dropoff_latitude.min()),max(df_taxi.pickup_latitude.max(),df_taxi.dropoff_latitude.max())))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#The borders of NY City, in coordinates comes out to be: city_long_border = (-74.03, -73.75) & city_lat_border = (40.63, 40.85)\n#Comparing this to our 'df_taxi.describe()' output we see that there are some coordinate points (pick ups/drop offs) that fall outside these borders. So let's limit our area of investigation to within the NY City borders.\ndf_taxi = df_taxi[df_taxi['pickup_longitude'] <= -73.75]\ndf_taxi = df_taxi[df_taxi['pickup_longitude'] >= -74.03]\ndf_taxi = df_taxi[df_taxi['pickup_latitude'] <= 40.85]\ndf_taxi = df_taxi[df_taxi['pickup_latitude'] >= 40.63]\ndf_taxi = df_taxi[df_taxi['dropoff_longitude'] <= -73.75]\ndf_taxi = df_taxi[df_taxi['dropoff_longitude'] >= -74.03]\ndf_taxi = df_taxi[df_taxi['dropoff_latitude'] <= 40.85]\ndf_taxi = df_taxi[df_taxi['dropoff_latitude'] >= 40.63]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Limited the New York City boundary as per City Long and Lat Boundary!**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Getting distance(in km) from geographocal co-ordinates\nfrom math import radians, sin, cos, sqrt, asin\ndef haversine(columns):\n    lat1, lon1, lat2, lon2 = columns\n    R = 6372.8 # Earth radius in kilometers\n    \n    dLat = radians(lat2 - lat1)\n    dLon = radians(lon2 - lon1)\n    lat1 = radians(lat1)\n    lat2 = radians(lat2)\n    \n    a = sin(dLat/2)**2 + cos(lat1)*cos(lat2)*sin(dLon/2)**2\n    c = 2*asin(sqrt(a))\n    \n    return R * c\n\ncols = ['pickup_latitude','pickup_longitude','dropoff_latitude','dropoff_longitude']\ndistances = df_taxi[cols].apply(lambda x: haversine(x),axis = 1)\ndf_taxi['distance_km'] = distances.copy()\ndf_taxi['distance_km'] = round(df_taxi.distance_km,2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x='distance_km',y='trip_duration',data=df_taxi)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Removing distance Outliers\ndf_taxi = df_taxi[df_taxi['distance_km'] > 0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Removed distance which have 0 value,seems to be cancelled trips.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Getting Speed(Km/h) of the taxi \ndf_taxi['speed_km/h']= 3600*(df_taxi.distance_km/df_taxi.trip_duration)  #3600 to convert it from km/s to km/h","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking Distance and Speed range\nprint('Distance Bounds: {} to {}'.format(df_taxi.distance_km.min(),df_taxi.distance_km.max()))\nprint('Speed Bounds: {} to {}'.format(df_taxi['speed_km/h'].min(),df_taxi['speed_km/h'].max()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Removing speed Outliers\ndf_taxi = df_taxi[df_taxi['speed_km/h'] > 0]\ndf_taxi = df_taxi[df_taxi['speed_km/h'] < 100]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Removed average speed equals to zero and more than 100, as its seems to be outliers.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dropping passenger count=0\ndf_taxi= df_taxi[df_taxi.passenger_count>0]\ndf_taxi['passenger_count'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting Trip Distribution\nplt.figure(figsize=(10,6))\nplt.hist(df_taxi.trip_duration, bins=100)\nplt.xlabel('Trip_duration')\nplt.ylabel('Number of Trips')\nplt.title('Trip Distribution')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Seems the distribution is skewed so we can apply certain transforms such as log transform!**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Applying Feature Scaling in trip_duration caloumn to normalize the data\ndf_taxi['log_trip_duration']= np.log1p(df_taxi['trip_duration'])\nplt.hist(df_taxi['log_trip_duration'].values, bins=100)\nplt.title('Log Trip Distribution')\nplt.xlabel('log(trip_duration)')\nplt.ylabel('Number of Trips')\nplt.show()\nsns.distplot(df_taxi[\"log_trip_duration\"], bins =100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualizing Passenger road map for picking up\nfig, ax = plt.subplots(ncols=1, nrows=1,figsize=(10,8))\nplt.ylim(40.63, 40.85)\nplt.xlim(-74.03,-73.75)\nax.scatter(df_taxi['pickup_longitude'],df_taxi['pickup_latitude'], s=0.02, alpha=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualizing Passenger road map for dropoff\nfig, ax = plt.subplots(ncols=1, nrows=1,figsize=(10,8))\nplt.ylim(40.63, 40.85)\nplt.xlim(-74.03,-73.75)\nax.scatter(df_taxi['dropoff_longitude'],df_taxi['dropoff_latitude'], s=0.02, alpha=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Converting Data to Geo Dataframe for pickup \ngdf=gpd.GeoDataFrame(df_taxi,geometry=gpd.points_from_xy(df_taxi['pickup_longitude'],df_taxi['pickup_latitude']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Geometry point has been generated for pickup\ngdf.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visulizing pickup points with geopandas\ngdf.plot(figsize=(12,10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Getting New York City map from Geopandas\nnyc = gpd.read_file(gpd.datasets.get_path('nybb'))\nax = nyc.plot(figsize=(12, 10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We can overlap datapoints to the map for getting better idea!**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"##### Categorical Encoding - One Hot Encoding","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Applying one hot encoding to the catagorical variables\ntaxi_vendor=pd.get_dummies(df_taxi['vendor_id'], prefix='vendor_id',drop_first= True)\ntaxi_pax=pd.get_dummies(df_taxi['passenger_count'], prefix='passenger',drop_first= True)\ntaxi_store_and_fwd_flag=pd.get_dummies(df_taxi['store_and_fwd_flag'], prefix='store_and_fwd_flag',drop_first= True)\ntaxi_pickup_day=pd.get_dummies(df_taxi['pickup_day'], prefix='pickup_day',drop_first= True)\ntaxi_dropoff_day=pd.get_dummies(df_taxi['dropoff_day'], prefix='dropoff_day',drop_first= True)\ntaxi_pickup_month=pd.get_dummies(df_taxi['pickup_month'], prefix='pickup_month',drop_first= True)\ntaxi_dropoff_month=pd.get_dummies(df_taxi['dropoff_month'], prefix='dropoff_month',drop_first= True)\ntaxi_pickup_traffic_scenerio=pd.get_dummies(df_taxi['traffic_scenerio_pickup'], prefix='pickup_',drop_first= True)\ntaxi_dropoff_traffic_scenerio=pd.get_dummies(df_taxi['traffic_scenerio_dropoff'], prefix='dropoff_',drop_first= True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Adding encoded columns to final data\ndf_taxi=pd.concat([df_taxi,taxi_pax,taxi_vendor,taxi_store_and_fwd_flag,taxi_pickup_day,taxi_dropoff_day,taxi_pickup_month,taxi_dropoff_month,taxi_pickup_traffic_scenerio,taxi_dropoff_traffic_scenerio],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_taxi.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dropping unnecessary columns from dataset\ndf_taxi=df_taxi.drop(['id','vendor_id','passenger_count','pickup_datetime','dropoff_datetime','pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude','log_trip_duration','speed_km/h','store_and_fwd_flag','traffic_scenerio_pickup','traffic_scenerio_dropoff','pickup_month','dropoff_month','pickup_day','dropoff_day','pickup_hour','dropoff_hour','geometry','dropoff_month_7'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_taxi.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 7. Spliting Dataset into Train and Test <a id='split'> ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Assigning X and y variables\nX = df_taxi.drop('trip_duration',1)\ny = df_taxi['trip_duration']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Splitting the dataset into train and test\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 8. Learning Algorithm Selection<a id='algo'> ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 8.1. Building Linear Regression Model <a id='logreg'>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LinearRegression()\nlr.fit(X_train,y_train)\nlr_pred = lr.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#RMSE score \nlr_rmse = np.sqrt(metrics.mean_squared_error(lr_pred,y_test))\nlr_rmse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#R2 score\nlr_r2score = metrics.r2_score(lr_pred,y_test)\nlr_r2score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Train Score\nlr_train=lr.score(X_train,y_train)\nlr_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Test Score\nlr_test=lr.score(X_test,y_test)\nlr_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Null RMSE\ny_null=np.zeros_like(y_test,dtype=float)\ny_null.fill(y_test.mean())\nnp.sqrt(metrics.mean_squared_error(y_test,y_null))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"coef1 = pd.DataFrame(lr.coef_,index=X_train.columns)\ncoef1.plot(kind='bar', title='Model Coefficients')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We can see that the regression model with all the columns performed well except few columns.**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 8.2. Building Decision Tree Regressor Model <a id='dt'>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dt=DecisionTreeRegressor()\ndt.fit(X_train,y_train)\ndt_pred=dt.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#RMSE score \ndt_rmse = np.sqrt(metrics.mean_squared_error(dt_pred,y_test))\ndt_rmse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#R2 score\ndt_r2score = metrics.r2_score(dt_pred,y_test)\ndt_r2score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Train Score\ndt_train=dt.score(X_train,y_train)\ndt_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Test Score\ndt_test=dt.score(X_test,y_test)\ndt_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 8.3. Building Random Forest Regressor Model <a id='rf'>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rf=RandomForestRegressor()\nrf.fit(X_train,y_train)\nrf_pred=rf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#RMSE score \nrf_rmse = np.sqrt(metrics.mean_squared_error(rf_pred,y_test))\nrf_rmse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#R2 score\nrf_r2score = metrics.r2_score(rf_pred,y_test)\nrf_r2score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Train Score\nrf_train=rf.score(X_train,y_train)\nrf_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Test Score\nrf_test=rf.score(X_test,y_test)\nrf_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 8.4. Building AdaBoost Regressor Model <a id='ab'>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ab=AdaBoostRegressor()\nab.fit(X_train,y_train)\nab_pred=ab.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#RMSE score \nab_rmse = np.sqrt(metrics.mean_squared_error(ab_pred,y_test))\nab_rmse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#R2 score\nab_r2score = metrics.r2_score(ab_pred,y_test)\nab_r2score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Train Score\nab_train=ab.score(X_train,y_train)\nab_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Test Score\nab_test=ab.score(X_test,y_test)\nab_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 8.5. Building GradientBoosting Regressor Model <a id='gb'>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"gb = GradientBoostingRegressor()\ngb.fit(X_train,y_train)\ngb_pred = gb.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#RMSE score \ngb_rmse = np.sqrt(metrics.mean_squared_error(gb_pred,y_test))\ngb_rmse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#R2 score\ngb_r2score = metrics.r2_score(gb_pred,y_test)\ngb_r2score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Train Score\ngb_train=gb.score(X_train,y_train)\ngb_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Test Score\ngb_test=gb.score(X_test,y_test)\ngb_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 8.6. Building XGB Regressor Model <a id='xgb'>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb= XGBRegressor()\nxgb.fit(X_train,y_train)\nxgb_pred=xgb.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#RMSE score \nxgb_rmse = np.sqrt(metrics.mean_squared_error(xgb_pred,y_test))\nxgb_rmse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#R2 score\nxgb_r2score = metrics.r2_score(xgb_pred,y_test)\nxgb_r2score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Train Score\nxgb_train=xgb.score(X_train,y_train)\nxgb_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Test Score\nxgb_test=xgb.score(X_test,y_test)\nxgb_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 8.7. Building LGBM Regressor Model <a id='lgbm'>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbm = lgb.LGBMRegressor()\nlgbm.fit(X_train,y_train)\nlgbm_pred = lgbm.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#RMSE score \nlgbm_rmse = np.sqrt(metrics.mean_squared_error(lgbm_pred,y_test))\nlgbm_rmse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#R2 score\nlgbm_r2score = metrics.r2_score(lgbm_pred,y_test)\nlgbm_r2score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Train Score\nlgbm_train=lgbm.score(X_train,y_train)\nlgbm_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Test Score\nlgbm_test=lgbm.score(X_test,y_test)\nlgbm_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 9. Model Performance Assessment <a id='perform'> ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating dictionary for all the metrics and models\nmetrics = {'Metrics': ['RMSE Score','R2 Score','Train Score','Test Score'],'Linear Regression':[lr_rmse,lr_r2score,lr_train,lr_test],\n          'Decision Tree Regressor':[dt_rmse,dt_r2score,dt_train,dt_test],'Random Forest Regressor':[rf_rmse,rf_r2score,rf_train,rf_test],\n        'AdaBoost Regressor':[ab_rmse,ab_r2score,ab_train,ab_test],\n          'GradientBoosting Regressor':[gb_rmse,gb_r2score,gb_train,gb_test],'XGBoost Regressor':[xgb_rmse,xgb_r2score,xgb_train,xgb_test],\n           'LGBM Regressor':[lgbm_rmse,lgbm_r2score,lgbm_train,lgbm_test]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Converting dictionary to dataframe\nmetrics = pd.DataFrame(metrics)\nmetrics","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Looking at the above Performance Matrix we can say thay XGBoost is the best model for this dataset.We may perform hyperparameter tuning on XGBoost model to improve the performance of the model**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 10. Model Explanability <a id='explain'> ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 10.1. Eli5<a id='eli5'>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Finding the importance of columns for prediction\nperm = PermutationImportance(xgb, random_state=1).fit(X_test,xgb_pred)\neli5.show_weights(perm, feature_names = X_test.columns.tolist())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 11. Closing Remarks <a id='close'> ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**In this project we covered various aspects of the Machine learning development cycle. We observed that the data exploration and variable analysis is a very important aspect of the whole cycle and should be done for thorough understanding of the data. We also cleaned the data while exploring as there were some outliers which should be treated before feature engineering. Further we did feature engineering to filter and gather only the optimal features which are more significant and covered most of the variance in the dataset. Then finally we trained the models on the optimum featureset to get the results.**","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}