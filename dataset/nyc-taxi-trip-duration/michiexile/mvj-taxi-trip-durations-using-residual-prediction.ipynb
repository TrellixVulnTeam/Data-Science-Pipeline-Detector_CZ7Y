{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%matplotlib inline\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-14T15:50:05.429252Z","iopub.execute_input":"2022-03-14T15:50:05.429607Z","iopub.status.idle":"2022-03-14T15:50:05.480221Z","shell.execute_reply.started":"2022-03-14T15:50:05.429506Z","shell.execute_reply":"2022-03-14T15:50:05.479217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import zipfile\n\ntrain = pd.read_csv(\"/kaggle/input/nyc-taxi-trip-duration/train.zip\", \n                    compression=\"zip\", index_col=\"id\")\ntest = pd.read_csv(\"/kaggle/input/nyc-taxi-trip-duration/test.zip\",\n                   compression=\"zip\", index_col=\"id\")\n\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-14T15:50:05.482091Z","iopub.execute_input":"2022-03-14T15:50:05.48235Z","iopub.status.idle":"2022-03-14T15:50:16.348967Z","shell.execute_reply.started":"2022-03-14T15:50:05.482317Z","shell.execute_reply":"2022-03-14T15:50:16.34798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.loc[train[\"store_and_fwd_flag\"] == \"Y\",:]\ntrain.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-14T15:50:16.350514Z","iopub.execute_input":"2022-03-14T15:50:16.350849Z","iopub.status.idle":"2022-03-14T15:50:16.603252Z","shell.execute_reply.started":"2022-03-14T15:50:16.350804Z","shell.execute_reply":"2022-03-14T15:50:16.602319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's include some sanity checks for the data.","metadata":{}},{"cell_type":"code","source":"train['pickup_datetime'] = pd.to_datetime(train.pickup_datetime)\ntest['pickup_datetime'] = pd.to_datetime(test.pickup_datetime)\ntrain.loc[:, 'pickup_date'] = train['pickup_datetime'].dt.date\ntest.loc[:, 'pickup_date'] = test['pickup_datetime'].dt.date\ntrain['dropoff_datetime'] = pd.to_datetime(train.dropoff_datetime)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T15:50:16.605021Z","iopub.execute_input":"2022-03-14T15:50:16.605343Z","iopub.status.idle":"2022-03-14T15:50:17.202043Z","shell.execute_reply.started":"2022-03-14T15:50:16.60531Z","shell.execute_reply":"2022-03-14T15:50:17.201106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EARTH_RADIUS=6378.137  ## km\ndef haversine(xy1, xy2):\n    return 2*EARTH_RADIUS*np.arcsin(np.sqrt(\n        np.sin((xy2[:,0]-xy1[:,0])/2)**2 +\n        np.cos(xy1[:,0])*np.cos(xy2[:,0])*np.sin((xy2[:,1]-xy2[:,1])/2)\n    ))\ntrain[\"distance\"] = haversine(\n    np.radians(train[[\"pickup_longitude\", \"pickup_latitude\"]].values),\n    np.radians(train[[\"dropoff_longitude\", \"dropoff_latitude\"]].values))\ntest[\"distance\"] = haversine(\n    np.radians(test[[\"pickup_longitude\", \"pickup_latitude\"]].values),\n    np.radians(test[[\"dropoff_longitude\", \"dropoff_latitude\"]].values))\n\npyplot.hist(np.log(train[\"distance\"]+1e-5), bins=50)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T15:50:17.204619Z","iopub.execute_input":"2022-03-14T15:50:17.204862Z","iopub.status.idle":"2022-03-14T15:50:17.797343Z","shell.execute_reply.started":"2022-03-14T15:50:17.204831Z","shell.execute_reply":"2022-03-14T15:50:17.79634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.loc[:, 'pickup_weekday'] = train['pickup_datetime'].dt.weekday\ntrain.loc[:, 'pickup_weekofyear'] = train['pickup_datetime'].dt.isocalendar().week\ntrain.loc[:, 'pickup_hour'] = train['pickup_datetime'].dt.hour\ntrain.loc[:, 'pickup_minute'] = train['pickup_datetime'].dt.minute\ntrain.loc[:, 'pickup_dt'] = (train['pickup_datetime'] - train['pickup_datetime'].min()).dt.total_seconds()\ntrain.loc[:, 'pickup_week_hour'] = train['pickup_weekday'] * 24 + train['pickup_hour']\n\ntest.loc[:, 'pickup_weekday'] = test['pickup_datetime'].dt.weekday\ntest.loc[:, 'pickup_weekofyear'] = test['pickup_datetime'].dt.isocalendar().week\ntest.loc[:, 'pickup_hour'] = test['pickup_datetime'].dt.hour\ntest.loc[:, 'pickup_minute'] = test['pickup_datetime'].dt.minute\ntest.loc[:, 'pickup_dt'] = (test['pickup_datetime'] - train['pickup_datetime'].min()).dt.total_seconds()\ntest.loc[:, 'pickup_week_hour'] = test['pickup_weekday'] * 24 + test['pickup_hour']","metadata":{"execution":{"iopub.status.busy":"2022-03-14T15:50:17.80228Z","iopub.execute_input":"2022-03-14T15:50:17.802592Z","iopub.status.idle":"2022-03-14T15:50:18.317485Z","shell.execute_reply.started":"2022-03-14T15:50:17.802548Z","shell.execute_reply":"2022-03-14T15:50:18.316444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since we have (in the training set) `distance` and `trip_duration`, we can simply calculate an `avg_speed` variable. Here, we are computing it in units of m/s (...since `distance` is in kilometers, and `trip_duration` is in seconds).","metadata":{}},{"cell_type":"code","source":"train.loc[:, 'avg_speed'] = 1000 * train['distance'] / train['trip_duration']","metadata":{"execution":{"iopub.status.busy":"2022-03-14T15:50:18.319382Z","iopub.execute_input":"2022-03-14T15:50:18.319711Z","iopub.status.idle":"2022-03-14T15:50:18.327751Z","shell.execute_reply.started":"2022-03-14T15:50:18.319655Z","shell.execute_reply":"2022-03-14T15:50:18.326695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"One idea for an approach would be to compute `predicted_trip_duration = predicted_distance*avg_speed` on the test set, and learn to predict the residual `residual = trip_duration - predicted_trip_duration`. That way, we can predict `predicted_trip_duration + residual` as our final submission prediction.\n\nTo do this, we need to predict the speed, and do so in the same way both for test and training set.","metadata":{}},{"cell_type":"code","source":"from sklearn import neighbors\nspeed_model = neighbors.KNeighborsRegressor(n_neighbors=2)\n\nspeed_model.fit(train[['pickup_dt']], train['avg_speed'])","metadata":{"execution":{"iopub.status.busy":"2022-03-14T15:50:18.329926Z","iopub.execute_input":"2022-03-14T15:50:18.330318Z","iopub.status.idle":"2022-03-14T15:50:19.539035Z","shell.execute_reply.started":"2022-03-14T15:50:18.330268Z","shell.execute_reply":"2022-03-14T15:50:19.538001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['pred_speed'] = speed_model.predict(train[['pickup_dt']])\ntest['pred_speed'] = speed_model.predict(test[['pickup_dt']])","metadata":{"execution":{"iopub.status.busy":"2022-03-14T15:50:19.541217Z","iopub.execute_input":"2022-03-14T15:50:19.541568Z","iopub.status.idle":"2022-03-14T15:50:20.231948Z","shell.execute_reply.started":"2022-03-14T15:50:19.541517Z","shell.execute_reply":"2022-03-14T15:50:20.230986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['pred_duration'] = train['pred_speed'] * train['distance']\ntest['pred_duration'] = test['pred_speed'] * test['distance']","metadata":{"execution":{"iopub.status.busy":"2022-03-14T15:50:20.233286Z","iopub.execute_input":"2022-03-14T15:50:20.233558Z","iopub.status.idle":"2022-03-14T15:50:20.245063Z","shell.execute_reply.started":"2022-03-14T15:50:20.233524Z","shell.execute_reply":"2022-03-14T15:50:20.24401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['residuals'] = train['trip_duration'] - train['pred_duration']","metadata":{"execution":{"iopub.status.busy":"2022-03-14T15:50:20.24632Z","iopub.execute_input":"2022-03-14T15:50:20.246603Z","iopub.status.idle":"2022-03-14T15:50:20.263196Z","shell.execute_reply.started":"2022-03-14T15:50:20.246568Z","shell.execute_reply":"2022-03-14T15:50:20.262001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's just check for high correlations with our target quantities in our dataset...","metadata":{}},{"cell_type":"code","source":"train.corr()[['trip_duration','pred_duration','residuals']].sort_values(\"trip_duration\",key=abs,ascending=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T15:50:20.265218Z","iopub.execute_input":"2022-03-14T15:50:20.265861Z","iopub.status.idle":"2022-03-14T15:50:20.297465Z","shell.execute_reply.started":"2022-03-14T15:50:20.265811Z","shell.execute_reply":"2022-03-14T15:50:20.296432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are some clear outliers in the dataset.\nLet's get rid of taxicab trips that are longer than 3h, as well as trips shorter than 1m.","metadata":{}},{"cell_type":"code","source":"print(f\"Shape before dropping outliers: {train.shape}\")\ntrain.drop(train[train[\"trip_duration\"] > 3*60*60].index, inplace=True)\ntrain.drop(train[train[\"trip_duration\"] < 60].index, inplace=True)\nprint(f\"Shape after dropping outliers: {train.shape}\")","metadata":{"execution":{"iopub.status.busy":"2022-03-14T15:50:20.300842Z","iopub.execute_input":"2022-03-14T15:50:20.301144Z","iopub.status.idle":"2022-03-14T15:50:20.322585Z","shell.execute_reply.started":"2022-03-14T15:50:20.301112Z","shell.execute_reply":"2022-03-14T15:50:20.321382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# External data\n\nLet's merge in extra data sets. Two of the award winning datasets generated for this competition are `knycmetars2016` with extensive hour-by-hour weather data and `new-york-city-taxi-with-osrm` with fastest, and second-fastest routes with both distances and step-by-step route desciptions.\n\nTo merge them, first do \"+ Add data\" in the sidebar, and then read in the CSV files using the Copy File Path link in the sidebar. For the weather data, we would have to interpolate - so we train a battery of simplistic kNN models to fill in the relevant data. For the trip data, the CSV file shares the same ID column as our original data, so we can use these row IDs to merge the data together. Pandas provides `df.merge` that allows for us to use the index column as merge keys if we so choose.","metadata":{}},{"cell_type":"code","source":"distance_matrix_data_train_1 = pd.read_csv(\"../input/new-york-city-taxi-with-osrm/fastest_routes_train_part_1.csv\", index_col=\"id\")\ndistance_matrix_data_train_2 = pd.read_csv(\"../input/new-york-city-taxi-with-osrm/fastest_routes_train_part_2.csv\", index_col=\"id\")\ndistance_matrix_data_test = pd.read_csv(\"../input/new-york-city-taxi-with-osrm/fastest_routes_test.csv\", index_col=\"id\")\n","metadata":{"execution":{"iopub.status.busy":"2022-03-14T15:50:20.32539Z","iopub.execute_input":"2022-03-14T15:50:20.325994Z","iopub.status.idle":"2022-03-14T15:50:48.84066Z","shell.execute_reply.started":"2022-03-14T15:50:20.325954Z","shell.execute_reply":"2022-03-14T15:50:48.839407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"distance_matrix_data_train = pd.concat([distance_matrix_data_train_1, distance_matrix_data_train_2])\ndistance_matrix_data_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-14T15:50:48.842641Z","iopub.execute_input":"2022-03-14T15:50:48.842931Z","iopub.status.idle":"2022-03-14T15:50:49.385381Z","shell.execute_reply.started":"2022-03-14T15:50:48.842898Z","shell.execute_reply":"2022-03-14T15:50:49.384472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntrain = pd.merge(train, distance_matrix_data_train, left_index=True, right_index=True, \n         sort=False, how=\"left\")\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-14T15:50:49.3867Z","iopub.execute_input":"2022-03-14T15:50:49.386987Z","iopub.status.idle":"2022-03-14T15:50:49.854766Z","shell.execute_reply.started":"2022-03-14T15:50:49.386934Z","shell.execute_reply":"2022-03-14T15:50:49.853836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.merge(test, distance_matrix_data_test, left_index=True, right_index=True,\n               sort=False, how=\"left\")\nprint(f\"# NA in the result: {test.isna().sum().sum()}\")\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-14T15:50:49.856448Z","iopub.execute_input":"2022-03-14T15:50:49.856716Z","iopub.status.idle":"2022-03-14T15:50:52.329992Z","shell.execute_reply.started":"2022-03-14T15:50:49.856683Z","shell.execute_reply":"2022-03-14T15:50:52.328981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"knyc_metars = pd.read_csv(\"../input/knycmetars2016/KNYC_Metars.csv\")\nknyc_metars[\"Time\"] = pd.to_datetime(knyc_metars[\"Time\"])\nknyc_metars[\"dt\"] = (knyc_metars[\"Time\"] - train['pickup_datetime'].min()).dt.total_seconds()\nknyc_metars.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-14T15:50:52.331416Z","iopub.execute_input":"2022-03-14T15:50:52.331657Z","iopub.status.idle":"2022-03-14T15:50:52.3931Z","shell.execute_reply.started":"2022-03-14T15:50:52.331625Z","shell.execute_reply":"2022-03-14T15:50:52.392153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"knyc_metars.dropna(axis=1,inplace=True)\nknyc_metars.isna().sum(), knyc_metars.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-14T15:50:52.39446Z","iopub.execute_input":"2022-03-14T15:50:52.394727Z","iopub.status.idle":"2022-03-14T15:50:52.4161Z","shell.execute_reply.started":"2022-03-14T15:50:52.394694Z","shell.execute_reply":"2022-03-14T15:50:52.4148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categorical_weathers = [\"Wind Dir\", \"Events\", \"Conditions\"]\nnumeric_weathers = [\"Temp.\", \"Humidity\", \"Dew Point\", \"Wind Speed\", \"Gust Speed\", \"Precip\"]\n[c for c in knyc_metars.columns if c not in categorical_weathers and c not in numeric_weathers]","metadata":{"execution":{"iopub.status.busy":"2022-03-14T15:50:52.418181Z","iopub.execute_input":"2022-03-14T15:50:52.418823Z","iopub.status.idle":"2022-03-14T15:50:52.428293Z","shell.execute_reply.started":"2022-03-14T15:50:52.418773Z","shell.execute_reply":"2022-03-14T15:50:52.427391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfrom sklearn import neighbors, multioutput\ncategorical_weather_model = multioutput.MultiOutputClassifier(\n    neighbors.KNeighborsClassifier(n_neighbors=2), n_jobs=-1)\nnumeric_weather_model = multioutput.MultiOutputRegressor(\n    neighbors.KNeighborsRegressor(n_neighbors=2), n_jobs=-1)\n\ncategorical_weather_model.fit(knyc_metars[[\"dt\"]], knyc_metars[categorical_weathers])\ntrain[categorical_weathers] = categorical_weather_model.predict(train[[\"pickup_dt\"]])\ntest[categorical_weathers] = categorical_weather_model.predict(test[[\"pickup_dt\"]])\n\nnumeric_weather_model.fit(knyc_metars[[\"dt\"]], knyc_metars[numeric_weathers])\ntrain[numeric_weathers] = numeric_weather_model.predict(train[[\"pickup_dt\"]])\ntest[numeric_weathers] = numeric_weather_model.predict(test[[\"pickup_dt\"]])","metadata":{"execution":{"iopub.status.busy":"2022-03-14T15:50:52.429545Z","iopub.execute_input":"2022-03-14T15:50:52.429798Z","iopub.status.idle":"2022-03-14T15:51:32.051822Z","shell.execute_reply.started":"2022-03-14T15:50:52.429767Z","shell.execute_reply":"2022-03-14T15:51:32.05074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We now have better distance estimates, so we should recalculate and repredict our average speed, and thus also our predicted distances and residuals.","metadata":{}},{"cell_type":"code","source":"# m/s\ntrain['osrm_speed'] = train[\"total_distance\"] / train['trip_duration']\nspeed_model.fit(train[['pickup_dt']], train['osrm_speed'])\ntrain['pred_osrm_speed'] = speed_model.predict(train[['pickup_dt']])\ntest['pred_osrm_speed'] = speed_model.predict(test[['pickup_dt']])\n\ntrain['osrm_duration'] = train['pred_speed'] * train[\"total_distance\"]\ntest['osrm_duration'] = test['pred_speed'] * test[\"total_distance\"]\n\ntrain['osrm_residuals'] = train['trip_duration'] - train['pred_duration']","metadata":{"execution":{"iopub.status.busy":"2022-03-14T15:51:32.053476Z","iopub.execute_input":"2022-03-14T15:51:32.053748Z","iopub.status.idle":"2022-03-14T15:51:32.737142Z","shell.execute_reply.started":"2022-03-14T15:51:32.053715Z","shell.execute_reply":"2022-03-14T15:51:32.736245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"do_not_use_for_training = ['id', 'pickup_datetime', 'dropoff_datetime',\n                           'trip_duration', 'check_trip_duration',\n                           'pickup_date', 'avg_speed', \"osrm_speed\",\n                           'pred_speed','pred_duration',\n                           \"pred_osrm_speed\", \"osrm_duration\",\n                           'residuals', \"osrm_residuals\",\n                           'store_and_fwd_flag', \n                           'starting_street', 'end_street',\n                           'total_distance', 'number_of_steps', \n                           'street_for_each_step', 'distance_per_step', \n                           'travel_time_per_step', 'step_maneuvers', \n                           'step_direction', 'step_location_list',\n                           'Wind Dir', 'Events', 'Conditions',\n                           'total_travel_time', 'Temp.', 'Humidity', \n                           'Dew Point', 'Wind Speed', 'Gust Speed', \n                           #'Precip'\n                          ]\nfeature_names = [f for f in train.columns if f not in do_not_use_for_training]\nX, y = train[feature_names], train[\"residuals\"]\nXtest = test[feature_names]\nprint(f\"Total feature set: {[f for f in train.columns]}\")\nprint(f\"Shape of training data: X {X.shape} y {y.shape}\")\nprint(f\"Shape of test features: X {Xtest.shape}\")\nprint(f\"Features used: {feature_names}\")","metadata":{"execution":{"iopub.status.busy":"2022-03-14T15:53:16.892261Z","iopub.execute_input":"2022-03-14T15:53:16.89278Z","iopub.status.idle":"2022-03-14T15:53:17.047625Z","shell.execute_reply.started":"2022-03-14T15:53:16.892739Z","shell.execute_reply":"2022-03-14T15:53:17.046763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import linear_model, model_selection, metrics, pipeline\nfrom sklearn import preprocessing, svm, compose, feature_selection\nfrom sklearn import ensemble, decomposition\nimport xgboost\n\ndef rmsle_score(yt, yp): \n    return np.sqrt(metrics.mean_squared_log_error(yt, yp))\n\nrmsle = metrics.make_scorer(rmsle_score,greater_is_better=False)\n\nparams = {\n    \"pca__n_components\": [3,5,7,10,15],\n    \"features__score_func\": [feature_selection.f_regression],\n    \"features__k\": [3,5,7,10,'all'],\n    \"lm__alpha\": np.logspace(-3,3,7),\n}\nmodel = model_selection.RandomizedSearchCV(\n        pipeline.Pipeline([\n          (\"pca\", decomposition.PCA()),\n          (\"features\",feature_selection.SelectKBest()),\n          (\"scaler\", preprocessing.StandardScaler()),\n          (\"lm\", linear_model.Ridge())\n        ]),\n    params, #scoring=rmsle, \n    cv=5, n_jobs=-1)\nmodel.get_params()","metadata":{"execution":{"iopub.status.busy":"2022-03-14T15:53:26.551986Z","iopub.execute_input":"2022-03-14T15:53:26.55232Z","iopub.status.idle":"2022-03-14T15:53:26.759537Z","shell.execute_reply.started":"2022-03-14T15:53:26.552284Z","shell.execute_reply":"2022-03-14T15:53:26.758397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nmodel.fit(X, y)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T15:53:27.783008Z","iopub.execute_input":"2022-03-14T15:53:27.783317Z","iopub.status.idle":"2022-03-14T15:53:29.185111Z","shell.execute_reply.started":"2022-03-14T15:53:27.783282Z","shell.execute_reply":"2022-03-14T15:53:29.181462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Model score: {model.best_score_}\")\nprint(f\"Model chosen parameters: {model.best_params_}\")","metadata":{"execution":{"iopub.status.busy":"2022-03-14T15:53:29.187659Z","iopub.execute_input":"2022-03-14T15:53:29.188068Z","iopub.status.idle":"2022-03-14T15:53:29.195852Z","shell.execute_reply.started":"2022-03-14T15:53:29.188021Z","shell.execute_reply":"2022-03-14T15:53:29.194912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dur_val = train['pred_duration'] + model.predict(X)\ndur_val[dur_val < 0] = 0\nprint(f\"Model RMSLE score: {rmsle_score(train['trip_duration'], dur_val)}\")","metadata":{"execution":{"iopub.status.busy":"2022-03-14T15:53:29.591295Z","iopub.execute_input":"2022-03-14T15:53:29.591589Z","iopub.status.idle":"2022-03-14T15:53:29.616896Z","shell.execute_reply.started":"2022-03-14T15:53:29.591557Z","shell.execute_reply":"2022-03-14T15:53:29.611447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import yellowbrick as yb\nimport yellowbrick.regressor as ybr\nimport yellowbrick.features as ybf\n\nX_train, X_val, y_train, y_val = model_selection.train_test_split(X, y)\nX_train.shape, X_val.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-14T15:53:35.644207Z","iopub.execute_input":"2022-03-14T15:53:35.644489Z","iopub.status.idle":"2022-03-14T15:53:35.921629Z","shell.execute_reply.started":"2022-03-14T15:53:35.644458Z","shell.execute_reply":"2022-03-14T15:53:35.920522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Residuals plot\nybr.residuals_plot(model.best_estimator_, X_train, y_train, X_val, y_val, is_fitted=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T15:53:36.578212Z","iopub.execute_input":"2022-03-14T15:53:36.578495Z","iopub.status.idle":"2022-03-14T15:53:37.926355Z","shell.execute_reply.started":"2022-03-14T15:53:36.578465Z","shell.execute_reply":"2022-03-14T15:53:37.925337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ybr.prediction_error(model.best_estimator_, X_train, y_train, X_val, y_val, is_fitted=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T15:53:37.927959Z","iopub.execute_input":"2022-03-14T15:53:37.928226Z","iopub.status.idle":"2022-03-14T15:53:38.336328Z","shell.execute_reply.started":"2022-03-14T15:53:37.928193Z","shell.execute_reply":"2022-03-14T15:53:38.335316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn\n\nfor f in train.columns:\n    pyplot.figure()\n    seaborn.displot(data=train.sample(frac=0.1), x=f, y=\"trip_duration\")\n    pyplot.title(f\"Plot of {f} against trip_duration\")\n    pyplot.show()\n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-14T15:53:38.551736Z","iopub.execute_input":"2022-03-14T15:53:38.552039Z","iopub.status.idle":"2022-03-14T15:57:09.309667Z","shell.execute_reply.started":"2022-03-14T15:53:38.552006Z","shell.execute_reply":"2022-03-14T15:57:09.308696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Let's use the base_model to predict both kinds of residuals, then\n# compute and feed both sets of predicted durations into a meta-model\nfrom sklearn import base\n\nmeta_model = ensemble.ExtraTreesRegressor()\n\navg_model = base.clone(model.best_estimator_)\nosrm_model = base.clone(model.best_estimator_)\n\navg_model.fit(X, train[\"residuals\"])\nosrm_model.fit(X, train[\"osrm_residuals\"])\n\npred_avg_residuals = avg_model.predict(X)\npred_osrm_residuals = osrm_model.predict(X)\n\nmeta_predictors = train[[\"pred_duration\", \"osrm_duration\"]].assign(\n    pred_avg_residuals=pred_avg_residuals,pred_osrm_residuals=pred_osrm_residuals)\n\nmeta_model.fit(meta_predictors, train[\"trip_duration\"])","metadata":{"execution":{"iopub.status.busy":"2022-03-14T16:02:38.049895Z","iopub.execute_input":"2022-03-14T16:02:38.050287Z","iopub.status.idle":"2022-03-14T16:02:39.73859Z","shell.execute_reply.started":"2022-03-14T16:02:38.050251Z","shell.execute_reply":"2022-03-14T16:02:39.737766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n#submission = test[[]].assign(trip_duration=test['pred_duration']+model.predict(Xtest))\n\ntest_avg_residuals = avg_model.predict(Xtest)\ntest_osrm_residuals = osrm_model.predict(Xtest)\n\ntest_meta = test[[\"pred_duration\", \"osrm_duration\"]].assign(\n    pred_avg_residuals=test_avg_residuals,pred_osrm_residuals=test_osrm_residuals)\n    \nsubmission = test[[]].assign(trip_duration=meta_model.predict(test_meta))\nsubmission['trip_duration'] = np.where(submission['trip_duration'] < 0, 0, submission['trip_duration'])\nsubmission.to_csv(\"submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-03-14T16:02:53.612199Z","iopub.execute_input":"2022-03-14T16:02:53.612529Z","iopub.status.idle":"2022-03-14T16:03:07.413173Z","shell.execute_reply.started":"2022-03-14T16:02:53.612497Z","shell.execute_reply":"2022-03-14T16:03:07.412277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}