{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%matplotlib inline\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-14T15:45:37.316681Z","iopub.execute_input":"2022-03-14T15:45:37.31702Z","iopub.status.idle":"2022-03-14T15:45:37.328477Z","shell.execute_reply.started":"2022-03-14T15:45:37.316981Z","shell.execute_reply":"2022-03-14T15:45:37.327637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import zipfile\n\ntrain = pd.read_csv(\"/kaggle/input/nyc-taxi-trip-duration/train.zip\", \n                    compression=\"zip\", index_col=\"id\")\ntest = pd.read_csv(\"/kaggle/input/nyc-taxi-trip-duration/test.zip\",\n                   compression=\"zip\", index_col=\"id\")\n\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-14T15:45:37.330405Z","iopub.execute_input":"2022-03-14T15:45:37.330786Z","iopub.status.idle":"2022-03-14T15:45:44.171749Z","shell.execute_reply.started":"2022-03-14T15:45:37.330751Z","shell.execute_reply":"2022-03-14T15:45:44.171089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Turns out that `store_and_forward == Y` may be a MUCH cleaner and authoritative subset of the data, with the added benefit that it is MUCH smaller.","metadata":{}},{"cell_type":"code","source":"train = train.loc[train[\"store_and_fwd_flag\"] == \"Y\",:]\ntrain.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-14T15:45:44.173037Z","iopub.execute_input":"2022-03-14T15:45:44.173443Z","iopub.status.idle":"2022-03-14T15:45:44.382215Z","shell.execute_reply.started":"2022-03-14T15:45:44.173406Z","shell.execute_reply":"2022-03-14T15:45:44.381439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's include some sanity checks for the data.","metadata":{}},{"cell_type":"code","source":"train['pickup_datetime'] = pd.to_datetime(train.pickup_datetime)\ntest['pickup_datetime'] = pd.to_datetime(test.pickup_datetime)\ntrain.loc[:, 'pickup_date'] = train['pickup_datetime'].dt.date\ntest.loc[:, 'pickup_date'] = test['pickup_datetime'].dt.date\ntrain['dropoff_datetime'] = pd.to_datetime(train.dropoff_datetime)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T15:45:44.384403Z","iopub.execute_input":"2022-03-14T15:45:44.384664Z","iopub.status.idle":"2022-03-14T15:45:44.883706Z","shell.execute_reply.started":"2022-03-14T15:45:44.38463Z","shell.execute_reply":"2022-03-14T15:45:44.88298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EARTH_RADIUS=6378.137  ## km\ndef haversine(xy1, xy2):\n    return 2*EARTH_RADIUS*np.arcsin(np.sqrt(\n        np.sin((xy2[:,0]-xy1[:,0])/2)**2 +\n        np.cos(xy1[:,0])*np.cos(xy2[:,0])*np.sin((xy2[:,1]-xy2[:,1])/2)\n    ))\ntrain[\"distance\"] = haversine(\n    np.radians(train[[\"pickup_longitude\", \"pickup_latitude\"]].values),\n    np.radians(train[[\"dropoff_longitude\", \"dropoff_latitude\"]].values))\ntest[\"distance\"] = haversine(\n    np.radians(test[[\"pickup_longitude\", \"pickup_latitude\"]].values),\n    np.radians(test[[\"dropoff_longitude\", \"dropoff_latitude\"]].values))\n\npyplot.hist(np.log(train[\"distance\"]+1e-5), bins=50)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T15:45:44.885027Z","iopub.execute_input":"2022-03-14T15:45:44.885435Z","iopub.status.idle":"2022-03-14T15:45:45.250132Z","shell.execute_reply.started":"2022-03-14T15:45:44.8854Z","shell.execute_reply":"2022-03-14T15:45:45.249454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.loc[:, 'pickup_weekday'] = train['pickup_datetime'].dt.weekday\ntrain.loc[:, 'pickup_weekofyear'] = train['pickup_datetime'].dt.isocalendar().week\ntrain.loc[:, 'pickup_hour'] = train['pickup_datetime'].dt.hour\ntrain.loc[:, 'pickup_minute'] = train['pickup_datetime'].dt.minute\ntrain.loc[:, 'pickup_dt'] = (train['pickup_datetime'] - train['pickup_datetime'].min()).dt.total_seconds()\ntrain.loc[:, 'pickup_week_hour'] = train['pickup_weekday'] * 24 + train['pickup_hour']\n\ntest.loc[:, 'pickup_weekday'] = test['pickup_datetime'].dt.weekday\ntest.loc[:, 'pickup_weekofyear'] = test['pickup_datetime'].dt.isocalendar().week\ntest.loc[:, 'pickup_hour'] = test['pickup_datetime'].dt.hour\ntest.loc[:, 'pickup_minute'] = test['pickup_datetime'].dt.minute\ntest.loc[:, 'pickup_dt'] = (test['pickup_datetime'] - train['pickup_datetime'].min()).dt.total_seconds()\ntest.loc[:, 'pickup_week_hour'] = test['pickup_weekday'] * 24 + test['pickup_hour']","metadata":{"execution":{"iopub.status.busy":"2022-03-14T15:45:45.251259Z","iopub.execute_input":"2022-03-14T15:45:45.252396Z","iopub.status.idle":"2022-03-14T15:45:45.821251Z","shell.execute_reply.started":"2022-03-14T15:45:45.252352Z","shell.execute_reply":"2022-03-14T15:45:45.820495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since we have (in the training set) `distance` and `trip_duration`, we can simply calculate an `avg_speed` variable. Here, we are computing it in units of m/s (...since `distance` is in kilometers, and `trip_duration` is in seconds).","metadata":{}},{"cell_type":"code","source":"train.loc[:, 'avg_speed'] = 1000 * train['distance'] / train['trip_duration']","metadata":{"execution":{"iopub.status.busy":"2022-03-14T15:45:45.822724Z","iopub.execute_input":"2022-03-14T15:45:45.823192Z","iopub.status.idle":"2022-03-14T15:45:45.828778Z","shell.execute_reply.started":"2022-03-14T15:45:45.823155Z","shell.execute_reply":"2022-03-14T15:45:45.828142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"One idea for an approach would be to compute `predicted_trip_duration = predicted_distance*avg_speed` on the test set, and learn to predict the residual `residual = trip_duration - predicted_trip_duration`. That way, we can predict `predicted_trip_duration + residual` as our final submission prediction.\n\nTo do this, we need to predict the speed, and do so in the same way both for test and training set.","metadata":{}},{"cell_type":"code","source":"from sklearn import neighbors\nspeed_model = neighbors.KNeighborsRegressor(n_neighbors=2)\n\nspeed_model.fit(train[['pickup_dt']], train['avg_speed'])","metadata":{"execution":{"iopub.status.busy":"2022-03-14T15:45:45.830174Z","iopub.execute_input":"2022-03-14T15:45:45.830768Z","iopub.status.idle":"2022-03-14T15:45:46.736475Z","shell.execute_reply.started":"2022-03-14T15:45:45.83073Z","shell.execute_reply":"2022-03-14T15:45:46.735721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['pred_speed'] = speed_model.predict(train[['pickup_dt']])\ntest['pred_speed'] = speed_model.predict(test[['pickup_dt']])","metadata":{"execution":{"iopub.status.busy":"2022-03-14T15:45:46.738034Z","iopub.execute_input":"2022-03-14T15:45:46.738268Z","iopub.status.idle":"2022-03-14T15:45:47.280918Z","shell.execute_reply.started":"2022-03-14T15:45:46.738234Z","shell.execute_reply":"2022-03-14T15:45:47.280186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['pred_duration'] = train['pred_speed'] * train['distance']\ntest['pred_duration'] = test['pred_speed'] * test['distance']","metadata":{"execution":{"iopub.status.busy":"2022-03-14T15:45:47.283482Z","iopub.execute_input":"2022-03-14T15:45:47.283737Z","iopub.status.idle":"2022-03-14T15:45:47.294353Z","shell.execute_reply.started":"2022-03-14T15:45:47.283702Z","shell.execute_reply":"2022-03-14T15:45:47.293647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['residuals'] = train['trip_duration'] - train['pred_duration']","metadata":{"execution":{"iopub.status.busy":"2022-03-14T15:45:47.295818Z","iopub.execute_input":"2022-03-14T15:45:47.296113Z","iopub.status.idle":"2022-03-14T15:45:47.302966Z","shell.execute_reply.started":"2022-03-14T15:45:47.296033Z","shell.execute_reply":"2022-03-14T15:45:47.302195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are some clear outliers in the dataset.\nLet's get rid of taxicab trips that are longer than 15h, as well as trips shorter than 1m.","metadata":{}},{"cell_type":"code","source":"print(f\"Shape before dropping outliers: {train.shape}\")\ntrain.drop(train[train[\"trip_duration\"] > 20*60*60].index, inplace=True)\ntrain.drop(train[train[\"trip_duration\"] < 60].index, inplace=True)\nprint(f\"Shape after dropping outliers: {train.shape}\")","metadata":{"execution":{"iopub.status.busy":"2022-03-14T15:45:47.304592Z","iopub.execute_input":"2022-03-14T15:45:47.304912Z","iopub.status.idle":"2022-03-14T15:45:47.32379Z","shell.execute_reply.started":"2022-03-14T15:45:47.304818Z","shell.execute_reply":"2022-03-14T15:45:47.323128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"do_not_use_for_training = ['id', 'pickup_datetime', 'dropoff_datetime',\n                           'trip_duration', 'check_trip_duration',\n                           'pickup_date', 'avg_speed', \n                           'pickup_lat_bin', 'pickup_long_bin',\n                           'center_lat_bin', 'center_long_bin',\n                           'pickup_dt_bin', 'pickup_datetime_group',\n                           'store_and_fwd_flag', \n                           'residuals','pred_speed','pred_duration']\nfeature_names = [f for f in train.columns if f not in do_not_use_for_training]\nX, y = train[feature_names], train[\"residuals\"]\nXtest = test[feature_names]\nprint(f\"Shape of training data: X {X.shape} y {y.shape}\")\nprint(f\"Shape of test features: X {Xtest.shape}\")\nprint(f\"Features used: {feature_names}\")","metadata":{"execution":{"iopub.status.busy":"2022-03-14T15:45:47.325034Z","iopub.execute_input":"2022-03-14T15:45:47.325303Z","iopub.status.idle":"2022-03-14T15:45:47.373119Z","shell.execute_reply.started":"2022-03-14T15:45:47.325261Z","shell.execute_reply":"2022-03-14T15:45:47.372408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import linear_model, model_selection, metrics, pipeline\nfrom sklearn import preprocessing, svm, compose, feature_selection\nimport xgboost\n\ndef rmsle_score(yt, yp): \n    return np.sqrt(metrics.mean_squared_log_error(yt, yp))\n                   \nrmsle = metrics.make_scorer(rmsle_score,greater_is_better=False)\n\nparams = {\n    \"poly__degree\": [2],\n    \"features__score_func\": [feature_selection.f_regression],\n    \"features__k\": [3,5,7,10,13],\n    #\"lm__alpha\": np.logspace(-3,3,7),\n    \"xgb__tree_method\": [\"gpu_hist\"],\n}\nmodel = model_selection.RandomizedSearchCV(\n        pipeline.Pipeline([\n          (\"features\",feature_selection.SelectKBest()),\n          (\"scaler\", preprocessing.StandardScaler()),\n          (\"poly\", preprocessing.PolynomialFeatures()),\n          #(\"lm\", linear_model.Lasso())\n          (\"xgb\", xgboost.XGBRegressor())\n        ]),\n    params, #scoring=rmsle, \n    cv=5, n_jobs=-1)\nmodel.get_params()","metadata":{"execution":{"iopub.status.busy":"2022-03-14T15:45:47.374523Z","iopub.execute_input":"2022-03-14T15:45:47.374787Z","iopub.status.idle":"2022-03-14T15:45:47.499393Z","shell.execute_reply.started":"2022-03-14T15:45:47.37475Z","shell.execute_reply":"2022-03-14T15:45:47.498572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nmodel.fit(X, y)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T15:45:47.500738Z","iopub.execute_input":"2022-03-14T15:45:47.501118Z","iopub.status.idle":"2022-03-14T15:46:12.394853Z","shell.execute_reply.started":"2022-03-14T15:45:47.501077Z","shell.execute_reply":"2022-03-14T15:46:12.391881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Model score: {model.best_score_}\")\nprint(f\"Model chosen parameters: {model.best_params_}\")","metadata":{"execution":{"iopub.status.busy":"2022-03-14T15:46:12.396695Z","iopub.execute_input":"2022-03-14T15:46:12.397414Z","iopub.status.idle":"2022-03-14T15:46:12.408852Z","shell.execute_reply.started":"2022-03-14T15:46:12.397369Z","shell.execute_reply":"2022-03-14T15:46:12.403816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_val = train['pred_duration'] + model.predict(X)\ny_val[y_val < 0] = 0\nprint(f\"Model RMSLE score: {rmsle_score(train['trip_duration'], y_val)}\")","metadata":{"execution":{"iopub.status.busy":"2022-03-14T15:46:12.410463Z","iopub.execute_input":"2022-03-14T15:46:12.411174Z","iopub.status.idle":"2022-03-14T15:46:12.513652Z","shell.execute_reply.started":"2022-03-14T15:46:12.411098Z","shell.execute_reply":"2022-03-14T15:46:12.512861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nsubmission = test[[]].assign(trip_duration=test['pred_duration']+model.predict(Xtest))\nsubmission['trip_duration'] = np.where(submission['trip_duration'] < 0, 0, submission['trip_duration'])\nsubmission.to_csv(\"submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-03-14T15:46:12.515056Z","iopub.execute_input":"2022-03-14T15:46:12.515511Z","iopub.status.idle":"2022-03-14T15:46:16.812184Z","shell.execute_reply.started":"2022-03-14T15:46:12.515472Z","shell.execute_reply":"2022-03-14T15:46:16.810513Z"},"trusted":true},"execution_count":null,"outputs":[]}]}