{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%matplotlib inline\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-08T01:03:51.249344Z","iopub.execute_input":"2022-03-08T01:03:51.249645Z","iopub.status.idle":"2022-03-08T01:03:51.2644Z","shell.execute_reply.started":"2022-03-08T01:03:51.249613Z","shell.execute_reply":"2022-03-08T01:03:51.263547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import zipfile\n\ntrain = pd.read_csv(\"/kaggle/input/nyc-taxi-trip-duration/train.zip\", \n                    compression=\"zip\", index_col=\"id\")\ntest = pd.read_csv(\"/kaggle/input/nyc-taxi-trip-duration/test.zip\",\n                   compression=\"zip\", index_col=\"id\")\n\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-08T01:03:51.269265Z","iopub.execute_input":"2022-03-08T01:03:51.269449Z","iopub.status.idle":"2022-03-08T01:03:57.772764Z","shell.execute_reply.started":"2022-03-08T01:03:51.269427Z","shell.execute_reply":"2022-03-08T01:03:57.772019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's include some sanity checks for the data.","metadata":{}},{"cell_type":"code","source":"print('Id is unique.') if train.index.nunique() == train.shape[0] else print('oops')\nprint('Train and test sets are distinct.') if len(np.intersect1d(train.index.values, test.index.values))== 0 else print('oops')\nprint('We do not need to worry about missing values.') if train.count().min() == train.shape[0] and test.count().min() == test.shape[0] else print('oops')\nprint('The store_and_fwd_flag has only two values {}.'.format(str(set(train.store_and_fwd_flag.unique()) | set(test.store_and_fwd_flag.unique()))))","metadata":{"execution":{"iopub.status.busy":"2022-03-08T01:03:57.779315Z","iopub.execute_input":"2022-03-08T01:03:57.781872Z","iopub.status.idle":"2022-03-08T01:04:08.012113Z","shell.execute_reply.started":"2022-03-08T01:03:57.781805Z","shell.execute_reply":"2022-03-08T01:04:08.011277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['pickup_datetime'] = pd.to_datetime(train.pickup_datetime)\ntest['pickup_datetime'] = pd.to_datetime(test.pickup_datetime)\ntrain.loc[:, 'pickup_date'] = train['pickup_datetime'].dt.date\ntest.loc[:, 'pickup_date'] = test['pickup_datetime'].dt.date\ntrain['dropoff_datetime'] = pd.to_datetime(train.dropoff_datetime)","metadata":{"execution":{"iopub.status.busy":"2022-03-08T01:04:08.013666Z","iopub.execute_input":"2022-03-08T01:04:08.01394Z","iopub.status.idle":"2022-03-08T01:04:10.249467Z","shell.execute_reply.started":"2022-03-08T01:04:08.013911Z","shell.execute_reply":"2022-03-08T01:04:10.24871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Are train and test sets from the same time period?\n\npyplot.plot(train.groupby(\"pickup_date\").count()[[\"vendor_id\"]])\npyplot.plot(test.groupby(\"pickup_date\").count()[[\"vendor_id\"]])","metadata":{"execution":{"iopub.status.busy":"2022-03-08T01:04:10.251437Z","iopub.execute_input":"2022-03-08T01:04:10.251668Z","iopub.status.idle":"2022-03-08T01:04:11.193878Z","shell.execute_reply.started":"2022-03-08T01:04:10.251642Z","shell.execute_reply":"2022-03-08T01:04:11.193212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Are train and test sets from the same geographic area?\n\nN = 10000\ncity_long_border = (-74.03, -73.75)\ncity_lat_border = (40.63, 40.85)\nfig, ax = pyplot.subplots(ncols=2, sharex=True, sharey=True)\nax[0].scatter(train['pickup_longitude'].values[:N], train['pickup_latitude'].values[:N],\n              color='blue', s=1, label='train', alpha=0.1)\nax[1].scatter(test['pickup_longitude'].values[:N], test['pickup_latitude'].values[:N],\n              color='green', s=1, label='test', alpha=0.1)\nfig.suptitle('Train and test area complete overlap.')\nax[0].legend(loc=0)\nax[0].set_ylabel('latitude')\nax[0].set_xlabel('longitude')\nax[1].set_xlabel('longitude')\nax[1].legend(loc=0)\npyplot.ylim(city_lat_border)\npyplot.xlim(city_long_border)","metadata":{"execution":{"iopub.status.busy":"2022-03-08T01:04:11.195242Z","iopub.execute_input":"2022-03-08T01:04:11.195509Z","iopub.status.idle":"2022-03-08T01:04:11.704144Z","shell.execute_reply.started":"2022-03-08T01:04:11.195462Z","shell.execute_reply":"2022-03-08T01:04:11.703424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EARTH_RADIUS=6378.137  ## km\ndef haversine(xy1, xy2):\n    return 2*EARTH_RADIUS*np.arcsin(np.sqrt(\n        np.sin((xy2[:,0]-xy1[:,0])/2)**2 +\n        np.cos(xy1[:,0])*np.cos(xy2[:,0])*np.sin((xy2[:,1]-xy2[:,1])/2)\n    ))\ntrain[\"distance\"] = haversine(\n    np.radians(train[[\"pickup_longitude\", \"pickup_latitude\"]].values),\n    np.radians(train[[\"dropoff_longitude\", \"dropoff_latitude\"]].values))\ntest[\"distance\"] = haversine(\n    np.radians(test[[\"pickup_longitude\", \"pickup_latitude\"]].values),\n    np.radians(test[[\"dropoff_longitude\", \"dropoff_latitude\"]].values))\n\npyplot.hist(np.log(train[\"distance\"]+1e-5), bins=50)","metadata":{"execution":{"iopub.status.busy":"2022-03-08T01:04:11.705302Z","iopub.execute_input":"2022-03-08T01:04:11.705643Z","iopub.status.idle":"2022-03-08T01:04:12.138184Z","shell.execute_reply.started":"2022-03-08T01:04:11.705605Z","shell.execute_reply":"2022-03-08T01:04:12.137447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.loc[:, 'pickup_weekday'] = train['pickup_datetime'].dt.weekday\ntrain.loc[:, 'pickup_weekofyear'] = train['pickup_datetime'].dt.isocalendar().week.astype(\"int32\")\ntrain.loc[:, 'pickup_hour'] = train['pickup_datetime'].dt.hour\ntrain.loc[:, 'pickup_minute'] = train['pickup_datetime'].dt.minute\ntrain.loc[:, 'pickup_dt'] = (train['pickup_datetime'] - train['pickup_datetime'].min()).dt.total_seconds()\ntrain.loc[:, 'pickup_week_hour'] = train['pickup_weekday'] * 24 + train['pickup_hour']\n\ntest.loc[:, 'pickup_weekday'] = test['pickup_datetime'].dt.weekday\ntest.loc[:, 'pickup_weekofyear'] = test['pickup_datetime'].dt.isocalendar().week.astype(\"int32\")\ntest.loc[:, 'pickup_hour'] = test['pickup_datetime'].dt.hour\ntest.loc[:, 'pickup_minute'] = test['pickup_datetime'].dt.minute\ntest.loc[:, 'pickup_dt'] = (test['pickup_datetime'] - train['pickup_datetime'].min()).dt.total_seconds()\ntest.loc[:, 'pickup_week_hour'] = test['pickup_weekday'] * 24 + test['pickup_hour']","metadata":{"execution":{"iopub.status.busy":"2022-03-08T01:04:12.139521Z","iopub.execute_input":"2022-03-08T01:04:12.139786Z","iopub.status.idle":"2022-03-08T01:04:13.796783Z","shell.execute_reply.started":"2022-03-08T01:04:12.139752Z","shell.execute_reply":"2022-03-08T01:04:13.795975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.loc[:, 'avg_speed'] = 1000 * train['distance'] / train['trip_duration']\n\nfig, ax = pyplot.subplots(ncols=3, sharey=True)\nax[0].plot(train.groupby('pickup_hour').mean()['avg_speed'], 'b', lw=2, alpha=0.7)\nax[1].plot(train.groupby('pickup_weekday').mean()['avg_speed'], 'g', lw=2, alpha=0.7)\nax[2].plot(train.groupby('pickup_week_hour').mean()['avg_speed'], 'r', lw=2, alpha=0.7)\nax[0].set_xlabel('hour')\nax[1].set_xlabel('weekday')\nax[2].set_xlabel('weekhour')\nax[0].set_ylabel('average speed')\nfig.suptitle('Rush hour average traffic speed')","metadata":{"execution":{"iopub.status.busy":"2022-03-08T01:04:13.801063Z","iopub.execute_input":"2022-03-08T01:04:13.803031Z","iopub.status.idle":"2022-03-08T01:04:14.843092Z","shell.execute_reply.started":"2022-03-08T01:04:13.802982Z","shell.execute_reply":"2022-03-08T01:04:14.842401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are some clear outliers in the dataset.\nLet's get rid of taxicab trips that are longer than 15h, as well as trips shorter than 1m.","metadata":{}},{"cell_type":"code","source":"print(f\"Shape before dropping outliers: {train.shape}\")\ntrain.drop(train[train[\"trip_duration\"] > 20*60*60].index, inplace=True) # no trip longer than 20h\ntrain.drop(train[train[\"trip_duration\"] < 60].index, inplace=True) # no trip shorter than 60s\ntrain.drop(train[train[\"distance\"] < 0.01].index, inplace=True) #Â no trip shorter than 10m\nprint(f\"Shape after dropping outliers: {train.shape}\")","metadata":{"execution":{"iopub.status.busy":"2022-03-08T01:04:14.844401Z","iopub.execute_input":"2022-03-08T01:04:14.844683Z","iopub.status.idle":"2022-03-08T01:04:16.629325Z","shell.execute_reply.started":"2022-03-08T01:04:14.844647Z","shell.execute_reply":"2022-03-08T01:04:16.628573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.describe()","metadata":{"execution":{"iopub.status.busy":"2022-03-08T01:04:16.632182Z","iopub.execute_input":"2022-03-08T01:04:16.63261Z","iopub.status.idle":"2022-03-08T01:04:17.290258Z","shell.execute_reply.started":"2022-03-08T01:04:16.632569Z","shell.execute_reply":"2022-03-08T01:04:17.289475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.dtypes\n","metadata":{"execution":{"iopub.status.busy":"2022-03-08T01:04:17.291613Z","iopub.execute_input":"2022-03-08T01:04:17.29186Z","iopub.status.idle":"2022-03-08T01:04:17.298747Z","shell.execute_reply.started":"2022-03-08T01:04:17.291825Z","shell.execute_reply":"2022-03-08T01:04:17.297958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Train a model to predict `avg_speed` given `pickup_week_hour` and `pickup_minute`\n# ...or maybe given just the timestamp? worth trying too...\n\nfrom sklearn import neighbors\navg_speed = neighbors.KNeighborsRegressor(2, n_jobs=-1)\navg_speed.fit(train[[\"pickup_week_hour\",\"pickup_minute\"]], train[\"avg_speed\"])\ntest[\"avg_speed\"] = avg_speed.predict(test[[\"pickup_week_hour\",\"pickup_minute\"]])","metadata":{"execution":{"iopub.status.busy":"2022-03-08T01:04:17.300385Z","iopub.execute_input":"2022-03-08T01:04:17.300869Z","iopub.status.idle":"2022-03-08T01:04:24.670147Z","shell.execute_reply.started":"2022-03-08T01:04:17.300831Z","shell.execute_reply":"2022-03-08T01:04:24.669253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.describe()","metadata":{"execution":{"iopub.status.busy":"2022-03-08T01:04:24.671454Z","iopub.execute_input":"2022-03-08T01:04:24.671726Z","iopub.status.idle":"2022-03-08T01:04:24.941922Z","shell.execute_reply.started":"2022-03-08T01:04:24.67169Z","shell.execute_reply":"2022-03-08T01:04:24.941106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Done preprocessing\n\nBy now `train` and `test` both have the same set of features (except for a few that don't occur in `test`). \nIt's time to build the model pipeline, pick features to include, and train the model.","metadata":{}},{"cell_type":"code","source":"do_not_use_for_training = ['id', 'pickup_datetime', 'dropoff_datetime',\n                           'trip_duration', 'check_trip_duration',\n                           'pickup_date', 'vendor_id',\n                           'pickup_lat_bin', 'pickup_long_bin',\n                           'center_lat_bin', 'center_long_bin',\n                           'pickup_dt_bin', 'pickup_datetime_group',\n                           'store_and_fwd_flag']\nfeature_names = [f for f in train.columns if f not in do_not_use_for_training]\nX, y = train[feature_names], train[\"trip_duration\"]\nXtest = test[feature_names]\nprint(f\"Shape of training data: X {X.shape} y {y.shape}\")\nprint(f\"Shape of test features: X {Xtest.shape}\")","metadata":{"execution":{"iopub.status.busy":"2022-03-08T01:04:24.943438Z","iopub.execute_input":"2022-03-08T01:04:24.943717Z","iopub.status.idle":"2022-03-08T01:04:25.053055Z","shell.execute_reply.started":"2022-03-08T01:04:24.943682Z","shell.execute_reply":"2022-03-08T01:04:25.052236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import model_selection\nX_train, X_val, y_train, y_val = model_selection.train_test_split(X,y, test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2022-03-08T01:04:25.054217Z","iopub.execute_input":"2022-03-08T01:04:25.055236Z","iopub.status.idle":"2022-03-08T01:04:25.786516Z","shell.execute_reply.started":"2022-03-08T01:04:25.055194Z","shell.execute_reply":"2022-03-08T01:04:25.78569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import linear_model, model_selection, metrics, pipeline\nfrom sklearn import preprocessing, svm, compose, feature_selection, kernel_approximation\n\nrmsle = metrics.make_scorer(lambda yt, yp: np.sqrt(metrics.mean_squared_log_error(yt, yp)),\n                             greater_is_better=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-08T01:04:25.787717Z","iopub.execute_input":"2022-03-08T01:04:25.78798Z","iopub.status.idle":"2022-03-08T01:04:25.795481Z","shell.execute_reply.started":"2022-03-08T01:04:25.787947Z","shell.execute_reply":"2022-03-08T01:04:25.794618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = [{\n    \"regressor__features__k\": range(3,X.shape[1]),\n    \"regressor__kernelapprox__kernel\": [\"rbf\"],\n    \"regressor__kernelapprox__gamma\": np.logspace(-2,2,3)\n},{\n    \"regressor__features__k\": range(3,X.shape[1]),\n    \"regressor__kernelapprox__kernel\": [\"laplacian\"],\n    \"regressor__kernelapprox__gamma\": np.logspace(-2,2,3)\n},{\n    \"regressor__features__k\": range(3,X.shape[1]),\n    \"regressor__kernelapprox__kernel\": [\"chi2\"],\n    \"regressor__kernelapprox__gamma\": np.logspace(-2,2,3)\n},{\n    \"regressor__features__k\": range(3,X.shape[1]),\n    \"regressor__kernelapprox__kernel\": [\"sigmoid\"],\n    \"regressor__kernelapprox__gamma\": np.logspace(-2,2,3)\n}\n]\nmodel = model_selection.RandomizedSearchCV(\n    compose.TransformedTargetRegressor(\n        regressor=pipeline.Pipeline([\n          (\"features\",feature_selection.SelectKBest(score_func=feature_selection.f_regression)),\n          (\"scaler\", preprocessing.StandardScaler()),\n          (\"kernelapprox\", kernel_approximation.Nystroem()),\n          (\"svm\", svm.LinearSVR())]),\n        func=np.log, inverse_func=np.exp),\n    params, scoring=rmsle, cv=5, n_jobs=-1, n_iter=20, verbose=2)\nmodel.get_params()","metadata":{"execution":{"iopub.status.busy":"2022-03-08T01:04:25.796698Z","iopub.execute_input":"2022-03-08T01:04:25.797216Z","iopub.status.idle":"2022-03-08T01:04:25.835958Z","shell.execute_reply.started":"2022-03-08T01:04:25.797178Z","shell.execute_reply":"2022-03-08T01:04:25.835041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import ensemble, tree, decomposition\nimport xgboost\n    \nparams = {\n    \"xgb__objective\": [\"reg:squaredlogerror\"],\n    \"xgb__eval_metric\": [\"rmsle\"],\n    \"xgb__tree_method\": [\"gpu_hist\"],\n    \"xgb__grow_policy\": [\"depthwise\", \"lossguide\"],\n    \"xgb__min_split_loss\": [0, 0.1, 0.5, 1, 5],\n    \"xgb__max_depth\": [2,4,6,8,10],\n    \"xgb__min_child_weight\": [5,10,50,100],\n    \"xgb__subsample\": [1.0, 0.75, 0.5, 0.25, 0.1],\n    \"xgb__sampling_method\": [\"uniform\", \"gradient_based\"],\n    \"xgb__n_estimators\": [50,100,200]\n}\n\nmodel = model_selection.RandomizedSearchCV(\n    pipeline.Pipeline([\n        (\"scaler\", preprocessing.StandardScaler()),\n        (\"xgb\", xgboost.XGBRegressor())]),\n    params, scoring=rmsle, cv=model_selection.TimeSeriesSplit(5), n_jobs=-1, verbose=1, n_iter=20\n)\nmodel.get_params()","metadata":{"execution":{"iopub.status.busy":"2022-03-08T02:27:15.823981Z","iopub.execute_input":"2022-03-08T02:27:15.824246Z","iopub.status.idle":"2022-03-08T02:27:15.849194Z","shell.execute_reply.started":"2022-03-08T02:27:15.824215Z","shell.execute_reply":"2022-03-08T02:27:15.84844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nmodel.fit(X, y)","metadata":{"execution":{"iopub.status.busy":"2022-03-08T02:27:20.522219Z","iopub.execute_input":"2022-03-08T02:27:20.522768Z","iopub.status.idle":"2022-03-08T02:30:46.746457Z","shell.execute_reply.started":"2022-03-08T02:27:20.522727Z","shell.execute_reply":"2022-03-08T02:30:46.745752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Model score: {model.best_score_}\")\nprint(f\"Model chosen parameters: {model.best_params_}\")","metadata":{"execution":{"iopub.status.busy":"2022-03-08T02:30:46.748192Z","iopub.execute_input":"2022-03-08T02:30:46.748694Z","iopub.status.idle":"2022-03-08T02:30:46.753751Z","shell.execute_reply.started":"2022-03-08T02:30:46.748655Z","shell.execute_reply":"2022-03-08T02:30:46.753069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nsubmission = test[[]].assign(trip_duration=model.best_estimator_.predict(Xtest)).to_csv(\"submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-03-08T01:08:24.908429Z","iopub.execute_input":"2022-03-08T01:08:24.908919Z","iopub.status.idle":"2022-03-08T01:08:27.944913Z","shell.execute_reply.started":"2022-03-08T01:08:24.908873Z","shell.execute_reply":"2022-03-08T01:08:27.944134Z"},"trusted":true},"execution_count":null,"outputs":[]}]}