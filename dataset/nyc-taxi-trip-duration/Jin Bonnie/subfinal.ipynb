{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#imports\nimport os\nimport csv\nimport pandas as pd\nimport numpy as np\nfrom matplotlib.pyplot import *\nimport matplotlib.pyplot as plt\nfrom matplotlib import animation\nfrom matplotlib import cm\nfrom sklearn.cluster import KMeans\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom dateutil import parser\nimport io\nimport base64\nfrom IPython.display import HTML\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom subprocess import check_output\nimport seaborn as sns\n#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import zipfile","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with zipfile.ZipFile(\"../input/nyc-taxi-trip-duration/test.zip\",\"r\") as z:\n    z.extractall(\".\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with zipfile.ZipFile(\"../input/nyc-taxi-trip-duration/train.zip\",\"r\") as z:\n    z.extractall(\".\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/nyc-taxi-trip-duration/train.zip')\ntest = pd.read_csv('../input/nyc-taxi-trip-duration/test.zip')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Datetyping the dates\ntrain['pickup_datetime'] = pd.to_datetime(train.pickup_datetime)\ntest['pickup_datetime'] = pd.to_datetime(test.pickup_datetime)\n\ntrain.drop(['dropoff_datetime'], axis=1, inplace=True) #as we don't have this feature in the testset\n\n#Date features creations and deletions\ntrain['month'] = train.pickup_datetime.dt.month\ntrain['week'] = train.pickup_datetime.dt.week\ntrain['weekday'] = train.pickup_datetime.dt.weekday\ntrain['hour'] = train.pickup_datetime.dt.hour\ntrain['minute'] = train.pickup_datetime.dt.minute\ntrain['minute_oftheday'] = train['hour'] * 60 + train['minute']\ntrain.drop(['minute'], axis=1, inplace=True)\n\ntest['month'] = test.pickup_datetime.dt.month\ntest['week'] = test.pickup_datetime.dt.week\ntest['weekday'] = test.pickup_datetime.dt.weekday\ntest['hour'] = test.pickup_datetime.dt.hour\ntest['minute'] = test.pickup_datetime.dt.minute\ntest['minute_oftheday'] = test['hour'] * 60 + test['minute']\ntest.drop(['minute'], axis=1, inplace=True)\n\ntrain.drop(['pickup_datetime'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#One-hot encoding binary categorical features\ntrain = pd.concat([train, pd.get_dummies(train['store_and_fwd_flag'])], axis=1)\ntest = pd.concat([test, pd.get_dummies(test['store_and_fwd_flag'])], axis=1)\n\ntrain.drop(['store_and_fwd_flag'], axis=1, inplace=True)\n\ntrain = pd.concat([train, pd.get_dummies(train['vendor_id'])], axis=1)\ntest = pd.concat([test, pd.get_dummies(test['vendor_id'])], axis=1)\n\ntrain.drop(['vendor_id'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Function aiming at calculating distances from coordinates\ndef ft_haversine_distance(lat1, lng1, lat2, lng2):\n    lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2))\n    AVG_EARTH_RADIUS = 6371 #km\n    lat = lat2 - lat1\n    lng = lng2 - lng1\n    d = np.sin(lat * 0.5) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(lng * 0.5) ** 2\n    h = 2 * AVG_EARTH_RADIUS * np.arcsin(np.sqrt(d))\n    return h\n\n#Add distance feature\ntrain['distance'] = ft_haversine_distance(train['pickup_latitude'].values,\n                                                 train['pickup_longitude'].values, \n                                                 train['dropoff_latitude'].values,\n                                                 train['dropoff_longitude'].values)\ntest['distance'] = ft_haversine_distance(test['pickup_latitude'].values, \n                                                test['pickup_longitude'].values, \n                                                test['dropoff_latitude'].values, \n                                                test['dropoff_longitude'].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Function aiming at calculating the direction\ndef ft_degree(lat1, lng1, lat2, lng2):\n    AVG_EARTH_RADIUS = 6371 #km\n    lng_delta_rad = np.radians(lng2 - lng1)\n    lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2))\n    y = np.sin(lng_delta_rad) * np.cos(lat2)\n    x = np.cos(lat1) * np.sin(lat2) - np.sin(lat1) * np.cos(lat2) * np.cos(lng_delta_rad)\n    return np.degrees(np.arctan2(y, x))\n\n#Add direction feature\ntrain['direction'] = ft_degree(train['pickup_latitude'].values,\n                                train['pickup_longitude'].values,\n                                train['dropoff_latitude'].values,\n                                train['dropoff_longitude'].values)\ntest['direction'] = ft_degree(test['pickup_latitude'].values,\n                                  test['pickup_longitude'].values, \n                                  test['dropoff_latitude'].values,\n                                  test['dropoff_longitude'].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualize distance outliers\ntrain.boxplot(column='distance', return_type='axes');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Remove distance outliers\ntrain = train[(train.distance < 200)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create speed feature\ntrain['speed'] = train.distance / train.trip_duration","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualize speed feature\ntrain.boxplot(column='speed', return_type='axes');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Remove speed outliers\ntrain = train[(train.speed < 30)]\ntrain.drop(['speed'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_cols = ['passenger_count','pickup_longitude','pickup_latitude',\n                'dropoff_longitude','dropoff_latitude',\n                'N','Y','month','week','weekday','hour',\n                'minute_oftheday','distance','direction']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = train[feature_cols]\ny_train = np.log1p(train['trip_duration']) \nx_test = test[feature_cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.2, random_state=1)\nXcv,Xv,Zcv,Zv = train_test_split(x_valid, y_valid, test_size=0.4, random_state=1)\ndata_tr  = xgb.DMatrix(x_train, label=y_train)\ndata_cv  = xgb.DMatrix(Xcv   , label=Zcv)\nevallist = [(data_tr, 'train'), (data_cv, 'valid')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"parms = {'max_depth':10, \n         'objective':'reg:linear',\n         'eta'      :0.05,\n         'subsample':0.8,#SGD will use this percentage of data\n#         'lambda '  :4, #L2 regularization term,>1 more conservative \n#         'colsample_bytree ':0.9,\n         'colsample_bylevel':1,\n         'min_child_weight': 10,\n         'nthread'  :3}  #number of cpu core to use\n\n#def xgb_rmsle_score(preds, dtrain):\n#    labels = dtrain.get_label()\n#    return 'rmsle', rmsle(preds, labels)\n\n#watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n#data_tr  = xgb.DMatrix(x_train, label=y_train)\n#data_cv  = xgb.DMatrix(Xcv   , label=Zcv)\n\nclf = xgb.train(parms, data_tr, num_boost_round=1000, evals = evallist,\n                  early_stopping_rounds=100, maximize=False, \n                  verbose_eval=100)\n\n#print('score = %1.5f, n_boost_round =%d.'%(model.best_score,model.best_iteration))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('score = %1.5f, n_boost_round =%d.'%(clf.best_score,clf.best_iteration))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test = xgb.DMatrix(x_test)\nztest = clf.predict(data_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ytest = np.exp(ztest)-1\nprint(ytest[:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({'id': test.id, 'trip_duration': ytest})\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}