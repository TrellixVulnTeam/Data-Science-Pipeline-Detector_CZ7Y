{"metadata":{"language_info":{"version":"3.6.3","file_extension":".py","mimetype":"text/x-python","codemirror_mode":{"version":3,"name":"ipython"},"pygments_lexer":"ipython3","nbconvert_exporter":"python","name":"python"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat_minor":1,"cells":[{"execution_count":null,"metadata":{"_cell_guid":"3d3c280b-6da4-4c67-ad6a-155ebb3ab3e0","collapsed":true,"_uuid":"23d30cd33b6fd93ca1121ead019092b71b6d5fa0"},"outputs":[],"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib\nfrom matplotlib import pyplot as plt \n#%matplotlib inline"},{"metadata":{"_cell_guid":"df044721-839d-4cde-91c5-002657e8bb19","_uuid":"858ddc8c3fbfbc763e89aa6b133ee89200839fce"},"cell_type":"markdown","source":"# Load training data"},{"execution_count":null,"metadata":{"_cell_guid":"28b5daec-477c-4f33-9453-39a64c194617","_uuid":"e75442f795ca97c99fb0d6ba32a67b568ad64e91"},"outputs":[],"cell_type":"code","source":"data = pd.read_csv('../input/train.csv')\ndata.describe()"},{"metadata":{"_cell_guid":"090cb60a-686c-4c02-8262-392202b4d97a","_uuid":"09ad011fe9086ca4dd37e3f2bd26acaccd4b5520"},"cell_type":"markdown","source":"# Split train data into validation and train set"},{"execution_count":null,"metadata":{"_cell_guid":"901b9c5a-2e32-4d16-8f73-1f011f88b85f","_uuid":"decdcbfc0ba9d7617fd5f46675f443395a173d69"},"outputs":[],"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_data, validation_data = train_test_split(data, test_size=0.3)\n\ntrain_data.describe()"},{"metadata":{"_cell_guid":"39fbdca3-f213-461c-aafe-817100aaafa7","_uuid":"d34eee05d5aacce57596c6162a49d49c85685bcf"},"cell_type":"markdown","source":"# WORD2VEC\n\n   Train word2vec model"},{"execution_count":null,"metadata":{"_cell_guid":"f5177981-bf5a-4aed-891b-6d690d4c6e72","_uuid":"347ddde15ab99114b04ea6c5063769e3ee6e54ed"},"outputs":[],"cell_type":"code","source":"from gensim.models import word2vec\nimport gensim.models\nimport gensim.utils\n\nsentences = data['text']\nsentences = (sentences.map(lambda x: gensim.utils.simple_preprocess(x)).tolist())\nprint(\"# of sentences = {}\".format(len(sentences)))\n\nphrases = gensim.models.Phrases(sentences)\nbigram = gensim.models.phrases.Phraser(phrases)\nmodel = word2vec.Word2Vec(list(bigram[sentences]),size=100)\n\nwv = model.wv\ndel model\n\nsimilar = wv.most_similar(positive=['woman'], negative=['man'])\nsimilar = map(lambda x: '{}\\t\\t\\t{}'.format(x[0],x[1]),similar)\nprint('Similar Words:','\\n' + '\\n'.join(similar))\n\nprint('Family - Woman similarity:',wv.similarity('family','woman'))\nprint('Family - Man similarity:',wv.similarity('family','man'))\n\nvocab = list(wv.vocab.keys())\nfeatures = wv[wv.vocab]\n\nprint('{} Words in model'.format(len(vocab)))"},{"metadata":{},"cell_type":"markdown","source":"Visualize word2vec vectors using TSNE"},{"execution_count":null,"metadata":{"scrolled":false},"outputs":[],"cell_type":"code","source":"from sklearn.manifold import TSNE\n\nfeatures_2d = TSNE(n_components=2,perplexity = 1).fit_transform(features)\n\n'''\nplt.figure()\n#plt.scatter(features_2d[:,0], features_2d[:,1])\n\nfor i in range(features_2d.shape[0]):\n    plt.text(features_2d[i,0],features_2d[i,1], vocab[i],\n             horizontalalignment='center', verticalalignment='center',clip_on=True)\n\nplt.xlim(np.min(features_2d[:,0]), np.max(features_2d[:,0]))\nplt.ylim(np.min(features_2d[:,1]), np.max(features_2d[:,1]))\nplt.show()\n'''"},{"metadata":{"_cell_guid":"0186c0b7-3e4d-4953-944a-e1eda0e897a7","_uuid":"e263f1c6b9c7abec7fdf68f121b125298e1da916"},"cell_type":"markdown","source":"# Cluster words\n\nCluster words using word2vec and "},{"execution_count":null,"metadata":{"_cell_guid":"b158f933-f81e-4812-99c8-db8f1b9b157e","scrolled":true,"_uuid":"58e3cd30a6074209b4d7135ffeaaa0d2c4dc506c"},"outputs":[],"cell_type":"code","source":"import matplotlib.cm\nfrom sklearn.cluster import DBSCAN\n\ncluster_alg = DBSCAN(eps=3)\n\n#from sklearn.cluster\n\nclusters = cluster_alg.fit_predict(features_2d)\n\nnclusters = np.unique(clusters).shape[0]\nprint(\"{} clusters\".format(nclusters))\n\nnorm = matplotlib.colors.Normalize(vmin=0, vmax=nclusters, clip=True)\nmapper = matplotlib.cm.ScalarMappable(norm=norm, cmap=matplotlib.cm.Spectral)\n\nplt.figure(figsize=(10,10),dpi=500)\n#plt.scatter(features_2d[:,0], features_2d[:,1])\n\nfor i in range(features_2d.shape[0]):\n    plt.text(features_2d[i,0],features_2d[i,1], vocab[i], color=mapper.to_rgba(clusters[i]),\n             horizontalalignment='center', verticalalignment='center',clip_on=True,\n                fontsize=3)\n    #plt.scatter(features_2d[i,0],features_2d[i,1],color=mapper.to_rgba(clusters[i]))\n\nplt.xlim(np.min(features_2d[:,0]) - 5, np.max(features_2d[:,0]) + 5)\nplt.ylim(np.min(features_2d[:,1]) - 5, np.max(features_2d[:,1]) + 5)\nplt.title('Clustered vocabulary')\nplt.savefig('out.csv',format = 'png',dpi=1000)\nprint('Saved...')\n\n"},{"execution_count":null,"metadata":{"_cell_guid":"f615da0f-f620-4589-a567-c8564768c5dd","_uuid":"61245c368a9dcac37b3d33ab9658ec1b41cbeb73"},"outputs":[],"cell_type":"code","source":"av = np.array(vocab)\n\nnc = len(np.unique(clusters))\nfor c in np.unique(clusters):\n    \n    cf = av[clusters == c]\n    if (cf.shape[0] > 1):\n        print(\"{}[{}] : {}\".format(c, cf.shape[0], cf))"},{"execution_count":null,"metadata":{"_cell_guid":"a37218b2-20d2-4d91-91a5-4bc4f388fd2a","collapsed":true,"_uuid":"8cab7be460de598cf3db246f89704a4047c4bcbd"},"outputs":[],"cell_type":"code","source":""}],"nbformat":4}