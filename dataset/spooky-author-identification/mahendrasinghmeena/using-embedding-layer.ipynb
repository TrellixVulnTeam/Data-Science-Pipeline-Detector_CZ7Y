{"nbformat":4,"cells":[{"outputs":[],"execution_count":null,"metadata":{"_uuid":"f13c617f9d6752189e26b41dc60aeb38ea61ddb6","_cell_guid":"33dcffc7-63e8-4f35-bd69-e9e9f2fffa36"},"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","cell_type":"code"},{"outputs":[],"execution_count":null,"metadata":{"_uuid":"6e61e47927ad7ad937c197bc1f1cd4a91432f89d","collapsed":true,"_cell_guid":"6c3b934d-ab00-453d-9a1f-0ab845a1e0a1"},"source":"df = pd.read_csv('../input/train.csv')","cell_type":"code"},{"outputs":[],"execution_count":null,"metadata":{"_uuid":"8e8cf652ed253c0d0eecf487d8593819e3e780e2","_cell_guid":"0b2fc296-c613-4b6c-a006-70f003e38e5b"},"source":"df","cell_type":"code"},{"outputs":[],"execution_count":null,"metadata":{"_uuid":"0414a755f74e61a538524a0cd4238c00789bcbe5","_cell_guid":"4a36167d-2637-4d94-91a4-fb57dc14d10d"},"source":"from keras.preprocessing.text import one_hot\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom keras.layers.embeddings import Embedding\nvocab_size = 500\ndf['encoded_text'] = [one_hot(x, vocab_size) for x in df['text']]","cell_type":"code"},{"outputs":[],"execution_count":null,"metadata":{"_uuid":"6521abffd5ec504005c0bc6ff523ccc572fa1f71","collapsed":true,"_cell_guid":"17b78d45-8f29-4924-b723-586864069100"},"source":"# pad documents to a max length of 4 words\nmax_length = 256\npadded_text = pad_sequences(df['encoded_text'], maxlen=max_length, padding='post')","cell_type":"code"},{"outputs":[],"execution_count":null,"metadata":{"_uuid":"651e1cf9e8e5f05954296edbb9cd0966db86944f","_cell_guid":"bfbb1a6e-082a-4c3d-bf1e-8cbef0e734b2"},"source":"padded_text[0]","cell_type":"code"},{"outputs":[],"execution_count":null,"metadata":{"_uuid":"972d91a674d31a4d15fa1e3778cb71be4af38eb4","_cell_guid":"c6df8d84-13d3-47a2-8003-85eb688c52ea"},"source":"from keras import regularizers, optimizers\nfrom keras.layers import BatchNormalization\n# define the model\nmodel = Sequential()\nmodel.add(Embedding(vocab_size, 50, input_length=max_length))\nmodel.add(Flatten())\nmodel.add(BatchNormalization())\n#model.add(Dense(1000, activation='relu', kernel_regularizer=regularizers.l2(0.02)))\nmodel.add(Dense(400, activation='elu', kernel_regularizer=regularizers.l2(0.01)))\nmodel.add(Dense(3, activation='softmax', kernel_regularizer=regularizers.l2(0.01)))\n# compile the model\nsgd = optimizers.SGD(lr=0.018, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n#model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['acc'])\n# summarize the model\nprint(model.summary())","cell_type":"code"},{"outputs":[],"execution_count":null,"metadata":{"_uuid":"deaed9e968379b49282625458591146b1d6176a3","collapsed":true,"_cell_guid":"728695be-ba9e-490e-97d2-9c2d64c9a806"},"source":"import keras\nfrom keras.layers import Dense, GlobalAveragePooling1D, Embedding\nimport keras.backend as K\nfrom keras.callbacks import EarlyStopping\nfrom keras.models import Sequential\n\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\na2c = {'EAP':0, 'HPL':1, 'MWS':2}\nlabels = to_categorical([a2c[x] for x in df['author']])","cell_type":"code"},{"outputs":[],"execution_count":null,"metadata":{"_uuid":"f20e40430201235dc0b195ed3b25fc2c505b6b04","_cell_guid":"3b1ee2ae-5401-4e26-bf74-efb229d453c0"},"source":"labels[:10]","cell_type":"code"},{"outputs":[],"execution_count":null,"metadata":{"_kg_hide-output":false,"_uuid":"670d94eaeca058a26383d653f6fe7ada24f9eb40","_kg_hide-input":true,"_cell_guid":"4ba652c5-ce98-4535-bebf-5bd0dd33ea4f"},"source":"# fit the model\nmodel.fit(padded_text, labels, epochs=50, verbose=1,batch_size=256, validation_split=0.33)","cell_type":"code"},{"outputs":[],"execution_count":null,"metadata":{"_uuid":"b1571693779c19b9ceb54cf8d654a8ca707bdf9a","collapsed":true,"_cell_guid":"fce25926-1f09-49ed-8047-0963c491886f"},"source":"df_test = pd.read_csv('../input/test.csv')\ndf_test['encoded_text'] = [one_hot(x, vocab_size) for x in df_test['text']]\npadded_text_test = pad_sequences(df_test['encoded_text'], maxlen=max_length, padding='post')\ny_pred = model.predict_proba(padded_text_test)\n\nresult = pd.read_csv('../input/sample_submission.csv')\nfor a, i in a2c.items():\n    result[a] = y_pred[:, i]","cell_type":"code"},{"outputs":[],"execution_count":null,"metadata":{"_uuid":"10b1b4545f3c425aa06448fc5b88aacc9a1b0cfa","collapsed":true,"_cell_guid":"f510c850-605b-42f1-b0bb-11fce906256b"},"source":"result.to_csv('out.csv')","cell_type":"code"},{"outputs":[],"execution_count":null,"metadata":{"_uuid":"7850e99286971e6986bbfd8fe1aadd33b6af6e59","collapsed":true,"_cell_guid":"edf980a1-c793-4b77-8090-30044322d25e"},"source":"print(one_hot('man', 2))\nprint(one_hot('woman', 2))\n","cell_type":"code"},{"outputs":[],"execution_count":null,"metadata":{"_uuid":"ca882d3fca9b817de673c99040b1a50a098e27b2","collapsed":true,"_cell_guid":"b4d10c37-3717-49b0-9366-d79dba40e5f7"},"source":"","cell_type":"code"}],"nbformat_minor":1,"metadata":{"language_info":{"nbconvert_exporter":"python","codemirror_mode":{"name":"ipython","version":3},"mimetype":"text/x-python","version":"3.6.3","file_extension":".py","name":"python","pygments_lexer":"ipython3"},"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"}}}