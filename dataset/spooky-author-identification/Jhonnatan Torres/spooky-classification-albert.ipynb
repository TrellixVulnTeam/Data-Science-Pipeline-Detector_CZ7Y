{"cells":[{"metadata":{},"cell_type":"markdown","source":"# ALBERT Model applied to the Spooky Classification Dataset\n\n- The goal of this notebook is to apply an ALBERT model to the spooky classification dataset, I could apply it to a more simple dataset like the Yelp Comments, IMDB reviews or the 20newsgroup dataset, however, as a Machine Learning exercise and because I want to improve my skills in the Tensorflow framework, I decided to use this dataset\n- The key reference for this notebook is available in the official TF Documentation **https://www.tensorflow.org/tutorials/text/classify_text_with_bert**\n<br><br>\n**Note:** English is not my primary language, my apologies in advance for any grammar mistake or typo"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"id":"GV70Oy696KGX"},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"hF14FxyS6KGo"},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/spooky-author-identification/train.zip')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"SFFeRHjc6KGp"},"cell_type":"code","source":"df.drop(columns='id', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"SZfscKnD6KGq","outputId":"dc1bac48-97d6-46af-f863-5b9bfcd497d4"},"cell_type":"code","source":"df.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"zQll89v66KGr"},"cell_type":"code","source":" df['text'] = df['text'].str.lower()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"zEeSnN3X6KGs","outputId":"ce4de9e7-f768-4b6c-9d89-2daf6423c606"},"cell_type":"code","source":"df.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"4MpnWZS76KGt","outputId":"0c86c397-7d52-42f4-b71a-8304dc110664"},"cell_type":"code","source":"df.author.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"vlMLoZvf6KGu"},"cell_type":"code","source":"authors_dict = {'EAP' : 0,\n                'MWS' : 1,\n                'HPL' : 2}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"SlsEYJqY6KGu"},"cell_type":"code","source":"df['author'] = df['author'].map(authors_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"dJGfQPHi6KGv"},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\nfrom sklearn.preprocessing import MaxAbsScaler\nfrom sklearn.svm import SVC\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import log_loss, confusion_matrix, classification_report\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"vqVuosag6KGw","outputId":"d8ff6902-b0db-48df-981f-a78ed26143a3"},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(df['text'], df['author'], test_size=0.30, \n                                                    stratify=df['author'], random_state=1234)\nprint(X_train.shape, X_test.shape, y_train.shape, y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"rD8q3lxe6KGx"},"cell_type":"code","source":"vectorizer = TfidfVectorizer(ngram_range=(1,1), min_df=2, max_features=5000, lowercase=False, stop_words=None)\nscaler = MaxAbsScaler()\nclassifier = BernoulliNB(binarize=0, alpha=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"w1OlDm4_6KGy"},"cell_type":"code","source":"pl = make_pipeline(vectorizer, classifier)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"id":"hCcqS_z46KGz","outputId":"4d731df5-51ea-413c-dd22-7fd6b4e0fdb1"},"cell_type":"code","source":"pl.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"4jIKtkcd6KG0"},"cell_type":"code","source":"preds_prob = pl.predict_proba(X_test)\npreds_class = pl.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"7LwHxXds6KG0","outputId":"20fc0e94-315b-47a8-d518-81a68bfd32d4"},"cell_type":"code","source":"nb_loss = log_loss(y_test, preds_prob)\nprint(nb_loss)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"BHeKdKGk6KG2","outputId":"d9d1b873-8c42-4bdb-fdd3-539311d33b64"},"cell_type":"code","source":"print(confusion_matrix(y_test, preds_class))\nprint('\\n')\nprint(classification_report(y_test, preds_class))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"These metrics can be used as a baseline, a pretty simple Naive Bayes model was fitted and achieved an accuracy of around **81%** not bad for a very simple model"},{"metadata":{"_kg_hide-output":true,"trusted":true,"id":"Fr0mW_rf6KG3","outputId":"219b9127-d11a-47c1-cb75-ad033bb240a9"},"cell_type":"code","source":"#This is a key step, you have to specify the version in order to avoid the Kaggle's kernel to upgrade tensorflow \n#and another dependencies that generate an error when Tensorflow tries to recognize the GPU\n!pip install tensorflow_text==2.3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"tsmxIU4b6KG4"},"cell_type":"code","source":"import tensorflow\nimport tensorflow_hub as hub\nimport tensorflow_text as text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tensorflow.random.set_seed(1234)\nnp.random.seed(1234)\nimport random\nrandom.seed(1234)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"G6aH5uI06KG4"},"cell_type":"code","source":"#extracted from the Tensorflow Hub\nURL_PREPROCESSOR = \"http://tfhub.dev/tensorflow/albert_en_preprocess/2\"\nURL_ENCODER = \"https://tfhub.dev/tensorflow/albert_en_base/2\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"kARwApsU6KG5"},"cell_type":"code","source":"#Adjusted model based on the example explained in the official documentation available in the following link: \n#https://www.tensorflow.org/tutorials/text/classify_text_with_bert\ndef build_classifier_model():\n    text_input = tensorflow.keras.layers.Input(shape=(), dtype=tensorflow.string, name='text')\n    preprocessing_layer = hub.KerasLayer(URL_PREPROCESSOR, name='preprocessing')\n    encoder_inputs = preprocessing_layer(text_input)\n    encoder = hub.KerasLayer(URL_ENCODER, trainable=True, name='ALBERT_encoder')\n    outputs = encoder(encoder_inputs)\n    net = outputs['pooled_output']\n    net = tensorflow.keras.layers.Dropout(0.50)(net)\n    net = tensorflow.keras.layers.Dense(3, activation='softmax', name='classifier_b')(net)\n    return tensorflow.keras.Model(text_input, net)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"FGt10D3X6KG6"},"cell_type":"code","source":"classifier_model = build_classifier_model()","execution_count":null,"outputs":[]},{"metadata":{"id":"iQTdbAp0JRTp","outputId":"27680b3c-0b76-4f01-9107-6db61296d2a8","trusted":true},"cell_type":"code","source":"!pip install -q tf-models-official","execution_count":null,"outputs":[]},{"metadata":{"id":"eJ_zYlcCJRN7","trusted":true},"cell_type":"code","source":"from official.nlp import optimization  # to create AdamW optmizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"50mi-LQg6KG7","outputId":"cbd78d44-8ede-42d6-ceb6-83177cfce7cc"},"cell_type":"code","source":"train_tf, test_tf = train_test_split(df, test_size=0.30, stratify=df['author'], random_state=1234)\nprint(train_tf.shape, test_tf.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"10Y6kOy06KG8"},"cell_type":"code","source":"#Utility referenced in the TF documentation to \"transform\" the pandas dataframe to a TF Tensor\n#https://www.tensorflow.org/tutorials/structured_data/preprocessing_layers#create_an_input_pipeline_using_tfdata\ndef df_to_dataset(dataframe, batch_size=32):\n    dataframe = dataframe.copy()\n    labels = dataframe.pop('author')\n    ds = tensorflow.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n    ds = ds.batch(batch_size)\n    return ds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"eMNiYoSH6KG9"},"cell_type":"code","source":"train_ds = df_to_dataset(train_tf, batch_size=32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"wq8slVZJ6KG-"},"cell_type":"code","source":"test_ds = df_to_dataset(test_tf, batch_size=32)","execution_count":null,"outputs":[]},{"metadata":{"id":"rnk8a6pCKN-1","trusted":true},"cell_type":"code","source":"#Optimizer referenced in the documentation example\nepochs = 5\nsteps_per_epoch = tensorflow.data.experimental.cardinality(train_ds).numpy()\nnum_train_steps = steps_per_epoch * epochs\nnum_warmup_steps = int(0.1*num_train_steps)\n\ninit_lr = 3e-5\noptimizer = optimization.create_optimizer(init_lr=init_lr,\n                                          num_train_steps=num_train_steps,\n                                          num_warmup_steps=num_warmup_steps,\n                                          optimizer_type='adamw')","execution_count":null,"outputs":[]},{"metadata":{"id":"aaESrt8sKNz0","trusted":true},"cell_type":"code","source":"classifier_model.compile(optimizer=optimizer,\n                         loss='sparse_categorical_crossentropy',\n                         metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"D5f-Xi2c6KG-","outputId":"cbdf638f-b744-4536-94a2-e94a08a3d744"},"cell_type":"code","source":"#to check the TF version and the GPU used in the training\nimport tensorflow\nprint(tensorflow.__version__)\ntensorflow.test.gpu_device_name()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"O2Toumfk6KG_","outputId":"8c4b283f-be0f-46c1-85a5-9afdbbfbddf3"},"cell_type":"code","source":"EPOCHS=3\nwith tensorflow.device('/device:GPU:0'):\n    history = classifier_model.fit(x=train_ds, validation_data=test_ds, batch_size=32, epochs=EPOCHS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"I4MjqUtV6KHA","outputId":"60c55506-e83f-430d-cca6-b1819391dc54"},"cell_type":"code","source":"classifier_model.evaluate(train_ds, batch_size=32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"W75qJCSk6KHA","outputId":"f9f657e2-2f2d-4839-9dd3-cee4ebf5f6df"},"cell_type":"code","source":"classifier_model.evaluate(test_ds, batch_size=32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"u38BFmDv6KHB"},"cell_type":"code","source":"tf_preds = classifier_model.predict(test_ds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"QLzCd8QY6KHC","outputId":"78af2b5e-6b5a-43d3-cd62-70bf98404ee0"},"cell_type":"code","source":"classifier_model.predict(X_test)[0:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"zASzqn9r6KHC","outputId":"9261bd56-14e2-42c1-f223-767c50bf84bb"},"cell_type":"code","source":"y_test[0:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"QJHjw39p6KHD","outputId":"80a95469-33c7-41c4-e175-4fec0eb74977"},"cell_type":"code","source":"albert_loss = log_loss(y_test, tf_preds)\nprint(albert_loss)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Multiclass Loss or Log Loss (Sklearn) is the metric defined by Kaggle for this competition\ndiff_loss = nb_loss - albert_loss\nif albert_loss < nb_loss:\n    print(\"ALBERT improved the loss metric by {}\".format(diff_loss))\nelse: print(\"loss metric was not improved by ALBERT compared to the base NB model\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"ZjR_ySWw6KHE","outputId":"ed260e2d-1543-46b9-a967-34ed488886ac"},"cell_type":"code","source":"tf_preds[0:5], y_test.iloc[0:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"o29bzrDK6KHE"},"cell_type":"code","source":"import numpy as np\ntf_preds_class = np.argmax(tf_preds, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"8CJ_OTwQ6KHF","outputId":"79bdeae6-ff1c-4f90-f223-75ed0b900fbf"},"cell_type":"code","source":"print(confusion_matrix(y_test, tf_preds_class))\nprint('\\n')\nprint(classification_report(y_test, tf_preds_class))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dep = pd.read_csv('/kaggle/input/spooky-author-identification/test.zip')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dep.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dep_preds = classifier_model.predict(dep['text'].values)\ndep_df = pd.DataFrame(data=dep_preds, columns=['EAP','MWS','HPL'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit_df = pd.concat([dep,dep_df], axis='columns')\nsubmit_df.drop(columns='text', inplace=True)\nsubmit_df.to_csv('submit.csv', index=False, index_label=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit_df.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Final Notes:\nAn ALBERT (A Light BERT Model) was applied to this dataset based on an example provided in the official TF documentation, same optimizer was used, however, base model was changed and an additional utility was used in order to transform the pandas dataframe to a TF tensor.\n\nThis is an example about how the different transformers available in the TF Hub can be used in a Text Classification Task."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}