{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport nltk\nfrom nltk.corpus import stopwords\nfrom gensim.models import word2vec\nfrom sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\nfrom sklearn.model_selection import train_test_split\nimport string\nfrom sklearn.naive_bayes import MultinomialNB\nimport xgboost as xgb\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn import ensemble, metrics, model_selection, naive_bayes\ncolor = sns.color_palette()\n\n%matplotlib inline\n\neng_stopwords = set(stopwords.words(\"english\"))\npd.options.mode.chained_assignment = None\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/spooky-author-identification/train.zip\")\ntest_df = pd.read_csv(\"../input/spooky-author-identification/test.zip\")\nprint(\"Number of rows in train dataset : \",train_df.shape[0])\nprint(\"Number of rows in test dataset : \",test_df.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nMeaning of author short forms :-\nEdgar Allan Poe (EAP)\nHP Lovecraft (HPL)\nMary Wollstonecraft Shelley (MWS)\nThe objective is to accurately identify the author of the sentences in the test set."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.author.value_counts(normalize=True)*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cnt_srs = train_df['author'].value_counts()\n\nplt.figure(figsize=(8,4))\nsns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8)\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('Author Name', fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"let's test writing styles of these amazing authors by checking out first 5 of their sentences.."},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in train_df[train_df['author']=='EAP']['text'][:5].values:\n    print(i)\n    print('****************')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in train_df[train_df['author']=='MWS']['text'][:5].values:\n    print(i)\n    print('****************')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in train_df[train_df['author']=='HPL']['text'][:5].values:\n    print(i)\n    print('****************')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"let's try word2vec for exploration and tfidf for classfier building part.."},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"corpus=[]\nfor i in train_df['text'].values:\n    corpus.append(str(i).split(\" \"))\ncorpus[:1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = word2vec.Word2Vec(corpus, size=100, workers=4)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(model.wv.most_similar('kill'))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def multiclass_logloss(actual, predicted, eps=1e-15):\n    \"\"\"Multi class version of Logarithmic Loss metric.\n    :param actual: Array containing the actual target classes\n    :param predicted: Matrix with class predictions, one probability per class\n    \"\"\"\n    # Convert 'actual' to a binary array if it's not already:\n    if len(actual.shape) == 1:\n        actual2 = np.zeros((actual.shape[0], predicted.shape[1]))\n        for i, val in enumerate(actual):\n            actual2[i, val] = 1\n        actual = actual2\n\n    clip = np.clip(predicted, eps, 1 - eps)\n    rows = actual.shape[0]\n    vsota = np.sum(actual * np.log(clip))\n    return -1.0 / rows * vsota","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.author\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lbl_enc = preprocessing.LabelEncoder()\ny = lbl_enc.fit_transform(train_df.author.values)\ny","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain, xvalid, ytrain, yvalid = train_test_split(train_df.text.values, y, \n                                                  stratify=y, \n                                                  random_state=42, \n                                                  test_size=0.1, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (xtrain.shape)\nprint (xvalid.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf_model = TfidfVectorizer(min_df=3,  max_features=None, \n            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n            ngram_range=(1, 3), use_idf=1,smooth_idf=1,sublinear_tf=1,\n            stop_words = 'english')\n\n# Fitting TF-IDF to both training and test sets (semi-supervised learning)\ntfidf_model.fit(list(xtrain) + list(xvalid))\nxtrain_tfidf_model =  tfidf_model.transform(xtrain) \nxvalid_tfidf_model = tfidf_model.transform(xvalid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ct_vec_model = CountVectorizer(analyzer='word',token_pattern=r'\\w{1,}',\n            ngram_range=(1, 3), stop_words = 'english')\n\n# Fitting Count Vectorizer to both training and test sets (semi-supervised learning)\nct_vec_model.fit(list(xtrain) + list(xvalid))\nxtrain_ct_vec_model =  ct_vec_model.transform(xtrain) \nxvalid_ct_vec_model = ct_vec_model.transform(xvalid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fitting a simple Naive Bayes on Counts\nclf = MultinomialNB()\nclf.fit(xtrain_ct_vec_model, ytrain)\npredictions = clf.predict_proba(xvalid_ct_vec_model)\n\nprint (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"let's try for some sample spooky sentence.."},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = clf.predict_proba(ct_vec_model.transform(['As soon as I opened the door , I gasped..',]))\npredictions","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* looks like this one may be written by HP Lovecraft..."},{"metadata":{},"cell_type":"markdown","source":"references:-\nhttps://www.kaggle.com/abhishek/approaching-almost-any-nlp-problem-on-kaggle\nhttps://www.kaggle.com/sudalairajkumar/simple-feature-engg-notebook-spooky-author"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}