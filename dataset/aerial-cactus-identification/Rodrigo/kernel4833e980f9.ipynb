{"cells":[{"metadata":{"id":"7Z9uSAUOfJdU","colab_type":"text"},"cell_type":"markdown","source":"# Instalación del ambiente"},{"metadata":{"id":"QisSLctDwFCM","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"%matplotlib inline\n%config InlineBackend.figure_format = 'retina'","execution_count":null,"outputs":[]},{"metadata":{"id":"C66n5YPQfZ-d","colab_type":"text"},"cell_type":"markdown","source":"## Descarga y unzip de dataset"},{"metadata":{"id":"6Aju-ZmXY6Gm","colab_type":"code","outputId":"526dcf9f-a022-4092-d9eb-377989d9d7f6","colab":{"base_uri":"https://localhost:8080/","height":124},"trusted":true},"cell_type":"code","source":"# !kaggle competitions download -c aerial-cactus-identification\n# import os\n# os.chdir('/content/competitions/aerial-cactus-identification')\n# !unzip -q test.zip\n# !unzip -q train.zip\n\nimport os\n# os.chdir('../input/Aerial Cactus Identification')\n# print(os.listdir(\"../input/Aerial Cactus Identification\"))\n# print(os.listdir(\"../input/train\"))\n# os.chdir('.')\n\n# !unzip -q test.zip\n# !unzip -q train.zip","execution_count":null,"outputs":[]},{"metadata":{"id":"SQYPsrVGe05k","colab_type":"text"},"cell_type":"markdown","source":"# Comienza implementación del Kernel"},{"metadata":{"id":"ckLvEg2Ae7zR","colab_type":"code","outputId":"7189a131-d4ed-46da-c5dc-c54782f0c6d6","colab":{"base_uri":"https://localhost:8080/","height":206},"trusted":true},"cell_type":"code","source":"import pandas as pd\ntrain_ds = pd.read_csv('../input/train.csv', dtype=str)\ntrain_ds.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"zFGRHwQOkenZ","colab_type":"code","outputId":"6aad037c-c751-42da-efd4-8e54f90af094","colab":{"base_uri":"https://localhost:8080/","height":72},"trusted":true},"cell_type":"code","source":"# se inspecciona que hay en los directorios\ntrain_dir = os.path.join('../input/train/train')\nprint('total training images:', len(os.listdir(train_dir)))\n\ntrain_files = os.listdir(train_dir)\nprint(train_files[:10])\n","execution_count":null,"outputs":[]},{"metadata":{"id":"ukjjCGdA9IBx","colab_type":"code","outputId":"2b0d6b21-089c-457b-9ee4-980a747bf7ea","colab":{"base_uri":"https://localhost:8080/","height":582},"trusted":true},"cell_type":"code","source":"#se muestran un par de imagenes\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\npic_index = 2\n\nnext_img = [os.path.join(train_dir, fname) \n                for fname in train_files[pic_index-2:pic_index]]\n\nfor i, img_path in enumerate(next_img):\n  print(img_path)\n  img = mpimg.imread(img_path)\n  print(img.shape)\n  plt.imshow(img)\n  plt.axis('Off')\n  plt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"n4vnQic695_7","colab_type":"code","outputId":"c3597e47-db03-4f31-e15b-8f7f87b51cd0","colab":{"base_uri":"https://localhost:8080/","height":625},"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport keras_preprocessing\nfrom keras_preprocessing import image\nfrom keras_preprocessing.image import ImageDataGenerator\n\n\n# codigo copiado del clasificador de piedra papel y tijera de la io \n# https://colab.research.google.com/github/lmoroney/io19/blob/master/Zero%20to%20Hero/Rock-Paper-Scissors.ipynb#scrollTo=LWTisYLQM1aM\n\nTRAINING_DIR = \"../input/train/train/\"\ntraining_datagen = ImageDataGenerator(\n  rescale = 1./255,\n  rotation_range=40,\n  width_shift_range=0.2,\n  height_shift_range=0.2,\n  shear_range=0.2,\n  zoom_range=0.2,\n  horizontal_flip=True,\n  fill_mode='nearest',\n  validation_split=0.25\n)\n\n\ntrain_generator = training_datagen.flow_from_dataframe(\n  dataframe=train_ds, \n  directory=TRAINING_DIR, \n  shuffle=True,\n  x_col=\"id\", \n  y_col=\"has_cactus\", \n  target_size=(32,32), \n  class_mode=\"categorical\",\n  subset=\"training\"\n)\n\nvalidation_generator = training_datagen.flow_from_dataframe(\n  dataframe=train_ds, \n  directory=TRAINING_DIR, \n  shuffle=True,\n  x_col=\"id\", \n  y_col=\"has_cactus\", \n  target_size=(32,32), \n  class_mode=\"categorical\",\n  subset=\"validation\"\n)\n\nmodel = tf.keras.models.Sequential([\n    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n    # This is the first convolution\n    \n#     tf.keras.layers.Flatten(input_shape=(32, 32, 3)),\n    \n    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(32, 32, 3)),\n    #tf.keras.layers.MaxPooling2D(2, 2),\n    # The second convolution\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    # The third convolution\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    # The fourth convolution\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    #tf.keras.layers.MaxPooling2D(2,2),\n    # Flatten the results to feed into a DNN\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dropout(0.5),\n    # 512 neuron hidden layer\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dense(2, activation='softmax')\n])\n\n\nmodel.summary()\n\nmodel.compile(loss = 'categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n\n# logdir = 'logs'\n# tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir)\n\nhistory = model.fit_generator(train_generator, epochs=32, validation_data = validation_generator, verbose = 1) #, callbacks=[tensorboard_callback])\n\n# model.save(\"rps.h5\")\n  ","execution_count":null,"outputs":[]},{"metadata":{"id":"uMmn21AS41cz","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# # Load TENSORBOARD\n# %load_ext tensorboard.notebook\n# # Start TENSORBOARD\n# %tensorboard --logdir logs","execution_count":null,"outputs":[]},{"metadata":{"id":"_3WXwtPNuEd3","colab_type":"code","outputId":"9864c4ed-925b-4c36-d496-c190697945b5","colab":{"base_uri":"https://localhost:8080/","height":560},"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend(loc=0)\nplt.figure()\n\nplt.plot(epochs, loss, 'r', label='Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation Loss')\nplt.legend(loc=0)\nplt.figure()\n\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"QfH2N-NaX5ql","colab_type":"code","outputId":"04b554d4-3089-4c22-abfa-ac18b11a21fd","colab":{"base_uri":"https://localhost:8080/","height":69},"trusted":true},"cell_type":"code","source":"import numpy as np \n\ntestdf = pd.read_csv(\"../input/sample_submission.csv\", dtype=str)\ntest_datagen = ImageDataGenerator(rescale = 1./255)\ntest_generator = test_datagen.flow_from_dataframe(\n  dataframe=testdf,\n  directory='../input/test/test/',\n  target_size=(32,32),\n  x_col=\"id\",\n  y_col=None,\n  class_mode=None,\n#   class_mode=\"categorical\",\n  shuffle=False,\n)\ntest_generator.reset()\npred = model.predict_generator(test_generator, verbose=1)\n\n\npredicted_class_indices = np.argmax(pred,axis=1)\n\n# print(predicted_class_indices)","execution_count":null,"outputs":[]},{"metadata":{"id":"OjnrQ9HabyHK","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"labels = (train_generator.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npredictions = [labels[k] for k in predicted_class_indices]\n\nfilenames=test_generator.filenames\nresults=pd.DataFrame({\"id\":filenames,\n                      \"has_cactus\":predictions})\nresults.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"Aerial Cactus Identification.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":1}