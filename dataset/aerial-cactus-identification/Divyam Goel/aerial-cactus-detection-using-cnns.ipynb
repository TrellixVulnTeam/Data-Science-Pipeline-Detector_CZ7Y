{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Import libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\n\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\n\nfrom tqdm import tqdm, tqdm_notebook\n\nfrom keras import models, layers\nfrom keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Flatten, Dense, LeakyReLU, Dropout\nfrom keras.applications import VGG16, densenet\nfrom keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Basic Setup\nI find it to be a good practice to setup base_dir, train_dir, test_dir in the beginning\nand then use these variable throughout the code whenever something from the file system\nhas to be accessed."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"base_dir = \"../input/\"\nprint(os.listdir(base_dir))\n\ntrain_dir = os.path.join(base_dir, \"train/train/\")\ntest_dir = os.path.join(base_dir, \"test/test/\")\n\ndf_train = pd.read_csv(os.path.join(base_dir, \"train.csv\"))\nprint(df_train.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Sample Image\nHere is a sample image just to get an idea of the kind of images in the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"im = cv2.imread(train_dir + df_train[\"id\"][0])\nplt.imshow(im)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## TensorBoard Visualization\nMagic functions are used to setup the environment for viewing dynamic TensorBoard visualizations when the model is training. TensorBoard allows you to visualize training loss and accuracy as well as validation loss and accuracy. Moreover, it also allows you to visualize the computation graph of your model. For more information checkout: [https://www.tensorflow.org/guide/summaries_and_tensorboard](http://)\n\nTo reload the tensorboard visualization, say when you start training a new model, run: `%reload_ext tensorboard.notebook` instead of `%load_ext tensorboard.notebook`"},{"metadata":{"trusted":true},"cell_type":"code","source":"%load_ext tensorboard.notebook\n%tensorboard --logdir logs","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Image Generators\nData Augmentation is a useful technique to increase the size of one's dataset. It is especially useful if the dataset is small as in this case. Augmentation involves rotating, fliping (both horizontal and vertical) and various other operations to obtain similar images for which we have labels. This effectively increases the dataset while also making the model trained on this dataset invariant to such operations.\n\nKeras provides ImageDataGenerators which lifts the burden of Image Preprocessing, Augmentation as well as Train/Val split from the shoulders' of the programmer. However, there is one drawback in using these generators. For datasets which can be stored in the memory, generators' significantly increase the training time. For datasets like the Cactus Aerial Detection, loading the dataset into the memory and then manually preprocessing it should be preferred. However, for the ease of use (augmentation), I will be using the generators only."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['has_cactus'] = df_train['has_cactus'].astype(str)\n\nbatch_size = 64\ntrain_size = 15750\nvalidation_size = 1750\n\ndatagen = ImageDataGenerator(\n    rescale=1./255,\n    horizontal_flip=True,\n    vertical_flip=True,\n    validation_split=0.1)\n\ndata_args = {\n    \"dataframe\": df_train,\n    \"directory\": train_dir,\n    \"x_col\": 'id',\n    \"y_col\": 'has_cactus',\n    \"shuffle\": True,\n    \"target_size\": (32, 32),\n    \"batch_size\": batch_size,\n    \"class_mode\": 'binary'\n}\n\ntrain_generator = datagen.flow_from_dataframe(**data_args, subset='training')\nvalidation_generator = datagen.flow_from_dataframe(**data_args, subset='validation')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Keras Callbacks\nKeras provides this another amazing feature called callbacks. Callbacks essentially allow you to run some computation after every epoch or step to evaluate the training of your model or to store the intermediate results.\n\nFollowing is a brief explanation of all the callbacks I have used:\n1. TensorBoard - Helps in visualizing the loss and acc for both training and validation sets during training\n2. EarlyStopping - Prevents overfitting. It continuously monitors the model by checking the given metric, say val_acc. If val_acc doesn't improve over the current best val_acc in specified number of epochs (patience) then the model stops training.\n3. ReduceLROnPlateau - It is similar to EarlyStopping except rather than stopping the training it reduces the learning rate. Lower learning rate allows the model to do more fine-grained learning.\n4. ModelCheckpoint - This is especially useful for models which take a long time to train. It allows us to store intermediate results i.e. after every epoch or so."},{"metadata":{"trusted":true},"cell_type":"code","source":"ckpt_path = 'aerial_cactus_detection.hdf5'\n\ntensorboard_cb = TensorBoard()\nearlystop_cb = EarlyStopping(monitor='val_acc', patience=10, verbose=1, restore_best_weights=True)\nreducelr_cb = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=5, verbose=1)\nmodelckpt_cb = ModelCheckpoint(ckpt_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n\ncallbacks = [tensorboard_cb, earlystop_cb, reducelr_cb, modelckpt_cb]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model\nMy choice for model is mostly random. I have used two blocks of three convolutional layers each. Each convolutional layer is followed by a batch normalization layer. I have used leaky relu for non-linearity. The convolutional layers are followed by two dense layers and then finally the output layer.\n\nBefore this model I tried using a pre-trained model.The results I got VGG16 using weights pretrained on ImageNet were subpar as compared to the current results. I feel this is because of the lack of batch normalization layers in the VGG16 but I could be wrong."},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models.Sequential([\n    Conv2D(32, (3,3), input_shape=(32, 32, 3)),\n    LeakyReLU(alpha=0.3),\n    BatchNormalization(),\n    Conv2D(32, (3,3)),\n    LeakyReLU(alpha=0.3),\n    BatchNormalization(),\n    Conv2D(32, (3,3)),\n    LeakyReLU(alpha=0.3),\n    BatchNormalization(),\n    MaxPooling2D(2,2),\n   \n    Conv2D(64, (3,3)),\n    LeakyReLU(alpha=0.3),\n    BatchNormalization(),\n    Conv2D(64, (3,3)),\n    LeakyReLU(alpha=0.3),\n    BatchNormalization(),\n    Conv2D(64, (3,3)),\n    LeakyReLU(alpha=0.3),\n    BatchNormalization(),\n    MaxPooling2D(2,2),\n    \n    Flatten(),\n    Dense(units=128),\n    LeakyReLU(alpha=0.3),\n    Dropout(0.4),\n    Dense(units=64),\n    LeakyReLU(alpha=0.3),\n    Dropout(0.4),\n    \n    Dense(units=1, activation='sigmoid')\n])\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer=Adam(lr=0.001),\n              metrics=['acc'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit_generator(train_generator,\n              validation_data=validation_generator,\n              steps_per_epoch=train_size//batch_size,\n              validation_steps=validation_size//batch_size,\n              epochs=100,\n              shuffle=True,\n              callbacks=callbacks, \n              verbose=2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train Vs Validation Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training plots\nepochs = [i for i in range(1, len(history.history['loss'])+1)]\n\nplt.plot(epochs, history.history['loss'], color='blue', label=\"training_loss\")\nplt.plot(epochs, history.history['val_loss'], color='red', label=\"validation_loss\")\nplt.legend(loc='best')\nplt.title('loss')\nplt.xlabel('epoch')\nplt.show()\n\nplt.plot(epochs, history.history['acc'], color='blue', label=\"training_accuracy\")\nplt.plot(epochs, history.history['val_acc'], color='red',label=\"validation_accuracy\")\nplt.legend(loc='best')\nplt.title('accuracy')\nplt.xlabel('epoch')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.read_csv(os.path.join(base_dir, \"sample_submission.csv\"))\nprint(df_test.head())\ntest_images = []\nimages = df_test['id'].values\n\nfor image_id in images:\n    test_images.append(cv2.imread(os.path.join(test_dir, image_id)))\n    \ntest_images = np.asarray(test_images)\ntest_images = test_images / 255.0\nprint(len(test_images))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict(test_images)\ndf_test['has_cactus'] = pred\ndf_test.to_csv('aerial-cactus-submission.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Acknowledgement\nTo successfully complete this playground challenge I viewed many publicly available kernels. However, some of them were particularly helpful as I learned a lot from them. Here is a special mention to them:\nhttps://www.kaggle.com/anirudhchak/cnn-using-keras\nhttps://www.kaggle.com/frlemarchand/simple-cnn-using-keras\n"},{"metadata":{},"cell_type":"markdown","source":"### Note\nThis is my first kernel ever. If you reached till the end then I hope you liked it. I have tried to explain everything well."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}