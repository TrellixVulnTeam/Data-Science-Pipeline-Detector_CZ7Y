{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Importing relevant libraries**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport os\nfrom os import listdir\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install tensorflow==2.0.0-beta1\n\nfrom tensorflow.python.ops import control_flow_util\ncontrol_flow_util.ENABLE_CONTROL_FLOW_V2 = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Checking the data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"training_dir = '../input/train/train/'\ntraining_imgs = listdir(training_dir)\nnum_training_imgs = len(training_imgs)\nnum_training_imgs","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" So there are 17500 images in the given data. The labels of these images are saved in 'train.csv' file"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels_df = pd.read_csv('../input/train.csv', index_col = 'id')\nprint(\"total entries : \" + str(train_labels_df.size))\ntrain_labels_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Calculating the pictures with cactus and without cactus"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.value_counts(train_labels_df['has_cactus'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nearly 3 times more pictures have cactus in them as compared to the pictures without cactus"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_test_image_path(id):\n    return training_dir + id\n\ndef draw_cactus_image(id, ax):\n    path = get_test_image_path(id)\n    img = mpimg.imread(path)\n    plt.imshow(img)\n    ax.set_title('Label: ' + str(train_labels_df.loc[id]['has_cactus']))\n\nfig = plt.figure(figsize=(20,20))\nfor i in range(12):\n    ax = fig.add_subplot(3, 4, i + 1)\n    draw_cactus_image(training_imgs[i], ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is really tough to differentiate between the images with cactus and without cactus, so we're going to rely on AI to do that"},{"metadata":{},"cell_type":"markdown","source":"**Loading the data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_image_path = [training_dir + ti for ti in training_imgs ]\ntrain_image_labels = [ train_labels_df.loc[ti]['has_cactus'] for ti in training_imgs]\n\n\nfor i in range(10):\n    print(train_image_path[i], train_image_labels[i])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To get from the image paths above to actual tf.Tensors we will combine tf.io.read_file and tf.image.decode_image. This very simple process is illustrated below for the first example:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def img_to_tensor(img_path):\n    img_tensor = tf.cast(tf.image.decode_image(tf.io.read_file(img_path)), tf.float32)\n    img_tensor /= 255.0 # normalized to [0,1]\n    return img_tensor\n\nimg_to_tensor(train_image_path[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So this is how we can convert our example to tensor of shape (32,32,3)"},{"metadata":{},"cell_type":"markdown","source":"**Making training and validation dataset from our data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(train_image_path, train_image_labels, test_size=0.2)\n\ndef process_image_in_record(path, label):\n    return img_to_tensor(path), label\n\ndef build_training_dataset(paths, labels, batch_size = 32):\n    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n    ds = ds.map(process_image_in_record)\n    ds = ds.shuffle(buffer_size = len(paths))\n    ds = ds.repeat()\n    ds = ds.batch(batch_size)\n    ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n    return ds\n\ndef build_validation_dataset(paths, labels, batch_size = 32):\n    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n    ds = ds.map(process_image_in_record)\n    ds = ds.batch(batch_size)\n    return ds\n\ntrain_ds = build_training_dataset(X_train, y_train)\nvalidation_ds = build_validation_dataset(X_valid, y_valid)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now that we have created training and validation dataset, let's verify them by a small example"},{"metadata":{"trusted":true},"cell_type":"code","source":"mini_train_ds = build_training_dataset(X_train[:5], y_train[:5], batch_size=2)\n# Fetch and print the first batch of 2 images\nfor images, labels in mini_train_ds.take(1):\n    print(images)\n    print(labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Building a model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.Sequential()\nmodel.add(tf.keras.layers.Flatten())\nmodel.add(tf.keras.layers.Dense(256, activation='relu'))\nmodel.add(tf.keras.layers.Dense(64, activation='relu'))\nmodel.add(tf.keras.layers.Dense(1, activation='sigmoid')) # because we are in a binary classification setup\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(train_ds, epochs=20, steps_per_epoch=400, validation_data=validation_ds)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We've reached 90% validation accurary and there was increase in the validation loss once."},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_accuracies_and_losses(history):\n    plt.title('Accuracy')\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.legend(['training', 'validation'], loc='upper left')\n    plt.show()\n    \n    plt.title('Cross-entropy loss')\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.legend(['training', 'validation'], loc='upper left')\n    plt.show()\n\nplot_accuracies_and_losses(history)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This shows us that our model is learning something and getting better gradually, we didn't allow much overfitting to occur. This shows that we haven't made any errors in setting up our data pipeline and model"},{"metadata":{},"cell_type":"markdown","source":"Furthermore, we were using basic model till now, but CNN or convulated neural networks are the most preferred option when processing image data, so let's try using CNNs"},{"metadata":{},"cell_type":"markdown","source":"**Making a CNN model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"cnn_model = tf.keras.Sequential()\n\ncnn_model.add(tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)))\ncnn_model.add(tf.keras.layers.MaxPooling2D((2,2)))\ncnn_model.add(tf.keras.layers.Conv2D(64, (3,3), activation='relu'))\ncnn_model.add(tf.keras.layers.MaxPooling2D((2,2)))\ncnn_model.add(tf.keras.layers.Conv2D(64, (3,3), activation='relu'))\n\ncnn_model.add(tf.keras.layers.Flatten())\ncnn_model.add(tf.keras.layers.Dense(64, activation='relu'))\ncnn_model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n\ncnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cnn_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = cnn_model.fit(train_ds, epochs=20, steps_per_epoch=400, validation_data=validation_ds)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Making a Submission**"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dir = '../input/test/test/'\ntest_imgs = listdir(test_dir)\nprint(len(test_imgs))\ntest_imgs[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def path_to_numpy_array(path):\n    tensor = img_to_tensor(path)\n    array = tensor.numpy()\n    return array\n\ntest_image_paths = [test_dir + ti for ti in test_imgs]\ntest_instances = np.asarray([path_to_numpy_array(tip) for tip in test_image_paths])\n\ntest_instances[:2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = cnn_model.predict(test_instances)\nprint(len(predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_data = pd.DataFrame({'id': test_imgs, 'has_cactus': predictions.flatten()})\nsubmission_data.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_data.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!head submission.csv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}