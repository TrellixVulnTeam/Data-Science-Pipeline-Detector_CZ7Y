{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport tensorflow as tf\nimport tensorflow.keras as keras\nimport tensorflow.keras.preprocessing.image as image\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.applications.resnet50 import preprocess_input\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1st step! - **load the data!**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_dir = '../input/train/train'\ntest_dir = '../input/test/test'\n\ntrain = pd.read_csv('../input/train.csv')\n\nprint('train has {} rows'.format(len(os.listdir(train_dir))))\nprint('test has {} rows'.format(len(os.listdir(test_dir))))\ntrain['has_cactus'] = train['has_cactus'].astype(str)\n\nprint(train['has_cactus'].dtype)\n#train['has_cactus'] = train['has_cactus'].apply(lambda x : int(x))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The images are clustered in only one folder. \nThere is a text files containing information on class and other parameters are provided. In this case, we will create a dataframe using pandas and text files provided, and create a meaningful dataframe with columns having file name (only the file names, not the path) and other classes to be used by the model. For this method, arguments to be used are:\n\ndataframe  : Dataframe having meaningful data (file name, class columns are a must)\ndirectory  : The path to the parent directory containing all images.\nx_col  : which will be the name of column(in dataframe) having file names\ny_col  : which will be the name of column(in dataframe) having class/label"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = image.ImageDataGenerator(1.0/255,\n                                        preprocessing_function=preprocess_input,\n                                        horizontal_flip=True,\n                                        width_shift_range = 0.2,\n                                        height_shift_range = 0.2)\n\nvalid_datagen = image.ImageDataGenerator(1.0/255,\n                                        preprocessing_function=preprocess_input\n                                        )\n\n                                   \n            \n            \ntrain_generator = train_datagen.flow_from_dataframe(dataframe=train[:15001],\n                                                   directory=train_dir,\n                                                   x_col='id',\n                                                   y_col='has_cactus',\n                                                   class_mode = 'binary',\n                                                   batch_size=64,\n                                                   target_size=(150,150))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_generator = valid_datagen.flow_from_dataframe(dataframe=train[15000:],\n                                                   directory=train_dir,\n                                                   x_col='id',\n                                                   y_col='has_cactus',\n                                                   class_mode='binary',\n                                                   batch_size=64,\n                                                   target_size=(150,150))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I tried different configuration after ResNet50 with ImageNet weights but the most accurate is with only an output layer with sigmoid activation function. "},{"metadata":{},"cell_type":"markdown","source":"From keras documentation: \n\nArguments\n* include_top: whether to include the fully-connected layer at the top of the network.\n* weights: one of None (random initialization) or 'imagenet' (pre-training on ImageNet).\n* input_tensor: optional Keras tensor (i.e. output of layers.Input()) to use as image input for the model.\n* input_shape: optional shape tuple, only to be specified if include_top is False (otherwise the input shape has to be (224, 224, 3) (with 'channels_last' data format) or (3, 224, 224) (with 'channels_first' data format). It should have exactly 3 inputs channels, and width and height should be no smaller than 32. E.g. (200, 200, 3) would be one valid value.\n* pooling: Optional pooling mode for feature extraction when include_top is False.\n* classes: optional number of classes to classify images into, only to be specified if include_top is True, and if no weights argument is specified.\n\n"},{"metadata":{},"cell_type":"markdown","source":"Let's create out model. We start with a Resnet CNN with imagenet weights but we left them be trained on train data.\ninclude_top=False since we don't want the Dense part of the NN but only the convolutions to extract features from the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"resnet_weights_path = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\nfilepath='weights.best.hdf5'\nes = EarlyStopping(monitor='accuracy', mode='min', verbose=1, patience=5,baseline=0.99)\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n\n\ndef myModel():\n    my_model2 = keras.models.Sequential()\n    input_layer = keras.layers.Input(shape=(150, 150, 3), name='image_input')\n    my_model2.add(ResNet50(weights='imagenet', include_top=False, input_tensor=input_layer))\n    my_model2.add(keras.layers.Flatten())\n    my_model2.add(keras.layers.Dense(16))\n    my_model2.add(keras.layers.BatchNormalization())\n    my_model2.add(keras.layers.Activation('relu'))\n    my_model2.add(keras.layers.Dropout(0.8))  #add strong normalization against overfitting\n    my_model2.add(keras.layers.Dense(1, activation='sigmoid'))\n    my_model2.layers[0].trainable=True\n    my_model2.summary()\n    return my_model2\n\nmy_model2 = myModel()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's compile the model with a RMSProp algorithm and simple binary crossentropy loss function and fit the data!"},{"metadata":{"trusted":true},"cell_type":"code","source":"my_model2.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nhistory_2 = my_model2.fit_generator(train_generator,\n                                   steps_per_epoch=50,\n                                   epochs=15,\n                                   validation_data= valid_generator,\n                                   validation_steps=50,\n                                   callbacks=[es, checkpoint])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see how change the training accuracy and the validation accuracy with the number of epochs:"},{"metadata":{"trusted":true},"cell_type":"code","source":"my_model2 = myModel()\nmy_model2.load_weights(filepath)\n\nmy_model2.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nprint(\"Created model and loaded weights from file\")\nscores = my_model2.evaluate_generator(valid_generator)\nprint(\"Accuracy = \", scores[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nacc = history_2.history['acc']\nepochs_2 = range(0,15)\n\nplt.plot( epochs_2,acc,label='training accuracy' )\n\nplt.xlabel('n epochs')\nplt.ylabel('accuracy')\n\nacc_val = history_2.history['val_acc']\nplt.plot(epochs_2, acc_val,label=\"validation accuracy\")\nplt.title('epochs vs acc')\nplt.legend()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's try to predict something!!"},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\nfrom scipy import ndimage, misc\n\nimg = cv2.imread('../input/train/train/008bd3d84a1145e154409c124de7cee9.jpg', flags=cv2.IMREAD_COLOR)\nplt.imshow(img)\nplt.show()\n\n\nfilepath  = '../input/train/train/028192187883168e2a7621c998dc447a.jpg'\nimage = ndimage.imread(filepath, mode=\"RGB\")\nimage_resized = misc.imresize(image, (150, 150,3))\n\nplt.imshow(image_resized)\nplt.show()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_resized = np.reshape(image_resized,[1,150,150,3])\n\nprint(my_model2.predict(image_resized))\n\n\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}