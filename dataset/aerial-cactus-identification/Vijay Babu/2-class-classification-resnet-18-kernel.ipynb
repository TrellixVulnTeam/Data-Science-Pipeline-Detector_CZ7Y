{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\n# This kernel draws heavily from https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":6,"outputs":[{"output_type":"stream","text":"['train', 'test', 'train.csv', 'sample_submission.csv']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import argparse\nimport random\nimport shutil\nimport time\nimport warnings\nimport sys\nimport sklearn\nimport pandas as pd\nimport tqdm\nimport copy \n\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.distributed as dist\nimport torch.optim\nimport torch.multiprocessing as mp\nimport torch.utils.data\nimport torch.utils.data.distributed\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torchvision.models as models\nimport torchvision.utils as tvutils\nprint(\"packages loaded\")","execution_count":7,"outputs":[{"output_type":"stream","text":"packages loaded\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#one time work of copying files suitably to the 2 class folders (cactus & nocactus)\nimport shutil\ntraindir = os.path.join('../input', 'train')\nresults = pd.read_csv('../input/train.csv',header = 0, index_col = 0)\nprint(results.shape)\nos.mkdir(\"../data\")\nos.mkdir(\"../data/train\")\nos.mkdir(\"../data/train/nocactus\")\nos.mkdir(\"../data/train/cactus\")\n\nfor i in range(results.shape[0]):\n    #print(\"i \",i)\n    if(results.iloc[i,0] == 0):\n        shutil.copy(os.path.join('../input/train/train/',results.index[i]),os.path.join('../data/train/nocactus/',results.index[i]))\n    else:\n        shutil.copy(os.path.join('../input/train/train/',results.index[i]),os.path.join('../data/train/cactus/',results.index[i]))\n        \n","execution_count":8,"outputs":[{"output_type":"stream","text":"(17500, 1)\n","name":"stdout"},{"output_type":"error","ename":"FileExistsError","evalue":"[Errno 17] File exists: '../data'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-8dd1091a4aea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/train.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/train/nocactus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '../data'"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nngpus_per_node = torch.cuda.device_count()\nfeature_extract = False # if true this will not re-train the model, but only change the last stage\nuse_pretrained = True\n\n# create model\nprint(\"=> creating model \")\nmodel = models.resnet18(pretrained=use_pretrained) #pretrained=use_pretrained\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n#model = torch.nn.DataParallel(model).cuda()\n\nif feature_extract:\n        for param in model.parameters():\n            param.requires_grad = False\n\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, 2)            \nmodel.to(device)\n\n# define loss function (criterion) and optimizer\ncriterion = nn.CrossEntropyLoss().cuda(ngpus_per_node)\n\n\nmodeldir = os.path.join('../data/', 'train')\n# Data loading code\nnormalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                 std=[0.229, 0.224, 0.225])\n\n#print(\"length\", train_dataset.__len__)\n\n#load the classification results\n#now based on results, move the image to either of 2 classification bucket\n#if dir \"cactus\" or \"nocactus\" is not present, create it\n\nfull_dataset = datasets.ImageFolder(\n    modeldir,\n    transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        normalize,\n    ]))\ntrain_dataset, val_dataset = torch.utils.data.random_split(full_dataset, {3*results.shape[0]//4,results.shape[0]- 3*results.shape[0]//4})\nprint(\"train length\",train_dataset.__len__)\nbatch = 128\ntrain_loader = torch.utils.data.DataLoader(\n    train_dataset, batch_size=batch, shuffle= False,\n    pin_memory=True)\n\nval_loader = torch.utils.data.DataLoader(\n    val_dataset, batch_size=batch, shuffle= False,\n    pin_memory=True)\n\nparams_to_update = []\n\nif feature_extract:\n    for name,param in model.named_parameters():\n        if param.requires_grad == True:\n            params_to_update.append(param)\n#            print(\"\\t\",name)\nelse:\n    for name,param in model.named_parameters():\n        if param.requires_grad == True:\n            params_to_update.append(param)\n#            print(\"\\t\",name)\n            \noptimizer = torch.optim.SGD(params_to_update, 0.001,\n                            momentum=0.9,\n                            weight_decay=1e-4)\n\n","execution_count":9,"outputs":[{"output_type":"stream","text":"=> creating model \ntrain length <bound method Subset.__len__ of <torch.utils.data.dataset.Subset object at 0x7f7b56045c50>>\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import copy\n\nbest_acc1 = 0\n\nclass AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self, name, fmt=':f'):\n        self.name = name\n        self.fmt = fmt\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n    def __str__(self):\n        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n        return fmtstr.format(**self.__dict__)\n\n\n\ndef accuracy(output, target,iter_cnt, topk=(1,)):\n    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n    with torch.no_grad():\n        maxk = max(topk)\n        batch_size = target.size(0)\n\n        _, pred = output.topk(maxk, 1, True, True)\n        pred = pred.t()\n        correct = pred.eq(target.view(1, -1).expand_as(pred))\n        res = []\n        for k in topk:\n            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n            res.append(correct_k.mul_(100.0 / batch_size))\n        return res\n\n\ndef train(train_loader,model, criterion, optimizer, epoch):\n\n    # switch to train mode\n    model.train()\n    top1 = AverageMeter('Acc@1', ':6.2f')\n    \n    for i, (input,target) in enumerate(train_loader):\n        #input = input.cuda(0, non_blocking=True)\n        #target = target.cuda(0, non_blocking=True)\n        input = input.to(device)\n        target = target.to(device)\n        # compute output\n        output = model(input)\n        loss = criterion(output, target)\n\n        # measure accuracy and record loss\n        acc1, acc5 = accuracy(output, target, i,topk=(1, 1)) #\n        top1.update(acc1[0], input.size(0))\n\n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n\ndef validate(val_loader,model, criterion):\n\n    # switch to evaluate mode\n    model.eval()\n    top1 = AverageMeter('Acc@1', ':6.2f')\n\n    with torch.no_grad():\n        end = time.time()\n        for i,(input, target) in enumerate(val_loader):\n            input = input.to(device)\n            target = target.to(device)\n            # compute output\n            output = model(input)\n            loss = criterion(output, target)\n\n            # measure accuracy and record loss\n            acc1, acc5 = accuracy(output, target, i,topk=(1, 1))\n            top1.update(acc1[0], input.size(0))\n\n        print(' * Acc@1 {top1.avg:.3f}'\n              .format(top1=top1))\n\n    return top1.avg\n\nmax_epoch = 15\nbest_model_wts = copy.deepcopy(model.state_dict())\nbest_acc1 = 0\n\nfor epoch in tqdm.tqdm(range(0, max_epoch)):\n    train(train_loader, model, criterion, optimizer, epoch)\n\n    # evaluate on validation set\n    acc1 = validate(val_loader, model, criterion)\n\n    # remember best acc@1 and save checkpoint\n    is_best = acc1 > best_acc1\n    if (acc1 > best_acc1):\n        best_acc1 = acc1\n        best_model_wts = copy.deepcopy(model.state_dict())\nmodel.load_state_dict(best_model_wts)    ","execution_count":11,"outputs":[{"output_type":"stream","text":"\n  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n  7%|▋         | 1/15 [00:53<12:30, 53.60s/it]\u001b[A","name":"stderr"},{"output_type":"stream","text":" * Acc@1 97.463\n","name":"stdout"},{"output_type":"stream","text":"\n 13%|█▎        | 2/15 [01:45<11:31, 53.18s/it]\u001b[A","name":"stderr"},{"output_type":"stream","text":" * Acc@1 98.354\n","name":"stdout"},{"output_type":"stream","text":"\n 20%|██        | 3/15 [02:38<10:36, 53.07s/it]\u001b[A","name":"stderr"},{"output_type":"stream","text":" * Acc@1 98.309\n","name":"stdout"},{"output_type":"stream","text":"\n 27%|██▋       | 4/15 [03:31<09:43, 53.08s/it]\u001b[A","name":"stderr"},{"output_type":"stream","text":" * Acc@1 98.354\n","name":"stdout"},{"output_type":"stream","text":"\n 33%|███▎      | 5/15 [04:24<08:49, 52.94s/it]\u001b[A","name":"stderr"},{"output_type":"stream","text":" * Acc@1 98.514\n","name":"stdout"},{"output_type":"stream","text":"\n 40%|████      | 6/15 [05:17<07:55, 52.86s/it]\u001b[A","name":"stderr"},{"output_type":"stream","text":" * Acc@1 98.103\n","name":"stdout"},{"output_type":"stream","text":"\n 47%|████▋     | 7/15 [06:09<07:03, 52.88s/it]\u001b[A","name":"stderr"},{"output_type":"stream","text":" * Acc@1 98.789\n","name":"stdout"},{"output_type":"stream","text":"\n 53%|█████▎    | 8/15 [07:01<06:07, 52.45s/it]\u001b[A","name":"stderr"},{"output_type":"stream","text":" * Acc@1 98.674\n","name":"stdout"},{"output_type":"stream","text":"\n 60%|██████    | 9/15 [07:53<05:14, 52.42s/it]\u001b[A","name":"stderr"},{"output_type":"stream","text":" * Acc@1 98.606\n","name":"stdout"},{"output_type":"stream","text":"\n 67%|██████▋   | 10/15 [08:45<04:21, 52.29s/it]\u001b[A","name":"stderr"},{"output_type":"stream","text":" * Acc@1 98.629\n","name":"stdout"},{"output_type":"stream","text":"\n 73%|███████▎  | 11/15 [09:37<03:28, 52.11s/it]\u001b[A","name":"stderr"},{"output_type":"stream","text":" * Acc@1 99.109\n","name":"stdout"},{"output_type":"stream","text":"\n 80%|████████  | 12/15 [10:29<02:36, 52.14s/it]\u001b[A","name":"stderr"},{"output_type":"stream","text":" * Acc@1 98.446\n","name":"stdout"},{"output_type":"stream","text":"\n 87%|████████▋ | 13/15 [11:21<01:43, 51.92s/it]\u001b[A","name":"stderr"},{"output_type":"stream","text":" * Acc@1 99.223\n","name":"stdout"},{"output_type":"stream","text":"\n 93%|█████████▎| 14/15 [12:13<00:52, 52.14s/it]\u001b[A","name":"stderr"},{"output_type":"stream","text":" * Acc@1 98.994\n","name":"stdout"},{"output_type":"stream","text":"\n100%|██████████| 15/15 [13:05<00:00, 52.15s/it]\u001b[A","name":"stderr"},{"output_type":"stream","text":" * Acc@1 99.131\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now try to predict on this model\n#classification: 0 = cactus, 1 = no cactus; so swap them\n#load the test data\npreddir = os.path.join('../input/', 'test')\n\ntest_dataset = datasets.ImageFolder(\n    preddir,\n    transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        normalize,\n    ]))\ntest_count = len([name for name in os.listdir('../input/test/test/')])\ntest_loader = torch.utils.data.DataLoader(\n    test_dataset, batch_size=1, shuffle= False,\n    pin_memory=True)\n\n# evaluate on test set\nmodel.eval()\npred_submit = pd.DataFrame(np.zeros(test_count,dtype=int))\nwith torch.no_grad():\n    end = time.time()\n    for i,(input, target) in tqdm.tqdm(enumerate(test_loader)):\n        input = input.cuda(0, non_blocking=True)\n        # compute output\n        output = model(input)\n        val,pred = torch.max(output, 1)\n        if (pred[0] == 0):\n            val[0] = torch.sigmoid(val[0])\n        else:\n            if (pred[0] == 1):\n                val[0] = 1-torch.sigmoid(val[0])\n            else:\n                val[0] = 2\n        pred_submit.iloc[i,0] = val[0].cpu().numpy()\nprediction = pd.read_csv('../input/sample_submission.csv',header = 0,index_col=0)        \npred_submit.index = prediction.index\nprediction.iloc[:,0] = pred_submit.iloc[:,0]\nprint(prediction.head())\n#os.mkdir(\"../output/\")\nprediction.to_csv(\"samplesubmission.csv\")\n ","execution_count":12,"outputs":[{"output_type":"stream","text":"\n0it [00:00, ?it/s]\u001b[A\n13it [00:00, 126.14it/s]\u001b[A\n28it [00:00, 131.78it/s]\u001b[A\n43it [00:00, 135.76it/s]\u001b[A\n58it [00:00, 139.22it/s]\u001b[A\n73it [00:00, 141.01it/s]\u001b[A\n88it [00:00, 141.75it/s]\u001b[A\n103it [00:00, 142.61it/s]\u001b[A\n118it [00:00, 143.34it/s]\u001b[A\n133it [00:00, 144.47it/s]\u001b[A\n148it [00:01, 143.93it/s]\u001b[A\n163it [00:01, 144.08it/s]\u001b[A\n178it [00:01, 142.83it/s]\u001b[A\n193it [00:01, 143.54it/s]\u001b[A\n208it [00:01, 143.07it/s]\u001b[A\n223it [00:01, 142.90it/s]\u001b[A\n238it [00:01, 143.62it/s]\u001b[A\n253it [00:01, 142.94it/s]\u001b[A\n268it [00:01, 143.15it/s]\u001b[A\n283it [00:01, 142.47it/s]\u001b[A\n298it [00:02, 142.36it/s]\u001b[A\n313it [00:02, 141.30it/s]\u001b[A\n328it [00:02, 138.57it/s]\u001b[A\n342it [00:02, 137.96it/s]\u001b[A\n357it [00:02, 140.36it/s]\u001b[A\n372it [00:02, 140.89it/s]\u001b[A\n387it [00:02, 142.27it/s]\u001b[A\n402it [00:02, 143.03it/s]\u001b[A\n417it [00:02, 144.38it/s]\u001b[A\n432it [00:03, 143.71it/s]\u001b[A\n447it [00:03, 143.99it/s]\u001b[A\n462it [00:03, 145.41it/s]\u001b[A\n477it [00:03, 142.98it/s]\u001b[A\n492it [00:03, 142.56it/s]\u001b[A\n507it [00:03, 143.15it/s]\u001b[A\n522it [00:03, 144.94it/s]\u001b[A\n537it [00:03, 145.36it/s]\u001b[A\n552it [00:03, 143.56it/s]\u001b[A\n567it [00:03, 143.06it/s]\u001b[A\n582it [00:04, 143.26it/s]\u001b[A\n597it [00:04, 143.42it/s]\u001b[A\n612it [00:04, 144.56it/s]\u001b[A\n627it [00:04, 145.07it/s]\u001b[A\n642it [00:04, 144.33it/s]\u001b[A\n657it [00:04, 144.31it/s]\u001b[A\n672it [00:04, 143.88it/s]\u001b[A\n687it [00:04, 143.98it/s]\u001b[A\n702it [00:04, 144.23it/s]\u001b[A\n717it [00:05, 143.63it/s]\u001b[A\n732it [00:05, 143.68it/s]\u001b[A\n747it [00:05, 144.16it/s]\u001b[A\n762it [00:05, 143.73it/s]\u001b[A\n777it [00:05, 144.54it/s]\u001b[A\n792it [00:05, 141.78it/s]\u001b[A\n807it [00:05, 140.59it/s]\u001b[A\n822it [00:05, 141.24it/s]\u001b[A\n837it [00:05, 141.82it/s]\u001b[A\n852it [00:05, 142.64it/s]\u001b[A\n867it [00:06, 142.26it/s]\u001b[A\n882it [00:06, 142.10it/s]\u001b[A\n897it [00:06, 143.72it/s]\u001b[A\n912it [00:06, 143.09it/s]\u001b[A\n927it [00:06, 143.44it/s]\u001b[A\n942it [00:06, 144.24it/s]\u001b[A\n957it [00:06, 144.51it/s]\u001b[A\n972it [00:06, 145.48it/s]\u001b[A\n987it [00:06, 145.40it/s]\u001b[A\n1002it [00:06, 143.75it/s]\u001b[A\n1017it [00:07, 142.78it/s]\u001b[A\n1032it [00:07, 142.51it/s]\u001b[A\n1047it [00:07, 144.19it/s]\u001b[A\n1062it [00:07, 143.36it/s]\u001b[A\n1077it [00:07, 144.35it/s]\u001b[A\n1092it [00:07, 145.13it/s]\u001b[A\n1107it [00:07, 145.32it/s]\u001b[A\n1122it [00:07, 145.71it/s]\u001b[A\n1137it [00:07, 145.37it/s]\u001b[A\n1152it [00:08, 141.82it/s]\u001b[A\n1167it [00:08, 141.75it/s]\u001b[A\n1182it [00:08, 140.84it/s]\u001b[A\n1197it [00:08, 143.24it/s]\u001b[A\n1212it [00:08, 139.28it/s]\u001b[A\n1227it [00:08, 141.16it/s]\u001b[A\n1242it [00:08, 141.53it/s]\u001b[A\n1257it [00:08, 142.65it/s]\u001b[A\n1272it [00:08, 141.39it/s]\u001b[A\n1287it [00:08, 141.54it/s]\u001b[A\n1302it [00:09, 141.85it/s]\u001b[A\n1317it [00:09, 141.45it/s]\u001b[A\n1332it [00:09, 138.82it/s]\u001b[A\n1347it [00:09, 139.69it/s]\u001b[A\n1362it [00:09, 141.01it/s]\u001b[A\n1377it [00:09, 139.93it/s]\u001b[A\n1392it [00:09, 139.16it/s]\u001b[A\n1407it [00:09, 140.34it/s]\u001b[A\n1422it [00:09, 139.80it/s]\u001b[A\n1437it [00:10, 140.78it/s]\u001b[A\n1452it [00:10, 141.42it/s]\u001b[A\n1467it [00:10, 141.60it/s]\u001b[A\n1482it [00:10, 143.60it/s]\u001b[A\n1497it [00:10, 143.86it/s]\u001b[A\n1512it [00:10, 144.96it/s]\u001b[A\n1527it [00:10, 143.01it/s]\u001b[A\n1542it [00:10, 143.80it/s]\u001b[A\n1557it [00:10, 143.39it/s]\u001b[A\n1572it [00:11, 141.59it/s]\u001b[A\n1587it [00:11, 140.30it/s]\u001b[A\n1602it [00:11, 140.67it/s]\u001b[A\n1617it [00:11, 140.12it/s]\u001b[A\n1632it [00:11, 141.03it/s]\u001b[A\n1647it [00:11, 140.42it/s]\u001b[A\n1662it [00:11, 141.77it/s]\u001b[A\n1677it [00:11, 140.05it/s]\u001b[A\n1692it [00:11, 138.97it/s]\u001b[A\n1706it [00:11, 139.18it/s]\u001b[A\n1720it [00:12, 137.92it/s]\u001b[A\n1734it [00:12, 138.41it/s]\u001b[A\n1748it [00:12, 138.64it/s]\u001b[A\n1762it [00:12, 138.51it/s]\u001b[A\n1777it [00:12, 139.53it/s]\u001b[A\n1792it [00:12, 141.34it/s]\u001b[A\n1807it [00:12, 141.59it/s]\u001b[A\n1822it [00:12, 142.27it/s]\u001b[A\n1837it [00:12, 143.08it/s]\u001b[A\n1852it [00:13, 142.80it/s]\u001b[A\n1867it [00:13, 142.32it/s]\u001b[A\n1882it [00:13, 142.99it/s]\u001b[A\n1897it [00:13, 141.93it/s]\u001b[A\n1912it [00:13, 143.21it/s]\u001b[A\n1927it [00:13, 141.42it/s]\u001b[A\n1942it [00:13, 141.21it/s]\u001b[A\n1957it [00:13, 139.75it/s]\u001b[A\n1971it [00:13, 135.78it/s]\u001b[A\n1986it [00:13, 137.58it/s]\u001b[A\n2001it [00:14, 139.26it/s]\u001b[A\n2015it [00:14, 137.47it/s]\u001b[A\n2030it [00:14, 139.53it/s]\u001b[A\n2045it [00:14, 139.59it/s]\u001b[A\n2060it [00:14, 141.23it/s]\u001b[A\n2075it [00:14, 142.03it/s]\u001b[A\n2090it [00:14, 143.89it/s]\u001b[A\n2105it [00:14, 144.51it/s]\u001b[A\n2120it [00:14, 144.92it/s]\u001b[A\n2135it [00:15, 144.83it/s]\u001b[A\n2150it [00:15, 143.17it/s]\u001b[A\n2165it [00:15, 141.80it/s]\u001b[A\n2180it [00:15, 143.26it/s]\u001b[A\n2195it [00:15, 141.92it/s]\u001b[A\n2210it [00:15, 141.85it/s]\u001b[A\n2225it [00:15, 143.11it/s]\u001b[A\n2240it [00:15, 141.95it/s]\u001b[A\n2255it [00:15, 142.31it/s]\u001b[A\n2270it [00:15, 143.60it/s]\u001b[A\n2286it [00:16, 145.62it/s]\u001b[A\n2301it [00:16, 144.99it/s]\u001b[A\n2316it [00:16, 143.35it/s]\u001b[A\n2331it [00:16, 143.98it/s]\u001b[A\n2346it [00:16, 142.49it/s]\u001b[A\n2361it [00:16, 143.71it/s]\u001b[A\n2376it [00:16, 143.31it/s]\u001b[A\n2391it [00:16, 143.75it/s]\u001b[A\n2406it [00:16, 144.15it/s]\u001b[A\n2421it [00:17, 142.53it/s]\u001b[A\n2436it [00:17, 143.14it/s]\u001b[A\n2451it [00:17, 143.96it/s]\u001b[A\n2466it [00:17, 145.35it/s]\u001b[A\n2481it [00:17, 143.42it/s]\u001b[A\n2496it [00:17, 144.61it/s]\u001b[A\n2511it [00:17, 144.79it/s]\u001b[A\n2526it [00:17, 144.09it/s]\u001b[A\n2541it [00:17, 142.92it/s]\u001b[A\n2556it [00:17, 142.34it/s]\u001b[A\n2571it [00:18, 142.26it/s]\u001b[A\n2586it [00:18, 141.11it/s]\u001b[A\n2601it [00:18, 140.59it/s]\u001b[A\n2616it [00:18, 140.90it/s]\u001b[A\n2631it [00:18, 140.37it/s]\u001b[A\n2646it [00:18, 140.25it/s]\u001b[A\n2661it [00:18, 138.81it/s]\u001b[A\n2675it [00:18, 137.62it/s]\u001b[A\n2690it [00:18, 139.87it/s]\u001b[A\n2705it [00:19, 141.09it/s]\u001b[A\n2720it [00:19, 140.66it/s]\u001b[A\n2735it [00:19, 141.62it/s]\u001b[A\n2750it [00:19, 142.52it/s]\u001b[A\n2765it [00:19, 138.27it/s]\u001b[A\n2779it [00:19, 132.07it/s]\u001b[A\n2793it [00:19, 133.31it/s]\u001b[A\n2807it [00:19, 133.56it/s]\u001b[A\n2821it [00:19, 133.66it/s]\u001b[A\n2835it [00:19, 134.10it/s]\u001b[A\n2849it [00:20, 130.89it/s]\u001b[A\n2863it [00:20, 127.08it/s]\u001b[A\n2876it [00:20, 127.42it/s]\u001b[A\n2889it [00:20, 127.67it/s]\u001b[A\n2904it [00:20, 131.17it/s]\u001b[A\n2918it [00:20, 130.59it/s]\u001b[A\n2932it [00:20, 132.76it/s]\u001b[A\n2946it [00:20, 133.65it/s]\u001b[A\n2961it [00:20, 137.50it/s]\u001b[A\n2975it [00:21, 135.95it/s]\u001b[A\n2989it [00:21, 135.25it/s]\u001b[A\n3003it [00:21, 132.64it/s]\u001b[A\n3017it [00:21, 134.54it/s]\u001b[A\n3031it [00:21, 133.50it/s]\u001b[A\n3045it [00:21, 134.18it/s]\u001b[A\n3059it [00:21, 131.75it/s]\u001b[A\n3073it [00:21, 133.38it/s]\u001b[A\n3087it [00:21, 134.07it/s]\u001b[A\n3101it [00:21, 131.14it/s]\u001b[A\n3115it [00:22, 132.27it/s]\u001b[A\n3129it [00:22, 132.15it/s]\u001b[A\n3143it [00:22, 132.47it/s]\u001b[A\n3157it [00:22, 131.25it/s]\u001b[A\n3171it [00:22, 128.85it/s]\u001b[A\n3185it [00:22, 129.85it/s]\u001b[A\n3200it [00:22, 134.20it/s]\u001b[A\n3215it [00:22, 138.29it/s]\u001b[A\n3230it [00:22, 140.16it/s]\u001b[A\n3245it [00:23, 142.42it/s]\u001b[A\n3260it [00:23, 142.32it/s]\u001b[A\n3275it [00:23, 141.79it/s]\u001b[A\n3290it [00:23, 140.15it/s]\u001b[A\n3305it [00:23, 141.57it/s]\u001b[A\n3320it [00:23, 143.51it/s]\u001b[A\n3335it [00:23, 143.13it/s]\u001b[A\n3350it [00:23, 142.15it/s]\u001b[A\n3365it [00:23, 142.75it/s]\u001b[A\n3380it [00:23, 144.32it/s]\u001b[A\n3395it [00:24, 144.39it/s]\u001b[A\n3410it [00:24, 143.15it/s]\u001b[A\n3425it [00:24, 138.29it/s]\u001b[A\n3439it [00:24, 135.94it/s]\u001b[A\n3453it [00:24, 134.59it/s]\u001b[A\n3467it [00:24, 131.74it/s]\u001b[A\n3481it [00:24, 130.82it/s]\u001b[A\n3495it [00:24, 129.93it/s]\u001b[A\n3509it [00:24, 129.52it/s]\u001b[A\n3522it [00:25, 127.94it/s]\u001b[A\n3536it [00:25, 129.86it/s]\u001b[A\n3550it [00:25, 130.35it/s]\u001b[A\n3564it [00:25, 129.54it/s]\u001b[A\n3577it [00:25, 127.05it/s]\u001b[A\n3591it [00:25, 128.61it/s]\u001b[A\n3605it [00:25, 130.63it/s]\u001b[A\n3619it [00:25, 131.52it/s]\u001b[A\n3633it [00:25, 131.24it/s]\u001b[A\n3647it [00:26, 129.22it/s]\u001b[A\n3660it [00:26, 129.03it/s]\u001b[A\n3673it [00:26, 129.13it/s]\u001b[A\n3687it [00:26, 129.75it/s]\u001b[A\n3700it [00:26, 126.22it/s]\u001b[A\n3713it [00:26, 127.17it/s]\u001b[A\n3726it [00:26, 127.79it/s]\u001b[A\n3740it [00:26, 128.98it/s]\u001b[A\n3753it [00:26, 128.91it/s]\u001b[A\n3767it [00:26, 129.96it/s]\u001b[A\n3781it [00:27, 129.12it/s]\u001b[A\n3795it [00:27, 130.09it/s]\u001b[A\n3809it [00:27, 128.86it/s]\u001b[A\n3823it [00:27, 129.35it/s]\u001b[A\n3836it [00:27, 129.10it/s]\u001b[A\n3849it [00:27, 126.10it/s]\u001b[A\n3862it [00:27, 125.42it/s]\u001b[A\n3875it [00:27, 126.33it/s]\u001b[A\n3888it [00:27, 127.11it/s]\u001b[A\n3901it [00:28, 126.66it/s]\u001b[A\n3914it [00:28, 124.11it/s]\u001b[A\n3927it [00:28, 124.55it/s]\u001b[A\n3940it [00:28, 125.61it/s]\u001b[A\n3954it [00:28, 127.49it/s]\u001b[A\n3967it [00:28, 126.53it/s]\u001b[A\n3981it [00:28, 127.82it/s]\u001b[A\n3994it [00:28, 127.54it/s]\u001b[A\n4000it [00:28, 138.92it/s]\u001b[A","name":"stderr"},{"output_type":"stream","text":"                                      has_cactus\nid                                              \n000940378805c44108d287872b2f04ce.jpg    0.694138\n0017242f54ececa4512b4d7937d1e21e.jpg    0.895040\n001ee6d8564003107853118ab87df407.jpg    0.047621\n002e175c3c1e060769475f52182583d0.jpg    0.008739\n0036e44a7e8f7218e9bc7bf8137e4943.jpg    0.379535\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}