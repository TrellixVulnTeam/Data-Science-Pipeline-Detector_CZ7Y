{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\n\n#prepara the data\ntrain_path = \"../input/train/train\"\ntest_path = \"../input/test/test\"\n\nlabel_frame = pd.read_csv('../input/train.csv')\ntest_frame = pd.read_csv('../input/sample_submission.csv')\nx_train = []\nx_test = []\ny_train = np.array(label_frame['has_cactus'])\n#load images\nfrom keras.preprocessing import image\nfor fname in label_frame['id']:\n    image_path = os.path.join(train_path , fname)\n    pil_image = image.load_img(image_path, target_size=(32, 32, 3))\n    np_image = image.img_to_array(pil_image)\n    x_train.append(np_image)\nfor fname in test_frame['id']:\n    image_path = os.path.join(test_path,fname)\n    pil_image = image.load_img(image_path,target_size = (32,32,3))\n    np_image = image.img_to_array(pil_image)\n    x_test.append(np_image)\n#trans to array\nx_train = np.array(x_train)\nx_train = x_train.astype('float32')/255\nx_test = np.array(x_test)\nx_test = x_test.astype('float32')/255\nprint(x_train.shape)\nprint(x_test.shape)","execution_count":1,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"},{"output_type":"stream","text":"(17500, 32, 32, 3)\n(4000, 32, 32, 3)\n","name":"stdout"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#build model\nfrom keras.applications import VGG16\nfrom keras import models\nfrom keras import layers\nfrom keras import optimizers\nfrom keras.callbacks import EarlyStopping,ModelCheckpoint,ReduceLROnPlateau\ndef get_model():\n    base = VGG16(include_top = False,weights = 'imagenet',input_shape = (32,32,3))\n    base.trainable = True\n    base.summary()\n    set_trainable = False\n    for layer in base.layers:\n        if layer.name == 'block5_conv3':\n            set_trainable = True\n        if set_trainable:\n            layer.trainable = True\n        else:\n            layer.trainable = False\n    model = models.Sequential()\n    model.add(base)\n    model.add(layers.Flatten())\n    \n    model.add(layers.BatchNormalization())\n    \n    model.add(layers.Dense(256,activation = 'relu'))\n    \n    model.add(layers.BatchNormalization())\n    model.add(layers.Dropout(0.5))\n    model.add(layers.Dense(1,activation = 'sigmoid'))\n    model.summary()\n    model.compile(loss = 'binary_crossentropy',optimizer = 'adam',metrics = ['acc'])\n    return model\n    \nmodel = get_model()\n'''\nx_val = x_train[16600:]\ny_val = y_train[16600:]\n\nmodel_check_point = ModelCheckpoint('./model.h5',monitor = 'val_loss',save_best_only = True)\nearly_stopping = EarlyStopping(monitor = 'val_loss',patience = 25)\nreduce_lr_on_plateau = ReduceLROnPlateau(monitor = 'val_loss',patience = 15)\n\nhistory = model.fit(x_train[:16600],y_train[:16600],epochs = 80,batch_size = 250,validation_data = (x_val,y_val),\\\n        callbacks = [model_check_point,reduce_lr_on_plateau])\n#visualize\nimport matplotlib.pyplot as plt\n\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()\n'''","execution_count":2,"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\nDownloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n58892288/58889256 [==============================] - 3s 0us/step\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         (None, 32, 32, 3)         0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n=================================================================\nTotal params: 14,714,688\nTrainable params: 14,714,688\nNon-trainable params: 0\n_________________________________________________________________\nWARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nvgg16 (Model)                (None, 1, 1, 512)         14714688  \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 512)               0         \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 512)               2048      \n_________________________________________________________________\ndense_1 (Dense)              (None, 256)               131328    \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 256)               1024      \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 256)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 1)                 257       \n=================================================================\nTotal params: 14,849,345\nTrainable params: 2,492,929\nNon-trainable params: 12,356,416\n_________________________________________________________________\n","name":"stdout"},{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"\"\\nx_val = x_train[16600:]\\ny_val = y_train[16600:]\\n\\nmodel_check_point = ModelCheckpoint('./model.h5',monitor = 'val_loss',save_best_only = True)\\nearly_stopping = EarlyStopping(monitor = 'val_loss',patience = 25)\\nreduce_lr_on_plateau = ReduceLROnPlateau(monitor = 'val_loss',patience = 15)\\n\\nhistory = model.fit(x_train[:16600],y_train[:16600],epochs = 80,batch_size = 250,validation_data = (x_val,y_val),        callbacks = [model_check_point,reduce_lr_on_plateau])\\n#visualize\\nimport matplotlib.pyplot as plt\\n\\nacc = history.history['acc']\\nval_acc = history.history['val_acc']\\nloss = history.history['loss']\\nval_loss = history.history['val_loss']\\n\\nepochs = range(len(acc))\\n\\nplt.plot(epochs, acc, 'bo', label='Training acc')\\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\\nplt.title('Training and validation accuracy')\\nplt.legend()\\n\\nplt.figure()\\n\\nplt.plot(epochs, loss, 'bo', label='Training loss')\\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\\nplt.title('Training and validation loss')\\nplt.legend()\\n\\nplt.show()\\n\""},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(x_train,y_train,epochs = 100,batch_size = 250)\ny_predictions = model.predict(x_test)\nresult = pd.DataFrame({'id' : pd.read_csv('../input/sample_submission.csv')['id'],'has_cactus' : y_predictions.squeeze()})\nresult.to_csv(\"submission.csv\", index=False, columns=['id', 'has_cactus'])\nprint('submit successful')","execution_count":3,"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nEpoch 1/100\n17500/17500 [==============================] - 5s 311us/step - loss: 0.1587 - acc: 0.9459\nEpoch 2/100\n17500/17500 [==============================] - 2s 109us/step - loss: 0.0740 - acc: 0.9765\nEpoch 3/100\n17500/17500 [==============================] - 2s 109us/step - loss: 0.0692 - acc: 0.9781\nEpoch 4/100\n17500/17500 [==============================] - 2s 112us/step - loss: 0.0486 - acc: 0.9840\nEpoch 5/100\n17500/17500 [==============================] - 2s 110us/step - loss: 0.0462 - acc: 0.9841\nEpoch 6/100\n17500/17500 [==============================] - 2s 112us/step - loss: 0.0423 - acc: 0.9863\nEpoch 7/100\n17500/17500 [==============================] - 2s 109us/step - loss: 0.0406 - acc: 0.9868\nEpoch 8/100\n17500/17500 [==============================] - 2s 109us/step - loss: 0.0350 - acc: 0.9875\nEpoch 9/100\n17500/17500 [==============================] - 2s 110us/step - loss: 0.0344 - acc: 0.9887\nEpoch 10/100\n17500/17500 [==============================] - 2s 109us/step - loss: 0.0301 - acc: 0.9893\nEpoch 11/100\n17500/17500 [==============================] - 2s 110us/step - loss: 0.0287 - acc: 0.9901\nEpoch 12/100\n17500/17500 [==============================] - 2s 109us/step - loss: 0.0237 - acc: 0.9918\nEpoch 13/100\n17500/17500 [==============================] - 2s 109us/step - loss: 0.0289 - acc: 0.9899\nEpoch 14/100\n17500/17500 [==============================] - 2s 109us/step - loss: 0.0229 - acc: 0.9912\nEpoch 15/100\n17500/17500 [==============================] - 2s 109us/step - loss: 0.0241 - acc: 0.9915\nEpoch 16/100\n17500/17500 [==============================] - 2s 109us/step - loss: 0.0239 - acc: 0.9917\nEpoch 17/100\n17500/17500 [==============================] - 2s 110us/step - loss: 0.0260 - acc: 0.9907\nEpoch 18/100\n17500/17500 [==============================] - 2s 109us/step - loss: 0.0190 - acc: 0.9929\nEpoch 19/100\n17500/17500 [==============================] - 2s 109us/step - loss: 0.0167 - acc: 0.9942\nEpoch 20/100\n17500/17500 [==============================] - 2s 109us/step - loss: 0.0236 - acc: 0.9922\nEpoch 21/100\n17500/17500 [==============================] - 2s 109us/step - loss: 0.0189 - acc: 0.9930\nEpoch 22/100\n17500/17500 [==============================] - 2s 109us/step - loss: 0.0174 - acc: 0.9938\nEpoch 23/100\n17500/17500 [==============================] - 2s 109us/step - loss: 0.0175 - acc: 0.9933\nEpoch 24/100\n16250/17500 [==========================>...] - ETA: 0s - loss: 0.0186 - acc: 0.9925","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-038424d585b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m250\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'id'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/sample_submission.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'has_cactus'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0my_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"submission.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'has_cactus'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'submit successful'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}