{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!mkdir data\n!cp ../input/aerial-cactus-identification/* data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!unzip -o data/test.zip -d data >/dev/null\n!unzip -o data/train.zip -d data >/dev/null\n!rm -f data/*.zip","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport datetime\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.optim.lr_scheduler as lr_scheduler\nimport torchvision.transforms as transforms\nimport torchvision\nfrom sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, precision_score, recall_score\nfrom PIL import Image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CLASS_NAMES = ('0', '1')\ndata_root = './data'\ntrain_data_path = os.path.join(data_root, 'train')\ntest_data_path = os.path.join(data_root, 'test')\ntrain_set_path = os.path.join(train_data_path, 'train')\ndev_set_path = os.path.join(train_data_path, 'dev')\ntest_set_path = os.path.join(train_data_path, 'test')\nNORM_MEAN = [0.485, 0.456, 0.406]\nNORM_STD = [0.229, 0.224, 0.225]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read csv file of train set and create right data\ntrain_targets = pd.read_csv(os.path.join(data_root, 'train.csv'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train_targets['id'].values\ny = train_targets['has_cactus'].values.astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, _X_test, y_train, _y_test = train_test_split(X, y, test_size=0.1, shuffle=True, stratify=y)\nX_dev, X_test, y_dev, y_test = train_test_split(_X_test, _y_test, test_size=0.5, shuffle=True, stratify=_y_test)\nno_cactus_weight = (y_train==1).sum() / y_train.shape[0]\nhas_cactus_weight = (y_train==0).sum() / y_train.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for set_path in (train_set_path, dev_set_path, test_set_path):\n  os.system(f\"mkdir {set_path}\")\n  for class_name in CLASS_NAMES:\n    os.system(f\"mkdir {os.path.join(set_path, class_name)}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for path, file_names, labels in ((train_set_path, X_train, y_train), (dev_set_path, X_dev, y_dev), (test_set_path, X_test, y_test)):\n  for file_name, label in zip(file_names, labels):\n    os.system(f\"mv -f {os.path.join(train_data_path, file_name)} {os.path.join(path, str(label), file_name)}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport math\nimport random\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport torchvision.transforms.functional as F\nfrom sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, precision_score, recall_score\nimport matplotlib.pyplot as plt\nfrom torch.utils.tensorboard import SummaryWriter\n\nfrom tqdm.autonotebook import tqdm\n\n\nMETRICS = {\n    'accuracy': {\n        'f': balanced_accuracy_score,\n        'args': {}\n    },\n    # 'balanced_accuracy': {\n    #     'f': balanced_accuracy_score,\n    #     'args': {}\n    # },\n    # 'f1': {\n    #     'f': f1_score,\n    #     'args': {'average': 'weighted'}\n    # },\n    # 'precision': {\n    #     'f': precision_score,\n    #     'args': {'average': 'weighted'}\n    # },\n    # 'recall': {\n    #     'f': recall_score,\n    #     'args': {'average': 'weighted'}\n    # }\n}\n\n\nNORM_MEAN = [0.485, 0.456, 0.406]\nNORM_STD = [0.229, 0.224, 0.225]\n\n\ndef make_image_label_grid(images, labels=None, class_names=None):\n    channels = images.shape[1]\n    if channels not in (3, 1):\n        raise ValueError(\"Images must have 1 or 3 channels\")\n    mean = NORM_MEAN if channels == 3 else [sum(NORM_MEAN) / 3]\n    std = NORM_STD if channels == 3 else [sum(NORM_STD) / 3]\n    mean = torch.tensor(mean)\n    std = torch.tensor(std)\n    mean = (-mean / std).tolist()\n    std = (1.0 / std).tolist()\n    img_grid = torchvision.utils.make_grid(images)\n    img_grid = F.normalize(img_grid, mean=mean, std=std)\n    return img_grid\n\n\ndef make_image_label_figure(images, labels=None, class_names=None):\n    channels = images.shape[1]\n    if channels not in (3, 1):\n        raise ValueError(\"Images must have 1 or 3 channels\")\n    mean = NORM_MEAN if channels == 3 else [sum(NORM_MEAN) / 3]\n    std = NORM_STD if channels == 3 else [sum(NORM_STD) / 3]\n    mean = torch.tensor(mean)\n    std = torch.tensor(std)\n    mean = (-mean / std).tolist()\n    std = (1.0 / std).tolist()\n    n = int(math.sqrt(len(images)))\n    figure = plt.figure(figsize=(n, n))\n    figure.subplots_adjust(hspace=0.4, wspace=0.4)\n    for i in range(n*n):\n        image, label = images[i], (0 if labels is None else labels[i])\n        image = F.normalize(image, mean=mean, std=std)\n        image = image.permute(1, 2, 0)\n        image = torch.squeeze(image)\n        image = (image * 255).int()\n        plt.subplot(n, n, i + 1, title='NA' if class_names is None else class_names[label])\n        plt.xticks([])\n        plt.yticks([])\n        plt.grid(False)\n        plt.imshow(image, cmap='gray' if channels == 1 else None)\n    return figure\n\n\nclass TrainerProgressBar(tqdm):\n\n    def __init__(self, desc=None, total=10, unit='it', position=None):\n        super(TrainerProgressBar, self).__init__(\n            desc=desc, total=total, leave=True, unit=unit, position=position, dynamic_ncols=True\n        )\n\n    def reset(self, total=None, desc=None, ordered_dict=None):\n        # super(TrainerProgressBar, self).reset(total)\n        self.last_print_n = self.n = 0\n        self.last_print_t = self.start_t = self._time()\n        if total is not None:\n            self.total = total\n        super(TrainerProgressBar, self).refresh()\n        if desc is not None:\n            super(TrainerProgressBar, self).set_description(desc)\n        if ordered_dict is not None:\n            super(TrainerProgressBar, self).set_postfix(ordered_dict)\n\n    def update(self, desc=None, ordered_dict=None, n=1):\n        if desc is not None:\n            super(TrainerProgressBar, self).set_description(desc)\n        if ordered_dict is not None:\n            super(TrainerProgressBar, self).set_postfix(ordered_dict)\n        super(TrainerProgressBar, self).update(n)\n\n\nclass PyTorchTrainer(object):\n\n    def __init__(self, device=None, metrics=None, epoch_callback=None, batch_callback=None):\n        self.device = torch.device(device) if device else torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n        self.metrics = metrics or METRICS\n        self.epoch_callback = epoch_callback\n        self.batch_callback = batch_callback\n\n        self.train_pb = None\n        self.epoch_train_pb = None\n        self.epoch_val_pb = None\n\n    def train(self, model, optimizer, loss_criterion, train_data_loader, val_data_loader, scheduler=None,\n              epochs=10):\n        # Print log\n        print(f\"=============================== Training NN ===============================\")\n        print(f\"== Epochs:              {epochs:6d}\")\n        print(f\"== Train batch size:    {train_data_loader.batch_size:6d}\")\n        print(f\"== Train batches:       {len(train_data_loader):6d}\")\n        print(f\"== Validate batch size: {val_data_loader.batch_size:6d}\")\n        print(f\"== Validate batches:    {len(val_data_loader):6d}\")\n        print(f\"===========================================================================\")\n        # Initialize progress bars\n        self.train_pb = TrainerProgressBar(desc=f'== Epoch {1}', total=epochs, unit='epoch', position=0)\n        self.epoch_train_pb = TrainerProgressBar(desc=f'== Train {1}', total=len(train_data_loader),\n                                                 unit='batch', position=1)\n        self.epoch_val_pb = TrainerProgressBar(desc=f'== Val {1}', total=len(val_data_loader), unit='batch',\n                                               position=2)\n        # Reset progress bars\n        self.train_pb.reset(total=epochs)\n        self.epoch_train_pb.reset(total=len(train_data_loader))\n        self.epoch_val_pb.reset(total=len(val_data_loader))\n        for epoch in range(epochs):\n            # Train batches\n            train_loss, train_metrics_dict = self.forward_batches(model, optimizer, loss_criterion,\n                                                                  train_data_loader, epoch, train=True)\n            # Val batches\n            val_loss, val_metrics_dict = self.forward_batches(model, optimizer, loss_criterion,\n                                                              val_data_loader, epoch, train=False)\n            # Make scheduler step\n            if scheduler:\n                if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n                    scheduler.step(train_loss, epoch=epoch)\n                else:\n                    scheduler.step(epoch=epoch)\n            # Update progress bar\n            lr = optimizer.param_groups[0]['lr']\n            if self.epoch_callback:\n                self.epoch_callback(model, epoch, lr, train_loss, val_loss, train_metrics_dict, val_metrics_dict)\n            metrics_dict = {'lr': lr}\n            for metric_name in train_metrics_dict:\n                metrics_dict[f\"train_{metric_name}\"] = train_metrics_dict[metric_name]\n                metrics_dict[f\"val_{metric_name}\"] = val_metrics_dict[metric_name]\n            metrics_dict.update({'train_loss': train_loss, 'val_loss': val_loss})\n            self.train_pb.update(desc=f'== Epoch {epoch+1}', ordered_dict=metrics_dict)\n        # Close progress bars\n        self.train_pb.close()\n        self.epoch_train_pb.close()\n        self.epoch_val_pb.close()\n        # Print log\n        print(f\"===========================================================================\")\n\n    def forward_batches(self, model, optimizer, loss_criterion, data_loader, epoch, train=True):\n        # Set model train or eval due to current phase\n        if train:\n            model.train()\n        else:\n            model.eval()\n        # Preset variables\n        avg_loss_value = 0\n        avg_metrics_dict = None\n        batches = len(data_loader)\n        # Reset progress bar\n        if train:\n            self.epoch_train_pb.reset(batches, f\"== Train {epoch+1}\")\n        else:\n            self.epoch_val_pb.reset(batches, f\"== Val {epoch+1}\")\n        for batch_i, data in enumerate(data_loader, 1):\n            # Forward batch\n            loss_value, predictions, targets = self.forward_batch(model, optimizer, loss_criterion, data,\n                                                                  train=train)\n            metrics_dict = self.metrics_dict(predictions, targets)\n            # Update variables\n            avg_loss_value += loss_value\n            if avg_metrics_dict is None:\n                avg_metrics_dict = metrics_dict.copy()\n            else:\n                for metric_name in avg_metrics_dict:\n                    avg_metrics_dict[metric_name] += metrics_dict[metric_name]\n            # Update progress bar\n            if self.batch_callback:\n                self.batch_callback(train, epoch, batch_i, batches, loss_value, metrics_dict)\n            metrics_dict.update({'loss': avg_loss_value/batch_i})\n            if train:\n                self.epoch_train_pb.update(ordered_dict=metrics_dict)\n            else:\n                self.epoch_val_pb.update(ordered_dict=metrics_dict)\n        # Update variables\n        avg_loss_value /= batches\n        for metric_name in avg_metrics_dict:\n            avg_metrics_dict[metric_name] /= batches\n        # Return\n        return avg_loss_value, avg_metrics_dict\n\n    def forward_batch(self, model, optimizer, loss_criterion, batch_data, train=True):\n        # Get Inputs and Targets and put them to device\n        inputs, targets = batch_data\n        _inputs = inputs.to(self.device)\n        _targets = targets.to(self.device)\n        with torch.set_grad_enabled(train):\n            # Forward model to get outputs\n            _outputs = model.forward(_inputs)\n            # Calculate Loss Criterion\n            loss = loss_criterion(_outputs, _targets)\n        if train:\n            # Zero optimizer gradients\n            optimizer.zero_grad()\n            # Calculate new gradients\n            loss.backward()\n            # Make optimizer step\n            optimizer.step()\n        # Variables\n        loss_value = loss.item()\n        predictions = _outputs.argmax(dim=1).data.cpu()\n        targets = targets.data\n        return loss_value, predictions, targets\n\n    def metrics_dict(self, predictions, targets):\n        d = {}\n        for metric_name in self.metrics:\n            metric_value = self.metrics[metric_name]['f'](predictions, targets, **self.metrics[metric_name]['args'])\n            d[metric_name] = metric_value\n\n        return d","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transforms\nclass TrainTransforms(transforms.Compose):\n\n    def __init__(self):\n        super(TrainTransforms, self).__init__([\n            transforms.RandomHorizontalFlip(p=0.5),\n            transforms.RandomVerticalFlip(p=0.5),\n#             transforms.ColorJitter(brightness=(0.75, 1.5), contrast=(0.75, 1.5), \n#                                    saturation=(0.75, 1.5), hue=(-0.1, 0.1)),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=NORM_MEAN, std=NORM_STD)\n        ])\n\n\nclass TestTransforms(transforms.Compose):\n\n    def __init__(self):\n        super(TestTransforms, self).__init__([\n            transforms.ToTensor(),\n            transforms.Normalize(mean=NORM_MEAN, std=NORM_STD)\n        ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train/dev/test dataloaders and datasets\n# Batch size\nbatch_size = 1024\n# Datasets\ntrain_dataset = torchvision.datasets.ImageFolder(train_set_path, transform=TrainTransforms())\ndev_dataset = torchvision.datasets.ImageFolder(dev_set_path, transform=TestTransforms())\ntest_dataset = torchvision.datasets.ImageFolder(test_set_path, transform=TestTransforms())\n# Dataloaders\ntrain_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\ndev_dataloader = torch.utils.data.DataLoader(dev_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\ntest_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show train batch\nimages, targets = next(iter(train_dataloader))\nfig = make_image_label_figure(images[:9], targets[:9], CLASS_NAMES)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show dev batch\nimages, targets = next(iter(dev_dataloader))\nfig = make_image_label_figure(images[:9], targets[:9], CLASS_NAMES)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show test batch\nimages, targets = next(iter(test_dataloader))\nfig = make_image_label_figure(images[:9], targets[:9], CLASS_NAMES)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torchvision.models as models\n\n\nclass ResNet(nn.Module):\n\n  def __init__(self, resnet18, classes):\n    super(ResNet, self).__init__()\n    self.feature_extractor = nn.Sequential(\n      resnet18.conv1,\n      resnet18.bn1,\n      resnet18.relu,\n      resnet18.maxpool,\n      resnet18.layer1,\n      resnet18.layer2,\n      resnet18.layer3\n    )\n    self.classifier = nn.Sequential(\n      nn.Dropout(0.2),\n      nn.Linear(2*2*256, classes)\n    )\n\n  def forward(self, x):\n    x = self.feature_extractor(x)\n    x = x.view(-1, 2*2*256)\n    x = self.classifier(x)\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train Net\ndevice = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n\nnet = ResNet(models.resnet18(pretrained=True), classes=2)\nnet = net.to(torch.device(device))\n\ncriterion = nn.CrossEntropyLoss(weight=torch.tensor([no_cactus_weight, has_cactus_weight], dtype=torch.float32).to(torch.device(device)))\noptimizer = optim.Adam(net.parameters(), lr=0.0001, weight_decay=0.0001)\nscheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.96)\n\nmetrics = {\n    'accuracy': {\n        'f': accuracy_score,\n        'args': {}\n    },\n    'balanced_accuracy': {\n        'f': balanced_accuracy_score,\n        'args': {}\n    },\n    'f1': {\n        'f': f1_score,\n        'args': {'average': 'weighted'}\n    }\n}\n\ntrainer = PyTorchTrainer(device=device, metrics=metrics)\ntrainer.train(net, optimizer, criterion, train_dataloader, dev_dataloader, scheduler=scheduler, epochs=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Trigger net to eval mode\nnet.eval()\nfor parameter in net.parameters():\n  parameter.requires_grad = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_metrics_dict(predictions, targets):\n  d = {}\n  for metric_name in metrics:\n    metric_value = metrics[metric_name]['f'](predictions, targets, **metrics[metric_name]['args'])\n    d[metric_name] = metric_value\n  return d\n\n# Forward test set\navg_metrics_dict = None\nbatches = len(test_dataloader)\nfor batch_data in test_dataloader:\n  # Get Inputs and put them to device\n  inputs, targets = batch_data\n  _inputs = inputs.to(torch.device(device))\n  # Forward model to get outputs\n  _outputs = net.forward(_inputs)\n  # Variables\n  predictions = _outputs.argmax(dim=1).data.cpu()\n  metrics_dict = get_metrics_dict(predictions, targets)\n  # Update variables\n  if avg_metrics_dict is None:\n    avg_metrics_dict = metrics_dict.copy()\n  else:\n    for metric_name in avg_metrics_dict:\n      avg_metrics_dict[metric_name] += metrics_dict[metric_name]\n\nfor metric_name in avg_metrics_dict:\n  avg_metrics_dict[metric_name] /= batches\n  print(metric_name, avg_metrics_dict[metric_name])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Submission Dataset Class\nclass SubmissionDataset(torch.utils.data.Dataset):\n  \n  def __init__(self, root, transform=None):\n    super(SubmissionDataset, self).__init__()\n    self.transform = transform\n    self.image_filenames = []\n    self.image_paths = []\n    for dirname, _, filenames in os.walk(root):\n      for filename in filenames:\n        self.image_filenames.append(filename)\n        self.image_paths.append(os.path.join(root, filename))\n  \n  def __len__(self):\n    return len(self.image_filenames)\n      \n  def __getitem__(self, index):\n    image = Image.open(self.image_paths[index])\n    return image if self.transform is None else self.transform(image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Submission Dataset\nsubmission_dataset = SubmissionDataset(test_data_path, transform=TestTransforms())\n# Submission Dataloader\nsubmission_dataloader = torch.utils.data.DataLoader(submission_dataset, batch_size=batch_size, shuffle=False, num_workers=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show submission batch\nimages = next(iter(submission_dataloader))\nfig = make_image_label_figure(images[:9])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get all submission predictions\ntest_predictions = None\nfor batch_data in submission_dataloader:\n  # Get Inputs and put them to device\n  inputs = batch_data\n  _inputs = inputs.to(torch.device(device))\n  # Forward model to get outputs\n  _outputs = net.forward(_inputs)\n  # Variables\n  predictions = _outputs.argmax(dim=1).data\n  test_predictions = predictions if test_predictions is None else torch.cat((test_predictions, predictions))\ntest_predictions = test_predictions.cpu().numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Write submission to pd.DataFrame\nsubmission_df = pd.DataFrame(np.c_[np.array(submission_dataset.image_filenames)[:,None], test_predictions], columns=['id', 'has_cactus'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Write submission DataFrame to csv\nsubmission_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm -rf data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}