{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Aerial Cactus Identification","metadata":{}},{"cell_type":"markdown","source":"# Load Packages","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport pandas as pd\nimport pickle\nimport cv2\nfrom tqdm import tqdm \nimport matplotlib as mpl\n\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimport zipfile ","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2021-11-18T23:19:08.464815Z","iopub.execute_input":"2021-11-18T23:19:08.465591Z","iopub.status.idle":"2021-11-18T23:19:11.839219Z","shell.execute_reply.started":"2021-11-18T23:19:08.465531Z","shell.execute_reply":"2021-11-18T23:19:11.838106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load DataFrame","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"../input/aerial-cactus-identification/train.csv\", dtype=str)\nprint(train.shape)","metadata":{"_cell_guid":"","_uuid":"","execution":{"iopub.status.busy":"2021-11-18T23:19:11.841305Z","iopub.execute_input":"2021-11-18T23:19:11.841703Z","iopub.status.idle":"2021-11-18T23:19:11.879241Z","shell.execute_reply.started":"2021-11-18T23:19:11.841643Z","shell.execute_reply":"2021-11-18T23:19:11.878435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:19:11.880985Z","iopub.execute_input":"2021-11-18T23:19:11.88175Z","iopub.status.idle":"2021-11-18T23:19:11.907309Z","shell.execute_reply.started":"2021-11-18T23:19:11.881686Z","shell.execute_reply":"2021-11-18T23:19:11.906516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Extract Images","metadata":{}},{"cell_type":"code","source":"zip_ref = zipfile.ZipFile('/kaggle/input/aerial-cactus-identification/train.zip')\nzip_ref.extractall()","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:19:11.908678Z","iopub.execute_input":"2021-11-18T23:19:11.909821Z","iopub.status.idle":"2021-11-18T23:19:15.07275Z","shell.execute_reply.started":"2021-11-18T23:19:11.909756Z","shell.execute_reply":"2021-11-18T23:19:15.071716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_path = \"train/\"\nprint('Training Images:', len(os.listdir(train_path)))","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:19:15.075705Z","iopub.execute_input":"2021-11-18T23:19:15.076314Z","iopub.status.idle":"2021-11-18T23:19:15.096649Z","shell.execute_reply.started":"2021-11-18T23:19:15.076005Z","shell.execute_reply":"2021-11-18T23:19:15.095462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Training Images:', len(os.listdir('train/')))\n\nfor i in range(10):\n  img = plt.imread('train/' + train.id[i])\n  print('Images shape', img.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:19:15.098666Z","iopub.execute_input":"2021-11-18T23:19:15.099015Z","iopub.status.idle":"2021-11-18T23:19:15.136552Z","shell.execute_reply.started":"2021-11-18T23:19:15.098971Z","shell.execute_reply":"2021-11-18T23:19:15.135772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# View Sample of Images","metadata":{}},{"cell_type":"code","source":"sample = train.sample(n=16).reset_index()\n\nplt.figure(figsize=(8,8))\n\nfor i, row in sample.iterrows():\n\n    img = mpimg.imread(f'train/{row.id}')    \n    label = row.has_cactus\n\n    plt.subplot(4,4,i+1)\n    plt.imshow(img)\n    plt.text(0, -5, f'Class {label}', color='k')\n        \n    plt.axis('off')\n\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:19:15.137792Z","iopub.execute_input":"2021-11-18T23:19:15.138218Z","iopub.status.idle":"2021-11-18T23:19:16.654701Z","shell.execute_reply.started":"2021-11-18T23:19:15.138178Z","shell.execute_reply":"2021-11-18T23:19:16.653781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Model\n\nHere we load a model that has been previously trained on this dataset. ","metadata":{}},{"cell_type":"code","source":"cnn = load_model('../input/models/Cactus/cactus_model_v01.h5')\ncnn.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:19:16.655754Z","iopub.execute_input":"2021-11-18T23:19:16.65609Z","iopub.status.idle":"2021-11-18T23:19:18.087121Z","shell.execute_reply.started":"2021-11-18T23:19:16.656051Z","shell.execute_reply":"2021-11-18T23:19:18.085987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Heatmap Functions\n\nIn the cell below we create the two functions that will be used to generate the heatmaps. \n* The function `create_grad_model()` is used to create a \"gradient model\" from our CNN. It needs to be called only once. \n* The function `compute_heatmap()` returns a numpy array representing the heatmap for a single image. ","metadata":{}},{"cell_type":"code","source":"def create_grad_model(model):\n    for layer in reversed(model.layers):\n        if len(layer.output_shape) == 4:\n            last_conv_layer = layer.name\n            break\n\n    grad_model = tf.keras.models.Model(\n        inputs=[model.inputs],\n        outputs=[model.get_layer(last_conv_layer).output, model.output])\n    \n    return grad_model \n\ndef compute_heatmap(image, class_ix, grad_model):\n\n    with tf.GradientTape() as tape:\n        inputs = tf.cast(image, tf.float32)\n        (conv_outputs, predictions) = grad_model(inputs)\n        loss = predictions[:, class_ix]\n    grads = tape.gradient(loss, conv_outputs)\n\n    cast_conv_outputs = tf.cast(conv_outputs > 0, \"float32\")\n    cast_grads = tf.cast(grads > 0, \"float32\")\n    guided_grads = cast_conv_outputs * cast_grads * grads\n\n    conv_outputs = conv_outputs[0]\n    guided_grads = guided_grads[0]\n\n    weights = tf.reduce_mean(guided_grads, axis=(0, 1))\n\n    cam = tf.reduce_sum(tf.multiply(weights, conv_outputs), axis=-1)\n\n    (w, h) = (image.shape[2], image.shape[1])\n    heatmap = cv2.resize(cam.numpy(), (w, h))\n        \n    return heatmap","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:19:18.088586Z","iopub.execute_input":"2021-11-18T23:19:18.088913Z","iopub.status.idle":"2021-11-18T23:19:18.10237Z","shell.execute_reply.started":"2021-11-18T23:19:18.08887Z","shell.execute_reply":"2021-11-18T23:19:18.101295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Example: First Heatmap","metadata":{}},{"cell_type":"code","source":"# Create Gradient Model\ngm = create_grad_model(cnn)\n\n# Select Image and Create Heatmap\nfilename = train.id[0]\nimg = mpimg.imread(f'train/{filename}')       \ntensor = img.reshape(-1,32,32,3) / 255\nheatmap = compute_heatmap(tensor, 1, gm)\n\nplt.figure(figsize=[9,3])\n\n# Display Image\nplt.subplot(1,3,1)\nplt.imshow(img)\nplt.axis('off')\n\n# Display Heatmap\nplt.subplot(1,3,2)\nplt.imshow(heatmap, cmap='coolwarm')\nplt.axis('off')\n\n# Display Image and Heatmap Together\nplt.subplot(1,3,3)\nplt.imshow(img, alpha=0.8, cmap='binary_r')\nplt.imshow(heatmap, alpha=0.6, cmap='coolwarm')\nplt.axis('off')\n    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:19:34.558867Z","iopub.execute_input":"2021-11-18T23:19:34.559549Z","iopub.status.idle":"2021-11-18T23:19:34.842852Z","shell.execute_reply.started":"2021-11-18T23:19:34.559498Z","shell.execute_reply":"2021-11-18T23:19:34.841526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The function below is used to get a sense as to the distribution of the heatmap values for images in the dataset. It creates heatmaps for every image in the DataFrame `df` and stores them into an array named values, which is then returned. ","metadata":{}},{"cell_type":"markdown","source":"# Displaying Multiple Heatmaps","metadata":{}},{"cell_type":"code","source":"def get_heatmap_dist(df, class_ix, gm):\n\n    values = None\n    for i, row in tqdm(df.iterrows()):\n        img = mpimg.imread(f'train/{row.id}')    \n        tensor = img.reshape(1,32,32,3) / 255\n        hm = compute_heatmap(tensor, class_ix, gm)\n\n        if values is None:\n            values = hm.flatten()\n        else:\n            values = np.hstack([values, hm.flatten()])\n\n    return values","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:19:40.713371Z","iopub.execute_input":"2021-11-18T23:19:40.713791Z","iopub.status.idle":"2021-11-18T23:19:40.722068Z","shell.execute_reply.started":"2021-11-18T23:19:40.713739Z","shell.execute_reply":"2021-11-18T23:19:40.720969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"values = get_heatmap_dist(train.sample(1000, random_state=1), 1, gm)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:19:40.724015Z","iopub.execute_input":"2021-11-18T23:19:40.724547Z","iopub.status.idle":"2021-11-18T23:19:57.129342Z","shell.execute_reply.started":"2021-11-18T23:19:40.724474Z","shell.execute_reply":"2021-11-18T23:19:57.128241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The colorscale that matplotlib assigns to an heatmap are determined be the values present within that image. As a result, each heatmap we display will have its own colorscale by default. We can make the colorscales uniform by specifying a \"norm\" for the color scale. This requires us to specify a lower and upper end for the color scale. We do that in the cell below. This requires some trial and error in order to get the heatmaps to display well. ","metadata":{}},{"cell_type":"code","source":"low = np.quantile(values, 0.10)\nhigh = np.quantile(values, 0.96)\n\nnorm = mpl.colors.Normalize(vmin=low, vmax=high)\n\nprint(low)\nprint(high)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:20:32.5813Z","iopub.execute_input":"2021-11-18T23:20:32.581782Z","iopub.status.idle":"2021-11-18T23:20:32.605771Z","shell.execute_reply.started":"2021-11-18T23:20:32.581734Z","shell.execute_reply":"2021-11-18T23:20:32.604679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will now diplay several images along with their class activation heatmaps.","metadata":{}},{"cell_type":"code","source":"# Select which images to display\nindices = range(12)\n\nfor i in indices:  \n    row = train.iloc[i,:]\n    img = mpimg.imread(f'train/{row.id}')    \n    label = row.has_cactus\n    \n    tensor = img.reshape(-1,32,32,3) / 255\n    heatmap = compute_heatmap(tensor, 1, gm)\n\n    if(label == '1'):\n        print('Cactus Present')\n    else:\n        print('No Cactus')\n    \n    plt.figure(figsize=[9,3])\n\n    plt.subplot(1,3,1)\n    plt.imshow(img)\n    plt.axis('off')\n\n    plt.subplot(1,3,2)\n    plt.imshow(heatmap, cmap='coolwarm', norm=norm)\n    plt.axis('off')\n\n    plt.subplot(1,3,3)\n    plt.imshow(img, alpha=0.6, cmap='binary_r')\n    plt.imshow(heatmap, alpha=0.6, cmap='coolwarm', norm=norm)\n    plt.axis('off')\n    \n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:20:34.694859Z","iopub.execute_input":"2021-11-18T23:20:34.695395Z","iopub.status.idle":"2021-11-18T23:20:38.230379Z","shell.execute_reply.started":"2021-11-18T23:20:34.695321Z","shell.execute_reply":"2021-11-18T23:20:38.228818Z"},"trusted":true},"execution_count":null,"outputs":[]}]}