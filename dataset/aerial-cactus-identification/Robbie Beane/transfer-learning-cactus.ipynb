{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Transfer Learning Tutorial","metadata":{}},{"cell_type":"markdown","source":"# Load Packages\n\nWe will begin by loading the necessary packages. ","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import backend as K\n\nimport zipfile ","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2022-03-22T19:38:27.448808Z","iopub.execute_input":"2022-03-22T19:38:27.44916Z","iopub.status.idle":"2022-03-22T19:38:35.827245Z","shell.execute_reply.started":"2022-03-22T19:38:27.449087Z","shell.execute_reply":"2022-03-22T19:38:35.82605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Helper Functions\n\nThe functions below are used for merging the contents of Keras history objects, and for displaying training curves. We will use these after each training run. ","metadata":{}},{"cell_type":"code","source":"def merge_history(hlist):\n    history = {}\n    for k in hlist[0].history.keys():\n        history[k] = sum([h.history[k] for h in hlist], [])\n    return history\n\ndef vis_training(h, start=1):\n    epoch_range = range(start, len(h['loss'])+1)\n    s = slice(start-1, None)\n\n    plt.figure(figsize=[14,4])\n\n    n = int(len(h.keys()) / 2)\n\n    for i in range(n):\n        k = list(h.keys())[i]\n        plt.subplot(1,n,i+1)\n        plt.plot(epoch_range, h[k][s], label='Training')\n        plt.plot(epoch_range, h['val_' + k][s], label='Validation')\n        plt.xlabel('Epoch'); plt.ylabel(k); plt.title(k)\n        plt.grid()\n        plt.legend()\n\n    plt.tight_layout()\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-03-22T19:39:08.737323Z","iopub.execute_input":"2022-03-22T19:39:08.737795Z","iopub.status.idle":"2022-03-22T19:39:08.750599Z","shell.execute_reply.started":"2022-03-22T19:39:08.737735Z","shell.execute_reply":"2022-03-22T19:39:08.749161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load DataFrame\n\nWe will now load information about training images into a Pandas DataFrame.","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"../input/aerial-cactus-identification/train.csv\", dtype=str)\nprint(train.shape)","metadata":{"_cell_guid":"","_uuid":"","execution":{"iopub.status.busy":"2022-03-22T19:39:20.133112Z","iopub.execute_input":"2022-03-22T19:39:20.13365Z","iopub.status.idle":"2022-03-22T19:39:20.183461Z","shell.execute_reply.started":"2022-03-22T19:39:20.133424Z","shell.execute_reply":"2022-03-22T19:39:20.182567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T19:39:23.3458Z","iopub.execute_input":"2022-03-22T19:39:23.346198Z","iopub.status.idle":"2022-03-22T19:39:23.377535Z","shell.execute_reply.started":"2022-03-22T19:39:23.346141Z","shell.execute_reply":"2022-03-22T19:39:23.376285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Label Distribution\n\nNext, we will check the distribution of the labels in our training set. ","metadata":{}},{"cell_type":"code","source":"y_train = train.has_cactus\n\n(train.has_cactus.value_counts() / len(train)).to_frame()","metadata":{"execution":{"iopub.status.busy":"2022-03-22T19:39:42.779236Z","iopub.execute_input":"2022-03-22T19:39:42.77972Z","iopub.status.idle":"2022-03-22T19:39:42.929463Z","shell.execute_reply.started":"2022-03-22T19:39:42.779632Z","shell.execute_reply":"2022-03-22T19:39:42.928561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Extract Images\n\nThe image files for this dataset are compressed into zip files. We will now extract the training images.","metadata":{}},{"cell_type":"code","source":"zip_ref = zipfile.ZipFile('/kaggle/input/aerial-cactus-identification/train.zip')\nzip_ref.extractall()","metadata":{"execution":{"iopub.status.busy":"2022-03-22T19:39:53.852369Z","iopub.execute_input":"2022-03-22T19:39:53.852821Z","iopub.status.idle":"2022-03-22T19:39:58.001993Z","shell.execute_reply.started":"2022-03-22T19:39:53.85276Z","shell.execute_reply":"2022-03-22T19:39:58.000745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_path = \"train/\"\nprint('Number of Training Images:', len(os.listdir(train_path)))","metadata":{"execution":{"iopub.status.busy":"2022-03-22T19:39:58.008301Z","iopub.execute_input":"2022-03-22T19:39:58.014808Z","iopub.status.idle":"2022-03-22T19:39:58.039727Z","shell.execute_reply.started":"2022-03-22T19:39:58.014671Z","shell.execute_reply":"2022-03-22T19:39:58.038637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# View Sample of Images\n\nNext, we will view a sample of training images. ","metadata":{}},{"cell_type":"code","source":"sample = train.sample(n=16).reset_index()\n\nplt.figure(figsize=(8,8))\n\nfor i, row in sample.iterrows():\n\n    img = mpimg.imread(f'train/{row.id}')    \n    label = row.has_cactus\n\n    plt.subplot(4,4,i+1)\n    plt.imshow(img)\n    plt.text(0, -5, f'Class {label}', color='k')\n        \n    plt.axis('off')\n\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-03-22T19:40:14.258853Z","iopub.execute_input":"2022-03-22T19:40:14.259262Z","iopub.status.idle":"2022-03-22T19:40:15.869117Z","shell.execute_reply.started":"2022-03-22T19:40:14.259204Z","shell.execute_reply":"2022-03-22T19:40:15.867629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Generators\n\nIn this section, we will split the labeled observations into training and validation sets. We will then create data loaders to feed the images into our neural network during training.","metadata":{}},{"cell_type":"code","source":"train_df, valid_df = train_test_split(train, test_size=0.2, random_state=1, stratify=train.has_cactus)\n\nprint(train_df.shape)\nprint(valid_df.shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T19:40:25.529526Z","iopub.execute_input":"2022-03-22T19:40:25.529986Z","iopub.status.idle":"2022-03-22T19:40:25.568214Z","shell.execute_reply.started":"2022-03-22T19:40:25.529928Z","shell.execute_reply":"2022-03-22T19:40:25.567177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale=1/255)\nvalid_datagen = ImageDataGenerator(rescale=1/255)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T19:40:31.265332Z","iopub.execute_input":"2022-03-22T19:40:31.265817Z","iopub.status.idle":"2022-03-22T19:40:31.271755Z","shell.execute_reply.started":"2022-03-22T19:40:31.265746Z","shell.execute_reply":"2022-03-22T19:40:31.27054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 64\n\ntrain_loader = train_datagen.flow_from_dataframe(\n    dataframe = train_df,\n    directory = train_path,\n    x_col = 'id',\n    y_col = 'has_cactus',\n    batch_size = BATCH_SIZE,\n    seed = 1,\n    shuffle = True,\n    class_mode = 'categorical',\n    target_size = (32,32)\n)\n\nvalid_loader = valid_datagen.flow_from_dataframe(\n    dataframe = valid_df,\n    directory = train_path,\n    x_col = 'id',\n    y_col = 'has_cactus',\n    batch_size = BATCH_SIZE,\n    seed = 1,\n    shuffle = True,\n    class_mode = 'categorical',\n    target_size = (32,32)\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-22T19:40:34.036563Z","iopub.execute_input":"2022-03-22T19:40:34.036997Z","iopub.status.idle":"2022-03-22T19:40:34.281107Z","shell.execute_reply.started":"2022-03-22T19:40:34.036903Z","shell.execute_reply":"2022-03-22T19:40:34.279797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TR_STEPS = len(train_loader)\nVA_STEPS = len(valid_loader)\n\nprint(TR_STEPS)\nprint(VA_STEPS)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T19:40:37.064989Z","iopub.execute_input":"2022-03-22T19:40:37.06544Z","iopub.status.idle":"2022-03-22T19:40:37.072914Z","shell.execute_reply.started":"2022-03-22T19:40:37.065369Z","shell.execute_reply":"2022-03-22T19:40:37.071564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build Network\n\nIn this section, we will construct our neural network. For feature extraction, we will use the [VGG16](https://www.geeksforgeeks.org/vgg-16-cnn-model/) model, as trained on the [ImageNet](https://www.image-net.org/) dataset. \n\nIn the cell below, we will load the pretrained VGG16 model into a variable named `base_model`. We will set `include_top=False` to indicate that we only wish to use the convolutional blocks that appear before the `Flatten()` layer. We will not include the dense layers composing the classifier at the top of the network. Instead, we will design and train our own classifier. \n\nWe set the `input_shape` parameter to indicate the shape of the images that we will be feeding into the network. \n\nFinally, we set the `trainable` parameter of the model to `False`. This tells Keras that we do not wish to update the weights in the base layer during training. We only wish to train the new classifier that we will design. ","metadata":{}},{"cell_type":"code","source":"base_model = tf.keras.applications.VGG16(input_shape=(32,32,3),\n                                         include_top=False,\n                                         weights='imagenet')\n\nbase_model.trainable = False","metadata":{"execution":{"iopub.status.busy":"2022-03-22T19:45:05.352664Z","iopub.execute_input":"2022-03-22T19:45:05.353158Z","iopub.status.idle":"2022-03-22T19:45:10.294814Z","shell.execute_reply.started":"2022-03-22T19:45:05.353098Z","shell.execute_reply":"2022-03-22T19:45:10.293718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Before moving forward, let's take a look at the structure of our base model. Notice that it consists of 5 convolutional blocks, some of which contain 2 convolutional layers, and some of which contain 3. Also note that none of the weights in the model are trainable (since we have set them to not be). ","metadata":{}},{"cell_type":"code","source":"base_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-22T19:45:18.697412Z","iopub.execute_input":"2022-03-22T19:45:18.69788Z","iopub.status.idle":"2022-03-22T19:45:18.71768Z","shell.execute_reply.started":"2022-03-22T19:45:18.697818Z","shell.execute_reply":"2022-03-22T19:45:18.71659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"VGG16 is one of many pretrained models that we could have used. Common choices include VGG16, VGG19, ResNet50, and InceptionV3. A full list of the pretrained models provided by Keras can be found here: [Keras Applications](https://keras.io/api/applications/)\n\nWe are now ready to build a classifier for our neural network. In the cell below, we include `base_model` in the network as if were a single layer. ","metadata":{}},{"cell_type":"code","source":"cnn = Sequential([\n    base_model,\n    \n    Flatten(),\n    \n    Dense(64, activation='relu'),\n    Dropout(0.5),\n    Dense(32, activation='relu'),\n    Dropout(0.5),\n    BatchNormalization(),\n    Dense(2, activation='softmax')\n])\n\ncnn.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-22T19:48:21.077734Z","iopub.execute_input":"2022-03-22T19:48:21.078161Z","iopub.status.idle":"2022-03-22T19:48:21.312122Z","shell.execute_reply.started":"2022-03-22T19:48:21.0781Z","shell.execute_reply":"2022-03-22T19:48:21.311094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Network\n\nWe are now ready to train the network.","metadata":{}},{"cell_type":"code","source":"opt = tf.keras.optimizers.Adam(0.001)\ncnn.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy', tf.keras.metrics.AUC()])","metadata":{"execution":{"iopub.status.busy":"2022-03-22T19:48:40.104581Z","iopub.execute_input":"2022-03-22T19:48:40.105058Z","iopub.status.idle":"2022-03-22T19:48:40.252105Z","shell.execute_reply.started":"2022-03-22T19:48:40.104997Z","shell.execute_reply":"2022-03-22T19:48:40.251098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training Run 1","metadata":{}},{"cell_type":"code","source":"%%time \n\nh1 = cnn.fit(\n    x = train_loader, \n    steps_per_epoch = TR_STEPS, \n    epochs = 10,\n    validation_data = valid_loader, \n    validation_steps = VA_STEPS, \n    verbose = 1\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T19:48:49.764649Z","iopub.execute_input":"2022-03-22T19:48:49.765055Z","iopub.status.idle":"2022-03-22T19:50:16.300466Z","shell.execute_reply.started":"2022-03-22T19:48:49.764994Z","shell.execute_reply":"2022-03-22T19:50:16.299417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = merge_history([h1])\nvis_training(history)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T19:50:50.023047Z","iopub.execute_input":"2022-03-22T19:50:50.023478Z","iopub.status.idle":"2022-03-22T19:50:51.0393Z","shell.execute_reply.started":"2022-03-22T19:50:50.023398Z","shell.execute_reply":"2022-03-22T19:50:51.037869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training Run 2","metadata":{}},{"cell_type":"code","source":"K.set_value(cnn.optimizer.learning_rate, 0.0001)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T19:51:07.326879Z","iopub.execute_input":"2022-03-22T19:51:07.327301Z","iopub.status.idle":"2022-03-22T19:51:07.335131Z","shell.execute_reply.started":"2022-03-22T19:51:07.327237Z","shell.execute_reply":"2022-03-22T19:51:07.333056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time \n\nh2 = cnn.fit(\n    x = train_loader, \n    steps_per_epoch = TR_STEPS, \n    epochs = 5,\n    validation_data = valid_loader, \n    validation_steps = VA_STEPS, \n    verbose = 1\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T19:51:13.303755Z","iopub.execute_input":"2022-03-22T19:51:13.304179Z","iopub.status.idle":"2022-03-22T19:51:54.768589Z","shell.execute_reply.started":"2022-03-22T19:51:13.304116Z","shell.execute_reply":"2022-03-22T19:51:54.767471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = merge_history([h1, h2])\nvis_training(history, start=10)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T19:52:59.683257Z","iopub.execute_input":"2022-03-22T19:52:59.684206Z","iopub.status.idle":"2022-03-22T19:53:00.939529Z","shell.execute_reply.started":"2022-03-22T19:52:59.684138Z","shell.execute_reply":"2022-03-22T19:53:00.938052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training Run 3 (Fine-Tuning)\n","metadata":{}},{"cell_type":"code","source":"base_model.trainable = True\n\nopt = tf.keras.optimizers.Adam(0.00001)\ncnn.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy', tf.keras.metrics.AUC()])","metadata":{"execution":{"iopub.status.busy":"2022-03-22T19:53:59.084904Z","iopub.execute_input":"2022-03-22T19:53:59.085323Z","iopub.status.idle":"2022-03-22T19:53:59.091472Z","shell.execute_reply.started":"2022-03-22T19:53:59.08526Z","shell.execute_reply":"2022-03-22T19:53:59.090147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time \n\nh3 = cnn.fit(\n    x = train_loader, \n    steps_per_epoch = TR_STEPS, \n    epochs = 10,\n    validation_data = valid_loader, \n    validation_steps = VA_STEPS, \n    verbose = 1\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T19:54:58.416648Z","iopub.execute_input":"2022-03-22T19:54:58.417074Z","iopub.status.idle":"2022-03-22T19:56:23.393994Z","shell.execute_reply.started":"2022-03-22T19:54:58.41701Z","shell.execute_reply":"2022-03-22T19:56:23.392137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"h3.history['auc'] = h3.history['auc_1'] \nh3.history['val_auc'] = h3.history['val_auc_1'] ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = merge_history([h1, h2, h3])\nvis_training(history, start=10)","metadata":{"execution":{"iopub.status.busy":"2022-03-22T19:56:40.009618Z","iopub.execute_input":"2022-03-22T19:56:40.010048Z","iopub.status.idle":"2022-03-22T19:56:41.131035Z","shell.execute_reply.started":"2022-03-22T19:56:40.009984Z","shell.execute_reply":"2022-03-22T19:56:41.129968Z"},"trusted":true},"execution_count":null,"outputs":[]}]}