{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Aerial Cactus Identification","metadata":{}},{"cell_type":"markdown","source":"https://keras.io/examples/vision/visualizing_what_convnets_learn/","metadata":{}},{"cell_type":"markdown","source":"# Load Packages","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport pandas as pd\nimport pickle\n\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimport zipfile ","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2021-11-18T23:35:23.371996Z","iopub.execute_input":"2021-11-18T23:35:23.372291Z","iopub.status.idle":"2021-11-18T23:35:30.007468Z","shell.execute_reply.started":"2021-11-18T23:35:23.372245Z","shell.execute_reply":"2021-11-18T23:35:30.006669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load DataFrame","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"../input/aerial-cactus-identification/train.csv\", dtype=str)\ntest = pd.read_csv(\"../input/aerial-cactus-identification/sample_submission.csv\", dtype=str)\nprint(train.shape)\nprint(test.shape)","metadata":{"_cell_guid":"","_uuid":"","execution":{"iopub.status.busy":"2021-11-18T23:35:30.009457Z","iopub.execute_input":"2021-11-18T23:35:30.009866Z","iopub.status.idle":"2021-11-18T23:35:30.077039Z","shell.execute_reply.started":"2021-11-18T23:35:30.009817Z","shell.execute_reply":"2021-11-18T23:35:30.076175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:35:30.078357Z","iopub.execute_input":"2021-11-18T23:35:30.078886Z","iopub.status.idle":"2021-11-18T23:35:30.100736Z","shell.execute_reply.started":"2021-11-18T23:35:30.078836Z","shell.execute_reply":"2021-11-18T23:35:30.099866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Label Distribution","metadata":{}},{"cell_type":"code","source":"y_train = train.has_cactus\n\n(train.has_cactus.value_counts() / len(train)).to_frame()","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:35:30.102779Z","iopub.execute_input":"2021-11-18T23:35:30.103049Z","iopub.status.idle":"2021-11-18T23:35:30.222401Z","shell.execute_reply.started":"2021-11-18T23:35:30.103006Z","shell.execute_reply":"2021-11-18T23:35:30.221617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Extract Images","metadata":{}},{"cell_type":"code","source":"train_zip_ref = zipfile.ZipFile('/kaggle/input/aerial-cactus-identification/train.zip')\ntrain_zip_ref.extractall()\n\ntest_zip_ref = zipfile.ZipFile('/kaggle/input/aerial-cactus-identification/test.zip')\ntest_zip_ref.extractall()","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:35:30.225146Z","iopub.execute_input":"2021-11-18T23:35:30.225639Z","iopub.status.idle":"2021-11-18T23:35:33.388131Z","shell.execute_reply.started":"2021-11-18T23:35:30.225471Z","shell.execute_reply":"2021-11-18T23:35:33.387234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_path = \"train/\"\ntest_path = \"test/\"\nprint('Training Images:', len(os.listdir(train_path)))\nprint('Training Images:', len(os.listdir(test_path)))","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:35:33.390711Z","iopub.execute_input":"2021-11-18T23:35:33.391255Z","iopub.status.idle":"2021-11-18T23:35:33.414903Z","shell.execute_reply.started":"2021-11-18T23:35:33.391205Z","shell.execute_reply":"2021-11-18T23:35:33.414128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Training Images:', len(os.listdir('train/')))\n\nfor i in range(10):\n  img = plt.imread('train/' + train.id[i])\n  print('Images shape', img.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:35:33.41789Z","iopub.execute_input":"2021-11-18T23:35:33.418194Z","iopub.status.idle":"2021-11-18T23:35:33.467546Z","shell.execute_reply.started":"2021-11-18T23:35:33.418149Z","shell.execute_reply":"2021-11-18T23:35:33.466396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# View Sample of Images","metadata":{}},{"cell_type":"code","source":"sample = train.sample(n=16).reset_index()\n\nplt.figure(figsize=(8,8))\n\nfor i, row in sample.iterrows():\n\n    img = mpimg.imread(f'train/{row.id}')    \n    label = row.has_cactus\n\n    plt.subplot(4,4,i+1)\n    plt.imshow(img)\n    plt.text(0, -5, f'Class {label}', color='k')\n        \n    plt.axis('off')\n\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:35:33.46889Z","iopub.execute_input":"2021-11-18T23:35:33.469234Z","iopub.status.idle":"2021-11-18T23:35:35.049559Z","shell.execute_reply.started":"2021-11-18T23:35:33.469189Z","shell.execute_reply":"2021-11-18T23:35:35.048517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Model","metadata":{}},{"cell_type":"code","source":"cnn = load_model('../input/models/Cactus/cactus_model_v01.h5')\ncnn.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:35:35.050736Z","iopub.execute_input":"2021-11-18T23:35:35.051071Z","iopub.status.idle":"2021-11-18T23:35:38.427184Z","shell.execute_reply.started":"2021-11-18T23:35:35.051033Z","shell.execute_reply":"2021-11-18T23:35:38.42615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Filter Visualization Functions\n\nThe functions in the cell below can be used to create a single filter visualization.","metadata":{}},{"cell_type":"code","source":"def compute_loss(input_image, layer, filter_index):\n    feature_extractor = tf.keras.Model(inputs=cnn.inputs, outputs=layer.output)\n    activation = feature_extractor(input_image)\n    # We avoid border artifacts by only involving non-border pixels in the loss.\n    filter_activation = activation[:, 2:-2, 2:-2, filter_index]\n    return tf.reduce_mean(filter_activation)\n\ndef gradient_ascent_step(img, layer, filter_index, learning_rate):\n    with tf.GradientTape() as tape:\n        tape.watch(img)\n        loss = compute_loss(img, layer, filter_index)\n    # Compute gradients.\n    grads = tape.gradient(loss, img)\n    # Normalize gradients.\n    grads = tf.math.l2_normalize(grads)\n    img += learning_rate * grads\n    return loss, img\n\ndef initialize_image():\n    img = tf.random.uniform((1, 32, 32, 3))\n    # ResNet50V2 expects inputs in the range [-1, +1].\n    # Here we scale our random inputs to [-0.125, +0.125]\n    return (img - 0.5) * 0.25\n\n\ndef visualize_filter(layer, filter_index, steps, learning_rate):\n    img = initialize_image()\n    for iteration in range(steps):\n        loss, img = gradient_ascent_step(img, layer, filter_index, learning_rate)\n\n    # Decode the resulting input image\n    img = deprocess_image(img[0].numpy())\n    return loss, img\n\n\ndef deprocess_image(img):\n    # Normalize array: center on 0., ensure variance is 0.15\n    img -= img.mean()\n    img /= img.std() + 1e-5\n    img *= 0.15\n\n    # Clip to [0, 1]\n    img += 0.5\n    img = np.clip(img, 0, 1)\n\n    # Convert to RGB array\n    img *= 255\n    img = np.clip(img, 0, 255).astype(\"uint8\")\n    return img","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:35:38.431815Z","iopub.execute_input":"2021-11-18T23:35:38.434379Z","iopub.status.idle":"2021-11-18T23:35:38.456343Z","shell.execute_reply.started":"2021-11-18T23:35:38.432389Z","shell.execute_reply":"2021-11-18T23:35:38.455025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The function in the cell below will create visualizations for all filters in a selected layer. ","metadata":{}},{"cell_type":"code","source":"def display_layer_filters(layer_name, steps=60, learning_rate=1):\n    layer = cnn.get_layer(name=layer_name)\n            \n    n_filters = layer.filters\n    n_cols = 8\n    n_rows = n_filters // n_cols\n    \n    print(f'{layer_name} - {n_filters} filters')\n    \n    plt.figure(figsize=[2*n_cols, 2*n_rows])\n    for i in range(n_filters):\n        plt.subplot(n_rows, n_cols, i+1)\n        loss, img = visualize_filter(layer, i, steps, learning_rate)\n        plt.imshow(img)\n        plt.axis('off')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:36:50.980278Z","iopub.execute_input":"2021-11-18T23:36:50.980972Z","iopub.status.idle":"2021-11-18T23:36:50.996018Z","shell.execute_reply.started":"2021-11-18T23:36:50.980677Z","shell.execute_reply":"2021-11-18T23:36:50.994629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualizing Individual Laters","metadata":{}},{"cell_type":"code","source":"display_layer_filters('conv2d')","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:36:53.404047Z","iopub.execute_input":"2021-11-18T23:36:53.404501Z","iopub.status.idle":"2021-11-18T23:37:00.374456Z","shell.execute_reply.started":"2021-11-18T23:36:53.404429Z","shell.execute_reply":"2021-11-18T23:37:00.373561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_layer_filters('conv2d_1', steps=200)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:37:58.294997Z","iopub.execute_input":"2021-11-18T23:37:58.295437Z","iopub.status.idle":"2021-11-18T23:38:14.32523Z","shell.execute_reply.started":"2021-11-18T23:37:58.29539Z","shell.execute_reply":"2021-11-18T23:38:14.324441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_layer_filters('conv2d_2', steps=200, learning_rate=1)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:38:25.065536Z","iopub.execute_input":"2021-11-18T23:38:25.065928Z","iopub.status.idle":"2021-11-18T23:39:13.56331Z","shell.execute_reply.started":"2021-11-18T23:38:25.065875Z","shell.execute_reply":"2021-11-18T23:39:13.562433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_layer_filters('conv2d_3', steps=200, learning_rate=1)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:39:13.565041Z","iopub.execute_input":"2021-11-18T23:39:13.565601Z","iopub.status.idle":"2021-11-18T23:41:02.30968Z","shell.execute_reply.started":"2021-11-18T23:39:13.565553Z","shell.execute_reply":"2021-11-18T23:41:02.308871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Display All Convolutional Filters","metadata":{}},{"cell_type":"code","source":"for layer in cnn.layers:\n    if 'conv' in layer.name:\n        display_layer_filters(layer.name, steps=200)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:41:25.154088Z","iopub.execute_input":"2021-11-18T23:41:25.154466Z","iopub.status.idle":"2021-11-18T23:43:36.957939Z","shell.execute_reply.started":"2021-11-18T23:41:25.154414Z","shell.execute_reply":"2021-11-18T23:43:36.95702Z"},"trusted":true},"execution_count":null,"outputs":[]}]}