{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"id":"tgB6q6VN3NoN","trusted":true},"cell_type":"code","source":"from glob import glob\n\nimport numpy as np\nimport tensorflow as tf\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom tensorflow.keras import layers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# os.listdir('train')","execution_count":null,"outputs":[]},{"metadata":{"id":"Naq83qEP4EZy","trusted":true},"cell_type":"code","source":"from zipfile import ZipFile\n# with ZipFile('../input//aerial-cactus-identification.zip')as zip_obj :\n#   zip_obj.extractall()\nwith ZipFile('../input/aerial-cactus-identification/test.zip')as test_obj :\n  test_obj.extractall()\nwith ZipFile('../input/aerial-cactus-identification/train.zip')as train_obj :\n  train_obj.extractall()","execution_count":null,"outputs":[]},{"metadata":{"id":"OUpbvkcL5EJQ"},"cell_type":"markdown","source":"## 데이터 확인","execution_count":null},{"metadata":{"id":"IU6nIYV75IAP"},"cell_type":"markdown","source":"## csv파일 확인\n - ```train.csv``` : id, has_cactus가 담겨 있으며 총 17500개의 데이터\n  - train데이터에 관한 csv\n - ```sample_submission.csv``` : 구성은 같으며 4000개의 데이터\n  - test데이터에 관한 csv","execution_count":null},{"metadata":{"id":"E_2p6F334ZXY","outputId":"e90536dd-764e-40ee-d4db-ffb38627eee0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/aerial-cactus-identification/train.csv')\nprint(df.head())\n\nfile_list = df['id']\nhas_cactus = df['has_cactus']\nprint(len(file_list), len(has_cactus))","execution_count":null,"outputs":[]},{"metadata":{"id":"DFdr3EMI4wq4","outputId":"da4885ee-0e0a-487b-8591-9ee13eb9f53e","trusted":true},"cell_type":"code","source":"test_df = pd.read_csv('../input/aerial-cactus-identification/sample_submission.csv')\nprint(test_df.head())\n\ntest_fnames = test_df['id']\ntest_labels = test_df['has_cactus']\n\nprint(len(test_fnames), len(test_labels))","execution_count":null,"outputs":[]},{"metadata":{"id":"yoESxlG256_5","outputId":"f8c511c0-4a6f-4c76-a12c-0a33c8364a3a","trusted":true},"cell_type":"code","source":"data_paths = glob('train/*.jpg')\ntest_paths = glob('test/*.jpg')\nprint(len(data_paths), len(test_paths))","execution_count":null,"outputs":[]},{"metadata":{"id":"bLglHmoCE5er","outputId":"6099772d-7aae-42b0-bd42-1175c6f80387","trusted":true},"cell_type":"code","source":"pa = glob('train/*.jpg')[0]\npa\ng = tf.io.read_file(pa)\nim = tf.io.decode_image(g)\nprint(im.shape)\nplt.imshow(im)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"au6Nu-N9FLJx","trusted":true},"cell_type":"code","source":"input_shape = (32, 32, 3)\nbatch_size = 32","execution_count":null,"outputs":[]},{"metadata":{"id":"ozZkAooa6x4E"},"cell_type":"markdown","source":"하지만 케글에서 실습을 하면서 강사님께서 알려주신 방법은 다음과 같다  \ncsv에서 ```id``` 열의 데이터를 활용해서 파일의 경로를 만들고 그에따른 label값을 ```has_cactus```열의 데이터로 만들었음","execution_count":null},{"metadata":{"id":"1RiKP3Wi62A-","trusted":true},"cell_type":"code","source":"data_dir = 'train'\n\ndata_paths = []\nfor fname, label in zip(file_list, has_cactus) :\n  data_paths.append((os.path.join(data_dir, fname), label))","execution_count":null,"outputs":[]},{"metadata":{"id":"XZDHY5kU6Hj_","outputId":"dda98762-5eb3-4680-fbc1-597daa31b9f5","trusted":true},"cell_type":"code","source":"data_paths[:10]","execution_count":null,"outputs":[]},{"metadata":{"id":"pOpEuaOv6p6Q"},"cell_type":"markdown","source":"### ***학습을 할때 validatio_data가 있으면 좋은 것일까?***\n그전에 먼저 데이터에 대해서 알아본다  \n<br>\n#### 데이터의 종류\n- Train Data\n - 분석 모델을 만들기 위한 학습용 데이터이다\n- Validation Data\n - 여러 분석 모델 중 어떤 모델이 적합한지 선택하기 위한 검증용 데이터이다.\n- Test Data\n - 최종적으로 선택된 분석 모델이 얼마나 잘 작동하는지 확인하기 위한 결과용 데이터이다.<br>\n\n#### https://3months.tistory.com/118\n","execution_count":null},{"metadata":{"id":"JZ4MYK1g-EAX"},"cell_type":"markdown","source":"\n\n```python\ndef read_data(path) :\n  gfile = tf.io.read_file(path)\n  image = tf.io.decode_image(gfile)\n\n  class_name = tf.strings.split(path, '/')[-1]\n  class_name = tf.strings.split(class_name, '_')[-1]\n  class_name = tf.strings.split(class_name, '.')[0]\n\n  onehot = tf.cast(labels == class_name, tf.uint8)\n\n  return image, onehot\n```\n\n기존의 read_data는 위의 함수의 형태로 되어 있었다. (mnist, cifar10)  \nmnist와 cifar와 같은 경우는 10개의 클래스로 분류하는 것\n하지만 이 데이터는\n- 입력된 사진으로 부터\n  - 선인장이 있는지\n  - 없는지\n2가지로 분류하는 것  \n\n- 이진분류? \n - 이진 분류에서 많이 사용하는 활성화함수 : ```sigmoid```\n - 다중 분류에서 많이 사용되는 활성화함수 : ```softmax```\n - 추가적으로 이진분류의 loss는 ```binary_crossentroy``` 활용","execution_count":null},{"metadata":{"id":"zyvyH1pRCUDS","trusted":true},"cell_type":"code","source":"def tmp_func (path_name) :\n  return path_name","execution_count":null,"outputs":[]},{"metadata":{"id":"jdnl4VJE9kMW","trusted":true},"cell_type":"code","source":"def read_data(path_name) :\n  img_path = path_name[0]\n  label = tf.strings.to_number(path_name[1], out_type=tf.int64)\n\n  gfile = tf.io.read_file(img_path)\n  image = tf.io.decode_image(gfile)\n  \n  return image, label","execution_count":null,"outputs":[]},{"metadata":{"id":"xsvawKTd_qHo","outputId":"944338f7-32d3-4ca5-83c2-a17293b815d3","trusted":true},"cell_type":"code","source":"a = tf.data.Dataset.from_tensor_slices(np.array(data_paths[:2]))\na = a.map(tmp_func)\np = next(iter(a))\np[0], p[1]","execution_count":null,"outputs":[]},{"metadata":{"id":"3Zp3rq2gA61u"},"cell_type":"markdown","source":"이전에 만든 data_path에는 경로와 그에 따른 label값들이 들어가게 된다  \n이를 각각 경로를 통해서 image를 읽어들이는 것과 label값을 return하도록 만든다  \n<br>\n**근데 .... label값을 그대로 return 해줘도 되는가?**  \n<br>\n이게 제일 의문점이다.  \nimage 자체는 ```tf.io.read_file```, ```tf.io.decode_image``` 기존에 사용했던 것들을 활용하면 되는 것  \n이전에 mnist나 cifar10 같은 경우는 각 입력값들로부터 onehot encoding을 통해서 결과를 return해주었지만 여기선 이진 분류이기 때문에 **선인장이 있는가? 없는가?**를 판단 하는 것이고 ......","execution_count":null},{"metadata":{"id":"4LN8H1AqD5a5"},"cell_type":"markdown","source":"[shuffle에서 buffer_size](https://helloyjam.github.io/tensorflow/buffer-size-in-shuffle/)\n\n이미지를 읽고 프로세싱하고 배치작업등의 무거운 작업을 하기 전에 tf.data.Dataset.shuffle()을 호출해야 한다  \n+. ```tf.data.Dataset.from_tensor_slices((파일목록, 라벨값))```\n - 파일목록과 라벨값으로 데이터셋을 만드는 것.... 기억해두자","execution_count":null},{"metadata":{"id":"5S3Cn2nVS3yo","trusted":true},"cell_type":"code","source":"train_ratio = 0.8\n\ntrain_paths = data_paths[:int(train_ratio*len(data_paths))]\ntest_paths = data_paths[int(train_ratio*len(data_paths)):]","execution_count":null,"outputs":[]},{"metadata":{"id":"94avpsdo_39O","trusted":true},"cell_type":"code","source":"train_ds = tf.data.Dataset.from_tensor_slices(np.array(train_paths))\ntrain_ds = train_ds.map(read_data)\n# print(next(iter(train_ds)))\n# 이때 확인하면 image에 대한 tensor값과 그 이미지에 대한 라벨을 알 수 있음\ntrain_ds = train_ds.shuffle(len(train_paths))\n# shuffle에 대한 buffer_size에 관해서도(위에 참고)\ntrain_ds = train_ds.batch(batch_size)\ntrain_ds = train_ds.repeat()","execution_count":null,"outputs":[]},{"metadata":{"id":"xLFoWAIhTsmp","trusted":true},"cell_type":"code","source":"valid_ds = tf.data.Dataset.from_tensor_slices(np.array(test_paths))\nvalid_ds = valid_ds.map(read_data)\nvalid_ds = valid_ds.batch(batch_size)\nvalid_ds = valid_ds.repeat()","execution_count":null,"outputs":[]},{"metadata":{"id":"Y8p-BN5jCgkH","trusted":true},"cell_type":"code","source":"inputs = layers.Input(input_shape)\n\n# Feature extraction\nnet = layers.Conv2D(32, 3, 1, 'SAME')(inputs)\nnet = layers.Activation('relu')(net)\nnet = layers.Conv2D(32, 3, 1, 'SAME')(net)\nnet = layers.Activation('relu')(net)\nnet = layers.MaxPooling2D((2, 2))(net)\nnet = layers.Dropout(0.5)(net)\n\nnet = layers.Conv2D(64, 3, 1, 'SAME')(net)\nnet = layers.Activation('relu')(net)\nnet = layers.Conv2D(64, 3, 1, 'SAME')(net)\nnet = layers.Activation('relu')(net)\nnet = layers.MaxPooling2D((2, 2))(net)\nnet = layers.Dropout(0.5)(net)\n\n# classification\nnet = layers.Flatten()(net)\nnet = layers.Dense(512)(net)\nnet = layers.Activation('relu')(net)\nnet = layers.Dropout(0.5)(net)\nnet = layers.Dense(1)(net)\nnet = layers.Activation('sigmoid')(net)\n\nmodel = tf.keras.Model(inputs=inputs, outputs=net, name='cactus_cnn')","execution_count":null,"outputs":[]},{"metadata":{"id":"yorC4uQCGWFi","outputId":"ad1989c2-cca4-4788-fb4e-af63ee7d071b","trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"id":"ln6e-2-zGYVA","trusted":true},"cell_type":"code","source":"model.compile(loss = tf.keras.losses.binary_crossentropy,\n              optimizer = tf.keras.optimizers.Adam(),\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"id":"7BMODvRqHTSp","trusted":true},"cell_type":"code","source":"steps_per_epoch = len(train_paths) // batch_size\nvalidation_steps = len(test_paths) // batch_size","execution_count":null,"outputs":[]},{"metadata":{"id":"GH-ijMFXHZ9I","outputId":"9d684e1b-b90b-4526-c4a6-0dc7cd5d0854","trusted":true},"cell_type":"code","source":"hist = model.fit(train_ds,\n                 validation_data=valid_ds,\n                 validation_steps=validation_steps,\n                 steps_per_epoch=steps_per_epoch,\n                 epochs = 30)","execution_count":null,"outputs":[]},{"metadata":{"id":"N4_opKadHfBf"},"cell_type":"markdown","source":"# 평가","execution_count":null},{"metadata":{"id":"3uRJARc4WDwL","outputId":"f65be399-1d6a-45d1-db42-8be1663c6252","trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"ccIZuxzzWG5Q","outputId":"16da7b02-a317-406d-ada0-13bb6e1b7f4b","trusted":true},"cell_type":"code","source":"test_fnames[:5]","execution_count":null,"outputs":[]},{"metadata":{"id":"bXwSTsA7WYBm","outputId":"8de3b704-7766-44b2-e86c-1a48af8081c5","trusted":true},"cell_type":"code","source":"test_labels[:5]","execution_count":null,"outputs":[]},{"metadata":{"id":"WduOySV7WcAv","outputId":"db06475e-9a17-4658-ddc5-485919e77ef4","trusted":true},"cell_type":"code","source":"test_dir = 'test'\n\neval_paths = []\nfor fname in test_fnames :\n  eval_paths.append(os.path.join(test_dir, fname))\n\nprint(eval_paths[:5])","execution_count":null,"outputs":[]},{"metadata":{"id":"XeqzMNzMWzgi","trusted":true},"cell_type":"code","source":"def image_read(path) :\n  g = tf.io.read_file(path)\n  im = tf.io.decode_image(g)\n\n  return im","execution_count":null,"outputs":[]},{"metadata":{"id":"JIQXYuuacq-Y","trusted":true},"cell_type":"code","source":"from tqdm import tqdm_notebook","execution_count":null,"outputs":[]},{"metadata":{"id":"ftduVgrDYLWR","outputId":"5d8a0667-9fcf-4868-bc41-97395542d0b5","trusted":true},"cell_type":"code","source":"# test_images = [image_read(path) for path in eval_paths]\n\ntest_images = []\nfor path in tqdm_notebook(eval_paths) :\n  test_images.append(image_read(path))\n\n# np.array(test_image).shape","execution_count":null,"outputs":[]},{"metadata":{"id":"epdrpNHfdC38","trusted":true},"cell_type":"code","source":"test_ds = tf.data.Dataset.from_tensor_slices(eval_paths)\ntest_ds = test_ds.map(image_read)\ntest_ds = test_ds.batch(batch_size)","execution_count":null,"outputs":[]},{"metadata":{"id":"kZMWeaAAYXgv","trusted":true},"cell_type":"code","source":"pred = model.predict(test_ds)","execution_count":null,"outputs":[]},{"metadata":{"id":"iosjnJ3FYnT3","outputId":"333c17d3-f1fb-4c7b-c3db-4f7965403233","trusted":true},"cell_type":"code","source":"pred.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"EQvkvFzk6R-o","trusted":true},"cell_type":"code","source":"pred = pred.reshape((4000))","execution_count":null,"outputs":[]},{"metadata":{"id":"eQ_ZYY5Z6wDD","trusted":true},"cell_type":"code","source":"submit_df = pd.read_csv('../input/aerial-cactus-identification/sample_submission.csv')\ntest_fnames = submit_df['id']\ntest_labels = pred  # 결과가 onehot이 아닌 binary로 담아줘야함\n\nsubmit_file = pd.DataFrame({'id':test_fnames, 'has_cactus':test_labels}, columns = ['id', 'has_cactus'])\nsubmit_file\nsubmit_file.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"id":"jOc4DDT38TGC","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}