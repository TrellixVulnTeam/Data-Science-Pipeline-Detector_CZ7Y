{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom tqdm.notebook import tqdm\nfrom tensorflow.keras.layers import Conv2D, Input, BatchNormalization, Activation, MaxPooling2D\nfrom tensorflow.keras.layers import Dense, Flatten\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\nfrom glob import glob\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from zipfile import ZipFile\n# with ZipFile('../input//aerial-cactus-identification.zip')as zip_obj :\n#   zip_obj.extractall()\nwith ZipFile('../input/aerial-cactus-identification/test.zip')as test_obj :\n  test_obj.extractall()\nwith ZipFile('../input/aerial-cactus-identification/train.zip')as train_obj :\n  train_obj.extractall()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('../input/aerial-cactus-identification/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_csv = pd.read_csv('../input/aerial-cactus-identification/train.csv')\ntrain_csv.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv('../input/aerial-cactus-identification/sample_submission.csv')\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_img_id = train_csv['id']\ntrain_img_label = train_csv['has_cactus']\nlen(train_img_id), len(train_img_label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_paths = []\nfor fname, label in tqdm(zip(train_img_id, train_img_label)):\n    input_paths.append((os.path.join('train', fname), label))\n    \nlen(input_paths)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train, valid = train_test_split(input_paths, train_size=0.8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train), len(valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_img(data):\n    img_path = data[0]\n    label = data[1]\n    label = tf.strings.to_number(label, out_type=tf.int64)\n    \n    tf_img = tf.io.read_file(img_path)\n    img = tf.image.decode_image(tf_img)\n    \n    return img, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = tf.data.Dataset.from_tensor_slices(np.array(train))\ntrain_dataset = train_dataset.map(read_img)\ntrain_dataset = train_dataset.shuffle(len(train))\ntrain_dataset = train_dataset.batch(32)\ntrain_dataset = train_dataset.repeat()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_dataset = tf.data.Dataset.from_tensor_slices(np.array(valid))\nvalid_dataset = valid_dataset.map(read_img)\nvalid_dataset = valid_dataset.batch(32)\nvalid_dataset = valid_dataset.repeat()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs = Input((32, 32, 3))\n\n# Feature Extraction\nnet = Conv2D(32, 3, 1, 'SAME')(inputs)\nnet = Activation('relu')(net)\nnet = Conv2D(32, 3, 1, 'SAME')(net)\nnet = Activation('relu')(net)\nnet = MaxPooling2D((2,2))(net)\nnet = BatchNormalization()(net)\n\nnet = Conv2D(64, 3, 1, 'SAME')(net)\nnet = Activation('relu')(net)\nnet = Conv2D(64, 3, 1, 'SAME')(net)\nnet = Activation('relu')(net)\nnet = MaxPooling2D((2,2))(net)\nnet = BatchNormalization()(net)\n\n# classification\nnet = Flatten()(net)\nnet = Dense(512)(net)\nnet = Activation('relu')(net)\nnet = BatchNormalization()(net)\nnet = Dense(1)(net)\noutput = Activation('sigmoid')(net)\n\nbasic_cnn = tf.keras.Model(inputs=inputs, outputs = output, name='basic_cnn')\n\nbasic_cnn.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"basic_cnn.compile(loss = tf.keras.losses.binary_crossentropy,\n             optimizer = tf.keras.optimizers.Adam(),\n             metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"es = EarlyStopping(monitor='val_loss', patience=5, mode='auto')\n# mc = ModelCheckpoint('basic_cnn.h5', monitor='val_accuracy', save_best_only=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"steps_per_epoch = len(train) // 32\nvalidation_steps = len(valid) // 32\n\nhist = basic_cnn.fit(train_dataset,\n                validation_data = valid_dataset,\n                validation_steps=validation_steps,\n                steps_per_epoch=steps_per_epoch,\n                epochs=50,\n                callbacks=[es]\n                )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_imgs = glob('test/*')\nlen(test_imgs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_img_read(path) :\n    tf_img = tf.io.read_file(path)\n    img = tf.io.decode_image(tf_img)\n    return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_ds = tf.data.Dataset.from_tensor_slices(test_imgs)\ntest_ds = test_ds.map(test_img_read)\ntest_ds = test_ds.batch(32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = basic_cnn.predict(test_ds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = pred.reshape((4000))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('../working')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.mkdir('output')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm -r *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_fname = sub['id']\ntest_label = pred\n\nsub_file = pd.DataFrame({'id':test_fname, 'has_cactus':test_label}, columns=['id', 'has_cactus'])\nsub_file.to_csv('./submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}