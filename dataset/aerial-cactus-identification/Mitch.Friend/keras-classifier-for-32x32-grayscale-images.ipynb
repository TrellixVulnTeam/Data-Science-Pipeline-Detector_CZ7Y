{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1 align=\"center\"> AlexNet Classifier For 32X32 Grayscale Images Using Keras"},{"metadata":{},"cell_type":"markdown","source":"## Program Outline\n1. Import Modules\n2. Data Exploration\n3. Create Class Weights\n4. Keras ImageDataGenerator\n5. AlexNet Architecture\n6. Fit Model\n7. Predict Probabilities on Testing Data\n8. Create Submission df"},{"metadata":{},"cell_type":"markdown","source":"# 1) Import Modules"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#import modules\nimport pandas as pd\nimport numpy as np\nfrom collections import Counter\nimport os\n\n\n#visuals\nimport matplotlib.pyplot as plt\n\n#determine class weights\nfrom sklearn.utils import class_weight\n\n#Image Preprocessing\nfrom keras.preprocessing.image import ImageDataGenerator\n\n#Keras\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\nfrom keras.optimizers import Adam\nfrom keras.optimizers import SGD\nfrom keras import initializers\nfrom keras.callbacks import TensorBoard\nfrom keras.utils import np_utils\nfrom keras.constraints import maxnorm\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.layers.normalization import BatchNormalization\n\n#Disable Warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2) Data Exploration"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv('..//input//train.csv')\nprint(train.shape)\nprint(train.head(10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.has_cactus.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3) Create Class Weights\n\n### To deal with imbalanced classes & save some time, assigning a larger weight to the minority class makes sure our algoritm isnt learning too much from the majority class. This also saves time as we do not have to perform a synthetic data generation technique like ADASYN or SMOTE."},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#set class weights\nclass_weights = class_weight.compute_class_weight('balanced',\n                                                 np.unique(train['has_cactus']),\n                                                 train['has_cactus'])\nprint(class_weights)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4) Keras ImageDataGenerator"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_training_model_data(dataframe, batch_size=32, mode='categorical'):\n    \n        #TypeError: If class_mode=\"binary\", y_col=\"has_cactus\" column values must be strings.\n        dataframe['has_cactus'] = dataframe['has_cactus'].astype(str) #resolve error\n        \n        IDG = ImageDataGenerator(rescale=1./255.,      #rescale: make RGB values between 1 and 0\n                                 horizontal_flip=True, #horizontal_flip: Boolean. Randomly flip inputs horizontally.\n                                 vertical_flip=True)   #vertical_flip: Boolean. Randomly flip inputs vertically.\n        \n        #Create Train Data to Feed Into CNN\n        train_data = IDG.flow_from_dataframe(dataframe=dataframe[:15925], #select first 90% of data\n                                             directory='..//input//train//train', #path to the images\n                                             x_col='id', #column in df that contains image names\n                                             y_col='has_cactus', #column in df that contains labels\n                                             class_mode='binary', #binary output\n                                             batch_size=batch_size, #batch size\n                                             color_mode='grayscale', #convert images to gray scale\n                                             target_size=(32,32)) #input image size\n        \n        #Create Validation Data to Feed Into CNN\n        validation_data = IDG.flow_from_dataframe(dataframe=dataframe[15925:], #select last 10% of data\n                                                  directory='..//input//train//train//',\n                                                  x_col='id',\n                                                  y_col='has_cactus',\n                                                  class_mode='binary',\n                                                  batch_size=batch_size,\n                                                  color_mode='grayscale',\n                                                  target_size=(32,32))\n        \n        return train_data, validation_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data, validation_data = create_training_model_data(train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5) AlexNet Architecture"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_alexnet = Sequential()\n\n# 1st Convolutional Layer\nmodel_alexnet.add(Conv2D(32,(3,3),                \n                 input_shape=(32, 32, 1), #dimensions = 32X32, color channel = B&W\n                 padding='same',\n                 activation='relu'))\n\n#pooling\nmodel_alexnet.add(MaxPooling2D(pool_size=(2,2), padding='same')) \nmodel_alexnet.add(BatchNormalization())\n\n# 2nd Convolutional Layer\nmodel_alexnet.add(Conv2D(64,(3,3),\n                padding='same',\n                activation='relu'))\n\n#pooling\nmodel_alexnet.add(MaxPooling2D(pool_size=(2,2), padding='same'))\nmodel_alexnet.add(BatchNormalization())\n\n# 3rd Convolutional Layer\nmodel_alexnet.add(Conv2D(64,(3,3),\n                padding='same',\n                activation='relu'))\nmodel_alexnet.add(BatchNormalization())\n\n#4th Convolutional Layer\nmodel_alexnet.add(Conv2D(128,(3,3),\n                padding='same',\n                activation='relu'))\nmodel_alexnet.add(BatchNormalization())\n\n#5th Convolutional Layer\nmodel_alexnet.add(Conv2D(128,(3,3),\n                padding='same',\n                activation='relu'))\n\n#pooling\nmodel_alexnet.add(MaxPooling2D(pool_size=(3,3), padding='same'))\nmodel_alexnet.add(BatchNormalization())\n\n\n#Flatten\nmodel_alexnet.add(Flatten())\n\n#1st Dense Layer\nmodel_alexnet.add(Dense(128,\n               activation='relu', kernel_initializer='glorot_uniform'))\nmodel_alexnet.add(Dropout(0.10))\nmodel_alexnet.add(BatchNormalization())\n\n#2nd Dense Layer\nmodel_alexnet.add(Dense(256,\n               activation='relu', kernel_initializer='glorot_uniform'))\nmodel_alexnet.add(Dropout(0.20))\nmodel_alexnet.add(BatchNormalization())\n\n# # 3rd Dense Layer\nmodel_alexnet.add(Dense(512,\n               activation='relu', kernel_initializer='glorot_uniform'))\nmodel_alexnet.add(Dropout(0.2))\nmodel_alexnet.add(BatchNormalization())\n\n#output layer\nmodel_alexnet.add(Dense(1, activation='sigmoid'))\n\n#Compile \nmodel_alexnet.compile(loss='binary_crossentropy', optimizer='adam',\n metrics=['accuracy'])\n\n# Set callback functions to early stop training and save the best model so far\ncallbacks = [EarlyStopping(monitor='val_loss', patience=20), #stop if no improvment after 10 epochs\n             \n             ModelCheckpoint(filepath='best_model_alexnet.h5', monitor='val_loss', save_best_only=True)] #improvment val_loss\n\n#summary of Model\nmodel_alexnet.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6) Fit Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"#fit model\nhistory = model_alexnet.fit_generator(train_data,\n          epochs=100,\n          steps_per_epoch=(15925/32),\n          callbacks=callbacks,\n          validation_data = validation_data,\n          validation_steps=(1575/32),\n          class_weight=class_weights,\n          verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = history.history['acc']\nval_accuracy = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(len(accuracy))\nplt.plot(epochs, accuracy, 'bo', label='Training Accuracy')\nplt.plot(epochs, val_accuracy, 'b', label='Validation Accuracy')\nplt.title('Training and Validation accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7) Predict Probabilities on Testing Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create IDG for test images\ntest_IDG = ImageDataGenerator(rescale=1./255.) #rescale test image RGB values\n\n#Perform IDG on images within the test directory\ntest_data = test_IDG.flow_from_directory(\n    directory='..//input//test//',\n    target_size=(32,32),\n    color_mode='grayscale',\n    class_mode='binary',\n    batch_size=1,\n    shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#get prediction probabilities for the 4000 test images\ny_pred = model_alexnet.predict_generator(test_data,steps=4000)\n\n#turn array into a single list\ny_pred = np.hstack(y_pred).tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#get a count of class predictions\nhas_cactus = [0 if proba<0.50 else 1 for proba in y_pred]\nprint(Counter(has_cactus).keys()) # equals to list(set(words))\nprint(Counter(has_cactus).values())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 8) Create Submission df"},{"metadata":{"trusted":true},"cell_type":"code","source":"#get the name of the files in the directory\nfiles=[]\nfiles = [f for f in sorted(os.listdir('..//input//test//test'))]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({'id':files,\n                          'has_cactus':y_pred})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}