{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"# Simple CNN using keras\n\nCreate an algorithm that can identify a specific type of cactus in aerial imagery.  \nSubmissions are evaluated on area under the ROC curve between the predicted probability and the observed target.  \n\n**Contents:**\n\n1. View and load image data\n- Build and train CNN model\n- View model performance\n- Create perdictions on test data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"code","source":"# Import modules\n\nimport os\nimport zipfile\nimport random\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport numpy as np # linear algebra\nimport matplotlib.pyplot as plt\nimport cv2\nfrom tensorflow import keras\n\n# from keras.applications.vgg16 import VGG16\n\nfrom tensorflow.keras.layers import Conv2D, Dense, Flatten, Dropout, Activation\nfrom tensorflow.keras.layers import BatchNormalization, Reshape, MaxPooling2D, GlobalAveragePooling2D\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n\nprint(os.listdir(\"../input/aerial-cactus-identification/\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load labelled image data into generators"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract images from zip files\n# (Not sure why I have to do this as everywhere seems to say that zip archives are automatically extracted... but oh well)\n\n# Need to extract them to /kaggle/temp/ directory (instead of /kaggle/working/)\n# Otherwise won't let me submit submission.csv file, instead generates output visulations of the images\n\nwith zipfile.ZipFile(\"../input/aerial-cactus-identification/train.zip\",\"r\") as z:\n    z.extractall(\"/kaggle/temp/\")\nwith zipfile.ZipFile(\"../input/aerial-cactus-identification/test.zip\",\"r\") as z:\n    z.extractall(\"/kaggle/temp/test/\") # needs to be in subdirectory (i.e. test/test/) for flow_from_directory to work\n\n# for dirname, _, filenames in os.walk(\"./train\"):\n#     for filename in filenames[:5]:\n#         print(os.path.join(dirname, filename))\n\nprint(len(os.listdir(\"../temp/train\")))\nprint(len(os.listdir(\"../temp/test/test\")))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set directories\n\ntrain_dir = \"../temp/train\"\ntest_dir = \"../temp/test\"\nlabels = pd.read_csv('../input/aerial-cactus-identification/train.csv')\n\nlabels.has_cactus = labels.has_cactus.astype(str) # Classes must be str and not int\nprint(labels['has_cactus'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display example image\n# Image(os.path.join(train_dir, labels.iloc[0,0]), width=250, height=250)\n\n# Plot random sample of training images\n\nrand_images = random.sample(os.listdir(train_dir), 16)\n\nfig = plt.figure(figsize=(16,4))\nfor i, im in enumerate(rand_images):\n    plt.subplot(2, 8, i+1)\n    im = cv2.imread(os.path.join(train_dir, im))\n    plt.imshow(im)\n    plt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split training data into training and validation sets\n\n# Could use sklearn.model_selection.train_test_split instead\n\nvalidation_split = 0.8\nidxs = np.random.permutation(range(len(labels))) < validation_split*len(labels)\n\ntrain_labels = labels[idxs]\nval_labels = labels[~idxs]\nprint(len(train_labels), len(val_labels))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Process image JPEGs into tensors\n# Pixel values rescaled from [0,255] to [0,1]\n\n# Generate batches of tensor image data (with real-time data augmentation - horizontal and vertical flips)\ntrain_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1/255, horizontal_flip=True, vertical_flip=True)\n\nbatch_size = 128\n\ntrain_generator = train_datagen.flow_from_dataframe(train_labels,directory=train_dir,x_col='id',\n                                                    y_col='has_cactus',class_mode='binary',batch_size=batch_size,\n                                                    target_size=(32,32))\nval_generator = train_datagen.flow_from_dataframe(val_labels,directory=train_dir,x_col='id',\n                                                    y_col='has_cactus',class_mode='binary',batch_size=batch_size,\n                                                    target_size=(32,32))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Build and train CNN model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build CNN model\n\ninput_shape = (32, 32, 3)\n\nmodel = keras.models.Sequential()\n\nmodel.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=input_shape))\nmodel.add(MaxPooling2D((2, 2)))\n\nmodel.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\n\nmodel.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\n\nmodel.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.summary()\n\n# Alternative model (incl. batch normalization, dropout and global average pooling)\n\n# model = keras.models.Sequential()\n\n# model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=input_shape))\n# model.add(BatchNormalization())\n# model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=input_shape))\n# model.add(BatchNormalization())\n# model.add(MaxPooling2D())\n\n# model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n# model.add(BatchNormalization())\n# model.add(MaxPooling2D())\n\n# model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n# model.add(BatchNormalization())\n# model.add(MaxPooling2D())\n\n# model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n# model.add(BatchNormalization())\n# model.add(MaxPooling2D())\n\n# model.add(GlobalAveragePooling2D())\n\n# model.add(Dense(256))\n# model.add(Activation('relu'))\n# model.add(Dropout(0.5))\n\n# model.add(Dense(1))\n# model.add(Activation('sigmoid'))\n\n# model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define model loss, optimizer and metrics\n\nmodel.compile(loss = keras.losses.binary_crossentropy,\n              optimizer = 'adam',\n              metrics = ['acc'])\n\ncallbacks = [EarlyStopping(monitor='val_loss', patience=20, verbose=1, restore_best_weights=True), # Stop training when a monitored metric has stopped improving\n             ReduceLROnPlateau(patience=10, verbose=1), # Reduce learning rate when a metric has stopped improving\n#              ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', \n#                              verbose=0, save_best_only=True)\n            ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train / fit model\n\nepochs = 100\n\nhistory = model.fit(train_generator,\n                    epochs = epochs,\n                    verbose = 1,\n                    callbacks = callbacks,\n                    validation_data = val_generator,\n                    #class_weight = class_weights,\n                   )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load best model (best weights restored automatically)\n\n# Model with lowest validation loss is loaded (not necessarily the model with the best validation accuracy...)\n\nidx = np.argmax(history.history['val_acc'])\nprint(history.history['val_loss'][idx], history.history['val_acc'][idx])\n\nidx = np.argmin(history.history['val_loss'])\nprint(history.history['val_loss'][idx], history.history['val_acc'][idx])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plot model performance"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluate model performance\n\nplt.figure(figsize=(16,4))\n\nplt.subplot(1,2,1)\nplt.plot(history.history['acc'], label = 'training accuracy')\nplt.xlabel('# epochs')\nplt.ylabel('Accuracy')\n\nplt.plot(history.history['val_acc'], label = \"validation accuracy\")\nplt.title(\"Accuracy evolution\")\nplt.legend()\nplt.ylim(0.9,1.01)\n\nplt.subplot(1,2,2)\nplt.plot(history.history['loss'], label = 'training loss')\nplt.xlabel('# epochs')\nplt.ylabel('Loss - Binary Cross Entropy')\n\nplt.plot(history.history['val_loss'], label = \"validation loss\")\nplt.title(\"Loss evolution\")\nplt.legend()\nplt.ylim(-0.01,0.1)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Make submission file with prediction on test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use trained model to make predication on test data\n\ntest_datagen = keras.preprocessing.image.ImageDataGenerator(rescale = 1/255)\n\ntest_generator = test_datagen.flow_from_directory(\n    directory = test_dir,\n    target_size = (32, 32),\n    batch_size = 1,\n    class_mode = None,\n    shuffle = False)\n\nprobabilities = model.predict(test_generator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create submission file\n\nsample_submission = pd.read_csv('../input/aerial-cactus-identification/sample_submission.csv')\ndf = pd.DataFrame({'id': sample_submission['id']})\ndf['has_cactus'] = probabilities\ndf.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}