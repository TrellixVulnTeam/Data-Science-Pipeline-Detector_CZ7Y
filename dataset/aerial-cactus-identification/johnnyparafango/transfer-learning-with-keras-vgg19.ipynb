{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"collapsed":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport glob","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Data Exploration\n## 1.1 Load the data frame\nLoad the data frame with paths (*id*) and labels (*has_cactus*)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/aerial-cactus-identification/train.csv\")\ndf.has_cactus = df.has_cactus.astype(str) # Convert the column to string to be used by keras generator later on\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.2 Visualize the images"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_paths = glob.glob(\"../input/aerial-cactus-identification/train/train/*.jpg\")\nplt.figure(figsize=(18, 4))\n\nfor i in range(1, 15):\n    ax = plt.subplot(1, 15, i)\n    ax.imshow(plt.imread(all_paths[i]))\n    ax.grid(False)\n    ax.axis('off')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Transfer learning VGG-19\n## 2.1 Base model\nLet's take the base vgg-19 model from pre trained keras model without the last layer. Then set all the vgg19 layer to be non-trainable."},{"metadata":{"trusted":true},"cell_type":"code","source":"vgg = keras.applications.vgg19.VGG19(include_top=False, weights='imagenet', input_shape=(150, 150, 3))\n\nfor layer in vgg.layers:\n    layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.2 Finishing the model\nLet's add the three additional dense layer to the model to be trained, a dropout layer and finally a dense layer with only one neuron with the sigmoid as activation function.\nThe output of the last layer will be a number between 0 and 1."},{"metadata":{"trusted":true},"cell_type":"code","source":"x = vgg.output\nx = layers.Flatten()(x)\nx = layers.Dense(1024, activation='relu')(x)\nx = layers.Dense(1024, activation='relu')(x)\nx = layers.Dense(512, activation='relu')(x)\nx = layers.Dropout(0.5)(x)\noutputs = layers.Dense(1, activation='sigmoid')(x)\n\nmodel = keras.Model(inputs=vgg.inputs, outputs=outputs)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.3 Build the data pipeline\nWe use the keras image data generator to load the images into the model, using the pandas dataframe for the file paths and labels.\nThe dataset is composed of 175000 images. We use the first 15k images as train set and the last 2.5k as valid set."},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n\ntrain_generator = datagen.flow_from_dataframe(df[:15000], \n                                              x_col=\"id\", y_col=\"has_cactus\", \n                                              directory=\"../input/aerial-cactus-identification/train/train/\", \n                                              class_mode=\"binary\", \n                                              batch_size=128, target_size=(150, 150))\n\nvalid_generator = datagen.flow_from_dataframe(df[15000:], \n                                              x_col=\"id\", y_col=\"has_cactus\", \n                                              directory=\"../input/aerial-cactus-identification/train/train/\", \n                                              class_mode=\"binary\", \n                                              batch_size=128, target_size=(150, 150))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.4 Compile and train the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit_generator(train_generator, validation_data=valid_generator, epochs=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# 3. Submission\n## 3.1 Make predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_generator = datagen.flow_from_directory(\"../input/aerial-cactus-identification/test\", classes=None, target_size=(150, 150))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_and_scale_img(path):\n    img = keras.preprocessing.image.load_img(path, target_size=(150, 150))\n    img = keras.preprocessing.image.img_to_array(img)\n    img /= 255.\n    return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_paths = glob.glob(\"../input/aerial-cactus-identification/test/test/*.jpg\")\nprint(\"Found %d images.\" % len(test_paths))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_set = [load_and_scale_img(path) for path in test_paths]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict([test_set])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df = pd.DataFrame(data={\n    \"id\": [path.split(\"/\")[-1] for path in test_paths], \n    \"has_cactus\": predictions[:, 0].astype(int)\n})\nsubmission_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df.to_csv('sample_submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}