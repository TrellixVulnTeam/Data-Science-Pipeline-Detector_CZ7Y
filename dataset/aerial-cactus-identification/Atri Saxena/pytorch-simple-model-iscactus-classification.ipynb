{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from __future__ import print_function, division\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.autograd import Variable\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, utils, models\nimport torch.nn.functional as F\nfrom tqdm import tqdm, tqdm_notebook\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport time\nimport os\n\nplt.ion()   # interactive mode\nmultiGPU = False\n\n%matplotlib inline","execution_count":23,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"TRAIN_IMG_PATH = \"../input/train/train/\"\nTEST_IMG_PATH = \"../input/test/test/\"\nLABELS_CSV_PATH = \"../input/train.csv\"\nSAMPLE_SUB_PATH = \"../input/sample_submission.csv\"","execution_count":24,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preparing Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"class CactusDataset(Dataset):\n    \"\"\"Cactus identification dataset.\"\"\"\n\n    def __init__(self, img_dir, dataframe, transform=None):\n        \"\"\"\n        Args:\n            img_dir (string): Directory with all the images.        \n            dataframe (pandas.core.frame.DataFrame): Pandas dataframe obtained\n                by read_csv().\n            transform (callable, optional): Optional transform to be applied\n                on a sample.\n        \"\"\"\n        self.labels_frame = dataframe\n        self.img_dir = img_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.labels_frame)\n\n    def __getitem__(self, idx):\n        img_name = os.path.join(self.img_dir, self.labels_frame.id[idx]) \n        image = Image.open(img_name)\n        label = self.labels_frame.has_cactus[idx]\n\n        if self.transform:\n            image = self.transform(image)\n\n        return [image, label] \n","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dframe = pd.read_csv(LABELS_CSV_PATH)\ncut = int(len(dframe)*0.95)\ntrain, test = np.split(dframe, [cut], axis=0)\ntest = test.reset_index(drop=True)\n\ntrain_ds = CactusDataset(TRAIN_IMG_PATH, train)\ntest_ds = CactusDataset(TRAIN_IMG_PATH, test)\nidx = 1\nplt.imshow(train_ds[idx][0])\nprint(train_ds[idx][1])\nprint(\"Shape of the image is: \", train_ds[idx][0].size)\n","execution_count":26,"outputs":[{"output_type":"stream","text":"1\nShape of the image is:  (32, 32)\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAHgVJREFUeJztnXtwndWV5dfW+23Jlh/y2xjzagPGKAQIkyLpSjdNUoFUUemkptJ0mmk6U0lqqOr5g2K6Jpmq+SM9NQmVzEyl4zRUQ1c6JJ2QiSeT9DhNGkh6gGCIsY2NjTH4KUu25Ics62FJe/6411NCOWvrWrKuTJ/1q6Iszrrnfkff/ba+e8+6e29zdwgh8qNirhcghJgbFPxCZIqCX4hMUfALkSkKfiEyRcEvRKYo+IXIFAW/EJmi4BciU6pmMtnM7gLwdQCVAP7a3b8SPb6hvt5bWuYltfHxcT6RfAvRzOiU8yPnqTYyMkK1mpraYBnpNdZU19A51dX8FI+PR9+uvLTfvORnaopzH5zjqsrg8iHzxkZHp7WOSIuug7q69OtZVcXXPjY2xrVRrlUFr3W0Rva7jQbniq3x9Nl+nBsajF7u/8+0g9/MKgH8DwAfAXAYwMtmttndd7E5LS3zcP8f/uukdu7cOXosdhJqquvonK6jR6l28MAhqq1atYqv43z6D8qyJR10TsfiJVQbGhqi2njwwldVBG/YyB+U6kp+PZw9e5Y/X/DHcH5rG9VYcPX19dE5Q8E1EF0f1ZWVVLv66quT4wsWLKBzTp8+TbVTp/j6Fy1aRLWaGn6DGBwcTI6fOHGCzmFrfGzz9+icyczkbf8tAPa5+353HwHwFIB7ZvB8QogyMpPgXwZg4i30cHFMCPEeYNY3/MzsQTPbamZbBwf5WzchRHmZSfAfAbBiwv8vL469C3ff5O6d7t5ZX98wg8MJIS4lMwn+lwGsM7M1ZlYD4FMANl+aZQkhZptp7/a7+6iZfQHA/0HB6nvc3V+P5lRWVmLevLTVV11dTecxa66qku+gNjY2TkurreW727Vkxzayjapq+O/VEOzanz1zhmrniesAANXEfhsLrMPKYLfcA5MwcgmYQxPtpA+dS+96F47VT7W6YCf9DDmP8+fPp3Oi81tRwV/r5uZmqkXOTnd3d3L81KlTdA6z+i6mOM+MfH53/ymAn87kOYQQc4O+4SdEpij4hcgUBb8QmaLgFyJTFPxCZMqMdvsv+mCVlWhrS1t9Q0MXn9RRV8czvVpbW6kWZUtFNuB5YjnW19fTOXGG2PQy3KJ5PpaeVxHYioUcrTRDw8NUi5JtmOVUU8Wtz8pGvkYPsukiq5Jx/PhxqjF7EIgzQk+e5DbmyZMnqbZv377keGQhsySi6HX+rceW/EghxL8oFPxCZIqCX4hMUfALkSkKfiEypay7/cPDw3j77beTWldXF5137Nix5HhVBd85jnY9Bwf5DnZLSwvVmhvTiRtRAka0I15pfI3tQeJJtGM+0J9OgIkSPqKSYZFbEZ3jpqam5HgrqeEIxHXuTnT3UG1gYIBq5wbSyUKjI/x3rqjg64gSdI4GpeOiZCHmtlRX8ySzqpp0CbvoHE5Gd34hMkXBL0SmKPiFyBQFvxCZouAXIlMU/EJkSlmtvqGhQex6fUdSY11LAGBkOG3LtLXxjj2NxJYDgIoKXnsusnKYxWZN/FgRUZJIZNlEFhtz9KLKycNB8s6ZLm6xRYknFUjbV3U1PAkqykm5mNp0E+kn1mdlcLCODt6BqSlosRYlYy1bupxqixeluzqFCUZj3DosFd35hcgUBb8QmaLgFyJTFPxCZIqCX4hMUfALkSkzsvrM7B0A/QDGAIy6e2f0+IqKCtrSiLXxAoAa0o5paQe3T6LsvO5uXr9t7969VGMZblEWWFVV0AqL1NsDuEUFAANBCy0QKyqqcxdpUXutqHZhA9HirDOuVVbyTMaqKt6ui2X81dXy54tatrUF2ZaRNTed6/v8OM+oHDhxIjl+MY7opfD5P+Tu6ZUIIS5b9LZfiEyZafA7gC1m9oqZPXgpFiSEKA8zfdt/h7sfMbNFAH5uZm+4+/MTH1D8o/AgwD8HCiHKz4zu/O5+pPhvD4AfAbgl8ZhN7t7p7p2sv70QovxMO/jNrNHMmi/8DOD3AOy8VAsTQswuM3nbvxjAj4rWTRWAv3P3f4gm1NbWYvXqlUmtuppbL+5pCyiyZKJMtYEBbqNFmXaL2hcmxyM7LLLRWpq4HRkVfIwKeLbMSz9ntA5mNQHA6tWrqRbZkX19fcnx6FxFbdRqKi++dRUALFyYfs2ioquHj/BiskuXLqXa2bO8WOvIyBGqVdWmz39XV7pwLQD09vYmx6Pr5reOW/IjJ+Hu+wHcON35Qoi5RVafEJmi4BciUxT8QmSKgl+ITFHwC5EpZS3gWVFRQXu4RTD7LSog2dDCC1ZGjAZWyaqVq5PjQ0E/vu5jPIPQwbP6oh5/XssLlzLL1IKMudbWVr6OoK9hZCuNEKs1Kj4aZfxFtu78INOOXW9RQdCo516ULVpdx9fY0Ng4redk1Nalr4HIMp+M7vxCZIqCX4hMUfALkSkKfiEyRcEvRKaUdbd/fHyctuWKdnpZC62aGr7rHe0qN7fwndcoycWRrqkW7dZGu8oD/XxHv6aG79rWBLvKLKHp7FneoixK0Glr4zvp02kpdj5InFqwYMG0jhW5DiyRqKeHtyE7M8DP1bHjfF50Haxdu5ZqNcTJ6DnOnSL2O19MWzPd+YXIFAW/EJmi4BciUxT8QmSKgl+ITFHwC5EpZU/sYQka3d3ddB6zNSJrJUqMieq39fTwumnsOetruPW2cOHi4Pm4pVRfw8ucR8lR7FxFdlhU77Cmlq8jskXZGpnVCwB1JFkFKNjEjIEh/pysXdcbb/K2bFGiU1TjMei+FtYFJCUqMTLK23WNEUfvIrp16c4vRK4o+IXIFAW/EJmi4BciUxT8QmSKgl+ITJnS6jOzxwF8DECPu68vjs0H8D0AqwG8A+CT7n6yhOdCHbGwRoa4FcXqko2Ocm9lePgM1Vpb5lHt3nvvpdqrr76aHD9w4BCdE1lbrS1tVDt2jFuOkRU1hnTLq6gGXlQLcXSc200RzBJjGZpTrWNsjK+jMsjgZHZkO2njBcR18OYF596NX4/z2vg81krt1de20Tn0XAXZj5Mp5c7/NwDumjT2MIBn3H0dgGeK/y+EeA8xZfC7+/MAJnddvAfAE8WfnwDAb5dCiMuS6X7mX+zuF76ydAyFjr1CiPcQM97w80LpEPqtQjN70My2mtnWgeArt0KI8jLd4O82sw4AKP5Laxu5+yZ373T3zsaG6TXSEEJceqYb/JsB3F/8+X4AP740yxFClItSrL7vArgTQLuZHQbwJQBfAfB9M3sAwAEAnyzlYONj47RY5NKlS+m8xYvTWwqRbbRnzx6qDQ7wjx8PPfQQ1ZgNeOgQt/pO96ULSALA8CBf/ze+8d+p9uyzv6Ba27x0wc1Vq1bROVGx0+UrV1Ktvp5n/I2Np63bs+fSWXZAnIkZWX1Rduc8ot166610zpEu3q7rjb38urriiiuodt8f3ke1WpI52bF8GZ3TTwqyPv2P/5POmcyUwe/unybS75Z8FCHEZYe+4SdEpij4hcgUBb8QmaLgFyJTFPxCZEpZC3iOjo2it7c3qUXFG1mWVVsbz4qLrK3Imnv22Wepdu211ybH161bR+eMjfBsxf7TvIDnX/zFI1R74VcvUG3Xrl3J8a4uXkDyyJEjVOs7w7Mjly9fTjWWdVZZxbPOooQ0d54xxwpgRlpdA7cpo9cz6uO39TfprE8AePHFF6l2+x0fSI6vv+F36BzWg7CunsfRZHTnFyJTFPxCZIqCX4hMUfALkSkKfiEyRcEvRKaU1eqrqqzCggXpwolRv7goo4sRZarNn5/OfAOAn/3sf1Nt587tyfHIVrzphpuo1rFkCdVuuOEGqi0N5n2w54PJ8de28WKQO3bsoNo7h3iG2759+6jGilJG537BggVUO32S14c9N8jtt6rq9HUwbx4v4no+KFoarfHH/2sz1b7+375Btd7T6d6RV155JZ3TcAlqY+jOL0SmKPiFyBQFvxCZouAXIlMU/EJkSll3+x185z7a7Wc7xwMDvB7c+fM8oSZqd9XVxZNcnnvuueT46Gi6RRYAXLGK13X78Ic+RLWoxtyC+XzHmdXVqwvadd14441U+7u//wHV3ti9m2pHyXmMXueoXdcQaf8FxDX8mog2PMrX0deX3n0HgKPHeIJUR0cH1fbt30+1b33rW8nx22+/nc5Zu3ZtcnwgSDyajO78QmSKgl+ITFHwC5EpCn4hMkXBL0SmKPiFyJRS2nU9DuBjAHrcfX1x7MsA/hTA8eLDHnH3n071XO5ObbGRwMph9crGx7nFFtl5fX19VGtqaqIaS6Y4dYpbQztfTycDAcAbb7xBtSjx5Oorr6Yas73WrFlD50Tr/9znPke17dv57/byr3+dHD9w4ACdczJI3rGgwF97ezvVmH1YaC6d5ixphQXE12ljYyPVmoPXk7X52vPmXjpn9570tXOKxEqKUu78fwPgrsT4o+6+ofjflIEvhLi8mDL43f15APxWKYR4TzKTz/xfMLPtZva4mfEa2kKIy5LpBv83AawFsAFAF4Cvsgea2YNmttXMtg4ODk7zcEKIS820gt/du919zAudFL4N4JbgsZvcvdPdO6N+7kKI8jKt4DeziRkMnwCw89IsRwhRLkqx+r4L4E4A7WZ2GMCXANxpZhtQSNR7B8CflXIwg6NiPJ1tN7+F2yRtq9Jtoc6PcauvtjqdCQgAC4OsuChDjNlDLS3cVuzoWEa11mZ+rO8+9RTVIrupqaE5OR7Vg4u09Rs7qfbh3/8I1W75wG3J8aGhITqnP7DYurqOUe3RRx+lGsvujGo8rl3Dz8eNN2+k2qmz/VRrrOc19+rr09f+8lo+h1qm3MH8LaYMfnf/dGL4sdIPIYS4HNE3/ITIFAW/EJmi4BciUxT8QmSKgl+ITClrAU8zQy0pJBlZQCzba8zH6ZzoC0U11XVUGxji30Jka+zv5xbPsmXc6osKPtbU1FDt8OHDfF5V+vxGmYxbtmyh2t53DlKNFZEEgGuuuSY53hJkt0WtvNrb023eAOCzn/0s1XaTIqN79/KMuYOHD1Etslmj1+zIEV4Ydng4bUfedlvaLgWA5tb0eXzh9RfpnMnozi9Epij4hcgUBb8QmaLgFyJTFPxCZIqCX4hMKavVBwDj42l7Lir0MXw+ba/U1XHLrqqS2y4N9fzXjrK9WFZfdXU1nRMVpWxu4JmMV1/Ni3Sa8YzFY8fS2W9RUcqor+GuXbuotu+tt6i2h1hp69evp3M2buQZc9FrfcttvK/hoo4lyfGVK1fSOQcPciuV9Y0EgObmdEYlAOwPevX17duTHL/55pvpnEWLFiXHo36Hk9GdX4hMUfALkSkKfiEyRcEvRKYo+IXIlPLu9jvfMY922VmrpmqSxAJwVwEARoLaf2NjY1Rju+LRDjBrTwYAQ8TFAIChIa5FsISmgVH+e0WtsBqD9mVHjx6l2p496R3s3XvT4wDQfeI41RYs4HUX1627impLlqR3+6O2bCtW8dZm3V1dVIsSe66+Np3oVHjOtEPTE5yP6tr0saLrdzK68wuRKQp+ITJFwS9Epij4hcgUBb8QmaLgFyJTSmnXtQLAkwAWo9AMaJO7f93M5gP4HoDVKLTs+qS78ywWAGPjYzTBZHSUW3OVFenEmSiJIaq1Nh7U3IusEmYfRok9kYU5MsJtwG3btlFtYGCAaqwOXlTTMDpXkS1aU8+TbViNOVbDEQC2bX+NatF5PBfUf2QJPI2NPKlq/gLefi2qNTkS2LpRPb6DB9N1EqPakL29aRtwNHi9JlPKnX8UwJ+7+3UAbgXweTO7DsDDAJ5x93UAnin+vxDiPcKUwe/uXe7+avHnfgC7ASwDcA+AJ4oPewLAvbO1SCHEpeeiPvOb2WoANwF4CcBid7/wdadjKHwsEEK8Ryg5+M2sCcAPATzk7mcmal74zm7ye7tm9qCZbTWzrYPB5yUhRHkpKfjNrBqFwP+Ouz9dHO42s46i3gGgJzXX3Te5e6e7d9YH1ViEEOVlyuC3QtbHYwB2u/vXJkibAdxf/Pl+AD++9MsTQswWpWT1fQDAZwDsMLML/tMjAL4C4Ptm9gCAAwA+OeUzOTA2ls7qGyfZfgDPmosy94aHh7k2ymvWNTQ0UC2yqRhRbcJI6ztxgmrTyYCsqeNrrx3i2rXrr6daV3c6Gw0ATpD1b9iwgc6Jzj1ruwUAz/3yl1RbunRpcvyqK6+kc6Isx6FBbotGFmxbkJXY1taWHN+3bx+d09OTfKN9UVl9Uwa/u/8KADsbv1vykYQQlxX6hp8QmaLgFyJTFPxCZIqCX4hMUfALkSllLeBZVV2F9oULk1qUwcSyzs6dO0fnDAxxGy2yciK7iXHmzBmq1dbybLp589KZb0DcnsqDYpwsqy86V6zYJgD8qz/4fard/9k/ohorQBrZV72neFLoLSRLEABefPFFqu0lbcOi35nZgwCwYukKqkVW3xCx5gCecdlOWnIBwDxiD9Y9X/oX6XTnFyJTFPxCZIqCX4hMUfALkSkKfiEyRcEvRKaU1eozq6CZcadOnaLzWNFP1jsPAEadZ/xF2XmRxrML6ZQwcy/q47d8+XKqjQzyoijMIoyKnUa24k9+8hOqRRYnK1h53fXr6ZzI7o3OI+v/CADXXpN+zqjPILveAODESZ5tWV/Dbd357TyrbzywbhnRtVMquvMLkSkKfiEyRcEvRKYo+IXIFAW/EJlS1t3+1tZ5+PjHP57Udu3aReexdkYHjxymc958802qRe2pWD01AKiqTjsBdUErrMqg3l60q3zyJE9yiRwJllwSJZ20tvL2VGfH+U705s2bqfbKK68kx6++7lo6Z8OGjVSL3I/bb7+dauw8nj7FnYq33nqLagcOHKDaSFCafvgkrynZUJe+fqIWa8zhMCv9fq47vxCZouAXIlMU/EJkioJfiExR8AuRKQp+ITJlSqvPzFYAeBKFFtwOYJO7f93MvgzgTwEcLz70EXf/afRcdbV1uOqqq5La4sW8w/f+/fuT44eOHqFzrgzaMb322g6q7drNa7stIjXV2tvb6ZzIOjzZ10e1qMYcq9MHAOeH0paSO69bGNUSHBnkdmTE9u3bk+MvvPACnXPt+pepduedd1Kts7OTauw1m9fC7c2WlhaqrV2zhmq/+MUvqHayl7/WfSd6k+NRWzZ2XY0F1uxkSvH5RwH8ubu/ambNAF4xs58XtUfd/b+WfDQhxGVDKb36ugB0FX/uN7PdAJbN9sKEELPLRX3mN7PVAG4C8FJx6Atmtt3MHjcz/v5WCHHZUXLwm1kTgB8CeMjdzwD4JoC1ADag8M7gq2Teg2a21cy2Hu9Nf7YRQpSfkoLfzKpRCPzvuPvTAODu3e4+5u7jAL4N4JbUXHff5O6d7t65MOhRLoQoL1MGvxXa2zwGYLe7f23CeMeEh30CwM5LvzwhxGxRym7/BwB8BsAOM9tWHHsEwKfNbAMK9t87AP5sqicaHRtFH7G3Irtp48Z0ttf6G2+gc3p7eVbckiW8HdMTTz5JtZ0703/fVq5cSecsW8b3RqtITUAgrk84Mszrt/WfSVtzUYuyKKtvOMhUW7t2LdVuvvnm5HhUq7E3+Fi45Wf/QDXWkgsAbr311uT49df9Dp2zdMkSqi3r6KDaiZ7jVDtyhNvSB/anMwWjOoPnWF3LIGN1MqXs9v8KQOrKCT19IcTljb7hJ0SmKPiFyBQFvxCZouAXIlMU/EJkikWtji41rc3NfseGtAXU09ND5218Xzpr62MfSxcDBYCFCxdSrSWwFaurq6k2NpbOmHr66afpnG3btlGtsbGRauOj/HWJbFFm240GFlBkQx07zbPRonO8YsWK5HhkK9Y3NFDt7NlzVIssQmZxDg/zgppj53lm3Pve9z6q3XfffVSrr+FFV1kh1+h3PvhO2h78k8//CXbv3c193Qnozi9Epij4hcgUBb8QmaLgFyJTFPxCZIqCX4hMKWuvvkWLFuGLX/xiUtuyZQudV0lskv7+fjonyoo7E8y74QaeKchso49+9KN0zrp166j29ttvU+2ff/l/qVZXV0c19nsfjHrMBTZgbRW3PkeH+bzx8+nMw5qaGjonynJsqOdW2fmmZqoxK3vJIl4wtjcotvnqy1v5sUa5RcgK1wLAqhXprNDICl61alVyPDq/k9GdX4hMUfALkSkKfiEyRcEvRKYo+IXIFAW/EJlSVquvqqoaCxemLZY/fuDf0Hksi218fJzOOXToENUOB1lsx4/zIoxrSJ+266+/ns6J+vitXLmaaid7p1foktEcZAJ2d3VR7dwgzyyLLEKWvbd0KS+eWpksFVmAWYdTraOqKn2JjwzywqQrg6KrvXX1VNv26m+oNjjAz+NAfzqrbzHpMwhwC7kysEsnozu/EJmi4BciUxT8QmSKgl+ITFHwC5EpU+72m1kdgOcB1BYf/wN3/5KZrQHwFIAFAF4B8Bl3D3sF9fb24knSDqu2ge+isgSHigr+t4vVRQOA/kCLkm1YckZbG+9Ovnr1FVSL2l3dfffdVNu+fTvVBgcHk+Pz58+nc5qC2nnP/fOvqLYo2I1mu9uRC9MRtMKKav/1nxmgWh9J0okSvw4ePEi1xcStAniyDQD0dHdTbd+bbybHo1ZvXcShOXuWJ61NppQ7/zCAD7v7jSi0477LzG4F8JcAHnX3KwGcBPBAyUcVQsw5Uwa/F7hwq6wu/ucAPgzgB8XxJwDcOysrFELMCiV95jezymKH3h4APwfwFoBT7n7hmxeHAfD3KEKIy46Sgt/dx9x9A4DlAG4BcE2pBzCzB81sq5ltHQzaPQshystF7fa7+ykA/wTgNgCtZnZhw3A5gOR3Zt19k7t3untnfVCBRghRXqYMfjNbaGatxZ/rAXwEwG4U/ghcaFFyP4Afz9YihRCXnlISezoAPGFmlSj8sfi+u//EzHYBeMrM/jOA3wB4bKonGh0dRV9f2no5/PpROo/ZMqymHgDU1XPrcOPGjVSLLMLNmzcnx2treX25m2/m7Z3e//7383mkRRkQt8nas2dPcrw7sJp+88orVDPjbcNaWlqo1tTUlB5v4HXpovN47hxPjDnWza+dgbNp6zOy0doXLKDayT6ecNXczGsJVgTXKnttXt++g845czK9juj6ncyUwe/u2wHclBjfj8LnfyHEexB9w0+ITFHwC5EpCn4hMkXBL0SmKPiFyBRj7Yxm5WBmxwFc6BvVDuBE2Q7O0Trejdbxbt5r61jl7twLnkBZg/9dBzbb6u7czNY6tA6tY1bXobf9QmSKgl+ITJnL4N80h8eeiNbxbrSOd/Mvdh1z9plfCDG36G2/EJkyJ8FvZneZ2R4z22dmD8/FGorreMfMdpjZNjPbWsbjPm5mPWa2c8LYfDP7uZm9WfyXVwWd3XV82cyOFM/JNjPjlUQv3TpWmNk/mdkuM3vdzP5dcbys5yRYR1nPiZnVmdmvzey14jr+U3F8jZm9VIyb75lZzYwO5O5l/Q9AJQplwK4AUAPgNQDXlXsdxbW8A6B9Do77QQAbAeycMPZfADxc/PlhAH85R+v4MoB/X+bz0QFgY/HnZgB7AVxX7nMSrKOs5wSAAWgq/lwN4CUAtwL4PoBPFcf/CsC/nclx5uLOfwuAfe6+3wulvp8CcM8crGPOcPfnAUwubHAPCoVQgTIVRCXrKDvu3uXurxZ/7kehWMwylPmcBOsoK15g1ovmzkXwLwMwsXj7XBb/dABbzOwVM3twjtZwgcXufqEY+zEAvED87PMFM9te/Fgw6x8/JmJmq1GoH/ES5vCcTFoHUOZzUo6iublv+N3h7hsB/AGAz5vZB+d6QUDhLz8Kf5jmgm8CWItCj4YuAF8t14HNrAnADwE85O5nJmrlPCeJdZT9nPgMiuaWylwE/xEAKyb8Py3+Odu4+5Hivz0AfoS5rUzUbWYdAFD8t2cuFuHu3cULbxzAt1Gmc2Jm1SgE3Hfc/enicNnPSWodc3VOise+6KK5pTIXwf8ygHXFncsaAJ8CkC6ON4uYWaOZNV/4GcDvAdgZz5pVNqNQCBWYw4KoF4KtyCdQhnNihWKMjwHY7e5fmyCV9ZywdZT7nJStaG65djAn7WbejcJO6lsA/sMcreEKFJyG1wC8Xs51APguCm8fz6Pw2e0BFHoePgPgTQD/CGD+HK3jbwHsALAdheDrKMM67kDhLf12ANuK/91d7nMSrKOs5wTADSgUxd2Owh+a/zjhmv01gH0A/h5A7UyOo2/4CZEpuW/4CZEtCn4hMkXBL0SmKPiFyBQFvxCZouAXIlMU/EJkioJfiEz5f4jvk2XM4MpRAAAAAElFTkSuQmCC\n"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_transform = transforms.Compose([\n        transforms.RandomResizedCrop(32),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomRotation(10),\n        transforms.ToTensor(),\n    ])","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ds = CactusDataset(TRAIN_IMG_PATH, train, data_transform)\ntest_ds = CactusDataset(TRAIN_IMG_PATH, test, data_transform)\ndatasets = {\"train\": train_ds, \"val\": test_ds}\n\nidx = 29\nprint(train_ds[idx][1])\nprint(\"Shape of the image is: \", train_ds[idx][0].shape)","execution_count":28,"outputs":[{"output_type":"stream","text":"1\nShape of the image is:  torch.Size([3, 32, 32])\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainloader = DataLoader(train_ds, batch_size=32,\n                        shuffle=True, num_workers=0)\n\ntestloader = DataLoader(test_ds, batch_size=4,\n                        shuffle=True, num_workers=0)\n\ndataloaders = {\"train\": trainloader, \"val\": testloader}","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epochs = 25\nnum_classes = 2\nbatch_size = 128\nlearning_rate = 0.002\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\ndevice","execution_count":30,"outputs":[{"output_type":"execute_result","execution_count":30,"data":{"text/plain":"device(type='cuda', index=0)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n\n    best_model_wts = model.state_dict()\n    best_acc = 0.0\n\n    for epoch in tqdm_notebook(range(num_epochs)):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n        \n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:     \n            since_epoch = time.time()\n            if phase == 'train':\n                scheduler.step()\n                model.train(True)  # Set model to training mode\n            else:\n                model.train(False)  # Set model to evaluate mode\n    \n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for data in tqdm_notebook(dataloaders[phase]):\n                # get the inputs\n                inputs, labels = data\n\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n                # zero the parameter gradients\n                optimizer.zero_grad()\n                \n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n                    \n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n                    \n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss / len(datasets[phase])\n            epoch_acc = running_corrects.double() / len(datasets[phase])\n\n            time_elapsed_epoch = time.time() - since_epoch\n            print('{} Loss: {:.4f} Acc: {:.4f} in {:.0f}m {:.0f}s'.format(\n                phase, epoch_loss, epoch_acc, time_elapsed_epoch // 60, time_elapsed_epoch % 60))\n            \n            # deep copy the model\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = model.state_dict()\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    return model","execution_count":31,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CactiCNN(nn.Module):\n    def __init__(self):\n        # ancestor constructor call\n        super(CactiCNN, self).__init__()\n        \n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=2)\n        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=2)\n        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=2)\n        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=2)\n        self.conv5 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=2)\n        self.conv6 = nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, padding=2)\n        self.bn1 = nn.BatchNorm2d(32)\n        self.bn2 = nn.BatchNorm2d(64)\n        self.bn3 = nn.BatchNorm2d(128)\n        self.bn4 = nn.BatchNorm2d(256)\n        self.bn5 = nn.BatchNorm2d(512)\n        self.bn6 = nn.BatchNorm2d(1024)\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=1)\n        self.avg = nn.AvgPool2d(4)\n        self.fc = nn.Linear(1024 * 9 * 9, 2) # !!!\n   \n    def forward(self, x):\n        x = self.pool(F.leaky_relu(self.bn1(self.conv1(x)))) # first convolutional layer then batchnorm, then activation then pooling layer.\n        x = self.pool(F.leaky_relu(self.bn2(self.conv2(x))))\n        x = self.pool(F.leaky_relu(self.bn3(self.conv3(x))))\n        x = self.pool(F.leaky_relu(self.bn4(self.conv4(x))))\n        x = self.pool(F.leaky_relu(self.bn5(self.conv5(x))))\n        x = self.pool(F.relu(self.bn6(self.conv6(x))))\n        x = self.avg(x)\n        #print(x.shape) # lifehack to find out the correct dimension for the Linear Layer\n        x = x.view(-1, 1024 * 9 * 9) # !!!\n        x = self.fc(x)\n        return x","execution_count":52,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = CactiCNN().to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)","execution_count":53,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_ft = train_model(model, criterion, optimizer, exp_lr_scheduler,\n                           num_epochs=num_epochs)","execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, max=25), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6fcb1ff828540489886270fd67004aa"}},"metadata":{}},{"output_type":"stream","text":"Epoch 0/24\n----------\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, max=520), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d919b877970402b8134185ac5730d29"}},"metadata":{}},{"output_type":"stream","text":"train Loss: 0.4310 Acc: 0.8795 in 2m 21s\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, max=219), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65596ab113284bf2a08ef5ca079a8829"}},"metadata":{}},{"output_type":"stream","text":"val Loss: 0.8200 Acc: 0.5783 in 0m 3s\n\nEpoch 1/24\n----------\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, max=520), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"761ba0250bf34cb6af8d881a9b12b827"}},"metadata":{}},{"output_type":"stream","text":"train Loss: 0.2107 Acc: 0.9146 in 2m 19s\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, max=219), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9ffc1e8dbbd473a99d4eec46a8b1c04"}},"metadata":{}},{"output_type":"stream","text":"val Loss: 0.2517 Acc: 0.8891 in 0m 3s\n\nEpoch 2/24\n----------\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, max=520), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4aef231ccf694a4388b82105476a696e"}},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df = pd.read_csv(SAMPLE_SUB_PATH)\noutput_df = pd.DataFrame(index=submission_df.index, columns=submission_df.keys() )\noutput_df['id'] = submission_df['id']\nsubmission_df['target'] =  [0] * len(submission_df)\n\ntdata_transform = transforms.Compose([\n        transforms.CenterCrop(32),\n        transforms.ToTensor(),\n])\n\nsubmission_ds = CactusDataset(TEST_IMG_PATH, submission_df, tdata_transform)\n\nsub_loader = DataLoader(submission_ds, batch_size=1,\n                        shuffle=False, num_workers=0)\n\n\ndef test_sumission(model):\n    since = time.time()\n    sub_outputs = []\n    model.train(False)  # Set model to evaluate mode\n    # Iterate over data.\n    prediction = []\n    for data in sub_loader:\n        # get the inputs\n        inputs, labels = data\n\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        # forward\n        outputs = model(inputs)\n        _, pred = torch.max(outputs.data, 1)\n        prediction.append(int(pred))\n      \n    time_elapsed = time.time() - since\n    print('Run complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed // 60, time_elapsed % 60))\n\n    return prediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv('../input/sample_submission.csv')\nsub['has_cactus'] = test_sumission(model_ft)\nsub.to_csv('submission1.csv', index= False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}