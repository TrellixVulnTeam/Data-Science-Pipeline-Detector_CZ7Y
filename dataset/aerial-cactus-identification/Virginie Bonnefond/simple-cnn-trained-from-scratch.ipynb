{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport pylab as plt\n%matplotlib inline\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\nfrom tqdm import tqdm\nimport random\nrandom.seed(0)\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import InputLayer, Input\nfrom tensorflow.keras.layers import Conv2D, Dense, Flatten, Dropout, Activation\nfrom tensorflow.keras.layers import BatchNormalization, Reshape, MaxPooling2D, GlobalAveragePooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Parameters"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"batch_size = 64\ntarget_size = (32, 32)\nclass_mode = 'binary'\nepochs = 100\ninput_shape = (32,32,3)\nnum_classes = 2\ndata_dir =  \"../input/train/train/\"\nvalidation_split = 0.8\ncolor_mode='rgb'\nx_col = 'id'\ny_col='has_cactus'\ndropout_dense_layer = 0.5","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Split training and validation into 80/20%"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/train.csv')\ndf.has_cactus = df.has_cactus.astype(str) # Classes must be str and not int\nmsk = np.random.rand(len(df)) < validation_split\ntrain = df[msk]\nvalidation = df[~msk]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Minimal Data Augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale=1/255, horizontal_flip=True, vertical_flip=True)\ntrain_generator = train_datagen.flow_from_dataframe(train, directory=data_dir, x_col=x_col, y_col=y_col, target_size=target_size, color_mode=color_mode, class_mode=class_mode, batch_size=batch_size, shuffle=True)\nvalidation_generator = train_datagen.flow_from_dataframe(validation, directory=data_dir, x_col=x_col, y_col=y_col, target_size=target_size, color_mode=color_mode, class_mode=class_mode, batch_size=batch_size, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fight Classes Imbalance"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils import class_weight\nclass_weights = class_weight.compute_class_weight('balanced', np.unique(train_generator.classes), train_generator.classes)\nclass_weights","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Design CNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=input_shape))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=input_shape))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D())\n\nmodel.add(Conv2D(64, (3, 3),padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D())\n\nmodel.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D())\n\nmodel.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D())\n\nmodel.add(GlobalAveragePooling2D())\n\nmodel.add(Dense(256))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(dropout_dense_layer))\n\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))\n\nmodel.compile(loss=keras.losses.binary_crossentropy,\n              optimizer='adam',\n              metrics=['accuracy'])\n\nmodel.summary()\n\ncallbacks = [EarlyStopping(monitor='val_loss', patience=20),\n             ReduceLROnPlateau(patience=10, verbose=1),\n             ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', verbose=0, save_best_only=True)]\n\nhistory = model.fit_generator(train_generator,\n          validation_data=validation_generator,\n          epochs=epochs,\n          verbose=1,\n          shuffle=True,\n          callbacks=callbacks,\n          class_weight=class_weights)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Plot Training Performances"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,5))\n\nplt.subplot(141)\nplt.plot(history.history['loss'], label='training')\nplt.plot(history.history['val_loss'], label='validation')\nplt.xlabel('# Epochs')\nplt.legend()\nplt.ylabel(\"Loss - Binary Cross Entropy\")\nplt.title('Loss Evolution')\n\nplt.subplot(142)\nplt.plot(history.history['loss'], label='training')\nplt.plot(history.history['val_loss'], label='validation')\nplt.ylim(0,0.1)\nplt.xlabel('# Epochs')\nplt.legend()\nplt.ylabel(\"Loss - Binary Cross Entropy\")\nplt.title('Zoom Near Zero - Loss Evolution')\n\nplt.subplot(143)\nplt.plot(history.history['acc'], label='training')\nplt.plot(history.history['val_acc'], label='validation')\nplt.xlabel('# Epochs')\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.title('Accuracy Evolution')\n\nplt.subplot(144)\nplt.plot(history.history['acc'], label='training')\nplt.plot(history.history['val_acc'], label='validation')\nplt.ylim(0.98,1)\nplt.xlabel('# Epochs')\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.title('Zoom Near One - Accuracy Evolution')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load best model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights(\"best_model.h5\")\n\nhistory.history['val_acc'][np.argmin(history.history['val_loss'])]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Classify images in test folder"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_folder = \"../input/test/\"\ntest_datagen = ImageDataGenerator(\n    rescale=1. / 255)\n\ntest_generator = test_datagen.flow_from_directory(\n    directory=test_folder,\n    target_size=target_size,\n    batch_size=1,\n    class_mode=None,\n    shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prepare Submission File"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission = pd.read_csv('../input/sample_submission.csv')\nfilenames = [path.split('/')[-1] for path in test_generator.filenames]\nprobabilities = list(model.predict_generator(test_generator)[:,0])\n\nsample_submission.id = filenames\nsample_submission.has_cactus = probabilities\n\nsample_submission.to_csv('sample_submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}