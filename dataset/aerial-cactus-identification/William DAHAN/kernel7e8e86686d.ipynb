{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's import the train dataset :"},{"metadata":{"trusted":false},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/aerial-cactus-identification/train.csv', dtype=str)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It's made of the name of each picture, we therefore need to extract the image from the .zip file :"},{"metadata":{"trusted":false},"cell_type":"code","source":"import zipfile\n\nwith zipfile.ZipFile('/kaggle/input/aerial-cactus-identification/train.zip','r') as file:\n    file.extractall('/kaggle/output/kaggle/working/train')\n\nwith zipfile.ZipFile('/kaggle/input/aerial-cactus-identification/test.zip','r') as file:\n    file.extractall('/kaggle/output/kaggle/working/test')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We need to check whether the dataset is imbalanced or not :"},{"metadata":{"trusted":false},"cell_type":"code","source":"print(\"Proportion of picture with cactus : {} % \".format(100 * round(sum(train[\"has_cactus\"].astype('int'))/train.shape[0], 4)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is imbalanced, but not that much, so we will not try to rebalanced it."},{"metadata":{"trusted":false},"cell_type":"code","source":"train_path = \"/kaggle/output/kaggle/working/train/train\"\ntest_path = '/kaggle/output/kaggle/working/test/'\nlabel_path = '/kaggle/input/aerial-cactus-identification/train.csv'\nsubmission_path = \"/kaggle/input/aerial-cactus-identification/sample_submission.csv\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's look at the image of cactus we have : "},{"metadata":{"trusted":false},"cell_type":"code","source":"import cv2\nfrom IPython.display import Image\n\nImage(os.path.join(train_path,train[\"id\"][0]),width=100,height=100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"According to the dataset, the is some cactus in the picture, but it is obvious. We hope a neural network will perform better than us !"},{"metadata":{"trusted":false},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We don't have that much picture to train the neural network on, so we will use the *ImageDataGenerator* function from *keras* in order to get more picture by turning/zooming a bit the already existing pictures : "},{"metadata":{"trusted":false},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\ngenerator = ImageDataGenerator(rescale=1./255,\n                               zoom_range=0.1,\n                               rotation_range=15,\n                               horizontal_flip=True,\n                               vertical_flip=True,\n                               zca_whitening=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will now split with the train set into a training and validation set. We use the generator previously defined :"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_valid = train_test_split(train, test_size=0.2)\n\ntrain_generator = generator.flow_from_dataframe(dataframe=X_train,\n                                                directory=train_path,\n                                                x_col=\"id\", y_col=\"has_cactus\", class_mode='binary',\n                                                target_size=(32, 32),\n                                                batch_size=64)\n\n\nvalid_generator = generator.flow_from_dataframe(dataframe=X_valid,\n                                                       directory=train_path,\n                                                       x_col=\"id\", y_col=\"has_cactus\", class_mode='binary',\n                                                       target_size=(32, 32),\n                                                       batch_size=64)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model\n\nWe need to define the model. We tried a residual network and a conventionnal convolutionnal neural network. But after some test, it turns out that a separable convolutionnal neural network worked best for us."},{"metadata":{"trusted":false},"cell_type":"code","source":"model = keras.models.Sequential([\n    keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", kernel_initializer=\"glorot_normal\", input_shape=[32, 32, 3]),\n    keras.layers.BatchNormalization(),\n    keras.layers.Activation(\"relu\"),\n    keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", kernel_initializer=\"glorot_normal\"),\n    keras.layers.BatchNormalization(),\n    keras.layers.Activation(\"relu\"),\n    keras.layers.MaxPool2D(pool_size=2),\n    \n    keras.layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", kernel_initializer=\"glorot_normal\"),\n    keras.layers.BatchNormalization(),\n    keras.layers.Activation(\"relu\"),\n    keras.layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", kernel_initializer=\"glorot_normal\"),\n    keras.layers.BatchNormalization(),\n    keras.layers.Activation(\"relu\"),\n    keras.layers.MaxPool2D(pool_size=2),\n    \n    keras.layers.Conv2D(filters=128, kernel_size=3, padding=\"same\", kernel_initializer=\"glorot_normal\"),\n    keras.layers.BatchNormalization(),\n    keras.layers.Activation(\"relu\"),\n    keras.layers.Conv2D(filters=128, kernel_size=3, padding=\"same\", kernel_initializer=\"glorot_normal\"),\n    keras.layers.BatchNormalization(),\n    keras.layers.Activation(\"relu\"),\n    keras.layers.MaxPool2D(pool_size=2),\n    \n    keras.layers.Conv2D(filters=256, kernel_size=3, padding=\"same\", kernel_initializer=\"glorot_normal\"),\n    keras.layers.BatchNormalization(),\n    keras.layers.Activation(\"relu\"),\n    keras.layers.Conv2D(filters=256, kernel_size=3, padding=\"same\", kernel_initializer=\"glorot_normal\"),\n    keras.layers.BatchNormalization(),\n    keras.layers.Activation(\"relu\"),\n    keras.layers.MaxPool2D(pool_size=2),\n    \n    keras.layers.Flatten(),\n    keras.layers.Dense(256, kernel_initializer=\"glorot_normal\", activation=\"relu\"),\n    keras.layers.Dropout(rate=0.5),\n    keras.layers.Dense(256, kernel_initializer=\"glorot_normal\", activation=\"relu\"),\n    keras.layers.Dense(1, activation=\"sigmoid\")\n])\n\nmodel.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.RMSprop(learning_rate=0.001), metrics=[\"accuracy\"])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can now train the model, we also make sure we have the GPU on, otherwise the model training will take a long time."},{"metadata":{"trusted":false},"cell_type":"code","source":"history=model.fit_generator(train_generator, epochs=100, validation_data=valid_generator, validation_steps=20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If we look at the learning curves we have :"},{"metadata":{"trusted":false},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns; sns.set()\n\ndef plot_learning_curves(history):\n    pd.DataFrame(history.history).plot(figsize=(8, 5))\n    plt.grid(True)\n    plt.gca().set_ylim(0, 1)\n    plt.show()\n\nplot_learning_curves(history)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction\n\nWe are now going to predict the test dataset :"},{"metadata":{"trusted":false},"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/aerial-cactus-identification/sample_submission.csv', dtype=str)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can't use the same generator as we already have used since we don't want to zoom in or rotate the picture."},{"metadata":{"trusted":false},"cell_type":"code","source":"soft_generator = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n\ntest_generator = soft_generator.flow_from_directory(directory=test_path, target_size=(32, 32), batch_size=1, class_mode='binary', shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"y_pred_proba = model.predict_generator(test_generator)\n\ny_pred = [0 if value < 0.50 else 1 for value in y_pred_proba] \ny_pred = np.array(y_pred)\ny_pred.reshape(4000,1)\n\nsubmission = pd.DataFrame(data = {'id': test[\"id\"], 'has_cactus': y_pred.reshape(-1).tolist()})\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"nbformat":4,"nbformat_minor":4}