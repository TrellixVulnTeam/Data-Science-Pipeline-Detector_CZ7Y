{"cells":[{"metadata":{"_uuid":"633d370c95a67365fe0186007aa352d8d35e625c","trusted":true},"cell_type":"code","source":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.utils import to_categorical\nfrom keras.preprocessing import image\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import to_categorical\nfrom tqdm import tqdm\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import cohen_kappa_score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import confusion_matrix\nfrom keras.optimizers import SGD\nimport cv2\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers.core import Activation\n\n# from resnets_utils import *\n\nfrom keras.models import load_model\n\nfrom keras.utils import np_utils\n\nfrom keras import applications\n\nfrom keras import optimizers\nfrom keras.models import Sequential,Model,load_model\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D,GlobalAveragePooling2D\nfrom keras.callbacks import TensorBoard,ReduceLROnPlateau,ModelCheckpoint","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\n# print(os.listdir(\"../input/test/test/\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c13b706b9f4777d0e761c0b837d97b52b3e2eda7","trusted":true},"cell_type":"code","source":"path = \"../input/\"\ntrain=pd.read_csv(path+'train.csv')\ntest = pd.read_csv(path+'sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# As it is a multi-class classification problem (3 classes), we will one-hot encode the target variable.\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nlabelencoder = LabelEncoder()\ntrain['has_cactus_en'] = labelencoder.fit_transform(train['has_cactus'])\n\n\n\nprint(train['has_cactus'].value_counts())\nprint(train['has_cactus'].value_counts())\n\n\ny=train['has_cactus']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.has_cactus.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_images(path, df):\n    train_image = []\n    for i in tqdm(range(df.shape[0])):\n        try:\n#             print(df_image_path+df['id'][i])\n            img = cv2.imread((path+df['id'][i]))\n            img = cv2.resize(img, (64,64))\n\n#             img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\n            img = image.img_to_array(img)\n            img = img/255\n            train_image.append(img)\n        except OSError:\n            print(df['id'][i])\n    image_array = np.array(train_image)   \n    return image_array\n        \n            \ntrain_image_path = '../input/train/train/'\ntest_image_path  = '../input/test/test/'\n\nX = load_images(train_image_path,train)\ntest_images = load_images(test_image_path, test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_image = []\n# for i in tqdm(range(test.shape[0])):\n# # for i in range(0,1):\n# #     try:\n#     img = cv2.imread((image_path+test['image'][i]))\n#     img = cv2.resize(img, (200,120))\n# #     img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n#     img = image.img_to_array(img)\n#     img = img/255\n    \n#     test_image.append(img)\n# #     except OSError:\n# #         print(train['file_path'][i])\n# test_images = np.array(test_image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.countplot(train['has_cactus'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom sklearn.utils.class_weight import compute_class_weight\n\nclass_weights = compute_class_weight('balanced', np.unique(y), y)\nclass_weights","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalize the data\n# X = X / 255.0\n# test = test / 255.0\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e62a89ec37bbb3eea04e42d4f2ecf6d85677e72b","trusted":true},"cell_type":"code","source":"# Step 4: Creating a validation set from the training data.\n\nX_train, X_test, y_train, y_test_class = train_test_split(X, y, random_state=42, test_size=0.2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ny_train = pd.get_dummies(y_train)\ny_test = pd.get_dummies(y_test_class)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"05293ba202a5a59395b835839ed03704c7d2fea6","trusted":true},"cell_type":"code","source":"# Step 5: Define the model structure.\n\n# We will create a simple architecture with 2 convolutional layers, one dense hidden layer and an output layer.\n\nmodel = Sequential()\n# model.add(Conv2D(64, kernel_size=(3, 3), padding='same',activation='relu',input_shape=(200,200,3)))\n# model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n# model.add(MaxPooling2D(pool_size=(2, 2)))\n# model.add(Dropout(0.25))\n\nmodel.add(Conv2D(32, (3, 3), padding=\"same\",  activation='relu',input_shape=(64,64,3)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\nmodel.add(Dropout(0.25))\n\n# (CONV => RELU) * 2 => POOL\nmodel.add(Conv2D(64, (3, 3), padding=\"same\", activation='relu' ))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, (3, 3), padding=\"same\", activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n          \n          \n# (CONV => RELU) * 2 => POOL\nmodel.add(Conv2D(128, (3, 3), padding=\"same\", activation='relu' ))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(128, (3, 3), padding=\"same\", activation='relu' ))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\n          \nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.50))\n\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(2, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cb4cc569dd040f4a7ac446213b33a51edda9b8b7","trusted":true},"cell_type":"code","source":"# Next, we will compile the model weâ€™ve created.\nopt = SGD(lr=1e-3, momentum=0.9, decay=1e-3 / 25)\nmodel.compile(loss='binary_crossentropy',optimizer=opt,metrics=['accuracy'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data Augmentation\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n\ndatagen = ImageDataGenerator(\n        rotation_range=10,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        fill_mode='nearest')\n\ndatagen.fit(X_train)\nprint('augmentation')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0d57b134c8d46f27c41a9fb65a148111165cab12","trusted":true},"cell_type":"code","source":"# Step 6: Training the model.\n\n# In this step, we will train the model on the training set images and validate it using, you guessed it, the validation set.\nbatch_size = 200\n# results  = model.fit(X_train, y_train, epochs=3, validation_data=(X_test, y_test))\n\nresults  = model.fit_generator(datagen.flow(X_train, y_train, batch_size = batch_size), epochs=1, \n                              steps_per_epoch=X_train.shape[0] // batch_size, \n                              validation_data=(X_test, y_test),\n                             class_weight = class_weights)\nprint(' class weight')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(model.history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the loss and accuracy curves for training and validation \nfig, ax = plt.subplots(2,1)\nax[0].plot(results.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(results.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(results.history['acc'], color='b', label=\"Training accuracy\")\nax[1].plot(results.history['val_acc'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b6d2cd69327f5ba2c6d94ba9118cfd17f63b4320","trusted":true},"cell_type":"code","source":"# Step 7: Find Accuracy\nfinal_loss, final_acc = model.evaluate(X_test, y_test, verbose=0)\nprint(\"Final loss: {0:.4f}, final accuracy: {1:.4f}\".format(final_loss, final_acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Look at confusion matrix \nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes)) \n    plt.xticks(tick_marks, classes , rotation=45)\n    plt.yticks(tick_marks, classes)\n\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Predict the values from the validation dataset\nY_pred = model.predict_classes(X_test) \n\n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(y_test_class, Y_pred) \nconfusion_mtx\n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes = range(0,2)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_cnn_pred  = model.predict_classes(test_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model = applications.resnet50.ResNet50(weights= None, include_top=False, input_shape= (64,64,3))\n\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dropout(0.2)(x)\npredictions = Dense(2, activation= 'softmax')(x)\nmodel = Model(inputs = base_model.input, outputs = predictions)\nfrom keras.optimizers import SGD, Adam\n# sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\nadam = Adam(lr=0.0001)\nmodel.compile(optimizer= adam, loss='categorical_crossentropy', metrics=['accuracy'])\n\n# model.fit(X_train, Y_train, epochs = 100, batch_size = 64)\n\nmodel.fit_generator(datagen.flow(X_train, y_train, batch_size = batch_size), epochs=100, \n                              steps_per_epoch=X_train.shape[0] // batch_size, \n                              validation_data=(X_test, y_test),\n                             class_weight = class_weights)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predict the values from the validation dataset\nY_pred = model.predict(X_test) \ntype(Y_pred)\nY_pred = Y_pred.argmax(axis=-1)\n\n\n# # compute the confusion matrix\nconfusion_mtx = confusion_matrix(y_test_class, Y_pred) \nconfusion_mtx\n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes = range(0,2)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resnet_pred =  model.predict(test_images)\n# resnet_pred = resnet_pred.argmax(axis=-1)\n\n\n# final_predictions =  (base_cnn_pred + resnet_pred) / 2\n# final_predictions = np.where(final_predictions >= 0.5, 1, 0)\ntest['has_cactus'] = resnet_pred\n\ntest[['id','has_cactus']]\ntest.to_csv('output.csv',  index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}