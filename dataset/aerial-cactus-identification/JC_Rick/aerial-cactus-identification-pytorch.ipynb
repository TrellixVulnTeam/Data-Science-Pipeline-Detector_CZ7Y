{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport pandas as pd\nimport cv2\nfrom tqdm import tqdm\nimport torch \nimport torch.backends.cudnn as cudnn\nfrom torchvision import models\nfrom torchvision import transforms as tfs\nfrom torch.utils.data import Dataset, DataLoader\nimport time\nfrom torch.autograd import Variable\nfrom PIL import Image\n\n\ndf = pd.read_csv('../input/train.csv')    \ndf_test = pd.read_csv('../input/sample_submission.csv')\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"Load data!!!!!!!"},{"metadata":{"trusted":true,"_uuid":"8e01ae1d481c394fa85ac92d75bbf4f0697d5633"},"cell_type":"code","source":"def train_tf(x):\n    im_aug = tfs.Compose([\n        tfs.RandomHorizontalFlip(),\n        tfs.RandomCrop(32),\n        tfs.ToTensor()\n    ])\n    x = im_aug(x)\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"23cdd6ee5526e6d380ba15d662ee6b2175849eb1"},"cell_type":"code","source":"train_img = []\ntrain_label = []\nfor i in tqdm(df.values):\n    img = cv2.imread(os.path.join('../input', 'train/train', i[0]))\n#     img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    \n    tf_img = Image.fromarray(img.astype('uint8')).convert('RGB')\n    if int(i[1]) == 1:\n        tf_img1 = train_tf(tf_img)\n        train_img.append((tf_img1, i[1]))\n    else:\n        for j in range(3):\n            tf_img1 = train_tf(tf_img)\n            train_img.append((tf_img1, i[1]))\n    img= np.transpose(img.astype(np.float32), (2, 1, 0))\n    img = torch.from_numpy(img)\n    train_img.append((img, i[1]))\n\ntest_img = []\nfor i in tqdm(df_test.values):\n    img = cv2.imread(os.path.join('../input', 'test/test', i[0]))\n    img= np.transpose(img.astype(np.float32), (2, 1, 0))\n    img = torch.from_numpy(img)\n    test_img.append((img, i[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4bff57cf3b3dd931ce5fd7ccc812451be18f9639"},"cell_type":"code","source":"import random\nval_data = random.sample(train_img, int(0.1 * len(train_img)))\ntrain_data = list(set(train_img).difference(set(val_data)))\nprint(len(train_data), len(val_data), len(train_data)+len(val_data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8b839a1a4193e703f4ad5fabb4f13d63218e2a2c"},"cell_type":"code","source":"model = models.resnet101(pretrained = False)\nclass_nums = 2\n########修改最后一层输出\nchannel_in = model.fc.in_features\nmodel.fc = torch.nn.Linear(channel_in, class_nums)\noptimizer = torch.optim.SGD(model.parameters(), lr = 1e-5, momentum = 0.9)\nloss_func = torch.nn.CrossEntropyLoss()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"686708cd87178a9c4f8885f5fadc67aaec0cfcb5"},"cell_type":"code","source":"train_loader = DataLoader(dataset = train_data, batch_size = 256, shuffle = True)\nval_loader = DataLoader(dataset = val_data, batch_size = 256)\nmodel = torch.nn.DataParallel(model, device_ids=[0])\nmodel.cuda()\ncudnn.benchmark = True\nfor epoch in range(2000):\n    batch_size_start = time.time()\n    train_loss = 0.\n    train_acc = 0.\n    for trainData,trainLabel in train_loader:\n        trainData= Variable(trainData.cuda())\n        trainLabel = Variable(trainLabel.cuda())\n        optimizer.zero_grad()\n        out = model(trainData)\n        \n        pred = torch.max(out, 1)[1]\n        train_correct = (pred == trainLabel).sum()\n        train_acc += train_correct.item()\n        \n        \n        loss = loss_func(out, trainLabel)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()\n    \n    print('Epoch [%d/%d],Train Loss: %.4f,Acc: %.4f, need time %.4f'\n                      % (epoch + 1, 2000, train_loss / (len(train_data) / 256), train_acc / (len(train_data)/256), time.time() - batch_size_start))\n#     val_acc = 0.\n#     val_loss = 0.\n#     model.eval()\n#     for (valData,valLabels) in val_loader:\n# #         time_start = time.time()\n#         valData = Variable(valData.cuda())\n#         valLabels = Variable(valLabels.cuda())\n#         outputs = model(valData)\n#         val_loss += loss.item()\n#         predict = torch.max(outputs.data, 1)[1]\n#         correct = (predict == valLabels).sum()\n#         val_acc += correct.item()\n#     print('Epoch [%d/%d],Train Loss: %.4f,Train acc: %.4f, Val Loss: %.4f, Val acc: %.4f,  need time %.4f'\n#                       %(epoch + 1, 2000, train_loss / len(train_data) * 256,train_acc / len(train_data) / 256,val_loss / len(valData) / 256,val_acc / len(valData) / 256,  time.time() - batch_size_start))\n    if (epoch+1) % 400 == 0:\n        torch.save(model.state_dict(), str(epoch)+'v2.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"291c7aca267d67a02c277d1647441be1231fd0ae"},"cell_type":"code","source":"# torch.save(model.state_dict(), '799v2.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d30dad51d62c8ece5a2bd9575613dd57b3348e15"},"cell_type":"code","source":"class MakeSubmission:\n    def __init__(self, test_img: list, csv_path: str, model_path: str):\n        model.load_state_dict(torch.load(model_path))\n        model.eval()\n        r = []\n        self.test_img = test_img\n        test_loader = DataLoader(dataset=test_img, batch_size=1)\n        for i, (inputs, labels) in enumerate(test_loader):\n            inputs, labels = Variable(inputs), Variable(labels)\n            outputs = model(inputs)\n            _, preds = torch.max(outputs.data, 1)\n            r.append(int(preds))\n        self.csv_path = csv_path\n        self.df = pd.read_csv(self.csv_path)\n        submission = pd.DataFrame({'id': self.df['id'], 'has_cactus': r})\n        submission.to_csv(model_path + \"sample_submission.csv\", index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"31fe1f39a341dd029538b01270586c5e481e970d"},"cell_type":"code","source":"MakeSubmission(test_img,  \"../input/sample_submission.csv\", '399v2.pkl')\nMakeSubmission(test_img,  \"../input/sample_submission.csv\", '799v2.pkl')\nMakeSubmission(test_img,  \"../input/sample_submission.csv\", '1199v2.pkl')\nMakeSubmission(test_img,  \"../input/sample_submission.csv\", '1599v2.pkl')\nMakeSubmission(test_img,  \"../input/sample_submission.csv\", '1999v2.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e6a8215ad9bfd07925a9654169737f45d6e32734"},"cell_type":"code","source":"ls","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}