{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Aerial Cactus Identification\n**Create a classifier capable of predicting whether an images contains a cactus.**\n### Load libraries****"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2 \nimport os\n\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, Dense, Flatten, BatchNormalization, Dropout, LeakyReLU, Flatten,  MaxPool2D\nfrom keras.layers.pooling import GlobalAveragePooling2D\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\nfrom sklearn.metrics import confusion_matrix, roc_auc_score, classification_report\nfrom sklearn.model_selection import train_test_split\n\nfrom tqdm import tqdm, tqdm_notebook","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Load Data\n\nThis dataset contains a large number of 32 x 32 thumbnail images containing aerial photos of a columnar cactus (Neobuxbaumia tetetzo). Kaggle has resized the images from the original dataset to make them uniform in size. The file name of an image corresponds to its id.\n\n#### Files\n\n- train/ - the training set images\n- test/ - the test set images (you must predict the labels of these)\n- train.csv - the training set labels, indicates whether the image has a cactus (has_cactus = 1)\n- sample_submission.csv - a sample submission file in the correct format\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dir = '../input/train/train/'\ntest_dir = '../input/test/test/'","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_data = pd.read_csv('../input/train.csv')\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Total training images: '+str(len(train_data)))\nprint(train_data.has_cactus.value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have total 17500 training images, among which 13136 are cactus and 4364 are non-cactus images."},{"metadata":{},"cell_type":"markdown","source":"### Data Preparation\n**Map training images to labels in train.csv**"},{"metadata":{"trusted":true},"cell_type":"code","source":"features = []\nlabels = []\n\nimages = train_data['id'].values\n\nfor img_id in tqdm_notebook(images):\n    features.append(cv2.imread(train_dir+img_id))\n    labels.append(train_data[train_data['id'] == img_id]\n                  ['has_cactus'].values[0])\n    \nfeatures = np.asarray(features)\nfeatures = features.astype('float32')\nfeatures /= 255\nlabels = np.asarray(labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data augmentation\ndatagen = ImageDataGenerator(\n            featurewise_center=False, \n            samplewise_center= False,\n            featurewise_std_normalization=False,\n            samplewise_std_normalization=False,\n            zca_whitening=False,\n            rotation_range=10,  #randomly rotate image in 0 to 180 degree\n            zoom_range=0.1, #randomly zoom image\n            width_shift_range=0.1, #randomly shift images horizontally\n            height_shift_range=0.1, #randomly shift images vertically\n            horizontal_flip = False, #randomly flip images\n            vertical_flip = False #randomly flip images\n)\ndatagen.fit(features)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Splitting our train and validation dataset\n\nNow,after preprocessing is done with our data we will split our dataset to training and validation."},{"metadata":{"trusted":true},"cell_type":"code","source":"# split dataset\nX_train, X_val, y_train, y_val = train_test_split(features, labels, test_size =0.1, random_state=2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Build the CNN model\n**[(Conv2D->relu0*3 -> MaxPool2D ]*2 -> Flatten -> Dense -> Dropout -> Dense -> Out**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(32, kernel_size=3, activation='relu',\n                 input_shape=(32,32,3), padding='same'))\nmodel.add(Conv2D(32, kernel_size=3, activation='relu',\n                 padding='same'))\nmodel.add(Conv2D(32, kernel_size=3, activation='relu',\n                 padding='same'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(64, kernel_size=3, activation='relu',\n                 padding='same'))\nmodel.add(Conv2D(64, kernel_size=3, activation='relu',\n                 padding='same'))\nmodel.add(Conv2D(64, kernel_size=3, activation='relu',\n                 padding='same'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compiling the model\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#set a learning rate annealer\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)\nepochs = 25\nbatch_size = 86","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = model.fit_generator(datagen.flow(X_train, y_train,batch_size=batch_size), \n                          epochs=epochs, validation_data=(X_val, y_val), verbose=2,\n                          steps_per_epoch=X_train.shape[0] // batch_size, \n                          callbacks=[learning_rate_reduction])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(clf.history['loss'])\nplt.plot(clf.history['val_loss'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_features = []\ntest_images = []\n\nfor img_id in tqdm_notebook(os.listdir(test_dir)):\n    test_features.append(cv2.imread(test_dir+img_id))\n    test_images.append(img_id)\n    \ntest_features = np.asarray(test_features)\ntest_features = test_features.astype('float32')\ntest_features /= 255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('cactus_model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Running the model over the test images\n\ntest_predictions = model.predict(test_features)\nsubmissions = pd.DataFrame(test_predictions, columns=['has_cactus'])\nsubmissions['has_cactus'] = submissions['has_cactus'].apply(lambda x: 1 if x > 0.75 else 0)\nsubmissions['id'] = ''\ncols = submissions.columns.tolist()\ncols = cols[-1:] + cols[:-1]\nsubmissions=submissions[cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, img in enumerate(test_images):\n    submissions.set_value(i,'id',img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Saving the output file\n\nsubmissions.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}