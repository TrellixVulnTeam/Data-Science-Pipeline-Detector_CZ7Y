{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"<p style='text-align:center;font-size:20px'><b> Kaggle Competition </b></p>"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"<p style='text-align:center;font-size:35px;'><b> Aerial Cactus Identification </b></p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport os,cv2\nfrom tqdm import tqdm_notebook\nfrom IPython.display import Image\nfrom keras.preprocessing import image\nfrom keras import optimizers\nfrom keras.layers import Conv2D, BatchNormalization, Dense, MaxPooling2D, Dropout, Flatten, GlobalAveragePooling2D\nfrom keras.models import Sequential\nfrom keras.applications.imagenet_utils import preprocess_input\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom keras import regularizers\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.vgg16 import VGG16\nprint(os.listdir(\"../input\"))\n\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing train file with Img_ID & has_cactus column\ntrain = pd.read_csv('../input/train.csv')\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test=pd.read_csv('../input/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# printing some of the columns \ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# printing some info about the dataset\ntrain.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.has_cactus.value_counts().plot.bar()\nprint('{:.2f} of images have has_cactus label=0'.format((train.has_cactus.value_counts()[0]/train.shape[0])*100))\nprint('{:.2f} of images have has_cactus label=1'.format((train.has_cactus.value_counts()[1]/train.shape[0])*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# setting train & test directory paths for importing images\ntrain_dir=\"../input/train/train\"\ntest_dir=\"../input/test/test\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# using ImageDataGenerator, available in keras for preprocessing\ndatagen=ImageDataGenerator(rescale=1./255)\nbatch_size=150","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# converting the datatype has_cactus column to str \ntrain.has_cactus=train.has_cactus.astype(str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# splitting the train dataset into train(15000) and validation(2500)\ntrain_generator=datagen.flow_from_dataframe(dataframe=train[:15001],directory=train_dir,x_col='id',\n                                            y_col='has_cactus',class_mode='binary',batch_size=batch_size,\n                                            target_size=(32, 32))\n\n\nvalidation_generator=datagen.flow_from_dataframe(dataframe=train[15000:],directory=train_dir,x_col='id',\n                                                y_col='has_cactus',class_mode='binary',batch_size=50,\n                                                target_size=(32, 32))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\n# layer 1\nmodel.add(Conv2D(64, (3,3), padding='same', activation=\"relu\", input_shape=(32, 32, 3)))\nmodel.add(BatchNormalization())\n# layer 2\nmodel.add(Conv2D(64, (3,3), padding='same', activation=\"relu\"))\nmodel.add(BatchNormalization())\n# layer 3\nmodel.add(Conv2D(64, (3,3), padding='same', activation=\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Dropout(0.4))\n# layer 4\nmodel.add(Conv2D(128, (3,3), padding='same', activation=\"relu\"))\nmodel.add(BatchNormalization())\n# layer 5\nmodel.add(Conv2D(128, (3,3), padding='same', activation=\"relu\"))\nmodel.add(BatchNormalization())\n# layer 5\nmodel.add(Conv2D(128, (3,3), padding='same', activation=\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Dropout(0.4))\n# layer 6\nmodel.add(Conv2D(256, (3,3), padding='same', activation=\"relu\"))\nmodel.add(BatchNormalization())\n# layer 7\nmodel.add(Conv2D(256, (3,3), padding='same', activation=\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Dropout(0.4))\n# layer 8\nmodel.add(Conv2D(256, (3,3), padding='same', activation=\"relu\"))\nmodel.add(BatchNormalization())\n# layer 9\nmodel.add(Conv2D(256, (3,3), padding='same', activation=\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Dropout(0.4))\n\nmodel.add(GlobalAveragePooling2D())\nmodel.add(Dense(units=256, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(units=256, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(units=1, activation='sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='binary_crossentropy',optimizer=optimizers.Adam(lr=0.001),metrics=['acc'])\nepochs=10\nhistory=model.fit_generator(train_generator,steps_per_epoch=100,epochs=10,\n                            validation_data=validation_generator,validation_steps=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc=history.history['acc']  ##getting  accuracy of each epochs\nepochs_=range(0,epochs)    \nplt.plot(epochs_,acc,label='training accuracy')\nplt.xlabel('no of epochs')\nplt.ylabel('accuracy')\n\nacc_val=history.history['val_acc']  ##getting validation accuracy of each epochs\nplt.plot(epochs_,acc_val,label='validation accuracy')\nplt.title(\"no of epochs vs accuracy\")\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv(os.path.join('../input', \"sample_submission.csv\"))\nprint(test_df.head())\ntest_images = []\nimages = test_df['id'].values\n\nfor image_id in images:\n    test_images.append(cv2.imread(os.path.join(test_dir, image_id)))\n    \ntest_images = np.asarray(test_images)\ntest_images = test_images / 255.0\nprint(\"Number of Test set images: \" + str(len(test_images)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(test_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df['has_cactus'] = y_pred\ntest_df.to_csv('submission.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}