{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"./\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":10,"outputs":[{"output_type":"stream","text":"['__notebook_source__.ipynb', '.ipynb_checkpoints']\n","name":"stdout"}]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"class ImageDataGenerator_self(object):\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.images = []\n        self.labels = []\n\n    def flow_from_directory(self, directory, classes, batch_size=32):\n        # LabelEncode(classをint型に変換)するためのdict\n        classes = {v: i for i, v in enumerate(sorted(classes))}\n        while True:\n            # ディレクトリから画像のパスを取り出す\n            for path in pathlib.Path(directory).iterdir():\n                # 画像を読み込みRGBへの変換、Numpyへの変換を行い、配列(self.iamges)に格納\n                with Image.open(path) as f:\n                    self.images.append(np.asarray(f.convert('RGB'), dtype=np.float32))\n                # ファイル名からラベルを取り出し、配列(self.labels)に格納\n                _, y = path.stem.split('_')\n                self.labels.append(to_categorical(classes[y], len(classes)))\n\n                # ここまでを繰り返し行い、batch_sizeの数だけ配列(self.iamges, self.labels)に格納\n                # batch_sizeの数だけ格納されたら、戻り値として返し、配列(self.iamges, self.labels)を空にする\n                if len(self.images) == batch_size:\n                    inputs = np.asarray(self.images, dtype=np.float32)\n                    targets = np.asarray(self.labels, dtype=np.float32)\n                    self.reset()\n                    yield inputs, targets\n\n    def flow_from_dir2(self, data_dir, data_list, label_train, classes, batch_size=32):\n        label_train = pd.read_csv(label_csv,index_col=0)\n        while True:\n            for img_path in data_list:\n                img = cv2.imread(data_dir + \"/\" + img_path)\n                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)\n                #img = img.transpose((2, 0, 1))\n                #img = img.reshape((1,) + img.shape)\n                self.images.append(img)\n\n                # ファイル名からラベルを取り出し、配列(self.labels)に格納\n                #_, y = path.stem.split('_')\n                y = label_train.loc[img_path,\"has_cactus\"]\n\n                self.labels.append(keras.utils.to_categorical(classes[y], len(classes)))\n\n                # ここまでを繰り返し行い、batch_sizeの数だけ配列(self.iamges, self.labels)に格納\n                # batch_sizeの数だけ格納されたら、戻り値として返し、配列(self.iamges, self.labels)を空にする\n                if len(self.images) == batch_size:\n                    inputs = np.asarray(self.images, dtype=np.float32)\n                    targets = np.asarray(self.labels, dtype=np.float32)\n                    self.reset()\n                    yield inputs, targets","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import csv,os\nimport numpy as np\nimport pandas as pd\nimport keras\ntrain_order = os.listdir(\"../input/train/train\")\npd_train_order = pd.DataFrame(train_order,columns = [\"id\"])\nlabel_train = pd.read_csv(\"../input/train.csv\")\ndf_train_label = pd.merge(pd_train_order, label_train)","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\ndata_dir=\"../input/train/train\"\ndata_list=os.listdir(data_dir)\nlabel_csv=\"../input/train.csv\"\nclasses=[\"0\",\"1\"]\nbatch_size = 10\nval_ratio = 0.1\n\ntrain_list = []\nval_list = []\n\nfor data in data_list:\n    if random.random() > val_ratio:\n        train_list.append(data)\n    else:\n        val_list.append(data)\nprint(len(train_list))\nprint(len(val_list))\n\ntrain_datagen=ImageDataGenerator_self()\ntest_datagen=ImageDataGenerator_self()\n","execution_count":13,"outputs":[{"output_type":"stream","text":"14039\n3461\n","name":"stdout"}]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from matplotlib import pyplot as plt\nfrom keras.applications.vgg16 import VGG16\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential, Model\nfrom keras.layers import Input, Activation, Dropout, Flatten, Dense, GlobalAveragePooling2D\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import optimizers\nfrom keras.utils import plot_model\nfrom keras.callbacks import ModelCheckpoint\nimport cv2\n\nimg_height,img_width,img_channel = cv2.imread(data_dir + \"/\" + data_list[0]).shape\nbase_model = VGG16(include_top=False, weights=None, input_tensor=None, input_shape=(img_width,img_height,img_channel))\n\nn_categories = 2\n\nx=base_model.output\nx=GlobalAveragePooling2D()(x)\nx=Dense(1024,activation='relu')(x)\nprediction=Dense(n_categories,activation='softmax')(x)\nmodel=Model(inputs=base_model.input,outputs=prediction)\n\nmodel.compile(optimizer=optimizers.SGD(lr=0.0001,momentum=0.9),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n#model.summary()","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.mkdir(\"/output\")\nfpath = '/output/weights.{epoch:03d}-{loss:.2f}-{acc:.2f}-{val_loss:.2f}-{val_acc:.2f}.hdf5'\nmodelCheckpoint = ModelCheckpoint(filepath = fpath,\n                                  monitor='loss',\n                                  verbose=1,\n                                  save_best_only=True,\n                                  save_weights_only=False,\n                                  mode='min',\n                                  period=1)\n\nmodel.fit_generator(\n    generator=train_datagen.flow_from_dir2(data_dir=data_dir, data_list=train_list, label_train=label_train, classes=classes,batch_size=batch_size),\n    #generator=train_datagen.flow_from_dir2(data_dir, data_list, label_csv,classes,batchsize),\n    steps_per_epoch=int(len(data_list) / batch_size),\n    epochs=100,\n    verbose=2,\n    validation_data=test_datagen.flow_from_dir2(data_dir=data_dir, data_list=val_list, label_train=label_train, classes=classes,batch_size=batch_size),\n    validation_steps=int(len(val_list) / batch_size),\n    callbacks=[modelCheckpoint]\n    )","execution_count":15,"outputs":[{"output_type":"stream","text":"Epoch 1/100\n - 41s - loss: 0.2731 - acc: 0.8794 - val_loss: 0.2243 - val_acc: 0.9092\n\nEpoch 00001: loss improved from inf to 0.27307, saving model to /output/weights.001-0.27-0.88-0.22-0.91.hdf5\nEpoch 2/100\n - 39s - loss: 0.1307 - acc: 0.9519 - val_loss: 0.0938 - val_acc: 0.9656\n\nEpoch 00002: loss improved from 0.27307 to 0.13067, saving model to /output/weights.002-0.13-0.95-0.09-0.97.hdf5\nEpoch 3/100\n","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-e4816083854c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_datagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow_from_dir2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodelCheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     )\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_json_str = model.to_json()\nopen(\"/output/vgg16.json\",\"w\").write(model_json_str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pathlib\nfrom keras.models import model_from_json\nweight_file = os.listdir(\"/output\")\nlatest_time = 0.0\nfor weight in weight_file:\n    if \".hdf5\" in weight:\n        st = pathlib.Path(\"/output/\" + weight).stat()\n        if latest_time < st.st_mtime:\n            latest_time = st.st_mtime\n            latest_weight = weight\nprint(latest_weight)\nprint(latest_time)\n\nmodel = model_from_json(open(\"/output/\" + \"/vgg16.json\").read())\nmodel.load_weights(\"/output/\" + latest_weight)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output = [[\"id\",\"has_cactus\"]]\npred_list = os.listdir(\"../input/test/test\")\nfor pred_img in pred_list:\n    img = cv2.cvtColor(cv2.imread(\"../input/test/test/\" + pred_img), cv2.COLOR_BGR2RGB).astype(np.float32)\n    img = img.reshape((1,) + img.shape)\n    result = model.predict(img)\n    output.append([os.path.basename(pred_img),result[0][1]])\n\nwith open('/output/pred_result.csv', 'w') as f:\n    writer = csv.writer(f)\n    writer.writerows(output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv('/output/pred_result.csv')\nsub.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out = os.listdir(\"/\")\nprint(out)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}