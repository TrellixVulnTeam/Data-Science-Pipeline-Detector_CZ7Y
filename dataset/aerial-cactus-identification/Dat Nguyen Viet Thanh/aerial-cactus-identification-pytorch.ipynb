{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!unzip /kaggle/input/aerial-cactus-identification/train.zip\n!unzip /kaggle/input/aerial-cactus-identification/test.zip","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport torch\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.transforms as transforms\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.getcwd()\n# place the files in your IDE working dicrectory .\nlabels = pd.read_csv(r'/kaggle/input/aerial-cactus-identification/train.csv')\nsubmission = pd.read_csv(r'/kaggle/input/aerial-cactus-identification/sample_submission.csv')\n\ntrain_path = r'/kaggle/working/train/'\ntest_path = r'/kaggle/working/test/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels['has_cactus'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label = 'Has Cactus', 'Hasn\\'t Cactus'\nplt.figure(figsize = (8,8))\nplt.pie(labels.groupby('has_cactus').size(), labels = label, autopct='%1.1f%%', shadow=True, startangle=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.image as img\nfig,ax = plt.subplots(1,5,figsize = (15,3))\n\nfor i,idx in enumerate(labels[labels['has_cactus'] == 1]['id'][-5:]):\n    path = os.path.join(train_path,idx)\n    ax[i].imshow(img.imread(path))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(1,5,figsize = (15,3))\nfor i,idx in enumerate(labels[labels['has_cactus'] == 0]['id'][:5]):\n    path = os.path.join(train_path,idx)\n    ax[i].imshow(img.imread(path))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\ndef imshow(image, ax=None, title=None, normalize=True):\n    if ax is None:\n        fig, ax = plt.subplots()\n    image = image.numpy().transpose((1, 2, 0))\n\n    if normalize:\n        mean = np.array([0.485, 0.456, 0.406])\n        std = np.array([0.229, 0.224, 0.225])\n        image = std * image + mean\n        image = np.clip(image, 0, 1)\n\n    ax.imshow(image)\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.spines['left'].set_visible(False)\n    ax.spines['bottom'].set_visible(False)\n    ax.tick_params(axis='both', length=0)\n    ax.set_xticklabels('')\n    ax.set_yticklabels('')\n\n    return ax","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CactiDataset(Dataset):\n    def __init__(self, data, path , transform = None):\n        super().__init__()\n        self.data = data.values\n        self.path = path\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self,index):\n        img_name,label = self.data[index]\n        img_path = os.path.join(self.path, img_name)\n        image = img.imread(img_path)\n        if self.transform is not None:\n            image = self.transform(image)\n        return image, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"means = np.array([0.485, 0.456, 0.406])\nstd = np.array([0.229, 0.224, 0.225])\ntrain_transform = transforms.Compose([transforms.ToPILImage(),\n                                      transforms.ToTensor(),\n                                      transforms.Normalize(means,std)])\n\ntest_transform = transforms.Compose([transforms.ToPILImage(),\n                                     transforms.ToTensor(),\n                                     transforms.Normalize(means,std)])\n\nvalid_transform = transforms.Compose([transforms.ToPILImage(),\n                                     transforms.ToTensor(),\n                                     transforms.Normalize(means,std)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train, valid_data = train_test_split(labels, stratify=labels.has_cactus, test_size=0.2)\n\ntrain_data = CactiDataset(train, train_path, train_transform )\nvalid_data = CactiDataset(valid_data, train_path, valid_transform )\ntest_data = CactiDataset(submission, test_path, test_transform )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Hyper parameters\n\nnum_epochs = 35\nnum_classes = 2\nbatch_size = 25\nlearning_rate = 0.001","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CPU or GPU\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\ndevice","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loader = DataLoader(dataset = train_data, batch_size = batch_size, shuffle=True, num_workers=4)\nvalid_loader = DataLoader(dataset = valid_data, batch_size = batch_size, shuffle=False, num_workers=4)\ntest_loader = DataLoader(dataset = test_data, batch_size = batch_size, shuffle=False, num_workers=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainimages, trainlabels = next(iter(train_loader))\n\nfig, axes = plt.subplots(figsize=(12, 12), ncols=5)\nprint('training images')\nfor i in range(5):\n    axe1 = axes[i] \n    imshow(trainimages[i], ax=axe1, normalize=False)\n\nprint(trainimages[0].size())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass CNN(nn.Module): \n    def __init__(self):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=3)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=3)\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(720, 1024)\n        self.fc2 = nn.Linear(1024, 2)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n        x = x.view(x.shape[0],-1)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = CNN()\nprint(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = CNN().to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# keeping-track-of-losses \ntrain_losses = []\nvalid_losses = []\n\nfor epoch in range(1, num_epochs + 1):\n    # keep-track-of-training-and-validation-loss\n    train_loss = 0.0\n    valid_loss = 0.0\n    \n    # training-the-model\n    model.train()\n    for data, target in train_loader:\n        # move-tensors-to-GPU \n        data = data.to(device)\n        target = target.to(device)\n        \n        # clear-the-gradients-of-all-optimized-variables\n        optimizer.zero_grad()\n        # forward-pass: compute-predicted-outputs-by-passing-inputs-to-the-model\n        output = model(data)\n        # calculate-the-batch-loss\n        loss = criterion(output, target)\n        # backward-pass: compute-gradient-of-the-loss-wrt-model-parameters\n        loss.backward()\n        # perform-a-ingle-optimization-step (parameter-update)\n        optimizer.step()\n        # update-training-loss\n        train_loss += loss.item() * data.size(0)\n        \n    # validate-the-model\n    model.eval()\n    for data, target in valid_loader:\n        \n        data = data.to(device)\n        target = target.to(device)\n        \n        output = model(data)\n        \n        loss = criterion(output, target)\n        \n        # update-average-validation-loss \n        valid_loss += loss.item() * data.size(0)\n    \n    # calculate-average-losses\n    train_loss = train_loss/len(train_loader.sampler)\n    valid_loss = valid_loss/len(valid_loader.sampler)\n    train_losses.append(train_loss)\n    valid_losses.append(valid_loss)\n        \n    # print-training/validation-statistics \n    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n        epoch, train_loss, valid_loss))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test-the-model\nmodel.eval()  # it-disables-dropout\nwith torch.no_grad():\n    correct = 0\n    total = 0\n    for images, labels in valid_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n        outputs = model(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n          \n    print('Val Accuracy of the model: {} %'.format(100 * correct / total))\n\n# Save \ntorch.save(model.state_dict(), 'model.ckpt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nplt.plot(train_losses, label='Training loss')\nplt.plot(valid_losses, label='Validation loss')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend(frameon=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test-the-model\npreds = []\nmodel.eval()  # it-disables-dropout\nwith torch.no_grad():\n    correct = 0\n    total = 0\n    for images, labels in test_loader:\n        images = images.to(device)\n        outputs = model(images)\n        _, predicted = torch.max(outputs.data, 1)\n        preds += predicted.tolist()\n\nsubmit = pd.read_csv('/kaggle/input/aerial-cactus-identification/sample_submission.csv')\nsubmit['has_cactus'] = preds\nsubmit.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}