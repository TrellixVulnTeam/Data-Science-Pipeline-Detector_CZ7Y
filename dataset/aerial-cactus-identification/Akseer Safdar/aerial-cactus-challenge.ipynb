{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Aerial Cactus Challenge"},{"metadata":{},"cell_type":"markdown","source":"In this kaggle challenge we have to identify if an image contains cactus or not. We will use open cv, CNN, keras to build our model and then train the model on training images.\nFinally we will make predictions using the model on test images."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#making the imports\n\nimport pandas as pd\nimport numpy as np\n\nimport cv2\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom keras.models import Sequential\nfrom keras.layers import Flatten, Conv2D, MaxPool2D, Activation, Dense, Dropout\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#define the directory\n\ntrain_directory=\"../input/train/train\"\ntest_directory=\"../input/test/test\"\ntrain=pd.read_csv('../input/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking the head\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (8,6))\nsns.set_style('dark')\nsns.countplot(train['has_cactus'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So we can see that most of the images in training set have cactus in them. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets display a random image from the training set\n\nimg = cv2.imread('../input/train/train/0148bb4a295cf49c0169d69a4a63df7e.jpg')\nplt.figure(figsize = (10,8))\nplt.imshow(img)\nplt.xticks([])\nplt.yticks([])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets display a random image from the training set\n\nimg = cv2.imread('../input/train/train/0de4702853bd3667fb24db3a8dcc07bd.jpg')\nplt.figure(figsize = (10,8))\nplt.imshow(img)\nplt.xticks([])\nplt.yticks([])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The images are low resolution, normally with human eye we will not be able to tell if there is a cactus or not in the image. But let's trust the judement of neural nets to perform this task for us. :-)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets check the shape of image\nimg.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"These are 32 by 32 pixel images (so quite low resolution). Number 3 indicates that these are color images, 1 would denote greyscale image."},{"metadata":{},"cell_type":"markdown","source":"## Data Augmentation\n\nPerforming Data Augmentation will be done by keras ImageDataGenerator, This is a form of regularization and our model will generalize better.\nWe will rescale so that all values range between 0 and 1. Setting aside 20% data for validation set. Shear range will displace each point in fixed direction. Horizontal flip will randomly flip the image in horizontal direction. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#define the parameters for ImageDataGenerator\ntrain_datagen = ImageDataGenerator(rescale= 1./255, validation_split= 0.2, shear_range= 0.2, \n                                  zoom_range= 0.2, horizontal_flip= True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#converting the has_cactus to a string\ntrain['has_cactus'] = train['has_cactus'].astype(str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets use data generator to make training and validation set.\n\ntrain_generator = train_datagen.flow_from_dataframe(train, \n                                                    directory= train_directory, \n                                                    subset= 'training',\n                                                    x_col= 'id',\n                                                    y_col= 'has_cactus',\n                                                    target_size= (32,32),\n                                                    class_mode= 'binary'\n                                                   )\n\n\ntest_generator = train_datagen.flow_from_dataframe(train,\n                                                  directory= train_directory,\n                                                  subset= 'validation',\n                                                  x_col= 'id',\n                                                  y_col= 'has_cactus',\n                                                  target_size= (32,32),\n                                                  class_mode= 'binary'\n                                                  )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So now we have 14k images for training set and 3.5k images for validation set."},{"metadata":{},"cell_type":"markdown","source":"## Creating the model\n\nWe will build our CNN model and will use a drop out of 30 % to prevent overfitting. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#define the model layers\nmodel = Sequential()\n\nmodel.add(Conv2D(32, (3,3), activation = 'relu', input_shape = (32,32,3)))\nmodel.add(Conv2D(32, (3,3), activation = 'relu'))\nmodel.add(MaxPool2D(2,2))\n\nmodel.add(Conv2D(64, (3,3), activation = 'relu'))\nmodel.add(Conv2D(64, (3,3), activation = 'relu'))\nmodel.add(MaxPool2D(2,2))\n\nmodel.add(Conv2D(128, (3,3), activation = 'relu'))\nmodel.add(MaxPool2D(2,2))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation = 'relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(1, activation = 'sigmoid'))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets compile the model\n\nmodel.compile(loss = 'binary_crossentropy',\n             optimizer= Adam(),\n             metrics= ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model summary\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train the Model\nlets do it for 20 epochs for demo. Although this could result in overfitting :-)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets train the model for 20 epochs\n\nhistory = model.fit_generator(train_generator,\n                             steps_per_epoch= 2000, \n                             epochs= 20, \n                             validation_data= test_generator,\n                             validation_steps= 64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#convert the results to a data frame\nhist = pd.DataFrame(history.history)\nhist['epoch'] = history.epoch\nhist","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plot the Training and Validation Accuracy/Loss\n\nSee how model tries to overfit after certain epochs. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#plotting the results to see difference between train and validation accuracy/loss\n\nplt.figure(figsize = (8,6))\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.plot(hist['epoch'],hist['val_acc'], label = 'Val Accuracy')\nplt.plot(hist['epoch'],hist['acc'], label = 'Train Accuracy')\nplt.xticks(range(0,20))\nplt.legend(loc = 'lower right')\nplt.title('Accuracy')\nplt.show()\n\nplt.figure(figsize = (8,6))\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.plot(hist['epoch'],hist['val_loss'], label = 'Val Loss')\nplt.plot(hist['epoch'],hist['loss'], label = 'Train Loss')\nplt.xticks(range(0,20))\nplt.legend()\nplt.title('Loss')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see that after epoch#4 the model starts to overfit. So we may have stopped the training at epoch 4. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#getting the test set ready to make predictions\n\nids = []\nX_test = []\n\nfor image in os.listdir(test_directory):\n    \n    ids.append(image.split('.')[0])\n    path = os.path.join(test_directory, image)\n    X_test.append(cv2.imread(path))\n    \nX_test = np.array(X_test)\nX_test = X_test.astype('float32')/ 255","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Lets make the predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"#making the predictions\npredictions = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#writing to submission file\n\nmy_sub = pd.read_csv('../input/sample_submission.csv')\nmy_sub['id'] = ids\nmy_sub['has_cactus'] = predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#convert the probability to 0s and ones. \ndef cvt_prob(x):\n    \n    if x >= 0.5:\n        return 1\n    else:\n        return 0\n    \nmy_sub['has_cactus'] = my_sub['has_cactus'].apply(cvt_prob)    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#see the count of 0s and 1s \nplt.figure(figsize = (8,6))\nsns.set_style('dark')\nsns.countplot(my_sub['has_cactus'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So as we had more images in training set with cactus in them so is the case with test set as well."},{"metadata":{"trusted":true},"cell_type":"code","source":"#write to submission file\nmy_sub.to_csv('my_sub1.csv',index= False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is a pretty decent model with good accuracy. In colclusion we can say that;\n\n**Scaling** is necessary to bring all of your features on to a similar scale so that your model should give equal attention to all the features. \nAdding more layers to build a complex model could give good accuracy on training data as model would try to memorize the training data and will not give desired performance on test data **(overfitting)**. \nTrain for **less epochs** as more epochs will result in **overfitting**. \nAlso use the Dropout to prevent **overfitting**. \n\n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}