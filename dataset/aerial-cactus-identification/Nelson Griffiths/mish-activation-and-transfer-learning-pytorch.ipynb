{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nimport os\nimport multiprocessing as mp","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import datasets\nimport torchvision.transforms as transforms\nfrom torchvision import models\nfrom torch.utils.data.sampler import SubsetRandomSampler\n\ndef mish(x):\n    return (x*torch.tanh(F.softplus(x)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\n\ntrain_on_gpu = torch.cuda.is_available()\n\nif not train_on_gpu:\n    print('CUDA is not available.  Training on CPU ...')\nelse:\n    print('CUDA is available!  Training on GPU ...')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Prep\n\nFirst, I am going to import our data sources and take a look at what we are working with. We have a csv file that contains our target variable and a folder with our cactus images."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/train.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4b05460b2e4320bde525cdff2cfe9dc5e011c8dc"},"cell_type":"code","source":"df['has_cactus'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df, val_df = train_test_split(df, stratify = df.has_cactus, test_size=.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking that validation set has same proportions as original training data\nval_df['has_cactus'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Build a class for our data to put our images and target variables into our pytorch dataloader\n# https://stanford.edu/~shervine/blog/pytorch-how-to-generate-data-parallel\n\nclass DataSet(torch.utils.data.Dataset):\n    def __init__(self, labels, data_directory, transform=None):\n        super().__init__()\n        self.labels = labels.values\n        self.data_dir = data_directory\n        self.transform=transform\n        \n    def __len__(self):\n        return len(self.labels)\n    \n    def __getitem__(self, index):\n        name, label = self.labels[index]\n        img_path = os.path.join(self.data_dir, name)\n        img = cv2.imread(img_path)\n        \n        if self.transform is not None:\n            img = self.transform(img)\n        return img, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4e57e9d038f1502a989c7b57719e19679c8ee002"},"cell_type":"code","source":"batch_size = 32\n\n# Transform training data with random flips and normalize it to prepare it for dataloader\ntrain_transforms = transforms.Compose([transforms.ToPILImage(),\n                                       transforms.RandomHorizontalFlip(),\n                                       transforms.ToTensor(),\n                                      transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n\nval_transforms = transforms.Compose([transforms.ToPILImage(),\n                                     transforms.ToTensor(),\n                                     transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n\ntrain_data = DataSet(train_df,'../input/train/train', transform = train_transforms)\nval_data = DataSet(val_df,'../input/train/train', transform = val_transforms)\n\ntrain_data_loader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True, num_workers=mp.cpu_count())\nval_data_loader = torch.utils.data.DataLoader(val_data, batch_size = batch_size, shuffle = True, num_workers=mp.cpu_count())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d7d9586bfbfb6030bdd041f038dcf04224bc2fe9"},"cell_type":"code","source":"#Checking what our cactus look like\nfig,ax = plt.subplots(1,3,figsize=(15,5))\n\nfor i, idx in enumerate(train_df[train_df['has_cactus']==1]['id'][0:3]):\n  path = os.path.join('../input/train/train',idx)\n  ax[i].imshow(cv2.imread(path))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cea94b8cc2d682f3829e8428e53f5e425652d26b"},"cell_type":"code","source":"#Building a CNN from scratch\nact = mish\nclass Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        self.conv1 = nn.Conv2d(3, 16, 3, padding = 1)\n        self.conv2 = nn.Conv2d(16, 32, 3, padding = 1)\n        self.conv3 = nn.Conv2d(32, 64, 3, padding = 1)\n        self.conv4 = nn.Conv2d(64, 128, 3, padding = 1)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.fc1 = nn.Linear(2*16*16, 256)\n        self.fc2 = nn.Linear(256, 128)\n        self.fc3 = nn.Linear(128, 64)\n        self.fc4 = nn.Linear(64, 2)\n        self.dropout = nn.Dropout(p = .25)\n        \n    def forward(self, x):\n        \n        x = self.pool(act(self.conv1(x)))\n        x = self.pool(act(self.conv2(x)))\n        x = self.pool(act(self.conv3(x)))\n        x = self.pool(act(self.conv4(x)))\n        \n        x = x.view(-1, 2*16*16)\n        x = self.dropout(x)\n        x = act(self.fc1(x))\n        x = self.dropout(x)\n        x = act(self.fc2(x))\n        x = self.dropout(x)\n        x = act(self.fc3(x))\n        x = self.dropout(x)\n        x = act(self.fc4(x))\n        \n        return x\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Net()\nif train_on_gpu:\n    model = model.cuda()\n\nepochs = 10\nlearning_rate = .0003\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adamax(model.parameters(), lr=learning_rate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Training and validation for model\n\nbest_loss = np.Inf\nbest_model = Net()\nif train_on_gpu:\n    best_model.cuda()\n\nfor epoch in range(1, epochs+1):\n    train_loss = 0\n    val_loss = 0\n    \n    model.train()\n    for images, labels in train_data_loader:\n        \n        if train_on_gpu:\n            images = images.cuda()\n            labels = labels.cuda()\n            \n        optimizer.zero_grad()\n        out = model(images)\n        loss = criterion(out, labels)\n        \n        loss.backward()\n        optimizer.step()\n        \n        train_loss += loss.item()\n        #print('Loss: {}'.format(loss.item()))\n        \n    model.eval()\n    for images, labels in val_data_loader:\n        \n        if train_on_gpu:\n            images = images.cuda()\n            labels = labels.cuda()\n            \n        out = model(images)\n        loss = criterion(out, labels)\n        \n        val_loss += loss.item()\n        \n    train_loss = train_loss/len(train_data_loader.dataset)\n    val_loss = val_loss/len(val_data_loader.dataset)  \n    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(epoch, train_loss, val_loss))\n    \n    #Saving the weights of the best model according to validation score\n    if val_loss < best_loss:\n        best_loss = val_loss\n        print('Improved Model Score - Updating Best Model Parameters...')\n        best_model.load_state_dict(model.state_dict())\n        \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check model accuracy\nbest_model.eval()\nwith torch.no_grad():\n    correct = 0\n    total = 0\n    for images, labels in val_data_loader:\n        if train_on_gpu:\n            images = images.cuda()\n            labels = labels.cuda()\n        outputs = best_model(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n          \n    print('Test Accuracy: {} %'.format(100 * correct / total))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vgg = models.vgg16()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class mish_layer(nn.Module):\n    def __init__(self):\n        super(mish_layer, self).__init__()\n        \n    def forward(self, input):\n        return mish(input)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"act = mish_layer()\n\nvgg.classifier[1] = act\nvgg.classifier[4] = act\n\nfor param in vgg.parameters():\n    param.requires_grad=False\nvgg.classifier[6] = nn.Linear(4096, 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vgg = vgg.cuda()\n\nepochs = 10\nlearning_rate = .0003\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adamax(vgg.parameters(), lr=learning_rate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_loss = np.Inf\nbest_model = Net()\nif train_on_gpu:\n    best_model.cuda()\n\nfor epoch in range(1, epochs+1):\n    train_loss = 0\n    val_loss = 0\n    \n    vgg.train()\n    for images, labels in train_data_loader:\n        \n        if train_on_gpu:\n            images = images.cuda()\n            labels = labels.cuda()\n            \n        optimizer.zero_grad()\n        out = vgg(images)\n        loss = criterion(out, labels)\n        \n        loss.backward()\n        optimizer.step()\n        \n        train_loss += loss.item()\n        #print('Loss: {}'.format(loss.item()))\n        \n    vgg.eval()\n    for images, labels in val_data_loader:\n        \n        if train_on_gpu:\n            images = images.cuda()\n            labels = labels.cuda()\n            \n        out = vgg(images)\n        loss = criterion(out, labels)\n        \n        val_loss += loss.item()\n        \n    train_loss = train_loss/len(train_data_loader.dataset)\n    val_loss = val_loss/len(val_data_loader.dataset)  \n    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(epoch, train_loss, val_loss))\n    \n    #Saving the weights of the best model according to validation score\n    if val_loss < best_loss:\n        best_loss = val_loss\n        print('Improved Model Score - Updating Best Model Parameters...')\n        best_model.load_state_dict(model.state_dict())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check model accuracy\nbest_model.eval()\nwith torch.no_grad():\n    correct = 0\n    total = 0\n    for images, labels in val_data_loader:\n        if train_on_gpu:\n            images = images.cuda()\n            labels = labels.cuda()\n        outputs = best_model(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n          \n    print('Test Accuracy: {} %'.format(100 * correct / total))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}