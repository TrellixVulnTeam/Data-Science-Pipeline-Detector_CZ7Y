{"cells":[{"metadata":{"id":"tv6ntk-oiSbp","colab_type":"text"},"cell_type":"markdown","source":"# Aerial Cactus Identification"},{"metadata":{"id":"1XyP61EQiSbw","colab_type":"text"},"cell_type":"markdown","source":"## Competition Description from Kaggle\nTo assess the impact of climate change on Earth's flora and fauna, it is vital to quantify how human activities such as logging, mining, and agriculture are impacting our protected natural areas. Researchers in Mexico have created the VIGIA project, which aims to build a system for autonomous surveillance of protected areas. A first step in such an effort is the ability to recognize the vegetation inside the protected areas. In this competition, you are tasked with creation of an algorithm that can identify a specific type of cactus in aerial imagery."},{"metadata":{"id":"EzhuOca2iSby","colab_type":"text"},"cell_type":"markdown","source":"### Data Format\n<ol>\n    <li>A folder containing 32x32 images.</li>\n    <li>Files train.csv and test.csv containing name of file as key, and a binary column has_cactus, which is 0 if no cactus in image and 1 if there is cactus in image.</li>\n</ol>\n\n### Target\nTake images and classify whether the image contains cactus or not."},{"metadata":{"id":"lhJvn4BaiSb3","colab_type":"text"},"cell_type":"markdown","source":"\n## First Steps"},{"metadata":{"id":"eFNinFPNd01O","colab_type":"text"},"cell_type":"markdown","source":"### Import Data From Kaggle"},{"metadata":{"id":"EDbLDwBIiSb8","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow.keras as keras\nimport matplotlib.pyplot as plt\nimport os\nfrom PIL import Image\nimport pathlib\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport pathlib\nimport math\n\ntf.enable_eager_execution()\n\n%matplotlib inline\n\nINPUT_DIR = '../input'\nTRAIN_IMG_DIR = INPUT_DIR+'/train/train'\nPRED_IMG_DIR = INPUT_DIR+'/test/test'\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n\nnp.random.seed(1000)","execution_count":null,"outputs":[]},{"metadata":{"id":"babOqFn1eEyh","colab_type":"text"},"cell_type":"markdown","source":"### Import Required Libraries"},{"metadata":{"id":"NczCmBjYiScL","colab_type":"code","outputId":"76a51a98-b3aa-43ab-9cbd-ab682e3197a9","colab":{"base_uri":"https://localhost:8080/","height":206},"trusted":true},"cell_type":"code","source":"df = pd.read_csv(INPUT_DIR+'/train.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"dhm_QeB9iScW","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# Split the dataset into training and testing set.\ntrain_df, test_df = train_test_split(df, train_size=0.70, random_state=0)\n\n# Find the number of items in each dataset\nn_training_items = train_df['id'].count()\nn_testing_items = test_df['id'].count()","execution_count":null,"outputs":[]},{"metadata":{"id":"1QPn92RJiScg","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"def img_path(img_file, img_type=0):\n    \"\"\" \n    img_file: name of image file\n    img_type: 0 if for training, 1 for evaluation dataset.\n    \"\"\"\n    if img_type==0:\n        return TRAIN_IMG_DIR+'/'+img_file\n    else:\n        return PRED_IMG_DIR+'/'+img_file\n    \n# Find the filename and corresponding labels of all images in training dataset.\ntrain_image_paths = [img_path(x) for x in train_df['id']]\ntrain_image_labels = [x for x in train_df['has_cactus']]\n    \n# Find the filename and corresponding labels of all images in testing dataset.\ntest_image_paths = [img_path(x) for x in test_df['id']]\ntest_image_labels = [x for x in test_df['has_cactus']]\n\n# Find the filenames of all prediction files.\npath = os.listdir(PRED_IMG_DIR)\npred_images_paths = [img_path(x, 1) for x in path]\nn_pred_items = len(pred_images_paths)","execution_count":null,"outputs":[]},{"metadata":{"id":"jTA2WSE2iScp","colab_type":"text"},"cell_type":"markdown","source":"## Check Image Type"},{"metadata":{"id":"URTKkjQ8iScs","colab_type":"code","outputId":"51aa2aa2-911d-4234-e1e7-534379b0db11","colab":{"base_uri":"https://localhost:8080/","height":287},"trusted":true},"cell_type":"code","source":"im = Image.open(train_image_paths[0])\nprint(im.format, im.size, im.mode)\nimgplot = plt.imshow(im)","execution_count":null,"outputs":[]},{"metadata":{"id":"NBTLmLgjiSc5","colab_type":"text"},"cell_type":"markdown","source":"The images are JPEG images of 32x32 resolution with 3 channels."},{"metadata":{"id":"8RmD23rgiSc8","colab_type":"text"},"cell_type":"markdown","source":"## Data Preprocessing"},{"metadata":{"id":"k9v_E_bgiSc9","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"def load_and_preprocess_image(imagefile):\n    \n    def preprocess_image(image):\n        image = tf.image.decode_jpeg(image, channels=3)\n        image = tf.image.resize(image, [32, 32])\n        image /= 255.0  # normalize to [0,1] range\n        return image\n    \n    image = tf.read_file(imagefile)\n    return preprocess_image(image)\n\ndef load_and_preprocess_from_path_label(path, label):\n    return load_and_preprocess_image(path), label","execution_count":null,"outputs":[]},{"metadata":{"id":"Ml4ggRz-iSdK","colab_type":"text"},"cell_type":"markdown","source":"## Creating Input Pipiline"},{"metadata":{"id":"zX57RilsiSdQ","colab_type":"code","outputId":"d9c10337-6717-4876-aab5-5416c2b8f483","colab":{"base_uri":"https://localhost:8080/","height":35},"trusted":true},"cell_type":"code","source":"# Tensorflow Dataset containing all image paths and labels\ntrain_ds = tf.data.Dataset.from_tensor_slices((train_image_paths, train_image_labels))\ntest_ds = tf.data.Dataset.from_tensor_slices((test_image_paths, test_image_labels))\npred_ds = tf.data.Dataset.from_tensor_slices(pred_images_paths)\n\n# Load the images into dataset from the path in the dataset\ntrain_ds = train_ds.map(load_and_preprocess_from_path_label)\ntest_ds = test_ds.map(load_and_preprocess_from_path_label)\npred_ds = pred_ds.map(load_and_preprocess_image)\n\ntrain_ds","execution_count":null,"outputs":[]},{"metadata":{"id":"2cSkq9z9iSda","colab_type":"code","outputId":"e79f2848-a9c9-4565-99e4-abb28fc65e7a","colab":{"base_uri":"https://localhost:8080/","height":55},"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 32\nsteps_per_epoch = int(math.ceil(n_training_items/BATCH_SIZE))\n# Training Dataset\ntrain_ds1 = (train_ds.cache()\n             .apply(\n                 tf.data.experimental.shuffle_and_repeat(buffer_size=n_training_items)\n             )\n             .batch(BATCH_SIZE)\n             .prefetch(buffer_size=AUTOTUNE)\n            )\n\n# Testing dataset\ntest_ds1 = (test_ds.cache()\n            .apply(tf.data.experimental.shuffle_and_repeat(buffer_size=n_training_items))\n            .batch(BATCH_SIZE)\n            .prefetch(buffer_size=AUTOTUNE))\n\n# Prediction dataset\npred_ds1 = (pred_ds\n            .cache()\n            .batch(BATCH_SIZE)\n            .prefetch(buffer_size=AUTOTUNE)\n           )\n\nprint(train_ds1, pred_ds1)\n\n","execution_count":null,"outputs":[]},{"metadata":{"id":"NTRe4GuXiSdw","colab_type":"text"},"cell_type":"markdown","source":"## Create Model\nUsing VGG19 inspired model."},{"metadata":{"id":"-tG7NIx9w-tJ","colab_type":"code","outputId":"75c93343-fa8c-4951-e631-f268f8ac78b2","colab":{"base_uri":"https://localhost:8080/","height":551},"trusted":true},"cell_type":"code","source":"model = keras.Sequential([\n    tf.layers.Conv2D(filters=12, strides=1, kernel_size=3, padding='valid',activation=tf.nn.leaky_relu, input_shape=(32,32,3)),\n    tf.layers.Conv2D(filters=32, kernel_size=3, activation=tf.nn.leaky_relu, input_shape=(32,32,3), padding='same'),\n    tf.layers.Conv2D(filters=32, kernel_size=3, activation=tf.nn.leaky_relu, padding='same'),\n    tf.layers.AveragePooling2D(pool_size=3, strides=2),\n\n    tf.layers.Conv2D(filters=64, kernel_size=3, activation=tf.nn.leaky_relu, padding='same'),\n    tf.layers.Conv2D(filters=64, kernel_size=3, activation=tf.nn.leaky_relu, padding='same'),\n    tf.layers.MaxPooling2D(pool_size=(2,2), strides=2),\n    tf.layers.Flatten(),\n    tf.layers.Dense(units=2, activation='softmax')\n])\n\nmodel.compile(optimizer='adam',loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"id":"LC4475VOnX2A","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"### Fit and Evaluate","execution_count":null,"outputs":[]},{"metadata":{"id":"Fx50zkpgiSd8","colab_type":"code","outputId":"e8f2600e-4fe0-41e0-ca61-c0de2bc39ea9","colab":{"base_uri":"https://localhost:8080/","height":256},"trusted":true},"cell_type":"code","source":"\nmodel.fit(train_ds1, epochs=6, steps_per_epoch=steps_per_epoch)","execution_count":null,"outputs":[]},{"metadata":{"id":"YsQZ7Kp4iSeG","colab_type":"code","outputId":"8ee4415f-e5f3-4017-c8a5-926352786821","colab":{"base_uri":"https://localhost:8080/","height":54},"trusted":true},"cell_type":"code","source":"model.evaluate(test_ds1, steps=n_testing_items)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that the testing set accuracy is higher than training set accuracy. Hence the model generalizes well."},{"metadata":{"id":"abgz_FRineTY","colab_type":"text"},"cell_type":"markdown","source":"## Evaluate and Prepare Submission File"},{"metadata":{"id":"kOmfO0USRv8F","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"logits = model.predict(pred_ds1, steps=n_pred_items)\npredictions = np.argmax(logits, axis=-1)","execution_count":null,"outputs":[]},{"metadata":{"id":"YDofpKjciSeK","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"names = np.array([x for x in path])\npred_df = pd.DataFrame(\n    {\n        \"id\":names,\n        \"has_cactus\":predictions\n    })\npred_df.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"qCJtucX-Rwns","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"pred_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"pucho-deep.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"nbformat":4,"nbformat_minor":1}