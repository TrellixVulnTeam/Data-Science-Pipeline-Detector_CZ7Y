{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n#Pytorch \nimport torch\nimport torchvision\nimport torch.nn.functional as F\nfrom torch import nn, optim\nfrom torch.optim.lr_scheduler import StepLR\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torchvision import transforms, models\n\nfrom PIL import Image\nfrom os import listdir\nfrom os.path import isfile, join\nimport cv2\nfrom sklearn.model_selection import train_test_split\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline\n\nimport os\nprint(os.listdir(\"../input\"))\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('device: {}'.format(device))\ntrain_folder='../input/train/train/'\ntest_folder='../input/test//test/'\nlabels=pd.read_csv('../input/train.csv')\nsubmission=pd.read_csv('../input/sample_submission.csv')\nprint('train dataset size: {}'.format(len(listdir(train_folder))))\nprint('test dataset size: {}'.format(len(listdir(test_folder))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create simple dataset\nclass Cactus(Dataset):\n    def __init__(self, folder, labels, transform=None):\n        self.transform=transform\n        self.folder=folder\n        self.labels=labels\n    def __len__(self):\n        return self.labels.shape[0]\n    def __getitem__(self,index):\n        img_path=os.path.join(self.folder, self.labels['id'].iloc[index])\n        img=Image.open(img_path)\n        img_label=self.labels['has_cactus'].iloc[index]\n        if self.transform:\n            img=self.transform(img)\n        return img, img_label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize some samples and their transformations\ndef visualize_samples(dataset, indices, count=5):\n    plt.figure(figsize=(count*3,3))\n    display_indices = indices[:count]\n    for i, index in enumerate(display_indices):    \n        x, y = dataset[index]\n        plt.subplot(1,count,i+1)\n        plt.title('has cactus: {}'.format(y))\n        plt.imshow(x)\n        plt.grid(False)\n        plt.axis('off')   \n\norig_dataset=Cactus(train_folder, labels)\nindices = np.random.choice(np.arange(len(orig_dataset)), 5, replace=False)\nvisualize_samples(orig_dataset, indices)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transformed_dataset=Cactus(train_folder, labels, \n                                    transform=transforms.Compose([\n                                    transforms.RandomHorizontalFlip(),\n                                    transforms.RandomVerticalFlip(),\n                                    transforms.RandomAffine(10),\n                                    transforms.RandomRotation((-10,10))\n                                                                    ]))\nvisualize_samples(transformed_dataset, indices)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Transforms\ntfs_train=transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.RandomRotation((-10,10)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))                \n                      ])\ntfs_test=transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))                \n                      ])\n\n#Datasets\ntrain_dataset=Cactus(train_folder, labels, transform=tfs_train)\ntest_dataset=Cactus(test_folder, submission, transform=tfs_test)\n\n# Dividing train dataset into train and validation\nbs=128\ndata_size=len(train_dataset)\nsplit=int(np.floor(0.1*data_size))\ndata_indices=list(range(data_size))\nnp.random.shuffle(data_indices)\ntrain_indices, val_indices=data_indices[split:], data_indices[:split]\n\n#Samplers\ntrain_sampler=SubsetRandomSampler(train_indices)\nval_sampler=SubsetRandomSampler(val_indices)\n\n#Loaders\ntrain_loader=DataLoader(train_dataset, batch_size=bs, sampler=train_sampler)\nval_loader=DataLoader(train_dataset, batch_size=bs//2, sampler=val_sampler)\ntest_loader=DataLoader(test_dataset, batch_size=bs//2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(model, train_loader, val_loader, loss, optimizer, num_epoch=10):\n    print('Training...')\n    loss_history=[]\n    train_history=[]\n    val_history=[]\n    val_loss_history=[]\n    for epoch in range(num_epoch):\n        model.train()\n        loss_accum=0\n        correct_samples=0\n        total_samples=0\n        \n        for i_step, (x,y) in enumerate(train_loader):\n            x,y=x.to(device),y.to(device)\n            prediction=model(x)\n            loss_value=criterion(prediction,y)\n            optimizer.zero_grad()\n            loss_value.backward()\n            optimizer.step()\n            \n            _, indices=torch.max(prediction, 1)\n            correct_samples+=torch.sum(indices==y).item()\n            total_samples+=y.shape[0]\n            \n            loss_accum+=loss_value\n            \n        scheduler.step()                    \n        train_loss=loss_accum/i_step\n        train_accuracy=float(correct_samples)/total_samples\n        val_accuracy, val_loss=compute_accuracy(model, val_loader)\n        \n        loss_history.append(float(train_loss))\n        train_history.append(train_accuracy)\n        val_history.append(val_accuracy)\n        val_loss_history.append(val_loss)\n        \n        print('Epoch: {}/{}, Train_loss: {}, Train_accuracy: {}, Val_loss: {}, Val_accuracy: {}'.format(epoch+1,\n                            num_epoch,train_loss,train_accuracy,val_loss,val_accuracy))\n    return loss_history, train_history, val_history, val_loss_history\n\ndef compute_accuracy(model,loader):\n    model.eval()\n    correct_samples=0\n    total_samples=0\n    loss_accum=0\n    with torch.no_grad():\n        for i_step, (x,y) in enumerate(loader):\n            x,y=x.to(device),y.to(device)\n            prediction=model(x)\n            loss_value=criterion(prediction,y)\n            _,indices=torch.max(prediction,1)\n            correct_samples+=torch.sum(indices==y).item()\n            total_samples+=y.shape[0]\n            loss_accum+=loss_value\n    ave_loss=loss_accum/i_step\n    accuracy=float(correct_samples)/total_samples\n    return accuracy, ave_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Define model\nmodel=models.resnet18(pretrained=True)\nnum_ftrs=model.fc.in_features\nmodel.fc=nn.Linear(num_ftrs,2)\nmodel=model.to(device)\n\n#Start training\ncriterion=nn.CrossEntropyLoss()\noptimizer=optim.Adamax(model.parameters(), lr=0.003, weight_decay=0.001)\nscheduler=StepLR(optimizer, step_size=10, gamma=0.1)\nloss_history, train_history, val_history, val_loss_history = train_model(model, train_loader, \n                                        val_loader, criterion, optimizer, 30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create submission file\nmodel.eval()\n\npredictions=[]\nfor i, (x,y) in enumerate(test_loader):\n    x,y=x.to(device), y.to(device)\n    prediction=model(x)\n    pred=prediction[:,1].detach().cpu().numpy()\n    for i in pred:\n        predictions.append(i)\n\nsubmission['has_cactus']=predictions\nsubmission.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}