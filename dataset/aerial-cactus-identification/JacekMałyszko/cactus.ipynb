{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"pd.read_csv('../input/train.csv')\nimport matplotlib.pyplot as plt\n%matplotlib inline  \nfrom PIL import Image\nall_images_fnames = os.listdir(\"../input/train/train\")\nfor i in all_images_fnames[:10]:\n    image = Image.open(\"../input/train/train/{}\".format(i))\n    image_numpy = np.asarray(image)\n    from matplotlib.pyplot import imshow\n    imshow(np.asarray(image_numpy))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torchvision\nimport PIL\n#https://colab.research.google.com/drive/109vu3F1LTzD1gdVV6cho9fKGx7lzbFll#scrollTo=9NRlYXKQy3Kx\ntransformations_rotation = torchvision.transforms.Compose([\n    torchvision.transforms.ColorJitter(brightness=.2, contrast=.2, hue=.2, saturation=.2),\n    torchvision.transforms.RandomHorizontalFlip(),\n    torchvision.transforms.RandomVerticalFlip(),\n    torchvision.transforms.RandomRotation(degrees = (90,90))\n])\ntransformations_no_rotation = torchvision.transforms.Compose([\n    torchvision.transforms.ColorJitter(brightness=.2, contrast=.2, hue=.2, saturation=.2),\n    torchvision.transforms.RandomHorizontalFlip(),\n    torchvision.transforms.RandomVerticalFlip()\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels_df = pd.read_csv('../input/train.csv')\nprint(\"How many pictures contain cactuses?\")\ntrain_labels_df['has_cactus'].sum() / train_labels_df['has_cactus'].count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_pictures_data = [Image.open(\"../input/train/train/{}\".format(i)) for i in list(train_labels_df['id'])]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"augumented_pictures_data =  []\naugumented_pictures_labels = []\nfor picture, label in zip(all_pictures_data, train_labels_df['has_cactus'].values):\n    augumented_pictures_data.append(picture)\n    augumented_pictures_labels.append(label)\n    for i in range(4):\n        augumented_pictures_data.append(transformations_rotation(picture))\n        augumented_pictures_data.append(transformations_no_rotation(picture))\n        augumented_pictures_labels.append(label)\n        augumented_pictures_labels.append(label)\nfor pic in augumented_pictures_data[:8]:\n    from matplotlib.pyplot import imshow\n    imshow(np.asarray(pic))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = torch.Tensor(np.asarray([np.asarray(i) for i in augumented_pictures_data])).cuda()\nprint(X.shape)\nX = X.reshape(17500*9, 3, 32, 32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = np.asarray(augumented_pictures_labels)\ny = torch.Tensor(labels).cuda()\nprint(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torchvision.models import vgg16\nmodel = vgg16(pretrained=True, progress=True)\nmodel.cuda()\nmodel.classifier[6]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_features = model.classifier[6].in_features\nfeatures = list(model.classifier.children())[:-1] # Remove last layer\nfeatures.extend([torch.nn.Linear(num_features, 2)]) # Add our layer with 4 outputs\nmodel.classifier = torch.nn.Sequential(*features) # Replace the model classifier\n\nfor param in model.features.parameters():\n    param.require_grad = False\nmodel.cuda()\nprint(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from  torch.utils import data\nimport random\nX.shape\nn = X.shape[0]\ntrain_indexes_count = int(n*0.1)\ntest_indexes_count = n - train_indexes_count\n\n\nfrom torch.utils.data import TensorDataset\nfrom torch.utils.data import DataLoader\n\ndataset = TensorDataset(X, y)\ntrain_set, test_set = data.random_split(dataset, (train_indexes_count, test_indexes_count))\nloader = DataLoader(train_set, batch_size = 128)\nfor epoch in range(30):\n    for X_sample, y_sample in loader:\n        print(y_sample)\n        break\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learning_rate = 0.0001\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for epoch in range(60):\n    losses = []\n    for batch_x, batch_y in loader:\n        y_pred = model(batch_x)\n        #print(labels_tensor)\n        #print(y_pred.argmax(dim=1))\n        loss = loss_fn(y_pred, batch_y.long())\n        losses.append(loss.item())\n        model.zero_grad()\n        loss.backward()\n        optimizer.step()\n    print(epoch, sum(losses) / len(losses))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loader = DataLoader(test_set, batch_size = 128)\ny_pred = []\nfor batch in loader:\n    y_pred += [i for i in model(batch[0]).argmax(1).cpu().numpy()]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test = [int(i[1].cpu().numpy()) for i in test_set]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_baseline = [1 for i in y_test]\nprint(classification_report(y_baseline, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pictures_data = [np.asarray(Image.open(\"../input/test/test/{}\".format(i))) for i in os.listdir(\"../input/test/test\")]\nlen(test_pictures_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_submit = torch.Tensor(np.asarray(test_pictures_data)).cuda()\nX_submit = X_submit.reshape(4000, 3, 32, 32)\n#print(X_submit.shape)\ny_submit = model(X_submit)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_submit_list = list(y_submit.argmax(1).cpu().numpy())\nwith open('to_submit.csv', 'w') as fhout:\n    fhout.write('id,has_cactus\\n')\n    for fname, y in zip(os.listdir(\"../input/test/test\"), y_submit_list):\n        fhout.write(\"{}, {}\\n\".format(fname, y))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}