{"cells":[{"metadata":{},"cell_type":"markdown","source":"Equipe: Leila K.Silva, Jane S.Deutsch, Jaqueline Damacena Duarte, Marli Aparecida Silva, Michael Abraao Soares Miranda\n\n### Conceitos de uma Convolutional Neural Network\nUma rede convolucional - CNN ou ConvNet, é uma classe de rede neural artificial do tipo feed-forward.  \nA arquitetura de uma ConvNet faz uma analogia ao padrão de conectividade de Neurônios no Cérebro Humano e foi inspirada na organização do Visual Cortex. Os neurônios individuais respondem a estímulos apenas em uma região restrita do campo visual conhecida como Campo Receptivo. Uma coleção desses campos são sobreposto para cobrir toda a área visual. Assim, a rede convolucional calcula um novo valor para um pixel da imagem com base nos pixels da vizinhança. \n\nRedes neurais convolucionais são muito adequadas em detectar padrões em imagens pois elas conseguem aprender invariância do ponto de vista. Ou seja, podem detectar os padrões independentemente da posição deles na imagem, uma vez que o filtro é aplicado em toda a imagem.\n\nArquitetura : MobileNetV2: A arquitetura do MobileNetV2 é baseada em uma estrutura residual invertida onde a entrada e saída do bloco residual são camadas finas de gargalo opostas aos modelos residuais tradicionais que usam representações expandidas na entrada do MobileNetV2 usa convoluções leves para filtrar recursos na camada de expansão intermediária\nUtilizamos um pré-treino para transferencia de aprendizado a partir de pesos conhecidos da base Imagenet.\n\nDepois, executamos uma rede neural convolucional do tipo Stack of Layers ( Keras.Sequential) com 1 camada densa com a função de não linearidade sigmoid e utilizando maxpooling para nossa base.\n\n\nCamadas de pooling = Camadas de agrupamento de pixels, ou pooling,  reduzem as dimensões dos dados, combinando as saídas de clusters de neurônios em uma camada em um único neurônio na próxima camada. O pooling pode ser local, ou global, máximo ou médio. Foi escolhido o Global Maxpooling 2D do Keras, que usa o valor máximo de cada cluster de neurônios na camada anterior e atua em todos os neuronios da camada convolucional.\n\nFunções de Ativação/não linearidade = escolhemos a função sigmoid ou logística.\n\nFiltros - Um filtro pode ser visto como uma abstração de um foco quadriculado que desliza por toda a imagem produzindo uma saída para a próxima camada. A saida de cada foco por onde o filtro é aplicado forma um pixel do mapa representativo da imagem, que é então passado à próxima camada. Essa operação de deslizar uma grade de parâmetros pela imagem é chamada de convolução. \n\nCamada Densa - são camadas totalmente conectadas (Fully Connected- FC), \nTransfer Learning : O aprendizado por transferência acelera o treinamento, pois permite reutilizar os modelos de classificação de imagens que já foram previamente treinados, apenas treinando novamente a camada superior da rede que determina as classes às quais uma imagem pode pertencer.\n\nData Augmentation: é uma técnica para criar novos dados de treinamento a partir de dados de treinamento existentes a partir da criação de versões de imagens do dataset de treinamento que pertencem à mesma classe da imagem original. No trabalho utilizamos apenas alguns procedimentos básicos, no caso de ajuste de brilho e normalização da imagem e flip, mas observamos que não favoreceu o modelo.\n\nPróximos passos, pretendemos trabalhar hyperparametros, tuning e buscar outros testes com outras augmentations para ver se favorece o modelo."},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom IPython.display import Image, display\nfrom sklearn.model_selection import GridSearchCV\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.version","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_csv = pd.read_csv('../input/train.csv')\nprint(train_csv.describe())\nprint(train_csv.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Has Cactus\ndisplay(Image('../input/train/train/0004be2cfeaba1c0361d39e2b000257b.jpg'))\ndisplay(Image('../input/train/train/000c8a36845c0208e833c79c1bffedd1.jpg'))\n\n# No cactus\ndisplay(Image('../input/train/train/ffede47a74e47a5930f81c0b6896479e.jpg'))\ndisplay(Image('../input/train/train/fff43acb3b7a23edcc4ae937be2b7522.jpg'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preparação da base de treino e de validação "},{"metadata":{},"cell_type":"markdown","source":"#### Base de treino corresponde a  90% dos arquivos e de teste10%"},{"metadata":{"trusted":true},"cell_type":"code","source":"filenames = ['../input/train/train/' + fname for fname in train_csv['id'].tolist()]\nlabels = train_csv['has_cactus'].tolist()\n\n\ntrain_filenames, test_filenames, train_labels, test_labels = train_test_split(filenames,\n                                                                            labels,\n                                                                            train_size=0.9,\n                                                                            random_state=420)\n\nsize_train = len(train_filenames)\nsize_test = len(test_filenames)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fazendo leitura/carregamento das imagens e redefinindo o tamanho para trabalhar\n#### Normaliza e padroniza o tamanho da imagem"},{"metadata":{"trusted":true},"cell_type":"code","source":"IMAGE_SIZE = 96 \nBATCH_SIZE = 32\n\ndef _parse_fn(filename, label):\n  image_decoded = tf.image.decode_jpeg(tf.io.read_file(filename))\n  image_normalized = (tf.cast(image_decoded, tf.float32)/127.5) - 1\n  image_resized = tf.image.resize(image_normalized, (IMAGE_SIZE, IMAGE_SIZE))\n  #image_resized = _augment_(image_resized) \n  return image_resized, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def _augment_(image):\n       image = tf.image.random_brightness(image,255.0, 1)\n       image = tf.clip_by_value(image, 0.0, 255.0)\n       image = tf.image.rot90(x, tf.random_uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n       return image\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = tf.data.Dataset.from_tensor_slices((tf.constant(train_filenames),tf.constant(train_labels))).map(_parse_fn).shuffle(buffer_size=10000).batch(BATCH_SIZE)\ntest_data = tf.data.Dataset.from_tensor_slices((tf.constant(test_filenames), tf.constant(test_labels))).map(_parse_fn).batch(BATCH_SIZE)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Modelo (pré-)treinado com pesos conhecidos ( Pesos do imagenet)"},{"metadata":{"trusted":true},"cell_type":"code","source":"IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3)\n\nmodelMNV2 = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n                                               include_top=False, \n                                               weights='imagenet')\nmodelMNV2.trainable = False\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pool_layer = tf.keras.layers.GlobalMaxPooling2D()\ndense_layer = tf.keras.layers.Dense(1, activation='relu')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.Sequential([modelMNV2,pool_layer,dense_layer])\nmodel.compile(optimizer= 'Adam',loss='binary_crossentropy',metrics=['accuracy'])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Treinando o modelo com na base aerial cactus"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epochs = 30\nsteps_per_epoch = int(size_train)\nval_steps = 10\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(train_data.repeat(),\n                    epochs=num_epochs,\n                    steps_per_epoch = steps_per_epoch,\n                    validation_data=test_data.repeat(), \n                    validation_steps=val_steps)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save_weights('weights_epoch_30.h5')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history.history['acc']\nval_acc = history.history['val_acc']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_folder = \"../input/test/\"\ntest_datagen = ImageDataGenerator(\n    rescale=1. / 127.5)\n\ntest_generator = test_datagen.flow_from_directory(\n    directory=test_folder,\n    target_size=(96,96),\n    batch_size=32,\n    class_mode='binary',\n    shuffle=False\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred=model.predict_generator(test_generator,verbose=1)\npred_binary = [0 if value<0.50 else 1 for value in pred]  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# aplicando a base de teste\ncsv_file = open(\"submission.csv\",\"w\")\ncsv_file.write(\"id,has_cactus\\n\")\nfor filename, prediction in zip(test_generator.filenames,pred_binary):\n    name = filename.split(\"/\")[1]\n    csv_file.write(str(name)+\",\"+str(prediction)+\"\\n\")\ncsv_file.close()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"name","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# base de teste do treino\n#pred = model.predict(test_data, batch_size=32, verbose=1, steps=55)\n#pred_binary =np.ravel([0 if value<0.50 else 1 for value in pred])  \n#submission_df = pd.DataFrame({'id':test_filenames,'has_cactus':pred_binary})\n#submission_df.to_csv('testedotreino.csv', index=False)\n#pred_binary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Referências\n#### Easy Image Classification with TensorFlow 2.0: TOWARDS DATA SCIENCE . Disponível em: https://towardsdatascience.com/easy-image-classification-with-tensorflow-2-0-f734fee52d13\n\n#### A comprehensive guide to convolutional neural networkds. TOWARDS DATA SCIENCE. Disponível em : https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53\n\n#### WIKIPEDIA. Convolutional Neural Network https://en.wikipedia.org/wiki/Convolutional_neural_network#Max_pooling_shape\n\n#### GITHUB/ Matheus Facure: Resolvendo CAPTCHAs com Redes Neurais Convolucionais. https://matheusfacure.github.io/2017/03/12/cnn-captcha/\n\n#### Frlemarchand: Simple-cnn-using-keras. (Kernel participante da competição). https://www.kaggle.com/frlemarchand/simple-cnn-using-keras"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}