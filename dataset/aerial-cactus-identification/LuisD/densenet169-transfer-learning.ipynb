{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\n\nimport cv2\nimport pandas as pd\nimport numpy as np\nimport json\n\nfrom tqdm import tqdm, tqdm_notebook\n\nimport keras\nfrom keras.models import Sequential, Model\nfrom keras.layers import Conv2D, Dense, MaxPooling2D, Flatten, Dropout\nfrom keras.preprocessing.image import ImageDataGenerator\n\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport os","execution_count":1,"outputs":[{"output_type":"stream","text":"['aerial-cactus-identification', 'densenet-keras']\n","name":"stdout"},{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"\n\n#print(os.listdir(\"../input/densenet-keras/DenseNet-BC-169-32-no-top.h5\"))\ntrain_dir = \"../input/aerial-cactus-identification/train/train/\"\ntest_dir = \"../input/aerial-cactus-identification/test/test/\"\ntrain_df = pd.read_csv('../input/aerial-cactus-identification/train.csv')","execution_count":2,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Loading the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = []\ny = []\nimges = train_df['id'].values\nfor img_id in tqdm_notebook(imges):\n    X.append(cv2.imread(train_dir + img_id))    \n    y.append(train_df[train_df['id'] == img_id]['has_cactus'].values[0])  \nX = np.asarray(X)\nX = X.astype('float32')\nX /= 255\n#y = np.asarray(y)\nprint('Shape of X tensor: ',X.shape)\nprint('Length of target list: ',len(y))\n\n","execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, max=17500), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f633f84f5a8942628f9c9a8e9934c813"}},"metadata":{}},{"output_type":"stream","text":"\nShape of X tensor:  (17500, 32, 32, 3)\nLength of target list:  17500\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Data augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.1)\ny_train = keras.utils.to_categorical(y_train,2)\ny_val = keras.utils.to_categorical(y_val,2)\n\ndatagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True,\n    vertical_flip=True)\n\nval_datagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True,\n    vertical_flip=True)\n","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen.fit(X_train)\nval_datagen.fit(X_val)","execution_count":5,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Loading the DenseNet169 and attaching the final classifier**"},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model = keras.applications.densenet.DenseNet169(include_top=False, input_shape=(32,32,3), \n                                                     weights = '../input/densenet-keras/DenseNet-BC-169-32-no-top.h5')\nbase_model.trainable = False","execution_count":6,"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"**Classifier on top of DenseNet**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#To add the final classifier\nadd_model = Sequential()\nadd_model.add(Flatten(input_shape=base_model.output_shape[1:]))\nadd_model.add(Dense(256, activation='relu'))\nadd_model.add(Dropout(0.2))\nadd_model.add(Dense(2, activation='softmax'))\n\nmodel = Model(inputs = base_model.input, outputs = add_model(base_model.output))\nmodel.compile(optimizer='adam',loss='categorical_crossentropy', \n                metrics=['accuracy'])","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fits the model on batches with real-time data augmentation:\nmodel.fit_generator(datagen.flow(X_train, y_train, batch_size=16),\n                    steps_per_epoch=len(X_train) / 16, epochs=100,\n                    validation_data = val_datagen.flow(X_val,y_val), validation_steps=len(X_val) / 16, verbose = 1)","execution_count":13,"outputs":[{"output_type":"stream","text":"Epoch 1/1\n766/765 [==============================] - 187s 244ms/step - loss: 0.1205 - acc: 0.9701 - val_loss: 0.0415 - val_acc: 0.9878\n","name":"stdout"},{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"<keras.callbacks.History at 0x7f1c2af6bda0>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_tst = []\nTest_imgs = []\nfor img_id in tqdm_notebook(os.listdir(test_dir)):\n    X_tst.append(cv2.imread(test_dir + img_id))     \n    Test_imgs.append(img_id)\nX_tst = np.asarray(X_tst)\nX_tst = X_tst.astype('float32')\nX_tst /= 255\n\n","execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, max=4000), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09d8ddb135b54c9c9a12eb1c5a64d4c3"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prediction\ntest_predictions = model.predict(X_tst)\n\n","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(test_predictions)\ntest_predictions_2 = np.argmax(test_predictions, axis = 1)\nprint(test_predictions_2)\nprint(test_predictions_2.shape)","execution_count":27,"outputs":[{"output_type":"stream","text":"[1 1 1 ... 1 1 1]\n(4000,)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df = pd.DataFrame(test_predictions_2, columns=['has_cactus'])\nsub_df['has_cactus'] = sub_df['has_cactus'].apply(lambda x: 1 if x > 0.75 else 0)\n\nsub_df['id'] = ''\ncols = sub_df.columns.tolist()\ncols = cols[-1:] + cols[:-1]\nsub_df=sub_df[cols]\n\nfor i, img in enumerate(Test_imgs):\n    sub_df.set_value(i,'id',img)\n    ","execution_count":28,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:10: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n  # Remove the CWD from sys.path while we load stuff.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df.head()","execution_count":29,"outputs":[{"output_type":"execute_result","execution_count":29,"data":{"text/plain":"                                     id  has_cactus\n0  79ac4cc3b082e0a1defe1be601806efd.jpg           1\n1  e880364d6521c6f3a27748ec62b0e335.jpg           1\n2  74912492b6cdf28c4bfb9c8e1d35af3e.jpg           1\n3  078cfa961183b30693ea2f13f5ff6d17.jpg           1\n4  7fd729184ef182899ce3e7a174fb9bc0.jpg           1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>has_cactus</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>79ac4cc3b082e0a1defe1be601806efd.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>e880364d6521c6f3a27748ec62b0e335.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>74912492b6cdf28c4bfb9c8e1d35af3e.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>078cfa961183b30693ea2f13f5ff6d17.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7fd729184ef182899ce3e7a174fb9bc0.jpg</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"**Submitting**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nsub_df.to_csv('submission.csv',index=False)\n\n","execution_count":30,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}