{"cells":[{"metadata":{},"cell_type":"markdown","source":"### The goal of this kernel is to create a simple Convolution Neural Network that will allow to differentiate images that contains cacti from images that do not. While better results closer to 100% accuracy could be designed using layers from pre-trained models such as VGG16, we want to stick with a fairly simple CNN architecture and see how far we can go, and whether pre-trained layers are even needed."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\nimport os\nfrom shutil import copyfile, move\nfrom tqdm import tqdm\nimport h5py","execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Just a quick check to make verify Tensorflow version and whether the GPU is found."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"print(tf.__version__)\nprint(tf.test.is_gpu_available())","execution_count":2,"outputs":[{"output_type":"stream","text":"1.13.1\nTrue\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Prepare the data"},{"metadata":{},"cell_type":"markdown","source":"In order to prepare the dataset and use Keras' ImageDataGenerator, it was decided to extract the images to a new folder where images are sorted into 2 folders, one for images with cacti, and one for images without. It is, therefore, required to load the .csv file provided to retrieve the groundtruth and copy the files in the right folder."},{"metadata":{"trusted":true},"cell_type":"code","source":"training_df = pd.read_csv(\"../input/train.csv\")\ntraining_df.head()","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"                                     id  has_cactus\n0  0004be2cfeaba1c0361d39e2b000257b.jpg           1\n1  000c8a36845c0208e833c79c1bffedd1.jpg           1\n2  000d1e9a533f62e55c289303b072733d.jpg           1\n3  0011485b40695e9138e92d0b3fb55128.jpg           1\n4  0014d7a11e90b62848904c1418fc8cf2.jpg           1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>has_cactus</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0004be2cfeaba1c0361d39e2b000257b.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000c8a36845c0208e833c79c1bffedd1.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000d1e9a533f62e55c289303b072733d.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0011485b40695e9138e92d0b3fb55128.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0014d7a11e90b62848904c1418fc8cf2.jpg</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"src = \"../input/train/train/\"\ndst = \"../sorted_training/\"\n\nos.mkdir(dst)\nos.mkdir(dst+\"true\")\nos.mkdir(dst+\"false\")\n\nwith tqdm(total=len(list(training_df.iterrows()))) as pbar:\n    for idx, row in training_df.iterrows():\n        pbar.update(1)\n        if row[\"has_cactus\"] == 1:\n            copyfile(src+row[\"id\"], dst+\"true/\"+row[\"id\"])\n        else:\n            copyfile(src+row[\"id\"], dst+\"false/\"+row[\"id\"])","execution_count":4,"outputs":[{"output_type":"stream","text":"100%|██████████| 17500/17500 [00:30<00:00, 579.17it/s]\n","name":"stderr"}]},{"metadata":{},"cell_type":"markdown","source":"I then extract the validation from the folder where I stored the training set. Note that this time, the files are moved and not just copied."},{"metadata":{"trusted":true},"cell_type":"code","source":"src = \"../sorted_training/\"\ndst = \"../sorted_validation/\"\n\nos.mkdir(dst)\nos.mkdir(dst+\"true\")\nos.mkdir(dst+\"false\")\n\nvalidation_df = training_df.sample(n=int(len(training_df)/10))\n\nwith tqdm(total=len(list(validation_df.iterrows()))) as pbar:\n    for idx, row in validation_df.iterrows():\n        pbar.update(1)\n        if row[\"has_cactus\"] == 1:\n            move(src+\"true/\"+row[\"id\"], dst+\"true/\"+row[\"id\"])\n        else:\n            move(src+\"false/\"+row[\"id\"], dst+\"false/\"+row[\"id\"])","execution_count":5,"outputs":[{"output_type":"stream","text":"100%|██████████| 1750/1750 [00:00<00:00, 6710.81it/s]\n","name":"stderr"}]},{"metadata":{},"cell_type":"markdown","source":"# Load the dataset"},{"metadata":{},"cell_type":"markdown","source":"Even though it is considered good practice to import all libraries at the beginning of a script, I tend to import the ones related to the model architecture right before, as it makes them visible and gives expectations to a reader as to what to find in the architecture."},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import InputLayer, Input\nfrom tensorflow.keras.layers import Conv2D, Dense, Flatten, Dropout, Activation\nfrom tensorflow.keras.layers import BatchNormalization, Reshape, MaxPooling2D, GlobalAveragePooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint","execution_count":6,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The dataset being relatively small, data augmentation is very important to generalise and learn what a cactus look like. Based on the fact that cactus detection seems like an easy problem and we're dealing with a small amount of data, the batch size is kept small as training will be quick anyway."},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 64\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1. / 255,\n    horizontal_flip=True,\n    vertical_flip=True)\n\ntrain_data_dir = \"../sorted_training\"\ntrain_generator = train_datagen.flow_from_directory(\n    train_data_dir,\n    shuffle=True,\n    target_size=(32, 32),\n    batch_size=batch_size,\n    class_mode='binary')\n\n\nvalidation_datagen = ImageDataGenerator(rescale=1. / 255)\nvalidation_data_dir = \"../sorted_validation\"\nvalidation_generator = validation_datagen.flow_from_directory(\n    validation_data_dir,\n    target_size=(32, 32),\n    batch_size=batch_size,\n    class_mode='binary')\n\ninput_shape = (32,32,3)\nnum_classes = 2\n","execution_count":7,"outputs":[{"output_type":"stream","text":"Found 15750 images belonging to 2 classes.\nFound 1750 images belonging to 2 classes.\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Model Creation: Convolutional Neural Network"},{"metadata":{},"cell_type":"markdown","source":"Some really insightful comments about deep learning model optimization can be found here (https://karpathy.github.io/2019/04/25/recipe/ ). "},{"metadata":{"trusted":true},"cell_type":"code","source":"dropout_dense_layer = 0.6\n\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), input_shape=input_shape))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(32, (3, 3)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(32, (3, 3)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(128, (3, 3)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\n\nmodel.add(Flatten())\nmodel.add(Dense(1024))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(dropout_dense_layer))\n\nmodel.add(Dense(256))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(dropout_dense_layer))\n\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))","execution_count":9,"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\nWARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss=keras.losses.binary_crossentropy,\n              optimizer=keras.optimizers.Adam(lr=0.001),\n              metrics=['accuracy'])","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"callbacks = [EarlyStopping(monitor='val_loss', patience=25),\n             ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]","execution_count":11,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 100\nhistory = model.fit_generator(train_generator,\n          validation_data=validation_generator,\n          epochs=epochs,\n          verbose=1,\n          shuffle=True,\n          callbacks=callbacks)","execution_count":12,"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nEpoch 1/100\n28/28 [==============================] - 1s 45ms/step - loss: 2.6307 - acc: 0.2646\n247/247 [==============================] - 16s 64ms/step - loss: 0.1438 - acc: 0.9426 - val_loss: 2.6307 - val_acc: 0.2646\nEpoch 2/100\n28/28 [==============================] - 1s 46ms/step - loss: 0.1593 - acc: 0.9474\n247/247 [==============================] - 14s 56ms/step - loss: 0.0698 - acc: 0.9751 - val_loss: 0.1593 - val_acc: 0.9474\nEpoch 3/100\n28/28 [==============================] - 1s 43ms/step - loss: 0.3698 - acc: 0.8411\n247/247 [==============================] - 13s 51ms/step - loss: 0.0555 - acc: 0.9817 - val_loss: 0.3698 - val_acc: 0.8411\nEpoch 4/100\n28/28 [==============================] - 1s 41ms/step - loss: 0.0740 - acc: 0.9754\n247/247 [==============================] - 13s 51ms/step - loss: 0.0391 - acc: 0.9876 - val_loss: 0.0740 - val_acc: 0.9754\nEpoch 5/100\n28/28 [==============================] - 1s 42ms/step - loss: 0.2949 - acc: 0.9080\n247/247 [==============================] - 13s 51ms/step - loss: 0.0362 - acc: 0.9871 - val_loss: 0.2949 - val_acc: 0.9080\nEpoch 6/100\n28/28 [==============================] - 1s 42ms/step - loss: 0.0672 - acc: 0.9823\n247/247 [==============================] - 13s 51ms/step - loss: 0.0357 - acc: 0.9886 - val_loss: 0.0672 - val_acc: 0.9823\nEpoch 7/100\n28/28 [==============================] - 1s 42ms/step - loss: 0.0538 - acc: 0.9823\n247/247 [==============================] - 13s 52ms/step - loss: 0.0370 - acc: 0.9888 - val_loss: 0.0538 - val_acc: 0.9823\nEpoch 8/100\n28/28 [==============================] - 1s 47ms/step - loss: 0.1315 - acc: 0.9640: 1s - loss: 0.1348 - ac\n247/247 [==============================] - 13s 54ms/step - loss: 0.0257 - acc: 0.9923 - val_loss: 0.1315 - val_acc: 0.9640\nEpoch 9/100\n28/28 [==============================] - 1s 41ms/step - loss: 0.0540 - acc: 0.9783\n247/247 [==============================] - 13s 53ms/step - loss: 0.0204 - acc: 0.9931 - val_loss: 0.0540 - val_acc: 0.9783\nEpoch 10/100\n28/28 [==============================] - 1s 42ms/step - loss: 0.0721 - acc: 0.9731\n247/247 [==============================] - 13s 52ms/step - loss: 0.0222 - acc: 0.9925 - val_loss: 0.0721 - val_acc: 0.9731\nEpoch 11/100\n28/28 [==============================] - 1s 42ms/step - loss: 2.6292 - acc: 0.7977\n247/247 [==============================] - 13s 51ms/step - loss: 0.0307 - acc: 0.9926 - val_loss: 2.6292 - val_acc: 0.7977\nEpoch 12/100\n28/28 [==============================] - 1s 47ms/step - loss: 0.0434 - acc: 0.9846\n247/247 [==============================] - 13s 53ms/step - loss: 0.0331 - acc: 0.9912 - val_loss: 0.0434 - val_acc: 0.9846\nEpoch 13/100\n28/28 [==============================] - 1s 43ms/step - loss: 0.0275 - acc: 0.9937\n247/247 [==============================] - 13s 53ms/step - loss: 0.0181 - acc: 0.9937 - val_loss: 0.0275 - val_acc: 0.9937\nEpoch 14/100\n108/247 [============>.................] - ETA: 6s - loss: 0.0108 - acc: 0.9961","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-676ed26df417>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m           callbacks=callbacks)\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1424\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1426\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m   def evaluate_generator(self,\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m       \u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1189\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{},"cell_type":"markdown","source":"Display the losses and accuracy of the model over the training and validation sets."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load the test data and evaluate the model"},{"metadata":{},"cell_type":"markdown","source":"Load the best performing model based on the validation loss."},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights(\"best_model.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_folder = \"../input/test/\"\ntest_datagen = ImageDataGenerator(\n    rescale=1. / 255)\n\ntest_generator = test_datagen.flow_from_directory(\n    directory=test_folder,\n    target_size=(32,32),\n    batch_size=1,\n    class_mode='binary',\n    shuffle=False\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred=model.predict_generator(test_generator,verbose=1)\npred_binary = [0 if value<0.50 else 1 for value in pred]  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Generate the submission .csv file."},{"metadata":{"trusted":true},"cell_type":"code","source":"csv_file = open(\"sample_submission_cnn.csv\",\"w\")\ncsv_file.write(\"id,has_cactus\\n\")\nfor filename, prediction in zip(test_generator.filenames,pred_binary):\n    name = filename.split(\"/\")[1].replace(\".tif\",\"\")\n    csv_file.write(str(name)+\",\"+str(prediction)+\"\\n\")\ncsv_file.close()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}