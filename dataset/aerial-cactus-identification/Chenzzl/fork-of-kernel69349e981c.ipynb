{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom PIL import Image\nfrom IPython.display import Image as IM\nimport os\nimport zipfile\nimport pandas as pd\nimport numpy as np\nimport os\nimport time\nimport torch\nfrom torchvision import datasets,transforms\nfrom torch.utils.data import DataLoader,Dataset\nfrom PIL import Image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_csv = pd.read_csv('/kaggle/input/aerial-cactus-identification/train.csv')\ntrain_csv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with zipfile.ZipFile('/kaggle/input/aerial-cactus-identification/train.zip','r') as z:\n    z.extractall('/kaggle/output/kaggle/working')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with zipfile.ZipFile('/kaggle/input/aerial-cactus-identification/test.zip','r') as z:\n    z.extractall('/kaggle/output/kaggle/working')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN_IMG_PATH = \"/kaggle/output/kaggle/working/train\"\nTEST_IMG_PATH = '/kaggle/output/kaggle/working/test'\nLABELS_CSV_PATH = '/kaggle/input/aerial-cactus-identification/train.csv'\nSAMPLE_SUB_PATH = \"/kaggle/input/aerial-cactus-identification/sample_submission.csv\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CactusDataset(Dataset):\n    def __init__(self,img_dir,dataframe,transform=None):\n        self.labels_frame = dataframe\n        self.img_dir = img_dir\n        self.transform = transform\n    def __len__(self):\n        return len(self.labels_frame)\n    def __getitem__(self,idx):\n        image = Image.open(os.path.join(self.img_dir,self.labels_frame.id[idx]))\n        label = self.labels_frame.has_cactus[idx]\n        if self.transform:\n            image = self.transform(image)\n        return [image,label]\n# train_transforms = transforms.Compose([transforms.RandomResizedCrop(224),\n#                                        transforms.RandomHorizontalFlip(0.5),\n#                                        transforms.ToTensor(),\n#                                        transforms.Normalize([0.485, 0.456, 0.406], \n#                                                             [0.229, 0.224, 0.225])])\n# test_transforms = transforms.Compose([transforms.Resize(256),\n#                                       transforms.CenterCrop(224),\n#                                       transforms.ToTensor(),\n#                                       transforms.Normalize([0.485, 0.456, 0.406], \n#                                                            [0.229, 0.224, 0.225])])\ntrain_transforms = transforms.Compose([transforms.RandomHorizontalFlip(0.5),\n                                       transforms.ToTensor(),\n                                       transforms.Normalize([0.485, 0.456, 0.406], \n                                                            [0.229, 0.224, 0.225])])\ntest_transforms = transforms.Compose([\n                                      transforms.ToTensor(),\n                                      transforms.Normalize([0.485, 0.456, 0.406], \n                                                           [0.229, 0.224, 0.225])])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dframe = pd.read_csv(LABELS_CSV_PATH)\ncut = int(len(dframe)*0.9)\ntrain, test = np.split(dframe, [cut], axis=0)\ntest = test.reset_index(drop=True)\n\ntrain_ds = CactusDataset(TRAIN_IMG_PATH, train, train_transforms)\ntest_ds = CactusDataset(TRAIN_IMG_PATH, test, test_transforms)\ndatasets = {\"train\": train_ds, \"val\": test_ds}\ntrainloader = DataLoader(train_ds, batch_size=32,\n                        shuffle=True, num_workers=0)\n\ntestloader = DataLoader(test_ds, batch_size=32,\n                        shuffle=True, num_workers=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in testloader:\n    print(i[0].shape)\n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super(Net,self).__init__()\n        self.conv1 = nn.Conv2d(3,64,3,1,padding=1)\n        self.conv2 = nn.Conv2d(64,64,3,1,padding=1)\n        self.conv3 = nn.Conv2d(64,128,3,1,padding=1)\n        self.conv4 = nn.Conv2d(128,128,3,1,padding=1)\n        self.conv5 = nn.Conv2d(128,256,3,1,padding=1)\n        self.conv6 = nn.Conv2d(256,256,3,1,padding=1)\n        self.conv7 = nn.Conv2d(256,256,3,1,padding=1)\n        self.fc1 = nn.Linear(256*4*4,2048)\n#         self.bn1 = nn.BatchNorm1d(num_features=2048)\n        self.fc2 = nn.Linear(2048,1024)\n#         self.bn2 = nn.BatchNorm1d(num_features=1024)\n        self.fc3 = nn.Linear(1024,2)\n    def forward(self,x):\n        \n        x = self.conv1(x) \n        x = F.relu(x)\n        x = self.conv2(x)\n        x = F.relu(x)\n        x = F.max_pool2d(x,2,2) #112 \n        x = self.conv3(x) \n        x = F.relu(x)\n        x = self.conv4(x)\n        x = F.relu(x)\n        x = F.max_pool2d(x,2,2) #56\n        x = self.conv5(x) \n        x = F.relu(x)\n        x = self.conv6(x) \n        x = F.relu(x)\n        x = self.conv7(x)\n        x = F.relu(x)\n        x = F.max_pool2d(x,2,2) #28\n        x = self.fc1(x.view(-1,256*4*4))\n        x = F.relu(x)\n        x = F.dropout(x,p=0.5)\n#         x = self.bn1(x)\n        x = self.fc2(x)\n        x = F.relu(x)\n        x = F.dropout(x,p=0.5)\n#         x = self.bn2(x)\n        x = self.fc3(x)\n        return F.log_softmax(x, dim=1)\n        \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nlr = 0.003\nmomentum  = 0.5\nmodel = Net().to(device)\noptimizer = torch.optim.SGD(model.parameters(),lr=lr,momentum=momentum)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(model ,device, train_loader,optimizer,epoch):\n    model.train()\n    for idx,(data, target) in enumerate(train_loader):\n        data, target = data.to(device),target.to(device)\n        data = data.view(-1,3,32,32)\n        pred = model(data)\n        loss = F.nll_loss(pred, target)\n            \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        if idx % 100 == 0:\n            print(\"Train Epoch: {}, iteration: {}, Loss: {}\".format(\n                epoch, idx, loss.item()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test(model, device, test_loader):\n    model.eval()\n    total_loss = 0.\n    correct = 0.\n    with torch.no_grad():\n        for idx, (data, target) in enumerate(test_loader):\n            data, target = data.to(device), target.to(device)\n            data = data.view(-1,3,32,32)\n            output = model(data) # batch_size * 10\n            total_loss += F.nll_loss(output, target, reduction=\"sum\").item() \n            pred = output.argmax(dim=1) # batch_size * 1\n            correct += pred.eq(target.view_as(pred)).sum().item()\n            \n\n    total_loss /= len(test_loader.dataset)\n    acc = correct/len(test_loader.dataset) * 100.\n    \n    print(\"Test loss: {}, Accuracy: {}\".format(total_loss, acc))\n    return acc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nnum_epoch = 200\nfor epoch in range(num_epoch):\n    train(model,device,trainloader,optimizer,epoch)\n    acc = test(model,device,testloader)\n    if acc>=99.8 and epoch>150:\n        print('acc={}'.format(acc),'End...')\n        break\n\n        \n# torch.save(model.state_dict,\"cactus.pt\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df = pd.read_csv(SAMPLE_SUB_PATH)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_ds = CactusDataset(TEST_IMG_PATH, sub_df, test_transforms)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_transforms = transforms.Compose([\n                                      transforms.ToTensor(),\n                                      transforms.Normalize([0.485, 0.456, 0.406], \n                                                           [0.229, 0.224, 0.225])])\n\nsubloader = DataLoader(sub_ds, batch_size=1,\n                        shuffle=False, num_workers=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_data = pd.read_csv('/kaggle/input/aerial-cactus-identification/sample_submission.csv')\n# list =[]\n# for i in range(len(test_data)):\n# #     print(test_data.iloc[i][0])\n#     image = Image.open(os.path.join('/kaggle/output/kaggle/working/test',test_data.iloc[i][0]))\n#     list.append(np.array(image)/255)\n    \n# test_tensor = torch.Tensor(list)\n# test_tensor = test_tensor.view(-1,3,32,32)\n# loader = torch.utils.data.DataLoader(\n#     test_tensor,\n#     batch_size=batch_size,shuffle=False,\n#     num_workers=1,pin_memory=True)\nresult = np.array([])\nwith torch.no_grad():\n    for i in subloader:\n#         print(i[0])\n#         break\n        v = model(i[0].to(device)).to('cpu').numpy().argmax(axis=1)\n#         print(v)\n        result = np.append(result,v)\nsub_df.has_cactus = result\nsub_df.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(subloader)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}