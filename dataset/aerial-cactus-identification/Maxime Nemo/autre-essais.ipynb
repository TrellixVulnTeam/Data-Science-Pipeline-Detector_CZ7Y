{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, MaxPool2D , Flatten, Dropout\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nimport zipfile\nfrom PIL import Image\nimport shutil\nimport os\nfrom keras.preprocessing.image import ImageDataGenerator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with zipfile.ZipFile(\"/kaggle/input/aerial-cactus-identification/train.zip\",\"r\") as z:\n    z.extractall(\".\")\n    \n#    print(z.namelist())\n\n# img = mpimg.imread('train/008bd3d84a1145e154409c124de7cee9.jpg')\n# imgplot = plt.imshow(img)\n# plt.show()\n\n\ndata = pd.read_csv(\"/kaggle/input/aerial-cactus-identification/train.csv\")\npath = data[\"id\"]\nvalue = data[\"has_cactus\"]\n\n\nx_train_0 = []\nx_train_1 = []\ny_train_0 = []\ny_train_1 = []\n\nfor i in range(17500):\n    im = Image.open(\"train/\" + str(path[i]))\n    data_img = np.array(im.getdata())\n    data_img = data_img.reshape((32,32,3))\n    if int(value[i]) == 0:   \n        x_train_0.append(data_img)\n        y_train_0.append(value[i])\n    else:\n        x_train_1.append(data_img)\n        y_train_1.append(value[i])\n\n        \n        \ntaille = min(len(x_train_0), len(x_train_1))\nx_train = x_train_0[:taille] + x_train_1[:taille]\ny_train = y_train_0[:taille] + y_train_1[:taille]\n\n\nx_train = np.array(x_train)\ny_train = np.array(y_train)\n\n\n\nwith zipfile.ZipFile(\"/kaggle/input/aerial-cactus-identification/test.zip\",\"r\") as z:\n    z.extractall(\".\")\n\nx_test = []\npath_list = []  # Pour avoir le nom des images plus tard\nfor path in z.namelist()[1:]:\n    path_list.append(path[5:])\n    im = Image.open(path)\n    data_img = np.array(im.getdata())\n    data_img = data_img.reshape((32,32,3))\n    x_test.append(data_img)\n\nx_test = np.array(x_test)\n    \nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train = x_train/255\nx_test = x_test/255\ny_train = tf.keras.utils.to_categorical(y_train)\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    horizontal_flip=True,\n    vertical_flip=True,\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# On va creer le mod√®le :\nmodel = Sequential()\n\nmodel.add(Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:], activation='relu'))\nmodel.add(Conv2D(32, (3, 3), activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(2, activation='softmax'))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import ReduceLROnPlateau\nreduce_lr = ReduceLROnPlateau(\n            monitor = \"val_accuracy\",\n            factor=0.2,\n            patience=2,\n            min_lr=0.001)\n\nfrom keras.callbacks import ModelCheckpoint\ncheckpointer = ModelCheckpoint(filepath='model.hdf5', verbose=1, save_best_only=True)\n\n\nmodel.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n\nhistory = model.fit(datagen.flow(x_train, y_train, batch_size=1000), epochs=50,\n                    validation_data=(x_val, y_val),\n                    callbacks=[reduce_lr, checkpointer])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_history(history):\n    \"\"\"\n    plot l'accuracy et la loss\n    \"\"\"\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'val'], loc='upper left')\n    plt.show()\n\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'val'], loc='upper left')\n    plt.show()\nplot_history(history)\n\n\nmodel.load_weights('model.hdf5')\n\nmodel.evaluate(x_val,y_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resultat = model.predict(x_test)\nresultat = np.argmax(resultat,axis = 1)\nresultat = pd.Series(resultat,name=\"has_cactus\")\n\n\n\ndf=pd.DataFrame({'id':path_list})\ndf['has_cactus']=resultat\ndf.to_csv(\"submission.csv\",index=False)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.listdir('.'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shutil.rmtree(\"./train\")\nshutil.rmtree(\"./test\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}