{"cells":[{"metadata":{},"cell_type":"markdown","source":"# My First Rodeo with FastAI\nThis is my first try with fastai so I'll keep it simple. Let me know where I could've done better."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom fastai import vision\nfrom fastai import metrics\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_imgs_path = '../input/train/train'\ntest_imgs_path = '../input/test/test'\nlabels_path = '../input/train.csv'\nin_path = '../input/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(labels_path)\ndf['id'] = 'train/train/' + df['id']\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.has_cactus.hist(grid=False, figsize=(5, 4), bins=np.arange(3)-0.3, width=0.6)\nplt.xticks([0, 1])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Number of images with cactus are ~3 times more than number of images without cactus. This might cause a bias towards presence of cactus. Let's see if transforms in fastai can handle this!"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data = vision.ImageDataBunch.from_df(in_path, df, ds_tfms=vision.get_transforms(), size=224)\ndata = data.normalize(vision.imagenet_stats)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.show_batch(rows=3, figsize=(10, 8))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = vision.cnn_learner(data, vision.models.resnet34, metrics=metrics.accuracy)\nlearn.fit(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"`learn.save('stage-1')` throws error as `../input/models` is read only. Work around might be `torch.save(fastai.get_model(learn.model).state_dict(), 'stage-1')`. If you want to save optimizer as well then:\n\n```\nstate = {'model': fastai.get_model(learn.model).state_dict(), 'opt':learn.opt.state_dict()}\ntorch.save(state, 'stage-1')\n```\n\nWe can certainly unfreeze and then fine-tune the model! But the model above seems preety good to me!\n\nLet's interpret the results we got!"},{"metadata":{"trusted":true},"cell_type":"code","source":"interp = vision.ClassificationInterpretation.from_learner(learn)\n\nlosses,idxs = interp.top_losses()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"interp.plot_top_losses(9, figsize=(15,11))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"interp.plot_confusion_matrix(figsize=(5,5), dpi=60)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since there are only 2 classes, we certainly doesn't need to call `learn.most_confused(...)`.\n\nFinally Predictions!"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df = pd.read_csv('../input/sample_submission.csv')\nfiles = submission_df['id'].values\nimg_paths = ('../input/test/test/' + submission_df['id']).values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_paths[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm\npreds = []\n\nfor p in tqdm(img_paths):\n    pred = learn.predict(vision.open_image(p))[-1].numpy()\n    preds.append(pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df['has_cactus'] = np.array(preds)[:, 1]\nsubmission_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.sum(np.array(preds)[:, 1] > 0.5), submission_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}