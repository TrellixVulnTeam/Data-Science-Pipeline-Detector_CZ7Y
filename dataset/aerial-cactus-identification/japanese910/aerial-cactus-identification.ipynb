{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\"\"\"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\"\"\"\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport os\nimport cv2\nimport numpy as np\nimport pandas as pd\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_label = pd.read_csv(\"/kaggle/input/aerial-cactus-identification/train.csv\")\nsubmission = pd.read_csv(\"/kaggle/input/aerial-cactus-identification/sample_submission.csv\")\n\nlist_0 = []\nlist_1 = []\n\nfor i in train_label[\"has_cactus\"]:\n    if i == 0:\n        list_0.append(i)\n    else:\n        list_1.append(i)\n        \ntrain_images = []\ntrain_labels = []\ntest_images = []\n\nfor i in train_label[\"has_cactus\"]:\n    train_labels.append(i)\n\ntrain_file = os.listdir(\"/kaggle/input/aerial-cactus-identification/train/train/\")\ntrain_file.sort()\ntest_file = os.listdir(\"/kaggle/input/aerial-cactus-identification/test/test/\")\ntest_file.sort()\n\nfor image_name in train_file:\n    img = cv2.imread(\"/kaggle/input/aerial-cactus-identification/train/train/\"+image_name)\n    train_images.append(img)\n\nfor image_name in test_file:\n    img = cv2.imread(\"/kaggle/input/aerial-cactus-identification/test/test/\"+image_name)\n    test_images.append(img)\n    \ntrain_images = np.array(train_images)/255\ntrain_labels = np.array(train_labels)\ntest_images = np.array(test_images)/255\n\ntrain_images.shape, train_labels.shape, test_images.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom keras.utils.np_utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D, Lambda, LeakyReLU\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.optimizers import Adam\nfrom keras.callbacks import LearningRateScheduler, ModelCheckpoint\n\nmodel = Sequential()\nmodel.add(Conv2D(64, (3,3), padding='same', input_shape=(32, 32, 3)))\nmodel.add(BatchNormalization(momentum=0.5, epsilon=1e-5, gamma_initializer=\"uniform\"))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(Conv2D(64,  (3,3), padding='same'))\nmodel.add(BatchNormalization(momentum=0.1, epsilon=1e-5, gamma_initializer=\"uniform\"))\n          \nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(MaxPooling2D(2, 2))\nmodel.add(Dropout(0.2))\n          \nmodel.add(Conv2D(128, (3,3), padding='same'))\nmodel.add(BatchNormalization(momentum=0.2, epsilon=1e-5, gamma_initializer=\"uniform\"))\nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(Conv2D(128,  (3,3), padding='same'))\nmodel.add(BatchNormalization(momentum=0.1, epsilon=1e-5, gamma_initializer=\"uniform\"))       \n          \nmodel.add(LeakyReLU(alpha=0.1))\nmodel.add(MaxPooling2D(2, 2))\nmodel.add(Dropout(0.2))  \n          \nmodel.add(Conv2D(256, (3,3), padding='same'))\nmodel.add(BatchNormalization(momentum=0.2, epsilon=1e-5, gamma_initializer=\"uniform\"))\nmodel.add(LeakyReLU(alpha=0.1))\n          \nmodel.add(Conv2D(128, (3,3), padding='same'))\nmodel.add(BatchNormalization(momentum=0.1, epsilon=1e-5, gamma_initializer=\"uniform\"))\nmodel.add(LeakyReLU(alpha=0.1))\n          \nmodel.add(MaxPooling2D(2, 2))\nmodel.add(Dropout(0.2))\n          \nmodel.add(Flatten())        \nmodel.add(Dense(256,activation='relu',name='dense1'))\nmodel.add(LeakyReLU(alpha=0.1))          \nmodel.add(BatchNormalization())\nmodel.add(Dense(1,activation='sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"initial_learningrate=1e-3\n\ndef lr_decay(epoch):\n    return initial_learningrate * 0.99 ** epoch\n\ncheckpoint = ModelCheckpoint(filepath='/kaggle/working/best_model.h5',monitor='val_loss', verbose=1, save_best_only=True)\n    \nmodel.compile(loss=\"binary_crossentropy\", optimizer=Adam(lr=initial_learningrate), metrics=[\"acc\"])\nmodel.fit(train_images,train_labels,epochs=100,batch_size=128,callbacks=[LearningRateScheduler(lr_decay,verbose=1),checkpoint],validation_split=0.2,verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime\nfrom keras.models import load_model\n\nbest_model = load_model(\"/kaggle/working/best_model.h5\")\npred = best_model.predict(test_images,verbose=1)\n\nresults = []\nfor i in range(len(pred)):\n    if pred[i] >= 0.5:\n        results.append(1)\n    else:\n        results.append(0)\n\n\nsubmissions=pd.DataFrame({\"id\": submission[\"id\"], \"has_cactus\": results})\nsubmissions.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}