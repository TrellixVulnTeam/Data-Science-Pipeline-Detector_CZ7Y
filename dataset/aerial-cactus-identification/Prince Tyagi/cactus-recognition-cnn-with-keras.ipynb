{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport tensorflow as tf\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D,DepthwiseConv2D, Dense, Flatten, Dropout, BatchNormalization, LeakyReLU,GlobalAveragePooling2D, Activation, Average,AveragePooling2D\nimport matplotlib.pyplot as plt\nfrom keras.optimizers import Adam,Adamax\nfrom keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, TensorBoard\nimport seaborn as sns\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"bas_dir=os.path.join('..','input')\ncsv_train=pd.read_csv(os.path.join(bas_dir,'train.csv'))\ntrain_dir=os.path.join(bas_dir,'train/train')\ntest_dir=os.path.join(bas_dir,'test/test')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"csv_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''count=csv_train['has_cactus'].value_counts()\nprint(count)\ncount.plot(kind=\"bar\")\nplt.show()'''\nsns.countplot(x = 'has_cactus',\n              data = csv_train,\n              order = csv_train['has_cactus'].value_counts().index)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using Image Generator to preprocess the data\ncsv_train['has_cactus']=csv_train['has_cactus'].astype('str')\nbatch_size = 100\ntrain_size = 15750\nvalidation_size = 1750\n\ndatagen = ImageDataGenerator(\n    rescale=1./255,\n    horizontal_flip=True,\n    vertical_flip=True,\n    validation_split=0.1,\n    zoom_range =0.3,\n    zca_whitening = False\n    )\n\ndata_args = {\n    \"dataframe\": csv_train,\n    \"directory\": train_dir,\n    \"x_col\": 'id',\n    \"y_col\": 'has_cactus',\n    \"featurewise_center\" : True,\n    \"featurewise_std_normalization\" : True,\n    \"samplewise_std_normalization\" : False,\n    \"samplewise_center\" : False,\n    \"shuffle\": True,\n    \"target_size\": (32, 32),\n    \"batch_size\": batch_size,\n    \"class_mode\": 'binary'\n}\n\ntrain_generator = datagen.flow_from_dataframe(**data_args, subset='training')\nvalidation_generator = datagen.flow_from_dataframe(**data_args, subset='validation')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Plotting Images\ndef plot_images():\n    f,ax=plt.subplots(3,20,figsize=(10,10))\n    print(ax.shape)\n    for j in range(ax.shape[0]):\n        for i  in range(ax.shape[1]):\n            image = next(train_generator)\n            img = array_to_img(image[0][0])\n            ax[j][i].imshow(img)\n            ax[j][i].axis(\"off\")\n    plt.subplots_adjust(wspace=0, hspace=1)\n    plt.show()\n    plt.axis(\"off\")\n    plt.title(\"Images\", fontsize=18)\n    \nplot_images()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Architecture\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def Le_Conv():\n    model = Sequential()\n    model.add(Conv2D(6, kernel_size=(3, 3), strides=(1, 1), activation='relu', input_shape=(32, 32, 3), padding=\"same\"))\n    model.add(AveragePooling2D(pool_size=(2, 2), strides=(1, 1), padding='valid'))\n    model.add(Conv2D(16, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding='valid'))\n    model.add(AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n    model.add(Conv2D(120, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding='valid'))\n    model.add(Flatten())\n    model.add(Dense(84, activation='relu'))\n    model.add(Dense(1, activation='sigmoid'))\n    model.compile(optimizer =  Adamax(lr =0.001) , loss = \"binary_crossentropy\", metrics=[\"acc\"])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_history=Le_Conv().fit_generator(train_generator,\n              validation_data=validation_generator,\n              steps_per_epoch=train_size//batch_size,\n              validation_steps=validation_size//batch_size,\n              epochs=100, verbose=1, \n              shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv(os.path.join(bas_dir, \"sample_submission.csv\"))\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv(os.path.join(bas_dir, \"sample_submission.csv\"))\nimport cv2\ntest_images = []\nimages = test_df['id'].values\nfor image_id in images:\n    test_images.append(cv2.imread(os.path.join(test_dir, image_id)))\n    \ntest_images = np.asarray(test_images)\ntest_images = test_images / 255.0\nprint(\"Number of Test set images: \" + str(len(test_images)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict = Le_Conv().predict(test_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df['has_cactus'] = predict\ntest_df.round(2)\ntest_df.to_csv('aerial-cactus-submission.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}