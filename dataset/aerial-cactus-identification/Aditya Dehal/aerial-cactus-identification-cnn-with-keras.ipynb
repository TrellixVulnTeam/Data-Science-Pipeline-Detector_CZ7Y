{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Aerial Cactus Identification"},{"metadata":{},"cell_type":"markdown","source":"In this kernel we will use Convolutional Neural Networks to build a model that can identify if there is a cactus in an image. **If you found this kernel useful then please consider upvoting :)**"},{"metadata":{},"cell_type":"markdown","source":"Here we will use [Keras](https://keras.io/) library to create the CNN.\n\nWe will create this kernel in four main steps:\n* Get the data\n* Visualise the data\n* Implement the model\n* Make predictions"},{"metadata":{},"cell_type":"markdown","source":"## Getting Started"},{"metadata":{},"cell_type":"markdown","source":"This is the first step in our pipeline. In this step we will import the required libraries and then we will import the training and test data."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Import Libraries\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport cv2 \nimport os\n\nimport keras.backend as k\nimport tensorflow as tf\n\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting the training images and labels\ntrain = pd.read_csv('../input/train.csv')\n\ntrain_labels = train['has_cactus']\ntrain_images = []\n\nfor img in tqdm(train['id']):\n    img_path = '../input/train/train/'+img;\n    train_images.append(cv2.resize(cv2.imread(img_path), (70, 70)))\ntrain_X = np.asarray(train_images)\ntrain_Y = pd.DataFrame(train_labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualising the Data"},{"metadata":{},"cell_type":"markdown","source":"Now let's visualise images and labels in the dataset to get a little bit of intuition about the data. Here we have displayed an image for each label."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title(train_Y['has_cactus'][0])\n_ = plt.imshow(train_X[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title(train_Y['has_cactus'][1000])\n_ = plt.imshow(train_X[1000])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here, we will split the dataset into training and test set data. We will use the training data for training purposes and test data will help us analyse how well our model works on previously unseen data elements. We have used scikit-learn's [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function for this purpose."},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(train_X, train_Y, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Implementing the model"},{"metadata":{},"cell_type":"markdown","source":"### Convolutional Neural Networks"},{"metadata":{},"cell_type":"markdown","source":"In this kernel we will be using a CNN implemented with the help of Keras for required task."},{"metadata":{},"cell_type":"markdown","source":"CNNs are very much similar to the traditional Neural Networks. CNNs are specially designed for Image recoginition and Computer Vision purposes. They already assume that the input will be an image and hence allows us to encode them accordingly. For more details on CNNs read [this](http://cs231n.github.io/convolutional-networks/)"},{"metadata":{},"cell_type":"markdown","source":"![](https://www.researchgate.net/publication/323227084/figure/fig3/AS:594709642756096@1518801236681/Structure-of-the-convolutional-neural-network.png)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras import layers\nfrom keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization, Activation\nfrom keras.models import Sequential\nfrom keras.preprocessing.image import ImageDataGenerator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ninput_shape = (70, 70, 3)\ndropout_dense_layer = 0.6\n\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), input_shape=input_shape))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(32, (3, 3)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(32, (3, 3)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(128, (3, 3)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\n\nmodel.add(Flatten())\nmodel.add(Dense(1024))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(dropout_dense_layer))\n\nmodel.add(Dense(256))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(dropout_dense_layer))\n\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"opt = keras.optimizers.adam(lr=0.0001, decay=1e-6)\nmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will use the ImageDataGenerator() for processing our Images. It generates tensors of the image data with real-time data augmentation. For more details on how to use it go [here](https://machinelearningmastery.com/image-augmentation-deep-learning-keras/)."},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen.fit(x_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=50), steps_per_epoch=x_train.shape[0], epochs=2, validation_data=(x_test, y_test), verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"[loss, accuracy] = model.evaluate(x_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Test Set Accuracy: '+str(accuracy*100)+\"%\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Making Predictions"},{"metadata":{},"cell_type":"markdown","source":"Finally, we have got a good accuracy and now it's time to make predictions for the test set data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting the test set images\ntest_path = '../input/test/test/'\ntest_images_names = []\n\nfor filename in tqdm(os.listdir(test_path)):\n    test_images_names.append(filename)\n    \ntest_images_names.sort()\n\nimages_test = []\n\nfor image_id in tqdm(test_images_names):\n    images_test.append(np.array(cv2.resize(cv2.imread(test_path + image_id), (70, 70))))\n    \nimages_test = np.asarray(images_test)\nimages_test = images_test.astype('float32')\nimages_test /= 255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# making predictions\nprediction = model.predict(images_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict = []\nfor i in range(len(prediction)):\n    if prediction[i][0]>0.5:\n        answer = prediction[i][0]\n    else:\n        answer = prediction[i][0]\n    predict.append(answer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('../input/sample_submission.csv')\nsubmission['has_cactus'] = predict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating the final submission file\nsubmission.to_csv('sample_submission.csv',index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}