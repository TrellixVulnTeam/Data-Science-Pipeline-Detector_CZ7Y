{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# APRESENTAÇÃO:\n# Trabalho de Reconhecimento de Imagens de Cactus para Competição do Kaggle.\n# Componentes:\n# Ângela Cristina.\n# Marcelo Rangel.\n# Márcio Rodrigues.\n# O Kernel do nosso trabalho partiu da própria base do Kernel: https://www.kaggle.com/silvioakempf/boateazul-dama-de-vermelho","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# IMPORTAÇÃO DE BIBLIOTECAS:\n# Bibliotecas básicas.\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Biblioteca de aprendizado profundo (deep learning) baseada na linguagem de programação LUA.\n# https://en.wikipedia.org/wiki/Torch_(machine_learning)\nimport torch \n\n# Biblioteca para facilitar a análise e processamento de imagens.\n# Guia https://docs.fast.ai/\nfrom fastai import * \nfrom fastai.vision import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CARREGAMENTO DOS DADOS:\n# Lendo os arquivos e adicionando-os a Variáveis.\ntrain_df = pd.read_csv(\"../input/aerial-cactus-identification/train.csv\")\ntest_df = pd.read_csv(\"../input/aerial-cactus-identification/sample_submission.csv\")\n\n# Armazenando as imagens para teste\ntest_img = ImageList.from_df(test_df, path='../input/aerial-cactus-identification/test', folder='test')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# PRIMEIRO BLOCO DE PROCESSAMENTO:\n# Criando Variável com padrões para formatação das imagens.\n# do_flip     : se TRUE, um flip aleatório é aplicado com probabilidade de 0.5\n# flip_vert   : requer do_flip = TRUE. Se for verdadeiro, a imagem pode ser invertida verticalmente ou girada em 90 graus, caso contrário, apenas\n#               uma inversão horizontal é aplicada.\n# max_rotate  : se não for NONE, uma rotação aleatória entre -max_rotate e max_rotate degrees é aplicada com probabilidade p_affine.\n# max_zoom    : se não 1. ou menos, um zoom aleatório entre 1. e max_zoom é aplicado com probabilidade p_affine.\n# max_lighting: se não for NONE, uma alteração aleatória de raio e contraste controlada por max_lighting, é aplicada com probabilidade p_lighting.\n# max_warp    : se não for NONE, uma deformação simétrica aleatória de magnitude entre -max_warp e maw_warp é aplicada com probabilidade p_affine.\n# p_affine    : a probabilidade de cada transformada de afim e dobra simétrica ser aplicada.\n# p_lighting  : a probabilidade de que cada transformação de iluminação seja aplicada.\n\ntrfm2 = get_transforms(do_flip=True, flip_vert=True, max_rotate=0, max_zoom=0, max_lighting=0.2, max_warp=0.2, p_affine=0.5, p_lighting=0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# SEGUNDO BLOCO DE PROCESSAMENTO:\n# Criando o treinamento baseado nas configurações criadas anteriormente, sendo processadas em cima da placa grafica (GPU).\n# split_by_rand_pct: como dividir em treino / validação? -> aleatoriamente, com o padrão de 20% em validação.\n\ntrain_img2 = (ImageList.from_df(train_df, path='../input/aerial-cactus-identification/train', folder='train')\n        .split_by_rand_pct(0.01)\n        .label_from_df()\n        .add_test(test_img)\n        .transform(trfm2, size=128)\n        .databunch(path='.', bs=64, device= torch.device('cuda:0'))\n        .normalize(imagenet_stats)\n       )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# TERCEIRO BLOCO DE PROCESSAMENTO:\n# Aplicando o treinamento no modelo densenet161, que obteve a maior acurácia, tendo sido testados os modelos resnet18, inception_v3 e o\n#          densenet161.\n# Modelos https://pytorch.org/docs/stable/torchvision/models.html\n\nlearn2 = cnn_learner(train_img2, models.densenet161, metrics=[error_rate, accuracy])\n\n# Gerando 5 ciclos de aprendizagem com o slice de 3e-02 que obteve a maior acurácia.\n# Slice : em vez de definir manualmente um LR para cada grupo, geralmente é mais fácil de usar Learner.lr_range.\n#         Este é um método de conveniência que retorna uma taxa de aprendizado para cada grupo de camadas. Se você passar, slice(start, end),\n#         então a taxa de aprendizado do primeiro grupo é start, e a do último end, e as restantes são uniformemente geometricamente espaçadas.\n#         Se você passar só slice(end), então a taxa de aprendizado do último grupo é end, e todos os outros grupos são end/10.\n\nlearn2.fit_one_cycle(5, slice(3e-02))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# FINALIZANDO:\n# Pegando os dados em forma de DataSet.\npreds,_ = learn2.get_preds(ds_type=DatasetType.Test)\n\n# Formatando o DataSet.\ntest_df.has_cactus = preds.numpy()[:, 0]\n\n# Gerando o arquivo para submissão.\ntest_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}