{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Import Libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport cv2\nfrom matplotlib import pyplot as plt\n%matplotlib inline\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# to unzip\nimport zipfile\n\n# Import PyTorch\nimport torchvision.transforms as transforms\nfrom torch.utils.data.sampler import SubsetRandomSampler\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import TensorDataset, DataLoader, Dataset\nimport torchvision\nimport torch.optim as optim","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Unzipping train and test image dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# ref: https://stackoverflow.com/questions/3451111/unzipping-files-in-python/3451150\ndef unzip(path):\n    with zipfile.ZipFile(path,\"r\") as z:\n        z.extractall('.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# unzip train folder\ntrain_zip_path = '../input/train.zip'\nunzip(train_zip_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_zip_path = '../input/test.zip'\nunzip(test_zip_path)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loading csv file for train images"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/train.csv')\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Method for drawing pie chart"},{"metadata":{"trusted":true},"cell_type":"code","source":"def draw_pie_chart(labels, sizes, explode=None):        \n    fig, ax = plt.subplots()\n    ax.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%', shadow=True, startangle=90)\n    ax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n\n    plt.show()    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Number of images for each classes in train set"},{"metadata":{"trusted":true},"cell_type":"code","source":"number_of_images_contains_cactus = train_df.has_cactus.value_counts().loc[1]\nnumber_of_images_does_not_contain_cactus = train_df.has_cactus.value_counts().loc[0]\n\nprint(number_of_images_contains_cactus)\nprint(number_of_images_does_not_contain_cactus)\n\ndraw_pie_chart([\"has_cactus\", \"no_cactus\"], [number_of_images_contains_cactus, number_of_images_does_not_contain_cactus], (0, 0.1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Number images in train and test image folder"},{"metadata":{"trusted":true},"cell_type":"code","source":"number_of_training_images = len(os.listdir('/kaggle/working/train'))\nnumber_of_test_images = len(os.listdir('/kaggle/working/test'))\n\nprint(f\"Total Train Images: {number_of_training_images}\")\nprint(f\"Total Test Images: {number_of_test_images}\")\n\ndraw_pie_chart([\"Total Training Images\", \"Total Test Images\"], [number_of_training_images, number_of_test_images], (0, 0.1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Dataset(Dataset):\n    def __init__(self, dataframe, data_dir, transform=None):\n        super().__init__()\n        self.dataframe = dataframe\n        self.data_dir = data_dir\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.dataframe)\n    \n    def __getitem__(self, index):\n        image_name, label = self.dataframe.iloc[index]\n        image_path = os.path.join(self.data_dir, image_name)\n        image = cv2.imread(image_path)\n        \n        if self.transform != None:\n            image = self.transform(image)\n        \n        return image, label            ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preparing train and validation data"},{"metadata":{"trusted":true},"cell_type":"code","source":"transforms_train_data = transforms.Compose([transforms.ToPILImage(),\n                                      transforms.RandomHorizontalFlip(),\n                                      transforms.RandomRotation(10),\n                                      transforms.ToTensor(),\n                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\ntransforms_train_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = Dataset(train_df, '/kaggle/working/train', transforms_train_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 64\n\nvalidation_size = int(np.floor(0.2*number_of_training_images))\n\nindices = list(range(number_of_training_images))\nnp.random.shuffle(indices)\n\ntrain_indices, validation_indices = indices[validation_size:], indices[:validation_size]\n\ntrain_sampler = SubsetRandomSampler(train_indices)\nvalidation_sampler = SubsetRandomSampler(validation_indices)\n\ntrain_loader = DataLoader(train_data, batch_size=batch_size, sampler=train_sampler)\nvalidation_loader = DataLoader(train_data, batch_size=batch_size, sampler=validation_sampler)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preparing Test Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission_path = \"../input/sample_submission.csv\"\nsample_submission_df = pd.read_csv(sample_submission_path)\nsample_submission_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transform_test_data = transforms.Compose([transforms.ToPILImage(),\n                                     transforms.ToTensor(),\n                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\ntransform_test_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = Dataset(sample_submission_df, '/kaggle/working/test', transform_test_data)\n\ntest_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's see some images"},{"metadata":{"trusted":true},"cell_type":"code","source":"classes  = ['Cactus', 'No Cactus']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_image(image):\n    '''Helper function to un-normalize and display an image'''\n    # unnormalize\n    image = image / 2 + 0.5\n    # convert from Tensor image and display\n    plt.imshow(np.transpose(image, (1, 2, 0)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_iter = iter(train_loader)\nimages, labels = data_iter.next()\nimages = images.numpy() # convert images to numpy for display\n\n# plot the images in the batch, along with the corresponding labels\nfig = plt.figure(figsize=(25, 4))\n# display 20 images\nfor idx in np.arange(10):\n    ax = fig.add_subplot(2, 5, idx+1, xticks=[], yticks=[])\n    show_image(images[idx])\n    print(images[idx].shape)\n    ax.set_title(classes[labels[idx]])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define The Network"},{"metadata":{"trusted":true},"cell_type":"code","source":"class CNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        # Convolutional Layer (sees 32x32x3 image tensor | outputs 16x16x16 image tensor) \n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n        # Convolutional Layer (sees 16x16x16 image tensor | outputs 8x8x32 image tensor)  \n        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n        # Convolutional Layer (sees 8x8x32 image tensor | outputs 4x4x64 image tensor)  \n        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n        # Convolutional Layer (sees 4x4x64 image tensor | outputs 2x2x128 image tensor)  \n        self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)        \n        \n        # batch normalization\n        self.bn1 = nn.BatchNorm2d(16)\n        self.bn2 = nn.BatchNorm2d(32)\n        self.bn3 = nn.BatchNorm2d(64)\n        self.bn4 = nn.BatchNorm2d(128)        \n        \n        # MaxPooling Layer\n        self.pool = nn.MaxPool2d(2, 2)\n        # fully connected layers\n        self.fc1 = nn.Linear(2*2*128, 512)        \n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 2)\n        \n        self.dropout = nn.Dropout(0.2)\n    \n    def forward(self, x):        \n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.pool(x)\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = self.pool(x)\n        x = F.relu(self.bn3(self.conv3(x)))\n        x = self.pool(x)\n        x = F.relu(self.bn4(self.conv4(x)))\n        x = self.pool(x)\n        \n        x = x.view(-1, 2*2*128)\n        x = self.dropout(x)\n        \n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        \n        x = F.relu(self.fc2(x))                        \n        x = self.dropout(x)\n        \n        x = F.relu(self.fc3(x))\n        \n        return x","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training The CNN Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Model:\n    def __init__(self, model, criterion, optimizer, train_on_gpu, train_loader, validation_loader):\n        self.model = model        \n        self.criterion = criterion\n        self.optimizer = optimizer\n        self.train_on_gpu = train_on_gpu                        \n        self.train_loader = train_loader\n        self.validation_loader = validation_loader\n        self.train_losses = []\n        self.validation_losses = []        \n        if self.train_on_gpu:\n            self.model.cuda()\n            \n    def fit(self, epochs=30, show_every=1):\n        self.train_losses = []\n        self.validation_losses = []\n        \n        minimum_validation_loss = np.inf        \n        for epoch in range(epochs):                               \n            train_loss = self.train()\n            self.train_losses.append(train_loss)\n                        \n            validation_loss = self.validate()\n            self.validation_losses.append(validation_loss)   \n            \n            if epoch%show_every == 0:\n                self.print_loss(epoch, train_loss, validation_loss)\n\n            if validation_loss < minimum_validation_loss: \n                self.save_model(minimum_validation_loss, validation_loss)\n                minimum_validation_loss = validation_loss        \n    \n    def train(self):\n        train_loss = 0.0\n\n        self.model.train()\n        for data, target in self.train_loader:\n            if self.train_on_gpu:\n                data, target = data.cuda(), target.cuda()\n\n            self.optimizer.zero_grad()\n\n            output = self.model(data)\n\n            loss = self.criterion(output, target)\n\n            loss.backward()\n\n            self.optimizer.step()\n\n            train_loss += loss.item()*data.size(0)       \n\n\n        train_loss = train_loss/len(self.train_loader.sampler)\n        return train_loss\n        \n    \n    def validate(self):                \n        validation_loss = 0.0\n        \n        self.model.eval()\n        \n        for data, target in self.validation_loader:\n            if self.train_on_gpu:\n                data, target = data.cuda(), target.cuda()\n\n            output = self.model(data)\n\n            loss = self.criterion(output, target)\n\n            validation_loss += loss.item()*data.size(0)\n            \n        validation_loss = validation_loss/len(self.validation_loader.sampler)\n        return validation_loss\n    \n    def print_loss(self, epoch, train_loss, validation_loss):        \n        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(epoch+1, train_loss, validation_loss))        \n    \n    def save_model(self, minimum_validation_loss, validation_loss):\n        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(minimum_validation_loss, validation_loss))            \n        torch.save(model.state_dict(), 'best_model.pt')        \n    \n    def load_best_model(self):\n        self.model.load_state_dict(torch.load('best_model.pt'))\n    \n    def predict(self, test_loader):\n        self.load_best_model()        \n        self.model.eval()\n\n        predictions = []\n\n        for data, target in test_loader:\n            if self.train_on_gpu:\n                    data, target = data.cuda(), target.cuda()\n\n            output = self.model(data)\n\n            prediction = output[:,1].detach().cpu().numpy()\n            for pred in prediction:\n                predictions.append(pred)\n                \n        return predictions\n    \n    def show_loss_graph(self):\n        plt.style.use('seaborn')\n        plt.plot(self.validation_losses, label='Validation loss')\n        plt.plot(self.train_losses, label='Train loss')\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.legend()\n        plt.show()        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check if CUDA is available\ntrain_on_gpu = torch.cuda.is_available()\n\nif not train_on_gpu:\n    print('CUDA is not available.  Training on CPU ...')\nelse:\n    print('CUDA is available!  Training on GPU ...')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = CNN()\n\ncriterion = nn.CrossEntropyLoss()\n\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\ncnn_model = Model(model, criterion, optimizer, train_on_gpu, train_loader, validation_loader)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cnn_model.fit(50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cnn_model.show_loss_graph()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Make Predictions on Test Set"},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = cnn_model.predict(test_loader)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create submission file"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission_df[\"has_cactus\"] = predictions\nsample_submission_df[\"has_cactus\"] = sample_submission_df[\"has_cactus\"].apply(lambda x: 1 if x > 0.75 else 0)\nsample_submission_df.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Removing the unzipped Train and Test image folder"},{"metadata":{"trusted":true},"cell_type":"code","source":"import shutil\n\n\nshutil.rmtree('/kaggle/working/train')\nshutil.rmtree('/kaggle/working/test')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## References - \n1 - https://www.kaggle.com/abhinand05/in-depth-guide-to-convolutional-neural-networks\n\n2 - https://www.kaggle.com/ateplyuk/pytorch-efficientnet"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}