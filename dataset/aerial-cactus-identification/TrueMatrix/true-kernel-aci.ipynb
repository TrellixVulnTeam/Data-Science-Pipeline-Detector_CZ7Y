{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Preprocessing #\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport os\nos.chdir(\"../input\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train-metadata excelsheet preview"},{"metadata":{"trusted":true},"cell_type":"code","source":"meta_data = pd.read_csv(\"train.csv\")\nmeta_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Sorting training data, according to the label provided in the csv spreadsheet"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dir = \"train/train\"\ntest_dir =  \"test/test\"\nos.listdir(train_dir)[:5]\nprint(len(os.listdir(train_dir)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating training, and validation generators for the purpose of feeding data into the network. 15000 to 2500."},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n#######Wiithout data augumentation, just for experimental purposes...#########\n\ntrain_gen = ImageDataGenerator(rescale = 1/255,\n                              horizontal_flip = True,\n                              height_shift_range = 0.2,\n                              width_shift_range = 0.2,\n                              brightness_range = [0.2,1.2],)\n                              #fill_mode=\"nearest\")\nvalid_gen = ImageDataGenerator(rescale=1/255)\n\nmeta_data.has_cactus = meta_data.has_cactus.astype(str)\n\ntrain_generator = train_gen.flow_from_dataframe(\n    dataframe = meta_data[:15000],\n    target_size=(150,150),\n    directory = train_dir,\n    x_col=\"id\",\n    y_col=\"has_cactus\",\n    class_mode = \"binary\"\n)\n\nvalid_generator = valid_gen.flow_from_dataframe(\n    dataframe = meta_data[15000:],\n    target_size = (150,150),\n    directory = train_dir,\n    x_col = \"id\",\n    y_col = \"has_cactus\",\n    class_mode = \"binary\",\n)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Performing transfer learning on the state of the art model VGG19"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow import keras\n\nbase_model = keras.applications.InceptionV3(include_top=False, weights='imagenet', input_tensor=None, input_shape=(150,150,3), pooling=None, classes=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# VGG19 is a state of the art model which has been trained on imagenet dataset\n# For our purposes we select the input shape as (32x32x3), here is the summary of the model.\n# We can see there are 5 blocks of convolution, and pooling layers.\nbase_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#locking all the layers to prevent their training, as we only want to extend it by adding our own Dense layer classifier.\n\nfor layer in base_model.layers:\n    layer.trainable = False\n    \n#Extracting last layer, and collecting it's last output, which we will use to feed into our extended model.\n\nlast_layer = base_model.layers[-1]\nlast_output = last_layer.output\n\n#Adding out own extended version of the model. For simplicity lets take it to 512 neurons in FC layer. And 2 \n#neurons in the last layer for classification purpose.\n\nextend = keras.layers.Flatten()(last_output)\nextend = keras.layers.Dense(512, activation = \"relu\") (extend)\nextend = keras.layers.Dropout(0.4)(extend)\nextend = keras.layers.Dense(1, activation=\"sigmoid\")(extend)\n\n#Defining our extended model now\n\nmodel = keras.models.Model(base_model.input, extend)\n\n#All looks good, let's compile our model now. We'll use loss as categorical_crossentropy, and optimizer as adam\n\nmodel.compile(loss = \"binary_crossentropy\",\n             optimizer=keras.optimizers.Adam(lr = 1e-3),\n             metrics=[\"acc\"])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model training, without troubleshooting any overfitting, just for the sake of experimentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmodel.fit_generator(\n    train_generator,\n    validation_data = valid_generator,\n    verbose = 1,\n    shuffle=True,\n    epochs = 10,\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# First I trained model with different configs, here are the results\n# 512 nodes, adam approx  validation accuracy 97.65\n# 512 nodes, RMSprop with lr=0.001  validation accuracy 97.55\n# 512 nodes, RMSpop with lr= 0.000001  validation accuracy 97.62\n# 1024 nodes, adam approx validation accuracy = 97.75\n# 1024 nodes, first with adam then RMSprop with lr = 0.0000000001 validation_acc = 0.9812\n# 1024 nodes, first with adam then RMSprop with lr = 0.000001 validation_acc = 0.9812\n# 1024 nodes, first with adam then RMSprop with lr = 0.001 validation_acc = 0.9796\n# 1024=>512 nodes, adam validation accuracy = 0.9764-0.9816\n# 1024=>512 nodes, SGD validation accuracy = 0.9804\n# 1024=>512 nodes, SGD->Adam validation accuracy = 0.9824=>0.9800=>0.9875 and more degradation\n# 1024=>512=>dropout  Adam->SGD lr =0.001 validation accuracy = 0.9800\n# 1024=>512=>dropout  Adam->SGD lr = 0.0001 validatio accuracy = 0.9800\n# Selected pool layer from block 3 in an attempt to get a better result, but ended up at validation accuracy = 0.70\n# The training is kinda stuck between 97 to 98.25%, I think a more complex network can help in it, if not let's see how the obtained results perform on test images\n# 1024=>dropout=>512=>dropout=>256=>dropout, adam, validation accuracy =  0.9736\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history.history[\"acc\"]\nloss = history.history[\"loss\"]\nval_acc = history.history[\"val_acc\"]\nval_loss = history.history[\"val_loss\"]\nepochs = range(len(acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n\nplt.plot(epochs, acc, label=\"Training Accuracy\")\nplt.plot(epochs, val_acc, label=\"Validation Accuracy\")\nplt.axis([0, 4, 0.7, 1])\nplt.title(\"Training vs Validation Accuracy\")\nplt.legend()\nplt.figure()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model.save(\"my_model.h5\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predicting the test images"},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir(\"test/test\")[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\nimages = []\n\nfor image in os.listdir(\"test/test\"):\n    images.append( cv2.imread(\"test/test/\" + image))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimage = np.asarray(images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image.resize(4000, 32, 32, 3)\nimage.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = model.predict(image)\nprediction.resize(4000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.DataFrame({\"id\" : os.listdir(test_dir),\n                   \"has_cactus\" : prediction})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv(\"../working/samplesubmission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}