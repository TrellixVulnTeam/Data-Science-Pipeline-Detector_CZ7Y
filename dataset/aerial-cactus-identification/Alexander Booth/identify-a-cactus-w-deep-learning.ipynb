{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/train.csv\")\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom tensorflow import keras\n\nX_train, X_val, Y_train, Y_val = train_test_split(train.id, train.has_cactus, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfrom os.path import join\n\n#load training images\ncatctus_dir = '../input/train/train'\n\n#get full image paths for train/val\ntrain_paths = [join(catctus_dir,filename) for filename in X_train]\nval_paths = [join(catctus_dir,filename) for filename in X_val]\n\ntrain_paths[0:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import Image, display\nfor i, img_path in enumerate(train_paths[0:5]):\n    display(Image(img_path))\n#yup, those are cacti","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import load_img, img_to_array\n\n#image size\nimg_rows, img_cols, image_size = 32, 32, 32\n\ndef read_and_prep_images(img_paths, img_height=image_size, img_width=image_size):\n    imgs = [load_img(img_path, target_size=(img_height, img_width)) for img_path in img_paths]\n    img_array = np.array([img_to_array(img) for img in imgs])\n    output = prep_data(img_array)\n    return(output)\n\n#training data has its labels already split out\ndef prep_data(raw):\n    x = raw[:,0:]\n    num_images = raw.shape[0]\n    out_x = x.reshape(num_images, img_rows, img_cols, 3)\n    out_x = out_x / 255\n    return out_x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = read_and_prep_images(train_paths)\nval_data = read_and_prep_images(val_paths)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.shape(train_data) #14000 train images, 3,500 val images","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow import keras\n#cactus or no\nnum_classes = 2\n\ntrain_labels = keras.utils.to_categorical(Y_train, num_classes)\nval_labels = keras.utils.to_categorical(Y_val, num_classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n#view a couple of the training images\nfor i in range(1,13):\n    plt.subplot(3,4,i)\n    plt.imshow(train_data[i-1])\n#moar cacti","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D\n\n#build the model\ncactus_model = Sequential()\ncactus_model.add(Conv2D(12, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=(img_rows, img_cols, 3))) #activation layer\n\n#additional learning layers\ncactus_model.add(Conv2D(20, kernel_size=(3, 3), padding='valid', activation='relu'))\ncactus_model.add(Conv2D(20, kernel_size=(3, 3), padding='valid', activation='relu'))\ncactus_model.add(Conv2D(20, kernel_size=(3, 3), padding='valid', activation='relu'))\ncactus_model.add(Conv2D(20, kernel_size=(3, 3), padding='valid', activation='relu'))\n\n#final prediction layers\ncactus_model.add(Flatten())\ncactus_model.add(Dense(100, activation='relu'))\ncactus_model.add(Dense(num_classes, activation='softmax'))\n\n#compile the model\ncactus_model.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer='adam',\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#initial fit with validation\nhistory = cactus_model.fit(train_data, train_labels,\n          batch_size=100,\n          epochs=10,\n          validation_data = (val_data, val_labels))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#https://www.kaggle.com/pheaboo/simple-cnn-trained-from-scratch\nplt.figure(figsize=(15,5))\n\nplt.subplot(141)\nplt.plot(history.history['loss'], label='training')\nplt.plot(history.history['val_loss'], label='validation')\nplt.xlabel('# Epochs')\nplt.legend()\nplt.ylabel(\"Loss - Binary Cross Entropy\")\nplt.title('Loss Evolution')\n\nplt.subplot(142)\nplt.plot(history.history['loss'], label='training')\nplt.plot(history.history['val_loss'], label='validation')\nplt.ylim(0,0.3)\nplt.xlabel('# Epochs')\nplt.legend()\nplt.ylabel(\"Loss - Binary Cross Entropy\")\nplt.title('Zoom Near Zero - Loss Evolution')\n\nplt.subplot(143)\nplt.plot(history.history['acc'], label='training')\nplt.plot(history.history['val_acc'], label='validation')\nplt.xlabel('# Epochs')\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.title('Accuracy Evolution')\n\nplt.subplot(144)\nplt.plot(history.history['acc'], label='training')\nplt.plot(history.history['val_acc'], label='validation')\nplt.ylim(0.9,1)\nplt.xlabel('# Epochs')\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.title('Zoom Near One - Accuracy Evolution')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#build the model, same as above\ncactus_model_aug = Sequential()\ncactus_model_aug.add(Conv2D(12, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=(img_rows, img_cols, 3))) #activation layer\n\n#additional learning layers\ncactus_model_aug.add(Conv2D(20, kernel_size=(3, 3), activation='relu'))\ncactus_model_aug.add(Conv2D(20, kernel_size=(3, 3), activation='relu'))\ncactus_model_aug.add(Conv2D(20, kernel_size=(3, 3), activation='relu'))\ncactus_model_aug.add(Conv2D(20, kernel_size=(3, 3), activation='relu'))\n\n#final prediction layers\ncactus_model_aug.add(Flatten())\ncactus_model_aug.add(Dense(100, activation='relu'))\ncactus_model_aug.add(Dense(num_classes, activation='softmax'))\n\n#compile the model\ncactus_model_aug.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer='adam',\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\ndatagen = ImageDataGenerator(featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=True)  # randomly flip images\n\ndatagen.fit(train_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cactus_model_aug.fit_generator(datagen.flow(train_data,train_labels),\n                              epochs = 15, validation_data = (val_data,val_labels), steps_per_epoch=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#aug was NOT better","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dir = '../input/test/test'\ntest_paths = [join(test_dir,filename) for filename in os.listdir(test_dir)]\ntest_paths[0:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(os.listdir(test_dir))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import Image, display\nfor i, img_path in enumerate(test_paths[0:5]):\n    display(Image(img_path))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = read_and_prep_images(test_paths)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.shape(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Get predictions\npreds_test = cactus_model.predict(test_data)\n\n# #the model returns a list of probabilities for each outcome. \nrealPreds = preds_test[:,0]\nrealPreds[0:12]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save test predictions to file\n# no aug performed better\noutput = pd.DataFrame({'id': os.listdir(test_dir),\n                       'has_cactus': realPreds})\noutput.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}