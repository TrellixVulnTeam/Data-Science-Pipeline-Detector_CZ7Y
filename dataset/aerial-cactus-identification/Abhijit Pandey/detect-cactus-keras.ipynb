{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout\nimport cv2\nfrom sklearn.model_selection import train_test_split\nimport os\nimport random\nimport matplotlib.pyplot as plt\n\nprint(os.listdir(\"../input\"))\ntrain_csv = pd.read_csv('../input/train.csv').sample(frac=1).reset_index(drop=True)\nimages = train_csv.id.values.tolist() #some bug causes .values to not be accepted as np array\ntarget = train_csv.has_cactus.values.tolist()\ntrain_X, test_X, train_Y, test_Y = train_test_split(images, target, test_size=0.1, random_state=42)\ndel train_csv, images, target","execution_count":1,"outputs":[{"output_type":"stream","text":"['test', 'sample_submission.csv', 'train.csv', 'train']\n","name":"stdout"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"def get_image(imname):\n    name = os.path.join('../input/train/train', imname)\n    img = cv2.imread(name, 1)\n    img = cv2.resize(img, (32,32))/255\n    return img","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_img = []\nbatch_tar = []\nval_x = []\nval_y = []\nfor i in range(len(train_X)):\n    batch_img.append(np.reshape(get_image(train_X[i]), (32,32,3)))\n    batch_tar.append(train_Y[i])\nfor i in range(len(test_X)):\n    val_x.append(np.reshape(get_image(test_X[i]), (32,32,3)))\n    val_y.append(test_Y[i])\nbatch_img, val_x = np.array(batch_img), np.array(val_x)","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(16, kernel_size=3, padding='same', activation='relu', input_shape=(32,32,3)))\nmodel.add(Conv2D(16, kernel_size=3, padding='same', activation='relu'))\nmodel.add(Conv2D(8, kernel_size=3, padding='same', activation='relu'))\nmodel.add(Flatten())\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","execution_count":5,"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(batch_img, batch_tar, validation_data = (val_x, val_y), epochs = 20)","execution_count":6,"outputs":[{"output_type":"stream","text":"Train on 15750 samples, validate on 1750 samples\nWARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nEpoch 1/20\n15750/15750 [==============================] - 5s 319us/sample - loss: 0.2187 - acc: 0.9126 - val_loss: 0.1023 - val_acc: 0.9657\nEpoch 2/20\n15750/15750 [==============================] - 2s 132us/sample - loss: 0.1079 - acc: 0.9602 - val_loss: 0.0627 - val_acc: 0.9766\nEpoch 3/20\n15750/15750 [==============================] - 2s 131us/sample - loss: 0.0826 - acc: 0.9705 - val_loss: 0.0747 - val_acc: 0.9720\nEpoch 4/20\n15750/15750 [==============================] - 2s 129us/sample - loss: 0.0715 - acc: 0.9751 - val_loss: 0.0447 - val_acc: 0.9823\nEpoch 5/20\n15750/15750 [==============================] - 2s 130us/sample - loss: 0.0646 - acc: 0.9772 - val_loss: 0.0998 - val_acc: 0.9583\nEpoch 6/20\n15750/15750 [==============================] - 2s 135us/sample - loss: 0.0559 - acc: 0.9804 - val_loss: 0.0342 - val_acc: 0.9851\nEpoch 7/20\n15750/15750 [==============================] - 2s 139us/sample - loss: 0.0401 - acc: 0.9855 - val_loss: 0.0308 - val_acc: 0.9874\nEpoch 8/20\n15750/15750 [==============================] - 2s 149us/sample - loss: 0.0362 - acc: 0.9863 - val_loss: 0.0244 - val_acc: 0.9891\nEpoch 9/20\n15750/15750 [==============================] - 2s 143us/sample - loss: 0.0256 - acc: 0.9919 - val_loss: 0.0455 - val_acc: 0.9829\nEpoch 10/20\n15750/15750 [==============================] - 2s 147us/sample - loss: 0.0209 - acc: 0.9941 - val_loss: 0.0171 - val_acc: 0.9931\nEpoch 11/20\n15750/15750 [==============================] - 2s 141us/sample - loss: 0.0193 - acc: 0.9933 - val_loss: 0.0182 - val_acc: 0.9931\nEpoch 12/20\n15750/15750 [==============================] - 2s 130us/sample - loss: 0.0144 - acc: 0.9957 - val_loss: 0.0358 - val_acc: 0.9874\nEpoch 13/20\n15750/15750 [==============================] - 2s 129us/sample - loss: 0.0135 - acc: 0.9952 - val_loss: 0.0174 - val_acc: 0.9937\nEpoch 14/20\n15750/15750 [==============================] - 2s 132us/sample - loss: 0.0098 - acc: 0.9967 - val_loss: 0.0227 - val_acc: 0.9926\nEpoch 15/20\n15750/15750 [==============================] - 2s 131us/sample - loss: 0.0053 - acc: 0.9988 - val_loss: 0.0167 - val_acc: 0.9943\nEpoch 16/20\n15750/15750 [==============================] - 2s 129us/sample - loss: 0.0070 - acc: 0.9978 - val_loss: 0.0154 - val_acc: 0.9949\nEpoch 17/20\n15750/15750 [==============================] - 2s 129us/sample - loss: 0.0090 - acc: 0.9972 - val_loss: 0.0193 - val_acc: 0.9931\nEpoch 18/20\n15750/15750 [==============================] - 2s 129us/sample - loss: 0.0044 - acc: 0.9989 - val_loss: 0.0299 - val_acc: 0.9874\nEpoch 19/20\n15750/15750 [==============================] - 2s 129us/sample - loss: 0.0041 - acc: 0.9989 - val_loss: 0.0201 - val_acc: 0.9914\nEpoch 20/20\n15750/15750 [==============================] - 2s 130us/sample - loss: 7.5573e-04 - acc: 1.0000 - val_loss: 0.0238 - val_acc: 0.9931\n","name":"stdout"},{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7fc959d0e208>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_list = os.listdir('../input/test/test')\ndef get_test_image(imname):\n    name = os.path.join('../input/test/test', imname)\n    img = cv2.imread(name, 1)\n    img = cv2.resize(img, (32,32))/255\n    return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_imgs = []\nfor i in range(len(test_list)):\n    test_imgs.append(np.reshape(get_test_image(test_list[i]), (32,32,3)))\ntest_imgs = np.array(test_imgs)\npred = model.predict(test_imgs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = [i[0] for i in pred]\n\nres_dict = {'id': test_list, 'has_cactus' : pred}\nres_df = pd.DataFrame(res_dict)\nres_df.to_csv('result.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}