{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Import libaries\nimport os\nimport time\nimport pandas as pd\nimport numpy as np\nimport cv2\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential,load_model \nfrom keras.layers import Dense,Conv2D,Dropout,MaxPooling2D,Flatten,BatchNormalization\nfrom keras.callbacks import EarlyStopping\nfrom keras import optimizers\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain_path='../input/train/train'\ntest_path='../input/test/test'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prepare train data \nlabel_train=pd.read_csv(\"../input/train.csv\")\n# Ordino il file in base all'id\nlabel_train=label_train.sort_values(by=['id'])\n# Creo 2 array distinti uno per gli id e l'altro per i label\nid=label_train['id'].values\nl=label_train['has_cactus'].values\n\ntrain=[]\nX=[]\nY=[]\na=0\n\nfor i in tqdm(sorted(os.listdir(train_path))):\n    path=os.path.join(train_path,i)\n    i=cv2.imread(path,cv2.IMREAD_COLOR)\n    X.append(i)\n    train.append([np.array(i),l[a]])\n    a=a+1\n\ntrain=np.array(train)\nY=train[:,1]\ntrain=train[:,0]\nX=np.array(X)\n\nX.shape\n\nX=X/255\ntrain=train/255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the first 25 images in Training Set \nplt.figure(figsize = (30,30))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    if Y[i]==1:\n        l=\"Has Cactus\"\n    elif Y[i]==0:\n        l=\"No Cactus\"\n    plt.xlabel(l,fontsize=25)\n    plt.imshow(train[i])\nplt.suptitle(\"First 25 images in Training Set \",fontsize=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prepare Test data \ntest_viz=[]\nX_test=[]\n\nfor i in tqdm(os.listdir(test_path)):\n    id=i\n    path=os.path.join(test_path,i)\n    i=cv2.imread(path,cv2.IMREAD_COLOR)\n    X_test.append(i)\n    test_viz.append([np.array(i),id])\n\nX_test=np.array(X_test)\nX_test.shape\ntest_viz=np.array(test_viz)\nid_test=test_viz[:,1]\ntest_viz=test_viz[:,0]\ntest_viz.shape\n\nX_test=X_test/255\ntest_viz=test_viz/255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the first 25 images in Test Set \nplt.figure(figsize = (30,30))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(test_viz[i])\nplt.suptitle(\"First 25 images in Testing Set \",fontsize=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m=Sequential()\nm.add(Conv2D(filters=32,kernel_size=2,padding=\"same\",activation=\"relu\",input_shape=(32,32,3)))\nm.add(Conv2D(filters=32,kernel_size=2,padding=\"same\",activation=\"relu\"))\nm.add(Conv2D(filters=32,kernel_size=4,padding=\"same\",activation=\"relu\"))\nm.add(MaxPooling2D(pool_size=2,strides=1))\nm.add(Dropout(0.2))\nm.add(Conv2D(filters=64,kernel_size=2,padding=\"same\",activation=\"relu\"))\nm.add(Conv2D(filters=64,kernel_size=2,padding=\"same\",activation=\"relu\"))\nm.add(Conv2D(filters=64,kernel_size=4,padding=\"same\",activation=\"relu\"))\nm.add(MaxPooling2D(pool_size=2,strides=1))\nm.add(Dropout(0.2))\nm.add(Conv2D(filters=128,kernel_size=2,padding=\"same\",activation=\"relu\"))\nm.add(Conv2D(filters=128,kernel_size=2,padding=\"same\",activation=\"relu\"))\nm.add(Conv2D(filters=128,kernel_size=4,padding=\"same\",activation=\"relu\"))\nm.add(MaxPooling2D(pool_size=2,strides=1))\nm.add(Dropout(0.2))\nm.add(Flatten())\nm.add(Dense(32,activation=\"relu\"))\nm.add(Dense(1,activation=\"sigmoid\"))\nm.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# training of the model\n# el=EarlyStopping(min_delta=0.006,patience=5,restore_best_weights=True)\nm.compile(loss=\"binary_crossentropy\",optimizer='adam',metrics=[\"accuracy\"])\ns=time.time()\nh=m.fit(X,Y,batch_size=128,validation_split=0.2,epochs=100)\ne=time.time()\nt=e-s\nprint(\"Addestramento completato in %d minuti e %d secondi\" %(t/60,t*60))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc=h.history['acc']\nval_acc=h.history['val_acc']\nloss=h.history['loss']\nval_loss=h.history['val_loss']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Trend of accuracy during the training \nplt.plot(acc)\nplt.plot(val_acc)\nplt.title('Cactus_identifier_net1 Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train','Validation'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Trend of loss during the training \nplt.plot(loss)\nplt.plot(val_loss)\nplt.title('Cactus_identifier_net1 Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train','Validation'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred=m.predict(X_test)\nids=[]\nlabel=[]\na=0\nfor i in tqdm(os.listdir(test_path)):\n    id=i\n    ids.append(id)\n    label.append(pred[a])\n    a=a+1\n\nlabel=np.array(label,dtype='float64')\nout=pd.DataFrame({'id': ids,'has_cactus':label[:,0]})\n\nout.to_csv('cactus_identifier_net.csv',index=False,header=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Confusion matrix for the Training Set \npred_train=m.predict(X)\np=[]\nfor i in pred_train:\n    if i>0.5:\n        p.append(1)\n    elif i<0.5:\n        p.append(0)\n        \np=np.array(p,dtype='int')\nY=np.array(Y,dtype='int')\n\ncm=confusion_matrix(Y,p)\ncm_df = pd.DataFrame(cm,index = ['0 - No Cactus','1 - Has Cactus'],  columns = ['0 - No Catus','1 - Has Cactus'])\nplt.figure(figsize=(10,10))\nsns.heatmap(cm_df,annot=True,cmap=\"Blues_r\",linewidth=0.5,square=True,fmt='g')\n\nplt.ylabel(\"True Label \")\nplt.xlabel(\"Predict Label\")\nplt.title(\"CONFUSION MATRIX FOR TRAINING SET\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}