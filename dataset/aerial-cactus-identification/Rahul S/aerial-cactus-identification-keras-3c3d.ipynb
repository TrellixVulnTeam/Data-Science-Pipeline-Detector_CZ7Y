{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nfrom keras.preprocessing.image import load_img, img_to_array\n\nimport keras\nfrom keras.layers import Dense, Conv2D, MaxPooling2D,Flatten, Dropout, Activation, Input\nfrom keras.models import Model\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ReduceLROnPlateau\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\n#print(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":10,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. Load Train DataSet"},{"metadata":{"trusted":true},"cell_type":"code","source":"#### Load training Data CSV\ntrainDF = pd.read_csv('../input/train.csv')\n\n#### Get training images \ntrainImgList = list(trainDF['id'])\ntrainImg = []\n\nfor img in trainImgList:\n    originalImage = load_img(f'../input/train/train/{img}')\n    arrayImage = img_to_array(originalImage) / 255\n    trainImg.append(arrayImage)\n    \ntrainImgNP = np.array(trainImg)\n\n#### Get training Lables\ntrainLabels = trainDF['has_cactus'].values","execution_count":11,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Model Helper Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"#### Model Helper Functions\ndef getConvLayer(inputLayer, kernelSize = 2 ,filters = 64):\n    conv1 = Conv2D(filters, kernelSize, activation = 'relu')(inputLayer)\n    #conv2 = Conv2D(filters, kernelSize, activation = 'relu')(conv1)\n    pool1 = MaxPooling2D()(conv1)\n    return pool1\n\ndef getFlattenLayer(inputLayer):\n    flat = Flatten()(inputLayer)\n    return flat\n\ndef getDenseLayer(inputLayer, units = 512, rate = .5):\n    dense1 = Dense(units, activation = 'relu')(inputLayer)\n    drop1 = Dropout(rate)(dense1)\n    return drop1\n\ndef getOutLayer(inputLayer):\n    out1 = Dense(1, activation = 'sigmoid')(inputLayer)\n    return out1\n\ndef getModel():\n    #### Create Model and show Summary\n    inputLayer = Input(shape = [32, 32, 3])\n\n    # 1st ConvLayer\n    conv1 = getConvLayer(inputLayer)\n\n    # 2nd ConvLayer\n    conv2 = getConvLayer(conv1, filters = 32)\n    \n    # 3rd ConvLayer\n    conv3 = getConvLayer(conv2, filters = 16)\n\n    # FlattenLayer\n    flat = getFlattenLayer(conv3)\n\n    # 1st DenseLayer\n    dense1 = getDenseLayer(flat)\n\n    # 2nd DenseLayer\n    dense2 = getDenseLayer(dense1)\n\n    # 3rd DenseLayer\n    dense3 = getDenseLayer(dense2)\n\n    # OutputLayer\n    out = getOutLayer(dense3)\n\n    # Create Model\n    model = Model(inputLayer, out)\n    #model.summary()\n    \n    return model\n\n#### Learn Rate reduction\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, factor=0.5, min_lr=0.00001)","execution_count":12,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Train Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"#### Compile and train Model\nmodel = getModel()\n\nmodel.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n\nmodel.fit(x = trainImgNP, y = trainLabels, batch_size = 64, epochs = 100, validation_split = .1, callbacks=[learning_rate_reduction])","execution_count":13,"outputs":[{"output_type":"stream","text":"Train on 15750 samples, validate on 1750 samples\nEpoch 1/100\n15750/15750 [==============================] - 3s 168us/step - loss: 0.4257 - acc: 0.7858 - val_loss: 0.2462 - val_acc: 0.9263\nEpoch 2/100\n15750/15750 [==============================] - 2s 119us/step - loss: 0.1659 - acc: 0.9406 - val_loss: 0.1349 - val_acc: 0.9491\nEpoch 3/100\n15750/15750 [==============================] - 2s 119us/step - loss: 0.1261 - acc: 0.9539 - val_loss: 0.1255 - val_acc: 0.9520\nEpoch 4/100\n15750/15750 [==============================] - 2s 119us/step - loss: 0.1095 - acc: 0.9601 - val_loss: 0.0843 - val_acc: 0.9697\nEpoch 5/100\n15750/15750 [==============================] - 2s 118us/step - loss: 0.0870 - acc: 0.9694 - val_loss: 0.0674 - val_acc: 0.9754\nEpoch 6/100\n15750/15750 [==============================] - 2s 118us/step - loss: 0.0788 - acc: 0.9711 - val_loss: 0.0602 - val_acc: 0.9777\nEpoch 7/100\n15750/15750 [==============================] - 2s 118us/step - loss: 0.0696 - acc: 0.9754 - val_loss: 0.0579 - val_acc: 0.9794\nEpoch 8/100\n15750/15750 [==============================] - 2s 118us/step - loss: 0.0650 - acc: 0.9764 - val_loss: 0.0616 - val_acc: 0.9783\nEpoch 9/100\n15750/15750 [==============================] - 2s 119us/step - loss: 0.0602 - acc: 0.9780 - val_loss: 0.0479 - val_acc: 0.9840\nEpoch 10/100\n15750/15750 [==============================] - 2s 120us/step - loss: 0.0553 - acc: 0.9811 - val_loss: 0.0421 - val_acc: 0.9851\nEpoch 11/100\n15750/15750 [==============================] - 2s 119us/step - loss: 0.0547 - acc: 0.9811 - val_loss: 0.0414 - val_acc: 0.9846\nEpoch 12/100\n15750/15750 [==============================] - 2s 117us/step - loss: 0.0545 - acc: 0.9799 - val_loss: 0.0430 - val_acc: 0.9863\nEpoch 13/100\n15750/15750 [==============================] - 2s 118us/step - loss: 0.0465 - acc: 0.9843 - val_loss: 0.0477 - val_acc: 0.9811\nEpoch 14/100\n15750/15750 [==============================] - 2s 119us/step - loss: 0.0468 - acc: 0.9834 - val_loss: 0.0376 - val_acc: 0.9851\nEpoch 15/100\n15750/15750 [==============================] - 2s 119us/step - loss: 0.0410 - acc: 0.9856 - val_loss: 0.0400 - val_acc: 0.9851\n\nEpoch 00015: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\nEpoch 16/100\n15750/15750 [==============================] - 2s 119us/step - loss: 0.0361 - acc: 0.9870 - val_loss: 0.0393 - val_acc: 0.9846\nEpoch 17/100\n15750/15750 [==============================] - 2s 120us/step - loss: 0.0353 - acc: 0.9881 - val_loss: 0.0322 - val_acc: 0.9886\nEpoch 18/100\n15750/15750 [==============================] - 2s 118us/step - loss: 0.0334 - acc: 0.9875 - val_loss: 0.0415 - val_acc: 0.9851\nEpoch 19/100\n15750/15750 [==============================] - 2s 119us/step - loss: 0.0326 - acc: 0.9888 - val_loss: 0.0317 - val_acc: 0.9903\nEpoch 20/100\n15750/15750 [==============================] - 2s 119us/step - loss: 0.0322 - acc: 0.9887 - val_loss: 0.0462 - val_acc: 0.9829\nEpoch 21/100\n15750/15750 [==============================] - 2s 120us/step - loss: 0.0328 - acc: 0.9876 - val_loss: 0.0309 - val_acc: 0.9897\nEpoch 22/100\n15750/15750 [==============================] - 2s 120us/step - loss: 0.0293 - acc: 0.9898 - val_loss: 0.0309 - val_acc: 0.9891\n\nEpoch 00022: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\nEpoch 23/100\n15750/15750 [==============================] - 2s 120us/step - loss: 0.0287 - acc: 0.9904 - val_loss: 0.0307 - val_acc: 0.9897\nEpoch 24/100\n15750/15750 [==============================] - 2s 119us/step - loss: 0.0275 - acc: 0.9908 - val_loss: 0.0314 - val_acc: 0.9897\nEpoch 25/100\n15750/15750 [==============================] - 2s 119us/step - loss: 0.0263 - acc: 0.9907 - val_loss: 0.0301 - val_acc: 0.9891\n\nEpoch 00025: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\nEpoch 26/100\n15750/15750 [==============================] - 2s 120us/step - loss: 0.0243 - acc: 0.9919 - val_loss: 0.0311 - val_acc: 0.9897\nEpoch 27/100\n15750/15750 [==============================] - 2s 120us/step - loss: 0.0243 - acc: 0.9916 - val_loss: 0.0298 - val_acc: 0.9897\nEpoch 28/100\n15750/15750 [==============================] - 2s 118us/step - loss: 0.0236 - acc: 0.9921 - val_loss: 0.0334 - val_acc: 0.9891\n\nEpoch 00028: ReduceLROnPlateau reducing learning rate to 1e-05.\nEpoch 29/100\n15750/15750 [==============================] - 2s 119us/step - loss: 0.0235 - acc: 0.9924 - val_loss: 0.0304 - val_acc: 0.9897\nEpoch 30/100\n15750/15750 [==============================] - 2s 121us/step - loss: 0.0241 - acc: 0.9922 - val_loss: 0.0339 - val_acc: 0.9891\nEpoch 31/100\n15750/15750 [==============================] - 2s 120us/step - loss: 0.0240 - acc: 0.9921 - val_loss: 0.0291 - val_acc: 0.9897\nEpoch 32/100\n15750/15750 [==============================] - 2s 124us/step - loss: 0.0228 - acc: 0.9923 - val_loss: 0.0300 - val_acc: 0.9897\nEpoch 33/100\n15750/15750 [==============================] - 2s 124us/step - loss: 0.0222 - acc: 0.9921 - val_loss: 0.0291 - val_acc: 0.9897\nEpoch 34/100\n15750/15750 [==============================] - 2s 120us/step - loss: 0.0222 - acc: 0.9929 - val_loss: 0.0315 - val_acc: 0.9891\nEpoch 35/100\n15750/15750 [==============================] - 2s 120us/step - loss: 0.0238 - acc: 0.9920 - val_loss: 0.0326 - val_acc: 0.9897\nEpoch 36/100\n15750/15750 [==============================] - 2s 119us/step - loss: 0.0226 - acc: 0.9922 - val_loss: 0.0292 - val_acc: 0.9891\nEpoch 37/100\n15750/15750 [==============================] - 2s 120us/step - loss: 0.0230 - acc: 0.9924 - val_loss: 0.0310 - val_acc: 0.9903\nEpoch 38/100\n15750/15750 [==============================] - 2s 121us/step - loss: 0.0209 - acc: 0.9934 - val_loss: 0.0320 - val_acc: 0.9897\nEpoch 39/100\n15750/15750 [==============================] - 2s 119us/step - loss: 0.0217 - acc: 0.9938 - val_loss: 0.0291 - val_acc: 0.9891\nEpoch 40/100\n15750/15750 [==============================] - 2s 119us/step - loss: 0.0213 - acc: 0.9925 - val_loss: 0.0316 - val_acc: 0.9897\nEpoch 41/100\n15750/15750 [==============================] - 2s 119us/step - loss: 0.0210 - acc: 0.9928 - val_loss: 0.0321 - val_acc: 0.9891\nEpoch 42/100\n15750/15750 [==============================] - 2s 120us/step - loss: 0.0214 - acc: 0.9930 - val_loss: 0.0353 - val_acc: 0.9891\nEpoch 43/100\n15750/15750 [==============================] - 2s 121us/step - loss: 0.0206 - acc: 0.9930 - val_loss: 0.0299 - val_acc: 0.9891\nEpoch 44/100\n15750/15750 [==============================] - 2s 118us/step - loss: 0.0201 - acc: 0.9935 - val_loss: 0.0307 - val_acc: 0.9897\nEpoch 45/100\n15750/15750 [==============================] - 2s 119us/step - loss: 0.0212 - acc: 0.9929 - val_loss: 0.0301 - val_acc: 0.9897\nEpoch 46/100\n15750/15750 [==============================] - 2s 119us/step - loss: 0.0202 - acc: 0.9936 - val_loss: 0.0303 - val_acc: 0.9897\nEpoch 47/100\n15750/15750 [==============================] - 2s 119us/step - loss: 0.0209 - acc: 0.9928 - val_loss: 0.0293 - val_acc: 0.9886\nEpoch 48/100\n15750/15750 [==============================] - 2s 121us/step - loss: 0.0202 - acc: 0.9934 - val_loss: 0.0288 - val_acc: 0.9903\nEpoch 49/100\n15750/15750 [==============================] - 2s 119us/step - loss: 0.0200 - acc: 0.9931 - val_loss: 0.0313 - val_acc: 0.9897\nEpoch 50/100\n15750/15750 [==============================] - 2s 117us/step - loss: 0.0201 - acc: 0.9932 - val_loss: 0.0285 - val_acc: 0.9886\nEpoch 51/100\n15750/15750 [==============================] - 2s 118us/step - loss: 0.0186 - acc: 0.9943 - val_loss: 0.0285 - val_acc: 0.9886\nEpoch 52/100\n15750/15750 [==============================] - 2s 119us/step - loss: 0.0196 - acc: 0.9935 - val_loss: 0.0322 - val_acc: 0.9897\nEpoch 53/100\n15750/15750 [==============================] - 2s 118us/step - loss: 0.0198 - acc: 0.9938 - val_loss: 0.0287 - val_acc: 0.9886\nEpoch 54/100\n15750/15750 [==============================] - 2s 120us/step - loss: 0.0194 - acc: 0.9938 - val_loss: 0.0288 - val_acc: 0.9886\nEpoch 55/100\n15750/15750 [==============================] - 2s 118us/step - loss: 0.0190 - acc: 0.9936 - val_loss: 0.0285 - val_acc: 0.9897\nEpoch 56/100\n15750/15750 [==============================] - 2s 118us/step - loss: 0.0184 - acc: 0.9939 - val_loss: 0.0281 - val_acc: 0.9886\nEpoch 57/100\n","name":"stdout"},{"output_type":"stream","text":"15750/15750 [==============================] - 2s 119us/step - loss: 0.0185 - acc: 0.9937 - val_loss: 0.0305 - val_acc: 0.9891\nEpoch 58/100\n15750/15750 [==============================] - 2s 120us/step - loss: 0.0187 - acc: 0.9943 - val_loss: 0.0292 - val_acc: 0.9891\nEpoch 59/100\n15750/15750 [==============================] - 2s 119us/step - loss: 0.0191 - acc: 0.9933 - val_loss: 0.0283 - val_acc: 0.9886\nEpoch 60/100\n15750/15750 [==============================] - 2s 119us/step - loss: 0.0189 - acc: 0.9931 - val_loss: 0.0301 - val_acc: 0.9886\nEpoch 61/100\n15750/15750 [==============================] - 2s 119us/step - loss: 0.0190 - acc: 0.9940 - val_loss: 0.0284 - val_acc: 0.9891\nEpoch 62/100\n15750/15750 [==============================] - 2s 121us/step - loss: 0.0169 - acc: 0.9947 - val_loss: 0.0330 - val_acc: 0.9886\nEpoch 63/100\n15750/15750 [==============================] - 2s 119us/step - loss: 0.0183 - acc: 0.9937 - val_loss: 0.0283 - val_acc: 0.9897\nEpoch 64/100\n15750/15750 [==============================] - 2s 118us/step - loss: 0.0175 - acc: 0.9941 - val_loss: 0.0282 - val_acc: 0.9897\nEpoch 65/100\n15750/15750 [==============================] - 2s 118us/step - loss: 0.0174 - acc: 0.9945 - val_loss: 0.0284 - val_acc: 0.9886\nEpoch 66/100\n15750/15750 [==============================] - 2s 118us/step - loss: 0.0169 - acc: 0.9950 - val_loss: 0.0304 - val_acc: 0.9897\nEpoch 67/100\n15750/15750 [==============================] - 2s 119us/step - loss: 0.0170 - acc: 0.9945 - val_loss: 0.0293 - val_acc: 0.9897\nEpoch 68/100\n15750/15750 [==============================] - 2s 120us/step - loss: 0.0179 - acc: 0.9945 - val_loss: 0.0311 - val_acc: 0.9886\nEpoch 69/100\n15750/15750 [==============================] - 2s 119us/step - loss: 0.0167 - acc: 0.9948 - val_loss: 0.0282 - val_acc: 0.9897\nEpoch 70/100\n15750/15750 [==============================] - 2s 120us/step - loss: 0.0168 - acc: 0.9948 - val_loss: 0.0281 - val_acc: 0.9891\nEpoch 71/100\n15750/15750 [==============================] - 2s 119us/step - loss: 0.0170 - acc: 0.9950 - val_loss: 0.0289 - val_acc: 0.9886\nEpoch 72/100\n15750/15750 [==============================] - 2s 119us/step - loss: 0.0166 - acc: 0.9945 - val_loss: 0.0280 - val_acc: 0.9891\nEpoch 73/100\n15750/15750 [==============================] - 2s 119us/step - loss: 0.0163 - acc: 0.9951 - val_loss: 0.0308 - val_acc: 0.9886\nEpoch 74/100\n15750/15750 [==============================] - 2s 119us/step - loss: 0.0161 - acc: 0.9947 - val_loss: 0.0286 - val_acc: 0.9897\nEpoch 75/100\n15750/15750 [==============================] - 2s 123us/step - loss: 0.0152 - acc: 0.9956 - val_loss: 0.0280 - val_acc: 0.9891\nEpoch 76/100\n15750/15750 [==============================] - 2s 124us/step - loss: 0.0154 - acc: 0.9956 - val_loss: 0.0284 - val_acc: 0.9891\nEpoch 77/100\n15750/15750 [==============================] - 2s 124us/step - loss: 0.0161 - acc: 0.9945 - val_loss: 0.0280 - val_acc: 0.9891\nEpoch 78/100\n15750/15750 [==============================] - 2s 125us/step - loss: 0.0144 - acc: 0.9955 - val_loss: 0.0289 - val_acc: 0.9909\nEpoch 79/100\n15750/15750 [==============================] - 2s 124us/step - loss: 0.0166 - acc: 0.9946 - val_loss: 0.0312 - val_acc: 0.9886\nEpoch 80/100\n15750/15750 [==============================] - 2s 123us/step - loss: 0.0153 - acc: 0.9951 - val_loss: 0.0297 - val_acc: 0.9891\nEpoch 81/100\n15750/15750 [==============================] - 2s 121us/step - loss: 0.0146 - acc: 0.9956 - val_loss: 0.0289 - val_acc: 0.9897\nEpoch 82/100\n15750/15750 [==============================] - 2s 119us/step - loss: 0.0152 - acc: 0.9949 - val_loss: 0.0298 - val_acc: 0.9891\nEpoch 83/100\n15750/15750 [==============================] - 2s 119us/step - loss: 0.0143 - acc: 0.9958 - val_loss: 0.0306 - val_acc: 0.9880\nEpoch 84/100\n15750/15750 [==============================] - 2s 120us/step - loss: 0.0138 - acc: 0.9957 - val_loss: 0.0281 - val_acc: 0.9891\nEpoch 85/100\n15750/15750 [==============================] - 2s 121us/step - loss: 0.0133 - acc: 0.9959 - val_loss: 0.0351 - val_acc: 0.9886\nEpoch 86/100\n15750/15750 [==============================] - 2s 122us/step - loss: 0.0146 - acc: 0.9953 - val_loss: 0.0280 - val_acc: 0.9897\nEpoch 87/100\n15750/15750 [==============================] - 2s 120us/step - loss: 0.0141 - acc: 0.9957 - val_loss: 0.0331 - val_acc: 0.9874\nEpoch 88/100\n15750/15750 [==============================] - 2s 121us/step - loss: 0.0143 - acc: 0.9956 - val_loss: 0.0402 - val_acc: 0.9886\nEpoch 89/100\n15750/15750 [==============================] - 2s 121us/step - loss: 0.0153 - acc: 0.9954 - val_loss: 0.0296 - val_acc: 0.9886\nEpoch 90/100\n15750/15750 [==============================] - 2s 120us/step - loss: 0.0130 - acc: 0.9961 - val_loss: 0.0334 - val_acc: 0.9886\nEpoch 91/100\n15750/15750 [==============================] - 2s 119us/step - loss: 0.0137 - acc: 0.9957 - val_loss: 0.0297 - val_acc: 0.9891\nEpoch 92/100\n15750/15750 [==============================] - 2s 120us/step - loss: 0.0136 - acc: 0.9959 - val_loss: 0.0282 - val_acc: 0.9891\nEpoch 93/100\n15750/15750 [==============================] - 2s 120us/step - loss: 0.0133 - acc: 0.9961 - val_loss: 0.0279 - val_acc: 0.9909\nEpoch 94/100\n15750/15750 [==============================] - 2s 130us/step - loss: 0.0136 - acc: 0.9962 - val_loss: 0.0298 - val_acc: 0.9880\nEpoch 95/100\n15750/15750 [==============================] - 2s 122us/step - loss: 0.0132 - acc: 0.9963 - val_loss: 0.0295 - val_acc: 0.9891\nEpoch 96/100\n15750/15750 [==============================] - 2s 124us/step - loss: 0.0130 - acc: 0.9962 - val_loss: 0.0291 - val_acc: 0.9891\nEpoch 97/100\n15750/15750 [==============================] - 2s 119us/step - loss: 0.0126 - acc: 0.9961 - val_loss: 0.0317 - val_acc: 0.9874\nEpoch 98/100\n15750/15750 [==============================] - 2s 119us/step - loss: 0.0142 - acc: 0.9952 - val_loss: 0.0308 - val_acc: 0.9880\nEpoch 99/100\n15750/15750 [==============================] - 2s 119us/step - loss: 0.0137 - acc: 0.9955 - val_loss: 0.0294 - val_acc: 0.9891\nEpoch 100/100\n15750/15750 [==============================] - 2s 122us/step - loss: 0.0119 - acc: 0.9968 - val_loss: 0.0303 - val_acc: 0.9886\n","name":"stdout"},{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"<keras.callbacks.History at 0x7fba8c1594a8>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## 4. Load Test DataSet"},{"metadata":{"trusted":true},"cell_type":"code","source":"#### Get testing images \ntestImgList = os.listdir(\"../input/test/test\")\ntestImg = []\n\nfor img in testImgList:\n    originalImage = load_img(f'../input/test/test/{img}')\n    arrayImage = img_to_array(originalImage) / 255\n    testImg.append(arrayImage)\n    \ntestImgNP = np.array(testImg)","execution_count":14,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5. Predict Labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"#### get Predictions for test Data\ntestPred = model.predict(testImgNP)\ntestPredRound = np.round(testPred)\nsubPred = [int(x) for [x] in testPredRound]","execution_count":15,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6. Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"#### Create a Submission DF\nsub = pd.DataFrame({'id' : testImgList, 'has_cactus' : subPred})\nsub.to_csv('submission_3C_3D.csv', index = False)","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}