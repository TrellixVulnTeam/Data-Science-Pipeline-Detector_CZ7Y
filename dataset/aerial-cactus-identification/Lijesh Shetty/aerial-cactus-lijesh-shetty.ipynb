{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Our model will be able to detect Cactus from aerial images provided.**\n\nI will take three approaches for building the model.\n\n**First, ** I will take VGG16 model, which is a pre-trained model. I will exclude its top layer. \nI will then pass my data into it, and extract features. \nThese features are basically pixel feature data coming out from the trained model. \nI will feed this data into my dense, fully connected model to output whether the image is cactus or not.\n\n**My Second approach is**, I will take inceptionV3 Model, again a pretrained model, and add to that my densely connected model as a top layer.\nI will feed my data into it, and determine whether the image is of cactus or not.\n\n**Finally,** my third model will be my model. I will build a CNN Model. \nIn CNN Model, it focusses on a small section of the image, and takes stride through the entire image.MaxPooling selects the max feature to carry forward to next layer and so on. \nCNN Model, MaxPooling & Activation, and you can repeat it several times... \nI also add drop features to regularize the learning, and the model to not overfit. \nThen I flatten, and connect it to densely, fully connected layers, and finally output whether the image is cactus or not.\n\n**As we go through this, we will find out which one gives one more accuracy, and I will submit that to the competition...\n**\n\n**SO ENJOY!!!!**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport gc\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/train.csv')\n#train_df.head()\n#train_df.has_cactus.value_counts()\n\ntest_df = pd.read_csv('../input/sample_submission.csv')\ntest_df.head()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"lets read the image, and see how it looks."},{"metadata":{"trusted":true},"cell_type":"code","source":"#import matplotlib.pyplot as plt\n#pix = plt.imread(os.path.join(\"../input/train/train\",df.iloc[2,0]))\n#plt.imshow(pix)\n\nfrom IPython.display import Image\nImage(os.path.join(\"../input/train/train\",train_df.iloc[2,0]),width=350,height=350)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I will create a validation set and training set from our data.\nThis I will use to verify our model accuracy."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X = train_df['id'].iloc[:15000]\ntrain_y= train_df['has_cactus'].iloc[:15000]\n\nval_X = train_df['id'].iloc[15000:]\nval_y= train_df['has_cactus'].iloc[15000:]\n\nval_X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for image data generator these labels have to be of type string.\ntest_df['has_cactus'] = train_df.has_cactus\ntrain_df.has_cactus = train_df.has_cactus.astype('str')\ntest_df.has_cactus = test_df.has_cactus.astype('str')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Following is the image data generator, which will load image using dataframe id column for both training and testing data."},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True,rescale = 1./255)\n\ntrain_data_iterator = datagen.flow_from_dataframe(dataframe=train_df[:15000],directory='../input/train/train',x_col='id',\n                                            y_col='has_cactus',class_mode='binary',batch_size=200,\n                                            target_size=(250,250))\n\nvalidation_data_iterator = datagen.flow_from_dataframe(dataframe=train_df[15000:],directory='../input/train/train',x_col='id',\n                                            y_col='has_cactus',class_mode='binary',batch_size=200,\n                                            target_size=(250,250))\n\ntest_data_iterator = datagen.flow_from_dataframe(dataframe=test_df,directory='../input/test/test',x_col='id',\n                                            y_col='has_cactus',class_mode='binary',batch_size=200,\n                                            target_size=(250,250))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Approach 1 : VGG16 MODEL **\n\nI will import VGG16 model,exclude its top layer, provide it with our training image features, extract the output features from the model, provide that as an input to my densely connected model, and output from my model whether the fed image is of cactus or not."},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Model\nfrom keras.applications.vgg16 import VGG16\nfrom keras.models import Sequential\n\n# lets print the layers of VGG16 to get more intution of the # of layers and what they do.\nbase_model = VGG16(include_top=False,weights='imagenet')\nfor i, layer in enumerate(base_model.layers):\n    print(i,layer.name,layer.output_shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here I have written a simple get feature method. \nIt provides the image features, and uses VGG16 Model to output features.\nThese features and labels are returned from this method."},{"metadata":{"trusted":true},"cell_type":"code","source":"def getFeatures(record_count,iterator_name):\n    count=0\n    labels = np.zeros(shape = record_count)\n    features=np.zeros(shape=(record_count,7,7,512))\n\n    for batch_features, batch_labels in iterator_name:\n        features[count*200:(count+1)*200] = base_model.predict(batch_features)\n        labels[count*200:(count+1)*200] = batch_labels\n        count += 1\n        #print('value of feature is',features[(count+1)*200])\n        print('count is',count)\n        if(count*200 >= record_count):\n            break\n    return (features,labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I call the method and get the VGG16 features output for my training data."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features,train_labels = getFeatures(17500,train_data_iterator)\ntrain_features[200]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below I separate training and validation feature data output of VGG16 model."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_train = train_features[:15000]\ntrain_label_train = train_labels[:15000]\n\ntrain_features_validation = train_features[15000:]\ntrain_label_validation = train_labels[15000:]\ntrain_features_validation.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I call the method and get the VGG16 features output for my testing data."},{"metadata":{"trusted":true},"cell_type":"code","source":"test_features,test_labels = getFeatures(4000,test_data_iterator)\ntest_features[35].shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I am reshaping the data below to make it ready to my model of densely connected layer."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_train.reshape(15000,7*7*512)\ntrain_features_validation.reshape(2500,7*7*512)\ntest_features.reshape(4000,7*7*512)\ntest_features.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets build the final layer\nfrom keras.models import Model\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras import regularizers\n\nmodel=Sequential()\nmodel.add(Flatten())\n#model.add(Dense(256,activation='relu',input_dim=(7*7*512)))\nmodel.add(Dense(64,activation='relu',kernel_regularizer=regularizers.l1_l2(.001),input_dim=(7*7*512)))\nmodel.add(Dense(128,activation='relu'))\nmodel.add(Dense(256,activation='relu'))\nmodel.add(Dense(512,activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1,activation='sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history=model.fit(train_features_train,train_label_train,epochs=10,batch_size=15,validation_data=(train_features_validation,train_label_validation)\n            )\nprint('history keys are ', history.history.keys())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**For Training set, loss is: 1.1549  & accuracy is : 0.9029 (90.29%)\nFor Validation set, loss is : 1.0813  and accuracy is: 0.8944 (89.44%)\n**\nWe will Save the model, and use it later."},{"metadata":{"trusted":true},"cell_type":"code","source":"model_json = model.to_json()\nopen('my_vgg16_model_arch.json','w').write(model_json)\n# save the weights learned as well\nmodel.save_weights('my_vgg16_model_weights.h5',overwrite=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Lines to free up the memory...\nimport gc\ndel model\ndel train_features\n\n\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I am loading from my saved model. Incase, if I loose my connectivity....:)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import model_from_json\n\nmodel_arch = 'my_vgg16_model_arch.json'\nmodel_wts = 'my_vgg16_model_weights.h5'\nloaded_model = model_from_json(open(model_arch).read())\nloaded_model.load_weights(model_wts)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below I am plotting accuracy of the model for my training and validation set.."},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.xlabel('epoch')\nplt.ylabel('accuracy')\nplt.legend(['train','validation'],loc='upper left')\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"proba_label = loaded_model.predict_proba(test_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test=pd.read_csv('../input/sample_submission.csv')\noutput_df=pd.DataFrame({'id':df_test['id'] })\noutput_df['has_cactus']=proba_label\noutput_df.head()\n#output_df.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Lines to free up the memory...\nimport gc\n\ndel loaded_model\ndel test_features\ndel history\ndel output_df\n\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Approach 2 : INCEPTION V3 MODEL **\n\nIn this approach we will use InceptionV3 model,and replace its top layer with our fully connected dense layer.\nI will pass the features of the image, and get accuracy for its prediction on test set.\n\nI create a inception 3 model, exclude its top layer, and set the layers to non trainable.\nThen I add my deeply connected dense model to it as a top layer. \nI then train only my newly added layers with the features.\n\nI then go back, and train some top layers of inception3 layer along with my top layers.\n\nOnce I am done through above steps my model is ready to predict on test set...\n**Enjoy!!!**\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Model, Sequential\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.layers import Dense, Dropout, Flatten,GlobalAveragePooling2D\nfrom keras import backend as K\n\n\nbase_model = InceptionV3(include_top=False,weights='imagenet')\nfor i, layer in enumerate(base_model.layers):\n    print(i,layer.name,layer.output_shape)\n    layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Add our fully connected dense model to the inception_v3 model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Add our fully connected dense model to the inception_v3 model\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\n# let's add a fully-connected layer\nx = Dense(256, activation='relu')(x)\nx = Dense(512, activation='relu')(x)\n# and a logistic layer -- let's say we have 200 classes\npredictions = Dense(1, activation='sigmoid')(x)\n\n# this is the model we will train\nmodel = Model(inputs=base_model.input, outputs=predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"lets fit the model with the layers of InceptionV3 frozen. \nI am training only the layers which I have added on top of it below."},{"metadata":{"trusted":true},"cell_type":"code","source":"# train only the top model since all the layers of inception_v3 is set to non train.\nhistory = model.fit_generator(train_data_iterator,steps_per_epoch=len(train_df)/200,epochs=50, verbose=1, \n                              validation_data=validation_data_iterator,validation_steps=50)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Once we have trained the model. \nI am going to train top layers, above 200th layer, of InceptionV3 and my added layers to the model.\nI will then train it with the training data."},{"metadata":{"trusted":true},"cell_type":"code","source":"for layer in model.layers[:200]:\n    layer.trainable = False\nfor layer in model.layers[200:]:\n    layer.trainable = True    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.optimizers import SGD\nmodel.compile(loss='binary_crossentropy',optimizer= SGD(lr=0.0001,momentum=0.9),metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit_generator(train_data_iterator,steps_per_epoch=len(train_df)/200,epochs=50, verbose=1, \n                              validation_data=validation_data_iterator,validation_steps=50)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Awesome!!! Inception V3 model accuracy for training data is 96.71%**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_json = model.to_json()\nopen('my_incpn_model_arch.json','w').write(model_json)\n# save the weights learned as well\nmodel.save_weights('my_incpn_model_weights.h5',overwrite=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Lines to free up the memory...\nimport gc\n\ndel model\ndel layer\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import model_from_json\n\nmodel_arch = 'my_incpn_model_arch.json'\nmodel_wts = 'my_incpn_model_weights.h5'\nloaded_model = model_from_json(open(model_arch).read())\nloaded_model.load_weights(model_wts)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now I am going to get features of the image for the testing data.\nI will use the test generator, and then feed this data into the model to get the prediction."},{"metadata":{"trusted":true},"cell_type":"code","source":"features=np.zeros(shape=(4000,250,250,3))\ni=0\nfor test_features_batch, test_labels_batch in test_data_iterator:\n        \n        features[i*200:(i+1)*200] = test_features_batch\n        print('count',i)\n        i +=1\n        if(i*200 >= 4000):\n            break\n        \nfeatures[2500]\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"proba_label = loaded_model.predict(features)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Since InceptionV3 outcome is really good, I am going to submit for competition.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test=pd.read_csv('../input/sample_submission.csv')\noutput_df=pd.DataFrame({'id':df_test['id'] })\noutput_df['has_cactus']=proba_label\noutput_df.head()\noutput_df.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Lines to free up the memory...\nimport gc\n\ndel loaded_model\ndel features\ndel output_df\n\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Approach 3 : Build my Own CNN Model**\n\nNow lets build our own model, and see what its accuracy is..."},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Model,Sequential\nfrom keras.preprocessing import utils\nfrom keras.layers import Dense, Dropout, Flatten,GlobalAveragePooling2D,Conv2D,MaxPooling2D\nfrom keras import backend as K\n\n# We will build the model...\n\nmodel = Sequential()\nmodel.add(Conv2D(64,(3,3),activation='relu',input_shape=(250,250,3)))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides = (2,2)))\n\nmodel.add(Conv2D(256,(3,3),activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides = (2,2)))\n\nmodel.add(Conv2D(512,(3,3),activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides = (2,2)))\n\nmodel.add(Conv2D(512,(3,3),activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides = (2,2)))\n\n\n\nmodel.add(Flatten())\nmodel.add(Dense(256,activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(256,activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1,activation='sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit_generator(train_data_iterator,steps_per_epoch=len(train_df)/200,epochs=5, verbose=1, \n                              validation_data=validation_data_iterator,validation_steps=50)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Accuracy with the self built model is 94.%**\n\nAs in the previous cases, lets save the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"model_json = model.to_json()\nopen('my_cnv_model_arch.json','w').write(model_json)\n# save the weights learned as well\nmodel.save_weights('my_cnv_model_weights.h5',overwrite=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import model_from_json\n\nmodel_arch = 'my_cnv_model_arch.json'\nmodel_wts = 'my_cnv_model_weights.h5'\nmy_loaded_model = model_from_json(open(model_arch).read())\nmy_loaded_model.load_weights(model_wts)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finally predict the outcome for the test data with my model..."},{"metadata":{"trusted":true},"cell_type":"code","source":"# I could have used the loaded model, but instead of using model directly.\ncnv_proba_label = model.predict(features)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**See Ya!!!! And Continue Building....\nKNOW ML.**"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}