{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os,cv2\nfrom IPython.display import Image\nfrom keras.preprocessing import image\nfrom keras import optimizers\nfrom keras import layers,models\nfrom keras.applications.imagenet_utils import preprocess_input\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom keras import regularizers\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.vgg16 import VGG16\n\n\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"## Descompactando os arquivos zipados\nimport zipfile\nwith zipfile.ZipFile(\"../input/aerial-cactus-identification/train.zip\",\"r\") as z:\n    z.extractall(\".\")\n\nwith zipfile.ZipFile(\"../input/aerial-cactus-identification/test.zip\",\"r\") as z:\n    z.extractall(\".\")  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Atribuindo os arquivos e diretórios a variáveis para futuras análises\n\ntrain_dir='train'\ntest_dir='test'\ntrain=pd.read_csv('../input/aerial-cactus-identification/train.csv')\n\ntest_df=pd.read_csv('../input/aerial-cactus-identification/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Localizando GPU\nfrom tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Imprimindo uma amostra do nosso dataset de treino\ntrain.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Conversão da coluna 'has_cactus' em string para realizar a separação dos dados\ntrain.has_cactus=train.has_cactus.astype(str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Quantidade de linhas e colunas do df\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Quantos registros são cactus e quantos nao são\ntrain['has_cactus'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Transforma os dados de entrada / utilizado para Augmentation\n\n#Rescale: Altera o dimensionamento da imagem, os dados originais são multiplixados pelo valor setado\n#rotation_range: Rotação de 20 graus nas imagens, \n#horizontal_flip: Reverter linhas <->\n#shear_range: Estica a imagem\ndatagen=ImageDataGenerator(rescale=1./255, rotation_range=20,horizontal_flip=True, shear_range = 0.2,zoom_range = 0.2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Leitura dos dados presentes no diretório Train_dir de acordo com o dataframe de treino, subdividindo em treino e validação\ntrain_generator=datagen.flow_from_dataframe(dataframe=train[:15001],directory=train_dir,x_col='id',\n                                            y_col='has_cactus',class_mode='binary',\n                                            target_size=(32,32))\n\n\nvalidation_generator=datagen.flow_from_dataframe(dataframe=train[15001:],directory=train_dir,x_col='id',\n                                                y_col='has_cactus',class_mode='binary',\n                                                target_size=(32,32))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#CNN sem utilização de tranfer learning\nwith tf.device('/GPU:0'):\n    model=models.Sequential()\n    model.add(layers.Conv2D(32,(3,3),activation='relu', input_shape = (32,32,3)))\n    model.add(layers.MaxPool2D((2,2)))\n    model.add(layers.Conv2D(64,(3,3),activation='relu', input_shape = (32,32,3)))\n    model.add(layers.MaxPool2D((2,2)))\n    model.add(layers.Conv2D(128,(3,3),activation='relu', input_shape = (32,32,3)))\n    model.add(layers.MaxPool2D((2,2)))\n    model.add(layers.Flatten())\n    model.add(layers.Dense(512,activation='relu'))\n    model.add(layers.Dense(1,activation='sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Verificaçao da arquitetura da CNN:\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compilando a CNN\nmodel.compile(loss='binary_crossentropy',optimizer='Adamax',metrics=['acc'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Executando o treinamento (sem VGG16)\nepochs=10\nhistory=model.fit_generator(train_generator,steps_per_epoch=450,epochs=10,validation_data=validation_generator,validation_steps=4500)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotar a acurácia/desempenho do modelo de acordo com as épocas, comparando traino da validação\nfig = plt.figure(figsize=(12,8))\nplt.plot(history.history['acc'],'blue')\nplt.plot(history.history['val_acc'],'orange')\nplt.xticks(np.arange(0, 10, 1))\nplt.yticks(np.arange(0.8,1.1,.05))\nplt.rcParams['figure.figsize'] = (10, 10)\nplt.xlabel(\"Num of Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Training Accuracy vs Validation Accuracy\")\nplt.grid(True)\nplt.gray()\nplt.legend(['train','validation'])\nplt.show()\n \nplt.figure(1)\nplt.plot(history.history['loss'],'blue')\nplt.plot(history.history['val_loss'],'orange')\nplt.xticks(np.arange(0, 10, 1))\nplt.rcParams['figure.figsize'] = (10, 10)\nplt.xlabel(\"Num of Epochs\")\nplt.ylabel(\"Loss\")\nplt.title(\"Training Loss vs Validation Loss\")\nplt.grid(True)\nplt.gray()\nplt.legend(['train','validation'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#melhorando o modelo utilizando o VGG16 \n#include_top = False: carregar VGG sem a parte classificadora do modelo\nmodel_vg=VGG16(weights='imagenet',include_top=False,input_shape=(32, 32, 3))\nmodel_vg.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Não altera os pesos da VGG\nmodel_vg.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#CNN com utilização de transfer learning\nfrom keras.layers import Activation, Dropout, Flatten, Dense,Conv2D,Conv3D,MaxPooling2D,AveragePooling2D,BatchNormalization\nmodel2 = models.Sequential()\nmodel2.add(model_vg)\n\nmodel2.add(Flatten())\nmodel2.add(Dense(256, use_bias=True))\nmodel2.add(BatchNormalization())\nmodel2.add(Activation(\"relu\"))\nmodel2.add(Dropout(0.5))\nmodel2.add(Dense(64,activation='relu'))\nmodel2.add(BatchNormalization())\nmodel2.add(Dense(16, activation='tanh'))\nmodel2.add(Dense(1, activation='sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compilando a rede\n \nwith tf.device('/GPU:0'):\n    model2.compile(optimizer='Adamax', loss='binary_crossentropy', metrics=['acc'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# steps_per_epoch: Quantas amostras são extraídas do gerador para prosseguir para a próxima época.Após a extração do lote de amostras do gerador(ou seja, depois de executar as etapas do gradiente descendente que procura localizar o mínimo global da funcao) inicia-se a próxima época.\n# função de custa \n# Executando o treinamento \n#loss(baseado no treino):valor da função de custo\n#val_loss(Baseado na validação):Se Val_loss for significamente maior, significa que houve overfiting no treinamento\nwith tf.device('/GPU:0'):\n    history_vgg=model2.fit_generator(train_generator,steps_per_epoch=450,epochs=15,validation_data=validation_generator,validation_steps=450)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotar a acurácia/desempenho do modelo de acordo com as épocas, comparando traino da validação\nfig = plt.figure(figsize=(12,8))\nplt.plot(history_vgg.history['acc'],'blue')\nplt.plot(history_vgg.history['val_acc'],'orange')\nplt.xticks(np.arange(0, 15, 1))\nplt.yticks(np.arange(0.8,1.1,.05))\nplt.rcParams['figure.figsize'] = (10, 10)\nplt.xlabel(\"Num of Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Training Accuracy vs Validation Accuracy\")\nplt.grid(True)\nplt.gray()\nplt.legend(['train','validation'])\nplt.show()\n \nplt.figure(1)\nplt.plot(history_vgg.history['loss'],'blue')\nplt.plot(history_vgg.history['val_loss'],'orange')\nplt.xticks(np.arange(0, 15, 1))\nplt.rcParams['figure.figsize'] = (10, 10)\nplt.xlabel(\"Num of Epochs\")\nplt.ylabel(\"Loss\")\nplt.title(\"Training Loss vs Validation Loss\")\nplt.grid(True)\nplt.gray()\nplt.legend(['train','validation'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#exportar o resultado:\ntest_dir='test/'\n\nX_test = []\nimges = test_df['id'].values\n\nfor img_id in imges:\n    X_test.append(cv2.imread(test_dir + img_id )) \n                  \nX_test = np.asarray(X_test)\nX_test = X_test.astype('float32')\nX_test /= 255\n\ny_test_pred  = model2.predict_proba(X_test)\n\ntest_df['has_cactus'] = y_test_pred\ntest_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}