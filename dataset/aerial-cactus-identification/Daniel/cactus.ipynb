{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from IPython.display import display\n\n# Global variables\nimage_size = (32, 32)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import load_img\nfrom os import listdir\nfrom os.path import join\nfrom pandas import read_csv\n\n# Take a look at the dataset\ntrain_labels = read_csv('../input/train.csv')\nfor image_name in listdir('../input/train/train')[:10]:\n    image = load_img(join('../input/train/train', image_name), target_size=image_size)\n    display(train_labels[train_labels['id'] == image_name]['has_cactus'].item())\n    display(image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications.vgg19 import VGG19, preprocess_input\nfrom keras.preprocessing.image import img_to_array, load_img\nfrom keras.utils import to_categorical\nfrom numpy import array\nfrom os import listdir\nfrom os.path import join\nfrom pandas import read_csv\nfrom tqdm import tqdm_notebook \n\ndef extract_features(label_path, set_path):\n    # Load all images and the corresponding labels\n    images = []\n    labels = []\n\n    # Create a pre-trained model\n    model = VGG19(include_top=False, input_shape=(image_size[0], image_size[1], 3))\n\n    train_labels = read_csv(label_path)\n    for image_name in tqdm_notebook (listdir(set_path)):\n        image = load_img(join(set_path, image_name), target_size=image_size)\n        images.append(img_to_array(image))\n        label = train_labels[train_labels['id'] == image_name]['has_cactus'].item()\n        labels.append(label)\n\n    training_images = preprocess_input(array(images))\n    training_labels = array(labels)\n\n    # Use the pre-trained network to extract features\n    features = model.predict(training_images)\n    \n    return features, training_labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from joblib import dump\nfrom os import listdir\n\nfeatures, training_labels = extract_features('../input/train.csv', '../input/train/train')\n\n# Save the features and labels to files\ndump(features, 'features.dat')\ndump(training_labels, 'labels.dat')\n\ndisplay(listdir('.'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from joblib import load\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten \nfrom matplotlib.pyplot import legend, plot, show, title, xlabel, ylabel\nfrom pathlib import Path\n\n# Load the features and labels\nx_train = load('features.dat')\ny_train = load('labels.dat')\n\n# Build the model\nmodel = Sequential()\nmodel.add(Flatten(input_shape=x_train.shape[1:]))\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()\n\n# Compile and fit\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nfit_model = model.fit(x_train, y_train, epochs=50, shuffle=True, validation_split=0.05)\n\n# summarize history for accuracy\nplot(fit_model.history['acc'])\nplot(fit_model.history['val_acc'])\ntitle('model accuracy')\nylabel('accuracy')\nxlabel('epoch')\nlegend(['train', 'test'], loc='upper left')\nshow()\n\n# summarize history for loss\nplot(fit_model.history['loss'])\nplot(fit_model.history['val_loss'])\ntitle('model loss')\nylabel('loss')\nxlabel('epoch')\nlegend(['train', 'test'], loc='upper left')\nshow()\n\n# Save the trained network\nPath('model_structure.json').write_text(model.to_json())\nmodel.save_weights('model_weights.h5')\n\ndisplay(listdir('.'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from csv import writer\nfrom keras.applications.vgg19 import preprocess_input\nfrom keras.models import model_from_json\nfrom keras.preprocessing.image import img_to_array\nfrom numpy import array\nfrom pathlib import Path\nfrom tqdm import tqdm_notebook \n\n# Load our trained model\nmodel_structure = Path('model_structure.json').read_text()\nmodel = model_from_json(model_structure)\nmodel.load_weights('model_weights.h5')\n\nimages = []\nfor image_name in tqdm_notebook(listdir('../input/test/test')):\n    image = load_img(join('../input/test/test', image_name), target_size=image_size)\n    images.append(img_to_array(image))\n    \nimages_to_predict = preprocess_input(array(images))\n\nfeature_extractor = VGG19(include_top=False, input_shape=(image_size[0], image_size[1], 3))\nfeatures = feature_extractor.predict(images_to_predict)\npredictions = model.predict(features)\n\ndisplay(predictions)\n\nwith open('submission.csv', 'w+') as submissionCsvFile:\n    csvWriter = writer(submissionCsvFile, lineterminator='\\n')\n    csvWriter.writerow(['id', 'has_cactus'])\n    \n    for index, image_name in enumerate(listdir('../input/test/test')):        \n        csvWriter.writerow([image_name, predictions[index][0]])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}