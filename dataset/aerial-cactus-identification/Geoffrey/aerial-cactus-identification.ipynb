{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nfrom __future__ import absolute_import, division, print_function, unicode_literals\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport PIL.Image as Image\nimport seaborn as sns\nsns.set(style=\"darkgrid\")\n\nimport os\nprint(os.listdir(\"../input\"))\n\n\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pylab as plt\n\nimport tensorflow as tf\ntf.enable_eager_execution()\n\nimport tensorflow_hub as hub\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/train.csv')\nsubmission=pd.read_csv('../input/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df['has_cactus'].value_counts())\nsns.countplot(x='has_cactus',data=df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(tf.test.is_gpu_available())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(os.listdir(\"../input/train/train\")))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"\ntrain_dir=\"../input/train/train\"\ntest_dir=\"../input/test/test\"\n\nprint(\"The Training Dir is {}\\nThe Validataion Dir is {}\".format(len(train_dir),len(test_dir)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image = Image.open(r\"../input/train/train/097480900e80806b84d5caa082eb34d1.jpg\")\ndisplay(image)\nimage = np.array(image)\ndisplay(image.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.has_cactus=df.has_cactus.astype(str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE=100\nIMG_SHAPE  = 224  # Our training data consists of images with width of 150 pixels and height of 150 pixels\ntrain_generator     = ImageDataGenerator(rescale=1./255,\n                                               rotation_range=40,\n                                                            width_shift_range=0.2,\n                                                            height_shift_range=0.2,\n                                                            shear_range=0.2,\n                                                            zoom_range=0.2,\n                                                            horizontal_flip=True,\n                                                            fill_mode='nearest')  # Generator for our training data\ntest_generator = ImageDataGenerator(rescale=1./255)  # Generator for our validation data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data=train_generator.flow_from_dataframe(dataframe=df[:15001],directory=train_dir,x_col='id',\n                                            y_col=\"has_cactus\",class_mode='binary',batch_size=BATCH_SIZE,\n                                            target_size=(IMG_SHAPE,IMG_SHAPE))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data[0][1].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_data=test_generator.flow_from_dataframe(dataframe=df[15000:],directory=train_dir,x_col='id',\n                                            y_col=\"has_cactus\",class_mode='binary',batch_size=BATCH_SIZE,\n                                            target_size=(224,224))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_data[0][1].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#loading the state of art neural network \n# URL = \"https://tfhub.dev/google/imagenet/inception_resnet_v2/classification/3\"\n\n# IMAGE_RES = 224\n\n# feature_extractor =  hub.Module(URL)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Freezing so that the training modeifies only the final layer\n#feature_extractor.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(224, 224, 3)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    \n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    \n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    \n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dense(2, activation='softmax')\n])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam', \n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS = 10\nhistory = model.fit_generator(\n    train_data,steps_per_epoch=10,\n    epochs=EPOCHS,\n    validation_data=validation_data,\n    validation_steps =20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history.history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history.history['acc']\nval_acc = history.history['val_acc']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(EPOCHS)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.savefig('./foo.png')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import PIL.Image as Image\n\n\ntest_image = os.listdir(train_dir)\n\nprint(test_image[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#image =tf.keras.utils.get_file('655c71d8c3f3d61f3797545e7d0414ce.jpg',train_dir+'655c71d8c3f3d61f3797545e7d0414ce.jpg')\nimage = Image.open(train_dir+'/'+test_image[0]).resize((IMG_SHAPE,IMG_SHAPE),3)\nimage","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if image.mode != \"RGB\":\n    image = image.convert(\"RGB\")\n\nimage = image.resize((224,224))\nimage= np.array(image)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(image[np.newaxis, ...].shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = model.predict(image[np.newaxis, ...])\nprint(max(prediction))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}