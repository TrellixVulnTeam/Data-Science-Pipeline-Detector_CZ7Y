{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.image as mpimg\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision.transforms as transforms\nimport torchvision\nfrom torch.utils.tensorboard import SummaryWriter\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data_dir = '../input'\ntrain_dir = data_dir + '/train/train/'\ntest_dir = data_dir + '/test/test/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = pd.read_csv(\"../input/train.csv\")\nlabels.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ImageData(Dataset):\n    def __init__(self, df, data_dir, transform):\n        super().__init__()\n        self.df = df\n        self.data_dir = data_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):       \n        img_name = self.df.id[index]\n        label = self.df.has_cactus[index]\n        \n        img_path = os.path.join(self.data_dir, img_name)\n        image = mpimg.imread(img_path)\n        image = self.transform(image)\n        return image, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 10\nbatch_size = 20\ndevice = torch.device('cuda:0')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Network(nn.Module): \n    def __init__(self):\n        super(Network, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3)\n        self.bn1 = nn.BatchNorm2d(32)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n        self.bn2 = nn.BatchNorm2d(64)\n        self.conv3 = nn.Conv2d(64, 128, kernel_size=3)\n        self.bn3 = nn.BatchNorm2d(128)\n        self.conv4 = nn.Conv2d(128, 256, kernel_size=3)\n        self.bn4 = nn.BatchNorm2d(256)\n        self.conv5 = nn.Conv2d(256, 512, kernel_size=3)\n        self.bn5 = nn.BatchNorm2d(512)\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.fc1 = nn.Linear(512, 1024)\n        self.fc2 = nn.Linear(1024, 2)\n\n    def forward(self, x):\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = F.relu(self.bn3(self.conv3(x)))\n        x = self.pool(x)\n        x = F.relu(self.bn4(self.conv4(x)))\n        x = self.pool(x)\n        x = F.relu(self.bn5(self.conv5(x)))\n        x = self.pool(x)\n        x = x.view(x.shape[0],-1)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_transf = transforms.Compose([transforms.ToPILImage(), transforms.ToTensor()])\ntrain_data = ImageData(df = labels, data_dir = train_dir, transform = data_transf)\ntrain_loader = DataLoader(dataset = train_data, batch_size = batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_size = len(train_data)\nvalidation_split = .2\nsplit = int(np.floor(validation_split * data_size))\nindices = list(range(data_size))\nnp.random.shuffle(indices)\n\n\ntrain_indices, val_indices = indices[split:], indices[:split]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.data.sampler import SubsetRandomSampler, Sampler\ntrain_sampler = SubsetRandomSampler(train_indices)\nval_sampler = SubsetRandomSampler(val_indices)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n                                           sampler=train_sampler)\nval_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n                                         sampler=val_sampler)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net = Network().to(device)\noptimizer = optim.Adam(net.parameters(), lr=0.001)\nloss_func = nn.CrossEntropyLoss()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(model, train_loader, val_loader, loss, optimizer, num_epochs):    \n    loss_history = []\n    train_history = []\n    val_history = []\n    for epoch in range(num_epochs):\n        model.train() # Enter train mode\n        \n        loss_accum = 0\n        correct_samples = 0\n        total_samples = 0\n        for i_step, (x, y) in enumerate(train_loader):\n            prediction = model(x.to(device))    \n            loss_value = loss(prediction, y.to(device))\n            optimizer.zero_grad()\n            loss_value.backward()\n            optimizer.step()\n            \n            _, indices = torch.max(prediction, 1)\n            correct_samples += torch.sum(indices == y.to(device))\n            total_samples += y.shape[0]\n            \n            loss_accum += loss_value\n    \n        ave_loss = loss_accum / (i_step + 1)\n        train_accuracy = float(correct_samples) / total_samples\n        val_accuracy = compute_accuracy(model, val_loader)\n        \n        loss_history.append(float(ave_loss))\n        train_history.append(train_accuracy)\n        val_history.append(val_accuracy)\n        \n        print(\"Average loss: %f, Train accuracy: %f, Val accuracy: %f\" % (ave_loss, train_accuracy, val_accuracy))\n        \n    return loss_history, train_history, val_history, model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def compute_accuracy(model, loader):\n    \"\"\"\n    Computes accuracy on the dataset wrapped in a loader\n    \n    Returns: accuracy as a float value between 0 and 1\n    \"\"\"\n    correct_samples = 0\n    total_samples = 0\n    model.eval() # Evaluation mode\n    for inputs, labels in loader:\n        prediction = model(inputs.to(device))    \n        _, indices = torch.max(prediction, 1)\n        correct_samples += torch.sum(indices == labels.to(device))\n        total_samples += labels.shape[0]\n    validation_accuracy = float(correct_samples) / total_samples\n        \n    return validation_accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss_history, train_history, val_history, trained_model = train_model(net, train_loader, val_loader, loss_func, optimizer, 20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit = pd.read_csv('../input/sample_submission.csv')\ntest_data = ImageData(df = submit, data_dir = test_dir, transform = data_transf)\ntest_loader = DataLoader(dataset = test_data, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net = trained_model\npredict = []\nfor batch_i, (data, target) in enumerate(test_loader):\n    data, target = data.to(device), target.to(device)\n    output = net(data)\n    \n    _, pred = torch.max(output.data, 1)\n    predict.append(int(pred))\n    \nsubmit['has_cactus'] = predict\nsubmit.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}