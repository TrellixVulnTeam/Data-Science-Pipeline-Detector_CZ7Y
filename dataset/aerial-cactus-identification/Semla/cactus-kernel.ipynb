{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import keras\nfrom keras.preprocessing import image\nfrom keras.callbacks import ModelCheckpoint\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# much prefer ggplot to plt but there seems to be a bug somewhere, can't install?\n#!pip install plotnine\n#!pip install 'plotnine[all]' \n#from plotnine import *\n\nfrom IPython.display import Image\nimport os\n#print(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load & explore data"},{"metadata":{},"cell_type":"markdown","source":"![](http://)Read training data from csv file and print first ten rows. As you can see the data is in the form of the name of an image file and whether it has cactus or not.\n\nUsing **pandas** (dataframes) makes alot of sense, for instance the flow_from_dataframe is convenient. Found a medium article from the author of this feature iiuc: https://medium.com/@vijayabhaskar96/tutorial-on-keras-flow-from-dataframe-1fd4493d237c"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_dir=\"../input/train/train\"\ntest_dir=\"../input/test/test\"\ntrain_data_labels = pd.read_csv('../input/train.csv') # training data and labels\ntest_data_labels = pd.read_csv('../input/sample_submission.csv') # # test data and labels\n\nprint(train_data_labels.shape)\nprint(test_data_labels.shape)\n\nhead_train_data_labels = train_data_labels.head(10)\nprint(head_train_data_labels)\nprint(type(head_train_data_labels))\n#print(test_data_labels.head(3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Show some images and their label."},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_img_label(df, directory):\n    for i, sample in df.iterrows():\n        #print(i)\n        #print(type(sample))\n        #f\"{train_dir}/{\n        img_file = sample['id']\n        img_data = plt.imread(f\"{directory}/{img_file}\")\n        #print(img)\n        plt.figure()\n        plt.text(10,40, f\"has cactus: {sample['has_cactus']}\")\n        plt.imshow(img_data)\n    \nplot_img_label(head_train_data_labels, train_dir)\n#plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ggplot(train_labels, aes('has cactus')) + \\\n #   geom_bar(stat = 'count')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create & compile model"},{"metadata":{},"cell_type":"markdown","source":"Since it is still images 2d convolutional layers are used. Check out the great Kaggle learning on the topic. \nI think Keras can guess the input shape of the first layer, except when using Generators and printing history (from the top of my head). So better to specify it. As can be seen in the images plotted above they are size 32,32 and b/w hence **input_shape=(32,32,1)** (the last 1 means only one channel, color image would have three)."},{"metadata":{"trusted":true},"cell_type":"code","source":"model= keras.models.Sequential()\nmodel.add(keras.layers.Conv2D(32,(3,3),activation='relu', input_shape=(32,32,1), padding='same' ))\nmodel.add(keras.layers.MaxPool2D(2,2))\nmodel.add(keras.layers.Conv2D(64,(3,3),activation='relu', padding='same' ))\nmodel.add(keras.layers.MaxPool2D((2,2))) # , padding='same' ))\nmodel.add(keras.layers.Conv2D(128,(3,3),activation='relu', padding='same'))\nmodel.add(keras.layers.MaxPool2D((2,2)))\nmodel.add(keras.layers.Conv2D(256,(3,3),activation='relu', padding='same'))\nmodel.add(keras.layers.MaxPool2D((2,2), padding='same' ))\n#model.add(keras.layers.Conv2D(256,(3,3),activation='relu', padding='same'))\n#model.add(keras.layers.MaxPool2D((2,2), padding='same' ))\nmodel.add(keras.layers.Dense(512, activation='relu'))\nmodel.add(keras.layers.Flatten())\nmodel.add(keras.layers.Dense(1,activation='sigmoid'))\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(), metrics= ['acc']) #lr=0.001\n#model.compile(loss='binary_crossentropy',optimizer=keras.optimizers.rmsprop(),metrics=['acc'])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train the model, then predict & submit"},{"metadata":{},"cell_type":"markdown","source":"Generators supply batches of samples to be run through the network. Instead of keeping them all in memory the machine can run a batch, release them and continue to the next batch. This also makes preprocessing a breeze, in this case done with ImageDataGenerator, which is done on the fly on the batches.\n\nThe ImageDataGenerator randomly changes the images a little on each epoch. I used to think that new images are created but iiuc that is not the way it works. Instead the images are changed a little according to the settings specified when creating an instance of image.ImageDataGenerator(). Depending on the problem different settings make sense, for instance many times flip_horizontal works while flip_vertical does not. In this case it is not so obvious what works.. do cactuses grow branches in a certain angle of the sun? And the aerial photography always using the samke angle. If so rotation may be bad. In any case I am keeping the transformations small. Might also make sense since the dataset is not that small."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Specify settings for the generators\ntrain_gen = image.ImageDataGenerator( rescale=1./255)# , rotation_range=10, width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True, vertical_flip=True) \n# todo: investigate if rotation & flipping is good? horizontal_flip=True\n\nval_gen = image.ImageDataGenerator(rescale=1./255) # no image augmentation on validation\nbatch_size = 100\n\ntrain_data_labels.has_cactus=train_data_labels.has_cactus.astype(str)\n# TypeError: If class_mode=\"binary\", y_col=\"has_cactus\" column values must be strings.\n\nvalidation_samples_num = 2000\ntrain_samples_num = train_data_labels.shape[0] - validation_samples_num\n\n# Create generator functions\n\n# Generator for supplying batches from training data\ntrain_generator = train_gen.flow_from_dataframe(dataframe= train_data_labels.iloc[:train_samples_num],directory=train_dir,x_col='id',\n                                            y_col='has_cactus',class_mode='binary',batch_size=batch_size\n                                              ,target_size=(32,32), color_mode='grayscale'\n                                            )\n\n# Generator for supplying batches from validation data\nvalidation_generator = val_gen.flow_from_dataframe(dataframe= train_data_labels.iloc[train_samples_num:], directory=train_dir,x_col='id',\n                                                y_col='has_cactus', class_mode='binary', batch_size=batch_size\n                                                ,target_size=(32,32), color_mode='grayscale'\n                                                  )\n\n# Generator for supplying batches from test data\ntest_generator = val_gen.flow_from_dataframe(dataframe= test_data_labels.iloc[:], directory=test_dir,x_col='id',\n                                                y_col='has_cactus', class_mode=None, batch_size= batch_size\n                                                ,target_size=(32,32), color_mode='grayscale', shuffle=False\n                                                  )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(train_samples_num / batch_size)\n# {epoch:03d}-{acc:03f}-{val_acc:03f}\ncheckpoint = ModelCheckpoint('best-model.h5', verbose=1, monitor='val_loss',save_best_only=True, mode='auto')\nhistory=model.fit_generator(train_generator, steps_per_epoch = train_samples_num // batch_size ,epochs=15,validation_data=validation_generator, validation_steps = validation_samples_num // batch_size, callbacks=[checkpoint] )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmodel.load_weights(filepath = 'best-model.h5')\n                   \n# todo: use flow from directory instead?\ntest_generator.reset()\npredictions = model.predict_generator( test_generator, steps=test_data_labels.shape[0] // batch_size, verbose=1 )\nprint(predictions[:10])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Inspect the predictions. Also plot some test images and their predictions.\n\n*It is recommended to never even peak at test-data. If you make any changes to your model based on the test-data, it is a very bad thing.*"},{"metadata":{"trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"print(predictions.shape)\nprint(test_data_labels.shape)\ndf = pd.DataFrame({'id':test_data_labels['id'], 'has_cactus' : predictions[:,0] })\nprint(df.shape)\nprint(df.head())\nplot_img_label(df.head(), test_dir)\ndf.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}