{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!pip install torchinfo\nimport os\nimport zipfile\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn.functional as F\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torchvision import transforms\nfrom torchinfo import summary\nfrom skimage import io\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2021-07-29T08:37:57.501061Z","iopub.execute_input":"2021-07-29T08:37:57.501408Z","iopub.status.idle":"2021-07-29T08:38:03.738488Z","shell.execute_reply.started":"2021-07-29T08:37:57.501378Z","shell.execute_reply":"2021-07-29T08:38:03.737474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATA_DIR        = '../input/aerial-cactus-identification/'\nTRAIN_ZIP_DIR   = DATA_DIR + 'train.zip'\nTEST_ZIP_DIR    = DATA_DIR + 'test.zip'\nSAMPLE_SUBMIS   = DATA_DIR + 'sample_submission.csv'\nANNOTATIONS_DIR = DATA_DIR + 'train.csv'\nTRAIN_DIR       = './train'\nTEST_DIR        = './test'\n\nDEVICE          = 'cuda' if torch.cuda.is_available() else 'cpu'\nN_LABELS        = 2\nN_EPOCHS        = 10\nBATCH_SIZE      = 64\nLEARNING_RATE   = 0.001\nMOMENTUM        = 0.9\nLABELS_MAP      = {0: 'No Cactus', 1: 'Cactus'}\n\ndef init_weights(layer):\n    if type(layer) in [nn.Linear, nn.Conv2d]:\n        nn.init.xavier_uniform_(layer.weight)\n        layer.bias.data.fill_(0.01)\n\ndef display_data(data, n=10, classes=None):\n    fig, ax = plt.subplots(1, n, figsize=(15,3))\n    indices = np.random.randint(0, len(data), size=n)\n    for i, j in enumerate(indices):\n        ax[i].imshow(np.transpose(data[j][0], (1, 2, 0)))\n        ax[i].axis('off')\n        if classes:\n            ax[i].set_title(classes[data[j][1]])\n            \ndef train_epoch(model, \n                dataloader, \n                lr=LEARNING_RATE, \n                optimizer=None, \n                loss_fn=nn.NLLLoss()):\n    optimizer = optimizer or torch.optim.Adam(model.parameters(), lr=lr)\n    model.train()\n    total_loss, accuracy, count = 0, 0, 0\n    for X, y in dataloader:\n        X, y = X.to(DEVICE), y.to(DEVICE)\n        optimizer.zero_grad()\n        out = model(X)\n        loss = loss_fn(out, y)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss\n        predicted = torch.max(out, 1)[1]\n        accuracy += (predicted == y).sum()\n        count += len(y)\n    return total_loss.item() / count, accuracy.item() / count\n\ndef validate(model, \n             dataloader, \n             loss_fn=nn.NLLLoss()):\n    model.eval()\n    total_loss, accuracy, count = 0, 0, 0\n    with torch.no_grad():\n        for X, y in dataloader:\n            X, y = X.to(DEVICE), y.to(DEVICE)\n            out = model(X)\n            total_loss += loss_fn(out, y)\n            predicted = torch.max(out, 1)[1]\n            accuracy += (predicted == y).sum()\n            count += len(y)\n    return total_loss.item() / count, accuracy.item() / count \n    \ndef train(model, \n          train_loader, \n          valid_loader=None, \n          optimizer=None, \n          lr=LEARNING_RATE, \n          epochs=N_EPOCHS, \n          loss_fn=nn.NLLLoss()):\n    optimizer = optimizer or torch.optim.Adam(net.parameters(),lr=lr)\n    history = {'train_loss': [], 'train_accuracy': []}\n    if valid_loader is not None:\n        history['validation_loss'] = []\n        history['validation_accuracy'] = []\n    for epoch in range(epochs):\n        tl, ta = train_epoch(model, \n                             train_loader, \n                             lr=lr, \n                             optimizer=optimizer, \n                             loss_fn=loss_fn)\n        history['train_loss'].append(tl)\n        history['train_accuracy'].append(ta)\n        if valid_loader is not None:\n            vl, va = validate(model, valid_loader, loss_fn=loss_fn)\n            print(f\"Epoch {epoch:2}, Train Acc = {ta:.3f}, Val Acc = {va:.3f}, Train Loss = {tl:.3f}, Val Loss={vl:.3f}\")\n            history['validation_loss'].append(vl)\n            history['validation_accuracy'].append(va)\n        else:\n            print(f\"Epoch {epoch:2}, Train Acc = {ta:.3f}, Train Loss = {tl:.3f}\")\n    return history\n\ndef plot_history(history, validation=False):\n    plt.figure(figsize=(15, 5))\n    plt.subplot(121)\n    plt.ylabel('Accuracy')\n    plt.xlabel('Epochs')\n    plt.plot(history['train_accuracy'], label='Training')\n    if validation:\n        plt.plot(history['validation_accuracy'], label='Validation')\n    plt.legend()\n    plt.subplot(122)\n    plt.ylabel('Loss')\n    plt.xlabel('Epochs')\n    plt.plot(history['train_loss'], label='Training')\n    if validation:\n        plt.plot(history['validation_loss'], label='Validation')\n    plt.legend()\n    \ndef submission(dataset, model):\n    model.eval()\n    result = []\n    with torch.no_grad():\n        for datapoint in dataset:\n            X = datapoint[0][None, ...].to(DEVICE)\n            out = model(X)\n            result.append([datapoint[1], float(torch.exp(out)[0][1])])\n    df = pd.DataFrame(result, columns = ['id', 'has_cactus'])\n    df = df.set_index('id')\n    df = df.sort_values('id')\n    df.to_csv('./submission.csv')\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-07-29T08:45:57.325435Z","iopub.execute_input":"2021-07-29T08:45:57.325805Z","iopub.status.idle":"2021-07-29T08:45:57.356327Z","shell.execute_reply.started":"2021-07-29T08:45:57.325775Z","shell.execute_reply":"2021-07-29T08:45:57.355405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not os.path.exists(TRAIN_DIR):\n    with zipfile.ZipFile(TRAIN_ZIP_DIR, 'r') as zip_ref:\n        zip_ref.extractall('./')\nif not os.path.exists(TEST_DIR):\n    with zipfile.ZipFile(TEST_ZIP_DIR, 'r') as zip_ref:\n        zip_ref.extractall('./')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-29T08:38:03.77138Z","iopub.execute_input":"2021-07-29T08:38:03.772059Z","iopub.status.idle":"2021-07-29T08:38:03.781428Z","shell.execute_reply.started":"2021-07-29T08:38:03.772022Z","shell.execute_reply":"2021-07-29T08:38:03.780729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ACIDataset(Dataset):\n    def __init__(self, \n                 img_dir,\n                 annotations_file=None, \n                 transform=None, \n                 target_transform=None):\n        self.img_dir = img_dir\n        self.is_labeled = False\n        if annotations_file is not None:\n            self.is_labeled = True\n            self.img_labels = pd.read_csv(annotations_file)\n        else:\n            self.img_labels = pd.DataFrame(os.listdir(img_dir))\n        self.transform = transform\n        self.target_transform = target_transform\n        \n    def __len__(self):\n        return len(self.img_labels)\n    \n    def __getitem__(self, idx):\n        img_path = os.path.join(self.img_dir, \n                                self.img_labels.iloc[idx, 0])\n        image = io.imread(img_path)\n        if self.transform:\n            image = self.transform(image)\n        if self.is_labeled:\n            label = self.img_labels.iloc[idx, 1]\n            if self.target_transform:\n                label = self.target_transform(label)\n            sample = [image, label]\n        else:\n            sample = [image, self.img_labels.iloc[idx, 0]]\n        return sample\n\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) \n\ndata = ACIDataset(\n    img_dir=TRAIN_DIR,\n    annotations_file=ANNOTATIONS_DIR,\n    transform=transform,\n    target_transform=None)\n\ntest_data = ACIDataset(\n    img_dir=TEST_DIR,\n    transform=transform)\n\ntrain_data, val_data = random_split(data, [len(data) * 8 // 10, \n                                           len(data) * 2 // 10])\n\ntrain_dl = DataLoader(train_data, batch_size=BATCH_SIZE)\nvalid_dl = DataLoader(val_data, batch_size=BATCH_SIZE)\nall_dl   = DataLoader(data, batch_size=BATCH_SIZE)\ntest_dl  = DataLoader(test_data, batch_size=BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2021-07-29T08:38:03.783018Z","iopub.execute_input":"2021-07-29T08:38:03.783368Z","iopub.status.idle":"2021-07-29T08:38:03.821193Z","shell.execute_reply.started":"2021-07-29T08:38:03.783335Z","shell.execute_reply":"2021-07-29T08:38:03.82052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_data(data, n=12, classes=LABELS_MAP)","metadata":{"execution":{"iopub.status.busy":"2021-07-29T08:38:03.937401Z","iopub.execute_input":"2021-07-29T08:38:03.937778Z","iopub.status.idle":"2021-07-29T08:38:04.544892Z","shell.execute_reply.started":"2021-07-29T08:38:03.937749Z","shell.execute_reply":"2021-07-29T08:38:04.544114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(\n            in_channels=3,\n            out_channels=10,\n            kernel_size=(5, 5))\n        self.pool = nn.MaxPool2d(\n            kernel_size=(2, 2))\n        self.conv2 = nn.Conv2d(\n            in_channels=10,\n            out_channels=20,\n            kernel_size=(3, 3))\n        self.fc = nn.Linear(\n            in_features = 20*6*6,\n            out_features = 2)\n        \n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 20*6*6)\n        x = F.log_softmax(self.fc(x), dim=1)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-07-29T08:38:04.627063Z","iopub.execute_input":"2021-07-29T08:38:04.627347Z","iopub.status.idle":"2021-07-29T08:38:04.634392Z","shell.execute_reply.started":"2021-07-29T08:38:04.62732Z","shell.execute_reply":"2021-07-29T08:38:04.633584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = Net().to(DEVICE)\n# model.apply(init_weights)\n# summary(model, input_size=(1,3,32,32))","metadata":{"execution":{"iopub.status.busy":"2021-07-29T08:05:02.823806Z","iopub.execute_input":"2021-07-29T08:05:02.824301Z","iopub.status.idle":"2021-07-29T08:05:05.080244Z","shell.execute_reply.started":"2021-07-29T08:05:02.824263Z","shell.execute_reply":"2021-07-29T08:05:05.079409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# optimizer = torch.optim.Adam(model.parameters(), \n#                              lr=LEARNING_RATE)\n# history = train(model, \n#                 train_dl, \n#                 valid_dl, \n#                 optimizer=optimizer, \n#                 lr=LEARNING_RATE, \n#                 epochs=N_EPOCHS, \n#                 loss_fn=nn.NLLLoss())","metadata":{"execution":{"iopub.status.busy":"2021-07-29T08:05:05.082553Z","iopub.execute_input":"2021-07-29T08:05:05.082923Z","iopub.status.idle":"2021-07-29T08:07:14.06619Z","shell.execute_reply.started":"2021-07-29T08:05:05.082883Z","shell.execute_reply":"2021-07-29T08:07:14.065117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot_history(history, validation=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-29T08:07:14.068094Z","iopub.execute_input":"2021-07-29T08:07:14.068488Z","iopub.status.idle":"2021-07-29T08:07:14.359588Z","shell.execute_reply.started":"2021-07-29T08:07:14.068432Z","shell.execute_reply":"2021-07-29T08:07:14.358639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture\nmodel_ = Net().to(DEVICE)\nmodel_.apply(init_weights)","metadata":{"execution":{"iopub.status.busy":"2021-07-29T08:38:07.666128Z","iopub.execute_input":"2021-07-29T08:38:07.666464Z","iopub.status.idle":"2021-07-29T08:38:07.675685Z","shell.execute_reply.started":"2021-07-29T08:38:07.666433Z","shell.execute_reply":"2021-07-29T08:38:07.674791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = torch.optim.Adam(model_.parameters(), \n                             lr=LEARNING_RATE)\nhistory = train(model_, \n                all_dl, \n                optimizer=optimizer, \n                lr=LEARNING_RATE, \n                epochs=N_EPOCHS, \n                loss_fn=nn.NLLLoss())","metadata":{"execution":{"iopub.status.busy":"2021-07-29T08:38:11.278929Z","iopub.execute_input":"2021-07-29T08:38:11.279247Z","iopub.status.idle":"2021-07-29T08:40:22.424371Z","shell.execute_reply.started":"2021-07-29T08:38:11.27921Z","shell.execute_reply":"2021-07-29T08:40:22.422106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history(history)","metadata":{"execution":{"iopub.status.busy":"2021-07-29T08:40:22.427247Z","iopub.execute_input":"2021-07-29T08:40:22.427659Z","iopub.status.idle":"2021-07-29T08:40:22.899094Z","shell.execute_reply.started":"2021-07-29T08:40:22.427616Z","shell.execute_reply":"2021-07-29T08:40:22.898214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission(test_data, model_)","metadata":{"execution":{"iopub.status.busy":"2021-07-29T08:46:09.249886Z","iopub.execute_input":"2021-07-29T08:46:09.250213Z","iopub.status.idle":"2021-07-29T08:46:15.62388Z","shell.execute_reply.started":"2021-07-29T08:46:09.250182Z","shell.execute_reply":"2021-07-29T08:46:15.622879Z"},"trusted":true},"execution_count":null,"outputs":[]}]}