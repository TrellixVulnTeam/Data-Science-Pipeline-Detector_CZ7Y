{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\nimport sklearn\nimport sklearn.model_selection\nimport scikitplot\n\nimport matplotlib.pyplot as plt\nimport tensorflow.keras as keras\nimport tensorflow as tf\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from skimage.io import imread\nfrom skimage.transform import rotate\ntrain_df = pd.read_csv('../input/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = []\ntrain_tgt = []\n\nfor idx, row in train_df.iterrows():\n    img = imread('../input/train/train/' + row['id'])\n    train_data.append(img)\n    train_tgt.append(row['has_cactus'])\n\ntrain_data = np.array(train_data)\ntrain_tgt = np.array(train_tgt)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_X, val_X, train_y, val_y = sklearn.model_selection.train_test_split(train_data, train_tgt, test_size=0.40)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"m0 = train_X[:,:,:,0].mean()\nm1 = train_X[:,:,:,1].mean()\nm2 = train_X[:,:,:,2].mean()\n\ndef augmented(data: list, tgt: list):\n    aug_data = []\n    aug_tgt = []\n\n    for i in range(data.shape[0]):\n        img = data[i, :, :, :]\n\n        # img[:,:,0] = (img[:,:,0] - m0)/128.\n        # img[:,:,1] = (img[:,:,1] - m1)/128.\n        # img[:,:,2] = (img[:,:,2] - m2)/128.\n        img = img/255.\n        \n        aug_data.append(img)\n\n        aug_data.append(rotate(img, 90.))\n        aug_data.append(rotate(img, 180.))\n        aug_data.append(rotate(img, 270.))\n\n        aug_data.append(np.flip(img))\n        aug_data.append(np.flip(img, axis=0))\n        aug_data.append(np.flip(img, axis=1))\n        \n        aug_tgt.append(tgt[i])\n        \n        aug_tgt.append(tgt[i])\n        aug_tgt.append(tgt[i])\n        aug_tgt.append(tgt[i])\n        \n        aug_tgt.append(tgt[i])\n        aug_tgt.append(tgt[i])\n        aug_tgt.append(tgt[i])\n\n    return np.array(aug_data), np.array(aug_tgt)\n\ntrain_X, train_y = augmented(train_X, train_y)\nval_X, val_y = augmented(val_X, val_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X.mean(axis=0).mean(axis=0).mean(axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_X.mean(axis=0).mean(axis=0).mean(axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = keras.Sequential([\n    keras.layers.InputLayer(input_shape=(32, 32, 3), batch_size=None, name='input'),\n\n    keras.layers.Conv2D(128, 1, 1, 'SAME', activation=keras.activations.relu, name='bottleneck1/conv1'),\n    keras.layers.Conv2D(16, 3, 1, 'SAME', activation=keras.activations.relu, name='bottleneck1/conv2'),\n    keras.layers.BatchNormalization(name='bottleneck1/bn1'),\n    \n    keras.layers.Conv2D(128, 1, 1, 'SAME', activation=keras.activations.relu, name='bottleneck2/conv1'),\n    keras.layers.Conv2D(32, 3, 2, 'SAME', activation=keras.activations.relu, name='bottleneck2/conv2'),\n    keras.layers.BatchNormalization(name='bottleneck2/bn1'),\n    \n    keras.layers.Conv2D(128, 1, 1, 'SAME', activation=keras.activations.relu, name='bottleneck3/conv1'),\n    keras.layers.Conv2D(64, 3, 2, 'SAME', activation=keras.activations.relu, name='bottleneck3/conv2'),\n    keras.layers.BatchNormalization(name='bottleneck3/bn1'),\n    \n    keras.layers.Flatten(name='flatten'),\n    \n    keras.layers.Dense(1, activation=keras.activations.sigmoid, name='prob')\n], name='sequential0')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n                              patience=5, min_lr=1e-9, verbose=1)\nearly_stop = keras.callbacks.EarlyStopping(monitor='loss', min_delta=1e-6, patience=5, verbose=True)\nmodel.compile(\n    loss='binary_crossentropy',\n    optimizer=keras.optimizers.SGD(lr=0.0001, decay=0),\n    metrics=['accuracy']\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(\n    x=train_X,\n    y=train_y,\n    validation_data=(val_X, val_y),\n    epochs=100, batch_size=50,\n    callbacks=[reduce_lr],\n    verbose=0\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_y = model.predict(train_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('validation accuracy: {}'.format(sklearn.metrics.roc_auc_score(train_y, pred_y)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dff = (train_y >0).flatten() != (pred_y > 0.75).flatten()\nfor idx in np.where(dff)[0]:\n    plt.figure()\n    print(val_y[idx], pred_y[idx])\n    for i in range(4):\n        I = val_X[idx+(2*i-1),:,:,:]\n        plt.subplot(2, 2, i+1)\n        plt.imshow(I)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_y[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_df = pd.read_csv('../input/sample_submission.csv')\ntest_X = []\nfor idx, row in output_df.iterrows():\n    test_X.append(imread('../input/test/test/' + row['id'])/255.)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_X = np.array(test_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_y = model.predict(test_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_df['has_cactus'] = test_y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!head submission.csv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save_weights('weights.hdf')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}