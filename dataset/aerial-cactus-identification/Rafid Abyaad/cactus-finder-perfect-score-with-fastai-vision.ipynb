{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Cactus Classifier with fastai.vision\n\nThis dataset is perfect for beginners, because the problem is literally trying to find stick-like patterns.Also fastai.vision library gives score 1 with little to no effort.\nI've tried densenet and resnet here and they both give perfect score. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom pathlib import Path\nfrom fastai import *\nfrom fastai.vision import *\nimport torch\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_folder = Path(\"../input\")\ntrain_df = pd.read_csv(\"../input/train.csv\")\ntest_df = pd.read_csv(\"../input/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_img = ImageList.from_df(test_df, path=data_folder/'test', folder='test')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"src = (ImageList.from_df(train_df, path=data_folder/'train', folder='train')\n        .split_by_rand_pct(0.01)\n        .label_from_df()\n        .add_test(test_img)\n       )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_img=src.databunch('.',bs=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_img.show_batch()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Transforms\n\nFrom the competetion details, we know these images were taken from air. So they resemble satelite imagery. Looking at the images though, they are very low resolution and look very ugly when blown up :D\n\nAnyways, some features are apparent from looking at the data:\n1. Some pictures are flipped vertically.\n2. Some are rotated.\n3. Some are zoomed in and some aren't.\n\nLucky for us, fastai has some default transforms ready. All we need to do is to plug them in. Default transforms include zooms, rotations and lighting.\nI'm just adding vertical flip in to account for aerial imagery."},{"metadata":{"trusted":true},"cell_type":"code","source":"tfms=get_transforms(flip_vert=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_img = (src.transform(tfms,size=128)\n            .databunch('.',bs=50)\n       )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training Densenet"},{"metadata":{"trusted":true},"cell_type":"code","source":"denselearner = cnn_learner(train_img, models.densenet161, metrics=[FBeta(),error_rate, accuracy])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"denselearner.lr_find()\ndenselearner.recorder.plot(suggestion=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = 7.5e-03\ndenselearner.fit_one_cycle(5, slice(lr))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"denselearner.unfreeze()\ndenselearner.lr_find()\ndenselearner.recorder.plot(suggestion=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"denselearner.fit_one_cycle(1, slice(1e-06))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training Resnet\nDensenet takes quite a lot of time considering this problem is trivial. Bit of an overkill to be honest.\nLet's try Resnet."},{"metadata":{"trusted":true},"cell_type":"code","source":"reslearner = cnn_learner(train_img, models.resnet101, metrics=[FBeta(),error_rate, accuracy])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reslearner.lr_find()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reslearner.recorder.plot(suggestion=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr=9e-3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reslearner.fit_one_cycle(5,slice(lr))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reslearner.unfreeze()\nreslearner.fit_one_cycle(2,slice(1e-6))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Resnet converges to 100% accuracy very quickly.\nPlotting losses and watching confusion matrix is of no need."},{"metadata":{"trusted":true},"cell_type":"code","source":"interp = ClassificationInterpretation.from_learner(reslearner)\ninterp.plot_top_losses(9, figsize=(7,6))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds,_ = reslearner.get_preds(ds_type=DatasetType.Test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.has_cactus = preds.numpy()[:, 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}