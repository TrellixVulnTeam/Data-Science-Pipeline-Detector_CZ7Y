{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom tqdm import tqdm, tqdm_notebook\nimport cv2 as cv\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":30,"outputs":[{"output_type":"stream","text":"['test', 'train', 'train.csv', 'sample_submission.csv']\n","name":"stdout"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# read dataset\n\n\ntrain_data = pd.read_csv('../input/train.csv')\ntrain_data.head()\n\ntraining_path = '../input/train/train/'\ntest_path = '../input/test/test/'\n\nimages_train = []\nlabels_train = []\n\nimages = train_data['id'].values\nfor image_id in tqdm_notebook(images):\n    \n    image = np.array(cv.imread(training_path + image_id))\n    label = train_data[train_data['id'] == image_id]['has_cactus'].values[0]\n    \n    images_train.append(image)\n    labels_train.append(label)\n    \n    images_train.append(np.flip(image))\n    labels_train.append(label)\n    \n    images_train.append(np.flipud(image))\n    labels_train.append(label)\n    \n    images_train.append(np.fliplr(image))\n    labels_train.append(label)\n    \n    \nimages_train = np.asarray(images_train)\nimages_train = images_train.astype('float32')\nimages_train /= 255.\n\nlabels_train = np.asarray(labels_train)\n\n","execution_count":31,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, max=17500), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5bd12395aee14ea694f97577e09dd059"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# read test set\n\ntest_images_names = []\n\nfor filename in os.listdir(test_path):\n    test_images_names.append(filename)\n    \ntest_images_names.sort()\n\nimages_test = []\n\nfor image_id in tqdm_notebook(test_images_names):\n    images_test.append(np.array(cv.imread(test_path + image_id)))\n    \nimages_test = np.asarray(images_test)\nimages_test = images_test.astype('float32')\nimages_test /= 255","execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, max=4000), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0646e337e5264519aafb5386e78aa0f3"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train/val split\n\n\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(images_train, labels_train, test_size = 0.30, stratify = labels_train)\n","execution_count":33,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# augment data\nfrom keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(\n                               width_shift_range=0.1, # Shift the pic width by a max of 10%\n                               height_shift_range=0.1, # Shift the pic height by a max of 10%\n                               horizontal_flip=True, # Allo horizontal flipping\n                               fill_mode='nearest' # Fill in missing pixels with the nearest filled value\n                              )\n","execution_count":34,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# build the model\nfrom keras.models import Sequential\nfrom keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D\n\nmodel = Sequential()\n\n# let's get 3 convolutional layers\n\nmodel.add(Conv2D(filters=32, kernel_size=(3,3),\n                 input_shape=(32,32,3), activation='relu',))\n\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3,3),\n                 input_shape=(32,32,3), activation='relu',))\n\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3,3),\n                 input_shape=(32,32,3), activation='relu',))\n\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n\nmodel.add(Flatten())\n\n# fully connected part of the network (158 neurons layer)\n\nmodel.add(Dense(128))\nmodel.add(Activation('relu'))\n\n# Dropouts help reduce overfitting by randomly turning neurons off during training.\n# Here we say randomly turn off 50% of neurons.\nmodel.add(Dropout(0.5))\n\n# Last layer, remember its binary, 0=cat , 1=dog\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))\n\n# we compile the model selecting the loss function, the optimization function and our metric\nmodel.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\nmodel.summary()\n","execution_count":35,"outputs":[{"output_type":"stream","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_8 (Conv2D)            (None, 30, 30, 32)        896       \n_________________________________________________________________\nmax_pooling2d_7 (MaxPooling2 (None, 15, 15, 32)        0         \n_________________________________________________________________\nconv2d_9 (Conv2D)            (None, 13, 13, 64)        18496     \n_________________________________________________________________\nmax_pooling2d_8 (MaxPooling2 (None, 6, 6, 64)          0         \n_________________________________________________________________\nconv2d_10 (Conv2D)           (None, 4, 4, 64)          36928     \n_________________________________________________________________\nmax_pooling2d_9 (MaxPooling2 (None, 2, 2, 64)          0         \n_________________________________________________________________\nflatten_3 (Flatten)          (None, 256)               0         \n_________________________________________________________________\ndense_5 (Dense)              (None, 128)               32896     \n_________________________________________________________________\nactivation_5 (Activation)    (None, 128)               0         \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 128)               0         \n_________________________________________________________________\ndense_6 (Dense)              (None, 1)                 129       \n_________________________________________________________________\nactivation_6 (Activation)    (None, 1)                 0         \n=================================================================\nTotal params: 89,345\nTrainable params: 89,345\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define callbacks\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n\nweight_name = 'weights_aerial_cactus.h5'\n\ncallback = [EarlyStopping(monitor='val_loss', \n                          mode='min', \n                          verbose=1, \n                          patience=10),\n            ReduceLROnPlateau(monitor='val_loss', \n                              factor=0.2,\n                              patience=5, \n                              min_lr=0.001,\n                              verbose=1),\n            ModelCheckpoint(filepath = weight_name,\n                            save_best_only=True,\n                            save_weights_only=True,\n                            verbose=1)]","execution_count":36,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train the CNN\nprint('training on: ', len(x_train))\nprint('validating on: ', len(x_test))\n\nmodel.fit_generator(\n    datagen.flow(x_train, y_train, batch_size=20),\n    steps_per_epoch=len(x_train)/20, \n    validation_data=(x_test, y_test),\n    epochs=100, \n    callbacks=callback\n                   )","execution_count":38,"outputs":[{"output_type":"stream","text":"training on:  49000\nvalidating on:  21000\nEpoch 1/100\n2450/2450 [==============================] - 67s 27ms/step - loss: 0.2193 - acc: 0.9155 - val_loss: 0.1400 - val_acc: 0.9439\n\nEpoch 00001: val_loss improved from inf to 0.14003, saving model to weights_aerial_cactus.h5\nEpoch 2/100\n2450/2450 [==============================] - 68s 28ms/step - loss: 0.1336 - acc: 0.9495 - val_loss: 0.0866 - val_acc: 0.9651\n\nEpoch 00002: val_loss improved from 0.14003 to 0.08659, saving model to weights_aerial_cactus.h5\nEpoch 3/100\n2450/2450 [==============================] - 69s 28ms/step - loss: 0.0964 - acc: 0.9633 - val_loss: 0.0599 - val_acc: 0.9777\n\nEpoch 00003: val_loss improved from 0.08659 to 0.05990, saving model to weights_aerial_cactus.h5\nEpoch 4/100\n2450/2450 [==============================] - 69s 28ms/step - loss: 0.0772 - acc: 0.9719 - val_loss: 0.0823 - val_acc: 0.9664\n\nEpoch 00004: val_loss did not improve from 0.05990\nEpoch 5/100\n2450/2450 [==============================] - 69s 28ms/step - loss: 0.0753 - acc: 0.9725 - val_loss: 0.0981 - val_acc: 0.9622\n\nEpoch 00005: val_loss did not improve from 0.05990\nEpoch 6/100\n2450/2450 [==============================] - 69s 28ms/step - loss: 0.0641 - acc: 0.9764 - val_loss: 0.0335 - val_acc: 0.9873\n\nEpoch 00006: val_loss improved from 0.05990 to 0.03352, saving model to weights_aerial_cactus.h5\nEpoch 7/100\n2450/2450 [==============================] - 70s 29ms/step - loss: 0.0590 - acc: 0.9781 - val_loss: 0.0518 - val_acc: 0.9793\n\nEpoch 00007: val_loss did not improve from 0.03352\nEpoch 8/100\n2450/2450 [==============================] - 70s 29ms/step - loss: 0.0554 - acc: 0.9804 - val_loss: 0.0577 - val_acc: 0.9778\n\nEpoch 00008: val_loss did not improve from 0.03352\nEpoch 9/100\n2450/2450 [==============================] - 70s 29ms/step - loss: 0.0529 - acc: 0.9809 - val_loss: 0.0482 - val_acc: 0.9816\n\nEpoch 00009: val_loss did not improve from 0.03352\nEpoch 10/100\n2450/2450 [==============================] - 69s 28ms/step - loss: 0.0479 - acc: 0.9828 - val_loss: 0.0624 - val_acc: 0.9777\n\nEpoch 00010: val_loss did not improve from 0.03352\nEpoch 11/100\n2450/2450 [==============================] - 70s 29ms/step - loss: 0.0490 - acc: 0.9827 - val_loss: 0.1040 - val_acc: 0.9552\n\nEpoch 00011: ReduceLROnPlateau reducing learning rate to 0.001.\n\nEpoch 00011: val_loss did not improve from 0.03352\nEpoch 12/100\n2450/2450 [==============================] - 69s 28ms/step - loss: 0.0475 - acc: 0.9827 - val_loss: 0.0497 - val_acc: 0.9804\n\nEpoch 00012: val_loss did not improve from 0.03352\nEpoch 13/100\n2450/2450 [==============================] - 69s 28ms/step - loss: 0.0425 - acc: 0.9851 - val_loss: 0.0303 - val_acc: 0.9890\n\nEpoch 00013: val_loss improved from 0.03352 to 0.03028, saving model to weights_aerial_cactus.h5\nEpoch 14/100\n2450/2450 [==============================] - 71s 29ms/step - loss: 0.0429 - acc: 0.9846 - val_loss: 0.0223 - val_acc: 0.9922\n\nEpoch 00014: val_loss improved from 0.03028 to 0.02230, saving model to weights_aerial_cactus.h5\nEpoch 15/100\n2450/2450 [==============================] - 70s 29ms/step - loss: 0.0404 - acc: 0.9859 - val_loss: 0.0418 - val_acc: 0.9844\n\nEpoch 00015: val_loss did not improve from 0.02230\nEpoch 16/100\n2450/2450 [==============================] - 69s 28ms/step - loss: 0.0456 - acc: 0.9840 - val_loss: 0.0589 - val_acc: 0.9781\n\nEpoch 00016: val_loss did not improve from 0.02230\nEpoch 17/100\n2450/2450 [==============================] - 68s 28ms/step - loss: 0.0394 - acc: 0.9866 - val_loss: 0.0281 - val_acc: 0.9903\n\nEpoch 00017: val_loss did not improve from 0.02230\nEpoch 18/100\n2450/2450 [==============================] - 69s 28ms/step - loss: 0.0383 - acc: 0.9862 - val_loss: 0.0400 - val_acc: 0.9850\n\nEpoch 00018: val_loss did not improve from 0.02230\nEpoch 19/100\n2450/2450 [==============================] - 69s 28ms/step - loss: 0.0399 - acc: 0.9857 - val_loss: 0.0493 - val_acc: 0.9803\n\nEpoch 00019: ReduceLROnPlateau reducing learning rate to 0.001.\n\nEpoch 00019: val_loss did not improve from 0.02230\nEpoch 20/100\n2450/2450 [==============================] - 71s 29ms/step - loss: 0.0349 - acc: 0.9876 - val_loss: 0.0363 - val_acc: 0.9870\n\nEpoch 00020: val_loss did not improve from 0.02230\nEpoch 21/100\n2450/2450 [==============================] - 70s 29ms/step - loss: 0.0362 - acc: 0.9870 - val_loss: 0.1225 - val_acc: 0.9532\n\nEpoch 00021: val_loss did not improve from 0.02230\nEpoch 22/100\n2450/2450 [==============================] - 69s 28ms/step - loss: 0.0386 - acc: 0.9867 - val_loss: 0.0272 - val_acc: 0.9905\n\nEpoch 00022: val_loss did not improve from 0.02230\nEpoch 23/100\n2450/2450 [==============================] - 69s 28ms/step - loss: 0.0365 - acc: 0.9871 - val_loss: 0.0245 - val_acc: 0.9910\n\nEpoch 00023: val_loss did not improve from 0.02230\nEpoch 24/100\n2450/2450 [==============================] - 68s 28ms/step - loss: 0.0355 - acc: 0.9871 - val_loss: 0.0447 - val_acc: 0.9843\n\nEpoch 00024: ReduceLROnPlateau reducing learning rate to 0.001.\n\nEpoch 00024: val_loss did not improve from 0.02230\nEpoch 00024: early stopping\n","name":"stdout"},{"output_type":"execute_result","execution_count":38,"data":{"text/plain":"<keras.callbacks.History at 0x7fc7a6d317f0>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# perform prediction\nmodel.load_weights(weight_name)\n\npredictions = model.predict(images_test, verbose = 1)\n\npredictions\n\n","execution_count":39,"outputs":[{"output_type":"stream","text":"4000/4000 [==============================] - 1s 352us/step\n","name":"stdout"},{"output_type":"execute_result","execution_count":39,"data":{"text/plain":"array([[0.9999815 ],\n       [1.        ],\n       [0.00112909],\n       ...,\n       [1.        ],\n       [1.        ],\n       [1.        ]], dtype=float32)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# send results\ntest_df = pd.read_csv('../input/sample_submission.csv')\nX_test = []\nimages_test = test_df['id'].values\n\nfor img_id in tqdm_notebook(images_test):\n    X_test.append(cv.imread(test_path + img_id))\n    \nX_test = np.asarray(X_test)\nX_test = X_test.astype('float32')\nX_test /= 255\n\ny_test_pred = model.predict_proba(X_test)\n\ntest_df['has_cactus'] = y_test_pred\ntest_df.to_csv('aerial-cactus-submission.csv', index = False)","execution_count":42,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, max=4000), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5732836ed9c941e19616c80b07e2094e"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print report\n\nfrom sklearn.metrics import confusion_matrix, roc_auc_score, classification_report\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nx_tr = images_train\ny_tr = labels_train\n\nimages_train = x_tr\nlabels_train = y_tr\n\ny_pred_probability = model.predict_proba(x_tr)\n\ny_pred = model.predict_classes(x_tr)\nconf_matrix = confusion_matrix(y_tr, y_pred)\nfig, ax = plt.subplots(figsize = (10, 10))\n\nsns.heatmap(conf_matrix, annot = True, fmt = 'd', xticklabels = ['0', '1'], yticklabels = ['0', '1'])\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\nplt.show()\n\nprint(classification_report(y_tr, y_pred, target_names = ['0','1']))\nprint(\"\\n\\n AUC: {:<0.4f}\".format(roc_auc_score(y_tr, y_pred_probability)))","execution_count":49,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 720x720 with 2 Axes>","image/png":"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\n"},"metadata":{}},{"output_type":"stream","text":"              precision    recall  f1-score   support\n\n           0       0.99      0.98      0.99     17456\n           1       0.99      1.00      1.00     52544\n\n   micro avg       0.99      0.99      0.99     70000\n   macro avg       0.99      0.99      0.99     70000\nweighted avg       0.99      0.99      0.99     70000\n\n\n\n AUC: 0.9997\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}