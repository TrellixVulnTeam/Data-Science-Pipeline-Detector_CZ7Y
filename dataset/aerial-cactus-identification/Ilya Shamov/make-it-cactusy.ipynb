{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom tensorflow.python.keras.applications.resnet50 import preprocess_input\nfrom tensorflow.python.keras.preprocessing.image import load_img, img_to_array\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.python import keras\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense, Flatten, Conv2D, Dropout","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Load train imgs data and labels\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_img_dir = \"../input/train/train/\"\ntrain_img_pathes = [train_img_dir + fpath for fpath in sorted(os.listdir(train_img_dir))]\n\ndf = pd.read_csv(\"../input/train.csv\")\n\ntrain_img_pathes[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check corresponding between labels and imgs\nlst = sorted(os.listdir(train_img_dir))\nerr = False\n\nfor i, idx in enumerate(df[\"id\"]):\n    if idx != lst[i]:\n        print(\"mismatch after %d iterations\" % i)\n        err = True\n        break\n\nif not err:\n    print(\"1:1 corresponding between train_img_pathes and df labels\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_size = 32\n\n\ndef read_and_prep_images(img_paths, img_height=img_size, img_width=img_size):\n    # to avoid OSError tooManyOpenedFiles I used batch loading\n    img_load_batch_size = 900\n    output = None\n    \n    for i in range(0, len(img_paths), img_load_batch_size):\n        print(\"process batch %d\" % i)\n        tmp_imgs =  [load_img(img_path, target_size=(img_height, img_width)) \n                     for img_path \n                     in img_paths[i:i+img_load_batch_size]]\n        tmp_img_array = np.array([img_to_array(img) for img in tmp_imgs])\n        \n        if type(output) != np.ndarray:\n            output = preprocess_input(tmp_img_array)\n        else:\n            output = np.vstack((output, preprocess_input(tmp_img_array)))\n        \n    return(output)\n\n\ntrain_imgs = read_and_prep_images(train_img_pathes)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Prepare model\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_classes = 2\nout_y = keras.utils.to_categorical(df[\"has_cactus\"], num_classes)\n\nnp.shape(train_imgs[0])\n\nmodel = Sequential()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.add(Conv2D(filters=50, kernel_size=(3, 3), input_shape=(32, 32, 3), activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Conv2D(30, kernel_size=(3, 3), activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Flatten())\nmodel.add(Dense(54, activation=\"relu\"))\nmodel.add(Dense(num_classes, activation=\"softmax\"))\n\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=\"adam\",\n              metrics=[\"accuracy\"])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fit model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(train_imgs, out_y,\n          batch_size=int(17500*0.8/100),\n          epochs=4,\n          validation_split = 0.2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now ready to classify test images"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_img_dir = \"../input/test/test/\"\ntest_img_pathes = [test_img_dir + fpath for fpath in sorted(os.listdir(test_img_dir))]\ntest_imgs = read_and_prep_images(test_img_pathes)\n\ntest_img_pathes[:5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Make predictions and write them to file"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"prediction = model.predict_proba(test_imgs)[:, 1]\nanswer = pd.DataFrame(columns=(\"id\", \"has_cactus\"))\n\ngetFilename = lambda s: s.split(\"/\")[-1]\nfor i in range(len(test_img_pathes)):\n    #print(getFilename(test_img_pathes[i]), prediction[i])\n    answer.loc[i] = (getFilename(test_img_pathes[i]), prediction[i])\n\nanswer.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"answer.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}