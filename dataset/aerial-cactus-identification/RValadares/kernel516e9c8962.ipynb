{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#Conceitos de Redes Convolucionais\n\n#Arquitetura\n\n#Trata se da organização da estrutura da rede, ou seja:\n#Quantidade de camadas (e quantidade de nós em cada camada);\n#Conexões;\n#Parâmetros;\n#Unidades de aprendizado.\n#As redes são organizadas em camadas, que ganham um formato de cadeia. Em cada camada é aplicada a função de ativação.\n#Os valores de saída das camadas servem de entrada para a camada seguinte.\n\n\n#Camadas de Convolução\n\n#Existem Arquiteturas específicas, isto é, desenvolvidas para realizar tarefas de alta complexidade: aplicação de filtros para gerar imagens novas ou reconhecimento de imagens.\n#As redes convolucionais são um exemplo deste tipo de arquitetura, são redes especializadas em processamento de dados com topologias que podem ser semelhante a grades – dados de imagem #com representação em uma grade 2D de pixels por exemplo.\n#O nome convolucional faz referência a compilação matemática realizada neste tipo de rede. Faz-se uso da convolução no lugar da multiplicação de matrizes em pelo menos uma de suas #camadas.\n#Convolução – Operador linear aplicado a duas funções cujo objetivo é medir uma terceira área subentendida pela sobreposição das mesmas em função do deslocamento existente entre elas.\n\n    \n#Camadas de Pooling\n\n#As camadas de agrupamento possuem a função de reduzir progressivamente o tamanho espacial da representação para reduzir a quantidade de parâmetros e o esforço computacional.\n#Simplifica a informação da camada anterior.\n\n    \n#Funções de ativação\n\n\n#São funções que Trazem a não-linearidade ao sistema -  para que a rede consiga aprender qualquer tipo de funcionalidade\n\n#Filtros\n\n#É um componente da camada de convolução, Trata - se da Matriz utilizada para multiplicar um conjunto de pixels para realizar uma transformação – comportamento, imagens. Cada filtro #produz um ângulo novo da imagem.\n\n\n#Camada densa\n\n#Última camada, normalmente representada por uma rede Perceptron de múltiplas camadas – MLP.\n\n#Transfer Learning\n\n#Aproveitamento de uma rede (Camadas, Filtros e pesos da rede neural) Que serão expostos a um novo grupo de treinamento com novas classes de saída.\n#Visa Aproveitar um Conhecimento Prévio e otimizar o tempo Face a  possibilidade de convergência mais rápida para os pesos reais.\n\n\n#Data Augmentation\n\n#Aumentar a quantidade de amostras de forma artificial, significa a Agregação de valor aos dados da base através da adição de informações derivadas de transformações.\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Importando Bibliotecas \n\n#Bibliotecas Módulos Utilização\n\n#Numpy            Usada com frequência para realizar cálculos em arrays multidimensionais\n#Pandas           Fornece ferramentas de análise de dados e estruturas de dados.\n#Pathlib          Object oriented filesystem paths  Trata se de um módulo com várias classes.\n#Fastai           Biblioteca opensource para Deep Learning\n#Fastai.vision    Módulo da biblioteca fastai com funções para definir um Dataset e treinar modelos para\n#                        tarefas de visão computacional\n#Torch            Biblioteca de machine learning, framework de computação científica e script language\n#                         baseado em uma linguagem de programação (Lua).\n#OS               Módulo de Iteração com o sistema operacional  vem na instalação do Python\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport torch \n\n# Biblioteca para facilitar a analise e processamento de imagens\n# Guia https://docs.fast.ai/\nfrom fastai import * \nfrom fastai.vision import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Leitura dos arquivos e declaração de variáveis","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/aerial-cactus-identification/train.csv\")\ntest_df = pd.read_csv(\"../input/aerial-cactus-identification/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_img = ImageList.from_df(test_df, path='../input/aerial-cactus-identification/test', folder='test')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Criar variável com padrões para formatação da imagem\n\n#do_flip : seTrue, um flip aleatório é aplicado com probabilidade de 0,5 \n#flip_vert : requer do_flip=True . Se for Verdadeiro, a imagem pode ser invertida verticalmente ou girada em 90 graus, caso contrário, apenas uma inversão horizontal é aplicada\t\n#max_rotate : se não for None, uma rotação aleatória entre -max_rotate e max_rotate degrees é aplicada com probabilidade p_affine\n#max_zoom : se não 1. ou menos, um zoom aleatório entre 1. e max_zoom é aplicado com probabilidade p_affine\n#max_lighting : se não for None, uma alteração aleatória de raio e contraste controlada por max_lighting é aplicada com probabilidade p_lighting \n#max_warp : se não for nenhum, uma deformação simétrica aleatória de magnitude entre -max_warp e maw_warp é aplicada com probabilidade p_affine\n#p_affine : a probabilidade de cada transformada de afim e dobra simétrica ser aplicada \n#p_lighting : a probabilidade de que cada transformação de iluminação seja aplicada","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trfm2 = get_transforms(do_flip=True, flip_vert=True, max_rotate=0, max_zoom=0, max_lighting=0.2, max_warp=0.2, p_affine=0.5, p_lighting=0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Criar treinamento baseado nas configurações criadas anteriormente!\n\n#Processadas em cima da placa grafica \t# split_by_rand_pct : Como dividir em treino / válido? -> aleatoriamente com o padrão de 20% em válido","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_img2 = (ImageList.from_df(train_df, path='../input/aerial-cactus-identification/train', folder='train')\n        .split_by_rand_pct(0.01)\n        .label_from_df()\n        .add_test(test_img)\n        .transform(trfm2, size=128)\n        .databunch(path='.', bs=64, device= torch.device('cuda:0'))\n        .normalize(imagenet_stats)\n       )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Aplicar o treinamento no modelo densenet161\n# Modelo que obteve a maior acurácia, tendo sido testados os modelos resnet18, inception_v3 e o densenet161\n# Modelos https://pytorch.org/docs/stable/torchvision/models.html","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn2 = cnn_learner(train_img2, models.densenet161, metrics=[error_rate, accuracy])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gerar 5 ciclos de aprendizagem com o slice de 3e-02 \n# Obteve a maior acurácia\n# Slice #Em vez de definir manualmente um LR para cada grupo, geralmente é mais fácil de usar Learner.lr_range.\n#Este é um método de conveniência que retorna uma taxa de aprendizado para cada grupo de camadas.\n#Se você passar, #slice(start,end) então a taxa de aprendizado do primeiro grupo é start a última end, e as restantes são uniformemente geometricamente espaçadas.\n#Se você passar só slice(end) então a taxa de aprendizado do último grupo é end, e todos os outros grupos são end/10.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn2.fit_one_cycle(5, slice(3e-02))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Buscar os dados em forma de DataSet\n# Formatando o dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds,_ = learn2.get_preds(ds_type=DatasetType.Test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Gerar arquivo para submissão:","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.has_cactus = preds.numpy()[:, 0]","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}