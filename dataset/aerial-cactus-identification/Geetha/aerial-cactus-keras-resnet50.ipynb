{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\n\ninput_dir = os.path.dirname(\"../input/aerial-cactus-identification/\")\nprint(os.listdir(input_dir))\n\ntrain = pd.read_csv(os.path.join(input_dir, \"train.csv\"))\ntest = pd.read_csv(os.path.join(input_dir, \"sample_submission.csv\"))\n                                \n# Any results you write to the current directory are saved as output.","execution_count":11,"outputs":[{"output_type":"stream","text":"['train', 'test', 'train.csv', 'sample_submission.csv']\n","name":"stdout"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"images = np.array(train.id.values)\nlabels = np.array(train.has_cactus)\n\n# split data into train/val - train-12000, val-5499\ntrain_images = images[:12000]\ntrain_labels = labels[:12000]\n\nval_images = images[12001:]\nval_labels = labels[12001:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\nimg_base_dir = \"train/train/\"\ntrn_data=[]\nfor name in train_images:\n    img_path = img_base_dir + name\n    i = cv2.imread(os.path.join(input_dir, img_path))  \n    trn_data.append(i)\n\ntrn_data = np.array(trn_data)\nprint('trn data shape', trn_data.shape)\n\nval_data=[]\nfor name in val_images:\n    img_path = img_base_dir + name\n    i = cv2.imread(os.path.join(input_dir, img_path))  \n    val_data.append(i)\n\nval_data = np.array(val_data)\nprint('val data shape', val_data.shape)\n\ntest_data=[]\ntest_img_base_dir = \"test/test/\"\ntest_images =  np.array(test.id.values)\ntest_labels = np.array(test.has_cactus)\n\nfor name in test_images:\n    img_path = test_img_base_dir + name\n    i = cv2.imread(os.path.join(input_dir, img_path))  \n    test_data.append(i)\n    \ntest_data = np.array(test_data)\nprint('test data shape', test_data.shape)","execution_count":15,"outputs":[{"output_type":"stream","text":"trn data shape (12000, 32, 32, 3)\nval data shape (5499, 32, 32, 3)\ntest data shape (4000, 32, 32, 3)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test_images)","execution_count":28,"outputs":[{"output_type":"stream","text":"['000940378805c44108d287872b2f04ce.jpg'\n '0017242f54ececa4512b4d7937d1e21e.jpg'\n '001ee6d8564003107853118ab87df407.jpg' ...\n 'ffbd469c56873d064326204aac546e0d.jpg'\n 'ffcb76b7d47f29ece11c751e5f763f52.jpg'\n 'fffed17d1a8e0433a934db518d7f532c.jpg']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\nimport numpy as np\nfrom keras.applications.resnet50 import preprocess_input\n\ndef generator(features, labels, batch_size):\n    # Create empty arrays to contain batch of features and labels#\n    batch_features = np.zeros((batch_size, 32, 32, 3))\n    batch_labels = np.zeros((batch_size,1))\n    num_features = len(features)\n    \n#     print('number of features: ', num_features)\n    \n    while True:\n        for i in range(batch_size):\n            index= random.choice(np.arange(num_features))\n            _data = keras.applications.resnet50.preprocess_input(features[index])\n\n            batch_features[i] = _data\n            batch_labels[i] = labels[index]\n            \n#             print(batch_features)\n#             print(batch_labels)\n            \n        yield batch_features, batch_labels\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# trn_gen = generator(trn_data, train_labels, 32)\n# print(trn_data.shape[1:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom pathlib import Path\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Flatten, GlobalAveragePooling2D\n\nopt = keras.optimizers.SGD(lr=0.001, momentum=0.9, decay=1e-5)\n\nweights = Path('../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5')\nbase_model = keras.applications.resnet50.ResNet50(include_top=False, weights=weights, input_shape=trn_data.shape[1:])\nx = base_model.output\n# model.add(Flatten())\n# model = GlobalAveragePooling2D()(model.output)\n# model.add(Dense(units = 1, activation='sigmoid'))\nx = GlobalAveragePooling2D()(x)\nx = Dense(1024, activation='relu')(x)\npredictions = Dense(1, activation='sigmoid')(x)\nmodel = Model(inputs = base_model.input, outputs = predictions)\n\nmodel.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_epochs = 10\nbatch_size = 64\n\nn_steps = int(trn_data.shape[0]/batch_size)\nn_val = int(val_data.shape[0]/batch_size)\n\ntrn_gen = generator(trn_data, train_labels, batch_size)\nval_gen = generator(val_data, val_labels, batch_size)\n\nfit_history = model.fit_generator(generator=trn_gen, validation_data=val_gen, verbose=1, epochs=n_epochs, steps_per_epoch=n_steps, validation_steps=n_val, initial_epoch=0)\n# acc_val = history.history['val_acc']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = []\nfor i in test_data:\n    pred_img = i[np.newaxis, ...] # add batch dimension\n    pred_img = keras.applications.resnet50.preprocess_input(pred_img)\n    res = model.predict(pred_img, batch_size=1)\n    results.append(res[0][0])\n\nsubmission = {'id': test_images, 'has_cactus':results} \nsubmission = pd.DataFrame(submission)\nprint(submission.head())","execution_count":42,"outputs":[{"output_type":"stream","text":"                                     id  has_cactus\n0  000940378805c44108d287872b2f04ce.jpg    0.988097\n1  0017242f54ececa4512b4d7937d1e21e.jpg    0.982426\n2  001ee6d8564003107853118ab87df407.jpg    0.016319\n3  002e175c3c1e060769475f52182583d0.jpg    0.013419\n4  0036e44a7e8f7218e9bc7bf8137e4943.jpg    0.839309\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index=False)","execution_count":43,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}