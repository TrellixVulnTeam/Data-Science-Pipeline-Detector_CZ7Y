{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\nimport cv2\nfrom glob import glob\nimport torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nfrom PIL import Image, ImageFile\nfrom torch.utils.data import TensorDataset, DataLoader,Dataset\nfrom sklearn.model_selection import train_test_split\nimport copy \n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nImageFile.LOAD_TRUNCATED_IMAGES = True\n#print(os.listdir(\"../input\"))\n#../input/train/train\n#../input/train/test\n\n# Any results you write to the current directory are saved as output.\nuse_cuda = torch.cuda.is_available()\nif not use_cuda:\n    print('No GPU found. Please use a GPU to train your neural network.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_frame = pd.read_csv('../input/aerial-cactus-identification/train.csv')\ntest_frame = pd.read_csv('../input/aerial-cactus-identification/sample_submission.csv')\n# VGG16 = models.vgg16(pretrained=True)\n# train_data = torchvision.datasets.ImageFolder('../input/train/train/', transform=transform)\n# valid_data = torchvision.datasets.ImageFolder('/data/dog_images/valid/', transform=transform)\n# test_data = torchvision.datasets.ImageFolder('../input/test/test/', transform=transform_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# NOTE: class is inherited from Dataset\nclass ImageLabelDataset(Dataset):\n    def __init__(self, df_data, prediction, folder=\"../input\"):\n        super().__init__()\n        self.df = df_data.values\n        self.prediction = prediction.values\n        self.folder = folder\n\n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        tensorimage = self.preprocess_image(self.df[index])\n        # print(label)\n        label = self.prediction[index]\n        # print(label)\n        return tensorimage, label\n    \n    def preprocess_image(self, img_path):\n        data_transform = transforms.Compose([transforms.ToPILImage(),\n                                             transforms.Resize(224), \n                                             transforms.CenterCrop(224), \n                                             transforms.RandomRotation(30), \n                                             transforms.ToTensor()\n                                            ])\n        image = cv2.imread(\"{}/{}\".format(self.folder, img_path))\n        image = data_transform(image)\n        return image","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"def preprocess_image(img_path):\n    '''\n    Use pre-trained VGG-16 model to obtain index corresponding to \n    predicted ImageNet class for image at specified path\n    \n    Args:\n        img_path: path to an image\n        \n    Returns:\n        Index corresponding to VGG-16 model's prediction\n    '''\n    data_transform = transforms.Compose([transforms.ToPILImage(),\n                                         transforms.CenterCrop(224), \n                                         transforms.RandomRotation(30), \n                                         transforms.ToTensor(),\n                                         transforms.Normalize(mean=[0.5, 0.5, 0.5],std=[0.5, 0.5, 0.5])\n                                        ])\n    # train_data = datasets.ImageFolder(train_dir, transform=data_transform)\n    # train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n    # print(\"../input/train/train/{}\".format(img_path))\n    image = cv2.imread(\"../input/train/train/{}\".format(img_path))\n    # image = Image.open(\"../input/train/train/{}\".format(img_path))\n    image = data_transform(image)\n    # image = image.clone().detach().requires_grad_(True)\n    # image = torch.tensor(image, requires_grad=True, dtype=torch.float)\n    # image = image.unsqueeze(0)\n    # if use_cuda:\n        # image = image.cuda()    \n    \n    return image # predicted class index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# label_frame = label_frame[:20]\n# label_frame['tensorimage']=label_frame['id'].apply(preprocess_image)\n# label_frame['tensorimage']=label_frame['tensorimage'].astype(float)\nprint(label_frame.dtypes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# label_frame.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_set = label_frame[\"id\"]\nprediction_set = label_frame.has_cactus\nbatch_size = 1\n\ntest_set = test_frame[\"id\"]\ntest_prediction_set = test_frame.has_cactus\n\nX_train, X_val, Y_train, Y_val = train_test_split(training_set, prediction_set, test_size=0.1, random_state=42)\nprint(len(X_train))\nprint(len(Y_train))\n\nprint(len(X_val))\nprint(len(Y_val))\n\n# train_set = torch.utils.data.DataLoader(X_train, batch_size=batch_size, shuffle=True, num_workers=0)\n# train_set = torch.utils.data.TensorDataset(torch.FloatTensor(torch.from_numpy(X_train.values)), torch.FloatTensor(y_train.values))\n# val_set = torch.utils.data.DataLoader(X_val, batch_size=batch_size, shuffle=True, num_workers=0)\n\ntrain_set = ImageLabelDataset(df_data=X_train, prediction=Y_train, folder=\"../input/aerial-cactus-identification/train/train\")\nval_set = ImageLabelDataset(df_data=X_val, prediction=Y_val, folder=\"../input/aerial-cactus-identification/train/train\")\npredict_set = ImageLabelDataset(df_data=test_set, prediction=test_prediction_set, folder=\"../input/aerial-cactus-identification/test/test\")\n\ntrain_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0)\nval_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=0)\ntest_loader = torch.utils.data.DataLoader(predict_set, batch_size=1, shuffle=True, num_workers=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Hyperparameters\nbatch_no = len(X_train) // batch_size  #batches\n# cols=X_train.shape[1] #Number of columns in input matrix\nn_output=1\n\n# Sequence Length\nsequence_length = 6  # of words in a sequence 892110\n# Batch Size\n# batch_size = 128\n# train_loader = batch_data(int_text, sequence_length, batch_size)\n# Number of Epochs\nnum_epochs = 20\n# Learning Rate\nlearning_rate = 0.0002\n# Model parameters\n# Input size\n# input_size = cols\n# Output size\noutput_size = 1\n# Embedding Dimension\nembedding_dim = 128\n# Hidden Dimension\nhidden_dim = 256\n# Number of RNN Layers\nn_layers = 2\n\n# Show stats for every n number of batches\nshow_every_n_batches = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_rnn(model, batch_size, optimizer, criterion, n_epochs, show_every_n_batches=100):\n    train_loss = 0\n    valid_loss = 0\n    batch_losses = []\n    val_batch_losses = []\n    valid_loss_min = np.Inf\n    \n    model.train()\n    \n    previousLoss = np.Inf\n    minLoss = np.Inf\n\n    print(\"Training for %d epoch(s)...\" % n_epochs)\n    for epoch_i in range(1, n_epochs + 1):\n        model.train()\n        for batch_idx, (data, target) in enumerate(train_loader):\n            \n            if use_cuda:\n                data, target = data.cuda(), target.cuda()\n            # clear the gradients of all optimized variables\n            # print(np.squeeze(target))\n            optimizer.zero_grad()\n            # forward pass: compute predicted outputs by passing inputs to the model\n            output = model(data)\n            # calculate the batch loss      \n            loss = criterion(output, target)\n            # backward pass: compute gradient of the loss with respect to model parameters\n            loss.backward()\n            # perform a single optimization step (parameter update)\n            optimizer.step()\n            # update training loss\n            ## find the loss and update the model parameters accordingly\n            ## record the average training loss, using something like\n            #batch_losses.append(loss.item())\n            train_loss += ((1 / (batch_idx + 1)) * (loss.item() - train_loss))\n            \n        model.eval()\n        for batch_idx, (data, target) in enumerate(val_loader):\n            # move to GPU\n            if use_cuda:\n                data, target = data.cuda(), target.cuda()\n            ## update the average validation loss\n            # forward pass: compute predicted outputs by passing inputs to the model\n            output = model(data)\n            # calculate the batch loss\n            loss = criterion(output, target)\n            # update average validation loss \n            #val_batch_losses.append(loss.item())\n            valid_loss += ((1 / (batch_idx + 1)) * (loss.item() - valid_loss))\n        \n        valid_loss = valid_loss/len(val_loader.dataset)\n        train_loss = train_loss/len(train_loader.dataset)\n        \n        #train_loss = np.average(batch_losses)\n        #valid_loss = np.average(val_batch_losses)\n        \n        # print training/validation statistics \n        if epoch_i%show_every_n_batches == 0:\n            print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(epoch_i, train_loss, valid_loss))\n        \n            ## TODO: save the model if validation loss has decreased\n            # save model if validation loss has decreased\n            if valid_loss < valid_loss_min:\n                print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n                valid_loss_min,\n                valid_loss))\n                with open('trained_rnn_new', 'wb') as pickle_file:\n                    torch.save(model.state_dict(), 'trained_rnn_new')\n                valid_loss_min = valid_loss\n                train_loss = 0\n                valid_loss = 0\n                batch_losses = []\n                val_batch_losses = []\n  \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_transfer = models.vgg16(pretrained=True)\nprint(model_transfer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# os.mkdir(\"../save\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Freeze training for all \"features\" layers\nfor param in model_transfer.features.parameters():\n    param.requires_grad = False\n    \ncustom_model = nn.Sequential(nn.Linear(25088, 1024), \n                  nn.ReLU(),\n                  nn.Dropout(p=0.5), \n                  nn.Linear(1024, 512), \n                  nn.ReLU(),\n                  nn.Dropout(p=0.5),\n                  nn.Linear(512, 2)\n                 )\n\nmodel_transfer.classifier = custom_model\n\nif use_cuda:\n    model_transfer = model_transfer.cuda()\n\n# print(model_transfer)\n\n# specify loss function\ncriterion_scratch = nn.CrossEntropyLoss()\n#criterion_scratch = nn.BCELoss()\n\n# specify optimizer\noptimizer_scratch = optim.SGD(model_transfer.classifier.parameters(), lr=learning_rate, momentum=0.9)\n#optimizer_scratch = optim.Adam(model_transfer.classifier.parameters(),lr=0.0001)\n\n#trained_rnn = train_rnn(model_transfer, batch_size, optimizer_scratch, criterion_scratch, num_epochs, show_every_n_batches)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#optimizer_scratch = optim.SGD(model_transfer.classifier.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0001)\n#train_rnn(model_transfer, batch_size, optimizer_scratch, criterion_scratch, num_epochs, show_every_n_batches)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_transfer.load_state_dict(torch.load('trained_rnn_new'))\n# test_files = np.array(glob(\"test/*\"))\n# print(test_files[:3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(file):\n    test_transform = transforms.Compose([transforms.ToPILImage(),\n                                             transforms.Resize(224), \n                                             transforms.CenterCrop(224), \n                                             transforms.ToTensor()\n                                            ])\n    image = cv2.imread(file)\n    image = test_transform(image)\n    image = image.unsqueeze(0)\n    if use_cuda:\n        image = image.cuda()\n    \n    output = model_transfer(image)\n    print(output)\n    pr = output[:,1].detach().cpu().numpy()\n    print(pr)\n    # print(os.path.basename(file))\n    print(output)\n    values, indices = output.max(1)\n    #print(values)\n    #print(indices)\n    return os.path.basename(file), indices.item()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_transfer.eval()\nsubmission = pd.read_csv('../input/aerial-cactus-identification/sample_submission.csv')\npreds = []\nfor batch_idx, (data, target) in enumerate(test_loader):\n    # move to GPU\n    if use_cuda:\n        data, target = data.cuda(), target.cuda()\n    ## update the average validation loss\n    # forward pass: compute predicted outputs by passing inputs to the model\n    output = model_transfer(data)\n    values, indices = output.max(1)\n    pr = output[:,1].detach().cpu().numpy()\n    preds.append(indices.item())\n    #for i in pr:\n        #preds.append(i)\n    #print(output)\n    #print(pr)\n    #print(values)\n    #print(indices)\n    # calculate the batch loss\nsubmission[\"has_cactus\"] = preds\nprint(submission.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission_61.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictoutput = pd.read_csv(\"../input/mydatasetforaerialcactus/submission_output.csv\")\npredictoutput.to_csv('submission_6.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import the modules we'll need\nfrom IPython.display import HTML\nimport base64\n\n# function that takes in a dataframe and creates a text link to  \n# download it (will only work for files < 2MB or so)\ndef create_download_link(df, title = \"Download CSV file\", filename=\"submission_1.csv\"):  \n    csv = df.to_csv(index=False)\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\n\n# create a link to download the dataframe\ncreate_download_link(submission)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.2"}},"nbformat":4,"nbformat_minor":1}