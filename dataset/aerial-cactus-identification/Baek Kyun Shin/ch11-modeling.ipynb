{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 11.4 항공 사진 내 선인장 식별 경진대회 성능 개선\n- [항공 사진 내 선인장 식별 경진대회 링크](https://www.kaggle.com/c/aerial-cactus-identification)\n- [모델링 코드 참고 링크](https://www.kaggle.com/bonhart/simple-cnn-on-pytorch-for-beginers)\n","metadata":{"papermill":{"duration":0.019252,"end_time":"2021-07-31T07:35:11.559316","exception":false,"start_time":"2021-07-31T07:35:11.540064","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import torch # 파이토치 \nimport random\nimport numpy as np\nimport os\n\n# 시드값 고정\nseed = 50\nos.environ['PYTHONHASHSEED'] = str(seed)\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\ntorch.backends.cudnn.enabled = False","metadata":{"papermill":{"duration":1.251689,"end_time":"2021-07-31T07:35:16.100289","exception":false,"start_time":"2021-07-31T07:35:14.8486","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-06T09:09:17.213993Z","iopub.execute_input":"2022-03-06T09:09:17.214789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"papermill":{"duration":0.073723,"end_time":"2021-07-31T07:35:16.195637","exception":false,"start_time":"2021-07-31T07:35:16.121914","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 11.4.1 데이터 준비","metadata":{"papermill":{"duration":0.019186,"end_time":"2021-07-31T07:35:16.23649","exception":false,"start_time":"2021-07-31T07:35:16.217304","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import pandas as pd\n\n# 데이터 경로\ndata_path = '/kaggle/input/aerial-cactus-identification/'\n\nlabels = pd.read_csv(data_path + 'train.csv')\nsubmission = pd.read_csv(data_path + 'sample_submission.csv')","metadata":{"papermill":{"duration":0.142952,"end_time":"2021-07-31T07:35:11.768582","exception":false,"start_time":"2021-07-31T07:35:11.62563","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from zipfile import ZipFile\n\n# 훈련 이미지 데이터 압축 풀기\nwith ZipFile(data_path + 'train.zip') as zipper:\n    zipper.extractall()\n    \n# 테스트 이미지 데이터 압축 풀기\nwith ZipFile(data_path + 'test.zip') as zipper:\n    zipper.extractall()","metadata":{"papermill":{"duration":3.021292,"end_time":"2021-07-31T07:35:14.809068","exception":false,"start_time":"2021-07-31T07:35:11.787776","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# 훈련 데이터, 검증 데이터 분리\ntrain, valid = train_test_split(labels, \n                                test_size=0.1,\n                                stratify=labels['has_cactus'],\n                                random_state=50)","metadata":{"_uuid":"c07eab67e573c7de05e11065b5bafc1bbff284fb","papermill":{"duration":0.907461,"end_time":"2021-07-31T07:35:17.163124","exception":false,"start_time":"2021-07-31T07:35:16.255663","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2 # OpenCV 라이브러리\nfrom torch.utils.data import Dataset # 데이터 생성을 위한 클래스\n\nclass ImageDataset(Dataset):\n    # 초기화 메서드(생성자)\n    def __init__(self, df, img_dir='./', transform=None):\n        super().__init__() # 상속받은 Dataset의 생성자 호출\n        # 전달받은 인수들 저장\n        self.df = df\n        self.img_dir = img_dir\n        self.transform = transform\n    \n    # 데이터셋 크기 반환 메서드 \n    def __len__(self):\n        return len(self.df)\n    \n    # 인덱스(idx)에 해당하는 데이터 반환 메서드 \n    def __getitem__(self, idx):\n        img_id = self.df.iloc[idx, 0]    # 이미지 ID\n        img_path = self.img_dir + img_id # 이미지 파일 경로 \n        image = cv2.imread(img_path)     # 이미지 파일 읽기 \n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # 이미지 색상 보정\n        label = self.df.iloc[idx, 1]     # 이미지 레이블(타깃값)\n\n        if self.transform is not None:\n            image = self.transform(image) # 변환기가 있다면 이미지 변환\n        return image, label","metadata":{"_uuid":"1b05af8d59d9d5b092e96f72dfebb19591416de9","papermill":{"duration":0.165331,"end_time":"2021-07-31T07:35:17.350292","exception":false,"start_time":"2021-07-31T07:35:17.184961","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 이미지 변환기 정의","metadata":{}},{"cell_type":"code","source":"from torchvision import transforms # 이미지 변환을 위한 모듈\n\n# 훈련 데이터용 변환기\ntransform_train = transforms.Compose([transforms.ToTensor(),\n                                      transforms.Pad(32, padding_mode='symmetric'),\n                                      transforms.RandomHorizontalFlip(),\n                                      transforms.RandomVerticalFlip(),\n                                      transforms.RandomRotation(10),\n                                      transforms.Normalize((0.485, 0.456, 0.406),\n                                                           (0.229, 0.224, 0.225))])\n\n# 검증 및 테스트 데이터용 변환기\ntransform_test= transforms.Compose([transforms.ToTensor(),\n                                    transforms.Pad(32, padding_mode='symmetric'),\n                                    transforms.Normalize((0.485, 0.456, 0.406),\n                                                         (0.229, 0.224, 0.225))])","metadata":{"papermill":{"duration":0.156062,"end_time":"2021-07-31T07:35:17.525455","exception":false,"start_time":"2021-07-31T07:35:17.369393","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 데이터셋 및 데이터 로더 생성","metadata":{}},{"cell_type":"code","source":"dataset_train = ImageDataset(df=train, img_dir='train/', transform=transform_train)\ndataset_valid = ImageDataset(df=valid, img_dir='train/', transform=transform_test)","metadata":{"papermill":{"duration":0.02571,"end_time":"2021-07-31T07:35:17.569851","exception":false,"start_time":"2021-07-31T07:35:17.544141","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader # 데이터 로더 클래스\n\nloader_train = DataLoader(dataset=dataset_train, batch_size=32, shuffle=True)\nloader_valid = DataLoader(dataset=dataset_valid, batch_size=32, shuffle=False)","metadata":{"_uuid":"c247391c28497ad35c72f5218398ea71f2d0d5ff","papermill":{"duration":0.027849,"end_time":"2021-07-31T07:35:17.670185","exception":false,"start_time":"2021-07-31T07:35:17.642336","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 11.4.2 모델 생성","metadata":{"papermill":{"duration":0.021461,"end_time":"2021-07-31T07:35:17.711457","exception":false,"start_time":"2021-07-31T07:35:17.689996","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import torch.nn as nn # 신경망 모듈\nimport torch.nn.functional as F # 신경망 모듈에서 자주 사용되는 함수\n\nclass Model(nn.Module):\n    # 신경망 계층 정의\n    def __init__(self):\n        super().__init__() # 상속받은 nn.Module의 __init__() 메서드 호출\n        # 1 ~ 5번째 {합성곱, 배치 정규화, 최대 풀링} 계층 \n        self.layer1 = nn.Sequential(nn.Conv2d(in_channels=3, out_channels=32,\n                                              kernel_size=3, padding=2),\n                                    nn.BatchNorm2d(32), # 배치 정규화\n                                    nn.LeakyReLU(), # LeakyReLU 활성화 함수\n                                    nn.MaxPool2d(kernel_size=2))\n\n        self.layer2 = nn.Sequential(nn.Conv2d(in_channels=32, out_channels=64,\n                                              kernel_size=3, padding=2),\n                                    nn.BatchNorm2d(64),\n                                    nn.LeakyReLU(),\n                                    nn.MaxPool2d(kernel_size=2))\n        \n        self.layer3 = nn.Sequential(nn.Conv2d(in_channels=64, out_channels=128,\n                                              kernel_size=3, padding=2),\n                                    nn.BatchNorm2d(128),\n                                    nn.LeakyReLU(),\n                                    nn.MaxPool2d(kernel_size=2))\n        \n        self.layer4 = nn.Sequential(nn.Conv2d(in_channels=128, out_channels=256,\n                                              kernel_size=3, padding=2),\n                                    nn.BatchNorm2d(256),\n                                    nn.LeakyReLU(),\n                                    nn.MaxPool2d(kernel_size=2))\n        \n        self.layer5 = nn.Sequential(nn.Conv2d(in_channels=256, out_channels=512,\n                                              kernel_size=3, padding=2),\n                                    nn.BatchNorm2d(512),\n                                    nn.LeakyReLU(),\n                                    nn.MaxPool2d(kernel_size=2))\n        # 평균 풀링 계층 \n        self.avg_pool = nn.AvgPool2d(kernel_size=4) \n        # 전결합 계층\n        self.fc1 = nn.Linear(in_features=512 * 1 * 1, out_features=64)\n        self.fc2 = nn.Linear(in_features=64, out_features=2)\n\n    # 순전파 출력 정의 \n    def forward(self, x):\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        x = self.layer5(x)\n        x = self.avg_pool(x)\n        x = x.view(-1, 512 * 1 * 1) # 평탄화\n        x = self.fc1(x)\n        x = self.fc2(x)\n        return x","metadata":{"_uuid":"0a2d5600bc2eb915ec0bdf5b52ba11e25096f7d0","papermill":{"duration":0.035364,"end_time":"2021-07-31T07:35:17.806004","exception":false,"start_time":"2021-07-31T07:35:17.77064","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Model().to(device)","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","papermill":{"duration":4.454117,"end_time":"2021-07-31T07:35:22.281793","exception":false,"start_time":"2021-07-31T07:35:17.827676","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 11.4.3 모델 훈련","metadata":{}},{"cell_type":"markdown","source":"### 손실 함수와 옵티마이저 설정","metadata":{"papermill":{"duration":0.019921,"end_time":"2021-07-31T07:35:22.32229","exception":false,"start_time":"2021-07-31T07:35:22.302369","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# 손실 함수\ncriterion = nn.CrossEntropyLoss()","metadata":{"papermill":{"duration":0.026967,"end_time":"2021-07-31T07:35:22.367753","exception":false,"start_time":"2021-07-31T07:35:22.340786","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 옵티마이저\noptimizer = torch.optim.Adamax(model.parameters(), lr=0.00006)","metadata":{"_uuid":"fceb2929d8750acb2de745cd9ff3d2d458820df8","papermill":{"duration":0.025596,"end_time":"2021-07-31T07:35:22.414767","exception":false,"start_time":"2021-07-31T07:35:22.389171","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 모델 훈련","metadata":{"papermill":{"duration":0.018667,"end_time":"2021-07-31T07:35:22.452854","exception":false,"start_time":"2021-07-31T07:35:22.434187","status":"completed"},"tags":[]}},{"cell_type":"code","source":"epochs = 70 # 총 에폭\n\n# 총 에폭만큼 반복\nfor epoch in range(epochs):\n    epoch_loss = 0 # 에폭별 손실값 초기화\n    \n    # '반복 횟수'만큼 반복 \n    for images, labels in loader_train:\n        # 이미지, 레이블 데이터 미니배치를 장비에 할당 \n        images = images.to(device)\n        labels = labels.to(device)\n        \n        # 옵티마이저 내 기울기 초기화\n        optimizer.zero_grad()\n        # 순전파 : 이미지 데이터를 신경망 모델의 입력값으로 사용해 출력값 계산\n        outputs = model(images)\n        # 손실 함수를 활용해 outputs와 labels의 손실값 계산\n        loss = criterion(outputs, labels)\n        # 현재 배치에서의 손실 추가\n        epoch_loss += loss.item() \n        # 역전파 수행\n        loss.backward()\n        # 가중치 갱신\n        optimizer.step()\n        \n    print(f'에폭 [{epoch+1}/{epochs}] - 손실값: {epoch_loss/len(loader_train):.4f}')    ","metadata":{"_uuid":"2c37417ae6b62ab4551bc8a888916ca1e591d284","papermill":{"duration":1968.706194,"end_time":"2021-07-31T08:08:11.179867","exception":false,"start_time":"2021-07-31T07:35:22.473673","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 11.4.4 성능 검증","metadata":{"papermill":{"duration":0.034274,"end_time":"2021-07-31T08:08:11.245607","exception":false,"start_time":"2021-07-31T08:08:11.211333","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score # ROC AUC 점수 계산 함수 임포트\n\n# 실제값과 예측 확률값을 담을 리스트 초기화\ntrue_list = []\npreds_list = []\n\nmodel.eval() # 모델을 평가 상태로 설정 \n\nwith torch.no_grad(): # 기울기 계산 비활성화\n    for images, labels in loader_valid:\n        # 이미지, 레이블 데이터 미니배치를 장비에 할당 \n        images = images.to(device)\n        labels = labels.to(device)\n        \n        # 순전파 : 이미지 데이터를 신경망 모델의 입력값으로 사용해 출력값 계산\n        outputs = model(images)\n        preds = torch.softmax(outputs.cpu(), dim=1)[:, 1] # 예측 확률값\n        true = labels.cpu() # 실제값 \n        # 예측 확률값과 실제값을 리스트에 추가\n        preds_list.extend(preds)\n        true_list.extend(true)\n        \n# 검증 데이터 ROC AUC 점수 계산 \nprint(f'검증 데이터 ROC AUC : {roc_auc_score(true_list, preds_list):.4f}')    ","metadata":{"papermill":{"duration":2.403619,"end_time":"2021-07-31T08:08:13.682873","exception":false,"start_time":"2021-07-31T08:08:11.279254","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 11.4.5 예측 및 결과 제출","metadata":{"papermill":{"duration":0.031882,"end_time":"2021-07-31T08:08:13.74921","exception":false,"start_time":"2021-07-31T08:08:13.717328","status":"completed"},"tags":[]}},{"cell_type":"code","source":"dataset_test = ImageDataset(df=submission, img_dir='test/', \n                            transform=transform_test)\nloader_test = DataLoader(dataset=dataset_test, batch_size=32, shuffle=False)\n\n# 예측 수행\nmodel.eval() # 모델을 평가 상태로 설정\n\npreds = [] # 타깃 예측값 저장용 리스트 초기화\n\nwith torch.no_grad(): # 기울기 계산 비활성화\n    for images, _ in loader_test:\n        # 이미지 데이터 미니배치를 장비에 할당\n        images = images.to(device)\n        \n        # 순전파 : 이미지 데이터를 신경망 모델의 입력값으로 사용해 출력값 계산\n        outputs = model(images)\n        # 타깃값이 1일 확률(예측값)\n        preds_part = torch.softmax(outputs.cpu(), dim=1)[:, 1].tolist()\n        # preds에 preds_part 이어붙이기\n        preds.extend(preds_part)","metadata":{"papermill":{"duration":6.007841,"end_time":"2021-07-31T08:08:19.867268","exception":false,"start_time":"2021-07-31T08:08:13.859427","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['has_cactus'] = preds\nsubmission.to_csv('submission.csv', index=False)","metadata":{"papermill":{"duration":0.058886,"end_time":"2021-07-31T08:08:19.961216","exception":false,"start_time":"2021-07-31T08:08:19.90233","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\n\nshutil.rmtree('./train')\nshutil.rmtree('./test')","metadata":{"papermill":{"duration":0.61593,"end_time":"2021-07-31T08:08:20.613892","exception":false,"start_time":"2021-07-31T08:08:19.997962","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]}]}