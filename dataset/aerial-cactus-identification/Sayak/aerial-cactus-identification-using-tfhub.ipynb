{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Context**\n\nTo assess the impact of climate change on Earth's flora and fauna, it is vital to quantify how human activities such as logging, mining, and agriculture are impacting our protected natural areas. Researchers in Mexico have created the [VIGIA project](https://jivg.org/research-projects/vigia/), which aims to build a system for autonomous surveillance of protected areas. A first step in such an effort is the ability to recognize the vegetation inside the protected areas. In this competition, you are tasked with creation of an algorithm that can identify a specific type of cactus in aerial imagery.\n\n**Provided data description**\n\nThis dataset contains a large number of 32 x 32 thumbnail images containing aerial photos of a columnar cactus (Neobuxbaumia tetetzo). Kaggle has resized the images from the original dataset to make them uniform in size. The file name of an image corresponds to its id.\n\nI will be using the fastai library for doing my experiments. I will be approaching the problem with a deep-learning based solution."},{"metadata":{},"cell_type":"markdown","source":"### Installation and imports"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nfrom sklearn.preprocessing import LabelBinarizer\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# list out the available files in the input path\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"!pip install tensorflow-gpu==2.0.0-beta1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"!pip install -q tensorflow_hub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_hub as hub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loading in the data files"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dir=\"../input/train/train\"\ntest_dir=\"../input/test/test\"\ntrain = pd.read_csv('../input/train.csv')\nsub_file = pd.read_csv(\"../input/sample_submission.csv\")\ndata_folder = \"../input\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_file.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A utility function to show 10 randomly selected images from the provided data split."},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_images(directory, df, is_train=True):\n    plt.figure(figsize=(15,15))\n    for i in range(10):\n        n = np.random.choice(df.shape[0], 1)\n        plt.subplot(5,5,i+1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.grid(True)\n        image = plt.imread(os.path.join(directory, df[\"id\"][int(n)]))\n        plt.imshow(image)\n        if is_train:\n            label = df[\"has_cactus\"][int(n)]\n            plt.xlabel(label)\n    plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train set\nshow_images(train_dir, train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test set\nshow_images(test_dir, sub_file, is_train=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's check out the class distribution in the train set. "},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"has_cactus\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see above, there is a class imabalance & we will handle this accordingly while training our model. We now split the available training set into additional training and validation sets."},{"metadata":{"trusted":true},"cell_type":"code","source":"# 90% for train\npartial_train = train.sample(frac=0.9)\ntrain.drop(partial_train.index, axis=0, inplace=True)\n\n# 10% for validation\nvalid = train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's check the class distributions in these two newly created splits. "},{"metadata":{"trusted":true},"cell_type":"code","source":"partial_train[\"has_cactus\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid[\"has_cactus\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# account for skew in the labeled data\nlb = LabelBinarizer()\ny_train = lb.fit_transform(partial_train[\"has_cactus\"])\nclassTotals = y_train.sum(axis=0)\nclassWeight = classTotals.max() / classTotals","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data augmentation set up"},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert the data-type of the labels to string to make it compatible with\n# ImageDataGenerator\npartial_train[\"has_cactus\"] = partial_train[\"has_cactus\"].astype(\"str\") \nvalid[\"has_cactus\"] = valid[\"has_cactus\"].astype(\"str\") \nsub_file[\"has_cactus\"] = sub_file[\"has_cactus\"].astype(\"str\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# set up the data augmentation objects\ntrainAug = tf.keras.preprocessing.image.ImageDataGenerator(\n  horizontal_flip=True,\n  fill_mode=\"nearest\")\n\nvalAug = tf.keras.preprocessing.image.ImageDataGenerator()\n\n# define the ImageNet mean subtraction (in RGB order) and set the\n# the mean subtraction value for each of the data augmentation\n# objects\nmean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\ntrainAug.mean = mean\nvalAug.mean = mean\n\ntrainGen = trainAug.flow_from_dataframe(partial_train, directory=train_dir, \n    x_col=\"id\", y_col=\"has_cactus\", target_size=(224, 224), \n    class_mode=\"categorical\", batch_size=64, shuffle=True)\n\nvalGen = valAug.flow_from_dataframe(valid, directory=train_dir, \n    x_col=\"id\", y_col=\"has_cactus\", target_size=(224, 224), \n    class_mode=\"categorical\", batch_size=64)\n\ntestGen = valAug.flow_from_dataframe(sub_file, directory=test_dir, \n    x_col=\"id\", y_col=\"has_cactus\", target_size=(224, 224), \n    class_mode=\"categorical\", batch_size=64)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Transfer learning using `TF-Hub`\n\nWe start by downloading the headless MobileNetV2 model without its classification head. This model was trained on the ImageNet dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"# define the input dimension of the KerasLayer and then set its layers to\n# trainable to adapt to our dataset\nfeature_extractor_url = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/2\"\nfeature_extractor_layer = hub.KerasLayer(feature_extractor_url,\n                                         input_shape=(224,224,3))\nfeature_extractor_layer.trainable = True","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's now use the `Sequential` API of Keras to add a dense layer on top of the feature extraction layer. "},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.Sequential([\n  feature_extractor_layer,\n  tf.keras.layers.Dense(2, activation=\"sigmoid\")\n])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We now compile the model supplying the optimizer, loss function and the metrics we are interested in. "},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(\n  optimizer=tf.keras.optimizers.Adam(),\n  loss='categorical_crossentropy',\n  metrics=['acc'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model training"},{"metadata":{"trusted":true},"cell_type":"code","source":"H = model.fit_generator(\n    trainGen,\n    steps_per_epoch=partial_train.shape[0] // 64,\n    validation_data=valGen,\n    validation_steps=valid.shape[0] // 64,\n    epochs=5,\n    class_weight=classWeight,\n    verbose=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We get a decent accuracy of **99.65%** on the validation set. We now plot the training history to look for any sign of overfitting. "},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_training(H, N):\n    plt.style.use(\"ggplot\")\n    plt.figure(figsize=(10,8))\n    plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n    plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n    plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n    plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n    plt.title(\"Training Loss and Accuracy\")\n    plt.xlabel(\"Epoch #\")\n    plt.ylabel(\"Loss/Accuracy\")\n    plt.legend(loc=\"upper center\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_training(H, 5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Inference on the test set and submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"# get the predictions from the network and map \n# the class-labels accordingly\npredIdxs = model.predict_generator(testGen,\n    steps=(sub_file.shape[0] // 64) + 1)\npredIdxs = np.argmax(predIdxs, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_file.has_cactus = predIdxs\nsub_file.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### References:\n- [TensorFlow Hub with Keras](https://www.tensorflow.org/beta/tutorials/images/hub_with_keras)\n- [Fine-tuning with Keras and Deep Learning](https://www.pyimagesearch.com/2019/06/03/fine-tuning-with-keras-and-deep-learning/)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}