{"cells":[{"metadata":{"_uuid":"b42f5b18-eabd-42bd-9107-68f6e3c43ffa","_cell_guid":"fd887340-bbf1-4e15-b755-c42d5c72ec9e","trusted":true},"cell_type":"code","source":"# Daniel Balle 2019\nimport zipfile\nimport os\nimport datetime\n\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mplimg\nfrom scipy import ndimage\n\ntf.enable_eager_execution()\ntf.set_random_seed(32)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data pre-processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"BASE_DIR = '/kaggle/input/aerial-cactus-identification'\nIMAGE_PATH = '{}/train/train'.format(BASE_DIR)\n\ntrain_df = pd.read_csv(\"{}/train.csv\".format(BASE_DIR))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to read some image\ndef read_image(image_id, base_dir=IMAGE_PATH, transformation=False):\n    train_image = mplimg.imread(\"{}/{}\".format(base_dir, image_id)) / 255.0\n    if not transformation:\n        return train_image\n\n    # Random data augmentation\n    train_image = ndimage.rotate(train_image, np.random.choice([0, 1, 2, 3]) * 90, mode='nearest')\n    if np.random.rand() > 0.5:\n        train_image = np.flip(train_image, np.random.choice([(0), (1), (0, 1)]))  # don't flip colors\n    train_image + (np.random.rand() * 0.2) - 0.1  # brightness\n    return train_image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot some data\nplt.figure(figsize=(8, 8))\nfor i in range(9):\n    plt.subplot(3, 3, i+1)\n    plt.xticks([])\n    plt.yticks([])\n    train_image = read_image(train_df['id'][i], transformation=True)\n    plt.imshow(train_image)\n    plt.xlabel(train_df['has_cactus'][i])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMAGE_DIMENSION = read_image(train_df['id'][0]).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split data into train (80%) and validation set (20%)\nshuffled_data = train_df.sample(frac=1)\n\nTRAIN_SIZE = int(len(train_df) * 0.8)\nVALIDATION_SIZE = len(train_df) - TRAIN_SIZE\n\ntrain_set = shuffled_data[0:TRAIN_SIZE]\nvalidation_set = shuffled_data[TRAIN_SIZE:]\n\nprint(TRAIN_SIZE)\nprint(VALIDATION_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check distribution of positives vs negatives\nprint(\"Training distribution:\\n------\")\nprint(\"Positives: {}\\nNegatives: {}\".format(\n    list(train_set['has_cactus']).count(1),\n    list(train_set['has_cactus']).count(0)))\nprint(\" = {}\\n\".format(list(train_set['has_cactus']).count(1) / TRAIN_SIZE))\n\nprint(\"Validation distribution:\\n------\")\nprint(\"Positives: {}\\nNegatives: {}\".format(\n    list(validation_set['has_cactus']).count(1),\n    list(validation_set['has_cactus']).count(0)))\nprint(\" = {}\".format(list(validation_set['has_cactus']).count(1) / VALIDATION_SIZE))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_samples = list(train_set['has_cactus']).count(1)\n\n# Sample with replacement from the negatives to balance the classes\npositive_train_df = train_set[train_set['has_cactus'] == 1]\nnegative_train_df = train_set[train_set['has_cactus'] == 0].sample(num_samples, replace=True)\n\nbalanced_train_set = pd.concat([positive_train_df, negative_train_df], ignore_index=True).sample(frac=1)\nBALANCED_TRAIN_SIZE = len(balanced_train_set)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generator for test and train data - needs to be callable\ndef train_gen():\n    for _, row in balanced_train_set.iterrows():\n        yield (read_image(row['id'], transformation=True), row['has_cactus'])\n\ndef validation_gen():\n    for _, row in validation_set.iterrows():\n        yield (read_image(row['id'], transformation=True), row['has_cactus'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 32\n\ntrain_ds = tf.data.Dataset.from_generator(train_gen, output_types=(tf.float32, tf.int16)).batch(BATCH_SIZE).repeat()\nvalidation_ds = tf.data.Dataset.from_generator(validation_gen, output_types=(tf.float32, tf.int16)).batch(BATCH_SIZE).repeat()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras import layers\nfrom tensorflow.keras import regularizers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's try a simple CNN\n# TODO(balle) try tf.keras.layers.BatchNormalization\nmodel = tf.keras.Sequential([\n    layers.Conv2D(16, (3, 3), activation='relu', input_shape=IMAGE_DIMENSION),\n    layers.Conv2D(32, (3, 3), activation='relu'),\n    layers.BatchNormalization(),\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.Dropout(0.5),\n    layers.MaxPooling2D((2, 2)),\n\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.Conv2D(128, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n    layers.BatchNormalization(),\n    layers.Conv2D(256, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n    layers.Dropout(0.5),\n    layers.MaxPooling2D((2, 2)),\n\n    layers.Flatten(),\n    # layers.Dense(32, activation=tf.nn.relu),\n    layers.Dense(1, activation=tf.nn.sigmoid)\n])\n\nmodel.summary()\n\n# note: categorical_crossentropy vs. softmax_crossentropy\nmodel.compile(\n  optimizer='adam',  # TODO(balle) tune learning rate!\n  loss='binary_crossentropy',\n  metrics=['accuracy']\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MAX_STEPS_PER_EPOCH = int(BALANCED_TRAIN_SIZE/BATCH_SIZE)\nMAX_VALIDATION_STEPS = int(VALIDATION_SIZE/BATCH_SIZE) * 5  # more validation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"early_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience=5)\ncheckpointer = tf.keras.callbacks.ModelCheckpoint(filepath='weights.hdf5', verbose=1, save_best_only=True)\nlogdir = \"/tensorboard/scalars/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorboard = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n\nhistory = model.fit_generator(train_ds,\n                              epochs=20,\n                              validation_data=validation_ds,\n                              steps_per_epoch=MAX_STEPS_PER_EPOCH,\n                              validation_steps=MAX_VALIDATION_STEPS,\n                              callbacks=[early_stopping, checkpointer, tensorboard])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights('weights.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print some predictions\nplt.figure(figsize=(8, 8))\nfor i in range(9):\n    j = np.random.randint(0, len(train_df))\n    plt.subplot(3, 3, i+1)\n    plt.xticks([])\n    plt.yticks([])\n    train_image = read_image(train_df['id'][j], transformation=False)\n    plt.imshow(train_image)\n    pred = model.predict(np.array([train_image]))[0][0]\n    plt.xlabel(\"true: {}\\npredicted: {:.2f}\".format(train_df['has_cactus'][j], pred))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prediction_gen():\n    for _, row in validation_set.iterrows():\n        yield read_image(row['id'], transformation=True)\n\n# Predict over multiple transformer images and take mean\nprediction_ds = tf.data.Dataset.from_generator(prediction_gen, output_types=(tf.float32)).batch(BATCH_SIZE)  # don't shuffle\nmultiple_predictions = [\n    model.predict_generator(prediction_ds)\n    for i in range(10)\n]\npredictions = np.mean(np.array(multiple_predictions), axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compute accuracy\nfrom sklearn.metrics import accuracy_score\nprint(accuracy_score(validation_set['has_cactus'], np.round(predictions).astype('int32')))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compute AUC\nfrom sklearn.metrics import roc_auc_score\nprint(roc_auc_score(validation_set['has_cactus'], predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission = pd.read_csv('{}/sample_submission.csv'.format(BASE_DIR))\nsample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_ids = os.listdir('{}/test/test'.format(BASE_DIR))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_gen():\n    for test_id in test_ids:\n        yield read_image(test_id, base_dir='{}/test/test'.format(BASE_DIR), transformation=True)\n\ntest_ds = tf.data.Dataset.from_generator(test_gen, output_types=(tf.float32)).batch(BATCH_SIZE)  # don't shuffle\nmultiple_test_predictions = [\n    model.predict_generator(test_ds)              \n    for i in range(10)\n]\ntest_predictions = np.mean(np.array(multiple_test_predictions), axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({'id': test_ids, 'has_cactus': test_predictions.flatten()})\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv', index = False, header = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thanks boys\n> *Daniel Balle 2019*"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}