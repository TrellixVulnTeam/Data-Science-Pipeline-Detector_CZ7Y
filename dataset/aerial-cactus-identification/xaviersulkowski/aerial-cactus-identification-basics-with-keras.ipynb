{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this kerel I will show how easly implement CNN in keras. We will walk through data preparation and analysis, model implementation, training with GPU and results analysis."},{"metadata":{},"cell_type":"markdown","source":"### imports"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false},"cell_type":"code","source":"import os\nimport shutil\nimport zipfile\nimport numpy as np \nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\nfrom cv2 import imread\nfrom IPython.display import Image\n\nfrom keras import optimizers\nfrom keras import regularizers\nfrom keras import layers,models\nfrom keras.preprocessing import image\nfrom keras.callbacks import EarlyStopping\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.imagenet_utils import preprocess_input\n\nfrom keras import backend as K","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### helpers"},{"metadata":{"trusted":false},"cell_type":"code","source":"def unzip(path):\n    with zipfile.ZipFile(path,\"r\") as z:\n        z.extractall('.')\n\n# since Keras remove f1-score from metrics it's need to be calculated manually        \n\ndef my_recall(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n        recall = true_positives / (possible_positives + K.epsilon())\n        return recall\n\ndef my_precision(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n        precision = true_positives / (predicted_positives + K.epsilon())\n        return precision\n\ndef my_f1(y_true, y_pred):\n    precision = my_precision(y_true, y_pred)\n    recall = my_recall(y_true, y_pred)\n    return 2*((precision*recall)/(precision+recall+K.epsilon()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. Data preparation"},{"metadata":{},"cell_type":"markdown","source":"### 1.1. Data loading"},{"metadata":{"trusted":false},"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have to types of files, csv and zip. In zip files there are pictures which contains or not cactuses. In csv there is information if picture with 'id' has cactus or not.  "},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"y_train=pd.read_csv('../input/aerial-cactus-identification/train.csv')\ny_test=pd.read_csv('../input/aerial-cactus-identification/sample_submission.csv')\n\ntrain_zip_path = '../input/aerial-cactus-identification/train.zip'\ntest_zip_path = '../input/aerial-cactus-identification/test.zip'\n\ntrain_path = './train'\ntest_path = './test'\n\nunzip(train_zip_path)\nunzip(test_zip_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(y_train.head(5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.2. Data analysis"},{"metadata":{},"cell_type":"markdown","source":"Very importat is to check classes distrbution, lets check. "},{"metadata":{"trusted":false},"cell_type":"code","source":"ax = sns.countplot(x=\"has_cactus\", data=y_train, palette=sns.color_palette(\"coolwarm\", 2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that training set is very unbalanced. There is about 3x times more pictures with cactus. At this time we should consider if accuracy is best metric to valuate results, check [Accuracy paradox.](https://en.wikipedia.org/wiki/Accuracy_paradox)"},{"metadata":{},"cell_type":"markdown","source":"Quick look at data. "},{"metadata":{"trusted":false},"cell_type":"code","source":"fig,ax = plt.subplots(1,5,figsize=(15,3))\n\nfor i, idx in enumerate(y_train[y_train['has_cactus']==1]['id'][:5]):\n  path = os.path.join(train_path,idx)\n  ax[i].imshow(imread(path))\n    \nfig.suptitle('pictures with cactus')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fig,ax = plt.subplots(1,5,figsize=(15,3))\n\nfor i, idx in enumerate(y_train[y_train['has_cactus']==0]['id'][:5]):\n  path = os.path.join(train_path,idx)\n  ax[i].imshow(imread(path))\n    \nfig.suptitle('pictures without cactus')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So we have a lot of low quality pictures... Thats bad. But we know that we are looking for cactuses, so we can assume that we should find longitudinal straight edges, it's mean that we need some filter and first idea should be [CNN.](https://towardsdatascience.com/simple-introduction-to-convolutional-neural-networks-cdf8d3077bac) "},{"metadata":{},"cell_type":"markdown","source":"### 1.3. Datasets preparation"},{"metadata":{},"cell_type":"markdown","source":"We will use Datagen module from keras to prepare our data for work with keras. "},{"metadata":{"trusted":false},"cell_type":"code","source":"datagen=ImageDataGenerator(rescale=1./255)  # if we rescale like this (1/255) we turn images to garyscale \nbatch_size=150","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Split data to train and validation sets."},{"metadata":{"trusted":false},"cell_type":"code","source":"validation_size = 0.3\nsplit_idx = int(len(y_train) * (1 - validation_size))\n\ny_train.has_cactus = y_train.has_cactus.astype(str)\n\ntrain_generator = datagen.flow_from_dataframe(dataframe=y_train[:split_idx],\n                                              directory=train_path,\n                                              x_col='id',\n                                              y_col='has_cactus',\n                                              class_mode='binary',\n                                              batch_size=batch_size,\n                                              target_size=(150,150)\n                                             )\n\n\nvalidation_generator = datagen.flow_from_dataframe(dataframe=y_train[split_idx:],\n                                                   directory=train_path,\n                                                   x_col='id',\n                                                   y_col='has_cactus',\n                                                   class_mode='binary',\n                                                   batch_size=50,\n                                                   target_size=(150,150)\n                                                  )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Model"},{"metadata":{},"cell_type":"markdown","source":"### 2.1. Model implementation"},{"metadata":{},"cell_type":"markdown","source":"Let's to some deep learning there!"},{"metadata":{"trusted":false},"cell_type":"code","source":"model=models.Sequential()\nmodel.add(layers.ZeroPadding2D((1,1),input_shape=(150,150,3)))\nmodel.add(layers.Conv2D(32,(3,3),activation='relu'))\nmodel.add(layers.MaxPool2D((2,2)))\nmodel.add(layers.ZeroPadding2D((1,1)))\n\nmodel.add(layers.Conv2D(64,(3,3),activation='relu'))\nmodel.add(layers.MaxPool2D((2,2)))\nmodel.add(layers.ZeroPadding2D((1,1)))\n\nmodel.add(layers.Conv2D(128,(3,3),activation='relu'))\nmodel.add(layers.MaxPool2D((2,2)))\nmodel.add(layers.ZeroPadding2D((1,1)))\n\nmodel.add(layers.Conv2D(128,(3,3),activation='relu'))\nmodel.add(layers.MaxPool2D((2,2)))\nmodel.add(layers.ZeroPadding2D((1,1)))\n\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(512,activation='relu'))\nmodel.add(layers.Dropout(0.7))\nmodel.add(layers.Dense(1,activation='sigmoid'))   # for more than two calsses use softmax instead of sigmoid\n         \n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's take a look at model structure"},{"metadata":{"trusted":false},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.2. Model compilation"},{"metadata":{},"cell_type":"markdown","source":"\n\nIn this step we need specify 3 important things: \n1. loss: \"binary_crossentropy\" seems to be ideal to binary classification problem ;)\n2. optimizer: there are a lot of optimizers, if you are not sure, use Adam (brief review about some optimizers [link](https://towardsdatascience.com/types-of-optimization-algorithms-used-in-neural-networks-and-ways-to-optimize-gradient-95ae5d39529f).\n3. metrics : thats criteria that we choose to evaluate out results, for unbalanced data I recomend to use f1-score.\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"model.compile(loss='binary_crossentropy',\n              optimizer=optimizers.Adam(),\n              metrics=['acc', my_f1]\n             )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.3. Model fitting"},{"metadata":{},"cell_type":"markdown","source":"We also add early stopping to prevent overfitting and waiting to death: [some info](https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/)."},{"metadata":{"trusted":false},"cell_type":"code","source":"es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"epochs = 15\nhistory = model.fit_generator(train_generator,\n                              steps_per_epoch=100,\n                              epochs=epochs,\n                              validation_data=validation_generator,\n                              validation_steps=50,\n                              callbacks=[es]\n                             )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.4. Model evaluation"},{"metadata":{"trusted":false},"cell_type":"code","source":"acc = history.history['acc']  ##getting  accuracy of each epochs\nepochs_ = range(0,len(acc))    \nplt.plot(epochs_,acc,label='training accuracy')\nplt.xlabel('no of epochs')\nplt.ylabel('accuracy')\n\nacc_val = history.history['val_acc']  ##getting validation accuracy of each epochs\nplt.scatter(epochs_,acc_val,label=\"validation accuracy\", c=\"r\", alpha=0.5)\nplt.title(\"no of epochs vs accuracy\")\nplt.legend()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"f1 = history.history['my_f1']  ##getting  accuracy of each epochs\nepochs_ = range(0,len(f1))    \nplt.plot(epochs_,f1,label='training f1-score')\nplt.xlabel('no of epochs')\nplt.ylabel('f1-score')\n\nf1_val = history.history['val_my_f1']  ##getting validation accuracy of each epochs\nplt.scatter(epochs_,f1_val,label=\"validation f1-score\", c=\"r\", alpha=0.5)\nplt.title(\"no of epochs vs f1-score\")\nplt.legend()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"loss = history.history['loss']    ##getting  loss of each epochs\nepochs_ = range(0,len(loss))\nplt.plot(epochs_,loss,label='training loss')\nplt.xlabel('No of epochs')\nplt.ylabel('loss')\n\nloss_val = history.history['val_loss']  ## getting validation loss of each epochs\nplt.scatter(epochs_,loss_val,label=\"validation loss\",  c=\"r\", alpha=0.5)\nplt.title('no of epochs vs loss')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Final prediction"},{"metadata":{"trusted":false},"cell_type":"code","source":"y_test.has_cactus = y_test.has_cactus.astype(str)\n\ntest_generator = datagen.flow_from_dataframe(dataframe=y_test,\n                                             directory=test_path,\n                                             x_col='id',\n                                             y_col='has_cactus',\n                                             class_mode=None,  # only data, no labels\n                                             shuffle=False,\n                                             target_size=(150,150)\n                                             )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"\ny_pred = model.predict_generator(test_generator, verbose=1)\n\nshutil.rmtree(train_path)\nshutil.rmtree(test_path)\n\ny_test['has_cactus'] = y_pred\ny_test.to_csv('submission.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"That's all."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}