{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"# Using Pre-trained DenseNet for Aerial Cactus Identification\nDataset from: https://www.kaggle.com/c/aerial-cactus-identification/overview"},{"metadata":{"trusted":true},"cell_type":"code","source":"# General libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loading and processing data  \nThe datasets loaded here contain only the ID number of the picture and the label (whether it contains a cactus or not). The actual image is contained in a sepparate folder and each file is named after its ID:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# File paths to get Kaggle data\ninput_path = '../input/'\ntrain_path = input_path + 'train/train/'\ntest_path = input_path + 'test/test/'\n\n# Load data\ntrain_df = pd.read_csv(input_path + 'train.csv')\nsample = pd.read_csv(input_path + 'sample_submission.csv')\n\n# Get ids and labels\ntrain_id = train_df['id']\nlabels = train_df['has_cactus']\ntest_id = sample['id']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We also want to get a validation set to get some metrics while training:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_val, y_train, y_val = train_test_split(train_id, labels, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finally, we need an array containing the actual images. The following function will fetch these images from the ids that we already have:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def fetch_images(ids, filepath):\n    # Array to load images into\n    arr = []\n    for img_id in ids:\n        img = plt.imread(filepath + img_id)\n        arr.append(img)\n        \n    # Turn into numpy array and normalize pixel values\n    arr = np.array(arr).astype('float32')\n    arr = arr / 255\n    return arr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Redefine sets to contain images and not ids\nx_train = fetch_images(ids=x_train, filepath=train_path)\nx_val = fetch_images(ids=x_val, filepath=train_path)\ntest = fetch_images(ids=test_id, filepath=test_path)\n\n# Get dimensions of each image\nimg_dim = x_train.shape[1:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets see what some of these images look like. The resolution is so low (32x32 pixels) that it is hard to understand what the image shows. Intuitively, one can tell that the cacti in the images are shown as white lines:"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(nrows=2, ncols=3)\nax = ax.ravel()\nplt.tight_layout(pad=0.2, h_pad=2)\n\nfor i in range(6):\n    ax[i].imshow(x_train[i])\n    ax[i].set_title('has_cactus = {}'.format(y_train.iloc[i]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Building the model\nThe model will consist of a pre-trained DenseNet, specifically DenseNet201 that consists of 201 layers and was trained using the imagenet dataset. Then it will be followed by a fully connected layer of our own:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Layers for the full model\nfrom keras.models import Model\nfrom keras.layers import Input, Dense, Flatten, Dropout, LeakyReLU, Activation\nfrom keras.layers.normalization import BatchNormalization\n\n# Pre-trained model\nfrom keras.applications.densenet import DenseNet201","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Hyperparameters\nbatch_size = 64\nepochs = 30\nsteps = x_train.shape[0] // batch_size","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we create the architecture for the model. I like using Keras' Functional API to build the models but using the Sequential approach yields the same results:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Inputs\ninputs = Input(shape=img_dim)\n\n# DenseNet\ndensenet201 = DenseNet201(weights='imagenet', include_top=False)(inputs)\n\n# Our FC layer\nflat1 = Flatten()(densenet201)\ndense1 = Dense(units=256, use_bias=True)(flat1)\nbatchnorm1 = BatchNormalization()(dense1)\nact1 = Activation(activation='relu')(batchnorm1)\ndrop1 = Dropout(rate=0.5)(act1)\n\n# Output\nout = Dense(units=1, activation='sigmoid')(drop1)\n\n# Create Model\nmodel = Model(inputs=inputs, outputs=out)\nmodel.compile(optimizer='adam', loss='binary_crossentropy')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finally, use `ReduceLROnPlateau` to deal with a plateauing learning rate and `ImageDataGenerator` to make sure our model is trained on different variations of the same picture:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import ReduceLROnPlateau\nfrom keras.preprocessing.image import ImageDataGenerator\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=3, verbose=2, mode='max')\n\nimg_aug = ImageDataGenerator(rotation_range=20, vertical_flip=True, horizontal_flip=True)\nimg_aug.fit(x_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show architecture of model\nfrom keras.utils import plot_model\nprint(model.summary())\nplot_model(model, to_file='densenet201_model.png')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fitting and getting results\n\nSince we're using `ImageDataGenerator`, we need to fit the model using Keras' `fit_generator()` instead of just `.fit()`:"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit_generator(img_aug.flow(x_train, y_train, batch_size=batch_size), \n                    steps_per_epoch=steps, epochs=epochs, \n                    validation_data=(x_val, y_val), callbacks=[reduce_lr], \n                    verbose=2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finally, get predictions from the model and produce a submission file:"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred = model.predict(test, verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample['has_cactus'] = test_pred\nsample.to_csv('densenet_model.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}