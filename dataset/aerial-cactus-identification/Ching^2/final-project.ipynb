{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Machine Learning Final Project\n## Date: May 5th 2019\n## Author:  [Ching Ching Huang]\n## Discussants: [TA: Tony Zhang, Professor: Ethan Meyers]"},{"metadata":{},"cell_type":"markdown","source":"## Kaggle competition: Aerial Cactus Identification\n\nAerial Cactus Identification: https://www.kaggle.com/c/aerial-cactus-identification\n\nHuman activities such as logging, mining and climate change have been impacting protected natural areas in Mexico. Researchers have started a project, VIGIA, to build a system for autonomous surveillance of protected areas. To do so, the first step is recognizing plants or vegetation in the protected area. The goal of the challenge is to correctly identify a specific type of cactus through aerial images.\n\nKaggle provides all the data that are required to solve the challenge.\n- train.csv file: containing the names and the labels of the images. If the image contains a cactus, the label is 1. Otherwise, the label is 0. \n- train folder: containing 17,500 images which are the images to train the machine.\n- test folder: containing 4000 images which are the images that we want to predict.\n\nEach image in the train and test folder has width of 32 pixels and height of 32 pixels. \n\nThere are around 400 people who submitted to this challenge. Around 50 people scored 100% on the leader board and around 400 people scored above 95%. I scrolled through submitted kernels and noticed most people are using Convolutional Neural Network (CNN) algorithm to solve the challenge; however, every kernel has different layers for the CNN algorithm."},{"metadata":{},"cell_type":"markdown","source":"## Setup\n\nIn order to try different algorithms, we need to load in and process the data to an expected form. We know train.csv contains the image file names and the labels. Hence, we get the path with the file name and add it to train_img list. Each image is converted to a 3D array while loading the data with matplotlib.image package. train_lb stores the labels of the images in train_img. After loading the data from the train folder, we split the train dataset to test and train set with scikit-learn package. We use the similar method to load images from test folder as test dataset."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.image as mpimg\nimport time\nfrom sklearn.model_selection import train_test_split\n\ncactus_label = pd.read_csv('../input/train.csv')\n\n#read in training set\ntrain_img = []\ntrain_lb = []\nfor i in range(len(cactus_label)):\n    row = cactus_label.iloc[i]\n    fileName = row['id']\n    train_lb.append(row['has_cactus'])\n    path = \"../input/train/train/{}\".format(fileName)\n    im = mpimg.imread(path)\n    train_img.append(im)\n    \nX_train, X_test, y_train, y_test = train_test_split(train_img, train_lb) \nX_train = np.array(X_train)\nX_test = np.array(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\ntest_img = []\nsample = pd.read_csv('../input/sample_submission.csv')\nfolder = '../input/test/test/'\n                   \nfor i in range(len(sample)):\n    row = sample.iloc[i]\n    fileName = row['id']\n    path = folder + fileName\n    img = mpimg.imread(path)\n    test_img.append(img)\n                     \ntest_img = np.asarray(test_img)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before we dive into solving the challenge, let's take a closer look at the data. In the train dataset, 75% of the images contain cacti. We notice that the proportion is very unbalanced. "},{"metadata":{"trusted":true},"cell_type":"code","source":"cactus_label['has_cactus'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n# Data to plot\nlabels = 'Has Cactus', 'No Cacuts'\nsizes = [13136, 4364]\ncolors = ['yellowgreen', 'lightskyblue']\n \n# Plot\nplt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=140)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## K Nearest Neighbor (KNN) Algorithm\n\nKNN is one of the most commonly used classification algorithms. We start with KNN algorithm to make sure the challenge is not too easy. That means if the accuracy rate with KNN is above 80%, then the challenge doesn't need to be solved with other more advanced algorithms. \n\nIn order to apply the KNN algorithm, we need to modify or process the data before training the machine. When we load the images, each image is stored as a 3D array. The KNN algorithm only takes 1D arrays. Therefore, we need to convert the images to 1D arrays by unstacking each row. Fortunately, there's a flatten method in numpy package to do the work for us. "},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nConvert 3D ararys to 1D array\nParamter: a list of 3D images\nReturn: a list of 1D images\n'''\ndef imageToFeatureVector(images):\n    flatten_img = []\n    for img in images:\n        data = np.array(img)\n        flattened = data.flatten()\n        flatten_img.append(flattened)\n    return flatten_img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nstart = time.time()\n\nX_train_flatten = imageToFeatureVector(X_train)\nX_test_flatten = imageToFeatureVector(X_test)\n\nknn = KNeighborsClassifier(n_neighbors = 5)\nknn.fit(X_train_flatten, y_train) \nscore = knn.score(X_test_flatten, y_test)\n\nend = time.time()\nprint(\"The run time of KNN is {:.3f} seconds\".format(end-start))\nprint(\"KNN alogirthm's test score is: {:.3f}\".format(score))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Balance Data\n\nSince we learned the unbalanced data is affecting the prediction, we need to reduce the number of images containing cacti. We will modify the data by loading the same number of images with cacti and without cacti to balance the data. "},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.image as mpimg\nimport time\nfrom sklearn.model_selection import train_test_split\ncactus_label = pd.read_csv('../input/train.csv')\n\n#read in training set\ntrain_img = []\ntrain_lb = []\nhas_cactus = 0\nno_cactus = 0\nfor i in range(len(cactus_label)):\n    row = cactus_label.iloc[i]\n    fileName = row['id'] \n    path = \"../input/train/train/{}\".format(fileName)\n    im = mpimg.imread(path)\n    if row['has_cactus'] == 1 and has_cactus < 4364:\n        has_cactus+= 1\n        train_lb.append(row['has_cactus'])\n        train_img.append(im)\n    elif row['has_cactus'] == 0 and no_cactus < 4364:\n        no_cactus += 1\n        train_lb.append(row['has_cactus'])\n        train_img.append(im)\n\n\n    \nX_train, X_test, y_train, y_test = train_test_split(train_img, train_lb) \nX_train = np.array(X_train)\nX_test = np.array(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n# Data to plot\nlabels = 'Has Cactus', 'No Cacuts'\nsizes = [train_lb.count(1), train_lb.count(0)]\ncolors = ['yellowgreen', 'lightskyblue']\n \n# Plot\nplt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=140)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nstart = time.time()\n\nX_train_flatten = imageToFeatureVector(X_train)\nX_test_flatten = imageToFeatureVector(X_test)\n\nknn = KNeighborsClassifier(n_neighbors = 5)\nknn.fit(X_train_flatten, y_train) \nscore = knn.score(X_test_flatten, y_test)\n\nend = time.time()\nprint(\"The run time of KNN is {:.3f} seconds\".format(end-start))\nprint(\"KNN alogirthm's test score is: {:.3f}\".format(score))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Discussion\n\nBefore balancing the data, KNN has an accuracy of approximatley 30% which means we can apply other algorithms to solve this challenge. It is not surprising that the accuracy is so low. There are 75% of the training images containing cactus. The unbalanced proportion of training data may lead to poor performance of KNN algorithm. Since there are 17,500 images and each image has 1,024 pixels, it makes sense that it took 400 seconds, almost 7 minutes, to execute. \n\nAfter balancing the data, the test score increased to 49%. Since there are less images in the dataset, it only took 76 seconds to execute. From the modification, we know that unbalanced data was affecting the prediction."},{"metadata":{},"cell_type":"markdown","source":"## Support Vector Machines (SVM)\n\nIn this section, we apply SVM using a linear kernel (LinearSVC) and a radial basis function (RBF) kernel. In order to find the best parameters for RBF kernel, we use GridSearchCV object on the training data to find the best values for free parameters. This part is similar to worksheet 6. To see whether normalizing the data will enhance the performance, we compare the result from training the machine with original data to the normalized data. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import LinearSVC\n\nstart = time.time()\nlinearKernel = LinearSVC().fit(X_train_flatten, y_train)\nscore = linearKernel.score(X_test_flatten,y_test)\nend = time.time()\n\nprint(\"The run time of Linear SVC is {:.3f} seconds\".format(end-start))\nprint(\"Linear SCV alogirthm's test score is: {:.3f}\".format(score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# try normalizing the features...\nfrom sklearn import preprocessing\nscaler = preprocessing.StandardScaler()\nstart = time.time()\nscaler.fit(X_train_flatten)\nX_test_normalized = scaler.transform(X_test_flatten)\nX_train_normalized = scaler.transform(X_train_flatten)\n\nlinearKernel = LinearSVC().fit(X_train_normalized, y_train)\nscore = linearKernel.score(X_test_normalized,y_test)\nend = time.time()\nprint(\"The run time of Linear SVC with normalized features is {:.3f} seconds\".format(end-start))\nprint(\"Linear SCV with normalized features has test score of: {:.3f}\".format(score))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Discussion\n\nAccording to the result, Linear SVC with original data has a test score of 81.9% and Linear SVC with normalized data has a test score of 83%. Normalizing the features barely improved the performance. Each GridSearchCV requires more than 3 hours to execute; however, each session on Kaggle is only 6 hours. Other algorithm requires some time to execute too. Therefore, I didn't execute both RBF kernels."},{"metadata":{},"cell_type":"markdown","source":"## Convolutional Neural Network (CNN) Algorithm\n\nThe last algorithm that I'd like to apply is the CNN algorithm. In order to build a model that recognizes objects correctly, we need to add different layers. \n\nIn the CNN model, I added three dense layers. The first layer is rectifying linear units with 128 units. The second layer is again rectifying linear units with 64 units. The last layer returns an output of softmax transformation."},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nstart = time.time()\nX_train_norm = tf.keras.utils.normalize(X_train, axis=1)\nX_test_norm = tf.keras.utils.normalize(X_test, axis=1)\n\nmodel = tf.keras.models.Sequential()\nmodel.add(tf.keras.layers.Flatten())\n\n#add layers\nmodel.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\nmodel.add(tf.keras.layers.Dense(64, activation=tf.nn.relu))\nmodel.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))\n\n#compile model\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\n#train \nmodel.fit(X_train_norm, np.array(y_train), epochs=10)\n\n# Evaluate the model on test set\nscore = model.evaluate(X_test, np.array(y_test), verbose=0)\n# Print test accuracy\nprint('\\n', 'Test accuracy:', score[1])\n\nend = time.time()\nprint(\"The run time of CNN is {:.3f} seconds\".format(end-start))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## CNN from other kernel with 99% accuracy\n\nI've compared my CNN model with other CNN models from the kernel that have scores of 99%. I wonder why my CNN model is not scoring 99%. The code copied below from the kernel serves as the model for comparison.\n\nThe link to the kernel: https://www.kaggle.com/gabrielmv/aerial-cactus-identification-keras"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv2D, Dense, Flatten, BatchNormalization, Dropout, LeakyReLU, DepthwiseConv2D, Flatten\nfrom keras.layers.pooling import GlobalAveragePooling2D\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n\ndef create_model():\n    model = Sequential()\n        \n    model.add(Conv2D(3, kernel_size = 3, activation = 'relu', input_shape = (32, 32, 3)))\n    \n    model.add(Conv2D(filters = 16, kernel_size = 3, activation = 'relu'))\n    model.add(Conv2D(filters = 16, kernel_size = 3, activation = 'relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n    \n    model.add(DepthwiseConv2D(kernel_size = 3, strides = 1, padding = 'Same', use_bias = True))\n    model.add(Conv2D(filters = 32, kernel_size = 1, activation = 'relu'))\n    model.add(Conv2D(filters = 64, kernel_size = 1, activation = 'relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n    \n    model.add(DepthwiseConv2D(kernel_size = 3, strides = 2, padding = 'Same', use_bias = True))\n    model.add(Conv2D(filters = 128, kernel_size = 1, activation = 'relu'))\n    model.add(Conv2D(filters = 256, kernel_size = 1, activation = 'relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n    \n    model.add(DepthwiseConv2D(kernel_size = 3, strides = 1, padding = 'Same', use_bias = True))\n    model.add(Conv2D(filters = 256, kernel_size = 1, activation = 'relu'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(filters = 512, kernel_size = 1, activation = 'relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n    \n    model.add(DepthwiseConv2D(kernel_size = 3, strides = 2, padding = 'Same', use_bias = True))\n    model.add(Conv2D(filters = 512, kernel_size = 1, activation = 'relu'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(filters = 1024, kernel_size = 1, activation = 'relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n    \n    model.add(DepthwiseConv2D(kernel_size = 3, strides = 1, padding = 'Same', use_bias = True))\n    model.add(Conv2D(filters = 1024, kernel_size = 1, activation = 'relu'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(filters = 2048, kernel_size = 1, activation = 'relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n    \n    #model.add(GlobalAveragePooling2D())\n    model.add(Flatten())\n    \n    model.add(Dense(470, activation = 'relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    \n    model.add(Dense(256, activation = 'relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    \n    model.add(Dense(128, activation = 'tanh'))\n\n    model.add(Dense(1, activation = 'sigmoid'))\n\n    model.compile(optimizer = 'rmsprop', loss = 'mean_squared_error', metrics = ['accuracy'])\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = create_model()\n\nhistory = model.fit(X_train, \n            np.array(y_train), \n            batch_size = 128, \n            epochs = 8, \n            validation_data = (X_test, np.array(y_test)),\n            verbose = 1)\n\npredictions = model.predict(X_test, verbose = 1)\n\n# Evaluate the model on test set\nscore = model.evaluate(X_test, np.array(y_test), verbose=0)\n# Print test accuracy\nprint('Test accuracy:', score[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Discussion\n\nI have a test score of 73.6% from the CNN model I've created. The score is lower than I expected. Therefore, I compared my CNN model with another CNN model which has a 96.5% test score. I've noticed that there are more sophisticated layers such as Conv2D. In addition, the CNN model from the kernel scored 99% without balancing the data. These are important factors to consider for future research."},{"metadata":{},"cell_type":"markdown","source":"## Result\n\nThe result is presented below:\n\nK Nearest Neighbor: 49.1% 90sec\n\nLinear SVC: 81.9% 88sec\n\nLinear SVC with normalized feature: 83% 52sec\n\nConvolutional Neural Network: 73.6% 8sec\n\nHence, we predict the test dataset with SVM using Linear SVC with normalized data."},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = preprocessing.StandardScaler()\nscaler.fit(X_train_flatten)\nX_test_normalized = scaler.transform(X_test_flatten)\nX_train_normalized = scaler.transform(X_train_flatten)\ntest_flatten = imageToFeatureVector(test_img)\ntest_normalized = scaler.transform(test_flatten)\nlinearKernel = LinearSVC().fit(X_train_normalized, y_train)\npredictions = linearKernel.predict(test_normalized)\nsample['has_cactus'] = predictions\nsample.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample.to_csv('sub.csv', index= False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conclusion\n\nFrom the result, we observed that after preprocessing the data, the run time for each algorithm is quite efficient. Even though CNN is the most efficient solution, the test score is lower than expected. According to the accuracy, SVM using linear SVC with normalized features is the most accuracte algorithm. In the future, I'd like to learn more about building a CNN model with multiple layers and the theory behind of it. In addition, I am interested in applying the same algorithm to identify different vegetation in the protected area. "},{"metadata":{},"cell_type":"markdown","source":"## Reflection\n\nWhat have I learned?\n\nThis is my second time doing image classification. Unlike my first Kaggle challenge, I spent more time understanding and processing the data, which I found to be the crucial step of this project. For example, unbalanced data affects the performance of the model, thus, we need to ensure the data is balanced before fitting in any algorithms. In addition, since each image is stored in a 3D array, it is required to flatten the 3D arrays to feature vectos. To improve the performance, we can also normalize the features. \n\nWhat went well?\n\nProcessing and balancing the data went well for me. Since we've done something similar in worksheet 6, and the documentation for flattening the features with numpy package is very clear, the whole process went smoothly. \n\nWhat were difficult?\n\nThis is my first time working with the Convolutional Neural Network algorithm. For me, understanding and adding the layers were difficult. I read and followed the example code from the documentation to build my own CNN model. However, the result wasn't good enough. Therefore, I compared mine with other CNN models. From those, I learned that I wasn't adding enough layers. I had to have different layers and increase the number of layers. \n\nRunning GridSearchCV was difficult for me too. Both GridSearchVC alogrithms took more than 6 hours to execute which exceeds the kaggle kernel session. \n\nHow much time did I spend on this project?\n\nIt took me approximately 24 hours to complete the final project.\n\n- Searching and understanding the challenge: 2 hours\n- Understanding and processing the data: 2 hours\n- KNN: 1 hours\n- SVM using Linears SVC: 3 hours\n- SVM using GridSearchCV: 4 hours\n- CNN: 5 hours\n- Write up: 3 hours\n- Meeting with Tony: 2 hours\n- Making slides for presentation: 2 hours"},{"metadata":{},"cell_type":"markdown","source":"## Sources\nhttps://stackoverflow.com/questions/7755684/flatten-opencv-numpy-array\n\nhttps://www.pyimagesearch.com/2016/08/08/k-nn-classifier-for-image-classification/\n\nhttps://www.tensorflow.org/guide/keras\n\nhttps://medium.com/tensorflow/hello-deep-learning-fashion-mnist-with-keras-50fcff8cd74a"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}