{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import random\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nfrom os.path import join\nimport shutil\n\nfrom tqdm import tqdm   # Progress bar\n\nimport torch\nimport torchvision\nimport torch.nn.functional as T\nfrom torchvision import transforms, models\nfrom torch.utils.data import DataLoader, Dataset\n\n\nrandom.seed(6)\nnp.random.seed(6)\ntorch.manual_seed(6)\ntorch.cuda.manual_seed(6)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\nroot_dir = ''\ninput_dir = '../input/aerial-cactus-identification'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Load Labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_val_labels = pd.read_csv(join(input_dir, 'train.csv'))\ntrain_val_labels.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(3,3))\nplt.title('Labels distribution')\nsns.countplot(train_val_labels['has_cactus']);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Make train and validation datasets"},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = ['no_cactus', 'has_cactus']\n\ntrain_dir = join(root_dir, 'train')\nval_dir = join(root_dir, 'val')\ntest_dir = join(root_dir, 'test')\n\n# Make train and val folders\nfor label in labels:\n    os.makedirs(join(train_dir, label), exist_ok=True)\n    os.makedirs(join(val_dir, label), exist_ok=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 15000 train photos and 2500 val photos\n\nsource_dir = join(input_dir, 'train', 'train')\n\nfor i, filename in enumerate(tqdm(os.listdir(source_dir))):\n\n#     if i % 10 != 0:   # Skip 90% photos\n#         continue\n\n    is_cactus = int(train_val_labels.loc[train_val_labels['id'] == filename]['has_cactus'])\n\n    if i % 7 == 0:   #if i % 7 == 0:   \n        shutil.copy(join(source_dir, filename), join(val_dir, labels[is_cactus], filename))\n    else:\n        shutil.copy(join(source_dir, filename), join(train_dir, labels[is_cactus], filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plot function"},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_sample_images(dataloader, batch_size, images_from_batch=0, denormalize=False, classes=None):\n    if denormalize:\n        mean = np.array([0.485, 0.456, 0.406])\n        std = np.array([0.229, 0.224, 0.225])\n    else:\n        mean = np.array([0., 0., 0.])\n        std = np.array([1., 1., 1.])\n    \n    if images_from_batch == 0 or images_from_batch > batch_size:\n            images_from_batch = batch_size\n        \n    for images, labels in dataloader:\n        plt.figure(figsize=(20, (batch_size // 20 + 1) * 3))\n\n        cols = 12\n        rows = batch_size // cols + 1\n        for i in range(images_from_batch):\n            image = images[i].permute(1, 2, 0).numpy() * std + mean   # Размерность RGB в конец\n            plt.subplot(rows, cols, i+1)\n            plt.xticks([])\n            plt.yticks([])\n            plt.grid(False)\n            plt.imshow(image.clip(0, 1))\n            if classes is not None:\n                plt.xlabel(classes[labels[i].numpy()])\n        plt.show()\n        \n        break","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preparing train and validation datasets"},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 500\n\ntrain_dir = join(root_dir, 'train')\nval_dir = join(root_dir, 'val')\n\nclasses = ['No', 'Cactus']\n\ntrain_transforms1 = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntrain_transforms2 = transforms.Compose([\n    transforms.RandomHorizontalFlip(p=1),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntrain_transforms3 = transforms.Compose([\n    transforms.RandomVerticalFlip(p=1),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntrain_transforms4 = transforms.Compose([\n    transforms.RandomHorizontalFlip(p=1),\n    transforms.RandomVerticalFlip(p=1),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\nval_transforms = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n#train_dataset = torchvision.datasets.ImageFolder(train_dir, train_transforms)\ntds1 = torchvision.datasets.ImageFolder(train_dir, train_transforms1)\ntds2 = torchvision.datasets.ImageFolder(train_dir, train_transforms2)\ntds3 = torchvision.datasets.ImageFolder(train_dir, train_transforms3)\ntds4 = torchvision.datasets.ImageFolder(train_dir, train_transforms4)\n\ntrain_dataset = torch.utils.data.ConcatDataset([tds1, tds2, tds3, tds4])\n\nval_dataset = torchvision.datasets.ImageFolder(val_dir, val_transforms)\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=0)\nval_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=0)\n\n\nfor images, labels in train_dataloader:\n    print(images.size())\n    print(labels.size())\n    break","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let's look at the samples"},{"metadata":{"trusted":true},"cell_type":"code","source":"show_sample_images(train_dataloader, batch_size, 72, denormalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Batch size: {batch_size}')\nprint(f'Train batches: {len(train_dataloader)}, Train samples: {len(train_dataset)}')\nprint(f'Val batches:   {len(val_dataloader)}, Val samples:    {len(val_dataset)}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Define train_model and validate functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_batch_loss_history = []\ntrain_batch_accuracy_history = []\n\ntrain_loss_history = []\ntrain_accuracy_history = []\n\nval_loss_history = []\nval_accuracy_history = []\n\ndef validate(model, loss, optimizer):\n        \n    dataloader = val_dataloader\n    model.eval()   # Set model to evaluate mode\n\n    sum_loss = 0.\n    sum_accuracy = 0.\n\n    for inputs, labels in dataloader:\n        inputs = inputs.cuda()\n        labels = labels.cuda()\n\n        optimizer.zero_grad()\n\n        with torch.set_grad_enabled(False):\n            preds = model(inputs)\n            loss_value = loss(preds, labels)\n            preds_class = preds.argmax(dim=1)\n\n        sum_loss += loss_value.item()\n        sum_accuracy += (preds_class == labels.data).float().mean().cpu().numpy().item()\n\n    val_loss = sum_loss / len(dataloader)\n    val_accuracy = sum_accuracy / len(dataloader)\n\n    val_loss_history.append(val_loss)\n    val_accuracy_history.append(val_accuracy)\n    \n    print(f'Validation accuracy {val_accuracy * 100:.2f} %, loss {val_loss:.4f}')\n\n    model.train()  # Вернули как было\n\n\ndef train_model(model, loss, optimizer, scheduler, num_epochs):\n        \n    for epoch in range(num_epochs):\n        print(f'Epoch {epoch}/{num_epochs-1}: ', end='')\n\n        dataloader = train_dataloader\n        model.train()  # Set model to training mode\n\n        sum_loss = 0.\n        sum_accuracy = 0.\n\n        # Прогон по батчам\n        for inputs, labels in dataloader:   #tqdm(dataloader):\n            inputs = inputs.cuda()\n            labels = labels.cuda()\n\n            optimizer.zero_grad()\n\n            # forward and backward\n            with torch.set_grad_enabled(True):\n                preds = model(inputs)\n                loss_value = loss(preds, labels)\n                preds_class = preds.argmax(dim=1)\n\n                loss_value.backward()\n                optimizer.step()\n                # scheduler.step()\n\n            batch_loss = loss_value.item()\n            batch_accuracy = (preds_class == labels.data).float().mean().cpu().numpy().item()\n\n            sum_loss += batch_loss\n            sum_accuracy += batch_accuracy\n            \n            train_batch_loss_history.append(batch_loss)\n            train_batch_accuracy_history.append(batch_accuracy)\n            #print(f'\\r----- {phase}, batch accuracy {train_batch_accuracy * 100:.2f} %, batch loss {train_batch_loss:.4f}')        \n            #validate(model, loss, optimizer)\n            \n        epoch_loss = sum_loss / len(dataloader)\n        epoch_acc = sum_accuracy / len(dataloader)\n\n        train_loss_history.append(epoch_loss)\n        train_accuracy_history.append(epoch_acc)\n        scheduler.step()\n\n        # Валидация\n        # print('\\n End epoch: ', end='')\n        validate(model, loss, optimizer)\n        \n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Define Model, Loss and Optimizer"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models.resnet50(pretrained=True)\n#model = models.mobilenet_v2(pretrained=True)\n\n# for param in model.parameters():\n#     param.requires_grad = False\n\nmodel.fc = torch.nn.Linear(model.fc.in_features, 2)\n#model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, 2)\n\nmodel = model.cuda()\n\nloss = torch.nn.CrossEntropyLoss() #weight=torch.FloatTensor([1, 1]).cuda())\noptimizer = torch.optim.Adam(model.parameters())#, lr=1.0e-3, weight_decay=0.01, amsgrad=True)\n\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.33)\n#scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[20, 40], gamma=0.1)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Batch size: {batch_size}\\nBatches: {len(train_dataloader)}\\nAll elements: {len(train_dataset)}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Let's train!"},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 7\n\ntrain_model(model, loss, optimizer, scheduler, num_epochs=epochs);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### History graphs"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10))\n    \nplt.subplot(1, 3, 1)\nplt.plot(train_batch_loss_history, label='Train Batch Loss')\nplt.plot(train_batch_accuracy_history, label='Train Batch Accuracy')\nplt.legend();\n\nplt.subplot(1, 3, 2)\nplt.plot(train_accuracy_history, label='Train accuracy')\nplt.plot(val_accuracy_history, label='Val accuracy')\nplt.legend();\n    \nplt.subplot(1, 3, 3)\nplt.plot(train_loss_history, label='Train Loss')\nplt.plot(val_loss_history, label='Val Loss')\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preparing test dataset and dataloader"},{"metadata":{"trusted":true},"cell_type":"code","source":"os.makedirs(join(root_dir, 'test'), exist_ok=True)\n\ntest_dir = join(root_dir, 'test')\n\nos.makedirs(join(test_dir, 'unknown'), exist_ok=True)\n\nsource_dir = join(input_dir, 'test', 'test')\n\nfor i, filename in enumerate(tqdm(sorted(os.listdir(source_dir)))):\n    shutil.copy(join(source_dir, filename), join(test_dir, 'unknown', filename))\n    \n    if i < 10:\n        print(filename)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_transforms = val_transforms\n\ntest_dataset = torchvision.datasets.ImageFolder(test_dir, test_transforms)\n\ntest_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=0)\n\nfor images, labels in test_dataloader:\n    print(images.size())\n    print(labels.size())\n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_sample_images(test_dataloader, batch_size, 12, denormalize=True, classes=['Unknown'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predict on test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.eval()\n\ntest_predictions = []\n\ni = 1\nfor images, labels in test_dataloader:\n    images = images.cuda()\n    with torch.set_grad_enabled(False):\n        preds = model(images)\n    test_predictions.append(T.softmax(preds, dim=1)[:,1].data.cpu().numpy())\n    print(f'\\r{i}/{len(test_dataloader)}', end='')\n    i += 1\n    \ntest_predictions = np.concatenate(test_predictions)  \ntest_predictions = (test_predictions >= 0.5).astype('int')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_files = next(iter(os.walk(join(test_dir, 'unknown'))))[2]\n\nprint(sorted(test_files)[:10])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Make submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df = pd.DataFrame.from_dict({'id': sorted(test_files), 'has_cactus': test_predictions})\nsubmission_df.set_index('id', inplace=True)\nsubmission_df.head(25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df.to_csv('submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm -rf train val test","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}