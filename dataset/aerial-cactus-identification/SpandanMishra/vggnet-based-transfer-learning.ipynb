{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\nimport torch.functional as F\nfrom torch.optim import Adam\nfrom torchvision import models, datasets,transforms\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom PIL import Image\nfrom sklearn.metrics import roc_auc_score\nimport matplotlib.pyplot as plt\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_data=pd.read_csv('../input/aerial-cactus-identification/train.csv')\nsample = pd.read_csv(\"../input/aerial-cactus-identification/sample_submission.csv\")\ntrain_data.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data[\"has_cactus\"].value_counts().plot(kind=\"pie\")\ntrain_dir = \"train/train/\"\nval_dir = \"train/train\"\ntrain_data.head(5)\ntrain_data.values[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class dataset_(torch.utils.data.Dataset):\n    def __init__(self,labels,data_directory,transform):\n        super().__init__()\n        #characterizes a dataset for Pytorch        \n        self.list_id=labels.values[:,0]\n        self.labels=labels.values[:,1]\n        self.data_dir=data_directory\n        self.transform=transform\n    \n    def __len__(self):\n        # Denotes the tota number of samples\n        return len(self.list_id)\n    \n    def __getitem__(self,index):\n        name=self.list_id[index]\n        img=Image.open('../input/aerial-cactus-identification/{}/{}'.format(self.data_dir,name))\n        img=self.transform(img)\n        return img,torch.tensor(self.labels[index],dtype=torch.float32)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Pretrained pytorch model , VGG-16 in our case, requires images have atleast H and W of 224 and the image should be normalized such that mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]"},{"metadata":{"trusted":true},"cell_type":"code","source":"image_transform={\"train\":transforms.Compose([transforms.RandomRotation(degrees=0),transforms.RandomResizedCrop(224),transforms.RandomHorizontalFlip(p=0.5),transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])]),\n                \"test\": transforms.Compose([transforms.Resize(224),transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Prepare the test data for submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dir = \"test/test/\"\ntest_df = dataset_(sample, test_dir, image_transform[\"test\"])\ntest_data_loader = torch.utils.data.DataLoader(test_df, batch_size=64,shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set, validation_set = train_test_split(train_data,stratify=train_data.has_cactus.values, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set[\"has_cactus\"].value_counts().plot(kind=\"pie\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_set[\"has_cactus\"].value_counts().plot(kind=\"pie\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_set = dataset_(train_data, train_dir,image_transform[\"train\"])\nvalidation_data_set = dataset_(train_data,val_dir, image_transform[\"test\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Load the data using Dataloader"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_frame = torch.utils.data.DataLoader(dataset=train_data_set, batch_size=32, shuffle=True)\nvalid_data_frame = torch.utils.data.DataLoader(dataset=validation_data_set, batch_size=32)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Load the VGG model and freeze the parameters weight for the feature detector. In the next code block we are going to create classifier and use the data to train the classifiers"},{"metadata":{"trusted":true},"cell_type":"code","source":"vgg16 = models.vgg16(pretrained=True)\nfor param in vgg16.parameters():\n    param.requires_grad = False\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import OrderedDict\n\nclassifier = torch.nn.Sequential(OrderedDict([\n    ('fc1',torch.nn.Linear(512*7*7,1024)),\n    ('relu',torch.nn.ReLU()),\n    ('fc2',torch.nn.Linear(1024,512)),\n    ('relu', torch.nn.ReLU()),\n    ('fc3',torch.nn.Linear(512,2)),\n    ('output',torch.nn.LogSoftmax(dim=1))\n]))\nvgg16.classifier = classifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = Adam(vgg16.classifier.parameters(), lr =0.001)\ncriterion = torch.nn.NLLLoss()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Make the computation $device$ ready\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"device = (\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ex_data, ex_label = next(iter(train_data_frame))\nfrom matplotlib import pyplot as plt\nplt.imshow(ex_data[1].view(224,224,-1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_epochs = 10\nvgg16.to(device)\ntrain_error_array = []\ntest_error_array = []\nfor epoch in range(total_epochs):\n    running_train_loss = 0.0\n    running_accuracy = 0.0\n    vgg16.train()\n    for step, (data, train_label) in enumerate(train_data_frame):\n        data, train_label = data.to(device), train_label.to(device)\n        output_pred = vgg16.forward(data)\n        train_ps = torch.exp(output_pred)\n        train_prob, train_cls = train_ps.topk(1, dim=1)\n        train_equals = (train_cls == train_label.long().view(*train_cls.shape))\n        running_accuracy += torch.mean(train_equals.type(torch.FloatTensor))\n        optimizer.zero_grad()\n        train_loss = criterion(output_pred, train_label.long())\n        running_train_loss += train_loss.item()\n        train_loss.backward()\n        optimizer.step()        \n        \n    else:\n        \n        test_accuracy= 0.0\n        testloss = 0.0\n        vgg16.eval()\n        with torch.no_grad():\n            for valid_data, valid_label in valid_data_frame:\n                valid_data, valid_label = valid_data.to(device), valid_label.to(device)\n                test_pred = vgg16.forward(valid_data)\n                test_loss = criterion(test_pred, valid_label.long())\n                testloss += test_loss.item()\n                out = torch.exp(test_pred)\n                prob, cls = out.topk(1, dim=1)\n                equals = (cls==valid_label.long().view(*cls.shape))\n                test_accuracy += torch.mean(equals.type(torch.FloatTensor))\n        train_error_array.append(running_train_loss/len(train_data_frame))\n        test_error_array.append(testloss/len(valid_data_frame))\n        print(f\"EPoch: {epoch+1} >> \")\n        print(f\"training loss >> {running_train_loss/len(train_data_frame)}\")\n        print(f\"test loss >> {testloss/len(valid_data_frame)}\")\n        print(f\"test accuracy >> {test_accuracy/len(valid_data_frame)}\")\n        print(\"\\n\")\n        \n\n            \n\n                        \n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(train_error_array, \"b\")\nplt.plot(test_error_array,'r')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output = []\nwith torch.no_grad():\n    vgg16.eval()\n    for test_data, _ in test_data_loader:\n        test_data = test_data.to(device)\n        test_output = vgg16.forward(test_data)\n        test_prob = torch.exp(test_output)\n\n        output += list(test_prob[:,1].cpu().data.numpy())\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_output = {\"id\": sample[\"id\"], \"has_cactus\":output}\nsample_output_dataframe = pd.DataFrame(sample_output)\nsample_output_dataframe.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"sample_output_dataframe.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}