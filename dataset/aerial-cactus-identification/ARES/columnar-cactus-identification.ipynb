{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"### Transfer Learning\n\nimport numpy as np\nimport pandas as pd\nimport os\nfrom tqdm import tqdm\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision.models as models\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision.transforms as transforms\n\nplt.ion()   # interactive mode","metadata":{"ExecuteTime":{"end_time":"2019-06-24T08:57:23.387512Z","start_time":"2019-06-24T08:57:21.551138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv('../input/train.csv')\nprint(len(df))\ndf.head()","metadata":{"ExecuteTime":{"end_time":"2019-06-24T08:57:24.290759Z","start_time":"2019-06-24T08:57:23.389304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dir = '../input/train/train/'\ntest_dir = '../input/test/test/'","metadata":{"ExecuteTime":{"end_time":"2019-06-24T08:57:24.372841Z","start_time":"2019-06-24T08:57:24.309603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ImageData(Dataset):\n    def __init__(self, df, data_dir, transform):\n        super().__init__()\n        self.df = df\n        self.data_dir = data_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):       \n        img_name = self.df.id[index]\n        label = self.df.has_cactus[index]\n        \n        img_path = os.path.join(self.data_dir, img_name)\n        image = mpimg.imread(img_path)\n        image = self.transform(image)\n        return image, label","metadata":{"ExecuteTime":{"end_time":"2019-06-24T08:57:24.547268Z","start_time":"2019-06-24T08:57:24.491205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 15\nbatch_size = 20\ndevice = torch.device('cuda:0')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_transf = transforms.Compose([transforms.ToPILImage(), transforms.ToTensor()])\ntrain_data = ImageData(df = df, data_dir = train_dir, transform = data_transf)\ntrain_loader = DataLoader(dataset = train_data, batch_size = batch_size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_loader = DataLoader(\n#             ImageFilelist(root=\"../input/train/train\", flist=train,\n#              transform=transforms.Compose([transforms.RandomSizedCrop(224),\n#                  transforms.RandomHorizontalFlip(),\n#                  transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n#             ])),\n#             batch_size=64, shuffle=False,\n#             num_workers=4, pin_memory=True)\n\n# val_loader = torch.utils.data.DataLoader(\n#             ImageFilelist(root=\"../input/train/train\", flist=train,\n#              transform=transforms.Compose([transforms.Scale(256),\n#                  transforms.CenterCrop(224),\n#                  transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n#             ])),\n#             batch_size=16, shuffle=False,\n#             num_workers=1, pin_memory=True)","metadata":{"ExecuteTime":{"end_time":"2019-06-24T10:19:23.482702Z","start_time":"2019-06-24T10:19:23.477593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"ExecuteTime":{"end_time":"2019-06-24T08:57:27.001249Z","start_time":"2019-06-24T08:57:26.998779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = models.resnet50(pretrained=True)\nmodel.cuda()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\nloss_func = nn.CrossEntropyLoss()","metadata":{"ExecuteTime":{"end_time":"2019-06-24T10:12:15.866535Z","start_time":"2019-06-24T10:04:47.897422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Train model\nfor epoch in tqdm(range(epochs)):\n    for i, (images, labels) in enumerate(train_loader):\n        images = images.to(device)\n        labels = labels.to(device)\n        \n        # Forward\n        outputs = model(images)\n        loss = loss_func(outputs, labels)\n        \n        # Backward and optimize\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        if (i+1) % 500 == 0:\n            print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, epochs, loss.item()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit = pd.read_csv('../input/sample_submission.csv')\ntest_data = ImageData(df = submit, data_dir = test_dir, transform = data_transf)\ntest_loader = DataLoader(dataset = test_data, shuffle=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict = []\nfor batch_i, (data, target) in enumerate(test_loader):\n    data, target = data.to(device), target.to(device)\n    output = model(data)\n    \n    _, pred = torch.max(output.data, 1)\n    predict.append(pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(predict)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit['has_cactus'] = predict\nsubmit.to_csv('submission.csv', index=False)\nsubmit.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}