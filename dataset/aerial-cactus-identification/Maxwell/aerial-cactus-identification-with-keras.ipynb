{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Aerial Cactus Identification with Keras\n\nThis kernel shows my finished work for this competition. I made a simple convolutional neural network with keras and trained it on a subset of the available data. The main breakthrough for me was creating a training set with an equal number of images of each class. One challenge I ran into was loading a model with the tensorflow.keras module -- it just doesn't seem to work with Tensorflow 1.13. To fix this I just used the original keras module as many others did. \n\nI am amazed by the quality and quantity of work that so many people put into this competition, and it was inspirational reading many polished kernels when I was getting started."},{"metadata":{},"cell_type":"markdown","source":"## Step 1: Examine the data\n\nThe first step in any data science project is to get an understanding of what you are working with. In this step, I declare my imports and paths to important locations on disk, load some data into memory, and examine it more closely."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Conv2D, Dense, Dropout, Flatten, MaxPooling2D\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n\nsns.set()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cactus_dir = \"../input/aerial-cactus-identification/\"\ntrain_dir = cactus_dir + \"/train/train/\"\ntest_dir = cactus_dir + \"/test/test/\"\n\ndf_train_data = pd.read_csv(cactus_dir + \"/train.csv\")\ndf_train_data['has_cactus'] = df_train_data['has_cactus'].astype(str)\n\ndf_test = pd.read_csv(cactus_dir + \"/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see what the 'train.csv' file has for us"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that each row is a filename ('id') and a class ('has_cactus'). Now let's see how many of each class we have:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The number of training images is: {}\".format(len(df_train_data)))\n\ndf_train_data['has_cactus'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So we have 17500 images total and just 4364 do not have a cactus in them. In other words, 75% of the training data consists of images with a cactus in it. To achieve better-than-random results, we'll have to do better than that. \n\nNow let's see what some of these images look like:"},{"metadata":{"trusted":true},"cell_type":"code","source":"display, axes = plt.subplots(4, 4, figsize=(16, 16))\nimgs = []\nlabels = []\nfor i, row in df_train_data.head(16).iterrows():\n    fname = os.path.join(train_dir, row['id'])\n    imgs.append(load_img(fname))\n    labels.append('Cactus' if row['has_cactus'] == '1' else 'No Cactus')\n\nfor i, ax in enumerate(axes.reshape(-1)):\n    ax.imshow(imgs[i])\n    ax.set_title(labels[i])\n    ax.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looking at a single image it is hard to immediately recognize that there is a cactus present. When we look at the images altogether a pattern is more clear -- long, straight lines seem to be the strongest identifier of a cactus in the images above. A simple convolutional network would probably do well on this data because it will be able to identify those long, straight features."},{"metadata":{},"cell_type":"markdown","source":"## Step 2: Prepare the Data for Keras\n\nThis is one of the most important steps in the ML process. If your data isn't prepared the right way for your model, then you might as well not have it. Luckily for us, the data has already been collected and formatted quite nicely. The remaining steps for us are to build training and validation sets, create a pipeline to load images into memory, and set up the ImageDataGenerator class from Keras to do some training data augmentation. "},{"metadata":{},"cell_type":"markdown","source":"### Training and Validation Sets\nWe need to create training and validation sets for our model. It is critical that these sets are disjoint -- no shared elements -- so that the validation set can be a true measure of our model's performance as it learns on the training data. \n\nI decided that my training set should be 50% images with a cactus and 50% images without a cactus so that the model would not initially have a bias towards classifing images as containing a cactus. On the other hand, I wanted my validation set to be 75% images with a cactus and 25% images without a cactus so it would be representative of the data overall.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"has_cactus = df_train_data[df_train_data['has_cactus'] == '1']\nnot_cactus = df_train_data[df_train_data['has_cactus'] == '0']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Want 80% of not_cactus to make up 50% of the training set\ndf_train = not_cactus[:3491]\ndf_train = df_train.append(has_cactus[:3491])\ndf_train = df_train.sample(frac=1).reset_index(drop=True)\n\ndf_train['has_cactus'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Want remainder of not_cactus to make up 25% of the validation set\ndf_valid = not_cactus[3491:]  # Has 873 elements\ndf_valid = df_valid.append(has_cactus[3491:3491 + 873*3])\ndf_valid = df_valid.sample(frac=1).reset_index(drop=True)\n\ndf_valid['has_cactus'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Augmentation and Pipeline\n\nNow that our training and validation sets have been established we can move on to the next step in the process, which is to create a pipeline to feed training images to our network. This is the part that I was most intimidated by when I first started coding in this competition, but tinkering with this next bit turned out to be one of my favorite parts of the whole thing. Keras makes this pretty straightforward:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data augmentation for training data\ntrain_datagen = ImageDataGenerator(rotation_range=50, \n                                   width_shift_range=0.2, \n                                   height_shift_range=0.2, \n                                   horizontal_flip=True, \n                                   rescale=1./255)\n\n# No augmentation for validation data\nvalid_datagen = ImageDataGenerator(rescale=1./255)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Keras also gives you an option to resize your images. I also scaled up the images by a factor of 2 here because that seemed to work better when I was testing."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Parameters for resizing the image and number of images in a training/validation batch\nnew_image_size = 64\nbatch_size = 128\n\n# Data pipeline: filename - dataframe --> image on disk --> keras model\n\n# Training data pipeline\ntrain_generator = train_datagen.flow_from_dataframe(df_train, \n                                                    directory=train_dir, \n                                                    x_col='id', \n                                                    y_col='has_cactus', \n                                                    target_size=(new_image_size, new_image_size), \n                                                    class_mode='binary', \n                                                    batch_size=batch_size)\n\n# Validation: exactly the same except flows from validation dataframe\nvalid_generator = valid_datagen.flow_from_dataframe(df_valid, \n                                                    directory=train_dir, \n                                                    x_col='id', \n                                                    y_col='has_cactus', \n                                                    target_size=(new_image_size, new_image_size),\n                                                    class_mode='binary',\n                                                    batch_size=batch_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 3: Building and Training a Convolutional Network\n\nIn this part we need to build our model, train it on our training data, and see how it performs. Once again, Keras makes this pretty straightforward.\n\n### Building a Model\n\nWe use the Keras Sequential API because this problem does not seem to require complex network architectures that the functional API is capable of providing. A simple CNN with some regularization (Dropout and Maxpooling2D) should do just fine! Here's my network:"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(32, (3, 3), input_shape=(new_image_size, new_image_size, 3), activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(MaxPooling2D((2,2)))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(MaxPooling2D((2,2)))\nmodel.add(Conv2D(128, (3,3), activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(MaxPooling2D((2,2)))\nmodel.add(Conv2D(512, (3,3), activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(MaxPooling2D((2,2)))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we compile the model using the AdamOptimizer with default settings and Binary Crossentropy as our loss metric. Accuracy is monitored because we need to be able to report how our model does on the training and validation sets. Additionally, we also create several callbacks which will help us during training. "},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam', \n              loss='binary_crossentropy', \n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save the model every time its best validation accuracy improves\ncheckpoint = ModelCheckpoint(\"model.hdf5\", \n                             monitor='val_acc', \n                             verbose=1, \n                             save_best_only=True, \n                             mode='max')\n\n# Reduce the learning rate when the model's performance begins to stagnate \nreduce_lr = ReduceLROnPlateau(monitor='val_acc', \n                              factor=.2,\n                              patience=10, \n                              min_lr=1e-9,\n                              verbose=1)\n\n# Using early stopping with a high patience value to balance improvement & my own patience\nearly_stop = EarlyStopping(monitor='val_acc', \n                           patience=100, \n                           verbose=1, \n                           mode='auto', \n                           baseline=None, \n                           restore_best_weights=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training the Model\n\nNow that our model is compiled and we've setup some callbacks to use during training, we can finally train our model. Note that we use model.fit_generator instead of model.fit because we set up our data pipeline with generators. This takes quite a while, so I'm going to load the model that I trained overnight on my own computer instead. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# hist = model.fit_generator(train_generator, \n#                            steps_per_epoch=len(df_train)//batch_size, \n#                            epochs=1000, \n#                            validation_data=valid_generator, \n#                            validation_steps=len(df_valid)//batch_size, \n#                            callbacks=[checkpoint, reduce_lr, early_stop],\n#                            verbose=0)\n\nmodel = load_model('../input/best-model-1/model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Normally, I would plot the model's accuracy as a function of the number of epochs it trained, but we can't do this when we are just loading the model, so this is commented out here."},{"metadata":{"trusted":true},"cell_type":"code","source":"# def plot_from_history(history):\n#     history_dict = history.history\n#     loss = history_dict['loss']\n#     val_loss = history_dict['val_loss']\n#     acc = history_dict['acc']\n#     val_acc = history_dict['val_acc']\n#     epochs = range(1, len(loss) + 1)\n    \n#     fig, ax1 = plt.subplots(1, figsize=(8, 4), dpi=150)\n#     ax1.set_title('Accuracy vs Epoch')\n#     ax1.plot(epochs, acc, label='Training Accuracy')\n#     ax1.plot(epochs, val_acc, label='Validation Accuracy')\n#     ax1.legend(loc='best')\n#     plt.show()\n\n# plot_from_history(hist)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We report the model's final validation accuracy so we know what to expect for our results (This can be done when loading the model)."},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate_generator(valid_generator, steps=len(df_valid)//batch_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Making Predictions\n\nNow that the model is trained, we can use it to make predictions on the test data. This will be what we submit to the competition. Our first step is to load the test data into memory, which we can do with the keras.preprocessing.image load_img and img_to_array functions. "},{"metadata":{"trusted":true},"cell_type":"code","source":"test_fnames = []\ntest_imgs = []\nfor fname in os.listdir(test_dir):\n    test_fnames.append(fname)\n    img = load_img(test_dir + fname, target_size=(new_image_size, new_image_size, 3))\n    img = img_to_array(img) / 255\n    test_imgs.append(img)\ntest_imgs = np.array(test_imgs)\n\ntest_imgs.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we make the predictions (Note that I do not use the predict_classes function):"},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict(test_imgs)\npred[:5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finally, we save the predictions to the disk. Make sure to set index=False, otherwise you'll end up with an extra column in your csv file that you submit... I learned that the hard way."},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame()\nsubmission['id'] = test_fnames\nsubmission['has_cactus'] = pred\nsubmission.to_csv('submission.csv', index=False)\n\nsubmission.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}