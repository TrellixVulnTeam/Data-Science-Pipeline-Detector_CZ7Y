{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TrainingLabels= pd.read_csv('/kaggle/input/aerial-cactus-identification/train.csv')\nTrainingLabels","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Extract the Zip Files Containing The Training Images and Test Images\nimport zipfile\n\nDataSetArray=[]\nDataSetArray.append(\"test\")\nDataSetArray.append(\"train\")\n\n\nfor i in range(2):\n    # Will unzip the files so that you can see them..\n    with zipfile.ZipFile(\"/kaggle/input/aerial-cactus-identification/\"+DataSetArray[i]+\".zip\",\"r\") as z:\n        z.extractall(\"./\"+DataSetArray[i]+\"/\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\nimport glob\n\n\nListOfImagesInTrainFolder= glob.glob(\"./train/train/*.jpg\")\nListOfImagesInTrainFolder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def DisplayImageAndLabel(i):\n    RandomImage=ListOfImagesInTrainFolder[i]\n    print(RandomImage)\n    im= cv2.imread(RandomImage)\n    plt.imshow(im)\n    print(TrainingLabels.iloc[i])\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def GetImageNameFromPath(Path):\n    Index=Path.find(\"./train/train/\")\n    Name=Path[Index+len(\"./train/train/\"):]\n    return Name\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GetImageNameFromPath(ListOfImagesInTrainFolder[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport torch\n\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check if CUDA is available\ntrain_on_gpu = torch.cuda.is_available()\n\nif not train_on_gpu:\n    print('CUDA is not available.  Training on CPU ...')\nelse:\n    print('CUDA is available!  Training on GPU ...')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# VGG-16 Takes 224x224 images as input, so we resize all of them\ndata_transform = transforms.Compose([transforms.RandomResizedCrop(224), \n                                      transforms.ToTensor()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = datasets.ImageFolder(\"./train/\", transform=data_transform)\ntest_data = datasets.ImageFolder(\"./test/\", transform=data_transform)\n# print out some data stats\nprint('Num training images: ', len(train_data))\nprint('Num test images: ', len(test_data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(train_data.imgs)):\n    Val1=train_data.imgs[i][0]\n    Label_=Labels[i]\n    train_data.imgs[i]=(Val1,Label_)\n    \nfor img in train_data.imgs:\n    print(img)\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define dataloader parameters\nbatch_size = 20\nnum_workers=0\n\n# prepare data loaders\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n                                           num_workers=num_workers)\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n                                          num_workers=num_workers)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Labels=[]\n\ndef GetLabelOfThatImage():\n    for img in train_data.imgs:\n        imgPath=img[0]\n        Name= GetImageNameFromPath(imgPath)\n        row= TrainingLabels.loc[TrainingLabels['id'] == Name]\n        Labels.append(row.iloc[0]['has_cactus'])\n    \nGetLabelOfThatImage()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Length of Labels is \"+str(len(Labels)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Labels[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize some sample data\n\n# obtain one batch of training images\ndataiter = iter(train_loader)\nimages, labels = dataiter.next()\nimages = images.numpy() # convert images to numpy for display\n\n# plot the images in the batch, along with the corresponding labels\nfig = plt.figure(figsize=(25, 4))\nfor idx in np.arange(20):\n    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n    plt.imshow(np.transpose(images[idx], (1, 2, 0)))\n    ax.set_title(Labels[idx])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load the pretrained model from pytorch\nvgg16 = models.vgg16(pretrained=True)\n\n# print out the model structure\nprint(vgg16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Freeze training for all \"features\" layers\nfor param in vgg16.features.parameters():\n    param.requires_grad = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.nn as nn\n\nn_inputs = vgg16.classifier[6].in_features\n\n#it's a cactus or not a cactus\nlast_layer = nn.Linear(n_inputs, 2)\n\nvgg16.classifier[6] = last_layer\n\n# if GPU is available, move the model to GPU\nif train_on_gpu:\n    vgg16.cuda()\n\n# check to see that your last layer produces the expected number of outputs\nprint(vgg16.classifier[6].out_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.optim as optim\n\n# specify loss function (categorical cross-entropy)\ncriterion = nn.CrossEntropyLoss()\n\n# specify optimizer (stochastic gradient descent) and learning rate = 0.001\noptimizer = optim.SGD(vgg16.classifier.parameters(), lr=0.001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_epochs = 5\n\nfor epoch in range(1, n_epochs+1):\n\n    # keep track of training and validation loss\n    train_loss = 0.0\n    \n    ###################\n    # train the model #\n    ###################\n    # model by default is set to train\n    for batch_i, (data, target) in enumerate(train_loader):\n        # move tensors to GPU if CUDA is available\n        if train_on_gpu:\n            data, target = data.cuda(), target.cuda()\n        # clear the gradients of all optimized variables\n        optimizer.zero_grad()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = vgg16(data)\n        # calculate the batch loss\n        loss = criterion(output, target)\n        # backward pass: compute gradient of the loss with respect to model parameters\n        loss.backward()\n        # perform a single optimization step (parameter update)\n        optimizer.step()\n        # update training loss \n        train_loss += loss.item()\n        \n        if batch_i % 20 == 19:    # print training loss every specified number of mini-batches\n            print('Epoch %d, Batch %d loss: %.16f' %\n                  (epoch, batch_i + 1, train_loss / 20))\n            train_loss = 0.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i=0\nMyData = pd.DataFrame()\nfor TestImg in test_data:\n    \n    img=test_data.imgs[i]\n    imgPath=img[0]\n    Name= GetImageNameFromPath(imgPath)\n    \n    Img=TestImg[0].unsqueeze(0)\n    output= vgg16(Img.cuda())\n    o=output.topk(1)\n    Indicies=o[1]\n    MyData= MyData.append({'id': str(Name) , 'has_cactus': int(Indicies)},ignore_index=True)\n\nMyData.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MyData","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nMyData.to_csv('./test/Result.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}