{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Cactus Classification"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Prep"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport glob\n%matplotlib inline \nimport os","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm\nimport tensorflow.keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense,Conv2D,Flatten,Dropout,MaxPooling2D,Activation,BatchNormalization,LeakyReLU,GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam,SGD\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.callbacks import CSVLogger,ModelCheckpoint,ReduceLROnPlateau\nfrom tensorflow.keras.regularizers import l2\nfrom PIL import Image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport cv2\nimport os\n\ndef load_imgs(path):\n    imgs = {}\n    for f in os.listdir(path):\n        fname = os.path.join(path, f)\n        imgs[f] = cv2.imread(fname)\n    return imgs\n\nimg_train = load_imgs('../input/train/train/')\nimg_test = load_imgs('../input/test/test/')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reading from the train folder, we normalized the images"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_csv = pd.read_csv('../input/train.csv')\nimport numpy as np\n\nX_train = []\nY_train = []\n\nfor _, row in train_csv.iterrows():\n    X_train.append(img_train[row['id']]/255)\n    Y_train.append(int(row['has_cactus']))\n\nX_train = np.array(X_train)\nY_train = np.array(Y_train)\n\nX_test = np.array([img_test[f] for f in img_test])\n\nprint('Training data shape:', X_train.shape, '=>', Y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport numpy as np\nfrom matplotlib import pyplot as plt\nplt.rcParams[\"axes.grid\"] = False","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plotting the normalized images- showing three images with cactus and two without cactus"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1, 5, figsize=(15, 4))\naxes[0].imshow(X_train[0])\naxes[0].set_title(\"Has cactus:\" + str(Y_train[0]))\naxes[1].imshow(X_train[1])\naxes[1].set_title(\"Has cactus:\" + str(Y_train[0]))\naxes[2].imshow(X_train[2])\naxes[2].set_title(\"Has cactus:\" + str(Y_train[0]))\naxes[3].imshow(X_train[1000])\naxes[3].set_title(\"Has cactus:\" + str(Y_train[1000]))\naxes[4].imshow(X_train[1050])\naxes[4].set_title(\"Has cactus:\" + str(Y_train[1050]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Image preprocessing using Guassian filtering\nFor sharpening the edges of cactus in the pixelated images, we applied Gaussian filtering"},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.ndimage import gaussian_filter\n\ndef img_sharpen(img):\n    blurred_f = gaussian_filter(img, 2)\n\n    filter_blurred_f = gaussian_filter(blurred_f, 2)\n\n    alpha = 15\n    sharpened = blurred_f + alpha * (blurred_f - filter_blurred_f)\n    return sharpened","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Sharpen the low quality cactus images\nsharp_img_xtrain = []\n\nfor im in X_train:\n    sharp_img_xtrain.append(img_sharpen(im))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plotting the same images as above except with the sharpening filter using Gaussian filtering"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1, 5, figsize=(15, 4))\naxes[0].imshow(sharp_img_xtrain[0])\naxes[0].set_title(\"Has cactus:\" + str(Y_train[0]))\naxes[1].imshow(sharp_img_xtrain[1])\naxes[1].set_title(\"Has cactus:\" + str(Y_train[0]))\naxes[2].imshow(sharp_img_xtrain[2])\naxes[2].set_title(\"Has cactus:\" + str(Y_train[0]))\naxes[3].imshow(sharp_img_xtrain[1000])\naxes[3].set_title(\"Has cactus:\" + str(Y_train[1000]))\naxes[4].imshow(sharp_img_xtrain[1050])\naxes[4].set_title(\"Has cactus:\" + str(Y_train[1050]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train/Test Split for CNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom numpy import array\n\nsharp_xtrain = array(sharp_img_xtrain)\nx_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Defining a class for pooling a layer using Mulitple Learning Instance. \nInspire by article on classifying images using deep multiple instance learning: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4908336/pdf/btw252.pdf"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\n\nclass noisyand(tf.keras.layers.Layer):\n    def __init__(self, num_classes, a = 20, **kwargs):\n        self.num_classes = num_classes\n        self.a = max(1,a)\n        super(noisyand,self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        self.b = self.add_weight(name = \"b\",shape = (1,input_shape[-1].value), initializer = \"uniform\",trainable = True)\n        super(noisyand,self).build(input_shape)\n\n    def call(self,x):\n        mean = tf.reduce_mean(x, axis = [1,2])\n        return (tf.nn.sigmoid(self.a * (mean - self.b)) - tf.nn.sigmoid(-self.a * self.b)) / (tf.nn.sigmoid(self.a * (1 - self.b)) - tf.nn.sigmoid(-self.a * self.b))\n    \n    def compute_output_shape(self, input_shape):\n        return input_shape[0], input_shape[3]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Defining the Deep CNN model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def define_model(input_shape= (32,32,3), num_classes=1):\n    model = Sequential()\n    model.add(Conv2D(64, kernel_size=(3, 3),\n                     activation='relu',\n                     padding = 'same',\n                     input_shape=input_shape))\n    \n    model.add(Conv2D(64, (3, 3), padding = 'same', activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D())\n    \n    model.add(Conv2D(128, (3, 3), activation='relu'))\n    model.add(MaxPooling2D())\n\n    model.add(Conv2D(128, (3, 3), activation='relu'))\n    model.add(Conv2D(128, (1, 1), activation='relu'))\n    \n    model.add(noisyand(num_classes+1))\n    model.add(Dense(num_classes, activation='sigmoid'))\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = define_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss=tensorflow.keras.losses.binary_crossentropy,\n                  optimizer=tensorflow.keras.optimizers.RMSprop(),\n                  metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epoch=15\nhistory = model.fit(x_train, y_train,\n         batch_size=32,\n         epochs=epoch,\n         verbose=1,\n         validation_data=(x_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plotting the accuracy scores of the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"acc=history.history['acc']\nepochs_=range(0,epoch)\nplt.plot(epochs_,acc,label='training accuracy')\n\nacc_val=history.history['val_acc']\nplt.scatter(epochs_,acc_val,label=\"validation accuracy\")\nplt.ylim([0.85,1.0])\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('Accuracy Plot of Model')\n\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plotting the loss scores of the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"acc=history.history['loss']\nepochs_=range(0,epoch)\nplt.plot(epochs_,acc,label='training loss')\n\nacc_val=history.history['val_loss']\nplt.scatter(epochs_,acc_val,label=\"validation loss\")\nplt.ylim([0,0.5])\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Loss Plot of Model')\n\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submission Part"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_set=pd.read_csv('../input/sample_submission.csv')\nsubmission_set.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Predicting images has cactus for submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions=np.empty((submission_set.shape[0],))\n    \nfor n in tqdm(range(submission_set.shape[0])):\n    data=np.array(Image.open('../input/test/test/'+submission_set.id[n]))\n    data=data.astype(np.float32)/255\n    #Sharpen the low quality cactus images\n    data=img_sharpen(data)\n    predictions[n]=model.predict(data.reshape((1,32,32,3)))[0]\n\n    \nsubmission_set['has_cactus']=predictions\nsubmission_set.to_csv('sample_submission.csv',index=False)\n\nsubmission_set.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ROC Curve"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, auc\n\nclf=model\ny_pred_proba = clf.predict_proba(x_test)\ny_pred = clf.predict_classes(x_test)\n\nfpr,tpr,_= roc_curve(y_test, y_pred_proba)\nroc_auc = auc(fpr, tpr)\n\nplt.figure()\nplt.plot(fpr, tpr, color='darkorange',\n         lw=1.5, label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=1.5, linestyle='--')\nplt.xlim([-0.05, 1.05])\nplt.ylim([-0.05, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic example')\nplt.legend(loc=\"lower right\")\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}