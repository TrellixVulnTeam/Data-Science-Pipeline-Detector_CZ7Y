{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        #print(os.path.join(dirname, filename))\n        pass\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"metaTrain=pd.read_csv(\"/kaggle/input/aerial-cactus-identification/train.csv\")\nbaseDir='/kaggle/input/aerial-cactus-identification/train/train/'\nmetaTrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fileNames=[str(baseDir+x) for x in metaTrain['id'].tolist()]\nfileLabels=metaTrain['has_cactus'].tolist()\nprint('There are '+str(len(fileNames)) + ' pictures.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp=pd.get_dummies(fileLabels)\nfileLabels=[]\nfor x,y in zip(temp[0].tolist(),temp[1].tolist()):\n    fileLabels.append([x,y])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import PIL\nimport matplotlib.pyplot as plt\n\nfrom PIL import Image\n\ndef makeTrainingBatch(batchIdx,batchSize):\n    trainImgs=[]\n    trainLabels=[]\n    for i in range(batchIdx*batchSize,(batchIdx+1)*batchSize):\n        img = Image.open(fileNames[i])\n        label=fileLabels[i]\n        img=img.resize((28,28))\n        img=np.asarray(img)\n        trainImgs.append(img)\n        trainLabels.append(label)\n    return np.array(trainImgs)/255.0,np.array(trainLabels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\n\nx=tf.placeholder(tf.float32,[None,28,28,3])\ny=tf.placeholder(tf.int32,[None,2])\nprob = tf.placeholder_with_default(1.0, shape=())\n\nskipConnection1 = tf.layers.conv2d(inputs=x,filters=16,kernel_size=[2, 2],\n                         padding=\"same\",activation=tf.nn.relu)\nskipConnection2= tf.layers.conv2d(inputs=x,filters=16,kernel_size=[3, 3],\n                         padding=\"same\",activation=tf.nn.relu)\nskipConnection3= tf.layers.conv2d(inputs=x,filters=16,kernel_size=[4, 4],\n                         padding=\"same\",activation=tf.nn.relu)\n\nconv1=tf.keras.layers.concatenate([skipConnection1,skipConnection2,skipConnection3],axis=-1)\n\nconv2 = tf.layers.conv2d(inputs=conv1,filters=64,kernel_size=[3, 3],\n      padding=\"same\",activation=tf.nn.relu)\npool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n# 14*14*64\n\nconv3 = tf.layers.conv2d(inputs=pool2,filters=64,kernel_size=[3, 3],\n      padding=\"same\",activation=tf.nn.relu)\npool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2], strides=2)\n# 7*7*64\n\nconv4 = tf.layers.conv2d(inputs=pool3,filters=128,kernel_size=[3, 3],\n      padding=\"same\",activation=tf.nn.relu)\npool4 = tf.layers.max_pooling2d(inputs=conv4, pool_size=[2, 2], strides=2)\n\npool2_flat = tf.reshape(pool4, [-1, 3 * 3 * 128])\ndense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\ndropout = tf.layers.dropout(dense, prob)\n\ndense2 = tf.layers.dense(inputs=dropout, units=32, activation=tf.nn.relu)\n\nlogits = tf.layers.dense(inputs=dense2, units=2)\n\nloss = tf.losses.softmax_cross_entropy(y, logits)\n\n# Configure the Training Op (for TRAIN mode)\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=0.003)\ntrain_op = optimizer.minimize(loss=loss)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Batch 200*300\ninit=tf.global_variables_initializer()\nsess=tf.Session()\n\nsess.run(init)\nbatchInt=0\nfor fulliters in range(200):\n    batchInt+=1\n    totLoss=0\n    for batch in range(100):\n        x_train,y_train=makeTrainingBatch(batch,175)\n        _,currLoss=sess.run([train_op,loss],feed_dict={x:x_train,y:y_train,prob:0.3})\n        totLoss+=currLoss\n    print('Batch: '+str(batchInt) + ' Loss is: '+ str(totLoss/175))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sampleSubmit=pd.read_csv('/kaggle/input/aerial-cactus-identification/sample_submission.csv')\nsampleSubmit.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testBaseDir='/kaggle/input/aerial-cactus-identification/test/test/'\nfileNamesPred=[str(testBaseDir+x) for x in sampleSubmit['id'].tolist()]\nfileLabelsPred=sampleSubmit['has_cactus'].tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def makeTestingBatch(batchIdx,batchSize):\n    trainImgs=[]\n    trainLabels=[]\n    for i in range(batchIdx*batchSize,(batchIdx+1)*batchSize):\n        img = Image.open(fileNamesPred[i])\n        label=fileLabelsPred[i]\n        img=img.resize((28,28))\n        img=np.asarray(img)\n        trainImgs.append(img)\n        trainLabels.append(label)\n    return np.array(trainImgs)/255.0,np.array(trainLabels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for fulliters in range(1):\n    masterPred=[]\n    x_train,y_train=makeTestingBatch(0,len(fileLabelsPred))\n    pred=sess.run([logits],feed_dict={x:x_train,prob:1.0})\n    for i in pred[0]:\n        if i[1]>i[0]:\n            masterPred.append(1)\n        else:\n            masterPred.append(0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sampleSubmit['has_cactus']=masterPred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sampleSubmit.to_csv('toSubmit.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}