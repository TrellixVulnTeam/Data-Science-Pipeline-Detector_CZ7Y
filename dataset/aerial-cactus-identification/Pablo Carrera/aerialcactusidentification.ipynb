{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Basics\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport random\n\n# Images\nimport os\nfrom PIL import Image\n\n# Machine Learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Tensorflow\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\nfrom keras.utils import to_categorical","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"def get_pixel_data(filepath):\n    \"\"\"\n    Get the pixel data from an image as a pandas DataFrame.\n    \"\"\"\n    # Import libraries\n    # import pandas as pd\n    # from PIL import Image\n    \n    # Open the file\n    image = Image.open(filepath)\n    \n    # Get the data and average between channels\n    pixel_data = np.array(image.getdata())\n    pixel_data = pixel_data.mean(axis = 1)\n    pixel_data = pixel_data.reshape(1,32*32)\n    pixel_data = pd.DataFrame(pixel_data, columns = np.arange(32*32))\n    \n    # Close the file\n    image.close()\n    \n    return pixel_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train data\npath = \"../input/train/train/\"\ntrain = pd.DataFrame()\nfor file in sorted(os.listdir(path)):\n    image = get_pixel_data(path + file)\n    train = train.append(image, ignore_index = True)\n\nlabels_train = pd.read_csv(\"../input/train.csv\").sort_values(\"id\")\n\n# Test data\npath = \"../input/test/test/\"\ntest = pd.DataFrame()\ntest_id = []\nfor file in sorted(os.listdir(path)):\n    image = get_pixel_data(path + file)\n    test  = test.append(image, ignore_index = True)\n    test_id.append(file)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"TRAIN---------------------\")\nprint(\"Shape: {}\".format(train.shape))\nprint(\"Label 0 (False): {}\".format(np.sum(labels_train.has_cactus == 0)))\nprint(\"Label 1 (True):  {}\".format(np.sum(labels_train.has_cactus == 1)))\nprint(\"TEST----------------------\")\nprint(\"Shape: {}\".format(test.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Simple model: Logistic regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create train set and validation set\nrandom.seed(0)\n\nidx = random.choices(range(17500), k = 10000)\nX_train = train.iloc[idx] / 255           # Normalize\nX_test  = train.drop(idx, axis = 0) / 255 # Normalize\ntest    = test / 255                      # Normalize\ny_train = labels_train.iloc[idx,1]\ny_test  = labels_train.drop(idx, axis = 0).iloc[:,1]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LogisticRegression(solver = \"lbfgs\", random_state = 0)\nmodel.fit(X_train, y_train)\nmodel.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Medium model: Random forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = RandomForestClassifier(n_estimators = 100, criterion = \"entropy\", random_state = 0)\nmodel.fit(X_train, y_train)\nmodel.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Complex model: Neuronal network"},{"metadata":{},"cell_type":"markdown","source":"## Dense network"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense(5, activation = \"relu\", input_shape = (1024,)))\nmodel.add(Dense(10, activation = \"relu\"))\nmodel.add(Dense(2,  activation = \"sigmoid\"))\nmodel.summary()\n\nmodel.compile(optimizer = \"adam\",\n              loss = \"categorical_crossentropy\",\n              metrics = [\"accuracy\"])\nmodel.fit(X_train, to_categorical(y_train), epochs = 5)\nmodel.evaluate(X_test, to_categorical(y_test))[1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Convolutional: 1 channel"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_cnn = np.array(X_train).reshape((X_train.shape[0], 32, 32, 1))\nX_test_cnn  = np.array(X_test).reshape((X_test.shape[0], 32, 32, 1))\ntest_cnn    = np.array(test).reshape((test.shape[0], 32, 32, 1))\n\nmodel = Sequential()\nmodel.add(Conv2D(filters = 8, kernel_size = 3, activation = \"relu\", input_shape = (32, 32, 1)))\nmodel.add(MaxPooling2D(pool_size = 2))\nmodel.add(Conv2D(filters = 16, kernel_size = 3, activation = \"relu\"))\nmodel.add(MaxPooling2D(pool_size = 2))\nmodel.add(Flatten())\nmodel.add(Dense(2,  activation = \"softmax\"))\nmodel.summary()\n\nmodel.compile(optimizer = \"adam\",\n              loss = \"categorical_crossentropy\",\n              metrics = [\"accuracy\"])\nmodel.fit(X_train_cnn, to_categorical(y_train), epochs = 10)\nmodel.evaluate(X_test_cnn, to_categorical(y_test))[1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Results"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make the predictions\npreds = model.predict_classes(test_cnn)\nprint(\"Label 0 (False): {}\".format(np.sum(preds == 0)))\nprint(\"Label 1 (True):  {}\".format(np.sum(preds == 1)))\n\n# Save the results\nresults = pd.DataFrame({\"id\" : test_id, \"has_cactus\": preds})\nresults.to_csv(\"submission.csv\", index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}