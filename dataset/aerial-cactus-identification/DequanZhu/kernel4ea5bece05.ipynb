{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\nfrom __future__ import print_function, division\nimport os\n\nimport pdb\n\nimport argparse\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, utils\n\n\nclass TestDatasets(Dataset):\n\n        def __init__(self,  test_dir, transform=None):\n            self.root_dir=test_dir\n            self.transform = transform\n            \n            self.abs_paths=self.get_paths()\n    \n        def __len__(self):\n            return len(self.abs_paths)\n            \n\n        def get_paths(self):\n            self.paths_list = os.listdir(self.root_dir)\n            abs_paths_list=[]\n            for path in self.paths_list:\n                abs_path=self.root_dir+path\n                abs_paths_list.append(abs_path)\n            return abs_paths_list\n        \n        def __getitem__(self, idx):\n            img_name = self.abs_paths[idx]\n            id=self.paths_list[idx]\n            image = Image.open(img_name)\n            \n            if self.transform:\n                image = self.transform(image)\n            return image,id\n\n\n\n\n\n\n\n  \n\nclass CactusDatasets(Dataset):\n    \"\"\"Face Landmarks dataset.\"\"\"\n\n    def __init__(self, csv_file, root_dir, transform=None,test=False):\n        self.test=test\n        self.cactus_frame = pd.read_csv(csv_file)\n        self.root_dir = root_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.cactus_frame)\n\n    def __getitem__(self, idx):\n        img_name = os.path.join(self.root_dir,self.cactus_frame.iloc[idx, 0])\n        image = Image.open(img_name)\n\n        if self.transform:\n            image = self.transform(image)\n        if not self.test:\n\n            label = self.cactus_frame.iloc[idx, 1].astype('float32')\n            return image,label\n        else:\n            return image\n\n\ntransform = transforms.Compose([transforms.Resize(size=(32, 32), interpolation=2),\n                                transforms.RandomHorizontalFlip(),\n                                transforms.RandomVerticalFlip(),\n                                transforms.ToTensor()])\n\n\ntr_cactus_datasets=CactusDatasets(csv_file='../input/train.csv',\n                                 root_dir='../input/train/train',\n                                 transform=transform)\n\n\ntest_datasets=TestDatasets('../input/test/test/',transform=transform)   \n\n\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net,self).__init__()\n        self.conv1=nn.Conv2d(3,6,5,1)\n        self.conv2=nn.Conv2d(6,16,5,1)\n        self.bn1=nn.BatchNorm2d(6)\n        self.bn2=nn.BatchNorm2d(16)\n        self.fc1=nn.Linear(5*5*16,120)\n        self.fc2=nn.Linear(120,84)\n        self.fc3=nn.Linear(84,1)\n        self.drop1=nn.Dropout2d(p=0.5)\n    def forward(self,x ):\n        x=self.conv1(x)\n        x=F.relu(self.bn1(x))\n        x=F.max_pool2d(x,2,2)\n        x=self.conv2(x)\n        x=F.relu(self.bn2(x))\n        x=F.max_pool2d(x,2,2)\n        x=x.view(-1,5*5*16)\n        x=F.relu(self.fc1(x))\n        x=F.relu(self.fc2(x))\n        x=self.fc3(self.drop1(x))\n        x=F.sigmoid(x)\n        return x\n\n\n\n\ndef train(model, device, train_loader, optimizer, epoch):\n    model.train()\n    for batch_idx, (data, target) in enumerate(train_loader):\n        data, target = data.to(device), target.to(device)\n        optimizer.zero_grad()\n        output = model(data)\n\n        loss=F.binary_cross_entropy(output,target)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % 10 == 0:\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.item()))\n\n\n            \n\n            \ndef main():\n    torch.manual_seed(1)\n    use_cuda=True\n    epoches=20\n    kwargs = {'num_workers': 4, 'pin_memory': True} if use_cuda else {}\n\n    \n    train_loader = torch.utils.data.DataLoader(tr_cactus_datasets, batch_size=64, shuffle=True,**kwargs)\n\n    test_loader=torch.utils.data.DataLoader(test_datasets,batch_size=4000, shuffle=False,**kwargs) \n    \n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = Net().to(device)\n    optimizer = optim.Adam(model.parameters(), lr=0.01)\n    for epoch in range(1, epoches+ 1):\n        train(model, device, train_loader, optimizer, epoch)\n     \n    model.eval()\n    predicts=[]\n    ids=[]\n    with torch.no_grad():\n        for data,img_name in test_loader:\n            data=data.to(device)          \n            preds=model(data)\n            preds=list(np.squeeze(preds.cpu().numpy()))\n            ids=img_name\n\n    df=pd.DataFrame({'id':ids,'has_cactus':preds})\n    df.to_csv('submission.csv ')\n    \n\n        \nif __name__ == '__main__':\n    main()\n\n\n\n\n# Any results you write to the current directory are saved as output.","execution_count":5,"outputs":[{"output_type":"stream","text":"['test', 'sample_submission.csv', 'train.csv', 'train']\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])) is deprecated. Please ensure they have the same size.\n  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n","name":"stderr"},{"output_type":"stream","text":"Train Epoch: 1 [0/17500 (0%)]\tLoss: 0.743777\nTrain Epoch: 1 [640/17500 (4%)]\tLoss: 0.296053\nTrain Epoch: 1 [1280/17500 (7%)]\tLoss: 0.214810\nTrain Epoch: 1 [1920/17500 (11%)]\tLoss: 0.287732\nTrain Epoch: 1 [2560/17500 (15%)]\tLoss: 0.246032\nTrain Epoch: 1 [3200/17500 (18%)]\tLoss: 0.070561\nTrain Epoch: 1 [3840/17500 (22%)]\tLoss: 0.112225\nTrain Epoch: 1 [4480/17500 (26%)]\tLoss: 0.124185\nTrain Epoch: 1 [5120/17500 (29%)]\tLoss: 0.266879\nTrain Epoch: 1 [5760/17500 (33%)]\tLoss: 0.126982\nTrain Epoch: 1 [6400/17500 (36%)]\tLoss: 0.286269\nTrain Epoch: 1 [7040/17500 (40%)]\tLoss: 0.137557\nTrain Epoch: 1 [7680/17500 (44%)]\tLoss: 0.168261\nTrain Epoch: 1 [8320/17500 (47%)]\tLoss: 0.243371\nTrain Epoch: 1 [8960/17500 (51%)]\tLoss: 0.160744\nTrain Epoch: 1 [9600/17500 (55%)]\tLoss: 0.152894\nTrain Epoch: 1 [10240/17500 (58%)]\tLoss: 0.260781\nTrain Epoch: 1 [10880/17500 (62%)]\tLoss: 0.125112\nTrain Epoch: 1 [11520/17500 (66%)]\tLoss: 0.190481\nTrain Epoch: 1 [12160/17500 (69%)]\tLoss: 0.145443\nTrain Epoch: 1 [12800/17500 (73%)]\tLoss: 0.099623\nTrain Epoch: 1 [13440/17500 (77%)]\tLoss: 0.249115\nTrain Epoch: 1 [14080/17500 (80%)]\tLoss: 0.069616\nTrain Epoch: 1 [14720/17500 (84%)]\tLoss: 0.126316\nTrain Epoch: 1 [15360/17500 (88%)]\tLoss: 0.121523\nTrain Epoch: 1 [16000/17500 (91%)]\tLoss: 0.159601\nTrain Epoch: 1 [16640/17500 (95%)]\tLoss: 0.135555\nTrain Epoch: 1 [17280/17500 (99%)]\tLoss: 0.141338\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([28])) that is different to the input size (torch.Size([28, 1])) is deprecated. Please ensure they have the same size.\n  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport os\nprint(os.listdir('./'))\ndf=pd.read_csv('./sample_submission.csv')\nprint(df)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nprint(os.listdir('./'))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}