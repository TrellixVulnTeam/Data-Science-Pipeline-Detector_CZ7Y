{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input/train/\"))\nimport keras\nimport cv2\nfrom keras.applications.vgg16 import VGG16\nimport tensorflow as tf\nimport random\nnp.random.seed(0)\nfrom tqdm import tqdm_notebook\n# model = VGG16(weights='imagenet', include_top=False)\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN_IMAGES_PATH = '../input/train/train'\nTEST_IMAGES_PATH = '../input/test/test'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create training, test dataframes for image IDs and their respective labels\ntrain_df = pd.read_csv('../input/train.csv')\ntest_df = pd.read_csv('../input/sample_submission.csv')\ntrain_image_ids = train_df['id']\ntraining_labels = train_df['has_cactus']\ntest_image_ids = test_df['id']\ntest_labels = test_df['has_cactus']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_images(folder_path, image_ids):\n    \"\"\"\n    Function to read images from disk and normalize them\n    \"\"\"\n    all_images = list()\n    for image_name in tqdm_notebook(image_ids):\n        image_path = os.path.join(folder_path, image_name)\n        image = cv2.imread(image_path)\n        all_images.append(image)\n    input_images = np.stack(all_images)\n    return input_images, input_images / 255\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Store train and test images in a numpy array\nall_train_images, normalized_images = get_images(TRAIN_IMAGES_PATH, train_image_ids)\ntest_images, normalized_test_images = get_images(TEST_IMAGES_PATH, test_image_ids)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"augs = [np.fliplr, np.flipud, np.rot90] # List of augmentations to be applied to the data\ndef augment(images, labels, augs):\n    \"\"\"\n    Apply data augmentation to all training images\n    To tackle class imbalance, apply one of the augmentations ( Randomly chosen )\n    to each image having label 1, and apply all transformations to image having\n    label 0.\n    \"\"\"\n    all_images = list()\n    all_labels = list()\n    for i,image in tqdm_notebook(enumerate(images)):\n        all_images.append(image)\n        cur_label = labels[i]\n        all_labels.append(cur_label)\n        if cur_label == 1:\n            all_images.append(augs[random.randint(0,2)](image))\n            all_labels.append(cur_label)\n        else:\n            for aug in augs:\n                all_labels.append(cur_label)\n                all_images.append(aug(image))\n    \n    return np.stack(all_images), np.array(all_labels)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# \nnormalized_train_images, final_training_labels = augment(normalized_images, np.array(training_labels), augs)\nNUM_TRAIN_IMAGES = int(0.75 * normalized_train_images.shape[0])\nindices = np.random.permutation(normalized_train_images.shape[0])\ntraining_idx, val_idx = indices[:NUM_TRAIN_IMAGES], indices[NUM_TRAIN_IMAGES:]\ntrain_data = normalized_train_images[training_idx,:]\ntrain_labels = np.array(final_training_labels)[training_idx]\n\nval_data = normalized_train_images[val_idx,:]\nval_labels = final_training_labels[val_idx]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_images_horizontally(images, labels=[], lookup_label=None,\n                            figsize=(15, 30)):\n    \"\"\"\n    Utility function to show images\n    \"\"\"\n\n    import matplotlib.pyplot as plt\n    from matplotlib.pyplot import figure, imshow, axis\n    print(labels[0])\n    fig = figure(figsize=figsize)\n    for i in range(images.shape[0]):\n        fig.add_subplot(1, images.shape[0], i + 1)\n        if lookup_label:\n            plt.title(lookup_label[labels[i]])\n        imshow(images[i])\n        axis('off')\nprint(final_training_labels[:30])\n\nshow_images_horizontally(normalized_train_images[10:20], np.array(final_training_labels[10:20]), lookup_label={1:\"has_cactus\", 0: \"no_cactus\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_weights(shape):\n  \"\"\"\n  Weights initializer\n  \"\"\"\n  initializer = tf.contrib.layers.xavier_initializer()\n  return tf.Variable(initializer(shape=shape))\n  \ndef get_biases(length):\n    \"\"\"\n    Initializing bias\n    \"\"\"\n    return tf.Variable(tf.constant(0.0005, shape=[length]))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def conv_layer(input, in_channels, filter_size, num_filters):\n    \"\"\"\n    Apply convolution operation to the image\n    \"\"\"\n    shape = [filter_size, filter_size, in_channels, num_filters]\n    weights = get_weights(shape)\n    bias = get_biases(num_filters)\n    layer = tf.nn.convolution(input,\n    weights,\n    strides=[1,1], dilation_rate=[1,1], \n    padding=\"SAME\")\n    layer= tf.nn.bias_add(layer, bias)\n    new_layer = tf.nn.relu(layer)\n    print(new_layer)\n    return new_layer, weights\n\n\ndef flatten(input_tensor):\n    \"\"\"\n    Flattens input tensor\n    \"\"\"\n    layer_shape = input_tensor.get_shape()\n    total_elements = layer_shape[1:4].num_elements()\n    layer = tf.reshape(input_tensor, [-1, total_elements])\n    return layer, total_elements\n\n\ndef fc_layer(input, in_features, out_features):\n  \"\"\"\n  Create fully connected layer\n  \"\"\"\n  weight = get_weights([in_features, out_features])\n  bias = get_biases(out_features)\n  layer = tf.matmul(input, weight) + bias\n  return layer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_image = tf.placeholder(name=\"input\", shape=(None, 32, 32, 3), dtype=tf.float32)\nlabels = tf.placeholder(name=\"labels\", shape=(None), dtype=tf.int64)\n# input_image = tf.cast(input_image, tf.float32)\n\n\nwith tf.variable_scope(\"block1_conv1\"):\n  layer_conv1, weights_1 = conv_layer(input_image, 3, 3, 32)\nwith tf.variable_scope(\"block1_conv2\"):\n  layer_conv2, weights_2 = conv_layer(layer_conv1, 32, 3, 32)\n#   layer_output_pool = tf.nn.max_pool(layer_conv2, ksize = [1,2,2,1], strides = [1,1,1,1],padding = \"SAME\")\nwith tf.variable_scope(\"block2_conv1\"):\n  layer_conv3, weights_3 = conv_layer(layer_conv2, 32, 3, 64)\nwith tf.variable_scope(\"block2_conv2\"):\n  layer_conv4, weights_4 = conv_layer(layer_conv3, 64, 3, 64)\n  layer_output_pool = tf.nn.max_pool(layer_conv4, ksize = [1,4,4,1], strides = [1,2,2,1], padding = \"VALID\")\n\nwith tf.variable_scope(\"block3_conv1\"):\n  layer_conv4, weights_4 = conv_layer(layer_output_pool, 64, 3, 128)\nwith tf.variable_scope(\"block3_conv2\"):\n  layer_conv5, weights_5 = conv_layer(layer_conv4, 128, 3, 128)\nwith tf.variable_scope(\"block3_conv3\"):\n  layer_conv6, weights_6 = conv_layer(layer_conv5, 128, 3, 128)\n  layer_output_pool = tf.nn.max_pool(layer_conv6, ksize = [1,4,4,1], strides = [1,2,2,1], padding = \"VALID\")\nprint(layer_output_pool, layer_conv4)\nflattened_layer, in_features = flatten(layer_output_pool)\nfclyr = fc_layer(flattened_layer, in_features, 128)\nfc_layer2 = tf.nn.relu(fclyr)\n\nfinal_layer = fc_layer(fc_layer2, 128, 2)\ny_pred = tf.nn.softmax(final_layer)\ncross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=final_layer,\n                                                        labels=tf.one_hot(labels,2))\ncost = tf.reduce_mean(cross_entropy)\noptimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\ngpu_options = tf.GPUOptions(allow_growth=True)\nconfig = tf.ConfigProto(gpu_options=gpu_options)\ninit=tf.global_variables_initializer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nsess = tf.Session(config = config)\nNUM_ITERATIONS = 20\nBATCH = 32\nsess.run(init)\nfor i in tqdm_notebook(range(NUM_ITERATIONS)):\n    num_batches = int(train_data.shape[0] / BATCH) + 1\n    losses = list()\n    epoch_predictions = list()\n    for j in tqdm_notebook(range(num_batches)):\n        batch_labels = train_labels[BATCH*j: BATCH*j + BATCH].astype(np.int64)\n        batch_data = train_data[BATCH*j: BATCH*j + BATCH]\n        loss, _, probabilities = sess.run([cost, optimizer, y_pred], feed_dict={input_image:batch_data, labels:batch_labels})\n        predictions = np.argmax(probabilities, axis=1)\n        epoch_predictions.extend(predictions)\n        losses.append(loss)\n    print(\"EPOCH \" + str(i))\n    epoch_predictions = np.array(epoch_predictions)\n    train_loss = np.mean(np.array(losses))\n    train_accuracy = (np.sum(epoch_predictions==train_labels) / train_labels.shape[0]) * 100\n    num_batches = int(val_data.shape[0] / BATCH) + 1\n    val_predictions = list()\n    for j in range(num_batches):\n        batch_data = val_data[BATCH*j: BATCH*j + BATCH]\n        batch_labels = val_labels[BATCH*j: BATCH*j + BATCH].astype(np.int64)\n        loss, _, probabilities = sess.run([cost, optimizer, y_pred], feed_dict={input_image:batch_data, labels:batch_labels})\n        predictions = np.argmax(probabilities, axis=1)\n        val_predictions.extend(predictions)\n        losses.append(loss)\n    val_accuracy = (np.sum(val_predictions==val_labels) / val_labels.shape[0]) * 100\n    print(\"Loss after Epoch - %f, Train Accuracy - %f, Val Accuracy - %f\" % (train_loss, train_accuracy, val_accuracy))\n        \n        \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds = list()\nnum_batches = int(normalized_test_images.shape[0] / BATCH) + 1\nfor j in range(num_batches):\n    batch_data = normalized_test_images[BATCH*j: BATCH*j + BATCH]\n    batch_labels = test_labels[BATCH*j: BATCH*j + BATCH].astype(np.int64)\n    probabilities = sess.run(y_pred, feed_dict={input_image:batch_data, labels:batch_labels})\n    predictions = np.argmax(probabilities, axis=1)\n    test_preds.extend(predictions)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df = test_df\nsubmission_df['has_cactus'] = np.array(test_preds)\nsubmission_df.to_csv(\"submissions.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# tf.reset_default_graph()\n\n# from keras.models import Sequential\n# from keras.layers import Dense, Dropout, Flatten\n# from keras.layers import Conv2D, MaxPooling2D","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model = Sequential()\n# model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(32,32,3)))\n# model.add(Conv2D(32, kernel_size=(3, 3),activation='relu'))\n# model.add(Conv2D(64, kernel_size=(3, 3),activation='relu'))\n# model.add(Conv2D(64, kernel_size=(3, 3),activation='relu'))\n# model.add(MaxPooling2D(pool_size=(2, 2)))\n# model.add(Conv2D(128, kernel_size=(3, 3),activation='relu'))          \n# model.add(Conv2D(128, kernel_size=(3, 3),activation='relu'))\n# model.add(Conv2D(128, kernel_size=(3, 3),activation='relu'))\n# model.add(MaxPooling2D(pool_size=(2, 2)))\n# model.add(Flatten())\n# model.add(Dense(128, activation='relu'))\n# model.add(Dense(2, activation='softmax'))\n# model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(train_data.shape)\n# print(train_labels.shape)\n# history=model.fit(train_data, np.eye(2)[train_labels], epochs=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Validation data accuract\n# scores = model.evaluate(val_data, np.eye(2)[np.array(val_labels, dtype=np.int64)], verbose=0)\n# print(\"Val Accuracy:\"+\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predictions = model.predict_classes(normalized_test_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# submission_df = test_df\n# submission_df['has_cactus'] = predictions\n# submission_df.to_csv(\"submissions.csv\",index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}