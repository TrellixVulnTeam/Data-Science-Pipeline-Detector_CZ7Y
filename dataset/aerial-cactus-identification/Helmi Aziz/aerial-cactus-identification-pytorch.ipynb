{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Jalankan Notebook dengan Colab**","metadata":{}},{"cell_type":"markdown","source":"**1. Mengunduh dataset dari Kaggle**\n\n(Khusus jika dijalankan dengan Google Colab) Sebelum menjalankan perintah di bawah, pastikan API token `kaggle.json` anda telah diunggah ke folder `content` di Google Colab.\n\nJika ingin dijalankan di local computer, tidak perlu menjalankan perintah di bawah. Dataset dapat diunduh secara manual dari [Aerial Cactus Identification](https://www.kaggle.com/c/aerial-cactus-identification/data) di Kaggle.\n","metadata":{"id":"FVpm5AiVj5Mr"}},{"cell_type":"code","source":"train_on = 'kaggle'\nif train_on == 'colab':\n    ! KAGGLE_CONFIG_DIR=/content/ kaggle competitions download -c aerial-cactus-identification","metadata":{"id":"QNVTeSPOWh_W","outputId":"d0217585-4182-4760-84a4-245a83311c52","execution":{"iopub.status.busy":"2021-12-08T10:21:00.372089Z","iopub.execute_input":"2021-12-08T10:21:00.372438Z","iopub.status.idle":"2021-12-08T10:21:00.377455Z","shell.execute_reply.started":"2021-12-08T10:21:00.372387Z","shell.execute_reply":"2021-12-08T10:21:00.376923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**2. Mengimpor *library* yang diperlukan**\n\nSetidaknya untuk pemodelan ini diperlukan *library* `PIL`, `zipfile`, `os`, `pandas`, `matplotlib`, `sklearn`, dan yang paling utama yaitu torch dan `torchvision`.\n\n","metadata":{"id":"FrofB4r1lVpA"}},{"cell_type":"code","source":"import PIL\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision.transforms as transforms\nimport zipfile\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom sklearn.model_selection import train_test_split","metadata":{"id":"A-U_qo2HT6VA","execution":{"iopub.status.busy":"2021-12-08T10:21:00.378924Z","iopub.execute_input":"2021-12-08T10:21:00.379591Z","iopub.status.idle":"2021-12-08T10:21:02.562171Z","shell.execute_reply.started":"2021-12-08T10:21:00.379552Z","shell.execute_reply":"2021-12-08T10:21:02.56143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**3. Mempersiapkan data**\n\nDataset yang telah diunduh kemudian dibuka, dibedah isinya menggunakan EDA sederhana, lalu untuk dataset dari `train.zip` dipisah *label*-nya menjadi dataset untuk pelatihan dan validasi menggunakan `sklearn` dengan rasio 4:1. Selanjutnya seluruh dataset yang awalnya berupa gambar diubah menjadi tensor, diselaraskan dengan setiap label yang tepat, kemudian dipersiapkan menggunakan `DataLoader` dengan tiap-tiap datanya dikelompokkan menjadi beberapa *batch* dengan ukuran tertentu. ","metadata":{"id":"UrWebAnJmUEh"}},{"cell_type":"code","source":"def unzip(path, extract_folder):\n    with zipfile.ZipFile(path,'r') as zip_ref:\n        zip_ref.extractall(extract_folder)\n\ncwd = os.getcwd()\nextract_folder = cwd+'/content'\n\ntrain_zip = '../input/aerial-cactus-identification/train.zip'\nunzip(train_zip, extract_folder)\ntest_zip = '../input/aerial-cactus-identification/test.zip'\nunzip(test_zip, extract_folder)\n    \nfor dirname, _, filenames in os.walk(extract_folder):\n    for filename in filenames[:5]:\n        print(os.path.join(dirname, filename))","metadata":{"id":"bMimnMR5ZvJF","outputId":"ddf36314-4498-48d4-8943-6a02b491a9b2","execution":{"iopub.status.busy":"2021-12-08T10:21:02.56321Z","iopub.execute_input":"2021-12-08T10:21:02.563417Z","iopub.status.idle":"2021-12-08T10:21:05.629994Z","shell.execute_reply.started":"2021-12-08T10:21:02.56339Z","shell.execute_reply":"2021-12-08T10:21:05.62922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels_path = \"../input/aerial-cactus-identification/train.csv\"\ntrain_label = pd.read_csv(train_labels_path)\n\nlabel = 'Without cactus', 'With cactus'\nplt.figure(figsize = (8,8))\nplt.title('Ð¡lass Distribution for Training Labels')\nplt.pie(train_label.groupby('has_cactus').size(), labels = label, autopct='%1.1f%%')\nplt.show()","metadata":{"id":"eLn6dxNTco9F","outputId":"e2b914e1-619c-43cb-a4a6-a8e1e42f581e","execution":{"iopub.status.busy":"2021-12-08T10:21:05.630934Z","iopub.execute_input":"2021-12-08T10:21:05.631121Z","iopub.status.idle":"2021-12-08T10:21:05.79478Z","shell.execute_reply.started":"2021-12-08T10:21:05.631098Z","shell.execute_reply":"2021-12-08T10:21:05.794041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_label.head()","metadata":{"id":"kDPMFCbK3P05","outputId":"85e4d4b9-8063-4d10-a77c-6e4439311625","execution":{"iopub.status.busy":"2021-12-08T10:21:05.796797Z","iopub.execute_input":"2021-12-08T10:21:05.797011Z","iopub.status.idle":"2021-12-08T10:21:05.80736Z","shell.execute_reply.started":"2021-12-08T10:21:05.796984Z","shell.execute_reply":"2021-12-08T10:21:05.80687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_labels_path = \"../input/aerial-cactus-identification/sample_submission.csv\" \ntest_label = pd.read_csv(test_labels_path)\ntest_label.head()","metadata":{"id":"orxrZ1kzsGPB","outputId":"a11c2fad-b7ec-4c1c-f7a7-7aaf103fc4c0","execution":{"iopub.status.busy":"2021-12-08T10:52:39.884533Z","iopub.execute_input":"2021-12-08T10:52:39.884831Z","iopub.status.idle":"2021-12-08T10:52:39.906512Z","shell.execute_reply.started":"2021-12-08T10:52:39.884794Z","shell.execute_reply":"2021-12-08T10:52:39.90588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_path = extract_folder+'/train'\ntest_path = extract_folder+'/test'","metadata":{"id":"w82iniv25BGz","execution":{"iopub.status.busy":"2021-12-08T10:21:05.829914Z","iopub.execute_input":"2021-12-08T10:21:05.8302Z","iopub.status.idle":"2021-12-08T10:21:05.834121Z","shell.execute_reply.started":"2021-12-08T10:21:05.830163Z","shell.execute_reply":"2021-12-08T10:21:05.833316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_label, validation_label = train_test_split(train_label, \n                                test_size=0.2,\n                                stratify=train_label['has_cactus'],\n                                random_state=10)","metadata":{"id":"vNfEb_gLWIbf","execution":{"iopub.status.busy":"2021-12-08T10:21:05.835131Z","iopub.execute_input":"2021-12-08T10:21:05.835338Z","iopub.status.idle":"2021-12-08T10:21:05.860531Z","shell.execute_reply.started":"2021-12-08T10:21:05.835306Z","shell.execute_reply":"2021-12-08T10:21:05.85995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_size = len(training_label)\nvalid_size = len(validation_label)\ntest_size = len(os.listdir(test_path))\n\nprint('There are {} many images in all folders'.format(len(os.listdir(training_path))+test_size))\nprint('There are {} many images to train with'.format(train_size))\nprint('There are {} many images to do validation testing with'.format(valid_size))\nprint('There are {} many images to test with'.format(test_size))","metadata":{"id":"hjssN56RLvxO","outputId":"95b896ce-65db-40ad-c60e-5cbb47d3496b","execution":{"iopub.status.busy":"2021-12-08T10:21:05.861751Z","iopub.execute_input":"2021-12-08T10:21:05.862205Z","iopub.status.idle":"2021-12-08T10:21:05.884287Z","shell.execute_reply.started":"2021-12-08T10:21:05.86216Z","shell.execute_reply":"2021-12-08T10:21:05.883577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CactusDataset(Dataset):\n    def __init__(self,labels,folder,transform=None):\n        super().__init__()\n        self.labels=labels.values\n        self.folder=folder\n        self.transform=transform\n        \n    def __len__(self):\n        return len(self.labels)\n    \n    def __getitem__ (self,index):\n        image_name,label=self.labels[index]\n        image_path=os.path.join(self.folder,image_name)\n        image=PIL.Image.open(image_path).convert('RGB')\n        if self.transform is not None:\n            image=self.transform(image)\n        return image,label","metadata":{"id":"us0VAhUNwH1m","execution":{"iopub.status.busy":"2021-12-08T10:21:05.885176Z","iopub.execute_input":"2021-12-08T10:21:05.885423Z","iopub.status.idle":"2021-12-08T10:21:05.891192Z","shell.execute_reply.started":"2021-12-08T10:21:05.885396Z","shell.execute_reply":"2021-12-08T10:21:05.890665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 512\ntransform = transforms.Compose([transforms.ToTensor()])\n\ntrain_dataset = CactusDataset(labels=training_label, folder=training_path, transform=transform)\ntrain_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle=True, num_workers=0)\nvalid_dataset = CactusDataset(labels=validation_label, folder=training_path, transform=transform)\nvalid_loader = DataLoader(dataset = valid_dataset, batch_size = batch_size, shuffle=True, num_workers=0)\ntest_dataset = CactusDataset(labels=test_label, folder=test_path, transform=transform)\ntest_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle=False, num_workers=0)","metadata":{"id":"ox7nGtP5wLIr","execution":{"iopub.status.busy":"2021-12-08T10:21:05.891981Z","iopub.execute_input":"2021-12-08T10:21:05.892452Z","iopub.status.idle":"2021-12-08T10:21:05.903519Z","shell.execute_reply.started":"2021-12-08T10:21:05.892423Z","shell.execute_reply":"2021-12-08T10:21:05.902825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**4. Perancangan arsitektur *convolutional neural network* (CNN) serta penentuan metode optimisasi dan *loss function***\n\nUntuk kasus ini, digunakan *convolutional neural network* dengan empat kali konvolusi. Metode optimisasi yang digunakan adalah *Adam* dengan *learning rate* $0.001$ dan *loss function* yang dipilih adalah *binary crossentropy*.","metadata":{"id":"Er-wDSgBnsCc"}},{"cell_type":"code","source":"class SimpleCNN(nn.Module): \n    def __init__(self):\n        super(SimpleCNN, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 16, kernel_size = 3, padding = 1)\n        self.conv2 = nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size = 3, padding = 1)\n        self.conv3 = nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 3, padding = 1)\n        self.conv4 = nn.Conv2d(in_channels = 64, out_channels = 512, kernel_size = 3, padding = 1)\n        self.pool = nn.MaxPool2d(kernel_size = (2, 2)) \n        self.fc1 = nn.Linear(2048, 128)\n        self.fc2 = nn.Linear(128, 1)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = self.pool(F.relu(self.conv3(x)))\n        x = self.pool(F.relu(self.conv4(x)))\n        x = torch.flatten(x, 1)\n        x = torch.relu(self.fc1(x))\n        x = torch.sigmoid(self.fc2(x))\n        return x","metadata":{"id":"pr1Jethv1bUK","execution":{"iopub.status.busy":"2021-12-08T10:21:05.904357Z","iopub.execute_input":"2021-12-08T10:21:05.904526Z","iopub.status.idle":"2021-12-08T10:21:05.91531Z","shell.execute_reply.started":"2021-12-08T10:21:05.904504Z","shell.execute_reply":"2021-12-08T10:21:05.914684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = SimpleCNN()\nprint(model)","metadata":{"id":"6nngF1A82VGZ","outputId":"84d421ce-8c8c-4cd8-fdbe-e6a1f8629be8","execution":{"iopub.status.busy":"2021-12-08T10:21:05.917206Z","iopub.execute_input":"2021-12-08T10:21:05.917408Z","iopub.status.idle":"2021-12-08T10:21:05.961071Z","shell.execute_reply.started":"2021-12-08T10:21:05.917383Z","shell.execute_reply":"2021-12-08T10:21:05.960291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Pelatihan dapat dibantu dengan GPU NVidia CUDA atau murni menggunakan CPU. Perintah berikut digunakan untuk mengaktivasi GPU supaya dapat mempercepat pelatihan.","metadata":{"id":"pPqFRRmHqk_r"}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n#device = torch.device(\"cpu\")\ndevice","metadata":{"id":"D-St5DxB5_j2","outputId":"a072d9a6-cc0f-4a18-dfe7-6a652a753b13","execution":{"iopub.status.busy":"2021-12-08T10:21:05.962052Z","iopub.execute_input":"2021-12-08T10:21:05.962254Z","iopub.status.idle":"2021-12-08T10:21:05.968746Z","shell.execute_reply.started":"2021-12-08T10:21:05.962229Z","shell.execute_reply":"2021-12-08T10:21:05.967974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"net = SimpleCNN().to(device)\noptimizer = optim.Adam(net.parameters(), lr=0.001)\ncriterion = nn.BCELoss()","metadata":{"id":"HatmAl6ErXAJ","execution":{"iopub.status.busy":"2021-12-08T10:21:05.970228Z","iopub.execute_input":"2021-12-08T10:21:05.970619Z","iopub.status.idle":"2021-12-08T10:21:05.989514Z","shell.execute_reply.started":"2021-12-08T10:21:05.970584Z","shell.execute_reply":"2021-12-08T10:21:05.988984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**5. Pelatihan *neural network***\n\nPerintah di bawah digunakan untuk melatih *neural network* yang telah dibentuk sebelumnya sebanyak $100$ kali pelatihan untuk mendapatkan bobot yang sesuai. Tetapi untuk berjaga-jaga, ditetapkan *early stopping* yang aktif ketika akurasi pelatihan dan akurasi validasi mencapai lebih dari $0.99$.","metadata":{"id":"OloG_TKLrGUc"}},{"cell_type":"code","source":"epochs = 100\nprint('Start training\\n')\nfor epoch in range(epochs): \n    epoch_loss = 0.0\n    true_positive = 0\n    true_negative = 0\n    false_positive = 0\n    false_negative = 0\n    for images, labels in train_loader:\n        optimizer.zero_grad()\n\n        images = images.to(device)\n        labels_amount = len(labels)\n        labels = labels.float()\n        labels = labels.resize_(labels_amount, 1)\n        labels = labels.to(device)\n\n        outputs = net(images)\n        loss = criterion(outputs, labels)\n\n        loss.backward()\n        optimizer.step()\n\n        batch_size = outputs.shape[0]\n        epoch_loss += loss.item()*batch_size/train_size\n        for i in range(batch_size):\n          if outputs[i][0].item()>=0.5:\n            if labels[i][0].item()>=0.5:\n              true_positive+=1\n            else:\n              false_positive+=1\n          else:\n            if labels[i][0].item()<0.5:\n              true_negative+=1\n            else:\n              false_negative+=1\n\n    with torch.no_grad():\n        val_epoch_loss = 0.0\n        val_true_positive = 0\n        val_true_negative = 0\n        val_false_positive = 0\n        val_false_negative = 0\n        for images, labels in valid_loader:\n            images = images.to(device)\n            labels_amount = len(labels)\n            labels = labels.float()\n            labels = labels.resize_(labels_amount, 1)\n            labels = labels.to(device)\n\n            outputs = net(images)\n            loss = criterion(outputs, labels)\n\n            batch_size = outputs.shape[0]\n            val_epoch_loss += loss.item()*batch_size/valid_size\n            for i in range(batch_size):\n              if outputs[i][0].item()>=0.5:\n                if labels[i][0].item()>=0.5:\n                  val_true_positive+=1\n                else:\n                  val_false_positive+=1\n              else:\n                if labels[i][0].item()<0.5:\n                  val_true_negative+=1\n                else:\n                  val_false_negative+=1\n\n\n    accuracy = (true_positive+true_negative)/(true_positive+true_negative+false_positive+false_negative)\n    precision = true_positive/(true_positive+false_positive)\n    recall = true_positive/(true_positive+false_negative)\n    f1 = 2*(recall * precision) / (recall + precision)\n\n    val_accuracy = (val_true_positive+val_true_negative)/(val_true_positive+val_true_negative+val_false_positive+val_false_negative)\n    val_precision = val_true_positive/(val_true_positive+val_false_positive)\n    val_recall = val_true_positive/(val_true_positive+val_false_negative)\n    val_f1 = 2*(val_recall * val_precision) / (val_recall + val_precision)\n\n    print(\"Epoch {}/{}\".format(epoch+1,epochs))\n    print(\"[Training]   Loss     : {:0.4f}, Accuracy     : {:0.4f}, Precision     : {:0.4f}, Recall     : {:0.4f}, F1 Score     : {:0.4f}\".format(epoch_loss,accuracy, precision,recall,f1))\n    print(\"[Validation] Val Loss : {:0.4f}, Val Accuracy : {:0.4f}, Val Precision : {:0.4f}, Val Recall : {:0.4f}, Val F1 Score : {:0.4f}\\n\".format(val_epoch_loss, val_accuracy, val_precision,val_recall,val_f1))\n    if accuracy >= 0.99:\n      if val_accuracy >= 0.99:\n        break\nprint('Finished training')","metadata":{"id":"KockbIiF2nt5","outputId":"4896935c-2bdc-4f2f-ce10-764f1af3febb","execution":{"iopub.status.busy":"2021-12-08T10:21:05.990805Z","iopub.execute_input":"2021-12-08T10:21:05.991002Z","iopub.status.idle":"2021-12-08T10:39:58.233191Z","shell.execute_reply.started":"2021-12-08T10:21:05.990977Z","shell.execute_reply":"2021-12-08T10:39:58.232528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**6. Pengujian *neural network***\n\n*Neural network* diuji dengan dataset dari `test.zip`, kemudian ditampilkan hasilnya untuk 8 gambar secara acak.","metadata":{"id":"Ahk5ryfvuCea"}},{"cell_type":"code","source":"import random\n\nnrows = 4\nncols = 4\n\npic_index = random.randint(0,test_size-1)\n\nfig = plt.gcf()\nfig.set_size_inches(ncols * 4, nrows * 4)\n\ntrain_human_names = os.listdir(test_path)\ntrain_human_names.sort()\n\nnext_human_pix = [os.path.join(test_path, fname) \n                for fname in train_human_names[pic_index-8:pic_index]]\n\nfor i, img_path in enumerate(next_human_pix):\n  sp = plt.subplot(nrows, ncols, i + 1)\n  sp.axis('Off')\n  img = mpimg.imread(img_path)\n  plt.imshow(img)\n  plt.text(-3, 35, train_human_names[i+pic_index-8])\nplt.show()\n\nwith torch.no_grad():\n  result = []\n  for images, labels in test_loader:\n    images = images.to(device)\n    outputs = net(images)\n    for i in range(outputs.shape[0]):\n      result.append(outputs[i][0].item())\n  \n  for i in range(pic_index-8, pic_index):\n    if result[i]>=0.5:\n      print(\"There's a cactus in {}\".format(test_label['id'][i]))\n    else:\n      print(\"There's no cactus in {}\".format(test_label['id'][i]))","metadata":{"id":"EFsivMY965cM","outputId":"170616dc-ee2c-49b6-d862-d9689e422931","execution":{"iopub.status.busy":"2021-12-08T10:39:58.234304Z","iopub.execute_input":"2021-12-08T10:39:58.234735Z","iopub.status.idle":"2021-12-08T10:40:02.129857Z","shell.execute_reply.started":"2021-12-08T10:39:58.234687Z","shell.execute_reply":"2021-12-08T10:40:02.129192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(test_labels_path)\ndf['has_cactus'] = result\ndf.to_csv('submission.csv',index=False)\ndf.head(15)","metadata":{"execution":{"iopub.status.busy":"2021-12-08T11:12:10.368394Z","iopub.execute_input":"2021-12-08T11:12:10.369166Z","iopub.status.idle":"2021-12-08T11:12:10.404845Z","shell.execute_reply.started":"2021-12-08T11:12:10.369116Z","shell.execute_reply":"2021-12-08T11:12:10.403958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\nshutil.rmtree('/kaggle/working/content/train')\nshutil.rmtree('/kaggle/working/content/test')","metadata":{"execution":{"iopub.status.busy":"2021-12-08T10:55:49.48179Z","iopub.execute_input":"2021-12-08T10:55:49.48219Z","iopub.status.idle":"2021-12-08T10:55:50.145296Z","shell.execute_reply.started":"2021-12-08T10:55:49.482141Z","shell.execute_reply":"2021-12-08T10:55:50.144471Z"},"trusted":true},"execution_count":null,"outputs":[]}]}