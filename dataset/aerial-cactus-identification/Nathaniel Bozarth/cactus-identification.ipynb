{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Importing Libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.utils import to_categorical\nfrom keras.preprocessing import image\n\nfrom sklearn.model_selection import train_test_split\n\nfrom tqdm import tqdm\n\nimport os as os\nos.getcwd()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loading Data\nFirst the labels..."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\n\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"...then the images. \n(This bit I had a horrible time with: evidence that it would do me good to spend some more time practicing for loops and syntactic understanding.)"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_image = []\nfor i in tqdm(range(train.shape[0])):\n    img = image.load_img('../input/train/train/'+ train['id'][i], target_size=(32, 32, 1), \n                         grayscale=False)\n    img = image.img_to_array(img)\n    img = img/255\n    train_image.append(img)\nX = np.array(train_image)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below, creating an object with the outcome variable (1 = image has a cactus in it, 2 = image does not) in it."},{"metadata":{"trusted":true},"cell_type":"code","source":"y=train['has_cactus']\ny = to_categorical(y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Separating the data into a training and testing set."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42,\n                                                   test_size=.33)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#verifying shape of each object\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Defining the model\nThis is a 2-dimensional convolutional neural network created using the Keras library."},{"metadata":{"trusted":true},"cell_type":"code","source":"nn1 = Sequential()\nnn1.add(Conv2D(32, kernel_size=(3, 3), activation='relu', \n               input_shape=(32,32,3)))\nnn1.add(Conv2D(64, (3,3), activation = 'relu'))\nnn1.add(MaxPooling2D(pool_size=(2,2)))\nnn1.add(Dropout(0.25))\nnn1.add(Flatten())\nnn1.add(Dense(128, activation='relu'))\nnn1.add(Dropout(0.5))\nnn1.add(Dense(2, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nn1.compile(loss='categorical_crossentropy',\n            optimizer = 'Adam', metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Training Wheels\nNote that, for the purpose of the Kaggle competition I have separated the provided training data into a training and test set. The test set is really a validation set. \n\nThe true test set is the data for which I have no labels and will be submitting my predictions for the competition."},{"metadata":{"trusted":true},"cell_type":"code","source":"nn1.fit(X_train, y_train, epochs=10, \n        validation_data=(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Evaluation on Validation set (Test set from Training Data)"},{"metadata":{"trusted":true},"cell_type":"code","source":"nn1_score = nn1.evaluate(X_test, y_test, batch_size=128)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Loss ----------------- Accuracy')\nprint(nn1_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nfrom keras.utils import np_utils\n\nnn1_pred = nn1.predict(X_test)\n\nnn1_pred_as_class = nn1_pred.argmax(axis=-1)\ny_test_as_class = y_test.argmax(axis=-1)\n\nprint(classification_report(y_test_as_class, nn1_pred_as_class))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This seems like a really good first result. On the 1 class, the class we're most concerned with, we identified 99% of all cactuses in the data and were correct 100% of the time. In our train_test_split we did a 67% training size and a 33% test size. \n\nBefore I ran this model, I accidentally flipped the train/test split. The model ran better on a larger training size. The precision on the accidental 33% training size was .99 instead of 1. This greater amount of precision was also reflected in the 0-class precision and recall as well (as follows logically)."},{"metadata":{},"cell_type":"markdown","source":"#### Predicting on the Test Data\nIn order to make predictions, we have to import the test images in the same way we did the training images."},{"metadata":{"trusted":true},"cell_type":"code","source":"import glob\nfrom PIL import Image\nfolder = glob.glob('../input/test/test/*.jpg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Z = np.array([np.array(Image.open(img)) for img in folder])\nZ.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = nn1.predict_proba(Z) #This command gives us probability for each class. ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df = pd.DataFrame(sub, columns = ['no_cactus','has_cactus'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now that we've made our prediciton, we need to adjoin the file name for each image.\n\nThis Kaggle competition requires that submissions be made via a CSV with the filename in column 1 and the probability that the image has a cactus in it in column 2. "},{"metadata":{"trusted":true},"cell_type":"code","source":"img_names = os.listdir('../input/test/test/')\n\nsub_df['id'] = img_names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del sub_df['no_cactus'] #We only need the probability that the image does in fact have a cactus\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df = sub_df[['id', 'has_cactus']]\nsub_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We now have a dataframe set up in accordance with the competition rules. "},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df.to_csv('sub_2.csv', index=False) #Creating the CSV for submission","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Honestly it's a good feeling to just get a submission in. But let's run another model just for shits and giggles. \n\n### Second Model\n#### Base MLP \nI want to run a really basic multi-layer perceptron. I don't anticipate that this will perform better, but I'd like to compare as an exploration. \n\nSince MLP takes a 2D list as it's feature list, we'll need to flatten our 32, 32, 2 array. "},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_flat = []\nfor sublist in X_train:\n    for item in sublist:\n        X_train_flat.append(item)\n        \nX_test_flat = []\nfor sublist in X_test:\n    for item in sublist:\n        X_test_flat.append(item)\n        \n#X_train_flat\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_pixels = X_train.flatten().reshape(11725, 3072)\n#these shape sizes are calculated as such: \n    #first number is number of records in array\n    #second number is multiplcation of the subsequent numbers in array, \n            #in this case: 32 * 32 * 3\n\nX_test_pixels = X_test.flatten().reshape(5775, 3072)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Here I'm transforming the target list to a dataframe so I can then delete the list of values for\n#the 0 (no cactus) class. \ny_train_df = pd.DataFrame(y_train, index=y_train[:,0])\ndel y_train_df[0]\ny_train_array = y_train_df.values\n\ny_test_df = pd.DataFrame(y_test, index=y_test[:,0])\ndel y_test_df[0]\ny_test_array = y_test_df.values\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### First go at MLPclassifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import accuracy_score\n\nMLP1 = MLPClassifier(activation='relu', hidden_layer_sizes=(18,9,5), learning_rate='constant',\n       random_state=1, shuffle=True, solver='lbfgs', tol=0.0001, warm_start=False)\nMLP1.fit(X_train_pixels, y_train_array)\nMLP1_preds = MLP1.predict(X_test_pixels)\nprint(\"Accuracy\", accuracy_score(y_test_array, MLP1_preds))\ntarget_names = [\"No Cactus\", \"Cactus\"]\nprint(classification_report(y_test_array, MLP1_preds, target_names=target_names))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As expected, this didn't work nearly as well. We'll go with the original more complicated convolutional neural net.\n\nWhat if we grid search for better parameters?"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"I tried to run the below grid search for the best number of layers/nodes. I went a little bonkers on number of nodes, however. After 5 hours, the model was still running. For this reason, I abandoned ship.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nfrom sklearn.model_selection import GridSearchCV\nimport time\nstart_time = time.clock()\nparameters = {'hidden_layer_sizes':[(1500, 1500, 1500), (1500, 800, 400), (500, 500, 500)]}\nMLP2 = MLPClassifier(activation='relu', learning_rate='constant', random_state=1, solver='adam')\ngrid_MLP2 = GridSearchCV(MLP2, parameters, n_jobs=-1, cv=5)\ngrid_MLP2.fit(X_train_pixels, y_train_array)\nprint(\"BEST PARAM\", MLP2.best_params_)\nprint(\"Time to run\", time.clock() - start_time, \"seconds\")\n'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Something a little more conservative...."},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import accuracy_score\nimport time\nstart_time = time.clock()\nparameters = {\n    'activation': ['tanh', 'relu'],\n    'solver': ['sgd', 'adam'],\n    'alpha': [0.0001, 0.05],\n    'learning_rate': ['constant','adaptive']}\nMLP3 = MLPClassifier(hidden_layer_sizes = (30, 50, 30), random_state=1)\ngrid_MLP3 = GridSearchCV(MLP3, parameters, n_jobs=-1, cv=5)\ngrid_MLP3.fit(X_train_pixels, y_train_array)\nprint(\"BEST PARAM\", MLP3.best_params_)\nprint(\"Time to run\", time.clock() - start_time, \"seconds\")\n'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above was still taking a very long time. Let's forget the grid search and just try switching some parametrs. "},{"metadata":{},"cell_type":"markdown","source":"#### MLPClassifier 2"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nMLP2 = MLPClassifier(activation='relu', hidden_layer_sizes=(50, 30, 50), learning_rate='constant',\n       random_state=1, shuffle=True, solver='adam', tol=0.0001, warm_start=False)\nMLP2.fit(X_train_pixels, y_train_array)\nMLP2_preds = MLP2.predict(X_test_pixels)\nprint(\"Accuracy\", accuracy_score(y_test_array, MLP2_preds))\ntarget_names = [\"No Cactus\", \"Cactus\"]\nprint(classification_report(y_test_array, MLP2_preds, target_names=target_names))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Overall, this new model actually improved inferior to our first first instance of MLP. I was somewhat unscientific, however, because I changed more than one parameter. I'm going to run the model again, reverting to the parametrs of the first model except for the node and layers. \n"},{"metadata":{},"cell_type":"markdown","source":"#### MLPClassifier 3"},{"metadata":{"trusted":true},"cell_type":"code","source":"MLP3 = MLPClassifier(activation='relu', hidden_layer_sizes=(50, 30, 30), learning_rate='constant',\n       random_state=1, shuffle=True, solver='lbfgs', tol=0.0001, warm_start=False)\nMLP3.fit(X_train_pixels, y_train_array)\nMLP3_preds = MLP3.predict(X_test_pixels)\nprint(\"Accuracy\", accuracy_score(y_test_array, MLP3_preds))\ntarget_names = [\"No Cactus\", \"Cactus\"]\nprint(classification_report(y_test_array, MLP3_preds, target_names=target_names))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This model performs marginally better than our first MLP classifier. It is still much inferior to the convolutional neural network. "},{"metadata":{},"cell_type":"markdown","source":"#### MLPClassifier 4"},{"metadata":{"trusted":true},"cell_type":"code","source":"''''''\nMLP4 = MLPClassifier(activation='relu', hidden_layer_sizes=(50, 30, 30, 30), learning_rate='constant',\n       random_state=1, shuffle=True, solver='lbfgs', tol=0.0001, warm_start=False)\nMLP4.fit(X_train_pixels, y_train_array)\nMLP4_preds = MLP3.predict(X_test_pixels)\nprint(\"Accuracy\", accuracy_score(y_test_array, MLP4_preds))\ntarget_names = [\"No Cactus\", \"Cactus\"]\nprint(classification_report(y_test_array, MLP4_preds, target_names=target_names))\n''''''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this run I added a fourth hidden layer with 30 nodes. This had exactly no difference in performance from the previous iteration. To cut down on processing time, I've commented out the code. \n\n### Conclusion\nThe internet can provide some great things! I found the code for the convolutional neural network on from a page called Analytics Vidhya. The model was tweaked to fit the data. It outperformed my from-scratch MLP by a long shot. In the future, I'd like to learn more about CNN so that I can improve my skills at tuning. For the purpose of this submit and this final project, however, I'm out. "}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}