{"cells":[{"metadata":{},"cell_type":"markdown","source":"# read README file first","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# everything is here\n\n# https://github.com/chiragp007/Object-detction-With-TensorFlow","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import pandas as pd\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport numpy as np\nimport cv2\nimport os\nimport re","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"path_train_csv=\"/home/chirag/Downloads/Kaggle_project/train.csv\"\nimg_dir_all_data=\"/home/chirag/Downloads/Kaggle_project/My_project/train\"\ntrain_df=pd.read_csv(path_train_csv)\n\n\ndef split_Bbox(value):\n    reg = np.array(re.findall(\"([0-9]+[.]?[0-9]*)\", value))\n    if len(reg) == 0:\n        reg = [-1, -1, -1, -1]\n        print(reg)\n    return reg\n\ndef csv_manipulation_and_filtering(df):\n    df['xmin'] = 0\n    df['ymin'] = 0\n    df['xmax'] = 0\n    df['ymax'] = 0\n    df[\"width\"]=600\n    df[\"height\"]=600\n    \n    df=df.rename(columns={\"image_id\": \"filename\"})\n    df=df.rename(columns={\"source\": \"class\"})\n    df[['xmin', 'ymin', 'xmax', 'ymax']] = np.stack(df['bbox'].apply(lambda value: split_Bbox(value)))\n    df.drop(columns=['bbox'], inplace=True)\n        \n    df['class']= \"wheat_head_detected\"\n    df[\"filename\"]=df['filename'].astype(str)+'.jpg'\n    \n    df['xmin'] = df['xmin'].astype(np.float)\n    df['ymin'] = df['ymin'].astype(np.float)\n    df['xmax'] = df['xmax'].astype(np.float)\n    df['ymax'] = df['ymax'].astype(np.float)\n    df['xmax']=df['xmin']+df['xmax']\n    df['ymax']=df['ymin']+df['ymax']\n  \n        \n    return df\n\n\ndf=csv_manipulation_and_filtering(train_df)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"## code for finding images which do not have BBOXs ## \n\nuniq=df[\"filename\"].unique()\nfrom PIL import Image\nimport glob\nfileList = []\ncount=0\nfor root, dirs, files in os.walk(img_dir_all_data, topdown=False):\n    for name in files:\n        if name.endswith('.jpg'):\n            name_of_img=os.path.splitext(name)[0]\n            count+=1\n            if name_of_img not in uniq:\n                fileList.append(name_of_img) \n                \n                \nlen(fileList)   \n\n# REMOVE THESE IMAGES FROM DATASET !!","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import sys\nsys.path.append(\"/home/chirag/Downloads/models-master/research/slim/\")\nfrom object_detection.legacy import train","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test_csv=df[0:47]\ntrain_csv=df[47:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test_csv.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_csv.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_output_path=\"/home/chirag/Downloads/Kaggle_project/My_project/train.record\"\ntest_output_path=\"/home/chirag/Downloads/Kaggle_project/My_project/test.record\"\n\ntest_img_dir=\"/home/chirag/Downloads/Kaggle_project/images/test/\"\n\nfiltered_img_path=\"/home/chirag/Downloads/Kaggle_project/images/train/\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" # Run this script 2 times for creating \"train.record\" and \"test.record\" ","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"#chnage your path , pass train and test dataframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from __future__ import division\nfrom __future__ import print_function\nfrom __future__ import absolute_import\n\nimport os\nimport io\nimport pandas as pd\nimport tensorflow as tf\n\nfrom PIL import Image\nfrom object_detection.utils import dataset_util\nfrom collections import namedtuple, OrderedDict\n\n\ndef class_text_to_int(row_label):\n    if row_label == 'wheat_head_detected':\n        return 1\n    else:\n        None\n\n\ndef split(df, group):\n    data = namedtuple('data', ['filename', 'object'])\n    gb = df.groupby(group)\n    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n\n\ndef create_tf_example(group, path):\n    with tf.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n        encoded_jpg = fid.read()\n    encoded_jpg_io = io.BytesIO(encoded_jpg)\n    image = Image.open(encoded_jpg_io)\n    width, height = image.size\n\n    filename = group.filename.encode('utf8')\n    image_format = b'jpg'\n    xmins = []\n    xmaxs = []\n    ymins = []\n    ymaxs = []\n    classes_text = []\n    classes = []\n\n    for index, row in group.object.iterrows():\n        xmins.append(row['xmin'] / width)\n        xmaxs.append(row['xmax'] / width)\n        ymins.append(row['ymin'] / height)\n        ymaxs.append(row['ymax'] / height)\n        classes_text.append(row['class'].encode('utf8'))\n        classes.append(class_text_to_int(row['class']))\n\n    tf_example = tf.train.Example(features=tf.train.Features(feature={\n        'image/height': dataset_util.int64_feature(height),\n        'image/width': dataset_util.int64_feature(width),\n        'image/filename': dataset_util.bytes_feature(filename),\n        'image/source_id': dataset_util.bytes_feature(filename),\n        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n        'image/format': dataset_util.bytes_feature(image_format),\n        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n        'image/object/class/label': dataset_util.int64_list_feature(classes),\n    }))\n    return tf_example\n\n\ndef main(_):\n    writer = tf.python_io.TFRecordWriter(train_output_path)\n    path = os.path.join(filtered_img_path)\n    \n    examples=train_csv\n    \n    grouped = split(examples, 'filename')\n    \n    for group in grouped:\n        tf_example = create_tf_example(group, path)\n        writer.write(tf_example.SerializeToString())\n\n    writer.close()\n    output_path = os.path.join(train_output_path)\n    print('Successfully created the TFRecords: {}'.format(output_path))\n\n\nif __name__ == '__main__':\n    tf.app.run()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"\nimport functools\nimport json\nimport os\nimport tensorflow as tf\nfrom tensorflow.contrib import framework as contrib_framework\n\nfrom object_detection.builders import dataset_builder\nfrom object_detection.builders import graph_rewriter_builder\nfrom object_detection.builders import model_builder\nfrom object_detection.legacy import trainer\nfrom object_detection.utils import config_util\n\ntf.logging.set_verbosity(tf.logging.INFO)\nflags = tf.app.flags\n\n\nFLAGS = flags.FLAGS\n\n# Create TRAINING folder in dir\n# copy this (faster_rcnn_resnet50_pets.config) and paste in this folder\n# do changes accordingly \n# create  lable.pbtxt file in this folder and put path in \"faster_rcnn_resnet50_pets\"\n# run this Cell and it will create many models in folders, it takes alot of time\n\ntraning_dir=\"/home/Downloads/models-master/research/object_detection/tranining\"\nPipeline_config_path =\"/home/Downloads/models-master/research/object_detection/tranining/faster_rcnn_resnet50_pets.config\"\n\n@contrib_framework.deprecated(None, 'Use object_detection/model_main.py.')\n\ndef main(_):\n  if FLAGS.task == 0: tf.gfile.MakeDirs(traning_dir)\n  if Pipeline_config_path:\n    configs = config_util.get_configs_from_pipeline_file(\n        Pipeline_config_path)\n    if FLAGS.task == 0:\n      tf.gfile.Copy(Pipeline_config_path,\n                    os.path.join(traning_dir, 'pipeline.config'),\n                    overwrite=True)\n  else:\n    configs = config_util.get_configs_from_multiple_files(\n        model_config_path=FLAGS.model_config_path,\n        train_config_path=FLAGS.train_config_path,\n        train_input_config_path=FLAGS.input_config_path)\n    if FLAGS.task == 0:\n      for name, config in [('model.config', FLAGS.model_config_path),\n                           ('train.config', FLAGS.train_config_path),\n                           ('input.config', FLAGS.input_config_path)]:\n        tf.gfile.Copy(config, os.path.join(FLAGS.train_dir, name),\n                      overwrite=True)\n\n  model_config = configs['model']\n  train_config = configs['train_config']\n  input_config = configs['train_input_config']\n\n  model_fn = functools.partial(\n      model_builder.build,\n      model_config=model_config,\n      is_training=True)\n\n  def get_next(config):\n    return dataset_builder.make_initializable_iterator(\n        dataset_builder.build(config)).get_next()\n\n  create_input_dict_fn = functools.partial(get_next, input_config)\n\n  env = json.loads(os.environ.get('TF_CONFIG', '{}'))\n  cluster_data = env.get('cluster', None)\n  cluster = tf.train.ClusterSpec(cluster_data) if cluster_data else None\n  task_data = env.get('task', None) or {'type': 'master', 'index': 0}\n  task_info = type('TaskSpec', (object,), task_data)\n\n  # Parameters for a single worker.\n  ps_tasks = 0\n  worker_replicas = 1\n  worker_job_name = 'lonely_worker'\n  task = 0\n  is_chief = True\n  master = ''\n\n  if cluster_data and 'worker' in cluster_data:\n    # Number of total worker replicas include \"worker\"s and the \"master\".\n    worker_replicas = len(cluster_data['worker']) + 1\n  if cluster_data and 'ps' in cluster_data:\n    ps_tasks = len(cluster_data['ps'])\n\n  if worker_replicas > 1 and ps_tasks < 1:\n    raise ValueError('At least 1 ps task is needed for distributed training.')\n\n  if worker_replicas >= 1 and ps_tasks > 0:\n    # Set up distributed training.\n    server = tf.train.Server(tf.train.ClusterSpec(cluster), protocol='grpc',\n                             job_name=task_info.type,\n                             task_index=task_info.index)\n    if task_info.type == 'ps':\n      server.join()\n      return\n\n    worker_job_name = '%s/task:%d' % (task_info.type, task_info.index)\n    task = task_info.index\n    is_chief = (task_info.type == 'master')\n    master = server.target\n\n  graph_rewriter_fn = None\n  if 'graph_rewriter_config' in configs:\n    graph_rewriter_fn = graph_rewriter_builder.build(\n        configs['graph_rewriter_config'], is_training=True)\n\n  trainer.train(\n      create_input_dict_fn,\n      model_fn,\n      train_config,\n      master,\n      task,\n      FLAGS.num_clones,\n      worker_replicas,\n      FLAGS.clone_on_cpu,\n      ps_tasks,\n      worker_job_name,\n      is_chief,\n      traning_dir,\n      graph_hook_fn=graph_rewriter_fn)\n\n\nif __name__ == '__main__':\n  tf.app.run()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# run this command in terminal","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"# MAKE SURE, YOU ARE IN \"/home/models-master/research/object_detection\"\n# in export_inference_graph.py, don't forget to put \n#                                \"sys.path.append(\"/home/chirag/Downloads/models-master/research/slim/\")\"  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# \"export_inference_graph.py \" download this from my repo","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#  python export_inference_graph.py \n#     --input_type image_tensor \n#     --pipeline_config_path tranining/faster_rcnn_resnet50_pets.config  \n#     --trained_checkpoint_prefix tranining/model.ckpt-4310 \n#     --output_directory inference_graph\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"## NOW YOU WILL HAVE .PB file in \"inference_graph\" folder","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}