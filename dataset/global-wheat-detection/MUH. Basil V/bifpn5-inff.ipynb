{"cells":[{"metadata":{"trusted":true,"id":"q94RznonfsE9","outputId":"e80d6454-0573-421e-b63b-f3432a60c974"},"cell_type":"code","source":"import numpy as np\nfrom keras.models import Sequential\nimport keras\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input,Dense,Activation,ZeroPadding2D,BatchNormalization,Flatten,Conv2D,MaxPool2D,Dropout,Reshape,Add,Conv2DTranspose,Concatenate\nfrom keras.layers import LeakyReLU\nfrom tensorflow.keras.models import Model\nimport tensorflow.keras.backend as K\nfrom keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.models import load_model\nimport cv2\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport matplotlib.patches as patches","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"id":"Fa2ty3TKfsFA"},"cell_type":"code","source":"import tensorflow as tf\n# import tensorflow_addons as tfa\nclass BatchNormalization(tf.keras.layers.BatchNormalization):\n    \"\"\"\n    \"Frozen state\" and \"inference mode\" are two separate concepts.\n    `layer.trainable = False` is to freeze the layer, so the layer will use\n    stored moving `var` and `mean` in the \"inference mode\", and both `gama`\n    and `beta` will not be updated !\n    \"\"\"\n    def call(self, x, training=False):\n        if not training:\n            training = tf.constant(False)\n        training = tf.logical_and(training, self.trainable)\n        return super().call(x, training)\n\ndef convolutional(input_layer, filters_shape, downsample=False, activate=True, bn=True, activate_type='leaky'):\n    if downsample:\n        input_layer = tf.keras.layers.ZeroPadding2D(((1, 0), (1, 0)))(input_layer)\n        padding = 'valid'\n        strides = 2\n    else:\n        strides = 1\n        padding = 'same'\n\n    conv = tf.keras.layers.Conv2D(filters=filters_shape[-1], kernel_size = filters_shape[0], strides=strides, padding=padding,\n                                  use_bias=not bn, kernel_regularizer=tf.keras.regularizers.l2(0.0005),\n                                  kernel_initializer=tf.random_normal_initializer(stddev=0.01),\n                                  bias_initializer=tf.constant_initializer(0.))(input_layer)\n\n    if bn: conv = BatchNormalization()(conv)\n    if activate == True:\n        if activate_type == \"leaky\":\n            conv = tf.nn.leaky_relu(conv, alpha=0.1)\n        elif activate_type == \"mish\":\n            conv = mish(conv)\n            # conv = softplus(conv)\n            # conv = conv * tf.math.tanh(tf.math.softplus(conv))\n            # conv = conv * tf.tanh(softplus(conv))\n            # conv = tf.nn.leaky_relu(conv, alpha=0.1)\n            # conv = tfa.activations.mish(conv)\n            # conv = conv * tf.nn.tanh(tf.keras.activations.relu(tf.nn.softplus(conv), max_value=20))\n            # conv = tf.nn.softplus(conv)\n            # conv = tf.keras.activations.relu(tf.nn.softplus(conv), max_value=20)\n\n    return conv\ndef softplus(x, threshold = 20.):\n    def f1():\n        return x\n    def f2():\n        return tf.exp(x)\n    def f3():\n        return tf.math.log(1 + tf.exp(x))\n    # mask = tf.greater(x, threshold)\n    # x = tf.exp(x[mask])\n    # return tf.exp(x)\n    return tf.case([(tf.greater(x, tf.constant(threshold)), lambda:f1()), (tf.less(x, tf.constant(-threshold)), lambda:f2())], default=lambda:f3())\n    # return tf.case([(tf.greater(x, threshold), lambda:f1())])\ndef mish(x):\n    return tf.keras.layers.Lambda(lambda x: x*tf.tanh(tf.math.log(1+tf.exp(x))))(x)\n    # return tf.keras.layers.Lambda(lambda x: softplus(x))(x)\n    # return tf.keras.layers.Lambda(lambda x: x * tf.tanh(softplus(x)))(x)\n\ndef residual_block(input_layer, input_channel, filter_num1, filter_num2, activate_type='leaky'):\n    short_cut = input_layer\n    conv = convolutional(input_layer, filters_shape=(1, 1, input_channel, filter_num1), activate_type=activate_type)\n    conv = convolutional(conv       , filters_shape=(3, 3, filter_num1,   filter_num2), activate_type=activate_type)\n\n    residual_output = short_cut + conv\n    return residual_output\n\n# def block_tiny(input_layer, input_channel, filter_num1, activate_type='leaky'):\n#     conv = convolutional(input_layer, filters_shape=(3, 3, input_channel, filter_num1), activate_type=activate_type)\n#     short_cut = input_layer\n#     conv = convolutional(conv, filters_shape=(3, 3, input_channel, filter_num1), activate_type=activate_type)\n#\n#     input_data = tf.concat([conv, short_cut], axis=-1)\n#     return residual_output\n\ndef route_group(input_layer, groups, group_id):\n    convs = tf.split(input_layer, num_or_size_splits=groups, axis=-1)\n    return convs[group_id]\n\ndef upsample(input_layer):\n    return tf.image.resize(input_layer, (input_layer.shape[1] * 2, input_layer.shape[2] * 2), method='bilinear')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"rQ0OcoeXfsFE"},"cell_type":"code","source":"def cspdarknet53(input_data):\n\n    input_data = convolutional(input_data, (3, 3,  3,  32), activate_type=\"mish\")\n    input_data = convolutional(input_data, (3, 3, 32,  64), downsample=True, activate_type=\"mish\")\n\n    route = input_data\n    route = convolutional(route, (1, 1, 64, 64), activate_type=\"mish\")\n    input_data = convolutional(input_data, (1, 1, 64, 64), activate_type=\"mish\")\n    for i in range(1):\n        input_data = residual_block(input_data,  64,  32, 64, activate_type=\"mish\")\n    input_data = convolutional(input_data, (1, 1, 64, 64), activate_type=\"mish\")\n\n    input_data = tf.concat([input_data, route], axis=-1)\n    input_data = convolutional(input_data, (1, 1, 128, 64), activate_type=\"mish\")\n    input_data = convolutional(input_data, (3, 3, 64, 128), downsample=True, activate_type=\"mish\")\n    route = input_data\n    route = convolutional(route, (1, 1, 128, 64), activate_type=\"mish\")\n    input_data = convolutional(input_data, (1, 1, 128, 64), activate_type=\"mish\")\n    for i in range(2):\n        input_data = residual_block(input_data, 64,  64, 64, activate_type=\"mish\")\n    input_data = convolutional(input_data, (1, 1, 64, 64), activate_type=\"mish\")\n    input_data = tf.concat([input_data, route], axis=-1)\n\n    input_data = convolutional(input_data, (1, 1, 128, 128), activate_type=\"mish\")\n    input_data = convolutional(input_data, (3, 3, 128, 256), downsample=True, activate_type=\"mish\")\n    route = input_data\n    route = convolutional(route, (1, 1, 256, 128), activate_type=\"mish\")\n    input_data = convolutional(input_data, (1, 1, 256, 128), activate_type=\"mish\")\n    for i in range(4):\n        input_data = residual_block(input_data, 128, 128, 128, activate_type=\"mish\")\n    input_data = convolutional(input_data, (1, 1, 128, 128), activate_type=\"mish\")\n    input_data = tf.concat([input_data, route], axis=-1)\n\n    input_data = convolutional(input_data, (1, 1, 256, 256), activate_type=\"mish\")\n    route_1 = input_data\n    input_data = convolutional(input_data, (3, 3, 256, 512), downsample=True, activate_type=\"mish\")\n    route = input_data\n    route = convolutional(route, (1, 1, 512, 256), activate_type=\"mish\")\n    input_data = convolutional(input_data, (1, 1, 512, 256), activate_type=\"mish\")\n    for i in range(4):\n        input_data = residual_block(input_data, 256, 256, 256, activate_type=\"mish\")\n    input_data = convolutional(input_data, (1, 1, 256, 256), activate_type=\"mish\")\n    input_data = tf.concat([input_data, route], axis=-1)\n\n    input_data = convolutional(input_data, (1, 1, 512, 512), activate_type=\"mish\")\n    route_2 = input_data\n    input_data = convolutional(input_data, (3, 3, 512, 1024), downsample=True, activate_type=\"mish\")\n    route = input_data\n    route = convolutional(route, (1, 1, 1024, 512), activate_type=\"mish\")\n    input_data = convolutional(input_data, (1, 1, 1024, 512), activate_type=\"mish\")\n    for i in range(4):\n        input_data = residual_block(input_data, 512, 512, 512, activate_type=\"mish\")\n    input_data = convolutional(input_data, (1, 1, 512, 512), activate_type=\"mish\")\n    input_data = tf.concat([input_data, route], axis=-1)\n\n    input_data = convolutional(input_data, (1, 1, 1024, 1024), activate_type=\"mish\")\n    input_data = convolutional(input_data, (1, 1, 1024, 512))\n    input_data = convolutional(input_data, (3, 3, 512, 1024))\n    input_data = convolutional(input_data, (1, 1, 1024, 512))\n\n    input_data = tf.concat([tf.nn.max_pool(input_data, ksize=13, padding='SAME', strides=1), tf.nn.max_pool(input_data, ksize=9, padding='SAME', strides=1)\n                            , tf.nn.max_pool(input_data, ksize=5, padding='SAME', strides=1), input_data], axis=-1)\n    input_data = convolutional(input_data, (1, 1, 2048, 512))\n    input_data = convolutional(input_data, (3, 3, 512, 1024))\n    input_data = convolutional(input_data, (1, 1, 1024, 512))\n\n    return route_1, route_2, input_data\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"LL7sv_cifsFJ"},"cell_type":"code","source":"def YOLOv4(input_layer, NUM_CLASS=0):\n    route_1, route_2, conv = cspdarknet53(input_layer)\n\n    route = conv\n    conv = convolutional(conv, (1, 1, 512, 256))\n    conv = upsample(conv)\n    route_2 = convolutional(route_2, (1, 1, 512, 256))\n    conv = tf.concat([route_2, conv], axis=-1)\n\n    conv = convolutional(conv, (1, 1, 512, 256))\n    conv = convolutional(conv, (3, 3, 256, 512))\n    conv = convolutional(conv, (1, 1, 512, 256))\n    conv = convolutional(conv, (3, 3, 256, 512))\n    conv = convolutional(conv, (1, 1, 512, 256))\n\n    route_2 = conv\n    conv = convolutional(conv, (1, 1, 256, 128))\n    conv = upsample(conv)\n    route_1 = convolutional(route_1, (1, 1, 256, 128))\n    conv = tf.concat([route_1, conv], axis=-1)\n\n    conv = convolutional(conv, (1, 1, 256, 128))\n    conv = convolutional(conv, (3, 3, 128, 256))\n    conv = convolutional(conv, (1, 1, 256, 128))\n    conv = convolutional(conv, (3, 3, 128, 256))\n    conv = convolutional(conv, (1, 1, 256, 128))\n\n    route_1 = conv\n    conv = convolutional(conv, (3, 3, 128, 256))\n    conv_sbbox = convolutional(conv, (1, 1, 256, 25 ), activate=False, bn=False)\n\n    conv = convolutional(route_1, (3, 3, 128, 256), downsample=True)\n    conv = tf.concat([conv, route_2], axis=-1)\n\n    conv = convolutional(conv, (1, 1, 512, 256))\n    conv = convolutional(conv, (3, 3, 256, 512))\n    conv = convolutional(conv, (1, 1, 512, 256))\n    conv = convolutional(conv, (3, 3, 256, 512))\n    conv = convolutional(conv, (1, 1, 512, 256))\n\n    route_2 = conv\n    conv = convolutional(conv, (3, 3, 256, 512))\n    conv_mbbox = convolutional(conv, (1, 1, 512, 25 ), activate=False, bn=False)\n\n    conv = convolutional(route_2, (3, 3, 256, 512), downsample=True)\n    conv = tf.concat([conv, route], axis=-1)\n\n    conv = convolutional(conv, (1, 1, 1024, 512))\n    conv = convolutional(conv, (3, 3, 512, 1024))\n    conv = convolutional(conv, (1, 1, 1024, 512))\n    conv = convolutional(conv, (3, 3, 512, 1024))\n    conv = convolutional(conv, (1, 1, 1024, 512))\n\n    conv = convolutional(conv, (3, 3, 512, 1024))\n    conv_lbbox = convolutional(conv, (1, 1, 1024, 25 ), activate=False, bn=False)\n    \n    conv_sbbox=Reshape((32,32,5,5),name='out1')(conv_sbbox)\n    conv_mbbox=Reshape((16,16,5,5),name='out2')(conv_mbbox)\n    conv_lbbox=Reshape((8,8,5,5),name='out3')(conv_lbbox)\n\n    \n\n    return [conv_sbbox, conv_mbbox, conv_lbbox]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def BIFPN(route_1,route_2,conv):\n    conv = convolutional(conv, (1, 1, 512, 256),activate_type=\"leaky\")\n    n31 = conv\n    conv = upsample(conv)\n    route_2 = convolutional(route_2, (1, 1, 512, 256),activate_type=\"leaky\")\n    n21 = route_2\n    conv = tf.concat([route_2, conv], axis=-1)\n    \n    conv = convolutional(conv, (1, 1, 512, 256),activate_type=\"leaky\")\n    conv = convolutional(conv, (3, 3, 256, 512),activate_type=\"leaky\")\n    conv = convolutional(conv, (1, 1, 512, 256),activate_type=\"leaky\")\n    \n    conv = convolutional(conv, (1, 1, 256, 128),activate_type=\"leaky\")\n    conv = upsample(conv)\n    n22=conv\n    \n    route_1 = convolutional(route_1, (1, 1, 256, 128),activate_type=\"leaky\")\n    n11=route_1\n    conv = tf.concat([route_1, conv], axis=-1)\n    \n    conv = convolutional(conv, (1, 1, 256, 128),activate_type=\"leaky\")\n    conv = convolutional(conv, (3, 3, 128, 256),activate_type=\"leaky\")\n    conv = convolutional(conv, (1, 1, 256, 128),activate_type=\"leaky\")\n    \n    n12=conv\n    \n    p1 = tf.concat([n11,n12], axis=-1)\n    p1 = convolutional(p1, (1, 1, 256, 128),activate_type=\"leaky\")\n    p1 = convolutional(p1, (3, 3, 128, 256),activate_type=\"leaky\")\n    n13=p1\n    \n    \n    conv = tf.concat([n13, n22], axis=-1)\n    conv   = convolutional(conv, (3, 3, 256, 256), downsample=True)\n    conv = tf.concat([conv, n21], axis=-1)\n    conv = convolutional(conv, (1, 1, 512, 256),activate_type=\"leaky\")\n    conv = convolutional(conv, (3, 3, 256, 512),activate_type=\"leaky\")\n    conv = convolutional(conv, (1, 1, 512, 256),activate_type=\"leaky\")\n    p2 = convolutional(conv, (3, 3, 256, 512),activate_type=\"leaky\")\n    \n    \n    rz = convolutional(conv, (3, 3, 256, 256), downsample=True)\n    conv = tf.concat([rz, n31], axis=-1)\n    conv = convolutional(conv, (1, 1, 512, 1024),activate_type=\"leaky\")\n    conv = convolutional(conv, (3, 3, 1024, 512),activate_type=\"leaky\")\n    \n    p3=conv\n    \n    \n    return [p1,p2,p3]\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"aklix4ktfsFN"},"cell_type":"code","source":"def decode_train(conv,clusters,shape,name):\n    clust=np.zeros((shape,shape,5,2))\n    for i in range(shape):\n        for j in range(shape):\n            clust[i][j]=clusters\n    clust=tf.convert_to_tensor(tf.cast(clust,dtype='float32'))\n        \n    xy=tf.sigmoid(conv[...,0:2])\n    wh=tf.exp(conv[...,2:4])*clust\n    prob=tf.sigmoid(conv[...,4:])\n                \n                \n    return tf.concat([xy,wh,prob],axis=-1,name=name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"K8eDO93sfsFQ"},"cell_type":"code","source":"clusters=np.array([[ 78. ,  78. ],\n       [ 33. ,  31.5],\n       [146. , 124. ],\n       [240. , 230. ],\n       [ 56.5,  45. ]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"3rq6ebcxfsFU"},"cell_type":"code","source":"def my_model(clusters,input_shape):\n    input_data=Input(input_shape)\n    [conv_sbbox, conv_mbbox, conv_lbbox] = YOLOv4(input_data)\n    \n    \n\n    conv_sbbox=decode_train(conv_sbbox,clusters,32,'sbbox')\n    conv_mbbox=decode_train(conv_mbbox,clusters,16,'mbbox')\n    conv_lbbox=decode_train(conv_lbbox,clusters,8,'lbbox')\n        \n    \n    \n    \n    model=Model(input_data,[conv_sbbox, conv_mbbox, conv_lbbox])\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def my_model2(clusters,input_shape):\n    input_data=Input(input_shape)\n    route_1, route_2, conv = cspdarknet53(input_data)\n    [p1,p2,p3] = BIFPN(route_1,route_2,conv)\n    #[p1,p2,p3] = BIFPN(p1,p2,p3)\n    #[p1,p2,p3] = BIFPN(p1,p2,p3)\n    \n    p1 = convolutional(p1, (1, 1, 256, 512),activate_type=\"leaky\")\n    p1 = convolutional(p1, (3, 3, 512, 256),activate_type=\"leaky\")\n    p1 = convolutional(p1, (1, 1, 256, 512),activate_type=\"leaky\")\n    p1 = convolutional(p1, (3, 3, 512, 256),activate_type=\"leaky\")\n    p1 = convolutional(p1, (1, 1, 256, 512),activate_type=\"leaky\")\n\n    p1 = convolutional(p1, (3, 3, 512, 256))\n    conv_sbbox = convolutional(p1, (1, 1, 256, 25 ), activate=False, bn=False)\n    \n    p2 = convolutional(p2, (1, 1, 512, 1024),activate_type=\"leaky\")\n    p2 = convolutional(p2, (3, 3, 1024, 512),activate_type=\"leaky\")\n    p2 = convolutional(p2, (1, 1, 512, 1024),activate_type=\"leaky\")\n    p2 = convolutional(p2, (3, 3, 1024, 512),activate_type=\"leaky\")\n    p2 = convolutional(p2, (1, 1, 512, 1024),activate_type=\"leaky\")\n\n    p2 = convolutional(p2, (3, 3, 1024, 512))\n    conv_mbbox = convolutional(p2, (1, 1, 512, 25 ), activate=False, bn=False)\n    \n    p3 = convolutional(p3, (1, 1, 512, 1024),activate_type=\"leaky\")\n    p3 = convolutional(p3, (3, 3, 1024, 512),activate_type=\"leaky\")\n    p3 = convolutional(p3, (1, 1, 512, 1024),activate_type=\"leaky\")\n    p3 = convolutional(p3, (3, 3, 1024, 512),activate_type=\"leaky\")\n    p3 = convolutional(p3, (1, 1, 512, 1024),activate_type=\"leaky\")\n\n    conv_lbbox = convolutional(p3, (1, 1, 1024, 25 ), activate=False, bn=False)\n    \n    conv_sbbox=tf.keras.layers.Reshape((32,32,5,5),name='out1')(conv_sbbox)\n    conv_mbbox=tf.keras.layers.Reshape((16,16,5,5),name='out2')(conv_mbbox)\n    conv_lbbox=tf.keras.layers.Reshape((8,8,5,5),name='out3')(conv_lbbox)\n    \n    \n\n    conv_sbbox=decode_train(conv_sbbox,clusters,32,'sbbox')\n    conv_mbbox=decode_train(conv_mbbox,clusters,16,'mbbox')\n    conv_lbbox=decode_train(conv_lbbox,clusters,8,'lbbox')\n\n        \n    \n    \n    \n    model=Model(input_data,[conv_sbbox, conv_mbbox, conv_lbbox])\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_model2(clusters,input_shape=(256,256,3)).summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"IA65NA60fsFk"},"cell_type":"code","source":"def iou(box, clusters):\n    x = np.minimum(clusters[:, 0], box[0])\n    y = np.minimum(clusters[:, 1], box[1])\n\n    intersection = x * y\n    box_area = box[0] * box[1]\n    cluster_area = clusters[:, 0] * clusters[:, 1]\n\n    iou_ = intersection / (box_area + cluster_area - intersection)\n\n    return iou_\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"pI3f2nW6fsFn"},"cell_type":"code","source":"def get_box_id(id):\n    bbox_list=[]\n    for index,image in enumerate(data['image_id']):\n        if (id==image):\n            bboz=get_list(data['bbox'][index])\n            w=bboz[2]\n            h=bboz[3]\n            x=bboz[0]\n            y=bboz[1]\n            bbox_list.append([x,y,x+w,y+h])\n    return np.array(bbox_list)\n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"sEIyuyFbfsFs"},"cell_type":"code","source":"def box_generator_helper(bboz,shape,clusters=clusters):\n        m,n=bboz.shape\n        bbox_array=np.zeros(shape)\n        for i in range(m):\n            #print(bboz[i][0],bboz[i][1],bboz[i][2],bboz[i][3])\n            w=int(bboz[i][2]-bboz[i][0])\n            h=int(bboz[i][3]-bboz[i][1])\n            x=int(bboz[i][0]+w/2)\n            y=int(bboz[i][1]+h/2)\n            #print(w,h,x,y)\n            xi = np.minimum(clusters[:, 0], w)\n            yi = np.minimum(clusters[:, 1], h)\n\n            intersection = xi * yi\n            box_area = (w) * (h)\n            cluster_area = clusters[:, 0] * clusters[:, 1]\n\n            iou_ = intersection / (box_area + cluster_area - intersection)\n            \n            anchor=np.argmax(iou_)\n            #print(anchor)\n            box1=int(x/(1024/shape[0]))\n            box2=int(y/(1024/shape[0]))\n            xr=(x%(1024/shape[0]))/(1024/shape[0])\n            yr=(y%(1024/shape[0]))/(1024/shape[0])\n            #tx=np.log(xr/((1-xr)+0.00000001))\n            #ty=np.log(yr/((1-yr)+0.000000001))\n            bw=w\n            bh=h\n            #tw=np.log(bw/clusters[anchor][0])\n            #th=np.log(bh/clusters[anchor][1])\n            #print(box1,box2,anchor)\n            #print(xr,yr,tw,th)\n            bbox_array[box1,box2,anchor,:]=xr,yr,bw,bh,1\n        return bbox_array\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"lY1-EOrAfsFv"},"cell_type":"code","source":"def box_generator(id,boxes,clusters,img):\n    if(len(id[9:])>0):\n        if(id[10:]=='h'):\n            img_center = np.array(img.shape[:2])[::-1]/2\n            img_center = np.hstack((img_center, img_center))\n            img =  img[:,::-1,:]\n            bboxes=get_box_id(id[:9])\n            bboxes[:,[0,2]] += 2*(img_center[[0,2]] - bboxes[:,[0,2]])\n            box_w = abs(bboxes[:,0] - bboxes[:,2])\n            bboxes[:,0] -= box_w\n            bboxes[:,2] += box_w\n            out1=box_generator_helper(bboxes,shape=(32,32,5,5))\n            out2=box_generator_helper(bboxes,shape=(16,16,5,5))\n            out3=box_generator_helper(bboxes,shape=(8,8,5,5))\n            return img,[out1,out2,out3]\n        elif(id[10:]=='v'):\n            img_center = np.array(img.shape[:2])[::-1]/2\n            img_center = np.hstack((img_center, img_center))\n            img =  img[::-1,:,:]\n            bboxes=get_box_id(id[:9])\n            bboxes[:,[1,3]] += 2*(img_center[[1,3]] - bboxes[:,[1,3]])\n            box_h = abs(bboxes[:,1] - bboxes[:,3])\n            bboxes[:,1] -= box_h\n            bboxes[:,3] += box_h\n            out1=box_generator_helper(bboxes,shape=(32,32,5,5))\n            out2=box_generator_helper(bboxes,shape=(16,16,5,5))\n            out3=box_generator_helper(bboxes,shape=(8,8,5,5))\n            return img,[out1,out2,out3]\n        elif(id[10:]=='vh'):\n            img_center = np.array(img.shape[:2])[::-1]/2\n            img_center = np.hstack((img_center, img_center))\n            img =  img[::-1,:,:]\n            bboxes=get_box_id(id[:9])\n            bboxes[:,[1,3]] += 2*(img_center[[1,3]] - bboxes[:,[1,3]])\n            box_h = abs(bboxes[:,1] - bboxes[:,3])\n            bboxes[:,1] -= box_h\n            bboxes[:,3] += box_h\n            \n            img_center = np.array(img.shape[:2])[::-1]/2\n            img_center = np.hstack((img_center, img_center))\n            img =  img[:,::-1,:]\n            bboxes[:,[0,2]] += 2*(img_center[[0,2]] - bboxes[:,[0,2]])\n            box_w = abs(bboxes[:,0] - bboxes[:,2])\n            bboxes[:,0] -= box_w\n            bboxes[:,2] += box_w\n            \n            \n            out1=box_generator_helper(bboxes,shape=(32,32,5,5))\n            out2=box_generator_helper(bboxes,shape=(16,16,5,5))\n            out3=box_generator_helper(bboxes,shape=(8,8,5,5))\n            return img,[out1,out2,out3]\n        elif(id[10:]=='hv'):\n            \n            img_center = np.array(img.shape[:2])[::-1]/2\n            img_center = np.hstack((img_center, img_center))\n            img =  img[:,::-1,:]\n            bboxes=get_box_id(id[:9])\n            bboxes[:,[0,2]] += 2*(img_center[[0,2]] - bboxes[:,[0,2]])\n            box_w = abs(bboxes[:,0] - bboxes[:,2])\n            bboxes[:,0] -= box_w\n            bboxes[:,2] += box_w\n            \n            img_center = np.array(img.shape[:2])[::-1]/2\n            img_center = np.hstack((img_center, img_center))\n            img =  img[::-1,:,:]\n            bboxes[:,[1,3]] += 2*(img_center[[1,3]] - bboxes[:,[1,3]])\n            box_h = abs(bboxes[:,1] - bboxes[:,3])\n            bboxes[:,1] -= box_h\n            bboxes[:,3] += box_h\n            \n            \n            out1=box_generator_helper(bboxes,shape=(32,32,5,5))\n            out2=box_generator_helper(bboxes,shape=(16,16,5,5))\n            out3=box_generator_helper(bboxes,shape=(8,8,5,5))\n            return img,[out1,out2,out3]\n         \n        elif(id[10:]=='c1'):\n          img_shape = img.shape\n          scale_x = -0.5\n          scale_y = scale_x\n          resize_scale_x = 1 + scale_x\n          resize_scale_y = 1 + scale_y\n          img=  cv2.resize(img, None, fx = resize_scale_x, fy = resize_scale_y)\n          canvas = np.zeros(img_shape, dtype = np.uint8)\n          y_lim = int(min(resize_scale_y,1)*img_shape[0])\n          x_lim = int(min(resize_scale_x,1)*img_shape[1])\n          canvas[:y_lim,:x_lim,:] =  img[:y_lim,:x_lim,:]\n          img = canvas\n\n          bboxes=get_box_id(id[:9])\n          bboxes[:,:4] *= [resize_scale_x, resize_scale_y, resize_scale_x, resize_scale_y]\n          bboxes = clip_box(bboxes, [0,0,1 + img_shape[1], img_shape[0]], 0.25)\n          row_mask=(bboxes[:,0:2]<1025).all(axis=1)\n          bboxes=bboxes[row_mask,:]\n          bboxes=np.clip(bboxes,0,1023)\n\n          out1=box_generator_helper(bboxes,shape=(32,32,5,5))\n          out2=box_generator_helper(bboxes,shape=(16,16,5,5))\n          out3=box_generator_helper(bboxes,shape=(8,8,5,5))\n          return img,[out1,out2,out3]\n\n        elif(id[10:]=='c2'):\n          img_shape = img.shape\n          scale_x = 1.0\n          scale_y = scale_x\n          resize_scale_x = 1 + scale_x\n          resize_scale_y = 1 + scale_y\n          img=  cv2.resize(img, None, fx = resize_scale_x, fy = resize_scale_y)\n          canvas = np.zeros(img_shape, dtype = np.uint8)\n          y_lim = int(min(resize_scale_y,1)*img_shape[0])\n          x_lim = int(min(resize_scale_x,1)*img_shape[1])\n          canvas[:y_lim,:x_lim,:] =  img[:y_lim,:x_lim,:]\n          img = canvas\n\n          bboxes=get_box_id(id[:9])\n          bboxes[:,:4] *= [resize_scale_x, resize_scale_y, resize_scale_x, resize_scale_y]\n          bboxes = clip_box(bboxes, [0,0,1 + img_shape[1], img_shape[0]], 0.25)\n          row_mask=(bboxes[:,0:2]<1025).all(axis=1)\n          bboxes=bboxes[row_mask,:]\n          bboxes=np.clip(bboxes,0,1023)\n\n          out1=box_generator_helper(bboxes,shape=(32,32,5,5))\n          out2=box_generator_helper(bboxes,shape=(16,16,5,5))\n          out3=box_generator_helper(bboxes,shape=(8,8,5,5))\n          return img,[out1,out2,out3]  \n\n        elif(id[10:]=='c3'):\n          img_shape = img.shape\n          scale_x = 1.5\n          scale_y = scale_x\n          resize_scale_x = 1 + scale_x\n          resize_scale_y = 1 + scale_y\n          img=  cv2.resize(img, None, fx = resize_scale_x, fy = resize_scale_y)\n          canvas = np.zeros(img_shape, dtype = np.uint8)\n          y_lim = int(min(resize_scale_y,1)*img_shape[0])\n          x_lim = int(min(resize_scale_x,1)*img_shape[1])\n          canvas[:y_lim,:x_lim,:] =  img[:y_lim,:x_lim,:]\n          img = canvas\n\n          bboxes=get_box_id(id[:9])\n          bboxes[:,:4] *= [resize_scale_x, resize_scale_y, resize_scale_x, resize_scale_y]\n          bboxes = clip_box(bboxes, [0,0,1 + img_shape[1], img_shape[0]], 0.25)\n          row_mask=(bboxes[:,0:2]<1025).all(axis=1)\n          bboxes=bboxes[row_mask,:]\n          bboxes=np.clip(bboxes,0,1023)\n\n          out1=box_generator_helper(bboxes,shape=(32,32,5,5))\n          out2=box_generator_helper(bboxes,shape=(16,16,5,5))\n          out3=box_generator_helper(bboxes,shape=(8,8,5,5))\n          return img,[out1,out2,out3]  \n\n        elif(id[10:]=='c4'):\n          img_shape = img.shape\n          scale_x = 2.0\n          scale_y = scale_x\n          resize_scale_x = 1 + scale_x\n          resize_scale_y = 1 + scale_y\n          img=  cv2.resize(img, None, fx = resize_scale_x, fy = resize_scale_y)\n          canvas = np.zeros(img_shape, dtype = np.uint8)\n          y_lim = int(min(resize_scale_y,1)*img_shape[0])\n          x_lim = int(min(resize_scale_x,1)*img_shape[1])\n          canvas[:y_lim,:x_lim,:] =  img[:y_lim,:x_lim,:]\n          img = canvas\n\n          bboxes=get_box_id(id[:9])\n          bboxes[:,:4] *= [resize_scale_x, resize_scale_y, resize_scale_x, resize_scale_y]\n          bboxes = clip_box(bboxes, [0,0,1 + img_shape[1], img_shape[0]], 0.25)\n          row_mask=(bboxes[:,0:2]<1025).all(axis=1)\n          bboxes=bboxes[row_mask,:]\n          bboxes=np.clip(bboxes,0,1023)\n\n          out1=box_generator_helper(bboxes,shape=(32,32,5,5))\n          out2=box_generator_helper(bboxes,shape=(16,16,5,5))\n          out3=box_generator_helper(bboxes,shape=(8,8,5,5))\n          return img,[out1,out2,out3]\n\n        elif(id[10:]=='c5'):\n          img_shape = img.shape\n          scale_x = 2.5\n          scale_y = scale_x\n          resize_scale_x = 1 + scale_x\n          resize_scale_y = 1 + scale_y\n          img=  cv2.resize(img, None, fx = resize_scale_x, fy = resize_scale_y)\n          canvas = np.zeros(img_shape, dtype = np.uint8)\n          y_lim = int(min(resize_scale_y,1)*img_shape[0])\n          x_lim = int(min(resize_scale_x,1)*img_shape[1])\n          canvas[:y_lim,:x_lim,:] =  img[:y_lim,:x_lim,:]\n          img = canvas\n\n          bboxes=get_box_id(id[:9])\n          bboxes[:,:4] *= [resize_scale_x, resize_scale_y, resize_scale_x, resize_scale_y]\n          bboxes = clip_box(bboxes, [0,0,1 + img_shape[1], img_shape[0]], 0.25)\n          row_mask=(bboxes[:,0:2]<1025).all(axis=1)\n          bboxes=bboxes[row_mask,:]\n          bboxes=np.clip(bboxes,0,1023)\n\n          out1=box_generator_helper(bboxes,shape=(32,32,5,5))\n          out2=box_generator_helper(bboxes,shape=(16,16,5,5))\n          out3=box_generator_helper(bboxes,shape=(8,8,5,5))\n          return img,[out1,out2,out3]\n\n\n            \n                        \n    \n    else:\n        bboz=get_box_id(id[:9])\n        out1=box_generator_helper(bboz,shape=(32,32,5,5))\n        out2=box_generator_helper(bboz,shape=(16,16,5,5))\n        out3=box_generator_helper(bboz,shape=(8,8,5,5))\n        return img,[out1,out2,out3]\n    ","execution_count":null,"outputs":[]},{"metadata":{"id":"lgmjYwy1oxps","trusted":true},"cell_type":"code","source":"def bbox_area(bbox):\n    return (bbox[:,2] - bbox[:,0])*(bbox[:,3] - bbox[:,1])","execution_count":null,"outputs":[]},{"metadata":{"id":"6xmzU94do2Cw","trusted":true},"cell_type":"code","source":"def clip_box(bbox, clip_box, alpha):\n    \"\"\"Clip the bounding boxes to the borders of an image\n    \n    Parameters\n    ----------\n    \n    bbox: numpy.ndarray\n        Numpy array containing bounding boxes of shape `N X 4` where N is the \n        number of bounding boxes and the bounding boxes are represented in the\n        format `x1 y1 x2 y2`\n    \n    clip_box: numpy.ndarray\n        An array of shape (4,) specifying the diagonal co-ordinates of the image\n        The coordinates are represented in the format `x1 y1 x2 y2`\n        \n    alpha: float\n        If the fraction of a bounding box left in the image after being clipped is \n        less than `alpha` the bounding box is dropped. \n    \n    Returns\n    -------\n    \n    numpy.ndarray\n        Numpy array containing **clipped** bounding boxes of shape `N X 4` where N is the \n        number of bounding boxes left are being clipped and the bounding boxes are represented in the\n        format `x1 y1 x2 y2` \n    \n    \"\"\"\n    ar_ = (bbox_area(bbox))\n    x_min = np.maximum(bbox[:,0], clip_box[0]).reshape(-1,1)\n    y_min = np.maximum(bbox[:,1], clip_box[1]).reshape(-1,1)\n    x_max = np.minimum(bbox[:,2], clip_box[2]).reshape(-1,1)\n    y_max = np.minimum(bbox[:,3], clip_box[3]).reshape(-1,1)\n    \n    bbox = np.hstack((x_min, y_min, x_max, y_max, bbox[:,4:]))\n    \n    delta_area = ((ar_ - bbox_area(bbox))/ar_)\n    \n    mask = (delta_area < (1 - alpha)).astype(int)\n    \n    bbox = bbox[mask == 1,:]\n\n\n    return bbox","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"EsWou92UfsF3"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"gIbOOnASfsF7"},"cell_type":"code","source":"def bbox_ciou(bboxes1, bboxes2):\n    \"\"\"\n    Complete IoU\n    @param bboxes1: (a, b, ..., 4)\n    @param bboxes2: (A, B, ..., 4)\n        x:X is 1:n or n:n or n:1\n    @return (max(a,A), max(b,B), ...)\n    ex) (4,):(3,4) -> (3,)\n        (2,1,4):(2,3,4) -> (2,3)\n    \"\"\"\n    bboxes1_area = bboxes1[..., 2] * bboxes1[..., 3]\n    bboxes2_area = bboxes2[..., 2] * bboxes2[..., 3]\n\n    bboxes1_coor = tf.concat(\n        [\n            bboxes1[..., :2] - bboxes1[..., 2:] * 0.5,\n            bboxes1[..., :2] + bboxes1[..., 2:] * 0.5,\n        ],\n        axis=-1,\n    )\n    bboxes2_coor = tf.concat(\n        [\n            bboxes2[..., :2] - bboxes2[..., 2:] * 0.5,\n            bboxes2[..., :2] + bboxes2[..., 2:] * 0.5,\n        ],\n        axis=-1,\n    )\n\n    left_up = tf.maximum(bboxes1_coor[..., :2], bboxes2_coor[..., :2])\n    right_down = tf.minimum(bboxes1_coor[..., 2:], bboxes2_coor[..., 2:])\n\n    inter_section = tf.maximum(right_down - left_up, 0.0)\n    inter_area = inter_section[..., 0] * inter_section[..., 1]\n\n    union_area = bboxes1_area + bboxes2_area - inter_area\n\n    iou = tf.math.divide_no_nan(inter_area, union_area)\n\n    enclose_left_up = tf.minimum(bboxes1_coor[..., :2], bboxes2_coor[..., :2])\n    enclose_right_down = tf.maximum(\n        bboxes1_coor[..., 2:], bboxes2_coor[..., 2:]\n    )\n\n    enclose_section = enclose_right_down - enclose_left_up\n\n    c_2 = enclose_section[..., 0] ** 2 + enclose_section[..., 1] ** 2\n\n    center_diagonal = bboxes2[..., :2] - bboxes1[..., :2]\n\n    rho_2 = center_diagonal[..., 0] ** 2 + center_diagonal[..., 1] ** 2\n\n    diou = iou - tf.math.divide_no_nan(rho_2, c_2)\n\n    v = (\n        (\n            tf.math.atan(\n                tf.math.divide_no_nan(bboxes1[..., 2], bboxes1[..., 3])\n            )\n            - tf.math.atan(\n                tf.math.divide_no_nan(bboxes2[..., 2], bboxes2[..., 3])\n            )\n        )\n        * 2/np.pi\n        \n    ) ** 2\n\n    alpha = tf.math.divide_no_nan(v, 1 - iou + v)\n\n    ciou = diou - alpha * v\n\n    return ciou","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"e6Ij4IeqfsGA"},"cell_type":"code","source":"def log_loss(y_true,y_pred):\n    return -y_true * tf.math.log(K.clip(y_pred,1e-5,(1-1e-5)))-( (1-y_true)*tf.math.log(1-(K.clip(y_pred,1e-5,(1-1e-5))) ))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"h-lLPqB2fsGD"},"cell_type":"code","source":"def yolo_loss(y_true,y_pred):\n  lossx=K.sum(tf.math.multiply(K.square(y_true[:,:,:,:,0:1]-y_pred[:,:,:,:,0:1]),y_true[:,:,:,:,4:]),axis=[1,2,3,4])\n  lossy=K.sum(tf.math.multiply(K.square(y_true[:,:,:,:,1:2]-y_pred[:,:,:,:,1:2]),y_true[:,:,:,:,4:]),axis=[1,2,3,4])\n  loss1=lossx+lossy\n  lossw=K.sum(tf.math.multiply(K.square(tf.keras.backend.sqrt(y_true[:,:,:,:,2:3])-tf.keras.backend.sqrt(y_pred[:,:,:,:,2:3])),y_true[:,:,:,:,4:]),axis=[1,2,3,4])\n  lossh=K.sum(tf.math.multiply(K.square(tf.keras.backend.sqrt(y_true[:,:,:,:,3:4])-tf.keras.backend.sqrt(y_pred[:,:,:,:,3:4])),y_true[:,:,:,:,4:]),axis=[1,2,3,4])\n  loss2=lossw+lossh\n  loss_xy_wh=(loss1+loss2)*2.0\n  #lossC=K.sum(tf.math.multiply(K.square(tf.math.subtract(y_true[:,:,:,4:],y_pred[:,:,:,4:])),y_true[:,:,:,4:]),axis=[1,2,3])\n  #lossC2 =K.sum(tf.math.multiply(K.square(tf.math.subtract(y_true[:,:,:,4:],y_pred[:,:,:,4:])),(1-y_true[:,:,:,4:])),axis=[1,2,3])/16  \n  #lossC=lossC+lossC2\n  #conf_focal = tf.pow(y_true[:,:,:,:,4:] - y_true[:,:,:,:,4:], 2)\n  conf_loss = K.sum( (\n           y_true[:,:,:,:,4:] * log_loss(y_true[:,:,:,:,4:],y_pred[:,:,:,:,4:])*1.5\n            +\n            (1-y_true[:,:,:,:,4:]) *0.05* log_loss(y_true[:,:,:,:,4:],y_pred[:,:,:,:,4:])\n    ),axis=[1,2,3,4])\n    \n  ciou = tf.expand_dims(bbox_ciou(y_pred[:,:,:,:,:4], y_true[:,:,:,:,:4]), axis=-1)\n  ciou_loss = y_true[:,:,:,:,4:] * 2.0 * (1- ciou)\n\n    \n  total_loss=loss_xy_wh+conf_loss+K.sum(ciou_loss,axis=[1,2,3,4])+conf_loss\n  return total_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"XJRnk6prfsGP"},"cell_type":"code","source":"model=my_model2(clusters,input_shape=(256,256,3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"4Umob3zCfsGS"},"cell_type":"code","source":"losses={'tf_op_layer_sbbox':yolo_loss,'tf_op_layer_mbbox':yolo_loss,'tf_op_layer_lbbox':yolo_loss}\nlossWeights={'tf_op_layer_sbbox':1,'tf_op_layer_mbbox':1,'tf_op_layer_lbbox':1}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"1y9eG_pkfsGV"},"cell_type":"code","source":"opt = tf.keras.optimizers.Adam(learning_rate=0.00001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"FFC1TCZIfsGZ"},"cell_type":"code","source":"#model.compile(optimizer=opt,loss=losses,loss_weights=lossWeights)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights('../input/bifpn5/BIFPN5.h5')","execution_count":null,"outputs":[]},{"metadata":{"id":"c8fn62bmCZjr","trusted":true},"cell_type":"code","source":"#model.save_weights('/content/drive/My Drive/Colab Notebooks/GAN weights/yolov4_2.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"O4TGXQ8WfsGi"},"cell_type":"code","source":"#train_generator=DataGenerator(train_ids,boxes,box_generator,clusters,batch_size=16,shuffle=False)\n#val_generator=DataGenerator(valid_ids,boxes,box_generator,clusters,batch_size=16,shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"DCjlyHS1fsGm"},"cell_type":"code","source":"#es=tf.keras.callbacks.EarlyStopping(\n#    monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='auto',\n#    baseline=None, restore_best_weights=True\n#)","execution_count":null,"outputs":[]},{"metadata":{"id":"tW-SPUuJoxfL","trusted":true},"cell_type":"code","source":"#checkpoint = ModelCheckpoint('/content/drive/My Drive/Colab Notebooks/GAN weights/yolov4_weights2.h5', monitor='loss', verbose=1,\n#    save_best_only=True, mode='auto', period=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nDIR_INPUT = '/kaggle/input/global-wheat-detection'\nDIR_TRAIN = f'{DIR_INPUT}/train'\nDIR_TEST = f'{DIR_INPUT}/test'\n\n\nimagenames = os.listdir(DIR_TEST)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results=[]\nfor count, name in enumerate(imagenames):\n    ids = name.split('.')[0]\n    imagepath = '%s/%s.jpg'%(DIR_TEST,ids)\n    img=cv2.imread(imagepath)\n    img1=cv2.resize(img,(256,256))\n    img1=img1/255.0\n    img1=img1[np.newaxis,:]\n    [box1,box2,box3]=model.predict(img1)\n    boxes=[]\n    scores=[]\n    for boz in [box1,box2]:\n          box=boz[0]\n          m=box.shape[0]\n          for i in range(m):\n            for j in range(m):\n                for k in range(5):\n                    if(box[i][j][k][4]>=0.9):\n                        x=(i*(1024/m))+(box[i][j][k][0]*(1024/m))\n                        y=(j*(1024/m))+(box[i][j][k][1]*(1024/m))\n                        w=box[i][j][k][2]\n                        h=box[i][j][k][3]\n                        x1=int((x-w/2))\n                        y1=int((y-h/2))\n                        x2=int((x+w/2))\n                        y2=int((y+h/2))\n                        #print(box[i][j][k][4])\n                       #print(box[i][j][k][4],int(x1),y1,x2,y2)\n                        boxes.append([y1,x1,y2,x2])\n                        scores.append(box[i][j][k][4])\n    \n      \n     \n    if(len(boxes)>0):\n        boxes=np.array(boxes)\n        scores=np.array(scores)\n        boxes=tf.convert_to_tensor(boxes)\n        scores=tf.convert_to_tensor(scores)\n        boxes=tf.cast(boxes, tf.float32)\n        scores=tf.cast(scores,tf.float32)\n        selected_indices = tf.image.non_max_suppression(\n            boxes, scores, max_output_size=50, iou_threshold=0.2)\n        selected_boxes = tf.gather(boxes, selected_indices)\n        selected_scores=tf.gather(scores,selected_indices)\n        boxes=np.array(selected_boxes)\n        scores=np.array(selected_scores)\n\n        pred_strings = []\n        m,n=boxes.shape\n        for i in range(m):\n            pred_strings.append(\"{0:.4f} {1} {2} {3} {4}\".format(np.clip(np.around(scores[i],4),0,1), np.clip(int(np.around(boxes[i][1])),0,1023), np.clip(int(np.around(boxes[i][0])),0,1023), np.clip(int(np.around(boxes[i][3]-boxes[i][1])),0,1023), np.clip(int(np.around(boxes[i][2]-boxes[i][0])),0,1023)))\n        if(len(pred_strings)>0):\n            result = {'image_id':ids,'PredictionString': \" \".join(pred_strings)}\n    else:\n        result = {'image_id':ids,'PredictionString': \" \"}\n        \n    results.append(result)\n    \n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.DataFrame(results, columns=['image_id', 'PredictionString'])\n\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def draw_boxes(box,ax):\n  m=box.shape[0]\n  for i in range(m):\n    for j in range(m):\n        for k in range(5):\n            if(box[i][j][k][4]>0.875):\n                x=(i*(1024/m))+(box[i][j][k][0]*(1024/m))\n                y=(j*(1024/m))+(box[i][j][k][1]*(1024/m))\n                w=box[i][j][k][2]\n                h=box[i][j][k][3]\n                x1=int((x-w/2))\n                y1=int((y-h/2))\n                x2=int((x+w/2))\n                y2=int((y+h/2))\n                #print(box[i][j][k][4])\n               #print(box[i][j][k][4],int(x1),y1,x2,y2)\n                rect = patches.Rectangle((x1,y1),w,h,linewidth=1,edgecolor='r',facecolor='none')\n                boxes.append([y1,x1,y2,x2])\n                scores.append(box[i][j][k][4])\n                #cv2.rectangle(img,(89,250),(202,363),(255,0,0),2)\n                ax.add_patch(rect)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img=cv2.imread('../input/global-wheat-detection/test/53f253011.jpg')\nimg1=cv2.resize(img,(256,256))\nimg1=img1/255.0\nimg1=img1[np.newaxis,:]\nbox1,box2,box3=model.predict(img1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(1)\nax.imshow(img[:,:,[2,1,0]])\nboxes=[]\nscores=[]\ndraw_boxes(box1[0],ax)\ndraw_boxes(box2[0],ax)\n#draw_boxes(box3[0],ax)\nboxes=np.array(boxes)\nscores=np.array(scores)\nboxes=tf.convert_to_tensor(boxes)\nscores=tf.convert_to_tensor(scores)\nboxes=tf.cast(boxes, tf.float32)\nscores=tf.cast(scores,tf.float32)\nselected_indices = tf.image.non_max_suppression(\n    boxes, scores, max_output_size=50, iou_threshold=0.2)\nselected_boxes = tf.gather(boxes, selected_indices)\nfig,ax = plt.subplots(1)\nax.imshow(img[:,:,[2,1,0]])\nfor i in selected_boxes:\n  rect = patches.Rectangle((i[1],i[0]),i[3]-i[1],i[2]-i[0],linewidth=3,edgecolor='r',facecolor='none')\n  ax.add_patch(rect)\nfig.set_size_inches((12,12))\nplt.show()\n\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}