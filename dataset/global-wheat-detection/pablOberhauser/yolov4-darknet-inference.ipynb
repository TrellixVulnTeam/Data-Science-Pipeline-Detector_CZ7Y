{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\ndef parser_image_preds(single_image):\n    image_preds = \"\"\n    prediction = single_image.split(\"seconds.\")[1]\n    individual_preds_in_image = prediction.split(\"wheathead\")[1:]\n    \n    for i in individual_preds_in_image:\n        pred = i.split(\":\")[1]\n        conf = float(\"\".join(pred.split('\\t')[0]).strip().replace(\"%\",\"\"))/100\n        \n        ny = \"\".join(i.split(\":\")[2:]).replace(\")\",\"\").split(\" \")\n        bbox = []\n        for inner in ny:\n            if inner.lstrip('-').isdigit():\n                bbox.append(int(inner))\n        \n        string_to_add = str(str(conf) + \" \" + str(bbox).replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\"))\n        image_preds += \" \" + string_to_add\n    return image_preds\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Notebook compiles darknet from scratch, uses weights that I have trained on my machine, and creates submission file using yolov4 on darknet.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cp -r /kaggle/input/darknet-jpo2/* ./","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.chdir(\"/kaggle/working/darknet_jpo/darknet/\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!cp ../../yolov4-wheat100_best_v2.weights backup/wheat100/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls backup/wheat100/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!sed '1 s/^.*$/GPU=0/; 2 s/^.*$/CUDNN=0/; 3 s/^.*$/CUDNN_HALF=0/; 5 s/^.*$/AVX=0/; 6 s/^.*$/OPENMP=0/; 7 s/^.*$/LIBSO=0/' -i Makefile","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!head Makefile","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! make clean","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!make ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Get list of test ids","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_subs = pd.read_csv(\"/kaggle/input/global-wheat-detection/sample_submission.csv\")\ntest_image_ids = test_subs.image_id.values\ntest_subs.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_image_ids","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pathlib import Path\nimport subprocess\n\nroot_image = Path(\"/kaggle/input/global-wheat-detection/test\")\ntest_images = [root_image / f\"{img}.jpg\" for img in test_subs.image_id]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open(\"test_predict.txt\", 'a') as file: # append lines to file\n    for i in test_image_ids:\n        new_name =  \"/kaggle/input/global-wheat-detection/test/{}.jpg\".format(i)\n        new_name = new_name + \"\\n\"\n        file.write(new_name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cmd = \"./darknet detector test data/wheat100.data cfg/yolov4-wheat100.cfg backup/wheat100/yolov4-wheat100_best_v2.weights -dont_show -ext_output < test_predict.txt > pr_res.txt -thresh 0.25\"\nb = subprocess.getoutput(cmd)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!head pr_res.txt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"conf_result_file = \"pr_res.txt\"\nfile_l = open(conf_result_file, 'r')   \nlines = file_l.read().split('\\n')\ncontent_str = \"\".join(lines)\nint_unique_predictions = content_str.split('Enter')[1:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res_lines = []  \n#single_image = int_unique_predictions[0]\nfor single_image in int_unique_predictions[:-1]:\n    img_id = \"\".join([i for i in single_image.split(\" \") if '.jpg' in i]).replace(\":\",\"\").split(\"/\")[-1].replace(\".jpg\", \"\")\n    print(img_id)\n    xx = parser_image_preds(single_image)\n    #print(img_id, xx)\n    res_lines.append({'image_id': img_id, 'PredictionString': xx})\n\nsubmission_df = pd.DataFrame(res_lines)     ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.chdir(\"/kaggle/working/\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm -r darknet","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}