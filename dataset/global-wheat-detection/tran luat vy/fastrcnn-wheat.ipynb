{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torchvision\nimport cv2\nimport numpy as np\nimport os\nfrom glob import glob\nfrom tqdm import tqdm\nfrom matplotlib import pyplot as plt\nfrom random import choice, choices, shuffle\nimport re\nfrom ipywidgets import IntProgress\nimport pandas as pd\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.utils.data.sampler import SequentialSampler\nfrom torchvision.models.detection import FasterRCNN\nfrom torchvision.models.detection.rpn import AnchorGenerator\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensor, ToTensorV2\n\n\nBOX_COLOR = (0, 0, 255)\nTEXT_COLOR = (255, 255, 255)\nTRAIN_IMG_DIR = \"../input/global-wheat-detection/train\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-11T06:15:58.2984Z","iopub.execute_input":"2021-12-11T06:15:58.299068Z","iopub.status.idle":"2021-12-11T06:16:01.997545Z","shell.execute_reply.started":"2021-12-11T06:15:58.298966Z","shell.execute_reply":"2021-12-11T06:16:01.996813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#show 1 ảnh\ndef plot_img(img, size=(7,7), is_rgb=False):\n    plt.figure(figsize=size)\n    if is_rgb:\n        plt.imshow(img)\n    else:\n        plt.imshow(img[:,:,::-1])\n    plt.show()\n    \n    \n#show nhiều ảnh\ndef plot_imgs(imgs, cols=5, size=7, is_rgb=False):\n    rows = len(imgs)//cols + 1\n    fig = plt.figure(figsize=(cols*size, rows*size))\n    for i, img in enumerate(imgs):\n        fig.add_subplot(rows, cols, i+1)\n        if is_rgb:\n            plt.imshow(img)\n        else:\n            plt.imshow(img[:,:,::-1])\n    plt.show()\n    \n    \n# vẽ bounding box lên ảnh\ndef visualize_bbox(img, boxes, thickness=3, color=BOX_COLOR):\n    img_copy = img.copy()\n    for box in boxes:\n        img_copy = cv2.rectangle(\n            img_copy,\n            (int(box[0]), int(box[1])),\n            (int(box[2]), int(box[3])),\n            color, thickness)\n    return img_copy\n\n\n# vẽ bounding box lên ảnh\ndef load_img(img_id, folder=TRAIN_IMG_DIR):\n    img_fn = f\"{folder}/{img_id}.jpg\"\n    img = cv2.imread(img_fn).astype(np.float32)\n    img /= 255.0\n    return img","metadata":{"execution":{"iopub.status.busy":"2021-12-11T06:16:01.999099Z","iopub.execute_input":"2021-12-11T06:16:01.999615Z","iopub.status.idle":"2021-12-11T06:16:02.011671Z","shell.execute_reply.started":"2021-12-11T06:16:01.999585Z","shell.execute_reply":"2021-12-11T06:16:02.009947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#chuyển đổi cặp [imgs, targets] sang dạng tensor theo device cpu/gpu\ndef data_to_device(images, targets, device=torch.device(\"cuda\")):\n    images = list(image.to(device) for image in images)\n    targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n    return images, targets\n\n\ndef expand_bbox(x):\n    r = np.array(re.findall(\"([0-9]+[.]?[0-9]*)\", x))\n    if len(r) == 0:\n        r = [-1, -1, -1, -1]\n    return r\n\n\n# đọc data từ file csv\n# output là 1 list chứa thông tin về các ảnh\n# mỗi phần tử bao gồm 1 image_id và 1 list các bounding box\ndef read_data_in_csv(csv_path=\"./wheat-dataset/train.csv\"):\n    df = pd.read_csv(csv_path)\n    df['x'], df['y'],  df['w'], df['h'] = -1, -1, -1, -1\n    df[['x', 'y', 'w', 'h']] = np.stack(df['bbox'].apply(lambda x: expand_bbox(x)))\n    df.drop(columns=['bbox'], inplace=True)\n    df['x'] = df['x'].astype(np.float)\n    df['y'] = df['y'].astype(np.float)\n    df['w'] = df['w'].astype(np.float)\n    df['h'] = df['h'].astype(np.float)\n    objs = []\n    img_ids = set(df[\"image_id\"])\n    \n    for img_id in tqdm(img_ids):\n        records = df[df[\"image_id\"] == img_id]\n        boxes = records[['x', 'y', 'w', 'h']].values\n        area = boxes[:,2]*boxes[:,3]\n        boxes[:,2] = boxes[:,0] + boxes[:,2]\n        boxes[:,3] = boxes[:,1] + boxes[:,3]\n\n        obj = {\n            \"img_id\": img_id,\n            \"boxes\": boxes,\n            \"area\":area\n        }\n        objs.append(obj)\n    return objs\n\n\nclass WheatDataset(Dataset):\n    def __init__(self, data, img_dir ,transform=None):\n        self.data = data\n        self.img_dir = img_dir\n        self.transform = transform\n        \n    def __getitem__(self, idx):\n        img_data = self.data[idx]\n        bboxes = img_data[\"boxes\"]\n        box_nb = len(bboxes)\n        labels = torch.ones((box_nb,), dtype=torch.int64)\n        iscrowd = torch.zeros((box_nb,), dtype=torch.int64)\n        img = load_img(img_data[\"img_id\"], self.img_dir)\n        area = img_data[\"area\"]\n        if self.transform is not None:\n            sample = {\n                \"image\":img,\n                \"bboxes\": bboxes,\n                \"labels\": labels,\n                \"area\": area\n            }\n            sample = self.transform(**sample)\n            img = sample['image']\n            area = sample[\"area\"]\n            bboxes = torch.stack(tuple(map(torch.tensor, zip(*sample['bboxes'])))).permute(1, 0)\n\n        target = {}\n        target['boxes'] = bboxes.type(torch.float32)\n        target['labels'] = labels\n        target['area'] = torch.as_tensor(area, dtype=torch.float32)\n        target['iscrowd'] = iscrowd\n        target[\"image_id\"] = torch.tensor([idx])\n        return img, target\n        \n    def __len__(self):\n        return len(self.data)\n    \n\ndef collate_fn(batch):\n    return tuple(zip(*batch))","metadata":{"execution":{"iopub.status.busy":"2021-12-11T06:16:02.013264Z","iopub.execute_input":"2021-12-11T06:16:02.013516Z","iopub.status.idle":"2021-12-11T06:16:02.033711Z","shell.execute_reply.started":"2021-12-11T06:16:02.013484Z","shell.execute_reply":"2021-12-11T06:16:02.033052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #load data form csv file\n# data = read_data_in_csv('../input/global-wheat-detection/train.csv')\n# shuffle(data)\n# device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n\n# # tạo transform cho dataset - các biến đổi để augmentation data\n# train_transform = A.Compose(\n#     [A.Flip(0.5), ToTensorV2(p=1.0)],\n#     bbox_params={\n#         \"format\":\"pascal_voc\",\n#         'label_fields': ['labels']\n# })\n\n# # khởi tạo Dataset và Dataloader\n# train_dataset = WheatDataset(data, img_dir=TRAIN_IMG_DIR, transform=train_transform)\n# train_loader = DataLoader(\n#     train_dataset,\n#     batch_size=8,\n#     shuffle=True,\n#     num_workers=2,\n#     collate_fn=collate_fn)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-11T06:16:02.03594Z","iopub.execute_input":"2021-12-11T06:16:02.036404Z","iopub.status.idle":"2021-12-11T06:16:02.046701Z","shell.execute_reply.started":"2021-12-11T06:16:02.036353Z","shell.execute_reply":"2021-12-11T06:16:02.046068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from torch.optim.lr_scheduler import _LRScheduler\n# from torch.optim.lr_scheduler import ReduceLROnPlateau\n\n\n# class GradualWarmupScheduler(_LRScheduler):\n#     def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n#         self.multiplier = multiplier\n#         if self.multiplier < 1.:\n#             raise ValueError('multiplier should be greater thant or equal to 1.')\n#         self.total_epoch = total_epoch\n#         self.after_scheduler = after_scheduler\n#         self.finished = False\n#         super(GradualWarmupScheduler, self).__init__(optimizer)\n\n#     def get_lr(self):\n#         if self.last_epoch > self.total_epoch:\n#             if self.after_scheduler:\n#                 if not self.finished:\n#                     self.after_scheduler.base_lrs = [base_lr * self.multiplier for base_lr in self.base_lrs]\n#                     self.finished = True\n#                 return self.after_scheduler.get_last_lr()\n#             return [base_lr * self.multiplier for base_lr in self.base_lrs]\n\n#         if self.multiplier == 1.0:\n#             return [base_lr * (float(self.last_epoch) / self.total_epoch) for base_lr in self.base_lrs]\n#         else:\n#             return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]\n\n#     def step_ReduceLROnPlateau(self, metrics, epoch=None):\n#         if epoch is None:\n#             epoch = self.last_epoch + 1\n#         self.last_epoch = epoch if epoch != 0 else 1  # ReduceLROnPlateau is called at the end of epoch, whereas others are called at beginning\n#         if self.last_epoch <= self.total_epoch:\n#             warmup_lr = [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]\n#             for param_group, lr in zip(self.optimizer.param_groups, warmup_lr):\n#                 param_group['lr'] = lr\n#         else:\n#             if epoch is None:\n#                 self.after_scheduler.step(metrics, None)\n#             else:\n#                 self.after_scheduler.step(metrics, epoch - self.total_epoch)\n\n#     def step(self, epoch=None, metrics=None):\n#         if type(self.after_scheduler) != ReduceLROnPlateau:\n#             if self.finished and self.after_scheduler:\n#                 if epoch is None:\n#                     self.after_scheduler.step(None)\n#                 else:\n#                     self.after_scheduler.step(epoch - self.total_epoch)\n#                 self._last_lr = self.after_scheduler.get_last_lr()\n#             else:\n#                 return super(GradualWarmupScheduler, self).step(epoch)\n#         else:\n#             self.step_ReduceLROnPlateau(metrics, epoch)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T06:16:02.048093Z","iopub.execute_input":"2021-12-11T06:16:02.048421Z","iopub.status.idle":"2021-12-11T06:16:02.056498Z","shell.execute_reply.started":"2021-12-11T06:16:02.048389Z","shell.execute_reply":"2021-12-11T06:16:02.0558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# num_classes = 2\n# num_epochs = 5\n# iters = 1\n# model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True, progress=False)\n# in_features = model.roi_heads.box_predictor.cls_score.in_features\n# model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n\n# params = [p for p in model.parameters() if p.requires_grad]\n# optimizer = torch.optim.SGD(params, lr=0.0005, momentum=0.9, weight_decay=0.0005)\n\n# scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs-1)\n# scheduler = GradualWarmupScheduler(optimizer, multiplier=10, total_epoch=1, after_scheduler=scheduler_cosine)\n\n# model.to(device)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T06:16:02.057745Z","iopub.execute_input":"2021-12-11T06:16:02.058053Z","iopub.status.idle":"2021-12-11T06:16:02.068563Z","shell.execute_reply.started":"2021-12-11T06:16:02.058019Z","shell.execute_reply":"2021-12-11T06:16:02.067934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # tiến hành train model\n# for epoch in range(num_epochs):\n#     scheduler.step(epoch)\n#     model.train()\n#     for images, targets in train_loader:\n#         images, targets = data_to_device(images, targets)\n#         loss_dict = model(images, targets)\n#         losses = sum(loss for loss in loss_dict.values())\n#         loss_value = losses.item()\n        \n#         optimizer.zero_grad()\n#         losses.backward()\n#         optimizer.step()\n        \n#         iters += 1\n#         # show loss per 30 iteration\n#         if iters%30 == 0:\n#             print(f\"Iteration #{iters} loss: {loss_value}\")\n            \n# #         # để đơn giản, ta save model mỗi 90 iteration\n# #         if iters%90 == 0:\n# #             model_path = f\"./saved_model/model_{iters}_{round(loss_value, 2)}.pth\"\n# #             torch.save(model.state_dict(), model_path)\n# #             model.train()","metadata":{"execution":{"iopub.status.busy":"2021-12-11T06:16:02.069958Z","iopub.execute_input":"2021-12-11T06:16:02.070244Z","iopub.status.idle":"2021-12-11T06:16:02.077745Z","shell.execute_reply.started":"2021-12-11T06:16:02.070209Z","shell.execute_reply":"2021-12-11T06:16:02.076964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# torch.save(model.state_dict(), './model_lr_5epoch.h5')","metadata":{"execution":{"iopub.status.busy":"2021-12-11T06:16:02.079375Z","iopub.execute_input":"2021-12-11T06:16:02.079572Z","iopub.status.idle":"2021-12-11T06:16:02.087721Z","shell.execute_reply.started":"2021-12-11T06:16:02.079549Z","shell.execute_reply":"2021-12-11T06:16:02.087089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"=========================================================================","metadata":{}},{"cell_type":"code","source":"class WheatTestDataset(Dataset):\n\n    def __init__(self, dataframe, image_dir, transforms=None):\n        super().__init__()\n\n        self.image_ids = dataframe['image_id'].unique()\n        self.df = dataframe\n        self.image_dir = image_dir\n        self.transforms = transforms\n\n    def __getitem__(self, index: int):\n\n        image_id = self.image_ids[index]\n        records = self.df[self.df['image_id'] == image_id]\n\n        image = cv2.imread(f'{self.image_dir}/{image_id}.jpg', cv2.IMREAD_COLOR)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n        image /= 255.0\n\n        if self.transforms:\n            sample = {\n                'image': image,\n            }\n            sample = self.transforms(**sample)\n            image = sample['image']\n\n        return image, image_id\n\n    def __len__(self) -> int:\n        return self.image_ids.shape[0]","metadata":{"execution":{"iopub.status.busy":"2021-12-11T06:16:02.089064Z","iopub.execute_input":"2021-12-11T06:16:02.089354Z","iopub.status.idle":"2021-12-11T06:16:02.220843Z","shell.execute_reply.started":"2021-12-11T06:16:02.089318Z","shell.execute_reply":"2021-12-11T06:16:02.219982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_test_transform():\n    return A.Compose([\n        # A.Resize(512, 512),\n        ToTensorV2(p=1.0)\n    ])","metadata":{"execution":{"iopub.status.busy":"2021-12-11T06:16:02.224191Z","iopub.execute_input":"2021-12-11T06:16:02.224544Z","iopub.status.idle":"2021-12-11T06:16:02.230366Z","shell.execute_reply.started":"2021-12-11T06:16:02.224505Z","shell.execute_reply":"2021-12-11T06:16:02.229588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load a model; pre-trained on COCO\n# model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False, pretrained_backbone=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T06:16:02.231685Z","iopub.execute_input":"2021-12-11T06:16:02.232212Z","iopub.status.idle":"2021-12-11T06:16:02.238491Z","shell.execute_reply.started":"2021-12-11T06:16:02.232055Z","shell.execute_reply":"2021-12-11T06:16:02.237672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n\n# num_classes = 2  # 1 class (wheat) + background\n\n# get number of input features for the classifier\n# in_features = model.roi_heads.box_predictor.cls_score.in_features\n\n# replace the pre-trained head with a new one\n# model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n\n# Load the trained weights\n# model.load_state_dict(torch.load('../input/fatercnnresnet152102410epochfold1/fastercnnresnet152_10ep_fold1_ap60.h5'))\nmodel = torch.load('../input/new-gwd2021-resnet50/model_ep-7_ap-0.6110084455701318')\n\nmodel.eval()\n\nx = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T06:16:02.240088Z","iopub.execute_input":"2021-12-11T06:16:02.240448Z","iopub.status.idle":"2021-12-11T06:16:08.336923Z","shell.execute_reply.started":"2021-12-11T06:16:02.240412Z","shell.execute_reply":"2021-12-11T06:16:08.336087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from torchvision.models.detection.backbone_utils import resnet_fpn_backbone\n# from torchvision.models.detection.faster_rcnn import FasterRCNN\n# from torchvision.models.detection.backbone_utils import BackboneWithFPN\n\n# def fasterrcnn_resnet_fpn(backbone_name='resnet152', progress=True, num_classes=91, pretrained=True, pretrained_backbone=True, **kwargs):\n#     if backbone_name == 'resnet50':\n#         model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=pretrained)\n#     elif backbone_name in ['resnet101', 'resnet152']:\n#         backbone = resnet_fpn_backbone(backbone_name, pretrained_backbone)\n#     else:\n#         backbone = my_resnet_fpn_backbone(backbone_name, pretrained_backbone)\n#     model = FasterRCNN(backbone, num_classes, **kwargs)\n#     return model","metadata":{"execution":{"iopub.status.busy":"2021-12-11T06:16:08.340242Z","iopub.execute_input":"2021-12-11T06:16:08.340833Z","iopub.status.idle":"2021-12-11T06:16:08.3475Z","shell.execute_reply.started":"2021-12-11T06:16:08.340802Z","shell.execute_reply":"2021-12-11T06:16:08.346777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n\n# # model = fasterrcnn_resnet_fpn(backbone_name='resnet152', pretrained=True, pretrained_backbone=True)\n# # in_features = model.roi_heads.box_predictor.cls_score.in_features\n# # model.roi_heads.box_predictor = FastRCNNPredictor(in_features, 2)\n# # model.load_state_dict(torch.load('../input/testmodelfastercnndungnb/model-frcnn-dungnb.h5'))\n\n# model1 = torch.load('../input/fasterrcnn20epfull1024folds1/model_ep-19_trainloss-1.0128233870248047')\n# model1.eval()\n\n# model2 = torch.load('../input/testdungnbnew/model-frcnn-dungnb-new.h5')\n# model2.eval()\n\n# model1 = model1.to(device)\n# model2 = model2.to(device)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T06:16:08.350719Z","iopub.execute_input":"2021-12-11T06:16:08.350975Z","iopub.status.idle":"2021-12-11T06:16:08.356164Z","shell.execute_reply.started":"2021-12-11T06:16:08.350943Z","shell.execute_reply":"2021-12-11T06:16:08.354985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ££££££££££££££££££££££££££££££££££££££3","metadata":{"execution":{"iopub.status.busy":"2021-12-11T06:16:08.357294Z","iopub.execute_input":"2021-12-11T06:16:08.357519Z","iopub.status.idle":"2021-12-11T06:16:08.36851Z","shell.execute_reply.started":"2021-12-11T06:16:08.357483Z","shell.execute_reply":"2021-12-11T06:16:08.367645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# detection_threshold = 0.5\n# results = []\n\n# for images, image_ids in test_data_loader:\n\n#     images = list(image.to(device) for image in images)\n#     output1 = model1(images)\n#     output2 = model2(images)\n#     break\n#     for i, image in enumerate(images):\n\n#         boxes = outputs[i]['boxes'].data.cpu().numpy()\n#         scores = outputs[i]['scores'].data.cpu().numpy()\n        \n#         boxes = boxes[scores >= detection_threshold].astype(np.int32)\n#         scores = scores[scores >= detection_threshold]\n#         image_id = image_ids[i]\n        \n#         boxes[:, 2] = boxes[:, 2] - boxes[:, 0]\n#         boxes[:, 3] = boxes[:, 3] - boxes[:, 1]\n        \n#         result = {\n#             'image_id': image_id,\n#             'PredictionString': format_prediction_string(boxes, scores)\n#         }\n\n        \n#         results.append(result)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T06:16:08.370136Z","iopub.execute_input":"2021-12-11T06:16:08.370409Z","iopub.status.idle":"2021-12-11T06:16:08.379626Z","shell.execute_reply.started":"2021-12-11T06:16:08.370373Z","shell.execute_reply":"2021-12-11T06:16:08.378715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ! pip install ensemble-boxes==1.0.4","metadata":{"execution":{"iopub.status.busy":"2021-12-11T06:16:08.380811Z","iopub.execute_input":"2021-12-11T06:16:08.381371Z","iopub.status.idle":"2021-12-11T06:16:08.389267Z","shell.execute_reply.started":"2021-12-11T06:16:08.381331Z","shell.execute_reply":"2021-12-11T06:16:08.388471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from ensemble_boxes import weighted_boxes_fusion\n","metadata":{"execution":{"iopub.status.busy":"2021-12-11T06:16:08.391718Z","iopub.execute_input":"2021-12-11T06:16:08.392394Z","iopub.status.idle":"2021-12-11T06:16:08.400233Z","shell.execute_reply.started":"2021-12-11T06:16:08.392354Z","shell.execute_reply":"2021-12-11T06:16:08.399348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# boxe1 = output1[0]['boxes'].cpu().detach().numpy()\n# boxe2 = output2[0]['boxes'].cpu().detach().numpy()","metadata":{"execution":{"iopub.status.busy":"2021-12-11T06:16:08.4015Z","iopub.execute_input":"2021-12-11T06:16:08.401918Z","iopub.status.idle":"2021-12-11T06:16:08.409729Z","shell.execute_reply.started":"2021-12-11T06:16:08.401879Z","shell.execute_reply":"2021-12-11T06:16:08.408894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# temp1 = pd.DataFrame(boxe1)\n# temp2 = pd.DataFrame(boxe2)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T06:16:08.412347Z","iopub.execute_input":"2021-12-11T06:16:08.412555Z","iopub.status.idle":"2021-12-11T06:16:08.420931Z","shell.execute_reply.started":"2021-12-11T06:16:08.41253Z","shell.execute_reply":"2021-12-11T06:16:08.420046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# temp[0][3]","metadata":{"execution":{"iopub.status.busy":"2021-12-11T06:16:08.42295Z","iopub.execute_input":"2021-12-11T06:16:08.423185Z","iopub.status.idle":"2021-12-11T06:16:08.430475Z","shell.execute_reply.started":"2021-12-11T06:16:08.423157Z","shell.execute_reply":"2021-12-11T06:16:08.429649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# boxes = []\n# for i in range(len(temp1)):\n#     boxes.append([temp1[i][0], temp1[i][1], temp1[i][2], temp1[i][3]])\n# len(boxes)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T06:16:08.431665Z","iopub.execute_input":"2021-12-11T06:16:08.431922Z","iopub.status.idle":"2021-12-11T06:16:08.441462Z","shell.execute_reply.started":"2021-12-11T06:16:08.431895Z","shell.execute_reply":"2021-12-11T06:16:08.440714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# boxes, scores, labels","metadata":{"execution":{"iopub.status.busy":"2021-12-11T06:16:08.442458Z","iopub.execute_input":"2021-12-11T06:16:08.44277Z","iopub.status.idle":"2021-12-11T06:16:08.454643Z","shell.execute_reply.started":"2021-12-11T06:16:08.442713Z","shell.execute_reply":"2021-12-11T06:16:08.453801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# boxes, scores, labels = weighted_boxes_fusion(boxes, scores, labels, weights=None, iou_thr=0.5, skip_box_thr=0.32)\n# boxes = np.array(boxes)\n# scores = np.array(scores)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T06:16:08.455466Z","iopub.execute_input":"2021-12-11T06:16:08.455692Z","iopub.status.idle":"2021-12-11T06:16:08.463778Z","shell.execute_reply.started":"2021-12-11T06:16:08.455664Z","shell.execute_reply":"2021-12-11T06:16:08.463016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ££££££££££££££££££££££££££££££££££££££££££££££","metadata":{"execution":{"iopub.status.busy":"2021-12-11T06:16:08.465823Z","iopub.execute_input":"2021-12-11T06:16:08.466707Z","iopub.status.idle":"2021-12-11T06:16:08.474161Z","shell.execute_reply.started":"2021-12-11T06:16:08.466666Z","shell.execute_reply":"2021-12-11T06:16:08.473335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv('../input/global-wheat-detection/sample_submission.csv')\ntest_df.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-11T06:16:08.475928Z","iopub.execute_input":"2021-12-11T06:16:08.47622Z","iopub.status.idle":"2021-12-11T06:16:08.498338Z","shell.execute_reply.started":"2021-12-11T06:16:08.476164Z","shell.execute_reply":"2021-12-11T06:16:08.49761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def collate_fn(batch):\n    return tuple(zip(*batch))\n\ntest_dataset = WheatTestDataset(test_df, '../input/global-wheat-detection/test', get_test_transform())\n\ntest_data_loader = DataLoader(\n    test_dataset,\n    batch_size=1,\n    shuffle=False,\n    num_workers=4,\n    drop_last=False,\n    collate_fn=collate_fn\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T06:16:08.499535Z","iopub.execute_input":"2021-12-11T06:16:08.499797Z","iopub.status.idle":"2021-12-11T06:16:08.514858Z","shell.execute_reply.started":"2021-12-11T06:16:08.499762Z","shell.execute_reply":"2021-12-11T06:16:08.514062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def format_prediction_string(boxes, scores):\n    pred_strings = []\n    for j in zip(scores, boxes):\n        pred_strings.append(\"{0:.4f} {1} {2} {3} {4}\".format(j[0], j[1][0], j[1][1], j[1][2], j[1][3]))\n\n    return \" \".join(pred_strings)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T06:16:08.519433Z","iopub.execute_input":"2021-12-11T06:16:08.520022Z","iopub.status.idle":"2021-12-11T06:16:08.525453Z","shell.execute_reply.started":"2021-12-11T06:16:08.519989Z","shell.execute_reply":"2021-12-11T06:16:08.52451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"detection_threshold = 0.5\nresults = []\n\nfor images, image_ids in test_data_loader:\n\n    images = list(image.to(device) for image in images)\n    outputs = model(images)\n\n    for i, image in enumerate(images):\n\n        boxes = outputs[i]['boxes'].data.cpu().numpy()\n        scores = outputs[i]['scores'].data.cpu().numpy()\n        \n        boxes = boxes[scores >= detection_threshold].astype(np.int32)\n        scores = scores[scores >= detection_threshold]\n        image_id = image_ids[i]\n        \n        boxes[:, 2] = boxes[:, 2] - boxes[:, 0]\n        boxes[:, 3] = boxes[:, 3] - boxes[:, 1]\n        \n        result = {\n            'image_id': image_id,\n            'PredictionString': format_prediction_string(boxes, scores)\n        }\n\n        \n        results.append(result)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T06:16:08.527669Z","iopub.execute_input":"2021-12-11T06:16:08.528212Z","iopub.status.idle":"2021-12-11T06:16:15.4871Z","shell.execute_reply.started":"2021-12-11T06:16:08.528173Z","shell.execute_reply":"2021-12-11T06:16:15.486094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# results[0:2]\n","metadata":{"execution":{"iopub.status.busy":"2021-12-11T06:16:15.488946Z","iopub.execute_input":"2021-12-11T06:16:15.489253Z","iopub.status.idle":"2021-12-11T06:16:15.495675Z","shell.execute_reply.started":"2021-12-11T06:16:15.489218Z","shell.execute_reply":"2021-12-11T06:16:15.494625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.DataFrame(results, columns=['image_id', 'PredictionString'])\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-11T06:16:15.497467Z","iopub.execute_input":"2021-12-11T06:16:15.498034Z","iopub.status.idle":"2021-12-11T06:16:15.518525Z","shell.execute_reply.started":"2021-12-11T06:16:15.497984Z","shell.execute_reply":"2021-12-11T06:16:15.517548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.to_csv('./submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T06:16:15.519852Z","iopub.execute_input":"2021-12-11T06:16:15.520288Z","iopub.status.idle":"2021-12-11T06:16:15.528265Z","shell.execute_reply.started":"2021-12-11T06:16:15.520254Z","shell.execute_reply":"2021-12-11T06:16:15.527497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sample = images[2].permute(1,2,0).cpu().numpy()\n# boxes = outputs[2]['boxes'].data.cpu().numpy()\n# scores = outputs[2]['scores'].data.cpu().numpy()\n\n# boxes = boxes[scores >= detection_threshold].astype(np.int32)\n\n\n# fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n\n# for box in boxes:\n#     cv2.rectangle(sample,\n#                   (box[0], box[1]),\n#                   (box[2], box[3]),\n#                   (220, 0, 0), 2)\n    \n# ax.set_axis_off()\n# ax.imshow(sample)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T06:16:15.529604Z","iopub.execute_input":"2021-12-11T06:16:15.530138Z","iopub.status.idle":"2021-12-11T06:16:15.535956Z","shell.execute_reply.started":"2021-12-11T06:16:15.530099Z","shell.execute_reply":"2021-12-11T06:16:15.535201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# torch.save(model,'./model.h5')","metadata":{"execution":{"iopub.status.busy":"2021-12-11T06:16:15.537116Z","iopub.execute_input":"2021-12-11T06:16:15.537613Z","iopub.status.idle":"2021-12-11T06:16:15.544677Z","shell.execute_reply.started":"2021-12-11T06:16:15.537566Z","shell.execute_reply":"2021-12-11T06:16:15.543931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model1 = torch.load('../input/testmodelfastercnndungnb/model-frcnn-dungnb.h5')","metadata":{"execution":{"iopub.status.busy":"2021-12-11T06:16:15.546997Z","iopub.execute_input":"2021-12-11T06:16:15.547869Z","iopub.status.idle":"2021-12-11T06:16:15.554591Z","shell.execute_reply.started":"2021-12-11T06:16:15.547832Z","shell.execute_reply":"2021-12-11T06:16:15.55383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model1","metadata":{"execution":{"iopub.status.busy":"2021-12-11T06:16:15.556647Z","iopub.execute_input":"2021-12-11T06:16:15.556922Z","iopub.status.idle":"2021-12-11T06:16:15.56328Z","shell.execute_reply.started":"2021-12-11T06:16:15.556888Z","shell.execute_reply":"2021-12-11T06:16:15.562615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model1 = torch.load('../input/testmodel/model.h5')","metadata":{"execution":{"iopub.status.busy":"2021-12-11T06:16:15.565029Z","iopub.execute_input":"2021-12-11T06:16:15.56549Z","iopub.status.idle":"2021-12-11T06:16:15.573657Z","shell.execute_reply.started":"2021-12-11T06:16:15.565457Z","shell.execute_reply":"2021-12-11T06:16:15.572915Z"},"trusted":true},"execution_count":null,"outputs":[]}]}