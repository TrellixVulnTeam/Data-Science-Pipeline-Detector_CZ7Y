{"cells":[{"metadata":{},"cell_type":"markdown","source":"I started working on this competition quite late but I thought I'd be okay. I easisy reached ~0.72 score and then decided to rewrite everything (I my solution was based on someone else's notebooks) and make it clean and easy to edit. \n\nTraining notebook (this one) is working just fine but I got issues with inference notebook: https://www.kaggle.com/poddiachyi/inference-yolov5-simple\n\nAll in all I made about 10 submissions all of which resulted in \"Submission CSV not found\" even though it perfectly worked on the test set.\n\nJust making it all public cause I don't care anymore. ","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nfrom tqdm.auto import tqdm\nimport shutil as sh\nimport numpy as np\nimport random\nimport torch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"csv_path = '../input/global-wheat-detection/train.csv'\ndataset_path = '../input/global-wheat-detection'\n\nIMG_SIZE = 1024","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!cp -r ../input/yolov5trainstable/* ./","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"!cd ../input/yolostuff/ && pip install -r requirements.txt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def set_seed():\n    seed = 42\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    np.random.seed(seed)\n    random.seed(seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_df(path):\n    df = pd.read_csv(csv_path)\n\n    bboxs = np.stack(df['bbox'].apply(lambda x: np.fromstring(x[1:-1], sep=',')))\n\n    for i, column in enumerate(['x', 'y', 'w', 'h']):\n        df[column] = bboxs[:,i]\n\n    df.drop(columns=['bbox'], inplace=True)\n\n    df['x_center'] = df['x'] + df['w'] / 2\n    df['y_center'] = df['y'] + df['h'] / 2\n    df['classes'] = 0\n\n    df = df[['image_id','x', 'y', 'w', 'h','x_center','y_center','classes']]\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = load_df(csv_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"index = list(set(df.image_id))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_folder(path):\n    if not os.path.exists(path):\n        os.makedirs(path)\n        \n        \ndef write_bboxes_to_ann(file, bboxes):\n    for j in range(len(bboxes)):\n        text = ' '.join(bboxes[j])\n        file.write(text)\n        file.write(\"\\n\")\n        \n        \ndef process_bboxes(ann_file, table):\n    with open(ann_file_path, 'w+') as f:\n        bboxes = table[['classes','x_center','y_center','w','h']].astype(float).values\n        bboxes = bboxes / IMG_SIZE\n        bboxes = bboxes.astype(str)\n        write_bboxes_to_ann(f, bboxes)\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm -r convertor/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_index = index[0 : len(index)//5]\nsource = 'train'\nfor name, table in tqdm(df.groupby('image_id')):\n    \n    if name in val_index:\n        phase = 'val2017/'\n    else:\n        phase = 'train2017/'\n    \n    full_labels_path = os.path.join('convertor', phase, 'labels')\n    create_folder(full_labels_path)\n    \n    ann_file_path = os.path.join(full_labels_path, name + '.txt') # annotation file\n    process_bboxes(ann_file_path, table)\n        \n    img_folder = os.path.join('convertor', phase, 'images')\n    create_folder(img_folder)\n    \n    name_with_ext = name + '.jpg'\n    img_src = os.path.join(dataset_path, source, name_with_ext)\n    img_dst = os.path.join('convertor', phase, 'images', name_with_ext)\n    sh.copy(img_src, img_dst)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"set_seed()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!python train.py --img 512 --batch 16 --epochs 40 --data ../input/yolostuff/wheat0.yaml --cfg ../input/yolostuff/yolov5x.yaml --name yolov5x_fold0 --weights ../input/yolostuff/yolov5x.pt\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"create_folder('trained_models')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!cp -r runs/exp0_yolov5x_fold0/weights/ trained_models/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm -r runs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm -rf convertor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}