{"cells":[{"metadata":{},"cell_type":"markdown","source":"# To DO List\n### 1> Inspect the data, number of boxes per image, class wise distinction, box size\n### 2> Split into training and validation set\n### 3> Add Augmentation ","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport glob\nfrom sklearn import preprocessing\nimport itertools\nimport matplotlib.pyplot as plt\nimport pickle\nimport copy\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input/detectron2/","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# # install dependencies: (use cu101 because colab has CUDA 10.1)\n# !pip install -U torch==1.5 torchvision==0.6 -f https://download.pytorch.org/whl/cu101/torch_stable.html \n# !pip install cython pyyaml==5.1\n# !pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n# import torch, torchvision\n# print(torch.__version__, torch.cuda.is_available())\n# !gcc --version\n# # opencv is pre-installed on colab","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !pip install detectron2==0.1.2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/index.html\n!pip install ../input/detectron2/pycocotools-2.0.0-cp37-cp37m-linux_x86_64.whl\n!pip install ../input/detectron\"2\"/torch-1.5.0cu101-cp37-cp37m-linux_x86_64.whl\n!pip install ../input/detectron2/torchvision-0.6.0cu101-cp37-cp37m-linux_x86_64.whl\n!pip install ../input/detectron2/yacs-0.1.7-py3-none-any.whl\n!pip install ../input/detectron2/fvcore-0.1.dev200505-py3-none-any.whl\n!pip install ../input/detectron2/detectron2-0.1.2cu101-cp37-cp37m-linux_x86_64.whl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# You may need to restart your runtime prior to this, to let your installation take effect\n# Some basic setup:\n# Setup detectron2 logger\nimport detectron2\nfrom detectron2.utils.logger import setup_logger\nsetup_logger()\n\n# import some common libraries\nimport numpy as np\nimport cv2\nimport random\n\n# import some common detectron2 utilities\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor\nfrom detectron2.config import get_cfg\nfrom detectron2.utils.visualizer import Visualizer\nfrom detectron2.data import MetadataCatalog\nfrom detectron2.structures import BoxMode\nfrom ast import literal_eval\nfrom detectron2.data import build_detection_train_loader\nfrom detectron2.data import transforms as T\nfrom detectron2.data import detection_utils as utils","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/global-wheat-detection/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../working/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le = preprocessing.LabelEncoder()\nle.fit(train['source'].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['bbox'] = train['bbox'].apply(literal_eval)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_ids = train['image_id'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grp_image_id = train.groupby('image_id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_datatset():    \n    img_dir = '/kaggle/input/global-wheat-detection/train/'\n    dataset_dicts = []\n\n    for img_id in image_ids:\n        image_anno_df = grp_image_id.get_group(img_id)\n        record = {}\n        file_path = '{}{}.jpg'.format(img_dir, img_id)\n        record[\"file_name\"] = file_path\n        record[\"image_id\"] = img_id\n        record[\"height\"] = int(image_anno_df.iloc[0].height)\n        record[\"width\"] = int(image_anno_df.iloc[0].width)\n\n        objs = []\n\n        for _,row in image_anno_df.iterrows():\n            bbox = row['bbox']\n            xmin, ymin, width, height = int(bbox[0]), int(bbox[1]), int(bbox[2]), int(bbox[3])\n            xmax = xmin + width\n            ymax = ymin + height\n\n            obj = {\n            \"bbox\": [xmin, ymin, xmax, ymax],\n            \"bbox_mode\": BoxMode.XYXY_ABS,\n            \"category_id\": 1,\n            \"iscrowd\": 0\n              }\n\n            objs.append(obj)\n\n        record[\"annotations\"] = objs\n        dataset_dicts.append(record)\n    return dataset_dicts\n  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_train_data():\n    with open('../input/wheat-datastet/wheat_data_dic.pkl', 'rb') as f:\n        wheat_data_dic = pickle.load(f)\n    for idx in wheat_data_dic:\n        for jdx in idx['annotations']:\n            jdx['category_id'] = int(0)\n    return wheat_data_dic","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_test_datatset():    \n    img_dir = '/kaggle/input/global-wheat-detection/test/'\n    dataset_dicts = []\n    \n    for img_path in glob.glob(img_dir + '*.jpg'):\n        record = {}\n        file_path = img_path\n        image_id = img_path.split('/')[-1].split('.')[0]\n        record['file_name'] = file_path\n        record['image_id'] = image_id\n        dataset_dicts.append(record)\n    return dataset_dicts\n  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes = le.classes_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from detectron2.data import DatasetCatalog, MetadataCatalog\nDatasetCatalog.register(\"object_detection_train_comp_2\", get_train_data)\nMetadataCatalog.get(\"object_detection_train_comp_2\").set(thing_classes=[\"wheat_head\"])\nod_dataset = MetadataCatalog.get(\"object_detection_train_comp_2\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"od_dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dataset_dicts = get_train_data()\n# for d in random.sample(dataset_dicts, 3):\n#     plt.figure(figsize=(20,10)) \n#     img = plt.imread(d[\"file_name\"])\n#     visualizer = Visualizer(img[:, :, ::-1], metadata=od_dataset, scale=0.5)\n#     vis = visualizer.draw_dataset_dict(d)\n#     plt.imshow(vis.get_image()[:, :, ::-1])\n#     plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from detectron2.engine import DefaultTrainer\nfrom detectron2.config import get_cfg, CfgNode","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def custom_mapper(dataset_dict):\n    # Implement a mapper, similar to the default DatasetMapper, but with your own customizations\n    dataset_dict = copy.deepcopy(dataset_dict)  # it will be modified by code below\n    image = utils.read_image(dataset_dict[\"file_name\"], format=\"BGR\")\n    transform_list = [T.Resize(1200,1200),\n                      T.RandomFlip(prob=0.5),\n                      T.RandomContrast(0.8, 3),\n                      T.RandomBrightness(0.8, 1.6),\n                      ]\n    \n    image, transforms = T.apply_transform_gens(transform_list, image)\n    dataset_dict[\"image\"] = torch.as_tensor(image.transpose(2, 0, 1).astype(\"float32\"))\n\n    annos = [\n        utils.transform_instance_annotations(obj, transforms, image.shape[:2])\n        for obj in dataset_dict.pop(\"annotations\")\n    ]\n    instances = utils.annotations_to_instances(annos, image.shape[:2])\n    dataset_dict[\"instances\"] = utils.filter_empty_instances(instances)\n    return dataset_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Trainer(DefaultTrainer):\n\n    @classmethod\n    def build_train_loader(cls, cfg: CfgNode):\n        return build_detection_train_loader(cfg, mapper=custom_mapper)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cfg = get_cfg()\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\ncfg.DATASETS.TRAIN = (\"object_detection_train_comp_2\",)\ncfg.DATASETS.TEST = ()\ncfg.DATALOADER.NUM_WORKERS = 8\ncfg.MODEL.WEIGHTS = '../input/detectron2/model_final_280758.pkl' # Let training initialize from model zoo\n# cfg.MODEL.WEIGHTS =  model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\ncfg.SOLVER.IMS_PER_BATCH = 2\ncfg.SOLVER.BASE_LR = 0.0025  # pick a good LR\ncfg.SOLVER.MAX_ITER = 3000    # 300 iterations seems good enough for this toy dataset; you may need to train longer for a practical dataset\ncfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset (default: 512)\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ballon)\n\nos.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\ntrainer = Trainer(cfg) \ntrainer.resume_or_load(resume=False)\ntrainer.train()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%load_ext tensorboard\n%tensorboard --logdir cfg.OUTPUT_DIR","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DatasetCatalog.register(\"object_detection_test\", create_test_datatset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set the testing threshold for this model\ncfg.DATASETS.TEST = (\"create_test_datatset\", )\npredictor = DefaultPredictor(cfg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataset = create_test_datatset()\nimg_ids = []\npred_string = []\n\nfor test_data in test_dataset:\n    image_id = test_data['file_name'].split('/')[-1].split('.')[0]\n    img = plt.imread(test_data['file_name'])\n    outputs = predictor(img)\n#     v = Visualizer(img[:, :, ::-1],\n#                    metadata=od_dataset, \n#                    scale=0.3, \n                   \n#     )\n#     v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\") )\n#     plt.figure(figsize=(25, 15))\n#     plt.imshow(cv2.cvtColor(v.get_image()[:, :, ::-1], cv2.COLOR_BGR2RGB))\n#     plt.show()\n    preds = []\n    for box,score in zip(outputs['instances'].get_fields()['pred_boxes'], outputs['instances'].get_fields()['scores']):\n        bbox = []\n        for idx in range(4):\n            bbox.append(box.data[idx].item())\n        preds.append(\"{} {} {} {} {}\".format(score.item(), int(bbox[0]), int(bbox[1]), int(bbox[2]-bbox[0]), int(bbox[3]-bbox[1])))\n        \n    pred_string.append(\" \".join(preds))\n    img_ids.append(image_id)\n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub={\"image_id\":img_ids, \"PredictionString\":pred_string}\nsub=pd.DataFrame(sub)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv('/kaggle/working/submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}