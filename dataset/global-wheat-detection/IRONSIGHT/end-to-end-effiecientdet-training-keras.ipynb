{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!git clone https://github.com/ravi02512/efficientdet-keras.git","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nos.chdir(\"/kaggle/working/efficientdet-keras\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_df=pd.read_csv(\"/kaggle/input/global-wheat-detection/train.csv\")\ntrain_data_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_id=[f\"{i}.jpg\" for i in train_data_df.image_id]\nxmins,ymins,xmaxs,ymaxs,area=[],[],[],[],[]\nfor bbox in train_data_df.bbox:\n    real_bbox=eval(bbox)\n    \n    xmin, ymin ,w ,h=real_bbox\n    \n    \n    \n    a=int(xmin+w)\n    b=int(ymin+h)\n    xmaxs.append(a)\n    ymaxs.append(b)\n\n    \n    c=int(xmin)\n    d=int(ymin)\n    xmins.append(c)\n    ymins.append(d)\n    \n    area.append(w*h)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=pd.DataFrame()\ndata[\"filename\"]=image_id\ndata[\"width\"]=train_data_df.width\ndata[\"width\"]=train_data_df.height\n\ndata[\"class\"]=[\"wheat\"]*len(image_id)\n\ndata[\"xmin\"]=xmins\ndata[\"ymin\"]=ymins\n\ndata[\"xmax\"]=xmaxs\ndata[\"ymax\"]=ymaxs\n\ndata[\"iscrowd\"]=[1]*len(image_id)\n\ndata[\"area\"]=area","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filtered_df=data.drop(data[(data[\"area\"]>200000) | (data[\"area\"]<2000)].index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filtered_df.reset_index(drop=True, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filtered_df.to_csv(\"train_labels.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.read_csv(\"train_labels.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def int64_feature(value):\n  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\n\ndef int64_list_feature(value):\n  return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n\n\ndef bytes_feature(value):\n  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\n\ndef bytes_list_feature(value):\n  return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n\n\ndef float_list_feature(value):\n  return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from __future__ import division\nfrom __future__ import print_function\nfrom __future__ import absolute_import\n\nimport os\nimport io\nimport pandas as pd\nimport tensorflow as tf\n\nfrom PIL import Image\nfrom collections import namedtuple, OrderedDict\nimport hashlib\n\n\n# TO-DO replace this with label map\ndef class_text_to_int(row_label):\n    if row_label == 'wheat':\n        return 1\n    else:\n        None\n\n\ndef split(df, group):\n    data = namedtuple('data', ['filename', 'object'])\n    gb = df.groupby(group)\n    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n\n\ndef create_tf_example(group, path):\n    with tf.io.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n        encoded_jpg = fid.read()\n    encoded_jpg_io = io.BytesIO(encoded_jpg)\n    image = Image.open(encoded_jpg_io)\n    key = hashlib.sha256(encoded_jpg).hexdigest()\n    \n    width, height = image.size\n\n    filename = group.filename.encode('utf8')\n    image_format = b'jpg'\n    xmins = []\n    xmaxs = []\n    ymins = []\n    ymaxs = []\n    classes_text = []\n    classes = []\n    iscrowd=[]\n    area=[]\n\n    for index, row in group.object.iterrows():\n        xmins.append(row['xmin'] / width)\n        xmaxs.append(row['xmax'] / width)\n        ymins.append(row['ymin'] / height)\n        ymaxs.append(row['ymax'] / height)\n        iscrowd.append(row[\"iscrowd\"])\n        area.append(row[\"area\"])\n        classes_text.append(row['class'].encode('utf8'))\n        classes.append(class_text_to_int(row['class']))\n\n    tf_example = tf.train.Example(features=tf.train.Features(feature={\n        'image/height': int64_feature(height),\n        'image/width': int64_feature(width),\n        'image/filename': bytes_feature(filename),\n        'image/source_id':bytes_feature(filename),\n        'image/key/sha256':bytes_feature(key.encode('utf8')),\n        'image/encoded':bytes_feature(encoded_jpg),\n        'image/format': bytes_feature('jpg'.encode('utf8')),\n        'image/object/bbox/xmin': float_list_feature(xmins),\n        'image/object/bbox/xmax': float_list_feature(xmaxs),\n        'image/object/bbox/ymin': float_list_feature(ymins),\n        'image/object/bbox/ymax': float_list_feature(ymaxs),\n        'image/object/class/text':bytes_list_feature(classes_text),\n        'image/object/class/label':int64_list_feature(classes),\n        'image/object/is_crowd':int64_list_feature(iscrowd),\n        'image/object/area':float_list_feature(area)\n    }))\n    return tf_example\n\n\ndef main(csv_input, train_output_path,val_output_path, image_dir):\n    train_writer = tf.io.TFRecordWriter(train_output_path)\n    val_writer = tf.io.TFRecordWriter(val_output_path)\n    path = os.path.join(image_dir)\n    examples = pd.read_csv(csv_input)\n    grouped = split(examples, 'filename')\n    for group in grouped[500:]:\n        tf_example = create_tf_example(group, path)\n        train_writer.write(tf_example.SerializeToString())\n        \n    for group in grouped[:500]:\n        tf_example = create_tf_example(group, path)\n        val_writer.write(tf_example.SerializeToString())\n\n\n    train_writer.close()\n    val_writer.close()\n    \n    train_output_path = os.path.join(os.getcwd(), train_output_path)\n    val_output_path = os.path.join(os.getcwd(), val_output_path)\n    \n    print('Successfully created the TFRecords: {}'.format(train_output_path))\n    print('Successfully created the TFRecords: {}'.format(val_output_path))\n\n\nif __name__ == '__main__':\n    csv_input=\"train_labels.csv\"\n    train_output_path=\"train_data.record\"\n    val_output_path=\"val_data.record\"\n    image_dir=\"/kaggle/input/global-wheat-detection/train\"\n    main(csv_input, train_output_path,val_output_path, image_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.mkdir(\"/kaggle/working/model\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pycocotools","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfrom absl import app\nfrom absl import flags\nfrom absl import logging\nimport tensorflow as tf\nfrom tensorflow.python.client import device_lib\nimport dataloader\nimport hparams_config\nimport utils\nfrom keras import train_lib\n\n\n\n\n\nFLAGS={'tpu':None,'gcp_project':None,'tpu_zone':None,'eval_master':'',\n      'eval_name':None,'strategy':None,'num_cores':8,'use_fake_data':False,\n      'use_xla':False,'model_dir':\"/kaggle/working/model\",'hparams':'','batch_size':2,\n      'eval_samples':2,'iterations_per_loop':100,'training_file_pattern':\"train_data.record\",\n      'validation_file_pattern':\"val_data.record\",'val_json_file':None,'testdev_dir':None,\n      'num_examples_per_epoch':50,'num_epochs':None,'mode':'train',\n      'model_name':'efficientdet-d3','eval_after_training':False,\n      'debug':False,'profile':False,'min_eval_interval':180,\n      'eval_timeout':None}\n\ndef get_callbacks(params,profile=False):\n  tb_callback = tf.keras.callbacks.TensorBoard(\n      log_dir=params['model_dir'], profile_batch=2 if profile else 0)\n  ckpt_callback = tf.keras.callbacks.ModelCheckpoint(\n      params['model_dir']+\"/best.h5\", verbose=1, save_weights_only=False,save_best_only=True)\n  early_stopping = tf.keras.callbacks.EarlyStopping(\n      monitor='val_loss', min_delta=0, patience=10, verbose=1)\n  return [tb_callback, ckpt_callback, early_stopping]\n\n\ndef main(FLAGS):\n  # Parse and override hparams\n  config = hparams_config.get_detection_config(FLAGS[\"model_name\"])\n  config.override(FLAGS[\"hparams\"])\n  if FLAGS[\"num_epochs\"]:  # NOTE: remove this flag after updating all docs.\n    config.num_epochs = FLAGS[\"num_epochs\"]\n\n  # Parse image size in case it is in string format.\n  config.image_size = utils.parse_image_size(config.image_size)\n\n  if FLAGS[\"use_xla\"] and FLAGS[\"strategy\"] != 'tpu':\n    tf.config.optimizer.set_jit(True)\n    for gpu in tf.config.list_physical_devices('GPU'):\n      tf.config.experimental.set_memory_growth(gpu, True)\n\n  if FLAGS[\"debug\"]:\n    tf.config.experimental_run_functions_eagerly(True)\n    tf.debugging.set_log_device_placement(True)\n    tf.random.set_seed(111111)\n    logging.set_verbosity(logging.DEBUG)\n\n  if FLAGS[\"strategy\"] == 'tpu':\n    tpu_cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(\n        FLAGS[\"tpu\"], zone=FLAGS[\"tpu_zone\"], project=FLAGS[\"gcp_project\"])\n    tf.config.experimental_connect_to_cluster(tpu_cluster_resolver)\n    tf.tpu.experimental.initialize_tpu_system(tpu_cluster_resolver)\n    ds_strategy = tf.distribute.TPUStrategy(tpu_cluster_resolver)\n    logging.info('All devices: %s', tf.config.list_logical_devices('TPU'))\n  elif FLAGS[\"strategy\"] == 'gpus':\n    ds_strategy = tf.distribute.MirroredStrategy()\n    logging.info('All devices: %s', tf.config.list_physical_devices('GPU'))\n  else:\n    if tf.config.list_physical_devices(\"GPU\"):\n      ds_strategy = tf.distribute.OneDeviceStrategy('device:GPU:0')\n    else:\n      ds_strategy = tf.distribute.OneDeviceStrategy('device:CPU:0')\n\n  # Check data path\n  if FLAGS[\"mode\"] in ('train',\n                    'train_and_eval') and FLAGS[\"training_file_pattern\"] is None:\n    raise RuntimeError('You must specify --training_file_pattern for training.')\n  if FLAGS[\"mode\"] in ('eval', 'train_and_eval'):\n    if FLAGS[\"validation_file_pattern\"] is None:\n      raise RuntimeError('You must specify --validation_file_pattern '\n                         'for evaluation.')\n\n  params = dict(\n      config.as_dict(),\n      model_name=FLAGS[\"model_name\"],\n      iterations_per_loop=FLAGS[\"iterations_per_loop\"],\n      model_dir=FLAGS[\"model_dir\"],\n      num_examples_per_epoch=FLAGS[\"num_examples_per_epoch\"],\n      strategy=FLAGS[\"strategy\"],\n      batch_size=FLAGS[\"batch_size\"] // ds_strategy.num_replicas_in_sync,\n      num_shards=ds_strategy.num_replicas_in_sync,\n      val_json_file=FLAGS[\"val_json_file\"],\n      testdev_dir=FLAGS[\"testdev_dir\"],\n      mode=FLAGS[\"mode\"])\n\n  # set mixed precision policy by keras api.\n  precision = utils.get_precision(params['strategy'], params['mixed_precision'])\n  policy = tf.keras.mixed_precision.experimental.Policy(precision)\n  tf.keras.mixed_precision.experimental.set_policy(policy)\n\n  def get_dataset(is_training, params):\n    file_pattern = (\n        FLAGS[\"training_file_pattern\"]\n        if is_training else FLAGS[\"validation_file_pattern\"])\n    return dataloader.InputReader(\n        file_pattern,\n        is_training=is_training,\n        use_fake_data=FLAGS[\"use_fake_data\"],\n        max_instances_per_image=config.max_instances_per_image)(\n            params)\n\n  with ds_strategy.scope():\n    model = train_lib.EfficientDetNetTrain(params['model_name'], config)\n    height, width = utils.parse_image_size(params['image_size'])\n    model.build((params['batch_size'], height, width, 3))\n    model.summary()\n    model.compile(\n        optimizer=train_lib.get_optimizer(params),\n        loss={\n            'box_loss':\n                train_lib.BoxLoss(\n                    params['delta'],reduction=tf.keras.losses.Reduction.NONE),\n            'box_iou_loss':\n                train_lib.BoxIouLoss(\n                    params['iou_loss_type'],\n                    params['min_level'],\n                    params['max_level'],\n                    params['num_scales'],\n                    params['aspect_ratios'],\n                    params['anchor_scale'],\n                    params['image_size'],\n                    reduction=tf.keras.losses.Reduction.NONE),\n            'class_loss':\n                train_lib.FocalLoss(\n                    params['alpha'],\n                    params['gamma'],\n                    label_smoothing=params['label_smoothing'],\n                    reduction=tf.keras.losses.Reduction.NONE)\n        })\n    ckpt_path = tf.train.latest_checkpoint(FLAGS[\"model_dir\"])\n    if ckpt_path:\n      model.load_weights(ckpt_path)\n    \n    model.freeze_vars(params['var_freeze_expr'])\n    model.fit(\n        get_dataset(True, params=params),\n        steps_per_epoch=FLAGS[\"num_examples_per_epoch\"],\n        epochs=1,\n        callbacks=get_callbacks(params, FLAGS[\"profile\"]),\n        validation_data=get_dataset(False, params=params),\n        validation_steps=FLAGS[\"eval_samples\"])\n    model.save_weights(os.path.join(FLAGS[\"model_dir\"], 'model'))\n\n\nif __name__ == '__main__':\n  main(FLAGS)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}