{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_path = \"../input/global-wheat-detection/\"\ntrainImg_path = dataset_path+\"train/\"\n\n# def class_to_id(class_name):\n#     return{\n#         'usask_1':0,\n#         'arvalis_1': 1,\n#         'inrae_1': 2,\n#         'ethz_1': 3,\n#         'arvalis_3': 4,\n#         'rres_1': 5,\n#         'arvalis_2': 6,\n#     }[class_name]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\n\nif not os.path.exists('training_data'):\n    os.makedirs('training_data')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import csv\n# import shutil as sh\n\n# # 開啟 CSV 檔案\n# n = 0\n# with open(dataset_path+'train.csv', newline='') as csvfile:\n\n#   # 讀取 CSV 檔案內容\n#   rows = csv.reader(csvfile)\n\n#   # 以迴圈輸出每一列\n#   for row in rows:\n#     imgId = row[0]\n#     if imgId=='image_id':\n#         continue\n#     print(imgId)\n#     width = row[1]\n#     height = row[2]\n    \n# #     print(row[3])\n#     bbox = []\n#     b = ''\n#     for r in row[3]:\n#         r = ord(r)\n#         if (r>=48 and r<=57) or r==46:\n#             b += chr(r)\n#         elif r ==44 or r==93:\n#             bbox.append(float(b))\n#             b = ''\n#     class_name = row[4]\n    \n# #     print(imgId, width, height, bbox, class_name, classId)\n    \n#     _l = int(bbox[0])\n#     _t = int(bbox[1])\n    \n#     x_center = (_l+int(bbox[2])/2)/int(width)\n#     y_center = (_t+int(bbox[3])/2)/int(height)\n#     bbox_width = int(bbox[2])/int(width)\n#     bbox_height = int(bbox[3])/int(height)\n    \n# #     classId = class_to_id(class_name)\n    \n#     s = '0 '+str(x_center)+' '+str(y_center)+' '+str(bbox_width)+' '+str(bbox_height)+'\\n'\n# #     print(s)\n\n#     fp = open('training_data/'+str(imgId)+'.txt', 'a')\n#     fp.write(s)\n#     fp.close()\n#     if not os.path.isfile('training_data/{}.jpg'.format(imgId)):\n#         sh.copy(\"../input/global-wheat-detection/train/{}.jpg\".format(imgId),'training_data/{}.jpg'.format(imgId))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !ls ./training_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f = open('wheat.yaml', 'w')\n\nf.write('train: ./training_data \\n')\nf.write('val: ./training_data \\n')\nf.write('test: ./testing_data \\n')\nf.write('\\n')\nf.write('nc: 1 \\n')\nf.write('\\n')\nf.write(\"names: ['wheat'] \\n\")\nf.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat wheat.yaml","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cp ../input/yolov5train/models/yolov5m.yaml yolov5m_wheat.yaml","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# f = open('../input/yolov5train/models/yolov5m.yaml', 'r')\n\n# s = f.readlines()\n# s[1] = \"nc: 7  # number of classes\\n\"\n# print(s[1])\n\n# fw = open('yolov5m_wheat.yaml', 'w')\n# fw.writelines(s)\n# fw.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !cat yolov5m_wheat.yaml","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ls ../input/global-wheat-detection/test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !python ../input/yolov5code/yolov5-master/train.py --device 0 --img-size 320 --batch-size 16 --epochs 1 --data wheat.yaml --cfg yolov5m_wheat.yaml","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!cp -r ../input/global-wheat-detection/test testing_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !python ../input/yolov5code/yolov5-master/test.py --task test --device 0 --weights ../input/yolov5m-320-16-50/best.pt --data wheat.yaml --img-size 320 --batch-size 16 --save-json --save-txt --name result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !cat runs/test/result/best_predictions.json","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predict"},{"metadata":{"trusted":true},"cell_type":"code","source":"# def detect():\n#     source = '../input/global-wheat-detection/test/'\n#     weights = '../input/yolov5m-320-160-50-wheat1/best.pt'\n# #     if not os.path.exists(weights):\n# #         weights = '../input/bestweight/best_yolov5x_fold0.pt'\n#     imgsz = 1024\n#     conf_thres = 0.5\n#     iou_thres = 0.6\n#     is_TTA = True\n    \n#     imagenames =  os.listdir(source)\n    \n#     device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n\n#     # Load model\n#     model = torch.load(weights, map_location=device)['model'].float()  # load to FP32\n#     model.to(device).eval()\n    \n#     dataset = LoadImages(source, img_size=imgsz)\n\n#     results = []\n#     fig, ax = plt.subplots(5, 2, figsize=(30, 70))\n#     count = 0\n#     # img = torch.zeros((1, 3, imgsz, imgsz), device=device)  # init img\n#     #for path, img, im0s, _ in dataset:\n#     for name in imagenames:\n#         image_id = name.split('.')[0]\n#         im01 = cv2.imread('%s/%s.jpg'%(source,image_id))  # BGR\n#         assert im01 is not None, 'Image Not Found '\n#         # Padded resize\n#         im_w, im_h = im01.shape[:2]\n#         if is_TTA:\n#             enboxes = []\n#             enscores = []\n#             for i in range(4):\n#                 im0 = TTAImage(im01, i)\n#                 boxes, scores = detect1Image(im0, imgsz, model, device, conf_thres, iou_thres)\n#                 for _ in range(3-i):\n#                     boxes = rotBoxes90(boxes, im_w, im_h)\n                    \n#                 if 1: #i<3:\n#                     enboxes.append(boxes)\n#                     enscores.append(scores) \n#             boxes, scores = detect1Image(im01, imgsz, model, device, conf_thres, iou_thres)\n#             enboxes.append(boxes)\n#             enscores.append(scores)\n\n#             boxes, scores, labels = run_wbf(enboxes, enscores, image_size = im_w, iou_thr=0.6, skip_box_thr=0.5)\n#             boxes = boxes.astype(np.int32).clip(min=0, max=im_w)\n#         else:\n#             boxes, scores = detect1Image(im01, imgsz, model, device, conf_thres, iou_thres)\n\n#         boxes[:, 2] = boxes[:, 2] - boxes[:, 0]\n#         boxes[:, 3] = boxes[:, 3] - boxes[:, 1]\n        \n#         boxes = boxes[scores >= 0.05].astype(np.int32)\n#         scores = scores[scores >=float(0.05)]\n#         if count<10:\n#             #sample = image.permute(1,2,0).cpu().numpy()\n#             for box, score in zip(boxes,scores):\n#                 cv2.rectangle(im0,\n#                               (box[0], box[1]),\n#                               (box[2]+box[0], box[3]+box[1]),\n#                               (220, 0, 0), 2)\n#                 cv2.putText(im0, '%.2f'%(score), (box[0], box[1]), cv2.FONT_HERSHEY_SIMPLEX ,  \n#                    0.5, (255,255,255), 2, cv2.LINE_AA)\n#             ax[count%5][count//5].imshow(im0)\n#             count+=1\n            \n#         result = {\n#             'image_id': image_id,\n#             'PredictionString': format_prediction_string(boxes, scores)\n#         }\n\n#         results.append(result)\n#     return results","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Detect"},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm submission.csv","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Change This!!!!"},{"metadata":{"trusted":true},"cell_type":"code","source":"!python ../input/yolov5code/yolov5-master/detect.py --source ../input/global-wheat-detection/test --device 0 --weight ../input/yolov5l-160-32-50-wheat/color.pt --conf 0.3 --save-txt --save-conf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import os\n# import cv2\n# import csv\n\n# def submit(l_path, test_path):\n#     label_path = l_path\n#     label_files = list(sorted(os.listdir(label_path)))\n# #     print(label_files)\n    \n#     csvfile = open('submission.csv', 'a')\n#     writer = csv.writer(csvfile)\n#     writer.writerow(['image_id', 'PredictionString'])\n\n#     for file in label_files:\n#         f = open(label_path+file,'r')\n#         contents = f.readlines()\n        \n#         img_name = file.replace('.txt', '.jpg')\n#         print(img_name)\n#         im = cv2.imread(test_path+img_name)\n#         h, w, c = im.shape\n#         print(h, w, c)\n        \n#         PredictionString = ''\n#         for content in contents:\n#             content = content.replace('\\n','')\n#             c = content.split(' ')\n#             print(c)\n            \n#             w_center = w*float(c[1])\n#             h_center = h*float(c[2])\n#             width = w*float(c[3])\n#             height = h*float(c[4])\n#             left = int(w_center - width/2)\n# #             right = int(w_center + width/2)\n#             top = int(h_center - height/2)\n# #             bottom = int(h_center + height/2)\n#             score = float(c[5])\n    \n#             s = str(score)+' '+str(left)+' '+str(top)+' '+str(round(width))+' '+str(round(height))+' '\n#             PredictionString += s\n# #             print(score, left, top, round(width), round(height))\n#         print(PredictionString)\n#         imgId = file.replace('.txt', '')\n#         writer.writerow([imgId, PredictionString])\n        \n\n\n# label_path = './runs/detect/exp/labels/'\n# testImg_path = '../input/global-wheat-detection/test/'\n# submit(label_path, testImg_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!cat ./submission.csv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd # 引用套件並縮寫為 pd  \ndf = pd.read_csv('submission.csv')  \nprint(df)  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# RCNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        \n        os.path.join(dirname, filename)\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torch\nimport cv2\nfrom torchvision import datasets,transforms\nfrom glob import glob\nimport os\nfrom PIL import Image\nfrom matplotlib import patches\nfrom torch.utils.data import Dataset\nimport torchvision\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\nfrom torchvision.models.detection import FasterRCNN\nfrom torchvision.models.detection.rpn import AnchorGenerator\nfrom torch.utils.data import DataLoader\n#Albumentation\nimport albumentations as al\nfrom albumentations.pytorch.transforms import ToTensorV2\n\ntrain_dir ='/kaggle/input/global-wheat-detection/train/'\ntest_dir = '/kaggle/input/global-wheat-detection/test/'\ntrain = pd.read_csv('../input/global-wheat-detection/train.csv') \nweights = '../input/fasterrcnn-resnet50-fpn/fasterrcnn_resnet50_fpn (1).pth'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample = pd.read_csv('../input/global-wheat-detection/sample_submission.csv')\nsample.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Wheatdatasets(Dataset):\n    \n    def __init__(self,dataframe,image_dir,transforms = None):\n        \n        super().__init__()\n    \n        self.image_id = dataframe['image_id'].unique()\n        self.df = dataframe\n        self.img_dir = image_dir\n        self.transforms = transforms\n        \n    def __getitem__(self,index:int):\n        \n        image_id = self.image_id[index]\n        record = self.df[self.df['image_id']==image_id]\n        \n        image = cv2.imread(self.img_dir+image_id+'.jpg',cv2.IMREAD_COLOR)\n        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB).astype(np.float32)\n        image = image/255.0\n       \n        if self.transforms:\n            sample ={\n                'image':image\n            }\n            sample =self.transforms(**sample)\n            image = sample['image']\n            \n            return image,image_id\n        \n    def __len__(self) -> int:\n        return self.image_id.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_transform():\n    return al.Compose([\n        ToTensorV2(p=1.0)\n    ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create the Model\nmodel = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained = False,pretrained_backbone=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else 'cpu'\nnum_class = 2 #wheats and background\n\nin_feature = model.roi_heads.box_predictor.cls_score.in_features\n\nmodel.roi_heads.box_predictor = FastRCNNPredictor(in_feature,num_class) #changin the pretrained head with a new one\n\nmodel.load_state_dict(torch.load(weights))\nmodel.eval()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = model.to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def collate_fn(batch):\n    return tuple(zip(*batch))\n\n\ntest_dataset = Wheatdatasets(sample,test_dir,get_transform())\n\n\n\ntest_dataloader = DataLoader(\ntest_dataset,\nbatch_size=4,\nshuffle =False,\nnum_workers =4,drop_last = False,\ncollate_fn = collate_fn)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def format_string(boxes,score):\n    pred_strings = []\n    for j in zip(score,boxes):\n        \n        pred_strings.append(\"{0:.4f} {1} {2} {3} {4}\".format(j[0], j[1][0], j[1][1], j[1][2], j[1][3]))\n        \n    return \" \".join(pred_strings)\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"detection_threshold = 0.5\nresults = []\n\nfor images, image_ids in test_dataloader:\n\n    images = list(image.to(device) for image in images)\n    outputs = model(images)\n\n    for i, image in enumerate(images):\n\n        boxes = outputs[i]['boxes'].data.cpu().numpy()\n        scores = outputs[i]['scores'].data.cpu().numpy()\n        \n        boxes = boxes[scores >= detection_threshold].astype(np.int32)\n        scores = scores[scores >= detection_threshold]\n        image_id = image_ids[i]\n        \n        boxes[:, 2] = boxes[:, 2] - boxes[:, 0]\n        boxes[:, 3] = boxes[:, 3] - boxes[:, 1]\n        \n        result = {\n            'image_id': image_id,\n            'PredictionString': format_string(boxes, scores)\n        }\n\n        \n        results.append(result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results[:2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.DataFrame(results, columns=['image_id', 'PredictionString'])\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sample = images[0].permute(1,2,0).cpu().numpy()\n# boxes = outputs[0]['boxes'].data.cpu().numpy()\n# score = outputs[0]['scores'].data.cpu().numpy()\n\n# boxes = boxes[score >= detection_threshold].astype(np.int32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n\n# for box in boxes:\n#     cv2.rectangle(sample,\n#                   (box[0], box[1]),\n#                   (box[2], box[3]),\n#                   (220, 0, 0), 2)\n    \n# ax.set_axis_off()\n# ax.imshow(sample)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_id = list(test_df['image_id'])\nprint(img_id)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df['image_id']\n# # df = df.drop([0, 1])\n# # df.reset_index(drop='true')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_df.loc[test_df['image_id'] == i]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in img_id:\n    q = df.loc[df['image_id'] == i]\n    if q.empty:\n        print(i)\n        p = test_df.loc[test_df['image_id'] == i]['PredictionString'].item()\n        df2 = pd.DataFrame([[i, p]], columns=['image_id','PredictionString'])\n        print(df2)\n        df = df.append(df2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !cat 'submission.csv'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}