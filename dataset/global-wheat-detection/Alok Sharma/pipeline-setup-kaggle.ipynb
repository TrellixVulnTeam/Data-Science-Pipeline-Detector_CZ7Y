{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv))\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport pathlib\nfrom fastai.basics import L\nfrom ast import literal_eval\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\nfrom fastai.vision.all import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_imgs_path = pathlib.Path('/kaggle/input/global-wheat-detection/train')\ntest_imgs_path = pathlib.Path('/kaggle/input/global-wheat-detection/test/')\ntrain_img_bbox_df = pd.read_csv(pathlib.Path('/kaggle/input/global-wheat-detection/train.csv'), delimiter=',')\ntrain_img_bbox_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_img_bbox_df\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_img_ids = L([im[:-4] for im in os.listdir(train_imgs_path) if im.find('.jpg') != -1])\ntrain_img_ids","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_img_ids = L([im[:-4] for im in os.listdir(test_imgs_path) if im.find('.jpg') != -1])\ntest_img_ids","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def image2bbox(img_id, image_dir_path):\n    bbox = train_img_bbox_df[train_img_bbox_df['image_id']==img_id]['bbox'].apply(lambda x: literal_eval(x))\n    img_name=img_id+'.jpg'\n    img_path = pathlib.Path(image_dir_path/img_name)\n    labels =[]\n    if len(bbox) > 0:\n        bbox = bbox.apply(lambda x: [a if idx <2 else a+x[idx-2] for idx,a in enumerate(x)]) #dataset has boboxes encoded [x_topleft, y_topleft, width, height]\n        labels = ['True']*len(bbox) \n\n    return img_path, bbox.tolist(), labels\n\n# test for an image\ni, b,l = image2bbox('b6ab77fd7', train_imgs_path)\nraw_bbox = train_img_bbox_df[train_img_bbox_df['image_id']=='b6ab77fd7']['bbox']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(b[0])\nprint(raw_bbox[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dict ={k:image2bbox(k, train_imgs_path) for k in train_img_ids}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Data dict size (num unique images): ', len(data_dict))\npositives_dict ={ k : v for k,v in data_dict.items() if len(v[1])>0 }\nnegatives_dict= { k: v for k,v in data_dict.items() if len(v[1])==0 }\nprint ('Num negatives: ', len(negatives_dict))\nprint('Num Positives: ', len(positives_dict))\n","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"train_db = DataBlock(blocks = (ImageBlock, BBoxBlock, BBoxLblBlock),\n                    get_items=get_image_files,\n                    splitter= RandomSplitter(),\n                    get_y= [lambda o:data_dict[o.name[:-4]][1], lambda o:data_dict[o.name[:-4]][2]],\n                    item_tfms =  [Resize(512, method='resize')],\n                    batch_tfms = [Normalize()],\n                    n_inp=1)\ntrain_db.summary(train_imgs_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dls=train_db.dataloaders(train_imgs_path,bs=1, verbose=True)\ntrain_dl = dls.train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image\ndef show_sample_batch(dl, max_n=2):\n    x,y1,y2=next(iter(dl))\n    print(x.shape)\n    print(y1.shape)\n    print(y2.shape)\n    xd,y1d,y2d = dl.decode((x,y1,y2))\n    xd = np.uint8(xd.numpy().squeeze())\n    xd = np.transpose(xd, axes=[1,2,0])\n    print(xd.shape)\n    return xd, y1d, y2d\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimg, y1, y2 = show_sample_batch(train_dl)\nax = plt.imshow(img)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"#Lets try to put the RetinaNet together using stuff from all around\nbackbone = create_body(resnet18, pretrained=True, cut=-2)\nbackbone","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}