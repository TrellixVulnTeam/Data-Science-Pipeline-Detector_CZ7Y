{"cells":[{"metadata":{},"cell_type":"markdown","source":"<a id=\"toc\"></a>\n# Table of Contents\n1. [Import libraries](#import_libraries)\n1. [Configure hyper-parameters](#configure_hyper_parameters)\n1. [Define helper-functions](#define_helper_functions)\n1. [Resize images and corresponding bboxes](#resize_images_and_corresponding_bboxes)\n1. [Save and compress the results](#save_and_compress_the_result)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id=\"import_libraries\"></a>\n# Import libraries\n[Bach to Table of Contents](#toc)","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pathlib\nfrom pathlib import Path\nimport json\n\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport albumentations as A\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"configure_hyper_parameters\"></a>\n# Configure hyper-parameters\n[Bach to Table of Contents](#toc)","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"ROOT = Path('/kaggle/input/global-wheat-detection/')\nTRAIN_DIR = ROOT / 'train'\nTEST_DIR = ROOT / 'test'\n\nWORKING_DIR = Path('/kaggle/working/')\n\nIMG_SIZE = 224","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"define_helper_functions\"></a>\n# Define helper-functions\n[Bach to Table of Contents](#toc)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_dataframe(csv_path: pathlib.PosixPath, image_dir: pathlib.PosixPath) -> pd.DataFrame:\n    df = pd.read_csv(csv_path)\n    \n    # Merge all bboxes of each corresponding image\n    # Format: [[x1 y1 w1 h1], [x2 y2 w2 h2], [x3 y3 w3 h3], ...]\n    df.bbox = df.bbox.apply(lambda x: ' '.join(np.array(json.loads(x), dtype=str)))\n    df.bbox = df.groupby(['image_id']).bbox.transform(lambda x: '|'.join(x))\n    df.drop_duplicates(inplace=True, ignore_index=True)\n    df.bbox = df.bbox.apply(lambda x: np.array([item.split(' ') for item in x.split('|')], dtype=np.float32).tolist())\n    \n    # Create a path to each image\n    df['image_path'] = df.image_id.apply(lambda x: str(image_dir / (x + '.jpg')))\n    \n    return df\n\ndef load_image(image_path: str) -> np.array:\n    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n\n    return image\n\ndef fix_out_of_range(bbox: list, max_size: int = 1024) -> list:\n    bbox[2] = min(bbox[2], max_size - bbox[0])\n    bbox[3] = min(bbox[3], max_size - bbox[1])\n\n    return bbox","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = load_dataframe(ROOT / 'train.csv', TRAIN_DIR)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"resize_images_and_corresponding_bboxes\"></a>\n# Resize images and corresponding bboxes\n[Bach to Table of Contents](#toc)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"mkdir train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = A.Compose(\n    [\n        A.Resize(height=IMG_SIZE, width=IMG_SIZE, p=1),\n    ], \n    p=1.0, \n    bbox_params=A.BboxParams(\n        format='coco',\n        min_area=0, \n        min_visibility=0,\n        label_fields=['labels']\n    )\n)\n\nlist_of_image_ids = []\nlist_of_bboxes = []\nlist_of_sources = []\n\nfor idx, row in tqdm(df.iterrows(), total=df.shape[0]):\n    image = load_image(row.image_path)\n    bboxes = row.bbox\n\n    # Fix \"out-of-range\" bboxes\n    bboxes = [fix_out_of_range(bbox) for bbox in bboxes]\n    \n    result = transform(image=image, bboxes=bboxes, labels=np.ones(len(bboxes)))\n    new_image = result['image']\n    new_bboxes = np.array(result['bboxes']).tolist()\n    \n    # Save new image\n    cv2.imwrite(str(WORKING_DIR / 'train' / (row.image_id + '.jpg')), new_image)\n\n    for new_bbox in new_bboxes:\n        list_of_image_ids.append(row.image_id)\n        list_of_bboxes.append(new_bbox)\n        list_of_sources.append(row.source)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_data_dict = {\n    'image_id': list_of_image_ids,\n    'width': [IMG_SIZE] * len(list_of_image_ids),\n    'height': [IMG_SIZE] * len(list_of_image_ids),\n    'bbox': list_of_bboxes,\n    'source': list_of_sources\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df = pd.DataFrame(new_data_dict)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"save_and_compress_the_result\"></a>\n# Save and compress the results\n[Bach to Table of Contents](#toc)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df.to_csv('train.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!cp $ROOT/sample_submission.csv ./\n!cp -r $ROOT/test ./","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!zip -rm -qq global-wheat-detection.zip train test train.csv sample_submission.csv","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}