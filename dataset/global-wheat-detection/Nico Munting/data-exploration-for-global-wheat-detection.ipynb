{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Import modules\nImport all modules we will use for data analysis"},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"import os\nfrom ast import literal_eval\n\nimport numpy as np\nimport pandas as pd\n\nimport cv2\n\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Import provided data"},{"metadata":{},"cell_type":"markdown","source":"First, we create a list of images in our train directory and we plot a sample of the available files. "},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"train_img_path = '../input/global-wheat-detection/train'\n\ntrain_files = os.listdir(train_img_path)\ntrain_list = [x[:-4] for x in train_files]\n\ntrain_ids = pd.DataFrame(train_list, columns=['image_id'])\ntrain_ids = train_ids.set_index('image_id')\n\ntrain_ids_sample = train_ids.sample(n=25)\n\nfig, axs = plt.subplots(nrows=5, ncols=5, figsize=(20, 20),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axs.flat):\n    image_id = train_ids_sample.iloc[i].name\n    image_bgr = cv2.imread(\"%s/%s.jpg\" % (train_img_path, image_id))\n    image = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n    ax.imshow(image)\n    ax.set_title(image_id)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Second, we do the same thing for the test images."},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"test_img_path = '../input/global-wheat-detection/test'\n\ntest_files = os.listdir(test_img_path)\ntest_list = [x[:-4] for x in test_files]\n\ntest_ids = pd.DataFrame(test_list, columns=['image_id'])\ntest_ids = test_ids.set_index('image_id')\n\nfig, axs = plt.subplots(nrows=2, ncols=5, figsize=(20, 10),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axs.flat):\n    image_id = test_ids.iloc[i].name\n    image_bgr = cv2.imread(\"%s/%s.jpg\" % (test_img_path, image_id))\n    image = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n    ax.imshow(image)\n    ax.set_title(image_id)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Third, we import the supplied CSV-files and have a look at a sample of the files that we imported."},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"train_meta = pd.read_csv('../input/global-wheat-detection/train.csv',\n                    converters={'bbox': literal_eval})\nsample_submission = pd.read_csv('../input/global-wheat-detection/sample_submission.csv')\n\nprint(train_meta)\nprint(sample_submission)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Combining metadata and images\n\nThe image IDs can occur multiple times in the CSV-file as there usually are multiple bounding boxes for each image. We count the number of bounding boxes per image and join this information to the list of unique images we created earlier."},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"# Get info about images from train.csv\ntrain_info = train_meta.groupby('image_id').agg({\n    'width': np.min, 'height': np.min, 'bbox': np.size})\ntrain_info = train_info.rename(columns={'bbox': 'bbox_no'})\n\n# Join image info to our original list of images\ntrain = pd.merge(train_ids, train_info, on='image_id', how='left')\nprint(train.info())\n\ntrain_no_info = train[train['bbox_no'].isnull()]\nprint(train_no_info.info())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Apparently, not all images have bounding boxes defined. Let's plot some of the images without bounding boxes to see if this is correct."},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"train_no_info_sample = train_no_info.sample(n=25)\n\nfig, axs = plt.subplots(nrows=5, ncols=5, figsize=(20, 20),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axs.flat):\n    image_id = train_no_info_sample.iloc[i].name\n    image_bgr = cv2.imread(\"%s/%s.jpg\" % (train_img_path, image_id))\n    image = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n    ax.imshow(image)\n    ax.set_title(image_id)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Bounding boxes\n## Number of boxes\n\nBased on the images it seems to be correct that there are no bounding boxes for these images. There do not seem to be any wheat heads in these images. Based on this we set the number of bounding boxes to 0 for these images. Now we can plot a histogram of the number of bounding boxes. "},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"train[train['bbox_no'].isnull()] = 0\n\nfig, ax = plt.subplots()\n_ = ax.hist(train['bbox_no'], bins=50)\n_ = ax.set_xlabel('No. of bounding boxes')\n_ = ax.set_ylabel('Frequency')\n_ = ax.set_title('Histogram of bounding boxes per image')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we plot a sample of images again, but this time we also plot the accompanying bounding boxes. "},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"train_sample = train.sample(n=25)\n\nfig, axs = plt.subplots(nrows=5, ncols=5, figsize=(20, 20),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axs.flat):\n    image_id = train_sample.iloc[i].name\n\n    image_bgr = cv2.imread(\"%s/%s.jpg\" % (train_img_path, image_id))\n    image = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n    bboxes = train_meta[train_meta['image_id'] == image_id]['bbox']    \n    \n    ax.imshow(image)\n    ax.set_title(image_id)\n    \n    # draw rectangle for each bounding box\n    for bbox in bboxes:\n        [xmin, ymin, width, height] = bbox\n        ax.add_patch(\n            plt.Rectangle((xmin, ymin), width, height,\n                          fill=False, edgecolor='r', linewidth=2, alpha=0.5)\n        )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Size and shape of boxes"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_meta['box_width'] = train_meta['bbox'].apply(lambda x: x[2])\ntrain_meta['box_height'] = train_meta['bbox'].apply(lambda x: x[3])\n\nfig, ax = plt.subplots()\n_ = ax.scatter(train_meta['box_width'], train_meta['box_height'])\n_ = ax.set_xlabel('Bounding box width (pixels)')\n_ = ax.set_ylabel('Bounding box height (pixels)')\n_ = ax.set_title('Scatter plot of bounding box width and heigth')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Big boxes \nSome bounding boxes appear to be suspicously big. We will have a detailed look at bounding boxes with a width or height more than 400 pixels. "},{"metadata":{"trusted":true},"cell_type":"code","source":"train_meta_outlier_box = train_meta[\n                                    (train_meta['box_width'] < 10)\n                                    | (train_meta['box_height'] < 10)\n                                    | (train_meta['box_width'] > 400)\n                                    | (train_meta['box_height'] > 400)\n                                  ]\n\ntrain_outlier_box = train_meta_outlier_box[['image_id', 'bbox']].groupby('image_id').agg({\n    'bbox': np.size})\ntrain_outlier_box = train_outlier_box.rename(columns={'bbox': 'bbox_no'})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now that we have our selection, we will plot a sample of the images with outlier boxes with the outlier bounding boxes only. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_outlier_box_sample = train_outlier_box.sample(n=25)\n\ntrain_outlier_box_sample = train[:4]\n\nfig, axs = plt.subplots(nrows=2, ncols=2, figsize=(20, 20),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axs.flat):\n    image_id = train_outlier_box_sample.iloc[i].name\n\n    image_bgr = cv2.imread(\"%s/%s.jpg\" % (train_img_path, image_id))\n    image = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n#     bboxes = train_meta_outlier_box[train_meta_outlier_box['image_id'] == image_id]['bbox']    \n    bboxes = train_meta[train_meta['image_id'] == image_id]['bbox']        \n    \n    ax.imshow(image)\n    ax.set_title(image_id)\n    \n    # draw rectangle for each bounding box\n    for bbox in bboxes:\n        [xmin, ymin, width, height] = bbox\n        ax.add_patch(\n            plt.Rectangle((xmin, ymin), width, height,\n                          fill=False, edgecolor='red', linewidth=5, alpha=1)\n        )","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}