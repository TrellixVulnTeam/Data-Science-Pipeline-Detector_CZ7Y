{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Object detection with Detecto\n[Detecto](https://github.com/alankbi/detecto) is a Python library built on top of PyTorch that simplifies the process of building object detection models. Only a few lines of code is needed to train a model. Let's give it a spin on the Global Wheat Detection dataset.","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import torch\nimport os, sys, ast\nimport pandas as pd\nimport numpy as np\nimport glob\nimport shutil\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Import annotation data\nStart by reading annotation data from the .csv file.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"DATA = '/kaggle/input/global-wheat-detection/'\ndf=pd.read_csv(DATA+\"train.csv\")\ndf.bbox = df.bbox.apply(ast.literal_eval)\nfor i in range(len(df)):\n    df.bbox.iloc[i][2]=df.bbox.iloc[i][0]+df.bbox.iloc[i][2] # xmax\n    df.bbox.iloc[i][3]=df.bbox.iloc[i][1]+df.bbox.iloc[i][3] # ymax\ndf.sample(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Copy a subset of training data\nDetecto wants training and validation data in separate folders. So below we will take a subset (to speed things up) of the training data and copy into local folders.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%mkdir train\n%mkdir validate\n\nfiles = glob.glob(DATA+\"train/*\")\ntrain, validate, rest = np.split(files, [int(len(files)*0.2), int(len(files)*0.25)])\nfor i in range(len(train)):\n    shutil.copy2(train[i], './train')\nfor i in range(len(validate)):\n    shutil.copy2(validate[i], './validate')\nlen(train), len(validate), len(rest)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Install Detecto\nDetecto is installed from a dataset, since internet is turned off. We also need the faster-rcnn pre-trained model, again fetched from a dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%%capture\n!mkdir -p /tmp/pip/cache/\n!cp /kaggle/input/detecto-install/detecto-1.1.3.xyz /tmp/pip/cache/detecto-1.1.3.tar.gz\n!cp /kaggle/input/detecto-install/detecto-1.1.3-py3-none-any.whl /tmp/pip/cache/\n!pip install --no-index --find-links /tmp/pip/cache/ detecto\n!mkdir -p /root/.cache/torch/checkpoints/\n!cp /kaggle/input/faster-rcnn/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth /root/.cache/torch/checkpoints/","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualize\nLet's start by visualizing a random image.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from detecto import utils, visualize, core\n\nplt.rcParams['figure.figsize'] = (12.0, 12.0)\n\nfiles = glob.glob(\"./train/*\")\nfor i in range(len(files)):\n    fid = files[i].replace('./train/', '').split('.')[0]\n    bx = df[df.image_id == fid]\n    if len(bx) > 0:\n        boxes=torch.FloatTensor(bx.bbox.tolist())\n        image = utils.read_image('./train/'+fid+'.jpg')\n        visualize.show_labeled_image(image, boxes)\n        break","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create Pascal VOC data\nDetecto expects annotation data in Pascal VOC format. And thus we need to install the pascal-voc-writer.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%%capture\n# install Pascal VOC writer from dataset\n!cp /kaggle/input/detecto-install/pascal_voc_writer-0.1.4-py3.6.egg /tmp/pip/cache/\n!cp /kaggle/input/detecto-install/pascal_voc_writer-0.1.4-py2.py3-none-any.whl /tmp/pip/cache/\n!pip install --no-index --find-links /tmp/pip/cache/ pascal_voc_writer","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create Pascal VOC .xml files, one for each image:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from pascal_voc_writer import Writer\n\nLABEL = \"Wheat\"\ndef create_voc(folder):\n    files = glob.glob(folder+\"/*\")\n    for i in range(len(files)):\n        fid = files[i].replace(folder+'/','').split('.')[0]\n        ldf=df[df.image_id == fid].reset_index()\n        if len(ldf)> 0:\n            width, height = ldf.width.iloc[0], ldf.height.iloc[0]\n            writer = Writer(fid+'.jpg', width, height)\n            for j in range(len(ldf)):\n                writer.addObject(LABEL, \n                                 int(ldf.bbox.iloc[j][0]), \n                                 int(ldf.bbox.iloc[j][1]), \n                                 int(ldf.bbox.iloc[j][2]),\n                                 int(ldf.bbox.iloc[j][3]))\n            writer.save(folder+'/'+fid+'.xml')\n        \ncreate_voc(\"./validate\")\ncreate_voc(\"./train\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train model\nTraining is super simple, just a few lines:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = core.Dataset('./train/')\nloader = core.DataLoader(dataset, batch_size=16, shuffle=True)\nval_dataset = core.Dataset('./validate/')\nmodel = core.Model([LABEL])\nlosses = model.fit(loader, val_dataset, epochs=2, learning_rate=0.001, lr_step_size=5, verbose=True)\nprint(losses)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#cleanup\n!rm -fr train\n!rm -fr validate","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Predict\nThen we can do predictions:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"tfiles = glob.glob(DATA+\"test/*\")\npredf=pd.DataFrame(columns=['image_id', 'PredictionString'])\nfor i in range(len(tfiles)):\n    image = utils.read_image(tfiles[i])\n    fid = tfiles[i].replace(DATA+'test/','').split('.')[0]\n    predictions = model.predict(image)\n    labels, boxes, scores = predictions\n    b=boxes.numpy().astype(int)\n    s=scores.numpy()\n    pstr=''\n    for i in range(len(b)):\n        p=[b[i][0], b[i][1], b[i][2]-b[i][0], b[i][3]-b[i][1]]\n        pstr=pstr+str(s[i])+' '+str(p[0])+' '+str(p[1])+' '+str(p[2])+' '+str(p[3])+' '\n    predf=predf.append({'image_id': fid, 'PredictionString': pstr}, ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submit\nAnd finally submit the data:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"predf.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}