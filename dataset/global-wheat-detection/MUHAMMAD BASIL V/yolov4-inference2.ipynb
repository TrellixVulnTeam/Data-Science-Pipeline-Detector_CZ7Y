{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom keras.models import Sequential\nimport keras\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input,Dense,Activation,ZeroPadding2D,BatchNormalization,Flatten,Conv2D,MaxPool2D,Dropout,Reshape,Add,Conv2DTranspose,Concatenate\nfrom keras.layers import LeakyReLU\nfrom tensorflow.keras.models import Model\nimport tensorflow.keras.backend as K\nfrom keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.models import load_model\nimport cv2\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport matplotlib.patches as patches","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import tensorflow as tf\n# import tensorflow_addons as tfa\nclass BatchNormalization(tf.keras.layers.BatchNormalization):\n    \"\"\"\n    \"Frozen state\" and \"inference mode\" are two separate concepts.\n    `layer.trainable = False` is to freeze the layer, so the layer will use\n    stored moving `var` and `mean` in the \"inference mode\", and both `gama`\n    and `beta` will not be updated !\n    \"\"\"\n    def call(self, x, training=False):\n        if not training:\n            training = tf.constant(False)\n        training = tf.logical_and(training, self.trainable)\n        return super().call(x, training)\n\ndef convolutional(input_layer, filters_shape, downsample=False, activate=True, bn=True, activate_type='leaky'):\n    if downsample:\n        input_layer = tf.keras.layers.ZeroPadding2D(((1, 0), (1, 0)))(input_layer)\n        padding = 'valid'\n        strides = 2\n    else:\n        strides = 1\n        padding = 'same'\n\n    conv = tf.keras.layers.Conv2D(filters=filters_shape[-1], kernel_size = filters_shape[0], strides=strides, padding=padding,\n                                  use_bias=not bn, kernel_regularizer=tf.keras.regularizers.l2(0.0005),\n                                  kernel_initializer=tf.random_normal_initializer(stddev=0.01),\n                                  bias_initializer=tf.constant_initializer(0.))(input_layer)\n\n    if bn: conv = BatchNormalization()(conv)\n    if activate == True:\n        if activate_type == \"leaky\":\n            conv = tf.nn.leaky_relu(conv, alpha=0.1)\n        elif activate_type == \"mish\":\n            conv = mish(conv)\n            # conv = softplus(conv)\n            # conv = conv * tf.math.tanh(tf.math.softplus(conv))\n            # conv = conv * tf.tanh(softplus(conv))\n            # conv = tf.nn.leaky_relu(conv, alpha=0.1)\n            # conv = tfa.activations.mish(conv)\n            # conv = conv * tf.nn.tanh(tf.keras.activations.relu(tf.nn.softplus(conv), max_value=20))\n            # conv = tf.nn.softplus(conv)\n            # conv = tf.keras.activations.relu(tf.nn.softplus(conv), max_value=20)\n\n    return conv\ndef softplus(x, threshold = 20.):\n    def f1():\n        return x\n    def f2():\n        return tf.exp(x)\n    def f3():\n        return tf.math.log(1 + tf.exp(x))\n    # mask = tf.greater(x, threshold)\n    # x = tf.exp(x[mask])\n    # return tf.exp(x)\n    return tf.case([(tf.greater(x, tf.constant(threshold)), lambda:f1()), (tf.less(x, tf.constant(-threshold)), lambda:f2())], default=lambda:f3())\n    # return tf.case([(tf.greater(x, threshold), lambda:f1())])\ndef mish(x):\n    return tf.keras.layers.Lambda(lambda x: x*tf.tanh(tf.math.log(1+tf.exp(x))))(x)\n    # return tf.keras.layers.Lambda(lambda x: softplus(x))(x)\n    # return tf.keras.layers.Lambda(lambda x: x * tf.tanh(softplus(x)))(x)\n\ndef residual_block(input_layer, input_channel, filter_num1, filter_num2, activate_type='leaky'):\n    short_cut = input_layer\n    conv = convolutional(input_layer, filters_shape=(1, 1, input_channel, filter_num1), activate_type=activate_type)\n    conv = convolutional(conv       , filters_shape=(3, 3, filter_num1,   filter_num2), activate_type=activate_type)\n\n    residual_output = short_cut + conv\n    return residual_output\n\n# def block_tiny(input_layer, input_channel, filter_num1, activate_type='leaky'):\n#     conv = convolutional(input_layer, filters_shape=(3, 3, input_channel, filter_num1), activate_type=activate_type)\n#     short_cut = input_layer\n#     conv = convolutional(conv, filters_shape=(3, 3, input_channel, filter_num1), activate_type=activate_type)\n#\n#     input_data = tf.concat([conv, short_cut], axis=-1)\n#     return residual_output\n\ndef route_group(input_layer, groups, group_id):\n    convs = tf.split(input_layer, num_or_size_splits=groups, axis=-1)\n    return convs[group_id]\n\ndef upsample(input_layer):\n    return tf.image.resize(input_layer, (input_layer.shape[1] * 2, input_layer.shape[2] * 2), method='bilinear')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def cspdarknet53(input_data):\n\n    input_data = convolutional(input_data, (3, 3,  3,  32), activate_type=\"mish\")\n    input_data = convolutional(input_data, (3, 3, 32,  64), downsample=True, activate_type=\"mish\")\n\n    route = input_data\n    route = convolutional(route, (1, 1, 64, 64), activate_type=\"mish\")\n    input_data = convolutional(input_data, (1, 1, 64, 64), activate_type=\"mish\")\n    for i in range(1):\n        input_data = residual_block(input_data,  64,  32, 64, activate_type=\"mish\")\n    input_data = convolutional(input_data, (1, 1, 64, 64), activate_type=\"mish\")\n\n    input_data = tf.concat([input_data, route], axis=-1)\n    input_data = convolutional(input_data, (1, 1, 128, 64), activate_type=\"mish\")\n    input_data = convolutional(input_data, (3, 3, 64, 128), downsample=True, activate_type=\"mish\")\n    route = input_data\n    route = convolutional(route, (1, 1, 128, 64), activate_type=\"mish\")\n    input_data = convolutional(input_data, (1, 1, 128, 64), activate_type=\"mish\")\n    for i in range(2):\n        input_data = residual_block(input_data, 64,  64, 64, activate_type=\"mish\")\n    input_data = convolutional(input_data, (1, 1, 64, 64), activate_type=\"mish\")\n    input_data = tf.concat([input_data, route], axis=-1)\n\n    input_data = convolutional(input_data, (1, 1, 128, 128), activate_type=\"mish\")\n    input_data = convolutional(input_data, (3, 3, 128, 256), downsample=True, activate_type=\"mish\")\n    route = input_data\n    route = convolutional(route, (1, 1, 256, 128), activate_type=\"mish\")\n    input_data = convolutional(input_data, (1, 1, 256, 128), activate_type=\"mish\")\n    for i in range(4):\n        input_data = residual_block(input_data, 128, 128, 128, activate_type=\"mish\")\n    input_data = convolutional(input_data, (1, 1, 128, 128), activate_type=\"mish\")\n    input_data = tf.concat([input_data, route], axis=-1)\n\n    input_data = convolutional(input_data, (1, 1, 256, 256), activate_type=\"mish\")\n    route_1 = input_data\n    input_data = convolutional(input_data, (3, 3, 256, 512), downsample=True, activate_type=\"mish\")\n    route = input_data\n    route = convolutional(route, (1, 1, 512, 256), activate_type=\"mish\")\n    input_data = convolutional(input_data, (1, 1, 512, 256), activate_type=\"mish\")\n    for i in range(4):\n        input_data = residual_block(input_data, 256, 256, 256, activate_type=\"mish\")\n    input_data = convolutional(input_data, (1, 1, 256, 256), activate_type=\"mish\")\n    input_data = tf.concat([input_data, route], axis=-1)\n\n    input_data = convolutional(input_data, (1, 1, 512, 512), activate_type=\"mish\")\n    route_2 = input_data\n    input_data = convolutional(input_data, (3, 3, 512, 1024), downsample=True, activate_type=\"mish\")\n    route = input_data\n    route = convolutional(route, (1, 1, 1024, 512), activate_type=\"mish\")\n    input_data = convolutional(input_data, (1, 1, 1024, 512), activate_type=\"mish\")\n    for i in range(4):\n        input_data = residual_block(input_data, 512, 512, 512, activate_type=\"mish\")\n    input_data = convolutional(input_data, (1, 1, 512, 512), activate_type=\"mish\")\n    input_data = tf.concat([input_data, route], axis=-1)\n\n    input_data = convolutional(input_data, (1, 1, 1024, 1024), activate_type=\"mish\")\n    input_data = convolutional(input_data, (1, 1, 1024, 512))\n    input_data = convolutional(input_data, (3, 3, 512, 1024))\n    input_data = convolutional(input_data, (1, 1, 1024, 512))\n\n    input_data = tf.concat([tf.nn.max_pool(input_data, ksize=13, padding='SAME', strides=1), tf.nn.max_pool(input_data, ksize=9, padding='SAME', strides=1)\n                            , tf.nn.max_pool(input_data, ksize=5, padding='SAME', strides=1), input_data], axis=-1)\n    input_data = convolutional(input_data, (1, 1, 2048, 512))\n    input_data = convolutional(input_data, (3, 3, 512, 1024))\n    input_data = convolutional(input_data, (1, 1, 1024, 512))\n\n    return route_1, route_2, input_data\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def YOLOv4(input_layer, NUM_CLASS=0):\n    route_1, route_2, conv = cspdarknet53(input_layer)\n\n    route = conv\n    conv = convolutional(conv, (1, 1, 512, 256))\n    conv = upsample(conv)\n    route_2 = convolutional(route_2, (1, 1, 512, 256))\n    conv = tf.concat([route_2, conv], axis=-1)\n\n    conv = convolutional(conv, (1, 1, 512, 256))\n    conv = convolutional(conv, (3, 3, 256, 512))\n    #conv = convolutional(conv, (1, 1, 512, 256))\n    #conv = convolutional(conv, (3, 3, 256, 512))\n    conv = convolutional(conv, (1, 1, 512, 256))\n\n    route_2 = conv\n    conv = convolutional(conv, (1, 1, 256, 128))\n    conv = upsample(conv)\n    route_1 = convolutional(route_1, (1, 1, 256, 128))\n    conv = tf.concat([route_1, conv], axis=-1)\n\n    conv = convolutional(conv, (1, 1, 256, 128))\n    conv = convolutional(conv, (3, 3, 128, 256))\n    #conv = convolutional(conv, (1, 1, 256, 128))\n    #conv = convolutional(conv, (3, 3, 128, 256))\n    conv = convolutional(conv, (1, 1, 256, 128))\n\n    route_1 = conv\n    conv = convolutional(conv, (3, 3, 128, 256))\n    conv_sbbox = convolutional(conv, (1, 1, 256, 25 ), activate=False, bn=False)\n\n    conv = convolutional(route_1, (3, 3, 128, 256), downsample=True)\n    conv = tf.concat([conv, route_2], axis=-1)\n\n    conv = convolutional(conv, (1, 1, 512, 256))\n    conv = convolutional(conv, (3, 3, 256, 512))\n    #conv = convolutional(conv, (1, 1, 512, 256))\n    #conv = convolutional(conv, (3, 3, 256, 512))\n    conv = convolutional(conv, (1, 1, 512, 256))\n\n    route_2 = conv\n    conv = convolutional(conv, (3, 3, 256, 512))\n    conv_mbbox = convolutional(conv, (1, 1, 512, 25 ), activate=False, bn=False)\n\n    conv = convolutional(route_2, (3, 3, 256, 512), downsample=True)\n    conv = tf.concat([conv, route], axis=-1)\n\n    conv = convolutional(conv, (1, 1, 1024, 512))\n    conv = convolutional(conv, (3, 3, 512, 1024))\n    #conv = convolutional(conv, (1, 1, 1024, 512))\n    #conv = convolutional(conv, (3, 3, 512, 1024))\n    conv = convolutional(conv, (1, 1, 1024, 512))\n\n    conv = convolutional(conv, (3, 3, 512, 1024))\n    conv_lbbox = convolutional(conv, (1, 1, 1024, 25 ), activate=False, bn=False)\n    \n    conv_sbbox=Reshape((32,32,5,5),name='out1')(conv_sbbox)\n    conv_mbbox=Reshape((16,16,5,5),name='out2')(conv_mbbox)\n    conv_lbbox=Reshape((8,8,5,5),name='out3')(conv_lbbox)\n\n    \n\n    return [conv_sbbox, conv_mbbox, conv_lbbox]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def decode_train(conv,clusters,shape,name):\n    clust=np.zeros((shape,shape,5,2))\n    for i in range(shape):\n        for j in range(shape):\n            clust[i][j]=clusters\n    clust=tf.convert_to_tensor(tf.cast(clust,dtype='float32'))\n        \n    xy=tf.sigmoid(conv[...,0:2])\n    wh=tf.exp(conv[...,2:4])*clust\n    prob=tf.sigmoid(conv[...,4:])\n                \n                \n    return tf.concat([xy,wh,prob],axis=-1,name=name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clusters=np.array([[0.04980469, 0.06445312],\n       [0.1171875 , 0.10253906],\n       [0.06445312, 0.03710938],\n       [0.09179688, 0.05859375],\n       [0.07226562, 0.08496094]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def my_model(clusters,input_shape):\n    input_data=Input(input_shape)\n    [conv_sbbox, conv_mbbox, conv_lbbox] = YOLOv4(input_data)\n\n    conv_sbbox=decode_train(conv_sbbox,clusters,32,'sbbox')\n    conv_mbbox=decode_train(conv_mbbox,clusters,16,'mbbox')\n    conv_lbbox=decode_train(conv_lbbox,clusters,8,'lbbox')\n        \n    \n    \n    \n    model=Model(input_data,[conv_sbbox, conv_mbbox, conv_lbbox])\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def bbox_ciou(bboxes1, bboxes2):\n    \"\"\"\n    Complete IoU\n    @param bboxes1: (a, b, ..., 4)\n    @param bboxes2: (A, B, ..., 4)\n        x:X is 1:n or n:n or n:1\n    @return (max(a,A), max(b,B), ...)\n    ex) (4,):(3,4) -> (3,)\n        (2,1,4):(2,3,4) -> (2,3)\n    \"\"\"\n    bboxes1_area = bboxes1[..., 2] * bboxes1[..., 3]\n    bboxes2_area = bboxes2[..., 2] * bboxes2[..., 3]\n\n    bboxes1_coor = tf.concat(\n        [\n            bboxes1[..., :2] - bboxes1[..., 2:] * 0.5,\n            bboxes1[..., :2] + bboxes1[..., 2:] * 0.5,\n        ],\n        axis=-1,\n    )\n    bboxes2_coor = tf.concat(\n        [\n            bboxes2[..., :2] - bboxes2[..., 2:] * 0.5,\n            bboxes2[..., :2] + bboxes2[..., 2:] * 0.5,\n        ],\n        axis=-1,\n    )\n\n    left_up = tf.maximum(bboxes1_coor[..., :2], bboxes2_coor[..., :2])\n    right_down = tf.minimum(bboxes1_coor[..., 2:], bboxes2_coor[..., 2:])\n\n    inter_section = tf.maximum(right_down - left_up, 0.0)\n    inter_area = inter_section[..., 0] * inter_section[..., 1]\n\n    union_area = bboxes1_area + bboxes2_area - inter_area\n\n    iou = tf.math.divide_no_nan(inter_area, union_area)\n\n    enclose_left_up = tf.minimum(bboxes1_coor[..., :2], bboxes2_coor[..., :2])\n    enclose_right_down = tf.maximum(\n        bboxes1_coor[..., 2:], bboxes2_coor[..., 2:]\n    )\n\n    enclose_section = enclose_right_down - enclose_left_up\n\n    c_2 = enclose_section[..., 0] ** 2 + enclose_section[..., 1] ** 2\n\n    center_diagonal = bboxes2[..., :2] - bboxes1[..., :2]\n\n    rho_2 = center_diagonal[..., 0] ** 2 + center_diagonal[..., 1] ** 2\n\n    diou = iou - tf.math.divide_no_nan(rho_2, c_2)\n\n    v = (\n        (\n            tf.math.atan(\n                tf.math.divide_no_nan(bboxes1[..., 2], bboxes1[..., 3])\n            )\n            - tf.math.atan(\n                tf.math.divide_no_nan(bboxes2[..., 2], bboxes2[..., 3])\n            )\n        )\n        * 2/np.pi\n        \n    ) ** 2\n\n    alpha = tf.math.divide_no_nan(v, 1 - iou + v)\n\n    ciou = diou - alpha * v\n\n    return ciou","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def log_loss(y_true,y_pred):\n    return -y_true * tf.math.log(y_pred+0.0000000001)-( (1-y_true)*tf.math.log(1-y_pred+0.000000000001) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def yolo_loss(y_true,y_pred):\n  lossx=K.sum(tf.math.multiply(K.square(y_true[:,:,:,:,0:1]-y_pred[:,:,:,:,0:1]),y_true[:,:,:,:,4:]),axis=[1,2,3,4])\n  lossy=K.sum(tf.math.multiply(K.square(y_true[:,:,:,:,1:2]-y_pred[:,:,:,:,1:2]),y_true[:,:,:,:,4:]),axis=[1,2,3,4])\n  loss1=lossx+lossy\n  lossw=K.sum(tf.math.multiply(K.square(y_true[:,:,:,:,2:3]-y_pred[:,:,:,:,2:3]),y_true[:,:,:,:,4:]),axis=[1,2,3,4])\n  lossh=K.sum(tf.math.multiply(K.square(y_true[:,:,:,:,3:4]-y_pred[:,:,:,:,3:4]),y_true[:,:,:,:,4:]),axis=[1,2,3,4])\n  loss2=lossw+lossh\n  loss_xy_wh=(loss1+loss2)*2.0\n  #lossC=K.sum(tf.math.multiply(K.square(tf.math.subtract(y_true[:,:,:,4:],y_pred[:,:,:,4:])),y_true[:,:,:,4:]),axis=[1,2,3])\n  #lossC2 =K.sum(tf.math.multiply(K.square(tf.math.subtract(y_true[:,:,:,4:],y_pred[:,:,:,4:])),(1-y_true[:,:,:,4:])),axis=[1,2,3])/16  \n  #lossC=lossC+lossC2\n  #conf_focal = tf.pow(y_true[:,:,:,:,4:] - y_true[:,:,:,:,4:], 2)\n  conf_loss = K.sum( (\n           y_true[:,:,:,:,4:] * log_loss(y_true[:,:,:,:,4:],y_pred[:,:,:,:,4:])*1.5\n            +\n            (1-y_true[:,:,:,:,4:]) *0.05* log_loss(y_true[:,:,:,:,4:],y_pred[:,:,:,:,4:])\n    ),axis=[1,2,3,4])\n    \n  ciou = tf.expand_dims(bbox_ciou(y_pred[:,:,:,:,:4], y_true[:,:,:,:,:4]), axis=-1)\n  ciou_loss = y_true[:,:,:,:,4:] * 2.0 * (1- ciou)\n\n    \n  total_loss=loss_xy_wh+K.sum(ciou_loss,axis=[1,2,3,4])+conf_loss\n  return total_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=my_model(clusters,input_shape=(256,256,3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights('../input/30k-wheats-modified/30k_yolov4_weights2.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_boxes(box,boxes,scores):\n  m=box.shape[0]\n  for i in range(m):\n    for j in range(m):\n        for k in range(5):\n            if(box[i][j][k][4]>=0.95):\n                x=(i*(1024/m))+(box[i][j][k][0]*(1024/m))\n                y=(j*(1024/m))+(box[i][j][k][1]*(1024/m))\n                w=box[i][j][k][2]*1024\n                h=box[i][j][k][3]*1024\n                x1=int((x-w/2))\n                y1=int((y-h/2))\n                x2=int((x+w/2))\n                y2=int((y+h/2))\n                #print(box[i][j][k][4])\n               #print(box[i][j][k][4],int(x1),y1,x2,y2)\n                boxes.append([y1,x1,y2,x2])\n                scores.append(box[i][j][k][4])\n                #cv2.rectangle(img,(89,250),(202,363),(255,0,0),2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def draw_boxes(address,model):\n    img=cv2.imread(address)\n    img1=cv2.resize(img,(256,256))\n    img1=img1/255.0\n    img1=img1[np.newaxis,:]\n    box1,box2,box3=model.predict(img1)\n    boxes=[]\n    scores=[]\n    get_boxes(box1[0],boxes,scores)\n    get_boxes(box2[0],boxes,scores)\n    get_boxes(box3[0],boxes,scores)\n    boxes=np.array(boxes)\n    scores=np.array(scores)\n    boxes=tf.convert_to_tensor(boxes)\n    scores=tf.convert_to_tensor(scores)\n    boxes=tf.cast(boxes, tf.float32)\n    scores=tf.cast(scores,tf.float32)\n    selected_indices = tf.image.non_max_suppression(\n        boxes, scores, max_output_size=50, iou_threshold=0.1)\n    selected_boxes = tf.gather(boxes, selected_indices)\n    selected_scores=tf.gather(scores,selected_indices)\n    return np.array(selected_scores),np.array(selected_boxes)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DIR_INPUT = '/kaggle/input/global-wheat-detection'\nDIR_TRAIN = f'{DIR_INPUT}/train'\nDIR_TEST = f'{DIR_INPUT}/test'\n\n\nimagenames = os.listdir(DIR_TEST)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results=[]\nfor count, name in enumerate(imagenames):\n    ids = name.split('.')[0]\n    imagepath = '%s/%s.jpg'%(DIR_TEST,ids)\n    img=cv2.imread(imagepath)\n    img1=cv2.resize(img,(256,256))\n    img1=img1/255.0\n    img1=img1[np.newaxis,:]\n    [box1,box2,box3]=model.predict(img1)\n    boxes=[]\n    scores=[]\n    for boz in [box1,box2,box3]:\n          box=boz[0]\n          m=box.shape[0]\n          for i in range(m):\n            for j in range(m):\n                for k in range(5):\n                    if(box[i][j][k][4]>=0.1):\n                        x=(i*(1024/m))+(box[i][j][k][0]*(1024/m))\n                        y=(j*(1024/m))+(box[i][j][k][1]*(1024/m))\n                        w=box[i][j][k][2]*1024\n                        h=box[i][j][k][3]*1024\n                        x1=int((x-w/2))\n                        y1=int((y-h/2))\n                        x2=int((x+w/2))\n                        y2=int((y+h/2))\n                        #print(box[i][j][k][4])\n                       #print(box[i][j][k][4],int(x1),y1,x2,y2)\n                        boxes.append([y1,x1,y2,x2])\n                        scores.append(box[i][j][k][4])\n    \n      \n     \n    if(len(boxes)>0):\n        boxes=np.array(boxes)\n        scores=np.array(scores)\n        boxes=tf.convert_to_tensor(boxes)\n        scores=tf.convert_to_tensor(scores)\n        boxes=tf.cast(boxes, tf.float32)\n        scores=tf.cast(scores,tf.float32)\n        selected_indices = tf.image.non_max_suppression(\n            boxes, scores, max_output_size=50, iou_threshold=0.1)\n        selected_boxes = tf.gather(boxes, selected_indices)\n        selected_scores=tf.gather(scores,selected_indices)\n        boxes=np.array(selected_boxes)\n        scores=np.array(selected_scores)\n\n        pred_strings = []\n        m,n=boxes.shape\n        for i in range(m):\n            pred_strings.append(\"{0:.4f} {1} {2} {3} {4}\".format(np.clip(np.around(scores[i],4),0,1), np.clip(int(np.around(boxes[i][1])),0,1023), np.clip(int(np.around(boxes[i][0])),0,1023), np.clip(int(np.around(boxes[i][3]-boxes[i][1])),0,1023), np.clip(int(np.around(boxes[i][2]-boxes[i][0])),0,1023)))\n        if(len(pred_strings)>0):\n            result = {'image_id':ids,'PredictionString': \" \".join(pred_strings)}\n    else:\n        result = {'image_id':ids,'PredictionString': \" \"}\n        \n    results.append(result)\n    \n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.DataFrame(results, columns=['image_id', 'PredictionString'])\n\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def draw_boxes(box,ax):\n  m=box.shape[0]\n  for i in range(m):\n    for j in range(m):\n        for k in range(5):\n            if(box[i][j][k][4]>0.875):\n                x=(i*(1024/m))+(box[i][j][k][0]*(1024/m))\n                y=(j*(1024/m))+(box[i][j][k][1]*(1024/m))\n                w=box[i][j][k][2]*1024\n                h=box[i][j][k][3]*1024\n                x1=int((x-w/2))\n                y1=int((y-h/2))\n                x2=int((x+w/2))\n                y2=int((y+h/2))\n                #print(box[i][j][k][4])\n               #print(box[i][j][k][4],int(x1),y1,x2,y2)\n                rect = patches.Rectangle((x1,y1),w,h,linewidth=1,edgecolor='r',facecolor='none')\n                boxes.append([y1,x1,y2,x2])\n                scores.append(box[i][j][k][4])\n                #cv2.rectangle(img,(89,250),(202,363),(255,0,0),2)\n                ax.add_patch(rect)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img=cv2.imread('../input/global-wheat-detection/test/f5a1f0358.jpg')\nimg1=cv2.resize(img,(256,256))\nimg1=img1/255.0\nimg1=img1[np.newaxis,:]\nbox1,box2,box3=model.predict(img1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(1)\nax.imshow(img[:,:,[2,1,0]])\nboxes=[]\nscores=[]\ndraw_boxes(box1[0],ax)\ndraw_boxes(box2[0],ax)\ndraw_boxes(box3[0],ax)\nboxes=np.array(boxes)\nscores=np.array(scores)\nboxes=tf.convert_to_tensor(boxes)\nscores=tf.convert_to_tensor(scores)\nboxes=tf.cast(boxes, tf.float32)\nscores=tf.cast(scores,tf.float32)\nselected_indices = tf.image.non_max_suppression(\n    boxes, scores, max_output_size=50, iou_threshold=0.2)\nselected_boxes = tf.gather(boxes, selected_indices)\nfig,ax = plt.subplots(1)\nax.imshow(img[:,:,[2,1,0]])\nfor i in selected_boxes:\n  rect = patches.Rectangle((i[1],i[0]),i[3]-i[1],i[2]-i[0],linewidth=3,edgecolor='r',facecolor='none')\n  ax.add_patch(rect)\nfig.set_size_inches((12,12))\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(1)\nax.imshow(img[:,:,[2,1,0]])\nboxes=[]\nscores=[]\ndraw_boxes(box1[0],ax)\ndraw_boxes(box2[0],ax)\ndraw_boxes(box3[0],ax)\nboxes=np.array(boxes)\nscores=np.array(scores)\nboxes=tf.convert_to_tensor(boxes)\nscores=tf.convert_to_tensor(scores)\nboxes=tf.cast(boxes, tf.float32)\nscores=tf.cast(scores,tf.float32)\nselected_indices = tf.image.non_max_suppression(\n    boxes, scores, max_output_size=50, iou_threshold=0.1)\nselected_boxes = tf.gather(boxes, selected_indices)\nfig,ax = plt.subplots(1)\nax.imshow(img[:,:,[2,1,0]])\nfor i in selected_boxes:\n  rect = patches.Rectangle((i[1],i[0]),i[3]-i[1],i[2]-i[0],linewidth=3,edgecolor='r',facecolor='none')\n  ax.add_patch(rect)\nfig.set_size_inches((12,12))\nplt.show()\n\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}