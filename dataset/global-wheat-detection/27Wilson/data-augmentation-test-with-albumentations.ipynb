{"cells":[{"metadata":{},"cell_type":"markdown","source":"### I've created this notebook as this is my first object detection challenge and thus wanted to explore image augmentation with using albumentations. I tested each function of albumentations. Sharing this publicly as this might be useful to beginners like me.\n\n#### I have no idea which function can make a great improvement on this challenge. Any information you have can share with me!","execution_count":null},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import os\nimport ast\nfrom collections import namedtuple\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom tqdm import tqdm\nfrom PIL import Image\n\nimport joblib\nfrom joblib import Parallel, delayed\n\nimport cv2\nimport albumentations\nfrom albumentations.pytorch.transforms import ToTensorV2\nfrom albumentations.core.transforms_interface import DualTransform\nfrom albumentations.augmentations.bbox_utils import denormalize_bbox, normalize_bbox\n\nfrom matplotlib import pyplot as plt\nimport matplotlib.patches as patches\nfrom matplotlib.image import imsave","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Constants\nBASE_DIR = '/kaggle/input/global-wheat-detection'\nWORK_DIR = '/kaggle/working'\n\n# Set seed for numpy for reproducibility\nnp.random.seed(1996)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(os.path.join(BASE_DIR, 'train.csv'))\n\n# Let's expand the bounding box coordinates and calculate the area of all the bboxes\ntrain_df[['x_min','y_min', 'width', 'height']] = pd.DataFrame([ast.literal_eval(x) for x in train_df.bbox.tolist()], index= train_df.index)\ntrain_df = train_df[['image_id', 'bbox', 'source', 'x_min', 'y_min', 'width', 'height']]\ntrain_df['area'] = train_df['width'] * train_df['height']\ntrain_df['x_max'] = train_df['x_min'] + train_df['width']\ntrain_df['y_max'] = train_df['y_min'] + train_df['height']\ntrain_df = train_df.drop(['bbox', 'source'], axis=1)\ntrain_df = train_df[['image_id', 'x_min', 'y_min', 'x_max', 'y_max', 'width', 'height', 'area']]\n\n# There are some buggy annonations in training images having huge bounding boxes. Let's remove those bboxes\ntrain_df = train_df[train_df['area'] < 100000]\n\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_ids = train_df['image_id'].unique()\nprint(f'Total number of training images: {len(image_ids)}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are two major formats of bounding boxes:\n\n1. **pascal_voc**, which is [x_min, y_min, x_max, y_max]\n2. **COCO**, which is [x_min, y_min, width, height]\n\nWe'll see how to perform image augmentations for both the formats. Let's first start with **pascal_voc** format.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the image on which data augmentaion is to be performed\nimage_id = 'c14c1e300'\nimage = cv2.imread(os.path.join(BASE_DIR, 'train', f'{image_id}.jpg'), cv2.IMREAD_COLOR)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\nimage /= 255.0\nplt.figure(figsize = (10, 10))\nplt.imshow(image)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We've our image ready, let's create an array of bounding boxes for all the wheat heads in the above image and the array of labels (we've only 2 class here: wheat head and background). As all bounding boxes are of same class, labels array will contain only 1's. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pascal_voc_boxes = train_df[train_df['image_id'] == image_id][['x_min', 'y_min', 'x_max', 'y_max']].astype(np.int32).values\ncoco_boxes = train_df[train_df['image_id'] == image_id][['x_min', 'y_min', 'width', 'height']].astype(np.int32).values\nassert(len(pascal_voc_boxes) == len(coco_boxes))\nlabels = np.ones((len(pascal_voc_boxes), ))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's plot the bounding boxes on the above image","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_bbox(bboxes, col, color='white', bbox_format='pascal_voc'):\n    \n    for i in range(len(bboxes)):\n        # Create a Rectangle patch\n        if bbox_format == 'pascal_voc':\n            rect = patches.Rectangle(\n                (bboxes[i][0], bboxes[i][1]),\n                bboxes[i][2] - bboxes[i][0], \n                bboxes[i][3] - bboxes[i][1], \n                linewidth=2, \n                edgecolor=color, \n                facecolor='none')\n        else:\n            rect = patches.Rectangle(\n                (bboxes[i][0], bboxes[i][1]),\n                bboxes[i][2], \n                bboxes[i][3], \n                linewidth=2, \n                edgecolor=color, \n                facecolor='none')\n\n        # Add the patch to the Axes\n        col.add_patch(rect)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's define augmentations using albumentations library and test it on the image above","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Blur","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"aug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.Blur(p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"VerticalFlip","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"aug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.VerticalFlip(p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"HorizontalFlip","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"aug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.HorizontalFlip(p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Flip","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"aug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.Flip(p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Normalize","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"aug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.Normalize(p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Transpose","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"aug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.Transpose(p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RandomCrop","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"aug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.RandomCrop(height=400, width=400, p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RandomGamma","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"aug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.RandomGamma( p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RandomRotate90","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"aug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.RandomRotate90( p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Rotate","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"aug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.Rotate(limit=30, p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ShiftScaleRotate","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"aug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.ShiftScaleRotate(p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"CenterCrop","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"aug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.CenterCrop(400, 400, p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"HueSaturationValue","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"aug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.HueSaturationValue(hue_shift_limit=0.5, sat_shift_limit= 0.5, val_shift_limit=0.5, p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"PadIfNeeded","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"aug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.PadIfNeeded(800, 800, p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RGBShift","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"aug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.RGBShift(r_shift_limit=0.5, g_shift_limit=0.5, b_shift_limit=0.5,p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RandomBrightness","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"aug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.RandomBrightness(limit=0.2, p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RandomContrast","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"aug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.RandomContrast(limit=0.2, p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"MotionBlur","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"aug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.MotionBlur(p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"MedianBlur","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"aug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.MedianBlur(blur_limit=3, p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"GaussianBlur","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"aug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.GaussianBlur(blur_limit=3, p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"GaussNoise","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"aug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.GaussNoise(var_limit=(0.1, 0.1), p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"GlassBlur","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"aug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.GlassBlur(sigma=0.1, max_delta=4, p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"CLAHE","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the image on which data augmentaion is to be performed\nimage_id = 'c14c1e300'\nimage = cv2.imread(os.path.join(BASE_DIR, 'train', f'{image_id}.jpg'), cv2.IMREAD_COLOR)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\naug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.CLAHE(p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ChannelShuffle","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the image on which data augmentaion is to be performed\nimage_id = 'c14c1e300'\nimage = cv2.imread(os.path.join(BASE_DIR, 'train', f'{image_id}.jpg'), cv2.IMREAD_COLOR)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\nimage /= 255.0\naug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.ChannelShuffle(p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"InvertImg","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the image on which data augmentaion is to be performed\nimage_id = 'c14c1e300'\nimage = cv2.imread(os.path.join(BASE_DIR, 'train', f'{image_id}.jpg'), cv2.IMREAD_COLOR)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\nimage /= 255.0\naug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.InvertImg(p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ToGray","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the image on which data augmentaion is to be performed\nimage_id = 'c14c1e300'\nimage = cv2.imread(os.path.join(BASE_DIR, 'train', f'{image_id}.jpg'), cv2.IMREAD_COLOR)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\nimage /= 255.0\naug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.ToGray(p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ToSepia","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the image on which data augmentaion is to be performed\nimage_id = 'c14c1e300'\nimage = cv2.imread(os.path.join(BASE_DIR, 'train', f'{image_id}.jpg'), cv2.IMREAD_COLOR)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\nimage /= 255.0\naug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.ToSepia(p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"JpegCompression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the image on which data augmentaion is to be performed\nimage_id = 'c14c1e300'\nimage = cv2.imread(os.path.join(BASE_DIR, 'train', f'{image_id}.jpg'), cv2.IMREAD_COLOR)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\nimage /= 255.0\naug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.JpegCompression(p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ImageCompression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the image on which data augmentaion is to be performed\nimage_id = 'c14c1e300'\nimage = cv2.imread(os.path.join(BASE_DIR, 'train', f'{image_id}.jpg'), cv2.IMREAD_COLOR)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\nimage /= 255.0\naug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.ImageCompression(p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cutout","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the image on which data augmentaion is to be performed\nimage_id = 'c14c1e300'\nimage = cv2.imread(os.path.join(BASE_DIR, 'train', f'{image_id}.jpg'), cv2.IMREAD_COLOR)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\nimage /= 255.0\naug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.Cutout(num_holes=8, max_h_size=64, max_w_size=64, fill_value=0, p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"CoarseDropout","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the image on which data augmentaion is to be performed\nimage_id = 'c14c1e300'\nimage = cv2.imread(os.path.join(BASE_DIR, 'train', f'{image_id}.jpg'), cv2.IMREAD_COLOR)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\nimage /= 255.0\naug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.CoarseDropout(max_holes=8, max_height=64, max_width=64,p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ToFloat","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the image on which data augmentaion is to be performed\nimage_id = 'c14c1e300'\nimage = cv2.imread(os.path.join(BASE_DIR, 'train', f'{image_id}.jpg'), cv2.IMREAD_COLOR)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\naug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.CLAHE(p=1),\n        albumentations.ToFloat(p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image/255.0)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the image on which data augmentaion is to be performed\nimage_id = 'c14c1e300'\nimage = cv2.imread(os.path.join(BASE_DIR, 'train', f'{image_id}.jpg'), cv2.IMREAD_COLOR)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\nimage /= 255.0\naug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.FromFloat(dtype='uint8', p=1),\n        albumentations.CLAHE(p=1),\n        albumentations.ToFloat(p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Crop","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the image on which data augmentaion is to be performed\nimage_id = 'c14c1e300'\nimage = cv2.imread(os.path.join(BASE_DIR, 'train', f'{image_id}.jpg'), cv2.IMREAD_COLOR)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\nimage /= 255.0\naug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.Crop( x_max=400, y_max=400,p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RandomScale","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the image on which data augmentaion is to be performed\nimage_id = 'c14c1e300'\nimage = cv2.imread(os.path.join(BASE_DIR, 'train', f'{image_id}.jpg'), cv2.IMREAD_COLOR)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\nimage /= 255.0\naug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.RandomScale(scale_limit=0.3, p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"LongestMaxSize","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the image on which data augmentaion is to be performed\nimage_id = 'c14c1e300'\nimage = cv2.imread(os.path.join(BASE_DIR, 'train', f'{image_id}.jpg'), cv2.IMREAD_COLOR)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\nimage /= 255.0\naug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.LongestMaxSize(400, p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RandomSizedCrop","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the image on which data augmentaion is to be performed\nimage_id = 'c14c1e300'\nimage = cv2.imread(os.path.join(BASE_DIR, 'train', f'{image_id}.jpg'), cv2.IMREAD_COLOR)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\nimage /= 255.0\naug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.RandomSizedCrop(min_max_height=(400, 400), height=512, width=512, p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RandomResizedCrop","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the image on which data augmentaion is to be performed\nimage_id = 'c14c1e300'\nimage = cv2.imread(os.path.join(BASE_DIR, 'train', f'{image_id}.jpg'), cv2.IMREAD_COLOR)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\nimage /= 255.0\naug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.RandomResizedCrop(height=512, width=512, p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RandomBrightnessContrast","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class CustomCutout(DualTransform):\n    \"\"\"\n    Custom Cutout augmentation with handling of bounding boxes \n    Note: (only supports square cutout regions)\n    \n    Author: Kaushal28\n    Reference: https://arxiv.org/pdf/1708.04552.pdf\n    \"\"\"\n    \n    def __init__(\n        self,\n        fill_value=0,\n        bbox_removal_threshold=0.50,\n        min_cutout_size=192,\n        max_cutout_size=512,\n        number=1,\n        always_apply=False,\n        p=0.5\n    ):\n        \"\"\"\n        Class construstor\n        :param fill_value: Value to be filled in cutout (default is 0 or black color)\n        :param bbox_removal_threshold: Bboxes having content cut by cutout path more than this threshold will be removed\n        :param min_cutout_size: minimum size of cutout (192 x 192)\n        :param max_cutout_size: maximum size of cutout (512 x 512)\n        \"\"\"\n        super(CustomCutout, self).__init__(always_apply, p)  # Initialize parent class\n        self.fill_value = fill_value\n        self.bbox_removal_threshold = bbox_removal_threshold\n        self.min_cutout_size = min_cutout_size\n        self.max_cutout_size = max_cutout_size\n        self.number = number\n        \n    def _get_cutout_position(self, img_height, img_width, cutout_size):\n        \"\"\"\n        Randomly generates cutout position as a named tuple\n        \n        :param img_height: height of the original image\n        :param img_width: width of the original image\n        :param cutout_size: size of the cutout patch (square)\n        :returns position of cutout patch as a named tuple\n        \"\"\"\n        position = namedtuple('Point', 'x y')\n        return position(\n            np.random.randint(0, img_width - cutout_size + 1),\n            np.random.randint(0, img_height - cutout_size + 1)\n        )\n    def _get_cutout(self, img_height, img_width):\n        \"\"\"\n        Creates a cutout pacth with given fill value and determines the position in the original image\n        \n        :param img_height: height of the original image\n        :param img_width: width of the original image\n        :returns (cutout patch, cutout size, cutout position)\n        \"\"\"\n        cutout_size = np.random.randint(self.min_cutout_size, self.max_cutout_size + 1)\n        cutout_position = self._get_cutout_position(img_height, img_width, cutout_size)\n        return np.full((cutout_size, cutout_size, 3), self.fill_value), cutout_size, cutout_position\n    def apply(self, image, **params):\n        \"\"\"\n        Applies the cutout augmentation on the given image\n        \n        :param image: The image to be augmented\n        :returns augmented image\n        \"\"\"\n        image = image.copy()  # Don't change the original image\n        self.img_height, self.img_width, _ = image.shape\n        for i in range(self.number):\n            cutout_arr, cutout_size, cutout_pos = self._get_cutout(self.img_height, self.img_width)\n            \n            # Set to instance variables to use this later\n            self.image = image\n            self.cutout_pos = cutout_pos\n            self.cutout_size = cutout_size\n            \n            image[cutout_pos.y:cutout_pos.y+cutout_size, cutout_pos.x:cutout_size+cutout_pos.x, :] = cutout_arr\n        return image\n    def apply_to_bbox(self, bbox, **params):\n        \"\"\"\n        Removes the bounding boxes which are covered by the applied cutout\n        \n        :param bbox: A single bounding box coordinates in pascal_voc format\n        :returns transformed bbox's coordinates\n        \"\"\"\n\n        # Denormalize the bbox coordinates\n        bbox = denormalize_bbox(bbox, self.img_height, self.img_width)\n        x_min, y_min, x_max, y_max = tuple(map(int, bbox))\n        if x_min >= x_max or y_min >= y_max:\n            return normalize_bbox((0, 0, 0, 0), self.img_height, self.img_width)\n\n        bbox_size = (x_max - x_min) * (y_max - y_min)  # width * height\n        overlapping_size = np.sum(\n            (self.image[y_min:y_max, x_min:x_max, 0] == self.fill_value) &\n            (self.image[y_min:y_max, x_min:x_max, 1] == self.fill_value) &\n            (self.image[y_min:y_max, x_min:x_max, 2] == self.fill_value)\n        )\n        # Remove the bbox if it has more than some threshold of content is inside the cutout patch\n        if overlapping_size / bbox_size > self.bbox_removal_threshold:\n            return normalize_bbox((0, 0, 0, 0), self.img_height, self.img_width)\n\n        return normalize_bbox(bbox, self.img_height, self.img_width)\n\n    def get_transform_init_args_names(self):\n        \"\"\"\n        Fetches the parameter(s) of __init__ method\n        :returns: tuple of parameter(s) of __init__ method\n        \"\"\"\n        return ('fill_value', 'bbox_removal_threshold', 'min_cutout_size', 'max_cutout_size', 'always_apply', 'p')\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the image on which data augmentaion is to be performed\nimage_id = 'c14c1e300'\nimage = cv2.imread(os.path.join(BASE_DIR, 'train', f'{image_id}.jpg'), cv2.IMREAD_COLOR)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\nimage /= 255.0\naug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        CustomCutout(bbox_removal_threshold=0.50,min_cutout_size=32,max_cutout_size=96,number=12,p=1),\n#         albumentations.RandomBrightnessContrast(brightness_limit=0.05, contrast_limit=0.8, p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RandomSizedBBoxSafeCrop","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the image on which data augmentaion is to be performed\nimage_id = 'c14c1e300'\nimage = cv2.imread(os.path.join(BASE_DIR, 'train', f'{image_id}.jpg'), cv2.IMREAD_COLOR)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\nimage /= 255.0\naug = albumentations.Compose([\n#         albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n         albumentations.PadIfNeeded(1200, 1200, p=1),\n         albumentations.RandomSizedBBoxSafeCrop(height=1024, width=1024, erosion_rate=4, p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RandomSnow","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the image on which data augmentaion is to be performed\nimage_id = 'c14c1e300'\nimage = cv2.imread(os.path.join(BASE_DIR, 'train', f'{image_id}.jpg'), cv2.IMREAD_COLOR)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\nimage /= 255.0\naug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.RandomSnow(p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RandomRain","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the image on which data augmentaion is to be performed\nimage_id = 'c14c1e300'\nimage = cv2.imread(os.path.join(BASE_DIR, 'train', f'{image_id}.jpg'), cv2.IMREAD_COLOR)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\nimage /= 255.0\naug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.RandomRain(p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RandomFog","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the image on which data augmentaion is to be performed\nimage_id = 'c14c1e300'\nimage = cv2.imread(os.path.join(BASE_DIR, 'train', f'{image_id}.jpg'), cv2.IMREAD_COLOR)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\nimage /= 255.0\naug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.RandomFog(p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RandomSunFlare","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the image on which data augmentaion is to be performed\nimage_id = 'c14c1e300'\nimage = cv2.imread(os.path.join(BASE_DIR, 'train', f'{image_id}.jpg'), cv2.IMREAD_COLOR)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\nimage /= 255.0\naug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.RandomSunFlare(flare_roi=(0, 0, 1, 0.5), src_radius=200, src_color=(255, 255, 255), p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RandomShadow","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the image on which data augmentaion is to be performed\nimage_id = 'c14c1e300'\nimage = cv2.imread(os.path.join(BASE_DIR, 'train', f'{image_id}.jpg'), cv2.IMREAD_COLOR)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\nimage /= 255.0\naug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.RandomShadow( p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ChannelDropout","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the image on which data augmentaion is to be performed\nimage_id = 'c14c1e300'\nimage = cv2.imread(os.path.join(BASE_DIR, 'train', f'{image_id}.jpg'), cv2.IMREAD_COLOR)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\nimage /= 255.0\naug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.ChannelDropout( p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ISONoise","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the image on which data augmentaion is to be performed\nimage_id = 'c14c1e300'\nimage = cv2.imread(os.path.join(BASE_DIR, 'train', f'{image_id}.jpg'), cv2.IMREAD_COLOR)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n# .astype(np.float32)\n# image /= 255.0\naug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.ISONoise( p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Solarize","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the image on which data augmentaion is to be performed\nimage_id = 'c14c1e300'\nimage = cv2.imread(os.path.join(BASE_DIR, 'train', f'{image_id}.jpg'), cv2.IMREAD_COLOR)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n# .astype(np.float32)\n# image /= 255.0\naug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.Solarize(threshold=224, p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Equalize","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the image on which data augmentaion is to be performed\nimage_id = 'c14c1e300'\nimage = cv2.imread(os.path.join(BASE_DIR, 'train', f'{image_id}.jpg'), cv2.IMREAD_COLOR)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n# .astype(np.float32)\n# image /= 255.0\naug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.Equalize( p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Posterize","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the image on which data augmentaion is to be performed\nimage_id = 'c14c1e300'\nimage = cv2.imread(os.path.join(BASE_DIR, 'train', f'{image_id}.jpg'), cv2.IMREAD_COLOR)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n# .astype(np.float32)\n# image /= 255.0\naug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.Posterize( p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Downscale","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the image on which data augmentaion is to be performed\nimage_id = 'c14c1e300'\nimage = cv2.imread(os.path.join(BASE_DIR, 'train', f'{image_id}.jpg'), cv2.IMREAD_COLOR)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\nimage /= 255.0\naug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.Downscale( p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"MultiplicativeNoise","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the image on which data augmentaion is to be performed\nimage_id = 'c14c1e300'\nimage = cv2.imread(os.path.join(BASE_DIR, 'train', f'{image_id}.jpg'), cv2.IMREAD_COLOR)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\nimage /= 255.0\naug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.MultiplicativeNoise( p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"DualIAATransform","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the image on which data augmentaion is to be performed\nimage_id = 'c14c1e300'\nimage = cv2.imread(os.path.join(BASE_DIR, 'train', f'{image_id}.jpg'), cv2.IMREAD_COLOR)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\nimage /= 255.0\naug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.DualIAATransform( p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ImageOnlyIAATransform","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the image on which data augmentaion is to be performed\nimage_id = 'c14c1e300'\nimage = cv2.imread(os.path.join(BASE_DIR, 'train', f'{image_id}.jpg'), cv2.IMREAD_COLOR)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\nimage /= 255.0\naug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.ImageOnlyIAATransform( p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"IAAEmboss","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the image on which data augmentaion is to be performed\nimage_id = 'c14c1e300'\nimage = cv2.imread(os.path.join(BASE_DIR, 'train', f'{image_id}.jpg'), cv2.IMREAD_COLOR)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\nimage /= 255.0\naug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.IAAEmboss( p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"IAASuperpixels","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the image on which data augmentaion is to be performed\nimage_id = 'c14c1e300'\nimage = cv2.imread(os.path.join(BASE_DIR, 'train', f'{image_id}.jpg'), cv2.IMREAD_COLOR)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\nimage /= 255.0\naug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.IAASuperpixels( p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"IAASharpen","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the image on which data augmentaion is to be performed\nimage_id = 'c14c1e300'\nimage = cv2.imread(os.path.join(BASE_DIR, 'train', f'{image_id}.jpg'), cv2.IMREAD_COLOR)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\nimage /= 255.0\naug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.IAASharpen( p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"IAAAdditiveGaussianNoise","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the image on which data augmentaion is to be performed\nimage_id = 'c14c1e300'\nimage = cv2.imread(os.path.join(BASE_DIR, 'train', f'{image_id}.jpg'), cv2.IMREAD_COLOR)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\nimage /= 255.0\naug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.IAAAdditiveGaussianNoise( p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"IAACropAndPad","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the image on which data augmentaion is to be performed\nimage_id = 'c14c1e300'\nimage = cv2.imread(os.path.join(BASE_DIR, 'train', f'{image_id}.jpg'), cv2.IMREAD_COLOR)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\nimage /= 255.0\naug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.IAACropAndPad( p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"IAAFliplr","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the image on which data augmentaion is to be performed\nimage_id = 'c14c1e300'\nimage = cv2.imread(os.path.join(BASE_DIR, 'train', f'{image_id}.jpg'), cv2.IMREAD_COLOR)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\nimage /= 255.0\naug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.IAAFliplr( p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"IAAFlipud","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the image on which data augmentaion is to be performed\nimage_id = 'c14c1e300'\nimage = cv2.imread(os.path.join(BASE_DIR, 'train', f'{image_id}.jpg'), cv2.IMREAD_COLOR)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\nimage /= 255.0\naug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.IAAFlipud( p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"IAAAffine","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the image on which data augmentaion is to be performed\nimage_id = 'c14c1e300'\nimage = cv2.imread(os.path.join(BASE_DIR, 'train', f'{image_id}.jpg'), cv2.IMREAD_COLOR)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\nimage /= 255.0\naug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.IAAAffine(scale=1.0, rotate=10, shear=5., order=1, cval=0, p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"IAAPiecewiseAffine","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the image on which data augmentaion is to be performed\nimage_id = 'c14c1e300'\nimage = cv2.imread(os.path.join(BASE_DIR, 'train', f'{image_id}.jpg'), cv2.IMREAD_COLOR)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\nimage /= 255.0\naug = albumentations.Compose([\n        albumentations.Resize(512, 512),   # Resize the given 1024 x 1024 image to 512 * 512\n#         albumentations.VerticalFlip(1),    # Verticlly flip the image\n        albumentations.IAAPiecewiseAffine(scale=(0.03, 0.05), nb_rows=4, nb_cols=4, order=1, cval=0,  p=1),\n    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\naug_result = aug(image=image, bboxes=pascal_voc_boxes, labels=labels)\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\nget_bbox(pascal_voc_boxes, ax[0], color='red')\nax[0].title.set_text('Original Image')\nax[0].imshow(image)\n\nget_bbox(aug_result['bboxes'], ax[1], color='red')\nax[1].title.set_text('Augmented Image')\nax[1].imshow(aug_result['image'])\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}