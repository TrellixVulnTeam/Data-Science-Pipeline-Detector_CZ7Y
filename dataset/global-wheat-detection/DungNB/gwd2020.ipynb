{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         if 'global-wheat-detection' not in dirname:\n#             print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!cp -r /kaggle/input/wheat-src/* .\n!ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install /kaggle/input/wheat-packages/torch-1.4.0-cp37-cp37m-linux_x86_64.whl -f ./ --no-index\n!pip install /kaggle/input/wheat-packages/torchvision-0.5.0-cp37-cp37m-linux_x86_64.whl -f ./ --no-index\n!pip install /kaggle/input/wheat-packages/ensemble_boxes-1.0.4-py3-none-any.whl -f ./ --no-index\n!pip install /kaggle/input/wheat-packages/omegaconf-2.0.0-py3-none-any.whl -f ./ --no-index\n!pip install /kaggle/input/wheat-packages/timm-0.1.28-py3-none-any.whl -f ./ --no-index","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport gc\nimport cv2\nimport random\nfrom PIL import Image\nfrom tqdm import tqdm\nfrom multiprocessing import Pool\nfrom matplotlib import pyplot as plt\nfrom ensemble_boxes import weighted_boxes_fusion\nfrom utils import get_resolution, save_dict, load_dict, format_prediction_string, make_pseudo_dataframe, refine_checkpoint_in, refine_checkpoint_out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/global-wheat-detection/sample_submission.csv')\nTEST_DIR = '/kaggle/input/global-wheat-detection/test'\nTRAIN_DIR = '/kaggle/input/global-wheat-detection/train'\nCHECKPOINT_DIR = '/kaggle/input/wheat2020-checkpoints'\n\nif len(test_df) > 10:\n    USE_AMP = True\n    VISUALIZE = False\n    PSEUDO = True\nelse:\n    USE_AMP = False\n    VISUALIZE = True\n    PSEUDO = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if USE_AMP:\n    !cp -r /kaggle/input/nvidiaapex/ .\n    !pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" nvidiaapex/. --user\n    !rm -rf nvidiaapex\n    from apex import amp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def visualize_result(test_df, TEST_DIR, output_dict):\n    for image_id in list(np.unique(test_df.image_id.values)):\n        img_path = '{}/{}.jpg'.format(TEST_DIR, image_id)\n        image = Image.open(img_path)\n        image = image.convert('RGB')\n        image = np.array(image)\n\n        boxes, scores = output_dict[image_id]\n        if len(boxes) > 0:\n            boxes = boxes.astype(np.int32)\n\n        fig, ax = plt.subplots(1, 1, figsize=(20, 10))\n        for box in boxes:\n            cv2.rectangle(image, (box[0], box[1]), (box[2], box[3]), (255, 0, 0), 3)\n\n        ax.set_axis_off()\n        ax.imshow(image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def run_wbf(test_df, box_pred, score_pred, label_pred, resolution_dict, NMS_THRESH, BOX_THRESH, PP_THRESH):\n    output_dict = {}\n    for image_id in np.unique(test_df.image_id.values):\n        boxes = box_pred[image_id]\n        scores = score_pred[image_id]\n        labels = label_pred[image_id]\n\n        boxes, scores, labels = weighted_boxes_fusion(boxes, scores, labels, weights=None, iou_thr=NMS_THRESH, skip_box_thr=BOX_THRESH)\n        boxes = np.array(boxes)\n        scores = np.array(scores)\n\n        idxs = np.where(scores > PP_THRESH)[0]\n        boxes = boxes[idxs]\n        scores = scores[idxs]\n\n        if len(boxes) > 0:\n            height, width = resolution_dict[image_id]\n            boxes[:, [0,2]] = (boxes[:, [0,2]]*width).clip(min=0, max=width-1)\n            boxes[:, [1,3]] = (boxes[:, [1,3]]*height).clip(min=0, max=height-1)\n        output_dict[image_id] = (boxes, scores)\n    return output_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def run_wbf_4preds(test_df, \n                   box_pred1, score_pred1, label_pred1, \n                   box_pred2, score_pred2, label_pred2, \n                   box_pred3, score_pred3, label_pred3, \n                   box_pred4, score_pred4, label_pred4,\n                   resolution_dict, NMS_THRESH, BOX_THRESH, PP_THRESH):\n    output_dict = {}\n    for image_id in np.unique(test_df.image_id.values):\n        boxes = box_pred1[image_id] + box_pred2[image_id] + box_pred3[image_id] + box_pred4[image_id]\n        scores = score_pred1[image_id] + score_pred2[image_id] + score_pred3[image_id] + score_pred4[image_id]\n        labels = label_pred1[image_id] + label_pred2[image_id] + label_pred3[image_id] + label_pred4[image_id]\n\n        boxes, scores, labels = weighted_boxes_fusion(boxes, scores, labels, weights=None, iou_thr=NMS_THRESH, skip_box_thr=BOX_THRESH)\n        boxes = np.array(boxes)\n        scores = np.array(scores)\n\n        idxs = np.where(scores > PP_THRESH)[0]\n        boxes = boxes[idxs]\n        scores = scores[idxs]\n\n        if len(boxes) > 0:\n            height, width = resolution_dict[image_id]\n            boxes[:, [0,2]] = (boxes[:, [0,2]]*width).clip(min=0, max=width-1)\n            boxes[:, [1,3]] = (boxes[:, [1,3]]*height).clip(min=0, max=height-1)\n        output_dict[image_id] = (boxes, scores)\n    return output_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get resolution for each image in test set\nwith Pool(processes=2) as pool:\n    results = [pool.apply_async(get_resolution, args=(image_id, TEST_DIR)) for image_id in list(np.unique(test_df.image_id.values))]\n    results = [ret.get() for ret in results]\npool.close()\nresolution_dict = {}\nfor ret in results:\n    resolution_dict[ret[0]] = (ret[1], ret[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!python predict.py  --network effdet \\\n                    --backbone ed7 \\\n                    --img-size 768 \\\n                    --batch-size 16 \\\n                    --workers 2 \\\n                    --test-csv /kaggle/input/global-wheat-detection/sample_submission.csv \\\n                    --test-dir /kaggle/input/global-wheat-detection/test \\\n                    --checkpoint-dir /kaggle/input/wheat2020-checkpoints \\\n                    --folds 0 1 2 3 4 \\\n                    --use-amp True\n\n!python predict.py  --network effdet \\\n                    --backbone ed7 \\\n                    --img-size 1024 \\\n                    --batch-size 16 \\\n                    --workers 2 \\\n                    --test-csv /kaggle/input/global-wheat-detection/sample_submission.csv \\\n                    --test-dir /kaggle/input/global-wheat-detection/test \\\n                    --checkpoint-dir /kaggle/input/wheat2020-checkpoints \\\n                    --folds 1 3 \\\n                    --use-amp True\n\n!python predict.py  --network effdet \\\n                    --backbone ed5 \\\n                    --img-size 512 \\\n                    --batch-size 16 \\\n                    --workers 2 \\\n                    --test-csv /kaggle/input/global-wheat-detection/sample_submission.csv \\\n                    --test-dir /kaggle/input/global-wheat-detection/test \\\n                    --checkpoint-dir /kaggle/input/wheat2020-checkpoints \\\n                    --folds 4 \\\n                    --use-amp True\n\n!python predict.py  --network fasterrcnn \\\n                    --backbone resnet152 \\\n                    --img-size 1024 \\\n                    --batch-size 16 \\\n                    --workers 2 \\\n                    --test-csv /kaggle/input/global-wheat-detection/sample_submission.csv \\\n                    --test-dir /kaggle/input/global-wheat-detection/test \\\n                    --checkpoint-dir /kaggle/input/wheat2020-checkpoints \\\n                    --folds 1 \\\n                    --use-amp False\n\neffdet_ed7_768_box_pred = load_dict('effdet_ed7_768_box_pred.pkl')\neffdet_ed7_768_score_pred = load_dict('effdet_ed7_768_score_pred.pkl')\neffdet_ed7_768_label_pred = load_dict('effdet_ed7_768_label_pred.pkl')\n\neffdet_ed7_1024_box_pred = load_dict('effdet_ed7_1024_box_pred.pkl')\neffdet_ed7_1024_score_pred = load_dict('effdet_ed7_1024_score_pred.pkl')\neffdet_ed7_1024_label_pred = load_dict('effdet_ed7_1024_label_pred.pkl')\n\neffdet_ed5_box_pred = load_dict('effdet_ed5_512_box_pred.pkl')\neffdet_ed5_score_pred = load_dict('effdet_ed5_512_score_pred.pkl')\neffdet_ed5_label_pred = load_dict('effdet_ed5_512_label_pred.pkl')\n\nfasterrcnn_box_pred = load_dict('fasterrcnn_resnet152_1024_box_pred.pkl')\nfasterrcnn_score_pred = load_dict('fasterrcnn_resnet152_1024_score_pred.pkl')\nfasterrcnn_label_pred = load_dict('fasterrcnn_resnet152_1024_label_pred.pkl')\n\noutput_dict = run_wbf_4preds(test_df, \n                             effdet_ed7_768_box_pred, effdet_ed7_768_score_pred, effdet_ed7_768_label_pred,\n                             effdet_ed7_1024_box_pred, effdet_ed7_1024_score_pred, effdet_ed7_1024_label_pred,\n                             effdet_ed5_box_pred, effdet_ed5_score_pred, effdet_ed5_label_pred,\n                             fasterrcnn_box_pred, fasterrcnn_score_pred, fasterrcnn_label_pred, \n                             resolution_dict, NMS_THRESH=0.50, BOX_THRESH=0.32, PP_THRESH=0.28)\n\ndel effdet_ed7_768_box_pred\ndel effdet_ed7_768_score_pred\ndel effdet_ed7_768_label_pred\n\ndel effdet_ed7_1024_box_pred\ndel effdet_ed7_1024_score_pred\ndel effdet_ed7_1024_label_pred\n\ndel effdet_ed5_box_pred\ndel effdet_ed5_score_pred\ndel effdet_ed5_label_pred\n\ndel fasterrcnn_box_pred\ndel fasterrcnn_score_pred\ndel fasterrcnn_label_pred\n\ngc.collect()\n\n## visualize\nif VISUALIZE:\n    visualize_result(test_df, TEST_DIR, output_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if PSEUDO:\n    df = pd.read_csv('csv/gwd2020.csv')   ### convert train.csv to image_id,fold,xmin,ymin,xmax,ymax,isbox,source\n    PSEUDO_FOLD = 1\n    make_pseudo_dataframe(test_df, output_dict, TEST_DIR, df, TRAIN_DIR, PSEUDO_FOLD)\n    del output_dict\n    gc.collect()\n\n    !python effdet_train.py --backbone ed6 \\\n                            --img-size 640 \\\n                            --batch-size 5 \\\n                            --pretrain-path /kaggle/input/wheat2020-checkpoints/effdet_ed6_640_fold1.pth \\\n                            --checkpoint-path ./effdet_ed6_640_fold1_with_optimizer.pth \\\n                            --epochs 10 \\\n                            --init-lr 8e-5 \\\n                            --mixup False \\\n                            --use-amp True \\\n                            --load-optimizer False \\\n                            --save-optimizer True\n    \n    #remove optimizer in checkpoint\n    refine_checkpoint_out('./effdet_ed6_640_fold1_with_optimizer.pth', './effdet_ed6_640_fold1.pth')\n    \n    !python predict.py  --network effdet \\\n                        --backbone ed6 \\\n                        --img-size 640 \\\n                        --batch-size 16 \\\n                        --workers 2 \\\n                        --test-csv /kaggle/input/global-wheat-detection/sample_submission.csv \\\n                        --test-dir /kaggle/input/global-wheat-detection/test \\\n                        --checkpoint-dir ./. \\\n                        --folds 1 \\\n                        --use-amp True\n\n    box_pred = load_dict('effdet_ed6_640_box_pred.pkl')\n    score_pred = load_dict('effdet_ed6_640_score_pred.pkl')\n    label_pred = load_dict('effdet_ed6_640_label_pred.pkl')\n    output_dict = run_wbf(test_df, box_pred, score_pred, label_pred, \n                          resolution_dict, NMS_THRESH=0.50, BOX_THRESH=0.42, PP_THRESH=0.32)\n    del box_pred\n    del score_pred\n    del label_pred\n    gc.collect()\n\n    !rm -rf ./train.csv\n    !rm -rf ./valid.csv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if PSEUDO:\n    df = pd.read_csv('csv/gwd2020.csv')   ### convert train.csv to image_id,fold,xmin,ymin,xmax,ymax,isbox,source\n    PSEUDO_FOLD = 1\n    make_pseudo_dataframe(test_df, output_dict, TEST_DIR, df, TRAIN_DIR, PSEUDO_FOLD)\n    del output_dict\n    gc.collect()\n\n    !python effdet_train.py --backbone ed6 \\\n                            --img-size 640 \\\n                            --batch-size 5 \\\n                            --pretrain-path ./effdet_ed6_640_fold1_with_optimizer.pth \\\n                            --checkpoint-path ./effdet_ed6_640_fold1.pth \\\n                            --epochs 6 \\\n                            --init-lr 1e-5 \\\n                            --mixup False \\\n                            --use-amp True \\\n                            --load-optimizer True \\\n                            --save-optimizer False\n    \n    !python predict.py  --network effdet \\\n                        --backbone ed6 \\\n                        --img-size 640 \\\n                        --batch-size 16 \\\n                        --workers 2 \\\n                        --test-csv /kaggle/input/global-wheat-detection/sample_submission.csv \\\n                        --test-dir /kaggle/input/global-wheat-detection/test \\\n                        --checkpoint-dir ./. \\\n                        --folds 1 \\\n                        --use-amp True\n\n    box_pred = load_dict('effdet_ed6_640_box_pred.pkl')\n    score_pred = load_dict('effdet_ed6_640_score_pred.pkl')\n    label_pred = load_dict('effdet_ed6_640_label_pred.pkl')\n    output_dict = run_wbf(test_df, box_pred, score_pred, label_pred, \n                          resolution_dict, NMS_THRESH=0.50, BOX_THRESH=0.44, PP_THRESH=0.34)\n    del box_pred\n    del score_pred\n    del label_pred\n    gc.collect()\n\n    !rm -rf ./train.csv\n    !rm -rf ./valid.csv\n    !rm -rf effdet_ed6_640_fold1_with_optimizer.pth","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm -rf ./effdet\n!rm -rf ./csv\n!rm -rf ./*.py\n!rm -rf ./*.pkl\n!rm -rf ./LICENSE\n!rm -rf ./README.md\n!rm -rf ./__pycache__\n!ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = []\nfor image_id in list(np.unique(test_df.image_id.values)):\n    boxes, scores = output_dict[image_id]\n    if len(boxes) > 0:\n        boxes = boxes.astype(np.int32)\n        #xyxy to xywh\n        boxes[:, 2] = boxes[:, 2] - boxes[:, 0]\n        boxes[:, 3] = boxes[:, 3] - boxes[:, 1]\n        \n    result = {\n        'image_id': image_id,\n        'PredictionString': format_prediction_string(boxes, scores)\n    }\n    results.append(result)\nsub_df = pd.DataFrame(results, columns=['image_id', 'PredictionString'])\nsub_df.to_csv('submission.csv', index=False)\nprint(sub_df.head(20))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}