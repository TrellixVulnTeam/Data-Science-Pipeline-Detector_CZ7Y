{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install ../input/wheat-detection/torch-1.5.0cu101-cp37-cp37m-linux_x86_64.whl\n!pip install ../input/wheat-detection/torchvision-0.6.0cu101-cp37-cp37m-linux_x86_64.whl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install ../input/wheat-detection/Pillow-7.2.0-cp37-cp37m-manylinux1_x86_64.whl\n!pip install ../input/wheat-detection/pycocotools-2.0.1-cp37-cp37m-linux_x86_64.whl\n!pip install ../input/wheat-detection/yacs-0.1.7-py3-none-any.whl\n!pip install ../input/wheat-detection/fvcore-0.1.1.post20200716-py3-none-any.whl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install ../input/wheat-detection/detectron2-0.2cu101-cp37-cp37m-linux_x86_64.whl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import detectron2\nfrom detectron2.utils.logger import setup_logger\n\nsetup_logger()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from detectron2.data import datasets, DatasetCatalog, MetadataCatalog,\\\nbuild_detection_train_loader, build_detection_test_loader\nimport pandas as pd\n\nDIR_INPUT = '../input/global-wheat-detection'\nsub_df = pd.read_csv(f'{DIR_INPUT}/sample_submission.csv')\ndata_dir = '../input/global-wheat-detection/test'\ndata_set_prefix = 'wheat'\n\nfor d in [\"train\", \"test\"]:\n    DatasetCatalog.register(\n        f\"{data_set_prefix}_{d}\",\n        lambda d=d: wheat_dataset(\n            tsub_df,\n            data_dir,\n            False,\n        ),\n    )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\nfrom tqdm.notebook import tqdm\nimport os\n\ndef wheat_dataset(df, folder, is_train):\n    unique_img_names = df[\"image_id\"].unique().tolist()  # Take unique image names\n    df_group = df.groupby(\"image_id\")  # Group the training by the image ids\n    dataset_dicts = []\n\n    for img_id, img_name in enumerate(tqdm(unique_img_names)):\n        img_group = df_group.get_group(img_name)  # Take all annotations for an image\n        img_path = os.path.join(folder, img_name + \".jpg\")  # Create path for an image\n        img = cv2.imread(img_path)\n        h, w = img.shape[:2]\n\n        record = dict()\n        record[\"file_name\"] = img_path\n        record[\"image_id\"] = img_id\n        record[\"height\"] = int(h)\n        record[\"width\"] = int(w)\n\n        dataset_dicts.append(record)\n\n    return dataset_dicts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class BaseWheatTTA:\n    \"\"\" author: @shonenkov \"\"\"\n    image_size = 1024\n\n    def augment(self, image):\n        raise NotImplementedError\n    \n    def batch_augment(self, images):\n        raise NotImplementedError\n    \n    def deaugment_boxes(self, boxes):\n        raise NotImplementedError\n\nclass TTAHorizontalFlip(BaseWheatTTA):\n    \"\"\" author: @shonenkov \"\"\"\n\n    def augment(self, image):\n        return image.flip(1)\n    \n    def batch_augment(self, images):\n        return images.flip(2)\n    \n    def deaugment_boxes(self, boxes):\n        boxes[:, [1,3]] = self.image_size - boxes[:, [3,1]]\n        return boxes\n\nclass TTAVerticalFlip(BaseWheatTTA):\n    \"\"\" author: @shonenkov \"\"\"\n    \n    def augment(self, image):\n        return image.flip(2)\n    \n    def batch_augment(self, images):\n        return images.flip(3)\n    \n    def deaugment_boxes(self, boxes):\n        boxes[:, [0,2]] = self.image_size - boxes[:, [2,0]]\n        return boxes\n    \nclass TTARotate90(BaseWheatTTA):\n    \"\"\" author: @shonenkov \"\"\"\n    \n    def augment(self, image):\n        return torch.rot90(image, 1, (1, 2))\n\n    def batch_augment(self, images):\n        return torch.rot90(images, 1, (2, 3))\n    \n    def deaugment_boxes(self, boxes):\n        res_boxes = boxes.copy()\n        res_boxes[:, [0,2]] = self.image_size - boxes[:, [1,3]]\n        res_boxes[:, [1,3]] = boxes[:, [2,0]]\n        return res_boxes\n\nclass TTACompose(BaseWheatTTA):\n    \"\"\" author: @shonenkov \"\"\"\n    def __init__(self, transforms):\n        self.transforms = transforms\n        \n    def augment(self, image):\n        for transform in self.transforms:\n            image = transform.augment(image)\n        return image\n    \n    def batch_augment(self, images):\n        for transform in self.transforms:\n            images = transform.batch_augment(images)\n        return images\n    \n    def prepare_boxes(self, boxes):\n        result_boxes = boxes.copy()\n        result_boxes[:,0] = np.min(boxes[:, [0,2]], axis=1)\n        result_boxes[:,2] = np.max(boxes[:, [0,2]], axis=1)\n        result_boxes[:,1] = np.min(boxes[:, [1,3]], axis=1)\n        result_boxes[:,3] = np.max(boxes[:, [1,3]], axis=1)\n        return result_boxes\n    \n    def deaugment_boxes(self, boxes):\n        for transform in self.transforms[::-1]:\n            boxes = transform.deaugment_boxes(boxes)\n        return self.prepare_boxes(boxes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from detectron2.config import get_cfg\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor\n\ndef test_cfg():\n    cfg = get_cfg()\n    cfg.MODEL.DEVICE='cpu'\n    cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n    #cfg.MODEL.WEIGHTS = '../input/modelfile/model_final.pth'\n    cfg.MODEL.WEIGHTS = '../input/modelfile2/model_final _iter10000.pth'\n    cfg.DATASETS.TEST = ('wheat_test', )\n    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.45\n    \n    return cfg\n\ncfg = test_cfg()\npredict = DefaultPredictor(cfg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\ndef rotate90(img):\n    tempimg = cv2.rotate(img.copy(), cv2.ROTATE_90_COUNTERCLOCKWISE)\n    outputs = predict(tempimg)['instances']\n    boxes = [i.cpu().detach().numpy() for i in outputs.pred_boxes]\n    res_boxes = boxes.copy()\n    for i in range(len(res_boxes)):\n        res_boxes[i] = res_boxes[i].tolist()\n        res_boxes[i][0] = 1024 - boxes[i][1]\n        res_boxes[i][2] = 1024 - boxes[i][3]\n        res_boxes[i][1] = boxes[i][2]\n        res_boxes[i][3] = boxes[i][0]\n    scores = outputs.scores.cpu().detach().numpy()\n    return res_boxes, scores","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def submit():\n\n    for idx, row in tqdm(sub_df.iterrows(), total=len(sub_df)):\n        boxes = []\n        scores = []\n        img_path = os.path.join(\"../input/global-wheat-detection/test/\", row.image_id+'.jpg')\n        img = cv2.imread(img_path)\n        outputs = predict(img)['instances']\n        boxes.extend([i.cpu().detach().numpy() for i in outputs.pred_boxes])\n        scores.extend(outputs.scores.cpu().detach().numpy())\n        boxes.extend(rotate90(img)[0])\n        scores.extend(rotate90(img)[1])\n        list_str = []\n        for box, score in zip(boxes, scores):\n            box[3] -= box[1]\n            box[2] -= box[0]\n            box = list(map(int, box))\n            score = round(score, 4)\n            list_str.append(score) \n            list_str.extend(box)\n        sub_df.loc[idx, 'PredictionString'] = ' '.join(map(str, list_str))\n    \n    return sub_df\n\nsub_df = submit()    \nsub_df.to_csv('submission.csv', index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}