{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport cv2\nfrom matplotlib import pyplot as plt\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/global-wheat-detection/train.csv')\nbboxs = np.stack(df['bbox'].apply(lambda x: np.fromstring(x[1:-1], sep=',')))\nfor i, column in enumerate(['x', 'y', 'w', 'h']):\n    df[column] = bboxs[:,i]\ndf.drop(columns=['bbox'], inplace=True)\ndf['x_center'] = df['x'] + df['w']/2\ndf['y_center'] = df['y'] + df['h']/2\ndf['classes'] = 0\nfrom tqdm.auto import tqdm\nimport shutil as sh\ndf = df[['image_id','x', 'y', 'w', 'h','x_center','y_center','classes']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"index = list(set(df.image_id))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"source = 'train'\nif True:\n    for fold in [0]:\n        val_index = index[len(index)*fold//5:len(index)*(fold+1)//5]\n        for name,mini in tqdm(df.groupby('image_id')):\n            if name in val_index:\n                path2save = 'val2017/'\n            else:\n                path2save = 'train2017/'\n            if not os.path.exists('convertor/fold{}/labels/'.format(fold)+path2save):\n                os.makedirs('convertor/fold{}/labels/'.format(fold)+path2save)\n            with open('convertor/fold{}/labels/'.format(fold)+path2save+name+\".txt\", 'w+') as f:\n                row = mini[['classes','x_center','y_center','w','h']].astype(float).values\n                row = row/1024\n                row = row.astype(str)\n                for j in range(len(row)):\n                    text = ' '.join(row[j])\n                    f.write(text)\n                    f.write(\"\\n\")\n            if not os.path.exists('convertor/fold{}/images/{}'.format(fold,path2save)):\n                os.makedirs('convertor/fold{}/images/{}'.format(fold,path2save))\n            sh.copy(\"../input/global-wheat-detection/{}/{}.jpg\".format(source,name),'convertor/fold{}/images/{}/{}.jpg'.format(fold,path2save,name))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!git clone https://github.com/apereirac/cr-plates-generator\n!pip install rstr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%cd cr-plates-generator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport glob\nimport time\nimport numpy as np\nimport plate\nimport context\nimport jsonutil\nimport perspective\nimport scene\nimport utils\nimport annotations","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from perspective import *\ndef warp_image2(image, bboxes, context,theta, phi, gamma):\n    step = int(context.getConfig(\"Perspective\", \"rotation_step\"))\n    fov = int(context.getConfig(\"Perspective\", \"field_of_view\"))\n    scale = float(context.getConfig(\"Perspective\", \"scale\"))\n    rotate_bboxes = context.getBoolean(\"Image\", \"rotate_bboxes\")\n    result_image, result_bboxes = warp_image(image, theta, phi, gamma, scale, fov, bboxes, rotate_bboxes)\n    return result_image, result_bboxes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"appContext = context.Context('configuration.cfg')\ndataset_size = int(appContext.getConfig('General', 'dataset_size'))\noutput_path = appContext.getConfig('General', 'output_path')\nannotator_type = appContext.getConfig('General', 'annotation_type')\nclear_output = appContext.getBoolean('General', 'clear_output')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls /kaggle/working/convertor/fold0/images","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r = [row.split(\".jpg\")[0] for row in os.listdir('/kaggle/working/convertor/fold0/images/val2017')]\nr[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def warp(image_data,f,size=1024,teta=10,phi=10):\n    image_data = cv2.resize(image_data,(size,size))\n    f = np.array(f.read().replace(\"\\n\",\" \").split(\" \")[:-1]).astype(float)\n    row = f.reshape(-1,5)[:,1:]*size\n    bounding_boxes = []\n    for f in row:\n        bounding_boxes0 = {\"cx\":f[0],\"cy\":f[1],\"w\":f[2],\"h\":f[3]}\n        bounding_boxes.append(bounding_boxes0)\n    image_data2, bounding_boxes2 =warp_image2(image_data, bounding_boxes, appContext,phi, teta, 0)\n    bounding_boxes_result = []\n    for bb in bounding_boxes2:\n        cx = bb['cx']\n        w1 = bb['w']\n        cy = bb['cy']\n        h1 = bb['h']\n        box = [cx-w1//2,cy-h1//2,cx + w1//2,cy + h1//2]\n        box = np.array(box).astype(int)\n        bounding_boxes_result.append(box)\n    return image_data2,bounding_boxes_result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_image(teta,phi):\n    image_data = cv2.imread(\"/kaggle/working/convertor/fold0/images/val2017/{}.jpg\".format(r[index]))[:,:,::-1]\n    image_data = cv2.resize(image_data,(1024,1024))\n    f = open(\"/kaggle/working/convertor/fold0/labels/val2017/{}.txt\".format(r[index]))\n    image_data1,bounding_boxes_result = warp(image_data,f,size=1024,teta=teta,phi=phi)\n    for i,box in enumerate(bounding_boxes_result):\n        if i==0:\n            image_data1 = cv2.rectangle(image_data1,(box[0], box[1]),(box[2], box[3]),(255, 0, 0), 2)\n        else:\n            image_data1 = cv2.rectangle(image_data1,(box[0], box[1]),(box[2], box[3]),(0, 255, 0), 2)\n    return image_data1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"index = 80\nimport matplotlib.pyplot as plt\nfrom matplotlib.widgets import Slider, Button, RadioButtons\n%matplotlib notebook\nt = np.arange(0.0, 1.0, 0.001)\na0 = 0\nf0 = 0\ndelta_f = 5.0\nfig, ax = plt.subplots(1, 1,figsize=[10,10])\nl = plt.imshow(get_image(0,0))\naxcolor = 'lightgoldenrodyellow'\naxfreq = plt.axes([0.25, 0.1, 0.65, 0.03], facecolor=axcolor)\naxamp = plt.axes([0.25, 0.15, 0.65, 0.03], facecolor=axcolor)\n\nsfreq = Slider(axfreq, 'theta', -90.0, 90.0, valinit=f0, valstep=delta_f)\nsamp = Slider(axamp, 'phi', -90.0, 90.0, valinit=a0)\n\n\ndef update(val):\n    amp = samp.val\n    freq = sfreq.val\n    l.set_data(get_image(amp,freq))\n    fig.canvas.draw_idle()\n\n\nsfreq.on_changed(update)\nsamp.on_changed(update)\n\nresetax = plt.axes([0.8, 0.025, 0.1, 0.04])\nbutton = Button(resetax, 'Reset', color=axcolor, hovercolor='0.975')\n\n\ndef reset(event):\n    sfreq.reset()\n    samp.reset()\nbutton.on_clicked(reset)\n\n\n\n\ndef colorfunc(label):\n    l.set_color(label)\n    fig.canvas.draw_idle()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}