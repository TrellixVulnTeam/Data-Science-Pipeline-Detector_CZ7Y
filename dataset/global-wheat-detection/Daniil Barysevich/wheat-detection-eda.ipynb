{"cells":[{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://cdn11.img.sputnik.by/images/102461/23/1024612300.jpg\" width=\"400\" height=\"400\">"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nfrom PIL import Image, ImageDraw\nfrom ast import literal_eval\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input/global-wheat-detection","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loading the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"root_path = \"../input/global-wheat-detection/\"\ntrain_folder = os.path.join(root_path, \"train\")\ntest_folder = os.path.join(root_path, \"test\")\ntrain_csv_path = os.path.join(root_path, \"train.csv\")\nsample_submission = os.path.join(root_path, \"sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(train_csv_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Some basic statistics"},{"metadata":{},"cell_type":"markdown","source":"All of the annotated images have resolution 1024 x 1024"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['width'].unique() == df['height'].unique() == [1024]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_bbox_area(bbox):\n    bbox = literal_eval(bbox)\n    return bbox[2] * bbox[3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['bbox_area'] = df['bbox'].apply(get_bbox_area)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['bbox_area'].value_counts().hist(bins=50)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As organizers say, there are many bounding boxes for each image, and not all images include wheat heads / bounding boxes."},{"metadata":{"trusted":true},"cell_type":"code","source":"unique_images = df['image_id'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_total = len(os.listdir(train_folder))\nnum_annotated = len(unique_images)\n\nprint(f\"There are {num_annotated} annotated images and {num_total - num_annotated} images without annotations.\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see all the unique sources of data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"sources = df['source'].unique()\nprint(f\"There are {len(sources)} sources of data: {sources}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['source'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's look at how many bounding boxes do we have for each image:"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(df['image_id'].value_counts(), bins=30)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Max number of bounding boxes is 116, whereas min (annotated) number is 1 "},{"metadata":{},"cell_type":"markdown","source":"## Visualizing images"},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_images(images, num = 5):\n    \n    images_to_show = np.random.choice(images, num)\n\n    for image_id in images_to_show:\n\n        image_path = os.path.join(train_folder, image_id + \".jpg\")\n        image = Image.open(image_path)\n\n        # get all bboxes for given image in [xmin, ymin, width, height]\n        bboxes = [literal_eval(box) for box in df[df['image_id'] == image_id]['bbox']]\n\n        # visualize them\n        draw = ImageDraw.Draw(image)\n        for bbox in bboxes:    \n            draw.rectangle([bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1] + bbox[3]], width=3)\n\n        plt.figure(figsize = (15,15))\n        plt.imshow(image)\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_images(unique_images)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Loook at photos by their source:"},{"metadata":{"trusted":true},"cell_type":"code","source":"for source in sources:\n    print(f\"Showing images for {source}:\")\n    show_images(df[df['source'] == source]['image_id'].unique(), num = 3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What can we tell from visualizations:\n\n* there are plenty of overlappind bounding boxes\n* all photos seem to be taken vertically \n* all plants are can be rotated differently, there is no single orientation. this means that different flip and roration agumentations should probably help\n* colors of wheet heads are quite different and seem to depend a little bit on the source\n* wheet heads themselves are seen from very different angles of view relevant to the observer"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}