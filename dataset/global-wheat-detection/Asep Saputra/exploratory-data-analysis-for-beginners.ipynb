{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Global Wheat Detection","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### An international computer science competition to count wheat ears more effectively, using image analysis","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<div align=\"center\"> <img width=\"512\" height=\"116\" src=\"http://www.global-wheat.com/wp-content/uploads/2019/11/temporary_gwd_logo-2.png\"</div>\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### The Problem \n\nFor several years, agricultural research has been using sensors to observe plants at key moments in their development. However, some important plant traits are still measured manually. One example of this is the manual counting of wheat ears from digital images – a long and tedious job. Factors that make it difficult to manually count wheat ears from digital images include the possibility of overlapping ears, variations in appearance according to maturity and genotype, the presence or absence of barbs, head orientation and even wind.  \n \n\n### The Need \n\nThere is the need for a robust and accurate computer model that is capable of counting wheat ears from digital images. This model will benefit phenotyping research and help producers around the world assess ear density, health and maturity more effectively. Some work has already been done in deep learning, though it has resulted in too little data to have a generic model.  \n\n\nRefer [this](http://www.global-wheat.com/) page for more details.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<div align=\"center\"><img src=\"http://www.global-wheat.com/wp-content/uploads/2020/04/ILLU_01_EN.jpg\" width=\"800\"/></div>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Let's Code!","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We can see the contents of the directory by using the os module","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nprint(os.listdir('../input/global-wheat-detection/'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are two folders namely train and test, and csv file for train and sample submission. Now, we we explore the file train.csv","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\ntrain_csv = pd.read_csv('../input/global-wheat-detection/train.csv')\ntrain_csv.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_csv.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"How does it look? we can see","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_csv.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Are there empty values ​​in the file? we check","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_csv.isnull().any().any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Good, it will make it easier for us to process data. now we get the whole info","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_csv.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### For widht dan hight","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_csv.width.unique())\nprint(train_csv.height.unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### For source","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"unique = train_csv['source'].unique()\nprint(unique)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_csv.image_id.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_csv.groupby(\"source\").image_id.count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nunique = train_csv.image_id.nunique()\nprint(nunique)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### For image_id","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_csv.groupby(\"source\").image_id.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can Visualization this","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\nplt.rcParams['figure.figsize'] = (18, 8)\nplt.rcParams['figure.figsize'] = (15, 10)\nsns.countplot(train_csv['source'], palette = 'hsv')\nplt.title('Distribution of Source', fontsize = 20)\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = ['ethz_1', 'arvalis_1', 'rres_1','arvalis_3','usask_1','arvalis_2','inrae_1 ']\nplt.rcParams['figure.figsize'] = (7, 7)\nplt.pie(train_csv['source'].value_counts(),labels=labels,explode = [0.0,0.0,0.05,0.05,0.2,0.2,0.2], autopct = '%.2f%%')\nplt.title('Source', fontsize = 21)\nplt.axis('off')\nplt.legend(loc='lower center', bbox_to_anchor=(1, 1))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### For bbox","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from ast import literal_eval\n\ndef get_bbox_area(bbox):\n    bbox = literal_eval(bbox)\n    return bbox[2] * bbox[3]\ntrain_csv['bbox_area'] = train_csv['bbox'].apply(get_bbox_area)\ntrain_csv['bbox_area'].value_counts().hist(bins=33)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory : train (images)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dir = '../input/global-wheat-detection/train'\ntest_dir = '../input/global-wheat-detection/test'\n\nprint('total train images:', len(os.listdir(train_dir)))\nprint('total test images:', len(os.listdir(test_dir)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.image as mpimg\n\npic_index = 100\ntrain_files = os.listdir(train_dir)\n\n\nnext_train = [os.path.join(train_dir, fname) \n                for fname in train_files[pic_index-4:pic_index]]\n\nfor i, img_path in enumerate(next_train):\n  img = mpimg.imread(img_path)\n  plt.imshow(img)\n  plt.axis('Off')\n  plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas_profiling import ProfileReport\nprofile = ProfileReport(train_csv, title='Report',progress_bar = False);\nprofile.to_widgets()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Get Predict","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}