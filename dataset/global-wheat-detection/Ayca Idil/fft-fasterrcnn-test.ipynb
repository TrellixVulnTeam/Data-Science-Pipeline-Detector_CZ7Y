{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport cv2\n\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\n\nimport torch\nimport torchvision\nimport torch.nn.functional as F\n\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.utils.data.sampler import SequentialSampler\n\nfrom matplotlib import pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load the model and restore parameters\nmodel = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained_backbone=False)\n\nnum_classes = 2  # 1 class (wheat) + background\n\n# get number of input channels for the final linear classifier\nin_features = model.roi_heads.box_predictor.cls_score.in_features\n\n# replace the pre-trained head with a new one\nmodel.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n\n# load the trained weights\ntrained_weights=torch.load('/kaggle/input/my-own-starter-fft-fasterrcnn-train/'+\\\n                           'fft_faster_rcnn_weights_w_metric_6_epochs.pth.tar',\\\n                            map_location=torch.device('cpu'))\nmodel.load_state_dict(trained_weights['model_state_dict'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device=torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nmodel=model.to(device)\nprint(device)\n\ndef format_prediction_string(boxes, scores):\n    pred_strings = []\n    for s, b in zip(scores, boxes.astype(int)):\n        pred_strings.append(f'{s:.4f} {b[0]} {b[1]} {b[2] - b[0]} {b[3] - b[1]}')\n\n    return \" \".join(pred_strings)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# boxes=np.array([])\n# scores=np.array([])\n# print(type(boxes))\n# print(boxes.astype(int))\n\n# pred_strings = []\n# for s, b in zip(scores, boxes.astype(int)):\n#     pred_strings.append(f'{s:.4f} {b[0]} {b[1]} {b[2] - b[0]} {b[3] - b[1]}')\n# \" \".join(pred_strings)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load and get fft masks\nall_ffts=np.load('../input/wheat-mean-ffts-200-images/wheat_detection_mean_ffts_200_images.npz')\nwheat_freq=all_ffts['wheat_freq']\nim_freq=all_ffts['im_freq']\npad2=1024\n\nthr_list=[0.2, 0.4, 0.6, 0.8]\nn_thr=len(thr_list)\nmask=np.zeros((pad2,pad2,3,n_thr))\nfor i in range(3):\n    plot_wheat=np.log(wheat_freq[:,:,i])\n    plot_im=np.log(im_freq[:,:,i])\n\n#     print(np.min(plot_wheat))\n#     print(np.min(plot_im))\n\n    # if printed values all positive\n    if np.min(plot_wheat)>0 and np.min(plot_im)>0:\n        plot_wheat[0,:]=0\n        plot_wheat[:,0]=0\n        plot_im[0,:]=0\n        plot_im[:,0]=0\n\n    plot_wheat=plot_wheat/np.sum(np.abs(plot_wheat))\n    plot_im=plot_im/np.sum(np.abs(plot_im))\n\n    fft_diff=plot_wheat-plot_im\n    fft_diff=np.fft.fftshift(fft_diff)\n\n    for kt in range(n_thr):\n        f_thr=thr_list[kt]\n        mask[:,:,i,kt]=fft_diff>f_thr*1e-7\n        exclude=120\n        mask[:exclude,:,:,kt],mask[-exclude:,:,:,kt]=0,0\n        mask[:,:exclude,:,kt],mask[:,-exclude:,:,kt]=0,0\n        \n        plt.figure()\n        plt.imshow(mask[:,:,i,kt],vmin=-0.2e-7,vmax=2e-7)\n        plt.colorbar()\n        plt.pause(0.1)\n\n        mask[:,:,i,kt]=np.fft.fftshift(mask[:,:,i,kt])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mask_input(images,mask,thr_list,pad2):\n    new_images=[]\n    n_thr=len(thr_list)\n    im_masked=np.zeros((3,pad2,pad2))\n    for image in images:\n        # get fft of full image in 3 color channels and mask\n        for j in range(3):\n            for kt in range(n_thr):\n                im_masked[j,:,:]+=np.real(np.fft.ifft2(np.fft.fft2(image[j,:,:])*mask[:,:,j,kt]))\n        # normalize to 0-1\n        im_masked=im_masked-np.min(im_masked)\n        im_masked=im_masked/np.max(im_masked)\n        \n        new_images.append(torch.from_numpy(im_masked).float())\n    return new_images    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Resizing input 'correctly' for avoiding syntax errors, but this will make the bboxes WRONG\n# For FasterRCNN different threshold than MaskRCNN\ndetection_threshold = 0.80\n\nmodel.eval()\nresults = []\nfor images in os.listdir(\"../input/global-wheat-detection/test/\"):\n    image_path = os.path.join(\"../input/global-wheat-detection/test/\", images)\n\n    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n    image = np.transpose(image, (2, 0, 1))\n    image /= 255.0\n\n    image = torch.tensor(image, dtype=torch.float)\n    \n    # Interpolate to 1024x1024 for masking\n    reinterpolate=False\n    if image.shape[1]!=pad2 or image.shape[2]!=pad2:\n        re_h=image.shape[1]\n        re_w=image.shape[2]\n        image=F.interpolate(image[None,:,:,:], size=(pad2, pad2), mode='bilinear')\n        image=torch.squeeze(image)\n        reinterpolate=True\n    \n    # mask the input images\n    image = mask_input([image],mask,thr_list,pad2)\n    image = image[0].to(device)\n    \n    # Reinterpolate to original size for forward pass\n    if reinterpolate:\n        image=F.interpolate(image[None,:,:,:], size=(re_h, re_w), mode='bilinear')\n    else:\n        image=torch.unsqueeze(image, 0)\n\n        \n    with torch.no_grad():\n        outputs = model(image)\n    \n    boxes = outputs[0]['boxes'].data.cpu().numpy()\n    scores = outputs[0]['scores'].data.cpu().numpy()\n\n    boxes = boxes[scores >= detection_threshold].astype(np.int32)\n    scores = scores[scores >= detection_threshold]\n    image_id = images[:-4]\n    \n    print(image_id)\n\n    result = {\n        'image_id': image_id,\n        'PredictionString': format_prediction_string(boxes, scores)\n    }\n\n    results.append(result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.DataFrame(results, columns=['image_id', 'PredictionString'])\ntest_df.head()\n\ntest_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}