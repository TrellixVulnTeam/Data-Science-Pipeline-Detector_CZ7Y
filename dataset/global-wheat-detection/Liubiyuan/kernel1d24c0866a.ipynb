{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport sys\nsys.path.insert(0,\"../input/wheatutils/yolov5-master-pure/yolov5-master\")\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfrom utils import google_utils\nfrom utils.datasets import *\nfrom utils.utils import *\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport cv2\nimport os\n\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Configure**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef run_wbf(boxes, scores, image_size=1023, iou_thr=0.5, skip_box_thr=0.7, weights=None):\n    #boxes = [prediction[image_index]['boxes'].data.cpu().numpy()/(image_size-1) for prediction in predictions]\n    #scores = [prediction[image_index]['scores'].data.cpu().numpy() for prediction in predictions]\n    labels = [np.zeros(score.shape[0]) for score in scores]\n    boxes = [box/(image_size) for box in boxes]\n    boxes, scores, labels = weighted_boxes_fusion(boxes, scores, labels, weights=None, iou_thr=iou_thr, skip_box_thr=skip_box_thr)\n    #boxes, scores, labels = nms(boxes, scores, labels, weights=[1,1,1,1,1], iou_thr=0.5)\n    boxes = boxes*(image_size)\n    return boxes, scores, labels\n\ndef TTAImage(image, index):\n    image1 = image.copy()\n    if index==0: \n        rotated_image = cv2.rotate(image1, cv2.ROTATE_90_CLOCKWISE)\n        return rotated_image\n    elif index==1:\n        rotated_image2 = cv2.rotate(image1, cv2.ROTATE_90_CLOCKWISE)\n        rotated_image2 = cv2.rotate(rotated_image2, cv2.ROTATE_90_CLOCKWISE)\n        return rotated_image2\n    elif index==2:\n        rotated_image3 = cv2.rotate(image1, cv2.ROTATE_90_CLOCKWISE)\n        rotated_image3 = cv2.rotate(rotated_image3, cv2.ROTATE_90_CLOCKWISE)\n        rotated_image3 = cv2.rotate(rotated_image3, cv2.ROTATE_90_CLOCKWISE)\n        return rotated_image3\n    elif index == 3:\n        return image1\n    \ndef rotBoxes90(boxes, im_w, im_h):\n    ret_boxes =[]\n    for box in boxes:\n        x1, y1, x2, y2 = box\n        x1, y1, x2, y2 = x1-im_w//2, im_h//2 - y1, x2-im_w//2, im_h//2 - y2\n        x1, y1, x2, y2 = y1, -x1, y2, -x2\n        x1, y1, x2, y2 = int(x1+im_w//2), int(im_h//2 - y1), int(x2+im_w//2), int(im_h//2 - y2)\n        x1a, y1a, x2a, y2a = min(x1, x2), min(y1, y2), max(x1, x2), max(y1, y2)\n        ret_boxes.append([x1a, y1a, x2a, y2a])\n    return np.array(ret_boxes)\n\ndef detect1Image(im0, imgsz, model, device, conf_thres, iou_thres):\n    img = letterbox(im0, new_shape=imgsz)[0]\n    # Convert\n    img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, to 3x416x416\n    img = np.ascontiguousarray(img)\n\n\n    img = torch.from_numpy(img).to(device)\n    img =  img.float()  # uint8 to fp16/32\n    img /= 255.0   \n    if img.ndimension() == 3:\n        img = img.unsqueeze(0)\n\n    # Inference\n    pred = model(img, augment=False)[0]\n\n    # Apply NMS\n    pred = non_max_suppression(pred, conf_thres, iou_thres)\n\n    boxes = []\n    scores = []\n    for i, det in enumerate(pred):  # detections per image\n        # save_path = 'draw/' + image_id + '.jpg'\n        if det is not None and len(det):\n            # Rescale boxes from img_size to im0 size\n            det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()\n\n            # Write results\n            for *xyxy, conf, cls in det:\n                boxes.append([int(xyxy[0]), int(xyxy[1]), int(xyxy[2]), int(xyxy[3])])\n                scores.append(conf)\n\n    return np.array(boxes), np.array(scores) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_hist = [[709,0,29,149,8,650,854,17,1532,224,319,2643,759,5639,3137,2741,6813,1621,2307,7205,2698,11966,4556,6124,4065,11436,9032,1096,2116,2476,21879,1433,6860,5239,14507,24854,9760,12524,19310,19484,24916,19586,25474,37620,28478,30689,40834,28251,42013,30700,35224,37839,30140,31922,24836,34327,28494,23063,21333,18109,20119,12411,17297,20126,10381,11759,16619,14940,6770,17773,7031,6054,7837,5466,10190,3770,4382,5194,679,2022,6769,1132,951,1318,2768,995,453,2119,517,279,1718,240,270,478,102,763,502,39,341,105,48,330,45,273,93,41,112,16,17,94,179,72,19,32,106,53,16,0,1,0,205,0,2,0,16,45,55,0,3,0,8,0,53,16,0,3,0,0,4,0,119,10,3,0,0,24,12,5,1,0,15,0,1,6,0,0,66,0,0,0,39,2,0,23,4,288,1,0,0,27,189,0,0,191,18,19,0,252,5,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n[340,2,8,17,32,63,98,120,162,160,207,304,418,489,553,651,723,857,1064,1216,1483,1724,1705,1875,1943,1998,2270,2239,2569,2473,2560,2654,3004,3027,2920,2895,3318,2913,3487,3397,3680,3530,3341,3949,4079,4111,4384,4470,4521,4698,4557,5080,4598,5367,4755,5675,5032,5364,6146,5855,6037,6378,6207,5712,7754,6290,6481,7644,6859,6605,8910,8369,6993,9633,8270,8426,8122,10626,10783,7943,9159,11868,10393,10482,8023,17871,8235,10538,11650,12445,13544,10063,11366,12589,13245,9114,13864,12585,11667,11404,12560,9429,15865,9455,11715,10499,12104,12521,11367,11314,8007,10997,11345,12327,8994,9322,9441,10355,9430,8092,10228,9169,8947,9216,8434,6804,4399,9155,14123,4004,5893,7453,7418,6617,7280,6767,5364,6619,5525,5116,5846,4570,5303,5998,3825,4079,5221,4204,3991,4970,3150,4082,2456,4520,2269,4185,2842,2398,3039,3285,1545,2663,2982,2137,1700,2112,2148,2198,1455,653,3972,592,1029,1905,1646,1025,794,1557,672,1726,939,1125,1155,679,1011,1083,563,560,1204,681,378,1289,164,560,577,524,530,640,735,276,647,434,436,347,686,223,543,323,275,521,356,363,163,435,353,280,275,342,134,417,260,253,266,308,255,148,189,292,224,131,281,167,176,199,193,290,137,194,155,135,165,143,167,188,166,142,156,154,155,87,86,25,7,0,0,6765],\n[0,0,3,3,11,10,16,29,22,60,114,190,404,700,1369,2295,3801,5877,7986,9680,11574,12894,13903,14184,14494,14412,13601,13549,12918,12379,12174,12048,11818,11625,11566,11261,11056,10916,10269,10301,9615,9290,8788,8550,8130,7821,7531,7273,7088,6850,6931,6875,6603,6667,6462,6456,6235,6287,6186,6223,5901,6081,6292,6163,6234,6039,6218,5826,5914,5803,5622,5615,5542,5439,5226,4979,4726,4766,4693,4592,4542,4500,4535,4700,4608,4582,4516,4493,4337,4290,4231,4141,3978,3893,3731,3606,3433,3472,3458,3544,3455,3519,3657,3610,3667,3863,3810,3915,3947,3896,3885,3782,3780,3553,3665,3694,3659,3764,3727,3746,3832,3907,3840,3980,4026,4051,4124,4307,4022,4019,4030,3827,3880,3984,3799,3946,3874,3900,3799,3880,3924,3677,3730,3661,3730,3599,3564,3529,3715,3626,3615,3627,3533,3404,3410,3413,3327,3193,3083,3075,3156,3164,3038,3094,3077,3126,3070,3029,3007,3131,3120,3029,3030,3126,2931,3007,2971,2883,2917,2786,2845,2784,2694,2752,2735,2731,2667,2774,2708,2716,2737,2647,2606,2637,2632,2705,2747,2644,2708,2759,2696,2732,2706,2732,2709,2678,2865,2700,2653,2558,2576,2560,2429,2492,2407,2394,2368,2311,2267,2113,2023,1961,1950,1791,1761,1713,1745,1597,1591,1528,1381,1385,1376,1314,1244,1136,1122,1071,943,895,851,800,774,744,735,666,613,533,499,450,416,370,351,316,277,1098]]\ntarget_hist = [np.array(x) for x in target_hist]\ndef img_hist(img):\n    img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n    hist_lst = []\n    save = False\n    if save:\n        file = open('target_hist.txt','w')\n    for i in range(3):\n        hist, _ = np.histogram(img_hsv[:, :, i].ravel(), 256, [0, 256])\n        if save:\n            s = '['+','.join([str(i) for i in hist])+']\\n'\n            file.write(s)\n        hist_lst.append(hist)\n    if save:\n        file.close()\n    return hist_lst\n\n\ndef aug_hist(src_img):\n    color = ('h', 's', 'v')\n    hist1_lst = img_hist(src_img)\n    hist2_lst = target_hist\n    src_hsv = cv2.cvtColor(src_img, cv2.COLOR_BGR2HSV)  # bgr转hsv\n    for i, col in enumerate(color):\n        # hist1 = cv2.calcHist([src_hsv], [i], None, [256], [0, 256])\n        hist1 = hist1_lst[i]\n        hist2 = hist2_lst[i]\n        cdf1 = hist1.cumsum()  # 灰度值0-255的累计值数组\n        cdf2 = hist2.cumsum()\n        cdf1_hist = hist1.cumsum() / cdf1.max()  # 灰度值的累计值的比率\n        cdf2_hist = hist2.cumsum() / cdf2.max()\n        diff_cdf = np.zeros([256, 256])  # diff_cdf 里是每2个灰度值比率间的差值\n        for j in range(256):\n            diff_cdf[j, :] = np.abs(cdf1_hist[j] - cdf2_hist)\n\n        lut = np.zeros(256)  # 映射表\n        for j in range(256):\n            # 直方图规定化的映射原理\n            index = int(np.argmin(diff_cdf[j,:]))\n            lut[j] = index\n        h = int(src_hsv.shape[0])\n        w = int(src_hsv.shape[1])\n        for j in range(h):  # 对原图像进行灰度值的映射\n            src_hsv[j, :, i] = lut[src_hsv[j, :, i]]\n\n    aug_img = cv2.cvtColor(src_hsv, cv2.COLOR_HSV2BGR)  # hsv转bgr\n    return aug_img","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nparser = {}\nparser['weights']='../input/best-train/best.pt'\nparser['source']='../input/global-wheat-detection/test'#/796707dd7.jpg\nparser['output']='/kaggle/input/global-wheat/'\nparser['img_size']=1024\nparser['conf_thresh']=0.35\nparser['iou_thresh']=0.6\nparser['agnostic_nms']=False\nparser['classes']=None\nparser['view_img']=True\nopt = parser\nshow = 0\naug_infer = 0\n#print(opt)\ndef detect(save_img=False):\n    out, source, weights, imgsz ,view_img= \\\n        opt['output'], opt['source'], opt['weights'], opt['img_size'],opt['view_img']\n\n\n    # Initialize\n    #device = opt['device']#torch_utils.select_device(opt['device'])\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n    # Load model\n    model = torch.load(weights, map_location=device)['model'].float()  # load to FP32\n    # torch.save(torch.load(weights, map_location=device), weights)  # update model if SourceChangeWarning\n    # model.fuse()\n    model.to(device).eval()\n\n    # Second-stage classifier\n    classify = False\n    if classify:\n        modelc = torch_utils.load_classifier(name='resnet101', n=2)  # initialize\n        modelc.load_state_dict(torch.load('weights/resnet101.pt', map_location=device)['model'])  # load weights\n        modelc.to(device).eval()\n\n    # Set Dataloader\n\n    dataset = LoadImages(source, img_size=imgsz)\n\n    # Get names and colors\n    names = model.module.names if hasattr(model, 'module') else model.names\n    colors = [[random.randint(0, 255) for _ in range(3)] for _ in range(len(names))]\n\n    # Run inference\n    t0 = time.time()\n    img = torch.zeros((1, 3, imgsz, imgsz), device=device)  # init img\n    _ = model(img) if device.type != 'cpu' else None  # run once\n    image_id_lst = [p.strip('.jpg') for p in os.listdir(source)]\n    df = pd.DataFrame(columns=['PredictionString'], index=image_id_lst)\n    fid = 0\n    for path, img, im0s, vid_cap in dataset:\n        if show:\n            fid += 1\n            plt.figure(fid)\n        image_id = path[path.rindex('/')+1:len(path)].strip('.jpg')\n        if aug_infer:\n            img = np.transpose(aug_hist(np.transpose(img,[1,2,0])),[2,0,1])\n        img = torch.from_numpy(img).to(device)\n        img = img.float()  # uint8 to fp32\n        img /= 255.0  # 0 - 255 to 0.0 - 1.0\n        if img.ndimension() == 3:\n            img = img.unsqueeze(0)\n            \n        # Inference\n        t1 = torch_utils.time_synchronized()\n        pred = model(img, augment=False)[0]\n\n        # Apply NMS\n        pred = non_max_suppression(pred, opt['conf_thresh'], opt['iou_thresh'], classes=opt['classes'], agnostic=opt['agnostic_nms'])\n        t2 = torch_utils.time_synchronized()\n\n#         # Apply Classifier\n#         if classify:\n#             pred = apply_classifier(pred, modelc, img, im0s)\n\n#         # Process detections\n        result = []\n        \n        for i, det in enumerate(pred):  # detections per image\n            if det is not None and len(det):\n                if show:\n                    plt.imshow(np.transpose(img.cpu().numpy()[0],[1,2,0]))\n\n                det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0s.shape).round()\n                for xmin,ymin,xmax,ymax, conf, cls in det:\n                    score = round(float(conf),2)\n                    width = xmax - xmin\n                    height = ymax - ymin\n                    result.append(' '.join(list(map(str, [score, int(xmin), int(ymin), int(width), int(height)]))))\n                    if show:\n                        plt.gca().add_patch(\n                            plt.Rectangle((int(xmin), int(ymin)), int(xmax) - int(xmin),\n                              int(ymax) - int(ymin), fill=False,\n                              edgecolor='r', linewidth=3)\n                        )\n            df.loc[image_id, 'PredictionString'] = ' '.join(result)\n        print('Done. (%.3fs)' % (t2 - t1))\n    df.reset_index(inplace=True, drop=False)\n    df.columns = ['image_id','PredictionString']\n    df.to_csv('submission.csv', index=False)\n    \n\nwith torch.no_grad():\n    detect()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}