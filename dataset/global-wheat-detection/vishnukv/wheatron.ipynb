{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install '/kaggle/input/pytorch-15/torch-1.5.0cu101-cp37-cp37m-linux_x86_64.whl'\n!pip install '/kaggle/input/pytorch-15/torchvision-0.6.0cu101-cp37-cp37m-linux_x86_64.whl'\n!pip install '/kaggle/input/pytorch-15/yacs-0.1.7-py3-none-any.whl'\n!pip install '/kaggle/input/pytorch-15/fvcore-0.1.1.post200513-py3-none-any.whl'\n!pip install '/kaggle/input/pytorch-15/pycocotools-2.0-cp37-cp37m-linux_x86_64.whl'\n!pip install '/kaggle/input/pytorch-15/detectron2-0.1.3cu101-cp37-cp37m-linux_x86_64.whl'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!nvidia-smi","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# install dependencies: (use cu101 because colab has CUDA 10.1)\n# !pip install -U torch==1.5 torchvision==0.6 -f https://download.pytorch.org/whl/cu101/torch_stable.html \n# !pip install cython pyyaml==5.1\n# !pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n# import torch, torchvision\n# print(torch.__version__, torch.cuda.is_available())\n# !gcc --version\n\n\n\n# # install detectron2:\n# !pip install detectron2==0.1.3 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.5/index.html","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport os\nimport random\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import patches\nimport seaborn as sns\n%matplotlib inline\n\nimport cv2\nimport itertools\n\nimport detectron2\nfrom detectron2.utils.logger import setup_logger\nsetup_logger()\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor, DefaultTrainer\nfrom detectron2.config import get_cfg\nfrom detectron2.utils.visualizer import Visualizer\nfrom detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader\nfrom detectron2.evaluation import COCOEvaluator, inference_on_dataset\nfrom detectron2.structures import BoxMode","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATA_DIR  = '../input/global-wheat-detection/train/'\nTEST_DIR  = '../input/global-wheat-detection/test/'\nList_Data_dir = os.listdir(DATA_DIR)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw = pd.read_csv('../input/global-wheat-detection/train.csv')\nraw","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract bbox column to xmin, ymin, width, height, then create xmax, ymax, and area columns\n\nraw[['xmin','ymin','w','h']] = pd.DataFrame(raw.bbox.str.strip('[]').str.split(',').tolist()).astype(float)\nraw['xmax'], raw['ymax'], raw['area'] = raw['xmin'] + raw['w'], raw['ymin'] + raw['h'], raw['w'] * raw['h']\nraw","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split train, val\nunique_files = raw.image_id.unique()\n\ntrain_files = set(np.random.choice(unique_files, int(len(unique_files) * 0.90), replace = False))\ntrain_df = raw[raw.image_id.isin(train_files)]\ntest_df = raw[~raw.image_id.isin(train_files)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def custom_dataset(df, dir_image):\n    \n    dataset_dicts = []\n    \n    for img_id, img_name in enumerate(df.image_id.unique()):\n        \n        record = {}\n        image_df = df[df['image_id'] == img_name]\n        img_path = dir_image + img_name + '.jpg'\n        \n        record['file_name'] = img_path\n        record['image_id'] = img_id\n        record['height'] = int(image_df['height'].values[0])\n        record['width'] = int(image_df['width'].values[0])\n                \n        objs = []\n        for _, row in image_df.iterrows():\n            \n            x_min = int(row.xmin)\n            y_min = int(row.ymin)\n            x_max = int(row.xmax)\n            y_max = int(row.ymax)\n            \n            poly = [(x_min, y_min), (x_max, y_min),\n                    (x_max, y_max), (x_min, y_max) ]\n            \n            poly = list(itertools.chain.from_iterable(poly))\n            \n            obj = {\n               \"bbox\": [x_min, y_min, x_max, y_max],\n               \"bbox_mode\": BoxMode.XYXY_ABS,\n               \"segmentation\": [poly],\n               \"category_id\": 0,\n               \"iscrowd\" : 0\n                \n                  }\n            \n            objs.append(obj)\n            \n        record['annotations'] = objs\n        dataset_dicts.append(record)\n        \n    return dataset_dicts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def register_dataset(df, dataset_label='wheat_train', image_dir = DATA_DIR):\n    \n    # Register dataset - if dataset is already registered, give it a new name    \n    try:\n        DatasetCatalog.register(dataset_label, lambda d=df: custom_dataset(df, image_dir))\n        MetadataCatalog.get(dataset_label).set(thing_classes = ['wheat'])\n    except:\n        # Add random int to dataset name to not run into 'Already registered' error\n        n = random.randint(1, 1000)\n        dataset_label = dataset_label + str(n)\n        DatasetCatalog.register(dataset_label, lambda d=df: custom_dataset(df, image_dir))\n        MetadataCatalog.get(dataset_label).set(thing_classes = ['wheat'])\n\n    return MetadataCatalog.get(dataset_label), dataset_label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metadata, train_dataset = register_dataset(train_df)\nmetadata, val_dataset = register_dataset(test_df, dataset_label='wheat_test')\n\nprint(metadata, train_dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cfg = get_cfg()\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/retinanet_R_101_FPN_3x.yaml\"))\ncfg.DATASETS.TRAIN = (train_dataset,)\ncfg.DATASETS.TEST = ()\ncfg.DATALOADER.NUM_WORKERS = 4\ncfg.MODEL.WEIGHTS = \"/kaggle/input/retinanet/R-101.pkl\"\ncfg.SOLVER.IMS_PER_BATCH = 4\ncfg.SOLVER.BASE_LR =  0.001\ncfg.SOLVER.MAX_ITER = 1500\ncfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256     \ncfg.MODEL.RETINANET.NUM_CLASSES = 1\n\n# cfg.SOLVER.WARMUP_ITERS = 1000\n\n# cfg.SOLVER.STEPS = (1000, 1500)\n# cfg.SOLVER.GAMMA = 0.05\n\n\n\n\nos.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\ntrainer = DefaultTrainer(cfg) \ntrainer.resume_or_load(resume=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainer.train()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cfg = get_cfg()\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/retinanet_R_101_FPN_3x.yaml\"))\ncfg.MODEL.WEIGHTS = \"output/model_final.pth\"\ncfg.MODEL.RETINANET.NUM_CLASSES = 1\ncfg.MODEL.RETINANET.SCORE_THRESH_TEST = 0.4\ncfg.DATASETS.TEST = ('wheat_test', )\npredictor = DefaultPredictor(cfg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluator = COCOEvaluator(val_dataset, cfg, False, output_dir=\"./output/\")\n# val_loader = build_detection_test_loader(cfg, val_dataset)\n# inference_on_dataset(trainer.model, val_loader, evaluator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CONFIG\n\nfont = cv2.FONT_HERSHEY_SIMPLEX     \nfontScale = 1 \ncolor = (255, 255, 0)\nthickness = 2\nresults = []\n\ndef format_prediction_string(boxes, scores):\n    pred_strings = []\n    for j in zip(scores, boxes):\n        pred_strings.append(\"{0:.4f} {1} {2} {3} {4}\".format(j[0], j[1][0], j[1][1], j[1][2], j[1][3]))\n\n    return \" \".join(pred_strings)\n\n\ndef result_show(df, color):\n    \n    for image_id in df_sub['image_id']:\n        im = cv2.imread('{}/{}.jpg'.format(TEST_DIR, image_id))\n        boxes = []\n        scores = []\n        labels = []\n        outputs = predictor(im)\n        out = outputs[\"instances\"].to(\"cpu\")\n        scores = out.get_fields()['scores'].numpy()\n        boxes = out.get_fields()['pred_boxes'].tensor.numpy().astype(int)\n        labels= out.get_fields()['scores'].numpy()\n        boxes = boxes.astype(int)\n        boxes[:, 2] = boxes[:, 2] - boxes[:, 0]\n        boxes[:, 3] = boxes[:, 3] - boxes[:, 1]\n        result = {'image_id': image_id,'PredictionString': format_prediction_string(boxes, scores)}\n        results.append(result)\n        im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB).astype(np.float32)\n        im /= 255.0\n        \n        for b,s in zip(boxes,scores):\n            cv2.rectangle(im, (b[0],b[1]), (b[0]+b[2],b[1]+b[3]), color, thickness)\n            cv2.putText(im, '{:.2}'.format(s), (b[0],b[1]), font, 1, color, thickness)\n                \n        plt.figure(figsize=(12,12))\n        plt.imshow(im)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf_sub = pd.read_csv('../input/global-wheat-detection/sample_submission.csv')\ndf_sub\n\nresult_show(df_sub['image_id'], color = (255, 255, 255))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(results)\ntest_df = pd.DataFrame(results, columns=['image_id', 'PredictionString'])\ntest_df.to_csv('submission.csv', index=False)\ntest_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}