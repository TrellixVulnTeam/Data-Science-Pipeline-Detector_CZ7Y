{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!ls .","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install ../input/packages/webcolors-1.11.1-py3-none-any.whl ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!cp -r ../input/efficientdet-code/EfficientDet .","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!mv ../input/weights2/efficientdet-d3_47_160500.pth ./EfficientDet/weights","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cd EfficientDet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls .","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nSimple Inference Script of EfficientDet-Pytorch\n\"\"\"\nimport os\nimport time\nimport torch\nfrom torch.backends import cudnn\nfrom matplotlib import colors\n\nfrom backbone import EfficientDetBackbone\nimport cv2\nimport numpy as np\nimport pandas as pd\n\nfrom efficientdet.utils import BBoxTransform, ClipBoxes\nfrom utils.utils import preprocess, invert_affine, postprocess, STANDARD_COLORS, standard_to_bgr, get_index_label, plot_one_box\n\nfrom ensemble_boxes import *\n\nthreshold = 0.2\niou_threshold = 0.7\ncompound_coef = 3\n\nuse_cuda = True\nuse_float16 = False\ncudnn.fastest = True\ncudnn.benchmark = True\nforce_input_size = 1024  # set None to use default size\n\nimg_path = '../../input/global-wheat-detection/test'\nobj_list = ['wheat']\nP_img_ext = [\"jpg\", \"png\", \"bmp\"]\nmodel_path = 'weights/efficientdet-d3_47_160500.pth'\n\n# replace this part with your project's anchor config\nanchor_ratios = [(1.0, 1.0), (1.4, 0.7), (0.7, 1.4)]\nanchor_scales = [2 ** 0, 2 ** (1.0 / 3.0), 2 ** (2.0 / 3.0)]\n\ncolor_list = standard_to_bgr(STANDARD_COLORS)\n# tf bilinear interpolation is different from any other's, just make do\ninput_sizes = [512, 640, 768, 896, 1024, 1280, 1280, 1536]\ninput_size = input_sizes[compound_coef] if force_input_size is None else force_input_size\n\n\ndef file_list(path, allfile):\n    filelist = os.listdir(path)\n\n    for filename in filelist:\n        filepath = os.path.join(path, filename)\n        if os.path.isdir(filepath):\n            file_list(filepath, allfile)\n        else:\n            if filepath.split(\".\")[-1] in P_img_ext:\n                allfile.append(filepath.strip())\n    return allfile\n\n\ndef display(preds, imgs, img_save_name, imshow=True, imwrite=False):\n    for i in range(len(imgs)):\n        if len(preds[i]['rois']) == 0:\n            continue\n\n        for j in range(len(preds[i]['rois'])):\n            x1, y1, x2, y2 = preds[i]['rois'][j].astype(np.int)\n            obj = obj_list[preds[i]['class_ids'][j]]\n            score = float(preds[i]['scores'][j])\n            plot_one_box(imgs[i], [x1, y1, x2, y2], label=obj,score=score,color=color_list[get_index_label(obj, obj_list)])\n\n        if imshow:\n            cv2.imshow('img', imgs[i])\n            cv2.waitKey(0)\n\n        if imwrite:\n            cv2.imwrite('test/{}_mark.jpg'.format(img_save_name), imgs[i])\n\n\nmodel = EfficientDetBackbone(compound_coef=compound_coef, num_classes=len(obj_list), ratios=anchor_ratios,\n                             scales=anchor_scales)\nmodel.load_state_dict(torch.load(model_path))\nmodel.requires_grad_(False)\nmodel.eval()\n\nif use_cuda:\n    model = model.cuda()\nif use_float16:\n    model = model.half()\n\n\nimg_list = []\nimg_list = file_list(img_path, img_list)\n\n# commit submission\nsubmission = []\n\nfor img in img_list:\n    print(\"Processing --->\", img)\n    prediction_string = []\n\n    ori_imgs, framed_imgs, framed_metas = preprocess(img, max_size=input_size)\n\n    if use_cuda:\n        x = torch.stack([torch.from_numpy(fi).cuda() for fi in framed_imgs], 0)\n    else:\n        x = torch.stack([torch.from_numpy(fi) for fi in framed_imgs], 0)\n\n    x = x.to(torch.float32 if not use_float16 else torch.float16).permute(0, 3, 1, 2)\n\n    with torch.no_grad():\n        features, regression, classification, anchors = model(x)\n        regressBoxes = BBoxTransform()\n        clipBoxes = ClipBoxes()\n        out = postprocess(x,\n                          anchors, regression, classification,\n                          regressBoxes, clipBoxes,\n                          threshold, iou_threshold)\n\n    out = invert_affine(framed_metas, out)\n    \n    # filter abnormal box\n    if len(out[0]['rois']) != 0:\n        index_d = []\n        for idx, box in enumerate(out[0]['rois']):\n            x1, y1, x2, y2 = box\n            if x2-x1>400 and y2 -y1 >400:\n                index_d.append(idx)\n\n        out[0]['rois'] = np.delete(out[0]['rois'], index_d, axis=0)\n        out[0]['scores'] = np.delete(out[0]['scores'], index_d)\n        out[0]['class_ids'] = np.delete(out[0]['class_ids'], index_d)\n\n    # WBF\n    boxes_list = (1.0/1024*out[0]['rois']).tolist()\n    scores_list = out[0]['scores'].tolist()\n    labels_list = out[0]['class_ids'].tolist()\n    boxes, scores, labels = weighted_boxes_fusion([boxes_list], [scores_list], [labels_list], weights=None, iou_thr=0.45, skip_box_thr=0.01)\n\n    out[0]['rois'] = np.array(boxes)*1024\n    out[0]['scores'] = np.array(scores)\n    out[0]['labels'] = np.array(labels)    \n    \n    #display(out, ori_imgs, img_name_save, imshow=False, imwrite=True)\n\n    if len(out[0]['rois']) == 0:\n        prediction_string.append(\"\")\n    else:\n        for j in range(len(out[0]['rois'])):\n            x1, y1, x2, y2 = out[0]['rois'][j].astype(np.int)\n            score = float(out[0]['scores'][j])\n\n            x = x1\n            y = y1\n            w = x2 - x1\n            h = y2 - y1\n            s = float(score)\n            prediction_string.append(\"{} {} {} {} {}\".format(s, x, y, w, h))\n            \n    img_name_save = os.path.basename(img)[:-4]\n    prediction_string = \" \".join(prediction_string)\n    submission.append([img_name_save,prediction_string])\n\n#print(submission)\nsample_submission = pd.DataFrame(submission, columns=[\"image_id\", \"PredictionString\"])\nsample_submission.to_csv('../submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cd ..","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm -rf EfficientDet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls .","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}