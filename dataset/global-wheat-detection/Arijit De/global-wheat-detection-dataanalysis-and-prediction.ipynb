{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n'''\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n'''\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If you like this kernel please upvote. \nI have learned from various exsting kernels, perticularly https://www.kaggle.com/aleksandradeis/globalwheatdetection-eda, please upvote this also.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**In this kernel first I will explore the data sets to understand the data in details to find its hidden features (EDA) of this wheat image data set.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom PIL import Image\n\n# opencv for image analysis\nimport cv2\nimport urllib","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from bokeh.plotting import figure\nfrom bokeh.io import output_notebook, show, output_file\nfrom bokeh.models import ColumnDataSource, HoverTool, Panel\nfrom bokeh.models.widgets import Tabs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!cp -r \"/kaggle/input/kerasretinanet/keras-retinanet\" .","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# install retinanet\n!git clone https://github.com/fizyr/keras-retinanet.git\n%cd keras-retinanet/\n\n!pip install .\n\n!python setup.py build_ext --inplace","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom keras_retinanet import models\nfrom keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\nfrom keras_retinanet.utils.visualization import draw_box, draw_caption\nfrom keras_retinanet.utils.colors import label_color\n\nimport urllib\nfrom tqdm.notebook import tqdm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Load Dataset**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/global-wheat-detection/train.csv\")  \ntrain_data_folder = \"/kaggle/input/global-wheat-detection/train/\"\ntest_data_folder = \"/kaggle/input/global-wheat-detection/test/\"\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Dataset shape: {}\".format(train.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check for missing values\ntrain.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**check if all the image Width & Height values are the same**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['width'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['height'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# take random index\nseed = 42\nrng = np.random.RandomState(seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_images(df):\n    # print a few images together with box\n    nrows=4\n    ncols=4\n    fig, axs = plt.subplots(nrows, ncols, figsize=(15, 15), sharex=True, sharey=True)\n\n    for r in range(nrows):\n        for c in range(ncols):\n            ridx = rng.choice(range(df.shape[0]))\n            img_name = df.iloc[ridx]['image_id']\n\n            image = plt.imread(train_data_folder+img_name+'.jpg')\n\n            axs[r, c].imshow(image)\n            axs[r, c].axis('off')\n            \n    plt.suptitle('Wheat head images')\n    plt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check a few random image to check the dataset.\nshow_images(train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**This data set contains the image names, image shape, bbox (xmin, ymin, width, height) as the location of every wheat head sqaure.**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**lets create a new data frame with the required fields in a usable manner for EDA\n**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_analysis=pd.DataFrame()\ndf_analysis['image_id']=train['image_id'].apply(lambda x: x+'.jpg')\n\n# extract the fields for use\nbbox = train.bbox.str.split(\",\",expand=True)\ndf_analysis['xmin'] = bbox[0].str.strip('[ ').astype(float)\ndf_analysis['ymin'] = bbox[1].str.strip(' ').astype(float)\ndf_analysis['xmax'] = bbox[2].str.strip(' ').astype(float)+df_analysis['xmin']\ndf_analysis['ymax'] = bbox[3].str.strip(' ]').astype(float)+df_analysis['ymin']\ndf_analysis['class']= 0\n\n# show the data frame\ndf_analysis.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets draw the box around the wheat heads to visualize and validate the data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# take random index\n# draw box on a random image\nseed = 42\nrng = np.random.RandomState(seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_images_with_box(df):\n    # print a few images together with box\n    nrows=4\n    ncols=4\n    fig, axs = plt.subplots(nrows, ncols, figsize=(15, 15), sharex=True, sharey=True)\n\n    for r in range(nrows):\n        for c in range(ncols):\n            ridx = rng.choice(range(df.shape[0]))\n            img_name = df.iloc[ridx]['image_id']\n      \n            image = plt.imread(train_data_folder+img_name)\n                        \n            # find all the records of the provided image and draw box on the wheat heads\n            chosen_image = df.loc[df[\"image_id\"]==img_name,[\"xmin\",\"ymin\",\"xmax\",\"ymax\"]]\n            bbox_array   = np.array(chosen_image.values.tolist())\n\n            for bbox in bbox_array:\n                image = cv2.rectangle(image, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), color = (255,255,255), thickness=3) \n\n            axs[r, c].imshow(image)\n            axs[r, c].axis('off')\n            \n    plt.suptitle('Images with Box')\n    plt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_images_with_box(df_analysis)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets plot images with high box counts (I am not stiching the boxes, as displaying them takes lot of time)\ndef show_images(se, start_idx, str_plot):\n    # print a few images from the provided Series\n    nrows=4\n    ncols=4\n    fig, axs = plt.subplots(nrows, ncols, figsize=(15, 15))\n    idx = start_idx\n    for r in range(nrows):\n        for c in range(ncols):\n            img = Image.open(train_data_folder+se.index[idx])\n            axs[r, c].imshow(img)\n            axs[r, c].axis('off')\n            title=\"box_count=\"+str(se.iloc[idx])\n            axs[r, c].set_title(title)\n            \n            idx = idx+1\n    plt.suptitle(str_plot)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After going over the images it's visible that there are various kind of images present in this data set.\n* few images are having many wheat heads and few are very less or no heads.\n* some of the images are taken in dark and some images are taken in a very high lighting condition. \n* there are images of green wheat heads and yellow heads (mature).\n\n** will explore the data more now with visualizatiin **","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Exploring the wheat head count distribution in the data set ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets see how the image box counts are ditributed.\nimg_freq=df_analysis['image_id'].value_counts()\nimg_freq[:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the log its visible that one image '35b935b6c.jpg' is having max 116 boxes and in the lower side few are only having one box.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Lets understand the image box count distribution**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"n, bins, patches = plt.hist(x=img_freq, bins='auto', color='#0504aa',\n                            alpha=0.7, rwidth=0.85)\nplt.grid(axis='y', alpha=0.75)\nplt.xlabel('Box Count')\nplt.ylabel('Frequency')\nplt.title('Image Box Distribution')\nplt.text(23, 45, r'$\\mu=15, b=3$')\nmaxfreq = n.max()\n# Set a clean upper y-axis limit.\nplt.ylim(ymax=np.ceil(maxfreq / 10) * 10 if maxfreq % 10 else maxfreq + 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\n\nsns.set_style('darkgrid')\nsns.distplot(img_freq)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**So most of the images are having box count in range 10 to 80.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets plot images with high box counts (I am not drawing the boxes, as displaying them takes some time)\ndef show_images(se, start_idx, str_plot):\n    # print a few images from the provided Series\n    nrows=4\n    ncols=4\n    fig, axs = plt.subplots(nrows, ncols, figsize=(15, 15))\n    idx = start_idx\n    for r in range(nrows):\n        for c in range(ncols):\n            img = Image.open(train_data_folder+se.index[idx])\n            axs[r, c].imshow(img)\n            axs[r, c].axis('off')\n            title=\"box_count=\"+str(se.iloc[idx])\n            axs[r, c].set_title(title)\n            \n            idx = idx+1\n    plt.suptitle(str_plot)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_images(img_freq, start_idx=0, str_plot='Images with max box counts')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_images(img_freq, start_idx=(len(img_freq)-1-16), str_plot='Images with lowest box counts')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** Exploring the Box size's to get some understanding of its accuracy and distribution **","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"box_width=(df_analysis['xmax']-df_analysis['xmin']).sort_values()\nbox_height=(df_analysis['ymax']-df_analysis['ymin']).sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"box_width","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot box width\nn, bins, patch = plt.hist(x=box_width, bins=50, color='#0504aa',\n                            alpha=0.7, rwidth=0.85)\nplt.grid(axis='y', alpha=0.75)\nplt.xlabel('Box Width')\nplt.ylabel('Frequency')\nplt.title('Box Width Distribution')\nplt.text(23, 45, r'$\\mu=15, b=3$')\nmaxfreq = n.max()\n# Set a clean upper y-axis limit.\nplt.ylim(ymax=np.ceil(maxfreq / 10) * 10 if maxfreq % 10 else maxfreq + 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_style('darkgrid')\nsns.distplot(box_width)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Check Box height distribution**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot box height\nn, bins, patch = plt.hist(x=box_height, bins=50, color='#0504aa',\n                            alpha=0.7, rwidth=0.85)\nplt.grid(axis='y', alpha=0.75)\nplt.xlabel('Box Height')\nplt.ylabel('Frequency')\nplt.title('Box Height Distribution')\nplt.text(23, 45, r'$\\mu=15, b=3$')\nmaxfreq = n.max()\n# Set a clean upper y-axis limit.\nplt.ylim(ymax=np.ceil(maxfreq / 10) * 10 if maxfreq % 10 else maxfreq + 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_style('darkgrid')\nsns.distplot(box_height)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_analysis['width']=df_analysis['xmax']-df_analysis['xmin']\ndf_analysis['height']=df_analysis['ymax']-df_analysis['ymin']\n\ndf_analysis.sort_values(by='width', inplace=True)\ndf_analysis.reset_index(inplace = True, drop = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_analysis.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_analysis.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# function to print images with highest box width size. \ndef show_box_width(df, start_idx, str_plot):\n    nrows=4\n    ncols=4\n    fig, axs = plt.subplots(nrows, ncols, figsize=(15, 15))\n    idx = start_idx\n    for r in range(nrows):\n        for c in range(ncols):\n            img = plt.imread(train_data_folder+df.iloc[idx].image_id)\n            axs[r, c].imshow(img)\n            axs[r, c].axis('off')\n            title=\"box width=\"+str(df.iloc[idx]['width'])\n            axs[r, c].set_title(title)\n                        \n            # find all the records of the provided image and draw box on the wheat heads\n            w, h, w1, h1 = df.iloc[idx][[\"xmin\",\"ymin\",\"xmax\",\"ymax\"]]\n         \n            img = cv2.rectangle(img, (int(w), int(h)), (int(w1), int(h1)), color = (255,255,255), thickness=3) \n\n            axs[r, c].imshow(img)\n            axs[r, c].axis('off')\n            idx = idx+1\n    plt.suptitle(str_plot)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_box_width(df_analysis, len(box_height)-16, 'Images with highest box width size')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above images its clear that w.r.t the Box width values few of the boxes are valid and few are covering multiple heads.\nSo this needs an correction in the image source.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"show_box_width(df_analysis, 0, 'Images with lowest box width size')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most of the box above does not cover any wheat head. So here we can actually ignore this boxes.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Explore the Dark and Bright images**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# get image brightness using opencv\ndef get_image_brightness(img):\n    image = cv2.imread(img)\n    # convert to grayscale\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    \n    # get average brightness\n    return int(np.array(gray).mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create a data frame with unique image names\ndf_img=pd.DataFrame()\n\ndf_img['image']=df_analysis['image_id'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_img['brightness'] = df_img['image'].apply(lambda x: get_image_brightness(train_data_folder+x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_img.sort_values(by='brightness', inplace=True)\ndf_img.reset_index(inplace = True, drop = True)\ndf_img.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_img.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# function to print images with highest box width size. \ndef show_image_brightness(df, start_idx, str_plot):\n    nrows=4\n    ncols=4\n    fig, axs = plt.subplots(nrows, ncols, figsize=(15, 15))\n    idx = start_idx\n    for r in range(nrows):\n        for c in range(ncols):\n            img = Image.open(train_data_folder+df.iloc[idx]['image'])\n            axs[r, c].imshow(img)\n            title=\"brightness=\"+str(df.iloc[idx]['brightness'])\n            axs[r, c].set_title(title)\n\n            axs[r, c].axis('off')\n            idx = idx+1\n    plt.suptitle(str_plot)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_image_brightness(df_img, df_img.shape[0]-16,'most brightest images')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_image_brightness(df_img, 0,'most darkest images')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Many of the images are too dark to be analyzed, so there brightness need to be increased.**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Analysis of images w.r.t green and yellow (mature) wheat heads.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_percentage_of_green_pixels(img):\n    image = cv2.imread(img)\n    # convert to HSV\n    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n    \n    # get the green mask\n    hsv_lower = (40, 40, 40) \n    hsv_higher = (70, 255, 255)\n    green_mask = cv2.inRange(hsv, hsv_lower, hsv_higher)\n    \n    return round(float(np.sum(green_mask)) / 255 / (1024 * 1024), 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# function to show images with highest box width size. \ndef show_images_green_pixels(df, start_idx, str_plot):\n    nrows=4\n    ncols=4\n    fig, axs = plt.subplots(nrows, ncols, figsize=(15, 15))\n    idx = start_idx\n    for r in range(nrows):\n        for c in range(ncols):\n            img = Image.open(train_data_folder+df.iloc[idx]['image'])\n            axs[r, c].imshow(img)\n            axs[r, c].axis('off')\n            title=\"green pix=\"+str(df.iloc[idx]['green'])\n            axs[r, c].set_title(title)\n\n            axs[r, c].axis('off')\n            idx = idx+1\n    plt.suptitle(str_plot)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_img['green'] = df_img['image'].apply(lambda x: get_percentage_of_green_pixels(train_data_folder+x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_img.sort_values(by='green', inplace=True)\ndf_img.reset_index(inplace = True, drop = True)\ndf_img.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_img.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_style('darkgrid')\nsns.distplot(df_img['green'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This shows that there is a large percentage of image's in this data set are in the mature state.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# display the greenest images\nshow_images_green_pixels(df_img, df_img.shape[0]-16,'most green images')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# display the less green(yellow) images\nshow_images_green_pixels(df_img, 0,'most yellow images')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Check the test data**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data=[]\nfor root, dirs, files in os.walk(test_data_folder):\n    for file in files:\n        test_data.append(file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('test data count: {}'.format(len(test_data)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# display test data\ndef show_test_data(tdata):\n    nrows=2\n    ncols=5\n    fig, axs = plt.subplots(nrows, ncols, figsize=(20, 8), squeeze=False)\n    idx = 0\n    \n    for r in range(nrows):\n        for c in range(ncols):\n            img = Image.open(test_data_folder+tdata[idx])\n            axs[r, c].imshow(img)\n            \n            axs[r, c].axis('off')\n            \n            idx = idx+1\n            \n    plt.suptitle(\"Test data\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_test_data(test_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Use retinanet for creating model for object detection ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Data Augmentataion need to be implemented, because **\n- image count is less\n- many images are too dark \n- few images are too bright.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Need to make a object detection model using keras RetinaNet **","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# check the GPU details\n!nvidia-smi","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating a model using retinanet\n#!keras_retinanet/bin/train.py --random-transform --gpu 0 --weights {PRETRAINED_MODEL} --lr {LR} --batch-size {BATCH_SIZE} --steps {STEPS} --epochs {EPOCHS} csv out_final.csv classes.csv\n# this will create resnet50_csv_02.h5 as an output model.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using a pre trained retinanet model first to try\nmodel = models.load_model(\"/kaggle/input/retinanet-model1/resnet50_csv_02.h5\", backbone_name='resnet50')\nmodel = models.convert_model(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(image):\n    image = preprocess_image(image.copy())\n    #image, scale = resize_image(image)\n\n    boxes, scores, labels = model.predict_on_batch(\n    np.expand_dims(image, axis=0)\n  )\n\n    #boxes /= scale\n\n    return boxes, scores, labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"THRES_SCORE = 0.55\n\ndef draw_detections(image, boxes, scores, labels):\n    for box, score, label in zip(boxes[0], scores[0], labels[0]):\n        if score < THRES_SCORE:\n            break\n\n        color = label_color(label)\n\n        b = box.astype(int)\n        draw_box(image, b, color=color)\n\n        caption = \"{:.3f}\".format(score)\n        draw_caption(image, b, caption)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_detected_objects(image_name):\n    img_path = test_data_folder+'/'+image_name\n  \n    image = read_image_bgr(img_path)\n    #image = cv2.imread(img_path)\n\n    boxes, scores, labels = predict(image)\n    \n    draw = image.copy()\n    draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n\n    draw_detections(draw, boxes, scores, labels)\n    plt.figure(figsize=(8,6))\n    plt.axis('off')\n    plt.imshow(draw)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for img in test_data:\n    show_detected_objects(img)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**TBD:\nFrom the above detection its clear that source images needs augmentation, such that model can be more robust.\nBecause there are many miss classification/prediction for the wheat heads.**\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"preds=[]\nimgid=[]\nfor img in test_data:\n    img_path = test_data_folder+'/'+img\n    image = read_image_bgr(img_path)\n    boxes, scores, labels = predict(image)\n    boxes=boxes[0]\n    scores=scores[0]\n    for idx in range(boxes.shape[0]):\n        if scores[idx]>THRES_SCORE:\n            box,score=boxes[idx],scores[idx]\n            imgid.append(img.split(\".\")[0])\n            preds.append(\"{} {} {} {} {}\".format(score, int(box[0]), int(box[1]), int(box[2]-box[0]), int(box[3]-box[1])))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub={\"image_id\":imgid, \"PredictionString\":preds}\nsub=pd.DataFrame(sub)\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_=sub.groupby([\"image_id\"])['PredictionString'].apply(lambda x: ' '.join(x)).reset_index()\nsub_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"samsub=pd.read_csv(\"/kaggle/input/global-wheat-detection/sample_submission.csv\")\nsamsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for idx,imgid in enumerate(samsub['image_id']):\n    samsub.iloc[idx,1]=sub_[sub_['image_id']==imgid].values[0,1]\n    \nsamsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"samsub.to_csv('/kaggle/working/submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}