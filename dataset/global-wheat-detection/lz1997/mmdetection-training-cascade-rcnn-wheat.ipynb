{"cells":[{"metadata":{},"cell_type":"markdown","source":"# v5公开了coco标签，应该能正常运行了吧\n# kaggle训练mmdet示例，可在线更改configs\n# 参考了 https://www.kaggle.com/superkevingit/faster-rcnn-with-mmdetection-without-internet\n\n# 第一步，进行安装","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls /kaggle/input #挺好的，能分离数据和代码\n!pip install ../input/mmcvwhl/addict-2.2.1-py3-none-any.whl\n!pip install ../input/mmdetection20513/mmcv-0.5.1-cp37-cp37m-linux_x86_64.whl\n!pip install ../input/mmdetection20513/terminal-0.4.0-py3-none-any.whl\n!pip install ../input/mmdetection20513/terminaltables-3.1.0-py3-none-any.whl\n\n!cp -r ../input/mmdetection20513/mmdetection/mmdetection .\n%cd mmdetection\n!cp -r ../../input/mmdetection20513/cocoapi/cocoapi .\n%cd cocoapi/PythonAPI\n!make\n!make install\n!python setup.py install\nimport pycocotools\n%cd ../..\n!pip install -v -e .\n%cd ../\nimport sys\nsys.path.append('mmdetection') # To find local version","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ###################分割线================\n# 安装完毕，先试试demo能不能正常使用","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from mmdet.apis import init_detector, inference_detector, show_result_pyplot\nimport mmcv\nfrom mmcv import Config\nfrom mmdet.models import build_detector\nfrom mmcv.runner import load_checkpoint\nfrom mmcv.parallel import MMDataParallel\nfrom mmdet.apis import single_gpu_test\nfrom mmdet.datasets import build_dataloader, build_dataset\n\nimport pandas as pd\nimport os\nimport json\n\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport torch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls \n# !python mmdetection/demo/image_demo.py \n# 报错image_demo.py: error: the following arguments are required: img, config, checkpoint\n\n\nconfig = 'mmdetection/configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py'\n\n# mm-faster不止有faster rcnn的权重，还有别的权重\ncheckpoint = '/kaggle/input/mm-faster/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth'\nmodel = init_detector(config, checkpoint, device='cuda:0')\n# model = init_detector(config, checkpoint, device='cpu')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = 'mmdetection/demo/demo.jpg'\nresult = inference_detector(model, img)\nshow_result_pyplot(model, img, result, score_thr=0.3)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 开始训练,使用cascade rcnn的配置文件","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"albu_train_transforms = [\n    dict(\n        type='HorizontalFlip',\n        p=0.5),\n    dict(\n        type='VerticalFlip',\n        p=0.5),\n\n    dict(\n        type='ShiftScaleRotate',\n        shift_limit=0.0625,\n        scale_limit=0.0,\n        rotate_limit=180,\n        interpolation=1,\n        p=0.5),\n        # p='abcde'),#故意写错，看看是否真的考虑了这段代码 #我去，真的定位到了albu库\n    dict(\n        type='RandomBrightnessContrast',\n        brightness_limit=[0.1, 0.3],\n        contrast_limit=[0.1, 0.3],\n        p=0.2),\n    # dict(\n    #     type='OneOf',\n    #     transforms=[\n    #         dict(\n    #             type='RGBShift',\n    #             r_shift_limit=10,\n    #             g_shift_limit=10,\n    #             b_shift_limit=10,\n    #             p=1.0),\n    #         dict(\n    #             type='HueSaturationValue',\n    #             hue_shift_limit=20,\n    #             sat_shift_limit=30,\n    #             val_shift_limit=20,\n    #             p=1.0)\n    #     ],\n    #     p=0.1),\n    # # dict(type='JpegCompression', quality_lower=85, quality_upper=95, p=0.2),\n    #\n    # dict(type='ChannelShuffle', p=0.1),\n    # dict(\n    #     type='OneOf',\n    #     transforms=[\n    #         dict(type='Blur', blur_limit=3, p=1.0),\n    #         dict(type='MedianBlur', blur_limit=3, p=1.0)\n    #     ],\n    #     p=0.1),\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 使用py文件类型的config，提升配置复用性\n\n##################################cascade_rcnn_r50_fpn.py#######################\n# model settings\nmodel = dict(\n    type='CascadeRCNN',\n    pretrained='/kaggle/input/mm-faster/resnet50-19c8e357.pth',\n    backbone=dict(\n        type='ResNet',\n        depth=50,\n        num_stages=4,\n        out_indices=(0, 1, 2, 3),\n        frozen_stages=1,\n        norm_cfg=dict(type='BN', requires_grad=True),\n        norm_eval=True,\n        style='pytorch'),\n    neck=dict(\n        type='FPN',\n        in_channels=[256, 512, 1024, 2048],\n        out_channels=256,\n        num_outs=5),\n    rpn_head=dict(\n        type='RPNHead',\n        in_channels=256,\n        feat_channels=256,\n        anchor_generator=dict(\n            type='AnchorGenerator',\n            scales=[8],\n            ratios=[0.5, 1.0, 2.0],\n            strides=[4, 8, 16, 32, 64]),\n        bbox_coder=dict(\n            type='DeltaXYWHBBoxCoder',\n            target_means=[.0, .0, .0, .0],\n            target_stds=[1.0, 1.0, 1.0, 1.0]),\n        loss_cls=dict(\n            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n        loss_bbox=dict(type='SmoothL1Loss', beta=1.0 / 9.0, loss_weight=1.0)),\n    roi_head=dict(\n        type='CascadeRoIHead',\n        num_stages=3,\n        stage_loss_weights=[1, 0.5, 0.25],\n        bbox_roi_extractor=dict(\n            type='SingleRoIExtractor',\n            roi_layer=dict(type='RoIAlign', out_size=7, sample_num=0),\n            out_channels=256,\n            featmap_strides=[4, 8, 16, 32]),\n        bbox_head=[\n            dict(\n                type='Shared2FCBBoxHead',\n                in_channels=256,\n                fc_out_channels=1024,\n                roi_feat_size=7,\n                num_classes=1,\n                bbox_coder=dict(\n                    type='DeltaXYWHBBoxCoder',\n                    target_means=[0., 0., 0., 0.],\n                    target_stds=[0.1, 0.1, 0.2, 0.2]),\n                reg_class_agnostic=True,\n                loss_cls=dict(\n                    type='CrossEntropyLoss',\n                    use_sigmoid=False,\n                    loss_weight=1.0),\n                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,\n                               loss_weight=1.0)),\n            dict(\n                type='Shared2FCBBoxHead',\n                in_channels=256,\n                fc_out_channels=1024,\n                roi_feat_size=7,\n                num_classes=1,\n                bbox_coder=dict(\n                    type='DeltaXYWHBBoxCoder',\n                    target_means=[0., 0., 0., 0.],\n                    target_stds=[0.05, 0.05, 0.1, 0.1]),\n                reg_class_agnostic=True,\n                loss_cls=dict(\n                    type='CrossEntropyLoss',\n                    use_sigmoid=False,\n                    loss_weight=1.0),\n                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,\n                               loss_weight=1.0)),\n            dict(\n                type='Shared2FCBBoxHead',\n                in_channels=256,\n                fc_out_channels=1024,\n                roi_feat_size=7,\n                num_classes=1,\n                bbox_coder=dict(\n                    type='DeltaXYWHBBoxCoder',\n                    target_means=[0., 0., 0., 0.],\n                    target_stds=[0.033, 0.033, 0.067, 0.067]),\n                reg_class_agnostic=True,\n                loss_cls=dict(\n                    type='CrossEntropyLoss',\n                    use_sigmoid=False,\n                    loss_weight=1.0),\n                loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0))\n        ]))\n# model training and testing settings\ntrain_cfg = dict(\n    rpn=dict(\n        assigner=dict(\n            type='MaxIoUAssigner',\n            pos_iou_thr=0.7,\n            neg_iou_thr=0.3,\n            min_pos_iou=0.3,\n            match_low_quality=True,\n            ignore_iof_thr=-1),\n        sampler=dict(\n            type='RandomSampler',\n            num=256,\n            pos_fraction=0.5,\n            neg_pos_ub=-1,\n            add_gt_as_proposals=False),\n        allowed_border=0,\n        pos_weight=-1,\n        debug=False),\n    rpn_proposal=dict(\n        nms_across_levels=False,\n        nms_pre=2000,\n        nms_post=2000,\n        max_num=2000,\n        nms_thr=0.7,\n        min_bbox_size=0),\n    rcnn=[\n        dict(\n            assigner=dict(\n                type='MaxIoUAssigner',\n                pos_iou_thr=0.5,\n                neg_iou_thr=0.5,\n                min_pos_iou=0.5,\n                match_low_quality=False,\n                ignore_iof_thr=-1),\n            sampler=dict(\n                type='RandomSampler',\n                num=512,\n                pos_fraction=0.25,\n                neg_pos_ub=-1,\n                add_gt_as_proposals=True),\n            pos_weight=-1,\n            debug=False),\n        dict(\n            assigner=dict(\n                type='MaxIoUAssigner',\n                pos_iou_thr=0.6,\n                neg_iou_thr=0.6,\n                min_pos_iou=0.6,\n                match_low_quality=False,\n                ignore_iof_thr=-1),\n            sampler=dict(\n                type='RandomSampler',\n                num=512,\n                pos_fraction=0.25,\n                neg_pos_ub=-1,\n                add_gt_as_proposals=True),\n            pos_weight=-1,\n            debug=False),\n        dict(\n            assigner=dict(\n                type='MaxIoUAssigner',\n                pos_iou_thr=0.7,\n                neg_iou_thr=0.7,\n                min_pos_iou=0.7,\n                match_low_quality=False,\n                ignore_iof_thr=-1),\n            sampler=dict(\n                type='RandomSampler',\n                num=512,\n                pos_fraction=0.25,\n                neg_pos_ub=-1,\n                add_gt_as_proposals=True),\n            pos_weight=-1,\n            debug=False)\n    ])\ntest_cfg = dict(\n    rpn=dict(\n        nms_across_levels=False,\n        nms_pre=1000,\n        nms_post=1000,\n        max_num=1000,\n        nms_thr=0.7,\n        min_bbox_size=0),\n    rcnn=dict(\n        score_thr=0.05, nms=dict(type='nms', iou_thr=0.5), max_per_img=100))\n\n\n\n###################################coco_detection.py#############################\ndataset_type = 'CocoDataset'\ndata_root = '/kaggle/input/mmdata/coco/' #记得加/\n\nclasses = ('wheat',) #需要加逗号，不然好像会报错\n\n#这个后续再改吧\nimg_norm_cfg = dict(mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\ntrain_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadAnnotations', with_bbox=True),\n    \n    # 如果是新手那就按照默认参数的比例扩大就行了，然后测试的时候取训练集的中间值。比如cascade50默认尺度是(1333,800)\n    dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),# The largest scale of image\n    # dict(type='Resize',img_scale=[(2000, 300), (2000, 1200)],multiscale_mode='range',keep_ratio=True), #别的代码看到了这种结构\n    \n    dict(type='RandomFlip', flip_ratio=0.5),\n    dict(type='Normalize', **img_norm_cfg),\n    dict(type='Pad', size_divisor=32),\n\n    # 知乎贴子增加的，和前面的段落配合\n    dict(\n    type='Albu',\n    transforms=albu_train_transforms,\n    bbox_params=dict(\n        type='BboxParams',\n        format='pascal_voc',\n        label_fields=['gt_labels'],\n        min_visibility=0.0,\n        filter_lost_elements=True),\n    keymap={\n        'img': 'image',\n        'gt_bboxes': 'bboxes'\n    },\n    update_pad_shape=False,\n    skip_img_without_anno=True),\n    \n    dict(type='DefaultFormatBundle'),\n    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels']),\n]\ntest_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='MultiScaleFlipAug',\n        \n        #test_pipeline 中img_scale的尺度可以为任意多个，含义为对测试集进行多尺度测试（可以理解为TTA）\n        img_scale=(1333, 800),\n        \n        flip=False,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='RandomFlip'),\n            dict(type='Normalize', **img_norm_cfg),\n            dict(type='Pad', size_divisor=32),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='Collect', keys=['img']),\n        ])\n]\ndata = dict(\n    samples_per_gpu=2,\n    workers_per_gpu=2,\n    train=dict(\n        type=dataset_type,\n        classes=classes,\n        #ann_file=data_root + 'annotations/instances_train2017.json',\n        #img_prefix=data_root + 'train2017/',\n        ann_file='/kaggle/input/wheat-coco-label/instances_train2017.json',\n        img_prefix='/kaggle/input/global-wheat-detection/train/',\n        pipeline=train_pipeline),\n    val=dict(\n        type=dataset_type,\n        classes=classes,\n        #ann_file=data_root + 'annotations/instances_val2017.json',\n        #img_prefix=data_root + 'val2017/',\n        ann_file='/kaggle/input/wheat-coco-label/instances_val2017.json',\n        img_prefix='/kaggle/input/global-wheat-detection/train/',\n        pipeline=test_pipeline),\n    test=dict(\n        type=dataset_type,\n        classes=classes,\n        #ann_file=data_root + 'annotations/instances_val2017.json',\n        #img_prefix=data_root + 'val2017/',\n        pipeline=test_pipeline))\nevaluation = dict(interval=5, metric='bbox')\n\n\n\n\n#######################################schedule_1x.py#################################\n# optimizer\noptimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001)\noptimizer_config = dict(grad_clip=None)\n# learning policy\nlr_config = dict(\n    policy='step',\n    warmup='linear',\n    warmup_iters=500,\n    warmup_ratio=0.001,\n    step=[8, 11])\ntotal_epochs = 50 #epochs\n\n\n\n\n#################################default_runtime.py#############################\ncheckpoint_config = dict(interval=10)\n# yapf:disable\nlog_config = dict(\n    interval=50,\n    hooks=[\n        dict(type='TextLoggerHook'),\n        # dict(type='TensorboardLoggerHook')\n    ])\n# yapf:enable\ndist_params = dict(backend='nccl')\nlog_level = 'INFO'\nload_from = None\nresume_from = None\nworkflow = [('train', 1)]\n\n\n\n\n############################生成配置###############################\nconfig_dict=dict(\n    model = model,\n    train_cfg = train_cfg,\n    test_cfg  = test_cfg ,\n    dataset_type =dataset_type,\n    data_root=data_root,\n    classes=classes,\n    img_norm_cfg=img_norm_cfg,\n    train_pipeline=train_pipeline,\n    test_pipeline=test_pipeline,\n    data =data ,\n    evaluation =evaluation ,\n    optimizer=optimizer,\n    optimizer_config=optimizer_config,\n    lr_config=lr_config,\n    total_epochs=total_epochs,\n    checkpoint_config=checkpoint_config,\n    log_config=log_config,\n    dist_params=dist_params,\n    log_level=log_level,\n    load_from =load_from ,\n    resume_from=resume_from,\n    workflow =workflow \n)\n\n\n\ncfg_real_time = Config(config_dict)\n\n# print(config_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train.py\nimport argparse\nimport copy\nimport os\nimport os.path as osp\nimport time\n\nimport mmcv\nimport torch\nfrom mmcv import Config, DictAction\nfrom mmcv.runner import init_dist\n\nfrom mmdet import __version__\nfrom mmdet.apis import set_random_seed, train_detector\nfrom mmdet.datasets import build_dataset\nfrom mmdet.models import build_detector\nfrom mmdet.utils import collect_env, get_root_logger\n\n\ndef parse_args():\n    parser = argparse.ArgumentParser(description='Train a detector')\n    \n    # 这里加短横线，加默认输入，后续处理掉这里\n    # parser.add_argument('--config', help='train config file path',default='/kaggle/input/mmconfigs/cascade_rcnn/cascade_rcnn_r50_fpn_1x_coco.py')\n    parser.add_argument('--work-dir', help='the dir to save logs and models')\n    parser.add_argument(\n        '--resume-from', help='the checkpoint file to resume from')\n    parser.add_argument(\n        '--no-validate',\n        action='store_true',\n        help='whether not to evaluate the checkpoint during training')\n    group_gpus = parser.add_mutually_exclusive_group()\n    group_gpus.add_argument(\n        '--gpus',\n        type=int,\n        help='number of gpus to use '\n        '(only applicable to non-distributed training)')\n    group_gpus.add_argument(\n        '--gpu-ids',\n        type=int,\n        nargs='+',\n        help='ids of gpus to use '\n        '(only applicable to non-distributed training)')\n    parser.add_argument('--seed', type=int, default=None, help='random seed')\n    parser.add_argument(\n        '--deterministic',\n        action='store_true',\n        help='whether to set deterministic options for CUDNN backend.')\n    parser.add_argument(\n        '--options', nargs='+', action=DictAction, help='arguments in dict')\n    parser.add_argument(\n        '--launcher',\n        choices=['none', 'pytorch', 'slurm', 'mpi'],\n        default='none',\n        help='job launcher')\n    parser.add_argument('--local_rank', type=int, default=0)\n    parser.add_argument(\n        '--autoscale-lr',\n        action='store_true',\n        help='automatically scale lr with the number of gpus')\n\n    # 网上说改成这个就能在notebook里用咯~\n    # args = parser.parse_args()\n    args, unknown = parser.parse_known_args()\n    \n    if 'LOCAL_RANK' not in os.environ:\n        os.environ['LOCAL_RANK'] = str(args.local_rank)\n\n    return args\n\n\ndef main():\n    args = parse_args()\n    \n\n    #cfg = Config.fromfile(args.config)\n    cfg = cfg_real_time\n    #print(cfg)\n    \n    if args.options is not None:\n        cfg.merge_from_dict(args.options)\n    # set cudnn_benchmark\n    if cfg.get('cudnn_benchmark', False):\n        torch.backends.cudnn.benchmark = True\n\n    # work_dir is determined in this priority: CLI > segment in file > filename\n    if args.work_dir is not None:\n        # update configs according to CLI args if args.work_dir is not None\n        cfg.work_dir = args.work_dir\n    elif cfg.get('work_dir', None) is None:\n        # use config filename as default work_dir if cfg.work_dir is None\n        # 删除了config文件的路径后改成了这个\n        cfg.work_dir = './work_dirs'\n    if args.resume_from is not None:\n        cfg.resume_from = args.resume_from\n    if args.gpu_ids is not None:\n        cfg.gpu_ids = args.gpu_ids\n    else:\n        cfg.gpu_ids = range(1) if args.gpus is None else range(args.gpus)\n\n    if args.autoscale_lr:\n        # apply the linear scaling rule (https://arxiv.org/abs/1706.02677)\n        cfg.optimizer['lr'] = cfg.optimizer['lr'] * len(cfg.gpu_ids) / 8\n\n    # init distributed env first, since logger depends on the dist info.\n    if args.launcher == 'none':\n        distributed = False\n    else:\n        distributed = True\n        init_dist(args.launcher, **cfg.dist_params)\n\n    # create work_dir\n    mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n    # init the logger before other steps\n    timestamp = time.strftime('%Y%m%d_%H%M%S', time.localtime())\n    log_file = osp.join(cfg.work_dir, f'{timestamp}.log')\n    logger = get_root_logger(log_file=log_file, log_level=cfg.log_level)\n\n    # init the meta dict to record some important information such as\n    # environment info and seed, which will be logged\n    meta = dict()\n    # log env info\n    env_info_dict = collect_env()\n    env_info = '\\n'.join([(f'{k}: {v}') for k, v in env_info_dict.items()])\n    dash_line = '-' * 60 + '\\n'\n    logger.info('Environment info:\\n' + dash_line + env_info + '\\n' +\n                dash_line)\n    meta['env_info'] = env_info\n\n    # log some basic info\n    logger.info(f'Distributed training: {distributed}')\n    logger.info(f'Config:\\n{cfg.pretty_text}')\n\n    # set random seeds\n    if args.seed is not None:\n        logger.info(f'Set random seed to {args.seed}, '\n                    f'deterministic: {args.deterministic}')\n        set_random_seed(args.seed, deterministic=args.deterministic)\n    cfg.seed = args.seed\n    meta['seed'] = args.seed\n\n    model = build_detector(\n        cfg.model, train_cfg=cfg.train_cfg, test_cfg=cfg.test_cfg)\n\n    datasets = [build_dataset(cfg.data.train)]\n    if len(cfg.workflow) == 2:\n        val_dataset = copy.deepcopy(cfg.data.val)\n        val_dataset.pipeline = cfg.data.train.pipeline\n        datasets.append(build_dataset(val_dataset))\n    if cfg.checkpoint_config is not None:\n        # save mmdet version, config file content and class names in\n        # checkpoints as meta data\n        cfg.checkpoint_config.meta = dict(\n            mmdet_version=__version__,\n            config=cfg.pretty_text,\n            CLASSES=datasets[0].CLASSES)\n    # add an attribute for visualization convenience\n    model.CLASSES = datasets[0].CLASSES\n    train_detector(\n        model,\n        datasets,\n        cfg,\n        distributed=distributed,\n        validate=(not args.no_validate),\n        timestamp=timestamp,\n        meta=meta)\n\n\n    \n    \nmain()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#这里修改下文件名；有时提示找不到bbox_mAP，先去掉这一段\n#!python mmdetection/tools/analyze_logs.py plot_curve work_dirs/20200602_051740.log.json --keys bbox_mAP --legend bbox_mAP --out mAP.png\n#import cv2\n\n#mAP_png=cv2.imread('mAP.png')\n#plt.imshow(mAP_png)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"config = 'mmdetection/configs/cascade_rcnn/cascade_rcnn_r50_fpn_1x_coco.py'\ncheckpoint = 'work_dirs/latest.pth'\nmodel = init_detector(config, checkpoint, device='cuda:0')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\ndef show_result(\n                img,\n                result,\n                score_thr=0.3,\n                bbox_color='green',\n                text_color='green',\n                thickness=1,\n                font_scale=0.5,\n                win_name='',\n                show=False,\n                wait_time=0,\n                out_file=None):\n    \"\"\"Draw `result` over `img`.\n    Args:\n        img (str or Tensor): The image to be displayed.\n        result (Tensor or tuple): The results to draw over `img`\n            bbox_result or (bbox_result, segm_result).\n        score_thr (float, optional): Minimum score of bboxes to be shown.\n            Default: 0.3.\n        bbox_color (str or tuple or :obj:`Color`): Color of bbox lines.\n        text_color (str or tuple or :obj:`Color`): Color of texts.\n        thickness (int): Thickness of lines.\n        font_scale (float): Font scales of texts.\n        win_name (str): The window name.\n        wait_time (int): Value of waitKey param.\n            Default: 0.\n        show (bool): Whether to show the image.\n            Default: False.\n        out_file (str or None): The filename to write the image.\n            Default: None.\n    Returns:\n        img (Tensor): Only if not `show` or `out_file`\n    \"\"\"\n    img = mmcv.imread(img)\n    img = img.copy()\n    if isinstance(result, tuple):\n        bbox_result, segm_result = result\n        if isinstance(segm_result, tuple):\n            segm_result = segm_result[0]  # ms rcnn\n    else:\n        bbox_result, segm_result = result, None\n    bboxes = np.vstack(bbox_result)\n    labels = [\n        np.full(bbox.shape[0], i, dtype=np.int32)\n        for i, bbox in enumerate(bbox_result)\n    ]\n    labels = np.concatenate(labels)\n    # draw segmentation masks\n    if segm_result is not None and len(labels) > 0:  # non empty\n        segms = mmcv.concat_list(segm_result)\n        inds = np.where(bboxes[:, -1] > score_thr)[0]\n        np.random.seed(42)\n        color_masks = [\n            np.random.randint(0, 256, (1, 3), dtype=np.uint8)\n            for _ in range(max(labels) + 1)\n        ]\n        for i in inds:\n            i = int(i)\n            color_mask = color_masks[labels[i]]\n            mask = segms[i]\n            img[mask] = img[mask] * 0.5 + color_mask * 0.5\n    # if out_file specified, do not show image in window\n    if out_file is not None:\n        show = False\n    # draw bounding boxes\n    mmcv.imshow_det_bboxes(\n        img,\n        bboxes,\n        labels,\n        class_names=('cancer_cell',),\n        score_thr=score_thr,\n        bbox_color=bbox_color,\n        text_color=text_color,\n        thickness=thickness,\n        font_scale=font_scale,\n        win_name=win_name,\n        show=show,\n        wait_time=wait_time,\n        out_file=out_file)\n\n    if not (show or out_file):\n        return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#输入测试图片的路径\nimg = '../input/global-wheat-detection/train/00333207f.jpg'\n# img = 'mmdetection/demo/demo.jpg\nresult = inference_detector(model, img)\n#print(result)\n\n#import cv2\n#cv2_img=cv2.imread(img)\n\n#print(result[0])\n#draw_0 = cv2.rectangle(cv2_img, (result[0][0][0], result[0][0][1]), (result[0][0][2], result[0][0][3]), (255, 0, 0), 2)\n\n# 保存下来是很正常的显示，完美\n#cv2.imwrite('temp_out.png',draw_0)\n\n\n#plt.imshow(mmcv.bgr2rgb(draw_0))\n\n# 这个未知原因报错了\n# show_result_pyplot(model, img, result, score_thr=0.3)\nimg = show_result(img, result, score_thr=0.3)\nplt.imshow(mmcv.bgr2rgb(img))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#这一段是为了最后的输出中找得到自己的输出文件\n!rm -rf mmdetection/","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}