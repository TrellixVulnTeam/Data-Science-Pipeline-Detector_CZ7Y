{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!cp -R ../input/yolov4tool ../working","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from yolov4tool.utils import *\nfrom yolov4tool.torch_utils import *\nfrom yolov4tool.darknet2pytorch import Darknet\nimport argparse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"hyper parameters\"\"\"\nuse_cuda = True\n\ndef detect_cv2(cfgfile, weightfile, imgfile):\n    import cv2\n    m = Darknet(cfgfile)\n\n    m.print_network()\n    m.load_weights(weightfile)\n    print('Loading weights from %s... Done!' % (weightfile))\n\n    if use_cuda:\n        m.cuda()\n\n    num_classes = m.num_classes\n    if num_classes == 20:\n        namesfile = 'data/voc.names'\n    elif num_classes == 80:\n        namesfile = 'data/coco.names'\n    else:\n        namesfile = '../input/cfgdata/obj.names'\n    class_names = load_class_names(namesfile)\n\n    img = cv2.imread(imgfile)\n    sized = cv2.resize(img, (m.width, m.height))\n    sized = cv2.cvtColor(sized, cv2.COLOR_BGR2RGB)\n\n\n    start = time.time()\n    boxes = do_detect(m, sized, 0.4, 0.6, use_cuda)\n    finish = time.time()\n    print('%s: Predicted in %f seconds.' % (imgfile, (finish - start)))\n\n    width = img.shape[1]\n    height = img.shape[0]\n    ans = ''\n\n    b = boxes[0]\n    for i in range(len(b)):\n        box = b[i]\n        x1 = int(box[0] * width)\n        y1 = int(box[1] * height)\n        x2 = int(box[2] * width)\n        y2 = int(box[3] * height)\n        w = x2 - x1\n        h = y2 - y1\n        ans = ans + str(box[4]) + ' '\n        ans = ans + str(x1) + ' '\n        ans = ans + str(y1) + ' '\n        ans = ans + str(w) + ' '\n        ans = ans + str(h) + ' '\n\n    return ans[:-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testfiles = [f for f in os.listdir('/kaggle/input/global-wheat-detection/test') if os.path.isfile(os.path.join('/kaggle/input/global-wheat-detection/test', f))]\nbox = []\nname = []\nfor test_img in testfiles:\n    cfg = '../input/cfgdata/yolov4-obj_test.cfg'\n    weight = '../input/weight/yolov4-obj_6000.weights'\n    img = os.path.join('/kaggle/input/global-wheat-detection/test', test_img)\n    \n    t = detect_cv2(cfg, weight, img)  \n    name.append(test_img[:-4])\n    box.append(t)\n\n\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\ncol_list = [name, box]\nsub = pd.DataFrame (col_list).transpose()\nsub.columns=['image_id', 'PredictionString']\nsub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}