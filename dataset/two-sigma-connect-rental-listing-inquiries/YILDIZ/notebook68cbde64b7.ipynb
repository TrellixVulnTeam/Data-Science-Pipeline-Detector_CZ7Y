{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"b6913d0f-8103-24fc-856d-6323e6a5e02e"},"source":"No categorical - no desc - no feature"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f88fed6b-6060-2853-413c-8ba268807718"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport random\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import model_selection, preprocessing, ensemble\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import Imputer\nfrom sklearn.metrics import log_loss\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom scipy import sparse\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f0e0c3f5-e939-1969-018f-371e5c2f3b1f"},"outputs":[],"source":"#input data\ntrain_df=pd.read_json('../input/train.json')\ntest_df=pd.read_json('../input/test.json')\nprint(train_df.shape)\nprint(test_df.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4cbf910c-f07b-8f94-cbb6-75a9dac56a5f"},"outputs":[],"source":"features_to_use  = [\"bathrooms\", \"bedrooms\", \"latitude\", \"longitude\", \"price\"]  #numeric features\n\n# count of photos #\ntrain_df[\"num_photos\"] = train_df[\"photos\"].apply(len)\ntest_df[\"num_photos\"] = test_df[\"photos\"].apply(len)\n\n# count of \"features\" #\ntrain_df[\"num_features\"] = train_df[\"features\"].apply(len)\ntest_df[\"num_features\"] = test_df[\"features\"].apply(len)\n\n# count of words present in description column #\ntrain_df[\"num_description_words\"] = train_df[\"description\"].apply(lambda x: len(x.split(\" \")))\ntest_df[\"num_description_words\"] = test_df[\"description\"].apply(lambda x: len(x.split(\" \")))\n\n# convert the created column to datetime object so as to extract more features \ntrain_df[\"created\"] = pd.to_datetime(train_df[\"created\"])\ntest_df[\"created\"] = pd.to_datetime(test_df[\"created\"])\n\n# Let us extract some features like year, month, day, hour from date columns #\ntrain_df[\"created_year\"] = train_df[\"created\"].dt.year\ntest_df[\"created_year\"] = test_df[\"created\"].dt.year\n\ntrain_df[\"created_month\"] = train_df[\"created\"].dt.month\ntest_df[\"created_month\"] = test_df[\"created\"].dt.month\n\ntrain_df[\"created_day\"] = train_df[\"created\"].dt.day\ntest_df[\"created_day\"] = test_df[\"created\"].dt.day\n\n#train_df[\"created_hour\"] = train_df[\"created\"].dt.hour\n#test_df[\"created_hour\"] = test_df[\"created\"].dt.hour\n\n# adding all these new features to use list #\nfeatures_to_use.extend([\"num_photos\", \"num_features\", \"num_description_words\", \"created_year\", \"created_month\", \"created_day\", \"listing_id\"])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3085bfa5-bc2b-bbbd-11ec-73691f7867a3"},"outputs":[],"source":"# Building_level:\ntrain_df.ix[train_df.building_id == '0', 'new_building_id'] = train_df['building_id'] + train_df['manager_id']\ntrain_df.ix[train_df.building_id != '0', 'new_building_id'] = train_df['building_id']\n\na=[np.nan]*len(train_df)\nbuilding_level={}\n\nfor bid in train_df['new_building_id'].values:\n    building_level[bid]=[0,0,0]\n    \nfor j in range(train_df.shape[0]):\n    rec=train_df.iloc[j]\n    if rec['interest_level']=='low':\n        building_level[rec['new_building_id']][0]+=1\n    if rec['interest_level']=='medium':\n        building_level[rec['new_building_id']][1]+=1\n    if rec['interest_level']=='high':\n        building_level[rec['new_building_id']][2]+=1\n        \nfor j in range(train_df.shape[0]):    \n        rec=train_df.iloc[j]\n        occurance = sum(building_level[rec['new_building_id']])\n        if occurance!=0:\n            a[j]= (building_level[rec['new_building_id']][0]*0.0 + building_level[rec['new_building_id']][1]*1.0 \\\n                   + building_level[rec['new_building_id']][2]*2.0) / occurance\n\ntrain_df['building_level']=a\n\ntest_df.ix[test_df.building_id == '0', 'new_building_id'] = test_df['building_id'] + test_df['manager_id']\ntest_df.ix[test_df.building_id != '0', 'new_building_id'] = test_df['building_id']\n\nb=[]\nfor i in test_df['new_building_id'].values:\n    if i not in building_level.keys():\n        b.append(np.nan)\n    else:\n        occurance = sum(building_level[i])\n        b.append((building_level[i][0]*0.0 + building_level[i][1]*1.0 \\\n                   + building_level[i][2]*2.0) / occurance)\n\ntest_df['building_level']=b\n\ntrain_df = train_df.drop(['new_building_id'], axis=1)\ntest_df = test_df.drop(['new_building_id'], axis=1)\n\nfeatures_to_use.append('building_level') "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a75c1169-d538-6b83-2c28-d8688e966986"},"outputs":[],"source":"#Manager_level\n#### Prepare train data\nindex=list(range(train_df.shape[0]))\nrandom.shuffle(index)\na=[np.nan]*len(train_df)\nb=[np.nan]*len(train_df)\nc=[np.nan]*len(train_df)\n\nfor i in range(5):\n    building_level={}\n    for j in train_df['manager_id'].values:\n        building_level[j]=[0,0,0]\n    test_index=index[int((i*train_df.shape[0])/5):int(((i+1)*train_df.shape[0])/5)]\n    train_index=list(set(index).difference(test_index))\n    for j in train_index:\n        temp=train_df.iloc[j]\n        if temp['interest_level']=='low':\n            building_level[temp['manager_id']][0]+=1\n        if temp['interest_level']=='medium':\n            building_level[temp['manager_id']][1]+=1\n        if temp['interest_level']=='high':\n            building_level[temp['manager_id']][2]+=1\n    for j in test_index:\n        temp=train_df.iloc[j]\n        if sum(building_level[temp['manager_id']])!=0:\n            a[j]=building_level[temp['manager_id']][0]*1.0/sum(building_level[temp['manager_id']])\n            b[j]=building_level[temp['manager_id']][1]*1.0/sum(building_level[temp['manager_id']])\n            c[j]=building_level[temp['manager_id']][2]*1.0/sum(building_level[temp['manager_id']])\ntrain_df['manager_level_low']=a\ntrain_df['manager_level_medium']=b\ntrain_df['manager_level_high']=c\n\n#### Prepare test data\na=[]\nb=[]\nc=[]\nbuilding_level={}\nfor j in train_df['manager_id'].values:\n    building_level[j]=[0,0,0]\nfor j in range(train_df.shape[0]):\n    temp=train_df.iloc[j]\n    if temp['interest_level']=='low':\n        building_level[temp['manager_id']][0]+=1\n    if temp['interest_level']=='medium':\n        building_level[temp['manager_id']][1]+=1\n    if temp['interest_level']=='high':\n        building_level[temp['manager_id']][2]+=1\n\nfor i in test_df['manager_id'].values:\n    if i not in building_level.keys():\n        a.append(np.nan)\n        b.append(np.nan)\n        c.append(np.nan)\n    else:\n        a.append(building_level[i][0]*1.0/sum(building_level[i]))\n        b.append(building_level[i][1]*1.0/sum(building_level[i]))\n        c.append(building_level[i][2]*1.0/sum(building_level[i]))\ntest_df['manager_level_low']=a\ntest_df['manager_level_medium']=b\ntest_df['manager_level_high']=c\n\nfeatures_to_use.append('manager_level_low') \nfeatures_to_use.append('manager_level_medium') \nfeatures_to_use.append('manager_level_high')"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}