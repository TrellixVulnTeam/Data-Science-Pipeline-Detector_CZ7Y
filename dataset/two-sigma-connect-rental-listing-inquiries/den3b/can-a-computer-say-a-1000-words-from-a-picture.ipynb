{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0,"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"8268708a-ee92-9786-a503-eeccd324bec1","_active":false},"source":"Colorspace\n==========","execution_count":null,"outputs":[],"execution_state":"idle"},{"metadata":{"_cell_guid":"3e186d6c-bb57-5836-6e79-d6ae19005c16","_active":true,"collapsed":false},"source":"from PIL import Image, ImageDraw, ImageFilter\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport nltk\nimport glob\nimport pandas as pd\n\n","execution_count":null,"cell_type":"code","outputs":[],"execution_state":"idle"},{"metadata":{"_cell_guid":"3334be2b-4526-f902-e42e-c7749ab57bdf","_active":false,"collapsed":false},"source":"plt.rcParams['figure.figsize'] = (10.0, 10.0)\ndirs = sorted(glob.glob('../input/images_sample/**/'))\ndf_img = pd.DataFrame(index = range(1000), columns = ['entry','h','w','size'])\ncounter = 0\nfor entry in dirs:\n    images = sorted(glob.glob(entry+'/**'))        \n    for im in images:\n        im = Image.open(im)\n        h,w = im.size\n        df_img.loc[counter]['entry','h','w','size'] = [entry,h,w,(h*w)]\n        counter += 1","execution_count":null,"cell_type":"code","outputs":[],"execution_state":"idle"},{"metadata":{"_cell_guid":"83ab5e37-f053-05bb-822a-4815d7c73f08","_active":false,"collapsed":false},"source":"df_img.convert_objects(convert_numeric=True)","execution_count":null,"cell_type":"code","outputs":[],"execution_state":"idle"},{"metadata":{"_cell_guid":"4e60913d-a64e-5714-d918-8758d430d9fc","_active":false,"collapsed":false},"source":"df_img.dropna(axis = 0, inplace = True)","execution_count":null,"cell_type":"code","outputs":[],"execution_state":"idle"},{"metadata":{"_cell_guid":"37d8e538-e361-8d90-aae8-430fe3d62dd2","_active":false,"collapsed":false},"source":"df_img['id'] = df_img.entry.apply(lambda x: x.split('/')[3])","execution_count":null,"cell_type":"code","outputs":[],"execution_state":"idle"},{"metadata":{"_cell_guid":"1887a709-65c2-7361-6279-47beb0f7470b","_active":false,"collapsed":false},"source":"df_img = df_img.convert_objects(convert_numeric=True)","execution_count":null,"cell_type":"code","outputs":[],"execution_state":"idle"},{"metadata":{"_cell_guid":"cb504304-c687-00c2-9915-217dc6c38645","_active":false,"collapsed":false},"source":"df_img.dtypes","execution_count":null,"cell_type":"code","outputs":[],"execution_state":"idle"},{"metadata":{"_cell_guid":"1ce932f8-eb7b-31d6-b4ff-5c14013031f7","_active":false,"collapsed":false},"source":"import re\nint(re.findall('\\d+\\/(.*)_','com/2/7211212_1ed4542')[0])","execution_count":null,"cell_type":"code","outputs":[],"execution_state":"idle"},{"metadata":{"_cell_guid":"c0d8faca-bb0c-0aed-f7e3-8e6fb7fcdeb5","_active":false,"collapsed":false},"source":"train_df.head(20)['photos'].str.find('[]')","execution_count":null,"cell_type":"code","outputs":[],"execution_state":"idle"},{"metadata":{"_cell_guid":"a0794bae-5513-21dd-8532-1278fc25027d","_active":false,"collapsed":false},"source":"train.loc[100055]","execution_count":null,"cell_type":"code","outputs":[],"execution_state":"idle"},{"metadata":{"_cell_guid":"4f7dfbfc-3bee-d87a-2855-a4221e11c4ef","_active":false,"collapsed":false},"source":"train\ntrain_df.photos.apply(lambda x: [int(re.findall('\\d+\\/(.\\d+)_',i)[0]) for i in x][])","execution_count":null,"cell_type":"code","outputs":[],"execution_state":"idle"},{"metadata":{"_cell_guid":"cfcf9582-0fa0-b170-7706-33ffcb9249ba","_active":false,"collapsed":false},"source":"train_df.head().photos.apply(lambda x: [int(re.findall('\\d+\\/(.*)_',i)[0]) for i in x])","execution_count":null,"cell_type":"code","outputs":[],"execution_state":"idle"},{"metadata":{"_cell_guid":"947ac4c1-2d16-40c7-9def-804692768f00","_active":false,"collapsed":false},"source":"train_df.head().photos","execution_count":null,"cell_type":"code","outputs":[],"execution_state":"idle"},{"metadata":{"_cell_guid":"5b9728cc-1883-e168-05ff-19024a77f2c8","_active":false,"collapsed":false},"source":"test_df = pd.read_json('../input/test.json')","execution_count":null,"cell_type":"code","outputs":[],"execution_state":"idle"},{"metadata":{"_cell_guid":"617ffc82-4293-9593-1612-44fb1b4ee5ea","_active":false,"collapsed":false},"source":"temp = pd.concat([train_df,df_img.groupby('id').mean()], axis = 1, join = 'inner')","execution_count":null,"cell_type":"code","outputs":[],"execution_state":"idle"},{"metadata":{"_cell_guid":"ac9d60dc-c3a5-ff01-472f-d92e93779a0f","_active":false,"collapsed":false},"source":"plt.plot(train_df.index)","execution_count":null,"cell_type":"code","outputs":[],"execution_state":"idle"},{"metadata":{"_cell_guid":"d3e35ab9-de12-b1aa-33a8-cf10ea113bc2","_active":false,"collapsed":false},"source":"df_img.groupby('id').mean()","execution_count":null,"cell_type":"code","outputs":[],"execution_state":"idle"},{"metadata":{"_cell_guid":"5f1b6dbe-bb39-a62d-ec04-72b9b4fbdae8","_active":false,"collapsed":false},"source":"images","execution_count":null,"cell_type":"code","outputs":[],"execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"389ff303-c029-fa17-6264-4ee7d707ffc3","_active":false},"outputs":[],"source":"from PIL import Image, ImageDraw, ImageFilter\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport nltk\nimport glob\n\nplt.rcParams['figure.figsize'] = (10.0, 10.0)\nimages = sorted(glob.glob('../input/images_sample/**/**.jpg'))\nfor im in images:\n    im = Image.open(im)\n    h, w = im.size\n    qu = im.quantize(colors=8, kmeans=4)\n    crgb = qu.convert('RGB')\n    col_rank = sorted(crgb.getcolors(h*w), reverse=True)\n    print(col_rank) #legend\n    draw = ImageDraw.Draw(im)\n    i = 0\n    for cnt, rgb in col_rank:\n        draw.rectangle([(10, i*40+10),(40, i*40+30)], fill=(rgb[0],rgb[1],rgb[2]), outline=(0,0,0))\n        draw.text((10, i*40+30), str(cnt), fill=(0,0,0))\n        i += 1\n    del draw\n    plt.imshow(im); plt.axis('off')\n    break","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"5f310156-59d9-9883-0c47-670f9ea4592f","_active":false},"source":"Image Statistics\n================","execution_count":null,"outputs":[],"execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5bf0abed-3bfe-09a0-3e51-b574326e1368","_active":false},"outputs":[],"source":"from PIL import ImageStat\nfor im in images:\n    img = Image.open(im)\n    stats = ImageStat.Stat(img, mask=None)\n    print(stats.extrema)\n    print(stats.count)\n    print(stats.sum)\n    print(stats.sum2)\n    print(stats.mean)\n    print(stats.median)\n    print(stats.rms)\n    print(stats.var)\n    print(stats.stddev)\n    plt.imshow(img); plt.axis('off')\n    break","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"3a528c44-f184-de07-97f1-f78e834b9863","_active":false},"source":"OCR Watermarks or Floor Plans for features\n==========================================","execution_count":null,"outputs":[],"execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a39125d0-6bcf-3f68-9d3b-6bf9727098b8","_active":false},"outputs":[],"source":"from PIL import Image\n#import pytesseract #sudo apt-get install tesseract-ocr or submit pull request to Kaggle Docker\nimport glob\n\n#images = glob.glob('../input/images_sample/**/**.jpg')\n#for im in images:\n#    img = Image.open(im) #rotate images 90 degrees\n#    t = pytesseract.image_to_string(img)\n#    if len(t)>0:\n#        print(im, '\\n', t)\n\n\"\"\"\n../input/images_sample/6812223/6812223_906d2825311544e3ef052c315f4dddb7.jpg \n HABITATS\n../input/images_sample/6811964/6811964_552eab2b6974e995b419654faecc1cd8.jpg \n BALCONY\n\nGreenhouse ubwa\na! m Mlnnv\n\nLIVING ROOM\nI2‘-5'n I9‘-2\"\n\nEEDROOM\nI! an IE Lo\"\n../input/images_sample/6811974/6811974_39be7f428f80beda5163e909ea05a95a.jpg \n MLLEJRE\n../input/images_sample/6811974/6811974_197bb9515b3d7929c2848e61a050ad1a.jpg \n U\nBALCONY\nUV‘NG/DININE\nH M' X Wl'\nm\nm x m- E\nr ..\nKIT NT ll:\nL D\n—H Vi-\nAIH STURAE\n\"\"\"\nprint('OCR..')","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fa481f69-06fd-16ca-770c-d4cd08129f12","_active":false},"outputs":[],"source":"import time; start_time = time.time()\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn import model_selection, preprocessing\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.pipeline import FeatureUnion\nfrom sklearn.metrics import log_loss\nfrom sklearn import pipeline\nimport pandas as pd\nimport numpy as np\nfrom nltk.stem.porter import *\nstemmer = PorterStemmer()\nfrom bs4 import BeautifulSoup\nimport random; random.seed(7)\nimport xgboost as xgb\nimport datetime as dt\n\ntrain = pd.read_json(open(\"../input/train.json\", \"r\"))[:100] #limit\ny = train.interest_level.values\nn = len(train)\n\ntest = pd.read_json(open(\"../input/test.json\", \"r\"))[:100] #limit\nlisting_id = test.listing_id.values\n\ncol = [x for x in train.columns if x not in ['listing_id','interest_level','street_address']]\nprint(col)\nprint(len(train),len(test))\n\ndef str_stem(s): \n    if isinstance(s, str):\n        s = s.lower()\n        s = s.replace(\"  \",\" \")\n        b = BeautifulSoup(s, \"lxml\")\n        s = b.get_text(\" \").strip()\n        s = (\" \").join([z for z in s.split(\" \")])\n        s = (\" \").join([stemmer.stem(z) for z in s.split(\" \")])\n        s = s.lower().strip()\n        return s\n    else:\n        return \"\"\n\nclass cust_regression_vals(BaseEstimator, TransformerMixin):\n    def fit(self, x, y=None):\n        return self\n    def transform(self, df):\n        d_col_drops=['xdescription', 'ydescription']\n        df = df.drop(d_col_drops, axis=1).values\n        return df\n\nclass cust_txt_col(BaseEstimator, TransformerMixin):\n    def __init__(self, key):\n        self.key = key\n    def fit(self, x, y=None):\n        return self\n    def transform(self, data_dict):\n        return data_dict[self.key].apply(str)\n    \ndf_all = pd.concat((train[col], test[col]), axis=0, ignore_index=True)\ntrain = []\ntest = []\n\ndf_all['photos'] = df_all.photos.apply(len)\n\ndf_all[\"price_be\"] = df_all[\"price\"]/df_all[\"bedrooms\"]\ndf_all[\"price_ba\"] = df_all[\"price\"]/df_all[\"bathrooms\"]\n\ndf_all[\"created\"] = pd.to_datetime(df_all[\"created\"])\ndf_all[\"created_year\"] = df_all[\"created\"].dt.year\ndf_all[\"created_month\"] = df_all[\"created\"].dt.month\ndf_all[\"created_day\"] = df_all[\"created\"].dt.day\ndf_all['created_hour'] = df_all[\"created\"].dt.hour\ndf_all['created_weekday'] = df_all['created'].dt.weekday\ndf_all['created_week'] = df_all['created'].dt.week\ndf_all['created_quarter'] = df_all['created'].dt.quarter\ndf_all['created_weekend'] = ((df_all['created_weekday'] == 5) & (df_all['created_weekday'] == 6))\ndf_all['created_wd'] = ((df_all['created_weekday'] != 5) & (df_all['created_weekday'] != 6))\ndf_all['created'] = df_all['created'].map(lambda x: float((x - dt.datetime(1899, 12, 30)).days) + (float((x - dt.datetime(1899, 12, 30)).seconds) / 86400))\n\ndf_all['x5'] = df_all['latitude'].map(lambda x : round(x,5))\ndf_all['y5'] = df_all['longitude'].map(lambda x : round(x,5))\ndf_all['x4'] = df_all['latitude'].map(lambda x : round(x,4))\ndf_all['y4'] = df_all['longitude'].map(lambda x : round(x,4))\ndf_all['x3'] = df_all['latitude'].map(lambda x : round(x,3))\ndf_all['y3'] = df_all['longitude'].map(lambda x : round(x,3))\ndf_all['x2'] = df_all['latitude'].map(lambda x : round(x,2))\ndf_all['y2'] = df_all['longitude'].map(lambda x : round(x,2))\n\ndummies = df_all['features'].str.join(sep=',').str.lower().str.get_dummies(sep=',')\ndf_all = pd.concat([df_all, dummies], axis=1)\ndummies = []\ndf_all['features'] = df_all.features.apply(len)\n\ncat = ['building_id',  'description', 'display_address', 'manager_id']\nlbl = preprocessing.LabelEncoder()\nfor c in cat:\n    if c in ['description']:\n        df_all['x'+c] = df_all[c].map(lambda x:str_stem(x))\n        df_all['y'+c] = df_all[c].values\n    df_all['words_of_'+c] = df_all[c].map(lambda x:len(x.strip().split(' ')))\n    df_all['len_of_'+c] = df_all[c].map(lambda x:len(x.strip()))\n    df_all[c] = lbl.fit_transform(list(df_all[c].values))\n    print(c, len(lbl.classes_))\n\ntrain = df_all.iloc[:n]\ntest = df_all.iloc[n:]\n#df_all = []\n\ntfidf = TfidfVectorizer(stop_words ='english', max_df=0.9)\ntsvd = TruncatedSVD(n_components=25, random_state = 7)\nclf = pipeline.Pipeline([\n        ('union', FeatureUnion(\n                    transformer_list = [\n                        ('cst',  cust_regression_vals()),\n                        ('txt1', pipeline.Pipeline([('s1', cust_txt_col(key='xdescription')), ('tfidf1', tfidf), ('tsvd1', tsvd)])),\n                        ('txt2', pipeline.Pipeline([('s2', cust_txt_col(key='ydescription')), ('tfidf2', tfidf), ('tsvd2', tsvd)]))\n                        ],\n                    transformer_weights = {\n                        'cst': 1.0,\n                        'txt1': 1.0,\n                        'txt2': 1.0\n                        },\n                n_jobs = -1\n                ))])\n\ny_val = lbl.fit_transform(y)\nxtrain = pd.DataFrame(clf.fit_transform(train)).apply(pd.to_numeric)\nxtrain = xgb.DMatrix(xtrain.values, y_val)\nxtest = pd.DataFrame(clf.transform(test)).apply(pd.to_numeric)\nxtest = xgb.DMatrix(xtest.values)\n\nparam = {}\nparam['objective'] = 'multi:softprob'\nparam['eta'] = 0.1\n#param['max_depth'] = 4\nparam['silent'] = True\nparam['num_class'] = 3\nparam['eval_metric'] = \"mlogloss\"\nparam['min_child_weight'] = 1\nparam['subsample'] = 0.8\nparam['colsample_bytree'] = 0.8\nparam['seed'] = 7\nplst = list(param.items())\nnfolds = 5\nnrounds = 1000\n\nmodel = xgb.cv(plst, xtrain, nrounds, nfolds, early_stopping_rounds=20, verbose_eval=25)\nbest_rounds = np.argmin(model['test-mlogloss-mean'])\nmodel = xgb.train(plst, xtrain, best_rounds)\nprint(log_loss(y_val, model.predict(xtrain)))\npreds = model.predict(xtest)\nout_df = pd.DataFrame(preds)\nout_df.columns = lbl.inverse_transform(out_df.columns)\nout_df[\"listing_id\"] = listing_id\nout_df.to_csv(\"z09submission01.csv\", index=False)\nprint('Done...',(time.time()-start_time)/60)","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"6b743033-cac4-285c-731c-87bdf471df5a","_active":false},"source":"Future Review\n=============\n- Can appliances be identified\n- Can room be measured\n- What kind of flooring\n- Can windows and their view be ranked\n- Can defects be identified\n- Is it furnished, someone living there\n- Has picture been photoshopped (altered)\n- Add your own to the list on comments and fork to suggest/showcase additional features","execution_count":null,"outputs":[],"execution_state":"idle"}]}