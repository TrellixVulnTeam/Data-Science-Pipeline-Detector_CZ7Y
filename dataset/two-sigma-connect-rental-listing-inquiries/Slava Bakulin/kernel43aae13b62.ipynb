{"cells":[{"metadata":{},"cell_type":"markdown","source":"\nhttps://www.kaggle.com/adamsfei/only-brand-new-features\n\nhttps://www.kaggle.com/guoday/cv-statistics-better-parameters-and-explaination\n\nhttps://www.kaggle.com/jxnlco/deduplicating-features\n\nhttps://www.kaggle.com/sudalairajkumar/xgb-starter-in-python\n\nhttps://www.kaggle.com/kazanova/xgboost-python-scores-around-0-544\n\n\nВ коде показал что откуда взято"},{"metadata":{},"cell_type":"markdown","source":"[Сам безлайн](https://www.kaggle.com/sudalairajkumar/xgb-starter-in-python)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport sys\nimport operator\nimport numpy as np\nimport pandas as pd\nfrom scipy import sparse\nimport random\nimport xgboost as xgb\nfrom sklearn import model_selection, preprocessing, ensemble\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import log_loss\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom collections import defaultdict, Counter","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def runXGB(train_X, train_y, test_X, test_y=None, feature_names=None, seed_val=0, num_rounds=1000):\n    param = {}\n    param['objective'] = 'multi:softprob'\n    param['eta'] = 0.03\n    param['max_depth'] = 6\n    param['silent'] = 1\n    param['num_class'] = 3\n    param['eval_metric'] = \"mlogloss\"\n    param['min_child_weight'] = 1\n    param['subsample'] = 0.7\n    param['colsample_bytree'] = 0.7\n    param['seed'] = seed_val\n    num_rounds = num_rounds\n\n    plst = list(param.items())\n    xgtrain = xgb.DMatrix(train_X, label=train_y)\n\n    if test_y is not None:\n        xgtest = xgb.DMatrix(test_X, label=test_y)\n        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n        model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=20)\n    else:\n        xgtest = xgb.DMatrix(test_X)\n        model = xgb.train(plst, xgtrain, num_rounds)\n\n    pred_test_y = model.predict(xgtest)\n    return pred_test_y, model","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data_path = \"../input/two-sigma-connect-rental-listing-inquiries/\"\ntrain_file = data_path + \"train.json.zip\"\ntest_file = data_path + \"test.json.zip\"\ntrain_df = pd.read_json(train_file, compression='zip')\ntest_df = pd.read_json(test_file, compression='zip')\n# print(train_df.shape)\n# print(test_df.shape)\n\n\nfeatures_to_use  = [\"bathrooms\", \"bedrooms\", \"latitude\", \"longitude\", \"price\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_price = int(train_df['price'].mean())\ntest_df.loc[test_df['price']<200,'price'] = mean_price\ntrain_df.loc[train_df['price']<200,'price'] = mean_price","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[Подход к очистке \"features\" отсюда](https://www.kaggle.com/jxnlco/deduplicating-features)"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_test = pd.concat([train_df, test_df], 0,sort=False)\n\nfeatures = train_test[[\"features\"]].apply(\n    lambda _: [list(map(str.strip, map(str.lower, x))) for x in _])\n\n\nn = 5\n\nfeature_counts = Counter()\nfor feature in features.features:\n    feature_counts.update(feature)\nfeature = sorted([k for (k,v) in feature_counts.items() if v > n])\nfeature[:10]\n\n\ndef clean(s):\n    x = s.replace(\"-\", \"\")\n    x = x.replace(\" \", \"\")\n    x = x.replace(\"24/7\", \"24\")\n    x = x.replace(\"24hr\", \"24\")\n    x = x.replace(\"24-hour\", \"24\")\n    x = x.replace(\"24hour\", \"24\")\n    x = x.replace(\"24 hour\", \"24\")\n    x = x.replace(\"common\", \"cm\")\n    x = x.replace(\"concierge\", \"doorman\")\n    x = x.replace(\"bicycle\", \"bike\")\n    x = x.replace(\"pets:cats\", \"cats\")\n    x = x.replace(\"allpetsok\", \"pets\")\n    x = x.replace(\"dogs\", \"pets\")\n    x = x.replace(\"private\", \"pv\")\n    x = x.replace(\"deco\", \"dc\")\n    x = x.replace(\"decorative\", \"dc\")\n    x = x.replace(\"onsite\", \"os\")\n    x = x.replace(\"outdoor\", \"od\")\n    x = x.replace(\"ss appliances\", \"stainless\")\n    return x\n\ndef feature_hash(x):\n    cleaned = clean(x, uniq)\n    key = cleaned[:4].strip()\n    return key\n\n\nkey2original = defaultdict(list)\nk = 4\nfor f in feature:\n    cleaned = clean(f)\n    key = cleaned[:k].strip()\n\n    key2original[key].append(f)\n\n    \ndef to_tuples():\n    for f in feature:\n        key = clean(f)[:k].strip()\n        yield (f, key2original[key][0])\n        \ndeduped = list(to_tuples())\ndf = pd.DataFrame(deduped, columns=[\"original_feature\", \"unique_feature\"])\n\ndict_rep_features = pd.Series(df['unique_feature'].values, df['original_feature'].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df['features'] = test_df['features'].apply(lambda x: list(map(str.strip, map(str.lower, x))))\\\n                    .apply(lambda x: [dict_rep_features[i] for i in x if i in dict_rep_features.index])\\\n                    .apply(lambda x: list(set(x)))\n\ntrain_df['features'] = train_df['features'].apply(lambda x: list(map(str.strip, map(str.lower, x))))\\\n                    .apply(lambda x: [dict_rep_features[i] for i in x if i in dict_rep_features.index])\\\n                    .apply(lambda x: list(set(x)))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[Фичи с полярной системой координат, поворотами и из следующей ячейки отсюда](https://www.kaggle.com/adamsfei/only-brand-new-features)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import math\ndef cart2rho(x, y):\n    rho = np.sqrt(x**2 + y**2)\n    return rho\n\n\ndef cart2phi(x, y):\n    phi = np.arctan2(y, x)\n    return phi\n\n\ndef rotation_x(row, alpha):\n    x = row['latitude']\n    y = row['longitude']\n    return x*math.cos(alpha) + y*math.sin(alpha)\n\n\ndef rotation_y(row, alpha):\n    x = row['latitude']\n    y = row['longitude']\n    return y*math.cos(alpha) - x*math.sin(alpha)\n\n\ndef add_rotation(degrees, df):\n    namex = \"rot\" + str(degrees) + \"_X\"\n    namey = \"rot\" + str(degrees) + \"_Y\"\n\n    df['num_' + namex] = df.apply(lambda row: rotation_x(row, math.pi/(180/degrees)), axis=1)\n    df['num_' + namey] = df.apply(lambda row: rotation_y(row, math.pi/(180/degrees)), axis=1)\n\n    return df\n\ndef operate_on_coordinates(tr_df, te_df):\n    for df in [tr_df, te_df]:\n        #polar coordinates system\n        df[\"num_rho\"] = df.apply(lambda x: cart2rho(x[\"latitude\"] - 40.78222222, x[\"longitude\"]+73.96527777), axis=1)\n        df[\"num_phi\"] = df.apply(lambda x: cart2phi(x[\"latitude\"] - 40.78222222, x[\"longitude\"]+73.96527777), axis=1)\n        #rotations\n        for angle in [15,30,45,60]:\n            df = add_rotation(angle, df)\n\n    return tr_df, te_df\n\ntrain_df, test_df = operate_on_coordinates(train_df, test_df)\n\nfeatures_to_use.extend(['num_rho', 'num_phi', 'num_rot15_X', 'num_rot15_Y', 'num_rot30_X',\n       'num_rot30_Y', 'num_rot45_X', 'num_rot45_Y', 'num_rot60_X',\n       'num_rot60_Y'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\n\ndef cap_share(x):\n    return sum(1 for c in x if c.isupper())/float(len(x)+1)\n\nfor df in [train_df, test_df]:\n    # do you think that users might feel annoyed BY A DESCRIPTION THAT IS SHOUTING AT THEM?\n    df['num_cap_share'] = df['description'].apply(cap_share)\n    \n    # how long in lines the desc is?\n    df['num_nr_of_lines'] = df['description'].apply(lambda x: x.count('<br /><br />'))\n   \n    # is the description redacted by the website?        \n    df['num_redacted'] = 0\n    df['num_redacted'].ix[df['description'].str.contains('website_redacted')] = 1\n\n    \n    # can we contact someone via e-mail to ask for the details?\n    df['num_email'] = 0\n    df['num_email'].ix[df['description'].str.contains('@')] = 1\n    \n    #and... can we call them?\n    \n    reg = re.compile(\".*?(\\(?\\d{3}\\D{0,3}\\d{3}\\D{0,3}\\d{4}).*?\", re.S)\n    def try_and_find_nr(description):\n        if reg.match(description) is None:\n            return 0\n        return 1\n\n    df['num_phone_nr'] = df['description'].apply(try_and_find_nr)\n\n    \n\n\nfeatures_to_use.extend(['num_cap_share', 'num_nr_of_lines', 'num_redacted',\n       'num_email', 'num_phone_nr'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# count of photos #\ntrain_df[\"num_photos\"] = train_df[\"photos\"].apply(len)\ntest_df[\"num_photos\"] = test_df[\"photos\"].apply(len)\n\n# count of \"features\" #\ntrain_df[\"num_features\"] = train_df[\"features\"].apply(len)\ntest_df[\"num_features\"] = test_df[\"features\"].apply(len)\n\n# count of words present in description column #\ntrain_df[\"num_description_words\"] = train_df[\"description\"].apply(lambda x: len(x.split(\" \")))\ntest_df[\"num_description_words\"] = test_df[\"description\"].apply(lambda x: len(x.split(\" \")))\n\n# convert the created column to datetime object so as to extract more features \ntrain_df[\"created\"] = pd.to_datetime(train_df[\"created\"])\ntest_df[\"created\"] = pd.to_datetime(test_df[\"created\"])\n\n# Let us extract some features like year, month, day, hour from date columns #\ntrain_df[\"created_year\"] = train_df[\"created\"].dt.year\ntest_df[\"created_year\"] = test_df[\"created\"].dt.year\ntrain_df[\"created_month\"] = train_df[\"created\"].dt.month\ntest_df[\"created_month\"] = test_df[\"created\"].dt.month\ntrain_df[\"created_day\"] = train_df[\"created\"].dt.day\ntest_df[\"created_day\"] = test_df[\"created\"].dt.day\ntrain_df[\"created_hour\"] = train_df[\"created\"].dt.hour\ntest_df[\"created_hour\"] = test_df[\"created\"].dt.hour\n\n# adding all these new features to use list #\nfeatures_to_use.extend([\"num_photos\", \"num_features\", \"num_description_words\",\"created_year\", \"created_month\", \"created_day\", \"listing_id\", \"created_hour\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[\"price_t\"] =train_df[\"price\"]/train_df[\"bedrooms\"]\ntest_df[\"price_t\"] = test_df[\"price\"]/test_df[\"bedrooms\"] \n\ntrain_df[\"room_sum\"] = train_df[\"bedrooms\"]+train_df[\"bathrooms\"] \ntest_df[\"room_sum\"] = test_df[\"bedrooms\"]+test_df[\"bathrooms\"] \n\n\nfeatures_to_use.extend([\"price_t\", \"room_sum\", \"num_description_words\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[Кодирование Y'ком менеджера отсюда](https://www.kaggle.com/guoday/cv-statistics-better-parameters-and-explaination) "},{"metadata":{"trusted":true},"cell_type":"code","source":"start_values = [0,0,0]\n\nindex=list(range(train_df.shape[0]))\nrandom.shuffle(index)\na=[np.nan]*len(train_df)\nb=[np.nan]*len(train_df)\nc=[np.nan]*len(train_df)\n\nfor i in range(5):\n    building_level={}\n    for j in train_df['manager_id'].values:\n        building_level[j]= start_values.copy()\n    test_index=index[int((i*train_df.shape[0])/5):int(((i+1)*train_df.shape[0])/5)]\n    train_index=list(set(index).difference(test_index))\n    for j in train_index:\n        temp=train_df.iloc[j]\n        if temp['interest_level']=='low':\n            building_level[temp['manager_id']][0]+=1\n        if temp['interest_level']=='medium':\n            building_level[temp['manager_id']][1]+=1\n        if temp['interest_level']=='high':\n            building_level[temp['manager_id']][2]+=1\n    for j in test_index:\n        temp=train_df.iloc[j]\n        if sum(building_level[temp['manager_id']])!=0:\n            a[j]=building_level[temp['manager_id']][0]*1.0/sum(building_level[temp['manager_id']])\n            b[j]=building_level[temp['manager_id']][1]*1.0/sum(building_level[temp['manager_id']])\n            c[j]=building_level[temp['manager_id']][2]*1.0/sum(building_level[temp['manager_id']])\ntrain_df['manager_level_low']=a\ntrain_df['manager_level_medium']=b\ntrain_df['manager_level_high']=c\n\n\na=[]\nb=[]\nc=[]\nbuilding_level={}\nfor j in train_df['manager_id'].values:\n    building_level[j]= start_values.copy()\nfor j in range(train_df.shape[0]):\n    temp=train_df.iloc[j]\n    if temp['interest_level']=='low':\n        building_level[temp['manager_id']][0]+=1\n    if temp['interest_level']=='medium':\n        building_level[temp['manager_id']][1]+=1\n    if temp['interest_level']=='high':\n        building_level[temp['manager_id']][2]+=1\n\nfor i in test_df['manager_id'].values:\n    if i not in building_level.keys():\n        a.append(np.nan)\n        b.append(np.nan)\n        c.append(np.nan)\n    else:\n        a.append(building_level[i][0]*1.0/sum(building_level[i]))\n        b.append(building_level[i][1]*1.0/sum(building_level[i]))\n        c.append(building_level[i][2]*1.0/sum(building_level[i]))\ntest_df['manager_level_low']=a\ntest_df['manager_level_medium']=b\ntest_df['manager_level_high']=c\n\nfeatures_to_use.append('manager_level_low') \nfeatures_to_use.append('manager_level_medium') \nfeatures_to_use.append('manager_level_high')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[Фичи Казановы](https://www.kaggle.com/kazanova/xgboost-python-scores-around-0-544)"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[\"listing_id1\"] = train_df[\"listing_id\"] - 68119576.0\ntest_df[\"listing_id1\"] =  test_df[\"listing_id\"] - 68119576.0\n\ntrain_df[\"num_price_by_furniture\"] = (train_df[\"price\"])/ (train_df[\"bathrooms\"] + train_df[\"bedrooms\"] + 1.0)\ntest_df[\"num_price_by_furniture\"] =  (test_df[\"price\"])/ (test_df[\"bathrooms\"] + test_df[\"bedrooms\"] +  1.0)\n\ntrain_df[\"price_latitue\"] = (train_df[\"price\"])/ (train_df[\"latitude\"]+1.0)\ntest_df[\"price_latitue\"] =  (test_df[\"price\"])/ (test_df[\"latitude\"]+1.0)\n\ntrain_df[\"price_longtitude\"] = (train_df[\"price\"])/ (train_df[\"longitude\"]-1.0)\ntest_df[\"price_longtitude\"] =  (test_df[\"price\"])/ (test_df[\"longitude\"]-1.0)  \n\ntrain_df[\"num_furniture\"] =  train_df[\"bathrooms\"] + train_df[\"bedrooms\"] \ntest_df[\"num_furniture\"] =   test_df[\"bathrooms\"] + test_df[\"bedrooms\"] \n\ntrain_df[\"total_days\"] =   (train_df[\"created_month\"] -4.0)*30 + train_df[\"created_day\"] +  train_df[\"created_hour\"] /25.0\ntest_df[\"total_days\"] =(test_df[\"created_month\"] -4.0)*30 + test_df[\"created_day\"] +  test_df[\"created_hour\"] /25.0        \ntrain_df[\"diff_rank\"]= train_df[\"total_days\"]/train_df[\"listing_id1\"]\ntest_df[\"diff_rank\"]= test_df[\"total_days\"]/test_df[\"listing_id1\"]\n\n\nfeatures_to_use.extend([ \"total_days\",\"diff_rank\",\n\"num_price_by_furniture\",\"price_latitue\",\"price_longtitude\",'num_furniture'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical = [\"display_address\", \"manager_id\", \"building_id\", \"street_address\"]\nfor f in categorical:\n        if train_df[f].dtype=='object':\n            #print(f)\n            lbl = preprocessing.LabelEncoder()\n            lbl.fit(list(train_df[f].values) + list(test_df[f].values))\n            train_df[f] = lbl.transform(list(train_df[f].values))\n            test_df[f] = lbl.transform(list(test_df[f].values))\n            features_to_use.append(f)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Придуманные фичи"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Прирост 0.001\ntrain_df[\"price0\"] = (train_df[\"price\"]%10==0).astype(int)\ntest_df[\"price0\"] = (test_df[\"price\"]%10==0).astype(int)\n\n# Прирост 0.002\ntrain_df[\"manager_count\"] = train_df[\"manager_id\"].replace(train_df[\"manager_id\"].value_counts())\ntest_df[\"manager_count\"] = test_df[\"manager_id\"].replace(train_df[\"manager_id\"].value_counts())\n\nfeatures_to_use.extend([\"price0\",'manager_count'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['features'] = train_df[\"features\"].apply(lambda x: \" \".join([\"_\".join(i.split(\" \")) for i in x]))\ntest_df['features'] = test_df[\"features\"].apply(lambda x: \" \".join([\"_\".join(i.split(\" \")) for i in x]))\nprint(train_df[\"features\"].head())\ntfidf = CountVectorizer(stop_words='english', max_features=70)\nte_sparse = tfidf.fit_transform(test_df[\"features\"])\ntr_sparse = tfidf.transform(train_df[\"features\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Тоже у Казановы взял\ntfidfdesc=TfidfVectorizer(min_df=20, max_features=50, strip_accents='unicode',lowercase =True,\n                    analyzer='word', token_pattern=r'\\w{16,}', ngram_range=(1, 2), use_idf=False,smooth_idf=False, \n                    sublinear_tf=True, stop_words = 'english')  \n\ntrain_df['description'] =  train_df['description'].apply(lambda x: str(x).encode('utf-8') if len(x)>2 else \"nulldesc\") \ntest_df['description'] =   test_df['description'].apply(lambda x: str(x).encode('utf-8') if len(x)>2 else \"nulldesc\") \nte_sparsed = tfidfdesc. fit_transform (test_df[\"description\"])  \ntr_sparsed = tfidfdesc.transform(train_df[\"description\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X = sparse.hstack([train_df[features_to_use], tr_sparse,tr_sparsed]).tocsr()#\ntest_X = sparse.hstack([test_df[features_to_use], te_sparse,te_sparsed]).tocsr()#\n\ntarget_num_map = {'high':0, 'medium':1, 'low':2}\ntrain_y = np.array(train_df['interest_level'].apply(lambda x: target_num_map[x]))\n\nprint(train_X.shape, test_X.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cv_scores = []\n# kf = model_selection.KFold(n_splits=5, shuffle=False, random_state=2016)\n# for dev_index, val_index in kf.split(range(train_X.shape[0])):\n#         dev_X, val_X = train_X[dev_index,:], train_X[val_index,:]\n#         dev_y, val_y = train_y[dev_index], train_y[val_index]\n#         preds, model = runXGB(dev_X, dev_y, val_X, val_y)\n#         cv_scores.append(log_loss(val_y, preds))\n        \n# print(np.mean(cv_scores))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds, model = runXGB(train_X, train_y, test_X, num_rounds=1000)\nout_df = pd.DataFrame(preds)\nout_df.columns = [\"high\", \"medium\", \"low\"]\nout_df[\"listing_id\"] = test_df.listing_id.values\nout_df.to_csv(\"xgb_starter2.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}