{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Two Sigma Connect: Rental Listing Inquiries"},{"metadata":{},"cell_type":"markdown","source":"## Step 1: Frame the Problem"},{"metadata":{},"cell_type":"markdown","source":"- <b>Objective: </b>In this competition we have to predict the popularity of an apartment listed on RentHop. For each listed apartment we have information such as number of rooms, description, address, location co-ordinates, price etc.\n- Popularity of each apartment is classified in 3 categories: high, medium, low. We have to predict probability for each category for given apartment information.\n\n\n- <b>Data Fields: </b>\n    - bathrooms: number of bathrooms\n    - bedrooms: number of bathrooms\n    - building_id\n    - created\n    - description\n    - display_address\n    - features: a list of features about this apartment\n    - latitude\n    - listing_id\n    - longitude\n    - manager_id\n    - photos: a list of photo links. You are welcome to download the pictures yourselves from renthop's site, but they are the same as imgs.zip. \n    - price: in USD\n    - street_address\n    - interest_level: this is the target variable. It has 3 categories: 'high', 'medium', 'low'"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_json('../input/two-sigma-connect-rental-listing-inquiries/train.json.zip')\nprint(data.shape)\ndata.head(n=3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 2: Data Exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_explore = data.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Description and photos are important information for listed apartment. Since currently I don't have knowledge about how to handle text and image features I will be discarding these features for now. I will just include the quantitaive information about these features. That might reveal something about intrest."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_explore['num_photos'] = data_explore['photos'].apply(len)\ndata_explore['num_features'] = data_explore['features'].apply(len)\ndata_explore['num_description_words'] = data_explore['description'].apply(lambda x: len(x.split(' ')))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_explore = data_explore.drop(['description', 'street_address', 'photos', 'listing_id'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_explore.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"null_cols = data_explore.isna().sum()\nnull_cols[null_cols>0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in data_explore.columns:\n    try:\n        print(col, '\\t\\t' ,data_explore[col].nunique())\n    except:\n        pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_explore['created_year'] = pd.DatetimeIndex(data_explore['created']).year\ndata_explore['created_month'] = pd.DatetimeIndex(data_explore['created']).month\ndata_explore['created_day'] = pd.DatetimeIndex(data_explore['created']).day","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_explore.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- It seems that the data is from year 2016 only which means created_year feature is redundant."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_explore = data_explore.drop(['created_year'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_histogram(data):\n    ax = plt.gca()\n    counts, _, patches = ax.hist(data)\n    for count, patch in zip(counts, patches):\n        if count>0:\n            ax.annotate(str(int(count)), xy=(patch.get_x(), patch.get_height()+5))\n    if data.name:\n        plt.xlabel(data.name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 13))\ni=1\nfor col in ['bathrooms', 'bedrooms', 'num_features', 'created_month', 'created_day', 'interest_level']:\n    plt.subplot(3, 2, i)\n    plot_histogram(data_explore[col])\n    i+=1\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- We can say that we have imbalance dataset. Many of apartment listing are seems to be less popular."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Box-Plot\nplt.figure(figsize=(8, 4))\nsns.boxplot(x='price', data=data_explore, orient='h')\nplt.xlim(-1000, 10000)\nax = plt.gca()\nax.get_xaxis().get_major_formatter().set_scientific(False)\nax.set_title('Distribution of Price')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Q1 = data_explore['price'].quantile(0.25)\nQ3 = data_explore['price'].quantile(0.75)\nIQR = Q3 - Q1\n((data_explore['price'] < (Q1 - 1.5 * IQR)) | (data_explore['price'] > (Q3 + 1.5 * IQR))).sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Box-Plot\nplt.figure(figsize=(7, 5))\nsns.boxplot(x='interest_level', y='price',  data=data_explore, orient='v')\nplt.ylim(-100, 10000)\nax = plt.gca()\nax.get_yaxis().get_major_formatter().set_scientific(False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Apartments where high intrest is shown are having less median price than the apartment where low or medium intrest is shown."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.scatterplot(x='longitude', y='latitude', hue='interest_level', data=data_explore)\nplt.xlim(-74.1, -73.7)\nplt.ylim(40.55, 40.95)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14, 10))\nplt.subplot(2, 2, 1)\nsns.barplot(x='interest_level', y='bedrooms',  data=data_explore, orient='v', estimator=np.median)\nplt.ylabel('Median # of Bedrooms')\nplt.subplot(2, 2, 2)\nsns.barplot(x='interest_level', y='bathrooms',  data=data_explore, orient='v', estimator=np.median)\nplt.ylabel('Median # of Bathrooms')\nplt.subplot(2, 2, 3)\nsns.barplot(x='interest_level', y='num_photos',  data=data_explore, orient='v', estimator=np.median)\nplt.ylabel('Median # of Photos')\nplt.subplot(2, 2, 4)\nsns.barplot(x='interest_level', y='num_description_words',  data=data_explore, orient='v', estimator=np.median)\nplt.ylabel('Median # of Words in Description')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud\n\nplt.figure(figsize = (12, 12))\ntext = ' '.join(data['description'].values)\nwordcloud = WordCloud(max_font_size=None, background_color='white', width=1200, height=1000).generate(text)\nplt.imshow(wordcloud)\nplt.title('Top Words in Apartment Description', fontsize=14)\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_features = list(data_explore['features'].values)\nplt.figure(figsize = (10, 10))\ntext = ' '.join(['_'.join(i.split(' ')) for j in list_of_features for i in j])\nwordcloud = WordCloud(max_font_size=None, background_color='white', collocations=False, width=1200, height=1000).generate(text)\nplt.imshow(wordcloud)\nplt.title('Top Features', fontsize=14)\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12, 12))\ndata['display_address'] = data['display_address'].apply(lambda x: x.replace(' ', '_'))\ntext = ' '.join(data['display_address'].values)\nwordcloud = WordCloud(max_font_size=None, background_color='white', width=1200, height=1000).generate(text)\nplt.imshow(wordcloud)\nplt.title('Display Addresses', fontsize=14)\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 3: Data Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, MultiLabelBinarizer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.base import BaseEstimator, TransformerMixin","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data.drop(columns=['interest_level'], axis=1).copy()\ny = data['interest_level'].copy()\nX.shape, y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_attrs = ['building_id', 'display_address', 'manager_id',]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedShuffleSplit\n\nsplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n\nfor train_index, test_index in split.split(X, y):\n    strat_train_set = data.iloc[train_index]\n    strat_test_set = data.iloc[test_index]\n\nX_train = strat_train_set.drop('interest_level', axis=1)\ny_train = strat_train_set['interest_level'].copy()\nX_test = strat_test_set.drop('interest_level', axis=1)\ny_test = strat_test_set['interest_level'].copy()\nX_train.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import itertools\nfrom collections import Counter\na = list(data['features'].values.flatten())\nfeature_list = list(itertools.chain.from_iterable(a))\ntop_25_features = [ x for x, y in Counter(feature_list).most_common(25)]\ntop_25_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CustomDateAttrs(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        X['created_month'] = pd.DatetimeIndex(X['created']).month\n        X['created_day'] = pd.DatetimeIndex(X['created']).day\n        X = X.drop(['created'], axis=1)\n        return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CustomNumAttrs(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        X['photos'] = X['photos'].apply(len)\n        X['description'] = X['description'].apply(lambda x: len(x.split(' ')))\n        return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoded_features = []\n\nclass CustomMultiLabelBinarizer(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        self.mlb_enc = None\n    \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X):\n        try:\n            X['features'] = X['features'].apply(lambda x: ['no_feature', ] if len(x)==0 else self.get_features(x))\n            if self.mlb_enc==None:\n                self.mlb_enc = MultiLabelBinarizer()\n                X_enc = pd.DataFrame(self.mlb_enc.fit_transform(X['features']), columns=self.mlb_enc.classes_, \n                                     index=X.index)\n                encoded_features.append(self.mlb_enc.classes_)\n            else:\n                X_enc = pd.DataFrame(self.mlb_enc.transform(X['features']), columns=self.mlb_enc.classes_, \n                                     index=X.index)\n            X = pd.concat([X, X_enc], axis=1)\n            X = X.drop('features', axis=1)\n        except Exception as e:\n            print(\"CustomMultiLabelBinarizer: Exception caught for {}: {}\".format(e))\n        return X\n    \n    @staticmethod\n    def get_features(x):\n        if len(x)==0:\n            return ['no_feature', ]\n        \n        features = [feature for feature in x if feature in top_25_features]\n        if len(features)==0:\n            features.append('other')\n        return features\n                ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pre_process = ColumnTransformer([('drop_cols', 'drop', ['street_address', 'listing_id']),\n                                 ('num_imputer', SimpleImputer(strategy='median'), ['bathrooms', 'bedrooms', 'price', 'latitude', 'longitude']),\n                                 ('custom_date_attr', CustomDateAttrs(), ['created', ]),\n                                 ('custom_num_attrs', CustomNumAttrs(), ['description', 'photos']),\n                                 ('list_encoder', CustomMultiLabelBinarizer(), ['features', ]),\n                                 ('cat_imputer', SimpleImputer(strategy='most_frequent'), cat_attrs)], remainder='passthrough')\n\nX_train_transformed = pre_process.fit_transform(X_train)\nX_test_transformed = pre_process.transform(X_test)\nX_train_transformed.shape, X_test_transformed.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_columns = ['bathrooms', 'bedrooms', 'price', 'latitude', 'longitude'] + ['created_month', 'created_day', ] + ['description', 'photos'] + list(encoded_features[0]) + cat_attrs\nprint(len(feature_columns), feature_columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_transformed = pd.DataFrame(X_train_transformed, columns=feature_columns)\nX_test_transformed = pd.DataFrame(X_test_transformed, columns=feature_columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_transformed.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 4: Modelling"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV, KFold, cross_val_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kf = KFold(n_splits=5, shuffle=True, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def performance_measures(model, store_results=True):\n    train_log_loss = cross_val_score(model, X_train_transformed, y_train, scoring='neg_log_loss', cv=kf, n_jobs=-1)\n    train_log_loss *= -1\n    test_log_loss = cross_val_score(model, X_test_transformed, y_test, scoring='neg_log_loss', cv=kf, n_jobs=-1)\n    test_log_loss *= -1\n    print(\"Mean Train Log Loss: {}\\nMean Test Log Loss: {}\".format(train_log_loss.mean(), test_log_loss.mean()))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_feature_importance(feature_columns, importance_values, top_n_features=0):\n    feature_imp = [ col for col in zip(feature_columns, importance_values)]\n    feature_imp.sort(key=lambda x:x[1], reverse=True)\n    \n    if top_n_features:\n        imp = pd.DataFrame(feature_imp[0:top_n_features], columns=['feature', 'importance'])\n    else:\n        imp = pd.DataFrame(feature_imp, columns=['feature', 'importance'])\n    plt.figure(figsize=(10, 8))\n    sns.barplot(y='feature', x='importance', data=imp, orient='h')\n    plt.title('Most Important Features', fontsize=16)\n    plt.ylabel(\"Feature\", fontsize=16)\n    plt.xlabel(\"\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from catboost import CatBoostClassifier\n\n\ncatboost_grid_params = [{'iterations':[1000, 1500, 2000], 'depth':[5, 6, 7, 8, 9]}] \n\ncatboost_clf = CatBoostClassifier(task_type=\"GPU\", loss_function='MultiClass', \n                                  cat_features=[36, 37, 38], random_state=42, verbose=0)\n\ngrid_search_results = catboost_clf.grid_search(catboost_grid_params, \n                                               X_train_transformed, y_train,\n                                               cv=5, partition_random_seed=42, \n                                               calc_cv_statistics=True,\n                                               search_by_train_test_split=True, refit=True, \n                                               shuffle=True,stratified=None, train_size=0.8, \n                                               verbose=0, plot=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_search_results['params']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"catboost_clf.is_fitted()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature_importance(feature_columns, catboost_clf.feature_importances_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"performance_measures(catboost_clf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 5: Prediction Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_trasformed = pre_process.transform(X)\npredicted_interest = catboost_clf.predict(X_trasformed)\ndata['predicted_interest_level'] = predicted_interest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 5))\nplt.subplot(1, 2, 1)\nplot_histogram(data['interest_level'])\nplt.subplot(1, 2, 2)\nplot_histogram(data['predicted_interest_level'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 6))\nplt.subplot(1, 2, 1)\nsns.scatterplot(x='longitude', y='latitude', hue='interest_level', data=data)\nplt.xlim(-74.1, -73.7)\nplt.ylim(40.55, 40.95)\nplt.subplot(1, 2, 2)\nsns.scatterplot(x='longitude', y='latitude', hue='predicted_interest_level', data=data)\nplt.xlim(-74.1, -73.7)\nplt.ylim(40.55, 40.95)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 6: Make submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"final_model = Pipeline([('pre_process', pre_process),\n                        ('catboost_clf', catboost_clf)])\nfinal_model.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import zipfile  \n\ntest_data = None  \nwith zipfile.ZipFile(\"../input/two-sigma-connect-rental-listing-inquiries/test.json.zip\", \"r\") as z:\n    for filename in z.namelist(): \n        with z.open(filename) as f:\n            test_data = pd.read_json(f.read())\n            \ntest_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = final_model.predict_proba(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output = pd.DataFrame(test_data['listing_id'])\noutput[[\"high\", \"medium\", \"low\"]] = predictions.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output.to_csv(\"./submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}