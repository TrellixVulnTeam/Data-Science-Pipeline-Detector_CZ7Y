{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport itertools\nimport matplotlib.pyplot as plt\nimport string\nimport re\nimport collections\nfrom sklearn import preprocessing\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:32:30.26297Z","iopub.execute_input":"2022-01-19T19:32:30.264006Z","iopub.status.idle":"2022-01-19T19:32:31.241486Z","shell.execute_reply.started":"2022-01-19T19:32:30.26386Z","shell.execute_reply":"2022-01-19T19:32:31.240791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install keras","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:32:31.243286Z","iopub.execute_input":"2022-01-19T19:32:31.243569Z","iopub.status.idle":"2022-01-19T19:32:39.934662Z","shell.execute_reply.started":"2022-01-19T19:32:31.243535Z","shell.execute_reply":"2022-01-19T19:32:39.933861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# READ DATA \ntrain_df = pd.read_json('../input/two-sigma-connect-rental-listing-inquiries/train.json.zip')\ntest_df = pd.read_json('../input/two-sigma-connect-rental-listing-inquiries/test.json.zip')","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:32:39.938141Z","iopub.execute_input":"2022-01-19T19:32:39.938364Z","iopub.status.idle":"2022-01-19T19:32:45.525009Z","shell.execute_reply.started":"2022-01-19T19:32:39.938336Z","shell.execute_reply":"2022-01-19T19:32:45.524228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TRAIN DATA FEATURE ENGINEERING","metadata":{}},{"cell_type":"code","source":"# convert TARGET to the numeric\ntrain_df['interest_level'] = train_df['interest_level'].apply(lambda x: 0 if x=='low' \n                                                      else 1 if x=='medium' \n                                                      else 2) \n# REMOVE UNNECESSARY WORDS FROM DESCRIPTION\ntrain_df['description'] = train_df['description'].apply(lambda x: x.replace(\"<br />\", \"\"))\ntrain_df['description'] = train_df['description'].apply(lambda x: x.replace(\"br\", \"\"))\ntrain_df['description'] = train_df['description'].apply(lambda x: x.replace(\"<p><a\", \"\"))\n\n#basic features\ntrain_df['rooms'] = train_df['bedrooms'] + train_df['bathrooms'] \n\n# count of photos #\ntrain_df[\"num_photos\"] = train_df[\"photos\"].apply(len)\n\n# count of \"features\" #\ntrain_df[\"num_features\"] = train_df[\"features\"].apply(len)\n\n# count of words present in description column #\ntrain_df[\"num_description_words\"] = train_df[\"description\"].apply(lambda x: len(x.split(\" \")))\n\n# description contains email\nregex = r'[\\w\\.-]+@[\\w\\.-]+'\ntrain_df['has_email'] = train_df['description'].apply(lambda x: 1 if re.findall(regex, x) else 0)\n\n# description contains phone\ntrain_df['has_phone'] = train_df['description'].apply(lambda x:re.sub('['+string.punctuation+']', '', x).split())\\\n        .apply(lambda x: [s for s in x if s.isdigit()])\\\n        .apply(lambda x: len([s for s in x if len(str(s))==10]))\\\n        .apply(lambda x: 1 if x>0 else 0)\n\n# CONVERT LOWER ALL OF WORDS\ntrain_df[[\"features\"]] = train_df[[\"features\"]].apply(\n    lambda _: [list(map(str.strip, map(str.lower, x))) for x in _])","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:32:45.526215Z","iopub.execute_input":"2022-01-19T19:32:45.526453Z","iopub.status.idle":"2022-01-19T19:32:51.56527Z","shell.execute_reply.started":"2022-01-19T19:32:45.526419Z","shell.execute_reply":"2022-01-19T19:32:51.564526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TEST DATA FEATURE ENGINEERING","metadata":{}},{"cell_type":"code","source":"# REMOVE UNNECESSARY WORDS FROM DESCRIPTION\ntest_df['description'] = test_df['description'].apply(lambda x: x.replace(\"<br />\", \"\"))\ntest_df['description'] = test_df['description'].apply(lambda x: x.replace(\"br\", \"\"))\ntest_df['description'] = test_df['description'].apply(lambda x: x.replace(\"<p><a\", \"\"))\n\n#basic features\ntest_df['rooms'] = test_df['bedrooms'] + test_df['bathrooms'] \n\n# count of photos #\ntest_df[\"num_photos\"] = test_df[\"photos\"].apply(len)\n\n# count of \"features\" #\ntest_df[\"num_features\"] = test_df[\"features\"].apply(len)\n\n# count of words present in description column #\ntest_df[\"num_description_words\"] = test_df[\"description\"].apply(lambda x: len(x.split(\" \")))\n\n# description contains email\nregex = r'[\\w\\.-]+@[\\w\\.-]+'\ntest_df['has_email'] = test_df['description'].apply(lambda x: 1 if re.findall(regex, x) else 0)\n\n# description contains phone\ntest_df['has_phone'] = test_df['description'].apply(lambda x:re.sub('['+string.punctuation+']', '', x).split())\\\n        .apply(lambda x: [s for s in x if s.isdigit()])\\\n        .apply(lambda x: len([s for s in x if len(str(s))==10]))\\\n        .apply(lambda x: 1 if x>0 else 0)\n\n# CONVERT LOWER ALL OF WORDS\ntest_df[[\"features\"]] = test_df[[\"features\"]].apply(\n    lambda _: [list(map(str.strip, map(str.lower, x))) for x in _])","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:32:51.567651Z","iopub.execute_input":"2022-01-19T19:32:51.567911Z","iopub.status.idle":"2022-01-19T19:33:00.364893Z","shell.execute_reply.started":"2022-01-19T19:32:51.567875Z","shell.execute_reply":"2022-01-19T19:33:00.364082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MOST FREQUENT FEATURES EXTRACTION","metadata":{}},{"cell_type":"code","source":"feature_value_train = train_df['features'].tolist()\nfeature_value_test = test_df['features'].tolist()\n\nfeature_value_train\nfeature_value_test\n\nfeature_lst_train = []\nfeature_lst_test = []\n\nfor i in range(len(feature_value_train)):\n    feature_lst_train += feature_value_train[i]\n    \nfor i in range(len(feature_value_test)):\n    feature_lst_test += feature_value_test[i]\n\nuniq_feature_train = list(set(feature_lst_train))\nuniq_feature_test = list(set(feature_lst_test))\n\n\n# see the frequency of each feature\ndef most_common(lst):\n    features = collections.Counter(lst)\n    feature_value = features.keys()\n    frequency = features.values()\n    data = [('feature_value', feature_value),\n            ('frequency', frequency),]    \n    df = pd.DataFrame.from_dict(dict(data))\n    return df.sort_values(by = 'frequency', ascending = False)\n\ndf_features_train = most_common(feature_lst_train)\ndf_features_test = most_common(feature_lst_test)\n\n\ndef newColumn(name, df, series):\n    feature = pd.Series(0,df.index,name = name)# data : 0\n    for row,word in enumerate(series):\n        if name in word:\n            feature.iloc[row] = 1\n    df[name] = feature # feature : series ; value in series : 1 or 0\n    return df\n\n# select features based on frequency\nfacilities = ['elevator', 'cats allowed', 'hardwood floors', 'dogs allowed', 'doorman', 'dishwasher', 'no fee', 'laundry in building', 'fitness center']\nfor name in facilities:\n    train_df = newColumn(name, train_df, train_df['features'])\n    test_df = newColumn(name, test_df, test_df['features'])","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:33:00.36607Z","iopub.execute_input":"2022-01-19T19:33:00.366337Z","iopub.status.idle":"2022-01-19T19:33:20.628477Z","shell.execute_reply.started":"2022-01-19T19:33:00.366299Z","shell.execute_reply":"2022-01-19T19:33:20.627733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LABEL ECONDING FOR CATEGORICAL VARIABLES","metadata":{}},{"cell_type":"code","source":"categorical = [\"display_address\", \"manager_id\", \"building_id\", \"street_address\"]\nfor f in categorical:\n        if train_df[f].dtype=='object':\n            #print(f)\n            lbl = preprocessing.LabelEncoder()\n            lbl.fit(list(train_df[f].values) + list(test_df[f].values))\n            train_df[f] = lbl.transform(list(train_df[f].values))\n            test_df[f] = lbl.transform(list(test_df[f].values))","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:33:20.629759Z","iopub.execute_input":"2022-01-19T19:33:20.630046Z","iopub.status.idle":"2022-01-19T19:33:22.831661Z","shell.execute_reply.started":"2022-01-19T19:33:20.630012Z","shell.execute_reply":"2022-01-19T19:33:22.830932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### LOGARITHMIC EXPRESSION TO THE PRICE COLUMN","metadata":{}},{"cell_type":"code","source":"train_df['price'] = np.log10(train_df['price'])\ntest_df['price'] = np.log10(test_df['price'])","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:33:22.832975Z","iopub.execute_input":"2022-01-19T19:33:22.833238Z","iopub.status.idle":"2022-01-19T19:33:22.844538Z","shell.execute_reply.started":"2022-01-19T19:33:22.833204Z","shell.execute_reply":"2022-01-19T19:33:22.843723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DROP UNNECESSARY COLUMNS","metadata":{}},{"cell_type":"code","source":"# TRAINING DATASET\ntrain_df.drop('created', axis=1, inplace=True)\ntrain_df.drop('description', axis=1, inplace=True)\ntrain_df.drop('features', axis=1, inplace=True)\ntrain_df.drop('photos', axis=1, inplace=True)\n\n\n# TEST DATASET\ntest_df.drop('created', axis=1, inplace=True)\ntest_df.drop('description', axis=1, inplace=True)\ntest_df.drop('features', axis=1, inplace=True)\ntest_df.drop('photos', axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:33:22.84588Z","iopub.execute_input":"2022-01-19T19:33:22.846234Z","iopub.status.idle":"2022-01-19T19:33:22.954466Z","shell.execute_reply.started":"2022-01-19T19:33:22.846194Z","shell.execute_reply":"2022-01-19T19:33:22.953678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# REGRESSION FOR PRICE","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import make_scorer, mean_absolute_error, mean_squared_error\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nimport xgboost as xgb\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.svm import SVR\nimport optuna\nimport math\n\nX = train_df.drop(['price'], axis = 1)\ny = train_df.price\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size = .3,\n                                                    random_state = 5)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:33:22.955803Z","iopub.execute_input":"2022-01-19T19:33:22.956335Z","iopub.status.idle":"2022-01-19T19:33:23.783974Z","shell.execute_reply.started":"2022-01-19T19:33:22.95629Z","shell.execute_reply":"2022-01-19T19:33:23.783228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Optimizer:\n    def __init__(self, metric, trials=30):\n        self.metric = metric\n        self.trials = trials\n        \n    def objective(self, trial):\n        model = create_model(trial)\n        model.fit(X, y)\n        preds = model.predict(X_test)\n        return mean_absolute_error(y_test, preds)\n            \n    def optimize(self):\n        study = optuna.create_study(direction=\"minimize\")\n        study.optimize(self.objective, n_trials=self.trials)\n        return study","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:33:23.785352Z","iopub.execute_input":"2022-01-19T19:33:23.785601Z","iopub.status.idle":"2022-01-19T19:33:23.792568Z","shell.execute_reply.started":"2022-01-19T19:33:23.785565Z","shell.execute_reply":"2022-01-19T19:33:23.791849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- XGB REGRESSOR OPTUNA PREDICTION","metadata":{}},{"cell_type":"code","source":"def create_model(trial):\n    params = {\n         'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n         'booster':trial.suggest_categorical('booster', ['gbtree', 'dart', 'gblinear']),\n         'learning_rate':trial.suggest_loguniform(\"learning_rate\", 0.001, 0.1),\n         'max_depth':trial.suggest_int(\"max_depth\", 3, 19),\n         'subsample':trial.suggest_uniform(\"subsample\", 0.0, 1.0),\n         'colsample_bytree':trial.suggest_uniform(\"colsample_bytree\", 0.0, 1.0),\n    }\n    model = xgb.XGBRegressor(**params)\n    return model\n\noptimizer = Optimizer('mae')\nxgb_opt_study = optimizer.optimize()\nxgb_opt_params = xgb_opt_study.best_params\nxgb_opt = xgb.XGBRegressor(**xgb_opt_params)   # Model\nxgb_opt.fit(X, y)\npreds = xgb_opt.predict(X_test)\n\nprint(\"Number of finished trials: \", len(xgb_opt_study.trials))\nprint(\"Best trial:\")\nxgb_trial = xgb_opt_study.best_trial\n\nprint(\"  Value: {}\".format(xgb_trial.value))\nprint(\"  Params: \")\nfor key, value in xgb_trial.params.items():\n    print(\"    {}: {}\".format(key, value))","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:33:23.793895Z","iopub.execute_input":"2022-01-19T19:33:23.794352Z","iopub.status.idle":"2022-01-19T19:40:33.583205Z","shell.execute_reply.started":"2022-01-19T19:33:23.794299Z","shell.execute_reply":"2022-01-19T19:40:33.582644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- RANDOM FOREST OPTUNA PREDICTION","metadata":{}},{"cell_type":"code","source":"def create_model(trial):\n    params = {\n        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n        'max_depth': trial.suggest_int('max_depth',3 ,19),\n        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n        'max_features': trial.suggest_categorical(\"max_features\", [\"auto\", \"sqrt\", \"log2\"])\n    }\n    model = RandomForestRegressor(**params)\n    return model\n\noptimizer = Optimizer('mae')\nrf_opt_study = optimizer.optimize()\nrf_opt_params = rf_opt_study.best_params\nrf_opt = RandomForestRegressor(**rf_opt_params)\nrf_opt.fit(X, y)\npreds = rf_opt.predict(X_test)\n\nprint(\"Number of finished trials: \", len(rf_opt_study.trials))\nprint(\"Best trial:\")\nrf_trial = rf_opt_study.best_trial\n\nprint(\"  Value: {}\".format(rf_trial.value))\nprint(\"  Params: \")\nfor key, value in rf_trial.params.items():\n    print(\"    {}: {}\".format(key, value))","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:40:33.586337Z","iopub.execute_input":"2022-01-19T19:40:33.587127Z","iopub.status.idle":"2022-01-19T19:55:08.662266Z","shell.execute_reply.started":"2022-01-19T19:40:33.587089Z","shell.execute_reply":"2022-01-19T19:55:08.660589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- LINEAR REGRESSION OPTUNA PREDICTION","metadata":{}},{"cell_type":"code","source":"def create_model(trial):\n    params = {\n        'copy_X': trial.suggest_categorical(\"copy_X\", [\"True\", \"False\"]),\n        'fit_intercept': trial.suggest_categorical(\"fit_intercept\", [\"True\", \"False\"]),\n        'n_jobs': trial.suggest_int('n_jobs',-1 ,3),\n    }\n    model = LinearRegression(**params)\n    return model\n\noptimizer = Optimizer('mae')\nlr_opt_study = optimizer.optimize()\nlr_opt_params = lr_opt_study.best_params\nlr_opt = LinearRegression(**lr_opt_params)\nlr_opt.fit(X, y)\npreds = lr_opt.predict(X_test)\n\nprint(\"Number of finished trials: \", len(lr_opt_study.trials))\nprint(\"Best trial:\")\nlr_trial = lr_opt_study.best_trial\n\nprint(\"  Value: {}\".format(lr_trial.value))\nprint(\"  Params: \")\nfor key, value in lr_trial.params.items():\n    print(\"    {}: {}\".format(key, value))","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:55:08.665711Z","iopub.execute_input":"2022-01-19T19:55:08.665917Z","iopub.status.idle":"2022-01-19T19:55:10.357757Z","shell.execute_reply.started":"2022-01-19T19:55:08.66589Z","shell.execute_reply":"2022-01-19T19:55:10.356929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let me show description of price","metadata":{}},{"cell_type":"code","source":"train_df['price'].describe()","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:55:10.362802Z","iopub.execute_input":"2022-01-19T19:55:10.365297Z","iopub.status.idle":"2022-01-19T19:55:10.388024Z","shell.execute_reply.started":"2022-01-19T19:55:10.365246Z","shell.execute_reply":"2022-01-19T19:55:10.387272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Pipeline for storing models","metadata":{}},{"cell_type":"code","source":"pipeline_models = []\n\nxgb_default = xgb.XGBRegressor()\nrf_default = RandomForestRegressor()\nlr_default = LinearRegression()\nsvm_default = SVR()\n\nmodels = [xgb_default, xgb_opt,\n          rf_default, rf_opt,\n          lr_default, lr_opt,\n          svm_default]\n\nmodel_names = ['XGB Regression (default)', 'XGB Regression (opt)', \n               'Random Forest (default)', 'Random Forest (opt)',\n               'Linear Regression (default)', 'Linear Regression (opt)',\n               'Support Vector Machine (default)']\n\n## Assign each model to a pipeline\nfor name, model in zip(model_names,models):\n    pipeline = (\"Scaled_\"+ name,\n                Pipeline([(\"Scaler\",StandardScaler()),\n                          (name,model)\n                         ]))\n    pipeline_models.append(pipeline)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:55:10.392572Z","iopub.execute_input":"2022-01-19T19:55:10.394953Z","iopub.status.idle":"2022-01-19T19:55:10.406097Z","shell.execute_reply.started":"2022-01-19T19:55:10.394906Z","shell.execute_reply":"2022-01-19T19:55:10.405384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Evaluate scores","metadata":{}},{"cell_type":"markdown","source":"* BEFORE PREDICTION INVERSE LOG10","metadata":{}},{"cell_type":"code","source":"train_df['price'] = 10 ** train_df['price']\ntest_df['price'] = 10 ** test_df['price']","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:55:10.410722Z","iopub.execute_input":"2022-01-19T19:55:10.413127Z","iopub.status.idle":"2022-01-19T19:55:10.425532Z","shell.execute_reply.started":"2022-01-19T19:55:10.413082Z","shell.execute_reply":"2022-01-19T19:55:10.424668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['price']","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:55:10.429664Z","iopub.execute_input":"2022-01-19T19:55:10.432043Z","iopub.status.idle":"2022-01-19T19:55:10.443863Z","shell.execute_reply.started":"2022-01-19T19:55:10.431973Z","shell.execute_reply":"2022-01-19T19:55:10.442972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score, cross_validate\n\n## Create a dataframe to store all the models' cross validation score\nevaluate = pd.DataFrame(columns=[\"model\",\"cv_MAE\", \"cv_RMSE\"])\nkfold = KFold(n_splits=5, shuffle=True, random_state=42)\n\n## Encoded dataset\nfor name,model in pipeline_models:\n    scores = cross_validate(model, X, y, cv=kfold, n_jobs=-1,\n                         scoring=('neg_root_mean_squared_error', 'neg_mean_absolute_error'))\n    \n    row = evaluate.shape[0]\n    evaluate.loc[row,\"model\"] = name\n    evaluate.loc[row,\"cv_MAE\"] = round(abs(scores['test_neg_mean_absolute_error']).mean(), 3)\n    evaluate.loc[row,\"cv_RMSE\"] = round(abs(scores['test_neg_root_mean_squared_error']).mean(), 3)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T19:55:10.445493Z","iopub.execute_input":"2022-01-19T19:55:10.446224Z","iopub.status.idle":"2022-01-19T20:14:33.185882Z","shell.execute_reply.started":"2022-01-19T19:55:10.446135Z","shell.execute_reply":"2022-01-19T20:14:33.185032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate","metadata":{"execution":{"iopub.status.busy":"2022-01-19T20:14:33.187976Z","iopub.execute_input":"2022-01-19T20:14:33.188482Z","iopub.status.idle":"2022-01-19T20:14:33.2035Z","shell.execute_reply.started":"2022-01-19T20:14:33.188443Z","shell.execute_reply":"2022-01-19T20:14:33.202809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- MAE score visualization","metadata":{}},{"cell_type":"code","source":"## Visualization\nfig, ax = plt.subplots(figsize=(16,9))\n\n## Encoded dataset\nbar = sns.barplot(evaluate[\"model\"], evaluate[\"cv_MAE\"])\nfor rec in bar.patches:\n    height = rec.get_height()\n    ax.text(rec.get_x() + rec.get_width()/2, height*1.02,height,ha=\"center\")\nax.set_title(\"Cross Validate Score (MAE)\")\nax.set_xticklabels(evaluate[\"model\"].to_list(),rotation =50)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T20:14:33.204631Z","iopub.execute_input":"2022-01-19T20:14:33.204938Z","iopub.status.idle":"2022-01-19T20:14:33.522879Z","shell.execute_reply.started":"2022-01-19T20:14:33.204904Z","shell.execute_reply":"2022-01-19T20:14:33.522211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- RMSE score visualization","metadata":{}},{"cell_type":"code","source":"## Visualization\nfig, ax = plt.subplots(figsize=(16,9))\n\n## Encoded dataset\nbar = sns.barplot(evaluate[\"model\"], evaluate[\"cv_RMSE\"])\nfor rec in bar.patches:\n    height = rec.get_height()\n    ax.text(rec.get_x() + rec.get_width()/2, height*1.02,height,ha=\"center\")\nax.set_title(\"Cross Validate Score (RMSE)\")\nax.set_xticklabels(evaluate[\"model\"].to_list(),rotation =50)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T20:14:33.52413Z","iopub.execute_input":"2022-01-19T20:14:33.52451Z","iopub.status.idle":"2022-01-19T20:14:33.818338Z","shell.execute_reply.started":"2022-01-19T20:14:33.52447Z","shell.execute_reply":"2022-01-19T20:14:33.817605Z"},"trusted":true},"execution_count":null,"outputs":[]}]}