{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"a4c706bd-29a9-e825-3118-8cd929a15d25"},"source":"text classification try"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3283e47d-734a-89c0-3455-ab71156ab41c"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd\n\n# data processing, CSV file I/O (e.g. pd.read_csv)\nimport numpy as np\nimport pandas as pd\nimport re\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics.pairwise import euclidean_distances\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"83a9e7d1-e5eb-ac9b-af44-4790df410c3f"},"outputs":[],"source":"data_rent= pd.read_json(\"../input/train.json\")\ndata_rent.head()\nprint(data_rent.groupby('interest_level').size())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8eeaa392-2a2e-063f-4b19-9b5f5a43d11d"},"outputs":[],"source":"data_rent['features']=data_rent['features'].apply(lambda x: ', '.join(x))\nimport nltk\nfrom nltk.tag import pos_tag\nfrom nltk import word_tokenize\nfrom nltk.corpus import stopwords\nstop = stopwords.words('english')\ndef cleaning_text(sentence):\n   sentence=sentence.lower()\n   sentence=re.sub('[^\\w\\s]',' ', sentence) #removes punctuations\n   sentence=re.sub('\\d+',' ', sentence) #removes digits\n   cleaned=' '.join([w for w in sentence.split() if not w in stop]) # removes english stopwords\n   cleaned=' '.join([w for w , pos in pos_tag(cleaned.split()) if (pos == 'NN' or pos=='JJ' or pos=='JJR' or pos=='JJS' )])\n   #selecting only nouns and adjectives\n   cleaned=' '.join([w for w in cleaned.split() if not len(w)<=2 ]) #removes single lettered words and digits\n   cleaned=cleaned.strip()\n   return cleaned\n\t  \ndata_rent['cleaned']= data_rent['description'].apply(lambda x: cleaning_text(x))\ndata_rent['feat_cleaned']= data_rent['features'].apply(lambda x: cleaning_text(x))\ndata_rent[\"final_feat\"] = data_rent[\"cleaned\"].map(str) +\" \"+data_rent[\"feat_cleaned\"]\ndata_rent.head(2)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0cff6b7c-999b-4cf4-9ecb-0a68ce04fc59"},"outputs":[],"source":"from sklearn.feature_extraction import DictVectorizer as DV\nvectorizer = DV( sparse = False )\ndata_rent_1 = vectorizer.fit_transform(data_rent)\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"43ef4066-11fa-664f-452b-2049ae401fd2"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nfrom scipy import stats, integrate\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(color_codes=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"07c890ae-df4f-55e5-5fdf-51502b91561d"},"outputs":[],"source":"sns.distplot(data_rent['bedrooms'],kde=False)\nsns.distplot(data_rent['bathrooms'],kde=False)\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bd8c54d0-d635-9dd5-756b-e8cc8bb68946"},"outputs":[],"source":"data_high=data_rent.loc[(data_rent['interest_level']=='high')]\ndata_medium=data_rent.loc[(data_rent['interest_level']=='medium')]\ndata_low=data_rent.loc[(data_rent['interest_level']=='low')]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"888b4e13-0ef8-94c5-21fc-567ef05fd2ef"},"outputs":[],"source":"data_high['cleaned'].apply(lambda x: pd.value_counts(x.split(\" \"))).sum(axis = 0)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"212bc99d-2326-3488-c9ae-cc256f15127e"},"outputs":[],"source":"from sklearn.model_selection import train_test_split\ntrain, test = train_test_split(data_rent, test_size = 0.2)\nprint(len(train))\nprint(len(test))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b3984c63-36c7-049b-7d73-d32ddb6f9664"},"outputs":[],"source":"binVectorizer = CountVectorizer(binary=True)\ncounts = binVectorizer.fit_transform(train['cleaned'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3f64ca1c-308d-9138-7cb8-ded4dc5e68be"},"outputs":[],"source":"from sklearn.naive_bayes import MultinomialNB\nclassifier = MultinomialNB()\ntargets = train['interest_level'].values\nclassifier.fit(counts, targets)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"358ecb4a-b321-503c-ff08-71e88b63969f"},"outputs":[],"source":"examples = test['cleaned']\nexample_counts = binVectorizer.transform(examples)\npredictions = classifier.predict(example_counts)\npredictions_df=pd.DataFrame(predictions)\npredictions_df.head(10)\nactual=test['interest_level'].values\nfrom sklearn.metrics import confusion_matrix\nmatrix=pd.DataFrame(confusion_matrix(actual, predictions,labels=[\"low\", \"medium\", \"high\"]))\nprint(matrix)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3ea96ac3-a982-c317-95ba-dd19e06d6e1f"},"outputs":[],"source":"pd.crosstab(test['interest_level'], predictions, rownames=['True'], colnames=['Predicted'], margins=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8b60c0ff-df81-ada0-c154-6c97a49a7a55"},"outputs":[],"source":"from sklearn.pipeline import Pipeline\n\npipeline = Pipeline([\n    ('vectorizer',  CountVectorizer()),\n    ('classifier',  MultinomialNB()) ])\n\n "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c5617410-1ebf-3a1b-1ec1-d1351db7fa27"},"outputs":[],"source":"pipeline.fit(train['cleaned'].values, train['interest_level'].values)\npredicts=pipeline.predict(test['cleaned'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"56986412-5aae-1923-d656-0590a4184eae"},"outputs":[],"source":"data_test= pd.read_json(\"../input/test.json\")\ndata_test.head()"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}