{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-15T01:45:01.253663Z","iopub.execute_input":"2021-06-15T01:45:01.254272Z","iopub.status.idle":"2021-06-15T01:45:01.263738Z","shell.execute_reply.started":"2021-06-15T01:45:01.254113Z","shell.execute_reply":"2021-06-15T01:45:01.26198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_json('/kaggle/input/two-sigma-connect-rental-listing-inquiries/train.json.zip')\ntrain_df['description'].head()","metadata":{"execution":{"iopub.status.busy":"2021-06-15T01:45:51.027707Z","iopub.execute_input":"2021-06-15T01:45:51.028044Z","iopub.status.idle":"2021-06-15T01:45:52.466971Z","shell.execute_reply.started":"2021-06-15T01:45:51.028014Z","shell.execute_reply":"2021-06-15T01:45:52.46585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom scipy import sparse\n\nclass MyCountVectorizer(CountVectorizer):\n    def __init__(self, dtype=np.float64, batch_size=None, **kwargs):\n        super().__init__(**kwargs)\n        self.dtype = dtype\n        self.batch_size = batch_size\n    \n    # Rewrite transform method\n    def fit(self, X, y=None):\n        super().fit(X, y)\n        return self\n    def transform(self, X):\n        # If batch_size is set then transform data in batch\n        if self.batch_size:\n            n_samples = X.shape[0]\n            if isinstance(X, pd.DataFrame)|isinstance(X, pd.Series):\n                res = []\n                for i in range(0, n_samples, self.batch_size):\n                    print(f\"Processsing row {i} to {min(i+self.batch_size, n_samples)}\")\n                    res.append(super().transform(X.iloc[i:min(i+self.batch_size, n_samples) ]).astype(self.dtype))\n                return sparse.vstack(res)\n\n            else:\n                return sparse.vstack([super().transform(X[i:min(i+self.batch_size, n_samples) ]).astype(self.dtype)  \n                        for i in range(0, n_samples, self.batch_size)])\n        else:\n            return super().transform(X).astype(self.dtype)","metadata":{"execution":{"iopub.status.busy":"2021-06-15T02:16:19.105897Z","iopub.execute_input":"2021-06-15T02:16:19.106263Z","iopub.status.idle":"2021-06-15T02:16:19.115464Z","shell.execute_reply.started":"2021-06-15T02:16:19.106232Z","shell.execute_reply":"2021-06-15T02:16:19.114473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Without batch size. Work as expected: using parent's fit and transform\nxf = MyCountVectorizer()\nxf.fit(train_df['description'])\nX0 = xf.transform(train_df['description'])\nX0.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-15T02:16:19.572865Z","iopub.execute_input":"2021-06-15T02:16:19.573422Z","iopub.status.idle":"2021-06-15T02:16:26.263275Z","shell.execute_reply.started":"2021-06-15T02:16:19.573389Z","shell.execute_reply":"2021-06-15T02:16:26.2623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# With batch size, fit and transform data in seperate steps.\n# Work as expected: modeified transform was used\nxf = MyCountVectorizer(batch_size=1000)\nxf.fit(train_df['description'])\nX1 = xf.transform(train_df['description'])\nX1.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-15T02:16:26.26534Z","iopub.execute_input":"2021-06-15T02:16:26.26573Z","iopub.status.idle":"2021-06-15T02:16:33.138161Z","shell.execute_reply.started":"2021-06-15T02:16:26.26569Z","shell.execute_reply":"2021-06-15T02:16:33.137095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"assert X1.sum()==X0.sum(),  \"Unmatched results\"","metadata":{"execution":{"iopub.status.busy":"2021-06-15T01:59:30.942333Z","iopub.execute_input":"2021-06-15T01:59:30.942667Z","iopub.status.idle":"2021-06-15T01:59:30.960062Z","shell.execute_reply.started":"2021-06-15T01:59:30.942609Z","shell.execute_reply":"2021-06-15T01:59:30.959246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# with batch size, fit_transform\n# As expected: since I didn't redefine fit_transform it would use parent's fit_transform which essentially performs the following\n# self.fit(X, y).transform() \n# https://github.com/scikit-learn/scikit-learn/blob/15a949460/sklearn/feature_extraction/text.py#L807\n# so what I thought was I would need to redefine fit_transform\nxf = MyCountVectorizer(batch_size=1000)\nX2 = xf.fit_transform(train_df['description'])\nX2.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-15T01:59:33.099832Z","iopub.execute_input":"2021-06-15T01:59:33.100185Z","iopub.status.idle":"2021-06-15T01:59:36.481468Z","shell.execute_reply.started":"2021-06-15T01:59:33.10014Z","shell.execute_reply":"2021-06-15T01:59:36.480483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom scipy import sparse\n\nclass MyCountVectorizer_1(CountVectorizer):\n    def __init__(self, dtype=np.float64, batch_size=None, **kwargs):\n        super().__init__(**kwargs)\n        self.dtype = dtype\n        self.batch_size = batch_size\n    \n    # Rewrite transform method\n    def fit(self, X, y=None):\n        super().fit(X, y)\n        return self\n    def transform(self, X):\n        # If batch_size is set then transform data in batch\n        if self.batch_size:\n            n_samples = X.shape[0]\n            if isinstance(X, pd.DataFrame)|isinstance(X, pd.Series):\n                res = []\n                for i in range(0, n_samples, self.batch_size):\n                    print(f\"Processsing row {i} to {min(i+self.batch_size, n_samples)}\")\n                    res.append(super().transform(X.iloc[i:min(i+self.batch_size, n_samples) ]).astype(self.dtype))\n                return sparse.vstack(res)\n\n            else:\n                return sparse.vstack([super().transform(X[i:min(i+self.batch_size, n_samples) ]).astype(self.dtype)  \n                        for i in range(0, n_samples, self.batch_size)])\n        else:\n            return super().transform(X).astype(self.dtype)\n    # Redefine fit_transform to use self.transform instead of super().transform\n    def fit_transform(X, y=None):\n        super().fit(X, y)\n        self.transform()","metadata":{"execution":{"iopub.status.busy":"2021-06-15T02:17:52.3265Z","iopub.execute_input":"2021-06-15T02:17:52.326914Z","iopub.status.idle":"2021-06-15T02:17:52.336776Z","shell.execute_reply.started":"2021-06-15T02:17:52.32688Z","shell.execute_reply":"2021-06-15T02:17:52.335828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# However it didn't seem to work\n# self.fit(X, y).transform()\nxf\nxf = MyCountVectorizer_1(batch_size=1000)\nX2 = xf.fit_transform(train_df['description'])\nX2.shape\n","metadata":{"execution":{"iopub.status.busy":"2021-06-15T02:19:49.493631Z","iopub.execute_input":"2021-06-15T02:19:49.494134Z","iopub.status.idle":"2021-06-15T02:19:54.798733Z","shell.execute_reply.started":"2021-06-15T02:19:49.494087Z","shell.execute_reply":"2021-06-15T02:19:54.797014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# And evern executing fit and transform in seperate steps didn't work\ndel xf\nxf = MyCountVectorizer_1(batch_size=1000)\nxf.fit(train_df['description'])\nX1 = xf.transform(train_df['description'])\nX1.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-15T02:19:59.488214Z","iopub.execute_input":"2021-06-15T02:19:59.488622Z","iopub.status.idle":"2021-06-15T02:20:04.981467Z","shell.execute_reply.started":"2021-06-15T02:19:59.488584Z","shell.execute_reply":"2021-06-15T02:20:04.980061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}