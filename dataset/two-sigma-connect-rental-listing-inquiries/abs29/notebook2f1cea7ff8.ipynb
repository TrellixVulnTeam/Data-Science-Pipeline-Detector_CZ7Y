{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ac85f1bd-1f8c-331d-f8c1-b9c0c1a6621d"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"796ddfa8-07b6-85a1-cba7-d6d543c21158"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold\nimport random\nfrom math import exp\nimport xgboost as xgb\nfrom nltk.stem import PorterStemmer\nimport re\n#import distance\n\nrandom.seed(321)\nnp.random.seed(321)\n\nX_train = pd.read_json(\"../input/train.json\")\nX_test = pd.read_json(\"../input/test.json\")\n\n\ninterest_level_map = {'low': 0, 'medium': 1, 'high': 2}\nX_train['interest_level'] = X_train['interest_level'].apply(lambda x: interest_level_map[x])\nX_test['interest_level'] = -1\n\n#remove outliers\nulimit = np.percentile(X_train.price.values, 99)\nX_train.ix[X_train['price']>ulimit,'price'] = ulimit"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5a113a79-70f9-201e-9636-18e57733be10"},"outputs":[],"source":"feature_transform = CountVectorizer(stop_words='english', max_features=150)\nX_train['features'] = X_train[\"features\"].apply(lambda x: \" \".join([\"_\".join(i.lower().split(\" \")) for i in x]))\nX_test['features'] = X_test[\"features\"].apply(lambda x: \" \".join([\"_\".join(i.lower().split(\" \")) for i in x]))\n#feature_transform.fit(list(X_train['features']) + list(X_test['features']))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4e7545d3-7e8e-7a38-3f69-4d41092c61e0"},"outputs":[],"source":"X_train.features.count()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"959af624-21d1-5706-3baf-c1e2fa8f7512"},"outputs":[],"source":"X_train['features'] = X_train['features'].apply(lambda x: ' '.join(['_'.join(i.split(' ')) for i in x]))\ntextcv = CountVectorizer(stop_words='english', max_features=200)\ntext_features = pd.DataFrame(textcv.fit_transform(X_train['features']).toarray(),\n                                 columns=['f_' + format(x, '03d') for x in range(1, 201)],\n                                 index=X_train.index)\nX_train = pd.concat(objs=(X_train, text_features), axis=1)\n#data_df.drop('features', axis=1, inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"577e704e-d7ba-17ab-7931-5f8bb4a9b16c"},"outputs":[],"source":"text_features.head()\nX_train.head()"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}