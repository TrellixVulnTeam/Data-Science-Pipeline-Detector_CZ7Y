{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6f738121-4bd4-0977-6b58-970ca69a8a63"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport scipy\n\nfrom sklearn.feature_extraction.text import HashingVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD\n\nfrom sklearn.naive_bayes import BernoulliNB, MultinomialNB\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import log_loss\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\n\ndf=pd.read_json(\"../input/train.json\")\ndf['priceperbed']=(df['price'].clip(upper=7000)/df['bedrooms'].clip(lower=1))\ndf['created']=df['created'].astype(np.datetime64)\ndf['created_day']=np.array(df.created.values, dtype='datetime64[D]').astype(np.float32)%7\ndf['created_week']=np.array(df.created.values, dtype='datetime64[W]').astype(np.float32)\ndf['created_hour']=np.array(df.created.values, dtype='datetime64[h]').astype(np.float32)%24\ndf['desc_count']=df.description.apply(lambda x: len(x.split())).clip(upper=150)\ndf['features_count']=df.features.apply(lambda x: len(x))\ndf['photos_count']=df.photos.apply(lambda x: len(x))\n\nlbl = preprocessing.LabelEncoder()\nlbl.fit(list(df['manager_id'].values))\ndf['manager_id'] = lbl.transform(list(df['manager_id'].values))\n\nfeature_list=['no fee', 'hardwood floors', 'laundry in building']\ndf['features']=df['features'].apply(lambda x: list(map(str.lower, x)))\nfor feature in feature_list:\n        df[feature]=df['features'].apply(lambda x: feature in x)\nvectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n                                 stop_words='english')\nvectorizer.fit(df.description.values)\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cccba8ab-9d7b-96bb-1872-8841233d1575"},"outputs":[],"source":"df_tv, df_test = train_test_split(df, random_state=0)\ndf_train, df_val = train_test_split(df_tv, random_state=0)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cc507f39-b701-dd3c-24e1-d5f45a9d298f"},"outputs":[],"source":"cols=['price', 'bathrooms', 'bedrooms', 'latitude', 'longitude', 'desc_count', 'priceperbed',\n      'photos_count', 'features_count', 'created_hour', 'no fee', 'hardwood floors', 'laundry in building']\n\nsvd = TruncatedSVD(n_components=5, n_iter=7, random_state=42)\nX_train = svd.fit_transform(vectorizer.transform(df_train.description))\nX_train=np.hstack([X_train, df_train[cols].values])\nX_val = svd.transform(vectorizer.transform(df_val.description))\nX_val=np.hstack([X_val, df_val[cols].values])\nX_test = svd.transform(vectorizer.transform(df_test.description))\nX_test=np.hstack([X_test, df_test[cols].values])\nclf=ExtraTreesClassifier(max_depth=23, n_estimators=1000,\n                             min_samples_split=10, random_state=0) \nclf.fit(X_train, df_train['interest_level'])\ny_pred=clf.predict_proba(X_train)\nscore=log_loss(df_train['interest_level'].values, y_pred)\ny_pred=clf.predict_proba(X_val)\nscore2=log_loss(df_val['interest_level'].values, y_pred)\ny_pred=clf.predict_proba(X_test)\nscore3=log_loss(df_test['interest_level'].values, y_pred)\nprint(\"%.6f %.6f %.6f\"%(score, score2, score3))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"969af18c-b6ae-df96-aaf1-4a61374d8ab6"},"outputs":[],"source":"cols=['price', 'bathrooms', 'bedrooms', 'latitude', 'longitude', 'desc_count', 'priceperbed',\n      'photos_count', 'features_count', 'manager_id', 'created_hour', 'no fee', 'hardwood floors', 'laundry in building']\n\nX_train = svd.transform(vectorizer.transform(df_train.description))\nX_train=np.hstack([X_train, df_train[cols].values])\nX_val = svd.transform(vectorizer.transform(df_val.description))\nX_val=np.hstack([X_val, df_val[cols].values])\nX_test = svd.transform(vectorizer.transform(df_test.description))\nX_test=np.hstack([X_test, df_test[cols].values])\nclf=ExtraTreesClassifier(max_depth=23, n_estimators=1000,\n                             min_samples_split=10, random_state=0) \nclf.fit(X_train, df_train['interest_level'])\ny_pred=clf.predict_proba(X_train)\nscore=log_loss(df_train['interest_level'].values, y_pred)\ny_pred=clf.predict_proba(X_val)\nscore2=log_loss(df_val['interest_level'].values, y_pred)\ny_pred=clf.predict_proba(X_test)\nscore3=log_loss(df_test['interest_level'].values, y_pred)\nprint(\"%.6f %.6f %.6f\"%(score, score2, score3))"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}