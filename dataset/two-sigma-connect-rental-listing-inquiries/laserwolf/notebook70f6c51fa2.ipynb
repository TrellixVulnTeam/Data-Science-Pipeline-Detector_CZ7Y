{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"db4e3b5a-6ba3-c346-7115-d9c97b281064"},"outputs":[],"source":"\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import log_loss\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\n\ndef scorer(estimator, X, y):\n    return -log_loss(y, estimator.predict_proba(X))\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\ndf=pd.read_json('../input/train.json')\ndf['priceperbed']=(df['price'].clip(upper=7000)/df['bedrooms'].clip(lower=1))\ndf['created']=df['created'].astype(np.datetime64)\ndf['created_day']=np.array(df.created.values, dtype='datetime64[D]').astype(np.float32)%7\ndf['created_week']=np.array(df.created.values, dtype='datetime64[W]').astype(np.float32)\ndf['created_hour']=np.array(df.created.values, dtype='datetime64[h]').astype(np.float32)%24\ndf['desc_count']=df.description.apply(lambda x: len(x.split())).clip(upper=150)\ndf['features_count']=df.features.apply(lambda x: len(x))\ndf['photos_count']=df.photos.apply(lambda x: len(x))\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9846ca6a-4d37-4dbd-7d52-1d791c1426ca"},"outputs":[],"source":"df['features']=df['features'].apply(lambda x: list(map(str.lower, x)))\ndf_features=pd.DataFrame(np.hstack(df.features.values), columns=['feature'])\ndf_feature_counts=pd.DataFrame(df_features.groupby(['feature']).size(), \n                               columns=['size']).reset_index()\ndf_feature_counts=df_feature_counts.sort_values('size', ascending=False)\nfeature_list=df_feature_counts.loc[df_feature_counts['size']>5000]['feature'].values\nfeature_list"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"179e3b03-ccf6-5a29-502e-7619d1db91fb"},"outputs":[],"source":"for feature in feature_list:\n        df[feature]=df['features'].apply(lambda x: feature in x)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"366e84ae-4887-e54a-88e1-6871206baa21"},"outputs":[],"source":"df_tv, df_test = train_test_split(df, random_state=0)\ndf_train, df_val = train_test_split(df_tv, random_state=0)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cacc9493-d310-85c6-b018-2edeb3f796ce"},"outputs":[],"source":"cols=['price', 'bathrooms', 'bedrooms', 'priceperbed', 'created_hour', 'desc_count', 'photos_count', 'features_count', \n      'elevator', 'hardwood floors', 'cats allowed', 'dogs allowed', 'doorman', 'dishwasher', \n      'laundry in building', 'no fee', 'fitness center', 'laundry in unit', 'pre-war', 'roof deck', \n      'outdoor space', 'dining room']"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"af3f9ed0-a6fd-e94e-8850-cfc9b0d212fe"},"outputs":[],"source":"cols=['price', 'bathrooms', 'bedrooms', 'priceperbed','created_hour',  'desc_count', 'photos_count',\n'features_count', 'no fee', 'hardwood floors', 'laundry in building']\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"23303d47-d933-2b4d-d957-9bb3e352ef47"},"outputs":[],"source":"    clf=ExtraTreesClassifier(max_depth=23, n_estimators=1000,\n                             min_samples_split=10, random_state=0) \n    clf.fit(df_train[cols].values, df_train['interest_level'])\n    y_pred=clf.predict_proba(df_train[cols])\n    score=log_loss(df_train['interest_level'].values, y_pred)\n    y_pred=clf.predict_proba(df_val[cols])\n    score2=log_loss(df_val['interest_level'].values, y_pred)\n    y_pred=clf.predict_proba(df_test[cols])\n    score3=log_loss(df_test['interest_level'].values, y_pred)\n    print(\"%.6f %.6f %.6f\"%(score, score2, score3))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7e633847-f48e-5084-e534-8388f4d378fd"},"outputs":[],"source":"    import xgboost as xgb\n    \n    param = {}\n    param['objective'] = 'multi:softprob'\n    #param['eta'] = 0.1\n    #param['max_depth'] = 23\n    param['num_class'] = 3\n    param['eval_metric'] = \"mlogloss\"\n    #param['min_child_weight'] = 10\n    #param['subsample'] = 0.7\n    #param['colsample_bytree'] = 0.7\n    param['seed'] = 0\n    plst = list(param.items())\n    target_num_map = {'high':0, 'low':1, 'medium':2}\n    train_y = np.array(df_train['interest_level'].apply(lambda x: target_num_map[x]))\n    xgtrain = xgb.DMatrix(df_train[cols].values, label=train_y)\n    model = xgb.train(plst, xgtrain, 100)\n    \n    xgtest = xgb.DMatrix(df_train[cols].values)\n    y_pred=model.predict(xgtest)\n    score=log_loss(df_train['interest_level'].values, y_pred)\n    xgtest = xgb.DMatrix(df_val[cols].values)\n    y_pred=model.predict(xgtest)\n    score2=log_loss(df_val['interest_level'].values, y_pred)\n    xgtest = xgb.DMatrix(df_test[cols].values)\n    y_pred=model.predict(xgtest)\n    score3=log_loss(df_test['interest_level'].values, y_pred)\n    print(\"%.6f %.6f %.6f\"%(score, score2, score3))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"45044a29-a3a6-14e0-a537-92e296ff98cc"},"outputs":[],"source":"import operator\nsorted(dict(zip(cols, clf.feature_importances_)).items(), key=operator.itemgetter(1))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f74658f5-f044-6019-7b70-0b9a5faa924f"},"outputs":[],"source":"feature_list"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b6b12ed0-74dc-d1f3-5f5e-f3345820706f"},"outputs":[],"source":"df['priceperbed']=(df['price'].clip(upper=7000)/df['bedrooms'].clip(lower=1))\ndf['created_month']=np.array(df.created.values, dtype='datetime64[M]').astype(np.float32)\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"deeedac5-84fe-86ad-8cb2-ba41edb28740"},"outputs":[],"source":"df['created_week'].max()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dd7392ad-b9ff-8d4a-21ef-18fc969cc903"},"outputs":[],"source":"df['laundry in unit']=(df['laundry in unit'])|(df['laundry in building'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5b137c40-b4a9-3d8d-7696-589c5f460a3a"},"outputs":[],"source":"df['laundry in unit'].sum()"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}