{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8a9d3f4c-6839-785a-131c-6da88d6617b3"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport scipy\n\nfrom sklearn.feature_extraction.text import HashingVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD\n\nfrom sklearn.naive_bayes import BernoulliNB, MultinomialNB\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import log_loss\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1166e7f7-545d-c548-1e14-999a4b028527"},"outputs":[],"source":"df=pd.read_json(\"../input/train.json\")\ndf['priceperbed']=(df['price'].clip(upper=7000)/df['bedrooms'].clip(lower=1))\ndf['created']=df['created'].astype(np.datetime64)\ndf['created_day']=np.array(df.created.values, dtype='datetime64[D]').astype(np.float32)%7\ndf['created_week']=np.array(df.created.values, dtype='datetime64[W]').astype(np.float32)\ndf['created_hour']=np.array(df.created.values, dtype='datetime64[h]').astype(np.float32)%24\ndf['desc_count']=df.description.apply(lambda x: len(x.split())).clip(upper=150)\ndf['features_count']=df.features.apply(lambda x: len(x))\ndf['photos_count']=df.photos.apply(lambda x: len(x))\n\nlbl = preprocessing.LabelEncoder()\nlbl.fit(list(df['manager_id'].values))\ndf['manager_id'] = lbl.transform(list(df['manager_id'].values))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9541def5-6392-7ad6-3f2c-6d3f5ac2d738"},"outputs":[],"source":"feature_list=['no fee', 'hardwood floors', 'laundry in building']\ndf['features']=df['features'].apply(lambda x: list(map(str.lower, x)))\nfor feature in feature_list:\n        df[feature]=df['features'].apply(lambda x: feature in x)\ncols=['price', 'bathrooms', 'bedrooms', 'latitude', 'longitude', 'manager_idpriceperbed','created_hour',  'desc_count', \n      'photos_count', 'features_count', 'no fee', 'hardwood floors', 'laundry in building']\n        "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b9dab898-2c41-ed82-b672-0549cd79a680"},"outputs":[],"source":"vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n                                 stop_words='english')\nvectorizer.fit(df.description.values)\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d6412daf-8744-46c9-1b67-18a1d5e4be35"},"outputs":[],"source":"df_tv, df_test = train_test_split(df, random_state=0)\ndf_train, df_val = train_test_split(df_tv, random_state=0)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2114c802-0833-3ec6-79ce-35a8c9946c57"},"outputs":[],"source":"svd = TruncatedSVD(n_components=5, n_iter=7, random_state=42)\nX_train = svd.fit_transform(vectorizer.transform(df_train.description))\n#X_train_dense=scipy.sparse.csr_matrix(df_train[cols].values, dtype=np.float64)\nX_train=np.hstack([X_train, df_train[cols].values])\nX_val = svd.transform(vectorizer.transform(df_val.description))\n#X_val_dense=scipy.sparse.csr_matrix(df_val[cols].values, dtype=np.float64)\nX_val=np.hstack([X_val, df_val[cols].values])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2523818e-25aa-bbea-cbe7-cab214d1c5ad"},"outputs":[],"source":"clf=ExtraTreesClassifier(max_depth=23, n_estimators=1000,\n                             min_samples_split=10, random_state=0) \nclf.fit(X_train, df_train['interest_level'])\ny_pred=clf.predict_proba(X_train)\nscore=log_loss(df_train['interest_level'].values, y_pred)\ny_pred=clf.predict_proba(X_val)\nscore2=log_loss(df_val['interest_level'].values, y_pred)\nprint(\"%.6f %.6f\"%(score, score2))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5c801f30-b84a-1605-075a-c8e8c5c6a70a"},"outputs":[],"source":"X_test = svd.transform(vectorizer.transform(df_test.description))\nX_test=np.hstack([X_test, df_test[cols].values])\ny_pred=clf.predict_proba(X_test)\nscore3=log_loss(df_test['interest_level'].values, y_pred)\nprint(\"%.6f\"%(score3))"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}