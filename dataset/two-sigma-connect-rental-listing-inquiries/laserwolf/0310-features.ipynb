{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"381725c2-ac49-6267-623e-667ebaf86853"},"outputs":[],"source":"\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import log_loss\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\n\ndef scorer(estimator, X, y):\n    return -log_loss(y, estimator.predict_proba(X))\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\ndf=pd.read_json('../input/train.json')\ndf['priceperbed']=(df['price'].clip(upper=7000)/df['bedrooms'].clip(lower=1))\ndf['created']=df['created'].astype(np.datetime64)\ndf['created_day']=np.array(df.created.values, dtype='datetime64[D]').astype(np.float32)%7\ndf['created_week']=np.array(df.created.values, dtype='datetime64[W]').astype(np.float32)\ndf['created_hour']=np.array(df.created.values, dtype='datetime64[h]').astype(np.float32)%24\ndf['desc_count']=df.description.apply(lambda x: len(x.split())).clip(upper=150)\ndf['features_count']=df.features.apply(lambda x: len(x))\ndf['photos_count']=df.photos.apply(lambda x: len(x))\n\ndf['features']=df['features'].apply(lambda x: list(map(str.lower, x)))\nfor feature in ['hardwood floors',  'laundry in building', 'cats_allowed']:\n    df[feature]=df['features'].apply(lambda x: feature in x)\n\ndf['medium']=df['interest_level']=='medium'\ndf['low']=df['interest_level']=='low'\ndf['high']=df['interest_level']=='high'"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2a73bba0-a48c-03d2-a3b4-e7b7bf062b72"},"outputs":[],"source":"x=[]\ny_train=[]\ny_val=[]\nfor i in range(100, df_train.shape[0], 3000):\n    x+=[i]\n    clf=ExtraTreesClassifier(max_depth=21, n_estimators=100, random_state=0)\n    clf.fit(df_train.iloc[:i][cols].values, df_train.iloc[:i]['interest_level'])\n    y_pred=clf.predict_proba(df_train.iloc[:i][cols])\n    score=log_loss(df_train.iloc[:i]['interest_level'].values, y_pred)\n    y_train+=[score]\n    y_pred=clf.predict_proba(df_test[cols])\n    score2=log_loss(df_test['interest_level'].values, y_pred)\n    y_val+=[score2]\n    print(\"%.6f %.6f\"%(score, score2))    "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5080f929-7f29-469f-194e-80daf935ce58"},"outputs":[],"source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import KFold\n\nkf = KFold(n_splits=4)\nscore_sum=0\nscore2_sum=0\nfor ktrain, ktest in kf.split(df_train):\n    clf=KNeighborsClassifier(n_neighbors=500)\n    clf.fit(df_train.iloc[ktrain][cols].values, df_train.iloc[ktrain]['interest_level'])\n    y_pred=clf.predict_proba(df_train.iloc[ktrain][cols])\n    score=log_loss(df_train.iloc[ktrain]['interest_level'].values, y_pred)\n    score_sum+=score\n    y_pred=clf.predict_proba(df_train.iloc[ktest][cols])\n    score2=log_loss(df_train.iloc[ktest]['interest_level'].values, y_pred)\n    score2_sum+=score2\n    print(\"%.6f %.6f\"%(score, score2))\nprint(\"means\")\nprint(\"%.6f %.6f\"%(score_sum/4, score2_sum/4))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c9763775-72a5-9ee7-da72-5dae8cbfce21"},"outputs":[],"source":"features_rows=(df.features.values)\nfeatures_rows=np.hstack(features_rows)\ndf_features=pd.DataFrame(features_rows, columns=['feature'])\ndf_feature_counts=pd.DataFrame(df_features.groupby(['feature']).size(), \n                               columns=['size']).reset_index()\ndf_feature_counts=df_feature_counts.sort_values('size', ascending=False)\nfeature_list=df_feature_counts.loc[df_feature_counts['size']>5000]['feature'].values\nfeature_list"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"36644352-4498-53fe-6a60-6bd9aeabee38"},"outputs":[],"source":"df_feature_counts[(df_feature_counts.feature.str.find(\"laundry\")!=-1)]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8fe696c0-0960-6e87-e955-37170529fb23"},"outputs":[],"source":"feature='dining room'\ndf[feature]=df['features'].apply(lambda x: feature in x)\nd={}\nfor j in ['high', 'medium', 'low']:\n    d[j]=[]\n    for i in [True, False]:\n        summa=(df[feature]==i).sum()\n        d[j]+=[((df[feature]==i)&(df.interest_level==j)).sum()/summa]\nplt.bar([0, 1], d['low'])\nplt.bar([0, 1], d['medium'], bottom=d['low'])\nplt.bar([0, 1], d['high'], bottom=np.sum([d['low'], d['medium']], axis=0))\nplt.show()        "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e5fb4e92-13a9-4eef-be7c-93b23be892b9"},"outputs":[],"source":"df['features']=df['features'].apply(lambda x: list(map(str.lower, x)))\ndf['cats_allowed']=df['features'].apply(lambda x: 'cats allowed' in x)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5e7268f8-bf56-2e9e-78d8-5f7d8a38e8f0"},"outputs":[],"source":"cols=['price', 'bathrooms', 'bedrooms', 'priceperbed', 'created_hour', \n          'desc_count', 'photos_count', 'features_count', 'hardwood floors',\n          'laundry in building', 'cats_allowed', 'created_day']\ndf_train, df_test = train_test_split(df, random_state=0)\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ad44aba1-2a92-9fe2-13af-953473c95156"},"outputs":[],"source":"kf = KFold(n_splits=4)\nscore_sum=0\nscore2_sum=0\nfor ktrain, ktest in kf.split(df_train):\n    clf=ExtraTreesClassifier(max_depth=13, n_estimators=100, min_samples_split=12, random_state=0)\n    clf.fit(df_train.iloc[ktrain][cols].values, df_train.iloc[ktrain]['interest_level'])\n    y_pred=clf.predict_proba(df_train.iloc[ktrain][cols])\n    score=log_loss(df_train.iloc[ktrain]['interest_level'].values, y_pred)\n    score_sum+=score\n    y_pred=clf.predict_proba(df_train.iloc[ktest][cols])\n    score2=log_loss(df_train.iloc[ktest]['interest_level'].values, y_pred)\n    score2_sum+=score2\n    print(\"%.6f %.6f\"%(score, score2))\nprint(\"means\")\nprint(\"%.6f %.6f\"%(score_sum/4, score2_sum/4))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2ad71288-47cf-39d1-55be-9ce163ce90db"},"outputs":[],"source":"    clf=ExtraTreesClassifier(max_depth=12, n_estimators=100, random_state=0)\n                            #min_samples_split=12, \n    clf.fit(df_train[cols].values, df_train['interest_level'])\n    y_pred=clf.predict_proba(df_train[cols])\n    score=log_loss(df_train['interest_level'].values, y_pred)\n    y_pred=clf.predict_proba(df_test[cols])\n    score2=log_loss(df_test['interest_level'].values, y_pred)\n    print(\"%.6f %.6f\"%(score, score2))"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}