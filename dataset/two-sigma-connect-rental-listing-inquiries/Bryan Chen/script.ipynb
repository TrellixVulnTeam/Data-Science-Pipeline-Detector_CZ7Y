{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e33d8dc9-2e0f-d586-574d-1e75f1bed159"},"outputs":[],"source":"%matplotlib inline\nimport pandas as pd\npd.options.display.max_columns = 100\nfrom matplotlib import pyplot as plt\nimport matplotlib\nmatplotlib.style.use('ggplot')\nimport numpy as np\npd.options.display.max_rows = 100\ndata = pd.read_json('../input/train.json')\nprint(\"\\nFirst 8\")\ndata.head(5)\ndef status(feature):\n\n    print ('Processing '+feature+': ok')\ndef get_combined_data():\n    # reading train data\n    train = pd.read_json('../input/train.json')\n    \n    # reading test data\n    test = pd.read_json('../input/test.json')\n\n    # extracting and then removing the targets from the training data \n    targets = train.interest_level\n    train.drop('interest_level',1,inplace=True)\n    \n\n    # merging train data and test data for future feature engineering\n    combined = train.append(test)\n    combined.reset_index(inplace=True)\n    combined.drop('index',inplace=True,axis=1)\n    \n    return combined\n\ncombined = get_combined_data()\ndef get_address():\n    global combined\n    \n    #extract street type from each address\n    combined['address_type'] = combined['street_address'].map(lambda type: \n                                                              type.split()[-1] if len(type)>1 else \"Other\")\n    \n    #map street types to general ones\n    street_dict = {\n        \"Street\": \"Street\",\n        \"St\": \"Street\",\n        \"St.\": \"Street\",\n        \"St..\": \"Street\",\n        \"St,\": \"Street\",\n        \"St...\": \"Street\",\n        \"Avenue\": \"Avenue\",\n        \"Ave\": \"Avenue\",\n        \"Ave.\": \"Avenue\",\n        \"Terrace\": \"Terrace\",\n    }\n    combined[\"address_type\"] = combined['address_type'].map(street_dict)\nget_address()\ncombined.head(50)\ndef process_streets():\n    \n    global combined\n    # we clean the street variable\n    combined.drop('street_address',axis=1,inplace=True)\n    combined.drop('display_address', axis=1, inplace=True)\n\n    # encoding in dummy variable\n    street_dummies = pd.get_dummies(combined['address_type'],prefix='address_type')\n    combined = pd.concat([combined,street_dummies],axis=1)\n    \n    # removing the title variable\n    combined.drop('address_type',axis=1,inplace=True)\n    \n    status('streets')\nprocess_streets()\ncombined.head(50)\ndef process_features():\n    global combined\n    \n    #replace with len\n    combined['features'] = combined['features'].map(lambda d: len(d))\nprocess_features()\ncombined.head()\ndef process_description():\n    global combined\n    \n    #replace\n    combined['description'] = combined['description'].map(lambda d: len(d.split()))\nprocess_description()\ncombined = combined.drop(\"listing_id\", 1)\ncombined = combined.drop(\"manager_id\", 1)\ncombined = combined.drop(\"building_id\", 1)\nfrom datetime import datetime\nfrom dateutil.parser import parse\ncombined['created'] = combined['created'].map(\n    lambda x: ((datetime.now() - parse(x)).days )\n)\ncombined = combined.drop(\"photos\", 1)\ndef scale_all_features():\n    \n    global combined\n    combined[combined['longitude']==0] = combined.longitude.median()\n    combined[combined.latitude == 0] = combined.latitude.median()\n    the_features = list(combined.columns)\n    combined[the_features] = combined[the_features].apply(lambda x: x/x.max(), axis=0)\n    \n    print ('Features scaled successfully !')\nscale_all_features()\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.cross_validation import StratifiedKFold\nfrom sklearn.grid_search import GridSearchCV\nfrom sklearn.ensemble.gradient_boosting import GradientBoostingClassifier\nfrom sklearn.cross_validation import cross_val_score\ndef compute_score(clf, X, y,scoring='accuracy'):\n    xval = cross_val_score(clf, X, y, cv = 5,scoring=scoring)\n    return np.mean(xval)\ndef recover_train_test_target():\n    global combined\n    \n    train0 = pd.read_json('../input/train.json')\n    \n    targets = train0.interest_level\n    targets = targets.map({\n        \"low\": -1,\n        \"medium\": 0,\n        \"high\": 1\n    })\n    train = combined.ix[0:49351]\n    test = combined.ix[49352:]\n    \n    return train,test,targets\ntrain,test,targets = recover_train_test_target()\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.feature_selection import SelectFromModel\nclf = ExtraTreesClassifier(n_estimators=200)\nclf = clf.fit(train, targets)\nfeatures = pd.DataFrame()\nfeatures['feature'] = train.columns\nfeatures['importance'] = clf.feature_importances_\nfeatures.sort(['importance'],ascending=False)\nmodel = SelectFromModel(clf, prefit=True)\ntrain_new = model.transform(train)\ntrain_new.shape\ntest_new = model.transform(test)\ntest_new.shape\nforest = RandomForestClassifier(max_features='sqrt')\n\nparameter_grid = {\n                 'max_depth' : [4,5,6,7,8],\n                 'n_estimators': list(range(200,300,10)),\n                 'criterion': ['gini','entropy']\n                 }\n\ncross_validation = StratifiedKFold(targets, n_folds=3)\n\ngrid_search = GridSearchCV(forest,\n                           param_grid=parameter_grid,\n                           cv=cross_validation)\n\ngrid_search.fit(train_new, targets)\n\nprint('Best score: {}'.format(grid_search.best_score_))\nprint('Best parameters: {}'.format(grid_search.best_params_))"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}