{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Etape 1 : Quel est le type de problème ?**\n\n- Il s'agit de prédire le nombre de demandes que reçoit une annonce sur le site Renthop. (apprentissage supervisé)\n- Variable d'intérêt : \"interest_level\" qui a trois catégories 'high' 'medium' 'low'\n- C'est un problème de classification"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Le sous-dossier contenant nos données\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#Librairies classiques de data science\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn import preprocessing \n\nimport datashader as ds\nfrom datashader import transfer_functions as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Les données d'apprentissage (train)\n\ntrain = pd.read_json(\"../input/two-sigma-connect-rental-listing-inquiries/train.json\")\ntrain = train.reset_index()\ntrain.pop(\"index\")\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Les données de validation (test)\n\ntest = pd.read_json(\"../input/two-sigma-connect-rental-listing-inquiries/test.json\")\ntest = test.reset_index()\ntest.pop(\"index\");\n\ntest.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Le fichier de soumission (submission) à Kaggle sur lequel est calculé notre score.\n\nsubmission = pd.read_csv(\"../input/two-sigma-connect-rental-listing-inquiries/sample_submission.csv\")\n\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Réindexation du test selon l'ordre de submission\n\ntest = test.set_index('listing_id')\ntest = test.reindex(index=submission['listing_id'])\ntest = test.reset_index()\n\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Regroupement des train et test avec indicatrice, pour avoir de nouvelles variables créées sur les deux\n#sets en même temps\n\ntrain[\"train_test\"] = 'train'\ntest[\"train_test\"] = 'test'\ntrain = pd.concat([train, test],axis=0,sort=True)\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Création de features\n\ntrain[\"price_type\"] = np.log(train[\"price\"])/(train[\"bedrooms\"]+1)\ntrain[\"room_sum\"] = train[\"bedrooms\"]+train[\"bathrooms\"] \ntrain[\"num_features\"] = train[\"features\"].apply(len)\ntrain[\"num_description_words\"] = train[\"description\"].apply(lambda x: len(x.split(\" \")))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Etape 2 : Quelles sont les données ? **\n\nRegardons tout d'abord la distribution de la variable d'intérêt : 'interest_level' qui prend les valeurs 'high' 'medium' ou 'low'. "},{"metadata":{"trusted":true},"cell_type":"code","source":"color = sns.color_palette()\nfreq = train['interest_level'].value_counts()\nsns.barplot(freq.index, freq.values, color=color[4])\nplt.ylabel('Frequence')\nplt.xlabel('Interest level')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"La majorité des appartements de la base train ont reçu un intérêt bas 'low'."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(train[\"bathrooms\"],normed=True,bins=range(7),alpha=0.5, color = color[3])\nplt.xlabel('Number of bathrooms', fontsize=13)\nplt.ylabel('freq', fontsize=13)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"80% des annonces sont des appartements avec une salle de bain unique."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Nombre moyen de salles de bain par niveau d'intérêt \nplt.figure(figsize=(10,6))\nsns.barplot(x='interest_level', y='bathrooms', data=train, order=['low', 'medium', 'high'])\nplt.xlabel('Interest Level')\nplt.ylabel('Nb moyen de salles de bain');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"En moyenne, les appartements de niveau d'intérêt low ont relativement plus de salles de bains que les annonces qui ont été classées medium ou high. On peut supposer qu'en effet, plus standards, et surement moins chers, les appartements classiques avec une salle de bain ont plus de succès ? "},{"metadata":{},"cell_type":"markdown","source":"**Bedrooms : **"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(train[\"bedrooms\"],normed=True,bins=range(8), alpha=0.5, color = color[1])\nplt.xlabel('Number of bedrooms', fontsize=13)\nplt.ylabel('freq', fontsize=13)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Environ 20% des appartements n'ont pas de chambre. On peut deviner que ce sont des studios? "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsns.barplot(x='interest_level', y='bedrooms', data=train, order=['low', 'medium', 'high'])\nplt.xlabel('Interest Level')\nplt.ylabel('Nb moyen de chambres')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Distribution bivariée bathrooms/bedrooms"},{"metadata":{"trusted":true},"cell_type":"code","source":"train2 = train.query(\"bathrooms < 5\")\n\nfig, ax = plt.subplots()\nh = ax.hist2d(train2[\"bathrooms\"], train2[\"bedrooms\"],normed=True)\nplt.colorbar(h[3], ax=ax)\n\nplt.xlabel('bathrooms')\nplt.ylabel('bedrooms')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Exploration de la variable \"features\" - liste de caractéristiques de l'appartement**\n\nOn créée une liste des caractéristiques totales listées dans toutes les annonces"},{"metadata":{"trusted":true},"cell_type":"code","source":"import itertools as it\n#chain.from_iterable(['ABC', 'DEF']) --> A B C D E F\n\nft = []\ntrain['features'].apply(lambda x: ft.append(x))\nft=list(it.chain.from_iterable(ft))\nprint(\"Nombre d'éléments: \" + str(len(ft)))\n\nuniq_ft = set(ft)\nprint(\"Nombre d'éléments uniques: \" + str(len(uniq_ft)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Feature recupéré dans les forums de Kaggle**\n\nCorrespond à la date de creation de chaque dossier contenant les images de l'annonce correspondante\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"image_timestamp = pd.read_csv('../input/hugoboum-renthop-image-timestamp/listing_image_time.csv')\nimage_timestamp.columns = ['listing_id', 'timestamp']\nimage_timestamp.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.merge(train,image_timestamp,on='listing_id',how='left')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**# Vérification des NA et valeurs abberantes**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.dropna(thresh=2) # car test a la colonne interest_level vide en toute logique\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.query(\"latitude == 0\")[\"latitude\"].agg(\"count\"))\nprint(train.query(\"longitude == 0\")[\"longitude\"].agg(\"count\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Inputation de l'emplacement median pour les points trop éloignés\n\nlatitude_median = np.median(train[\"latitude\"])\nlongitude_median = np.median(train[\"longitude\"])\n\nprint(latitude_median)\nprint(longitude_median)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['latitude'].values[train['latitude'] < 39] = latitude_median\ntrain['latitude'].values[train['latitude'] > 41] = latitude_median\n\ntrain['longitude'].values[train['longitude'] <-80] = longitude_median\ntrain['longitude'].values[train['longitude'] > -70] = longitude_median\n\nprint('Valeurs abberantes ')\nprint(train.query(\"latitude == 0\")[\"latitude\"].agg(\"count\"))\nprint(train.query(\"longitude == 0\")[\"longitude\"].agg(\"count\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Etudions les prix : **"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Quantiles de prix\ntrain[\"price\"].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Distribution log-prix\nsns.distplot(np.log(train[\"price\"]),hist=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Test de (log) normalité, pour les prix\nfrom scipy.stats import jarque_bera\n\njb = jarque_bera(np.log(train[\"price\"]))\nprint(\"p-value Jarque-Bera normality test: \" + str(jb[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Zoom sur le gros des prix\n\nsns.distplot(train.query(\"price < 10000\")[\"price\"] ,hist=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Catégorisation des prix\n\ntrain[\"price_cat\"] = pd.cut(train[\"price\"],np.array([0,1500,5000,500000,5000000]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.groupby(\"price_cat\").agg(\"count\").iloc[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"price_cat\"] = train[\"price_cat\"].astype(\"str\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Reformatage des catégories de prix selon le format accepté dans les modèles\n\nle = preprocessing.LabelEncoder()\ntrain[\"price_cat\"] = le.fit_transform(train[\"price_cat\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**rues les plus courantes**"},{"metadata":{"trusted":true},"cell_type":"code","source":"streets = train.groupby(train[\"display_address\"]).agg([\"count\"]).iloc[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"streets.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k=100\n\ntopstreets = streets.sort_values(ascending=False).iloc[:k]\ntopstreets = pd.DataFrame(topstreets)\ntopstreets[\"street\"] = topstreets.index\ntopstreets = topstreets.unstack().iloc[:k]\ntopstreets = topstreets.reset_index().drop([\"level_0\",\"level_1\"],axis=1)\ntopstreets.columns = [\"display_address\",\"display_address_count\"]\ntopstreets.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(40,200))\nsns.barplot(y=\"display_address\", x=\"display_address_count\", data=topstreets)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#On remet cette information comme variable dans le train \n\ntrain  = pd.merge(train,topstreets,on='display_address',how='left')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Même procédure pour les managers**"},{"metadata":{"trusted":true},"cell_type":"code","source":"managers = train.groupby(train[\"manager_id\"]).agg([\"count\"]).iloc[:,1]\n\n\nmanagers = pd.DataFrame(managers)\nmanagers = managers.unstack()\nmanagers[\"manager_id\"] = managers.index\n\nmanagers = managers.reset_index().drop([\"level_0\",\"level_1\"],axis=1)\nmanagers.columns = [\"manager_id\",\"manager_id_count\"]\nmanagers = managers.iloc[:-1,:]\nmanagers.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train  = pd.merge(train,managers,on='manager_id',how='left')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**On s'intéresse maintenant aux dates**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"created\"].iloc[2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"created\"] = train[\"created\"].astype(\"datetime64\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Création de variables temporelles\n\ntrain[\"year\"] = train[\"created\"].dt.year \ntrain[\"month\"] = train[\"created\"].dt.month\ntrain[\"day\"] = train[\"created\"].dt.dayofweek\ntrain[\"hour\"] = train[\"created\"].dt.hour ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Distributions des variables temporelles\n# Les heures de la journée\n\ncnt_hour = train['hour'].value_counts()\nsns.barplot(cnt_hour.index, cnt_hour.values, alpha=0.7, color=color[2])\nplt.xlabel('Nombre annonces')\nplt.ylabel('Heure de la journée')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nous pouvons observer que la majorité des annonces sont crées entre 1h et 6h du matin. On peut penser qu'il s'agit des heures auxquelles les mises à jour du site sont effectuées. \nCette variable n'est pas pertinente pour l'analyse."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Les jours de la semaine : Lundi = 0\n\ncnt_day = train['day'].value_counts()\nsns.barplot(cnt_day.index, cnt_day.values, alpha=0.7, color=color[3])\nplt.ylabel('Nombre annonces')\nplt.xlabel('jour de la semaine')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On remarque que plus d'annonces créées le mardi, mercredi et jeudi plutôt que le weekend."},{"metadata":{"trusted":true},"cell_type":"code","source":"cnt_month = train['month'].value_counts()\nsns.barplot(cnt_month.index, cnt_month.values, alpha=0.7, color=color[3])\nplt.ylabel('Nombre annonces')\nplt.xlabel('mois de l annee')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On observe les annonces par mois : on s'attend à ce qu'il y ait plus d'annonces sur les mois avant l'été, car en général, on quitte un appartement pour déménager pendant les vacances. "},{"metadata":{},"cell_type":"markdown","source":"**Graphiques bivariés**\n\nColoris par valeur de la variable d'interêt"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Filtrage des données seulement numériques pour analyse de corrélations\n\ntrain_numeric = train._get_numeric_data()\ntrain_numeric = pd.concat([train_numeric,train[\"interest_level\"],train[\"train_test\"]],axis=1)\ntrain_numeric.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fonction pratique pour sortir un grand nombre de graphs.\n\nsns.pairplot(train_numeric, hue=\"interest_level\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ces graphs permettent de visualiser:\n* en diagonale: toutes les distributions colorées par interest_level\n* hors diagonale: les nuages de points croisés entre chaque variable deux à deux\n\nOn peut ainsi voir si des variables séparent bien les niveaux d'interest_level"},{"metadata":{},"cell_type":"markdown","source":"Coloris par valeur de la variable indicatrice de train ou test"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_numeric[\"train_test\"] = train[\"train_test\"]\nsns.pairplot(train_numeric, hue=\"train_test\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"En refaisant la même chose avec la variable indicatrice train_test en coloris, on peut visualiser la différence de distribution des données du train et du test sets."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_numeric = train_numeric.drop(['year','train_test'],axis=1);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le = preprocessing.LabelEncoder()\ntrain_numeric[\"interest_level\"] = le.fit_transform(train_numeric[\"interest_level\"].fillna('0'))\nnp.unique(train_numeric[\"interest_level\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_numeric = train_numeric.query('interest_level>0')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Corrélations"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_corrs = train_numeric.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(train_corrs,cmap=\"viridis\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Corrélations avec la variable d'interêt\n\ntrain_interestlevel_corrs = train_corrs['interest_level']\ntrain_interestlevel_corrs = pd.DataFrame(train_interestlevel_corrs)\ntrain_interestlevel_corrs['variable'] = train_interestlevel_corrs.index\ntrain_interestlevel_corrs = train_interestlevel_corrs [train_interestlevel_corrs['variable'] != 'interest_level']\n\nsns.barplot(y='variable', x='interest_level', data=train_interestlevel_corrs)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Création d'une carte**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nplot_width  = int(750)\nplot_height = int(plot_width//1.2)\nx_range, y_range = ((-8242000,-8210000), (4965000,4990000))\ntrain[\"longitude_mercator\"],train[\"latitude_mercator\"] = ds.utils.lnglat_to_meters(train[\"longitude\"],train[\"latitude\"])\n\ncvs = ds.Canvas(plot_width=plot_width, plot_height=plot_height, x_range=x_range, y_range=y_range)\nagg = cvs.points(train, 'longitude_mercator', 'latitude_mercator',ds.count(\"bedrooms\"))\nimg = tf.shade(agg, cmap=ds.colors.inferno, how='eq_hist')\nimg","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Création d'une variable par clustering**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#Seul l'algorithme KMeans est adapté à notre taille de dataset\n\nfrom sklearn.cluster import KMeans\n\nNYC_Cluster =  KMeans(n_clusters=15, random_state=42)\n\ngeodata = pd.concat([train[\"latitude\"],train[\"longitude\"]], axis=1)\ntrain[\"nyc_cluster\"] = NYC_Cluster.fit_predict(geodata)\n                     \n#Ajouter d'autres variables dans les données ne fait que brouiller les clusters\n\nprint(train.groupby(\"nyc_cluster\").agg(\"count\").iloc[:,1])\n\nplot = sns.lmplot(data=train,x=\"longitude\",y=\"latitude\",hue=\"nyc_cluster\",legend=\"full\",palette=\"Set3\",fit_reg=False)\nplt.show()\n\n#Zoom sur Manhattan\n\ntrain2 = train.query(\"longitude > -74.03\")\ntrain2 = train2.query(\"longitude < -73.9\")\ntrain2 = train2.query(\"latitude > 40.65\")\ntrain2 = train2.query(\"latitude < 40.87\")\n\ntrain2 = train2.sample(n=1000)\nprint(\"Zoom sur Manhattan\")\nplot = sns.lmplot(data=train2,x=\"longitude\",y=\"latitude\",hue=\"nyc_cluster\",legend=\"full\",palette=\"Set3\",fit_reg=False)\nplt.show()\n\ntmp = pd.concat([geodata,train [\"nyc_cluster\"]],axis=1)\nprint(\"Corrélations\")\nprint(tmp.corr())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Latent Semantic Analysis (TF-IDF puis SVD tronquée)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nvectorizer = TfidfVectorizer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidfeats = vectorizer.fit_transform(train[\"description\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidfeats.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import TruncatedSVD","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svd = TruncatedSVD(n_components=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lsa_feats = svd.fit_transform(tfidfeats)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(svd.explained_variance_ratio_.cumsum())\nplt.show()\nprint(\"Variance expliquée: \" + str(svd.explained_variance_ratio_.sum()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lsa_feats = pd.DataFrame(lsa_feats)\nlsa_feats_colnames = [\"lsa_\" + str(i+1) for i in range(100)]\nlsa_feats.columns = lsa_feats_colnames\ntrain = pd.concat([train,lsa_feats],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"features\"] = train[\"features\"].astype(\"str\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidfeats2 = vectorizer.fit_transform(train[\"features\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidfeats2.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svd2 = TruncatedSVD(n_components=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lsa_feats2 = svd2.fit_transform(tfidfeats2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(svd2.explained_variance_ratio_.cumsum())\nplt.show()\nprint(\"Variance expliquée: \" + str(svd2.explained_variance_ratio_.sum()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lsa_feats2 = pd.DataFrame(lsa_feats2)\nlsa_feats2_colnames = [\"lsa2_\" + str(i+1) for i in range(20)]\nlsa_feats2.columns = lsa_feats2_colnames\ntrain = pd.concat([train,lsa_feats2],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Analyse de sentiments**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from textblob import TextBlob","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"description_polarity, description_subjectivity = [],[]\n\n\nfor desc in train[\"description\"]:\n    desc_blob= TextBlob(desc)\n    description_polarity.append(desc_blob.sentiment.polarity)\n    description_subjectivity.append(desc_blob.sentiment.subjectivity)\n\ntrain[\"description_polarity\"] = description_polarity\ntrain[\"description_subjectivity\"] = description_subjectivity\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Photos**\n\nNous n'avons pas pu télécharger les photos (torrent mort) mais nous avons tout de même les liens"},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"photos\"][1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"photos_count\"] =  train.photos.apply(len)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"photos_count\"][1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"On crée une variable on l'on garde seulement la première photo de chaque annonce\nCela reduit la taille à télécharger à environ 200ko* 50 000 = 10Go \n\nphotos_2 = []\n\nfor item in train[\"photos\"]:\n    try:\n        photos_2.append(item[0])\n    except IndexError:\n        photos_2.append(np.nan)\ntrain[\"photos_2\"] = photos_2\n\n\nimport requests\nfrom PIL import Image\nimport io\n\nimages = []\n\nfor image_url in train[\"photos_2\"]:\n    try:\n        img_data = requests.get(url= image_url).content\n        img = Image.open(io.BytesIO(img_data))\n        images.append(np.array(img))\n        \n    except requests.exceptions.MissingSchema:\n        images.append(np.nan)\n        \nimages = pd.DataFrame(images)\nprint(images.shape)\n\nExporter les images en csv pour les remettre en dataset Kaggle que l'on liera ensuite (\"+Add Dataset\")\nimages.to_csv()\n\n\nImpossible d'effectuer cette étape;\n\"failed. exited with code 137\". Problème de mémoire.\n"},{"metadata":{},"cell_type":"markdown","source":"**Modélisation et prédiction**\n\nOn utilise un Gradient Boosting"},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Variables dont a extrait l'info et/ou inutilisables\n\ntrain = train.drop(['building_id','created','description','display_address',\n           'features','manager_id','photos','street_address'],axis=1)\n\ntrain['display_address_count'] = train['display_address_count'].astype(\"float\")\ntrain['manager_id_count'] = train['manager_id_count'].astype(\"float\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"FeatureTools\nimport featuretools as ft\n\nes = ft.EntitySet(id = 'feature_engineering')\n\ntable = pd.DataFrame(train.drop(['interest_level','longitude_mercator','latitude_mercator'],axis=1).iloc[:,:15])\n\nes = es.entity_from_dataframe(entity_id = 'main_table', \n                              dataframe = table, \n                              index = 'listing_id')\n\nes"},{"metadata":{"trusted":true},"cell_type":"markdown","source":" ft.primitives.list_primitives()"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"features, feature_names = ft.dfs(entityset = es, target_entity = 'main_table', max_depth=2,\n                                 agg_primitives = ['mean', 'min', 'max'],\n                                 trans_primitives = ['subtract_numeric', 'divide_numeric'])\n"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"features.head()"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"feature_names"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"train = pd.merge(train,features,on='listing_id',how='left')"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Séparation train et test\n\ntest = train[train.train_test == \"test\"]\ntrain = train[train.train_test == \"train\"]\n\ntrain.pop(\"train_test\")\ntrain_target = train.pop(\"interest_level\")\n\ntest = test.drop(['interest_level','train_test'],axis=1)\n\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"train_scaled = preprocessing.scale(train)\n\ntrain_scaled = pd.DataFrame(train_scaled)\n\ntrain_scaled.columns = train.columns\n\ntrain = train_scaled"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"test_scaled = preprocessing.scale(test)\n\ntest_scaled = pd.DataFrame(test_scaled)\n\ntest_scaled.columns = test.columns\n\ntest = test_scaled"},{"metadata":{"trusted":true},"cell_type":"code","source":"gradient_booster = lgb.LGBMClassifier()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On utilise une cross valisation et une grid search\nLa loss function optimisée (logarithmic loss) est celle qui score les participants au leaderboard"},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_parameters = {'n_estimators': [100,500,1000],'num_leaves': [10,30,50],\n                   'reg_alpha' : [0.2,0.4,0.6],'learning_rate' : [0.05,0.1]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gs = GridSearchCV(estimator=gradient_booster, param_grid = grid_parameters, \n                  cv= 4, scoring= 'neg_log_loss')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Estimation\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"gs.fit(train,train_target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gs.cv_results_['mean_test_score']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_log_loss = -1 * np.max(gs.cv_results_['mean_test_score'])\n\nprint(\"La log-loss de validation croisée du meilleur parametrage est de \" + str(best_log_loss))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Hyperparametrage retenu\ngs.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Utilisation faite des variables\nplt.figure(figsize=(40,200))\n\ndf = pd.concat([pd.DataFrame(train.columns),\n                pd.DataFrame(gs.best_estimator_.feature_importances_)],\n               axis=1)\ndf.columns = ['variable', 'importance']\nsns.barplot(y=\"variable\", x=\"importance\", data= df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gs.best_estimator_.classes_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Prédiction**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Prédiction du test (proba associée à chaque classe pour chaque observation)\n\npredictions = gs.predict_proba(test)\npredictions = pd.DataFrame(predictions)\n\npredictions.columns = ['high','low','medium']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Remise dans le fichier à soumettre pour être classé\n\nsubmission['high'] = predictions['high']\nsubmission['medium'] = predictions['medium']\nsubmission['low'] = predictions['low']\n\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Soumission**"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('projet ML.csv', index=False);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Pour aller plus loin dans la modélisation:\n* Une Random Forest \n* Un ensembling (stacking) des deux modèles ?"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}