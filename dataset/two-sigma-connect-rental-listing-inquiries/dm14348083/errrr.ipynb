{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"5cc08b2d-6f7c-898c-379e-8ad31baa0836"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"aa50b20d-2c02-01dc-22fe-aac92aa317d4"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"da9b1e09-b1c4-fe65-81dc-5193c1e26eb7"},"outputs":[],"source":"from sklearn import model_selection, preprocessing, ensemble\nfrom sklearn.metrics import log_loss\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.ensemble import GradientBoostingClassifier"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3353c35a-3e8c-0afc-2ae2-f12af8cf275d"},"outputs":[],"source":"def preprocess(data):\n    data['num_photos'] = data['photos'].apply(len)\n    data['num_features'] = data['features'].apply(len)\n\n    def fill_empty(row):\n        if row.num_features == 0:\n            return ['null']\n        return row.features\n\n    data['features_filled'] = data.apply(lambda row: fill_empty(row), axis = 1)\n    \n    data['features_word'] = data['features_filled'].apply(lambda x: \" \".join([\"_\".join(i.split(\" \")) for i in x]))\n    tfidf = CountVectorizer(stop_words = 'english', max_features = 200)\n    data_sparse = tfidf.fit_transform(data['features_word'])\n    \n    data['created_year'] = pd.to_datetime(data['created']).dt.year\n    data['created_month'] = pd.to_datetime(data['created']).dt.month\n    data['created_day'] = pd.to_datetime(data['created']).dt.day\n\n    return data"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"70e83eb7-d96d-57bc-2640-021b5123f898"},"outputs":[],"source":"train = pd.read_json('../input/train.json')\nlabel_num_map = { 'high': 0, 'medium': 1, 'low': 2 }\ntrain['label'] = train['interest_level'].apply(lambda x: label_num_map[x])\n\ninterest_level = pd.get_dummies(train['interest_level'])\ninterest_level\ntrain = pd.concat([train, interest_level], axis = 1)\n\ntrain = preprocess(train)\nuse_features = ['bedrooms', 'bathrooms', 'price', 'num_features', 'num_photos']\ntrain_X = train[use_features]\ntrain_y = train['label']\ngradientB_model = GradientBoostingClassifier(n_estimators=20, learning_rate=1.0, max_depth=1, random_state=0).fit(train_X, train_y)\ngradientB_model = gradientB_model.fit(train_X, train_y)\n\ntest = pd.read_json('../input/test.json')\nlisting_id = test['listing_id']\ntest = preprocess(test)[use_features]\nresult = gradientB_model.predict(test)\n\nresult_df = pd.DataFrame({ 'level': result })\nil = pd.get_dummies(result_df['level'])\nresult_df = pd.concat([result_df, il], axis = 1)\nresult_df = result_df[[0, 1, 2]]\nresult_df.index = test.index\nresult_df.rename(columns = {0: 'high', 1: 'medium', 2: 'low'}, inplace = True)\nresult_df = pd.concat([result_df, listing_id], axis = 1)\nresult_df.set_index('listing_id', inplace = True)\nresult_df.to_csv('result.csv')"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}