{"cells":[{"metadata":{},"cell_type":"markdown","source":"ある程度上位には入れて、これ以上はもう良いだろうという気持ちになったので方針を書きます\n\n* 提出はパラメーターを少し変えて5つしてます\n* agent1(初日, 650くらい)\n  * 終了するタイミングがわかっている多腕バンディットは、UCBよりSoftmax Action Selection(?名称がよくわかってない)の方がよかった記憶があるので、単純に実装\n  * 自分の行動を記録しておけば、相手の行動は　sum(lastActions) - 自分の行動 でわかる\n    * バージョンアップして必要なくなったっぽいが\n  * hits / cnts で減衰していない値を得たかったので、hitsに+するときに割ってる\n* agent2(二日目, 900弱?)\n  * 相手の行動を考慮するようにした\n  * 相手が認識している優先順位を回数と順序で推定、優先順位順に99-0を割り当てる\n  * 不確実な相手の結果より自分の結果の方を優先したいので重み付けを入れた\n* agent3(三日目, 9連勝して1000を超えてるのもある)\n  * パラメーター調整が不十分だったことがわかったので調整した"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!pip install kaggle-environments --upgrade -q","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%writefile agent1.py\n\n\nimport math, random\n\n\nhistory = {\n    \"turn\": 0,\n    \"cnts\": [0] * 100,\n    \"ocnts\": [0] * 100,\n    \"hits\": [0] * 100,\n    \"la\": -1,\n}\n\ndef agent1(observation, configuration):\n    global history\n\n    N = 100\n    p = [63.9413, 0.000533149]\n    ti = observation[\"step\"]\n    if ti == 0:\n        pass\n    else:\n        la = history[\"la\"]\n        ola = sum(observation['lastActions']) - la\n        if sum(history[\"hits\"]) < observation['reward']:\n            history[\"hits\"][la] += 1 / pow(0.97, history[\"cnts\"][la] + history[\"ocnts\"][la])\n        history[\"cnts\"][la] += 1\n        history[\"ocnts\"][ola] += 1\n\n    tau = p[0] / (ti + 1) + p[1]\n    ea = [0] * N\n    hits = history[\"hits\"]\n    cnts = history[\"cnts\"]\n    ocnts = history[\"ocnts\"]\n    for i in range(N):\n        if cnts[i] == 0:\n            ea[i] = math.exp(0.99 * pow(0.97, ocnts[i]) / tau)\n        else:\n            ea[i] = math.exp(hits[i] / cnts[i] * pow(0.97, cnts[i] + ocnts[i]) / tau)\n\n    se = sum(ea)\n    r = random.random() * se\n    t = 0\n    la = 99\n    for i in range(N):\n        t += ea[i]\n        if t >= r:\n            la = i\n            break\n\n    history[\"la\"] = la\n    return la\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%writefile agent2.py\n\nimport math, random\n\n\nhistory = {\n    \"turn\": 0,\n    \"cnts\": [0] * 100,\n    \"ocnts\": [0] * 100,\n    \"hits\": [0] * 100,\n    \"osteps\": [0] * 100,\n    \"la\": -1,\n}\n\ndef agent2(observation, configuration):\n    global history\n\n    N = 100\n    p = [4.60575, 0.000629018, 1.82229]\n    ti = observation[\"step\"]\n    if ti == 0:\n        pass\n    else:\n        la = history[\"la\"]\n        ola = sum(observation['lastActions']) - la\n        history[\"osteps\"][ola] = ti\n        if sum(history[\"hits\"]) < observation['reward']:\n            history[\"hits\"][la] += 1 / pow(0.97, history[\"cnts\"][la] + history[\"ocnts\"][la])\n        history[\"cnts\"][la] += 1\n        history[\"ocnts\"][ola] += 1\n\n    tau = p[0] / (ti + 1) + p[1]\n    ea = [0] * N\n    hits = history[\"hits\"]\n    cnts = history[\"cnts\"]\n    ocnts = history[\"ocnts\"]\n    osteps = history[\"osteps\"]\n\n    tv = sorted([(-ocnts[i], osteps[i], i) for i in range(N)])\n    ot = [0] * N\n    for i in range(N):\n        ot[tv[i][2]] = 99 - i\n\n    for i in range(N):\n        if cnts[i] == 0:\n            if ocnts[i] > 1:\n                ea[i] = math.exp(ot[i] / 100 * pow(0.97, ocnts[i]) / tau)\n            else:\n                ea[i] = math.exp(0.99 * pow(0.97, ocnts[i]) / tau)\n        else:\n            w = pow(cnts[i], p[2])\n            wo = ocnts[i]\n            if ocnts[i] < 2:\n                wo = 0\n            r = hits[i] / cnts[i]\n            ro = ot[i] / 100\n            ea[i] = math.exp((r * w + ro * wo) / (w + wo) * pow(0.97, cnts[i] + ocnts[i]) / tau)\n\n    se = sum(ea)\n    r = random.random() * se\n    t = 0\n    la = 99\n    for i in range(N):\n        t += ea[i]\n        if t >= r:\n            la = i\n            break\n\n    history[\"la\"] = la\n    return la\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"%%writefile agent3.py\n\nimport math, random\n\n\nhistory = {\n    \"turn\": 0,\n    \"cnts\": [0] * 100,\n    \"ocnts\": [0] * 100,\n    \"hits\": [0] * 100,\n    \"osteps\": [0] * 100,\n    \"la\": -1,\n}\n\ndef agent3(observation, configuration):\n    global history\n\n    N = 100\n    p = [0.39918, 0.000138129, 1.23946]\n    ti = observation[\"step\"]\n    if ti == 0:\n        pass\n    else:\n        la = history[\"la\"]\n        ola = sum(observation['lastActions']) - la\n        history[\"osteps\"][ola] = ti\n        if sum(history[\"hits\"]) < observation['reward']:\n            history[\"hits\"][la] += 1 / pow(0.97, history[\"cnts\"][la] + history[\"ocnts\"][la])\n        history[\"cnts\"][la] += 1\n        history[\"ocnts\"][ola] += 1\n\n    tau = p[0] / (ti + 1) + p[1]\n    ea = [0] * N\n    hits = history[\"hits\"]\n    cnts = history[\"cnts\"]\n    ocnts = history[\"ocnts\"]\n    osteps = history[\"osteps\"]\n\n    tv = sorted([(-ocnts[i], osteps[i], i) for i in range(N)])\n    ot = [0] * N\n    for i in range(N):\n        ot[tv[i][2]] = 99 - i\n\n    for i in range(N):\n        if cnts[i] == 0:\n            if ocnts[i] > 1:\n                ea[i] = math.exp(min(500, ot[i] / 100 * pow(0.97, ocnts[i]) / tau))\n            else:\n                ea[i] = math.exp(min(500, 0.99 * pow(0.97, ocnts[i]) / tau))\n        else:\n            w = pow(cnts[i], p[2])\n            wo = ocnts[i]\n            if ocnts[i] < 2:\n                wo = 0\n            r = hits[i] / cnts[i]\n            ro = ot[i] / 100\n            ea[i] = math.exp(min(500, (r * w + ro * wo) / (w + wo) * pow(0.97, cnts[i] + ocnts[i]) / tau))\n\n    se = sum(ea)\n    r = random.random() * se\n    t = 0\n    la = 99\n    for i in range(N):\n        t += ea[i]\n        if t >= r:\n            la = i\n            break\n\n    history[\"la\"] = la\n    return la\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from kaggle_environments import make, evaluate\n\nagents = [\"random\", \"agent1.py\", \"agent2.py\", \"agent3.py\"]\nrun_count = 100\n\nfor i in range(4):\n    for j in range(i+1, 4):\n        ak = [0] * 2\n        aw = [0] * 2\n\n        for _ in range(run_count):\n            env = make(\"mab\")\n\n            steps = env.run([agents[i], agents[j]])\n\n            k = [0, 0]\n            for s in steps[1:]:\n                la = s[0]['observation']['lastActions']\n                t = s[0]['observation']['thresholds']\n                try:\n                    k[0] += t[la[0]] / 97\n                    k[1] += t[la[1]] / 97\n                except Exception as e:\n                    print(e)\n                    print(s)\n\n            ak[0] += k[0]\n            ak[1] += k[1]\n            if k[0] >= k[1]:\n                aw[0] += 1\n            else:\n                aw[1] += 1\n\n        print(f\"{agents[i]} win: {aw[0]} avg: {ak[0] / run_count} vs {agents[j]} win: {aw[1]} avg: {ak[1] / run_count}\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"その他\n\n* パラメーター調整はC++でシュミレーションすると速い\n* 評価はrewardより確率の合計の方が正確(なはず)\n* このコンテストでより上位に入るためにこれからすべきこと\n  * 毎日5つ提出し続ける\n  * すべての提出物を評価対象にしてる理由がわからん"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}