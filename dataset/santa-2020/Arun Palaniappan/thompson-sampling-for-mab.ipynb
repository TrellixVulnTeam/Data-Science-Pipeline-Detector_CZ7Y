{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"! pip install kaggle-environments --upgrade -q","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"%%writefile ts_sampling.py\n\nimport numpy as np\n\narm_success = None  #Holds the paramter \\alpha for each arm\narm_failures = None  #Holds the paramter \\beta for each arm \narm = None\ntotal_returns = 0\n\ndef agent(observation, configuration):\n    global arm_success, arm_failures, arm, total_returns\n    \n    n_bandits = configuration.banditCount\n    \n    if observation.step == 0:\n        arm_success = np.ones(n_bandits)\n        arm_failures = np.ones(n_bandits)\n    else:\n        reward = observation.reward - total_returns\n        arm_success[arm] += reward\n        arm_failures[arm] += (1 - reward)\n        total_returns = observation.reward\n        \n    arm_samples = np.random.beta(arm_success, arm_failures)\n        \n    arm = int(np.argmax(arm_samples))\n    \n    return (arm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from kaggle_environments import make\nenv = make(\"mab\", debug=True)\n\nenv.reset()\nenv.run([\"../input/santa-2020/submission.py\", \"ts_sampling.py\"])\nenv.render(mode=\"ipython\", width=800, height=500)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}