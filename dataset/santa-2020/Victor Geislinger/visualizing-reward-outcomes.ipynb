{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"# Visualizing Rewards"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"## Motivation\n\nI've been playing around with relatively simple strategies like the $\\epsilon$-greedy algorithm just to see how the agent does in general. I wanted a way to compare the different models other than looking at the final score."},{"metadata":{},"cell_type":"markdown","source":"# Class Definition\n\nHere we define our class to make life easy to plot multiple simulations to compare"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%writefile SimulationExplorer.py\n\nimport matplotlib.pyplot as plt\n\nclass SimViz:\n    '''\n    '''\n    \n    def __init__(self, sims=None):\n        \n        # Copy simulations to object\n        if sims:\n            self.sims = {name:env for name,env in sims.items()}\n            # Get simulation environments (JSON)\n            self.envs = {k:self.get_env_json(env) for k,env in self.sims.items()}\n        else:\n            self.sims = {}\n            self.envs = {}\n            \n    def get_env_json(self, env):\n        '''\n        '''\n        try:\n            env_json = env.toJSON()\n            return env_json\n        except:\n            print('ERROR: Invalid environment')\n            \n    def add_env(self, env, name=None):\n        '''\n        '''\n        # TODO: Make sure it is a unique name\n        if name is None:\n            name =  f'{len(self.envs) + 1}'\n            name += f'_{\"\".join(k[-1] for k in self.envs.keys())}'\n        # Add to both sims and envs\n        self.sims[name] = env\n        self.envs[name] = self.get_env_json(env)\n        \n    def add_sim(self, env, name=None):\n        '''\n        '''\n        # TODO: Make sure it is a unique name\n        if name is None:\n            name =  f'{len(self.sims) + 1}'\n            name += f'_{\"\".join(k[-1] for k in self.sims.keys())}'\n        # Add to both sim and env\n        self.sims[name] = env\n        self.add_env(env, name)\n            \n\n    def get_rewards(self, name):\n        '''\n        '''\n        # TODO:  Check for error\n        agent_steps = self.envs.get(name).get('steps')\n        n_steps = len(agent_steps)\n        rewards = [agent_steps[s][0].get('reward') for s in range(n_steps)]\n        return rewards\n    \n    def plot_total_reward(self, names=None, *args, **kwargs):\n        '''\n        '''\n        fig,ax = plt.subplots(figsize=(12,8))\n        ax.set_title('Total Rewards Over Steps')\n        ax.set_xlabel('Steps')\n        ax.set_ylabel('Rewards (cummulative)')\n        if names is None:\n            names = list(self.envs.keys())\n        elif not isinstance(names, list):\n            names = [names]\n        \n        # Plot all the simulations given\n        for name in names:\n            rewards = self.get_rewards(name)\n            ax.plot(rewards, label=name, *args, **kwargs)\n        \n        ax.legend(loc='upper left', ncol=2)\n#         ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left',\n#            ncol=2)\n\n        return fig,ax\n   \n        \n            ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Example Usage"},{"metadata":{},"cell_type":"markdown","source":"## Simulate Agents"},{"metadata":{},"cell_type":"markdown","source":"### Example agent"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%writefile always0_agent.py\n\n# Randomly pick different bandits/machines\ndef always0_agent(observation, configuration):\n    '''Always select machine #0\n    '''\n    choice = 0\n    return choice\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%writefile random_agent.py\n\nimport numpy as np\nnp.random.seed(27)\n\n# Randomly pick different bandits/machines\ndef random_agent(observation, configuration):\n    '''Randomly select machine\n    '''\n    # Cast from NumPy integer type\n    choice = int(np.random.choice(np.arange(configuration.banditCount)))\n    return choice\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Run simulation"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install kaggle-environments --upgrade","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from kaggle_environments import make","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"always0_v_always0 = make(\"mab\", debug=True)\n\nalways0_v_always0.run([\"always0_agent.py\", \"always0_agent.py\"])\nalways0_v_always0.render(mode=\"ipython\", width=800, height=300)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_v_random_env = make(\"mab\", debug=True)\n\nrandom_v_random_env.run([\"random_agent.py\", \"random_agent.py\"])\nrandom_v_random_env.render(mode=\"ipython\", width=800, height=300)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_v_always0 = make(\"mab\", debug=True)\n\nrandom_v_always0.run([\"random_agent.py\", \"always0_agent.py\"])\nrandom_v_always0.render(mode=\"ipython\", width=800, height=300)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"always0_v_random = make(\"mab\", debug=True)\n\nalways0_v_random.run([\"always0_agent.py\", \"random_agent.py\"])\nalways0_v_random.render(mode=\"ipython\", width=800, height=300)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualize Agents"},{"metadata":{"trusted":true},"cell_type":"code","source":"import SimulationExplorer as Explorer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sims = {\n    'always_0-v-always_0': always0_v_always0,\n    'random-v-always_0': random_v_always0,\n    'random-v-random': random_v_random_env,\n    'always_0-v-random': always0_v_random,\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = Explorer.SimViz(sims)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f ,ax = test.plot_total_reward(linestyle='dashed')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f_rand, ax_rand = test.plot_total_reward(['always_0-v-always_0','always_0-v-random'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Check that simulation total results match with plots"},{"metadata":{"trusted":true},"cell_type":"code","source":"for n,env in sims.items():\n    print(n,env.toJSON().get('rewards'))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}