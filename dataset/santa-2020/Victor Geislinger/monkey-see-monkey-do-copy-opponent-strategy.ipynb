{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Monkey See, Monkey Do: Copy Opponent Strategy"},{"metadata":{},"cell_type":"markdown","source":"Obviously not a great strategy by itself but how often does it actually win due to random chance?"},{"metadata":{},"cell_type":"markdown","source":"## Agent Setup"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%writefile agent_copy_strat.py\n\nimport random\nrandom.seed(27)\n\nclass Agent:\n    \n    def __init__(self):\n        self.my_moves = []\n        self.opponent_moves = []\n        self.rewards = []\n    \n    def random_move(self, obs, config):\n        '''Make a random move\n        '''\n        move = random.choice(range(config.banditCount))\n        return move\n        \n    def get_last_move(self, moves, obs, config):\n        '''Get the last move of given list of moves (of an agent).\n        '''\n        try:\n            move = moves[-1]\n        except IndexError:\n            move = self.random_move(obs,config)\n        return move\n        \n    def copy_move(self, obs, config):\n        '''Simply copy last move of opponent.\n        '''\n        return self.get_last_move(self.opponent_moves, obs, config)\n    \n    # TODO: Record other information besides moves\n    def record_history(self, obs, conf):\n        '''Record history like list of moves (both agents), rewards, etc.\n        '''\n        # If first turn, don't record anything\n        if obs.step > 0:\n            # Record opponenet last move\n            # TODO: consider if more than two agents\n            my_index = (obs.agentIndex) % 2\n            opponent_index = (obs.agentIndex + 1) % 2\n            my_last_move = obs.lastActions[my_index]        \n            opponent_last_move = obs.lastActions[opponent_index]\n            self.my_moves.append(my_last_move)\n            self.opponent_moves.append(opponent_last_move)\n            # TODO: Record rewards\n        return\n    \n    def use_strategy(self, obs, config, strat='random'):\n        '''Return which bandit to choose given a strategy, observations, & \n        environment configuration.\n        '''\n        if strat.lower() == 'random':\n            move = self.random_move(obs, config)\n        elif strat.lower() == 'copy_move':\n            move = self.copy_move(obs, config)\n        # Default to choosing first lever if not known strategy\n        else:\n            move = 0\n        return move\n    \n\nmy_agent = Agent()\n\ndef agent_run(observation, config):\n    # Record history\n    my_agent.record_history(observation, config)\n    # Simply copy moves\n    bandit = my_agent.use_strategy(observation, config, strat='copy_move')\n    return bandit ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Agent Runs"},{"metadata":{},"cell_type":"markdown","source":"Let's create a random agent to run against"},{"metadata":{"trusted":true},"cell_type":"code","source":"from agent_copy_strat import Agent \n\nrand_agent = Agent()\ndef rand_run(obs,conf):\n    bandit = rand_agent.use_strategy(obs,conf,strat='random')\n    return bandit","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!pip install kaggle-environments --upgrade -q","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from kaggle_environments import make","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"env = make(\"mab\", debug=True)\n\nenv.run(['agent_copy_strat.py', rand_run])\nenv.render(mode=\"ipython\", width=800, height=300)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Evaluation"},{"metadata":{},"cell_type":"markdown","source":"### Checkout the rewards over time"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Import module we'll need to import our custom module\nfrom shutil import copyfile\n\n# Copy our file into the working directory (make sure it has .py suffix)\ncopyfile(src=\"../input/visualizing-reward-outcomes/SimulationExplorer.py\", \n         dst= \"../working/SimulationExplorer.py\")\n\n# Import SimulationExplorer functions\nimport SimulationExplorer as Explorer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sims = {'test':env}\ntest = Explorer.SimViz(sims)\ntest.plot_total_reward()\n\nfor n,env in sims.items():\n    print(n,env.toJSON().get('rewards'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Multiple runs"},{"metadata":{},"cell_type":"markdown","source":"Alright, let's see how this does a few many runs. Should be able to sneak out a few lucky wins"},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_trial_results(trial, env, start_time):\n    '''Helper function to see how agents compare\n    '''\n    rewards = env.toJSON().get('rewards')\n    print(f'Trial # {trial}:')\n    print(f'\\t{time.time()-start_time:.4} seconds')\n    print(f'\\t{\"W\" if rewards[0]>rewards[1] else \"L\"} â†’ {rewards}')\n    diff = rewards[0]-rewards[-1]\n    print(f'\\tDifference: {diff}')\n    \n    return diff","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\n\n\nsims = {}\ndiffs = []\n\nfor trial in range(20):\n    start_time = time.time()\n    myagent = Agent()\n    \n    env = make(\"mab\", debug=True)\n    env.run(['agent_copy_strat.py', rand_run])\n\n    #\n    name = f'Trial#{trial}'\n    sims[name] = env\n    \n    #\n    diffs.append(print_trial_results(trial, env, start_time))\n\n\ntest = Explorer.SimViz(sims)\ntest.plot_total_reward()\n\nprint(f'Win Percentage: {sum(1 for x in diffs if x>0)/len(diffs):.2}')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}