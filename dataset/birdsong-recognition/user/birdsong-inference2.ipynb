{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!cp -R /kaggle/input/mpg123 .","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!dpkg -i mpg123/libaudio2_1.9.4-6_amd64.deb\n!dpkg -i mpg123/libportaudio2_19.6.0-1_amd64.deb\n!dpkg -i mpg123/libout123-0_1.25.10-1_amd64.deb \n!dpkg -i mpg123/mpg123_1.25.10-1_amd64.deb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!cp -R /kaggle/input/efficientnetpytorch .","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.data as data\nimport torchvision\nimport torchvision.models as models\nimport torchvision.transforms as T\nimport librosa\nimport scipy\nimport os\nfrom efficientnetpytorch.efficientnet_pytorch.model import EfficientNet","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_path = '/kaggle/input/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MyModel(nn.Module):\n\n    def __init__(self):\n        super(MyModel, self).__init__()\n        # Convert 1 channel to 3 channel to be able to send to resnet18\n        self.conv1 = nn.Conv2d(1, 3, kernel_size=3, padding=1)\n        self.base_model = EfficientNet.from_name('efficientnet-b2')\n        self.fc2 = nn.Linear(1000, 264) # 264 different birds\n\n    def forward(self, x):\n        \n        x = self.conv1(x)\n        x = self.base_model(x)\n        x = self.fc2(x)\n        \n        return x\n        \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\nmodel = MyModel().to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_state_dict(torch.load('/kaggle/input/birdsongmodel2/birdsong_model2.pth'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/birdsong-recognition/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train_df[(train_df.filename != 'XC395021.mp3') & (train_df.filename != 'XC504005.mp3') & (train_df.filename != 'XC504006.mp3') & (train_df.filename != 'XC505006.mp3')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ebird_codes = np.array(sorted(list(set(train_df['ebird_code']))))\nbird_to_idx = { bird: idx for idx, bird in enumerate(ebird_codes) }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pathlib import Path\nTEST = Path(\"../input/birdsong-recognition/test_audio\").exists()\n\nif TEST:\n    DATA_DIR = \"../input/birdsong-recognition/\"\nelse:\n    # dataset created by @shonenkov, thanks!\n    DATA_DIR = \"../input/birdcall-check/\"\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv(DATA_DIR + 'test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df_grouped = test_df.groupby(['audio_id']).agg(list).reset_index(drop=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df_grouped","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"row_id_birds = {}\nmodel.eval()\nfor i in range(len(test_df_grouped)):\n    print(i)\n    row = test_df_grouped.iloc[i]\n    audio_id = row.audio_id\n    ! mpg123 -q -w /kaggle/working/wav_file{i}.wav {DATA_DIR}test_audio/{audio_id}.mp3\n    sr, audio = scipy.io.wavfile.read(f'/kaggle/working/wav_file{i}.wav')\n    \n    if len(audio.shape) == 2:\n        audio = audio[:, 0]\n    # Generate a melspectrogram with 256 mels.\n\n    \n    if row.site[0] != 'site3':\n        audio_id_seconds = np.array(row.seconds)\n        audio_id_row_ids = np.array(row.row_id)\n\n        sorted_ids = np.argsort(audio_id_seconds)\n        audio_id_seconds = audio_id_seconds[sorted_ids].astype('int')\n        audio_id_row_ids = audio_id_row_ids[sorted_ids]\n    \n        start_second = 0\n        for j in range(len(row.row_id)):\n            if row.site[0] != 'site3':\n                clip = audio[start_second * sr: audio_id_seconds[j] * sr]\n                start_second = audio_id_seconds[j]\n            else:\n                clip = audio\n            clip = np.pad(clip, (0, 576000 - len(clip))).astype('float32')\n            mel = librosa.feature.melspectrogram(clip, sr=sr, n_mels=128)\n            mel = (mel - mel.mean()) / (mel.std() + 1e-12)\n            mel = mel[None, None, ...]\n            y_pred = model(torch.tensor(mel).to(device)).detach().cpu().sigmoid().numpy().squeeze()\n            if np.any(y_pred > 0.2):\n                row_id_birds[row.row_id[j]] = ' '.join(ebird_codes[(y_pred > 0.2).astype('bool')].tolist())\n            else: \n                row_id_birds[row.row_id[j]] = 'nocall'\n    else:\n        labels = []\n        for j in range(0, len(audio), 576000):\n            clip = audio[j: j + 576000]\n            clip = np.pad(clip, (0, 576000 - len(clip))).astype('float32')\n            mel = librosa.feature.melspectrogram(clip, sr=sr, n_mels=128)\n            mel = (mel - mel.mean()) / (mel.std() + 1e-12)\n            mel = mel[None, None, ...]\n            y_pred = model(torch.tensor(mel).to(device)).detach().cpu().sigmoid().numpy().squeeze()\n            if np.any(y_pred > 0.8):\n                labels += ebird_codes[(y_pred > 0.8).astype('bool')].tolist()\n        if len(labels) == 0:\n            row_id_birds[row.row_id[j]] = 'nocall'\n        else:\n            row_id_birds[row.row_id[j]] = ' '.join(labels)\n#     !rm wav_file{i}.wav","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"row_id_birds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({\n    'row_id': test_df.row_id.values,\n    'birds': [row_id_birds[row_id] for row_id in test_df.row_id.values]\n})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}