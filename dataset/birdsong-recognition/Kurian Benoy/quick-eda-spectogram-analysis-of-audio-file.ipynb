{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Importing libraries","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import librosa\nimport librosa.display\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport IPython\nimport scipy\n\n\nfrom IPython.display import Audio\nfrom IPython.core.display import HTML\nfrom pandas_profiling import ProfileReport\nfrom scipy.io import wavfile","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Quick peek at the markdown","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# no of bird classes\n! ls /kaggle/input/birdsong-recognition/train_audio/ | wc -l","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/birdsong-recognition/train.csv')\ntest = pd.read_csv('/kaggle/input/birdsong-recognition/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_summary = pd.read_csv('/kaggle/input/birdsong-recognition/example_test_audio_summary.csv')\ntrain_summary.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Quick EDA\n\nusing pandas profile report","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_profile = ProfileReport(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_profile.to_widgets()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# Press the output to see the complete report\ntrain_profile","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Analysing the sound with EDA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Audio('/kaggle/input/birdsong-recognition/train_audio/eawpew/XC148566.mp3')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- loading audio with librosa\n- finding beat_time","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y, sr = librosa.load('/kaggle/input/birdsong-recognition/train_audio/eawpew/XC148566.mp3')\ntempo, beat_frames = librosa.beat.beat_track(y=y, sr=sr)\n\nprint('Estimated tempo: {:.2f} beats per minute'.format(tempo))\n\nbeat_times = librosa.frames_to_time(beat_frames, sr=sr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- find sample_rate\n- find signal_length\n- duration","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Sample rate  :\", sr)\nprint(f\"Signal Length:{len(y)}\")\nprint(f\"Duration     : {len(y)/sr}seconds\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 5))\nlibrosa.display.waveplot(y, sr=sr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Spectogram\n\n- checking what is characteristics of frequency","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sg0 = librosa.stft(y)\nsg_mag, sg_phase = librosa.magphase(sg0)\ndisplay(librosa.display.specshow(sg_mag))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sg1 = librosa.feature.melspectrogram(S=sg_mag, sr=sr)\ndisplay(librosa.display.specshow(sg1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sg2 = librosa.amplitude_to_db(sg1, ref=np.min)\nlibrosa.display.specshow(sg2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## What's inside a spectogram","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# code adapted from the librosa.feature.melspectrogram documentation\nlibrosa.display.specshow(sg2, sr=16000, y_axis='mel', fmax=8000, x_axis='time')\nplt.colorbar(format='%+2.0f dB')\nplt.title('Mel spectrogram')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sg2.min(), sg2.max(), sg2.mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fourier Transformation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Code adapted from https://musicinformationretrieval.com/fourier_transform.html and the original\n# implementation of fastai audio by John Hartquist at https://github.com/sevenfx/fastai_audio/\ndef fft_and_display(signal, sr):\n    ft = scipy.fftpack.fft(signal, n=len(signal))\n    ft = ft[:len(signal)//2+1]\n    ft_mag = np.absolute(ft)\n    f = np.linspace(0, sr/2, len(ft_mag)) # frequency variable\n    plt.figure(figsize=(13, 5))\n    plt.plot(f, ft_mag) # magnitude spectrum\n    plt.xlabel('Frequency (Hz)')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fft_and_display(y, sr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Making a submission","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv('/kaggle/input/birdsong-recognition/sample_submission.csv')\nsub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}