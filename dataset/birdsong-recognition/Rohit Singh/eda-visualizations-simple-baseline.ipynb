{"cells":[{"metadata":{},"cell_type":"markdown","source":"## 1. Introduction \n\n* There are already many projects underway to extensively monitor birds by continuously recording natural soundscapes over long periods. However, as many living and nonliving things make noise, the analysis of these datasets is often done manually by domain experts. These analyses are painstakingly slow, and results are often incomplete.\n\n\n* In this competition, you will identify a wide variety of bird vocalizations in soundscape recordings. Due to the complexity of the recordings, they contain weak labels. There might be anthropogenic sounds (e.g., airplane overflights) or other bird and non-bird (e.g., chipmunk) calls in the background, with a particular labeled bird species in the foreground. Bring your new ideas to build effective detectors and classifiers for analyzing complex soundscape recordings!\n\n\n### Which bird is this?\n\n![](https://partnersinflight.org/wp-content/uploads/2017/03/Bird-Collage-PIF.png)\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 2. Preliminaries\n\n#### Now Let's Begin by Importing the data\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"! pip install -q pydub","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\n\n\nimport random\nimport seaborn as sns\nimport cv2\n# General packages\nimport pandas as pd\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport PIL\nimport IPython.display as ipd\nimport glob\nimport h5py\nimport plotly.graph_objs as go\nimport plotly.express as px\nfrom scipy import signal\nfrom scipy.io import wavfile\nfrom PIL import Image\nfrom scipy.fftpack import fft\nfrom pydub import AudioSegment\nfrom tempfile import mktemp\n\nfrom bokeh.layouts import column, row\nfrom bokeh.models import ColumnDataSource, LinearAxis, Range1d\nfrom bokeh.models.tools import HoverTool\nfrom bokeh.palettes import BuGn4\nfrom bokeh.plotting import figure, output_notebook, show\nfrom bokeh.transform import cumsum\nfrom math import pi\n\noutput_notebook()\n\n\nfrom IPython.display import Image, display\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('../input/birdsong-recognition/')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loading Dataset\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"BASE_PATH = '../input/birdsong-recognition'\n\n# image and mask directories\ntrain_data_dir = f'{BASE_PATH}/train_audio'\ntest_data_dir = f'{BASE_PATH}/example_test_audio'\n\nprint('Reading data...')\ntest_audio_metadata = pd.read_csv(f'{BASE_PATH}/example_test_audio_metadata.csv')\ntest_audio_summary = pd.read_csv(f'{BASE_PATH}/example_test_audio_summary.csv')\n\ntrain = pd.read_csv(f'{BASE_PATH}/train.csv')\ntest = pd.read_csv(f'{BASE_PATH}/test.csv')\nsubmission = pd.read_csv(f'{BASE_PATH}/sample_submission.csv')\n\n\nprint('Reading data completed')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The dataset comprises of following important files:\n\n\n1. **train_audio**:  The train data consists of short recordings of individual bird calls generously uploaded by users of [xenocanto.org](https://www.xeno-canto.org/)\n\n2. **test_audio**:  The hidden test set audio data.\n\n\n3. **test.csv**:  Only the first three rows are available for download; the full test.csv is in the hidden test set.\n\n    * `site`: Site ID.\n    * `row_id`: ID code for the row.\n    * `seconds`: the second ending the time window, if any. Site 3 time windows cover the entire audio file and have null entries for seconds.\n    * `audio_id`: ID code for the audio file.\n\n4. **example_test_audio_metadata.csv**:  Complete metadata for the example test audio. These labels have higher time precision than is used for the hidden test set.\n\n5. **example_test_audio_summary.csv**:  Metadata for the example test audio, converted to the same format as used in the hidden test set.\n\n    * `filename_seconds`: a row identifier.\n    * `birds`: all ebird codes present in the time window.\n    * `filename`: name of file\n    * `seconds`: the second ending the time window.\n\n6. **train.csv**:  A wide range of metadata is provided for the training data. The most directly relevant fields are:\n\n    * `ebird_code`: a code for the bird species. You can review detailed information about the bird codes by appending the code to https://ebird.org/species/, such as https://ebird.org/species/amecro for the American Crow.\n    * `recodist`: the user who provided the recording.\n    * `location`: where the recording was taken. Some bird species may have local call 'dialects', so you may want to seek geographic diversity in your training data.\n    * `date`: while some bird calls can be made year round, such as an alarm call, some are restricted to a specific season. You may want to seek temporal diversity in your training data.\n    * `filename`: the name of the associated audio file.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"display(train.head())\nprint(\"Shape of train_data :\", train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(test.head())\nprint(\"Shape of test :\", test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(test_audio_metadata.head())\nprint(\"Shape of test_audio_metadata :\", test_audio_metadata.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(test_audio_summary.head())\nprint(\"Shape of test_audio_metadata :\", test_audio_summary.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Checking for Null values\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def check_null_values(df):\n    # checking missing data\n    total = df.isnull().sum().sort_values(ascending = False)\n    percent = (df.isnull().sum()/df.isnull().count()*100).sort_values(ascending = False)\n    missing_data  = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    return missing_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**train.csv**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"check_null_values(train).head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**inference**\n* column `background` has a lot of null values, almost 61%\n* column `description`, `playback_used` and `bird_seen` also has significant amount of null values.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**test.csv**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"check_null_values(test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**example_test_audio_metadata.csv**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"check_null_values(test_audio_metadata).head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**example_test_audio_summary.csv**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"check_null_values(test_audio_summary)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Before starting EDA let's checkout few audio samples","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_audio = [\n    'aldfly/XC134874.mp3',\n    'amegfi/XC109299.mp3',\n    'brebla/XC104521.mp3',\n    'lewwoo/XC161334.mp3',\n    'macwar/XC125970.mp3',\n    'norwat/XC124175.mp3',\n    'pinjay/XC153392.mp3',\n    'rufhum/XC133552.mp3',\n    'weskin/XC124287.mp3',\n    'yetvir/XC120867.mp3'    \n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for audio in sample_audio:\n    print(\"Audio sample of bird\", audio.split('/')[0])\n    display(ipd.Audio(f\"{train_data_dir}/{audio}\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Let's perform some EDA\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 4.1 Plotting distribution of birds based on latitude and longitude","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.scatter(data_frame=train, x='longitude', y='latitude', color='ebird_code')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.2 Plotting number of samples in train_audio folder\n\nPulling an audio sample from each bird\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_audio = []\ntotal = 0\n\nbird_audio_folders = [ folder for folder in glob.glob(f'{train_data_dir}/*')]\nbirds_data = []\n\nfor folder in bird_audio_folders:\n    # get all the wave files\n    all_files = [y for y in os.listdir(folder) if '.mp3' in y]\n    total += len(all_files)\n    # collect the first file from each dir\n    sample_audio.append(folder + '/'+ all_files[0])\n    birds_data.append({'bird_name': folder.split('/')[-1], 'num_audio_samples': len(all_files)})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"birds_sample_df = pd.DataFrame(data= birds_data)\n# taking first 25 samples from birds_sample_df\nbirds_sample_df_top30 = birds_sample_df.sample(30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\n# df = px.data.tips()\nfig = px.bar(birds_sample_df_top30, x=\"num_audio_samples\", y=\"bird_name\",color='bird_name', orientation='h',\n             hover_data=[\"num_audio_samples\", \"bird_name\"],\n             height=800,\n             title='Number of audio samples in tarin data')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.ebird_code.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**inference**\n\n* number of samples of each bird can vary from 9 to 100\n* most of the birds has number of recordings equal to 100\n* only a single bird named `redhea` has number of recordings less than 10","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 4.3 Distribution of number of recordings based on country","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# displaying only the top 30 countries\ncountry = train.country.value_counts()\ncountry_df = pd.DataFrame({'country':country.index, 'frequency':country.values}).head(30)\n\nfig = px.bar(country_df, x=\"frequency\", y=\"country\",color='country', orientation='h',\n             hover_data=[\"country\", \"frequency\"],\n             height=1000,\n             title='Number of audio samples besed on country of recording')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**inference**\n* Most of the voice samples are recorded in `USA`, `Canada` and `Mexico`.\n* While some samples are also recorded in countries like `Belgium`, `Panama`, etc. That may be because of the availability of some bird species limited to these countries only.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 4.4 Checking for datetime features\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"##datetime feature section is inspired from this notebook, olease upvote it too\n## https://www.kaggle.com/rohanrao/birdcall-eda-chirp-hoot-and-flutter\n\n## let's create some datafremes \n\ndf_date = train.groupby(\"date\")[\"species\"].count().reset_index().rename(columns = {\"species\": \"recordings\"})\ndf_date.date = pd.to_datetime(df_date.date, errors = \"coerce\")\ndf_date.dropna(inplace = True)\ndf_date[\"weekday\"] = df_date.date.dt.day_name()\n\n\ntrain[\"hour\"] = pd.to_numeric(train.time.str.split(\":\", expand = True)[0], errors = \"coerce\")\ndf_hour = train[~train.hour.isna()].groupby(\"hour\")[\"species\"].count().reset_index().rename(columns = {\"species\": \"recordings\"})\n\n\ndf_weekday = df_date.groupby(\"weekday\")[\"recordings\"].sum().reset_index().sort_values(\"recordings\", ascending = False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# source 1\nsource_1 = ColumnDataSource(df_date)\ntooltips_1 = [ (\"Date\", \"@date{%F}\"), (\"Recordings\", \"@recordings\")]\nformatters = { \"@date\": \"datetime\" }\n\nv1 = figure(plot_width = 800, plot_height = 450, x_axis_type = \"datetime\", title = \"Date of recording\")\nv1.line(\"date\", \"recordings\", source = source_1, color = \"red\", alpha = 0.6)\n\nv1.add_tools(HoverTool(tooltips = tooltips_1, formatters = formatters))\n\nv1.xaxis.axis_label = \"Date\"\nv1.yaxis.axis_label = \"Recordings\"\n\n\n# source 2\nsource_2 = ColumnDataSource(df_hour)\n\ntooltips_2 = [\n    (\"Hour\", \"@hour\"),\n    (\"Recordings\", \"@recordings\")\n]\n\nv2 = figure(plot_width = 400, plot_height = 400, tooltips = tooltips_2, title = \"Hour of recording\")\nv2.vbar(\"hour\", top = \"recordings\", source = source_2, width = 0.75, color = \"blue\", alpha = 0.6)\n\nv2.xaxis.axis_label = \"Hour of day\"\nv2.yaxis.axis_label = \"Recordings\"\n\n\n# source 3\nsource_3 = ColumnDataSource(df_weekday)\n\ntooltips_3 = [\n    (\"Weekday\", \"@weekday\"),\n    (\"Recordings\", \"@recordings\")\n]\n\nv3 = figure(plot_width = 400, plot_height = 400, x_range = df_weekday.weekday.values, tooltips = tooltips_3, title = \"Weekday of recording\")\nv3.vbar(\"weekday\", top = \"recordings\", source = source_3, width = 0.75, color = \"blue\", alpha = 0.6)\n\nv3.xaxis.axis_label = \"Day of week\"\nv3.yaxis.axis_label = \"Recordings\"\n\nv3.xaxis.major_label_orientation = pi / 2\n\n\nshow(column(v1, row(v2, v3)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**inference**\n* Most of the recordings are taken after `year 2012`, but there are few recordings as old as of `year 1980`, they may or may not be outliers\n\n* Majority of the recordings have taken place durin the early hours of the day (6am - 11am).\n\n* Number of recordings taken on weekends are much greater than the number of recordings taken on weekdays.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 4.5 Comparing Spectrograms for different birds\n\n\nA **spectrogram** is a visual representation of the spectrum of frequencies of a signal as it varies with time. When applied to an audio signal, spectrograms are sometimes called **sonographs**, **voiceprints**, or **voicegrams**. When the data is represented in a 3D plot they may be called **waterfalls**.\n\nTo know more about spectograms please visit https://en.wikipedia.org/wiki/Spectrogram\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def log_specgram(audio, sample_rate, window_size=20,\n                 step_size=10, eps=1e-10):\n    nperseg = int(round(window_size * sample_rate / 1e3))\n    noverlap = int(round(step_size * sample_rate / 1e3))\n    \n    freqs, _, spec = signal.spectrogram(audio,\n                                    fs=sample_rate,\n                                    window='hann',\n                                    nperseg=nperseg,\n                                    noverlap=noverlap,\n                                    detrend=False)\n    return freqs, np.log(spec.T.astype(np.float32) + eps)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"spect_samples = [\n    'aldfly/XC134874.mp3',\n    'ameavo/XC133080.mp3',\n    'amecro/XC109768.mp3',\n    'amepip/XC111040.mp3',\n    'amewig/XC150063.mp3',\n    'astfly/XC109920.mp3',\n    'balori/XC101614.mp3',\n    'bkbmag1/XC114081.mp3',\n    'bkpwar/XC133993.mp3',\n    'bnhcow/XC113821.mp3',\n    'btnwar/XC101591.mp3',\n    'carwre/XC109026.mp3',\n    'chswar/XC101586.mp3',\n    'evegro/XC110121.mp3',\n    'greegr/XC109029.mp3',\n    'hamfly/XC122665.mp3',\n    'hoomer/XC134692.mp3',\n    'horlar/XC113144.mp3',\n    'lesgol/XC116239.mp3',\n    'macwar/XC113825.mp3',\n    'norfli/XC104536.mp3',\n    'orcwar/XC113131.mp3',\n    'pibgre/XC109907.mp3',\n    'rebnut/XC104516.mp3',\n    'ruckin/XC127130.mp3'    \n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(22,22))\nplt.suptitle('comparing spectograms for different birds', fontsize=20)\n\n\nfor i, filepath in enumerate(spect_samples):\n    # Make subplots\n    plt.subplot(5,5,i+1)\n    bird_name, file_name = filepath.split('/')\n    plt.title(f\"Bird name: {bird_name}\\nfile_name: {file_name}\")\n    # create spectogram\n    mp3_audio = AudioSegment.from_file(f'{train_data_dir}/{filepath}', format=\"mp3\")  # read mp3\n    wname = mktemp('.wav')  # use temporary file\n    mp3_audio.export(wname, format=\"wav\")  # convert to wav\n    \n    samplerate, test_sound  = wavfile.read(wname)\n    _, spectrogram = log_specgram(test_sound, samplerate)\n    plt.imshow(spectrogram.T, aspect='auto', origin='lower')\n    plt.axis('off')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.6 Comparing Spectrograms for same bird (aldfly)\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"aldfly_samples = [\n 'aldfly/XC157462.mp3',\n 'aldfly/XC318444.mp3',\n 'aldfly/XC374636.mp3',\n 'aldfly/XC189268.mp3',\n 'aldfly/XC296725.mp3',\n 'aldfly/XC167789.mp3',\n 'aldfly/XC373885.mp3',\n 'aldfly/XC188432.mp3',\n 'aldfly/XC189264.mp3',\n 'aldfly/XC154449.mp3',\n 'aldfly/XC189269.mp3',\n 'aldfly/XC2628.mp3',\n 'aldfly/XC420909.mp3',\n 'aldfly/XC179600.mp3',\n 'aldfly/XC188434.mp3',\n 'aldfly/XC264715.mp3',\n 'aldfly/XC189262.mp3',\n 'aldfly/XC139577.mp3',\n 'aldfly/XC16967.mp3',\n 'aldfly/XC189263.mp3',\n 'aldfly/XC318899.mp3',\n 'aldfly/XC193116.mp3',\n 'aldfly/XC269063.mp3',\n 'aldfly/XC180091.mp3',\n 'aldfly/XC381871.mp3',\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(22,22))\nplt.suptitle('comparing spectograms for same bird', fontsize=20)\n\nfor i, filepath in enumerate(aldfly_samples):\n    # Make subplots\n    plt.subplot(5,5,i+1)\n    bird_name, file_name = filepath.split('/')\n    plt.title(f\"Bird name: {bird_name}\\nfile_name: {file_name}\")\n    \n    # create spectogram\n    mp3_audio = AudioSegment.from_file(f\"{train_data_dir}/\" + filepath, format=\"mp3\")  # read mp3\n    wname = mktemp('.wav')  # use temporary file\n    mp3_audio.export(wname, format=\"wav\")  # convert to wav\n    \n    samplerate, test_sound  = wavfile.read(wname)\n    _, spectrogram = log_specgram(test_sound, samplerate)\n    \n    plt.imshow(spectrogram.T, aspect='auto', origin='lower')\n    plt.axis('off')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.7 Comparing waveforms for different birds","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(22,22))\nplt.suptitle('comparing waveforms for different bird', fontsize=20)\n\n\nfor i, filepath in enumerate(spect_samples):\n    # Make subplots\n    plt.subplot(5,5,i+1)\n    bird_name, file_name = filepath.split('/')\n    plt.title(f\"Bird name: {bird_name}\\nfile_name: {file_name}\")\n    # create spectogram\n    mp3_audio = AudioSegment.from_file(f'{train_data_dir}/{filepath}', format=\"mp3\")  # read mp3\n    wname = mktemp('.wav')  # use temporary file\n    mp3_audio.export(wname, format=\"wav\")  # convert to wav\n    \n    samplerate, test_sound  = wavfile.read(wname)\n    plt.plot(test_sound, '-', )\n    plt.axis('off')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.8 Comparing waveforms for same bird (aldfly)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(22,22))\nplt.suptitle('comparing waveforms for aldfly bird', fontsize=20)\n\nfor i, filepath in enumerate(aldfly_samples):\n    # Make subplots\n    plt.subplot(5,5,i+1)\n    bird_name, file_name = filepath.split('/')\n    plt.title(f\"Bird name: {bird_name}\\nfile_name: {file_name}\")\n    \n    # create spectogram\n    mp3_audio = AudioSegment.from_file(f\"{train_data_dir}/\" + filepath, format=\"mp3\")  # read mp3\n    wname = mktemp('.wav')  # use temporary file\n    mp3_audio.export(wname, format=\"wav\")  # convert to wav\n    \n    samplerate, test_sound  = wavfile.read(wname)\n    plt.plot(test_sound, '-', )\n    plt.axis('off')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4.9 Plotting waveform and spectogram side by side for better comparison","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"duplicate_samples = []\nfor val in spect_samples[:5]:\n    duplicate_samples.append(val)\n    duplicate_samples.append(val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(22,22))\nplt.suptitle('comparing spectograms with waveforms for same bird', fontsize=20)\n\n\nfor i, filepath in enumerate(duplicate_samples):\n    # Make subplots    \n    plt.subplot(5,2,i+1)\n    bird_name, file_name = filepath.split('/')\n    plt.title(f\"Bird name: {bird_name}\\nfile_name: {file_name}\")\n    # create spectogram\n    mp3_audio = AudioSegment.from_file(f'{train_data_dir}/{filepath}', format=\"mp3\")  # read mp3\n    wname = mktemp('.wav')  # use temporary file\n    mp3_audio.export(wname, format=\"wav\")  # convert to wav\n    \n    samplerate, test_sound  = wavfile.read(wname)\n    _, spectrogram = log_specgram(test_sound, samplerate)\n\n    if i % 2 == 0:\n        plt.imshow(spectrogram.T, aspect='auto', origin='lower')  \n    else:\n        plt.plot(test_sound, '-', )\n    \n    plt.axis('off')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5. Baseline submission","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* by just submitting `nocall` we get a LB score 0.54, which suggests 54% of data in public test set has no bird voice at all. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# References\n\n* https://en.wikipedia.org/wiki/Spectrogram\n* https://www.kaggle.com/timolee/audio-data-conversion-to-images-eda\n* https://www.kaggle.com/rohanrao/birdcall-eda-chirp-hoot-and-flutter","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# END NOTES\nThis notebook is work in progress. \nI will keep on updating this kernel with my new findings and learning in order to help everyone who has just started in this competition.\n\n**<span style=\"color:Red\">Please upvote this kernel if you like it . It motivates me to produce more quality content :)**  ","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}