{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!cd /kaggle/input/audio2numpy\n!cp -r /kaggle/input/audio2numpy/* ./\nfrom audio2numpy import open_audio","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\n\nimport keras\nimport tensorflow.keras.layers as L\nfrom tensorflow.keras.models import Model\nimport tensorflow as tf \n\nimport glob as glob\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score\n\nfrom joblib import Parallel, delayed\nfrom tqdm import tqdm_notebook\n\nfrom scipy.sparse import csr_matrix\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom transformers import BertConfig,TFBertModel,BertModel\n\nimport gc\nimport librosa","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"NUM_BINS = 512\nMAX_LEN = 512\ndef audio_read(path):\n    recording, sr = open_audio(path)\n    \n    if recording.shape[0] != recording.size:\n        return recording.mean(axis=1) \n    else:\n        return recording\n############################################################\ndef tokenize(path, NUM_BINS = NUM_BINS,MAX_LEN=MAX_LEN):\n    signal = np.resize(audio_read(path), (MAX_LEN,))\n    signal_bins = np.linspace(signal.min(), signal.max(), NUM_BINS + 1)\n    signal = np.digitize(signal, bins=signal_bins) - 1 \n    signal = np.minimum(signal, NUM_BINS - 1)\n    return signal.astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def tokenize_list(lis, NUM_BINS = NUM_BINS,MAX_LEN=MAX_LEN):\n    signals = np.array([Parallel(n_jobs=4)(delayed(tokenize)(filename) for filename in tqdm_notebook(train_audio[:max_len]))])[0]   \n    return signals","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model(MAX_LEN = MAX_LEN, NUM_BINS = NUM_BINS):\n    ids = L.Input((MAX_LEN,), dtype=tf.int32)\n    config = BertConfig() \n    config.vocab_size = NUM_BINS\n    config.num_hidden_layers = 3\n    bert_model = TFBertModel(config=config)\n\n    x = bert_model(ids)[0]\n    x = L.Flatten()(x)\n    x = L.Dense(264,activation='softmax')(x)\n    \n    model = Model(inputs=ids, outputs=x)\n#     optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n    model.compile(loss='categorical_crossentropy', optimizer='adam',metrics = 'accuracy')\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = build_model()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_audio = []\nfor directory in sorted(glob.glob('/kaggle/input/birdsong-recognition/train_audio/*')):\n    train_audio.extend(sorted(glob.glob(directory+'/*')))\ntrain_audio = np.array(train_audio)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_len = len(train_audio)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#1h 19m for all 21_000\nX = np.array([Parallel(n_jobs=4)(delayed(tokenize)(filename) for filename in tqdm_notebook(train_audio[:max_len]))])[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Preprocess dataset and create validation sets\nle = LabelEncoder()\nseed = 43\ntrain = pd.read_csv('/kaggle/input/birdsong-recognition/train.csv')\nle.fit(train['ebird_code'])\nY = pd.get_dummies(train['ebird_code'])[:X.shape[0]].values.reshape((-1,264)).astype(int)\ny = pd.Series(le.fit_transform(train['ebird_code'])[:X.shape[0]].ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.shape,Y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with tf.device('/gpu:0'):\n    model.fit(X,Y,epochs=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_preds = model.predict(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(np.argmax(Y,axis=1),np.argmax(val_preds,axis=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/birdsong-recognition/test.csv')\nTEST_FOLDER = '../input/birdsong-recognition/test_audio/'\ntry:\n    print('predicting')\n    preds = []\n    for index, row in test.iterrows():\n        # Get test row information\n        site = row['site']\n        start_time = row['seconds'] - 5\n        row_id = row['row_id']\n        audio_id = row['audio_id']\n\n        # Get the test sound clip\n        if site == 'site_1' or site == 'site_2':\n            x = tokenize(TEST_FOLDER + audio_id + '.mp3')\n        else:\n            x = tokenize(TEST_FOLDER + audio_id + '.mp3')\n        \n#         x = extract_features(TEST_FOLDER + audio_id + '.mp3').reshape(1, -1)\n        # Make the prediction\n        pred = le.inverse_transform(np.argmax(model.predict(x).flatten(),axis=1))\n#         pred = le.inverse_transform(clf.predict(nan_remove(x.flatten().reshape(1, -1))))\n#         print(pred)\n        # Store prediction\n        preds.append([row_id, pred])\nexcept:\n     preds = pd.read_csv('../input/birdsong-recognition/sample_submission.csv')\n        \npreds = pd.DataFrame(preds, columns=['row_id', 'birds'])\npreds.to_csv('submission.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}