{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom sklearn.preprocessing import LabelEncoder\nimport IPython.display as ipd\nimport matplotlib.pyplot as plt\n!pip install librosa \nimport librosa\nimport librosa.display","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/birdsong-recognition/train.csv')\nprint(f'Dataframe has {len(df)} rows')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le = LabelEncoder()\nfig = go.Figure(data=go.Scattergeo(lat=df['latitude'], \n                     lon=df['longitude'], hovertext=df['species'], marker_color=le.fit_transform(df['species'])))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dates = df['date'].value_counts().sort_index()\nfig = go.Figure([go.Scatter(x=dates[4:].index, y=dates[4:].values)])\nfig.update_layout(title='Quantity of birds recorded over time')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"species = df['species'].value_counts()\nfig = go.Figure(data=[\n    go.Bar(y=species.values, x=species.index)\n])\n\nfig.update_layout(title='Distribution of Bird Species')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"durations = df['duration'].value_counts()\nfig = go.Figure(data=[\n    go.Bar(y=durations.values, x=durations.index, marker_color='deeppink')\n])\n\nfig.update_layout(title='Distribution of durations in seconds')\nfig.update_xaxes(range=[0, 500])\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_dir = '../input/birdsong-recognition/train_audio/'\ndf['full_path'] = base_dir + df['ebird_code'] + '/' + df['filename']\n\n# Now let's sample a fiew audio files\namered = df[df['ebird_code'] == \"amered\"].sample(1, random_state = 33)['full_path'].values[0]\ncangoo = df[df['ebird_code'] == \"cangoo\"].sample(1, random_state = 33)['full_path'].values[0]\nhaiwoo = df[df['ebird_code'] == \"haiwoo\"].sample(1, random_state = 33)['full_path'].values[0]\npingro = df[df['ebird_code'] == \"pingro\"].sample(1, random_state = 33)['full_path'].values[0]\nvesspa = df[df['ebird_code'] == \"vesspa\"].sample(1, random_state = 33)['full_path'].values[0]\n\nbird_sample_list = [\"amered\", \"cangoo\", \"haiwoo\", \"pingro\", \"vesspa\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ipd.Audio(amered)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ipd.Audio(cangoo)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ipd.Audio(haiwoo)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ipd.Audio(pingro)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y, sr = librosa.load(vesspa)\naudio_file, _ = librosa.effects.trim(y)\ny_amered, sr_amered = librosa.load(amered)\naudio_amered, _ = librosa.effects.trim(y_amered)\n\ny_cangoo, sr_cangoo = librosa.load(cangoo)\naudio_cangoo, _ = librosa.effects.trim(y_cangoo)\n\ny_haiwoo, sr_haiwoo = librosa.load(haiwoo)\naudio_haiwoo, _ = librosa.effects.trim(y_haiwoo)\n\ny_pingro, sr_pingro = librosa.load(pingro)\naudio_pingro, _ = librosa.effects.trim(y_pingro)\n\ny_vesspa, sr_vesspa = librosa.load(vesspa)\naudio_vesspa, _ = librosa.effects.trim(y_vesspa)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(5, figsize = (16, 9))\nfig.suptitle('Sound Waves', fontsize=16)\n\nlibrosa.display.waveplot(y = audio_amered, sr = sr_amered, color = \"#A300F9\", ax=ax[0])\nlibrosa.display.waveplot(y = audio_cangoo, sr = sr_cangoo, color = \"#4300FF\", ax=ax[1])\nlibrosa.display.waveplot(y = audio_haiwoo, sr = sr_haiwoo, color = \"#009DFF\", ax=ax[2])\nlibrosa.display.waveplot(y = audio_pingro, sr = sr_pingro, color = \"#00FFB0\", ax=ax[3])\nlibrosa.display.waveplot(y = audio_vesspa, sr = sr_vesspa, color = \"#D9FF00\", ax=ax[4]);\n\nfor i, name in zip(range(5), bird_sample_list):\n    ax[i].set_ylabel(name, fontsize=13)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}