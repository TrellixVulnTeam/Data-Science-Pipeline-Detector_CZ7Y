{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import librosa,librosa.display\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline\nimport numpy, scipy, matplotlib.pyplot as plt, IPython.display as ipd\n#import stanford_mir; stanford_mir.init()\nfrom ipywidgets import interact\nfrom tqdm.notebook import tqdm\nimport glob\nimport joblib\nimport pandas as pd\nimport os\nimport tarfile\nimport numpy as np\nfrom pathlib import Path","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/birdsong-recognition/train.csv')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/birdsong-recognition/test.csv')\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv('../input/birdsong-recognition/sample_submission.csv')\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_audio = pd.read_csv('../input/birdsong-recognition/example_test_audio_summary.csv')\ntest_audio[80:100]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_audio.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_meta = pd.read_csv('../input/birdsong-recognition/example_test_audio_metadata.csv')\ntest_meta[123:145]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_meta.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y,sr = librosa.load('../input/birdsong-recognition/train_audio/aldfly/XC134874.mp3')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to display the audio\nipd.Audio(y, rate=sr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The sample rate is 22050 which means that the recorder was recording 22050 times per second.\nprint(\"sampling rate :\",sr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The y.shape = (562011,) which means that there were 562011 samples recorded on just one channel (Mono) over the whole audio.\nprint(y.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using simple math, you can calculate the duration of this audio file by dividing the total_number_of_samples over the sample_rate\nprint(\"duration of audio file :\",y.shape[0]/sr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tempo, beat_frames = librosa.beat.beat_track(y=y, sr=sr)\nprint(tempo)\nprint(beat_frames)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"converts the frame numbers beat_frames into timings:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"beat_times = librosa.frames_to_time(beat_frames, sr=sr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"beat_times","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plot the beat locations over the waveform:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14, 5))\nlibrosa.display.waveplot(y, alpha=0.6)\nplt.vlines(beat_times, -1, 1, color='r')\nplt.ylim(-1, 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plot a histogram of the intervals between adjacent beats:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"beat_times_diff = numpy.diff(beat_times)\nplt.figure(figsize=(14, 5))\nplt.hist(beat_times_diff, bins=50, range=(0,4))\nplt.xlabel('Beat Length (seconds)')\nplt.ylabel('Count')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hop_length = 512","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"22050/512","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separate harmonics and percussives into two waveforms\ny_harmonic, y_percussive = librosa.effects.hpss(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_percussive.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"By Default, the Mel-scaled power spectrogram window and hop length are the following:\n\nn_fft=2048\n\nhop_length=512","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"So assuming you used the default sample rate (sr=22050), the output of your mfcc function makes sense:\n\noutput length = (seconds) * (sample rate) / (hop_length)\n\n(1319) * (22050) / (512) = 56804 samples","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#mel_feat = librosa.feature.melspectrogram(y=y, sr=sr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#mel_feat.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mfcc = librosa.feature.mfcc(y=y, sr=sr, hop_length=hop_length, n_mfcc=13)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mfcc.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(25.488*22050)/512","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''train_dir = '../input/birdsong-recognition/train_audio'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''diff_birds = os.listdir(train_dir)'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''len(diff_birds)'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''diff_birds[0]'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''list_mfcc = []\ny_label = []'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#hop_length = 1024","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''def calculate_mfcc(audio):\n    # Load the example clip\n    y, sr = librosa.load(audio)\n    \n    # Compute MFCC features from the raw signal\n    mfcc = librosa.feature.mfcc(y=y, sr=sr, hop_length=hop_length, n_mfcc=10)\n    return mfcc'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''n_jobs=4\nverbose=1'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''for bird in tqdm(diff_birds):\n    filelist = glob.glob(os.path.join(train_dir + '/' + bird,'*.mp3'))\n    y_label.append([bird]*len(filelist))\n    #for audio in filelist:\n    mfcc_feature = [joblib.delayed(calculate_mfcc)(audio) for audio in filelist ]\n    out = joblib.Parallel(n_jobs=n_jobs, verbose=verbose)(mfcc_feature)\n    list_mfcc.append(out)'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_audio(filename):\n    try:\n        return librosa.load(filename, sr=None)\n    except Exception as e:\n        print(f\"Cannot load '{filename}': {e}\")\n        return None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_mfcc(y, sr=22050, n_mfcc=10):\n    try:\n        return librosa.feature.mfcc(y=y, \n                                    sr=sr if sr > 0 else MFCC[\"sr\"], \n                                    n_mfcc=n_mfcc)\n    except Exception as e:\n        print(f\"Cannot extract MFCC: {e}\")\n        return None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def parse_audio(input_dir, output_file, max_per_label=10000):\n    \n    with tarfile.open(output_file, \"w:xz\") as tar:\n    \n        sub_dirs = list(input_dir.iterdir())    \n        for sub_dir in tqdm(sub_dirs):\n            print(sub_dir)\n\n            for i, mp3 in enumerate(sub_dir.glob(\"*.mp3\")):\n\n                if i >= max_per_label:\n                    break\n\n                ysr = load_audio(mp3)\n                if ysr is None:\n                    continue\n\n                mfcc = extract_mfcc(y=ysr[0], \n                                    sr=ysr[1], \n                                    n_mfcc=MFCC['n_mfcc'])\n                if mfcc is None:\n                    continue\n                \n                filename = Path(f\"{mp3.name}.npy\")\n                print(filename)\n                np.save(filename, mfcc)            \n                tar.add(filename)\n                filename.unlink()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_dir = Path('../input/birdsong-recognition/train_audio')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_file = Path('train_features.xz')\noutput_file","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_dir = Path('../input/birdsong-recognition/train_audio')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MFCC = {\n    \"sr\": 22050, # sampling rate for loading audio\n    \"n_mfcc\": 12 # number of MFCC features per frame that can fit in HDD\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"parse_audio(input_dir, output_file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}