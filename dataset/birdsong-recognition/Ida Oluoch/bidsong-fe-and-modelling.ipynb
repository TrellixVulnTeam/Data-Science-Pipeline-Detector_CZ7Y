{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import cv2 as cv\nimport audioread\nimport logging\nimport os\nimport random\nimport time\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom tqdm import tqdm\nimport pickle\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# from colored import fg, bg, attr\n\nimport librosa\nimport IPython.display\nimport numpy as np\nimport pandas as pd\nimport soundfile as sf\nfrom pydub import AudioSegment as AS\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.data as data\nfrom torch.optim import Adam\nfrom torch import FloatTensor, LongTensor, DoubleTensor\nfrom torchvision.models import resnet34\n# from facenet_pytorch import MTCNN, InceptionResnetV1\nimport tensorflow as tf\n\nfrom contextlib import contextmanager\nfrom pathlib import Path\nfrom typing import Optional\n\n\n\nfrom fastprogress import progress_bar\nfrom sklearn.metrics import f1_score\nfrom torchvision import models, transforms\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import to_categorical\nfrom keras.preprocessing.sequence import pad_sequences as pad\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#functions for utilities\n\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\ndef set_seed(seed: int = 42):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n    \ndef get_logger(out_file=None):\n    logger = logging.getLogger()\n    formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n    logger.handlers = []\n    logger.setLevel(logging.INFO)\n#     logger.addHandler(handler)\n    \n    if out_file is not None:\n        fh = logging.FileHandler(out_file)\n        fh.setFormatter(formatter)\n        fh.setLevel(logging.INFO)\n        logger.addHandler(fh)\n    logger.info(\"logger set up\")\n    return logger\n\n@contextmanager #to ensure output of time is string\ndef timer(name: str, logger: Optional[logging.Logger] = None):\n    t0 = time.time()\n    msg = f\"[{name}] start\"\n    if logger is None:\n        print(msg)\n    else:\n        logger.info(msg)\n    yield\n    \n    msg =  f\"[{name}] done in {time.time() - t0:.2f} s\"\n    if logger is None:\n        print(msg)\n    else:\n        logger.info(msg)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logger = get_logger(\"main.log\")\nset_seed(1213)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"timer(\"time\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/birdsong-recognition/train.csv')\ntest = pd.read_csv('../input/birdsong-recognition/test.csv')\naudio_path = \"../input/birdsong-recognition/train_audio\"\nTEST = Path(\"../input/birdsong-recognition/test_audio\").exists()\n\nif TEST:\n    DATA_DIR = Path(\"../input/birdsong-recognition/\")\nelse:\n    # dataset created by @shonenkov, thanks!\n    DATA_DIR = Path(\"../input/birdcall-check/\")\n    \ntest_audio = DATA_DIR / \"test_audio\"\n\ntrain_extend = pd.read_csv(\"../input/xeno-canto-bird-recordings-extended-a-m/train_extended.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SR = 44100\nEPOCHS = 30\nMAXLEN = 100000\nCHUNK_SIZE = 10000\nCHUNKS = 3\nN_MELS = 256 #no of melspectrogram features per time step\nMEL_LEN = 1954 #total no of time steps in each melspectrogram\nDROP = 0.2\nFr = 512 #output features of resnet34","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#different kind of one hot encoding\n\nkeys = set(train[\"ebird_code\"])\nvalues = np.arange(0, len(keys))\ncode_dict = dict(zip(sorted(keys), values))\nprint(code_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"INV_BIRD_CODE = {v: k for k, v in code_dict.items()}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dirname = train[\"ebird_code\"]\nfilename = train[\"filename\"]\nbase_path = \"../input/birdsong-recognition/train_audio\"\n\nfor dirname,filename in zip(dirname, filename):\n    path = base_path + '/'+ dirname + '/'+ filename\n    size_file = os.path.getsize(path)\n    if size_file == 0:\n        print('Empty label file:', path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''spliting into train and cross-val 80% train 20% val'''\ntrain = shuffle(train)\nsplit = int(0.8*len(train))\ntrain = train.reset_index(drop = True)\nval = train[split:].reset_index(drop = True)\ntrain = train[:split].reset_index(drop = True)\n# train, val = train_test_split(train, test_size = 0.2)\nprint(len(train))\nprint(len(val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nn-mels - no of mel bands to generate\nfmin - min frequency\nfmax - max frequency\n'''\n\nmelspec_params = {\"n_mels\": 128, \"fmin\":20, \"fmax\":1600}\n\n'''\ndict with params for model \n\n'''\nmodel_config = {\"base_model_name\": \"resnet50\", \"pretrained\": False, \"num_classes\": 264 }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#defining some utility funs","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def normalize(x):\n    return np.float(x)/2**15\n\ndef read(file, norm = False):\n    try : a = AS.from_mp3(file)\n    except: return np.zeros(MAXLEN)\n    \n    y = np.array(a.get_array_of_samples())\n    if a.channels == 2: y = y.reshape((-1, 2))\n        \n    if norm: return a.frame_rate, normalize(y)\n    if not norm: return a.frame_rate, np.float32(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nn-mels - no of mel bands to generate\nfmin - min frequency\nfmax - max frequency\n'''\n\nmelspec_params = {\"n_mels\": 128, \"fmin\":20, \"fmax\":1600}\n\n'''\ndict with params for model \n\n'''\nmodel_config = {\"base_model_name\": \"resnet50\", \"pretrained\": False, \"num_classes\": 264 }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_len(length):\n    '''get the maximum length of a signal'''\n    if length > MAXLEN : return MAXLEN\n    if length <= MAXLEN : return length","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_idx(length):\n    '''select start and end index of a given audio chunk'''\n    length = get_len(length)\n    idx = np.random.randint(length + 1)\n    chunk_range = idx , idx + CHUNK_SIZE\n    chunk_idx = max([0, chunk_range[0]])\n#     chunk_idx = min([chunk_range[1], 0])\n    return (chunk_idx, chunk_idx + CHUNK_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_chunk(data, length):\n    \"\"\"takes index from chunk data and outputs a given chunk\"\"\"\n    index = get_idx(length)\n    return data[index[0]:index[1]]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_signal(data):\n    length = max(data.shape)\n    data = data.flatten().reshape(1,-1)\n    data = np.float32(pad(data, maxlen = MAXLEN).reshape(-1))\n    return [get_chunk(data, length) for _ in range(CHUNKS)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def to_tensor(data):\n    return [FloatTensor(point) for point in data]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#if submission is succesful file will be overwritten\nsub = pd.read_csv(\"../input/birdsong-recognition/sample_submission.csv\")\nsub.to_csv(\"submission.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#building a model\nclass ResNet(nn.Module):\n    '''\n    Define a class of neural networks and override the feed foward function \n    '''\n    def __init__(self, base_model_name: str,  pretrained = False, num_classes=264):\n        super().__init__()\n        base_model = models.__getattribute__(base_model_name)(pretrained = pretrained)\n        layers = list(base_model.children())[:-2]\n#         layers = []\n\n        layers.append(nn.AdaptiveMaxPool2d(1))\n        self.encoder = nn.Sequential(*layers)\n        \n        in_features = base_model.fc.in_features\n        \n        self.classifier = nn.Sequential(nn.Linear(in_features, 1024), nn.ReLU(), nn.Dropout(p=0.2), nn.ReLU(), nn.Dropout(p=0.2), nn.Linear(1024, num_classes))\n                                        \n    def forward(self, x):\n        batch_size = x.size(0)\n        x = self.encoder(x).view(batch_size, -1)#-1 is used when you are sure of the no of rows/cols but not sure of the other\n        x = self.classifier(x)\n        multiclass_prob = F.softmax(x, dim=1) #helps assign decimal values to a multi-class problem\n        multilabel_prob = F.sigmoid(x)\n        return {\"logits\": x, \"multiclass_prob\": multiclass_prob, \"multilabel_prob\": multilabel_prob}\n            \n                                        \n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class BirdNet(nn.Module):\n    def __init__(self, f, o):\n        super(BirdNet, self).__init__()\n        self.dropout = nn.Dropout(p=DROP)\n        self.dense_output = nn.Linear(f, o)\n        self.resnet = resnet34(pretrained=True)\n        self.resnet_head = list(self.resnet.children())\n        self.resnet_head = nn.Sequential(*self.resnet_head[:-1])\n\n    def forward(self, x):\n        x = self.resnet_head(x)\n        x = self.dense_output(self.dropout(x.view(-1, Fr)))\n#         print(x.shape)\n        multiclass_prob = F.softmax(x, dim=1) #helps assign decimal values to a multi-class problem\n        multilabel_prob = F.sigmoid(x)\n        return {\"logits\": x, \"multiclass_prob\": multiclass_prob, \"multilabel_prob\": multilabel_prob}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class newmodel(nn.Module):\n    def __init__(self, num_classes = 264, drpout=0.5):\n        super().__init__()\n        self.Convlayer1 = nn.Sequential(\n            nn.Conv2d(3, 8, 3),\n            nn.Conv2d(8, 16, 3),\n            nn.MaxPool2d(2),\n            nn.ReLU(),\n            nn.Dropout(drpout)\n        )\n        self.Convlayer2 = nn.Sequential(\n            nn.Conv2d(16, 32, 3),\n            nn.Conv2d(32, 32, 3),\n            nn.MaxPool2d(4),\n            nn.ReLU(),\n            nn.Dropout(drpout)\n        )\n        self.Convlayer3 = nn.Sequential(\n            nn.Conv2d(32, 64, 3),\n            nn.Conv2d(64, 64, 3),\n            nn.MaxPool2d(2),\n            nn.ReLU(),\n            nn.Dropout(drpout)\n        )\n        self.Convlayer4 = nn.Sequential(\n            nn.Conv2d(64, 128, 3),\n            nn.Conv2d(128, 256, 3),\n#             nn.MaxPool2d(3),\n            nn.ReLU(),\n            nn.Dropout(drpout)\n        )\n        \n        self.lin1 = nn.Linear(2304, 1500)\n        self.lin2 = nn.Linear(1500, num_classes)\n        \n    def forward(self, x):\n        batch_size = x.size(0)\n        x = self.Convlayer1(x)\n        x = self.Convlayer2(x)\n        x = self.Convlayer3(x)\n        x = self.Convlayer4(x)\n        x = x.view(batch_size, -1)\n        x = self.lin1(x)\n        x = self.lin2(x)\n#         y = isinstance(x, (torch.uint8, torch.unit8))\n#         print(y)\n#         multiclass_prob = F.softmax(x, dim=1) \n#         multilabel_prob = F.sigmoid(x)\n        return {\"logits\": x}\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = newmodel()\nprint(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(os.listdir(\"../input/birdsong-recognition/train_audio\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mono_to_color(X: np.ndarray, mean=None, std=None, norm_max=None, norm_min=None, eps=1e-6):\n    X = np.stack([X, X, X], axis=-1)\n    \n    #Standardize\n    mean = mean or X.mean()\n    X = X - mean\n    std = std or X.std()\n    Xstd = X / (std + eps)\n    _min, _max = Xstd.min(), Xstd.max()\n    norm_max = norm_max or _max\n    norm_min = norm_min or _min\n    \n    if (_max - _min) > eps:\n        #Normalize to [0, 255]\n        V = Xstd\n        V[V < norm_min] = norm_min\n        V[V > norm_max] = norm_max\n        V = 255 * (V - norm_min)/ (norm_max - norm_min)\n        V = V.astype(np.uint8)\n    else:\n        #return only zeros\n        V = np.zeros_like(Xstd, dtype=np.uint8)\n    return V","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = \"../input/birdsong-recognition/train_audio\"\nfilename = train[\"filename\"]\nebird_code = train[\"ebird_code\"]\ndf_two = train.filter(['filename','ebird_code'])\ndf_two.head()\n# for row in df_two.itertuples():\n#     path1 = path + '/'+ ebird_code + '/'+ filename \n#     print(path1)\n#     print(path1)\n#     arry = load_audio(path1)\n#     print(arry)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_audio(path):\n    try : y, sr = librosa.load(path, sr = SR)\n    except Exception as e:\n        \n        print(\"Error encountered while parsing file: \", path, e)\n        return np.zeros(MAXLEN)\n    \n    return y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def to_melspectogram(audio_ts):\n    melspec = librosa.feature.melspectrogram(audio_ts, sr=SR, **melspec_params)\n    melspc = librosa.power_to_db(melspec).astype(np.float32)\n    \n    return melspc\n\ndef get_melsp_img(data):\n    data = get_signal(data)\n    mel = np.stack([to_melspectogram(point) for point in data])\n    return mel","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_transform = transforms.Compose([transforms.ToTensor()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# os.remove(\"melspecs.npy\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"    class BirdDataset(data.Dataset):\n        '''class defining the birds dataset to be fed to a model to identify the\n           types of birds'''\n\n        def __init__(self, df, path, img_size=255, transform=None):\n            self.code_dict = code_dict\n            self.classes = len(code_dict)\n            self.df, self.path = df, path\n            self.dataset_length = len(df)\n            self.img_size = img_size\n            self.transform = transform\n\n        def __len__(self):\n            return self.dataset_length\n\n        def __getitem__(self, i):\n            file_name = self.df.filename[i]\n            stripped_files = os.path.splitext(file_name)[0]\n            # print(file_name)\n            ebird_code = self.df.ebird_code[i]\n            num_code = self.code_dict[ebird_code]\n            arrayvals = np.load(os.path.join(self.path, ebird_code, stripped_files + \".\" + \"npy\"))\n#             arrayvals = np.ma.masked_equal(arrayvals, 0)#assume zero values in array\n            code = to_categorical([num_code], num_classes=self.classes)\n            # return code\n            return to_tensor([arrayvals, code])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bird_dfs = BirdDataset(train , \"../input/melspecs/melspecs\", transform = data_transform)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(bird_dfs[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bird_df = data.DataLoader(bird_dfs, batch_size = 16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for step, (x, y) in enumerate(bird_df):\n#     print(x.shape)\n#     print(y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bird_train_df = BirdDataset(train, \"../input/melspecs/melspecs\", transform = data_transform)\nbird_val_df = BirdDataset(val, \"../input/melspecs/melspecs\", transform = data_transform)\n\nbird_loader_train = tqdm(data.DataLoader(bird_train_df, batch_size = 16, num_workers = 4 ))\nbird_loader_val = tqdm(data.DataLoader(bird_val_df, batch_size = 16, num_workers = 4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(bird_loader_train))\nprint(len(bird_loader_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for step, (x, y) in enumerate(bird_loader_val):\n#     print(x.shape)\n# #     print(y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# '''init the model'''\n# model1 = newmodel().to(device)\n\n# '''init optimizer'''\n# optimizer = Adam(model1.parameters(), lr = 0.001)\n# criterion = nn.CrossEntropyLoss()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"O = len(code_dict)\n# F = 512\nmodel1 = BirdNet(f=Fr, o=O).to(device)\noptimizer = Adam([{'params': model1.resnet.parameters(), 'lr': 0.001},\n                  {'params': model1.dense_output.parameters(), 'lr': 0.001}])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''define cross entropy loss and accuracy'''\ndef cel(y_true, y_pred):\n    y_true = torch.argmax(y_true ,axis = -1).squeeze()\n    loss = nn.CrossEntropyLoss()\n    criterion = loss(y_pred, y_true)\n    return criterion\n\ndef accuracy(y_true, y_soft_pred):\n    y_true = torch.argmax(y_true, axis = -1).squeeze()\n    y_soft_pred = torch.argmax(y_soft_pred, axis = -1).squeeze()\n    acc = (y_true == y_soft_pred).float().sum()/len(y_true)\n#     acc = torch.round(acc)*100\n    return acc\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.getcwd()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_shuffle_idx(tensor):\n    return shuffle(np.arange(len(tensor)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_metric(data, batch, epoch, start, end, metric, typ):\n    t = typ, metric, \"%s\", data, \"%s\"\n    if typ == \"train\": pre = \"BATCH \" + str(batch-1) + \" \"\n    if typ == \"val\" : pre = \"\\nEPOCH \" +str(epoch+1) + \" \" \n    time = np.round(end - start, 1); time = \"Time: {} s\".format(time)\n#     fonts = [(fg(211), attr('reset')), (fg(212), attr('reset')), (fg(213), attr('reset'))]\n    print(pre  + \"{} {} : {}{}{}\".format(*t) + \" \" + time)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_stats = {\n    'train': [],\n    \"val\": []\n}\nloss_stats = {\n    'train': [],\n    \"val\": []\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"files = os.listdir('/kaggle/working')\nprint(files)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# os.remove(\"weightsmd1.pth\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"D = (3, 128, 255)\nPATH = \"weightsmd1.pth\"\n\n'''training the model'''\nstart = time.time()\n# print(f\"start time is.{start}\")\n\nfor epoch in range(EPOCHS):\n\n    train_epoch_loss = 0\n    train_epoch_acc = 0\n\n    state = {\n        \"epoch\": epoch,\n        \"state_dict\": model1.state_dict(),\n        \"optimizer\": optimizer.state_dict()\n    }\n\n    torch.save(state, PATH)\n#     checkpoint = torch.load(PATH)\n#     model1.load_state_dict(checkpoint['state_dict'])\n#     optimizer.load_state_dict(checkpoint['optimizer'])\n\n    model1.train()\n\n    batch = 1\n\n    for train_x, train_y in bird_loader_train:\n        \n        idx = get_shuffle_idx(train_x)\n        train_x = train_x[idx].to(device)\n        train_y = train_y[idx].to(device)\n        \n        optimizer.zero_grad()\n\n        train_preds = model1.forward(train_x)\n        train_outputs = train_preds[\"logits\"]\n        train_loss = cel(train_y, train_outputs)\n#         train_softmax = train_preds[\"multiclass_prob\"]\n        train_acc = accuracy(train_y, train_outputs)\n       \n        train_loss.backward()\n        optimizer.step()\n        \n        tr_acc = np.round(train_acc.item(), 3)\n        train_epoch_loss += train_loss.item() \n        train_epoch_acc += train_acc.item()\n        \n        \n        end = time.time()\n        batch = batch + 1\n\n        is_print = batch % 100 == 1\n        if is_print: print_metric(tr_acc, batch, epoch, start, end, \"Acc\", \"train\")\n        \n    epoch_loss = train_epoch_loss / len(bird_loader_train)\n    epoch_acc = train_epoch_acc / len(bird_loader_train)\n    \n    print('Loss {:.4f} Acc: {:.4f} '.format(epoch_loss, epoch_acc))\n    \n    valid_epoch_loss = 0\n    valid_epoch_acc = 0\n\n    model1.eval()\n\n    with torch.no_grad():\n        for valid_x, valid_y in bird_loader_val:\n            idx = get_shuffle_idx(valid_x)\n\n            valid_x = valid_x[idx].to(device)\n            valid_y = valid_y[idx].to(device)\n\n            valid_preds = model1.forward(valid_x)\n            valid_outputs = valid_preds['logits']\n#             valid_softmax = valid_preds['multiclass_prob']\n            valid_loss = cel(valid_y, valid_outputs)\n            valid_acc = accuracy(valid_y, valid_outputs)\n            \n            val_acc = np.round(valid_acc.item(), 3)\n            valid_epoch_loss += valid_loss.item() \n            valid_epoch_acc += valid_acc.item()\n#             valid_epoch_loss += valid_loss.item() * valid_x.size(0)\n#             valid_epoch_acc += torch.sum(preds == valid_y)\n        \n        epoch_valid_loss = valid_epoch_loss / len(bird_loader_val)\n        epoch_valid_acc = valid_epoch_acc / len(bird_loader_val)\n        \n        print('Loss {:.4f} Acc: {:.4f} '.format(epoch_valid_loss, epoch_valid_acc))\n\n    end = time.time()\n    print_metric(val_acc, batch, epoch, start, end, \"Acc\", \"val\")\n\n    print('ENDING TRAINING...', epoch)\n\n#     loss_stats['train'].append(train_epoch_loss / len(bird_loader_train))\n#     loss_stats['val'].append(valid_epoch_loss / len(bird_loader_val))\n\n#     acc_stats['train'].append(train_epoch_acc / len(bird_loader_train))\n#     acc_stats['val'].append(valid_epoch_acc / len(bird_loader_val))\n    loss_stats['train'].append(epoch_loss)\n    loss_stats['val'].append(epoch_valid_loss)\n\n    acc_stats['train'].append(epoch_acc)\n    acc_stats['val'].append(epoch_valid_acc)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def train_model(model, dataloaders, criterion, optimizer, num_epochs=25):\n#     since = time.time()\n    \n#     for epoch in range(num_epochs):\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(loss_stats['train']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title(\"train and val loss vs no of Epochs\")\nplt.xlabel(\"Training epochs\")\nplt.ylabel(\"Loss\")\nplt.plot(range(EPOCHS), loss_stats['val'], label=\"val loss\")\nplt.plot(range(EPOCHS), loss_stats['train'], label=\"train_loss\")\nplt.xticks(np.arange(EPOCHS, 1))\nplt.legend()\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.title(\"train and val accuracy vs no of Epochs\")\nplt.xlabel(\"Training epochs\")\nplt.ylabel(\"Accuracy\")\nplt.plot(range(EPOCHS), acc_stats['val'], label=\"val_acc\")\nplt.plot(range(EPOCHS), acc_stats['train'], label=\"train_acc\")\nplt.xticks(np.arange(EPOCHS, 1))\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class TestDataset(data.Dataset):\n    '''\n    Class that defines the test dataset that will be fed into the model\n    '''\n    def __init__(self, dfs: pd.DataFrame, clip: np.ndarray, img_size =224, melspect_params={}):\n        self.dfs = dfs\n        self.clip = clip\n        self.img_size = img_size\n        self.melspect_params = melspect_params\n    \n    def __len__(self):\n        return len(self.dfs)\n    \n    def __getitem__(self, idx: int):\n        sr = 32000\n        sample = self.dfs.loc[idx, :]\n        site = sample['site']\n        row_id = sample['row_id']\n        if site ==\"site_3\":\n            y = self.clip.astype(np.float32)\n            len_y = len(y)\n            start = 0\n            end = sr * 5\n            images = []\n            while len_y > start:\n                y_batch = y[start:end].astype(np.float32)\n                if len(y_batch) != (sr * 5):\n                    break\n                start = end\n                end = end + sr * 5\n                \n                melspec = librosa.feature.melspectrogram(y_batch, sr=sr, **melspec_params)\n                melspc = librosa.power_to_db(melspec).astype(np.float32)\n                \n                image = mono_to_color(melspec)\n                height, width, _ = image.shape\n                image = cv.resize(image, (int(width * self.img_size/height), self.img_size))\n                image = np.moveaxis(image, 2, 0)\n                image = (image/255.0).astype(np.float32)\n                images.append(image)\n                \n            images = np.asarray(images)\n            return images, row_id, site\n        else:\n            end_seconds = int(sample['seconds'])\n            start_seconds = int(end_seconds - 5)\n            \n            start_index = sr * start_seconds\n            end_index = sr * end_seconds\n            \n            y = self.clip[start_index:end_index].astype(np.float32)\n            \n            melspec = librosa.feature.melspectrogram(y, sr=sr, **melspec_params)\n            melspec = librosa.power_to_db(melspec).astype(np.float32)\n            \n            image = mono_to_color(melspec)\n            height, width, _ = image.shape\n            image = image = cv.resize(image, (int(width * self.img_size/height), self.img_size))\n            image = np.moveaxis(image, 2, 0)\n            image = (image/255.0).astype(np.float32)\n            \n            return image, row_id, site\n                \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# clip, _ = librosa.load(\"../input/birdsong-recognition/train_audio/ameavo/XC133080.mp3\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_df = TestDataset(test, clip )\n# for i in range(5):\n#     print(test_df[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#extracting features from audio\n# def feature extraction():\n#     dataset = ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model(weights_path: str):\n    model = newmodel()\n    checkpoint = torch.load(weights_path)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    model.to(device)\n    model.eval()\n    return model\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prediction_for_clip(test_df:pd.DataFrame, clip:np.ndarray, model, mel_params:dict, threshold = 0.5):\n    \n    dataset = TestDataset(test, clip=clip, img_size=224, melspect_params = mel_params)\n    loader = data.DataLoader(dataset, batch_size=1, shuffle=False)\n    \n    model.eval()\n    prediction_dict ={}\n    \n    for image, row_id, site in progress_bar(loader):\n        site = site[0]\n        row_id = row_id[0]\n        \n        if site in {\"site_1\", \"site_2\"}:\n            image = image.to(device)\n            \n            with torch.no_grad():\n                prediction = model(image)\n                #no more tracking operations and pick a suitable dimention\n                proba = prediction[\"multilabel_prob\"].detach().cpu().numpy().reshape(-1)\n                \n                events = proba >= threshold\n                labels = np.argwhere(events).reshape(-1).tolist()\n                \n        else:\n            #avoiding prediction on large batch\n            image = image.squeeze(0)\n            batch_size = 16\n            whole_size = image.size(0)\n            if whole_size % batch_size == 0:\n                n_iter = whole_size // batch_size\n            else:\n                n_iter = whole_size // batch_size + 1\n                \n            all_events = set()\n            for batch_i in range(n_iter):\n                batch = image[batch_i * batch_size : (batch_i + 1) * batch_size]\n                \n                if batch.ndim == 3:\n                    batch = batch.unsqueeze(0)\n                    \n                batch = batch.to(device)\n                with torch.no_grad():\n                    prediction = model(batch)\n                    proba = prediction[\"multilabel_prob\"].detach().cpu().numpy()\n                    \n                    events = proba >= threshold\n                    for i in range(len(events)):\n                        event = events[i, :]\n                        labels = np.argwhere(event).reshape(-1).tolist()\n                        \n                        for label in labels:\n                            all_events.add(label)\n            labels = list(all_events)\n        if len(labels) == 0:\n            prediction_dict[row_id] = \"nocall\"\n            \n        else:\n            label_str_list = list(map(lambda x: INV_BIRD_CODE[x], labels))\n            label_string = \" \".join(label_str_list)\n            prediction_dict[row_id] = label_string\n            \n    return prediction_dict\n                \n                ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prediction(test_df : pd.DataFrame, test_audio: Path, mel_params: dict, weights_path: str, threshold=0.5):\n    model = get_model(weights_path)\n    unique_audio_id = test[\"audio_id\"].unique()\n    check_audio = os.listdir(\"../input/birdcall-check/test_audio\")\n#     warnings.filterwarnings(\"ignore\")\n    \n    predictions_dfs = []\n    for audio_id in check_audio:\n        \n        clip, _ = librosa.load(test_audio / (audio_id ),\n                                   sr=SR,\n                                   mono=True,\n                                   res_type=\"kaiser_fast\")\n        test_df_for_audio_id = test.query(f\"audio_id == '{audio_id}'\").reset_index(drop=True)\n        \n        with timer(f\"Prediction on {audio_id}\", logger):\n            prediction_dict = prediction_for_clip(test, clip=clip, model=model, mel_params=mel_params, threshold=threshold)\n            \n            row_id = list(prediction_dict.keys())\n            birds = list(prediction_dict.values())\n            prediction_df = pd.DataFrame({\"row_id\": row_id, \"birds\": birds})\n            predictions_dfs.append(prediction_df)\n            \n        prediction_df = pd.concat(predictions_dfs, axis=0, sort=False).reset_index(drop=True)\n        return prediction_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = prediction(test_df=test,\n                        test_audio=test_audio,\n                        weights_path = \"weightsmd1.pth\"\n                        mel_params=melspec_params,\n                        threshold=0.6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}