{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"!pip install noisereduce","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"import librosa\nimport librosa.display\nimport random\nimport IPython\n\nimport numpy as np\nimport pandas as pd\nimport noisereduce as nr\n\nfrom pathlib import Path\nfrom matplotlib import pyplot as plt\nfrom scipy.ndimage import maximum_filter1d","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def view_audio(audio_path,swich = [1,1,1]):\n    y, sr = librosa.load(audio_path)\n\n    graphs = len(swich)\n\n    fig = plt.figure(figsize=(20,graphs*5))\n    \n    if swich[0] == 1:\n        ax1 = fig.add_subplot(graphs,1,1,title='waveplot')\n        # 波形で表示\n        librosa.display.waveplot(y, sr=sr)\n    \n    if swich[1] == 1:\n        # メルスペクトログラムとやらに変換\n        S = librosa.feature.melspectrogram(y, sr=sr, n_mels=128)\n        # デシベル（音量）スケールのスペクトログラムに変換\n        log_S = librosa.amplitude_to_db(S, ref=np.max)\n\n        # librosaのスペクトログラムを出してくれるAPIを呼ぶ\n        ax2 = fig.add_subplot(graphs,1,2,title='mel power spectrogram')\n        librosa.display.specshow(log_S, sr=sr, x_axis='time', y_axis='mel')\n        plt.colorbar()\n    \n    if swich[2] ==1:        \n        # 短時間フーリエ変換 \n        X = librosa.stft(y)\n        Xdb = librosa.amplitude_to_db(abs(X))\n        ax3 = fig.add_subplot(graphs,1,3,title='stft')\n        librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')\n        plt.colorbar()\n    \n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"audio_path = '/kaggle/input/birdsong-recognition/train_audio/whtswi/XC425114.mp3'\n#ipd.Audio(audio_path)\n\nview_audio(audio_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def envelope(y, rate, threshold):\n    mask = []\n    y_mean = maximum_filter1d(np.abs(y), size=rate//20)\n    for mean in y_mean:\n        if mean > threshold:\n            mask.append(True)\n        else:\n            mask.append(False)\n    return mask, y_mean","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TEST_DIR = '../input/birdcall-check/test_audio'\ntest_path = []\nimport os\nfor dirname, _, filenames in os.walk(TEST_DIR):\n    for filename in filenames:\n        audio_path = os.path.join(dirname, filename)\n        test_path.append(audio_path)\n\n\nprint(test_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\nthr = 0.25\nx_deonoise = []\n\n\nfor i in range(len(test_path)):\n    x, sr = librosa.load(test_path[i])\n    mask, env = envelope(x, sr, thr)\n    x_deonoise.append(nr.reduce_noise(audio_clip=x, noise_clip=x[np.logical_not(mask)], verbose=False))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## blue →(denoise)→ orenge\nfor i in range(len(test_path)):\n    x, sr = librosa.load(test_path[i])\n    plt.plot(x)\n    plt.plot(x_deonoise[i])\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x,sr = librosa.load('../input/birdcall-check/test_audio/856b194b097441958697c2bcd1f63982.mp3')\n# 元の音声\nIPython.display.Audio(data=x, rate=sr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ノイズ除去\nIPython.display.Audio(data=x_deonoise[0], rate=sr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 同じ鳥の鳴き声を重ねてみた。"},{"metadata":{"trusted":true},"cell_type":"code","source":"ald_0 , str_0 = librosa.load('../input/birdsong-recognition/train_audio/aldfly/XC134874.mp3',offset=0,duration=5)\nald_1 , str_1 = librosa.load('../input/birdsong-recognition/train_audio/aldfly/XC135454.mp3',offset=0,duration=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def view_audio(y,sr,swich = [1,1,1]):\n    \n    graphs = len(swich)\n\n    fig = plt.figure(figsize=(20,graphs*5))\n    \n    if swich[0] == 1:\n        ax1 = fig.add_subplot(graphs,1,1,title='waveplot')\n        # 波形で表示\n        librosa.display.waveplot(y, sr=sr)\n    \n    if swich[1] == 1:\n        # メルスペクトログラムとやらに変換\n        S = librosa.feature.melspectrogram(y, sr=sr, n_mels=128)\n        # デシベル（音量）スケールのスペクトログラムに変換\n        log_S = librosa.amplitude_to_db(S, ref=np.max)\n\n        # librosaのスペクトログラムを出してくれるAPIを呼ぶ\n        ax2 = fig.add_subplot(graphs,1,2,title='mel power spectrogram')\n        librosa.display.specshow(log_S, sr=sr, x_axis='time', y_axis='mel')\n        plt.colorbar()\n    \n    if swich[2] ==1:        \n        # 短時間フーリエ変換 \n        X = librosa.stft(y)\n        Xdb = librosa.amplitude_to_db(abs(X))\n        ax3 = fig.add_subplot(graphs,1,3,title='stft')\n        librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')\n        plt.colorbar()\n    \n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IPython.display.Audio(data=ald_0, rate=str_0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"view_audio(ald_0,str_0,[1,0,0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IPython.display.Audio(data=ald_1, rate=str_1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"view_audio(ald_1,str_1,[1,0,0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IPython.display.Audio(data=ald_0 +ald_1, rate=str_0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"view_audio(ald_0+ald_1,str_0,[1,0,0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 標準化したほうが良さそう？"},{"metadata":{"trusted":true},"cell_type":"code","source":"def audio_norm(data):\n    max_data = np.max(data)\n    min_data = np.min(data)\n    data = (data-min_data)/(max_data-min_data+1e-6)\n    return data-0.5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"norm_0 = audio_norm(ald_0)\nnorm_1 = audio_norm(ald_1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IPython.display.Audio(data=norm_0 +norm_1, rate=str_0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"view_audio(norm_0+norm_1,str_0,[1,0,0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = norm_0+norm_1\nmask, env = envelope(x, str_0, thr)\ndenoise = nr.reduce_noise(audio_clip=x, noise_clip=x[np.logical_not(mask)], verbose=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(x)\nplt.plot(denoise)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}