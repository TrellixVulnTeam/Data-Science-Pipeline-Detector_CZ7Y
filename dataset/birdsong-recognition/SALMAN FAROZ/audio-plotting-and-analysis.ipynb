{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Cornell Birdcall Identification üê¶\n![](https://www.depthworld.com/wp-content/uploads/2019/03/Quetzal.jpg)\n\nMost birds have a wide repertoire of songs and call, but there‚Äôs an important distinction to be made between the two. Among the songbirds and various other groups of birds (such as cuckoos, owls, and nightjars), songs are used to defend territory and attract mates. Therefore, it‚Äôs the males that sing the most‚Äîusually during breeding season.\n\n## Upvote if you like my kernel\n\n### üìé Types of Calls\n\n* Alarm calls\n\n* Contact calls\n\n* Flight calls\n\n* Begging calls\n\n* Describing Sounds\n\n* Trill\n\n* Buzz and Thin\n\n* Harsh\n\n* Bell-like, flute-like, whistling, or metallic\n\n* Other Noises\nThere‚Äôs more to bird sounds than just vocals. Downy Woodpeckers advertise their presence by drumming rapidly on a tree‚Äîand sometimes on the side of your house. (In fact, you can ID certain woodpecker species by measuring the pace of their knocks.) Mating season is often full of unexpected noises like the soft thwacks of a Ruffed Grouse‚Äôs wings or the squeaky vibrato of an American Woodcock‚Äôs flight feathers. Listen for subtler sounds, too, such as shuffling leaves, flapping feathers, and clumsy, crashing fowl in water. They can point to behavioral clues and help you solve an ID. ","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport warnings\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nfrom colorama import Fore, Back, Style \nfrom sklearn.model_selection import train_test_split\nfrom sklearn import svm, datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport xgboost\nfrom plotly.offline import plot, iplot, init_notebook_mode\nimport plotly.graph_objs as go\nfrom plotly.subplots import make_subplots\nimport plotly.express as px\nfrom statsmodels.formula.api import ols\nimport plotly.graph_objs as gobj\ninit_notebook_mode(connected=True)\nwarnings.filterwarnings(\"ignore\")\nimport plotly.figure_factory as ff\n\n%matplotlib inline\nds=pd.read_csv(\"../input/birdsong-recognition/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = go.Figure(data=go.Scattergeo(\n        locationmode = 'USA-states',\n        lon = ds['longitude'],\n        lat = ds['latitude'],\n        text = ds['location'],\n        mode = 'markers',\n        marker = dict(\n            size = 8,\n            opacity = 0.8,\n            reversescale = True,\n            autocolorscale = False,\n            symbol = 'square',\n            line = dict(\n                width=1,\n                color='rgba(102, 102, 102)'\n            ),\n            colorscale = 'Blues',\n            cmin = 0,\n            color = ds['duration'],\n            cmax = ds['duration'].max(),\n            colorbar_title=\"Duration\"\n        )))\n\nfig.update_layout(\n        title = 'Recorded Place all over the world',\n        geo = dict(\n            scope='world',\n            showland = True,\n            landcolor = \"rgb(250, 250, 250)\",\n            subunitcolor = \"rgb(217, 217, 217)\",\n            countrycolor = \"rgb(217, 217, 217)\",\n            countrywidth = 0.5,\n            subunitwidth = 0.5\n        ),\n    )\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"val=ds[\"pitch\"].value_counts()\nnt=[\"Not specified\"]\n\nlvl=[\"level\"] \nbt=[\"both\"]\ndc=[\"decreasing\"]\ninc=[\"increasing\"]\n\nfig = go.Figure(data=[\n    go.Bar(name='Not specified', x=nt, y=[val[\"Not specified\"]]),\n    go.Bar(name='Level', x=lvl, y=[val[\"level\"]]),\n    go.Bar(name='Both', x=bt, y=[val[\"both\"]]),\n    go.Bar(name='decreasing', x=dc, y=[val[\"decreasing\"]]),\n    go.Bar(name='increasing', x=inc, y=[val[\"increasing\"]])\n    \n    \n])\n# Change the bar mode\nfig.update_layout(barmode='group',title=\"Pitch Labels\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import librosa\naudio_path = '../input/birdsong-recognition/train_audio/aldfly/XC134874.mp3'\nx , sr = librosa.load(audio_path)\nprint(type(x), type(sr))\nprint(x.shape, sr)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"librosa.load(audio_path, sr=None)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# üìé Waveform üîä \n\n#### A waveform is an image that represents an audio signal or recording. It shows the changes in amplitude over a certain amount of time. The amplitude of the signal is measured on the y-axis (vertically), while time is measured on the x-axis (horizontally).\n","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"import IPython.display as ipd\nipd.Audio(audio_path)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport librosa.display\nplt.figure(figsize=(14, 5))\nlibrosa.display.waveplot(x, sr=sr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### plot of the amplitude envelope of a waveform.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# üìé Spectrogram\n","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"X = librosa.stft(x)\nXdb = librosa.amplitude_to_db(abs(X))\nplt.figure(figsize=(14, 5))\nlibrosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')\nplt.colorbar()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### A spectrogram is a visual representation of the spectrum of frequencies of sound or other signals as they vary with time. Spectrograms are sometimes called sonographs, voiceprints, or voicegrams. When the data is represented in a 3D plot, they may be called waterfalls. In 2-dimensional arrays, the first axis is frequency while the second axis is time.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='log')\nplt.colorbar()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### vertical axis shows frequencies (from 0 to 10kHz), and the horizontal axis shows the time of the clip","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# üìé Zero Crossing Rate\n\nThe zero-crossing rate is the rate of sign-changes along a signal, i.e., the rate at which the signal changes from positive to zero to negative or from negative to zero to positive. This feature has been used heavily in both speech recognition and music information retrieval, being a key feature to classify percussive sounds.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"x, sr = librosa.load('../input/birdsong-recognition/train_audio/aldfly/XC134874.mp3')\n#Plot the signal:\nplt.figure(figsize=(14, 5))\nlibrosa.display.waveplot(x, sr=sr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"n0 = 9000\nn1 = 9100\nplt.figure(figsize=(14, 5))\nplt.plot(x[n0:n1])\nplt.grid()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# üìé Spectral Centroid\n\n### The spectral centroid is a measure used in digital signal processing to characterise a spectrum. It indicates where the center of mass of the spectrum is located. Perceptually, it has a robust connection with the impression of brightness of a sound.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import sklearn\nspectral_centroids = librosa.feature.spectral_centroid(x, sr=sr)[0]\nspectral_centroids.shape\n(775,)\n# Computing the time variable for visualization\nframes = range(len(spectral_centroids))\nt = librosa.frames_to_time(frames)\n# Normalising the spectral centroid for visualisation\ndef normalize(x, axis=0):\n    return sklearn.preprocessing.minmax_scale(x, axis=axis)\n#Plotting the Spectral Centroid along the waveform\nlibrosa.display.waveplot(x, sr=sr, alpha=0.4)\nplt.plot(t, normalize(spectral_centroids), color='r')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# üìé Spectral Rolloff\n### Spectral rolloff is the frequency below which a specified percentage of the total spectral energy, e.g. 85%, lies.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"spectral_rolloff = librosa.feature.spectral_rolloff(x+0.01, sr=sr)[0]\nlibrosa.display.waveplot(x, sr=sr, alpha=0.4)\nplt.plot(t, normalize(spectral_rolloff), color='r')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# üìé Mel-Frequency Cepstral Coefficients\n\n### In sound processing, the mel-frequency cepstrum is a representation of the short-term power spectrum of a sound, based on a linear cosine transform of a log power spectrum on a nonlinear mel scale of frequency. Mel-frequency cepstral coefficients are coefficients that collectively make up an MFC.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"x, fs = librosa.load('../input/birdsong-recognition/train_audio/aldfly/XC134874.mp3')\nlibrosa.display.waveplot(x, sr=sr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"mfccs = librosa.feature.mfcc(x, sr=fs)\nprint(mfccs.shape)\n(20, 97)\n#Displaying  the MFCCs:\nlibrosa.display.specshow(mfccs, sr=sr, x_axis='time')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import sklearn\nmfccs = sklearn.preprocessing.scale(mfccs, axis=1)\nprint(mfccs.mean(axis=1))\nprint(mfccs.var(axis=1))\nlibrosa.display.specshow(mfccs, sr=sr, x_axis='time')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# üìé Chroma Frequencies\n\n### Chroma features are an interesting and powerful representation for music audio in which the entire spectrum is projected onto 12 bins representing the 12 distinct semitones (or chroma) of the musical octave","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Loadign the file\nx, sr = librosa.load('../input/birdsong-recognition/train_audio/aldfly/XC134874.mp3')\nhop_length = 512\nchromagram = librosa.feature.chroma_stft(x, sr=sr, hop_length=hop_length)\nplt.figure(figsize=(15, 5))\nlibrosa.display.specshow(chromagram, x_axis='time', y_axis='chroma', hop_length=hop_length, cmap='coolwarm')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Would Continue....","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}