{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport librosa\nimport librosa.display\nimport IPython.display as ipd\n\nimport sklearn\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_audio_dir = '../input/birdsong-recognition/train_audio'\ntrain = pd.read_csv('../input/birdsong-recognition/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_dir = '../input/birdsong-recognition/train_audio/'\ntrain['full_path'] = base_dir + train['ebird_code'] + '/'+ train['filename']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train['ebird_code']== 'amered'].sample(1, random_state = 33)['full_path'].values[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"amered = train[train['ebird_code']== 'amered'].sample(1, random_state = 33)['full_path'].values[0]\npingro = train[train['ebird_code'] == \"pingro\"].sample(1, random_state = 33)['full_path'].values[0]\nvesspa = train[train['ebird_code'] == \"vesspa\"].sample(1, random_state = 33)['full_path'].values[0]\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"audio_file, _ = librosa.effects.trim(y)\n\n# the result is an numpy ndarray\nprint('Audio File:', audio_file, '\\n')\nprint('Audio File shape:', np.shape(audio_file))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ipd.Audio(amered)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"audio_amered, sr = librosa.load(amered)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  Spectrogram ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"n_fft = 2048 # FFT window size\nhop_length = 512\n\nD_amered = np.abs(librosa.stft(audio_amered, n_fft = n_fft, hop_length = hop_length))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DB_amered = librosa.amplitude_to_db(D_amered, ref = np.max)\nlibrosa.display.specshow(DB_amered, sr = sr, hop_length = hop_length, x_axis = 'time', \n                         y_axis = 'log', cmap = 'cool')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Spectrogram tells....\n* Most of the energy is concenterated between above 2048 frequency and 8192 frequency.\n\n* Whenever vibration of sound becomes strong, the intensity get dark.\n\n* At 0.6s the intensity is strong, it means there is bird sound. Likewise at 2 and at 4.2s.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# #Let see Sound Waves\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nplt.Figure(figsize=(16,9))\nplt.title(('Sound waves'), fontsize=16)\n\nlibrosa.display.waveplot(y= audio_amered, sr = sr, color = \"#A300F9\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"the chirping sound occur at 0.6, 1.8(approx) amd 4","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Zero-Crossing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"n0 = 9000\nn1 = 9100\nplt.figure(figsize=(14, 5))\nplt.plot(audio_amered[n0:n1])\nplt.grid()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"zero_amered = librosa.zero_crossings(audio_amered, pad=False)\nprint('change rate {}'.format(sum(zero_amered)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In speech processing, the zero-crossing counts can help distinguish between voiced and un-voiced speech.  \nUn-voiced sounds are very noise-like ('Shh' and 'Sss' for example). \nIn addition, zero-crossings could also be used to determine if your signal has a DC offset.  \nIf you signal is 'muted' and you are not seeing alot of zero-crossings might mean that your signal is offset from the zero-line","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# spectral centroid","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"spectral_centroids = librosa.feature.spectral_centroid(audio_amered, sr=sr)[0]\n\n# Shape is a vector\nprint('Centroids:', spectral_centroids, '\\n')\nprint('Shape of Spectral Centroids:', spectral_centroids.shape, '\\n')\n\n# Computing the time variable for visualization\nframes = range(len(spectral_centroids))\n\n# Converts frame counts to time (seconds)\nt = librosa.frames_to_time(frames)\n\nprint('frames:', frames, '\\n')\nprint('t:', t)\n\n# Function that normalizes the Sound Data\ndef normalize(x, axis=0):\n    return sklearn.preprocessing.minmax_scale(x, axis=axis)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16, 6))\nlibrosa.display.waveplot(audio_amered, sr=sr, alpha=0.4, color = '#A300F9', lw=3)\nplt.plot(t, normalize(spectral_centroids), color='#FFB100', lw=2)\nplt.legend([\"Spectral Centroid\", \"Wave\"])\nplt.title(\"Spectral Centroid: Cangoo Bird\", fontsize=16);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"(https://medium.com/@jehoshaphatia/100-days-of-ml-code-day-034-985f64a73c)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":" “The spectral centroid is a measure used in digital signal processing to characterise a spectrum. It indicates where the “center of mass” of the spectrum is located. Perceptually, it has a robust connection with the impression of “brightness” of a sound”\nSpectral Centroid tells us something about the timbre of a sound. Specifically, it gives us information about how bright a sound is. Visually, you can understand Spectral Centroid by imagining you have a frequency spectrum made out of solid object\n\nSpectra Centroid can be a nice feature if timbre is relevant to the thing you are trying to model.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#  Spectral Rolloff ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"spectral_rolloff = librosa.feature.spectral_rolloff(audio_amered, sr=sr)[0]\n\n\nframes = range(len(spectral_rolloff))\n\nt = librosa.frames_to_time(frames)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nplt.figure(figsize = (16, 6))\nlibrosa.display.waveplot(audio_amered, sr=sr, alpha=0.4, color = '#A300F9', lw=3)\nplt.plot(t, normalize(spectral_rolloff), color='#FFB100', lw=3)\nplt.legend([\"Spectral Rolloff\", \"Wave\"])\nplt.title(\"Spectral Rolloff: Amered Bird\", fontsize=16);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The roll-off is a measure of spectral shape useful for distinguishing voiced from unvoiced speech. The\nfrequency below which 85% of the magnitude distribution of the spectrum is concentrated is known as Roll-Off.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"More to go...","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"https://www.kaggle.com/andradaolteanu/birdcall-recognition-eda-and-audio-fe\n","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}