{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"base_path = \"../input/birdsong-recognition/\"\ntrain_df = pd.read_csv(os.path.join(base_path, \"train.csv\"))\ntest_df = pd.read_csv(os.path.join(base_path, \"test.csv\"))\nos.listdir(\"../input/birdsong-recognition/\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[\"filename\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#preview of an audio clip\nimport IPython\nIPython.display.Audio(base_path + \"train_audio/\" + train_df[\"ebird_code\"].iloc[0] +\"/\"+ train_df[\"filename\"].iloc[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import librosa\nimport matplotlib.pyplot as plt\nfrom scipy import signal\ny, sr = librosa.load(base_path + \"train_audio/\" + train_df[\"ebird_code\"].iloc[0] +\"/\"+ train_df[\"filename\"].iloc[0])\nM = librosa.feature.melspectrogram(y=y, sr = 48000)\nM = librosa.power_to_db(M, ref=np.max)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"M.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(M)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from zipfile import ZipFile","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from https://www.kaggle.com/daisukelab/creating-fat2019-preprocessed-data\ndef mono_to_color(X, mean=None, std=None, norm_max=None, norm_min=None, eps=1e-6):\n    # Stack X as [X,X,X]\n#     X = np.stack([X, X, X], axis=-1)\n\n    # Standardize\n    mean = mean or X.mean()\n    X = X - mean\n    std = std or X.std()\n    Xstd = X / (std + eps)\n    _min, _max = Xstd.min(), Xstd.max()\n    norm_max = norm_max or _max\n    norm_min = norm_min or _min\n    if (_max - _min) > eps:\n        # Normalize to [0, 255]\n        V = Xstd\n        V[V < norm_min] = norm_min\n        V[V > norm_max] = norm_max\n        V = 255 * (V - norm_min) / (norm_max - norm_min)\n        V = V.astype(np.uint8)\n    else:\n        # Just zero\n        V = np.zeros_like(Xstd, dtype=np.uint8)\n    return V","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_spectogram(path, sr, duration):\n    try:\n        y, _ = librosa.load(path, sr = sr, duration=duration)\n        M = librosa.feature.melspectrogram(y=y, sr=sr)\n        M = librosa.power_to_db(M)\n        M = mono_to_color(M)\n        cv2.imwrite(path.split(\"/\")[-1][:-4] + \".jpg\", M, [int(cv2.IMWRITE_JPEG_QUALITY), 85])\n        with ZipFile('birdsongs.zip', 'a') as myzip:\n            myzip.write(path.split(\"/\")[-1][:-4] + \".jpg\")\n        os.remove(path.split(\"/\")[-1][:-4] + \".jpg\")\n    except:\n        print(\"spectrogram generation failed\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[\"duration\"].hist(bins = 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nfrom tqdm import tqdm_notebook as tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm -rf birdsongs.zip","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in tqdm(range(len(train_df))):\n    warnings.simplefilter(\"ignore\")\n    row = train_df.iloc[i]\n    duration = np.min([400, row[\"duration\"]])\n    if duration != row[\"duration\"]:\n        print(\"truncated audio\")\n    fp = base_path + \"train_audio/\" + row[\"ebird_code\"] +\"/\"+ row[\"filename\"]\n    sr = float(row[\"sampling_rate\"].split(\" \")[0])\n    build_spectogram(fp, sr, duration)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls -l","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.iloc[-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}