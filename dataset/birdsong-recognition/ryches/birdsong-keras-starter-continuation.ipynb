{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/birdsong-recognition/train.csv\")\ntest_df = pd.read_csv(\"../input/birdsong-recognition/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\nbase_path = \"../input/birdsongspectrograms/\"\ndef read_img(img_path):\n    img = cv2.imread(base_path + img_path[:-3] + \"jpg\", 0)\n    return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 32\nimg_size = (128, 1200)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_classes = train_df[\"ebird_code\"].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ntrain_df[\"ebird_code\"] = le.fit_transform(train_df[\"ebird_code\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"files = [file[:-3] + \"mp3\" for file in os.listdir(base_path)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train_df[train_df[\"filename\"].isin(files)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nclass DataGenerator(keras.utils.Sequence):\n    def __init__(self, df=train_df, im_path = base_path, augmentations=None, batch_size=batch_size, img_size=img_size, shuffle=True):\n        'Initialization'\n        self.batch_size = batch_size\n        self.df = df\n        self.height, self.width = img_size[0], img_size[1]\n        self.shuffle = shuffle\n        self.augment = augmentations\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.ceil(len(self.df) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:min((index+1)*self.batch_size,len(self.df))]\n\n        # Find list of IDs\n        list_IDs_im = [self.df.iloc[k] for k in indexes]\n        \n        # Generate data\n        X, y = self.data_generation(list_IDs_im)\n        return X, y\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.df))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def data_generation(self, list_IDs_im):\n        X = np.empty((len(list_IDs_im),self.height,self.width, 3))\n        y = np.zeros((len(list_IDs_im), num_classes))\n        for i, im_path in enumerate(list_IDs_im):\n            im = read_img(im_path[\"filename\"])\n            if im is None:\n                print(\"image not loaded correctly\")\n                im = np.zeros((self.height, self.width, 3))\n            if len(im.shape)==2:\n                im = np.repeat(im[...,None],3,2)\n            if im.shape[1]-self.width <= 0:\n                start_seq = 0\n            else:\n                start_seq = np.random.randint(0, im.shape[1]-self.width)\n            im = im[:, start_seq:start_seq+self.width,:]\n            X[i, :, :im.shape[1], :] = im\n            y[i,im_path[\"ebird_code\"]] = 1\n        X = X/255.\n        return X, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_gen = DataGenerator(df=train_df, im_path = base_path, augmentations=None, batch_size=batch_size, img_size=img_size, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch = next(train_gen.__iter__())\nprint(np.argmax(batch[1], axis = 1))\nplt.imshow(batch[0][0])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications.resnet50 import ResNet50\nfrom keras import layers\nfrom keras.models import Model\nmodel = ResNet50(weights='imagenet', include_top=False, input_shape = (img_size[0], img_size[1], 3), pooling = 'max')\nfinal_output = keras.layers.Dense(num_classes, activation = 'softmax')(model.output)\nmodel = Model(inputs = model.input, outputs = final_output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import load_model\nmodel = load_model(\"../input/birdsong-model/model.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def custom_model():\n#     inputs = keras.Input(shape=(img_size[0], img_size[1], 3))\n#     x = layers.Conv2D(2, 3, activation=\"relu\")(inputs)\n#     x = layers.Conv2D(4, 3, activation=\"relu\")(x)\n#     x = layers.MaxPooling2D((2, 3))(x)\n#     x = layers.Conv2D(8, 3, activation=\"relu\")(x)\n#     x = layers.Conv2D(16, 3, activation=\"relu\")(x)\n#     x = layers.MaxPooling2D((2, 3))(x)\n#     x = layers.Conv2D(32, 3, activation=\"relu\")(x)\n#     x = layers.Conv2D(64, 3, activation=\"relu\")(x)\n#     x = layers.MaxPooling2D((2, 3))(x)\n#     x = layers.Conv2D(128, 3, activation=\"relu\")(x)\n#     x = layers.Conv2D(256, 3, activation=\"relu\")(x)\n#     x = layers.MaxPooling2D((1, 2))(x)\n#     x = layers.Conv2D(512, 3, activation=\"relu\")(x)\n#     x = layers.Conv2D(1024, 3, activation=\"relu\")(x)\n#     x = layers.GlobalMaxPooling2D()(x)\n#     x = layers.Dense(num_classes, activation = \"relu\")(x)\n#     outputs = layers.Dense(num_classes, activation = \"softmax\")(x)\n#     model = keras.Model(inputs, outputs)\n#     return model\n# model = custom_model()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.read_csv(\"../input/birdsong-recognition/example_test_audio_metadata.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_summary = pd.read_csv(\"../input/birdsong-recognition/example_test_audio_summary.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import librosa\nimport cv2\n#from https://www.kaggle.com/daisukelab/creating-fat2019-preprocessed-data\ndef mono_to_color(X, mean=None, std=None, norm_max=None, norm_min=None, eps=1e-6):\n    # Stack X as [X,X,X]\n#     X = np.stack([X, X, X], axis=-1)\n\n    # Standardize\n    mean = mean or X.mean()\n    X = X - mean\n    std = std or X.std()\n    Xstd = X / (std + eps)\n    _min, _max = Xstd.min(), Xstd.max()\n    norm_max = norm_max or _max\n    norm_min = norm_min or _min\n    if (_max - _min) > eps:\n        # Normalize to [0, 255]\n        V = Xstd\n        V[V < norm_min] = norm_min\n        V[V > norm_max] = norm_max\n        V = 255 * (V - norm_min) / (norm_max - norm_min)\n        V = V.astype(np.uint8)\n    else:\n        # Just zero\n        V = np.zeros_like(Xstd, dtype=np.uint8)\n    return V\n\ndef build_spectrogram(path, offset, duration):\n    y, sr = librosa.load(path, offset=offset, duration=duration)\n    total_secs = y.shape[0] / sr\n    M = librosa.feature.melspectrogram(y=y, sr=sr)\n    M = librosa.power_to_db(M)\n    M = mono_to_color(M)\n    \n    cv2.imwrite(path.split(\"/\")[-1][:-4] + \".jpg\", M, [int(cv2.IMWRITE_JPEG_QUALITY), 85])\n    M = cv2.imread(path.split(\"/\")[-1][:-4] + \".jpg\", 0)\n    M = np.repeat(M[...,None],3,2)/255.\n    os.remove(path.split(\"/\")[-1][:-4] + \".jpg\")\n    return M\nM = build_spectrogram(\"../input/birdsong-recognition/example_test_audio/BLKFR-10-CPL_20190611_093000.pt540.mp3\", 0, 5)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(M)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_path = \"../input/birdsong-recognition/example_test_audio/\"\ntest_files = os.listdir(test_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_summary[\"seconds\"] = test_summary[\"filename_seconds\"].str.split(\"_\").apply(pd.Series)[3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for row in range(len(test_summary)):\n    for file in test_files:\n        if test_summary.iloc[row][\"filename\"] in file:\n            fp = test_path + file\n    warnings.simplefilter(\"ignore\")\n    M = build_spectrogram(fp, int(test_summary.iloc[row][\"seconds\"]) - 5, 5)\n    holder = np.empty((1, img_size[0], img_size[1], 3))\n    holder[:, :, :M.shape[1], :] = M\n    prediction = model.predict(holder)\n    print(fp.split(\"/\")[-1], int(test_summary.iloc[row][\"seconds\"]) - 5, le.classes_[prediction[0] > .05], test_summary.iloc[row][\"birds\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_summary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.read_csv(\"../input/birdsong-recognition/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}