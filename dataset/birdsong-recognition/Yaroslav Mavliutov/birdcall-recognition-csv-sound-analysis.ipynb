{"cells":[{"metadata":{"_uuid":"b73bd015-8005-4f2d-9abd-6c5d2f0095f8","_cell_guid":"f657d56e-1790-495d-9d0f-4b2508ab40b6","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfrom IPython.display import Audio\nimport librosa\nimport librosa.display\nimport IPython.display as ipd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nimport torch\nimport torch.nn as nn\nfrom torch.optim import Adam\nfrom albumentations import Normalize\nfrom torchvision.models import resnet34\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch import FloatTensor, LongTensor, DoubleTensor\n\nfrom keras.utils import to_categorical\nfrom keras.preprocessing.sequence import pad_sequences as pad","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.backends.cudnn.benchmark = True","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_csv = pd.read_csv(\"../input/birdsong-recognition/train.csv\")\ntest_csv = pd.read_csv(\"../input/birdsong-recognition/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"There are {:,} unique bird species in the dataset.\".format(len(train_csv['species'].unique())))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_csv.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_csv.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"example_audio = '../input/birdsong-recognition/train_audio/amebit/XC127371.mp3'\ny, sr = librosa.load(example_audio, sr=None)\nprint(\"Class:\", example_audio.split('/')[-2])\nAudio(example_audio)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Analysis\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### csv","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_csv['year'] = train_csv['date'].apply(lambda x: x.split('-')[0])\ntrain_csv['month'] = train_csv['date'].apply(lambda x: x.split('-')[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A lot of the data was registered between 2013 and 2019, during Spring and Summer months","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 5))\nax = sns.countplot(train_csv['date'].apply(lambda x: x.split('-')[0]), palette=\"hls\")\nplt.title(\"Audio Files Registration per Year\", fontsize=12)\nplt.xticks(rotation=90, fontsize=13)\nplt.ylabel('Frequency')\nplt.xlabel('Year')\nplt.xlabel(\"\");\n\nplt.figure(figsize=(12, 5))\nax = sns.countplot(train_csv['date'].apply(lambda x: x.split('-')[1]), palette=\"hls\")\nplt.title(\"Audio Files Registration per Month\", fontsize=12)\nplt.xticks(rotation=90, fontsize=13)\nplt.ylabel('Frequency')\nplt.xlabel('Month')\nplt.xlabel(\"\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top15 = list(train_csv['country'].value_counts().head(15).reset_index()['index'])\ndata = train_csv[train_csv['country'].isin(top15)]\n\nplt.figure(figsize=(12, 5))\nax = sns.countplot(data['country'], palette='hls', order = data['country'].value_counts().index)\n\nplt.title(\"Top 15 Countries with most Recordings\", fontsize=16)\nplt.ylabel(\"Frequency\", fontsize=14)\nplt.yticks(fontsize=13)\nplt.xticks(rotation=45, fontsize=13)\nplt.xlabel(\"\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"..... to be continued","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### mp3","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_csv['duration_interval'] = \">500\"\ntrain_csv.loc[train_csv['duration'] <= 100, 'duration_interval'] = \"<=100\"\ntrain_csv.loc[(train_csv['duration'] > 100) & (train_csv['duration'] <= 200), 'duration_interval'] = \"100-200\"\ntrain_csv.loc[(train_csv['duration'] > 200) & (train_csv['duration'] <= 300), 'duration_interval'] = \"200-300\"\ntrain_csv.loc[(train_csv['duration'] > 300) & (train_csv['duration'] <= 400), 'duration_interval'] = \"300-400\"\ntrain_csv.loc[(train_csv['duration'] > 400) & (train_csv['duration'] <= 500), 'duration_interval'] = \"400-500\"\n\nplt.figure(figsize=(12, 5))\nax = sns.countplot(train_csv['duration_interval'], palette=\"hls\")\n\nplt.title(\"Distribution of Recordings Duration\", fontsize=16)\nplt.ylabel(\"Frequency\", fontsize=14)\nplt.yticks(fontsize=13)\nplt.xticks(rotation=45, fontsize=13)\nplt.xlabel(\"\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"....to be continued","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Features extraction from audio","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The audio data is composed by:\n\n- **Sound**: sequence of vibrations in varying pressure strengths (y)\n- **Sample Rate**: (sr) is the number of samples of audio carried per second, measured in Hz or kHz","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"top7birds = list(train_csv['ebird_code'].value_counts().head(7).reset_index()['index'])\nprint(top7birds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"birds = dict()\nfor bird in top7birds:\n    birds[bird] = '../input/birdsong-recognition/train_audio/' + bird + '/' + train_csv[train_csv['ebird_code'] == bird].sample(1, random_state = 33)['filename'].values[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ipd.Audio(list(birds.values())[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ipd.Audio(list(birds.values())[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ipd.Audio(list(birds.values())[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ipd.Audio(list(birds.values())[3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ipd.Audio(list(birds.values())[4])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ipd.Audio(list(birds.values())[5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ipd.Audio(list(birds.values())[6])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"birds_audio = dict()\nfor bird in birds.keys():\n    y, sr = librosa.load(birds[bird])\n    birds_audio[bird], _ = librosa.effects.trim(y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"https://pudding.cool/2018/02/waveforms/\n\nhttps://musiclab.chromeexperiments.com/Spectrogram/\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(len(top7birds), figsize = (16, 9))\nfig.suptitle('Sound Waves', fontsize=16)\n\nfor i, bird in zip(range(len(top7birds)), top7birds):\n    librosa.display.waveplot(y = birds_audio[bird], sr = sr, ax=ax[i])\n    ax[i].set_ylabel(bird, fontsize=13)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"....to be continued","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}