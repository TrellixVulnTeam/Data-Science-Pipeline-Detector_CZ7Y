{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Welcome\n","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport librosa\nfrom collections import Counter\nimport plotly.express as px\nfrom plotly import graph_objs as go\n\nimport random\n\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.applications import ResNet50\n\nimport sklearn\nfrom pylab import *\nfrom scipy import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH = '../input/birdsong-recognition/'\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df =  pd.read_csv(PATH + 'train.csv')\ntest_df = pd.read_csv(PATH + 'test.csv')\nexample_test_audio_metadata = pd.read_csv(PATH + 'example_test_audio_metadata.csv')\nexample_test_audio_summary = pd.read_csv(PATH + 'example_test_audio_summary.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA\n### Part 1: analyz csv\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def info_df(df):\n    if 'ebird_code' in df.columns:\n        print('In train dataset: ')\n    else:\n        print('In test dataset: ')\n    print('Count of columns {}'.format(df.shape[1]))\n    print('String of columns {}'.format(df.shape[0]))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"info_df(train_df)\n\ninfo_df(test_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### in testdataset we have only 3 columns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top = Counter([ i for i in train_df['ebird_code']])\ntemp = pd.DataFrame(top.most_common(25))\ntemp.columns = ['Most_bird','count']\ntemp.style.background_gradient(cmap='Reds')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top = Counter([ i for i in train_df['ebird_code']])\ntemp = pd.DataFrame(top.most_common()[:-25:-1])\ntemp.columns = ['Least_bird','count']\ntemp.style.background_gradient(cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Most bird species have 100 records\n#### The minimum count of audio recordings is \"redhea\" - 9\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"top = Counter([ i for i in train_df['ebird_code']])\ntemp = pd.DataFrame(top.most_common(270))\n\ntemp.columns = ['Most_bird','count']\nfig = px.bar(temp, x=\"count\", y=\"Most_bird\", title='Distribution of birds in our dataset', orientation='h', \n             width=900, height=900, color='Most_bird')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nax = sns.barplot(x = 'channels', y = 'ebird_code', data = pd.DataFrame(train_df['ebird_code'].groupby(train_df['channels']).count()).reset_index(), palette=\"muted\")\nplt.title('Count of stereo and mono recordings', fontsize=16)\nplt.xlabel(\"\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top = Counter([ i for i in train_df['country']])\ntemp = pd.DataFrame(top.most_common(25))\ntemp.columns = ['Recordings per Country','count']\ntemp.style.background_gradient(cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### The largest count of  recordings in America","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = pd.DataFrame(top.most_common(100))\ntemp.columns = ['Most_common_countries','count']\nfig = px.bar(temp, x=\"count\", y=\"Most_common_countries\", title='Recordings per Country', orientation='h', \n             width=900, height=900, color='Most_common_countries')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf = px.data.gapminder().query(\"year==2007\")[[\"country\", \"iso_alpha\"]]\n\ndata = pd.merge(left=train_df, right=df, how=\"inner\", on=\"country\")\n\n# Group by country and count how many species can be found in each\ndata = data.groupby(by=[\"country\", \"iso_alpha\"]).count()[\"species\"].reset_index()\n\nfig = px.choropleth(data, locations=\"iso_alpha\", color=\"species\", hover_name=\"country\",\n                    color_continuous_scale=px.colors.sequential.Purpor,\n                    title = \"World Map: Recordings per Country\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### in some countries there are no records at all","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def bird_countries(view, df_view):\n    '''\n    input - ebird code, dataframe\n    output - distribution of bird around the countries\n    '''\n    df_view = df_view.loc[df_view['ebird_code']==view] \n    df = px.data.gapminder().query(\"year == 2007\")[[\"country\", \"iso_alpha\"]]\n    data = pd.merge(left=df_view, right=df, how=\"inner\", on=\"country\")\n    data = data.groupby(by=[\"country\", \"iso_alpha\"]).count()[\"species\"].reset_index()\n    fig = px.scatter_geo(data, locations=\"iso_alpha\",\n                     color=\"species\", # which column to use to set the color of markers\n                     hover_name=\"country\", # column added to hover information\n                     projection=\"natural earth\",\n                     title =\"World Map: {} per Country\".format(view))\n    fig.show() \n\n    \n    \n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### You can view the location of any bird by country","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"bird_countries('houspa', train_df)\nbird_countries('carwre', train_df)\nbird_countries('amepip', train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_country = pd.DataFrame(train_df['ebird_code'].groupby(train_df['country']).unique()).reset_index()\ntop = Counter([item for sublist in df_country['ebird_code'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(25))\ntemp.columns = ['bird_per_Countries','count']\ntemp.style.background_gradient(cmap='Greens')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_country = pd.DataFrame(train_df['ebird_code'].groupby(train_df['country']).unique()).reset_index()\ntop = Counter([item for sublist in df_country['ebird_code'] for item in sublist])\ntemp = pd.DataFrame(top.most_common()[:-25:-1])\ntemp.columns = ['bird_per_Countries','count']\ntemp.style.background_gradient(cmap='Reds')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Some bird voices recorded only in a single country","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = temp.loc[temp['count'] == 1]\ntemp['ebird_code'] = temp['bird_per_Countries']\ndata = pd.merge(left=temp, right=train_df, how=\"inner\", on=\"ebird_code\")[['ebird_code','country']]\npd.DataFrame(data['country'].groupby(data['ebird_code']).unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### All species with a single country are located in America","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def bird_location(view, df_view):\n    '''\n    input - ebird code, dataframe\n    output - bird location\n    '''\n    df_view = df_view.loc[df_view['ebird_code'] == view][['ebird_code','latitude','longitude']]\n    df_view = df_view.loc[df_view['longitude'] != 'Not specified']\n    df_view = df_view.loc[df_view['latitude'] != 'Not specified']\n    df_view['longitude'] = df_view.longitude.astype('float')\n    df_view['latitude'] = df_view.latitude.astype('float')\n    px.set_mapbox_access_token(\"pk.eyJ1IjoiYXJuaW1lbjUiLCJhIjoiY2tlM2U3a3EwMGliZzJ5bXNnYjE2YTJrciJ9.4GEtm-YYF0e0nIzyoSeABw\")\n    fig = px.scatter_mapbox(df_view, lat=\"latitude\", lon=\"longitude\",  color=\"latitude\", \n                  color_continuous_scale=px.colors.cyclical.IceFire, size_max=15, zoom=2,\n                            title ='latitude and longitude of the {} record'.format(view))\n    fig.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bird_location('houspa', train_df)\nbird_location('carwre', train_df)\nbird_location('amepip', train_df)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Part 2 audio analysis","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### The audio data is composed by:\n\n##### Sound: sequence of vibrations in varying pressure strengths (y)\n#### Sample Rate: (sr) is the number of samples of audio carried per second, measured in Hz or kHz","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"audio_path = []\nfor i in train_df.index:\n    initial_letter = train_df.loc[i]['ebird_code'][0] \n    if initial_letter < 'c':\n        audio_path.append('../input/birdsong-resampled-train-audio-00/')\n    elif initial_letter < 'g':\n        audio_path.append('../input/birdsong-resampled-train-audio-01/')\n    elif initial_letter < 'n':\n        audio_path.append('../input/birdsong-resampled-train-audio-02/')\n    elif initial_letter < 's':\n        audio_path.append('../input/birdsong-resampled-train-audio-03/')\n    else:\n        audio_path.append('../input/birdsong-resampled-train-audio-04/')\n        \ntrain_df['audio_path'] = audio_path","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def random_audio(df):\n    index = random.choice(list(df.index))\n    name = '{}{}/{}.wav'.format(df.loc[index]['audio_path'] , df.loc[index]['ebird_code'],  df.loc[index]['filename'].split('.')[0])\n    y, sr = librosa.load(name)\n    print('y:', y, '\\n')\n    print('y shape:', np.shape(y), '\\n')\n    print('Sample Rate (KHz):', sr, '\\n')\n    print('Check Len of Audio:', np.shape(y)[0]/sr)\n    return y, sr \n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y, sr = random_audio(train_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### analysis of a signal fragment","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.io import wavfile as wav\nimport scipy\n\ndef anlysis_signal(df):\n    index = random.choice(list(df.index))\n    name = '{}{}/{}.wav'.format(df.loc[index]['audio_path'] , df.loc[index]['ebird_code'],  df.loc[index]['filename'].split('.')[0])\n    M=501\n    fig = plt.figure(figsize=(25,12))\n    hM1=int(np.floor((1+M)/2))\n    hM2=int(np.floor(M/2))\n    (fs,x)=wav.read(name)\n    x1=x[5000:5000+M]*np.hamming(M)\n    N=511\n    fftbuffer=np.zeros([N])\n    fftbuffer[:hM1]=x1[hM2:]\n    fftbuffer[N-hM2:]=x1[:hM2]\n    X=scipy.fft.fft(fftbuffer)\n    mX=abs(X)\n    pX=np.angle(X)\n    suptitle(\"Signal analysis {}\".format(df.loc[index]['filename'].split('.')[0]))\n    subplot(3, 1, 1)\n    st='input signal {}'.format(df.loc[index]['ebird_code'])\n    plt.title(st, fontsize=16)\n    plot(x,linewidth=2, c = 'green')\n    legend(loc='center')\n    subplot(3, 1, 2)\n    st='Frequency spectrum of the input signal'\n    plt.title(st, fontsize=16)\n    plot(mX,linewidth=2, c = 'red')\n    legend(loc='best')\n    subplot(3, 1, 3)\n    st='Phase spectrum of the input signal'\n    pX=np.unwrap(np.angle(X))\n    plt.title(st, fontsize=16)\n    plot(pX,linewidth=2)\n    legend(loc='best') \n    show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(3):\n    anlysis_signal(train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def audios_ebird(label, df):\n    df = df.loc[df['ebird_code'] == label]\n    index = random.choice(df.index)\n    name = '{}{}/{}.wav'.format(df.loc[index]['audio_path'] , df.loc[index]['ebird_code'],  df.loc[index]['filename'].split('.')[0])\n    y, sr = librosa.load(name)\n    return y, sr\n\n\ncolor = ['red', 'green', 'yellow', 'orange', 'blue']\ndef visualization_audio_bird(label, df):\n    col = random.choice(color)\n    fig = plt.figure(figsize=(25,12))\n    df = df.loc[df['ebird_code'] == label][['ebird_code','filename','audio_path']]\n    fig.suptitle(label, fontsize=30, c=col)\n    num = 0\n    for index in df.index:\n        num += 1\n        if num > 20:\n            break\n        plt.subplot(5,4,num)\n        filepath = '{}{}/{}.wav'.format(df.loc[index]['audio_path'] , df.loc[index]['ebird_code'],  df.loc[index]['filename'].split('.')[0])\n        clip, sample_rate = librosa.load(filepath, sr=None)\n        plt.axis('off')\n        plt.plot(clip, c=col, lw=0.5)\n        \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"visualization_audio_bird('aldfly', train_df)\nvisualization_audio_bird('osprey', train_df)\nvisualization_audio_bird('coohaw', train_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing\n##### Now we can extract features from our data. We’re going to be using librosa, but we’ll also show another utility, scipy.io,\n#### for comparison and to observe some implicit preprocessing that’s happening.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def random_audio_sample_rate(df):\n    index = random.choice(list(df.index))\n    name = '{}{}/{}.wav'.format(df.loc[index]['audio_path'] , df.loc[index]['ebird_code'],  df.loc[index]['filename'].split('.')[0])\n    librosa_audio, librosa_sample_rate = librosa.load(name)\n    scipy_sample_rate, scipy_audio = wav.read(name)\n    print(\"Original sample rate: {}\".format(scipy_sample_rate))\n    print(\"Librosa sample rate: {}\".format(librosa_sample_rate))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_audio_sample_rate(train_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###  Librosa’s load function will convert the sampling rate to 22.05 KHz automatically.\n### It will also normalize the bit depth between -1 and 1.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def audio_file_min_max(df):\n    index = random.choice(list(df.index))\n    name = '{}{}/{}.wav'.format(df.loc[index]['audio_path'] , df.loc[index]['ebird_code'],  df.loc[index]['filename'].split('.')[0])\n    librosa_audio, librosa_sample_rate = librosa.load(name)\n    scipy_sample_rate, scipy_audio = wav.read(name)\n    print('Original audio file min~max range: {} to {}'.format(np.min(scipy_audio), np.max(scipy_audio)))\n    print('Librosa audio file min~max range: {0:.2f} to {0:.2f}'.format(np.min(librosa_audio), np.max(librosa_audio)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"audio_file_min_max(train_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Extracting MFCCs from audio using Librosa\n\n##### MFCC - Mel Frequency Cepstral Coefficient\n##### What is a MFCC? MFCC is a kind of representation of the signal spectrum energy.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import librosa\nimport librosa.display\n\ndef mfccs(df):\n    index = random.choice(list(df.index))\n    name = '{}{}/{}.wav'.format(df.loc[index]['audio_path'] , df.loc[index]['ebird_code'],  df.loc[index]['filename'].split('.')[0])\n    librosa_audio, librosa_sample_rate = librosa.load(name)\n    mfccs = librosa.feature.mfcc(y=librosa_audio, sr=librosa_sample_rate, n_mels = 128, fmin=20, fmax=16000)\n    plt.figure (figsize = (8,8))\n    librosa.display.specshow(mfccs, sr = librosa_sample_rate, x_axis = 'time')\n    plt.title('MFCC')\n    return mfccs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mfcc = mfccs(train_df)\nprint(mfcc.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Now we can get a spectogram","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"###### *What is a spectrogram? A spectrogram is a visual representation of the spectrum of frequencies of a signal as it varies with time. When applied to an audio signal, spectrograms are sometimes called sonographs, voiceprints, or voicegrams (wiki).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def linear_spectrogram(df):\n    index = random.choice(list(df.index))\n    name = '{}{}/{}.wav'.format(df.loc[index]['audio_path'] , df.loc[index]['ebird_code'],  df.loc[index]['filename'].split('.')[0])\n    librosa_audio, librosa_sample_rate = librosa.load(name)\n    D = librosa.stft(librosa_audio)  # \n    S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n    plt.figure (figsize = (8,8))\n    ### You can display the spectrogram using librosa.display.specshow \n    librosa.display.specshow(S_db)\n    plt.title('linear_spectrogram')\n    plt.colorbar()\n    return linear_spectrogram\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"linear_spectrogram(train_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### A spectrogram is a visual way to represent the level or “volume” of a signal over time at various frequencies present in a waveform. It is usually shown as a heat map.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### The next version will learn the model\n# thanks for watching) ","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}