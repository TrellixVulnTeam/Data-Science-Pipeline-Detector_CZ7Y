{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/mcdermottLab/pycochleagram.git","metadata":{"execution":{"iopub.status.busy":"2021-09-10T15:25:08.137158Z","iopub.execute_input":"2021-09-10T15:25:08.137729Z","iopub.status.idle":"2021-09-10T15:25:10.812602Z","shell.execute_reply.started":"2021-09-10T15:25:08.13763Z","shell.execute_reply":"2021-09-10T15:25:10.8114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg -y libasound2-dev","metadata":{"execution":{"iopub.status.busy":"2021-09-10T15:25:10.814977Z","iopub.execute_input":"2021-09-10T15:25:10.815296Z","iopub.status.idle":"2021-09-10T15:25:13.963275Z","shell.execute_reply.started":"2021-09-10T15:25:10.815263Z","shell.execute_reply":"2021-09-10T15:25:13.962093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install pqdm","metadata":{"execution":{"iopub.status.busy":"2021-09-10T15:25:13.966108Z","iopub.execute_input":"2021-09-10T15:25:13.966575Z","iopub.status.idle":"2021-09-10T15:25:23.842007Z","shell.execute_reply.started":"2021-09-10T15:25:13.966521Z","shell.execute_reply":"2021-09-10T15:25:23.841043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os,glob,re,math\nimport pandas as pd\nimport numpy as np\nimport librosa\nimport matplotlib.pyplot as plt\nget_ipython().run_line_magic('matplotlib', 'inline')\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom tqdm import tqdm\nfrom pqdm.processes import pqdm\nimport cv2\nimport librosa\n#from itertools import islice\nimport matplotlib\nimport tensorflow as tf\nfrom scipy.signal import freqz\nimport torch\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-09-10T15:25:23.843752Z","iopub.execute_input":"2021-09-10T15:25:23.844051Z","iopub.status.idle":"2021-09-10T15:25:33.444911Z","shell.execute_reply.started":"2021-09-10T15:25:23.84402Z","shell.execute_reply":"2021-09-10T15:25:33.443723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(os.getcwd())\nos.chdir('./pycochleagram')\nprint(os.getcwd())\n!python setup.py install","metadata":{"execution":{"iopub.status.busy":"2021-09-10T15:25:33.447503Z","iopub.execute_input":"2021-09-10T15:25:33.447835Z","iopub.status.idle":"2021-09-10T15:25:36.035139Z","shell.execute_reply.started":"2021-09-10T15:25:33.447797Z","shell.execute_reply":"2021-09-10T15:25:36.034158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.chdir('/kaggle/working')","metadata":{"execution":{"iopub.status.busy":"2021-09-10T15:25:36.036354Z","iopub.execute_input":"2021-09-10T15:25:36.036639Z","iopub.status.idle":"2021-09-10T15:25:36.041485Z","shell.execute_reply.started":"2021-09-10T15:25:36.036609Z","shell.execute_reply":"2021-09-10T15:25:36.040506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from distutils.dir_util import copy_tree\ncopy_tree(\"../input/cochleagramfile\", \"../working/\")","metadata":{"execution":{"iopub.status.busy":"2021-09-10T15:25:36.042846Z","iopub.execute_input":"2021-09-10T15:25:36.043131Z","iopub.status.idle":"2021-09-10T15:25:36.376669Z","shell.execute_reply.started":"2021-09-10T15:25:36.043105Z","shell.execute_reply":"2021-09-10T15:25:36.375598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pydub import AudioSegment\n\nimport cochleagram as cgram\nimport demo\nimport erbfilter as erb\n\nfrom librosa.display import waveplot\nfrom scipy.signal import butter, lfilter\nfrom skimage.restoration import denoise_wavelet \nfrom scipy import signal","metadata":{"execution":{"iopub.status.busy":"2021-09-10T15:25:36.380711Z","iopub.execute_input":"2021-09-10T15:25:36.381157Z","iopub.status.idle":"2021-09-10T15:25:38.257482Z","shell.execute_reply.started":"2021-09-10T15:25:36.381119Z","shell.execute_reply":"2021-09-10T15:25:38.2562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ROOT_DIR = '../input/birdsong-recognition/'\nTRAIN_AUDIO = f'{ROOT_DIR}/train_audio'","metadata":{"execution":{"iopub.status.busy":"2021-09-10T15:25:38.262206Z","iopub.execute_input":"2021-09-10T15:25:38.262582Z","iopub.status.idle":"2021-09-10T15:25:38.266957Z","shell.execute_reply.started":"2021-09-10T15:25:38.262544Z","shell.execute_reply":"2021-09-10T15:25:38.266013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CLASS = os.listdir('../input/birdsong-recognition/train_audio')\n\ntrain_audio = glob.glob('../input/birdsong-recognition/train_audio/*/*.mp3')\ntrain_audio_1 =glob.glob('../input/xeno-canto-bird-recordings-extended-a-m/A-M/*/*.mp3')\ntrain_audio_2 = glob.glob('../input/xeno-canto-bird-recordings-extended-n-z/N-Z/*/*.mp3')\n\ndf = pd.read_csv('../input/birdsong-recognition/train.csv')\n\ndf = df[['ebird_code', 'filename', 'duration','author','country','rating']]\ndf1 = pd.read_csv('../input/xeno-canto-bird-recordings-extended-a-m/train_extended.csv')[['ebird_code', 'filename', 'duration','author','country','rating']]\ndf2 = pd.read_csv('../input/xeno-canto-bird-recordings-extended-n-z/train_extended.csv')[['ebird_code', 'filename', 'duration','author','country','rating']]\n\nframes_temp = pd.concat([df1,df2])\n\ndftemp = pd.read_csv('../input/freefield1010-cochlea/data/train_ff1010.csv')\n\nlist1 = ['Cornell Bird identification',len(set(df['ebird_code'])),len(df['ebird_code'])]\nlist2 = ['Xeno-canto',len(set(frames_temp['ebird_code'])),len(frames_temp['ebird_code'])]\nlist3 = ['freefeild1010','no call',len(dftemp['filename'])]\nlist4 = ['Cornell Bird identification + Xeno-canto + freefeild1010',str(len(set(frames_temp['ebird_code']))) + ' Species' +' and nocall',len(df['ebird_code'])+len(frames_temp['ebird_code'])+len(dftemp['filename'])]\n\ndftable = pd.DataFrame([list1,list2,list3,list4],columns = ['Dataset','Number of classes/ bird species','Number of recordings'])\n\ndftable.to_csv('dftable.csv')\n\nframes = pd.concat([df,df1,df2])\n\npath = train_audio + train_audio_1 + train_audio_2\npath.remove('../input/birdsong-recognition/train_audio/lotduc/XC195038.mp3')\n# path.remove('../input/xeno-canto-bird-recordings-extended-a-m/A-M/houspa/XC555482.mp3')","metadata":{"execution":{"iopub.status.busy":"2021-09-10T15:25:38.268183Z","iopub.execute_input":"2021-09-10T15:25:38.268785Z","iopub.status.idle":"2021-09-10T15:25:52.796868Z","shell.execute_reply.started":"2021-09-10T15:25:38.26875Z","shell.execute_reply":"2021-09-10T15:25:52.795946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class cochleagram:\n    IMAGE_HEIGHT = 256\n    IMAGE_WIDTH = 576\n    SR=32000\n    hi_lim = SR//2\n    low_lim = 10\n    n_filters = int(np.floor(erb.freq2erb(hi_lim) - erb.freq2erb(low_lim)) - 1)\n    nonlinearity = 'db'\n    ret_mode='envs',\n    sample_factor = 2   # 87.5% overlap 2-75% verlap","metadata":{"execution":{"iopub.status.busy":"2021-09-10T15:25:52.797944Z","iopub.execute_input":"2021-09-10T15:25:52.798354Z","iopub.status.idle":"2021-09-10T15:25:52.80371Z","shell.execute_reply.started":"2021-09-10T15:25:52.798323Z","shell.execute_reply":"2021-09-10T15:25:52.80273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# test","metadata":{}},{"cell_type":"code","source":"signal, sr = librosa.load('../input/birdsong-recognition/train_audio/aldfly/XC134874.mp3',sr = None,duration = 10)\n\nhuman_co = cgram.human_cochleagram(signal,sr =cochleagram.SR,\n                             n = cochleagram.n_filters,\n                             low_lim = cochleagram.low_lim, hi_lim =cochleagram.hi_lim,\n                             sample_factor = cochleagram.sample_factor,\n                             nonlinearity=cochleagram.nonlinearity)\n\nimport cv2\nres = cv2.resize(np.flipud(human_co), dsize=(576,256), interpolation=cv2.INTER_CUBIC)\n\nplt.imshow(res, aspect='auto')","metadata":{"execution":{"iopub.status.busy":"2021-09-10T15:25:52.80483Z","iopub.execute_input":"2021-09-10T15:25:52.805321Z","iopub.status.idle":"2021-09-10T15:26:01.465844Z","shell.execute_reply.started":"2021-09-10T15:25:52.805258Z","shell.execute_reply":"2021-09-10T15:26:01.464228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config_patch = {'use_inv_stem' : True,\n          'use_patch' : [True,16],}","metadata":{"execution":{"iopub.status.busy":"2021-09-10T15:26:01.46811Z","iopub.execute_input":"2021-09-10T15:26:01.46878Z","iopub.status.idle":"2021-09-10T15:26:01.475669Z","shell.execute_reply.started":"2021-09-10T15:26:01.468725Z","shell.execute_reply":"2021-09-10T15:26:01.474417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inv_stem(x):\n    print(x.shape)\n    x1 = x.transpose(0, 1).view(24, 24, 16, 16)\n    y = torch.zeros(384, 384, dtype=x.dtype)\n    for i in range(24):\n        for j in range(24):\n            y[i*16:(i+1)*16, j*16:(j+1)*16] = x1[i, j]\n    return y","metadata":{"execution":{"iopub.status.busy":"2021-09-10T15:26:01.477579Z","iopub.execute_input":"2021-09-10T15:26:01.478253Z","iopub.status.idle":"2021-09-10T15:26:01.490474Z","shell.execute_reply.started":"2021-09-10T15:26:01.478202Z","shell.execute_reply":"2021-09-10T15:26:01.489481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def image_patch(mel_spect):\n    if config_patch.get('use_inv_stem'):\n#         spect = torch.from_numpy(np.flip(mel_spect).copy())\n        spect = torch.from_numpy(mel_spect.copy())\n        spect = inv_stem(spect)\n#         print(spect.shape)\n    else:\n        if config_patch.get('use_patch')[0]:\n            patch_size = config_patch.get('use_patch')[1]\n            spect = np.zeros((384, 384), dtype=np.float32)\n        for i in range(0, 192, patch_size):\n            spect[2 * i : 2 * i + patch_size, :] = mel_spect[i : i + patch_size, : 384]\n            spect[2 * i + patch_size : 2 * i + 2*patch_size, :] = mel_spect[i : i + patch_size, 384 : ]\n            mel_spect = spect\n    return spect.cpu().detach().numpy()","metadata":{"execution":{"iopub.status.busy":"2021-09-10T15:26:01.491664Z","iopub.execute_input":"2021-09-10T15:26:01.492372Z","iopub.status.idle":"2021-09-10T15:26:01.505166Z","shell.execute_reply.started":"2021-09-10T15:26:01.492339Z","shell.execute_reply":"2021-09-10T15:26:01.503876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(image_patch(res), aspect='auto')","metadata":{"execution":{"iopub.status.busy":"2021-09-10T15:26:01.506463Z","iopub.execute_input":"2021-09-10T15:26:01.506906Z","iopub.status.idle":"2021-09-10T15:26:01.801383Z","shell.execute_reply.started":"2021-09-10T15:26:01.506876Z","shell.execute_reply":"2021-09-10T15:26:01.800544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# test end","metadata":{}},{"cell_type":"code","source":"def cochlea(file_path):\n    signal, sr = librosa.load(file_path,sr = None,duration = 10)\n    human_co = cgram.human_cochleagram(signal,sr =cochleagram.SR,\n                             n = cochleagram.n_filters,\n                             low_lim = cochleagram.low_lim, hi_lim =cochleagram.hi_lim,\n                             sample_factor = cochleagram.sample_factor,\n                             nonlinearity=cochleagram.nonlinearity)\n    return human_co","metadata":{"execution":{"iopub.status.busy":"2021-09-10T15:26:01.802433Z","iopub.execute_input":"2021-09-10T15:26:01.802913Z","iopub.status.idle":"2021-09-10T15:26:01.809571Z","shell.execute_reply.started":"2021-09-10T15:26:01.80288Z","shell.execute_reply":"2021-09-10T15:26:01.808272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config_patch = {'use_inv_stem' : True,\n          'use_patch' : [True,16],}","metadata":{"execution":{"iopub.status.busy":"2021-09-10T15:26:01.811501Z","iopub.execute_input":"2021-09-10T15:26:01.812442Z","iopub.status.idle":"2021-09-10T15:26:01.830353Z","shell.execute_reply.started":"2021-09-10T15:26:01.812388Z","shell.execute_reply":"2021-09-10T15:26:01.828371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inv_stem(x):\n    print(x.shape)\n    x1 = x.transpose(0, 1).view(24, 24, 16, 16)\n    y = torch.zeros(384, 384, dtype=x.dtype)\n    for i in range(24):\n        for j in range(24):\n            y[i*16:(i+1)*16, j*16:(j+1)*16] = x1[i, j]\n    return y","metadata":{"execution":{"iopub.status.busy":"2021-09-10T15:26:01.831944Z","iopub.execute_input":"2021-09-10T15:26:01.832522Z","iopub.status.idle":"2021-09-10T15:26:01.846355Z","shell.execute_reply.started":"2021-09-10T15:26:01.832485Z","shell.execute_reply":"2021-09-10T15:26:01.844909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def image_patch(mel_spect):\n    if config_patch.get('use_inv_stem'):\n#         spect = torch.from_numpy(np.flip(mel_spect).copy())\n        spect = torch.from_numpy(mel_spect.copy())\n        spect = inv_stem(spect)\n#         print(spect.shape)\n    else:\n        if config_patch.get('use_patch')[0]:\n            patch_size = config_patch.get('use_patch')[1]\n            spect = np.zeros((384, 384), dtype=np.float32)\n        for i in range(0, 192, patch_size):\n            spect[2 * i : 2 * i + patch_size, :] = mel_spect[i : i + patch_size, : 384]\n            spect[2 * i + patch_size : 2 * i + 2*patch_size, :] = mel_spect[i : i + patch_size, 384 : ]\n            mel_spect = spect\n    return spect.cpu().detach().numpy()","metadata":{"execution":{"iopub.status.busy":"2021-09-10T15:26:01.848079Z","iopub.execute_input":"2021-09-10T15:26:01.848826Z","iopub.status.idle":"2021-09-10T15:26:01.86571Z","shell.execute_reply.started":"2021-09-10T15:26:01.848785Z","shell.execute_reply":"2021-09-10T15:26:01.864531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_allgroup = []\nseq = path\nsubStr_list = [ f.name for f in os.scandir('../input/birdsong-recognition/train_audio') if f.is_dir() ]\n\nfor name in subStr_list:\n    list_temp = []\n    for text in path:\n        if name in text:\n            list_temp.append(text)\n    list_allgroup.append(list_temp)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T15:26:01.86703Z","iopub.execute_input":"2021-09-10T15:26:01.867661Z","iopub.status.idle":"2021-09-10T15:26:03.368618Z","shell.execute_reply.started":"2021-09-10T15:26:01.867629Z","shell.execute_reply":"2021-09-10T15:26:03.36746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_allgroup = sorted(list_allgroup)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T15:26:03.3703Z","iopub.execute_input":"2021-09-10T15:26:03.370816Z","iopub.status.idle":"2021-09-10T15:26:03.376613Z","shell.execute_reply.started":"2021-09-10T15:26:03.37077Z","shell.execute_reply":"2021-09-10T15:26:03.375509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(list_allgroup)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T15:26:03.379641Z","iopub.execute_input":"2021-09-10T15:26:03.379986Z","iopub.status.idle":"2021-09-10T15:26:03.392422Z","shell.execute_reply.started":"2021-09-10T15:26:03.379954Z","shell.execute_reply":"2021-09-10T15:26:03.391356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_chucks = []\n\nfour_split = np.array_split(list_allgroup,12 )\nfor array in four_split:\n    list_chucks.append((list(array)))","metadata":{"execution":{"iopub.status.busy":"2021-09-10T15:26:52.023208Z","iopub.execute_input":"2021-09-10T15:26:52.024126Z","iopub.status.idle":"2021-09-10T15:26:52.043095Z","shell.execute_reply.started":"2021-09-10T15:26:52.024064Z","shell.execute_reply":"2021-09-10T15:26:52.042121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_allgroup = list_chucks[0]","metadata":{"execution":{"iopub.status.busy":"2021-09-10T15:26:56.120915Z","iopub.execute_input":"2021-09-10T15:26:56.121466Z","iopub.status.idle":"2021-09-10T15:26:56.125427Z","shell.execute_reply.started":"2021-09-10T15:26:56.121424Z","shell.execute_reply":"2021-09-10T15:26:56.12464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_root_dir = \"cochleagram\"\nos.makedirs(os.path.join(output_root_dir), exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T15:26:57.525058Z","iopub.execute_input":"2021-09-10T15:26:57.525709Z","iopub.status.idle":"2021-09-10T15:26:57.530311Z","shell.execute_reply.started":"2021-09-10T15:26:57.52564Z","shell.execute_reply":"2021-09-10T15:26:57.529422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\n  \nsrc = '../input/freefield1010-cochlea/data/nocall'\ntrg = './cochleagram/nocall/'\n\nos.makedirs(trg, exist_ok=True)\n\nfiles=os.listdir(src)\n \n# iterating over all the files in\n# the source directory\nfor fname in files:\n    shutil.copy2(os.path.join(src,fname), trg)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T15:26:58.910131Z","iopub.execute_input":"2021-09-10T15:26:58.910859Z","iopub.status.idle":"2021-09-10T15:27:51.462117Z","shell.execute_reply.started":"2021-09-10T15:26:58.910808Z","shell.execute_reply":"2021-09-10T15:27:51.461143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def long_substr(data):\n    substrs = lambda x: {x[i:i+j] for i in range(len(x)) for j in range(len(x) - i + 1)}\n    s = substrs(data[0])\n    for val in data[1:]:\n        s.intersection_update(substrs(val))\n    return max(s, key=len).split('/')[1].strip()","metadata":{"execution":{"iopub.status.busy":"2021-09-10T15:27:51.463567Z","iopub.execute_input":"2021-09-10T15:27:51.464001Z","iopub.status.idle":"2021-09-10T15:27:51.469906Z","shell.execute_reply.started":"2021-09-10T15:27:51.46397Z","shell.execute_reply":"2021-09-10T15:27:51.46915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_allgroup[0][0]","metadata":{"execution":{"iopub.status.busy":"2021-09-10T15:27:51.471409Z","iopub.execute_input":"2021-09-10T15:27:51.471832Z","iopub.status.idle":"2021-09-10T15:27:51.487142Z","shell.execute_reply.started":"2021-09-10T15:27:51.471799Z","shell.execute_reply":"2021-09-10T15:27:51.486089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(list_allgroup)","metadata":{"execution":{"iopub.status.busy":"2021-09-10T15:27:51.488912Z","iopub.execute_input":"2021-09-10T15:27:51.489646Z","iopub.status.idle":"2021-09-10T15:27:51.499792Z","shell.execute_reply.started":"2021-09-10T15:27:51.4896Z","shell.execute_reply":"2021-09-10T15:27:51.498959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pathlib","metadata":{"execution":{"iopub.status.busy":"2021-09-07T23:12:26.034565Z","iopub.execute_input":"2021-09-07T23:12:26.035478Z","iopub.status.idle":"2021-09-07T23:12:26.042532Z","shell.execute_reply.started":"2021-09-07T23:12:26.035427Z","shell.execute_reply":"2021-09-07T23:12:26.041509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for sub_list in list_allgroup:\n# def final_cochlea(sub_list):\n    x_bird = pathlib.PurePath(sub_list[0])\n    bird_name = x_bird.parent.name\n    print(bird_name)\n    os.makedirs(os.path.join(output_root_dir,bird_name), exist_ok=True)\n    for path_file in sub_list:\n        fileName = os.path.basename(path_file)[:-4]\n        human_co = cochlea(path_file)\n        res = cv2.resize(np.flipud(human_co), dsize=(576,256), interpolation=cv2.INTER_CUBIC)\n        img = image_patch(res)\n        matplotlib.image.imsave(os.path.join(os.path.join(output_root_dir,bird_name,\"{}.jpg\".format(fileName))), img*255)\n#         cv2.imwrite(os.path.join(os.path.join(output_root_dir,bird_name,\"{}.jpg\".format(fileName))),img*255)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T03:02:22.111545Z","iopub.execute_input":"2021-09-08T03:02:22.111907Z","iopub.status.idle":"2021-09-08T03:03:19.087998Z","shell.execute_reply.started":"2021-09-08T03:02:22.111877Z","shell.execute_reply":"2021-09-08T03:03:19.085706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# res = pqdm(list_allgroup, final_cochlea, n_jobs=8)","metadata":{"execution":{"iopub.status.busy":"2021-09-07T23:12:26.055944Z","iopub.execute_input":"2021-09-07T23:12:26.056357Z","iopub.status.idle":"2021-09-08T03:01:50.872014Z","shell.execute_reply.started":"2021-09-07T23:12:26.056325Z","shell.execute_reply":"2021-09-08T03:01:50.865637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir('./cochleagram')","metadata":{"execution":{"iopub.status.busy":"2021-09-08T03:03:31.837475Z","iopub.execute_input":"2021-09-08T03:03:31.837856Z","iopub.status.idle":"2021-09-08T03:03:31.846226Z","shell.execute_reply.started":"2021-09-08T03:03:31.837824Z","shell.execute_reply":"2021-09-08T03:03:31.845525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# coch = demo.demo_human_cochleagram_helper(signal,sr,50, nonlinearity=None)\n# coch_log = demo.demo_human_cochleagram_helper(signal,sr,50,nonlinearity='db')\n# coch_pow = demo.demo_human_cochleagram_helper(signal,sr,50,nonlinearity='power' )","metadata":{"execution":{"iopub.status.busy":"2021-09-08T03:01:50.87786Z","iopub.status.idle":"2021-09-08T03:01:50.87855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import utils\n# plt.figure(figsize=(10, 4))\n# plt.title('Cochleagram with no nonlinearity')\n# plt.ylabel('Filter #')\n# plt.xlabel('time')\n# utils.cochshow(np.flipud(coch), interact=False, cmap = 'viridis')\n# plt.gca().invert_yaxis()\n# plt.savefig('Cochleagram with no nonlinearity.png', bbox_inches='tight',transparent = True)\n\n\n# plt.figure(figsize=(10, 4))\n# plt.title('Cochleagram with nonlinearity: decibel')\n# plt.ylabel('Filter #')\n# plt.xlabel('time')\n# utils.cochshow(np.flipud(coch_log), interact=False, cmap = 'viridis')\n# plt.gca().invert_yaxis()\n# plt.savefig('Cochleagram with no nonlinearity_log.png', bbox_inches='tight',transparent = True)\n\n\n# plt.figure(figsize=(10, 4))\n# plt.title('Cochleagram with nonlinearity: power')\n# plt.ylabel('Filter #')\n# plt.xlabel('time')\n# utils.cochshow(np.flipud(coch_pow), interact=False, cmap = 'viridis')\n# plt.gca().invert_yaxis()\n# plt.savefig('Cochleagram with no nonlinearity_pow.png', bbox_inches='tight',transparent = True)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T03:01:50.880523Z","iopub.status.idle":"2021-09-08T03:01:50.881248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Done","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}