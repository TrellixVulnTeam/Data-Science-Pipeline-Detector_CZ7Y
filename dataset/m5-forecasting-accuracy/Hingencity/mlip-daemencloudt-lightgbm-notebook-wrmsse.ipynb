{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Credits:\n*  We used the notebook: https://www.kaggle.com/rohitsingh9990/m5-lgbm-fe as a baseline for this notebook.\n*  Wrmsse objective function code from: https://www.kaggle.com/girmdshinsei/for-japanese-beginner-with-wrmsse-in-lgbm/notebook","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport os\nimport numpy as np\nimport dask.dataframe as dd\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_rows', 500)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport lightgbm as lgb\nfrom sklearn import preprocessing, metrics\nimport gc\nimport joblib\nimport warnings\nfrom sklearn.neighbors import KNeighborsRegressor\nwarnings.filterwarnings('ignore')\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.tree import DecisionTreeRegressor\nimport datetime\nfrom sklearn.metrics import mean_squared_error\nfrom scipy.sparse import csr_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"INPUT_DIR_PATH = '../input/mlip-daemencloudt-feature-computation-notebook/'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Functions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_dir(path):\n    for dirname, _, filenames in os.walk(path):\n        for filename in filenames:\n            print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Functions for val/train split","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_test_split(data):\n     \n    # going to evaluate with the last 28 days\n    x_train = data[data['date'] <= '2016-03-27']\n    y_train = x_train['demand']\n    x_val = data[(data['date'] > '2016-03-27') & (data['date'] <= '2016-04-24')]\n    y_val = x_val['demand']\n    test = data[(data['date'] > '2016-04-24')]\n    del data\n    gc.collect()\n    return x_train, y_train, x_val, y_val, test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Functions for running LightGBM","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def run_lgb(x_train, y_train, x_val, y_val, test):\n    \n    params = {\n        #'boosting_type': 'dart',\n        'metric': 'custom',\n        'objective': 'tweedie',\n        'tweedie_variance_power': 1.1, \n        'seed': 20,\n        'learning_rate': 0.1,\n        'num_iterations':2000,\n        'max_bin':500,\n        'min_data_in_leaf' : 100,\n        'feature fraction': 0.5, \n        'num_leaves': 100,\n        'bagging_fraction': 0.3,\n        'bagging_freq': 1\n        }\n    \n    evals_result = {}\n\n    train_set = lgb.Dataset(x_train[features], y_train)\n    val_set = lgb.Dataset(x_val[features], y_val)\n    \n    del x_train, y_train\n    \n    model = lgb.train(params, train_set,early_stopping_rounds = 250, valid_sets = [train_set, val_set], verbose_eval = 10, feval= wrmsse,\\\n                       evals_result=evals_result)\n    \n    ax = lgb.plot_metric(evals_result)\n    plt.show()\n    \n    val_pred = model.predict(x_val[features], num_iteration=model.best_iteration)\n    y_pred = model.predict(test[features], num_iteration=model.best_iteration)\n    test['demand'] = y_pred\n    del y_pred \n    gc.collect()\n    return test, model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rmse(predictions, y):\n    return np.sqrt(mean_squared_error(y, predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Function for the submission","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(test, submission):\n    predictions = test[['id', 'date', 'demand']]\n    predictions = pd.pivot(predictions, index = 'id', columns = 'date', values = 'demand').reset_index()\n    predictions.columns = ['id'] + ['F' + str(i + 1) for i in range(28)]\n\n    evaluation_rows = [row for row in submission['id'] if 'evaluation' in row] \n    evaluation = submission[submission['id'].isin(evaluation_rows)]\n\n    validation = submission[['id']].merge(predictions, on = 'id')\n    final = pd.concat([validation, evaluation])\n    final.to_csv('submission_new.csv', index = False)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Global variables","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"features = [\n    \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\", \"event_name_1\", \"event_type_1\", \"snap_CA\", \"snap_TX\", \\\n    \"snap_WI\", \"sell_price\", \\\n    # demand features.\n    \"shift_t28\",   \\\n     \"rolling_mean_28_7\",\"rolling_mean_28_28\",  \\\n    # price features\n    \"price_change_t1\", \n    # time features.\n    \"year\", \"month\", \"dayofweek\", \"before_holiday\", \"after_holiday\"\n]\n\n\n\n\nprint(f'length: {len(features)}')\nprint(features)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Main part","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Loading the preprocessed data our feature computation notebook: https://www.kaggle.com/hingencity/mlip-daemencloudt-feature-computation-notebook ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_pickle(f'{INPUT_DIR_PATH}Features{1}.pkl')\nfor i in range(2,6):\n    data = pd.concat([data, pd.read_pickle(f'{INPUT_DIR_PATH}Features{i}.pkl')])\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Japanese WRMSSE\nThe wrmsse code of the japanese beginner notebook: https://www.kaggle.com/girmdshinsei/for-japanese-beginner-with-wrmsse-in-lgbm/notebook to add a wrmsse metric to the LightGBM tree","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train_val = pd.read_csv('/kaggle/input/m5-forecasting-accuracy/sales_train_validation.csv')\n\nNUM_ITEMS = sales_train_val.shape[0]\n\nsubmission = pd.read_csv('/kaggle/input/m5-forecasting-accuracy/sample_submission.csv')\nDAYS_PRED = submission.shape[1] - 1  # 28\nproduct = sales_train_val[['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id']].drop_duplicates()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weight_mat = np.c_[np.ones([NUM_ITEMS,1]).astype(np.int8), # level 1\n                   pd.get_dummies(product.state_id.astype(str),drop_first=False).astype('int8').values,\n                   pd.get_dummies(product.store_id.astype(str),drop_first=False).astype('int8').values,\n                   pd.get_dummies(product.cat_id.astype(str),drop_first=False).astype('int8').values,\n                   pd.get_dummies(product.dept_id.astype(str),drop_first=False).astype('int8').values,\n                   pd.get_dummies(product.state_id.astype(str) + product.cat_id.astype(str),drop_first=False).astype('int8').values,\n                   pd.get_dummies(product.state_id.astype(str) + product.dept_id.astype(str),drop_first=False).astype('int8').values,\n                   pd.get_dummies(product.store_id.astype(str) + product.cat_id.astype(str),drop_first=False).astype('int8').values,\n                   pd.get_dummies(product.store_id.astype(str) + product.dept_id.astype(str),drop_first=False).astype('int8').values,\n                   pd.get_dummies(product.item_id.astype(str),drop_first=False).astype('int8').values,\n                   pd.get_dummies(product.state_id.astype(str) + product.item_id.astype(str),drop_first=False).astype('int8').values,\n                   np.identity(NUM_ITEMS).astype(np.int8) #item :level 12\n                   ].T\n\nweight_mat_csr = csr_matrix(weight_mat)\ndel weight_mat; gc.collect()\n\ndef weight_calc(data, product, sales_train_val):\n\n    d_name = ['d_' + str(i+1) for i in range(1913)]\n\n    sales_train_val = weight_mat_csr * sales_train_val[d_name].values\n\n    # calculate the start position(first non-zero demand observed date) for each item \n    # 1-1914 day \n    df_tmp = ((sales_train_val>0) * np.tile(np.arange(1,1914),(weight_mat_csr.shape[0],1)))\n\n    start_no = np.min(np.where(df_tmp==0,9999,df_tmp),axis=1)-1\n\n    flag = np.dot(np.diag(1/(start_no+1)) , np.tile(np.arange(1,1914),(weight_mat_csr.shape[0],1)))<1\n\n    sales_train_val = np.where(flag,np.nan,sales_train_val)\n\n    # denominator of RMSSE / RMSSE\n    weight1 = np.nansum(np.diff(sales_train_val,axis=1)**2,axis=1)/(1913-start_no)\n\n    # calculate the sales amount for each item/level\n    df_tmp = data[(data['date'] > '2016-03-27') & (data['date'] <= '2016-04-24')]\n    df_tmp['amount'] = df_tmp['demand'] * df_tmp['sell_price']\n    df_tmp =df_tmp.groupby(['id'])['amount'].apply(np.sum)\n    df_tmp = df_tmp[product.id].values\n    \n    weight2 = weight_mat_csr * df_tmp \n\n    weight2 = weight2/np.sum(weight2)\n\n    del sales_train_val\n    gc.collect()\n    \n    return weight1, weight2\n\nweight1, weight2 = weight_calc(data,product,sales_train_val)\n\ndef wrmsse(preds, data):\n    \n    # this function is calculate for last 28 days to consider the non-zero demand period\n    \n    # actual obserbed values \n    y_true = data.get_label()\n    \n    y_true = y_true[-(NUM_ITEMS * DAYS_PRED):]\n    preds = preds[-(NUM_ITEMS * DAYS_PRED):]\n    # number of columns\n    num_col = DAYS_PRED\n    \n    # reshape data to original array((NUM_ITEMS*num_col,1)->(NUM_ITEMS, num_col) ) \n    reshaped_preds = preds.reshape(num_col, NUM_ITEMS).T\n    reshaped_true = y_true.reshape(num_col, NUM_ITEMS).T\n    \n          \n    train = weight_mat_csr*np.c_[reshaped_preds, reshaped_true]\n    \n    score = np.sum(\n                np.sqrt(\n                    np.mean(\n                        np.square(\n                            train[:,:num_col] - train[:,num_col:])\n                        ,axis=1) / weight1) * weight2)\n    \n    return 'wrmsse', score, False\n\ndef wrmsse_simple(preds, data):\n    \n    # actual obserbed values \n    y_true = data.get_label()\n    \n    y_true = y_true[-(NUM_ITEMS * DAYS_PRED):]\n    preds = preds[-(NUM_ITEMS * DAYS_PRED):]\n    # number of columns\n    num_col = DAYS_PRED\n    \n    # reshape data to original array((NUM_ITEMS*num_col,1)->(NUM_ITEMS, num_col) ) \n    reshaped_preds = preds.reshape(num_col, NUM_ITEMS).T\n    reshaped_true = y_true.reshape(num_col, NUM_ITEMS).T\n          \n    train = np.c_[reshaped_preds, reshaped_true]\n    \n    weight2_2 = weight2[:NUM_ITEMS]\n    weight2_2 = weight2_2/np.sum(weight2_2)\n    \n    score = np.sum(\n                np.sqrt(\n                    np.mean(\n                        np.square(\n                            train[:,:num_col] - train[:,num_col:])\n                        ,axis=1) /  weight1[:NUM_ITEMS])*weight2_2)\n    \n    return 'wrmsse', score, False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, y_train, x_val, y_val, test = train_test_split(data)\ndel data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Run LightGBM","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test, model = run_lgb(x_train, y_train, x_val, y_val, test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n    #Plotting feature importances\n\n    \n    #Plotting feature importances\nax = lgb.plot_importance(model, max_num_features=23, importance_type='split')\nplt.show()\n    \n    #Plotting feature importances\nax = lgb.plot_importance(model, max_num_features=23, importance_type='gain')\nplt.show()\n    \nax = lgb.plot_tree(model, tree_index=53, figsize=(15, 15), show_info=['split_gain'])\nplt.show()\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predict and submit","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\ndel x_train, y_train, x_val, y_val\ndel weight_mat_csr\n#del model\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict(test, submission)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}