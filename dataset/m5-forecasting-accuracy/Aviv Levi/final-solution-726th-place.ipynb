{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"from typing import Union\n\nimport numpy as np\nimport pandas as pd\npd.set_option(\"max_columns\", 50)\nfrom tqdm.auto import tqdm as tqdm\nimport pickle\nfrom random import sample\nimport random\nimport lightgbm as lgbm\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import neighbors\nfrom sklearn.ensemble import RandomForestRegressor\nfrom catboost import CatBoostRegressor\nimport xgboost as xgb\nimport gc\n\n\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Flatten\n\nimport tensorflow as tf\n# physical_devices = tf.config.list_physical_devices('GPU') \n# tf.config.experimental.set_memory_growth(physical_devices[0], True)\n\n\nfrom sklearn.preprocessing import LabelEncoder\n\nrandom.seed(820)\n\n#Evaluator, with it the final models for the ensamble will be picked.\n# the evaluator takes predictions and scores them for the last month in the train.\nclass WRMSSEEvaluator(object):\n    \n    group_ids = ( 'all_id', 'state_id', 'store_id', 'cat_id', 'dept_id', 'item_id',\n        ['state_id', 'cat_id'],  ['state_id', 'dept_id'], ['store_id', 'cat_id'],\n        ['store_id', 'dept_id'], ['item_id', 'state_id'], ['item_id', 'store_id'])\n\n    def __init__(self, \n                 train_df: pd.DataFrame, \n                 valid_df: pd.DataFrame, \n                 calendar: pd.DataFrame, \n                 prices: pd.DataFrame):\n        '''\n        intialize and calculate weights\n        '''\n        self.calendar = calendar\n        self.prices = prices\n        self.train_df = train_df\n        self.valid_df = valid_df\n        self.train_target_columns = [i for i in self.train_df.columns if i.startswith('d_')]\n        self.weight_columns = self.train_df.iloc[:, -28:].columns.tolist()\n\n        self.train_df['all_id'] = \"all\"\n\n        self.id_columns = [i for i in self.train_df.columns if not i.startswith('d_')]\n        self.valid_target_columns = [i for i in self.valid_df.columns if i.startswith('d_')]\n\n        if not all([c in self.valid_df.columns for c in self.id_columns]):\n            self.valid_df = pd.concat([self.train_df[self.id_columns], self.valid_df],\n                                      axis=1, \n                                      sort=False)\n        self.train_series = self.trans_30490_to_42840(self.train_df, \n                                                      self.train_target_columns, \n                                                      self.group_ids)\n        self.valid_series = self.trans_30490_to_42840(self.valid_df, \n                                                      self.valid_target_columns, \n                                                      self.group_ids)\n        self.weights = self.get_weight_df()\n        self.scale = self.get_scale()\n        self.train_series = None\n        self.train_df = None\n        self.prices = None\n        self.calendar = None\n\n    def get_scale(self):\n        '''\n        scaling factor for each series ignoring starting zeros\n        '''\n        scales = []\n        for i in tqdm(range(len(self.train_series))):\n            series = self.train_series.iloc[i].values\n            series = series[np.argmax(series!=0):]\n            scale = ((series[1:] - series[:-1]) ** 2).mean()\n            scales.append(scale)\n        return np.array(scales)\n    \n    def get_name(self, i):\n        '''\n        convert a str or list of strings to unique string \n        used for naming each of 42840 series\n        '''\n        if type(i) == str or type(i) == int:\n            return str(i)\n        else:\n            return \"--\".join(i)\n    \n    def get_weight_df(self) -> pd.DataFrame:\n        \"\"\"\n        returns weights for each of 42840 series in a dataFrame\n        \"\"\"\n        day_to_week = self.calendar.set_index(\"d\")[\"wm_yr_wk\"].to_dict()\n        weight_df = self.train_df[[\"item_id\", \"store_id\"] + self.weight_columns].set_index(\n            [\"item_id\", \"store_id\"]\n        )\n        weight_df = (\n            weight_df.stack().reset_index().rename(columns={\"level_2\": \"d\", 0: \"value\"})\n        )\n        weight_df[\"wm_yr_wk\"] = weight_df[\"d\"].map(day_to_week)\n        weight_df = weight_df.merge(\n            self.prices, how=\"left\", on=[\"item_id\", \"store_id\", \"wm_yr_wk\"]\n        )\n        weight_df[\"value\"] = weight_df[\"value\"] * weight_df[\"sell_price\"]\n        weight_df = weight_df.set_index([\"item_id\", \"store_id\", \"d\"]).unstack(level=2)[\n            \"value\"\n        ]\n        weight_df = weight_df.loc[\n            zip(self.train_df.item_id, self.train_df.store_id), :\n        ].reset_index(drop=True)\n        weight_df = pd.concat(\n            [self.train_df[self.id_columns], weight_df], axis=1, sort=False\n        )\n        weights_map = {}\n        for i, group_id in enumerate(tqdm(self.group_ids, leave=False)):\n            lv_weight = weight_df.groupby(group_id)[self.weight_columns].sum().sum(axis=1)\n            lv_weight = lv_weight / lv_weight.sum()\n            for i in range(len(lv_weight)):\n                weights_map[self.get_name(lv_weight.index[i])] = np.array(\n                    [lv_weight.iloc[i]]\n                )\n        weights = pd.DataFrame(weights_map).T / len(self.group_ids)\n\n        return weights\n\n    def trans_30490_to_42840(self, df, cols, group_ids, dis=False):\n        '''\n        transform 30490 sries to all 42840 series\n        '''\n        series_map = {}\n        for i, group_id in enumerate(tqdm(self.group_ids, leave=False, disable=dis)):\n            tr = df.groupby(group_id)[cols].sum()\n            for i in range(len(tr)):\n                series_map[self.get_name(tr.index[i])] = tr.iloc[i].values\n        return pd.DataFrame(series_map).T\n    \n    def get_rmsse(self, valid_preds) -> pd.Series:\n        '''\n        returns rmsse scores for all 42840 series\n        '''\n        score = ((self.valid_series - valid_preds) ** 2).mean(axis=1)\n        rmsse = (score / self.scale).map(np.sqrt)\n        return rmsse\n\n    def score(self, valid_preds: Union[pd.DataFrame, np.ndarray]) -> float:\n        assert self.valid_df[self.valid_target_columns].shape == valid_preds.shape\n\n        if isinstance(valid_preds, np.ndarray):\n            valid_preds = pd.DataFrame(valid_preds, columns=self.valid_target_columns)\n\n        valid_preds = pd.concat([self.valid_df[self.id_columns], valid_preds],\n                                axis=1, \n                                sort=False)\n        valid_preds = self.trans_30490_to_42840(valid_preds, \n                                                self.valid_target_columns, \n                                                self.group_ids, \n                                                True)\n        self.rmsse = self.get_rmsse(valid_preds)\n        self.contributors = pd.concat([self.weights, self.rmsse], \n                                      axis=1, \n                                      sort=False).prod(axis=1)\n        return np.sum(self.contributors)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loading data\ntrain_df = pd.read_csv(\"../input/m5-forecasting-accuracy/sales_train_validation.csv\")\ncalendar = pd.read_csv(\"../input/m5-forecasting-accuracy/calendar.csv\")\nprices = pd.read_csv(\"../input/m5-forecasting-accuracy/sell_prices.csv\")\n\n#Split train-test for evaluator\ntrain_fold_df = train_df.iloc[:, :-28]\nvalid_fold_df = train_df.iloc[:, -28:].copy()\n\n# Evaluator created\ne = WRMSSEEvaluator(train_fold_df, valid_fold_df, calendar, prices)\ndel train_fold_df, train_df, calendar, prices","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#This cell loads train-reday data sets and pre-trained label encoders.\n\ngc.collect()\nAllTrain = pickle.load(open('../input/train-ready/train.pkl', \"rb\"))\n\nAllTrain[\"d\"] = pickle.load(open(\"../input/train-ready/init_train_d.pkl\", \"rb\"))\nAllTrain.dropna(inplace=True) # remove oldest year.\n\nle_dept =  pickle.load(open('../input/train-ready/le_dept.pkl', \"rb\"))\nle_state = pickle.load(open('../input/train-ready/le_state.pkl', \"rb\"))\n\nle_item =  LabelEncoder()\nle_store =  LabelEncoder()\n\nAllTrain[\"item_id\"] = le_item.fit_transform(AllTrain[\"item_id\"])\nAllTrain[\"store_id\"] = le_store.fit_transform(AllTrain[\"store_id\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set validation.\nFirs27days_mar2016 = ((AllTrain.year == 2016) & (AllTrain.month == 3)& (AllTrain.mday <= 27))\nFebJan2016 = ((AllTrain.year == 2016) & (AllTrain.month < 3))\nYearSmallerThan2016 = (AllTrain.year < 2016)\n\nMainTrain = AllTrain.loc[Firs27days_mar2016 | FebJan2016 | YearSmallerThan2016].copy()\nValidation = AllTrain.loc[~AllTrain.index.isin(MainTrain.index)].copy()\n\n# Down sample main only.\nMainTrain_index = list(MainTrain.index)\nMainTrain_ds_index = sample(MainTrain_index, (len(MainTrain_index)//100) * 32) # 32% of data\nMainTrain_ds_index = sorted(MainTrain_ds_index)\nMainTrain = MainTrain.loc[MainTrain_ds_index]\nMainTrain = MainTrain.reset_index().drop(\"index\", axis = 1)\n\nMainTrain = MainTrain.loc[MainTrain.index.isin(MainTrain_ds_index)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Memory save\ndel YearSmallerThan2016, FebJan2016, Firs27days_mar2016, AllTrain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Features selected\nMainTrain = MainTrain[[\"sales\", \"id\", \"year\",\"dept_id\",\"wday\", \"item_id\", \"store_id\", \"mean_1_months_ago\",\"mean_2_months_ago\",\"avg_last_year\", \"d\"]]\nValidation = Validation[[\"sales\", \"id\", \"year\",\"dept_id\",\"wday\", \"item_id\", \"store_id\", \"mean_1_months_ago\",\"mean_2_months_ago\",\"avg_last_year\", \"d\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 'd' is a feature representing the day sequential number.\nfirst_day =  Validation.head(1).d.values[0]\nValidation['d'] = Validation['d'] - (first_day - 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission = pd.read_csv(\"../input/m5-forecasting-accuracy/sample_submission.csv\") # actual file used for submission\nsample_submission_ = sample_submission.loc[sample_submission[\"id\"].str.contains(\"validation\")].copy() # valudation building\nsample_submission_copy = sample_submission_.copy() # test building","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract product_id\ndef get_product(row):\n    split_row = row.split(\"_\")\n    return split_row[0] + \"_\" + split_row[1] + \"_\" + split_row[2] + \"_\" + split_row[3] + \"_\" + split_row[4]\n\nsample_submission['product_id'] = sample_submission[\"id\"].apply(get_product)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating ground_truth DataFrames to compare with prediction on the last month in the train set.\nground_truth = sample_submission.loc[sample_submission['id'].str.contains(\"validation\")].copy()\nground_truth = ground_truth[[\"product_id\"]].copy()\n\nfor day in range(1,29):\n    only_day_sales = Validation.loc[Validation[\"d\"].astype(\"int\") == day].copy()\n    only_day_sales[\"product_id\"] = only_day_sales.id.str[:-len(\"validation\") - 1]\n    ground_truth[\"F{}\".format(day)] = ground_truth.merge(only_day_sales[[\"product_id\", \"sales\"]], on=\"product_id\")[\"sales\"]\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split X - features. y- target (sales)\nX = MainTrain.drop([\"id\", \"sales\", 'd'], axis =1)\nX = X.loc[:,~X.columns.duplicated()] # rem dup cols\n\ny = MainTrain[\"sales\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This function trains diefferent models for the ensemble\ndef train_N_models(X,y, help1):\n    predictors = {}\n\n    print(\"trainig\")\n    if \"rf\" not in help1:\n        # RF\n        print(\"rf\")\n        regr = RandomForestRegressor(max_depth=5, random_state=0,\n                                  n_estimators=70, n_jobs = -1)\n        regr.fit(X, y) \n        predictors[\"rf\"] = regr\n        help1[\"rf\"] = regr\n\n\n    if \"catboost\" not in help1:\n        #     catboost\n        print(\"catboost\")\n        catb = CatBoostRegressor(iterations=100,\n                                  learning_rate=0.078,\n                                  depth=10,\n                                random_seed = 32,\n                                logging_level = \"Silent\",\n                                thread_count = -1)\n        catb.fit(X, y)\n        predictors[\"catboost\"] = catb\n        help1[\"catboost\"] = catb\n\n\n    if \"XGBoost\" not in help1:\n        # XGBoost\n        print(\"XGBoost\")\n        model = xgb.XGBRegressor(colsample_bytree=0.4,\n                         gamma=0,                 \n                         learning_rate=0.17,\n                         max_depth=3,\n                         min_child_weight=1.5,\n                         n_estimators=70,                                                                    \n                         reg_alpha=0.75,\n                         reg_lambda=0.45,\n                         subsample=0.6,\n                         seed=42) \n\n        model.fit(X,y)\n        predictors[\"xgboost\"] = model\n        help1[\"XGBoost\"] = model\n\n    if \"lightgbm\" not in help1:\n        # lightgbm\n        print(\"lightgbm\")\n        parms = {\"boosting_type\" : 'dart',\n                 \"num_leaves\" : 3,\n                 \"max_depth\" :2, \n                 'learning_rate':0.25,\n                 \"n_estimators\" : 80,\n                 \"objective\" : \"regression\", \n                 \"min_split_gain\" : 0,\n                 \"min_child_weight\" : 0.001,\n                 \"min_child_samples\" : 20,\n                 \"reg_alpha\" : 0,\n                 \"reg_lambda\" : 0, \n                 \"random_state\" : 1406,\n                 \"n_jobs\" : -1,\n                 \"silent\" : False}\n\n        model = lgbm.LGBMRegressor(boosting_type = parms[\"boosting_type\"],\n                                  num_leaves = parms[\"num_leaves\"],max_depth = parms[\"max_depth\"],\n                                  learning_rate = parms[\"learning_rate\"],n_estimators = parms[\"n_estimators\"],\n                                  objective = parms[\"objective\"],min_split_gain = parms[\"min_split_gain\"],\n                                  min_child_weight = parms[\"min_child_weight\"],\n                                  min_child_samples = parms[\"min_child_samples\"],reg_alpha = parms[\"reg_alpha\"],\n                                  reg_lambda = parms[\"reg_lambda\"],random_state = parms[\"random_state\"],\n                                  n_jobs = parms[\"n_jobs\"],silent = parms[\"silent\"])\n\n        model.fit(X, y)\n        predictors[\"lightgbm\"] = model\n        help1[\"lightgbm\"] = model\n\n\n    if \"lr\" not in help1:\n        print(\"lr\")\n        # liniar regression \n        lm = linear_model.LinearRegression(n_jobs = -1)\n        model = lm.fit(X,y)\n        predictors[\"lr\"] = model\n        help1[\"lr\"] = model\n\n\n    if \"NN\" not in help1:\n        print(\"NN\")\n        # NN\n        NN_model = Sequential()\n\n        # The Input Layer :\n        NN_model.add(Dense(30, kernel_initializer=\"glorot_normal\",input_dim =X.shape[1], activation=\"selu\"))\n\n        # The Hidden Layers :\n        NN_model.add(Dense(15, kernel_initializer=\"glorot_normal\",activation=\"elu\"))\n        NN_model.add(Dense(15, kernel_initializer=\"glorot_normal\",activation=\"elu\"))\n\n        # The Output Layer :\n        NN_model.add(Dense(1, kernel_initializer='glorot_normal',activation=\"elu\"))\n\n        # Compile the network :\n        NN_model.compile(loss=\"mean_squared_error\", optimizer=\"Adadelta\", metrics=[\"acc\"])\n\n        NN_model.fit(X, y, epochs=1, batch_size=400, validation_split = 0.2, verbose = True) \n        predictors[\"NN\"] = NN_model\n        help1[\"NN\"] = NN_model\n\n\n    return predictors\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"help1 = {}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train without the last month, for validation\nif \"d\" in X:\n    predictors_valid = train_N_models(X.drop(\"d\", axis = 1) ,y, help1)\nelse:\n    predictors_valid = train_N_models(X ,y, help1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For every day there is a test DataFrame containing the features of that day.\n# In this case we only use the validation rows\ntest_days = []\ntest_columns = list(MainTrain.columns)\ntest_columns.remove(\"sales\")\ntest_columns.remove(\"d\")\n\nfor day in range(0, 28):\n    test_days.append(pickle.load(open(\"../input/tests-28/test_{}.pkl\".format(day), \"rb\")))\n    test_days[day] = test_days[day].loc[test_days[day][\"id\"].str.contains(\"validation\")].copy()\n\n    test_days[-1][\"dept_id\"] = le_dept.transform(test_days[-1][\"dept_id\"])\n    test_days[-1][\"state_id\"] = le_state.transform(test_days[-1][\"state_id\"])\n    test_days[-1][\"item_id\"] = le_item.transform(test_days[-1][\"item_id\"])\n    test_days[-1][\"store_id\"] = le_store.transform(test_days[-1][\"store_id\"])\n    test_days[-1] = test_days[-1][test_columns]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make validation days - DataFrame for every day in the validation set.\nvalidation_days = []\ntest_days_cols = test_days[0].columns\nfor day in range(1,29):\n    valid_day = Validation.loc[Validation.d == day][test_days_cols]\n    valid_day = valid_day.loc[:,~valid_day.columns.duplicated()] # rem dup cols\n\n    valid_day = valid_day.set_index('item_id')\n    valid_day = valid_day.reindex(index=test_days[0]['item_id'])\n    validation_days.append(valid_day.reset_index())\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This function makes prediction given a validation day DataFrame\ndef predict_28_days_validation(model, X):\n    temp = pd.DataFrame()\n    for day, validation in enumerate(validation_days):\n        print(day, end = \"  \")\n        col = \"F{}\".format(day + 1)\n        sample_submission_copy[col] = model.predict(validation_days[day].drop([\"id\"], axis = 1)[X.columns])\n        sample_submission_copy[col] =  sample_submission_copy[col].round(1)\n        temp[col] = sample_submission_copy[col].to_numpy().flatten()    \n    print()\n    return temp.to_numpy()\n# column is every product * 28 days all the way down","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Predictions for ensemble\npreds_validation = pd.DataFrame()\nfor predictor_name, predictor in predictors_valid.items():\n    print(predictor_name)\n    preds_validation[predictor_name] = predict_28_days_validation(predictor, X).flatten()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_validation[\"ground_truth\"] = ground_truth.drop(\"product_id\", axis =1).to_numpy().flatten()\npreds_validation = preds_validation.clip(0, 99)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initial ensemble \nX_ens = preds_validation.drop(\"ground_truth\", axis = 1)\ny_ens = preds_validation[\"ground_truth\"]\n\n\nregr = xgb.XGBRegressor (eta =0.1,  \n                        nthread = -1, \n                        n_estimators= 30, \n                        max_depth= 2, \n                        max_delta_step= 16,\n                         colsample_bytree= 0.4,\n                         scale_pos_weight= 0.9,\n                         base_score= 0.9,\n                         eval_metric= 'rmse')\nregr.fit(X_ens, y_ens) \npickle.dump(regr, open(\"regr_ens.pkl\", \"wb\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Validation = Validation.drop(\"d\", axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train on all the months in the data\nhelp1 = {}\n\nMainTrain = MainTrain.loc[:,~MainTrain.columns.duplicated()] # rem dup cols\nValidation = Validation.loc[:,~Validation.columns.duplicated()] # rem dup cols\n\n\nX = MainTrain.append(Validation)\ny = X[\"sales\"]\n\nX = X.drop([\"item_id\", \"id\", \"sales\", \"d\"], axis =1)\nX = X.loc[:,~X.columns.duplicated()] # rem dup cols\n\npredictors_test = train_N_models(X, y, help1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predict for every day in the test set\npreds_test = pd.DataFrame()\nfor predictor_name, predictor in predictors_test.items():\n    print(predictor_name)\n    preds_test[predictor_name] = predict_28_days_validation(predictor, X).flatten()       \npreds_test = preds_test.clip(0,99)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# re-run\nwhos = %who_ls\nif \"Save_preds_test\" in whos:\n    preds_test = Save_preds_test\nelse:\n    Save_preds_test =  preds_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Final models selection.\nX_ens = preds_validation.drop(\"ground_truth\", axis = 1)\ny_ens = preds_validation[\"ground_truth\"]\n\nregr = xgb.XGBRegressor (eta =0.3,  \n                        nthread = -1, \n                        n_estimators= 50, \n                        max_depth= 3, \n                         max_delta_step= 6,\n                        colsample_bytree= 0.4,\n#                          scale_pos_weight= 0.9,\n                         base_score= 0.9,\n                         random_state=0,\n                         eval_metric= 'rmse')\n\nbest_grade = 999\nsave_x_ens = X_ens.copy()\ndf = pd.DataFrame()\nfor i, model in enumerate(X_ens):\n    model_name = list(save_x_ens.columns)[i]\n    print(model_name)\n    df[model_name] = X_ens[model_name]\n    \n    regr.fit(df, y_ens)\n    \n    Ens_preds = regr.predict(preds_test[df.columns])\n    Ens_preds = Ens_preds.reshape(sample_submission_.shape[0], 28)\n    Ens_preds_c = Ens_preds\n    grade = e.score(Ens_preds_c)\n    print(grade)\n    \n    if grade < best_grade:  # improve\n        print(\"adding {} helped! grade now: {} prev grade: {}\".format(model_name, grade, best_grade))\n        best_grade = grade\n        print(df.columns)\n        columns_best_regr = df.columns\n    else:\n        print(\"adding {} did not help. get out.\".format(model_name))\n        df = df.drop(model_name, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in preds_test.columns:\n    if col not in columns_best_regr:\n        preds_test = preds_test.drop(col, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train final ensemble.\nregr.fit(df[columns_best_regr], y_ens)\n\nEns_preds = regr.predict(preds_test[columns_best_regr])\nEns_preds = Ens_preds.reshape(sample_submission_.shape[0], 28)\ne.score(Ens_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For every day there is a test DataFrame containing the features of that day.\n# In this case we only use all the rows - validation and test\ntest_days = []\nfor day in range(0, 28):\n    test_days.append(pickle.load(open(\"../input/tests-28/test_{}.pkl\".format(day), \"rb\")))\n    test_days[-1][\"dept_id\"] = le_dept.transform(test_days[-1][\"dept_id\"])\n    test_days[-1][\"state_id\"] = le_state.transform(test_days[-1][\"state_id\"])\n    test_days[-1][\"item_id\"] = le_item.transform(test_days[-1][\"item_id\"])\n    test_days[-1][\"store_id\"] = le_store.transform(test_days[-1][\"store_id\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_28_days_test(model, X):\n    temp = pd.DataFrame()\n    for day, test in enumerate(test_days):\n        print(day, end = \"  \")\n        col = \"F{}\".format(day + 1)\n        sample_submission[col] = model.predict(test.drop([\"id\"], axis = 1)[X.columns])\n        sample_submission[col] =  sample_submission[col].round(1)\n        temp[col] = sample_submission[col].to_numpy().flatten()    \n    print()\n    return temp.to_numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Memory cleanup\nwhos = %who_ls\nif \"Ens_preds\" in whos:\n    del Ens_preds\n    \nif \"X_ens\" in whos:\n    del X_ens\n\nif \"Validation\" in whos:\n    del Validation\n    \ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for predictor_name in columns_best_regr:\n    print(predictor_name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Final predictions.\nprint(\"predicting!\")\n\npreds = pd.DataFrame()   \n    \n\nfor predictor_name in columns_best_regr:\n    print(predictor_name)\n    preds[predictor_name] = predict_28_days_test(predictors_test[predictor_name], X).flatten()\n\nif \"lr\" in preds:\n    preds[\"lr\"] = preds[\"lr\"].clip(lower = 0.1)\n    \nEns_preds_test = regr.predict(preds)\nEns_preds_test = Ens_preds_test.reshape(sample_submission.shape[0], 28)\n    \nF_cols = [\"F{}\".format(i) for i in range(1,29)]\nsample_submission[F_cols] = Ens_preds_test\nsample_submission = sample_submission.round(1)\nsample_submission[F_cols] = sample_submission[F_cols].clip(lower = 0.01, axis=0) # drop negatives\n\nif \"product_id\"  in sample_submission:\n    sample_submission =  sample_submission.drop(\"product_id\", axis = 1)\nsample_submission.to_csv(\"submission.csv\", index= False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}