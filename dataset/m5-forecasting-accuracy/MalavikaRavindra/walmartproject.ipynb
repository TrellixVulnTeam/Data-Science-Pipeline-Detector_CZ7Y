{"cells":[{"metadata":{},"cell_type":"markdown","source":"\n","execution_count":null},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport plotly_express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom lightgbm import LGBMRegressor\nimport joblib","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reading the data","execution_count":null},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-input":false,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"sales = pd.read_csv('/kaggle/input/m5-forecasting-accuracy/sales_train_evaluation.csv')\nsales.name = 'sales'\ncalendar = pd.read_csv('/kaggle/input/m5-forecasting-accuracy/calendar.csv')\ncalendar.name = 'calendar'\nprices = pd.read_csv('/kaggle/input/m5-forecasting-accuracy/sell_prices.csv')\nprices.name = 'prices'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfor d in range(1942,1970):\n    col = 'd_' + str(d)\n    sales[col] = 0\n    sales[col] = sales[col].astype(np.int16)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Downcasting\n","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"sales_bd = np.round(sales.memory_usage().sum()/(1024*1024),1)\ncalendar_bd = np.round(calendar.memory_usage().sum()/(1024*1024),1)\nprices_bd = np.round(prices.memory_usage().sum()/(1024*1024),1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Downcast in order to save memory\ndef downcast(df):\n    cols = df.dtypes.index.tolist()\n    types = df.dtypes.values.tolist()\n    for i,t in enumerate(types):\n        if 'int' in str(t):\n            if df[cols[i]].min() > np.iinfo(np.int8).min and df[cols[i]].max() < np.iinfo(np.int8).max:\n                df[cols[i]] = df[cols[i]].astype(np.int8)\n            elif df[cols[i]].min() > np.iinfo(np.int16).min and df[cols[i]].max() < np.iinfo(np.int16).max:\n                df[cols[i]] = df[cols[i]].astype(np.int16)\n            elif df[cols[i]].min() > np.iinfo(np.int32).min and df[cols[i]].max() < np.iinfo(np.int32).max:\n                df[cols[i]] = df[cols[i]].astype(np.int32)\n            else:\n                df[cols[i]] = df[cols[i]].astype(np.int64)\n        elif 'float' in str(t):\n            if df[cols[i]].min() > np.finfo(np.float16).min and df[cols[i]].max() < np.finfo(np.float16).max:\n                df[cols[i]] = df[cols[i]].astype(np.float16)\n            elif df[cols[i]].min() > np.finfo(np.float32).min and df[cols[i]].max() < np.finfo(np.float32).max:\n                df[cols[i]] = df[cols[i]].astype(np.float32)\n            else:\n                df[cols[i]] = df[cols[i]].astype(np.float64)\n        elif t == np.object:\n            if cols[i] == 'date':\n                df[cols[i]] = pd.to_datetime(df[cols[i]], format='%Y-%m-%d')\n            else:\n                df[cols[i]] = df[cols[i]].astype('category')\n    return df  \n\nsales = downcast(sales)\nprices = downcast(prices)\ncalendar = downcast(calendar)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"sales_ad = np.round(sales.memory_usage().sum()/(1024*1024),1)\ncalendar_ad = np.round(calendar.memory_usage().sum()/(1024*1024),1)\nprices_ad = np.round(prices.memory_usage().sum()/(1024*1024),1)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"dic = {'DataFrame':['sales','calendar','prices'],\n       'Before downcasting':[sales_bd,calendar_bd,prices_bd],\n       'After downcasting':[sales_ad,calendar_ad,prices_ad]}\n\nmemory = pd.DataFrame(dic)\nmemory = pd.melt(memory, id_vars='DataFrame', var_name='Status', value_name='Memory (MB)')\nmemory.sort_values('Memory (MB)',inplace=True)\nfig = px.bar(memory, x='DataFrame', y='Memory (MB)', color='Status', barmode='group', text='Memory (MB)')\nfig.update_traces(texttemplate='%{text} MB', textposition='outside')\nfig.update_layout(template='seaborn', title='Effect of Downcasting')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Melting the data\n Convert from wide to long format\n","execution_count":null},{"metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"df = pd.melt(sales, id_vars=['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'], var_name='d', value_name='sold').dropna()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nCombine price data from prices dataframe and days data from calendar dataset.","execution_count":null},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"df = pd.merge(df, calendar, on='d', how='left')\ndf = pd.merge(df, prices, on=['store_id','item_id','wm_yr_wk'], how='left') ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis\n","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"group = sales.groupby(['state_id','store_id','cat_id','dept_id'],as_index=False)['item_id'].count().dropna()\ngroup['USA'] = 'United States of America'\ngroup.rename(columns={'state_id':'State','store_id':'Store','cat_id':'Category','dept_id':'Department','item_id':'Count'},inplace=True)\nfig = px.treemap(group, path=['USA', 'State', 'Store', 'Category', 'Department'], values='Count',\n                  color='Count',\n                  color_continuous_scale= px.colors.sequential.Sunset,\n                  title='Walmart: Distribution of items')\nfig.update_layout(template='seaborn')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"group_price_cat = df.groupby(['store_id','cat_id','item_id'],as_index=False)['sell_price'].mean().dropna()\nfig = px.violin(group_price_cat, x='store_id', color='cat_id', y='sell_price',box=True, hover_name='item_id')\nfig.update_xaxes(title_text='Store')\nfig.update_yaxes(title_text='Selling Price($)')\nfig.update_layout(template='seaborn',title='Distribution of Items prices wrt Stores across Categories',\n                 legend_title_text='Category')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# As can be seen from the plot above, food category items are quite cheap as compared with hobbies and household items. Hobbies and household items have almost the same price range.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":" Items Sold","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"group = df.groupby(['year','date','state_id','store_id'], as_index=False)['sold'].sum().dropna()\nfig = px.violin(group, x='store_id', color='state_id', y='sold',box=True)\nfig.update_xaxes(title_text='Store')\nfig.update_yaxes(title_text='Total items sold')\nfig.update_layout(template='seaborn',title='Distribution of Items sold in the Stores',legend_title_text='State')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Below are some of the observations from the above plot:-\n  <li><b><u>California</u></b>: <b>CA_3</b> has sold the most number of items while, <b>CA_4</b> has sold the least number of items.</li>\n  <li><b><u>Texas</u></b>: <b>TX_2</b> and **TX_3** have sold the maximum number of items. <b>TX_1</b> has sold the least number of items.</li>\n  <li><b><u>Wisconsin</u></b>: <b>WI_2</b> has sold the maximum number of items while, <b>WI_3</b> has sold the least number of items.</li>\n  <li><b><u>USA</u></b>: <b>CA_3</b> has sold the most number of items while, <b>CA_4</b> has sold the least number of items.</li>\n</ul>\n\n","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = go.Figure()\ntitle = 'Items sold over time'\nyears = group.year.unique().tolist()\nbuttons = []\ny=3\nfor state in group.state_id.unique().tolist():\n    group_state = group[group['state_id']==state]\n    for store in group_state.store_id.unique().tolist():\n        group_state_store = group_state[group_state['store_id']==store]\n        fig.add_trace(go.Scatter(name=store, x=group_state_store['date'], y=group_state_store['sold'], showlegend=True, \n                                   yaxis='y'+str(y) if y!=1 else 'y'))\n    y-=1\n\nfig.update_layout(\n        xaxis=dict(\n        #autorange=True,\n        range = ['2011-01-29','2016-05-22'],\n        rangeselector=dict(\n            buttons=list([\n                dict(count=1,\n                     label=\"1m\",\n                     step=\"month\",\n                     stepmode=\"backward\"),\n                dict(count=6,\n                     label=\"6m\",\n                     step=\"month\",\n                     stepmode=\"backward\"),\n                dict(count=1,\n                     label=\"YTD\",\n                     step=\"year\",\n                     stepmode=\"todate\"),\n                dict(count=1,\n                     label=\"1y\",\n                     step=\"year\",\n                     stepmode=\"backward\"),\n                dict(count=2,\n                     label=\"2y\",\n                     step=\"year\",\n                     stepmode=\"backward\"),\n                dict(count=3,\n                     label=\"3y\",\n                     step=\"year\",\n                     stepmode=\"backward\"),\n                dict(count=4,\n                     label=\"4y\",\n                     step=\"year\",\n                     stepmode=\"backward\"),\n                dict(step=\"all\")\n            ])\n        ),\n        rangeslider=dict(\n            autorange=True,\n        ),\n        type=\"date\"\n    ),\n    yaxis=dict(\n        anchor=\"x\",\n        autorange=True,\n        domain=[0, 0.33],\n        mirror=True,\n        showline=True,\n        side=\"left\",\n        tickfont={\"size\":10},\n        tickmode=\"auto\",\n        ticks=\"\",\n        title='WI',\n        titlefont={\"size\":20},\n        type=\"linear\",\n        zeroline=False\n    ),\n    yaxis2=dict(\n        anchor=\"x\",\n        autorange=True,\n        domain=[0.33, 0.66],\n        mirror=True,\n        showline=True,\n        side=\"left\",\n        tickfont={\"size\":10},\n        tickmode=\"auto\",\n        ticks=\"\",\n        title = 'TX',\n        titlefont={\"size\":20},\n        type=\"linear\",\n        zeroline=False\n    ),\n    yaxis3=dict(\n        anchor=\"x\",\n        autorange=True,\n        domain=[0.66, 1],\n        mirror=True,\n        showline=True,\n        side=\"left\",\n        tickfont={\"size\":10},\n        tickmode=\"auto\",\n        ticks='',\n        title=\"CA\",\n        titlefont={\"size\":20},\n        type=\"linear\",\n        zeroline=False\n    )\n    )\nfig.update_layout(template='seaborn', title=title)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"State wise Analysis\n  \nsales and revenue of all the stores individually across all the three states: California, Texas & Wisconsin. \nFirst plot shows the daily sales of a store. I have plotted the values separately for SNAP days. Also, SNAP promotes food purchase, I have plotted food sales as well to check if it really affects the food sales.\nSecond plot shows the daily revenue of a store with separate plotting for SNAP days\n\n","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df['revenue'] = df['sold']*df['sell_price'].astype(np.float32)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def introduce_nulls(df):\n    idx = pd.date_range(df.date.dt.date.min(), df.date.dt.date.max())\n    df = df.set_index('date')\n    df = df.reindex(idx)\n    df.reset_index(inplace=True)\n    df.rename(columns={'index':'date'},inplace=True)\n    return df\n\ndef plot_metric(df,state,store,metric):\n    store_sales = df[(df['state_id']==state)&(df['store_id']==store)&(df['date']<='2016-05-22')]\n    food_sales = store_sales[store_sales['cat_id']=='FOODS']\n    store_sales = store_sales.groupby(['date','snap_'+state],as_index=False)['sold','revenue'].sum()\n    snap_sales = store_sales[store_sales['snap_'+state]==1]\n    non_snap_sales = store_sales[store_sales['snap_'+state]==0]\n    food_sales = food_sales.groupby(['date','snap_'+state],as_index=False)['sold','revenue'].sum()\n    snap_foods = food_sales[food_sales['snap_'+state]==1]\n    non_snap_foods = food_sales[food_sales['snap_'+state]==0]\n    non_snap_sales = introduce_nulls(non_snap_sales)\n    snap_sales = introduce_nulls(snap_sales)\n    non_snap_foods = introduce_nulls(non_snap_foods)\n    snap_foods = introduce_nulls(snap_foods)\n    fig = go.Figure()\n    #fig.add_trace(go.Scatter(x=non_snap_sales['date'],y=non_snap_sales[metric],name='Total '+metric+'(Non-SNAP)'))\n    #fig.add_trace(go.Scatter(x=snap_sales['date'],y=snap_sales[metric],name='Total '+metric+'(SNAP)'))\n    fig.add_trace(go.Scatter(x=non_snap_foods['date'],y=non_snap_foods[metric],\n                           name='Food '+metric+'(Non-SNAP)'))\n    fig.add_trace(go.Scatter(x=snap_foods['date'],y=snap_foods[metric],\n                           name='Food '+metric+'(SNAP)'))\n    fig.update_yaxes(title_text='Total items sold' if metric=='sold' else 'Total revenue($)')\n    fig.update_layout(template='seaborn',title=store)\n    fig.update_layout(\n        xaxis=dict(\n        #autorange=True,\n        range = ['2011-01-29','2016-05-22'],\n        rangeselector=dict(\n            buttons=list([\n                dict(count=1,\n                     label=\"1m\",\n                     step=\"month\",\n                     stepmode=\"backward\"),\n                dict(count=6,\n                     label=\"6m\",\n                     step=\"month\",\n                     stepmode=\"backward\"),\n                dict(count=1,\n                     label=\"YTD\",\n                     step=\"year\",\n                     stepmode=\"todate\"),\n                dict(count=1,\n                     label=\"1y\",\n                     step=\"year\",\n                     stepmode=\"backward\"),\n                dict(count=2,\n                     label=\"2y\",\n                     step=\"year\",\n                     stepmode=\"backward\"),\n                dict(count=3,\n                     label=\"3y\",\n                     step=\"year\",\n                     stepmode=\"backward\"),\n                dict(count=4,\n                     label=\"4y\",\n                     step=\"year\",\n                     stepmode=\"backward\"),\n                dict(step=\"all\")\n            ])\n        ),\n        rangeslider=dict(\n            autorange=True,\n        ),\n        type=\"date\"\n    ))\n    return fig","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"cal_data = group.copy()\ncal_data = cal_data[cal_data.date <= '22-05-2016']\ncal_data['week'] = cal_data.date.dt.weekofyear\ncal_data['day_name'] = cal_data.date.dt.day_name()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def calmap(cal_data, state, store, scale):\n    cal_data = cal_data[(cal_data['state_id']==state)&(cal_data['store_id']==store)]\n    years = cal_data.year.unique().tolist()\n    fig = make_subplots(rows=len(years),cols=1,shared_xaxes=True,vertical_spacing=0.005)\n    r=1\n    for year in years:\n        data = cal_data[cal_data['year']==year]\n        data = introduce_nulls(data)\n        fig.add_trace(go.Heatmap(\n            z=data.sold,\n            x=data.week,\n            y=data.day_name,\n            hovertext=data.date.dt.date,\n            coloraxis = \"coloraxis\",name=year,\n        ),r,1)\n        fig.update_yaxes(title_text=year,tickfont=dict(size=5),row = r,col = 1)\n        r+=1\n    fig.update_xaxes(range=[1,53],tickfont=dict(size=10), nticks=53)\n    fig.update_layout(coloraxis = {'colorscale':scale})\n    fig.update_layout(template='seaborn', title=store)\n    return fig","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"California\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### <a id='C1'>CA_1</a>","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = plot_metric(df,'CA','CA_1','sold')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = plot_metric(df,'CA','CA_1','revenue')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = plot_metric(df,'CA','CA_2','sold')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = plot_metric(df,'CA','CA_2','revenue')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### CA_3\n","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = plot_metric(df,'CA','CA_3','sold')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = plot_metric(df,'CA','CA_3','revenue')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### CA4\n","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = plot_metric(df,'CA','CA_4','sold')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = plot_metric(df,'CA','CA_4','revenue')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n# Texas","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### <a id='T1'>TX_1</a>","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = plot_metric(df,'TX','TX_1','sold')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = plot_metric(df,'TX','TX_1','revenue')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### TX2\n","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = plot_metric(df,'TX','TX_2','sold')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = plot_metric(df,'TX','TX_2','revenue')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### TX_3","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = plot_metric(df,'TX','TX_3','sold')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = plot_metric(df,'TX','TX_3','revenue')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Wisconsin","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### <a id='W1'>WI_1</a>","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = plot_metric(df,'WI','WI_1','sold')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = plot_metric(df,'WI','WI_1','revenue')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id='W2'>WI_2</a>\n","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = plot_metric(df,'WI','WI_2','sold')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = plot_metric(df,'WI','WI_2','revenue')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id='W3'>WI_3</a>","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = plot_metric(df,'WI','WI_3','sold')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = plot_metric(df,'WI','WI_3','revenue')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering\n\nLabel Encoding,\nIntroduce Lags,\nMean Encoding,\nRolling Window Weekly Mean,\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Store the categories along with their codes\nd_id = dict(zip(df.id.cat.codes, df.id))\nd_item_id = dict(zip(df.item_id.cat.codes, df.item_id))\nd_dept_id = dict(zip(df.dept_id.cat.codes, df.dept_id))\nd_cat_id = dict(zip(df.cat_id.cat.codes, df.cat_id))\nd_store_id = dict(zip(df.store_id.cat.codes, df.store_id))\nd_state_id = dict(zip(df.state_id.cat.codes, df.state_id))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#1\n#del group, group_price_cat, group_price_store, group_state, group_state_store, cal_data\n#gc.collect();\n\n#2\ndf.d = df['d'].apply(lambda x: x.split('_')[1]).astype(np.int16)\ncols = df.dtypes.index.tolist()\ntypes = df.dtypes.values.tolist()\nfor i,type in enumerate(types):\n    if type.name == 'category':\n        df[cols[i]] = df[cols[i]].cat.codes\n        \n#3\ndf.drop('date',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" Introduce Lags\n\nAdding Lag features to the the target variable `sold`","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"lags = [1,2,3,6,12,24,36]\nfor lag in lags:\n    df['sold_lag_'+str(lag)] = df.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],as_index=False)['sold'].shift(lag).astype(np.float16)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Mean Encoding\n\n- item\n- state\n- store\n- category\n- department\n- category & department\n- store & item\n- category & item\n- department & item\n- state & store\n- state, store and category\n- store, category and department","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['iteam_sold_avg'] = df.groupby('item_id')['sold'].transform('mean').astype(np.float16)\ndf['state_sold_avg'] = df.groupby('state_id')['sold'].transform('mean').astype(np.float16)\ndf['store_sold_avg'] = df.groupby('store_id')['sold'].transform('mean').astype(np.float16)\ndf['cat_sold_avg'] = df.groupby('cat_id')['sold'].transform('mean').astype(np.float16)\ndf['dept_sold_avg'] = df.groupby('dept_id')['sold'].transform('mean').astype(np.float16)\ndf['cat_dept_sold_avg'] = df.groupby(['cat_id','dept_id'])['sold'].transform('mean').astype(np.float16)\ndf['store_item_sold_avg'] = df.groupby(['store_id','item_id'])['sold'].transform('mean').astype(np.float16)\ndf['cat_item_sold_avg'] = df.groupby(['cat_id','item_id'])['sold'].transform('mean').astype(np.float16)\ndf['dept_item_sold_avg'] = df.groupby(['dept_id','item_id'])['sold'].transform('mean').astype(np.float16)\ndf['state_store_sold_avg'] = df.groupby(['state_id','store_id'])['sold'].transform('mean').astype(np.float16)\ndf['state_store_cat_sold_avg'] = df.groupby(['state_id','store_id','cat_id'])['sold'].transform('mean').astype(np.float16)\ndf['store_cat_dept_sold_avg'] = df.groupby(['store_id','cat_id','dept_id'])['sold'].transform('mean').astype(np.float16)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" introduce a lot of Null values, so I'll remove data for first 35 days as I have introduced lags till 36 days.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[df['d']>=36]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Save the data for training.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_pickle('data.pkl')\ndel df\ngc.collect();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modelling and Prediction","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_pickle('data.pkl')\nvalid = data[(data['d']>=1914) & (data['d']<1942)][['id','d','sold']]\ntest = data[data['d']>=1942][['id','d','sold']]\neval_preds = test['sold']\nvalid_preds = valid['sold']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Get the store ids\nstores = sales.store_id.cat.codes.unique().tolist()\nfor store in stores:\n    df = data[data['store_id']==store]\n    \n    #Split the data\n    X_train, y_train = df[df['d']<1914].drop('sold',axis=1), df[df['d']<1914]['sold']\n    X_valid, y_valid = df[(df['d']>=1914) & (df['d']<1942)].drop('sold',axis=1), df[(df['d']>=1914) & (df['d']<1942)]['sold']\n    X_test = df[df['d']>=1942].drop('sold',axis=1)\n    \n    #Train and validate\n    model = LGBMRegressor(\n        n_estimators=1000,\n        learning_rate=0.3,\n        subsample=0.8,\n        colsample_bytree=0.8,\n        max_depth=8,\n        num_leaves=50,\n        min_child_weight=300\n    )\n    print('*****Prediction for Store: {}*****'.format(d_store_id[store]))\n    model.fit(X_train, y_train, eval_set=[(X_train,y_train),(X_valid,y_valid)],\n             eval_metric='rmse', verbose=20, early_stopping_rounds=20)\n    valid_preds[X_valid.index] = model.predict(X_valid)\n    eval_preds[X_test.index] = model.predict(X_test)\n    filename = 'model'+str(d_store_id[store])+'.pkl'\n    # save model\n    joblib.dump(model, filename)\n    del model, X_train, y_train, X_valid, y_valid\n    gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Set actual equal to false if you want to top in the public leaderboard :P\nactual = False\nif actual == False:\n    #Get the validation results(We already have them as less than one month left for competition to end)\n    validation = sales[['id']+['d_' + str(i) for i in range(1914,1942)]]\n    validation['id']=pd.read_csv('/kaggle/input/m5-forecasting-accuracy/sales_train_validation.csv').id\n    validation.columns=['id'] + ['F' + str(i + 1) for i in range(28)]\nelse:\n    #Get the actual validation results\n    valid['sold'] = valid_preds\n    validation = valid[['id','d','sold']]\n    validation = pd.pivot(validation, index='id', columns='d', values='sold').reset_index()\n    validation.columns=['id'] + ['F' + str(i + 1) for i in range(28)]\n    validation.id = validation.id.map(d_id).str.replace('evaluation','validation')\n\n#Get the evaluation results\ntest['sold'] = eval_preds\nevaluation = test[['id','d','sold']]\nevaluation = pd.pivot(evaluation, index='id', columns='d', values='sold').reset_index()\nevaluation.columns=['id'] + ['F' + str(i + 1) for i in range(28)]\n#Remap the category id to their respective categories\nevaluation.id = evaluation.id.map(d_id)\n\n#Prepare the submission\nsubmit = pd.concat([validation,evaluation]).reset_index(drop=True)\nsubmit.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}