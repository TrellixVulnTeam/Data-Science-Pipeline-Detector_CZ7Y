{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Set environment variables\nimport os\nimport warnings\nimport numpy as np\nimport pandas as pd\n\nVERSION = 1\nINPUT_PATH = f\"/kaggle/input/m5-forecasting-accuracy\"\nBASE_PATH = f\"/kaggle/working/m5-forecasting-accuracy-ver{VERSION}\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Turn off warnings\n\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Change directory\n\nos.chdir(INPUT_PATH)\nprint(f\"Change to directory: {os.getcwd()}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Memory usage function and merge by concat function (not to lose data type)\n\ndef format_memory_usage(total_bytes):\n    unit_list = [\"\", \"Ki\", \"Mi\", \"Gi\"]\n    for unit in unit_list:\n        if total_bytes < 1024:\n            return f\"{total_bytes:.2f}{unit}B\"\n        total_bytes /= 1024\n    return f\"{total_bytes:.2f}{unit}B\"\n\ndef merge_by_concat(df1, df2, columns):\n    df_temp = df1[columns]\n    df_temp = df_temp.merge(df2, on = columns, how = \"left\")\n    new_columns = [column for column in list(df_temp) if column not in columns]\n    df1 = pd.concat([df1, df_temp[new_columns]], axis = 1)\n    return df1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering - Sales - Basic Features\n- Our final goal is to predict sales for 28 days after day 1913,\n- so the time series of sales should be one of the most essential features in our model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load and check dataset\n\ndf_sales_train_validation = pd.read_csv(\"sales_train_validation.csv\")\ndf_sales_train_validation.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Add another 28 days with null values to make predictions successfully\n\nnumber_of_train = 1913\ndays_to_predict = 28\n\nfor i in range(days_to_predict):\n    prediction_d = number_of_train + (i + 1)\n    df_sales_train_validation[f\"d_{prediction_d}\"] = np.nan\ndf_sales_train_validation.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create features\n# Melt the dataframe to have \"sales everyday\" as a feature\n\nindex_columns = [\"id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"]\n\ndf_sales_features = df_sales_train_validation.melt(\n    id_vars = index_columns\n    , var_name = \"d\"\n    , value_name = \"sales\"\n)\ndf_sales_features.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Memory usage control\n\nmemory_usage_string = format_memory_usage(df_sales_features.memory_usage().sum())\nprint(f\"Original memory usage: {memory_usage_string}\")\n\n# Technics: converting strings to categorical variables\nfor column in index_columns:\n    df_sales_features[column] = df_sales_features[column].astype(\"category\")\n\nmemory_usage_string = format_memory_usage(df_sales_features.memory_usage().sum())\nprint(f\"Reduced memory usage: {memory_usage_string}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering - Sales with Price and Calendar\n- Joining DataFrames in Pandas is memory-consuming, so we do the join work after creating basic features.\n- A lot of 0s before the first positive number in sales may mean that the item is only available after a certain time.\n- So, \"when the product has price in a certain store\", this means that product is available after that day.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load price dataset\n\ndf_sell_prices = pd.read_csv(\"sell_prices.csv\")\ndf_sell_prices.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create features\n# Items are available after that a certain time\n\ndf_available_after = df_sell_prices.groupby([\"store_id\",\"item_id\"])[\"wm_yr_wk\"].agg([\"min\"]).reset_index()\ndf_available_after.columns = [\"store_id\", \"item_id\", \"available_after\"]\ndf_available_after.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Join df_sales_features and df_available_after\n\ndf_sales_features = merge_by_concat(df_sales_features, df_available_after, [\"store_id\", \"item_id\"])\ndf_sales_features.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We can drop those rows before available date\n# To achieve this, we need df_calendar's help\n\ndf_calendar = pd.read_csv(\"calendar.csv\")\ndf_calendar.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Join df_sales_features and df_calendar\n\ndf_sales_features = merge_by_concat(df_sales_features, df_calendar[[\"d\", \"wm_yr_wk\"]], [\"d\"])\ndf_sales_features.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We only need those entries after \"available_after\"\n\ndf_sales_features = df_sales_features[df_sales_features[\"wm_yr_wk\"] >= df_sales_features[\"available_after\"]]\ndf_sales_features = df_sales_features.reset_index(drop = True)\ndf_sales_features.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Memory usage control\n\nmemory_usage_string = format_memory_usage(df_sales_features.memory_usage().sum())\nprint(f\"Original memory usage: {memory_usage_string}\")\n\n# Technics: we know the minimum of a certain column, so we find the difference between each row and its minimum\n# and store those differences in int16\ndf_sales_features.drop([\"wm_yr_wk\"], axis = 1, inplace = True)\ndf_sales_features[\"available_after\"] = (df_sales_features[\"available_after\"] - df_sales_features[\"available_after\"].min()).astype(np.int16)\n\n# Technics: for column \"d\", we would like to store it with int16 format\ndf_sales_features[\"d\"] = df_sales_features[\"d\"].apply(lambda x: int(x[2:])).astype(np.int16)\n\nmemory_usage_string = format_memory_usage(df_sales_features.memory_usage().sum())\nprint(f\"Reduced memory usage: {memory_usage_string}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sort values to easily join features later\n\ndf_sales_features.sort_values(by = [\"id\", \"d\"], inplace = True)\ndf_sales_features.reset_index(drop = True, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check dataset\n\ndf_sales_features.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check data type\n\ndf_sales_features.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Change to output path\n\ntry:\n    os.chdir(BASE_PATH)\n    print(f\"Change to directory: {os.getcwd()}\")\nexcept:\n    os.mkdir(BASE_PATH)\n    os.chdir(BASE_PATH)\n    print(f\"Create and change to directory: {os.getcwd()}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save pickle file\n\ndf_sales_features.to_pickle(\"sales_basic_features.pkl\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}