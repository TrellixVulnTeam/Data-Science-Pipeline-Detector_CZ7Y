{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Set environment variables\nimport os\nimport warnings\nimport numpy as np\nimport pandas as pd\nfrom math import ceil\n\nVERSION = 1\nINPUT_PATH = f\"/kaggle/input/m5-forecasting-accuracy\"\nBASE_PATH = f\"/kaggle/working/m5-forecasting-accuracy-ver{VERSION}\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Turn off warnings\n\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Change directory\n\nos.chdir(INPUT_PATH)\nprint(f\"Change to directory: {os.getcwd()}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Memory usage function and merge by concat function (not to lose data type)\n\ndef format_memory_usage(total_bytes):\n    unit_list = [\"\", \"Ki\", \"Mi\", \"Gi\"]\n    for unit in unit_list:\n        if total_bytes < 1024:\n            return f\"{total_bytes:.2f}{unit}B\"\n        total_bytes /= 1024\n    return f\"{total_bytes:.2f}{unit}B\"\n\ndef merge_by_concat(df1, df2, columns):\n    df_temp = df1[columns]\n    df_temp = df_temp.merge(df2, on = columns, how = \"left\")\n    new_columns = [column for column in list(df_temp) if column not in columns]\n    df1 = pd.concat([df1, df_temp[new_columns]], axis = 1)\n    return df1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering - Calendar\n- For each sales record, we want to add further information from the raw calendar dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load and check dataset\n\ndf_calendar = pd.read_csv(\"calendar.csv\")\ndf_calendar.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select the necessary information\n# For example, we can extract day, month or year information from \"date\" column\n\ncalendar_selected_columns = [\n    \"date\"\n    , \"d\"\n    , \"event_name_1\"\n    , \"event_type_1\"\n    , \"event_name_2\"\n    , \"event_type_2\"\n    , \"snap_CA\"\n    , \"snap_TX\"\n    , \"snap_WI\"\n]\ndf_calendar_features = df_calendar[calendar_selected_columns]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Memory usage control\n\nmemory_usage_string = format_memory_usage(df_calendar_features.memory_usage().sum())\nprint(f\"Original memory usage: {memory_usage_string}\")\n\n# Technics: converting strings to categorical variables\ncalendar_category_columns = [\n    \"event_name_1\"\n    , \"event_type_1\"\n    , \"event_name_2\"\n    , \"event_type_2\"\n    , \"snap_CA\"\n    , \"snap_TX\"\n    , \"snap_WI\"\n]\nfor column in calendar_category_columns:\n    df_calendar_features[column] = df_calendar_features[column].astype(\"category\")\n\nmemory_usage_string = format_memory_usage(df_calendar_features.memory_usage().sum())\nprint(f\"Reduced memory usage: {memory_usage_string}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create features\n# Convert date to datetime variables and store the derivative information in int8\n\nmemory_usage_string = format_memory_usage(df_calendar_features.memory_usage().sum())\nprint(f\"Original memory usage: {memory_usage_string}\")\n\ndf_calendar_features[\"date\"] = pd.to_datetime(df_calendar_features[\"date\"])\ndf_calendar_features[\"day\"] = df_calendar_features[\"date\"].dt.day.astype(np.int8)\ndf_calendar_features[\"weekday\"] = df_calendar_features[\"date\"].dt.dayofweek.astype(np.int8)\ndf_calendar_features[\"week\"] = df_calendar_features[\"date\"].dt.week.astype(np.int8)\ndf_calendar_features[\"month\"] = df_calendar_features[\"date\"].dt.month.astype(np.int8)\ndf_calendar_features[\"year\"] = (df_calendar_features[\"date\"].dt.year - df_calendar_features[\"date\"].dt.year.min()).astype(np.int8)\ndf_calendar_features[\"week_of_month\"] = df_calendar_features[\"date\"].dt.day.apply(lambda x: ceil(x / 7)).astype(np.int8)\ndf_calendar_features[\"is_weekend\"] = (df_calendar_features[\"weekday\"] >= 5).astype(np.int8)\n\n# Technics: for column \"d\", we would like to store it with int16 format\ndf_calendar_features[\"d\"] = df_calendar_features[\"d\"].apply(lambda x: int(x[2:])).astype(np.int16)\n\nmemory_usage_string = format_memory_usage(df_calendar_features.memory_usage().sum())\nprint(f\"Memory usage after columns added: {memory_usage_string}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check dataset\n\ndf_calendar_features.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check data type\n\ndf_calendar_features.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering - Price\n- For each sales record, we want to add further information from the raw price dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load and check dataset\n\ndf_sell_prices = pd.read_csv(\"sell_prices.csv\")\ndf_sell_prices.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create features\n# Selling prices are not as fluctuating as we expect,\n# so we only need several characteristics to capture their distribution\n\ndf_sell_prices_grouped = df_sell_prices.groupby([\"store_id\", \"item_id\"])\n\nmemory_usage_string = format_memory_usage(df_sell_prices.memory_usage().sum())\nprint(f\"Original memory usage: {memory_usage_string}\")\n\ndf_sell_prices[\"price_max\"] = df_sell_prices_grouped[\"sell_price\"].transform(\"max\").astype(np.float16)\ndf_sell_prices[\"price_min\"] = df_sell_prices_grouped[\"sell_price\"].transform(\"min\").astype(np.float16)\ndf_sell_prices[\"price_mean\"] = df_sell_prices_grouped[\"sell_price\"].transform(\"mean\").astype(np.float16)\ndf_sell_prices[\"price_std\"] = df_sell_prices_grouped[\"sell_price\"].transform(\"std\").astype(np.float16)\ndf_sell_prices[\"price_scaled\"] = (\n    (df_sell_prices[\"sell_price\"] - df_sell_prices[\"price_min\"])\n    / (df_sell_prices[\"price_max\"] - df_sell_prices[\"price_min\"])\n).astype(np.float16)\ndf_sell_prices[\"price_nunique\"] = df_sell_prices_grouped[\"sell_price\"].transform(\"nunique\").astype(np.int16)\ndf_sell_prices[\"item_nunique\"] = df_sell_prices.groupby([\"store_id\", \"sell_price\"])[\"item_id\"].transform(\"nunique\").astype(np.int16)\n\nmemory_usage_string = format_memory_usage(df_sell_prices.memory_usage().sum())\nprint(f\"Memory usage after columns added: {memory_usage_string}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check dataset\n\ndf_sell_prices.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering - Price with Calendar\n- Joining DataFrames in Pandas is memory consuming, so we do the join work after creating basic features.\n- We want to evaluate how do prices change over weeks, months or years,\n- so we need to join price and calendar datasets to generate these features.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Join df_sell_prices and raw df_calendar\n\ndf_price_features = merge_by_concat(df_sell_prices, df_calendar[[\"wm_yr_wk\", \"month\", \"year\", \"d\"]], [\"wm_yr_wk\"])\ndf_price_features.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create features\n# Evaluate how do prices change periodically\n\nmemory_usage_string = format_memory_usage(df_price_features.memory_usage().sum())\nprint(f\"Original memory usage: {memory_usage_string}\")\n\ndf_price_features[\"price_mean_change_week\"] = (\n    df_price_features[\"sell_price\"] / df_price_features.groupby([\"store_id\", \"item_id\", \"wm_yr_wk\"])[\"sell_price\"].transform(\"mean\")\n).astype(np.float16)\ndf_price_features[\"price_mean_change_month\"] = (\n    df_price_features[\"sell_price\"] / df_price_features.groupby([\"store_id\", \"item_id\", \"month\"])[\"sell_price\"].transform(\"mean\")\n).astype(np.float16)\ndf_price_features[\"price_mean_change_year\"] = (\n    df_price_features[\"sell_price\"] / df_price_features.groupby([\"store_id\", \"item_id\", \"year\"])[\"sell_price\"].transform(\"mean\")\n).astype(np.float16)\n\nmemory_usage_string = format_memory_usage(df_price_features.memory_usage().sum())\nprint(f\"Memory usage after columns added: {memory_usage_string}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check dataset\n\nprice_selected_columns = [\n    \"store_id\"\n    , \"item_id\"\n    , \"d\"\n    , \"sell_price\"\n    , \"price_max\"\n    , \"price_min\"\n    , \"price_mean\"\n    , \"price_std\"\n    , \"price_scaled\"\n    , \"price_nunique\"\n    , \"item_nunique\"\n    , \"price_mean_change_week\"\n    , \"price_mean_change_month\"\n    , \"price_mean_change_year\"\n]\ndf_price_features = df_price_features[price_selected_columns]\ndf_price_features.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Memory usage control\n\nmemory_usage_string = format_memory_usage(df_price_features.memory_usage().sum())\nprint(f\"Original memory usage: {memory_usage_string}\")\n\n# Technics: converting strings to categorical variables\nprice_category_columns = [\"store_id\", \"item_id\"]\nfor column in price_category_columns:\n    df_price_features[column] = df_price_features[column].astype(\"category\")\n\n# Technics: for column \"sell_price\", we would like to store it with float16 format\ndf_price_features[\"sell_price\"] = df_price_features[\"sell_price\"].astype(np.float16)\n\n# Technics: for column \"d\", we would like to store it with int16 format\ndf_price_features[\"d\"] = df_price_features[\"d\"].apply(lambda x: int(x[2:])).astype(np.int16)\n\nmemory_usage_string = format_memory_usage(df_price_features.memory_usage().sum())\nprint(f\"Reduced memory usage: {memory_usage_string}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check dataset\n\ndf_price_features.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check data type\n\ndf_price_features.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Change to output path\n\ntry:\n    os.chdir(BASE_PATH)\n    print(f\"Change to directory: {os.getcwd()}\")\nexcept:\n    os.mkdir(BASE_PATH)\n    os.chdir(BASE_PATH)\n    print(f\"Create and change to directory: {os.getcwd()}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save pickle file\n\ndf_calendar_features.to_pickle(\"calendar_features.pkl\")\ndf_price_features.to_pickle(\"price_features.pkl\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}