{"cells":[{"metadata":{},"cell_type":"markdown","source":"# About this notebook\n- To continue the creation of lag features, we definitely want to have more information from the past sales,\n- but it is just not possible and not efficiently to create features by shifting \"sales\" column until day 1941,\n- so we must have a better way to get the information we want with reasonable calculation and memory usage.\n- Basic features: https://www.kaggle.com/kaiweihuang/m5-forecasting-accuracy-sales-basic-features\n- Lag features: https://www.kaggle.com/kaiweihuang/m5-forecasting-accuracy-sales-lag-features","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Set environment variables\nimport os\nimport time\nimport warnings\nimport numpy as np\nimport pandas as pd\n\nVERSION = 1\nINPUT_PATH = f\"/kaggle/input/m5-forecasting-accuracy-sales-basic-features\"\nBASE_PATH = f\"/kaggle/working/m5-forecasting-accuracy-ver{VERSION}\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Turn off warnings\n\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Change directory\n\nos.chdir(INPUT_PATH)\nprint(f\"Change to directory: {os.getcwd()}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Memory usage function\n\ndef format_memory_usage(total_bytes):\n    unit_list = [\"\", \"Ki\", \"Mi\", \"Gi\"]\n    for unit in unit_list:\n        if total_bytes < 1024:\n            return f\"{total_bytes:.2f}{unit}B\"\n        total_bytes /= 1024\n    return f\"{total_bytes:.2f}{unit}B\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set global variables\n\ndays_to_predict = 28\nrolling_days = [60, 90, 180, 365]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load dataset from our previous work\n\ndf_rolling_features = pd.read_pickle(\"m5-forecasting-accuracy-ver1/sales_basic_features.pkl\")\ndf_rolling_features.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering - Sales - Rolling Lag Features\n- From day 1 to 28, we have created lag features to contain raw information.\n- Because of memory constraint, it is not possible to keep creating those features until day 1941,\n- and even if we have enough spaces, it is still not the most efficient way to utilize the memory.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"- For each longer period, we calculate some descriptive statistics of its distribution to capture the characteristics.\n- For example, for sales information in past 60 days, instead of shifting \"sales\" column 60 times,\n- we can create features like mean or median by a moving window with 1 step each time,\n- which stores the crucial information efficiently, and condense 60 columns into one.\n- And remember that 28 days shift is to ensure that every prediction row contains those features.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get necessary columns only\n\ndf_rolling_features = df_rolling_features[[\"id\", \"d\", \"sales\"]]\ndf_rolling_features.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create features\n# Generate rolling lag features and control the memory usage\n\ndf_rolling_grouped = df_rolling_features.groupby([\"id\"])[\"sales\"]\n\nfor day in rolling_days:\n\n    start_time = time.time()\n    print(f\"Rolling {str(day)} Start.\")\n\n    df_rolling_features[f\"rolling_{str(day)}_max\"] = df_rolling_grouped.transform(lambda x: x.shift(days_to_predict).rolling(day).max()).astype(np.float16)\n    df_rolling_features[f\"rolling_{str(day)}_min\"] = df_rolling_grouped.transform(lambda x: x.shift(days_to_predict).rolling(day).min()).astype(np.float16)\n    df_rolling_features[f\"rolling_{str(day)}_median\"] = df_rolling_grouped.transform(lambda x: x.shift(days_to_predict).rolling(day).median()).astype(np.float16)\n    df_rolling_features[f\"rolling_{str(day)}_mean\"] = df_rolling_grouped.transform(lambda x: x.shift(days_to_predict).rolling(day).mean()).astype(np.float16)\n    df_rolling_features[f\"rolling_{str(day)}_std\"] = df_rolling_grouped.transform(lambda x: x.shift(days_to_predict).rolling(day).std()).astype(np.float16)\n\n    end_time = time.time()\n    print(f\"Calculation time: {round(end_time - start_time)} seconds\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check dataset\n\ndf_rolling_features.head(120)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check data type\n\ndf_rolling_features.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check current memory usage\n\nmemory_usage_string = format_memory_usage(df_rolling_features.memory_usage().sum())\nprint(f\"Current memory usage: {memory_usage_string}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Note\n- Some more ways to make features better:\n- Now, for sales within past 28 days, we collect all raw data as features in previous notebook,\n- but we don't know if raw data will perform better than descriptive statistics.\n- Also, keep shifting 28 days is making the training data have a lot of NaN, especially in longer periods.\n- So, 1) Shifting within 28 days, which will increase the effective training data, but let features in prediction row fewer.\n- 2) Calculating descriptive statistics in shorter periods, such as 7, 14, 21, 30.\n- 3) We have also canceled the calculation of skewness and kurtosis due to memory limit, and they are worth trying actually.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Change to output path\n\ntry:\n    os.chdir(BASE_PATH)\n    print(f\"Change to directory: {os.getcwd()}\")\nexcept:\n    os.mkdir(BASE_PATH)\n    os.chdir(BASE_PATH)\n    print(f\"Create and change to directory: {os.getcwd()}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save pickle file\n\ndf_rolling_features.to_pickle(\"sales_rolling_features.pkl\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}