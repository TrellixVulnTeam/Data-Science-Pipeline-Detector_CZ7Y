{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom fbprophet import Prophet\nfrom tqdm import tqdm, tnrange\nfrom multiprocessing import Pool, cpu_count\nimport functools","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"calendar_data = pd.read_csv('/kaggle/input/m5-forecasting-accuracy/calendar.csv')\n#sales_data =  pd.read_csv('/kaggle/input/m5-forecasting-accuracy/sales_train_validation.csv')\nsell_prices = pd.read_csv('/kaggle/input/m5-forecasting-accuracy/sell_prices.csv')\nsubmission0 = pd.read_csv('/kaggle/input/m5-forecasting-accuracy/sample_submission.csv')\n#submission_m = pd.read_csv('../input/subjune25/submission.csv')\nevaluation = pd.read_csv('/kaggle/input/m5-forecasting-accuracy/sales_train_evaluation.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#temp = submission0.iloc[submission_m.shape[0]:,:]\n#temp2 = pd.concat([submission_m,temp])\n#temp2.to_csv('temp2.csv')\n#temp2.shape\n\nsales_data = evaluation\nsales_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_id_info(id1):\n    id_info= id1.split('_')\n    state = id_info[3]\n    category = id_info[0]\n    return state,category\n\n\ndef select_snaps(df,id1):\n    state, category = extract_id_info(id1)\n    snap_days_CA = df[df['snap_CA']==1]['date'].unique()\n    snap_days_TX = df[df['snap_TX']==1]['date'].unique()\n    snap_days_WI = df[df['snap_TX']==1]['date'].unique()\n    if state =='CA':\n        return snap_days_CA\n    elif state == 'TX':\n        return snap_days_TX\n    else:\n        return snap_days_WI","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_holidays(id1):\n\n    Hol1_rel = calendar_data[calendar_data['event_type_1']=='Religious']['date'].unique()\n    Hol1_nat = calendar_data[calendar_data['event_type_1']=='National']['date'].unique()\n    Hol1_cul = calendar_data[calendar_data['event_type_1']=='Cultural']['date'].unique()\n    Hol1_Sp = calendar_data[calendar_data['event_type_1']=='Sporting']['date'].unique()\n\n    #----------------------------\n    Hol2_rel = calendar_data[calendar_data['event_type_2']=='Religious']['date'].unique()\n    Hol2_cul = calendar_data[calendar_data['event_type_2']=='Cultural']['date'].unique()    \n    \n    snap_days1 = pd.DataFrame({\n      'holiday': 'snaps',\n      'ds': pd.to_datetime(select_snaps(calendar_data, id1)),\n      'lower_window': 0,\n      'upper_window': 0,\n    })\n\n    \n    holiday1_rel = pd.DataFrame({\n      'holiday': 'holiday_religious',\n      'ds': pd.to_datetime(Hol1_rel),\n      'lower_window': -1,\n      'upper_window': 1,\n    })\n\n\n\n    holiday1_cul = pd.DataFrame({\n      'holiday': 'holiday_cultural',\n      'ds': pd.to_datetime(Hol1_cul),\n      'lower_window': -1,\n      'upper_window': 1,\n    })\n\n    holiday1_nat = pd.DataFrame({\n      'holiday': 'holiday_national',\n      'ds': pd.to_datetime(Hol1_nat),\n      'lower_window': -1,\n      'upper_window': 1,\n    })\n\n\n    holiday2_cul = pd.DataFrame({\n      'holiday': 'holiday_religious',\n      'ds': pd.to_datetime(Hol2_cul),\n      'lower_window': -1,\n      'upper_window': 1,\n    })\n\n\n    holiday2_rel = pd.DataFrame({\n      'holiday': 'holiday_religious',\n      'ds': pd.to_datetime(Hol2_rel),\n      'lower_window': -1,\n      'upper_window': 1,\n    })\n    holidays =  pd.concat((snap_days1,holiday1_rel,holiday1_cul,holiday1_nat,holiday2_cul,holiday2_rel))\n    return holidays\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nHol1_rel = df[df['event_type_1']=='Religious']['snapshot_date'].unique()\nHol1_nat = df[df['event_type_1']=='National']['snapshot_date'].unique()\nHol1_cul = df[df['event_type_1']=='Cultural']['snapshot_date'].unique()\nHol1_Sp = df[df['event_type_1']=='Sporting']['snapshot_date'].unique()\n\n#----------------------------\nHol2_rel = df[df['event_type_2']=='Religious']['snapshot_date'].unique()\nHol2_cul = df[df['event_type_2']=='Cultural']['snapshot_date'].unique()\n\n\n\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def run_prophet(id1,data):\n    holidays = get_holidays(id1)\n    model = Prophet(uncertainty_samples=False,\n                    holidays=holidays,\n                    weekly_seasonality = True,\n                    yearly_seasonality= True,\n                    changepoint_prior_scale = 0.7\n                   )\n    \n    #model.add_seasonality(name='monthly', period=30.5, fourier_order=2)\n    model.fit(data)\n    future = model.make_future_dataframe(periods=28, include_history=False)\n    forecast2 = model.predict(future)\n    submission = make_validation_file(id1,forecast2)\n    return submission\n\n\nF_cols = np.array(['F'+str(i) for i in range(1,29)])\n\ndef make_validation_file(id1,forecast2):\n    item_id = id1\n    submission = pd.DataFrame(columns=F_cols)\n    submission.insert(0,'id',item_id)\n    forecast2['yhat'] = np.where(forecast2['yhat']<0,0,forecast2['yhat'])\n    forecast2.rename({'yhat':'y','ds':'ds'},inplace=True,axis = 1)\n    forecast2 = forecast2[['ds','y']].T\n    submission.loc[1,'id'] =item_id\n    submission[F_cols] = forecast2.loc['y',:].values[-28:]\n    #col_order = np.insert(F_cols,0,'id')\n    #sub_val = submission[col_order]\n    return submission\n\n\n\"\"\"\ndef train_model(data,holidays, id1,train_start, train_end):\n    data = data[data['id']==id1]\n    data = data.rename({'snapshot_date':'ds','sales':'y'},axis=1)[['sell_price','ds','y']]\n    data_tr = data[(data['ds']>=str(train_start)) & (data['ds']<=str(train_end))]\n    median =  data_tr['sell_price'].median(axis = 0)\n    data_tr['sell_price'] = data_tr['sell_price'].fillna(median)\n    data_tr['ds'] = data_tr['ds'].astype('datetime64')\n    m2 = Prophet(holidays=holidays,weekly_seasonality = True, yearly_seasonality= True,changepoint_prior_scale = 0.7,uncertainty_samples = False)\n    m2.add_seasonality(name='monthly', period=30.5, fourier_order=5)\n    m2.add_regressor('sell_price')\n    m2.fit(data_tr)\n    return m2\n\"\"\"\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nid1 = sales_data.iloc[0,0]\ndata_series = sales_data.iloc[1,start_idx:]\ndata_series.index = calendar_data['date'][start_idx:start_idx+len(data_series)]\ndata_series =  pd.DataFrame(data_series)\ndata_series = data_series.reset_index()\ndata_series.columns = ['ds', 'y']\ndata_series\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# *VALIDATION PREDICTION***","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"common_cols = 6\nend_time = sales_data.shape[1] - common_cols\nstart_time = end_time -2*365\nstart_idx = start_time + 5\ndata_m =[]\nid_lst =[]\nfor i in tnrange(sales_data.shape[0]):\n    id_lst.append(sales_data.iloc[i,0])\n    data_series = sales_data.iloc[i,start_idx:]\n    data_series.index = calendar_data['date'][start_idx:start_idx+len(data_series)]\n    data_series =  pd.DataFrame(data_series)\n    data_series = data_series.reset_index()\n    data_series.columns = ['ds', 'y']\n    data_m.append(data_series)\n    \ncomb_lst = [(id_lst[counter],data_m[counter]) for counter in range(0,len(id_lst))]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nstart = time.time()\nwith Pool(4) as p:\n    submission = p.starmap(run_prophet,comb_lst)\n\nsubmission = pd.concat(submission,axis =0)\nend = time.time()\nelapsed_time = end-start\ntime_taken = time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))\nprint('time',time_taken)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#temp = submission0.iloc[submission.shape[0]:,:]\n#submission = pd.concat([submission,temp])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.shape\nsubmission.to_csv('submission_evaluation.csv',index = False)\nsubmission.shape","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}