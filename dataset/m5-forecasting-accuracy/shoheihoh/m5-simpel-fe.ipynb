{"cells":[{"metadata":{},"cell_type":"markdown","source":"https://www.kaggle.com/kyakovlev/m5-simple-fe を参考にしています。","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"- id                  \n    - item_id             \n        - dept_id             \n        - cat_id              \n    - store_id            \n        - state_id            \n- d                   \n- sales               :target、売り上げ\n- release             :発売されてからの期間(週)\n- sell_price          :値段\n    - price_max           \n    - price_min           \n    - price_std           \n    - price_mean          \n    - price_norm      :sell_price / price_max。値段が一番高い時と比べた時の比率。\n    - price_nunique   :そのお店の、そのアイテムの、期間中の、値段の個数\n    - item_nunique    :その値段の、そのアイテムの、期間中の、アイテムの個数\n    - price_momentum      :sell_price / 昨日のsell_price\n    - price_momentum_m    :sell_price / 1ヶ月のsell_priceの平均\n    - price_momentum_y    :sell_price / 1年のsell_priceの平均\n- event_name_1        category\n- event_type_1        category\n- event_name_2        category\n- event_type_2        category\n- snap_CA             category\n- snap_TX             category\n- snap_WI             category\n    - tm_d                :日にち\n    - tm_w                :その年の、週目\n    - tm_m                :月\n    - tm_y                :年\n    - tm_wm               :月の何周目か。7日:1周目、8日:２周目\n    - tm_dw               :曜日。月曜日:0、日曜日:6\n    - tm_w_end            :週末かどうか。祝日も加えたい。","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# モジュールのインポート","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os, sys, gc, time, warnings, pickle, psutil, random\nfrom math import ceil\nfrom sklearn.preprocessing import LabelEncoder\n\nwarnings.filterwarnings('ignore')\npd.set_option(\"display.max_columns\", 500)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 関数の定義\n- メモリを扱う関数\n    - get_memory_usage: メモリの使用量を調べる。\n    - sizeof_fmt: メモリのサイズの単位を調整する。\n    - reduce_mem_usage: メモリのサイズを節約する。\n- dataframeの結合を扱う関数\n    - merge_by_concat: 2つのデータフレームを結合する。カラムを増やすイメージ。\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#メモリの使用量を調べる。\ndef get_memory_usage():\n    process_id   = os.getpid()                #自分のプロセス番号\n    process      = psutil.Process(process_id) #プロセスを指定\n    memory_usage = process.memory_info()[0]/2. ** 30\n    memory_usage = np.round(memory_usage, 2)\n    return memory_usage\n\n\n#メモリのサイズを調整する。\ndef sizeof_fmt(num, suffix='B'):\n    for unit in ['', 'Ki', 'Mi', 'Gi', 'Ti', 'Pi', 'Ei', 'Zi']:\n        if abs(num) < 1024.0:\n            return \"{:3.1f}{unit}{suffix}\".format(num, unit=unit, suffix=suffix)\n        num /=  1024.0\n    return \"{:.1f}{unit}{suffix}\".format(num, unit='Yi', suffix=suffix)\n\n\n#メモリのサイズを節約する。\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                       df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f} % reduction)'.format(end_mem, (start_mem - end_mem) * 100 / start_mem))\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 2つのdfを繋げる。\ndef merge_by_concat(df1, df2, merge_on):\n    merged_gf = df1[merge_on]\n    merged_gf = merged_gf.merge(df2, on=merge_on, how='left')\n    new_columns = [col for col in list(merged_gf) if col not in merge_on]\n    df1 = pd.concat([df1, merged_gf[new_columns]], axis=1)\n    return df1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 定数の設定と、データの準備\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"TARGET = 'sales'         \nEND_TRAIN = 1913         \nMAIN_INDEX = ['id','d'] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# データの読み込み\ntrain_df    = pd.read_csv('../input/m5-forecasting-accuracy/sales_train_validation.csv')\nprices_df   = pd.read_csv('../input/m5-forecasting-accuracy/sell_prices.csv')\ncalendar_df = pd.read_csv('../input/m5-forecasting-accuracy/calendar.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# trainデータの整形と保存\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### パート1: trainデータをmeltして、releaseより前の情報は、必要ないため削除する。","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_dfをmeltする。\nindex_columns = ['id','item_id','dept_id','cat_id','store_id','state_id']\ngrid_df = pd.melt(train_df, \n                  id_vars = index_columns, \n                  var_name = 'd', \n                  value_name = TARGET)\nprint('Train rows: {} to {} '.format(len(train_df), len(grid_df)))\n\n\n# predict用の、1914日目から1942日目のrowを追加。\nadd_grid = pd.DataFrame()\nfor i in range(1,29):\n    temp_df = train_df[index_columns]\n    temp_df = temp_df.drop_duplicates()\n    temp_df['d'] = 'd_'+ str(END_TRAIN+i)\n    temp_df[TARGET] = np.nan\n    add_grid = pd.concat([add_grid,temp_df])\n\ngrid_df = pd.concat([grid_df,add_grid])\ngrid_df = grid_df.reset_index(drop=True)\n\n\n# メモリの節約のため、①今後使わないdfを削除。②columnsのtype: 'object' → 'category'に変更\ndel temp_df, add_grid, train_df\n\nprint(\"{:>20}: {:>8}\".format('Original grid_df',sizeof_fmt(grid_df.memory_usage(index=True).sum())))\nfor col in index_columns:\n    grid_df[col] = grid_df[col].astype('category')\nprint(\"{:>20}: {:>8}\".format('Reduced grid_df',sizeof_fmt(grid_df.memory_usage(index=True).sum())))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 各店舗での各商品の発売日(release)を調べる。\nrelease_df = prices_df.groupby(['store_id', 'item_id'])['wm_yr_wk'].agg(['min']).reset_index()\nrelease_df.columns = ['store_id', 'item_id', 'release']\ngrid_df = merge_by_concat(grid_df, release_df, ['store_id','item_id'])\ndel release_df\n\n\n# releaseより前の情報は必要ないので、削除する。\ngrid_df = merge_by_concat(grid_df, calendar_df[['wm_yr_wk', 'd']], ['d'])\ngrid_df = grid_df[grid_df['wm_yr_wk']>=grid_df['release']]\ngrid_df = grid_df.reset_index(drop=True)\n\n\n# releaseカラムは、差分だけ保持することで、メモリを節約する。\nprint(\"{:>20}: {:>8}\".format('Original grid_df',sizeof_fmt(grid_df.memory_usage(index=True).sum())))\ngrid_df['release'] = grid_df['release'] - grid_df['release'].min()\ngrid_df['release'] = grid_df['release'].astype(np.int16)\nprint(\"{:>20}: {:>8}\".format('Reduced grid_df',sizeof_fmt(grid_df.memory_usage(index=True).sum())))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_df.to_pickle('grid_part_1.pkl')\nprint('Size:', grid_df.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### パート2: pricesデータをmergeする。\nメモリがギリギリなので、必要最低限のカラムだけ保持して保存。最大で15.5GBくらいまでいく。","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"prices_df['price_max']     = prices_df.groupby(['store_id','item_id'])['sell_price'].transform('max')\nprices_df['price_min']     = prices_df.groupby(['store_id','item_id'])['sell_price'].transform('min')\nprices_df['price_std']     = prices_df.groupby(['store_id','item_id'])['sell_price'].transform('std')\nprices_df['price_mean']    = prices_df.groupby(['store_id','item_id'])['sell_price'].transform('mean')\nprices_df['price_norm']    = prices_df['sell_price']/prices_df['price_max']\nprices_df['price_nunique'] = prices_df.groupby(['store_id','item_id'])['sell_price'].transform('nunique')\nprices_df['item_nunique']  = prices_df.groupby(['store_id','sell_price'])['item_id'].transform('nunique')\n\n# 瞬間の、月毎の、年毎の、価格の変動を特徴量として加えたい。そのために、calendar_dfから、month, yearを持ってくる。\ncalendar_prices = calendar_df[['wm_yr_wk','month','year']]\ncalendar_prices = calendar_prices.drop_duplicates(subset=['wm_yr_wk'])\nprices_df = prices_df.merge(calendar_prices[['wm_yr_wk','month','year']], on=['wm_yr_wk'], how='left')\ndel calendar_prices\n\nprices_df['price_momentum']   = prices_df['sell_price']/prices_df.groupby(['store_id','item_id'])['sell_price'].transform(lambda x: x.shift(1))\nprices_df['price_momentum_m'] = prices_df['sell_price']/prices_df.groupby(['store_id','item_id','month'])['sell_price'].transform('mean')\nprices_df['price_momentum_y'] = prices_df['sell_price']/prices_df.groupby(['store_id','item_id','year'])['sell_price'].transform('mean')\n\ndel prices_df['month'], prices_df['year']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"original_columns = list(grid_df)\ngrid_df = grid_df.merge(prices_df, on=['store_id','item_id','wm_yr_wk'], how='left')\nkeep_columns = [col for col in list(grid_df) if col not in original_columns]\ngrid_df = grid_df[MAIN_INDEX + keep_columns]\ngrid_df = reduce_mem_usage(grid_df)\ngrid_df.to_pickle('grid_part_2.pkl')\nprint('Size:', grid_df.shape)\ndel prices_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### パート3: calendarデータをmergeする。","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_df = pd.read_pickle('grid_part_1.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_df = grid_df[MAIN_INDEX]\n\n\n# merge\nicols = ['date',\n         'd',\n         'event_name_1',\n         'event_type_1',\n         'event_name_2',\n         'event_type_2',\n         'snap_CA',\n         'snap_TX',\n         'snap_WI']\ngrid_df = grid_df.merge(calendar_df[icols], on=['d'], how='left')\n\n\n# メモリの節約\nicols = ['event_name_1',\n         'event_type_1',\n         'event_name_2',\n         'event_type_2',\n         'snap_CA',\n         'snap_TX',\n         'snap_WI']\nfor col in icols:\n    grid_df[col] = grid_df[col].astype('category')\n    \n    \n# 新しい特徴量の作成\ngrid_df['date']  = pd.to_datetime(grid_df['date'])\ngrid_df['tm_d']  = grid_df['date'].dt.day.astype(np.int8)\ngrid_df['tm_w']  = grid_df['date'].dt.week.astype(np.int8)\ngrid_df['tm_m']  = grid_df['date'].dt.month.astype(np.int8)\ngrid_df['tm_y']  = grid_df['date'].dt.year\ngrid_df['tm_y']  = (grid_df['tm_y'] - grid_df['tm_y'].min()).astype(np.int8)\ngrid_df['tm_wm'] = grid_df['tm_d'].apply(lambda x: ceil(x/7)).astype(np.int8) #月の何周目か。7日:1周目、8日:２周目\ngrid_df['tm_dw'] = grid_df['date'].dt.dayofweek.astype(np.int8) #曜日。月曜日:0、日曜日:6\ngrid_df['tm_w_end'] = (grid_df['tm_dw']>=5).astype(np.int8) #週末かどうか。祝日も加えたい。\n\ndel grid_df['date']  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_df.to_pickle('grid_part_3.pkl')\nprint('Size:', grid_df.shape)\n\ndel calendar_df, grid_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### パートおまけ: さらにメモリを節約する。","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# パート1のメモリをさらに減らす。\ngrid_df = pd.read_pickle('grid_part_1.pkl')\ngrid_df['d'] = grid_df['d'].apply(lambda x: x[2:]).astype(np.int16)\n\ndel grid_df['wm_yr_wk']\ngrid_df.to_pickle('grid_part_1.pkl')\n\ndel grid_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# まとめ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_df = pd.concat([pd.read_pickle('grid_part_1.pkl'),\n                     pd.read_pickle('grid_part_2.pkl').iloc[:,2:],\n                     pd.read_pickle('grid_part_3.pkl').iloc[:,2:]],\n                     axis=1)\n\nprint(\"{:>20}: {:>8}\".format('Full Grid',sizeof_fmt(grid_df.memory_usage(index=True).sum())))\nprint('Size', grid_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 2.4GBは学習に扱うのに大きすぎる。\n# state_id, shop_idで区切って、学習すれば、よりメモリを減らせる。\n\nstate_id = 'CA'\ngrid_df = grid_df[grid_df['state_id']==state_id]\nprint(\"{:>20}: {:>8}\".format('Full Grid',sizeof_fmt(grid_df.memory_usage(index=True).sum())))\n\nstore_id = 'CA_1'\ngrid_df = grid_df[grid_df['store_id']==store_id]\nprint(\"{:>20}: {:>8}\".format('Full Grid',sizeof_fmt(grid_df.memory_usage(index=True).sum())))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_df.info()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}