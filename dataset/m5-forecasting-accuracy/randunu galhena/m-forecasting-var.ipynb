{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this analysis I firstly identified this data set follwed time series distribution and there  has more than one time-dependent variables which are the independent items. These kind of the time series explain as multivariate time series. So Vector Autoregression Data mode (VAR) we can use for these kind of the data set. Because of that I used for the prdiction VAR model and before creating data model I did some descriptive analysis..."},{"metadata":{"trusted":true},"cell_type":"code","source":"path = \"../input/m5-forecasting-accuracy\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nfrom statsmodels.tsa.arima_model import ARIMA\nimport seaborn as sns\nimport os","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Sell Prices Data Set"},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = pd.read_csv(os.path.join(path, \"sell_prices.csv\")) #import the data sets\ndf1.head(5)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Sales Train Validation Data Set"},{"metadata":{"trusted":true},"cell_type":"code","source":"df2 = pd.read_csv(os.path.join(path, \"sales_train_validation.csv\"))\ndf2.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Calendar Data Set"},{"metadata":{"trusted":true},"cell_type":"code","source":"df3 = pd.read_csv(os.path.join(path, \"calendar.csv\"))\ndf3.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df3.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis"},{"metadata":{},"cell_type":"markdown","source":"Select the one item \"HOBBIES_1_002\" see how it sold within stores, then can see clearly this item sold in all three state and 10 stores each states"},{"metadata":{"trusted":true},"cell_type":"code","source":"df2_subset = df2[df2['item_id'] == 'HOBBIES_1_002'] \ndf2_subset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 5))\nplt.plot(df2_subset.iloc[0, 6:].values)\nplt.xlabel('Days')\nplt.ylabel('NUmber of Units sales')\nplt.title('HOBBIES_1_002 item sales within time period')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below graph draw using 7 day moving avarages and from the graph we can see there have some seasonality structures because of that time series prediction modeks can be use for the analysis.."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 5))\nplt.plot(df2_subset.iloc[0, 6:].rolling(7).mean().values)\nplt.xlabel('Days')\nplt.ylabel('NUmber of Units sales')\nplt.title('HOBBIES_1_002 item sales within time period with  days moving averages')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure()\nfig.set_figheight(40)\nfig.set_figwidth(30)\nplt.suptitle('HOBBIES_1_002 item sales within 10 stores with  days moving averages', fontsize=20)\nfor i in range(10):\n    plt.subplot(10, 2, i+1)\n    plt.plot(df2_subset.iloc[i, 6:].rolling(7).mean().values,label=df2_subset.iloc[i, 4])\n    plt.legend()\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Above graph draw using \"HOBBIES_1_002\" item which sold in 10 stores and it was usefull to determine data set follow on time series pattern. Above graph indicate some special times period sales go increase..."},{"metadata":{"trusted":true},"cell_type":"code","source":"abc = df2.groupby(['cat_id'])['dept_id'].count()\nabc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nabc.plot(kind='bar',color=['r', 'g', 'b'])\nplt.title(\"Number of sales within Categories\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most of the items related with FOODS"},{"metadata":{"trusted":true},"cell_type":"code","source":"abc1 = df2.groupby(['dept_id'])['item_id'].count()\nabc1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nabc1.plot(kind='bar',color=['r', 'g', 'b','y','c', 'm','k'])\nplt.title(\"Number of sales within Department\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most of the people bought FOODS_3 department"},{"metadata":{},"cell_type":"markdown","source":"## Consider about Sell price data set"},{"metadata":{"trusted":true},"cell_type":"code","source":"df1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"group2 = df1.groupby(['store_id'],as_index=False)['sell_price'].sum()\ngroup2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x='store_id',y='sell_price', kind='bar', data=group2,height=6, aspect=2)\nplt.xlabel('Store ID')\nplt.ylabel('Total Sales')\nplt.title(\"Distribution of total sales within stores\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"group3 = group2.groupby(group2['store_id'].str.contains('CA'))['sell_price'].sum()\ngroup3","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Accordint above sell price total values California has higher total sell. may be more rich peoples are living in California state Or there have 4 stores but other two states have 2 stores each other that might be a cause for that."},{"metadata":{"trusted":true},"cell_type":"code","source":"df1_subset2 = df1[df1['store_id'].str.contains('CA')]\ndf1_subset2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"group4 = df1_subset2.groupby(['store_id'],as_index=False)['sell_price'].sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x='store_id',y='sell_price', kind='bar', data=group4,height=5, aspect=2.5)\nplt.xlabel('Store ID')\nplt.ylabel('Total Sales')\nplt.title(\"Distribution of total sales within CA state\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## California state CA_1 store mean sell price variation"},{"metadata":{"trusted":true},"cell_type":"code","source":"df1_subset = df1[df1['store_id'] == 'CA_1']\ndf1_subset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"qqq=df1_subset.loc[df1_subset['item_id'].str.contains('HOBBIES_1')]\nqqq","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grouped = qqq.groupby(['wm_yr_wk'])['sell_price'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure()\nfig.set_figheight(12)\nfig.set_figwidth(20)\nplt.ylabel('Mean Sales')\nplt.suptitle('Mean price variasion within Department on CA_1 Store', fontsize=20)\nfor i in range(1,3,1):\n    #plt.subplot(1, 2, 1)\n    qqq=df1_subset.loc[df1_subset['item_id'].str.contains('HOBBIES_' + str(i))]\n    grouped = qqq.groupby(['wm_yr_wk'])['sell_price'].mean()\n    grouped.plot(label='HOBBIES_' + str(i))\n    plt.legend()  \nfor i in range(1,4,1):   \n    qqq=df1_subset.loc[df1_subset['item_id'].str.contains('FOODS_' + str(i))]\n    grouped = qqq.groupby(['wm_yr_wk'])['sell_price'].mean()\n    grouped.plot(label='FOODS_' + str(i))\n    plt.legend() \nfor i in range(1,3,1):\n    qqq=df1_subset.loc[df1_subset['item_id'].str.contains('HOUSEHOLD_' + str(i))]\n    grouped = qqq.groupby(['wm_yr_wk'])['sell_price'].mean()\n    grouped.plot(label='HOUSEHOLD_' + str(i))\n    plt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Above line graph shows HOBBIES_1 department show increassing trent over time. But others stay as stable when times go up. might be some electronic gaming equipment related with HOBBIES_1 products because thease items prices rapidly increasing because new technology are introducing day by day in current world then thease devises prices increse."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure()\nfig.set_figheight(8)\nfig.set_figwidth(20)\nplt.suptitle('HOUSEHOLD item sels variation with moving averages', fontsize=20)\nfor i in range(1,3,1):\n    #plt.subplot(1, 2, i)\n    qqq=df1_subset.loc[df1_subset['item_id'].str.contains('HOUSEHOLD_' + str(i))]\n    grouped = qqq.groupby(['wm_yr_wk'])['sell_price'].mean()\n    grouped.plot()\n    plt.legend()\n    plt.xlabel('Day')\n    plt.ylabel('mean seles')\n    \n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Specially when see HOUSEHOLD_1 & HOUSEHOLD_2 stores in California there have opposite trend between two stores. One has little increassing trend but other has little decreasing trend."},{"metadata":{},"cell_type":"markdown","source":"## Concatenate Calender data set & Sales train data set"},{"metadata":{"trusted":true},"cell_type":"code","source":"df3.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ff38=df3.iloc[0:1913, :]\nff38.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ff8=df2.iloc[:, 6:]\nff8","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df2 = ff8.transpose()\nnew_df2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ff38.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df2.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df996 = new_df2.reset_index()\ndf996","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del df996['index']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df996","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_col = pd.concat([df996,ff38.date,ff38.weekday,ff38.year], axis=1)\ndf_col","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rows = []\nfor i in range(0,1913,1):\n     rows.append(df_col.iloc[i,:30490].sum())\n#print(rows)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dftt = pd.DataFrame(rows, columns=[\"sum\"])\ndftt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gh=df_col.iloc[0:1913,30491:30493]\ngh","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_col1 = pd.concat([dftt,gh], axis=1)\ndf_col1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"calender5 = df_col1.groupby(['weekday'],as_index=False)['sum'].sum()\ncalender5","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below graph well indicate week end days is more busy days because more items sold in saturday and sunday. when people have more free time in week end days then they more interested to buy products"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,6))\nax = sns.lineplot(x=\"weekday\", y=\"sum\", data=calender5,color=\"coral\", label=\"no of units\").set_title('Sales by day')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x='year', kind='count',palette=\"ch:.25\", data=df_col,height=5, aspect=2)\nplt.title(\"Sales by year\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2012/2013/2014 years almost all year opened the these stores but 2011 very small days does not had selles. When consider the 2016 there had less number of data may be this data sets collect in middle of 2016 year.."},{"metadata":{},"cell_type":"markdown","source":"# Vector Autoregression Data model creation (VAR)"},{"metadata":{"trusted":true},"cell_type":"code","source":"del df_col['weekday']\ndel df_col['year']\ndf_col","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"chan = df_col.columns.tolist() #Get \"Date\" variable infront as 1st column\nchan = chan[-1:] + chan[:-1]\ndf_col_n = df_col[chan]\ndf_col_n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From this point I can select the size of my data set this is important because when i use whole data set to train the model then laptop get struck. I think some memory issue in laptop. laptop not capable to predict too much bigger data sets."},{"metadata":{"trusted":true},"cell_type":"code","source":"df9=df_col_n.iloc[:, :1501] #I used first 1000 items and avalable all 1913 days to the prediction\ndf9","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df9.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df9['date'] = pd.to_datetime(df9.date) #Convert the \"date\" variable as datetime because its intial data type is object\ndata = df9.drop(['date'], axis=1)        \ndata.index = df9.date                   #Convert date variable as index of the dataframe\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df9.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = data.columns ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.vector_ar.var_model import VAR\nmodel = VAR(endog=data)\nmodel_fit = model.fit()\nyhat = model_fit.forecast(model_fit.y, steps=1941)\nprint(yhat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = pd.DataFrame(index=range(0,len(yhat)),columns=[cols]) \nfor j in range(0,1500):\n    for i in range(1913,1941):\n       pred.iloc[i][j] = yhat[i][j]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ffinal=pred.iloc[1913:1941, 0:1500]\nffinal","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_sum = ffinal.transpose() #Convert the output data frame inta standard submission format\nfinal_sum","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_sum.to_csv(\"submission4.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After I covet the data in to csv file format then its column names and id names created according to standard submission format"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":4}