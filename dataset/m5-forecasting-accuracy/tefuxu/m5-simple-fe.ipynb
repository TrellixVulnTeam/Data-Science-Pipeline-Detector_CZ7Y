{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# General imports\nimport numpy as np\nimport pandas as pd\nimport os, sys, gc, time, warnings, pickle, psutil, random\n\nfrom math import ceil\n\nfrom sklearn.preprocessing import LabelEncoder\n\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## メモリ使用量を確認するためのシンプルな「メモリプロファイラ」\ndef get_memory_usage():\n    return np.round(psutil.Process(os.getpid()).memory_info()[0]/2.**30, 2) \n        \ndef sizeof_fmt(num, suffix='B'):\n    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n        if abs(num) < 1024.0:\n            return \"%3.1f%s%s\" % (num, unit, suffix)\n        num /= 1024.0\n    return \"%.1f%s%s\" % (num, 'Yi', suffix)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## メモリ削減\n# :df pandas dataframe to reduce size             # type: pd.DataFrame()\n# :verbose                                        # type: bool\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                       df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## dtypesを失わないための連結による結合\ndef merge_by_concat(df1, df2, merge_on):\n    merged_gf = df1[merge_on]\n    merged_gf = merged_gf.merge(df2, on=merge_on, how='left')\n    new_columns = [col for col in list(merged_gf) if col not in merge_on]\n    df1 = pd.concat([df1, merged_gf[new_columns]], axis=1)\n    return df1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"########################### Vars\n#################################################################################\nTARGET = 'sales'         # Our main target\nEND_TRAIN = 1913         # Last day in train set\nMAIN_INDEX = ['id','d']  # We can identify item by these columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########################### Load Data\n#################################################################################\nprint('Load Main Data')\n\n# Here are reafing all our data \n# without any limitations and dtype modification\ntrain_df = pd.read_csv('../input/m5-forecasting-accuracy/sales_train_validation.csv')\nprices_df = pd.read_csv('../input/m5-forecasting-accuracy/sell_prices.csv')\ncalendar_df = pd.read_csv('../input/m5-forecasting-accuracy/calendar.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########################### グリッド作成\n#################################################################################\nprint('Create Grid')\n\n# 水平表現を変形できます \n# 縦方向の「ビュー」 \n# index は「id」、「item_id」、「dept_id」、「cat_id」、「store_id」、「state_id」 \n# ラベルは「d_」列です\n\nindex_columns = ['id','item_id','dept_id','cat_id','store_id','state_id']\ngrid_df = pd.melt(train_df, \n                  id_vars = index_columns, \n                  var_name = 'd', \n                  value_name = TARGET)\n\n# train_dfを見ると、行は多くありません \n# しかし、それぞれの日により多くのtrain dataを提供できます\nprint('Train rows:', len(train_df), len(grid_df))\n\n# 予測できるように\n# \"test set\"をグリッドに追加する必要があります\nadd_grid = pd.DataFrame()\nfor i in range(1,29):\n    temp_df = train_df[index_columns]\n    temp_df = temp_df.drop_duplicates()\n    temp_df['d'] = 'd_'+ str(END_TRAIN+i)\n    temp_df[TARGET] = np.nan\n    add_grid = pd.concat([add_grid,temp_df])\n\ngrid_df = pd.concat([grid_df,add_grid])\ngrid_df = grid_df.reset_index(drop=True)\n\n# 一時的なDFを削除する\ndel temp_df, add_grid\n\n# オリジナルのtrain_dfは必要ありません もう削除できます\ndel train_df\n\n# df = df構築を使用する必要はありません \n# 代わりにinplace = Trueを使用できます。 \n# 次のようにして\n# grid_df.reset_index（drop = True、inplace = True） \n\n# メモリ使用量を確認しましょう\nprint(\"{:>20}: {:>8}\".format('Original grid_df',sizeof_fmt(grid_df.memory_usage(index=True).sum())))\n\n# 一部のメモリを解放できます \n# 文字列をカテゴリに変換する \n# 結合には影響せず、貴重なデータを失うことはありません\nfor col in index_columns:\n    grid_df[col] = grid_df[col].astype('category')\n\n# メモリ使用量をもう一度確認してみましょう\nprint(\"{:>20}: {:>8}\".format('Reduced grid_df',sizeof_fmt(grid_df.memory_usage(index=True).sum())))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########################### 製品発売日\n#################################################################################\nprint('Release week')\n\n# 各train_dfアイテム行の先行ゼロ値は実際の0売上ではなく、\n# 店にアイテムがないことを意味します\n# このようなゼロを削除することで、一部のメモリを安全にすることができます\n\n# 価格は週ごとに設定されるので、 リリース週があまり正確ではありません\nrelease_df = prices_df.groupby(['store_id','item_id'])['wm_yr_wk'].agg(['min']).reset_index()\nrelease_df.columns = ['store_id','item_id','release']\n\n# これでrelease_dfを結合できます\ngrid_df = merge_by_concat(grid_df, release_df, ['store_id','item_id'])\ndel release_df\n\n# ＃grid_dfから「ゼロ」行をいくつか削除したい  \n# それを行うには、wm_yr_wk列が必要です \n# 部分的にcalendar_dfを結合してみましょう\ngrid_df = merge_by_concat(grid_df, calendar_df[['wm_yr_wk','d']], ['d'])\n                      \n# これで、いくつかの行をカットして安全なメモリにできます\ngrid_df = grid_df[grid_df['wm_yr_wk']>=grid_df['release']]\ngrid_df = grid_df.reset_index(drop=True)\n\n# メモリ使用量を確認しましょう\nprint(\"{:>20}: {:>8}\".format('Original grid_df',sizeof_fmt(grid_df.memory_usage(index=True).sum())))\n\n# 特徴量の1つとしてリリース週を維持する必要がありますか？ \n# 良いCVだけが答えを出すことができます。 \n# リリース値を縮小してみましょう。 \n# 最小変換はここでは役に立たない\n# int16→integer（-32768から32767）\n# やgrid_df ['release'].max（）→int16のような変換は。\n# しかし、必要な場合に備えて、変換するある方法があります。\ngrid_df['release'] = grid_df['release'] - grid_df['release'].min()\ngrid_df['release'] = grid_df['release'].astype(np.int16)\n\n# メモリ使用量をもう一度確認してみましょう\nprint(\"{:>20}: {:>8}\".format('Reduced grid_df',sizeof_fmt(grid_df.memory_usage(index=True).sum())))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########################### 保存 part 1\n#################################################################################\nprint('Save Part 1')\n\n# BASEグリッドの準備ができました \n# 今後の使用のため（モデルトレーニング）pickleファイルとして保存できます\ngrid_df.to_pickle('grid_part_1.pkl')\n\nprint('Size:', grid_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########################### 価格\n#################################################################################\nprint('Prices')\n\n# 基本的な集計を行うことができます\nprices_df['price_max'] = prices_df.groupby(['store_id','item_id'])['sell_price'].transform('max')\nprices_df['price_min'] = prices_df.groupby(['store_id','item_id'])['sell_price'].transform('min')\nprices_df['price_std'] = prices_df.groupby(['store_id','item_id'])['sell_price'].transform('std')\nprices_df['price_mean'] = prices_df.groupby(['store_id','item_id'])['sell_price'].transform('mean')\n\n# そして価格正規化を行います（最小/最大スケーリング）\nprices_df['price_norm'] = prices_df['sell_price']/prices_df['price_max']\n\n# 一部のアイテムはインフレに依存する可能性があります \n# いくつかのアイテムは非常に「安定」しています\nprices_df['price_nunique'] = prices_df.groupby(['store_id','item_id'])['sell_price'].transform('nunique')\nprices_df['item_nunique'] = prices_df.groupby(['store_id','sell_price'])['item_id'].transform('nunique')\n\n# 移動集計をしたい \n# 「枠」として月と年が欲しい\ncalendar_prices = calendar_df[['wm_yr_wk','month','year']]\ncalendar_prices = calendar_prices.drop_duplicates(subset=['wm_yr_wk'])\nprices_df = prices_df.merge(calendar_prices[['wm_yr_wk','month','year']], on=['wm_yr_wk'], how='left')\ndel calendar_prices\n\n# これで、価格に（ある種の）「勢い」を加えることができます \n# 週ごとにシフト \n# 月平均 年平均\nprices_df['price_momentum'] = prices_df['sell_price']/prices_df.groupby(['store_id','item_id'])['sell_price'].transform(lambda x: x.shift(1))\nprices_df['price_momentum_m'] = prices_df['sell_price']/prices_df.groupby(['store_id','item_id','month'])['sell_price'].transform('mean')\nprices_df['price_momentum_y'] = prices_df['sell_price']/prices_df.groupby(['store_id','item_id','year'])['sell_price'].transform('mean')\n\ndel prices_df['month'], prices_df['year']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########################### 価格の結合と保存 part 2\n#################################################################################\nprint('Merge prices and save part 2')\n\n# 価格の結合\noriginal_columns = list(grid_df)\ngrid_df = grid_df.merge(prices_df, on=['store_id','item_id','wm_yr_wk'], how='left')\nkeep_columns = [col for col in list(grid_df) if col not in original_columns]\ngrid_df = grid_df[MAIN_INDEX+keep_columns]\ngrid_df = reduce_mem_usage(grid_df)\n\n# 保存 part 2\ngrid_df.to_pickle('grid_part_2.pkl')\nprint('Size:', grid_df.shape)\n\n# prices_dfはもういらない\ndel prices_df\n\n# 新しい列を削除できます \n# または単にpart_1をロードする\ngrid_df = pd.read_pickle('grid_part_1.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########################### カレンダーの結合\n#################################################################################\ngrid_df = grid_df[MAIN_INDEX]\n\n# カレンダーを部分的に結合\nicols = ['date',\n         'd',\n         'event_name_1',\n         'event_type_1',\n         'event_name_2',\n         'event_type_2',\n         'snap_CA',\n         'snap_TX',\n         'snap_WI']\n\ngrid_df = grid_df.merge(calendar_df[icols], on=['d'], how='left')\n\n# データを縮小する \n# 'snap_'列はboolまたはint8に変換できる \nicols = ['event_name_1',\n         'event_type_1',\n         'event_name_2',\n         'event_type_2',\n         'snap_CA',\n         'snap_TX',\n         'snap_WI']\nfor col in icols:\n    grid_df[col] = grid_df[col].astype('category')\n\n# 日時に変換\ngrid_df['date'] = pd.to_datetime(grid_df['date'])\n\n# 日付からいくつかの特徴量を作る\ngrid_df['tm_d'] = grid_df['date'].dt.day.astype(np.int8)\ngrid_df['tm_w'] = grid_df['date'].dt.week.astype(np.int8)\ngrid_df['tm_m'] = grid_df['date'].dt.month.astype(np.int8)\ngrid_df['tm_y'] = grid_df['date'].dt.year\ngrid_df['tm_y'] = (grid_df['tm_y'] - grid_df['tm_y'].min()).astype(np.int8)\ngrid_df['tm_wm'] = grid_df['tm_d'].apply(lambda x: ceil(x/7)).astype(np.int8)\n\ngrid_df['tm_dw'] = grid_df['date'].dt.dayofweek.astype(np.int8)\ngrid_df['tm_w_end'] = (grid_df['tm_dw']>=5).astype(np.int8)\n\n# 日付の削除\ndel grid_df['date']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########################### 保存 part 3 (日付)\n#################################################################################\nprint('Save part 3')\n\n# 保存 part 3\ngrid_df.to_pickle('grid_part_3.pkl')\nprint('Size:', grid_df.shape)\n\n# calendar_dfはもういらない\ndel calendar_df\ndel grid_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########################### 追加のクリーニング\n#################################################################################\n\n## Part 1\n# 'd' → int\ngrid_df = pd.read_pickle('grid_part_1.pkl')\ngrid_df['d'] = grid_df['d'].apply(lambda x: x[2:]).astype(np.int16)\n\n# 'wm_yr_wk'の削除\n# テスト値がtrainにないため\ndel grid_df['wm_yr_wk']\ngrid_df.to_pickle('grid_part_1.pkl')\n\ndel grid_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########################### 概要\n#################################################################################\n\n# 今、私たちは3つの特徴量セットを持っています\ngrid_df = pd.concat([pd.read_pickle('grid_part_1.pkl'),\n                     pd.read_pickle('grid_part_2.pkl').iloc[:,2:],\n                     pd.read_pickle('grid_part_3.pkl').iloc[:,2:]],\n                     axis=1)\n                     \n# メモリ使用量をもう一度\nprint(\"{:>20}: {:>8}\".format('Full Grid',sizeof_fmt(grid_df.memory_usage(index=True).sum())))\nprint('Size:', grid_df.shape)\n\n# 2.5GiB + はまだ大きすぎて、（Kaggleでは）モデルをトレーニングできません \n# lag特徴量はまだありません \n# しかし、state_idまたはshop_idでトレーニングできるとしたらどうでしょう？\nstate_id = 'CA'\ngrid_df = grid_df[grid_df['state_id']==state_id]\nprint(\"{:>20}: {:>8}\".format('Full Grid',sizeof_fmt(grid_df.memory_usage(index=True).sum())))\n#           Full Grid:   1.2GiB\n\nstore_id = 'CA_1'\ngrid_df = grid_df[grid_df['store_id']==store_id]\nprint(\"{:>20}: {:>8}\".format('Full Grid',sizeof_fmt(grid_df.memory_usage(index=True).sum())))\n#           Full Grid: 321.2MiB\n\n# もう十分だと思います \n# 他のNotebookではlag特徴量について話します\n# Thank you.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########################### 特徴量の最終リスト\n#################################################################################\ngrid_df.info()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}