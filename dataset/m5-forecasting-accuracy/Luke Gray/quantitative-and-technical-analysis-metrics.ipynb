{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this notebook, we will be using quantitative analysis and technical analysis techniques often used in finance to visualize trend strength and volatility. Though, in this notebook, I am simply plotting the techniques, I hope this will inspire some creative feature engineering.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#data manipulation packages\nimport pandas as pd\nimport numpy as np\nimport scipy\nimport re\n\n#visualization tools\n%matplotlib inline\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom itertools import cycle\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\npd.set_option('display.max_rows', 300)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales = pd.read_csv('/kaggle/input/m5-forecasting-accuracy/sales_train_validation.csv')\ncal = pd.read_csv('/kaggle/input/m5-forecasting-accuracy/calendar.csv')\nprices = pd.read_csv('/kaggle/input/m5-forecasting-accuracy/sell_prices.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For the sake of simplicity, we will choose a random item to demonstrate how the different quantitative and TA graphs play out.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"item = 'FOODS_3_090_CA_3_validation'\nd_cols = [col for col in sales.columns if 'd_' in col]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2-STD Bollinger Bands","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"One way to detect outliers, or unexpected volatility, is through the use of bollinger bands - bands two standard deviations above and below the item's window mean. Those that are outside the bands will be deamed outliers.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def plot_bollinger_bands(item):\n    '''bollinger bands around the 50-day rolling mean items sold per day for specified item.\n    Args:\n        item(str): id of the item we are wanting to plot.\n    \n    Returns:\n        line plot of item sale history as well as 50-day rolling standard deviation of the time series (2):\n    '''\n    item_df = sales.loc[sales['id'] == item][d_cols].T\n    item_df = item_df.rename(columns={sales.index[sales['id']==item].to_list()[0]:item}) # Name it correctly\n    item_df = item_df.reset_index().rename(columns={'index': 'd'}) # make the index \"d\"\n    item_df['mean'] = item_df[item].rolling(window=50).mean()\n    item_df['std'] = item_df[item].rolling(window=50).std()\n    item_df['upper_band'] = item_df['mean'] + (item_df['std'] * 2)\n    item_df['lower_band'] = item_df['mean'] - (item_df['std'] * 2)\n    \n    item_df[[item, 'mean', 'upper_band', 'lower_band']].plot(figsize=(15,8))\n    plt.grid(linestyle='-', linewidth='1')\n    plt.title('30 Day Bollinger Band for {}'.format(item))\n    plt.ylabel('Number of Times the Item is Sold')\n    plt.xlabel('Day')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_bollinger_bands(item)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see tha there are many instances in which the actual sales is outside of the bands.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Relative Rotation","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"To get really familiar with the item's strength - relative to it's category - , we can plot a Relative Rotation Graph. This locates the an item's relative strength and momentum from one period to another, and is compared to those properties of the benchmark (item's category aggregated stats). The direction of the property is important; each quadrant illustrates if the item's selling history is leading, lagging, weakening, or improving. The ideal formation is that the item's relative strength and momentum are both above 100, and is heading in the direction of the leading quadrant. The graph created below should help clarify.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def plot_RRG(item_cat, window):\n    '''Relative Rotation Graph (RRG) of a sample of items and its categories. RRGs are made \n    of an item's/category's relative strength and momentum.\n    \n    Args:\n        item(str): id of the item we are wanting to plot.\n        window(int): window to to roll over.\n    \n    Returns:\n        RRG of item nad it's category. This RRG takes advantage of a simple moving average.\n    '''\n    colors = cycle(plt.rcParams['axes.prop_cycle'].by_key()['color'])\n    \n    category = sales.loc[sales['id']==item_cat]['cat_id']\n    benchmark = sales.loc[sales['cat_id'].isin(category)][d_cols].mean(axis=0).T\n    benchmark = pd.DataFrame({'mean_values':benchmark.values})\n    \n    \n    # Get the difference in price from previous step\n    benchmark_delta = benchmark.diff().dropna()\n    # Get rid of the first row, which is NaN since it did not have a previous \n    # row to calculate the differences  \n    benchmark_delta = benchmark_delta[1:]\n    # Make the positive gains (up) and negative gains (down) Series\n    b_up, b_down = benchmark_delta.copy(), benchmark_delta.copy()\n    b_up[b_up < 0] = 0\n    b_down[b_down > 0] = 0\n    \n    #Calculate SMA\n    b_roll_up2 = b_up.rolling(window).mean()\n    b_roll_down2 = b_down.abs().rolling(window).mean()  \n\n    b_RS2 = b_roll_up2 / b_roll_down2\n#     b_RSI2 = 100.0 - (100.0 / (1.0 + b_RS2))\n    benchmark['jdk_rs'] = 100 + ((b_RS2 - b_RS2.mean()) / b_RS2.std() + 1)\n    \n    b_mom = benchmark.iloc[:,0].diff(periods = window)\n    benchmark['jdk_mom'] = 100 + ((b_mom - b_mom.mean()) / b_mom.std() + 1)\n    \n    \n    #Repeat steps for a sample of items in that category\n#     series_sample = sales.loc[sales['cat_id'].isin(category)]['id'].sample(sample)#grab sample of items\n    \n    series = sales.loc[sales['id'] == item][d_cols].T\n\n    # Get the difference in price from previous step\n    item_delta = series.diff().dropna()\n\n    item_delta = item_delta[1:] \n\n    # Make the positive gains (up) and negative gains (down) Series\n    i_up, i_down = item_delta.copy(), item_delta.copy()\n    i_up[i_up < 0] = 0\n    i_down[i_down > 0] = 0\n\n    # Calculate the EWMA\n#     roll_up1 = up.ewm(span=window).mean()\n#     roll_down1 = down.abs().ewm(span=window).mean()\n\n#     # Calculate the RSI based on EWMA\n#     RS1 = roll_up1 / roll_down1\n#     RSI1 = 100.0 - (100.0 / (1.0 + RS1))\n\n    # Calculate the SMA\n    i_roll_up2 = i_up.rolling(window).mean()\n    i_roll_down2 = i_down.abs().rolling(window).mean()\n\n    # Calculate the RSI based on SMA\n    i_RS2 = i_roll_up2 / i_roll_down2\n#     i_RSI2 = 100.0 - (100.0 / (1.0 + i_RS2))\n    series['jdk_rs'] = 100 + ((i_RS2 - i_RS2.mean()) / i_RS2.std() + 1)\n\n    i_mom = series.iloc[:,0].diff(periods = window)\n\n    series['jdk_mom'] = 100 + ((i_mom - i_mom.mean()) / i_mom.std() + 1)\n    \n    from scipy.interpolate import interp1d\n    from matplotlib.patches import ConnectionPatch, FancyArrowPatch\n    \n    ix = series.iloc[::220]['jdk_rs'].values\n    iy = series.iloc[::220][\"jdk_mom\"].values\n    \n    bx = benchmark.iloc[::150, benchmark.columns.get_loc(\"jdk_rs\")].values\n    by = benchmark.iloc[::150, benchmark.columns.get_loc(\"jdk_mom\")].values\n    \n    improving_lagging = np.linspace(94,       \n                     100, \n                     1000)\n    leading_weaking = np.linspace(100,       \n                     106, \n                     1000)\n\n    \n    b_origin=(bx[-2],by[-2])\n    bxy =(bx[-1],by[-1])\n    \n    i_origin=(ix[-2],iy[-2])\n    ixy =(ix[-1],iy[-1])\n    \n\n    #plotting RRG in steps of 150 days\n    fig, axes = plt.subplots(1,1, figsize=(25,10), dpi=100)\n    plt.scatter(bx,by, marker='o', label='Benchmark', color='red')\n    plt.scatter(ix,iy, marker='o', label = 'Item', color=next(colors))\n    axes.set_axisbelow(True)\n    axes.grid(linestyle='-', linewidth='2.0')\n    plt.xlim(95,105)\n    plt.ylim(95,105)\n    plt.axhline(100, linewidth=4, color='b')  #horizontal line\n    plt.axvline(100, linewidth=4, color='b')\n    plt.gca().fill_between(improving_lagging, \n                           100, \n                           106.5, \n                           alpha=0.1, color='b', zorder=3, label='Improving')\n    plt.gca().fill_between(leading_weaking, \n                           100, \n                           106.5, \n                           alpha=0.1, color='g', zorder=4, label='Leading')\n    plt.gca().fill_between(leading_weaking, \n                           94, \n                           100, \n                           alpha=0.1, color='y', zorder=5, label='Weakening')\n    plt.gca().fill_between(improving_lagging, \n                           94, \n                           100, \n                           alpha=0.1, color='r', zorder=6, label='Lagging')\n    plt.quiver(b_origin[0], b_origin[1], bxy[0]-b_origin[0], bxy[1]-b_origin[1],\n               scale_units='xy', angles='xy',alpha=.9, scale=1, pivot='tip', width=.0025, headlength = 4.5, headwidth=3, color='maroon')\n    plt.quiver(i_origin[0], i_origin[1], ixy[0]-i_origin[0], ixy[1]-i_origin[1],\n               scale_units='xy', angles='xy',alpha=.9, scale=1, pivot='tip', width=.0025, headlength = 4.5, headwidth=3, color='royalblue')\n    plt.xlabel('JDK Relative Strength', fontsize=14)\n    plt.ylabel('JDK Momentum', fontsize=14)\n    plt.legend(fontsize='xx-large')\n    plt.title('Relative Rotation Graph for Item Category', fontsize=25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_RRG('FOODS_3_090_CA_3_validation', 350)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the above example, we can see that this particular item start out in the middle of the graph, but gradually moves to the leading quadrant, which signals progressing sales momentum and strength. The item's benchmark (average of all food items) is also leading quandrant. Since the benchmark is further from the middle, it looks the average food item is performing better than this particular item.\n\nThe vectors represent the direction the item and benchmark are heading compared to the last period the RRG was calculated. The item is heading further in the leading quadrant (which is promising) while the benchmark is regressing closer to the middle (not a good sign).","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Average True Range","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Below we will add an Average True Range (ATR) plot. This feature measures the trendiness of the data; the higher the ATR value, the more the item sales are trending in either direction.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#Volatility measure\ndef wwma(values, window):\n    \"\"\"\n     J. Welles Wilder's EMA \n    \"\"\"\n    return values.ewm(alpha=1/window, adjust=False).mean()\n\ndef ATR(item, window):\n    \n    item_df = sales.loc[sales['id'] == item][d_cols].T\n    item_wwma = item_df.ewm(alpha=1/window, adjust=False).mean() #Wilder's EMA\n        \n    high = item_df.rolling(window).max()\n    low = item_df.rolling(window).min()\n    close = item_df.rolling(window).mean()\n    item_df['tr0'] = abs(high - low)\n    item_df['tr1'] = abs(high - close.shift())\n    item_df['tr2'] = abs(low - close.shift())\n    tr = item_df[['tr0', 'tr1', 'tr2']].max(axis=1)\n    atr = wwma(tr, window)\n    return atr\n\n\n\nitem = 'HOBBIES_1_004_CA_1_validation'\n\nitem_atr = ATR(item, 60)\n\nfig, axes = plt.subplots(1,1, figsize=(15,8), dpi=100)\nitem_atr.plot()\naxes.grid(linestyle='-', linewidth='1.0')\nplt.xlabel('Day')\nplt.ylabel('True Range')\nplt.title('%s Average True Range (ATR)'% item)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that near d_1000 that the item sales begins to trend before tailing off at the end. This matches the upwards trend we observe when we just simply plot item sales over time or category sales (all items in the category averaged) over time.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Relative Strength Index","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Another metric we can plot out is the item's relative strength, which shows how well the item is selling within its window. Relative strength is the percentage of days that experienced higher selling than the previous day to the percentage of that experience lower selling than the previous day.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def plot_RSI(item, window, category=False):\n    '''Relative strength of specified item compared to the average relative strength of all items in its category.\n    \n    Args:\n        item(str): id of the item we are wanting to plot.\n        window(int): number of days we want to average over.\n        category(bool): whether or not we are finding the RS of an item or a category.\n    \n    Returns:\n        Relative strength of item or category.\n    '''\n    if category == True:\n        category = sales.loc[sales['id']==item]['cat_id']\n        series = sales.loc[sales['cat_id'].isin(category)][d_cols].mean(axis=0).T\n    else:\n        series = sales.loc[sales['id'] == item][d_cols].T\n    \n    # Get the difference in price from previous step\n    delta = series.diff().dropna()\n    # Get rid of the first row, which is NaN since it did not have a previous \n    # row to calculate the differences\n    delta = delta[1:] \n\n    # Make the positive gains (up) and negative gains (down) Series\n    up, down = delta.copy(), delta.copy()\n    up[up < 0] = 0\n    down[down > 0] = 0\n\n    # Calculate the EWMA\n    roll_up1 = up.ewm(span=window).mean()\n    roll_down1 = down.abs().ewm(span=window).mean()\n\n    # Calculate the RSI based on EWMA\n    RS1 = roll_up1 / roll_down1\n    RSI1 = 100.0 - (100.0 / (1.0 + RS1))\n\n    # Calculate the SMA\n    roll_up2 = up.rolling(window).mean()\n    roll_down2 = down.abs().rolling(window).mean()\n\n    # Calculate the RSI based on SMA\n    RS2 = roll_up2 / roll_down2\n    RSI2 = 100.0 - (100.0 / (1.0 + RS2))\n\n    # Compare graphically\n    fig, axes = plt.subplots(1, 1, figsize=(15, 6), dpi=100)\n    RSI1.plot(ax=axes, label='EWMA of Item Sold', alpha=0.8).set_ylabel('RS Index', fontsize=14)\n    RSI2.plot(ax=axes, label='SMA of Item Sold', alpha=0.8).set_ylabel('RSI Index', fontsize=14)\n    axes.set_title('Relative Strength (using EWMA and SMA) of Item', fontsize=16);\n    axes.grid(linestyle='-', linewidth='1')\n    axes.legend(['RSI via EWMA', 'RSI via SMA'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_RSI(item, 20, category=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Based on the graph, we can see that both the simple moving average and the exponentially weighted moving avg hover around the 50 mark - give or take 10. This suggest that, throughout the time period, the item's sales experience consistent fluctuations of up days (# of the item sales is higher than the day before) and down days (# of the item sales is lower than the day before).","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Annualized Volatility","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Annualized volatility - a popular metric used in finance that presents item sales volatility in annualized terms; we multiply our daily standard deviation by sq root of 365 days.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def annualized_volatility(item, window):\n    \"Return the annualized standard deviation of daily log returns of item.\"\n    \n    item_df = sales.loc[sales['id'] == item][d_cols].T\n    ann_vol = item_df.diff().rolling(window).std()*(365**0.5)\n    return ann_vol\n\nitem_ann = annualized_volatility(item, 30)\n\nfig, axes = plt.subplots(1,1, figsize=(15,8), dpi=100)\nitem_ann.plot(ax=axes)\naxes.grid(linestyle='-', linewidth='1.0')\nplt.xlabel('Day')\nplt.ylabel('Volatility')\nplt.title('%s Annualized Volatility'% item)\nplt.legend(item)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Based on the graph above, we can see that the annualized volatility increases over time as the item experiences more and more sales.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Semivariance","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Lastly, we will consider an item's semivariance. This is the item's downside sales volatililty. It is a risk measurement, so it isolates the variance of sales below the item's sales mean.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"series = sales.loc[sales['id']==item][d_cols].T\nseries = series.rename(columns={sales.index[sales['id']==item].to_list()[0]:item})\nseries['mean'] = series[item].rolling(30).mean().fillna(series[item].mean())\nseries.fillna(method='ffill', inplace=True)\nseries.loc[series[item]<series['mean'], 'semivariance'] = series[item].rolling(30).var()\nseries.semivariance.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def semivariance(item, w1, w2):\n    '''\n    Semivariance records the variance of sales that fall below the sales average of a period of time.\n    '''\n    \n    series = sales.loc[sales['id']==item][d_cols].T\n    series = series.rename(columns={sales.index[sales['id']==item].to_list()[0]:item})\n    series['mean'] = series[item].rolling(w1).mean().fillna(series[item].mean())\n    series.loc[series[item]<series['mean'], 'semivariance'] = series[item].rolling(w2).var()\n    series.fillna(method='ffill', inplace=True)\n    return series['semivariance']\n\nitem_semi = semivariance(item, 30, 30)\n\nfig, axes = plt.subplots(1,1, figsize=(15,8), dpi=100)\nitem_semi.plot(ax=axes)\naxes.grid(linestyle='-', linewidth='1.0')\nplt.xlabel('Day')\nplt.ylabel('Volatility')\nplt.title('%s Annualized Volatility'% item)\nplt.legend(item)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I hope these metrics give you some idea of how to incororate strength and volatility in your feature engineering.\n\nOther quantitative analysis ideas could be item-to-benchmark beta, triple exp. moving average (TEMA), relative volatility (comparing volatility of item sales over two different moving avg windows), or even entropy.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}