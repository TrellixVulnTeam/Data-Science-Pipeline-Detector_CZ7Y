{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nimport seaborn as sns\nimport gc\nimport lightgbm as lgb\nimport time\n# import datetime\n# import xgboost as xgb\n# import time\n# import itertools\n# from sklearn.linear_model import LinearRegression\n# from sklearn.model_selection import train_test_split\n# from sklearn.preprocessing import OneHotEncoder\n# from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import r2_score\n\n%matplotlib inline\nsns.set()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# 데이터 불러오기\nINPUT_DIR = '/kaggle/input/m5-forecasting-accuracy'\n\ncalendar_df = pd.read_csv(f\"{INPUT_DIR}/calendar.csv\")\nsell_prices_df = pd.read_csv(f\"{INPUT_DIR}/sell_prices.csv\")\nsales_train_validation_df = pd.read_csv(f\"{INPUT_DIR}/sales_train_validation.csv\")\nsample_submission_df = pd.read_csv(f\"{INPUT_DIR}/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"calendar_df.head() # 제품 판매 날짜에 대한 정보\n# date: 날짜\n# wm_yr_wk:\n# weekday: 요일 / # wday: 요일을 숫자로\n# month: 월 / # year: 연도\n# d: unique value \n# event_name_1, 2: / # event_type_1, 2:\n# snap_CA: / # snap_TX: / # snap_WI: ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"calendar_df['event_name_1'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"calendar_df['event_type_1'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"calendar_df['event_name_2'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"calendar_df['event_type_2'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sell_prices_df.head()  # 상점(store_id) 및 날짜(wm_yr_wk) 당 판매 된 제품(item_id) 가격(sell_price)에 대한 정보를 포함.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train_validation_df.head()  # 제품(item_id) 및 상점(store_id) 별 과거 일일 단위 판매 데이터를 포함\n# id = {item_id}_{store_id} 로 구성됨. ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission_df.head()  # 제출 파일 예시","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calendar data type cast -> Memory Usage Reduction\n# Calendar 데이터 타입 변경 -> 메모리 사용 감소\ncalendar_df[[\"month\", \"snap_CA\", \"snap_TX\", \"snap_WI\", \"wday\"]] = calendar_df[[\"month\", \"snap_CA\", \"snap_TX\", \"snap_WI\", \"wday\"]].astype(\"int8\")\ncalendar_df[[\"wm_yr_wk\", \"year\"]] = calendar_df[[\"wm_yr_wk\", \"year\"]].astype(\"int16\") \ncalendar_df[\"date\"] = calendar_df[\"date\"].astype(\"datetime64\")\n\nnan_features = ['event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']\nfor feature in nan_features:\n    calendar_df[feature].fillna('unknown', inplace = True)\n\ncalendar_df[[\"weekday\", \"event_name_1\", \"event_type_1\", \"event_name_2\", \"event_type_2\"]] = calendar_df[[\"weekday\", \"event_name_1\", \"event_type_1\", \"event_name_2\", \"event_type_2\"]] .astype(\"category\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sales Training dataset cast -> Memory Usage Reduction\nsales_train_validation_df.loc[:, \"d_1\":] = sales_train_validation_df.loc[:, \"d_1\":].astype(\"int16\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make ID column to sell_price dataframe\n# 다른 df 에서 쓰고 있는 id를 만들어 줌. \nsell_prices_df.loc[:, \"id\"] = sell_prices_df.loc[:, \"item_id\"] + \"_\" + sell_prices_df.loc[:, \"store_id\"] + \"_validation\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sell_prices_df = pd.concat([sell_prices_df, sell_prices_df[\"item_id\"].str.split(\"_\", expand=True)], axis=1)  # cat_id, dept_id, 뭔가를 생성함.\n# column 명 바꿈\nsell_prices_df = sell_prices_df.rename(columns={0:\"cat_id\", 1:\"dept_id\"})\n# type 바꿈 \nsell_prices_df[[\"store_id\", \"item_id\", \"cat_id\", \"dept_id\"]] = sell_prices_df[[\"store_id\",\"item_id\", \"cat_id\", \"dept_id\"]].astype(\"category\")\n# 필요 없는 열 삭제\nsell_prices_df = sell_prices_df.drop(columns=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sell_prices_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 데이터 전처리","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# 세개의 데이터 셋을 결합한다. \n# 예측 모델에 적용하기 쉽게하기 위해 옆으로 넓은 데이터셋에서 아래로 긴 데이터 셋을 만든다.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_dataframe():\n    # Wide format dataset \n    df_wide_train = sales_train_validation_df.drop(columns=[\"item_id\", \"dept_id\", \"cat_id\", \"state_id\",\"store_id\", \"id\"]).T\n    df_wide_train.index = calendar_df[\"date\"][:1913]\n    df_wide_train.columns = sales_train_validation_df[\"id\"]\n    \n    # Making test label dataset\n    df_wide_test = pd.DataFrame(np.zeros(shape=(56, len(df_wide_train.columns))), index=calendar_df.date[1913:], columns=df_wide_train.columns)\n    df_wide = pd.concat([df_wide_train, df_wide_test])\n\n    # Convert wide format to long format\n    df_long = df_wide.stack().reset_index(1)\n    df_long.columns = [\"id\", \"value\"]\n\n    del df_wide_train, df_wide_test, df_wide\n    gc.collect()\n    \n    df = pd.merge(pd.merge(df_long.reset_index(), calendar_df, on=\"date\"), sell_prices_df, on=[\"id\", \"wm_yr_wk\"])\n    df = df.drop(columns=[\"d\"])\n    #     df[[\"cat_id\", \"store_id\", \"item_id\", \"id\", \"dept_id\"]] = df[[\"cat_id\"\", store_id\", \"item_id\", \"id\", \"dept_id\"]].astype(\"category\")\n    df[\"sell_price\"] = df[\"sell_price\"].astype(\"float16\")   \n    df[\"value\"] = df[\"value\"].astype(\"int32\")\n    df[\"state_id\"] = df[\"store_id\"].str[:2].astype(\"category\")\n\n\n    del df_long\n    gc.collect()\n\n    return df\n\ndf = make_dataframe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_date_feature(df):\n    df[\"year\"] = df[\"date\"].dt.year.astype(\"int16\")\n    df[\"month\"] = df[\"date\"].dt.month.astype(\"int8\")\n    df[\"week\"] = df[\"date\"].dt.week.astype(\"int8\")\n    df[\"day\"] = df[\"date\"].dt.day.astype(\"int8\")\n    df[\"quarter\"]  = df[\"date\"].dt.quarter.astype(\"int8\")\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = add_date_feature(df)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data Visualization\n# Total Item Sold Transition\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp_series = df.groupby([\"cat_id\", \"date\"])[\"value\"].sum()\ntemp_series","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 4))\nplt.plot(temp_series[temp_series.index.get_level_values(\"cat_id\") == \"FOODS\"].index.get_level_values(\"date\"), temp_series[temp_series.index.get_level_values(\"cat_id\") == \"FOODS\"].values, label=\"FOODS\")\nplt.plot(temp_series[temp_series.index.get_level_values(\"cat_id\") == \"HOUSEHOLD\"].index.get_level_values(\"date\"), temp_series[temp_series.index.get_level_values(\"cat_id\") == \"HOUSEHOLD\"].values, label=\"HOUSEHOLD\")\nplt.plot(temp_series[temp_series.index.get_level_values(\"cat_id\") == \"HOBBIES\"].index.get_level_values(\"date\"), temp_series[temp_series.index.get_level_values(\"cat_id\") == \"HOBBIES\"].values, label=\"HOBBIES\")\nplt.xlabel(\"Year\")\nplt.ylabel(\"# of sold items\")\nplt.title(\"Total Item Sold Transition of each Category\")\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Point of the graph\n\nFOODS is the most sold item category of these three categories.\nHOUSEHOLD is the 2nd one, and HOBBIES are the least sold one.\nFOODS category appearently has some periodical feature.\nDuring one year, it seems more items are sold in summer than in winter, however, we have to verify this.\nAs for more short time interval, it seems the trend has monthly or weekly features. (Let's take a look below)\n\nHOUSEHOLD category items sold is gradually increasing from 2011.\nHowever, it may be because some items are not in the store in 2011.\nSo we have to take the total item in the store into account. Periodical Features are not so clear in this category compared to FOODS.\n\nIn HOBBIES category, periodical features are less appearent like HOUSEHOLD category.\n\nIn some point (around the end of year), all categories don't have any sold. So I think we have to consider whether we take these days into account when training models.\n\nSo let's take a look at the latest year, 2015!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"temp_series = temp_series.loc[temp_series.index.get_level_values(\"date\") >= \"2015-01-01\"]\nplt.figure(figsize=(12, 4))\nplt.plot(temp_series[temp_series.index.get_level_values(\"cat_id\") == \"FOODS\"].index.get_level_values(\"date\"), temp_series[temp_series.index.get_level_values(\"cat_id\") == \"FOODS\"].values, label=\"FOODS\")\nplt.plot(temp_series[temp_series.index.get_level_values(\"cat_id\") == \"HOUSEHOLD\"].index.get_level_values(\"date\"), temp_series[temp_series.index.get_level_values(\"cat_id\") == \"HOUSEHOLD\"].values, label=\"HOUSEHOLD\")\nplt.plot(temp_series[temp_series.index.get_level_values(\"cat_id\") == \"HOBBIES\"].index.get_level_values(\"date\"), temp_series[temp_series.index.get_level_values(\"cat_id\") == \"HOBBIES\"].values, label=\"HOBBIES\")\nplt.xlabel(\"Year-Month\")\nplt.ylabel(\"# of sold items\")\nplt.title(\"Total Item Sold Transition of each Category from 2015\")\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}