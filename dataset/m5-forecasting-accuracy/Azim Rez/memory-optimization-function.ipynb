{"cells":[{"metadata":{},"cell_type":"markdown","source":"Thank you to @[ragnar123](https://www.kaggle.com/ragnar123)","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport os\nimport re\nimport numpy as np\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nThe dataset used for this tutorial is **df_sales_train_validation** from M5 competition.\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf_sales_train_validation = pd.read_csv(r'../input/m5-forecasting-accuracy/sales_train_validation.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sales_train_validation.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"One of the challenges working with pandas dataframe is dimensions of the frames. Generally there are millions of records. Dataframes containing Time Series data are usually huge. Although some libraries or techniques has come to help the situation, still there is a lot to be done. Pandas.melt function is one of them in order to reduce the horizontal size of the frames and make it vertically.  This helps for better processing but it is not enough. \nAnother technique is reducing the size of dataframes. \n\nMost of the times the data type set for columns are initially set to the maximum size. Considering the number of columns with the same conditions makes the situation worse. For example in M5 dataset, the sales_train_validation.csv  conveys the amount of sold items in 1913 days. Simply the number of sold items per day would not be high. Here, the following code returns the maximum amount over all 1913 days.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = df_sales_train_validation.filter(regex='d_').columns\nmax = 0\nfor c in cols:\n    if df_sales_train_validation[c].max() > max:\n        max = df_sales_train_validation[c].max()\nprint('The maximum value for columns d_1 to d_1913 is: ', max)        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"So, the maximum amount is 763! The interesting point is that all columns are set with int64 data type. For more information, int64 is defined to save numbers with almost 19 digits. However, in our case the maximum target is a 3 digits number which could be processed with int16 as well; so let’s reduce the size of all of columns to int16. The following code helps to do so easily. \n\nThe point regarding this function is that it could be used for any dataframe and you will not have to care about the name of target columns or whether its data types are enumerated as integer or not. \n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def ReduceSize(df_,  fl = 1):\n    intValues = ['int_', 'intc', 'intp', 'int8', 'int16', 'int32', 'int64', 'uint8', 'uint16', 'uint32', 'uint64']\n    floatValues = ['float_', 'float16', 'float32', 'float64']\n    minn, maxx = 0, 0 \n    stype = ''\n    for c in df_.columns:\n        try:\n            if df_[c].dtypes == 'object':\n                df_[c] = df_[c].astype('int64')\n                print('Successful conversion Object to Integer for COlumn: ', c)\n        except:\n            print('Not Possible Casting Object to INT64 for column: ', c)\n        stype = df_[c].dtypes\n        #Cast to INT\n        if stype in intValues:\n            minn , maxx = 1, -1\n            maxx = df_[c].max()\n            minn = df_[c].min()\n            if (minn >= -128) &  (maxx <= 128):\n                df_[c] = df_[c].astype('int8')                   \n            else:\n                if (minn >= -32767) &  (maxx <= 32767):\n                    df_[c] = df_[c].astype('int16')\n                else:\n                    if (minn >= -2147483647) &  (maxx <= 2147483647):\n                        df_[c] = df_[c].astype('int32')\n                    else:\n                        df_[c] = df_[c].astype('int64')\n            #Cast to UINT\n            if (fl == 2):\n                if (minn >= 0) &  (maxx <= 255):\n                    df_[c] = df_[c].astype('uint8')                   \n                else:\n                    if (minn >= 0) &  (maxx <= 65535):\n                        df_[c] = df_[c].astype('uint16')                   \n                    else:\n                        if (minn >= 0) &  (maxx <= 4294967295):\n                            df_[c] = df_[c].astype('uint32')                   \n                        else:\n                            if (minn >= 0) &  (maxx <= 18446744073709551615):\n                                df_[c] = df_[c].astype('uint64')                   \n        \n        if stype in floatValues:\n            try:\n                df_[c] = df_[c].astype('float16')\n            except:\n                try:\n                    df_[c] = df_[c].astype('float32')\n                except:\n                    df_[c] = df_[c].astype('float64')            \n        print(c)\n    \n    return df_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before we do any operation on our data let's get some info about the dataset. The function ****memory_usage**** shows how much memory is occupied by the dataset. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sales_train_validation.memory_usage(index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nThis function gives information based on columns, therefor if we would to see the whole volume occupied, a SUM() is needed as follow:\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nnp.sum(df_sales_train_validation.memory_usage(index=False))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ReduceSize(df_sales_train_validation)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The data originally is not big but after loading, joining as well as other operations then become huge and a big size RAM will be needed\n\n\n![](https://gdpr.report/wp-content/uploads/2019/05/graph-3078539_1280-e1557991579520-635x360.png)\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"\nNow let's see the memory used after **OPTIMIZATION**:\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nnp.sum(df_sales_train_validation.memory_usage(index=False))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nThe size before omptimization is 468082480 and after running function and getting optimized it become 98604660. With some simple calculations we will see that **the size of the data is decreased for almost 80 percent**.\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"![](https://fmad.io/images/blog/20160128_zip.png)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"There are **TWO arguments** for this function. The **first** one is a Dataframe, and the **second** is a number that could be 1 or 2. Normally it would be set with 1 as default value but if you would like to include **Unsigned Integer** (“uint8”, “uint16”, “uint32”, or “uint64”) as your possible datatypes the second arument must set with 2.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# **THIS FUNCTION COULD BE USED FOR ANY DATAFRAME FROM ANY COMPETIOTION OR CHALLENGE!** \n\n#  So keep it and USE it ...","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"I appreciate try the function with your existing dataset. In case you face error or inefficiency please let me know so as to improve it. \n","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}