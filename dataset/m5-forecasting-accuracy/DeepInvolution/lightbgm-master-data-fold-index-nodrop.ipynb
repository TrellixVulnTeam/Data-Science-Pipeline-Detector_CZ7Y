{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from tqdm.notebook import tqdm_notebook as tqdm\nfrom typing import Union\nimport lightgbm as lgb\nimport pandas as pd\nimport numpy as np\nimport datetime\nimport feather\nimport random\nimport time\nimport os\nimport gc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#! ls /kaggle/input/m5-forecasting-accuracy","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n\nSEED = 1414\nDATA_DIR = '/kaggle/input'    \nseed_everything(SEED)\nFOLD = 2\nEPOCHS = 200","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class WRMSSEEvaluator(object):\n\n    def __init__(self, train_df: pd.DataFrame, valid_df: pd.DataFrame, calendar: pd.DataFrame, prices: pd.DataFrame):\n        train_y = train_df.loc[:, train_df.columns.str.startswith('d_')]\n        train_target_columns = train_y.columns.tolist()\n        weight_columns = train_y.iloc[:, -28:].columns.tolist()\n\n        train_df['all_id'] = 0  # for lv1 aggregation\n\n        id_columns = train_df.loc[:, ~train_df.columns.str.startswith('d_')].columns.tolist()\n        valid_target_columns = valid_df.loc[:, valid_df.columns.str.startswith('d_')].columns.tolist()\n\n        if not all([c in valid_df.columns for c in id_columns]):\n            valid_df = pd.concat([train_df[id_columns], valid_df], axis=1, sort=False)\n\n        self.train_df = train_df\n        self.valid_df = valid_df\n        self.calendar = calendar\n        self.prices = prices\n\n        self.weight_columns = weight_columns\n        self.id_columns = id_columns\n        self.valid_target_columns = valid_target_columns\n\n        weight_df = self.get_weight_df()\n\n        self.group_ids = (\n            'all_id',\n            'state_id',\n            'store_id',\n            'cat_id',\n            'dept_id',\n            ['state_id', 'cat_id'],\n            ['state_id', 'dept_id'],\n            ['store_id', 'cat_id'],\n            ['store_id', 'dept_id'],\n            'item_id',\n            ['item_id', 'state_id'],\n            ['item_id', 'store_id']\n        )\n\n        for i, group_id in enumerate(tqdm(self.group_ids)):\n            setattr(self, f'lv{i + 1}_train_df', train_df.groupby(group_id)[train_target_columns].sum())\n            setattr(self, f'lv{i + 1}_valid_df', valid_df.groupby(group_id)[valid_target_columns].sum())\n\n            lv_weight = weight_df.groupby(group_id)[weight_columns].sum().sum(axis=1)\n            setattr(self, f'lv{i + 1}_weight', lv_weight / lv_weight.sum())\n\n    def get_weight_df(self) -> pd.DataFrame:\n        day_to_week = self.calendar.set_index('d')['wm_yr_wk'].to_dict()\n        weight_df = self.train_df[['item_id', 'store_id'] + self.weight_columns].set_index(['item_id', 'store_id'])\n        weight_df = weight_df.stack().reset_index().rename(columns={'level_2': 'd', 0: 'value'})\n        weight_df['wm_yr_wk'] = weight_df['d'].map(day_to_week)\n\n        weight_df = weight_df.merge(self.prices, how='left', on=['item_id', 'store_id', 'wm_yr_wk'])\n        weight_df['value'] = weight_df['value'] * weight_df['sell_price']\n        weight_df = weight_df.set_index(['item_id', 'store_id', 'd']).unstack(level=2)['value'].reset_index(drop=True)\n        weight_df = pd.concat([self.train_df[self.id_columns], weight_df], axis=1, sort=False)\n        return weight_df\n\n    def rmsse(self, valid_preds: pd.DataFrame, lv: int) -> pd.Series:\n        train_y = getattr(self, f'lv{lv}_train_df')\n        valid_y = getattr(self, f'lv{lv}_valid_df')\n        score = ((valid_y - valid_preds) ** 2).mean(axis=1)\n        scale = ((train_y.iloc[:, 1:].values - train_y.iloc[:, :-1].values) ** 2).mean(axis=1)\n        return (score / scale / len(valid_y)).map(np.sqrt)\n\n    def score(self, valid_preds: Union[pd.DataFrame, np.ndarray]) -> float:\n        assert self.valid_df[self.valid_target_columns].shape == valid_preds.shape\n\n        if isinstance(valid_preds, np.ndarray):\n            valid_preds = pd.DataFrame(valid_preds, columns=self.valid_target_columns)\n\n        valid_preds = pd.concat([self.valid_df[self.id_columns], valid_preds], axis=1, sort=False)\n\n        all_scores = []\n        for i, group_id in enumerate(self.group_ids):\n            lv_scores = self.rmsse(valid_preds.groupby(group_id)[self.valid_target_columns].sum(), i + 1)\n            weight = getattr(self, f'lv{i + 1}_weight')\n            lv_scores = pd.concat([weight, lv_scores], axis=1, sort=False).prod(axis=1)\n            all_scores.append(lv_scores.sum())\n\n        return np.mean(all_scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class WRMSSEForLightGBM(WRMSSEEvaluator):\n\n    def feval(self, preds, dtrain):\n        preds = preds.reshape(self.valid_df[self.valid_target_columns].shape)\n        score = self.score(preds)\n        return ('WRMSSE', score, False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_pivot_columns(df, split):\n    #dataframe.pivot()\n\n    fix_cols = ['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id']\n    cols = ['d_'+str(x) for x in np.unique(df['d'].apply(lambda x: int(x[2:])).values).tolist()]\n    if split == 'valid':\n        return cols\n    else:\n        return fix_cols+cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#oof_index  = np.load(DATA_DIR+'/d-master-data-fold-index-nodrop-npy/oof_index.npy')\n#test_index = np.load(DATA_DIR+'/d-master-data-fold-index-nodrop-npy/test_index.npy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#oof = np.zeros(len(oof_index))\n#prediction = np.zeros(len(test_index))\n#scores = []\n\nfor i in range(FOLD):\n    print(\"Fold\", i, 'started at', time.ctime())\n    \n    train_idx = np.load(DATA_DIR+'/d-master-data-fold-index-nodrop-npy/train_{}.npy'.format(i))\n    valid_idx = np.load(DATA_DIR+'/d-master-data-fold-index-nodrop-npy/valid_{}.npy'.format(i))\n    print('Index reading done!')\n    \n    data = pd.read_hdf(DATA_DIR+'/d-master-data-fold-index-nodrop-h5/sales.h5', key='data')\n    feats = [x for x in data.columns.values.tolist() if x not in ['date', 'part', 'id', 'target','d']]\n    print('Datasets and features reading done!')\n\n    train_x, train_y = data[feats].iloc[train_idx], data['target'].iloc[train_idx]\n    valid_x, valid_y = data[feats].iloc[valid_idx], data['target'].iloc[valid_idx]\n    print('Data split done!')\n    \n    train_cols = get_pivot_columns(data.iloc[train_idx], 'train')\n    valid_cols = get_pivot_columns(data.iloc[valid_idx], 'valid')\n    del data, feats, train_idx, valid_idx\n    gc.collect()\n    print('Pivot columns done!')\n\n    params = {\n        'learning_rate': 0.025,\n        'max_depth': 10,\n        'num_leaves':2**10+1,\n        'metric': 'rmse',\n        'random_state': SEED,\n        'n_jobs':-1} \n    lgb_train = lgb.Dataset(train_x,\n                            label=train_y,\n                            free_raw_data=False)\n    lgb_test = lgb.Dataset(valid_x,\n                           label=valid_y,\n                           free_raw_data=False)\n    \n    del train_x, valid_x\n    gc.collect()\n    \n    train_df = pd.read_csv(DATA_DIR+'/m5-forecasting-accuracy/sales_train_validation.csv')\n    train_df = reduce_mem_usage(train_df, verbose=True)\n    print('Raw datasets reading done!')\n    train_fold_df = train_df[train_cols]\n    valid_fold_df = train_df[valid_cols]\n    print('Train and valid fold done!')\n    del train_df\n    gc.collect()\n    calendar = pd.read_csv(DATA_DIR+'/m5-forecasting-accuracy/calendar.csv')\n    calendar = reduce_mem_usage(calendar, verbose=True)\n    prices   = pd.read_csv(DATA_DIR+'/m5-forecasting-accuracy/sell_prices.csv')\n    prices   = reduce_mem_usage(prices, verbose=True)\n    print('Calendar and prices reading done!')\n    evaluator = WRMSSEForLightGBM(train_fold_df, valid_fold_df, calendar, prices)\n    del calendar, prices\n    gc.collect()\n    print('Evaluator done!')\n    \n    model = lgb.train(params,\n                      lgb_train,\n                      num_boost_round=EPOCHS,\n                      valid_sets = lgb_test,\n                      verbose_eval=50,\n                      early_stopping_rounds=50,\n                      feval=evaluator.feval\n                     )\n    del lgb_train, lgb_test\n    gc.collect()\n    \n    #y_pred_valid = model.predict(valid_x)\n    #y_pred = model.predict(data[feats].iloc[test_index], num_iteration=model.best_iteration)\n\n    #oof[valid_idx] = y_pred_valid.reshape(-1,)\n    #scores.append(f1_score(valid_y, np.round(np.clip(y_pred_valid, 0, 10)).astype(int), average = 'macro'))\n    #prediction += y_pred\n    print('\\n')\n\n#prediction /= N_FOLD","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}