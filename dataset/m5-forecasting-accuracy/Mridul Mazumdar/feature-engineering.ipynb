{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport logging\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nfrom math import ceil\n\ndef reduce_usage_mem(df):\n        for col in  df.columns:\n            if str(df[col].dtype)=='int64':\n                df[col]=df[col].astype('int16')\n            if str(df[col].dtype)=='float64':\n                df[col]=df[col].astype('float16')\n        return df\n\ndef merge_by_concat(df1, df2, on_col):\n    merged_df = df1[on_col]\n    merged_df = merged_df.merge(df2, on=on_col, how='left')\n    new_columns = [col for col in list(merged_df) if col not in on_col]\n    df1 = pd.concat([df1, merged_df[new_columns]], axis=1)\n    return df1\n\n\nclass m5_preprocessing(object):\n\n    def __init__(self,sales_df_path,calendar_df_path,price_df_path,weather_df_path):\n        self.sales_df_path=sales_df_path\n        self.calendar_df_path=calendar_df_path\n        self.price_df_path=price_df_path\n        self.weather_df_path=weather_df_path\n        return\n\n    def load_data(self):\n        if (self.sales_df_path[-4:] != '.csv'):\n            logging.error('The sales_df file is not a .csv file')\n        \n        if (self.calendar_df_path[-4:] != '.csv'):\n            logging.error('The calendar_df file is not a .csv file')\n\n        if (self.price_df_path[-4:] !='.csv'):\n            logging.error('The price_df file is not a .csv file')\n\n        if (self.weather_df_path[-4:] != '.csv'):\n            logging.error('The weather_df file is not a .csv file')\n\n        else:\n            logging.debug('Loading data')\n            sales_df=reduce_usage_mem(pd.read_csv(self.sales_df_path))\n            calendar_df=reduce_usage_mem(pd.read_csv(self.calendar_df_path))\n            price_df=reduce_usage_mem(pd.read_csv(self.price_df_path))\n            weather_df=reduce_usage_mem(pd.read_csv(self.weather_df_path))\n        return sales_df,calendar_df,price_df,weather_df\n\n    def preprocess(self,sales_df,calendar_df,price_df,weather_df):\n        \n        logging.debug('Preparing store wise grid')\n        \n        index_cols=['id','item_id','dept_id','cat_id','store_id','state_id']\n        TARGET='sales'\n\n        grid_df = pd.melt(sales_df, \n                  id_vars = index_cols, \n                  var_name = 'd', \n                  value_name = TARGET)\n        \n        add_grid = pd.DataFrame()\n        for i in range(1,29):\n            temp_df = sales_df[index_cols]\n            temp_df = temp_df.drop_duplicates()\n            temp_df['d'] = 'd_'+ str(1941+i)\n            temp_df['sales'] = np.nan\n            add_grid = pd.concat([add_grid,temp_df])\n\n        grid_df = pd.concat([grid_df,add_grid])\n        grid_df = grid_df.reset_index(drop=True)\n\n        for col in index_cols:\n            grid_df[col] = grid_df[col].astype('category')\n\n        grid_df=reduce_usage_mem(grid_df)\n        del sales_df\n        del add_grid\n        \n        grid_df['d'] = grid_df['d'].apply(lambda x: x[2:]).astype('int16')\n\n        calendar_df['d'] = calendar_df['d'].apply(lambda x: x[2:]).astype('int16')\n\n        release_df = price_df.groupby(['store_id','item_id'])['wm_yr_wk'].agg(['min']).reset_index()\n        release_df.columns = ['store_id','item_id','release']\n\n        grid_df = merge_by_concat(grid_df, release_df, ['store_id','item_id'])\n        del release_df\n        grid_df = merge_by_concat(grid_df, calendar_df[['wm_yr_wk','d']], ['d'])\n        grid_df = grid_df[grid_df['wm_yr_wk']>=grid_df['release']]\n        grid_df = grid_df.reset_index(drop=True)\n        grid_df['release'] = grid_df['release'] - grid_df['release'].min()\n        grid_df['release'] = grid_df['release'].astype('int16')\n\n        grid_df = grid_df.assign(**{\n            'lag_{}'.format(lag): grid_df.groupby(['id'])['sales'].transform(lambda x: x.shift(lag)).astype('float16')\n            for lag in range(28,43)\n            })\n\n\n        for i in [7,14,30,60]:\n            print('Rolling period:', i)\n            grid_df['rolling_mean_'+str(i)] = grid_df.groupby(['id'])['sales'].transform(lambda x: x.shift(28).rolling(i).mean()).astype('float16')\n            grid_df['rolling_std_'+str(i)]  = grid_df.groupby(['id'])['sales'].transform(lambda x: x.shift(28).rolling(i).std()).astype('float16')\n        \n        grid_df[grid_df['d']<=1941]=grid_df[grid_df['d']<=1941].dropna().reset_index(drop=True)\n\n        price_df['price_max'] = price_df.groupby(['store_id','item_id'])['sell_price'].transform('max')\n        price_df['price_min'] = price_df.groupby(['store_id','item_id'])['sell_price'].transform('min')\n        price_df['price_std'] = price_df.groupby(['store_id','item_id'])['sell_price'].transform('std')\n        price_df['price_mean'] = price_df.groupby(['store_id','item_id'])['sell_price'].transform('mean')\n\n        price_df['price_norm'] = price_df['sell_price']/price_df['price_max']\n        price_df['price_nunique'] = price_df.groupby(['store_id','item_id'])['sell_price'].transform('nunique') \n        price_df['item_nunique'] = price_df.groupby(['store_id','sell_price'])['item_id'].transform('nunique')\n\n        calendar_price = calendar_df[['wm_yr_wk','month','year']]\n        calendar_price = calendar_price.drop_duplicates(subset=['wm_yr_wk'])\n\n        price_df = price_df.merge(calendar_price[['wm_yr_wk','month','year']], on=['wm_yr_wk'] )\n        del calendar_price\n\n        price_df['price_momentum'] = price_df['sell_price']/price_df.groupby(['store_id','item_id'])['sell_price'].transform(lambda x: x.shift(1))\n        price_df['price_momentum_m'] = price_df['sell_price']/price_df.groupby(['store_id','item_id','month'])['sell_price'].transform('mean')\n        price_df['price_momentum_y'] = price_df['sell_price']/price_df.groupby(['store_id','item_id','year'])['sell_price'].transform('mean')\n\n        del price_df['month'], price_df['year']\n\n        grid_df = reduce_usage_mem(grid_df)\n        price_df = reduce_usage_mem(price_df)\n\n        grid_df = grid_df.merge(price_df, on=['store_id','item_id','wm_yr_wk'],how='left')\n        grid_df = reduce_usage_mem(grid_df)\n\n        grid_df['item_id']=grid_df['item_id'].astype('category')\n        grid_df['store_id']=grid_df['store_id'].astype('category')\n\n\n        calendar_df['date'] = pd.to_datetime(calendar_df['date'])\n        calendar_df['event_name_1']=LabelEncoder().fit_transform(calendar_df['event_name_1']).astype('int16')\n        calendar_df['event_type_1']=LabelEncoder().fit_transform(calendar_df['event_type_1']).astype('int16')\n        calendar_df['event_name_2']=LabelEncoder().fit_transform(calendar_df['event_name_2']).astype('int16')\n        calendar_df['event_type_2']=LabelEncoder().fit_transform(calendar_df['event_type_2']).astype('int16')\n\n        calendar_df['tm_d'] = calendar_df['date'].dt.day.astype(np.int16)\n        calendar_df['tm_w'] = calendar_df['date'].dt.week.astype(np.int16)\n        calendar_df['tm_m'] = calendar_df['date'].dt.month.astype(np.int16)\n        calendar_df['tm_y'] = calendar_df['date'].dt.year\n        calendar_df['tm_y'] = (calendar_df['tm_y'] - calendar_df['tm_y'].min()).astype(np.int16)\n        calendar_df['tm_wm'] = calendar_df['tm_d'].apply(lambda x: ceil(x/7)).astype(np.int16) \n\n        calendar_df['tm_dw'] = calendar_df['date'].dt.dayofweek.astype(np.int16) \n        calendar_df['tm_w_end'] = (calendar_df['tm_dw']>=5).astype(np.int16)\n\n        del calendar_df['date'] \n        del calendar_df['weekday'] \n        del calendar_df['wm_yr_wk']\n        del grid_df['wm_yr_wk']\n        grid_df = grid_df.merge(calendar_df, on=['d'])\n\n        icols =  [\n            ['cat_id'],\n            ['dept_id'],\n            ['item_id'],\n            ]\n\n        for col in icols:\n            print('Encoding', col)\n            col_name = '_'+'_'.join(col)+'_'\n            grid_df['enc'+col_name+'mean'] = grid_df.groupby(col)['sales'].transform('mean').astype(np.float16)\n            grid_df['enc'+col_name+'std'] = grid_df.groupby(col)['sales'].transform('std').astype(np.float16)\n\n\n        grid_df['item_id']=LabelEncoder().fit_transform(grid_df['item_id']).astype('int16')\n        grid_df['dept_id']=LabelEncoder().fit_transform(grid_df['dept_id']).astype('int16')\n        grid_df['cat_id']=LabelEncoder().fit_transform(grid_df['cat_id']).astype('int16')\n        \n        weather_df['d'] = weather_df['d'].apply(lambda x: x[2:]).astype('int16')\n\n        grid_df=grid_df.merge(weather_df[['AWND','PRCP','TAVG','state_id','d']],on=['state_id','d'])\n        \n        for store in grid_df['store_id'].unique():\n            logging.debug('exporting {}_full_grid.pkl'.format(store))\n            grid_df[(grid_df['store_id']==store) & (grid_df['d']<=1941)].to_pickle('train_data/{}_full_grid.pkl'.format(store))\n            grid_df[(grid_df['store_id']==store) & (grid_df['d']>1941)].to_pickle('test_data/{}_test_grid.pkl'.format(store))\n            \n            return '{}_full_grid.pkl'.format(store)","metadata":{"_uuid":"d9b28672-0c2f-4c1d-934d-6a6632136b2e","_cell_guid":"780af227-e395-43df-bd25-3a6d81720f10","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}