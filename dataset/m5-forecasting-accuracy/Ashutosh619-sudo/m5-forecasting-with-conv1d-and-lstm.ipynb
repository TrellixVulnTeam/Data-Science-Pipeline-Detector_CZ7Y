{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/m5-forecasting-accuracy/sales_train_validation.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**I Have Copied this code, but all it does is reduces the memory usage so that the ram doesn't blow up.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics: \n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max< np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = reduce_mem_usage(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"calendar = pd.read_csv(\"/kaggle/input/m5-forecasting-accuracy/calendar.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"calendar.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"calendar = reduce_mem_usage(calendar)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Converting the date to datetime object and extracting all the dates in a list for further use**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime as dt\ndate_index = calendar['date']\ndates = date_index[0:1913]\ndates_list = [dt.datetime.strptime(date, '%Y-%m-%d').date() for date in dates]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dates_list[:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**This code converts the dataframe that we can use to forecast every shop.We only took the values and removed everything and then transposed it.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['item_store_id'] = train.apply(lambda x: x['item_id']+'_'+x['store_id'],axis=1)\nDF_Sales = train.loc[:,'d_1':'d_1913'].T\nDF_Sales.columns = train['item_store_id'].values\nDF_Sales = pd.DataFrame(DF_Sales).set_index([dates_list])\nDF_Sales.index = pd.to_datetime(DF_Sales.index)\nDF_Sales.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in DF_Sales.columns[:5]:\n    y = pd.DataFrame(DF_Sales.loc[:,col])\n    y = pd.DataFrame(y).set_index([dates_list])\n    \n    y.index = pd.to_datetime(y.index)\n    \n    ax = y.plot(figsize=(30, 9),color='red')\n    ax.set_facecolor('lightgrey')\n    plt.xticks(fontsize=21 )\n    plt.yticks(fontsize=21 )\n    plt.legend(fontsize=20)\n    plt.title(label = 'Sales Demand Selected Time Series Over Time',fontsize = 23)\n    plt.ylabel(ylabel = 'Sales Demand',fontsize = 21)\n    plt.xlabel(xlabel = 'Date',fontsize = 21)\n    plt.show()\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**After looking at the 1st and 2nd graph I see some seasonality as there is increase in sales in the beginning of a new year, but this is not true for all of them for some reason**"},{"metadata":{},"cell_type":"markdown","source":"# **We will try to predict for one store for now**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = np.array(y)\nscaler = MinMaxScaler(feature_range=(0, 1))\ndataset = scaler.fit_transform(data.reshape(-1, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_size = int(len(dataset) * 0.67)\ntest_size = len(dataset) - train_size\ntrain, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\ntrain.shape,test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_dataset(dataset, look_back=1):\n    dataX, dataY = [], []\n    for i in range(len(dataset)-look_back-1):\n        a = dataset[i:(i+look_back), 0]\n        dataX.append(a)\n        dataY.append(dataset[i + look_back, 0])\n    return np.array(dataX), np.array(dataY)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,y_train = create_dataset(train,28)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test,y_test = create_dataset(test,28)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainX = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\ntestX = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainX","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.layers import GRU\nfrom tensorflow.keras.layers import Bidirectional\nfrom tensorflow.keras.layers import Conv1D","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv1D(filters=32, kernel_size=5,\n                      strides=1, padding=\"causal\",\n                      activation=\"relu\",\n                      input_shape=[None, 1]))\nmodel.add(LSTM(512))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer='adam',metrics=[\"mean_squared_error\"])\nmodel.fit(trainX, y_train, epochs=100,batch_size=1, verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traning_pred = model.predict(trainX)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pred = pd.Series(scaler.inverse_transform(traning_pred).flatten())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(num=None, figsize=(19, 6), facecolor='w', edgecolor='k')\nplt.plot(train_pred)\nplt.plot(train)\nplt.legend([\"Predicted\",\"Real\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred = scaler.inverse_transform(model.predict(testX)).flatten()\nplt.figure(num=None, figsize=(19, 6), dpi=80, facecolor='w', edgecolor='k')\nplt.plot(test_pred)\nplt.plot(test)\nplt.legend([\"Predicted\",\"Real\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Do upvote if you found it helpful.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}