{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 概要\n以下Notebookを元に日本語にさせていただいています。ありがとうございます。  \nまた、自分用に変数名を変更したり、メモしたりしていますのでご注意ください。\n![](http://)https://www.kaggle.com/robikscube/m5-forecasting-starter-data-exploration"},{"metadata":{},"cell_type":"markdown","source":"# M5 Forecasting Challenge\n<img src=\"https://images.ctfassets.net/osv85d77hkdf/7LsZ5bZzvGaG6iwYkoKEUc/84afe0bf84371542fe56e6d5f0b3377b/hero_telescope_01_2x.png\" width=\"500\" height=\"300\" />\n\nこのnotebookのゴールは2020年のM5コンペをすばやく理解してもらうことだ。\n読み終えれば、あなたは問題を解く良い目標を思いつき、提供されたデータとその評価を得られるだろう。\n\n注意:\n- 2つの平行して実施されるコンペがある。： **Accuracy** と **Uncertainty**\n    - **Accuracy** は評価指標にWeightedRMSSE（Weighted Root Mean Squared Scaled Error）\n    - **Uncertainty** は評価指標にWeightedWPL（Weighted Scaled Pinball Loss）\n- Wal-Martの階層的販売データの予測が仕事である\n- そのデータは3つの州（カリフォルニア州、テキサス州、ウィスコンシン州）のデータと商品レベル（item level）、部門（department）、商品カテゴリー（product catgories）、店の詳細が入っている\n- 加えて、説明変数である価格、プロモーション、曜日、スペシャルイベントなどがある"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pylab as plt\nimport seaborn as sns\nfrom itertools import cycle\n\n# 参考：グラフ作成のためのチートシートとPythonによる各種グラフの実装\n# https://qiita.com/4m1t0/items/76b0033edb545a78cef5\n# 最大列\npd.set_option('max_columns', 50)\n# https://matplotlib.org/3.1.3/gallery/style_sheets/bmh.html\n# 「Bayesian Methods for Hackers style sheet」\nplt.style.use('bmh')\n# 「rcParams」はmatplotlibのデフォルトセット\n# 「axes.prop_cycle」はcycler.Cycler型\ncolor_pal = plt.rcParams['axes.prop_cycle'].by_key()['color']\ncolor_cycle = cycle(plt.rcParams['axes.prop_cycle'].by_key()['color'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# Data Files\n- `calendar.csv` - 各日の情報.\n- `sales_train_validation.csv` - 各日および店での販売個数[d_1 - d_1913]\n- `sample_submission.csv` - 現在の提出フォーマット。「Evaluation」タブで詳細を見れる。\n- `sell_prices.csv` - 店、日付単位での販売価格\n\nNot available yet:\n- `sales_train_evaluation.csv` - コンペの提出期限の1ヶ月前にて字される。[d_1 - d_1941]"},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls -GFlash --color ../input/m5-forecasting-accuracy/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# データ読み込み\nINPUT_DIR = '../input/m5-forecasting-accuracy'\n# cal = pd.read_csv(f'{INPUT_DIR}/calendar.csv')\n# stv = pd.read_csv(f'{INPUT_DIR}/sales_train_validation.csv')\n# ss = pd.read_csv(f'{INPUT_DIR}/sample_submission.csv')\n# sellp = pd.read_csv(f'{INPUT_DIR}/sell_prices.csv')\n\ndf_calendar = pd.read_csv(f'{INPUT_DIR}/calendar.csv')\ndf_sales_train_validation = pd.read_csv(f'{INPUT_DIR}/sales_train_validation.csv')\ndf_sample_submission = pd.read_csv(f'{INPUT_DIR}/sample_submission.csv')\ndf_sell_prices = pd.read_csv(f'{INPUT_DIR}/sell_prices.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_calendar.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sales_train_validation.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sell_prices.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 何を正確に予測するのか?\n28日間の販売個数を予測しようとしている。サンプル提出ファイルは以下のフォーマットになっている:\n- 列は28日分ある。私達の予測でこれらを埋める。\n- 各行は特定の商品を表す。このIDは商品タイプ、州、店を示す。が、正確には商品を知らない。"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"sales_train_validation.csvのデータセットには販売履歴データが与えられている。\n- 行はd_1〜d_1913日間のデータセットが存在する。商品の部門、カテゴリー、州、店のIDがある。\n- d_1914 - d_1941はステージ1で予測する**validation**の行です。\n- d_1942 - d_1969は最後に予測する**evaluation**の行です。"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sales_train_validation.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1商品のデータを見える化する\n- たくさん販売している商品をランダムに鳥、学習データを通してどのように売られているか見ましょう\n- `FOODS_3_090_CA_3_validation`がたくさん売られていますね。\n- 売れずに低迷している日があることに注意しましょう。"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 「日付」の列を取り出す\nd_cols = [column for column in df_sales_train_validation.columns if 'd_' in column]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# ↓にpandasで以下を実行する\n# 1. 商品を選択\n# 2. IDにindexを設定し、売上データのみの列にする\n#   https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.set_index.html\n# 3. 転置する\n# 4. データをプロットする\n\ndf_sales_train_validation.loc[\n    df_sales_train_validation['id'] == 'FOODS_3_090_CA_3_validation'\n] \\\n.set_index('id')[d_cols] \\\n.T \\\n.plot(figsize=(15, 5),\n      title='FOODS_3_090_CA_3 sales by \"d\" number',\n      color=next(color_cycle))\nplt.legend('')\nplt.show()\n\n# 見た感じは250日目ぐらいまでほとんど売れてないね...","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 実際の日とデータをマージする\n- 過去と未来の日付の追加情報を持つカレンダーが与えられている\n- カレンダーデータは各日のデータとマージできる\n- ここから週および年の流行がわかるだろう"},{"metadata":{"trusted":true},"cell_type":"code","source":"# カレンダーではこのようになっている\n# 列は今注目している列のみ\ndf_calendar[\n    [\n    # 日付ID（d_1〜）\n    'd',\n    # 実際の日付\n    'date',\n    # イベント名1\n    'event_name_1',\n    # イベント名2\n    'event_name_2',\n    # イベントタイプ1\n    'event_type_1',\n    # イベントタイプ2\n    'event_type_2', \n    # カリフォルニア州のSNAP\n    'snap_CA',\n    ]\n].head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# 商品データとカレンダーをマージする\n# 先程のデータ取り出し\ndf_example = df_sales_train_validation.loc[\n    df_sales_train_validation['id'] == 'FOODS_3_090_CA_3_validation'] \\\n[d_cols].T\n# 列名（元のindex名）を正しくする\ndf_example = df_example.rename(columns={8412:'FOODS_3_090_CA_3'})\n# インデックス値をリセット\n# 名称を「d」とする\ndf_example = df_example.reset_index().rename(columns={'index': 'd'}) # make the index \"d\"\n# カレンダー情報のマージ\n# 「validate」は1:1のマージであることをチェックする\ndf_example = df_example.merge(df_calendar, how='left', validate='1:1')\n# indexにdate（calendar.csvの日付）を設定する\ndf_example.set_index('date')['FOODS_3_090_CA_3'] \\\n    .plot(figsize=(15, 5),\n          color=next(color_cycle),\n          title='FOODS_3_090_CA_3 sales by actual sale dates')\nplt.show()\n\n# 2011-10-05あたりから売上てるのがわかる","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 他のトップセールスの例を見てみよう！(1)\n# HOBBIES_1_234_CA_3_validation\ndf_example2 = df_sales_train_validation.loc[\n    df_sales_train_validation['id'] == 'HOBBIES_1_234_CA_3_validation'\n][d_cols].T\ndf_example2 = df_example2.rename(columns={6324:'HOBBIES_1_234_CA_3'}) # Name it correctly\ndf_example2 = df_example2.reset_index().rename(columns={'index': 'd'}) # make the index \"d\"\ndf_example2 = df_example2.merge(df_calendar, how='left', validate='1:1')\ndf_example2.set_index('date')['HOBBIES_1_234_CA_3'] \\\n    .plot(figsize=(15, 5),\n          color=next(color_cycle),\n          title='HOBBIES_1_234_CA_3 sales by actual sale dates')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 他のトップセールスの例を見てみよう！(2)\n# HOUSEHOLD_1_118_CA_3_validation\ndf_example3 = df_sales_train_validation.loc[\n    df_sales_train_validation['id'] == 'HOUSEHOLD_1_118_CA_3_validation'\n][d_cols].T\ndf_example3 = df_example3.rename(columns={6776:'HOUSEHOLD_1_118_CA_3'}) # Name it correctly\ndf_example3 = df_example3.reset_index().rename(columns={'index': 'd'}) # make the index \"d\"\ndf_example3 = df_example3.merge(df_calendar, how='left', validate='1:1')\ndf_example3.set_index('date')['HOUSEHOLD_1_118_CA_3'] \\\n    .plot(figsize=(15, 5),\n          color=next(color_cycle),\n          title='HOUSEHOLD_1_118_CA_3 sales by actual sale dates')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 時間変数で売上を分解する\n- 今、例で挙げた商品が以下単位でどのように売られているか見てみよう。\n    - 1週間\n    - 1月\n    - 1年"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# サンプル商品IDリスト\nexample_ids = ['FOODS_3_090_CA_3','HOBBIES_1_234_CA_3','HOUSEHOLD_1_118_CA_3']\n# サンプル商品の売上データ\ndf_example_all = [\n    df_example, \n    df_example2, \n    df_example3\n]\n\n# 各商品データをプロットしていく\nfor i in [0, 1, 2]:\n    # グラフ準備\n    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 3))\n    \n    # 週単位で平均を取る\n    df_example_all[i].groupby('wday').mean()[\n        example_ids[i]] \\\n        .plot(\n            kind='line',\n            title='average sale: day of week',\n            lw=5,\n            color=color_pal[0],\n            ax=ax1\n    )\n    \n    # 月単位で平均を取る\n    df_example_all[i].groupby('month').mean()[\n        example_ids[i]] \\\n        .plot(kind='line',\n              title='average sale: month',\n              lw=5,\n              color=color_pal[4],\n              ax=ax2)\n    \n    # 年で平均を取る\n    df_example_all[i].groupby('year').mean()[example_ids[i]] \\\n        .plot(kind='line',\n              lw=5,\n              title='average sale: year',\n              color=color_pal[2],\n              ax=ax3)\n    \n    # サブタイトル\n    fig.suptitle(f'Trends for item: {example_ids[i]}',\n                 size=20,\n                 y=1.1)\n    plt.tight_layout()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 他の商品も見てみよう！\n- 一緒に異なる20商品を出してみよう\n- それらのグラフからいくつかの考察が得られるだろう\n    - 共通して言えるのは一定期間、購入されていない商品がある。\n    - 1日に売れる量が1つ、または少ない商品があり、それは予測が難しいだろう\n    - 他の商品は急な需要が見られる（スーパーボウルの日曜か？）、もしかしたら与えられている\"イベント\"のデータが役立つかもしれない。"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# 20例のデータ取り出し\ntwenty_examples = df_sales_train_validation.sample(\n        20, random_state=529\n    ) \\\n    .set_index('id')[d_cols] \\\n    .T \\\n    .merge(df_calendar.set_index('d')['date'],\n           left_index=True,\n           right_index=True,\n            validate='1:1') \\\n    .set_index('date')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# 20例のデータをプロット\nfig, axs = plt.subplots(10, 2, figsize=(15, 20))\naxs = axs.flatten()\nax_idx = 0\nfor item in twenty_examples.columns:\n    twenty_examples[item].plot(title=item,\n                              color=next(color_cycle),\n                              ax=axs[ax_idx])\n    ax_idx += 1\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 商品タイプ別の売上高の推移\n- いくつかの商品タイプがある\n    - Hobbies（娯楽品）\n    - Household（日用品）\n    - Foods（食べ物）\n- 各商品タイプごとの需要をプロットしてみよう"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# 何の商品タイプがあるか\ndf_sales_train_validation['cat_id'].unique()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# カテゴリ別でどれだけ商品数があるか\ndf_sales_train_validation.groupby('cat_id').count()['id'] \\\n    .sort_values() \\\n    .plot(kind='barh', figsize=(15, 5), title='Count of Items by Category')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# 過去の売上\n# index: 日付ID\n# column: 商品ID\npast_sales = df_sales_train_validation.set_index('id')[d_cols] \\\n    .T \\\n    .merge(df_calendar.set_index('d')['date'],\n           left_index=True,\n           right_index=True,\n            validate='1:1') \\\n    .set_index('date')\n\n\n# カテゴリ別で各商品データを取り出して\nfor i in df_sales_train_validation['cat_id'].unique():\n    # 対象カテゴリの商品列を取り出す\n    items_col = [c for c in past_sales.columns if i in c]\n    # 対象カテゴリの商品数を合計してプロット\n    past_sales[items_col] \\\n        .sum(axis=1) \\\n        .plot(figsize=(15, 5),\n              alpha=0.8,\n              title='Total Sales by Item Type')\nplt.legend(df_sales_train_validation['cat_id'].unique())\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 店ごとの売上\n10店舗のデータが提供されている。店舗ごとの売上数はいくらか？\n- いくつかの店舗は他店舗よりも一定の売上がある\n- 「CA_2」の店舗は2015年に大きな変化が起こったようだ"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# 店リスト\nstore_list = df_sell_prices['store_id'].unique()\n\n# 店単位で集計\nfor s in store_list:\n    # 店単位で商品取り出し\n    # ※ IDに店のIDが含まれている\n    store_items = [c for c in past_sales.columns if s in c]\n    # 店単位で移動平均を出す\n    # https://note.nkmk.me/python-pandas-rolling/\n    # 店で売っている商品を日付ごとに合計して90日ずつの移動平均を表示\n    past_sales[store_items] \\\n        .sum(axis=1) \\\n        .rolling(90).mean() \\\n        .plot(figsize=(15, 5),\n              alpha=0.8,\n              title='Rolling 90 Day Average Total Sales (10 stores)')\nplt.legend(store_list)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- 同じデータを異なる側面で見るため、店舗ごとの7日間の需要を移動平均でプロットする\n- 明らかにいくつかの店舗は急激な変化をしていて、店の拡張をしたり、競合店が近くにできたりしている可能性がある\n- どちらにせよ、需要パターンは予測するモデルを作る時には重要である"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# 店で売っている商品を日付ごとに合計して7日ずつの移動平均を表示\nfig, axes = plt.subplots(5, 2, figsize=(15, 10), sharex=True)\naxes = axes.flatten()\nax_idx = 0\nfor s in store_list:\n    store_items = [c for c in past_sales.columns if s in c]\n    past_sales[store_items] \\\n        .sum(axis=1) \\\n        .rolling(7).mean() \\\n        .plot(alpha=1,\n              ax=axes[ax_idx],\n              title=s,\n              lw=3,\n              color=next(color_cycle))\n    ax_idx += 1\n# plt.legend(store_list)\nplt.suptitle('Weekly Sale Trends by Store ID')\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 売上とカレンダーのヒートマップ"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# ----------------------------------------------------------------------------\n# Author:  Nicolas P. Rougier\n# License: BSD\n# ----------------------------------------------------------------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Polygon\nfrom datetime import datetime\nfrom dateutil.relativedelta import relativedelta\n\n\ndef calmap(ax, year, data):\n    ax.tick_params('x', length=0, labelsize=\"medium\", which='major')\n    ax.tick_params('y', length=0, labelsize=\"x-small\", which='major')\n\n    # Month borders\n    xticks, labels = [], []\n    start = datetime(year,1,1).weekday()\n    for month in range(1,13):\n        first = datetime(year, month, 1)\n        last = first + relativedelta(months=1, days=-1)\n\n        y0 = first.weekday()\n        y1 = last.weekday()\n        x0 = (int(first.strftime(\"%j\"))+start-1)//7\n        x1 = (int(last.strftime(\"%j\"))+start-1)//7\n\n        P = [ (x0,   y0), (x0,    7),  (x1,   7),\n              (x1,   y1+1), (x1+1,  y1+1), (x1+1, 0),\n              (x0+1,  0), (x0+1,  y0) ]\n        xticks.append(x0 +(x1-x0+1)/2)\n        labels.append(first.strftime(\"%b\"))\n        poly = Polygon(P, edgecolor=\"black\", facecolor=\"None\",\n                       linewidth=1, zorder=20, clip_on=False)\n        ax.add_artist(poly)\n    \n    ax.set_xticks(xticks)\n    ax.set_xticklabels(labels)\n    ax.set_yticks(0.5 + np.arange(7))\n    ax.set_yticklabels([\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"])\n    ax.set_title(\"{}\".format(year), weight=\"semibold\")\n    \n    # Clearing first and last day from the data\n    valid = datetime(year, 1, 1).weekday()\n    data[:valid,0] = np.nan\n    valid = datetime(year, 12, 31).weekday()\n    # data[:,x1+1:] = np.nan\n    data[valid+1:,x1] = np.nan\n\n    # Showing data\n    ax.imshow(data, extent=[0,53,0,7], zorder=10, vmin=-1, vmax=1,\n              cmap=\"RdYlBu_r\", origin=\"lower\", alpha=.75)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- クリスマスにはウォルマートは閉まるようだ\n- 最も需要が高い日は2016年3月6日の日曜だ\n- 何があったんだろうと思うかもしれないが...もしかしたら、CNN主催の7回目の民主党党首の候補のディベート（https://www.onthisday.com/date/2016/march/6）\n    - んなわけない :D"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 最低売上\nprint('The lowest sale date was:', past_sales.sum(axis=1).sort_values().index[0],\n     'with', past_sales.sum(axis=1).sort_values().values[0], 'sales')\n# 最高売上 ※ 元はlowestだけどhighestに変更\nprint('The highest sale date was:', past_sales.sum(axis=1).sort_values(ascending=False).index[0],\n     'with', past_sales.sum(axis=1).sort_values(ascending=False).values[0], 'sales')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# ヒートマップ作成\nfrom sklearn.preprocessing import StandardScaler\nsscale = StandardScaler()\npast_sales.index = pd.to_datetime(past_sales.index)\n\nfor i in df_sales_train_validation['cat_id'].unique():\n    # 2013年\n    fig, axes = plt.subplots(3, 1, figsize=(20, 8))\n    items_col = [c for c in past_sales.columns if i in c]\n    sales2013 = past_sales.loc[past_sales.index.isin(pd.date_range('31-Dec-2012',\n                                                                   periods=371))][items_col].mean(axis=1)\n    vals = np.hstack(sscale.fit_transform(sales2013.values.reshape(-1, 1)))\n    calmap(axes[0], 2013, vals.reshape(53,7).T)\n    \n    # 2014年\n    sales2014 = past_sales.loc[past_sales.index.isin(pd.date_range('30-Dec-2013',\n                                                                   periods=371))][items_col].mean(axis=1)\n    vals = np.hstack(sscale.fit_transform(sales2014.values.reshape(-1, 1)))\n    calmap(axes[1], 2014, vals.reshape(53,7).T)\n    \n    # 2015年\n    sales2015 = past_sales.loc[past_sales.index.isin(pd.date_range('29-Dec-2014',\n                                                                   periods=371))][items_col].mean(axis=1)\n    vals = np.hstack(sscale.fit_transform(sales2015.values.reshape(-1, 1)))\n    calmap(axes[2], 2015, vals.reshape(53,7).T)\n    \n    plt.suptitle(i, fontsize=30, x=0.4, y=1.01)\n    plt.tight_layout()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ヒートマップから面白いことがわかる:\n- 食品は月末になるほど購入量が少なくなる。月の初めに給料の支払いがあるから？\n- 日用品と娯楽品は1月に少なくなる。これは連休シーズンの後だから。\n- 明らかに週末は買い物日だ（商品カテゴリーに無関係）"},{"metadata":{},"cell_type":"markdown","source":"# 販売価格\n各商品の階層的販売価格が与えられている。以前から取り上げている商品を見てみよう\n- この商品の価格は上昇している\n- 他店舗では異なる価格で販売されている"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15, 5))\nstores = []\n\n# 1商品の店舗・週別の価格をプロット\nfor store, d in df_sell_prices.query('item_id == \"FOODS_3_090\"').groupby('store_id'):\n    d.plot(x='wm_yr_wk',\n          y='sell_price',\n          style='.',\n          color=next(color_cycle),\n          figsize=(15, 5),\n          title='FOODS_3_090 sale price over time',\n         ax=ax,\n          legend=store)\n    stores.append(store)\n    plt.legend()\nplt.legend(stores)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df_sell_prices['Category'] = df_sell_prices['item_id'].str.split('_', expand=True)[0]\nfig, axs = plt.subplots(1, 3, figsize=(15, 4))\ni = 0\n\n# 店舗・カテゴリ別の価格をプロット\nfor cat, d in df_sell_prices.groupby('Category'):\n    ax = d['sell_price'].apply(np.log1p) \\\n        .plot(kind='hist',\n                         bins=20,\n                         title=f'Distribution of {cat} prices',\n                         ax=axs[i],\n                                         color=next(color_cycle))\n    ax.set_xlabel('Log(price)')\n    i += 1\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 簡単な提出\n- 過去30日間の平均を提出してみる"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 過去30日間の平均を取った辞書データ\nthirty_day_avg_map = df_sales_train_validation.set_index('id')[d_cols[-30:]].mean(axis=1).to_dict()\n\n# 予測日の列リスト\nfcols = [f for f in df_sample_submission.columns if 'F' in f]\n\nfor f in fcols:\n    # 各商品単位で平均の値を設定\n    df_sample_submission[f] = df_sample_submission['id'].map(thirty_day_avg_map).fillna(0)\n    \ndf_sample_submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### submission.csvの例\nid,F1,F2,F3,F4,F5,F6,F7,F8,F9,F10,F11,F12,F13,F14,F15,F16,F17,F18,F19,F20,F21,F22,F23,F24,F25,F26,F27,F28\nHOBBIES_1_001_CA_1_validation,0.9666666666666667,0.9666666666666667,0.9666666666666667,0.9666666666666667,0.9666666666666667,0.9666666666666667,0.9666666666666667,0.9666666666666667,0.9666666666666667,0.9666666666666667,0.9666666666666667,0.9666666666666667,0.9666666666666667,0.9666666666666667,0.9666666666666667,0.9666666666666667,0.9666666666666667,0.9666666666666667,0.9666666666666667,0.9666666666666667,0.9666666666666667,0.9666666666666667,0.9666666666666667,0.9666666666666667,0.9666666666666667,0.9666666666666667,0.9666666666666667,0.9666666666666667\nHOBBIES_1_002_CA_1_validation,0.13333333333333333,0.13333333333333333,0.13333333333333333,0.13333333333333333,0.13333333333333333,0.13333333333333333,0.13333333333333333,0.13333333333333333,0.13333333333333333,0.13333333333333333,0.13333333333333333,0.13333333333333333,0.13333333333333333,0.13333333333333333,0.13333333333333333,0.13333333333333333,0.13333333333333333,0.13333333333333333,0.13333333333333333,0.13333333333333333,0.13333333333333333,0.13333333333333333,0.13333333333333333,0.13333333333333333,0.13333333333333333,0.13333333333333333,0.13333333333333333,0.13333333333333333"},{"metadata":{},"cell_type":"markdown","source":"## TODO\n- 週単位での販売履歴の平均に基づいた簡単な予測\n- FacebookのProphetモデルの利用  \n  https://facebook.github.io/prophet/\n- 日の特徴量を元にしたLGBM/XGBモデル"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}