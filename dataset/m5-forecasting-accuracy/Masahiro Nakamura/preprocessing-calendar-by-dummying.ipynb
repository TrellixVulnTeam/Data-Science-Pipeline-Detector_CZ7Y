{"cells":[{"metadata":{},"cell_type":"markdown","source":"Thank you for opening this notebook!","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"In this notebook, I'd like to talk about one of the ways to deal with \"calendar.csv\".","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# What to do in this article?\n## I preprocess \"calendar.csv\" so that we can use to Machine Learning\n# What not to do in this article?\n## I don't make a prediction using other files.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Loading data and check missing values","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"At first, I load calendar.csv on this notebook.","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"calendar = pd.read_csv(\"/kaggle/input/m5-forecasting-accuracy/calendar.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I finished loading. Then, let's check the begining of the data. Here, I use 'head()'.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"calendar.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are lots of 'NaN'. Let's check the num of missing values. Here, I use \"isnull().sum()\".","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"calendar.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see missing values in event_name_1, event_type_1, event_name_2 and event_type_2.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"It seems that the number is not few. Let's check the outline by using \"describe()\".","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"calendar.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that the rate of missing value is high.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"This might lead to trouble of machine learning.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"To avoid the situation, we can select two actions.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"1 We eliminate four columns.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"2 We make new feature values by using them.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Here, we choose second option.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# See the contents of each data.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Then, let's see the contents of each data.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## event_name_1","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"calendar[\"event_name_1\"].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(calendar[\"event_name_1\"].unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 31 kinds of data in \"event_name_1\". It seems that they are names of special days such as 'SuperBowl' and 'ValentinesDay'.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## event_type_1","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Next, let's check \"event_type_1\".","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"calendar[\"event_type_1\"].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems that these datas mention the kinds of special days.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## event_name_2, event_type_2","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"By the way there is a question that why \"calendar.csv\" has \"event_name_2\" and \"event_type_2\".","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Let's check.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"calendar[\"event_name_2\"].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"calendar[\"event_type_2\"].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If we watched carefully, we can realize that there are same contents in both name ans event.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"I use \"set\" to check the duplication.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"event_name = set(calendar[\"event_name_1\"].unique()) & set(calendar[\"event_name_2\"].unique())\nprint(event_name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"event_type = set(calendar[\"event_type_1\"].unique()) & set(calendar[\"event_type_2\"].unique())\nprint(event_type)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can say that there are duplicates in event_name and event_type.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We can say that some day corresponds to TWO SPECIAL DAYS.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Dummying special days and kinds.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"To make special days feature values, we need to deal with \"nan\".","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Then, I express if each days adapts to each special days by using 0 and 1.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"If one day did not adapt to any special days, its all columns are 0.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"event_name_one = calendar[\"event_name_1\"]\nevent_name_one = pd.get_dummies(event_name_one)\nevent_name_one.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here, I made calendar's \"event_name_1\" dummy variable. I do same thing to \"event_name_2\".","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"event_name_two = calendar[\"event_name_2\"]\nevent_name_two = pd.get_dummies(event_name_two)\nevent_name_two.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I completed making dummy variable. Next, I coalesce two data.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"event_names = pd.merge(event_name_one, event_name_two, right_index=True, left_index=True)\nevent_names.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"event_names.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I used \"merge\". Duplicated data like Cinco De Mayo has \"_x\" or \"_y\".","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Next, I make Cinco De Mayo, OrthodoxEaster, Easter and Father's day again.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"If something_x or something_y had 1, something's value make 1. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"event_names['Easter'] = 0\nevent_names['Cinco De Mayo'] = 0\nevent_names['OrthodoxEaster'] = 0\nevent_names[\"Father's day\"] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for index in event_names.index:\n    if event_names.loc[index,\"Cinco De Mayo_x\"] == 1 or event_names.loc[index,\"Cinco De Mayo_y\"] == 1:\n        event_names.loc[index,\"Cinco De Mayo\"] = 1        \n    if event_names.loc[index,\"Easter_x\"] == 1 or event_names.loc[index,\"Easter_y\"] == 1:\n        event_names.loc[index,\"Easter\"] = 1    \n    if event_names.loc[index,\"Father's day_x\"] == 1 or event_names.loc[index,\"Father's day_y\"] == 1:\n        event_names.loc[index,\"Father's day\"] = 1    \n    if event_names.loc[index,\"OrthodoxEaster_x\"] == 1 or event_names.loc[index,\"OrthodoxEaster_y\"] == 1:\n        event_names.loc[index,\"OrthodoxEaster\"] = 1    \n        \nevent_names.drop('Cinco De Mayo_x', axis=1, inplace=True)\nevent_names.drop('Cinco De Mayo_y', axis=1, inplace=True)\nevent_names.drop('Easter_x', axis=1, inplace=True)\nevent_names.drop('Easter_y', axis=1, inplace=True)\nevent_names.drop(\"Father's day_x\", axis=1, inplace=True)\nevent_names.drop(\"Father's day_y\", axis=1, inplace=True)\nevent_names.drop('OrthodoxEaster_x', axis=1, inplace=True)\nevent_names.drop('OrthodoxEaster_y', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"event_names.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I eliminated duplicated data. There is not any more \"nan\".","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"I deal with event_type by using same way of thinking.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"event_type_one = calendar[\"event_type_1\"]\nevent_type_one = pd.get_dummies(event_type_one)\nevent_type_one.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"event_type_two = calendar[\"event_type_2\"]\nevent_type_two = pd.get_dummies(event_type_two)\nevent_type_two.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"event_types = pd.merge(event_type_one, event_type_two, right_index=True, left_index=True)\nevent_types['Cultural'] = 0\nevent_types['Religious'] = 0\nevent_types.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for index in event_types.index:\n    if event_types.loc[index,\"Cultural_x\"] == 1 or event_types.loc[index,\"Cultural_y\"] == 1:\n        event_types.loc[index,\"Cultural\"] = 1        \n    if event_types.loc[index,\"Religious_x\"] == 1 or event_types.loc[index,\"Religious_y\"] == 1:\n        event_types.loc[index,\"Religious\"] = 1    \n        \n        \nevent_types.drop('Cultural_x', axis=1, inplace=True)\nevent_types.drop('Cultural_y', axis=1, inplace=True)\nevent_types.drop('Religious_x', axis=1, inplace=True)\nevent_types.drop('Religious_y', axis=1, inplace=True)\n\nevent_types.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Finalize calendar","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Finally, I coalesce original data, event_name and event_types.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"calendar = pd.concat([calendar, event_names, event_types], axis=1)\ncalendar.drop('event_name_1', axis=1, inplace=True)\ncalendar.drop('event_type_1', axis=1, inplace=True)\ncalendar.drop('event_name_2', axis=1, inplace=True)\ncalendar.drop('event_type_2', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"calendar.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"calendar.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is no more missing values.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Below code is last action.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"calendar.to_csv('calendar_dummied.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this notebook, I preprocessed calendar.csv to make special days dummy values and eliminate missing values.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Thank you for reading to the last.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}