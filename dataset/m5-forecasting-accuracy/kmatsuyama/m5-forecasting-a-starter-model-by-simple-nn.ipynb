{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Next\nVisualize the featuer importances of NN model: https://www.kaggle.com/kmatsuyama/shap-feature-importances-plot-of-nn-models"},{"metadata":{},"cell_type":"markdown","source":"# Overview\n* This kernel will produce:\n    * a starter model to predict the future sales using keras\n* This kernel will not produce:\n    * EDA\n    * particular feature engineering\n    "},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# Libraries\nimport numpy as np\nimport pandas as pd\npd.set_option('max_columns', None)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('seaborn')\n%matplotlib inline\nimport copy\nimport datetime\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.preprocessing import LabelEncoder\n\nimport os\nimport re\nimport gc\nimport pickle  \nimport random\nimport keras\n\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\n#import tensorflow_hub as hub\nimport keras.backend as K\n\nfrom keras.models import Model\nfrom keras.layers import Dense, Input, Dropout, Lambda\nfrom keras.optimizers import Adam\nfrom keras.callbacks import Callback\nfrom scipy.stats import spearmanr, rankdata\nfrom os.path import join as path_join\nfrom numpy.random import seed\nfrom urllib.parse import urlparse\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import KFold\nfrom sklearn.linear_model import MultiTaskElasticNet\nfrom sklearn.linear_model import Ridge\nimport glob\nfrom sklearn.model_selection import train_test_split\n\nseed(42)\nrandom.seed(42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading the data"},{"metadata":{},"cell_type":"markdown","source":"In this part, we will:\n* load the data\n* name the date respectively\n\n\nabout this part, thanks to great kernel!  \nhttps://www.kaggle.com/robikscube/m5-forecasting-starter-data-exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dict = {}\nfor i in glob.glob('../input/m5-forecasting-accuracy/*'):\n    name = i.split('/')[-1].split('.')[0]\n    if name != 'MTeamSpellings':\n        data_dict[name] = pd.read_csv(i)\n    else:\n        data_dict[name] = pd.read_csv(i, encoding='cp1252')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dict.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check the subimission fotmat\ndata_dict['sample_submission']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# name the data respectively \n\ncal = data_dict['calendar']\nstv = data_dict['sales_train_validation']\nss = data_dict['sample_submission']\nsellp = data_dict['sell_prices']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# processing"},{"metadata":{},"cell_type":"markdown","source":"In this part, we will:\n* extract wday, month, events and SNAP availability of stores as features\n* process the events columns to binary (any event:1, no event:0)\n\n\nSNAP is a program of US that support food-purchase for low (or no) income person.  \nmore at: https://en.wikipedia.org/wiki/Supplemental_Nutrition_Assistance_Program"},{"metadata":{"trusted":true},"cell_type":"code","source":"stv_df = stv.drop(['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'], axis=1).set_index('id').T\nstv_df['d'] = stv_df.index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.merge(cal, stv_df, left_on='d', right_on='d', how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def event_detector(x):\n    if x == None:\n        return 0\n    else:\n        return 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#drop the date we won't use\ndrp = ['wm_yr_wk', 'weekday', 'year', 'd', 'event_type_1', 'event_type_2']\n\n#we will use these columns\ncols_x = ['wday', 'month', 'event_name_1', 'event_name_2','snap_CA', 'snap_TX', 'snap_WI']\n\n\n# process events to binary\ndf = df.drop(drp, axis=1)\ndf['event_name_1'] = df['event_name_1'].apply(lambda x: event_detector(x))\ndf['event_name_2'] = df['event_name_2'].apply(lambda x: event_detector(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# modeling"},{"metadata":{},"cell_type":"markdown","source":"In this part, we will:\n* prepare the data for training; we will use 2015-06-19 ~ 2016-04-25 as the training period\n* make a very simple NN model using Keras\n* visualize the process of training "},{"metadata":{"trusted":true},"cell_type":"code","source":"# separate validation data and evaluation data\nddf = df[(pd.to_datetime(df['date']) < '2016-04-25')&(pd.to_datetime(df['date']) >= '2015-06-19')].drop('date', axis=1)\nvalid_df = df[(pd.to_datetime(df['date']) >= '2016-04-25')&(pd.to_datetime(df['date']) < '2016-05-23')].drop('date', axis=1)\neval_df = df[pd.to_datetime(df['date']) >= '2016-05-23'].drop('date', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_ddf = ddf[cols_x]\ny_ddf = ddf.drop(cols_x, axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(\n         X_ddf, y_ddf, test_size=0.33, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Activation\nfrom keras.callbacks import TensorBoard\nimport keras.backend as K\nEarlyStopping = tf.keras.callbacks.EarlyStopping()\n\n\ndef rmse(y_true, y_pred):\n    return K.sqrt(K.mean(K.square(y_pred -y_true)))\n\nepochs=250\nbatch_size = 96\nverbose = 1\nvalidation_split = 0.2\ninput_dim = X_train.shape[1]\nn_out = y_train.shape[1]\n\nmodel = Sequential([\n                Dense(512, input_shape=(input_dim,)),\n                Activation('relu'),\n                Dropout(0.2),\n                Dense(512),\n                Activation('relu'),\n                Dropout(0.2),\n                Dense(n_out),\n                Activation('relu'),\n                    ])\n\nmodel.compile(loss='mse',\n                 optimizer='adam',\n                 metrics=['mse', rmse])\nhist = model.fit(X_train, y_train,\n                         batch_size = batch_size, epochs = epochs,\n                         callbacks = [EarlyStopping],\n                         verbose=verbose, validation_split=validation_split)\n\nscore = model.evaluate(X_test, y_test, verbose=verbose)\nprint(\"\\nTest score:\", score[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.clf()\nplt.figsize=(15, 10)\nloss = hist.history['loss']\nval_loss = hist.history['val_loss']\nepochs = range(1, len(loss) +1)\n\nplt.plot(epochs, loss, 'bo', label = 'Training loss')\nplt.plot(epochs, val_loss, 'b', label = 'Validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import shap\ndf_train_normed = X_train\ndf_train_normed_summary = shap.kmeans(df_train_normed.values, 25)\n# Instantiate an explainer with the model predictions and training data summary\nexplainer = shap.KernelExplainer(model.predict, df_train_normed_summary)\n# Extract Shapley values from the explainer\nshap_values = explainer.shap_values(df_train_normed.values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# make prediction"},{"metadata":{},"cell_type":"markdown","source":"In this part, we will:\n* make predictions of validation and evaluation periods\n    * validation period: 2016-04-25 to 2016-05-22 （d_1914 - d_1941) \n    * evaluation period: 2016-05-23 to 2016-06-19 （d_1942 - d_1969）\n* visualize the predicted sales of some products"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_valid = valid_df[cols_x]\nX_eval = eval_df[cols_x]\n\n# predict validation and evaluation respectively\npred_valid = pd.DataFrame(model.predict(X_valid), columns = ss[0:int(len(ss)/2)].set_index('id').T.columns)\npred_eval = pd.DataFrame(model.predict(X_eval), columns = ss[int(len(ss)/2):].set_index('id').T.columns)\nss_valid =  pred_valid.T\nss_eval = pred_eval.T\n\n# concatenate val and eval\nsubmission_df = pd.concat([ss_valid, ss_eval]).reset_index()\nsubmission_df.columns = ss.columns\n\nsubmission_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#check some of prediction\nd_cols = [c for c in submission_df.columns if 'F' in c]\npred_example = submission_df.sample(10, random_state=2020).set_index('id')[d_cols].T\n\nfig, axs = plt.subplots(5, 2, figsize=(15, 10))\naxs = axs.flatten()\nax_idx = 0\nfor item in pred_example.columns:\n    pred_example[item].plot(title=item,\n                              ax=axs[ax_idx])\n    ax_idx += 1\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"More:\n* visualize the feature importances of NN model: https://www.kaggle.com/kmatsuyama/shap-feature-importances-plot-of-nn-models"},{"metadata":{},"cell_type":"markdown","source":"Further:\n* more understanding the data\n* feature engineerings based on EDA\n* model tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}