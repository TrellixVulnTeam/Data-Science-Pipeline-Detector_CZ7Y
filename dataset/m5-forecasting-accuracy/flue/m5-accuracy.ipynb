{"cells":[{"metadata":{},"cell_type":"markdown","source":"references:\n\n* https://www.kaggle.com/kyakovlev/m5-simple-fe\n* https://speakerdeck.com/syaorn_13/kaggle-m5-forecasting-accuracy-42nd-place-solution\n* https://www.kaggle.com/anshuls235/time-series-forecasting-eda-fe-modelling#5.-Feature-Engineering"},{"metadata":{},"cell_type":"markdown","source":"### モジュールのインポートとデータの読み込み"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#必要なモジュールのインポート\n\nimport os\nimport pandas as pd\nimport numpy as np\nimport plotly_express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom lightgbm import LGBMRegressor\nimport joblib\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import LabelEncoder\n\n\npd.set_option('display.max_columns', 100)\npd.set_option('display.max_rows', 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#データの読み込み\n\nsales = pd.read_csv('/kaggle/input/m5-forecasting-accuracy/sales_train_evaluation.csv')\nsales.name = 'sales'\ncalendar = pd.read_csv('/kaggle/input/m5-forecasting-accuracy/calendar.csv')\ncalendar.name = 'calendar'\nprices = pd.read_csv('/kaggle/input/m5-forecasting-accuracy/sell_prices.csv')\nprices.name = 'prices'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for d in range(1942,1970):\n    col = 'd_' + str(d)\n    sales[col] = 0\n    sales[col] = sales[col].astype(np.int16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#データのメモリ削減\n#https://www.kaggle.com/fabiendaniel/elo-world\n\ndef downcast(df):\n    cols = df.dtypes.index.tolist()\n    types = df.dtypes.values.tolist()\n    for i,t in enumerate(types):\n        if 'int' in str(t):\n            if df[cols[i]].min() > np.iinfo(np.int8).min and df[cols[i]].max() < np.iinfo(np.int8).max:\n                df[cols[i]] = df[cols[i]].astype(np.int8)\n            elif df[cols[i]].min() > np.iinfo(np.int16).min and df[cols[i]].max() < np.iinfo(np.int16).max:\n                df[cols[i]] = df[cols[i]].astype(np.int16)\n            elif df[cols[i]].min() > np.iinfo(np.int32).min and df[cols[i]].max() < np.iinfo(np.int32).max:\n                df[cols[i]] = df[cols[i]].astype(np.int32)\n            else:\n                df[cols[i]] = df[cols[i]].astype(np.int64)\n        elif 'float' in str(t):\n            if df[cols[i]].min() > np.finfo(np.float16).min and df[cols[i]].max() < np.finfo(np.float16).max:\n                df[cols[i]] = df[cols[i]].astype(np.float16)\n            elif df[cols[i]].min() > np.finfo(np.float32).min and df[cols[i]].max() < np.finfo(np.float32).max:\n                df[cols[i]] = df[cols[i]].astype(np.float32)\n            else:\n                df[cols[i]] = df[cols[i]].astype(np.float64)\n        elif t == np.object:\n            if cols[i] == 'date':\n                df[cols[i]] = pd.to_datetime(df[cols[i]], format='%Y-%m-%d')\n            else:\n                df[cols[i]] = df[cols[i]].astype('category')\n    return df  \n\nsales = downcast(sales)\nprices = downcast(prices)\ncalendar = downcast(calendar)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#データフレームの統合\n\ndf = pd.melt(sales, id_vars=['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'], var_name='d', value_name='sold').dropna()\ndf = pd.merge(df, calendar, on='d', how='left')\ndf = pd.merge(df, prices, on=['store_id','item_id','wm_yr_wk'], how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#インデックスデータの格納\n\nd_id = dict(zip(df.id.cat.codes, df.id))\nd_item_id = dict(zip(df.item_id.cat.codes, df.item_id))\nd_dept_id = dict(zip(df.dept_id.cat.codes, df.dept_id))\nd_cat_id = dict(zip(df.cat_id.cat.codes, df.cat_id))\nd_store_id = dict(zip(df.store_id.cat.codes, df.store_id))\nd_state_id = dict(zip(df.state_id.cat.codes, df.state_id))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#カテゴリ変数のエンコード\nlist1=['event_name_1','event_type_1','event_name_2','event_type_2']\nfor i in list1:\n    df[i] = df[i].cat.add_categories(\"nan\").fillna(\"nan\")\n    df[i]=LabelEncoder().fit_transform(df[i]).astype(np.int8)\n    df[i]=df[i].astype('category')\n    \n#日数の型変換\ndf.d = df['d'].apply(lambda x: x.split('_')[1]).astype(np.int16)\n\n#カテゴリ変数の型変換\ncols = df.dtypes.index.tolist()\ntypes = df.dtypes.values.tolist()\nfor i,type in enumerate(types):\n    if type.name == 'category':\n        df[cols[i]] = df[cols[i]].cat.codes\n\n#日付型に変換\ndf['date'] = df['date'].apply(lambda x: x.strftime('%d')).astype(np.int8)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 特徴量エンジニアリング"},{"metadata":{"trusted":true},"cell_type":"code","source":"#ラグ特徴量の作成\n\nlags = [28,35,42,49]\nfor lag in lags:\n    df['sold_lag_'+str(lag)] = df.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],as_index=False)['sold'].shift(lag).astype(np.float16)\n\nlags2 = [1,2]\nfor lag in lags2:\n    df['event1_lag_'+str(lag)] = df.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],as_index=False)['event_name_1'].shift(lag).astype(np.float16)\n    df['event1_lag_'+str(lag)].fillna(100, inplace=True)\n    df['event1_lag_'+str(lag)]=df['event1_lag_'+str(lag)].astype(np.int8)\n    df['event1_lag_'+str(lag)]=df['event1_lag_'+str(lag)].astype('category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#その他特徴量の作成\n\ndf['item_sold_avg'] = df.groupby('item_id')['sold'].transform('mean').astype(np.float16)    \n#df['state_sold_avg'] = df.groupby('state_id')['sold'].transform('mean').astype(np.float16)\n#df['store_sold_avg'] = df.groupby('store_id')['sold'].transform('mean').astype(np.float16)\ndf['cat_sold_avg'] = df.groupby('cat_id')['sold'].transform('mean').astype(np.float16)\ndf['dept_sold_avg'] = df.groupby('dept_id')['sold'].transform('mean').astype(np.float16)\ndf['cat_dept_sold_avg'] = df.groupby(['cat_id','dept_id'])['sold'].transform('mean').astype(np.float16)\ndf['store_item_sold_avg'] = df.groupby(['store_id','item_id'])['sold'].transform('mean').astype(np.float16)\ndf['cat_item_sold_avg'] = df.groupby(['cat_id','item_id'])['sold'].transform('mean').astype(np.float16)\ndf['dept_item_sold_avg'] = df.groupby(['dept_id','item_id'])['sold'].transform('mean').astype(np.float16)\n#df['state_store_sold_avg'] = df.groupby(['state_id','store_id'])['sold'].transform('mean').astype(np.float16)\n#df['state_store_cat_sold_avg'] = df.groupby(['state_id','store_id','cat_id'])['sold'].transform('mean').astype(np.float16)\ndf['store_cat_dept_sold_avg'] = df.groupby(['store_id','cat_id','dept_id'])['sold'].transform('mean').astype(np.float16)\n\ndf['wm_yr_wk_linear']=LabelEncoder().fit_transform(df['wm_yr_wk'].values).astype(np.int16)\ndf.drop(['wm_yr_wk'], axis=1, inplace=True)\n\ndf['price_lag'] = df.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],as_index=False)['sell_price'].shift(7).astype(np.float16)\ndf['price-diff']=df['price_lag']-df['sell_price']\ndf.drop(['price_lag'], axis=1, inplace=True)\n\ndf['sell_price'].fillna(-1,inplace=True)\ndf['decimal']=df['sell_price'].apply(lambda x: 100*(x-int(x))).astype(np.int16)\ndf['sell_price'].replace(-1,np.nan,inplace=True)\n\ndf['expanding_price_mean'] = df.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'])['sell_price'].transform(lambda x: x.expanding(2).mean()).astype(np.float16)\ndf['diff_moving_mean']=df['expanding_price_mean']-df['sell_price']\ndf.drop(['expanding_price_mean'], axis=1, inplace=True)\n\ndf['price-diff']=df['price-diff'].astype(np.float16)\ndf.drop(['wday'], axis=1, inplace=True)\ndf['decimal']=df['decimal'].astype(np.int8)\ndf['year']=LabelEncoder().fit_transform(df['year']).astype(np.int8)\n\ndf['daily_avg_sold'] = df.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id','d'])['sell_price'].transform('mean').astype(np.float16)\ndf['avg_sold'] = df.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'])['sell_price'].transform('mean').astype(np.float16)\ndf['selling_trend'] = (df['daily_avg_sold'] - df['avg_sold']).astype(np.float16)\ndf.drop(['daily_avg_sold','avg_sold'],axis=1,inplace=True)\n\n\ndf['price_max'] = df.groupby(['store_id','item_id'])['sell_price'].transform('max')\n#df['price_min'] = df.groupby(['store_id','item_id'])['sell_price'].transform('min')\n#df['price_std'] = df.groupby(['store_id','item_id'])['sell_price'].transform('std')\n#df['price_mean'] = df.groupby(['store_id','item_id'])['sell_price'].transform('mean')\ndf['price_norm'] = df['sell_price']/df['price_max']\n#df['price_momentum'] = df['sell_price']/df.groupby(['store_id','item_id'])['sell_price'].transform(lambda x: x.shift(1))\ndf['price_momentum_m'] = df['sell_price']/df.groupby(['store_id','item_id','month'])['sell_price'].transform('mean')\ndf['price_momentum_y'] = df['sell_price']/df.groupby(['store_id','item_id','year'])['sell_price'].transform('mean')\n\n#df['rolling_sold_mean'] = df.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'])['sold'].transform(lambda x: x.rolling(window=7).mean()).astype(np.float16)\n#df['expanding_sold_mean'] = df.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'])['sold'].transform(lambda x: x.expanding(2).mean()).astype(np.float16)\n#df['daily_avg_sold'] = df.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id','d'])['sold'].transform('mean').astype(np.float16)\n#df['avg_sold'] = df.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'])['sold'].transform('mean').astype(np.float16)\n#df['selling_trend'] = (df['daily_avg_sold'] - df['avg_sold']).astype(np.float16)\n#df.drop(['daily_avg_sold','avg_sold'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#不要なカラムの削除\n\nlist3=['cat_id','state_id']\nfor i in list3:\n    df.drop([i], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#データフレームをpklで保存\n\ndf = df[df['d']>=49]\ndf.to_pickle('data.pkl')\ndel df, sales, prices, calendar\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#テストデータの切り出し\n\ndata = pd.read_pickle('data.pkl')\nvalid_csv=data[(data['d']>=1914) & (data['d']<1942)][['id','d','sold']]\ntest = data[data['d']>=1942][['id','d','sold']]\neval_preds = test['sold']\nvalid_preds_csv=valid_csv['sold']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#カテゴリ変数の格納\n\ncat_column=[]\nfor i in data.columns:\n    if(str(data.dtypes[i])=='category'):\n        cat_column.append(i)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### モデル構築"},{"metadata":{"trusted":true},"cell_type":"code","source":"#store_idごとにモデリング\n\nfor store in d_store_id:\n    df = data[data['store_id']==store]\n    \n    X_train, y_train = df[df['d']<1914].drop('sold',axis=1), df[df['d']<1914]['sold']\n    X_valid_csv, y_valid_csv = df[(df['d']>=1914) & (df['d']<1942)].drop('sold',axis=1), df[(df['d']>=1914) & (df['d']<1942)]['sold']\n    X_test = df[df['d']>=1942].drop('sold',axis=1)\n    \n    model = LGBMRegressor(\n        learning_rate= 0.05,\n        subsample=0.6,\n        feature_fraction=0.6,\n        num_iterations = 1200,\n        max_bin=350,\n        num_leaves= 100,\n        lambda_l2=0.003,\n        max_depth=200,\n        min_data_in_leaf= 80,\n        force_row_wise= True,\n    )\n    print('*****Prediction for Store: {}*****'.format(d_store_id[store]))\n    model.fit(X_train, y_train, eval_set=[(X_train,y_train),(X_valid_csv,y_valid_csv)],\n             eval_metric='rmse',  verbose=100, early_stopping_rounds=20,categorical_feature=cat_column)\n    valid_preds_csv[X_valid_csv.index] = model.predict(X_valid_csv)\n    eval_preds[X_test.index] = model.predict(X_test)\n    filename = 'model'+str(d_store_id[store])+'.pkl'\n\n    #モデルの保存\n    joblib.dump(model, filename)\n    del model, X_train, y_train, X_valid_csv, y_valid_csv\n    gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#feature importanceの算出と可視化\n\nfeature_importance_df = pd.DataFrame()\nfeatures = [f for f in data.columns if f != 'sold']\nfor filename in os.listdir('/kaggle/working/'):\n    if 'model' in filename:\n        model = joblib.load(filename)\n        store_importance_df = pd.DataFrame()\n        store_importance_df[\"feature\"] = features\n        store_importance_df[\"importance\"] = model.feature_importances_\n        store_importance_df[\"store\"] = filename[5:9]\n        feature_importance_df = pd.concat([feature_importance_df, store_importance_df], axis=0)\n    \ndef display_importances(feature_importance_df_):\n    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:].index\n    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n    plt.figure(figsize=(8, 10))\n    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n    plt.title('LightGBM Features (averaged over store predictions)')\n    plt.tight_layout()\n    \ndisplay_importances(feature_importance_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### submissionの作成"},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_csv['sold'] = valid_preds_csv\nvalidation = valid_csv[['id','d','sold']]\nvalidation = pd.pivot(validation, index='id', columns='d', values='sold').reset_index()\nvalidation.columns=['id'] + ['F' + str(i + 1) for i in range(28)]\nvalidation.id = validation.id.map(d_id).str.replace('evaluation','validation')\n\ntest['sold'] = eval_preds\nevaluation = test[['id','d','sold']]\nevaluation = pd.pivot(evaluation, index='id', columns='d', values='sold').reset_index()\nevaluation.columns=['id'] + ['F' + str(i + 1) for i in range(28)]\nevaluation.id = evaluation.id.map(d_id)\n\n#提出ファイルの作成\nsubmit = pd.concat([validation,evaluation]).reset_index(drop=True)\n\n#dark magic\n#https://www.kaggle.com/kyakovlev/m5-dark-magic\nfor i in range(1,29):\n    submit['F'+str(i)] *= 1.04\n\nsubmit.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}