{"cells":[{"metadata":{},"cell_type":"markdown","source":"# M5 Forecasting EDA\n<img src=\"https://miro.medium.com/max/3840/0*jn2WJx_mISGppOXM.jpg\" width=\"500\" height=\"300\" />\n\nThe goal of this notebook is to explore the competition dataset, which is a heirarchial time-series data for Walmart sales data.\nThe main data is located in sales_train_validation.csv which describes the sales for a set of items across multiple categoris, departments, states, stores.\n**The price changes!!**\n\nForked from https://www.kaggle.com/robikscube/m5-forecasting-starter-data-exploration"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#imports\nimport os \nimport json\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pylab as plt\nimport seaborn as sns\nfrom itertools import cycle\nfrom tqdm import tqdm\n\npd.set_option('max_columns', 100)\npd.set_option('max_rows', 50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Read the data\ndata_dir = '../input/m5-forecasting-accuracy'\ncal_df = pd.read_csv(os.path.join(data_dir, 'calendar.csv'))\nstv_df = pd.read_csv(os.path.join(data_dir, 'sales_train_validation.csv'))\nsubmission_df = pd.read_csv(os.path.join(data_dir, 'sample_submission.csv'))\nprices_df = pd.read_csv(os.path.join(data_dir, 'sell_prices.csv'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nThe sales number for each day is given in columns d_1 -> d_n\nThe items are specified by 5-tuple: item_id, dept_id, cat_id, store_id, state_id\n\"\"\"\nstv_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# TODO: check how we can use the events? \ncal_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# TODO: check how to aggregate stv with price\nprices_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stv_df_transpose = stv_df.set_index('id').loc[:,'d_1':].T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stv_df_transpose.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cal_df.set_index('d')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = stv_df_transpose.merge(cal_df.set_index('d'),\n                       left_index=True,\n                       right_index=True,\n                        validate='1:1').set_index('date')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"examples = np.random.choice(x.columns, 1)\nexamples_df = x[examples]\nexamples_df.plot(alpha=0.5, figsize=(20,10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# What exactly are we trying to predict?\nWe are trying for forecast sales for 28 forecast days. The sample submission has the following format:\n- The columns represent 28 forecast days. We will fill these forecast days with our predictions.\n- The rows each represent a specific item. This id tells us the item type, state, and store. We don't know what these items are exactly."},{"metadata":{"trusted":true},"cell_type":"code","source":"ss.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are given historic sales data in the `sales_train_validation` dataset.\n- rows exist in this dataset for days d_1 to d_1913. We are given the department, category, state, and store id of the item.\n- d_1914 - d_1941 represents the `validation` rows which we will predict in stage 1\n- d_1942 - d_1969 represents the `evaluation` rows which we will predict for the final competition standings."},{"metadata":{"trusted":true},"cell_type":"code","source":"stv.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualizing the data for a single item\n- Lets take a random item that sell a lot and see how it's sales look across the training data.\n- `FOODS_3_090_CA_3_validation` sells a lot\n- Note there are days where it appears the item is unavailable and sales flatline"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"d_cols = [c for c in stv.columns if 'd_' in c] # sales data columns\n\n# Below we are chaining the following steps in pandas:\n# 1. Select the item.\n# 2. Set the id as the index, Keep only sales data columns\n# 3. Transform so it's a column\n# 4. Plot the data\nstv.loc[stv['id'] == 'FOODS_3_090_CA_3_validation'] \\\n    .set_index('id')[d_cols] \\\n    .T \\\n    .plot(figsize=(15, 5),\n          title='FOODS_3_090_CA_3 sales by \"d\" number',\n          color=next(color_cycle))\nplt.legend('')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Merging the data with real dates\n- We are given a calendar with additional information about past and future dates.\n- The calendar data can be merged with our days data\n- From this we can find weekly and annual trends"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calendar data looks like this (only showing columns we care about for now)\ncal[['d','date','event_name_1','event_name_2',\n     'event_type_1','event_type_2', 'snap_CA']].head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Merge calendar on our items' data\nexample = stv.loc[stv['id'] == 'FOODS_3_090_CA_3_validation'][d_cols].T\nexample = example.rename(columns={8412:'FOODS_3_090_CA_3'}) # Name it correctly\nexample = example.reset_index().rename(columns={'index': 'd'}) # make the index \"d\"\nexample = example.merge(cal, how='left', validate='1:1')\nexample.set_index('date')['FOODS_3_090_CA_3'] \\\n    .plot(figsize=(15, 5),\n          color=next(color_cycle),\n          title='FOODS_3_090_CA_3 sales by actual sale dates')\nplt.show()\n\n# Select more top selling examples\nexample2 = stv.loc[stv['id'] == 'HOBBIES_1_234_CA_3_validation'][d_cols].T\nexample2 = example2.rename(columns={6324:'HOBBIES_1_234_CA_3'}) # Name it correctly\nexample2 = example2.reset_index().rename(columns={'index': 'd'}) # make the index \"d\"\nexample2 = example2.merge(cal, how='left', validate='1:1')\n\nexample3 = stv.loc[stv['id'] == 'HOUSEHOLD_1_118_CA_3_validation'][d_cols].T\nexample3 = example3.rename(columns={6776:'HOUSEHOLD_1_118_CA_3'}) # Name it correctly\nexample3 = example3.reset_index().rename(columns={'index': 'd'}) # make the index \"d\"\nexample3 = example3.merge(cal, how='left', validate='1:1')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Sales broken down by time variables\n- Now that we have our example item lets see how it sells by:\n    - Day of the week\n    - Month\n    - Year"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"examples = ['FOODS_3_090_CA_3','HOBBIES_1_234_CA_3','HOUSEHOLD_1_118_CA_3']\nexample_df = [example, example2, example3]\nfor i in [0, 1, 2]:\n    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 3))\n    example_df[i].groupby('wday').mean()[examples[i]] \\\n        .plot(kind='line',\n              title='average sale: day of week',\n              lw=5,\n              color=color_pal[0],\n              ax=ax1)\n    example_df[i].groupby('month').mean()[examples[i]] \\\n        .plot(kind='line',\n              title='average sale: month',\n              lw=5,\n              color=color_pal[4],\n\n              ax=ax2)\n    example_df[i].groupby('year').mean()[examples[i]] \\\n        .plot(kind='line',\n              lw=5,\n              title='average sale: year',\n              color=color_pal[2],\n\n              ax=ax3)\n    fig.suptitle(f'Trends for item: {examples[i]}',\n                 size=20,\n                 y=1.1)\n    plt.tight_layout()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Lets look at a lot of different items!\n- Lets put it all together to plot 20 different items and their sales\n- Some observations from these plots:\n    - It is common to see an item unavailable for a period of time.\n    - Some items only sell 1 or less in a day, making it very hard to predict.\n    - Other items show spikes in their demand (super bowl sunday?) possibly the \"events\" provided to us could help with these."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"twenty_examples = stv.sample(20, random_state=529) \\\n        .set_index('id')[d_cols] \\\n    .T \\\n    .merge(cal.set_index('d')['date'],\n           left_index=True,\n           right_index=True,\n            validate='1:1') \\\n    .set_index('date')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(10, 2, figsize=(15, 20))\naxs = axs.flatten()\nax_idx = 0\nfor item in twenty_examples.columns:\n    twenty_examples[item].plot(title=item,\n                              color=next(color_cycle),\n                              ax=axs[ax_idx])\n    ax_idx += 1\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Combined Sales over Time by Type\n- We have several item types:\n    - Hobbies\n    - Household\n    - Foods\n- Lets plot the total demand over time for each type"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"stv['cat_id'].unique()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"stv.groupby('cat_id').count()['id'] \\\n    .sort_values() \\\n    .plot(kind='barh', figsize=(15, 5), title='Count of Items by Category')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"past_sales = stv.set_index('id')[d_cols] \\\n    .T \\\n    .merge(cal.set_index('d')['date'],\n           left_index=True,\n           right_index=True,\n            validate='1:1') \\\n    .set_index('date')\n\n\nfor i in stv['cat_id'].unique():\n    items_col = [c for c in past_sales.columns if i in c]\n    past_sales[items_col] \\\n        .sum(axis=1) \\\n        .plot(figsize=(15, 5),\n              alpha=0.8,\n              title='Total Sales by Item Type')\nplt.legend(stv['cat_id'].unique())\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Rollout of items being sold.\n- We can see the some items come into supply that previously didn't exist. Similarly some items stop being sold completely.\n- Lets plot the sales, but only count if item is selling or not selling (0 -> not selling, >0 -> selling)\n- This plot shows us that many items are being slowly introduced into inventory, so many of them will not register a sale at the beginning of the provided data."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"past_sales_clipped = past_sales.clip(0, 1)\nfor i in stv['cat_id'].unique():\n    items_col = [c for c in past_sales.columns if i in c]\n    (past_sales_clipped[items_col] \\\n        .mean(axis=1) * 100) \\\n        .plot(figsize=(15, 5),\n              alpha=0.8,\n              title='Inventory Sale Percentage by Date',\n              style='.')\nplt.ylabel('% of Inventory with at least 1 sale')\nplt.legend(stv['cat_id'].unique())\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Sales by Store\nWe are provided data for 10 unique stores. What are the total sales by stores?\n- Note that some stores are more steady than others.\n- CA_2 seems to have a big change occur in 2015"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"store_list = sellp['store_id'].unique()\nfor s in store_list:\n    store_items = [c for c in past_sales.columns if s in c]\n    past_sales[store_items] \\\n        .sum(axis=1) \\\n        .rolling(90).mean() \\\n        .plot(figsize=(15, 5),\n              alpha=0.8,\n              title='Rolling 90 Day Average Total Sales (10 stores)')\nplt.legend(store_list)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looking at the same data a different way, we can plot a rolling 7 day total demand count by store. Note clearly that some stores have abrupt changes in their demand, it could be that the store expanded or a new competitor was built near by. Either way this is imporant to note when creating predictive models about demand pattern. "},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(5, 2, figsize=(15, 10), sharex=True)\naxes = axes.flatten()\nax_idx = 0\nfor s in store_list:\n    store_items = [c for c in past_sales.columns if s in c]\n    past_sales[store_items] \\\n        .sum(axis=1) \\\n        .rolling(7).mean() \\\n        .plot(alpha=1,\n              ax=axes[ax_idx],\n              title=s,\n              lw=3,\n              color=next(color_cycle))\n    ax_idx += 1\n# plt.legend(store_list)\nplt.suptitle('Weekly Sale Trends by Store ID')\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Sales Heatmap Calendar"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# ----------------------------------------------------------------------------\n# Author:  Nicolas P. Rougier\n# License: BSD\n# ----------------------------------------------------------------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Polygon\nfrom datetime import datetime\nfrom dateutil.relativedelta import relativedelta\n\n\ndef calmap(ax, year, data):\n    ax.tick_params('x', length=0, labelsize=\"medium\", which='major')\n    ax.tick_params('y', length=0, labelsize=\"x-small\", which='major')\n\n    # Month borders\n    xticks, labels = [], []\n    start = datetime(year,1,1).weekday()\n    for month in range(1,13):\n        first = datetime(year, month, 1)\n        last = first + relativedelta(months=1, days=-1)\n\n        y0 = first.weekday()\n        y1 = last.weekday()\n        x0 = (int(first.strftime(\"%j\"))+start-1)//7\n        x1 = (int(last.strftime(\"%j\"))+start-1)//7\n\n        P = [ (x0,   y0), (x0,    7),  (x1,   7),\n              (x1,   y1+1), (x1+1,  y1+1), (x1+1, 0),\n              (x0+1,  0), (x0+1,  y0) ]\n        xticks.append(x0 +(x1-x0+1)/2)\n        labels.append(first.strftime(\"%b\"))\n        poly = Polygon(P, edgecolor=\"black\", facecolor=\"None\",\n                       linewidth=1, zorder=20, clip_on=False)\n        ax.add_artist(poly)\n    \n    ax.set_xticks(xticks)\n    ax.set_xticklabels(labels)\n    ax.set_yticks(0.5 + np.arange(7))\n    ax.set_yticklabels([\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"])\n    ax.set_title(\"{}\".format(year), weight=\"semibold\")\n    \n    # Clearing first and last day from the data\n    valid = datetime(year, 1, 1).weekday()\n    data[:valid,0] = np.nan\n    valid = datetime(year, 12, 31).weekday()\n    # data[:,x1+1:] = np.nan\n    data[valid+1:,x1] = np.nan\n\n    # Showing data\n    ax.imshow(data, extent=[0,53,0,7], zorder=10, vmin=-1, vmax=1,\n              cmap=\"RdYlBu_r\", origin=\"lower\", alpha=.75)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It appears that walmarts are closed on Chirstmas day. The highest demand day of all the data was on Sunday March 6th, 2016. What happened on this day you may ask... well the [Seventh Democratic presidential candidates debate hosted by CNN and held in Flint, Michigan](https://www.onthisday.com/date/2016/march/6)... I doubt that impacted sales though :D"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('The lowest sale date was:', past_sales.sum(axis=1).sort_values().index[0],\n     'with', past_sales.sum(axis=1).sort_values().values[0], 'sales')\nprint('The lowest sale date was:', past_sales.sum(axis=1).sort_values(ascending=False).index[0],\n     'with', past_sales.sum(axis=1).sort_values(ascending=False).values[0], 'sales')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsscale = StandardScaler()\npast_sales.index = pd.to_datetime(past_sales.index)\nfor i in stv['cat_id'].unique():\n    fig, axes = plt.subplots(3, 1, figsize=(20, 8))\n    items_col = [c for c in past_sales.columns if i in c]\n    sales2013 = past_sales.loc[past_sales.index.isin(pd.date_range('31-Dec-2012',\n                                                                   periods=371))][items_col].mean(axis=1)\n    vals = np.hstack(sscale.fit_transform(sales2013.values.reshape(-1, 1)))\n    calmap(axes[0], 2013, vals.reshape(53,7).T)\n    sales2014 = past_sales.loc[past_sales.index.isin(pd.date_range('30-Dec-2013',\n                                                                   periods=371))][items_col].mean(axis=1)\n    vals = np.hstack(sscale.fit_transform(sales2014.values.reshape(-1, 1)))\n    calmap(axes[1], 2014, vals.reshape(53,7).T)\n    sales2015 = past_sales.loc[past_sales.index.isin(pd.date_range('29-Dec-2014',\n                                                                   periods=371))][items_col].mean(axis=1)\n    vals = np.hstack(sscale.fit_transform(sales2015.values.reshape(-1, 1)))\n    calmap(axes[2], 2015, vals.reshape(53,7).T)\n    plt.suptitle(i, fontsize=30, x=0.4, y=1.01)\n    plt.tight_layout()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some interesting things to note from these heatmaps:\n- Food tends to have lower number of purchases as the month goes on. Could this be because people get their paychecks early in the month?\n- Household and Hobby items sell much less in January - after the Holiday season is over.\n- Cleary weekends are more popular shopping days regardless of the item category."},{"metadata":{},"cell_type":"markdown","source":"# Sale Prices\nWe are given historical sale prices of each item. Lets take a look at our example item from before.\n- It looks to me like the price of this item is growing.\n- Different stores have different selling prices."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15, 5))\nstores = []\nfor store, d in sellp.query('item_id == \"FOODS_3_090\"').groupby('store_id'):\n    d.plot(x='wm_yr_wk',\n          y='sell_price',\n          style='.',\n          color=next(color_cycle),\n          figsize=(15, 5),\n          title='FOODS_3_090 sale price over time',\n         ax=ax,\n          legend=store)\n    stores.append(store)\n    plt.legend()\nplt.legend(stores)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"sellp['Category'] = sellp['item_id'].str.split('_', expand=True)[0]\nfig, axs = plt.subplots(1, 3, figsize=(15, 4))\ni = 0\nfor cat, d in sellp.groupby('Category'):\n    ax = d['sell_price'].apply(np.log1p) \\\n        .plot(kind='hist',\n                         bins=20,\n                         title=f'Distribution of {cat} prices',\n                         ax=axs[i],\n                                         color=next(color_cycle))\n    ax.set_xlabel('Log(price)')\n    i += 1\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# A simple submission\n- Submit the average value from the past 30 days"},{"metadata":{"trusted":true},"cell_type":"code","source":"thirty_day_avg_map = stv.set_index('id')[d_cols[-30:]].mean(axis=1).to_dict()\nfcols = [f for f in ss.columns if 'F' in f]\nfor f in fcols:\n    ss[f] = ss['id'].map(thirty_day_avg_map).fillna(0)\n    \nss.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## TODO\n- Simple prediction based on historical average sale by day of week\n- Facebook prophet model\n- lgbm/xgb model based on day features"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}