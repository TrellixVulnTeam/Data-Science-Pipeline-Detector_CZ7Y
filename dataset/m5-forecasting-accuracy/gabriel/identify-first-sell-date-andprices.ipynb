{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Launch Date of Each Item","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Get launch date\n\nprices = pd.read_csv(\"/kaggle/input/m5-forecasting-accuracy/sell_prices.csv\")\nprices['id'] = prices['store_id'] + \"_\" + prices['item_id']\ncal = pd.read_csv(\"/kaggle/input/m5-forecasting-accuracy/calendar.csv\")\ncal = cal[['wm_yr_wk', 'date', 'd']]\ncal['d'] = cal['d'].str.replace(\"d_\", \"\").astype(int)\nprices = prices.merge(cal[['wm_yr_wk', 'd']].groupby(['wm_yr_wk'])[['d']].min().reset_index(), on = 'wm_yr_wk')\nprices = prices.sort_values(['id', 'd'])\nlaunch_date = prices.groupby(['id'])[['d']].min().reset_index()\nlaunch_date.head()\n\nlaunch_date.to_csv(\"m5_launch_date.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Get Prices","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get prices\n\nprices = prices.drop(['d', 'store_id', 'item_id'], axis= 1)\ncal = cal.drop('date', axis = 1)\nprices = prices.merge(cal, on = 'wm_yr_wk')\nprices = prices.drop(['wm_yr_wk'], axis = 1)\nprices = prices.pivot(index = 'id', columns = 'd', values = 'sell_price')\n\n# Remove this line for eventual test set\nprices = prices.iloc[:,:-28]\n\nprices.reset_index().to_csv(\"m5_prices_wide.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Get Weekends","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cal = pd.read_csv(\"/kaggle/input/m5-forecasting-accuracy/calendar.csv\")\n\n# Weekends\n\ncal = pd.read_csv(\"/kaggle/input/m5-forecasting-accuracy/calendar.csv\")\nweekends = cal[['wday']]\nweekends[(weekends['wday'] == 1) | (weekends['wday'] == 2) | (weekends['wday'] == 7)] = 1\nweekends[(weekends['wday'] != 1) & (weekends['wday'] != 2) & (weekends['wday'] != 7)] = 0\n\nweekends.columns = ['weekend']\n\n# Remove for eventual set\nweekends = weekends.iloc[:-28]\n\nweekends.to_csv(\"m5_weekends.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Get SNAP Dates","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Snap\nsales = pd.read_csv(\"/kaggle/input/m5-forecasting-accuracy/sales_train_validation.csv\", usecols = [0,1,2,3,4,5])\nsnap_CA = cal['snap_CA'].values\nsnap_WI = cal['snap_WI'].values\nsnap_TX = cal['snap_TX'].values\nsnap_CA_m = np.repeat(snap_CA.reshape(-1,1), repeats = np.sum(sales['state_id'] == \"CA\"), axis = 1).transpose()\nsnap_TX_m = np.repeat(snap_TX.reshape(-1,1), repeats = np.sum(sales['state_id'] == \"TX\"), axis = 1).transpose()\nsnap_WI_m = np.repeat(snap_WI.reshape(-1,1), repeats = np.sum(sales['state_id'] == \"WI\"), axis = 1).transpose()\nsnap = np.concatenate([snap_CA_m, snap_TX_m, snap_WI_m], axis = 0)\n\nsnap = pd.DataFrame(snap)\n\n# remove for final set\nsnap.iloc[:, :-28].to_csv(\"snap.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Get Holidays","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# holidays\nlist_of_hols = list(set(np.append(cal['event_name_1'].unique(), cal['event_name_2'].unique())))[1:]\n\nholidays = cal.loc[(cal['event_name_1'] == list_of_hols[0]) | (cal['event_name_2'] == list_of_hols[0]), ['date', 'event_name_1', 'date','event_name_2']]\n\nfor i in list_of_hols[1:]:\n    holidays = holidays.append(cal.loc[(cal['event_name_1'] == i) | (cal['event_name_2'] == i), ['date', 'event_name_1', 'date','event_name_2']])\n    \nholidays_m = holidays.iloc[:,:2].rename(columns = {'event_name_1':'holiday'}).append(holidays.iloc[:,2:].rename(columns = {'event_name_2':'holiday'}))\n\nholidays_m = holidays_m.dropna()\n\nholidays_m = holidays_m[['holiday', 'date']]\nholidays_m.columns = ['holiday', 'ds']\nholidays_m['lower_window'] = 0\nholidays_m['upper_window'] = 0\n\nholidays_m.loc[holidays_m['holiday'] == \"Thanksgiving\",'lower_window'] = -1\nholidays_m.loc[holidays_m['holiday'] == \"Thanksgiving\",'upper_window'] = 1\n\nholidays_m.loc[holidays_m['holiday'] == \"Christmas\",'lower_window'] = -1\nholidays_m.loc[holidays_m['holiday'] == \"Christmas\",'upper_window'] = 1\n\nholidays_m.loc[holidays_m['holiday'] == \"Easter\",'lower_window'] = -2\n\nholidays_m.loc[holidays_m['holiday'] == \"Eid al-Fitr\",'lower_window'] = -1\nholidays_m.loc[holidays_m['holiday'] == \"Eid al-Fitr\",'upper_window'] = 1\n\n\nholidays_m['ds'] = pd.to_datetime(holidays_m['ds'])\n\nholidays_m.to_csv(\"m5_holidays.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Some Optional Feature: (A) Cumulative Max, (B) Cumulative Number of Zero Sales, (C) Percenatge of Zero Sales in the last (7/14/28/56) days ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Cumulative Max","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sales = pd.read_csv(\"/kaggle/input/m5-forecasting-accuracy/sales_train_validation.csv\")\nsale_hist = sales.iloc[:,6:]\ncumulative_max = sale_hist.transpose().cummax().transpose()\nextra = pd.DataFrame(np.repeat(cumulative_max.iloc[:,-1].values.reshape(-1,1), repeats = 28, axis = 1))\nextra.columns = extra.columns + 1914\ncumulative_max = pd.concat([cumulative_max, extra], axis = 1)\ncumulative_max.to_csv(\"cumulative_max.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Freq of Zero Sales in the last t days","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sale_hist = sales.iloc[:,6:]\nsale_hist[sale_hist != 0] = 2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sale_hist[sale_hist == 0] = 1\nsale_hist[sale_hist == 2] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cum_7_freq_zero = sale_hist.transpose().rolling(7).mean().transpose()\ncum_14_freq_zero = sale_hist.transpose().rolling(14).mean().transpose()\ncum_28_freq_zero = sale_hist.transpose().rolling(28).mean().transpose()\ncum_56_freq_zero = sale_hist.transpose().rolling(56).mean().transpose()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"extra = pd.DataFrame(np.repeat(cum_7_freq_zero.iloc[:,-1].values.reshape(-1,1), repeats = 28, axis = 1))\nextra.columns = extra.columns + 1914\ncum_7_freq_zero = pd.concat([cum_7_freq_zero, extra], axis = 1)\n\nextra = pd.DataFrame(np.repeat(cum_14_freq_zero.iloc[:,-1].values.reshape(-1,1), repeats = 28, axis = 1))\nextra.columns = extra.columns + 1914\ncum_14_freq_zero = pd.concat([cum_14_freq_zero, extra], axis = 1)\n\nextra = pd.DataFrame(np.repeat(cum_28_freq_zero.iloc[:,-1].values.reshape(-1,1), repeats = 28, axis = 1))\nextra.columns = extra.columns + 1914\ncum_28_freq_zero = pd.concat([cum_28_freq_zero, extra], axis = 1)\n\nextra = pd.DataFrame(np.repeat(cum_56_freq_zero.iloc[:,-1].values.reshape(-1,1), repeats = 28, axis = 1))\nextra.columns = extra.columns + 1914\ncum_56_freq_zero = pd.concat([cum_56_freq_zero, extra], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cum_7_freq_zero.fillna(0).to_csv(\"cum_7_freq_zero.csv\", index = False)\ncum_14_freq_zero.fillna(0).to_csv(\"cum_14_freq_zero.csv\", index = False)\ncum_28_freq_zero.fillna(0).to_csv(\"cum_28_freq_zero.csv\", index = False)\ncum_56_freq_zero.fillna(0).to_csv(\"cum_56_freq_zero.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cum_zero = sale_hist.transpose().cumsum().transpose()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Cumulative Zeros","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"history_zeros = (cum_zero.values - np.repeat(launch_date['d'].values.reshape(-1,1) - 1, repeats = 1913, axis = 1)) - 1\nhistory_zeros[history_zeros < 0] = 0\ncumulative_zero = pd.DataFrame(np.concatenate([history_zeros, np.repeat(history_zeros[:,-1].reshape(-1,1), 28, axis = 1)], axis = 1))\ncumulative_zero.to_csv(\"cumulative_zero.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DF to store results when training","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/m5-forecasting-accuracy/sample_submission.csv\")\ndf2 = pd.DataFrame(np.zeros([30490, 1913])).astype(int)\n\ndf3 = df.drop(['id'], axis = 1)\ndf3.columns = list(np.arange(1914, 1914+28))\ndf2.columns = df2.columns + 1\ndf_sample = pd.concat([df[['id']].head(30490), df2.astype(int), df3.head(30490)], axis = 1)\ndf_sample.to_csv(\"holder.csv\", index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}