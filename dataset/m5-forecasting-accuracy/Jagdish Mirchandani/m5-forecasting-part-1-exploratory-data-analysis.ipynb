{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\nWelcome to the \"M5 Forecasting - Accuracy\" competition! In this competition, contestants are challenged to forecast future sales at Walmart based on heirarchical sales in the states of California, Texas, and Wisconsin.\n\n# Task in hand\nIn this competition, we need to forecast the sales for [d_1942 - d_1969]. These rows form the test set.\n\nThe rows Â [d_1914 - d_1941] form the validation set.\n\nRemaining rows form the training set.\n\n# Appeal to fellow Kagglers:)\nThis is my first attempt towards a time series problem, so, please upvote this kernel,your upvote will be like a reward for my work.\n\n# This notebook will cover only EDA"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom plotly.subplots import make_subplots\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\nfrom tqdm.notebook import tqdm as tqdm\nimport statsmodels.api as sm\nimport gc\nplt.style.use('fivethirtyeight')\nfrom pylab import rcParams\nimport random\nimport seaborn as sns\nfrom lightgbm import LGBMRegressor\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to display all the columns in the dataset\npd.pandas.set_option('display.max_columns', None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Lets check the datasets"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_sales = pd.read_csv(\"../input/m5-forecasting-accuracy/sales_train_evaluation.csv\")\ncalendar = pd.read_csv(\"../input/m5-forecasting-accuracy/calendar.csv\")\nsell_prices = pd.read_csv(\"../input/m5-forecasting-accuracy/sell_prices.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_sales.shape, calendar.shape,sell_prices.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_sales.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"calendar.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sell_prices.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_sales.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are lots of zeros in the datasets for \"d_x\" columns, these are nothing bul sale values on any given day, zero here signfies, either the item was not available on that day or was not sold because of no demand."},{"metadata":{"trusted":true},"cell_type":"code","source":"calendar.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sell_prices.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Lets check for null values"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_sales.isnull().sum().sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sell_prices.isnull().sum().sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"calendar.isnull().sum().sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Memory Reduction\n\nWe have a huge dataset to work on, and before feeding this dataset into the model, we are going to \"Melt\" it which would the data fram would be converted from wide format to a long format. I have kept the id variables as id, item_id, dept_id, cat_id, store_id and state_id. They have in total 30490 unique values when compunded together. Now the total number of days for which we have the data is 1969 days. Therefore the melted dataframe will be having 30490x1969 i.e. 60034810 rows.\n\nIn order to process to such huge dataset, we would need to reduce the memor usage. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# memory usage reduction\ndef downcast(df):\n    cols = df.dtypes.index.tolist()\n    types = df.dtypes.values.tolist()\n    for i,t in enumerate(types):\n        if 'int' in str(t):\n            if df[cols[i]].min() > np.iinfo(np.int8).min and df[cols[i]].max() < np.iinfo(np.int8).max:\n                df[cols[i]] = df[cols[i]].astype(np.int8)\n            elif df[cols[i]].min() > np.iinfo(np.int16).min and df[cols[i]].max() < np.iinfo(np.int16).max:\n                df[cols[i]] = df[cols[i]].astype(np.int16)\n            elif df[cols[i]].min() > np.iinfo(np.int32).min and df[cols[i]].max() < np.iinfo(np.int32).max:\n                df[cols[i]] = df[cols[i]].astype(np.int32)\n            else:\n                df[cols[i]] = df[cols[i]].astype(np.int64)\n        elif 'float' in str(t):\n            if df[cols[i]].min() > np.finfo(np.float16).min and df[cols[i]].max() < np.finfo(np.float16).max:\n                df[cols[i]] = df[cols[i]].astype(np.float16)\n            elif df[cols[i]].min() > np.finfo(np.float32).min and df[cols[i]].max() < np.finfo(np.float32).max:\n                df[cols[i]] = df[cols[i]].astype(np.float32)\n            else:\n                df[cols[i]] = df[cols[i]].astype(np.float64)\n        elif t == np.object:\n            if cols[i] == 'date':\n                df[cols[i]] = pd.to_datetime(df[cols[i]], format='%Y-%m-%d')\n            else:\n                df[cols[i]] = df[cols[i]].astype('category')\n    return df  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# calling memory reduction function for each data set\ntrain_sales = downcast(train_sales)\nsell_prices = downcast(sell_prices)\ncalendar = downcast(calendar)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's save the list of date variables to a list\nd_cols = [c for c in train_sales.columns if 'd_' in c]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets save top 3 selling items to be analysed later\ntop3 = train_sales.set_index(\"id\")[d_cols].sum(1).sort_values(ascending  = False)[:3].index","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Melting the dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_df = pd.melt(train_sales, \n                  id_vars = ['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'], \n                  var_name = 'd', \n                  value_name = \"sales\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"group = grid_df.groupby(['state_id','store_id','cat_id','dept_id'],as_index=False)['sales'].sum().dropna()\ngroup['USA'] = 'United States of America'\ngroup.rename(columns={'state_id':'State','store_id':'Store','cat_id':'Category','dept_id':'Department','item_id':'sales'},inplace=True)\nfig = px.treemap(group, path=['USA','State', 'Store', 'Category', 'Department'], values='sales',\n                  color='sales',\n                  title='Sum of sales across whole USA/different States/Stores/Categories/Departments')\nfig.update_layout(template='seaborn')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train_sales\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets drop the columns we are not going to use for EDA\ncalendar.drop(['wm_yr_wk','weekday','wday','month','year','event_name_1','event_type_1', 'event_name_2','event_type_2'],1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create a master dataset by merging melted dataset and the calendar dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"master = pd.merge(grid_df,calendar, on = \"d\")\nmaster.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del grid_df\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Helper Functions\n    1. sales: To plot graphs for sales of different categories\n    2. decompose: This function will decompose the given time series into three parts, \"seasonal\", \"trend\" and \"observed\"\n    3. random_color: This function will pick a random color for the graph calling this function."},{"metadata":{"trusted":true},"cell_type":"code","source":"def sales(feat,param):\n    sales_df = master.loc[master[feat] == param]\n    sales_df['date'] = pd.to_datetime(sales_df['date'])\n    sales_df =sales_df.groupby('date')['sales'].sum().reset_index()\n    sales_df = sales_df.set_index('date')\n    return sales_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from itertools import cycle, islice\ndef decompose(y):\n    rcParams['figure.figsize'] = 18, 8\n    decomposition = sm.tsa.seasonal_decompose(y, model='additive')\n    fig = decomposition.plot()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def random_color():\n    colors = [\"blue\",\"black\",\"brown\",\"red\",\"yellow\",\"green\",\"orange\",\"turquoise\",\"magenta\",\"cyan\"]\n    random.shuffle(colors)\n    return colors[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# STATE WISE SALES\n\nLet's take a look at the state wise sales\n\nWe will preprocess our data a little bit before moving forward. Daily data can be tricky to work with since itâs a briefer amount of time, so letâs use monthly averages instead. Weâll make the conversion with the resample function."},{"metadata":{"trusted":true},"cell_type":"code","source":"# list of unique states\nmaster.state_id.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CA = sales(\"state_id\",\"CA\") # create a dataframe for the state CA\ny_ca = CA['sales'].resample('MS').mean() # taking monthly average\ncolour = random_color()\ny_ca.plot(figsize=(15, 6),color = colour,title = (\"Sales for the state of CA\"))\nplt.ylabel = (\"Sales\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some distinguishable patterns appear when we plot the data. \nThe time-series has seasonality pattern, such as sales are always low at the beginning of the year and high at the mid of the year. \nThere is always an upward trend within any single year."},{"metadata":{},"cell_type":"markdown","source":"We can also visualize our data using a method called time-series decomposition that allows us to decompose our time series into three distinct components: trend, seasonality, and noise."},{"metadata":{"trusted":true},"cell_type":"code","source":"decompose(y_ca)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The plot above clearly shows that the sales of state CA is unstable, along with its obvious seasonality."},{"metadata":{"trusted":true},"cell_type":"code","source":"WI = sales(\"state_id\",\"WI\")\ny_wi = WI['sales'].resample('MS').mean()\ncolour = random_color()\ny_wi.plot(figsize=(15, 6),color = colour,title = (\"Sales for the state of WI\"))\nplt.ylabel = (\"Sales\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some distinguishable patterns appear when we plot the data. The time-series has seasonality pattern, such as sales are always low at the beginning of the year and high at the mid of the year. There is always an upward trend within any single year."},{"metadata":{"trusted":true},"cell_type":"code","source":"decompose(y_wi)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The plot above clearly shows that the sales of state CA is unstable, along with its obvious seasonality."},{"metadata":{"trusted":true},"cell_type":"code","source":"TX = sales(\"state_id\",\"TX\")\ny_tx = TX['sales'].resample('MS').mean()\ncolour = random_color()\ny_tx.plot(figsize=(15, 6),color = colour,title = (\"Sales for the state of TX\"))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Sales are not very different from the other states."},{"metadata":{"trusted":true},"cell_type":"code","source":"decompose(y_tx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del CA,WI,TX\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CATEGORY WISE SALES\n\nLet's take a look at the category wise sales"},{"metadata":{"trusted":true},"cell_type":"code","source":"# list of unique categories\nmaster.cat_id.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"foods = sales(\"cat_id\",\"FOODS\")\ny_f = foods['sales'].resample('MS').mean()\ncolour = random_color()\ny_f.plot(figsize=(15, 6),color = colour,title = (\"Sales for the category:FOODS\"))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decompose(y_f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hobbies = sales(\"cat_id\",\"HOBBIES\")\ny_hb = hobbies['sales'].resample('MS').mean()\ncolour = random_color()\nplt.ylabel = (\"Sales\")\ny_hb.plot(figsize=(15, 6),color = colour,title = (\"Sales for the category:HOBBIES\"))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decompose(y_hb)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"household = sales(\"cat_id\",\"HOUSEHOLD\")\ny_hh = household['sales'].resample('MS').mean()\ncolour = random_color()\ny_hh.plot(figsize=(15, 6),color = colour,title = (\"Sales for the category:HOUSEHOLD\"))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decompose(y_hh)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del foods,hobbies,household,y_f,y_hb,y_hh\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# STORE WISE SALES"},{"metadata":{"trusted":true},"cell_type":"code","source":"master.store_id.unique","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CA_1 = sales(\"store_id\",\"CA_1\")\ny_CA1 = CA_1['sales'].resample('MS').mean()\ncolour = random_color()\ny_CA1.plot(figsize=(15, 6),color = colour,title = (\"Sales for the store:CA_1\"))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decompose(y_CA1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CA_2 = sales(\"store_id\",\"CA_2\")\ny_CA2 = CA_2['sales'].resample('MS').mean()\ncolour = random_color()\ny_CA2.plot(figsize=(15, 6),color = colour,title = (\"Sales for the store:CA_2\"))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decompose(y_CA2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CA_3 = sales(\"store_id\",\"CA_3\")\ny_CA3 = CA_3['sales'].resample('MS').mean()\ncolour = random_color()\ny_CA3.plot(figsize=(15, 6),color = colour,title = \"Sales for the store:CA_3\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decompose(y_CA3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CA_4 = sales(\"store_id\",\"CA_4\")\ny_CA4 = CA_4['sales'].resample('MS').mean()\ncolour = random_color()\ny_CA4.plot(figsize=(15, 6),color = colour,title = (\"Sales for the store:CA_4\"))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decompose(y_CA4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TX_1 = sales(\"store_id\",\"TX_1\")\ny_TX1 = TX_1['sales'].resample('MS').mean()\ncolour = random_color()\ny_TX1.plot(figsize=(15, 6),color = colour,title = (\"Sales for the store:TX_1\"))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decompose(y_TX1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TX_2 = sales(\"store_id\",\"TX_2\")\ny_TX2 = TX_2['sales'].resample('MS').mean()\ncolour = random_color()\nplt.ylabel = (\"Sales\")\ny_TX2.plot(figsize=(15, 6),color = colour,title = (\"Sales for the store:TX_2\"))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decompose(y_TX2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TX_3 = sales(\"store_id\",\"TX_3\")\ny_TX3 = TX_3['sales'].resample('MS').mean()\ncolour = random_color()\nplt.ylabel = (\"Sales\")\ny_TX3.plot(figsize=(15, 6),color = colour,title = (\"Sales for the store:TX_3\"))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decompose(y_TX3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"WI_1 = sales(\"store_id\",\"WI_1\")\ny_WI1 = WI_1['sales'].resample('MS').mean()\ncolour = random_color()\nplt.ylabel = (\"Sales\")\ny_WI1.plot(figsize=(15, 6),color = colour,title = (\"Sales for the store:WI_1\"))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decompose(y_WI1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"WI_2= sales(\"store_id\",\"WI_2\")\ny_WI2 = WI_2['sales'].resample('MS').mean()\ncolour = random_color()\nplt.ylabel = (\"Sales\")\ny_WI2.plot(figsize=(15, 6),color = colour,title = (\"Sales for the store:WI_2\"))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decompose(y_WI2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"WI_3= sales(\"store_id\",\"WI_3\")\ny_WI3 = WI_3['sales'].resample('MS').mean()\ncolour = random_color()\nplt.ylabel = (\"Sales\")\ny_WI3.plot(figsize=(15, 6),color = colour,title = (\"Sales for the store:WI_3\"))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decompose(y_WI3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del CA_1,CA_2,CA_3,CA_4,TX_1,TX_2,TX_3,WI_1,WI_2,WI_3\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# TOP SELLING PRODUCTS"},{"metadata":{"trusted":true},"cell_type":"code","source":"top = sales(\"id\",top3[0])\ny_top = top['sales'].resample('MS').mean()\ncolour = random_color()\ny_top.plot(figsize=(15, 6),color = colour,title = (\"Sales for the Product:\" + top3[0]))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top = sales(\"id\",top3[1])\ny_top = top['sales'].resample('MS').mean()\ncolour = random_color()\ny_top.plot(figsize=(15, 6),color = colour,title = (\"Sales for the Product:\" + top3[1]))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top = sales(\"id\",top3[2])\ny_top = top['sales'].resample('MS').mean()\ncolour = random_color()\ny_top.plot(figsize=(15, 6),color = colour,title = (\"Sales for the Product:\" + top3[2]))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del top3,y_top\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# PRICE DISTRIBUTION"},{"metadata":{"trusted":true},"cell_type":"code","source":"colour = random_color()\nsns.distplot(sell_prices[\"sell_price\"],color = colour).set_title(\"Price Distribution\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colour = random_color()\nCA_1= sell_prices[sell_prices[\"store_id\"] == \"CA_1\"]\nsns.distplot(CA_1[\"sell_price\"],color = colour).set_title(\"Price Distribution for CA_1\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colour = random_color()\nCA_2= sell_prices[sell_prices[\"store_id\"] == \"CA_2\"]\nsns.distplot(CA_2[\"sell_price\"],color = colour).set_title(\"Price Distribution for CA_2\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colour = random_color()\nCA_3= sell_prices[sell_prices[\"store_id\"] == \"CA_3\"]\nsns.distplot(CA_3[\"sell_price\"],color = colour).set_title(\"Price Distribution for CA_3\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colour = random_color()\nCA_4= sell_prices[sell_prices[\"store_id\"] == \"CA_4\"]\nsns.distplot(CA_4[\"sell_price\"],color = colour).set_title(\"Price Distribution for CA_4\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colour = random_color()\nTX_1= sell_prices[sell_prices[\"store_id\"] == \"TX_1\"]\nsns.distplot(TX_1[\"sell_price\"],color = colour).set_title(\"Price Distribution for TX_1\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colour = random_color()\nTX_2= sell_prices[sell_prices[\"store_id\"] == \"TX_2\"]\nsns.distplot(TX_2[\"sell_price\"],color = colour).set_title(\"Price Distribution for TX_2\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colour = random_color()\nTX_3= sell_prices[sell_prices[\"store_id\"] == \"TX_3\"]\nsns.distplot(TX_3[\"sell_price\"],color = colour).set_title(\"Price Distribution for TX_3\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colour = random_color()\nWI_1= sell_prices[sell_prices[\"store_id\"] == \"WI_1\"]\nsns.distplot(WI_1[\"sell_price\"],color = colour).set_title(\"Price Distribution for WI_1\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colour = random_color()\nWI_2= sell_prices[sell_prices[\"store_id\"] == \"WI_2\"]\nsns.distplot(WI_2[\"sell_price\"],color = colour).set_title(\"Price Distribution for WI_2\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colour = random_color()\nWI_3= sell_prices[sell_prices[\"store_id\"] == \"WI_3\"]\nsns.distplot(WI_3[\"sell_price\"],color = colour).set_title(\"Price Distribution for WI_3\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del sell_prices,CA_1,CA_2,CA_3,CA_4,TX_1,TX_2,TX_3,WI_1,WI_2,WI_3\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Link to model building notebook: https://www.kaggle.com/jagdmir/m5-forecasting-part-two-lgbm-regressor"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}