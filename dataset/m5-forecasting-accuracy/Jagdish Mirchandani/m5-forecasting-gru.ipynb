{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"# Introduction\nWelcome to the \"M5 Forecasting - Accuracy\" competition! In this competition, contestants are challenged to forecast future sales at Walmart based on heirarchical sales in the states of California, Texas, and Wisconsin.\n\n# Task in hand\nIn this competition, we need to forecast the sales for [d_1942 - d_1969]. These rows form the test set.\n\nThe rows  [d_1914 - d_1941] form the validation set.\n\nRemaining rows form the training set.\n\n    This notebook covers Modelling only, to check EDA, check https://www.kaggle.com/jagdmir/m5-forecasting-part-one-eda."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use(\"dark_background\")\nimport gc\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, Callback\nimport tensorflow as tf\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Flatten,Embedding,Activation,Dropout\nfrom keras.layers import Conv1D,MaxPooling1D,GlobalMaxPooling1D,LSTM\nfrom keras.layers import Bidirectional\nfrom sklearn.preprocessing import MinMaxScaler","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# load data\ntrain = pd.read_csv(\"/kaggle/input/m5-forecasting-accuracy/sales_train_evaluation.csv\")\ncalendar = pd.read_csv(\"/kaggle/input/m5-forecasting-accuracy/calendar.csv\")\nsell_prices = pd.read_csv(\"/kaggle/input/m5-forecasting-accuracy/sell_prices.csv\")\nsample = pd.read_csv(\"/kaggle/input/m5-forecasting-accuracy/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape,calendar.shape,sell_prices.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"calendar.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Let's take a sneak peek of the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop(['item_id','dept_id','cat_id','store_id','state_id'],1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"calendar.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sell_prices.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Check Null Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum().sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lots of zeros above shows particular item was either not sold on that particular day or was not in stock"},{"metadata":{"trusted":true},"cell_type":"code","source":"calendar.isnull().sum().sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Memory Usage Reduction\n\nWe need to melt the dataset in order to proceed further. but before we do that, we need to reduce the memory usage. if we dont reduce memory usage, we may get memory usage errors."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Downcast in order to save memory\ndef downcast(df):\n    cols = df.dtypes.index.tolist()\n    types = df.dtypes.values.tolist()\n    for i,t in enumerate(types):\n        if 'int' in str(t):\n            if df[cols[i]].min() > np.iinfo(np.int8).min and df[cols[i]].max() < np.iinfo(np.int8).max:\n                df[cols[i]] = df[cols[i]].astype(np.int8)\n            elif df[cols[i]].min() > np.iinfo(np.int16).min and df[cols[i]].max() < np.iinfo(np.int16).max:\n                df[cols[i]] = df[cols[i]].astype(np.int16)\n            elif df[cols[i]].min() > np.iinfo(np.int32).min and df[cols[i]].max() < np.iinfo(np.int32).max:\n                df[cols[i]] = df[cols[i]].astype(np.int32)\n            else:\n                df[cols[i]] = df[cols[i]].astype(np.int64)\n        elif 'float' in str(t):\n            if df[cols[i]].min() > np.finfo(np.float16).min and df[cols[i]].max() < np.finfo(np.float16).max:\n                df[cols[i]] = df[cols[i]].astype(np.float16)\n            elif df[cols[i]].min() > np.finfo(np.float32).min and df[cols[i]].max() < np.finfo(np.float32).max:\n                df[cols[i]] = df[cols[i]].astype(np.float32)\n            else:\n                df[cols[i]] = df[cols[i]].astype(np.float64)\n        elif t == np.object:\n            if cols[i] == 'date':\n                df[cols[i]] = pd.to_datetime(df[cols[i]], format='%Y-%m-%d')\n            else:\n                df[cols[i]] = df[cols[i]].astype('category')\n    return df  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = downcast(train)\nsell_prices = downcast(sell_prices)\ncalendar = downcast(calendar)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(1942,1970):\n    col = \"d_\"+ str(i)\n    train[col] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_new = train.T\ntrain_new.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_new = train_new[1:]\ntrain_new","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_new.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sc = MinMaxScaler(feature_range = (0, 1))\ntrain_new = sc.fit_transform(train_new)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train_new)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# training data, from 0 to 1913\nX = []\nlookup = 14\nfor i in range(0,1899): \n    X.append(train_new[i:i+lookup])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"j=0\ny=[]\nfor i in range(lookup,1913):    \n    y.append(train_new[i][0:30490])\nprint(len(y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test train split \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = np.array(X_train, dtype = 'float16')\ny_train = np.array(y_train, dtype = 'float16')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape,y_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import LSTM\nfrom keras.layers import GRU\n\nmodel = Sequential()\n\nmodel.add(GRU(64,input_shape=(np.array(X_train).shape[1], np.array(X_train).shape[2]),return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(GRU(64,return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(GRU(64,return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(GRU(64))\nmodel.add(Dropout(0.2))\n\nmodel.add(tf.keras.layers.Dense(30490))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(\n  loss='mse',\n  metrics=[tf.keras.metrics.MeanSquaredError()],\n  optimizer=tf.keras.optimizers.Adam(0.001)\n)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(X_train, y_train,\nepochs=20,\nbatch_size=10,\nvalidation_split=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history.history['mean_squared_error']\nval_acc = history.history['val_mean_squared_error']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction on X_test"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n\nX_test_1 = np.array(X_test[0:14])\ny_test_1 = np.array(y_test[0:14])\n\ny_test_pred = np.array(model.predict(X_test_1))\n\ny_test_pred = sc.inverse_transform(y_test_pred)\ny_test_1 = sc.inverse_transform(y_test_1)\n\nmean_squared_error(y_test_1,y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predict for validation time frame"},{"metadata":{"trusted":true},"cell_type":"code","source":"# validation data, from d_1914 - d_1941\nval = []\nlookup = 14\nfor i in range(1913,1941):  \n    val.append(train_new[i:i+lookup])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.array(val).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.array(y_val).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val1 = np.array(val[:14])\nval1.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val2 = np.array(val[14:])\nval2.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_val1_pred = model.predict(val1)\nnp.array(y_val1_pred).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_val2_pred = model.predict(val2)\nnp.array(y_val2_pred).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_val_pred = np.concatenate((y_val1_pred,y_val2_pred))\nnp.array(y_val_pred).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_val_pred = sc.inverse_transform(y_val_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predict for test time frame"},{"metadata":{"trusted":true},"cell_type":"code","source":"test =y_val_pred.reshape(28,1,30490)\nnp.array(test).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test1 = test[0:14]\nnp.array(test1).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test2 = test[14:]\nnp.array(test2).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred1 = model.predict(test1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred2 = model.predict(test2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred = np.concatenate((test_pred1,test_pred2))\nnp.array(test_pred).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred = sc.inverse_transform(test_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv(\"../input/m5-forecasting-accuracy/sample_submission.csv\")\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_ids = sub.id\nsub.drop('id',1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub[0:30490] = test_pred[0:30490].T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub[30490:60980] = test_pred[0:30490].T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.insert(loc=0, column='id', value=sub_ids)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}