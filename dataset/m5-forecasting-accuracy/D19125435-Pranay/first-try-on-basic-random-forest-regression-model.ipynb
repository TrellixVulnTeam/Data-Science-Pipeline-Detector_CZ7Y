{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction"},{"metadata":{},"cell_type":"markdown","source":"The Makridakis Open Forecasting Center (MOFC) at the University of Nicosia conducts cutting-edge forecasting research and provides business forecast training. It helps companies achieve accurate predictions, estimate the levels of uncertainty, avoiding costly mistakes, and apply best forecasting practices. The MOFC is well known for its Makridakis Competitions, the first of which ran in the 1980s."},{"metadata":{},"cell_type":"markdown","source":"# Problem Statement"},{"metadata":{},"cell_type":"markdown","source":"**Will use hierarchical sales data from Walmart, the worldâ€™s largest company by revenue, to forecast daily sales for the next 28 days.\n**"},{"metadata":{},"cell_type":"markdown","source":"# About Data "},{"metadata":{},"cell_type":"markdown","source":"The data, covers stores in three US States (California, Texas, and Wisconsin) and includes item level, department, product categories, and store details. In addition, it has explanatory variables such as price, promotions, day of the week, and special events. Together, this robust dataset can be used to improve forecasting accuracy. In the challenge, we are predicting item sales at stores in various locations for two 28-day time periods. Information about the data is found in the https://mofc.unic.ac.cy/m5-competition/\n"},{"metadata":{},"cell_type":"markdown","source":"**Data Files:** \n* calendar.csv - Contains information about the dates on which the products are sold.\n* sales_train_validation.csv - Contains the historical daily unit sales data per product and store [d_1 - d_1913]\n* sample_submission.csv - The correct format for submissions.\n* sell_prices.csv - Contains information about the price of the products sold per store and date.\n* sales_train_evaluation.csv - Available once month before competition deadline. Will include sales [d_1 - d_1941]\n"},{"metadata":{},"cell_type":"markdown","source":"# Index\n1. Import packages\n2. Read dataset \n3. Data Summary\n4. Data Exploration\n5. Feature Selection & Modeling\n6. Validation"},{"metadata":{},"cell_type":"markdown","source":"**1. Import Packages**"},{"metadata":{"trusted":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import FormatStrFormatter\nimport seaborn as sn\nfrom matplotlib import cm\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import r2_score,mean_squared_error\nfrom sklearn.preprocessing import LabelEncoder,OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\n# Only necessary in Jupyter notebook\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**2. Read dataset**"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false},"cell_type":"code","source":"\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"calendar = pd.read_csv(\"/kaggle/input/m5-forecasting-accuracy/calendar.csv\")\nsell_prices = pd.read_csv(\"/kaggle/input/m5-forecasting-accuracy/sell_prices.csv\")\nsales_train_validation = pd.read_csv(\"/kaggle/input/m5-forecasting-accuracy/sales_train_validation.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**3. Data Summary**"},{"metadata":{"trusted":false},"cell_type":"code","source":"calendar[\"event_type_1_snap\"] = pd.notna(calendar[\"event_type_1\"]) \ncalendar[\"event_type_2_snap\"] = pd.notna(calendar[\"event_type_2\"]) \ncalendar[\"date\"] =  pd.to_datetime(calendar[\"date\"])\ncalendar[\"d_month\"] = calendar[\"date\"].dt.day\ncalendar[\"year\"] = pd.to_numeric(calendar[\"year\"])\ncalendar[\"wday\"] = pd.to_numeric(calendar[\"wday\"])\nprint(calendar.shape)\ncalendar.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(sell_prices.shape)\nsell_prices.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(sales_train_validation.shape)\nsales_train_validation.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**4. Data Exploration**"},{"metadata":{},"cell_type":"markdown","source":"4.1 Calendar Dataset"},{"metadata":{"trusted":false},"cell_type":"code","source":"calendar_snap_byWday = calendar.groupby(['year','wday','weekday'])[(\"snap_CA\",\"snap_TX\",\"snap_WI\")].sum().sort_index(1)\nfig, ax = plt.subplots()\ncalendar_snap_byEvent = calendar.groupby([\"year\",\"event_type_1_snap\"])[(\"snap_CA\",\"snap_TX\",\"snap_WI\")].sum().unstack().plot(ax=ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"4.2 Sell Prices Dataset"},{"metadata":{"trusted":false},"cell_type":"code","source":"sales_data = pd.merge(sell_prices, calendar[[\"year\",\"month\",\"d\",\"wday\",\"weekday\",\"event_type_1_snap\",\"event_type_2_snap\",\"wm_yr_wk\"]], left_on='wm_yr_wk', right_on='wm_yr_wk')\nax = plt.gca()\nax.yaxis.set_major_formatter(FormatStrFormatter('$%.2f M'))\nsales_data[[\"year\",\"sell_price\"]].groupby([\"year\"]).mean().unstack().plot(kind='bar',stacked=True,ax=ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"4.3 Sales Train Validation Dataset"},{"metadata":{"trusted":false},"cell_type":"code","source":"clus20 = sales_train_validation.iloc[:,2:]\ndata = clus20.groupby(\"state_id\").sum()\ndata\nx = sn.heatmap(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"clus20 = sales_train_validation.iloc[:,2:]\ndata = clus20.groupby(\"cat_id\").sum()\ndata\nx = sn.heatmap(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**5. Feature Selection & Modeling**"},{"metadata":{"trusted":false},"cell_type":"code","source":"#Data Prepartions & removing tempoprary objects from memory \n\ncolumn_index = [1,2,3,4,5]\nfor i in range(6 , len(sales_train_validation.columns)):\n    column_index.append(i)\n\nclus_hobbies = sales_train_validation.iloc[:,column_index].query(\"cat_id == 'HOBBIES'\")\nclus_household = sales_train_validation.iloc[:,column_index].query(\"cat_id == 'HOUSEHOLD'\")\nclus_foods = sales_train_validation.iloc[:,column_index].query(\"cat_id == 'FOODS'\")\nclus_ca = sales_train_validation.iloc[:,column_index].query(\"state_id == 'CA'\")\nclus_tx = sales_train_validation.iloc[:,column_index].query(\"state_id == 'TX'\")\nclus_wi = sales_train_validation.iloc[:,column_index].query(\"state_id == 'WI'\")\nclus = sales_train_validation.iloc[:,column_index]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Bucket columns by calander days of month\nfrom datetime import datetime\ncolumnsets = []\nfor i in range(1,32):      \n    d = calendar[:1913].query(\"d_month == \"+ str(i))[\"d\"]\n    columnsets.append([d.values])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Label encoding for catagorical data\ndef label_encoding(data_preap,cat_features):\n    categorical_names = {}\n    data = []\n    encoders = []\n    \n    data = data_preap[:]\n    for feature in cat_features:\n        le = sklearn.preprocessing.LabelEncoder()\n        le.fit(data.iloc[:,feature])\n        data.iloc[:, feature] = le.transform(data.iloc[:, feature])\n        categorical_names[feature] = le.classes_\n        encoders.append(le)\n    X_data = data.astype(float)\n    return X_data, encoders\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Training random forest model\ndef train_model(X_train, X_test, Y_train, Y_test):\n    # Random forest regressor model with Training dataset\n    start_time = datetime.today()\n    regressor = RandomForestRegressor(n_estimators = 350, random_state = 50)\n    regressor.fit(X_train,Y_train)\n\n    print(\"Time taken to Train Model: \" + str(datetime.today() - start_time))\n\n    # Running Regession model score check\n    Y_score = regressor.score(X_test,Y_test)\n    return regressor,Y_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Predict function from model\ndef model_prediect(regressor,X_data):\n    # Predicting model model result\n    Y_pred = regressor.predict(X_data)\n    return Y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Validating model with last year data & generating rmse value for the model predection\ndef validate_model(regressor,X_validation, Y_validation):\n   \n    Y_validation_pred = model_prediect(regressor, X_validation)\n    mse = mean_squared_error(Y_validation, Y_validation_pred)\n    rmse = np.sqrt(mse)\n    return rmse, Y_validation_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":" # Basic function for geting data from pandas based on range\ndef get_data_range(Inital_Range,start_index,end_index):\n    result = []\n    [result.append(a) for a in Inital_Range]\n    for i in range(max(Inital_Range) +1 + start_index, end_index):\n        result.append(i)\n    return result","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":" # main function to run predictions\ndef run_predictions(orig_data):\n    process_data = orig_data[:]\n    results = pd.DataFrame()\n    for s in range(1,29):\n        categorical_features = [0,1]\n        data = []\n        data_range = []\n        for i in range(0,s):\n            [data_range.append(a) for a in columnsets[i]]\n        data_list = [process_data[a] for a in data_range]\n        data  = pd.concat(data_list,axis = 1)\n\n\n        data.insert(loc=0, column='item_id', value=process_data[\"item_id\"])\n        data.insert(loc=1, column='store_id', value=process_data[\"store_id\"])\n        X_data_preap = data[:]\n\n        d = get_data_range(categorical_features,0,len(X_data_preap.columns)-1)   \n        X,label_encoders = label_encoding(X_data_preap.iloc[:,d],categorical_features)\n        Y = X.iloc[:,-1]\n\n        d_validation = get_data_range(categorical_features,1,len(X_data_preap.columns))   \n        X_validation,label_encoders_validation = label_encoding(X_data_preap.iloc[:,d_validation],categorical_features)\n        Y_validation = X_validation.iloc[:,-1]\n\n        print(\"Running Model for Day \" + str(s))\n        # Sampling data for train & split\n        X_train, X_test, Y_train, Y_test = train_test_split(X.iloc[:,0:len(X.columns)-1],Y,test_size = 0.2, random_state = 0)\n        model, score = train_model(X_train, X_test, Y_train, Y_test)\n        print(\"Model Score: \" + str(score))\n        \n       # Uncomment for inital model\n        rmse,validation_predictions = validate_model(model,X_validation.iloc[:,0:len(X_validation.columns)-1], Y_validation)\n        print(\"RMSE Result: \" + str(rmse))\n        \n        if (len(results.columns) == 0):\n            for feature in categorical_features:\n                results[feature] = label_encoders_validation[feature].inverse_transform(X_validation.iloc[:,feature].astype(int))\n\n        results[\"d_\" + str(s)] = validation_predictions.astype(int)\n        print(results)\n        results.to_csv('pd_predictions_' + str(s) +'.csv')\n    return results","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Calling Predic function for 28 days of month\n# Uncomment to run predictions \n#pd_predictions = run_predictions(clus)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Display first few recods of the predictions\n#pd_predictions.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":4}