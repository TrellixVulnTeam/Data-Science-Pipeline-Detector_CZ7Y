{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# M5 Data Preprocessing\n## FOODS\nDamien Park  \n2020-04-12","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"---","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tqdm\nimport gc\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# from statsmodels.tsa.statespace import sarimax\n# import statsmodels as sm\n\n# from sklearn.preprocessing import MinMaxScaler\n# from sklearn.model_selection import train_test_split\n# from sklearn.metrics import mean_squared_error\n# import keras\n\npd.set_option(\"display.max_columns\", 100)\npd.set_option(\"display.max_rows\", 500)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/m5-forecasting-accuracy/sales_train_validation.csv\")\ncalendar = pd.read_csv(\"../input/m5-forecasting-accuracy/calendar.csv\")\nsell = pd.read_csv(\"../input/m5-forecasting-accuracy/sell_prices.csv\")\n# sample = pd.read_csv(\"../input/m5-forecasting-accuracy/sample_submission.csv\")\n\n# data type\ntrain.iloc[:, 6:] = train.iloc[:, 6:].astype(\"int16\")\ncalendar.iloc[:, 11:] = calendar.iloc[:, 11:].astype(\"int8\")\nsell.sell_price = sell.sell_price.astype(\"float16\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.id.replace(regex=\"_validation\", value=\"\", inplace=True)\nsell[\"id\"] = sell.item_id+\"_\"+sell.store_id\nsell.drop(columns=[\"store_id\", \"item_id\"], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train dataset\n# setting columns which we use\ntrain_col = ['id', 'date', \n             'FOODS_1', 'FOODS_2', 'FOODS_3', \n             'HOBBIES_1', \"HOBBIES_2\", \n             'HOUSEHOLD_1', 'HOUSEHOLD_2', \n             'FOODS', 'HOBBIES', \n             'CA_1', 'CA_2', 'CA_3', 'CA_4', \n             'TX_1', 'TX_2', 'TX_3', \n             'WI_1', 'WI_2', 'WI_3', \n             'CA', 'TX', \n             \"snap_CA\", \"snap_TX\", \"snap_WI\", \n             'Cultural', 'National', 'Religious', 'Sporting', \n             \"release\", \n             'sell_price', 'sales']\n\n# event one-hot encoding\ntrain_event = calendar.loc[:, [\"d\", \"event_name_1\", \"event_type_1\", \"event_name_2\", \"event_type_2\"]]\ntrain_event = train_event.melt(id_vars=\"d\")\ntrain_event = train_event[~train_event.value.isnull()].reset_index(drop=True)\ntrain_event.variable.replace(to_replace={\"event_name_1\":\"event_name\", \"event_name_2\":\"event_name\", \n                                   \"event_type_1\":\"event_type\", \"event_type_2\":\"event_type\"}, \n                             inplace=True)\n\ntrain_event_type = train_event.query(\"variable=='event_type'\").loc[:, [\"d\"]].merge(pd.get_dummies(train_event.query(\"variable=='event_type'\").value), \n                                                                                   left_index=True, right_index=True, how=\"left\")\ntrain_event_name = train_event.query(\"variable=='event_name'\").loc[:, [\"d\"]].merge(pd.get_dummies(train_event.query(\"variable=='event_name'\").value), \n                                                                                   left_index=True, right_index=True, how=\"left\")\ntrain_event_type = train_event_type.groupby(\"d\").sum()\ntrain_event_name = train_event_name.groupby(\"d\").sum()\ntrain_event_type.reset_index(inplace=True)\ntrain_event_name.reset_index(inplace=True)\n\n# train one-hot encoding\ntrain_dept_id = pd.get_dummies(train.dept_id)\ntrain_cat_id = pd.get_dummies(train.cat_id)\ntrain_store_id = pd.get_dummies(train.store_id)\ntrain_state_id = pd.get_dummies(train.state_id)\n\n# merge all data\ndf_dummies = pd.concat([train[[\"id\"]], train_dept_id, train_cat_id, train_store_id, train_state_id], axis=1)\ntrain_df = df_dummies.merge(train.iloc[:, 6:], left_index=True, right_index=True, how=\"left\")\n\ndel train, train_dept_id, train_cat_id, train_store_id, train_state_id\ngc.collect()\n\ntrain_df = train_df.melt(id_vars=list(df_dummies.columns), \n                         var_name=\"d\", value_name=\"sales\")\n\ntrain_df = train_df.merge(calendar.loc[:, [\"date\", \"d\", \"wm_yr_wk\", \"snap_CA\", \"snap_TX\", \"snap_WI\"]], \n                          left_on=\"d\", right_on=\"d\", how=\"left\")\n\ndel calendar\ngc.collect()\n\ntrain_df = train_df.merge(train_event_type, on=\"d\", how=\"left\")\ntrain_df = train_df.merge(sell.loc[:, [\"id\", \"wm_yr_wk\", \"sell_price\"]], \n                          on=[\"id\", \"wm_yr_wk\"], how=\"left\")\n# df = df.loc[:, col]\ntrain_df.fillna(0, inplace=True)\ntrain_df.loc[:, ['snap_CA', 'snap_TX', 'snap_WI', \n                 'Cultural', 'National', 'Religious', 'Sporting']] = train_df.loc[:, ['snap_CA', 'snap_TX', 'snap_WI', \n                                                                                      'Cultural', 'National', 'Religious', 'Sporting']].astype(\"uint8\")\ntrain_df.date = pd.to_datetime(train_df.date)\n# train_df.set_index([\"id\", \"date\"], inplace=True)\n\ndel sell\ngc.collect()\n\ntrain_df[\"release\"] = 1\ntrain_df.loc[train_df.sell_price==0, \"release\"] = 0\ntrain_df.release = train_df.release.astype(\"uint8\")\n\n# reordering columns\ntrain_df = train_df.loc[:, train_col]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/m5-forecasting-accuracy/sales_train_validation.csv\")\ncalendar = pd.read_csv(\"../input/m5-forecasting-accuracy/calendar.csv\")\nsell = pd.read_csv(\"../input/m5-forecasting-accuracy/sell_prices.csv\")\n# sample = pd.read_csv(\"../input/m5-forecasting-accuracy/sample_submission.csv\")\n\n# data type\ntrain.iloc[:, 6:] = train.iloc[:, 6:].astype(\"int16\")\ncalendar.iloc[:, 11:] = calendar.iloc[:, 11:].astype(\"int8\")\nsell.sell_price = sell.sell_price.astype(\"float16\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.id.replace(regex=\"_validation\", value=\"\", inplace=True)\nsell[\"id\"] = sell.item_id+\"_\"+sell.store_id\nsell.drop(columns=[\"store_id\", \"item_id\"], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test dataset\n# setting columns which we use\ntest_col = ['id', 'date', \n            'FOODS_1', 'FOODS_2', 'FOODS_3', \n            'HOBBIES_1', \"HOBBIES_2\", \n            'HOUSEHOLD_1', 'HOUSEHOLD_2', \n            'FOODS', 'HOBBIES', \n            'CA_1', 'CA_2', 'CA_3', 'CA_4', \n            'TX_1', 'TX_2', 'TX_3', \n            'WI_1', 'WI_2', 'WI_3', \n            'CA', 'TX', \n            \"snap_CA\", \"snap_TX\", \"snap_WI\", \n            'Cultural', 'National', 'Religious', 'Sporting', \n            \"release\", \n            'sell_price', 'sales']\n\n# event one-hot encoding\ntest_event = calendar.query(\"date>'2016-04-24'\").loc[:, [\"d\", \"event_name_1\", \"event_type_1\", \"event_name_2\", \"event_type_2\"]]\ntest_event = test_event.melt(id_vars=\"d\")\ntest_event = test_event[~test_event.value.isnull()].reset_index(drop=True)\ntest_event.variable.replace(to_replace={\"event_name_1\":\"event_name\", \"event_name_2\":\"event_name\", \n                                        \"event_type_1\":\"event_type\", \"event_type_2\":\"event_type\"}, \n                            inplace=True)\n\ntest_event_type = test_event.query(\"variable=='event_type'\").loc[:, [\"d\"]].merge(pd.get_dummies(test_event.query(\"variable=='event_type'\").value), \n                                                                       left_index=True, right_index=True, how=\"left\")\ntest_event_name = test_event.query(\"variable=='event_name'\").loc[:, [\"d\"]].merge(pd.get_dummies(test_event.query(\"variable=='event_name'\").value), \n                                                                       left_index=True, right_index=True, how=\"left\")\ntest_event_type = test_event_type.groupby(\"d\").sum()\ntest_event_name = test_event_name.groupby(\"d\").sum()\ntest_event_type.reset_index(inplace=True)\ntest_event_name.reset_index(inplace=True)\ntest_event_type = calendar.query(\"date>'2016-04-24'\").loc[:, [\"d\", \"date\"]].merge(test_event_type, how=\"left\")\ntest_event_name = calendar.query(\"date>'2016-04-24'\").loc[:, [\"d\", \"date\"]].merge(test_event_name, how=\"left\")\ntest_event_type.date = pd.to_datetime(test_event_type.date)\ntest_event_name.date = pd.to_datetime(test_event_name.date)\ntest_event_type.fillna(0, inplace=True)\ntest_event_name.fillna(0, inplace=True)\ntest_event_type.iloc[:, 2:] = test_event_type.iloc[:, 2:].astype(\"uint8\")\ntest_event_name.iloc[:, 2:] = test_event_name.iloc[:, 2:].astype(\"uint8\")\n\n\nsample = pd.read_csv(\"../input/m5-forecasting-accuracy/sample_submission.csv\")\n\nvalidation = sample[sample.id.str.contains(\"validation\")].add_prefix(\"val_\")\nevaluation = sample[sample.id.str.contains(\"evaluation\")].add_prefix(\"evl_\")\nvalidation.rename(columns={\"val_id\":\"id\"}, inplace=True)\nevaluation.rename(columns={\"evl_id\":\"id\"}, inplace=True)\nvalidation.id.replace(regex=\"_validation\", value=\"\", inplace=True)\nevaluation.id.replace(regex=\"_evaluation\", value=\"\", inplace=True)\n\nvalidation = validation.melt(id_vars=\"id\", var_name=\"F\", value_name=\"sales\")\nevaluation = evaluation.melt(id_vars=\"id\", var_name=\"F\", value_name=\"sales\")\n\nval = ['val_F1', 'val_F2', 'val_F3', 'val_F4', 'val_F5', 'val_F6', \n       'val_F7', 'val_F8', 'val_F9', 'val_F10', 'val_F11', 'val_F12', \n       'val_F13', 'val_F14', 'val_F15', 'val_F16', 'val_F17', 'val_F18', \n       'val_F19', 'val_F20', 'val_F21', 'val_F22', 'val_F23', 'val_F24', \n       'val_F25', 'val_F26', 'val_F27', 'val_F28']\nevl = ['evl_F1', 'evl_F2', 'evl_F3', 'evl_F4', 'evl_F5', 'evl_F6', \n       'evl_F7', 'evl_F8', 'evl_F9', 'evl_F10', 'evl_F11', 'evl_F12', \n       'evl_F13', 'evl_F14', 'evl_F15', 'evl_F16', 'evl_F17', 'evl_F18', \n       'evl_F19', 'evl_F20', 'evl_F21', 'evl_F22', 'evl_F23', 'evl_F24', \n       'evl_F25', 'evl_F26', 'evl_F27', 'evl_F28']\nval = pd.DataFrame(data={\"F\":val, \"date\":pd.date_range(\"2016-04-25\", \"2016-05-22\")})\nevl = pd.DataFrame(data={\"F\":evl, \"date\":pd.date_range(\"2016-05-23\", \"2016-06-19\")})\n\nvalidation = validation.merge(val).drop(columns=[\"F\"])\nevaluation = evaluation.merge(evl).drop(columns=[\"F\"])\n\nfor i in ['FOODS_1', 'FOODS_2', 'FOODS_3', 'HOBBIES_1', 'HOBBIES_2',\n          'HOUSEHOLD_1', 'HOUSEHOLD_2', 'FOODS', 'HOBBIES', 'HOUSEHOLD', \n          'CA_1', 'CA_2', 'CA_3', 'CA_4', \n          'TX_1', 'TX_2', 'TX_3', \n          'WI_1', 'WI_2', 'WI_3',\n          'CA', 'TX', 'WI']:\n    validation[i] = 0\n    validation.loc[validation.id.str.contains(i), i] = 1\n\nfor i in ['FOODS_1', 'FOODS_2', 'FOODS_3', 'HOBBIES_1', 'HOBBIES_2',\n          'HOUSEHOLD_1', 'HOUSEHOLD_2', 'FOODS', 'HOBBIES', 'HOUSEHOLD', \n          'CA_1', 'CA_2', 'CA_3', 'CA_4', \n          'TX_1', 'TX_2', 'TX_3', \n          'WI_1', 'WI_2', 'WI_3',\n          'CA', 'TX', 'WI']:\n    evaluation[i] = 0\n    evaluation.loc[evaluation.id.str.contains(i), i] = 1\n\ncalendar.date = pd.to_datetime(calendar.date)\nvalidation = validation.merge(calendar.loc[:, [\"date\", \"wm_yr_wk\", \"snap_CA\", \"snap_TX\", \"snap_WI\"]], \n                              left_on=\"date\", right_on=\"date\", how=\"left\")\nevaluation = evaluation.merge(calendar.loc[:, [\"date\", \"wm_yr_wk\", \"snap_CA\", \"snap_TX\", \"snap_WI\"]], \n                              left_on=\"date\", right_on=\"date\", how=\"left\")\nvalidation = validation.merge(sell.loc[:, [\"id\", \"wm_yr_wk\", \"sell_price\"]], \n                              on=[\"id\", \"wm_yr_wk\"], how=\"left\")\nevaluation = evaluation.merge(sell.loc[:, [\"id\", \"wm_yr_wk\", \"sell_price\"]], \n                              on=[\"id\", \"wm_yr_wk\"], how=\"left\")\n\nvalidation[\"release\"] = 1\nvalidation.loc[validation.sell_price==0, \"release\"] = 0\nvalidation.release = validation.release.astype(\"uint8\")\nevaluation[\"release\"] = 1\nevaluation.loc[evaluation.sell_price==0, \"release\"] = 0\nevaluation.release = evaluation.release.astype(\"uint8\")\n\nvalidation = validation.merge(test_event_type, on=\"date\", how=\"left\")\nevaluation = evaluation.merge(test_event_type, on=\"date\", how=\"left\")\n\n# reordering columns\nvalidation = validation.loc[:, test_col]\nevaluation = evaluation.loc[:, test_col]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain_df.query(\"FOODS_1==1\").reset_index(drop=True).to_csv(\"../working/df_FOODS_1.csv\", index=False)\ntrain_df.query(\"FOODS_2==1\").reset_index(drop=True).to_csv(\"../working/df_FOODS_2.csv\", index=False)\ntrain_df.query(\"FOODS_3==1\").reset_index(drop=True).to_csv(\"../working/df_FOODS_3.csv\", index=False)\n\n# train_df.query(\"HOBBIES_1==1\").reset_index(drop=True).to_csv(\"../working/df_HOBBIES_1.csv\", index=False)\n# train_df.query(\"HOBBIES_2==1\").reset_index(drop=True).to_csv(\"../working/df_HOBBIES_2.csv\", index=False)\n\n# train_df.query(\"HOUSEHOLD_1==1\").reset_index(drop=True).to_csv(\"../working/df_HOUSEHOLD_1.csv\", index=False)\n# train_df.query(\"HOUSEHOLD_2==1\").reset_index(drop=True).to_csv(\"../working/df_HOUSEHOLD_2.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nvalidation.reset_index(drop=True).to_csv(\"../working/validation.csv\", index=False)\nevaluation.reset_index(drop=True).to_csv(\"../working/evaluation.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = train_df\ndf[\"item_id\"] = df.id.apply(func=lambda x:x[:-5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# _ = df.query(\"FOODS_1==1 and CA==1 and release==1\").groupby([\"item_id\", \"snap_CA\"]).sales.mean()\n# _ = _.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = df.query(\"FOODS_1==1 and CA==1 and release==1\").loc[:, [\"item_id\", \"snap_CA\", \"sales\"]]\n_ = _.reset_index(drop=True)\nitem_list = np.sort(pd.unique(_.item_id))\n\nstart = 0\ncount = len(item_list)//44+1\n\nplt.figure(figsize=(30, 30))\nplt.suptitle(\"FOODS_1 and CA\")\nfor idx, val in enumerate(range(44, count*44+1, 44)):\n    plt.subplot(count, 1, idx+1)\n    temp = item_list[start:val]\n    start = val\n    sns.boxplot(data=_.query(\"item_id in @temp\").sort_values(\"item_id\"), x=\"item_id\", y=\"sales\", hue=\"snap_CA\")\n    plt.xticks(rotation=45)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = df.query(\"FOODS_1==1 and TX==1 and release==1\").loc[:, [\"item_id\", \"snap_TX\", \"sales\"]]\n_ = _.reset_index(drop=True)\nitem_list = np.sort(pd.unique(_.item_id))\n\nstart = 0\ncount = len(item_list)//44+1\n\nplt.figure(figsize=(30, 30))\nplt.suptitle(\"FOODS_1 and TX\")\nfor idx, val in enumerate(range(44, count*44+1, 44)):\n    plt.subplot(count, 1, idx+1)\n    temp = item_list[start:val]\n    start = val\n    sns.boxplot(data=_.query(\"item_id in @temp\").sort_values(\"item_id\"), x=\"item_id\", y=\"sales\", hue=\"snap_TX\")\n    plt.xticks(rotation=45)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = df.query(\"FOODS_1==1 and CA==0 and TX==0 and release==1\").loc[:, [\"item_id\", \"snap_WI\", \"sales\"]]\n_ = _.reset_index(drop=True)\nitem_list = np.sort(pd.unique(_.item_id))\n\nstart = 0\ncount = len(item_list)//44+1\n\nplt.figure(figsize=(30, 30))\nplt.suptitle(\"FOODS_1 and WI\")\nfor idx, val in enumerate(range(44, count*44+1, 44)):\n    plt.subplot(count, 1, idx+1)\n    temp = item_list[start:val]\n    start = val\n    sns.boxplot(data=_.query(\"item_id in @temp\").sort_values(\"item_id\"), x=\"item_id\", y=\"sales\", hue=\"snap_WI\")\n    plt.xticks(rotation=45)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = df.query(\"FOODS_2==1 and CA==1 and release==1\").loc[:, [\"item_id\", \"snap_CA\", \"sales\"]]\n_ = _.reset_index(drop=True)\nitem_list = np.sort(pd.unique(_.item_id))\n\nstart = 0\ncount = len(item_list)//50+1\n\nplt.figure(figsize=(50, 30))\nplt.suptitle(\"FOODS_2 and CA\")\nfor idx, val in enumerate(range(50, count*50+1, 50)):\n    plt.subplot(count, 1, idx+1)\n    temp = item_list[start:val]\n    start = val\n    sns.boxplot(data=_.query(\"item_id in @temp\").sort_values(\"item_id\"), x=\"item_id\", y=\"sales\", hue=\"snap_CA\")\n    plt.xticks(rotation=45)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = df.query(\"FOODS_2==1 and TX==1 and release==1\").loc[:, [\"item_id\", \"snap_TX\", \"sales\"]]\n_ = _.reset_index(drop=True)\nitem_list = np.sort(pd.unique(_.item_id))\n\nstart = 0\ncount = len(item_list)//50+1\n\nplt.figure(figsize=(50, 30))\nplt.suptitle(\"FOODS_2 and TX\")\nfor idx, val in enumerate(range(50, count*50+1, 50)):\n    plt.subplot(count, 1, idx+1)\n    temp = item_list[start:val]\n    start = val\n    sns.boxplot(data=_.query(\"item_id in @temp\").sort_values(\"item_id\"), x=\"item_id\", y=\"sales\", hue=\"snap_TX\")\n    plt.xticks(rotation=45)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = df.query(\"FOODS_2==1 and CA==0 and TX==0 and release==1\").loc[:, [\"item_id\", \"snap_WI\", \"sales\"]]\n_ = _.reset_index(drop=True)\nitem_list = np.sort(pd.unique(_.item_id))\n\nstart = 0\ncount = len(item_list)//50+1\n\nplt.figure(figsize=(50, 30))\nplt.suptitle(\"FOODS_2 and WI\")\nfor idx, val in enumerate(range(50, count*50+1, 50)):\n    plt.subplot(count, 1, idx+1)\n    temp = item_list[start:val]\n    start = val\n    sns.boxplot(data=_.query(\"item_id in @temp\").sort_values(\"item_id\"), x=\"item_id\", y=\"sales\", hue=\"snap_WI\")\n    plt.xticks(rotation=45)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = df.query(\"FOODS_3==1 and CA==1 and release==1\").loc[:, [\"item_id\", \"snap_CA\", \"sales\"]]\n_ = _.reset_index(drop=True)\nitem_list = np.sort(pd.unique(_.item_id))\n\nstart = 0\ncount = len(item_list)//50+1\n\nplt.figure(figsize=(50, 30))\nplt.suptitle(\"FOODS_3 and CA\")\nfor idx, val in enumerate(range(50, count*50+1, 50)):\n    plt.subplot(count, 1, idx+1)\n    temp = item_list[start:val]\n    start = val\n    sns.boxplot(data=_.query(\"item_id in @temp\").sort_values(\"item_id\"), x=\"item_id\", y=\"sales\", hue=\"snap_CA\")\n    plt.xticks(rotation=45)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = df.query(\"FOODS_3==1 and TX==1 and release==1\").loc[:, [\"item_id\", \"snap_TX\", \"sales\"]]\n_ = _.reset_index(drop=True)\nitem_list = np.sort(pd.unique(_.item_id))\n\nstart = 0\ncount = len(item_list)//50+1\n\nplt.figure(figsize=(50, 30))\nplt.suptitle(\"FOODS_3 and TX\")\nfor idx, val in enumerate(range(50, count*50+1, 50)):\n    plt.subplot(count, 1, idx+1)\n    temp = item_list[start:val]\n    start = val\n    sns.boxplot(data=_.query(\"item_id in @temp\").sort_values(\"item_id\"), x=\"item_id\", y=\"sales\", hue=\"snap_TX\")\n    plt.xticks(rotation=45)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_ = df.query(\"FOODS_3==1 and CA==0 and TX==0 and release==1\").loc[:, [\"item_id\", \"snap_WI\", \"sales\"]]\n_ = _.reset_index(drop=True)\nitem_list = np.sort(pd.unique(_.item_id))\n\nstart = 0\ncount = len(item_list)//50+1\n\nplt.figure(figsize=(50, 30))\nplt.suptitle(\"FOODS_3 and WI\")\nfor idx, val in enumerate(range(50, count*50+1, 50)):\n    plt.subplot(count, 1, idx+1)\n    temp = item_list[start:val]\n    start = val\n    sns.boxplot(data=_.query(\"item_id in @temp\").sort_values(\"item_id\"), x=\"item_id\", y=\"sales\", hue=\"snap_WI\")\n    plt.xticks(rotation=45)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\nThe end of notebook","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}