{"cells":[{"metadata":{},"cell_type":"markdown","source":"# EDA (Japanese)"},{"metadata":{},"cell_type":"markdown","source":"M5コンペティション(Accuracy)のEDAノートブックです。コメントについては、日本語で書かせていただきます。\n\nThis is EDA notebook for M5 Accuracy competition. I'm sorry for writing comments in japanese.\n\nWRMSSEの計算については、下記カーネルを参考にさせていただきました。\n\n- This kernel is based on [for_Japanese_beginner(with WRMSSE in LGBM)](https://www.kaggle.com/girmdshinsei/for-japanese-beginner-with-wrmsse-in-lgbm)\n\nコンペティションガイド[M5-Competitors-Guide_Final-1.pdf](https://mk0mcompetitiont8ake.kinstacdn.com/wp-content/uploads/2020/02/M5-Competitors-Guide_Final-1.pdf)に目を通していることを前提として書くため、各カラムの内容説明などは省略します。"},{"metadata":{"ExecuteTime":{"end_time":"2020-05-09T16:18:14.162513Z","start_time":"2020-05-09T16:18:13.318514Z"},"trusted":true},"cell_type":"code","source":"import datetime\nimport gc\nimport random\nimport warnings\nfrom typing import List\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.io as pio; pio.renderers.default='notebook'\nfrom plotly.subplots import make_subplots\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom IPython.display import display\n\n# from src.notebook_utils import reduce_memory_usage, merge_by_concat, show_basic_info\n# from src.df_transformer import ReplaceBeforeFirstSell\n# from src.plot_utils import PlotlyFigure","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def reduce_memory_usage(\n    df: pd.DataFrame,\n    verbose: bool = True,\n) -> pd.DataFrame:\n    \"\"\"\n    受け取ったデータフレームについてそれぞれのカラムのデータ型を調べ、最小メモリ型に変換することで\n    データフレームのメモリ使用量を削減する。\n    \"\"\"\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and \\\n                   c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and \\\n                        c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and \\\n                        c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and \\\n                        c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if c_min > np.finfo(np.float16).min and \\\n                   c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and \\\n                        c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose:\n        print(\n            'Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'\n            .format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df\n\n\ndef merge_by_concat(\n    df1: pd.DataFrame,\n    df2: pd.DataFrame,\n    merge_on: List[str],\n) -> pd.DataFrame:\n    \"\"\"\n    型情報を失わずにデータフレームをマージする\n    \"\"\"\n    merged_gf = df1[merge_on]\n    merged_gf = merged_gf.merge(df2, on=merge_on, how='left')\n    new_columns = [col for col in list(merged_gf) if col not in merge_on]\n    df1 = pd.concat([df1, merged_gf[new_columns]], axis=1)\n    return df1\n\n\ndef show_basic_info(df: pd.DataFrame):\n    \"\"\"\n    データフレームの基本情報を表示する\n    \"\"\"\n    df.info()\n    display(df.head())\n    display(df.tail())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ReplaceBeforeFirstSell(object):\n\n    def __init__(self):\n        pass\n\n    def transform(\n        self,\n        df: pd.DataFrame,\n        value_columns: List[str],\n    ) -> pd.DataFrame:\n        df_values = df[value_columns].values\n        tmp = np.tile(np.arange(1, len(value_columns) + 1),\n                      (df_values.shape[0], 1))\n        tmp_values = ((df_values > 0) * tmp)\n        start_no = np.min(np.where(\n            tmp_values == 0, 9999, tmp_values), axis=1) - 1\n        flag = np.dot(np.diag(1 / (start_no + 1)), tmp) < 1\n        df_values = np.where(flag, np.nan, df_values)\n        df[value_columns] = df_values\n        return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class PlotlyFigure(object):\n    \"\"\"\n    Provide application methods as adapter class of plotly\n    \"\"\"\n    def __init__(self):\n        pass\n\n    def add_range_selector(\n        self,\n        fig: go.Figure,\n    ) -> go.Figure:\n        fig.update_xaxes(\n            rangeselector=dict(\n                buttons=list([\n                    dict(count=12*7, label=\"12w\",\n                         step=\"day\", stepmode=\"backward\"),\n                    dict(count=24*7, label=\"24w\",\n                         step=\"day\", stepmode=\"backward\"),\n                    dict(count=36*7, label=\"36w\",\n                         step=\"day\", stepmode=\"backward\"),\n                    dict(count=1, label=\"1y\",\n                         step=\"year\", stepmode=\"backward\"),\n                    dict(count=2, label=\"2y\",\n                         step=\"year\", stepmode=\"backward\"),\n                    dict(step=\"all\")\n                ])\n            )\n        )\n        return fig\n\n    def add_shape_region(\n        self,\n        fig: go.Figure,\n        start_date: str,\n        end_date: str,\n        color: str = None,\n    ) -> go.Figure:\n        fig.add_shape(\n            type='rect',\n            xref='x',\n            yref='paper',\n            x0=start_date,\n            y0=0,\n            x1=end_date,\n            y1=1,\n            fillcolor=color,\n            opacity=0.5,\n            layer='below',\n            line_width=0,\n        )\n        return fig\n\n    def format_annotation(\n        self,\n        fig: go.Figure,\n        ax: float = 0,\n        ay: float = -40,\n        showarrow: bool = True,\n        arrowhead: float = 7,\n    ) -> go.Figure:\n        fig.update_annotations(dict(\n                    xref=\"x\",\n                    yref=\"y\",\n                    showarrow=showarrow,\n                    arrowhead=arrowhead,\n                    ax=ax,\n                    ay=ay,\n        ))\n        return fig","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-05-09T16:18:14.167514Z","start_time":"2020-05-09T16:18:14.163513Z"},"trusted":true},"cell_type":"code","source":"plotly_util = PlotlyFigure()\nplt.style.use('ggplot')\nrandom.seed(42)","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-05-09T16:18:14.176513Z","start_time":"2020-05-09T16:18:14.168515Z"},"trusted":true},"cell_type":"code","source":"HISTORY_COUNTS = 1913\nPRED_COUNTS = 28\nNUM_ITEMS = 30490\n\nHISTORY_COLUMNS = [f'd_{i + 1}' for i in range(HISTORY_COUNTS)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load Dataset"},{"metadata":{},"cell_type":"markdown","source":"コンペティションでは、3つのCSV形式のファイルで与えられます。"},{"metadata":{"ExecuteTime":{"end_time":"2020-05-09T16:18:18.767513Z","start_time":"2020-05-09T16:18:14.177515Z"},"trusted":true},"cell_type":"code","source":"calendar = pd.read_csv('../input/m5-forecasting-accuracy/calendar.csv')\nsales = pd.read_csv('../input/m5-forecasting-accuracy/sales_train_validation.csv')\nprices = pd.read_csv('../input/m5-forecasting-accuracy/sell_prices.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### calendar.csv"},{"metadata":{},"cell_type":"markdown","source":"calendar.csvには日付やイベントの情報が含まれます。\n\n特徴的なのはsnap(Supplemental Nutrition Assistance Program：補充的栄養支援プログラム)関連のカラムである。SNAPとは、アメリカの低所得者向けの栄養補助プログラムであり、該当日においてSNAP購買が許可されるかどうかを表している。\n\n- 参考PDF: https://www.maff.go.jp/primaff/kanko/project/attach/pdf/170900_28cr02_02.pdf"},{"metadata":{"ExecuteTime":{"end_time":"2020-05-09T16:18:18.795573Z","start_time":"2020-05-09T16:18:18.768514Z"},"scrolled":false,"trusted":true},"cell_type":"code","source":"show_basic_info(calendar)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### sales_train_validation.csv"},{"metadata":{"ExecuteTime":{"end_time":"2020-05-06T15:27:24.053443Z","start_time":"2020-05-06T15:27:24.049447Z"}},"cell_type":"markdown","source":"sales_train_validation.csvには、商品関連のID(item_id, dept_id, etc)と売り上げの履歴(d_1～d_1913)が含まれます。\n\n本コンペティションはvalidationとevaluationの2つのフェーズに分かれており、validationフェーズでは、d_1～d_1913のデータからd_1914～d_1941の28日間のデータを予測します。この期間は、リーダーボードにてスコアが表示されるため、こちらのスコアを参考にすることができます。\n\n6月(evaluationフェーズ)にはd_1～d_1941のデータが与えられ、d_1942～d_1968の28日間のデータを予測します。evaluationフェーズでは、リーダーボードのスコアが隠されるので、参加者は過学習を避けるために、適切なCVの戦略を決める必要があります。(validationフェーズでも同様ですが)\n\n- Note: 6月時点でd_1～d_1941のデータを含むsales_train_evaluation.csvが公開されます"},{"metadata":{"ExecuteTime":{"end_time":"2020-05-09T16:18:18.866527Z","start_time":"2020-05-09T16:18:18.796514Z"},"scrolled":true,"trusted":true},"cell_type":"code","source":"show_basic_info(sales)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### sell_prices.csv"},{"metadata":{},"cell_type":"markdown","source":"sell_prices.csvには、店舗ごとの各商品の週単位での価格が格納されています。"},{"metadata":{"ExecuteTime":{"end_time":"2020-05-09T16:18:18.879526Z","start_time":"2020-05-09T16:18:18.867525Z"},"scrolled":true,"trusted":true},"cell_type":"code","source":"show_basic_info(prices)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## View raw data"},{"metadata":{},"cell_type":"markdown","source":"本コンペティションにおいて予測したいのは「各店舗・商品全ての組み合わせについての28日先までの販売数」です。\n\nその組み合わせは30,490通りあり、店舗や商品、イベント情報などの特徴をモデルに組み込んで良い予測ができるように学習する必要があります。\n\n様々な集計を行うより先にまずは30490通りの中から、いくつかをランダムサンプリングしその販売数（ついでに価格)の推移を確認しましょう。"},{"metadata":{},"cell_type":"markdown","source":"### Sales"},{"metadata":{"ExecuteTime":{"end_time":"2020-05-09T16:18:20.727526Z","start_time":"2020-05-09T16:18:18.880526Z"},"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(5, 2, figsize=(15, 10))\nsamples = random.sample(range(len(sales)), 10)\n\nx = pd.to_datetime(calendar.iloc[:HISTORY_COUNTS, :]['date']).values\nfor ax, sample in zip(axes.flatten(), samples):\n    y = sales[HISTORY_COLUMNS].loc[sample, :]\n    ax.plot(x, y)\n    ax.set_title(sales.loc[sample, 'id'])\n    ax.set_xlabel('date')\n    ax.set_ylabel('sales')\n\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"実行のたびに異なる商品の学習期間全体の販売数の推移が出力されます。販売数推移からは例えば以下のような特徴が読み取れます。"},{"metadata":{"ExecuteTime":{"end_time":"2020-05-06T15:54:36.755366Z","start_time":"2020-05-06T15:54:36.751365Z"}},"cell_type":"markdown","source":"- 1日の販売数が少ない商品が多い (1日に1個も売れなかったり、売れても2, 3個だったりする)\n- 急激に販売数が上がり元に戻る箇所が存在する(スパイク形状が存在する)\n- 学習期間の途中から販売された商品が多数存在する。"},{"metadata":{},"cell_type":"markdown","source":"### Prices"},{"metadata":{"ExecuteTime":{"end_time":"2020-05-09T16:18:34.703525Z","start_time":"2020-05-09T16:18:20.728526Z"},"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(5, 2, figsize=(15, 10))\nsamples = random.sample(range(len(sales)), 10)\n\nfor ax, sample in zip(axes.flatten(), samples):\n    item = sales['item_id'].loc[sample]\n    store = sales['store_id'].loc[sample]\n    ax.plot(\n        prices[(prices['item_id']==item) & (prices['store_id']==store)]['wm_yr_wk'],\n        prices[(prices['item_id']==item) & (prices['store_id']==store)]['sell_price']\n    )\n    ax.set_title(f\"Price of {sales['id'].loc[sample]}\")\n    ax.set_xlabel('week number')\n    ax.set_ylabel('price')\n    \nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- 値段が常に一定の商品もあれば、激しく変動する商品も存在する。"},{"metadata":{},"cell_type":"markdown","source":"## Timeseries Aggregation"},{"metadata":{},"cell_type":"markdown","source":"### Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"続いて時系列に着目して、様々な集計を実施します。"},{"metadata":{},"cell_type":"markdown","source":"集計の前処理として、salesデータフレームに前処理を加えます。\n\n下記はPDFの注記ですが、本コンペティションの評価指標となるRMSSEのスケール計算の際に使用されるデータは、初めて商品が販売された日以降のデータ\nとなります。\n\n> Note that the denominator of RMSSE is computed only for the time-periods for which the examined product(s) are actively sold, i.e., the periods following the first non-zero demand observed for the series under evaluation.\n\nスケール計算対象範囲の販売数0と、範囲外の販売数0を明確に区別する必要があるため、初めて商品が販売された日以前の販売数0をNaNに置換します。"},{"metadata":{"ExecuteTime":{"end_time":"2020-05-09T16:21:37.899847Z","start_time":"2020-05-09T16:18:34.704526Z"},"trusted":true},"cell_type":"code","source":"replacer = ReplaceBeforeFirstSell()\nreplacer.transform(sales, HISTORY_COLUMNS)\nshow_basic_info(sales)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Total Sales"},{"metadata":{},"cell_type":"markdown","source":"まず初めに、予測対象全体での販売数推移(日次)と移動平均(1週間,4週間,90日間)を可視化します。\n\nグラフ右側の緑とピンクの色はそれぞれ、validationフェーズとevaluationフェーズの予測区間を表しています。"},{"metadata":{"ExecuteTime":{"end_time":"2020-05-09T16:21:38.711845Z","start_time":"2020-05-09T16:21:37.900845Z"},"trusted":true},"cell_type":"code","source":"x = calendar.iloc[:HISTORY_COUNTS, :]['date'].values\ntotal_sales = sales[HISTORY_COLUMNS].sum()\nfig = go.Figure(\n    data=[go.Scatter(x=x, y=total_sales.values, name='raw')],\n)\nfig.add_trace(go.Scatter(x=x, y=total_sales.rolling(7).mean().values, name='1 week MA'))\nfig.add_trace(go.Scatter(x=x, y=total_sales.rolling(28).mean().values, name='4 week MA'))\nfig.add_trace(go.Scatter(x=x, y=total_sales.rolling(90).mean().values, name='90 days MA'))\nfig = plotly_util.add_range_selector(fig)\nfig = plotly_util.add_shape_region(fig, '2016-04-25', '2016-05-23', 'LightSeaGreen')\nfig = plotly_util.add_shape_region(fig, '2016-05-23', '2016-06-19', 'LightPink')\nfig.update_layout(\n    title_text='All item sales(sum)',\n    xaxis_title='date',\n    yaxis_title='sales',\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"グラフから読み取れる内容の例として、下記のようなことがわかります。\n\n- 全体として緩やかな上昇トレンドが存在する。\n- 12月24日はほとんどの商品販売を停止している。\n- 1週間の中では週末に販売数が多く、週明けから半ばにかけて少ない。\n- 年間では冬に販売数が少なく、夏にピークを迎える傾向にある。"},{"metadata":{},"cell_type":"markdown","source":"### Mean Sales"},{"metadata":{},"cell_type":"markdown","source":"学習期間の初期と終盤では、商品のユニーク数が異なることが分かっています。\n\n予測対象としては個々の商品について予測することとなるため、1商品あたりの平均販売数の日次推移についても確認しておきましょう。\n\n前処理によって、初めて販売数が非ゼロになるまでの商品販売数はNaNに置換されているためmean()メソッドによる平均計算対象からは省かれます。"},{"metadata":{"ExecuteTime":{"end_time":"2020-05-09T16:21:39.482846Z","start_time":"2020-05-09T16:21:38.712845Z"},"trusted":true},"cell_type":"code","source":"x = calendar.iloc[:HISTORY_COUNTS, :]['date'].values\ntotal_sales = sales[HISTORY_COLUMNS].mean()\nfig = go.Figure(\n    data=[go.Scatter(x=x, y=total_sales.values, name='raw')],\n)\nfig.add_trace(go.Scatter(x=x, y=total_sales.rolling(7).mean().values, name='1 week MA'))\nfig.add_trace(go.Scatter(x=x, y=total_sales.rolling(28).mean().values, name='4 week MA'))\nfig.add_trace(go.Scatter(x=x, y=total_sales.rolling(90).mean().values, name='90 days MA'))\nfig = plotly_util.add_range_selector(fig)\nfig = plotly_util.add_shape_region(fig, '2016-04-25', '2016-05-23', 'LightSeaGreen')\nfig = plotly_util.add_shape_region(fig, '2016-05-23', '2016-06-19', 'LightPink')\nfig.update_layout(\n    title_text='All item sales(mean)',\n    xaxis_title='date',\n    yaxis_title='sales',\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"商品全体の売り上げとは対照的に、1商品あたりの販売数平均を見たときは下降傾向(ただし直近は横ばい)にあります。\n\nこのことから学習期間の初期と比較して、終盤はロングテールとなっていることがわかります。"},{"metadata":{},"cell_type":"markdown","source":"### First sales"},{"metadata":{},"cell_type":"markdown","source":"続いて上記の内容に関連して、予測対象(商品×店舗)のユニーク数の時系列推移をプロットします。"},{"metadata":{"ExecuteTime":{"end_time":"2020-05-09T16:21:40.428871Z","start_time":"2020-05-09T16:21:39.483845Z"},"trusted":true},"cell_type":"code","source":"date_map = {i + 1: datetime.datetime.strptime(calendar['date'].min(\n), '%Y-%m-%d') + datetime.timedelta(days=i) for i in range(HISTORY_COUNTS)}\n\nsales['first_sold'] = HISTORY_COUNTS - sales[HISTORY_COLUMNS].count(axis=1) + 1\nsales['first_sold'] = sales['first_sold'].replace(date_map)\n\nfirst_sales = sales.groupby('first_sold').size(\n).reset_index().rename(columns={0: 'count'})\nfirst_sales['cumulative count'] = first_sales['count'].cumsum()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-05-09T16:21:40.503871Z","start_time":"2020-05-09T16:21:40.42987Z"},"trusted":true},"cell_type":"code","source":"fig = make_subplots(specs=[[{\"secondary_y\": True}]])\nfig.add_trace(go.Scatter(\n    x=first_sales['first_sold'], y=first_sales['count'], mode='markers', name='First sold count'),\n    secondary_y=False,)\nfig.add_trace(go.Scatter(\n    x=first_sales['first_sold'], y=first_sales['cumulative count'],\n    name='Cumulative count', line = dict(color='firebrick', dash='dot')),\n    secondary_y=True,)\nfig = plotly_util.add_range_selector(fig)\nfig = plotly_util.add_shape_region(fig, '2016-04-25', '2016-05-23', 'LightSeaGreen')\nfig = plotly_util.add_shape_region(fig, '2016-05-23', '2016-06-19', 'LightPink')\n\nfig.update_layout(\n    title_text='Daily counts of item sold first time',\n    xaxis_title='date',\n)\nfig.update_yaxes(title_text=\"Item count\", secondary_y=False)\nfig.update_yaxes(title_text=\"Cumulative item count\", secondary_y=True)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- 最初の半年ほどで約半数の商品が販売され始め、以降は継続的に商品×店舗のユニーク数が増加している。\n- 2016/02/17以降はNaNが存在せず、30490種類のID全ての販売数がRMSSEのscale計算に有効である。(validation期間の開始は2016/04/25～)"},{"metadata":{},"cell_type":"markdown","source":"### Actual unique counts"},{"metadata":{},"cell_type":"markdown","source":"販売が開始された商品が刻々と増え続けていることがわかりましたが、実際に販売数が1以上の商品のユニーク数は日々どのように推移しているのでしょうか。\n\nこのような観点から、30,490種類の予測対象系列について、販売数が1以上の系列の数の時系列推移をプロットします。"},{"metadata":{"ExecuteTime":{"end_time":"2020-05-09T16:21:41.068888Z","start_time":"2020-05-09T16:21:40.504871Z"},"trusted":true},"cell_type":"code","source":"x = calendar.iloc[:HISTORY_COUNTS, :]['date'].values\nunique_sales = (sales[HISTORY_COLUMNS].fillna(0) > 0).sum()\nfig = go.Figure(\n    data=[go.Scatter(x=x, y=unique_sales.values, name='raw')],\n)\nfig.add_trace(go.Scatter(x=x, y=unique_sales.rolling(7).mean().values, name='1 week MA'))\nfig.add_trace(go.Scatter(x=x, y=unique_sales.rolling(28).mean().values, name='4 week MA'))\nfig.add_trace(go.Scatter(x=x, y=unique_sales.rolling(90).mean().values, name='90 days MA'))\nfig = plotly_util.add_range_selector(fig)\nfig = plotly_util.add_shape_region(fig, '2016-04-25', '2016-05-23', 'LightSeaGreen')\nfig = plotly_util.add_shape_region(fig, '2016-05-23', '2016-06-19', 'LightPink')\nfig.update_layout(\n    title_text='Unique Sales',\n    xaxis_title='date',\n    yaxis_title='unique sales count',\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"実際に販売されている商品の数も、右肩上がりであることがわかりました。"},{"metadata":{},"cell_type":"markdown","source":"## Product Features"},{"metadata":{},"cell_type":"markdown","source":"続いて商品関連の特徴量について、目的変数(sales)との相関を中心に調べます。"},{"metadata":{},"cell_type":"markdown","source":"### Product kinds"},{"metadata":{},"cell_type":"markdown","source":"まず最初に、最新時点での商品×店舗のユニーク数をcat_id毎、dept_id毎に確認します。"},{"metadata":{"ExecuteTime":{"end_time":"2020-05-09T16:21:41.910162Z","start_time":"2020-05-09T16:21:41.069891Z"},"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(12, 6))\nax1 = fig.add_subplot(221)\nax2 = fig.add_subplot(222)\nax3 = fig.add_subplot(223)\nax4 = fig.add_subplot(224)\n\nsales.groupby(['cat_id'])['item_id'].\\\n    count()[::-1].plot.barh(ax=ax1)\n\nsales[sales['cat_id']=='FOODS'].\\\n    groupby(['dept_id'])['item_id'].\\\n    count()[::-1].plot.barh(ax=ax2)\n\nsales[sales['cat_id']=='HOUSEHOLD'].\\\n    groupby(['dept_id'])['item_id'].\\\n    count()[::-1].plot.barh(ax=ax3)\n\nsales[sales['cat_id']=='HOBBIES'].\\\n    groupby(['dept_id'])['item_id'].\\\n    count()[::-1].plot.barh(ax=ax4)\n\nax1.set_title('Item counts per category')\nax1.set_xlabel('item_count')\nax2.set_title('FOODS item counts per department')\nax2.set_xlabel('item_count')\nax3.set_title('HOUSEHOLDS item counts per department')\nax3.set_xlabel('item_count')\nax4.set_title('HOBBIES item counts per department')\nax4.set_xlabel('item_count')\nfig.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- カテゴリ別の商品数としては、FOODS, HOUSEHOLD, HOBBIESの順に多い\n- FOODSカテゴリの中でFOODS_3、HOBBIESカテゴリの中でHOBBIES_1の商品数の多さが目立つ。"},{"metadata":{},"cell_type":"markdown","source":"上記と併せて、cat_id, dept_id毎の販売数合計も可視化してみます。"},{"metadata":{"ExecuteTime":{"end_time":"2020-05-09T16:21:43.424215Z","start_time":"2020-05-09T16:21:41.911163Z"},"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(12, 6))\nax1 = fig.add_subplot(221)\nax2 = fig.add_subplot(222)\nax3 = fig.add_subplot(223)\nax4 = fig.add_subplot(224)\n\nsales.groupby(['cat_id'])[HISTORY_COLUMNS].\\\n    sum().sum(axis=1)[::-1].plot.barh(ax=ax1)\n\nsales[sales['cat_id']=='FOODS'].\\\n    groupby(['dept_id'])[HISTORY_COLUMNS].\\\n    sum().sum(axis=1)[::-1].plot.barh(ax=ax2)\n\nsales[sales['cat_id']=='HOUSEHOLD'].\\\n    groupby(['dept_id'])[HISTORY_COLUMNS].\\\n    sum().sum(axis=1)[::-1].plot.barh(ax=ax3)\n\nsales[sales['cat_id']=='HOBBIES'].\\\n    groupby(['dept_id'])[HISTORY_COLUMNS].\\\n    sum().sum(axis=1)[::-1].plot.barh(ax=ax4)\n\nax1.set_title('Item sales per category')\nax1.set_xlabel('item_count')\nax2.set_title('FOODS item counts per department')\nax2.set_xlabel('item_count')\nax3.set_title('HOUSEHOLDS item counts per department')\nax3.set_xlabel('item_count')\nax4.set_title('HOBBIES item counts per department')\nax4.set_xlabel('item_count')\nfig.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ユニーク数のグラフとの比較により下記のようなことがわかります。"},{"metadata":{},"cell_type":"markdown","source":"- HOUSEHOLD_1とHOUSEHOLD_2の間で、ユニーク数にそれほど差はないものの販売数に4倍近く差がある。\n- HOUSEHOLDほどではないもののHOBBIESカテゴリにも同様の傾向あがる(ユニーク数と販売数の比率の違い)\n- FOODSカテゴリは１アイテムあたりの販売数が多い傾向(特にFOODS_3)"},{"metadata":{},"cell_type":"markdown","source":"### Sales per department"},{"metadata":{},"cell_type":"markdown","source":"続いて、dept_id毎の日次販売数を確認します。\n\n最初に1913日分の1商品あたりの販売数がどのように分布しているか、dept_id毎に大まかな特徴をつかむため、箱ひげ図で表します。(クリスマスは、外れ値として除外しています)"},{"metadata":{"ExecuteTime":{"end_time":"2020-05-09T16:21:44.011217Z","start_time":"2020-05-09T16:21:43.425215Z"},"trusted":true},"cell_type":"code","source":"dept_sales = sales.groupby(['dept_id'])[HISTORY_COLUMNS].mean().T\ndept_sales = dept_sales.loc[calendar.loc[:HISTORY_COUNTS-1, :][~(calendar['event_name_1'] == 'Christmas')]['d'].values, :]\n\nfig = go.Figure()\nfor col in dept_sales:\n    fig.add_trace(go.Box(x=[col]*len(dept_sales), y=dept_sales[col], name=col))\n    \nfig.update_layout(\n    title_text='Unit sales box plot per department',\n    xaxis_title='dept_id',\n    yaxis_title='mean sales per product',\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"箱ひげ図からは下記のような内容がわかります。\n\n- FOOD_3カテゴリの販売数が、ほかのdept_idと比べて突出しており、日によって販売数の変動が激しいこともわかる。\n- FOOD_1カテゴリとFOOD_2カテゴリでは中央値としては比較的近いが、FOOD_2の方が販売数の変動が激しい。\n- どのカテゴリも共通して上側に外れ値が存在する。それぞれのdept_idについて日次販売数のヒストグラムを書くと、右裾の長い形状となることがわかる。\n\nまた、HOBBIES_2やHOUSEHOLD_2は基本的に1日の販売数が少ないことがわかるが、平均に対する外れ値の倍率が高い。今回の評価指標であるRMSSEは、販売数の変動が小さい商品の影響度を高くするようにスケール計算が行われるので、このような商品群に対する予測も重要であると考えられる。"},{"metadata":{"ExecuteTime":{"end_time":"2020-05-09T16:21:44.569216Z","start_time":"2020-05-09T16:21:44.012215Z"},"trusted":true},"cell_type":"code","source":"x = calendar.iloc[:HISTORY_COUNTS, :]['date'].values\ndept_sales = sales.groupby(['dept_id'])[HISTORY_COLUMNS].sum()\n\nfig = go.Figure()\nfor dept in dept_sales.index:\n    y = dept_sales.loc[dept, :].values\n    fig.add_trace(go.Scatter(x=x, y=y, name=dept))\n\nfig = plotly_util.add_range_selector(fig)\nfig = plotly_util.add_shape_region(fig, '2016-04-25', '2016-05-23', 'LightSeaGreen')\nfig = plotly_util.add_shape_region(fig, '2016-05-23', '2016-06-19', 'LightPink')\nfig.update_layout(\n    title_text='Item sales per department',\n    xaxis_title='date',\n    yaxis_title='sales',\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-05-09T16:21:44.636215Z","start_time":"2020-05-09T16:21:44.570215Z"},"trusted":true},"cell_type":"code","source":"fig = go.Figure()\nfor dept in dept_sales.index:\n    y = dept_sales.loc[dept, :].rolling(7).mean().values\n    fig.add_trace(go.Scatter(x=x, y=y, name=dept))\n\nfig = plotly_util.add_range_selector(fig)\nfig = plotly_util.add_shape_region(fig, '2016-04-25', '2016-05-23', 'LightSeaGreen')\nfig = plotly_util.add_shape_region(fig, '2016-05-23', '2016-06-19', 'LightPink')\nfig.update_layout(\n    title_text='Item sales per department(1week MA)',\n    xaxis_title='date',\n    yaxis_title='sales',\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"箱ひげ図で読み取れた内容のいくつかは、上の時系列推移プロットからも読み取れます。時系列推移から読み取れる内容として、下記のようなことが挙げられます。\n\n- dept_idをまたいで、基本的には販売数の上下は似たように推移していることがわかる。\n- HOUSEHOLD_1の販売数が2012年6月に急増している。"},{"metadata":{},"cell_type":"markdown","source":"### Weekday effect per department"},{"metadata":{},"cell_type":"markdown","source":"これまで商品販売数の時系列推移をいくつかプロットしてきましたが、曜日周期性が存在することが明らかです。\n\nそこでdept_id毎にどの曜日に販売されやすいか大まかにつかむための可視化を行います。\n\n下記のヒートマップは全期間のdept_idの曜日ごとの販売数の割合を表しています。列(曜日)方向に和をとると1になります。"},{"metadata":{"ExecuteTime":{"end_time":"2020-05-09T16:21:45.352215Z","start_time":"2020-05-09T16:21:44.637215Z"},"trusted":true},"cell_type":"code","source":"dept_sales = sales.groupby(['dept_id'])[HISTORY_COLUMNS].sum().T\ndept_sales_weekly = pd.merge(dept_sales, calendar[['d', 'weekday']], \n         left_index=True, right_on=['d']).groupby(['weekday']).sum()\n\n\nfig = plt.figure(figsize=(10, 8))\nax = fig.add_subplot(111)\nsns.heatmap(dept_sales_weekly.T.apply(lambda x: x / x.sum(), axis=1)\n            [['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']],\n            cmap='Blues',\n            annot=True,\n            fmt='.3f',\n            linewidths=.5)\nax.set_title('Weekday sales rate of each department', size=14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- 全体的に週末に販売数が集中する。\n- HOBBIES_2カテゴリは、比較的曜日により販売数のバラつきが少ない。\n- FOOD_2カテゴリは金曜日より月曜日の販売数が多い唯一のカテゴリである。"},{"metadata":{},"cell_type":"markdown","source":"### Products not recently sold"},{"metadata":{},"cell_type":"markdown","source":"商品によっては、学習期間の前半には販売されていたものの販売が終了しているものも含まれる可能性があります。\n\nそこで最新日からsalesが非ゼロの時点までを遡り、最新日時点で何日連続で販売がないかを確認してみましょう。(最新日が非ゼロの場合は0)"},{"metadata":{"ExecuteTime":{"end_time":"2020-05-09T16:21:46.031264Z","start_time":"2020-05-09T16:21:45.354215Z"},"trusted":true},"cell_type":"code","source":"df_values = sales[HISTORY_COLUMNS].values\ntmp = np.tile(np.arange(1, len(HISTORY_COLUMNS) + 1)[::-1],\n              (df_values.shape[0], 1))\ntmp_values = ((df_values) > 0) * tmp\nlast_no = np.min(np.where(tmp_values == 0, 9999, tmp_values), axis=1) - 1\nsales['last_sold'] = pd.to_datetime(calendar.loc[HISTORY_COUNTS - last_no - 1, 'date'].values)\n\nlast_sales = sales.groupby('last_sold').size(\n).reset_index().rename(columns={0: 'count'})\nlast_sales['cumulative count'] = last_sales['count'].cumsum()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-05-09T16:21:46.059263Z","start_time":"2020-05-09T16:21:46.032263Z"},"trusted":true},"cell_type":"code","source":"fig = make_subplots(specs=[[{\"secondary_y\": True}]])\nfig.add_trace(go.Scatter(\n    x=last_sales['last_sold'], y=last_sales['count'], mode='markers', name='Last sold item count'),\n    secondary_y=False,)\nfig.add_trace(go.Scatter(\n    x=last_sales['last_sold'], y=last_sales['cumulative count'],\n    name='Cumulative count', line = dict(color='firebrick', dash='dot')),\n    secondary_y=True,)\nfig = plotly_util.add_range_selector(fig)\nfig = plotly_util.add_shape_region(fig, '2016-04-25', '2016-05-23', 'LightSeaGreen')\nfig = plotly_util.add_shape_region(fig, '2016-05-23', '2016-06-19', 'LightPink')\n\nfig.update_layout(\n    title_text='Daily counts of item sold last time',\n    xaxis_title='date',\n)\nfig.update_yaxes(title_text=\"Item count\", secondary_y=False)\nfig.update_yaxes(title_text=\"Cumulative item count\", secondary_y=True)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-05-06T19:08:16.743868Z","start_time":"2020-05-06T19:08:16.738867Z"}},"cell_type":"markdown","source":"9割以上の商品は直近2週間の間に販売履歴が存在するが、少数ではあるが長い期間販売されていないものも存在する。\n\n95%点と99%点を計算すると、それぞれ最終日である2016/04/24の1か月前・3か月半前程度となる。"},{"metadata":{"ExecuteTime":{"end_time":"2020-05-09T16:21:46.068263Z","start_time":"2020-05-09T16:21:46.060264Z"},"trusted":true},"cell_type":"code","source":"print(f\"95%: {last_sales[(last_sales['cumulative count'] / NUM_ITEMS) <= 0.05]['last_sold'].max()}\")\nprint(f\"99%: {last_sales[(last_sales['cumulative count'] / NUM_ITEMS) <= 0.01]['last_sold'].max()}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Store Features"},{"metadata":{},"cell_type":"markdown","source":"### Sales per store"},{"metadata":{"ExecuteTime":{"end_time":"2020-05-08T13:31:25.75483Z","start_time":"2020-05-08T13:31:25.750829Z"}},"cell_type":"markdown","source":"store_id毎の日次販売数を確認します。\n\n最初に1913日分の1商品あたりの販売数がどのように分布しているか、store_id毎に大まかな特徴をつかむため、箱ひげ図で表します。(同様にクリスマスは、外れ値として除外しています)"},{"metadata":{"ExecuteTime":{"end_time":"2020-05-09T16:21:46.696865Z","start_time":"2020-05-09T16:21:46.069263Z"},"trusted":true},"cell_type":"code","source":"store_sales = sales.groupby(['store_id'])[HISTORY_COLUMNS].mean().T\nstore_sales = store_sales.loc[calendar.loc[:HISTORY_COUNTS-1, :][~(calendar['event_name_1'] == 'Christmas')]['d'].values, :]\n\nfig = go.Figure()\nfor col in store_sales:\n    fig.add_trace(go.Box(x=[col]*len(store_sales), y=store_sales[col], name=col))\n    \nfig.update_layout(\n    title_text='Unit sales box plot per store',\n    xaxis_title='store_id',\n    yaxis_title='mean sales per product',\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- CA_3の販売数が他店舗と比較して突出している。\n- TXの店舗の中で、TX_2は販売数平均のバラつきが大きいように見える\n- 基本的にはどの店舗も共通して上側に外れ値が存在する。それぞれのstore_idについて日次販売数のヒストグラムを書くと、右裾の長い形状となることがわかる。\n- WI_1とTX_2にはクリスマス以外で商品の販売が極端少ない日(下側の外れ値)が存在する。"},{"metadata":{},"cell_type":"markdown","source":"続いて店舗毎の販売数の時系列推移をプロットします。"},{"metadata":{"ExecuteTime":{"end_time":"2020-05-09T16:21:47.25398Z","start_time":"2020-05-09T16:21:46.697866Z"},"trusted":true},"cell_type":"code","source":"x = calendar.iloc[:HISTORY_COUNTS, :]['date'].values\nstore_sales = sales.groupby(['store_id'])[HISTORY_COLUMNS].sum()\n\nfig = go.Figure()\nfor store in store_sales.index:\n    y = store_sales.loc[store, :].values\n    fig.add_trace(go.Scatter(x=x, y=y, name=store))\n\nfig = plotly_util.add_range_selector(fig)\nfig = plotly_util.add_shape_region(fig, '2016-04-25', '2016-05-23', 'LightSeaGreen')\nfig = plotly_util.add_shape_region(fig, '2016-05-23', '2016-06-19', 'LightPink')\nfig.update_layout(\n    title_text='Item sales per store',\n    xaxis_title='date',\n    yaxis_title='sales',\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-05-09T16:21:47.34398Z","start_time":"2020-05-09T16:21:47.254979Z"},"trusted":true},"cell_type":"code","source":"fig = go.Figure()\nfor store in store_sales.index:\n    y = store_sales.loc[store, :].rolling(7).mean().values\n    fig.add_trace(go.Scatter(x=x, y=y, name=store))\n\nfig = plotly_util.add_range_selector(fig)\nfig = plotly_util.add_shape_region(fig, '2016-04-25', '2016-05-23', 'LightSeaGreen')\nfig = plotly_util.add_shape_region(fig, '2016-05-23', '2016-06-19', 'LightPink')\nfig.update_layout(\n    title_text='Item sales per store (1week MA)',\n    xaxis_title='date',\n    yaxis_title='sales',\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- WI_1とWI_2ではそれぞれ2012年の10月と6月あたりに販売数が急増している。\n- CA_2についても同様に2015年の6月から7月にかけて、販売数が急増している。\n- 箱ひげ図からも同様に読み取れるように、時系列推移グラフにおいて、CA_4の販売数のバラつきが小さいことが目立つ。\n- 1週間移動平均のグラフで1月に約2回のピークをもつ販売数の周期性がみられる\n\n特にCA_2については比較的最近の2015年に販売数の急増があるため、その前後では販売数推移の傾向が変わっていることも考えられ、モデル学習の際に古いデータが予測に悪影響を及ぼさないか注意が必要である。"},{"metadata":{},"cell_type":"markdown","source":"### Weekday effect per store"},{"metadata":{"ExecuteTime":{"end_time":"2020-05-08T14:02:00.343708Z","start_time":"2020-05-08T14:02:00.340707Z"}},"cell_type":"markdown","source":"店舗の立地によって、どの曜日に販売されやすいかの傾向が異なることが考えられます。\n\n商品カテゴリの場合と同様に店舗毎に曜日の販売数割合を大まかに把握するため、ヒートマップで可視化します。"},{"metadata":{"ExecuteTime":{"end_time":"2020-05-09T16:21:48.088001Z","start_time":"2020-05-09T16:21:47.34498Z"},"trusted":true},"cell_type":"code","source":"store_sales = sales.groupby(['store_id'])[HISTORY_COLUMNS].sum().T\nstore_sales_weekly = pd.merge(store_sales, calendar[['d', 'weekday']], \n         left_index=True, right_on=['d']).groupby(['weekday']).sum()\n\n\nfig = plt.figure(figsize=(10, 8))\nax = fig.add_subplot(111)\nsns.heatmap(store_sales_weekly.T.apply(lambda x: x / x.sum(), axis=1)\n            [['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']],\n            cmap='Blues',\n            annot=True,\n            fmt='.3f',\n            linewidths=.5)\nax.set_title('Weekday sales rate of each store', size=14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- CA_2, WI_1の2店舗は特に週末に販売数が集中する傾向にある。\n- CA_4, WI_2の2店舗は全店舗の中では満遍なく販売数が散らばる傾向にある。"},{"metadata":{},"cell_type":"markdown","source":"## Other Features"},{"metadata":{},"cell_type":"markdown","source":"### products × store raw data"},{"metadata":{},"cell_type":"markdown","source":"同じ商品でも店舗によって客層が異なり、販売数が異なることも考えられます。\n\nここでもまずは、集計データではなく生データから確認してみましょう。ランダムにitem_idを選出し、各店舗での売り上げの推移を確認します。"},{"metadata":{"ExecuteTime":{"end_time":"2020-05-09T16:32:34.95991Z","start_time":"2020-05-09T16:32:34.953909Z"},"scrolled":true,"trusted":true},"cell_type":"code","source":"def random_plot(item_id=None):\n    \"\"\"\n    item_idを引数に渡すことで描画するアイテムを直接指定することも可能\n    \"\"\"\n    fig, axes = plt.subplots(5, 2, figsize=(15, 10))\n    if item_id is None:\n        item = random.sample(list(sales['item_id'].unique()), 1)[0]\n    else:\n        item = item_id\n\n    x = pd.to_datetime(calendar.iloc[:HISTORY_COUNTS, :]['date']).values\n    for ax, store in zip(axes.flatten(), sales['store_id'].unique()):\n        y = sales[(sales['item_id']==item) & (sales['store_id']==store)][HISTORY_COLUMNS].values[0]\n        ax.plot(x, y)\n        ax.set_title(store)\n        ax.set_xlabel('date')\n        ax.set_ylabel('sales')\n\n    fig.suptitle(f'{item} sales per store', fontsize=16)\n    plt.tight_layout()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-05-09T16:32:38.375854Z","start_time":"2020-05-09T16:32:37.698946Z"},"trusted":true},"cell_type":"code","source":"random_plot('FOODS_3_090')","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-05-09T16:41:36.179643Z","start_time":"2020-05-09T16:41:35.394031Z"},"scrolled":true,"trusted":true},"cell_type":"code","source":"random_plot('HOUSEHOLD_1_528')","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-05-09T16:33:17.261568Z","start_time":"2020-05-09T16:33:16.49557Z"},"trusted":true},"cell_type":"code","source":"random_plot('FOODS_2_243')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"商品をランダムに選出し、店舗ごとの販売数の時系列推移を数回比較する。(例示のため、直接item_idを指定してるが引数にitem_idを指定せずに実行するとランダムに商品が選ばれる)\n\n- 商品を販売休止している期間が存在し、店舗毎に異なる場合がある(FOODS_2_243)\n- 販売数の多いFOODS_3_090のように、同タイミングで販売数が0に落ち込む商品も存在する。\n\n生データを確認することで、多様な推移が存在し予測が容易ではないことがわかる。"},{"metadata":{},"cell_type":"markdown","source":"### department rate per store"},{"metadata":{"ExecuteTime":{"end_time":"2020-05-09T16:50:31.593207Z","start_time":"2020-05-09T16:50:31.589207Z"}},"cell_type":"markdown","source":"続いて、店舗毎にどのdept_idの商品が売れやすいかを大まかに把握するために店舗毎のdept_idの販売数比率をヒートマップで可視化する。"},{"metadata":{"ExecuteTime":{"end_time":"2020-05-09T17:14:42.637634Z","start_time":"2020-05-09T17:14:41.897634Z"},"trusted":true},"cell_type":"code","source":"store_dept_sales = sales.groupby(['store_id', 'dept_id']).sum().sum(axis=1).unstack()\nstore_dept_sales = store_dept_sales.apply(lambda x: x / x.sum(), axis=1)\n\nfig = plt.figure(figsize=(10, 8))\nax = fig.add_subplot(111)\nsns.heatmap(store_dept_sales,\n            cmap='RdPu',\n            annot=True,\n            fmt='.3f',\n            linewidths=.5)\nax.set_title('Department sales rate of each store', size=14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- 全般的にFOODS_3の販売数が占める割合が大きい。FOODS_3が全体の半数以上である店舗が3店舗(CA_1, TX_2, WI_3)\n- その中で、CA_2はFOODS_3の販売数が占める割合が比較的小さく、FOODS_1の占める割合が他の店舗と比較して大きい。\n- その他でもHOBBIES_1やHOUSEHOLD_1は店舗によって、割合の差が大きいことが様子が見て取れる。"},{"metadata":{},"cell_type":"markdown","source":"### SNAP effect"},{"metadata":{},"cell_type":"markdown","source":"続いてSNAP購買の可否は、販売数にどの程度の影響を及ぼしているかといった観点での可視化を行います。\n\nまずはじめに、学習期間における各州のSNAPの比率を確認します。"},{"metadata":{"ExecuteTime":{"end_time":"2020-05-09T17:58:15.144287Z","start_time":"2020-05-09T17:58:14.829802Z"},"trusted":true},"cell_type":"code","source":"snap_ca = calendar.iloc[:HISTORY_COUNTS, :][['date', 'weekday', 'snap_CA']].set_index('date')\nsnap_tx = calendar.iloc[:HISTORY_COUNTS, :][['date', 'weekday', 'snap_TX']].set_index('date')\nsnap_wi = calendar.iloc[:HISTORY_COUNTS, :][['date', 'weekday', 'snap_WI']].set_index('date')\n\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 4))\nsnap_ca['snap_CA'].value_counts().plot.bar(ax=ax1)\nsnap_tx['snap_TX'].value_counts().plot.bar(ax=ax2)\nsnap_wi['snap_WI'].value_counts().plot.bar(ax=ax3)\n\nax1.set_title('SNAP days in CA')\nax2.set_title('SNAP days in TX')\nax3.set_title('SNAP days in WI')\nax1.set_xticklabels(['No SNAP', 'SNAP'])\nax2.set_xticklabels(['No SNAP', 'SNAP'])\nax3.set_xticklabels(['No SNAP', 'SNAP'])\nax1.set_ylabel('Day counts')\nax2.set_ylabel('Day counts')\nax3.set_ylabel('Day counts')\nplt.tight_layout()\n\nfig = plt.figure(figsize=(12, 6))\nax = fig.add_subplot(111)\n\ncalendar.iloc[:HISTORY_COUNTS, :][['date', 'weekday', 'snap_CA', 'snap_TX', 'snap_WI']].\\\n    set_index('date').groupby('weekday').sum().plot.barh(ax=ax)\nax.set_title('SNAP day counts per weekday')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"各州についてSNAP購買が許可される日付の合計数は同じですが、日付は異なることがあります。(曜日ごとのSNAP購買が許可された日数の違いとして表れています)"},{"metadata":{},"cell_type":"markdown","source":"続いて各州について、SNAPとNo SNAPの場合に分けて販売数の時系列推移を確認してみます。"},{"metadata":{"ExecuteTime":{"end_time":"2020-05-09T18:31:59.44978Z","start_time":"2020-05-09T18:31:57.45378Z"},"scrolled":true,"trusted":true},"cell_type":"code","source":"cax1 = snap_ca[snap_ca['snap_CA']==1].reset_index()['date'].values\ncay1 = np.extract((snap_ca['snap_CA']==1).values,\n                sales[sales['state_id']=='CA'][HISTORY_COLUMNS].sum().values)\n\ncax2 = snap_ca[snap_ca['snap_CA']==0].reset_index()['date'].values\ncay2 = np.extract((snap_ca['snap_CA']==0).values,\n                sales[sales['state_id']=='CA'][HISTORY_COLUMNS].sum().values)\n\ntxx1 = snap_tx[snap_tx['snap_TX']==1].reset_index()['date'].values\ntxy1 = np.extract((snap_tx['snap_TX']==1).values,\n                sales[sales['state_id']=='TX'][HISTORY_COLUMNS].sum().values)\n\ntxx2 = snap_tx[snap_tx['snap_TX']==0].reset_index()['date'].values\ntxy2 = np.extract((snap_tx['snap_TX']==0).values,\n                sales[sales['state_id']=='TX'][HISTORY_COLUMNS].sum().values)\n\nwix1 = snap_wi[snap_wi['snap_WI']==1].reset_index()['date'].values\nwiy1 = np.extract((snap_wi['snap_WI']==1).values,\n                sales[sales['state_id']=='WI'][HISTORY_COLUMNS].sum().values)\n\nwix2 = snap_wi[snap_wi['snap_WI']==0].reset_index()['date'].values\nwiy2 = np.extract((snap_wi['snap_WI']==0).values,\n                sales[sales['state_id']=='WI'][HISTORY_COLUMNS].sum().values)\n\n\nfig = make_subplots(rows=3, cols=1, subplot_titles=('Item Sales in CA', 'Item Sales in TX', 'Item Sales in WI'))\nfig.add_trace(go.Scatter(x=cax1, y=cay1, name='SNAP(CA)'), row=1, col=1)\nfig.add_trace(go.Scatter(x=cax2, y=cay2, name='No SNAP(CA)'), row=1, col=1)\nfig.add_trace(go.Scatter(x=txx1, y=txy1, name='SNAP(TX)'), row=2, col=1)\nfig.add_trace(go.Scatter(x=txx2, y=txy2, name='No SNAP(TX)'), row=2, col=1)\nfig.add_trace(go.Scatter(x=wix1, y=wiy1, name='SNAP(WI)'), row=3, col=1)\nfig.add_trace(go.Scatter(x=wix2, y=wiy2, name='No SNAP(WI)'), row=3, col=1)\n\nfig = plotly_util.add_range_selector(fig)\nfig.update_layout(\n    height=1000,\n    title_text='Item sales by SNAP and No SNAP',\n    xaxis_title='date',\n    yaxis_title='sales',\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"SNAPフラグが1の日と0の日の販売数推移を州別でプロットしたところ下記のようなことがわかる。\n\n- どの州もSNAPフラグが1の日の方が、平均的に販売数が高いことがわかる。\n- 中でもWI州はプロットを見て一目でわかる程度に、他の州よりもSNAPの効果が大きい。\n\nSNAPによる効果の大きさは、WI>>TX>CAであるがSNAPの日の平均販売数とNo SNAPの日の平均販売数の比率を確認する以下のグラフでも確認できる。"},{"metadata":{"ExecuteTime":{"end_time":"2020-05-09T18:43:59.709993Z","start_time":"2020-05-09T18:43:59.694996Z"},"trusted":true},"cell_type":"code","source":"fig = make_subplots(rows=1, cols=3, shared_yaxes=True,\n                    subplot_titles=(f'CA ({cay1.mean() / cay2.mean():.3f})',\n                                    f'TX ({txy1.mean() / txy2.mean():.3f})',\n                                    f'WI ({wiy1.mean() / wiy2.mean():.3f})'))\n\nfig.add_trace(go.Bar(x=['SNAP', 'No SNAP'], y=[cay1.mean(), cay2.mean()], name='CA'), row=1, col=1)\nfig.add_trace(go.Bar(x=['SNAP', 'No SNAP'], y=[txy1.mean(), txy2.mean()], name='TX'), row=1, col=2)\nfig.add_trace(go.Bar(x=['SNAP', 'No SNAP'], y=[wiy1.mean(), wiy2.mean()], name='WI'), row=1, col=3)\n\nfig.update_layout(\n    height=400,\n    title_text='Item average daily sales by SNAP and No SNAP',\n    xaxis_title='date',\n    yaxis_title='sales',\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"SNAPは貧しい家族向けの制度であり、SNAP対象外の家庭には無関係であるため、貧しい家庭の多い地域の店舗で販売数増加の効果が大きいと考えられます。"},{"metadata":{},"cell_type":"markdown","source":"### Event calendar in 2015"},{"metadata":{},"cell_type":"markdown","source":"直近の1年について、どのようなイベントがあるかを総販売数グラフにアノテーションをつける形で確認します。\n\n2016年は4月までしかデータが存在しないので、2015年のイベントを表示します。"},{"metadata":{"ExecuteTime":{"end_time":"2020-05-09T19:32:03.525685Z","start_time":"2020-05-09T19:32:02.699686Z"},"trusted":true},"cell_type":"code","source":"fig = make_subplots(rows=6, cols=2)\ntotal_sales = sales[HISTORY_COLUMNS].sum()\n\nfor month in range(1, 13):\n    x = calendar[(calendar['year'] == 2015) & (calendar['month'] == month)]['date'].values\n    events = calendar[(calendar['event_name_1'].notnull()) &\n                      (calendar['year'] == 2015) &\n                      (calendar['month'] == month)]\n    fig = fig.add_trace(go.Scatter(\n        x=x,\n        y=total_sales.loc[\n            calendar[(calendar['year'] == 2015) & (calendar['month'] == month)]['d']\n            ].values,\n        name=f'month: {month}',\n        ),\n        row=(month - 1) // 2 + 1,\n        col=(month - 1) % 2 + 1,\n        )\n    for idx in events.index:\n        fig.add_annotation(x=events.loc[idx, 'date'],\n                           y=total_sales.loc[events.loc[idx, 'd']],\n                           text=events.loc[idx, 'event_name_1'],\n                           row=(month - 1) // 2 + 1,\n                           col=(month - 1) % 2 + 1)\n# fig = plotly_util.format_annotation(fig)\nfig.update_layout(\n    height=1200,\n    title_text='Item Sales in 2015 with events',\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"クリスマスには販売を停止していることは、これまでの分析で確認した通りですが、それ以外のイベントでは総販売数で見て一目でわかるほどのイベント効果はないようです。(あくまで目視レベルでの話です。7月のIndependenceDayは週末の販売数増加に逆らって減少している感じがします。)"},{"metadata":{},"cell_type":"markdown","source":"## Basic Timeseries Analysis"},{"metadata":{},"cell_type":"markdown","source":"**TODO**"},{"metadata":{},"cell_type":"markdown","source":"## Learn  about RMSSE(WRMSSE)"},{"metadata":{},"cell_type":"markdown","source":"これまでcsv形式で与えられたデータセットから様々な集計を実施してきました。\n\n本コンペティションでは、モデルの予測の良さを評価するための評価指標が定められているため、モデリングに進む前に評価指標と指標の選択理由についてしっかりと把握しておきたいと思います。"},{"metadata":{},"cell_type":"markdown","source":"**TODO**"},{"metadata":{},"cell_type":"markdown","source":"## Proceed to FE and modeling"},{"metadata":{},"cell_type":"markdown","source":"ここまでの内容をもとに、特徴量エンジニアリングとモデリングに進みます。\n\nまたリーダーボードのPublicスコアに最適化しないように、良いCV方法の検討も併せて実施します。"},{"metadata":{},"cell_type":"markdown","source":"M5_Competition_FE_and_modelingカーネルにて公開予定。"}],"metadata":{"kernelspec":{"display_name":"Python 3.7.6 64-bit ('.venv': venv)","language":"python","name":"python37664bitvenvvenv57c51957199f49dc8560bc8b24294d71"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":true}},"nbformat":4,"nbformat_minor":4}