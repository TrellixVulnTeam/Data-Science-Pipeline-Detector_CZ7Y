{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Transformerによる時系列予測","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# upload modules","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from distutils.dir_util import copy_tree\n\ncopy_tree(src = \"/kaggle/input/m5-forecasting/src\", \n          dst = \"/kaggle/working/src\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# import modules","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport sys \nimport gc \nimport warnings \nimport random\nfrom pathlib import Path\n\nimport numpy as np\nimport torch \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsys.path.append(os.getcwd())\n\nseed = 0\nrandom.seed(seed)  \nnp.random.seed(seed)  \ntorch.manual_seed(seed) \n\npd.set_option('display.max_columns', 1000)\npd.set_option('display.max_rows', 5000)\n\n%matplotlib inline\nplt.tick_params(colors='white')\nsns.set_style(\"darkgrid\")\n\nwarnings.simplefilter('ignore', FutureWarning)\nwarnings.simplefilter('ignore', pd.core.common.SettingWithCopyWarning)\nwarnings.simplefilter('ignore', RuntimeWarning)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from src.data.make_dataset import (\n    read_dataset, \n    get_date_cols, \n    merge_dataset\n)\nfrom src.features.build_dataset import (\n    TSdatasets, \n    setting_dataloader\n)\n\nfrom src.features.build_features import (\n    select_activate_items, \n    complement_missing,\n    add_base_features,\n    feature_enginearing\n)\nfrom src.models.eval_model import (\n    WRMSSEEvaluator, \n    root_mean_squared_error, \n    eval_quantity\n)\nfrom src.models.setting_model import (\n    AdaBound, \n    GradualWarmupScheduler\n)\nfrom src.models.architecture import TransformerModel\nfrom src.models.loss import RMSELoss\nfrom src.models.setting_model import setting_model\nfrom src.models.train_model import RecursiveModel\nfrom src.visualization.visualize import (\n    plot_sales,\n    plot_lr_and_sr,\n    plot_losses,\n    plot_eval, \n    plot_eval_per_group,\n    plot_prediction\n)\nfrom src.models.predict_model import (\n    output_inverse, \n    to_submission\n)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Config","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"private_sub = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_path = 'models/transformer.model'\nvis_dir = 'reports/figures'\nreports_dir = 'reports'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dataset\nN_IDS = 5000\n# N_IDS = 30490\nmax_train_size = 364 * 5\n\ntest_size = 28\nd_col = 'd'\n\n# features\ndiff_trans = False\n\npow_trans = False\nseason_diff_interval = 0\n# season_diff_interval = 28\nstd_trans = True\nminmax_trans = False\n\nbase_cols = [\n    'date', \n    'weekday', \n    'month', \n    'year', \n    'event_name_1', \n    'event_type_1', \n    'event_name_2', \n    'event_type_2', \n    'snap_CA', \n    'snap_TX', \n    'snap_WI'\n]\n\nnum_cols = [\n    'sell_price', \n    'is_snap'\n]\nsales_cat_cols = [\n    'id', \n    'item_id', \n    'dept_id', \n    'cat_id', \n    'store_id', \n    'state_id'\n]\ncat_cols = [\n    'quarter', \n    'is_weekend', \n    'part_of_month', \n    'event_name_1', \n    'event_type_1'\n]\n\nall_cat_cols = sales_cat_cols + cat_cols \n\n# if 0, onehot\ncat_emb = {\n    'id': 80,\n    'item_id': 30, \n    'dept_id': 0,\n    'cat_id': 0, \n    'store_id': 0, \n    'state_id': 0,\n    'quarter': 0,\n    'is_weekend': 0,\n    'part_of_month': 0,\n    'weekday': 3,\n    'month': 4,\n    'event_name_1': 10,\n    'event_type_1':0,\n    'event_name_2': 10,\n    'event_type_2':0\n}\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model\nepochs = 30\nbatch_size = 1024//4\nclipping_value = 0.5\nlog_interval = 1\n\nbptt_x = 28 * 3\nbptt_y = test_size\nlags = [(1, 6), (7, 28 * 3)] # (tau, period)\n\nall_lags = [lag for tau, period in lags for lag in range(tau, period+1, tau)]\nt_emb = sum([lag[1] // lag[0] for lag in lags])\nmax_tau, max_lag  = lags[-1]\n\nscheduled_sampling = True\nsrc_mask = False\nmemory_mask = False\nnhid = 2048 // 2 # the dimension of the feedforward network model in nn.TransformerEncoder\nnlayers = 6 // 2 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\nnhead = 8 // 2 # the number of heads in the multiheadattention models\ndropout = 0.2 # the dropout value\n# fc_dims = [128, 64]\nfc_dims = []\nactivation = 'relu'\n\nlr = 1e-3 # learning rate\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Read","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sell_prices, sample_submission, calendar, sales_train = read_dataset(private_sub)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"level_cols, train_d_cols, test_d_cols, d2F_map = get_date_cols(\n    sales_train, \n    sample_submission, \n    max_train_size, \n    max_lag, \n    private_sub=private_sub\n)\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature engineering","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train = sales_train.iloc[:N_IDS, :]\n\nX = merge_dataset(\n    sales_train, \n    calendar, \n    sell_prices, \n    base_cols,\n    level_cols,\n    train_d_cols,\n    test_d_cols\n)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = select_activate_items(X, train_d_cols, test_size, bptt_x, max_lag)\nX = complement_missing(X)\nX = add_base_features(X)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_sales(\n    X.groupby('d')['sales'].sum(), \n    X['sales'], \n    train_d_cols\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X, all_cat_cols, all_num_cols, list_dtrans, id_enc = feature_enginearing(\n    X, \n    train_d_cols[max_lag+1:-test_size], \n    test_d_cols, \n    lags, \n    max_lag,\n    sales_cat_cols,\n    cat_cols,\n    num_cols, \n    diff_trans,\n    dtrans_map={'sales':[pow_trans, std_trans, minmax_trans, season_diff_interval], \n                'sell_price':[False, True, False, 0]}, \n    clipping_range={'sales': (0.0, 1.0), \n                    'sell_price': (0.0, 1.0)}\n)\n\ntrainloader, validloader, validmaskloader, testloader = setting_dataloader(\n    X, \n    train_d_cols,\n    test_d_cols,\n    all_num_cols,\n    all_cat_cols,\n    bptt_x,\n    bptt_y,\n    max_lag,\n    test_size,\n    batch_size,\n)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_sales(\n    X.groupby(['id', 'd'])['sales'].sum().reset_index().pivot(\n        index='id', columns='d', values='sales'\n    ).sum(0), \n    X['sales'], \n    train_d_cols\n)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modeling","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model_params = dict(\n    src_seq_len=bptt_x,\n    d_model=len(all_num_cols),\n    nhead=nhead,\n    nhid=nhid,\n    nlayers=nlayers,\n    dropout=dropout,\n    fc_dims=fc_dims,\n    activation=activation,\n    use_src_mask=src_mask,\n    use_memory_mask=memory_mask,\n)\n\nopt_params = dict(lr=lr, weight_decay=1e-4, amsgrad=False)\n\nlr_params = dict(T_max=epochs - (epochs // 10), eta_min=1e-5)\n\nwarmup_params = dict(multiplier=1, total_epoch=epochs // 10)\n\nsr_params = dict(\n    decay_schedules=\"inverse_sigmoid_decay\",\n    k=epochs,\n    start=1.0,\n    end=0.01,\n    slope=0.3,\n)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_, optimizer, _, lr_scheduler, sr_scheduler = setting_model(\n    X,\n    cat_emb,\n    all_cat_cols,\n    all_num_cols,\n    model_params,\n    opt_params,\n    lr_params,\n    warmup_params,\n    sr_params,\n)\n\nplot_lr_and_sr(epochs, optimizer, lr_scheduler, sr_scheduler)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = RecursiveModel(bptt_y, all_lags)\nmodel.setting_model(\n    *setting_model(\n        X,\n        cat_emb,\n        all_cat_cols,\n        all_num_cols,\n        model_params,\n        opt_params,\n        lr_params,\n        warmup_params,\n        sr_params,\n    )\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Training...')\nlosses = model.train(model_path, trainloader, validloader, epochs)\n\ndel trainloader\ngc.collect()\n\nplot_losses(model, losses)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_idx = testloader.dataset.en_cat_i[:, 0, 0].argsort()\ntrain_pred_d_cols = train_d_cols[-test_size*2:-test_size]\nvalid_pred_d_cols = train_d_cols[-test_size:]\n\ntrainmaskset = TSdatasets(\n    X, \n    train_d_cols[-((test_size * 2) + max_lag):-test_size], \n    all_num_cols, \n    all_cat_cols, \n    bptt_x, \n    bptt_y, \n    max_lag,\n    mask=True\n)\ntrainmaskloader = torch.utils.data.DataLoader(\n    trainmaskset, batch_size=batch_size, shuffle=False\n)\n\nprint('Predicting...')\n\noutput_train = output_inverse(\n    model.predict(trainmaskloader)[pred_idx], \n    list_dtrans[0], \n    id_enc.classes_, \n    train_pred_d_cols,\n    diff_trans,\n    sales_train.loc[\n        :N_IDS, train_d_cols[-test_size*2-1]].values,    \n)\n\noutput_valid = output_inverse(\n    model.predict(validmaskloader)[pred_idx], \n    list_dtrans[0], \n    id_enc.classes_, \n    valid_pred_d_cols,\n    diff_trans,\n    sales_train.loc[\n        :N_IDS, train_d_cols[-test_size-1]].values\n)\n\noutput_test = output_inverse(\n    model.predict(testloader)[pred_idx], \n    list_dtrans[0], \n    id_enc.classes_, \n    test_d_cols,\n    diff_trans,\n    sales_train.loc[\n        :N_IDS, train_d_cols[-1]].values\n)\n\n\noutput_train = pd.concat(\n    [sales_train[level_cols].set_index('id'), output_train], \n    axis=1\n)\n\noutput_valid = pd.concat(\n    [sales_train[level_cols].set_index('id'), output_valid], \n    axis=1\n)\n\ntrue_train = sales_train[level_cols + train_pred_d_cols[-test_size:]].set_index('id')\ntrue_valid = sales_train[level_cols + valid_pred_d_cols].set_index('id')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_eval(\n    Path(vis_dir, 'eval_train'), \n    output_train[train_pred_d_cols[-test_size:]], \n    true_train[train_pred_d_cols[-test_size:]]\n)\nplot_eval(\n    Path(vis_dir, 'eval_valid'), \n    output_valid[valid_pred_d_cols], \n    true_valid[valid_pred_d_cols]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_eval_per_group(\n    Path(vis_dir, 'eval_valid'), output_valid, true_valid, 'dept_id', valid_pred_d_cols\n)\nplot_eval_per_group(\n    Path(vis_dir, 'eval_valid'), output_valid, true_valid, 'store_id', valid_pred_d_cols\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_prediction(\n    Path(vis_dir, 'pred_test'), \n    sales_train.loc[: N_IDS - 1, train_d_cols], \n    output_test\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eval_quantity(\n    Path(reports_dir, 'eval_results.json'),\n    output_valid,\n    sales_train,\n    calendar,\n    sell_prices,\n    valid_pred_d_cols,\n)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"my_submission = to_submission(\n    output_test,\n    sales_train,\n    sample_submission,\n    test_d_cols,\n    d2F_map,\n    private_sub=private_sub,\n\n)\n\nmy_submission.to_csv(\"submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_submission","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}