{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc\nimport os","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load data"},{"metadata":{"trusted":true},"cell_type":"code","source":"path = \"../input/m5-forecasting-accuracy\"\ncalendar = pd.read_csv(os.path.join(path, \"calendar.csv\"))\nselling_prices = pd.read_csv(os.path.join(path, \"sell_prices.csv\"))\nsample_submission = pd.read_csv(os.path.join(path, \"sample_submission.csv\"))\nsales = pd.read_csv(os.path.join(path, \"sales_train_validation.csv\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"calendar.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, var in enumerate([\"year\", \"weekday\", \"month\", \n                          \"snap_CA\", \"snap_TX\", \"snap_WI\"]):\n    plt.figure()\n    g = sns.countplot(calendar[var])\n    g.set_xticklabels(g.get_xticklabels(), rotation=45)\n    g.set_title(var)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OrdinalEncoder\n\ndef prep_calendar(df):\n    df = df.copy()\n    temp = [\"wday\", \"month\", \"year\", \"event_name_1\", \"event_type_1\"]\n    df = df[[\"wm_yr_wk\", \"d\"] + temp]\n    df.fillna(\"missing\", inplace=True)\n    df[temp] = OrdinalEncoder().fit_transform(df[temp])\n    for v in temp:\n        df[temp] = df[temp].astype(\"uint8\")\n    df.wm_yr_wk = df.wm_yr_wk.astype(\"uint16\")\n    return df\n\ncalendar = prep_calendar(calendar)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"calendar.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Notes for modeling\n\n\n- wday -> integer coding & embedding\n\n- year(?) -> integer coding & embedding\n\n- month(?) -> integer coding & embedding\n\n- \"event_name_1\", \"event_type_1\"\": simple imputer & integer coding & embedding\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"sales.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, var in enumerate([\"state_id\", \"store_id\", \"cat_id\", \"dept_id\"]):\n    plt.figure()\n    g = sns.countplot(sales[var])\n    g.set_xticklabels(g.get_xticklabels(), rotation=45)\n    g.set_title(var)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales.item_id.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Drop dates to save space. Offline, this is not required."},{"metadata":{"trusted":true},"cell_type":"code","source":"sales.drop([\"d_\" + str(i+1) for i in range(800)], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Reshaping\n\nWe now reshape the data from wide to long, using \"id\" as fixed and swapping \"d_1\", to \"d_1913\". "},{"metadata":{"trusted":true},"cell_type":"code","source":"sales[sales.item_id==\"HOBBIES_1_001\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def melt_sales(df):\n    df = df.drop([\"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"], axis=1).melt(\n        id_vars=['id'], var_name='d', value_name='demand')\n    return df\n\nsales = melt_sales(sales)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Add reshaped submission file\n\nSo that it sneaks through data preprocessing easily."},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Turn strings like \"F1\" to \"d_1914\"\ndef map_f2d(d_col, id_col):\n    eval_flag = id_col.str.endswith(\"evaluation\")\n    return \"d_\" + (d_col.str[1:].astype(\"int\") + 1913 + 28 * eval_flag).astype(\"str\")\n\n# Reverse\ndef map_d2f(d_col, id_col):\n    eval_flag = id_col.str.endswith(\"evaluation\")\n    return \"F\" + (d_col.str[2:].astype(\"int\") - 1913 - 28 * eval_flag).astype(\"str\")\n\n# Example\nmap_f2d(pd.Series([\"F1\", \"F2\", \"F28\", \"F1\", \"F2\", \"F28\"]), \n        pd.Series([\"validation\", \"validation\", \"validation\", \"evaluation\", \"evaluation\", \"evaluation\"]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = sample_submission.melt(id_vars=\"id\", var_name=\"d\", value_name=\"demand\").assign(\n    demand=np.nan,\n    d = lambda df: map_f2d(df.d, df.id))\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales = pd.concat([sales, submission])\nsales.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Change \"evaluation\" to \"validation\"..."},{"metadata":{"trusted":true},"cell_type":"code","source":"sales.id = sales.id.str.replace(\"evaluation\", \"validation\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\ndef add_lagged_features(df):\n    df['lag_t56'] = df.groupby('id')['demand'].transform(lambda x: x.shift(56))\n    df['rolling_mean_t30'] = df.groupby('id')['demand'].transform(lambda x: x.shift(56).rolling(30, min_periods=1).mean())\n  \n    temp = [\"lag_t56\", \"rolling_mean_t30\"]\n    df.dropna(subset=temp, inplace=True)    \n    df[temp] = StandardScaler().fit_transform(df[temp])\n    for v in temp:\n        df[v] = df[v].astype(\"float32\")\n    return df\n\nsales = add_lagged_features(sales)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Add relevant id information\n\nAfter combination of training and test data, we can join further info."},{"metadata":{"trusted":true},"cell_type":"code","source":"def expand_id(id):\n    return id.str.split(\"_\", expand=True).assign(\n        dept_id=lambda df: df.iloc[:,0] + \"_\" + df.iloc[:,1], \n        item_id=lambda df: df.iloc[:,0] + \"_\" + df.iloc[:,1] + \"_\" + df.iloc[:, 2],\n        store_id=lambda df: df.iloc[:,3] + \"_\" + df.iloc[:,4]).drop(np.arange(6), axis=1)\n\n# Example\nexpand_id(sales[\"id\"].head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"uid = pd.Series(sales[\"id\"].unique())\nid_lookup = expand_id(uid)\nid_lookup[\"id\"] = uid\n\nencode_item_id = OrdinalEncoder()\nencode_dept_id = OrdinalEncoder()\nencode_store_id = OrdinalEncoder()\nid_lookup[\"item_id\"] = encode_item_id.fit_transform(id_lookup[[\"item_id\"]]).astype(\"uint16\")\nid_lookup[\"dept_id\"] = encode_dept_id.fit_transform(id_lookup[[\"dept_id\"]]).astype(\"uint8\")\nid_lookup[\"store_id\"] = encode_store_id.fit_transform(id_lookup[[\"store_id\"]]).astype(\"uint8\")\n\nid_lookup.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales = sales.merge(id_lookup, on=\"id\", how=\"left\")\ndel sales[\"id\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Selling prices\n\nContains selling prices for each store_id, item_id_wm_yr_wk combination."},{"metadata":{"trusted":true},"cell_type":"code","source":"selling_prices.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Derive some time related features:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Add relative change\ndef prep_selling_prices(df):\n    df = df.copy()\n    df[\"store_id\"] = encode_store_id.transform(df[[\"store_id\"]]).astype(\"uint8\")\n    df[\"item_id\"] = encode_item_id.transform(df[[\"item_id\"]]).astype(\"uint16\")\n    df[\"wm_yr_wk\"] = df[\"wm_yr_wk\"].astype(\"uint16\")\n    \n    df[\"sell_price_rel_diff\"] = df.groupby([\"store_id\", \"item_id\"])[\"sell_price\"].pct_change()\n    sell_price_cummin = df.groupby([\"store_id\", \"item_id\"])[\"sell_price\"].cummin()\n    sell_price_cummax = df.groupby([\"store_id\", \"item_id\"])[\"sell_price\"].cummax()\n    df[\"sell_price_cumrel\"] = (df[\"sell_price\"] - sell_price_cummin) / (sell_price_cummax - sell_price_cummin)\n    df.fillna({\"sell_price_rel_diff\": 0, \"sell_price_cumrel\": 1}, inplace=True)\n    floats = [\"sell_price_cumrel\", \"sell_price_rel_diff\", \"sell_price\"]\n    sc = StandardScaler()\n    df[floats] = sc.fit_transform(df[floats])\n    for v in floats:\n        df[v] = df[v].astype(\"float32\")\n    return df\n\nselling_prices = prep_selling_prices(selling_prices)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"selling_prices.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Notes for modeling\n\n**Features**:\n\n- sell_price: numeric\n\n- relative change to last date (per store and item): numeric\n\n- price position between cummin and cummax (per store and item): numeric\n\n**Reshape**: No\n\n**Merge key(s)**: to sales data by store_id, item_id, wm_yr_wk (through calendar data)"},{"metadata":{},"cell_type":"markdown","source":"### Combine all"},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()\nsales = sales.merge(calendar, how=\"left\", on=\"d\")\ndel sales[\"d\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()\nsales = sales.merge(selling_prices, how=\"left\", on=[\"wm_yr_wk\", \"store_id\", \"item_id\"])\ndel sales[\"wm_yr_wk\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales.fillna({\"sell_price\": 0, \"sell_price_rel_diff\": 0, \"sell_price_cumrel\": 0}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Modelling\n\nWe will now use Tensorflow & Keras to model sales demand as a function of the prepared input. Key pieces are the categorical predictors prepared above. They will be fed through embedding layers and combined to dense numeric features.\n\nFor simplicity, we use MSE as evaluation criterion. This will most certainly change in future commits."},{"metadata":{},"cell_type":"markdown","source":"### Create input dicts for multi-input"},{"metadata":{"trusted":true},"cell_type":"code","source":"training_flag = pd.notna(sales.demand)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_Xy(df, ind=None, return_y = True):\n    if ind is not None:\n        df = df[ind]\n    X = {\"dense1\": df[[\"lag_t56\", \"rolling_mean_t30\", \"sell_price\", \"sell_price_rel_diff\", \n                       \"sell_price_cumrel\"]].to_numpy(dtype=\"float32\"),\n         \"item_id\": df[[\"item_id\"]].to_numpy(dtype=\"uint16\")}\n    for i, v in enumerate([\"wday\", \"month\", \"year\", \"event_name_1\", \"event_type_1\", \"dept_id\", \"store_id\"]):\n        X[v] = df[[v]].to_numpy(dtype=\"uint8\")\n    if return_y:\n        return X, df.demand.to_numpy(dtype=\"float32\")\n    else:\n        return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sales.to_csv(\"sales.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, y_train = make_Xy(sales, training_flag) # make_Xy(sales[0:1000000])\ny_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = make_Xy(sales, ~training_flag, return_y=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del sales\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The model"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\ntf.keras.backend.clear_session()  # For easy reset of notebook state.\n\nfrom tensorflow.keras.layers import Dense, Input, Embedding\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import concatenate, Flatten\nfrom tensorflow.keras import regularizers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dense part\ndense_input = Input(shape=(5, ), name='dense1')\ndense_branch = Dense(30, activation=\"relu\")(dense_input)\ndense_branch = Dense(30, activation=\"relu\")(dense_branch)\n\n# Embedded input\nwday_input = Input(shape=(1,), name='wday')\nmonth_input = Input(shape=(1,), name='month')\nyear_input = Input(shape=(1,), name='year')\nevent_name_1_input = Input(shape=(1,), name='event_name_1')\nevent_type_1_input = Input(shape=(1,), name='event_type_1')\nitem_id_input = Input(shape=(1,), name='item_id')\ndept_id_input = Input(shape=(1,), name='dept_id')\nstore_id_input = Input(shape=(1,), name='store_id')\n\n# Embedding layers\nwday_emb = Flatten()(Embedding(7, 3, )(wday_input))\nmonth_emb = Flatten()(Embedding(12, 3)(month_input))\nyear_emb = Flatten()(Embedding(6, 3)(year_input))\nevent_name_1_emb = Flatten()(Embedding(31, 5)(event_name_1_input))\nevent_type_1_emb = Flatten()(Embedding(5, 2)(event_type_1_input))\nitem_id_emb = Flatten()(Embedding(len(encode_item_id.categories_[0]), 50)(item_id_input))\nitem_id_emb = Dense(20, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01))(item_id_emb)\ndept_id_emb = Flatten()(Embedding(7, 3)(dept_id_input))\nstore_id_emb = Flatten()(Embedding(10, 4)(store_id_input))\n\nx = concatenate([dense_branch, wday_emb, month_emb, year_emb, event_name_1_emb,\n                event_type_1_emb, item_id_emb, dept_id_emb, store_id_emb])\nx = Dense(100, activation=\"relu\")(x)\nx = Dense(20, activation=\"relu\")(x)\nprediction = Dense(1, activation=\"linear\", name='output')(x)\n\nmodel = Model(inputs={\"dense1\": dense_input, \"wday\": wday_input, \"month\": month_input,\n                      \"year\": year_input, \"event_name_1\": event_name_1_input, \"event_type_1\": event_type_1_input,\n                      \"item_id\": item_id_input, \"dept_id\": dept_id_input, \"store_id\": store_id_input},\n              outputs=prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()\n\nkeras.utils.plot_model(model, 'model.png', show_shapes=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss=keras.losses.mean_squared_error,\n              optimizer=keras.optimizers.RMSprop(),\n              metrics=['mse'])\n\nhistory = model.fit(X_train, \n                    y_train,\n                    batch_size=4096,\n                    epochs=10,\n                    validation_split=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the evaluation metrics over epochs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('modelM5.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict(X_test, batch_size=4096)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = submission.assign(\n    demand = np.clip(pred, 0, None),\n    d = lambda df: map_d2f(df.d, df.id))\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Right column order\ncol_order = [\"id\"] + [\"F\" + str(i + 1) for i in range(28)]\nsubmission = submission.pivot(index=\"id\", columns=\"d\", values=\"demand\").reset_index()[col_order]\n\n# Right row order\nsubmission = sample_submission[[\"id\"]].merge(submission, how=\"left\", on=\"id\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":4}