{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# M5 Forecasting Accuracy","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\npd.options.display.max_columns = 50\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom  datetime import datetime, timedelta\n\nimport os\nimport gc\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-22T10:13:49.996675Z","iopub.execute_input":"2021-11-22T10:13:49.997631Z","iopub.status.idle":"2021-11-22T10:13:51.01311Z","shell.execute_reply.started":"2021-11-22T10:13:49.997528Z","shell.execute_reply":"2021-11-22T10:13:51.011845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# データの取得, DataFrame化\npath = \"../input/m5-forecasting-accuracy\"\n\nsales = pd.read_csv(os.path.join(path, \"sales_train_evaluation.csv\"))\ncalendar = pd.read_csv(os.path.join(path, \"calendar.csv\"))\nprices = pd.read_csv(os.path.join(path, \"sell_prices.csv\"))\nsample_submission = pd.read_csv(os.path.join(path, \"sample_submission.csv\"))\n\n# 回帰する日付の追加\nfor d in range(1942,1970):\n    col = 'd_' + str(d)\n    sales[col] = 0\n    sales[col] = sales[col].astype(np.int16)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-22T10:13:52.917967Z","iopub.execute_input":"2021-11-22T10:13:52.91831Z","iopub.status.idle":"2021-11-22T10:14:05.361869Z","shell.execute_reply.started":"2021-11-22T10:13:52.918272Z","shell.execute_reply":"2021-11-22T10:14:05.360687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# メモリ消費を抑えるために, ダウンキャストする　(kaggle notebook上でデータを整理する際にRAMを消費尽くしてしまう)\n# 最小値, 最大値が収まるデータ型に変更する\ndef downcast(df):\n    cols = df.dtypes.index.tolist() \n    types = df.dtypes.values.tolist()\n    for i,t in enumerate(types):\n        if 'int' in str(t):\n            if df[cols[i]].min() > np.iinfo(np.int8).min and df[cols[i]].max() < np.iinfo(np.int8).max:\n                df[cols[i]] = df[cols[i]].astype(np.int8)\n            elif df[cols[i]].min() > np.iinfo(np.int16).min and df[cols[i]].max() < np.iinfo(np.int16).max:\n                df[cols[i]] = df[cols[i]].astype(np.int16)\n            elif df[cols[i]].min() > np.iinfo(np.int32).min and df[cols[i]].max() < np.iinfo(np.int32).max:\n                df[cols[i]] = df[cols[i]].astype(np.int32)\n            else:\n                df[cols[i]] = df[cols[i]].astype(np.int64)\n        elif 'float' in str(t):\n            if df[cols[i]].min() > np.finfo(np.float16).min and df[cols[i]].max() < np.finfo(np.float16).max:\n                df[cols[i]] = df[cols[i]].astype(np.float16)\n            elif df[cols[i]].min() > np.finfo(np.float32).min and df[cols[i]].max() < np.finfo(np.float32).max:\n                df[cols[i]] = df[cols[i]].astype(np.float32)\n            else:\n                df[cols[i]] = df[cols[i]].astype(np.float64)\n        elif t == np.object:\n            if cols[i] == 'date':\n                df[cols[i]] = pd.to_datetime(df[cols[i]], format='%Y-%m-%d')\n            else:\n                df[cols[i]] = df[cols[i]].astype('category')\n    return df  \n\nsales = downcast(sales)\nprices = downcast(prices)\ncalendar = downcast(calendar)\n\n# データ整理 meltメソッドを用いてsalesのcolumn'd_〇'を'd'columnにまとめ, calender.csvと'd' columnでmergeできるようにする\ndf = pd.melt(sales, id_vars=['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'], var_name='d', value_name='sold').dropna()\ndf = pd.merge(df, calendar, on='d', how='left')\ndf = pd.merge(df, prices, on=['store_id','item_id','wm_yr_wk'], how='left') \ndisplay(df.head())\nprint(df.info())","metadata":{"execution":{"iopub.status.busy":"2021-11-22T10:14:05.363892Z","iopub.execute_input":"2021-11-22T10:14:05.364223Z","iopub.status.idle":"2021-11-22T10:18:58.834381Z","shell.execute_reply.started":"2021-11-22T10:14:05.364178Z","shell.execute_reply":"2021-11-22T10:18:58.833443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Number of Index : 59181090 (= 30980(商品の数) * 1941(日数))  ","metadata":{}},{"cell_type":"markdown","source":"# EDA  ","metadata":{}},{"cell_type":"markdown","source":"### sell-priceについて","metadata":{}},{"cell_type":"code","source":"# 特定の商品において, priceとsoldの関係性を簡単に確認 soldとpriceの相関係数も計算\nitemID =['HOBBIES_1_001','HOBBIES_1_010','HOBBIES_2_001','HOBBIES_2_100',\n        'HOUSEHOLD_1_001','HOUSEHOLD_1_010','HOUSEHOLD_2_001','HOUSEHOLD_2_100',\n        'FOODS_1_001','FOODS_1_010','FOODS_2_001','FOODS_2_100']\nprint('赤 : sold / 青 : price')\nprint('CA_1')\nr,c=0,0\nfig, ax = plt.subplots(3,4,figsize=(18, 12))\nfor i in range(0,12):\n    df_store = df[df['store_id']=='CA_1']\n    item_df = df_store[df_store['item_id']==itemID[i]]\n    print('{} sold/price相関係数:'.format(itemID[i]),item_df['sold'].corr(item_df['sell_price']))\n    ax2 = ax[r][c].twinx() \n    ax[r][c].plot(item_df['date'],item_df['sell_price'],color='b',alpha=0.5)\n    ax2.plot(item_df['date'],item_df['sold'],color='r',alpha=0.5)\n    ax[r][c].set_title(itemID[i])\n    c+=1\n    if c ==4:\n        c=0\n        r+=1\n#plt.savefig('CA_1_price.png')\nplt.show()\n\nprint('\\nCA_2')\nr,c=0,0\nfig, ax = plt.subplots(3,4,figsize=(18, 12))\nfor i in range(0,12):\n    df_store = df[df['store_id']=='CA_2']\n    item_df = df_store[df_store['item_id']==itemID[i]]\n    print('{} sold/price相関係数:'.format(itemID[i]),item_df['sold'].corr(item_df['sell_price']))\n    ax2 = ax[r][c].twinx() \n    ax[r][c].plot(item_df['date'],item_df['sell_price'],color='b',alpha=0.5)\n    ax2.plot(item_df['date'],item_df['sold'],color='r',alpha=0.5)\n    ax[r][c].set_title(itemID[i])\n    c+=1\n    if c ==4:\n        c=0\n        r+=1\n#plt.savefig('CA_2_price.png')\nplt.show()\n\nprint('\\nCA_3')\nr,c=0,0\nfig, ax = plt.subplots(3,4,figsize=(18, 12))\nfor i in range(0,12):\n    df_store = df[df['store_id']=='CA_3']\n    item_df = df_store[df_store['item_id']==itemID[i]]\n    print('{} sold/price相関係数:'.format(itemID[i]),item_df['sold'].corr(item_df['sell_price']))\n    ax2 = ax[r][c].twinx() \n    ax[r][c].plot(item_df['date'],item_df['sell_price'],color='b',alpha=0.5)\n    ax2.plot(item_df['date'],item_df['sold'],color='r',alpha=0.5)\n    ax[r][c].set_title(itemID[i])\n    c+=1\n    if c ==4:\n        c=0\n        r+=1\n#plt.savefig('CA_3_price.png')\nplt.show()\n\nprint('\\nTX_1')\nr,c=0,0\nfig, ax = plt.subplots(3,4,figsize=(18, 12))\nfor i in range(0,12):\n    df_store = df[df['store_id']=='TX_1']\n    item_df = df_store[df_store['item_id']==itemID[i]]\n    print('{} sold/price相関係数:'.format(itemID[i]),item_df['sold'].corr(item_df['sell_price']))\n    ax2 = ax[r][c].twinx() \n    ax[r][c].plot(item_df['date'],item_df['sell_price'],color='b',alpha=0.5)\n    ax2.plot(item_df['date'],item_df['sold'],color='r',alpha=0.5)\n    ax[r][c].set_title(itemID[i])\n    c+=1\n    if c ==4:\n        c=0\n        r+=1\n#plt.savefig('TX_1_price.png')\nplt.show()\n\nprint('\\nWI_1')\nr,c=0,0\nfig, ax = plt.subplots(3,4,figsize=(18, 12))\nfor i in range(0,12):\n    df_store = df[df['store_id']=='WI_1']\n    item_df = df_store[df_store['item_id']==itemID[i]]\n    print('{} sold/price相関係数:'.format(itemID[i]),item_df['sold'].corr(item_df['sell_price']))\n    ax2 = ax[r][c].twinx() \n    ax[r][c].plot(item_df['date'],item_df['sell_price'],color='b',alpha=0.5)\n    ax2.plot(item_df['date'],item_df['sold'],color='r',alpha=0.5)\n    ax[r][c].set_title(itemID[i])\n    c+=1\n    if c ==4:\n        c=0\n        r+=1\n#plt.savefig('WI_1_price.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-22T06:15:01.319201Z","iopub.execute_input":"2021-11-22T06:15:01.319428Z","iopub.status.idle":"2021-11-22T06:15:52.251035Z","shell.execute_reply.started":"2021-11-22T06:15:01.319401Z","shell.execute_reply":"2021-11-22T06:15:52.250018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n・priceの変動は少なく, 利用する期間内において周期性は確認できない  \n・相関係数はsoldとpriceの変動間隔が異なるため参考にしづらいが, 図を確認する限りでは商品の価格変動と, 販売個数に相関はない","metadata":{}},{"cell_type":"markdown","source":"### soldについて","metadata":{}},{"cell_type":"code","source":"# 例として一つの商品のsoldの推移を確認する\ndf_1 = df[df['item_id']=='HOBBIES_1_001']\nplt.plot(df_1['date'],df_1['sold'])\nplt.title('HOBBIES_1_001')\nplt.xlabel('date')\nplt.ylabel('sold')\n#plt.savefig('HOBBIES_1_001_sold_.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-22T06:15:52.252333Z","iopub.execute_input":"2021-11-22T06:15:52.252711Z","iopub.status.idle":"2021-11-22T06:15:52.52801Z","shell.execute_reply.started":"2021-11-22T06:15:52.252675Z","shell.execute_reply":"2021-11-22T06:15:52.526948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# soldの分布を確認する\nstate_id_lst = df['state_id'].unique()\nstore_id_lst = df['store_id'].unique()\ncategory = df['cat_id'].unique()\n\nfig, ax = plt.subplots(2,5,figsize=(20, 9))\nr,c=0,0\nfor store_id in store_id_lst:\n    df_store = df[df['store_id']==store_id]\n    sns.boxplot(x='cat_id',y='sold',data=df_store,ax=ax[r][c])\n    ax[r][c].set_title(store_id)\n    c +=1\n    if c==5:\n        r+=1\n        c=0\n#plt.savefig('Dist_sold.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-22T06:15:52.529616Z","iopub.execute_input":"2021-11-22T06:15:52.529928Z","iopub.status.idle":"2021-11-22T06:16:19.649632Z","shell.execute_reply.started":"2021-11-22T06:15:52.529891Z","shell.execute_reply":"2021-11-22T06:16:19.648542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* 多くの商品のsoldは0であり, おそらく商品によって多数売れることが想定される\n* 最大販売数においてFOODSが最も多く, HOUSEHOLD, HOBBIESはそれと比較して少ない傾向がある","metadata":{}},{"cell_type":"code","source":"\n# 各州における全ての商品の販売数(総和)の推移を可視化\nfig, ax = plt.subplots(1,3,figsize=(20, 4))\nfor i,state_id in enumerate(state_id_lst):\n    df_state = df[df['state_id']==state_id]\n    sold=df_state.groupby('date').sum()['sold']\n    sold_rol = sold.rolling('30D',center=True).mean()\n    ax[i].plot(sold,c='b') # 生データの推移：青\n    ax[i].plot(sold_rol,c='r') # 移動平均：赤\n    ax[i].set_ylim(0,26000)\n    ax[i].set_title(state_id)\n#plt.savefig('Each_state_all_goods_sold.png')\nplt.show()\n# 各州における全ての商品の販売数(総和) 週,月,年について可視化\nfig, ax = plt.subplots(1,3,figsize=(20, 4))\nfor i,state_id in enumerate(state_id_lst):\n    df_state = df[df['state_id']==state_id]\n    df_state=df_state.groupby('date').sum()\n    sns.boxplot(x='wday',y='sold',data=df_state,ax=ax[i])\n    ax[i].set_title(state_id)\n    ax[i].set_xticklabels(['Saturday', 'Sunday','Monday', 'Tuesday', 'Wendthday', 'Thursday', 'Fryday'])\n#plt.savefig('Each_state_all_goods_sold_box_week.png')\nplt.show()\nfig, ax = plt.subplots(1,3,figsize=(20, 4))\nfor i,state_id in enumerate(state_id_lst):\n    df_state = df[df['state_id']==state_id]\n    df_state=df_state.groupby('date').sum()\n    sns.boxplot(x='month',y='sold',data=df_state,ax=ax[i])\n    ax[i].set_title(state_id)\n    ax[i].set_xticklabels(['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'])\n#plt.savefig('Each_state_all_goods_sold_box_month.png')\nplt.show()\nfig, ax = plt.subplots(1,3,figsize=(20, 4))\nfor i,state_id in enumerate(state_id_lst):\n    df_state = df[df['state_id']==state_id]\n    df_state=df_state.groupby('date').sum()\n    sns.boxplot(x='year',y='sold',data=df_state,ax=ax[i])\n    ax[i].set_title(state_id)\n    ax[i].set_xticklabels(['2011', '2012','2013', '2014', '2015', '2016'])\n#plt.savefig('Each_state_all_goods_sold_box_year.png')\nplt.show()\n\n\n# 各お店における全ての商品の販売数(総和)の推移を可視化\nr,c=0,0\nfig, ax = plt.subplots(2,5,figsize=(30, 8))\nfor store_id in store_id_lst:\n    df_store = df[df['store_id']==store_id]\n    sold=df_store.groupby('date').sum()['sold']\n    sold_rol = sold.rolling('30D',center=True).mean()\n    ax[r][c].plot(sold,c='b') # 生データの推移：青\n    ax[r][c].plot(sold_rol,c='r') # 移動平均：赤\n    ax[r][c].set_ylim(0,9000)\n    ax[r][c].set_title(store_id)\n    c+=1\n    if c ==5:\n        c=0\n        r+=1\n#plt.savefig('Each_state_each_goods_sold_year.png')\nplt.show()\n        \n# 全てのお店における全ての商品の販売数の推移を可視化\nsold=df.groupby('date').sum()['sold']\nsold_rol = sold.rolling('30D',center=True).mean()\nplt.plot(sold,c='b') # 生データの推移：青\nplt.plot(sold_rol,c='r') # 移動平均：赤\nplt.title('all aggregate units sales')\n#plt.savefig('all_aggregate_units_sales.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-22T06:16:19.651037Z","iopub.execute_input":"2021-11-22T06:16:19.65154Z","iopub.status.idle":"2021-11-22T06:17:30.979241Z","shell.execute_reply.started":"2021-11-22T06:16:19.651507Z","shell.execute_reply":"2021-11-22T06:17:30.978312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# 各お店におけるカテゴリ毎の商品の販売数(総和)の推移を可視化\n#　箱ひげ図によりデータの分布を可視化\nr,c=0,0\nfor state_id in state_id_lst:\n    fig, ax = plt.subplots(3,4,figsize=(25, 15))\n    df_state = df[df['state_id']==state_id]\n    for i,cat_id in enumerate(category):\n        df_state_cat = df_state[df_state['cat_id']==cat_id]\n        df_sc=df_state_cat.groupby('date').sum()\n        sold_rol = df_sc['sold'].rolling('30D',center=True).mean()\n        ax[i][0].plot(df_sc['sold'],c='b') # 生データの推移：青\n        ax[i][0].plot(sold_rol,c='r') # 移動平均：赤\n        ax[i][0].set_title(state_id+'_'+cat_id)\n        sns.boxplot(x='wday', y='sold', data=df_sc,ax=ax[i][1])\n        ax[i][1].set_title(state_id+'_'+cat_id+' week')\n        ax[i][1].set_xticklabels(['Saturday', 'Sunday','Monday', 'Tuesday', 'Wendthday', 'Thursday', 'Fryday'])\n        sns.boxplot(x='month', y='sold', data=df_sc,ax=ax[i][2])\n        ax[i][2].set_title(state_id+'_'+cat_id+' month')\n        ax[i][2].set_xticklabels(['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'])\n        sns.boxplot(x='year', y='sold', data=df_sc,ax=ax[i][3])\n        ax[i][3].set_title(state_id+'_'+cat_id+' year')\n        ax[i][3].set_xticklabels(['2011', '2012','2013', '2014', '2015', '2016'])\n    #plt.savefig('{}_sold_box.png'.format(state_id))\n    plt.show()\n    \n","metadata":{"execution":{"iopub.status.busy":"2021-11-22T06:17:30.980864Z","iopub.execute_input":"2021-11-22T06:17:30.98109Z","iopub.status.idle":"2021-11-22T06:17:57.403971Z","shell.execute_reply.started":"2021-11-22T06:17:30.981062Z","shell.execute_reply":"2021-11-22T06:17:57.402971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### sold について 可視化結果からの考察\n* 全体, 州, お店, 商品のカテゴリ毎において商品販売数は全て右肩上がり\n * 年々増加が確認される\n * (移動平均の推移より, 年単位の周期性があるのではないか？)\n* 州ごとに販売個数の推移が異なる\n* 州が同一であってもお店によって総販売個数の推移の様子が異なる\n* 州, 商品カテゴリにおいて曜日毎に販売個数が異なる\n * 土曜日曜が高く、水曜日まで減少し、木曜日から増加に転じる傾向(週のなかでの周期性)\n * 商品カテゴリにおいて, HOBBISEでは土曜＞日曜, HOUSEHOLD, FOODSでは日曜＞土曜となった\n \nしたがって、曜日、年の情報は回帰に特に有効であると考える","metadata":{}},{"cell_type":"markdown","source":"### SNAPの有無について\nSNAP : 低所得の家族や個人に、食品を購入するための電子給付振替のデビットカードを提供するものである。多くの州では、月の10日間に渡って金銭的な給付が人々に分配され、それぞれの日に1/10の人々がカードで給付を受けることができる。\n⇒　食品商品において販売数が増減する可能性","metadata":{}},{"cell_type":"code","source":"# SNAPの有無による, FOODの販売数の変化を確認\n\n# 各州における全ての商品の販売数(総和)の推移を可視化\nfig, ax = plt.subplots(1,3,figsize=(20, 4))\nfor i,state_id in enumerate(state_id_lst):\n    df_state = df[df['state_id']==state_id]\n    df_state = df_state[df_state['cat_id']=='FOODS']\n    sold=df_state.groupby('date').sum()['sold']\n    sold_rol = sold.rolling('30D',center=True).mean()\n    ax[i].plot(sold,c='c') # 生データの推移：シアン\n    ax[i].plot(sold_rol,c='m') # 移動平均：マゼンタ\n    \n    df_state_snap = df_state[df_state['snap_{}'.format(state_id)]==1]\n    df_ss=df_state_snap.groupby('date').sum()['sold']\n    ss_sold_rol = df_ss.rolling('30D',center=True).mean()\n    ax[i].plot(df_ss,c='b') # SNAP 生データの推移：青\n    ax[i].plot(ss_sold_rol,c='r') # SNAP 移動平均：赤\n    ax[i].set_ylim(0,16000)\n    ax[i].set_title(state_id)\n#plt.savefig('Each_state_SNAP_year.png')\nplt.show()\n\n\n# 各お店における全ての商品の販売数(総和)の推移を可視化\nr,c=0,0\nfig, ax = plt.subplots(2,5,figsize=(30, 8))\nfor store_id in store_id_lst:\n    df_store = df[df['store_id']==store_id]\n    df_state = df_state[df_state['cat_id']=='FOODS']\n    sold=df_store.groupby('date').sum()['sold']\n    sold_rol = sold.rolling('30D',center=True).mean()\n    ax[r][c].plot(sold,c='c') # 生データの推移：シアン\n    ax[r][c].plot(sold_rol,c='m') # 移動平均：マゼンタ\n    \n    df_store_snap = df_store[df_store['snap_{}'.format(store_id[:2])]==1]\n    df_ss=df_store_snap.groupby('date').sum()['sold']\n    ss_sold_rol = df_ss.rolling('30D',center=True).mean()\n    ax[r][c].plot(df_ss,c='b') # SNAP 生データの推移：青\n    ax[r][c].plot(ss_sold_rol,c='r') # SNAP 移動平均：赤\n    ax[r][c].set_ylim(0,9000)\n    ax[r][c].set_title(store_id)\n    c+=1\n    if c ==5:\n        c=0\n        r+=1\n#plt.savefig('Each_store_SNAP_year.png')\nplt.show()\n        \n","metadata":{"execution":{"iopub.status.busy":"2021-11-22T06:17:57.405678Z","iopub.execute_input":"2021-11-22T06:17:57.406213Z","iopub.status.idle":"2021-11-22T06:18:35.647432Z","shell.execute_reply.started":"2021-11-22T06:17:57.406163Z","shell.execute_reply":"2021-11-22T06:18:35.643929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(3,3,figsize=(20, 12))\nfor i,state_id in enumerate(state_id_lst):\n    df_state = df[df['state_id']==state_id]\n    df_state = df_state[df_state['cat_id']=='FOODS']\n    df_state_snap = df_state[df_state['snap_{}'.format(state_id)]==1]\n    df_ss=df_state_snap.groupby('date').sum()\n\n    sns.boxplot(x='wday', y='sold', data=df_ss,ax=ax[i][0])\n    ax[i][0].set_title(state_id+'_'+'FOODS'+' week')\n    ax[i][0].set_xticklabels(['Saturday', 'Sunday','Monday', 'Tuesday', 'Wendthday', 'Thursday', 'Fryday'])\n    sns.boxplot(x='month', y='sold', data=df_ss,ax=ax[i][1])\n    ax[i][1].set_title(state_id+'_'+'FOODS'+' month')\n    ax[i][1].set_xticklabels(['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'])\n    sns.boxplot(x='year', y='sold', data=df_ss,ax=ax[i][2])\n    ax[i][2].set_title(state_id+'_'+'FOODS'+' year')\n    ax[i][2].set_xticklabels(['2011', '2012','2013', '2014', '2015', '2016'])\n#plt.savefig('Each_store_goods_SNAP_year.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-22T06:18:35.650745Z","iopub.execute_input":"2021-11-22T06:18:35.651251Z","iopub.status.idle":"2021-11-22T06:18:48.286939Z","shell.execute_reply.started":"2021-11-22T06:18:35.651209Z","shell.execute_reply":"2021-11-22T06:18:48.285886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* お店ごとにSNAPの有無で若干の商品の販売数が上昇が確認できる  \n * WI_2, WI_3が顕著\n* SNAPを無視した際の箱ひげ図と比較して, SNAPがある場合, 月ごとの販売数の変動が若干大きくなったになった印象","metadata":{}},{"cell_type":"markdown","source":"## 特徴量エンジニアリング","metadata":{}},{"cell_type":"markdown","source":"EDAで得られた情報から特徴量エンジニアリング(機械学習モデルに入力する特徴量の選択, 生成)を行う。 EDAより, 次の特徴量を追加することが有効であることが考えられる\n* 一週間, 一月のラグ\n* 移動平均  \n\nしたがって, 今回は存在するデータの最長1月先まで予測するため, 1月前の販売数とそれを基準として, 1日前, 2日前, 1週間前といったラグデータを用いる。\nまた, 全体的なトレンドとして商品販売数が同様な推移をしていることから, 周期的な推移が確認されるラグと, それぞれの移動平均が有効となることが考えられる。  \nまた, データの階層(CA, CA_1, CA_1_HOBBIESのような)ごとにトレンドが存在する可能性があるため, TargetEncodingを行う(Ordered Target Statistics)","metadata":{}},{"cell_type":"code","source":"d_id = dict(zip(df.id.cat.codes, df.id))\nd_store_id = dict(zip(df.store_id.cat.codes, df.store_id))\n\n# 意味が重複しているデータの除去\ndf.drop([\"date\", \"wm_yr_wk\", \"weekday\"],axis=1,inplace=True)\n\n# d(初日から何日目であるかを表すcolumn)をint型にする\ndf.d = df['d'].apply(lambda x: x.split('_')[1]).astype(np.int16)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-22T10:18:58.836128Z","iopub.execute_input":"2021-11-22T10:18:58.836473Z","iopub.status.idle":"2021-11-22T10:20:15.486946Z","shell.execute_reply.started":"2021-11-22T10:18:58.836442Z","shell.execute_reply":"2021-11-22T10:20:15.485767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# カテゴリカル変数をエンコード\ncols = df.dtypes.index.tolist()\ntypes = df.dtypes.values.tolist()\nfor i,type in enumerate(types):\n    if type.name == 'category':\n        df[cols[i]] = df[cols[i]].cat.codes\n        \n\n# lag特徴の追加\n# 予測する最大が28日後であるため, 28日前に対してlagを計算する\n# 1,2,3日前, 1,2,4週間前, 約2月前のsoldを追加\nlags = [1,2,3,7,14,28,56]\nfor lag in lags:\n    df['sold_lag_'+str(lag)] = df.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],as_index=False)['sold'].shift(lag+28).astype(np.float16)\n    \n# ラグにおける移動平均の追加\nsold_lag_cols = ['sold_lag_7','sold_lag_28']\nfor win in [7,28] :\n    for lag,lag_col in zip([7,28], sold_lag_cols):\n        df['rmean_{}_{}'.format(lag,win)] = df.groupby(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'])['sold_lag_'+str(lag)].transform(lambda x: x.rolling(window=win).mean()).astype(np.float16)\n\n# Target Encoding \n# sold に対して Orderd Target Encoding\ncols = ['state_id','store_id','cat_id','dept_id']\nnew_cols = ['state_id_ots','store_id_ots','cat_id_ots','dept_id_ots']\ndf_new = pd.DataFrame()\nimport category_encoders as ce\nte = ce.CatBoostEncoder(random_state=42)\nfor c,nc in zip(cols,new_cols):\n    df[nc] = te.fit_transform(df[c],df['sold'])\ndf = downcast(df)        \n\n# ラグの導入によるNanの除去\ndf = df[df['d']>=57]\ndf.tail()","metadata":{"execution":{"iopub.status.busy":"2021-11-22T10:20:15.488744Z","iopub.execute_input":"2021-11-22T10:20:15.489039Z","iopub.status.idle":"2021-11-22T10:26:54.029991Z","shell.execute_reply.started":"2021-11-22T10:20:15.489001Z","shell.execute_reply":"2021-11-22T10:26:54.029134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-11-22T10:26:54.031876Z","iopub.execute_input":"2021-11-22T10:26:54.032135Z","iopub.status.idle":"2021-11-22T10:26:54.046308Z","shell.execute_reply.started":"2021-11-22T10:26:54.032103Z","shell.execute_reply":"2021-11-22T10:26:54.045298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 予測に利用する作成したデータの作成\ndf.to_pickle('data.pkl')\ndel df\ngc.collect();","metadata":{"execution":{"iopub.status.busy":"2021-11-22T10:26:54.047442Z","iopub.execute_input":"2021-11-22T10:26:54.047669Z","iopub.status.idle":"2021-11-22T10:27:03.209057Z","shell.execute_reply.started":"2021-11-22T10:26:54.047633Z","shell.execute_reply":"2021-11-22T10:27:03.208138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling and Forecast","metadata":{}},{"cell_type":"code","source":"# 訓練, 検証用のデータの分割, テストデータを指定\ndata = pd.read_pickle('data.pkl')\nvalid = data[(data['d']>=1914) & (data['d']<1942)][['id','d','sold']]\ntest = data[data['d']>=1942][['id','d','sold']]\neval_preds = test['sold']\nvalid_preds = valid['sold']","metadata":{"execution":{"iopub.status.busy":"2021-11-22T10:27:03.210739Z","iopub.execute_input":"2021-11-22T10:27:03.21112Z","iopub.status.idle":"2021-11-22T10:27:09.407374Z","shell.execute_reply.started":"2021-11-22T10:27:03.211062Z","shell.execute_reply":"2021-11-22T10:27:09.406426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from lightgbm import LGBMRegressor\nimport joblib\nimport optuna\nimport sklearn.datasets\n\n# optuna, lightgbmに用いるseed値\nseed=42\n\ndef objectives(trial):\n    # optunaでのハイパーパラメータサーチ範囲の設定\n    params = {\n            'learning_rate' : trial.suggest_float('learning_rate',0.05,0.1),\n            'num_leaves': trial.suggest_int('num_leaves', 63, 255),\n            'max_depth' : trial.suggest_int('max_depth', 4,8),\n            'min_child_samples': trial.suggest_int('min_child_samples', 10, 100)\n            }\n\n    # LightGBMで学習+予測\n    model = LGBMRegressor(random_state=seed,**params)# 追加部分\n    model.fit(X_train, y_train,eval_set=[(X_train,y_train),(X_valid,y_valid)],eval_metric='tweedie',early_stopping_rounds=20,verbose=False)\n\n    # 検証データを用いた評価\n    score = model.score(X_valid, y_valid)\n    \n    return score\n\n#store ごとにモデルを作成し, テストデータを予測する\nstores = sales.store_id.cat.codes.unique().tolist()\nfor store in stores:\n    df = data[data['store_id']==store]\n    \n    #訓練, 検証用, (テスト)　にデータを分割　\n    X_train, y_train = df[df['d']<1914].drop('sold',axis=1), df[df['d']<1914]['sold']\n    X_valid, y_valid = df[(df['d']>=1914) & (df['d']<1942)].drop('sold',axis=1), df[(df['d']>=1914) & (df['d']<1942)]['sold']\n    X_test = df[df['d']>=1942].drop('sold',axis=1)\n    \n    print('*****Prediction for Store: {}*****'.format(d_store_id[store]))\n    \n    # optunaによる最適化呼び出し\n    opt = optuna.create_study(direction='maximize',sampler=optuna.samplers.TPESampler(seed=seed))\n    opt.optimize(objectives, n_trials=10)\n\n    # 最適パラメータ取得\n    trial = opt.best_trial\n    params_best = dict(trial.params.items())\n    params_best['random_seed'] = 0\n\n    # 最適パラメータで学習/予測    \n    model = LGBMRegressor(n_estimators=1000,random_state=seed,**params_best)\n    \n    model.fit(X_train, y_train, eval_set=[(X_train,y_train),(X_valid,y_valid)],\n             eval_metric='tweedie', verbose=20, early_stopping_rounds=50)\n    valid_preds[X_valid.index] = model.predict(X_valid)\n    eval_preds[X_test.index] = model.predict(X_test)\n    filename = 'model'+str(d_store_id[store])+'.pkl'\n    # modelの保存\n    joblib.dump(model, filename)\n    del model, X_train, y_train, X_valid, y_valid\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-11-22T10:27:09.408993Z","iopub.execute_input":"2021-11-22T10:27:09.409248Z","iopub.status.idle":"2021-11-22T11:26:10.025346Z","shell.execute_reply.started":"2021-11-22T10:27:09.409216Z","shell.execute_reply":"2021-11-22T11:26:10.024241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 訓練の際のvalidationの予測結果を獲得\nvalid['sold'] = valid_preds\nvalidation = valid[['id','d','sold']]\nvalidation = pd.pivot(validation, index='id', columns='d', values='sold').reset_index()\nvalidation.columns=['id'] + ['F' + str(i + 1) for i in range(28)]\nvalidation.id = validation.id.map(d_id).str.replace('evaluation','validation')\n\n# testの予測結果を獲得\ntest['sold'] = eval_preds\nevaluation = test[['id','d','sold']]\nevaluation = pd.pivot(evaluation, index='id', columns='d', values='sold').reset_index()\nevaluation.columns=['id'] + ['F' + str(i + 1) for i in range(28)]\n#　カテゴリーIDをそれぞれのカテゴリーにリマップ\nevaluation.id = evaluation.id.map(d_id)\n\n#　submissionの作成 \nsubmit = pd.concat([validation,evaluation]).reset_index(drop=True)\nsubmit.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T11:26:10.028159Z","iopub.execute_input":"2021-11-22T11:26:10.028888Z","iopub.status.idle":"2021-11-22T11:26:14.58042Z","shell.execute_reply.started":"2021-11-22T11:26:10.028841Z","shell.execute_reply":"2021-11-22T11:26:14.57974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"参考 :    \nhttps://www.kaggle.com/headsortails/back-to-predict-the-future-interactive-m5-eda   \nhttps://www.kaggle.com/anshuls235/time-series-forecasting-eda-fe-modelling","metadata":{}}]}