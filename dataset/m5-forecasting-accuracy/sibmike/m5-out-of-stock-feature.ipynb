{"cells":[{"metadata":{},"cell_type":"markdown","source":"### M5 - 'out_of_stock' feature\n\nAs @narsil notes that ***Sales = min (demand, inventory)*** in [this discussion](https://www.kaggle.com/c/m5-forecasting-accuracy/discussion/138085#790628). So we need **to distinguish beween zero demand and zero supply**. \n'out_of_stock' feature flags highly improbable long gaps for a given 'id'. \n\nThis notebook describes general approach and logic behind it.\nIt is a bit slow and needs a performance boost to build the feature."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# General imports\nimport numpy as np\nimport pandas as pd\nimport os, sys, gc, time, warnings, pickle, psutil, random\n\nfrom math import ceil\nfrom tqdm import tqdm\nfrom sklearn.preprocessing import LabelEncoder\n\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now we have 3 sets of features\ngrid_df = pd.concat([pd.read_pickle('/kaggle/input/m5-simple-fe/grid_part_1.pkl'),\n                     pd.read_pickle('/kaggle/input/m5-simple-fe/grid_part_2.pkl').iloc[:,2:],\n                     pd.read_pickle('/kaggle/input/m5-simple-fe/grid_part_3.pkl').iloc[:,2:]],\n                     axis=1)\ngrid_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets pick a product with pronounced gaps: 'HOBBIES_1_288_CA_1_validation'\nm = grid_df.id=='HOBBIES_1_288_CA_1_validation'\nsales_ts = grid_df.loc[m,'sales'].values\nsales_ts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def gap_finder(ts):\n    \n    # this function finds gaps and calculates their length:\n    ts = (~(ts > 0)).astype(int)\n\n    for i, val in enumerate(ts):\n        if val == 0: \n            continue\n        else: \n            ts[i] += ts[i-1]\n            ts[i-1] = -1\n    return ts\n\ndef gap_counter(ts):\n    \n    # value_counts for gaps lengths\n    \n    counts = np.unique(ts, return_counts=True)\n    return dict(zip(counts[0], counts[1]))\n\nm = grid_df.id=='HOBBIES_1_288_CA_1_validation'\n\nsales_gaps = gap_counter(gap_finder(grid_df.loc[m,'sales'].values))\nsales_gaps","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets try to build a synthetic series with gaps.\n# We assume products have a constant chance of being sold on any particular day.\n# So for every day we will flip an unfair coin with probability of sale equal to 'dates_with sale'/'all_dates'\n# >>>This might be an oversimplistic assumption, a moving window might be used instead.\n\ndef synth_sales(gaps_dict, min_gap=1000):\n    \n    sum_sale_days = gaps_dict[0] # key '0' gives number of days with sales\n    sum_days = sum(gaps_dict.values()) # sum of all keys - number of all days\n    \n    # Sum of days in gaps longer than minimum gap length:\n    sum_gap_length = sum([k for k in [*sales_gaps.keys()] if k > min_gap])\n    \n    # Exlude all the gaps longer than min_gap_length from probability calculation:\n    p = sum_sale_days/(sum_days-sum_gap_length)\n    \n    return np.random.binomial(1, p, sum(gaps_dict.values()))\n\nsynth_sales_gaps = gap_counter(gap_finder(synth_sales(sales_gaps)))\nsynth_sales_gaps","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# As you can see we dont have results > 20. \n# To make sure this is a consistent result lets run simulation 1,000 times:\n# >>>> n equal 1,000 might be an overshot for some ids.\n\nn=1000\n\nsym_df = pd.DataFrame([gap_counter(gap_finder(synth_sales(sales_gaps))) for i in range(n)])\ngap_length_prob = (sym_df.sum(axis=0)/n).sort_index()\ngap_length_prob","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The shortest gap that has been seen in less than 5% of simulated series:\nmin_gap_length = min(gap_length_prob[gap_length_prob<0.05].index)\nmin_gap_length","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now we exclude the gaps longer than min_gap_length from 'probability of sale' calculation, \n# because we assume them to be non-random.\n# Run the simulation recursively until the min_gap_length does not decrease:\n\nn=1000\nnew_min_gap_length = 0\n\nwhile new_min_gap_length != min_gap_length:\n    \n    if new_min_gap_length!=0: min_gap_length=new_min_gap_length\n\n    sym_df = pd.DataFrame([gap_counter(gap_finder(synth_sales(sales_gaps, min_gap_length))) for i in range(n)])\n    gap_length_prob = (sym_df.sum(axis=0)/n).sort_index()\n\n    # Lets find the shortes gap that has been seen in les than 5% of simulated series:\n    new_min_gap_length = min(gap_length_prob[gap_length_prob<0.05].index)\n\nmin_gap_length","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Finally we need to make a feature 'out_of_stock' for the product:\nm = grid_df.id=='HOBBIES_1_288_CA_1_validation'\nidx = grid_df.loc[m,'sales'].index\n\ngf = pd.Series(gap_finder(grid_df.loc[m,'sales'].values), index = idx)\ngf = gf.replace(-1,np.nan).fillna(method='backfill') \ngf = gf > min_gap_length\ngf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let calculate 'out-of-stock' for the first 30 ids:\ngrid_df['out_of_stock'] = 0\n\nn=1000\nprods = list(grid_df.id.unique())\ngap_length_list = []\n\nfor prod_id in tqdm(prods[:30]):\n    \n    m = grid_df.id == prod_id\n    idx = grid_df.loc[m,'sales'].index\n\n    sales_gaps = gap_counter(gap_finder(grid_df.loc[m,'sales'].values))\n\n    sym_df = pd.DataFrame([gap_counter(gap_finder(synth_sales(sales_gaps))) for i in range(n)])\n    gap_length_prob = (sym_df.sum(axis=0)/n).sort_index()\n\n    min_gap_length = min(gap_length_prob[gap_length_prob<0.05].index)\n    new_min_gap_length = 0\n    \n    while new_min_gap_length < min_gap_length:\n\n        if new_min_gap_length!=0: min_gap_length=new_min_gap_length\n\n        sym_df = pd.DataFrame([gap_counter(gap_finder(synth_sales(sales_gaps, min_gap_length))) for i in range(n)])\n        gap_length_prob = (sym_df.sum(axis=0)/n).sort_index()\n\n        # Lets find the shortes gap that has been seen in les than 5% of simulated series:\n        new_min_gap_length = min(gap_length_prob[gap_length_prob<0.05].index)\n\n    gf = pd.Series(gap_finder(grid_df.loc[m,'sales'].values), index = idx)\n    gf = gf.replace(-1,np.nan).fillna(method='backfill') \n    gf = gf > min_gap_length\n    grid_df.loc[m,'out_of_stock'] = gf*1\n    gap_length_list += [min_gap_length]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# TOO SLOW"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let take 'out-of-stock' gap length for different products:\n#from collections import Counter\n#Counter(gap_length_list)\n\ngap_length_list[:15]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# As you can see the out-of-stock gap length vary extremely from product to product.\n# For densily traded products it maybe as short as 8 days, while for rare products it might be over 60 days.\n\n# The current approach to calculating it is SLOW. I will try to refactor it and build the feature in the next notebook.\n# Comments are welcome. Please let me know if you spot inefficiencies or mistakes.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" [Discussion here.](https://www.kaggle.com/c/m5-forecasting-accuracy/discussion/138085#790628)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}