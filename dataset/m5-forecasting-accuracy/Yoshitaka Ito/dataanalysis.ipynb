{"cells":[{"metadata":{},"cell_type":"markdown","source":"以下のnotebookを参考に、モデリング前の時系列データの分析方法を学ぶ  \n\n* [M5 Forecasting - Starter Data Exploration](https://www.kaggle.com/robikscube/m5-forecasting-starter-data-exploration)\n* [Back to (predict) the future - Interactive M5 EDA](https://www.kaggle.com/headsortails/back-to-predict-the-future-interactive-m5-eda)","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom itertools import cycle\npd.set_option('max_columns', 50)\nplt.style.use('bmh')\ncolor_pal = plt.rcParams['axes.prop_cycle'].by_key()['color']\ncolor_cycle = cycle(plt.rcParams['axes.prop_cycle'].by_key()['color'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. ファイル内容の確認","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/m5-forecasting-accuracy/sales_train_validation.csv')\nprices = pd.read_csv('../input/m5-forecasting-accuracy/sell_prices.csv')\ncalendar = pd.read_csv('../input/m5-forecasting-accuracy/calendar.csv')\n\nsample_submit = pd.read_csv('../input/m5-forecasting-accuracy/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_eval = pd.read_csv('../input/m5-forecasting-accuracy/sales_train_evaluation.csv')\ntrain_eval.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ・sales_train_validationファイル","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"項目\n> + id: 商品id。item_idとstore_idの組み合わせ識別子\n> + item_id：商品id2\n> + dept_id：商品ジャンル1\n> + cat_id：商品ジャンル2\n> + d_1~d_1913：日別商品売上数  \n  \nデータ分類\n> + カテゴリデータ：dept_id, cat_id, store_id, state_id\n> + 定量データ：d_1~d_1913","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ・sell_prices","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"prices.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ストア毎の日別(週別？)の商品販売価格データ  \n  \n項目\n> * store_id：ストア識別子\n> * item_id：商品id\n> * wm_yr_wk：販売日(週？)。calendarファイルとの連結キー。calenderファイルと組み合わせることで、日ごとの販売価格がわかる。\n> * sell_price：販売価格  \n  \nデータ分類\n> * カテゴリデータ：store_id, item_id, wm_yr_wk\n> * 定量データ：sell_price","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"prices.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ・Calendar","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"calendar.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"日別データ。販売日ごとの、wm_yr_wk(sell_priceとの連結キー)、曜日、年、日、イベント状況がわかる。  \n  \n項目\n> + date:販売日\n> + w_yr_wk:商品価格キー。sell_priceを参照することで販売価格わかる\n> + weekday：曜日\n> + wday：曜日表す数値\n> + month：月\n> + year：年\n> + d：日。trainデータの日項目(d1~)に対応。\n> + event_name_1, event_name_2：イベントあればイベント名\n> + event_type_1, event_type_2：開催イベントの種類\n> + snap_：国の食事支援対象かどうか","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"calendar.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 販売量予測対象日の確認  \n  \n+ train: 2011-01-29('d_1') ~ 2016-04-24('d_1913')\n+ validation: 2016-04-25('d_1914') ~ 2016-05-22('d_1941')\n+ evaluation: 2016-05-23('F1') ~ 2016-06-19('F28')  \n  \n約5年間のデータセットを用いて、販売量の予測モデルを作成し、2016年4月後半〜5月後半の予測でモデルの評価を行い、最終的な予測対象は、2016年5月後半〜6月前半","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 2.trainデータの分析","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"・trainデータとcalendarデータの年月日をマージして、日毎のデータ作成","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# 日別売上列取得用\nd_cols = [c for c in train.columns if 'd_' in c]\n\ndate_train = train.set_index('id')[d_cols].T \\\n                  .merge(calendar.set_index('d')['date'],\n                         left_index=True, right_index=True,\n                         validate='1:1')\n# 日付をインデックス化\ndate_train['date'] = pd.to_datetime(date_train['date'])\n# インデックスを日付型に変更\ndate_train = date_train.set_index('date')\n\ndate_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.1 商品ごとの売上状況  \n  \n20種類ほどランダムサンプリングして、時系列での販売状況を確認","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# calendarファイルとマージして、20商品の日別売上取得\ntwenty_examples = date_train.sample(20, random_state=8, axis=1)\n\ntwenty_examples.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 可視化１。商品20アイテムの販売状況比較\ntwenty_examples.plot(figsize=(15,5))\nplt.legend(twenty_examples.columns, loc='upper left', bbox_to_anchor=(1, 1))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> + 商品により販売量に大きな違いあり。\n> + 販売量が0近辺で推移する商品もあれば、数十以上で買われる商品もあるので、商品により販売数量差が激しい。","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# 可視化２。商品ごとの販売推移\nfig, axs = plt.subplots(10, 2, figsize=(20, 25))\naxs = axs.flatten()\nax_idx = 0\nfor item in twenty_examples.columns:\n    twenty_examples[item].plot(title=item,\n                               color=next(color_cycle),\n                               ax=axs[ax_idx])\n    ax_idx += 1\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> + 商品毎に、周期性がありそう。\n> + ほとんどの商品で、一回の販売量が数個程度で、0も多い。\n> + 初販売日が比較的新しい商品は、販売開始までの日別販売個数が0になっている。\n> + 季節性がある商品は、買われるシーズン以外は、ほとんど0個。","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 2.2 商品全体の販売状況確認","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# 日別の全販売数計算\nall_past_sales = date_train.copy()\nall_past_sales['total'] = all_past_sales.sum(axis=1)\n\n# 可視化\nall_past_sales['total'].plot(figsize=(12, 3), alpha=0.8, title='Total Sales')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"毎年末、0まで落ち込む日があるので何の日か確認","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# 売上最小日確認\nall_past_sales.sort_values(by='total')[:5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> + 毎年クリスマスは売上最小（年に1度の休みらしい）\n> + 販売数は緩やかに上昇傾向\n> + 一年の中で、季節的？な販売サイクルがありそう","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"del all_past_sales","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.3 州ごとの販売状況  \n  \n州ごとに、月別販売数の推移を可視化","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 州ごとに集計\nfor i in train['state_id'].unique():\n    # 州ごとの商品取得\n    state_col = [c for c in date_train.columns if i in c]\n    # ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 州ごとに集計\nfor i in train['state_id'].unique():\n    # 州ごとの商品取得\n    state_col = [c for c in date_train.columns if i in c]\n    # 月ごとに集計\n    month_data = date_train.loc['2011-02-01':'2016-03-31' ,state_col].resample('M').sum()\n    month_data['total'] = month_data.sum(axis=1)\n    month_data['total'].plot(figsize=(12, 3), alpha=0.8, title='Monthly Sales Volume per State')\nplt.legend(train['state_id'].unique())\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> + カリフォルニアの売上が最も多い。ウィスコンシンは2015年後半にはテキサスを抜いた。\n> + ３州の売上は異なるものの、上昇・下降の流れは、全て似通っており、季節性のサイクルがありそう。\n> + 2015年の前半は、テキサス、ウィスコンシンにおいて、他の年とサイクルがずれており、小さく乱高下している。","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 2.4 カテゴリ別販売傾向  \n  \nカテゴリ別の月別売上の推移を確認","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# カテゴリごとに集計\nfor i in train['cat_id'].unique():\n    # カテゴリごとの商品取得\n    category_col = [c for c in date_train.columns if i in c]\n    # 月ごとに集計\n    month_data = date_train.loc['2011-02-01':'2016-03-31' ,category_col].resample('M').sum()\n    month_data['total'] = month_data.sum(axis=1)\n    month_data['total'].plot(figsize=(10, 3), alpha=0.8, title='Monthly Sales Volume per Category')\nplt.legend(train['cat_id'].unique())\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> + FOODSは、他２つよりはるかに販売量が大きいが、2012年後半から増加は一進一退。\n> + FOODSは、一年の中で季節性の販売サイクルがありそう。\n> + HOUSEHOLDは、年々緩やかに上昇しており、FOODSほどではないが、季節性のサイクルがありそう。\n> + HOBBIESは、ほぼ水平に推移しており、季節性のサイクルもなさそう。","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 2.5 店舗別売上傾向  \n  \n店舗別の月別売上の推移を確認","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# store_idリスト\nstore_list = prices['store_id'].unique()\nstore_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1, 3, figsize=(15,5), sharex=True, sharey=True)\naxes = axes.flatten()\nca_idx = 0\ntx_idx = 1\nwi_idx = 2\nfor s in store_list:\n    store_items = [c for c in date_train.columns if s in c]\n    month_data = date_train.loc['2011-02-01':'2016-03-31' ,store_items].resample('M').sum()\n    month_data['total'] = month_data.sum(axis=1)\n    if 'CA_' in s :\n        sns.lineplot(y='total',x=month_data.index,\n                     data=month_data,ax=axes[ca_idx], color=next(color_cycle))\n    elif 'TX_' in s:\n        sns.lineplot(y='total',x=month_data.index,\n                     data=month_data,ax=axes[tx_idx], color=next(color_cycle))\n    elif 'WI_' in s:\n        sns.lineplot(y='total',x=month_data.index,\n                     data=month_data,ax=axes[wi_idx], color=next(color_cycle))\n        \naxes[ca_idx].legend([c for c in store_list if 'CA_' in c])\naxes[ca_idx].title.set_text('CA')\naxes[tx_idx].legend([c for c in store_list if 'TX_' in c])\naxes[tx_idx].title.set_text('TX')\naxes[wi_idx].legend([c for c in store_list if 'WI_' in c])\naxes[wi_idx].title.set_text('WI')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> + 州ごとに季節性のサイクルがありそう。\n> + 全体で見ると、CA_3の販売量が他店舗より圧倒的に多い。（店舗サイズの違いか？）\n> + 全般的に販売量は、年々増加している。\n> + CAでは、CA_2の販売量が2015年から急激にあがっている。\n> + TXでは、TX_3の販売量が2014年から伸び、TX_2に肉薄している。一方で、TX_2は、2013年後半に販売量を大きく減らし、その後回復していない。\n> + WIでは、WI_1とWI_2の販売量が2012年後半に急激に増加している。（店舗を大きくしたか？）一方で、WI_3は、2012年から2015年まで減少傾向。","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 2.6 デパートメント毎の売上傾向  \n  \nデパートメント毎の月別販売量を可視化","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# デパートメントごとに集計\nfor i in train['dept_id'].unique():\n    # デパートメントごとの商品取得\n    dep_col = [c for c in date_train.columns if i in c]\n    # 月ごとに集計\n    month_data = date_train.loc['2011-02-01':'2016-03-31' ,dep_col].resample('M').sum()\n    month_data['total'] = month_data.sum(axis=1)\n    month_data['total'].plot(figsize=(10, 3), alpha=0.8, \n                             title='Monthly Sales Volume per Department',\n                             color = next(color_cycle))\nplt.legend(train['dept_id'].unique(),  loc='upper left', bbox_to_anchor=(1, 1))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> + 全てのFOODSの販売量が大きいわけではなく、FOODS_3の販売量が非常に大きく、年内でも季節性のサイクルが見られる。\n> + FOODS_1, FOODSL_2の販売量は、HOBBIES_1とほぼ変わらないが、FOODS_2は2015年から上昇傾向。\n> + HOBBIES_2の販売量は、とても低く年が変わっても、変化なし。\n> + HOSEHOLD_1は、緩やかな上昇傾向が続き、年内でもサイクルがありそう。","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 2.7 売上サイクルの確認  \n  \n曜日ごと、月ごとの販売状況の確認","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"・カテゴリごとの売上サイクル","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# 月ごと、曜日ごとの売上ヒートマップ作成用関数\n# ----------------------------------------------------------------------------\n# Author:  Nicolas P. Rougier\n# License: BSD\n# ----------------------------------------------------------------------------\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Polygon\nfrom datetime import datetime\nfrom dateutil.relativedelta import relativedelta\n\n\ndef calmap(ax, year, data):\n    ax.tick_params('x', length=0, labelsize=\"medium\", which='major')\n    ax.tick_params('y', length=0, labelsize=\"x-small\", which='major')\n\n    # Month borders\n    xticks, labels = [], []\n    start = datetime(year,1,1).weekday()\n    for month in range(1,13):\n        first = datetime(year, month, 1)\n        last = first + relativedelta(months=1, days=-1)\n\n        y0 = first.weekday()\n        y1 = last.weekday()\n        x0 = (int(first.strftime(\"%j\"))+start-1)//7\n        x1 = (int(last.strftime(\"%j\"))+start-1)//7\n\n        P = [ (x0,   y0), (x0,    7),  (x1,   7),\n              (x1,   y1+1), (x1+1,  y1+1), (x1+1, 0),\n              (x0+1,  0), (x0+1,  y0) ]\n        xticks.append(x0 +(x1-x0+1)/2)\n        labels.append(first.strftime(\"%b\"))\n        poly = Polygon(P, edgecolor=\"black\", facecolor=\"None\",\n                       linewidth=1, zorder=20, clip_on=False)\n        ax.add_artist(poly)\n    \n    ax.set_xticks(xticks)\n    ax.set_xticklabels(labels)\n    ax.set_yticks(0.5 + np.arange(7))\n    ax.set_yticklabels([\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"])\n    ax.set_title(\"{}\".format(year), weight=\"semibold\")\n    \n    # Clearing first and last day from the data\n    valid = datetime(year, 1, 1).weekday()\n    data[:valid,0] = np.nan\n    valid = datetime(year, 12, 31).weekday()\n    # data[:,x1+1:] = np.nan\n    data[valid+1:,x1] = np.nan\n\n    # Showing data\n    ax.imshow(data, extent=[0,53,0,7], zorder=10, vmin=-1, vmax=1,\n              cmap=\"RdYlBu_r\", origin=\"lower\", alpha=.75)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsscale = StandardScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.preprocessing import StandardScaler\n# sscale = StandardScaler()\n\n# カテゴリ毎に、曜日毎、月毎の売上ヒートマップ\n# 2013年から2015年まで1年毎に作成\nfor i in train['cat_id'].unique():\n    fig, axes = plt.subplots(3, 1, figsize=(20, 8))\n    items_col = [c for c in date_train.columns if i in c]\n    \n    # 2013年\n    sale2013 = date_train.loc[date_train.index.isin(\n                pd.date_range('31-Dec-2012', periods=371))][items_col].mean(axis=1)\n     # 標準化の返り値は2次元配列なので、hstackで一次元配列化\n    vals = np.hstack(sscale.fit_transform(sale2013.values.reshape(-1, 1)))\n    # vals.reshape(53, 7)で、データを一行毎に一週間分にしている。\n    calmap(axes[0], 2013, vals.reshape(53, 7).T)\n    \n    # 2014年\n    sales2014 = date_train.loc[date_train.index.isin(\n                pd.date_range('30-Dec-2013',periods=371))][items_col].mean(axis=1)\n    vals = np.hstack(sscale.fit_transform(sales2014.values.reshape(-1, 1)))\n    calmap(axes[1], 2014, vals.reshape(53,7).T)\n    \n    # 2015年\n    sales2015 = date_train.loc[date_train.index.isin(\n                pd.date_range('29-Dec-2014',periods=371))][items_col].mean(axis=1)\n    vals = np.hstack(sscale.fit_transform(sales2015.values.reshape(-1, 1)))\n    calmap(axes[2], 2015, vals.reshape(53,7).T)\n    \n    plt.suptitle(i, fontsize=30, x=0.4, y=1.01)\n    plt.tight_layout()\n    plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> + どのカテゴリも土日の販売量が多い。\n> + hobby, householdは１月のweekdayの販売量が少ない。\n> + Hobby：10月〜12月の販売量が多い。1月が一番少ない。\n> + household：1月、12月は販売量少ない。\n> + foods：12月の後半の週末は販売量少ない。あとは、通年で土日の販売量が多い。","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"・州ごとの、曜日別販売量サイクル","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# 曜日データ用意\nweek_train = train.set_index('id')[d_cols].T \\\n                    .merge(calendar.set_index('d')['wday'],\n                          left_index=True, right_index=True,\n                          validate='1:1')\n\n# # 州ごとに、販売量を曜日でグループ化\nfor i in train['state_id'].unique():\n    # 州ごとに商品取得\n    state_col = [c for c in week_train.columns if i in c]\n    # 曜日ごとにグループ化して平均値取得\n    state_train = week_train[state_col + ['wday']].copy()\n    state_train['total'] = state_train[state_col].sum(axis=1)\n    state_week = state_train.groupby(by='wday')['total'].mean()\n    # 曜日をインデックスにして可視化\n    state_week.sort_index(inplace=True) \n    state_week = state_week.reset_index()\n    week_dic = {1:'Sat', 2:'Sun', 3:'Mon', 4:'Tue', 5:'Wed', 6:'Thu', 7:'Fri'}\n    state_week['weekday'] = state_week['wday'].map(week_dic)\n    state_week.set_index('weekday', inplace=True)\n    state_week['total'].plot(alpha=0.8,\n                             title='Weekly Seasonality per State')\nplt.legend(train['state_id'].unique(),  loc='upper left', bbox_to_anchor=(1, 1))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> + WI州のみ、日曜日の販売量が土曜日より大きくない。（WI州の人たちは、日曜日よりも土曜日に買い物に行くのか？）\n> + その他は、州ごとの週間購買行動に違いはない。","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"・州ごとの、月別販売量サイクル","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# 月データ用意\nmonth_train = train.set_index('id')[d_cols].T \\\n                    .merge(calendar.set_index('d')['month'],\n                          left_index=True, right_index=True,\n                          validate='1:1')\n\n# 州ごとに、販売量を月でグループ化\nfor i in train['state_id'].unique():\n    # 州ごとに商品取得\n    state_col = [c for c in month_train.columns if i in c]\n    # 月ごとにグループ化して平均値取得\n    state_train = month_train[state_col + ['month']].copy()\n    state_train['total'] = state_train[state_col].sum(axis=1)\n    state_month = state_train.groupby(by='month')['total'].mean()\n    # 月をインデックスにして可視化\n    state_month.sort_index(inplace=True) \n    state_month = state_month.reset_index()\n    state_month.set_index('month', inplace=True)\n    state_month['total'].plot(alpha=0.8,\n                             title='Monthly Seasonality per State')\nplt.legend(train['state_id'].unique(),  loc='upper left', bbox_to_anchor=(1, 1))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> + 2月から4月(冬)にかけて、WI州のみ販売量が下がる。一方で、8月から12月(夏〜初冬)は緩やかに増加する。他の２州は、これと反対の動きをする。\n> + 他は、大きな違いがない。","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"・州ごとカテゴリごとの曜日別販売量","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1, 3, figsize=(15,3))\naxes = axes.flatten()\nfood_idx = 0\nhobby_idx = 1\nhouse_idx = 2\n\nfor s in train['state_id'].unique():\n    # 州ごとに商品取得\n    state_col = [c for c in week_train.columns if s in c]\n    # カテゴリ毎に商品わける\n    food_col = [c for c in state_col if 'FOODS_' in c]\n    hobby_col = [c for c in state_col if 'HOBBIES_' in c]\n    house_col = [c for c in state_col if 'HOUSEHOLD_' in c]\n    \n    for i in range(3):\n        # food, hobby, house\n        if i == 0:\n            col = food_col\n        elif i ==1:\n            col = hobby_col\n        else:\n            col = house_col\n            \n        # 曜日ごとにグループ化して平均値取得\n        state_train = week_train[col + ['wday']].copy()\n        state_train['total'] = state_train[col].sum(axis=1)\n        state_week = state_train.groupby(by='wday')['total'].mean()\n        # 曜日をインデックスにして可視化\n        state_week.sort_index(inplace=True) \n        state_week = state_week.reset_index()\n        week_dic = {1:'Sat', 2:'Sun', 3:'Mon', 4:'Tue', 5:'Wed', 6:'Thu', 7:'Fri'}\n        state_week['weekday'] = state_week['wday'].map(week_dic)\n        state_week.set_index('weekday', inplace=True)\n        \n        if i == 0:\n            state_week['total'].plot(ax = axes[food_idx])\n        elif i == 1:\n            state_week['total'].plot(ax = axes[hobby_idx])\n        else:\n            state_week['total'].plot(ax = axes[house_idx])\n\n\naxes[food_idx].title.set_text('FOODS')\naxes[hobby_idx].title.set_text('HOBBIES')\naxes[house_idx].title.set_text('HOUSEHOLD')\naxes[food_idx].legend([c for c in train['state_id'].unique()])\naxes[hobby_idx].legend([c for c in train['state_id'].unique()])\naxes[house_idx].legend([c for c in train['state_id'].unique()])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> + 曜日別では、カテゴリにかかわらず、州ごとの違いはそんなに無さそう。\n> + FOODSの購入で、WI州のみ日曜日がトップではない。","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"・州ごとカテゴリごとの月別販売量","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1, 3, figsize=(15,3))\naxes = axes.flatten()\nfood_idx = 0\nhobby_idx = 1\nhouse_idx = 2\n\nfor s in train['state_id'].unique():\n    # 州ごとに商品取得\n    state_col = [c for c in month_train.columns if s in c]\n    # カテゴリ毎に商品わける\n    food_col = [c for c in state_col if 'FOODS_' in c]\n    hobby_col = [c for c in state_col if 'HOBBIES_' in c]\n    house_col = [c for c in state_col if 'HOUSEHOLD_' in c]\n    \n    for i in range(3):\n        # food, hobby, house\n        if i == 0:\n            col = food_col\n        elif i ==1:\n            col = hobby_col\n        else:\n            col = house_col\n\n        # 月ごとにグループ化して平均値取得\n        state_train = month_train[state_col + ['month']].copy()\n        state_train['total'] = state_train[col].sum(axis=1)\n        state_month = state_train.groupby(by='month')['total'].mean()\n        # 月をインデックスにして可視化\n        state_month.sort_index(inplace=True) \n        state_month = state_month.reset_index()\n        state_month.set_index('month', inplace=True)\n        \n        if i == 0:\n            state_month['total'].plot(ax = axes[food_idx])\n        elif i == 1:\n            state_month['total'].plot(ax = axes[hobby_idx])\n        else:\n            state_month['total'].plot(ax = axes[house_idx])\n\n\naxes[food_idx].title.set_text('FOODS')\naxes[hobby_idx].title.set_text('HOBBIES')\naxes[house_idx].title.set_text('HOUSEHOLD')\naxes[food_idx].legend([c for c in train['state_id'].unique()])\naxes[hobby_idx].legend([c for c in train['state_id'].unique()])\naxes[house_idx].legend([c for c in train['state_id'].unique()])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> + FOODS: WI州では、2〜4月(冬)に販売量が減少している。一方で、8月から微増傾向になる。他の２州は、これと反対の動き。\n> + HOBBIES: ３州とも同じ動き。\n> + HOUSEHOLD: CA州が、2〜4月に販売量が増加傾向。","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 3.CalendarとPriceデータの分析","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 3.1 Calendarデータの分析","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"calendar.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"・nan数の確認","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"calendar.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> + event_name_2 と event_type_2 は、5レコードしかないので除外。\n> + event_name_1, event_type_1, snap_を分析する。","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"・event_name_1, event_type_1","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print('イベントの種類（上位10種）：')\nprint(calendar['event_name_1'].value_counts()[:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('イベントタイプ：')\nprint(calendar['event_type_1'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# イベントタイプの割合\nevent_type = calendar['event_type_1'].value_counts()\nevent_type = pd.DataFrame(index=event_type.index, data=event_type)\n\nevent_type['rate'] = round(event_type['event_type_1'] / event_type['event_type_1'].sum(), 2)\nevent_type.plot.bar(y='rate', ylim=[0, 0.5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 全train日数に占めるイベント発生割合。\nprint('全train日すに占めるイベント発生割合：')\nprint(round(calendar['event_type_1'].notnull().sum() / len(calendar['date']), 2) * 100, ' %')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> + イベント発生率は、全日数の8%ほど。\n> + イベントの内容は、バレンタインデーなどの宗教的な日や国の記念日に関わること。\n> + イベント割合は、宗教イベントと国の記念日がそれぞれ3割超え、後は文化が2割でスポーツが1割\n> + この手のイベントは全国で同じ日だと思われるので、州による違いは考慮する必要がないと考えられる。","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"・SNAP：生活保護制度（食料支援制度）","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"CA = pd.DataFrame(data = calendar['snap_CA'].value_counts()).T\nTX = pd.DataFrame(data = calendar['snap_TX'].value_counts()).T\nWI = pd.DataFrame(data = calendar['snap_WI'].value_counts()).T\nstate_snap = pd.concat([CA, TX, WI])\nstate_snap['rate'] = round(state_snap[1] / state_snap.sum(axis=1), 2)\nstate_snap.plot.bar(y='rate', ylim=[0, 0.5])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> + 全ての州で同じだけsnap対象日がある。\n> + snap対象日は、全日数の３割ほど。  \n  \n次に、州ごとのsnap対象日が同じか確認。","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# 日付をインデックス化\ncal_in_data = calendar.copy()\ncal_in_data['date'] = pd.to_datetime(cal_in_data['date'])\n# インデックスを日付型に変更\ncal_in_data = cal_in_data.set_index('date')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"snap_list = ['snap_CA', 'snap_TX', 'snap_WI']\nfig, axes = plt.subplots(3, 1, figsize=(20, 8))\n\nfor i in range(len(snap_list)):\n    snap2013 = cal_in_data.loc[cal_in_data.index.isin(\n                    pd.date_range('31-Dec-2012', periods=371))][snap_list[i]]\n    vals = np.hstack(sscale.fit_transform(snap2013.values.reshape(-1, 1)))\n    # vals.reshape(53, 7)で、データを一行毎に一週間分にしている。\n    calmap(axes[i], 2013, vals.reshape(53, 7).T)\n    \n    axes[i].set_title('2013: ' + snap_list[i])\n\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> + 実施回数は同じでも、州により実施日が異なることがわかる。\n> + ただし、どの州も、月の前半にsnap対象日が集中している。","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"・年度で実施日が異なるかをWI州で確認","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 3.2 Priceデータの分析","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### ・カテゴリごと、州ごとの販売価格の分布を確認  \n  \n(価格は、対数変換する）","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# 価格を対数変換\nprices['log_price'] = np.log1p(prices['sell_price'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"・州ごと、カテゴリごとの分布","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(1, 3, figsize=(20,5), sharex=True)\naxs = axs.flatten()\naxs_idx = 0\nfor i in train['cat_id'].unique():\n    price_data = prices[prices['item_id'].str.contains(i)][['store_id', 'log_price']]\n    for state in train['state_id'].unique():\n        state_data = price_data[price_data['store_id'].str.contains(state)]['log_price']\n        sns.distplot(state_data, ax=axs[axs_idx], kde=True, label=state)\n    axs[axs_idx].set_title(i)\n    axs[axs_idx].legend()\n    axs_idx += 1\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> + どの商品も州による販売価格の違いは無い。\n> + FOODSの平均価格帯は、他のカテゴリより安い。\n> + FOODSとHOUSEHOLDは山が１つなので、デパートメントの違いによる価格帯の波は無い。\n> + HOBBIESは、山が２つあるので、価格帯が２種類あるっぽい。（デパートメントの違いの影響か？）","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 3.3 時系列分析","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### イベントの影響分析  \n  \n・カテゴリごとのイベント有りなしの購買行動の違い","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# イベント実施日取り出し\nevent_date = pd.to_datetime(calendar[calendar['event_type_1'].notnull()]['date'])\nnon_event_date = pd.to_datetime(calendar[calendar['event_type_1'].isnull()]['date'])\n\n# イベント有り無しそれぞれの日別販売量取得\nevent_sales = date_train[date_train.index.isin(event_date)]\n# クリスマスは閉店なので、クリスマス日のレコードは除外\nevent_sales = event_sales[~event_sales.index.isin(['2011-12-25','2012-12-25','2013-12-25','2014-12-25','2015-12-25'])]\n\nnon_event_sales = date_train[date_train.index.isin(non_event_date)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(1, 3, figsize=(20,5), sharex=True)\naxs = axs.flatten()\naxs_idx = 0\nfor cat in train['cat_id'].unique():\n    item_list = [c for c in non_event_sales.columns if cat in c]\n    # 30日移動平均で販売量の推移確認\n    event_data = event_sales[item_list].sum(axis=1).rolling(30).mean()\n    non_event_data = non_event_sales[item_list].sum(axis=1).rolling(30).mean()\n    sns.lineplot(event_data.index, event_data.values, ax= axs[axs_idx], label='event')\n    sns.lineplot(non_event_data.index, non_event_data.values, ax= axs[axs_idx], label='non_event')\n    axs[axs_idx].legend()\n    axs[axs_idx].set_title(cat)\n    axs_idx += 1\nplt.suptitle('- 30 days moving average -', fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> + FOODSは、2013年以降、イベントによる違いがほとんど無い。\n> + FOODS以外は、2013年以降、イベントを実施していない日の方が平均販売量が多い。\n> + イベントの７割が宗教か国家的行事に関わることなので、そういった日は、あまり買い物しないのかもしれない。","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"・イベントの種類別の各カテゴリへの影響  \n-> イベントの絶対数が少ないので一旦省略","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"・州ごとのイベント有りなしの購買行動の違い","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(1, 3, figsize=(20,5), sharex=True)\naxs = axs.flatten()\naxs_idx = 0\nfor s in train['state_id'].unique():\n    item_list = [c for c in non_event_sales.columns if s in c]\n    # 30日移動平均で販売量の推移確認\n    event_data = event_sales[item_list].sum(axis=1).rolling(30).mean()\n    non_event_data = non_event_sales[item_list].sum(axis=1).rolling(30).mean()\n    sns.lineplot(event_data.index, event_data.values, ax= axs[axs_idx], label='event')\n    sns.lineplot(non_event_data.index, non_event_data.values, ax= axs[axs_idx], label='non_event')\n    axs[axs_idx].legend()\n    axs[axs_idx].set_title(s)\n    axs_idx += 1\nplt.suptitle('- 30 days moving average -', fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> + カテゴリ別の動きと同じように、2013年以降動きがトレンド化。\n> + CAとWIは、2013年以降、イベント実施していない日の方が購買量多い。\n> + TXは、2013年以降、イベントによる違いが殆ど無い。","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### SNAPの影響分析  \n  \n・州別のSNAP実施日の購買状況","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# イベント実施日取り出し\nevent_date = pd.to_datetime(calendar[calendar['event_type_1'].notnull()]['date'])\nnon_event_date = pd.to_datetime(calendar[calendar['event_type_1'].isnull()]['date'])\n\n# イベント有り無しそれぞれの日別販売量取得\nevent_sales = date_train[date_train.index.isin(event_date)]\n# クリスマスは閉店なので、クリスマス日のレコードは除外\nevent_sales = event_sales[~event_sales.index.isin(['2011-12-25','2012-12-25','2013-12-25','2014-12-25','2015-12-25'])]\n\nnon_event_sales = date_train[date_train.index.isin(non_event_date)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# snap実施日取り出し\nsnap_date = pd.to_datetime(calendar[(calendar['snap_CA'] == 1) |\n                                    (calendar['snap_TX'] == 1) |\n                                    (calendar['snap_TX'] == 1)]['date'])\n                           \nnon_snap_date = pd.to_datetime(calendar[~((calendar['snap_CA'] == 1) |\n                                         (calendar['snap_TX'] == 1) |\n                                         (calendar['snap_TX'] == 1))]['date'])\n\n# snap有り無しそれぞれの日別販売量取得\nsnap_sales = date_train[date_train.index.isin(snap_date)]\n# クリスマスは閉店なので、クリスマス日のレコードは除外\nsnap_sales = snap_sales[~snap_sales.index.isin(['2011-12-25','2012-12-25','2013-12-25','2014-12-25','2015-12-25'])]\n\nnon_snap_sales = date_train[date_train.index.isin(non_snap_date)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(1, 3, figsize=(20,5), sharex=True)\naxs = axs.flatten()\naxs_idx = 0\nfor s in train['state_id'].unique():\n    item_list = [c for c in non_event_sales.columns if s in c]\n    # 30日移動平均で販売量の推移確認\n    snap_data = snap_sales[item_list].sum(axis=1).rolling(30).mean()\n    non_snap_data = non_snap_sales[item_list].sum(axis=1).rolling(30).mean()\n    sns.lineplot(snap_data.index, snap_data.values, ax= axs[axs_idx], label='snap')\n    sns.lineplot(non_snap_data.index, non_snap_data.values, ax= axs[axs_idx], label='non_snap')\n    axs[axs_idx].legend()\n    axs[axs_idx].set_title(s)\n    axs_idx += 1\nplt.suptitle('- 30 days moving average of SNAP -', fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> + どの州でも、snap実施日の方が、販売数量が多くなっている。特にWI州は、snap未実施日との差が大きい。\n> + ただし、snapは食事支援なので、snap実施日にすべてのカテゴリで販売量が増えているか確認が必要。","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"・州別、カテゴリ別のsnap別購買状況の確認","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# 州別、カテゴリ別のsnap別平均購買量の算出\nday_num_list = []\nnon_day_num_list = []\ns_c_list = []\nfor state in train['state_id'].unique():\n    item_list = [c for c in non_event_sales.columns if state in c]\n    for cat in train['cat_id'].unique():\n        items = [s for s in item_list if cat in s]\n        s_c_data = snap_sales[items]\n        non_s_c_data = non_snap_sales[items]\n    \n        # snap有り無し別一日あたり平均販売数算出\n        s_c_data['total'] = s_c_data.sum(axis=1)\n        s_c_num = round(s_c_data['total'].sum() / len(s_c_data))\n        non_s_c_data['total'] = non_s_c_data.sum(axis=1)\n        non_s_c_num = round(non_s_c_data['total'].sum() / len(non_s_c_data))\n        \n        # リストに保存\n        day_num_list.append(s_c_num)\n        non_day_num_list.append(non_s_c_num)\n        s_c_list.append(state + '_' + cat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 可視化用にdf化\nCA_df = pd.DataFrame({'category':['HOBBIES','HOBBIES', 'HOUSEHOLD','HOUSEHOLD', 'FOODS','FOODS'],\n                      'snap': ['SNAP', 'no_SNAP', 'SNAP', 'no_SNAP', 'SNAP', 'no_SNAP'],\n                      'num': [day_num_list[0], non_day_num_list[0],day_num_list[1], non_day_num_list[1],\n                              day_num_list[2], non_day_num_list[2]]})\n\nTX_df = pd.DataFrame({'category':['HOBBIES','HOBBIES', 'HOUSEHOLD','HOUSEHOLD', 'FOODS','FOODS'],\n                      'snap': ['SNAP', 'no_SNAP', 'SNAP', 'no_SNAP', 'SNAP', 'no_SNAP'],\n                      'num': [day_num_list[3], non_day_num_list[3],day_num_list[4], non_day_num_list[4],\n                              day_num_list[5], non_day_num_list[5]]})\nWI_df = pd.DataFrame({'category':['HOBBIES','HOBBIES', 'HOUSEHOLD','HOUSEHOLD', 'FOODS','FOODS'],\n                      'snap': ['SNAP', 'no_SNAP', 'SNAP', 'no_SNAP', 'SNAP', 'no_SNAP'],\n                      'num': [day_num_list[6], non_day_num_list[6],day_num_list[7], non_day_num_list[7],\n                              day_num_list[8], non_day_num_list[8]]})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(1, 3, figsize=(15,4), sharex=True)\naxs = axs.flatten()\ndf_list = [CA_df, TX_df, WI_df]\nname = ['CA', 'TX', 'WI']\nfor i in range(3):\n    sns.barplot(x='category', y='num', hue='snap', data= df_list[i], ax=axs[i])\n    axs[i].set_title(name[i])\n\nplt.suptitle('- daily Sales Volume per State -', fontsize=15)\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> + どの州も傾向が変わらず、SNAP日はFOODSの購入量が伸びている。\n> + 特に、WI州で、SNAP日にはFOODSの購入量の増加割合が大きい。\n> + HOBBIES, HOUSEHOLDもわずかながらSNAP日は購入量が多い。（SNAP日に客足多いのか？）","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"・ヒートマップで、SNAP日の曜日別購買効果を確認","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# ヒートマップ用に、月別・曜日別販売量を集計\n\n# snap日の曜日別、月別販売量計算\nsnap_sales['total'] = snap_sales.sum(axis=1)\nm_w_snap = pd.merge(snap_sales, cal_in_data, left_index=True, right_index=True, how='left')\nm_w_snap = m_w_snap[['total', 'wday', 'month']]\nm_w_sum = m_w_snap.groupby(['month', 'wday']).sum() # 月別、曜日別販売数\nm_w_count = m_w_snap.groupby(['month', 'wday']).count() # 月別、曜日別データ数\nm_w_sum['day_num'] = round(m_w_sum['total'] / m_w_count['total'], 0) # 日別販売数算出\nm_w_sum.drop('total', axis=1, inplace=True)\n\n# 非snap日の曜日別、月別販売量計算\nnon_snap_sales['total'] = non_snap_sales.sum(axis=1)\nnon_m_w_snap = pd.merge(non_snap_sales, cal_in_data, left_index=True, right_index=True, how='left')\nnon_m_w_snap = non_m_w_snap[['total', 'wday', 'month']]\nnon_m_w_sum = non_m_w_snap.groupby(['month', 'wday']).sum()\nnon_m_w_count = non_m_w_snap.groupby(['month', 'wday']).count() # 月別、曜日別データ数\nnon_m_w_sum['day_num'] = round(non_m_w_sum['total'] / non_m_w_count['total'], 0) # 日別販売数算出\nnon_m_w_sum.drop('total', axis=1, inplace=True)\n\n# 各集計を合体して、snap実施による一日あたり販売量の増加率を算出\nmerged_m_w = pd.merge(m_w_sum, non_m_w_sum, left_index=True, right_index=True, suffixes=('_SNAP', '_non'))\nmerged_m_w['rate'] = round((merged_m_w['day_num_SNAP'] / merged_m_w['day_num_non']), 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# heatmap用df\nheat_m_w = pd.DataFrame(data=merged_m_w['rate'].values.reshape(12,7).T,\n                        index=['Sat', 'Sun', 'Mon', 'Tue', 'Wed', 'Thu', 'Fri'],\n                        columns=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'])\n\n# heatmap\nfig = plt.figure(figsize=(10,5))\nsns.heatmap(heat_m_w, alpha=0.9, cmap='Reds')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> + ヒートマップを見ると、年間を通して平日の月〜木の色が濃く、SNAPがある平日は、購買量が1〜2割増加している。\n> + SNAPの影響は、FOODSが大きかったので、この増加のほとんどはFOODSと考えられる。","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 4. 個別分析  \n  \nランダムに、FOODS, HOBBIES, HOUSEHOLDから商品を１つづつ選択し、1年間での売上推移や、SNAPやイベントの影響、価格変動などを確認","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 4.1 個別商品の、一年間の販売における、SNAP、イベントの影響分析  \n  \nランダムに、FOODS, HOBBIES, HOUSEHOLDから商品を１つづつ選択し分析する","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# 各カテゴリよりサンプルitem抽出\nfood_sample = date_train.loc[:,date_train.columns.str.contains('FOODS')] \\\n                        .sample(1, random_state=7, axis=1)\nhouse_sample = date_train.loc[:,date_train.columns.str.contains('HOUSEHOLD')] \\\n                        .sample(1, random_state=7, axis=1)\nhobby_sample = date_train.loc[:,date_train.columns.str.contains('HOBBIES')] \\\n                        .sample(1, random_state=7, axis=1)\n\n# 2015年のデータ抽出\nfood_data = food_sample.loc['2015-01-01':'2015-12-31',:][food_sample.columns]\nhouse_data = house_sample.loc['2015-01-01':'2015-12-31',:][house_sample.columns]\nhobby_data = hobby_sample.loc['2015-01-01':'2015-12-31',:][hobby_sample.columns]\n\n# 各商品の2015年のsnap日を取得\nsnap_food_2015 = calendar[(calendar['date'].str.contains('2015-')) \n                        & (calendar['snap_WI'] == 1) ]['date']\nsnap_house_2015 = calendar[(calendar['date'].str.contains('2015-')) \n                        & (calendar['snap_TX'] == 1) ]['date']\nsnap_hobby_2015 = calendar[(calendar['date'].str.contains('2015-')) \n                        & (calendar['snap_CA'] == 1) ]['date']\n# 2015年のイベント日を取得\nevent_2015 = calendar[(calendar['date'].str.contains('2015-')) \n                        & (calendar['event_type_1'].notnull()) ]['date']\n\n# snap日の各売上データ抽出\nsnap_food_data = food_data[food_data.index.isin(snap_food_2015)]\nsnap_house_data = house_data[house_data.index.isin(snap_house_2015)]\nsnap_hobby_data = hobby_data[hobby_data.index.isin(snap_hobby_2015)]\n\n# event日の各売上データ抽出\nevent_food_data = food_data[food_data.index.isin(event_2015)]\nevent_house_data = house_data[house_data.index.isin(event_2015)]\nevent_hobby_data = hobby_data[hobby_data.index.isin(event_2015)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 2015年での、３アイテムの販売量と、イベント日、snap日の可視化\n\ny_list = [food_data, house_data, hobby_data]\nsnap_y_list = [snap_food_data, snap_house_data, snap_hobby_data]\nevent_y_list = [event_food_data, event_house_data, event_hobby_data]\n\nfig, axs = plt.subplots(3, 1, figsize=(20,8), sharex=True)\naxs = axs.flatten()\n\nfor i in range(3):\n    sns.lineplot(y_list[i].index, y_list[i].values.flatten(), alpha=0.4, ax=axs[i], color=next(color_cycle))\n    sns.scatterplot(event_y_list[i].index, event_y_list[i].values.flatten(),\n                    marker='o', color='red', ax=axs[i], label='event_day')\n    sns.scatterplot(snap_y_list[i].index, snap_y_list[i].values.flatten(),\n                    marker='+', color='black', ax=axs[i], label='snap_day')\n    axs[i].set_title('2015: ' + y_list[i].columns[0])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> + サンプルで選んだ３品目のうち、event日に食料が他のカテゴリより多く買われている感じだが、snapに関しては３サンプルで大きな違いがあるように見えない。\n> + 単品だとズレがあるので、もう何アイテムか選んだ方がいいのかもしれない。","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"・販売価格の変化と販売量の変化の分析  \n  \nー＞インフレ率とかも考えなければいけなくなるので、一旦スキップ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5. その他  \n  ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"・ゼロ値の分布確認  \nすべての商品が、毎日買われているわけではないので、過去5年のデータで、どれだけゼロ値があるのか確認。　　\n2011-01-29から2016-02-04までの日々の購買数0の商品割合を算出し、購買数0の日毎割合を調べる。","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# 日毎の販売数0の商品割合算出\ncount_0 = lambda x: x.value_counts()[0]\ndate_train['zero_num'] = date_train.apply(count_0, axis=1)\ndate_train['zero_ratio'] = round((date_train['zero_num'] / len(date_train.columns)), 2)\n\n# ヒストグラム\nsns.distplot(date_train['zero_ratio'], kde=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> + ほとんどの日別レコードで、7割がゼロ値と。ゼロだらけのデータとなっている。  \n  \n次に、年ごとの0値の分布状況を確認","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# 年ごとのデータ取り出し\ny_2011 = date_train['2011-01-01':'2011-12-31'][['zero_num','zero_ratio']]\ny_2012 = date_train['2012-01-01':'2012-12-31'][['zero_num','zero_ratio']]\ny_2013 = date_train['2013-01-01':'2013-12-31'][['zero_num','zero_ratio']]\ny_2014 = date_train['2014-01-01':'2014-12-31'][['zero_num','zero_ratio']]\ny_2015 = date_train['2015-01-01':'2015-12-31'][['zero_num','zero_ratio']]\ny_2016 = date_train['2015-01-01':'2015-12-31'][['zero_num','zero_ratio']]\n\n# 年ごとに、日別0値割合計算\nitem_num = len(date_train.columns) - 2 # 商品数\ny_2011['zero_ratio'] = round((y_2011['zero_num'] / item_num), 2)\ny_2012['zero_ratio'] = round((y_2012['zero_num'] / item_num), 2)\ny_2013['zero_ratio'] = round((y_2013['zero_num'] / item_num), 2)\ny_2014['zero_ratio'] = round((y_2014['zero_num'] / item_num), 2)\ny_2015['zero_ratio'] = round((y_2015['zero_num'] / item_num), 2)\ny_2016['zero_ratio'] = round((y_2016['zero_num'] / item_num), 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 日別0値割合を年ごとにヒストグラムで可視化\n\nfig, axs = plt.subplots(1, 6, figsize=(20,3), sharex=True)\naxs = axs.flatten()\n\nyear_list = [y_2011, y_2012, y_2013, y_2014, y_2015, y_2016]\nyear_name = [2011, 2012, 2013, 2014, 2015, 2016]\n\nfor i in range(6):\n    sns.distplot(year_list[i]['zero_ratio'], kde=True, ax=axs[i])\n    axs[i].set_title(year_name[i])\nplt.suptitle('- zero_ratio distribution per day -', fontsize=14, y=1.2)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> + 2011年、2012年に関しては、ほとんどの日毎レコードで0値が7割・8割という0だらけのデータ。\n> + 2013年から、0値が減少している。  \n  \nー＞2011年、2012年のレコードは使い物にならないか？","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"以上見てきた各分析結果を、時系列予測モデルに反映させなければならない・・・。","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}