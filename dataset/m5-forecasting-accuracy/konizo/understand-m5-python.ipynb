{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\nimport pandas as pd\nimport numpy as np\nimport dask.dataframe as dd\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_rows', 500)\nimport matplotlib.pyplot as plt\nimport seaborn as sns; sns.set()\nimport lightgbm as lgb\n#import dask_xgboost as xgb\n#import dask.dataframe as dd\nfrom sklearn import preprocessing, metrics\nfrom sklearn.preprocessing import LabelEncoder\nimport gc\nimport os\nfrom sklearn.cluster import KMeans\nfrom tqdm import tqdm\nfrom scipy.sparse import csr_matrix\nfrom datetime import timedelta\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns: #columns毎に処理\n        col_type = df[col].dtypes\n        if col_type in numerics: #numericsのデータ型の範囲内のときに処理を実行. データの最大最小値を元にデータ型を効率的なものに変更\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df\n\n# カテゴリ変数化（NaNはそのままになる）\ndef encode_categorical(df, cols):\n    \n    for col in cols:\n        # Leave NaN as it is.\n        le = LabelEncoder()\n        not_null = df[col][df[col].notnull()]\n        df[col] = pd.Series(le.fit_transform(not_null), index=not_null.index)\n\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import IPython\n\ndef display(*dfs, head=True):\n    for df in dfs:\n        IPython.display.display(df.head() if head else df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## R transrate to Python\nRef.\nhttps://www.kaggle.com/kailex/m5-forecaster-0-57330"},{"metadata":{},"cell_type":"markdown","source":"### 1. Make Data / Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"h = 28 \nmax_lags = 366\ntr_last = 1913\nfday = pd.to_datetime(\"2016-04-25\") ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get data\ndef create_dt(is_train = True, nrows = 10**100):\n    \n    cal = pd.read_csv('../input/m5-forecasting-accuracy/calendar.csv')\n    cal['date'] = pd.to_datetime(cal['date'])\n    cal['is_weekend'] = 1\n    cal['is_weekend'] = cal['is_weekend'].where(cal['weekday'].isin(['Saturday', 'Sunday']), 0)\n    cal = reduce_mem_usage(cal)\n    \n    prices = pd.read_csv('../input/m5-forecasting-accuracy/sell_prices.csv')\n    prices = reduce_mem_usage(prices)\n    \n    if is_train:\n        dt = pd.read_csv('../input/m5-forecasting-accuracy/sales_train_validation.csv', nrows=nrows)\n    else:\n        dt = pd.read_csv('../input/m5-forecasting-accuracy/sales_train_validation.csv', nrows=nrows)\n        dt = dt.drop(['d_' + str(i) for i in range(1, tr_last - max_lags + 1)], axis = 1)\n        \n        na_cols = list(['d_' + str(i) for i in range(tr_last + 1, tr_last + 2 * h + 1)])\n        for i in na_cols:\n            dt[i] = np.nan\n            \n    dt = dt[dt['store_id'] == 'CA_1']\n            \n    dt = pd.melt(dt, id_vars = ['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'], var_name = 'd', value_name = 'sales')\n    dt = pd.merge(dt, cal[['d', 'date', 'is_weekend', 'wm_yr_wk', 'event_name_1', 'snap_CA', 'snap_TX', 'snap_WI']], on = 'd', how = 'left')\n    dt = pd.merge(dt, prices, on = ['store_id', 'item_id', 'wm_yr_wk'], how = 'left')\n    \n    dt = reduce_mem_usage(dt)\n    \n    return dt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make feature\ndef create_fea(dt):\n    \n    for lag in [7, 28, 29]:\n#     for lag in [28, 29]:\n        dt[f\"lag_{lag}\"] = dt.groupby([\"id\"])[\"sales\"].transform(lambda x: x.shift(lag))\n        \n    # min_periods = 1 とすることで R の結果と一致\n    for win in [7, 30, 90, 180]:\n        dt[f\"roll_mean_28_{win}\"] = dt.groupby([\"id\"])[\"sales\"].transform(lambda x: x.shift(28).rolling(win, min_periods = 1).mean())\n    \n    # min_periods を指定しないことで R の結果と一致\n    for win in [28]:\n        dt[f\"roll_max_28_{win}\"] = dt.groupby([\"id\"])[\"sales\"].transform(lambda x: x.shift(28).rolling(win).max())\n        dt[f\"roll_var_28_{win}\"] = dt.groupby([\"id\"])[\"sales\"].transform(lambda x: x.shift(28).rolling(win).var())\n        \n    # R と計算結果（fillna(0）したあとの平均）が微妙に異なる（astype(float)のせい？）\n    # dt['price_change_1'].astype(float).fillna(0).mean()\n    # dt[\"shift_price_t1\"].astype(float).fillna(0).mean()\n    # dt['sell_price'].astype(float).fillna(0).mean()\n    dt[\"shift_price_t1\"] = dt.groupby([\"id\"])[\"sell_price\"].transform(lambda x: x.shift(1))\n    dt['price_change_1'] = dt['sell_price'] / dt['shift_price_t1'] -1\n    dt = dt.drop(['shift_price_t1'], axis = 1)\n    \n    # R と計算結果（fillna(0）したあとの平均）が微妙に異なる（astype(float)のせい？）\n    dt[\"rolling_price_max_t365\"] = dt.groupby([\"id\"])[\"sell_price\"].transform(lambda x: x.shift(1).rolling(365).max())\n    dt[\"price_change_365\"] = dt[\"sell_price\"] / dt[\"rolling_price_max_t365\"] - 1\n    dt = dt.drop(['rolling_price_max_t365'], axis = 1)\n    \n    # event_name_1 はNaN（文字列）埋めしておく\n    dt['event_name_1'] = dt['event_name_1'].fillna('NaN')\n    # カテゴリ変数化\n    dt = encode_categorical(dt, [\"item_id\", \"state_id\", \"dept_id\", \"cat_id\", \"event_name_1\"])\n    \n    dt['wday'] = dt['date'].dt.weekday\n    dt['mday'] = dt['date'].dt.day\n    dt['week'] = dt['date'].dt.week\n    dt['month'] = dt['date'].dt.month\n    dt['quarter'] = dt['date'].dt.quarter\n    dt['year'] = dt['date'].dt.year\n    # 不要な列\n#     dt['store_id'] = np.nan\n#     dt['d'] = np.nan\n#     dt['wm_yr_wk'] = np.nan\n    dt = dt.drop(['store_id', 'd', 'wm_yr_wk'], axis = 1)\n    \n    dt = reduce_mem_usage(dt)\n    \n    return dt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tr = create_dt()\ntr = create_fea(tr)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = [\n    'id', 'item_id', 'dept_id', 'cat_id', 'state_id', 'sales', 'date', 'event_name_1', 'snap_CA', 'snap_TX', 'snap_WI',\n    'sell_price', \n    'lag_7',\n    'lag_28', 'lag_29',\n    'roll_mean_28_7', 'roll_mean_28_30', 'roll_mean_28_90', 'roll_mean_28_180', 'roll_max_28_28', 'roll_var_28_28',\n    'price_change_1', 'price_change_365', 'wday', 'mday', 'week', 'month', 'quarter', 'year', 'is_weekend']\n\ntr = tr[features].dropna()\ny = tr.sales\n# indexの定義\nidx = tr[tr['date'] <= tr['date'].max() - timedelta(days = h)].index\n\n# 不要な列\ntr['id'] = np.nan\ntr['sales'] = np.nan\ntr['date'] = np.nan\n\ntr = tr.drop(['id', 'sales', 'date'], axis = 1)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# カテゴリ変数への変換\ncats = [\n    \"item_id\", \"state_id\", \"dept_id\", \"cat_id\", \"event_name_1\", \n    \"wday\", \"mday\", \"week\", \"month\", \"quarter\", \"year\", \"is_weekend\", \"snap_CA\", \"snap_TX\", \"snap_WI\"]\n\ndef change_cat(dt):\n    for i in cats:\n        dt[i] = dt[i].astype('category')\n    return dt\n\ntr = change_cat(tr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"# tr.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 型変換しておく\ndef change_type(dt):\n    for col in dt.select_dtypes(include='float16').astype(float).columns:\n        dt[col] = dt[col].astype(float)\n    return dt\ntr = change_type(tr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tr.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lgbm\nxtr = lgb.Dataset(\n    tr[tr.index.isin(idx)],\n    y[y.index.isin(idx)],\n    categorical_feature = cats\n)\nxval = lgb.Dataset(\n    tr[~tr.index.isin(idx)],\n    y[~y.index.isin(idx)],\n    categorical_feature = cats\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lgbm\nparams = {\n#     'boosting_type': 'gbdt',\n    'metric': 'rmse',\n    'objective': 'poisson',\n    'force_row_wise': True,\n#     'n_jobs': -1,\n#     'seed': 236,\n    'learning_rate': 0.075,\n    'sub_feature': 0.8,\n    'sub_row': 0.75,\n    'bagging_fraction': 1,\n    'lambda_l2': 0.1,\n    'nthread': 4\n#     'colsample_bytree': 0.75\n}\n\nmodel = lgb.train(\n    params,\n    xtr,\n    num_boost_round = 2000,\n#     num_boost_round = 100,\n    early_stopping_rounds = 400,\n#     early_stopping_rounds = 10,\n    valid_sets = [xtr, xval],\n    verbose_eval = 200)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get test data\nte = create_dt(False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3. Prediction & Submit"},{"metadata":{"trusted":true},"cell_type":"code","source":"for day in pd.date_range(start = fday, end = fday + timedelta(days = 2 * h - 1), freq='D'):\n    print(day)\n    tst = te[(te.date >= day - timedelta(days = max_lags))&(te.date <= day)]\n    tst = create_fea(tst)\n    tst = change_cat(tst)\n    tst = change_type(tst)\n    tst = tst[tst.date == day].drop(['id', 'sales', 'date'], axis = 1)\n    te.loc[te['date'] == day, 'sales'] = model.predict(tst)\n    gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('../input/m5-forecasting-accuracy/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = te[(te.date >= fday)&(te.date <= fday + timedelta(days = h -1))][['id', 'date', 'sales']]\npredictions = pd.pivot(predictions, index = 'id', columns = 'date', values = 'sales').reset_index()\npredictions.columns = ['id'] + ['F' + str(i + 1) for i in range(28)]\n\nevaluation_rows = [row for row in submission['id'] if 'evaluation' in row] \nevaluation = submission[submission['id'].isin(evaluation_rows)]\n\nvalidation = submission[['id']].merge(predictions, on = 'id')\nfinal = pd.concat([validation, evaluation])\nfinal.to_csv('submission.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# importanceを表示する\nimportance = pd.DataFrame(model.feature_importance(), index=tr.columns, columns=['importance'])\nimportance.sort_values(by = 'importance', ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"te.groupby(['date'])['sales'].sum().plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":4}