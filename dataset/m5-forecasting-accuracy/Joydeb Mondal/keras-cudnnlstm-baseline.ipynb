{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\nimport os\n\nfrom tqdm import trange, tqdm_notebook\n\nfrom tensorflow.keras import backend as K\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_salesval_coltypes():\n    keys = ['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'] + \\\n        [f\"d_{i}\" for i in range(1, 1914)]\n    values = ['object', 'category', 'category', 'category', 'category', 'category'] +\\\n        [\"uint16\" for i in range(1, 1914)]\n    return dict(zip(keys, values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"timesteps = 100\ny_steps = 28\ninput_scaler = MinMaxScaler()\noutput_scaler = StandardScaler()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def get_data():\n    data = pd.read_csv(os.path.join(\"/kaggle/input/m5-forecasting-accuracy\", 'sales_train_validation.csv'), dtype=get_salesval_coltypes())\n    \n\n    # Our timeseries data is in cols d_1 to d_1913\n    data = data.iloc[:, 6:]\n    #data = (data-data.min())/(data.max()-data.min())\n\n    # For later - test train split, for now just get shapes right\n    x = []\n    y = []\n\n    # Well just iterate through slicing timesteps until we get somewhat near the end. With a\n    # proper train test split, we could be more precise\n    for i in range(1, 12):\n        x_data = data.iloc[:, i*timesteps:i*timesteps+timesteps]\n        y_data = data.iloc[:, i*timesteps+timesteps:i*timesteps+timesteps+y_steps]\n        x.extend(x_data.to_numpy())\n        y.extend(y_data.to_numpy())\n        #print(f\"Samples {samples.shape}, preds {preds.shape}\")\n\n    # Scale and reshape our input\n    x_train = np.array(x)\n    input_scaler.fit(x_train)\n    x_train = input_scaler.transform(x_train)\n    x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n\n    # Scale our prediction labels\n    y_train = np.array(y)\n    output_scaler.fit(y_train)\n    y_train = output_scaler.transform(y_train)\n    \n    # Take a slice of n{timesteps} from the input data\n    x_test = data.iloc[:,-timesteps:].to_numpy()\n\n    # Reshape to fit the format for input scalar\n    x_test = x_test.reshape((len(data), x_test.shape[1]))\n    # Normalize the input\n    x_test = input_scaler.transform(x_test)\n    # Reshape to fit the format for LSTM model\n    x_test = x_test.reshape((len(data), x_test.shape[1], 1))\n    return x_train,y_train,x_test\n\nx_train,y_train,x_test = get_data()    \nprint(x_train.shape)\nprint(y_train.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def root_mean_squared_error(y_true, y_pred):\n        return K.sqrt(K.mean(K.square(y_pred - y_true)))\ndef build_model(epochs,batch_size):\n    steps = x_train.shape[1]\n    n_features = x_train.shape[2]\n    n_steps_out = y_train.shape[1]\n\n    model = tf.keras.models.Sequential()\n    model.add(tf.compat.v1.keras.layers.CuDNNLSTM(100, return_sequences=True, input_shape=(steps, n_features)))\n    model.add(tf.compat.v1.keras.layers.CuDNNLSTM(50))\n    model.add(tf.keras.layers.Dense(n_steps_out))\n    model.compile(optimizer='adam', loss=root_mean_squared_error) # this loss needs changing to competition loss.\n    model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n    return model\nepochs = 80\nbatch_size = 1000\nmodel = build_model(epochs,batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_prediction(x_test):\n    # Get our predictions\n    pred = model.predict(x_test)\n    submission = pd.read_csv(os.path.join(\"/kaggle/input/m5-forecasting-accuracy\",'sample_submission.csv'))\n    # Inverse to transform to get the predictions at the right scale\n    pred = output_scaler.inverse_transform(pred)\n    # Round the predictions back to integers\n    pred = np.round(np.abs(pred))\n    validation = pd.concat([pd.DataFrame(pred[:,0:y_steps]), pd.DataFrame(pred[:,-y_steps:])])\n    validation = validation.astype(int)\n\n    # Reset index to match the submission dataframe\n    validation.reset_index(inplace=True, drop=True)\n\n    # Add the id column from the submission dataframe to our results\n    validation['id'] = submission.id\n    validation = validation.reindex(\n            columns=['id'] + [c for c in validation.columns if c != 'id'], copy=False)\n\n    # Add the correct colummn names for the submission file format\n    validation.columns = ['id'] + [f\"F{i}\" for i in range(1, 29)]\n\n    validation.to_csv('submission.csv', index=False)\nmake_prediction(x_test)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}