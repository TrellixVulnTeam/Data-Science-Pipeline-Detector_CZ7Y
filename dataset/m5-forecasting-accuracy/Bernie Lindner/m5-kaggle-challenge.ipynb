{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-20T17:14:10.771686Z","iopub.execute_input":"2022-02-20T17:14:10.771967Z","iopub.status.idle":"2022-02-20T17:14:10.790888Z","shell.execute_reply.started":"2022-02-20T17:14:10.771936Z","shell.execute_reply":"2022-02-20T17:14:10.789387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Metrics","metadata":{"execution":{"iopub.status.busy":"2021-11-30T09:52:46.783382Z","iopub.execute_input":"2021-11-30T09:52:46.783757Z","iopub.status.idle":"2021-11-30T09:52:46.789022Z","shell.execute_reply.started":"2021-11-30T09:52:46.783723Z","shell.execute_reply":"2021-11-30T09:52:46.787906Z"}}},{"cell_type":"code","source":"# https://gist.github.com/bshishov/5dc237f59f019b26145648e2124ca1c9\ndef _error(actual: np.ndarray, predicted: np.ndarray):\n    \"\"\" Simple error \"\"\"\n    return actual - predicted\n\ndef _naive_forecasting(actual: np.ndarray, seasonality: int = 1):\n    \"\"\" Naive forecasting method which just repeats previous samples \"\"\"\n    return actual[:-seasonality]\n\ndef mse(actual: np.ndarray, predicted: np.ndarray):\n    \"\"\" Mean Squared Error \"\"\"\n    return np.mean(np.square(_error(actual, predicted)))\n\ndef mae(actual: np.ndarray, predicted: np.ndarray):\n    \"\"\" Mean Absolute Error \"\"\"\n    return np.mean(np.abs(_error(actual, predicted)))\n\ndef rmsse(actual: np.ndarray, predicted: np.ndarray, seasonality: int = 1):\n    \"\"\" Root Mean Squared Scaled Error \"\"\"\n    q = np.abs(_error(actual, predicted)) / mae(actual[seasonality:], _naive_forecasting(actual, seasonality))\n    return np.sqrt(np.mean(np.square(q)))\n\n# https://gist.github.com/bshishov/5dc237f59f019b26145648e2124ca1c9#gistcomment-3593885\ndef rmsse(actual: np.ndarray, predicted: np.ndarray, seasonality: int = 1):\n    \"\"\" Root Mean Squared Scaled Error \"\"\"\n    q = mse(actual, predicted) / mse(actual[seasonality:], _naive_forecasting(actual, seasonality))\n    return np.sqrt(q)\n\n# https://www.kaggle.com/chrisrichardmiles/m5-wrmsse-custom-objective-and-custom-metric\n# oos_scale = 1/w_12_train.oos_level_12_scale\ndef oos_rmsse(preds, train_data): \n        actuals = train_data.get_label()\n        diff = actuals - preds\n        grad = -diff * oos_scale\n        hess = np.ones_like(diff)\n        return grad, hess\n    \n# The scaling factor, w_12_train.oos_level_12_scale, \n# is the same as described in the competition, except \n# I removed zeros that I believed were due to being \n# out of stock before calculation.\n\n# https://stackoverflow.com/questions/65216794/importerror-when-importing-metric-from-sklearn\n# ! conda install sklearn\n# ! pip install scikit-learn==0.24\nfrom sklearn.metrics import mean_squared_error #, mean_absolute_percentage_error\nfrom sklearn.utils import check_array\ndef mean_absolute_percentage_error(y_true, y_pred): \n    y_true, y_pred = check_array(y_true, y_pred)\n\n    ## Note: does not handle mix 1d representation\n    #if _is_1d(y_true): \n    #    y_true, y_pred = _check_1d_array(y_true, y_pred)\n\n    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n\n\n\n#Defining MAPE function\ndef MAPE(Y_actual,Y_Predicted):\n    mape = np.mean(np.abs((Y_actual - Y_Predicted)/Y_actual))*100\n    return mape\n\n# https://www.kaggle.com/chameleontk/rmse-and-wrmsse-of-a-submission\ndef wrmsse(preds, y_true):\n    # number of columns\n    num_col = DAYS_PRED\n\n    reshaped_preds = preds.reshape(num_col, NUM_ITEMS).T\n    reshaped_true = y_true.reshape(num_col, NUM_ITEMS).T\n    \n          \n    train = weight_mat_csr*np.c_[reshaped_preds, reshaped_true]\n    \n    score = np.sum(\n                np.sqrt(\n                    np.mean(\n                        np.square(\n                            train[:,:num_col] - train[:,num_col:])\n                        ,axis=1) / weight1) * weight2)\n    \n    return score\n\n# TODO: See if below is better?\n# https://www.kaggle.com/sibmike/fast-clear-wrmsse-18ms?scriptVersionId=32323454\n\n","metadata":{"execution":{"iopub.status.busy":"2022-02-20T17:16:12.783653Z","iopub.execute_input":"2022-02-20T17:16:12.78534Z","iopub.status.idle":"2022-02-20T17:16:13.89987Z","shell.execute_reply.started":"2022-02-20T17:16:12.785259Z","shell.execute_reply":"2022-02-20T17:16:13.898115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Own local wrmsse evaluation/function","metadata":{}},{"cell_type":"code","source":"# https://www.kaggle.com/c/m5-forecasting-accuracy/discussion/143070\n\n# https://www.kaggle.com/dhananjay3/wrmsse-evaluator-with-extra-features\nfrom typing import Union\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm.auto import tqdm as tqdm\n\nclass WRMSSEEvaluator(object):\n    \n    group_ids = ( 'all_id', 'state_id', 'store_id', 'cat_id', 'dept_id', 'item_id',\n        ['state_id', 'cat_id'],  ['state_id', 'dept_id'], ['store_id', 'cat_id'],\n        ['store_id', 'dept_id'], ['item_id', 'state_id'], ['item_id', 'store_id'])\n\n    def __init__(self, \n                 train_df: pd.DataFrame, \n                 valid_df: pd.DataFrame, \n                 calendar: pd.DataFrame, \n                 prices: pd.DataFrame):\n        '''\n        intialize and calculate weights\n        '''\n        self.calendar = calendar\n        self.prices = prices\n        self.train_df = train_df\n        self.valid_df = valid_df\n        self.train_target_columns = [i for i in self.train_df.columns if i.startswith('d_')]\n        self.weight_columns = self.train_df.iloc[:, -28:].columns.tolist()\n\n        self.train_df['all_id'] = \"all\"\n\n        self.id_columns = [i for i in self.train_df.columns if not i.startswith('d_')]\n        self.valid_target_columns = [i for i in self.valid_df.columns if i.startswith('d_')]\n\n        if not all([c in self.valid_df.columns for c in self.id_columns]):\n            self.valid_df = pd.concat([self.train_df[self.id_columns], self.valid_df],\n                                      axis=1, \n                                      sort=False)\n        self.train_series = self.trans_30490_to_42840(self.train_df, \n                                                      self.train_target_columns, \n                                                      self.group_ids)\n        self.valid_series = self.trans_30490_to_42840(self.valid_df, \n                                                      self.valid_target_columns, \n                                                      self.group_ids)\n        self.weights = self.get_weight_df()\n        self.scale = self.get_scale()\n        self.train_series = None\n        self.train_df = None\n        self.prices = None\n        self.calendar = None\n\n    def get_scale(self):\n        '''\n        scaling factor for each series ignoring starting zeros\n        '''\n        scales = []\n        for i in tqdm(range(len(self.train_series))):\n            series = self.train_series.iloc[i].values\n            series = series[np.argmax(series!=0):]\n            scale = ((series[1:] - series[:-1]) ** 2).mean()\n            scales.append(scale)\n        return np.array(scales)\n    \n    def get_name(self, i):\n        '''\n        convert a str or list of strings to unique string \n        used for naming each of 42840 series\n        '''\n        if type(i) == str or type(i) == int:\n            return str(i)\n        else:\n            return \"--\".join(i)\n    \n    def get_weight_df(self) -> pd.DataFrame:\n        \"\"\"\n        returns weights for each of 42840 series in a dataFrame\n        \"\"\"\n        day_to_week = self.calendar.set_index(\"d\")[\"wm_yr_wk\"].to_dict()\n        weight_df = self.train_df[[\"item_id\", \"store_id\"] + self.weight_columns].set_index(\n            [\"item_id\", \"store_id\"]\n        )\n        weight_df = (\n            weight_df.stack().reset_index().rename(columns={\"level_2\": \"d\", 0: \"value\"})\n        )\n        weight_df[\"wm_yr_wk\"] = weight_df[\"d\"].map(day_to_week)\n        weight_df = weight_df.merge(\n            self.prices, how=\"left\", on=[\"item_id\", \"store_id\", \"wm_yr_wk\"]\n        )\n        weight_df[\"value\"] = weight_df[\"value\"] * weight_df[\"sell_price\"]\n        weight_df = weight_df.set_index([\"item_id\", \"store_id\", \"d\"]).unstack(level=2)[\n            \"value\"\n        ]\n        weight_df = weight_df.loc[\n            zip(self.train_df.item_id, self.train_df.store_id), :\n        ].reset_index(drop=True)\n        weight_df = pd.concat(\n            [self.train_df[self.id_columns], weight_df], axis=1, sort=False\n        )\n        weights_map = {}\n        for i, group_id in enumerate(tqdm(self.group_ids, leave=False)):\n            lv_weight = weight_df.groupby(group_id)[self.weight_columns].sum().sum(axis=1)\n            lv_weight = lv_weight / lv_weight.sum()\n            for i in range(len(lv_weight)):\n                weights_map[self.get_name(lv_weight.index[i])] = np.array(\n                    [lv_weight.iloc[i]]\n                )\n        weights = pd.DataFrame(weights_map).T / len(self.group_ids)\n\n        return weights\n\n    def trans_30490_to_42840(self, df, cols, group_ids, dis=False):\n        '''\n        transform 30490 sries to all 42840 series\n        '''\n        series_map = {}\n        for i, group_id in enumerate(tqdm(self.group_ids, leave=False, disable=dis)):\n            tr = df.groupby(group_id)[cols].sum()\n            for i in range(len(tr)):\n                series_map[self.get_name(tr.index[i])] = tr.iloc[i].values\n        return pd.DataFrame(series_map).T\n    \n    def get_rmsse(self, valid_preds) -> pd.Series:\n        '''\n        returns rmsse scores for all 42840 series\n        '''\n        score = ((self.valid_series - valid_preds) ** 2).mean(axis=1)\n        rmsse = (score / self.scale).map(np.sqrt)\n        return rmsse\n\n    def score(self, valid_preds: Union[pd.DataFrame, np.ndarray]) -> float:\n        assert self.valid_df[self.valid_target_columns].shape == valid_preds.shape\n\n        if isinstance(valid_preds, np.ndarray):\n            valid_preds = pd.DataFrame(valid_preds, columns=self.valid_target_columns)\n\n        valid_preds = pd.concat([self.valid_df[self.id_columns], valid_preds],\n                                axis=1, \n                                sort=False)\n        valid_preds = self.trans_30490_to_42840(valid_preds, \n                                                self.valid_target_columns, \n                                                self.group_ids, \n                                                True)\n        self.rmsse = self.get_rmsse(valid_preds)\n        self.contributors = pd.concat([self.weights, self.rmsse], \n                                      axis=1, \n                                      sort=False).prod(axis=1)\n        return np.sum(self.contributors)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T17:16:20.200346Z","iopub.execute_input":"2022-02-20T17:16:20.200998Z","iopub.status.idle":"2022-02-20T17:16:20.241101Z","shell.execute_reply.started":"2022-02-20T17:16:20.200935Z","shell.execute_reply":"2022-02-20T17:16:20.240174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Kaggle API","metadata":{"execution":{"iopub.status.busy":"2021-11-30T09:25:24.405403Z","iopub.execute_input":"2021-11-30T09:25:24.405738Z","iopub.status.idle":"2021-11-30T09:25:24.410409Z","shell.execute_reply.started":"2021-11-30T09:25:24.405706Z","shell.execute_reply":"2021-11-30T09:25:24.409661Z"}}},{"cell_type":"code","source":"# https://github.com/Kaggle/kaggle-api\n! mkdir ~/.kaggle\n! cp /kaggle/input/api-key/kaggle.json ~/.kaggle/\n! chmod 600 ~/.kaggle/kaggle.json","metadata":{"execution":{"iopub.status.busy":"2022-02-20T17:07:35.478643Z","iopub.execute_input":"2022-02-20T17:07:35.479105Z","iopub.status.idle":"2022-02-20T17:07:37.778078Z","shell.execute_reply.started":"2022-02-20T17:07:35.479045Z","shell.execute_reply":"2022-02-20T17:07:37.776445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Functions","metadata":{}},{"cell_type":"markdown","source":"## Data functions","metadata":{}},{"cell_type":"code","source":"# https://www.kaggle.com/c/m5-forecasting-accuracy/discussion/133582\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df\n\ndef get_sample(wide_df, n: int = 100):\n    sample_df = wide_df.sample(n)\n    print(\"sampling {} out of {} ({} %)\".format(sample_df.shape[0], wide_df.shape[0], round(sample_df.shape[0]/wide_df.shape[0]*100,1)))\n    return sample_df\n\ndef melt_m5(wide_df: pd.DataFrame, \n            id_cols: list = None, d_cols: list = None, \n            var_name: str = 'day', value_name: str = 'num_sales'):\n    \n    if id_cols is None:    # \n        print('Using default id_cols')\n        id_cols = ['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id']\n    if d_cols is None:\n        print('Using default d_cols')\n        d_cols = [d_col for d_col in wide_df.columns if d_col.startswith('d_')]\n        \n    df_melted = pd.melt(wide_df, id_vars=id_cols, value_vars=d_cols, var_name ='d', value_name ='num_sales')\n    \n    return df_melted\n\ndef join_on_calendar_price(df, df_calendar, df_prices):\n    df_calendar = pd.merge(df, df_calendar, how='left', on='d')\n    # Seems below merge is very memory hungry\n    df_calendar_price = pd.merge(df_calendar, df_prices, how='left', on='d')\n    return df_calendar_price\n\n# https://datascience.stackexchange.com/questions/45550/merge-2-dataframe-with-memory-error","metadata":{"execution":{"iopub.status.busy":"2022-02-20T17:19:16.185854Z","iopub.execute_input":"2022-02-20T17:19:16.187133Z","iopub.status.idle":"2022-02-20T17:19:16.21475Z","shell.execute_reply.started":"2022-02-20T17:19:16.187024Z","shell.execute_reply":"2022-02-20T17:19:16.213817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read data","metadata":{}},{"cell_type":"markdown","source":"We are predicting 28 forecast days (F1-F28) of items sold for each row. For the validation rows, this corresponds to d_1914 - d_1941, \nand for the evaluation rows, this corresponds to d_1942 - d_1969. (Note: a month before the competition close, the ground truth for the validation rows will be provided.)\n\nsales_train_validation.csv - Contains the historical daily unit sales data per product and store [d_1 - d_1913]\nsales_train_evaluation.csv - Includes sales [d_1 - d_1941]\n \nTrain [d_1 - d_1913] / validation [d_1914 - d_1941] (public?) | evaluation [d_1942 - d_1969] (private?)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-20T16:17:51.594418Z","iopub.execute_input":"2022-02-20T16:17:51.595602Z","iopub.status.idle":"2022-02-20T16:17:51.600482Z","shell.execute_reply.started":"2022-02-20T16:17:51.595527Z","shell.execute_reply":"2022-02-20T16:17:51.5992Z"}}},{"cell_type":"code","source":"validation_column_names = ['d_'+ str(i+1) for i in range(1913, 1941)] # public (we will be given this one month )\nevaluation_column_names = ['d_'+ str(i+1) for i in range(1942, 1969)] # \n# in the submission file\nforecast_column_names = ['F'+ str(i+1) for i in range(28)]","metadata":{"execution":{"iopub.status.busy":"2022-02-20T17:14:10.793003Z","iopub.execute_input":"2022-02-20T17:14:10.79334Z","iopub.status.idle":"2022-02-20T17:14:10.800865Z","shell.execute_reply.started":"2022-02-20T17:14:10.793304Z","shell.execute_reply":"2022-02-20T17:14:10.799784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Contains information about the dates on which the products are sold.\ndf_calendar = reduce_mem_usage(pd.read_csv('/kaggle/input/m5-forecasting-accuracy/calendar.csv'))\n# The correct format for submissions. Reference the Evaluation tab for more info.\ndf_sample_submission = reduce_mem_usage(pd.read_csv('/kaggle/input/m5-forecasting-accuracy/sample_submission.csv'))\n# Contains informatio|n about the price of the products sold per store and date.\ndf_sell_prices = reduce_mem_usage(pd.read_csv('/kaggle/input/m5-forecasting-accuracy/sell_prices.csv'))\n# Contains the historical daily unit sales data per product and store [d_1 - d_1913]\ndf_sales_train_validation = reduce_mem_usage(pd.read_csv('/kaggle/input/m5-forecasting-accuracy/sales_train_validation.csv'))\n# Includes sales [d_1 - d_1941] (labels used for the Public leaderboard)\ndf_sales_train_evaluation = reduce_mem_usage(pd.read_csv('/kaggle/input/m5-forecasting-accuracy/sales_train_evaluation.csv'))","metadata":{"execution":{"iopub.status.busy":"2022-02-20T17:08:47.843222Z","iopub.execute_input":"2022-02-20T17:08:47.843503Z","iopub.status.idle":"2022-02-20T17:14:10.768852Z","shell.execute_reply.started":"2022-02-20T17:08:47.843473Z","shell.execute_reply":"2022-02-20T17:14:10.767378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sales_train_validation","metadata":{"execution":{"iopub.status.busy":"2022-02-20T16:17:51.602148Z","iopub.execute_input":"2022-02-20T16:17:51.602619Z","iopub.status.idle":"2022-02-20T16:17:51.654482Z","shell.execute_reply.started":"2022-02-20T16:17:51.602588Z","shell.execute_reply":"2022-02-20T16:17:51.653926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sample_submission","metadata":{"execution":{"iopub.status.busy":"2022-02-20T16:17:51.656399Z","iopub.execute_input":"2022-02-20T16:17:51.656785Z","iopub.status.idle":"2022-02-20T16:17:51.691705Z","shell.execute_reply.started":"2022-02-20T16:17:51.656741Z","shell.execute_reply":"2022-02-20T16:17:51.691141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Transform","metadata":{}},{"cell_type":"code","source":"df_sales_train_evaluation_long = melt_m5(df_sales_train_evaluation)\ndf_sales_train_evaluation_long_cal_price = join_on_calendar_price(df_sales_train_evaluation_long, df_calendar, df_sell_prices)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T17:19:58.106296Z","iopub.execute_input":"2022-02-20T17:19:58.106724Z","iopub.status.idle":"2022-02-20T17:20:48.126096Z","shell.execute_reply.started":"2022-02-20T17:19:58.106691Z","shell.execute_reply":"2022-02-20T17:20:48.124741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 0. Naive Forecast methods","metadata":{}},{"cell_type":"markdown","source":"Last day sales","metadata":{}},{"cell_type":"code","source":"last_day_1913_sales = df_sales_train_validation[['id', 'd_1913']].copy()\nlast_day_1913_sales.loc[:, 'id_join'] = last_day_1913_sales['id'].str.split('_').str[:-1].str.join('_')\nlast_day_1913_sales","metadata":{"execution":{"iopub.status.busy":"2022-02-20T16:17:51.714478Z","iopub.execute_input":"2022-02-20T16:17:51.71476Z","iopub.status.idle":"2022-02-20T16:17:52.089905Z","shell.execute_reply.started":"2022-02-20T16:17:51.714728Z","shell.execute_reply":"2022-02-20T16:17:52.089484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df_sample_submission.shape)\ndf_submission_train_avg = df_sample_submission.copy()\n# https://stackoverflow.com/questions/64886253/how-can-i-remove-string-after-last-underscore-in-python-dataframe\ndf_sales_train_validation.loc[:, 'id_join'] = df_sales_train_validation['id'].str.split('_').str[:-1].str.join('_')\ndf_submission_train_avg.loc[:, 'id_join'] = df_submission_train_avg['id'].str.split('_').str[:-1].str.join('_')\ndf_submission_train_avg = df_submission_train_avg.merge(last_day_1913_sales.drop(columns='id'),how='left', on='id_join')\nprint(df_submission_train_avg.shape)\ndf_submission_train_avg=df_submission_train_avg.drop(columns=forecast_column_names)\nfor forecast_column_name in forecast_column_names: \n    df_submission_train_avg[forecast_column_name] = list(df_submission_train_avg['d_1913'].values)\ndf_submission_train_avg.drop(columns=['id_join', 'd_1913']).to_csv(\"df_submission_train_avg.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T16:17:52.09083Z","iopub.execute_input":"2022-02-20T16:17:52.091114Z","iopub.status.idle":"2022-02-20T16:17:54.411539Z","shell.execute_reply.started":"2022-02-20T16:17:52.091079Z","shell.execute_reply":"2022-02-20T16:17:54.410631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_submission_train_avg","metadata":{"execution":{"iopub.status.busy":"2022-02-20T16:17:54.412747Z","iopub.execute_input":"2022-02-20T16:17:54.413637Z","iopub.status.idle":"2022-02-20T16:17:54.448073Z","shell.execute_reply.started":"2022-02-20T16:17:54.413609Z","shell.execute_reply":"2022-02-20T16:17:54.447218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted = df_submission_train_avg.loc[30490:, forecast_column_names].values\nactual = df_sales_train_evaluation[validation_column_names].values\nprint(\"mean_squared_error: \", mean_squared_error(actual, predicted, squared=False))\nprint(\"mean absolute error: \", mae(actual, predicted))\n# print(\"mean_absolute_percentage_error: \", MAPE(actual, predicted))\nprint(\"Root Mean Squared Scaled Error: \", rmsse(actual, predicted))","metadata":{"execution":{"iopub.status.busy":"2022-02-20T16:20:52.87199Z","iopub.execute_input":"2022-02-20T16:20:52.872303Z","iopub.status.idle":"2022-02-20T16:20:52.897626Z","shell.execute_reply.started":"2022-02-20T16:20:52.872273Z","shell.execute_reply":"2022-02-20T16:20:52.896439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ! kaggle competitions submit -f df_submission_train_avg.csv -m df_submission_train_avg  m5-forecasting-accuracy","metadata":{"execution":{"iopub.status.busy":"2022-02-20T16:20:54.885817Z","iopub.execute_input":"2022-02-20T16:20:54.886866Z","iopub.status.idle":"2022-02-20T16:20:54.891555Z","shell.execute_reply.started":"2022-02-20T16:20:54.886812Z","shell.execute_reply":"2022-02-20T16:20:54.890376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! kaggle competitions submissions m5-forecasting-accuracy","metadata":{"execution":{"iopub.status.busy":"2022-02-20T16:20:55.80672Z","iopub.execute_input":"2022-02-20T16:20:55.806996Z","iopub.status.idle":"2022-02-20T16:20:56.869716Z","shell.execute_reply.started":"2022-02-20T16:20:55.806966Z","shell.execute_reply":"2022-02-20T16:20:56.869158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 0.1 last 28 days","metadata":{"execution":{"iopub.status.busy":"2021-11-30T11:56:23.876562Z","iopub.execute_input":"2021-11-30T11:56:23.877058Z","iopub.status.idle":"2021-11-30T11:56:23.880559Z","shell.execute_reply.started":"2021-11-30T11:56:23.876997Z","shell.execute_reply":"2021-11-30T11:56:23.879863Z"}}},{"cell_type":"code","source":"last_28_days = ['d_'+ str(i+1) for i in range(1885, 1913)]\nprint(len(last_28_days))","metadata":{"execution":{"iopub.status.busy":"2022-02-20T16:21:30.031819Z","iopub.execute_input":"2022-02-20T16:21:30.032221Z","iopub.status.idle":"2022-02-20T16:21:30.039656Z","shell.execute_reply.started":"2022-02-20T16:21:30.03218Z","shell.execute_reply":"2022-02-20T16:21:30.03806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_submission_last_28_days = df_sample_submission.copy()\n\ndf_submission_last_28_days[forecast_column_names] = np.concatenate((df_sales_train_validation[last_28_days].values, df_sales_train_validation[last_28_days].values))\ndf_submission_last_28_days","metadata":{"execution":{"iopub.status.busy":"2022-02-20T16:21:30.209144Z","iopub.execute_input":"2022-02-20T16:21:30.20947Z","iopub.status.idle":"2022-02-20T16:21:30.270636Z","shell.execute_reply.started":"2022-02-20T16:21:30.209439Z","shell.execute_reply":"2022-02-20T16:21:30.269722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted = df_submission_last_28_days.loc[30490:, forecast_column_names].values\nactual = df_sales_train_evaluation[validation_column_names].values\nprint(\"mean_squared_error: \", mean_squared_error(actual, predicted, squared=False))\nprint(\"mean absolute error: \", mae(actual, predicted))\n# print(\"mean_absolute_percentage_error: \", mean_absolute_percentage_error(actual, predicted))\nprint(\"Root Mean Squared Scaled Error: \", rmsse(actual, predicted))","metadata":{"execution":{"iopub.status.busy":"2022-02-20T16:21:32.467927Z","iopub.execute_input":"2022-02-20T16:21:32.469436Z","iopub.status.idle":"2022-02-20T16:21:32.492792Z","shell.execute_reply.started":"2022-02-20T16:21:32.469368Z","shell.execute_reply":"2022-02-20T16:21:32.491978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_submission_last_28_days","metadata":{"execution":{"iopub.status.busy":"2022-02-20T16:21:34.338177Z","iopub.execute_input":"2022-02-20T16:21:34.339423Z","iopub.status.idle":"2022-02-20T16:21:34.37815Z","shell.execute_reply.started":"2022-02-20T16:21:34.339351Z","shell.execute_reply":"2022-02-20T16:21:34.377545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_submission_last_28_days.to_csv(\"submission_last_28_days.csv\", index=False)\n# ! kaggle competitions submit -f submission_last_28_days.csv -m df_submission_last_28_days  m5-forecasting-accuracy\n! kaggle competitions submissions m5-forecasting-accuracy","metadata":{"execution":{"iopub.status.busy":"2022-02-09T05:53:00.180811Z","iopub.execute_input":"2022-02-09T05:53:00.181188Z","iopub.status.idle":"2022-02-09T05:53:00.510325Z","shell.execute_reply.started":"2022-02-09T05:53:00.181142Z","shell.execute_reply":"2022-02-09T05:53:00.509287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Google Auto ML","metadata":{}},{"cell_type":"code","source":"google_auto_ml_val_only = pd.read_csv(\"/kaggle/input/m5-forecaset-google-automl-results-v1/bq-results-20220208-161332-8exhswoe6c6m.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-02-20T16:48:43.311222Z","iopub.execute_input":"2022-02-20T16:48:43.311468Z","iopub.status.idle":"2022-02-20T16:48:46.41776Z","shell.execute_reply.started":"2022-02-20T16:48:43.31144Z","shell.execute_reply":"2022-02-20T16:48:46.416642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sample_submission","metadata":{"execution":{"iopub.status.busy":"2022-02-20T16:48:46.419459Z","iopub.execute_input":"2022-02-20T16:48:46.419734Z","iopub.status.idle":"2022-02-20T16:48:46.455526Z","shell.execute_reply.started":"2022-02-20T16:48:46.419706Z","shell.execute_reply":"2022-02-20T16:48:46.454657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"google_auto_ml_val_only_wide = google_auto_ml_val_only.pivot(index='id', columns='date', values='predicted_num_sales')\ngoogle_auto_ml_val_only_wide.reset_index(inplace=True)\n#google_auto_ml_val_only_wide.index.name = None\n#del df.index.name\ngoogle_auto_ml_val_only_wide.columns = ['id'] + forecast_column_names\ngoogle_auto_ml_val_only_wide['id'] = google_auto_ml_val_only_wide['id'].str.replace('_evaluation','_validation')\ngoogle_auto_ml_val_only_wide","metadata":{"execution":{"iopub.status.busy":"2022-02-20T16:48:49.381705Z","iopub.execute_input":"2022-02-20T16:48:49.381969Z","iopub.status.idle":"2022-02-20T16:48:50.007743Z","shell.execute_reply.started":"2022-02-20T16:48:49.38194Z","shell.execute_reply":"2022-02-20T16:48:50.006337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"google_auto_ml_val_only_wide_submission = df_sample_submission.copy()\n# Hopefully order of ids don't matter when submitting\ngoogle_auto_ml_val_only_wide_submission[0:len(google_auto_ml_val_only_wide)] = google_auto_ml_val_only_wide\ngoogle_auto_ml_val_only_wide_submission","metadata":{"execution":{"iopub.status.busy":"2022-02-20T16:48:53.072783Z","iopub.execute_input":"2022-02-20T16:48:53.073081Z","iopub.status.idle":"2022-02-20T16:48:53.185861Z","shell.execute_reply.started":"2022-02-20T16:48:53.073051Z","shell.execute_reply":"2022-02-20T16:48:53.184583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"google_auto_ml_val_only_wide_submission.to_csv(\"google_auto_ml_val_only_wide_submission.csv\", index=False)\n# ! kaggle competitions submit -f google_auto_ml_val_only_wide_submission.csv -m google_auto_ml_val_only_wide_submission  m5-forecasting-accuracy\n","metadata":{"execution":{"iopub.status.busy":"2022-02-20T16:48:56.313677Z","iopub.execute_input":"2022-02-20T16:48:56.314891Z","iopub.status.idle":"2022-02-20T16:48:57.704657Z","shell.execute_reply.started":"2022-02-20T16:48:56.314838Z","shell.execute_reply":"2022-02-20T16:48:57.703291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! kaggle competitions submissions m5-forecasting-accuracy","metadata":{"execution":{"iopub.status.busy":"2022-02-20T16:49:01.267667Z","iopub.execute_input":"2022-02-20T16:49:01.267957Z","iopub.status.idle":"2022-02-20T16:49:02.428466Z","shell.execute_reply.started":"2022-02-20T16:49:01.267926Z","shell.execute_reply":"2022-02-20T16:49:02.426706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted = df_submission_last_28_days.loc[30490:, forecast_column_names].values\nactual = df_sales_train_evaluation[validation_column_names].values\nprint(\"mean_squared_error: \", mean_squared_error(actual, predicted, squared=False))\nprint(\"mean absolute error: \", mae(actual, predicted))\n# print(\"mean_absolute_percentage_error: \", mean_absolute_percentage_error(actual, predicted))\nprint(\"Root Mean Squared Scaled Error: \", rmsse(actual, predicted))","metadata":{"execution":{"iopub.status.busy":"2022-02-20T16:49:09.260152Z","iopub.execute_input":"2022-02-20T16:49:09.26082Z","iopub.status.idle":"2022-02-20T16:49:09.291146Z","shell.execute_reply.started":"2022-02-20T16:49:09.260743Z","shell.execute_reply":"2022-02-20T16:49:09.290269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sales_train_evaluation","metadata":{"execution":{"iopub.status.busy":"2022-02-20T16:27:08.365767Z","iopub.execute_input":"2022-02-20T16:27:08.366054Z","iopub.status.idle":"2022-02-20T16:27:08.407349Z","shell.execute_reply.started":"2022-02-20T16:27:08.366011Z","shell.execute_reply":"2022-02-20T16:27:08.406329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Order matters in submission?","metadata":{}},{"cell_type":"code","source":"google_auto_ml_val_only_wide_submission_same_order=google_auto_ml_val_only_wide_submission.copy()\ngoogle_auto_ml_val_only_wide_submission_same_order.id=google_auto_ml_val_only_wide_submission_same_order.id.astype(\"category\")\ngoogle_auto_ml_val_only_wide_submission_same_order.id.cat.set_categories(df_sample_submission['id'].tolist(), inplace=True)\ngoogle_auto_ml_val_only_wide_submission_same_order.sort_values([\"id\"], inplace=True)\ngoogle_auto_ml_val_only_wide_submission_same_order.reset_index(inplace=True, drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T16:50:12.960742Z","iopub.execute_input":"2022-02-20T16:50:12.961054Z","iopub.status.idle":"2022-02-20T16:50:13.171445Z","shell.execute_reply.started":"2022-02-20T16:50:12.960998Z","shell.execute_reply":"2022-02-20T16:50:13.170184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sample_submission","metadata":{"execution":{"iopub.status.busy":"2022-02-20T16:32:58.799499Z","iopub.execute_input":"2022-02-20T16:32:58.799927Z","iopub.status.idle":"2022-02-20T16:32:58.837444Z","shell.execute_reply.started":"2022-02-20T16:32:58.799897Z","shell.execute_reply":"2022-02-20T16:32:58.836558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"google_auto_ml_val_only_wide_submission","metadata":{"execution":{"iopub.status.busy":"2022-02-20T16:50:19.60579Z","iopub.execute_input":"2022-02-20T16:50:19.606684Z","iopub.status.idle":"2022-02-20T16:50:19.663395Z","shell.execute_reply.started":"2022-02-20T16:50:19.606647Z","shell.execute_reply":"2022-02-20T16:50:19.66227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"google_auto_ml_val_only_wide_submission_same_order.query(\"id in ('HOBBIES_1_001_CA_1_validation', 'HOBBIES_1_001_CA_1_evaluation')\")","metadata":{"execution":{"iopub.status.busy":"2022-02-20T16:50:52.635502Z","iopub.execute_input":"2022-02-20T16:50:52.63582Z","iopub.status.idle":"2022-02-20T16:50:52.706853Z","shell.execute_reply.started":"2022-02-20T16:50:52.635788Z","shell.execute_reply":"2022-02-20T16:50:52.706058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"google_auto_ml_val_only_wide_submission_same_order.to_csv(\"google_auto_ml_val_only_wide_submission_same_order.csv\", index=False)\n! kaggle competitions submit -f google_auto_ml_val_only_wide_submission_same_order.csv -m google_auto_ml_val_only_wide_submission_same_order  m5-forecasting-accuracy\n","metadata":{"execution":{"iopub.status.busy":"2022-02-20T16:37:08.13557Z","iopub.execute_input":"2022-02-20T16:37:08.13604Z","iopub.status.idle":"2022-02-20T16:37:15.078433Z","shell.execute_reply.started":"2022-02-20T16:37:08.135976Z","shell.execute_reply":"2022-02-20T16:37:15.077193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! kaggle competitions submissions m5-forecasting-accuracy","metadata":{"execution":{"iopub.status.busy":"2022-02-20T16:48:06.65043Z","iopub.execute_input":"2022-02-20T16:48:06.6507Z","iopub.status.idle":"2022-02-20T16:48:07.727421Z","shell.execute_reply.started":"2022-02-20T16:48:06.650675Z","shell.execute_reply":"2022-02-20T16:48:07.726747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Error analysis","metadata":{}},{"cell_type":"code","source":"df_submission_last_28_days","metadata":{"execution":{"iopub.status.busy":"2022-02-20T16:41:33.992598Z","iopub.execute_input":"2022-02-20T16:41:33.992888Z","iopub.status.idle":"2022-02-20T16:41:34.034818Z","shell.execute_reply.started":"2022-02-20T16:41:33.992858Z","shell.execute_reply":"2022-02-20T16:41:34.034011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## sktime naive","metadata":{}},{"cell_type":"code","source":"! pip install sktime","metadata":{},"execution_count":null,"outputs":[]}]}