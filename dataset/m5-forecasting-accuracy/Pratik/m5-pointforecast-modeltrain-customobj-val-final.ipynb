{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\nfrom collections import defaultdict\nimport gc, sys","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"with open('../input/m5-pointforecast-itstorder-hist-val-2/ordered_train_df.pkl', 'rb') as f:\n    train_df = pickle.load(f)\nwith open('../input/m5-pointforecast-itstorder-hist-val-2/ordered_val_df.pkl', 'rb') as f:\n    val_df = pickle.load(f)\nwith open('../input/m5-pointforecast-itstorder-hist-val-2/val_weights.pkl', 'rb') as f:\n    val_weights = pickle.load(f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.shape, val_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Category:\n    def __init__(self, unique_items, item_to_id={}):\n        self.items = unique_items\n        self.item_to_id = item_to_id\n        for _id, item_name in enumerate(self.items):\n            self.item_to_id[item_name] = _id\n        self.type = np.int16\n        if len(self.items) > 30000:\n            self.type = np.int32\n    \n    def encode_series(self, items):\n        return np.array([self.item_to_id[_item] for _item in items]).astype(self.type)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('../input/m5-point-forecast-createinput-1100/cat_feats.pkl', 'rb') as f:\n    cat_feats = pickle.load(f)\nwith open('../input/m5-point-forecast-createinput-1100/cat_feats_name2idx.pkl', 'rb') as f:\n    cat_feats_name2idx = pickle.load(f)\nwith open('../input/m5-point-forecast-createinput-1100/cat_feats_objs.pkl', 'rb') as f:\n    cat_feats_objs = pickle.load(f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('../input/m5-pointforecast-agggroups-idxs-k-val/agg_groups_idxs_K', 'rb') as f:\n    agg_groups = pickle.load(f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask = (val_weights.weight != 0).values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"w = val_weights.weight.values.astype(np.float64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"w = w[mask]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"K = val_weights.K.values.astype(np.float64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"K = K[mask]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"K.min(), K.max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sales_mean = val_weights.sales_mean.values[mask]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sales_std = val_weights.sales_std.values[mask]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_is = (val_weights.weight != 0).sum(); num_is","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = train_df.y.values.astype(np.float64)\ny_val = val_df.y.values.astype(np.float64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train, y_val","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_df = train_df.drop('y', axis=1)\nX_val_df = val_df.drop('y', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dset = lgb.Dataset(X_train_df, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_dset = lgb.Dataset(X_val_df, y_val, reference=train_dset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"agg_groups[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def custom_obj(preds, train_ds):\n    #calculate L for each (item,store)\n    y = train_ds.get_label()\n    yt = y.reshape(num_is, -1)\n    predst = preds.reshape(num_is, -1)\n    \n    L = np.sum(((yt - predst)**2), axis=1)\n    L = L[:,None]\n    h = float(yt.shape[1])\n    _w = 1.0 * (0.0 + 1e2*w)\n    _w = _w/12.0\n    grads = -1.0 * _w[:,None] * K[:,None] * (yt - predst) * (h**-0.5) * (L**-0.5)\n    hess = (-1.0) * K[:,None] * _w[:,None] * (h**-0.5) * ((-1.0)*(L**-0.5) + ((yt - predst)**2)*(L**-1.5))\n    # iterate over agg_groups each one is a single time series\n    for idxs_g, K_g in agg_groups:\n        yt_g = yt[idxs_g,:]\n        predst_g = predst[idxs_g,:]\n        _w_g = _w[idxs_g].sum()\n        L_g = np.sum((yt_g - predst_g)**2)\n        grads_g = -1.0 * _w_g * K_g * (yt_g - predst_g) * (h**-0.5) * (L_g**-0.5) \n        grads[idxs_g,:] = grads[idxs_g,:] + grads_g\n        hess_g = (-1.0) * K_g * _w_g * (h**-0.5) * ((-1.0)*(L_g**-0.5) + ((yt_g - predst_g)**2)*(L_g**-1.5))\n        hess[idxs_g,:] = hess[idxs_g,:] + hess_g    \n    grads = grads.reshape(-1)\n    hess = hess.reshape(-1)\n    return (grads, hess)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def custom_eval(preds, train_ds):\n    y = train_ds.get_label()\n    yt = y.reshape(num_is, -1)\n    predst = preds.reshape(num_is, -1)\n    #custom_eval\n    h = float(yt.shape[1])\n    eval_result = np.sum(w * K * (h**-0.5) * (np.sum(((yt-predst)**2), axis=1)**0.5)) \n    for idxs_g, K_g in agg_groups:\n        yt_g = yt[idxs_g,:].sum(axis=0)\n        predst_g = predst[idxs_g,:].sum(axis=0)\n        _w_g = w[idxs_g].sum()\n        eval_result += (_w_g * K_g * (np.sum((yt_g-predst_g)**2)**0.5)/ (h**0.5))\n    eval_result = eval_result * (1.0/12.0)\n    return ('wrmsse', eval_result, False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col_names = list(X_train_df.columns.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col_names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# weight_scale 1e2\nparams = {\n    'boosting_type': 'gbdt',\n    'num_leaves': 2**10-1,\n    'learning_rate': 0.03,\n    'metrics':'l2',\n    'feature_fraction': 0.7,\n    'bagging_fraction': 0.75,\n    'bagging_freq': 1,\n    'verbose': 2,\n    'min_data_in_leaf': 2**11-1,\n    'boost_from_average': False\n}\n\ngbm = lgb.train(params, train_dset, valid_sets=[val_dset, train_dset], feature_name=col_names, categorical_feature=[0,1,2,3,4],\n                fobj=custom_obj, feval=custom_eval, num_boost_round=1200)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted(list(zip(col_names, gbm.feature_importance())), key=lambda item: item[1], reverse=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gbm.save_model('gbm_customObj.txt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! ls -alrh","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}