{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 0. Import libraries and read in data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom matplotlib.pyplot import figure\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/m5-forecasting-accuracy/sales_train_validation.csv')\nprice_df = pd.read_csv(\"../input/m5-forecasting-accuracy/sell_prices.csv\")\ncal_df = pd.read_csv(\"../input/m5-forecasting-accuracy/calendar.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cal_df[\"d\"]=cal_df[\"d\"].apply(lambda x: int(x.split(\"_\")[1]))\nprice_df[\"id\"] = price_df[\"item_id\"] + \"_\" + price_df[\"store_id\"] + \"_validation\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. Calculate weight for the level 12 series"},{"metadata":{"trusted":true},"cell_type":"code","source":"for day in tqdm(range(1886, 1914)):\n    wk_id = list(cal_df[cal_df[\"d\"]==day][\"wm_yr_wk\"])[0]\n    wk_price_df = price_df[price_df[\"wm_yr_wk\"]==wk_id]\n    df = df.merge(wk_price_df[[\"sell_price\", \"id\"]], on=[\"id\"], how='inner')\n    df[\"unit_sales_\" + str(day)] = df[\"sell_price\"] * df[\"d_\" + str(day)]\n    df.drop(columns=[\"sell_price\"], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"dollar_sales\"] = df[[c for c in df.columns if c.find(\"unit_sales\")==0]].sum(axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(columns=[c for c in df.columns if c.find(\"unit_sales\")==0], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"weight\"] = df[\"dollar_sales\"] / df[\"dollar_sales\"].sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(columns=[\"dollar_sales\"], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"weight\"] /= 12","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Transform time series"},{"metadata":{"trusted":true},"cell_type":"code","source":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Largest sales value is', df[[c for c in df.columns if c.find('d_')==0]].max().max(), \n      '\\nLargest int16 is', np.iinfo(np.int16).max)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for d in range(1914, 1942):\n    df[\"d_\" + str(d)] = np.nan","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = df.drop(columns = [c for c in df.columns if c.find('d_')==0 and int(c.split('_')[1]) < 1100])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_melted = temp.melt(id_vars=[n for n in temp.columns if n.find(\"id\")!=-1],\n       value_vars=[n for n in temp.columns if n.find(\"d_\")==0],\n       var_name = 'day', value_name = 'sales')\ndel temp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[['id', 'd_1100']].head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_melted.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_melted[\"day\"]=df_melted[\"day\"].apply(lambda x: int(x.split(\"_\")[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_melted=df_melted.merge(cal_df.drop(columns=[\"date\", \"wm_yr_wk\", \n                                            \"weekday\"]), left_on=[\"day\"], right_on=[\"d\"]).drop(columns=[\"d\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_melted['event_name_1'].value_counts(dropna=False).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_melted['event_name_1'].astype('category').cat.codes.astype(\"int8\").value_counts().head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_melted[\"event_name_1\"]=df_melted[\"event_name_1\"].astype('category').cat.codes.astype(\"int8\")\ndf_melted[\"event_name_2\"]=df_melted[\"event_name_2\"].astype('category').cat.codes.astype(\"int8\")\ndf_melted[\"event_type_1\"]=df_melted[\"event_type_1\"].astype('category').cat.codes.astype(\"int8\")\ndf_melted[\"event_type_2\"]=df_melted[\"event_type_2\"].astype('category').cat.codes.astype(\"int8\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"useful_ids = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id']\nid_encodings = [id_col + '_encoding' for id_col in useful_ids]\n\nfor id_col in useful_ids:\n    if id_col == 'item_id':\n        df_melted[id_col + '_encoding'] = df_melted[id_col].astype('category').cat.codes.astype(\"int16\")\n    else: \n        df_melted[id_col + '_encoding'] = df_melted[id_col].astype('category').cat.codes.astype(\"int8\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_melted.drop(columns=['year'] + useful_ids, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reduce_mem_usage(df_melted)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_melted['test'] = df_melted[[\"id\",\"sales\"]].groupby(\"id\")[\"sales\"].shift(1).fillna(-1).astype(np.int16)\nprint(list(df_melted[df_melted['day']==1101]['test']) == list(df_melted[df_melted['day']==1100]['sales']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_melted.drop(columns=['test'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create lags, lags starts from 28 days ago to 77 days ago, spaced by 7 days\nfor lag in tqdm([28, 35, 42, 49, 56, 63, 70, 77]):\n    df_melted[\"lag_\" + str(lag)] = df_melted[[\"id\",\"sales\"]].groupby(\"id\")[\"sales\"].shift(lag).fillna(-1).astype(np.int16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_melted=df_melted[df_melted['lag_77']!=-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert list(df_melted[df_melted['day']==1528]['lag_28']) == list(df_melted[df_melted['day']==1500]['sales'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_melted.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"price_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_melted=df_melted.merge(cal_df[['d', 'wm_yr_wk']], left_on=['day'], right_on=['d']).drop(columns=['d'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_melted=df_melted.merge(price_df[['id', 'sell_price', 'wm_yr_wk']], on=['id', 'wm_yr_wk'], how='inner')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del price_df\ndel cal_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_params = {\n            \"objective\" : \"poisson\",\n            \"metric\" :\"rmse\",\n            \"force_row_wise\" : True,\n            \"learning_rate\" : 0.05,\n    #         \"sub_feature\" : 0.8,\n            \"sub_row\" : 0.75,\n            \"bagging_freq\" : 1,\n            \"lambda_l2\" : 0.1,\n    #         \"nthread\" : 4\n            \"metric\": [\"rmse\"],\n        'verbosity': 1,\n        'num_iterations' : 2048,\n        'num_leaves': 64,\n        \"min_data_in_leaf\": 50,\n    }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del wk_price_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = df_melted[df_melted[\"day\"] < 1886].drop(columns=[\"sales\"])\nX_val = df_melted[df_melted[\"day\"].between(1886, 1913)].drop(columns=[\"sales\"])\nX_test = df_melted[df_melted[\"day\"] > 1913].drop(columns=[\"sales\"])\n\ny_train = df_melted[df_melted[\"day\"] < 1886][\"sales\"]\ny_val = df_melted[df_melted[\"day\"].between(1886, 1913)][\"sales\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%who DataFrame","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del df_melted","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nnp.random.seed(777)\n\nfake_valid_inds = np.random.choice(X_train.index.values, 2_000_000, replace = False)\ntrain_inds = np.setdiff1d(X_train.index.values, fake_valid_inds)\ntrain_data = lgb.Dataset(X_train.drop(columns=['id']).loc[train_inds] , label = y_train.loc[train_inds], \n                         categorical_feature=id_encodings, free_raw_data=False)\nfake_valid_data = lgb.Dataset(X_train.drop(columns=['id']).loc[fake_valid_inds], label = y_train.loc[fake_valid_inds],\n                              categorical_feature=id_encodings,\n                 free_raw_data=False)# This is a random sample, we're not gonna apply any time series train-test-split tricks here!","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nm_lgb = lgb.train(best_params, train_data, valid_sets = [fake_valid_data], verbose_eval=1) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for d in range(1886, 1914):\n    df['F_' + str(d)] = m_lgb.predict(X_val[X_val['day']==d].drop(columns=['id']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"h = 28\nn = 1885\ndef rmsse(ground_truth, forecast, train_series, axis=1):\n    # assuming input are numpy array or matrices\n    assert axis == 0 or axis == 1\n    assert type(ground_truth) == np.ndarray and type(forecast) == np.ndarray and type(train_series) == np.ndarray\n    \n    if axis == 1:\n        # using axis == 1 we must guarantee these are matrices and not arrays\n        assert ground_truth.shape[1] > 1 and forecast.shape[1] > 1 and train_series.shape[1] > 1\n    \n    numerator = ((ground_truth - forecast)**2).sum(axis=axis)\n    if axis == 1:\n        denominator = 1/(n-1) * ((train_series[:, 1:] - train_series[:, :-1]) ** 2).sum(axis=axis)\n    else:\n        denominator = 1/(n-1) * ((train_series[1:] - train_series[:-1]) ** 2).sum(axis=axis)\n    if (numerator < 0).any():\n        print('nu')\n    elif (denominator < 0).any():\n        print(denominator[denominator < 0])\n    return (1/h * numerator/denominator) ** 0.5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"level_groupings = {2: [\"state_id\"], 3: [\"store_id\"], 4: [\"cat_id\"], 5: [\"dept_id\"], \n              6: [\"state_id\", \"cat_id\"], 7: [\"state_id\", \"dept_id\"], 8: [\"store_id\", \"cat_id\"], 9: [\"store_id\", \"dept_id\"],\n              10: [\"item_id\"], 11: [\"item_id\", \"state_id\"]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#remake agg_df\nnew_agg_df = pd.DataFrame(df[[c for c in df.columns if c.find(\"d_\") == 0 or c.find(\"F_\") == 0]].sum()).transpose()\nnew_agg_df[\"level\"] = 1\nnew_agg_df[\"weight\"] = 1/12\ncolumn_order = new_agg_df.columns\n\nfor level in level_groupings:\n    temp_df = df.groupby(by=level_groupings[level]).sum().reset_index()\n    temp_df[\"level\"] = level\n    new_agg_df = new_agg_df.append(temp_df[column_order])\ndel temp_df\n\nagg_df = new_agg_df\n\ntrain_series_cols = [c for c in df.columns if c.find(\"d_\") == 0 and int(c.split('_')[1]) < 1886]\nground_truth_cols = [c for c in df.columns if c.find(\"d_\") == 0 and int(c.split('_')[1]) in range(1886, 1914)]\nforecast_cols = [c for c in df.columns if c.find(\"F_\") == 0]\n\ndf[\"rmsse\"] = rmsse(np.array(df[ground_truth_cols]), \n        np.array(df[forecast_cols]), np.array(df[train_series_cols]))\nagg_df[\"rmsse\"] = rmsse(np.array(agg_df[ground_truth_cols]), \n        np.array(agg_df[forecast_cols]), np.array(agg_df[train_series_cols]))\n\ndf[\"wrmsse\"] = df[\"weight\"] * df[\"rmsse\"]\nagg_df[\"wrmsse\"] = agg_df[\"weight\"] * agg_df[\"rmsse\"]\n\nprint(df[\"wrmsse\"].sum() + agg_df[\"wrmsse\"].sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb.plot_importance(m_lgb)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### Make submission file"},{"metadata":{"trusted":true},"cell_type":"code","source":"submit_df = df[[\"id\"]]\nfor i in range(1, 29):\n    submit_df[\"F\" + str(i)] = m_lgb.predict(X_test[X_test['day']==i+1913].drop(columns=['id']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit_df2 = submit_df.copy()\nsubmit_df2[\"id\"] = submit_df2[\"id\"].apply(lambda x: x.replace('validation',\n                                                              'evaluation'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit_df = submit_df.append(submit_df2).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit_df.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}