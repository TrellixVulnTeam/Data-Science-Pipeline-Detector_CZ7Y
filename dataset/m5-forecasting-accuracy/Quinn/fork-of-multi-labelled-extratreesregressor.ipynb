{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 0. Import libraries and read in data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom matplotlib.pyplot import figure\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, RandomForestClassifier, ExtraTreesClassifier\nfrom sklearn.metrics import mean_squared_error, confusion_matrix, accuracy_score, precision_score, recall_score, mean_squared_error\nfrom sklearn.preprocessing import MinMaxScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/m5-forecasting-accuracy/sales_train_validation.csv')\nprice_df = pd.read_csv(\"../input/m5-forecasting-accuracy/sell_prices.csv\")\ncal_df = pd.read_csv(\"../input/m5-forecasting-accuracy/calendar.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cal_df[\"d\"]=cal_df[\"d\"].apply(lambda x: int(x.split(\"_\")[1]))\nprice_df[\"id\"] = price_df[\"item_id\"] + \"_\" + price_df[\"store_id\"] + \"_validation\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. Calculate weight for the level 12 series"},{"metadata":{"trusted":true},"cell_type":"code","source":"for day in tqdm(range(1886, 1914)):\n    wk_id = list(cal_df[cal_df[\"d\"]==day][\"wm_yr_wk\"])[0]\n    wk_price_df = price_df[price_df[\"wm_yr_wk\"]==wk_id]\n    df = df.merge(wk_price_df[[\"sell_price\", \"id\"]], on=[\"id\"], how='inner')\n    df[\"unit_sales_\" + str(day)] = df[\"sell_price\"] * df[\"d_\" + str(day)]\n    df.drop(columns=[\"sell_price\"], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"dollar_sales\"] = df[[c for c in df.columns if c.find(\"unit_sales\")==0]].sum(axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(columns=[c for c in df.columns if c.find(\"unit_sales\")==0], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"weight\"] = df[\"dollar_sales\"] / df[\"dollar_sales\"].sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(columns=[\"dollar_sales\"], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"weight\"] /= 12","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Infer round truth values, and weights for all the higher level series by aggregating"},{"metadata":{"trusted":true},"cell_type":"code","source":"agg_df = pd.DataFrame(df[[c for c in df.columns if c.find(\"d_\") == 0]].sum()).transpose()\nagg_df[\"level\"] = 1\nagg_df[\"weight\"] = 1/12\ncolumn_order = agg_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"level_groupings = {2: [\"state_id\"], 3: [\"store_id\"], 4: [\"cat_id\"], 5: [\"dept_id\"], \n              6: [\"state_id\", \"cat_id\"], 7: [\"state_id\", \"dept_id\"], 8: [\"store_id\", \"cat_id\"], 9: [\"store_id\", \"dept_id\"],\n              10: [\"item_id\"], 11: [\"item_id\", \"state_id\"]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for level in tqdm(level_groupings):\n    temp_df = df.groupby(by=level_groupings[level]).sum().reset_index()\n    temp_df[\"level\"] = level\n    agg_df = agg_df.append(temp_df[column_order])\n\ndel temp_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.shape[0], agg_df.shape[0], df.shape[0] + agg_df.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"agg_df[\"weight\"].sum() + df[\"weight\"].sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Multi Label Regression with ExtraTreesRegressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"h = 28\ndef rmsse(ground_truth, forecast, train_series, axis=1, n=1885):\n    # assuming input are numpy array or matrices\n    assert axis == 0 or axis == 1\n    assert type(ground_truth) == np.ndarray and type(forecast) == np.ndarray and type(train_series) == np.ndarray\n    \n    if axis == 1:\n        # using axis == 1 we must guarantee these are matrices and not arrays\n        assert ground_truth.shape[1] > 1 and forecast.shape[1] > 1 and train_series.shape[1] > 1\n    \n    numerator = ((ground_truth - forecast)**2).sum(axis=axis)\n    if axis == 1:\n        denominator = 1/(n-1) * ((train_series[:, 1:] - train_series[:, :-1]) ** 2).sum(axis=axis)\n    else:\n        denominator = 1/(n-1) * ((train_series[1:] - train_series[:-1]) ** 2).sum(axis=axis)\n    return (1/h * numerator/denominator) ** 0.5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.get_dummies(df.drop(columns=[\"id\", \"item_id\", \"weight\"]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[[\"id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\", \"weight\"]].join(pd.get_dummies(df.drop(columns=[\"id\", \"item_id\", \"weight\"])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_s = 100\nbest_m = None\nbest_start_date = 1000","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"1885 - 28+28","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for _ in tqdm(range(50)):\n    rand_est = random.randint(20, 50)\n    rand_depth = random.randint(10, 30)\n    rand_start_date = random.randint(1200, 1500)\n    \n    print(rand_est, rand_depth)\n    \n    \n    average = []\n    \n    for cv in range(1, 4):\n        train_start = rand_start_date - 28 * cv\n        train_end = 1885 - 28 * cv\n        \n        regressor = ExtraTreesRegressor(n_estimators=rand_est, max_depth=rand_depth, random_state=42)\n        \n        drop_cols = [item for item in [c for c in df.columns if c.find(\"F_\")==0] + ['wrmsse', 'rmsse'] if item in df.columns]\n        df.drop(columns=drop_cols, inplace=True)\n\n        regressor.fit(df.drop(columns=[\"id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"] +\\\n                              [c for c in df.columns if c.find(\"d_\")==0 and int(c.split(\"_\")[1]) not in range(train_start, train_end + 1)]),\n              df[[c for c in df.columns if c.find(\"d_\")==0 and int(c.split(\"_\")[1]) in range(train_end + 1, train_end + 28 + 1)]])\n\n        pred_df = pd.DataFrame(regressor.predict(df.drop(columns=[\"id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"] +\\\n                                       [c for c in df.columns if c.find(\"d_\")==0 and int(c.split(\"_\")[1]) not in range(train_start+28, train_end + 28 + 1)])))\n        pred_df.columns = [\"F_\" + str(d) for d in range(train_end + 28 + 1, train_end + 28 + 28 + 1)]\n        df = df.join(pred_df)\n\n        # remake agg_df\n        new_agg_df = pd.DataFrame(df[[c for c in df.columns if c.find(\"d_\") == 0 or c.find(\"F_\") == 0]].sum()).transpose()\n        new_agg_df[\"level\"] = 1\n        new_agg_df[\"weight\"] = 1/12\n        column_order = new_agg_df.columns\n\n        for level in level_groupings:\n            temp_df = df.groupby(by=level_groupings[level]).sum().reset_index()\n            temp_df[\"level\"] = level\n            new_agg_df = new_agg_df.append(temp_df[column_order])\n        del temp_df\n\n        agg_df = new_agg_df\n        \n        train_series_cols = [c for c in df.columns if c.find(\"d_\") == 0][:-28]\n        ground_truth_cols = [c for c in df.columns if c.find(\"d_\") == 0][-28:]\n        forecast_cols = [c for c in df.columns if c.find(\"F_\") == 0]\n\n        df[\"rmsse\"] = rmsse(np.array(df[ground_truth_cols]), \n                np.array(df[forecast_cols]), np.array(df[train_series_cols]))\n        agg_df[\"rmsse\"] = rmsse(np.array(agg_df[ground_truth_cols]), \n                np.array(agg_df[forecast_cols]), np.array(agg_df[train_series_cols]))\n\n        df[\"wrmsse\"] = df[\"weight\"] * df[\"rmsse\"]\n        agg_df[\"wrmsse\"] = agg_df[\"weight\"] * agg_df[\"rmsse\"]\n\n        print(\"CV\", cv, \":\", df[\"wrmsse\"].sum() + agg_df[\"wrmsse\"].sum())\n\n        average.append(df[\"wrmsse\"].sum() + agg_df[\"wrmsse\"].sum())\n    \n    this_s = np.array(average).mean()\n    if this_s < best_s:\n        best_s = this_s\n        best_m = regressor\n        best_start_date = rand_start_date\n        \n    print(this_s, best_s)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fit the best_m with the closest training set\nbest_m.fit(df.drop(columns=[\"id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"] +\\\n                              [c for c in df.columns if c.find(\"d_\")==0 and int(c.split(\"_\")[1]) not in range(best_start_date, 1886)]),\n              df[[c for c in df.columns if c.find(\"d_\")==0 and int(c.split(\"_\")[1]) in range(1886, 1914)]])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### Make submission file"},{"metadata":{"trusted":true},"cell_type":"code","source":"submit_df = df[[\"id\"]]\npred = best_m.predict(df.drop(columns=[\"id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"] +\n                               [c for c in df.columns if c.find(\"d_\")==0 and int(c.split(\"_\")[1]) not in range(best_start_date+28, 1914)]))\nfor i in range(1, 29):\n    submit_df[\"F\" + str(i)] = pred[:, i-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit_df2 = submit_df.copy()\nsubmit_df2[\"id\"] = submit_df2[\"id\"].apply(lambda x: x.replace('validation',\n                                                              'evaluation'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit_df = submit_df.append(submit_df2).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit_df.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}