{"cells":[{"metadata":{},"cell_type":"markdown","source":"# M5: First Look at the Data\n\nNot the world's prettiest notebook, but good enough to get a feel for the data in this competition and how to use it.\n\n***\n\n### Loading packages","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Input files\n***\n### File Paths","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"files = {}\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        files[filename[:4]] = os.path.join(dirname, filename)\nfiles","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loading files\n\nSeems like the data is not too big, all can be loaded in one go in around 12 seconds.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain_df, cal_df, prc_df, sub_df = [pd.read_csv(files[f]) for f in ['sale', 'cale', 'sell', 'samp']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Understanding the data\n\n***\n\n### Training data\n\n* The primary key is the `id`, which is a combination of all remaining categorical columns:\n  * `item_id` = `dept_id` + `_{nnn}`; `dept_id` = `cat_id` + `_{n}` \n  * `store_id` = `state_id` + `_{n}`\n* Item sales are stored in wide format in columns `d_1`, ... `d_1913`\n  * These are the **target (y)** values for training!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"There are %d unique item ids to forecast!\"%train_df.shape[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"One thing that should be noted is that the are **a lot** of items with days that have no sales, as shown in the figure below (where blue represents days with sales).\n* It is quite possible that some items weren't selling from the very beggining which seems to be confirmed by price data (see the section on the price data).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"n = 100 # number of items to sample\nsales = train_df[[c for c in train_df.columns if c.startswith('d_')]].sample(n)\nfig, ax = plt.subplots(1, 1, facecolor='w', figsize=(15,10))\nax = sns.heatmap(sales>0, cbar=False, xticklabels=False, yticklabels=False, cmap=\"GnBu\")\nplt.title(\"Heatmap of >0 sales indicator for %d randomly selected items\"%n, fontsize=16)\nplt.ylabel(\"Items\")\nplt.xlabel(\"Time\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Submission file\n\nThe submission file requires two types of predictions:\n\n* `'validation'`: this is for the initial training stage and covers `d_1914` to `d_1941`\n* `'evaluation'`: this is for the final submission stage and covers `d_1942` to `d_1969`","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df['type'] = sub_df['id'].apply(lambda x: x.split('_')[-1]).astype('category')\nsub_df['type'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since we currently only have `'validation'` stage data, we should extract only `id`s that have the `'validation'` suffix, which can be matched against the `id` column from `train_df`:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"val_df = sub_df[sub_df['type']=='validation'].drop('type',1)\nval_df.sample(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Calendar Data\n\nThe calendar data contains day-specific information for **all** 1969 days in the training, validation and evaluation time periods. These can be used as features for the training set, using the `d` column for merging - and can be used for forecasting since they are known ex ante.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"First 3 rows of the calendar data:\")\ndisplay(cal_df.head(3))\nprint(\"Last 3 rows of the calendar data:\")\ndisplay(cal_df.tail(3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Price data\n\nThe price data contains weekly prices for every `id`, spanning the training, validation and evaluation periods.\n\n* Importantly, this means we have price data available ex ante, allowing us to use future prices when making predictions!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"prc_df.loc[:,'id'] = prc_df['item_id'] + '_' + prc_df['store_id'] + '_validation'\nprc_df = prc_df.drop(['store_id', 'item_id'],1)\ndisplay(prc_df.sample(5))\nprint(\"Earliest week: %d\"%prc_df['wm_yr_wk'].min())\nprint(\"Latest week: %d\"%prc_df['wm_yr_wk'].max())\nprint(\"Number of unique id: %d\"%len(prc_df['id'].unique()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The price data can also help pinpoint when certain items may not have been available:\n\n* First, we can see that **all** items are available and have price data up to the latest period in the data i.e. week 11621 (there may be gaps though which should be checked later...)\n* Second, we can see that some items are not available from the very beginning (though most are)\n  * This needs to be accounted for, as some 0 sale counts should in fact be NaN in the training data set!\n  * Also there's some seasonality to when new products get introduced - not sure if this matters...","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"id_grp = prc_df.groupby('id')\nmin_wk = id_grp['wm_yr_wk'].min()\nmax_wk = id_grp['wm_yr_wk'].max()\nprint(\"Summary statistics for latest week of prices for each item shows that ALL items have prices available in the last week:\")\ndisplay(max_wk.describe())\nprint(\"New items appear to be rolled out in a staggered, seasonal fashion:\")\nfig, ax = plt.subplots(1, 1, facecolor='w', figsize=(12,6))\nax.hist(min_wk, bins=25)\nplt.title('Minimum week across different item IDs', fontsize=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*** \n<br><br><br><br><br><br><br><br>","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}