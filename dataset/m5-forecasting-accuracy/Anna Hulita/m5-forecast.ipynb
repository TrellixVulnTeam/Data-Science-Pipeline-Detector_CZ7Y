{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn import metrics\nimport lightgbm as lgb\nfrom sklearn.linear_model import Ridge\nimport gc\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# d_1 - d_1913 - train\n# d_1914 - d_1941 - validation\n# d_1942 - d_1969 - evaluation\n\n# validation_start = 1914\n# evaluation_start = 1942\n\n# train_start = 1500\n# prediction_start = 1914","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # avg prediction\n# def get_train(sales, train_start, train_end):\n#     # train_start - included\n#     # train_end - excluded\n#     train_range = range(train_start,train_end)\n#     d_train  = ['d_' + str(i) for i in train_range]\n#     sales_columns = ['id','item_id','dept_id','cat_id','store_id','state_id']\n#     train = sales[sales_columns + d_train]\n\n#     train = train.rename(dict(zip(d_train, train_range)), axis=1)\n#     train['id'] = train['id'].str.replace('_evaluation','')\n#     train = train.melt(id_vars=sales_columns, value_vars=train_range, var_name='d', value_name='demand')\n#     return train\n\n# def predict_avg(train, avg_n):\n#     # predict avg\n#     train_end = train['d'].max()\n#     avg_data = train[train['d']>(train_end-avg_n)]\n#     avg_data = avg_data.groupby(['id'])['demand'].mean()\n#     avg_data = pd.DataFrame(avg_data)\n\n\n#     f_columns = ['F' + str(i+1) for i in range(0,28)]\n#     for column in f_columns:\n#         avg_data[column] = avg_data['demand']\n\n#     avg_data = avg_data[f_columns]\n#     avg_data.reset_index(inplace=True)\n#     return avg_data\n\n# def submit_avg():\n#     train = get_train(sales, 1800, validation_start)\n#     avg_data_val = predict_avg(train, 28)\n#     avg_data_val['id'] = avg_data_val['id'] + '_validation'\n    \n#     train = get_train(sales, 1800, evaluation_start)\n#     avg_data_eval = predict_avg(train, 28)\n#     avg_data_eval['id'] = avg_data_eval['id'] + '_evaluation'\n    \n#     avg_data = pd.concat([avg_data_val,avg_data_eval])\n    \n#     submission = submission[['id']].merge(avg_data, how='left')\n#     submission.to_csv(\"submission28.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def reshape_sales(sales, train_start, train_end):\n    # train_start - included\n    # train_end - excluded\n    train_range = range(train_start,train_end)\n    d_train  = ['d_' + str(i) for i in train_range]\n    sales_columns = ['id','item_id','dept_id','cat_id','store_id','state_id']\n    sales = sales[sales_columns + d_train]\n    \n    sales = sales.reindex(columns=sales.columns.tolist() + [\"d_\" + str(train_end + i) for i in range(28)])\n\n    sales['id'] = sales['id'].str.replace('_evaluation','')\n    sales = sales.melt(id_vars=sales_columns, var_name='d', value_name='demand')\n    sales['d'] = sales['d'].str[2:].astype(\"int16\")\n    \n    calendar['event'] = (~calendar['event_name_1'].isna()|~calendar['event_name_2'].isna()).astype(int)\n    sales = sales.merge(calendar[['d','wday','event']], how='left', on=['d'])\n    return sales","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepare_sales(sales):\n    le = LabelEncoder()\n    sales['wday'] = le.fit_transform(sales['wday'])\n    \n    le = LabelEncoder()\n    sales['cat_id'] = le.fit_transform(sales['cat_id'])\n\n    le = LabelEncoder()\n    sales['dept_id'] = le.fit_transform(sales['dept_id'])\n\n    sales['lag28'] = sales.groupby(['id'])['demand'].transform(lambda x: x.shift(28))\n    sales['lag30'] = sales.groupby(['id'])['demand'].transform(lambda x: x.shift(30))\n    \n    sales['rolling_mean_7'] = sales.groupby(['id'])['demand'].transform(lambda x: x.shift(28).rolling(7).mean())\n    sales['rolling_mean_3'] = sales.groupby(['id'])['demand'].transform(lambda x: x.shift(28).rolling(3).mean())\n    sales['rolling_mean_30'] = sales.groupby(['id'])['demand'].transform(lambda x: x.shift(28).rolling(30).mean())\n    \n    sales['rolling_std_7'] = sales.groupby(['id'])['demand'].transform(lambda x: x.shift(28).rolling(7).std())\n    \n    #sales = sales[~sales['rolling_mean_7'].isna()]\n    sales.sort_values(['id','d'], inplace=True)\n    sales.fillna(method = 'bfill', inplace=True)\n\n    return sales","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_predict_lgb(sales, prediction_start):\n    d_min = sales['d'].min()\n    d_max = prediction_start-1\n    val_split_d = d_min+int((d_max-d_min)*0.9)\n    \n    test = sales[sales['d']>=prediction_start]\n    val = sales[(sales['d']<prediction_start)&(sales['d']>=val_split_d)]\n    train = sales[sales['d']<val_split_d][~sales['rolling_mean_7'].isna()]\n        \n    train_set = lgb.Dataset(train[features], label=train[label], feature_name=features, categorical_feature=cat_features)\n    val_set = lgb.Dataset(val[features], label=val[label], feature_name=features, categorical_feature=cat_features)\n    \n    params = {\n        'boosting_type': 'gbdt',\n        'metric': 'rmse',\n        'objective': 'regression',\n        'n_jobs': -1,\n        'seed': 236,\n        'learning_rate': 0.1,\n        'bagging_fraction': 0.75,\n        'bagging_freq': 10, \n        'colsample_bytree': 0.75}\n    \n    model = lgb.train(params, train_set, num_boost_round = 1000, early_stopping_rounds = 50, valid_sets = [train_set, val_set], verbose_eval = 100)\n\n    val_pred = model.predict(val[features])\n    val_score = np.sqrt(metrics.mean_squared_error(val_pred, val[label]))\n    print('val rmse score is {}'.format(val_score))\n\n    test_pred = model.predict(test[features])\n    test['demand']=test_pred\n    \n    return test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_predict_ridge(sales, prediction_start):\n    test = sales[sales['d']>=prediction_start]\n    train = sales[sales['d']<prediction_start]\n\n    model = Ridge(alpha=1.0)\n    \n    model.fit(train[features], train[label])\n    test_pred = model.predict(test[features])\n    test['demand'] = test_pred\n    \n    return test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def submit(sales, train_start, train_predict_func, mode='validation'):\n    if mode == 'validation':\n        prediction_start = 1914\n    elif mode == 'evaluation':\n        prediction_start = 1942\n    \n    print('reshaping sales ...')\n    sales = reshape_sales(sales, train_start, prediction_start)\n    print('preparing sales ...')\n    sales = prepare_sales(sales)\n    print('training and predicting ...')\n    test = train_predict_func(sales, prediction_start)\n    \n    prediction = pd.pivot(test[['id','d','demand']], index = 'id', columns = 'd', values = 'demand')\n    prediction.columns = ['F'+str(i+1) for i in range(0,28)]\n    prediction.reset_index(inplace=True)\n    prediction['id'] = prediction['id']+'_'+mode\n    return prediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def reshape_validation(sales):\n    # get validation ground truth for comparison\n    d_validation  = ['d_' + str(i) for i in range(1914, 1914+28)]\n    sales_validation = sales[['id']+d_validation]\n    sales_validation['id'] = sales_validation['id'].str.replace('_evaluation','')\n    sales_validation = sales_validation.melt(id_vars=['id'], var_name='d', value_name='val_demand')\n    sales_validation['d'] = sales_validation['d'].str[2:].astype(\"int16\")\n    return sales_validation\n\ndef get_rmse_score(sales_validation, test):\n    sales_validation = sales_validation[['id','d','val_demand']].merge(test[['id','d','demand']], on=['id','d'],how='left')\n    rmse = np.sqrt(metrics.mean_squared_error(sales_validation['val_demand'], sales_validation['demand']))\n    return rmse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['wday', 'lag28', 'rolling_mean_7', 'rolling_std_7', 'lag30', 'rolling_mean_3', 'rolling_mean_30', 'event','cat_id','dept_id']\ncat_features = ['wday', 'event','cat_id','dept_id'] \nlabel = 'demand'\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dev mode\n# submission = pd.read_csv('/kaggle/input/m5-forecasting-accuracy/sample_submission.csv')\n# calendar = pd.read_csv('/kaggle/input/m5-forecasting-accuracy/calendar.csv')\n# calendar['d'] = calendar['d'].str[2:].astype(\"int16\")\n\n# sales = pd.read_csv('/kaggle/input/m5-forecasting-accuracy/sales_train_evaluation.csv')\n# sales_validation = reshape_validation(sales)\n\n# train_start, prediction_start = 1000, 1914\n\n# print('reshaping sales ...')\n# sales = reshape_sales(sales, train_start, prediction_start)\n# print('preparing sales ...')\n# sales = prepare_sales(sales)\n\n# test = train_predict_lgb(sales, prediction_start)\n# rmse = get_rmse_score(sales_validation, test)\n# rmse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 2.2497847944992713","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/m5-forecasting-accuracy/sample_submission.csv')\ncalendar = pd.read_csv('/kaggle/input/m5-forecasting-accuracy/calendar.csv')\ncalendar['d'] = calendar['d'].str[2:].astype(\"int16\")\n\nsales = pd.read_csv('/kaggle/input/m5-forecasting-accuracy/sales_train_evaluation.csv')\nprediction_val = submit(sales, 1000, train_predict_lgb, mode='validation')\n\nsales = pd.read_csv('/kaggle/input/m5-forecasting-accuracy/sales_train_evaluation.csv')\nprediction_eval = submit(sales, 1000, train_predict_lgb, mode='evaluation')\n\nprediction_data = pd.concat([prediction_val,prediction_eval])\nsubmission = submission[['id']].merge(prediction_data, how='left')\nsubmission.to_csv(\"submission_lgb.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}