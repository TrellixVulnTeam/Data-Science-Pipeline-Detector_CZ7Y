{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport cv2\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nr = plt.imread\ndef p(x):plt.imshow(x);plt.show()\n    \nimport math\ndef subplotter(img_list,ncols=6,figsize=14,names=None):\n    nrows= math.ceil(len(img_list)/ncols)\n    \n    plt.figure(figsize=(figsize,figsize))\n    for i,img in enumerate(img_list):\n        plt.subplot(nrows,ncols,i+1)\n        plt.imshow(img)\n        if names:plt.title(names[i])\n    plt.show()\n    \nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/cassava-leaf-disease-classification/train.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['label'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['label'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_dir='/kaggle/input/cassava-leaf-disease-classification/train_images/'\nnum_imgs=42\n\nfor e in df['label'].unique():\n    print(e)\n    small_df=df[df.label==e].sample(frac=1)\n    img_list=[];name_list=[]\n    for i in range(num_imgs):\n        img_name=small_df.iloc[i]['image_id']\n        img_list.append(r(img_dir+img_name))\n        name_list.append(img_name.split('.')[0])\n    subplotter(img_list,names=name_list,figsize=28)\n        \n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Images clicked in wide variety of lighting,angle,,number and position distribution. Differences betweeen classes is quite noticible"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Trainer"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install timm\n!pip install pytorch-lightning\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, utils\nimport torch, timm\nimport pytorch_lightning as pl\nfrom pytorch_lightning.metrics.functional import accuracy\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader, random_split\nfrom pytorch_lightning.loggers import TensorBoardLogger\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class PlantLoader(Dataset):\n    def __init__(self, img_names,targets, transform=None):\n        self.img_names=img_names\n        self.targets=targets\n        self.transform=transform\n        self.img_dir='/kaggle/input/cassava-leaf-disease-classification/train_images/'\n    def __len__(self):\n        return len(self.img_names)\n    def __getitem__(self, idx):\n        \n        img_name=self.img_names[idx]\n        label=int(self.targets[idx])\n        \n        image=r(img_dir+img_name)\n        \n        if self.transform: image = self.transform(image)\n            \n        return image,label\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.shape(df[df.label==2].iloc[1:200] )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils import resample\nfrom sklearn.model_selection import train_test_split\nnum_samples=2600 ; df_balanced=None\n\nfor e in df['label'].unique():\n    df_class = df[df.label==e].iloc[:num_samples]\n    \n    df_upsampled = resample(df_class, \n                                 replace=True,     # sample with replacement\n                                 n_samples=num_samples,    # to match majority class\n                                 random_state=123) # reproducible results\n \n\n    if df_balanced is None: df_balanced = df_upsampled\n    else: df_balanced = pd.concat([df_balanced, df_upsampled])\n \n\nprint(df_balanced['label'].value_counts() )\n\nX_train, X_test, y_train, y_test = train_test_split( df_balanced.image_id, df_balanced.label, test_size=0.2, random_state=42)\n\nprint(y_train.value_counts() )\nprint(y_test.value_counts() )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size=32\n\nnormalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])\ntrain_augs=transforms.Compose([\n            transforms.ToPILImage(),\n            transforms.RandomResizedCrop(224),\n            transforms.RandomHorizontalFlip(),\n            transforms.ToTensor(),\n            normalize ])\n\nval_augs=transforms.Compose([\n            transforms.ToPILImage(),\n            transforms.ToTensor(),\n            normalize ])\n\n\ndataset = PlantLoader(list(X_train),list(y_train),train_augs)\ntrain_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=8)\n\n\ndataset = PlantLoader(list(X_test),list(y_test),val_augs)\nval_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=8)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, (images, target) in enumerate(train_dataloader):\n    print(torch.min(images),torch.max(images),target)\n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class PlantModel(pl.LightningModule):\n\n    def __init__(self):\n        super(PlantModel, self).__init__()\n        self.model = timm.create_model('resnest26d', pretrained=True)\n\n    def forward(self, x):\n        return self.model(x)\n\n    def training_step(self, batch, batch_nb):\n        x, y = batch\n        loss = F.cross_entropy(self(x), y)\n        self.log('train_loss', loss, prog_bar=True)\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        x, y = batch\n        logits = self(x)\n        loss = F.nll_loss(logits, y)\n\n        # validation metrics\n        preds = torch.argmax(logits, dim=1)\n        acc = accuracy(preds, y)\n        self.log('val_loss', loss, prog_bar=True)\n        self.log('val_acc', acc, prog_bar=True)\n        return loss\n    \n    def configure_optimizers(self):\n        return torch.optim.Adam(self.parameters(), lr=1e-3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lr finder\nplant_model = PlantModel()\ntrainer = pl.Trainer(gpus=1)\n\nlr_finder = trainer.tuner.lr_find(plant_model,train_dataloader=train_dataloader)\n\nfig = lr_finder.plot(suggest=True)\nfig.show()\n\n\nprint(lr_finder.suggestion())\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%load_ext tensorboard\n%tensorboard --logdir logs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plant_model = PlantModel()\nlogger = TensorBoardLogger('tb_logs', name='my_model')\n\n\ntrainer = pl.Trainer(gpus=1, max_epochs=3, progress_bar_refresh_rate=20,logger=logger)\n\ntrainer.fit(plant_model, train_dataloader,val_dataloader)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}