{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import cv2\nfrom collections import defaultdict\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom pathlib import Path\nfrom PIL import Image, ImageOps\nimport sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\nimport timm\nimport torch\nfrom torch.nn.functional import softmax\nfrom torch.utils.data import Dataset, DataLoader\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nfrom albumentations import Compose, OneOf\nfrom albumentations.augmentations.transforms import *\nfrom albumentations.pytorch.transforms import ToTensorV2 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"repeat_preds = 2\ninput_size = (512, 512)\ntest_img_path = '../input/cassava-leaf-disease-classification/test_images'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_fnames = [\n    #'../input/cassava-notebook-34-model/effnet_epoch_12.pickle', # valid acc 0.8924485125858124 \n    #'../input/cassava-run-1612850859606531-model/effnet_epoch_19.pickle',\n    # Removing this model - was trained on an old version of the transforms\n    #'../input/cassava-final-ensemble-models/train_2021-02-12_18-03-44_model_epoch_10.pickle', # valid acc 0.8826849733028223\n    #'../input/cassava-final-ensemble-models/train_2021-02-12_10-12-59_model_epoch_8.pickle', # valid acc 0.8858886346300534\n    '../input/cassava-final-ensemble-models/train_2021-02-14_10-23-02_model_epoch_9.pickle', # valid acc 0.8987032799389779\n    '../input/cassava-final-ensemble-models/train_2021-02-14_21-33-31_model_epoch_11.pickle', # valid acc 0.8994660564454615\n    '../input/cassava-final-ensemble-models/train_2021-02-15_21-38-02_model_epoch_9.pickle', # valid acc 0.8890922959572846\n    #'../input/cassava-final-ensemble-models/train_2021-02-17_11-31-19_model_epoch_8.pickle', # valid acc 0.883905415713196\n    '../input/cassava-train-20210217-214040-model-epoch-14/train_2021-02-17_21-40-40_model_epoch_14.pickle' # valid acc 0.8903127383676582\n]\nmodels = [torch.load(x) \n          for x in model_fnames]\nmodels = [x.to(device) for x in models]\nmodels = [x.eval() for x in models]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_files = [x for x in Path('../input/cassava-leaf-disease-classification/test_images').iterdir()\n                 if x.is_file()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_tfms_rrc = Compose([\n    RandomResizedCrop(\n                *input_size,\n                always_apply=True, scale=(.75, 1.0),\n                interpolation=cv2.INTER_CUBIC,\n                ratio=(1, 1),\n                p=1.0),\n    Rotate(limit=[-45, 45], interpolation=cv2.INTER_LANCZOS4),\n    Transpose(),\n    Flip(),\n    Normalize(),\n    ToTensorV2()\n])\n\ntest_tfms_cc = Compose([\n    Rotate(limit=[-45, 45], interpolation=cv2.INTER_LANCZOS4, p=0.3),\n    CenterCrop(\n            *input_size,\n            always_apply=True,\n            p=1.0),\n    #Transpose(),\n    Flip(),\n    Normalize(),\n    ToTensorV2()\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_list = defaultdict(list)\npredictions_agg = {}\n\nfor filepath in predict_files:\n    image_id = filepath.name\n    pimage = Image.open(filepath).convert('RGB')\n    image = np.array(pimage)\n    \n    # Predict on images using rrc\n    for model in models:\n        image_rrc = test_tfms_rrc(image=image)['image'] # image image image\n        image_expand = torch.unsqueeze(image_rrc, axis=0).to(device)\n        with torch.no_grad():\n            out = model(image_expand)\n            distribution = softmax(out, dim=1)\n            predictions_list[image_id].append(distribution)\n    \n\n    # Predict on images using center crop with presizing to 600\n    image_rs = cv2.resize(image, (600, 600), cv2.INTER_CUBIC)\n    for _ in range(repeat_preds):\n        for model in models:\n            image_cc = test_tfms_cc(image=image_rs)['image'] # image image image\n            image_expand = torch.unsqueeze(image_cc, axis=0).to(device)\n            with torch.no_grad():\n                out = model(image_expand)\n                distribution = softmax(out, dim=1)\n                predictions_list[image_id].append(distribution)\n            \nfor image_id, prediction_list in predictions_list.items():\n    pred = torch.stack(prediction_list).sum(axis=0).cpu().numpy()\n    print(image_id, pred)\n    predictions_agg[image_id] = np.argmax(pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('submission.csv', 'w+') as submission:\n    submission.write('image_id,label\\n')\n    for img_id, prediction in predictions_agg.items():\n        submission.write(f'{img_id},{prediction}\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!cat submission.csv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}