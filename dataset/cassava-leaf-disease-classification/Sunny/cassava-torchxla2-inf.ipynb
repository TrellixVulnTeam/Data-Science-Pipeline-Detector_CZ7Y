{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"package_path = '../input/timm-pytorch-image-models/pytorch-image-models-master'\nimport sys; sys.path.append(package_path)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import gc\nimport os\nimport time\nimport torch\nimport albumentations\n\nimport numpy as np\nimport pandas as pd\n\nimport cv2\nfrom PIL import Image\n\nimport torch.nn as nn\nfrom sklearn import metrics\nfrom sklearn import model_selection\nfrom torch.nn import functional as F\nfrom torch.optim import Adam\n\nimport timm\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"class TimmModels(nn.Module):\n    def __init__(self, model_name, pretrained=True, num_classes=5):\n        super(TimmModels, self).__init__()\n        self.m = timm.create_model(model_name, pretrained=pretrained)\n        model_list = list(self.m.children())\n        model_list[-1] = nn.Linear(in_features=model_list[-1].in_features,\n                                   out_features=num_classes,\n                                   bias=True\n                                  )\n        self.m = nn.Sequential(*model_list)\n        \n    def forward(self, image):\n        out = self.m(image)\n        return out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FLAGS = {'fold':0,\n         'model':'resnext50_32x4d',\n         'pretrained': True,\n         'batch_size':8,\n         'num_workers':4,\n         'lr':3e-4,\n         'epochs':10,\n         'device':'cuda:0'\n        }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ImageDataset:\n    def __init__(self,\n                 image_paths,\n                 targets,\n                 resize,\n                 augmentations=None,\n                 backend='pil',\n                 channel_first=True\n                ):\n        \"\"\"\n        :param image_paths: list of paths to images\n        :param targets: numpy array\n        :param resize: tuple or None\n        :param augmentations: albumentations augmentations\n        \"\"\"\n        \n        self.image_paths = image_paths\n        self.targets = targets\n        self.resize = resize\n        self.augmentations = augmentations\n        self.backend = backend\n        self.channel_first = channel_first\n        \n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, item):\n        targets = self.targets[item]\n        \n        if self.backend == 'pil':\n            image = Image.open(self.image_paths[item])\n            \n            if self.resize is not None:\n                image = image.resize((self.resize[1], self.resize[0]),\n                                     resample=Image.BILINEAR\n                                    )\n                \n            image = np.array(image)\n            \n            if self.augmentations is not None:\n                augmented = self.augmentations(image=image)\n                image = augmented['image']\n                \n        elif self.backend == 'cv2':\n            image = cv2.imread(self.image_paths[item])\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n            \n            if self.resize is not None:\n                image = cv2.resize(image, \n                                   (self.resize[1], self.resize[0]),\n                                   interpolation=cv2.INTER_CUBIC\n                                  )\n                \n            if self.augmentations is not None:\n                augmented = self.augmentations(image=image)\n                \n            image = augmented['image']\n            \n        else:\n            raise Exception(\"Backend not implemented\")\n            \n        if self.channel_first:\n            image = np.transpose(image, (2,0,1)).astype(np.float32)\n            \n        return {\"image\":torch.tensor(image),\n                \"targets\":torch.tensor(targets)\n               }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TEST_PATH = '../input/cassava-leaf-disease-classification/test_images/'\n\ntest_images = os.listdir(TEST_PATH)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_images = [\n    os.path.join(TEST_PATH, i) for i in test_images\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_images","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_targets = [-1 for i in range(len(test_images))]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean = (0.485, 0.456, 0.406)\nstd = (0.229, 0.224, 0.225)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_aug = albumentations.Compose(\n    [\n        albumentations.Normalize(\n            mean,\n            std,\n            max_pixel_value=255.0,\n            always_apply=True\n        )\n    ]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataset = ImageDataset(\n    image_paths=test_images,\n    targets=test_targets,\n    resize=None,\n    augmentations=valid_aug\n)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_loader = torch.utils.data.DataLoader(\n    test_dataset,\n    batch_size=FLAGS['batch_size'],\n    num_workers=FLAGS['num_workers'],\n    drop_last=False,\n    shuffle=False\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = TimmModels(\n    FLAGS['model'],\n    pretrained=False,\n    num_classes=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_state_dict(torch.load('../input/cassava-torchxla2-model/xla_trained_model_10_epochs_fold_0.pth'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = FLAGS['device']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def infer(data_loader, \n          model, \n          device):\n    \n    fin_targets = []\n    fin_outputs = []\n    \n    for bi, d in enumerate(data_loader):\n        \n        images = d['image'].to(device)\n        targets = d['targets'].to(device)\n        \n        with torch.no_grad(): outputs = model(images)\n            \n        #targets_np = targets.cpu().detach().numpy().tolist()\n        outputs_np = outputs.cpu().detach().numpy().tolist()\n        \n        #fin_targets.extend(targets_np)\n        fin_outputs.extend(outputs_np)\n        \n        del outputs_np\n        \n        gc.collect()\n        \n    return fin_outputs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = infer(test_loader, model, device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.DataFrame()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['image_id'] = list(os.listdir(TEST_PATH))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['label'] = np.argmax(predictions, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample = pd.read_csv('../input/cassava-leaf-disease-classification/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample['image_id']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample['label']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['label']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['image_id']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train_images, train_targets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images = list(os.listdir('../input/cassava-leaf-disease-classification/train_images'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_data_path = '../input/cassava-leaf-disease-classification/train_images'\ntrain_images = [\n    os.path.join(training_data_path, i) for i in train_images\n]\n\ntrain_targets = [-1 for i in range(len(train_images))]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_images=train_images[0:15000]\nvalid_targets=train_targets[0:15000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_dataset = ImageDataset(\n    image_paths=valid_images,\n    targets=valid_targets,\n    resize=None,\n    augmentations=valid_aug\n)\n\nvalid_loader = torch.utils.data.DataLoader(\n    valid_dataset,\n    batch_size=FLAGS['batch_size'],\n    num_workers=FLAGS['num_workers'],\n    drop_last=False,\n    shuffle=False\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predictions = infer(valid_loader, model, device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list(os.listdir('../input/cassava-leaf-disease-classification/train_images'))[0:15000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_images","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}