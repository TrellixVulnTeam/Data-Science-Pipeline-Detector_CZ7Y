{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!pip install efficientnet_pytorch\nfrom prettytable import PrettyTable\n\ndef count_parameters(model):\n    table = PrettyTable([\"Modules\", \"Parameters\"])\n    total_params = 0\n    for name, parameter in model.named_parameters():\n        if not parameter.requires_grad: continue\n        param = parameter.numel()\n        table.add_row([name, param])\n        total_params+=param\n    print(table)\n    print(f\"Total Trainable Params: {total_params}\")\n    return total_params","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch.nn import functional as F\nimport cv2\nimport numpy as np\nimport time\nimport random\nfrom tqdm import tqdm_notebook as tqdm\nimport pandas as pd\nimport os\n\nfrom torchvision import models\n\nfrom torch.utils.data import DataLoader,Dataset\nfrom torchvision import transforms\nfrom albumentations.pytorch import ToTensorV2\n\nfrom albumentations import (\n    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, CenterCrop, Resize\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#parameters\ntrain_dir= '../input/cassava-leaf-disease-classification/train_images'\ntest_dir = '../input/cassava-leaf-disease-classification/test_images'\ncfg = {\n    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n    'epochs':30,\n    'batch_size':42,\n    'lr':0.0001,\n    'input_size':256,\n    \n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imagenames = [name for name in os.listdir(train_dir)]\ncsv = pd.read_csv('../input/cassava-leaf-disease-classification/train.csv')\nprint(csv.head(10))\nprint(csv['label'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_train_transforms():\n    return Compose([\n            RandomResizedCrop(cfg['input_size'], cfg['input_size']),\n            Transpose(p=0.5),\n            HorizontalFlip(p=0.5),\n            VerticalFlip(p=0.5),\n            ShiftScaleRotate(p=0.5),\n            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.2),\n            RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n        ], p=1.)\n\ndef get_valid_transforms():\n    return Compose([\n            CenterCrop(cfg['input_size'], cfg['input_size'], p=1.),\n            Resize(cfg['input_size'], cfg['input_size']),\n        ], p=1.)\n\n\ndef normalize_and_to_tensor(img):\n    transform = Compose([Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n                       ToTensorV2(p=1.0)],p=1.0)\n    return transform(image=img)['image']\n\nclass CASSAVA(Dataset):\n    def __init__(self,\n                 imagenames,\n                 csv,\n                 root_dir,\n                 input_size=cfg['input_size'],\n                 transforms=None,\n                 train=True):\n        self.imagenames = imagenames\n        self.csv = csv\n        self.root_dir = root_dir\n        self.input_size = input_size\n        self.transforms = transforms\n        self.train = train\n    def __len__(self):\n        return len(self.imagenames)\n    def get_onehot(self,label):\n        onehot = np.zeros(5)\n        onehot[label] = 1\n        return onehot\n    def __getitem__(self,idx):\n        imagename = self.imagenames[idx]\n        label = self.csv[self.csv['image_id']==imagename]['label']\n        label = self.get_onehot(label)\n        image = cv2.imread(self.root_dir+'/'+imagename)\n        image = cv2.resize(image,(self.input_size,self.input_size))\n        if self.transforms is not None:\n            image_aug = self.transforms(image=image)['image']\n        else:\n            image_aug = image\n        image_aug = normalize_and_to_tensor(image_aug)\n        label = torch.from_numpy(label)\n        return image_aug,label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transforms = get_train_transforms()\nt_dataset = CASSAVA(imagenames[300:],csv,train_dir,transforms = train_transforms)\ntrain_loader = DataLoader(dataset=t_dataset, batch_size=cfg['batch_size'], shuffle=True, num_workers=2)\n\nvalid_transforms = get_valid_transforms()\nv_dataset = CASSAVA(imagenames[:300],csv,train_dir,transforms = valid_transforms)\nvalid_loader = DataLoader(dataset=v_dataset, batch_size=cfg['batch_size'], shuffle=False, num_workers=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"backbone = models.resnet50(pretrained=False)\nmodules = list(backbone.children())[:-2]\nbackbone = nn.Sequential(*modules)\nprint(backbone)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nclass BACKBONE(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.effn = backbone\n        self.average = nn.AvgPool2d((8,8))\n        self.flatten = nn.Flatten()        \n    def forward(self,x):\n        x = self.effn(x)\n        x = self.average(x)\n        x = self.flatten(x)\n        #x = F.relu(self.projection(x))\n        return x\n    \nclass MLP(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.dense1 = nn.Linear(2048,1024)\n        self.dense2 = nn.Linear(1024,5)\n    def forward(self,X):\n        X = F.relu(self.dense1(X))\n        return self.dense2(X)\n\nclass CLASSIFIER(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.backbone = BACKBONE()\n        self.backbone.load_state_dict(torch.load('../input/simsaim-weights/I_am_trained_14.pt',map_location='cpu'))\n        self.mlp = MLP()\n    def forward(self,X):\n        X = self.backbone(X)\n        X = self.mlp(X)\n        return F.softmax(X,dim=-1)\n    \nmodel = CLASSIFIER()\nmodel.to(cfg['device'])\nx = torch.randn((1,3,cfg['input_size'],cfg['input_size']))\nx = x.to(cfg['device'])\n\ny = model(x)\nprint(y.size())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Loss(y_true,y_pred):\n    l = -y_true*((1-y_pred)**4.0)*torch.log(y_pred)\n    l = torch.sum(l,axis=-1)\n    return l","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters(), lr=cfg['lr'])\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10, verbose=True)\nmodel.to(cfg['device'])\n\nfor epoch in range(cfg['epochs']):\n    \n    #epoch parameters\n    epoch_loss = 0\n    model.train()\n\n    start = time.time()\n    \n    for i,(image1,label) in enumerate(tqdm(train_loader,total=train_loader.__len__(),ncols = 500)):\n        \n        image1 = image1.to(cfg['device'])\n        label = label.to(cfg['device'])\n        \n        #represent\n        scores = model(image1)\n   \n        #Focal Loss\n        loss = Loss(label,scores)\n        \n        #backprop\n        optimizer.zero_grad()\n        loss.mean().backward()\n        optimizer.step()\n        \n        epoch_loss+=loss.mean().item()\n    \n\n    scheduler.step(epoch_loss/(i+1))\n    print('Epoch {:03}: | Loss: {:.3f} | Training time: {}'.format(\n            epoch + 1, \n            epoch_loss/(i+1), \n            str(time.time() - start)[:7],\n    torch.save(model.state_dict(), 'trained_{}.pt'.format(epoch))))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''    #validation\n    model.eval()\n    final_acc = 0\n    count=0\n    for image,labels in tqdm(valid_loader,total=valid_loader.__len__(),ncols=500):\n        image1 = image.to(cfg['device'])\n        scores = model(image1)\n        preds = scores.max(dim=-1)[0].detach().cpu().numpy()\n        labels = labels.max(dim=-1)[0].detach().cpu().numpy()\n        acc = np.sum(preds==labels)\n        print(acc,labels.shape[0])\n        final_acc+=acc\n        count+=labels.shape[0]'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"510*42","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}