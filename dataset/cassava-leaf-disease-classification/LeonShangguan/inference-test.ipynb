{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"package_paths = ['../input/imgclsmob/imgclsmob-master', \n                '../input/efficientnetpytorch/EfficientNet-PyTorch-master', \n                '../input/timm-pytorch-image-models/pytorch-image-models-master']\nimport sys\nfor package_path in package_paths:\n    sys.path.append(package_path)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport torch\nimport random\nfrom albumentations import *\nfrom albumentations.pytorch import ToTensorV2\nfrom torch.utils.data import Dataset, DataLoader\nimport timm\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom efficientnet_pytorch import EfficientNet\nfrom pytorch.pytorchcv.model_provider import get_model as ptcv_get_model\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CasDataset(Dataset):\n\n    def __init__(self, df, path, transforms):\n        self.df = df\n        self.path = path\n        self.transforms = transforms\n\n    def __len__(self):\n        return self.df.shape[0]\n\n    def __getitem__(self, idx):\n        image = cv2.imread(self.path+self.df.loc[idx, 'image_id'])\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        if self.transforms:\n            transformed = self.transforms(image=image)\n            image = transformed['image']\n\n        return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CasModel(nn.Module):\n\n    def __init__(self, num_classes=5, model=\"resnet34\"):\n        super().__init__()\n\n        if model == \"resnet16\":\n            self.backbone = ptcv_get_model(\"resnet16\", pretrained=False)\n            self.backbone.features.final_pool = nn.AdaptiveAvgPool2d(1)\n            self.backbone.output = nn.Sequential(nn.Linear(512, num_classes))\n        elif model == \"resnet34\":\n            self.backbone = ptcv_get_model(\"resnet34\", pretrained=False)\n            self.backbone.features.final_pool = nn.AdaptiveAvgPool2d(1)\n            self.backbone.output = nn.Sequential(nn.Linear(512, num_classes))\n        elif model == \"efficientnet-b2\":\n            self.backbone = EfficientNet.from_pretrained(\"efficientnet-b2\")\n            self.backbone._fc = nn.Linear(self.backbone._fc.in_features, num_classes)\n        elif model == \"efficientnet-b4\":\n            self.backbone = EfficientNet.from_pretrained(\"efficientnet-b4\")\n            self.backbone._fc = nn.Linear(self.backbone._fc.in_features, num_classes)\n        elif model == \"efficientnet-b7\":\n            self.backbone = EfficientNet.from_pretrained(\"efficientnet-b7\")\n            self.backbone._fc = nn.Linear(self.backbone._fc.in_features, num_classes)\n        elif model == \"vit-b\":\n            self.backbone = timm.create_model(\"vit_base_patch16_384\", pretrained=False)\n            self.backbone.head = nn.Linear(self.backbone.head.in_features, num_classes)\n        elif model == \"vit-l\":\n            self.backbone = timm.create_model(\"vit_large_patch16_384\", pretrained=False)\n            self.backbone.head = nn.Linear(self.backbone.head.in_features, num_classes)\n        elif model == \"vit-r\":\n            self.backbone = timm.create_model(\"vit_base_resnet50d_224\", pretrained=False)\n            self.backbone.head = nn.Linear(self.backbone.head.in_features, num_classes)\n        elif model == \"efficientnet-b4-timm\":\n            self.backbone = timm.create_model(\"tf_efficientnet_b4_ns\", pretrained=False)\n            self.backbone.classifier = nn.Linear(self.backbone.classifier.in_features, num_classes)\n        else:\n            raise NotImplementedError\n\n    def forward(self, x):\n        x = self.backbone(x)\n        # x = F.sigmoid(x)\n\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def inference_one_epoch(model, data_loader, device):\n    model.eval()\n\n    image_preds_all = []\n    \n    for step, (imgs) in enumerate(data_loader):\n        imgs = imgs.to(device).float()\n        \n        image_preds = model(imgs)   #output = model(input)\n        image_preds_all += [torch.softmax(image_preds, 1).detach().cpu().numpy()]\n        \n    \n    image_preds_all = np.concatenate(image_preds_all, axis=0)\n    return image_preds_all","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tta = 12\nIMAGE_SIZE = 512\n\nif tta > 1:\n    transforms_test = Compose([\n            CenterCrop(IMAGE_SIZE, IMAGE_SIZE, p=1.0),\n#             Resize(IMAGE_SIZE, IMAGE_SIZE, p=1.0),\n#             Resize(IMAGE_SIZE, IMAGE_SIZE, p=1.),\n            HorizontalFlip(p=0.5),\n            VerticalFlip(p=0.5),\n            Transpose(p=0.5),\n#             RandomBrightnessContrast(brightness_limit=(-0.1, 0.1),\n#                                      contrast_limit=(-0.1, 0.1),\n#                                      p=0.5),\n            Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n                max_pixel_value=255.0,\n                p=1.0\n            ),\n            ToTensorV2(p=1.0),\n        ])\nelse:\n    transforms_test = Compose([\n            CenterCrop(IMAGE_SIZE, IMAGE_SIZE, p=1.0),\n            Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n                max_pixel_value=255.0,\n                p=1.0\n            ),\n            ToTensorV2(p=1.0),\n        ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seed_everything(960630)\n\ntest_df = pd.DataFrame()\ntest_df['image_id'] = list(os.listdir('../input/cassava-leaf-disease-classification/test_images/'))\ntest_data = CasDataset(test_df, '../input/cassava-leaf-disease-classification/test_images/', transforms_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_loader = DataLoader(\n                test_data, \n                batch_size=32,\n                num_workers=8,\n                shuffle=False,\n                pin_memory=False,\n            )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds = []\ndevice = torch.device('cuda:0')\nmodel = CasModel(model=\"resnet34\").to(device)\n\nfor fold in range(5):\n    model.load_state_dict(torch.load(f'../input/casresnet34/resnet34_f_{fold}.pth'))\n\n    with torch.no_grad():\n        for t in range(tta):\n            test_preds += [inference_one_epoch(model, test_loader, device)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds = np.mean(test_preds, axis=0) \ntest_df['label'] = np.argmax(test_preds, axis=1)\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}