{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!/opt/conda/bin/python3.7 -m pip install --upgrade pip\n! pip install -q efficientnet","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers\nimport os\nimport re\nimport math\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom kaggle_datasets import KaggleDatasets\nimport efficientnet.tfkeras as efn\nimport json\nimport csv\ntf.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GCS_DS_PATH = KaggleDatasets().get_gcs_path('cassava-leaf-disease-classification')\nGCS_DS_PATH","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f = open(\"../input/cassava-leaf-disease-classification/label_num_to_disease_map.json\",\"r\")\ndisease_names = json.load(f)\ndisease_names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() \n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMAGE_SIZE = [300,300]\nAUTO = tf.data.experimental.AUTOTUNE\nCLASSES = 5\nCHANNELS=3\n\nFILENAMES = tf.io.gfile.glob(GCS_DS_PATH + '/train_tfrecords/*.tfrec')\nTRAINING_FILENAMES = FILENAMES[:-2]\nVALIDATION_FILENAMES = FILENAMES[-2:]\nTEST_FILENAMES = tf.io.gfile.glob(GCS_DS_PATH + '/test_tfrecords/*.tfrec')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_dict={}\nwith open(\"../input/cassava-leaf-disease-classification/train.csv\") as file:\n    reader = csv.reader(file,skipinitialspace=True)\n    next(reader)\n    for row in reader:\n        count_dict[row[1]]=count_dict.get(row[1],0)+1\n        \nsamples_ls = list(count_dict.values())\ntot_samples = sum(samples_ls)\nclass_weights={}\nfor i in range(5):\n    class_weights[i] = tot_samples/(CLASSES*samples_ls[i])\n    \nclass_weights","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0 \n    image = tf.image.resize(image, [*IMAGE_SIZE])\n    return image\n\n\ndef read_labeled_tfrecord(example):\n    LABELED_TFREC_FORMAT = {\n        \"image\"              : tf.io.FixedLenFeature([], tf.string),\n        \"target\"              : tf.io.FixedLenFeature([], tf.int64),\n    }\n    \n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    label = example[\"target\"]\n    label = tf.one_hot(label,depth=5)\n    label = tf.cast(label,tf.float32)\n    return image, label\n\n\ndef read_unlabeled_tfrecord(example):\n    UNLABELED_TFREC_FORMAT = {\n        \"image\"              : tf.io.FixedLenFeature([], tf.string),\n        \"image_name\"           : tf.io.FixedLenFeature([], tf.string),\n    }\n    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    idnum = example['image_name']\n    return image, idnum\n\ndef load_dataset(filenames, labeled=True, ordered=False):\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False \n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) \n    dataset = dataset.with_options(ignore_order)\n    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord, num_parallel_calls=AUTO)\n    return dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def data_augment(image, label):\n    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_pixel_1 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_pixel_2 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_pixel_3 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n            \n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    \n    if p_spatial > .75:\n        image = tf.image.transpose(image)\n        \n    if p_rotate > .75:\n        image = tf.image.rot90(image, k=3)\n    elif p_rotate > .5:\n        image = tf.image.rot90(image, k=2) \n    elif p_rotate > .25:\n        image = tf.image.rot90(image, k=1)\n        \n    if p_pixel_1 >= .4:\n        image = tf.image.random_saturation(image, lower=.9, upper=1.1)\n    if p_pixel_2 >= .4:\n        image = tf.image.random_contrast(image, lower=.8, upper=1.2)\n    if p_pixel_3 >= .4:\n        image = tf.image.random_brightness(image, max_delta=.1)\n        \n    if p_crop > .7:\n        if p_crop > .9:\n            image = tf.image.central_crop(image, central_fraction=.7)\n        elif p_crop > .8:\n            image = tf.image.central_crop(image, central_fraction=.8)\n        else:\n            image = tf.image.central_crop(image, central_fraction=.9)\n    elif p_crop > .4:\n        crop_size = tf.random.uniform([], int(IMAGE_SIZE[0]*.8),IMAGE_SIZE[0], dtype=tf.int32)\n        image = tf.image.random_crop(image, size=[crop_size, crop_size, CHANNELS])\n    \n    image = tf.image.resize(image, [*IMAGE_SIZE])\n    return image,label\n\ndef get_training_dataset():\n    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n    dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n    dataset = dataset.repeat() \n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\ndef get_validation_dataset(ordered=False):\n    dataset = load_dataset(VALIDATION_FILENAMES, labeled=True, ordered=ordered)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.cache()\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\ndef get_test_dataset(ordered=False):\n    dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\ndef count_data_items(filenames):\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)\n\nNUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\nNUM_VALIDATION_IMAGES = count_data_items(VALIDATION_FILENAMES)\nNUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\nprint('Dataset: {} training images, {} validation images, {} unlabeled test images'.format(NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES, NUM_TEST_IMAGES))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n\ntrain_ds = get_training_dataset()\nvalid_ds = get_validation_dataset()\ntest_ds = get_test_dataset()\n\nprint(\"Training:\", train_ds)\nprint(\"Validation:\",valid_ds)\nprint(\"Test:\", test_ds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Training data shapes:\")\nfor image, label in train_ds.take(3):\n    print(image.numpy().shape, label.numpy().shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Test data shapes:\")\nfor image, idnum in test_ds.take(3):\n    print(image.numpy().shape, idnum.numpy().shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''2 : efn.EfficientNetB2(weights=\"imagenet\",include_top=False ,input_shape=[*IMAGE_SIZE, 3]),\n        3 : tf.keras.applications.EfficientNetB3(weights=\"imagenet\",include_top=False ,input_shape=[*IMAGE_SIZE, 3]),\n        4 : tf.keras.applications.EfficientNetB4(weights=\"imagenet\",include_top=False ,input_shape=[*IMAGE_SIZE, 3]),\n        5 : tf.keras.applications.EfficientNetB5(weights=\"imagenet\",include_top=False ,input_shape=[*IMAGE_SIZE, 3]),\n        6 : tf.keras.applications.EfficientNetB6(weights=\"imagenet\",include_top=False ,input_shape=[*IMAGE_SIZE, 3]),\n        7 : tf.keras.applications.EfficientNetB7(weights=\"imagenet\",include_top=False ,input_shape=[*IMAGE_SIZE, 3]),\n        8 : tf.keras.applications.Xception(include_top=False, weights='imagenet',input_shape=[*IMAGE_SIZE, 3]),\n        9 : tf.keras.applications.ResNet50(include_top=False, weights='imagenet',input_shape=[*IMAGE_SIZE, 3]),\n        10: tf.keras.applications.ResNet101(include_top=False, weights='imagenet',input_shape=[*IMAGE_SIZE, 3]),\n        11: tf.keras.applications.ResNet152(include_top=False, weights='imagenet',input_shape=[*IMAGE_SIZE, 3])'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model():\n    efficient_net = {\n        0 : tf.keras.applications.EfficientNetB0(weights=\"imagenet\",include_top=False ,input_shape=[*IMAGE_SIZE, 3]),\n        1 : tf.keras.applications.EfficientNetB1(weights=\"imagenet\",include_top=False ,input_shape=[*IMAGE_SIZE, 3]),\n    }\n\n    output = {}\n    inputs = tf.keras.Input(shape=(*IMAGE_SIZE, 3))\n    \n    ls =   [0,1]      #[3,5,7]  \n    \n    '''\n    for net in efficient_net.values():\n        for layer in net.layers[1:]:\n            layer.name =  \"layer_\"+str(i)\n            i+=1'''\n    \n    \n    \n    \n    for i in ls:\n        pretrained_model = efficient_net[i]\n        x = pretrained_model(inputs)\n        x = tf.keras.layers.GlobalAveragePooling2D(name = \"average_\"+str(i))(x)\n        output[i] = tf.keras.layers.Dense(CLASSES,activation=\"sigmoid\", dtype='float32',name=\"dense_\"+str(i))(x)\n        del x,pretrained_model\n\n    \n    outputs = tf.keras.layers.average(list(output.values()))\n    model = tf.keras.Model(inputs, outputs)\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = create_model()\nmodel.save('trial.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def compile_model(model, lr=0.0001):\n    \n    optimizer = tf.keras.optimizers.Adam(lr=lr)\n    \n    loss = tf.keras.losses.CategoricalCrossentropy()\n        \n    metrics = [\n       tf.keras.metrics.CategoricalAccuracy(name='categorical_accuracy')\n    ]\n\n    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n    print('Compiled! ')\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.models.load_model('trial.h5')\nmodel = compile_model(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_callbacks():\n    \n    cpk_path = './best_model.h5'\n    \n    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n        filepath=cpk_path,\n        monitor='val_categorical_accuracy',\n        mode='max',\n        save_best_only=True,\n        save_weights_only = True, #Saving weights only. \n                                  #You will need to create model again\n                                  #wherever you need to predict from it.\n        verbose=1,\n    )\n\n    reducelr = tf.keras.callbacks.ReduceLROnPlateau(\n        monitor='val_categorical_accuracy',\n        mode='max',\n        factor=0.1,\n        patience=3,\n        verbose=0\n    )\n\n    earlystop = tf.keras.callbacks.EarlyStopping(\n        monitor='val_categorical_accuracy',\n        mode='max',\n        patience=15, \n        verbose=1\n    )\n    \n    callbacks = [checkpoint, reducelr, earlystop]         \n    \n    return callbacks","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS= 3\nVERBOSE =1\n\nSTEPS_PER_EPOCH = NUM_TRAINING_IMAGES//(BATCH_SIZE)\n\ntf.keras.backend.clear_session()\nwith strategy.scope():\n    \n    model = create_model()\n    model = compile_model(model, lr=0.0001)\n   \n    callbacks = create_callbacks()\n    \n    history = model.fit(train_ds, \n                        epochs=EPOCHS,\n                        callbacks=callbacks,\n                        validation_data = valid_ds,\n                        steps_per_epoch = STEPS_PER_EPOCH,\n                        verbose=VERBOSE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2 = create_model()\n\nmodel2.load_weights('./best_model.h5')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2.predict(test_ds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history.history['categorical_accuracy']\nval_acc = history.history['val_categorical_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs_range = range(len(history.history['val_loss']))\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Categorical Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Categorical Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Categorical Accuracy')\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}