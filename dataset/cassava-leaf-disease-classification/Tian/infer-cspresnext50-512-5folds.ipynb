{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install ../input/timm034/timm-0.3.4-py3-none-any.whl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#!python ../input/ttach-master/setup.py install","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import time\nimport os\nimport timm\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.utils.data.sampler import SubsetRandomSampler, RandomSampler, SequentialSampler\n#from efficientnet_pytorch import model as enet\nimport albumentations\nfrom albumentations.pytorch import ToTensorV2\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\n#import ttach as tta","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Config"},{"metadata":{"trusted":true},"cell_type":"code","source":"image_folder = '../input/cassava-leaf-disease-classification/test_images/'\n\nenet_type = 'cspresnext50'\nimage_size = 512\nbatch_size = 4\nnum_workers = 4\nout_dim = 5\n\ndevice = torch.device('cuda')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"ls ../input/cdl-cspresnext50-512/ ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_pths = [\n    '../input/cdl-cspresnext50-512/light_best_model_fold0.pth',\n    '../input/cdl-cspresnext50-512/light_best_model_fold1.pth',\n    '../input/cdl-cspresnext50-512/light_best_model_fold2.pth',\n    '../input/cdl-cspresnext50-512/light_best_model_fold3.pth',\n    '../input/cdl-cspresnext50-512/light_best_model_fold4.pth',\n            ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class net(nn.Module):\n    def __init__(self, model_name=enet_type, pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained)\n        \n        n_features = self.model.head.fc.in_features\n        self.model.head.fc = nn.Linear(n_features, 5)\n\n    def forward(self, x):\n        output = self.model(x)\n        return output","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"class LEAFDataset(Dataset):\n    def __init__(self, folder, transforms=None):\n\n        self.file_names = os.listdir(folder)\n        self.transforms = transforms\n\n    def __len__(self):\n        return len(self.file_names)\n\n    def __getitem__(self, index):\n        image_id = self.file_names[index]\n        \n        image_file = os.path.join(image_folder, image_id)\n        image = cv2.imread(image_file)\n        image = image[:, :, ::-1]\n\n        if self.transforms is not None:\n            image = self.transforms(image=image)['image']\n\n        return image, image_id","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Augmentations"},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = albumentations.Compose([\n    albumentations.Resize(image_size, image_size),\n    albumentations.Normalize(),\n    ToTensorV2()\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ====================================================\n# inference\n# ====================================================\n\nres = []\nfor model_pth in model_pths:\n    model = net(enet_type)\n    model.load_state_dict(torch.load(model_pth))\n    model.eval()\n    model.to(device)\n    \n    test_dataset = LEAFDataset(image_folder, transforms=transform)\n    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers)\n\n    single_model_probs = []\n    image_ids_list = []\n    with torch.no_grad():\n        for idx, (images, image_ids) in enumerate(tqdm(test_loader)):\n            outputs = model(images.to(device))\n            pred = outputs.detach().softmax(1).cpu().numpy()\n            single_model_probs.append(pred)\n            image_ids_list.append(image_ids)\n#             if idx == 5:\n#                 break\n        \n    single_model_probs = np.concatenate(single_model_probs)\n    image_ids_list = np.concatenate(image_ids_list)\n    res.append(single_model_probs)\n    \n    del model\n    torch.cuda.empty_cache()\n    \nres = sum(res) / len(model_pths)\nprobs = res.argmax(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.DataFrame({'image_id': image_ids_list, 'label': probs});sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}