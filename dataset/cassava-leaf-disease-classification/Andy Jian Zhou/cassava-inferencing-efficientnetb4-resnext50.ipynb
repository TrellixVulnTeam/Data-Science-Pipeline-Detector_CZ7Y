{"cells":[{"metadata":{"papermill":{"duration":0.008279,"end_time":"2021-02-04T15:41:22.679928","exception":false,"start_time":"2021-02-04T15:41:22.671649","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Inference notebook (only for submissions)"},{"metadata":{"papermill":{"duration":29.095695,"end_time":"2021-02-04T15:41:51.782761","exception":false,"start_time":"2021-02-04T15:41:22.687066","status":"completed"},"tags":[],"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"!pip install ../input/efficientnet-pytorch\n!pip install \"../input/pretrained-models/pretrained-models.pytorch-master\"\n","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":3.128746,"end_time":"2021-02-04T15:41:54.922039","exception":false,"start_time":"2021-02-04T15:41:51.793293","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"from fastai.vision.all import *\nfrom efficientnet_pytorch import EfficientNet\nimport albumentations\nfrom albumentations.pytorch import ToTensorV2\n#import torchvision.models as pretrainedmodels","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission setup\n\nCreating paths and CFG for use"},{"metadata":{"trusted":true},"cell_type":"code","source":"class SubmissionConfig:\n    n_tta       = 1\n    beta        = 0.25\n    models      = ['model-f0.pkl', 'model-f1.pkl', 'model-f2.pkl', 'model-f3.pkl', 'model-f4.pkl']\n    \ncfg = SubmissionConfig()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","papermill":{"duration":0.028063,"end_time":"2021-02-04T15:41:54.959678","exception":false,"start_time":"2021-02-04T15:41:54.931615","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# this is only for submissions\npath_str = '../input/cassava-leaf-disease-classification'\n\nsubmission_df = pd.read_csv(f'{path_str}/sample_submission.csv')\n\nmodels_path = '../input/effnetmodels/'\ntest_images_path = f'{path_str}/test_images/'\ntest_data_path = submission_df['image_id'].apply(lambda x: test_images_path+x)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ALL COMBINED[](http://)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from albumentations import (\n    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, CenterCrop, Resize\n)\nfrom albumentations.pytorch import ToTensorV2\n\n\nall_album = [albumentations.Resize(512,512),albumentations.Transpose(p=1.),albumentations.HorizontalFlip(p=1.),\n            albumentations.VerticalFlip(p=1.),\n            albumentations.HueSaturationValue(\n                hue_shift_limit=0.2, \n                sat_shift_limit=0.2, \n                val_shift_limit=0.2, \n                p=1.\n            ), albumentations.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(all_album)-1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## For Efficient Net"},{"metadata":{"trusted":true},"cell_type":"code","source":"final_predictions = 0\nfor i in range(6):\n    class AlbumentationsTransform(RandTransform):\n        split_idx,order = None, 2\n    \n        def __init__(self, train_aug, valid_aug): \n            store_attr()\n    \n        def before_call(self, b, split_idx):\n            self.idx = split_idx\n    \n        def encodes(self, img: PILImage):\n            if self.idx == 0:\n                aug_img = self.train_aug(image=np.array(img))['image']\n            else:\n                aug_img = self.valid_aug(image=np.array(img))['image']\n            return PILImage.create(aug_img)\n    \n    def get_train_aug(size): \n        return albumentations.Compose([\n                all_album[0],all_album[i+1]\n    ], p=1.)\n    def get_valid_aug(size): \n        return albumentations.Compose([\n            albumentations.Resize(size, size),\n            albumentations.CenterCrop(size, size, p=1.),\n            albumentations.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n    ], p=1.), \n\n\n    def get_x(row): return images_path/row['image_id']\n    def get_y(row): return row['label']\n    \n    \n    predictions = 0\n\n    for model in cfg.models:\n        learn = load_learner(Path(models_path + model), cpu=False).to_fp16()\n        learn_tst_dl = learn.dls.test_dl(test_data_path)\n\n        learn.cbs.pop(3) # remove wandb\n        learn.cbs.pop(3) # remove cutmix\n        learn.cbs.pop(3) # remove savemodel callback\n    \n        learn_predictions = learn.tta(dl=learn_tst_dl, n=cfg.n_tta, beta=cfg.beta)\n        predictions += learn_predictions[0]\n\n    \n\n    predictions = predictions / len(cfg.models)\n    final_predictions += predictions\n    \nfinal_predictions = final_predictions/(len(all_album)-1)\n\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path_str = '../input/cassava-leaf-disease-classification'\n\nmodels_path = '../input/resnextmodels/'\ntest_images_path = f'{path_str}/test_images/'\n#test_data_path = submission_df['image_id'].apply(lambda x: test_images_path+x)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## For Resext\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"final_predictions_resnext = 0\nfor i in range(4):\n    class AlbumentationsTransform(RandTransform):\n        split_idx,order = None, 2\n    \n        def __init__(self, train_aug, valid_aug): \n            store_attr()\n    \n        def before_call(self, b, split_idx):\n            self.idx = split_idx\n    \n        def encodes(self, img: PILImage):\n            if self.idx == 0:\n                aug_img = self.train_aug(image=np.array(img))['image']\n            else:\n                aug_img = self.valid_aug(image=np.array(img))['image']\n            return PILImage.create(aug_img)\n    \n    def get_train_aug(size): \n        return albumentations.Compose([\n                all_album[0],all_album[i+1]\n    ], p=1.)\n    def get_valid_aug(size): \n        return albumentations.Compose([\n            albumentations.Resize(size, size),\n            albumentations.CenterCrop(size, size, p=1.),\n    ], p=1.)\n\n\n    def get_x(row): return images_path/row['image_id']\n    def get_y(row): return row['label']\n    \n    \n    predictions = 0\n\n    for model in cfg.models:\n        learn = load_learner(Path(models_path + model), cpu=False).to_fp16()\n        learn_tst_dl = learn.dls.test_dl(test_data_path)\n\n        learn.cbs.pop(3) # remove wandb\n        learn.cbs.pop(3) # remove cutmix\n        learn.cbs.pop(3) # remove savemodel callback\n    \n        learn_predictions = learn.tta(dl=learn_tst_dl, n=cfg.n_tta, beta=cfg.beta)\n        predictions += learn_predictions[0]\n\n    \n\n    predictions = predictions / len(cfg.models)\n    final_predictions_resnext += predictions\n    \nfinal_predictions_resnext = final_predictions_resnext/(len(all_album)-1)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_final_predictions = 0.5*final_predictions + 0.5*final_predictions_resnext\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Augmentations for inference "},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nclass AlbumentationsTransform(RandTransform):\n    split_idx,order = None, 2\n    \n    def __init__(self, train_aug, valid_aug): \n        store_attr()\n    \n    def before_call(self, b, split_idx):\n        self.idx = split_idx\n    \n    def encodes(self, img: PILImage):\n        if self.idx == 0:\n            aug_img = self.train_aug(image=np.array(img))['image']\n        else:\n            aug_img = self.valid_aug(image=np.array(img))['image']\n        return PILImage.create(aug_img)\n    \ndef get_train_aug(size): \n    return albumentations.Compose([\n            albumentations.RandomResizedCrop(size,size),\n            albumentations.Transpose(p=0.5),\n            albumentations.HorizontalFlip(p=0.5),\n            albumentations.VerticalFlip(p=0.5),\n            albumentations.ShiftScaleRotate(p=0.5),\n            albumentations.HueSaturationValue(\n                hue_shift_limit=0.2, \n                sat_shift_limit=0.2, \n                val_shift_limit=0.2, \n                p=0.5\n            ),\n            albumentations.RandomBrightnessContrast(\n                brightness_limit=(-0.1,0.1), \n                contrast_limit=(-0.1, 0.1), \n                p=0.5\n            ),\n], p=1.)\ndef get_valid_aug(size): \n    return albumentations.Compose([\n        albumentations.Resize(size, size),\n        albumentations.CenterCrop(size, size, p=1.),\n], p=1.)\n\n\ndef get_x(row): return images_path/row['image_id']\ndef get_y(row): return row['label']\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction loop"},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\npredictions = 0\n\nfor model in cfg.models:\n    learn = load_learner(Path(models_path + model), cpu=False).to_fp16()\n    learn_tst_dl = learn.dls.test_dl(test_data_path)\n\n    learn.cbs.pop(3) # remove wandb\n    learn.cbs.pop(3) # remove cutmix\n    learn.cbs.pop(3) # remove savemodel callback\n    \n    learn_predictions = learn.tta(dl=learn_tst_dl, n=cfg.n_tta, beta=cfg.beta)\n    predictions += learn_predictions[0]\n\n    \n# average the predictions\npredictions = predictions / len(cfg.models)\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submit"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df['label'] = np.argmax(final_final_predictions, axis=1)\nsubmission_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}