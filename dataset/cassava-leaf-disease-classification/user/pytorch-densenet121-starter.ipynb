{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport os\nimport torchvision.models as models\nimport torch.utils.data as data\nimport sklearn.utils as utils\nfrom PIL import Image\nimport torchvision.transforms as T\nimport sklearn.metrics as metrics","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"input_path = '/kaggle/input/cassava-leaf-disease-classification/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(os.path.join(input_path, 'train.csv'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_classes = len(df.label.unique())\nnum_classes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.base = models.densenet121(pretrained=False)\n        self.dense = nn.Linear(1000, num_classes)\n    def forward(self, x):\n        return self.dense(self.base(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = 'cuda:0' if torch.cuda.is_available() else 'cpu'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Model().to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Dataset(data.Dataset):\n    def __init__(self, df, transforms):\n        super(Dataset, self).__init__()\n        self.df = df\n        self.transforms = transforms\n    def __getitem__(self, index):\n        row = self.df.iloc[index]\n        label = row.label\n        img = Image.open(f'{input_path}/train_images/{row.image_id}')\n        return self.transforms(img), np.array([label])\n    def __len__(self):\n        return len(self.df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = utils.shuffle(df, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transforms = T.Compose([\n    T.Resize((256, 256)),\n    T.ToTensor(),\n    T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5),)\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_transforms = T.Compose([\n    T.Resize((256, 256)),\n    T.ToTensor(),\n    T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5),)\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = Dataset(df=df.iloc[:20000].reset_index(drop=True), transforms=train_transforms)\nval_dataset = Dataset(df=df.iloc[20000:].reset_index(drop=True), transforms=val_transforms)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataloader = data.DataLoader(dataset=train_dataset, num_workers=2, shuffle=True, batch_size=32)\nval_dataloader = data.DataLoader(dataset=val_dataset, num_workers=2, shuffle=True, batch_size=32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = nn.CrossEntropyLoss().cuda()\nopt = torch.optim.Adam(model.parameters(), lr=0.0001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS = 2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(EPOCHS):\n    model.train()\n    print('\\nTraining...')\n    for b, (x, y) in enumerate(train_dataloader):\n        \n        opt.zero_grad()\n        x = x.cuda()\n        y = y.cuda()\n        y_pred = model(x)\n        loss = criterion(y_pred, y.squeeze())\n        loss.backward()\n        opt.step()\n        \n        if b % 20 == 0:\n            print('\\rEpoch: {}/{}, Batch: {}/{} Loss: {}'.format(i+1, EPOCHS, b+1, len(train_dataloader), loss.item()), end='')\n    model.eval()\n    print('\\nValidation....')\n    y_actuals = []\n    y_preds = []\n    \n    for b, (x, y) in enumerate(val_dataloader):\n        \n        x = x.cuda()\n        y = y.cuda()\n        y_pred = model(x).detach()\n        loss = criterion(y_pred, y.squeeze())\n        y_actuals += y.cpu().numpy().tolist()\n        y_preds += y_pred.cpu().numpy().tolist()\n        if b % 20 == 0:\n            print('\\rEpoch: {}/{}, Batch: {}/{} Loss: {}'.format(i+1, EPOCHS, b+1, len(val_dataloader), loss.item()), end='')\n        \n    y_actuals = np.array(y_actuals).squeeze()\n    y_preds = np.array(y_preds).argmax(1)\n    print('Accuracy: ', np.sum(y_preds == y_actuals) / len(y_actuals))\n    print(metrics.classification_report(y_actuals, y_preds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df = pd.read_csv(os.path.join(input_path, 'sample_submission.csv'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class TestDataset(data.Dataset):\n    def __init__(self, df, transforms):\n        super(TestDataset, self).__init__()\n        self.df = df\n        self.transforms = transforms\n    def __getitem__(self, index):\n        row = self.df.iloc[index]\n        img = Image.open(f'{input_path}/test_images/{row.image_id}')\n        return self.transforms(img)\n    def __len__(self):\n        return len(self.df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_transforms = T.Compose([\n    T.Resize((256, 256)),\n    T.ToTensor(),\n    T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5),)\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = TestDataset(df=submission_df, transforms=test_transforms)\ntest_dataloader = data.DataLoader(dataset=train_dataset, shuffle=False, batch_size=16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.eval()\ntest_preds = []\nfor x in test_dataloader:\n    x = x.cuda()\n    y_pred = model(x).detach()\n    test_preds += y_pred.cpu().numpy().argmax(1).tolist()\ntest_preds = np.array(test_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df['label'] = test_preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!nvidia-smi","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}