{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2020-12-28T21:48:19.308213Z","iopub.status.busy":"2020-12-28T21:48:19.307497Z","iopub.status.idle":"2020-12-28T21:48:22.324425Z","shell.execute_reply":"2020-12-28T21:48:22.325648Z"},"papermill":{"duration":3.053483,"end_time":"2020-12-28T21:48:22.325881","exception":false,"start_time":"2020-12-28T21:48:19.272398","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport glob\nfrom itertools import chain\nimport os\nimport random\nimport zipfile\n!pip install --upgrade pip \n!pip install efficientnet_pytorch\n!pip install timm\n!pip install linformer\n!pip install vit-pytorch\n# Pytorch Implementation from this Github: # https://github.com/lukemelas/EfficientNet-PyTorch  \nimport torch \nimport torch.nn as nn\nimport torch.nn.functional as F \nimport torch.optim as optim \nimport time \nimport torchvision \nimport matplotlib.pyplot as plt \nimport copy \n\nfrom torch.optim import lr_scheduler\nfrom linformer import Linformer\nfrom torchvision import datasets, models, transforms, utils\nfrom torch.utils.data import Dataset, DataLoader \nfrom PIL import Image\nfrom torch.optim.lr_scheduler import StepLR\nfrom skimage import io, transform \nfrom sklearn.model_selection import train_test_split \nfrom tqdm.notebook import tqdm\nfrom vit_pytorch.efficient import ViT\nfrom vit_pytorch.distill import DistillableViT, DistillWrapper\nfrom torchvision.models import resnet50\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#!pip install efficientnet_pytorch\n#from efficientnet_pytorch import EfficientNet\nimport timm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training settings\nbatch_size = 64\nepochs = 11\nlr = 3e-5\ngamma = 0.7\nseed = 42\ndevice = 'cuda'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_everything(seed)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-28T21:51:19.02638Z","iopub.status.busy":"2020-12-28T21:51:19.025492Z","iopub.status.idle":"2020-12-28T21:51:19.530276Z","shell.execute_reply":"2020-12-28T21:51:19.529534Z"},"papermill":{"duration":0.55878,"end_time":"2020-12-28T21:51:19.530439","exception":false,"start_time":"2020-12-28T21:51:18.971659","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Loading data \ndataset_dir = \"../input/cassava-leaf-disease-classification/\"\ndata_df = pd.read_csv(dataset_dir + \"train.csv\")   \n\n# Add to column Image_ID the image path in dataframe \ndata_df[\"path\"] = dataset_dir + \"train_images/\" + data_df[\"image_id\"] \n\n# Rearrange column order\ndata_df = data_df[[\"image_id\", \"path\", \"label\"]]","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-28T21:51:19.609767Z","iopub.status.busy":"2020-12-28T21:51:19.609126Z","iopub.status.idle":"2020-12-28T21:51:19.621304Z","shell.execute_reply":"2020-12-28T21:51:19.621932Z"},"papermill":{"duration":0.058307,"end_time":"2020-12-28T21:51:19.622058","exception":false,"start_time":"2020-12-28T21:51:19.563751","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_colwidth', -1)\ndata_df.head() ","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-28T21:51:19.696787Z","iopub.status.busy":"2020-12-28T21:51:19.696121Z","iopub.status.idle":"2020-12-28T21:51:19.958969Z","shell.execute_reply":"2020-12-28T21:51:19.959483Z"},"papermill":{"duration":0.302946,"end_time":"2020-12-28T21:51:19.959612","exception":false,"start_time":"2020-12-28T21:51:19.656666","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Look how an image looks like\n\nimg = data_df.iloc[0] \nimg = Image.open(img[\"path\"]) # e.g. open image of picture\nimg ","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-28T21:51:20.217975Z","iopub.status.busy":"2020-12-28T21:51:20.216913Z","iopub.status.idle":"2020-12-28T21:51:20.219504Z","shell.execute_reply":"2020-12-28T21:51:20.22014Z"},"papermill":{"duration":0.065701,"end_time":"2020-12-28T21:51:20.220272","exception":false,"start_time":"2020-12-28T21:51:20.154571","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Preprocessing step \ntrain_transform = transforms.Compose([\n    transforms.RandomResizedCrop(224), \n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.485,0.456,0.406), (0.229, 0.224,0.225))\n]) \n\nval_transform = transforms.Compose([\n    transforms.Resize(256), \n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n])\n","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-28T21:51:20.336687Z","iopub.status.busy":"2020-12-28T21:51:20.335799Z","iopub.status.idle":"2020-12-28T21:51:20.342643Z","shell.execute_reply":"2020-12-28T21:51:20.342083Z"},"papermill":{"duration":0.0671,"end_time":"2020-12-28T21:51:20.342762","exception":false,"start_time":"2020-12-28T21:51:20.275662","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# split data in train and validation data \ntrain_list, valid_list = train_test_split(data_df, test_size=0.15) ","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-28T21:51:20.462005Z","iopub.status.busy":"2020-12-28T21:51:20.461054Z","iopub.status.idle":"2020-12-28T21:51:20.464303Z","shell.execute_reply":"2020-12-28T21:51:20.463659Z"},"papermill":{"duration":0.067242,"end_time":"2020-12-28T21:51:20.464395","exception":false,"start_time":"2020-12-28T21:51:20.397153","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Create custom dataset with tensor for each image and label for each image\n# source: https://stackoverflow.com/questions/61391919/loading-image-data-from-pandas-to-pytorch \n\nclass MyDataset(Dataset): \n    def __init__(self, dataframe, transform = None): \n        self.dataframe = dataframe \n        self.transform = transform\n        \n    def __len__(self): \n        return len(self.dataframe) \n    \n    def __getitem__(self, index): \n        row = self.dataframe.iloc[index] \n        img = Image.open(row[\"path\"])  \n        #tensor = torchvision.transforms.functional.to_tensor(img)\n        label = row[\"label\"]\n        \n        if self.transform: \n            img = self.transform(img)\n        return img, label\n    \n        \n# create dataset with tensors and their belonging labels for each image\ntrain_data = MyDataset(train_list, transform = train_transform) \nvalid_data = MyDataset(valid_list, transform = val_transform) ","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-28T21:51:20.579541Z","iopub.status.busy":"2020-12-28T21:51:20.57865Z","iopub.status.idle":"2020-12-28T21:51:20.581451Z","shell.execute_reply":"2020-12-28T21:51:20.581992Z"},"papermill":{"duration":0.063945,"end_time":"2020-12-28T21:51:20.582141","exception":false,"start_time":"2020-12-28T21:51:20.518196","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Create Dataloader for train and validation set\ntrain_loader = DataLoader(train_data, batch_size = batch_size, shuffle = True) \nvalid_loader = DataLoader(valid_data, batch_size = batch_size, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-28T21:51:20.699852Z","iopub.status.busy":"2020-12-28T21:51:20.698881Z","iopub.status.idle":"2020-12-28T21:51:20.704808Z","shell.execute_reply":"2020-12-28T21:51:20.705503Z"},"papermill":{"duration":0.068958,"end_time":"2020-12-28T21:51:20.70572","exception":false,"start_time":"2020-12-28T21:51:20.636762","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"print(len(train_loader.dataset))\nprint(len(train_loader))  # each batch size\nprint(type(train_loader)) \nprint(len(valid_loader.dataset)) ","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-28T21:51:20.822496Z","iopub.status.busy":"2020-12-28T21:51:20.821701Z","iopub.status.idle":"2020-12-28T21:51:20.824853Z","shell.execute_reply":"2020-12-28T21:51:20.824324Z"},"papermill":{"duration":0.063391,"end_time":"2020-12-28T21:51:20.824985","exception":false,"start_time":"2020-12-28T21:51:20.761594","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Train and validation loader in a dict\ntrain_val_loader = {\"train\": train_loader, \"val\": valid_loader}","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-28T21:51:20.946641Z","iopub.status.busy":"2020-12-28T21:51:20.945581Z","iopub.status.idle":"2020-12-28T21:51:20.948859Z","shell.execute_reply":"2020-12-28T21:51:20.948208Z"},"papermill":{"duration":0.067054,"end_time":"2020-12-28T21:51:20.948971","exception":false,"start_time":"2020-12-28T21:51:20.881917","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"dataset_sizes = {j: len(train_val_loader[j].dataset) for j in [\"train\", \"val\"]} ","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-28T21:51:21.068255Z","iopub.status.busy":"2020-12-28T21:51:21.0673Z","iopub.status.idle":"2020-12-28T21:51:21.071727Z","shell.execute_reply":"2020-12-28T21:51:21.071119Z"},"papermill":{"duration":0.066774,"end_time":"2020-12-28T21:51:21.071835","exception":false,"start_time":"2020-12-28T21:51:21.005061","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"dataset_sizes","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-28T21:51:21.586769Z","iopub.status.busy":"2020-12-28T21:51:21.585646Z","iopub.status.idle":"2020-12-28T21:51:21.588702Z","shell.execute_reply":"2020-12-28T21:51:21.589269Z"},"papermill":{"duration":0.459007,"end_time":"2020-12-28T21:51:21.589417","exception":false,"start_time":"2020-12-28T21:51:21.13041","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# use gpu if possible\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.058752,"end_time":"2020-12-28T21:51:21.708232","exception":false,"start_time":"2020-12-28T21:51:21.64948","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## Transfer Learning and Fintetuning \n\nBased on the Pytorch Tutorial: https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html "},{"metadata":{},"cell_type":"markdown","source":"# **Linformer**"},{"metadata":{"trusted":true},"cell_type":"code","source":"efficient_transformer = Linformer(\n    dim=128,\n    seq_len=49+1,  # 7x7 patches + 1 cls-token\n    depth=12,\n    heads=8,\n    k=64\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visual Transformer"},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\ntrain_model_dir = \"../input/en-pretrained/efficient_net_b0_finetune.pt\"\nteacher = EfficientNet.from_name(\"efficientnet-b0\").to(device)  # not trained weights\n\n# recreate architecture as for the training model\nnum_feature = teacher._fc.in_features  # of the final layer\nteacher._fc = nn.Linear(num_feature, 5) # output-layer to 5\nteacher = teacher.to(device) \nteacher.load_state_dict(torch.load(train_model_dir, map_location='cuda:0')) \nteacher.eval()\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmodel = timm.create_model('vit_base_patch16_224', pretrained=True) \nmodel.head = nn.Linear(768,5)\nmodel = model.to(device)\nmodel.eval()\n\n\n\"\"\"\nmodel = DistillableViT(\n    dim=128,\n    image_size=224,\n    patch_size=32,\n    num_classes=5,\n    channels=3,\n    depth=6,\n    heads=8,\n    dropout = 0.1,\n    emb_dropout = 0.1,\n    mlp_dim = 2048\n).to(device)\n\ndistiller = DistillWrapper(\n    student = model,\n    teacher = teacher,\n    temperature = 3,           # temperature of distillation\n    alpha = 0.5                # trade between main loss and distillation loss\n)\n\n\"\"\"\n\nmodel","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"# loss function\ncriterion = nn.CrossEntropyLoss()\n# optimizer\noptimizer = optim.Adam(model.parameters(), lr=lr)\n# scheduler\nscheduler = StepLR(optimizer, step_size=1, gamma=gamma)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"best_model_wts = copy.deepcopy(model.state_dict())\nfor epoch in range(epochs):\n    epoch_loss = 0\n    epoch_accuracy = 0\n\n    for data, label in tqdm(train_loader):\n        data = data.to(device)\n        label = label.to(device)\n        output = model(data)\n        loss = criterion(output, label)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        acc = (output.argmax(dim=1) == label).float().mean()\n        epoch_accuracy += acc / len(train_loader)\n        epoch_loss += loss / len(train_loader)\n\n    with torch.no_grad():\n        epoch_val_accuracy = 0\n        epoch_val_loss = 0\n        for data, label in valid_loader:\n            data = data.to(device)\n            label = label.to(device)\n\n            val_output = model(data)\n            val_loss = criterion(val_output, label)\n\n            acc = (val_output.argmax(dim=1) == label).float().mean()\n            epoch_val_accuracy += acc / len(valid_loader)\n            epoch_val_loss += val_loss / len(valid_loader)\n            \n    scheduler.step()\n\n    print(\n        f\"Epoch : {epoch+1} - loss : {epoch_loss:.4f} - acc: {epoch_accuracy:.4f} - val_loss : {epoch_val_loss:.4f} - val_acc: {epoch_val_accuracy:.4f}\\n\"\n    )\n    \nmodel.load_state_dict(best_model_wts)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-28T21:51:22.621465Z","iopub.status.busy":"2020-12-28T21:51:22.620594Z","iopub.status.idle":"2020-12-28T21:51:22.623929Z","shell.execute_reply":"2020-12-28T21:51:22.624586Z"},"papermill":{"duration":0.068869,"end_time":"2020-12-28T21:51:22.624735","exception":false,"start_time":"2020-12-28T21:51:22.555866","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Save trained model in output/kaggle/working\npath = \"./ViT_f.pt\"\n\n# Save model\ntorch.save(model.state_dict(), path) ","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.06003,"end_time":"2020-12-28T21:51:22.744951","exception":false,"start_time":"2020-12-28T21:51:22.684921","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## Inference\n\nSave model and load it for inference (support from here: https://pytorch.org/tutorials/beginner/saving_loading_models.html, https://pytorch.org/tutorials/beginner/saving_loading_models.html) \nhttps://discuss.pytorch.org/t/how-to-use-train-model-for-predict-unseen-data/81689"},{"metadata":{"execution":{"iopub.execute_input":"2020-12-28T21:51:22.878098Z","iopub.status.busy":"2020-12-28T21:51:22.877048Z","iopub.status.idle":"2020-12-28T21:51:25.033624Z","shell.execute_reply":"2020-12-28T21:51:25.032436Z"},"papermill":{"duration":2.226579,"end_time":"2020-12-28T21:51:25.033792","exception":false,"start_time":"2020-12-28T21:51:22.807213","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# load model \ntrain_model_dir = \"../input/efficientnet-model/efficient_net.pt\"\nmodel = EfficientNet.from_name(\"efficientnet-b3\").to(device)  # not trained weights\ntrain_model_dir = \"../input/efficientnet-model/efficient_net_b5_finetune.pt\"\nmodel = EfficientNet.from_name(\"efficientnet-b5\").to(device)  # not trained weights\n\n# recreate architecture as for the training model\nnum_feature = model._fc.in_features  # of the final layer\nmodel._fc = nn.Linear(num_feature, 5) # output-layer to 5\nmodel = model.to(device) ","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-28T21:51:25.158695Z","iopub.status.busy":"2020-12-28T21:51:25.158059Z","iopub.status.idle":"2020-12-28T21:51:26.702368Z","shell.execute_reply":"2020-12-28T21:51:26.702891Z"},"papermill":{"duration":1.606879,"end_time":"2020-12-28T21:51:26.703041","exception":false,"start_time":"2020-12-28T21:51:25.096162","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"model.load_state_dict(torch.load(train_model_dir)) \nmodel.eval()","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-28T21:51:26.829045Z","iopub.status.busy":"2020-12-28T21:51:26.828361Z","iopub.status.idle":"2020-12-28T21:51:26.838521Z","shell.execute_reply":"2020-12-28T21:51:26.837962Z"},"papermill":{"duration":0.07634,"end_time":"2020-12-28T21:51:26.838624","exception":false,"start_time":"2020-12-28T21:51:26.762284","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Load test image sample\ntest_df = pd.read_csv(dataset_dir + \"sample_submission.csv\")   \n\n# Add to column Image_ID the image path in dataframe \ntest_df[\"path\"] = dataset_dir + \"test_images/\" + test_df[\"image_id\"] \n\n# Rearrange column order\ntest_df = test_df[[\"image_id\", \"path\", \"label\"]]","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-28T21:51:26.968458Z","iopub.status.busy":"2020-12-28T21:51:26.967067Z","iopub.status.idle":"2020-12-28T21:51:26.971069Z","shell.execute_reply":"2020-12-28T21:51:26.97156Z"},"papermill":{"duration":0.072877,"end_time":"2020-12-28T21:51:26.971686","exception":false,"start_time":"2020-12-28T21:51:26.898809","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-28T21:51:27.096974Z","iopub.status.busy":"2020-12-28T21:51:27.096231Z","iopub.status.idle":"2020-12-28T21:51:27.100762Z","shell.execute_reply":"2020-12-28T21:51:27.100243Z"},"papermill":{"duration":0.068873,"end_time":"2020-12-28T21:51:27.100862","exception":false,"start_time":"2020-12-28T21:51:27.031989","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"test = MyDataset(test_df, val_transform) ","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-28T21:51:27.224891Z","iopub.status.busy":"2020-12-28T21:51:27.224241Z","iopub.status.idle":"2020-12-28T21:51:27.228393Z","shell.execute_reply":"2020-12-28T21:51:27.228865Z"},"papermill":{"duration":0.069247,"end_time":"2020-12-28T21:51:27.228992","exception":false,"start_time":"2020-12-28T21:51:27.159745","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"testloader = DataLoader(test, batch_size = 4, shuffle=False, num_workers=4)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.06044,"end_time":"2020-12-28T21:51:27.348086","exception":false,"start_time":"2020-12-28T21:51:27.287646","status":"completed"},"tags":[]},"cell_type":"markdown","source":"### Feed model test image\n\nBased on this pytorch Tutorial section: \"Test the network on the test data\" https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html"},{"metadata":{"trusted":true},"cell_type":"code","source":"d = [2, 3] \ns = [2, 4,2]\nd.extend(s)\nd","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-28T21:51:27.475558Z","iopub.status.busy":"2020-12-28T21:51:27.47461Z","iopub.status.idle":"2020-12-28T21:51:27.652819Z","shell.execute_reply":"2020-12-28T21:51:27.65209Z"},"papermill":{"duration":0.244853,"end_time":"2020-12-28T21:51:27.65299","exception":false,"start_time":"2020-12-28T21:51:27.408137","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"pred_labels = [] \nfor data in testloader: \n    img, label = data  \n    img = img.to(device) \n    label = label.to(device)\n    \n    outputs = model(img) # predict output \n    \n    _, predicted = torch.max(outputs, 1) \n    for each in predicted:  # when more/parallel outputs\n        pred_labels.append(each.item())","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-28T21:51:28.774024Z","iopub.status.busy":"2020-12-28T21:51:28.773025Z","iopub.status.idle":"2020-12-28T21:51:28.777966Z","shell.execute_reply":"2020-12-28T21:51:28.778456Z"},"papermill":{"duration":0.077885,"end_time":"2020-12-28T21:51:28.77858","exception":false,"start_time":"2020-12-28T21:51:28.700695","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Create Submission file with predicted value\nsubmission = pd.DataFrame({\"image_id\": test_df[\"image_id\"], \"label\": pred_labels})\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-28T21:51:28.907139Z","iopub.status.busy":"2020-12-28T21:51:28.906174Z","iopub.status.idle":"2020-12-28T21:51:29.210125Z","shell.execute_reply":"2020-12-28T21:51:29.207493Z"},"papermill":{"duration":0.37102,"end_time":"2020-12-28T21:51:29.210288","exception":false,"start_time":"2020-12-28T21:51:28.839268","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Save submission file\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}