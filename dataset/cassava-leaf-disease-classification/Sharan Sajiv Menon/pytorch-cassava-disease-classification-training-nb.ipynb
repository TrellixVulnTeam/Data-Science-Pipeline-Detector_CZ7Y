{"cells":[{"metadata":{"_kg_hide-output":true,"trusted":true,"collapsed":true},"cell_type":"code","source":"!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n!python pytorch-xla-env-setup.py --apt-packages libomp5 libopenblas-dev\n!pip install efficientnet_pytorch","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch_xla\nimport torch_xla.core.xla_model as xm","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_csv = pd.read_csv(\"/kaggle/input/cassava-leaf-disease-classification/train.csv\")\ntrain_csv.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.mkdir(\"/kaggle/temp\")\nos.mkdir(\"/kaggle/temp/training_images\")\nfor i in list(set(train_csv[\"label\"])):\n    os.mkdir(\"/kaggle/temp/training_images/{}\".format(i))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_training_files = os.listdir(\"/kaggle/input/cassava-leaf-disease-classification/train_images\")\nlen(all_training_files)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm\nimport shutil","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for file in tqdm(all_training_files):\n    label = int(train_csv[train_csv[\"image_id\"] == file][\"label\"])\n    dirname = \"/kaggle/input/cassava-leaf-disease-classification/train_images/\" + file\n    outname = \"/kaggle/temp/training_images/{}/{}\".format(label, file)\n    shutil.copyfile(dirname, outname)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torchvision\nfrom torchvision import datasets, transforms\nfrom torch import nn, optim\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader, sampler, random_split\nfrom torchvision import models","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import albumentations as A\nfrom albumentations.pytorch import ToTensorV2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom PIL import Image\nimport json","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from ignite.engine import Engine, Events, create_supervised_trainer, create_supervised_evaluator\nfrom ignite.handlers import ModelCheckpoint, EarlyStopping\nfrom ignite.metrics import Accuracy, Loss, RunningAverage, ConfusionMatrix\nfrom ignite.contrib.handlers import ProgressBar","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_data_loaders(data_dir, batch_size):\n    transform = transforms.Compose([transforms.RandomResizedCrop(512),\n                                transforms.RandomHorizontalFlip(),\n                                transforms.RandomVerticalFlip(),\n#                                 transforms.RandomRotation(20),\n                                transforms.ToTensor(),\n                                transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n    all_data = datasets.ImageFolder(data_dir, transform=transform)\n    train_data_len = int(len(all_data)*0.81)\n    valid_data_len = int(len(all_data) - train_data_len)\n    train_data, val_data = random_split(all_data, [train_data_len, valid_data_len])\n    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n    return ((train_loader, val_loader), all_data.classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = \"/kaggle/temp/training_images/\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(train_loader, val_loader), classes = get_data_loaders(path, 256)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataiter = iter(train_loader)\nimages, labels = dataiter.next()\nimages = images.numpy() # convert images to numpy for display\n# plot the images in the batch, along with the corresponding labels\nfig = plt.figure(figsize=(14, 10))\nfor idx in np.arange(20):\n    ax = fig.add_subplot(5, 12/2, idx+1, xticks=[], yticks=[])\n    plt.imshow(np.transpose(images[idx], (1, 2, 0)))\n    ax.set_title(classes[labels[idx]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\ndevice = xm.xla_device()\ndevice","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from efficientnet_pytorch import EfficientNet\nclass Model(nn.Module):\n    def __init__(self, num_classes):\n        super(Model, self).__init__()\n#         self.base = models.densenet161(pretrained=True)\n        self.base = EfficientNet.from_pretrained('efficientnet-b5')\n        self.dense = nn.Linear(1000, num_classes)\n        \n        for param in self.base.parameters():\n            param.requires_grad = False\n    def forward(self, x):\n        return self.dense(self.base(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model = models.resnext50_32x4d(pretrained=True)\nmodel = Model(len(classes))\n# from efficientnet_pytorch import EfficientNet\n# model = EfficientNet.from_pretrained('efficientnet-b5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"print(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def count_params(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\ncount_params(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for param in model.parameters():\n#     param.requires_grad = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# n_inputs = model.fc.in_features\n# last_layer = nn.Linear(n_inputs, len(classes))\n# model.fc = last_layer\n# model = model.to(device)\n# print(model.fc.out_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = model.to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = criterion.to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_history = {'accuracy':[],'loss':[]}\nvalidation_history = {'accuracy':[],'loss':[]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainer = create_supervised_trainer(model, optimizer, criterion, device=device)\nevaluator = create_supervised_evaluator(model,\n                                        device=device,\n                                        metrics={\n                                            'accuracy': Accuracy(),\n                                            'loss': Loss(criterion),\n                                            'cm':ConfusionMatrix(len(classes))\n                                            })\n@trainer.on(Events.ITERATION_COMPLETED)\ndef log_a_dot(engine):\n    print(\".\",end=\"\")\n\n@trainer.on(Events.EPOCH_COMPLETED)\ndef log_training_results(trainer):\n    evaluator.run(train_loader)\n    metrics = evaluator.state.metrics\n    accuracy = metrics['accuracy']*100\n    loss = metrics['loss']\n    training_history['accuracy'].append(accuracy)\n    training_history['loss'].append(loss)\n    print()\n    print(\"Training Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\"\n          .format(trainer.state.epoch, accuracy, loss))\n    \n@trainer.on(Events.EPOCH_COMPLETED)   \ndef log_validation_results(trainer):\n    evaluator.run(val_loader)\n    metrics = evaluator.state.metrics\n    accuracy = metrics['accuracy']*100\n    loss = metrics['loss']\n    validation_history['accuracy'].append(accuracy)\n    validation_history['loss'].append(loss)\n    print(\"Validation Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\"\n          .format(trainer.state.epoch, accuracy, loss))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainer.run(train_loader, max_epochs=8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelsave = model.to(\"cpu\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(modelsave.state_dict(), \"/kaggle/working/model.pth\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# all_testing_files = os.listdir(\"/kaggle/input/cassava-leaf-disease-classification/test_images/\")\n# len(all_testing_files)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# model.eval()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def apply_test_transforms(inp):\n#     out = transforms.functional.resize(inp, [224,224])\n#     out = transforms.functional.to_tensor(out)\n#     out = transforms.functional.normalize(out, [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n#     return out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from PIL import Image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def predict(model, image):\n#     im_as_tensor = apply_test_transforms(im)\n#     minibatch = torch.stack([im_as_tensor])\n#     if torch.cuda.is_available():\n#         minibatch = minibatch.cuda()\n#     pred = model(minibatch)\n#     _, classnum = torch.max(pred, 1)\n#     return classes[classnum]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# rows = []\n# for file in all_testing_files:\n#     fname = \"/kaggle/input/cassava-leaf-disease-classification/test_images/\" + file\n#     im = Image.open(fname)\n#     cls = predict(model, im)\n#     row = {'imageid':file, 'label':cls}\n#     rows.append(row)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# submission = pd.DataFrame(rows)\n# submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# submission.to_csv('./submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}