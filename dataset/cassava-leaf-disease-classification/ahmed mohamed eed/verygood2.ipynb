{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"pip install --quiet /kaggle/input/kerasapplications","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install --quiet /kaggle/input/efficientnet-git","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#26\nimport efficientnet.tfkeras as efn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#27\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport tensorflow as tf\nfrom tensorflow.keras import models, layers\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.optimizers import Adam\n# ignoring warnings\nimport warnings\nwarnings.simplefilter(\"ignore\")\nimport os, cv2, json\nfrom PIL import Image\n#from tensorflow.keras.applications import EfficientNetB0\n#from tensorflow.keras.applications import EfficientNetB3\n#from tensorflow.keras.applications import EfficientNetB4\n#from tensorflow.keras.applications import EfficientNetB5\n#from tensorflow.keras.applications import EfficientNetB6\n#from tensorflow.keras.applications import EfficientNetB7\nfrom keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, Input, Dropout\nfrom keras.models import Model, Sequential","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#28\nWORK_DIR = '../input/cassava-leaf-disease-classification'\nos.listdir(WORK_DIR)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#29\nprint('Train images: %d' %len(os.listdir(os.path.join(WORK_DIR, \"train_images\"))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#30\nwith open(os.path.join(WORK_DIR, \"label_num_to_disease_map.json\")) as file:\n    print(json.dumps(json.loads(file.read()), indent=4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels = pd.read_csv(os.path.join(WORK_DIR, \"train.csv\"))\nprint(train_labels.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#32\nsns.countplot(train_labels.label, edgecolor = 'black',\n              palette = reversed(sns.color_palette(\"viridis\", 5)))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_normall = pd.read_csv(\"../input/anomaly005/normall_all.csv\")\ndata_normall","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#35\ndata_anomaly = pd.read_csv(\"../input/anomaly005/anomaly_all.csv\")\ndata_anomaly","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n#split the data into train and test set\ntrain,val25 = train_test_split(data_normall, test_size=0.25, random_state=0 , shuffle=True)\n#save the data\ntrain.to_csv('train.csv',index=False)\nval25.to_csv('val25.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas, sys\nimport pandas as pd\n\n\na = pd.read_csv(\"../input/anomaly005/anomaly_all.csv\")\nb = pd.read_csv(\"./val25.csv\")\n\nmerged =pd.concat([a,b])\n\nmerged.to_csv('./val30.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test =pd.read_csv(\"./train.csv\")\ndata_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_val = pd.read_csv(\"./val30.csv\")\ndata_val","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#36\n# Main parameters\nBATCH_SIZE = 4\nSTEPS_PER_EPOCH = len(data_test) / BATCH_SIZE\nVALIDATION_STEPS = len(data_val) / BATCH_SIZE\nEPOCHS = 10\nTARGET_SIZE = 512","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#37\ndata_test.label = data_test.label.astype('str')\n\ntrain_datagen = ImageDataGenerator(\n                                     preprocessing_function = None,\n                                     rotation_range = 45,\n                                     zoom_range = 0.2,\n                                     horizontal_flip = True,\n                                     vertical_flip = True,\n                                     fill_mode = 'nearest',\n                                     shear_range = 0.1,\n                                     height_shift_range = 0.1,\n                                     width_shift_range = 0.1,\n                                     featurewise_center = True,\n                                     featurewise_std_normalization = True)\n\ntrain_generator = train_datagen.flow_from_dataframe(data_test,\n                         directory = os.path.join(WORK_DIR, \"train_images\"),\n                         #subset = \"training\",\n                         x_col = \"image_id\",\n                         y_col = \"label\",\n                         target_size = (TARGET_SIZE, TARGET_SIZE),\n                         batch_size = BATCH_SIZE,shuffle=True,\n                         class_mode = \"sparse\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#38\ndata_val.label = data_val.label.astype('str')\n\nvalidation_datagen = ImageDataGenerator(rescale=1./255)\nvalidation_generator = train_datagen.flow_from_dataframe(data_val,\n                         directory = os.path.join(WORK_DIR, \"train_images\"),\n                         #subset = \"training\",\n                         x_col = \"image_id\",\n                         y_col = \"label\",\n                         target_size = (TARGET_SIZE, TARGET_SIZE),\n                         batch_size = BATCH_SIZE,shuffle=True,\n                         class_mode = \"sparse\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model():\n    model = models.Sequential()\n    model.add(efn.EfficientNetB4(include_top = False, weights = \"../input/efficientnet-keras-noisystudent-weights-b0b7/efficientnet-b4_noisy-student_notop.h5\",\n                             input_shape = (TARGET_SIZE, TARGET_SIZE, 3)))\n    model.add(layers.GlobalAveragePooling2D())\n    \n    #model.add(Dense(2048, activation=\"relu\"))    \n    model.add(Dense(1024, activation=\"relu\"))\n    model.add(Dense(512, activation=\"relu\"))\n\n    model.add(Dropout(0.25))\n    \n    model.add(Dense(5, activation=\"softmax\"))\n    model.compile(optimizer = Adam(lr = 0.001),\n                  loss = \"sparse_categorical_crossentropy\",\n                  metrics = [\"sparse_categorical_accuracy\"])\n    return model\nmodel = create_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#40\nprint('Our EfficientNet CNN has %d layers' %len(model.layers))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#41\nmodel_save = ModelCheckpoint('./EffNetB_best_weights.h5', \n                             save_best_only = True, \n                             save_weights_only = True,\n                             monitor = 'val_loss', \n                             mode = 'min', verbose = 1)\nearly_stop = EarlyStopping(monitor = 'val_loss', min_delta = 0.001, \n                           patience = 5, mode = 'min', verbose = 1,\n                           restore_best_weights = True)\nreduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.3, \n                              patience = 2, min_delta = 0.001, \n                              mode = 'min', verbose = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from keras.models import load_model\n#model_new = load_model('../input/verygood2/outliersModel_20.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#42\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch = STEPS_PER_EPOCH,\n    epochs = EPOCHS,\n    validation_data = validation_generator,\n    validation_steps = VALIDATION_STEPS,\n    #callbacks = [model_save, early_stop, reduce_lr]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#43\nss = pd.read_csv(os.path.join(WORK_DIR, \"sample_submission.csv\"))\nss\npreds = []\n\nfor image_id in ss.image_id:\n    image = Image.open(os.path.join(WORK_DIR,  \"test_images\", image_id))\n    image = image.resize((TARGET_SIZE, TARGET_SIZE))\n    image = np.expand_dims(image, axis = 0)\n    preds.append(np.argmax(model.predict(image)))\n\nss['label'] = preds\nss\nss.to_csv('submission.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#44\nss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#45\nmodel.save('outliersModel4_12.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#46\nmodel.save_weights('outliersWeight4_12.h5')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}