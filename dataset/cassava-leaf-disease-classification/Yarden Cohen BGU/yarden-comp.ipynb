{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Image Recognition with a CNN"},{"metadata":{},"cell_type":"markdown","source":"## 1. prepping the Data"},{"metadata":{},"cell_type":"markdown","source":"### 1.0 import labels"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\n\nlabels = pd.read_csv(\"../input/cassava-leaf-disease-classification/train.csv\")\nlabels.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.1 importing folder directly into dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dir = '../input/cassava-leaf-disease-classification/train_images'\ntest_dir = '../input/cassava-leaf-disease-classification/test_images'\n\nbatch_size = 32\nimg_height = 256\nimg_width = 256\n\nfrom keras import preprocessing\n\n\ntrain_datagen = preprocessing.image.ImageDataGenerator(rescale=1./225,\n                                                       rotation_range=40,\n                                                       width_shift_range=0.2,\n                                                       height_shift_range=0.2,\n                                                       shear_range=0.2,\n                                                       zoom_range=0.2,\n                                                       validation_split=0.3,\n                                                       horizontal_flip=True,)\n\ntest_datagen = preprocessing.image.ImageDataGenerator(rescale=1./255)\n\ntrain_ds = train_datagen.flow_from_dataframe(dataframe=labels.astype(str),\n                                             directory=train_dir,\n                                             subset='training',\n                                             x_col=\"image_id\",\n                                             validation_split=0.2,\n                                             y_col=\"label\",\n                                             shuffle=True,\n                                             target_size=(img_height,img_width),\n                                             batch_size=batch_size,\n                                             class_mode='categorical')\n\nval_ds = train_datagen.flow_from_dataframe(dataframe=labels.astype(str),\n                                             directory=train_dir,\n                                             subset='validation',\n                                             x_col=\"image_id\",\n                                             validation_split=0.2,\n                                             y_col=\"label\",\n                                             shuffle=True,\n                                             target_size=(img_height,img_width),\n                                             batch_size=batch_size,\n                                             class_mode='categorical')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import numpy as np\n# np.unique(train_ds.labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. creating the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_classes = 5\n\nfrom keras import models, layers, optimizers\n\nmodel = models.Sequential()\n\nmodel.add(layers.Conv2D(16,(3,3), activation='relu', input_shape=(img_height,img_width,3)))\nmodel.add(layers.MaxPooling2D(2,2))\nmodel.add(layers.Conv2D(32,(3,3), activation='relu', input_shape=(img_height,img_width,3)))\nmodel.add(layers.MaxPooling2D(2,2))\nmodel.add(layers.Conv2D(64,(3,3), activation='relu', input_shape=(img_height,img_width,3)))\nmodel.add(layers.MaxPooling2D(2,2))\nmodel.add(layers.Dropout(0.2))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(128, activation='relu'))\nmodel.add(layers.Dense(num_classes, activation='softmax'))\n\nmodel.compile(optimizer=optimizers.Adam(),\n             loss='categorical_crossentropy',\n             metrics=['accuracy'])\n\nmodel.summary()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.1 visualizing the model - network architecture"},{"metadata":{"trusted":true},"cell_type":"code","source":"# try:\n#     import visualkeras\n# except:\n#     !pip install visualkeras\n#     import visualkeras\n\n# visualkeras.layered_view(model, draw_volume=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. (again) create the model - yarden's version"},{"metadata":{"trusted":true},"cell_type":"code","source":"# # input_size = X_train.shape[1:]\n# input_size = 32\n# # class_num = y_test.shape[1]\n# class_num = 5\n\n# from keras.models import Sequential\n# from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\n# from keras.layers.convolutional import Conv2D, MaxPooling2D \n\n# model = Sequential()\n\n# model.add(Conv2D(32, (3, 3), input_shape=input_size, padding='same'))\n# model.add(Activation('relu'))\n\n# model.add(Conv2D(32, (3, 3), input_shape=(3, 32, 32), activation='relu', padding='same'))\n# model.add(Dropout(0.2))\n# model.add(BatchNormalization())\n\n# model.add(Conv2D(64, (3, 3), padding='same'))\n# model.add(Activation('relu'))\n\n# model.add(MaxPooling2D(pool_size=(2, 2)))\n# model.add(Dropout(0.2))\n# model.add(BatchNormalization())\n\n# model.add(Conv2D(64, (3, 3), padding='same'))\n# model.add(Activation('relu'))\n# model.add(MaxPooling2D(pool_size=(2, 2)))\n# model.add(Dropout(0.2))\n# model.add(BatchNormalization())\n    \n# model.add(Conv2D(128, (3, 3), padding='same'))\n# model.add(Activation('relu'))\n# model.add(Dropout(0.2))\n# model.add(BatchNormalization())\n\n# model.add(Flatten())\n# model.add(Dropout(0.2))\n\n# model.add(Dense(256, kernel_constraint=maxnorm(3)))\n# model.add(Activation('relu'))\n# model.add(Dropout(0.2))\n# model.add(BatchNormalization())\n    \n# model.add(Dense(128, kernel_constraint=maxnorm(3)))\n# model.add(Activation('relu'))\n# model.add(Dropout(0.2))\n# model.add(BatchNormalization())\n\n# model.add(Dense(class_num))\n# model.add(Activation('softmax'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. training model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# gpu_info = !nvidia-smi\n# gpu_info = '\\n'.join(gpu_info)\n# print(gpu_info)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ENABLE GPU\n\n# device = torch.device('cuda')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs=100\nsteps_per_epoch = 150\n\nhistory = model.fit(\n    train_ds,steps_per_epoch=steps_per_epoch,\n    validation_data=val_ds,validation_steps=steps_per_epoch,\n    epochs=epochs,\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5. evaluating the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6. improving hparams\nlet's now generate random hparams and test each one\nWe'll start by first declaring functions for each purpose"},{"metadata":{},"cell_type":"markdown","source":"### 5.1 function declerations"},{"metadata":{"trusted":true},"cell_type":"code","source":"# def generate_number():\n\n# def generate_layer_type():\n\n# def generate_layer_params(layer_type):\n\n# def generate_layer(layer_type,layer_params):\n\n# def create_model(layers):\n\n# def train_and_eval_model(model):\n\n# def log_score(score):\n\n# def print_score(score):","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## start random hparams generation"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n# best_score = 0\n# while True:\n#     N_layers = generate_number()\n#     layers = []\n#     for i in range(N):\n#         layer_type = generate_layer_type()\n#         layer_params = generate_layer_params(layer_type)\n#         layer = generate_layer(layer_type,layer_params)\n#         layers.append(layer)\n        \n#     model = create_model(layers)\n#     score = train_and_eval_model(model)\n#     log_score(score)\n#     if score>best_score:\n#         print_score(score)\n#         best_score = score\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# epochs = 25\n# optimizer = 'adam'\n\n# model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n\n\n# print(model.summary())\n\n# numpy.random.seed(seed)\n# model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=64)\n\n# # Model evaluation\n# scores = model.evaluate(X_test, y_test, verbose=0)\n# print(\"Accuracy: %.2f%%\" % (scores[1]*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7. submission\n## 7.1 create test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dir = '../input/cassava-leaf-disease-classification/test_images'\n\nfrom keras import preprocessing\n\n\ntest_datagen = preprocessing.image.ImageDataGenerator(rescale=1./255)\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image\nimport numpy as np\nimport pandas as pd\nimport os\n\nss = pd.read_csv(\"../input/cassava-leaf-disease-classification/sample_submission.csv\")\npreds = []\n\nfor image_id in ss.image_id:\n    image = Image.open(os.path.join(test_dir, image_id))\n    image = image.resize((img_height, img_width))\n    image = np.expand_dims(image, axis = 0)\n    preds.append(np.argmax(model.predict(image)))\n\nss['label'] = preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss.to_csv('submission.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}