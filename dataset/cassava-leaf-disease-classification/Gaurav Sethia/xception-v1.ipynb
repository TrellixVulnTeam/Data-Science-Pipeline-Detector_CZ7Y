{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Importing Libraries"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport cv2\nimport json\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.applications import Xception\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Distrubtion of classes"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/cassava-leaf-disease-classification/train.csv')\ndf.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Remove the duplicate image according to discussions"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[~df['image_id'].isin(['1562043567.jpg', '3551135685.jpg', '2252529694.jpg'])]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('/kaggle/input/cassava-leaf-disease-classification/label_num_to_disease_map.json') as f:\n    mapping = json.loads(f.read())\n    print(mapping)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['label'].value_counts().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.pie(df['label'].value_counts(), labels = mapping.values()) \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"def visualize(img_list):\n    rows = 2\n    cols = 4\n\n    plt.figure(figsize=(20, 10))\n\n    for i in range(rows*cols):\n        plt.subplot(10/cols+1, cols, i+1)\n        r = np.random.randint(len(img_list))\n        img_path = \"/kaggle/input/cassava-leaf-disease-classification/train_images/\" + str(img_list[r])\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        #hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n        plt.xticks([])\n        plt.yticks([])\n        plt.title(str(img_list[r]))\n        plt.imshow(img)\n        #plt.imshow(hsv, cmap = 'hsv')\n\n    plt.tight_layout()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualizing Class 0 -> Cassava Bacterial Blight (CBB)\ncbb_df = df[df['label'].isin([0])]\ncbb_img_list = list(df['image_id'])\n\nvisualize(cbb_img_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualizing Class 1 -> Cassava Brown Streak Disease (CBSD)\ncbsd_df = df[df['label'].isin([1])]\ncbsd_img_list = list(df['image_id'])\n\nvisualize(cbsd_img_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualizing Class 2 -> Cassava Green Mottle (CGM)\ncgm_df = df[df['label'].isin([2])]\ncgm_img_list = list(df['image_id'])\n\nvisualize(cgm_img_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualizing Class 3 -> Cassava Mosaic Disease (CMD)\ncmd_df = df[df['label'].isin([3])]\ncmd_img_list = list(df['image_id'])\n\nvisualize(cmd_img_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualizing Class 4 -> Healthy Leaves\nhealthy_df = df[df['label'].isin([4])]\nhealthy_img_list = list(df['image_id'])\n\nvisualize(healthy_img_list)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Defining Hyper Parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 16\nTARGET_SIZE = 299\nBASE_DIR = \"/kaggle/input/cassava-leaf-disease-classification/\"\nEPOCHS = 30","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Augumentations along with Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Defining the preprocessing function\ndef preprocess(image):\n    #Converting to numpy array from numpy tensor with rank 3\n    image = np.array(image, dtype=np.uint8)\n    #Converting to RGB\n    #img = cv2.cvtCoor(img, cv2.COLOR_BGR2RGB)\n    #Gaussian Blur\n    gaussian_blur = cv2.GaussianBlur(image,(5,5),0)\n    img = np.asarray(gaussian_blur, dtype=np.float64)\n    return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Converting labels to string to use sparse class mode\ndf.label = df.label.astype('str')\n\n#Training  Augumentation\ndatagen = ImageDataGenerator(rescale=1.0/255,\n                             featurewise_center=True,\n                             featurewise_std_normalization=True,\n                             rotation_range=30,\n                             width_shift_range=0.3,\n                             height_shift_range=0.3,\n                             shear_range=15.0,\n                             zoom_range=0.3,\n                             horizontal_flip=True,\n                             brightness_range=[0.5, 1.0],\n                             validation_split=0.2,\n                             fill_mode='nearest',\n                             preprocessing_function=preprocess)\n\n\ntrain_datagen = datagen.flow_from_dataframe(df,\n                                            directory = os.path.join(BASE_DIR, \"train_images\"),\n                                            subset = \"training\",\n                                            x_col = \"image_id\",\n                                            y_col = \"label\",\n                                            target_size = (TARGET_SIZE, TARGET_SIZE),\n                                            batch_size = BATCH_SIZE,\n                                            class_mode = \"sparse\")\n\n#Validation\nvalidation_datagen = ImageDataGenerator(rescale=1.0/255,\n                                        validation_split=0.2,\n                                       preprocessing_function=preprocess)\n\n\nvalid_datagen = validation_datagen.flow_from_dataframe(df,\n                                            directory = os.path.join(BASE_DIR, \"train_images\"),\n                                            subset = \"validation\",\n                                            x_col = \"image_id\",\n                                            y_col = \"label\",\n                                            target_size = (TARGET_SIZE, TARGET_SIZE),\n                                            batch_size = BATCH_SIZE,\n                                            class_mode = \"sparse\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Defining the Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"#He Uniform Initializer for Dense Layer\nimport tensorflow as tf\ndef my_init(shape, dtype=None):\n    initializer = tf.keras.initializers.he_uniform(seed = 1)\n    return initializer(shape, dtype=dtype)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model = Xception(weights = 'imagenet', include_top=False, input_shape = (TARGET_SIZE, TARGET_SIZE, 3), pooling=None)\n\nbase_output = base_model.output\npooling_layer = layers.GlobalAveragePooling2D()(base_output)\nDense1 = layers.Dense(128, activation = \"relu\", kernel_initializer=my_init)(pooling_layer)\nBN1 = layers.BatchNormalization()(Dense1)\ndropout = layers.Dropout(0.2)(BN1)\nmodel = layers.Dense(5, activation=\"softmax\")(dropout)\n\nmodel = models.Model(base_model.input, model)\n\nmodel.compile(optimizer = Adam(lr = 0.001), \n              loss = \"sparse_categorical_crossentropy\", \n              metrics=[\"acc\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n\nfilepath = \"model.h5\"\n    \ncallbacks = [ReduceLROnPlateau(monitor='val_loss', patience=1, verbose=1, factor=0.2),\n             EarlyStopping(monitor='val_loss', patience=3),\n             ModelCheckpoint(filepath=filepath, monitor='val_loss', save_best_only=True)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"h = model.fit(train_datagen, epochs = EPOCHS, validation_data = valid_datagen, callbacks=callbacks)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plotting "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use(\"ggplot\")\nplt.figure()\nN = 12\nplt.plot(np.arange(0, N), h.history[\"acc\"], label=\"train_acc\")\nplt.plot(np.arange(0, N), h.history[\"val_acc\"], label=\"val_acc\")\nplt.title(\"Accuracy\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss/Accuracy\")\nplt.legend(loc=\"upper left\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use(\"ggplot\")\nplt.figure()\nN = 12\nplt.plot(np.arange(0, N), h.history[\"loss\"], label=\"train_loss\")\nplt.plot(np.arange(0, N), h.history[\"val_loss\"], label=\"val_loss\")\nplt.title(\"Accuracy\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss/Accuracy\")\nplt.legend(loc=\"upper left\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}