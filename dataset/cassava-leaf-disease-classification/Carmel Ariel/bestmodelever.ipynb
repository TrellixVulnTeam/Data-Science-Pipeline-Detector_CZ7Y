{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## load data and packages\nimport cv2\nimport math, re, os\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nfrom kaggle_datasets import KaggleDatasets\nfrom torch.utils.data import random_split\nfrom torch.utils.data import Dataset, DataLoader\nimport albumentations as albu\nfrom albumentations.pytorch.transforms import ToTensorV2\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\n\n## detect TPU'=\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)\n\n## Set Variabels\nAUTOTUNE = tf.data.experimental.AUTOTUNE\nGCS_PATH = KaggleDatasets().get_gcs_path()\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync\nIMAGE_SIZE = [512, 512]\nCLASSES = np.array(['0', '1', '2', '3', '4'])\nOUTPUT_SIZE = CLASSES.size\nONE_HOT_CLASSES = tf.one_hot(CLASSES.astype(np.float), OUTPUT_SIZE)\nEPOCHS = 25\n\n\n\n\n## load data set\nTRAIN_CSV = \"../input/cassava-leaf-disease-classification/train.csv\"\nTRAIN_IMAGE_FOLDER = '../input/cassava-leaf-disease-classification/train_images'\nsPath = '../input/cassava-leaf-disease-classification/test_images/'\n\n\nclass TrainDataset(Dataset):\n    def _init_(self, train, train_mode=True, transforms=None):\n        self.train = train\n        self.transforms = transforms\n        self.train_mode = train_mode\n\n    def _len_(self):\n        return self.train.shape[0]\n\n    def _getitem_(self, index):\n        image_path = os.path.join(TRAIN_IMAGE_FOLDER, self.train.iloc[index].image_id)\n        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        if (self.transforms):\n            image = self.transforms(image=image)[\"image\"]\n        if not (self.train_mode):\n            return {\"x\": image}\n        return {\n            \"x\": image,\n            \"y\": torch.tensor(self.train.iloc[index, self.train.columns.str.startswith('label')], dtype=torch.float64)\n        }\n\n\nclass TestDataset(Dataset):\n    def _init_(self, test_df, transforms=None):\n        self.test_df = test_df\n        self.transforms = transforms\n\n    def _len_(self):\n        return self.test_df.shape[0]\n\n    def _getitem_(self, index):\n        image_path = os.path.join(sPath, self.test_df.iloc[index].image_id)\n        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        if (self.transforms):\n            image = self.transforms(image=image)[\"image\"]\n        return {\n            \"x\": image\n        }\n\n\n## Adding in augmentations\ndef get_augmentations():\n    mean = (0.485, 0.456, 0.406)\n    std = (0.229, 0.224, 0.225)\n\n    train_augmentations = albu.Compose([\n        albu.RandomResizedCrop(*IMAGE_SIZE, p=1.0),\n        albu.Transpose(p=0.5),\n        albu.HorizontalFlip(p=0.5),\n        albu.VerticalFlip(0.5),\n        albu.Normalize(mean, std, max_pixel_value=255.0, always_apply=True),\n        ToTensorV2(p=1.0)\n    ], p=1.0)\n\n    valid_augmentations = albu.Compose([\n        albu.Resize(*IMAGE_SIZE),\n        albu.Normalize(mean, std, max_pixel_value=255, always_apply=True),\n        ToTensorV2(p=1.0)\n    ], p=1.0)\n\n    return train_augmentations, valid_augmentations\n\n\n## Define data loading methods\ntrain_augs, val_augs = get_augmentations()\n\n\n## Building our model\nlearning_rate = 0.001\n\nclass MyNet(nn.Module):\n\n    def _init_(self):\n        super(MyNet, self)._init_()\n        self.conv1 = nn.Conv2d(3, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(20 * 5 * 5, 50)\n        self.fc2 = nn.Linear(50, OUTPUT_SIZE)\n        self.localization = nn.Sequential(\n            nn.Conv2d(3, 8, kernel_size=7),\n            nn.MaxPool2d(2, stride=2),\n            nn.ReLU(True),\n            nn.Conv2d(8, 10, kernel_size=5),\n            nn.MaxPool2d(2, stride=2),\n            nn.ReLU(True))\n        self.fc_loc = nn.Sequential(\n            nn.Linear(10 * 4 * 4, 32),\n            nn.ReLU(True),\n            nn.Linear(32, 3 * 2))\n        self.fc_loc[2].weight.data.zero_()\n        self.fc_loc[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n\n    def stn(self, x):\n        print(x.size())\n        xs = self.localization(x)\n        xs = xs.view(-1, 10 * 4 * 4)\n        theta = self.fc_loc(xs)\n        theta = theta.view(-1, 2, 3)\n        print(theta.size())\n        grid = F.affine_grid(theta, x.size())\n        x = F.grid_sample(x, grid)\n        return x\n\n    def forward(self, x):\n        x = self.stn(x)\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n        x = x.view(-1, 20 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x, dim=1)\n\n\n# ST\n\nwith strategy.scope():\n    my_net = MyNet()\n    optimizer = torch.optim.Adam(my_net.parameters(), lr=learning_rate, weight_decay=1e-5)\n    loss_fn = nn.CrossEntropyLoss()\n\n\n## load data\ntrainDataFrame = pd.read_csv(TRAIN_CSV)\ntrainDataset = TrainDataset(trainDataFrame, transforms=train_augs)\ntrainData, validationData = random_split(trainDataset, [round(len(trainDataset)*0.8), round(len(trainDataset)*0.2)])\ntrainDataLoader = DataLoader(trainData, batch_size=64,  num_workers=4, shuffle=True)\nvalidationDataLoader = DataLoader(validationData, batch_size=64,  num_workers=4, shuffle=True)\n\ntestDataFrame = pd.DataFrame()\ntestDataFrame['image_id'] = list(os.listdir('../input/cassava-leaf-disease-classification/test_images/'))\ntestDataset = TestDataset(testDataFrame, transforms=val_augs)\ntestDataLoader = DataLoader(testDataset, BATCH_SIZE, num_workers=4, shuffle=False)\n\n\ntraining_results_my_net = np.zeros(len(trainDataLoader) * EPOCHS)\nfor t in range(EPOCHS):\n    for index, data in enumerate(trainDataLoader):\n        x = data.get(\"x\")\n        y = data.get(\"y\")\n        y_pred = my_net(x)\n        loss = loss_fn(y_pred, y)\n        training_results_my_net[t * len(trainDataLoader) + index] = loss.data\n        print(\"my net\", loss.item())\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\nplt.plot(np.arange(len(training_results_my_net)), training_results_my_net)\nplt.ylabel('Training Loss')\nplt.suptitle('My Network Train Loss')\nplt.show()\n\nvalidation_results_my_net = np.zeros(len(validationDataLoader))\nfor index, data in enumerate(validationDataLoader):\n    x = data.get(\"x\")\n    y = data.get(\"y\")\n    y_pred = my_net(x)\n    loss = loss_fn(y_pred, y)\n    validation_results_my_net[index] = loss.data\n\nplt.plot(np.arange(len(validation_results_my_net)), validation_results_my_net)\nplt.ylabel('Validation Loss')\nplt.suptitle('My Network Validation Loss')\nplt.show()\n\ntest_results_my_net = np.zeros(len(testDataLoader))\nfor index, data in enumerate(testDataLoader):\n    x = data.get(\"x\")\n    y = data.get(\"y\")\n    y_pred = my_net(x)\n    loss = loss_fn(y_pred, y)\n    test_results_my_net[index] = loss.data\n\nplt.plot(np.arange(len(test_results_my_net)), test_results_my_net)\nplt.ylabel('Test Loss')\nplt.suptitle('My Network Test Loss')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}