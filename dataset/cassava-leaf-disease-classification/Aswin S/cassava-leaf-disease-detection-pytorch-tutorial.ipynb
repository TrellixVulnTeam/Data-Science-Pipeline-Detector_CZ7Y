{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import Modules","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport time\nimport os\nimport copy\nimport json\n\n# visualization modules\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\n# pytorch modules\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.nn import functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import models\nimport torchvision.transforms as transforms\n\n# augmentation\nimport albumentations\nfrom albumentations.pytorch.transforms import ToTensorV2\n\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:40:15.304922Z","iopub.execute_input":"2022-03-06T08:40:15.305576Z","iopub.status.idle":"2022-03-06T08:40:16.990166Z","shell.execute_reply.started":"2022-03-06T08:40:15.305527Z","shell.execute_reply":"2022-03-06T08:40:16.989481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load the Dataset","metadata":{}},{"cell_type":"code","source":"BASE_DIR = \"../input/cassava-leaf-disease-classification/\"\n\ntrain = pd.read_csv(BASE_DIR+'train.csv')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:40:19.825035Z","iopub.execute_input":"2022-03-06T08:40:19.825639Z","iopub.status.idle":"2022-03-06T08:40:19.863516Z","shell.execute_reply.started":"2022-03-06T08:40:19.825599Z","shell.execute_reply":"2022-03-06T08:40:19.8629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# loading mapping for target label\nwith open(BASE_DIR+'label_num_to_disease_map.json') as f:\n    mapping = json.loads(f.read())\n    mapping = {int(k): v for k, v in mapping.items()}\nmapping","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:40:20.114855Z","iopub.execute_input":"2022-03-06T08:40:20.11557Z","iopub.status.idle":"2022-03-06T08:40:20.129245Z","shell.execute_reply.started":"2022-03-06T08:40:20.115533Z","shell.execute_reply":"2022-03-06T08:40:20.12848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['label_names'] = train['label'].map(mapping)\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:40:20.35724Z","iopub.execute_input":"2022-03-06T08:40:20.357939Z","iopub.status.idle":"2022-03-06T08:40:20.378982Z","shell.execute_reply.started":"2022-03-06T08:40:20.3579Z","shell.execute_reply":"2022-03-06T08:40:20.378283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"def plot_images(class_id, label, total_images=6):\n    # get image ids corresponding to the target class id\n    plot_list = train[train['label']==class_id].sample(total_images)['image_id'].tolist()\n    \n    labels = [label for i in range(total_images)]\n    # dynamically set size for subplot\n    size = int(np.sqrt(total_images))\n    if size*size < total_images:\n        size += 1\n    \n    # set figure size\n    plt.figure(figsize=(15,15))\n    \n    # plot the image in subplot\n    for index, (image_id, label) in enumerate(zip(plot_list, labels)):\n        plt.subplot(size, size, index+1)\n        image = Image.open(str(BASE_DIR+'train_images/'+image_id))\n        plt.imshow(image)\n        plt.title(label, fontsize=14)\n        plt.axis('off')\n        \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:40:20.939994Z","iopub.execute_input":"2022-03-06T08:40:20.940267Z","iopub.status.idle":"2022-03-06T08:40:20.957075Z","shell.execute_reply.started":"2022-03-06T08:40:20.940236Z","shell.execute_reply":"2022-03-06T08:40:20.956119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_images(0, mapping[0], 6)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:40:21.203858Z","iopub.execute_input":"2022-03-06T08:40:21.20426Z","iopub.status.idle":"2022-03-06T08:40:22.233815Z","shell.execute_reply.started":"2022-03-06T08:40:21.204218Z","shell.execute_reply":"2022-03-06T08:40:22.231531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_images(1, mapping[1], 6)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:40:22.235222Z","iopub.execute_input":"2022-03-06T08:40:22.236009Z","iopub.status.idle":"2022-03-06T08:40:23.176958Z","shell.execute_reply.started":"2022-03-06T08:40:22.235972Z","shell.execute_reply":"2022-03-06T08:40:23.176354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_images(2, mapping[2], 6)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:40:23.178237Z","iopub.execute_input":"2022-03-06T08:40:23.178691Z","iopub.status.idle":"2022-03-06T08:40:23.972093Z","shell.execute_reply.started":"2022-03-06T08:40:23.178655Z","shell.execute_reply":"2022-03-06T08:40:23.971504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_images(3, mapping[3], 6)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:40:23.973815Z","iopub.execute_input":"2022-03-06T08:40:23.974154Z","iopub.status.idle":"2022-03-06T08:40:24.770809Z","shell.execute_reply.started":"2022-03-06T08:40:23.974124Z","shell.execute_reply":"2022-03-06T08:40:24.769113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_images(4, mapping[4], 6)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:40:24.772324Z","iopub.execute_input":"2022-03-06T08:40:24.77277Z","iopub.status.idle":"2022-03-06T08:40:25.588493Z","shell.execute_reply.started":"2022-03-06T08:40:24.772736Z","shell.execute_reply":"2022-03-06T08:40:25.587869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# class distribution\nsns.countplot(train['label_names'])\nplt.xticks(rotation=90)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:40:25.589656Z","iopub.execute_input":"2022-03-06T08:40:25.589985Z","iopub.status.idle":"2022-03-06T08:40:25.816641Z","shell.execute_reply.started":"2022-03-06T08:40:25.589956Z","shell.execute_reply":"2022-03-06T08:40:25.815966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Configuration and Utility Functions","metadata":{}},{"cell_type":"code","source":"DIM = (256, 256)\nWIDTH, HEIGHT = DIM\nNUM_CLASSES = 5\nNUM_WORKERS = 24\nTRAIN_BATCH_SIZE = 32\nTEST_BATCH_SIZE = 32\nSEED = 1\n\nDEVICE = 'cuda'\n\nMEAN = [0.485, 0.456, 0.406]\nSTD = [0.229, 0.224, 0.225]","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:40:25.817782Z","iopub.execute_input":"2022-03-06T08:40:25.818319Z","iopub.status.idle":"2022-03-06T08:40:25.824451Z","shell.execute_reply.started":"2022-03-06T08:40:25.818277Z","shell.execute_reply":"2022-03-06T08:40:25.82365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Augmentations","metadata":{}},{"cell_type":"code","source":"def get_test_transforms(value = 'val'):\n    if value == 'train':\n        return albumentations.Compose([\n            albumentations.Resize(WIDTH, HEIGHT),\n            albumentations.HorizontalFlip(p=0.5),\n            albumentations.Rotate(limit=(-90, 90)),\n            albumentations.VerticalFlip(p=0.5),\n            albumentations.Normalize(MEAN, STD, max_pixel_value=255.0, always_apply=True),\n            ToTensorV2(p=1.0)\n        ])\n    elif value == 'val':\n        return albumentations.Compose([\n            albumentations.Resize(WIDTH, HEIGHT),\n            albumentations.Normalize(MEAN, STD, max_pixel_value=255.0, always_apply=True),\n            ToTensorV2(p=1.0)\n        ])","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:40:25.827132Z","iopub.execute_input":"2022-03-06T08:40:25.827345Z","iopub.status.idle":"2022-03-06T08:40:25.834Z","shell.execute_reply.started":"2022-03-06T08:40:25.827322Z","shell.execute_reply":"2022-03-06T08:40:25.833348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset Loader Class","metadata":{}},{"cell_type":"code","source":"class CassavaDataset(Dataset):\n    def __init__(self, image_ids, labels, dimension=None, augmentations=None, folder='train_images'):\n        super().__init__()\n        self.image_ids = image_ids\n        self.labels = labels\n        self.dim = dimension\n        self.augmentations = augmentations\n        self.folder = folder\n    \n    # returns the length\n    def __len__(self):\n        return len(self.image_ids)\n    \n    # return the image and label for that index\n    def __getitem__(self, idx):\n        img = Image.open(os.path.join(BASE_DIR, self.folder, self.image_ids[idx]))\n        \n        if self.dim:\n            img = img.resize(self.dim)\n        \n        # convert to numpy array\n        img = np.array(img)\n        \n        if self.augmentations:\n            augmented = self.augmentations(image=img)\n            img = augmented['image']\n        \n        label = torch.tensor(self.labels[idx], dtype=torch.long)\n        return img, label","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:40:25.836162Z","iopub.execute_input":"2022-03-06T08:40:25.8366Z","iopub.status.idle":"2022-03-06T08:40:25.846059Z","shell.execute_reply.started":"2022-03-06T08:40:25.836564Z","shell.execute_reply":"2022-03-06T08:40:25.845255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train Test Split","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(train['image_id'], train['label'], test_size=0.25)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:40:25.847288Z","iopub.execute_input":"2022-03-06T08:40:25.847595Z","iopub.status.idle":"2022-03-06T08:40:25.858661Z","shell.execute_reply.started":"2022-03-06T08:40:25.84756Z","shell.execute_reply":"2022-03-06T08:40:25.857921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import WeightedRandomSampler\ndef sampler_(labels):\n    label_unique, counts = np.unique(labels, return_counts=True)\n    print('Unique Labels', label_unique)\n    weights = [sum(counts) / c for c in counts]\n    sample_weights = [weights[w] for w in labels]\n    sampler = WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)\n    return sampler","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:40:25.861415Z","iopub.execute_input":"2022-03-06T08:40:25.861628Z","iopub.status.idle":"2022-03-06T08:40:25.867382Z","shell.execute_reply.started":"2022-03-06T08:40:25.861605Z","shell.execute_reply":"2022-03-06T08:40:25.866644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_sampler = sampler_(y_train)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:40:25.940272Z","iopub.execute_input":"2022-03-06T08:40:25.940495Z","iopub.status.idle":"2022-03-06T08:40:25.952772Z","shell.execute_reply.started":"2022-03-06T08:40:25.940449Z","shell.execute_reply":"2022-03-06T08:40:25.952005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create dataloaders for training antrain_test_splitidation\ntrain_dataset = CassavaDataset(\n    image_ids=x_train.values,\n    labels=y_train.values,\n    augmentations=get_test_transforms('train'),\n    dimension=DIM\n)\n\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=TRAIN_BATCH_SIZE,\n    num_workers=NUM_WORKERS,\n    shuffle=False,\n    sampler=train_sampler\n)\n\nval_dataset = CassavaDataset(\n    image_ids=x_test.values,\n    labels=y_test.values,\n    augmentations=get_test_transforms('val'),\n    dimension=DIM\n)\n\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=TRAIN_BATCH_SIZE,\n    num_workers=NUM_WORKERS,\n    shuffle=False\n)\n\nloaders = {'train': train_loader, 'val': val_loader}","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:40:29.54892Z","iopub.execute_input":"2022-03-06T08:40:29.549181Z","iopub.status.idle":"2022-03-06T08:40:29.55758Z","shell.execute_reply.started":"2022-03-06T08:40:29.549153Z","shell.execute_reply":"2022-03-06T08:40:29.556433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# to check whether dataset is working or not\n# fetch the data based on index\nval_dataset[0]","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:40:31.433658Z","iopub.execute_input":"2022-03-06T08:40:31.434182Z","iopub.status.idle":"2022-03-06T08:40:31.51899Z","shell.execute_reply.started":"2022-03-06T08:40:31.434146Z","shell.execute_reply":"2022-03-06T08:40:31.518269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Use Pretrained Model (Transfer Learning)","metadata":{}},{"cell_type":"code","source":"def getModel():\n    net = models.resnet152(pretrained=True)\n    \n    # if you want to train the whole network, comment this code\n    # freeze all the layers in the network\n    for param in net.parameters():\n        param.requires_grad = False\n        \n    num_ftrs = net.fc.in_features\n    # create last few layers\n    net.fc = nn.Sequential(\n        nn.Linear(num_ftrs, 256),\n        nn.ReLU(),\n        nn.Dropout(0.3),\n        nn.Linear(256, NUM_CLASSES),\n        nn.LogSoftmax(dim=1)\n    )\n    \n    # use gpu if any\n    net = net.cuda() if DEVICE else net\n    return net","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:40:34.266038Z","iopub.execute_input":"2022-03-06T08:40:34.266289Z","iopub.status.idle":"2022-03-06T08:40:34.271908Z","shell.execute_reply.started":"2022-03-06T08:40:34.266263Z","shell.execute_reply":"2022-03-06T08:40:34.271251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = getModel()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:40:35.425766Z","iopub.execute_input":"2022-03-06T08:40:35.426288Z","iopub.status.idle":"2022-03-06T08:40:45.863243Z","shell.execute_reply.started":"2022-03-06T08:40:35.426251Z","shell.execute_reply":"2022-03-06T08:40:45.862517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math\ndef cyclical_lr(stepsize, min_lr=3e-4, max_lr=3e-3):\n\n    # Scaler: we can adapt this if we do not want the triangular CLR\n    scaler = lambda x: 1.\n\n    # Lambda function to calculate the LR\n    lr_lambda = lambda it: min_lr + (max_lr - min_lr) * relative(it, stepsize)\n\n    # Additional function to see where on the cycle we are\n    def relative(it, stepsize):\n        cycle = math.floor(1 + it / (2 * stepsize))\n        x = abs(it / stepsize - 2 * cycle + 1)\n        return max(0, (1 - x)) * scaler(cycle)\n\n    return lr_lambda","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:40:45.865869Z","iopub.execute_input":"2022-03-06T08:40:45.866304Z","iopub.status.idle":"2022-03-06T08:40:45.872925Z","shell.execute_reply.started":"2022-03-06T08:40:45.866265Z","shell.execute_reply":"2022-03-06T08:40:45.872055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\n# optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\noptimizer = torch.optim.SGD(model.parameters(), lr=1., momentum=0.9)\nstep_size = 4*len(train_loader)\nclr = cyclical_lr(step_size, min_lr=3e-4, max_lr=3e-3)\nscheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, [clr])","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:40:45.875515Z","iopub.execute_input":"2022-03-06T08:40:45.875727Z","iopub.status.idle":"2022-03-06T08:40:45.892389Z","shell.execute_reply.started":"2022-03-06T08:40:45.875702Z","shell.execute_reply":"2022-03-06T08:40:45.8918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(model)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:40:45.895655Z","iopub.execute_input":"2022-03-06T08:40:45.896211Z","iopub.status.idle":"2022-03-06T08:40:45.901307Z","shell.execute_reply.started":"2022-03-06T08:40:45.896179Z","shell.execute_reply":"2022-03-06T08:40:45.9006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# freeze (or) unfreeze all the layers\nunfreeze = True # to freeze, set it as False\nfor param in model.parameters():\n    param.requires_grad = unfreeze","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:40:45.902977Z","iopub.execute_input":"2022-03-06T08:40:45.903761Z","iopub.status.idle":"2022-03-06T08:40:45.911377Z","shell.execute_reply.started":"2022-03-06T08:40:45.903725Z","shell.execute_reply":"2022-03-06T08:40:45.910703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# find total parameters and trainable parameters\ntotal_params = sum(p.numel() for p in model.parameters())\nprint(f'{total_params:,} total parameters')\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(f'{trainable_params:,} training parameters')","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:40:45.912713Z","iopub.execute_input":"2022-03-06T08:40:45.913272Z","iopub.status.idle":"2022-03-06T08:40:45.92594Z","shell.execute_reply.started":"2022-03-06T08:40:45.913236Z","shell.execute_reply":"2022-03-06T08:40:45.925123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Steps for Training and Validation","metadata":{}},{"cell_type":"code","source":"def train_model(model, dataloaders, criterion, optimizer, num_epochs=5, scheduler=scheduler):\n    # set starting time\n    start_time = time.time()\n    \n    val_acc_history = []\n    \n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    \n    for epoch in range(num_epochs):\n        print(f'Epoch {epoch}/{num_epochs-1}')\n        print('-'*15)\n        \n        # each epoch have training and validation phase\n        for phase in ['train', 'val']:\n            # set mode for model\n            if phase == 'train':\n                model.train() # set model to training mode\n            else:\n                model.eval() # set model to evaluate mode\n                \n            running_loss = 0.0\n            running_corrects = 0\n            fin_out = []\n            \n            # iterate over data\n            for inputs, labels in dataloaders[phase]:\n                # move data to corresponding hardware\n                inputs = inputs.to(DEVICE)\n                labels = labels.to(DEVICE)\n                \n                # reset (or) zero the parameter gradients\n                optimizer.zero_grad()\n                \n                # training (or) validation process\n                with torch.set_grad_enabled(phase=='train'):\n                    outputs = model(inputs)\n                    loss = criterion(outputs, labels)\n                    \n                    _, preds = torch.max(outputs, 1)\n                    \n                    # back propagation in the network\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n                        scheduler.step()\n                        \n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n                \n            # calculate loss and accuarcy for the epoch\n            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n            \n            # print loss and acc for training & validation\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n            \n            # update the best weights\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n            if phase == 'val':\n                val_acc_history.append(epoch_acc)\n                \n        print()\n    end_time = time.time() - start_time\n    \n    print('Training completes in {:.0f}m {:.0f}s'.format(end_time // 60, end_time % 60))\n    print('Best Val Acc: {:.4f}'.format(best_acc))\n    \n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model, val_acc_history","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:40:46.621516Z","iopub.execute_input":"2022-03-06T08:40:46.622018Z","iopub.status.idle":"2022-03-06T08:40:46.634877Z","shell.execute_reply.started":"2022-03-06T08:40:46.62198Z","shell.execute_reply":"2022-03-06T08:40:46.633913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train the model\nmodel, accuracy = train_model(model=model, dataloaders=loaders, criterion=criterion, optimizer=optimizer, num_epochs=5, scheduler=scheduler)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T08:40:48.754832Z","iopub.execute_input":"2022-03-06T08:40:48.755589Z","iopub.status.idle":"2022-03-06T09:11:42.654722Z","shell.execute_reply.started":"2022-03-06T08:40:48.755537Z","shell.execute_reply":"2022-03-06T09:11:42.653879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# save the model and model weights\ntorch.save(model, '/kaggle/working/best_model.h5')\ntorch.save(model.state_dict(), '/kaggle/working/best_model_weights')","metadata":{"execution":{"iopub.status.busy":"2022-01-01T14:12:27.165154Z","iopub.execute_input":"2022-01-01T14:12:27.165516Z","iopub.status.idle":"2022-01-01T14:12:28.163537Z","shell.execute_reply.started":"2022-01-01T14:12:27.16548Z","shell.execute_reply":"2022-01-01T14:12:28.162402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# freeze (or) unfreeze all the layers\nunfreeze = True # to freeze, set it as False\nfor param in model.parameters():\n    param.requires_grad = unfreeze","metadata":{"execution":{"iopub.status.busy":"2022-01-01T15:50:56.349245Z","iopub.execute_input":"2022-01-01T15:50:56.349914Z","iopub.status.idle":"2022-01-01T15:50:56.360381Z","shell.execute_reply.started":"2022-01-01T15:50:56.349875Z","shell.execute_reply":"2022-01-01T15:50:56.359292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # unfreeze seleected layers\n# layers = list(range(5,7))\n# i = 0\n# for layer in model.children():\n#     if i in layers:\n#         for param in layer.parameters():\n#             param.requires_grad = True\n#     i += 1","metadata":{"execution":{"iopub.status.busy":"2022-01-01T14:53:29.042309Z","iopub.execute_input":"2022-01-01T14:53:29.042946Z","iopub.status.idle":"2022-01-01T14:53:29.053886Z","shell.execute_reply.started":"2022-01-01T14:53:29.042908Z","shell.execute_reply":"2022-01-01T14:53:29.04993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# find total parameters and trainable parameters\ntotal_params = sum(p.numel() for p in model.parameters())\nprint(f'{total_params:,} total parameters')\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(f'{trainable_params:,} training parameters')","metadata":{"execution":{"iopub.status.busy":"2022-01-01T15:26:36.514006Z","iopub.execute_input":"2022-01-01T15:26:36.514313Z","iopub.status.idle":"2022-01-01T15:26:36.527036Z","shell.execute_reply.started":"2022-01-01T15:26:36.514279Z","shell.execute_reply":"2022-01-01T15:26:36.525698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # gives the number of layers\n# for i,layer in enumerate(model.children()):\n#     print(i)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T15:26:39.983821Z","iopub.execute_input":"2022-01-01T15:26:39.984432Z","iopub.status.idle":"2022-01-01T15:26:39.988823Z","shell.execute_reply.started":"2022-01-01T15:26:39.984394Z","shell.execute_reply":"2022-01-01T15:26:39.987547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testing the Model","metadata":{}},{"cell_type":"code","source":"# empty the cache from cuda device\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T09:13:11.079307Z","iopub.execute_input":"2022-03-06T09:13:11.079828Z","iopub.status.idle":"2022-03-06T09:13:11.388851Z","shell.execute_reply.started":"2022-03-06T09:13:11.079788Z","shell.execute_reply":"2022-03-06T09:13:11.387896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(model, dataloader, device):\n    # set mode to eval\n    model.eval()\n    fin_out = []\n    \n    with torch.no_grad():\n        for images, targets in dataloader:\n            images = images.to(device)\n            targets = targets.to(device)\n            \n            outputs = model(images)\n            \n            fin_out.append(F.softmax(outputs, dim=1).detach().cpu().numpy())\n            \n    return np.concatenate(fin_out)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T09:13:12.264444Z","iopub.execute_input":"2022-03-06T09:13:12.264844Z","iopub.status.idle":"2022-03-06T09:13:12.270752Z","shell.execute_reply.started":"2022-03-06T09:13:12.26481Z","shell.execute_reply":"2022-03-06T09:13:12.26976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# steps for model prediction\ndevice = torch.device('cuda') # if you don't have gpu, set it as cpu\nmodel.to(device)\npred = predict(model, val_loader, device)\npred = pred.argmax(axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T09:13:13.450058Z","iopub.execute_input":"2022-03-06T09:13:13.450752Z","iopub.status.idle":"2022-03-06T09:14:27.083674Z","shell.execute_reply.started":"2022-03-06T09:13:13.450714Z","shell.execute_reply":"2022-03-06T09:14:27.08268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test.values[:5]","metadata":{"execution":{"iopub.status.busy":"2022-03-06T09:14:27.085877Z","iopub.execute_input":"2022-03-06T09:14:27.086151Z","iopub.status.idle":"2022-03-06T09:14:27.09226Z","shell.execute_reply.started":"2022-03-06T09:14:27.086113Z","shell.execute_reply":"2022-03-06T09:14:27.091634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred[:5]","metadata":{"execution":{"iopub.status.busy":"2022-03-06T09:14:27.093592Z","iopub.execute_input":"2022-03-06T09:14:27.094048Z","iopub.status.idle":"2022-03-06T09:14:27.104661Z","shell.execute_reply.started":"2022-03-06T09:14:27.094011Z","shell.execute_reply":"2022-03-06T09:14:27.103986Z"},"trusted":true},"execution_count":null,"outputs":[]}]}