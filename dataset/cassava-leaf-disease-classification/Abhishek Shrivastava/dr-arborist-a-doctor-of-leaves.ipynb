{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('../input/cassava-leaf-disease-classification'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## import all necessary libraries required for this project\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime\nimport os \nimport torchvision\nimport albumentations as A\nimport os\nfrom pathlib import Path\nfrom tqdm import tqdm\nimport plotly.graph_objects as go\nimport plotly_express as px\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\nimport matplotlib.pyplot as plt\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport tensorflow as tf\nfrom tensorflow.keras import models, layers\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.applications import EfficientNetB3\nfrom tensorflow.keras.optimizers import Adam\nimport warnings\nwarnings.simplefilter(\"ignore\")\nimport os, cv2, json\nfrom PIL import Image\nfrom tensorflow.keras.layers import Flatten,LSTM, Dense, Flatten, Embedding \nfrom tensorflow.keras.preprocessing.sequence import pad_sequences \nfrom tensorflow.keras.utils import to_categorical \nfrom tensorflow.keras.models import Sequential \nfrom keras_preprocessing.text import Tokenizer \nfrom keras.initializers import glorot_uniform \nfrom sklearn import model_selection\n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### locate the files required for analysis\nWORK_DIR = '../input/cassava-leaf-disease-classification'\nos.listdir(WORK_DIR)\nprint('Train images: %d' %len(os.listdir(\n    os.path.join(WORK_DIR, \"train_images\"))))\n\nwith open(os.path.join(WORK_DIR, \"label_num_to_disease_map.json\")) as file:\n    print(json.dumps(json.loads(file.read()), indent=4))\n    \ntrain_labels = pd.read_csv(os.path.join(WORK_DIR, \"train.csv\"))\ntrain_labels.head()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### Define the constants/hyperparameter\nBATCH_SIZE = 8\nSTEPS_PER_EPOCH = len(train_labels)*0.8 / BATCH_SIZE\nVALIDATION_STEPS = len(train_labels)*0.2 / BATCH_SIZE\nEPOCHS = 20\nTARGET_SIZE = 350","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Define paths required.\nbase_path = Path('../input/cassava-leaf-disease-classification')\ntrain_img_dir = base_path /'train_images'\ntest_img_dir = base_path /'test_images'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Define the dataframes\ntrain_df = pd.read_csv(base_path/'train.csv')\ndiseaseMapping = pd.read_json(base_path/'label_num_to_disease_map.json', typ='series')\n\ntrain_images = os.listdir(base_path/'train_images/')\ntest_images = os.listdir(base_path/'test_images/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diseaseMapping","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mappingDict = diseaseMapping.to_dict()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Start understanding of data\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train_df.replace(mappingDict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Visualisation of each disease\nlabelCounts = train_df['label'].value_counts().reset_index()\nlabelCounts.columns = ['Label', 'Number of Observations']\n\nfig = px.pie(labelCounts, names = 'Label',values='Number of Observations', labels = mappingDict, color_discrete_sequence=px.colors.sequential.YlOrBr)\n\n\nfig.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"uniqueIds = train_df['image_id'].nunique()\nif(uniqueIds == len(train_df)):\n    print('There are no repeating Image IDs in the dataset')\nelse:\n    print(f'There are {len(train_df) - uniqueIds} repeating Image IDs')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(train_images))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"healthyImages = train_df[train_df['label'] == 'Healthy']['image_id'].to_list()\ncbbImages = train_df[train_df['label'] == 'Cassava Bacterial Blight (CBB)']['image_id'].to_list()\ncbsdImages = train_df[train_df['label'] == 'Cassava Brown Streak Disease (CBSD)']['image_id'].to_list()\ncgmImages = train_df[train_df['label'] == 'Cassava Green Mottle (CGM)']['image_id'].to_list()\ncmdImages = train_df[train_df['label'] == 'Cassava Mosaic Disease (CMD)']['image_id'].to_list()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def showImages(images):\n\n    # Extract 9 random images from it\n    random_images = [np.random.choice(images) for i in range(9)]\n\n    # Adjust the size of your images\n    plt.figure(figsize=(10,8))\n\n    # Iterate and plot random images\n    for i in range(9):\n        plt.subplot(3, 3, i + 1)\n        img = plt.imread(train_img_dir/random_images[i])\n        plt.imshow(img, cmap='gray')\n        plt.axis('off')\n\n    # Adjust subplot parameters to give specified padding\n    plt.tight_layout()   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def showHistogram(sample_img, title):\n    f = plt.figure(figsize=(16,8))\n    f.add_subplot(1,2, 1)\n\n    raw_image = plt.imread(train_img_dir/sample_img)\n    plt.imshow(raw_image, cmap='gray')\n    plt.colorbar()\n    plt.title(title)\n    print(f\"Image dimensions:  {raw_image.shape[0],raw_image.shape[1]}\")\n    print(f\"Maximum pixel value : {raw_image.max():.1f} ; Minimum pixel value:{raw_image.min():.1f}\")\n    print(f\"Mean value of the pixels : {raw_image.mean():.1f} ; Standard deviation : {raw_image.std():.1f}\")\n\n    f.add_subplot(1,2, 2)\n\n    #_ = plt.hist(raw_image.ravel(),bins = 256, color = 'orange',)\n    _ = plt.hist(raw_image[:, :, 0].ravel(), bins = 256, color = 'red', alpha = 0.5)\n    _ = plt.hist(raw_image[:, :, 1].ravel(), bins = 256, color = 'Green', alpha = 0.5)\n    _ = plt.hist(raw_image[:, :, 2].ravel(), bins = 256, color = 'Blue', alpha = 0.5)\n    _ = plt.xlabel('Intensity Value')\n    _ = plt.ylabel('Count')\n    _ = plt.legend(['Red_Channel', 'Green_Channel', 'Blue_Channel'])\n    plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_image(image_id):\n    image = cv2.imread(str(train_img_dir/image_id))\n    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\ndef showChannelDistribution(images, leafType):\n    imageArray = [load_image(image_id) for image_id in images]\n    image\n    red_values = [np.mean(imageArray[idx][:, :, 0]) for idx in range(len(imageArray))]\n    green_values = [np.mean(imageArray[idx][:, :, 1]) for idx in range(len(imageArray))]\n    blue_values = [np.mean(imageArray[idx][:, :, 2]) for idx in range(len(imageArray))]\n    values = [np.mean(imageArray[idx]) for idx in range(len(imageArray))]\n    \n    hist_data = [red_values, green_values, blue_values, values]\n    group_labels = ['Red', 'Green', 'Blue', 'All']\n\n    fig = ff.create_distplot(hist_data, group_labels,colors = ['red', 'green','blue','grey'])\n    fig.update_layout(template = 'plotly_white', title_text = f'Channel Distribution - {leafType}')\n    fig.show()\n    return hist_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def showBoxPlot(histData, leafType):\n    figData = []\n    for i, name in zip(range(3), ['Red', 'Green', 'Blue']):\n        trace = go.Box(y = histData[i], name = name, boxpoints='all', marker_color  = name)\n        figData.append(trace)\n\n    fig = go.Figure(figData)\n    fig.update_layout(title_text = f'Pixel Intensity Distribution - {leafType}', template = 'plotly_white')\n    fig.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"showImages(healthyImages)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"showHistogram(healthyImages[0], 'Healthy Image')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = showChannelDistribution(healthyImages, 'Healthy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"showBoxPlot(data, 'Healthy Leaves')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"showImages(cbbImages)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"showHistogram(cbbImages[0], 'CBB Image')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = showChannelDistribution(cbbImages, 'CBB Images')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"showBoxPlot(data, 'CBB Images')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"showImages(cbsdImages)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"showHistogram(cbsdImages[0], 'CBSD Image')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = showChannelDistribution(cbsdImages, 'CBSD Images')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"showImages(cgmImages)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"showHistogram(cgmImages[0], 'CGM Image')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = showChannelDistribution(cgmImages, 'CGM Images')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"showBoxPlot(data, 'CGM Images')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"showImages(cmdImages)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"showHistogram(cmdImages[0], 'CMD Image')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = showChannelDistribution(cmdImages[:2000], 'CMD Images')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"showBoxPlot(data, 'CMD Images')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"channelIntensityDf = pd.DataFrame(\n    {\n        'Leaf Type' : ['Healthy', 'CBB','CBSD', 'CGM', 'CMD'], \n        'Red Channel Mean' : [108,102,106,113,110],\n        'Green Channel Mean' : [126,117,123,128,128],\n        'Blue Channel Mean' : [80,66,72,85,80]\n    }\n)\n\nchannelIntensityDf.style.background_gradient(cmap='Greens', axis = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels.label = train_labels.label.astype('str')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(validation_split = 0.2,\n                                     preprocessing_function = None,\n                                     rotation_range = 45,\n                                     zoom_range = 0.2,\n                                     horizontal_flip = True,\n                                     vertical_flip = True,\n                                     fill_mode = 'nearest',\n                                     shear_range = 0.1,\n                                     height_shift_range = 0.1,\n                                     width_shift_range = 0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = train_datagen.flow_from_dataframe(train_labels,\n                         directory = os.path.join(WORK_DIR, \"train_images\"),\n                         subset = \"training\",\n                         x_col = \"image_id\",\n                         y_col = \"label\",\n                         target_size = (TARGET_SIZE, TARGET_SIZE),\n                         batch_size = BATCH_SIZE,\n                         class_mode = \"sparse\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_datagen = ImageDataGenerator(validation_split = 0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_generator = validation_datagen.flow_from_dataframe(train_labels,\n                         directory = os.path.join(WORK_DIR, \"train_images\"),\n                         subset = \"validation\",\n                         x_col = \"image_id\",\n                         y_col = \"label\",\n                         target_size = (TARGET_SIZE, TARGET_SIZE),\n                         batch_size = BATCH_SIZE,\n                         class_mode = \"sparse\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model():\n    conv_base = EfficientNetB3(include_top = False, weights = None,\n                               input_shape = (TARGET_SIZE, TARGET_SIZE, 3))\n    model = conv_base.output\n    model = layers.GlobalAveragePooling2D()(model)\n    model = layers.Dense(5, activation = \"softmax\")(model)\n    model = models.Model(conv_base.input, model)\n\n    model.compile(optimizer = Adam(lr = 0.001),\n                  loss = \"sparse_categorical_crossentropy\",\n                  metrics = [\"acc\"])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = create_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('./EffNetB0_512_8.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Our EfficientNet CNN has %d layers' %len(model.layers))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss = pd.read_csv(os.path.join(WORK_DIR, \"sample_submission.csv\"))\nss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = []\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for image_id in ss.image_id:\n    image = Image.open(os.path.join(WORK_DIR,  \"test_images\", image_id))\n    image = image.resize((TARGET_SIZE, TARGET_SIZE))\n    image = np.expand_dims(image, axis = 0)\n    preds.append(np.argmax(model.predict(image)))\n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predict = model.predict(image)\ny_predict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#preds = np.round(preds,4)\n\nprint(\"prediction is :\", preds)\n\n#my_submission = pd.DataFrame(preds, columns=['image_id', 'label'])\n#submission.label = preds\n#my_submission.to_csv('submission.csv', index=False)\n#submission.to_csv('submission.csv', index=False)\n\n#image_names = [img_name.numpy().decode('utf-8') for img, img_name in iter(test_images.unbatch())]\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = {'image_id' : image_id, 'label' : preds}\n#print(df)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#my_submission = pd.DataFrame(df)\n#print(my_submission)\n#my_submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ss = pd.DataFrame(df)\n#ss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import load_model\nprev_model = load_model('EffNetB0_512_8.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_model = Sequential()\ntop_model.add(Embedding(TARGET_SIZE, 20, input_length=TARGET_SIZE)) \ntop_model.add(LSTM(32,dropout=0.2, recurrent_dropout=0.2)) \ntop_model.add(Dense(1, activation='sigmoid'))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import Model\nmodel_new = Model(inputs=prev_model.input, outputs=top_model(prev_model.output))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_new.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc']) \nprint(model_new.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_new =[]\nfor image_id in ss.image_id:\n    image = Image.open(os.path.join(WORK_DIR,  \"test_images\", image_id))\n    image = image.resize((TARGET_SIZE, TARGET_SIZE))\n    image = np.expand_dims(image, axis = 0)\n    pred_new.append(np.argmax(model_new.predict(image)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"prediction is :\", pred_new)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predict_new = model_new.predict(image)\ny_predict_new","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#my_submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss[\"label\"] = pred_new\nss.to_csv('submission.csv', index=False)\n\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}