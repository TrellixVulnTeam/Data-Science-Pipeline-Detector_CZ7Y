{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\n\nimport albumentations as A\nimport cv2\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nimport torch.optim as optim\n\nfrom tqdm.notebook import tqdm\nfrom torch.utils.data import Dataset, DataLoader\nfrom albumentations.pytorch import ToTensorV2\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import KFold, StratifiedKFold\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nimport warnings  \nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"DIR_INPUT = '/kaggle/input/cassava-leaf-disease-classification'\nDIR_WEIGHTS = '/kaggle/input/cassava-pytorch-starter-train'\n\nSEED = 42\nN_FOLDS = 5\nBATCH_SIZE = 64\nSIZE = 256","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CassavaDataset(Dataset):\n    \n    def __init__(self, df, dataset='train', transforms=None):\n    \n        self.df = df\n        self.transforms=transforms\n        self.dataset=dataset\n        \n    def __len__(self):\n        return self.df.shape[0]\n    \n    def __getitem__(self, idx):\n        image_src = f'{DIR_INPUT}/{self.dataset}_images/{self.df.loc[idx, \"image_id\"]}'\n        # print(image_src)\n        image = cv2.imread(image_src, cv2.IMREAD_COLOR)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.transforms:\n            transformed = self.transforms(image=image)\n            image = transformed['image']\n\n        return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CassavaModel(nn.Module):\n    \n    def __init__(self, num_classes=5):\n        super().__init__()\n        \n        self.backbone = torchvision.models.resnet18(pretrained=False)\n        \n        in_features = self.backbone.fc.in_features\n\n        self.logit = nn.Linear(in_features, num_classes)\n        \n    def forward(self, x):\n        batch_size, C, H, W = x.shape\n        \n        x = self.backbone.conv1(x)\n        x = self.backbone.bn1(x)\n        x = self.backbone.relu(x)\n        x = self.backbone.maxpool(x)\n\n        x = self.backbone.layer1(x)\n        x = self.backbone.layer2(x)\n        x = self.backbone.layer3(x)\n        x = self.backbone.layer4(x)\n        \n        x = F.adaptive_avg_pool2d(x,1).reshape(batch_size,-1)\n        x = F.dropout(x, 0.25, self.training)\n\n        x = self.logit(x)\n\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transforms_test = A.Compose([\n    A.Resize(height=SIZE, width=SIZE, p=1.0),\n    A.Normalize(p=1.0),\n    ToTensorV2(p=1.0),\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df = pd.read_csv(DIR_INPUT + '/sample_submission.csv')\nsubmission_df.iloc[:, 1] = 0\n\nsubmission_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if submission_df.shape[0] == 1:\n    submission_df = pd.DataFrame([{'image_id': '2216849948.jpg', 'label': 0},{'image_id': '2216849948.jpg', 'label': 0}])\n    submission_df.reset_index(drop=True, inplace=True)\n\nsubmission_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_test = CassavaDataset(df=submission_df, dataset='test', transforms=transforms_test)\ndataloader_test = DataLoader(dataset_test, batch_size=BATCH_SIZE, num_workers=4, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submissions = None\ndevice = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device('cpu')\n\nfor i_fold in range(N_FOLDS):\n    \n    model = CassavaModel(num_classes=5)\n    model.to(device)\n    \n    checkpoint = torch.load(f\"{DIR_WEIGHTS}/model_state_fold_{i_fold}.pth\", map_location=device)\n    model.load_state_dict(checkpoint['model_state_dict'], strict=True)\n    model.eval()\n    test_preds = None\n\n    for step, batch in enumerate(dataloader_test):\n\n        images = batch\n        images = images.to(device, dtype=torch.float)\n\n        with torch.no_grad():\n            outputs = model(images)\n\n            preds = torch.softmax(outputs, dim=1).data.cpu()\n            \n            if test_preds is None:\n                test_preds = preds\n            else:\n                test_preds = torch.cat((test_preds, preds), dim=0)\n    \n    \n    # submission_df[['label']] = test_preds.argmax(test_preds, dim=1)\n    # submission_df.to_csv('submission_fold_{}.csv'.format(i_fold), index=False)\n\n    # logits avg\n    if submissions is None:\n        submissions = test_preds / N_FOLDS\n    else:\n        submissions += test_preds / N_FOLDS\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submissions[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df['label'] = torch.argmax(submissions, dim=1)\nsubmission_df.to_csv('submission.csv', index=False)\nsubmission_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}