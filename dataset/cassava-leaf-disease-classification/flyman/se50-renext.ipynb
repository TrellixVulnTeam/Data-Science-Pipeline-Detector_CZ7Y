{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install timm --no-index --find-links=file:///kaggle/input/timm-package/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install albumentations --no-index --find-links=file:///kaggle/input/albumentationspackage/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls /kaggle/input","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\nimport torch\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom torch.nn import Parameter\nimport os\nimport cv2\nimport timm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import albumentations as A","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def gem(x, p=3, eps=1e-5):\n    return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n\nclass GeM(nn.Module):\n\n    def __init__(self, p=3, eps=1e-5):\n        super(GeM, self).__init__()\n        self.p = Parameter(torch.ones(1) * p)\n        self.eps = eps\n\n    def forward(self, x):\n        return gem(x, p=self.p, eps=self.eps)\n\n    def __repr__(self):\n        return self.__class__.__name__ + '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + ', ' + 'eps=' + str(\n            self.eps) + ')'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self, num_classes=5):\n        super().__init__()\n\n        # self.mean_tensor=torch.from_numpy(cfg.DATA.PIXEL_MEAN ).float().cuda()\n        # self.std_val_tensor = torch.from_numpy(cfg.DATA.PIXEL_STD).float().cuda()\n        # self.model = EfficientNet.from_pretrained(model_name='efficientnet-b0')\n        # self.model = timm.create_model('mobilenetv2_110d', pretrained=True)\n\n        # self.model = timm.create_model('mobilenetv2_110d', pretrained=True)\n        self.model = timm.create_model('seresnext50_32x4d', pretrained=False)\n\n        self._avg_pooling = nn.AdaptiveAvgPool2d(1)\n\n        self.dropout=nn.Dropout(0.5)\n\n        self._fc = nn.Linear(2048 , num_classes, bias=True)\n\n    def forward(self, inputs):\n\n        #do preprocess\n\n        input_iid = inputs\n        input_iid=input_iid/255.\n        bs = input_iid.size(0)\n        # Convolution layers\n        x = self.model.forward_features(input_iid)\n        fm = self._avg_pooling(x)\n        fm = fm.view(bs, -1)\n        feature=self.dropout(fm)\n\n\n        x = self._fc(feature)\n\n\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DatasetTest():\n    def __init__(self, test_data_dir):\n        self.ds = self.get_list(test_data_dir)\n\n        self.root_dir = test_data_dir\n        \n        self.val_trans=A.Compose([A.HorizontalFlip(p=0.5),\n                                    A.VerticalFlip(p=0.5),\n                                    A.ColorJitter(brightness=0.1, contrast=0.2, saturation=0.2, hue=0.00, always_apply=False, p=1.0),\n                                    A.RandomCrop(height= 600, width = 600,always_apply=True, p=1.0)]\n                                )\n\n        \n    def get_list(self, dir):\n        pic_list = os.listdir(dir)\n        \n        return pic_list\n\n    def __len__(self):\n\n        return len(self.ds)\n     \n    def preprocess_func(self, image):\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        \n        image1=self.val_trans(image=image)['image']\n        image2=self.val_trans(image=image)['image']\n        image3=self.val_trans(image=image)['image']\n        image4=self.val_trans(image=image)['image']\n        image5=self.val_trans(image=image)['image']\n        image6=self.val_trans(image=image)['image']\n        image7=self.val_trans(image=image)['image']\n        image8=self.val_trans(image=image)['image']\n        \n        image_batch = np.stack([image1,\n                                image2,\n                                image3,\n                                image4,\n                                image5,\n                                image6,\n                                image7,\n                                image8\n                               ])\n\n        image_batch = np.transpose(image_batch, axes=[0, 3, 1, 2])\n        return image, image_batch\n\n    def __getitem__(self, item):\n        fname = self.ds[item]\n\n        image_path = os.path.join(self.root_dir, fname)\n        image = cv2.imread(image_path, -1)\n        image,float_image = self.preprocess_func(image)\n\n        return fname, image,float_image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# class DatasetTest():\n#     def __init__(self, test_data_dir):\n#         self.ds = self.get_list(test_data_dir)\n\n#         self.root_dir = test_data_dir\n\n#     def get_list(self, dir):\n#         pic_list = os.listdir(dir)\n\n#         return pic_list\n\n#     def __len__(self):\n\n#         return len(self.ds)\n\n#     def preprocess_func(self, image):\n#         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n#         image=cv2.resize(image,(640,640))\n\n#         image_90=np.rot90(image,1)\n#         image_180 = np.rot90(image, 2)\n#         image_270 = np.rot90(image, 3)\n\n#         image_fliplr = np.fliplr(image)\n#         image_fliplr_90 = np.rot90(image, 1)\n#         image_fliplr_180 = np.rot90(image, 2)\n#         image_fliplr_270 = np.rot90(image, 3)\n\n#         image_batch = np.stack([image,image_90,image_180,image_270,\n#                                 image_fliplr,image_fliplr_90,image_fliplr_180,image_fliplr_270])\n\n#         image_batch = np.transpose(image_batch, axes=[0, 3, 1, 2])\n#         return image, image_batch\n\n#     def __getitem__(self, item):\n#         fname = self.ds[item]\n\n#         image_path = os.path.join(self.root_dir, fname)\n#         image = cv2.imread(image_path, -1)\n#         image,float_image = self.preprocess_func(image)\n\n#         return fname, image,float_image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nkaggle_root = '/kaggle/input'\nmodel_dir = os.path.join(kaggle_root, 'cassva-models-se50-640')\nweights = [os.path.join(model_dir, f) for f in os.listdir(model_dir)]\n\ntest_datadir= os.path.join(kaggle_root, 'cassava-leaf-disease-classification/test_images')\n\ndataiter=DatasetTest(test_datadir)\n\n\ndef predict_with_model(model,weights):\n    merge_res_dict = {}    \n    for j, weight in enumerate(weights):\n        model.load_state_dict(torch.load(weight, map_location=device), strict=False)\n        ### load your weights\n        model.eval()\n\n        cur_result=pd.DataFrame(columns=['image_id','label'])\n        \n        len_data = len(dataiter)\n\n        image_ids=[]\n        precictions=[]\n        for i in range(len(dataiter)):\n            print('weight {}: data {}/{}'.format(j, i+1, len_data))\n            fname,_,float_image=dataiter.__getitem__(i)\n\n            input=torch.from_numpy(float_image).to(device).float()\n            with torch.no_grad():\n                output=model(input)\n\n                output=torch.nn.functional.softmax(output,dim=-1)\n                output=output.cpu().numpy()\n\n                output=np.mean(output,axis=0)\n\n            image_ids.append(fname)\n\n            label=np.argmax(output)\n\n            precictions.append(label)\n            if fname not in merge_res_dict:\n                merge_res_dict[fname] = output\n            else:\n                merge_res_dict[fname] += output\n\n#         cur_result['image_id']=image_ids\n#         cur_result['label'] = precictions\n        \n#         cur_result.to_csv('{}.csv'.format(weight.split('/')[-1]),index=False)\n#         cur_result.to_csv('submission.csv',index=False)\n        \n    merge_result = pd.DataFrame(columns=['image_id','label'])\n    precictions = []\n    for fname in merge_res_dict:\n        label = np.argmax(merge_res_dict[fname])\n        precictions.append(label)\n    merge_result['image_id'] = image_ids\n    merge_result['label'] = precictions\n#     print(merge_res_dict)\n#     print(merge_result)\n    merge_result.to_csv('submission.csv',index=False)\n    \n\nmodel=Net().to(device)\n\npredict_with_model(model,weights)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}