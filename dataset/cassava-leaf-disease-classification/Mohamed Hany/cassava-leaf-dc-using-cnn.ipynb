{"cells":[{"metadata":{"id":"8b-taxqLMShr","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nfrom sklearn.metrics import accuracy_score\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import datasets, layers, models\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, LSTM, BatchNormalization\nfrom keras.callbacks import TensorBoard\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom keras.callbacks import ReduceLROnPlateau\nfrom PIL import Image \nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom tensorflow.keras.layers import Conv2D , MaxPool2D , Flatten","execution_count":null,"outputs":[]},{"metadata":{"id":"DPmMc6dbsXTp","outputId":"34d3e06c-8ce0-444a-8b62-3a407f077809","trusted":true},"cell_type":"code","source":"WORK_DIR = '../input/cassava-leaf-disease-classification'\nos.listdir(WORK_DIR)","execution_count":null,"outputs":[]},{"metadata":{"id":"kaKs505TQfBT","outputId":"9bf60ffb-1f4d-424d-b515-38a3b27f83df","trusted":true},"cell_type":"code","source":"train_labels = pd.read_csv(os.path.join(WORK_DIR, \"train.csv\"))\ntrain_labels.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"K_ZjrinlR9xh","outputId":"fe3a99b0-657f-4581-ca27-1059ebce6243","trusted":true},"cell_type":"code","source":"sns.countplot(train_labels.label, edgecolor = 'black',\n              palette = sns.color_palette(\"viridis\", 5))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"wLnVKdxcSEhx","outputId":"463a0b10-dbb1-4b90-b9df-06d2c9adc2d5","trusted":true},"cell_type":"code","source":"y_pred = [3] * len(train_labels.label)\nprint('The baseline accuracy: %.3f' \n      %accuracy_score(y_pred, train_labels.label))","execution_count":null,"outputs":[]},{"metadata":{"id":"EQqSpaEiVBGy","trusted":true},"cell_type":"code","source":"BATCH_SIZE = 64\nSTEPS_PER_EPOCH = len(train_labels)*0.7 / BATCH_SIZE\nVALIDATION_STEPS = len(train_labels)*0.3 / BATCH_SIZE\nEPOCHS = 50\nTARGET_SIZE = 64","execution_count":null,"outputs":[]},{"metadata":{"id":"UckWV8fEVMdv","outputId":"a05bbe06-138e-4b2f-cf73-b8d6bfc4d8b9","trusted":true},"cell_type":"code","source":"train_labels.label = train_labels.label.astype('str')\n\ntrain_generator = ImageDataGenerator(validation_split = 0.2,\n                                     preprocessing_function = None,\n                                     zoom_range = 0.15,\n                                     cval = 0.,\n                                     horizontal_flip = True,\n                                     vertical_flip = True,\n                                     fill_mode = 'nearest',\n                                     shear_range = 0.15,\n                                     height_shift_range = 0.15,\n                                     width_shift_range = 0.15) \\\n    .flow_from_dataframe(train_labels,\n                         directory = os.path.join(WORK_DIR, \"train_images\"),\n                         subset = \"training\",\n                         x_col = \"image_id\",\n                         y_col = \"label\",\n                         target_size = (TARGET_SIZE, TARGET_SIZE),\n                         batch_size = BATCH_SIZE,\n                         class_mode = \"sparse\")\n\nvalidation_generator = ImageDataGenerator(validation_split = 0.2) \\\n    .flow_from_dataframe(train_labels,\n                         directory = os.path.join(WORK_DIR, \"train_images\"),\n                         subset = \"validation\",\n                         x_col = \"image_id\",\n                         y_col = \"label\",\n                         target_size = (TARGET_SIZE, TARGET_SIZE),\n                         batch_size = BATCH_SIZE,\n                         class_mode = \"sparse\")","execution_count":null,"outputs":[]},{"metadata":{"id":"ybdptAMaWA5B","trusted":true},"cell_type":"code","source":"def create_model():\n    import tensorflow as tf\n    model = tf.keras.models.Sequential([\n    # Note the input shape is the desired size of the image 200x 200 with 3 bytes color\n    # The first convolution\n    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(TARGET_SIZE, TARGET_SIZE, 3)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    # The second convolution\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    # The third convolution\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    # The fourth convolution\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    # Flatten the results to feed into a dense layer\n    tf.keras.layers.Flatten(),\n    # 128 neuron in the fully-connected layer\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(256, activation='relu'),\n    tf.keras.layers.Dense(5, activation='softmax')\n    ])\n    \n    from tensorflow.keras.optimizers import RMSprop\n    model.compile(optimizer = 'Adam',\n                  loss = \"sparse_categorical_crossentropy\",\n                  metrics = [\"acc\"])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"id":"E25w9JEUrvzF","outputId":"93de504a-51f7-40ff-e001-970955f919fd","trusted":true},"cell_type":"code","source":"model = create_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"id":"sWMsdBfnrv4F","outputId":"ce2c5362-3945-4346-a0a4-f07df91c4149","trusted":true},"cell_type":"code","source":"model_save = ModelCheckpoint('./best_baseline_model.h5', \n                             save_best_only = True, \n                             save_weights_only = True,\n                             monitor = 'val_loss', \n                             mode = 'min', verbose = 1)\nearly_stop = EarlyStopping(monitor = 'val_loss', min_delta = 0.001, \n                           patience = 5, mode = 'min', verbose = 1,\n                           restore_best_weights = True)\nreduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, \n                              patience = 2, min_delta = 0.001, \n                              mode = 'min', verbose = 1)\n\n\n\nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch = STEPS_PER_EPOCH,\n    epochs = EPOCHS,\n    validation_data = validation_generator,\n    validation_steps = VALIDATION_STEPS,\n    callbacks = [model_save, early_stop, reduce_lr]\n)","execution_count":null,"outputs":[]},{"metadata":{"id":"AJTeFezTrv6i","outputId":"80b07a14-88c7-456d-9047-32306037785e","trusted":true},"cell_type":"code","source":"ss = pd.read_csv(os.path.join(WORK_DIR, \"sample_submission.csv\"))\nss","execution_count":null,"outputs":[]},{"metadata":{"id":"X6UydMyKrv2Q","outputId":"d2fe5889-4d1b-450f-810b-a4391be87685","trusted":true},"cell_type":"code","source":"preds = []\n\nfor image_id in ss.image_id:\n    image = Image.open(os.path.join(WORK_DIR,  \"test_images\", image_id))\n    image = image.resize((TARGET_SIZE, TARGET_SIZE))\n    image = np.expand_dims(image, axis = 0)\n    preds.append(np.argmax(model.predict(image)))\n\nss['label'] = preds\nss","execution_count":null,"outputs":[]},{"metadata":{"id":"0Gg-qJjbwXqm","trusted":true},"cell_type":"code","source":"ss.to_csv('submission.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}