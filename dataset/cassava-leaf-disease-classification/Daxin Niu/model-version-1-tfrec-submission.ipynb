{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#### MODEL_BASELINE_SCRIPT_DISABLED\n# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# # for dirname, _, filenames in os.walk('/kaggle/input'):\n# #     for filename in filenames:\n# #         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### MODEL_BASELINE_SCRIPT_DISABLED\n# # A baseline model based on VGG16\n# # Group members: Bangxi Xiao, Daxin Niu, Wendy Huai\n# # Contact: bangxi_xiao@brown.edu, daxin_niu@brown.edu, zuxuan_huai@brown.edu\n\n# # This file implements a baseline model for cassava leaf disease classification\n\n# import time\n# import pickle\n# import numpy as np\n# import pandas as pd\n# import shutil, os\n# from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPool2D, Input\n# import json\n# from scipy import stats\n# from tensorflow.keras import Model, Sequential\n# from tensorflow.keras.regularizers import l1\n# from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n# from tensorflow.keras.optimizers import Adam\n# from tensorflow.keras.optimizers.schedules import ExponentialDecay\n# from tensorflow.keras.applications import VGG16\n# from matplotlib import pyplot as plt\n# from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n# import seaborn as sns\n# from sklearn.model_selection import train_test_split\n# from PIL import Image, ImageStat\n# from skimage import io, color\n\n# # Loading the training data\n# train_raw = pd.read_csv('/kaggle/input/cassava-leaf-disease-classification/train.csv', encoding='utf_8_sig', engine='python')\n# print(train_raw.head())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### MODEL_BASELINE_SCRIPT_DISABLED\n# _batch_size = 32\n# _image_width = 160\n# _image_height = 120\n\n\n# # def file_move(file_names, labels, train=True, pic_file='D:\\\\proj\\\\cassava-leaf-disease-classification\\\\train_images\\\\'):\n# #     if train:\n# #         front = 'train\\\\'\n# #     else:\n# #         front = 'test\\\\'\n# #     for fn, label in zip(file_names, labels):\n# #         if os.path.exists(pic_file + front + str(label)):\n# #             shutil.move(pic_file + fn, pic_file + front + str(label))\n# #         else:\n# #             os.makedirs(pic_file + front + str(label))\n# #             shutil.move(pic_file + fn, pic_file + front + str(label))\n# #     print('DONE.')\n\n\n# train_raw['label'] = train_raw['label'].astype(str)\n# x_train, x_test, y_train, y_test = train_test_split(train_raw['image_id'], train_raw['label'], test_size=0.2)\n# xy_train = pd.DataFrame({'x': x_train, 'y': y_train})\n# xy_test = pd.DataFrame({'x': x_test, 'y': y_test})\n\n# # file_move(x_train.tolist(), y_train.tolist(), True)\n# # file_move(x_test.tolist(), y_test.tolist(), False)\n\n# train_data_gen = ImageDataGenerator(\n#     rescale=1. / 255,\n#     shear_range=0.2,\n#     zoom_range=0.2,\n#     horizontal_flip=True,\n#     validation_split=0.2\n# )\n\n\n# train_generator = train_data_gen.flow_from_dataframe(dataframe=train_raw,\n#                                                      directory='/kaggle/input/cassava-leaf-disease-classification/train_images',\n#                                                      subset='training',\n#                                                      x_col='image_id',\n#                                                      y_col='label',\n#                                                      shuffle=True,\n#                                                      target_size=(160, 120),\n#                                                      batch_size=32,\n#                                                      class_mode='categorical')\n\n\n# validation_generator = train_data_gen.flow_from_dataframe(dataframe=train_raw,\n#                                                           directory='/kaggle/input/cassava-leaf-disease-classification/train_images',\n#                                                           subset='validation',\n#                                                           x_col='image_id',\n#                                                           y_col='label',\n#                                                           shuffle=True,\n#                                                           target_size=(160, 120),\n#                                                           batch_size=32,\n#                                                           class_mode='categorical')\n\n\n# def tb_callback(exp_name):\n#     return TensorBoard(log_dir=_log_dir + exp_name, profile_batch=0, histogram_freq=1)\n\n\n# def build_baseline_vgg():\n#     input_shape = (160, 120, 3)\n#     baseline_model = VGG16(weights=None, include_top=False, input_shape=input_shape)\n#     x = baseline_model.output\n#     x = Flatten()(x)\n#     x = Dense(512, activation='relu')(x)\n#     x = Dropout(rate=0.25)(x)\n\n#     x = Dense(256, activation='relu')(x)\n#     x = Dropout(rate=0.25)(x)\n\n#     x = Dense(128, activation='relu')(x)\n#     x = Dropout(rate=0.25)(x)\n\n#     predictions = Dense(5, activation='softmax')(x)\n#     model = Model(inputs=baseline_model.input, outputs=predictions)\n#     model.compile(optimizer=_opt,\n#                   loss=_loss,\n#                   metrics=_metrics)\n    \n#     print(model.summary())\n    \n\n    #     return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### MODEL_BASELINE_SCRIPT_DISABLED\n# _shuffle = True\n\n# _log_dir = '/kaggle/ouput/logs/baseline_model/'\n# _seed = 27\n# _learning_rate = 0.0001\n# _schedule = ExponentialDecay(_learning_rate, decay_steps=10_0000, decay_rate=0.96)\n# _opt = Adam(learning_rate=_schedule)\n# _es = EarlyStopping(monitor='val_accuracy', patience=20)\n# _tb = tb_callback('Baseline_model_1')\n# _callbacks = [_es, _tb]\n# _metrics = ['accuracy']\n# _loss = 'categorical_crossentropy'\n# _epochs = 4\n\n\n# baseline_model1 = build_baseline_vgg()\n# baseline_model1_hist = baseline_model1.fit(train_generator,\n#                                            epochs=_epochs,\n#                                            validation_data=validation_generator,\n#                                            callbacks=_callbacks,\n#                                            shuffle=_shuffle)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### MODEL_BASELINE_SCRIPT_DISABLED\n# # save model\n# from keras.models import load_model\n# import os\n# def save_model(model, name):\n#   model_name = '{}.h5'.format(name)\n#   save_dir = os.path.join(os.getcwd(), 'saved_models')\n  \n#   # Save model and weights\n#   if not os.path.isdir(save_dir):\n#       os.makedirs(save_dir)\n#   model_path = os.path.join(save_dir, model_name)\n#   model.save(model_path)\n#   print('Saved trained model at %s ' % model_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### MODEL_BASELINE_SCRIPT_DISABLED\n# save_model(baseline_model1, 'baseline_model1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### MODEL_VERSION_1_SCRIPT_DISABLED\n# # Make sure to save the model you trained to /kaggle/working! \n# import pandas as pd\n# import numpy as np\n# import tensorflow as tf\n# from tensorflow import keras\n# from tensorflow.keras.preprocessing.image import smart_resize\n# ## Load model. Use \"load_weights\" if you only save your model weights.\n# model = keras.models.load_model(\"./saved_models/baseline_model1.h5\")\n\n# preds = []\n# sample_sub = pd.read_csv('/kaggle/input/cassava-leaf-disease-classification/sample_submission.csv')\n\n# sample_sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### MODEL_VERSION_2_SCRIPT_DISABLED\n# for image in sample_sub.image_id:\n#     img = keras.preprocessing.image.load_img('/kaggle/input/cassava-leaf-disease-classification/test_images/' + image)\n#     #\n#     # Preprocess image here (rescale, etc. - you might need to use parameters you determined during training)\n#     #\n#     img = img_to_array(img)\n#     img = smart_resize(img, (160, 120))\n#     img = tf.reshape(img, (-1, 160, 120, 3))\n    \n#     # Now apply your model and save your prediction:\n#     prediction = model.predict(img)\n    \n#     preds.append(np.argmax(prediction))\n\n# my_submission = pd.DataFrame({'image_id': sample_sub.image_id, 'label': preds})\n# my_submission.to_csv('/kaggle/working/submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### MODEL_VERSION_1_SCRIPT_DISABLED\n# # Library import\n# import pandas as pd\n# import os\n# import re\n# import tensorflow as tf\n# from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n# from tensorflow.keras.optimizers import Adam\n# from tensorflow.keras.optimizers.schedules import ExponentialDecay\n# from tensorflow.keras.applications import VGG16\n# from functools import partial\n# from sklearn.model_selection import train_test_split\n\n\n# # Constant Variables:\n# _auto_tune = tf.data.experimental.AUTOTUNE\n# _batch_size = 32\n\n# _image_width_original = 512\n# _image_height_original = 512\n# _image_size = [_image_width_original, _image_height_original]\n\n# _image_resize_width = 320\n# _image_resize_height = 320\n# _image_resize = [_image_resize_width, _image_resize_height]\n# print('Model input shape {} x {}.'.format(_image_resize_width, _image_resize_height))\n\n# _channels = 3\n# _n_class = 5\n# _n_repeat = 4\n# _img_norm = 255.0\n\n# _classes = [str(x) for x in range(_n_class)]\n# _major_label = 3\n# _classes_names = ['Cassava Bacterial Blight',\n#                   'Cassava Brown Streak Disease',\n#                   'Cassava Green Mottle',\n#                   'Cassava Mosaic Disease',\n#                   'Healthy']\n# _train_file = '/kaggle/input/cassava-leaf-disease-classification/train_tfrecords/'\n# _train_recs = os.listdir(_train_file)\n# _test_file = '/kaggle/input/cassava-leaf-disease-classification/test_tfrecords/'\n# _test_recs = os.listdir(_test_file)\n# _epochs = 50\n# _valid_size = 0.1\n# _train_df = pd.read_csv('/kaggle/input/cassava-leaf-disease-classification/train.csv', encoding='utf_8_sig', engine='python')\n# _file_label_map = dict(zip(_train_df.image_id.tolist(), _train_df.label.astype(int).tolist()))\n# _random_corp_size = [_image_resize_width, _image_resize_height, _channels]\n\n\n# # Decoding single image:\n# def decode_img(img,\n#                n_channels: int = _channels,\n#                img_size: list = None,\n#                img_norm : float = _img_norm):\n#     if img_size is None:\n#         img_size = _image_size\n#     img = tf.image.decode_jpeg(img, channels=n_channels)\n#     img = tf.reshape(img, [*img_size, n_channels])\n#     img = tf.cast(img, tf.float32) / img_norm\n#     return img\n\n\n# # Parsing the files\n# def parse_img(x,\n#               n_class: int = _n_class):\n#     feature_description = {'image': tf.io.FixedLenFeature([], tf.string, default_value=''),\n#                            'target': tf.io.FixedLenFeature([], tf.int64, default_value=-1)}\n#     parsed_features = tf.io.parse_single_example(x, feature_description)\n#     img = decode_img(parsed_features['image'])\n#     label = tf.one_hot(parsed_features['target'], depth=n_class)\n#     return img, label\n\n\n# # Load data\n# def load_img(files: list,\n#             ordered=False):\n#     df = tf.data.TFRecordDataset(files)\n#     ignore_order = tf.data.Options()\n#     if not ordered:\n#         ignore_order.experimental_deterministic = False\n#     df = df.with_options(ignore_order)\n#     df = df.map(parse_img)\n#     return df\n\n\n# # Resize image\n# def resize_img(img,\n#                label,\n#                shape=None):\n#     if shape is None:\n#         shape = _image_resize\n#     return tf.image.resize(img, shape), label\n\n\n# # Sampling by randomly corp the picture with a fixed size:\n# def random_corp_sample_img(df,\n#                            corp_size=None,\n#                            n_repeat=_n_repeat):\n#     if corp_size is None:\n#         corp_size = _image_resize\n#     df_r = df.map(random_corp_img)\n#     for _ in range(n_repeat-1):\n#         df_r = df_r.concatenate(df.map(random_corp_img))\n#     return df_r\n\n\n# # Random corp:\n# def random_corp_img(img,\n#                     label,\n#                     size=None):\n#     if size is None:\n#         size = _random_corp_size\n#     img = tf.image.random_crop(img, size=size)\n#     return img, label\n\n\n# # Data Augmentation\n# def augment_img(img,\n#                 label):\n#     img = tf.image.random_flip_left_right(img)\n#     img = tf.image.random_flip_up_down(img)\n#     return img, label\n\n\n# # Train-validation split\n# _train_fn, _valid_fn = \\\n#     train_test_split(tf.io.gfile.glob(_train_file + 'ld_train*.tfrec'),\n#                      test_size=_valid_size,\n#                      random_state=5,\n#                      shuffle=True)\n# _test_fn = tf.io.gfile.glob(_test_file + 'ld_test*.tfrec')\n\n\n\n# # Function for getting the training data set\n# def get_train_data(train_fn: list = _train_fn,\n#                    batch_size: int = _batch_size):\n#     df = load_img(train_fn)\n\n#     df_minor = df.filter(lambda x, y: tf.argmax(y) != _major_label)\n#     df_major = df.filter(lambda x, y: tf.argmax(y) == _major_label)\n    \n#     df_major = df_major.map(resize_img)\n#     df_minor = random_corp_sample_img(df_minor)\n#     df = df_major.concatenate(df_minor)\n\n#     df = df.map(augment_img)\n#     df = df.repeat().shuffle(2048).batch(batch_size).prefetch(_auto_tune)\n#     return df\n\n\n# # Function for getting the validation data set\n# def get_valid_data(valid_fn: list = _valid_fn,\n#                    batch_size: int = _batch_size):\n#     df = load_img(valid_fn)\n#     df = df.map(resize_img, num_parallel_calls = _auto_tune)\n#     df = df.batch(batch_size).cache().prefetch(_auto_tune)\n#     return df\n\n\n# # Function for getting the testing data set\n# def get_test_data(test_fn: list = _test_fn,\n#                   batch_size: int = _batch_size):\n#     df = load_img(test_fn)\n#     df = df.map(resize_img)\n#     df = df.batch(batch_size)\n#     return df\n\n\n# # Reporting the size of training, validation and testing data\n# def report_data_size(train_f=_train_fn,\n#                      valid_f=_valid_fn,\n#                      test_f=_test_fn):\n#     def count_file(x):\n#         return sum([int(re.compile(r\"-([0-9]*)\\.\").search(i).group(1)) for i in x])\n#     n_train, n_valid, n_test = count_file(train_f), count_file(valid_f), count_file(test_f)\n#     print('Train Images: {} | Validation Images: {} | Test Images: {}'.format(n_train, n_valid, n_test))\n#     return n_train, n_valid, n_test\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### MODEL_VERSION_1_SCRIPT_DISABLED\n# # Check the size of the data\n# _n_train, _n_valid, _n_test = report_data_size()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### MODEL_VERSION_1_SCRIPT_DISABLED\n# # Fetching training, validation and testing data\n# train_data = get_train_data()\n# valid_data = get_valid_data()\n# test_data = get_test_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### MODEL_VERSION_1_SCRIPT_DISABLED\n# print(\"Train Data Size {} | Validation Data Size {} | Test Data Size {}\".format(train_data._flat_shapes, valid_data._flat_shapes, test_data._flat_shapes))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### MODEL_VERSION_1_SCRIPT_DISABLED\n# #####################\n\n# from tensorflow.keras.applications import ResNet152V2\n# from tensorflow.keras.layers import Input\n\n# LR = 0.001\n# base = ResNet152V2(include_top=False, weights='imagenet', input_shape=(*_image_resize, _channels))\n\n# from tensorflow.keras.layers import AveragePooling2D\n# from tensorflow.keras.layers import Dropout\n# from tensorflow.keras.layers import Flatten\n# from tensorflow.keras.layers import Dense\n# from tensorflow.keras.layers import BatchNormalization\n# from tensorflow.keras.models import Model\n# from tensorflow.keras.optimizers import Adam\n# from tensorflow.keras.losses import categorical_crossentropy\n\n# # Construct structure after ResNet\n# head = base.output\n# head = AveragePooling2D(pool_size=(7, 7))(head)\n# head = BatchNormalization()(head)\n# head = Flatten()(head)\n# head = Dense(512, activation='relu')(head)\n# head = Dropout(rate=0.1)(head)\n# head = Dense(128, activation='relu')(head)\n# head = Dropout(rate=0.1)(head)\n# head = Dense(5, activation='softmax')(head)\n\n# # Combine the model\n# model = Model(inputs=base.input, outputs=head)\n\n# # Freeze base layers\n# # base.trainable = False\n\n# # Compile the model\n# model.compile(loss=categorical_crossentropy, optimizer=Adam(learning_rate=LR), metrics=['accuracy'])\n\n\n# # Add Earlystopping to monitor validation loss\n# from tensorflow.keras.callbacks import EarlyStopping\n\n# callback = EarlyStopping(monitor='val_loss', mode='min', patience=5)\n\n# # Train model\n# H = model.fit(train_data,\n#               epochs=_epochs,\n#               validation_data=valid_data,\n#               steps_per_epoch=_n_train // _batch_size,\n#               validation_steps=_n_valid // _batch_size\n#               )\n\n\n# ########################","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### MODEL_VERSION_2_SCRIPT_DISABLED\n# # Library import\n# import pandas as pd\n# import os\n# import re\n# import cv2\n# import albumentations as alb\n# import numpy as np\n# import tensorflow as tf\n# from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n# from tensorflow.keras.optimizers import Adam\n# from tensorflow.keras.optimizers.schedules import ExponentialDecay\n# from tensorflow.keras.applications import VGG19, EfficientNetB4, ResNet152V2, InceptionResNetV2\n# from tensorflow.keras.layers import AveragePooling2D\n# from tensorflow.keras.regularizers import l1_l2\n# from tensorflow.keras.layers import Dropout\n# from tensorflow.keras.layers import Flatten\n# from tensorflow.keras.layers import Dense\n# from tensorflow.keras.layers import BatchNormalization\n# from tensorflow.keras.models import Model\n# from tensorflow.keras.optimizers import Adam\n# from tensorflow.keras.losses import CategoricalCrossentropy\n# from functools import partial\n# from sklearn.model_selection import train_test_split\n\n\n# def tb_callback(exp_name):\n#     return TensorBoard(log_dir='/logs/'+ exp_name, profile_batch=0, histogram_freq=1)\n\n\n# class HyperParams(object):\n#     \"\"\"\n#     An Initialization of all the global parameters of the model, as well as data augmentation.\n#     \"\"\"\n#     # Data Processing and Image Augmentation\n#     image_size = 512\n#     n_channel = 3\n#     minor_class = [0, 1, 2, 4]\n#     major_class = 3\n#     crop_scale = (0.10, 1)\n#     gr_shuffle = (3, 3)\n#     ssr = [0.05, 0.05, 360]\n#     husat = [20, 20, 20]\n#     bricon = [0.1, 0.1]\n#     blur_limit = 3\n#     dist_limit = 0.1\n#     cutout = [5, 0.1]\n#     prob = 0.5\n#     cutmix = [0, 1]\n#     valid_frac = 0.2\n#     pairing_prob = 0.2\n#     epochs = 30\n#     normalization = 'imagenet'\n#     pixel_crop = 150\n#     train_dir = '/kaggle/input/cassava-leaf-disease-classification/train_images/'\n#     label_df = pd.read_csv('/kaggle/input/cassava-leaf-disease-classification/train.csv', encoding='utf_8_sig', engine='python')\n#     opt = Adam(learning_rate=1e-04)\n#     loss = CategoricalCrossentropy(label_smoothing=0.05)\n#     metrics = ['accuracy']\n#     dropout_prob = 0.1\n#     reg = l1_l2(0.0001)\n\n\n# class DataGen(tf.keras.utils.Sequence):\n#     def __init__(self,\n#                  data,\n#                  dir,\n#                  batch_size=128,\n#                  transform=None,\n#                  pairing=False,\n#                  pairing_prob=0.6,\n#                  pixel_crop=150,\n#                  seed=1000):\n#         self.data = data\n#         self.dir = dir\n#         self.batch_size = batch_size\n#         self.transform = transform\n#         self.pairing = pairing\n#         self.pairing_prob = pairing_prob\n#         self.pixel_crop = pixel_crop,\n#         self.seed = seed\n\n#     def __len__(self):\n#         return int(np.ceil(len(self.data) / float(self.batch_size)))\n\n#     def __getitem__(self, idx):\n#         batched_data = self.data.iloc[idx * self.batch_size:(idx + 1) * self.batch_size]\n#         print('Preparing Data for batch {}'.format(idx))\n#         labels = batched_data.label.tolist()\n#         images = batched_data['image_id'].tolist()\n#         x = np.array([self.process_img_file(i, j, k) for i, j, k in zip(images, labels, batched_data.index)])\n#         y = np.array([self.process_label(i) for i in labels])\n#         return x, y\n\n#     def process_img_file(self, f, l, idx):\n#         p = self.dir + f\n#         img = cv2.imread(p)\n#         img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n#         if self.transform is not None:\n#             img = self.transform(image=img)['image']\n\n#         if self.pairing:\n#             sampled_idx = self.data.sample(frac=self.pairing_prob).index\n#             if idx in sampled_idx:\n#                 try:\n#                     add_path = self.dir + self.data.loc[self.data.label == l].sample(1)['image_id'].iloc[0]\n#                 except IndexError:\n#                     add_path = self.dir + self.data.sample(1)['image_id'].iloc[0]\n#                     print('An inter-class pairing operation is occurring.')\n#                     self.counter += 1\n#                 add_img = cv2.imread(add_path)\n#                 add_img = cv2.cvtColor(add_img, cv2.COLOR_BGR2RGB)\n\n#                 if self.transform is not None:\n#                     add_img = self.transform(image=add_img)['image']\n\n#                 max_x = add_img.shape[0] - self.pixel_crop[0]\n#                 max_y = add_img.shape[1] - self.pixel_crop[0]\n\n#                 x = np.random.randint(0, max_x)\n#                 y = np.random.randint(0, max_y)\n\n#                 crop = add_img[x:x + self.pixel_crop[0], y:y + self.pixel_crop[0], :]\n#                 img[x:x + self.pixel_crop[0], y:y + self.pixel_crop[0], :] = crop\n#         return img.tolist()\n\n#     def process_label(self, l):\n#         if int(l) == 0:\n#             return [1, 0, 0, 0, 0]\n#         elif int(l) == 1:\n#             return [0, 1, 0, 0, 0]\n#         elif int(l) == 2:\n#             return [0, 0, 1, 0, 0]\n#         elif int(l) == 3:\n#             return [0, 0, 0, 1, 0]\n#         else:\n#             return [0, 0, 0, 0, 1]\n\n\n# def img_aug(hps=HyperParams, img_size=None, p_arg=None):\n#     if img_size is None:\n#         img_size = hps.image_size\n#     if p_arg is None:\n#         p_arg = hps.prob\n#     if hps.normalization == 'imagenet':\n#         m = (0.485, 0.456, 0.406)\n#         s = (0.229, 0.224, 0.225)\n#     elif hps.normalization == 'custom':\n#         m = (0.442, 0.511, 0.318)\n#         s = (0.233, 0.236, 0.225)\n#     else:\n#         m = (0, 0, 0)\n#         s = (1, 1, 1)\n\n#     train_seq = alb.Compose([alb.RandomResizedCrop(height=img_size,\n#                                                    width=img_size,\n#                                                    scale=hps.crop_scale),\n#                              alb.RandomGridShuffle(p=p_arg,\n#                                                    grid=hps.gr_shuffle),\n#                              alb.Transpose(p=p_arg),\n#                              alb.HorizontalFlip(p=p_arg),\n#                              alb.VerticalFlip(p=p_arg),\n#                              alb.ShiftScaleRotate(p=p_arg,\n#                                                   shift_limit=hps.ssr[0],\n#                                                   scale_limit=hps.ssr[1],\n#                                                   rotate_limit=hps.ssr[2]),\n#                              alb.HueSaturationValue(p=p_arg,\n#                                                     hue_shift_limit=hps.husat[0],\n#                                                     sat_shift_limit=hps.husat[1],\n#                                                     val_shift_limit=hps.husat[2]),\n#                              alb.RandomBrightnessContrast(p=p_arg,\n#                                                           brightness_limit=hps.bricon[0],\n#                                                           contrast_limit=hps.bricon[1]),\n#                              alb.OneOf([alb.MotionBlur(blur_limit=hps.blur_limit),\n#                                         alb.MedianBlur(blur_limit=hps.blur_limit),\n#                                         alb.GaussianBlur(blur_limit=hps.blur_limit)],\n#                                        p=p_arg),\n#                              alb.OneOf([alb.OpticalDistortion(distort_limit=hps.dist_limit),\n#                                         alb.GridDistortion(distort_limit=hps.dist_limit)],\n#                                        p=p_arg),\n#                              alb.Cutout(p=p_arg,\n#                                         num_holes=hps.cutout[0],\n#                                         max_h_size=np.int(hps.cutout[1] * img_size),\n#                                         max_w_size=np.int(hps.cutout[1] * img_size)),\n#                              alb.Normalize(mean=m,\n#                                            std=s)])\n\n#     test_seq = alb.Compose([alb.SmallestMaxSize(max_size=img_size),\n#                             alb.CenterCrop(height=img_size,\n#                                            width=img_size),\n#                             alb.Normalize(mean=m,\n#                                           std=s)\n#                             ])\n\n#     return train_seq, test_seq\n\n\n# class TrainModel(object):\n#     def __init__(self,\n#                  model_name,\n#                  num_class,\n#                  img_size,\n#                  n_channel,\n#                  opt,\n#                  loss,\n#                  metrics,\n#                  reg,\n#                  dropout_prob,\n#                  include_top=False,\n#                  weight='imagenet'):\n#         self.mn = model_name\n#         self.img_size = img_size\n#         self.n_channel = n_channel\n#         self.include_top = include_top\n#         self.opt = opt\n#         self.init_weights = weight\n#         self.metrics = metrics\n#         self.reg = reg\n#         self.loss = loss\n#         self.p = dropout_prob\n#         self.n_class = num_class\n\n#     def get_model(self, freeze_status):\n#         if self.mn == 'EfficientNetB4':\n#             base = EfficientNetB4(include_top=self.include_top,\n#                                   weights=self.init_weights,\n#                                   input_shape=(self.img_size, self.img_size, self.n_channel))\n#             self._freeze_layer(base, strategy=freeze_status)\n#             x = base.output\n#             x = AveragePooling2D(pool_size=(16, 16))(x)\n#         elif self.mn == 'ResNet152V2':\n#             base = InceptionResNetV2(include_top=self.include_top,\n#                                      weights=self.init_weights,\n#                                      input_shape=(self.img_size, self.img_size, self.n_channel))\n#             self._freeze_layer(base, strategy=freeze_status)\n#             x = base.output\n#             x = AveragePooling2D(pool_size=(14, 14))(x)\n#         else:\n#             base = InceptionResNetV2(include_top=self.include_top,\n#                                      weights=self.init_weights,\n#                                      input_shape=(self.img_size, self.img_size, self.n_channel))\n#             self._freeze_layer(base, strategy=freeze_status)\n#             x = base.output\n#             x = AveragePooling2D(pool_size=(7, 7))(x)\n\n#         x = BatchNormalization()(x)\n#         x = Flatten()(x)\n#         x = Dense(256,\n#                   activation='relu',\n#                   kernel_regularizer=self.reg)(x)\n#         x = Dropout(self.p)(x)\n#         output = Dense(self.n_class,\n#                        activation='softmax')(x)\n#         model = Model(inputs=base.input, outputs=output)\n#         model.compile(loss=self.loss,\n#                       optimizer=self.opt,\n#                       metrics=self.metrics)\n#         return model\n\n#     def _freeze_layer(self, m, strategy):\n#         if strategy == 'all':\n#             m.trainable = False\n#         elif strategy == 'batch_norm':\n#             for layer in m.layers:\n#                 if 'bn' in layer.name:\n#                     layer.trainable = False\n#         else:\n#             pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### MODEL_VERSION_2_SCRIPT_DISABLED\n# H = HyperParams\n# train_set = H.label_df.sample(frac=1 - H.valid_frac).reset_index(drop=True)\n# valid_set = H.label_df.drop(index=train_set.index).reset_index(drop=True)\n# train_transform, valid_transform = img_aug()\n\n# m = TrainModel(model_name='EfficientNetB4',\n#                num_class=5,\n#                img_size=H.image_size,\n#                n_channel=H.n_channel,\n#                opt=H.opt,\n#                loss=H.loss,\n#                metrics=H.metrics,\n#                reg=H.reg,\n#                dropout_prob=H.dropout_prob)\n\n# efficient_net_b4 = m.get_model(freeze_status='all')\n\n# train_dg = DataGen(data=train_set,\n#                    dir=H.train_dir,\n#                    transform=train_transform,\n#                    pairing=True,\n#                    batch_size=16)\n# valid_gen = DataGen(data=valid_set,\n#                     dir=H.train_dir,\n#                     transform=valid_transform)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### MODEL_VERSION_2_SCRIPT_DISABLED\n# _es = EarlyStopping(monitor='val_loss', mode='min', patience=5)\n# _callbacks = [_es]\n\n# efficient_net_b4_history = efficient_net_b4.fit(train_dg,\n#                                                 callbacks=_callbacks,\n#                                                 epochs=5,\n#                                                 validation_data=valid_gen)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # # Library import\n# import pandas as pd\n# import os\n# import re\n# import cv2\n# import albumentations as alb\n# import numpy as np\n# import tensorflow as tf\n# from tensorflow.keras.callbacks import EarlyStopping, TensorBoard, ReduceLROnPlateau\n# from tensorflow.keras.optimizers import Adam\n# from tensorflow.keras.optimizers.schedules import ExponentialDecay\n# from tensorflow.keras.applications import VGG19, ResNet152V2, InceptionResNetV2\n# from tensorflow.keras.layers import AveragePooling2D, Activation, GlobalAveragePooling2D\n# from tensorflow.keras.regularizers import l1_l2\n# from tensorflow.keras.layers import Dropout\n# from tensorflow.keras.layers import Flatten\n# from tensorflow.keras.layers import Dense\n# from tensorflow.keras.layers import BatchNormalization\n# from tensorflow.keras.models import Model\n# from tensorflow.keras.optimizers import Adam\n# from tensorflow.keras.losses import CategoricalCrossentropy\n# from functools import partial\n# from sklearn.model_selection import train_test_split\n# import matplotlib.pyplot as plt\n# from tensorflow.keras.models import Sequential, Model\n# from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n# from tensorflow.keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D, BatchNormalization, Activation\n# from tensorflow.keras.applications import EfficientNetB3, EfficientNetB4\n# from tensorflow.keras.losses import CategoricalCrossentropy\n# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n# from sklearn.model_selection import train_test_split\n# from tensorflow import keras\n\n# # import os\n\n# # df = pd.read_csv('train.csv')\n# # df.head()\n\n\n# # # Data preprocessing: image generation through picture augmentations\n# class HyperParams(object):\n#     \"\"\"\n#     An Initialization of all the global parameters of the model, as well as data augmentation.\n#     \"\"\"\n#     # Data Processing and Image Augmentation\n#     image_size = 320\n#     n_channel = 3\n#     minor_class = [0, 1, 2, 4]\n#     major_class = 3\n#     crop_scale = (0.10, 1)\n#     gr_shuffle = (3, 3)\n#     ssr = [0.05, 0.05, 360]\n#     husat = [20, 20, 20]\n#     bricon = [0.1, 0.1]\n#     blur_limit = 3\n#     dist_limit = 0.1\n#     cutout = [5, 0.1]\n#     prob = 0.5\n#     cutmix = [0, 1]\n#     valid_frac = 0.2\n#     pairing_prob = 0.2\n#     pixel_crop = 150\n#     drop_connect = 0.0\n#     opt = tf.keras.optimizers.Adam(lr=1e-04)\n#     loss = CategoricalCrossentropy(label_smoothing=0.02)\n#     epochs = 20\n#     finetune_epochs = 10\n#     batch_size = 8\n#     metrics = ['categorical_accuracy']\n#     dropout_prob = 0.1\n#     seed = 42\n#     reg = l1_l2(0.0001)\n\n\n# def img_aug(hps=HyperParams, \n#             img_size=None, \n#             p_arg=None):\n#     if img_size is None:\n#         img_size = hps.image_size\n#     if p_arg is None:\n#         p_arg = hps.prob\n#     train_seq = alb.Compose([alb.RandomResizedCrop(height=img_size,\n#                                                    width=img_size,\n#                                                    scale=hps.crop_scale),\n#                              alb.RandomGridShuffle(p=p_arg,\n#                                                    grid=hps.gr_shuffle),\n#                              alb.Transpose(p=p_arg),\n#                              alb.HorizontalFlip(p=p_arg),\n#                              alb.VerticalFlip(p=p_arg),\n#                              alb.ShiftScaleRotate(p=p_arg,\n#                                                   shift_limit=hps.ssr[0],\n#                                                   scale_limit=hps.ssr[1],\n#                                                   rotate_limit=hps.ssr[2]),\n#                              alb.HueSaturationValue(p=p_arg,\n#                                                     hue_shift_limit=hps.husat[0],\n#                                                     sat_shift_limit=hps.husat[1],\n#                                                     val_shift_limit=hps.husat[2]),\n#                              alb.RandomBrightnessContrast(p=p_arg,\n#                                                           brightness_limit=hps.bricon[0],\n#                                                           contrast_limit=hps.bricon[1]),\n#                              alb.OneOf([alb.MotionBlur(blur_limit=hps.blur_limit),\n#                                         alb.MedianBlur(blur_limit=hps.blur_limit),\n#                                         alb.GaussianBlur(blur_limit=hps.blur_limit)],\n#                                        p=p_arg),\n#                              alb.OneOf([alb.OpticalDistortion(distort_limit=hps.dist_limit),\n#                                         alb.GridDistortion(distort_limit=hps.dist_limit)],\n#                                        p=p_arg),\n#                              alb.Cutout(p=p_arg,\n#                                         num_holes=hps.cutout[0],\n#                                         max_h_size=np.int(hps.cutout[1] * img_size),\n#                                         max_w_size=np.int(hps.cutout[1] * img_size))])\n#     test_seq = alb.Compose([alb.SmallestMaxSize(max_size=img_size),\n#                             alb.CenterCrop(height=img_size,\n#                                            width=img_size)\n#                             ])\n\n#     return train_seq, test_seq\n\n\n# # Generating balance sample from train data set\n# def gen_aug_imgs(df,\n#                  hyps=HyperParams,\n#                  lower=4,\n#                  upper=9,\n#                  directory='./train_aug_imgs/',\n#                  aug_fn=img_aug(), train=True):\n#     if train:\n#         augment, _ = aug_fn\n#     else:\n#         _, augment = aug_fn\n#     aug_imgs = []\n#     aug_labels = []\n#     for img, label in zip(df['image_id'].tolist(), df['label'].tolist()):\n#         print(img)\n#         img_loc = hyps.train_dir + img\n#         i = cv2.imread(img_loc)\n#         if label == hyps.major_class or not train:\n#             i_aug = augment(image=i)['image']\n#             file_name = '{}_{}.jpg'.format(img.split('.')[0], 0)\n#             cv2.imwrite(directory + file_name, i_aug)\n#             aug_imgs.append(file_name)\n#             aug_labels.append(label)\n#         else:\n#             n = np.random.randint(lower, upper)\n#             for p in range(n):\n#                 i_aug = augment(image=i)['image']\n#                 file_name = '{}_{}.jpg'.format(img.split('.')[0], p)\n#                 cv2.imwrite('./train_aug_imgs/{}'.format(file_name), i_aug)\n#                 aug_imgs.append(file_name)\n#                 aug_labels.append(label)\n#     aug_train_set = pd.DataFrame({'image_id': aug_imgs, 'label': aug_labels})\n#     aug_train_set.to_csv('aug_train.csv', encoding='utf_8_sig', index=False)\n\n\n# H = HyperParams\n# train_set = H.label_df.sample(frac=1 - H.valid_frac, random_state=H.seed).reset_index(drop=True)\n# valid_set = H.label_df.drop(index=train_set.index).reset_index(drop=True)\n# train_transform, valid_transform = img_aug()\n# gen_aug_imgs(train_set)\n# valid_set.to_csv('valid.csv', encoding='utf_8_sig', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Generating balance sample from train data set\n# train_set = pd.read_csv('./path', encoding='utf_8_sig')\n# valid_set = pd.read_csv('./path', encoding='utf_8_sig')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import pandas as pd\n# import matplotlib.pyplot as plt\n# import numpy as np\n# import tensorflow as tf\n# from tensorflow.keras.models import Sequential, Model\n# from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n# from tensorflow.keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D, BatchNormalization, Activation\n# from tensorflow.keras.applications import EfficientNetB3\n# from tensorflow.keras.losses import CategoricalCrossentropy\n# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n# from sklearn.model_selection import train_test_split\n# from tensorflow import keras\n# import os\n\n# df = pd.read_csv('/kaggle/input/cassava-leaf-disease-classification/train.csv', \n#                  encoding='utf_8_sig')\n\n\n# def img_augmentation(train=True):\n#     if train:\n#         aug = ImageDataGenerator(\n#             horizontal_flip=True,\n#             vertical_flip=True,\n#             rescale=1/255,\n#             height_shift_range=0.2,\n#             width_shift_range=0.2,\n#             rotation_range=40,\n#             shear_range=0.2,\n#             fill_mode='nearest',\n#             preprocessing_function=lambda x: train_transform(image=x)['image'],\n#             zoom_range=[0.3, 0.6]\n#         )\n#     else:\n#         aug = ImageDataGenerator(\n#             rescale=1/255,\n#             preprocessing_function=lambda x: valid_transform(image=x)['image']\n#         )\n#     return aug\n\n\n# def gen_train_data(d,\n#                    img_size,\n#                    img,\n#                    label,\n#                    batch_size,\n#                    img_aug):\n#     train_gen = img_aug.flow_from_dataframe(dataframe=d,\n#                                             x_col=img,\n#                                             y_col=label,\n#                                             class_model='categorical',\n#                                             target_size=(img_size, img_size),\n#                                             color_mode='rgb',\n#                                             batch_size=batch_size)\n#     return train_gen\n\n\n# def gen_valid_data(d,\n#                    img_size,\n#                    img,\n#                    label,\n#                    batch_size,\n#                    img_aug):\n#     valid_gen = img_aug.flow_from_dataframe(dataframe=d,\n#                                             x_col=img,\n#                                             y_col=label,\n#                                             class_model='categorical',\n#                                             target_size=(img_size, img_size),\n#                                             batch_size=batch_size,\n#                                             shuffle=False)\n#     return valid_gen\n\n\n# def gen_test_data(d,\n#                   img_size,\n#                   img,\n#                   batch_size,\n#                   img_aug):\n#     test_gen = img_aug.flow_from_dataframe(dataframe=d,\n#                                            x_col=img,\n#                                            y_col=None,\n#                                            batch_size=batch_size,\n#                                            seed=42,\n#                                            shuffle=False,\n#                                            class_mode=None,\n#                                            target_size=(img_size, img_size))\n#     return test_gen\n\n\n# df['label'] = df['label'].astype('str')  # Since we are using inbuilt generator it takes label as string\n# df['path'] = '/kaggle/input/cassava-leaf-disease-classification/train_images/' + df['image_id']\n# X_train, X_valid = train_test_split(df, test_size=0.1, random_state=42, \n#                                     shuffle=True, stratify=df['label'])\n\n# _img_size = 320\n# _batch_size = 16\n# img_aug_engine = img_augmentation()\n# train_gen = gen_train_data(X_train,\n#                            img='path',\n#                            label='label',\n#                            batch_size=_batch_size,\n#                            img_size=_img_size,\n#                            img_aug=img_augmentation(train=True))\n# valid_gen = gen_valid_data(X_valid,\n#                            img='path',\n#                            label='label',\n#                            batch_size=_batch_size * 2,\n#                            img_size=_img_size,\n#                            img_aug=img_augmentation(train=False))\n\n\n# def load_model(weights_path,\n#                drop_connect,\n#                img_size,\n#                opt,\n#                loss,\n#                metrics=None):\n#     if metrics is None:\n#         metrics = ['categorical_accuracy']\n#     base = EfficientNetB4(\n#         weights=None,\n#         include_top=False,\n#         input_shape=(img_size, img_size, 3),\n#         drop_connect_rate=drop_connect\n#     )\n\n#     base.load_weights(weights_path)\n#     for layer in base.layers:\n#         layer.trainable = True\n#         if 'bn' in layer.name:\n#             layer.trainable = False\n\n#     x = base.output\n#     x = GlobalAveragePooling2D()(x)\n#     x = Dense(512,\n#               activation='relu')(x)\n#     x = BatchNormalization()(x)\n#     x = Activation('relu')(x)\n#     x = Dropout(0.3)(x)\n#     x = Dense(128,\n#               activation='relu')(x)\n#     x = Dropout(0.1)(x)\n#     x = Dense(5,\n#               activation='softmax')(x)\n#     m = Model(inputs=base.input, outputs=x)\n#     m.compile(\n#         optimizer=opt,\n#         loss=loss,\n#         metrics=metrics\n#     )\n#     return m","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# _weight_path = '../input/eb4-weights/eb4.h5'\n\n# _drop_connect = 0.1\n# _opt = tf.keras.optimizers.Adam(lr=1e-04)\n# _loss = CategoricalCrossentropy(label_smoothing=0.05)\n# _epochs = 30\n# _finetune_epochs = 10\n\n# model_ver_4 = load_model(weights_path=_weight_path,\n#                          drop_connect=_drop_connect,\n#                          img_size=_img_size,\n#                          opt=_opt,\n#                          loss=_loss)\n\n# model_ver_4.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# weight_path_save = 'best_model.hdf5'\n# last_weight_path = 'last_model.hdf5'\n\n# _es = EarlyStopping(monitor='val_loss',\n#                     mode='min',\n#                     patience=10)\n# _r = ReduceLROnPlateau(monitor='val_loss',\n#                        factor=0.8,\n#                        patience=2,\n#                        verbose=1,\n#                        mode='auto',\n#                        epsilon=0.0001,\n#                        cooldown=5,\n#                        min_lr=0.00001)\n\n# _callback = [_es, _r]\n\n# history = model_ver_4.fit(train_gen,\n#                           validation_data=valid_gen,\n#                           epochs=_epochs,\n#                           callbacks=_callback)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Unfreezing the batch norm layers:\n# for layer in model_ver_3.layers:\n#     layer.trainable = True\n#     if 'bn' in layer.name:\n#         layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from matplotlib import pyplot as plt\n# plt.plot(history.history['val_categorical_accuracy'], label='Validation Acc.')\n# plt.plot(history.history['categorical_accuracy'], label='Train Acc.')\n# plt.xlabel('Epochs')\n# plt.ylabel('Accuracy')\n# plt.legend()\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from matplotlib import pyplot as plt\n# plt.plot(history.history['val_loss'], label='Validation loss')\n# plt.plot(history.history['loss'], label='Train loss')\n# plt.xlabel('Epochs')\n# plt.ylabel('LOSS')\n# plt.legend()\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def img_augmentation_ft(train=True):\n#     if train:\n#         aug = ImageDataGenerator(\n#             horizontal_flip=True,\n#             vertical_flip=True,\n#             height_shift_range=0.2,\n#             width_shift_range=0.2,\n#             featurewise_std_normalization=True,\n#             brightness_range=[0.7, 1.3],\n#             rotation_range=40,\n#             shear_range=0.22,\n#             fill_mode='nearest',\n#             zoom_range=[-0.2, 0.7]\n#         )\n#     else:\n#         aug = ImageDataGenerator()\n#     return aug\n\n# train_gen_ft = gen_train_data(X_train,\n#                               img='path',\n#                               label='label',\n#                               batch_size=_batch_size,\n#                               img_size=_img_size,\n#                               img_aug=img_augmentation_ft(train=True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# history2 = model_ver_3.fit(train_gen_ft,\n#                            validation_data=valid_gen,\n#                            epochs=_finetune_epochs,\n#                            callbacks=_callback)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # save model\n# from keras.models import load_model\n# import os\n\n# def save_model(model, name):\n#     model_name = '{}.h5'.format(name)\n#     save_dir = os.path.join(os.getcwd(), 'saved_models')\n  \n#     # Save model and weights\n#     if not os.path.isdir(save_dir):\n#         os.makedirs(save_dir)\n#     model_path = os.path.join(save_dir, model_name)\n#     model.save(model_path)\n#     print('Saved trained model at %s ' % model_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# save_model(model_ver_4, 'model_ver_4')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make sure to save the model you trained to /kaggle/working! \nimport os\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow_hub as hub\nfrom tensorflow.keras.preprocessing.image import smart_resize, img_to_array\n## Load model. Use \"load_weights\" if you only save your model weights.\n# m = hub.KerasLayer('../input/mobilenetv3s-ver-1/MobileNetV3S')\n# model0 = tf.keras.Sequential([tf.keras.Input(shape=(224,224,3)), m])\nmodel1 = tf.keras.models.load_model('../input/resnet50-ver-1/ResNet50_ver_1.h5')\nmodel2 = tf.keras.models.load_model('../input/vgg19-ver-1/VGG19_ver_1_cp2.h5')\nmodel3 = tf.keras.models.load_model('../input/mobilenetv3large-ver-1/MobileNetV3Large_ver_1_1_cp5.h5')\nnorm_constant = 0.87 + 0.91\nalpha_1 = 0.91 / norm_constant\nalpha_2 = 0.87 / norm_constant\nalpha_3 = 0.6 / norm_constant\n\npreds = []\n\nsample_sub = pd.read_csv('/kaggle/input/cassava-leaf-disease-classification/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for image in sample_sub.image_id:\n    img = keras.preprocessing.image.load_img('/kaggle/input/cassava-leaf-disease-classification/test_images/' + image)\n    img = img_to_array(img)\n    img = tf.reshape(tf.image.resize(img, (512, 512)), (-1, 512, 512, 3))\n    prediction1 = model1.predict(img) * alpha_1\n    prediction2 = model2.predict(img) * alpha_2\n    prediction3 = model3.predict(img) * alpha_3\n    \n    prediction = prediction1 + prediction2 + prediction3\n    preds.append(np.argmax(prediction))\n\nmy_submission = pd.DataFrame({'image_id': sample_sub.image_id, 'label': preds})\nmy_submission.to_csv('/kaggle/working/submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}