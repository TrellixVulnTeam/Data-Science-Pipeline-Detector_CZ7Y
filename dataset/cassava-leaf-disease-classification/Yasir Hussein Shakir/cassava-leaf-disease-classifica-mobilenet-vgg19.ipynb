{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport cv2\nimport tensorflow as tf\nfrom tensorflow.keras import Input, Model\nfrom keras.layers import Dense, Dropout, Flatten, add\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\nimport keras\nfrom tensorflow.keras.applications import DenseNet201\nfrom keras.applications.mobilenet import MobileNet\nfrom keras.applications.densenet import DenseNet169\nfrom keras.applications.vgg19 import VGG19\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils import to_categorical\nfrom keras.layers.experimental.preprocessing import RandomFlip, RandomRotation, RandomCrop, Rescaling, RandomTranslation\nfrom keras import Sequential\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"root_dir = '../input/cassava-leaf-disease-classification'\n\ntrain_df = pd.read_csv(os.path.join(root_dir, 'train.csv'))\nprint(\"there are \" + str(train_df.shape[0]) + \" train samples\" )\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain_img_dir = os.path.join(root_dir, 'train_images')  \n\nfigure = plt.figure(figsize = (20,20))\n\ncont = 0\n    \nfor i in range(5):\n    \n    speci = train_df[train_df['label'] == i]\n    \n    for j in range(5):\n        \n        img = Image.open(os.path.join(train_img_dir, speci.iloc[j,0]))\n        \n        plt.subplot(5,5, cont+1)\n        \n        plt.imshow(img)\n        \n        cont = cont + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimage_preprocessor = Sequential([\n    RandomFlip(\"horizontal_and_vertical\"),\n    RandomCrop(300,300),\n    RandomTranslation(0.3, 0.3),\n    RandomRotation(0.5),\n    Rescaling(1./255)])\n\ndef custom_gen(batch_size, image_dir, h = 300, w = 300):\n    \n    start = 0\n    end = batch_size\n    images = train_df['image_id']\n    labels = train_df['label']\n    while 1:\n        \n        if end >= train_df.shape[0]:\n            start = 0\n            end = batch_size \n            continue\n        else:\n        \n            batch = []\n\n            if start == 0:\n                names = images[:end]\n                y = to_categorical(labels[:end], num_classes = 5)\n            else:\n                names = images[start:end]\n                y = to_categorical(labels[start:end], num_classes = 5)\n\n            for name in names:\n\n                img = cv2.imread(os.path.join(image_dir,name))\n                img = np.expand_dims(img, axis = 0)\n                img = image_preprocessor(img)\n                img = np.squeeze(img, axis = 0)\n                batch.append(img)\n\n\n\n            end = end + batch_size\n            start = start +  batch_size\n\n\n            yield np.array(batch), y\n            \n            \n            \n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#densenet169_dir = \"../input/allmodelwthih5/densenet169_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n#base_dens = DenseNet169(weights = densenet169_dir, include_top = False, input_shape = (300, 300, 3))\n#base_dens.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dens_base = create_base_model(base_dens)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# MobileNet Base Model creating NON trainable\nmobilenet_weights_dir = '../input/allmodelwthih5/mobilenet_1_0_224_tf_no_top.h5'\nbase_mob = MobileNet(weights = mobilenet_weights_dir, include_top = False)\nbase_mob.trainable  = False\n\nvgg19_weights_dir = \"../input/allmodelwthih5/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\"\nbase_vgg19 = VGG19(weights = vgg19_weights_dir, include_top = False, input_shape = (300,300,3))\nbase_vgg19.trainable = False\n\n\n# function to create a base model with standard output of 1024\n\ndef create_base_model(base_model):\n    \n    inputs = Input(shape = (300,300,3))\n    \n    base_out = base_model(inputs)\n    \n    base_out = Flatten()(base_out)\n    \n    base_out = Dropout(0.3)(base_out)\n    \n    base1_out = Dense(1024, activation = 'relu')(base_out)\n    \n    model = Model(inputs = inputs, outputs = base1_out)\n    \n    return model\n\n\nvgg19_base = create_base_model(base_vgg19)\n\nmob_base = create_base_model(base_mob)\n\n\n\n\n\ndef create_model(base1, base2):\n    \n    inputs = Input(shape = (300,300,3))\n    \n    base1_out = base1(inputs)\n    base2_out = base2(inputs)\n\n    base_out = add([base1_out, base2_out])\n    \n    outputs = Dense(512, activation = 'relu')(base_out)\n    \n    outputs = Dropout(0.2)(outputs)\n    \n    outputs = Dense(5, activation = 'softmax')(outputs)\n    \n    model = Model(inputs = inputs, outputs = outputs)\n    \n    model.summary()\n\n    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy')\n    \n    lrd = ReduceLROnPlateau(monitor = 'val_loss',\n                         patience = 200,\n                         verbose = 1,\n                         factor = 0.75,\n                         min_lr = 1e-10)\n\n    mcp = ModelCheckpoint('model.h5')\n\n    es = EarlyStopping(verbose=1, patience=60)\n    \n    return model\n    \n    \nmodel = create_model(mob_base, vgg19_base)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 64\nepochs = 25\nsteps_per_epoch = train_df.shape[0] // batch_size\ntrain_gen = custom_gen(batch_size, train_img_dir)\n\nhistory = model.fit(train_gen, epochs = epochs, steps_per_epoch = steps_per_epoch )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history.history.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# summarize history for loss\nplt.plot(history.history['loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_leaf = \"../input/cassava-leaf-disease-classification/test_images\"\n\ntest_names = pd.Series(os.listdir(test_leaf))\n\n\nfor j in range(3):\n\n    for i in tqdm(range(len(test_names))):\n\n        image = cv2.imread(os.path.join(test_leaf, test_names[i]))\n        image = np.expand_dims(image, axis = 0)\n        image = image_preprocessor(image)\n        if i ==0:\n\n            pred = model.predict(image)\n        else:\n            pred = np.concatenate([pred, model.predict(image)])\n            \n    if j ==0:\n        final = pred\n    else:\n        final = final +pred\n     \npred = pd.Series(np.argmax(final, axis = 1))\n\n\ntest_df = pd.concat([test_names, pred], axis = 1)\ntest_df = test_df.rename(columns = {0: 'image_id', 1: 'label'})\n\ntest_df.to_csv('submission.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}