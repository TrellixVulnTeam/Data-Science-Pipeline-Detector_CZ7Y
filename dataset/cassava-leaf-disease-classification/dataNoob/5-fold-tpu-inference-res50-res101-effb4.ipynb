{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import math, re, os\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom kaggle_datasets import KaggleDatasets\nfrom tensorflow import keras\nfrom functools import partial\nfrom sklearn.model_selection import train_test_split\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nimport glob\nfrom PIL import Image\nfrom imgaug import augmenters as iaa\n\nfrom keras.preprocessing.image import ImageDataGenerator\n\nprint(\"Tensorflow version \" + tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMAGE_SIZE = 512\nBATCH_SIZE = 64","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# img_adjust_layer = tf.keras.layers.Lambda(tf.keras.applications.resnet50.preprocess_input, input_shape=[IMAGE_SIZE, IMAGE_SIZE, 3])\n    \n# base_model = tf.keras.applications.ResNet50(weights=None, include_top=False)\n\n    \n# model = tf.keras.Sequential([\n\n#         base_model,\n#         tf.keras.layers.GlobalAveragePooling2D(),\n\n#         #tf.keras.layers.Dense(128, activation='relu'),\n#         #tf.keras.layers.Dropout(0.4),\n#         tf.keras.layers.Dense(5, activation='softmax')\n# ])\n    \n# model.compile(\n#         optimizer=tf.keras.optimizers.Adam(),\n#         loss='sparse_categorical_crossentropy',  \n#         metrics=['sparse_categorical_accuracy']\n# )\n\n#model.load_weights('../input/getting-started-tpus-new-tfrecords-01052020-v2/resnet50_01052021_v2.h5')\n# model101_0 = keras.models.load_model('../input/tpus-resnet101-with-5-fold/resnet101_0.h5')# This one is no good\n# model101_1 = keras.models.load_model('../input/tpus-resnet101-with-5-fold/resnet101_1.h5')\n# model101_2 = keras.models.load_model('../input/tpus-resnet101-with-5-fold/resnet101_2.h5')\n# model101_3 = keras.models.load_model('../input/tpus-resnet101-with-5-fold/resnet101_3.h5')\n# model101_4 = keras.models.load_model('../input/tpus-resnet101-with-5-fold/resnet101_4.h5')\n\n# model50_0 = keras.models.load_model('../input/resnet50-5fold-0/resnet50_0.h5')\n# model50_1 = keras.models.load_model('../input/resnet50-5fold-0/resnet50_1.h5')\n# model50_2 = keras.models.load_model('../input/resnet50-5fold-0/resnet50_2.h5')\n# model50_3 = keras.models.load_model('../input/resnet50-5fold-0/resnet50_3.h5')\n# model50_4 = keras.models.load_model('../input/resnet50-5fold-0/resnet50_4.h5')\n\n# modeleffb3_0 = keras.models.load_model('../input/efficient-net-0115/efficientnet_0.h5')\n\n# modeleffb4_0 = keras.models.load_model('../input/efficientb4-net-0117/efficientnet_0.h5')\nmodeleffb4_0121 = keras.models.load_model('../input/efficientb4-net-0121/efficientnet_0.h5')\nmodeleffb4_0124 = keras.models.load_model('../input/fork-of-fork-of-efficientb4-net-0124/efficientnet_0.h5')\n\nmod_lst = [modeleffb4_0124]\n# mod_lst = [model50_0, model50_1, model50_2, model50_3, model50_4]\n# mod_lst = [model101_1, model101_2]\n# mod_lst = [modeleffb4_0, model50_4, model101_4]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dir = \"../input/cassava-leaf-disease-classification/test_images\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# The image augmentations to use:"},{"metadata":{"trusted":true},"cell_type":"code","source":"seq = iaa.Sequential([\n    iaa.Crop(px=(0, 128)), # crop images from each side by 0 to 16px (randomly chosen)\n    iaa.Fliplr(0.5), # horizontally flip 50% of the images\n    iaa.Flipud(0.5), # vertically flip 50% of all images\n    #iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5)\n#     iaa.GaussianBlur(sigma=(0, 2.0)), # blur images with a sigma of 0 to 3.0\n#     iaa.Dropout((0.01, 0.15), per_channel=0.5)\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_preds_model_list_norm_inds(image_dir, model_obj_list, TTA=True, aug_num=5, normalize_indices=None):\n    '''\n    normalize_indices should be a list of 0s and 1s for indicators of which models we want to have normalized (i.e., divided by 255)\n    \n    '''\n    \n    preds = []\n    img_ids = []\n    \n    for i in glob.glob(image_dir+\"/*.jpg\"):\n        print(i)\n        image = Image.open(i)\n        image = image.resize((IMAGE_SIZE, IMAGE_SIZE))\n        \n        # create aug_num augmentations of the image and let all models in model_obj_list get a score\n        aug_imgs = [seq(image=np.array(image))*((1-g)+g/255) for j in range(aug_num) for g in normalize_indices]\n            \n        avg_pred = np.concatenate([mod.predict(np.expand_dims(aug_imgs[i], axis = 0)) for i in range(aug_num) for mod in model_obj_list]).mean(0)\n\n        \n        preds.append(np.argmax(avg_pred))\n        img_ids.append(i.replace(image_dir+\"/\", \"\"))\n    \n    return(pd.DataFrame({'image_id':img_ids, \n                         'label':preds}))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_preds_model_list(image_dir, model_obj_list, TTA=True, aug_num=5, normalize=True):\n    preds = []\n    img_ids = []\n    \n    for i in glob.glob(image_dir+\"/*.jpg\"):\n        print(i)\n        image = Image.open(i)\n        image = image.resize((IMAGE_SIZE, IMAGE_SIZE))\n        #image = np.expand_dims(image, axis = 0)\n        #image = image/255\n        \n    \n        if(TTA):\n            # create aug_num augmentations of the image and let all models in model_obj_list get a score\n            if normalize:\n                aug_imgs = [seq(image=np.array(image))/255 for j in range(aug_num)]\n            else: \n                aug_imgs = [seq(image=np.array(image)) for j in range(aug_num)]\n            #aug_imgs = np.expand_dims(aug_imgs, axis = 0)\n            avg_pred = np.concatenate([mod.predict(np.expand_dims(aug_imgs[i], axis = 0)) for i in range(aug_num) for mod in model_obj_list]).mean(0)\n        else:\n            image = image/255\n            # take the average of all models' predictions\n            avg_pred = np.concatenate([mod.predict(image) for mod in model_obj_list]).mean(0)\n        \n        preds.append(np.argmax(avg_pred))\n        img_ids.append(i.replace(image_dir+\"/\", \"\"))\n    \n    return(pd.DataFrame({'image_id':img_ids, \n                         'label':preds}))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_preds(image_dir, model_obj, normalize=True):\n    preds = []\n    img_ids = []\n    \n    for i in glob.glob(image_dir+\"/*.jpg\"):\n        image = Image.open(i)\n        image = image.resize((IMAGE_SIZE, IMAGE_SIZE))\n        image = np.expand_dims(image, axis = 0)\n        \n        if normalize:\n            image = image/255\n        preds.append(np.argmax(model_obj.predict(image)))\n        img_ids.append(i.replace(image_dir+\"/\", \"\"))\n    \n    return(pd.DataFrame({'image_id':img_ids, \n                         'label':preds}))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\npredict_df = get_preds_model_list(test_dir, mod_lst, normalize=False, aug_num=5)\n# predict_df = get_preds(test_dir, model_obj=modeleffb4_0, normalize=False)\n# predict_df = get_preds_model_list_norm_inds(test_dir, mod_lst, normalize_indices=[0,1,1])\n\npredict_df.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(predict_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}