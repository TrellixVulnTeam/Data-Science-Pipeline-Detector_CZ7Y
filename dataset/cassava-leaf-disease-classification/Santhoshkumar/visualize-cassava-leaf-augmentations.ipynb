{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Cassava Augmentations\n\nBelow augmentation utility functions are copied from [ihelon](https://www.kaggle.com/ihelon) notebook, Thanks for the excellent resource [ihelon](https://www.kaggle.com/ihelon)\n\nPlease have a look at his work once.\n\nhttps://www.kaggle.com/ihelon/monet-visualization-and-augmentation"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport math\nimport random\nimport torch\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\nimport albumentations as A\nimport torchvision\nfrom PIL import Image\nimport torch\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def set_seed(seed):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    \n    \nSEED = 42\nset_seed(SEED)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BASE_PATH = '../input/cassava-leaf-disease-classification/'\nIMAGE_PATH = os.path.join(BASE_PATH, \"train_images\")\nIMAGE = '../input/cassava-leaf-disease-classification/train_images/469487.jpg'\nIMAGE_SIZE_AUG = 256\nmean = (0.485, 0.456, 0.406)\nstd = (0.229, 0.224, 0.225)\np=0.5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"augmentations = A.Compose(\n        [     \n        A.RandomResizedCrop(IMAGE_SIZE_AUG, IMAGE_SIZE_AUG),\n        A.Transpose(p=p),\n        A.HorizontalFlip(p=p),\n        A.VerticalFlip(p=p),\n        A.OneOf([\n        A.IAAAdditiveGaussianNoise(),\n        A.GaussNoise(),\n        ], p=p),\n        A.ShiftScaleRotate(p=p),\n        A.Normalize(mean, std, max_pixel_value=255.0, always_apply=True),  \n        ]\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Cassava_Train_DS:\n    \n    def __init__(self, image_paths, targets, resize, augmentations=None):\n        self.image_paths = image_paths\n        self.targets = targets\n        self.resize = resize\n        self.augmentations = augmentations\n        \n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, item):\n        image = Image.open(self.image_paths[item])\n        targets = self.targets[item]\n        if self.resize is not None:\n            image = image.resize(\n                (self.resize[1], self.resize[0]), resample=Image.BILINEAR\n            )\n        image = np.array(image)\n        if self.augmentations is not None:\n            augmented = self.augmentations(image=image)\n            image = augmented[\"image\"]\n        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n        dct = {\n            \"image\": torch.tensor(image),\n            \"targets\": torch.tensor(targets),\n        }\n                \n        return dct","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def _transform_aug(\n    input_path='../input/cassava-leaf-disease-classification/',\n    image_path = '../input/cassava-leaf-disease-classification/train_images/',\n    resize = (256, 256)\n):\n           \n    train_df = pd.read_csv(input_path+'train.csv')\n    train_images = train_df.image_id.values.tolist()\n    train_images = [os.path.join(image_path, i) for i in train_images]\n    train_targets = train_df.label.values   \n    train_dataset = Cassava_Train_DS(train_images, train_targets, resize = resize, augmentations = augmentations)\n    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n    for idx, data in enumerate(trainloader): \n        break\n    print(data['targets'].numpy())\n    im = torchvision.utils.make_grid(data['image'], nrow=8)  # the default nrow is 8\n    inv_normalize = torchvision.transforms.Normalize(\n        mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],\n        std=[1/0.229, 1/0.224, 1/0.225]\n    )\n    im_inv = inv_normalize(im)\n    plt.figure(figsize=(17,15))\n    plt.imshow(np.transpose(im_inv.numpy(), (1, 2, 0)));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Batch Visualizer\n_transform_aug()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def batch_visualization(path, n_images, is_random=True, figsize=(16, 16)):\n    plt.figure(figsize=figsize)\n    \n    w = int(n_images ** .5)\n    h = math.ceil(n_images / w)\n    all_names = os.listdir(path)\n\n    image_names = all_names[:n_images]\n    if is_random:\n        image_names = random.sample(all_names, n_images)\n    \n    for ind, image_name in enumerate(image_names):\n        img = cv2.imread(os.path.join(path, image_name))\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) \n        plt.subplot(h, w, ind + 1)\n        plt.imshow(img)\n        plt.axis(\"off\")\n    \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_visualization(IMAGE_PATH, 1, is_random=True, figsize=(10, 6))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_visualization(IMAGE_PATH, 16, is_random=True, figsize=(10, 10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_visualization(IMAGE_PATH, 100, is_random=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def color_hist_visualization(image_path, figsize=(16, 4)):\n    plt.figure(figsize=figsize)\n    \n    img = cv2.imread(image_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) \n    plt.subplot(1, 4, 1)\n    plt.imshow(img)\n    plt.axis(\"off\")\n    \n    colors = [\"red\", \"green\", \"blue\"]\n    for i in range(len(colors)):\n        plt.subplot(1, 4, i + 2)\n        plt.hist(\n            img[:, :, i].reshape(-1),\n            bins=25,\n            alpha=0.5,\n            color=colors[i],\n            density=True\n        )\n        plt.xlim(0, 255)\n        plt.xticks([])\n        plt.yticks([])\n    \n    \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"color_hist_visualization(IMAGE)\n\ncolor_hist_visualization(IMAGE)\n\ncolor_hist_visualization(IMAGE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def channels_visualization(image_path, figsize=(16, 4)):\n    plt.figure(figsize=figsize)\n    \n    img = cv2.imread(image_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) \n    plt.subplot(1, 4, 1)\n    plt.imshow(np.mean(img, axis=2), cmap=\"gray\")\n    plt.axis('off')\n    \n    for i in range(3):\n        plt.subplot(1, 4, i + 2)\n        tmp_img = np.full_like(img, 0)\n        tmp_img[:, :, i] = img[:, :, i]\n        plt.imshow(tmp_img)\n        plt.xlim(0, 255)\n        plt.xticks([])\n        plt.yticks([])\n    \n    \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"channels_visualization(IMAGE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def grayscale_visualization(image_path, figsize=(8, 4)):\n    plt.figure(figsize=figsize)\n    \n    img = cv2.imread(image_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) \n    plt.subplot(1, 2, 1)\n    plt.imshow(img)\n    plt.axis('off')\n    \n    plt.subplot(1, 2, 2)\n    tmp_img = np.full_like(img, 0)\n    for i in range(3):\n        tmp_img[:, :, i] = img.mean(axis=-1)\n    plt.imshow(tmp_img)\n    plt.axis('off')\n    \n    \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grayscale_visualization(IMAGE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_simple_augmentation(image_path, transform):\n    img = cv2.imread(image_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) \n    \n    plt.figure(figsize=(10, 5))\n    \n    plt.subplot(1, 2, 1)\n    plt.imshow(img)\n    plt.axis(\"off\")\n    \n    plt.subplot(1, 2, 2)\n    x = transform(image=img)[\"image\"]\n    plt.imshow(x)\n    plt.axis(\"off\")\n\n    plt.show()\n    \ndef plot_multiple_augmentation(image_path, transform):\n    img = cv2.imread(image_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) \n    \n    plt.figure(figsize=(10, 10))\n    \n    plt.subplot(2, 2, 1)\n    plt.imshow(img)\n    plt.axis(\"off\")\n    \n    plt.subplot(2, 2, 2)\n    x = transform(image=img)[\"image\"]\n    plt.imshow(x)\n    plt.axis(\"off\")\n    \n    plt.subplot(2, 2, 3)\n    x = transform(image=img)[\"image\"]\n    plt.imshow(x)\n    plt.axis(\"off\")\n    \n    plt.subplot(2, 2, 4)\n    x = transform(image=img)[\"image\"]\n    plt.imshow(x)\n    plt.axis(\"off\")\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Blur the input image using a random-sized kernel.\n\nDefault: albumentations.augmentations.transforms.Blur (blur_limit=7, always_apply=False, p=0.5)"},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = A.Compose(\n    [\n        A.Blur(p=1.0, blur_limit=(5, 5)),\n    ]\n)\n\nplot_simple_augmentation(IMAGE, transform)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Apply Contrast Limited Adaptive Histogram Equalization to the input image.\n\nDefault: albumentations.augmentations.transforms.CLAHE (clip_limit=4.0, tile_grid_size=(8, 8), always_apply=False, p=0.5)"},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = A.CLAHE(p=1.0, clip_limit=(10, 10), tile_grid_size=(3, 3))\n\nplot_simple_augmentation(IMAGE, transform)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Crop the central part of the input.\n\nDefault: albumentations.augmentations.transforms.CenterCrop (height, width, always_apply=False, p=1.0)"},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = A.CenterCrop(p=1.0, height=100, width=150)\n\nplot_simple_augmentation(IMAGE, transform)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Randomly Drop Channels in the input Image.\n\nDefault: albumentations.augmentations.transforms.ChannelDropout (channel_drop_range=(1, 1), fill_value=0, always_apply=False, p=0.5)"},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = A.ChannelDropout(p=1.0, channel_drop_range=(1, 2), fill_value=0)\n\nplot_multiple_augmentation(IMAGE, transform)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Randomly rearrange channels of the input RGB image.\n\nDefault: albumentations.augmentations.transforms.ChannelShuffle(p=0.5)"},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = A.ChannelShuffle(p=1.0)\n\nplot_multiple_augmentation(IMAGE, transform)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Crop region from image.\n\nDefault: albumentations.augmentations.transforms.Crop (x_min=0, y_min=0, x_max=1024, y_max=1024, always_apply=False, p=1.0)"},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = A.Crop(p=1.0, x_min=0, y_min=0, x_max=150, y_max=150)\n\nplot_simple_augmentation(IMAGE, transform)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Crop a random part of the input.\n\nDefault: albumentations.augmentations.transforms.RandomCrop (height, width, always_apply=False, p=1.0)"},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = A.RandomCrop(p=1.0, height=100, width=100)\n\nplot_multiple_augmentation(IMAGE, transform)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CoarseDropout of the rectangular regions in the image.\n\nDefault: albumentations.augmentations.transforms.CoarseDropout (max_holes=8, max_height=8, max_width=8, min_holes=None, min_height=None, min_width=None, fill_value=0, mask_fill_value=None, always_apply=False, p=0.5)"},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = A.CoarseDropout(\n    max_holes=8,\n    max_height=8,\n    max_width=8, \n    min_holes=None,\n    min_height=None,\n    min_width=None, \n    fill_value=0, \n    always_apply=False,\n    p=0.5\n)\n\nplot_multiple_augmentation(IMAGE, transform)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Decreases image quality by downscaling and upscaling back.\n\nDefault: albumentations.augmentations.transforms.Downscale (scale_min=0.25, scale_max=0.25, interpolation=0, always_apply=False, p=0.5)"},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = A.Downscale(\n    p=1.0, scale_min=0.01, scale_max=0.20, interpolation=0,\n)\n\nplot_multiple_augmentation(\n    IMAGE,\n    transform,\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Equalize the image histogram.\n\nDefault: albumentations.augmentations.transforms.Equalize (mode='cv', by_channels=True, mask=None, mask_params=(), always_apply=False, p=0.5)"},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = A.Equalize(\n    p=1.0, mode='cv', by_channels=True,\n)\n\nplot_simple_augmentation(\n    IMAGE,\n    transform,\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Flip the input horizontally around the y-axis.\n\nDefault: albumentations.augmentations.transforms.HorizontalFlip(p=0.5)"},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = A.HorizontalFlip(\n    p=1,\n)\n\nplot_simple_augmentation(\n    IMAGE,\n    transform,\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Flip the input vertically around the x-axis.\n\nDefault: albumentations.augmentations.transforms.VerticalFlip(p=0.5)"},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = A.VerticalFlip(\n    p=1.0,\n)\n\nplot_simple_augmentation(\n    IMAGE,\n    transform,\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Flip the input either horizontally, vertically or both horizontally and vertically.\n\nDefault: albumentations.augmentations.transforms.Flip(p=0.5)"},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = A.Flip(\n    p=1.0,\n)\n\nplot_multiple_augmentation(\n    IMAGE,\n    transform,\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Apply gaussian noise to the input image.\n\nDefault: albumentations.augmentations.transforms.GaussNoise (var_limit=(10.0, 50.0), mean=0, always_apply=False, p=0.5)"},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = A.GaussNoise(\n    p=1.0, var_limit=(500.0, 500.0),\n)\n\nplot_simple_augmentation(\n    IMAGE,\n    transform,\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Grid Distortion\n\nDefault: albumentations.augmentations.transforms.GridDistortion (num_steps=5, distort_limit=0.3, interpolation=1, border_mode=4, value=None, mask_value=None, always_apply=False, p=0.5)"},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = A.GridDistortion(\n    p=1.0, num_steps=15, distort_limit=(-2., 2.), \n    interpolation=0, border_mode=0, value=(0, 0, 0), mask_value=None,\n)\n\nplot_multiple_augmentation(\n    IMAGE,\n    transform,\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Randomly change hue, saturation and value of the input image.\n\nDefault: albumentations.augmentations.transforms.HueSaturationValue (hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, always_apply=False, p=0.5)"},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = A.HueSaturationValue(\n    p=1.0, \n    hue_shift_limit=(-100, 100), \n    sat_shift_limit=(-100, 100), \n    val_shift_limit=(-100, 100),\n)\n\nplot_multiple_augmentation(\n    IMAGE,\n    transform,\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Apply camera sensor noise.\n\nDefault: albumentations.augmentations.transforms.ISONoise (color_shift=(0.01, 0.05), intensity=(0.1, 0.5), always_apply=False, p=0.5)"},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = A.ISONoise(\n    p=1.0, intensity=(0.0, 2.0), color_shift=(0.0, 1.0)\n)\n\nplot_multiple_augmentation(\n    IMAGE,\n    transform,\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Decrease Jpeg, WebP compression of an image.\n\nDefault: albumentations.augmentations.transforms.ImageCompression (quality_lower=99, quality_upper=100, compression_type=<ImageCompressionType.JPEG: 0>, always_apply=False, p=0.5)"},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = A.ImageCompression(\n    p=1.0, quality_lower=0, quality_upper=10, compression_type=0,\n)\n\nplot_multiple_augmentation(\n    IMAGE,\n    transform,\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Invert the input image by subtracting pixel values from 255.\n\nDefault: albumentations.augmentations.transforms.InvertImg(p=0.5)"},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = A.InvertImg(\n    p=1.0,\n)\n\nplot_simple_augmentation(\n    IMAGE,\n    transform,\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Decrease Jpeg compression of an image.\n\nDefault: albumentations.augmentations.transforms.JpegCompression (quality_lower=99, quality_upper=100, always_apply=False, p=0.5)"},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = A.JpegCompression(\n    p=1.0, quality_lower=0, quality_upper=10,\n)\n\nplot_multiple_augmentation(\n    IMAGE,\n    transform,\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Apply motion blur to the input image using a random-sized kernel.\n\nDefault: albumentations.augmentations.transforms.MotionBlur(p=0.5)"},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = A.MotionBlur(\n    p=1.0, blur_limit=(3, 50),\n)\n\nplot_multiple_augmentation(\n    IMAGE,\n    transform,\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Multiply image to random number or array of numbers.\n\nDefault: albumentations.augmentations.transforms.MultiplicativeNoise (multiplier=(0.9, 1.1), per_channel=False, elementwise=False, always_apply=False, p=0.5)"},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = A.MultiplicativeNoise(\n    p=1.0, multiplier=(0.1, 5.0), per_channel=True, elementwise=False,\n)\n\nplot_multiple_augmentation(\n    IMAGE,\n    transform,\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Randomly apply affine transforms: translate, scale and rotate the input.\n\nDefault: albumentations.augmentations.transforms.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=45, interpolation=1, border_mode=4, always_apply=False, p=0.5)"},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = A.ShiftScaleRotate(p=1)\n\nplot_multiple_augmentation(\n    IMAGE,\n    transform,\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Apply gaussian noise to the input image.\n\nDefault: albumentations.augmentations.transforms.GaussNoise (var_limit=(10.0, 50.0), mean=0, always_apply=False, p=0.5)"},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = A.GaussNoise(p=1)\n\nplot_multiple_augmentation(\n    IMAGE,\n    transform,\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Randomly change hue, saturation and value of the input image.\n\nDefault: albumentations.augmentations.transforms.HueSaturationValue (hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, always_apply=False, p=0.5)"},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = A.HueSaturationValue (hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, always_apply=False, p=1)\n\nplot_multiple_augmentation(\n    IMAGE,\n    transform,\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Randomly change brightness of the input image.\n\nDefault: albumentations.augmentations.transforms.RandomBrightness (limit=0.2, always_apply=False, p=0.5)"},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, brightness_by_max=True, always_apply=False, p=1)\nplot_multiple_augmentation(\n    IMAGE,\n    transform,\n)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}