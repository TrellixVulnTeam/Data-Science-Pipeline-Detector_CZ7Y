{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip3 install --no-dependencies ../input/efficientnetcassava/Keras_Applications-1.0.8-py3-none-any.whl\n!pip3 install --no-dependencies ../input/efficientnetcassava/efficientnet-1.1.1-py3-none-any.whl","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import re\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport json","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import models\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import losses\nfrom sklearn.model_selection import train_test_split\nfrom efficientnet.keras import EfficientNetB3 as EfficientNet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"AUTO = tf.data.experimental.AUTOTUNE\nSIZE = 600\nORIGINAL_WIDTH = 800\nORIGINAL_HEIGHT = 600\nCHANNELS = 3\nBATCH_SIZE = 32","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def decode_image(path):\n    image = tf.io.read_file(path)\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = (tf.cast(image, tf.float32) / 255.0)\n    image = tf.image.resize(image, [ORIGINAL_HEIGHT, ORIGINAL_WIDTH])\n    image = tf.reshape(image, [ORIGINAL_HEIGHT, ORIGINAL_WIDTH , CHANNELS])\n    return image\n\ndef normalize(x):\n    x = tf.image.resize(x, [ORIGINAL_HEIGHT, ORIGINAL_WIDTH])\n    x = tf.reshape(x, [ORIGINAL_HEIGHT, ORIGINAL_WIDTH, CHANNELS])\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def data_aug(x: tf.Tensor) -> tf.Tensor:\n    x = tf.cond(tf.random.uniform([], 0, 1) > 0.2, lambda: tf.image.random_crop(x, [int(ORIGINAL_HEIGHT*0.8), int(ORIGINAL_WIDTH*0.8), 3]), lambda: x)\n    x = normalize(x)\n    x = tf.cond(tf.random.uniform([], 0, 1) > 0.1, lambda: tf.image.random_flip_left_right(x), lambda: x)\n    x = tf.cond(tf.random.uniform([], 0, 1) > 0.1, lambda: tf.image.random_flip_up_down(x), lambda: x)\n    \n    x = tf.cond(tf.random.uniform([], 0, 1) > 0.7, lambda: tf.image.random_saturation(x, 0.6, 1.6), lambda: x)\n    x = tf.cond(tf.random.uniform([], 0, 1) > 0.7, lambda: tf.image.random_brightness(x, 0.05), lambda: x)\n    x = tf.cond(tf.random.uniform([], 0, 1) > 0.7, lambda: tf.image.random_contrast(x, 0.7, 1.3), lambda: x)\n    x = tf.cond(tf.random.uniform([], 0, 1) > 0.5, lambda: tf.image.rot90(x, tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32)), lambda: x)\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"load_dir = \"/kaggle/input/cassava-leaf-disease-classification\"\nsub_df = pd.read_csv(load_dir + '/sample_submission.csv')\nsub_df['paths'] = load_dir + \"/test_images/\" + sub_df.image_id","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_dataset(augment=False):\n    test_dataset =tf.data.Dataset.from_tensor_slices(sub_df.paths.values).map(decode_image, num_parallel_calls=AUTO)\n    \n    if augment:\n        test_dataset = test_dataset.map(lambda x: data_aug(x), num_parallel_calls=AUTO)\n    else:\n        test_dataset = test_dataset.map(lambda x:normalize(x))\n    return test_dataset.batch(BATCH_SIZE).prefetch(AUTO)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_model(i):\n    inputs = layers.Input(shape=(ORIGINAL_HEIGHT, ORIGINAL_WIDTH, 3))\n    model = Sequential([\n        EfficientNet(include_top=False,weights=None, input_tensor=inputs),\n        layers.GlobalAveragePooling2D(name=\"avg_pool\"),\n        layers.BatchNormalization(),\n        layers.Dropout(0.3, name=\"top_dropout\"),\n        layers.Dense(5, activation=\"softmax\", name=\"pred\")\n    ])\n    model.load_weights(F\"../input/efficientnetcassava/EfficientNetB3_tl_best_weights_{i}.h5\")\n    model.compile(loss=losses.SparseCategoricalCrossentropy(), optimizer=tf.optimizers.Adam(lr=0.001), metrics=['accuracy'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_models = 5\nmodels = []\nfor i in range(n_models):\n    models.append(load_model(i))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = []\ntest_dataset = load_dataset()\n\nfor i in range(n_models):\n    preds.append(models[i].predict(test_dataset, verbose=1))\n    \nfor i in range(10):\n    test_dataset_augmented = load_dataset(augment=True)\n    for i in range(n_models):\n        preds.append(models[i].predict(test_dataset_augmented, verbose=1))\n    \n        \npreds = np.mean(preds, axis=0)\npreds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df['label'] = preds.argmax(axis=1)\nsub_df.drop(columns='paths').to_csv('submission.csv', index=False)\n!head submission.csv","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}