{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"raw","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"# [1] - Import Modules\n\"\"\"import modules\"\"\"\n\nimport sys\nsys.path.append('../input/pytorch-image-models/pytorch-image-models-master')\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torch.autograd import Variable\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import ExponentialLR, CosineAnnealingWarmRestarts\n\n\nimport PIL\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport cv2\nimport itertools\n\nfrom torchvision.transforms import ToTensor\nimport torchvision.transforms as transforms\nimport torchvision.models as models\n\nfrom sklearn import metrics, model_selection, preprocessing\nfrom imblearn.over_sampling import SMOTE\n\nfrom tqdm.notebook import tqdm\nimport time\nimport datetime\nimport timm","metadata":{"execution":{"iopub.status.busy":"2021-06-18T14:08:38.007579Z","iopub.execute_input":"2021-06-18T14:08:38.007911Z","iopub.status.idle":"2021-06-18T14:08:38.016866Z","shell.execute_reply.started":"2021-06-18T14:08:38.00788Z","shell.execute_reply":"2021-06-18T14:08:38.014191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Data","metadata":{}},{"cell_type":"code","source":"# [2] - Dataset Loader\n\"\"\"Dataset loader class\"\"\"\n\nclass CassavaDataset(Dataset):                    # Override torch.utils.data.Dataset\n  def __init__(self, data, targets, dataset, transform=None):\n    \"\"\"\n    Args:\n      csv_file    (string): path of csv file\n      dir         (string): path of images\n      transform  (callable, optional): Optional transform\n    \"\"\"\n    self.files = data\n    self.targets = targets\n    self.classes = list(set(targets))\n    self.transform = transform\n    self.dataset = dataset\n\n  def __len__(self):\n    return len(self.files)\n\n  def __getitem__(self, idx):\n    if torch.is_tensor(idx):\n      idx = idx.tolist()\n    name = self.files[idx]\n    img_name = os.path.join(name)\n    image = Image.open(img_name)\n    \"\"\"\n    ------------------------------------------------------------\"\"\"\n    input_size = 384\n    imagenet_stats = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    \n    if self.dataset == 'train':\n        transform = transforms.Compose([transforms.RandomResizedCrop((input_size, input_size)),\n                                        transforms.RandomHorizontalFlip(p=0.5),\n                                        transforms.RandomVerticalFlip(p=0.5),\n                                        transforms.ToTensor(),\n                                        transforms.Normalize(*imagenet_stats)])\n        image = transform(image)\n    elif self.dataset == 'test':\n        transform = transforms.Compose([transforms.Resize((input_size, input_size)),\n                                        transforms.ToTensor(),\n                                        transforms.Normalize(*imagenet_stats)])   \n        image = transform(image)\n    \"\"\"---------------------------------------------------------\"\"\"\n\n    label = self.targets[idx]\n\n    if self.transform:                    ## IDK\n      sample = self.transform(sample)\n\n    return image, label","metadata":{"execution":{"iopub.status.busy":"2021-06-18T14:08:38.029229Z","iopub.execute_input":"2021-06-18T14:08:38.029481Z","iopub.status.idle":"2021-06-18T14:08:38.039399Z","shell.execute_reply.started":"2021-06-18T14:08:38.029458Z","shell.execute_reply":"2021-06-18T14:08:38.038338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# [2] - load csv file\n\"\"\"load from csv\"\"\"\n\ndfx = pd.read_csv('../input/cassava-leaf-disease-classification/train.csv')\n\ndf_train, df_valid = model_selection.train_test_split(dfx, test_size=0.1, random_state=42, stratify=dfx.label.values)\n\n_train = df_train.reset_index(drop=True)\ndf_valid = df_valid.reset_index(drop=True)\n\nimage_path = \"../input/cassava-leaf-disease-classification/train_images/\"\n\ntrain_image_paths = [os.path.join(image_path, x) for x in df_train.image_id.values]\nvalid_image_paths = [os.path.join(image_path, x) for x in df_valid.image_id.values]\n\ntrain_targets = df_train.label.values\nvalid_targets = df_valid.label.values","metadata":{"execution":{"iopub.status.busy":"2021-06-18T14:08:38.06503Z","iopub.execute_input":"2021-06-18T14:08:38.065295Z","iopub.status.idle":"2021-06-18T14:08:38.146118Z","shell.execute_reply.started":"2021-06-18T14:08:38.065272Z","shell.execute_reply":"2021-06-18T14:08:38.145351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# [3] - load data\n\"\"\"load datasets\"\"\"\n\ncassava_train = CassavaDataset(train_image_paths, train_targets, 'train')\ncassava_test = CassavaDataset(valid_image_paths, valid_targets, 'test')\n\nbatch_size = 16\n\ntrain_loader = DataLoader(cassava_train, batch_size=batch_size, shuffle=False, num_workers=2)\ntest_loader = DataLoader(cassava_test, batch_size=batch_size, shuffle=False, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2021-06-18T14:08:38.147433Z","iopub.execute_input":"2021-06-18T14:08:38.147771Z","iopub.status.idle":"2021-06-18T14:08:38.15999Z","shell.execute_reply.started":"2021-06-18T14:08:38.147734Z","shell.execute_reply":"2021-06-18T14:08:38.158885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"markdown","source":"Module to summarize loss and accuracy from (reference: https://github.com/rwightman/pytorch-image-models/blob/master/timm/utils/metrics.py )","metadata":{}},{"cell_type":"code","source":"# [4] - Module to print loss and accuracy\n\"\"\"load datasets\"\"\"\n\nclass AverageMeter:\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n\ndef accuracy(output, target, topk=(1,)):\n    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n    maxk = max(topk)\n    batch_size = target.size(0)\n    _, pred = output.topk(maxk, 1, True, True)\n    pred = pred.t()\n    correct = pred.eq(target.reshape(1, -1).expand_as(pred))\n    return [correct[:k].reshape(-1).float().sum(0) * 100. / batch_size for k in topk]","metadata":{"execution":{"iopub.status.busy":"2021-06-18T14:08:38.16208Z","iopub.execute_input":"2021-06-18T14:08:38.162517Z","iopub.status.idle":"2021-06-18T14:08:38.17165Z","shell.execute_reply.started":"2021-06-18T14:08:38.162481Z","shell.execute_reply":"2021-06-18T14:08:38.170611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Models\n","metadata":{}},{"cell_type":"code","source":"# [5] - Train one epoch\n\"\"\"Function to train one epoch\"\"\"\n\ndef train_epoch(model, loader, device, loss_func, optimizer, scheduler):\n    model.train()\n    summary_loss = AverageMeter() # track running loss\n    summary_acc = AverageMeter() # track running accuracy\n    start = time.time() # track time\n   \n    n = len(loader)\n    \n    for batch in tqdm(loader):\n\n        images, labels = batch\n        images = images.to(device)\n        labels = labels.to(device)\n\n        out = model(images)                  # Generate predictions\n        loss = loss_func(out, labels)  # Calculate loss   \n\n\n\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n    \n        with torch.no_grad():\n            acc = accuracy(out, labels)[0]\n            \n        summary_loss.update(loss.detach().item(), batch_size)\n        summary_acc.update(acc.detach().item(), batch_size)\n        \n    train_time = str(datetime.timedelta(seconds=time.time() - start))\n    print('Train loss: {:.5f} - Train acc: {:.2f}% - time: {}'.format(summary_loss.avg, \n                                                                      summary_acc.avg,\n                                                                      train_time))\n    return summary_loss, summary_acc","metadata":{"execution":{"iopub.status.busy":"2021-06-18T14:08:38.191131Z","iopub.execute_input":"2021-06-18T14:08:38.191379Z","iopub.status.idle":"2021-06-18T14:08:38.198868Z","shell.execute_reply.started":"2021-06-18T14:08:38.191355Z","shell.execute_reply":"2021-06-18T14:08:38.1978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# [6] - Validate one epoch\n\"\"\"Function to test one epoch\"\"\"\n\ndef validate_epoch(model, loader, device, loss_func):\n    model.eval()\n    summary_loss = AverageMeter() # track running loss\n    summary_acc = AverageMeter() # track running accuracy\n    start = time.time() # track time\n    \n    n = len(loader)\n    \n    for batch in tqdm(loader):\n        with torch.no_grad():\n            images, labels = batch\n            images = images.to(device)\n            labels = labels.to(device)\n\n            out = model(images)                  # Generate predictions\n            loss = loss_func(out, labels)  # Calculate loss   \n\n            acc = accuracy(out, labels)[0]\n            \n            summary_loss.update(loss.detach().item(), batch_size)\n            summary_acc.update(acc.detach().item(), batch_size)\n\n        \n    eval_time = str(datetime.timedelta(seconds=time.time() - start))\n    print('Val loss: {:.5f} - Val acc: {:.2f}% - time: {}'.format(summary_loss.avg,\n                                                                  summary_acc.avg,\n                                                                  eval_time))\n    return summary_loss, summary_acc","metadata":{"execution":{"iopub.status.busy":"2021-06-18T14:08:38.200341Z","iopub.execute_input":"2021-06-18T14:08:38.200902Z","iopub.status.idle":"2021-06-18T14:08:38.212356Z","shell.execute_reply.started":"2021-06-18T14:08:38.200865Z","shell.execute_reply":"2021-06-18T14:08:38.211489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# [7] - Load the ResNext Model\n\"\"\"Load the ResNext model\"\"\"\n\nresnet = timm.create_model('resnext50_32x4d', pretrained=True)\n\nnum_ftrs = resnet.fc.in_features\nresnet.fc = nn.Linear(num_ftrs, 5)\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nresnet.to(device)","metadata":{"execution":{"iopub.status.busy":"2021-06-18T14:08:38.214062Z","iopub.execute_input":"2021-06-18T14:08:38.21441Z","iopub.status.idle":"2021-06-18T14:08:45.361032Z","shell.execute_reply.started":"2021-06-18T14:08:38.214376Z","shell.execute_reply":"2021-06-18T14:08:45.360177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# [8] - Train ResNext Model\n\"\"\"Train the ResNext model\"\"\"\n\nnum_epochs = 1\nbest_acc = 0\nbest_epoch = 0\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(resnet.parameters(), lr=0.01, momentum=0.9)\nscheduler =  ReduceLROnPlateau(optimizer, mode='min', factor=0.2, patience=2, verbose=True, eps=1e-6)\n\nfor epoch in range(num_epochs):\n    print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n\n    train_loss, train_acc = train_epoch(resnet, train_loader, device, criterion, optimizer, scheduler)\n    val_loss, val_acc = validate_epoch(resnet, test_loader, device, criterion)\n    scheduler.step(val_loss.avg)\n\n    if val_acc.avg > best_acc:\n        best_acc = val_acc.avg\n        best_epoch = epoch\n    \n    if epoch == 9:\n        print('Saving model...')\n        PATH = './timm_resnext_epoch{}_384.pth'.format(epoch + 1)\n        torch.save(resnet.state_dict(),PATH)","metadata":{"execution":{"iopub.status.busy":"2021-06-18T14:08:52.434796Z","iopub.execute_input":"2021-06-18T14:08:52.435152Z","iopub.status.idle":"2021-06-18T14:09:18.081159Z","shell.execute_reply.started":"2021-06-18T14:08:52.435116Z","shell.execute_reply":"2021-06-18T14:09:18.079482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# [9] - Load the Xception Model\n\"\"\"Load the Xception model\"\"\"\n\nxception = timm.create_model('xception', pretrained=True)\n\nnum_ftrs = xception.fc.in_features\nxception.fc = nn.Linear(num_ftrs, 5)\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nxception.to(device)","metadata":{"execution":{"iopub.status.busy":"2021-06-18T14:09:20.869877Z","iopub.execute_input":"2021-06-18T14:09:20.870218Z","iopub.status.idle":"2021-06-18T14:09:22.946416Z","shell.execute_reply.started":"2021-06-18T14:09:20.870184Z","shell.execute_reply":"2021-06-18T14:09:22.945553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# [10] - Train Xception Model\n\"\"\"Train the Xception model\"\"\"\n\nnum_epochs = 10\nbest_acc = 0\nbest_epoch = 0\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(xception.parameters(), lr=0.01, momentum=0.9)\nscheduler =  ReduceLROnPlateau(optimizer, mode='min', factor=0.2, patience=2, verbose=True, eps=1e-6)\n\nfor epoch in range(num_epochs):\n    print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n\n    train_loss, train_acc = train_epoch(xception, train_loader, device, criterion, optimizer, scheduler)\n    val_loss, val_acc = validate_epoch(xception, test_loader, device, criterion)\n    scheduler.step(val_loss.avg)\n\n    if val_acc.avg > best_acc:\n        best_acc = val_acc.avg\n        best_epoch = epoch\n    \n    if epoch == 9:\n        print('Saving model...')\n        PATH = './timm_xception_epoch{}_384.pth'.format(epoch + 1)\n        torch.save(xception.state_dict(),PATH)","metadata":{"execution":{"iopub.status.busy":"2021-06-18T14:09:47.560166Z","iopub.execute_input":"2021-06-18T14:09:47.560495Z","iopub.status.idle":"2021-06-18T14:19:45.026429Z","shell.execute_reply.started":"2021-06-18T14:09:47.560465Z","shell.execute_reply":"2021-06-18T14:19:45.024707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing - Inference","metadata":{}},{"cell_type":"code","source":"# [11] - Load ResNext Model\n\"\"\"Load the ResNext model\"\"\"\n\nPATH = './timm_resnext_epoch10_384.pth'\n\nresnet = timm.create_model('resnext50_32x4d', pretrained=False)\n\nnum_ftrs = resnet.fc.in_features\nresnet.fc = nn.Linear(num_ftrs, 5)\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nresnet.to(device)\n\nresnet.load_state_dict(torch.load(PATH))\n\nresnet.eval()","metadata":{"execution":{"iopub.status.busy":"2021-06-18T05:19:31.739524Z","iopub.execute_input":"2021-06-18T05:19:31.739783Z","iopub.status.idle":"2021-06-18T05:19:38.870724Z","shell.execute_reply.started":"2021-06-18T05:19:31.739756Z","shell.execute_reply":"2021-06-18T05:19:38.87Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# [12] - Load Xception Model\n\"\"\"Load the ResNext model\"\"\"\n\nPATH = './timm_xception_epoch10_384.pth'\n\nxception = timm.create_model('xception', pretrained=False)\n\nnum_ftrs = resnet.fc.in_features\nxception.fc = nn.Linear(num_ftrs, 5)\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nxception.to(device)\n\nxception.load_state_dict(torch.load(PATH))\n\nxception.eval()","metadata":{"execution":{"iopub.status.busy":"2021-06-18T05:19:38.873673Z","iopub.execute_input":"2021-06-18T05:19:38.873934Z","iopub.status.idle":"2021-06-18T05:19:40.262476Z","shell.execute_reply.started":"2021-06-18T05:19:38.873907Z","shell.execute_reply":"2021-06-18T05:19:40.26173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# [13] - For submission\n\"\"\"Create submission csv\"\"\"\n\nsubmission_df = pd.read_csv('../input/cassava-leaf-disease-classification/sample_submission.csv')\nsubmission_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-18T05:19:40.263701Z","iopub.execute_input":"2021-06-18T05:19:40.264032Z","iopub.status.idle":"2021-06-18T05:19:40.281863Z","shell.execute_reply.started":"2021-06-18T05:19:40.263997Z","shell.execute_reply":"2021-06-18T05:19:40.280975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# [14] - TTA\n\"\"\"Test Time Augmentation\"\"\"\n\ninput_size = 384\nstats = ([0.4914, 0.4822, 0.4465], [0.247, 0.243, 0.261])\n\ntrans1 = transforms.Compose([transforms.Resize((input_size, input_size)),\n                             transforms.Pad(8, padding_mode='reflect'),\n                             transforms.ToTensor(),\n                             transforms.Normalize(*stats)])\n\ntrans2 = transforms.Compose([transforms.Resize((input_size, input_size)),\n                             transforms.RandomHorizontalFlip(p=0.3),\n                             transforms.RandomResizedCrop(input_size),\n                             transforms.ToTensor(),\n                             transforms.Normalize(*stats)])\n\ntrans3 = transforms.Compose([transforms.Resize((input_size, input_size)),\n                             transforms.RandomVerticalFlip(p=0.3),\n                             transforms.RandomResizedCrop(input_size),\n                             transforms.ToTensor(),\n                             transforms.Normalize(*stats)])\n\ntrans4 = transforms.Compose([transforms.Resize((input_size, input_size)),\n                             transforms.RandomHorizontalFlip(p=0.5),\n                             transforms.RandomVerticalFlip(p=0.5),\n                             transforms.RandomResizedCrop(input_size),\n                             transforms.ToTensor(),\n                             transforms.Normalize(*stats)])\ntranss = [trans1, trans2, trans3, trans4]","metadata":{"execution":{"iopub.status.busy":"2021-06-18T05:19:40.283204Z","iopub.execute_input":"2021-06-18T05:19:40.283561Z","iopub.status.idle":"2021-06-18T05:19:40.294044Z","shell.execute_reply.started":"2021-06-18T05:19:40.283525Z","shell.execute_reply":"2021-06-18T05:19:40.293237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# [13]\n\"\"\"Inference\"\"\"\n\nfrom PIL import Image\n\ntest_path = '/kaggle/input/cassava-leaf-disease-classification/test_images/'\ntest_images = os.listdir(test_path)\ntrain_image_paths = [os.path.join(test_path, x) for x in test_images]\n\ny_preds = []\ny2_preds = []\n\n\n\np = 0\nfor i in test_images:\n    res = []\n    image = Image.open(f'/kaggle/input/cassava-leaf-disease-classification/test_images/{i}')\n    input_size = 384\n    \n    outs = torch.Tensor(np.zeros((len(transs), 5)))\n    outs2 = torch.Tensor(np.zeros((len(transs), 5)))\n    k = 0\n    for trans in transs:\n        img = trans(image)\n        img = img.reshape(1, img.shape[0], img.shape[1], img.shape[2])\n        img = Variable(img.to(device))\n        out = resnet(img)\n        out2= xception(img)\n        outs[k,:] = 4*out\n        outs2[k,:] = 5*out2\n        k += 1\n\n    out = outs.mean(axis=0)\n    out2 = outs2.mean(axis=0)\n    res.append(out2)\n\n    mean = torch.mean(torch.stack(res), dim = 0)\n\n    _, predicted = torch.max(out2.data, 0)\n    y_preds.append(predicted.item())","metadata":{"execution":{"iopub.status.busy":"2021-06-18T05:19:40.304518Z","iopub.execute_input":"2021-06-18T05:19:40.304974Z","iopub.status.idle":"2021-06-18T05:19:41.484996Z","shell.execute_reply.started":"2021-06-18T05:19:40.304937Z","shell.execute_reply":"2021-06-18T05:19:41.484148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sub = pd.DataFrame({'image_id': test_images, 'label': y_preds})\ndisplay(df_sub)","metadata":{"execution":{"iopub.status.busy":"2021-06-18T05:19:41.494025Z","iopub.execute_input":"2021-06-18T05:19:41.494378Z","iopub.status.idle":"2021-06-18T05:19:41.507476Z","shell.execute_reply.started":"2021-06-18T05:19:41.494343Z","shell.execute_reply":"2021-06-18T05:19:41.506573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sub.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-18T05:19:41.508819Z","iopub.execute_input":"2021-06-18T05:19:41.509155Z","iopub.status.idle":"2021-06-18T05:19:41.751165Z","shell.execute_reply.started":"2021-06-18T05:19:41.509118Z","shell.execute_reply":"2021-06-18T05:19:41.750395Z"},"trusted":true},"execution_count":null,"outputs":[]}]}