{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\n**Who this notebook is for**  \nThis notebook is for anyone interested in creating a baseline model using Tensor Processing Units (TPUs) and begin making submissions to the **[Cassava Leaf Disease Classification competition](https://www.kaggle.com/c/cassava-leaf-disease-classification)**. If you've taken the **[Kaggle Intro to Deep Learning](https://www.kaggle.com/learn/intro-to-deep-learning)** and//or the **[Kaggle Computer Vision](https://www.kaggle.com/learn/computer-vision)** course you'll find this notebook to be a good starting place to bridge what you've learned in our micro-courses and applying that knowledge to get started in a competition.  \n\n**How to use this notebook**  \nFeel free to use this notebook as a walkthrough on how to build a preliminary image classification model using TensorFlow and Tensor Processing Units (TPUs). You can copy and edit the notebook by clicking on the corresponding button in the top right, which will make your own personal copy of the notebook in your Kaggle account. From there any edits you make will be unique to your own copy of the notebook!\n\n\n**TPUs with TensorFlow**  \nWe'll be using TensorFlow and Keras to build our computer vision model, and using TPUs to both train our model and make predictions. If you'd like to learn about more about TPUs be sure to check out our **[Learn With Me: Getting Started with Tensor Processing Units (TPUs)](https://youtu.be/1pdwRQ1DQfY)** video.  \n\n**References**  \nThis notebook was built using the following amazing resources created by Kagglers:\n- **Martin Gorner:** [Getting Started With 100 Flowers on TPU](https://www.kaggle.com/mgornergoogle/getting-started-with-100-flowers-on-tpu)\n- **Amy Jang:** [TensorFlow + Transfer Learning: Melanoma](https://www.kaggle.com/amyjang/tensorflow-transfer-learning-melanoma)\n- **Phil Culliton:** [A Simple TF 2.1 Notebook](https://www.kaggle.com/philculliton/a-simple-tf-2-1-notebook)","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.039382,"end_time":"2020-11-19T21:45:23.042097","exception":false,"start_time":"2020-11-19T21:45:23.002715","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Set up environment","metadata":{"papermill":{"duration":0.037375,"end_time":"2020-11-19T21:45:23.192515","exception":false,"start_time":"2020-11-19T21:45:23.15514","status":"completed"},"tags":[]}},{"cell_type":"code","source":"!pip install --upgrade tensorflow\n!pip install -U efficientnet","metadata":{"execution":{"iopub.status.busy":"2021-12-20T18:41:28.130389Z","iopub.execute_input":"2021-12-20T18:41:28.130838Z","iopub.status.idle":"2021-12-20T18:41:40.867129Z","shell.execute_reply.started":"2021-12-20T18:41:28.130798Z","shell.execute_reply":"2021-12-20T18:41:40.866179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math, re, os, warnings\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport shutil\nimport matplotlib.pyplot as plt\nfrom matplotlib import gridspec\nfrom kaggle_datasets import KaggleDatasets\nfrom tensorflow import keras\nfrom functools import partial\nfrom sklearn.model_selection import train_test_split\nimport tensorflow_hub as hub\nfrom tensorflow import keras\nfrom tensorflow.keras import preprocessing\nfrom tensorflow.keras.layers.experimental import preprocessing\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import EarlyStopping\nprint(\"Tensorflow version \" + tf.__version__)\ntf.config.optimizer.set_jit(True)\n\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\nimport efficientnet.keras as efn \nimport gc\n\nimport cv2\nfrom PIL import Image\nimport PIL","metadata":{"papermill":{"duration":6.890298,"end_time":"2020-11-19T21:45:30.119979","exception":false,"start_time":"2020-11-19T21:45:23.229681","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-20T18:42:04.565383Z","iopub.execute_input":"2021-12-20T18:42:04.565733Z","iopub.status.idle":"2021-12-20T18:42:08.705216Z","shell.execute_reply.started":"2021-12-20T18:42:04.5657Z","shell.execute_reply":"2021-12-20T18:42:08.704421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Place images in the right folders","metadata":{}},{"cell_type":"code","source":"# Create training and validation folder\nos.mkdir('/kaggle/working/train_data/')\nos.mkdir('/kaggle/working/valid_data/')\n\n# Open dataset file \ndataset = pd.read_csv(\"../input/cassava-leaf-disease-classification/train.csv\")\n\n# Split training images in training and validation images\ntraining_data, validation_data = train_test_split(dataset, test_size=0.33)\n\ntraining_file_names = list(training_data['image_id'].values) \ntraining_img_labels = list(training_data['label'].values) \nvalidation_file_names = list(validation_data['image_id'].values) \nvalidation_img_labels = list(validation_data['label'].values) \n\n# Create folders of labels\nfolders_to_be_created = np.unique(list(dataset['label'])) #.values \n\n# set source and destination\nsource = \"../input/cassava-leaf-disease-classification/train_images\"\ntraining_destination = '/kaggle/working/train_data'\nvalidation_destination = '/kaggle/working/valid_data'\n\n# Create folders for training and validation images\nfor new_path in folders_to_be_created: \n    if not os.path.exists(\".//\" + str(new_path)):\n        train_map = os.path.join('/kaggle/working/train_data/', str(new_path))\n        valid_map = os.path.join('/kaggle/working/valid_data/', str(new_path))\n        os.makedirs(train_map)\n        os.makedirs(valid_map)\n        \n#os.path.exists('/kaggle/working/valid_data/2')\n        \nfolders = folders_to_be_created.copy() \n\n# Places training images in the right folders   \nfor f in range(len(training_file_names)): \n    tr_current_img = training_file_names[f] \n    tr_current_label = training_img_labels[f] \n    src = os.path.join(source, tr_current_img)\n    dst = os.path.join(training_destination, str(tr_current_label))\n    shutil.copy(src, dst)\n    \n# Places validation images in the right folders    \nfor f in range(len(validation_file_names)): \n    va_current_img = validation_file_names[f] \n    va_current_label = validation_img_labels[f] \n    src = os.path.join(source, va_current_img)\n    dst = os.path.join(validation_destination, str(va_current_label))\n    shutil.copy(src, dst)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T18:42:11.987949Z","iopub.execute_input":"2021-12-20T18:42:11.988373Z","iopub.status.idle":"2021-12-20T18:44:59.419325Z","shell.execute_reply.started":"2021-12-20T18:42:11.988331Z","shell.execute_reply":"2021-12-20T18:44:59.418472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data exploration\nmet dank aan: https://www.kaggle.com/xhlulu/reducing-image-sizes-to-32x32","metadata":{}},{"cell_type":"code","source":"label_df = pd.read_csv('../input/cassava-leaf-disease-classification/train.csv')\nlabel_df.head()\n\nlabel_df['label'].value_counts().plot(kind='bar')\n\n'''def display_samples(df, columns=4, rows=3):\n    fig=plt.figure(figsize=(5*columns, 3*rows))\n\n    for i in range(columns*rows):\n        image_path = df.loc[i,'image_id']\n        image_id = df.loc[i,'label']\n        img = cv2.imread(f'kaggle/working/train_data/{image_path}')\n        fig.add_subplot(rows, columns, i+1)\n        plt.title(image_id)\n        plt.imshow(img)\n\ndisplay_samples(label_df)'''","metadata":{"execution":{"iopub.status.busy":"2021-12-20T18:48:07.157219Z","iopub.execute_input":"2021-12-20T18:48:07.157595Z","iopub.status.idle":"2021-12-20T18:48:07.301331Z","shell.execute_reply.started":"2021-12-20T18:48:07.157563Z","shell.execute_reply":"2021-12-20T18:48:07.300401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Delete images out of 3\npath, dirs, files = next(os.walk(\"/kaggle/working/train_data/4\"))\nfile_count = len(files)\nfile_count\n\ntotal_images = 8452+1580 + 1479 + 706 + 1718\nweight_0 = 1 / (706/total_images)\nweight_1 = 1 / (1479/total_images)\nweight_2 = 1 / (1580/total_images)\nweight_3 = 1 / (8452/total_images)\nweight_4 = 1 / (1718/total_images)\n\n\n# Eventueel foto's uit mapje 3 verwijderen? \n#filenames = os.listdir(\"/kaggle/working/train_data/3\")\n\n#for i in filenames[:1000]:\n    #os.remove(\"/kaggle/working/train_data/3/\" + i) ","metadata":{"execution":{"iopub.status.busy":"2021-12-20T18:48:12.65877Z","iopub.execute_input":"2021-12-20T18:48:12.659133Z","iopub.status.idle":"2021-12-20T18:48:12.67062Z","shell.execute_reply.started":"2021-12-20T18:48:12.659099Z","shell.execute_reply":"2021-12-20T18:48:12.669687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set Matplotlib defaults\nplt.rc('figure', autolayout=True)\nplt.rc('axes', labelweight='bold', labelsize='large',\n       titleweight='bold', titlesize=18, titlepad=10)\nplt.rc('image', cmap='magma')\nwarnings.filterwarnings(\"ignore\") # to clean up output cells\n\n\n# Load training and validation sets\n'''ds_train_ = image_dataset_from_directory(\n    '/kaggle/working/train_data',\n    labels='inferred',\n    label_mode='int',\n    image_size=[512, 512], #128, 299\n    interpolation='nearest',\n    batch_size=64,\n    shuffle=True,\n)'''\n\nds_train_ = image_dataset_from_directory(\n    '/kaggle/working/train_data',\n    labels='inferred',\n    label_mode='int',\n    image_size=[48, 48], #128, 299\n    interpolation='nearest',\n    batch_size=128,\n    shuffle=True,\n    validation_split=0.8,\n    subset=\"training\",\n    seed=123\n    )\n\nds_train_valid_ = image_dataset_from_directory(\n    '/kaggle/working/train_data',\n    labels='inferred',\n    label_mode='int',\n    image_size=[48, 48], #128, 299, 512\n    interpolation='nearest',\n    batch_size=128,\n    shuffle=True,\n    validation_split=0.8,\n    subset=\"validation\",\n    seed=123\n    )\n\nds_valid_ = image_dataset_from_directory(\n    '/kaggle/working/valid_data',\n    labels='inferred',\n    label_mode='int',\n    image_size=[48, 48], #128 512\n    interpolation='nearest',\n    batch_size=128,\n    shuffle=False,\n    #validation_split=0.1,\n    #subset=\"training\",\n    #seed=123\n)\n\n# Data Pipeline\ndef convert_to_float(image, label):\n    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n    return image, label\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\nds_train = (\n    ds_train_\n    .map(convert_to_float)\n    .cache()\n    .prefetch(buffer_size=AUTOTUNE)\n)\nds_train_valid = (\n    ds_train_valid_\n    .map(convert_to_float)\n    .cache()\n    .prefetch(buffer_size=AUTOTUNE)\n)\nds_valid = (\n    ds_valid_\n    .map(convert_to_float)\n    .cache()\n    .prefetch(buffer_size=AUTOTUNE)\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T20:34:54.532381Z","iopub.execute_input":"2021-12-20T20:34:54.532714Z","iopub.status.idle":"2021-12-20T20:34:55.558699Z","shell.execute_reply.started":"2021-12-20T20:34:54.532683Z","shell.execute_reply":"2021-12-20T20:34:55.557781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Set up variables\nWe'll set up some of our variables for our notebook here. \n\nIf by chance you're using a private dataset, you'll also want to make sure that you have the **Google Cloud Software Development Kit (SDK)** attached to your notebook. You can find the Google Cloud SDK under the `Add-ons` dropdown menu at the top of your notebook. Documentation for the **Google Cloud Software Development Kit (SDK)** can be found **[here](https://www.kaggle.com/product-feedback/163416)**.","metadata":{"papermill":{"duration":0.038122,"end_time":"2020-11-19T21:45:34.458722","exception":false,"start_time":"2020-11-19T21:45:34.4206","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AUTOTUNE = tf.data.experimental.AUTOTUNE\n#GCS_PATH = KaggleDatasets().get_gcs_path()\nBATCH_SIZE = 128\nIMAGE_SIZE = [48, 48]\nCLASSES = ['0', '1', '2', '3', '4']\nEPOCHS = 40\n\nearly_stopping = EarlyStopping(\n    min_delta=0.01, # minimium amount of change to count as an improvement\n    patience=10, # how many epochs to wait before stopping\n    restore_best_weights=True,\n    monitor = 'val_loss', \n    mode = 'auto',\n)\n\nclass MyCustomCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        gc.collect()\n        tf.keras.backend.clear_session()\n\nlr_scheduler = keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate=1e-5, \n    decay_steps=10000, \n    decay_rate=0.9)","metadata":{"papermill":{"duration":145.219568,"end_time":"2020-11-19T21:47:59.715925","exception":false,"start_time":"2020-11-19T21:45:34.496357","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-12-20T20:35:00.280111Z","iopub.execute_input":"2021-12-20T20:35:00.280486Z","iopub.status.idle":"2021-12-20T20:35:00.290805Z","shell.execute_reply.started":"2021-12-20T20:35:00.280453Z","shell.execute_reply":"2021-12-20T20:35:00.288392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model with pre-trained base 'EfficientnetB0'","metadata":{}},{"cell_type":"code","source":"'''!pip install segmentation-models\n#from tensorflow.keras.mixed_precision import experimental as mixed_precision\n\n#keras.utils.generic_utils = keras.utils\n#policy = mixed_precision.Policy('mixed_float16')\n#mixed_precision.set_policy(policy)\n\n# parameters for data\nheight = 224\nwidth = 224\nchannels = 3\ninput_shape = (height, width, channels)\nn_classes = CLASSES\n\nefnb0 = tf.keras.applications.efficientnet.EfficientNetB0(\n    include_top=False, weights='imagenet',\n    input_shape=input_shape, classes=n_classes,\n    classifier_activation='softmax'\n)\n\n\nmodel = keras.Sequential([\n    layers.Rescaling(1./255),\n    efnb0, \n    layers.GlobalAveragePooling2D(),\n    layers.Flatten(),\n    #layers.LeakyReLU(alpha=0.01),\n    layers.Dense(6, activation = 'relu'), #Leakyrelu? layers.LeakyReLU(alpha=0.3) of activation = LeakyRelu\n    layers.Dropout(rate=0.3),\n    layers.Dense(5, activation = 'softmax')\n])\n\nmodel.compile(\n    optimizer='adam',\n    loss='sparse_categorical_crossentropy',\n    metrics=['sparse_categorical_accuracy'],\n    run_eagerly=True,\n)\n\n#model.summary()\n\nhistory = model.fit(\n    ds_train_valid,\n    validation_data=ds_valid,\n    epochs=EPOCHS,\n    callbacks=[MyCustomCallback()], #earlystopping\n    batch_size = BATCH_SIZE #  put your callbacks in a list\n    #verbose=0,  # turn off training log\n)\n\nhistory_frame = pd.DataFrame(history.history)\nhistory_frame.loc[:, ['loss', 'val_loss']].plot()\nhistory_frame.loc[:, ['sparse_categorical_accuracy', 'val_sparse_categorical_accuracy']].plot()'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model with pre-trained base 'inception'","metadata":{}},{"cell_type":"code","source":"'''pretrained_base = tf.keras.models.load_model(\n    '../input/cv-course-models/cv-course-models/inceptionv3'\n)\n\npretrained_base.trainable = False\n\nmodel = keras.Sequential([\n    layers.Rescaling(1./255),\n    #layers.BatchNormalization(renorm=True),\n    pretrained_base,\n    layers.Flatten(),\n    layers.Dense(6, activation = 'relu'), #Leakyrelu?\n    #layers.Dropout(rate=0.3),\n    layers.Dense(5, activation = 'softmax')\n])\n\nmodel.compile(\n    optimizer='adam',\n    loss='sparse_categorical_crossentropy',\n    metrics=['sparse_categorical_accuracy'],\n    run_eagerly=True,\n)\n\nhistory = model.fit(\n    ds_train_valid,\n    validation_data=ds_valid,\n    epochs=EPOCHS,\n    callbacks=[MyCustomCallback()], #earlystopping\n    batch_size = BATCH_SIZE,# put your callbacks in a list\n    #verbose=0,  # turn off training log\n)\n\nhistory_frame = pd.DataFrame(history.history)\nhistory_frame.loc[:, ['loss', 'val_loss']].plot()\nhistory_frame.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot();'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Self defined base","metadata":{}},{"cell_type":"code","source":"model = keras.Sequential([\n    layers.InputLayer(input_shape=[48, 48, 3]),\n    layers.Rescaling(1./255),\n    layers.Dropout(0.2),\n    \n    # Data Augmentation\n    preprocessing.RandomFlip(mode='horizontal'), \n    preprocessing.RandomRotation(factor=0.1),\n    preprocessing.RandomFlip(mode='vertical'), # meaning, top-to-bottom\n    #preprocessing.RandomWidth(factor=0.15), # horizontal stretch\n    #preprocessing.RandomTranslation(height_factor=0.1, width_factor=0.1),\n\n    # Block One\n    layers.BatchNormalization(renorm=True),\n    layers.Conv2D(filters=32, \n                  kernel_size=3,\n                  activation='relu',\n                  padding='same',\n                  strides = (2,2)),\n    layers.Conv2D(filters=32, \n                  kernel_size=3,\n                  activation='relu',\n                  padding='same',\n                  strides = (2,2)),\n    layers.MaxPool2D(pool_size=2,\n                     strides=2,\n                     padding='same'),\n    layers.Dropout(0.2), \n    \n    # Block Two\n    layers.BatchNormalization(renorm=True),\n    layers.Conv2D(filters=64,\n                  kernel_size=3,\n                  activation='relu',\n                  padding='same', \n                  strides = (2,2)),\n    layers.Conv2D(filters=64,\n                  kernel_size=3,\n                  activation='relu',\n                  padding='same', \n                  strides = (2,2)),\n    layers.MaxPool2D(pool_size=2,\n                     strides=2,\n                     padding='same'),\n    layers.Dropout(0.2),\n    \n    # Block Three\n    layers.BatchNormalization(renorm=True),\n    layers.Conv2D(filters=128,\n                  kernel_size=3,\n                  activation='relu', \n                  padding='same',\n                  strides = (2,2)),\n    layers.Conv2D(filters=128,\n                  kernel_size=3,\n                  activation='relu',\n                  padding='same',\n                  strides = (2,2)),\n    layers.MaxPool2D(pool_size=2,\n                     strides=2,\n                     padding='same'),\n    layers.Dropout(0.2),\n    \n     # Block four\n    layers.BatchNormalization(renorm=True),\n    layers.Conv2D(filters=256,\n                  kernel_size=3,\n                  activation='relu', \n                  padding='same',\n                  strides = (2,2)),\n    layers.Conv2D(filters=256,\n                  kernel_size=3,\n                  activation='relu',\n                  padding='same',\n                  strides = (2,2)),\n    layers.MaxPool2D(pool_size=2,\n                     strides=2,\n                     padding='same'),\n    layers.Dropout(0.2),\n\n    # Head\n    layers.BatchNormalization(renorm=True),\n    layers.Flatten(),\n    layers.Dense(512, activation='relu'),\n    layers.Dropout(0.2),\n    layers.Dense(512, activation='relu'),\n    layers.Dropout(0.2),\n    layers.Dense(512, activation='relu'),\n    layers.Dropout(0.2),\n    layers.Dense(512, activation='relu'),\n    layers.Dropout(0.2),\n    layers.Dense(len(CLASSES), activation='softmax'),\n])\n\noptimizer = tf.keras.optimizers.Adam(lr=0.0001)\n\nmodel.compile(\n    #optimizer=tf.keras.optimizers.Adam(learning_rate=lr_scheduler, epsilon=0.001),\n    #optimizer = Adam(lr=0.001)\n    #optimizer='adam',\n    optimizer = optimizer,\n    loss='sparse_categorical_crossentropy',\n    metrics=['sparse_categorical_accuracy'], \n)\n\nhistory = model.fit(\n    ds_train_valid,\n    validation_data=ds_valid,\n    epochs=EPOCHS,\n    batch_size = BATCH_SIZE,\n    callbacks=[early_stopping],\n    verbose=1,\n    class_weight = {0: weight_0, \n                    1: weight_1, \n                    2: weight_2, \n                    3: weight_3, \n                    4: weight_4, \n                    }\n)\n\n#tf_reset_default_graph()\n\nhistory_frame = pd.DataFrame(history.history)\nhistory_frame.loc[:, ['loss', 'val_loss']].plot()\nhistory_frame.loc[:, ['sparse_categorical_accuracy', 'val_sparse_categorical_accuracy']].plot();\n\n#keras.utils.plot_model(model, show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T20:35:05.113029Z","iopub.execute_input":"2021-12-20T20:35:05.113409Z","iopub.status.idle":"2021-12-20T21:02:57.12889Z","shell.execute_reply.started":"2021-12-20T20:35:05.113374Z","shell.execute_reply":"2021-12-20T21:02:57.128151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = model.predict(ds_valid)\nvalues, counts = np.unique([CLASSES[np.argmax(predictions[i,])] for i in range(len(predictions))], return_counts=True)\nvalues, counts\n\nclasss = [1, 2, 3, 4, 5]\n\nfrom sklearn import metrics\n\ntarget = np.concatenate([label for example, label in ds_valid])\n\nmetrics.cohen_kappa_score([classs[np.argmax(predictions[i,])] for i in range(len(predictions))], target)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T21:03:15.952222Z","iopub.execute_input":"2021-12-20T21:03:15.952595Z","iopub.status.idle":"2021-12-20T21:03:17.870229Z","shell.execute_reply.started":"2021-12-20T21:03:15.952563Z","shell.execute_reply":"2021-12-20T21:03:17.869409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''# Block Two\n    layers.BatchNormalization(renorm=True),\n    layers.Conv2D(filters=64,\n                  kernel_size=3,\n                  activation='relu',\n                  padding='same', \n                  strides = (2,2)),\n    layers.Conv2D(filters=64,\n                  kernel_size=3,\n                  activation='relu',\n                  padding='same', \n                  strides = (2,2)),\n    layers.MaxPool2D(pool_size=2,\n                     strides=2,\n                     padding='same'),\n    layers.Dropout(0.25),\n    \n    # Block Three\n    layers.BatchNormalization(renorm=True),\n    layers.Conv2D(filters=128,\n                  kernel_size=3,\n                  activation='relu', \n                  padding='same',\n                  strides = (2,2)),\n    layers.Conv2D(filters=128,\n                  kernel_size=3,\n                  activation='relu',\n                  padding='same',\n                  strides = (2,2)),\n    layers.MaxPool2D(pool_size=2,\n                     strides=2,\n                     padding='same'),'''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Adding in augmentations \nYou learned about augmentations in the **[Computer Vision: Data Augmentation](https://www.kaggle.com/ryanholbrook/data-augmentation)** lesson on Kaggle Learn, and here I've applied an augmentation available to us through TensorFlow. You can read more about these augmentations (as well as all of the other augmentations available to you!) in the **[TensorFlow tf.image documentation](https://www.tensorflow.org/api_docs/python/tf/image)**.  \n\nIf you're interested in learning how to create and use custom augmentations, check out these **[Rotation Augmentation GPU/TPU](https://www.kaggle.com/cdeotte/rotation-augmentation-gpu-tpu-0-96)** and **[CutMix and MixUp on GPU/TPU](https://www.kaggle.com/cdeotte/cutmix-and-mixup-on-gpu-tpu)** from Kaggle Grandmaster Chris Deotte.","metadata":{"papermill":{"duration":0.038372,"end_time":"2020-11-19T21:48:00.765394","exception":false,"start_time":"2020-11-19T21:48:00.727022","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Define data loading methods\nThe following functions will be used to load our `training`, `validation`, and `test` datasets, as well as print out the number of images in each dataset.","metadata":{"papermill":{"duration":0.038742,"end_time":"2020-11-19T21:48:00.930185","exception":false,"start_time":"2020-11-19T21:48:00.891443","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Brief exploratory data analysis (EDA)\nFirst we'll print out the shapes and labels for a sample of each of our three datasets:","metadata":{"papermill":{"duration":0.041086,"end_time":"2020-11-19T21:48:01.478205","exception":false,"start_time":"2020-11-19T21:48:01.437119","status":"completed"},"tags":[]}},{"cell_type":"code","source":"'''print(\"Training data shapes:\")\nfor image, label in get_training_dataset().take(3):\n    print(image.numpy().shape, label.numpy().shape)\nprint(\"Training data label examples:\", label.numpy())\nprint(\"Validation data shapes:\")\nfor image, label in get_validation_dataset().take(3):\n    print(image.numpy().shape, label.numpy().shape)\nprint(\"Validation data label examples:\", label.numpy())\nprint(\"Test data shapes:\")\nfor image, idnum in get_test_dataset().take(3):\n    print(image.numpy().shape, idnum.numpy().shape)\nprint(\"Test data IDs:\", idnum.numpy().astype('U')) # U=unicode string'''","metadata":{"execution":{"iopub.execute_input":"2020-11-19T21:48:01.575573Z","iopub.status.busy":"2020-11-19T21:48:01.574436Z","iopub.status.idle":"2020-11-19T21:48:18.597144Z","shell.execute_reply":"2020-11-19T21:48:18.596204Z"},"papermill":{"duration":17.07767,"end_time":"2020-11-19T21:48:18.597304","exception":false,"start_time":"2020-11-19T21:48:01.519634","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The following code chunk sets up a series of functions that will print out a grid of images. The grid of images will contain images and their corresponding labels.","metadata":{"papermill":{"duration":0.044101,"end_time":"2020-11-19T21:48:18.6862","exception":false,"start_time":"2020-11-19T21:48:18.642099","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"You can also modify the above code to look at your `validation` and `test` data, like this:","metadata":{"papermill":{"duration":0.086379,"end_time":"2020-11-19T21:48:22.547481","exception":false,"start_time":"2020-11-19T21:48:22.461102","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Building the model\n## Learning rate schedule\nWe learned about learning rates in the **[Intro to Deep Learning: Stochastic Gradient Descent](https://www.kaggle.com/ryanholbrook/stochastic-gradient-descent)** lesson, and here I've created a learning rate schedule mostly using the defaults in the **[Keras Exponential Decay Learning Rate Scheduler](https://keras.io/api/optimizers/learning_rate_schedules/exponential_decay/)** documentation (I did change the `initial_learning_rate`. You can adjust the learning rate scheduler below, and read more about the other types of schedulers available to you in the **[Keras learning rate schedules API](https://keras.io/api/optimizers/learning_rate_schedules/)**.","metadata":{"papermill":{"duration":0.230199,"end_time":"2020-11-19T21:48:28.353794","exception":false,"start_time":"2020-11-19T21:48:28.123595","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Building our model\nIn order to ensure that our model is trained on the TPU, we build it using `with strategy.scope()`.    \n\nThis model was built using transfer learning, meaning that we have a _pre-trained model_ (ResNet50) as our base model and then the customizable model built using `tf.keras.Sequential`. If you're new to transfer learning I recommend setting `base_model.trainable` to **False**, but _do_ encourage you to change which base model you're using (more options are available in the **[`tf.keras.applications` Module](https://www.tensorflow.org/api_docs/python/tf/keras/applications)** documentation) as well iterate on the custom model. \n\nNote that we're using `sparse_categorical_crossentropy` as our loss function, because we did _not_ one-hot encode our labels.","metadata":{"papermill":{"duration":0.22538,"end_time":"2020-11-19T21:48:29.285377","exception":false,"start_time":"2020-11-19T21:48:29.059997","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Train the model\nAs our model is training you'll see a printout for each epoch, and can also monitor TPU usage by clicking on the TPU metrics in the toolbar at the top right of your notebook.","metadata":{"papermill":{"duration":0.174404,"end_time":"2020-11-19T21:48:49.513099","exception":false,"start_time":"2020-11-19T21:48:49.338695","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"With model.summary() we'll see a printout of each of our layers, their corresponding shape, as well as the associated number of parameters. Notice that at the bottom of the printout we'll see information on the total parameters, trainable parameters, and non-trainable parameters. Because we're using a pre-trained model, we expect there to be a large number of non-trainable parameters (because the weights have already been assigned in the pre-trained model).","metadata":{"papermill":{"duration":1.26977,"end_time":"2020-11-19T22:04:49.3763","exception":false,"start_time":"2020-11-19T22:04:48.10653","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Evaluating our model\nThe first chunk of code is provided to show you where the variables in the second chunk of code came from. As you can see, there's a lot of room for improvement in this model, but because we're using TPUs and have a relatively short training time, we're able to iterate on our model fairly rapidly.","metadata":{"papermill":{"duration":1.245239,"end_time":"2020-11-19T22:04:54.493139","exception":false,"start_time":"2020-11-19T22:04:53.2479","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# print out variables available to us\n'''print(history.history.keys())'''","metadata":{"execution":{"iopub.execute_input":"2020-11-19T22:04:57.050462Z","iopub.status.busy":"2020-11-19T22:04:57.0494Z","iopub.status.idle":"2020-11-19T22:04:57.053166Z","shell.execute_reply":"2020-11-19T22:04:57.053855Z"},"papermill":{"duration":1.31245,"end_time":"2020-11-19T22:04:57.054025","exception":false,"start_time":"2020-11-19T22:04:55.741575","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create learning curves to evaluate model performance\n'''history_frame = pd.DataFrame(history.history)\nhistory_frame.loc[:, ['loss', 'val_loss']].plot()\nhistory_frame.loc[:, ['sparse_categorical_accuracy', 'val_sparse_categorical_accuracy']].plot();'''","metadata":{"execution":{"iopub.execute_input":"2020-11-19T22:04:59.5746Z","iopub.status.busy":"2020-11-19T22:04:59.573814Z","iopub.status.idle":"2020-11-19T22:04:59.983142Z","shell.execute_reply":"2020-11-19T22:04:59.982506Z"},"papermill":{"duration":1.671861,"end_time":"2020-11-19T22:04:59.983272","exception":false,"start_time":"2020-11-19T22:04:58.311411","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Making predictions\nNow that we've trained our model we can use it to make predictions! ","metadata":{"papermill":{"duration":1.326243,"end_time":"2020-11-19T22:05:02.628032","exception":false,"start_time":"2020-11-19T22:05:01.301789","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Load testdata \n'''ds_test_ = image_dataset_from_directory(\n    '..input/cassava-leaf-disease-classification/test_images',\n    labels='inferred',\n    label_mode='int',\n    image_size=[48, 48], #128, 299\n    interpolation='nearest',\n    batch_size=64,\n    shuffle=True,\n)\n\n# Data Pipeline\ndef convert_to_float(image, label):\n    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n    return image, label\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\nds_test = (\n    ds_test_\n    .map(convert_to_float)\n    .cache()\n    .prefetch(buffer_size=AUTOTUNE)\n)\n\nprobabilities = model.predict(ds_test)\npredictions = np.argmax(probabilties, axis=-1)\nprint(predictions)\n\n'''\n\n#OLD CODE\n'''test_ds = get_test_dataset(ordered=True) \ntest_ds = test_ds.map(to_float32)\n\nprint('Computing predictions...')\ntest_images_ds = testing_dataset\ntest_images_ds = test_ds.map(lambda image, idnum: image)\nprobabilities = model.predict(test_images_ds)\npredictions = np.argmax(probabilities, axis=-1)\nprint(predictions)'''","metadata":{"execution":{"iopub.execute_input":"2020-11-19T22:05:07.746039Z","iopub.status.busy":"2020-11-19T22:05:07.744935Z","iopub.status.idle":"2020-11-19T22:05:22.234912Z","shell.execute_reply":"2020-11-19T22:05:22.235492Z"},"papermill":{"duration":15.776858,"end_time":"2020-11-19T22:05:22.235661","exception":false,"start_time":"2020-11-19T22:05:06.458803","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating a submission file\nNow that we've trained a model and made predictions we're ready to submit to the competition! You can run the following code below to get your submission file.","metadata":{"papermill":{"duration":1.271799,"end_time":"2020-11-19T22:05:24.759257","exception":false,"start_time":"2020-11-19T22:05:23.487458","status":"completed"},"tags":[]}},{"cell_type":"code","source":"'''print('Generating submission.csv file...')\ntest_ids_ds = test_ds.map(lambda image, idnum: idnum).unbatch()\ntest_ids = next(iter(test_ids_ds.batch(NUM_TEST_IMAGES))).numpy().astype('U') # all in one batch\nnp.savetxt('submission.csv', np.rec.fromarrays([test_ids, predictions]), fmt=['%s', '%d'], delimiter=',', header='id,label', comments='')\n!head submission.csv'''","metadata":{"execution":{"iopub.execute_input":"2020-11-19T22:05:27.316025Z","iopub.status.busy":"2020-11-19T22:05:27.315202Z","iopub.status.idle":"2020-11-19T22:05:28.241598Z","shell.execute_reply":"2020-11-19T22:05:28.24078Z"},"papermill":{"duration":2.185537,"end_time":"2020-11-19T22:05:28.241723","exception":false,"start_time":"2020-11-19T22:05:26.056186","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Be aware that because this is a code competition with a hidden test set, internet and TPUs cannot be enabled on your submission notebook. Therefore TPUs will only be available for training models. For a walk-through on how to train on TPUs and run inference/submit on GPUs, see our [TPU Docs](https://www.kaggle.com/docs/tpu#tpu6).","metadata":{"papermill":{"duration":1.255302,"end_time":"2020-11-19T22:05:30.746339","exception":false,"start_time":"2020-11-19T22:05:29.491037","status":"completed"},"tags":[]}}]}