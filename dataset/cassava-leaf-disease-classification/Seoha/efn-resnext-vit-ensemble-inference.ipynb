{"cells":[{"metadata":{},"cell_type":"markdown","source":"# EFN+ResNext+ViT Ensemble Inference\nif this helps, please do Upvote this code and the original üëçüèº\n\n< Reference Code > <br>\n-[Pytorch Efficientnet Baseline [Inference] TTA](https://www.kaggle.com/khyeh0719/pytorch-efficientnet-baseline-inference-tta)"},{"metadata":{},"cell_type":"markdown","source":"# Import Library"},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"from glob import glob\nfrom sklearn.model_selection import GroupKFold, StratifiedKFold\nimport cv2\nfrom skimage import io\nimport torch\nfrom torch import nn\nimport os\nfrom datetime import datetime\nimport time\nimport random\nimport cv2\nimport torchvision\nfrom torchvision import transforms\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\n\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset,DataLoader\nfrom  torch.cuda.amp import autocast, GradScaler\n\nimport sklearn\nimport joblib\nfrom sklearn.metrics import roc_auc_score, log_loss\nfrom sklearn import metrics\nimport cv2\nfrom sklearn.metrics import log_loss\n\n!pip install ../input/timmpackagelatestwhl/timm-0.3.4-py3-none-any.whl\nimport timm\nimport warnings \nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CFG Setting"},{"metadata":{"trusted":true},"cell_type":"code","source":"CFG = {\n    'seed': 719,\n    'model_arch': ['tf_efficientnet_b4_ns','resnext50_32x4d','vit_base_patch16_384'],\n    'weight_path': sorted(os.listdir('../input/cassava-ensemble-model')),\n    'img_size': 512,\n    'train_bs': 64,\n    'valid_bs': 64,\n    'lr': 1e-4,\n    'num_workers': 4,\n    'device': 'cuda',\n    'tta': 2,\n    'weights': [1,1,1,1,1,1]\n}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Import Test Set"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/cassava-leaf-disease-classification/train.csv')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Helper Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\ndef get_img(path):\n    im_bgr = cv2.imread(path)\n    im_rgb = im_bgr[:, :, ::-1]\n    return im_rgb","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DataSet for Loader"},{"metadata":{"trusted":true},"cell_type":"code","source":"class CassavaDataset(Dataset):\n    def __init__(\n        self, df, data_root, transforms=None, output_label=True):\n        super().__init__()\n        self.df = df.reset_index(drop=True).copy()\n        self.transforms = transforms\n        self.data_root = data_root\n        self.output_label = output_label\n    \n    def __len__(self):\n        return self.df.shape[0]\n    \n    def __getitem__(self, index: int):\n        if self.output_label:\n            target = self.df.iloc[index]['label']\n        path = \"{}/{}\".format(self.data_root, self.df.iloc[index]['image_id'])\n        img  = get_img(path)\n        if self.transforms:\n            img = self.transforms(image=img)['image']\n        if self.output_label == True:\n            return img, target\n        else:\n            return img","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Augmentations"},{"metadata":{"trusted":true},"cell_type":"code","source":"from albumentations import (\n    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, CenterCrop, Resize)\nfrom albumentations.pytorch import ToTensorV2\n\ndef get_inference_transforms():\n    return Compose([\n            RandomResizedCrop(CFG['img_size'], CFG['img_size']),\n            Transpose(p=0.5),\n            HorizontalFlip(p=0.5),\n            VerticalFlip(p=0.5),\n            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n            RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n            ToTensorV2(p=1.0),\n        ], p=1.)\n\ndef get_inference_transforms_vit():\n    return Compose([\n            RandomResizedCrop(CFG['img_size'], CFG['img_size']),\n            Resize(384, 384),\n            Transpose(p=0.5),\n            HorizontalFlip(p=0.5),\n            VerticalFlip(p=0.5),\n            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n            RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n            ToTensorV2(p=1.0),\n        ], p=1.)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"class EnsembleModel(nn.Module):\n    def __init__(self, model_arch, n_class, pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(model_arch, pretrained=pretrained)\n        if model_arch == 'tf_efficientnet_b4_ns':\n            n_features = self.model.classifier.in_features\n            self.model.classifier = nn.Linear(n_features, n_class)\n        if model_arch == 'resnext50_32x4d':\n            n_features = self.model.fc.in_features\n            self.model.fc = nn.Linear(n_features, n_class)\n        if model_arch == 'vit_base_patch16_384':\n            n_features = self.model.head.in_features\n            self.model.head = nn.Linear(n_features, n_class)\n        \n    def forward(self, x):\n        x = self.model(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Inference Function"},{"metadata":{"trusted":true},"cell_type":"code","source":"def inference_one_epoch(model, data_loader, device):\n    model.eval()\n    image_preds_all = []\n    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n    for step, (imgs) in pbar:\n        imgs = imgs.to(device).float()\n        image_preds = model(imgs)\n        image_preds_all += [torch.softmax(image_preds, 1).detach().cpu().numpy()]\n    image_preds_all = np.concatenate(image_preds_all, axis=0)\n    return image_preds_all","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Main - Inference"},{"metadata":{"trusted":true},"cell_type":"code","source":"if __name__ == '__main__':\n    seed_everything(CFG['seed'])\n    for ix, model_arch in enumerate(CFG['model_arch']):\n        TEST_DIR = '../input/cassava-leaf-disease-classification/test_images/'\n        test = pd.DataFrame(); test['image_id'] = list(os.listdir(TEST_DIR))\n        if model_arch=='vit_base_patch16_384':\n            testset= CassavaDataset(test, TEST_DIR, transforms=get_inference_transforms_vit(), output_label=False)\n        else: \n            testset= CassavaDataset(test, TEST_DIR, transforms=get_inference_transforms(), output_label=False)\n        tst_loader = DataLoader(testset, batch_size=CFG['valid_bs'],num_workers=CFG['num_workers'],shuffle=False,pin_memory=False,)\n        \n        device = torch.device(CFG['device'])\n        model = EnsembleModel(model_arch, train.label.nunique()).to(device)\n        tst_preds = []\n        for i,weight in enumerate(CFG['weight_path'][ix*2:ix*2+2]):    \n            model.load_state_dict(torch.load(os.path.join('../input/cassava-ensemble-model',weight))['model'])\n            with torch.no_grad():\n                for _ in range(CFG['tta']):\n                    tst_preds += [CFG['weights'][i]/sum(CFG['weights'])/CFG['tta']*inference_one_epoch(model, tst_loader, device)]\n        avg_tst_preds = np.mean(tst_preds, axis=0)\n\n        if not (os.path.isdir('./total_preds')): os.mkdir('./total_preds')\n        np.save('./total_preds/total_preds.npy', tst_preds)\n        if not (os.path.isdir('./mean_preds')): os.mkdir('./mean_preds')\n        np.save('./mean_preds/mean_preds.npy', avg_tst_preds)\n\n        del model\n        torch.cuda.empty_cache()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Make Submission File"},{"metadata":{"trusted":true},"cell_type":"code","source":"test['label'] = np.argmax(avg_tst_preds, axis=1)\ntest.to_csv('submission.csv', index=False)\ntest.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}