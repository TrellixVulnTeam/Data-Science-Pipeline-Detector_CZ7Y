{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**This Notebook mostly cover with visual demmonstration of various types of advance augmentation. For that, It becomes heavier to load quickly and may take few time to load the notebook.**\n\n![image](https://user-images.githubusercontent.com/17668390/169665594-608f7468-7323-41f8-9ba0-400fe9eb828f.gif)\n\n---\n\n### Update : Mosaic Augmentation\n\nI am trying to add the **Mosaic** augmentation. However, it's not completed yet. To create a class label in `CutMix` or `MixUp` type augmentation, we can use `beta` such as `np.random.beta` or `scipy.stats.beta` and do as follows for two labels:\n\n\n```\nlabel = label_one*beta + (1-beta)*label_two\n```\n\nBut what if we've **more than two** images? In [YoLo4](https://arxiv.org/abs/2004.10934), they've tried an interesting augmentation called **Mosaic Augmentation** for object detection problems. Unlike `CutMix` or `MixUp`, this augmentation creates augmented samples with **4** images. Here is a asked question over [Stack Overflow](https://stackoverflow.com/questions/65181294/how-to-create-class-label-for-mosaic-augmentation-in-image-classification), there we can find some approaches, please feel free to share your implementation. -)","metadata":{"_kg_hide-input":false}},{"cell_type":"markdown","source":"# Advanced Augmentation\n\nHi, This is a simple EDA and data augmentation pipeline for multi-class image classification with custom sequence data generator in `tf.keras`. Here image samples will be used. Mainly I will show how you can use some of the advanced augmentation in a custom `tf.keras.utils.Sequence` generator in `tf.keras`. Note, **we will add only multi-class image classification data set**, e.g., \n\n- [Cassava Leaf Disease Classification](https://www.kaggle.com/c/cassava-leaf-disease-classification)\n- [APTOS 2019](https://www.kaggle.com/c/aptos2019-blindness-detection)\n\n\nThe advanced augmentaiton are as follows:\n\n```\n- CutMix\n- MixUp\n- FMix\n- RGBShift\n- ChannelShuffle\n- ColorJitter\n```\n\nThe implementations of `CutMix` and `MixUp` augmentation are taken from [Chris Deotte](https://www.kaggle.com/cdeotte/cutmix-and-mixup-on-gpu-tpu) and integrated into a custom [tf.keras.utils.Sequence](https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence) generator with few modification. The `FMix` is simply taken from the original source code, from [here](https://github.com/ecs-vlc/FMix). ","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom glob import glob\nfrom pylab import rcParams\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\nimport os, gc, cv2, random, warnings, math, sys, json, pprint\n\n# sklearn\nfrom sklearn.utils import class_weight\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score, balanced_accuracy_score\n\n# tf \nimport tensorflow as tf\nfrom tensorflow import keras \nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \nwarnings.simplefilter('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-21T19:01:47.724053Z","iopub.execute_input":"2022-05-21T19:01:47.725086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# helper function to plot sample \ndef plot_imgs(dataset_show, row, col):\n    rcParams['figure.figsize'] = 30,15\n    for i in range(row):\n        f, ax = plt.subplots(1,col)\n        for p in range(col):\n            idx = np.random.randint(0, len(dataset_show))\n            img, label = dataset_show[idx]\n            ax[p].grid(False)\n            ax[p].imshow(img[0])\n            try:\n                ax[p].set_title(label[0].numpy())\n            except:\n                ax[p].set_title(label[0])\n    plt.show()\n    \n\ndef visulize(path, n_images, is_random=True, figsize=(16, 16)):\n    plt.figure(figsize=figsize)\n    \n    w = int(n_images ** .5)\n    h = math.ceil(n_images / w)\n    \n    image_names = os.listdir(path)\n    for i in range(n_images):\n        image_name = image_names[i]\n        \n        if is_random:\n            image_name = random.choice(image_names)\n            \n        img = cv2.imread(os.path.join(path, image_name))\n        plt.subplot(h, w, i + 1)\n        plt.imshow(img)\n        plt.xticks([])\n        plt.yticks([])\n    plt.show()","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Competition Data\n\nCurrently, we have 3 multi-class competition data to play with. We will add more and also add new interesting augmentation. We can choose any of the following competition data set.\n\n- [Cassava Leaf Disease Classification](https://www.kaggle.com/c/cassava-leaf-disease-classification)\n- [APTOS 2019](https://www.kaggle.com/c/aptos2019-blindness-detection)","metadata":{}},{"cell_type":"markdown","source":"**Choose a Dataset**","metadata":{}},{"cell_type":"code","source":"# use casava leaf disease comp. (multi-class problem)\nuse_casava = False\n\n# use aptos comp. (multi-class prob)\nuse_aptos  = False\n\n# use flower recognition data from kaggle \nuse_flower_recognition = True","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_DIM = (224, 224, 3)\nBATCH_SIZ = 25\nSEED  = 101","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BaseConfig(object):\n    if use_casava:\n        TRAIN_DF = '../input/cassava-leaf-disease-classification/train.csv'\n        TRAIN_IMG_PATH = '../input/cassava-leaf-disease-classification/train_images/'\n        TEST_IMG_PATH  = '../input/cassava-leaf-disease-classification/test_images/'\n        CLASS_MAP  = '../input/cassava-leaf-disease-classification/label_num_to_disease_map.json'\n        NUM_CLASSES = 5\n    \n    elif use_aptos:\n        TRAIN_DF = '../input/aptos2019-blindness-detection/train.csv'\n        TRAIN_IMG_PATH = '../input/aptos2019-blindness-detection/train_images/'\n        TEST_IMG_PATH  = '../input/aptos2019-blindness-detection/test_images/'\n        NUM_CLASSES = 5\n    \n    elif use_flower_recognition:\n        TRAIN_IMG_PATH = '../input/flowers-recognition/flowers'\n        train_datagen = ImageDataGenerator()\n        train_generator = train_datagen.flow_from_directory(\n            TRAIN_IMG_PATH,\n            target_size=IMAGE_DIM[:2],\n            batch_size=BATCH_SIZ,\n            seed=SEED, \n            shuffle=True,\n            class_mode='categorical'\n        )\n        NUM_CLASSES = 5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Overview**","metadata":{}},{"cell_type":"code","source":"try:\n    df = pd.read_csv(BaseConfig.TRAIN_DF)\n    \n    if use_casava:\n        assert df.shape[0] == len(df.image_id.unique()) , \"NOT ALL ID UNIQUE\"\n    elif use_aptos:\n        assert df.shape[0] == len(df.id_code.unique()), \"NOT ALL ID UNIQUE\"\n    \n    print(df.info())\n    df.head()\nexcept:\n    pass","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Custom Sequence Data Generator","metadata":{}},{"cell_type":"code","source":"class SequenceGenerator(keras.utils.Sequence):\n    def __init__(self, \n                 img_path, \n                 data, \n                 batch_size, \n                 dim, \n                 shuffle=True, \n                 use_mosaicmix=False):\n        self.dim  = dim\n        self.data = data\n        self.shuffle  = shuffle\n        self.img_path = img_path\n        self.batch_size = batch_size\n        self.use_mosaicmix = use_mosaicmix\n        self.list_idx   = self.data.index.values\n        if use_casava:\n            self.label = pd.get_dummies(self.data['label'], columns = ['label'])\n        elif use_aptos:\n            self.label = pd.get_dummies(self.data['diagnosis'], columns = ['diagnosis'])\n        self.on_epoch_end()\n        \n    def __len__(self):\n        return int(np.ceil(float(len(self.data)) / float(self.batch_size)))\n    \n    def __getitem__(self, index):\n        batch_idx = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n        idx = [self.list_idx[k] for k in batch_idx]\n        \n        Data   = np.empty((self.batch_size, *self.dim))\n        Target = np.empty((self.batch_size, BaseConfig.NUM_CLASSES), dtype = np.float32)\n\n        for i, k in enumerate(idx):\n            # load the image file using cv2\n            if use_casava:\n                image = cv2.imread(self.img_path + self.data['image_id'][k])\n                image = image[:,:,::-1]\n            elif use_aptos:\n                image = cv2.imread(self.img_path + self.data['id_code'][k] + '.png')\n                image = image[:,:,::-1]\n            image = cv2.resize(image, self.dim[:2])\n\n            # assign \n            Data[i,] =  image\n            Target[i,] = self.label.iloc[k,].values\n            \n        if self.use_mosaicmix:\n            Data, Target = MosaicMix(Data, Target, self.dim[0]) \n\n        return Data, Target \n    \n    def on_epoch_end(self):\n        self.indices = np.arange(len(self.list_idx))\n        if self.shuffle:\n            np.random.shuffle(self.indices)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if use_casava or use_aptos:\n    datagens = SequenceGenerator(\n            BaseConfig.TRAIN_IMG_PATH, \n            df, \n            batch_size=BATCH_SIZ,\n            dim=IMAGE_DIM,\n            shuffle = True\n        )\nelse:\n    datagens = BaseConfig.train_generator","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images, labels = next(\n    iter\n    (\n        datagens\n    )\n)\n\nimages.shape, labels.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CutMix Augmentation","metadata":{}},{"cell_type":"code","source":"def CutMix(image, label, DIM, PROBABILITY = 1.0):\n    # input image - is a batch of images of size [n,dim,dim,3] not a single image of [dim,dim,3]\n    # output - a batch of images with cutmix applied\n    CLASSES = BaseConfig.NUM_CLASSES\n    \n    imgs = []; labs = []\n    for j in range(len(image)):\n        # DO CUTMIX WITH PROBABILITY DEFINED ABOVE\n        P = tf.cast( tf.random.uniform([],0,1)<=PROBABILITY, tf.int32)\n        \n        # CHOOSE RANDOM IMAGE TO CUTMIX WITH\n        k = tf.cast( tf.random.uniform([],0,len(image)),tf.int32)\n        \n        # CHOOSE RANDOM LOCATION\n        x = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\n        y = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\n        \n        b = tf.random.uniform([],0,1) # this is beta dist with alpha=1.0\n        \n        WIDTH = tf.cast( DIM * tf.math.sqrt(1-b),tf.int32) * P\n        ya = tf.math.maximum(0,y-WIDTH//2)\n        yb = tf.math.minimum(DIM,y+WIDTH//2)\n        xa = tf.math.maximum(0,x-WIDTH//2)\n        xb = tf.math.minimum(DIM,x+WIDTH//2)\n        \n        # MAKE CUTMIX IMAGE\n        one = image[j,ya:yb,0:xa,:]\n        two = image[k,ya:yb,xa:xb,:]\n        three = image[j,ya:yb,xb:DIM,:]\n        middle = tf.concat([one,two,three],axis=1)\n        img = tf.concat([image[j,0:ya,:,:],middle,image[j,yb:DIM,:,:]],axis=0)\n        imgs.append(img)\n        \n        # MAKE CUTMIX LABEL\n        a = tf.cast(WIDTH*WIDTH/DIM/DIM,tf.float32)\n        labs.append((1-a)*label[j] + a*label[k])\n            \n    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\n    image2 = tf.reshape(tf.stack(imgs),(len(image),DIM,DIM,3))\n    label2 = tf.reshape(tf.stack(labs),(len(image),CLASSES))\n    \n    return image2,label2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cutmix_image, cutmix_label = CutMix(images, labels, IMAGE_DIM[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(20, 20))\ncolumns = 4\nrows = 5\n\nfor i in range(1, columns*rows +1):\n    img = cutmix_image[i].numpy().astype('int')\n    lbl = cutmix_label[i].numpy()\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(img)\n    plt.axis(\"off\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## MixUp Augmentation","metadata":{}},{"cell_type":"code","source":"def MixUp(image, label, DIM, PROBABILITY = 1.0):\n    # input image - is a batch of images of size [n,dim,dim,3] not a single image of [dim,dim,3]\n    # output - a batch of images with mixup applied\n    CLASSES = BaseConfig.NUM_CLASSES\n    \n    imgs = []; labs = []\n    for j in range(len(image)):\n        # DO MIXUP WITH PROBABILITY DEFINED ABOVE\n        P = tf.cast( tf.random.uniform([],0,1)<=PROBABILITY, tf.float32)\n                   \n        # CHOOSE RANDOM\n        k = tf.cast( tf.random.uniform([],0,len(image)),tf.int32)\n        a = tf.random.uniform([],0,1)*P # this is beta dist with alpha=1.0\n                    \n        # MAKE MIXUP IMAGE\n        img1 = image[j,]\n        img2 = image[k,]\n        imgs.append((1-a)*img1 + a*img2)\n                    \n        # MAKE CUTMIX LABEL\n        labs.append((1-a)*label[j] + a*label[k])\n            \n    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\n    image2 = tf.reshape(tf.stack(imgs),(len(image),DIM,DIM,3))\n    label2 = tf.reshape(tf.stack(labs),(len(image),CLASSES))\n    return image2,label2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mixup_image, mixup_label = MixUp(images, labels, IMAGE_DIM[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(20, 20))\ncolumns = 4\nrows = 5\n\nfor i in range(1, columns*rows +1):\n    img = mixup_image[i].numpy().astype('int')\n    lbl = mixup_label[i].numpy()\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(img)\n    plt.axis(\"off\")\n    \nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## FMix Augmentation","metadata":{}},{"cell_type":"code","source":"sys.path.insert(0, \"/kaggle/input/pyutils\")\nfrom fmix_utils import sample_mask\n\ndef FMix(image, label, DIM,  alpha=1, decay_power=3, max_soft=0.0, reformulate=False):\n    lam, mask = sample_mask(alpha, decay_power,(DIM, DIM), max_soft, reformulate)\n    index = tf.constant(np.random.permutation(int(image.shape[0])))\n    mask  = np.expand_dims(mask, -1)\n    \n    # samples \n    image1 = image * mask\n    image2 = tf.gather(image, index) * (1 - mask)\n    image3 = image1 + image2\n\n    # labels\n    label1 = label * lam \n    label2 = tf.gather(label, index) * (1 - lam)\n    label3 = label1 + label2 \n    return image3, label3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fmix_image, fmix_label = FMix(images, labels, IMAGE_DIM[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(20, 20))\ncolumns = 4\nrows = 5\n\nfor i in range(1, columns*rows +1):\n    img = fmix_image[i].numpy().astype('int')\n    lbl = fmix_label[i].numpy()\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(img)\n    plt.axis(\"off\")\n    \nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Mosaic Augmentation [Work In Progress]","metadata":{}},{"cell_type":"code","source":"def MosaicMix(image, label, DIM, minfrac=0.25, maxfrac=0.75):\n    xc, yc  = np.random.randint(DIM * minfrac, DIM * maxfrac, (2,))\n    indices = np.random.permutation(int(image.shape[0]))\n    mosaic_image = np.zeros((DIM, DIM, 3), dtype=np.float32)\n    final_imgs   = []\n    \n    # Iterate over the full indices \n    for j in range(len(indices)): \n        # Take 4 sample for to create a mosaic sample randomly \n        rand4indices = [j] + random.sample(list(indices), 3) \n        \n        # Make mosaic with 4 samples \n        for i in range(len(rand4indices)):\n            if i == 0:    # top left\n                x1a, y1a, x2a, y2a =  0,  0, xc, yc\n                x1b, y1b, x2b, y2b = DIM - xc, DIM - yc, DIM, DIM # from bottom right        \n            elif i == 1:  # top right\n                x1a, y1a, x2a, y2a = xc, 0, DIM , yc\n                x1b, y1b, x2b, y2b = 0, DIM - yc, DIM - xc, DIM # from bottom left\n            elif i == 2:  # bottom left\n                x1a, y1a, x2a, y2a = 0, yc, xc, DIM\n                x1b, y1b, x2b, y2b = DIM - xc, 0, DIM, DIM-yc   # from top right\n            elif i == 3:  # bottom right\n                x1a, y1a, x2a, y2a = xc, yc,  DIM, DIM\n                x1b, y1b, x2b, y2b = 0, 0, DIM-xc, DIM-yc    # from top left\n                \n            # Copy-Paste\n            mosaic_image[y1a:y2a, x1a:x2a] = image[i,][y1b:y2b, x1b:x2b]\n                   \n        # Append the Mosiac samples\n        final_imgs.append(mosaic_image)\n \n    return final_imgs, label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_imgs(dataset_show, row, col):\n    rcParams['figure.figsize'] = 30,15\n    for i in range(row):\n        f, ax = plt.subplots(1,col)\n        for p in range(col):\n            idx = np.random.randint(0, len(dataset_show))\n            img, label = dataset_show[idx]\n            ax[p].grid(False)\n            ax[p].imshow(img[0]/255.)\n            ax[p].axis('off')\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if not use_casava or use_aptos:\n#     # WIP\n#     ds = tf.data.Dataset.from_generator(\n#         lambda: datagens, \n#         output_types=(tf.float32, tf.float32), \n#         output_shapes=([BATCH_SIZ, 224, 224, 3], [BATCH_SIZ, BaseConfig.NUM_CLASSES])\n#     )\n    \n#     ds_mos = ds.map(lambda x, y: MosaicMix(x, y, IMAGE_DIM[0]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if use_casava or use_aptos:\n    mosaic_gens = SequenceGenerator(\n        BaseConfig.TRAIN_IMG_PATH, \n        df, \n        batch_size=BATCH_SIZ,\n        dim=IMAGE_DIM,\n        shuffle = True,\n        use_mosaicmix = True\n    )\n    \n    plot_imgs(mosaic_gens, 10, 3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Channel Shuffle","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import layers\n\nclass ChannelShuffle(layers.Layer):\n    def __init__(self, groups=3, seed=None, **kwargs):\n        super().__init__(**kwargs)\n        self.groups = groups\n        self.seed = seed\n\n    def _channel_shuffling(self, images):\n        unbatched = images.shape.rank == 3\n        if unbatched:\n            images = tf.expand_dims(images, axis=0)\n\n        height = tf.shape(images)[1]\n        width = tf.shape(images)[2]\n        num_channels = images.shape[3]\n\n        if not num_channels % self.groups == 0:\n            raise ValueError(\n                \"The number of input channels should be \"\n                \"divisible by the number of groups.\"\n                f\"Received: channels={num_channels}, groups={self.groups}\"\n            )\n\n        channels_per_group = num_channels // self.groups\n        images = tf.reshape(\n            images, [-1, height, width, self.groups, channels_per_group]\n        )\n        images = tf.transpose(images, perm=[3, 1, 2, 4, 0])\n        images = tf.random.shuffle(images, seed=self.seed)\n        images = tf.transpose(images, perm=[4, 1, 2, 3, 0])\n        images = tf.reshape(images, [-1, height, width, num_channels])\n\n        if unbatched:\n            images = tf.squeeze(images, axis=0)\n\n        return images\n\n    def call(self, images, training=True):\n        if training:\n            return self._channel_shuffling(images)\n        else:\n            return images\n\n    def get_config(self):\n        config = super().get_config()\n        config.update({\"groups\": self.groups, \"seed\": self.seed})\n        return config","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"chlshl_image = ChannelShuffle(groups=3)(images)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(20, 20))\ncolumns = 4\nrows = 5\n\nfor i in range(1, columns*rows +1):\n    img = chlshl_image[i].numpy().astype('int')\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(img)\n    plt.axis(\"off\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Color Jitter","metadata":{}},{"cell_type":"code","source":"class ColorJitter(layers.Layer):\n    def __init__(\n        self,\n        brightness_factor=0.5,\n        contrast_factor=(0.5, 0.9),\n        saturation_factor=(0.5, 0.9),\n        hue_factor=0.5,\n        seed=None,\n        **kwargs,\n    ):\n        super().__init__(**kwargs)\n        self.seed = seed\n        self.brightness_factor = self._check_factor_limit(\n            brightness_factor, name=\"brightness\"\n        )\n        self.contrast_factor = self._check_factor_limit(\n            contrast_factor, name=\"contrast\"\n        )\n        self.saturation_factor = self._check_factor_limit(\n            saturation_factor, name=\"saturation\"\n        )\n        self.hue_factor = self._check_factor_limit(hue_factor, name=\"hue\")\n\n    def _check_factor_limit(self, factor, name):\n        if isinstance(factor, (int, float)):\n            if factor < 0:\n                raise TypeError(\n                    \"The factor value should be non-negative scalar or tuple \"\n                    f\"or list of two upper and lower bound number. Received: {factor}\"\n                )\n            if name == \"brightness\" or name == \"hue\":\n                return abs(factor)\n            return (0, abs(factor))\n        elif isinstance(factor, (tuple, list)) and len(factor) == 2:\n            if name == \"brightness\" or name == \"hue\":\n                raise ValueError(\n                    \"The factor limit for brightness and hue, it should be a single \"\n                    f\"non-negative scaler. Received: {factor} for {name}\"\n                )\n            return sorted(factor)\n        else:\n            raise TypeError(\n                \"The factor value should be non-negative scalar or tuple \"\n                f\"or list of two upper and lower bound number. Received: {factor}\"\n            )\n\n    def _color_jitter(self, images):\n        original_dtype = images.dtype\n        images = tf.cast(images, dtype=tf.float32)\n\n        brightness = tf.image.random_brightness(\n            images, max_delta=self.brightness_factor * 255.0, seed=self.seed\n        )\n        brightness = tf.clip_by_value(brightness, 0.0, 255.0)\n\n        contrast = tf.image.random_contrast(\n            brightness,\n            lower=self.contrast_factor[0],\n            upper=self.contrast_factor[1],\n            seed=self.seed,\n        )\n        saturation = tf.image.random_saturation(\n            contrast,\n            lower=self.saturation_factor[0],\n            upper=self.saturation_factor[1],\n            seed=self.seed,\n        )\n        hue = tf.image.random_hue(saturation, max_delta=self.hue_factor, seed=self.seed)\n        return tf.cast(hue, original_dtype)\n\n    def call(self, images, training=True):\n        if training:\n            return self._color_jitter(images)\n        else:\n            return images\n\n    def get_config(self):\n        config = super().get_config()\n        config.update(\n            {\n                \"brightness_factor\": self.brightness_factor,\n                \"contrast_factor\": self.contrast_factor,\n                \"saturation_factor\": self.saturation_factor,\n                \"hue_factor\": self.hue_factor,\n                \"seed\": self.seed,\n            }\n        )\n        return config","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cjit_image = ColorJitter()(images)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(20, 20))\ncolumns = 4\nrows = 5\n\nfor i in range(1, columns*rows +1):\n    img = cjit_image[i].numpy().astype('int')\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(img)\n    plt.axis(\"off\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## RGBShift","metadata":{"execution":{"iopub.status.busy":"2022-04-01T07:17:54.292559Z","iopub.execute_input":"2022-04-01T07:17:54.292998Z","iopub.status.idle":"2022-04-01T07:17:54.297488Z","shell.execute_reply.started":"2022-04-01T07:17:54.29296Z","shell.execute_reply":"2022-04-01T07:17:54.296588Z"}}},{"cell_type":"code","source":"class RGBShift(layers.Layer):\n    \"\"\"RGBShift class randomly shift values for each channel of the input RGB image. \n    The expected images should be [0-255] pixel ranges.\n    Input shape:\n        3D (unbatched) or 4D (batched) tensor with shape:\n        `(..., height, width, channels)`, in `\"channels_last\"` format\n    Output shape:\n        3D (unbatched) or 4D (batched) tensor with shape:\n        `(..., height, width, channels)`, in `\"channels_last\"` format\n    Args:\n        factor: A scalar or tuple or list of two upper and lower bound number. \n            If factor is a single value, the range will be (-factor, factor). \n            The factor value can be float or integer; for float the valid limits are \n            (-1.0, 1.0) and for integer the valid limits are (-255, 255).\n        seed: Integer. Used to create a random seed. Default: None.\n    Call arguments: call method for the RGBShift layer.\n        Args:\n            images: Tensor representing images of shape\n                [batch_size, width, height, channels], with dtype tf.float32 / tf.uint8, or,\n                [width, height, channels], with dtype tf.float32 / tf.uint8\n        Returns:\n            images: augmented images, same shape as input.\n   \n    Usage:\n    ```python\n    (images, labels), _ = tf.keras.datasets.cifar10.load_data()\n    rgbshift = keras_cv.layers.RGBShift(factor=(-2, 2))\n    augmented_images = rgbshift(images)\n    ```\n    \"\"\"\n    def __init__(\n        self,\n        factor,\n        seed=None,\n        **kwargs\n    ):\n        super().__init__(**kwargs)\n        self.factor = self._set_shift_limit(factor)\n        self.seed = seed\n        \n    def _set_shift_limit(self, factor):\n        if isinstance(factor, (tuple, list)):\n            if len(factor) != 2: \n                raise ValueError(f'The factor should be scalar, tuple or list of two upper and lower \\\n                                            bound number. Got {factor}')\n            return self._check_factor_range(sorted(factor))\n        elif isinstance(factor, (int, float)):\n            factor = abs(factor)\n            return self._check_factor_range([-factor, factor])\n        else:\n            raise ValueError(f'The factor should be scalar, tuple or list of two upper and lower bound \\\n                                            umber. Got {factor}')\n            \n    @staticmethod\n    def _check_factor_range(factor):\n        if all(isinstance(each_elem, float) for each_elem in factor):\n            if factor[0] < -1.0 or factor[1] > 1.0:\n                raise ValueError(f\"Got {factor}\")\n            return factor\n        elif all(isinstance(each_elem, int) for each_elem in factor):\n            if factor[0] < -255 or factor[1] > 255:\n                raise ValueError(f\"Got {factor}\")\n            return factor\n        else:\n            raise ValueError(f'Both bound must be same dtype. Got {factor}')\n            \n    def _get_random_uniform(self, shift_limit, rgb_delta_shape):\n            if self.seed is not None:\n                _rand_uniform = tf.random.stateless_uniform(\n                    shape=rgb_delta_shape,\n                    seed=[0, self.seed],\n                    minval=shift_limit[0],\n                    maxval=shift_limit[1],\n                )\n            else:\n                _rand_uniform = tf.random.uniform(\n                    rgb_delta_shape, \n                    minval=shift_limit[0], \n                    maxval=shift_limit[1], \n                    dtype=tf.float32\n                )\n                \n            if all(isinstance(each_elem, float) for each_elem in shift_limit):\n                _rand_uniform = _rand_uniform * 85.0\n            \n            return _rand_uniform\n    \n    def _rgb_shifting(self, images):\n        rank = images.shape.rank\n        original_dtype = images.dtype\n\n        if rank == 3:\n            rgb_delta_shape = (1, 1)\n        elif rank == 4:\n            # Keep only the batch dim. This will ensure to have same adjustment\n            # with in one image, but different across the images.\n            rgb_delta_shape = [tf.shape(images)[0], 1, 1]\n        else:\n            raise ValueError(\n                f\"Expect the input image to be rank 3 or 4. Got {images.shape}\"\n            )\n        r_shift = self._get_random_uniform(self.factor, rgb_delta_shape)   \n        g_shift = self._get_random_uniform(self.factor, rgb_delta_shape)\n        b_shift = self._get_random_uniform(self.factor, rgb_delta_shape)\n        unstack_rgb = tf.unstack(tf.cast(images, dtype=tf.float32), axis=-1)\n        shifted_rgb = tf.stack([tf.add(unstack_rgb[0], r_shift),\n                                tf.add(unstack_rgb[1], g_shift),\n                                tf.add(unstack_rgb[2], b_shift)], axis=-1)\n        shifted_rgb = tf.clip_by_value(shifted_rgb, 0.0, 255.0)\n\n        return tf.cast(shifted_rgb, dtype=original_dtype)\n\n    def call(self, images, training=True):\n        if training:\n            return self._rgb_shifting(images)\n        else:\n            return images\n    def get_config(self):\n        config = super().get_config()\n        config.update(\n            {\n                \"factor\": self.factor, \n                \"seed\": self.seed\n            }\n        )\n        return config \n    def compute_output_shape(self, input_shape):\n        return input_shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rgbshift_images = RGBShift(factor=(-120, 120))(images)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(20, 20))\ncolumns = 4\nrows = 5\n\nfor i in range(1, columns*rows +1):\n    img = rgbshift_images[i].numpy().astype('int')\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(img)\n    plt.axis(\"off\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_stuff(a, b, c, d, titles):\n    plt.figure(figsize=(25, 25))\n    \n    plt.subplot(1, 4, 1)\n    plt.axis('off')\n    plt.imshow(a.astype('int'))\n    plt.title(titles[0])\n    \n    plt.subplot(1, 4, 2)\n    plt.axis('off')\n    plt.imshow(b.astype('int'))\n    plt.title(titles[1])\n    \n    plt.subplot(1, 4, 3)\n    plt.axis('off')\n    plt.imshow(c.astype('int'))\n    plt.title(titles[2])\n    \n    plt.subplot(1, 4, 4)\n    plt.axis('off')\n    plt.imshow(d.astype('int'))\n    plt.title(titles[3])\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rgbshift_images = RGBShift(factor=(-120, 120))(images)\ncjit_image      = ColorJitter()(images)\nchlshl_image    = ChannelShuffle(groups=3)(images)\n\nfmix_image, fmix_label     = FMix(images, labels, IMAGE_DIM[0])\nmixup_image, mixup_label   = MixUp(images, labels, IMAGE_DIM[0])\ncutmix_image, cutmix_label = CutMix(images, labels, IMAGE_DIM[0])\n\n\nfor i, (orig, rg, cj, ch, fm, mi, cu) in enumerate(zip(images, rgbshift_images, \n                                                       cjit_image, chlshl_image, \n                                                       fmix_image, mixup_image, \n                                                       cutmix_image)):\n    plot_stuff(\n        orig,\n        rg.numpy(),\n        cj.numpy(), \n        ch.numpy(), \n        ['Input', 'RGBShift', 'ColorJitter', 'ChannelShuffle']\n    )\n    \n    plot_stuff(\n        orig,\n        fm.numpy(),\n        mi.numpy(),\n        cu.numpy(),\n        ['Input','FMix', 'MixUp', 'CutMix']\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n\n## Resource\n\n- [[TF.Keras] Melanoma Classification Starter, TabNet](https://www.kaggle.com/ipythonx/tf-keras-melanoma-classification-starter-tabnet)\n- [[TF.Keras]: Cassava: Advanced Training Mechanism](https://www.kaggle.com/ipythonx/tf-keras-cassava-advanced-training-mechanism)\n- [[TF]: 3D & 2D Model for Brain Tumor Classification](https://www.kaggle.com/ipythonx/tf-3d-2d-model-for-brain-tumor-classification/notebook)\n- [[TF]: Segmentation Modeling into Classifier Model](https://www.kaggle.com/ipythonx/tf-segmentation-modeling-into-classifier-model/notebook)\n- [[Keras]: Bengali.AI Grapheme Classification](https://www.kaggle.com/ipythonx/keras-bengali-ai-grapheme-classification?scriptVersionId=65475261)","metadata":{}}]}