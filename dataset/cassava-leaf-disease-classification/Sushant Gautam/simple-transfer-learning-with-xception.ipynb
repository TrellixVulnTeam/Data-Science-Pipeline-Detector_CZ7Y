{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas  as pd\nimport numpy as np\nimport matplotlib.pyplot  as plt\nfrom sklearn.utils import shuffle\nimport cv2\n\nimport tensorflow as tf \nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Dense,Dropout, Flatten, BatchNormalization, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model\nfrom keras import backend as k \nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping, ReduceLROnPlateau\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_path = '../input/cassava-leaf-disease-classification/'\ntrain_csv_data_path = data_path + 'train.csv'\nlabel_json_data_path = data_path + 'label_num_to_disease_map.json'\nimages_dir_data_path = data_path + 'train_images'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_csv = pd.read_csv(train_csv_data_path)\ntrain_csv['label'] = train_csv['label'].astype('string')\n\nlabel_class = pd.read_json(label_json_data_path, orient='index')\nlabel_class = label_class.values.flatten().tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_csv.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(label_class)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Label names :\")\nfor i, label in enumerate(label_class):\n    print(f\" {i}. {label}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot some train images\nIMG_SIZE = 300\npaths_show = [images_dir_data_path + \"/\" + train_csv.iloc[i]['image_id'] for i in range(6)]\nprint(paths_show)\nplt.figure(figsize=(40,50))\nfor i in range(6):\n    img = cv2.cvtColor(cv2.imread(paths_show[i]), cv2.COLOR_BGR2RGB)\n    resized_img = cv2.resize(img, (IMG_SIZE, IMG_SIZE)).reshape(-1, IMG_SIZE, IMG_SIZE, 3)/255\n    plt.subplot(4,2,i+1)\n    plt.title('image_show')\n    plt.imshow(resized_img[0])\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Augmentation and Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data augmentation and preprocessing\ntrain_gen = ImageDataGenerator(\n                                rotation_range=360,\n                                width_shift_range=0.1,\n                                height_shift_range=0.1,\n                                brightness_range=[0.1,0.9],\n                                shear_range=25,\n                                zoom_range=0.3,\n                                channel_shift_range=0.1,\n                                horizontal_flip=True,\n                                vertical_flip=True,\n                                rescale=1/255,\n                                validation_split=0.15\n\n                              )\n\nvalid_gen = ImageDataGenerator(rescale=1/255,\n                               validation_split = 0.15\n                              )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 32\nIMG_SIZE = 512\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = train_gen.flow_from_dataframe(\n                            dataframe=train_csv,\n                            directory = images_dir_data_path,\n                            x_col = \"image_id\",\n                            y_col = \"label\",\n                            target_size = (IMG_SIZE, IMG_SIZE),\n                            class_mode = \"categorical\",\n                            batch_size = BATCH_SIZE,\n                            shuffle = True,\n                            subset = \"training\",\n\n)\n\nvalid_generator = valid_gen.flow_from_dataframe(\n                            dataframe=train_csv,\n                            directory = images_dir_data_path,\n                            x_col = \"image_id\",\n                            y_col = \"label\",\n                            target_size = (IMG_SIZE, IMG_SIZE),\n                            class_mode = \"categorical\",\n                            batch_size = BATCH_SIZE,\n                            shuffle = False,\n                            subset = \"validation\"\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualizing Train Set"},{"metadata":{"trusted":true},"cell_type":"code","source":"batch = next(train_generator)\nimages = batch[0]\nlabels = batch[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(train_generator))\nprint(len(valid_generator))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 9))\n# only show 6 images\nfor i, (img, label) in enumerate(zip(images, labels)):\n    # label is like : [0. 0. 0. 1. 0.]\n    plt.subplot(2,3, i%6+1)\n    plt.axis('off')\n    plt.imshow(img)\n    plt.title(label_class[np.argmax(label)])\n    if i == 7:\n        break\n    \n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for Xception\nIMG_SIZE = 512\nmodel_xception = tf.keras.applications.Xception(include_top=False, input_shape=(IMG_SIZE,IMG_SIZE,3), weights=None)\n\nmodel_xception.save_weights('xceptionweights.h5')\n\nmodel_xception.load_weights('xceptionweights.h5')\nmodel_xception.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fine Tune Last layer of Xception"},{"metadata":{"trusted":true},"cell_type":"code","source":"for layer in model_xception.layers:\n    layer.trainable=False\nmodel_xception.layers[-2].trainable = True\nmodel_xception.layers[-3].trainable = True\n\n\n#Adding custom Layers \nx = model_xception.output\nx = GlobalAveragePooling2D()(x)\n# x = Dense(256, activation='relu')(x)\n# x = Dropout(0.3)(x)\nx = Dense(256, activation=\"elu\")(x)\nx = Dropout(0.3)(x)\nx = Dense(50, activation=\"elu\")(x)\nx = Dropout(0.1)(x)\npredictions = Dense(5, activation=\"softmax\")(x)\n\n# creating the final model \nmodel_final = Model(inputs = model_xception.input, outputs = predictions)\nmodel_final.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.optimizers import RMSprop\n# compile the model \nmodel_final.compile(loss = \"categorical_crossentropy\", optimizer =RMSprop(lr=0.001), metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n                              patience=2, min_lr=0.000001)\nmcp_save = ModelCheckpoint('model_train.hdf5', save_best_only=True, monitor='acc', mode='max')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"STEPS_PER_EPOCH = len(train_generator) // BATCH_SIZE\nVALID_STEPS = len(valid_generator) // BATCH_SIZE\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model_final.fit(\n      train_generator,\n      steps_per_epoch=STEPS_PER_EPOCH,\n      epochs=20,\n      validation_data=valid_generator,\n      batch_size= VALID_STEPS,\n      callbacks=[mcp_save]\n      )\n\nmodel_final.save('model_xception_fine_last_layerv1.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualization Accuracy and Loss\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntest_img_path = data_path+\"test_images/2216849948.jpg\"\nimg = cv2.imread(test_img_path)\nresized_img = cv2.resize(img, (IMG_SIZE, IMG_SIZE)).reshape(-1, IMG_SIZE, IMG_SIZE, 3)/255.\nplt.figure(figsize=(8,4))\nplt.title(\"TEST IMAGE\")\nplt.imshow(resized_img[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = []\nss = pd.read_csv(data_path+'sample_submission.csv')\n\nfor image in ss.image_id:\n    img = tf.keras.preprocessing.image.load_img(data_path+'test_images/' + image)\n    img = tf.keras.preprocessing.image.img_to_array(img)\n    img = tf.keras.preprocessing.image.smart_resize(img, (IMG_SIZE, IMG_SIZE))\n    img = tf.reshape(img, (-1, IMG_SIZE, IMG_SIZE, 3))\n    prediction = model_final.predict(img/255)\n    preds.append(np.argmax(prediction))\n\nmy_submission = pd.DataFrame({'image_id': ss.image_id, 'label': preds})\nmy_submission.to_csv('submission.csv', index=False) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  for EfficientNetB7\n# model_effiB7 = tf.keras.applications.EfficientNetB7(include_top=False, input_shape=(IMG_SIZE,IMG_SIZE, 3))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for i, layer in enumerate(model_effiB7.layers):\n#     print(\"{}:  {}\".format(i, layer))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fine tune last layer of efficientnet B7"},{"metadata":{"trusted":true},"cell_type":"code","source":"# for layer in model_effiB7.layers:\n#     layer.trainable=False\n# model_effiB7.layers[-2].trainable = True\n# model_effiB7.layers[-3].trainable = True\n\n\n# #Adding custom Layers \n# x = model_effiB7.output\n# x = GlobalAveragePooling2D()(x)\n# # x = Dense(256, activation='relu')(x)\n# # x = Dropout(0.3)(x)\n# x = Dense(256, activation=\"elu\")(x)\n# x = Dropout(0.3)(x)\n# x = Dense(50, activation=\"elu\")(x)\n# x = Dropout(0.1)(x)\n# predictions = Dense(5, activation=\"softmax\")(x)\n\n# # creating the final model \n# model_final = Model(inputs = model_effiB7.input, outputs = predictions)\n# model_final.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from tensorflow.keras.optimizers import RMSprop\n# # compile the model \n# model_final.compile(loss = \"categorical_crossentropy\", optimizer =RMSprop(lr=0.001), metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will penalize our learning rate,if the validation accuracy does not improve after 2 epoch by 10% and finally train it for given epochs with batch_size=BATCH_SIZE"},{"metadata":{"trusted":true},"cell_type":"code","source":"# reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n#                               patience=2, min_lr=0.000001)\n# mcp_save = ModelCheckpoint('model_train.hdf5', save_best_only=True, monitor='acc', mode='max')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"# history = model_final.fit(\n#       train_generator,\n#       steps_per_epoch=BATCH_SIZE + 10,#len(train_generator)//BATCH_SIZE,\n#       epochs=20,\n#       validation_data=valid_generator,\n#       batch_size= BATCH_SIZE,#len(valid_generator)//BATCH_SIZE,\n#       callbacks=[reduce_lr, mcp_save]\n#       )\n\n# model_final.save('model_efficentNetB7fine_last_layerv1.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visulaization Accuracy and Loss"},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(history.history.keys())\n# # summarize history for accuracy\n# plt.plot(history.history['accuracy'])\n# plt.plot(history.history['val_accuracy'])\n# plt.title('model accuracy')\n# plt.ylabel('accuracy')\n# plt.xlabel('epoch')\n# plt.legend(['train', 'test'], loc='upper left')\n# plt.show()\n# # summarize history for loss\n# plt.plot(history.history['loss'])\n# plt.plot(history.history['val_loss'])\n# plt.title('model loss')\n# plt.ylabel('loss')\n# plt.xlabel('epoch')\n# plt.legend(['train', 'test'], loc='upper left')\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_img_path = data_path+\"test_images/2216849948.jpg\"\n\n# img = cv2.imread(test_img_path)\n# resized_img = cv2.resize(img, (IMG_SIZE, IMG_SIZE)).reshape(-1, IMG_SIZE, IMG_SIZE, 3)/255\n\n# plt.figure(figsize=(8,4))\n# plt.title(\"TEST IMAGE\")\n# plt.imshow(resized_img[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# preds = []\n# ss = pd.read_csv(data_path+'sample_submission.csv')\n\n# for image in ss.image_id:\n#     img = tf.keras.preprocessing.image.load_img(data_path+'test_images/' + image)\n#     img = tf.keras.preprocessing.image.img_to_array(img)\n#     img = tf.keras.preprocessing.image.smart_resize(img, (IMG_SIZE, IMG_SIZE))\n#     img = tf.reshape(img, (-1, IMG_SIZE, IMG_SIZE, 3))\n#     prediction = model_final.predict(img/255)\n#     preds.append(np.argmax(prediction))\n\n# my_submission = pd.DataFrame({'image_id': ss.image_id, 'label': preds})\n# my_submission.to_csv('submission.csv', index=False) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}