{"cells":[{"metadata":{},"cell_type":"markdown","source":"![](https://howtocure.com/wp-content/uploads/2019/10/Cassava-Leaves.jpg)"},{"metadata":{},"cell_type":"markdown","source":"Cassava originated in South America and was introduced to Africa in relatively recent times. It is known to be a very drought-tolerant crop with the ability to yield even when planted in poor soils. When cassava was first grown in Africa, it was used for subsidiary purposes though it is now considered to be one of the most important food staple crops on the continent. Its production is moving toward an industrialized system in which plant material is used for a variety of products including starch, flour, and animal feed."},{"metadata":{},"cell_type":"markdown","source":"As the second-largest provider of carbohydrates in Africa, cassava is a key food security crop grown by smallholder farmers because it can withstand harsh conditions. At least 80% of household farms in Sub-Saharan Africa grow this starchy root, but viral diseases are major sources of poor yields. With the help of data science, it may be possible to identify common diseases so they can be treated.\n\nExisting methods of disease detection require farmers to solicit the help of government-funded agricultural experts to visually inspect and diagnose the plants. This suffers from being labor-intensive, low-supply and costly. As an added challenge, effective solutions for farmers must perform well under significant constraints, since African farmers may only have access to mobile-quality cameras with low-bandwidth."},{"metadata":{},"cell_type":"markdown","source":"![](https://www.bing.com/images/search?view=detailV2&ccid=LnFdsek3&id=304C6B3F770790F5BC0604B8AB370F975A7AE3B8&thid=OIP.LnFdsek3pT7Ed_vrgBv2kQHaE6&mediaurl=http%3a%2f%2fgondwanaecotours.com%2fwp-content%2fuploads%2f2016%2f01%2fcassava-1280x850.jpg&exph=850&expw=1280&q=cassava+leaf&simid=608055820647793674&ck=C7F803AB5B29A6DFAD14B6F61A022DB5&selectedIndex=2&FORM=IRPRST&ajaxhist=0)"},{"metadata":{},"cell_type":"markdown","source":"# **IMPORT RELEVANT LIBRARIES**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n\n\n\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport tensorflow as tf\nfrom tensorflow.keras import models, layers\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.applications import EfficientNetB3\nfrom tensorflow.keras.optimizers import Adam\n\n# ignoring warnings\nimport warnings\nwarnings.simplefilter(\"ignore\")\n\nimport os, cv2, json\nfrom PIL import Image","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. ** PROVIDING PATH FOR THE DIRECTORY**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os \n\n\nWORK_DIR = '../input/cassava-leaf-disease-classification'\nos.listdir(WORK_DIR)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **BASIC LOOK INTO THE DATA**"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Train images: %d' %len(os.listdir(\n    os.path.join(WORK_DIR, \"train_images\"))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open(os.path.join(WORK_DIR, \"label_num_to_disease_map.json\")) as file:\n    print(json.dumps(json.loads(file.read()), indent=4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels = pd.read_csv(os.path.join(WORK_DIR, \"train.csv\"))\ntrain_labels.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **STAGES OF BUILDING A MODEL**"},{"metadata":{},"cell_type":"markdown","source":"PARAMETERS"},{"metadata":{"trusted":true},"cell_type":"code","source":"# target size and number of epochs can be tuned to your needs for obtaining better accuracy\n\n\n\nBATCH_SIZE = 8\nSTEPS_PER_EPOCH = len(train_labels)*0.8 / BATCH_SIZE\nVALIDATION_STEPS = len(train_labels)*0.2 / BATCH_SIZE\nEPOCHS = 20\nTARGET_SIZE = 350","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"IMAGEDATAGENERATOR"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n\n\n\ntrain_labels.label = train_labels.label.astype('str')\n\ntrain_datagen = ImageDataGenerator(validation_split = 0.2,\n                                     preprocessing_function = None,\n                                     rotation_range = 45,\n                                     zoom_range = 0.2,\n                                     horizontal_flip = True,\n                                     vertical_flip = True,\n                                     fill_mode = 'nearest',\n                                     shear_range = 0.1,\n                                     height_shift_range = 0.1,\n                                     width_shift_range = 0.1)\n\n\ntrain_generator = train_datagen.flow_from_dataframe(train_labels,\n                         directory = os.path.join(WORK_DIR, \"train_images\"),\n                         subset = \"training\",\n                         x_col = \"image_id\",\n                         y_col = \"label\",\n                         target_size = (TARGET_SIZE, TARGET_SIZE),\n                         batch_size = BATCH_SIZE,\n                         class_mode = \"sparse\")\n\n\nvalidation_datagen = ImageDataGenerator(validation_split = 0.2)\n\nvalidation_generator = validation_datagen.flow_from_dataframe(train_labels,\n                         directory = os.path.join(WORK_DIR, \"train_images\"),\n                         subset = \"validation\",\n                         x_col = \"image_id\",\n                         y_col = \"label\",\n                         target_size = (TARGET_SIZE, TARGET_SIZE),\n                         batch_size = BATCH_SIZE,\n                         class_mode = \"sparse\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"MODEL"},{"metadata":{},"cell_type":"markdown","source":"SELECT YOUR MODEL ACCORDINGLY\n\n\n\nimportant thing to remmember : chose a model with lesser parameters and higher accuracy\n#here i have taken effeciantnetB0"},{"metadata":{},"cell_type":"markdown","source":"![](https://miro.medium.com/max/828/0*09AED_CjE-PUFxKC.png)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model():\n    conv_base = EfficientNetB3(include_top = False, weights = None,\n                               input_shape = (TARGET_SIZE, TARGET_SIZE, 3))\n    model = conv_base.output\n    model = layers.GlobalAveragePooling2D()(model)\n    model = layers.Dense(5, activation = \"softmax\")(model)\n    model = models.Model(conv_base.input, model)\n\n    model.compile(optimizer = Adam(lr = 0.001),\n                  loss = \"sparse_categorical_crossentropy\",\n                  metrics = [\"acc\"])\n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"SUMMARY"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = create_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Our EfficientNet CNN has %d layers' %len(model.layers))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights('../input/cassava-leaf-disease-models/basic_EfNetB0_imagenet_512.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"TRAINING"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_save = ModelCheckpoint('./EffNetB0_512_8_best_weights.h5', \n                             save_best_only = True, \n                             save_weights_only = True,\n                             monitor = 'val_loss', \n                             mode = 'min', verbose = 1)\nearly_stop = EarlyStopping(monitor = 'val_loss', min_delta = 0.001, \n                           patience = 5, mode = 'min', verbose = 1,\n                           restore_best_weights = True)\nreduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.3, \n                              patience = 2, min_delta = 0.001, \n                              mode = 'min', verbose = 1)\n\n\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch = STEPS_PER_EPOCH,\n    epochs = EPOCHS,\n    validation_data = validation_generator,\n    validation_steps = VALIDATION_STEPS,\n    callbacks = [model_save, early_stop, reduce_lr]\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"SAVE THE MODEL"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('./EffNetB0_512_8.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# PREDICTION\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv(os.path.join(WORK_DIR, \"sample_submission.csv\"))\nsubmission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = []\n\nfor image_id in submission.image_id:\n    image = Image.open(os.path.join(WORK_DIR,  \"test_images\", image_id))\n    image = image.resize((TARGET_SIZE, TARGET_SIZE))\n    image = np.expand_dims(image, axis = 0)\n    preds.append(np.argmax(model.predict(image)))\n\nsubmission['label'] = preds\nsubmission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If you like the notebook give me a upvote "},{"metadata":{},"cell_type":"markdown","source":"![](https://designshop-6aa0.kxcdn.com/photos/have-a-happy-day-greeting-card-balloon-quote-postcard-2411_21.jpg)"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}