{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Comparing peformance of TF pretrained model\n\nIn this notebook, I am going to train a sample of provided data on every pretrained model provided by tensorflow. following models will be compared\n* DenseNet169\n* InceptionV3\n* MobileNetV2\n* NASNetLarge\n* ResNet101\n* VGG19\n* Xception\n* EfficientNetB4\n\nThis notebook generate a image of plots of loss and accuracy for every model you can download that from output tab\n\nThis is not a programming tutorial notebook. Main foucs is on comparing different architectures"},{"metadata":{},"cell_type":"markdown","source":"Let's set our directories here"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"image_directory = \"/kaggle/input/cassava-leaf-disease-classification/train_images\"\ntrain_csv_dir = \"/kaggle/input/cassava-leaf-disease-classification/train.csv\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Following cell loads the train.csv"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\n\ntrain_csv = pd.read_csv(train_csv_dir,dtype=str)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. A useful function which splits data into train, test ensuring each set get equal not of examples for a class. In short it splits data eqaually.\n2. Secondly, it take a sample from whole data. where parameter samples refer to no of total examples to consider for each class which then later get split into train and test"},{"metadata":{"trusted":true},"cell_type":"code","source":"def balanced_train_test_split(df, label_col, samples, split=0.25):\n    dfs_train = []\n    dfs_test = []\n\n    no_of_classes = len(set(df[label_col].tolist()))\n    for class_id in range(0, no_of_classes):\n        class_df = df[(df[label_col]==str(class_id))].head(n=samples)\n        class_df_train = class_df.sample(frac=1-split)\n        class_df_test = class_df.drop(class_df_train.index)\n        dfs_train.append(class_df_train)\n        dfs_test.append(class_df_test)\n    \n    \n    dfs_train = pd.concat(dfs_train).sample(frac=1)\n    dfs_test = pd.concat(dfs_test).sample(frac=1)\n    \n    return dfs_train, dfs_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* to save time I will load only 500 examples of each class and use them to train all the networks"},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test = balanced_train_test_split(train_csv, \"label\", samples = 500, split=0.2)\ntrain_examples = train.count()[0]\ntest_examples = test.count()[0]\n\nprint(\"Total training examples: \", train_examples)\nprint(\"Total testing examples: \", test_examples)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Following cell makes generator to load images in batches. I am using batch of 16 for each  model and target image size will be 256x256"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimage_size=(256,256)\nimage_shape=(256,256,3)\nbatch_size=16\n\nkwargs = {\n    \"directory\":image_directory, \"x_col\":'image_id', \"y_col\":'label',\n    \"target_size\":image_size, \"color_mode\":'rgb', \"classes\":None,\n    \"class_mode\":'categorical', \"batch_size\":batch_size, \"shuffle\":True, \n}\n\ngenerator = ImageDataGenerator()\n\ntrain_generator = generator.flow_from_dataframe(train, **kwargs)\ntest_generator = generator.flow_from_dataframe(test, **kwargs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Following cell define setting to use for all the models and a function to attach final dense layers to make predictions. I will train each model for 30 epochs with learning rate of 0.001"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers import Dropout,Flatten,Dense,BatchNormalization,Activation\nimport tensorflow as tf\n\nmodelsettings = {\n    \"include_top\":False, \"weights\":'imagenet', \"input_shape\":image_shape\n}\n\noptimize_adam =  tf.keras.optimizers.Adam(learning_rate=0.001)\nloss_func = \"categorical_crossentropy\"\nacc_mat = \"categorical_accuracy\"\n\nfit_settings={\n    \"x\":train_generator, \"steps_per_epoch\":train_examples//batch_size,\n    \"validation_data\":test_generator, \"validation_steps\":test_examples//batch_size, \n    \"epochs\":20, \"verbose\":1,\"shuffle\":True\n}\n\ndef create_model(model):\n    model = tf.keras.Sequential([\n            model,\n            Flatten(),\n            Dense(256),\n            BatchNormalization(),\n            Activation(\"relu\"),\n            Dropout(0.5),\n            Dense(32),\n            BatchNormalization(),\n            Activation(\"relu\"),\n            Dense(5, activation=\"softmax\"),\n        ])\n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create first model - DenseNet169\nin the next cell densenet will be trained for 20 epochs as per settings above"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications import DenseNet169\n\nDenseNet = create_model(DenseNet169(**modelsettings))\n\nDenseNet.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DenseNet.compile(optimizer=optimize_adam,loss=loss_func,metrics=[acc_mat])\ndensenet_history = DenseNet.fit(**fit_settings)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create second model - InceptionV3\nin the next cell inception will be trained for 20 epochs as per settings above"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications import InceptionV3\n\nInception = create_model(InceptionV3(**modelsettings))\n\nInception.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Inception.compile(optimizer=optimize_adam,loss=loss_func,metrics=[acc_mat])\ninception_history = Inception.fit(**fit_settings)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create third model - MobileNetV2\nin the next cell mobilenet will be trained for 20 epochs as per settings above"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications import MobileNetV2\n\nmobilenet = create_model(MobileNetV2(**modelsettings))\n\nmobilenet.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mobilenet.compile(optimizer=optimize_adam,loss=loss_func,metrics=[acc_mat])\nmobilenet_history = mobilenet.fit(**fit_settings)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create fourth model - NASNetMobile\nin the next cell nasnet will be trained for 20 epochs as per settings above"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications import NASNetMobile\n\nnasnet = create_model(NASNetMobile(input_shape=(256,256,3), include_top=False, weights=None))\n\nnasnet.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nasnet.compile(optimizer=optimize_adam,loss=loss_func,metrics=[acc_mat])\nnasnet_history = nasnet.fit(**fit_settings)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create Fifth model - ResNet101V2\nin the next cell resnet will be trained for 20 epochs as per settings above"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications import ResNet101V2\n\nresnet = create_model(ResNet101V2(**modelsettings))\n\nresnet.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resnet.compile(optimizer=optimize_adam,loss=loss_func,metrics=[acc_mat])\nresnet_history = resnet.fit(**fit_settings)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create sixth model - VGG19\nin the next cell vgg will be trained for 20 epochs as per settings above"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications import VGG19\n\nvgg = create_model(VGG19(**modelsettings))\n\nvgg.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vgg.compile(optimizer=optimize_adam,loss=loss_func,metrics=[acc_mat])\nvgg_history = vgg.fit(**fit_settings)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create seventh model - xception\nin the next cell xception will be trained for 20 epochs as per settings above"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications import Xception\n\nxception = create_model(Xception(**modelsettings))\n\nxception.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xception.compile(optimizer=optimize_adam,loss=loss_func,metrics=[acc_mat])\nxception_history = xception.fit(**fit_settings)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create eighth model - EfficientNet\nin the next cell efficientnet will be trained for 20 epochs as per settings above"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications import EfficientNetB4\n\nEfficientNet = create_model(EfficientNetB4(**modelsettings))\n\nEfficientNet.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EfficientNet.compile(optimizer=optimize_adam,loss=loss_func,metrics=[acc_mat])\nefficientnet_history = EfficientNet.fit(**fit_settings)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Plot the results "},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef plot_loss(ax, history,title):\n    ax.plot(history.history[\"loss\"], label = \"loss\")\n    ax.plot(history.history[\"val_loss\"], label=\"val_loss\")\n    ax.set(xlabel=\"epochs\", ylabel=\"loss\")\n    ax.set_title(title)\n    ax.legend()\n    \ndef plot_metrics(ax, history,title, metrics):\n    ax.plot(history.history[metrics], label=metrics)\n    ax.plot(history.history[\"val_\"+metrics], label=\"val_\"+metrics)\n    ax.set(xlabel=\"epochs\", ylabel=title)\n    ax.set_title(title)\n    ax.legend()\n    \n    \nfig, axes = plt.subplots(8, 2, figsize=(18,40))\nplt.subplots_adjust(hspace=0.5)\n\n# model 1 - DenseNet169\nplot_loss(axes[0,0], densenet_history, \"DenseNet169 loss\")\nplot_metrics(axes[0,1], densenet_history, \"DenseNet169 accuracy\", \"categorical_accuracy\")\n\n# model 2 - inceptionv3\nplot_loss(axes[1,0], inception_history, \"InceptionV3 loss\")\nplot_metrics(axes[1,1], inception_history, \"InceptionV3 accuracy\", \"categorical_accuracy\")\n\n# model 3 - mobilenet\nplot_loss(axes[2,0], mobilenet_history, \"MobileNetV2 loss\")\nplot_metrics(axes[2,1], mobilenet_history, \"MobileNetV2 accuracy\", \"categorical_accuracy\")\n\n# model 4 - NASnetlarge\nplot_loss(axes[3,0], nasnet_history, \"NASNetLarge loss\")\nplot_metrics(axes[3,1], nasnet_history, \"NASNetLarge accuracy\", \"categorical_accuracy\")\n\n# model 5 - ResNet101\nplot_loss(axes[4,0], resnet_history, \"ResNet101V2 loss\")\nplot_metrics(axes[4,1], resnet_history, \"ResNet101V2 accuracy\", \"categorical_accuracy\")\n\n# model 6 - VGG19\nplot_loss(axes[5,0], vgg_history, \"VGG19 loss\")\nplot_metrics(axes[5,1], vgg_history, \"VGG19 accuracy\", \"categorical_accuracy\")\n\n# model 7 - Xception\nplot_loss(axes[6,0], xception_history, \"Xception loss\")\nplot_metrics(axes[6,1], xception_history, \"Xception accuracy\", \"categorical_accuracy\")\n\n# model 8 - EfficientNet\nplot_loss(axes[7,0], efficientnet_history, \"EfficientNetB4 loss\")\nplot_metrics(axes[7,1], efficientnet_history, \"EfficientNetB4 accuracy\", \"categorical_accuracy\")\n\nfig.savefig(\"Comparingmodels.png\", dpi=300)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}