{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom collections import OrderedDict\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! pip install ../input/timm-package/timm-0.1.26-py3-none-any.whl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom tqdm import tqdm\nimport torch\nimport numpy as np\nfrom sklearn.model_selection import GroupKFold, StratifiedKFold\nimport os\nimport pandas as pd\nfrom torch.utils.data import Dataset, DataLoader\nimport cv2\nfrom torch import nn\nimport random\nimport timm\nfrom sklearn.metrics import roc_auc_score, log_loss\n\nfrom albumentations import (\n    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout,\n    ShiftScaleRotate, CenterCrop, Resize\n)\n\nfrom albumentations.pytorch import ToTensorV2\n\nfrom albumentations import (\n    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout,\n    ShiftScaleRotate, CenterCrop, Resize\n)\n\nfrom albumentations.pytorch import ToTensorV2\n\n\ndef get_train_transforms():\n    return Compose([\n        RandomResizedCrop(CFG['img_size'], CFG['img_size']),\n        Transpose(p=0.5),\n        HorizontalFlip(p=0.5),\n        VerticalFlip(p=0.5),\n        ShiftScaleRotate(p=0.5),\n        HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n        RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n        CoarseDropout(p=0.5),\n        Cutout(p=0.5),\n        ToTensorV2(p=1.0),\n    ], p=1.)\n\ntrain = pd.read_csv('../input/cassava-leaf-disease-classification/train.csv')\n\ndef get_valid_transforms():\n    return Compose([\n        CenterCrop(CFG['img_size'], CFG['img_size'], p=1.),\n        Resize(CFG['img_size'], CFG['img_size']),\n        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n        ToTensorV2(p=1.0),\n    ], p=1.)\n\ndef rand_bbox(size, lam):\n    W = size[0]\n    H = size[1]\n    cut_rat = np.sqrt(1. - lam)\n    cut_w = np.int(W * cut_rat)\n    cut_h = np.int(H * cut_rat)\n\n    # uniform\n    cx = np.random.randint(W)\n    cy = np.random.randint(H)\n\n    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n    bby1 = np.clip(cy - cut_h // 2, 0, H)\n    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n    bby2 = np.clip(cy + cut_h // 2, 0, H)\n    return bbx1, bby1, bbx2, bby2\n\ndef get_inference_transforms():\n    return Compose([\n        RandomResizedCrop(CFG['img_size'], CFG['img_size']),\n        Transpose(p=0.5),\n        HorizontalFlip(p=0.5),\n        VerticalFlip(p=0.5),\n        HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n        RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n        ToTensorV2(p=1.0),\n    ], p=1.)\n\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nCFG = {\n    'fold_num': 5,\n    'seed': 719,\n    'model_arch': 'tf_efficientnet_b4_ns',\n    'img_size': 512,\n    'epochs': 10,\n    'train_bs': 32,\n    'valid_bs': 32,\n    'lr': 1e-4,\n    'num_workers': 4,\n    'accum_iter': 1, # suppoprt to do batch accumulation for backprop with effectively larger batch size\n    'verbose_step': 1,\n    'device': 'cuda:0',\n    'tta': 3,\n    'used_epochs': [25,26,27,28,29],\n    'weights': [1,1,1,1]\n}\n\n\nclass CassavaNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        # backbone = timm.create_model(TIMM_MODEL, pretrained=True)\n        # print(backbone) tf_efficientnet_b4_ns\n        #backbone = EfficientNet.from_pretrained('efficientnet-b4')\n        backbone = timm.create_model('tf_efficientnet_b4_ns', pretrained=False)\n        #n_features = backbone._fc.in_features\n        n_features = backbone.classifier.in_features\n        self.backbone = nn.Sequential(*backbone.children())[:-3]\n        # print(self.backbone)\n        self.classifier = nn.Linear(n_features, 5)\n        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n\n    def forward_features(self, x):\n        x = self.backbone(x)\n        return x\n\n    def forward(self, x):\n        feats = self.forward_features(x)\n        x = self.pool(feats).view(x.size(0), -1)\n        x = self.classifier(x)\n        return x, feats\n\nclass CassavaDataset(Dataset):\n    def __init__(self, df, data_root,\n                 transforms=None,\n                 output_label=True,\n                 one_hot_label=False,\n                 do_fmix=False,\n                 fmix_params={\n                     'alpha': 1.,\n                     'decay_power': 3.,\n                     'shape': (CFG['img_size'], CFG['img_size']),\n                     'max_soft': True,\n                     'reformulate': False\n                 },\n                 do_cutmix=False,\n                 cutmix_params={\n                     'alpha': 1,\n                 }\n                 ):\n\n        super().__init__()\n        self.df = df.reset_index(drop=True).copy()\n        self.transforms = transforms\n        self.data_root = data_root\n        self.do_fmix = do_fmix\n        self.fmix_params = fmix_params\n        self.do_cutmix = do_cutmix\n        self.cutmix_params = cutmix_params\n\n        self.output_label = output_label\n        self.one_hot_label = one_hot_label\n\n        if output_label == True:\n            self.labels = self.df['label'].values\n            # print(self.labels)\n\n            if one_hot_label is True:\n                self.labels = np.eye(self.df['label'].max() + 1)[self.labels]\n                # print(self.labels)\n\n    def __len__(self):\n        return self.df.shape[0]\n\n    def __getitem__(self, index: int):\n\n        # get labels\n        if self.output_label:\n            target = self.labels[index]\n\n        img = get_img(\"{}/{}\".format(self.data_root, self.df.loc[index]['image_id']))\n\n        if self.transforms:\n            img = self.transforms(image=img)['image']\n\n        if self.do_fmix and np.random.uniform(0., 1., size=1)[0] > 0.5:\n            with torch.no_grad():\n                # lam, mask = sample_mask(**self.fmix_params)\n\n                lam = np.clip(np.random.beta(self.fmix_params['alpha'], self.fmix_params['alpha']), 0.6, 0.7)\n\n                # Make mask, get mean / std\n                mask = make_low_freq_image(self.fmix_params['decay_power'], self.fmix_params['shape'])\n                mask = binarise_mask(mask, lam, self.fmix_params['shape'], self.fmix_params['max_soft'])\n\n                fmix_ix = np.random.choice(self.df.index, size=1)[0]\n                fmix_img = get_img(\"{}/{}\".format(self.data_root, self.df.iloc[fmix_ix]['image_id']))\n\n                if self.transforms:\n                    fmix_img = self.transforms(image=fmix_img)['image']\n\n                mask_torch = torch.from_numpy(mask)\n\n                # mix image\n                img = mask_torch * img + (1. - mask_torch) * fmix_img\n\n                # print(mask.shape)\n\n                # assert self.output_label==True and self.one_hot_label==True\n\n                # mix target\n                rate = mask.sum() / CFG['img_size'] / CFG['img_size']\n                target = rate * target + (1. - rate) * self.labels[fmix_ix]\n                # print(target, mask, img)\n                # assert False\n\n        if self.do_cutmix and np.random.uniform(0., 1., size=1)[0] > 0.5:\n            # print(img.sum(), img.shape)\n            with torch.no_grad():\n                cmix_ix = np.random.choice(self.df.index, size=1)[0]\n                cmix_img = get_img(\"{}/{}\".format(self.data_root, self.df.iloc[cmix_ix]['image_id']))\n                if self.transforms:\n                    cmix_img = self.transforms(image=cmix_img)['image']\n\n                lam = np.clip(np.random.beta(self.cutmix_params['alpha'], self.cutmix_params['alpha']), 0.3, 0.4)\n                bbx1, bby1, bbx2, bby2 = rand_bbox((CFG['img_size'], CFG['img_size']), lam)\n\n                img[:, bbx1:bbx2, bby1:bby2] = cmix_img[:, bbx1:bbx2, bby1:bby2]\n\n                rate = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (CFG['img_size'] * CFG['img_size']))\n                target = rate * target + (1. - rate) * self.labels[cmix_ix]\n\n            # print('-', img.sum())\n            # print(target)\n            # assert False\n\n        # do label smoothing\n        # print(type(img), type(target))\n        if self.output_label == True:\n            return img, target\n        else:\n            return img\n\ndef inference_one_epoch(model, data_loader, device):\n    model.eval()\n\n    image_preds_all = []\n\n    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n    for step, (imgs) in pbar:\n        imgs = imgs.to(device).float()\n\n        image_preds= model(imgs)  # output = model(input)\n        image_preds_all += [torch.softmax(image_preds, 1).detach().cpu().numpy()]\n\n    image_preds_all = np.concatenate(image_preds_all, axis=0)\n    return image_preds_all\n\ndef get_img(path):\n    im_bgr = cv2.imread(path)\n    im_rgb = im_bgr[:, :, ::-1]\n    # print(im_rgb)\n    return im_rgb\n\nclass CassvaImgClassifier(nn.Module):\n    def __init__(self, model_arch, n_class, pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(model_arch, pretrained=pretrained)\n        n_features = self.model.classifier.in_features\n        self.model.classifier = nn.Linear(n_features, n_class)\n        '''\n        self.model.classifier = nn.Sequential(\n            nn.Dropout(0.3),\n            #nn.Linear(n_features, hidden_size,bias=True), nn.ELU(),\n            nn.Linear(n_features, n_class, bias=True)\n        )\n        '''\n\n    def forward(self, x):\n        x = self.model(x)\n        return x\n\nif __name__ == '__main__':\n    # for training only, need nightly build pytorch\n\n    seed_everything(CFG['seed'])\n\n    folds = StratifiedKFold(n_splits=CFG['fold_num']).split(np.arange(train.shape[0]), train.label.values)\n\n    for fold, (trn_idx, val_idx) in enumerate(folds):\n        # we'll train fold 0 first\n        if fold > 0:\n            break\n\n        print('Inference fold {} started'.format(fold))\n\n        valid_ = train.loc[val_idx, :].reset_index(drop=True)\n        valid_ds = CassavaDataset(valid_, '../input/cassava-leaf-disease-classification/train_images/',\n                                  transforms=get_inference_transforms(), output_label=False)\n\n        test = pd.DataFrame()\n        test['image_id'] = list(os.listdir('../input/cassava-leaf-disease-classification/test_images/'))\n        test_ds = CassavaDataset(test, '../input/cassava-leaf-disease-classification/test_images/',\n                                 transforms=get_inference_transforms(), output_label=False)\n\n#         val_loader = torch.utils.data.DataLoader(\n#             valid_ds,\n#             batch_size=CFG['valid_bs'],\n#             num_workers=CFG['num_workers'],\n#             shuffle=False,\n#             pin_memory=False,\n#         )\n\n        tst_loader = torch.utils.data.DataLoader(\n            test_ds,\n            batch_size=CFG['valid_bs'],\n            num_workers=CFG['num_workers'],\n            shuffle=False,\n            pin_memory=False,\n        )\n\n        device = torch.device(CFG['device'])\n        model = CassvaImgClassifier(CFG['model_arch'], train.label.nunique()).to(device)\n        #model = CassavaNet().to(device) \n#         val_preds = []\n        tst_preds = []\n\n        # for epoch in range(CFG['epochs']-3):\n        #for i, epoch in enumerate(CFG['used_epochs']):\n        for i in [1]:#range(5):\n            # model.load_state_dict(torch.load(\n            #     '../input/pytorch-efficientnet-baseline-train-amp-aug/{}_fold_{}_{}'.format(CFG['model_arch'], fold,\n            #                                                                                 epoch)))\n            #model.load_state_dict(torch.load('../input/models-2-3/tf_efficientnet_b4_ns_fold_4_9.pth',map_location={'cuda:1':'cuda:0'}))\n            for epoch in [1,2,3,4,5,6,7,8,9]:#CFG['used_epochs']:\n                ckpt=torch.load('../input/model-comined/tf_efficientnet_b4_ns_fold_{}_{}.pth'.format(i,epoch),map_location={'cuda:1':'cuda:0'})\n                #ckpt_model_dict = remove_prefix(ckpt, 'me.')\n                ckpt_model_dict = OrderedDict([(k[7:],v) if 'module.' in k else (k,v) for k, v in ckpt.items()])\n                model.load_state_dict(ckpt_model_dict)\n\n\n                with torch.no_grad():\n#                     for _ in range(CFG['tta']):\n#                         val_preds += [inference_one_epoch(model, val_loader,device)]\n                        \n                     tst_preds += [inference_one_epoch(model, tst_loader,device)]\n#         val_preds = np.mean(val_preds, axis=0)\n        tst_preds = np.mean(tst_preds, axis=0)\n\n#         print('fold {} validation loss = {:.5f}'.format(fold, log_loss(valid_.label.values, val_preds)))\n#         print('fold {} validation accuracy = {:.5f}'.format(fold, (\n#                     valid_.label.values == np.argmax(val_preds, axis=1)).mean()))\n\n        del model\n        torch.cuda.empty_cache()\n        test['label'] = np.argmax(tst_preds, axis=1)\n        test.head()\n        test.to_csv('submission.csv', index=False)\n        print(test)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}