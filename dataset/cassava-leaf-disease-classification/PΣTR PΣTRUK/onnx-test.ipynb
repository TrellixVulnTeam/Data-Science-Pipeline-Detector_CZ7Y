{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install efficientnet_pytorch\n!pip install onnx_tf\n!pip install onnxruntime\n!pip install onnx_tf\n\nimport cv2\nimport torch\nfrom torch import nn\nimport efficientnet_pytorch\nfrom matplotlib import pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-01T11:27:29.184712Z","iopub.execute_input":"2022-02-01T11:27:29.185178Z","iopub.status.idle":"2022-02-01T11:28:00.491022Z","shell.execute_reply.started":"2022-02-01T11:27:29.1851Z","shell.execute_reply":"2022-02-01T11:28:00.48983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path_to_model = '../input/eff-net/efficientnet.torch'\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2022-02-01T11:28:00.492572Z","iopub.execute_input":"2022-02-01T11:28:00.493019Z","iopub.status.idle":"2022-02-01T11:28:00.502416Z","shell.execute_reply.started":"2022-02-01T11:28:00.492971Z","shell.execute_reply":"2022-02-01T11:28:00.501439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = efficientnet_pytorch.EfficientNet.from_pretrained(\"efficientnet-b0\")\nmodel._fc = nn.Linear(in_features=1280, out_features=5, bias=True)\nmodel.to(device)\nmodel.load_state_dict(\n            torch.load(path_to_model, map_location=device)[\"model_state_dict\"]\n)\nmodel.eval();","metadata":{"execution":{"iopub.status.busy":"2022-02-01T11:28:00.504153Z","iopub.execute_input":"2022-02-01T11:28:00.504491Z","iopub.status.idle":"2022-02-01T11:28:00.73002Z","shell.execute_reply.started":"2022-02-01T11:28:00.504447Z","shell.execute_reply":"2022-02-01T11:28:00.729248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from albumentations import Normalize, Compose, Resize\nfrom albumentations.pytorch import ToTensorV2\n\nIMAGE_SIZE = (256, 256)\n\ntransforms_valid = Compose(\n    [\n        Resize(*IMAGE_SIZE),\n        Normalize(\n            mean=[0.485, 0.456, 0.406],\n            std=[0.229, 0.224, 0.225],\n        ),\n        ToTensorV2(),\n    ],\n    p=1,\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T11:28:00.732153Z","iopub.execute_input":"2022-02-01T11:28:00.732704Z","iopub.status.idle":"2022-02-01T11:28:01.625409Z","shell.execute_reply.started":"2022-02-01T11:28:00.732654Z","shell.execute_reply":"2022-02-01T11:28:01.624755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(img, model, device, transform):\n    img = transform(image=img)[\"image\"]\n    img = torch.unsqueeze(img, 0)\n    x_test = img.to(device)\n\n    with torch.no_grad():\n        _, pred = model(x_test).max(1)\n    predict = pred.tolist()\n    return predict[0]","metadata":{"execution":{"iopub.status.busy":"2022-02-01T11:28:01.626618Z","iopub.execute_input":"2022-02-01T11:28:01.627426Z","iopub.status.idle":"2022-02-01T11:28:01.633227Z","shell.execute_reply.started":"2022-02-01T11:28:01.627387Z","shell.execute_reply":"2022-02-01T11:28:01.632642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = cv2.imread('../input/cassava-leaf-disease-classification/train_images/100533489.jpg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\nplt.imshow(image);\nplt.title(predict(image, model, device, transforms_valid));","metadata":{"execution":{"iopub.status.busy":"2022-02-01T11:28:01.634193Z","iopub.execute_input":"2022-02-01T11:28:01.634787Z","iopub.status.idle":"2022-02-01T11:28:02.066079Z","shell.execute_reply.started":"2022-02-01T11:28:01.634751Z","shell.execute_reply":"2022-02-01T11:28:02.064895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = transforms_valid(image=image)[\"image\"]\nimg = torch.unsqueeze(img, 0)\ndummy_input = img\nmodel(dummy_input).max(1)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T11:28:02.067304Z","iopub.execute_input":"2022-02-01T11:28:02.067656Z","iopub.status.idle":"2022-02-01T11:28:02.172327Z","shell.execute_reply.started":"2022-02-01T11:28:02.06759Z","shell.execute_reply":"2022-02-01T11:28:02.171612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.set_swish(memory_efficient=False) # https://github.com/lukemelas/EfficientNet-PyTorch/issues/91","metadata":{"execution":{"iopub.status.busy":"2022-02-01T11:28:02.174029Z","iopub.execute_input":"2022-02-01T11:28:02.174634Z","iopub.status.idle":"2022-02-01T11:28:02.180647Z","shell.execute_reply.started":"2022-02-01T11:28:02.174587Z","shell.execute_reply":"2022-02-01T11:28:02.179745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Export Model","metadata":{}},{"cell_type":"code","source":"path_to_save_model = './EffNet.onnx'\n\ntorch.onnx.export(model,         # model being run \n     dummy_input.to(device),     # model input (or a tuple for multiple inputs) \n     path_to_save_model,         # where to save the model  \n     export_params = True,       # store the trained parameter weights inside the model file \n     do_constant_folding = True, # whether to execute constant folding for optimization\n     input_names = ['input'],    # the model's input names\n     output_names = ['output'])  # the model's output names\n\nprint('Model has been converted to ONNX')","metadata":{"execution":{"iopub.status.busy":"2022-02-01T11:28:02.182234Z","iopub.execute_input":"2022-02-01T11:28:02.182484Z","iopub.status.idle":"2022-02-01T11:28:06.264269Z","shell.execute_reply.started":"2022-02-01T11:28:02.182455Z","shell.execute_reply":"2022-02-01T11:28:06.26343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load the model using onnx.load","metadata":{}},{"cell_type":"code","source":"import onnx\n\nonnx_model = onnx.load(path_to_save_model)\nonnx.checker.check_model(onnx_model)","metadata":{"execution":{"iopub.status.busy":"2022-02-01T11:28:06.265905Z","iopub.execute_input":"2022-02-01T11:28:06.266125Z","iopub.status.idle":"2022-02-01T11:28:06.313395Z","shell.execute_reply.started":"2022-02-01T11:28:06.266098Z","shell.execute_reply":"2022-02-01T11:28:06.312585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create inference session with onnxruntime.infernnce","metadata":{}},{"cell_type":"code","source":"import onnxruntime as onnxrt\n\n# Lauch the session\nonnx_session = onnxrt.InferenceSession(path_to_save_model)\n\n# Assigns the input numpy array as input vector for the onnx session\nonnx_inputs = {onnx_session.get_inputs()[0].name: dummy_input.numpy()}\n\n# Inference\nonnx_predictions = onnx_session.run(None, onnx_inputs)\nonnx_predictions[0].argmax(1)[0]","metadata":{"execution":{"iopub.status.busy":"2022-02-01T11:28:06.3148Z","iopub.execute_input":"2022-02-01T11:28:06.315449Z","iopub.status.idle":"2022-02-01T11:28:06.469515Z","shell.execute_reply.started":"2022-02-01T11:28:06.315403Z","shell.execute_reply":"2022-02-01T11:28:06.468614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from onnx_tf.backend import prepare  # The \"prepare\" function is a wrapper for a session in tensorflow\n\n# Load the onnx model with onnx module\nonnx_model = onnx.load(path_to_save_model)\n\n# Inference\ntensorflow_predictions = prepare(onnx_model).run(dummy_input.numpy())[0]; \nprint(tensorflow_predictions.argmax(1)[0])","metadata":{"execution":{"iopub.status.busy":"2022-02-01T11:45:57.713905Z","iopub.execute_input":"2022-02-01T11:45:57.714364Z","iopub.status.idle":"2022-02-01T11:46:03.356592Z","shell.execute_reply.started":"2022-02-01T11:45:57.71431Z","shell.execute_reply":"2022-02-01T11:46:03.355528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# https://www.canva.com/design/DAE2veRgTBE/6ytSoSs5eqTHcb6a8hDEbg/view?utm_content=DAE2veRgTBE&utm_campaign=designshare&utm_medium=link&utm_source=publishsharelink","metadata":{}}]}