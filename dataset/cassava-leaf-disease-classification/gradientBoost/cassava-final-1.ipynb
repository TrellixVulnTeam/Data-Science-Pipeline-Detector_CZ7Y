{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os, sys, cv2\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport numpy as np\nimport os, time, cv2, sys\nfrom PIL import Image\nimport torchvision.transforms as transforms\n\n\nsz=224\nnum_classes=4\nproj_dir = '/kaggle/input/cassava-leaf-disease-classification/'\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def softmax(X, theta=1.0, axis=None):\n    y = np.atleast_2d(X)\n\n    if axis is None:\n        axis = next(j[0] for j in enumerate(y.shape) if j[1] > 1)\n\n    y = y * float(theta)\n    # subtract the max for numerical stability\n    y = y - np.expand_dims(np.max(y, axis=axis), axis)\n    # exponentiate y\n    y = np.exp(y)\n    # take the sum along the specified axis\n    ax_sum = np.expand_dims(np.sum(y, axis=axis), axis)\n    p = y / ax_sum\n    # flatten if X was 1D\n    if len(X.shape) == 1: p = p.flatten()\n    return p","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def light_model(num_classes):\n    squeezenet_custom=torchvision.models.squeezenet1_0(pretrained=False)\n\n    classifier = nn.Sequential(\n        nn.Dropout(0.5),\n        nn.Conv2d(in_channels=512\n                  , out_channels=num_classes\n                  , kernel_size=(1, 1)\n                  , stride=(1, 1)\n                  , padding=(1, 1)),\n        nn.ReLU(inplace=True),\n        nn.AdaptiveAvgPool2d((1, 1))\n    )\n\n    squeezenet_custom.classifier = classifier\n    return squeezenet_custom\n\n\ndef vgg_16(num_classes):\n        model = torchvision.models.vgg16(pretrained=False)\n\n        classifier = nn.Sequential(\n            nn.Dropout(),\n            nn.Linear(512 * 7 * 7, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, num_classes),\n            )\n\n        model.classifier = classifier\n        return model\n\nsqueezenet_custom_4 = light_model(4)\nsqueezenet_custom_2 = light_model(2)\nvgg_custom_2=vgg_16(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data Transforms\n\nleaf_transform=transforms.Compose([\n    transforms.CenterCrop(400)\n    , transforms.Resize(size=(224, 224))\n    \n    , transforms.ToTensor()\n    , transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"minority_idx = {\n    0: 0\n    , 1: 1\n    , 2: 2\n    , 3: 4    \n}\n\nbinary_idx = {\n    0: '0_1_2_4'\n    , 1: 3\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weight_dir='../input/cassava-models-2'\nprint(os.listdir(weight_dir))\nmodel_1_path=os.path.join('../input/cassava-models', 'minority_weights.pth')\nmodel_2_path=os.path.join(weight_dir, 'binary_weights_2.pth')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_1=torch.load(model_1_path, map_location=torch.device('cuda'))\nweights_1 = model_1.state_dict()\nsqueezenet_custom_4.load_state_dict(weights_1)\nsqueezenet_custom_4.eval()\n\nmodel_2=torch.load(model_2_path, map_location=torch.device('cuda'))\nweights_2 = model_2.state_dict()\nvgg_custom_2.load_state_dict(weights_2)\nvgg_custom_2.eval()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prediction_logic(img, squeezenet_custom_4, squeezenet_custom_2, thresh_3=0.50):\n    \n    preds_minority = softmax(squeezenet_custom_4(img).cpu().detach().numpy())\n    preds_binary = softmax(squeezenet_custom_2(img).cpu().detach().numpy())\n    binary_cls=np.argmax(preds_binary)\n    minority_cls=np.argmax(preds_minority)\n    \n    cls_3 = preds_binary[0][1]\n    print(preds_minority, preds_binary)\n    if cls_3 <= thresh_3:\n        return minority_idx[minority_cls]\n    else: \n        return binary_idx[binary_cls]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def img_transform(img_path):\n    img = Image.open(img_path).convert('RGB')\n    r,g,b = img.split()\n    img = Image.merge(\"RGB\", (b,g,r))\n\n    img = leaf_transform(img).float()\n    img = img.unsqueeze(0)\n    return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dir=(os.path.join(proj_dir, 'train_images'))\ntest_dir=(os.path.join(proj_dir, 'test_images'))\n\ndf = pd.read_csv(os.path.join(proj_dir, 'train.csv'))\nsample_df = pd.read_csv(os.path.join(proj_dir, 'sample_submission.csv'))\nsample_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntest_preds=[]\nfor i, j in enumerate(os.listdir(test_dir)):\n    print(i, j)\n    img_path=os.path.join(test_dir, j)\n    img=img_transform(img_path)\n    final_pred=prediction_logic(img, squeezenet_custom_4, squeezenet_custom_2)\n    test_preds.append([j,final_pred])\nprint(test_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.DataFrame.from_records(test_preds, columns=['image_id', 'label'])\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.chdir('/kaggle/working/')\nsub.to_csv(\"/kaggle/working/submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}