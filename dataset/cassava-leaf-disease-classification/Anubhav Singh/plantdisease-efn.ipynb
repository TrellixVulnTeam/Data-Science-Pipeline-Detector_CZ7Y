{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install -U efficientnet","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nimport json\nfrom tensorflow.keras.utils import Sequence,to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.applications import *\nimport efficientnet.keras as efn \nfrom tensorflow.keras.models import Model,load_model\nfrom tensorflow.keras.callbacks import *\nfrom tensorflow.keras.layers import *\nimport tensorflow.compat.v1 as tc\nimport tensorflow as tf\nimport albumentations as A\nfrom tqdm import tqdm\nfrom sklearn.utils import shuffle\nfrom tensorflow.keras.optimizers import *","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df=pd.read_csv('/kaggle/input/cassava-leaf-disease-classification/train.csv')\nsample_sub=pd.read_csv('/kaggle/input/cassava-leaf-disease-classification/sample_submission.csv')\ntrain_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('/kaggle/input/cassava-leaf-disease-classification/label_num_to_disease_map.json') as f:\n    label_dic=json.load(f)\nprint(label_dic)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_img_path='/kaggle/input/cassava-leaf-disease-classification/train_images/'\ntest_img_path='/kaggle/input/cassava-leaf-disease-classification/test_images/'\nweight_path='/kaggle/input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig=plt.figure(figsize=(15,15))\nr,c=3,3\nfor i in range(1,r*c+1):\n    img=cv2.imread(os.path.join(train_img_path,train_df.loc[i,'image_id']))\n    img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n    t=train_df.loc[i,'label']\n    fig.add_subplot(r,c,i)\n    plt.imshow(img)\n    plt.title(label_dic[str(t)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE=15\nDIMS=(224,224,3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df_,val_df=train_test_split(train_df,test_size=0.2)\ntrain_ids,train_lbls=train_df_['image_id'].values,train_df_['label'].values\nval_ids,val_lbls=val_df['image_id'].values,val_df['label'].values\nprint('Number of samples in train and val: {},{} '.format(len(train_ids),len(val_ids)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n#Augmentation\ntransform = A.Compose([\n            A.HorizontalFlip(),\n            A.VerticalFlip(),\n            A.CenterCrop(224,224),\n            A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.50, rotate_limit=45, p=.75),\n            A.GridDistortion(),])\n\n#augmented_image = transform(image=image)['image']\n\nfig=plt.figure(figsize=(15,15))\nr,c=4,2\nfor i in range(1,r*c+1):\n    img=cv2.imread(os.path.join(train_img_path,train_df.loc[i,'image_id']))\n    img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n    if i%2==0:\n        img = transform(image=img)['image']\n    fig.add_subplot(r,c,i)\n    plt.imshow(img)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class customGen(Sequence):\n    def __init__(self,data,path,batch_size=BATCH_SIZE,dims=DIMS,shuffle_=True,is_train=True):\n        self.img_ids=data[0]\n        self.labels=data[1]\n        self.batch_size=batch_size\n        self.dims=DIMS\n        self.is_train=is_train\n        self.on_epoch_end()\n        self.path=path\n        \n    \n    def __len__(self):\n        return int(len(self.img_ids)//self.batch_size)\n    \n    def on_epoch_end(self):\n        self.indexes=np.arange(len(self.img_ids))        \n        if self.is_train:\n                np.random.shuffle(self.indexes)\n            \n    def __getitem__(self,index):\n        indexes=self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        img_ix=[self.img_ids[i] for i in indexes]\n        y=[self.labels[i] for i in indexes]\n        X=self.__data_generation(img_ix)\n        return X,to_categorical(y,num_classes=5)\n    \n    def overlap_image(self,x):\n        sec_img=np.random.choice(self.img_ids)\n        img=cv2.imread(os.path.join(self.path,sec_img))\n        img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n        img=cv2.resize(img,(self.dims[0],self.dims[1]))\n        overlay=cv2.addWeighted(x,0.8,img,0.25,0)\n        return overlay\n        \n    \n    def augment_(self,image):\n        transform = A.Compose([\n            A.HorizontalFlip(),\n            A.VerticalFlip(),\n            A.CenterCrop(224,224),\n            A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.50, rotate_limit=45, p=.75),\n            A.GridDistortion(),])\n        \n        augmented_image = transform(image=image)['image']\n        return augmented_image\n    \n    \n    def __data_generation(self,ix):\n        tmp=np.zeros((self.batch_size,*self.dims))\n        for ix_,img_id in enumerate(ix):\n            img=cv2.imread(os.path.join(self.path,img_id))\n            img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n            img=cv2.resize(img,(self.dims[0],self.dims[1]))            \n            if self.is_train:\n                #Dont always apply augmentation\n                if np.random.randint(2)==1:\n                    img=self.augment_(img)\n                #img=self.overlap_image(img)\n            tmp[ix_]=img.astype('float')/255.\n        return tmp\n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_gen=customGen([train_ids,train_lbls],train_img_path)\nval_gen=customGen([val_ids,val_lbls],train_img_path,is_train=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_=Input(DIMS)\nx0=Conv2D(3,5,strides=1,padding='same')(input_)\nx0=BatchNormalization()(x0)\nx0=Activation('relu')(x0)\nbase_feat0=efn.EfficientNetB0(weights='imagenet',include_top=False)(x0)\nx0=Reshape((base_feat0.shape[1]*base_feat0.shape[2],base_feat0.shape[3]))(base_feat0)\n\nx1=Conv2D(3,8,strides=1,padding='same')(input_)\nx1=BatchNormalization()(x1)\nx1=Activation('relu')(x1)\nbase_feat1=efn.EfficientNetB1(weights='imagenet',include_top=False)(x1)\nx1=Reshape((base_feat1.shape[1]*base_feat1.shape[2],base_feat1.shape[3]))(base_feat1)\n\nx2=Conv2D(3,12,strides=1,padding='same')(input_)\nx2=BatchNormalization()(x2)\nx2=Activation('relu')(x2)\nbase_feat2=efn.EfficientNetB2(weights='imagenet',include_top=False)(x2)\nx2=Reshape((base_feat2.shape[1]*base_feat2.shape[2],base_feat2.shape[3]))(base_feat2)\n\nx=Concatenate()([x0,x1,x2])\nx=Bidirectional(LSTM(1024,return_sequences=True))(x)\nx=Bidirectional(LSTM(512))(x)\nx=Dense(1280,activation='relu')(x)\nout=Dense(5,activation='sigmoid')(x)\nmodel=Model(input_,out)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['acc'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mc=ModelCheckpoint('classifier.h5',mode='min',monitor='val_loss')\nrop=ReduceLROnPlateau(monitor='val_loss',mode='min',min_lr=0.0000001,verbose=1,patience=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history=model.fit(train_gen,steps_per_epoch=train_gen.__len__(),epochs=20,\n                  validation_data=val_gen,validation_steps=val_gen.__len__(),callbacks=[mc])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, acc, 'b',color='red', label='Training acc')\nplt.plot(epochs, val_acc, 'b',color='blue', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'b', color='red', label='Training loss')\nplt.plot(epochs, val_loss, 'b',color='blue', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}