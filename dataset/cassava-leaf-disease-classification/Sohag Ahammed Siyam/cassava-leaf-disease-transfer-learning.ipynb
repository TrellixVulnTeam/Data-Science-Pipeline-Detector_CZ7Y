{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import clear_output\n!pip install keras\n!pip install tensorflow\nclear_output()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nos.listdir('../input/cassava-leaf-disease-classification')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_img_path = '../input/cassava-leaf-disease-classification/train_images'\nimages = os.listdir(train_img_path)\n\nprint(\"Training images:\", len(images))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\nfile = open('../input/cassava-leaf-disease-classification/label_num_to_disease_map.json')\n\nclass_map = json.load(file)\nprint(json.dumps(class_map,indent=1))\nlis = json.dumps(class_map)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\n\ntrain_file = '../input/cassava-leaf-disease-classification/train.csv'\n\ntrain = pd.read_csv(train_file)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nax = plt.figure(figsize=(14,6))\n\nax = sns.countplot(x = 'label',data=train, palette=\"pastel\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Samples of \"0\": \"Cassava Bacterial Blight (CBB)\""},{"metadata":{"trusted":true},"cell_type":"code","source":"samples = train[train['label']==0].sample(3).reset_index() #Reset index isn't necessary\nsamples","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14,6))\n\nfor i, (image_id, label) in enumerate(zip(samples.image_id, samples.label)):\n    plt.subplot(1,3,i+1)\n    path = os.path.join('../input/cassava-leaf-disease-classification/train_images',image_id)\n    img = cv2.imread(path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    plt.imshow(img)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Samples of \"1\": \"Cassava Brown Streak Disease (CBSD)\""},{"metadata":{"trusted":true},"cell_type":"code","source":"samples = train[train['label']==1].sample(3)\n\nplt.figure(figsize=(14,6))\n\nfor i, (image_id, label) in enumerate(zip(samples.image_id, samples.label)):\n    plt.subplot(1,3,i+1)\n    path = os.path.join('../input/cassava-leaf-disease-classification/train_images',image_id)\n    img = cv2.imread(path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    plt.imshow(img)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Samples of \"2\": \"Cassava Green Mottle (CGM)\""},{"metadata":{"trusted":true},"cell_type":"code","source":"samples = train[train['label']==2].sample(3)\n\nplt.figure(figsize=(14,6))\n\nfor i, (image_id, label) in enumerate(zip(samples.image_id, samples.label)):\n    plt.subplot(1,3,i+1)\n    path = os.path.join('../input/cassava-leaf-disease-classification/train_images',image_id)\n    img = cv2.imread(path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    plt.imshow(img)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Samples of \"3\": \"Cassava Mosaic Disease (CMD)\"****"},{"metadata":{"trusted":true},"cell_type":"code","source":"samples = train[train['label']==3].sample(3)\n\nplt.figure(figsize=(14,6))\n\nfor i, (image_id, label) in enumerate(zip(samples.image_id, samples.label)):\n    plt.subplot(1,3,i+1)\n    path = os.path.join('../input/cassava-leaf-disease-classification/train_images',image_id)\n    img = cv2.imread(path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    plt.imshow(img)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Samples of \"4\": \"Healthy\""},{"metadata":{"trusted":true},"cell_type":"code","source":"samples = train[train['label']==4].sample(3)\n\nplt.figure(figsize=(14,6))\n\nfor i, (image_id, label) in enumerate(zip(samples.image_id, samples.label)):\n    plt.subplot(1,3,i+1)\n    path = os.path.join('../input/cassava-leaf-disease-classification/train_images',image_id)\n    img = cv2.imread(path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    plt.imshow(img)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We need to convert labels to string ,label     21397 non-null  int64 \n\ntrain['label'] = train['label'].astype('str')\ntrain.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***Image Data Generator***"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = plt.imread('../input/cassava-leaf-disease-classification/train_images/1000015157.jpg')\nimg.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes = 5\nimg_rows, img_cols = 512, 512\nbatch_size = 32\n\nSTEPS_PER_EPOCH = len(train)*0.7 / batch_size\nVALIDATION_STEPS = len(train)*0.3 / batch_size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nTRAIN_DIR = '../input/cassava-leaf-disease-classification/train_images'\n\ntrain_datagen = ImageDataGenerator(rescale = 1./255,\n                                   rotation_range = 45,\n                                   zoom_range = 0.2,\n                                   width_shift_range = 0.3,\n                                   height_shift_range = 0.3,\n                                   shear_range = 0.2,\n                                   horizontal_flip = True,\n                                   vertical_flip = True,\n                                   fill_mode = 'nearest',\n                                   validation_split = 0.3)\n\ntrain_generator = train_datagen.flow_from_dataframe(train,\n                                                    TRAIN_DIR,\n                                                    subset='training',\n                                                    x_col = 'image_id',\n                                                    y_col = 'label',\n                                                    target_size=(img_rows, img_cols),\n                                                    batch_size=batch_size,\n                                                    class_mode='categorical')\n\nvalidation_datagen = ImageDataGenerator(validation_split = 0.3)\n\nvalidation_generator = validation_datagen.flow_from_dataframe(train,\n                                                    TRAIN_DIR,\n                                                    subset='validation',\n                                                    x_col = 'image_id',\n                                                    y_col = 'label',\n                                                    target_size=(img_rows, img_cols),\n                                                    batch_size=batch_size,\n                                                    class_mode='categorical')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\nfrom keras.layers.normalization import BatchNormalization\nfrom tensorflow.keras.models import Model\n\n\n# Re-loads the MobileNet model without the top or FC layers\nvgg16 = VGG16(weights = 'imagenet',include_top = False,input_shape = (img_rows, img_cols, 3))\n\nfor layer in vgg16.layers:\n    layer.trainable = False\n    \n\ndef addTopModelvgg16(bottom_model, num_classes):\n    \"\"\"creates the top or head of the model that will be \n    placed ontop of the bottom layers\"\"\"\n\n    top_model = bottom_model.output\n    top_model = GlobalAveragePooling2D()(top_model)\n    top_model = Dense(1024,activation='relu')(top_model)\n    top_model = Dense(1024,activation='relu')(top_model)\n    top_model = Dense(512,activation='relu')(top_model)\n    top_model = Dense(num_classes,activation='softmax')(top_model)\n    return top_model\n\n\nnum_classes = classes\n\nFC_Head = addTopModelvgg16(vgg16, num_classes)\n\nmodel = Model(inputs = vgg16.input, outputs = FC_Head)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n                   \ncheckpoint = ModelCheckpoint(\"./vgg19.h5\",\n                             monitor = \"val_loss\",\n                             mode = \"min\",\n                             save_best_only = True,\n                             verbose = 1)\n\nearlystop = EarlyStopping(monitor = 'val_loss', \n                          min_delta = 0.001, \n                          patience = 15,\n                          verbose = 1,\n                          restore_best_weights = True)\n\nreduce_lr = ReduceLROnPlateau(monitor = 'val_loss',\n                              factor = 0.2,\n                              patience = 2,\n                              verbose = 1,\n                              min_delta = 0.0001,\n                              min_lr = 0.00000001)\n\n\ncallbacks = [checkpoint,earlystop,reduce_lr]\n\n\n\nmodel.compile(loss = 'categorical_crossentropy',\n              optimizer = Adam(),\n              metrics = ['accuracy'])\n\n\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch = STEPS_PER_EPOCH,\n    epochs = epochs,\n    validation_data = validation_generator,\n    validation_steps = VALIDATION_STEPS,\n    callbacks = callbacks\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = pd.DataFrame(history.history)\nresult.plot(figsize=(10,8))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample = pd.read_csv('../input/cassava-leaf-disease-classification/sample_submission.csv')\nsample","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image\n\ntest_image = '../input/cassava-leaf-disease-classification/test_images'\npreds = []\n\nfor image_id in sample['image_id']:\n    image = Image.open(os.path.join(test_image, image_id))\n    image = image.resize((img_rows, img_cols))\n    image = np.expand_dims(image, axis = 0)\n    preds.append(np.argmax(model.predict(image)))\n    \nsample['label'] = preds\nsample","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}