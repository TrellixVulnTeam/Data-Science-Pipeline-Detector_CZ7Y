{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install ../input/efficientnet-pytorch-07/efficientnet_pytorch-0.7.0/","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport json\nimport os\nimport cv2\nfrom matplotlib import pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\nimport efficientnet_pytorch\nfrom efficientnet_pytorch import EfficientNet\n\nimport warnings  \nwarnings.filterwarnings('ignore')\n\nfrom distutils.dir_util import copy_tree\n#model = '../input/resnet152/'\nmodel = '../input/efficientnet-pytorch/'\ncheckpoints = '/root/.cache/torch/hub/checkpoints/'\ncopy_tree(model,checkpoints)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"BATCH = 5\nEPOCHS = 1\n\nLR = 0.0001\nIM_SIZE = 512\n\nDEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nTRAIN_DIR = '../input/cassava-leaf-disease-classification/train_images/'\nTEST_DIR = '../input/cassava-leaf-disease-classification/test_images/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = json.load(open(\"../input/cassava-leaf-disease-classification/label_num_to_disease_map.json\"))\nprint(labels)\n\ntrain = pd.read_csv('../input/cassava-leaf-disease-classification/train.csv')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_Train, Y_Train = train['image_id'].values, train['label'].values\nX_Test = [name for name in (os.listdir(TEST_DIR))]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X_Train = X_Train[0:1050]\n#Y_Train = Y_Train[0:1050]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class GetData(Dataset):\n    def __init__(self, Dir, FNames, Labels, Transform):\n        self.dir = Dir\n        self.fnames = FNames\n        self.transform = Transform\n        self.lbs = Labels\n        \n    def __len__(self):\n        return len(self.fnames)\n\n    def __getitem__(self, index):\n        \n        image = cv2.imread(os.path.join(self.dir, self.fnames[index]))\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n        original = image\n        new_color = image\n\n        lower = np.array([60, 60, 120])\n        upper = np.array([250, 120, 215])\n        mask = cv2.inRange(new_color, lower, upper)\n        result4 = cv2.bitwise_and(original,original,mask=mask)\n        result4 = cv2.cvtColor(result4, cv2.COLOR_LAB2RGB)\n        result4[mask==0] = (255,255,255)          \n        \n        lower = np.array([165, 115, 185])\n        upper = np.array([225, 155, 210])\n        mask = cv2.inRange(new_color, lower, upper)\n        result2 = cv2.bitwise_and(original,original,mask=mask)\n        result2 = cv2.cvtColor(result2, cv2.COLOR_LAB2RGB)\n        result2[mask==0] = (255,255,255)\n\n        lower = np.array([195, 105, 125])\n        upper = np.array([255, 125, 145])\n        mask = cv2.inRange(new_color, lower, upper)\n        result3 = cv2.bitwise_and(original,original,mask=mask)\n        result3 = cv2.cvtColor(result3, cv2.COLOR_LAB2RGB)\n        result3[mask==0] = (255,255,255)\n\n        lower = np.array([115, 118, 120])\n        upper = np.array([217, 130, 130])\n        mask = cv2.inRange(new_color, lower, upper)\n        result5 = cv2.bitwise_and(original,original,mask=mask)\n        result5 = cv2.cvtColor(result5, cv2.COLOR_LAB2RGB)\n        result5[mask==0] = (255,255,255)\n\n        result = cv2.bitwise_and(result4,result2)\n        result = cv2.bitwise_and(result,result3)\n        image = cv2.bitwise_and(result,result5)\n\n        if \"train\" in self.dir:\n            image = Transform_train(image=image)['image']\n            return image, self.lbs[index]\n        \n        elif \"test\" in self.dir: \n            image = Transform_test(image=image)['image']\n            return image, self.fnames[index]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from albumentations import (\n    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, CenterCrop,RandomGridShuffle, Resize\n)\nfrom albumentations.pytorch import ToTensorV2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Transform_train = Compose([\n            CenterCrop(IM_SIZE, IM_SIZE),\n            RandomGridShuffle(grid=(2, 2), p=0.5),\n            Transpose(p=0.5),\n            HorizontalFlip(p=0.5),\n            VerticalFlip(p=0.5),\n            ShiftScaleRotate(p=0.5),\n            #HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n            #RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n            #CoarseDropout(p=0.5),\n            #Cutout(p=0.5),\n            ToTensorV2(p=1.0),\n        ], p=1.)\n\nTransform_test = Compose([\n            CenterCrop(IM_SIZE, IM_SIZE),\n            #Resize(IM_SIZE, IM_SIZE),\n            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n            ToTensorV2(p=1.0),\n        ], p=1.)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = EfficientNet.from_pretrained('efficientnet-b7', num_classes=5)\nmodel.load_state_dict(torch.load('../input/my-model2/my_model (2)'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = model.to(DEVICE)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=LR)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.model_selection import train_test_split\n\n# x_train_idx, x_valid_idx, y_train_idx, y_valid_idx = train_test_split(X_Train,Y_Train, test_size=0.1,shuffle =True)\n# print(x_train_idx.shape, y_train_idx.shape)\n# print(x_valid_idx.shape, y_valid_idx.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\n\nn_splits=5\nfold = StratifiedKFold(n_splits=n_splits,shuffle=True)\n\nfor trn_idx, val_idx in fold.split(X_Train,Y_Train):\n\n    x_train_idx = X_Train[trn_idx]\n    y_train_idx = Y_Train[trn_idx]\n    x_valid_idx = X_Train[val_idx]\n    y_valid_idx = Y_Train[val_idx]\n    \n   \n    trainset = GetData(TRAIN_DIR, x_train_idx, y_train_idx, Transform_train)\n    trainloader = DataLoader(trainset, batch_size=BATCH, shuffle=True, num_workers=8)\n\n    validset = GetData(TRAIN_DIR, x_valid_idx, y_valid_idx, Transform_test)\n    validloader = DataLoader(validset, batch_size=BATCH, shuffle=True, num_workers=8)    \n\n    for epoch in range(EPOCHS):\n        tr_loss = 0.0\n        tr_acc = 0.0\n        val_loss = 0.0\n        val_acc = 0.0\n        scheduler.step()\n        model.train()\n        for i, (images, labels) in enumerate(trainloader):\n            images = images.to(DEVICE)\n            labels = labels.to(DEVICE)\n            optimizer.zero_grad()\n            logits = model(images)\n            \n            loss = criterion(logits, labels)\n            preds_class = torch.argmax(logits, 1)\n            \n            loss.backward()\n            optimizer.step()\n\n            tr_loss += loss.detach().item()\n            tr_acc += (preds_class == labels.data).float().mean().data.cpu().numpy()  #считаем accuracy\n            \n        with torch.no_grad():\n            model.eval()\n            for i, (images, labels) in enumerate(validloader):\n                \n                images = images.to(DEVICE)\n                labels = labels.to(DEVICE)\n                optimizer.zero_grad()\n                logits = model(images)\n                \n                loss = criterion(logits, labels)\n                preds_class = torch.argmax(logits, 1)\n                \n                val_loss += loss.detach().item()\n                val_acc += (preds_class == labels.data).float().mean().data.cpu().numpy()  #считаем accuracy\n                \n        print('Epoch: %d | Train_Loss: %.4f | Train_Acc: %.4f | Valid_Loss: %.4f | Valid_Acc: %.4f '%(epoch, tr_loss / len(trainloader), tr_acc / len(trainloader), val_loss / len(validloader), val_acc / len(validloader)))    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(model.state_dict(),'my_model')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testset = GetData(TEST_DIR, X_Test, None, Transform_test)\ntestloader = DataLoader(testset, batch_size=1, shuffle=False, num_workers=8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s_ls = []\n\nwith torch.no_grad():\n    model.eval()\n    for image, fname in testloader: \n        image = image.to(DEVICE)\n        \n        logits = model(image)        \n        ps = torch.exp(logits)        \n        _, top_class = ps.topk(1, dim=1)\n        \n        for pred in top_class:\n            s_ls.append([fname[0], pred.item()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.DataFrame.from_records(s_ls, columns=['image_id', 'label'])\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}