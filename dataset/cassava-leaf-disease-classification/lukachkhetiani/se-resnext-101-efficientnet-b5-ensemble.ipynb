{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"cd ../input/dataclass06/dataclasses-0.6","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install .","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cd ../../../working","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip3 install ../input/torch170/torch-1.7.0-cp37-cp37m-manylinux1_x86_64.whl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir -p /root/.cache/torch/hub/checkpoints","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!cp ../input/pretrained/for_kaggle/*.pt* /root/.cache/torch/hub/checkpoints","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!cp -r ../input/pretrained/for_kaggle/facebookresearch_WSL-Images_master /root/.cache/torch/hub/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!cp -r ../input/pretrained/for_kaggle/intel-isl_MiDaS_master /root/.cache/torch/hub/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cd ../input/pretrained/for_kaggle/EfficientNet-PyTorch-master","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install .","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cd ../../../../working","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!cp -r ../input/image-models/pytorch-image-models-master/* .","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from efficientnet_pytorch import EfficientNet \nfrom torchvision import models\nimport torch \nimport cv2 \nimport glob \nimport torch.nn.functional as F\nimport timm\nimport numpy as np\n\nmidas = torch.hub.load(\"intel-isl/MiDaS\", \"MiDaS\")\nmidas.cuda().eval()\nmidas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\ntransform = midas_transforms.default_transform\n\nefficient = EfficientNet.from_name('efficientnet-b5', num_classes=5)\nefficient.load_state_dict(torch.load('../input/ensemblev5/eff_best.pth'))\nefficient.eval().cuda()\n\nseresnext = timm.create_model('seresnext101_32x4d', num_classes=5)\nseresnext.load_state_dict(torch.load('../input/ensemblev5/seresnext_best.pth'))\nseresnext.eval().cuda()\n\nprint('Models have been loaded...\\n')\n\ndef processor(image):\n    img = cv2.resize(image, (512,512))\n    img = (img - [0.485, 0.456, 0.406]) / [0.229, 0.224, 0.225]\n    image = torch.tensor(img.transpose(2,0,1), dtype=torch.float).unsqueeze(0).cuda()\n    return image\n\ndef get_depth(img):\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    input_batch = transform(img).to(\"cuda\")\n    with torch.no_grad():\n        prediction = midas(input_batch)\n\n        prediction = torch.nn.functional.interpolate(\n            prediction.unsqueeze(1),\n            size=img.shape[:2],\n            mode=\"bicubic\",\n        ).squeeze()\n    output = prediction.cpu().numpy()\n    img_min = np.min(output)\n    img_max = np.max(output)\n    return output > ((img_min+img_max)/3)\n\ndef crop_image(image, depth):\n    depth = depth.astype(int)\n    mask_3d = np.stack((depth,depth,depth),axis=2)\n    masked_arr = np.where(mask_3d==1,img,mask_3d).astype(np.uint8)\n    c = np.where(masked_arr!=[0,0,0])\n    x_max = max(c[1])\n    x_min = min(c[1])\n    y_max = max(c[0])\n    y_min = min(c[0])\n    image = masked_arr[y_min:y_max, x_min:x_max]\n    return image\n\nfiles = glob.glob('../input/cassava-leaf-disease-classification/test_images/*')\nnames, labels = [], []\n\n#images = ['1000015157.jpg','1000201771.jpg','100042118.jpg','1000723321.jpg','1000812911.jpg','1000837476.jpg','1000910826.jpg','1001320321.jpg','1001723730.jpg']\n\n\n\nfor file in files:\n    img = cv2.imread(file)\n    process = img \n    depth = get_depth(process)\n    img = crop_image(img, depth)\n    img = processor(img)\n    \n    se_out = seresnext(img)\n    eff_out = efficient(img)\n    total = (se_out + eff_out)/2\n    names.append(file.split('/')[-1])\n    labels.append(int(torch.argmax(torch.nn.functional.softmax(total)).detach().cpu()))\n    \nimport pandas as pd\n\ndataset = {'image_id': names,\n        'label': labels\n        }\n\ndf = pd.DataFrame(dataset, columns= ['image_id', 'label'])\n\ndf.to_csv ('submission.csv', index = False, header=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}