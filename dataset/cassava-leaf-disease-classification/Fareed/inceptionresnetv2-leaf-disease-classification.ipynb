{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport tensorflow as tf\nimport keras\nimport albumentations as A\nfrom sklearn import model_selection, preprocessing \nimport cv2\nimport tensorflow as tf\nimport numpy as np \nfrom matplotlib import pyplot as plt\nfrom PIL import Image\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading Paths, Directory and Data-Folders "},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"INPUT_PATH = \"../input/cassava-leaf-disease-classification/\"\ntrain_images_path = INPUT_PATH+\"train_images/\"\ntest_images_path = INPUT_PATH+\"test_images/\"\nsample = \"../input/cassava-leaf-disease-classification/sample_submission.csv\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(INPUT_PATH+\"train.csv\")##../input/cassava-leaf-disease-classification/train.csv\"\ndf.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for img in os.listdir(INPUT_PATH+\"train_images/\")[:1]:\n    #print(img)\n    img = Image.open(os.path.join(train_images_path+img))\n    plt.imshow(img)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_df = pd.read_csv(sample)\nsample_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_classes = sorted(df[\"label\"].unique())\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Prepare Dataset For training**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.label = df.label.astype(\"str\")\nbatch_size=16\ninput_size = (299, 299)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data Augmentation**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    validation_split = 0.1,\n    rotation_range=360,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range=0.1,\n    zoom_range=0.1,\n    #channel_shift_range=0.2,\n    horizontal_flip=True,\n    vertical_flip=True,\n    rescale=None,\n    preprocessing_function=None,\n    )\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    dataframe=df,\n    directory=train_images_path,\n    x_col=\"image_id\",\n    y_col=\"label\",\n    batch_size=batch_size,\n    target_size=input_size,\n    class_mode=\"sparse\", \n    subset = \"training\"\n)\nvalid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(validation_split=0.1)\nvalid_generator = train_datagen.flow_from_dataframe(\n    dataframe=df,\n    directory=train_images_path,\n    x_col=\"image_id\",\n    y_col=\"label\",\n    batch_size=batch_size,\n    target_size=input_size ,\n    class_mode=\"sparse\", \n    subset=\"validation\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Let's Have a look of few data** "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,10))\nfor i in range(16):\n    plt.subplot(4,4,i+1)\n    batch = train_generator.next()\n    image = batch[0].astype('uint8')\n    plt.imshow(np.array(image[0,:,:,::-1]))\n    plt.axis(\"off\")\n# show the figure\nplt.show()            \n                        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Define Model, Train and Evaluate"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import Model\nfrom keras import optimizers\nfrom keras.optimizers import Adam\nfrom keras.models import Sequential\nfrom keras.layers import GlobalAveragePooling2D,Dense\n\nmodel_dir = \"../input/inceptionresnetv2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\"\nmodel = Sequential()\nmodel.add( tf.keras.applications.InceptionResNetV2(\n    include_top=False,\n    weights= model_dir, input_shape=(299, 299, 3)))\n\nmodel.add(GlobalAveragePooling2D())\nmodel.add(Dense(len(num_classes), activation=\"softmax\"))\nmodel.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmodel.compile(loss=\"sparse_categorical_crossentropy\",\n              optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n             metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Let's Train**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmodel_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n        filepath='best_inceptionresnetV2.h5',\n        save_weights_only=True,\n        monitor='val_loss',\n        mode='max',\n        save_best_only=True)\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n\nhist  = model.fit_generator(\n    train_generator,\n    validation_data = valid_generator,\n    #\n    steps_per_epoch = len(df)*0.9//batch_size,\n    validation_steps = len(df)*0.1//batch_size, \n    epochs = 10,\n    callbacks = [model_checkpoint ,early_stopping],\n    \n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# accuracy \nplt.plot(hist.history['accuracy'])\nplt.plot(hist.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# loss\nplt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model = model.load_weights(\"./best_inceptionresnetV2.h5\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Predict and make Submission**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\npredictions = []\nfor  image_id in sample_df.image_id:\n    img = Image.open(os.path.join(test_images_path+image_id))\n    img = img.resize((224,224))\n    img = np.expand_dims(img, axis=0)\n    predictions.append(np.argmax(model.predict(img)))\n\nsample_df[\"label\"] = predictions\nsample_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_df.head\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_df.to_csv(\"submission.csv\", index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}