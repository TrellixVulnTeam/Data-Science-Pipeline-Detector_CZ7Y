{"cells":[{"metadata":{},"cell_type":"markdown","source":"\nFor more reference on training notebook, refer to the following link:\n\nhttps://www.kaggle.com/mohitkeshwanii/cassava-ensemble-vgg16-mobilenetv2-densenet169"},{"metadata":{},"cell_type":"markdown","source":"## Import Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nimport os\nimport glob\nimport json\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport cv2\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D,GlobalAveragePooling2D, Flatten, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.optimizers import Adam\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport logging\nlogger = tf.get_logger()\nlogger.setLevel(logging.ERROR)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_files(base_dir, target_dir):\n    count = 0\n    path = get_path(base_dir, target_dir)\n    for dirname, _, filenames in os.walk(path):\n        for filename in filenames:\n            count+=len(glob.glob(os.path.join(dirname, filename)))\n        return path, count\n    \ndef get_path(base_dir, target_dir):\n    path = os.path.join(base_dir,target_dir)\n    return path","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Directory Setup"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"base_dir = '/kaggle/input/cassava-leaf-disease-classification'\ntrain_dir = 'train_images'\nlabels_file = 'train.csv'\ntest_dir = 'test_images'\njson_file = 'label_num_to_disease_map.json'\n\ntrain_path, train_count = get_files(base_dir,train_dir)\ntest_path, test_count = get_files(base_dir,test_dir)\n\nwith open(get_path(base_dir,json_file)) as f:\n    class_names = json.load(f)\n    class_dict = pd.Series(class_names.values()).to_dict()\n    f.close()\n\ndata = pd.read_csv(get_path(base_dir, labels_file))\ndata['class_name'] = data.label.map(class_dict)\n\nprint(\"No of Train Images: {}\".format(train_count))\nprint(\"No of Test Images: {}\".format(test_count))\nprint(\"No of Classes: {}\".format(len(class_dict)))\nprint(\"Classes:\")\nfor v in class_dict.values():\n    print(\" \\u2022 {}\".format(v))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['class_name'].value_counts().plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk(train_path):\n    for filename in filenames:\n        image = cv2.imread(os.path.join(train_path, filename))\n        image_size = image.shape\n        break\n\nimage_size","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"def visualize_img(images):\n    fig = plt.figure(figsize=(20, 15))\n    for i,a in enumerate(images):\n        fig.add_subplot(4, 4, i+1, xticks=[], yticks=[])\n        path = get_path(train_path, a)\n        img = cv2.imread(path)\n        plt.imshow(img)\n        plt.title(data[data.image_id == a].class_name.values[0])\n    \nfig = plt.figure(figsize=(15, 15))\nfor i in range(5):\n    images = data[data.label == i].image_id\n    images = np.random.choice(images , 4)\n    visualize_img(images)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loading the Models\n1. VGG16\n2. DenseNet169"},{"metadata":{"trusted":true},"cell_type":"code","source":"vgg_model = tf.keras.models.load_model(\"../input/cassava-models/vgg16.h5\")\ndensenet_model = tf.keras.models.load_model(\"../input/cassava-models/densenet.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss = pd.read_csv(os.path.join(base_dir, \"sample_submission.csv\"))\nss.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Helper Function"},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image\ndef predict(image_path, model):\n    im = Image.open(image_path)\n    test_image = np.asarray(im)\n    processed_test_image = process_image(test_image)\n    processed_test_image = np.expand_dims(processed_test_image, axis = 0)\n    \n    ps = model.predict(processed_test_image)\n    return ps\n    \ndef process_image(image):\n    image = tf.cast(image , tf.float32)\n    image = tf.image.resize(image , (224 , 224))\n    image = image/255\n    image = image.numpy()\n    return image\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Ensemble"},{"metadata":{"trusted":true},"cell_type":"code","source":"model1_list=[]\nmodel2_list=[]\n\npredicted_label_list = []\n\nfor image in ss.image_id:\n    model1_list.append(predict(os.path.join(test_path, image), vgg_model))\n    model2_list.append(predict(os.path.join(test_path, image), densenet_model))\n\nfor vgg,dense in zip(model1_list, model2_list):\n    predicted_label_list.append(np.argmax(vgg/np.linalg.norm(vgg) + dense/np.linalg.norm(dense)))\n    \nss['label'] = predicted_label_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss.to_csv('submission.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}